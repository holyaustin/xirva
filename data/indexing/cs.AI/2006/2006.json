[{"id": "2006.00059", "submitter": "Mehul Bhatt", "authors": "Vasiliki Kondyli and Mehul Bhatt and Jakob Suchan", "title": "Towards a Human-Centred Cognitive Model of Visuospatial Complexity in\n  Everyday Driving", "comments": "9th European Starting AI Researchers Symposium (STAIRS), at ECAI\n  2020, the 24th European Conference on Artificial Intelligence (ECAI).,\n  Santiago de Compostela, Spain", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CV cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a human-centred, cognitive model of visuospatial complexity in\neveryday, naturalistic driving conditions. With a focus on visual perception,\nthe model incorporates quantitative, structural, and dynamic attributes\nidentifiable in the chosen context; the human-centred basis of the model lies\nin its behavioural evaluation with human subjects with respect to\npsychophysical measures pertaining to embodied visuoauditory attention. We\nreport preliminary steps to apply the developed cognitive model of visuospatial\ncomplexity for human-factors guided dataset creation and benchmarking, and for\nits use as a semantic template for the (explainable) computational analysis of\nvisuospatial complexity.\n", "versions": [{"version": "v1", "created": "Fri, 29 May 2020 20:12:39 GMT"}, {"version": "v2", "created": "Tue, 2 Jun 2020 07:01:09 GMT"}], "update_date": "2020-06-03", "authors_parsed": [["Kondyli", "Vasiliki", ""], ["Bhatt", "Mehul", ""], ["Suchan", "Jakob", ""]]}, {"id": "2006.00088", "submitter": "Filip Ilievski", "authors": "Filip Ilievski and Daniel Garijo and Hans Chalupsky and Naren Teja\n  Divvala and Yixiang Yao and Craig Rogers and Rongpeng Li and Jun Liu and\n  Amandeep Singh and Daniel Schwabe and Pedro Szekely", "title": "KGTK: A Toolkit for Large Knowledge Graph Manipulation and Analysis", "comments": "16 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.DB", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Knowledge graphs (KGs) have become the preferred technology for representing,\nsharing and adding knowledge to modern AI applications. While KGs have become a\nmainstream technology, the RDF/SPARQL-centric toolset for operating with them\nat scale is heterogeneous, difficult to integrate and only covers a subset of\nthe operations that are commonly needed in data science applications. In this\npaper we present KGTK, a data science-centric toolkit designed to represent,\ncreate, transform, enhance and analyze KGs. KGTK represents graphs in tables\nand leverages popular libraries developed for data science applications,\nenabling a wide audience of developers to easily construct knowledge graph\npipelines for their applications. We illustrate the framework with real-world\nscenarios where we have used KGTK to integrate and manipulate large KGs, such\nas Wikidata, DBpedia and ConceptNet.\n", "versions": [{"version": "v1", "created": "Fri, 29 May 2020 21:29:14 GMT"}, {"version": "v2", "created": "Sun, 23 May 2021 15:14:45 GMT"}, {"version": "v3", "created": "Wed, 26 May 2021 15:22:48 GMT"}], "update_date": "2021-05-27", "authors_parsed": [["Ilievski", "Filip", ""], ["Garijo", "Daniel", ""], ["Chalupsky", "Hans", ""], ["Divvala", "Naren Teja", ""], ["Yao", "Yixiang", ""], ["Rogers", "Craig", ""], ["Li", "Rongpeng", ""], ["Liu", "Jun", ""], ["Singh", "Amandeep", ""], ["Schwabe", "Daniel", ""], ["Szekely", "Pedro", ""]]}, {"id": "2006.00093", "submitter": "Giulia Vilone", "authors": "Giulia Vilone and Luca Longo", "title": "Explainable Artificial Intelligence: a Systematic Review", "comments": "78 pages, 18 figures, journal paper to be submitted to Information\n  Fusion", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Explainable Artificial Intelligence (XAI) has experienced a significant\ngrowth over the last few years. This is due to the widespread application of\nmachine learning, particularly deep learning, that has led to the development\nof highly accurate models but lack explainability and interpretability. A\nplethora of methods to tackle this problem have been proposed, developed and\ntested. This systematic review contributes to the body of knowledge by\nclustering these methods with a hierarchical classification system with four\nmain clusters: review articles, theories and notions, methods and their\nevaluation. It also summarises the state-of-the-art in XAI and recommends\nfuture research directions.\n", "versions": [{"version": "v1", "created": "Fri, 29 May 2020 21:41:12 GMT"}, {"version": "v2", "created": "Tue, 2 Jun 2020 20:56:06 GMT"}, {"version": "v3", "created": "Thu, 4 Jun 2020 15:49:44 GMT"}, {"version": "v4", "created": "Mon, 12 Oct 2020 16:16:40 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Vilone", "Giulia", ""], ["Longo", "Luca", ""]]}, {"id": "2006.00113", "submitter": "Abdelaziz Lakhfif", "authors": "Abdelaziz Lakhfif and Mohamed Tayeb Laskri", "title": "A frame semantics based approach to comparative study of digitized\n  corpus", "comments": "Proceedings of the 7th International Symposium ISKO-Maghreb Knowledge\n  Organization in the Perspective of Digital Humanities: Research &\n  Applications November 25th & 26th, 2018, pp. 217-223, Bejaia, Algeria", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  in this paper, we present a corpus linguistics based approach applied to\nanalyzing digitized classical multilingual novels and narrative texts, from a\nsemantic point of view. Digitized novels such as \"the hobbit (Tolkien J. R. R.,\n1937)\" and \"the hound of the Baskervilles (Doyle A. C. 1901-1902)\", which were\nwidely translated to dozens of languages, provide rich materials for analyzing\nlanguages differences from several perspectives and within a number of\ndisciplines like linguistics, philosophy and cognitive science. Taking motion\nevents conceptualization as a case study, this paper, focus on the morphologic,\nsyntactic, and semantic annotation process of English-Arabic aligned corpus\ncreated from a digitized novels, in order to re-examine the linguistic\nencodings of motion events in English and Arabic in terms of Frame Semantics.\nThe present study argues that differences in motion events conceptualization\nacross languages can be described with frame structure and frame-to-frame\nrelations.\n", "versions": [{"version": "v1", "created": "Fri, 29 May 2020 22:56:25 GMT"}], "update_date": "2020-06-02", "authors_parsed": [["Lakhfif", "Abdelaziz", ""], ["Laskri", "Mohamed Tayeb", ""]]}, {"id": "2006.00195", "submitter": "Arash Mohammadi", "authors": "Parvin Malekzadeh, Mohammad Salimibeni, Arash Mohammadi, Akbar Assa,\n  and Konstantinos N. Plataniotis", "title": "MM-KTD: Multiple Model Kalman Temporal Differences for Reinforcement\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There has been an increasing surge of interest on development of advanced\nReinforcement Learning (RL) systems as intelligent approaches to learn optimal\ncontrol policies directly from smart agents' interactions with the environment.\nObjectives: In a model-free RL method with continuous state-space, typically,\nthe value function of the states needs to be approximated. In this regard, Deep\nNeural Networks (DNNs) provide an attractive modeling mechanism to approximate\nthe value function using sample transitions. DNN-based solutions, however,\nsuffer from high sensitivity to parameter selection, are prone to overfitting,\nand are not very sample efficient. A Kalman-based methodology, on the other\nhand, could be used as an efficient alternative. Such an approach, however,\ncommonly requires a-priori information about the system (such as noise\nstatistics) to perform efficiently. The main objective of this paper is to\naddress this issue. Methods: As a remedy to the aforementioned problems, this\npaper proposes an innovative Multiple Model Kalman Temporal Difference (MM-KTD)\nframework, which adapts the parameters of the filter using the observed states\nand rewards. Moreover, an active learning method is proposed to enhance the\nsampling efficiency of the system. More specifically, the estimated uncertainty\nof the value functions are exploited to form the behaviour policy leading to\nmore visits to less certain values, therefore, improving the overall learning\nsample efficiency. As a result, the proposed MM-KTD framework can learn the\noptimal policy with significantly reduced number of samples as compared to its\nDNN-based counterparts. Results: To evaluate performance of the proposed MM-KTD\nframework, we have performed a comprehensive set of experiments based on three\nRL benchmarks. Experimental results show superiority of the MM-KTD framework in\ncomparison to its state-of-the-art counterparts.\n", "versions": [{"version": "v1", "created": "Sat, 30 May 2020 06:39:55 GMT"}], "update_date": "2020-06-02", "authors_parsed": [["Malekzadeh", "Parvin", ""], ["Salimibeni", "Mohammad", ""], ["Mohammadi", "Arash", ""], ["Assa", "Akbar", ""], ["Plataniotis", "Konstantinos N.", ""]]}, {"id": "2006.00199", "submitter": "Sule Anjomshoae", "authors": "Sule Anjomshoae, Kary Fr\\\"amling and Amro Najjar", "title": "Explanations of Black-Box Model Predictions by Contextual Importance and\n  Utility", "comments": null, "journal-ref": null, "doi": "10.1007/978-3-030-30391-4_6", "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The significant advances in autonomous systems together with an immensely\nwider application domain have increased the need for trustable intelligent\nsystems. Explainable artificial intelligence is gaining considerable attention\namong researchers and developers to address this requirement. Although there is\nan increasing number of works on interpretable and transparent machine learning\nalgorithms, they are mostly intended for the technical users. Explanations for\nthe end-user have been neglected in many usable and practical applications. In\nthis work, we present the Contextual Importance (CI) and Contextual Utility\n(CU) concepts to extract explanations that are easily understandable by experts\nas well as novice users. This method explains the prediction results without\ntransforming the model into an interpretable one. We present an example of\nproviding explanations for linear and non-linear models to demonstrate the\ngeneralizability of the method. CI and CU are numerical values that can be\nrepresented to the user in visuals and natural language form to justify actions\nand explain reasoning for individual instances, situations, and contexts. We\nshow the utility of explanations in car selection example and Iris flower\nclassification by presenting complete (i.e. the causes of an individual\nprediction) and contrastive explanation (i.e. contrasting instance against the\ninstance of interest). The experimental results show the feasibility and\nvalidity of the provided explanation methods.\n", "versions": [{"version": "v1", "created": "Sat, 30 May 2020 06:49:50 GMT"}], "update_date": "2020-06-02", "authors_parsed": [["Anjomshoae", "Sule", ""], ["Fr\u00e4mling", "Kary", ""], ["Najjar", "Amro", ""]]}, {"id": "2006.00212", "submitter": "Bo Pang", "authors": "Bo Pang, Kaiwen Zha, Hanwen Cao, Jiajun Tang, Minghui Yu, Cewu Lu", "title": "Complex Sequential Understanding through the Awareness of Spatial and\n  Temporal Concepts", "comments": "15 pages, 5 figures, 8 tables", "journal-ref": "Nat Mach Intell 2, 24-253 (2020)", "doi": "10.1038/s42256-020-0168-3", "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding sequential information is a fundamental task for artificial\nintelligence. Current neural networks attempt to learn spatial and temporal\ninformation as a whole, limited their abilities to represent large scale\nspatial representations over long-range sequences. Here, we introduce a new\nmodeling strategy called Semi-Coupled Structure (SCS), which consists of deep\nneural networks that decouple the complex spatial and temporal concepts\nlearning. Semi-Coupled Structure can learn to implicitly separate input\ninformation into independent parts and process these parts respectively.\nExperiments demonstrate that a Semi-Coupled Structure can successfully annotate\nthe outline of an object in images sequentially and perform video action\nrecognition. For sequence-to-sequence problems, a Semi-Coupled Structure can\npredict future meteorological radar echo images based on observed images. Taken\ntogether, our results demonstrate that a Semi-Coupled Structure has the\ncapacity to improve the performance of LSTM-like models on large scale\nsequential tasks.\n", "versions": [{"version": "v1", "created": "Sat, 30 May 2020 07:51:50 GMT"}], "update_date": "2020-06-02", "authors_parsed": [["Pang", "Bo", ""], ["Zha", "Kaiwen", ""], ["Cao", "Hanwen", ""], ["Tang", "Jiajun", ""], ["Yu", "Minghui", ""], ["Lu", "Cewu", ""]]}, {"id": "2006.00283", "submitter": "Dennis Soemers", "authors": "Dennis J. N. J. Soemers, \\'Eric Piette, Matthew Stephenson, Cameron\n  Browne", "title": "Manipulating the Distributions of Experience used for Self-Play Learning\n  in Expert Iteration", "comments": "Accepted at the IEEE Conference on Games (CoG) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Expert Iteration (ExIt) is an effective framework for learning game-playing\npolicies from self-play. ExIt involves training a policy to mimic the search\nbehaviour of a tree search algorithm - such as Monte-Carlo tree search - and\nusing the trained policy to guide it. The policy and the tree search can then\niteratively improve each other, through experience gathered in self-play\nbetween instances of the guided tree search algorithm. This paper outlines\nthree different approaches for manipulating the distribution of data collected\nfrom self-play, and the procedure that samples batches for learning updates\nfrom the collected data. Firstly, samples in batches are weighted based on the\ndurations of the episodes in which they were originally experienced. Secondly,\nPrioritized Experience Replay is applied within the ExIt framework, to\nprioritise sampling experience from which we expect to obtain valuable training\nsignals. Thirdly, a trained exploratory policy is used to diversify the\ntrajectories experienced in self-play. This paper summarises the effects of\nthese manipulations on training performance evaluated in fourteen different\nboard games. We find major improvements in early training performance in some\ngames, and minor improvements averaged over fourteen games.\n", "versions": [{"version": "v1", "created": "Sat, 30 May 2020 14:32:46 GMT"}], "update_date": "2020-06-02", "authors_parsed": [["Soemers", "Dennis J. N. J.", ""], ["Piette", "\u00c9ric", ""], ["Stephenson", "Matthew", ""], ["Browne", "Cameron", ""]]}, {"id": "2006.00417", "submitter": "Jeiyoon Park", "authors": "Jeiyoon Park, Chanhee Lee, Kuekyeng Kim, Heuiseok Lim", "title": "Variational Reward Estimator Bottleneck: Learning Robust Reward\n  Estimator for Multi-Domain Task-Oriented Dialog", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite its notable success in adversarial learning approaches to\nmulti-domain task-oriented dialog system, training the dialog policy via\nadversarial inverse reinforcement learning often fails to balance the\nperformance of the policy generator and reward estimator. During optimization,\nthe reward estimator often overwhelms the policy generator and produces\nexcessively uninformative gradients. We proposes the Variational Reward\nestimator Bottleneck (VRB), which is an effective regularization method that\naims to constrain unproductive information flows between inputs and the reward\nestimator. The VRB focuses on capturing discriminative features, by exploiting\ninformation bottleneck on mutual information. Empirical results on a\nmulti-domain task-oriented dialog dataset demonstrate that the VRB\nsignificantly outperforms previous methods.\n", "versions": [{"version": "v1", "created": "Sun, 31 May 2020 02:44:36 GMT"}], "update_date": "2020-06-02", "authors_parsed": [["Park", "Jeiyoon", ""], ["Lee", "Chanhee", ""], ["Kim", "Kuekyeng", ""], ["Lim", "Heuiseok", ""]]}, {"id": "2006.00483", "submitter": "Erwin de Gelder", "authors": "Erwin de Gelder, Jeroen Manders, Corrado Grappiolo, Jan-Pieter\n  Paardekooper, Olaf Op den Camp, Bart De Schutter", "title": "Real-World Scenario Mining for the Assessment of Automated Vehicles", "comments": "8 pages, 8 figures, 4 tables", "journal-ref": "Proceedings of the IEEE 2020 Intelligent Transportation Systems\n  Conference (ITSC)", "doi": "10.1109/ITSC45102.2020.9294652", "report-no": null, "categories": "cs.RO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Scenario-based methods for the assessment of Automated Vehicles (AVs) are\nwidely supported by many players in the automotive field. Scenarios captured\nfrom real-world data can be used to define the scenarios for the assessment and\nto estimate their relevance. Therefore, different techniques are proposed for\ncapturing scenarios from real-world data. In this paper, we propose a new\nmethod to capture scenarios from real-world data using a two-step approach. The\nfirst step consists in automatically labeling the data with tags. Second, we\nmine the scenarios, represented by a combination of tags, based on the labeled\ntags. One of the benefits of our approach is that the tags can be used to\nidentify characteristics of a scenario that are shared among different type of\nscenarios. In this way, these characteristics need to be identified only once.\nFurthermore, the method is not specific for one type of scenario and,\ntherefore, it can be applied to a large variety of scenarios. We provide two\nexamples to illustrate the method. This paper is concluded with some promising\nfuture possibilities for our approach, such as automatic generation of\nscenarios for the assessment of automated vehicles.\n", "versions": [{"version": "v1", "created": "Sun, 31 May 2020 10:10:39 GMT"}, {"version": "v2", "created": "Mon, 12 Jul 2021 09:33:28 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["de Gelder", "Erwin", ""], ["Manders", "Jeroen", ""], ["Grappiolo", "Corrado", ""], ["Paardekooper", "Jan-Pieter", ""], ["Camp", "Olaf Op den", ""], ["De Schutter", "Bart", ""]]}, {"id": "2006.00555", "submitter": "Samira Abnar", "authors": "Samira Abnar and Mostafa Dehghani and Willem Zuidema", "title": "Transferring Inductive Biases through Knowledge Distillation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Having the right inductive biases can be crucial in many tasks or scenarios\nwhere data or computing resources are a limiting factor, or where training data\nis not perfectly representative of the conditions at test time. However,\ndefining, designing and efficiently adapting inductive biases is not\nnecessarily straightforward. In this paper, we explore the power of knowledge\ndistillation for transferring the effect of inductive biases from one model to\nanother. We consider families of models with different inductive biases, LSTMs\nvs. Transformers and CNNs vs. MLPs, in the context of tasks and scenarios where\nhaving the right inductive biases is critical. We study the effect of inductive\nbiases on the solutions the models converge to and investigate how and to what\nextent the effect of inductive biases is transferred through knowledge\ndistillation, in terms of not only performance but also different aspects of\nconverged solutions.\n", "versions": [{"version": "v1", "created": "Sun, 31 May 2020 16:34:08 GMT"}, {"version": "v2", "created": "Tue, 2 Jun 2020 13:19:36 GMT"}, {"version": "v3", "created": "Sun, 4 Oct 2020 19:57:06 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Abnar", "Samira", ""], ["Dehghani", "Mostafa", ""], ["Zuidema", "Willem", ""]]}, {"id": "2006.00587", "submitter": "Zhizhou Ren", "authors": "Jianhao Wang, Zhizhou Ren, Beining Han, Jianing Ye, Chongjie Zhang", "title": "Towards Understanding Linear Value Decomposition in Cooperative\n  Multi-Agent Q-Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Value decomposition is a popular and promising approach to scaling up\nmulti-agent reinforcement learning in cooperative settings. However, the\ntheoretical understanding of such methods is limited. In this paper, we\nintroduce a variant of the fitted Q-iteration framework for analyzing\nmulti-agent Q-learning with value decomposition. Based on this framework, we\nderive a closed-form solution to the empirical Bellman error minimization with\nlinear value decomposition. With this novel solution, we further reveal two\ninteresting insights: 1) linear value decomposition implicitly implements a\nclassical multi-agent credit assignment called counterfactual difference\nrewards; and 2) On-policy data distribution or richer Q function classes can\nimprove the training stability of multi-agent Q-learning. In the empirical\nstudy, our experiments demonstrate the realizability of our theoretical\nclosed-form formulation and implications in the didactic examples and a broad\nset of StarCraft II unit micromanagement tasks, respectively.\n", "versions": [{"version": "v1", "created": "Sun, 31 May 2020 19:14:03 GMT"}, {"version": "v2", "created": "Tue, 23 Jun 2020 15:11:41 GMT"}, {"version": "v3", "created": "Mon, 5 Oct 2020 15:24:13 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Wang", "Jianhao", ""], ["Ren", "Zhizhou", ""], ["Han", "Beining", ""], ["Ye", "Jianing", ""], ["Zhang", "Chongjie", ""]]}, {"id": "2006.00592", "submitter": "Sahan Bulathwela", "authors": "Sahan Bulathwela, Mar\\'ia P\\'erez-Ortiz, Aldo Lipani, Emine Yilmaz and\n  John Shawe-Taylor", "title": "Predicting Engagement in Video Lectures", "comments": "In Proceedings of International Conference on Educational Data Mining\n  2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The explosion of Open Educational Resources (OERs) in the recent years\ncreates the demand for scalable, automatic approaches to process and evaluate\nOERs, with the end goal of identifying and recommending the most suitable\neducational materials for learners. We focus on building models to find the\ncharacteristics and features involved in context-agnostic engagement (i.e.\npopulation-based), a seldom researched topic compared to other contextualised\nand personalised approaches that focus more on individual learner engagement.\nLearner engagement, is arguably a more reliable measure than popularity/number\nof views, is more abundant than user ratings and has also been shown to be a\ncrucial component in achieving learning outcomes. In this work, we explore the\nidea of building a predictive model for population-based engagement in\neducation. We introduce a novel, large dataset of video lectures for predicting\ncontext-agnostic engagement and propose both cross-modal and modality-specific\nfeature sets to achieve this task. We further test different strategies for\nquantifying learner engagement signals. We demonstrate the use of our approach\nin the case of data scarcity. Additionally, we perform a sensitivity analysis\nof the best performing model, which shows promising performance and can be\neasily integrated into an educational recommender system for OERs.\n", "versions": [{"version": "v1", "created": "Sun, 31 May 2020 19:28:16 GMT"}, {"version": "v2", "created": "Wed, 10 Jun 2020 15:33:02 GMT"}], "update_date": "2020-06-11", "authors_parsed": [["Bulathwela", "Sahan", ""], ["P\u00e9rez-Ortiz", "Mar\u00eda", ""], ["Lipani", "Aldo", ""], ["Yilmaz", "Emine", ""], ["Shawe-Taylor", "John", ""]]}, {"id": "2006.00715", "submitter": "Shengcai Liu", "authors": "Kangfei Zhao, Shengcai Liu, Yu Rong, Jeffrey Xu Yu", "title": "Towards Feature-free TSP Solver Selection: A Deep Learning Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Travelling Salesman Problem (TSP) is a classical NP-hard problem and has\nbroad applications in many disciplines and industries. In a large scale\nlocation-based services system, users issue TSP queries concurrently, where a\nTSP query is a TSP instance with $n$ points. In the literature, many advanced\nTSP solvers are developed to find high-quality solutions. Such solvers can\nsolve some TSP instances efficiently but may take an extremely long time for\nsome other instances. Due to the diversity of TSP instances, it is well-known\nthat there exists no universal best solver dominating all other solvers on all\npossible TSP instances. To solve TSP efficiently, in addition to developing new\nTSP solvers, it needs to find a per-instance solver for each TSP instance,\nwhich is known as the TSP solver selection problem. In this paper, for the\nfirst time, we propose a deep learning framework, \\CTAS, for TSP solver\nselection in an end-to-end manner. Specifically, \\CTAS exploits deep\nconvolutional neural networks to extract informative features from TSP\ninstances and involves data argumentation strategies to handle the scarcity of\nlabeled TSP instances. Moreover, to support large scale TSP solver selection,\nwe construct a challenging TSP benchmark dataset with 6,000 instances, which is\nknown as the largest TSP benchmark. Our \\CTAS achieves over 2$\\times$ speedup\nof the average running time, comparing the single best solver, and outperforms\nthe state-of-the-art statistical models.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jun 2020 04:48:36 GMT"}, {"version": "v2", "created": "Wed, 14 Apr 2021 10:28:04 GMT"}], "update_date": "2021-04-15", "authors_parsed": [["Zhao", "Kangfei", ""], ["Liu", "Shengcai", ""], ["Rong", "Yu", ""], ["Yu", "Jeffrey Xu", ""]]}, {"id": "2006.00778", "submitter": "Desmond Wuhan Cai", "authors": "Desmond Cai, Duc Thien Nguyen, Shiau Hong Lim, Laura Wynter", "title": "Variational Bayesian Inference for Crowdsourcing Predictions", "comments": "7 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Crowdsourcing has emerged as an effective means for performing a number of\nmachine learning tasks such as annotation and labelling of images and other\ndata sets. In most early settings of crowdsourcing, the task involved\nclassification, that is assigning one of a discrete set of labels to each task.\nRecently, however, more complex tasks have been attempted including asking\ncrowdsource workers to assign continuous labels, or predictions. In essence,\nthis involves the use of crowdsourcing for function estimation. We are\nmotivated by this problem to drive applications such as collaborative\nprediction, that is, harnessing the wisdom of the crowd to predict quantities\nmore accurately. To do so, we propose a Bayesian approach aimed specifically at\nalleviating overfitting, a typical impediment to accurate prediction models in\npractice. In particular, we develop a variational Bayesian technique for two\ndifferent worker noise models - one that assumes workers' noises are\nindependent and the other that assumes workers' noises have a latent low-rank\nstructure. Our evaluations on synthetic and real-world datasets demonstrate\nthat these Bayesian approaches perform significantly better than existing\nnon-Bayesian approaches and are thus potentially useful for this class of\ncrowdsourcing problems.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jun 2020 08:11:50 GMT"}, {"version": "v2", "created": "Tue, 2 Jun 2020 02:53:30 GMT"}], "update_date": "2020-06-03", "authors_parsed": [["Cai", "Desmond", ""], ["Nguyen", "Duc Thien", ""], ["Lim", "Shiau Hong", ""], ["Wynter", "Laura", ""]]}, {"id": "2006.00871", "submitter": "Raz Saremi", "authors": "Denisse Martinez Mejorado, Razieh Saremi, Ye Yang, and Jose E.\n  Ramirez-Marquez", "title": "Study on Patterns and Effect of Task Diversity in Software Crowdsourcing", "comments": "10 pages, 8 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Context: The success of software crowdsourcing depends on steady tasks supply\nand active worker pool. Existing analysis reveals an average task failure ratio\nof 15.7% in software crowdsourcing market. Goal: The objective of this study is\nto empirically investigate patterns and effect of task diversity in software\ncrowdsourcing platform in order to improve the success and efficiency of\nsoftware crowdsourcing. Method: We propose a conceptual task diversity model,\nand develop an approach to measuring and analyzing task diversity.More\nspecifically, this includes grouping similar tasks, ranking them based on their\ncompetition level and identifying the dominant attributes that distinguish\namong these levels, and then studying the impact of task diversity on task\nsuccess and worker performance in crowdsourcing platform. The empirical study\nis conducted on more than one year's real-world data from TopCoder, the leading\nsoftware crowdsourcing platform. Results: We identified that monetary prize and\ntask complexity are the dominant attributes that differentiate among different\ncompetition levels. Based on these dominant attributes, we found three task\ndiversity patterns (configurations) from workers behavior perspective:\nresponsive to prize, responsive to prize and complexity and over responsive to\nprize. This study supports that1) responsive to prize configuration provides\nhighest level of task density and workers' reliability in a platform; 2)\nresponsive to prize and complexity configuration leads to attracting high level\nof trustworthy workers; 3) over responsive to prize configuration results in\nhighest task stability and the lowest failure ratio in the platform for not\nhigh similar tasks.\n", "versions": [{"version": "v1", "created": "Fri, 29 May 2020 02:07:33 GMT"}, {"version": "v2", "created": "Wed, 29 Jul 2020 22:22:36 GMT"}], "update_date": "2020-07-31", "authors_parsed": [["Mejorado", "Denisse Martinez", ""], ["Saremi", "Razieh", ""], ["Yang", "Ye", ""], ["Ramirez-Marquez", "Jose E.", ""]]}, {"id": "2006.00882", "submitter": "Adrien Bennetot", "authors": "Adrien Bennetot, Vicky Charisi, Natalia D\\'iaz-Rodr\\'iguez", "title": "Should artificial agents ask for help in human-robot collaborative\n  problem-solving?", "comments": "Accepted at Brain-PIL Workshop - ICRA2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transferring as fast as possible the functioning of our brain to artificial\nintelligence is an ambitious goal that would help advance the state of the art\nin AI and robotics. It is in this perspective that we propose to start from\nhypotheses derived from an empirical study in a human-robot interaction and to\nverify if they are validated in the same way for children as for a basic\nreinforcement learning algorithm. Thus, we check whether receiving help from an\nexpert when solving a simple close-ended task (the Towers of Hano\\\"i) allows to\naccelerate or not the learning of this task, depending on whether the\nintervention is canonical or requested by the player. Our experiences have\nallowed us to conclude that, whether requested or not, a Q-learning algorithm\nbenefits in the same way from expert help as children do.\n", "versions": [{"version": "v1", "created": "Mon, 25 May 2020 09:15:30 GMT"}], "update_date": "2020-06-02", "authors_parsed": [["Bennetot", "Adrien", ""], ["Charisi", "Vicky", ""], ["D\u00edaz-Rodr\u00edguez", "Natalia", ""]]}, {"id": "2006.00888", "submitter": "Ursin Brunner", "authors": "Ursin Brunner and Kurt Stockinger", "title": "ValueNet: A Natural Language-to-SQL System that Learns from Database\n  Information", "comments": null, "journal-ref": "37th IEEE International Conference on Data Engineering (ICDE 2021)", "doi": null, "report-no": null, "categories": "cs.DB cs.AI", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Building natural language (NL) interfaces for databases has been a\nlong-standing challenge for several decades. The major advantage of these\nso-called NL-to-SQL systems is that end-users can query complex databases\nwithout the need to know SQL or the underlying database schema. Due to\nsignificant advancements in machine learning, the recent focus of research has\nbeen on neural networks to tackle this challenge on complex datasets like\nSpider. Several recent NL-to-SQL systems achieve promising results on this\ndataset. However, none of the published systems, that provide either the source\ncode or executable binaries, extract and incorporate values from the user\nquestions for generating SQL statements. Thus, the practical use of these\nsystems in a real-world scenario has not been sufficiently demonstrated yet.\n  In this paper we propose ValueNet light and ValueNet -- two end-to-end\nNL-to-SQL systems that incorporate values using the challenging Spider dataset.\nThe main idea of our approach is to use not only metadata information from the\nunderlying database but also information on the base data as input for our\nneural network architecture. In particular, we propose a novel architecture\nsketch to extract values from a user question and come up with possible value\ncandidates which are not explicitly mentioned in the question. We then use a\nneural model based on an encoder-decoder architecture to synthesize the SQL\nquery. Finally, we evaluate our model on the Spider challenge using the\nExecution Accuracy metric, a more difficult metric than used by most\nparticipants of the challenge. Our experimental evaluation demonstrates that\nValueNet light and ValueNet reach state-of-the-art results of 67% and 62%\naccuracy, respectively, for translating from NL to SQL whilst incorporating\nvalues.\n", "versions": [{"version": "v1", "created": "Fri, 29 May 2020 15:43:39 GMT"}, {"version": "v2", "created": "Mon, 22 Feb 2021 09:31:01 GMT"}], "update_date": "2021-02-24", "authors_parsed": [["Brunner", "Ursin", ""], ["Stockinger", "Kurt", ""]]}, {"id": "2006.00900", "submitter": "Henry Charlesworth", "authors": "Henry Charlesworth and Giovanni Montana", "title": "PlanGAN: Model-based Planning With Sparse Rewards and Multiple Goals", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning with sparse rewards remains a significant challenge in reinforcement\nlearning (RL), especially when the aim is to train a policy capable of\nachieving multiple different goals. To date, the most successful approaches for\ndealing with multi-goal, sparse reward environments have been model-free RL\nalgorithms. In this work we propose PlanGAN, a model-based algorithm\nspecifically designed for solving multi-goal tasks in environments with sparse\nrewards. Our method builds on the fact that any trajectory of experience\ncollected by an agent contains useful information about how to achieve the\ngoals observed during that trajectory. We use this to train an ensemble of\nconditional generative models (GANs) to generate plausible trajectories that\nlead the agent from its current state towards a specified goal. We then combine\nthese imagined trajectories into a novel planning algorithm in order to achieve\nthe desired goal as efficiently as possible. The performance of PlanGAN has\nbeen tested on a number of robotic navigation/manipulation tasks in comparison\nwith a range of model-free reinforcement learning baselines, including\nHindsight Experience Replay. Our studies indicate that PlanGAN can achieve\ncomparable performance whilst being around 4-8 times more sample efficient.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jun 2020 12:53:09 GMT"}], "update_date": "2020-06-02", "authors_parsed": [["Charlesworth", "Henry", ""], ["Montana", "Giovanni", ""]]}, {"id": "2006.00917", "submitter": "Peter Hillmann", "authors": "Tobias Uhlig and Peter Hillmann and Oliver Rose", "title": "Evaluation of the general applicability of Dragoon for the k-center\n  problem", "comments": null, "journal-ref": "Winter Simulation Conference 2016", "doi": null, "report-no": null, "categories": "cs.DC cs.AI cs.CC cs.MA cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The k-center problem is a fundamental problem we often face when considering\ncomplex service systems. Typical challenges include the placement of warehouses\nin logistics or positioning of servers for content delivery networks. We\npreviously have proposed Dragoon as an effective algorithm to approach the\nk-center problem. This paper evaluates Dragoon with a focus on potential worst\ncase behavior in comparison to other techniques. We use an evolutionary\nalgorithm to generate instances of the k-center problem that are especially\nchallenging for Dragoon. Ultimately, our experiments confirm the previous good\nresults of Dragoon, however, we also can reliably find scenarios where it is\nclearly outperformed by other approaches.\n", "versions": [{"version": "v1", "created": "Thu, 28 May 2020 16:54:17 GMT"}], "update_date": "2020-06-02", "authors_parsed": [["Uhlig", "Tobias", ""], ["Hillmann", "Peter", ""], ["Rose", "Oliver", ""]]}, {"id": "2006.00970", "submitter": "Mohammad-Ali Javidian", "authors": "Mohammad Ali Javidian and Marco Valtorta and Pooyan Jamshidi", "title": "Learning LWF Chain Graphs: A Markov Blanket Discovery Approach", "comments": "This is an extended version of the accepted paper for UAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper provides a graphical characterization of Markov blankets in chain\ngraphs (CGs) under the Lauritzen-Wermuth-Frydenberg (LWF) interpretation. The\ncharacterization is different from the well-known one for Bayesian networks and\ngeneralizes it. We provide a novel scalable and sound algorithm for Markov\nblanket discovery in LWF CGs and prove that the Grow-Shrink algorithm, the IAMB\nalgorithm, and its variants are still correct for Markov blanket discovery in\nLWF CGs under the same assumptions as for Bayesian networks. We provide a sound\nand scalable constraint-based framework for learning the structure of LWF CGs\nfrom faithful causally sufficient data and prove its correctness when the\nMarkov blanket discovery algorithms in this paper are used. Our proposed\nalgorithms compare positively/competitively against the state-of-the-art LCD\n(Learn Chain graphs via Decomposition) algorithm, depending on the algorithm\nthat is used for Markov blanket discovery. Our proposed algorithms make a broad\nrange of inference/learning problems computationally tractable and more\nreliable because they exploit locality.\n", "versions": [{"version": "v1", "created": "Fri, 29 May 2020 16:44:25 GMT"}], "update_date": "2020-06-02", "authors_parsed": [["Javidian", "Mohammad Ali", ""], ["Valtorta", "Marco", ""], ["Jamshidi", "Pooyan", ""]]}, {"id": "2006.00979", "submitter": "Bobak Shahriari", "authors": "Matt Hoffman, Bobak Shahriari, John Aslanides, Gabriel Barth-Maron,\n  Feryal Behbahani, Tamara Norman, Abbas Abdolmaleki, Albin Cassirer, Fan Yang,\n  Kate Baumli, Sarah Henderson, Alex Novikov, Sergio G\\'omez Colmenarejo,\n  Serkan Cabi, Caglar Gulcehre, Tom Le Paine, Andrew Cowie, Ziyu Wang, Bilal\n  Piot, and Nando de Freitas", "title": "Acme: A Research Framework for Distributed Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep reinforcement learning has led to many recent-and\ngroundbreaking-advancements. However, these advances have often come at the\ncost of both the scale and complexity of the underlying RL algorithms.\nIncreases in complexity have in turn made it more difficult for researchers to\nreproduce published RL algorithms or rapidly prototype ideas. To address this,\nwe introduce Acme, a tool to simplify the development of novel RL algorithms\nthat is specifically designed to enable simple agent implementations that can\nbe run at various scales of execution. Our aim is also to make the results of\nvarious RL algorithms developed in academia and industrial labs easier to\nreproduce and extend. To this end we are releasing baseline implementations of\nvarious algorithms, created using our framework. In this work we introduce the\nmajor design decisions behind Acme and show how these are used to construct\nthese baselines. We also experiment with these agents at different scales of\nboth complexity and computation-including distributed versions. Ultimately, we\nshow that the design decisions behind Acme lead to agents that can be scaled\nboth up and down and that, for the most part, greater levels of parallelization\nresult in agents with equivalent performance, just faster.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jun 2020 14:38:52 GMT"}], "update_date": "2020-06-02", "authors_parsed": [["Hoffman", "Matt", ""], ["Shahriari", "Bobak", ""], ["Aslanides", "John", ""], ["Barth-Maron", "Gabriel", ""], ["Behbahani", "Feryal", ""], ["Norman", "Tamara", ""], ["Abdolmaleki", "Abbas", ""], ["Cassirer", "Albin", ""], ["Yang", "Fan", ""], ["Baumli", "Kate", ""], ["Henderson", "Sarah", ""], ["Novikov", "Alex", ""], ["Colmenarejo", "Sergio G\u00f3mez", ""], ["Cabi", "Serkan", ""], ["Gulcehre", "Caglar", ""], ["Paine", "Tom Le", ""], ["Cowie", "Andrew", ""], ["Wang", "Ziyu", ""], ["Piot", "Bilal", ""], ["de Freitas", "Nando", ""]]}, {"id": "2006.00997", "submitter": "Tao Bian", "authors": "Tao Bian and Zhong-Ping Jiang", "title": "Temporal-Differential Learning in Continuous Environments", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI math.OC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, a new reinforcement learning (RL) method known as the method\nof temporal differential is introduced. Compared to the traditional\ntemporal-difference learning method, it plays a crucial role in developing\nnovel RL techniques for continuous environments. In particular, the\ncontinuous-time least squares policy evaluation (CT-LSPE) and the\ncontinuous-time temporal-differential (CT-TD) learning methods are developed.\nBoth theoretical and empirical evidences are provided to demonstrate the\neffectiveness of the proposed temporal-differential learning methodology.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jun 2020 15:01:03 GMT"}], "update_date": "2020-06-02", "authors_parsed": [["Bian", "Tao", ""], ["Jiang", "Zhong-Ping", ""]]}, {"id": "2006.01011", "submitter": "Mohammad Abdulaziz", "authors": "Mohammad Abdulaziz and Dominik Berger", "title": "Computing Plan-Length Bounds Using Lengths of Longest Paths", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We devise a method to exactly compute the length of the longest simple path\nin factored state spaces, like state spaces encountered in classical planning.\nAlthough the complexity of this problem is NEXP-Hard, we show that our method\ncan be used to compute practically useful upper-bounds on lengths of plans. We\nshow that the computed upper-bounds are significantly (in many cases, orders of\nmagnitude) better than bounds produced by previous bounding techniques and that\nthey can be used to improve the SAT-based planning.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jun 2020 15:16:50 GMT"}, {"version": "v2", "created": "Mon, 1 Mar 2021 11:17:15 GMT"}], "update_date": "2021-03-02", "authors_parsed": [["Abdulaziz", "Mohammad", ""], ["Berger", "Dominik", ""]]}, {"id": "2006.01016", "submitter": "Federico Carnevale", "authors": "Abhishek Das, Federico Carnevale, Hamza Merzic, Laura Rimell, Rosalia\n  Schneider, Josh Abramson, Alden Hung, Arun Ahuja, Stephen Clark, Gregory\n  Wayne, Felix Hill", "title": "Probing Emergent Semantics in Predictive Agents via Question Answering", "comments": "ICML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work has shown how predictive modeling can endow agents with rich\nknowledge of their surroundings, improving their ability to act in complex\nenvironments. We propose question-answering as a general paradigm to decode and\nunderstand the representations that such agents develop, applying our method to\ntwo recent approaches to predictive modeling -action-conditional CPC (Guo et\nal., 2018) and SimCore (Gregor et al., 2019). After training agents with these\npredictive objectives in a visually-rich, 3D environment with an assortment of\nobjects, colors, shapes, and spatial configurations, we probe their internal\nstate representations with synthetic (English) questions, without\nbackpropagating gradients from the question-answering decoder into the agent.\nThe performance of different agents when probed this way reveals that they\nlearn to encode factual, and seemingly compositional, information about\nobjects, properties and spatial relations from their physical environment. Our\napproach is intuitive, i.e. humans can easily interpret responses of the model\nas opposed to inspecting continuous vectors, and model-agnostic, i.e.\napplicable to any modeling approach. By revealing the implicit knowledge of\nobjects, quantities, properties and relations acquired by agents as they learn,\nquestion-conditional agent probing can stimulate the design and development of\nstronger predictive learning objectives.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jun 2020 15:27:36 GMT"}], "update_date": "2020-06-02", "authors_parsed": [["Das", "Abhishek", ""], ["Carnevale", "Federico", ""], ["Merzic", "Hamza", ""], ["Rimell", "Laura", ""], ["Schneider", "Rosalia", ""], ["Abramson", "Josh", ""], ["Hung", "Alden", ""], ["Ahuja", "Arun", ""], ["Clark", "Stephen", ""], ["Wayne", "Gregory", ""], ["Hill", "Felix", ""]]}, {"id": "2006.01022", "submitter": "Muhammad Zuhair Qadir", "authors": "Muhammad Zuhair Qadir, Songhao Piao, Haiyang Jiang and Mohammed El\n  Habib Souidi", "title": "A novel approach for multi-agent cooperative pursuit to capture grouped\n  evaders", "comments": "published paper's draft version", "journal-ref": "Journal of Supercomputing, J Supercomput 76 (2020)", "doi": "10.1007/s11227-018-2591-3", "report-no": null, "categories": "cs.AI cs.GT cs.LG cs.MA cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An approach of mobile multi-agent pursuit based on application of\nself-organizing feature map (SOFM) and along with that reinforcement learning\nbased on agent group role membership function (AGRMF) model is proposed. This\nmethod promotes dynamic organization of the pursuers' groups and also makes\npursuers' group evader according to their desire based on SOFM and AGRMF\ntechniques. This helps to overcome the shortcomings of the pursuers that they\ncannot fully reorganize when the goal is too independent in process of AGRMF\nmodels operation. Besides, we also discuss a new reward function. After the\nformation of the group, reinforcement learning is applied to get the optimal\nsolution for each agent. The results of each step in capturing process will\nfinally affect the AGR membership function to speed up the convergence of the\ncompetitive neural network. The experiments result shows that this approach is\nmore effective for the mobile agents to capture evaders.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jun 2020 15:39:58 GMT"}, {"version": "v2", "created": "Sat, 27 Jun 2020 10:25:27 GMT"}], "update_date": "2020-06-30", "authors_parsed": [["Qadir", "Muhammad Zuhair", ""], ["Piao", "Songhao", ""], ["Jiang", "Haiyang", ""], ["Souidi", "Mohammed El Habib", ""]]}, {"id": "2006.01023", "submitter": "Abd AlRahman AlMomani", "authors": "Jie Sun, Abd AlRahman AlMomani, Erik Bollt", "title": "Data-Driven Learning of Boolean Networks and Functions by Optimal\n  Causation Entropy Principle (BoCSE)", "comments": "18 pages, 6 Figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.IT math.DS math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Boolean functions and networks are commonly used in the modeling and analysis\nof complex biological systems, and this paradigm is highly relevant in other\nimportant areas in data science and decision making, such as in the medical\nfield and in the finance industry. Automated learning of a Boolean network and\nBoolean functions, from data, is a challenging task due in part to the large\nnumber of unknowns (including both the structure of the network and the\nfunctions) to be estimated, for which a brute force approach would be\nexponentially complex. In this paper we develop a new information theoretic\nmethodology that we show to be significantly more efficient than previous\napproaches. Building on the recently developed optimal causation entropy\nprinciple (oCSE), that we proved can correctly infer networks distinguishing\nbetween direct versus indirect connections, we develop here an efficient\nalgorithm that furthermore infers a Boolean network (including both its\nstructure and function) based on data observed from the evolving states at\nnodes. We call this new inference method, Boolean optimal causation entropy\n(BoCSE), which we will show that our method is both computationally efficient\nand also resilient to noise. Furthermore, it allows for selection of a set of\nfeatures that best explains the process, a statement that can be described as a\nnetworked Boolean function reduced order model. We highlight our method to the\nfeature selection in several real-world examples: (1) diagnosis of urinary\ndiseases, (2) Cardiac SPECT diagnosis, (3) informative positions in the game\nTic-Tac-Toe, and (4) risk causality analysis of loans in default status. Our\nproposed method is effective and efficient in all examples.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jun 2020 15:42:44 GMT"}], "update_date": "2020-06-02", "authors_parsed": [["Sun", "Jie", ""], ["AlMomani", "Abd AlRahman", ""], ["Bollt", "Erik", ""]]}, {"id": "2006.01067", "submitter": "Alon Jacovi", "authors": "Alon Jacovi, Yoav Goldberg", "title": "Aligning Faithful Interpretations with their Social Attribution", "comments": "Accepted as a journal paper to TACL", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We find that the requirement of model interpretations to be faithful is vague\nand incomplete. With interpretation by textual highlights as a case-study, we\npresent several failure cases. Borrowing concepts from social science, we\nidentify that the problem is a misalignment between the causal chain of\ndecisions (causal attribution) and the attribution of human behavior to the\ninterpretation (social attribution). We re-formulate faithfulness as an\naccurate attribution of causality to the model, and introduce the concept of\naligned faithfulness: faithful causal chains that are aligned with their\nexpected social behavior. The two steps of causal attribution and social\nattribution together complete the process of explaining behavior. With this\nformalization, we characterize various failures of misaligned faithful\nhighlight interpretations, and propose an alternative causal chain to remedy\nthe issues. Finally, we implement highlight explanations of the proposed causal\nformat using contrastive explanations.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jun 2020 16:45:38 GMT"}, {"version": "v2", "created": "Sun, 3 Jan 2021 00:45:44 GMT"}, {"version": "v3", "created": "Thu, 14 Jan 2021 18:54:01 GMT"}], "update_date": "2021-01-15", "authors_parsed": [["Jacovi", "Alon", ""], ["Goldberg", "Yoav", ""]]}, {"id": "2006.01096", "submitter": "Anoopkumar Sonar", "authors": "Anoopkumar Sonar, Vincent Pacelli, and Anirudha Majumdar", "title": "Invariant Policy Optimization: Towards Stronger Generalization in\n  Reinforcement Learning", "comments": "16 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A fundamental challenge in reinforcement learning is to learn policies that\ngeneralize beyond the operating domains experienced during training. In this\npaper, we approach this challenge through the following invariance principle:\nan agent must find a representation such that there exists an action-predictor\nbuilt on top of this representation that is simultaneously optimal across all\ntraining domains. Intuitively, the resulting invariant policy enhances\ngeneralization by finding causes of successful actions. We propose a novel\nlearning algorithm, Invariant Policy Optimization (IPO), that implements this\nprinciple and learns an invariant policy during training. We compare our\napproach with standard policy gradient methods and demonstrate significant\nimprovements in generalization performance on unseen domains for linear\nquadratic regulator and grid-world problems, and an example where a robot must\nlearn to open doors with varying physical properties.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jun 2020 17:28:19 GMT"}, {"version": "v2", "created": "Fri, 24 Jul 2020 03:54:06 GMT"}, {"version": "v3", "created": "Mon, 9 Nov 2020 09:54:50 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Sonar", "Anoopkumar", ""], ["Pacelli", "Vincent", ""], ["Majumdar", "Anirudha", ""]]}, {"id": "2006.01195", "submitter": "Konstantin Yakovlev S", "authors": "Konstantin Yakovlev, Anton Andreychuk, Roni Stern", "title": "Revisiting Bounded-Suboptimal Safe Interval Path Planning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Safe-interval path planning (SIPP) is a powerful algorithm for finding a path\nin the presence of dynamic obstacles. SIPP returns provably optimal solutions.\nHowever, in many practical applications of SIPP such as path planning for\nrobots, one would like to trade-off optimality for shorter planning time. In\nthis paper we explore different ways to build a bounded-suboptimal SIPP and\ndiscuss their pros and cons. We compare the different bounded-suboptimal\nversions of SIPP experimentally. While there is no universal winner, the\nresults provide insights into when each method should be used.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jun 2020 18:42:52 GMT"}], "update_date": "2020-06-03", "authors_parsed": [["Yakovlev", "Konstantin", ""], ["Andreychuk", "Anton", ""], ["Stern", "Roni", ""]]}, {"id": "2006.01204", "submitter": "Zitao Liu", "authors": "Shiting Xu, Wenbiao Ding, Zitao Liu", "title": "Automatic Dialogic Instruction Detection for K-12 Online One-on-one\n  Classes", "comments": "The 21th International Conference on Artificial Intelligence in\n  Education(AIED), 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Online one-on-one class is created for highly interactive and immersive\nlearning experience. It demands a large number of qualified online instructors.\nIn this work, we develop six dialogic instructions and help teachers achieve\nthe benefits of one-on-one learning paradigm. Moreover, we utilize neural\nlanguage models, i.e., long short-term memory (LSTM), to detect above six\ninstructions automatically. Experiments demonstrate that the LSTM approach\nachieves AUC scores from 0.840 to 0.979 among all six types of instructions on\nour real-world educational dataset.\n", "versions": [{"version": "v1", "created": "Sat, 16 May 2020 01:55:31 GMT"}], "update_date": "2020-06-03", "authors_parsed": [["Xu", "Shiting", ""], ["Ding", "Wenbiao", ""], ["Liu", "Zitao", ""]]}, {"id": "2006.01272", "submitter": "Christopher Frye", "authors": "Christopher Frye, Damien de Mijolla, Tom Begley, Laurence Cowton,\n  Megan Stanley, Ilya Feige", "title": "Shapley explainability on the data manifold", "comments": "To appear in ICLR 2021; 9 pages, 6 figures, 2 appendices", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Explainability in AI is crucial for model development, compliance with\nregulation, and providing operational nuance to predictions. The Shapley\nframework for explainability attributes a model's predictions to its input\nfeatures in a mathematically principled and model-agnostic way. However,\ngeneral implementations of Shapley explainability make an untenable assumption:\nthat the model's features are uncorrelated. In this work, we demonstrate\nunambiguous drawbacks of this assumption and develop two solutions to Shapley\nexplainability that respect the data manifold. One solution, based on\ngenerative modelling, provides flexible access to data imputations; the other\ndirectly learns the Shapley value-function, providing performance and stability\nat the cost of flexibility. While \"off-manifold\" Shapley values can (i) give\nrise to incorrect explanations, (ii) hide implicit model dependence on\nsensitive attributes, and (iii) lead to unintelligible explanations in\nhigher-dimensional data, on-manifold explainability overcomes these problems.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jun 2020 21:20:04 GMT"}, {"version": "v2", "created": "Wed, 14 Oct 2020 20:31:25 GMT"}, {"version": "v3", "created": "Mon, 22 Feb 2021 17:09:23 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Frye", "Christopher", ""], ["de Mijolla", "Damien", ""], ["Begley", "Tom", ""], ["Cowton", "Laurence", ""], ["Stanley", "Megan", ""], ["Feige", "Ilya", ""]]}, {"id": "2006.01294", "submitter": "Fubao Wu", "authors": "Fubao Wu, Han Hee Song, Jiangtao Yin, Lixin Gao, Mario Baldi, Narendra\n  Anand", "title": "NEMA: Automatic Integration of Large Network Management Databases", "comments": "14 pages, 13 Figures, 7 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Network management, whether for malfunction analysis, failure prediction,\nperformance monitoring and improvement, generally involves large amounts of\ndata from different sources. To effectively integrate and manage these sources,\nautomatically finding semantic matches among their schemas or ontologies is\ncrucial. Existing approaches on database matching mainly fall into two\ncategories. One focuses on the schema-level matching based on schema properties\nsuch as field names, data types, constraints and schema structures. Network\nmanagement databases contain massive tables (e.g., network products, incidents,\nsecurity alert and logs) from different departments and groups with nonuniform\nfield names and schema characteristics. It is not reliable to match them by\nthose schema properties. The other category is based on the instance-level\nmatching using general string similarity techniques, which are not applicable\nfor the matching of large network management databases. In this paper, we\ndevelop a matching technique for large NEtwork MAnagement databases (NEMA)\ndeploying instance-level matching for effective data integration and\nconnection. We design matching metrics and scores for both numerical and\nnon-numerical fields and propose algorithms for matching these fields. The\neffectiveness and efficiency of NEMA are evaluated by conducting experiments\nbased on ground truth field pairs in large network management databases. Our\nmeasurement on large databases with 1,458 fields, each of which contains over\n10 million records, reveals that the accuracies of NEMA are up to 95%. It\nachieves 2%-10% higher accuracy and 5x-14x speedup over baseline methods.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jun 2020 22:21:40 GMT"}], "update_date": "2020-06-03", "authors_parsed": [["Wu", "Fubao", ""], ["Song", "Han Hee", ""], ["Yin", "Jiangtao", ""], ["Gao", "Lixin", ""], ["Baldi", "Mario", ""], ["Anand", "Narendra", ""]]}, {"id": "2006.01304", "submitter": "Kyungmi Lee", "authors": "Kyungmi Lee, Anantha P. Chandrakasan", "title": "Rethinking Empirical Evaluation of Adversarial Robustness Using\n  First-Order Attack Methods", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We identify three common cases that lead to overestimation of adversarial\naccuracy against bounded first-order attack methods, which is popularly used as\na proxy for adversarial robustness in empirical studies. For each case, we\npropose compensation methods that either address sources of inaccurate gradient\ncomputation, such as numerical instability near zero and non-differentiability,\nor reduce the total number of back-propagations for iterative attacks by\napproximating second-order information. These compensation methods can be\ncombined with existing attack methods for a more precise empirical evaluation\nmetric. We illustrate the impact of these three cases with examples of\npractical interest, such as benchmarking model capacity and regularization\ntechniques for robustness. Overall, our work shows that overestimated\nadversarial accuracy that is not indicative of robustness is prevalent even for\nconventionally trained deep neural networks, and highlights cautions of using\nempirical evaluation without guaranteed bounds.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jun 2020 22:55:09 GMT"}], "update_date": "2020-06-03", "authors_parsed": [["Lee", "Kyungmi", ""], ["Chandrakasan", "Anantha P.", ""]]}, {"id": "2006.01322", "submitter": "Gregorio P\\'erez Bernal", "authors": "Gregorio Perez Bernal, Luisa Toro Villegas, Mauricio Toro", "title": "Saber Pro success prediction model using decision tree based learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The primary objective of this report is to determine what influences the\nsuccess rates of students who have studied in Colombia, analyzing the Saber 11,\nthe test done at the last school year, some socioeconomic aspects and comparing\nthe Saber Pro results with the national average. The problem this faces is to\nfind what influences success, but it also provides an insight in the countries\neducation dynamics and predicts one's opportunities to be prosperous. The\nopposite situation to the one presented in this paper could be the desertion\nlevels, in the sense that by detecting what makes someone outstanding, these\nfactors can say what makes one unsuccessful. The solution proposed to solve\nthis problem was to implement a CART decision tree algorithm that helps to\npredict the probability that a student has of scoring higher than the mean\nvalue, based on different socioeconomic and academic factors, such as the\nprofession of the parents of the subject parents and the results obtained on\nSaber 11. It was discovered that one of the most influential factors is the\nscore in the Saber 11, on the topic of Social Studies, and that the gender of\nthe subject is not as influential as it is usually portrayed as. The algorithm\ndesigned provided significant insight into which factors most affect the\nprobability of success of any given person and if further pursued could be used\nin many given situations such as deciding which subject in school should be\ngiven more intensity to and academic curriculum in general.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jun 2020 00:19:02 GMT"}], "update_date": "2020-06-03", "authors_parsed": [["Bernal", "Gregorio Perez", ""], ["Villegas", "Luisa Toro", ""], ["Toro", "Mauricio", ""]]}, {"id": "2006.01392", "submitter": "Dang Nguyen", "authors": "Thomas P. Quinn, Dang Nguyen, Santu Rana, Sunil Gupta, Svetha\n  Venkatesh", "title": "DeepCoDA: personalized interpretability for compositional health data", "comments": "To appear at ICML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Interpretability allows the domain-expert to directly evaluate the model's\nrelevance and reliability, a practice that offers assurance and builds trust.\nIn the healthcare setting, interpretable models should implicate relevant\nbiological mechanisms independent of technical factors like data\npre-processing. We define personalized interpretability as a measure of\nsample-specific feature attribution, and view it as a minimum requirement for a\nprecision health model to justify its conclusions. Some health data, especially\nthose generated by high-throughput sequencing experiments, have nuances that\ncompromise precision health models and their interpretation. These data are\ncompositional, meaning that each feature is conditionally dependent on all\nother features. We propose the Deep Compositional Data Analysis (DeepCoDA)\nframework to extend precision health modelling to high-dimensional\ncompositional data, and to provide personalized interpretability through\npatient-specific weights. Our architecture maintains state-of-the-art\nperformance across 25 real-world data sets, all while producing interpretations\nthat are both personalized and fully coherent for compositional data.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jun 2020 05:14:22 GMT"}, {"version": "v2", "created": "Tue, 16 Jun 2020 23:46:02 GMT"}], "update_date": "2020-06-18", "authors_parsed": [["Quinn", "Thomas P.", ""], ["Nguyen", "Dang", ""], ["Rana", "Santu", ""], ["Gupta", "Sunil", ""], ["Venkatesh", "Svetha", ""]]}, {"id": "2006.01415", "submitter": "Bao Trung Nguyen", "authors": "Isidro M. Alvarez, Trung B. Nguyen, Will N. Browne, Mengjie Zhang", "title": "A Layered Learning Approach to Scaling in Learning Classifier Systems\n  for Boolean Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning classifier systems (LCSs) originated from cognitive-science research\nbut migrated such that LCS became powerful classification techniques. Modern\nLCSs can be used to extract building blocks of knowledge to solve more\ndifficult problems in the same or a related domain. Recent works on LCSs showed\nthat the knowledge reuse through the adoption of Code Fragments, GP-like\ntree-based programs, into LCSs could provide advances in scaling. However,\nsince solving hard problems often requires constructing high-level building\nblocks, which also results in an intractable search space, a limit of scaling\nwill eventually be reached. Inspired by human problem-solving abilities, XCSCF*\ncan reuse learned knowledge and learned functionality to scale to complex\nproblems by transferring them from simpler problems using layered learning.\nHowever, this method was unrefined and suited to only the Multiplexer problem\ndomain. In this paper, we propose improvements to XCSCF* to enable it to be\nrobust across multiple problem domains. This is demonstrated on the benchmarks\nMultiplexer, Carry-one, Majority-on, and Even-parity domains. The required base\naxioms necessary for learning are proposed, methods for transfer learning in\nLCSs developed and learning recast as a decomposition into a series of\nsubordinate problems. Results show that from a conventional tabula rasa, with\nonly a vague notion of what subordinate problems might be relevant, it is\npossible to capture the general logic behind the tested domains, so the\nadvanced system is capable of solving any individual n-bit Multiplexer, n-bit\nCarry-one, n-bit Majority-on, or n-bit Even-parity problem.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jun 2020 06:43:44 GMT"}], "update_date": "2020-06-03", "authors_parsed": [["Alvarez", "Isidro M.", ""], ["Nguyen", "Trung B.", ""], ["Browne", "Will N.", ""], ["Zhang", "Mengjie", ""]]}, {"id": "2006.01419", "submitter": "Youngchul Sung", "authors": "Seungyul Han, Youngchul Sung", "title": "Diversity Actor-Critic: Sample-Aware Entropy Regularization for\n  Sample-Efficient Exploration", "comments": "Accepted to Proceedings of the 38th International Conference on\n  Machine Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, sample-aware policy entropy regularization is proposed to\nenhance the conventional policy entropy regularization for better exploration.\nExploiting the sample distribution obtainable from the replay buffer, the\nproposed sample-aware entropy regularization maximizes the entropy of the\nweighted sum of the policy action distribution and the sample action\ndistribution from the replay buffer for sample-efficient exploration. A\npractical algorithm named diversity actor-critic (DAC) is developed by applying\npolicy iteration to the objective function with the proposed sample-aware\nentropy regularization. Numerical results show that DAC significantly\noutperforms existing recent algorithms for reinforcement learning.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jun 2020 06:51:25 GMT"}, {"version": "v2", "created": "Wed, 9 Jun 2021 03:05:50 GMT"}], "update_date": "2021-06-10", "authors_parsed": [["Han", "Seungyul", ""], ["Sung", "Youngchul", ""]]}, {"id": "2006.01444", "submitter": "Kai Sauerwald", "authors": "Kai Sauerwald, Jonas Haldimann, Martin von Berg, Christoph Beierle", "title": "Descriptor Revision for Conditionals: Literal Descriptors and\n  Conditional Preservation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Descriptor revision by Hansson is a framework for addressing the problem of\nbelief change. In descriptor revision, different kinds of change processes are\ndealt with in a joint framework. Individual change requirements are qualified\nby specific success conditions expressed by a belief descriptor, and belief\ndescriptors can be combined by logical connectives. This is in contrast to the\ncurrently dominating AGM paradigm shaped by Alchourr\\'on, G\\\"ardenfors, and\nMakinson, where different kinds of changes, like a revision or a contraction,\nare dealt with separately. In this article, we investigate the realisation of\ndescriptor revision for a conditional logic while restricting descriptors to\nthe conjunction of literal descriptors. We apply the principle of conditional\npreservation developed by Kern-Isberner to descriptor revision for\nconditionals, show how descriptor revision for conditionals under these\nrestrictions can be characterised by a constraint satisfaction problem, and\nimplement it using constraint logic programming. Since our conditional logic\nsubsumes propositional logic, our approach also realises descriptor revision\nfor propositional logic.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jun 2020 08:21:33 GMT"}], "update_date": "2020-06-03", "authors_parsed": [["Sauerwald", "Kai", ""], ["Haldimann", "Jonas", ""], ["von Berg", "Martin", ""], ["Beierle", "Christoph", ""]]}, {"id": "2006.01456", "submitter": "Utku Ozbulak", "authors": "Utku Ozbulak, Manvel Gasparyan, Wesley De Neve, Arnout Van Messem", "title": "Perturbation Analysis of Gradient-based Adversarial Attacks", "comments": "Accepted for publication in Pattern Recognition Letters, 2020", "journal-ref": "Pattern Recognition Letters 2020, Volume 135, Pages 133-120", "doi": "10.1016/j.patrec.2020.04.034", "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  After the discovery of adversarial examples and their adverse effects on deep\nlearning models, many studies focused on finding more diverse methods to\ngenerate these carefully crafted samples. Although empirical results on the\neffectiveness of adversarial example generation methods against defense\nmechanisms are discussed in detail in the literature, an in-depth study of the\ntheoretical properties and the perturbation effectiveness of these adversarial\nattacks has largely been lacking. In this paper, we investigate the objective\nfunctions of three popular methods for adversarial example generation: the\nL-BFGS attack, the Iterative Fast Gradient Sign attack, and Carlini & Wagner's\nattack (CW). Specifically, we perform a comparative and formal analysis of the\nloss functions underlying the aforementioned attacks while laying out\nlarge-scale experimental results on ImageNet dataset. This analysis exposes (1)\nthe faster optimization speed as well as the constrained optimization space of\nthe cross-entropy loss, (2) the detrimental effects of using the signature of\nthe cross-entropy loss on optimization precision as well as optimization space,\nand (3) the slow optimization speed of the logit loss in the context of\nadversariality. Our experiments reveal that the Iterative Fast Gradient Sign\nattack, which is thought to be fast for generating adversarial examples, is the\nworst attack in terms of the number of iterations required to create\nadversarial examples in the setting of equal perturbation. Moreover, our\nexperiments show that the underlying loss function of CW, which is criticized\nfor being substantially slower than other adversarial attacks, is not that much\nslower than other loss functions. Finally, we analyze how well neural networks\ncan identify adversarial perturbations generated by the attacks under\nconsideration, hereby revisiting the idea of adversarial retraining on\nImageNet.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jun 2020 08:51:37 GMT"}], "update_date": "2020-06-03", "authors_parsed": [["Ozbulak", "Utku", ""], ["Gasparyan", "Manvel", ""], ["De Neve", "Wesley", ""], ["Van Messem", "Arnout", ""]]}, {"id": "2006.01460", "submitter": "Satwik Kottur", "authors": "Seungwhan Moon, Satwik Kottur, Paul A. Crook, Ankita De, Shivani\n  Poddar, Theodore Levin, David Whitney, Daniel Difranco, Ahmad Beirami,\n  Eunjoon Cho, Rajen Subba, Alborz Geramifard", "title": "Situated and Interactive Multimodal Conversations", "comments": "20 pages, 5 figures, 11 tables, accepted to COLING 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Next generation virtual assistants are envisioned to handle multimodal inputs\n(e.g., vision, memories of previous interactions, in addition to the user's\nutterances), and perform multimodal actions (e.g., displaying a route in\naddition to generating the system's utterance). We introduce Situated\nInteractive MultiModal Conversations (SIMMC) as a new direction aimed at\ntraining agents that take multimodal actions grounded in a co-evolving\nmultimodal input context in addition to the dialog history. We provide two\nSIMMC datasets totalling ~13K human-human dialogs (~169K utterances) using a\nmultimodal Wizard-of-Oz (WoZ) setup, on two shopping domains: (a) furniture\n(grounded in a shared virtual environment) and, (b) fashion (grounded in an\nevolving set of images). We also provide logs of the items appearing in each\nscene, and contextual NLU and coreference annotations, using a novel and\nunified framework of SIMMC conversational acts for both user and assistant\nutterances. Finally, we present several tasks within SIMMC as objective\nevaluation protocols, such as Structural API Prediction and Response\nGeneration. We benchmark a collection of existing models on these SIMMC tasks\nas strong baselines, and demonstrate rich multimodal conversational\ninteractions. Our data, annotations, code, and models are publicly available.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jun 2020 09:02:23 GMT"}, {"version": "v2", "created": "Tue, 10 Nov 2020 20:21:19 GMT"}], "update_date": "2020-11-12", "authors_parsed": [["Moon", "Seungwhan", ""], ["Kottur", "Satwik", ""], ["Crook", "Paul A.", ""], ["De", "Ankita", ""], ["Poddar", "Shivani", ""], ["Levin", "Theodore", ""], ["Whitney", "David", ""], ["Difranco", "Daniel", ""], ["Beirami", "Ahmad", ""], ["Cho", "Eunjoon", ""], ["Subba", "Rajen", ""], ["Geramifard", "Alborz", ""]]}, {"id": "2006.01473", "submitter": "Emmanouil Rigas", "authors": "Emmanouil Rigas, Panayiotis Kolios, Georgios Ellinas", "title": "Extending the Multiple Traveling Salesman Problem for Scheduling a Fleet\n  of Drones Performing Monitoring Missions", "comments": "To appear in the 23rd IEEE International Conference on Intelligent\n  Transportation Systems", "journal-ref": "23rd IEEE International Conference on Intelligent Transportation\n  Systems", "doi": "10.1109/ITSC45102.2020.9294568", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we schedule the travel path of a set of drones across a graph\nwhere the nodes need to be visited multiple times at pre-defined points in\ntime. This is an extension of the well-known multiple traveling salesman\nproblem. The proposed formulation can be applied in several domains such as the\nmonitoring of traffic flows in a transportation network, or the monitoring of\nremote locations to assist search and rescue missions. Aiming to find the\noptimal schedule, the problem is formulated as an Integer Linear Program (ILP).\nGiven that the problem is highly combinatorial, the optimal solution scales\nonly for small sized problems. Thus, a greedy algorithm is also proposed that\nuses a one-step look ahead heuristic search mechanism. In a detailed\nevaluation, it is observed that the greedy algorithm has near-optimal\nperformance as it is on average at 92.06% of the optimal, while it can\npotentially scale up to settings with hundreds of drones and locations.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jun 2020 09:17:18 GMT"}], "update_date": "2021-01-06", "authors_parsed": [["Rigas", "Emmanouil", ""], ["Kolios", "Panayiotis", ""], ["Ellinas", "Georgios", ""]]}, {"id": "2006.01503", "submitter": "Loic Pauleve", "authors": "Gilles Audemard (CRIL), Lo\\\"ic Paulev\\'e (LaBRI), Laurent Simon\n  (LaBRI)", "title": "SAT Heritage: a community-driven effort for archiving, building and\n  running more than thousand SAT solvers", "comments": null, "journal-ref": "SAT 2020, The 23rd International Conference on Theory and\n  Applications of Satisfiability Testing, 2020, Alghero, Italy", "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  SAT research has a long history of source code and binary releases, thanks to\ncompetitions organized every year. However, since every cycle of competitions\nhas its own set of rules and an adhoc way of publishing source code and\nbinaries, compiling or even running any solver may be harder than what it\nseems. Moreover, there has been more than a thousand solvers published so far,\nsome of them released in the early 90's. If the SAT community wants to archive\nand be able to keep track of all the solvers that made its history, it urgently\nneeds to deploy an important effort. We propose to initiate a community-driven\neffort to archive and to allow easy compilation and running of all SAT solvers\nthat have been released so far. We rely on the best tools for archiving and\nbuilding binaries (thanks to Docker, GitHub and Zenodo) and provide a\nconsistent and easy way for this. Thanks to our tool, building (or running) a\nsolver from its source (or from its binary) can be done in one line.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jun 2020 10:03:56 GMT"}], "update_date": "2020-06-03", "authors_parsed": [["Audemard", "Gilles", "", "CRIL"], ["Paulev\u00e9", "Lo\u00efc", "", "LaBRI"], ["Simon", "Laurent", "", "LaBRI"]]}, {"id": "2006.01601", "submitter": "Alexander Kell Mr", "authors": "Alexander J. M. Kell, A. Stephen McGough, Matthew Forshaw", "title": "Optimizing carbon tax for decentralized electricity markets using an\n  agent-based model", "comments": "Accepted at The Eleventh ACM International Conference on Future\n  Energy Systems (e-Energy'20) AMLIES Workshop", "journal-ref": null, "doi": "10.1145/3396851.3402369", "report-no": null, "categories": "eess.SY cs.AI cs.LG cs.SY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Averting the effects of anthropogenic climate change requires a transition\nfrom fossil fuels to low-carbon technology. A way to achieve this is to\ndecarbonize the electricity grid. However, further efforts must be made in\nother fields such as transport and heating for full decarbonization. This would\nreduce carbon emissions due to electricity generation, and also help to\ndecarbonize other sources such as automotive and heating by enabling a\nlow-carbon alternative. Carbon taxes have been shown to be an efficient way to\naid in this transition. In this paper, we demonstrate how to to find optimal\ncarbon tax policies through a genetic algorithm approach, using the electricity\nmarket agent-based model ElecSim. To achieve this, we use the NSGA-II genetic\nalgorithm to minimize average electricity price and relative carbon intensity\nof the electricity mix. We demonstrate that it is possible to find a range of\ncarbon taxes to suit differing objectives. Our results show that we are able to\nminimize electricity cost to below \\textsterling10/MWh as well as carbon\nintensity to zero in every case. In terms of the optimal carbon tax strategy,\nwe found that an increasing strategy between 2020 and 2035 was preferable. Each\nof the Pareto-front optimal tax strategies are at least above\n\\textsterling81/tCO2 for every year. The mean carbon tax strategy was\n\\textsterling240/tCO2.\n", "versions": [{"version": "v1", "created": "Thu, 28 May 2020 06:54:43 GMT"}], "update_date": "2020-06-03", "authors_parsed": [["Kell", "Alexander J. M.", ""], ["McGough", "A. Stephen", ""], ["Forshaw", "Matthew", ""]]}, {"id": "2006.01610", "submitter": "Quentin Cappart", "authors": "Quentin Cappart and Thierry Moisan and Louis-Martin Rousseau and\n  Isabeau Pr\\'emont-Schwarz and Andre Cire", "title": "Combining Reinforcement Learning and Constraint Programming for\n  Combinatorial Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Combinatorial optimization has found applications in numerous fields, from\naerospace to transportation planning and economics. The goal is to find an\noptimal solution among a finite set of possibilities. The well-known challenge\none faces with combinatorial optimization is the state-space explosion problem:\nthe number of possibilities grows exponentially with the problem size, which\nmakes solving intractable for large problems. In the last years, deep\nreinforcement learning (DRL) has shown its promise for designing good\nheuristics dedicated to solve NP-hard combinatorial optimization problems.\nHowever, current approaches have two shortcomings: (1) they mainly focus on the\nstandard travelling salesman problem and they cannot be easily extended to\nother problems, and (2) they only provide an approximate solution with no\nsystematic ways to improve it or to prove optimality. In another context,\nconstraint programming (CP) is a generic tool to solve combinatorial\noptimization problems. Based on a complete search procedure, it will always\nfind the optimal solution if we allow an execution time large enough. A\ncritical design choice, that makes CP non-trivial to use in practice, is the\nbranching decision, directing how the search space is explored. In this work,\nwe propose a general and hybrid approach, based on DRL and CP, for solving\ncombinatorial optimization problems. The core of our approach is based on a\ndynamic programming formulation, that acts as a bridge between both techniques.\nWe experimentally show that our solver is efficient to solve two challenging\nproblems: the traveling salesman problem with time windows, and the 4-moments\nportfolio optimization problem. Results obtained show that the framework\nintroduced outperforms the stand-alone RL and CP solutions, while being\ncompetitive with industrial solvers.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jun 2020 13:54:27 GMT"}], "update_date": "2020-06-03", "authors_parsed": [["Cappart", "Quentin", ""], ["Moisan", "Thierry", ""], ["Rousseau", "Louis-Martin", ""], ["Pr\u00e9mont-Schwarz", "Isabeau", ""], ["Cire", "Andre", ""]]}, {"id": "2006.01626", "submitter": "Bilal Abu-Salih", "authors": "Bilal Abu-Salih, Marwan Al-Tawil, Ibrahim Aljarah, Hossam Faris,\n  Pornpit Wongthongtham", "title": "Relational Learning Analysis of Social Politics using Knowledge Graph\n  Embedding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge Graphs (KGs) have gained considerable attention recently from both\nacademia and industry. In fact, incorporating graph technology and the copious\nof various graph datasets have led the research community to build\nsophisticated graph analytics tools. Therefore, the application of KGs has\nextended to tackle a plethora of real-life problems in dissimilar domains.\nDespite the abundance of the currently proliferated generic KGs, there is a\nvital need to construct domain-specific KGs. Further, quality and credibility\nshould be assimilated in the process of constructing and augmenting KGs,\nparticularly those propagated from mixed-quality resources such as social media\ndata. This paper presents a novel credibility domain-based KG Embedding\nframework. This framework involves capturing a fusion of data obtained from\nheterogeneous resources into a formal KG representation depicted by a domain\nontology. The proposed approach makes use of various knowledge-based\nrepositories to enrich the semantics of the textual contents, thereby\nfacilitating the interoperability of information. The proposed framework also\nembodies a credibility module to ensure data quality and trustworthiness. The\nconstructed KG is then embedded in a low-dimension semantically-continuous\nspace using several embedding techniques. The utility of the constructed KG and\nits embeddings is demonstrated and substantiated on link prediction,\nclustering, and visualisation tasks.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jun 2020 14:10:28 GMT"}], "update_date": "2020-06-03", "authors_parsed": [["Abu-Salih", "Bilal", ""], ["Al-Tawil", "Marwan", ""], ["Aljarah", "Ibrahim", ""], ["Faris", "Hossam", ""], ["Wongthongtham", "Pornpit", ""]]}, {"id": "2006.01770", "submitter": "Lily Hu", "authors": "Lily Hu and Issa Kohler-Hausmann", "title": "What's Sex Got To Do With Fair Machine Learning?", "comments": "11 pages, 5 figures, ACM Conference on Fairness, Accountability, and\n  Transparency", "journal-ref": null, "doi": "10.1145/3351095.3375674", "report-no": null, "categories": "cs.CY cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Debate about fairness in machine learning has largely centered around\ncompeting definitions of what fairness or nondiscrimination between groups\nrequires. However, little attention has been paid to what precisely a group is.\nMany recent approaches to \"fairness\" require one to specify a causal model of\nthe data generating process. These exercises make an implicit ontological\nassumption that a racial or sex group is simply a collection of individuals who\nshare a given trait. We show this by exploring the formal assumption of\nmodularity in causal models, which holds that the dependencies captured by one\ncausal pathway are invariant to interventions on any other pathways. Causal\nmodels of sex propose two substantive claims: 1) There exists a feature,\nsex-on-its-own, that is an inherent trait of an individual that causally brings\nabout social phenomena external to it in the world; and 2) the relations\nbetween sex and its effects can be modified in whichever ways and the former\nfeature would still retain the meaning that sex has in our world. We argue that\nthis ontological picture is false. Many of the \"effects\" that sex purportedly\n\"causes\" are in fact constitutive features of sex as a social status. They give\nthe social meaning of sex features, meanings that are precisely what make sex\ndiscrimination a distinctively morally problematic type of action. Correcting\nthis conceptual error has a number of implications for how models can be used\nto detect discrimination. Formal diagrams of constitutive relations present an\nentirely different path toward reasoning about discrimination. Whereas causal\ndiagrams guide the construction of sophisticated modular counterfactuals,\nconstitutive diagrams identify a different kind of counterfactual as central to\nan inquiry on discrimination: one that asks how the social meaning of a group\nwould be changed if its non-modular features were altered.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jun 2020 16:51:39 GMT"}, {"version": "v2", "created": "Thu, 4 Jun 2020 22:54:18 GMT"}], "update_date": "2020-06-08", "authors_parsed": [["Hu", "Lily", ""], ["Kohler-Hausmann", "Issa", ""]]}, {"id": "2006.01784", "submitter": "Vahid Yazdanpanah", "authors": "Vahid Yazdanpanah, Devrim Murat Yazan, W. Henk M. Zijm", "title": "Coordinating Multiagent Industrial Symbiosis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a formal multiagent framework for coordinating a class of\ncollaborative industrial practices called Industrial Symbiotic Networks (ISNs)\nas cooperative games. The game-theoretic formulation of ISNs enables systematic\nreasoning about what we call the ISN implementation problem. Specifically, the\ncharacteristics of ISNs may lead to the inapplicability of standard fair and\nstable benefit allocation methods. Inspired by realistic ISN scenarios and\nfollowing the literature on normative multiagent systems, we consider\nregulations and normative socio-economic policies as coordination instruments\nthat in combination with ISN games resolve the situation. In this multiagent\nsystem, employing Marginal Contribution Nets (MC-Nets) as rule-based\ncooperative game representations foster the combination of regulations and ISN\ngames with no loss in expressiveness. We develop algorithmic methods for\ngenerating regulations that ensure the implementability of ISNs and as a policy\nsupport, present the policy requirements that guarantee the implementability of\nall the desired ISNs in a balanced-budget way.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jun 2020 17:05:43 GMT"}], "update_date": "2020-06-03", "authors_parsed": [["Yazdanpanah", "Vahid", ""], ["Yazan", "Devrim Murat", ""], ["Zijm", "W. Henk M.", ""]]}, {"id": "2006.01790", "submitter": "Dimitrios Michael Manias", "authors": "Dimitrios Michael Manias, Hassan Hawilo, Manar Jammal, Abdallah Shami", "title": "Depth-Optimized Delay-Aware Tree (DO-DAT) for Virtual Network Function\n  Placement", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the constant increase in demand for data connectivity, network service\nproviders are faced with the task of reducing their capital and operational\nexpenses while ensuring continual improvements to network performance. Although\nNetwork Function Virtualization (NFV) has been identified as a solution,\nseveral challenges must be addressed to ensure its feasibility. In this paper,\nwe present a machine learning-based solution to the Virtual Network Function\n(VNF) placement problem. This paper proposes the Depth-Optimized Delay-Aware\nTree (DO-DAT) model by using the particle swarm optimization technique to\noptimize decision tree hyper-parameters. Using the Evolved Packet Core (EPC) as\na use case, we evaluate the performance of the model and compare it to a\npreviously proposed model and a heuristic placement strategy.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jun 2020 17:18:20 GMT"}], "update_date": "2020-06-03", "authors_parsed": [["Manias", "Dimitrios Michael", ""], ["Hawilo", "Hassan", ""], ["Jammal", "Manar", ""], ["Shami", "Abdallah", ""]]}, {"id": "2006.01800", "submitter": "Merlin Carl", "authors": "Merlin Carl", "title": "Automatized Evaluation of Formalization Exercises in Mathematics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.LO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe two systems for supporting beginner students in acquiring basic\nskills in expressing statements in the formalism of first-order predicate\nlogic; the first, called \"math dictations\", presents users with the task of\nformalizing a given natural-language sentence, while the second, called \"Game\nof Def\", challenges users to give a formal description of a set of a geometric\npattern displayed to them. In both cases, an automatic checking takes place.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jun 2020 17:34:46 GMT"}, {"version": "v2", "created": "Thu, 9 Jul 2020 16:28:54 GMT"}], "update_date": "2020-07-10", "authors_parsed": [["Carl", "Merlin", ""]]}, {"id": "2006.01830", "submitter": "Reinhard Diestel", "authors": "Reinhard Diestel", "title": "Tangles: a new paradigm for clusters and types", "comments": "arXiv admin note: substantial text overlap with arXiv:1907.07341", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditional clustering identifies groups of objects that share certain\nqualities. Tangles do the converse: they identify groups of qualities that\noften occur together. They can thereby discover, relate, and structure types:\nof behaviour, political views, texts, or viruses. If desired, tangles can also\nbe used for direct clustering of objects. They offer a precise, quantitative\nparadigm suited particularly to fuzzy clusters, since they do not require any\n`hard' assignments of objects to the clusters they collectively form. This is a\ndraft of the introductory chapter of a book I am preparing on the application\nof tangles in the empirical sciences. The purpose of posting this draft early\nis to give authors of tangle application papers a generic reference for the\nbasic guiding principles underlying tangle applications outside mathematics, so\nthat in their own papers they can concentrate on the ideas specific to their\nparticular application rather than having to repeat the generic story each\ntime. The text starts with three separate generic introductions to tangles in\nthe natural sciences, in the social sciences, and in data science including\nmachine learning. It then gives a short informal description of the abstract\nnotion of tangles that encompasses all these potential applications.\n", "versions": [{"version": "v1", "created": "Wed, 3 Jun 2020 13:13:54 GMT"}], "update_date": "2020-06-04", "authors_parsed": [["Diestel", "Reinhard", ""]]}, {"id": "2006.01855", "submitter": "Reid McIlroy-Young", "authors": "Reid McIlroy-Young and Siddhartha Sen and Jon Kleinberg and Ashton\n  Anderson", "title": "Aligning Superhuman AI with Human Behavior: Chess as a Model System", "comments": "11 pages, 11 figure, Proceedings of the 25th ACM SIGKDD international\n  conference on Knowledge discovery and data mining, Virtual 2020", "journal-ref": null, "doi": "10.1145/3394486.3403219", "report-no": null, "categories": "cs.AI cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As artificial intelligence becomes increasingly intelligent---in some cases,\nachieving superhuman performance---there is growing potential for humans to\nlearn from and collaborate with algorithms. However, the ways in which AI\nsystems approach problems are often different from the ways people do, and thus\nmay be uninterpretable and hard to learn from. A crucial step in bridging this\ngap between human and artificial intelligence is modeling the granular actions\nthat constitute human behavior, rather than simply matching aggregate human\nperformance.\n  We pursue this goal in a model system with a long history in artificial\nintelligence: chess. The aggregate performance of a chess player unfolds as\nthey make decisions over the course of a game. The hundreds of millions of\ngames played online by players at every skill level form a rich source of data\nin which these decisions, and their exact context, are recorded in minute\ndetail. Applying existing chess engines to this data, including an open-source\nimplementation of AlphaZero, we find that they do not predict human moves well.\n  We develop and introduce Maia, a customized version of Alpha-Zero trained on\nhuman chess games, that predicts human moves at a much higher accuracy than\nexisting engines, and can achieve maximum accuracy when predicting decisions\nmade by players at a specific skill level in a tuneable way. For a dual task of\npredicting whether a human will make a large mistake on the next move, we\ndevelop a deep neural network that significantly outperforms competitive\nbaselines. Taken together, our results suggest that there is substantial\npromise in designing artificial intelligence systems with human collaboration\nin mind by first accurately modeling granular human decision-making.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jun 2020 18:12:52 GMT"}, {"version": "v2", "created": "Fri, 19 Jun 2020 17:24:52 GMT"}, {"version": "v3", "created": "Tue, 14 Jul 2020 17:57:37 GMT"}], "update_date": "2020-07-15", "authors_parsed": [["McIlroy-Young", "Reid", ""], ["Sen", "Siddhartha", ""], ["Kleinberg", "Jon", ""], ["Anderson", "Ashton", ""]]}, {"id": "2006.01889", "submitter": "Paulius Dilkas", "authors": "Paulius Dilkas, Vaishak Belle", "title": "Generating Random Logic Programs Using Constraint Programming", "comments": "This is an extended version of the paper published in CP 2020", "journal-ref": "In: Simonis H. (eds) Principles and Practice of Constraint\n  Programming. CP 2020. Lecture Notes in Computer Science, vol 12333. Springer,\n  Cham (2020)", "doi": "10.1007/978-3-030-58475-7_48", "report-no": null, "categories": "cs.LO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Testing algorithms across a wide range of problem instances is crucial to\nensure the validity of any claim about one algorithm's superiority over\nanother. However, when it comes to inference algorithms for probabilistic logic\nprograms, experimental evaluations are limited to only a few programs. Existing\nmethods to generate random logic programs are limited to propositional programs\nand often impose stringent syntactic restrictions. We present a novel approach\nto generating random logic programs and random probabilistic logic programs\nusing constraint programming, introducing a new constraint to control the\nindependence structure of the underlying probability distribution. We also\nprovide a combinatorial argument for the correctness of the model, show how the\nmodel scales with parameter values, and use the model to compare probabilistic\ninference algorithms across a range of synthetic problems. Our model allows\ninference algorithm developers to evaluate and compare the algorithms across a\nwide range of instances, providing a detailed picture of their (comparative)\nstrengths and weaknesses.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jun 2020 19:12:53 GMT"}, {"version": "v2", "created": "Fri, 11 Sep 2020 16:40:31 GMT"}], "update_date": "2020-09-14", "authors_parsed": [["Dilkas", "Paulius", ""], ["Belle", "Vaishak", ""]]}, {"id": "2006.01908", "submitter": "Ashok Goel", "authors": "Ashok Goel", "title": "AI-Powered Learning: Making Education Accessible, Affordable, and\n  Achievable", "comments": "17 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We have developed an AI-powered socio-technical system for making online\nlearning in higher education more accessible, affordable and achievable. In\nparticular, we have developed four novel and intertwined AI technologies: (1)\nVERA, a virtual experimentation research assistant for supporting inquiry-based\nlearning of scientific knowledge, (2) Jill Watson Q&A, a virtual teaching\nassistant for answering questions based on educational documents including the\nVERA user reference guide, (3) Jill Watson SA, a virtual social agent that\npromotes online interactions, and (4) Agent Smith, that helps generate a Jill\nWatson Q&A agent for new documents such as class syllabi. The results are\npositive: (i) VERA enhances ecological knowledge and is freely available\nonline; (ii) Jill Watson Q&A has been used by >4,000 students in >12 online\nclasses and saved teachers >500 hours of work; (iii) Jill Q&A and Jill Watson\nSA promote learner engagement, interaction, and community; and (iv). Agent\nSmith helps generate Jill Watson Q&A for a new syllabus within ~25 hours. Put\ntogether, these innovative technologies help make online learning\nsimultaneously more accessible (by making materials available online),\naffordable (by saving teacher time), and achievable (by providing learning\nassistance and fostering student engagement).\n", "versions": [{"version": "v1", "created": "Tue, 2 Jun 2020 19:41:52 GMT"}], "update_date": "2020-06-04", "authors_parsed": [["Goel", "Ashok", ""]]}, {"id": "2006.01916", "submitter": "Ingyu Jason Choi", "authors": "Jason Ingyu Choi, Eugene Agichtein", "title": "Quantifying the Effects of Prosody Modulation on User Engagement and\n  Satisfaction in Conversational Systems", "comments": "Published in CHIIR 2020, 4 pages", "journal-ref": null, "doi": "10.1145/3343413.3378009", "report-no": null, "categories": "cs.HC cs.AI cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As voice-based assistants such as Alexa, Siri, and Google Assistant become\nubiquitous, users increasingly expect to maintain natural and informative\nconversations with such systems. However, for an open-domain conversational\nsystem to be coherent and engaging, it must be able to maintain the user's\ninterest for extended periods, without sounding boring or annoying. In this\npaper, we investigate one natural approach to this problem, of modulating\nresponse prosody, i.e., changing the pitch and cadence of the response to\nindicate delight, sadness or other common emotions, as well as using\npre-recorded interjections. Intuitively, this approach should improve the\nnaturalness of the conversation, but attempts to quantify the effects of\nprosodic modulation on user satisfaction and engagement remain challenging. To\naccomplish this, we report results obtained from a large-scale empirical study\nthat measures the effects of prosodic modulation on user behavior and\nengagement across multiple conversation domains, both immediately after each\nturn, and at the overall conversation level. Our results indicate that the\nprosody modulation significantly increases both immediate and overall user\nsatisfaction. However, since the effects vary across different domains, we\nverify that prosody modulations do not substitute for coherent, informative\ncontent of the responses. Together, our results provide useful tools and\ninsights for improving the naturalness of responses in conversational systems.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jun 2020 19:53:13 GMT"}], "update_date": "2020-06-04", "authors_parsed": [["Choi", "Jason Ingyu", ""], ["Agichtein", "Eugene", ""]]}, {"id": "2006.01921", "submitter": "Ingyu Jason Choi", "authors": "Jason Ingyu Choi, Ali Ahmadvand, Eugene Agichtein", "title": "Offline and Online Satisfaction Prediction in Open-Domain Conversational\n  Systems", "comments": "Published in CIKM '19, 10 pages", "journal-ref": null, "doi": "10.1145/3357384.3358047", "report-no": null, "categories": "cs.HC cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Predicting user satisfaction in conversational systems has become critical,\nas spoken conversational assistants operate in increasingly complex domains.\nOnline satisfaction prediction (i.e., predicting satisfaction of the user with\nthe system after each turn) could be used as a new proxy for implicit user\nfeedback, and offers promising opportunities to create more responsive and\neffective conversational agents, which adapt to the user's engagement with the\nagent. To accomplish this goal, we propose a conversational satisfaction\nprediction model specifically designed for open-domain spoken conversational\nagents, called ConvSAT. To operate robustly across domains, ConvSAT aggregates\nmultiple representations of the conversation, namely the conversation history,\nutterance and response content, and system- and user-oriented behavioral\nsignals. We first calibrate ConvSAT performance against state of the art\nmethods on a standard dataset (Dialogue Breakdown Detection Challenge) in an\nonline regime, and then evaluate ConvSAT on a large dataset of conversations\nwith real users, collected as part of the Alexa Prize competition. Our\nexperimental results show that ConvSAT significantly improves satisfaction\nprediction for both offline and online setting on both datasets, compared to\nthe previously reported state-of-the-art approaches. The insights from our\nstudy can enable more intelligent conversational systems, which could adapt in\nreal-time to the inferred user satisfaction and engagement.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jun 2020 20:04:56 GMT"}], "update_date": "2020-06-04", "authors_parsed": [["Choi", "Jason Ingyu", ""], ["Ahmadvand", "Ali", ""], ["Agichtein", "Eugene", ""]]}, {"id": "2006.01962", "submitter": "Shiwali Mohan", "authors": "Shiwali Mohan, Matt Klenk, Matthew Shreve, Kent Evans, Aaron Ang, John\n  Maxwell", "title": "Characterizing an Analogical Concept Memory for Architectures\n  Implementing the Common Model of Cognition", "comments": "To be presented the Eighth Annual Conference on Advances in Cognitive\n  Systems (ACS 2020) (https://advancesincognitivesystems.github.io/acs/)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.HC cs.RO cs.SC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Architectures that implement the Common Model of Cognition - Soar, ACT-R, and\nSigma - have a prominent place in research on cognitive modeling as well as on\ndesigning complex intelligent agents. In this paper, we explore how\ncomputational models of analogical processing can be brought into these\narchitectures to enable concept acquisition from examples obtained\ninteractively. We propose a new analogical concept memory for Soar that\naugments its current system of declarative long-term memories. We frame the\nproblem of concept learning as embedded within the larger context of\ninteractive task learning (ITL) and embodied language processing (ELP). We\ndemonstrate that the analogical learning methods implemented in the proposed\nmemory can quickly learn a diverse types of novel concepts that are useful not\nonly in recognition of a concept in the environment but also in action\nselection. Our approach has been instantiated in an implemented cognitive\nsystem \\textsc{Aileen} and evaluated on a simulated robotic domain.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jun 2020 21:54:03 GMT"}, {"version": "v2", "created": "Fri, 19 Jun 2020 00:25:25 GMT"}, {"version": "v3", "created": "Wed, 29 Jul 2020 18:02:17 GMT"}], "update_date": "2020-07-31", "authors_parsed": [["Mohan", "Shiwali", ""], ["Klenk", "Matt", ""], ["Shreve", "Matthew", ""], ["Evans", "Kent", ""], ["Ang", "Aaron", ""], ["Maxwell", "John", ""]]}, {"id": "2006.02008", "submitter": "Junhong Xu", "authors": "Junhong Xu, Kai Yin, Lantao Liu", "title": "Kernel Taylor-Based Value Function Approximation for Continuous-State\n  Markov Decision Processes", "comments": "Accepted by Robotics: Science and Systems 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a principled kernel-based policy iteration algorithm to solve the\ncontinuous-state Markov Decision Processes (MDPs). In contrast to most\ndecision-theoretic planning frameworks, which assume fully known state\ntransition models, we design a method that eliminates such a strong assumption,\nwhich is oftentimes extremely difficult to engineer in reality. To achieve\nthis, we first apply the second-order Taylor expansion of the value function.\nThe Bellman optimality equation is then approximated by a partial differential\nequation, which only relies on the first and second moments of the transition\nmodel. By combining the kernel representation of value function, we then design\nan efficient policy iteration algorithm whose policy evaluation step can be\nrepresented as a linear system of equations characterized by a finite set of\nsupporting states. We have validated the proposed method through extensive\nsimulations in both simplified and realistic planning scenarios, and the\nexperiments show that our proposed approach leads to a much superior\nperformance over several baseline methods.\n", "versions": [{"version": "v1", "created": "Wed, 3 Jun 2020 01:48:43 GMT"}], "update_date": "2020-06-04", "authors_parsed": [["Xu", "Junhong", ""], ["Yin", "Kai", ""], ["Liu", "Lantao", ""]]}, {"id": "2006.02046", "submitter": "Zuohui Fu", "authors": "Zuohui Fu, Yikun Xian, Ruoyuan Gao, Jieyu Zhao, Qiaoying Huang,\n  Yingqiang Ge, Shuyuan Xu, Shijie Geng, Chirag Shah, Yongfeng Zhang, Gerard de\n  Melo", "title": "Fairness-Aware Explainable Recommendation over Knowledge Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There has been growing attention on fairness considerations recently,\nespecially in the context of intelligent decision making systems. Explainable\nrecommendation systems, in particular, may suffer from both explanation bias\nand performance disparity. In this paper, we analyze different groups of users\naccording to their level of activity, and find that bias exists in\nrecommendation performance between different groups. We show that inactive\nusers may be more susceptible to receiving unsatisfactory recommendations, due\nto insufficient training data for the inactive users, and that their\nrecommendations may be biased by the training records of more active users, due\nto the nature of collaborative filtering, which leads to an unfair treatment by\nthe system. We propose a fairness constrained approach via heuristic re-ranking\nto mitigate this unfairness problem in the context of explainable\nrecommendation over knowledge graphs. We experiment on several real-world\ndatasets with state-of-the-art knowledge graph-based explainable recommendation\nalgorithms. The promising results show that our algorithm is not only able to\nprovide high-quality explainable recommendations, but also reduces the\nrecommendation unfairness in several respects.\n", "versions": [{"version": "v1", "created": "Wed, 3 Jun 2020 05:04:38 GMT"}, {"version": "v2", "created": "Sun, 28 Jun 2020 02:34:35 GMT"}], "update_date": "2020-06-30", "authors_parsed": [["Fu", "Zuohui", ""], ["Xian", "Yikun", ""], ["Gao", "Ruoyuan", ""], ["Zhao", "Jieyu", ""], ["Huang", "Qiaoying", ""], ["Ge", "Yingqiang", ""], ["Xu", "Shuyuan", ""], ["Geng", "Shijie", ""], ["Shah", "Chirag", ""], ["Zhang", "Yongfeng", ""], ["de Melo", "Gerard", ""]]}, {"id": "2006.02078", "submitter": "Nadia Labai", "authors": "Nadia Labai, Magdalena Ortiz, Mantas \\v{S}imkus", "title": "An ExpTime Upper Bound for $\\mathcal{ALC}$ with Integers (Extended\n  Version)", "comments": "This is a pre-print containing the proofs omitted from the conference\n  version. 36 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Concrete domains, especially those that allow to compare features with\nnumeric values, have long been recognized as a very desirable extension of\ndescription logics (DLs), and significant efforts have been invested into\nadding them to usual DLs while keeping the complexity of reasoning in check.\nFor expressive DLs and in the presence of general TBoxes, for standard\nreasoning tasks like consistency, the most general decidability results are for\nthe so-called $\\omega$-admissible domains, which are required to be dense.\nSupporting non-dense domains for features that range over integers or natural\nnumbers remained largely open, despite often being singled out as a highly\ndesirable extension. The decidability of some extensions of $\\mathcal{ALC}$\nwith non-dense domains has been shown, but existing results rely on powerful\nmachinery that does not allow to infer any elementary bounds on the complexity\nof the problem. In this paper, we study an extension of $\\mathcal{ALC}$ with a\nrich integer domain that allows for comparisons (between features, and between\nfeatures and constants coded in unary), and prove that consistency can be\nsolved using automata-theoretic techniques in single exponential time, and thus\nhas no higher worst-case complexity than standard $\\mathcal{ALC}$. Our upper\nbounds apply to some extensions of DLs with concrete domains known from the\nliterature, support general TBoxes, and allow for comparing values along paths\nof ordinary (not necessarily functional) roles.\n", "versions": [{"version": "v1", "created": "Wed, 3 Jun 2020 07:28:39 GMT"}], "update_date": "2020-06-04", "authors_parsed": [["Labai", "Nadia", ""], ["Ortiz", "Magdalena", ""], ["\u0160imkus", "Mantas", ""]]}, {"id": "2006.02081", "submitter": "Olivier Bailleux", "authors": "Olivier Bailleux (LIB), Yacine Boufkhad (LIAFA)", "title": "Constraint Reductions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This is a commentary on the CP 2003 paper \"Efficient cnf encoding of boolean\ncardinality constraints\". After recalling its context, we outline a\nclassification of Constraints with respect to their deductive power regarding\nGeneral Arc Consistency (GAC).\n", "versions": [{"version": "v1", "created": "Wed, 3 Jun 2020 07:37:05 GMT"}], "update_date": "2020-06-04", "authors_parsed": [["Bailleux", "Olivier", "", "LIB"], ["Boufkhad", "Yacine", "", "LIAFA"]]}, {"id": "2006.02168", "submitter": "Paul Hofmann", "authors": "Jinghai Rao and Dimitar Dimitrov and Paul Hofmann and Norman Sadeh", "title": "A Mixed Initiative Semantic Web Framework for Process Composition", "comments": null, "journal-ref": "IEEE International Semantic Web Conference 2006, 873-886,\n  Springer, Berlin, Heidelberg", "doi": null, "report-no": null, "categories": "cs.SE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Semantic Web technologies offer the prospect of significantly reducing the\namount of effort required to integrate existing enterprise functionality in\nsupport of new composite processes; whether within a given organization or\nacross multiple ones. A significant body of work in this area has aimed to\nfully automate this process, while assuming that all functionality has already\nbeen encapsulated in the form of semantic web services with rich and accurate\nannotations. In this article, we argue that this assumption is often\nunrealistic. Instead, we describe a mixed initiative framework for semantic web\nservice discovery and composition that aims at flexibly interleaving human\ndecision making and automated functionality in environments where annotations\nmay be incomplete and even inconsistent.\n", "versions": [{"version": "v1", "created": "Wed, 3 Jun 2020 11:02:31 GMT"}], "update_date": "2020-06-04", "authors_parsed": [["Rao", "Jinghai", ""], ["Dimitrov", "Dimitar", ""], ["Hofmann", "Paul", ""], ["Sadeh", "Norman", ""]]}, {"id": "2006.02174", "submitter": "Alessandro Suglia", "authors": "Alessandro Suglia, Ioannis Konstas, Andrea Vanzo, Emanuele\n  Bastianelli, Desmond Elliott, Stella Frank and Oliver Lemon", "title": "CompGuessWhat?!: A Multi-task Evaluation Framework for Grounded Language\n  Learning", "comments": "Accepted to the Annual Conference of the Association for\n  Computational Linguistics (ACL) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Approaches to Grounded Language Learning typically focus on a single\ntask-based final performance measure that may not depend on desirable\nproperties of the learned hidden representations, such as their ability to\npredict salient attributes or to generalise to unseen situations. To remedy\nthis, we present GROLLA, an evaluation framework for Grounded Language Learning\nwith Attributes with three sub-tasks: 1) Goal-oriented evaluation; 2) Object\nattribute prediction evaluation; and 3) Zero-shot evaluation. We also propose a\nnew dataset CompGuessWhat?! as an instance of this framework for evaluating the\nquality of learned neural representations, in particular concerning attribute\ngrounding. To this end, we extend the original GuessWhat?! dataset by including\na semantic layer on top of the perceptual one. Specifically, we enrich the\nVisualGenome scene graphs associated with the GuessWhat?! images with abstract\nand situated attributes. By using diagnostic classifiers, we show that current\nmodels learn representations that are not expressive enough to encode object\nattributes (average F1 of 44.27). In addition, they do not learn strategies nor\nrepresentations that are robust enough to perform well when novel scenes or\nobjects are involved in gameplay (zero-shot best accuracy 50.06%).\n", "versions": [{"version": "v1", "created": "Wed, 3 Jun 2020 11:21:42 GMT"}], "update_date": "2020-06-04", "authors_parsed": [["Suglia", "Alessandro", ""], ["Konstas", "Ioannis", ""], ["Vanzo", "Andrea", ""], ["Bastianelli", "Emanuele", ""], ["Elliott", "Desmond", ""], ["Frank", "Stella", ""], ["Lemon", "Oliver", ""]]}, {"id": "2006.02184", "submitter": "Agnes Cseh", "authors": "Katar\\'ina Cechl\\'arov\\'a, \\'Agnes Cseh, Zsuzsanna Jank\\'o, Mari\\'an\n  Kire\\v{s}, Luk\\'a\\v{s} Mi\\v{n}o", "title": "A quest for a fair schedule: The Young Physicists' Tournament", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.DM math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Young Physicists Tournament is an established team-oriented scientific\ncompetition between high school students from 37 countries on 5 continents. The\ncompetition consists of scientific discussions called Fights. Three or four\nteams participate in each Fight, each of whom presents a problem while rotating\nthe roles of Presenter, Opponent, Reviewer, and Observer among them.\n  The rules of a few countries require that each team announce in advance 3\nproblems they will present at the national tournament. The task of the\norganizers is to choose the composition of Fights in such a way that each team\npresents each of its chosen problems exactly once and within a single Fight no\nproblem is presented more than once. Besides formalizing these feasibility\nconditions, in this paper we formulate several additional fairness conditions\nfor tournament schedules. We show that the fulfillment of some of them can be\nensured by constructing suitable edge colorings in bipartite graphs. To find\nfair schedules, we propose integer linear programs and test them on real as\nwell as randomly generated data.\n", "versions": [{"version": "v1", "created": "Wed, 3 Jun 2020 11:45:06 GMT"}, {"version": "v2", "created": "Mon, 19 Apr 2021 07:39:26 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Cechl\u00e1rov\u00e1", "Katar\u00edna", ""], ["Cseh", "\u00c1gnes", ""], ["Jank\u00f3", "Zsuzsanna", ""], ["Kire\u0161", "Mari\u00e1n", ""], ["Mi\u0148o", "Luk\u00e1\u0161", ""]]}, {"id": "2006.02216", "submitter": "Manh Duong Phung", "authors": "Thi Thanh Van Nguyen, Manh Duong Phung, Dinh Tuan Pham, Quang Vinh\n  Tran", "title": "Development of a Fuzzy-based Patrol Robot Using in Building Automation\n  System", "comments": "in Vietnamese language", "journal-ref": "Journal of Computer Science and Cybernetics, Vol 27, No 1 (2011),\n  pp 83-92", "doi": null, "report-no": null, "categories": "cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A Building Automation System (BAS) has functions of monitoring and\ncontrolling the operation of all building sub-systems such as HVAC\n(Heating-Ventilation, Air-conditioning Control), electric consumption\nmanagement, fire alarm control, security and access control, and appliance\nswitching control. In the BAS, almost operations are automatically performed at\nthe control centre, the building security therefore must be strictly protected.\nIn the traditional system, the security is usually ensured by a number of\ncameras installed at fixed positions and it may results in a limited vision. To\novercome this disadvantage, our paper presents a novel security system in which\na mobile robot is used as a patrol. The robot is equipped with fuzzy-based\nalgorithms to allow it to avoid the obstacles in an unknown environment as well\nas other necessary mechanisms demanded for its patrol mission. The experiment\nresults show that the system satisfies the requirements for the objective of\nmonitoring and securing the building.\n", "versions": [{"version": "v1", "created": "Wed, 13 May 2020 07:05:02 GMT"}], "update_date": "2020-06-04", "authors_parsed": [["Van Nguyen", "Thi Thanh", ""], ["Phung", "Manh Duong", ""], ["Pham", "Dinh Tuan", ""], ["Tran", "Quang Vinh", ""]]}, {"id": "2006.02230", "submitter": "Sanket Tavarageri", "authors": "Sanket Tavarageri, Alexander Heinecke, Sasikanth Avancha, Gagandeep\n  Goyal, Ramakrishna Upadrasta, Bharat Kaul", "title": "PolyDL: Polyhedral Optimizations for Creation of High Performance DL\n  primitives", "comments": "arXiv admin note: substantial text overlap with arXiv:2002.02145", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.AI cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Neural Networks (DNNs) have revolutionized many aspects of our lives.\nThe use of DNNs is becoming ubiquitous including in softwares for image\nrecognition, speech recognition, speech synthesis, language translation, to\nname a few. he training of DNN architectures however is computationally\nexpensive. Once the model is created, its use in the intended application - the\ninference task, is computationally heavy too and the inference needs to be fast\nfor real time use. For obtaining high performance today, the code of Deep\nLearning (DL) primitives optimized for specific architectures by expert\nprogrammers exposed via libraries is the norm. However, given the constant\nemergence of new DNN architectures, creating hand optimized code is expensive,\nslow and is not scalable.\n  To address this performance-productivity challenge, in this paper we present\ncompiler algorithms to automatically generate high performance implementations\nof DL primitives that closely match the performance of hand optimized\nlibraries. We develop novel data reuse analysis algorithms using the polyhedral\nmodel to derive efficient execution schedules automatically. In addition,\nbecause most DL primitives use some variant of matrix multiplication at their\ncore, we develop a flexible framework where it is possible to plug in library\nimplementations of the same in lieu of a subset of the loops. We show that such\na hybrid compiler plus a minimal library-use approach results in\nstate-of-the-art performance. We develop compiler algorithms to also perform\noperator fusions that reduce data movement through the memory hierarchy of the\ncomputer system.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jun 2020 06:44:09 GMT"}, {"version": "v2", "created": "Tue, 17 Nov 2020 15:43:42 GMT"}], "update_date": "2020-11-18", "authors_parsed": [["Tavarageri", "Sanket", ""], ["Heinecke", "Alexander", ""], ["Avancha", "Sasikanth", ""], ["Goyal", "Gagandeep", ""], ["Upadrasta", "Ramakrishna", ""], ["Kaul", "Bharat", ""]]}, {"id": "2006.02256", "submitter": "Catarina Moreira", "authors": "Catarina Moreira and Matheus Hammes and Rasim Serdar Kurdoglu and\n  Peter Bruza", "title": "QuLBIT: Quantum-Like Bayesian Inference Technologies for Cognition and\n  Decision", "comments": null, "journal-ref": "Proceedings of the 42nd Annual Meeting of the Cognitive Science\n  Society, 2020", "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper provides the foundations of a unified cognitive decision-making\nframework (QulBIT) which is derived from quantum theory. The main advantage of\nthis framework is that it can cater for paradoxical and irrational human\ndecision making. Although quantum approaches for cognition have demonstrated\nadvantages over classical probabilistic approaches and bounded rationality\nmodels, they still lack explanatory power. To address this, we introduce a\nnovel explanatory analysis of the decision-maker's belief space. This is\nachieved by exploiting quantum interference effects as a way of both\nquantifying and explaining the decision-maker's uncertainty. We detail the main\nmodules of the unified framework, the explanatory analysis method, and\nillustrate their application in situations violating the Sure Thing Principle.\n", "versions": [{"version": "v1", "created": "Sat, 30 May 2020 09:02:03 GMT"}, {"version": "v2", "created": "Mon, 28 Jun 2021 18:39:34 GMT"}], "update_date": "2021-06-30", "authors_parsed": [["Moreira", "Catarina", ""], ["Hammes", "Matheus", ""], ["Kurdoglu", "Rasim Serdar", ""], ["Bruza", "Peter", ""]]}, {"id": "2006.02359", "submitter": "Simon DeDeo", "authors": "Zachary Wojtowicz and Simon DeDeo", "title": "From Probability to Consilience: How Explanatory Values Implement\n  Bayesian Reasoning", "comments": "19 pages, 1 figure, comments welcome", "journal-ref": "Trends in Cognitive Sciences (2020)", "doi": "10.1016/j.tics.2020.09.013", "report-no": null, "categories": "q-bio.NC cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work in cognitive science has uncovered a diversity of explanatory\nvalues, or dimensions along which we judge explanations as better or worse. We\npropose a Bayesian account of how these values fit together to guide\nexplanation. The resulting taxonomy provides a set of predictors for which\nexplanations people prefer and shows how core values from psychology,\nstatistics, and the philosophy of science emerge from a common mathematical\nframework. In addition to operationalizing the explanatory virtues associated\nwith, for example, scientific argument-making, this framework also enables us\nto reinterpret the explanatory vices that drive conspiracy theories, delusions,\nand extremist ideologies.\n", "versions": [{"version": "v1", "created": "Wed, 3 Jun 2020 16:11:45 GMT"}], "update_date": "2020-10-29", "authors_parsed": [["Wojtowicz", "Zachary", ""], ["DeDeo", "Simon", ""]]}, {"id": "2006.02419", "submitter": "Angeliki  Lazaridou", "authors": "Angeliki Lazaridou, Marco Baroni", "title": "Emergent Multi-Agent Communication in the Deep Learning Era", "comments": "Added some more references and discussion", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ability to cooperate through language is a defining feature of humans. As\nthe perceptual, motory and planning capabilities of deep artificial networks\nincrease, researchers are studying whether they also can develop a shared\nlanguage to interact. From a scientific perspective, understanding the\nconditions under which language evolves in communities of deep agents and its\nemergent features can shed light on human language evolution. From an applied\nperspective, endowing deep networks with the ability to solve problems\ninteractively by communicating with each other and with us should make them\nmore flexible and useful in everyday life.\n  This article surveys representative recent language emergence studies from\n  both of these two angles.\n", "versions": [{"version": "v1", "created": "Wed, 3 Jun 2020 17:50:16 GMT"}, {"version": "v2", "created": "Tue, 14 Jul 2020 09:21:53 GMT"}], "update_date": "2020-07-15", "authors_parsed": [["Lazaridou", "Angeliki", ""], ["Baroni", "Marco", ""]]}, {"id": "2006.02482", "submitter": "Daniel Malinsky", "authors": "Numair Sani, Daniel Malinsky, Ilya Shpitser", "title": "Explaining the Behavior of Black-Box Prediction Algorithms with Causal\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose to explain the behavior of black-box prediction methods (e.g.,\ndeep neural networks trained on image pixel data) using causal graphical\nmodels. Specifically, we explore learning the structure of a causal graph where\nthe nodes represent prediction outcomes along with a set of macro-level\n\"interpretable\" features, while allowing for arbitrary unmeasured confounding\namong these variables. The resulting graph may indicate which of the\ninterpretable features, if any, are possible causes of the prediction outcome\nand which may be merely associated with prediction outcomes due to confounding.\nThe approach is motivated by a counterfactual theory of causal explanation\nwherein good explanations point to factors that are \"difference-makers\" in an\ninterventionist sense. The resulting analysis may be useful in algorithm\nauditing and evaluation, by identifying features which make a causal difference\nto the algorithm's output.\n", "versions": [{"version": "v1", "created": "Wed, 3 Jun 2020 19:02:34 GMT"}, {"version": "v2", "created": "Tue, 16 Feb 2021 04:37:09 GMT"}, {"version": "v3", "created": "Wed, 16 Jun 2021 16:49:13 GMT"}], "update_date": "2021-06-17", "authors_parsed": [["Sani", "Numair", ""], ["Malinsky", "Daniel", ""], ["Shpitser", "Ilya", ""]]}, {"id": "2006.02577", "submitter": "Mark Tygert", "authors": "Isabel Kloumann and Mark Tygert", "title": "An optimizable scalar objective value cannot be objective and should not\n  be the sole objective", "comments": "13 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.LG cs.SY eess.SY math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper concerns the ethics and morality of algorithms and computational\nsystems, and has been circulating internally at Facebook for the past couple\nyears. The paper reviews many Nobel laureates' work, as well as the work of\nother prominent scientists such as Richard Dawkins, Andrei Kolmogorov, Vilfredo\nPareto, and John von Neumann. The paper draws conclusions based on such works,\nas summarized in the title. The paper argues that the standard approach to\nmodern machine learning and artificial intelligence is bound to be biased and\nunfair, and that longstanding traditions in the professions of law, justice,\npolitics, and medicine should help.\n", "versions": [{"version": "v1", "created": "Wed, 3 Jun 2020 23:10:38 GMT"}], "update_date": "2020-06-05", "authors_parsed": [["Kloumann", "Isabel", ""], ["Tygert", "Mark", ""]]}, {"id": "2006.02579", "submitter": "Tao Li", "authors": "James Bannon, Brad Windsor, Wenbo Song and Tao Li", "title": "Causality and Batch Reinforcement Learning: Complementary Approaches To\n  Planning In Unknown Domains", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning algorithms have had tremendous successes in online\nlearning settings. However, these successes have relied on low-stakes\ninteractions between the algorithmic agent and its environment. In many\nsettings where RL could be of use, such as health care and autonomous driving,\nthe mistakes made by most online RL algorithms during early training come with\nunacceptable costs. These settings require developing reinforcement learning\nalgorithms that can operate in the so-called batch setting, where the\nalgorithms must learn from set of data that is fixed, finite, and generated\nfrom some (possibly unknown) policy. Evaluating policies different from the one\nthat collected the data is called off-policy evaluation, and naturally poses\ncounter-factual questions. In this project we show how off-policy evaluation\nand the estimation of treatment effects in causal inference are two approaches\nto the same problem, and compare recent progress in these two areas.\n", "versions": [{"version": "v1", "created": "Wed, 3 Jun 2020 23:14:14 GMT"}], "update_date": "2020-06-05", "authors_parsed": [["Bannon", "James", ""], ["Windsor", "Brad", ""], ["Song", "Wenbo", ""], ["Li", "Tao", ""]]}, {"id": "2006.02636", "submitter": "Sergio Casas", "authors": "Sergio Casas, Cole Gulino, Simon Suo, Raquel Urtasun", "title": "The Importance of Prior Knowledge in Precise Multimodal Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Roads have well defined geometries, topologies, and traffic rules. While this\nhas been widely exploited in motion planning methods to produce maneuvers that\nobey the law, little work has been devoted to utilize these priors in\nperception and motion forecasting methods. In this paper we propose to\nincorporate these structured priors as a loss function. In contrast to imposing\nhard constraints, this approach allows the model to handle non-compliant\nmaneuvers when those happen in the real world. Safe motion planning is the end\ngoal, and thus a probabilistic characterization of the possible future\ndevelopments of the scene is key to choose the plan with the lowest expected\ncost. Towards this goal, we design a framework that leverages REINFORCE to\nincorporate non-differentiable priors over sample trajectories from a\nprobabilistic model, thus optimizing the whole distribution. We demonstrate the\neffectiveness of our approach on real-world self-driving datasets containing\ncomplex road topologies and multi-agent interactions. Our motion forecasts not\nonly exhibit better precision and map understanding, but most importantly\nresult in safer motion plans taken by our self-driving vehicle. We emphasize\nthat despite the importance of this evaluation, it has been often overlooked by\nprevious perception and motion forecasting works.\n", "versions": [{"version": "v1", "created": "Thu, 4 Jun 2020 03:56:11 GMT"}], "update_date": "2020-06-05", "authors_parsed": [["Casas", "Sergio", ""], ["Gulino", "Cole", ""], ["Suo", "Simon", ""], ["Urtasun", "Raquel", ""]]}, {"id": "2006.02648", "submitter": "Andreas Chandra", "authors": "Andreas Chandra, Ruben Stefanus", "title": "Experiments on Paraphrase Identification Using Quora Question Pairs\n  Dataset", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We modeled the Quora question pairs dataset to identify a similar question.\nThe dataset that we use is provided by Quora. The task is a binary\nclassification. We tried several methods and algorithms and different approach\nfrom previous works. For feature extraction, we used Bag of Words including\nCount Vectorizer, and Term Frequency-Inverse Document Frequency with unigram\nfor XGBoost and CatBoost. Furthermore, we also experimented with WordPiece\ntokenizer which improves the model performance significantly. We achieved up to\n97 percent accuracy. Code and Dataset.\n", "versions": [{"version": "v1", "created": "Thu, 4 Jun 2020 05:43:25 GMT"}, {"version": "v2", "created": "Fri, 5 Jun 2020 03:38:51 GMT"}], "update_date": "2020-06-08", "authors_parsed": [["Chandra", "Andreas", ""], ["Stefanus", "Ruben", ""]]}, {"id": "2006.02689", "submitter": "Dieqiao Feng", "authors": "Dieqiao Feng, Carla P. Gomes, and Bart Selman", "title": "Solving Hard AI Planning Instances Using Curriculum-Driven Deep\n  Reinforcement Learning", "comments": "8 pages, 6 figures, accepted by IJCAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite significant progress in general AI planning, certain domains remain\nout of reach of current AI planning systems. Sokoban is a PSPACE-complete\nplanning task and represents one of the hardest domains for current AI\nplanners. Even domain-specific specialized search methods fail quickly due to\nthe exponential search complexity on hard instances. Our approach based on deep\nreinforcement learning augmented with a curriculum-driven method is the first\none to solve hard instances within one day of training while other modern\nsolvers cannot solve these instances within any reasonable time limit. In\ncontrast to prior efforts, which use carefully handcrafted pruning techniques,\nour approach automatically uncovers domain structure. Our results reveal that\ndeep RL provides a promising framework for solving previously unsolved AI\nplanning problems, provided a proper training curriculum can be devised.\n", "versions": [{"version": "v1", "created": "Thu, 4 Jun 2020 08:13:12 GMT"}], "update_date": "2020-06-05", "authors_parsed": [["Feng", "Dieqiao", ""], ["Gomes", "Carla P.", ""], ["Selman", "Bart", ""]]}, {"id": "2006.02716", "submitter": "Alexandr Grichshenko", "authors": "Alexandr Grichshenko, Luiz Jonata Pires de Araujo, Susanna Gimaeva,\n  Joseph Alexander Brown", "title": "Using Tabu Search Algorithm for Map Generation in the Terra Mystica\n  Tabletop Game", "comments": null, "journal-ref": "ISMSI '20: Proceedings of the 2020 4th International Conference on\n  Intelligent Systems, Metaheuristics & Swarm Intelligence", "doi": "10.1145/3396474.3396492", "report-no": null, "categories": "cs.AI cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Tabu Search (TS) metaheuristic improves simple local search algorithms (e.g.\nsteepest ascend hill-climbing) by enabling the algorithm to escape local optima\npoints. It has shown to be useful for addressing several combinatorial\noptimization problems. This paper investigates the performance of TS and\nconsiders the effects of the size of the Tabu list and the size of the\nneighbourhood for a procedural content generation, specifically the generation\nof maps for a popular tabletop game called Terra Mystica. The results validate\nthe feasibility of the proposed method and how it can be used to generate maps\nthat improve existing maps for the game.\n", "versions": [{"version": "v1", "created": "Thu, 4 Jun 2020 09:15:46 GMT"}], "update_date": "2020-06-05", "authors_parsed": [["Grichshenko", "Alexandr", ""], ["de Araujo", "Luiz Jonata Pires", ""], ["Gimaeva", "Susanna", ""], ["Brown", "Joseph Alexander", ""]]}, {"id": "2006.02767", "submitter": "Abonia Sojasingarayar", "authors": "Abonia Sojasingarayar", "title": "Seq2Seq AI Chatbot with Attention Mechanism", "comments": "18 pages 8 Figures 4 Tables 5 Equations", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Intelligent Conversational Agent development using Artificial Intelligence or\nMachine Learning technique is an interesting problem in the field of Natural\nLanguage Processing. With the rise of deep learning, these models were quickly\nreplaced by end to end trainable neural networks.\n", "versions": [{"version": "v1", "created": "Thu, 4 Jun 2020 10:54:43 GMT"}], "update_date": "2020-06-05", "authors_parsed": [["Sojasingarayar", "Abonia", ""]]}, {"id": "2006.02818", "submitter": "Mo Hossny", "authors": "Mohammed Hossny, Julie Iskander, Mohammed Attia, Khaled Saleh", "title": "Refined Continuous Control of DDPG Actors via Parametrised Activation", "comments": "9 pages, 7 figures, 2 tables, submitted to Elsevier. This manuscript\n  version is made available under the CC-BY-NC-ND 4.0 license\n  http://creativecommons.org/licenses/by- nc-nd/4.0/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose enhancing actor-critic reinforcement learning\nagents by parameterising the final actor layer which produces the actions in\norder to accommodate the behaviour discrepancy of different actuators, under\ndifferent load conditions during interaction with the environment. We propose\nbranching the action producing layer in the actor to learn the tuning parameter\ncontrolling the activation layer (e.g. Tanh and Sigmoid). The learned\nparameters are then used to create tailored activation functions for each\nactuator. We ran experiments on three OpenAI Gym environments, i.e.\nPendulum-v0, LunarLanderContinuous-v2 and BipedalWalker-v2. Results have shown\nan average of 23.15% and 33.80% increase in total episode reward of the\nLunarLanderContinuous-v2 and BipedalWalker-v2 environments, respectively. There\nwas no significant improvement in Pendulum-v0 environment but the proposed\nmethod produces a more stable actuation signal compared to the state-of-the-art\nmethod. The proposed method allows the reinforcement learning actor to produce\nmore robust actions that accommodate the discrepancy in the actuators' response\nfunctions. This is particularly useful for real life scenarios where actuators\nexhibit different response functions depending on the load and the interaction\nwith the environment. This also simplifies the transfer learning problem by\nfine tuning the parameterised activation layers instead of retraining the\nentire policy every time an actuator is replaced. Finally, the proposed method\nwould allow better accommodation to biological actuators (e.g. muscles) in\nbiomechanical systems.\n", "versions": [{"version": "v1", "created": "Thu, 4 Jun 2020 12:27:46 GMT"}], "update_date": "2020-06-05", "authors_parsed": [["Hossny", "Mohammed", ""], ["Iskander", "Julie", ""], ["Attia", "Mohammed", ""], ["Saleh", "Khaled", ""]]}, {"id": "2006.02854", "submitter": "Christian Anti\\'c", "authors": "Christian Anti\\'c", "title": "Analogical Proportions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI cs.LG cs.SC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Analogy-making is at the core of human intelligence and creativity with\napplications to such diverse tasks as commonsense reasoning, learning, language\nacquisition, and story telling. This paper contributes to the foundations of\nartificial general intelligence by introducing from first principles an\nabstract algebraic framework of analogical proportions of the form `$a$ is to\n$b$ what $c$ is to $d$' in the general setting of universal algebra. This\nenables us to compare mathematical objects possibly across different domains in\na uniform way which is crucial for AI-systems. The main idea is to define\nsolutions to analogical equations in terms of maximal sets of algebraic\njustifications, which amounts to deriving abstract terms of concrete elements\nfrom a `known' source domain which can then be instantiated in an `unknown'\ntarget domain to obtain analogous elements. It turns out that our notion of\nanalogical proportions has appealing mathematical properties. For example, we\nshow that analogical proportions preserve functional dependencies across\ndifferent domains, which is desirable. We study Lepage's axioms of analogical\nproportions and argue why we disagree with his symmetry, central permutation,\nstrong reflexivity, and strong determinism axioms. We compare our framework\nwith two prominent and recently introduced frameworks of analogical proportions\nfrom the literature in the concrete domains of sets and numbers, and we show\nthat in each case we either disagree with the notion from the literature\njustified by some plausible counter-example or we can show that our model\nyields strictly more reasonable solutions. This provides evidence for its\napplicability. In a broader sense, this paper is a first step towards a theory\nof analogical reasoning and learning systems with potential applications to\nfundamental AI-problems like commonsense reasoning and computational learning\nand creativity.\n", "versions": [{"version": "v1", "created": "Thu, 4 Jun 2020 13:44:36 GMT"}, {"version": "v2", "created": "Sun, 7 Jun 2020 13:54:42 GMT"}, {"version": "v3", "created": "Tue, 25 Aug 2020 14:30:38 GMT"}, {"version": "v4", "created": "Thu, 10 Dec 2020 14:52:31 GMT"}, {"version": "v5", "created": "Sat, 17 Apr 2021 14:36:37 GMT"}, {"version": "v6", "created": "Tue, 25 May 2021 12:12:56 GMT"}], "update_date": "2021-05-26", "authors_parsed": [["Anti\u0107", "Christian", ""]]}, {"id": "2006.02862", "submitter": "Emna Jabri EmnaJ", "authors": "Emna Jabri", "title": "A Novel Approach for Generating SPARQL Queries from RDF Graphs", "comments": "in French. arXiv admin note: substantial text overlap with\n  arXiv:1810.02869 by other authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work is done as part of a research master's thesis project. The goal is\nto generate SPARQL queries based on user-supplied keywords to query RDF graphs.\nTo do this, we first transformed the input ontology into an RDF graph that\nreflects the semantics represented in the ontology. Subsequently, we stored\nthis RDF graph in the Neo4j graphical database to ensure efficient and\npersistent management of RDF data. At the time of the interrogation, we studied\nthe different possible and desired interpretations of the request originally\nmade by the user. We have also proposed to carry out a sort of transformation\nbetween the two query languages SPARQL and Cypher, which is specific to Neo4j.\nThis allows us to implement the architecture of our system over a wide variety\nof BD-RDFs providing their query languages, without changing any of the other\ncomponents of the system. Finally, we tested and evaluated our tool using\ndifferent test bases, and it turned out that our tool is comprehensive,\neffective, and powerful enough.\n", "versions": [{"version": "v1", "created": "Sat, 30 May 2020 18:28:49 GMT"}], "update_date": "2020-06-05", "authors_parsed": [["Jabri", "Emna", ""]]}, {"id": "2006.02909", "submitter": "Nicholas Schaub", "authors": "Nicholas J. Schaub, Nathan Hotaling", "title": "Assessing Intelligence in Artificial Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The purpose of this work was to develop of metrics to assess network\narchitectures that balance neural network size and task performance. To this\nend, the concept of neural efficiency is introduced to measure neural layer\nutilization, and a second metric called artificial intelligence quotient (aIQ)\nwas created to balance neural network performance and neural network\nefficiency. To study aIQ and neural efficiency, two simple neural networks were\ntrained on MNIST: a fully connected network (LeNet-300-100) and a convolutional\nneural network (LeNet-5). The LeNet-5 network with the highest aIQ was 2.32%\nless accurate but contained 30,912 times fewer parameters than the highest\naccuracy network. Both batch normalization and dropout layers were found to\nincrease neural efficiency. Finally, high aIQ networks are shown to be\nmemorization and overtraining resistant, capable of learning proper digit\nclassification with an accuracy of 92.51% even when 75% of the class labels are\nrandomized. These results demonstrate the utility of aIQ and neural efficiency\nas metrics for balancing network performance and size.\n", "versions": [{"version": "v1", "created": "Wed, 3 Jun 2020 16:45:42 GMT"}], "update_date": "2020-06-05", "authors_parsed": [["Schaub", "Nicholas J.", ""], ["Hotaling", "Nathan", ""]]}, {"id": "2006.02949", "submitter": "Dale Zhou", "authors": "Dale Zhou, David M. Lydon-Staley, Perry Zurn, Danielle S. Bassett", "title": "The growth and form of knowledge networks by kinesthetic curiosity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Throughout life, we might seek a calling, companions, skills, entertainment,\ntruth, self-knowledge, beauty, and edification. The practice of curiosity can\nbe viewed as an extended and open-ended search for valuable information with\nhidden identity and location in a complex space of interconnected information.\nDespite its importance, curiosity has been challenging to computationally model\nbecause the practice of curiosity often flourishes without specific goals,\nexternal reward, or immediate feedback. Here, we show how network science,\nstatistical physics, and philosophy can be integrated into an approach that\ncoheres with and expands the psychological taxonomies of specific-diversive and\nperceptual-epistemic curiosity. Using this interdisciplinary approach, we\ndistill functional modes of curious information seeking as searching movements\nin information space. The kinesthetic model of curiosity offers a vibrant\ncounterpart to the deliberative predictions of model-based reinforcement\nlearning. In doing so, this model unearths new computational opportunities for\nidentifying what makes curiosity curious.\n", "versions": [{"version": "v1", "created": "Thu, 4 Jun 2020 15:30:41 GMT"}], "update_date": "2020-06-05", "authors_parsed": [["Zhou", "Dale", ""], ["Lydon-Staley", "David M.", ""], ["Zurn", "Perry", ""], ["Bassett", "Danielle S.", ""]]}, {"id": "2006.03000", "submitter": "Kaige Yang Mr", "authors": "Kaige Yang and Laura Toni", "title": "Differentiable Linear Bandit Algorithm", "comments": "16 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Upper Confidence Bound (UCB) is arguably the most commonly used method for\nlinear multi-arm bandit problems. While conceptually and computationally\nsimple, this method highly relies on the confidence bounds, failing to strike\nthe optimal exploration-exploitation if these bounds are not properly set. In\nthe literature, confidence bounds are typically derived from concentration\ninequalities based on assumptions on the reward distribution, e.g.,\nsub-Gaussianity. The validity of these assumptions however is unknown in\npractice. In this work, we aim at learning the confidence bound in a\ndata-driven fashion, making it adaptive to the actual problem structure.\nSpecifically, noting that existing UCB-typed algorithms are not differentiable\nwith respect to confidence bound, we first propose a novel differentiable\nlinear bandit algorithm. Then, we introduce a gradient estimator, which allows\nthe confidence bound to be learned via gradient ascent. Theoretically, we show\nthat the proposed algorithm achieves a\n$\\tilde{\\mathcal{O}}(\\hat{\\beta}\\sqrt{dT})$ upper bound of $T$-round regret,\nwhere $d$ is the dimension of arm features and $\\hat{\\beta}$ is the learned\nsize of confidence bound. Empirical results show that $\\hat{\\beta}$ is\nsignificantly smaller than its theoretical upper bound and proposed algorithms\noutperforms baseline ones on both simulated and real-world datasets.\n", "versions": [{"version": "v1", "created": "Thu, 4 Jun 2020 16:43:55 GMT"}], "update_date": "2020-06-05", "authors_parsed": [["Yang", "Kaige", ""], ["Toni", "Laura", ""]]}, {"id": "2006.03079", "submitter": "Tim Taylor", "authors": "Tim Taylor", "title": "The Importance of Open-Endedness (for the Sake of Open-Endedness)", "comments": "To appear in Proceedings of the Artificial Life Conference 2020\n  (ALIFE 2020), MIT Press", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A paper in the recent Artificial Life journal special issue on open-ended\nevolution (OEE) presents a simple evolving computational system that, it is\nclaimed, satisfies all proposed requirements for OEE (Hintze, 2019). Analysis\nand discussion of the system are used to support the further claims that\ncomplexity and diversity are the crucial features of open-endedness, and that\nwe should concentrate on providing proper definitions for those terms rather\nthan engaging in \"the quest for open-endedness for the sake of open-endedness\"\n(Hintze, 2019, p. 205). While I wholeheartedly support the pursuit of precise\ndefinitions of complexity and diversity in relation to OEE research, I\nemphatically reject the suggestion that OEE is not a worthy research topic in\nits own right. In the same issue of the journal, I presented a \"high-level\nconceptual framework to help orient the discussion and implementation of\nopen-endedness in evolutionary systems\" (Taylor, 2019). In the current brief\ncontribution I apply my framework to Hinzte's model to understand its\nlimitations. In so doing, I demonstrate the importance of studying\nopen-endedness for the sake of open-endedness.\n", "versions": [{"version": "v1", "created": "Thu, 4 Jun 2020 18:02:31 GMT"}], "update_date": "2020-06-08", "authors_parsed": [["Taylor", "Tim", ""]]}, {"id": "2006.03122", "submitter": "Mohammad Naser Sabet Jahromi", "authors": "Satya M. Muddamsetty, Mohammad N. S. Jahromi, Thomas B. Moeslund", "title": "SIDU: Similarity Difference and Uniqueness Method for Explainable AI", "comments": "Accepted manuscript in IEEE International Conference on Image\n  Processing", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A new brand of technical artificial intelligence ( Explainable AI ) research\nhas focused on trying to open up the 'black box' and provide some\nexplainability. This paper presents a novel visual explanation method for deep\nlearning networks in the form of a saliency map that can effectively localize\nentire object regions. In contrast to the current state-of-the art methods, the\nproposed method shows quite promising visual explanations that can gain greater\ntrust of human expert. Both quantitative and qualitative evaluations are\ncarried out on both general and clinical data sets to confirm the effectiveness\nof the proposed method.\n", "versions": [{"version": "v1", "created": "Thu, 4 Jun 2020 20:33:40 GMT"}], "update_date": "2020-06-08", "authors_parsed": [["Muddamsetty", "Satya M.", ""], ["Jahromi", "Mohammad N. S.", ""], ["Moeslund", "Thomas B.", ""]]}, {"id": "2006.03185", "submitter": "Zhiwen Tang", "authors": "Limin Chen, Zhiwen Tang, Grace Hui Yang", "title": "Balancing Reinforcement Learning Training Experiences in Interactive\n  Information Retrieval", "comments": "Accepted by SIGIR 2020", "journal-ref": null, "doi": "10.1145/3397271.3401200", "report-no": null, "categories": "cs.IR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Interactive Information Retrieval (IIR) and Reinforcement Learning (RL) share\nmany commonalities, including an agent who learns while interacts, a long-term\nand complex goal, and an algorithm that explores and adapts. To successfully\napply RL methods to IIR, one challenge is to obtain sufficient relevance labels\nto train the RL agents, which are infamously known as sample inefficient.\nHowever, in a text corpus annotated for a given query, it is not the relevant\ndocuments but the irrelevant documents that predominate. This would cause very\nunbalanced training experiences for the agent and prevent it from learning any\npolicy that is effective. Our paper addresses this issue by using domain\nrandomization to synthesize more relevant documents for the training. Our\nexperimental results on the Text REtrieval Conference (TREC) Dynamic Domain\n(DD) 2017 Track show that the proposed method is able to boost an RL agent's\nlearning effectiveness by 22\\% in dealing with unseen situations.\n", "versions": [{"version": "v1", "created": "Fri, 5 Jun 2020 00:38:39 GMT"}, {"version": "v2", "created": "Wed, 9 Jun 2021 01:41:34 GMT"}], "update_date": "2021-06-10", "authors_parsed": [["Chen", "Limin", ""], ["Tang", "Zhiwen", ""], ["Yang", "Grace Hui", ""]]}, {"id": "2006.03201", "submitter": "Eadom Dessalene", "authors": "Eadom Dessalene, Michael Maynord, Chinmaya Devaraj, Cornelia Fermuller\n  and Yiannis Aloimonos", "title": "Egocentric Object Manipulation Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce Egocentric Object Manipulation Graphs (Ego-OMG) - a novel\nrepresentation for activity modeling and anticipation of near future actions\nintegrating three components: 1) semantic temporal structure of activities, 2)\nshort-term dynamics, and 3) representations for appearance. Semantic temporal\nstructure is modeled through a graph, embedded through a Graph Convolutional\nNetwork, whose states model characteristics of and relations between hands and\nobjects. These state representations derive from all three levels of\nabstraction, and span segments delimited by the making and breaking of\nhand-object contact. Short-term dynamics are modeled in two ways: A) through 3D\nconvolutions, and B) through anticipating the spatiotemporal end points of hand\ntrajectories, where hands come into contact with objects. Appearance is modeled\nthrough deep spatiotemporal features produced through existing methods. We note\nthat in Ego-OMG it is simple to swap these appearance features, and thus\nEgo-OMG is complementary to most existing action anticipation methods. We\nevaluate Ego-OMG on the EPIC Kitchens Action Anticipation Challenge. The\nconsistency of the egocentric perspective of EPIC Kitchens allows for the\nutilization of the hand-centric cues upon which Ego-OMG relies. We demonstrate\nstate-of-the-art performance, outranking all other previous published methods\nby large margins and ranking first on the unseen test set and second on the\nseen test set of the EPIC Kitchens Action Anticipation Challenge. We attribute\nthe success of Ego-OMG to the modeling of semantic structure captured over long\ntimespans. We evaluate the design choices made through several ablation\nstudies. Code will be released upon acceptance\n", "versions": [{"version": "v1", "created": "Fri, 5 Jun 2020 02:03:25 GMT"}], "update_date": "2020-06-08", "authors_parsed": [["Dessalene", "Eadom", ""], ["Maynord", "Michael", ""], ["Devaraj", "Chinmaya", ""], ["Fermuller", "Cornelia", ""], ["Aloimonos", "Yiannis", ""]]}, {"id": "2006.03204", "submitter": "Vitali Petsiuk", "authors": "Vitali Petsiuk and Rajiv Jain and Varun Manjunatha and Vlad I. Morariu\n  and Ashutosh Mehra and Vicente Ordonez and Kate Saenko", "title": "Black-box Explanation of Object Detectors via Saliency Maps", "comments": "CVPR 2021 (oral). Project page\n  https://cs-people.bu.edu/vpetsiuk/drise/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We propose D-RISE, a method for generating visual explanations for the\npredictions of object detectors. Utilizing the proposed similarity metric that\naccounts for both localization and categorization aspects of object detection\nallows our method to produce saliency maps that show image areas that most\naffect the prediction. D-RISE can be considered \"black-box\" in the software\ntesting sense, as it only needs access to the inputs and outputs of an object\ndetector. Compared to gradient-based methods, D-RISE is more general and\nagnostic to the particular type of object detector being tested, and does not\nneed knowledge of the inner workings of the model. We show that D-RISE can be\neasily applied to different object detectors including one-stage detectors such\nas YOLOv3 and two-stage detectors such as Faster-RCNN. We present a detailed\nanalysis of the generated visual explanations to highlight the utilization of\ncontext and possible biases learned by object detectors.\n", "versions": [{"version": "v1", "created": "Fri, 5 Jun 2020 02:13:35 GMT"}, {"version": "v2", "created": "Thu, 10 Jun 2021 22:36:13 GMT"}], "update_date": "2021-06-14", "authors_parsed": [["Petsiuk", "Vitali", ""], ["Jain", "Rajiv", ""], ["Manjunatha", "Varun", ""], ["Morariu", "Vlad I.", ""], ["Mehra", "Ashutosh", ""], ["Ordonez", "Vicente", ""], ["Saenko", "Kate", ""]]}, {"id": "2006.03226", "submitter": "Yujie Wu", "authors": "Yujie Wu, Rong Zhao, Jun Zhu, Feng Chen, Mingkun Xu, Guoqi Li, Sen\n  Song, Lei Deng, Guanrui Wang, Hao Zheng, Jing Pei, Youhui Zhang, Mingguo\n  Zhao, and Luping Shi", "title": "Brain-inspired global-local learning incorporated with neuromorphic\n  computing", "comments": "5 figures, 6 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Two main routes of learning methods exist at present including error-driven\nglobal learning and neuroscience-oriented local learning. Integrating them into\none network may provide complementary learning capabilities for versatile\nlearning scenarios. At the same time, neuromorphic computing holds great\npromise, but still needs plenty of useful algorithms and algorithm-hardware\nco-designs for exploiting the advantages. Here, we report a neuromorphic hybrid\nlearning model by introducing a brain-inspired meta-learning paradigm and a\ndifferentiable spiking model incorporating neuronal dynamics and synaptic\nplasticity. It can meta-learn local plasticity and receive top-down supervision\ninformation for multiscale synergic learning. We demonstrate the advantages of\nthis model in multiple different tasks, including few-shot learning, continual\nlearning, and fault-tolerance learning in neuromorphic vision sensors. It\nachieves significantly higher performance than single-learning methods, and\nshows promise in empowering neuromorphic applications revolution. We further\nimplemented the hybrid model in the Tianjic neuromorphic platform by exploiting\nalgorithm-hardware co-designs and proved that the model can fully utilize\nneuromorphic many-core architecture to develop hybrid computation paradigm.\n", "versions": [{"version": "v1", "created": "Fri, 5 Jun 2020 04:24:19 GMT"}, {"version": "v2", "created": "Thu, 3 Sep 2020 12:01:40 GMT"}, {"version": "v3", "created": "Tue, 22 Jun 2021 01:15:53 GMT"}], "update_date": "2021-06-23", "authors_parsed": [["Wu", "Yujie", ""], ["Zhao", "Rong", ""], ["Zhu", "Jun", ""], ["Chen", "Feng", ""], ["Xu", "Mingkun", ""], ["Li", "Guoqi", ""], ["Song", "Sen", ""], ["Deng", "Lei", ""], ["Wang", "Guanrui", ""], ["Zheng", "Hao", ""], ["Pei", "Jing", ""], ["Zhang", "Youhui", ""], ["Zhao", "Mingguo", ""], ["Shi", "Luping", ""]]}, {"id": "2006.03280", "submitter": "Fran\\c{c}ois Schwarzentruber", "authors": "Arthur Queffelec and Ocan Sankur and Fran\\c{c}ois Schwarzentruber", "title": "Conflict-Based Search for Connected Multi-Agent Path Finding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study a variant of the multi-agent path finding problem (MAPF) in which\nagents are required to remain connected to each other and to a designated base.\nThis problem has applications in search and rescue missions where the entire\nexecution must be monitored by a human operator. We re-visit the conflict-based\nsearch algorithm known for MAPF, and define a variant where conflicts arise\nfrom disconnections rather than collisions. We study optimizations, and give\nexperimental results in which we compare our algorithms with the literature.\n", "versions": [{"version": "v1", "created": "Fri, 5 Jun 2020 08:02:36 GMT"}], "update_date": "2020-06-08", "authors_parsed": [["Queffelec", "Arthur", ""], ["Sankur", "Ocan", ""], ["Schwarzentruber", "Fran\u00e7ois", ""]]}, {"id": "2006.03312", "submitter": "Rapha\\\"el Dang-Nhu", "authors": "Rapha\\\"el Dang-Nhu", "title": "PLANS: Robust Program Learning from Neurally Inferred Specifications", "comments": "16 pages, 6 figures, 5 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent years have seen the rise of statistical program learning based on\nneural models as an alternative to traditional rule-based systems for\nprogramming by example. Rule-based approaches offer correctness guarantees in\nan unsupervised way as they inherently capture logical rules, while neural\nmodels are more realistically scalable to raw, high-dimensional input, and\nprovide resistance to noisy I/O specifications. We introduce PLANS (Program\nLeArning from Neurally inferred Specifications), a hybrid model for program\nsynthesis from visual observations that gets the best of both worlds, relying\non (i) a neural architecture trained to extract abstract, high-level\ninformation from each raw individual input (ii) a rule-based system using the\nextracted information as I/O specifications to synthesize a program capturing\nthe different observations. In order to address the key challenge of making\nPLANS resistant to noise in the network's output, we introduce a filtering\nheuristic for I/O specifications based on selective classification techniques.\nWe obtain state-of-the-art performance at program synthesis from diverse\ndemonstration videos in the Karel and ViZDoom environments, while requiring no\nground-truth program for training. We make our implementation available at\ngithub.com/rdang-nhu/PLANS.\n", "versions": [{"version": "v1", "created": "Fri, 5 Jun 2020 08:51:34 GMT"}], "update_date": "2020-06-08", "authors_parsed": [["Dang-Nhu", "Rapha\u00ebl", ""]]}, {"id": "2006.03357", "submitter": "Michael Cohen", "authors": "Michael K. Cohen and Elliot Catt and Marcus Hutter", "title": "Curiosity Killed or Incapacitated the Cat and the Asymptotically Optimal\n  Agent", "comments": "13 pages, with 5 page appendix; 3 figures", "journal-ref": "Journal of Selected Areas in Information Theory 2 (2021)", "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learners are agents that learn to pick actions that lead to\nhigh reward. Ideally, the value of a reinforcement learner's policy approaches\noptimality--where the optimal informed policy is the one which maximizes\nreward. Unfortunately, we show that if an agent is guaranteed to be\n\"asymptotically optimal\" in any (stochastically computable) environment, then\nsubject to an assumption about the true environment, this agent will be either\n\"destroyed\" or \"incapacitated\" with probability 1. Much work in reinforcement\nlearning uses an ergodicity assumption to avoid this problem. Often, doing\ntheoretical research under simplifying assumptions prepares us to provide\npractical solutions even in the absence of those assumptions, but the\nergodicity assumption in reinforcement learning may have led us entirely astray\nin preparing safe and effective exploration strategies for agents in dangerous\nenvironments. Rather than assuming away the problem, we present an agent,\nMentee, with the modest guarantee of approaching the performance of a mentor,\ndoing safe exploration instead of reckless exploration. Critically, Mentee's\nexploration probability depends on the expected information gain from\nexploring. In a simple non-ergodic environment with a weak mentor, we find\nMentee outperforms existing asymptotically optimal agents and its mentor.\n", "versions": [{"version": "v1", "created": "Fri, 5 Jun 2020 10:42:29 GMT"}, {"version": "v2", "created": "Wed, 26 May 2021 15:55:28 GMT"}], "update_date": "2021-05-27", "authors_parsed": [["Cohen", "Michael K.", ""], ["Catt", "Elliot", ""], ["Hutter", "Marcus", ""]]}, {"id": "2006.03363", "submitter": "Amjad Ibrahim", "authors": "Amjad Ibrahim and Alexander Pretschner", "title": "From Checking to Inference: Actual Causality Computations as\n  Optimization Problems", "comments": "ATVA 2020 The 18th International Symposium on Automated Technology\n  for Verification and Analysis", "journal-ref": null, "doi": "10.1007/978-3-030-59152-6_19", "report-no": null, "categories": "cs.AI cs.CY cs.DS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Actual causality is increasingly well understood. Recent formal approaches,\nproposed by Halpern and Pearl, have made this concept mature enough to be\namenable to automated reasoning. Actual causality is especially vital for\nbuilding accountable, explainable systems. Among other reasons, causality\nreasoning is computationally hard due to the requirements of counterfactuality\nand the minimality of causes. Previous approaches presented either inefficient\nor restricted, and domain-specific, solutions to the problem of automating\ncausality reasoning. In this paper, we present a novel approach to formulate\ndifferent notions of causal reasoning, over binary acyclic models, as\noptimization problems, based on quantifiable notions within counterfactual\ncomputations. We contribute and compare two compact, non-trivial, and sound\ninteger linear programming (ILP) and Maximum Satisfiability (MaxSAT) encodings\nto check causality. Given a candidate cause, both approaches identify what a\nminimal cause is. Also, we present an ILP encoding to infer causality without\nrequiring a candidate cause. We show that both notions are efficiently\nautomated. Using models with more than $8000$ variables, checking is computed\nin a matter of seconds, with MaxSAT outperforming ILP in many cases. In\ncontrast, inference is computed in a matter of minutes.\n", "versions": [{"version": "v1", "created": "Fri, 5 Jun 2020 10:56:52 GMT"}, {"version": "v2", "created": "Mon, 6 Jul 2020 11:28:01 GMT"}], "update_date": "2020-10-16", "authors_parsed": [["Ibrahim", "Amjad", ""], ["Pretschner", "Alexander", ""]]}, {"id": "2006.03432", "submitter": "Ondrej Kuzelka", "authors": "Ondrej Kuzelka", "title": "Lifted Inference in 2-Variable Markov Logic Networks with Function and\n  Cardinality Constraints Using Discrete Fourier Transform", "comments": "arXiv admin note: text overlap with arXiv:2002.10259, This version:\n  fixed a typo in Section 3.1", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we show that inference in 2-variable Markov logic networks\n(MLNs) with cardinality and function constraints is domain-liftable. To obtain\nthis result we use existing domain-lifted algorithms for weighted first-order\nmodel counting (Van den Broeck et al, KR 2014) together with discrete Fourier\ntransform of certain distributions associated to MLNs.\n", "versions": [{"version": "v1", "created": "Thu, 4 Jun 2020 11:07:54 GMT"}, {"version": "v2", "created": "Thu, 16 Jul 2020 13:15:21 GMT"}], "update_date": "2020-07-17", "authors_parsed": [["Kuzelka", "Ondrej", ""]]}, {"id": "2006.03434", "submitter": "Mathias Unberath", "authors": "Mathias Unberath and Kimia Ghobadi and Scott Levin and Jeremiah Hinson\n  and Gregory D Hager", "title": "Artificial Intelligence-based Clinical Decision Support for COVID-19 --\n  Where Art Thou?", "comments": "Invited perspective piece on AI in the fight against COVID-19 to\n  appear in Advanced Intelligent Systems", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The COVID-19 crisis has brought about new clinical questions, new workflows,\nand accelerated distributed healthcare needs. While artificial intelligence\n(AI)-based clinical decision support seemed to have matured, the application of\nAI-based tools for COVID-19 has been limited to date. In this perspective\npiece, we identify opportunities and requirements for AI-based clinical\ndecision support systems and highlight challenges that impact \"AI readiness\"\nfor rapidly emergent healthcare challenges.\n", "versions": [{"version": "v1", "created": "Fri, 5 Jun 2020 13:34:47 GMT"}], "update_date": "2020-06-08", "authors_parsed": [["Unberath", "Mathias", ""], ["Ghobadi", "Kimia", ""], ["Levin", "Scott", ""], ["Hinson", "Jeremiah", ""], ["Hager", "Gregory D", ""]]}, {"id": "2006.03472", "submitter": "Emile van Krieken", "authors": "Emile van Krieken, Erman Acar, Frank van Harmelen", "title": "Analyzing Differentiable Fuzzy Implications", "comments": "10 pages, 10 figures, accepted to 17th International Conference on\n  Principles of Knowledge Representation and Reasoning (KR 2020). arXiv admin\n  note: substantial text overlap with arXiv:2002.06100", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Combining symbolic and neural approaches has gained considerable attention in\nthe AI community, as it is often argued that the strengths and weaknesses of\nthese approaches are complementary. One such trend in the literature are weakly\nsupervised learning techniques that employ operators from fuzzy logics. In\nparticular, they use prior background knowledge described in such logics to\nhelp the training of a neural network from unlabeled and noisy data. By\ninterpreting logical symbols using neural networks (or grounding them), this\nbackground knowledge can be added to regular loss functions, hence making\nreasoning a part of learning.\n  In this paper, we investigate how implications from the fuzzy logic\nliterature behave in a differentiable setting. In such a setting, we analyze\nthe differences between the formal properties of these fuzzy implications. It\nturns out that various fuzzy implications, including some of the most\nwell-known, are highly unsuitable for use in a differentiable learning setting.\nA further finding shows a strong imbalance between gradients driven by the\nantecedent and the consequent of the implication. Furthermore, we introduce a\nnew family of fuzzy implications (called sigmoidal implications) to tackle this\nphenomenon. Finally, we empirically show that it is possible to use\nDifferentiable Fuzzy Logics for semi-supervised learning, and show that\nsigmoidal implications outperform other choices of fuzzy implications.\n", "versions": [{"version": "v1", "created": "Thu, 4 Jun 2020 15:34:37 GMT"}], "update_date": "2020-06-08", "authors_parsed": [["van Krieken", "Emile", ""], ["Acar", "Erman", ""], ["van Harmelen", "Frank", ""]]}, {"id": "2006.03533", "submitter": "Seokhwan Kim", "authors": "Seokhwan Kim, Mihail Eric, Karthik Gopalakrishnan, Behnam Hedayatnia,\n  Yang Liu, Dilek Hakkani-Tur", "title": "Beyond Domain APIs: Task-oriented Conversational Modeling with\n  Unstructured Knowledge Access", "comments": "To be presented at SIGDIAL 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most prior work on task-oriented dialogue systems are restricted to a limited\ncoverage of domain APIs, while users oftentimes have domain related requests\nthat are not covered by the APIs. In this paper, we propose to expand coverage\nof task-oriented dialogue systems by incorporating external unstructured\nknowledge sources. We define three sub-tasks: knowledge-seeking turn detection,\nknowledge selection, and knowledge-grounded response generation, which can be\nmodeled individually or jointly. We introduce an augmented version of MultiWOZ\n2.1, which includes new out-of-API-coverage turns and responses grounded on\nexternal knowledge sources. We present baselines for each sub-task using both\nconventional and neural approaches. Our experimental results demonstrate the\nneed for further research in this direction to enable more informative\nconversational systems.\n", "versions": [{"version": "v1", "created": "Fri, 5 Jun 2020 16:12:18 GMT"}], "update_date": "2020-06-08", "authors_parsed": [["Kim", "Seokhwan", ""], ["Eric", "Mihail", ""], ["Gopalakrishnan", "Karthik", ""], ["Hedayatnia", "Behnam", ""], ["Liu", "Yang", ""], ["Hakkani-Tur", "Dilek", ""]]}, {"id": "2006.03553", "submitter": "Lucas Cassano Dr.", "authors": "Lucas Cassano and Ali H. Sayed", "title": "Logical Team Q-learning: An approach towards factored policies in\n  cooperative MARL", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the challenge of learning factored policies in cooperative MARL\nscenarios. In particular, we consider the situation in which a team of agents\ncollaborates to optimize a common cost. The goal is to obtain factored policies\nthat determine the individual behavior of each agent so that the resulting\njoint policy is optimal. The main contribution of this work is the introduction\nof Logical Team Q-learning (LTQL). LTQL does not rely on assumptions about the\nenvironment and hence is generally applicable to any collaborative MARL\nscenario. We derive LTQL as a stochastic approximation to a dynamic programming\nmethod we introduce in this work. We conclude the paper by providing\nexperiments (both in the tabular and deep settings) that illustrate the claims.\n", "versions": [{"version": "v1", "created": "Fri, 5 Jun 2020 17:02:36 GMT"}, {"version": "v2", "created": "Sun, 28 Mar 2021 19:05:57 GMT"}], "update_date": "2021-04-28", "authors_parsed": [["Cassano", "Lucas", ""], ["Sayed", "Ali H.", ""]]}, {"id": "2006.03589", "submitter": "Gr\\'egoire Montavon", "authors": "Thomas Schnake, Oliver Eberle, Jonas Lederer, Shinichi Nakajima,\n  Kristof T. Sch\\\"utt, Klaus-Robert M\\\"uller, Gr\\'egoire Montavon", "title": "Higher-Order Explanations of Graph Neural Networks via Relevant Walks", "comments": "14 pages + 6 pages supplement", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph Neural Networks (GNNs) are a popular approach for predicting graph\nstructured data. As GNNs tightly entangle the input graph into the neural\nnetwork structure, common explainable AI approaches are not applicable. To a\nlarge extent, GNNs have remained black-boxes for the user so far. In this\npaper, we show that GNNs can in fact be naturally explained using higher-order\nexpansions, i.e. by identifying groups of edges that jointly contribute to the\nprediction. Practically, we find that such explanations can be extracted using\na nested attribution scheme, where existing techniques such as layer-wise\nrelevance propagation (LRP) can be applied at each step. The output is a\ncollection of walks into the input graph that are relevant for the prediction.\nOur novel explanation method, which we denote by GNN-LRP, is applicable to a\nbroad range of graph neural networks and lets us extract practically relevant\ninsights on sentiment analysis of text data, structure-property relationships\nin quantum chemistry, and image classification.\n", "versions": [{"version": "v1", "created": "Fri, 5 Jun 2020 17:59:14 GMT"}, {"version": "v2", "created": "Fri, 12 Jun 2020 15:49:11 GMT"}, {"version": "v3", "created": "Fri, 27 Nov 2020 04:10:00 GMT"}], "update_date": "2020-11-30", "authors_parsed": [["Schnake", "Thomas", ""], ["Eberle", "Oliver", ""], ["Lederer", "Jonas", ""], ["Nakajima", "Shinichi", ""], ["Sch\u00fctt", "Kristof T.", ""], ["M\u00fcller", "Klaus-Robert", ""], ["Montavon", "Gr\u00e9goire", ""]]}, {"id": "2006.03626", "submitter": "Joseph Scott", "authors": "Joseph Scott, Maysum Panju, and Vijay Ganesh", "title": "LGML: Logic Guided Machine Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce Logic Guided Machine Learning (LGML), a novel approach that\nsymbiotically combines machine learning (ML) and logic solvers with the goal of\nlearning mathematical functions from data. LGML consists of two phases, namely\na learning-phase and a logic-phase with a corrective feedback loop, such that,\nthe learning-phase learns symbolic expressions from input data, and the\nlogic-phase cross verifies the consistency of the learned expression with known\nauxiliary truths. If inconsistent, the logic-phase feeds back \"counterexamples\"\nto the learning-phase. This process is repeated until the learned expression is\nconsistent with auxiliary truth. Using LGML, we were able to learn expressions\nthat correspond to the Pythagorean theorem and the sine function, with several\norders of magnitude improvements in data efficiency compared to an approach\nbased on an out-of-the-box multi-layered perceptron (MLP).\n", "versions": [{"version": "v1", "created": "Fri, 5 Jun 2020 18:42:08 GMT"}, {"version": "v2", "created": "Mon, 29 Mar 2021 19:27:23 GMT"}], "update_date": "2021-03-31", "authors_parsed": [["Scott", "Joseph", ""], ["Panju", "Maysum", ""], ["Ganesh", "Vijay", ""]]}, {"id": "2006.03647", "submitter": "Tatsuya Matsushima", "authors": "Tatsuya Matsushima, Hiroki Furuta, Yutaka Matsuo, Ofir Nachum,\n  Shixiang Gu", "title": "Deployment-Efficient Reinforcement Learning via Model-Based Offline\n  Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most reinforcement learning (RL) algorithms assume online access to the\nenvironment, in which one may readily interleave updates to the policy with\nexperience collection using that policy. However, in many real-world\napplications such as health, education, dialogue agents, and robotics, the cost\nor potential risk of deploying a new data-collection policy is high, to the\npoint that it can become prohibitive to update the data-collection policy more\nthan a few times during learning. With this view, we propose a novel concept of\ndeployment efficiency, measuring the number of distinct data-collection\npolicies that are used during policy learning. We observe that na\\\"{i}vely\napplying existing model-free offline RL algorithms recursively does not lead to\na practical deployment-efficient and sample-efficient algorithm. We propose a\nnovel model-based algorithm, Behavior-Regularized Model-ENsemble (BREMEN) that\ncan effectively optimize a policy offline using 10-20 times fewer data than\nprior works. Furthermore, the recursive application of BREMEN is able to\nachieve impressive deployment efficiency while maintaining the same or better\nsample efficiency, learning successful policies from scratch on simulated\nrobotic environments with only 5-10 deployments, compared to typical values of\nhundreds to millions in standard RL baselines. Codes and pre-trained models are\navailable at https://github.com/matsuolab/BREMEN .\n", "versions": [{"version": "v1", "created": "Fri, 5 Jun 2020 19:33:19 GMT"}, {"version": "v2", "created": "Tue, 23 Jun 2020 16:54:09 GMT"}], "update_date": "2020-06-24", "authors_parsed": [["Matsushima", "Tatsuya", ""], ["Furuta", "Hiroki", ""], ["Matsuo", "Yutaka", ""], ["Nachum", "Ofir", ""], ["Gu", "Shixiang", ""]]}, {"id": "2006.03662", "submitter": "Sam Ritter", "authors": "Sam Ritter, Ryan Faulkner, Laurent Sartran, Adam Santoro, Matt\n  Botvinick, David Raposo", "title": "Rapid Task-Solving in Novel Environments", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose the challenge of rapid task-solving in novel environments (RTS),\nwherein an agent must solve a series of tasks as rapidly as possible in an\nunfamiliar environment. An effective RTS agent must balance between exploring\nthe unfamiliar environment and solving its current task, all while building a\nmodel of the new environment over which it can plan when faced with later\ntasks. While modern deep RL agents exhibit some of these abilities in\nisolation, none are suitable for the full RTS challenge. To enable progress\ntoward RTS, we introduce two challenge domains: (1) a minimal RTS challenge\ncalled the Memory&Planning Game and (2) One-Shot StreetLearn Navigation, which\nintroduces scale and complexity from real-world data. We demonstrate that\nstate-of-the-art deep RL agents fail at RTS in both domains, and that this\nfailure is due to an inability to plan over gathered knowledge. We develop\nEpisodic Planning Networks (EPNs) and show that deep-RL agents with EPNs excel\nat RTS, outperforming the nearest baseline by factors of 2-3 and learning to\nnavigate held-out StreetLearn maps within a single episode. We show that EPNs\nlearn to execute a value iteration-like planning algorithm and that they\ngeneralize to situations beyond their training experience. algorithm and that\nthey generalize to situations beyond their training experience.\n", "versions": [{"version": "v1", "created": "Fri, 5 Jun 2020 20:09:20 GMT"}, {"version": "v2", "created": "Wed, 24 Mar 2021 16:28:57 GMT"}, {"version": "v3", "created": "Mon, 19 Apr 2021 18:00:46 GMT"}], "update_date": "2021-04-21", "authors_parsed": [["Ritter", "Sam", ""], ["Faulkner", "Ryan", ""], ["Sartran", "Laurent", ""], ["Santoro", "Adam", ""], ["Botvinick", "Matt", ""], ["Raposo", "David", ""]]}, {"id": "2006.03713", "submitter": "Ziyao Zhang Mr.", "authors": "Ziyao Zhang and Liang Ma and Kin K. Leung and Konstantinos Poularakis\n  and Mudhakar Srivatsa", "title": "State Action Separable Reinforcement Learning", "comments": "16 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement Learning (RL) based methods have seen their paramount successes\nin solving serial decision-making and control problems in recent years. For\nconventional RL formulations, Markov Decision Process (MDP) and\nstate-action-value function are the basis for the problem modeling and policy\nevaluation. However, several challenging issues still remain. Among most cited\nissues, the enormity of state/action space is an important factor that causes\ninefficiency in accurately approximating the state-action-value function. We\nobserve that although actions directly define the agents' behaviors, for many\nproblems the next state after a state transition matters more than the action\ntaken, in determining the return of such a state transition. In this regard, we\npropose a new learning paradigm, State Action Separable Reinforcement Learning\n(sasRL), wherein the action space is decoupled from the value function learning\nprocess for higher efficiency. Then, a light-weight transition model is learned\nto assist the agent to determine the action that triggers the associated state\ntransition. In addition, our convergence analysis reveals that under certain\nconditions, the convergence time of sasRL is $O(T^{1/k})$, where $T$ is the\nconvergence time for updating the value function in the MDP-based formulation\nand $k$ is a weighting factor. Experiments on several gaming scenarios show\nthat sasRL outperforms state-of-the-art MDP-based RL algorithms by up to\n$75\\%$.\n", "versions": [{"version": "v1", "created": "Fri, 5 Jun 2020 22:02:57 GMT"}], "update_date": "2020-06-09", "authors_parsed": [["Zhang", "Ziyao", ""], ["Ma", "Liang", ""], ["Leung", "Kin K.", ""], ["Poularakis", "Konstantinos", ""], ["Srivatsa", "Mudhakar", ""]]}, {"id": "2006.03810", "submitter": "Deepan Das", "authors": "Deepan Das, Haley Massa, Abhimanyu Kulkarni, Theodoros Rekatsinas", "title": "An Empirical Analysis of the Impact of Data Augmentation on Knowledge\n  Distillation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Generalization Performance of Deep Learning models trained using Empirical\nRisk Minimization can be improved significantly by using Data Augmentation\nstrategies such as simple transformations, or using Mixed Samples. We attempt\nto empirically analyze the impact of such strategies on the transfer of\ngeneralization between teacher and student models in a distillation setup. We\nobserve that if a teacher is trained using any of the mixed sample augmentation\nstrategies, such as MixUp or CutMix, the student model distilled from it is\nimpaired in its generalization capabilities. We hypothesize that such\nstrategies limit a model's capability to learn example-specific features,\nleading to a loss in quality of the supervision signal during distillation. We\npresent a novel Class-Discrimination metric to quantitatively measure this\ndichotomy in performance and link it to the discriminative capacity induced by\nthe different strategies on a network's latent space.\n", "versions": [{"version": "v1", "created": "Sat, 6 Jun 2020 08:20:48 GMT"}, {"version": "v2", "created": "Tue, 9 Jun 2020 13:01:00 GMT"}], "update_date": "2020-06-11", "authors_parsed": [["Das", "Deepan", ""], ["Massa", "Haley", ""], ["Kulkarni", "Abhimanyu", ""], ["Rekatsinas", "Theodoros", ""]]}, {"id": "2006.03857", "submitter": "Yu Yang", "authors": "Yu Yang, Zhiyuan Wen, Jiannong Cao, Jiaxing Shen, Hongzhi Yin and\n  Xiaofang Zhou", "title": "EPARS: Early Prediction of At-risk Students with Online and Offline\n  Learning Behaviors", "comments": "To be published in DASFAA 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Early prediction of students at risk (STAR) is an effective and significant\nmeans to provide timely intervention for dropout and suicide. Existing works\nmostly rely on either online or offline learning behaviors which are not\ncomprehensive enough to capture the whole learning processes and lead to\nunsatisfying prediction performance. We propose a novel algorithm (EPARS) that\ncould early predict STAR in a semester by modeling online and offline learning\nbehaviors. The online behaviors come from the log of activities when students\nuse the online learning management system. The offline behaviors derive from\nthe check-in records of the library. Our main observations are two folds.\nSignificantly different from good students, STAR barely have regular and clear\nstudy routines. We devised a multi-scale bag-of-regularity method to extract\nthe regularity of learning behaviors that is robust to sparse data. Second,\nfriends of STAR are more likely to be at risk. We constructed a co-occurrence\nnetwork to approximate the underlying social network and encode the social\nhomophily as features through network embedding. To validate the proposed\nalgorithm, extensive experiments have been conducted among an Asian university\nwith 15,503 undergraduate students. The results indicate EPARS outperforms\nbaselines by 14.62% ~ 38.22% in predicting STAR.\n", "versions": [{"version": "v1", "created": "Sat, 6 Jun 2020 12:56:26 GMT"}], "update_date": "2020-06-09", "authors_parsed": [["Yang", "Yu", ""], ["Wen", "Zhiyuan", ""], ["Cao", "Jiannong", ""], ["Shen", "Jiaxing", ""], ["Yin", "Hongzhi", ""], ["Zhou", "Xiaofang", ""]]}, {"id": "2006.03950", "submitter": "Aylin Caliskan", "authors": "Autumn Toney and Aylin Caliskan", "title": "ValNorm Quantifies Semantics to Reveal Consistent Valence Biases Across\n  Languages and Over Centuries", "comments": "15 pages, 3 figures, 12 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Word embeddings, which are numeric dictionaries for machines to process\nlanguage, learn implicit biases from linguistic regularities captured by word\nco-occurrence information. As a result, statistical methods can detect and\nquantify social biases along with widely shared associations present in the\ncorpus the word embeddings are trained on. By extending methods that quantify\nhuman-like biases in word embeddings, we introduce ValNorm, a novel word\nembedding intrinsic evaluation task and a method to measure the affective\nmeaning of valence (pleasantness/unpleasantness) in words, with high accuracy.\nThe correlation between human judgment scores of valence for 399 words\ncollected to establish pleasantness norms in English and ValNorm scores is\nr=0.88. These 399 words, obtained from the social psychology literature, are\nused to measure biases that are non-discriminatory among social groups. We\nhypothesize that the valence associations for this set of words (in various\ntranslations) are widely shared across languages and consistent over time. We\nestimate valence associations of these words using word embeddings from seven\nlanguages representing various language structures and from historical text\ncovering 200 years. Our method achieves consistently high accuracy, suggesting\nthat the valence associations for these words are widely shared. In contrast,\nwe measure gender stereotypes using the same set of word embeddings and find\nthat social biases vary across languages. Our results signal that valence\nassociations of this word set represent widely shared associations of the last\ntwo centuries. Consequently, ValNorm can be used to evaluate valence norms and\nthe accuracy of word embeddings especially when measuring biases.\n", "versions": [{"version": "v1", "created": "Sat, 6 Jun 2020 19:29:36 GMT"}, {"version": "v2", "created": "Thu, 18 Jun 2020 23:59:07 GMT"}, {"version": "v3", "created": "Wed, 11 Nov 2020 04:16:21 GMT"}], "update_date": "2020-11-12", "authors_parsed": [["Toney", "Autumn", ""], ["Caliskan", "Aylin", ""]]}, {"id": "2006.03955", "submitter": "Aylin Caliskan", "authors": "Wei Guo and Aylin Caliskan", "title": "Detecting Emergent Intersectional Biases: Contextualized Word Embeddings\n  Contain a Distribution of Human-like Biases", "comments": "19 pages, 2 figures, 4 tables", "journal-ref": "AAAI/ACM Conference on Artificial Intelligence, Ethics, and\n  Society 2021", "doi": "10.1145/3461702.3462536", "report-no": null, "categories": "cs.CY cs.AI cs.CL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  With the starting point that implicit human biases are reflected in the\nstatistical regularities of language, it is possible to measure biases in\nEnglish static word embeddings. State-of-the-art neural language models\ngenerate dynamic word embeddings dependent on the context in which the word\nappears. Current methods measure pre-defined social and intersectional biases\nthat appear in particular contexts defined by sentence templates. Dispensing\nwith templates, we introduce the Contextualized Embedding Association Test\n(CEAT), that can summarize the magnitude of overall bias in neural language\nmodels by incorporating a random-effects model. Experiments on social and\nintersectional biases show that CEAT finds evidence of all tested biases and\nprovides comprehensive information on the variance of effect magnitudes of the\nsame bias in different contexts. All the models trained on English corpora that\nwe study contain biased representations.\n  Furthermore, we develop two methods, Intersectional Bias Detection (IBD) and\nEmergent Intersectional Bias Detection (EIBD), to automatically identify the\nintersectional biases and emergent intersectional biases from static word\nembeddings in addition to measuring them in contextualized word embeddings. We\npresent the first algorithmic bias detection findings on how intersectional\ngroup members are strongly associated with unique emergent biases that do not\noverlap with the biases of their constituent minority identities. IBD and EIBD\nachieve high accuracy when detecting the intersectional and emergent biases of\nAfrican American females and Mexican American females. Our results indicate\nthat biases at the intersection of race and gender associated with members of\nmultiple minority groups, such as African American females and Mexican American\nfemales, have the highest magnitude across all neural language models.\n", "versions": [{"version": "v1", "created": "Sat, 6 Jun 2020 19:49:50 GMT"}, {"version": "v2", "created": "Mon, 22 Jun 2020 20:08:41 GMT"}, {"version": "v3", "created": "Mon, 6 Jul 2020 18:43:34 GMT"}, {"version": "v4", "created": "Fri, 16 Apr 2021 01:45:35 GMT"}, {"version": "v5", "created": "Wed, 19 May 2021 15:06:28 GMT"}], "update_date": "2021-05-20", "authors_parsed": [["Guo", "Wei", ""], ["Caliskan", "Aylin", ""]]}, {"id": "2006.03979", "submitter": "Caris Moses", "authors": "Caris Moses, Michael Noseworthy, Leslie Pack Kaelbling, Tom\\'as\n  Lozano-P\\'erez, and Nicholas Roy", "title": "Visual Prediction of Priors for Articulated Object Interaction", "comments": "IEEE International Conference on Robotics and Automation (ICRA) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Exploration in novel settings can be challenging without prior experience in\nsimilar domains. However, humans are able to build on prior experience quickly\nand efficiently. Children exhibit this behavior when playing with toys. For\nexample, given a toy with a yellow and blue door, a child will explore with no\nclear objective, but once they have discovered how to open the yellow door,\nthey will most likely be able to open the blue door much faster. Adults also\nexhibit this behavior when entering new spaces such as kitchens. We develop a\nmethod, Contextual Prior Prediction, which provides a means of transferring\nknowledge between interactions in similar domains through vision. We develop\nagents that exhibit exploratory behavior with increasing efficiency, by\nlearning visual features that are shared across environments, and how they\ncorrelate to actions. Our problem is formulated as a Contextual Multi-Armed\nBandit where the contexts are images, and the robot has access to a\nparameterized action space. Given a novel object, the objective is to maximize\nreward with few interactions. A domain which strongly exhibits correlations\nbetween visual features and motion is kinemetically constrained mechanisms. We\nevaluate our method on simulated prismatic and revolute joints.\n", "versions": [{"version": "v1", "created": "Sat, 6 Jun 2020 21:17:03 GMT"}], "update_date": "2020-06-09", "authors_parsed": [["Moses", "Caris", ""], ["Noseworthy", "Michael", ""], ["Kaelbling", "Leslie Pack", ""], ["Lozano-P\u00e9rez", "Tom\u00e1s", ""], ["Roy", "Nicholas", ""]]}, {"id": "2006.04001", "submitter": "Manuel Arias Chao", "authors": "Yuan Tian, Manuel Arias Chao, Chetan Kulkarni, Kai Goebel and Olga\n  Fink", "title": "Real-Time Model Calibration with Deep Reinforcement Learning", "comments": "18 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The dynamic, real-time, and accurate inference of model parameters from\nempirical data is of great importance in many scientific and engineering\ndisciplines that use computational models (such as a digital twin) for the\nanalysis and prediction of complex physical processes. However, fast and\naccurate inference for processes with large and high dimensional datasets\ncannot easily be achieved with state-of-the-art methods under noisy real-world\nconditions. The primary reason is that the inference of model parameters with\ntraditional techniques based on optimisation or sampling often suffers from\ncomputational and statistical challenges, resulting in a trade-off between\naccuracy and deployment time. In this paper, we propose a novel framework for\ninference of model parameters based on reinforcement learning. The contribution\nof the paper is twofold: 1) We reformulate the inference problem as a tracking\nproblem with the objective of learning a policy that forces the response of the\nphysics-based model to follow the observations; 2) We propose the constrained\nLyapunov-based actor-critic (CLAC) algorithm to enable the robust and accurate\ninference of physics-based model parameters in real time under noisy real-world\nconditions. The proposed methodology is demonstrated and evaluated on two\nmodel-based diagnostics test cases utilizing two different physics-based models\nof turbofan engines. The performance of the methodology is compared to that of\ntwo alternative approaches: a state update method (unscented Kalman filter) and\na supervised end-to-end mapping with deep neural networks. The experimental\nresults demonstrate that the proposed methodology outperforms all other tested\nmethods in terms of speed and robustness, with high inference accuracy.\n", "versions": [{"version": "v1", "created": "Sun, 7 Jun 2020 00:11:42 GMT"}, {"version": "v2", "created": "Tue, 9 Jun 2020 12:25:49 GMT"}], "update_date": "2020-06-11", "authors_parsed": [["Tian", "Yuan", ""], ["Chao", "Manuel Arias", ""], ["Kulkarni", "Chetan", ""], ["Goebel", "Kai", ""], ["Fink", "Olga", ""]]}, {"id": "2006.04003", "submitter": "Grace McFassel", "authors": "Grace McFassel, Dylan A. Shell", "title": "Every Action Based Sensor", "comments": "16 pages, 7 figures, WAFR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In studying robots and planning problems, a basic question is what is the\nminimal information a robot must obtain to guarantee task completion. Erdmann's\ntheory of action-based sensors is a classical approach to characterizing\nfundamental information requirements. That approach uses a plan to derive a\ntype of virtual sensor which prescribes actions that make progress toward a\ngoal. We show that the established theory is incomplete: the previous method\nfor obtaining such sensors, using backchained plans, overlooks some sensors.\nFurthermore, there are plans, that are guaranteed to achieve goals, where the\nexisting methods are unable to provide any action-based sensor. We identify the\nunderlying feature common to all such plans. Then, we show how to produce\naction-based sensors even for plans where the existing treatment is inadequate,\nalthough for these cases they have no single canonical sensor. Consequently,\nthe approach is generalized to produce sets of sensors. Finally, we show also\nthat this is a complete characterization of action-based sensors for planning\nproblems and discuss how an action-based sensor translates into the traditional\nconception of a sensor.\n", "versions": [{"version": "v1", "created": "Sun, 7 Jun 2020 00:30:54 GMT"}], "update_date": "2020-06-09", "authors_parsed": [["McFassel", "Grace", ""], ["Shell", "Dylan A.", ""]]}, {"id": "2006.04027", "submitter": "Qiang Gao", "authors": "Qiang Gao, Zhipeng Luo, Diego Klabjan", "title": "Efficient Architecture Search for Continual Learning", "comments": "12 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Continual learning with neural networks is an important learning framework in\nAI that aims to learn a sequence of tasks well. However, it is often confronted\nwith three challenges: (1) overcome the catastrophic forgetting problem, (2)\nadapt the current network to new tasks, and meanwhile (3) control its model\ncomplexity. To reach these goals, we propose a novel approach named as\nContinual Learning with Efficient Architecture Search, or CLEAS in short. CLEAS\nworks closely with neural architecture search (NAS) which leverages\nreinforcement learning techniques to search for the best neural architecture\nthat fits a new task. In particular, we design a neuron-level NAS controller\nthat decides which old neurons from previous tasks should be reused (knowledge\ntransfer), and which new neurons should be added (to learn new knowledge). Such\na fine-grained controller allows one to find a very concise architecture that\ncan fit each new task well. Meanwhile, since we do not alter the weights of the\nreused neurons, we perfectly memorize the knowledge learned from previous\ntasks. We evaluate CLEAS on numerous sequential classification tasks, and the\nresults demonstrate that CLEAS outperforms other state-of-the-art alternative\nmethods, achieving higher classification accuracy while using simpler neural\narchitectures.\n", "versions": [{"version": "v1", "created": "Sun, 7 Jun 2020 02:59:29 GMT"}, {"version": "v2", "created": "Tue, 9 Jun 2020 04:54:11 GMT"}], "update_date": "2020-06-11", "authors_parsed": [["Gao", "Qiang", ""], ["Luo", "Zhipeng", ""], ["Klabjan", "Diego", ""]]}, {"id": "2006.04037", "submitter": "Hardik Meisheri", "authors": "Nazneen N Sultana, Hardik Meisheri, Vinita Baniwal, Somjit Nath,\n  Balaraman Ravindran, Harshad Khadilkar", "title": "Reinforcement Learning for Multi-Product Multi-Node Inventory Management\n  in Supply Chains", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  This paper describes the application of reinforcement learning (RL) to\nmulti-product inventory management in supply chains. The problem description\nand solution are both adapted from a real-world business solution. The novelty\nof this problem with respect to supply chain literature is (i) we consider\nconcurrent inventory management of a large number (50 to 1000) of products with\nshared capacity, (ii) we consider a multi-node supply chain consisting of a\nwarehouse which supplies three stores, (iii) the warehouse, stores, and\ntransportation from warehouse to stores have finite capacities, (iv) warehouse\nand store replenishment happen at different time scales and with realistic time\nlags, and (v) demand for products at the stores is stochastic. We describe a\nnovel formulation in a multi-agent (hierarchical) reinforcement learning\nframework that can be used for parallelised decision-making, and use the\nadvantage actor critic (A2C) algorithm with quantised action spaces to solve\nthe problem. Experiments show that the proposed approach is able to handle a\nmulti-objective reward comprised of maximising product sales and minimising\nwastage of perishable products.\n", "versions": [{"version": "v1", "created": "Sun, 7 Jun 2020 04:02:59 GMT"}], "update_date": "2020-06-09", "authors_parsed": [["Sultana", "Nazneen N", ""], ["Meisheri", "Hardik", ""], ["Baniwal", "Vinita", ""], ["Nath", "Somjit", ""], ["Ravindran", "Balaraman", ""], ["Khadilkar", "Harshad", ""]]}, {"id": "2006.04042", "submitter": "Sayyed Ali Hossayni", "authors": "Sayyed-Ali Hossayni, Mohammad-R Akbarzadeh-T, Diego Reforgiato\n  Recupero, Aldo Gangemi, Esteve Del Acebo, Josep Llu\\'is de la Rosa i Esteva", "title": "An Algorithm for Fuzzification of WordNets, Supported by a Mathematical\n  Proof", "comments": "6 pages, without figures, theoretical", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  WordNet-like Lexical Databases (WLDs) group English words into sets of\nsynonyms called \"synsets.\" Although the standard WLDs are being used in many\nsuccessful Text-Mining applications, they have the limitation that word-senses\nare considered to represent the meaning associated to their corresponding\nsynsets, to the same degree, which is not generally true. In order to overcome\nthis limitation, several fuzzy versions of synsets have been proposed. A common\ntrait of these studies is that, to the best of our knowledge, they do not aim\nto produce fuzzified versions of the existing WLD's, but build new WLDs from\nscratch, which has limited the attention received from the Text-Mining\ncommunity, many of whose resources and applications are based on the existing\nWLDs. In this study, we present an algorithm for constructing fuzzy versions of\nWLDs of any language, given a corpus of documents and a word-sense\ndisambiguation (WSD) system for that language. Then, using the\nOpen-American-National-Corpus and UKB WSD as algorithm inputs, we construct and\npublish online the fuzzified version of English WordNet (FWN). We also propose\na theoretical (mathematical) proof of the validity of its results.\n", "versions": [{"version": "v1", "created": "Sun, 7 Jun 2020 04:47:40 GMT"}], "update_date": "2020-06-09", "authors_parsed": [["Hossayni", "Sayyed-Ali", ""], ["Akbarzadeh-T", "Mohammad-R", ""], ["Recupero", "Diego Reforgiato", ""], ["Gangemi", "Aldo", ""], ["Del Acebo", "Esteve", ""], ["Esteva", "Josep Llu\u00eds de la Rosa i", ""]]}, {"id": "2006.04061", "submitter": "Kwei-Herng Lai", "authors": "Kwei-Herng Lai, Daochen Zha, Yuening Li, Xia Hu", "title": "Dual Policy Distillation", "comments": "Accepeted by IJCAI'20", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Policy distillation, which transfers a teacher policy to a student policy has\nachieved great success in challenging tasks of deep reinforcement learning.\nThis teacher-student framework requires a well-trained teacher model which is\ncomputationally expensive. Moreover, the performance of the student model could\nbe limited by the teacher model if the teacher model is not optimal. In the\nlight of collaborative learning, we study the feasibility of involving joint\nintellectual efforts from diverse perspectives of student models. In this work,\nwe introduce dual policy distillation(DPD), a student-student framework in\nwhich two learners operate on the same environment to explore different\nperspectives of the environment and extract knowledge from each other to\nenhance their learning. The key challenge in developing this dual learning\nframework is to identify the beneficial knowledge from the peer learner for\ncontemporary learning-based reinforcement learning algorithms, since it is\nunclear whether the knowledge distilled from an imperfect and noisy peer\nlearner would be helpful. To address the challenge, we theoretically justify\nthat distilling knowledge from a peer learner will lead to policy improvement\nand propose a disadvantageous distillation strategy based on the theoretical\nresults. The conducted experiments on several continuous control tasks show\nthat the proposed framework achieves superior performance with a learning-based\nagent and function approximation without the use of expensive teacher models.\n", "versions": [{"version": "v1", "created": "Sun, 7 Jun 2020 06:49:47 GMT"}], "update_date": "2020-06-09", "authors_parsed": [["Lai", "Kwei-Herng", ""], ["Zha", "Daochen", ""], ["Li", "Yuening", ""], ["Hu", "Xia", ""]]}, {"id": "2006.04072", "submitter": "Haiyang Chen", "authors": "Haiyang Chen, Hyung Jin Chang, Andrew Howes", "title": "Implications of Human Irrationality for Reinforcement Learning", "comments": "12 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work in the behavioural sciences has begun to overturn the long-held\nbelief that human decision making is irrational, suboptimal and subject to\nbiases. This turn to the rational suggests that human decision making may be a\nbetter source of ideas for constraining how machine learning problems are\ndefined than would otherwise be the case. One promising idea concerns human\ndecision making that is dependent on apparently irrelevant aspects of the\nchoice context. Previous work has shown that by taking into account choice\ncontext and making relational observations, people can maximize expected value.\nOther work has shown that Partially observable Markov decision processes\n(POMDPs) are a useful way to formulate human-like decision problems. Here, we\npropose a novel POMDP model for contextual choice tasks and show that, despite\nthe apparent irrationalities, a reinforcement learner can take advantage of the\nway that humans make decisions. We suggest that human irrationalities may offer\na productive source of inspiration for improving the design of AI architectures\nand machine learning methods.\n", "versions": [{"version": "v1", "created": "Sun, 7 Jun 2020 07:44:53 GMT"}], "update_date": "2020-06-09", "authors_parsed": [["Chen", "Haiyang", ""], ["Chang", "Hyung Jin", ""], ["Howes", "Andrew", ""]]}, {"id": "2006.04089", "submitter": "Weiguo Pian", "authors": "Weiguo Pian, Yingbo Wu, Ziyi Kou", "title": "STDI-Net: Spatial-Temporal Network with Dynamic Interval Mapping for\n  Bike Sharing Demand Prediction", "comments": "accepted by CIKM workshops 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As an economical and healthy mode of shared transportation, Bike Sharing\nSystem (BSS) develops quickly in many big cities. An accurate prediction method\ncan help BSS schedule resources in advance to meet the demands of users, and\ndefinitely improve operating efficiencies of it. However, most of the existing\nmethods for similar tasks just utilize spatial or temporal information\nindependently. Though there are some methods consider both, they only focus on\ndemand prediction in a single location or between location pairs. In this\npaper, we propose a novel deep learning method called Spatial-Temporal Dynamic\nInterval Network (STDI-Net). The method predicts the number of renting and\nreturning orders of multiple connected stations in the near future by modeling\njoint spatial-temporal information. Furthermore, we embed an additional module\nthat generates dynamical learnable mappings for different time intervals, to\ninclude the factor that different time intervals have a strong influence on\ndemand prediction in BSS. Extensive experiments are conducted on the NYC Bike\ndataset, the results demonstrate the superiority of our method over existing\nmethods.\n", "versions": [{"version": "v1", "created": "Sun, 7 Jun 2020 08:52:40 GMT"}, {"version": "v2", "created": "Tue, 25 Aug 2020 19:23:49 GMT"}, {"version": "v3", "created": "Mon, 28 Dec 2020 23:17:43 GMT"}], "update_date": "2021-01-01", "authors_parsed": [["Pian", "Weiguo", ""], ["Wu", "Yingbo", ""], ["Kou", "Ziyi", ""]]}, {"id": "2006.04102", "submitter": "Nayeon Lee", "authors": "Nayeon Lee, Belinda Z. Li, Sinong Wang, Wen-tau Yih, Hao Ma, Madian\n  Khabsa", "title": "Language Models as Fact Checkers?", "comments": "Accepted in FEVER Workshop (ACL2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work has suggested that language models (LMs) store both common-sense\nand factual knowledge learned from pre-training data. In this paper, we\nleverage this implicit knowledge to create an effective end-to-end fact checker\nusing a solely a language model, without any external knowledge or explicit\nretrieval components. While previous work on extracting knowledge from LMs have\nfocused on the task of open-domain question answering, to the best of our\nknowledge, this is the first work to examine the use of language models as fact\ncheckers. In a closed-book setting, we show that our zero-shot LM approach\noutperforms a random baseline on the standard FEVER task, and that our\nfine-tuned LM compares favorably with standard baselines. Though we do not\nultimately outperform methods which use explicit knowledge bases, we believe\nour exploration shows that this method is viable and has much room for\nexploration.\n", "versions": [{"version": "v1", "created": "Sun, 7 Jun 2020 09:52:05 GMT"}, {"version": "v2", "created": "Fri, 24 Jul 2020 07:15:37 GMT"}], "update_date": "2020-07-27", "authors_parsed": [["Lee", "Nayeon", ""], ["Li", "Belinda Z.", ""], ["Wang", "Sinong", ""], ["Yih", "Wen-tau", ""], ["Ma", "Hao", ""], ["Khabsa", "Madian", ""]]}, {"id": "2006.04109", "submitter": "Yipeng Kang", "authors": "Yipeng Kang, Tonghan Wang, Gerard de Melo", "title": "Incorporating Pragmatic Reasoning Communication into Emergent Language", "comments": "9 pages. Accepted as a spotlight paper to NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Emergentism and pragmatics are two research fields that study the dynamics of\nlinguistic communication along substantially different timescales and\nintelligence levels. From the perspective of multi-agent reinforcement\nlearning, they correspond to stochastic games with reinforcement training and\nstage games with opponent awareness. Given that their combination has been\nexplored in linguistics, we propose computational models that combine\nshort-term mutual reasoning-based pragmatics with long-term language\nemergentism. We explore this for agent communication referential games as well\nas in Starcraft II, assessing the relative merits of different kinds of mutual\nreasoning pragmatics models both empirically and theoretically. Our results\nshed light on their importance for making inroads towards getting more natural,\naccurate, robust, fine-grained, and succinct utterances.\n", "versions": [{"version": "v1", "created": "Sun, 7 Jun 2020 10:31:06 GMT"}, {"version": "v2", "created": "Tue, 15 Dec 2020 18:19:21 GMT"}], "update_date": "2020-12-16", "authors_parsed": [["Kang", "Yipeng", ""], ["Wang", "Tonghan", ""], ["de Melo", "Gerard", ""]]}, {"id": "2006.04120", "submitter": "Thomas Parr", "authors": "Karl Friston, Lancelot Da Costa, Danijar Hafner, Casper Hesp, Thomas\n  Parr", "title": "Sophisticated Inference", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Active inference offers a first principle account of sentient behaviour, from\nwhich special and important cases can be derived, e.g., reinforcement learning,\nactive learning, Bayes optimal inference, Bayes optimal design, etc. Active\ninference resolves the exploitation-exploration dilemma in relation to prior\npreferences, by placing information gain on the same footing as reward or\nvalue. In brief, active inference replaces value functions with functionals of\n(Bayesian) beliefs, in the form of an expected (variational) free energy. In\nthis paper, we consider a sophisticated kind of active inference, using a\nrecursive form of expected free energy. Sophistication describes the degree to\nwhich an agent has beliefs about beliefs. We consider agents with beliefs about\nthe counterfactual consequences of action for states of affairs and beliefs\nabout those latent states. In other words, we move from simply considering\nbeliefs about 'what would happen if I did that' to 'what would I believe about\nwhat would happen if I did that'. The recursive form of the free energy\nfunctional effectively implements a deep tree search over actions and outcomes\nin the future. Crucially, this search is over sequences of belief states, as\nopposed to states per se. We illustrate the competence of this scheme, using\nnumerical simulations of deep decision problems.\n", "versions": [{"version": "v1", "created": "Sun, 7 Jun 2020 11:18:58 GMT"}], "update_date": "2020-06-09", "authors_parsed": [["Friston", "Karl", ""], ["Da Costa", "Lancelot", ""], ["Hafner", "Danijar", ""], ["Hesp", "Casper", ""], ["Parr", "Thomas", ""]]}, {"id": "2006.04156", "submitter": "Ruairidh Battleday", "authors": "Ruairidh M. Battleday and Thomas L. Griffiths", "title": "Analogy as Nonparametric Bayesian Inference over Relational Systems", "comments": "In Proceedings for the Annual Meeting of the Cognitive Science\n  Society 2020 (CogSci 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Much of human learning and inference can be framed within the computational\nproblem of relational generalization. In this project, we propose a Bayesian\nmodel that generalizes relational knowledge to novel environments by\nanalogically weighting predictions from previously encountered relational\nstructures. First, we show that this learner outperforms a naive, theory-based\nlearner on relational data derived from random- and Wikipedia-based systems\nwhen experience with the environment is small. Next, we show how our\nformalization of analogical similarity translates to the selection and\nweighting of analogies. Finally, we combine the analogy- and theory-based\nlearners in a single nonparametric Bayesian model, and show that optimal\nrelational generalization transitions from relying on analogies to building a\ntheory of the novel system with increasing experience in it. Beyond predicting\nunobserved interactions better than either baseline, this formalization gives a\ncomputational-level perspective on the formation and abstraction of analogies\nthemselves.\n", "versions": [{"version": "v1", "created": "Sun, 7 Jun 2020 14:07:46 GMT"}], "update_date": "2020-06-09", "authors_parsed": [["Battleday", "Ruairidh M.", ""], ["Griffiths", "Thomas L.", ""]]}, {"id": "2006.04161", "submitter": "Maulik Kamdar", "authors": "Maulik R. Kamdar and Mark A. Musen", "title": "An Empirical Meta-analysis of the Life Sciences (Linked?) Open Data on\n  the Web", "comments": "Under Review at Nature Scientific Data", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  While the biomedical community has published several \"open data\" sources in\nthe last decade, most researchers still endure severe logistical and technical\nchallenges to discover, query, and integrate heterogeneous data and knowledge\nfrom multiple sources. To tackle these challenges, the community has\nexperimented with Semantic Web and linked data technologies to create the Life\nSciences Linked Open Data (LSLOD) cloud. In this paper, we extract schemas from\nmore than 80 publicly available biomedical linked data graphs into an LSLOD\nschema graph and conduct an empirical meta-analysis to evaluate the extent of\nsemantic heterogeneity across the LSLOD cloud. We observe that several LSLOD\nsources exist as stand-alone data sources that are not inter-linked with other\nsources, use unpublished schemas with minimal reuse or mappings, and have\nelements that are not useful for data integration from a biomedical\nperspective. We envision that the LSLOD schema graph and the findings from this\nresearch will aid researchers who wish to query and integrate data and\nknowledge from multiple biomedical sources simultaneously on the Web.\n", "versions": [{"version": "v1", "created": "Sun, 7 Jun 2020 14:26:32 GMT"}], "update_date": "2020-06-09", "authors_parsed": [["Kamdar", "Maulik R.", ""], ["Musen", "Mark A.", ""]]}, {"id": "2006.04167", "submitter": "Agi Kurucz", "authors": "Olga Gerasimova, Stanislav Kikot, Agi Kurucz, Vladimir Podolskii,\n  Michael Zakharyaschev", "title": "A tetrachotomy of ontology-mediated queries with a covering axiom", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We are interested in the problem of efficiently determining the data\ncomplexity of answering queries mediated by non-Horn description logic\nontologies and constructing their optimal rewritings to standard database\nqueries. In general, this problem is known to be extremely complex. In this\narticle, we strip it to the bare bones and focus on conjunctive queries\nmediated by a simple covering axiom stating that one class is covered by the\nunion of two other classes. We develop a novel technique to prove that, quite\nsurprisingly, deciding first-order rewritability of even such simple\nontology-mediated queries is PSpace-hard. The main result of this article is a\ncomplete and transparent syntactic AC0/NL/P/coNP tetrachotomy of path queries\nunder the assumption that the covering classes are disjoint. We also obtain a\nnumber of syntactic and semantic sufficient conditions (without the path query\nassumption) for membership in AC0, L, NL, and P.\n", "versions": [{"version": "v1", "created": "Sun, 7 Jun 2020 14:47:07 GMT"}, {"version": "v2", "created": "Sun, 19 Jul 2020 16:52:59 GMT"}], "update_date": "2020-07-21", "authors_parsed": [["Gerasimova", "Olga", ""], ["Kikot", "Stanislav", ""], ["Kurucz", "Agi", ""], ["Podolskii", "Vladimir", ""], ["Zakharyaschev", "Michael", ""]]}, {"id": "2006.04176", "submitter": "Zafeirios Fountas PhD", "authors": "Zafeirios Fountas, Noor Sajid, Pedro A.M. Mediano, Karl Friston", "title": "Deep active inference agents using Monte-Carlo methods", "comments": "To appear in NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Active inference is a Bayesian framework for understanding biological\nintelligence. The underlying theory brings together perception and action under\none single imperative: minimizing free energy. However, despite its theoretical\nutility in explaining intelligence, computational implementations have been\nrestricted to low-dimensional and idealized situations. In this paper, we\npresent a neural architecture for building deep active inference agents\noperating in complex, continuous state-spaces using multiple forms of\nMonte-Carlo (MC) sampling. For this, we introduce a number of techniques, novel\nto active inference. These include: i) selecting free-energy-optimal policies\nvia MC tree search, ii) approximating this optimal policy distribution via a\nfeed-forward `habitual' network, iii) predicting future parameter belief\nupdates using MC dropouts and, finally, iv) optimizing state transition\nprecision (a high-end form of attention). Our approach enables agents to learn\nenvironmental dynamics efficiently, while maintaining task performance, in\nrelation to reward-based counterparts. We illustrate this in a new toy\nenvironment, based on the dSprites data-set, and demonstrate that active\ninference agents automatically create disentangled representations that are apt\nfor modeling state transitions. In a more complex Animal-AI environment, our\nagents (using the same neural architecture) are able to simulate future state\ntransitions and actions (i.e., plan), to evince reward-directed navigation -\ndespite temporary suspension of visual input. These results show that deep\nactive inference - equipped with MC methods - provides a flexible framework to\ndevelop biologically-inspired intelligent agents, with applications in both\nmachine learning and cognitive science.\n", "versions": [{"version": "v1", "created": "Sun, 7 Jun 2020 15:10:42 GMT"}, {"version": "v2", "created": "Thu, 22 Oct 2020 13:17:36 GMT"}], "update_date": "2020-10-23", "authors_parsed": [["Fountas", "Zafeirios", ""], ["Sajid", "Noor", ""], ["Mediano", "Pedro A. M.", ""], ["Friston", "Karl", ""]]}, {"id": "2006.04200", "submitter": "Abhishek Dubey", "authors": "Ayan Mukhopadhyay and Geoffrey Pettet and Sayyed Vazirizade and Di Lu\n  and Said El Said and Alex Jaimes and Hiba Baroud and Yevgeniy Vorobeychik and\n  Mykel Kochenderfer and Abhishek Dubey", "title": "A Review of Incident Prediction, Resource Allocation, and Dispatch\n  Models for Emergency Management", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CY cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the last fifty years, researchers have developed statistical, data-driven,\nanalytical, and algorithmic approaches for designing and improving emergency\nresponse management (ERM) systems. The problem is inherently difficult and\nconstitutes spatio-temporal decision making under uncertainty, which has been\naddressed in the literature with varying assumptions and approaches. This\nsurvey provides a detailed review of these approaches, focusing on the key\nchallenges and issues regarding three subprocesses that are part of this\nproblem (a) incident prediction, (b) resource allocation, and (c)\ncomputer-aided dispatch to handle the emergency conditions. We highlight the\nstrengths and weaknesses of prior work in this domain and explore the\nsimilarities and differences between different modeling paradigms. We conclude\nby illustrating remain challenges and opportunities for future research in this\ncomplex domain.\n", "versions": [{"version": "v1", "created": "Sun, 7 Jun 2020 16:50:59 GMT"}, {"version": "v2", "created": "Tue, 9 Jun 2020 22:04:06 GMT"}, {"version": "v3", "created": "Fri, 12 Jun 2020 19:42:58 GMT"}, {"version": "v4", "created": "Fri, 3 Jul 2020 12:06:58 GMT"}, {"version": "v5", "created": "Tue, 1 Sep 2020 06:30:26 GMT"}, {"version": "v6", "created": "Mon, 1 Feb 2021 16:42:36 GMT"}], "update_date": "2021-02-02", "authors_parsed": [["Mukhopadhyay", "Ayan", ""], ["Pettet", "Geoffrey", ""], ["Vazirizade", "Sayyed", ""], ["Lu", "Di", ""], ["Said", "Said El", ""], ["Jaimes", "Alex", ""], ["Baroud", "Hiba", ""], ["Vorobeychik", "Yevgeniy", ""], ["Kochenderfer", "Mykel", ""], ["Dubey", "Abhishek", ""]]}, {"id": "2006.04201", "submitter": "Xu He", "authors": "Xu He, Haipeng Chen and Bo An", "title": "Learning Behaviors with Uncertain Human Feedback", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Human feedback is widely used to train agents in many domains. However,\nprevious works rarely consider the uncertainty when humans provide feedback,\nespecially in cases that the optimal actions are not obvious to the trainers.\nFor example, the reward of a sub-optimal action can be stochastic and sometimes\nexceeds that of the optimal action, which is common in games or real-world.\nTrainers are likely to provide positive feedback to sub-optimal actions,\nnegative feedback to the optimal actions and even do not provide feedback in\nsome confusing situations. Existing works, which utilize the Expectation\nMaximization (EM) algorithm and treat the feedback model as hidden parameters,\ndo not consider uncertainties in the learning environment and human feedback.\nTo address this challenge, we introduce a novel feedback model that considers\nthe uncertainty of human feedback. However, this incurs intractable calculus in\nthe EM algorithm. To this end, we propose a novel approximate EM algorithm, in\nwhich we approximate the expectation step with the Gradient Descent method.\nExperimental results in both synthetic scenarios and two real-world scenarios\nwith human participants demonstrate the superior performance of our proposed\napproach.\n", "versions": [{"version": "v1", "created": "Sun, 7 Jun 2020 16:51:48 GMT"}], "update_date": "2020-06-09", "authors_parsed": [["He", "Xu", ""], ["Chen", "Haipeng", ""], ["An", "Bo", ""]]}, {"id": "2006.04216", "submitter": "Chengrun Yang", "authors": "Chengrun Yang, Jicong Fan, Ziyang Wu, Madeleine Udell", "title": "Efficient AutoML Pipeline Search with Matrix and Tensor Factorization", "comments": "This is an extended version of AutoML Pipeline Selection: Efficiently\n  Navigating the Combinatorial Space (DOI: 10.1145/3394486.3403197) at KDD 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data scientists seeking a good supervised learning model on a new dataset\nhave many choices to make: they must preprocess the data, select features,\npossibly reduce the dimension, select an estimation algorithm, and choose\nhyperparameters for each of these pipeline components. With new pipeline\ncomponents comes a combinatorial explosion in the number of choices! In this\nwork, we design a new AutoML system to address this challenge: an automated\nsystem to design a supervised learning pipeline. Our system uses matrix and\ntensor factorization as surrogate models to model the combinatorial pipeline\nsearch space. Under these models, we develop greedy experiment design protocols\nto efficiently gather information about a new dataset. Experiments on large\ncorpora of real-world classification problems demonstrate the effectiveness of\nour approach.\n", "versions": [{"version": "v1", "created": "Sun, 7 Jun 2020 18:08:48 GMT"}], "update_date": "2020-06-11", "authors_parsed": [["Yang", "Chengrun", ""], ["Fan", "Jicong", ""], ["Wu", "Ziyang", ""], ["Udell", "Madeleine", ""]]}, {"id": "2006.04222", "submitter": "Shariq Iqbal", "authors": "Shariq Iqbal, Christian A. Schroeder de Witt, Bei Peng, Wendelin\n  B\\\"ohmer, Shimon Whiteson, Fei Sha", "title": "Randomized Entity-wise Factorization for Multi-Agent Reinforcement\n  Learning", "comments": "ICML 2021 Camera Ready", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-agent settings in the real world often involve tasks with varying types\nand quantities of agents and non-agent entities; however, common patterns of\nbehavior often emerge among these agents/entities. Our method aims to leverage\nthese commonalities by asking the question: ``What is the expected utility of\neach agent when only considering a randomly selected sub-group of its observed\nentities?'' By posing this counterfactual question, we can recognize\nstate-action trajectories within sub-groups of entities that we may have\nencountered in another task and use what we learned in that task to inform our\nprediction in the current one. We then reconstruct a prediction of the full\nreturns as a combination of factors considering these disjoint groups of\nentities and train this ``randomly factorized\" value function as an auxiliary\nobjective for value-based multi-agent reinforcement learning. By doing so, our\nmodel can recognize and leverage similarities across tasks to improve learning\nefficiency in a multi-task setting. Our approach, Randomized Entity-wise\nFactorization for Imagined Learning (REFIL), outperforms all strong baselines\nby a significant margin in challenging multi-task StarCraft micromanagement\nsettings.\n", "versions": [{"version": "v1", "created": "Sun, 7 Jun 2020 18:28:41 GMT"}, {"version": "v2", "created": "Wed, 21 Oct 2020 16:39:47 GMT"}, {"version": "v3", "created": "Fri, 11 Jun 2021 18:53:47 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Iqbal", "Shariq", ""], ["de Witt", "Christian A. Schroeder", ""], ["Peng", "Bei", ""], ["B\u00f6hmer", "Wendelin", ""], ["Whiteson", "Shimon", ""], ["Sha", "Fei", ""]]}, {"id": "2006.04271", "submitter": "Cong Wang", "authors": "Cong Wang, Qifeng Zhang, Qiyan Tian, Shuo Li, Xiaohui Wang, David\n  Lane, Yvan Petillot, Ziyang Hong, Sen Wang", "title": "Multi-Task Reinforcement Learning based Mobile Manipulation Control for\n  Dynamic Object Tracking and Grasping", "comments": "6 pages, 7 figures, submitted to IROS2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Agile control of mobile manipulator is challenging because of the high\ncomplexity coupled by the robotic system and the unstructured working\nenvironment. Tracking and grasping a dynamic object with a random trajectory is\neven harder. In this paper, a multi-task reinforcement learning-based mobile\nmanipulation control framework is proposed to achieve general dynamic object\ntracking and grasping. Several basic types of dynamic trajectories are chosen\nas the task training set. To improve the policy generalization in practice,\nrandom noise and dynamics randomization are introduced during the training\nprocess. Extensive experiments show that our policy trained can adapt to unseen\nrandom dynamic trajectories with about 0.1m tracking error and 75\\% grasping\nsuccess rate of dynamic objects. The trained policy can also be successfully\ndeployed on a real mobile manipulator.\n", "versions": [{"version": "v1", "created": "Sun, 7 Jun 2020 21:18:36 GMT"}], "update_date": "2020-06-09", "authors_parsed": [["Wang", "Cong", ""], ["Zhang", "Qifeng", ""], ["Tian", "Qiyan", ""], ["Li", "Shuo", ""], ["Wang", "Xiaohui", ""], ["Lane", "David", ""], ["Petillot", "Yvan", ""], ["Hong", "Ziyang", ""], ["Wang", "Sen", ""]]}, {"id": "2006.04331", "submitter": "Hiteshi Sharma", "authors": "Hiteshi Sharma and Rahul Jain", "title": "Randomized Policy Learning for Continuous State and Action MDPs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep reinforcement learning methods have achieved state-of-the-art results in\na variety of challenging, high-dimensional domains ranging from video games to\nlocomotion. The key to success has been the use of deep neural networks used to\napproximate the policy and value function. Yet, substantial tuning of weights\nis required for good results. We instead use randomized function approximation.\nSuch networks are not only cheaper than training fully connected networks but\nalso improve the numerical performance. We present \\texttt{RANDPOL}, a\ngeneralized policy iteration algorithm for MDPs with continuous state and\naction spaces. Both the policy and value functions are represented with\nrandomized networks. We also give finite time guarantees on the performance of\nthe algorithm. Then we show the numerical performance on challenging\nenvironments and compare them with deep neural network based algorithms.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jun 2020 02:49:47 GMT"}, {"version": "v2", "created": "Mon, 16 Nov 2020 01:55:12 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Sharma", "Hiteshi", ""], ["Jain", "Rahul", ""]]}, {"id": "2006.04361", "submitter": "Hiroyasu Tsukamoto", "authors": "Hiroyasu Tsukamoto and Soon-Jo Chung", "title": "Neural Contraction Metrics for Robust Estimation and Control: A Convex\n  Optimization Approach", "comments": "IEEE Control Systems Letters (L-CSS). Preprint version, accepted June\n  2020", "journal-ref": "IEEE Control Systems Letters, vol. 5, no. 1, pp. 211-216, Jan.\n  2021", "doi": "10.1109/LCSYS.2020.3001646", "report-no": null, "categories": "eess.SY cs.AI cs.LG cs.RO cs.SY math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a new deep learning-based framework for robust nonlinear\nestimation and control using the concept of a Neural Contraction Metric (NCM).\nThe NCM uses a deep long short-term memory recurrent neural network for a\nglobal approximation of an optimal contraction metric, the existence of which\nis a necessary and sufficient condition for exponential stability of nonlinear\nsystems. The optimality stems from the fact that the contraction metrics\nsampled offline are the solutions of a convex optimization problem to minimize\nan upper bound of the steady-state Euclidean distance between perturbed and\nunperturbed system trajectories. We demonstrate how to exploit NCMs to design\nan online optimal estimator and controller for nonlinear systems with bounded\ndisturbances utilizing their duality. The performance of our framework is\nillustrated through Lorenz oscillator state estimation and spacecraft optimal\nmotion planning problems.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jun 2020 05:29:38 GMT"}, {"version": "v2", "created": "Thu, 30 Jul 2020 05:43:50 GMT"}, {"version": "v3", "created": "Fri, 31 Jul 2020 03:27:26 GMT"}], "update_date": "2020-11-20", "authors_parsed": [["Tsukamoto", "Hiroyasu", ""], ["Chung", "Soon-Jo", ""]]}, {"id": "2006.04363", "submitter": "Taher Jafferjee", "authors": "Taher Jafferjee, Ehsan Imani, Erin Talvitie, Martha White, Micheal\n  Bowling", "title": "Hallucinating Value: A Pitfall of Dyna-style Planning with Imperfect\n  Environment Models", "comments": "9 pages, 7 figures,", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dyna-style reinforcement learning (RL) agents improve sample efficiency over\nmodel-free RL agents by updating the value function with simulated experience\ngenerated by an environment model. However, it is often difficult to learn\naccurate models of environment dynamics, and even small errors may result in\nfailure of Dyna agents. In this paper, we investigate one type of model error:\nhallucinated states. These are states generated by the model, but that are not\nreal states of the environment. We present the Hallucinated Value Hypothesis\n(HVH): updating values of real states towards values of hallucinated states\nresults in misleading state-action values which adversely affect the control\npolicy. We discuss and evaluate four Dyna variants; three which update real\nstates toward simulated -- and therefore potentially hallucinated -- states and\none which does not. The experimental results provide evidence for the HVH thus\nsuggesting a fruitful direction toward developing Dyna algorithms robust to\nmodel error.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jun 2020 05:30:09 GMT"}], "update_date": "2020-06-09", "authors_parsed": [["Jafferjee", "Taher", ""], ["Imani", "Ehsan", ""], ["Talvitie", "Erin", ""], ["White", "Martha", ""], ["Bowling", "Micheal", ""]]}, {"id": "2006.04376", "submitter": "Baihan Lin", "authors": "Baihan Lin, Xinxin Zhang", "title": "Speaker Diarization as a Fully Online Learning Problem in MiniVox", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.HC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We proposed a novel machine learning framework to conduct real-time\nmulti-speaker diarization and recognition without prior registration and\npretraining in a fully online learning setting. Our contributions are two-fold.\nFirst, we proposed a new benchmark to evaluate the rarely studied fully online\nspeaker diarization problem. We built upon existing datasets of real world\nutterances to automatically curate MiniVox, an experimental environment which\ngenerates infinite configurations of continuous multi-speaker speech stream.\nSecond, we considered the practical problem of online learning with\nepisodically revealed rewards and introduced a solution based on\nsemi-supervised and self-supervised learning methods. Additionally, we provided\na workable web-based recognition system which interactively handles the cold\nstart problem of new user's addition by transferring representations of old\narms to new ones with an extendable contextual bandit. We demonstrated that our\nproposed method obtained robust performance in the online MiniVox framework.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jun 2020 06:40:29 GMT"}, {"version": "v2", "created": "Tue, 15 Sep 2020 17:30:57 GMT"}, {"version": "v3", "created": "Thu, 22 Oct 2020 02:56:34 GMT"}], "update_date": "2020-10-23", "authors_parsed": [["Lin", "Baihan", ""], ["Zhang", "Xinxin", ""]]}, {"id": "2006.04387", "submitter": "Laura Giordano", "authors": "Laura Giordano and Daniele Theseider Dupr\\'e", "title": "An ASP approach for reasoning in a concept-aware multipreferential\n  lightweight DL", "comments": "Paper presented at the 36th International Conference on Logic\n  Programming (ICLP 2020), University Of Calabria, Rende (CS), Italy, September\n  2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we develop a concept aware multi-preferential semantics for\ndealing with typicality in description logics, where preferences are associated\nwith concepts, starting from a collection of ranked TBoxes containing\ndefeasible concept inclusions. Preferences are combined to define a\npreferential interpretation in which defeasible inclusions can be evaluated.\nThe construction of the concept-aware multipreference semantics is related to\nBrewka's framework for qualitative preferences. We exploit Answer Set\nProgramming (in particular, asprin) to achieve defeasible reasoning under the\nmultipreference approach for the lightweight description logic EL+bot.\n  The paper is under consideration for acceptance in TPLP.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jun 2020 07:15:38 GMT"}, {"version": "v2", "created": "Sat, 8 Aug 2020 07:53:44 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Giordano", "Laura", ""], ["Dupr\u00e9", "Daniele Theseider", ""]]}, {"id": "2006.04419", "submitter": "Daniel Hernandez Mr", "authors": "Daniel Hernandez, Charles Takashi Toyin Gbadamosi, James Goodman,\n  James Alfred Walker", "title": "Metagame Autobalancing for Competitive Multiplayer Games", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automated game balancing has often focused on single-agent scenarios. In this\npaper we present a tool for balancing multi-player games during game design.\nOur approach requires a designer to construct an intuitive graphical\nrepresentation of their meta-game target, representing the relative scores that\nhigh-level strategies (or decks, or character types) should experience. This\npermits more sophisticated balance targets to be defined beyond a simple\nrequirement of equal win chances. We then find a parameterization of the game\nthat meets this target using simulation-based optimization to minimize the\ndistance to the target graph. We show the capabilities of this tool on examples\ninheriting from Rock-Paper-Scissors, and on a more complex asymmetric fighting\ngame.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jun 2020 08:55:30 GMT"}], "update_date": "2020-10-05", "authors_parsed": [["Hernandez", "Daniel", ""], ["Gbadamosi", "Charles Takashi Toyin", ""], ["Goodman", "James", ""], ["Walker", "James Alfred", ""]]}, {"id": "2006.04435", "submitter": "Xiang Li", "authors": "Xiang Li, Ben Kao, Caihua Shan, Dawei Yin, Martin Ester", "title": "CAST: A Correlation-based Adaptive Spectral Clustering Algorithm on\n  Multi-scale Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of applying spectral clustering to cluster multi-scale\ndata, which is data whose clusters are of various sizes and densities.\nTraditional spectral clustering techniques discover clusters by processing a\nsimilarity matrix that reflects the proximity of objects. For multi-scale data,\ndistance-based similarity is not effective because objects of a sparse cluster\ncould be far apart while those of a dense cluster have to be sufficiently\nclose. Following [16], we solve the problem of spectral clustering on\nmulti-scale data by integrating the concept of objects' \"reachability\nsimilarity\" with a given distance-based similarity to derive an objects'\ncoefficient matrix. We propose the algorithm CAST that applies trace Lasso to\nregularize the coefficient matrix. We prove that the resulting coefficient\nmatrix has the \"grouping effect\" and that it exhibits \"sparsity\". We show that\nthese two characteristics imply very effective spectral clustering. We evaluate\nCAST and 10 other clustering methods on a wide range of datasets w.r.t. various\nmeasures. Experimental results show that CAST provides excellent performance\nand is highly robust across test cases of multi-scale data.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jun 2020 09:46:35 GMT"}], "update_date": "2020-06-09", "authors_parsed": [["Li", "Xiang", ""], ["Kao", "Ben", ""], ["Shan", "Caihua", ""], ["Yin", "Dawei", ""], ["Ester", "Martin", ""]]}, {"id": "2006.04471", "submitter": "Daniel Hernandez Mr", "authors": "Daniel Hernandez, Kevin Denamganai, Sam Devlin, Spyridon Samothrakis,\n  James Alfred Walker", "title": "A Comparison of Self-Play Algorithms Under a Generalized Framework", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Throughout scientific history, overarching theoretical frameworks have\nallowed researchers to grow beyond personal intuitions and culturally biased\ntheories. They allow to verify and replicate existing findings, and to link is\nconnected results. The notion of self-play, albeit often cited in multiagent\nReinforcement Learning, has never been grounded in a formal model. We present a\nformalized framework, with clearly defined assumptions, which encapsulates the\nmeaning of self-play as abstracted from various existing self-play algorithms.\nThis framework is framed as an approximation to a theoretical solution concept\nfor multiagent training. On a simple environment, we qualitatively measure how\nwell a subset of the captured self-play methods approximate this solution when\npaired with the famous PPO algorithm. We also provide insights on interpreting\nquantitative metrics of performance for self-play training. Our results\nindicate that, throughout training, various self-play definitions exhibit\ncyclic policy evolutions.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jun 2020 11:02:37 GMT"}], "update_date": "2020-06-09", "authors_parsed": [["Hernandez", "Daniel", ""], ["Denamganai", "Kevin", ""], ["Devlin", "Sam", ""], ["Samothrakis", "Spyridon", ""], ["Walker", "James Alfred", ""]]}, {"id": "2006.04497", "submitter": "Omer Ben-Porat", "authors": "Gal Bahar, Omer Ben-Porat, Kevin Leyton-Brown and Moshe Tennenholtz", "title": "Learning under Invariable Bayesian Safety", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.AI cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A recent body of work addresses safety constraints in explore-and-exploit\nsystems. Such constraints arise where, for example, exploration is carried out\nby individuals whose welfare should be balanced with overall welfare. In this\npaper, we adopt a model inspired by recent work on a bandit-like setting for\nrecommendations. We contribute to this line of literature by introducing a\nsafety constraint that should be respected in every round and determines that\nthe expected value in each round is above a given threshold. Due to our\nmodeling, the safe explore-and-exploit policy deserves careful planning, or\notherwise, it will lead to sub-optimal welfare. We devise an asymptotically\noptimal algorithm for the setting and analyze its instance-dependent\nconvergence rate.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jun 2020 12:07:59 GMT"}], "update_date": "2020-06-09", "authors_parsed": [["Bahar", "Gal", ""], ["Ben-Porat", "Omer", ""], ["Leyton-Brown", "Kevin", ""], ["Tennenholtz", "Moshe", ""]]}, {"id": "2006.04509", "submitter": "Siddhant Arora", "authors": "Siddhant Arora, Srikanta Bedathur, Maya Ramanath, Deepak Sharma", "title": "IterefinE: Iterative KG Refinement Embeddings using Symbolic Knowledge", "comments": "16 pages, 7 figures, AKBC 2020 Conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.DB cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge Graphs (KGs) extracted from text sources are often noisy and lead\nto poor performance in downstream application tasks such as KG-based question\nanswering.While much of the recent activity is focused on addressing the\nsparsity of KGs by using embeddings for inferring new facts, the issue of\ncleaning up of noise in KGs through KG refinement task is not as actively\nstudied. Most successful techniques for KG refinement make use of inference\nrules and reasoning over ontologies. Barring a few exceptions, embeddings do\nnot make use of ontological information, and their performance in KG refinement\ntask is not well understood. In this paper, we present a KG refinement\nframework called IterefinE which iteratively combines the two techniques - one\nwhich uses ontological information and inferences rules, PSL-KGI, and the KG\nembeddings such as ComplEx and ConvE which do not. As a result, IterefinE is\nable to exploit not only the ontological information to improve the quality of\npredictions, but also the power of KG embeddings which (implicitly) perform\nlonger chains of reasoning. The IterefinE framework, operates in a co-training\nmode and results in explicit type-supervised embedding of the refined KG from\nPSL-KGI which we call as TypeE-X. Our experiments over a range of KG benchmarks\nshow that the embeddings that we produce are able to reject noisy facts from KG\nand at the same time infer higher quality new facts resulting in up to 9%\nimprovement of overall weighted F1 score\n", "versions": [{"version": "v1", "created": "Wed, 3 Jun 2020 14:05:54 GMT"}], "update_date": "2020-06-09", "authors_parsed": [["Arora", "Siddhant", ""], ["Bedathur", "Srikanta", ""], ["Ramanath", "Maya", ""], ["Sharma", "Deepak", ""]]}, {"id": "2006.04520", "submitter": "Liang Zhao", "authors": "Yifei Zhao, Yu-Hang Zhou, Mingdong Ou, Huan Xu, Nan Li", "title": "Maximizing Cumulative User Engagement in Sequential Recommendation: An\n  Online Optimization Perspective", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To maximize cumulative user engagement (e.g. cumulative clicks) in sequential\nrecommendation, it is often needed to tradeoff two potentially conflicting\nobjectives, that is, pursuing higher immediate user engagement (e.g.,\nclick-through rate) and encouraging user browsing (i.e., more items exposured).\nExisting works often study these two tasks separately, thus tend to result in\nsub-optimal results. In this paper, we study this problem from an online\noptimization perspective, and propose a flexible and practical framework to\nexplicitly tradeoff longer user browsing length and high immediate user\nengagement. Specifically, by considering items as actions, user's requests as\nstates and user leaving as an absorbing state, we formulate each user's\nbehavior as a personalized Markov decision process (MDP), and the problem of\nmaximizing cumulative user engagement is reduced to a stochastic shortest path\n(SSP) problem. Meanwhile, with immediate user engagement and quit probability\nestimation, it is shown that the SSP problem can be efficiently solved via\ndynamic programming. Experiments on real-world datasets demonstrate the\neffectiveness of the proposed approach. Moreover, this approach is deployed at\na large E-commerce platform, achieved over 7% improvement of cumulative clicks.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jun 2020 09:02:51 GMT"}], "update_date": "2020-06-09", "authors_parsed": [["Zhao", "Yifei", ""], ["Zhou", "Yu-Hang", ""], ["Ou", "Mingdong", ""], ["Xu", "Huan", ""], ["Li", "Nan", ""]]}, {"id": "2006.04556", "submitter": "Ariam Rivas", "authors": "Ariam Rivas, Irl\\'an Grangel-Gonz\\'alez, Diego Collarana, Jens\n  Lehmann, Maria-Esther Vidal", "title": "Unveiling Relations in the Industry 4.0 Standards Landscape based on\n  Knowledge Graph Embeddings", "comments": "15 pages, 7 figures, DEXA2020 Conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.DB cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Industry~4.0 (I4.0) standards and standardization frameworks have been\nproposed with the goal of \\emph{empowering interoperability} in smart\nfactories. These standards enable the description and interaction of the main\ncomponents, systems, and processes inside of a smart factory. Due to the\ngrowing number of frameworks and standards, there is an increasing need for\napproaches that automatically analyze the landscape of I4.0 standards.\nStandardization frameworks classify standards according to their functions into\nlayers and dimensions. However, similar standards can be classified differently\nacross the frameworks, producing, thus, interoperability conflicts among them.\nSemantic-based approaches that rely on ontologies and knowledge graphs, have\nbeen proposed to represent standards, known relations among them, as well as\ntheir classification according to existing frameworks. Albeit informative, the\nstructured modeling of the I4.0 landscape only provides the foundations for\ndetecting interoperability issues. Thus, graph-based analytical methods able to\nexploit knowledge encoded by these approaches, are required to uncover\nalignments among standards. We study the relatedness among standards and\nframeworks based on community analysis to discover knowledge that helps to cope\nwith interoperability conflicts between standards. We use knowledge graph\nembeddings to automatically create these communities exploiting the meaning of\nthe existing relationships. In particular, we focus on the identification of\nsimilar standards, i.e., communities of standards, and analyze their properties\nto detect unknown relations. We empirically evaluate our approach on a\nknowledge graph of I4.0 standards using the Trans$^*$ family of embedding\nmodels for knowledge graph entities. Our results are promising and suggest that\nrelations among standards can be detected accurately.\n", "versions": [{"version": "v1", "created": "Wed, 3 Jun 2020 17:37:08 GMT"}], "update_date": "2020-06-09", "authors_parsed": [["Rivas", "Ariam", ""], ["Grangel-Gonz\u00e1lez", "Irl\u00e1n", ""], ["Collarana", "Diego", ""], ["Lehmann", "Jens", ""], ["Vidal", "Maria-Esther", ""]]}, {"id": "2006.04562", "submitter": "Mirko Lenz", "authors": "Mirko Lenz, Premtim Sahitaj, Sean Kallenberg, Christopher Coors, Lorik\n  Dumani, Ralf Schenkel, Ralph Bergmann", "title": "Towards an Argument Mining Pipeline Transforming Texts to Argument\n  Graphs", "comments": null, "journal-ref": null, "doi": "10.3233/FAIA200510", "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper targets the automated extraction of components of argumentative\ninformation and their relations from natural language text. Moreover, we\naddress a current lack of systems to provide complete argumentative structure\nfrom arbitrary natural language text for general usage. We present an argument\nmining pipeline as a universally applicable approach for transforming German\nand English language texts to graph-based argument representations. We also\nintroduce new methods for evaluating the results based on existing benchmark\nargument structures. Our results show that the generated argument graphs can be\nbeneficial to detect new connections between different statements of an\nargumentative text. Our pipeline implementation is publicly available on\nGitHub.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jun 2020 13:10:19 GMT"}, {"version": "v2", "created": "Mon, 28 Sep 2020 11:07:04 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Lenz", "Mirko", ""], ["Sahitaj", "Premtim", ""], ["Kallenberg", "Sean", ""], ["Coors", "Christopher", ""], ["Dumani", "Lorik", ""], ["Schenkel", "Ralf", ""], ["Bergmann", "Ralph", ""]]}, {"id": "2006.04599", "submitter": "Aylin Caliskan", "authors": "Akshat Pandey and Aylin Caliskan", "title": "Disparate Impact of Artificial Intelligence Bias in Ridehailing\n  Economy's Price Discrimination Algorithms", "comments": "16 pages, 3 tables, 8 figures", "journal-ref": "AAAI/ACM Conference on Artificial Intelligence, Ethics, and\n  Society (AAAI/ACM AIES 2021)", "doi": "10.1145/3461702.3462561", "report-no": null, "categories": "cs.CY cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Ridehailing applications that collect mobility data from individuals to\ninform smart city planning predict each trip's fare pricing with automated\nalgorithms that rely on artificial intelligence (AI). This type of AI\nalgorithm, namely a price discrimination algorithm, is widely used in the\nindustry's black box systems for dynamic individualized pricing. Lacking\ntransparency, studying such AI systems for fairness and disparate impact has\nnot been possible without access to data used in generating the outcomes of\nprice discrimination algorithms. Recently, in an effort to enhance transparency\nin city planning, the city of Chicago regulation mandated that transportation\nproviders publish anonymized data on ridehailing. As a result, we present the\nfirst large-scale measurement of the disparate impact of price discrimination\nalgorithms used by ridehailing applications.\n  The application of random effects models from the meta-analysis literature\ncombines the city-level effects of AI bias on fare pricing from census tract\nattributes, aggregated from the American Community Survey. An analysis of 100\nmillion ridehailing samples from the city of Chicago indicates a significant\ndisparate impact in fare pricing of neighborhoods due to AI bias learned from\nridehailing utilization patterns associated with demographic attributes.\nNeighborhoods with larger non-white populations, higher poverty levels, younger\nresidents, and high education levels are significantly associated with higher\nfare prices, with combined effect sizes, measured in Cohen's d, of -0.32,\n-0.28, 0.69, and 0.24 for each demographic, respectively. Further, our methods\nhold promise for identifying and addressing the sources of disparate impact in\nAI algorithms learning from datasets that contain U.S. geolocations.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jun 2020 13:51:03 GMT"}, {"version": "v2", "created": "Fri, 12 Jun 2020 21:06:33 GMT"}, {"version": "v3", "created": "Fri, 19 Jun 2020 00:45:59 GMT"}, {"version": "v4", "created": "Mon, 22 Jun 2020 19:43:31 GMT"}, {"version": "v5", "created": "Thu, 8 Apr 2021 14:42:09 GMT"}, {"version": "v6", "created": "Mon, 3 May 2021 20:35:37 GMT"}], "update_date": "2021-05-05", "authors_parsed": [["Pandey", "Akshat", ""], ["Caliskan", "Aylin", ""]]}, {"id": "2006.04635", "submitter": "Thomas William Anthony", "authors": "Thomas Anthony, Tom Eccles, Andrea Tacchetti, J\\'anos Kram\\'ar, Ian\n  Gemp, Thomas C. Hudson, Nicolas Porcel, Marc Lanctot, Julien P\\'erolat,\n  Richard Everett, Roman Werpachowski, Satinder Singh, Thore Graepel, and Yoram\n  Bachrach", "title": "Learning to Play No-Press Diplomacy with Best Response Policy Iteration", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.GT cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in deep reinforcement learning (RL) have led to considerable\nprogress in many 2-player zero-sum games, such as Go, Poker and Starcraft. The\npurely adversarial nature of such games allows for conceptually simple and\nprincipled application of RL methods. However real-world settings are\nmany-agent, and agent interactions are complex mixtures of common-interest and\ncompetitive aspects. We consider Diplomacy, a 7-player board game designed to\naccentuate dilemmas resulting from many-agent interactions. It also features a\nlarge combinatorial action space and simultaneous moves, which are challenging\nfor RL algorithms. We propose a simple yet effective approximate best response\noperator, designed to handle large combinatorial action spaces and simultaneous\nmoves. We also introduce a family of policy iteration methods that approximate\nfictitious play. With these methods, we successfully apply RL to Diplomacy: we\nshow that our agents convincingly outperform the previous state-of-the-art, and\ngame theoretic equilibrium analysis shows that the new process yields\nconsistent improvements.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jun 2020 14:33:31 GMT"}, {"version": "v2", "created": "Wed, 17 Jun 2020 21:34:42 GMT"}, {"version": "v3", "created": "Wed, 26 Aug 2020 17:01:22 GMT"}], "update_date": "2020-08-27", "authors_parsed": [["Anthony", "Thomas", ""], ["Eccles", "Tom", ""], ["Tacchetti", "Andrea", ""], ["Kram\u00e1r", "J\u00e1nos", ""], ["Gemp", "Ian", ""], ["Hudson", "Thomas C.", ""], ["Porcel", "Nicolas", ""], ["Lanctot", "Marc", ""], ["P\u00e9rolat", "Julien", ""], ["Everett", "Richard", ""], ["Werpachowski", "Roman", ""], ["Singh", "Satinder", ""], ["Graepel", "Thore", ""], ["Bachrach", "Yoram", ""]]}, {"id": "2006.04666", "submitter": "Nayeon Lee", "authors": "Nayeon Lee, Yejin Bang, Andrea Madotto, Pascale Fung", "title": "Misinformation Has High Perplexity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Debunking misinformation is an important and time-critical task as there\ncould be adverse consequences when misinformation is not quashed promptly.\nHowever, the usual supervised approach to debunking via misinformation\nclassification requires human-annotated data and is not suited to the fast\ntime-frame of newly emerging events such as the COVID-19 outbreak. In this\npaper, we postulate that misinformation itself has higher perplexity compared\nto truthful statements, and propose to leverage the perplexity to debunk false\nclaims in an unsupervised manner. First, we extract reliable evidence from\nscientific and news sources according to sentence similarity to the claims.\nSecond, we prime a language model with the extracted evidence and finally\nevaluate the correctness of given claims based on the perplexity scores at\ndebunking time. We construct two new COVID-19-related test sets, one is\nscientific, and another is political in content, and empirically verify that\nour system performs favorably compared to existing systems. We are releasing\nthese datasets publicly to encourage more research in debunking misinformation\non COVID-19 and other topics.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jun 2020 15:13:44 GMT"}, {"version": "v2", "created": "Wed, 10 Jun 2020 08:49:30 GMT"}], "update_date": "2020-06-11", "authors_parsed": [["Lee", "Nayeon", ""], ["Bang", "Yejin", ""], ["Madotto", "Andrea", ""], ["Fung", "Pascale", ""]]}, {"id": "2006.04672", "submitter": "Weichao Mao", "authors": "Weichao Mao, Kaiqing Zhang, Qiaomin Xie, Tamer Ba\\c{s}ar", "title": "POLY-HOOT: Monte-Carlo Planning in Continuous Space MDPs with\n  Non-Asymptotic Analysis", "comments": "NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Monte-Carlo planning, as exemplified by Monte-Carlo Tree Search (MCTS), has\ndemonstrated remarkable performance in applications with finite spaces. In this\npaper, we consider Monte-Carlo planning in an environment with continuous\nstate-action spaces, a much less understood problem with important applications\nin control and robotics. We introduce POLY-HOOT, an algorithm that augments\nMCTS with a continuous armed bandit strategy named Hierarchical Optimistic\nOptimization (HOO) (Bubeck et al., 2011). Specifically, we enhance HOO by using\nan appropriate polynomial, rather than logarithmic, bonus term in the upper\nconfidence bounds. Such a polynomial bonus is motivated by its empirical\nsuccesses in AlphaGo Zero (Silver et al., 2017b), as well as its significant\nrole in achieving theoretical guarantees of finite space MCTS (Shah et al.,\n2019). We investigate, for the first time, the regret of the enhanced HOO\nalgorithm in non-stationary bandit problems. Using this result as a building\nblock, we establish non-asymptotic convergence guarantees for POLY-HOOT: the\nvalue estimate converges to an arbitrarily small neighborhood of the optimal\nvalue function at a polynomial rate. We further provide experimental results\nthat corroborate our theoretical findings.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jun 2020 15:23:19 GMT"}, {"version": "v2", "created": "Wed, 30 Dec 2020 05:21:05 GMT"}], "update_date": "2021-01-01", "authors_parsed": [["Mao", "Weichao", ""], ["Zhang", "Kaiqing", ""], ["Xie", "Qiaomin", ""], ["Ba\u015far", "Tamer", ""]]}, {"id": "2006.04689", "submitter": "Faisal Abu-Khzam", "authors": "Faisal N. Abu-Khzam, Mohamed Mahmoud Abd El-Wahab and Noureldin Yosri", "title": "Graph Minors Meet Machine Learning: the Power of Obstructions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computational intractability has for decades motivated the development of a\nplethora of methodologies that mainly aimed at a quality-time trade-off. The\nuse of Machine Learning techniques has finally emerged as one of the possible\ntools to obtain approximate solutions to ${\\cal NP}$-hard combinatorial\noptimization problems. In a recent article, Dai et al. introduced a method for\ncomputing such approximate solutions for instances of the Vertex Cover problem.\nIn this paper we consider the effectiveness of selecting a proper training\nstrategy by considering special problem instances called \"obstructions\" that we\nbelieve carry some intrinsic properties of the problem itself. Capitalizing on\nthe recent work of Dai et al. on the Vertex Cover problem, and using the same\ncase study as well as 19 other problem instances, we show the utility of using\nobstructions for training neural networks. Experiments show that training with\nobstructions results in a huge reduction in number of iterations needed for\nconvergence, thus gaining a substantial reduction in the time needed for\ntraining the model.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jun 2020 15:40:04 GMT"}], "update_date": "2020-06-09", "authors_parsed": [["Abu-Khzam", "Faisal N.", ""], ["El-Wahab", "Mohamed Mahmoud Abd", ""], ["Yosri", "Noureldin", ""]]}, {"id": "2006.04697", "submitter": "Hebi Li", "authors": "Hebi Li, Qi Xiao, Jin Tian", "title": "Supervised Whole DAG Causal Discovery", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose to address the task of causal structure learning from data in a\nsupervised manner. Existing work on learning causal directions by supervised\nlearning is restricted to learning pairwise relation, and not well suited for\nwhole DAG discovery. We propose a novel approach of modeling the whole DAG\nstructure discovery as a supervised learning. To fit the problem in hand, we\npropose to use permutation equivariant models that align well with the problem\ndomain. We evaluate the proposed approach extensively on synthetic graphs of\nsize 10,20,50,100 and real data, and show promising results compared with a\nvariety of previous approaches.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jun 2020 15:53:20 GMT"}], "update_date": "2020-06-09", "authors_parsed": [["Li", "Hebi", ""], ["Xiao", "Qi", ""], ["Tian", "Jin", ""]]}, {"id": "2006.04702", "submitter": "Zhijing Jin", "authors": "Qipeng Guo, Zhijing Jin, Xipeng Qiu, Weinan Zhang, David Wipf, Zheng\n  Zhang", "title": "CycleGT: Unsupervised Graph-to-Text and Text-to-Graph Generation via\n  Cycle Training", "comments": "INLG 2020 Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Two important tasks at the intersection of knowledge graphs and natural\nlanguage processing are graph-to-text (G2T) and text-to-graph (T2G) conversion.\nDue to the difficulty and high cost of data collection, the supervised data\navailable in the two fields are usually on the magnitude of tens of thousands,\nfor example, 18K in the WebNLG~2017 dataset after preprocessing, which is far\nfewer than the millions of data for other tasks such as machine translation.\nConsequently, deep learning models for G2T and T2G suffer largely from scarce\ntraining data. We present CycleGT, an unsupervised training method that can\nbootstrap from fully non-parallel graph and text data, and iteratively back\ntranslate between the two forms. Experiments on WebNLG datasets show that our\nunsupervised model trained on the same number of data achieves performance on\npar with several fully supervised models. Further experiments on the\nnon-parallel GenWiki dataset verify that our method performs the best among\nunsupervised baselines. This validates our framework as an effective approach\nto overcome the data scarcity problem in the fields of G2T and T2G. Our code is\navailable at https://github.com/QipengGuo/CycleGT.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jun 2020 15:59:00 GMT"}, {"version": "v2", "created": "Thu, 11 Jun 2020 17:26:44 GMT"}, {"version": "v3", "created": "Wed, 9 Dec 2020 19:29:27 GMT"}], "update_date": "2020-12-11", "authors_parsed": [["Guo", "Qipeng", ""], ["Jin", "Zhijing", ""], ["Qiu", "Xipeng", ""], ["Zhang", "Weinan", ""], ["Wipf", "David", ""], ["Zhang", "Zheng", ""]]}, {"id": "2006.04707", "submitter": "Daniel Schiff", "authors": "Daniel Schiff and Bogdana Rakova and Aladdin Ayesh and Anat Fanti and\n  Michael Lennon", "title": "Principles to Practices for Responsible AI: Closing the Gap", "comments": "Preprint draft. A version has been submitted to the 2020 European\n  Conference on AI (ECAI) Workshop on \"ADVANCING TOWARDS THE SDGs: ARTIFICIAL\n  INTELLIGENCE FOR A FAIR, JUST AND EQUITABLE WORLD (AI4EQ)\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Companies have considered adoption of various high-level artificial\nintelligence (AI) principles for responsible AI, but there is less clarity on\nhow to implement these principles as organizational practices. This paper\nreviews the principles-to-practices gap. We outline five explanations for this\ngap ranging from a disciplinary divide to an overabundance of tools. In turn,\nwe argue that an impact assessment framework which is broad, operationalizable,\nflexible, iterative, guided, and participatory is a promising approach to close\nthe principles-to-practices gap. Finally, to help practitioners with applying\nthese recommendations, we review a case study of AI's use in forest ecosystem\nrestoration, demonstrating how an impact assessment framework can translate\ninto effective and responsible AI practices.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jun 2020 16:04:44 GMT"}], "update_date": "2020-06-09", "authors_parsed": [["Schiff", "Daniel", ""], ["Rakova", "Bogdana", ""], ["Ayesh", "Aladdin", ""], ["Fanti", "Anat", ""], ["Lennon", "Michael", ""]]}, {"id": "2006.04734", "submitter": "Adrien Ecoffet", "authors": "Adrien Ecoffet and Joel Lehman", "title": "Reinforcement Learning Under Moral Uncertainty", "comments": "28 pages, 18 figures; update adds discussion of a possible flaw of\n  Nash voting, discussion of further possible research into MEC, as well as a\n  few more references; updated to ICML version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An ambitious goal for machine learning is to create agents that behave\nethically: The capacity to abide by human moral norms would greatly expand the\ncontext in which autonomous agents could be practically and safely deployed,\ne.g. fully autonomous vehicles will encounter charged moral decisions that\ncomplicate their deployment. While ethical agents could be trained by rewarding\ncorrect behavior under a specific moral theory (e.g. utilitarianism), there\nremains widespread disagreement about the nature of morality. Acknowledging\nsuch disagreement, recent work in moral philosophy proposes that ethical\nbehavior requires acting under moral uncertainty, i.e. to take into account\nwhen acting that one's credence is split across several plausible ethical\ntheories. This paper translates such insights to the field of reinforcement\nlearning, proposes two training methods that realize different points among\ncompeting desiderata, and trains agents in simple environments to act under\nmoral uncertainty. The results illustrate (1) how such uncertainty can help\ncurb extreme behavior from commitment to single theories and (2) several\ntechnical complications arising from attempting to ground moral philosophy in\nRL (e.g. how can a principled trade-off between two competing but incomparable\nreward functions be reached). The aim is to catalyze progress towards\nmorally-competent agents and highlight the potential of RL to contribute\ntowards the computational grounding of moral philosophy.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jun 2020 16:40:12 GMT"}, {"version": "v2", "created": "Wed, 15 Jul 2020 00:15:50 GMT"}, {"version": "v3", "created": "Mon, 19 Jul 2021 18:52:16 GMT"}], "update_date": "2021-07-21", "authors_parsed": [["Ecoffet", "Adrien", ""], ["Lehman", "Joel", ""]]}, {"id": "2006.04753", "submitter": "Zhigao Guo", "authors": "Zhigao Guo and Anthony C. Constantinou", "title": "Approximate learning of high dimensional Bayesian network structures via\n  pruning of Candidate Parent Sets", "comments": null, "journal-ref": null, "doi": "10.3390/e22101142", "report-no": null, "categories": "cs.AI cs.GR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Score-based algorithms that learn Bayesian Network (BN) structures provide\nsolutions ranging from different levels of approximate learning to exact\nlearning. Approximate solutions exist because exact learning is generally not\napplicable to networks of moderate or higher complexity. In general,\napproximate solutions tend to sacrifice accuracy for speed, where the aim is to\nminimise the loss in accuracy and maximise the gain in speed. While some\napproximate algorithms are optimised to handle thousands of variables, these\nalgorithms may still be unable to learn such high dimensional structures. Some\nof the most efficient score-based algorithms cast the structure learning\nproblem as a combinatorial optimisation of candidate parent sets. This paper\nexplores a strategy towards pruning the size of candidate parent sets, aimed at\nhigh dimensionality problems. The results illustrate how different levels of\npruning affect the learning speed relative to the loss in accuracy in terms of\nmodel fitting, and show that aggressive pruning may be required to produce\napproximate solutions for high complexity problems.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jun 2020 17:09:18 GMT"}, {"version": "v2", "created": "Thu, 10 Sep 2020 15:48:29 GMT"}], "update_date": "2020-12-02", "authors_parsed": [["Guo", "Zhigao", ""], ["Constantinou", "Anthony C.", ""]]}, {"id": "2006.04757", "submitter": "Markus N Rabe", "authors": "Markus N. Rabe and Dennis Lee and Kshitij Bansal and Christian Szegedy", "title": "Mathematical Reasoning via Self-supervised Skip-tree Training", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.PL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We examine whether self-supervised language modeling applied to mathematical\nformulas enables logical reasoning. We suggest several logical reasoning tasks\nthat can be used to evaluate language models trained on formal mathematical\nstatements, such as type inference, suggesting missing assumptions and\ncompleting equalities. To train language models for formal mathematics, we\npropose a novel skip-tree task. We find that models trained on the skip-tree\ntask show surprisingly strong mathematical reasoning abilities, and outperform\nmodels trained on standard skip-sequence tasks. We also analyze the models'\nability to formulate new conjectures by measuring how often the predictions are\nprovable and useful in other proofs.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jun 2020 17:12:08 GMT"}, {"version": "v2", "created": "Wed, 10 Jun 2020 04:30:28 GMT"}, {"version": "v3", "created": "Wed, 12 Aug 2020 07:48:41 GMT"}], "update_date": "2020-08-13", "authors_parsed": [["Rabe", "Markus N.", ""], ["Lee", "Dennis", ""], ["Bansal", "Kshitij", ""], ["Szegedy", "Christian", ""]]}, {"id": "2006.04760", "submitter": "Ding Liu", "authors": "Ding Liu, Hui Li", "title": "Outlier Detection Using a Novel method: Quantum Clustering", "comments": "9 pages, 18 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new assumption in outlier detection: Normal data instances are\ncommonly located in the area that there is hardly any fluctuation on data\ndensity, while outliers are often appeared in the area that there is violent\nfluctuation on data density. And based on this hypothesis, we apply a novel\ndensity-based approach to unsupervised outlier detection. This approach, called\nQuantum Clustering (QC), deals with unlabeled data processing and constructs a\npotential function to find the centroids of clusters and the outliers. The\nexperiments show that the potential function could clearly find the hidden\noutliers in data points effectively. Besides, by using QC, we could find more\nsubtle outliers by adjusting the parameter $\\sigma$. Moreover, our approach is\nalso evaluated on two datasets (Air Quality Detection and Darwin Correspondence\nProject) from two different research areas, and the results show the wide\napplicability of our method.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jun 2020 17:19:41 GMT"}], "update_date": "2020-06-09", "authors_parsed": [["Liu", "Ding", ""], ["Li", "Hui", ""]]}, {"id": "2006.04766", "submitter": "Hongmei He Ph.D", "authors": "Hongmei He and Zhenhuan Zhu", "title": "A Heuristically Self-Organised Linguistic Attribute Deep Learning in\n  Edge Computing For IoT Intelligence", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the development of Internet of Things (IoT), IoT intelligence becomes\nemerging technology. \"Curse of Dimensionality\" is the barrier of data fusion in\nedge devices for the success of IoT intelligence. A Linguistic Attribute\nHierarchy (LAH), embedded with Linguistic Decision Trees (LDTs), can represent\na new attribute deep learning. In contrast to the conventional deep learning,\nan LAH could overcome the shortcoming of missing interpretation by providing\ntransparent information propagation through the rules, produced by LDTs in the\nLAH. Similar to the conventional deep learning, the computing complexity of\noptimising LAHs blocks the applications of LAHs. In this paper, we propose a\nheuristic approach to constructing an LAH, embedded with LDTs for decision\nmaking or classification by utilising the distance correlations between\nattributes and between attributes and the goal variable. The set of attributes\nis divided to some attribute clusters, and then they are heuristically\norganised to form a linguistic attribute hierarchy. The proposed approach was\nvalidated with some benchmark decision making or classification problems from\nthe UCI machine learning repository. The experimental results show that the\nproposed self-organisation algorithm can construct an effective and efficient\nlinguistic attribute hierarchy. Such a self-organised linguistic attribute\nhierarchy embedded with LDTs can not only efficiently tackle \"curse of\ndimensionality\" in a single LDT for data fusion with massive attributes, but\nalso achieve better or comparable performance on decision making or\nclassification, compared to the single LDT for the problem to be solved. The\nself-organisation algorithm is much efficient than the Genetic Algorithm in\nWrapper for the optimisation of LAHs. This makes it feasible to embed the\nself-organisation algorithm in edge devices for IoT intelligence.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jun 2020 17:36:05 GMT"}], "update_date": "2020-06-09", "authors_parsed": [["He", "Hongmei", ""], ["Zhu", "Zhenhuan", ""]]}, {"id": "2006.04778", "submitter": "Vijay Keswani", "authors": "L. Elisa Celis and Lingxiao Huang and Vijay Keswani and Nisheeth K.\n  Vishnoi", "title": "Fair Classification with Noisy Protected Attributes: A Framework with\n  Provable Guarantees", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CY cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an optimization framework for learning a fair classifier in the\npresence of noisy perturbations in the protected attributes. Compared to prior\nwork, our framework can be employed with a very general class of linear and\nlinear-fractional fairness constraints, can handle multiple, non-binary\nprotected attributes, and outputs a classifier that comes with provable\nguarantees on both accuracy and fairness. Empirically, we show that our\nframework can be used to attain either statistical rate or false positive rate\nfairness guarantees with a minimal loss in accuracy, even when the noise is\nlarge, in two real-world datasets.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jun 2020 17:52:48 GMT"}, {"version": "v2", "created": "Wed, 14 Oct 2020 14:18:18 GMT"}, {"version": "v3", "created": "Tue, 16 Feb 2021 17:21:58 GMT"}], "update_date": "2021-02-17", "authors_parsed": [["Celis", "L. Elisa", ""], ["Huang", "Lingxiao", ""], ["Keswani", "Vijay", ""], ["Vishnoi", "Nisheeth K.", ""]]}, {"id": "2006.04856", "submitter": "Julian Yarkony", "authors": "Naveed Haghani, Jiaoyang Li, Sven Koenig, Gautam Kunapuli, Claudio\n  Contardo, Julian Yarkony", "title": "Integer Programming for Multi-Robot Planning: A Column Generation\n  Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of coordinating a fleet of robots in a warehouse so\nas to maximize the reward achieved within a time limit while respecting problem\nand robot specific constraints. We formulate the problem as a weighted set\npacking problem where elements are defined as being the space-time positions a\nrobot can occupy and the items that can be picked up and delivered. We enforce\nthat robots do not collide, that each item is delivered at most once, and that\nthe number of robots active at any time does not exceed the total number\navailable. Since the set of robot routes is not enumerable, we attack\noptimization using column generation where pricing is a resource-constrained\nshortest-path problem.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jun 2020 18:19:14 GMT"}], "update_date": "2020-06-11", "authors_parsed": [["Haghani", "Naveed", ""], ["Li", "Jiaoyang", ""], ["Koenig", "Sven", ""], ["Kunapuli", "Gautam", ""], ["Contardo", "Claudio", ""], ["Yarkony", "Julian", ""]]}, {"id": "2006.04948", "submitter": "Andrew Critch PhD", "authors": "Andrew Critch, David Krueger", "title": "AI Research Considerations for Human Existential Safety (ARCHES)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Framed in positive terms, this report examines how technical AI research\nmight be steered in a manner that is more attentive to humanity's long-term\nprospects for survival as a species. In negative terms, we ask what existential\nrisks humanity might face from AI development in the next century, and by what\nprinciples contemporary technical research might be directed to address those\nrisks.\n  A key property of hypothetical AI technologies is introduced, called\n\\emph{prepotence}, which is useful for delineating a variety of potential\nexistential risks from artificial intelligence, even as AI paradigms might\nshift. A set of \\auxref{dirtot} contemporary research \\directions are then\nexamined for their potential benefit to existential safety. Each research\ndirection is explained with a scenario-driven motivation, and examples of\nexisting work from which to build. The research directions present their own\nrisks and benefits to society that could occur at various scales of impact, and\nin particular are not guaranteed to benefit existential safety if major\ndevelopments in them are deployed without adequate forethought and oversight.\nAs such, each direction is accompanied by a consideration of potentially\nnegative side effects.\n", "versions": [{"version": "v1", "created": "Sat, 30 May 2020 02:05:16 GMT"}], "update_date": "2020-06-11", "authors_parsed": [["Critch", "Andrew", ""], ["Krueger", "David", ""]]}, {"id": "2006.04986", "submitter": "Mojtaba Nayyeri", "authors": "Mojtaba Nayyeri, Sahar Vahdati, Can Aykul, Jens Lehmann", "title": "5* Knowledge Graph Embeddings with Projective Transformations", "comments": "Accepted in AAAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Performing link prediction using knowledge graph embedding models has become\na popular approach for knowledge graph completion. Such models employ a\ntransformation function that maps nodes via edges into a vector space in order\nto measure the likelihood of the links. While mapping the individual nodes, the\nstructure of subgraphs is also transformed. Most of the embedding models\ndesigned in Euclidean geometry usually support a single transformation type -\noften translation or rotation, which is suitable for learning on graphs with\nsmall differences in neighboring subgraphs. However, multi-relational knowledge\ngraphs often include multiple sub-graph structures in a neighborhood (e.g.\ncombinations of path and loop structures), which current embedding models do\nnot capture well. To tackle this problem, we propose a novel KGE model (5*E) in\nprojective geometry, which supports multiple simultaneous transformations -\nspecifically inversion, reflection, translation, rotation, and homothety. The\nmodel has several favorable theoretical properties and subsumes the existing\napproaches. It outperforms them on the most widely used link prediction\nbenchmarks\n", "versions": [{"version": "v1", "created": "Mon, 8 Jun 2020 23:28:07 GMT"}, {"version": "v2", "created": "Sun, 14 Mar 2021 16:46:48 GMT"}], "update_date": "2021-03-16", "authors_parsed": [["Nayyeri", "Mojtaba", ""], ["Vahdati", "Sahar", ""], ["Aykul", "Can", ""], ["Lehmann", "Jens", ""]]}, {"id": "2006.05022", "submitter": "Qinqing Zheng", "authors": "Arun Kumar Kuchibhotla and Qinqing Zheng", "title": "Near-Optimal Confidence Sequences for Bounded Random Variables", "comments": "Accepted to ICML 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.AI cs.LG stat.AP stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many inference problems, such as sequential decision problems like A/B\ntesting, adaptive sampling schemes like bandit selection, are often online in\nnature. The fundamental problem for online inference is to provide a sequence\nof confidence intervals that are valid uniformly over the growing-into-infinity\nsample sizes. To address this question, we provide a near-optimal confidence\nsequence for bounded random variables by utilizing Bentkus' concentration\nresults. We show that it improves on the existing approaches that use the\nCram{\\'e}r-Chernoff technique such as the Hoeffding, Bernstein, and Bennett\ninequalities. The resulting confidence sequence is confirmed to be favorable in\nboth synthetic coverage problems and an application to adaptive stopping\nalgorithms.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jun 2020 02:50:01 GMT"}, {"version": "v2", "created": "Sun, 14 Feb 2021 20:35:34 GMT"}, {"version": "v3", "created": "Thu, 3 Jun 2021 20:43:21 GMT"}], "update_date": "2021-06-07", "authors_parsed": [["Kuchibhotla", "Arun Kumar", ""], ["Zheng", "Qinqing", ""]]}, {"id": "2006.05044", "submitter": "Baocheng Zhu", "authors": "Baocheng Zhu, Shijun Wang and James Zhang", "title": "Neural Physicist: Learning Physical Dynamics from Image Sequences", "comments": "19 pages, 20 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We present a novel architecture named Neural Physicist (NeurPhy) to learn\nphysical dynamics directly from image sequences using deep neural networks. For\nany physical system, given the global system parameters, the time evolution of\nstates is governed by the underlying physical laws. How to learn meaningful\nsystem representations in an end-to-end way and estimate accurate state\ntransition dynamics facilitating long-term prediction have been long-standing\nchallenges. In this paper, by leveraging recent progresses in representation\nlearning and state space models (SSMs), we propose NeurPhy, which uses\nvariational auto-encoder (VAE) to extract underlying Markovian dynamic state at\neach time step, neural process (NP) to extract the global system parameters,\nand a non-linear non-recurrent stochastic state space model to learn the\nphysical dynamic transition. We apply NeurPhy to two physical experimental\nenvironments, i.e., damped pendulum and planetary orbits motion, and achieve\npromising results. Our model can not only extract the physically meaningful\nstate representations, but also learn the state transition dynamics enabling\nlong-term predictions for unseen image sequences. Furthermore, from the\nmanifold dimension of the latent state space, we can easily identify the degree\nof freedom (DoF) of the underlying physical systems.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jun 2020 04:36:51 GMT"}], "update_date": "2020-06-11", "authors_parsed": [["Zhu", "Baocheng", ""], ["Wang", "Shijun", ""], ["Zhang", "James", ""]]}, {"id": "2006.05048", "submitter": "Osonde Osoba Ph.D.", "authors": "Osonde A. Osoba, Raffaele Vardavas, Justin Grana, Rushil Zutshi, Amber\n  Jaycocks", "title": "Policy-focused Agent-based Modeling using RL Behavioral Models", "comments": "This is a more detailed version of a paper (\"Modeling Agent Behaviors\n  for Policy Analysis via Reinforcement Learning\") accepted to appear in IEEE\n  ICMLA 2020. This also corrects an error in Fig. 7 of the original arXiv\n  submission. Fig. 7 now specifies the right ABM architecture (\"flu\" instead of\n  \"tax\")", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Agent-based Models (ABMs) are valuable tools for policy analysis. ABMs help\nanalysts explore the emergent consequences of policy interventions in\nmulti-agent decision-making settings. But the validity of inferences drawn from\nABM explorations depends on the quality of the ABM agents' behavioral models.\nStandard specifications of agent behavioral models rely either on heuristic\ndecision-making rules or on regressions trained on past data. Both prior\nspecification modes have limitations. This paper examines the value of\nreinforcement learning (RL) models as adaptive, high-performing, and\nbehaviorally-valid models of agent decision-making in ABMs. We test the\nhypothesis that RL agents are effective as utility-maximizing agents in policy\nABMs. We also address the problem of adapting RL algorithms to handle\nmulti-agency in games by adapting and extending methods from recent literature.\nWe evaluate the performance of such RL-based ABM agents via experiments on two\npolicy-relevant ABMs: a minority game ABM, and an ABM of Influenza\nTransmission. We run some analytic experiments on our AI-equipped ABMs e.g.\nexplorations of the effects of behavioral heterogeneity in a population and the\nemergence of synchronization in a population. The experiments show that RL\nbehavioral models are effective at producing reward-seeking or\nreward-maximizing behaviors in ABM agents. Furthermore, RL behavioral models\ncan learn to outperform the default adaptive behavioral models in the two ABMs\nexamined.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jun 2020 04:55:07 GMT"}, {"version": "v2", "created": "Mon, 5 Oct 2020 19:28:48 GMT"}, {"version": "v3", "created": "Thu, 5 Nov 2020 20:41:17 GMT"}], "update_date": "2020-11-09", "authors_parsed": [["Osoba", "Osonde A.", ""], ["Vardavas", "Raffaele", ""], ["Grana", "Justin", ""], ["Zutshi", "Rushil", ""], ["Jaycocks", "Amber", ""]]}, {"id": "2006.05051", "submitter": "Thodoris Lykouris", "authors": "Kiant\\'e Brantley, Miroslav Dudik, Thodoris Lykouris, Sobhan\n  Miryoosefi, Max Simchowitz, Aleksandrs Slivkins, Wen Sun", "title": "Constrained episodic reinforcement learning in concave-convex and\n  knapsack settings", "comments": "The NeurIPS 2020 version of this paper includes a small bug, leading\n  to an incorrect dependence on H in Theorem 3.4. This version fixes it by\n  adjusting Eq. (9), Theorem 3.4 and the relevant proofs. Changes in the main\n  text are noted in red. Changes in the appendix are limited to Appendices B.1,\n  B.5, and B.6 and the statement of Lemma F.3", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an algorithm for tabular episodic reinforcement learning with\nconstraints. We provide a modular analysis with strong theoretical guarantees\nfor settings with concave rewards and convex constraints, and for settings with\nhard constraints (knapsacks). Most of the previous work in constrained\nreinforcement learning is limited to linear constraints, and the remaining work\nfocuses on either the feasibility question or settings with a single episode.\nOur experiments demonstrate that the proposed algorithm significantly\noutperforms these approaches in existing constrained episodic environments.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jun 2020 05:02:44 GMT"}, {"version": "v2", "created": "Sun, 6 Jun 2021 03:30:29 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Brantley", "Kiant\u00e9", ""], ["Dudik", "Miroslav", ""], ["Lykouris", "Thodoris", ""], ["Miryoosefi", "Sobhan", ""], ["Simchowitz", "Max", ""], ["Slivkins", "Aleksandrs", ""], ["Sun", "Wen", ""]]}, {"id": "2006.05076", "submitter": "Kun Kuang", "authors": "Kun Kuang, Bo Li, Peng Cui, Yue Liu, Jianrong Tao, Yueting Zhuang and\n  Fei Wu", "title": "Stable Prediction via Leveraging Seed Variable", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we focus on the problem of stable prediction across unknown\ntest data, where the test distribution is agnostic and might be totally\ndifferent from the training one. In such a case, previous machine learning\nmethods might exploit subtly spurious correlations in training data induced by\nnon-causal variables for prediction. Those spurious correlations are changeable\nacross data, leading to instability of prediction across data. By assuming the\nrelationships between causal variables and response variable are invariant\nacross data, to address this problem, we propose a conditional independence\ntest based algorithm to separate those causal variables with a seed variable as\npriori, and adopt them for stable prediction. By assuming the independence\nbetween causal and non-causal variables, we show, both theoretically and with\nempirical experiments, that our algorithm can precisely separate causal and\nnon-causal variables for stable prediction across test data. Extensive\nexperiments on both synthetic and real-world datasets demonstrate that our\nalgorithm outperforms state-of-the-art methods for stable prediction.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jun 2020 06:56:31 GMT"}], "update_date": "2020-06-11", "authors_parsed": [["Kuang", "Kun", ""], ["Li", "Bo", ""], ["Cui", "Peng", ""], ["Liu", "Yue", ""], ["Tao", "Jianrong", ""], ["Zhuang", "Yueting", ""], ["Wu", "Fei", ""]]}, {"id": "2006.05078", "submitter": "Samuel Daulton", "authors": "Samuel Daulton, Maximilian Balandat, Eytan Bakshy", "title": "Differentiable Expected Hypervolume Improvement for Parallel\n  Multi-Objective Bayesian Optimization", "comments": "To appear in Advances in Neural Information Processing Systems 33,\n  2020. Code is available at https://github.com/pytorch/botorch", "journal-ref": "Advances in Neural Information Processing Systems 33, 2020", "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many real-world scenarios, decision makers seek to efficiently optimize\nmultiple competing objectives in a sample-efficient fashion. Multi-objective\nBayesian optimization (BO) is a common approach, but many of the\nbest-performing acquisition functions do not have known analytic gradients and\nsuffer from high computational overhead. We leverage recent advances in\nprogramming models and hardware acceleration for multi-objective BO using\nExpected Hypervolume Improvement (EHVI)---an algorithm notorious for its high\ncomputational complexity. We derive a novel formulation of q-Expected\nHypervolume Improvement (qEHVI), an acquisition function that extends EHVI to\nthe parallel, constrained evaluation setting. qEHVI is an exact computation of\nthe joint EHVI of q new candidate points (up to Monte-Carlo (MC) integration\nerror). Whereas previous EHVI formulations rely on gradient-free acquisition\noptimization or approximated gradients, we compute exact gradients of the MC\nestimator via auto-differentiation, thereby enabling efficient and effective\noptimization using first-order and quasi-second-order methods. Our empirical\nevaluation demonstrates that qEHVI is computationally tractable in many\npractical scenarios and outperforms state-of-the-art multi-objective BO\nalgorithms at a fraction of their wall time.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jun 2020 06:57:47 GMT"}, {"version": "v2", "created": "Thu, 11 Jun 2020 19:41:18 GMT"}, {"version": "v3", "created": "Fri, 23 Oct 2020 04:20:57 GMT"}], "update_date": "2020-11-12", "authors_parsed": [["Daulton", "Samuel", ""], ["Balandat", "Maximilian", ""], ["Bakshy", "Eytan", ""]]}, {"id": "2006.05133", "submitter": "Andrea Aler Tubella", "authors": "Andrea Aler Tubella, Andreas Theodorou, Virginia Dignum, Loizos\n  Michael", "title": "Contestable Black Boxes", "comments": "Accepted at RuleML 2020 as a short paper", "journal-ref": null, "doi": "10.1007/978-3-030-57977-7_12", "report-no": null, "categories": "cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The right to contest a decision with consequences on individuals or the\nsociety is a well-established democratic right. Despite this right also being\nexplicitly included in GDPR in reference to automated decision-making, its\nstudy seems to have received much less attention in the AI literature compared,\nfor example, to the right for explanation. This paper investigates the type of\nassurances that are needed in the contesting process when algorithmic\nblack-boxes are involved, opening new questions about the interplay of\ncontestability and explainability. We argue that specialised complementary\nmethodologies to evaluate automated decision-making in the case of a particular\ndecision being contested need to be developed. Further, we propose a\ncombination of well-established software engineering and rule-based approaches\nas a possible socio-technical solution to the issue of contestability, one of\nthe new democratic challenges posed by the automation of decision making.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jun 2020 09:09:00 GMT"}, {"version": "v2", "created": "Tue, 30 Jun 2020 14:49:12 GMT"}], "update_date": "2020-09-18", "authors_parsed": [["Tubella", "Andrea Aler", ""], ["Theodorou", "Andreas", ""], ["Dignum", "Virginia", ""], ["Michael", "Loizos", ""]]}, {"id": "2006.05159", "submitter": "Albert Dulian", "authors": "Albert Dulian and John C. Murray", "title": "Physically constrained short-term vehicle trajectory forecasting with\n  naive semantic maps", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Urban environments manifest a high level of complexity, and therefore it is\nof vital importance for safety systems embedded within autonomous vehicles\n(AVs) to be able to accurately predict the short-term future motion of nearby\nagents. This problem can be further understood as generating a sequence of\nfuture coordinates for a given agent based on its past motion data e.g.\nposition, velocity, acceleration etc, and whilst current approaches demonstrate\nplausible results they have a propensity to neglect a scene's physical\nconstrains. In this paper we propose the model based on a combination of the\nCNN and LSTM encoder-decoder architecture that learns to extract a relevant\nroad features from semantic maps as well as general motion of agents and uses\nthis learned representation to predict their short-term future trajectories. We\ntrain and validate the model on the publicly available dataset that provides\ndata from urban areas, allowing us to examine it in challenging and uncertain\nscenarios. We show that our model is not only capable of anticipating future\nmotion whilst taking into consideration road boundaries, but can also\neffectively and precisely predict trajectories for a longer time horizon than\ninitially trained for.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jun 2020 09:52:44 GMT"}], "update_date": "2020-06-11", "authors_parsed": [["Dulian", "Albert", ""], ["Murray", "John C.", ""]]}, {"id": "2006.05163", "submitter": "Vaishali Pal", "authors": "Vaishali Pal, Manish Shrivastava and Laurent Besacier", "title": "ConfNet2Seq: Full Length Answer Generation from Spoken Questions", "comments": "Accepted at Text, Speech and Dialogue, 2020", "journal-ref": "ConfNet2Seq, Text, Speech, and Dialogue - 23rd International\n  Conference, {TSD}, Brno, Czech Republic, September 8-11, 2020, Proceedings,\n  12284, 2020, 524-531 (2020)", "doi": "10.1007/978-3-030-58323-1_56", "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conversational and task-oriented dialogue systems aim to interact with the\nuser using natural responses through multi-modal interfaces, such as text or\nspeech. These desired responses are in the form of full-length natural answers\ngenerated over facts retrieved from a knowledge source. While the task of\ngenerating natural answers to questions from an answer span has been widely\nstudied, there has been little research on natural sentence generation over\nspoken content. We propose a novel system to generate full length natural\nlanguage answers from spoken questions and factoid answers. The spoken sequence\nis compactly represented as a confusion network extracted from a pre-trained\nAutomatic Speech Recognizer. This is the first attempt towards generating\nfull-length natural answers from a graph input(confusion network) to the best\nof our knowledge. We release a large-scale dataset of 259,788 samples of spoken\nquestions, their factoid answers and corresponding full-length textual answers.\nFollowing our proposed approach, we achieve comparable performance with best\nASR hypothesis.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jun 2020 10:04:49 GMT"}, {"version": "v2", "created": "Thu, 11 Jun 2020 08:39:41 GMT"}], "update_date": "2020-09-24", "authors_parsed": [["Pal", "Vaishali", ""], ["Shrivastava", "Manish", ""], ["Besacier", "Laurent", ""]]}, {"id": "2006.05188", "submitter": "Jeremias Knoblauch", "authors": "Jeremias Knoblauch, Hisham Husain, Tom Diethe", "title": "Optimal Continual Learning has Perfect Memory and is NP-hard", "comments": "Accepted for publication at ICML (International Conference on Machine\n  Learning) 2020; 13 pages, 8 Figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Continual Learning (CL) algorithms incrementally learn a predictor or\nrepresentation across multiple sequentially observed tasks. Designing CL\nalgorithms that perform reliably and avoid so-called catastrophic forgetting\nhas proven a persistent challenge. The current paper develops a theoretical\napproach that explains why. In particular, we derive the computational\nproperties which CL algorithms would have to possess in order to avoid\ncatastrophic forgetting. Our main finding is that such optimal CL algorithms\ngenerally solve an NP-hard problem and will require perfect memory to do so.\nThe findings are of theoretical interest, but also explain the excellent\nperformance of CL algorithms using experience replay, episodic memory and core\nsets relative to regularization-based approaches.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jun 2020 11:20:38 GMT"}], "update_date": "2020-06-11", "authors_parsed": [["Knoblauch", "Jeremias", ""], ["Husain", "Hisham", ""], ["Diethe", "Tom", ""]]}, {"id": "2006.05203", "submitter": "Travis LaCroix", "authors": "Travis LaCroix and Aydin Mohseni", "title": "The Tragedy of the AI Commons", "comments": "40 Pages, 5 Figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.GT cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Policy and guideline proposals for ethical artificial-intelligence research\nhave proliferated in recent years. These are supposed to guide the\nsocially-responsible development of AI for the common good. However, there\ntypically exist incentives for non-cooperation (i.e., non-adherence to such\npolicies and guidelines); and, these proposals often lack effective mechanisms\nto enforce their own normative claims. The situation just described constitutes\na social dilemma; namely, a situation where no one has an individual incentive\nto cooperate, though mutual cooperation would lead to the best outcome for all\ninvolved. In this paper, we use stochastic evolutionary game dynamics to model\nthis social dilemma in the context of the ethical development of artificial\nintelligence. This formalism allows us to isolate variables that may be\nintervened upon, thus providing actionable suggestions for increased\ncooperation amongst numerous stakeholders in AI. Our results show how\nstochastic effects can help make cooperation viable in such a scenario. They\nsuggest that coordination for a common good should be attempted in smaller\ngroups in which the cost for cooperation is low, and the perceived risk of\nfailure is high. This provides insight into the conditions under which we\nshould expect such ethics proposals to be successful with regard to their\nscope, scale, and content.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jun 2020 12:01:01 GMT"}, {"version": "v2", "created": "Mon, 18 Jan 2021 19:07:13 GMT"}], "update_date": "2021-01-20", "authors_parsed": [["LaCroix", "Travis", ""], ["Mohseni", "Aydin", ""]]}, {"id": "2006.05219", "submitter": "Amir Ahooye Atashin", "authors": "Majid Mohammadi, Amir Ahooye Atashin, Wout Hofman, Yao-Hua Tan", "title": "SANOM Results for OAEI 2019", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Simulated annealing-based ontology matching (SANOM) participates for the\nsecond time at the ontology alignment evaluation initiative (OAEI) 2019. This\npaper contains the configuration of SANOM and its results on the anatomy and\nconference tracks. In comparison to the OAEI 2017, SANOM has improved\nsignificantly, and its results are competitive with the state-of-the-art\nsystems. In particular, SANOM has the highest recall rate among the\nparticipated systems in the conference track, and is competitive with AML, the\nbest performing system, in terms of F-measure. SANOM is also competitive with\nLogMap on the anatomy track, which is the best performing system in this track\nwith no usage of particular biomedical background knowledge. SANOM has been\nadapted to the HOBBIT platfrom and is now available for the registered users.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jun 2020 12:33:47 GMT"}], "update_date": "2020-06-11", "authors_parsed": [["Mohammadi", "Majid", ""], ["Atashin", "Amir Ahooye", ""], ["Hofman", "Wout", ""], ["Tan", "Yao-Hua", ""]]}, {"id": "2006.05241", "submitter": "Ashutosh Kumar Tiwari", "authors": "Ashutosh Kumar Tiwari, Sandeep Varma Nadimpalli", "title": "New Fusion Algorithm provides an alternative approach to Robotic Path\n  planning", "comments": "7 pages, 3 figures", "journal-ref": "International Journal of Information Engineering and Electronic\n  Business(IJIEEB), Vol.12, No.3, pp. 1-7, 2020", "doi": "10.5815/ijieeb.2020.03.01", "report-no": null, "categories": "cs.RO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For rapid growth in technology and automation, human tasks are being taken\nover by robots as robots have proven to be better with both speed and\nprecision. One of the major and widespread usages of these robots is in the\nindustrial businesses, where they are employed to carry massive loads in and\naround work areas. As these working environments might not be completely\nlocalized and could be dynamically changing, new approaches must be evaluated\nto guarantee a crash-free way of performing duties. This paper presents a new\nand efficient fusion algorithm for solving the path planning problem in a\ncustom 2D environment. This fusion algorithm integrates an improved and\noptimized version of both, A* algorithm and the Artificial potential field\nmethod. Firstly, an initial or preliminary path is planned in the environmental\nmodel by adopting the A* algorithm. The heuristic function of this A* algorithm\nis optimized and improved according to the environmental model. This is\nfollowed by selecting and saving the key nodes in the initial path. Lastly, on\nthe basis of these saved key nodes, path smoothing is done by artificial\npotential field method. Our simulation results carried out using Python viz.\nlibraries indicate that the new fusion algorithm is feasible and superior in\nsmoothness performance and can satisfy as a time-efficient and cheaper\nalternative to conventional A* strategies of path planning.\n", "versions": [{"version": "v1", "created": "Sat, 6 Jun 2020 17:52:00 GMT"}], "update_date": "2020-06-11", "authors_parsed": [["Tiwari", "Ashutosh Kumar", ""], ["Nadimpalli", "Sandeep Varma", ""]]}, {"id": "2006.05249", "submitter": "Daniel Harari", "authors": "Hanna Benoni, Daniel Harari and Shimon Ullman", "title": "What takes the brain so long: Object recognition at the level of minimal\n  images develops for up to seconds of presentation time", "comments": "7 pages, 2 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Rich empirical evidence has shown that visual object recognition in the brain\nis fast and effortless, with relevant brain signals reported to start as early\nas 80 ms. Here we study the time trajectory of the recognition process at the\nlevel of minimal recognizable images (termed MIRC). These are images that can\nbe recognized reliably, but in which a minute change of the image (reduction by\neither size or resolution) has a drastic effect on recognition. Subjects were\nassigned to one of nine exposure conditions: 200, 500, 1000, 2000 ms with or\nwithout masking, as well as unlimited time. The subjects were not limited in\ntime to respond after presentation. The results show that in the masked\nconditions, recognition rates develop gradually over an extended period, e.g.\naverage of 18% for 200 ms exposure and 45% for 500 ms, increasing significantly\nwith longer exposure even above 2 secs. When presented for unlimited time\n(until response), MIRC recognition rates were equivalent to the rates of\nfull-object images presented for 50 ms followed by masking. What takes the\nbrain so long to recognize such images? We discuss why processes involving\neye-movements, perceptual decision-making and pattern completion are unlikely\nexplanations. Alternatively, we hypothesize that MIRC recognition requires an\nextended top-down process complementing the feed-forward phase.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jun 2020 13:33:04 GMT"}], "update_date": "2020-06-11", "authors_parsed": [["Benoni", "Hanna", ""], ["Harari", "Daniel", ""], ["Ullman", "Shimon", ""]]}, {"id": "2006.05255", "submitter": "\\'Angel Gonz\\'alez-Prieto", "authors": "Jes\\'us Bobadilla, Ra\\'ul Lara-Cabrera, \\'Angel Gonz\\'alez-Prieto,\n  Fernando Ortega", "title": "DeepFair: Deep Learning for Improving Fairness in Recommender Systems", "comments": "18 pages, 9 figures, 4 tables", "journal-ref": "International Journal of Interactive Multimedia and Artificial\n  Intelligence, 2020", "doi": "10.9781/ijimai.2020.11.001", "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The lack of bias management in Recommender Systems leads to minority groups\nreceiving unfair recommendations. Moreover, the trade-off between equity and\nprecision makes it difficult to obtain recommendations that meet both criteria.\nHere we propose a Deep Learning based Collaborative Filtering algorithm that\nprovides recommendations with an optimum balance between fairness and accuracy\nwithout knowing demographic information about the users. Experimental results\nshow that it is possible to make fair recommendations without losing a\nsignificant proportion of accuracy.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jun 2020 13:39:38 GMT"}], "update_date": "2020-12-22", "authors_parsed": [["Bobadilla", "Jes\u00fas", ""], ["Lara-Cabrera", "Ra\u00fal", ""], ["Gonz\u00e1lez-Prieto", "\u00c1ngel", ""], ["Ortega", "Fernando", ""]]}, {"id": "2006.05398", "submitter": "Danny Driess", "authors": "Danny Driess, Jung-Su Ha, Marc Toussaint", "title": "Deep Visual Reasoning: Learning to Predict Action Sequences for Task and\n  Motion Planning from an Initial Scene Image", "comments": "Robotics: Science and Systems (R:SS) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a deep convolutional recurrent neural network that\npredicts action sequences for task and motion planning (TAMP) from an initial\nscene image. Typical TAMP problems are formalized by combining reasoning on a\nsymbolic, discrete level (e.g. first-order logic) with continuous motion\nplanning such as nonlinear trajectory optimization. Due to the great\ncombinatorial complexity of possible discrete action sequences, a large number\nof optimization/motion planning problems have to be solved to find a solution,\nwhich limits the scalability of these approaches.\n  To circumvent this combinatorial complexity, we develop a neural network\nwhich, based on an initial image of the scene, directly predicts promising\ndiscrete action sequences such that ideally only one motion planning problem\nhas to be solved to find a solution to the overall TAMP problem. A key aspect\nis that our method generalizes to scenes with many and varying number of\nobjects, although being trained on only two objects at a time. This is possible\nby encoding the objects of the scene in images as input to the neural network,\ninstead of a fixed feature vector. Results show runtime improvements of several\nmagnitudes. Video: https://youtu.be/i8yyEbbvoEk\n", "versions": [{"version": "v1", "created": "Tue, 9 Jun 2020 16:52:02 GMT"}], "update_date": "2020-06-11", "authors_parsed": [["Driess", "Danny", ""], ["Ha", "Jung-Su", ""], ["Toussaint", "Marc", ""]]}, {"id": "2006.05405", "submitter": "Shangqing Liu", "authors": "Shangqing Liu, Yu Chen, Xiaofei Xie, Jingkai Siow, Yang Liu", "title": "Retrieval-Augmented Generation for Code Summarization via Hybrid GNN", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Source code summarization aims to generate natural language summaries from\nstructured code snippets for better understanding code functionalities.\nHowever, automatic code summarization is challenging due to the complexity of\nthe source code and the language gap between the source code and natural\nlanguage summaries. Most previous approaches either rely on retrieval-based\n(which can take advantage of similar examples seen from the retrieval database,\nbut have low generalization performance) or generation-based methods (which\nhave better generalization performance, but cannot take advantage of similar\nexamples). This paper proposes a novel retrieval-augmented mechanism to combine\nthe benefits of both worlds. Furthermore, to mitigate the limitation of Graph\nNeural Networks (GNNs) on capturing global graph structure information of\nsource code, we propose a novel attention-based dynamic graph to complement the\nstatic graph representation of the source code, and design a hybrid message\npassing GNN for capturing both the local and global structural information. To\nevaluate the proposed approach, we release a new challenging benchmark, crawled\nfrom diversified large-scale open-source C projects (total 95k+ unique\nfunctions in the dataset). Our method achieves the state-of-the-art\nperformance, improving existing methods by 1.42, 2.44 and 1.29 in terms of\nBLEU-4, ROUGE-L and METEOR.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jun 2020 17:09:29 GMT"}, {"version": "v2", "created": "Sun, 4 Oct 2020 08:06:49 GMT"}, {"version": "v3", "created": "Mon, 23 Nov 2020 11:38:37 GMT"}, {"version": "v4", "created": "Thu, 26 Nov 2020 05:33:27 GMT"}, {"version": "v5", "created": "Thu, 13 May 2021 03:41:22 GMT"}], "update_date": "2021-05-14", "authors_parsed": [["Liu", "Shangqing", ""], ["Chen", "Yu", ""], ["Xie", "Xiaofei", ""], ["Siow", "Jingkai", ""], ["Liu", "Yang", ""]]}, {"id": "2006.05443", "submitter": "Yinlam Chow", "authors": "Yinlam Chow and Brandon Cui and MoonKyung Ryu and Mohammad Ghavamzadeh", "title": "Variational Model-based Policy Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Model-based reinforcement learning (RL) algorithms allow us to combine\nmodel-generated data with those collected from interaction with the real system\nin order to alleviate the data efficiency problem in RL. However, designing\nsuch algorithms is often challenging because the bias in simulated data may\novershadow the ease of data generation. A potential solution to this challenge\nis to jointly learn and improve model and policy using a universal objective\nfunction. In this paper, we leverage the connection between RL and\nprobabilistic inference, and formulate such an objective function as a\nvariational lower-bound of a log-likelihood. This allows us to use expectation\nmaximization (EM) and iteratively fix a baseline policy and learn a variational\ndistribution, consisting of a model and a policy (E-step), followed by\nimproving the baseline policy given the learned variational distribution\n(M-step). We propose model-based and model-free policy iteration (actor-critic)\nstyle algorithms for the E-step and show how the variational distribution\nlearned by them can be used to optimize the M-step in a fully model-based\nfashion. Our experiments on a number of continuous control tasks show that\ndespite being more complex, our model-based (E-step) algorithm, called {\\em\nvariational model-based policy optimization} (VMBPO), is more sample-efficient\nand robust to hyper-parameter tuning than its model-free (E-step) counterpart.\nUsing the same control tasks, we also compare VMBPO with several\nstate-of-the-art model-based and model-free RL algorithms and show its sample\nefficiency and performance.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jun 2020 18:30:15 GMT"}, {"version": "v2", "created": "Wed, 24 Jun 2020 01:00:51 GMT"}], "update_date": "2020-06-25", "authors_parsed": [["Chow", "Yinlam", ""], ["Cui", "Brandon", ""], ["Ryu", "MoonKyung", ""], ["Ghavamzadeh", "Mohammad", ""]]}, {"id": "2006.05595", "submitter": "Srijita Das", "authors": "Srijita Das, Sriraam Natarajan, Kaushik Roy, Ronald Parr and Kristian\n  Kersting", "title": "Fitted Q-Learning for Relational Domains", "comments": "10 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of Approximate Dynamic Programming in relational\ndomains. Inspired by the success of fitted Q-learning methods in propositional\nsettings, we develop the first relational fitted Q-learning algorithms by\nrepresenting the value function and Bellman residuals. When we fit the\nQ-functions, we show how the two steps of Bellman operator; application and\nprojection steps can be performed using a gradient-boosting technique. Our\nproposed framework performs reasonably well on standard domains without using\ndomain models and using fewer training trajectories.\n", "versions": [{"version": "v1", "created": "Wed, 10 Jun 2020 01:18:47 GMT"}], "update_date": "2020-06-11", "authors_parsed": [["Das", "Srijita", ""], ["Natarajan", "Sriraam", ""], ["Roy", "Kaushik", ""], ["Parr", "Ronald", ""], ["Kersting", "Kristian", ""]]}, {"id": "2006.05608", "submitter": "Mohammad Pirhooshyaran", "authors": "Mohammad Pirhooshyaran, Lawrence V. Snyder", "title": "Simultaneous Decision Making for Stochastic Multi-echelon Inventory\n  Optimization with Deep Neural Networks as Decision Makers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a framework that uses deep neural networks (DNN) to optimize\ninventory decisions in complex multi-echelon supply chains. We first introduce\npairwise modeling of general stochastic multi-echelon inventory optimization\n(SMEIO). Then, we present a framework which uses DNN agents to directly\ndetermine order-up-to levels between any adjacent pair of nodes in the supply\nchain. Our model considers a finite horizon and accounts for the initial\ninventory conditions. Our method is suitable for a wide variety of supply chain\nnetworks, including general topologies that may contain both assembly and\ndistribution nodes, and systems with nonlinear cost structures. We first\nnumerically demonstrate the effectiveness of the method by showing that its\nsolutions are close to the optimal solutions for single-node and serial supply\nchain networks, for which exact methods are available. Then, we investigate\nmore general supply chain networks and find that the proposed method performs\nbetter in terms of both objective function values and the number of\ninteractions with the environment compared to alternate methods.\n", "versions": [{"version": "v1", "created": "Wed, 10 Jun 2020 02:02:52 GMT"}, {"version": "v2", "created": "Tue, 23 Mar 2021 10:47:26 GMT"}], "update_date": "2021-03-24", "authors_parsed": [["Pirhooshyaran", "Mohammad", ""], ["Snyder", "Lawrence V.", ""]]}, {"id": "2006.05635", "submitter": "Longshaokan Wang", "authors": "Longshaokan Wang, Maryam Fazel-Zarandi, Aditya Tiwari, Spyros\n  Matsoukas, Lazaros Polymenakos", "title": "Data Augmentation for Training Dialog Models Robust to Speech\n  Recognition Errors", "comments": "To be presented at 2nd Workshop on NLP for ConvAI, ACL 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Speech-based virtual assistants, such as Amazon Alexa, Google assistant, and\nApple Siri, typically convert users' audio signals to text data through\nautomatic speech recognition (ASR) and feed the text to downstream dialog\nmodels for natural language understanding and response generation. The ASR\noutput is error-prone; however, the downstream dialog models are often trained\non error-free text data, making them sensitive to ASR errors during inference\ntime. To bridge the gap and make dialog models more robust to ASR errors, we\nleverage an ASR error simulator to inject noise into the error-free text data,\nand subsequently train the dialog models with the augmented data. Compared to\nother approaches for handling ASR errors, such as using ASR lattice or\nend-to-end methods, our data augmentation approach does not require any\nmodification to the ASR or downstream dialog models; our approach also does not\nintroduce any additional latency during inference time. We perform extensive\nexperiments on benchmark data and show that our approach improves the\nperformance of downstream dialog models in the presence of ASR errors, and it\nis particularly effective in the low-resource situations where there are\nconstraints on model size or the training data is scarce.\n", "versions": [{"version": "v1", "created": "Wed, 10 Jun 2020 03:18:15 GMT"}], "update_date": "2020-06-11", "authors_parsed": [["Wang", "Longshaokan", ""], ["Fazel-Zarandi", "Maryam", ""], ["Tiwari", "Aditya", ""], ["Matsoukas", "Spyros", ""], ["Polymenakos", "Lazaros", ""]]}, {"id": "2006.05714", "submitter": "Giorgio Visani Mr", "authors": "Giorgio Visani, Enrico Bagli, Federico Chesani", "title": "OptiLIME: Optimized LIME Explanations for Diagnostic Computer Algorithms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Local Interpretable Model-Agnostic Explanations (LIME) is a popular method to\nperform interpretability of any kind of Machine Learning (ML) model. It\nexplains one ML prediction at a time, by learning a simple linear model around\nthe prediction. The model is trained on randomly generated data points, sampled\nfrom the training dataset distribution and weighted according to the distance\nfrom the reference point - the one being explained by LIME. Feature selection\nis applied to keep only the most important variables. LIME is widespread across\ndifferent domains, although its instability - a single prediction may obtain\ndifferent explanations - is one of the major shortcomings. This is due to the\nrandomness in the sampling step, as well as to the flexibility in tuning the\nweights and determines a lack of reliability in the retrieved explanations,\nmaking LIME adoption problematic. In Medicine especially, clinical\nprofessionals trust is mandatory to determine the acceptance of an explainable\nalgorithm, considering the importance of the decisions at stake and the related\nlegal issues. In this paper, we highlight a trade-off between explanation's\nstability and adherence, namely how much it resembles the ML model. Exploiting\nour innovative discovery, we propose a framework to maximise stability, while\nretaining a predefined level of adherence. OptiLIME provides freedom to choose\nthe best adherence-stability trade-off level and more importantly, it clearly\nhighlights the mathematical properties of the retrieved explanation. As a\nresult, the practitioner is provided with tools to decide whether the\nexplanation is reliable, according to the problem at hand. We extensively test\nOptiLIME on a toy dataset - to present visually the geometrical findings - and\na medical dataset. In the latter, we show how the method comes up with\nmeaningful explanations both from a medical and mathematical standpoint.\n", "versions": [{"version": "v1", "created": "Wed, 10 Jun 2020 08:10:37 GMT"}, {"version": "v2", "created": "Wed, 29 Jul 2020 10:40:26 GMT"}], "update_date": "2020-07-30", "authors_parsed": [["Visani", "Giorgio", ""], ["Bagli", "Enrico", ""], ["Chesani", "Federico", ""]]}, {"id": "2006.05729", "submitter": "Shray Bansal", "authors": "Shray Bansal, Jin Xu, Ayanna Howard, Charles Isbell", "title": "A Bayesian Framework for Nash Equilibrium Inference in Human-Robot\n  Parallel Play", "comments": "Accepted at Robotics: Science and Systems (RSS) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.GT cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider shared workspace scenarios with humans and robots acting to\nachieve independent goals, termed as parallel play. We model these as\ngeneral-sum games and construct a framework that utilizes the Nash equilibrium\nsolution concept to consider the interactive effect of both agents while\nplanning. We find multiple Pareto-optimal equilibria in these tasks. We\nhypothesize that people act by choosing an equilibrium based on social norms\nand their personalities. To enable coordination, we infer the equilibrium\nonline using a probabilistic model that includes these two factors and use it\nto select the robot's action. We apply our approach to a close-proximity\npick-and-place task involving a robot and a simulated human with three\npotential behaviors - defensive, selfish, and norm-following. We showed that\nusing a Bayesian approach to infer the equilibrium enables the robot to\ncomplete the task with less than half the number of collisions while also\nreducing the task execution time as compared to the best baseline. We also\nperformed a study with human participants interacting either with other humans\nor with different robot agents and observed that our proposed approach performs\nsimilar to human-human parallel play interactions. The code is available at\nhttps://github.com/shray/bayes-nash\n", "versions": [{"version": "v1", "created": "Wed, 10 Jun 2020 08:38:49 GMT"}], "update_date": "2020-06-11", "authors_parsed": [["Bansal", "Shray", ""], ["Xu", "Jin", ""], ["Howard", "Ayanna", ""], ["Isbell", "Charles", ""]]}, {"id": "2006.05754", "submitter": "Mattia Antonino Di Gangi", "authors": "Luisa Bentivogli and Beatrice Savoldi and Matteo Negri and Mattia\n  Antonino Di Gangi and Roldano Cattoni and Marco Turchi", "title": "Gender in Danger? Evaluating Speech Translation Technology on the\n  MuST-SHE Corpus", "comments": "9 pages of content, accepted at ACL 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.SD eess.AS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Translating from languages without productive grammatical gender like English\ninto gender-marked languages is a well-known difficulty for machines. This\ndifficulty is also due to the fact that the training data on which models are\nbuilt typically reflect the asymmetries of natural languages, gender bias\nincluded. Exclusively fed with textual data, machine translation is\nintrinsically constrained by the fact that the input sentence does not always\ncontain clues about the gender identity of the referred human entities. But\nwhat happens with speech translation, where the input is an audio signal? Can\naudio provide additional information to reduce gender bias? We present the\nfirst thorough investigation of gender bias in speech translation, contributing\nwith: i) the release of a benchmark useful for future studies, and ii) the\ncomparison of different technologies (cascade and end-to-end) on two language\ndirections (English-Italian/French).\n", "versions": [{"version": "v1", "created": "Wed, 10 Jun 2020 09:55:38 GMT"}], "update_date": "2020-06-11", "authors_parsed": [["Bentivogli", "Luisa", ""], ["Savoldi", "Beatrice", ""], ["Negri", "Matteo", ""], ["Di Gangi", "Mattia Antonino", ""], ["Cattoni", "Roldano", ""], ["Turchi", "Marco", ""]]}, {"id": "2006.05779", "submitter": "Xin Xin", "authors": "Xin Xin, Alexandros Karatzoglou, Ioannis Arapakis, Joemon M. Jose", "title": "Self-Supervised Reinforcement Learning for Recommender Systems", "comments": "SIGIR2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In session-based or sequential recommendation, it is important to consider a\nnumber of factors like long-term user engagement, multiple types of user-item\ninteractions such as clicks, purchases etc. The current state-of-the-art\nsupervised approaches fail to model them appropriately. Casting sequential\nrecommendation task as a reinforcement learning (RL) problem is a promising\ndirection. A major component of RL approaches is to train the agent through\ninteractions with the environment. However, it is often problematic to train a\nrecommender in an on-line fashion due to the requirement to expose users to\nirrelevant recommendations. As a result, learning the policy from logged\nimplicit feedback is of vital importance, which is challenging due to the pure\noff-policy setting and lack of negative rewards (feedback). In this paper, we\npropose self-supervised reinforcement learning for sequential recommendation\ntasks. Our approach augments standard recommendation models with two output\nlayers: one for self-supervised learning and the other for RL. The RL part acts\nas a regularizer to drive the supervised layer focusing on specific\nrewards(e.g., recommending items which may lead to purchases rather than\nclicks) while the self-supervised layer with cross-entropy loss provides strong\ngradient signals for parameter updates. Based on such an approach, we propose\ntwo frameworks namely Self-Supervised Q-learning(SQN) and Self-Supervised\nActor-Critic(SAC). We integrate the proposed frameworks with four\nstate-of-the-art recommendation models. Experimental results on two real-world\ndatasets demonstrate the effectiveness of our approach.\n", "versions": [{"version": "v1", "created": "Wed, 10 Jun 2020 11:18:57 GMT"}, {"version": "v2", "created": "Thu, 11 Jun 2020 09:36:45 GMT"}], "update_date": "2020-06-12", "authors_parsed": [["Xin", "Xin", ""], ["Karatzoglou", "Alexandros", ""], ["Arapakis", "Ioannis", ""], ["Jose", "Joemon M.", ""]]}, {"id": "2006.05821", "submitter": "Mustafa Gunel", "authors": "Anil Ozturk, Mustafa Burak Gunel, Melih Dal, Ugur Yavas, Nazim Kemal\n  Ure", "title": "Development of A Stochastic Traffic Environment with Generative\n  Time-Series Models for Improving Generalization Capabilities of Autonomous\n  Driving Agents", "comments": "7 pages, 4 figures, 7 tables, IV2020", "journal-ref": null, "doi": "10.1109/IV47402.2020.9304774", "report-no": null, "categories": "cs.RO cs.AI eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automated lane changing is a critical feature for advanced autonomous driving\nsystems. In recent years, reinforcement learning (RL) algorithms trained on\ntraffic simulators yielded successful results in computing lane changing\npolicies that strike a balance between safety, agility and compensating for\ntraffic uncertainty. However, many RL algorithms exhibit simulator bias and\npolicies trained on simple simulators do not generalize well to realistic\ntraffic scenarios. In this work, we develop a data driven traffic simulator by\ntraining a generative adverserial network (GAN) on real life trajectory data.\nThe simulator generates randomized trajectories that resembles real life\ntraffic interactions between vehicles, which enables training the RL agent on\nmuch richer and realistic scenarios. We demonstrate through simulations that RL\nagents that are trained on GAN-based traffic simulator has stronger\ngeneralization capabilities compared to RL agents trained on simple rule-driven\nsimulators.\n", "versions": [{"version": "v1", "created": "Wed, 10 Jun 2020 13:14:34 GMT"}], "update_date": "2021-03-16", "authors_parsed": [["Ozturk", "Anil", ""], ["Gunel", "Mustafa Burak", ""], ["Dal", "Melih", ""], ["Yavas", "Ugur", ""], ["Ure", "Nazim Kemal", ""]]}, {"id": "2006.05826", "submitter": "Maximilian Igl", "authors": "Maximilian Igl, Gregory Farquhar, Jelena Luketina, Wendelin Boehmer,\n  Shimon Whiteson", "title": "Transient Non-Stationarity and Generalisation in Deep Reinforcement\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Non-stationarity can arise in Reinforcement Learning (RL) even in stationary\nenvironments. For example, most RL algorithms collect new data throughout\ntraining, using a non-stationary behaviour policy. Due to the transience of\nthis non-stationarity, it is often not explicitly addressed in deep RL and a\nsingle neural network is continually updated. However, we find evidence that\nneural networks exhibit a memory effect where these transient\nnon-stationarities can permanently impact the latent representation and\nadversely affect generalisation performance. Consequently, to improve\ngeneralisation of deep RL agents, we propose Iterated Relearning (ITER). ITER\naugments standard RL training by repeated knowledge transfer of the current\npolicy into a freshly initialised network, which thereby experiences less\nnon-stationarity during training. Experimentally, we show that ITER improves\nperformance on the challenging generalisation benchmarks ProcGen and Multiroom.\n", "versions": [{"version": "v1", "created": "Wed, 10 Jun 2020 13:26:31 GMT"}, {"version": "v2", "created": "Tue, 16 Jun 2020 11:25:37 GMT"}, {"version": "v3", "created": "Sat, 17 Apr 2021 08:32:53 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Igl", "Maximilian", ""], ["Farquhar", "Gregory", ""], ["Luketina", "Jelena", ""], ["Boehmer", "Wendelin", ""], ["Whiteson", "Shimon", ""]]}, {"id": "2006.05832", "submitter": "Samuel Schmidgall", "authors": "Samuel Schmidgall", "title": "Adaptive Reinforcement Learning through Evolving Self-Modifying Neural\n  Networks", "comments": "GECCO'2020 Poster: Submitted and accepted", "journal-ref": "Proc. of GECCO 2020", "doi": "10.1145/3377929.3389901", "report-no": null, "categories": "cs.NE cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The adaptive learning capabilities seen in biological neural networks are\nlargely a product of the self-modifying behavior emerging from online plastic\nchanges in synaptic connectivity. Current methods in Reinforcement Learning\n(RL) only adjust to new interactions after reflection over a specified time\ninterval, preventing the emergence of online adaptivity. Recent work addressing\nthis by endowing artificial neural networks with neuromodulated plasticity have\nbeen shown to improve performance on simple RL tasks trained using\nbackpropagation, but have yet to scale up to larger problems. Here we study the\nproblem of meta-learning in a challenging quadruped domain, where each leg of\nthe quadruped has a chance of becoming unusable, requiring the agent to adapt\nby continuing locomotion with the remaining limbs. Results demonstrate that\nagents evolved using self-modifying plastic networks are more capable of\nadapting to complex meta-learning learning tasks, even outperforming the same\nnetwork updated using gradient-based algorithms while taking less time to\ntrain.\n", "versions": [{"version": "v1", "created": "Fri, 22 May 2020 02:24:44 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["Schmidgall", "Samuel", ""]]}, {"id": "2006.05842", "submitter": "Zongqing Lu", "authors": "Jiechuan Jiang and Zongqing Lu", "title": "The Emergence of Individuality in Multi-Agent Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Individuality is essential in human society, which induces the division of\nlabor and thus improves the efficiency and productivity. Similarly, it should\nalso be the key to multi-agent cooperation. Inspired by that individuality is\nof being an individual separate from others, we propose a simple yet efficient\nmethod for the emergence of individuality (EOI) in multi-agent reinforcement\nlearning (MARL). EOI learns a probabilistic classifier that predicts a\nprobability distribution over agents given their observation and gives each\nagent an intrinsic reward of being correctly predicted by the classifier. The\nintrinsic reward encourages the agents to visit their own familiar\nobservations, and learning the classifier by such observations makes the\nintrinsic reward signals stronger and the agents more identifiable. To further\nenhance the intrinsic reward and promote the emergence of individuality, two\nregularizers are proposed to increase the discriminability of the classifier.\nWe implement EOI on top of popular MARL algorithms. Empirically, we show that\nEOI significantly outperforms existing methods in a variety of multi-agent\ncooperative scenarios.\n", "versions": [{"version": "v1", "created": "Wed, 10 Jun 2020 14:11:21 GMT"}], "update_date": "2020-06-11", "authors_parsed": [["Jiang", "Jiechuan", ""], ["Lu", "Zongqing", ""]]}, {"id": "2006.05846", "submitter": "Nicholas Chancellor", "authors": "Nicholas Chancellor, Robert Cumming, Tim Thomas", "title": "Toward a standardized methodology for constructing quantum computing use\n  cases", "comments": "9 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a standardized methodology for developing and evaluating use cases\nfor quantum computers and quantum inspired methods. This methodology consists\nof a standardized set of questions which should be asked to determine how and\nindeed if, near term quantum computing can play a role in a given application.\nDeveloping such a set of questions is important because it allows different use\ncases to be evaluated in a fair and objective way, rather than considering each\ncase on an ad hoc basis which could lead to an evaluation which focuses on\npositives of a use case, while ignoring weaknesses. To demonstrate our\nmethodology we apply it to a concrete use case, ambulance dispatch, and find\nthat there are some ways in which near term quantum computing could be deployed\nsensibly, but also demonstrate some cases ways in which its use would not be\nadvised. The purpose of this paper is to initiate a dialogue within the\ncommunity of quantum computing scientists and potential end users on what\nquestions should be asked when developing real world use cases.\n", "versions": [{"version": "v1", "created": "Wed, 10 Jun 2020 14:23:37 GMT"}], "update_date": "2020-06-11", "authors_parsed": [["Chancellor", "Nicholas", ""], ["Cumming", "Robert", ""], ["Thomas", "Tim", ""]]}, {"id": "2006.05894", "submitter": "Ivan Bravi", "authors": "Ivan Bravi and Simon Lucas", "title": "Rinascimento: using event-value functions for playing Splendor", "comments": "To appear in IEEE Conference on Games 2019 Proceedings", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the realm of games research, Artificial General Intelligence algorithms\noften use score as main reward signal for learning or playing actions. However\nthis has shown its severe limitations when the point rewards are very rare or\nabsent until the end of the game. This paper proposes a new approach based on\nevent logging: the game state triggers an event every time one of its features\nchanges. These events are processed by an Event-value Function (EF) that\nassigns a value to a single action or a sequence. The experiments have shown\nthat such approach can mitigate the problem of scarce point rewards and improve\nthe AI performance. Furthermore this represents a step forward in controlling\nthe strategy adopted by the artificial agent, by describing a much richer and\ncontrollable behavioural space through the EF. Tuned EF are able to neatly\nsynthesise the relevance of the events in the game. Agents using an EF show\nmore robust when playing games with several opponents.\n", "versions": [{"version": "v1", "created": "Wed, 10 Jun 2020 15:28:11 GMT"}], "update_date": "2020-06-11", "authors_parsed": [["Bravi", "Ivan", ""], ["Lucas", "Simon", ""]]}, {"id": "2006.05905", "submitter": "Weiguo Pian", "authors": "Weiguo Pian, Yingbo Wu, Xiangmou Qu, Junpeng Cai, Ziyi Kou", "title": "Spatial-Temporal Dynamic Graph Attention Networks for Ride-hailing\n  Demand Prediction", "comments": "11 pages, 6 figures. arXiv admin note: text overlap with\n  arXiv:2006.04089", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ride-hailing demand prediction is an essential task in spatial-temporal data\nmining. Accurate Ride-hailing demand prediction can help to pre-allocate\nresources, improve vehicle utilization and user experiences. Graph\nConvolutional Networks (GCN) is commonly used to model the complicated\nirregular non-Euclidean spatial correlations. However, existing GCN-based\nride-hailing demand prediction methods only assign the same importance to\ndifferent neighbor regions, and maintain a fixed graph structure with static\nspatial relationships throughout the timeline when extracting the irregular\nnon-Euclidean spatial correlations. In this paper, we propose the\nSpatial-Temporal Dynamic Graph Attention Network (STDGAT), a novel ride-hailing\ndemand prediction method. Based on the attention mechanism of GAT, STDGAT\nextracts different pair-wise correlations to achieve the adaptive importance\nallocation for different neighbor regions. Moreover, in STDGAT, we design a\nnovel time-specific commuting-based graph attention mode to construct a dynamic\ngraph structure for capturing the dynamic time-specific spatial relationships\nthroughout the timeline. Extensive experiments are conducted on a real-world\nride-hailing demand dataset, and the experimental results demonstrate the\nsignificant improvement of our method on three evaluation metrics RMSE, MAPE\nand MAE over state-of-the-art baselines.\n", "versions": [{"version": "v1", "created": "Sun, 7 Jun 2020 13:00:19 GMT"}, {"version": "v2", "created": "Wed, 9 Dec 2020 08:30:26 GMT"}, {"version": "v3", "created": "Fri, 28 May 2021 19:53:56 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Pian", "Weiguo", ""], ["Wu", "Yingbo", ""], ["Qu", "Xiangmou", ""], ["Cai", "Junpeng", ""], ["Kou", "Ziyi", ""]]}, {"id": "2006.05918", "submitter": "Abenezer Girma Mr", "authors": "Abenezer Girma, Seifemichael Amsalu, Abrham Workineh, Mubbashar Khan,\n  Abdollah Homaifar", "title": "Deep Learning with Attention Mechanism for Predicting Driver Intention\n  at Intersection", "comments": "IEEE Intelligent Vehicles Symposium 2020 (IEEE IV 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.HC cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, a driver's intention prediction near a road intersection is\nproposed. Our approach uses a deep bidirectional Long Short-Term Memory (LSTM)\nwith an attention mechanism model based on a hybrid-state system (HSS)\nframework. As intersection is considered to be as one of the major source of\nroad accidents, predicting a driver's intention at an intersection is very\ncrucial. Our method uses a sequence to sequence modeling with an attention\nmechanism to effectively exploit temporal information out of the time-series\nvehicular data including velocity and yaw-rate. The model then predicts ahead\nof time whether the target vehicle/driver will go straight, stop, or take right\nor left turn. The performance of the proposed approach is evaluated on a\nnaturalistic driving dataset and results show that our method achieves high\naccuracy as well as outperforms other methods. The proposed solution is\npromising to be applied in advanced driver assistance systems (ADAS) and as\npart of active safety system of autonomous vehicles.\n", "versions": [{"version": "v1", "created": "Wed, 10 Jun 2020 16:12:00 GMT"}], "update_date": "2020-06-11", "authors_parsed": [["Girma", "Abenezer", ""], ["Amsalu", "Seifemichael", ""], ["Workineh", "Abrham", ""], ["Khan", "Mubbashar", ""], ["Homaifar", "Abdollah", ""]]}, {"id": "2006.05962", "submitter": "Pavel Surynek", "authors": "Pavel Surynek", "title": "At-Most-One Constraints in Efficient Representations of Mutex Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The At-Most-One (AMO) constraint is a special case of cardinality constraint\nthat requires at most one variable from a set of Boolean variables to be set to\nTRUE. AMO is important for modeling problems as Boolean satisfiability (SAT)\nfrom domains where decision variables represent spatial or temporal placements\nof some objects that cannot share the same spatial or temporal slot. The AMO\nconstraint can be used for more efficient representation and problem solving in\nmutex networks consisting of pair-wise mutual exclusions forbidding pairs of\nBoolean variable to be simultaneously TRUE. An on-line method for automated\ndetection of cliques for efficient representation of incremental mutex networks\nwhere new mutexes arrive using AMOs is presented. A comparison of SAT-based\nproblem solving in mutex networks represented by AMO constraints using various\nencodings is shown.\n", "versions": [{"version": "v1", "created": "Wed, 10 Jun 2020 17:21:06 GMT"}], "update_date": "2020-06-11", "authors_parsed": [["Surynek", "Pavel", ""]]}, {"id": "2006.05963", "submitter": "Violet Xinying Chen", "authors": "Violet Xinying Chen, J.N. Hooker", "title": "Balancing Fairness and Efficiency in an Optimization Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Optimization models generally aim for efficiency by maximizing total benefit\nor minimizing cost. Yet a trade-off between fairness and efficiency is an\nimportant element of many practical decisions. We propose a principled and\npractical method for balancing these two criteria in an optimization model.\nFollowing a critical assessment of existing schemes, we define a set of social\nwelfare functions (SWFs) that combine Rawlsian leximax fairness and\nutilitarianism and overcome some of the weaknesses of previous approaches. In\nparticular, we regulate the equity/efficiency trade-off with a single parameter\nthat has a meaningful interpretation in practical contexts. We formulate the\nSWFs using mixed integer constraints and sequentially maximize them subject to\nconstraints that define the problem at hand. After providing practical\nstep-by-step instructions for implementation, we demonstrate the method on\nproblems of realistic size involving healthcare resource allocation and\ndisaster preparation. The solution times are modest, ranging from a fraction of\na second to 18 seconds for a given value of the trade-off parameter.\n", "versions": [{"version": "v1", "created": "Wed, 10 Jun 2020 17:24:42 GMT"}], "update_date": "2020-06-11", "authors_parsed": [["Chen", "Violet Xinying", ""], ["Hooker", "J. N.", ""]]}, {"id": "2006.05986", "submitter": "Vaibhav Kumar", "authors": "Vaibhav Kumar and Alan W. black", "title": "ClarQ: A large-scale and diverse dataset for Clarification Question\n  Generation", "comments": "Accepted at ACL 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Question answering and conversational systems are often baffled and need help\nclarifying certain ambiguities. However, limitations of existing datasets\nhinder the development of large-scale models capable of generating and\nutilising clarification questions. In order to overcome these limitations, we\ndevise a novel bootstrapping framework (based on self-supervision) that assists\nin the creation of a diverse, large-scale dataset of clarification questions\nbased on post-comment tuples extracted from stackexchange. The framework\nutilises a neural network based architecture for classifying clarification\nquestions. It is a two-step method where the first aims to increase the\nprecision of the classifier and second aims to increase its recall. We\nquantitatively demonstrate the utility of the newly created dataset by applying\nit to the downstream task of question-answering. The final dataset, ClarQ,\nconsists of ~2M examples distributed across 173 domains of stackexchange. We\nrelease this dataset in order to foster research into the field of\nclarification question generation with the larger goal of enhancing dialog and\nquestion answering systems.\n", "versions": [{"version": "v1", "created": "Wed, 10 Jun 2020 17:56:50 GMT"}, {"version": "v2", "created": "Thu, 11 Jun 2020 17:18:39 GMT"}], "update_date": "2020-06-12", "authors_parsed": [["Kumar", "Vaibhav", ""], ["black", "Alan W.", ""]]}, {"id": "2006.06026", "submitter": "Tiancheng Zhao", "authors": "Maxine Eskenazi, Tiancheng Zhao", "title": "Report from the NSF Future Directions Workshop, Toward User-Oriented\n  Agents: Research Directions and Challenges", "comments": "Final report of the NSF Future Directions Workshop, Toward\n  User-Oriented Agents: Research Directions and Challenges", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This USER Workshop was convened with the goal of defining future research\ndirections for the burgeoning intelligent agent research community and to\ncommunicate them to the National Science Foundation. It took place in\nPittsburgh Pennsylvania on October 24 and 25, 2019 and was sponsored by\nNational Science Foundation Grant Number IIS-1934222. Any opinions, findings\nand conclusions or future directions expressed in this document are those of\nthe authors and do not necessarily reflect the views of the National Science\nFoundation. The 27 participants presented their individual research interests\nand their personal research goals. In the breakout sessions that followed, the\nparticipants defined the main research areas within the domain of intelligent\nagents and they discussed the major future directions that the research in each\narea of this domain should take\n", "versions": [{"version": "v1", "created": "Wed, 10 Jun 2020 18:32:35 GMT"}], "update_date": "2020-06-12", "authors_parsed": [["Eskenazi", "Maxine", ""], ["Zhao", "Tiancheng", ""]]}, {"id": "2006.06054", "submitter": "Zaheen Ahmad", "authors": "Zaheen Farraz Ahmad, Levi H. S. Lelis, Michael Bowling", "title": "Marginal Utility for Planning in Continuous or Large Discrete Action\n  Spaces", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sample-based planning is a powerful family of algorithms for generating\nintelligent behavior from a model of the environment. Generating good candidate\nactions is critical to the success of sample-based planners, particularly in\ncontinuous or large action spaces. Typically, candidate action generation\nexhausts the action space, uses domain knowledge, or more recently, involves\nlearning a stochastic policy to provide such search guidance. In this paper we\nexplore explicitly learning a candidate action generator by optimizing a novel\nobjective, marginal utility. The marginal utility of an action generator\nmeasures the increase in value of an action over previously generated actions.\nWe validate our approach in both curling, a challenging stochastic domain with\ncontinuous state and action spaces, and a location game with a discrete but\nlarge action space. We show that a generator trained with the marginal utility\nobjective outperforms hand-coded schemes built on substantial domain knowledge,\ntrained stochastic policies, and other natural objectives for generating\nactions for sampled-based planners.\n", "versions": [{"version": "v1", "created": "Wed, 10 Jun 2020 20:24:53 GMT"}, {"version": "v2", "created": "Wed, 17 Jun 2020 17:00:39 GMT"}], "update_date": "2020-06-18", "authors_parsed": [["Ahmad", "Zaheen Farraz", ""], ["Lelis", "Levi H. S.", ""], ["Bowling", "Michael", ""]]}, {"id": "2006.06057", "submitter": "Schyler Chengyao Sun", "authors": "Schyler C. Sun, Chen Li, Zhuangkun Wei, Antonios Tsourdos, Weisi Guo", "title": "Scalable Partial Explainability in Neural Networks via Flexible\n  Activation Functions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Achieving transparency in black-box deep learning algorithms is still an open\nchallenge. High dimensional features and decisions given by deep neural\nnetworks (NN) require new algorithms and methods to expose its mechanisms.\nCurrent state-of-the-art NN interpretation methods (e.g. Saliency maps,\nDeepLIFT, LIME, etc.) focus more on the direct relationship between NN outputs\nand inputs rather than the NN structure and operations itself. In current deep\nNN operations, there is uncertainty over the exact role played by neurons with\nfixed activation functions. In this paper, we achieve partially explainable\nlearning model by symbolically explaining the role of activation functions (AF)\nunder a scalable topology. This is carried out by modeling the AFs as adaptive\nGaussian Processes (GP), which sit within a novel scalable NN topology, based\non the Kolmogorov-Arnold Superposition Theorem (KST). In this scalable NN\narchitecture, the AFs are generated by GP interpolation between control points\nand can thus be tuned during the back-propagation procedure via gradient\ndescent. The control points act as the core enabler to both local and global\nadjustability of AF, where the GP interpolation constrains the intrinsic\nautocorrelation to avoid over-fitting. We show that there exists a trade-off\nbetween the NN's expressive power and interpretation complexity, under linear\nKST topology scaling. To demonstrate this, we perform a case study on a binary\nclassification dataset of banknote authentication. By quantitatively and\nqualitatively investigating the mapping relationship between inputs and output,\nour explainable model can provide interpretation over each of the\none-dimensional attributes. These early results suggest that our model has the\npotential to act as the final interpretation layer for deep neural networks.\n", "versions": [{"version": "v1", "created": "Wed, 10 Jun 2020 20:30:15 GMT"}], "update_date": "2020-06-12", "authors_parsed": [["Sun", "Schyler C.", ""], ["Li", "Chen", ""], ["Wei", "Zhuangkun", ""], ["Tsourdos", "Antonios", ""], ["Guo", "Weisi", ""]]}, {"id": "2006.06074", "submitter": "Eric Veith", "authors": "Eric MSP Veith, Stephan Balduin, Nils Wenninghoff, Martin Tr\\\"oschel,\n  Lars Fischer, Astrid Nie{\\ss}e, Thomas Wolgast, Richard Sethmann, Bastian\n  Fraune, Torben Woltjen", "title": "Analyzing Power Grid, ICT, and Market Without Domain Knowledge Using\n  Distributed Artificial Intelligence", "comments": "Submitted to DACH Energy Informatics 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern cyber-physical systems (CPS), such as our energy infrastructure, are\nbecoming increasingly complex: An ever-higher share of Artificial Intelligence\n(AI)-based technologies use the Information and Communication Technology (ICT)\nfacet of energy systems for operation optimization, cost efficiency, and to\nreach CO2 goals worldwide. At the same time, markets with increased flexibility\nand ever shorter trade horizons enable the multi-stakeholder situation that is\nemerging in this setting. These systems still form critical infrastructures\nthat need to perform with highest reliability. However, today's CPS are\nbecoming too complex to be analyzed in the traditional monolithic approach,\nwhere each domain, e.g., power grid and ICT as well as the energy market, are\nconsidered as separate entities while ignoring dependencies and side-effects.\nTo achieve an overall analysis, we introduce the concept for an application of\ndistributed artificial intelligence as a self-adaptive analysis tool that is\nable to analyze the dependencies between domains in CPS by attacking them. It\neschews pre-configured domain knowledge, instead exploring the CPS domains for\nemergent risk situations and exploitable loopholes in codices, with a focus on\nrational market actors that exploit the system while still following the market\nrules.\n", "versions": [{"version": "v1", "created": "Wed, 10 Jun 2020 21:32:39 GMT"}], "update_date": "2020-06-12", "authors_parsed": [["Veith", "Eric MSP", ""], ["Balduin", "Stephan", ""], ["Wenninghoff", "Nils", ""], ["Tr\u00f6schel", "Martin", ""], ["Fischer", "Lars", ""], ["Nie\u00dfe", "Astrid", ""], ["Wolgast", "Thomas", ""], ["Sethmann", "Richard", ""], ["Fraune", "Bastian", ""], ["Woltjen", "Torben", ""]]}, {"id": "2006.06082", "submitter": "Subhabrata Majumdar", "authors": "Emily Dodwell, Cheryl Flynn, Balachander Krishnamurthy, Subhabrata\n  Majumdar, Ritwik Mitra", "title": "Towards Integrating Fairness Transparently in Industrial Applications", "comments": "14 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Numerous Machine Learning (ML) bias-related failures in recent years have led\nto scrutiny of how companies incorporate aspects of transparency and\naccountability in their ML lifecycles. Companies have a responsibility to\nmonitor ML processes for bias and mitigate any bias detected, ensure business\nproduct integrity, preserve customer loyalty, and protect brand image.\nChallenges specific to industry ML projects can be broadly categorized into\nprincipled documentation, human oversight, and need for mechanisms that enable\ninformation reuse and improve cost efficiency. We highlight specific roadblocks\nand propose conceptual solutions on a per-category basis for ML practitioners\nand organizational subject matter experts. Our systematic approach tackles\nthese challenges by integrating mechanized and human-in-the-loop components in\nbias detection, mitigation, and documentation of projects at various stages of\nthe ML lifecycle. To motivate the implementation of our system -- SIFT (System\nto Integrate Fairness Transparently) -- we present its structural primitives\nwith an example real-world use case on how it can be used to identify potential\nbiases and determine appropriate mitigation strategies in a participatory\nmanner.\n", "versions": [{"version": "v1", "created": "Wed, 10 Jun 2020 21:54:27 GMT"}, {"version": "v2", "created": "Mon, 19 Oct 2020 22:35:50 GMT"}, {"version": "v3", "created": "Sat, 13 Feb 2021 23:23:08 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Dodwell", "Emily", ""], ["Flynn", "Cheryl", ""], ["Krishnamurthy", "Balachander", ""], ["Majumdar", "Subhabrata", ""], ["Mitra", "Ritwik", ""]]}, {"id": "2006.06114", "submitter": "Filip Ilievski", "authors": "Filip Ilievski, Pedro Szekely, Jingwei Cheng, Fu Zhang, Ehsan Qasemi", "title": "Consolidating Commonsense Knowledge", "comments": "14 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Commonsense reasoning is an important aspect of building robust AI systems\nand is receiving significant attention in the natural language understanding,\ncomputer vision, and knowledge graphs communities. At present, a number of\nvaluable commonsense knowledge sources exist, with different foci, strengths,\nand weaknesses. In this paper, we list representative sources and their\nproperties. Based on this survey, we propose principles and a representation\nmodel in order to consolidate them into a Common Sense Knowledge Graph (CSKG).\nWe apply this approach to consolidate seven separate sources into a first\nintegrated CSKG. We present statistics of CSKG, present initial investigations\nof its utility on four QA datasets, and list learned lessons.\n", "versions": [{"version": "v1", "created": "Wed, 10 Jun 2020 23:40:11 GMT"}, {"version": "v2", "created": "Mon, 22 Jun 2020 19:38:59 GMT"}], "update_date": "2020-06-24", "authors_parsed": [["Ilievski", "Filip", ""], ["Szekely", "Pedro", ""], ["Cheng", "Jingwei", ""], ["Zhang", "Fu", ""], ["Qasemi", "Ehsan", ""]]}, {"id": "2006.06143", "submitter": "James D. Finch", "authors": "James D. Finch and Jinho D. Choi", "title": "Emora STDM: A Versatile Framework for Innovative Dialogue System\n  Development", "comments": "Accepted by SIGDIAL 2020: System Demonstrations", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This demo paper presents Emora STDM (State Transition Dialogue Manager), a\ndialogue system development framework that provides novel workflows for rapid\nprototyping of chat-based dialogue managers as well as collaborative\ndevelopment of complex interactions. Our framework caters to a wide range of\nexpertise levels by supporting interoperability between two popular approaches,\nstate machine and information state, to dialogue management. Our Natural\nLanguage Expression package allows seamless integration of pattern matching,\ncustom NLP modules, and database querying, that makes the workflows much more\nefficient. As a user study, we adopt this framework to an interdisciplinary\nundergraduate course where students with both technical and non-technical\nbackgrounds are able to develop creative dialogue managers in a short period of\ntime.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jun 2020 01:31:17 GMT"}], "update_date": "2020-06-12", "authors_parsed": [["Finch", "James D.", ""], ["Choi", "Jinho D.", ""]]}, {"id": "2006.06192", "submitter": "Kanako Esaki", "authors": "Kanako Esaki, Tadayuki Matsumura, Kiyoto Ito and Hiroyuki Mizuno", "title": "Sensorimotor Visual Perception on Embodied System Using Free Energy\n  Principle", "comments": "8 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an embodied system based on the free energy principle (FEP) for\nsensorimotor visual perception. We evaluated it in a character-recognition task\nusing the MNIST dataset. Although the FEP has successfully described a rule\nthat living things obey mathematically and claims that a biological system\ncontinues to change its internal models and behaviors to minimize the\ndifference in predicting sensory input, it is not enough to model sensorimotor\nvisual perception. An embodiment of the system is the key to achieving\nsensorimotor visual perception. The proposed embodied system is configured by a\nbody and memory. The body has an ocular motor system controlling the direction\nof eye gaze, which means that the eye can only observe a small focused area of\nthe environment. The memory is not photographic, but is a generative model\nimplemented with a variational autoencoder that contains prior knowledge about\nthe environment, and that knowledge is classified. By limiting body and memory\nabilities and operating according to the FEP, the embodied system repeatedly\ntakes action to obtain the next sensory input based on various potentials of\nfuture sensory inputs. In the evaluation, the inference of the environment was\nrepresented as an approximate posterior distribution of characters (0 - 9). As\nthe number of repetitions increased, the attention area moved continuously,\ngradually reducing the uncertainty of characters. Finally, the probability of\nthe correct character became the highest among the characters. Changing the\ninitial attention position provides a different final distribution, suggesting\nthat the proposed system has a confirmation bias.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jun 2020 05:03:45 GMT"}], "update_date": "2020-06-12", "authors_parsed": [["Esaki", "Kanako", ""], ["Matsumura", "Tadayuki", ""], ["Ito", "Kiyoto", ""], ["Mizuno", "Hiroyuki", ""]]}, {"id": "2006.06217", "submitter": "Abhishek Gupta", "authors": "Abhishek Gupta (1 and 2), Camylle Lanteigne (1 and 3), and Sara\n  Kingsley (4) ((1) Montreal AI Ethics Institute, (2) Microsoft, (3) McGill\n  University, (4) Carnegie Mellon University)", "title": "SECure: A Social and Environmental Certificate for AI Systems", "comments": "Accepted for presentation at the Canadian Society for Ecological\n  Economics 2020 Research Symposium, Tracing the Veins 2020, ICML 2020\n  Deploying and Monitoring Machine Learning Systems workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.LG econ.GN q-fin.EC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In a world increasingly dominated by AI applications, an understudied aspect\nis the carbon and social footprint of these power-hungry algorithms that\nrequire copious computation and a trove of data for training and prediction.\nWhile profitable in the short-term, these practices are unsustainable and\nsocially extractive from both a data-use and energy-use perspective. This work\nproposes an ESG-inspired framework combining socio-technical measures to build\neco-socially responsible AI systems. The framework has four pillars:\ncompute-efficient machine learning, federated learning, data sovereignty, and a\nLEEDesque certificate.\n  Compute-efficient machine learning is the use of compressed network\narchitectures that show marginal decreases in accuracy. Federated learning\naugments the first pillar's impact through the use of techniques that\ndistribute computational loads across idle capacity on devices. This is paired\nwith the third pillar of data sovereignty to ensure the privacy of user data\nvia techniques like use-based privacy and differential privacy. The final\npillar ties all these factors together and certifies products and services in a\nstandardized manner on their environmental and social impacts, allowing\nconsumers to align their purchase with their values.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jun 2020 06:10:46 GMT"}, {"version": "v2", "created": "Sun, 19 Jul 2020 12:39:45 GMT"}], "update_date": "2020-07-21", "authors_parsed": [["Gupta", "Abhishek", "", "1 and 2"], ["Lanteigne", "Camylle", "", "1 and 3"], ["Kingsley", "Sara", ""]]}, {"id": "2006.06248", "submitter": "Arbaaz Khan", "authors": "Arbaaz Khan, Alejandro Ribeiro, Vijay Kumar, Anthony G. Francis", "title": "Graph Neural Networks for Motion Planning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper investigates the feasibility of using Graph Neural Networks (GNNs)\nfor classical motion planning problems. We propose guiding both continuous and\ndiscrete planning algorithms using GNNs' ability to robustly encode the\ntopology of the planning space using a property called permutation invariance.\nWe present two techniques, GNNs over dense fixed graphs for low-dimensional\nproblems and sampling-based GNNs for high-dimensional problems. We examine the\nability of a GNN to tackle planning problems such as identifying critical nodes\nor learning the sampling distribution in Rapidly-exploring Random Trees (RRT).\nExperiments with critical sampling, a pendulum and a six DoF robot arm show\nGNNs improve on traditional analytic methods as well as learning approaches\nusing fully-connected or convolutional neural networks.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jun 2020 08:19:06 GMT"}, {"version": "v2", "created": "Mon, 14 Dec 2020 17:07:58 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["Khan", "Arbaaz", ""], ["Ribeiro", "Alejandro", ""], ["Kumar", "Vijay", ""], ["Francis", "Anthony G.", ""]]}, {"id": "2006.06251", "submitter": "Rajaa El Hamdani", "authors": "Paul Boniol, George Panagopoulos, Christos Xypolopoulos, Rajaa El\n  Hamdani, David Restrepo Amariles, Michalis Vazirgiannis", "title": "Performance in the Courtroom: Automated Processing and Visualization of\n  Appeal Court Decisions in France", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Artificial Intelligence techniques are already popular and important in the\nlegal domain. We extract legal indicators from judicial judgment to decrease\nthe asymmetry of information of the legal system and the access-to-justice gap.\nWe use NLP methods to extract interesting entities/data from judgments to\nconstruct networks of lawyers and judgments. We propose metrics to rank lawyers\nbased on their experience, wins/loss ratio and their importance in the network\nof lawyers. We also perform community detection in the network of judgments and\npropose metrics to represent the difficulty of cases capitalising on\ncommunities features.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jun 2020 08:22:59 GMT"}, {"version": "v2", "created": "Fri, 12 Jun 2020 09:17:36 GMT"}, {"version": "v3", "created": "Thu, 9 Jul 2020 19:47:27 GMT"}], "update_date": "2020-07-13", "authors_parsed": [["Boniol", "Paul", ""], ["Panagopoulos", "George", ""], ["Xypolopoulos", "Christos", ""], ["Hamdani", "Rajaa El", ""], ["Amariles", "David Restrepo", ""], ["Vazirgiannis", "Michalis", ""]]}, {"id": "2006.06282", "submitter": "Zhixi Li", "authors": "Zhixi Li and Vincent Tam", "title": "A Novel Meta-Heuristic Optimization Algorithm Inspired by the Spread of\n  Viruses", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  According to the no-free-lunch theorem, there is no single meta-heuristic\nalgorithm that can optimally solve all optimization problems. This motivates\nmany researchers to continuously develop new optimization algorithms. In this\npaper, a novel nature-inspired meta-heuristic optimization algorithm called\nvirus spread optimization (VSO) is proposed. VSO loosely mimics the spread of\nviruses among hosts, and can be effectively applied to solving many challenging\nand continuous optimization problems. We devise a new representation scheme and\nviral operations that are radically different from previously proposed\nvirus-based optimization algorithms. First, the viral RNA of each host in VSO\ndenotes a potential solution for which different viral operations will help to\ndiversify the searching strategies in order to largely enhance the solution\nquality. In addition, an imported infection mechanism, inheriting the searched\noptima from another colony, is introduced to possibly avoid the prematuration\nof any potential solution in solving complex problems. VSO has an excellent\ncapability to conduct adaptive neighborhood searches around the discovered\noptima for achieving better solutions. Furthermore, with a flexible infection\nmechanism, VSO can quickly escape from local optima. To clearly demonstrate\nboth its effectiveness and efficiency, VSO is critically evaluated on a series\nof well-known benchmark functions. Moreover, VSO is validated on its\napplicability through two real-world examples including the financial portfolio\noptimization and optimization of hyper-parameters of support vector machines\nfor classification problems. The results show that VSO has attained superior\nperformance in terms of solution fitness, convergence rate, scalability,\nreliability, and flexibility when compared to those results of the conventional\nas well as state-of-the-art meta-heuristic optimization algorithms.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jun 2020 09:35:28 GMT"}], "update_date": "2020-06-12", "authors_parsed": [["Li", "Zhixi", ""], ["Tam", "Vincent", ""]]}, {"id": "2006.06323", "submitter": "Nikhil Sheoran", "authors": "Atanu R Sinha, Deepali Jain, Nikhil Sheoran, Sopan Khosla, Reshmi\n  Sasidharan", "title": "Surveys without Questions: A Reinforcement Learning Approach", "comments": "The Thirty-Third AAAI Conference on Artificial Intelligence (AAAI-19)", "journal-ref": "Proceedings of the AAAI Conference on Artificial Intelligence,\n  vol. 33, July 2019, pp. 257-64", "doi": "10.1609/aaai.v33i01.3301257", "report-no": null, "categories": "cs.AI cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The 'old world' instrument, survey, remains a tool of choice for firms to\nobtain ratings of satisfaction and experience that customers realize while\ninteracting online with firms. While avenues for survey have evolved from\nemails and links to pop-ups while browsing, the deficiencies persist. These\ninclude - reliance on ratings of very few respondents to infer about all\ncustomers' online interactions; failing to capture a customer's interactions\nover time since the rating is a one-time snapshot; and inability to tie back\ncustomers' ratings to specific interactions because ratings provided relate to\nall interactions. To overcome these deficiencies we extract proxy ratings from\nclickstream data, typically collected for every customer's online interactions,\nby developing an approach based on Reinforcement Learning (RL). We introduce a\nnew way to interpret values generated by the value function of RL, as proxy\nratings. Our approach does not need any survey data for training. Yet, on\nvalidation against actual survey data, proxy ratings yield reasonable\nperformance results. Additionally, we offer a new way to draw insights from\nvalues of the value function, which allow associating specific interactions to\ntheir proxy ratings. We introduce two new metrics to represent ratings - one,\ncustomer-level and the other, aggregate-level for click actions across\ncustomers. Both are defined around proportion of all pairwise, successive\nactions that show increase in proxy ratings. This intuitive customer-level\nmetric enables gauging the dynamics of ratings over time and is a better\npredictor of purchase than customer ratings from survey. The aggregate-level\nmetric allows pinpointing actions that help or hurt experience. In sum, proxy\nratings computed unobtrusively from clickstream, for every action, for each\ncustomer, and for every session can offer interpretable and more insightful\nalternative to surveys.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jun 2020 10:41:07 GMT"}], "update_date": "2020-06-14", "authors_parsed": [["Sinha", "Atanu R", ""], ["Jain", "Deepali", ""], ["Sheoran", "Nikhil", ""], ["Khosla", "Sopan", ""], ["Sasidharan", "Reshmi", ""]]}, {"id": "2006.06343", "submitter": "Emilio Gamba", "authors": "Bart Bogaerts, Emilio Gamba, Tias Guns", "title": "A framework for step-wise explaining how to solve constraint\n  satisfaction problems", "comments": null, "journal-ref": null, "doi": "10.1016/j.artint.2021.103550", "report-no": null, "categories": "cs.LO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We explore the problem of step-wise explaining how to solve constraint\nsatisfaction problems, with a use case on logic grid puzzles. More\nspecifically, we study the problem of explaining the inference steps that one\ncan take during propagation, in a way that is easy to interpret for a person.\nThereby, we aim to give the constraint solver explainable agency, which can\nhelp in building trust in the solver by being able to understand and even learn\nfrom the explanations. The main challenge is that of finding a sequence of\nsimple explanations, where each explanation should aim to be as cognitively\neasy as possible for a human to verify and understand. This contrasts with the\narbitrary combination of facts and constraints that the solver may use when\npropagating. We propose the use of a cost function to quantify how simple an\nindividual explanation of an inference step is, and identify the\nexplanation-production problem of finding the best sequence of explanations of\na CSP. Our approach is agnostic of the underlying constraint propagation\nmechanisms, and can provide explanations even for inference steps resulting\nfrom combinations of constraints. In case multiple constraints are involved, we\nalso develop a mechanism that allows to break the most difficult steps up and\nthus gives the user the ability to zoom in on specific parts of the\nexplanation. Our proposed algorithm iteratively constructs the explanation\nsequence by using an optimistic estimate of the cost function to guide the\nsearch for the best explanation at each step. Our experiments on logic grid\npuzzles show the feasibility of the approach in terms of the quality of the\nindividual explanations and the resulting explanation sequences obtained.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jun 2020 11:35:41 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Bogaerts", "Bart", ""], ["Gamba", "Emilio", ""], ["Guns", "Tias", ""]]}, {"id": "2006.06367", "submitter": "Ping Guo", "authors": "Ping Guo, and Qian Yin", "title": "Synergetic Learning Systems: Concept, Architecture, and Algorithms", "comments": "This work is based on first principle for artificial intelligence.\n  Some terminologies and syntax errors are revised in this version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Drawing on the idea that brain development is a Darwinian process of\n``evolution + selection'' and the idea that the current state is a local\nequilibrium state of many bodies with self-organization and evolution processes\ndriven by the temperature and gravity in our universe, in this work, we\ndescribe an artificial intelligence system called the ``Synergetic Learning\nSystems''. The system is composed of two or more subsystems (models, agents or\nvirtual bodies), and it is an open complex giant system. Inspired by natural\nintelligence, the system achieves intelligent information processing and\ndecision-making in a given environment through cooperative/competitive\nsynergetic learning. The intelligence evolved by the natural law of ``it is not\nthe strongest of the species that survives, but the one most responsive to\nchange,'' while an artificial intelligence system should adopt the law of\n``human selection'' in the evolution process. Therefore, we expect that the\nproposed system architecture can also be adapted in human-machine synergy or\nmulti-agent synergetic systems. It is also expected that under our design\ncriteria, the proposed system will eventually achieve artificial general\nintelligence through long term coevolution.\n", "versions": [{"version": "v1", "created": "Sun, 31 May 2020 06:23:03 GMT"}, {"version": "v2", "created": "Sun, 14 Jun 2020 10:19:17 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["Guo", "Ping", ""], ["Yin", "Qian", ""]]}, {"id": "2006.06412", "submitter": "Raunak Bhattacharyya", "authors": "Raunak Bhattacharyya, Blake Wulfe, Derek Phillips, Alex Kuefler,\n  Jeremy Morton, Ransalu Senanayake, Mykel Kochenderfer", "title": "Modeling Human Driving Behavior through Generative Adversarial Imitation\n  Learning", "comments": "28 pages, 8 figures. arXiv admin note: text overlap with\n  arXiv:1803.01044", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Imitation learning is an approach for generating intelligent behavior when\nthe cost function is unknown or difficult to specify. Building upon work in\ninverse reinforcement learning (IRL), Generative Adversarial Imitation Learning\n(GAIL) aims to provide effective imitation even for problems with large or\ncontinuous state and action spaces. Driver modeling is one example of a problem\nwhere the state and action spaces are continuous. Human driving behavior is\ncharacterized by non-linearity and stochasticity, and the underlying cost\nfunction is unknown. As a result, learning from human driving demonstrations is\na promising approach for generating human-like driving behavior. This article\ndescribes the use of GAIL for learning-based driver modeling. Because driver\nmodeling is inherently a multi-agent problem, where the interaction between\nagents needs to be modeled, this paper describes a parameter-sharing extension\nof GAIL called PS-GAIL to tackle multi-agent driver modeling. In addition, GAIL\nis domain agnostic, making it difficult to encode specific knowledge relevant\nto driving in the learning process. This paper describes Reward Augmented\nImitation Learning (RAIL), which modifies the reward signal to provide\ndomain-specific knowledge to the agent. Finally, human demonstrations are\ndependent upon latent factors that may not be captured by GAIL. This paper\ndescribes Burn-InfoGAIL, which allows for disentanglement of latent variability\nin demonstrations. Imitation learning experiments are performed using NGSIM, a\nreal-world highway driving dataset. Experiments show that these modifications\nto GAIL can successfully model highway driving behavior, accurately replicating\nhuman demonstrations and generating realistic, emergent behavior in the traffic\nflow arising from the interaction between driving agents.\n", "versions": [{"version": "v1", "created": "Wed, 10 Jun 2020 05:47:39 GMT"}], "update_date": "2020-06-12", "authors_parsed": [["Bhattacharyya", "Raunak", ""], ["Wulfe", "Blake", ""], ["Phillips", "Derek", ""], ["Kuefler", "Alex", ""], ["Morton", "Jeremy", ""], ["Senanayake", "Ransalu", ""], ["Kochenderfer", "Mykel", ""]]}, {"id": "2006.06431", "submitter": "Qinbing Fu", "authors": "Qinbing Fu and Shigang Yue", "title": "Complementary Visual Neuronal Systems Model for Collision Sensing", "comments": "7 pages, 6 figures. This work has been accepted for publication in a\n  future IEEE conference. Copyright has been transferred to the IEEE. This\n  version may no longer be accessible after the conference publication in IEEE\n  Xplore", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inspired by insects' visual brains, this paper presents original modelling of\na complementary visual neuronal systems model for real-time and robust\ncollision sensing. Two categories of wide-field motion sensitive neurons, i.e.,\nthe lobula giant movement detectors (LGMDs) in locusts and the lobula plate\ntangential cells (LPTCs) in flies, have been studied, intensively. The LGMDs\nhave specific selectivity to approaching objects in depth that threaten\ncollision; whilst the LPTCs are only sensitive to translating objects in\nhorizontal and vertical directions. Though each has been modelled and applied\nin various visual scenes including robot scenarios, little has been done on\ninvestigating their complementary functionality and selectivity when\nfunctioning together. To fill this vacancy, we introduce a hybrid model\ncombining two LGMDs (LGMD-1 and LGMD-2) with horizontally (rightward and\nleftward) sensitive LPTCs (LPTC-R and LPTC-L) specialising in fast collision\nperception. With coordination and competition between different activated\nneurons, the proximity feature by frontal approaching stimuli can be largely\nsharpened up by suppressing translating and receding motions. The proposed\nmethod has been implemented in ground micro-mobile robots as embedded systems.\nThe multi-robot experiments have demonstrated the effectiveness and robustness\nof the proposed model for frontal collision sensing, which outperforms previous\nsingle-type neuron computation methods against translating interference.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jun 2020 13:40:59 GMT"}], "update_date": "2020-06-12", "authors_parsed": [["Fu", "Qinbing", ""], ["Yue", "Shigang", ""]]}, {"id": "2006.06434", "submitter": "Xuefeng Yang", "authors": "Ningyuan Sun, Xuefeng Yang, Yunfeng Liu", "title": "TableQA: a Large-Scale Chinese Text-to-SQL Dataset for Table-Aware SQL\n  Generation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.AI cs.LG", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Parsing natural language to corresponding SQL (NL2SQL) with data driven\napproaches like deep neural networks attracts much attention in recent years.\nExisting NL2SQL datasets assume that condition values should appear exactly in\nnatural language questions and the queries are answerable given the table.\nHowever, these assumptions may fail in practical scenarios, because user may\nuse different expressions for the same content in the table, and query\ninformation outside the table without the full picture of contents in table.\nTherefore we present TableQA, a large-scale cross-domain Natural Language to\nSQL dataset in Chinese language consisting 64,891 questions and 20,311 unique\nSQL queries on over 6,000 tables. Different from exisiting NL2SQL datasets,\nTableQA requires to generalize well not only to SQL skeletons of different\nquestions and table schemas, but also to the various expressions for condition\nvalues. Experiment results show that the state-of-the-art model with 95.1%\ncondition value accuracy on WikiSQL only gets 46.8% condition value accuracy\nand 43.0% logic form accuracy on TableQA, indicating the proposed dataset is\nchallenging and necessary to handle. Two table-aware approaches are proposed to\nalleviate the problem, the end-to-end approaches obtains 51.3% and 47.4%\naccuracy on the condition value and logic form tasks, with improvement of 4.7%\nand 3.4% respectively.\n", "versions": [{"version": "v1", "created": "Wed, 10 Jun 2020 03:49:08 GMT"}], "update_date": "2020-06-12", "authors_parsed": [["Sun", "Ningyuan", ""], ["Yang", "Xuefeng", ""], ["Liu", "Yunfeng", ""]]}, {"id": "2006.06444", "submitter": "Caelan Garrett", "authors": "Zi Wang, Caelan Reed Garrett, Leslie Pack Kaelbling, and Tom\\'as\n  Lozano-P\\'erez", "title": "Learning compositional models of robot skills for task and motion\n  planning", "comments": "First two authors contributed equally. arXiv admin note: text overlap\n  with arXiv:1803.00967", "journal-ref": "The International Journal of Robotics Research (IJRR), 2020", "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The objective of this work is to augment the basic abilities of a robot by\nlearning to use sensorimotor primitives to solve complex long-horizon\nmanipulation problems. This requires flexible generative planning that can\ncombine primitive abilities in novel combinations and thus generalize across a\nwide variety of problems. In order to plan with primitive actions, we must have\nmodels of the actions: under what circumstances will executing this primitive\nsuccessfully achieve some particular effect in the world?\n  We use, and develop novel improvements on, state-of-the-art methods for\nactive learning and sampling. We use Gaussian process methods for learning the\nconstraints on skill effectiveness from small numbers of expensive-to-collect\ntraining examples. Additionally, we develop efficient adaptive sampling methods\nfor generating a comprehensive and diverse sequence of continuous candidate\ncontrol parameter values (such as pouring waypoints for a cup) during planning.\nThese values become end-effector goals for traditional motion planners that\nthen solve for a full robot motion that performs the skill. By using learning\nand planning methods in conjunction, we take advantage of the strengths of each\nand plan for a wide variety of complex dynamic manipulation tasks. We\ndemonstrate our approach in an integrated system, combining traditional\nrobotics primitives with our newly learned models using an efficient robot task\nand motion planner. We evaluate our approach both in simulation and in the real\nworld through measuring the quality of the selected primitive actions. Finally,\nwe apply our integrated system to a variety of long-horizon simulated and\nreal-world manipulation problems.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jun 2020 20:45:34 GMT"}, {"version": "v2", "created": "Wed, 5 May 2021 03:00:32 GMT"}], "update_date": "2021-05-06", "authors_parsed": [["Wang", "Zi", ""], ["Garrett", "Caelan Reed", ""], ["Kaelbling", "Leslie Pack", ""], ["Lozano-P\u00e9rez", "Tom\u00e1s", ""]]}, {"id": "2006.06535", "submitter": "Sicong Liu", "authors": "Sicong Liu, Junzhao Du, Anshumali Shrivastava, Lin Zhong", "title": "Privacy Adversarial Network: Representation Learning for Mobile Data\n  Privacy", "comments": null, "journal-ref": null, "doi": "10.1145/3369816", "report-no": null, "categories": "cs.LG cs.AI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The remarkable success of machine learning has fostered a growing number of\ncloud-based intelligent services for mobile users. Such a service requires a\nuser to send data, e.g. image, voice and video, to the provider, which presents\na serious challenge to user privacy. To address this, prior works either\nobfuscate the data, e.g. add noise and remove identity information, or send\nrepresentations extracted from the data, e.g. anonymized features. They\nstruggle to balance between the service utility and data privacy because\nobfuscated data reduces utility and extracted representation may still reveal\nsensitive information.\n  This work departs from prior works in methodology: we leverage adversarial\nlearning to a better balance between privacy and utility. We design a\n\\textit{representation encoder} that generates the feature representations to\noptimize against the privacy disclosure risk of sensitive information (a\nmeasure of privacy) by the \\textit{privacy adversaries}, and concurrently\noptimize with the task inference accuracy (a measure of utility) by the\n\\textit{utility discriminator}. The result is the privacy adversarial network\n(\\systemname), a novel deep model with the new training algorithm, that can\nautomatically learn representations from the raw data.\n  Intuitively, PAN adversarially forces the extracted representations to only\nconvey the information required by the target task. Surprisingly, this\nconstitutes an implicit regularization that actually improves task accuracy. As\na result, PAN achieves better utility and better privacy at the same time! We\nreport extensive experiments on six popular datasets and demonstrate the\nsuperiority of \\systemname compared with alternative methods reported in prior\nwork.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jun 2020 09:42:04 GMT"}], "update_date": "2020-06-12", "authors_parsed": [["Liu", "Sicong", ""], ["Du", "Junzhao", ""], ["Shrivastava", "Anshumali", ""], ["Zhong", "Lin", ""]]}, {"id": "2006.06547", "submitter": "Alexander Turner", "authors": "Alexander Matt Turner, Neale Ratzlaff, Prasad Tadepalli", "title": "Avoiding Side Effects in Complex Environments", "comments": "Accepted as spotlight paper at NeurIPS 2020. 10 pages main paper; 19\n  pages with appendices", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reward function specification can be difficult. Rewarding the agent for\nmaking a widget may be easy, but penalizing the multitude of possible negative\nside effects is hard. In toy environments, Attainable Utility Preservation\n(AUP) avoided side effects by penalizing shifts in the ability to achieve\nrandomly generated goals. We scale this approach to large, randomly generated\nenvironments based on Conway's Game of Life. By preserving optimal value for a\nsingle randomly generated reward function, AUP incurs modest overhead while\nleading the agent to complete the specified task and avoid many side effects.\nVideos and code are available at https://avoiding-side-effects.github.io/.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jun 2020 16:02:30 GMT"}, {"version": "v2", "created": "Thu, 22 Oct 2020 15:15:46 GMT"}], "update_date": "2020-10-23", "authors_parsed": [["Turner", "Alexander Matt", ""], ["Ratzlaff", "Neale", ""], ["Tadepalli", "Prasad", ""]]}, {"id": "2006.06580", "submitter": "Baihan Lin", "authors": "Baihan Lin, Djallel Bouneffouf, Guillermo Cecchi", "title": "Online Learning in Iterated Prisoner's Dilemma to Mimic Human Behavior", "comments": "To the best of our knowledge, this is the first attempt to explore\n  the full spectrum of reinforcement learning agents (multi-armed bandits,\n  contextual bandits and reinforcement learning) in the sequential social\n  dilemma. This mental variants section supersedes and extends our work\n  arXiv:1706.02897 (MAB), arXiv:2005.04544 (CB) and arXiv:1906.11286 (RL) into\n  the multi-agent setting", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.AI cs.LG cs.MA q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Prisoner's Dilemma mainly treat the choice to cooperate or defect as an\natomic action. We propose to study online learning algorithm behavior in the\nIterated Prisoner's Dilemma (IPD) game, where we explored the full spectrum of\nreinforcement learning agents: multi-armed bandits, contextual bandits and\nreinforcement learning. We have evaluate them based on a tournament of iterated\nprisoner's dilemma where multiple agents can compete in a sequential fashion.\nThis allows us to analyze the dynamics of policies learned by multiple\nself-interested independent reward-driven agents, and also allows us study the\ncapacity of these algorithms to fit the human behaviors. Results suggest that\nconsidering the current situation to make decision is the worst in this kind of\nsocial dilemma game. Multiples discoveries on online learning behaviors and\nclinical validations are stated.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jun 2020 15:58:32 GMT"}, {"version": "v2", "created": "Thu, 10 Sep 2020 14:17:09 GMT"}], "update_date": "2020-09-11", "authors_parsed": [["Lin", "Baihan", ""], ["Bouneffouf", "Djallel", ""], ["Cecchi", "Guillermo", ""]]}, {"id": "2006.06600", "submitter": "Hao Sun", "authors": "Hao Sun, Ziping Xu, Yuhang Song, Meng Fang, Jiechao Xiong, Bo Dai,\n  Bolei Zhou", "title": "Zeroth-Order Supervised Policy Improvement", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Policy gradient (PG) algorithms have been widely used in reinforcement\nlearning (RL). However, PG algorithms rely on exploiting the value function\nbeing learned with the first-order update locally, which results in limited\nsample efficiency. In this work, we propose an alternative method called\nZeroth-Order Supervised Policy Improvement (ZOSPI). ZOSPI exploits the\nestimated value function $Q$ globally while preserving the local exploitation\nof the PG methods based on zeroth-order policy optimization. This learning\nparadigm follows Q-learning but overcomes the difficulty of efficiently\noperating argmax in continuous action space. It finds max-valued action within\na small number of samples. The policy learning of ZOSPI has two steps: First,\nit samples actions and evaluates those actions with a learned value estimator,\nand then it learns to perform the action with the highest value through\nsupervised learning. We further demonstrate such a supervised learning\nframework can learn multi-modal policies. Experiments show that ZOSPI achieves\ncompetitive results on the continuous control benchmarks with a remarkable\nsample efficiency.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jun 2020 16:49:23 GMT"}, {"version": "v2", "created": "Mon, 5 Jul 2021 07:18:16 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Sun", "Hao", ""], ["Xu", "Ziping", ""], ["Song", "Yuhang", ""], ["Fang", "Meng", ""], ["Xiong", "Jiechao", ""], ["Dai", "Bo", ""], ["Zhou", "Bolei", ""]]}, {"id": "2006.06609", "submitter": "Alon Talmor", "authors": "Alon Talmor, Oyvind Tafjord, Peter Clark, Yoav Goldberg, Jonathan\n  Berant", "title": "Leap-Of-Thought: Teaching Pre-Trained Models to Systematically Reason\n  Over Implicit Knowledge", "comments": "Presented as Spotlight at NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To what extent can a neural network systematically reason over symbolic\nfacts? Evidence suggests that large pre-trained language models (LMs) acquire\nsome reasoning capacity, but this ability is difficult to control. Recently, it\nhas been shown that Transformer-based models succeed in consistent reasoning\nover explicit symbolic facts, under a \"closed-world\" assumption. However, in an\nopen-domain setup, it is desirable to tap into the vast reservoir of implicit\nknowledge already encoded in the parameters of pre-trained LMs. In this work,\nwe provide a first demonstration that LMs can be trained to reliably perform\nsystematic reasoning combining both implicit, pre-trained knowledge and\nexplicit natural language statements. To do this, we describe a procedure for\nautomatically generating datasets that teach a model new reasoning skills, and\ndemonstrate that models learn to effectively perform inference which involves\nimplicit taxonomic and world knowledge, chaining and counting. Finally, we show\nthat \"teaching\" models to reason generalizes beyond the training distribution:\nthey successfully compose the usage of multiple reasoning skills in single\nexamples. Our work paves a path towards open-domain systems that constantly\nimprove by interacting with users who can instantly correct a model by adding\nsimple natural language statements.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jun 2020 17:02:20 GMT"}, {"version": "v2", "created": "Fri, 19 Jun 2020 15:31:59 GMT"}, {"version": "v3", "created": "Sat, 14 Nov 2020 07:47:21 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Talmor", "Alon", ""], ["Tafjord", "Oyvind", ""], ["Clark", "Peter", ""], ["Goldberg", "Yoav", ""], ["Berant", "Jonathan", ""]]}, {"id": "2006.06620", "submitter": "Nishad Gothoskar", "authors": "Nishad Gothoskar, Miguel L\\'azaro-Gredilla, Dileep George", "title": "From proprioception to long-horizon planning in novel environments: A\n  hierarchical RL model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For an intelligent agent to flexibly and efficiently operate in complex\nenvironments, they must be able to reason at multiple levels of temporal,\nspatial, and conceptual abstraction. At the lower levels, the agent must\ninterpret their proprioceptive inputs and control their muscles, and at the\nhigher levels, the agent must select goals and plan how they will achieve those\ngoals. It is clear that each of these types of reasoning is amenable to\ndifferent types of representations, algorithms, and inputs. In this work, we\nintroduce a simple, three-level hierarchical architecture that reflects these\ndistinctions. The low-level controller operates on the continuous\nproprioceptive inputs, using model-free learning to acquire useful behaviors.\nThese in turn induce a set of mid-level dynamics, which are learned by the\nmid-level controller and used for model-predictive control, to select a\nbehavior to activate at each timestep. The high-level controller leverages a\ndiscrete, graph representation for goal selection and path planning to specify\ntargets for the mid-level controller. We apply our method to a series of\nnavigation tasks in the Mujoco Ant environment, consistently demonstrating\nsignificant improvements in sample-efficiency compared to prior model-free,\nmodel-based, and hierarchical RL methods. Finally, as an illustrative example\nof the advantages of our architecture, we apply our method to a complex maze\nenvironment that requires efficient exploration and long-horizon planning.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jun 2020 17:19:12 GMT"}], "update_date": "2020-06-12", "authors_parsed": [["Gothoskar", "Nishad", ""], ["L\u00e1zaro-Gredilla", "Miguel", ""], ["George", "Dileep", ""]]}, {"id": "2006.06626", "submitter": "Guannan Qu", "authors": "Guannan Qu, Yiheng Lin, Adam Wierman, Na Li", "title": "Scalable Multi-Agent Reinforcement Learning for Networked Systems with\n  Average Reward", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.AI cs.LG cs.MA cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It has long been recognized that multi-agent reinforcement learning (MARL)\nfaces significant scalability issues due to the fact that the size of the state\nand action spaces are exponentially large in the number of agents. In this\npaper, we identify a rich class of networked MARL problems where the model\nexhibits a local dependence structure that allows it to be solved in a scalable\nmanner. Specifically, we propose a Scalable Actor-Critic (SAC) method that can\nlearn a near optimal localized policy for optimizing the average reward with\ncomplexity scaling with the state-action space size of local neighborhoods, as\nopposed to the entire network. Our result centers around identifying and\nexploiting an exponential decay property that ensures the effect of agents on\neach other decays exponentially fast in their graph distance.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jun 2020 17:23:17 GMT"}], "update_date": "2020-06-12", "authors_parsed": [["Qu", "Guannan", ""], ["Lin", "Yiheng", ""], ["Wierman", "Adam", ""], ["Li", "Na", ""]]}, {"id": "2006.06630", "submitter": "Alessandro Gianola", "authors": "Silvio Ghilardi, Alessandro Gianola, Marco Montali, Andrey Rivkin", "title": "Petri Nets with Parameterised Data: Modelling and Verification (Extended\n  Version)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  During the last decade, various approaches have been put forward to integrate\nbusiness processes with different types of data. Each of such approaches\nreflects specific demands in the whole process-data integration spectrum. One\nparticular important point is the capability of these approaches to flexibly\naccommodate processes with multiple cases that need to co-evolve. In this work,\nwe introduce and study an extension of coloured Petri nets, called\ncatalog-nets, providing two key features to capture this type of processes. On\nthe one hand, net transitions are equipped with guards that simultaneously\ninspect the content of tokens and query facts stored in a read-only, persistent\ndatabase. On the other hand, such transitions can inject data into tokens by\nextracting relevant values from the database or by generating genuinely fresh\nones. We systematically encode catalog-nets into one of the reference\nframeworks for the (parameterised) verification of data and processes. We show\nthat fresh-value injection is a particularly complex feature to handle, and\ndiscuss strategies to tame it. Finally, we discuss how catalog nets relate to\nwell-known formalisms in this area.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jun 2020 17:26:08 GMT"}], "update_date": "2020-06-12", "authors_parsed": [["Ghilardi", "Silvio", ""], ["Gianola", "Alessandro", ""], ["Montali", "Marco", ""], ["Rivkin", "Andrey", ""]]}, {"id": "2006.06649", "submitter": "Qing Li", "authors": "Qing Li, Siyuan Huang, Yining Hong, Yixin Chen, Ying Nian Wu,\n  Song-Chun Zhu", "title": "Closed Loop Neural-Symbolic Learning via Integrating Neural Perception,\n  Grammar Parsing, and Symbolic Reasoning", "comments": "ICML 2020. Project page: https://liqing-ustc.github.io/NGS", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The goal of neural-symbolic computation is to integrate the connectionist and\nsymbolist paradigms. Prior methods learn the neural-symbolic models using\nreinforcement learning (RL) approaches, which ignore the error propagation in\nthe symbolic reasoning module and thus converge slowly with sparse rewards. In\nthis paper, we address these issues and close the loop of neural-symbolic\nlearning by (1) introducing the \\textbf{grammar} model as a \\textit{symbolic\nprior} to bridge neural perception and symbolic reasoning, and (2) proposing a\nnovel \\textbf{back-search} algorithm which mimics the top-down human-like\nlearning procedure to propagate the error through the symbolic reasoning module\nefficiently. We further interpret the proposed learning framework as maximum\nlikelihood estimation using Markov chain Monte Carlo sampling and the\nback-search algorithm as a Metropolis-Hastings sampler. The experiments are\nconducted on two weakly-supervised neural-symbolic tasks: (1) handwritten\nformula recognition on the newly introduced HWF dataset; (2) visual question\nanswering on the CLEVR dataset. The results show that our approach\nsignificantly outperforms the RL methods in terms of performance, converging\nspeed, and data efficiency. Our code and data are released at\n\\url{https://liqing-ustc.github.io/NGS}.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jun 2020 17:42:49 GMT"}, {"version": "v2", "created": "Mon, 27 Jul 2020 22:17:10 GMT"}], "update_date": "2020-07-29", "authors_parsed": [["Li", "Qing", ""], ["Huang", "Siyuan", ""], ["Hong", "Yining", ""], ["Chen", "Yixin", ""], ["Wu", "Ying Nian", ""], ["Zhu", "Song-Chun", ""]]}, {"id": "2006.06731", "submitter": "Guy Tennenholtz", "authors": "Guy Tennenholtz, Uri Shalit, Shie Mannor, Yonathan Efroni", "title": "Bandits with Partially Observable Offline Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study linear contextual bandits with access to a large, partially\nobservable, offline dataset that was sampled from some fixed policy. We show\nthat this problem is closely related to a variant of the bandit problem with\nside information. We construct a linear bandit algorithm that takes advantage\nof the projected information, and prove regret bounds. Our results demonstrate\nthe ability to take full advantage of partially observable offline data.\nParticularly, we prove regret bounds that improve current bounds by a factor\nrelated to the visible dimensionality of the contexts in the data. Our results\nindicate that partially observable offline data can significantly improve\nonline learning algorithms. Finally, we demonstrate various characteristics of\nour approach through synthetic simulations.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jun 2020 18:48:03 GMT"}], "update_date": "2020-06-15", "authors_parsed": [["Tennenholtz", "Guy", ""], ["Shalit", "Uri", ""], ["Mannor", "Shie", ""], ["Efroni", "Yonathan", ""]]}, {"id": "2006.06814", "submitter": "Jianhong Wang", "authors": "Jianhong Wang, Yuan Zhang, Tae-Kyun Kim, Yunjie Gu", "title": "Modelling Hierarchical Structure between Dialogue Policy and Natural\n  Language Generator with Option Framework for Task-oriented Dialogue System", "comments": "Published as a conference paper at ICLR 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Designing task-oriented dialogue systems is a challenging research topic,\nsince it needs not only to generate utterances fulfilling user requests but\nalso to guarantee the comprehensibility. Many previous works trained end-to-end\n(E2E) models with supervised learning (SL), however, the bias in annotated\nsystem utterances remains as a bottleneck. Reinforcement learning (RL) deals\nwith the problem through using non-differentiable evaluation metrics (e.g., the\nsuccess rate) as rewards. Nonetheless, existing works with RL showed that the\ncomprehensibility of generated system utterances could be corrupted when\nimproving the performance on fulfilling user requests. In our work, we (1)\npropose modelling the hierarchical structure between dialogue policy and\nnatural language generator (NLG) with the option framework, called HDNO, where\nthe latent dialogue act is applied to avoid designing specific dialogue act\nrepresentations; (2) train HDNO via hierarchical reinforcement learning (HRL),\nas well as suggest the asynchronous updates between dialogue policy and NLG\nduring training to theoretically guarantee their convergence to a local\nmaximizer; and (3) propose using a discriminator modelled with language models\nas an additional reward to further improve the comprehensibility. We test HDNO\non MultiWoz 2.0 and MultiWoz 2.1, the datasets on multi-domain dialogues, in\ncomparison with word-level E2E model trained with RL, LaRL and HDSA, showing\nimprovements on the performance evaluated by automatic evaluation metrics and\nhuman evaluation. Finally, we demonstrate the semantic meanings of latent\ndialogue acts to show the explanability for HDNO.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jun 2020 20:55:28 GMT"}, {"version": "v2", "created": "Thu, 23 Jul 2020 10:26:21 GMT"}, {"version": "v3", "created": "Wed, 30 Sep 2020 21:56:52 GMT"}, {"version": "v4", "created": "Fri, 19 Feb 2021 17:26:40 GMT"}], "update_date": "2021-02-22", "authors_parsed": [["Wang", "Jianhong", ""], ["Zhang", "Yuan", ""], ["Kim", "Tae-Kyun", ""], ["Gu", "Yunjie", ""]]}, {"id": "2006.06831", "submitter": "Julius von K\\\"ugelgen", "authors": "Amir-Hossein Karimi, Julius von K\\\"ugelgen, Bernhard Sch\\\"olkopf,\n  Isabel Valera", "title": "Algorithmic recourse under imperfect causal knowledge: a probabilistic\n  approach", "comments": "Camera ready version (NeurIPS 2020 spotlight)", "journal-ref": "34th Conference on Neural Information Processing Systems (NeurIPS\n  2020), Vancouver, Canada", "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work has discussed the limitations of counterfactual explanations to\nrecommend actions for algorithmic recourse, and argued for the need of taking\ncausal relationships between features into consideration. Unfortunately, in\npractice, the true underlying structural causal model is generally unknown. In\nthis work, we first show that it is impossible to guarantee recourse without\naccess to the true structural equations. To address this limitation, we propose\ntwo probabilistic approaches to select optimal actions that achieve recourse\nwith high probability given limited causal knowledge (e.g., only the causal\ngraph). The first captures uncertainty over structural equations under additive\nGaussian noise, and uses Bayesian model averaging to estimate the\ncounterfactual distribution. The second removes any assumptions on the\nstructural equations by instead computing the average effect of recourse\nactions on individuals similar to the person who seeks recourse, leading to a\nnovel subpopulation-based interventional notion of recourse. We then derive a\ngradient-based procedure for selecting optimal recourse actions, and\nempirically show that the proposed approaches lead to more reliable\nrecommendations under imperfect causal knowledge than non-probabilistic\nbaselines.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jun 2020 21:19:07 GMT"}, {"version": "v2", "created": "Tue, 16 Jun 2020 14:00:20 GMT"}, {"version": "v3", "created": "Fri, 23 Oct 2020 11:31:38 GMT"}], "update_date": "2020-10-26", "authors_parsed": [["Karimi", "Amir-Hossein", ""], ["von K\u00fcgelgen", "Julius", ""], ["Sch\u00f6lkopf", "Bernhard", ""], ["Valera", "Isabel", ""]]}, {"id": "2006.06856", "submitter": "Mo Tiwari", "authors": "Mo Tiwari, Martin Jinye Zhang, James Mayclin, Sebastian Thrun, Chris\n  Piech, Ilan Shomorony", "title": "BanditPAM: Almost Linear Time $k$-Medoids Clustering via Multi-Armed\n  Bandits", "comments": "21 pages, NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Clustering is a ubiquitous task in data science. Compared to the commonly\nused $k$-means clustering, $k$-medoids clustering requires the cluster centers\nto be actual data points and support arbitrary distance metrics, which permits\ngreater interpretability and the clustering of structured objects. Current\nstate-of-the-art $k$-medoids clustering algorithms, such as Partitioning Around\nMedoids (PAM), are iterative and are quadratic in the dataset size $n$ for each\niteration, being prohibitively expensive for large datasets. We propose\nBanditPAM, a randomized algorithm inspired by techniques from multi-armed\nbandits, that reduces the complexity of each PAM iteration from $O(n^2)$ to\n$O(n \\log n)$ and returns the same results with high probability, under\nassumptions on the data that often hold in practice. As such, BanditPAM matches\nstate-of-the-art clustering loss while reaching solutions much faster. We\nempirically validate our results on several large real-world datasets,\nincluding a coding exercise submissions dataset, the 10x Genomics 68k PBMC\nsingle-cell RNA sequencing dataset, and the MNIST handwritten digits dataset.\nIn these experiments, we observe that BanditPAM returns the same results as\nstate-of-the-art PAM-like algorithms up to 4x faster while performing up to\n200x fewer distance computations. The improvements demonstrated by BanditPAM\nenable $k$-medoids clustering on a wide range of applications, including\nidentifying cell types in large-scale single-cell data and providing scalable\nfeedback for students learning computer science online. We also release highly\noptimized Python and C++ implementations of our algorithm.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jun 2020 22:17:16 GMT"}, {"version": "v2", "created": "Sun, 6 Dec 2020 22:40:18 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Tiwari", "Mo", ""], ["Zhang", "Martin Jinye", ""], ["Mayclin", "James", ""], ["Thrun", "Sebastian", ""], ["Piech", "Chris", ""], ["Shomorony", "Ilan", ""]]}, {"id": "2006.06861", "submitter": "Joe Eappen", "authors": "Zikang Xiong, Joe Eappen, He Zhu, Suresh Jagannathan", "title": "Robustness to Adversarial Attacks in Learning-Enabled Controllers", "comments": "17 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning-enabled controllers used in cyber-physical systems (CPS) are known\nto be susceptible to adversarial attacks. Such attacks manifest as\nperturbations to the states generated by the controller's environment in\nresponse to its actions. We consider state perturbations that encompass a wide\nvariety of adversarial attacks and describe an attack scheme for discovering\nadversarial states. To be useful, these attacks need to be natural, yielding\nstates in which the controller can be reasonably expected to generate a\nmeaningful response. We consider shield-based defenses as a means to improve\ncontroller robustness in the face of such perturbations. Our defense strategy\nallows us to treat the controller and environment as black-boxes with unknown\ndynamics. We provide a two-stage approach to construct this defense and show\nits effectiveness through a range of experiments on realistic continuous\ncontrol domains such as the navigation control-loop of an F16 aircraft and the\nmotion control system of humanoid robots.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jun 2020 22:29:07 GMT"}], "update_date": "2020-06-15", "authors_parsed": [["Xiong", "Zikang", ""], ["Eappen", "Joe", ""], ["Zhu", "He", ""], ["Jagannathan", "Suresh", ""]]}, {"id": "2006.06870", "submitter": "Justin Terry", "authors": "Justin K Terry, Nathaniel Grammel", "title": "Multi-Agent Informational Learning Processes", "comments": "We are withdrawing this paper as section 2.1.1 implicitly assumes\n  information gain at all points is homogenous. A researcher has provided us an\n  example showing that this assumption causes our model to make unexpected and\n  pathological predictions, and we are aware of now way to remove this\n  assumption from our work", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new mathematical model of multi-agent reinforcement learning,\nthe Multi-Agent Informational Learning Processor \"MAILP\" model. The model is\nbased on the notion that agents have policies for a certain amount of\ninformation, models how this information iteratively evolves and propagates\nthrough many agents. This model is very general, and the only meaningful\nassumption made is that learning for individual agents progressively slows over\ntime.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jun 2020 23:18:50 GMT"}, {"version": "v2", "created": "Fri, 24 Jul 2020 05:28:53 GMT"}, {"version": "v3", "created": "Sat, 19 Sep 2020 22:31:37 GMT"}, {"version": "v4", "created": "Thu, 25 Feb 2021 21:43:47 GMT"}], "update_date": "2021-03-01", "authors_parsed": [["Terry", "Justin K", ""], ["Grammel", "Nathaniel", ""]]}, {"id": "2006.06874", "submitter": "Pierre Sermanet", "authors": "Rostam Dinyari and Pierre Sermanet and Corey Lynch", "title": "Learning to Play by Imitating Humans", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Acquiring multiple skills has commonly involved collecting a large number of\nexpert demonstrations per task or engineering custom reward functions. Recently\nit has been shown that it is possible to acquire a diverse set of skills by\nself-supervising control on top of human teleoperated play data. Play is rich\nin state space coverage and a policy trained on this data can generalize to\nspecific tasks at test time outperforming policies trained on individual expert\ntask demonstrations. In this work, we explore the question of whether robots\ncan learn to play to autonomously generate play data that can ultimately\nenhance performance. By training a behavioral cloning policy on a relatively\nsmall quantity of human play, we autonomously generate a large quantity of\ncloned play data that can be used as additional training. We demonstrate that a\ngeneral purpose goal-conditioned policy trained on this augmented dataset\nsubstantially outperforms one trained only with the original human data on 18\ndifficult user-specified manipulation tasks in a simulated robotic tabletop\nenvironment. A video example of a robot imitating human play can be seen here:\nhttps://learning-to-play.github.io/videos/undirected_play1.mp4\n", "versions": [{"version": "v1", "created": "Thu, 11 Jun 2020 23:28:54 GMT"}], "update_date": "2020-06-15", "authors_parsed": [["Dinyari", "Rostam", ""], ["Sermanet", "Pierre", ""], ["Lynch", "Corey", ""]]}, {"id": "2006.06875", "submitter": "Lirong Xia", "authors": "Lirong Xia", "title": "The Smoothed Possibility of Social Choice", "comments": "NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a framework that leverages the smoothed complexity analysis by\nSpielman and Teng to circumvent paradoxes and impossibility theorems in social\nchoice, motivated by modern applications of social choice powered by AI and ML.\nFor Condrocet's paradox, we prove that the smoothed likelihood of the paradox\neither vanishes at an exponential rate as the number of agents increases, or\ndoes not vanish at all. For the ANR impossibility on the non-existence of\nvoting rules that simultaneously satisfy anonymity, neutrality, and\nresolvability, we characterize the rate for the impossibility to vanish, to be\neither polynomially fast or exponentially fast. We also propose a novel\neasy-to-compute tie-breaking mechanism that optimally preserves anonymity and\nneutrality for even number of alternatives in natural settings. Our results\nillustrate the smoothed possibility of social choice -- even though the paradox\nand the impossibility theorem hold in the worst case, they may not be a big\nconcern in practice.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jun 2020 23:39:31 GMT"}, {"version": "v2", "created": "Thu, 22 Oct 2020 21:05:18 GMT"}, {"version": "v3", "created": "Fri, 8 Jan 2021 14:50:56 GMT"}], "update_date": "2021-01-11", "authors_parsed": [["Xia", "Lirong", ""]]}, {"id": "2006.06896", "submitter": "Yujia Shen", "authors": "Yujia Shen, Arthur Choi, Adnan Darwiche", "title": "A New Perspective on Learning Context-Specific Independence", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Local structure such as context-specific independence (CSI) has received much\nattention in the probabilistic graphical model (PGM) literature, as it\nfacilitates the modeling of large complex systems, as well as for reasoning\nwith them. In this paper, we provide a new perspective on how to learn CSIs\nfrom data. We propose to first learn a functional and parameterized\nrepresentation of a conditional probability table (CPT), such as a neural\nnetwork. Next, we quantize this continuous function, into an arithmetic circuit\nrepresentation that facilitates efficient inference. In the first step, we can\nleverage the many powerful tools that have been developed in the machine\nlearning literature. In the second step, we exploit more recently-developed\nanalytic tools from explainable AI, for the purposes of learning CSIs. Finally,\nwe contrast our approach, empirically and conceptually, with more traditional\nvariable-splitting approaches, that search for CSIs more explicitly.\n", "versions": [{"version": "v1", "created": "Fri, 12 Jun 2020 01:11:02 GMT"}], "update_date": "2020-06-15", "authors_parsed": [["Shen", "Yujia", ""], ["Choi", "Arthur", ""], ["Darwiche", "Adnan", ""]]}, {"id": "2006.06923", "submitter": "Weiya Ren", "authors": "Weiya Ren", "title": "Potential Field Guided Actor-Critic Reinforcement Learning", "comments": "7 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider the problem of actor-critic reinforcement\nlearning. Firstly, we extend the actor-critic architecture to actor-critic-N\narchitecture by introducing more critics beyond rewards. Secondly, we combine\nthe reward-based critic with a potential-field-based critic to formulate the\nproposed potential field guided actor-critic reinforcement learning approach\n(actor-critic-2). This can be seen as a combination of the model-based\ngradients and the model-free gradients in policy improvement. State with large\npotential field often contains a strong prior information, such as pointing to\nthe target at a long distance or avoiding collision by the side of an obstacle.\nIn this situation, we should trust potential-field-based critic more as policy\nevaluation to accelerate policy improvement, where action policy tends to be\nguided. For example, in practical application, learning to avoid obstacles\nshould be guided rather than learned by trial and error. State with small\npotential filed is often lack of information, for example, at the local minimum\npoint or around the moving target. At this time, we should trust reward-based\ncritic as policy evaluation more to evaluate the long-term return. In this\ncase, action policy tends to explore. In addition, potential field evaluation\ncan be combined with planning to estimate a better state value function. In\nthis way, reward design can focus more on the final stage of reward, rather\nthan reward shaping or phased reward. Furthermore, potential field evaluation\ncan make up for the lack of communication in multi-agent cooperation problem,\ni.e., multi-agent each has a reward-based critic and a relative unified\npotential-field-based critic with prior information. Thirdly, simplified\nexperiments on predator-prey game demonstrate the effectiveness of the proposed\napproach.\n", "versions": [{"version": "v1", "created": "Fri, 12 Jun 2020 03:09:25 GMT"}], "update_date": "2020-06-15", "authors_parsed": [["Ren", "Weiya", ""]]}, {"id": "2006.06956", "submitter": "Gang Chen", "authors": "Gang Chen", "title": "Decorrelated Double Q-learning", "comments": "8 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Q-learning with value function approximation may have the poor performance\nbecause of overestimation bias and imprecise estimate. Specifically,\noverestimation bias is from the maximum operator over noise estimate, which is\nexaggerated using the estimate of a subsequent state. Inspired by the recent\nadvance of deep reinforcement learning and Double Q-learning, we introduce the\ndecorrelated double Q-learning (D2Q). Specifically, we introduce the\ndecorrelated regularization item to reduce the correlation between value\nfunction approximators, which can lead to less biased estimation and low\nvariance. The experimental results on a suite of MuJoCo continuous control\ntasks demonstrate that our decorrelated double Q-learning can effectively\nimprove the performance.\n", "versions": [{"version": "v1", "created": "Fri, 12 Jun 2020 05:59:05 GMT"}], "update_date": "2020-06-15", "authors_parsed": [["Chen", "Gang", ""]]}, {"id": "2006.07042", "submitter": "Nicolas Grislain", "authors": "Nicolas Grislain, Nicolas Perrin and Antoine Thabault", "title": "Recurrent Neural Networks for Stochastic Control in Real-Time Bidding", "comments": null, "journal-ref": "2019. Proceedings of the 25th ACM SIGKDD International Conference\n  on Knowledge Discovery & Data Mining. Association for Computing Machinery,\n  New York, NY, USA", "doi": "10.1145/3292500.3330749", "report-no": null, "categories": "cs.LG cs.AI cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bidding in real-time auctions can be a difficult stochastic control task;\nespecially if underdelivery incurs strong penalties and the market is very\nuncertain. Most current works and implementations focus on optimally delivering\na campaign given a reasonable forecast of the market. Practical implementations\nhave a feedback loop to adjust and be robust to forecasting errors, but no\nimplementation, to the best of our knowledge, uses a model of market risk and\nactively anticipates market shifts. Solving such stochastic control problems in\npractice is actually very challenging. This paper proposes an approximate\nsolution based on a Recurrent Neural Network (RNN) architecture that is both\neffective and practical for implementation in a production environment. The RNN\nbidder provisions everything it needs to avoid missing its goal. It also\ndeliberately falls short of its goal when buying the missing impressions would\ncost more than the penalty for not reaching it.\n", "versions": [{"version": "v1", "created": "Fri, 12 Jun 2020 09:53:10 GMT"}], "update_date": "2020-06-15", "authors_parsed": [["Grislain", "Nicolas", ""], ["Perrin", "Nicolas", ""], ["Thabault", "Antoine", ""]]}, {"id": "2006.07043", "submitter": "C\\'edric Colas", "authors": "C\\'edric Colas, Ahmed Akakzia, Pierre-Yves Oudeyer, Mohamed Chetouani,\n  Olivier Sigaud", "title": "Language-Conditioned Goal Generation: a New Approach to Language\n  Grounding for RL", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the real world, linguistic agents are also embodied agents: they perceive\nand act in the physical world. The notion of Language Grounding questions the\ninteractions between language and embodiment: how do learning agents connect or\nground linguistic representations to the physical world ? This question has\nrecently been approached by the Reinforcement Learning community under the\nframework of instruction-following agents. In these agents, behavioral policies\nor reward functions are conditioned on the embedding of an instruction\nexpressed in natural language. This paper proposes another approach: using\nlanguage to condition goal generators. Given any goal-conditioned policy, one\ncould train a language-conditioned goal generator to generate language-agnostic\ngoals for the agent. This method allows to decouple sensorimotor learning from\nlanguage acquisition and enable agents to demonstrate a diversity of behaviors\nfor any given instruction. We propose a particular instantiation of this\napproach and demonstrate its benefits.\n", "versions": [{"version": "v1", "created": "Fri, 12 Jun 2020 09:54:38 GMT"}], "update_date": "2020-06-15", "authors_parsed": [["Colas", "C\u00e9dric", ""], ["Akakzia", "Ahmed", ""], ["Oudeyer", "Pierre-Yves", ""], ["Chetouani", "Mohamed", ""], ["Sigaud", "Olivier", ""]]}, {"id": "2006.07070", "submitter": "Nicolas Grislain", "authors": "Gr\\'egoire Jauvion and Nicolas Grislain", "title": "Optimal Allocation of Real-Time-Bidding and Direct Campaigns", "comments": null, "journal-ref": "Proceedings of the 24th ACM SIGKDD International Conference on\n  Knowledge Discovery and Data Mining, July 2018, Pages 416-424", "doi": "10.1145/3219819.3219877", "report-no": null, "categories": "cs.GT cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider the problem of optimizing the revenue a web\npublisher gets through real-time bidding (i.e. from ads sold in real-time\nauctions) and direct (i.e. from ads sold through contracts agreed in advance).\nWe consider a setting where the publisher is able to bid in the real-time\nbidding auction for each impression. If it wins the auction, it chooses a\ndirect campaign to deliver and displays the corresponding ad.\n  This paper presents an algorithm to build an optimal strategy for the\npublisher to deliver its direct campaigns while maximizing its real-time\nbidding revenue. The optimal strategy gives a formula to determine the\npublisher bid as well as a way to choose the direct campaign being delivered if\nthe publisher bidder wins the auction, depending on the impression\ncharacteristics.\n  The optimal strategy can be estimated on past auctions data. The algorithm\nscales with the number of campaigns and the size of the dataset. This is a very\nimportant feature, as in practice a publisher may have thousands of active\ndirect campaigns at the same time and would like to estimate an optimal\nstrategy on billions of auctions.\n  The algorithm is a key component of a system which is being developed, and\nwhich will be deployed on thousands of web publishers worldwide, helping them\nto serve efficiently billions of ads a day to hundreds of millions of visitors.\n", "versions": [{"version": "v1", "created": "Fri, 12 Jun 2020 10:44:56 GMT"}], "update_date": "2020-06-15", "authors_parsed": [["Jauvion", "Gr\u00e9goire", ""], ["Grislain", "Nicolas", ""]]}, {"id": "2006.07113", "submitter": "Dookun Park", "authors": "Dookun Park, Hao Yuan, Dongmin Kim, Yinglei Zhang, Matsoukas Spyros,\n  Young-Bum Kim, Ruhi Sarikaya, Edward Guo, Yuan Ling, Kevin Quinn, Pham Hung,\n  Benjamin Yao, Sungjin Lee", "title": "Large-scale Hybrid Approach for Predicting User Satisfaction with\n  Conversational Agents", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Measuring user satisfaction level is a challenging task, and a critical\ncomponent in developing large-scale conversational agent systems serving the\nneeds of real users. An widely used approach to tackle this is to collect human\nannotation data and use them for evaluation or modeling. Human annotation based\napproaches are easier to control, but hard to scale. A novel alternative\napproach is to collect user's direct feedback via a feedback elicitation system\nembedded to the conversational agent system, and use the collected user\nfeedback to train a machine-learned model for generalization. User feedback is\nthe best proxy for user satisfaction, but is not available for some ineligible\nintents and certain situations. Thus, these two types of approaches are\ncomplementary to each other. In this work, we tackle the user satisfaction\nassessment problem with a hybrid approach that fuses explicit user feedback,\nuser satisfaction predictions inferred by two machine-learned models, one\ntrained on user feedback data and the other human annotation data. The hybrid\napproach is based on a waterfall policy, and the experimental results with\nAmazon Alexa's large-scale datasets show significant improvements in inferring\nuser satisfaction. A detailed hybrid architecture, an in-depth analysis on user\nfeedback data, and an algorithm that generates data sets to properly simulate\nthe live traffic are presented in this paper.\n", "versions": [{"version": "v1", "created": "Fri, 29 May 2020 16:29:09 GMT"}], "update_date": "2020-06-15", "authors_parsed": [["Park", "Dookun", ""], ["Yuan", "Hao", ""], ["Kim", "Dongmin", ""], ["Zhang", "Yinglei", ""], ["Spyros", "Matsoukas", ""], ["Kim", "Young-Bum", ""], ["Sarikaya", "Ruhi", ""], ["Guo", "Edward", ""], ["Ling", "Yuan", ""], ["Quinn", "Kevin", ""], ["Hung", "Pham", ""], ["Yao", "Benjamin", ""], ["Lee", "Sungjin", ""]]}, {"id": "2006.07185", "submitter": "Ahmed Akakzia", "authors": "Ahmed Akakzia, C\\'edric Colas, Pierre-Yves Oudeyer, Mohamed Chetouani,\n  Olivier Sigaud", "title": "Grounding Language to Autonomously-Acquired Skills via Goal Generation", "comments": "Published at ICLR 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We are interested in the autonomous acquisition of repertoires of skills.\nLanguage-conditioned reinforcement learning (LC-RL) approaches are great tools\nin this quest, as they allow to express abstract goals as sets of constraints\non the states. However, most LC-RL agents are not autonomous and cannot learn\nwithout external instructions and feedback. Besides, their direct language\ncondition cannot account for the goal-directed behavior of pre-verbal infants\nand strongly limits the expression of behavioral diversity for a given language\ninput. To resolve these issues, we propose a new conceptual approach to\nlanguage-conditioned RL: the Language-Goal-Behavior architecture (LGB). LGB\ndecouples skill learning and language grounding via an intermediate semantic\nrepresentation of the world. To showcase the properties of LGB, we present a\nspecific implementation called DECSTR. DECSTR is an intrinsically motivated\nlearning agent endowed with an innate semantic representation describing\nspatial relations between physical objects. In a first stage (G -> B), it\nfreely explores its environment and targets self-generated semantic\nconfigurations. In a second stage (L -> G), it trains a language-conditioned\ngoal generator to generate semantic goals that match the constraints expressed\nin language-based inputs. We showcase the additional properties of LGB w.r.t.\nboth an end-to-end LC-RL approach and a similar approach leveraging\nnon-semantic, continuous intermediate representations. Intermediate semantic\nrepresentations help satisfy language commands in a diversity of ways, enable\nstrategy switching after a failure and facilitate language grounding.\n", "versions": [{"version": "v1", "created": "Fri, 12 Jun 2020 13:46:10 GMT"}, {"version": "v2", "created": "Wed, 20 Jan 2021 21:22:20 GMT"}, {"version": "v3", "created": "Mon, 25 Jan 2021 15:47:16 GMT"}], "update_date": "2021-01-26", "authors_parsed": [["Akakzia", "Ahmed", ""], ["Colas", "C\u00e9dric", ""], ["Oudeyer", "Pierre-Yves", ""], ["Chetouani", "Mohamed", ""], ["Sigaud", "Olivier", ""]]}, {"id": "2006.07187", "submitter": "Kamran Kowsari", "authors": "Kamran Kowsari, Rasoul Sali, Lubaina Ehsan, William Adorno, Asad Ali,\n  Sean Moore, Beatrice Amadi, Paul Kelly, Sana Syed, Donald Brown", "title": "HMIC: Hierarchical Medical Image Classification, A Deep Learning\n  Approach", "comments": null, "journal-ref": "Information 11, no. 6 (2020): 318", "doi": "10.3390/info11060318", "report-no": null, "categories": "eess.IV cs.AI cs.CV cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Image classification is central to the big data revolution in medicine.\nImproved information processing methods for diagnosis and classification of\ndigital medical images have shown to be successful via deep learning\napproaches. As this field is explored, there are limitations to the performance\nof traditional supervised classifiers. This paper outlines an approach that is\ndifferent from the current medical image classification tasks that view the\nissue as multi-class classification. We performed a hierarchical classification\nusing our Hierarchical Medical Image classification (HMIC) approach. HMIC uses\nstacks of deep learning models to give particular comprehension at each level\nof the clinical picture hierarchy. For testing our performance, we use biopsy\nof the small bowel images that contain three categories in the parent level\n(Celiac Disease, Environmental Enteropathy, and histologically normal\ncontrols). For the child level, Celiac Disease Severity is classified into 4\nclasses (I, IIIa, IIIb, and IIIC).\n", "versions": [{"version": "v1", "created": "Fri, 12 Jun 2020 15:15:29 GMT"}, {"version": "v2", "created": "Tue, 23 Jun 2020 22:59:38 GMT"}], "update_date": "2020-06-25", "authors_parsed": [["Kowsari", "Kamran", ""], ["Sali", "Rasoul", ""], ["Ehsan", "Lubaina", ""], ["Adorno", "William", ""], ["Ali", "Asad", ""], ["Moore", "Sean", ""], ["Amadi", "Beatrice", ""], ["Kelly", "Paul", ""], ["Syed", "Sana", ""], ["Brown", "Donald", ""]]}, {"id": "2006.07262", "submitter": "Safa Alver", "authors": "Safa Alver, Doina Precup", "title": "A Brief Look at Generalization in Visual Meta-Reinforcement Learning", "comments": "Accepted to the 4th Lifelong Learning Workshop at ICML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to the realization that deep reinforcement learning algorithms trained on\nhigh-dimensional tasks can strongly overfit to their training environments,\nthere have been several studies that investigated the generalization\nperformance of these algorithms. However, there has been no similar study that\nevaluated the generalization performance of algorithms that were specifically\ndesigned for generalization, i.e. meta-reinforcement learning algorithms. In\nthis paper, we assess the generalization performance of these algorithms by\nleveraging high-dimensional, procedurally generated environments. We find that\nthese algorithms can display strong overfitting when they are evaluated on\nchallenging tasks. We also observe that scalability to high-dimensional tasks\nwith sparse rewards remains a significant problem among many of the current\nmeta-reinforcement learning algorithms. With these results, we highlight the\nneed for developing meta-reinforcement learning algorithms that can both\ngeneralize and scale.\n", "versions": [{"version": "v1", "created": "Fri, 12 Jun 2020 15:17:17 GMT"}, {"version": "v2", "created": "Tue, 30 Jun 2020 22:27:38 GMT"}, {"version": "v3", "created": "Fri, 3 Jul 2020 13:55:03 GMT"}], "update_date": "2020-07-06", "authors_parsed": [["Alver", "Safa", ""], ["Precup", "Doina", ""]]}, {"id": "2006.07292", "submitter": "Bishwamittra Ghosh", "authors": "Bishwamittra Ghosh and Daniel Neider", "title": "A Formal Language Approach to Explaining RNNs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents LEXR, a framework for explaining the decision making of\nrecurrent neural networks (RNNs) using a formal description language called\nLinear Temporal Logic (LTL). LTL is the de facto standard for the specification\nof temporal properties in the context of formal verification and features many\ndesirable properties that make the generated explanations easy for humans to\ninterpret: it is a descriptive language, it has a variable-free syntax, and it\ncan easily be translated into plain English. To generate explanations, LEXR\nfollows the principle of counterexample-guided inductive synthesis and combines\nValiant's probably approximately correct learning (PAC) with constraint\nsolving. We prove that LEXR's explanations satisfy the PAC guarantee (provided\nthe RNN can be described by LTL) and show empirically that these explanations\nare more accurate and easier-to-understand than the ones generated by recent\nalgorithms that extract deterministic finite automata from RNNs.\n", "versions": [{"version": "v1", "created": "Fri, 12 Jun 2020 16:17:53 GMT"}], "update_date": "2020-06-15", "authors_parsed": [["Ghosh", "Bishwamittra", ""], ["Neider", "Daniel", ""]]}, {"id": "2006.07300", "submitter": "Hari Teja Tatavarti", "authors": "Hari Teja Tatavarti, Prashant Doshi, Layton Hayes", "title": "Recurrent Sum-Product-Max Networks for Decision Making in\n  Perfectly-Observed Environments", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent investigations into sum-product-max networks (SPMN) that generalize\nsum-product networks (SPN) offer a data-driven alternative for decision making,\nwhich has predominantly relied on handcrafted models. SPMNs computationally\nrepresent a probabilistic decision-making problem whose solution scales\nlinearly in the size of the network. However, SPMNs are not well suited for\nsequential decision making over multiple time steps. In this paper, we present\nrecurrent SPMNs (RSPMN) that learn from and model decision-making data over\ntime. RSPMNs utilize a template network that is unfolded as needed depending on\nthe length of the data sequence. This is significant as RSPMNs not only inherit\nthe benefits of SPMNs in being data driven and mostly tractable, they are also\nwell suited for sequential problems. We establish conditions on the template\nnetwork, which guarantee that the resulting SPMN is valid, and present a\nstructure learning algorithm to learn a sound template network. We demonstrate\nthat the RSPMNs learned on a testbed of sequential decision-making data sets\ngenerate MEUs and policies that are close to the optimal on perfectly-observed\ndomains. They easily improve on a recent batch-constrained reinforcement\nlearning method, which is important because RSPMNs offer a new model-based\napproach to offline reinforcement learning.\n", "versions": [{"version": "v1", "created": "Fri, 12 Jun 2020 16:31:11 GMT"}], "update_date": "2020-06-15", "authors_parsed": [["Tatavarti", "Hari Teja", ""], ["Doshi", "Prashant", ""], ["Hayes", "Layton", ""]]}, {"id": "2006.07301", "submitter": "Neda Navidi", "authors": "Neda Navidi, Francoi Chabo, Saga Kurandwa, Iv Lutigma, Vincent Robt,\n  Gregry Szrftgr, Andea Schuh", "title": "Human and Multi-Agent collaboration in a human-MARL teaming framework", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.HC cs.LG cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning provides effective results with agents learning from\ntheir observations, received rewards, and internal interactions between agents.\nThis study proposes a new open-source MARL framework, called COGMENT, to\nefficiently leverage human and agent interactions as a source of learning. We\ndemonstrate these innovations by using a designed real-time environment with\nunmanned aerial vehicles driven by RL agents, collaborating with a human. The\nresults of this study show that the proposed collaborative paradigm and the\nopen-source framework leads to significant reductions in both human effort and\nexploration costs.\n", "versions": [{"version": "v1", "created": "Fri, 12 Jun 2020 16:32:42 GMT"}, {"version": "v2", "created": "Mon, 1 Mar 2021 21:24:19 GMT"}], "update_date": "2021-03-03", "authors_parsed": [["Navidi", "Neda", ""], ["Chabo", "Francoi", ""], ["Kurandwa", "Saga", ""], ["Lutigma", "Iv", ""], ["Robt", "Vincent", ""], ["Szrftgr", "Gregry", ""], ["Schuh", "Andea", ""]]}, {"id": "2006.07352", "submitter": "Eli Shlizerman", "authors": "Jimin Kim, Eli Shlizerman", "title": "Deep Reinforcement Learning for Neural Control", "comments": "Please see the associated Video at: https://youtu.be/ixsUMfb9m_U", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.AI cs.LG cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel methodology for control of neural circuits based on deep\nreinforcement learning. Our approach achieves aimed behavior by generating\nexternal continuous stimulation of existing neural circuits (neuromodulation\ncontrol) or modulations of neural circuits architecture (connectome control).\nBoth forms of control are challenging due to nonlinear and recurrent complexity\nof neural activity. To infer candidate control policies, our approach maps\nneural circuits and their connectome into a grid-world like setting and infers\nthe actions needed to achieve aimed behavior. The actions are inferred by\nadaptation of deep Q-learning methods known for their robust performance in\nnavigating grid-worlds. We apply our approach to the model of \\textit{C.\nelegans} which simulates the full somatic nervous system with muscles and body.\nOur framework successfully infers neuropeptidic currents and synaptic\narchitectures for control of chemotaxis. Our findings are consistent with in\nvivo measurements and provide additional insights into neural control of\nchemotaxis. We further demonstrate the generality and scalability of our\nmethods by inferring chemotactic neural circuits from scratch.\n", "versions": [{"version": "v1", "created": "Fri, 12 Jun 2020 17:41:12 GMT"}], "update_date": "2020-06-15", "authors_parsed": [["Kim", "Jimin", ""], ["Shlizerman", "Eli", ""]]}, {"id": "2006.07390", "submitter": "Jake Hanson", "authors": "Jake R. Hanson and Sara I. Walker", "title": "Formalizing Falsification for Theories of Consciousness Across\n  Computational Hierarchies", "comments": "10 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The scientific study of consciousness is currently undergoing a critical\ntransition in the form of a rapidly evolving scientific debate regarding\nwhether or not currently proposed theories can be assessed for their scientific\nvalidity. At the forefront of this debate is Integrated Information Theory\n(IIT), widely regarded as the preeminent theory of consciousness because of its\nquantification of consciousness in terms a scalar mathematical measure called\n$\\Phi$ that is, in principle, measurable. Epistemological issues in the form of\nthe \"unfolding argument\" have provided a refutation of IIT by demonstrating how\nit permits functionally identical systems to have differences in their\npredicted consciousness. The implication is that IIT and any other proposed\ntheory based on a system's causal structure may already be falsified even in\nthe absence of experimental refutation. However, so far the arguments\nsurrounding the issue of falsification of theories of consciousness are too\nabstract to readily determine the scope of their validity. Here, we make these\nabstract arguments concrete by providing a simple example of functionally\nequivalent machines realizable with table-top electronics that take the form of\nisomorphic digital circuits with and without feedback. This allows us to\nexplicitly demonstrate the different levels of abstraction at which a theory of\nconsciousness can be assessed. Within this computational hierarchy, we show how\nIIT is simultaneously falsified at the finite-state automaton (FSA) level and\nunfalsifiable at the combinatorial state automaton (CSA) level. We use this\nexample to illustrate a more general set of criteria for theories of\nconsciousness: to avoid being unfalsifiable or already falsified scientific\ntheories of consciousness must be invariant with respect to changes that leave\nthe inference procedure fixed at a given level in a computational hierarchy.\n", "versions": [{"version": "v1", "created": "Fri, 12 Jun 2020 18:05:46 GMT"}, {"version": "v2", "created": "Sat, 5 Sep 2020 16:31:31 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Hanson", "Jake R.", ""], ["Walker", "Sara I.", ""]]}, {"id": "2006.07409", "submitter": "Prithviraj Ammanabrolu", "authors": "Prithviraj Ammanabrolu, Ethan Tien, Matthew Hausknecht, Mark O. Riedl", "title": "How to Avoid Being Eaten by a Grue: Structured Exploration Strategies\n  for Textual Worlds", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Text-based games are long puzzles or quests, characterized by a sequence of\nsparse and potentially deceptive rewards. They provide an ideal platform to\ndevelop agents that perceive and act upon the world using a combinatorially\nsized natural language state-action space. Standard Reinforcement Learning\nagents are poorly equipped to effectively explore such spaces and often\nstruggle to overcome bottlenecks---states that agents are unable to pass\nthrough simply because they do not see the right action sequence enough times\nto be sufficiently reinforced. We introduce Q*BERT, an agent that learns to\nbuild a knowledge graph of the world by answering questions, which leads to\ngreater sample efficiency. To overcome bottlenecks, we further introduce\nMC!Q*BERT an agent that uses an knowledge-graph-based intrinsic motivation to\ndetect bottlenecks and a novel exploration strategy to efficiently learn a\nchain of policy modules to overcome them. We present an ablation study and\nresults demonstrating how our method outperforms the current state-of-the-art\non nine text games, including the popular game, Zork, where, for the first\ntime, a learning agent gets past the bottleneck where the player is eaten by a\nGrue.\n", "versions": [{"version": "v1", "created": "Fri, 12 Jun 2020 18:24:06 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["Ammanabrolu", "Prithviraj", ""], ["Tien", "Ethan", ""], ["Hausknecht", "Matthew", ""], ["Riedl", "Mark O.", ""]]}, {"id": "2006.07430", "submitter": "Xuxi Yang", "authors": "Xuxi Yang, Werner Duvaud, Peng Wei", "title": "Continuous Control for Searching and Planning with a Learned Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Decision-making agents with planning capabilities have achieved huge success\nin the challenging domain like Chess, Shogi, and Go. In an effort to generalize\nthe planning ability to the more general tasks where the environment dynamics\nare not available to the agent, researchers proposed the MuZero algorithm that\ncan learn the dynamical model through the interactions with the environment. In\nthis paper, we provide a way and the necessary theoretical results to extend\nthe MuZero algorithm to more generalized environments with continuous action\nspace. Through numerical results on two relatively low-dimensional MuJoCo\nenvironments, we show the proposed algorithm outperforms the soft actor-critic\n(SAC) algorithm, a state-of-the-art model-free deep reinforcement learning\nalgorithm.\n", "versions": [{"version": "v1", "created": "Fri, 12 Jun 2020 19:10:41 GMT"}, {"version": "v2", "created": "Mon, 22 Jun 2020 03:32:50 GMT"}], "update_date": "2020-06-23", "authors_parsed": [["Yang", "Xuxi", ""], ["Duvaud", "Werner", ""], ["Wei", "Peng", ""]]}, {"id": "2006.07443", "submitter": "Sam Ganzfried", "authors": "Sam Ganzfried", "title": "Algorithm for Computing Approximate Nash Equilibrium in Continuous Games\n  with Application to Continuous Blotto", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.AI cs.MA econ.TH math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Successful algorithms have been developed for computing Nash equilibrium in a\nvariety of finite game classes. However, solving continuous games -- in which\nthe pure strategy space is (potentially uncountably) infinite -- is far more\nchallenging. Nonetheless, many real-world domains have continuous action\nspaces, e.g., where actions refer to an amount of time, money, or other\nresource that is naturally modeled as being real-valued as opposed to integral.\nWe present a new algorithm for {approximating} Nash equilibrium strategies in\ncontinuous games. In addition to two-player zero-sum games, our algorithm also\napplies to multiplayer games and games with imperfect information. We\nexperiment with our algorithm on a continuous imperfect-information Blotto\ngame, in which two players distribute resources over multiple battlefields.\nBlotto games have frequently been used to model national security scenarios and\nhave also been applied to electoral competition and auction theory. Experiments\nshow that our algorithm is able to quickly compute close approximations of Nash\nequilibrium strategies for this game.\n", "versions": [{"version": "v1", "created": "Fri, 12 Jun 2020 19:53:18 GMT"}, {"version": "v2", "created": "Fri, 26 Jun 2020 06:33:21 GMT"}, {"version": "v3", "created": "Wed, 28 Apr 2021 00:34:42 GMT"}, {"version": "v4", "created": "Thu, 27 May 2021 09:15:14 GMT"}, {"version": "v5", "created": "Tue, 1 Jun 2021 06:46:50 GMT"}], "update_date": "2021-06-02", "authors_parsed": [["Ganzfried", "Sam", ""]]}, {"id": "2006.07446", "submitter": "Hong-Cheol Choi", "authors": "Kwangyeon Kim, Akshita Gupta, Hong-Cheol Choi, Inseok Hwang", "title": "Safety-guaranteed Reinforcement Learning based on Multi-class Support\n  Vector Machine", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Several works have addressed the problem of incorporating constraints in the\nreinforcement learning (RL) framework, however majority of them can only\nguarantee the satisfaction of soft constraints. In this work, we address the\nproblem of satisfying hard state constraints in a model-free RL setting with\nthe deterministic system dynamics. The proposed algorithm is developed for the\ndiscrete state and action space and utilizes a multi-class support vector\nmachine (SVM) to represent the policy. The state constraints are incorporated\nin the SVM optimization framework to derive an analytical solution for\ndetermining the policy parameters. This final policy converges to a solution\nwhich is guaranteed to satisfy the constraints. Additionally, the proposed\nformulation adheres to the Q-learning framework and thus, also guarantees\nconvergence to the optimal solution. The algorithm is demonstrated with\nmultiple example problems.\n", "versions": [{"version": "v1", "created": "Fri, 12 Jun 2020 19:58:49 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["Kim", "Kwangyeon", ""], ["Gupta", "Akshita", ""], ["Choi", "Hong-Cheol", ""], ["Hwang", "Inseok", ""]]}, {"id": "2006.07461", "submitter": "Khurram Javed", "authors": "Khurram Javed, Martha White, Yoshua Bengio", "title": "Learning Causal Models Online", "comments": "Spurious features, causal models, online learning, random search,\n  non-iid", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Predictive models -- learned from observational data not covering the\ncomplete data distribution -- can rely on spurious correlations in the data for\nmaking predictions. These correlations make the models brittle and hinder\ngeneralization. One solution for achieving strong generalization is to\nincorporate causal structures in the models; such structures constrain learning\nby ignoring correlations that contradict them. However, learning these\nstructures is a hard problem in itself. Moreover, it's not clear how to\nincorporate the machinery of causality with online continual learning. In this\nwork, we take an indirect approach to discovering causal models. Instead of\nsearching for the true causal model directly, we propose an online algorithm\nthat continually detects and removes spurious features. Our algorithm works on\nthe idea that the correlation of a spurious feature with a target is not\nconstant over-time. As a result, the weight associated with that feature is\nconstantly changing. We show that by continually removing such features, our\nmethod converges to solutions that have strong generalization. Moreover, our\nmethod combined with random search can also discover non-spurious features from\nraw sensory data. Finally, our work highlights that the information present in\nthe temporal structure of the problem -- destroyed by shuffling the data -- is\nessential for detecting spurious features online.\n", "versions": [{"version": "v1", "created": "Fri, 12 Jun 2020 20:49:20 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["Javed", "Khurram", ""], ["White", "Martha", ""], ["Bengio", "Yoshua", ""]]}, {"id": "2006.07499", "submitter": "Bo-Hsiang (Andy) Tseng", "authors": "Bo-Hsiang Tseng, Jianpeng Cheng, Yimai Fang, David Vandyke", "title": "A Generative Model for Joint Natural Language Understanding and\n  Generation", "comments": "The 58th Annual Meeting of the Association for Computational\n  Linguistics, ACL2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Natural language understanding (NLU) and natural language generation (NLG)\nare two fundamental and related tasks in building task-oriented dialogue\nsystems with opposite objectives: NLU tackles the transformation from natural\nlanguage to formal representations, whereas NLG does the reverse. A key to\nsuccess in either task is parallel training data which is expensive to obtain\nat a large scale. In this work, we propose a generative model which couples NLU\nand NLG through a shared latent variable. This approach allows us to explore\nboth spaces of natural language and formal representations, and facilitates\ninformation sharing through the latent space to eventually benefit NLU and NLG.\nOur model achieves state-of-the-art performance on two dialogue datasets with\nboth flat and tree-structured formal representations. We also show that the\nmodel can be trained in a semi-supervised fashion by utilising unlabelled data\nto boost its performance.\n", "versions": [{"version": "v1", "created": "Fri, 12 Jun 2020 22:38:55 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["Tseng", "Bo-Hsiang", ""], ["Cheng", "Jianpeng", ""], ["Fang", "Yimai", ""], ["Vandyke", "David", ""]]}, {"id": "2006.07500", "submitter": "Divyat Mahajan", "authors": "Divyat Mahajan, Shruti Tople, Amit Sharma", "title": "Domain Generalization using Causal Matching", "comments": "Proceedings of the 38th International Conference on Machine Learning\n  (ICML), PMLR 139, 2021. (Long Talk)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the domain generalization literature, a common objective is to learn\nrepresentations independent of the domain after conditioning on the class\nlabel. We show that this objective is not sufficient: there exist\ncounter-examples where a model fails to generalize to unseen domains even after\nsatisfying class-conditional domain invariance. We formalize this observation\nthrough a structural causal model and show the importance of modeling\nwithin-class variations for generalization. Specifically, classes contain\nobjects that characterize specific causal features, and domains can be\ninterpreted as interventions on these objects that change non-causal features.\nWe highlight an alternative condition: inputs across domains should have the\nsame representation if they are derived from the same object. Based on this\nobjective, we propose matching-based algorithms when base objects are observed\n(e.g., through data augmentation) and approximate the objective when objects\nare not observed (MatchDG). Our simple matching-based algorithms are\ncompetitive to prior work on out-of-domain accuracy for rotated MNIST,\nFashion-MNIST, PACS, and Chest-Xray datasets. Our method MatchDG also recovers\nground-truth object matches: on MNIST and Fashion-MNIST, top-10 matches from\nMatchDG have over 50% overlap with ground-truth matches.\n", "versions": [{"version": "v1", "created": "Fri, 12 Jun 2020 22:39:35 GMT"}, {"version": "v2", "created": "Wed, 7 Oct 2020 16:03:08 GMT"}, {"version": "v3", "created": "Tue, 29 Jun 2021 09:54:44 GMT"}], "update_date": "2021-06-30", "authors_parsed": [["Mahajan", "Divyat", ""], ["Tople", "Shruti", ""], ["Sharma", "Amit", ""]]}, {"id": "2006.07508", "submitter": "Joe Booth", "authors": "Joe Booth, Vladimir Ivanov", "title": "Realistic Physics Based Character Controller", "comments": "5 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.HC cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Over the course of the last several years there was a strong interest in\napplication of modern optimal control techniques to the field of character\nanimation. This interest was fueled by introduction of efficient learning based\nalgorithms for policy optimization, growth in computation power, and game\nengine improvements. It was shown that it is possible to generate natural\nlooking control of a character by using two ingredients. First, the simulated\nagent must adhere to a motion capture dataset. And second, the character aims\nto track the control input from the user. The paper aims at closing the gap\nbetween the researchers and users by introducing an open source implementation\nof physics based character control in Unity framework that has a low entry\nbarrier and a steep learning curve.\n", "versions": [{"version": "v1", "created": "Fri, 12 Jun 2020 23:13:16 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["Booth", "Joe", ""], ["Ivanov", "Vladimir", ""]]}, {"id": "2006.07510", "submitter": "Peter Clark", "authors": "Sumithra Bhakthavatsalam, Kyle Richardson, Niket Tandon, Peter Clark", "title": "Do Dogs have Whiskers? A New Knowledge Base of hasPart Relations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new knowledge-base of hasPart relationships, extracted from a\nlarge corpus of generic statements. Complementary to other resources available,\nit is the first which is all three of: accurate (90% precision), salient\n(covers relationships a person may mention), and has high coverage of common\nterms (approximated as within a 10 year old's vocabulary), as well as having\nseveral times more hasPart entries than in the popular ontologies ConceptNet\nand WordNet. In addition, it contains information about quantifiers, argument\nmodifiers, and links the entities to appropriate concepts in Wikipedia and\nWordNet. The knowledge base is available at https://allenai.org/data/haspartkb\n", "versions": [{"version": "v1", "created": "Fri, 12 Jun 2020 23:34:05 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["Bhakthavatsalam", "Sumithra", ""], ["Richardson", "Kyle", ""], ["Tandon", "Niket", ""], ["Clark", "Peter", ""]]}, {"id": "2006.07532", "submitter": "Tan Zhi-Xuan", "authors": "Tan Zhi-Xuan, Jordyn L. Mann, Tom Silver, Joshua B. Tenenbaum, Vikash\n  K. Mansinghka", "title": "Online Bayesian Goal Inference for Boundedly-Rational Planning Agents", "comments": "Accepted to NeurIPS 2020. 10 pages (excl. references), 6\n  figures/tables. (Supplement: 8 pages, 11 figures/tables). Code available at:\n  https://github.com/ztangent/Plinf.jl", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  People routinely infer the goals of others by observing their actions over\ntime. Remarkably, we can do so even when those actions lead to failure,\nenabling us to assist others when we detect that they might not achieve their\ngoals. How might we endow machines with similar capabilities? Here we present\nan architecture capable of inferring an agent's goals online from both optimal\nand non-optimal sequences of actions. Our architecture models agents as\nboundedly-rational planners that interleave search with execution by\nreplanning, thereby accounting for sub-optimal behavior. These models are\nspecified as probabilistic programs, allowing us to represent and perform\nefficient Bayesian inference over an agent's goals and internal planning\nprocesses. To perform such inference, we develop Sequential Inverse Plan Search\n(SIPS), a sequential Monte Carlo algorithm that exploits the online replanning\nassumption of these models, limiting computation by incrementally extending\ninferred plans as new actions are observed. We present experiments showing that\nthis modeling and inference architecture outperforms Bayesian inverse\nreinforcement learning baselines, accurately inferring goals from both optimal\nand non-optimal trajectories involving failure and back-tracking, while\ngeneralizing across domains with compositional structure and sparse rewards.\n", "versions": [{"version": "v1", "created": "Sat, 13 Jun 2020 01:48:10 GMT"}, {"version": "v2", "created": "Sun, 25 Oct 2020 01:36:16 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Zhi-Xuan", "Tan", ""], ["Mann", "Jordyn L.", ""], ["Silver", "Tom", ""], ["Tenenbaum", "Joshua B.", ""], ["Mansinghka", "Vikash K.", ""]]}, {"id": "2006.07558", "submitter": "Kyle Dent", "authors": "Kyle Dent", "title": "Ethical Considerations for AI Researchers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Use of artificial intelligence is growing and expanding into applications\nthat impact people's lives. People trust their technology without really\nunderstanding it or its limitations. There is the potential for harm and we are\nalready seeing examples of that in the world. AI researchers have an obligation\nto consider the impact of intelligent applications they work on. While the\nethics of AI is not clear-cut, there are guidelines we can consider to minimize\nthe harm we might introduce.\n", "versions": [{"version": "v1", "created": "Sat, 13 Jun 2020 04:31:42 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["Dent", "Kyle", ""]]}, {"id": "2006.07647", "submitter": "Ivan Smirnov", "authors": "Ivan Smirnov, Florian Lemmerich, Markus Strohmaier", "title": "Quota-based debiasing can decrease representation of already\n  underrepresented groups", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many important decisions in societies such as school admissions, hiring, or\nelections are based on the selection of top-ranking individuals from a larger\npool of candidates. This process is often subject to biases, which typically\nmanifest as an under-representation of certain groups among the selected or\naccepted individuals. The most common approach to this issue is debiasing, for\nexample via the introduction of quotas that ensure proportional representation\nof groups with respect to a certain, often binary attribute. Cases include\nquotas for women on corporate boards or ethnic quotas in elections. This,\nhowever, has the potential to induce changes in representation with respect to\nother attributes. For the case of two correlated binary attributes we show that\nquota-based debiasing based on a single attribute can worsen the representation\nof already underrepresented groups and decrease overall fairness of selection.\nWe use several data sets from a broad range of domains from recidivism risk\nassessments to scientific citations to assess this effect in real-world\nsettings. Our results demonstrate the importance of including all relevant\nattributes in debiasing procedures and that more efforts need to be put into\neliminating the root causes of inequalities as purely numerical solutions such\nas quota-based debiasing might lead to unintended consequences.\n", "versions": [{"version": "v1", "created": "Sat, 13 Jun 2020 14:26:42 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["Smirnov", "Ivan", ""], ["Lemmerich", "Florian", ""], ["Strohmaier", "Markus", ""]]}, {"id": "2006.07710", "submitter": "Harshay Shah", "authors": "Harshay Shah, Kaustav Tamuly, Aditi Raghunathan, Prateek Jain,\n  Praneeth Netrapalli", "title": "The Pitfalls of Simplicity Bias in Neural Networks", "comments": "NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Several works have proposed Simplicity Bias (SB)---the tendency of standard\ntraining procedures such as Stochastic Gradient Descent (SGD) to find simple\nmodels---to justify why neural networks generalize well [Arpit et al. 2017,\nNakkiran et al. 2019, Soudry et al. 2018]. However, the precise notion of\nsimplicity remains vague. Furthermore, previous settings that use SB to\ntheoretically justify why neural networks generalize well do not simultaneously\ncapture the non-robustness of neural networks---a widely observed phenomenon in\npractice [Goodfellow et al. 2014, Jo and Bengio 2017]. We attempt to reconcile\nSB and the superior standard generalization of neural networks with the\nnon-robustness observed in practice by designing datasets that (a) incorporate\na precise notion of simplicity, (b) comprise multiple predictive features with\nvarying levels of simplicity, and (c) capture the non-robustness of neural\nnetworks trained on real data. Through theory and empirics on these datasets,\nwe make four observations: (i) SB of SGD and variants can be extreme: neural\nnetworks can exclusively rely on the simplest feature and remain invariant to\nall predictive complex features. (ii) The extreme aspect of SB could explain\nwhy seemingly benign distribution shifts and small adversarial perturbations\nsignificantly degrade model performance. (iii) Contrary to conventional wisdom,\nSB can also hurt generalization on the same data distribution, as SB persists\neven when the simplest feature has less predictive power than the more complex\nfeatures. (iv) Common approaches to improve generalization and\nrobustness---ensembles and adversarial training---can fail in mitigating SB and\nits pitfalls. Given the role of SB in training neural networks, we hope that\nthe proposed datasets and methods serve as an effective testbed to evaluate\nnovel algorithmic approaches aimed at avoiding the pitfalls of SB.\n", "versions": [{"version": "v1", "created": "Sat, 13 Jun 2020 20:15:26 GMT"}, {"version": "v2", "created": "Wed, 28 Oct 2020 09:33:46 GMT"}], "update_date": "2020-10-29", "authors_parsed": [["Shah", "Harshay", ""], ["Tamuly", "Kaustav", ""], ["Raghunathan", "Aditi", ""], ["Jain", "Prateek", ""], ["Netrapalli", "Praneeth", ""]]}, {"id": "2006.07712", "submitter": "Patrick Lambrix", "authors": "Huanyu Li and Rickard Armiento and Patrick Lambrix", "title": "An Ontology for the Materials Design Domain", "comments": "16 pages", "journal-ref": null, "doi": "10.1007/978-3-030-62466-8_14", "report-no": null, "categories": "cs.DB cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the materials design domain, much of the data from materials calculations\nare stored in different heterogeneous databases. Materials databases usually\nhave different data models. Therefore, the users have to face the challenges to\nfind the data from adequate sources and integrate data from multiple sources.\nOntologies and ontology-based techniques can address such problems as the\nformal representation of domain knowledge can make data more available and\ninteroperable among different systems. In this paper, we introduce the\nMaterials Design Ontology (MDO), which defines concepts and relations to cover\nknowledge in the field of materials design. MDO is designed using domain\nknowledge in materials science (especially in solid-state physics), and is\nguided by the data from several databases in the materials design field. We\nshow the application of the MDO to materials data retrieved from well-known\nmaterials databases.\n", "versions": [{"version": "v1", "created": "Sat, 13 Jun 2020 20:32:07 GMT"}, {"version": "v2", "created": "Thu, 5 Nov 2020 14:46:09 GMT"}], "update_date": "2020-11-06", "authors_parsed": [["Li", "Huanyu", ""], ["Armiento", "Rickard", ""], ["Lambrix", "Patrick", ""]]}, {"id": "2006.07837", "submitter": "Fedor Sandomirskiy", "authors": "Reshef Meir, Fedor Sandomirskiy, and Moshe Tennenholtz", "title": "Representative Committees of Peers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.AI econ.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A population of voters must elect representatives among themselves to decide\non a sequence of possibly unforeseen binary issues. Voters care only about the\nfinal decision, not the elected representatives. The disutility of a voter is\nproportional to the fraction of issues, where his preferences disagree with the\ndecision.\n  While an issue-by-issue vote by all voters would maximize social welfare, we\nare interested in how well the preferences of the population can be\napproximated by a small committee.\n  We show that a k-sortition (a random committee of k voters with the majority\nvote within the committee) leads to an outcome within the factor 1+O(1/k) of\nthe optimal social cost for any number of voters n, any number of issues $m$,\nand any preference profile.\n  For a small number of issues m, the social cost can be made even closer to\noptimal by delegation procedures that weigh committee members according to\ntheir number of followers. However, for large m, we demonstrate that the\nk-sortition is the worst-case optimal rule within a broad family of\ncommittee-based rules that take into account metric information about the\npreference profile of the whole population.\n", "versions": [{"version": "v1", "created": "Sun, 14 Jun 2020 08:20:47 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["Meir", "Reshef", ""], ["Sandomirskiy", "Fedor", ""], ["Tennenholtz", "Moshe", ""]]}, {"id": "2006.07853", "submitter": "Danilo Vasconcellos  Vargas", "authors": "Danilo Vasconcellos Vargas and Toshitake Asabuki", "title": "Continual General Chunking Problem and SyncMap", "comments": null, "journal-ref": "AAAI2021", "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.CV cs.ET cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Humans possess an inherent ability to chunk sequences into their constituent\nparts. In fact, this ability is thought to bootstrap language skills and\nlearning of image patterns which might be a key to a more animal-like type of\nintelligence. Here, we propose a continual generalization of the chunking\nproblem (an unsupervised problem), encompassing fixed and probabilistic chunks,\ndiscovery of temporal and causal structures and their continual variations.\nAdditionally, we propose an algorithm called SyncMap that can learn and adapt\nto changes in the problem by creating a dynamic map which preserves the\ncorrelation between variables. Results of SyncMap suggest that the proposed\nalgorithm learn near optimal solutions, despite the presence of many types of\nstructures and their continual variation. When compared to Word2vec, PARSER and\nMRIL, SyncMap surpasses or ties with the best algorithm on $66\\%$ of the\nscenarios while being the second best in the remaining $34\\%$. SyncMap's\nmodel-free simple dynamics and the absence of loss functions reveal that,\nperhaps surprisingly, much can be done with self-organization alone. Code\navailable at https://github.com/zweifel/SyncMap.\n", "versions": [{"version": "v1", "created": "Sun, 14 Jun 2020 09:39:56 GMT"}, {"version": "v2", "created": "Tue, 16 Jun 2020 02:00:10 GMT"}, {"version": "v3", "created": "Wed, 3 Feb 2021 07:17:42 GMT"}, {"version": "v4", "created": "Mon, 5 Apr 2021 09:40:22 GMT"}], "update_date": "2021-04-06", "authors_parsed": [["Vargas", "Danilo Vasconcellos", ""], ["Asabuki", "Toshitake", ""]]}, {"id": "2006.07869", "submitter": "Georgios Papoudakis", "authors": "Georgios Papoudakis, Filippos Christianos, Lukas Sch\\\"afer, Stefano V.\n  Albrecht", "title": "Benchmarking Multi-Agent Deep Reinforcement Learning Algorithms in\n  Cooperative Tasks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-agent deep reinforcement learning (MARL) suffers from a lack of\ncommonly-used evaluation tasks and criteria, making comparisons between\napproaches difficult. In this work, we consistently evaluate and compare three\ndifferent classes of MARL algorithms (independent learning, centralised\nmulti-agent policy gradient, value decomposition) in a diverse range of\ncooperative multi-agent learning tasks. Our experiments serve as a reference\nfor the expected performance of algorithms across different learning tasks, and\nwe provide insights regarding the effectiveness of different learning\napproaches. We open-source EPyMARL, which extends the PyMARL\ncodebase~\\citep{samvelyan19smac} to include additional algorithms and allow for\nflexible configuration of algorithm implementation details such as parameter\nsharing. Finally, we open-source two environments for multi-agent research\nwhich focus on coordination under sparse rewards.\n", "versions": [{"version": "v1", "created": "Sun, 14 Jun 2020 11:22:53 GMT"}, {"version": "v2", "created": "Tue, 27 Apr 2021 10:56:58 GMT"}, {"version": "v3", "created": "Fri, 11 Jun 2021 10:53:40 GMT"}], "update_date": "2021-06-14", "authors_parsed": [["Papoudakis", "Georgios", ""], ["Christianos", "Filippos", ""], ["Sch\u00e4fer", "Lukas", ""], ["Albrecht", "Stefano V.", ""]]}, {"id": "2006.07879", "submitter": "Moeez Subhani", "authors": "Moeez M. Subhani, Ashiq Anjum", "title": "Multiclass Disease Predictions Based on Integrated Clinical and Genomics\n  Datasets", "comments": null, "journal-ref": "In Poceedings of The Eleventh International Conference on\n  Bioinformatics, Biocomputational Systems and Biotechnologies. Athens. 2019.\n  IARA: Wilmington, pp. 20-27", "doi": null, "report-no": null, "categories": "q-bio.GN cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Clinical predictions using clinical data by computational methods are common\nin bioinformatics. However, clinical predictions using information from\ngenomics datasets as well is not a frequently observed phenomenon in research.\nPrecision medicine research requires information from all available datasets to\nprovide intelligent clinical solutions. In this paper, we have attempted to\ncreate a prediction model which uses information from both clinical and\ngenomics datasets. We have demonstrated multiclass disease predictions based on\ncombined clinical and genomics datasets using machine learning methods. We have\ncreated an integrated dataset, using a clinical (ClinVar) and a genomics (gene\nexpression) dataset, and trained it using instance-based learner to predict\nclinical diseases. We have used an innovative but simple way for multiclass\nclassification, where the number of output classes is as high as 75. We have\nused Principal Component Analysis for feature selection. The classifier\npredicted diseases with 73\\% accuracy on the integrated dataset. The results\nwere consistent and competent when compared with other classification models.\nThe results show that genomics information can be reliably included in datasets\nfor clinical predictions and it can prove to be valuable in clinical\ndiagnostics and precision medicine.\n", "versions": [{"version": "v1", "created": "Sun, 14 Jun 2020 12:23:49 GMT"}], "update_date": "2021-06-25", "authors_parsed": [["Subhani", "Moeez M.", ""], ["Anjum", "Ashiq", ""]]}, {"id": "2006.07906", "submitter": "Shahin Jabbari", "authors": "Aida Rahmattalabi, Shahin Jabbari, Himabindu Lakkaraju, Phebe Vayanos,\n  Max Izenberg, Ryan Brown, Eric Rice, Milind Tambe", "title": "Fair Influence Maximization: A Welfare Optimization Approach", "comments": "The short version of this paper appears in the proceedings of AAAI-21", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Several behavioral, social, and public health interventions, such as\nsuicide/HIV prevention or community preparedness against natural disasters,\nleverage social network information to maximize outreach. Algorithmic influence\nmaximization techniques have been proposed to aid with the choice of \"peer\nleaders\" or \"influencers\" in such interventions. Yet, traditional algorithms\nfor influence maximization have not been designed with these interventions in\nmind. As a result, they may disproportionately exclude minority communities\nfrom the benefits of the intervention. This has motivated research on fair\ninfluence maximization. Existing techniques come with two major drawbacks.\nFirst, they require committing to a single fairness measure. Second, these\nmeasures are typically imposed as strict constraints leading to undesirable\nproperties such as wastage of resources.\n  To address these shortcomings, we provide a principled characterization of\nthe properties that a fair influence maximization algorithm should satisfy. In\nparticular, we propose a framework based on social welfare theory, wherein the\ncardinal utilities derived by each community are aggregated using the\nisoelastic social welfare functions. Under this framework, the trade-off\nbetween fairness and efficiency can be controlled by a single inequality\naversion design parameter. We then show under what circumstances our proposed\nprinciples can be satisfied by a welfare function. The resulting optimization\nproblem is monotone and submodular and can be solved efficiently with\noptimality guarantees. Our framework encompasses as special cases leximin and\nproportional fairness. Extensive experiments on synthetic and real world\ndatasets including a case study on landslide risk management demonstrate the\nefficacy of the proposed framework.\n", "versions": [{"version": "v1", "created": "Sun, 14 Jun 2020 14:08:10 GMT"}, {"version": "v2", "created": "Tue, 15 Dec 2020 21:39:06 GMT"}], "update_date": "2020-12-17", "authors_parsed": [["Rahmattalabi", "Aida", ""], ["Jabbari", "Shahin", ""], ["Lakkaraju", "Himabindu", ""], ["Vayanos", "Phebe", ""], ["Izenberg", "Max", ""], ["Brown", "Ryan", ""], ["Rice", "Eric", ""], ["Tambe", "Milind", ""]]}, {"id": "2006.07916", "submitter": "James Cheney", "authors": "James Cheney, Xavier Gombau, Ghita Berrada and Sidahmed\n  Benabderrahmane", "title": "Categorical anomaly detection in heterogeneous data using minimum\n  description length clustering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fast and effective unsupervised anomaly detection algorithms have been\nproposed for categorical data based on the minimum description length (MDL)\nprinciple. However, they can be ineffective when detecting anomalies in\nheterogeneous datasets representing a mixture of different sources, such as\nsecurity scenarios in which system and user processes have distinct behavior\npatterns. We propose a meta-algorithm for enhancing any MDL-based anomaly\ndetection model to deal with heterogeneous data by fitting a mixture model to\nthe data, via a variant of k-means clustering. Our experimental results show\nthat using a discrete mixture model provides competitive performance relative\nto two previous anomaly detection algorithms, while mixtures of more\nsophisticated models yield further gains, on both synthetic datasets and\nrealistic datasets from a security scenario.\n", "versions": [{"version": "v1", "created": "Sun, 14 Jun 2020 14:48:37 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["Cheney", "James", ""], ["Gombau", "Xavier", ""], ["Berrada", "Ghita", ""], ["Benabderrahmane", "Sidahmed", ""]]}, {"id": "2006.07968", "submitter": "Christopher Potts", "authors": "Atticus Geiger, Alexandra Carstensen, Michael C. Frank, and\n  Christopher Potts", "title": "Relational reasoning and generalization using non-symbolic neural\n  networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Humans have a remarkable capacity to reason about abstract relational\nstructures, an ability that may support some of the most impressive,\nhuman-unique cognitive feats. Because equality (or identity) is a simple and\nubiquitous relational operator, equality reasoning has been a key case study\nfor the broader question of abstract relational reasoning. This paper revisits\nthe question of whether equality can be learned by neural networks that do not\nencode explicit symbolic structure. Earlier work arrived at a negative answer\nto this question, but that result holds only for a particular class of\nhand-crafted feature representations. In our experiments, we assess\nout-of-sample generalization of equality using both arbitrary representations\nand representations that have been pretrained on separate tasks to imbue them\nwith abstract structure. In this setting, even simple neural networks are able\nto learn basic equality with relatively little training data. In a second case\nstudy, we show that sequential equality problems (learning ABA sequences) can\nbe solved with only positive training instances. Finally, we consider a more\ncomplex, hierarchical equality problem, but this requires vastly more data.\nHowever, using a pretrained equality network as a modular component of this\nlarger task leads to good performance with no task-specific training. Overall,\nthese findings indicate that neural models are able to solve equality-based\nreasoning tasks, suggesting that essential aspects of symbolic reasoning can\nemerge from data-driven, non-symbolic learning processes.\n", "versions": [{"version": "v1", "created": "Sun, 14 Jun 2020 18:25:42 GMT"}, {"version": "v2", "created": "Tue, 16 Jun 2020 04:34:22 GMT"}], "update_date": "2020-06-17", "authors_parsed": [["Geiger", "Atticus", ""], ["Carstensen", "Alexandra", ""], ["Frank", "Michael C.", ""], ["Potts", "Christopher", ""]]}, {"id": "2006.07970", "submitter": "Hui Wang", "authors": "Hui Wang, Mike Preuss, Michael Emmerich and Aske Plaat", "title": "Tackling Morpion Solitaire with AlphaZero-likeRanked Reward\n  Reinforcement Learning", "comments": "4 pages, 2 figures. the first/ongoing attempt to tackle Morpion\n  Solitaire using ranked reward reinforcement learning. submitted to SYNASC2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Morpion Solitaire is a popular single player game, performed with paper and\npencil. Due to its large state space (on the order of the game of Go)\ntraditional search algorithms, such as MCTS, have not been able to find good\nsolutions. A later algorithm, Nested Rollout Policy Adaptation, was able to\nfind a new record of 82 steps, albeit with large computational resources. After\nachieving this record, to the best of our knowledge, there has been no further\nprogress reported, for about a decade.\n  In this paper we take the recent impressive performance of deep self-learning\nreinforcement learning approaches from AlphaGo/AlphaZero as inspiration to\ndesign a searcher for Morpion Solitaire. A challenge of Morpion Solitaire is\nthat the state space is sparse, there are few win/loss signals. Instead, we use\nan approach known as ranked reward to create a reinforcement learning self-play\nframework for Morpion Solitaire. This enables us to find medium-quality\nsolutions with reasonable computational effort. Our record is a 67 steps\nsolution, which is very close to the human best (68) without any other\nadaptation to the problem than using ranked reward. We list many further\navenues for potential improvement.\n", "versions": [{"version": "v1", "created": "Sun, 14 Jun 2020 18:32:08 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["Wang", "Hui", ""], ["Preuss", "Mike", ""], ["Emmerich", "Michael", ""], ["Plaat", "Aske", ""]]}, {"id": "2006.08055", "submitter": "Theja Tulabandhula", "authors": "Theja Tulabandhula, Deeksha Sinha, Prasoon Patidar", "title": "Multi-Purchase Behavior: Modeling and Optimization", "comments": "40 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI econ.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of modeling purchase of multiple items and utilizing it\nto display optimized recommendations, which is a central problem for online\ne-commerce platforms. Rich personalized modeling of users and fast computation\nof optimal products to display given these models can lead to significantly\nhigher revenues and simultaneously enhance the end user experience. We present\na parsimonious multi-purchase family of choice models called the BundleMVL-K\nfamily, and develop a binary search based iterative strategy that efficiently\ncomputes optimized recommendations for this model. This is one of the first\nattempts at operationalizing multi-purchase class of choice models. We\ncharacterize structural properties of the optimal solution, which allow one to\ndecide if a product is part of the optimal assortment in constant time,\nreducing the size of the instance that needs to be solved computationally. We\nalso establish the hardness of computing optimal recommendation sets. We show\none of the first quantitative links between modeling multiple purchase behavior\nand revenue gains. The efficacy of our modeling and optimization techniques\ncompared to competing solutions is shown using several real world datasets on\nmultiple metrics such as model fitness, expected revenue gains and run-time\nreductions. The benefit of taking multiple purchases into account is observed\nto be $6-8\\%$ in relative terms for the Ta Feng and UCI shopping datasets when\ncompared to the MNL model for instances with $\\sim 1500$ products.\nAdditionally, across $8$ real world datasets, the test log-likelihood fits of\nour models are on average $17\\%$ better in relative terms. The simplicity of\nour models and the iterative nature of our optimization technique allows\npractitioners meet stringent computational constraints while increasing their\nrevenues in practical recommendation applications at scale.\n", "versions": [{"version": "v1", "created": "Sun, 14 Jun 2020 23:47:14 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["Tulabandhula", "Theja", ""], ["Sinha", "Deeksha", ""], ["Patidar", "Prasoon", ""]]}, {"id": "2006.08092", "submitter": "Teawon Han", "authors": "Teawon Han, Subramanya Nageshrao, Dimitar P. Filev, Umit Ozguner", "title": "An online evolving framework for advancing reinforcement-learning based\n  automated vehicle control", "comments": "Accepted in IFAC 2020 WC", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.AI cs.RO cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, an online evolving framework is proposed to detect and revise\na controller's imperfect decision-making in advance. The framework consists of\nthree modules: the evolving Finite State Machine (e-FSM), action-reviser, and\ncontroller modules. The e-FSM module evolves a stochastic model (e.g.,\nDiscrete-Time Markov Chain) from scratch by determining new states and\nidentifying transition probabilities repeatedly. With the latest stochastic\nmodel and given criteria, the action-reviser module checks validity of the\ncontroller's chosen action by predicting future states. Then, if the chosen\naction is not appropriate, another action is inspected and selected. In order\nto show the advantage of the proposed framework, the Deep Deterministic Policy\nGradient (DDPG) w/ and w/o the online evolving framework are applied to control\nan ego-vehicle in the car-following scenario where control criteria are set by\nspeed and safety. Experimental results show that inappropriate actions chosen\nby the DDPG controller are detected and revised appropriately through our\nproposed framework, resulting in no control failures after a few iterations.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jun 2020 02:27:23 GMT"}, {"version": "v2", "created": "Tue, 16 Jun 2020 12:54:05 GMT"}], "update_date": "2020-06-17", "authors_parsed": [["Han", "Teawon", ""], ["Nageshrao", "Subramanya", ""], ["Filev", "Dimitar P.", ""], ["Ozguner", "Umit", ""]]}, {"id": "2006.08140", "submitter": "Abhishek Gupta", "authors": "Mirka Snyder Caron (1), Abhishek Gupta (1 and 2) ((1) Montreal AI\n  Ethics Institute, (2) Microsoft)", "title": "The Social Contract for AI", "comments": "Accepted paper for presentation at the IJCAI 2019 AI for Social Good\n  workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Like any technology, AI systems come with inherent risks and potential\nbenefits. It comes with potential disruption of established norms and methods\nof work, societal impacts and externalities. One may think of the adoption of\ntechnology as a form of social contract, which may evolve or fluctuate in time,\nscale, and impact. It is important to keep in mind that for AI, meeting the\nexpectations of this social contract is critical, because recklessly driving\nthe adoption and implementation of unsafe, irresponsible, or unethical AI\nsystems may trigger serious backlash against industry and academia involved\nwhich could take decades to resolve, if not actually seriously harm society.\nFor the purpose of this paper, we consider that a social contract arises when\nthere is sufficient consensus within society to adopt and implement this new\ntechnology. As such, to enable a social contract to arise for the adoption and\nimplementation of AI, developing: 1) A socially accepted purpose, through 2) A\nsafe and responsible method, with 3) A socially aware level of risk involved,\nfor 4) A socially beneficial outcome, is key.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jun 2020 05:30:48 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["Caron", "Mirka Snyder", "", "1 and 2"], ["Gupta", "Abhishek", "", "1 and 2"]]}, {"id": "2006.08150", "submitter": "Pascale Zarate", "authors": "Sarfaraz Zolfani, Morteza Yazdani, Dragan Pamucar, Pascale Zarat\\'e\n  (IRIT-ADRIA, IRIT, UT1)", "title": "A VIKOR and TOPSIS focused reanalysis of the MADM methods based on\n  logarithmic normalization", "comments": null, "journal-ref": "FACTA UNIVERSITATIS Series: Mechanical Engineering, University of\n  NIS, 2020", "doi": "10.22190/FUME191129016Z", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Decision and policy-makers in multi-criteria decision-making analysis take\ninto account some strategies in order to analyze outcomes and to finally make\nan effective and more precise decision. Among those strategies, the\nmodification of the normalization process in the multiple-criteria\ndecision-making algorithm is still a question due to the confrontation of many\nnormalization tools. Normalization is the basic action in defining and solving\na MADM problem and a MADM model. Normalization is the first, also necessary,\nstep in solving, i.e. the application of a MADM method. It is a fact that the\nselection of normalization methods has a direct effect on the results. One of\nthe latest normalization methods introduced is the Logarithmic Normalization\n(LN) method. This new method has a distinguished advantage, reflecting in that\na sum of the normalized values of criteria always equals 1. This normalization\nmethod had never been applied in any MADM methods before. This research study\nis focused on the analysis of the classical MADM methods based on logarithmic\nnormalization. VIKOR and TOPSIS, as the two famous MADM methods, were selected\nfor this reanalysis research study. Two numerical examples were checked in both\nmethods, based on both the classical and the novel ways based on the LN. The\nresults indicate that there are differences between the two approaches.\nEventually, a sensitivity analysis is also designed to illustrate the\nreliability of the final results.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jun 2020 06:08:31 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["Zolfani", "Sarfaraz", "", "IRIT-ADRIA, IRIT, UT1"], ["Yazdani", "Morteza", "", "IRIT-ADRIA, IRIT, UT1"], ["Pamucar", "Dragan", "", "IRIT-ADRIA, IRIT, UT1"], ["Zarat\u00e9", "Pascale", "", "IRIT-ADRIA, IRIT, UT1"]]}, {"id": "2006.08151", "submitter": "Pascale Zarate", "authors": "Pascale Zarat\\'e (UT1, IRIT, IRIT-ADRIA), Alemany Mme, Ana Esteso\n  Alvarez, Amir Sakka (UR TSCF), Guy Camilleri (UT3)", "title": "Group Decision Support for agriculture planning by a combination of\n  Mathematical Model and Collaborative Tool", "comments": null, "journal-ref": "ICDSST2020, University of Zaragoza, May 2020, Zaragoza, Spain.\n  pp.25-31", "doi": null, "report-no": null, "categories": "cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Decision making in the Agriculture domain can be a complex task. The land\narea allocated to each crop should be fixed every season according to several\nparameters: prices, demand, harvesting periods, seeds, ground, season etc...\nThe decision to make becomes more difficult when a group of farmers must fix\nthe price and all parameters all together. Generally, optimization models are\nuseful for farmers to find no dominated solutions, but it remains difficult if\nthe farmers have to agree on one solution. We combine two approaches in order\nto support a group of farmers engaged in this kind of decision making process.\nWe firstly generate a set of no dominated solutions thanks to a centralized\noptimization model. Based on this set of solution we then used a Group Decision\nSupport System called GRUS for choosing the best solution for the group of\nfarmers. The combined approach allows us to determine the best solution for the\ngroup in a consensual way. This combination of approaches is very innovative\nfor the Agriculture. This approach has been tested in laboratory in a previous\nwork. In the current work the same experiment has been conducted with real\nbusiness (farmers) in order to benefit from their expertise. The two\nexperiments are compared.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jun 2020 06:12:04 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["Zarat\u00e9", "Pascale", "", "UT1, IRIT, IRIT-ADRIA"], ["Mme", "Alemany", "", "UR TSCF"], ["Alvarez", "Ana Esteso", "", "UR TSCF"], ["Sakka", "Amir", "", "UR TSCF"], ["Camilleri", "Guy", "", "UT3"]]}, {"id": "2006.08153", "submitter": "Pascale Zarate", "authors": "Fadwa Oukhay, Pascale Zarat\\'e (UT1, IRIT, IRIT-ADRIA), Taieb Romdhane", "title": "Intelligent Decision Support System for Updating Control Plans", "comments": null, "journal-ref": "ICDSST 2020, University of Zaragoza, Spain, May 2020, Zaragoza,\n  Spain. pp.49-55", "doi": null, "report-no": null, "categories": "cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the current competitive environment, it is crucial for manufacturers to\nmake the best decisions in the shortest time, in order to optimize the\nefficiency and effectiveness of the manufacturing systems. These decisions\nreach from the strategic level to tactical and operational production planning\nand control. In this context, elaborating intelligent decisions support systems\n(DSS) that are capable of integrating a wide variety of models along with data\nand knowledge resources has become promising. This paper proposes an\nintelligent DSS for quality control planning. The DSS is a recommender system\n(RS) that helps the decision maker to select the best control scenario using\ntwo different approaches. The first is a manual choice using a multi-criteria\ndecision making method. The second is an automatic recommendation based on\ncase-based reasoning (CBR) technique. Furthermore, the proposed RS makes it\npossible to continuously update the control plans in order to be adapted to the\nactual process quality situation. In so doing, CBR is used for learning the\nrequired knowledge in order to improve the decision quality. A numerical\napplication is performed in a real case study in order to illustrate the\nfeasibility and practicability of the proposed DSS.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jun 2020 06:16:51 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["Oukhay", "Fadwa", "", "UT1, IRIT, IRIT-ADRIA"], ["Zarat\u00e9", "Pascale", "", "UT1, IRIT, IRIT-ADRIA"], ["Romdhane", "Taieb", ""]]}, {"id": "2006.08155", "submitter": "Pascale Zarate", "authors": "Jean Gomes Turet, Ana Paula Cabral Seixtas Cabral, Pascale Zarat\\'e\n  (UT1, IRIT, IRIT-ADRIA)", "title": "Selection of an Integrated Security Area for locating a State Military\n  Organization (SMO) based on group decision system: a multicriteria approach", "comments": null, "journal-ref": "ICDSST 2020, University of Zaragoza, Spain, May 2020, Zaragoza,\n  Spain", "doi": null, "report-no": null, "categories": "cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Over the past few years there has been growing concern among authorities over\ncrimes committed worldwide. In Brazil it is no different. High crime rates have\nencouraged government authorities involved in public safety to identify\nsolutions to minimize crimes. In this context, one way to plan and manage\nsecurity is in the division of neighborhoods in ISA (Integrated Security\nAreas). Each ISA has a neighborhood conglomerates taking into account their\ngeolocation. From this it becomes possible to maximize security management and\ncombat crime. Based on that, one of the main points that generate great\ndiscussion at the governmental level is the choice of a certain integrated\nsecurity area for the installation of a certain police battalion. This choice\ninvolves multiple decision makers since several hierarchies are involved. Thus,\nthis paper aims to identify the best ISA to deploy a police battalion using\ngroup decision techniques and tools. For this work the Group Decision Support\nSystem (GDSS) called GRoUp Support (GRUS) was used from two main Vote\ntechniques: Condorcet and Borda. With this it was possible to identify the best\nISA taking into account the pre-established criteria.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jun 2020 06:20:32 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["Turet", "Jean Gomes", "", "UT1, IRIT, IRIT-ADRIA"], ["Cabral", "Ana Paula Cabral Seixtas", "", "UT1, IRIT, IRIT-ADRIA"], ["Zarat\u00e9", "Pascale", "", "UT1, IRIT, IRIT-ADRIA"]]}, {"id": "2006.08156", "submitter": "Ke Shang", "authors": "Hisao Ishibuchi and Lie Meng Pang and Ke Shang", "title": "Solution Subset Selection for Final Decision Making in Evolutionary\n  Multi-Objective Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In general, a multi-objective optimization problem does not have a single\noptimal solution but a set of Pareto optimal solutions, which forms the Pareto\nfront in the objective space. Various evolutionary algorithms have been\nproposed to approximate the Pareto front using a pre-specified number of\nsolutions. Hundreds of solutions are obtained by their single run. The\nselection of a single final solution from the obtained solutions is assumed to\nbe done by a human decision maker. However, in many cases, the decision maker\ndoes not want to examine hundreds of solutions. Thus, it is needed to select a\nsmall subset of the obtained solutions. In this paper, we discuss subset\nselection from a viewpoint of the final decision making. First we briefly\nexplain existing subset selection studies. Next we formulate an expected loss\nfunction for subset selection. We also show that the formulated function is the\nsame as the IGD plus indicator. Then we report experimental results where the\nproposed approach is compared with other indicator-based subset selection\nmethods.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jun 2020 06:26:58 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["Ishibuchi", "Hisao", ""], ["Pang", "Lie Meng", ""], ["Shang", "Ke", ""]]}, {"id": "2006.08164", "submitter": "Gabriel Lima", "authors": "Gabriel Lima, Meeyoung Cha, Chiyoung Cha, Hyeyoung Hwang", "title": "COVID-19 Vaccine Acceptance in the US and UK in the Early Phase of the\n  Pandemic: AI-Generated Vaccines Hesitancy for Minors, and the Role of\n  Governments", "comments": "Published to the Journal of the Korean Data Analysis Society vol. 23\n  no. 3", "journal-ref": null, "doi": "10.37727/jkdas.2021.23.2.1045", "report-no": null, "categories": "cs.CY cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This study presents survey results of the public's willingness to get\nvaccinated against COVID-19 during an early phase of the pandemic and examines\nfactors that could influence vaccine acceptance based on a between-subjects\ndesign. A representative quota sample of 572 adults in the US and UK\nparticipated in an online survey. First, the participants' medical use\ntendencies and initial vaccine acceptance were assessed; then, short vignettes\nwere provided to evaluate their changes in attitude towards COVID-19 vaccines.\nFor data analysis, ANOVA and post hoc pairwise comparisons were used. The\nparticipants were more reluctant to vaccinate their children than themselves\nand the elderly. The use of artificial intelligence (AI) in vaccine development\ndid not influence vaccine acceptance. Vignettes that explicitly stated the high\neffectiveness of vaccines led to an increase in vaccine acceptance. Our study\nsuggests public policies emphasizing the vaccine effectiveness against the\nvirus could lead to higher vaccination rates. We also discuss the public's\nexpectations of governments concerning vaccine safety and present a series of\nimplications based on our findings.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jun 2020 06:47:13 GMT"}, {"version": "v2", "created": "Fri, 3 Jul 2020 07:16:44 GMT"}, {"version": "v3", "created": "Wed, 23 Jun 2021 07:10:17 GMT"}], "update_date": "2021-06-24", "authors_parsed": [["Lima", "Gabriel", ""], ["Cha", "Meeyoung", ""], ["Cha", "Chiyoung", ""], ["Hwang", "Hyeyoung", ""]]}, {"id": "2006.08170", "submitter": "Jin Zhang", "authors": "Jin Zhang, Jianhao Wang, Hao Hu, Tong Chen, Yingfeng Chen, Changjie\n  Fan and Chongjie Zhang", "title": "MetaCURE: Meta Reinforcement Learning with Empowerment-Driven\n  Exploration", "comments": null, "journal-ref": "In International Conference on Machine Learning (pp. 12600-12610).\n  PMLR", "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Meta reinforcement learning (meta-RL) extracts knowledge from previous tasks\nand achieves fast adaptation to new tasks. Despite recent progress, efficient\nexploration in meta-RL remains a key challenge in sparse-reward tasks, as it\nrequires quickly finding informative task-relevant experiences in both\nmeta-training and adaptation. To address this challenge, we explicitly model an\nexploration policy learning problem for meta-RL, which is separated from\nexploitation policy learning, and introduce a novel empowerment-driven\nexploration objective, which aims to maximize information gain for task\nidentification. We derive a corresponding intrinsic reward and develop a new\noff-policy meta-RL framework, which efficiently learns separate context-aware\nexploration and exploitation policies by sharing the knowledge of task\ninference. Experimental evaluation shows that our meta-RL method significantly\noutperforms state-of-the-art baselines on various sparse-reward MuJoCo\nlocomotion tasks and more complex sparse-reward Meta-World tasks.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jun 2020 06:56:18 GMT"}, {"version": "v2", "created": "Sun, 7 Feb 2021 00:04:14 GMT"}, {"version": "v3", "created": "Mon, 19 Jul 2021 01:31:34 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Zhang", "Jin", ""], ["Wang", "Jianhao", ""], ["Hu", "Hao", ""], ["Chen", "Tong", ""], ["Chen", "Yingfeng", ""], ["Fan", "Changjie", ""], ["Zhang", "Chongjie", ""]]}, {"id": "2006.08236", "submitter": "Joey Hong", "authors": "Joey Hong and Branislav Kveton and Manzil Zaheer and Yinlam Chow and\n  Amr Ahmed", "title": "Non-Stationary Off-Policy Optimization", "comments": "AISTATS 2021; 16 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Off-policy learning is a framework for evaluating and optimizing policies\nwithout deploying them, from data collected by another policy. Real-world\nenvironments are typically non-stationary and the offline learned policies\nshould adapt to these changes. To address this challenge, we study the novel\nproblem of off-policy optimization in piecewise-stationary contextual bandits.\nOur proposed solution has two phases. In the offline learning phase, we\npartition logged data into categorical latent states and learn a near-optimal\nsub-policy for each state. In the online deployment phase, we adaptively switch\nbetween the learned sub-policies based on their performance. This approach is\npractical and analyzable, and we provide guarantees on both the quality of\noff-policy optimization and the regret during online deployment. To show the\neffectiveness of our approach, we compare it to state-of-the-art baselines on\nboth synthetic and real-world datasets. Our approach outperforms methods that\nact only on observed context.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jun 2020 09:16:09 GMT"}, {"version": "v2", "created": "Tue, 1 Dec 2020 09:36:21 GMT"}, {"version": "v3", "created": "Sun, 4 Apr 2021 06:44:08 GMT"}], "update_date": "2021-04-06", "authors_parsed": [["Hong", "Joey", ""], ["Kveton", "Branislav", ""], ["Zaheer", "Manzil", ""], ["Chow", "Yinlam", ""], ["Ahmed", "Amr", ""]]}, {"id": "2006.08246", "submitter": "David Speck", "authors": "David Speck, Andr\\'e Biedenkapp, Frank Hutter, Robert Mattm\\\"uller,\n  Marius Lindauer", "title": "Learning Heuristic Selection with Dynamic Algorithm Configuration", "comments": "Long version of the paper at the International Conference on\n  Automated Planning and Scheduling (ICAPS) 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A key challenge in satisficing planning is to use multiple heuristics within\none heuristic search. An aggregation of multiple heuristic estimates, for\nexample by taking the maximum, has the disadvantage that bad estimates of a\nsingle heuristic can negatively affect the whole search. Since the performance\nof a heuristic varies from instance to instance, approaches such as algorithm\nselection can be successfully applied. In addition, alternating between\nmultiple heuristics during the search makes it possible to use all heuristics\nequally and improve performance. However, all these approaches ignore the\ninternal search dynamics of a planning system, which can help to select the\nmost useful heuristics for the current expansion step. We show that dynamic\nalgorithm configuration can be used for dynamic heuristic selection which takes\ninto account the internal search dynamics of a planning system. Furthermore, we\nprove that this approach generalizes over existing approaches and that it can\nexponentially improve the performance of the heuristic search. To learn dynamic\nheuristic selection, we propose an approach based on reinforcement learning and\nshow empirically that domain-wise learned policies, which take the internal\nsearch dynamics of a planning system into account, can exceed existing\napproaches.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jun 2020 09:35:07 GMT"}, {"version": "v2", "created": "Wed, 9 Dec 2020 09:25:42 GMT"}, {"version": "v3", "created": "Mon, 12 Apr 2021 14:32:32 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Speck", "David", ""], ["Biedenkapp", "Andr\u00e9", ""], ["Hutter", "Frank", ""], ["Mattm\u00fcller", "Robert", ""], ["Lindauer", "Marius", ""]]}, {"id": "2006.08295", "submitter": "Jakub Kowalski", "authors": "Jakub Kowalski, Rados{\\l}aw Miernik, Maksymilian Mika, Wojciech\n  Pawlik, Jakub Sutowicz, Marek Szyku{\\l}a, Andrzej Tkaczyk", "title": "Efficient Reasoning in Regular Boardgames", "comments": "IEEE Conference on Games 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present the technical side of reasoning in Regular Boardgames (RBG)\nlanguage -- a universal General Game Playing (GGP) formalism for the class of\nfinite deterministic games with perfect information, encoding rules in the form\nof regular expressions. RBG serves as a research tool that aims to aid in the\ndevelopment of generalized algorithms for knowledge inference, analysis,\ngeneration, learning, and playing games. In all these tasks, both generality\nand efficiency are important.\n  In the first part, this paper describes optimizations used by the RBG\ncompiler. The impact of these optimizations ranges from 1.7 to even 33-fold\nefficiency improvement when measuring the number of possible game playouts per\nsecond. Then, we perform an in-depth efficiency comparison with three other\nmodern GGP systems (GDL, Ludii, Ai Ai). We also include our own highly\noptimized game-specific reasoners to provide a point of reference of the\nmaximum speed. Our experiments show that RBG is currently the fastest among the\nabstract general game playing languages, and its efficiency can be competitive\nto common interface-based systems that rely on handcrafted game-specific\nimplementations. Finally, we discuss some issues and methodology of computing\nbenchmarks like this.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jun 2020 11:42:08 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["Kowalski", "Jakub", ""], ["Miernik", "Rados\u0142aw", ""], ["Mika", "Maksymilian", ""], ["Pawlik", "Wojciech", ""], ["Sutowicz", "Jakub", ""], ["Szyku\u0142a", "Marek", ""], ["Tkaczyk", "Andrzej", ""]]}, {"id": "2006.08327", "submitter": "Raphael Kramer", "authors": "Raphael Kramer and Arthur Kramer", "title": "Exact and heuristic methods for the discrete parallel machine scheduling\n  location problem", "comments": "25 pages, 5 figures, 7 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The discrete parallel machine makespan scheduling location (ScheLoc) problem\nis an integrated combinatorial optimization problem that combines facility\nlocation and job scheduling. The problem consists in choosing the locations of\n$p$ machines among a finite set of candidates and scheduling a set of jobs on\nthese machines, aiming to minimize the makespan. Depending on the machine\nlocation, the jobs may have different release dates, and thus the location\ndecisions have a direct impact on the scheduling decisions. To solve the\nproblem, it is proposed a new arc-flow formulation, a column generation and\nthree heuristic procedures that are evaluated through extensive computational\nexperiments. By embedding the proposed procedures into a framework algorithm,\nwe are able to find proven optimal solutions for all benchmark instances from\nthe related literature and to obtain small percentage gaps for a new set of\nchallenging instances.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jun 2020 00:10:18 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["Kramer", "Raphael", ""], ["Kramer", "Arthur", ""]]}, {"id": "2006.08331", "submitter": "Abdelrhman Saleh", "authors": "Abdelrhman Saleh, Tovly Deutsch, Stephen Casper, Yonatan Belinkov,\n  Stuart Shieber", "title": "Probing Neural Dialog Models for Conversational Understanding", "comments": null, "journal-ref": null, "doi": "10.18653/v1/2020.nlp4convai-1.15", "report-no": null, "categories": "cs.CL cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The predominant approach to open-domain dialog generation relies on\nend-to-end training of neural models on chat datasets. However, this approach\nprovides little insight as to what these models learn (or do not learn) about\nengaging in dialog. In this study, we analyze the internal representations\nlearned by neural open-domain dialog systems and evaluate the quality of these\nrepresentations for learning basic conversational skills. Our results suggest\nthat standard open-domain dialog systems struggle with answering questions,\ninferring contradiction, and determining the topic of conversation, among other\ntasks. We also find that the dyadic, turn-taking nature of dialog is not fully\nleveraged by these models. By exploring these limitations, we highlight the\nneed for additional research into architectures and training methods that can\nbetter capture high-level information about dialog.\n", "versions": [{"version": "v1", "created": "Sun, 7 Jun 2020 17:32:00 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Saleh", "Abdelrhman", ""], ["Deutsch", "Tovly", ""], ["Casper", "Stephen", ""], ["Belinkov", "Yonatan", ""], ["Shieber", "Stuart", ""]]}, {"id": "2006.08333", "submitter": "Sasanka Sekhar Chanda", "authors": "Sasanka Sekhar Chanda and Sai Yayavaram", "title": "An Algorithm to find Superior Fitness on NK Landscapes under High\n  Complexity: Muddling Through", "comments": "6 pages and 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.MA q-bio.PE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Under high complexity - given by pervasive interdependence between\nconstituent elements of a decision in an NK landscape - our algorithm obtains\nfitness superior to that reported in extant research. We distribute the\ndecision elements comprising a decision into clusters. When a change in value\nof a decision element is considered, a forward move is made if the aggregate\nfitness of the cluster members residing alongside the decision element is\nhigher. The decision configuration with the highest fitness in the path is\nselected. Increasing the number of clusters obtains even higher fitness.\nFurther, implementing moves comprising of up to two changes in a cluster also\nobtains higher fitness. Our algorithm obtains superior outcomes by enabling\nmore extensive search, allowing inspection of more distant configurations. We\nname this algorithm the muddling through algorithm, in memory of Charles\nLindblom who spotted the efficacy of the process long before sophisticated\ncomputer simulations came into being.\n", "versions": [{"version": "v1", "created": "Sat, 6 Jun 2020 11:08:20 GMT"}, {"version": "v2", "created": "Mon, 7 Sep 2020 12:12:40 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Chanda", "Sasanka Sekhar", ""], ["Yayavaram", "Sai", ""]]}, {"id": "2006.08343", "submitter": "William Schoenberg", "authors": "William Schoenberg", "title": "Automated Diagram Generation to Build Understanding and Usability", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Causal loop and stock and flow diagrams are broadly used in System Dynamics\nbecause they help organize relationships and convey meaning. Using the\nanalytical work of Schoenberg (2019) to select what to include in a compressed\nmodel, this paper demonstrates how that information can be clearly presented in\nan automatically generated causal loop diagram. The diagrams are generated\nusing tools developed by people working in graph theory and the generated\ndiagrams are clear and aesthetically pleasing. This approach can also be built\nupon to generate stock and flow diagrams. Automated stock and flow diagram\ngeneration opens the door to representing models developed using only\nequations, regardless or origin, in a clear and easy to understand way. Because\nmodels can be large, the application of grouping techniques, again developed\nfor graph theory, can help structure the resulting diagrams in the most usable\nform. This paper describes the algorithms developed for automated diagram\ngeneration and shows a number of examples of their uses in large models. The\napplication of these techniques to existing, but inaccessible, equation-based\nmodels can help broaden the knowledge base for System Dynamics modeling. The\ntechniques can also be used to improve layout in all, or part, of existing\nmodels with diagrammatic informtion.\n", "versions": [{"version": "v1", "created": "Wed, 27 May 2020 22:32:16 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["Schoenberg", "William", ""]]}, {"id": "2006.08347", "submitter": "Sujatha A A", "authors": "Sujatha A, L Govindaraju and N Shivakumar", "title": "Application of Fuzzy Rule based System for Highway Research Board\n  Classification of Soils", "comments": "14 pages, 7 figures,\n  https://wireilla.com/ijfls/abstract/10220ijfls01.html", "journal-ref": "International Journal of Fuzzy Logic Systems, vol. 10, no. 2, pp.\n  1-14, 2020", "doi": "10.5121/ijfls.2020.10201", "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fuzzy rule-based model is a powerful tool for imitating the human way of\nthinking and solving uncertainty-related problems as it allows for\nunderstandable and interpretable rule bases. The objective of this paper is to\nstudy the applicability of fuzzy rule-based modelling to quantify soil\nclassification for engineering purposes by qualitatively considering soil index\nproperties. The classification system of the Highway Research Board is\nconsidered to illustrate a fuzzy rule-based model. The soil's index properties\nare fuzzified using triangular functions, and the fuzzy membership values are\ncalculated. Fuzzy arithmetical operators are then applied to the membership\nvalues obtained for classification. Fuzzy decision tree classification\nalgorithm is used to derive fuzzy if-then rules to quantify qualitative soil\nclassification. The proposed system is implemented in MATLAB. The results\nobtained are checked and the implementation of the proposed model is measured\nagainst the outcomes of the laboratory tests.\n", "versions": [{"version": "v1", "created": "Sun, 10 May 2020 14:33:32 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["A", "Sujatha", ""], ["Govindaraju", "L", ""], ["Shivakumar", "N", ""]]}, {"id": "2006.08364", "submitter": "Pablo Robles-Granda", "authors": "Pablo Robles-Granda, Suwen Lin, Xian Wu, Sidney D'Mello, Gonzalo J.\n  Martinez, Koustuv Saha, Kari Nies, Gloria Mark, Andrew T. Campbell, Munmun De\n  Choudhury, Anind D. Dey, Julie Gregg, Ted Grover, Stephen M. Mattingly,\n  Shayan Mirjafari, Edward Moskal, Aaron Striegel, Nitesh V. Chawla", "title": "Jointly Predicting Job Performance, Personality, Cognitive Ability,\n  Affect, and Well-Being", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Assessment of job performance, personalized health and psychometric measures\nare domains where data-driven and ubiquitous computing exhibits the potential\nof a profound impact in the future. Existing techniques use data extracted from\nquestionnaires, sensors (wearable, computer, etc.), or other traits, to assess\nwell-being and cognitive attributes of individuals. However, these techniques\ncan neither predict individual's well-being and psychological traits in a\nglobal manner nor consider the challenges associated to processing the data\navailable, that is incomplete and noisy. In this paper, we create a benchmark\nfor predictive analysis of individuals from a perspective that integrates:\nphysical and physiological behavior, psychological states and traits, and job\nperformance. We design data mining techniques as benchmark and uses real noisy\nand incomplete data derived from wearable sensors to predict 19 constructs\nbased on 12 standardized well-validated tests. The study included 757\nparticipants who were knowledge workers in organizations across the USA with\nvaried work roles. We developed a data mining framework to extract the\nmeaningful predictors for each of the 19 variables under consideration. Our\nmodel is the first benchmark that combines these various instrument-derived\nvariables in a single framework to understand people's behavior by leveraging\nreal uncurated data from wearable, mobile, and social media sources. We verify\nour approach experimentally using the data obtained from our longitudinal\nstudy. The results show that our framework is consistently reliable and capable\nof predicting the variables under study better than the baselines when\nprediction is restricted to the noisy, incomplete data.\n", "versions": [{"version": "v1", "created": "Wed, 10 Jun 2020 14:30:29 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["Robles-Granda", "Pablo", ""], ["Lin", "Suwen", ""], ["Wu", "Xian", ""], ["D'Mello", "Sidney", ""], ["Martinez", "Gonzalo J.", ""], ["Saha", "Koustuv", ""], ["Nies", "Kari", ""], ["Mark", "Gloria", ""], ["Campbell", "Andrew T.", ""], ["De Choudhury", "Munmun", ""], ["Dey", "Anind D.", ""], ["Gregg", "Julie", ""], ["Grover", "Ted", ""], ["Mattingly", "Stephen M.", ""], ["Mirjafari", "Shayan", ""], ["Moskal", "Edward", ""], ["Striegel", "Aaron", ""], ["Chawla", "Nitesh V.", ""]]}, {"id": "2006.08381", "submitter": "Kevin Ellis", "authors": "Kevin Ellis, Catherine Wong, Maxwell Nye, Mathias Sable-Meyer, Luc\n  Cary, Lucas Morales, Luke Hewitt, Armando Solar-Lezama, Joshua B. Tenenbaum", "title": "DreamCoder: Growing generalizable, interpretable knowledge with\n  wake-sleep Bayesian program learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Expert problem-solving is driven by powerful languages for thinking about\nproblems and their solutions. Acquiring expertise means learning these\nlanguages -- systems of concepts, alongside the skills to use them. We present\nDreamCoder, a system that learns to solve problems by writing programs. It\nbuilds expertise by creating programming languages for expressing domain\nconcepts, together with neural networks to guide the search for programs within\nthese languages. A ``wake-sleep'' learning algorithm alternately extends the\nlanguage with new symbolic abstractions and trains the neural network on\nimagined and replayed problems. DreamCoder solves both classic inductive\nprogramming tasks and creative tasks such as drawing pictures and building\nscenes. It rediscovers the basics of modern functional programming, vector\nalgebra and classical physics, including Newton's and Coulomb's laws. Concepts\nare built compositionally from those learned earlier, yielding multi-layered\nsymbolic representations that are interpretable and transferrable to new tasks,\nwhile still growing scalably and flexibly with experience.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jun 2020 13:06:29 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["Ellis", "Kevin", ""], ["Wong", "Catherine", ""], ["Nye", "Maxwell", ""], ["Sable-Meyer", "Mathias", ""], ["Cary", "Luc", ""], ["Morales", "Lucas", ""], ["Hewitt", "Luke", ""], ["Solar-Lezama", "Armando", ""], ["Tenenbaum", "Joshua B.", ""]]}, {"id": "2006.08409", "submitter": "Katerina Morozova", "authors": "Alexander Gavrilenko, Katerina Morozova", "title": "Machine Common Sense", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine common sense remains a broad, potentially unbounded problem in\nartificial intelligence (AI). There is a wide range of strategies that can be\nemployed to make progress on this challenge. This article deals with the\naspects of modeling commonsense reasoning focusing on such domain as\ninterpersonal interactions. The basic idea is that there are several types of\ncommonsense reasoning: one is manifested at the logical level of physical\nactions, the other deals with the understanding of the essence of human-human\ninteractions. Existing approaches, based on formal logic and artificial neural\nnetworks, allow for modeling only the first type of common sense. To model the\nsecond type, it is vital to understand the motives and rules of human behavior.\nThis model is based on real-life heuristics, i.e., the rules of thumb,\ndeveloped through knowledge and experience of different generations. Such\nknowledge base allows for development of an expert system with inference and\nexplanatory mechanisms (commonsense reasoning algorithms and personal models).\nAlgorithms provide tools for a situation analysis, while personal models make\nit possible to identify personality traits. The system so designed should\nperform the function of amplified intelligence for interactions, including\nhuman-machine.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jun 2020 13:59:47 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["Gavrilenko", "Alexander", ""], ["Morozova", "Katerina", ""]]}, {"id": "2006.08425", "submitter": "William Schoenberg", "authors": "Robert Eberlein, William Schoenberg", "title": "Finding the Loops that Matter", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Loops that Matter method (Schoenberg et. al, 2019) for understanding\nmodel behavior provides metrics showing the contribution of the feedback loops\nin a model to behavior at each point in time. To provide these metrics, it is\nnecessary find the set of loops on which to compute them. We show in this paper\nthe necessity of including loops that are important at different points in the\nsimulation. These important loops may not be independent of one another and\ncannot be determined from static analysis of the model structure. We then\ndescribe an algorithm that can be used to discover the most important loops in\nmodels that are too feedback rich for exhaustive loop discovery. We demonstrate\nthe use of this algorithm in terms of its ability to find the most explanatory\nloops, and its computational performance for large models. By using this\napproach, the Loops that Matter method can be applied to models of any size or\ncomplexity.\n", "versions": [{"version": "v1", "created": "Wed, 27 May 2020 22:27:58 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["Eberlein", "Robert", ""], ["Schoenberg", "William", ""]]}, {"id": "2006.08434", "submitter": "Remy Priem", "authors": "Remy Priem, Hugo Gagnon, Ian Chittick, Stephane Dufresne, Youssef\n  Diouane and Nathalie Bartoli", "title": "An efficient application of Bayesian optimization to an industrial MDO\n  framework for aircraft design", "comments": "16 pages, 8 figures, 4 tables. AIAA AVIATION 2020 FORUM", "journal-ref": null, "doi": "10.2514/6.2020-3152", "report-no": null, "categories": "cs.CE cs.AI cs.LG math.OC stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  The multi-level, multi-disciplinary and multi-fidelity optimization framework\ndeveloped at Bombardier Aviation has shown great results to explore efficient\nand competitive aircraft configurations. This optimization framework has been\ndeveloped within the Isight software, the latter offers a set of ready-to-use\noptimizers. Unfortunately, the computational effort required by the Isight\noptimizers can be prohibitive with respect to the requirements of an industrial\ncontext. In this paper, a constrained Bayesian optimization optimizer, namely\nthe super efficient global optimization with mixture of experts, is used to\nreduce the optimization computational effort. The obtained results showed\nsignificant improvements compared to two of the popular Isight optimizers. The\ncapabilities of the tested constrained Bayesian optimization solver are\ndemonstrated on Bombardier research aircraft configuration study cases.\n", "versions": [{"version": "v1", "created": "Fri, 12 Jun 2020 07:44:25 GMT"}], "update_date": "2020-06-17", "authors_parsed": [["Priem", "Remy", ""], ["Gagnon", "Hugo", ""], ["Chittick", "Ian", ""], ["Dufresne", "Stephane", ""], ["Diouane", "Youssef", ""], ["Bartoli", "Nathalie", ""]]}, {"id": "2006.08457", "submitter": "Florian Dietz", "authors": "Florian Dietz", "title": "Interaction Networks: Using a Reinforcement Learner to train other\n  Machine Learning algorithms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The wiring of neurons in the brain is more flexible than the wiring of\nconnections in contemporary artificial neural networks. It is possible that\nthis extra flexibility is important for efficient problem solving and learning.\n  This paper introduces the Interaction Network. Interaction Networks aim to\ncapture some of this extra flexibility.\n  An Interaction Network consists of a collection of conventional neural\nnetworks, a set of memory locations, and a DQN or other reinforcement learner.\nThe DQN decides when each of the neural networks is executed, and on what\nmemory locations. In this way, the individual neural networks can be trained on\ndifferent data, for different tasks. At the same time, the results of the\nindividual networks influence the decision process of the reinforcement\nlearner. This results in a feedback loop that allows the DQN to perform actions\nthat improve its own decision-making.\n  Any existing type of neural network can be reproduced in an Interaction\nNetwork in its entirety, with only a constant computational overhead.\n  Interaction Networks can then introduce additional features to improve\nperformance further. These make the algorithm more flexible and general, but at\nthe expense of being harder to train.\n  In this paper, thought experiments are used to explore how the additional\nabilities of Interaction Networks could be used to improve various existing\ntypes of neural networks.\n  Several experiments have been run to prove that the concept is sound. These\nshow that the basic idea works, but they also reveal a number of challenges\nthat do not appear in conventional neural networks, which make Interaction\nNetworks very hard to train.\n  Further research needs to be done to alleviate these issues. A number of\npromising avenues of research to achieve this are outlined in this paper.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jun 2020 15:03:53 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["Dietz", "Florian", ""]]}, {"id": "2006.08458", "submitter": "Matthew Craven", "authors": "Matthew J. Craven and John R. Woodward", "title": "Evolution of Group-Theoretic Cryptology Attacks using Hyper-heuristics", "comments": "16 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.GR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In previous work, we developed a single Evolutionary Algorithm (EA) to solve\nrandom instances of the Anshel-Anshel-Goldfeld (AAG) key exchange protocol over\npolycyclic groups. The EA consisted of six simple heuristics which manipulated\nstrings. The present work extends this by exploring the use of hyper-heuristics\nin group-theoretic cryptology for the first time. Hyper-heuristics are a way to\ngenerate new algorithms from existing algorithm components (in this case the\nsimple heuristics), with the EAs being one example of the type of algorithm\nwhich can be generated by our hyper-heuristic framework. We take as a starting\npoint the above EA and allow hyper-heuristics to build on it by making small\ntweaks to it. This adaptation is through a process of taking the EA and\ninjecting chains of heuristics built from the simple heuristics. We demonstrate\nwe can create novel heuristic chains, which when placed in the EA create\nalgorithms which out-perform the existing EA. The new algorithms solve a\nmarkedly greater number of random AAG instances than the EA for harder\ninstances. This suggests the approach could be applied to many of the same\nkinds of problems, providing a framework for the solution of cryptology\nproblems over groups. The contribution of this paper is thus a framework to\nautomatically build algorithms to attack cryptology problems.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jun 2020 15:03:57 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["Craven", "Matthew J.", ""], ["Woodward", "John R.", ""]]}, {"id": "2006.08467", "submitter": "Marie-Laure Mugnier", "authors": "Pierre Bourhis and Michel Lecl\\`ere and Marie-Laure Mugnier and Sophie\n  Tison and Federico Ulliana and Lily Galois", "title": "Oblivious and Semi-Oblivious Boundedness for Existential Rules", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CC cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the notion of boundedness in the context of positive existential\nrules, that is, whether there exists an upper bound to the depth of the chase\nprocedure, that is independent from the initial instance. By focussing our\nattention on the oblivious and the semi-oblivious chase variants, we give a\ncharacterization of boundedness in terms of FO-rewritability and chase\ntermination. We show that it is decidable to recognize if a set of rules is\nbounded for several classes and outline the complexity of the problem.\n  This report contains the paper published at IJCAI 2019 and an appendix with\nfull proofs.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jun 2020 15:18:57 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["Bourhis", "Pierre", ""], ["Lecl\u00e8re", "Michel", ""], ["Mugnier", "Marie-Laure", ""], ["Tison", "Sophie", ""], ["Ulliana", "Federico", ""], ["Galois", "Lily", ""]]}, {"id": "2006.08472", "submitter": "Hao Sun", "authors": "Chengping Rao and Hao Sun and Yang Liu", "title": "Physics informed deep learning for computational elastodynamics without\n  labeled data", "comments": "26 pages, 22 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.AI cs.CE cs.LG cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Numerical methods such as finite element have been flourishing in the past\ndecades for modeling solid mechanics problems via solving governing partial\ndifferential equations (PDEs). A salient aspect that distinguishes these\nnumerical methods is how they approximate the physical fields of interest.\nPhysics-informed deep learning is a novel approach recently developed for\nmodeling PDE solutions and shows promise to solve computational mechanics\nproblems without using any labeled data. The philosophy behind it is to\napproximate the quantity of interest (e.g., PDE solution variables) by a deep\nneural network (DNN) and embed the physical law to regularize the network. To\nthis end, training the network is equivalent to minimization of a well-designed\nloss function that contains the PDE residuals and initial/boundary conditions\n(I/BCs). In this paper, we present a physics-informed neural network (PINN)\nwith mixed-variable output to model elastodynamics problems without resort to\nlabeled data, in which the I/BCs are hardly imposed. In particular, both the\ndisplacement and stress components are taken as the DNN output, inspired by the\nhybrid finite element analysis, which largely improves the accuracy and\ntrainability of the network. Since the conventional PINN framework augments all\nthe residual loss components in a \"soft\" manner with Lagrange multipliers, the\nweakly imposed I/BCs cannot not be well satisfied especially when complex I/BCs\nare present. To overcome this issue, a composite scheme of DNNs is established\nbased on multiple single DNNs such that the I/BCs can be satisfied forcibly in\na \"hard\" manner. The propose PINN framework is demonstrated on several\nnumerical elasticity examples with different I/BCs, including both static and\ndynamic problems as well as wave propagation in truncated domains. Results show\nthe promise of PINN in the context of computational mechanics applications.\n", "versions": [{"version": "v1", "created": "Wed, 10 Jun 2020 19:05:08 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["Rao", "Chengping", ""], ["Sun", "Hao", ""], ["Liu", "Yang", ""]]}, {"id": "2006.08475", "submitter": "Muhammad Cheema", "authors": "Lingxiao Li, Muhammad Aamir Cheema, Hua Lu, Mohammed Eunus Ali, Adel\n  N. Toosi", "title": "Comparing Alternative Route Planning Techniques: A Comparative User\n  Study on Melbourne, Dhaka and Copenhagen Road Networks", "comments": "Extended the user study to also include the road networks of Dhaka\n  and Copenhagen (the previous version only had Melbourne road network)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many modern navigation systems and map-based services do not only provide the\nfastest route from a source location s to a target location t but also provide\na few alternative routes to the users as more options to choose from.\nConsequently, computing alternative paths has received significant research\nattention. However, it is unclear which of the existing approaches generates\nalternative routes of better quality because the quality of these alternatives\nis mostly subjective. Motivated by this, in this paper, we present a user study\nconducted on the road networks of Melbourne, Dhaka and Copenhagen that compares\nthe quality (as perceived by the users) of the alternative routes generated by\nfour of the most popular existing approaches including the routes provided by\nGoogle Maps. We also present a web-based demo system that can be accessed using\nany internet-enabled device and allows users to see the alternative routes\ngenerated by the four approaches for any pair of selected source and target. We\nreport the average ratings received by the four approaches and our statistical\nanalysis shows that there is no credible evidence that the four approaches\nreceive different ratings on average. We also discuss the limitations of this\nuser study and recommend the readers to interpret these results with caution\nbecause certain factors may have affected the participants' ratings.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jun 2020 15:25:48 GMT"}, {"version": "v2", "created": "Thu, 14 Jan 2021 08:52:53 GMT"}], "update_date": "2021-01-15", "authors_parsed": [["Li", "Lingxiao", ""], ["Cheema", "Muhammad Aamir", ""], ["Lu", "Hua", ""], ["Ali", "Mohammed Eunus", ""], ["Toosi", "Adel N.", ""]]}, {"id": "2006.08480", "submitter": "Vaishak Belle", "authors": "Vaishak Belle", "title": "Symbolic Logic meets Machine Learning: A Brief Survey in Infinite\n  Domains", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The tension between deduction and induction is perhaps the most fundamental\nissue in areas such as philosophy, cognition and artificial intelligence (AI).\nThe deduction camp concerns itself with questions about the expressiveness of\nformal languages for capturing knowledge about the world, together with proof\nsystems for reasoning from such knowledge bases. The learning camp attempts to\ngeneralize from examples about partial descriptions about the world. In AI,\nhistorically, these camps have loosely divided the development of the field,\nbut advances in cross-over areas such as statistical relational learning,\nneuro-symbolic systems, and high-level control have illustrated that the\ndichotomy is not very constructive, and perhaps even ill-formed. In this\narticle, we survey work that provides further evidence for the connections\nbetween logic and learning. Our narrative is structured in terms of three\nstrands: logic versus learning, machine learning for logic, and logic for\nmachine learning, but naturally, there is considerable overlap. We place an\nemphasis on the following \"sore\" point: there is a common misconception that\nlogic is for discrete properties, whereas probability theory and machine\nlearning, more generally, is for continuous properties. We report on results\nthat challenge this view on the limitations of logic, and expose the role that\nlogic can play for learning in infinite domains.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jun 2020 15:29:49 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["Belle", "Vaishak", ""]]}, {"id": "2006.08505", "submitter": "Nicolas Perrin-Gilbert", "authors": "Geoffrey Cideron, Thomas Pierrot, Nicolas Perrin, Karim Beguir and\n  Olivier Sigaud", "title": "QD-RL: Efficient Mixing of Quality and Diversity in Reinforcement\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel reinforcement learning algorithm,QD-RL, that incorporates\nthe strengths of off-policy RL algorithms into Quality Diversity (QD)\napproaches. Quality-Diversity methods contribute structural biases by\ndecoupling the search for diversity from the search for high return, resulting\nin efficient management of the exploration-exploitation trade-off. However,\nthese approaches generally suffer from sample inefficiency as they call upon\nevolutionary techniques. QD-RL removes this limitation by relying on off-policy\nRL algorithms. More precisely, we train a population of off-policy deep RL\nagents to simultaneously maximize diversity inside the population and the\nreturn of the agents. QD-RL selects agents from the diversity-return Pareto\nFront, resulting in stable and efficient population updates. Our experiments on\nthe Ant-Maze environment show that QD-RL can solve challenging exploration and\ncontrol problems with deceptive rewards while being more than 15 times more\nsample efficient than its evolutionary counterparts.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jun 2020 16:04:06 GMT"}, {"version": "v2", "created": "Tue, 13 Apr 2021 12:15:55 GMT"}], "update_date": "2021-04-14", "authors_parsed": [["Cideron", "Geoffrey", ""], ["Pierrot", "Thomas", ""], ["Perrin", "Nicolas", ""], ["Beguir", "Karim", ""], ["Sigaud", "Olivier", ""]]}, {"id": "2006.08555", "submitter": "Stephen McAleer", "authors": "Stephen McAleer, John Lanier, Roy Fox, Pierre Baldi", "title": "Pipeline PSRO: A Scalable Approach for Finding Approximate Nash\n  Equilibria in Large Games", "comments": "SM and JL contributed equally", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.AI cs.LG cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Finding approximate Nash equilibria in zero-sum imperfect-information games\nis challenging when the number of information states is large. Policy Space\nResponse Oracles (PSRO) is a deep reinforcement learning algorithm grounded in\ngame theory that is guaranteed to converge to an approximate Nash equilibrium.\nHowever, PSRO requires training a reinforcement learning policy at each\niteration, making it too slow for large games. We show through counterexamples\nand experiments that DCH and Rectified PSRO, two existing approaches to scaling\nup PSRO, fail to converge even in small games. We introduce Pipeline PSRO\n(P2SRO), the first scalable general method for finding approximate Nash\nequilibria in large zero-sum imperfect-information games. P2SRO is able to\nparallelize PSRO with convergence guarantees by maintaining a hierarchical\npipeline of reinforcement learning workers, each training against the policies\ngenerated by lower levels in the hierarchy. We show that unlike existing\nmethods, P2SRO converges to an approximate Nash equilibrium, and does so faster\nas the number of parallel workers increases, across a variety of imperfect\ninformation games. We also introduce an open-source environment for Barrage\nStratego, a variant of Stratego with an approximate game tree complexity of\n$10^{50}$. P2SRO is able to achieve state-of-the-art performance on Barrage\nStratego and beats all existing bots. Experiment code is available\nathttps://github.com/JBLanier/pipeline-psro.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jun 2020 17:17:17 GMT"}, {"version": "v2", "created": "Thu, 18 Feb 2021 19:26:01 GMT"}], "update_date": "2021-02-22", "authors_parsed": [["McAleer", "Stephen", ""], ["Lanier", "John", ""], ["Fox", "Roy", ""], ["Baldi", "Pierre", ""]]}, {"id": "2006.08601", "submitter": "Samuel Lerman", "authors": "Samuel Lerman, Chenliang Xu, Charles Venuto, Henry Kautz", "title": "Explaining Local, Global, And Higher-Order Interactions In Deep Learning", "comments": "Presented at ICCV, 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a simple yet highly generalizable method for explaining\ninteracting parts within a neural network's reasoning process. First, we design\nan algorithm based on cross derivatives for computing statistical interaction\neffects between individual features, which is generalized to both 2-way and\nhigher-order (3-way or more) interactions. We present results side by side with\na weight-based attribution technique, corroborating that cross derivatives are\na superior metric for both 2-way and higher-order interaction detection.\nMoreover, we extend the use of cross derivatives as an explanatory device in\nneural networks to the computer vision setting by expanding Grad-CAM, a popular\ngradient-based explanatory tool for CNNs, to the higher order. While Grad-CAM\ncan only explain the importance of individual objects in images, our method,\nwhich we call Taylor-CAM, can explain a neural network's relational reasoning\nacross multiple objects. We show the success of our explanations both\nqualitatively and quantitatively, including with a user study. We will release\nall code as a tool package to facilitate explainable deep learning.\n", "versions": [{"version": "v1", "created": "Fri, 12 Jun 2020 18:13:27 GMT"}, {"version": "v2", "created": "Wed, 4 Nov 2020 17:06:53 GMT"}, {"version": "v3", "created": "Sun, 25 Jul 2021 17:14:43 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Lerman", "Samuel", ""], ["Xu", "Chenliang", ""], ["Venuto", "Charles", ""], ["Kautz", "Henry", ""]]}, {"id": "2006.08605", "submitter": "Akbar Siami Namin", "authors": "Shuvalaxmi Dass and Xiaozhen Xue and Akbar Siami Namin", "title": "Detection of Coincidentally Correct Test Cases through Random Forests", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The performance of coverage-based fault localization greatly depends on the\nquality of test cases being executed. These test cases execute some lines of\nthe given program and determine whether the underlying tests are passed or\nfailed. In particular, some test cases may be well-behaved (i.e., passed) while\nexecuting faulty statements. These test cases, also known as coincidentally\ncorrect test cases, may negatively influence the performance of the\nspectra-based fault localization and thus be less helpful as a tool for the\npurpose of automated debugging. In other words, the involvement of these\ncoincidentally correct test cases may introduce noises to the fault\nlocalization computation and thus cause in divergence of effectively localizing\nthe location of possible bugs in the given code. In this paper, we propose a\nhybrid approach of ensemble learning combined with a supervised learning\nalgorithm namely, Random Forests (RF) for the purpose of correctly identifying\ntest cases that are mislabeled to be the passing test cases. A cost-effective\nanalysis of flipping the test status or trimming (i.e., eliminating from the\ncomputation) the coincidental correct test cases is also reported.\n", "versions": [{"version": "v1", "created": "Sun, 14 Jun 2020 15:01:53 GMT"}], "update_date": "2020-06-17", "authors_parsed": [["Dass", "Shuvalaxmi", ""], ["Xue", "Xiaozhen", ""], ["Namin", "Akbar Siami", ""]]}, {"id": "2006.08659", "submitter": "James Goodman", "authors": "James Goodman, Simon Lucas", "title": "Does it matter how well I know what you're thinking? Opponent Modelling\n  in an RTS game", "comments": "Preprint of paper accepted for IEEE World Congress on Computational\n  Intelligence (IEEE WCCI) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Opponent Modelling tries to predict the future actions of opponents, and is\nrequired to perform well in multi-player games. There is a deep literature on\nlearning an opponent model, but much less on how accurate such models must be\nto be useful. We investigate the sensitivity of Monte Carlo Tree Search (MCTS)\nand a Rolling Horizon Evolutionary Algorithm (RHEA) to the accuracy of their\nmodelling of the opponent in a simple Real-Time Strategy game. We find that in\nthis domain RHEA is much more sensitive to the accuracy of an opponent model\nthan MCTS. MCTS generally does better even with an inaccurate model, while this\nwill degrade RHEA's performance. We show that faced with an unknown opponent\nand a low computational budget it is better not to use any explicit model with\nRHEA, and to model the opponent's actions within the tree as part of the MCTS\nalgorithm.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jun 2020 18:10:22 GMT"}], "update_date": "2020-06-17", "authors_parsed": [["Goodman", "James", ""], ["Lucas", "Simon", ""]]}, {"id": "2006.08672", "submitter": "Ingrid Nunes", "authors": "Ingrid Nunes and Dietmar Jannach", "title": "A systematic review and taxonomy of explanations in decision support and\n  recommender systems", "comments": null, "journal-ref": "User Modeling and User-Adapted Interaction, 27 (3-5), 393-444\n  (2017)", "doi": "10.1007/s11257-017-9195-0", "report-no": null, "categories": "cs.AI cs.IR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  With the recent advances in the field of artificial intelligence, an\nincreasing number of decision-making tasks are delegated to software systems. A\nkey requirement for the success and adoption of such systems is that users must\ntrust system choices or even fully automated decisions. To achieve this,\nexplanation facilities have been widely investigated as a means of establishing\ntrust in these systems since the early years of expert systems. With today's\nincreasingly sophisticated machine learning algorithms, new challenges in the\ncontext of explanations, accountability, and trust towards such systems\nconstantly arise. In this work, we systematically review the literature on\nexplanations in advice-giving systems. This is a family of systems that\nincludes recommender systems, which is one of the most successful classes of\nadvice-giving software in practice. We investigate the purposes of explanations\nas well as how they are generated, presented to users, and evaluated. As a\nresult, we derive a novel comprehensive taxonomy of aspects to be considered\nwhen designing explanation facilities for current and future decision support\nsystems. The taxonomy includes a variety of different facets, such as\nexplanation objective, responsiveness, content and presentation. Moreover, we\nidentified several challenges that remain unaddressed so far, for example\nrelated to fine-grained issues associated with the presentation of explanations\nand how explanation facilities are evaluated.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jun 2020 18:19:20 GMT"}], "update_date": "2020-06-17", "authors_parsed": [["Nunes", "Ingrid", ""], ["Jannach", "Dietmar", ""]]}, {"id": "2006.08688", "submitter": "Ke Yang", "authors": "Ke Yang, Joshua R. Loftus, Julia Stoyanovich", "title": "Causal intersectionality for fair ranking", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we propose a causal modeling approach to intersectional\nfairness, and a flexible, task-specific method for computing intersectionally\nfair rankings. Rankings are used in many contexts, ranging from Web search\nresults to college admissions, but causal inference for fair rankings has\nreceived limited attention. Additionally, the growing literature on causal\nfairness has directed little attention to intersectionality. By bringing these\nissues together in a formal causal framework we make the application of\nintersectionality in fair machine learning explicit, connected to important\nreal world effects and domain knowledge, and transparent about technical\nlimitations. We experimentally evaluate our approach on real and synthetic\ndatasets, exploring its behaviour under different structural assumptions.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jun 2020 18:57:46 GMT"}], "update_date": "2020-06-17", "authors_parsed": [["Yang", "Ke", ""], ["Loftus", "Joshua R.", ""], ["Stoyanovich", "Julia", ""]]}, {"id": "2006.08714", "submitter": "Joey Hong", "authors": "Joey Hong and Branislav Kveton and Manzil Zaheer and Yinlam Chow and\n  Amr Ahmed and Craig Boutilier", "title": "Latent Bandits Revisited", "comments": "16 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A latent bandit problem is one in which the learning agent knows the arm\nreward distributions conditioned on an unknown discrete latent state. The\nprimary goal of the agent is to identify the latent state, after which it can\nact optimally. This setting is a natural midpoint between online and offline\nlearning---complex models can be learned offline with the agent identifying\nlatent state online---of practical relevance in, say, recommender systems. In\nthis work, we propose general algorithms for this setting, based on both upper\nconfidence bounds (UCBs) and Thompson sampling. Our methods are contextual and\naware of model uncertainty and misspecification. We provide a unified\ntheoretical analysis of our algorithms, which have lower regret than classic\nbandit policies when the number of latent states is smaller than actions. A\ncomprehensive empirical study showcases the advantages of our approach.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jun 2020 19:24:02 GMT"}], "update_date": "2020-06-17", "authors_parsed": [["Hong", "Joey", ""], ["Kveton", "Branislav", ""], ["Zaheer", "Manzil", ""], ["Chow", "Yinlam", ""], ["Ahmed", "Amr", ""], ["Boutilier", "Craig", ""]]}, {"id": "2006.08731", "submitter": "Johannes Vass", "authors": "Johannes Vass, Marie-Louise Lackner, Nysret Musliu", "title": "Exact and Metaheuristic Approaches for the Production Leveling Problem", "comments": "Instance set is published under\n  https://dbai.tuwien.ac.at/staff/jvass/production-leveling/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we introduce a new problem in the field of production planning\nwhich we call the Production Leveling Problem. The task is to assign orders to\nproduction periods such that the load in each period and on each production\nresource is balanced, capacity limits are not exceeded and the orders'\npriorities are taken into account. Production Leveling is an important\nintermediate step between long-term planning and the final scheduling of orders\nwithin a production period, as it is responsible for selecting good subsets of\norders to be scheduled within each period.\n  A formal model of the problem is proposed and NP-hardness is shown by\nreduction from Bin Backing. As an exact method for solving moderately sized\ninstances we introduce a MIP formulation. For solving large problem instances,\nmetaheuristic local search is investigated. A greedy heuristic and two\nneighborhood structures for local search are proposed, in order to apply them\nusing Variable Neighborhood Descent and Simulated Annealing. Regarding exact\ntechniques, the main question of research is, up to which size instances are\nsolvable within a fixed amount of time. For the metaheuristic approaches the\naim is to show that they produce near-optimal solutions for smaller instances,\nbut also scale well to very large instances.\n  A set of realistic problem instances from an industrial partner is\ncontributed to the literature, as well as random instance generators. The\nexperimental evaluation conveys that the proposed MIP model works well for\ninstances with up to 250 orders. Out of the investigated metaheuristic\napproaches, Simulated Annealing achieves the best results. It is shown to\nproduce solutions with less than 3% average optimality gap on small instances\nand to scale well up to thousands of orders and dozens of periods and products.\nThe presented metaheuristic methods are already being used in the industry.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jun 2020 20:04:59 GMT"}], "update_date": "2020-06-17", "authors_parsed": [["Vass", "Johannes", ""], ["Lackner", "Marie-Louise", ""], ["Musliu", "Nysret", ""]]}, {"id": "2006.08742", "submitter": "Michael Curry", "authors": "Michael J. Curry, Ping-Yeh Chiang, Tom Goldstein, John Dickerson", "title": "Certifying Strategyproof Auction Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.AI cs.LG cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Optimal auctions maximize a seller's expected revenue subject to individual\nrationality and strategyproofness for the buyers. Myerson's seminal work in\n1981 settled the case of auctioning a single item; however, subsequent decades\nof work have yielded little progress moving beyond a single item, leaving the\ndesign of revenue-maximizing auctions as a central open problem in the field of\nmechanism design. A recent thread of work in \"differentiable economics\" has\nused tools from modern deep learning to instead learn good mechanisms. We focus\non the RegretNet architecture, which can represent auctions with arbitrary\nnumbers of items and participants; it is trained to be empirically\nstrategyproof, but the property is never exactly verified leaving potential\nloopholes for market participants to exploit. We propose ways to explicitly\nverify strategyproofness under a particular valuation profile using techniques\nfrom the neural network verification literature. Doing so requires making\nseveral modifications to the RegretNet architecture in order to represent it\nexactly in an integer program. We train our network and produce certificates in\nseveral settings, including settings for which the optimal strategyproof\nmechanism is not known.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jun 2020 20:22:48 GMT"}], "update_date": "2020-06-17", "authors_parsed": [["Curry", "Michael J.", ""], ["Chiang", "Ping-Yeh", ""], ["Goldstein", "Tom", ""], ["Dickerson", "John", ""]]}, {"id": "2006.08753", "submitter": "Michael Cohen", "authors": "Michael K. Cohen and Marcus Hutter", "title": "Pessimism About Unknown Unknowns Inspires Conservatism", "comments": "12 pages, plus 16-page appendix; to be published in COLT 2020\n  proceedings", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  If we could define the set of all bad outcomes, we could hard-code an agent\nwhich avoids them; however, in sufficiently complex environments, this is\ninfeasible. We do not know of any general-purpose approaches in the literature\nto avoiding novel failure modes. Motivated by this, we define an idealized\nBayesian reinforcement learner which follows a policy that maximizes the\nworst-case expected reward over a set of world-models. We call this agent\npessimistic, since it optimizes assuming the worst case. A scalar parameter\ntunes the agent's pessimism by changing the size of the set of world-models\ntaken into account. Our first main contribution is: given an assumption about\nthe agent's model class, a sufficiently pessimistic agent does not cause\n\"unprecedented events\" with probability $1-\\delta$, whether or not designers\nknow how to precisely specify those precedents they are concerned with. Since\npessimism discourages exploration, at each timestep, the agent may defer to a\nmentor, who may be a human or some known-safe policy we would like to improve.\nOur other main contribution is that the agent's policy's value approaches at\nleast that of the mentor, while the probability of deferring to the mentor goes\nto 0. In high-stakes environments, we might like advanced artificial agents to\npursue goals cautiously, which is a non-trivial problem even if the agent were\nallowed arbitrary computing power; we present a formal solution.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jun 2020 20:46:33 GMT"}], "update_date": "2020-06-17", "authors_parsed": [["Cohen", "Michael K.", ""], ["Hutter", "Marcus", ""]]}, {"id": "2006.08765", "submitter": "Junyi Gao", "authors": "Junyi Gao, Cao Xiao, Lucas M. Glass, Jimeng Sun", "title": "COMPOSE: Cross-Modal Pseudo-Siamese Network for Patient Trial Matching", "comments": "Accepted by KDD'20", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Clinical trials play important roles in drug development but often suffer\nfrom expensive, inaccurate and insufficient patient recruitment. The\navailability of massive electronic health records (EHR) data and trial\neligibility criteria (EC) bring a new opportunity to data driven patient\nrecruitment. One key task named patient-trial matching is to find qualified\npatients for clinical trials given structured EHR and unstructured EC text\n(both inclusion and exclusion criteria). How to match complex EC text with\nlongitudinal patient EHRs? How to embed many-to-many relationships between\npatients and trials? How to explicitly handle the difference between inclusion\nand exclusion criteria? In this paper, we proposed CrOss-Modal PseudO-SiamEse\nnetwork (COMPOSE) to address these challenges for patient-trial matching. One\npath of the network encodes EC using convolutional highway network. The other\npath processes EHR with multi-granularity memory network that encodes\nstructured patient records into multiple levels based on medical ontology.\nUsing the EC embedding as query, COMPOSE performs attentional record alignment\nand thus enables dynamic patient-trial matching. COMPOSE also introduces a\ncomposite loss term to maximize the similarity between patient records and\ninclusion criteria while minimize the similarity to the exclusion criteria.\nExperiment results show COMPOSE can reach 98.0% AUC on patient-criteria\nmatching and 83.7% accuracy on patient-trial matching, which leads 24.3%\nimprovement over the best baseline on real-world patient-trial matching tasks.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jun 2020 21:01:33 GMT"}], "update_date": "2020-06-17", "authors_parsed": [["Gao", "Junyi", ""], ["Xiao", "Cao", ""], ["Glass", "Lucas M.", ""], ["Sun", "Jimeng", ""]]}, {"id": "2006.08767", "submitter": "Borja Gonzalez Le\\'on", "authors": "Borja G. Leon, Murray Shanahan, Francesco Belardinelli", "title": "Systematic Generalisation through Task Temporal Logic and Deep\n  Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a neuro-symbolic agent that combines deep reinforcement\nlearning (DRL) with temporal logic (TL), and achieves systematic\nout-of-distribution generalisation in tasks that involve following a formally\nspecified instruction. Specifically, the agent learns general notions of\nnegation and disjunction, and successfully applies them to previously unseen\nobjects without further training. To this end, we also introduce Task Temporal\nLogic (TTL), a learning-oriented formal language, whose atoms are designed to\nhelp the training of a DRL agent targeting systematic generalisation. To\nvalidate this combination of logic-based and neural-network techniques, we\nprovide experimental evidence for the kind of neural-network architecture that\nmost enhances the generalisation performance of the agent. Our findings suggest\nthat the right architecture can significatively improve the ability of the\nagent to generalise in systematic ways, even with abstract operators, such as\nnegation, which previous research have struggled with.\n", "versions": [{"version": "v1", "created": "Fri, 12 Jun 2020 09:02:40 GMT"}, {"version": "v2", "created": "Wed, 30 Sep 2020 19:28:18 GMT"}], "update_date": "2020-10-05", "authors_parsed": [["Leon", "Borja G.", ""], ["Shanahan", "Murray", ""], ["Belardinelli", "Francesco", ""]]}, {"id": "2006.08768", "submitter": "Tatiana Valentine Guy", "authors": "Eli\\v{s}ka Zugarov\\'a and Tatiana V. Guy", "title": "Similarity-based transfer learning of decision policies", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A problem of learning decision policy from past experience is considered.\nUsing the Fully Probabilistic Design (FPD) formalism, we propose a new general\napproach for finding a stochastic policy from the past data.\n", "versions": [{"version": "v1", "created": "Fri, 12 Jun 2020 16:39:54 GMT"}], "update_date": "2020-06-17", "authors_parsed": [["Zugarov\u00e1", "Eli\u0161ka", ""], ["Guy", "Tatiana V.", ""]]}, {"id": "2006.08785", "submitter": "Anji Liu", "authors": "Anji Liu and Yitao Liang and Ji Liu and Guy Van den Broeck and Jianshu\n  Chen", "title": "On Effective Parallelization of Monte Carlo Tree Search", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite its groundbreaking success in Go and computer games, Monte Carlo Tree\nSearch (MCTS) is computationally expensive as it requires a substantial number\nof rollouts to construct the search tree, which calls for effective\nparallelization. However, how to design effective parallel MCTS algorithms has\nnot been systematically studied and remains poorly understood. In this paper,\nwe seek to lay its first theoretical foundation, by examining the potential\nperformance loss caused by parallelization when achieving a desired speedup. In\nparticular, we discover the necessary conditions of achieving a desirable\nparallelization performance, and highlight two of their practical benefits.\nFirst, by examining whether existing parallel MCTS algorithms satisfy these\nconditions, we identify key design principles that should be inherited by\nfuture algorithms, for example tracking the unobserved samples (used in WU-UCT\n(Liu et al., 2020)). We theoretically establish this essential design\nfacilitates $\\mathcal{O} ( \\ln n + M / \\sqrt{\\ln n} )$ cumulative regret when\nthe maximum tree depth is 2, where $n$ is the number of rollouts and $M$ is the\nnumber of workers. A regret of this form is highly desirable, as compared to\n$\\mathcal{O} ( \\ln n )$ regret incurred by a sequential counterpart, its excess\npart approaches zero as $n$ increases. Second, and more importantly, we\ndemonstrate how the proposed necessary conditions can be adopted to design more\neffective parallel MCTS algorithms. To illustrate this, we propose a new\nparallel MCTS algorithm, called BU-UCT, by following our theoretical\nguidelines. The newly proposed algorithm, albeit preliminary, out-performs four\ncompetitive baselines on 11 out of 15 Atari games. We hope our theoretical\nresults could inspire future work of more effective parallel MCTS.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jun 2020 21:36:00 GMT"}, {"version": "v2", "created": "Sun, 4 Oct 2020 21:13:55 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Liu", "Anji", ""], ["Liang", "Yitao", ""], ["Liu", "Ji", ""], ["Broeck", "Guy Van den", ""], ["Chen", "Jianshu", ""]]}, {"id": "2006.08818", "submitter": "Ingrid Nunes", "authors": "Ingrid Nunes, Phillip Taylor, Lina Barakat, Nathan Griffiths, Simon\n  Miles", "title": "Explaining reputation assessments", "comments": null, "journal-ref": "International Journal of Human-Computer Studies, 123, 1-17 (2019)", "doi": "10.1016/j.ijhcs.2018.10.007", "report-no": null, "categories": "cs.AI cs.HC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Reputation is crucial to enabling human or software agents to select among\nalternative providers. Although several effective reputation assessment methods\nexist, they typically distil reputation into a numerical representation, with\nno accompanying explanation of the rationale behind the assessment. Such\nexplanations would allow users or clients to make a richer assessment of\nproviders, and tailor selection according to their preferences and current\ncontext. In this paper, we propose an approach to explain the rationale behind\nassessments from quantitative reputation models, by generating arguments that\nare combined to form explanations. Our approach adapts, extends and combines\nexisting approaches for explaining decisions made using multi-attribute\ndecision models in the context of reputation. We present example argument\ntemplates, and describe how to select their parameters using explanation\nalgorithms. Our proposal was evaluated by means of a user study, which followed\nan existing protocol. Our results give evidence that although explanations\npresent a subset of the information of trust scores, they are sufficient to\nequally evaluate providers recommended based on their trust score. Moreover,\nwhen explanation arguments reveal implicit model information, they are less\npersuasive than scores.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jun 2020 23:19:35 GMT"}], "update_date": "2020-06-17", "authors_parsed": [["Nunes", "Ingrid", ""], ["Taylor", "Phillip", ""], ["Barakat", "Lina", ""], ["Griffiths", "Nathan", ""], ["Miles", "Simon", ""]]}, {"id": "2006.08820", "submitter": "Ingrid Nunes", "authors": "Fernando Santos, Ingrid Nunes, Ana L. C. Bazzan", "title": "Quantitatively Assessing the Benefits of Model-driven Development in\n  Agent-based Modeling and Simulation", "comments": null, "journal-ref": "Simulation Modelling Practice and Theory, v. 104, 1-19 (2020)", "doi": "10.1016/j.simpat.2020.102126", "report-no": null, "categories": "cs.AI cs.SE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The agent-based modeling and simulation (ABMS) paradigm has been used to\nanalyze, reproduce, and predict phenomena related to many application areas.\nAlthough there are many agent-based platforms that support simulation\ndevelopment, they rely on programming languages that require extensive\nprogramming knowledge. Model-driven development (MDD) has been explored to\nfacilitate simulation modeling, by means of high-level modeling languages that\nprovide reusable building blocks that hide computational complexity, and code\ngeneration. However, there is still limited knowledge of how MDD approaches to\nABMS contribute to increasing development productivity and quality. We thus in\nthis paper present an empirical study that quantitatively compares the use of\nMDD and ABMS platforms mainly in terms of effort and developer mistakes. Our\nevaluation was performed using MDD4ABMS-an MDD approach with a core and\nextensions to two application areas, one of which developed for this study-and\nNetLogo, a widely used platform. The obtained results show that MDD4ABMS\nrequires less effort to develop simulations with similar (sometimes better)\ndesign quality than NetLogo, giving evidence of the benefits that MDD can\nprovide to ABMS.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jun 2020 23:29:04 GMT"}], "update_date": "2020-06-17", "authors_parsed": [["Santos", "Fernando", ""], ["Nunes", "Ingrid", ""], ["Bazzan", "Ana L. C.", ""]]}, {"id": "2006.08828", "submitter": "Ayman Moawad", "authors": "Ayman Moawad, Ehsan Islam, Namdoo Kim, Ram Vijayagopal, Aymeric\n  Rousseau, and Wei Biao Wu", "title": "Explainable AI for a No-Teardown Vehicle Component Cost Estimation: A\n  Top-Down Approach", "comments": "17 pages, 18 figures", "journal-ref": null, "doi": "10.1109/TAI.2021.3065011", "report-no": null, "categories": "cs.CY cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The broader ambition of this article is to popularize an approach for the\nfair distribution of the quantity of a system's output to its subsystems, while\nallowing for underlying complex subsystem level interactions. Particularly, we\npresent a data-driven approach to vehicle price modeling and its component\nprice estimation by leveraging a combination of concepts from machine learning\nand game theory. We show an alternative to common teardown methodologies and\nsurveying approaches for component and vehicle price estimation at the\nmanufacturer's suggested retail price (MSRP) level that has the advantage of\nbypassing the uncertainties involved in 1) the gathering of teardown data, 2)\nthe need to perform expensive and biased surveying, and 3) the need to perform\nretail price equivalent (RPE) or indirect cost multiplier (ICM) adjustments to\nmark up direct manufacturing costs to MSRP. This novel exercise not only\nprovides accurate pricing of the technologies at the customer level, but also\nshows the, a priori known, large gaps in pricing strategies between\nmanufacturers, vehicle sizes, classes, market segments, and other factors.\nThere is also clear synergism or interaction between the price of certain\ntechnologies and other specifications present in the same vehicle. Those\n(unsurprising) results are indication that old methods of manufacturer-level\ncomponent costing, aggregation, and the application of a flat and rigid RPE or\nICM adjustment factor should be carefully examined. The findings are based on\nan extensive database, developed by Argonne National Laboratory, that includes\nmore than 64,000 vehicles covering MY1990 to MY2020 over hundreds of vehicle\nspecs.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jun 2020 23:47:19 GMT"}], "update_date": "2021-03-30", "authors_parsed": [["Moawad", "Ayman", ""], ["Islam", "Ehsan", ""], ["Kim", "Namdoo", ""], ["Vijayagopal", "Ram", ""], ["Rousseau", "Aymeric", ""], ["Wu", "Wei Biao", ""]]}, {"id": "2006.08831", "submitter": "Chuizheng Meng", "authors": "Sungyong Seo, Chuizheng Meng, Sirisha Rambhatla, Yan Liu", "title": "Physics-aware Spatiotemporal Modules with Auxiliary Tasks for\n  Meta-Learning", "comments": "To be published in the 30th International Joint Conference on\n  Artificial Intelligence (IJCAI-21)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Modeling the dynamics of real-world physical systems is critical for\nspatiotemporal prediction tasks, but challenging when data is limited. The\nscarcity of real-world data and the difficulty in reproducing the data\ndistribution hinder directly applying meta-learning techniques. Although the\nknowledge of governing partial differential equations (PDE) of data can be\nhelpful for the fast adaptation to few observations, it is mostly infeasible to\nexactly find the equation for observations in real-world physical systems. In\nthis work, we propose a framework, physics-aware meta-learning with auxiliary\ntasks, whose spatial modules incorporate PDE-independent knowledge and temporal\nmodules utilize the generalized features from the spatial modules to be adapted\nto the limited data, respectively. The framework is inspired by a local\nconservation law expressed mathematically as a continuity equation and does not\nrequire the exact form of governing equation to model the spatiotemporal\nobservations. The proposed method mitigates the need for a large number of\nreal-world tasks for meta-learning by leveraging spatial information in\nsimulated data to meta-initialize the spatial modules. We apply the proposed\nframework to both synthetic and real-world spatiotemporal prediction tasks and\ndemonstrate its superior performance with limited observations.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jun 2020 23:51:40 GMT"}, {"version": "v2", "created": "Mon, 7 Jun 2021 22:03:35 GMT"}], "update_date": "2021-06-09", "authors_parsed": [["Seo", "Sungyong", ""], ["Meng", "Chuizheng", ""], ["Rambhatla", "Sirisha", ""], ["Liu", "Yan", ""]]}, {"id": "2006.08832", "submitter": "Kyle Brown", "authors": "Kyle Brown and Katherine Driggs-Campbell and Mykel J. Kochenderfer", "title": "A Taxonomy and Review of Algorithms for Modeling and Predicting Human\n  Driver Behavior", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.AI cs.CY cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a review and taxonomy of 200 models from the literature on driver\nbehavior modeling. We begin by introducing a mathematical framework for\ndescribing the dynamics of interactive multi-agent traffic. Based on the\npartially observable stochastic game, this framework provides a basis for\ndiscussing different driver modeling techniques. Our taxonomy is constructed\naround the core modeling tasks of state estimation, intention estimation, trait\nestimation, and motion prediction, and also discusses the auxiliary tasks of\nrisk estimation, anomaly detection, behavior imitation and microscopic traffic\nsimulation. Existing driver models are categorized based on the specific tasks\nthey address and key attributes of their approach.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jun 2020 23:53:45 GMT"}, {"version": "v2", "created": "Mon, 3 Aug 2020 18:35:04 GMT"}, {"version": "v3", "created": "Sun, 29 Nov 2020 03:40:24 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Brown", "Kyle", ""], ["Driggs-Campbell", "Katherine", ""], ["Kochenderfer", "Mykel J.", ""]]}, {"id": "2006.08842", "submitter": "Hongzhi Wang", "authors": "Shun Yao, Hongzhi Wang and Yu Yan", "title": "Index Selection for NoSQL Database with Deep Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new approach of NoSQL database index selection. For different\nworkloads, we select different indexes and their different parameters to\noptimize the database performance. The approach builds a deep reinforcement\nlearning model to select an optimal index for a given fixed workload and adapts\nto a changing workload. Experimental results show that, Deep Reinforcement\nLearning Index Selection Approach (DRLISA) has improved performance to varying\ndegrees according to traditional single index structures.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jun 2020 00:40:50 GMT"}], "update_date": "2020-06-17", "authors_parsed": [["Yao", "Shun", ""], ["Wang", "Hongzhi", ""], ["Yan", "Yu", ""]]}, {"id": "2006.08845", "submitter": "Kyle Jordan Brown", "authors": "Kyle Brown, Oriana Peltzer, Martin A. Sehr, Mac Schwager, Mykel J.\n  Kochenderfer", "title": "Optimal Sequential Task Assignment and Path Finding for Multi-Agent\n  Robotic Assembly Planning", "comments": "Presented at International Conference on Robotics and Automation\n  (ICRA) 2020", "journal-ref": "International Conference on Robotics and Automation (ICRA) 2020", "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of sequential task assignment and collision-free routing\nfor large teams of robots in applications with inter-task precedence\nconstraints (e.g., task $A$ and task $B$ must both be completed before task $C$\nmay begin). Such problems commonly occur in assembly planning for robotic\nmanufacturing applications, in which sub-assemblies must be completed before\nthey can be combined to form the final product. We propose a hierarchical\nalgorithm for computing makespan-optimal solutions to the problem. The\nalgorithm is evaluated on a set of randomly generated problem instances where\nrobots must transport objects between stations in a \"factory \"grid world\nenvironment. In addition, we demonstrate in high-fidelity simulation that the\noutput of our algorithm can be used to generate collision-free trajectories for\nnon-holonomic differential-drive robots.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jun 2020 00:45:07 GMT"}], "update_date": "2020-06-17", "authors_parsed": [["Brown", "Kyle", ""], ["Peltzer", "Oriana", ""], ["Sehr", "Martin A.", ""], ["Schwager", "Mac", ""], ["Kochenderfer", "Mykel J.", ""]]}, {"id": "2006.08875", "submitter": "Zichuan Lin", "authors": "Zichuan Lin, Garrett Thomas, Guangwen Yang, Tengyu Ma", "title": "Model-based Adversarial Meta-Reinforcement Learning", "comments": "Accepted by NeurIPS 2020. Code at https://github.com/LinZichuan/AdMRL", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Meta-reinforcement learning (meta-RL) aims to learn from multiple training\ntasks the ability to adapt efficiently to unseen test tasks. Despite the\nsuccess, existing meta-RL algorithms are known to be sensitive to the task\ndistribution shift. When the test task distribution is different from the\ntraining task distribution, the performance may degrade significantly. To\naddress this issue, this paper proposes Model-based Adversarial\nMeta-Reinforcement Learning (AdMRL), where we aim to minimize the worst-case\nsub-optimality gap -- the difference between the optimal return and the return\nthat the algorithm achieves after adaptation -- across all tasks in a family of\ntasks, with a model-based approach. We propose a minimax objective and optimize\nit by alternating between learning the dynamics model on a fixed task and\nfinding the adversarial task for the current model -- the task for which the\npolicy induced by the model is maximally suboptimal. Assuming the family of\ntasks is parameterized, we derive a formula for the gradient of the\nsuboptimality with respect to the task parameters via the implicit function\ntheorem, and show how the gradient estimator can be efficiently implemented by\nthe conjugate gradient method and a novel use of the REINFORCE estimator. We\nevaluate our approach on several continuous control benchmarks and demonstrate\nits efficacy in the worst-case performance over all tasks, the generalization\npower to out-of-distribution tasks, and in training and test time sample\nefficiency, over existing state-of-the-art meta-RL algorithms.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jun 2020 02:21:49 GMT"}, {"version": "v2", "created": "Sat, 27 Feb 2021 13:19:45 GMT"}], "update_date": "2021-03-02", "authors_parsed": [["Lin", "Zichuan", ""], ["Thomas", "Garrett", ""], ["Yang", "Guangwen", ""], ["Ma", "Tengyu", ""]]}, {"id": "2006.08880", "submitter": "Zongshun Wang", "authors": "Zongshun Wang and Jiachao Wu", "title": "The SCC-recursiveness Principle in Fuzzy Argumentation Frameworks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dung's abstract argumentation theory plays a guiding role in the field of\nformal argumentation. The properties of argumentation semantics have been\ndeeply explored in the previous literature. The SCC-recursiveness principle is\na property of the extensions which relies on the graph-theoretical notion of\nstrongly connected components. It provides a general recursive schema for\nargumentation semantics, which is an efficient and incremental algorithm for\ncomputing the argumentation semantics. However, in argumentation frameworks\nwith uncertain arguments and uncertain attack relation, the SCC-recursive\ntheory is absence. This paper is an exploration of the SCC-recursive theory in\nfuzzy argumentation frameworks (FAFs), which add numbers as fuzzy degrees to\nthe arguments and attacks. In this paper, in order to extend the\nSCC-recursiveness principle to FAFs, we first modify the reinstatement\nprinciple and directionality principle to fit the FAFs. Then the\nSCC-recursiveness principle in FAFs is formalized by the modified principles.\nAdditionally, some illustrating examples show that the SCC-recursiveness\nprinciple also provides an efficient and incremental algorithm for simplify the\ncomputation of argumentation semantics in FAFs.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jun 2020 02:33:06 GMT"}], "update_date": "2020-06-17", "authors_parsed": [["Wang", "Zongshun", ""], ["Wu", "Jiachao", ""]]}, {"id": "2006.08906", "submitter": "Mingde Zhao", "authors": "Mingde Zhao", "title": "META-Learning Eligibility Traces for More Sample Efficient Temporal\n  Difference Learning", "comments": "A thesis submitted to McGill University in partial fulfillment of the\n  requirements of the degree of Master of Computer Science", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Temporal-Difference (TD) learning is a standard and very successful\nreinforcement learning approach, at the core of both algorithms that learn the\nvalue of a given policy, as well as algorithms which learn how to improve\npolicies. TD-learning with eligibility traces provides a way to do temporal\ncredit assignment, i.e. decide which portion of a reward should be assigned to\npredecessor states that occurred at different previous times, controlled by a\nparameter $\\lambda$. However, tuning this parameter can be time-consuming, and\nnot tuning it can lead to inefficient learning. To improve the sample\nefficiency of TD-learning, we propose a meta-learning method for adjusting the\neligibility trace parameter, in a state-dependent manner. The adaptation is\nachieved with the help of auxiliary learners that learn distributional\ninformation about the update targets online, incurring roughly the same\ncomputational complexity per step as the usual value learner. Our approach can\nbe used both in on-policy and off-policy learning. We prove that, under some\nassumptions, the proposed method improves the overall quality of the update\ntargets, by minimizing the overall target error. This method can be viewed as a\nplugin which can also be used to assist prediction with function approximation\nby meta-learning feature (observation)-based $\\lambda$ online, or even in the\ncontrol case to assist policy improvement. Our empirical evaluation\ndemonstrates significant performance improvements, as well as improved\nrobustness of the proposed algorithm to learning rate variation.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jun 2020 03:41:07 GMT"}], "update_date": "2020-06-17", "authors_parsed": [["Zhao", "Mingde", ""]]}, {"id": "2006.08910", "submitter": "Yichong Xu", "authors": "Yichong Xu, Ruosong Wang, Lin F. Yang, Aarti Singh and Artur Dubrawski", "title": "Preference-based Reinforcement Learning with Finite-Time Guarantees", "comments": "Thirty-fourth Conference on Neural Information Processing Systems\n  (NeurIPS 2020). Spotlight presentation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Preference-based Reinforcement Learning (PbRL) replaces reward values in\ntraditional reinforcement learning by preferences to better elicit human\nopinion on the target objective, especially when numerical reward values are\nhard to design or interpret. Despite promising results in applications, the\ntheoretical understanding of PbRL is still in its infancy. In this paper, we\npresent the first finite-time analysis for general PbRL problems. We first show\nthat a unique optimal policy may not exist if preferences over trajectories are\ndeterministic for PbRL. If preferences are stochastic, and the preference\nprobability relates to the hidden reward values, we present algorithms for\nPbRL, both with and without a simulator, that are able to identify the best\npolicy up to accuracy $\\varepsilon$ with high probability. Our method explores\nthe state space by navigating to under-explored states, and solves PbRL using a\ncombination of dueling bandits and policy search. Experiments show the efficacy\nof our method when it is applied to real-world problems.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jun 2020 03:52:41 GMT"}, {"version": "v2", "created": "Fri, 23 Oct 2020 20:24:58 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Xu", "Yichong", ""], ["Wang", "Ruosong", ""], ["Yang", "Lin F.", ""], ["Singh", "Aarti", ""], ["Dubrawski", "Artur", ""]]}, {"id": "2006.08942", "submitter": "Mishal Fatima", "authors": "Mishal Fatima, Muhammad Umar Karim Khan, and Chong Min Kyung", "title": "Global Feature Aggregation for Accident Anticipation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Anticipation of accidents ahead of time in autonomous and non-autonomous\nvehicles aids in accident avoidance. In order to recognize abnormal events such\nas traffic accidents in a video sequence, it is important that the network\ntakes into account interactions of objects in a given frame. We propose a novel\nFeature Aggregation (FA) block that refines each object's features by computing\na weighted sum of the features of all objects in a frame. We use FA block along\nwith Long Short Term Memory (LSTM) network to anticipate accidents in the video\nsequences. We report mean Average Precision (mAP) and Average Time-to-Accident\n(ATTA) on Street Accident (SA) dataset. Our proposed method achieves the\nhighest score for risk anticipation by predicting accidents 0.32 sec and 0.75\nsec earlier compared to the best results with Adaptive Loss and dynamic\nparameter prediction based methods respectively.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jun 2020 06:17:15 GMT"}], "update_date": "2020-06-17", "authors_parsed": [["Fatima", "Mishal", ""], ["Khan", "Muhammad Umar Karim", ""], ["Kyung", "Chong Min", ""]]}, {"id": "2006.08958", "submitter": "Eric Hutter", "authors": "Eric Hutter and Mathias Pacher and Uwe Brinkschulte", "title": "On the Hardness of Problems Involving Negator Relationships in an\n  Artificial Hormone System", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Artificial Hormone System (AHS) is a self-organizing middleware to\nallocate tasks in a distributed system. We extended it by so-called negator\nhormones to enable conditional task structures. However, this extension\nincreases the computational complexity of seemingly simple decision problems in\nthe system: In [1] and [2], we defined the problems Negator-Path and\nNegator-Sat and proved their NP-completeness. In this supplementary report to\nthese papers, we show examples of Negator-Path and Negator-Sat, introduce the\nnovel problem Negator-Stability and explain why all of these problems involving\nnegators are hard to solve algorithmically.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jun 2020 07:17:40 GMT"}], "update_date": "2020-06-17", "authors_parsed": [["Hutter", "Eric", ""], ["Pacher", "Mathias", ""], ["Brinkschulte", "Uwe", ""]]}, {"id": "2006.08993", "submitter": "Amine Echraibi", "authors": "Amine Echraibi (IMT Atlantique - INFO), Joachim Flocon-Cholet,\n  St\\'ephane Gosselin, Sandrine Vaton (INFO)", "title": "On the Variational Posterior of Dirichlet Process Deep Latent Gaussian\n  Mixture Models", "comments": null, "journal-ref": "ICML Workshop on Invertible Neural Networks, Normalizing Flows,\n  and Explicit Likelihood Models, Jul 2020, Vienna, Austria", "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Thanks to the reparameterization trick, deep latent Gaussian models have\nshown tremendous success recently in learning latent representations. The\nability to couple them however with nonparamet-ric priors such as the Dirichlet\nProcess (DP) hasn't seen similar success due to its non parameteriz-able\nnature. In this paper, we present an alternative treatment of the variational\nposterior of the Dirichlet Process Deep Latent Gaussian Mixture Model\n(DP-DLGMM), where we show that the prior cluster parameters and the variational\nposteriors of the beta distributions and cluster hidden variables can be\nupdated in closed-form. This leads to a standard reparameterization trick on\nthe Gaussian latent variables knowing the cluster assignments. We demonstrate\nour approach on standard benchmark datasets, we show that our model is capable\nof generating realistic samples for each cluster obtained, and manifests\ncompetitive performance in a semi-supervised setting.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jun 2020 08:46:18 GMT"}, {"version": "v2", "created": "Mon, 27 Jul 2020 12:41:05 GMT"}], "update_date": "2020-07-28", "authors_parsed": [["Echraibi", "Amine", "", "IMT Atlantique - INFO"], ["Flocon-Cholet", "Joachim", "", "INFO"], ["Gosselin", "St\u00e9phane", "", "INFO"], ["Vaton", "Sandrine", "", "INFO"]]}, {"id": "2006.09000", "submitter": "Kirill Bykov", "authors": "Kirill Bykov, Marina M.-C. H\\\"ohne, Klaus-Robert M\\\"uller, Shinichi\n  Nakajima, Marius Kloft", "title": "How Much Can I Trust You? -- Quantifying Uncertainties in Explaining\n  Neural Networks", "comments": "12 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Explainable AI (XAI) aims to provide interpretations for predictions made by\nlearning machines, such as deep neural networks, in order to make the machines\nmore transparent for the user and furthermore trustworthy also for applications\nin e.g. safety-critical areas. So far, however, no methods for quantifying\nuncertainties of explanations have been conceived, which is problematic in\ndomains where a high confidence in explanations is a prerequisite. We therefore\ncontribute by proposing a new framework that allows to convert any arbitrary\nexplanation method for neural networks into an explanation method for Bayesian\nneural networks, with an in-built modeling of uncertainties. Within the\nBayesian framework a network's weights follow a distribution that extends\nstandard single explanation scores and heatmaps to distributions thereof, in\nthis manner translating the intrinsic network model uncertainties into a\nquantification of explanation uncertainties. This allows us for the first time\nto carve out uncertainties associated with a model explanation and subsequently\ngauge the appropriate level of explanation confidence for a user (using\npercentiles). We demonstrate the effectiveness and usefulness of our approach\nextensively in various experiments, both qualitatively and quantitatively.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jun 2020 08:54:42 GMT"}], "update_date": "2020-06-17", "authors_parsed": [["Bykov", "Kirill", ""], ["H\u00f6hne", "Marina M. -C.", ""], ["M\u00fcller", "Klaus-Robert", ""], ["Nakajima", "Shinichi", ""], ["Kloft", "Marius", ""]]}, {"id": "2006.09019", "submitter": "Justinas Miseikis", "authors": "Justinas Miseikis, Pietro Caroni, Patricia Duchamp, Alina Gasser,\n  Rastislav Marko, Nelija Miseikiene, Frederik Zwilling, Charles de\n  Castelbajac, Lucas Eicher, Michael Fruh, Hansruedi Fruh", "title": "Lio -- A Personal Robot Assistant for Human-Robot Interaction and Care\n  Applications", "comments": "Accepted submission at IEEE Robotics and Automation Letters (RA-L),\n  submitted to IEEE IROS 2020", "journal-ref": null, "doi": "10.1109/LRA.2020.3007462", "report-no": null, "categories": "cs.RO cs.AI cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Lio is a mobile robot platform with a multi-functional arm explicitly\ndesigned for human-robot interaction and personal care assistant tasks. The\nrobot has already been deployed in several health care facilities, where it is\nfunctioning autonomously, assisting staff and patients on an everyday basis.\nLio is intrinsically safe by having full coverage in soft artificial-leather\nmaterial as well as having collision detection, limited speed and forces.\nFurthermore, the robot has a compliant motion controller. A combination of\nvisual, audio, laser, ultrasound and mechanical sensors are used for safe\nnavigation and environment understanding. The ROS-enabled setup allows\nresearchers to access raw sensor data as well as have direct control of the\nrobot. The friendly appearance of Lio has resulted in the robot being well\naccepted by health care staff and patients. Fully autonomous operation is made\npossible by a flexible decision engine, autonomous navigation and automatic\nrecharging. Combined with time-scheduled task triggers, this allows Lio to\noperate throughout the day, with a battery life of up to 8 hours and recharging\nduring idle times. A combination of powerful on-board computing units provides\nenough processing power to deploy artificial intelligence and deep\nlearning-based solutions on-board the robot without the need to send any\nsensitive data to cloud services, guaranteeing compliance with privacy\nrequirements. During the COVID-19 pandemic, Lio was rapidly adjusted to perform\nadditional functionality like disinfection and remote elevated body temperature\ndetection. It complies with ISO13482 - Safety requirements for personal care\nrobots, meaning it can be directly tested and deployed in care facilities.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jun 2020 09:37:44 GMT"}], "update_date": "2020-07-20", "authors_parsed": [["Miseikis", "Justinas", ""], ["Caroni", "Pietro", ""], ["Duchamp", "Patricia", ""], ["Gasser", "Alina", ""], ["Marko", "Rastislav", ""], ["Miseikiene", "Nelija", ""], ["Zwilling", "Frederik", ""], ["de Castelbajac", "Charles", ""], ["Eicher", "Lucas", ""], ["Fruh", "Michael", ""], ["Fruh", "Hansruedi", ""]]}, {"id": "2006.09040", "submitter": "Christopher Brix", "authors": "Christopher Brix, Thomas Noll", "title": "Debona: Decoupled Boundary Network Analysis for Tighter Bounds and\n  Faster Adversarial Robustness Proofs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks are commonly used in safety-critical real-world applications.\nUnfortunately, the predicted output is often highly sensitive to small, and\npossibly imperceptible, changes to the input data. Proving that either no such\nadversarial examples exist, or providing a concrete instance, is therefore\ncrucial to ensure safe applications. As enumerating and testing all potential\nadversarial examples is computationally infeasible, verification techniques\nhave been developed to provide mathematically sound proofs of their absence\nusing overestimations of the network activations. We propose an improved\ntechnique for computing tight upper and lower bounds of these node values,\nbased on increased flexibility gained by computing both bounds independently of\neach other. Furthermore, we gain an additional improvement by re-implementing\npart of the original state-of-the-art software \"Neurify\", leading to a faster\nanalysis. Combined, these adaptations reduce the necessary runtime by up to\n94%, and allow a successful search for networks and inputs that were previously\ntoo complex. We provide proofs for tight upper and lower bounds on max-pooling\nlayers in convolutional networks. To ensure widespread usability, we open\nsource our implementation \"Debona\", featuring both the implementation specific\nenhancements as well as the refined boundary computation for faster and more\nexact~results.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jun 2020 10:00:33 GMT"}, {"version": "v2", "created": "Tue, 2 Feb 2021 16:53:29 GMT"}], "update_date": "2021-02-03", "authors_parsed": [["Brix", "Christopher", ""], ["Noll", "Thomas", ""]]}, {"id": "2006.09042", "submitter": "Muhammad Suhaib Tanveer", "authors": "Muhammad Suhaib Tanveer, Muhammad Umar Karim Khan, Chong-Min Kyung", "title": "Fine-Tuning DARTS for Image Classification", "comments": "8 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural Architecture Search (NAS) has gained attraction due to superior\nclassification performance. Differential Architecture Search (DARTS) is a\ncomputationally light method. To limit computational resources DARTS makes\nnumerous approximations. These approximations result in inferior performance.\nWe propose to fine-tune DARTS using fixed operations as they are independent of\nthese approximations. Our method offers a good trade-off between the number of\nparameters and classification accuracy. Our approach improves the top-1\naccuracy on Fashion-MNIST, CompCars, and MIO-TCD datasets by 0.56%, 0.50%, and\n0.39%, respectively compared to the state-of-the-art approaches. Our approach\nperforms better than DARTS, improving the accuracy by 0.28%, 1.64%, 0.34%,\n4.5%, and 3.27% compared to DARTS, on CIFAR-10, CIFAR-100, Fashion-MNIST,\nCompCars, and MIO-TCD datasets, respectively.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jun 2020 10:00:45 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Tanveer", "Muhammad Suhaib", ""], ["Khan", "Muhammad Umar Karim", ""], ["Kyung", "Chong-Min", ""]]}, {"id": "2006.09066", "submitter": "Mohamed Sana", "authors": "Mohamed Sana, Antonio De Domenico, Wei Yu, Yves Lostanlen, and Emilio\n  Calvanese Strinati", "title": "Multi-Agent Reinforcement Learning for Adaptive User Association in\n  Dynamic mmWave Networks", "comments": "Part of this work has been presented in IEEE Globecom 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.AI cs.LG cs.MA", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Network densification and millimeter-wave technologies are key enablers to\nfulfill the capacity and data rate requirements of the fifth generation (5G) of\nmobile networks. In this context, designing low-complexity policies with local\nobservations, yet able to adapt the user association with respect to the global\nnetwork state and to the network dynamics is a challenge. In fact, the\nframeworks proposed in literature require continuous access to global network\ninformation and to recompute the association when the radio environment\nchanges. With the complexity associated to such an approach, these solutions\nare not well suited to dense 5G networks. In this paper, we address this issue\nby designing a scalable and flexible algorithm for user association based on\nmulti-agent reinforcement learning. In this approach, users act as independent\nagents that, based on their local observations only, learn to autonomously\ncoordinate their actions in order to optimize the network sum-rate. Since there\nis no direct information exchange among the agents, we also limit the signaling\noverhead. Simulation results show that the proposed algorithm is able to adapt\nto (fast) changes of radio environment, thus providing large sum-rate gain in\ncomparison to state-of-the-art solutions.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jun 2020 10:51:27 GMT"}], "update_date": "2020-06-17", "authors_parsed": [["Sana", "Mohamed", ""], ["De Domenico", "Antonio", ""], ["Yu", "Wei", ""], ["Lostanlen", "Yves", ""], ["Strinati", "Emilio Calvanese", ""]]}, {"id": "2006.09073", "submitter": "Zihao Zhu", "authors": "Zihao Zhu, Jing Yu, Yujing Wang, Yajing Sun, Yue Hu, Qi Wu", "title": "Mucko: Multi-Layer Cross-Modal Knowledge Reasoning for Fact-based Visual\n  Question Answering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fact-based Visual Question Answering (FVQA) requires external knowledge\nbeyond visible content to answer questions about an image, which is challenging\nbut indispensable to achieve general VQA. One limitation of existing FVQA\nsolutions is that they jointly embed all kinds of information without\nfine-grained selection, which introduces unexpected noises for reasoning the\nfinal answer. How to capture the question-oriented and\ninformation-complementary evidence remains a key challenge to solve the\nproblem. In this paper, we depict an image by a multi-modal heterogeneous\ngraph, which contains multiple layers of information corresponding to the\nvisual, semantic and factual features. On top of the multi-layer graph\nrepresentations, we propose a modality-aware heterogeneous graph convolutional\nnetwork to capture evidence from different layers that is most relevant to the\ngiven question. Specifically, the intra-modal graph convolution selects\nevidence from each modality and cross-modal graph convolution aggregates\nrelevant information across different modalities. By stacking this process\nmultiple times, our model performs iterative reasoning and predicts the optimal\nanswer by analyzing all question-oriented evidence. We achieve a new\nstate-of-the-art performance on the FVQA task and demonstrate the effectiveness\nand interpretability of our model with extensive experiments.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jun 2020 11:03:37 GMT"}, {"version": "v2", "created": "Wed, 17 Jun 2020 00:49:02 GMT"}, {"version": "v3", "created": "Wed, 4 Nov 2020 01:36:36 GMT"}], "update_date": "2020-11-05", "authors_parsed": [["Zhu", "Zihao", ""], ["Yu", "Jing", ""], ["Wang", "Yujing", ""], ["Sun", "Yajing", ""], ["Hu", "Yue", ""], ["Wu", "Qi", ""]]}, {"id": "2006.09161", "submitter": "Hongru Wang", "authors": "Hongru Wang and Xiangru Tang and Sunny Lai and Kwong Sak Leung and Jia\n  Zhu and Gabriel Pui Cheong Fung and Kam-Fai Wong", "title": "CUHK at SemEval-2020 Task 4: CommonSense Explanation, Reasoning and\n  Prediction with Multi-task Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes our system submitted to task 4 of SemEval 2020:\nCommonsense Validation and Explanation (ComVE) which consists of three\nsub-tasks. The task is to directly validate the given sentence whether or not\nit makes sense and require the model to explain it. Based on BERTarchitecture\nwith a multi-task setting, we propose an effective and interpretable \"Explain,\nReason and Predict\" (ERP) system to solve the three sub-tasks about\ncommonsense: (a) Validation, (b)Reasoning, and (c) Explanation. Inspired by\ncognitive studies of common sense, our system first generates a reason or\nunderstanding of the sentences and then chooses which one statement makes\nsense, which is achieved by multi-task learning. During the post-evaluation,\nour system has reached 92.9% accuracy in subtask A (rank 11), 89.7% accuracy in\nsubtask B (rank 9), andBLEU score of 12.9 in subtask C (rank 8)\n", "versions": [{"version": "v1", "created": "Fri, 12 Jun 2020 13:51:12 GMT"}, {"version": "v2", "created": "Tue, 28 Jul 2020 00:34:47 GMT"}], "update_date": "2020-07-29", "authors_parsed": [["Wang", "Hongru", ""], ["Tang", "Xiangru", ""], ["Lai", "Sunny", ""], ["Leung", "Kwong Sak", ""], ["Zhu", "Jia", ""], ["Fung", "Gabriel Pui Cheong", ""], ["Wong", "Kam-Fai", ""]]}, {"id": "2006.09181", "submitter": "Subhro Das", "authors": "Nathan Fulton, Nathan Hunt, Nghia Hoang, Subhro Das", "title": "Formal Verification of End-to-End Learning in Cyber-Physical Systems:\n  Progress and Challenges", "comments": "7 pages, 4 figures. NeurIPS Workshop on Safety and Robustness in\n  Decision Making, 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Autonomous systems -- such as self-driving cars, autonomous drones, and\nautomated trains -- must come with strong safety guarantees. Over the past\ndecade, techniques based on formal methods have enjoyed some success in\nproviding strong correctness guarantees for large software systems including\noperating system kernels, cryptographic protocols, and control software for\ndrones. These successes suggest it might be possible to ensure the safety of\nautonomous systems by constructing formal, computer-checked correctness proofs.\nThis paper identifies three assumptions underlying existing formal verification\ntechniques, explains how each of these assumptions limits the applicability of\nverification in autonomous systems, and summarizes preliminary work toward\nimproving the strength of evidence provided by formal verification.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jun 2020 16:50:47 GMT"}], "update_date": "2020-06-17", "authors_parsed": [["Fulton", "Nathan", ""], ["Hunt", "Nathan", ""], ["Hoang", "Nghia", ""], ["Das", "Subhro", ""]]}, {"id": "2006.09196", "submitter": "Mieczys{\\l}aw K{\\l}opotek", "authors": "Mieczys{\\l}aw A. K{\\l}opotek", "title": "p-d-Separation -- A Concept for Expressing Dependence/Independence\n  Relations in Causal Networks", "comments": "arXiv admin note: substantial text overlap with arXiv:1806.02373", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spirtes, Glymour and Scheines formulated a Conjecture that a direct\ndependence test and a head-to-head meeting test would suffice to construe\ndirected acyclic graph decompositions of a joint probability distribution\n(Bayesian network) for which Pearl's d-separation applies. This Conjecture was\nlater shown to be a direct consequence of a result of Pearl and Verma. This\npaper is intended to prove this Conjecture in a new way, by exploiting the\nconcept of p-d-separation (partial dependency separation). While Pearl's\nd-separation works with Bayesian networks, p-d-separation is intended to apply\nto causal networks: that is partially oriented networks in which orientations\nare given to only to those edges, that express statistically confirmed causal\ninfluence, whereas undirected edges express existence of direct influence\nwithout possibility of determination of direction of causation. As a\nconsequence of the particular way of proving the validity of this Conjecture,\nan algorithm for construction of all the directed acyclic graphs (dags)\ncarrying the available independence information is also presented. The notion\nof a partially oriented graph (pog) is introduced and within this graph the\nnotion of p-d-separation is defined. It is demonstrated that the p-d-separation\nwithin the pog is equivalent to d-separation in all derived dags.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jun 2020 09:30:12 GMT"}], "update_date": "2020-06-17", "authors_parsed": [["K\u0142opotek", "Mieczys\u0142aw A.", ""]]}, {"id": "2006.09213", "submitter": "Wei Wei", "authors": "Wei Wei, Bei Zhou, Georgios Leontidis", "title": "A Hybrid Natural Language Generation System Integrating Rules and Deep\n  Learning Algorithms", "comments": "6 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes an enhanced natural language generation system combining\nthe merits of both rule-based approaches and modern deep learning algorithms,\nboosting its performance to the extent where the generated textual content is\ncapable of exhibiting agile human-writing styles and the content logic of which\nis highly controllable. We also come up with a novel approach called HMCU to\nmeasure the performance of the natural language processing comprehensively and\nprecisely.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jun 2020 00:50:41 GMT"}, {"version": "v2", "created": "Wed, 17 Jun 2020 14:40:38 GMT"}], "update_date": "2020-06-18", "authors_parsed": [["Wei", "Wei", ""], ["Zhou", "Bei", ""], ["Leontidis", "Georgios", ""]]}, {"id": "2006.09226", "submitter": "Francesco Faccio", "authors": "Francesco Faccio, Louis Kirsch, J\\\"urgen Schmidhuber", "title": "Parameter-based Value Functions", "comments": "To appear as a conference paper at ICLR 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditional off-policy actor-critic Reinforcement Learning (RL) algorithms\nlearn value functions of a single target policy. However, when value functions\nare updated to track the learned policy, they forget potentially useful\ninformation about old policies. We introduce a class of value functions called\nParameter-based Value Functions (PVFs) whose inputs include the policy\nparameters. They can generalize across different policies. PVFs can evaluate\nthe performance of any policy given a state, a state-action pair, or a\ndistribution over the RL agent's initial states. First we show how PVFs yield\nnovel off-policy policy gradient theorems. Then we derive off-policy\nactor-critic algorithms based on PVFs trained by Monte Carlo or Temporal\nDifference methods. We show how learned PVFs can zero-shot learn new policies\nthat outperform any policy seen during training. Finally our algorithms are\nevaluated on a selection of discrete and continuous control tasks using shallow\npolicies and deep neural networks. Their performance is comparable to\nstate-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jun 2020 15:04:49 GMT"}, {"version": "v2", "created": "Tue, 6 Oct 2020 17:14:32 GMT"}, {"version": "v3", "created": "Fri, 15 Jan 2021 15:01:49 GMT"}], "update_date": "2021-01-18", "authors_parsed": [["Faccio", "Francesco", ""], ["Kirsch", "Louis", ""], ["Schmidhuber", "J\u00fcrgen", ""]]}, {"id": "2006.09234", "submitter": "Chao Qu", "authors": "Xiaoyu Tan, Chao Qu, Junwu Xiong, James Zhang", "title": "Model Embedding Model-Based Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Model-based reinforcement learning (MBRL) has shown its advantages in\nsample-efficiency over model-free reinforcement learning (MFRL). Despite the\nimpressive results it achieves, it still faces a trade-off between the ease of\ndata generation and model bias. In this paper, we propose a simple and elegant\nmodel-embedding model-based reinforcement learning (MEMB) algorithm in the\nframework of the probabilistic reinforcement learning. To balance the\nsample-efficiency and model bias, we exploit both real and imaginary data in\nthe training. In particular, we embed the model in the policy update and learn\n$Q$ and $V$ functions from the real data set. We provide the theoretical\nanalysis of MEMB with the Lipschitz continuity assumption on the model and\npolicy. At last, we evaluate MEMB on several benchmarks and demonstrate our\nalgorithm can achieve state-of-the-art performance.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jun 2020 15:10:28 GMT"}], "update_date": "2020-06-17", "authors_parsed": [["Tan", "Xiaoyu", ""], ["Qu", "Chao", ""], ["Xiong", "Junwu", ""], ["Zhang", "James", ""]]}, {"id": "2006.09265", "submitter": "Wenda Li", "authors": "Wenda Li and Lei Yu and Yuhuai Wu and Lawrence C. Paulson", "title": "IsarStep: a Benchmark for High-level Mathematical Reasoning", "comments": "9 pages, published at ICLR 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI cs.CL cs.LG cs.PL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A well-defined benchmark is essential for measuring and accelerating research\nprogress of machine learning models. In this paper, we present a benchmark for\nhigh-level mathematical reasoning and study the reasoning capabilities of\nneural sequence-to-sequence models. We build a non-synthetic dataset from the\nlargest repository of proofs written by human experts in a theorem prover. The\ndataset has a broad coverage of undergraduate and research-level mathematical\nand computer science theorems. In our defined task, a model is required to fill\nin a missing intermediate proposition given surrounding proofs. This task\nprovides a starting point for the long-term goal of having machines generate\nhuman-readable proofs automatically. Our experiments and analysis reveal that\nwhile the task is challenging, neural models can capture non-trivial\nmathematical reasoning. We further design a hierarchical transformer that\noutperforms the transformer baseline.\n", "versions": [{"version": "v1", "created": "Sat, 13 Jun 2020 21:09:23 GMT"}, {"version": "v2", "created": "Wed, 24 Mar 2021 16:45:18 GMT"}], "update_date": "2021-03-25", "authors_parsed": [["Li", "Wenda", ""], ["Yu", "Lei", ""], ["Wu", "Yuhuai", ""], ["Paulson", "Lawrence C.", ""]]}, {"id": "2006.09324", "submitter": "Shubham Kumar Bharti", "authors": "Xuezhou Zhang, Shubham Kumar Bharti, Yuzhe Ma, Adish Singla, Xiaojin\n  Zhu", "title": "The Sample Complexity of Teaching-by-Reinforcement on Q-Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the sample complexity of teaching, termed as \"teaching dimension\"\n(TDim) in the literature, for the teaching-by-reinforcement paradigm, where the\nteacher guides the student through rewards. This is distinct from the\nteaching-by-demonstration paradigm motivated by robotics applications, where\nthe teacher teaches by providing demonstrations of state/action trajectories.\nThe teaching-by-reinforcement paradigm applies to a wider range of real-world\nsettings where a demonstration is inconvenient, but has not been studied\nsystematically. In this paper, we focus on a specific family of reinforcement\nlearning algorithms, Q-learning, and characterize the TDim under different\nteachers with varying control power over the environment, and present matching\noptimal teaching algorithms. Our TDim results provide the minimum number of\nsamples needed for reinforcement learning, and we discuss their connections to\nstandard PAC-style RL sample complexity and teaching-by-demonstration sample\ncomplexity results. Our teaching algorithms have the potential to speed up RL\nagent learning in applications where a helpful teacher is available.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jun 2020 17:06:04 GMT"}, {"version": "v2", "created": "Mon, 8 Mar 2021 03:35:37 GMT"}], "update_date": "2021-03-09", "authors_parsed": [["Zhang", "Xuezhou", ""], ["Bharti", "Shubham Kumar", ""], ["Ma", "Yuzhe", ""], ["Singla", "Adish", ""], ["Zhu", "Xiaojin", ""]]}, {"id": "2006.09367", "submitter": "Devendra Singh Chaplot", "authors": "Devendra Singh Chaplot, Helen Jiang, Saurabh Gupta, Abhinav Gupta", "title": "Semantic Curiosity for Active Visual Learning", "comments": "See project webpage at\n  https://devendrachaplot.github.io/projects/SemanticCuriosity", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study the task of embodied interactive learning for object\ndetection. Given a set of environments (and some labeling budget), our goal is\nto learn an object detector by having an agent select what data to obtain\nlabels for. How should an exploration policy decide which trajectory should be\nlabeled? One possibility is to use a trained object detector's failure cases as\nan external reward. However, this will require labeling millions of frames\nrequired for training RL policies, which is infeasible. Instead, we explore a\nself-supervised approach for training our exploration policy by introducing a\nnotion of semantic curiosity. Our semantic curiosity policy is based on a\nsimple observation -- the detection outputs should be consistent. Therefore,\nour semantic curiosity rewards trajectories with inconsistent labeling behavior\nand encourages the exploration policy to explore such areas. The exploration\npolicy trained via semantic curiosity generalizes to novel scenes and helps\ntrain an object detector that outperforms baselines trained with other possible\nalternatives such as random exploration, prediction-error curiosity, and\ncoverage-maximizing exploration.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jun 2020 17:59:24 GMT"}], "update_date": "2020-06-17", "authors_parsed": [["Chaplot", "Devendra Singh", ""], ["Jiang", "Helen", ""], ["Gupta", "Saurabh", ""], ["Gupta", "Abhinav", ""]]}, {"id": "2006.09428", "submitter": "Abhishek Gupta", "authors": "Abhishek Gupta (1 and 2), Camylle Lanteigne (1 and 3) ((1) Montreal AI\n  Ethics Institute, (2) Microsoft, (3) McGill University)", "title": "Response by the Montreal AI Ethics Institute to the European\n  Commission's Whitepaper on AI", "comments": "Submitted to the European Commission", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In February 2020, the European Commission (EC) published a white paper\nentitled, On Artificial Intelligence - A European approach to excellence and\ntrust. This paper outlines the EC's policy options for the promotion and\nadoption of artificial intelligence (AI) in the European Union. The Montreal AI\nEthics Institute (MAIEI) reviewed this paper and published a response\naddressing the EC's plans to build an \"ecosystem of excellence\" and an\n\"ecosystem of trust,\" as well as the safety and liability implications of AI,\nthe internet of things (IoT), and robotics.\n  MAIEI provides 15 recommendations in relation to the sections outlined above,\nincluding: 1) focus efforts on the research and innovation community, member\nstates, and the private sector; 2) create alignment between trading partners'\npolicies and EU policies; 3) analyze the gaps in the ecosystem between\ntheoretical frameworks and approaches to building trustworthy AI; 4) focus on\ncoordination and policy alignment; 5) focus on mechanisms that promote private\nand secure sharing of data; 6) create a network of AI research excellence\ncentres to strengthen the research and innovation community; 7) promote\nknowledge transfer and develop AI expertise through Digital Innovation Hubs; 8)\nadd nuance to the discussion regarding the opacity of AI systems; 9) create a\nprocess for individuals to appeal an AI system's decision or output; 10)\nimplement new rules and strengthen existing regulations; 11) ban the use of\nfacial recognition technology; 12) hold all AI systems to similar standards and\ncompulsory requirements; 13) ensure biometric identification systems fulfill\nthe purpose for which they are implemented; 14) implement a voluntary labelling\nsystem for systems that are not considered high-risk; 15) appoint individuals\nto the oversight process who understand AI systems well and are able to\ncommunicate potential risks.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jun 2020 18:16:51 GMT"}], "update_date": "2020-06-18", "authors_parsed": [["Gupta", "Abhishek", "", "1 and 2"], ["Lanteigne", "Camylle", "", "1 and 3"]]}, {"id": "2006.09436", "submitter": "Daniel Palenicek", "authors": "Alexander I. Cowen-Rivers, Daniel Palenicek, Vincent Moens, Mohammed\n  Abdullah, Aivar Sootla, Jun Wang, Haitham Ammar", "title": "SAMBA: Safe Model-Based & Active Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose SAMBA, a novel framework for safe reinforcement\nlearning that combines aspects from probabilistic modelling, information\ntheory, and statistics. Our method builds upon PILCO to enable active\nexploration using novel(semi-)metrics for out-of-sample Gaussian process\nevaluation optimised through a multi-objective problem that supports\nconditional-value-at-risk constraints. We evaluate our algorithm on a variety\nof safe dynamical system benchmarks involving both low and high-dimensional\nstate representations. Our results show orders of magnitude reductions in\nsamples and violations compared to state-of-the-art methods. Lastly, we provide\nintuition as to the effectiveness of the framework by a detailed analysis of\nour active metrics and safety constraints.\n", "versions": [{"version": "v1", "created": "Fri, 12 Jun 2020 10:40:46 GMT"}], "update_date": "2020-06-18", "authors_parsed": [["Cowen-Rivers", "Alexander I.", ""], ["Palenicek", "Daniel", ""], ["Moens", "Vincent", ""], ["Abdullah", "Mohammed", ""], ["Sootla", "Aivar", ""], ["Wang", "Jun", ""], ["Ammar", "Haitham", ""]]}, {"id": "2006.09497", "submitter": "Xuezhou Zhang", "authors": "Xuezhou Zhang, Yuzhe ma, Adish Singla", "title": "Task-agnostic Exploration in Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Efficient exploration is one of the main challenges in reinforcement learning\n(RL). Most existing sample-efficient algorithms assume the existence of a\nsingle reward function during exploration. In many practical scenarios,\nhowever, there is not a single underlying reward function to guide the\nexploration, for instance, when an agent needs to learn many skills\nsimultaneously, or multiple conflicting objectives need to be balanced. To\naddress these challenges, we propose the \\textit{task-agnostic RL} framework:\nIn the exploration phase, the agent first collects trajectories by exploring\nthe MDP without the guidance of a reward function. After exploration, it aims\nat finding near-optimal policies for $N$ tasks, given the collected\ntrajectories augmented with \\textit{sampled rewards} for each task. We present\nan efficient task-agnostic RL algorithm, \\textsc{UCBZero}, that finds\n$\\epsilon$-optimal policies for $N$ arbitrary tasks after at most $\\tilde\nO(\\log(N)H^5SA/\\epsilon^2)$ exploration episodes. We also provide an\n$\\Omega(\\log (N)H^2SA/\\epsilon^2)$ lower bound, showing that the $\\log$\ndependency on $N$ is unavoidable. Furthermore, we provide an $N$-independent\nsample complexity bound of \\textsc{UCBZero} in the statistically easier setting\nwhen the ground truth reward functions are known.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jun 2020 20:23:41 GMT"}], "update_date": "2020-06-18", "authors_parsed": [["Zhang", "Xuezhou", ""], ["ma", "Yuzhe", ""], ["Singla", "Adish", ""]]}, {"id": "2006.09507", "submitter": "Yingqian Zhang", "authors": "Bram Cals, Yingqian Zhang, Remco Dijkman, Claudy van Dorst", "title": "Solving the Order Batching and Sequencing Problem using Deep\n  Reinforcement Learning", "comments": "Preprint", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In e-commerce markets, on time delivery is of great importance to customer\nsatisfaction. In this paper, we present a Deep Reinforcement Learning (DRL)\napproach for deciding how and when orders should be batched and picked in a\nwarehouse to minimize the number of tardy orders. In particular, the technique\nfacilitates making decisions on whether an order should be picked individually\n(pick-by-order) or picked in a batch with other orders (pick-by-batch), and if\nso with which other orders. We approach the problem by formulating it as a\nsemi-Markov decision process and develop a vector-based state representation\nthat includes the characteristics of the warehouse system. This allows us to\ncreate a deep reinforcement learning solution that learns a strategy by\ninteracting with the environment and solve the problem with a proximal policy\noptimization algorithm. We evaluate the performance of the proposed DRL\napproach by comparing it with several batching and sequencing heuristics in\ndifferent problem settings. The results show that the DRL approach is able to\ndevelop a strategy that produces consistent, good solutions and performs better\nthan the proposed heuristics.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jun 2020 20:40:41 GMT"}], "update_date": "2020-06-18", "authors_parsed": [["Cals", "Bram", ""], ["Zhang", "Yingqian", ""], ["Dijkman", "Remco", ""], ["van Dorst", "Claudy", ""]]}, {"id": "2006.09519", "submitter": "Rachel Freedman", "authors": "Rachel Freedman", "title": "Aligning with Heterogeneous Preferences for Kidney Exchange", "comments": "Presented at the IJCAI-PRICAI 2020 Workshop on Artificial\n  Intelligence Safety", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  AI algorithms increasingly make decisions that impact entire groups of\nhumans. Since humans tend to hold varying and even conflicting preferences, AI\nalgorithms responsible for making decisions on behalf of such groups encounter\nthe problem of preference aggregation: combining inconsistent and sometimes\ncontradictory individual preferences into a representative aggregate. In this\npaper, we address this problem in a real-world public health context: kidney\nexchange. The algorithms that allocate kidneys from living donors to patients\nneeding transplants in kidney exchange matching markets should prioritize\npatients in a way that aligns with the values of the community they serve, but\nallocation preferences vary widely across individuals. In this paper, we\npropose, implement and evaluate a methodology for prioritizing patients based\non such heterogeneous moral preferences. Instead of selecting a single static\nset of patient weights, we learn a distribution over preference functions based\non human subject responses to allocation dilemmas, then sample from this\ndistribution to dynamically determine patient weights during matching. We find\nthat this methodology increases the average rank of matched patients in the\nsampled preference ordering, indicating better satisfaction of group\npreferences. We hope that this work will suggest a roadmap for future automated\nmoral decision making on behalf of heterogeneous groups.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jun 2020 21:16:53 GMT"}], "update_date": "2020-06-18", "authors_parsed": [["Freedman", "Rachel", ""]]}, {"id": "2006.09529", "submitter": "Padmanabhan Santhanam", "authors": "P. Santhanam", "title": "Quality Management of Machine Learning Systems", "comments": "AAAI-20 Workshop on Engineering Dependable and Secure Machine\n  Learning Systems- February 7, 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the past decade, Artificial Intelligence (AI) has become a part of our\ndaily lives due to major advances in Machine Learning (ML) techniques. In spite\nof an explosive growth in the raw AI technology and in consumer facing\napplications on the internet, its adoption in business applications has\nconspicuously lagged behind. For business/mission-critical systems, serious\nconcerns about reliability and maintainability of AI applications remain. Due\nto the statistical nature of the output, software 'defects' are not well\ndefined. Consequently, many traditional quality management techniques such as\nprogram debugging, static code analysis, functional testing, etc. have to be\nreevaluated. Beyond the correctness of an AI model, many other new quality\nattributes, such as fairness, robustness, explainability, transparency, etc.\nbecome important in delivering an AI system. The purpose of this paper is to\npresent a view of a holistic quality management framework for ML applications\nbased on the current advances and identify new areas of software engineering\nresearch to achieve a more trustworthy AI.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jun 2020 21:34:44 GMT"}], "update_date": "2020-06-18", "authors_parsed": [["Santhanam", "P.", ""]]}, {"id": "2006.09540", "submitter": "Adil Rasheed Professor", "authors": "Eivind Meyer and Amalie Heiberg and Adil Rasheed and Omer San", "title": "COLREG-Compliant Collision Avoidance for Unmanned Surface Vehicle using\n  Deep Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Path Following and Collision Avoidance, be it for unmanned surface vessels or\nother autonomous vehicles, are two fundamental guidance problems in robotics.\nFor many decades, they have been subject to academic study, leading to a vast\nnumber of proposed approaches. However, they have mostly been treated as\nseparate problems, and have typically relied on non-linear first-principles\nmodels with parameters that can only be determined experimentally. The rise of\nDeep Reinforcement Learning (DRL) in recent years suggests an alternative\napproach: end-to-end learning of the optimal guidance policy from scratch by\nmeans of a trial-and-error based approach. In this article, we explore the\npotential of Proximal Policy Optimization (PPO), a DRL algorithm with\ndemonstrated state-of-the-art performance on Continuous Control tasks, when\napplied to the dual-objective problem of controlling an underactuated\nAutonomous Surface Vehicle in a COLREGs compliant manner such that it follows\nan a priori known desired path while avoiding collisions with other vessels\nalong the way. Based on high-fidelity elevation and AIS tracking data from the\nTrondheim Fjord, an inlet of the Norwegian sea, we evaluate the trained agent's\nperformance in challenging, dynamic real-world scenarios where the ultimate\nsuccess of the agent rests upon its ability to navigate non-uniform marine\nterrain while handling challenging, but realistic vessel encounters.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jun 2020 22:05:58 GMT"}], "update_date": "2020-06-18", "authors_parsed": [["Meyer", "Eivind", ""], ["Heiberg", "Amalie", ""], ["Rasheed", "Adil", ""], ["San", "Omer", ""]]}, {"id": "2006.09595", "submitter": "Andre Esteva", "authors": "Andre Esteva, Anuprit Kale, Romain Paulus, Kazuma Hashimoto, Wenpeng\n  Yin, Dragomir Radev, Richard Socher", "title": "CO-Search: COVID-19 Information Retrieval with Semantic Search, Question\n  Answering, and Abstractive Summarization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The COVID-19 global pandemic has resulted in international efforts to\nunderstand, track, and mitigate the disease, yielding a significant corpus of\nCOVID-19 and SARS-CoV-2-related publications across scientific disciplines. As\nof May 2020, 128,000 coronavirus-related publications have been collected\nthrough the COVID-19 Open Research Dataset Challenge. Here we present\nCO-Search, a retriever-ranker semantic search engine designed to handle complex\nqueries over the COVID-19 literature, potentially aiding overburdened health\nworkers in finding scientific answers during a time of crisis. The retriever is\nbuilt from a Siamese-BERT encoder that is linearly composed with a TF-IDF\nvectorizer, and reciprocal-rank fused with a BM25 vectorizer. The ranker is\ncomposed of a multi-hop question-answering module, that together with a\nmulti-paragraph abstractive summarizer adjust retriever scores. To account for\nthe domain-specific and relatively limited dataset, we generate a bipartite\ngraph of document paragraphs and citations, creating 1.3 million (citation\ntitle, paragraph) tuples for training the encoder. We evaluate our system on\nthe data of the TREC-COVID information retrieval challenge. CO-Search obtains\ntop performance on the datasets of the first and second rounds, across several\nkey metrics: normalized discounted cumulative gain, precision, mean average\nprecision, and binary preference.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jun 2020 01:32:48 GMT"}], "update_date": "2020-06-18", "authors_parsed": [["Esteva", "Andre", ""], ["Kale", "Anuprit", ""], ["Paulus", "Romain", ""], ["Hashimoto", "Kazuma", ""], ["Yin", "Wenpeng", ""], ["Radev", "Dragomir", ""], ["Socher", "Richard", ""]]}, {"id": "2006.09610", "submitter": "Tianwen Jiang", "authors": "Tianwen Jiang, Tong Zhao, Bing Qin, Ting Liu, Nitesh V. Chawla, Meng\n  Jiang", "title": "Canonicalizing Open Knowledge Bases with Multi-Layered Meta-Graph Neural\n  Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Noun phrases and relational phrases in Open Knowledge Bases are often not\ncanonical, leading to redundant and ambiguous facts. In this work, we integrate\nstructural information (from which tuple, which sentence) and semantic\ninformation (semantic similarity) to do the canonicalization. We represent the\ntwo types of information as a multi-layered graph: the structural information\nforms the links across the sentence, relational phrase, and noun phrase layers;\nthe semantic information forms weighted intra-layer links for each layer. We\npropose a graph neural network model to aggregate the representations of noun\nphrases and relational phrases through the multi-layered meta-graph structure.\nExperiments show that our model outperforms existing approaches on a public\ndatasets in general domain.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jun 2020 02:32:36 GMT"}], "update_date": "2020-06-18", "authors_parsed": [["Jiang", "Tianwen", ""], ["Zhao", "Tong", ""], ["Qin", "Bing", ""], ["Liu", "Ting", ""], ["Chawla", "Nitesh V.", ""], ["Jiang", "Meng", ""]]}, {"id": "2006.09641", "submitter": "Yunzhi Zhang", "authors": "Yunzhi Zhang, Pieter Abbeel, Lerrel Pinto", "title": "Automatic Curriculum Learning through Value Disagreement", "comments": "https://sites.google.com/berkeley.edu/vds/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Continually solving new, unsolved tasks is the key to learning diverse\nbehaviors. Through reinforcement learning (RL), we have made massive strides\ntowards solving tasks that have a single goal. However, in the multi-task\ndomain, where an agent needs to reach multiple goals, the choice of training\ngoals can largely affect sample efficiency. When biological agents learn, there\nis often an organized and meaningful order to which learning happens. Inspired\nby this, we propose setting up an automatic curriculum for goals that the agent\nneeds to solve. Our key insight is that if we can sample goals at the frontier\nof the set of goals that an agent is able to reach, it will provide a\nsignificantly stronger learning signal compared to randomly sampled goals. To\noperationalize this idea, we introduce a goal proposal module that prioritizes\ngoals that maximize the epistemic uncertainty of the Q-function of the policy.\nThis simple technique samples goals that are neither too hard nor too easy for\nthe agent to solve, hence enabling continual improvement. We evaluate our\nmethod across 13 multi-goal robotic tasks and 5 navigation tasks, and\ndemonstrate performance gains over current state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jun 2020 03:58:25 GMT"}], "update_date": "2020-06-18", "authors_parsed": [["Zhang", "Yunzhi", ""], ["Abbeel", "Pieter", ""], ["Pinto", "Lerrel", ""]]}, {"id": "2006.09646", "submitter": "Amber Srivastava Mr", "authors": "Amber Srivastava and Srinivasa M Salapaka", "title": "Parameterized MDPs and Reinforcement Learning Problems -- A Maximum\n  Entropy Principle Based Framework", "comments": "17 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a framework to address a class of sequential decision making\nproblems. Our framework features learning the optimal control policy with\nrobustness to noisy data, determining the unknown state and action parameters,\nand performing sensitivity analysis with respect to problem parameters. We\nconsider two broad categories of sequential decision making problems modelled\nas infinite horizon Markov Decision Processes (MDPs) with (and without) an\nabsorbing state. The central idea underlying our framework is to quantify\nexploration in terms of the Shannon Entropy of the trajectories under the MDP\nand determine the stochastic policy that maximizes it while guaranteeing a low\nvalue of the expected cost along a trajectory. This resulting policy enhances\nthe quality of exploration early on in the learning process, and consequently\nallows faster convergence rates and robust solutions even in the presence of\nnoisy data as demonstrated in our comparisons to popular algorithms such as\nQ-learning, Double Q-learning and entropy regularized Soft Q-learning. The\nframework extends to the class of parameterized MDP and RL problems, where\nstates and actions are parameter dependent, and the objective is to determine\nthe optimal parameters along with the corresponding optimal policy. Here, the\nassociated cost function can possibly be non-convex with multiple poor local\nminima. Simulation results applied to a 5G small cell network problem\ndemonstrate successful determination of communication routes and the small cell\nlocations. We also obtain sensitivity measures to problem parameters and\nrobustness to noisy environment data.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jun 2020 04:08:35 GMT"}, {"version": "v2", "created": "Sun, 10 Jan 2021 22:37:40 GMT"}], "update_date": "2021-05-20", "authors_parsed": [["Srivastava", "Amber", ""], ["Salapaka", "Srinivasa M", ""]]}, {"id": "2006.09670", "submitter": "Ali AhmadiTeshnizi", "authors": "Ali AhmadiTeshnizi, Saber Salehkaleybar, Negar Kiyavash", "title": "LazyIter: A Fast Algorithm for Counting Markov Equivalent DAGs and\n  Designing Experiments", "comments": "11 pages, 2 figures, ICML", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The causal relationships among a set of random variables are commonly\nrepresented by a Directed Acyclic Graph (DAG), where there is a directed edge\nfrom variable $X$ to variable $Y$ if $X$ is a direct cause of $Y$. From the\npurely observational data, the true causal graph can be identified up to a\nMarkov Equivalence Class (MEC), which is a set of DAGs with the same\nconditional independencies between the variables. The size of an MEC is a\nmeasure of complexity for recovering the true causal graph by performing\ninterventions. We propose a method for efficient iteration over possible MECs\ngiven intervention results. We utilize the proposed method for computing MEC\nsizes and experiment design in active and passive learning settings. Compared\nto previous work for computing the size of MEC, our proposed algorithm reduces\nthe time complexity by a factor of $O(n)$ for sparse graphs where $n$ is the\nnumber of variables in the system. Additionally, integrating our approach with\ndynamic programming, we design an optimal algorithm for passive experiment\ndesign. Experimental results show that our proposed algorithms for both\ncomputing the size of MEC and experiment design outperform the state of the\nart.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jun 2020 05:51:34 GMT"}], "update_date": "2020-06-18", "authors_parsed": [["AhmadiTeshnizi", "Ali", ""], ["Salehkaleybar", "Saber", ""], ["Kiyavash", "Negar", ""]]}, {"id": "2006.09684", "submitter": "Guorui Zhou", "authors": "Biye Jiang, Pengye Zhang, Rihan Chen, Binding Dai, Xinchen Luo, Yin\n  Yang, Guan Wang, Guorui Zhou, Xiaoqiang Zhu, Kun Gai", "title": "DCAF: A Dynamic Computation Allocation Framework for Online Serving\n  System", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.AI eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern large-scale systems such as recommender system and online advertising\nsystem are built upon computation-intensive infrastructure. The typical\nobjective in these applications is to maximize the total revenue, e.g.\nGMV~(Gross Merchandise Volume), under a limited computation resource. Usually,\nthe online serving system follows a multi-stage cascade architecture, which\nconsists of several stages including retrieval, pre-ranking, ranking, etc.\nThese stages usually allocate resource manually with specific computing power\nbudgets, which requires the serving configuration to adapt accordingly. As a\nresult, the existing system easily falls into suboptimal solutions with respect\nto maximizing the total revenue. The limitation is due to the face that,\nalthough the value of traffic requests vary greatly, online serving system\nstill spends equal computing power among them.\n  In this paper, we introduce a novel idea that online serving system could\ntreat each traffic request differently and allocate \"personalized\" computation\nresource based on its value. We formulate this resource allocation problem as a\nknapsack problem and propose a Dynamic Computation Allocation Framework~(DCAF).\nUnder some general assumptions, DCAF can theoretically guarantee that the\nsystem can maximize the total revenue within given computation budget. DCAF\nbrings significant improvement and has been deployed in the display advertising\nsystem of Taobao for serving the main traffic. With DCAF, we are able to\nmaintain the same business performance with 20\\% computation resource\nreduction.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jun 2020 07:00:57 GMT"}], "update_date": "2020-06-18", "authors_parsed": [["Jiang", "Biye", ""], ["Zhang", "Pengye", ""], ["Chen", "Rihan", ""], ["Dai", "Binding", ""], ["Luo", "Xinchen", ""], ["Yang", "Yin", ""], ["Wang", "Guan", ""], ["Zhou", "Guorui", ""], ["Zhu", "Xiaoqiang", ""], ["Gai", "Kun", ""]]}, {"id": "2006.09786", "submitter": "Carl-Johan Hoel", "authors": "Carl-Johan Hoel, Tommy Tram, Jonas Sj\\\"oberg", "title": "Reinforcement Learning with Uncertainty Estimation for Tactical\n  Decision-Making in Intersections", "comments": null, "journal-ref": "IEEE Intelligent Transportation Systems Conference (ITSC), 2020,\n  pp. 318-324", "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper investigates how a Bayesian reinforcement learning method can be\nused to create a tactical decision-making agent for autonomous driving in an\nintersection scenario, where the agent can estimate the confidence of its\nrecommended actions. An ensemble of neural networks, with additional randomized\nprior functions (RPF), are trained by using a bootstrapped experience replay\nmemory. The coefficient of variation in the estimated $Q$-values of the\nensemble members is used to approximate the uncertainty, and a criterion that\ndetermines if the agent is sufficiently confident to make a particular decision\nis introduced. The performance of the ensemble RPF method is evaluated in an\nintersection scenario, and compared to a standard Deep Q-Network method. It is\nshown that the trained ensemble RPF agent can detect cases with high\nuncertainty, both in situations that are far from the training distribution,\nand in situations that seldom occur within the training distribution. In this\nstudy, the uncertainty information is used to choose safe actions in unknown\nsituations, which removes all collisions from within the training distribution,\nand most collisions outside of the distribution.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jun 2020 11:29:26 GMT"}], "update_date": "2020-11-04", "authors_parsed": [["Hoel", "Carl-Johan", ""], ["Tram", "Tommy", ""], ["Sj\u00f6berg", "Jonas", ""]]}, {"id": "2006.09807", "submitter": "Sam Snodgrass", "authors": "Sam Snodgrass and Anurag Sarkar", "title": "Multi-Domain Level Generation and Blending with Sketches via\n  Example-Driven BSP and Variational Autoencoders", "comments": "To appear in FDG 2020 Cite as: @inproceedings{snodgrass2020blending,\n  title={Multi-Domain Level Generation and Blending with Sketches via\n  Example-Driven BSP and Variational Autoencoders}, author={Snodgrass, Sam and\n  Sarkar, Anurag}, booktitle={Proceedings of the 15th International Conference\n  on the Foundations of Digital Games}, year={2020} }", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Procedural content generation via machine learning (PCGML) has demonstrated\nits usefulness as a content and game creation approach, and has been shown to\nbe able to support human creativity. An important facet of creativity is\ncombinational creativity or the recombination, adaptation, and reuse of ideas\nand concepts between and across domains. In this paper, we present a PCGML\napproach for level generation that is able to recombine, adapt, and reuse\nstructural patterns from several domains to approximate unseen domains. We\nextend prior work involving example-driven Binary Space Partitioning for\nrecombining and reusing patterns in multiple domains, and incorporate\nVariational Autoencoders (VAEs) for generating unseen structures. We evaluate\nour approach by blending across $7$ domains and subsets of those domains. We\nshow that our approach is able to blend domains together while retaining\nstructural components. Additionally, by using different groups of training\ndomains our approach is able to generate both 1) levels that reproduce and\ncapture features of a target domain, and 2) levels that have vastly different\nproperties from the input domain.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jun 2020 12:21:22 GMT"}], "update_date": "2020-06-18", "authors_parsed": [["Snodgrass", "Sam", ""], ["Sarkar", "Anurag", ""]]}, {"id": "2006.09868", "submitter": "Vaishak Belle", "authors": "Vaishak Belle", "title": "Logic, Probability and Action: A Situation Calculus Perspective", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.LO cs.SC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The unification of logic and probability is a long-standing concern in AI,\nand more generally, in the philosophy of science. In essence, logic provides an\neasy way to specify properties that must hold in every possible world, and\nprobability allows us to further quantify the weight and ratio of the worlds\nthat must satisfy a property. To that end, numerous developments have been\nundertaken, culminating in proposals such as probabilistic relational models.\nWhile this progress has been notable, a general-purpose first-order knowledge\nrepresentation language to reason about probabilities and dynamics, including\nin continuous settings, is still to emerge. In this paper, we survey recent\nresults pertaining to the integration of logic, probability and actions in the\nsituation calculus, which is arguably one of the oldest and most well-known\nformalisms. We then explore reduction theorems and programming interfaces for\nthe language. These results are motivated in the context of cognitive robotics\n(as envisioned by Reiter and his colleagues) for the sake of concreteness.\nOverall, the advantage of proving results for such a general language is that\nit becomes possible to adapt them to any special-purpose fragment, including\nbut not limited to popular probabilistic relational models.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jun 2020 13:49:53 GMT"}], "update_date": "2020-06-18", "authors_parsed": [["Belle", "Vaishak", ""]]}, {"id": "2006.09890", "submitter": "Guangyi Zhang", "authors": "Guangyi Zhang and Aristides Gionis", "title": "Diverse Rule Sets", "comments": null, "journal-ref": "Proceedings of the 26th ACM SIGKDD Conference on Knowledge\n  Discovery and Data Mining (KDD '20), August 23--27, 2020, Virtual Event, CA,\n  USA", "doi": "10.1145/3394486.3403204", "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While machine-learning models are flourishing and transforming many aspects\nof everyday life, the inability of humans to understand complex models poses\ndifficulties for these models to be fully trusted and embraced. Thus,\ninterpretability of models has been recognized as an equally important quality\nas their predictive power. In particular, rule-based systems are experiencing a\nrenaissance owing to their intuitive if-then representation.\n  However, simply being rule-based does not ensure interpretability. For\nexample, overlapped rules spawn ambiguity and hinder interpretation. Here we\npropose a novel approach of inferring diverse rule sets, by optimizing small\noverlap among decision rules with a 2-approximation guarantee under the\nframework of Max-Sum diversification. We formulate the problem as maximizing a\nweighted sum of discriminative quality and diversity of a rule set.\n  In order to overcome an exponential-size search space of association rules,\nwe investigate several natural options for a small candidate set of\nhigh-quality rules, including frequent and accurate rules, and examine their\nhardness. Leveraging the special structure in our formulation, we then devise\nan efficient randomized algorithm, which samples rules that are highly\ndiscriminative and have small overlap. The proposed sampling algorithm\nanalytically targets a distribution of rules that is tailored to our objective.\n  We demonstrate the superior predictive power and interpretability of our\nmodel with a comprehensive empirical study against strong baselines.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jun 2020 14:15:25 GMT"}], "update_date": "2020-06-18", "authors_parsed": [["Zhang", "Guangyi", ""], ["Gionis", "Aristides", ""]]}, {"id": "2006.09895", "submitter": "J\\'ozsef D\\'aniel G\\'asp\\'ar", "authors": "J\\'ozsef D\\'aniel G\\'asp\\'ar, Martin Horv\\'ath, Gy\\H{o}z\\H{o}\n  Horv\\'ath and Zolt\\'an Zvara", "title": "Ranking and benchmarking framework for sampling algorithms on synthetic\n  data streams", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the fields of big data, AI, and streaming processing, we work with large\namounts of data from multiple sources. Due to memory and network limitations,\nwe process data streams on distributed systems to alleviate computational and\nnetwork loads. When data streams with non-uniform distributions are processed,\nwe often observe overloaded partitions due to the use of simple hash\npartitioning. To tackle this imbalance, we can use dynamic partitioning\nalgorithms that require a sampling algorithm to precisely estimate the\nunderlying distribution of the data stream. There is no standardized way to\ntest these algorithms. We offer an extensible ranking framework with benchmark\nand hyperparameter optimization capabilities and supply our framework with a\ndata generator that can handle concept drifts.\n  Our work includes a generator for dynamic micro-bursts that we can apply to\nany data stream. We provide algorithms that react to concept drifts and compare\nthose against the state-of-the-art algorithms using our framework.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jun 2020 14:25:07 GMT"}], "update_date": "2020-06-18", "authors_parsed": [["G\u00e1sp\u00e1r", "J\u00f3zsef D\u00e1niel", ""], ["Horv\u00e1th", "Martin", ""], ["Horv\u00e1th", "Gy\u0151z\u0151", ""], ["Zvara", "Zolt\u00e1n", ""]]}, {"id": "2006.09896", "submitter": "Adam Sutton", "authors": "Adam Sutton and Nello Cristianini", "title": "On the Learnability of Concepts: With Applications to Comparing Word\n  Embedding Algorithms", "comments": "7 Pages. AIAI 2020. 5 equations 6 tables", "journal-ref": "Artificial Intelligence Applications and Innovations. AIAI 2020.\n  IFIP Advances in Information and Communication Technology, vol 584", "doi": "10.1007/978-3-030-49186-4", "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Word Embeddings are used widely in multiple Natural Language Processing (NLP)\napplications. They are coordinates associated with each word in a dictionary,\ninferred from statistical properties of these words in a large corpus. In this\npaper we introduce the notion of \"concept\" as a list of words that have shared\nsemantic content. We use this notion to analyse the learnability of certain\nconcepts, defined as the capability of a classifier to recognise unseen members\nof a concept after training on a random subset of it. We first use this method\nto measure the learnability of concepts on pretrained word embeddings. We then\ndevelop a statistical analysis of concept learnability, based on hypothesis\ntesting and ROC curves, in order to compare the relative merits of various\nembedding algorithms using a fixed corpora and hyper parameters. We find that\nall embedding methods capture the semantic content of those word lists, but\nfastText performs better than the others.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jun 2020 14:25:36 GMT"}], "update_date": "2020-06-18", "authors_parsed": [["Sutton", "Adam", ""], ["Cristianini", "Nello", ""]]}, {"id": "2006.09919", "submitter": "Hua Zheng", "authors": "Hua Zheng, Wei Xie and Mingbin Ben Feng", "title": "Green Simulation Assisted Reinforcement Learning with Model Risk for\n  Biomanufacturing Learning and Control", "comments": "12 pages, 1 figures. To appear in the Proceedings of the 2020 Winter\n  Simulation Conference (WSC)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Biopharmaceutical manufacturing faces critical challenges, including\ncomplexity, high variability, lengthy lead time, and limited historical data\nand knowledge of the underlying system stochastic process. To address these\nchallenges, we propose a green simulation assisted model-based reinforcement\nlearning to support process online learning and guide dynamic decision making.\nBasically, the process model risk is quantified by the posterior distribution.\nAt any given policy, we predict the expected system response with prediction\nrisk accounting for both inherent stochastic uncertainty and model risk. Then,\nwe propose green simulation assisted reinforcement learning and derive the\nmixture proposal distribution of decision process and likelihood ratio based\nmetamodel for the policy gradient, which can selectively reuse process\ntrajectory outputs collected from previous experiments to increase the\nsimulation data-efficiency, improve the policy gradient estimation accuracy,\nand speed up the search for the optimal policy. Our numerical study indicates\nthat the proposed approach demonstrates the promising performance.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jun 2020 14:59:13 GMT"}], "update_date": "2020-06-18", "authors_parsed": [["Zheng", "Hua", ""], ["Xie", "Wei", ""], ["Feng", "Mingbin Ben", ""]]}, {"id": "2006.09939", "submitter": "Aleksandr Panov", "authors": "Alexey Skrynnik, Aleksey Staroverov, Ermek Aitygulov, Kirill Aksenov,\n  Vasilii Davydov, Aleksandr I. Panov", "title": "Forgetful Experience Replay in Hierarchical Reinforcement Learning from\n  Demonstrations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Currently, deep reinforcement learning (RL) shows impressive results in\ncomplex gaming and robotic environments. Often these results are achieved at\nthe expense of huge computational costs and require an incredible number of\nepisodes of interaction between the agent and the environment. There are two\nmain approaches to improving the sample efficiency of reinforcement learning\nmethods - using hierarchical methods and expert demonstrations. In this paper,\nwe propose a combination of these approaches that allow the agent to use\nlow-quality demonstrations in complex vision-based environments with multiple\nrelated goals. Our forgetful experience replay (ForgER) algorithm effectively\nhandles errors in expert data and reduces quality losses when adapting the\naction space and states representation to the agent's capabilities. Our\nproposed goal-oriented structuring of replay buffer allows the agent to\nautomatically highlight sub-goals for solving complex hierarchical tasks in\ndemonstrations. Our method is universal and can be integrated into various\noff-policy methods. It surpasses all known existing state-of-the-art RL methods\nusing expert demonstrations on various model environments. The solution based\non our algorithm beats all the solutions for the famous MineRL competition and\nallows the agent to mine a diamond in the Minecraft environment.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jun 2020 15:38:40 GMT"}], "update_date": "2020-06-18", "authors_parsed": [["Skrynnik", "Alexey", ""], ["Staroverov", "Aleksey", ""], ["Aitygulov", "Ermek", ""], ["Aksenov", "Kirill", ""], ["Davydov", "Vasilii", ""], ["Panov", "Aleksandr I.", ""]]}, {"id": "2006.09950", "submitter": "Aleksandr Panov", "authors": "Andrey Gorodetskiy, Alexandra Shlychkova, Aleksandr I. Panov", "title": "Delta Schema Network in Model-based Reinforcement Learning", "comments": "Published at the AGI 2020 conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work is devoted to unresolved problems of Artificial General\nIntelligence - the inefficiency of transfer learning. One of the mechanisms\nthat are used to solve this problem in the area of reinforcement learning is a\nmodel-based approach. In the paper we are expanding the schema networks method\nwhich allows to extract the logical relationships between objects and actions\nfrom the environment data. We present algorithms for training a Delta Schema\nNetwork (DSN), predicting future states of the environment and planning actions\nthat will lead to positive reward. DSN shows strong performance of transfer\nlearning on the classic Atari game environment.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jun 2020 15:58:25 GMT"}, {"version": "v2", "created": "Wed, 8 Jul 2020 05:58:54 GMT"}], "update_date": "2020-07-09", "authors_parsed": [["Gorodetskiy", "Andrey", ""], ["Shlychkova", "Alexandra", ""], ["Panov", "Aleksandr I.", ""]]}, {"id": "2006.09981", "submitter": "Mojtaba Moattari", "authors": "Mojtaba Moattari, Mohammad Hassan Moradi, Emad Roshandel", "title": "Uncertainty Principle based optimization; new metaheuristics framework", "comments": "18 pages, 2 figures, 11 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To more flexibly balance between exploration and exploitation, a new\nmeta-heuristic method based on Uncertainty Principle concepts is proposed in\nthis paper. UP is is proved effective in multiple branches of science. In the\nbranch of quantum mechanics, canonically conjugate observables such as position\nand momentum cannot both be distinctly determined in any quantum state. In the\nsame manner, the branch of Spectral filtering design implies that a nonzero\nfunction and its Fourier transform cannot both be sharply localized. After\ndelving into such concepts on Uncertainty Principle and their variations in\nquantum physics, Fourier analysis, and wavelet design, the proposed framework\nis described in terms of algorithm and flowchart. Our proposed optimizer's idea\nis based on an inherent uncertainty in performing local search versus global\nsolution search. A set of compatible metrics for each part of the framework is\nproposed to derive preferred form of algorithm. Evaluations and comparisons at\nthe end of paper show competency and distinct capability of the algorithm over\nsome of the well-known and recently proposed metaheuristics.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jun 2020 16:20:42 GMT"}], "update_date": "2020-06-18", "authors_parsed": [["Moattari", "Mojtaba", ""], ["Moradi", "Mohammad Hassan", ""], ["Roshandel", "Emad", ""]]}, {"id": "2006.09982", "submitter": "Trevor E. Carlson", "authors": "Srivatsa P and Kyle Timothy Ng Chu and Burin Amornpaisannon and\n  Yaswanth Tavva and Venkata Pavan Kumar Miriyala and Jibin Wu and Malu Zhang\n  and Haizhou Li and Trevor E. Carlson", "title": "You Only Spike Once: Improving Energy-Efficient Neuromorphic Inference\n  to ANN-Level Accuracy", "comments": "10 pages, 4 figures. This work has been submitted to the IEEE for\n  possible publication. Copyright may be transferred without notice, after\n  which this version may no longer be accessible. This work is an extended\n  version of the paper accepted to the 2nd Workshop on Accelerated Machine\n  Learning (AccML 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.AR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the past decade, advances in Artificial Neural Networks (ANNs) have\nallowed them to perform extremely well for a wide range of tasks. In fact, they\nhave reached human parity when performing image recognition, for example.\nUnfortunately, the accuracy of these ANNs comes at the expense of a large\nnumber of cache and/or memory accesses and compute operations. Spiking Neural\nNetworks (SNNs), a type of neuromorphic, or brain-inspired network, have\nrecently gained significant interest as power-efficient alternatives to ANNs,\nbecause they are sparse, accessing very few weights, and typically only use\naddition operations instead of the more power-intensive multiply-and-accumulate\n(MAC) operations. The vast majority of neuromorphic hardware designs support\nrate-encoded SNNs, where the information is encoded in spike rates.\nRate-encoded SNNs could be seen as inefficient as an encoding scheme because it\ninvolves the transmission of a large number of spikes. A more efficient\nencoding scheme, Time-To-First-Spike (TTFS) encoding, encodes information in\nthe relative time of arrival of spikes. While TTFS-encoded SNNs are more\nefficient than rate-encoded SNNs, they have, up to now, performed poorly in\nterms of accuracy compared to previous methods. Hence, in this work, we aim to\novercome the limitations of TTFS-encoded neuromorphic systems. To accomplish\nthis, we propose: (1) a novel optimization algorithm for TTFS-encoded SNNs\nconverted from ANNs and (2) a novel hardware accelerator for TTFS-encoded SNNs,\nwith a scalable and low-power design. Overall, our work in TTFS encoding and\ntraining improves the accuracy of SNNs to achieve state-of-the-art results on\nMNIST MLPs, while reducing power consumption by 1.46$\\times$ over the\nstate-of-the-art neuromorphic hardware.\n", "versions": [{"version": "v1", "created": "Wed, 3 Jun 2020 15:55:53 GMT"}, {"version": "v2", "created": "Sun, 8 Nov 2020 09:10:57 GMT"}], "update_date": "2020-11-11", "authors_parsed": [["P", "Srivatsa", ""], ["Chu", "Kyle Timothy Ng", ""], ["Amornpaisannon", "Burin", ""], ["Tavva", "Yaswanth", ""], ["Miriyala", "Venkata Pavan Kumar", ""], ["Wu", "Jibin", ""], ["Zhang", "Malu", ""], ["Li", "Haizhou", ""], ["Carlson", "Trevor E.", ""]]}, {"id": "2006.09996", "submitter": "Micha{\\l} Okulewicz", "authors": "Micha{\\l} Okulewicz and Jacek Ma\\'ndziuk", "title": "Dynamic Vehicle Routing Problem: A Monte Carlo approach", "comments": null, "journal-ref": "Information Technologies: Research and Their Interdisciplinary\n  Applications 2015, 119-138, Institute of Computer Science Polish Academy of\n  Sciences, ISBN 978-83-63159-23-8", "doi": null, "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we solve the Dynamic Vehicle Routing Problem (DVRP). DVRP is a\nmodification of the Vehicle Routing Problem, in which the clients' requests\n(cities) number and location might not be known at the beginning of the working\nday Additionally, all requests must be served during one working day by a fleet\nof vehicles with limited capacity. In this work we propose a Monte Carlo method\n(MCTree), which directly approaches the dynamic nature of arriving requests in\nthe DVRP. The method is also hybridized (MCTree+PSO) with our previous\nTwo-Phase Multi-swarm Particle Swarm Optimization (2MPSO) algorithm.\n  Our method is based on two assumptions. First, that we know a bounding\nrectangle of the area in which the requests might appear. Second, that the\ninitial requests' sizes and frequency of appearance are representative for the\nyet unknown clients' requests. In order to solve the DVRP we divide the working\nday into several time slices in which we solve a static problem. In our Monte\nCarlo approach we randomly generate the unknown clients' requests with uniform\nspatial distribution over the bounding rectangle and requests' sizes uniformly\nsampled from the already known requests' sizes. The solution proposal is\nconstructed with the application of a clustering algorithm and a route\nconstruction algorithm.\n  The MCTree method is tested on a well established set of benchmarks proposed\nby Kilby et al. and is compared with the results achieved by applying our\nprevious 2MPSO algorithm and other literature results. The proposed MCTree\napproach achieves a better time to quality trade-off then plain heuristic\nalgorithms. Moreover, a hybrid MCTree+PSO approach achieves better time to\nquality trade-off then 2MPSO for small optimization time limits, making the\nhybrid a good candidate for handling real world scale goods delivery problems.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jun 2020 23:10:00 GMT"}], "update_date": "2020-06-18", "authors_parsed": [["Okulewicz", "Micha\u0142", ""], ["Ma\u0144dziuk", "Jacek", ""]]}, {"id": "2006.10022", "submitter": "Forough Arabshahi", "authors": "Forough Arabshahi, Jennifer Lee, Mikayla Gawarecki, Kathryn Mazaitis,\n  Amos Azaria, Tom Mitchell", "title": "Conversational Neuro-Symbolic Commonsense Reasoning", "comments": "Appearing in the 35th AAAI international Conference on Artificial\n  Intelligence, 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In order for conversational AI systems to hold more natural and broad-ranging\nconversations, they will require much more commonsense, including the ability\nto identify unstated presumptions of their conversational partners. For\nexample, in the command \"If it snows at night then wake me up early because I\ndon't want to be late for work\" the speaker relies on commonsense reasoning of\nthe listener to infer the implicit presumption that they wish to be woken only\nif it snows enough to cause traffic slowdowns. We consider here the problem of\nunderstanding such imprecisely stated natural language commands given in the\nform of \"if-(state), then-(action), because-(goal)\" statements. More precisely,\nwe consider the problem of identifying the unstated presumptions of the speaker\nthat allow the requested action to achieve the desired goal from the given\nstate (perhaps elaborated by making the implicit presumptions explicit). We\nrelease a benchmark data set for this task, collected from humans and annotated\nwith commonsense presumptions. We present a neuro-symbolic theorem prover that\nextracts multi-hop reasoning chains, and apply it to this problem. Furthermore,\nto accommodate the reality that current AI commonsense systems lack full\ncoverage, we also present an interactive conversational framework built on our\nneuro-symbolic system, that conversationally evokes commonsense knowledge from\nhumans to complete its reasoning chains.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jun 2020 17:28:38 GMT"}, {"version": "v2", "created": "Fri, 19 Jun 2020 18:24:40 GMT"}, {"version": "v3", "created": "Tue, 2 Feb 2021 07:37:41 GMT"}], "update_date": "2021-02-03", "authors_parsed": [["Arabshahi", "Forough", ""], ["Lee", "Jennifer", ""], ["Gawarecki", "Mikayla", ""], ["Mazaitis", "Kathryn", ""], ["Azaria", "Amos", ""], ["Mitchell", "Tom", ""]]}, {"id": "2006.10034", "submitter": "Matthew Chang", "authors": "Matthew Chang, Arjun Gupta, Saurabh Gupta", "title": "Semantic Visual Navigation by Watching YouTube Videos", "comments": "NeurIPS 2020. Project website with code, models, and videos:\n  https://matthewchang.github.io/value-learning-from-video", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Semantic cues and statistical regularities in real-world environment layouts\ncan improve efficiency for navigation in novel environments. This paper learns\nand leverages such semantic cues for navigating to objects of interest in novel\nenvironments, by simply watching YouTube videos. This is challenging because\nYouTube videos don't come with labels for actions or goals, and may not even\nshowcase optimal behavior. Our method tackles these challenges through the use\nof Q-learning on pseudo-labeled transition quadruples (image, action, next\nimage, reward). We show that such off-policy Q-learning from passive data is\nable to learn meaningful semantic cues for navigation. These cues, when used in\na hierarchical navigation policy, lead to improved efficiency at the ObjectGoal\ntask in visually realistic simulations. We observe a relative improvement of\n15-83% over end-to-end RL, behavior cloning, and classical methods, while using\nminimal direct interaction.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jun 2020 17:56:00 GMT"}, {"version": "v2", "created": "Tue, 27 Oct 2020 05:46:46 GMT"}], "update_date": "2020-10-28", "authors_parsed": [["Chang", "Matthew", ""], ["Gupta", "Arjun", ""], ["Gupta", "Saurabh", ""]]}, {"id": "2006.10085", "submitter": "Samira Samadi", "authors": "Mehrdad Ghadiri, Samira Samadi, Santosh Vempala", "title": "Socially Fair k-Means Clustering", "comments": "12 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that the popular k-means clustering algorithm (Lloyd's heuristic),\nused for a variety of scientific data, can result in outcomes that are\nunfavorable to subgroups of data (e.g., demographic groups). Such biased\nclusterings can have deleterious implications for human-centric applications\nsuch as resource allocation. We present a fair k-means objective and algorithm\nto choose cluster centers that provide equitable costs for different groups.\nThe algorithm, Fair-Lloyd, is a modification of Lloyd's heuristic for k-means,\ninheriting its simplicity, efficiency, and stability. In comparison with\nstandard Lloyd's, we find that on benchmark datasets, Fair-Lloyd exhibits\nunbiased performance by ensuring that all groups have equal costs in the output\nk-clustering, while incurring a negligible increase in running time, thus\nmaking it a viable fair option wherever k-means is currently used.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jun 2020 18:05:17 GMT"}, {"version": "v2", "created": "Thu, 29 Oct 2020 16:03:50 GMT"}], "update_date": "2020-10-30", "authors_parsed": [["Ghadiri", "Mehrdad", ""], ["Samadi", "Samira", ""], ["Vempala", "Santosh", ""]]}, {"id": "2006.10228", "submitter": "Chang-Shing Lee", "authors": "Chang-Shing Lee, Mei-Hui Wang, Wen-Kai Kuan, Zong-Han Ciou, Yi-Lin\n  Tsai, Wei-Shan Chang, Lian-Chao Li, Naoyuki Kubota, Tzong-Xiang Huang, Eri\n  Sato-Shimokawara, and Toru Yamaguchi", "title": "A Study on AI-FML Robotic Agent for Student Learning Behavior Ontology\n  Construction", "comments": "This article has been accepted as a conference paper at CcS 2020 and\n  will be published in IEEE", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CY cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose an AI-FML robotic agent for student learning\nbehavior ontology construction which can be applied in English speaking and\nlistening domain. The AI-FML robotic agent with the ontology contains the\nperception intelligence, computational intelligence, and cognition intelligence\nfor analyzing student learning behavior. In addition, there are three\nintelligent agents, including a perception agent, a computational agent, and a\ncognition agent in the AI-FML robotic agent. We deploy the perception agent and\nthe cognition agent on the robot Kebbi Air. Moreover, the computational agent\nwith the Deep Neural Network (DNN) model is performed in the cloud and can\ncommunicate with the perception agent and cognition agent via the Internet. The\nproposed AI-FML robotic agent is applied in Taiwan and tested in Japan. The\nexperimental results show that the agents can be utilized in the human and\nmachine co-learning model for the future education.\n", "versions": [{"version": "v1", "created": "Thu, 18 Jun 2020 01:45:30 GMT"}, {"version": "v2", "created": "Sat, 27 Jun 2020 11:56:54 GMT"}], "update_date": "2020-06-30", "authors_parsed": [["Lee", "Chang-Shing", ""], ["Wang", "Mei-Hui", ""], ["Kuan", "Wen-Kai", ""], ["Ciou", "Zong-Han", ""], ["Tsai", "Yi-Lin", ""], ["Chang", "Wei-Shan", ""], ["Li", "Lian-Chao", ""], ["Kubota", "Naoyuki", ""], ["Huang", "Tzong-Xiang", ""], ["Sato-Shimokawara", "Eri", ""], ["Yamaguchi", "Toru", ""]]}, {"id": "2006.10356", "submitter": "Priyank Agrawal", "authors": "Priyank Agrawal and Theja Tulabandhula", "title": "Learning by Repetition: Stochastic Multi-armed Bandits under Priming\n  Effect", "comments": "Appears in the 36th Conference on Uncertainty in Artificial\n  Intelligence (UAI 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the effect of persistence of engagement on learning in a stochastic\nmulti-armed bandit setting. In advertising and recommendation systems,\nrepetition effect includes a wear-in period, where the user's propensity to\nreward the platform via a click or purchase depends on how frequently they see\nthe recommendation in the recent past. It also includes a counteracting\nwear-out period, where the user's propensity to respond positively is dampened\nif the recommendation was shown too many times recently. Priming effect can be\nnaturally modelled as a temporal constraint on the strategy space, since the\nreward for the current action depends on historical actions taken by the\nplatform. We provide novel algorithms that achieves sublinear regret in time\nand the relevant wear-in/wear-out parameters. The effect of priming on the\nregret upper bound is also additive, and we get back a guarantee that matches\npopular algorithms such as the UCB1 and Thompson sampling when there is no\npriming effect. Our work complements recent work on modeling time varying\nrewards, delays and corruptions in bandits, and extends the usage of rich\nbehavior models in sequential decision making settings.\n", "versions": [{"version": "v1", "created": "Thu, 18 Jun 2020 08:27:23 GMT"}], "update_date": "2020-06-19", "authors_parsed": [["Agrawal", "Priyank", ""], ["Tulabandhula", "Theja", ""]]}, {"id": "2006.10437", "submitter": "Vivek Nallur", "authors": "Elayne Ruane and Vivek Nallur", "title": "\"EHLO WORLD\" -- Checking If Your Conversational AI Knows Right from\n  Wrong", "comments": "8 pages, 2 figures, SoCAI 2020 : AISB Symposium on Conversational AI", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In this paper we discuss approaches to evaluating and validating the ethical\nclaims of a Conversational AI system. We outline considerations around both a\ntop-down regulatory approach and bottom-up processes. We describe the ethical\nbasis for each approach and propose a hybrid which we demonstrate by taking the\ncase of a customer service chatbot as an example. We speculate on the kinds of\ntop-down and bottom-up processes that would need to exist for a hybrid\nframework to successfully function as both an enabler as well as a shepherd\namong multiple use-cases and multiple competing AI solutions.\n", "versions": [{"version": "v1", "created": "Thu, 18 Jun 2020 11:33:02 GMT"}], "update_date": "2020-06-19", "authors_parsed": [["Ruane", "Elayne", ""], ["Nallur", "Vivek", ""]]}, {"id": "2006.10504", "submitter": "Tanuj Kr Aasawat", "authors": "Xiufeng Yang and Tanuj Kr Aasawat and Kazuki Yoshizoe", "title": "Practical Massively Parallel Monte-Carlo Tree Search Applied to\n  Molecular Design", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is common practice to use large computational resources to train neural\nnetworks, as is known from many examples, such as reinforcement learning\napplications. However, while massively parallel computing is often used for\ntraining models, it is rarely used for searching solutions for combinatorial\noptimization problems. In this paper, we propose a novel massively parallel\nMonte-Carlo Tree Search (MP-MCTS) algorithm that works efficiently for 1,000\nworker scale, and apply it to molecular design. This is the first work that\napplies distributed MCTS to a real-world and non-game problem. Existing work on\nlarge-scale parallel MCTS show efficient scalability in terms of the number of\nrollouts up to 100 workers, but suffer from the degradation in the quality of\nthe solutions. MP-MCTS maintains the search quality at larger scale, and by\nrunning MP-MCTS on 256 CPU cores for only 10 minutes, we obtained candidate\nmolecules having similar score to non-parallel MCTS running for 42 hours.\nMoreover, our results based on parallel MCTS (combined with a simple RNN model)\nsignificantly outperforms existing state-of-the-art work. Our method is generic\nand is expected to speed up other applications of MCTS.\n", "versions": [{"version": "v1", "created": "Thu, 18 Jun 2020 13:23:40 GMT"}, {"version": "v2", "created": "Tue, 13 Oct 2020 09:12:04 GMT"}, {"version": "v3", "created": "Tue, 6 Apr 2021 06:33:09 GMT"}], "update_date": "2021-04-07", "authors_parsed": [["Yang", "Xiufeng", ""], ["Aasawat", "Tanuj Kr", ""], ["Yoshizoe", "Kazuki", ""]]}, {"id": "2006.10521", "submitter": "Song Gao", "authors": "Jinmeng Rao, Song Gao, Yuhao Kang, Qunying Huang", "title": "LSTM-TrajGAN: A Deep Learning Approach to Trajectory Privacy Protection", "comments": "16 pages, 7 figures, in the Proceedings of the 11th International\n  Conference on Geographic Information Science (GIScience 2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The prevalence of location-based services contributes to the explosive growth\nof individual-level trajectory data and raises public concerns about privacy\nissues. In this research, we propose a novel LSTM-TrajGAN approach, which is an\nend-to-end deep learning model to generate privacy-preserving synthetic\ntrajectory data for data sharing and publication. We design a loss metric\nfunction TrajLoss to measure the trajectory similarity losses for model\ntraining and optimization. The model is evaluated on the\ntrajectory-user-linking task on a real-world semantic trajectory dataset.\nCompared with other common geomasking methods, our model can better prevent\nusers from being re-identified, and it also preserves essential spatial,\ntemporal, and thematic characteristics of the real trajectory data. The model\nbetter balances the effectiveness of trajectory privacy protection and the\nutility for spatial and temporal analyses, which offers new insights into the\nGeoAI-powered privacy protection.\n", "versions": [{"version": "v1", "created": "Sun, 14 Jun 2020 03:04:19 GMT"}], "update_date": "2020-06-19", "authors_parsed": [["Rao", "Jinmeng", ""], ["Gao", "Song", ""], ["Kang", "Yuhao", ""], ["Huang", "Qunying", ""]]}, {"id": "2006.10523", "submitter": "Pavel Matrenin", "authors": "Vadim Manusov, Pavel Matrenin", "title": "Optimization of Fuzzy Controller of a Wind Power Plant Based on the\n  Swarm Intelligence", "comments": null, "journal-ref": "13th International Scientific-Technical Conference on Actual\n  Problems of Electronics Instrument Engineering (APEIE), Novosibirsk, 2016", "doi": "10.1109/APEIE.2016.7806936", "report-no": null, "categories": "eess.SY cs.AI cs.NE cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The article considers the problem of the optimal control of a wind power\nplant based on fuzzy control and automation of generating the fuzzy rule base.\nFuzzy rules by experts do not always provide a maximum power output of the wind\nplant and fuzzy rule bases require an adjustment in the case of changing the\nparameters of the wind power plant or the environment. This research proposes\nthe method for optimizing the fuzzy rules base compiled by various experts. The\nmethod is based on balancing weights of fuzzy rules into the base by the\nParticle Swarm Optimization algorithm. The experiment has shown that the\nproposed method allows forming the fuzzy rule base as an exemplary optimal base\nfrom a non-optimized set of fuzzy rules. The optimal fuzzy rule base has been\ntaken under consideration for the concrete control loop of wind power plant and\nthe concrete fuzzy model of the wind.\n", "versions": [{"version": "v1", "created": "Sun, 14 Jun 2020 05:20:56 GMT"}], "update_date": "2020-06-19", "authors_parsed": [["Manusov", "Vadim", ""], ["Matrenin", "Pavel", ""]]}, {"id": "2006.10524", "submitter": "Beren Millidge Mr", "authors": "Beren Millidge, Alexander Tschantz, Anil K Seth, Christopher L Buckley", "title": "Reinforcement Learning as Iterative and Amortised Inference", "comments": "initial upload; 05-07-20 -- updated with minor corrections", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There are several ways to categorise reinforcement learning (RL) algorithms,\nsuch as either model-based or model-free, policy-based or planning-based,\non-policy or off-policy, and online or offline. Broad classification schemes\nsuch as these help provide a unified perspective on disparate techniques and\ncan contextualise and guide the development of new algorithms. In this paper,\nwe utilise the control as inference framework to outline a novel classification\nscheme based on amortised and iterative inference. We demonstrate that a wide\nrange of algorithms can be classified in this manner providing a fresh\nperspective and highlighting a range of existing similarities. Moreover, we\nshow that taking this perspective allows us to identify parts of the\nalgorithmic design space which have been relatively unexplored, suggesting new\nroutes to innovative RL algorithms.\n", "versions": [{"version": "v1", "created": "Sat, 13 Jun 2020 16:10:03 GMT"}, {"version": "v2", "created": "Mon, 22 Jun 2020 12:58:19 GMT"}, {"version": "v3", "created": "Sun, 5 Jul 2020 18:37:20 GMT"}], "update_date": "2020-07-07", "authors_parsed": [["Millidge", "Beren", ""], ["Tschantz", "Alexander", ""], ["Seth", "Anil K", ""], ["Buckley", "Christopher L", ""]]}, {"id": "2006.10525", "submitter": "Islam Elnabarawy", "authors": "Islam Elnabarawy, Kristijana Arroyo, Donald C. Wunsch II", "title": "StarCraft II Build Order Optimization using Deep Reinforcement Learning\n  and Monte-Carlo Tree Search", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The real-time strategy game of StarCraft II has been posed as a challenge for\nreinforcement learning by Google's DeepMind. This study examines the use of an\nagent based on the Monte-Carlo Tree Search algorithm for optimizing the build\norder in StarCraft II, and discusses how its performance can be improved even\nfurther by combining it with a deep reinforcement learning neural network. The\nexperimental results accomplished using Monte-Carlo Tree Search achieves a\nscore similar to a novice human player by only using very limited time and\ncomputational resources, which paves the way to achieving scores comparable to\nthose of a human expert by combining it with the use of deep reinforcement\nlearning.\n", "versions": [{"version": "v1", "created": "Fri, 12 Jun 2020 08:53:52 GMT"}], "update_date": "2020-06-19", "authors_parsed": [["Elnabarawy", "Islam", ""], ["Arroyo", "Kristijana", ""], ["Wunsch", "Donald C.", "II"]]}, {"id": "2006.10532", "submitter": "Petr\\^onio Silva C. L.", "authors": "Petr\\^onio C. L. Silva, Paulo V. C. Batista, H\\'elder S. Lima, Marcos\n  A. Alves, Frederico G. Guimar\\~aes, Rodrigo C. P. Silva", "title": "COVID-ABS: An Agent-Based Model of COVID-19 Epidemic to Simulate Health\n  and Economic Effects of Social Distancing Interventions", "comments": "37 pages, 17 figures", "journal-ref": "Chaos, Solitons & Fractals (2020)", "doi": "10.1016/j.chaos.2020.110088", "report-no": null, "categories": "cs.AI physics.soc-ph", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  The COVID-19 pandemic due to the SARS-CoV-2 coronavirus has directly impacted\nthe public health and economy worldwide. To overcome this problem, countries\nhave adopted different policies and non-pharmaceutical interventions for\ncontrolling the spread of the virus. This paper proposes the COVID-ABS, a new\nSEIR (Susceptible-Exposed-Infected-Recovered) agent-based model that aims to\nsimulate the pandemic dynamics using a society of agents emulating people,\nbusiness and government. Seven different scenarios of social distancing\ninterventions were analyzed, with varying epidemiological and economic effects:\n(1) do nothing, (2) lockdown, (3) conditional lockdown, (4) vertical isolation,\n(5) partial isolation, (6) use of face masks, and (7) use of face masks\ntogether with 50% of adhesion to social isolation. In the impossibility of\nimplementing scenarios with lockdown, which present the lowest number of deaths\nand highest impact on the economy, scenarios combining the use of face masks\nand partial isolation can be the more realistic for implementation in terms of\nsocial cooperation. The COVID-ABS model was implemented in Python programming\nlanguage, with source code publicly available. The model can be easily extended\nto other societies by changing the input parameters, as well as allowing the\ncreation of a multitude of other scenarios. Therefore, it is a useful tool to\nassist politicians and health authorities to plan their actions against the\nCOVID-19 epidemic.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jun 2020 03:44:48 GMT"}, {"version": "v2", "created": "Wed, 8 Jul 2020 23:12:59 GMT"}], "update_date": "2020-07-10", "authors_parsed": [["Silva", "Petr\u00f4nio C. L.", ""], ["Batista", "Paulo V. C.", ""], ["Lima", "H\u00e9lder S.", ""], ["Alves", "Marcos A.", ""], ["Guimar\u00e3es", "Frederico G.", ""], ["Silva", "Rodrigo C. P.", ""]]}, {"id": "2006.10553", "submitter": "Elad Liebman", "authors": "Elad Liebman and Peter Stone", "title": "Artificial Musical Intelligence: A Survey", "comments": "99 pages, 5 figures, preprint: currently under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.AI cs.MM eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computers have been used to analyze and create music since they were first\nintroduced in the 1950s and 1960s. Beginning in the late 1990s, the rise of the\nInternet and large scale platforms for music recommendation and retrieval have\nmade music an increasingly prevalent domain of machine learning and artificial\nintelligence research. While still nascent, several different approaches have\nbeen employed to tackle what may broadly be referred to as \"musical\nintelligence.\" This article provides a definition of musical intelligence,\nintroduces a taxonomy of its constituent components, and surveys the wide range\nof AI methods that can be, and have been, brought to bear in its pursuit, with\na particular emphasis on machine learning methods.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jun 2020 04:46:32 GMT"}], "update_date": "2020-06-19", "authors_parsed": [["Liebman", "Elad", ""], ["Stone", "Peter", ""]]}, {"id": "2006.10564", "submitter": "Chirag Gupta", "authors": "Chirag Gupta, Aleksandr Podkopaev, Aaditya Ramdas", "title": "Distribution-free binary classification: prediction sets, confidence\n  intervals and calibration", "comments": "33 pages, 3 figures, appears as a spotlight at Neural Information\n  Processing Systems (NeurIPS) '20", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study three notions of uncertainty quantification -- calibration,\nconfidence intervals and prediction sets -- for binary classification in the\ndistribution-free setting, that is without making any distributional\nassumptions on the data. With a focus towards calibration, we establish a\n'tripod' of theorems that connect these three notions for score-based\nclassifiers. A direct implication is that distribution-free calibration is only\npossible, even asymptotically, using a scoring function whose level sets\npartition the feature space into at most countably many sets. Parametric\ncalibration schemes such as variants of Platt scaling do not satisfy this\nrequirement, while nonparametric schemes based on binning do. To close the\nloop, we derive distribution-free confidence intervals for binned probabilities\nfor both fixed-width and uniform-mass binning. As a consequence of our 'tripod'\ntheorems, these confidence intervals for binned probabilities lead to\ndistribution-free calibration. We also derive extensions to settings with\nstreaming data and covariate shift.\n", "versions": [{"version": "v1", "created": "Thu, 18 Jun 2020 14:17:29 GMT"}, {"version": "v2", "created": "Wed, 30 Sep 2020 12:46:59 GMT"}, {"version": "v3", "created": "Mon, 8 Mar 2021 03:11:51 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Gupta", "Chirag", ""], ["Podkopaev", "Aleksandr", ""], ["Ramdas", "Aaditya", ""]]}, {"id": "2006.10609", "submitter": "Lukas Ruff", "authors": "Jacob Kauffmann, Lukas Ruff, Gr\\'egoire Montavon, Klaus-Robert\n  M\\\"uller", "title": "The Clever Hans Effect in Anomaly Detection", "comments": "17 pages, preprint", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The 'Clever Hans' effect occurs when the learned model produces correct\npredictions based on the 'wrong' features. This effect which undermines the\ngeneralization capability of an ML model and goes undetected by standard\nvalidation techniques has been frequently observed for supervised learning\nwhere the training algorithm leverages spurious correlations in the data. The\nquestion whether Clever Hans also occurs in unsupervised learning, and in which\nform, has received so far almost no attention. Therefore, this paper will\ncontribute an explainable AI (XAI) procedure that can highlight the relevant\nfeatures used by popular anomaly detection models of different type. Our\nanalysis reveals that the Clever Hans effect is widespread in anomaly detection\nand occurs in many (unexpected) forms. Interestingly, the observed Clever Hans\neffects are in this case not so much due to the data, but due to the anomaly\ndetection models themselves whose structure makes them unable to detect the\ntruly relevant features, even though vast amounts of data points are available.\nOverall, our work contributes a warning against an unrestrained use of existing\nanomaly detection models in practical applications, but it also points at a\npossible way out of the Clever Hans dilemma, specifically, by allowing multiple\nanomaly models to mutually cancel their individual structural weaknesses to\njointly produce a better and more trustworthy anomaly detector.\n", "versions": [{"version": "v1", "created": "Thu, 18 Jun 2020 15:27:05 GMT"}], "update_date": "2020-06-19", "authors_parsed": [["Kauffmann", "Jacob", ""], ["Ruff", "Lukas", ""], ["Montavon", "Gr\u00e9goire", ""], ["M\u00fcller", "Klaus-Robert", ""]]}, {"id": "2006.10627", "submitter": "Qian Liu", "authors": "Qian Liu, Shengnan An, Jian-Guang Lou, Bei Chen, Zeqi Lin, Yan Gao,\n  Bin Zhou, Nanning Zheng, Dongmei Zhang", "title": "Compositional Generalization by Learning Analytical Expressions", "comments": "To appear in NeurIPS 2020 (Spotlight)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Compositional generalization is a basic and essential intellective capability\nof human beings, which allows us to recombine known parts readily. However,\nexisting neural network based models have been proven to be extremely deficient\nin such a capability. Inspired by work in cognition which argues\ncompositionality can be captured by variable slots with symbolic functions, we\npresent a refreshing view that connects a memory-augmented neural model with\nanalytical expressions, to achieve compositional generalization. Our model\nconsists of two cooperative neural modules, Composer and Solver, fitting well\nwith the cognitive argument while being able to be trained in an end-to-end\nmanner via a hierarchical reinforcement learning algorithm. Experiments on the\nwell-known benchmark SCAN demonstrate that our model seizes a great ability of\ncompositional generalization, solving all challenges addressed by previous\nworks with 100% accuracies.\n", "versions": [{"version": "v1", "created": "Thu, 18 Jun 2020 15:50:57 GMT"}, {"version": "v2", "created": "Sat, 24 Oct 2020 03:47:49 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Liu", "Qian", ""], ["An", "Shengnan", ""], ["Lou", "Jian-Guang", ""], ["Chen", "Bei", ""], ["Lin", "Zeqi", ""], ["Gao", "Yan", ""], ["Zhou", "Bin", ""], ["Zheng", "Nanning", ""], ["Zhang", "Dongmei", ""]]}, {"id": "2006.10632", "submitter": "Yatin Chaudhary", "authors": "Yatin Chaudhary, Hinrich Sch\\\"utze, Pankaj Gupta", "title": "Explainable and Discourse Topic-aware Neural Language Understanding", "comments": "Accepted at ICML2020 (13 pages, 2 figures), acknowledgements added", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Marrying topic models and language models exposes language understanding to a\nbroader source of document-level context beyond sentences via topics. While\nintroducing topical semantics in language models, existing approaches\nincorporate latent document topic proportions and ignore topical discourse in\nsentences of the document. This work extends the line of research by\nadditionally introducing an explainable topic representation in language\nunderstanding, obtained from a set of key terms correspondingly for each latent\ntopic of the proportion. Moreover, we retain sentence-topic associations along\nwith document-topic association by modeling topical discourse for every\nsentence in the document. We present a novel neural composite language model\nthat exploits both the latent and explainable topics along with topical\ndiscourse at sentence-level in a joint learning framework of topic and language\nmodels. Experiments over a range of tasks such as language modeling, word sense\ndisambiguation, document classification, retrieval and text generation\ndemonstrate ability of the proposed model in improving language understanding.\n", "versions": [{"version": "v1", "created": "Thu, 18 Jun 2020 15:53:58 GMT"}, {"version": "v2", "created": "Fri, 19 Jun 2020 08:50:24 GMT"}], "update_date": "2020-06-22", "authors_parsed": [["Chaudhary", "Yatin", ""], ["Sch\u00fctze", "Hinrich", ""], ["Gupta", "Pankaj", ""]]}, {"id": "2006.10701", "submitter": "Annie Xie", "authors": "Annie Xie, James Harrison, Chelsea Finn", "title": "Deep Reinforcement Learning amidst Lifelong Non-Stationarity", "comments": "supplementary website at https://sites.google.com/stanford.edu/lilac/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As humans, our goals and our environment are persistently changing throughout\nour lifetime based on our experiences, actions, and internal and external\ndrives. In contrast, typical reinforcement learning problem set-ups consider\ndecision processes that are stationary across episodes. Can we develop\nreinforcement learning algorithms that can cope with the persistent change in\nthe former, more realistic problem settings? While on-policy algorithms such as\npolicy gradients in principle can be extended to non-stationary settings, the\nsame cannot be said for more efficient off-policy algorithms that replay past\nexperiences when learning. In this work, we formalize this problem setting, and\ndraw upon ideas from the online learning and probabilistic inference literature\nto derive an off-policy RL algorithm that can reason about and tackle such\nlifelong non-stationarity. Our method leverages latent variable models to learn\na representation of the environment from current and past experiences, and\nperforms off-policy RL with this representation. We further introduce several\nsimulation environments that exhibit lifelong non-stationarity, and empirically\nfind that our approach substantially outperforms approaches that do not reason\nabout environment shift.\n", "versions": [{"version": "v1", "created": "Thu, 18 Jun 2020 17:34:50 GMT"}], "update_date": "2020-06-19", "authors_parsed": [["Xie", "Annie", ""], ["Harrison", "James", ""], ["Finn", "Chelsea", ""]]}, {"id": "2006.10720", "submitter": "Hossein Hajipour", "authors": "Hossein Hajipour, Mateusz Malinowski, Mario Fritz", "title": "IReEn: Iterative Reverse-Engineering of Black-Box Functions via Neural\n  Program Synthesis", "comments": "14 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.PL cs.SE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we investigate the problem of revealing the functionality of a\nblack-box agent. Notably, we are interested in the interpretable and formal\ndescription of the behavior of such an agent. Ideally, this description would\ntake the form of a program written in a high-level language. This task is also\nknown as reverse engineering and plays a pivotal role in software engineering,\ncomputer security, but also most recently in interpretability. In contrast to\nprior work, we do not rely on privileged information on the black box, but\nrather investigate the problem under a weaker assumption of having only access\nto inputs and outputs of the program. We approach this problem by iteratively\nrefining a candidate set using a generative neural program synthesis approach\nuntil we arrive at a functionally equivalent program. We assess the performance\nof our approach on the Karel dataset. Our results show that the proposed\napproach outperforms the state-of-the-art on this challenge by finding a\nfunctional equivalent program in 78% of cases -- even exceeding prior work that\nhad privileged information on the black-box.\n", "versions": [{"version": "v1", "created": "Thu, 18 Jun 2020 17:50:48 GMT"}], "update_date": "2020-06-19", "authors_parsed": [["Hajipour", "Hossein", ""], ["Malinowski", "Mateusz", ""], ["Fritz", "Mario", ""]]}, {"id": "2006.10734", "submitter": "Rohit Girdhar", "authors": "Rohit Girdhar, Laura Gustafson, Aaron Adcock and Laurens van der\n  Maaten", "title": "Forward Prediction for Physical Reasoning", "comments": "Webpage/code/models: https://facebookresearch.github.io/phyre-fwd/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Physical reasoning requires forward prediction: the ability to forecast what\nwill happen next given some initial world state. We study the performance of\nstate-of-the-art forward-prediction models in the complex physical-reasoning\ntasks of the PHYRE benchmark. We do so by incorporating models that operate on\nobject or pixel-based representations of the world into simple\nphysical-reasoning agents. We find that forward-prediction models can improve\nphysical-reasoning performance, particularly on complex tasks that involve many\nobjects. However, we also find that these improvements are contingent on the\ntest tasks being small variations of train tasks, and that generalization to\ncompletely new task templates is challenging. Surprisingly, we observe that\nforward predictors with better pixel accuracy do not necessarily lead to better\nphysical-reasoning performance.Nevertheless, our best models set a new\nstate-of-the-art on the PHYRE benchmark.\n", "versions": [{"version": "v1", "created": "Thu, 18 Jun 2020 17:57:42 GMT"}, {"version": "v2", "created": "Mon, 29 Mar 2021 19:41:24 GMT"}], "update_date": "2021-03-31", "authors_parsed": [["Girdhar", "Rohit", ""], ["Gustafson", "Laura", ""], ["Adcock", "Aaron", ""], ["van der Maaten", "Laurens", ""]]}, {"id": "2006.10742", "submitter": "Amy Zhang", "authors": "Amy Zhang, Rowan McAllister, Roberto Calandra, Yarin Gal, Sergey\n  Levine", "title": "Learning Invariant Representations for Reinforcement Learning without\n  Reconstruction", "comments": "Accepted as an oral at ICLR 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study how representation learning can accelerate reinforcement learning\nfrom rich observations, such as images, without relying either on domain\nknowledge or pixel-reconstruction. Our goal is to learn representations that\nboth provide for effective downstream control and invariance to task-irrelevant\ndetails. Bisimulation metrics quantify behavioral similarity between states in\ncontinuous MDPs, which we propose using to learn robust latent representations\nwhich encode only the task-relevant information from observations. Our method\ntrains encoders such that distances in latent space equal bisimulation\ndistances in state space. We demonstrate the effectiveness of our method at\ndisregarding task-irrelevant information using modified visual MuJoCo tasks,\nwhere the background is replaced with moving distractors and natural videos,\nwhile achieving SOTA performance. We also test a first-person highway driving\ntask where our method learns invariance to clouds, weather, and time of day.\nFinally, we provide generalization results drawn from properties of\nbisimulation metrics, and links to causal inference.\n", "versions": [{"version": "v1", "created": "Thu, 18 Jun 2020 17:59:35 GMT"}, {"version": "v2", "created": "Wed, 7 Apr 2021 01:57:14 GMT"}], "update_date": "2021-04-08", "authors_parsed": [["Zhang", "Amy", ""], ["McAllister", "Rowan", ""], ["Calandra", "Roberto", ""], ["Gal", "Yarin", ""], ["Levine", "Sergey", ""]]}, {"id": "2006.10782", "submitter": "Max Tegmark", "authors": "Silviu-Marian Udrescu, Andrew Tan, Jiahai Feng, Orisvaldo Neto, Tailin\n  Wu, Max Tegmark", "title": "AI Feynman 2.0: Pareto-optimal symbolic regression exploiting graph\n  modularity", "comments": "17 pages, 6 figs, replaced to match accepted NeurIPS version", "journal-ref": "34th Conference on Neural Information Processing Systems (Neurips\n  2020), Vancouver, Canada", "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.IT math.IT physics.comp-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an improved method for symbolic regression that seeks to fit data\nto formulas that are Pareto-optimal, in the sense of having the best accuracy\nfor a given complexity. It improves on the previous state-of-the-art by\ntypically being orders of magnitude more robust toward noise and bad data, and\nalso by discovering many formulas that stumped previous methods. We develop a\nmethod for discovering generalized symmetries (arbitrary modularity in the\ncomputational graph of a formula) from gradient properties of a neural network\nfit. We use normalizing flows to generalize our symbolic regression method to\nprobability distributions from which we only have samples, and employ\nstatistical hypothesis testing to accelerate robust brute-force search.\n", "versions": [{"version": "v1", "created": "Thu, 18 Jun 2020 18:01:19 GMT"}, {"version": "v2", "created": "Wed, 16 Dec 2020 17:58:47 GMT"}], "update_date": "2020-12-17", "authors_parsed": [["Udrescu", "Silviu-Marian", ""], ["Tan", "Andrew", ""], ["Feng", "Jiahai", ""], ["Neto", "Orisvaldo", ""], ["Wu", "Tailin", ""], ["Tegmark", "Max", ""]]}, {"id": "2006.10807", "submitter": "Zhen Zeng", "authors": "Zhen Zeng, Adrian R\\\"ofer, Odest Chadwicke Jenkins", "title": "Semantic Linking Maps for Active Visual Object Search", "comments": "Published in ICRA 2020 (Best Paper Award in Cognitive Robotics)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We aim for mobile robots to function in a variety of common human\nenvironments. Such robots need to be able to reason about the locations of\npreviously unseen target objects. Landmark objects can help this reasoning by\nnarrowing down the search space significantly. More specifically, we can\nexploit background knowledge about common spatial relations between landmark\nand target objects. For example, seeing a table and knowing that cups can often\nbe found on tables aids the discovery of a cup. Such correlations can be\nexpressed as distributions over possible pairing relationships of objects. In\nthis paper, we propose an active visual object search strategy method through\nour introduction of the Semantic Linking Maps (SLiM) model. SLiM simultaneously\nmaintains the belief over a target object's location as well as landmark\nobjects' locations, while accounting for probabilistic inter-object spatial\nrelations. Based on SLiM, we describe a hybrid search strategy that selects the\nnext best view pose for searching for the target object based on the maintained\nbelief. We demonstrate the efficiency of our SLiM-based search strategy through\ncomparative experiments in simulated environments. We further demonstrate the\nreal-world applicability of SLiM-based search in scenarios with a Fetch mobile\nmanipulation robot.\n", "versions": [{"version": "v1", "created": "Thu, 18 Jun 2020 18:59:44 GMT"}], "update_date": "2020-06-22", "authors_parsed": [["Zeng", "Zhen", ""], ["R\u00f6fer", "Adrian", ""], ["Jenkins", "Odest Chadwicke", ""]]}, {"id": "2006.10822", "submitter": "Yan Zhang", "authors": "Yan Zhang, Michael M. Zavlanos", "title": "Cooperative Multi-Agent Reinforcement Learning with Partial Observations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a distributed zeroth-order policy optimization\nmethod for Multi-Agent Reinforcement Learning (MARL). Existing MARL algorithms\noften assume that every agent can observe the states and actions of all the\nother agents in the network. This can be impractical in large-scale problems,\nwhere sharing the state and action information with multi-hop neighbors may\nincur significant communication overhead. The advantage of the proposed\nzeroth-order policy optimization method is that it allows the agents to compute\nthe local policy gradients needed to update their local policy functions using\nlocal estimates of the global accumulated rewards that depend on partial state\nand action information only and can be obtained using consensus. Specifically,\nto calculate the local policy gradients, we develop a new distributed\nzeroth-order policy gradient estimator that relies on one-point\nresidual-feedback which, compared to existing zeroth-order estimators that also\nrely on one-point feedback, significantly reduces the variance of the policy\ngradient estimates improving, in this way, the learning performance. We show\nthat the proposed distributed zeroth-order policy optimization method with\nconstant stepsize converges to a neighborhood of the global optimal policy that\ndepends on the number of consensus steps used to calculate the local estimates\nof the global accumulated rewards. Moreover, we provide numerical experiments\nthat demonstrate that our new zeroth-order policy gradient estimator is more\nsample-efficient compared to other existing one-point estimators.\n", "versions": [{"version": "v1", "created": "Thu, 18 Jun 2020 19:36:22 GMT"}], "update_date": "2020-06-22", "authors_parsed": [["Zhang", "Yan", ""], ["Zavlanos", "Michael M.", ""]]}, {"id": "2006.10836", "submitter": "Tao Meng", "authors": "Tao Meng and Kai-Wei Chang", "title": "An Integer Linear Programming Framework for Mining Constraints from Data", "comments": "13 pages, published in ICML2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Structured output prediction problems (e.g., sequential tagging, hierarchical\nmulti-class classification) often involve constraints over the output label\nspace. These constraints interact with the learned models to filter infeasible\nsolutions and facilitate in building an accountable system. However, although\nconstraints are useful, they are often based on hand-crafted rules. This raises\na question -- \\emph{can we mine constraints and rules from data based on a\nlearning algorithm?}\n  In this paper, we present a general framework for mining constraints from\ndata. In particular, we consider the inference in structured output prediction\nas an integer linear programming (ILP) problem. Then, given the coefficients of\nthe objective function and the corresponding solution, we mine the underlying\nconstraints by estimating the outer and inner polytopes of the feasible set. We\nverify the proposed constraint mining algorithm in various synthetic and\nreal-world applications and demonstrate that the proposed approach successfully\nidentifies the feasible set at scale.\n  In particular, we show that our approach can learn to solve 9x9 Sudoku\npuzzles and minimal spanning tree problems from examples without providing the\nunderlying rules. Our algorithm can also integrate with a neural network model\nto learn the hierarchical label structure of a multi-label classification task.\nBesides, we provide a theoretical analysis about the tightness of the polytopes\nand the reliability of the mined constraints.\n", "versions": [{"version": "v1", "created": "Thu, 18 Jun 2020 20:09:53 GMT"}, {"version": "v2", "created": "Fri, 11 Jun 2021 04:34:33 GMT"}], "update_date": "2021-06-14", "authors_parsed": [["Meng", "Tao", ""], ["Chang", "Kai-Wei", ""]]}, {"id": "2006.10898", "submitter": "Suchithra Rajendran", "authors": "Suchithra Rajendran, Emily Pagel", "title": "Recommendations for Emerging Air Taxi Network Operations based on Online\n  Review Analysis of Helicopter Services", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The effects of traffic congestion are adverse, primarily including air\npollution, commuter stress, and an increase in vehicle operating costs and\naccidents on the road. In efforts to alleviate these problems in metropolitan\ncities, logistics companies plan to introduce a new method of everyday commute\ncalled air taxis, an Urban Air Mobility (UAM) service. These are\nelectric-powered vehicles that are expected to operate in the forthcoming years\nby international transportation companies like Airbus, Uber, and Kitty Hawk.\nSince these flying taxis are emerging mode of transportation, it is necessary\nto provide recommendations for the initial design, implementation, and\noperation. This study proposes managerial insights for these upcoming services\nby analyzing online customer reviews and conducting an internal assessment of\nhelicopter operations. Helicopters are similar to air taxis in regards to their\noperations, and therefore, customer reviews pertaining to the former can enable\nus to obtain insights into the strengths and weaknesses of the short-distance\naviation service, in general. A four-stage sequential approach is used in this\nresearch, wherein the online reviews are mined in Stage 1, analyzed using the\nbigram and trigram models in Stage 2, 7S internal assessment is conducted for\nhelicopter services in Stage 3, and managerial recommendations for air taxis\nare proposed in Stage 4. The insights obtained in this paper could assist any\nair taxi companies in providing better customer service when they venture into\nthe market.\n  Keywords: Air taxi; Emerging technology; Urban Air Mobility (UAM); Helicopter\nservices; Online customer reviews; Text analytics;\n", "versions": [{"version": "v1", "created": "Thu, 18 Jun 2020 23:44:49 GMT"}], "update_date": "2020-06-22", "authors_parsed": [["Rajendran", "Suchithra", ""], ["Pagel", "Emily", ""]]}, {"id": "2006.10904", "submitter": "Harshal Chaudhari", "authors": "Harshal A. Chaudhari, John W. Byers and Evimaria Terzi", "title": "Learn to Earn: Enabling Coordination within a Ride Hailing Fleet", "comments": "16 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of optimizing social welfare objectives on multi sided ride\nhailing platforms such as Uber, Lyft, etc., is challenging, due to misalignment\nof objectives between drivers, passengers, and the platform itself. An ideal\nsolution aims to minimize the response time for each hyper local passenger ride\nrequest, while simultaneously maintaining high demand satisfaction and supply\nutilization across the entire city. Economists tend to rely on dynamic pricing\nmechanisms that stifle price sensitive excess demand and resolve the supply\ndemand imbalances emerging in specific neighborhoods. In contrast, computer\nscientists primarily view it as a demand prediction problem with the goal of\npreemptively repositioning supply to such neighborhoods using black box\ncoordinated multi agent deep reinforcement learning based approaches. Here, we\nintroduce explainability in the existing supply repositioning approaches by\nestablishing the need for coordination between the drivers at specific\nlocations and times. Explicit need based coordination allows our framework to\nuse a simpler non deep reinforcement learning based approach, thereby enabling\nit to explain its recommendations ex post. Moreover, it provides envy free\nrecommendations i.e., drivers at the same location and time do not envy one\nanother's future earnings. Our experimental evaluation demonstrates the\neffectiveness, the robustness, and the generalizability of our framework.\nFinally, in contrast to previous works, we make available a reinforcement\nlearning environment for end to end reproducibility of our work and to\nencourage future comparative studies.\n", "versions": [{"version": "v1", "created": "Fri, 19 Jun 2020 00:20:15 GMT"}, {"version": "v2", "created": "Thu, 16 Jul 2020 17:07:58 GMT"}], "update_date": "2020-07-17", "authors_parsed": [["Chaudhari", "Harshal A.", ""], ["Byers", "John W.", ""], ["Terzi", "Evimaria", ""]]}, {"id": "2006.10916", "submitter": "Seyed Abdulaziz Esmaeili", "authors": "Seyed A. Esmaeili, Brian Brubach, Leonidas Tsepenekas, John P.\n  Dickerson", "title": "Probabilistic Fair Clustering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In clustering problems, a central decision-maker is given a complete metric\ngraph over vertices and must provide a clustering of vertices that minimizes\nsome objective function. In fair clustering problems, vertices are endowed with\na color (e.g., membership in a group), and the features of a valid clustering\nmight also include the representation of colors in that clustering. Prior work\nin fair clustering assumes complete knowledge of group membership. In this\npaper, we generalize prior work by assuming imperfect knowledge of group\nmembership through probabilistic assignments. We present clustering algorithms\nin this more general setting with approximation ratio guarantees. We also\naddress the problem of \"metric membership\", where different groups have a\nnotion of order and distance. Experiments are conducted using our proposed\nalgorithms as well as baselines to validate our approach and also surface\nnuanced concerns when group membership is not known deterministically.\n", "versions": [{"version": "v1", "created": "Fri, 19 Jun 2020 01:34:21 GMT"}], "update_date": "2020-06-22", "authors_parsed": [["Esmaeili", "Seyed A.", ""], ["Brubach", "Brian", ""], ["Tsepenekas", "Leonidas", ""], ["Dickerson", "John P.", ""]]}, {"id": "2006.10935", "submitter": "Pavel Matrenin", "authors": "Pavel Matrenin, Viktor Sekaev", "title": "Particle Swarm Optimization with Velocity Restriction and Evolutionary\n  Parameters Selection for Scheduling Problem", "comments": null, "journal-ref": "2015 International Siberian Conference on Control and\n  Communications (SIBCON), 21-23 May 2015, Omsk, Russia", "doi": "10.1109/SIBCON.2015.7147143", "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The article presents a study of the Particle Swarm optimization method for\nscheduling problem. To improve the method's performance a restriction of\nparticles' velocity and an evolutionary meta-optimization were realized. The\napproach proposed uses the Genetic algorithms for selection of the parameters\nof Particle Swarm optimization. Experiments were carried out on test tasks of\nthe job-shop scheduling problem. This research proves the applicability of the\napproach and shows the importance of tuning the behavioral parameters of the\nswarm intelligence methods to achieve a high performance.\n", "versions": [{"version": "v1", "created": "Fri, 19 Jun 2020 02:28:57 GMT"}], "update_date": "2020-06-22", "authors_parsed": [["Matrenin", "Pavel", ""], ["Sekaev", "Viktor", ""]]}, {"id": "2006.10938", "submitter": "Pavel Matrenin", "authors": "Pavel Matrenin, Vadim Manusov", "title": "The cyclic job-shop scheduling problem: The new subclass of the job-shop\n  problem and applying the Simulated annealing to solve it", "comments": null, "journal-ref": "2016 2nd International Conference on Industrial Engineering,\n  Applications and Manufacturing (ICIEAM), 19-20 May 2016, Chelyabinsk, Russia", "doi": "10.1109/ICIEAM.2016.7911676", "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the paper, the new approach to the scheduling problem are described. The\napproach deals with the problem of planning the cyclic production and proposes\nto consider such scheduling problem as the cyclic job-shop problem of the order\nk, where k is the number of reiterations. It was found out that planning of\nonly one iteration of the loop is less effective than planning of the entire\ncycle. To the experimental research, a number of test instances of the job-shop\nscheduling problem by Operation Research Library were used. The Simulated\nAnnealing was applied to solve the instances. The experiments proved that the\napproach proposed allows increasing the efficiency of cyclic scheduling\nsignificantly.\n", "versions": [{"version": "v1", "created": "Fri, 19 Jun 2020 02:36:29 GMT"}], "update_date": "2020-06-22", "authors_parsed": [["Matrenin", "Pavel", ""], ["Manusov", "Vadim", ""]]}, {"id": "2006.10964", "submitter": "Yanshan Wang", "authors": "David Oniani, Yanshan Wang", "title": "A Qualitative Evaluation of Language Models on Automatic\n  Question-Answering for COVID-19", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  COVID-19 has resulted in an ongoing pandemic and as of 12 June 2020, has\ncaused more than 7.4 million cases and over 418,000 deaths. The highly dynamic\nand rapidly evolving situation with COVID-19 has made it difficult to access\naccurate, on-demand information regarding the disease. Online communities,\nforums, and social media provide potential venues to search for relevant\nquestions and answers, or post questions and seek answers from other members.\nHowever, due to the nature of such sites, there are always a limited number of\nrelevant questions and responses to search from, and posted questions are\nrarely answered immediately. With the advancements in the field of natural\nlanguage processing, particularly in the domain of language models, it has\nbecome possible to design chatbots that can automatically answer consumer\nquestions. However, such models are rarely applied and evaluated in the\nhealthcare domain, to meet the information needs with accurate and up-to-date\nhealthcare data. In this paper, we propose to apply a language model for\nautomatically answering questions related to COVID-19 and qualitatively\nevaluate the generated responses. We utilized the GPT-2 language model and\napplied transfer learning to retrain it on the COVID-19 Open Research Dataset\n(CORD-19) corpus. In order to improve the quality of the generated responses,\nwe applied 4 different approaches, namely tf-idf, BERT, BioBERT, and USE to\nfilter and retain relevant sentences in the responses. In the performance\nevaluation step, we asked two medical experts to rate the responses. We found\nthat BERT and BioBERT, on average, outperform both tf-idf and USE in\nrelevance-based sentence filtering tasks. Additionally, based on the chatbot,\nwe created a user-friendly interactive web application to be hosted online.\n", "versions": [{"version": "v1", "created": "Fri, 19 Jun 2020 05:13:57 GMT"}, {"version": "v2", "created": "Tue, 23 Jun 2020 20:23:04 GMT"}], "update_date": "2020-06-25", "authors_parsed": [["Oniani", "David", ""], ["Wang", "Yanshan", ""]]}, {"id": "2006.10980", "submitter": "Shuai Han", "authors": "Shuai Han and Wenbo Zhou and Jing Liu and Shuai L\\\"u", "title": "NROWAN-DQN: A Stable Noisy Network with Noise Reduction and Online\n  Weight Adjustment for Exploration", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep reinforcement learning has been applied more and more widely nowadays,\nespecially in various complex control tasks. Effective exploration for noisy\nnetworks is one of the most important issues in deep reinforcement learning.\nNoisy networks tend to produce stable outputs for agents. However, this\ntendency is not always enough to find a stable policy for an agent, which\ndecreases efficiency and stability during the learning process. Based on\nNoisyNets, this paper proposes an algorithm called NROWAN-DQN, i.e., Noise\nReduction and Online Weight Adjustment NoisyNet-DQN. Firstly, we develop a\nnovel noise reduction method for NoisyNet-DQN to make the agent perform stable\nactions. Secondly, we design an online weight adjustment strategy for noise\nreduction, which improves stable performance and gets higher scores for the\nagent. Finally, we evaluate this algorithm in four standard domains and analyze\nproperties of hyper-parameters. Our results show that NROWAN-DQN outperforms\nprior algorithms in all these domains. In addition, NROWAN-DQN also shows\nbetter stability. The variance of the NROWAN-DQN score is significantly\nreduced, especially in some action-sensitive environments. This means that in\nsome environments where high stability is required, NROWAN-DQN will be more\nappropriate than NoisyNets-DQN.\n", "versions": [{"version": "v1", "created": "Fri, 19 Jun 2020 07:10:42 GMT"}], "update_date": "2020-06-22", "authors_parsed": [["Han", "Shuai", ""], ["Zhou", "Wenbo", ""], ["Liu", "Jing", ""], ["L\u00fc", "Shuai", ""]]}, {"id": "2006.11020", "submitter": "Bruno Yun", "authors": "Bruno Yun, Srdjan Vesic and Nir Oren", "title": "Representing Pure Nash Equilibria in Argumentation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we describe an argumentation-based representation of normal\nform games, and demonstrate how argumentation can be used to compute pure\nstrategy Nash equilibria. Our approach builds on Modgil's Extended\nArgumentation Frameworks. We demonstrate its correctness, prove several\ntheoretical properties it satisfies, and outline how it can be used to explain\nwhy certain strategies are Nash equilibria to a non-expert human user.\n", "versions": [{"version": "v1", "created": "Fri, 19 Jun 2020 08:53:35 GMT"}], "update_date": "2020-06-22", "authors_parsed": [["Yun", "Bruno", ""], ["Vesic", "Srdjan", ""], ["Oren", "Nir", ""]]}, {"id": "2006.11029", "submitter": "Andreas Venzke", "authors": "Andreas Venzke, Guannan Qu, Steven Low, Spyros Chatzivasileiadis", "title": "Learning Optimal Power Flow: Worst-Case Guarantees for Neural Networks", "comments": "The code to reproduce the simulation results is available\n  https://doi.org/10.5281/zenodo.3871755", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.SY eess.SY math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces for the first time a framework to obtain provable\nworst-case guarantees for neural network performance, using learning for\noptimal power flow (OPF) problems as a guiding example. Neural networks have\nthe potential to substantially reduce the computing time of OPF solutions.\nHowever, the lack of guarantees for their worst-case performance remains a\nmajor barrier for their adoption in practice. This work aims to remove this\nbarrier. We formulate mixed-integer linear programs to obtain worst-case\nguarantees for neural network predictions related to (i) maximum constraint\nviolations, (ii) maximum distances between predicted and optimal decision\nvariables, and (iii) maximum sub-optimality. We demonstrate our methods on a\nrange of PGLib-OPF networks up to 300 buses. We show that the worst-case\nguarantees can be up to one order of magnitude larger than the empirical lower\nbounds calculated with conventional methods. More importantly, we show that the\nworst-case predictions appear at the boundaries of the training input domain,\nand we demonstrate how we can systematically reduce the worst-case guarantees\nby training on a larger input domain than the domain they are evaluated on.\n", "versions": [{"version": "v1", "created": "Fri, 19 Jun 2020 09:19:14 GMT"}], "update_date": "2020-06-22", "authors_parsed": [["Venzke", "Andreas", ""], ["Qu", "Guannan", ""], ["Low", "Steven", ""], ["Chatzivasileiadis", "Spyros", ""]]}, {"id": "2006.11035", "submitter": "Stefano Melacci", "authors": "Lapo Faggi, Alessandro Betti, Dario Zanca, Stefano Melacci, Marco Gori", "title": "Wave Propagation of Visual Stimuli in Focus of Attention", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fast reactions to changes in the surrounding visual environment require\nefficient attention mechanisms to reallocate computational resources to most\nrelevant locations in the visual field. While current computational models keep\nimproving their predictive ability thanks to the increasing availability of\ndata, they still struggle approximating the effectiveness and efficiency\nexhibited by foveated animals. In this paper, we present a\nbiologically-plausible computational model of focus of attention that exhibits\nspatiotemporal locality and that is very well-suited for parallel and\ndistributed implementations. Attention emerges as a wave propagation process\noriginated by visual stimuli corresponding to details and motion information.\nThe resulting field obeys the principle of \"inhibition of return\" so as not to\nget stuck in potential holes. An accurate experimentation of the model shows\nthat it achieves top level performance in scanpath prediction tasks. This can\neasily be understood at the light of a theoretical result that we establish in\nthe paper, where we prove that as the velocity of wave propagation goes to\ninfinity, the proposed model reduces to recently proposed state of the art\ngravitational models of focus of attention.\n", "versions": [{"version": "v1", "created": "Fri, 19 Jun 2020 09:33:21 GMT"}], "update_date": "2020-06-22", "authors_parsed": [["Faggi", "Lapo", ""], ["Betti", "Alessandro", ""], ["Zanca", "Dario", ""], ["Melacci", "Stefano", ""], ["Gori", "Marco", ""]]}, {"id": "2006.11097", "submitter": "Antonis Bikakis Dr.", "authors": "Antonis Bikakis, Patrice Caire", "title": "Contextual and Possibilistic Reasoning for Coalition Formation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In multiagent systems, agents often have to rely on other agents to reach\ntheir goals, for example when they lack a needed resource or do not have the\ncapability to perform a required action. Agents therefore need to cooperate.\nThen, some of the questions raised are: Which agent(s) to cooperate with? What\nare the potential coalitions in which agents can achieve their goals? As the\nnumber of possibilities is potentially quite large, how to automate the\nprocess? And then, how to select the most appropriate coalition, taking into\naccount the uncertainty in the agents' abilities to carry out certain tasks? In\nthis article, we address the question of how to find and evaluate coalitions\namong agents in multiagent systems using MCS tools, while taking into\nconsideration the uncertainty around the agents' actions. Our methodology is\nthe following: We first compute the solution space for the formation of\ncoalitions using a contextual reasoning approach. Second, we model agents as\ncontexts in Multi-Context Systems (MCS), and dependence relations among agents\nseeking to achieve their goals, as bridge rules. Third, we systematically\ncompute all potential coalitions using algorithms for MCS equilibria, and given\na set of functional and non-functional requirements, we propose ways to select\nthe best solutions. Finally, in order to handle the uncertainty in the agents'\nactions, we extend our approach with features of possibilistic reasoning. We\nillustrate our approach with an example from robotics.\n", "versions": [{"version": "v1", "created": "Fri, 19 Jun 2020 11:59:55 GMT"}, {"version": "v2", "created": "Tue, 6 Oct 2020 18:45:37 GMT"}], "update_date": "2020-10-08", "authors_parsed": [["Bikakis", "Antonis", ""], ["Caire", "Patrice", ""]]}, {"id": "2006.11152", "submitter": "Paolo Liberatore", "authors": "Paolo Liberatore", "title": "Common equivalence and size after forgetting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Forgetting variables from a propositional formula may increase its size.\nIntroducing new variables is a way to shorten it. Both operations can be\nexpressed in terms of common equivalence, a weakened version of equivalence. In\nturn, common equivalence can be expressed in terms of forgetting. An algorithm\nfor forgetting and checking common equivalence in polynomial space is given for\nthe Horn case; it is polynomial-time for the subclass of single-head formulae.\nMinimizing after forgetting is polynomial-time if the formula is also acyclic\nand variables cannot be introduced, NP-hard when they can.\n", "versions": [{"version": "v1", "created": "Fri, 19 Jun 2020 14:27:51 GMT"}, {"version": "v2", "created": "Thu, 6 May 2021 12:07:40 GMT"}], "update_date": "2021-05-07", "authors_parsed": [["Liberatore", "Paolo", ""]]}, {"id": "2006.11161", "submitter": "Aman Chadha Mr.", "authors": "Aman Chadha, John Britto, and M. Mani Roja", "title": "iSeeBetter: Spatio-temporal video super-resolution using recurrent\n  generative back-projection networks", "comments": "11 pages, 6 figures, 4 tables, Project Page:\n  https://iseebetter.amanchadha.com/", "journal-ref": "Springer Journal of Computational Visual Media, Tsinghua\n  University Press, 6(3):307-317, 2020", "doi": "10.1007/s41095-020-0175-7", "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.MM eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, learning-based models have enhanced the performance of single-image\nsuper-resolution (SISR). However, applying SISR successively to each video\nframe leads to a lack of temporal coherency. Convolutional neural networks\n(CNNs) outperform traditional approaches in terms of image quality metrics such\nas peak signal to noise ratio (PSNR) and structural similarity (SSIM). However,\ngenerative adversarial networks (GANs) offer a competitive advantage by being\nable to mitigate the issue of a lack of finer texture details, usually seen\nwith CNNs when super-resolving at large upscaling factors. We present\niSeeBetter, a novel GAN-based spatio-temporal approach to video\nsuper-resolution (VSR) that renders temporally consistent super-resolution\nvideos. iSeeBetter extracts spatial and temporal information from the current\nand neighboring frames using the concept of recurrent back-projection networks\nas its generator. Furthermore, to improve the \"naturality\" of the\nsuper-resolved image while eliminating artifacts seen with traditional\nalgorithms, we utilize the discriminator from super-resolution generative\nadversarial network (SRGAN). Although mean squared error (MSE) as a primary\nloss-minimization objective improves PSNR/SSIM, these metrics may not capture\nfine details in the image resulting in misrepresentation of perceptual quality.\nTo address this, we use a four-fold (MSE, perceptual, adversarial, and\ntotal-variation (TV)) loss function. Our results demonstrate that iSeeBetter\noffers superior VSR fidelity and surpasses state-of-the-art performance.\n", "versions": [{"version": "v1", "created": "Sat, 13 Jun 2020 01:36:30 GMT"}, {"version": "v2", "created": "Mon, 22 Jun 2020 20:34:00 GMT"}, {"version": "v3", "created": "Sat, 29 Aug 2020 21:38:05 GMT"}, {"version": "v4", "created": "Wed, 30 Sep 2020 00:45:38 GMT"}], "update_date": "2020-10-01", "authors_parsed": [["Chadha", "Aman", ""], ["Britto", "John", ""], ["Roja", "M. Mani", ""]]}, {"id": "2006.11266", "submitter": "Dibya Ghosh", "authors": "Dibya Ghosh, Marlos C. Machado, Nicolas Le Roux", "title": "An operator view of policy gradient methods", "comments": "NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We cast policy gradient methods as the repeated application of two operators:\na policy improvement operator $\\mathcal{I}$, which maps any policy $\\pi$ to a\nbetter one $\\mathcal{I}\\pi$, and a projection operator $\\mathcal{P}$, which\nfinds the best approximation of $\\mathcal{I}\\pi$ in the set of realizable\npolicies. We use this framework to introduce operator-based versions of\ntraditional policy gradient methods such as REINFORCE and PPO, which leads to a\nbetter understanding of their original counterparts. We also use the\nunderstanding we develop of the role of $\\mathcal{I}$ and $\\mathcal{P}$ to\npropose a new global lower bound of the expected return. This new perspective\nallows us to further bridge the gap between policy-based and value-based\nmethods, showing how REINFORCE and the Bellman optimality operator, for\nexample, can be seen as two sides of the same coin.\n", "versions": [{"version": "v1", "created": "Fri, 19 Jun 2020 17:55:07 GMT"}, {"version": "v2", "created": "Mon, 22 Jun 2020 14:48:01 GMT"}, {"version": "v3", "created": "Thu, 22 Oct 2020 23:16:04 GMT"}], "update_date": "2020-10-26", "authors_parsed": [["Ghosh", "Dibya", ""], ["Machado", "Marlos C.", ""], ["Roux", "Nicolas Le", ""]]}, {"id": "2006.11274", "submitter": "Ruosong Wang", "authors": "Ruosong Wang, Simon S. Du, Lin F. Yang, Ruslan Salakhutdinov", "title": "On Reward-Free Reinforcement Learning with Linear Function Approximation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reward-free reinforcement learning (RL) is a framework which is suitable for\nboth the batch RL setting and the setting where there are many reward functions\nof interest. During the exploration phase, an agent collects samples without\nusing a pre-specified reward function. After the exploration phase, a reward\nfunction is given, and the agent uses samples collected during the exploration\nphase to compute a near-optimal policy. Jin et al. [2020] showed that in the\ntabular setting, the agent only needs to collect polynomial number of samples\n(in terms of the number states, the number of actions, and the planning\nhorizon) for reward-free RL. However, in practice, the number of states and\nactions can be large, and thus function approximation schemes are required for\ngeneralization. In this work, we give both positive and negative results for\nreward-free RL with linear function approximation. We give an algorithm for\nreward-free RL in the linear Markov decision process setting where both the\ntransition and the reward admit linear representations. The sample complexity\nof our algorithm is polynomial in the feature dimension and the planning\nhorizon, and is completely independent of the number of states and actions. We\nfurther give an exponential lower bound for reward-free RL in the setting where\nonly the optimal $Q$-function admits a linear representation. Our results imply\nseveral interesting exponential separations on the sample complexity of\nreward-free RL.\n", "versions": [{"version": "v1", "created": "Fri, 19 Jun 2020 17:59:36 GMT"}], "update_date": "2020-06-22", "authors_parsed": [["Wang", "Ruosong", ""], ["Du", "Simon S.", ""], ["Yang", "Lin F.", ""], ["Salakhutdinov", "Ruslan", ""]]}, {"id": "2006.11300", "submitter": "Daniel Angelov", "authors": "Daniel Angelov, Yordan Hristov, Subramanian Ramamoorthy", "title": "From Demonstrations to Task-Space Specifications: Using Causal Analysis\n  to Extract Rule Parameterization from Demonstrations", "comments": "arXiv admin note: substantial text overlap with arXiv:1903.01267", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning models of user behaviour is an important problem that is broadly\napplicable across many application domains requiring human-robot interaction.\nIn this work, we show that it is possible to learn generative models for\ndistinct user behavioural types, extracted from human demonstrations, by\nenforcing clustering of preferred task solutions within the latent space. We\nuse these models to differentiate between user types and to find cases with\noverlapping solutions. Moreover, we can alter an initially guessed solution to\nsatisfy the preferences that constitute a particular user type by\nbackpropagating through the learned differentiable models. An advantage of\nstructuring generative models in this way is that we can extract causal\nrelationships between symbols that might form part of the user's specification\nof the task, as manifested in the demonstrations. We further parameterize these\nspecifications through constraint optimization in order to find a safety\nenvelope under which motion planning can be performed. We show that the\nproposed method is capable of correctly distinguishing between three user\ntypes, who differ in degrees of cautiousness in their motion, while performing\nthe task of moving objects with a kinesthetically driven robot in a tabletop\nenvironment. Our method successfully identifies the correct type, within the\nspecified time, in 99% [97.8 - 99.8] of the cases, which outperforms an IRL\nbaseline. We also show that our proposed method correctly changes a default\ntrajectory to one satisfying a particular user specification even with unseen\nobjects. The resulting trajectory is shown to be directly implementable on a\nPR2 humanoid robot completing the same task.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jun 2020 00:21:13 GMT"}], "update_date": "2020-06-23", "authors_parsed": [["Angelov", "Daniel", ""], ["Hristov", "Yordan", ""], ["Ramamoorthy", "Subramanian", ""]]}, {"id": "2006.11305", "submitter": "Cem C. Tutum", "authors": "Cem C Tutum, Suhaib Abdulquddos, Risto Miikkulainen", "title": "Generalization of Agent Behavior through Explicit Representation of\n  Context", "comments": "7 pages, 6 figures, 3 tables. Revised with more comprehensive CARLA\n  results. arXiv admin note: substantial text overlap with arXiv:2002.05640", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In order to deploy autonomous agents in digital interactive environments,\nthey must be able to act robustly in unseen situations. The standard machine\nlearning approach is to include as much variation as possible into training\nthese agents. The agents can then interpolate within their training, but they\ncannot extrapolate much beyond it. This paper proposes a principled approach\nwhere a context module is coevolved with a skill module in the game. The\ncontext module recognizes the temporal variation in the game and modulates the\noutputs of the skill module so that the action decisions can be made robustly\neven in previously unseen situations. The approach is evaluated in the Flappy\nBird and LunarLander video games, as well as in the CARLA autonomous driving\nsimulation. The Context+Skill approach leads to significantly more robust\nbehavior in environments that require extrapolation beyond training. Such a\nprincipled generalization ability is essential in deploying autonomous agents\nin real-world tasks, and can serve as a foundation for continual adaptation as\nwell.\n", "versions": [{"version": "v1", "created": "Thu, 18 Jun 2020 04:35:22 GMT"}, {"version": "v2", "created": "Tue, 9 Feb 2021 21:51:41 GMT"}], "update_date": "2021-02-11", "authors_parsed": [["Tutum", "Cem C", ""], ["Abdulquddos", "Suhaib", ""], ["Miikkulainen", "Risto", ""]]}, {"id": "2006.11309", "submitter": "Tom Bewley", "authors": "Tom Bewley, Jonathan Lawry, Arthur Richards", "title": "Modelling Agent Policies with Interpretable Imitation Learning", "comments": "6 pages, 3 figures; under review for the 1st TAILOR Workshop, due to\n  take place 29-30 August 2020 in Santiago de Compostela", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As we deploy autonomous agents in safety-critical domains, it becomes\nimportant to develop an understanding of their internal mechanisms and\nrepresentations. We outline an approach to imitation learning for\nreverse-engineering black box agent policies in MDP environments, yielding\nsimplified, interpretable models in the form of decision trees. As part of this\nprocess, we explicitly model and learn agents' latent state representations by\nselecting from a large space of candidate features constructed from the Markov\nstate. We present initial promising results from an implementation in a\nmulti-agent traffic environment.\n", "versions": [{"version": "v1", "created": "Fri, 19 Jun 2020 18:19:08 GMT"}], "update_date": "2020-06-23", "authors_parsed": [["Bewley", "Tom", ""], ["Lawry", "Jonathan", ""], ["Richards", "Arthur", ""]]}, {"id": "2006.11312", "submitter": "Martin Aleksandrov D", "authors": "Martin Aleksandrov", "title": "Envy-freeness up to one item: Shall we add or remove resources?", "comments": "10 pages, 1 table, 2 figures, v1 is a working version, v2 is the\n  polished version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a fair division model in which agents have general valuations for\nbundles of indivisible items. We propose two new axiomatic properties for\nallocations in this model: EF1+- and EFX+-. We compare these with the existing\nEF1 and EFX. Although EF1 and EF1+- allocations often exist, our results assert\neloquently that EFX+- and PO allocations exist in each case where EFX and PO\nallocations do not exist. Additionally, we prove several new impossibility and\nincompatibility results.\n", "versions": [{"version": "v1", "created": "Fri, 19 Jun 2020 18:29:05 GMT"}, {"version": "v2", "created": "Tue, 23 Jun 2020 14:49:28 GMT"}], "update_date": "2020-06-24", "authors_parsed": [["Aleksandrov", "Martin", ""]]}, {"id": "2006.11362", "submitter": "Lirong Xia", "authors": "Lirong Xia", "title": "Optimal Statistical Hypothesis Testing for Social Choice", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.AI cs.GT stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the following question in this paper: \"What are the most robust\nstatistical methods for social choice?'' By leveraging the theory of uniformly\nleast favorable distributions in the Neyman-Pearson framework to finite models\nand randomized tests, we characterize uniformly most powerful (UMP) tests,\nwhich is a well-accepted statistical optimality w.r.t. robustness, for testing\nwhether a given alternative is the winner under Mallows' model and under\nCondorcet's model, respectively.\n", "versions": [{"version": "v1", "created": "Fri, 19 Jun 2020 20:40:33 GMT"}], "update_date": "2020-06-23", "authors_parsed": [["Xia", "Lirong", ""]]}, {"id": "2006.11363", "submitter": "Andr\\'es P\\'aez", "authors": "Andr\\'es P\\'aez", "title": "Moore's Paradox and the logic of belief", "comments": null, "journal-ref": "Manuscrito 43(2), 2020", "doi": null, "report-no": null, "categories": "cs.LO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Moores Paradox is a test case for any formal theory of belief. In Knowledge\nand Belief, Hintikka developed a multimodal logic for statements that express\nsentences containing the epistemic notions of knowledge and belief. His account\npurports to offer an explanation of the paradox. In this paper I argue that\nHintikkas interpretation of one of the doxastic operators is philosophically\nproblematic and leads to an unnecessarily strong logical system. I offer a\nweaker alternative that captures in a more accurate way our logical intuitions\nabout the notion of belief without sacrificing the possibility of providing an\nexplanation for problematic cases such as Moores Paradox.\n", "versions": [{"version": "v1", "created": "Fri, 19 Jun 2020 20:41:19 GMT"}], "update_date": "2020-06-23", "authors_parsed": [["P\u00e1ez", "Andr\u00e9s", ""]]}, {"id": "2006.11371", "submitter": "Arun Das", "authors": "Arun Das and Paul Rad", "title": "Opportunities and Challenges in Explainable Artificial Intelligence\n  (XAI): A Survey", "comments": "24 pages, 20 figures, survey paper, submitting to IEEE", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nowadays, deep neural networks are widely used in mission critical systems\nsuch as healthcare, self-driving vehicles, and military which have direct\nimpact on human lives. However, the black-box nature of deep neural networks\nchallenges its use in mission critical applications, raising ethical and\njudicial concerns inducing lack of trust. Explainable Artificial Intelligence\n(XAI) is a field of Artificial Intelligence (AI) that promotes a set of tools,\ntechniques, and algorithms that can generate high-quality interpretable,\nintuitive, human-understandable explanations of AI decisions. In addition to\nproviding a holistic view of the current XAI landscape in deep learning, this\npaper provides mathematical summaries of seminal work. We start by proposing a\ntaxonomy and categorizing the XAI techniques based on their scope of\nexplanations, methodology behind the algorithms, and explanation level or usage\nwhich helps build trustworthy, interpretable, and self-explanatory deep\nlearning models. We then describe the main principles used in XAI research and\npresent the historical timeline for landmark studies in XAI from 2007 to 2020.\nAfter explaining each category of algorithms and approaches in detail, we then\nevaluate the explanation maps generated by eight XAI algorithms on image data,\ndiscuss the limitations of this approach, and provide potential future\ndirections to improve XAI evaluation.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jun 2020 02:58:10 GMT"}, {"version": "v2", "created": "Tue, 23 Jun 2020 01:48:56 GMT"}], "update_date": "2020-06-24", "authors_parsed": [["Das", "Arun", ""], ["Rad", "Paul", ""]]}, {"id": "2006.11413", "submitter": "Feng Qi", "authors": "Feng Qi, Guanjun Jiang", "title": "Visualizing and Understanding Vision System", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  How the human vision system addresses the object identity-preserving\nrecognition problem is largely unknown. Here, we use a vision\nrecognition-reconstruction network (RRN) to investigate the development,\nrecognition, learning and forgetting mechanisms, and achieve similar\ncharacteristics to electrophysiological measurements in monkeys. First, in\nnetwork development study, the RRN also experiences critical developmental\nstages characterized by specificities in neuron types, synapse and activation\npatterns, and visual task performance from the early stage of coarse salience\nmap recognition to mature stage of fine structure recognition. In digit\nrecognition study, we witness that the RRN could maintain object invariance\nrepresentation under various viewing conditions by coordinated adjustment of\nresponses of population neurons. And such concerted population responses\ncontained untangled object identity and properties information that could be\naccurately extracted via high-level cortices or even a simple weighted\nsummation decoder. In the learning and forgetting study, novel structure\nrecognition is implemented by adjusting entire synapses in low magnitude while\npattern specificities of original synaptic connectivity are preserved, which\nguaranteed a learning process without disrupting the existing functionalities.\nThis work benefits the understanding of the human visual processing mechanism\nand the development of human-like machine intelligence.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jun 2020 07:08:49 GMT"}], "update_date": "2020-06-23", "authors_parsed": [["Qi", "Feng", ""], ["Jiang", "Guanjun", ""]]}, {"id": "2006.11419", "submitter": "Chuangchuang Sun", "authors": "Chuangchuang Sun, Dong-Ki Kim, Jonathan P. How", "title": "FISAR: Forward Invariant Safe Reinforcement Learning with a Deep Neural\n  Network-Based Optimize", "comments": "Accepted to ICML 2020 Workshop Theoretical Foundations of RL;\n  Accepted to ICRA 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper investigates reinforcement learning with constraints, which are\nindispensable in safety-critical environments. To drive the constraint\nviolation monotonically decrease, we take the constraints as Lyapunov functions\nand impose new linear constraints on the policy parameters' updating dynamics.\nAs a result, the original safety set can be forward-invariant. However, because\nthe new guaranteed-feasible constraints are imposed on the updating dynamics\ninstead of the original policy parameters, classic optimization algorithms are\nno longer applicable. To address this, we propose to learn a generic deep\nneural network (DNN)-based optimizer to optimize the objective while satisfying\nthe linear constraints. The constraint-satisfaction is achieved via projection\nonto a polytope formulated by multiple linear inequality constraints, which can\nbe solved analytically with our newly designed metric. To the best of our\nknowledge, this is the \\textit{first} DNN-based optimizer for constrained\noptimization with the forward invariance guarantee. We show that our optimizer\ntrains a policy to decrease the constraint violation and maximize the\ncumulative reward monotonically. Results on numerical constrained optimization\nand obstacle-avoidance navigation validate the theoretical findings.\n", "versions": [{"version": "v1", "created": "Fri, 19 Jun 2020 21:58:42 GMT"}, {"version": "v2", "created": "Thu, 9 Jul 2020 03:11:59 GMT"}, {"version": "v3", "created": "Tue, 3 Nov 2020 16:16:15 GMT"}, {"version": "v4", "created": "Wed, 5 May 2021 23:42:55 GMT"}], "update_date": "2021-05-07", "authors_parsed": [["Sun", "Chuangchuang", ""], ["Kim", "Dong-Ki", ""], ["How", "Jonathan P.", ""]]}, {"id": "2006.11431", "submitter": "Miguel Campo PhD", "authors": "Miguel Campo, Zhengxing Chen, Luke Kung, Kittipat Virochsiri and\n  Jianyu Wang", "title": "Band-limited Soft Actor Critic Model", "comments": "8 pages plus additional material", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Soft Actor Critic (SAC) algorithms show remarkable performance in complex\nsimulated environments. A key element of SAC networks is entropy\nregularization, which prevents the SAC actor from optimizing against fine\ngrained features, oftentimes transient, of the state-action value function.\nThis results in better sample efficiency during early training. We take this\nidea one step further by artificially bandlimiting the target critic spatial\nresolution through the addition of a convolutional filter. We derive the closed\nform solution in the linear case and show that bandlimiting reduces the\ninterdependency between the low and high frequency components of the\nstate-action value approximation, allowing the critic to learn faster. In\nexperiments, the bandlimited SAC outperformed the classic twin-critic SAC in a\nnumber of Gym environments, and displayed more stability in returns. We derive\nnovel insights about SAC by adding a stochastic noise disturbance, a technique\nthat is increasingly being used to learn robust policies that transfer well to\nthe real world counterparts.\n", "versions": [{"version": "v1", "created": "Fri, 19 Jun 2020 22:52:43 GMT"}], "update_date": "2020-06-23", "authors_parsed": [["Campo", "Miguel", ""], ["Chen", "Zhengxing", ""], ["Kung", "Luke", ""], ["Virochsiri", "Kittipat", ""], ["Wang", "Jianyu", ""]]}, {"id": "2006.11438", "submitter": "Sheng Li", "authors": "Sheng Li, Jayesh K. Gupta, Peter Morales, Ross Allen, Mykel J.\n  Kochenderfer", "title": "Deep Implicit Coordination Graphs for Multi-agent Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-agent reinforcement learning (MARL) requires coordination to\nefficiently solve certain tasks. Fully centralized control is often infeasible\nin such domains due to the size of joint action spaces. Coordination graph\nbased formalization allows reasoning about the joint action based on the\nstructure of interactions. However, they often require domain expertise in\ntheir design. This paper introduces the deep implicit coordination graph (DICG)\narchitecture for such scenarios. DICG consists of a module for inferring the\ndynamic coordination graph structure which is then used by a graph neural\nnetwork based module to learn to implicitly reason about the joint actions or\nvalues. DICG allows learning the tradeoff between full centralization and\ndecentralization via standard actor-critic methods to significantly improve\ncoordination for domains with large number of agents. We apply DICG to both\ncentralized-training-centralized-execution and\ncentralized-training-decentralized-execution regimes. We demonstrate that DICG\nsolves the relative overgeneralization pathology in predatory-prey tasks as\nwell as outperforms various MARL baselines on the challenging StarCraft II\nMulti-agent Challenge (SMAC) and traffic junction environments.\n", "versions": [{"version": "v1", "created": "Fri, 19 Jun 2020 23:41:49 GMT"}, {"version": "v2", "created": "Wed, 3 Feb 2021 23:29:50 GMT"}], "update_date": "2021-02-05", "authors_parsed": [["Li", "Sheng", ""], ["Gupta", "Jayesh K.", ""], ["Morales", "Peter", ""], ["Allen", "Ross", ""], ["Kochenderfer", "Mykel J.", ""]]}, {"id": "2006.11441", "submitter": "Mengdi Xu", "authors": "Mengdi Xu, Wenhao Ding, Jiacheng Zhu, Zuxin Liu, Baiming Chen, Ding\n  Zhao", "title": "Task-Agnostic Online Reinforcement Learning with an Infinite Mixture of\n  Gaussian Processes", "comments": "16 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Continuously learning to solve unseen tasks with limited experience has been\nextensively pursued in meta-learning and continual learning, but with\nrestricted assumptions such as accessible task distributions, independently and\nidentically distributed tasks, and clear task delineations. However, real-world\nphysical tasks frequently violate these assumptions, resulting in performance\ndegradation. This paper proposes a continual online model-based reinforcement\nlearning approach that does not require pre-training to solve task-agnostic\nproblems with unknown task boundaries. We maintain a mixture of experts to\nhandle nonstationarity, and represent each different type of dynamics with a\nGaussian Process to efficiently leverage collected data and expressively model\nuncertainty. We propose a transition prior to account for the temporal\ndependencies in streaming data and update the mixture online via sequential\nvariational inference. Our approach reliably handles the task distribution\nshift by generating new models for never-before-seen dynamics and reusing old\nmodels for previously seen dynamics. In experiments, our approach outperforms\nalternative methods in non-stationary tasks, including classic control with\nchanging dynamics and decision making in different driving scenarios.\n", "versions": [{"version": "v1", "created": "Fri, 19 Jun 2020 23:52:45 GMT"}, {"version": "v2", "created": "Mon, 29 Jun 2020 14:20:43 GMT"}, {"version": "v3", "created": "Mon, 30 Nov 2020 17:06:14 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Xu", "Mengdi", ""], ["Ding", "Wenhao", ""], ["Zhu", "Jiacheng", ""], ["Liu", "Zuxin", ""], ["Chen", "Baiming", ""], ["Zhao", "Ding", ""]]}, {"id": "2006.11446", "submitter": "Nidhi Rastogi", "authors": "Nidhi Rastogi, Sharmishtha Dutta, Mohammed J. Zaki, Alex Gittens, and\n  Charu Aggarwal", "title": "MALOnt: An Ontology for Malware Threat Intelligence", "comments": null, "journal-ref": null, "doi": "10.13140/RG.2.2.16426.64962", "report-no": null, "categories": "cs.CR cs.AI cs.IR", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Malware threat intelligence uncovers deep information about malware, threat\nactors, and their tactics, Indicators of Compromise(IoC), and vulnerabilities\nin different platforms from scattered threat sources. This collective\ninformation can guide decision making in cyber defense applications utilized by\nsecurity operation centers(SoCs). In this paper, we introduce an open-source\nmalware ontology - MALOnt that allows the structured extraction of information\nand knowledge graph generation, especially for threat intelligence. The\nknowledge graph that uses MALOnt is instantiated from a corpus comprising\nhundreds of annotated malware threat reports. The knowledge graph enables the\nanalysis, detection, classification, and attribution of cyber threats caused by\nmalware. We also demonstrate the annotation process using MALOnt on exemplar\nthreat intelligence reports. A work in progress, this research is part of a\nlarger effort towards auto-generation of knowledge graphs (KGs)for gathering\nmalware threat intelligence from heterogeneous online resources.\n", "versions": [{"version": "v1", "created": "Sat, 20 Jun 2020 00:25:07 GMT"}], "update_date": "2020-06-23", "authors_parsed": [["Rastogi", "Nidhi", ""], ["Dutta", "Sharmishtha", ""], ["Zaki", "Mohammed J.", ""], ["Gittens", "Alex", ""], ["Aggarwal", "Charu", ""]]}, {"id": "2006.11465", "submitter": "Junpei Zhong", "authors": "Junpei Zhong and Angelo Cangelosi and Stefan Wermter", "title": "Towards a self-organizing pre-symbolic neural model representing\n  sensorimotor primitives", "comments": null, "journal-ref": "Frontiers in behavioral neuroscience, 8, 22 (2014)", "doi": "10.3389/fnbeh.2014.00022", "report-no": null, "categories": "cs.NE cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The acquisition of symbolic and linguistic representations of sensorimotor\nbehavior is a cognitive process performed by an agent when it is executing\nand/or observing own and others' actions. According to Piaget's theory of\ncognitive development, these representations develop during the sensorimotor\nstage and the pre-operational stage. We propose a model that relates the\nconceptualization of the higher-level information from visual stimuli to the\ndevelopment of ventral/dorsal visual streams. This model employs neural network\narchitecture incorporating a predictive sensory module based on an RNNPB\n(Recurrent Neural Network with Parametric Biases) and a horizontal product\nmodel. We exemplify this model through a robot passively observing an object to\nlearn its features and movements. During the learning process of observing\nsensorimotor primitives, i.e. observing a set of trajectories of arm movements\nand its oriented object features, the pre-symbolic representation is\nself-organized in the parametric units. These representational units act as\nbifurcation parameters, guiding the robot to recognize and predict various\nlearned sensorimotor primitives. The pre-symbolic representation also accounts\nfor the learning of sensorimotor primitives in a latent learning context.\n", "versions": [{"version": "v1", "created": "Sat, 20 Jun 2020 01:58:28 GMT"}, {"version": "v2", "created": "Sun, 12 Jul 2020 04:30:56 GMT"}], "update_date": "2020-07-14", "authors_parsed": [["Zhong", "Junpei", ""], ["Cangelosi", "Angelo", ""], ["Wermter", "Stefan", ""]]}, {"id": "2006.11483", "submitter": "Le Yu", "authors": "Le Yu, Leilei Sun, Bowen Du, Chuanren Liu, Hui Xiong, Weifeng Lv", "title": "Predicting Temporal Sets with Deep Neural Networks", "comments": "9 pages, 6 figures, Proceedings of the 26th ACM SIGKDD Conference on\n  Knowledge Discovery and Data Mining (KDD '2020)", "journal-ref": null, "doi": "10.1145/3394486.3403152", "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a sequence of sets, where each set contains an arbitrary number of\nelements, the problem of temporal sets prediction aims to predict the elements\nin the subsequent set. In practice, temporal sets prediction is much more\ncomplex than predictive modelling of temporal events and time series, and is\nstill an open problem. Many possible existing methods, if adapted for the\nproblem of temporal sets prediction, usually follow a two-step strategy by\nfirst projecting temporal sets into latent representations and then learning a\npredictive model with the latent representations. The two-step approach often\nleads to information loss and unsatisfactory prediction performance. In this\npaper, we propose an integrated solution based on the deep neural networks for\ntemporal sets prediction. A unique perspective of our approach is to learn\nelement relationship by constructing set-level co-occurrence graph and then\nperform graph convolutions on the dynamic relationship graphs. Moreover, we\ndesign an attention-based module to adaptively learn the temporal dependency of\nelements and sets. Finally, we provide a gated updating mechanism to find the\nhidden shared patterns in different sequences and fuse both static and dynamic\ninformation to improve the prediction performance. Experiments on real-world\ndata sets demonstrate that our approach can achieve competitive performances\neven with a portion of the training data and can outperform existing methods\nwith a significant margin.\n", "versions": [{"version": "v1", "created": "Sat, 20 Jun 2020 03:29:02 GMT"}, {"version": "v2", "created": "Sun, 28 Jun 2020 03:00:44 GMT"}, {"version": "v3", "created": "Thu, 2 Jul 2020 05:43:43 GMT"}, {"version": "v4", "created": "Wed, 8 Jul 2020 01:58:42 GMT"}], "update_date": "2020-07-09", "authors_parsed": [["Yu", "Le", ""], ["Sun", "Leilei", ""], ["Du", "Bowen", ""], ["Liu", "Chuanren", ""], ["Xiong", "Hui", ""], ["Lv", "Weifeng", ""]]}, {"id": "2006.11524", "submitter": "Saeed Amizadeh", "authors": "Saeed Amizadeh, Hamid Palangi, Oleksandr Polozov, Yichen Huang,\n  Kazuhito Koishida", "title": "Neuro-Symbolic Visual Reasoning: Disentangling \"Visual\" from \"Reasoning\"", "comments": "Published in Proceedings of the 37th International Conference on\n  Machine Learning (ICML), Online, PMLR 119, 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.NE cs.SC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Visual reasoning tasks such as visual question answering (VQA) require an\ninterplay of visual perception with reasoning about the question semantics\ngrounded in perception. However, recent advances in this area are still\nprimarily driven by perception improvements (e.g. scene graph generation)\nrather than reasoning. Neuro-symbolic models such as Neural Module Networks\nbring the benefits of compositional reasoning to VQA, but they are still\nentangled with visual representation learning, and thus neural reasoning is\nhard to improve and assess on its own. To address this, we propose (1) a\nframework to isolate and evaluate the reasoning aspect of VQA separately from\nits perception, and (2) a novel top-down calibration technique that allows the\nmodel to answer reasoning questions even with imperfect perception. To this\nend, we introduce a differentiable first-order logic formalism for VQA that\nexplicitly decouples question answering from visual perception. On the\nchallenging GQA dataset, this framework is used to perform in-depth,\ndisentangled comparisons between well-known VQA models leading to informative\ninsights regarding the participating models as well as the task.\n", "versions": [{"version": "v1", "created": "Sat, 20 Jun 2020 08:48:29 GMT"}, {"version": "v2", "created": "Tue, 30 Jun 2020 07:34:34 GMT"}, {"version": "v3", "created": "Tue, 25 Aug 2020 23:30:57 GMT"}], "update_date": "2020-08-27", "authors_parsed": [["Amizadeh", "Saeed", ""], ["Palangi", "Hamid", ""], ["Polozov", "Oleksandr", ""], ["Huang", "Yichen", ""], ["Koishida", "Kazuhito", ""]]}, {"id": "2006.11560", "submitter": "Helge Spieker", "authors": "Helge Spieker, Arnaud Gotlieb", "title": "Learning Objective Boundaries for Constraint Optimization Problems", "comments": "The 6th International Conference on machine Learning, Optimization\n  and Data science - LOD 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Constraint Optimization Problems (COP) are often considered without\nsufficient knowledge on the boundaries of the objective variable to optimize.\nWhen available, tight boundaries are helpful to prune the search space or\nestimate problem characteristics. Finding close boundaries, that correctly\nunder- and overestimate the optimum, is almost impossible without actually\nsolving the COP. This paper introduces Bion, a novel approach for boundary\nestimation by learning from previously solved instances of the COP. Based on\nsupervised machine learning, Bion is problem-specific and solver-independent\nand can be applied to any COP which is repeatedly solved with different data\ninputs. An experimental evaluation over seven realistic COPs shows that an\nestimation model can be trained to prune the objective variables' domains by\nover 80%. By evaluating the estimated boundaries with various COP solvers, we\nfind that Bion improves the solving process for some problems, although the\neffect of closer bounds is generally problem-dependent.\n", "versions": [{"version": "v1", "created": "Sat, 20 Jun 2020 12:09:49 GMT"}], "update_date": "2020-06-23", "authors_parsed": [["Spieker", "Helge", ""], ["Gotlieb", "Arnaud", ""]]}, {"id": "2006.11645", "submitter": "Tsung-Yen Yang", "authors": "Tsung-Yen Yang and Justinian Rosca and Karthik Narasimhan and Peter J.\n  Ramadge", "title": "Accelerating Safe Reinforcement Learning with Constraint-mismatched\n  Policies", "comments": "International Conference on Machine Learning (ICML) 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of reinforcement learning when provided with (1) a\nbaseline control policy and (2) a set of constraints that the learner must\nsatisfy. The baseline policy can arise from demonstration data or a teacher\nagent and may provide useful cues for learning, but it might also be\nsub-optimal for the task at hand, and is not guaranteed to satisfy the\nspecified constraints, which might encode safety, fairness or other\napplication-specific requirements. In order to safely learn from baseline\npolicies, we propose an iterative policy optimization algorithm that alternates\nbetween maximizing expected return on the task, minimizing distance to the\nbaseline policy, and projecting the policy onto the constraint-satisfying set.\nWe analyze our algorithm theoretically and provide a finite-time convergence\nguarantee. In our experiments on five different control tasks, our algorithm\nconsistently outperforms several state-of-the-art baselines, achieving 10 times\nfewer constraint violations and 40% higher reward on average.\n", "versions": [{"version": "v1", "created": "Sat, 20 Jun 2020 20:20:47 GMT"}, {"version": "v2", "created": "Wed, 7 Oct 2020 05:08:21 GMT"}, {"version": "v3", "created": "Sat, 10 Jul 2021 02:55:37 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Yang", "Tsung-Yen", ""], ["Rosca", "Justinian", ""], ["Narasimhan", "Karthik", ""], ["Ramadge", "Peter J.", ""]]}, {"id": "2006.11684", "submitter": "Yuan Shen", "authors": "Yuan Shen, Shanduojiao Jiang, Yanlin Chen, Eileen Yang, Xilun Jin,\n  Yuliang Fan, Katie Driggs Campbell", "title": "To Explain or Not to Explain: A Study on the Necessity of Explanations\n  for Autonomous Vehicles", "comments": "9.5 pages, 7 figures, submitted to UIST2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.HC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Explainable AI, in the context of autonomous systems, like self driving cars,\nhas drawn broad interests from researchers. Recent studies have found that\nproviding explanations for an autonomous vehicle actions has many benefits,\ne.g., increase trust and acceptance, but put little emphasis on when an\nexplanation is needed and how the content of explanation changes with context.\nIn this work, we investigate which scenarios people need explanations and how\nthe critical degree of explanation shifts with situations and driver types.\nThrough a user experiment, we ask participants to evaluate how necessary an\nexplanation is and measure the impact on their trust in the self driving cars\nin different contexts. We also present a self driving explanation dataset with\nfirst person explanations and associated measure of the necessity for 1103\nvideo clips, augmenting the Berkeley Deep Drive Attention dataset.\nAdditionally, we propose a learning based model that predicts how necessary an\nexplanation for a given situation in real time, using camera data inputs. Our\nresearch reveals that driver types and context dictates whether or not an\nexplanation is necessary and what is helpful for improved interaction and\nunderstanding.\n", "versions": [{"version": "v1", "created": "Sun, 21 Jun 2020 00:38:24 GMT"}], "update_date": "2020-06-23", "authors_parsed": [["Shen", "Yuan", ""], ["Jiang", "Shanduojiao", ""], ["Chen", "Yanlin", ""], ["Yang", "Eileen", ""], ["Jin", "Xilun", ""], ["Fan", "Yuliang", ""], ["Campbell", "Katie Driggs", ""]]}, {"id": "2006.11704", "submitter": "Weihang Yuan", "authors": "Weihang Yuan, H\\'ector Mu\\~noz-Avila", "title": "Hierarchical Reinforcement Learning for Deep Goal Reasoning: An\n  Expressiveness Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hierarchical DQN (h-DQN) is a two-level architecture of feedforward neural\nnetworks where the meta level selects goals and the lower level takes actions\nto achieve the goals. We show tasks that cannot be solved by h-DQN,\nexemplifying the limitation of this type of hierarchical framework (HF). We\ndescribe the recurrent hierarchical framework (RHF), generalizing architectures\nthat use a recurrent neural network at the meta level. We analyze the\nexpressiveness of HF and RHF using context-sensitive grammars. We show that RHF\nis more expressive than HF. We perform experiments comparing an implementation\nof RHF with two HF baselines; the results corroborate our theoretical findings.\n", "versions": [{"version": "v1", "created": "Sun, 21 Jun 2020 03:29:05 GMT"}], "update_date": "2020-06-23", "authors_parsed": [["Yuan", "Weihang", ""], ["Mu\u00f1oz-Avila", "H\u00e9ctor", ""]]}, {"id": "2006.11737", "submitter": "Deepak Vijaykeerthy", "authors": "Philips George John, Deepak Vijaykeerthy, Diptikalyan Saha", "title": "Verifying Individual Fairness in Machine Learning Models", "comments": "An extended version of the paper accepted at UAI 2020, 12 pages, code\n  is available at https://github.com/philips-george/ifv-uai-2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of whether a given decision model, working with\nstructured data, has individual fairness. Following the work of Dwork, a model\nis individually biased (or unfair) if there is a pair of valid inputs which are\nclose to each other (according to an appropriate metric) but are treated\ndifferently by the model (different class label, or large difference in\noutput), and it is unbiased (or fair) if no such pair exists. Our objective is\nto construct verifiers for proving individual fairness of a given model, and we\ndo so by considering appropriate relaxations of the problem. We construct\nverifiers which are sound but not complete for linear classifiers, and\nkernelized polynomial/radial basis function classifiers. We also report the\nexperimental results of evaluating our proposed algorithms on publicly\navailable datasets.\n", "versions": [{"version": "v1", "created": "Sun, 21 Jun 2020 08:37:54 GMT"}], "update_date": "2020-06-23", "authors_parsed": [["John", "Philips George", ""], ["Vijaykeerthy", "Deepak", ""], ["Saha", "Diptikalyan", ""]]}, {"id": "2006.11751", "submitter": "Aleksei Petrenko", "authors": "Aleksei Petrenko, Zhehui Huang, Tushar Kumar, Gaurav Sukhatme, Vladlen\n  Koltun", "title": "Sample Factory: Egocentric 3D Control from Pixels at 100000 FPS with\n  Asynchronous Reinforcement Learning", "comments": "Paper published in ICML2020. Visualizations of trained policies can\n  be found at https://sites.google.com/view/sample-factory", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Increasing the scale of reinforcement learning experiments has allowed\nresearchers to achieve unprecedented results in both training sophisticated\nagents for video games, and in sim-to-real transfer for robotics. Typically\nsuch experiments rely on large distributed systems and require expensive\nhardware setups, limiting wider access to this exciting area of research. In\nthis work we aim to solve this problem by optimizing the efficiency and\nresource utilization of reinforcement learning algorithms instead of relying on\ndistributed computation. We present the \"Sample Factory\", a high-throughput\ntraining system optimized for a single-machine setting. Our architecture\ncombines a highly efficient, asynchronous, GPU-based sampler with off-policy\ncorrection techniques, allowing us to achieve throughput higher than $10^5$\nenvironment frames/second on non-trivial control problems in 3D without\nsacrificing sample efficiency. We extend Sample Factory to support self-play\nand population-based training and apply these techniques to train highly\ncapable agents for a multiplayer first-person shooter game. The source code is\navailable at https://github.com/alex-petrenko/sample-factory\n", "versions": [{"version": "v1", "created": "Sun, 21 Jun 2020 10:00:23 GMT"}, {"version": "v2", "created": "Tue, 23 Jun 2020 00:41:58 GMT"}], "update_date": "2020-06-24", "authors_parsed": [["Petrenko", "Aleksei", ""], ["Huang", "Zhehui", ""], ["Kumar", "Tushar", ""], ["Sukhatme", "Gaurav", ""], ["Koltun", "Vladlen", ""]]}, {"id": "2006.11769", "submitter": "Daniel Santiago Cuervo G\\'omez", "authors": "Santiago Cuervo and Marco Alzate", "title": "Emergent cooperation through mutual information maximization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.MA cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With artificial intelligence systems becoming ubiquitous in our society, its\ndesigners will soon have to start to consider its social dimension, as many of\nthese systems will have to interact among them to work efficiently. With this\nin mind, we propose a decentralized deep reinforcement learning algorithm for\nthe design of cooperative multi-agent systems. The algorithm is based on the\nhypothesis that highly correlated actions are a feature of cooperative systems,\nand hence, we propose the insertion of an auxiliary objective of maximization\nof the mutual information between the actions of agents in the learning\nproblem. Our system is applied to a social dilemma, a problem whose optimal\nsolution requires that agents cooperate to maximize a macroscopic performance\nfunction despite the divergent individual objectives of each agent. By\ncomparing the performance of the proposed system to a system without the\nauxiliary objective, we conclude that the maximization of mutual information\namong agents promotes the emergence of cooperation in social dilemmas.\n", "versions": [{"version": "v1", "created": "Sun, 21 Jun 2020 11:15:55 GMT"}], "update_date": "2020-06-23", "authors_parsed": [["Cuervo", "Santiago", ""], ["Alzate", "Marco", ""]]}, {"id": "2006.11814", "submitter": "Michele Loi Dr.", "authors": "Michele Loi and Lonneke van der Plas", "title": "A blindspot of AI ethics: anti-fragility in statistical prediction", "comments": "7th Swiss Conference on Data Science (accepted as Poster)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  With this paper, we aim to put an issue on the agenda of AI ethics that in\nour view is overlooked in the current discourse. The current discussions are\ndominated by topics suchas trustworthiness and bias, whereas the issue we like\nto focuson is counter to the debate on trustworthiness. We fear that the\noveruse of currently dominant AI systems that are driven by short-term\nobjectives and optimized for avoiding error leads to a society that loses its\ndiversity and flexibility needed for true progress. We couch our concerns in\nthe discourse around the term anti-fragility and show with some examples what\nthreats current methods used for decision making pose for society.\n", "versions": [{"version": "v1", "created": "Sun, 21 Jun 2020 14:46:55 GMT"}], "update_date": "2020-06-25", "authors_parsed": [["Loi", "Michele", ""], ["van der Plas", "Lonneke", ""]]}, {"id": "2006.11827", "submitter": "Ellen Vitercik", "authors": "Maria-Florina Balcan, Tuomas Sandholm, Ellen Vitercik", "title": "Refined bounds for algorithm configuration: The knife-edge of dual class\n  approximability", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.DS cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automating algorithm configuration is growing increasingly necessary as\nalgorithms come with more and more tunable parameters. It is common to tune\nparameters using machine learning, optimizing performance metrics such as\nruntime and solution quality. The training set consists of problem instances\nfrom the specific domain at hand. We investigate a fundamental question about\nthese techniques: how large should the training set be to ensure that a\nparameter's average empirical performance over the training set is close to its\nexpected, future performance? We answer this question for algorithm\nconfiguration problems that exhibit a widely-applicable structure: the\nalgorithm's performance as a function of its parameters can be approximated by\na \"simple\" function. We show that if this approximation holds under the\nL-infinity norm, we can provide strong sample complexity bounds. On the flip\nside, if the approximation holds only under the L-p norm for p smaller than\ninfinity, it is not possible to provide meaningful sample complexity bounds in\nthe worst case. We empirically evaluate our bounds in the context of integer\nprogramming, one of the most powerful tools in computer science. Via\nexperiments, we obtain sample complexity bounds that are up to 700 times\nsmaller than the previously best-known bounds.\n", "versions": [{"version": "v1", "created": "Sun, 21 Jun 2020 15:32:21 GMT"}, {"version": "v2", "created": "Thu, 24 Dec 2020 16:47:46 GMT"}], "update_date": "2020-12-25", "authors_parsed": [["Balcan", "Maria-Florina", ""], ["Sandholm", "Tuomas", ""], ["Vitercik", "Ellen", ""]]}, {"id": "2006.11880", "submitter": "Jianjun Hu", "authors": "Changchang Zeng, Shaobo Li, Qin Li, Jie Hu, and Jianjun Hu", "title": "A Survey on Machine Reading Comprehension: Tasks, Evaluation Metrics and\n  Benchmark Datasets", "comments": "68 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine Reading Comprehension (MRC) is a challenging Natural Language\nProcessing(NLP) research field with wide real-world applications. The great\nprogress of this field in recent years is mainly due to the emergence of\nlarge-scale datasets and deep learning. At present, a lot of MRC models have\nalready surpassed human performance on various benchmark datasets despite the\nobvious giant gap between existing MRC models and genuine human-level reading\ncomprehension. This shows the need for improving existing datasets, evaluation\nmetrics, and models to move current MRC models toward \"real\" understanding. To\naddress the current lack of comprehensive survey of existing MRC tasks,\nevaluation metrics, and datasets, herein, (1) we analyze 57 MRC tasks and\ndatasets and propose a more precise classification method of MRC tasks with 4\ndifferent attributes; (2) we summarized 9 evaluation metrics of MRC tasks, 7\nattributes and 10 characteristics of MRC datasets; (3) We also discuss key open\nissues in MRC research and highlighted future research directions. In addition,\nwe have collected, organized, and published our data on the companion\nwebsite(https://mrc-datasets.github.io/) where MRC researchers could directly\naccess each MRC dataset, papers, baseline projects, and the leaderboard.\n", "versions": [{"version": "v1", "created": "Sun, 21 Jun 2020 19:18:54 GMT"}, {"version": "v2", "created": "Wed, 21 Oct 2020 04:19:14 GMT"}], "update_date": "2020-10-22", "authors_parsed": [["Zeng", "Changchang", ""], ["Li", "Shaobo", ""], ["Li", "Qin", ""], ["Hu", "Jie", ""], ["Hu", "Jianjun", ""]]}, {"id": "2006.11905", "submitter": "Purva Tendulkar", "authors": "Purva Tendulkar, Abhishek Das, Aniruddha Kembhavi, Devi Parikh", "title": "Feel The Music: Automatically Generating A Dance For An Input Song", "comments": "4 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a general computational approach that enables a machine to\ngenerate a dance for any input music. We encode intuitive, flexible heuristics\nfor what a 'good' dance is: the structure of the dance should align with the\nstructure of the music. This flexibility allows the agent to discover creative\ndances. Human studies show that participants find our dances to be more\ncreative and inspiring compared to meaningful baselines. We also evaluate how\nperception of creativity changes based on different presentations of the dance.\nOur code is available at https://github.com/purvaten/feel-the-music.\n", "versions": [{"version": "v1", "created": "Sun, 21 Jun 2020 20:29:50 GMT"}, {"version": "v2", "created": "Tue, 23 Jun 2020 20:11:23 GMT"}], "update_date": "2020-06-25", "authors_parsed": [["Tendulkar", "Purva", ""], ["Das", "Abhishek", ""], ["Kembhavi", "Aniruddha", ""], ["Parikh", "Devi", ""]]}, {"id": "2006.12007", "submitter": "Yu Bai", "authors": "Yu Bai, Chi Jin, Tiancheng Yu", "title": "Near-Optimal Reinforcement Learning with Self-Play", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper considers the problem of designing optimal algorithms for\nreinforcement learning in two-player zero-sum games. We focus on self-play\nalgorithms which learn the optimal policy by playing against itself without any\ndirect supervision. In a tabular episodic Markov game with $S$ states, $A$\nmax-player actions and $B$ min-player actions, the best existing algorithm for\nfinding an approximate Nash equilibrium requires $\\tilde{\\mathcal{O}}(S^2AB)$\nsteps of game playing, when only highlighting the dependency on $(S,A,B)$. In\ncontrast, the best existing lower bound scales as $\\Omega(S(A+B))$ and has a\nsignificant gap from the upper bound. This paper closes this gap for the first\ntime: we propose an optimistic variant of the \\emph{Nash Q-learning} algorithm\nwith sample complexity $\\tilde{\\mathcal{O}}(SAB)$, and a new \\emph{Nash\nV-learning} algorithm with sample complexity $\\tilde{\\mathcal{O}}(S(A+B))$. The\nlatter result matches the information-theoretic lower bound in all\nproblem-dependent parameters except for a polynomial factor of the length of\neach episode. In addition, we present a computational hardness result for\nlearning the best responses against a fixed opponent in Markov games---a\nlearning objective different from finding the Nash equilibrium.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jun 2020 05:00:13 GMT"}, {"version": "v2", "created": "Tue, 14 Jul 2020 04:21:16 GMT"}], "update_date": "2020-07-15", "authors_parsed": [["Bai", "Yu", ""], ["Jin", "Chi", ""], ["Yu", "Tiancheng", ""]]}, {"id": "2006.12020", "submitter": "Stefan Sarkadi", "authors": "OHAAI Collaboration: Federico Castagna, Timotheus Kampik, Atefeh\n  Keshavarzi Zafarghandi, Micka\\\"el Lafages, Jack Mumford, Christos T.\n  Rodosthenous, Samy S\\'a, Stefan Sarkadi, Joseph Singleton, Kenneth Skiba,\n  Andreas Xydis", "title": "Online Handbook of Argumentation for AI: Volume 1", "comments": "editor: Federico Castagna and Francesca Mosca and Jack Mumford and\n  Stefan Sarkadi and Andreas Xydis", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This volume contains revised versions of the papers selected for the first\nvolume of the Online Handbook of Argumentation for AI (OHAAI). Previously,\nformal theories of argument and argument interaction have been proposed and\nstudied, and this has led to the more recent study of computational models of\nargument. Argumentation, as a field within artificial intelligence (AI), is\nhighly relevant for researchers interested in symbolic representations of\nknowledge and defeasible reasoning. The purpose of this handbook is to provide\nan open access and curated anthology for the argumentation research community.\nOHAAI is designed to serve as a research hub to keep track of the latest and\nupcoming PhD-driven research on the theory and application of argumentation in\nall areas related to AI.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jun 2020 06:07:13 GMT"}], "update_date": "2020-06-23", "authors_parsed": [["OHAAI Collaboration", "", ""], ["Castagna", "Federico", ""], ["Kampik", "Timotheus", ""], ["Zafarghandi", "Atefeh Keshavarzi", ""], ["Lafages", "Micka\u00ebl", ""], ["Mumford", "Jack", ""], ["Rodosthenous", "Christos T.", ""], ["S\u00e1", "Samy", ""], ["Sarkadi", "Stefan", ""], ["Singleton", "Joseph", ""], ["Skiba", "Kenneth", ""], ["Xydis", "Andreas", ""]]}, {"id": "2006.12117", "submitter": "Sheeba Samuel", "authors": "Sheeba Samuel, Frank L\\\"offler, Birgitta K\\\"onig-Ries", "title": "Machine Learning Pipelines: Provenance, Reproducibility and FAIR Data\n  Principles", "comments": "Accepted at ProvenanceWeek 2020\n  (https://iitdbgroup.github.io/ProvenanceWeek2020/)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Machine learning (ML) is an increasingly important scientific tool supporting\ndecision making and knowledge generation in numerous fields. With this, it also\nbecomes more and more important that the results of ML experiments are\nreproducible. Unfortunately, that often is not the case. Rather, ML, similar to\nmany other disciplines, faces a reproducibility crisis. In this paper, we\ndescribe our goals and initial steps in supporting the end-to-end\nreproducibility of ML pipelines. We investigate which factors beyond the\navailability of source code and datasets influence reproducibility of ML\nexperiments. We propose ways to apply FAIR data practices to ML workflows. We\npresent our preliminary results on the role of our tool, ProvBook, in capturing\nand comparing provenance of ML experiments and their reproducibility using\nJupyter Notebooks.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jun 2020 10:17:34 GMT"}], "update_date": "2020-06-23", "authors_parsed": [["Samuel", "Sheeba", ""], ["L\u00f6ffler", "Frank", ""], ["K\u00f6nig-Ries", "Birgitta", ""]]}, {"id": "2006.12122", "submitter": "Edward Grefenstette", "authors": "Andres Campero, Roberta Raileanu, Heinrich K\\\"uttler, Joshua B.\n  Tenenbaum, Tim Rockt\\\"aschel, Edward Grefenstette", "title": "Learning with AMIGo: Adversarially Motivated Intrinsic Goals", "comments": "18 pages, 6 figures, published at The Ninth International Conference\n  on Learning Representations (2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  A key challenge for reinforcement learning (RL) consists of learning in\nenvironments with sparse extrinsic rewards. In contrast to current RL methods,\nhumans are able to learn new skills with little or no reward by using various\nforms of intrinsic motivation. We propose AMIGo, a novel agent incorporating --\nas form of meta-learning -- a goal-generating teacher that proposes\nAdversarially Motivated Intrinsic Goals to train a goal-conditioned \"student\"\npolicy in the absence of (or alongside) environment reward. Specifically,\nthrough a simple but effective \"constructively adversarial\" objective, the\nteacher learns to propose increasingly challenging -- yet achievable -- goals\nthat allow the student to learn general skills for acting in a new environment,\nindependent of the task to be solved. We show that our method generates a\nnatural curriculum of self-proposed goals which ultimately allows the agent to\nsolve challenging procedurally-generated tasks where other forms of intrinsic\nmotivation and state-of-the-art RL methods fail.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jun 2020 10:22:08 GMT"}, {"version": "v2", "created": "Tue, 23 Feb 2021 07:57:41 GMT"}], "update_date": "2021-02-24", "authors_parsed": [["Campero", "Andres", ""], ["Raileanu", "Roberta", ""], ["K\u00fcttler", "Heinrich", ""], ["Tenenbaum", "Joshua B.", ""], ["Rockt\u00e4schel", "Tim", ""], ["Grefenstette", "Edward", ""]]}, {"id": "2006.12129", "submitter": "Mauro Vallati", "authors": "Daniel Harabor and Mauro Vallati", "title": "Organising a Successful AI Online Conference: Lessons from SoCS 2020", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The 13th Symposium on Combinatorial Search (SoCS) was held May 26-28, 2020.\nOriginally scheduled to take place in Vienna, Austria, the symposium pivoted\ntoward a fully online technical program in early March. As an in-person event\nSoCS offers participants a diverse array of scholarly activities including\ntechnical talks (long and short), poster sessions, plenary sessions, a\ncommunity meeting and, new for 2020, a Master Class tutorial program.\n  This paper describes challenges, approaches and opportunities associated with\nadapting these many different activities to the online setting. We consider\nissues such as scheduling, dissemination, attendee interaction and community\nengagement before, during and after the event. We report on the approaches\ntaken by SoCS in each case, we give a post-hoc analysis of their their\neffectiveness and we discuss how these decisions continue to impact the SoCS\ncommunity in the days after SoCS 2020.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jun 2020 10:34:06 GMT"}], "update_date": "2020-06-23", "authors_parsed": [["Harabor", "Daniel", ""], ["Vallati", "Mauro", ""]]}, {"id": "2006.12136", "submitter": "Matteo Turchetta", "authors": "Matteo Turchetta, Andrey Kolobov, Shital Shah, Andreas Krause, Alekh\n  Agarwal", "title": "Safe Reinforcement Learning via Curriculum Induction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In safety-critical applications, autonomous agents may need to learn in an\nenvironment where mistakes can be very costly. In such settings, the agent\nneeds to behave safely not only after but also while learning. To achieve this,\nexisting safe reinforcement learning methods make an agent rely on priors that\nlet it avoid dangerous situations during exploration with high probability, but\nboth the probabilistic guarantees and the smoothness assumptions inherent in\nthe priors are not viable in many scenarios of interest such as autonomous\ndriving. This paper presents an alternative approach inspired by human\nteaching, where an agent learns under the supervision of an automatic\ninstructor that saves the agent from violating constraints during learning. In\nthis model, we introduce the monitor that neither needs to know how to do well\nat the task the agent is learning nor needs to know how the environment works.\nInstead, it has a library of reset controllers that it activates when the agent\nstarts behaving dangerously, preventing it from doing damage. Crucially, the\nchoices of which reset controller to apply in which situation affect the speed\nof agent learning. Based on observing agents' progress, the teacher itself\nlearns a policy for choosing the reset controllers, a curriculum, to optimize\nthe agent's final policy reward. Our experiments use this framework in two\nenvironments to induce curricula for safe and efficient learning.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jun 2020 10:48:17 GMT"}, {"version": "v2", "created": "Thu, 21 Jan 2021 14:32:19 GMT"}], "update_date": "2021-01-22", "authors_parsed": [["Turchetta", "Matteo", ""], ["Kolobov", "Andrey", ""], ["Shah", "Shital", ""], ["Krause", "Andreas", ""], ["Agarwal", "Alekh", ""]]}, {"id": "2006.12323", "submitter": "Xu Ji", "authors": "Xu Ji, Joao Henriques, Tinne Tuytelaars, Andrea Vedaldi", "title": "Automatic Recall Machines: Internal Replay, Continual Learning and the\n  Brain", "comments": "NeurIPS 2020 Workshop on BabyMind", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Replay in neural networks involves training on sequential data with memorized\nsamples, which counteracts forgetting of previous behavior caused by\nnon-stationarity. We present a method where these auxiliary samples are\ngenerated on the fly, given only the model that is being trained for the\nassessed objective, without extraneous buffers or generator networks. Instead\nthe implicit memory of learned samples within the assessed model itself is\nexploited. Furthermore, whereas existing work focuses on reinforcing the full\nseen data distribution, we show that optimizing for not forgetting calls for\nthe generation of samples that are specialized to each real training batch,\nwhich is more efficient and scalable. We consider high-level parallels with the\nbrain, notably the use of a single model for inference and recall, the\ndependency of recalled samples on the current environment batch, top-down\nmodulation of activations and learning, abstract recall, and the dependency\nbetween the degree to which a task is learned and the degree to which it is\nrecalled. These characteristics emerge naturally from the method without being\ncontrolled for.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jun 2020 15:07:06 GMT"}, {"version": "v2", "created": "Wed, 15 Jul 2020 15:17:33 GMT"}, {"version": "v3", "created": "Sat, 12 Dec 2020 17:58:30 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["Ji", "Xu", ""], ["Henriques", "Joao", ""], ["Tuytelaars", "Tinne", ""], ["Vedaldi", "Andrea", ""]]}, {"id": "2006.12328", "submitter": "Joeran Beel", "authors": "Joeran Beel, Bryan Tyrell, Edward Bergman, Andrew Collins, Shahad\n  Nagoor", "title": "Siamese Meta-Learning and Algorithm Selection with\n  'Algorithm-Performance Personas' [Proposal]", "comments": "7th Workshop on Automated Machine Learning (AutoML 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automated per-instance algorithm selection often outperforms single learners.\nKey to algorithm selection via meta-learning is often the (meta) features,\nwhich sometimes though do not provide enough information to train a\nmeta-learner effectively. We propose a Siamese Neural Network architecture for\nautomated algorithm selection that focuses more on 'alike performing' instances\nthan meta-features. Our work includes a novel performance metric and method for\nselecting training samples. We introduce further the concept of 'Algorithm\nPerformance Personas' that describe instances for which the single algorithms\nperform alike. The concept of 'alike performing algorithms' as ground truth for\nselecting training samples is novel and provides a huge potential as we\nbelieve. In this proposal, we outline our ideas in detail and provide the first\nevidence that our proposed metric is better suitable for training sample\nselection that standard performance metrics such as absolute errors.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jun 2020 15:12:21 GMT"}, {"version": "v2", "created": "Tue, 23 Jun 2020 09:27:59 GMT"}], "update_date": "2020-06-24", "authors_parsed": [["Beel", "Joeran", ""], ["Tyrell", "Bryan", ""], ["Bergman", "Edward", ""], ["Collins", "Andrew", ""], ["Nagoor", "Shahad", ""]]}, {"id": "2006.12344", "submitter": "Willian T. Lunardi", "authors": "Willian T. Lunardi, Ernesto G. Birgin, D\\'ebora P. Ronconi, Holger\n  Voos", "title": "Metaheuristics for the Online Printing Shop Scheduling Problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, the online printing shop scheduling problem introduced in\n(Lunardi et al., Mixed Integer Linear Programming and Constraint Programming\nModels for the Online Printing Shop Scheduling Problem, Computers & Operations\nResearch, to appear) is considered. This challenging real scheduling problem,\nthat emerged in the nowadays printing industry, corresponds to a flexible job\nshop scheduling problem with sequencing flexibility; and it presents several\ncomplicating specificities such as resumable operations, periods of\nunavailability of the machines, sequence-dependent setup times, partial\noverlapping between operations with precedence constraints, and fixed\noperations, among others. A local search strategy and metaheuristic approaches\nfor the problem are proposed and evaluated. Based on a common representation\nscheme, trajectory and populational metaheuristics are considered. Extensive\nnumerical experiments with large-sized instances show that the proposed methods\nare suitable for solving practical instances of the problem; and that they\noutperform a half-heuristic-half-exact off-the-shelf solver by a large extent.\nNumerical experiments with classical instances of the flexible job shop\nscheduling problem show that the introduced methods are also competitive when\napplied to this particular case.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jun 2020 15:38:00 GMT"}], "update_date": "2020-06-23", "authors_parsed": [["Lunardi", "Willian T.", ""], ["Birgin", "Ernesto G.", ""], ["Ronconi", "D\u00e9bora P.", ""], ["Voos", "Holger", ""]]}, {"id": "2006.12362", "submitter": "Cristiana Santos", "authors": "George Anthony Gal, Cristiana Santos, Lucien Rapp, R\\'eeka Markovich\n  and Leendert van der Torre", "title": "Artificial intelligence in space", "comments": "32 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In the next coming years, space activities are expected to undergo a radical\ntransformation with the emergence of new satellite systems or new services\nwhich will incorporate the contributions of artificial intelligence and machine\nlearning defined as covering a wide range of innovations from autonomous\nobjects with their own decision-making power to increasingly sophisticated\nservices exploiting very large volumes of information from space. This chapter\nidentifies some of the legal and ethical challenges linked to its use. These\nlegal and ethical challenges call for solutions which the international\ntreaties in force are not sufficient to determine and implement. For this\nreason, a legal methodology must be developed that makes it possible to link\nintelligent systems and services to a system of rules applicable thereto. It\ndiscusses existing legal AI-based tools amenable for making space law\nactionable, interoperable and machine readable for future compliance tools.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jun 2020 16:00:44 GMT"}], "update_date": "2020-06-23", "authors_parsed": [["Gal", "George Anthony", ""], ["Santos", "Cristiana", ""], ["Rapp", "Lucien", ""], ["Markovich", "R\u00e9eka", ""], ["van der Torre", "Leendert", ""]]}, {"id": "2006.12366", "submitter": "Neil Vaughan", "authors": "Neil Vaughan, Bogdan Gabrys", "title": "Scoring and Assessment in Medical VR Training Simulators with Dynamic\n  Time Series Classification", "comments": "Copyright 2020. This manuscript version is made available under\n  CC-BY-NC-ND 4.0 license http://creativecommons.org/licenses/by-nc-nd/4.0/", "journal-ref": "Engineering Applications of Artificial Intelligence (2020) 103760", "doi": "10.1016/j.engappai.2020.103760", "report-no": null, "categories": "eess.SP cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This research proposes and evaluates scoring and assessment methods for\nVirtual Reality (VR) training simulators. VR simulators capture detailed\nn-dimensional human motion data which is useful for performance analysis.\nCustom made medical haptic VR training simulators were developed and used to\nrecord data from 271 trainees of multiple clinical experience levels. DTW\nMultivariate Prototyping (DTW-MP) is proposed. VR data was classified as\nNovice, Intermediate or Expert. Accuracy of algorithms applied for time-series\nclassification were: dynamic time warping 1-nearest neighbor (DTW-1NN) 60%,\nnearest centroid SoftDTW classification 77.5%, Deep Learning: ResNet 85%, FCN\n75%, CNN 72.5% and MCDCNN 28.5%. Expert VR data recordings can be used for\nguidance of novices. Assessment feedback can help trainees to improve skills\nand consistency. Motion analysis can identify different techniques used by\nindividuals. Mistakes can be detected dynamically in real-time, raising alarms\nto prevent injuries.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jun 2020 15:46:25 GMT"}], "update_date": "2020-06-23", "authors_parsed": [["Vaughan", "Neil", ""], ["Gabrys", "Bogdan", ""]]}, {"id": "2006.12425", "submitter": "Shan Li", "authors": "Shan Li, Baoxu Shi, Jaewon Yang, Ji Yan, Shuai Wang, Fei Chen, Qi He", "title": "Deep Job Understanding at LinkedIn", "comments": "4 pages, to appear in SIGIR2020", "journal-ref": null, "doi": "10.1145/3397271.3401403", "report-no": null, "categories": "cs.IR cs.AI cs.CL cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As the world's largest professional network, LinkedIn wants to create\neconomic opportunity for everyone in the global workforce. One of its most\ncritical missions is matching jobs with processionals. Improving job targeting\naccuracy and hire efficiency align with LinkedIn's Member First Motto. To\nachieve those goals, we need to understand unstructured job postings with noisy\ninformation. We applied deep transfer learning to create domain-specific job\nunderstanding models. After this, jobs are represented by professional\nentities, including titles, skills, companies, and assessment questions. To\ncontinuously improve LinkedIn's job understanding ability, we designed an\nexpert feedback loop where we integrated job understanding models into\nLinkedIn's products to collect job posters' feedback. In this demonstration, we\npresent LinkedIn's job posting flow and demonstrate how the integrated deep job\nunderstanding work improves job posters' satisfaction and provides significant\nmetric lifts in LinkedIn's job recommendation system.\n", "versions": [{"version": "v1", "created": "Fri, 29 May 2020 20:04:59 GMT"}], "update_date": "2020-06-23", "authors_parsed": [["Li", "Shan", ""], ["Shi", "Baoxu", ""], ["Yang", "Jaewon", ""], ["Yan", "Ji", ""], ["Wang", "Shuai", ""], ["Chen", "Fei", ""], ["He", "Qi", ""]]}, {"id": "2006.12442", "submitter": "Stephen Roller", "authors": "Stephen Roller, Y-Lan Boureau, Jason Weston, Antoine Bordes, Emily\n  Dinan, Angela Fan, David Gunning, Da Ju, Margaret Li, Spencer Poff, Pratik\n  Ringshia, Kurt Shuster, Eric Michael Smith, Arthur Szlam, Jack Urbanek, Mary\n  Williamson", "title": "Open-Domain Conversational Agents: Current Progress, Open Problems, and\n  Future Directions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present our view of what is necessary to build an engaging open-domain\nconversational agent: covering the qualities of such an agent, the pieces of\nthe puzzle that have been built so far, and the gaping holes we have not filled\nyet. We present a biased view, focusing on work done by our own group, while\nciting related work in each area. In particular, we discuss in detail the\nproperties of continual learning, providing engaging content, and being\nwell-behaved -- and how to measure success in providing them. We end with a\ndiscussion of our experience and learnings, and our recommendations to the\ncommunity.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jun 2020 17:23:47 GMT"}, {"version": "v2", "created": "Mon, 13 Jul 2020 17:35:31 GMT"}], "update_date": "2020-07-14", "authors_parsed": [["Roller", "Stephen", ""], ["Boureau", "Y-Lan", ""], ["Weston", "Jason", ""], ["Bordes", "Antoine", ""], ["Dinan", "Emily", ""], ["Fan", "Angela", ""], ["Gunning", "David", ""], ["Ju", "Da", ""], ["Li", "Margaret", ""], ["Poff", "Spencer", ""], ["Ringshia", "Pratik", ""], ["Shuster", "Kurt", ""], ["Smith", "Eric Michael", ""], ["Szlam", "Arthur", ""], ["Urbanek", "Jack", ""], ["Williamson", "Mary", ""]]}, {"id": "2006.12453", "submitter": "D Bayani", "authors": "David Bayani (1), Stefan Mitsch (1) ((1) Carnegie Mellon University)", "title": "Fanoos: Multi-Resolution, Multi-Strength, Interactive Explanations for\n  Learned Systems", "comments": "52 pages, 19 pages main body, 90 references, 3 figures, 5 tables, 12\n  pseudocode blocks Update 24 Sep. 2020 : Added a pointer to further, external\n  content: Append Section E. Update 20 Mar. 2021: Substantial additions.\n  Further explanations of process, with far more pseudocode. Some corrections\n  to a previous description; see errata section. Also briefly describe a few\n  implemented extensions", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.HC cs.LG cs.NE cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning becomes increasingly important to control the behavior of\nsafety and financially critical components in sophisticated environments, where\nthe inability to understand learned components in general, and neural nets in\nparticular, poses serious obstacles to their adoption. Explainability and\ninterpretability methods for learned systems have gained considerable academic\nattention, but the focus of current approaches on only one aspect of\nexplanation, at a fixed level of abstraction, and limited if any formal\nguarantees, prevents those explanations from being digestible by the relevant\nstakeholders (e.g., end users, certification authorities, engineers) with their\ndiverse backgrounds and situation-specific needs. We introduce Fanoos, a\nflexible framework for combining formal verification techniques, heuristic\nsearch, and user interaction to explore explanations at the desired level of\ngranularity and fidelity. We demonstrate the ability of Fanoos to produce and\nadjust the abstractness of explanations in response to user requests on a\nlearned controller for an inverted double pendulum and on a learned CPU usage\nmodel.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jun 2020 17:35:53 GMT"}, {"version": "v2", "created": "Thu, 24 Sep 2020 05:13:25 GMT"}, {"version": "v3", "created": "Sun, 25 Oct 2020 04:12:45 GMT"}, {"version": "v4", "created": "Sat, 20 Mar 2021 07:30:47 GMT"}, {"version": "v5", "created": "Wed, 14 Apr 2021 01:03:32 GMT"}, {"version": "v6", "created": "Tue, 27 Apr 2021 07:49:17 GMT"}, {"version": "v7", "created": "Wed, 28 Apr 2021 08:59:42 GMT"}], "update_date": "2021-04-29", "authors_parsed": [["Bayani", "David", "", "Carnegie Mellon University"], ["Mitsch", "Stefan", "", "Carnegie Mellon University"]]}, {"id": "2006.12478", "submitter": "John Co-Reyes", "authors": "John D. Co-Reyes, Suvansh Sanjeev, Glen Berseth, Abhishek Gupta,\n  Sergey Levine", "title": "Ecological Reinforcement Learning", "comments": "Preprint. Website at:\n  https://sites.google.com/view/ecological-rl/home", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Much of the current work on reinforcement learning studies episodic settings,\nwhere the agent is reset between trials to an initial state distribution, often\nwith well-shaped reward functions. Non-episodic settings, where the agent must\nlearn through continuous interaction with the world without resets, and where\nthe agent receives only delayed and sparse reward signals, is substantially\nmore difficult, but arguably more realistic considering real-world environments\ndo not present the learner with a convenient \"reset mechanism\" and easy reward\nshaping. In this paper, instead of studying algorithmic improvements that can\naddress such non-episodic and sparse reward settings, we instead study the\nkinds of environment properties that can make learning under such conditions\neasier. Understanding how properties of the environment impact the performance\nof reinforcement learning agents can help us to structure our tasks in ways\nthat make learning tractable. We first discuss what we term \"environment\nshaping\" -- modifications to the environment that provide an alternative to\nreward shaping, and may be easier to implement. We then discuss an even simpler\nproperty that we refer to as \"dynamism,\" which describes the degree to which\nthe environment changes independent of the agent's actions and can be measured\nby environment transition entropy. Surprisingly, we find that even this\nproperty can substantially alleviate the challenges associated with\nnon-episodic RL in sparse reward settings. We provide an empirical evaluation\non a set of new tasks focused on non-episodic learning with sparse rewards.\nThrough this study, we hope to shift the focus of the community towards\nanalyzing how properties of the environment can affect learning and the\nultimate type of behavior that is learned via RL.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jun 2020 17:55:03 GMT"}], "update_date": "2020-06-23", "authors_parsed": [["Co-Reyes", "John D.", ""], ["Sanjeev", "Suvansh", ""], ["Berseth", "Glen", ""], ["Gupta", "Abhishek", ""], ["Levine", "Sergey", ""]]}, {"id": "2006.12484", "submitter": "Qinghua Liu", "authors": "Chi Jin, Sham M. Kakade, Akshay Krishnamurthy, Qinghua Liu", "title": "Sample-Efficient Reinforcement Learning of Undercomplete POMDPs", "comments": "To appear at NeurIPS 2020 as spotlight", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Partial observability is a common challenge in many reinforcement learning\napplications, which requires an agent to maintain memory, infer latent states,\nand integrate this past information into exploration. This challenge leads to a\nnumber of computational and statistical hardness results for learning general\nPartially Observable Markov Decision Processes (POMDPs). This work shows that\nthese hardness barriers do not preclude efficient reinforcement learning for\nrich and interesting subclasses of POMDPs. In particular, we present a\nsample-efficient algorithm, OOM-UCB, for episodic finite undercomplete POMDPs,\nwhere the number of observations is larger than the number of latent states and\nwhere exploration is essential for learning, thus distinguishing our results\nfrom prior works. OOM-UCB achieves an optimal sample complexity of\n$\\tilde{\\mathcal{O}}(1/\\varepsilon^2)$ for finding an $\\varepsilon$-optimal\npolicy, along with being polynomial in all other relevant quantities. As an\ninteresting special case, we also provide a computationally and statistically\nefficient algorithm for POMDPs with deterministic state transitions.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jun 2020 17:58:54 GMT"}, {"version": "v2", "created": "Sun, 25 Oct 2020 03:22:02 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Jin", "Chi", ""], ["Kakade", "Sham M.", ""], ["Krishnamurthy", "Akshay", ""], ["Liu", "Qinghua", ""]]}, {"id": "2006.12497", "submitter": "Alexander Lavin", "authors": "Alexander Lavin and Gregory Renard", "title": "Technology Readiness Levels for AI & ML", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The development and deployment of machine learning systems can be executed\neasily with modern tools, but the process is typically rushed and\nmeans-to-an-end. The lack of diligence can lead to technical debt, scope creep\nand misaligned objectives, model misuse and failures, and expensive\nconsequences. Engineering systems, on the other hand, follow well-defined\nprocesses and testing standards to streamline development for high-quality,\nreliable results. The extreme is spacecraft systems, where mission critical\nmeasures and robustness are ingrained in the development process. Drawing on\nexperience in both spacecraft engineering and AI/ML (from research through\nproduct), we propose a proven systems engineering approach for machine learning\ndevelopment and deployment. Our Technology Readiness Levels for ML (TRL4ML)\nframework defines a principled process to ensure robust systems while being\nstreamlined for ML research and product, including key distinctions from\ntraditional software engineering. Even more, TRL4ML defines a common language\nfor people across the organization to work collaboratively on ML technologies.\n", "versions": [{"version": "v1", "created": "Sun, 21 Jun 2020 17:14:34 GMT"}, {"version": "v2", "created": "Sat, 4 Jul 2020 00:54:51 GMT"}, {"version": "v3", "created": "Wed, 16 Dec 2020 14:47:51 GMT"}], "update_date": "2020-12-17", "authors_parsed": [["Lavin", "Alexander", ""], ["Renard", "Gregory", ""]]}, {"id": "2006.12551", "submitter": "Corban Rivera", "authors": "Corban G. Rivera, Katie M. Popek, Chace Ashcraft, Edward W. Staley,\n  Kapil D. Katyal, Bart L. Paulhamus", "title": "PICO: Primitive Imitation for COntrol", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we explore a novel framework for control of complex systems\ncalled Primitive Imitation for Control PICO. The approach combines ideas from\nimitation learning, task decomposition, and novel task sequencing to generalize\nfrom demonstrations to new behaviors. Demonstrations are automatically\ndecomposed into existing or missing sub-behaviors which allows the framework to\nidentify novel behaviors while not duplicating existing behaviors.\nGeneralization to new tasks is achieved through dynamic blending of behavior\nprimitives. We evaluated the approach using demonstrations from two different\nrobotic platforms. The experimental results show that PICO is able to detect\nthe presence of a novel behavior primitive and build the missing control\npolicy.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jun 2020 18:23:46 GMT"}], "update_date": "2020-06-25", "authors_parsed": [["Rivera", "Corban G.", ""], ["Popek", "Katie M.", ""], ["Ashcraft", "Chace", ""], ["Staley", "Edward W.", ""], ["Katyal", "Kapil D.", ""], ["Paulhamus", "Bart L.", ""]]}, {"id": "2006.12587", "submitter": "Thomas Rausch", "authors": "Thomas Rausch and Waldemar Hummer and Vinod Muthusamy", "title": "PipeSim: Trace-driven Simulation of Large-Scale AI Operations Platforms", "comments": "11 pages, 13 figures, extended version of OpML'20 paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.AI cs.LG cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Operationalizing AI has become a major endeavor in both research and\nindustry. Automated, operationalized pipelines that manage the AI application\nlifecycle will form a significant part of tomorrow's infrastructure workloads.\nTo optimize operations of production-grade AI workflow platforms we can\nleverage existing scheduling approaches, yet it is challenging to fine-tune\noperational strategies that achieve application-specific cost-benefit tradeoffs\nwhile catering to the specific domain characteristics of machine learning (ML)\nmodels, such as accuracy, robustness, or fairness. We present a trace-driven\nsimulation-based experimentation and analytics environment that allows\nresearchers and engineers to devise and evaluate such operational strategies\nfor large-scale AI workflow systems. Analytics data from a production-grade AI\nplatform developed at IBM are used to build a comprehensive simulation model.\nOur simulation model describes the interaction between pipelines and system\ninfrastructure, and how pipeline tasks affect different ML model metrics. We\nimplement the model in a standalone, stochastic, discrete event simulator, and\nprovide a toolkit for running experiments. Synthetic traces are made available\nfor ad-hoc exploration as well as statistical analysis of experiments to test\nand examine pipeline scheduling, cluster resource allocation, and similar\noperational mechanisms.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jun 2020 19:55:37 GMT"}], "update_date": "2020-06-24", "authors_parsed": [["Rausch", "Thomas", ""], ["Hummer", "Waldemar", ""], ["Muthusamy", "Vinod", ""]]}, {"id": "2006.12616", "submitter": "Guido Schillaci", "authors": "Guido Schillaci and Luis Miranda and Uwe Schmidt", "title": "Prediction error-driven memory consolidation for continual learning. On\n  the case of adaptive greenhouse models", "comments": "Revised version. Paper under review, submitted to Springer German\n  Journal on Artificial Intelligence (K\\\"unstliche Intelligenz), Special Issue\n  on Developmental Robotics", "journal-ref": null, "doi": "10.1007/s13218-020-00700-8", "report-no": null, "categories": "q-bio.NC cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This work presents an adaptive architecture that performs online learning and\nfaces catastrophic forgetting issues by means of episodic memories and\nprediction-error driven memory consolidation. In line with evidences from the\ncognitive science and neuroscience, memories are retained depending on their\ncongruency with the prior knowledge stored in the system. This is estimated in\nterms of prediction error resulting from a generative model. Moreover, this AI\nsystem is transferred onto an innovative application in the horticulture\nindustry: the learning and transfer of greenhouse models. This work presents a\nmodel trained on data recorded from research facilities and transferred to a\nproduction greenhouse.\n", "versions": [{"version": "v1", "created": "Tue, 19 May 2020 15:22:53 GMT"}, {"version": "v2", "created": "Mon, 27 Jul 2020 11:16:28 GMT"}], "update_date": "2021-01-29", "authors_parsed": [["Schillaci", "Guido", ""], ["Miranda", "Luis", ""], ["Schmidt", "Uwe", ""]]}, {"id": "2006.12620", "submitter": "Nevena Lazic", "authors": "Nevena Lazic, Dong Yin, Mehrdad Farajtabar, Nir Levine, Dilan Gorur,\n  Chris Harris, Dale Schuurmans", "title": "A maximum-entropy approach to off-policy evaluation in average-reward\n  MDPs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work focuses on off-policy evaluation (OPE) with function approximation\nin infinite-horizon undiscounted Markov decision processes (MDPs). For MDPs\nthat are ergodic and linear (i.e. where rewards and dynamics are linear in some\nknown features), we provide the first finite-sample OPE error bound, extending\nexisting results beyond the episodic and discounted cases. In a more general\nsetting, when the feature dynamics are approximately linear and for arbitrary\nrewards, we propose a new approach for estimating stationary distributions with\nfunction approximation. We formulate this problem as finding the\nmaximum-entropy distribution subject to matching feature expectations under\nempirical dynamics. We show that this results in an exponential-family\ndistribution whose sufficient statistics are the features, paralleling\nmaximum-entropy approaches in supervised learning. We demonstrate the\neffectiveness of the proposed OPE approaches in multiple environments.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jun 2020 18:13:37 GMT"}], "update_date": "2020-06-24", "authors_parsed": [["Lazic", "Nevena", ""], ["Yin", "Dong", ""], ["Farajtabar", "Mehrdad", ""], ["Levine", "Nir", ""], ["Gorur", "Dilan", ""], ["Harris", "Chris", ""], ["Schuurmans", "Dale", ""]]}, {"id": "2006.12622", "submitter": "Qiang He", "authors": "Qiang He, Xinwen Hou", "title": "Reducing Estimation Bias via Weighted Delayed Deep Deterministic Policy\n  Gradient", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The overestimation phenomenon caused by function approximation is a\nwell-known issue in value-based reinforcement learning algorithms such as deep\nQ-networks and DDPG, which could lead to suboptimal policies. To address this\nissue, TD3 takes the minimum value between a pair of critics, which introduces\nunderestimation bias. By unifying these two opposites, we propose a novel\nWeighted Delayed Deep Deterministic Policy Gradient algorithm, which can reduce\nthe estimation error and further improve the performance by weighting a pair of\ncritics. We compare the learning process of value function between DDPG, TD3,\nand our proposed algorithm, which verifies that our algorithm could indeed\neliminate the estimation error of value function. We evaluate our algorithm in\nthe OpenAI Gym continuous control tasks, outperforming the state-of-the-art\nalgorithms on every environment tested.\n", "versions": [{"version": "v1", "created": "Thu, 18 Jun 2020 01:28:07 GMT"}], "update_date": "2020-06-24", "authors_parsed": [["He", "Qiang", ""], ["Hou", "Xinwen", ""]]}, {"id": "2006.12632", "submitter": "Benjamin Krarup", "authors": "Benjamin Krarup, Senka Krivic, Felix Lindner, Derek Long", "title": "Towards Contrastive Explanations for Comparing the Ethics of Plans", "comments": "Accepted to the ICRA-AGAINST-20 workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The development of robotics and AI agents has enabled their wider usage in\nhuman surroundings. AI agents are more trusted to make increasingly important\ndecisions with potentially critical outcomes. It is essential to consider the\nethical consequences of the decisions made by these systems. In this paper, we\npresent how contrastive explanations can be used for comparing the ethics of\nplans. We build upon an existing ethical framework to allow users to make\nsuggestions to plans and receive contrastive explanations.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jun 2020 21:38:16 GMT"}], "update_date": "2020-06-24", "authors_parsed": [["Krarup", "Benjamin", ""], ["Krivic", "Senka", ""], ["Lindner", "Felix", ""], ["Long", "Derek", ""]]}, {"id": "2006.12638", "submitter": "Ashish Tiwari", "authors": "Ashish Tiwari, Arjun Radhakrishna, Sumit Gulwani, and Daniel Perelman", "title": "Information-theoretic User Interaction: Significant Inputs for Program\n  Synthesis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Programming-by-example technologies are being deployed in industrial products\nfor real-time synthesis of various kinds of data transformations. These\ntechnologies rely on the user to provide few representative examples of the\ntransformation task. Motivated by the need to find the most pertinent question\nto ask the user, in this paper, we introduce the {\\em significant questions\nproblem}, and show that it is hard in general. We then develop an\ninformation-theoretic greedy approach for solving the problem. We justify the\ngreedy algorithm using the conditional entropy result, which informally says\nthat the question that achieves the maximum information gain is the one that we\nknow least about.\n  In the context of interactive program synthesis, we use the above result to\ndevelop an {\\em{active program learner}} that generates the significant inputs\nto pose as queries to the user in each iteration. The procedure requires\nextending a {\\em{passive program learner}} to a {\\em{sampling program learner}}\nthat is able to sample candidate programs from the set of all consistent\nprograms to enable estimation of information gain. It also uses clustering of\ninputs based on features in the inputs and the corresponding outputs to sample\na small set of candidate significant inputs. Our active learner is able to\ntradeoff false negatives for false positives and converge in a small number of\niterations on a real-world dataset of %around 800 string transformation tasks.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jun 2020 21:46:40 GMT"}], "update_date": "2020-06-24", "authors_parsed": [["Tiwari", "Ashish", ""], ["Radhakrishna", "Arjun", ""], ["Gulwani", "Sumit", ""], ["Perelman", "Daniel", ""]]}, {"id": "2006.12692", "submitter": "Lingheng Meng", "authors": "Lingheng Meng, Rob Gorbet, Dana Kuli\\'c", "title": "The Effect of Multi-step Methods on Overestimation in Deep Reinforcement\n  Learning", "comments": "7 pages, 4 figures, the 25th International Conference on Pattern\n  Recognition (ICPR)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-step (also called n-step) methods in reinforcement learning (RL) have\nbeen shown to be more efficient than the 1-step method due to faster\npropagation of the reward signal, both theoretically and empirically, in tasks\nexploiting tabular representation of the value-function. Recently, research in\nDeep Reinforcement Learning (DRL) also shows that multi-step methods improve\nlearning speed and final performance in applications where the value-function\nand policy are represented with deep neural networks. However, there is a lack\nof understanding about what is actually contributing to the boost of\nperformance. In this work, we analyze the effect of multi-step methods on\nalleviating the overestimation problem in DRL, where multi-step experiences are\nsampled from a replay buffer. Specifically building on top of Deep\nDeterministic Policy Gradient (DDPG), we propose Multi-step DDPG (MDDPG), where\ndifferent step sizes are manually set, and its variant called Mixed Multi-step\nDDPG (MMDDPG) where an average over different multi-step backups is used as\nupdate target of Q-value function. Empirically, we show that both MDDPG and\nMMDDPG are significantly less affected by the overestimation problem than DDPG\nwith 1-step backup, which consequently results in better final performance and\nlearning speed. We also discuss the advantages and disadvantages of different\nways to do multi-step expansion in order to reduce approximation error, and\nexpose the tradeoff between overestimation and underestimation that underlies\noffline multi-step methods. Finally, we compare the computational resource\nneeds of Twin Delayed Deep Deterministic Policy Gradient (TD3), a state-of-art\nalgorithm proposed to address overestimation in actor-critic methods, and our\nproposed methods, since they show comparable final performance and learning\nspeed.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jun 2020 01:35:54 GMT"}], "update_date": "2020-06-24", "authors_parsed": [["Meng", "Lingheng", ""], ["Gorbet", "Rob", ""], ["Kuli\u0107", "Dana", ""]]}, {"id": "2006.12694", "submitter": "George Monta\\~nez", "authors": "Jake Williams, Abel Tadesse, Tyler Sam, Huey Sun, George D. Montanez", "title": "Limits of Transfer Learning", "comments": "Accepted for presentation at the Sixth International Conference on\n  Machine Learning, Optimization, and Data Science (LOD 2020), July 19-23, 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transfer learning involves taking information and insight from one problem\ndomain and applying it to a new problem domain. Although widely used in\npractice, theory for transfer learning remains less well-developed. To address\nthis, we prove several novel results related to transfer learning, showing the\nneed to carefully select which sets of information to transfer and the need for\ndependence between transferred information and target problems. Furthermore, we\nprove how the degree of probabilistic change in an algorithm using transfer\nlearning places an upper bound on the amount of improvement possible. These\nresults build on the algorithmic search framework for machine learning,\nallowing the results to apply to a wide range of learning problems using\ntransfer.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jun 2020 01:48:23 GMT"}], "update_date": "2020-06-24", "authors_parsed": [["Williams", "Jake", ""], ["Tadesse", "Abel", ""], ["Sam", "Tyler", ""], ["Sun", "Huey", ""], ["Montanez", "George D.", ""]]}, {"id": "2006.12698", "submitter": "Saichethan Reddy", "authors": "Saichethan Miriyala Reddy and Saisree Miriyala", "title": "Security and Privacy Preserving Deep Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Commercial companies that collect user data on a large scale have been the\nmain beneficiaries of this trend since the success of deep learning techniques\nis directly proportional to the amount of data available for training. Massive\ndata collection required for deep learning presents obvious privacy issues.\nUsers personal, highly sensitive data such as photos and voice recordings are\nkept indefinitely by the companies that collect it. Users can neither delete it\nnor restrict the purposes for which it is used. So, data privacy has been a\nvery important concern for governments and companies these days. It gives rise\nto a very interesting challenge since on the one hand, we are pushing further\nand further for high-quality models and accessible data, but on the other hand,\nwe need to keep data safe from both intentional and accidental leakage. The\nmore personal the data is it is more restricted it means some of the most\nimportant social issues cannot be addressed using machine learning because\nresearchers do not have access to proper training data. But by learning how to\nmachine learning that protects privacy we can make a huge difference in solving\nmany social issues like curing disease etc. Deep neural networks are\nsusceptible to various inference attacks as they remember information about\ntheir training data. In this chapter, we introduce differential privacy, which\nensures that different kinds of statistical analyses dont compromise privacy\nand federated learning, training a machine learning model on a data to which we\ndo not have access to.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jun 2020 01:53:46 GMT"}, {"version": "v2", "created": "Mon, 29 Jun 2020 09:34:12 GMT"}], "update_date": "2020-06-30", "authors_parsed": [["Reddy", "Saichethan Miriyala", ""], ["Miriyala", "Saisree", ""]]}, {"id": "2006.12719", "submitter": "Shikib Mehri", "authors": "Shikib Mehri and Maxine Eskenazi", "title": "Unsupervised Evaluation of Interactive Dialog with DialoGPT", "comments": "Published at to SIGdial 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is important to define meaningful and interpretable automatic evaluation\nmetrics for open-domain dialog research. Standard language generation metrics\nhave been shown to be ineffective for dialog. This paper introduces the FED\nmetric (fine-grained evaluation of dialog), an automatic evaluation metric\nwhich uses DialoGPT, without any fine-tuning or supervision. It also introduces\nthe FED dataset which is constructed by annotating a set of human-system and\nhuman-human conversations with eighteen fine-grained dialog qualities. The FED\nmetric (1) does not rely on a ground-truth response, (2) does not require\ntraining data and (3) measures fine-grained dialog qualities at both the turn\nand whole dialog levels. FED attains moderate to strong correlation with human\njudgement at both levels.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jun 2020 03:36:09 GMT"}], "update_date": "2020-06-25", "authors_parsed": [["Mehri", "Shikib", ""], ["Eskenazi", "Maxine", ""]]}, {"id": "2006.12756", "submitter": "Kinjal Basu", "authors": "Kinjal Basu, Cyrus DiCiccio, Heloise Logan, Noureddine El Karoui", "title": "A Framework for Fairness in Two-Sided Marketplaces", "comments": "15 pages, 7 Tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many interesting problems in the Internet industry can be framed as a\ntwo-sided marketplace problem. Examples include search applications and\nrecommender systems showing people, jobs, movies, products, restaurants, etc.\nIncorporating fairness while building such systems is crucial and can have a\ndeep social and economic impact (applications include job recommendations,\nrecruiters searching for candidates, etc.). In this paper, we propose a\ndefinition and develop an end-to-end framework for achieving fairness while\nbuilding such machine learning systems at scale. We extend prior work to\ndevelop an optimization framework that can tackle fairness constraints from\nboth the source and destination sides of the marketplace, as well as dynamic\naspects of the problem. The framework is flexible enough to adapt to different\ndefinitions of fairness and can be implemented in very large-scale settings. We\nperform simulations to show the efficacy of our approach.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jun 2020 04:47:37 GMT"}], "update_date": "2020-06-24", "authors_parsed": [["Basu", "Kinjal", ""], ["DiCiccio", "Cyrus", ""], ["Logan", "Heloise", ""], ["Karoui", "Noureddine El", ""]]}, {"id": "2006.12769", "submitter": "Ziran Wang", "authors": "Zhenyu Shou and Ziran Wang and Kyungtae Han and Yongkang Liu and\n  Prashant Tiwari and Xuan Di", "title": "Long-Term Prediction of Lane Change Maneuver Through a Multilayer\n  Perceptron", "comments": "Accepted by 31st IEEE Intelligent Vehicles Symposium", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Behavior prediction plays an essential role in both autonomous driving\nsystems and Advanced Driver Assistance Systems (ADAS), since it enhances\nvehicle's awareness of the imminent hazards in the surrounding environment.\nMany existing lane change prediction models take as input lateral or angle\ninformation and make short-term (< 5 seconds) maneuver predictions. In this\nstudy, we propose a longer-term (5~10 seconds) prediction model without any\nlateral or angle information. Three prediction models are introduced, including\na logistic regression model, a multilayer perceptron (MLP) model, and a\nrecurrent neural network (RNN) model, and their performances are compared by\nusing the real-world NGSIM dataset. To properly label the trajectory data, this\nstudy proposes a new time-window labeling scheme by adding a time gap between\npositive and negative samples. Two approaches are also proposed to address the\nunstable prediction issue, where the aggressive approach propagates each\npositive prediction for certain seconds, while the conservative approach adopts\na roll-window average to smooth the prediction. Evaluation results show that\nthe developed prediction model is able to capture 75% of real lane change\nmaneuvers with an average advanced prediction time of 8.05 seconds.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jun 2020 05:32:40 GMT"}], "update_date": "2020-06-24", "authors_parsed": [["Shou", "Zhenyu", ""], ["Wang", "Ziran", ""], ["Han", "Kyungtae", ""], ["Liu", "Yongkang", ""], ["Tiwari", "Prashant", ""], ["Di", "Xuan", ""]]}, {"id": "2006.12789", "submitter": "Christoph Benzm\\\"uller", "authors": "Christoph Benzm\\\"uller and David Fuenmayor and Bertram Lomfeld", "title": "Encoding Legal Balancing: Automating an Abstract Ethico-Legal Value\n  Ontology in Preference Logic", "comments": "46 pages, 18 figures; extended and improved version of our\n  contribution to the 1st Workshop on Models of Legal Reasoning (MLR 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Enabling machines to legal balancing is a non-trivial task challenged by a\nmultitude of factors some of which are addressed and explored in this work. We\npropose a holistic approach to formal modelling at different abstraction layers\nsupported by a pluralistic framework in which the encoding of an ethico-legal\nvalue ontology is developed in combination with the exploration of a\nformalisation logic, with legal domain knowledge and with exemplary use cases\nuntil a reflective equilibrium is reached. Our work is enabled by a\nmeta-logical approach to universal logical reasoning and it applies the\nrecently introduced LOGIKEY methodology for designing normative theories for\nethical and legal reasoning. We explore and illustrate the application of the\nmultilayered LOGIKEY approach for the modelling of legal and world knowledge\nthat is constrained by context-dependent value preferences. The framework is\nthen exemplary applied for explaining and resolving legal conflicts in property\nlaw (wild animal cases) within a modern proof assistant system.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jun 2020 06:57:15 GMT"}, {"version": "v2", "created": "Tue, 19 Jan 2021 06:32:03 GMT"}, {"version": "v3", "created": "Thu, 28 Jan 2021 21:09:44 GMT"}], "update_date": "2021-02-01", "authors_parsed": [["Benzm\u00fcller", "Christoph", ""], ["Fuenmayor", "David", ""], ["Lomfeld", "Bertram", ""]]}, {"id": "2006.12792", "submitter": "Quanquan Gu", "authors": "Jinghui Chen and Quanquan Gu", "title": "RayS: A Ray Searching Method for Hard-label Adversarial Attack", "comments": "9 pages, 4 figures, 9 tables. In KDD 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks are vulnerable to adversarial attacks. Among different\nattack settings, the most challenging yet the most practical one is the\nhard-label setting where the attacker only has access to the hard-label output\n(prediction label) of the target model. Previous attempts are neither effective\nenough in terms of attack success rate nor efficient enough in terms of query\ncomplexity under the widely used $L_\\infty$ norm threat model. In this paper,\nwe present the Ray Searching attack (RayS), which greatly improves the\nhard-label attack effectiveness as well as efficiency. Unlike previous works,\nwe reformulate the continuous problem of finding the closest decision boundary\ninto a discrete problem that does not require any zeroth-order gradient\nestimation. In the meantime, all unnecessary searches are eliminated via a fast\ncheck step. This significantly reduces the number of queries needed for our\nhard-label attack. Moreover, interestingly, we found that the proposed RayS\nattack can also be used as a sanity check for possible \"falsely robust\" models.\nOn several recently proposed defenses that claim to achieve the\nstate-of-the-art robust accuracy, our attack method demonstrates that the\ncurrent white-box/black-box attacks could still give a false sense of security\nand the robust accuracy drop between the most popular PGD attack and RayS\nattack could be as large as $28\\%$. We believe that our proposed RayS attack\ncould help identify falsely robust models that beat most white-box/black-box\nattacks.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jun 2020 07:01:50 GMT"}, {"version": "v2", "created": "Sat, 5 Sep 2020 18:17:34 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Chen", "Jinghui", ""], ["Gu", "Quanquan", ""]]}, {"id": "2006.12793", "submitter": "Ross Cutler", "authors": "Jamie Pool, Ebrahim Beyrami, Vishak Gopal, Ashkan Aazami, Jayant\n  Gupchup, Jeff Rowland, Binlong Li, Pritesh Kanani, Ross Cutler, and Johannes\n  Gehrke", "title": "Lumos: A Library for Diagnosing Metric Regressions in Web-Scale\n  Applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Web-scale applications can ship code on a daily to weekly cadence. These\napplications rely on online metrics to monitor the health of new releases.\nRegressions in metric values need to be detected and diagnosed as early as\npossible to reduce the disruption to users and product owners. Regressions in\nmetrics can surface due to a variety of reasons: genuine product regressions,\nchanges in user population, and bias due to telemetry loss (or processing) are\namong the common causes. Diagnosing the cause of these metric regressions is\ncostly for engineering teams as they need to invest time in finding the root\ncause of the issue as soon as possible. We present Lumos, a Python library\nbuilt using the principles of AB testing to systematically diagnose metric\nregressions to automate such analysis. Lumos has been deployed across the\ncomponent teams in Microsoft's Real-Time Communication applications Skype and\nMicrosoft Teams. It has enabled engineering teams to detect 100s of real\nchanges in metrics and reject 1000s of false alarms detected by anomaly\ndetectors. The application of Lumos has resulted in freeing up as much as 95%\nof the time allocated to metric-based investigations. In this work, we open\nsource Lumos and present our results from applying it to two different\ncomponents within the RTC group over millions of sessions. This general library\ncan be coupled with any production system to manage the volume of alerting\nefficiently.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jun 2020 07:02:07 GMT"}], "update_date": "2020-06-25", "authors_parsed": [["Pool", "Jamie", ""], ["Beyrami", "Ebrahim", ""], ["Gopal", "Vishak", ""], ["Aazami", "Ashkan", ""], ["Gupchup", "Jayant", ""], ["Rowland", "Jeff", ""], ["Li", "Binlong", ""], ["Kanani", "Pritesh", ""], ["Cutler", "Ross", ""], ["Gehrke", "Johannes", ""]]}, {"id": "2006.12862", "submitter": "Roberta Raileanu", "authors": "Roberta Raileanu, Max Goldstein, Denis Yarats, Ilya Kostrikov, Rob\n  Fergus", "title": "Automatic Data Augmentation for Generalization in Deep Reinforcement\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep reinforcement learning (RL) agents often fail to generalize to unseen\nscenarios, even when they are trained on many instances of semantically similar\nenvironments. Data augmentation has recently been shown to improve the sample\nefficiency and generalization of RL agents. However, different tasks tend to\nbenefit from different kinds of data augmentation. In this paper, we compare\nthree approaches for automatically finding an appropriate augmentation. These\nare combined with two novel regularization terms for the policy and value\nfunction, required to make the use of data augmentation theoretically sound for\ncertain actor-critic algorithms. We evaluate our methods on the Procgen\nbenchmark which consists of 16 procedurally-generated environments and show\nthat it improves test performance by ~40% relative to standard RL algorithms.\nOur agent outperforms other baselines specifically designed to improve\ngeneralization in RL. In addition, we show that our agent learns policies and\nrepresentations that are more robust to changes in the environment that do not\naffect the agent, such as the background. Our implementation is available at\nhttps://github.com/rraileanu/auto-drac.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jun 2020 09:50:22 GMT"}, {"version": "v2", "created": "Sat, 20 Feb 2021 12:32:59 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Raileanu", "Roberta", ""], ["Goldstein", "Max", ""], ["Yarats", "Denis", ""], ["Kostrikov", "Ilya", ""], ["Fergus", "Rob", ""]]}, {"id": "2006.12896", "submitter": "Veronika Yordanova", "authors": "Veronika Yordanova, Bart Gips", "title": "Coverage Path Planning with Track Spacing Adaptation for Autonomous\n  Underwater Vehicles", "comments": "Accepted submission at IEEE Robotics and Automation Letters (RA-L); 8\n  pages, 6 figures", "journal-ref": null, "doi": "10.1109/LRA.2020.3003886", "report-no": null, "categories": "cs.RO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we address the mine countermeasures (MCM) search problem for an\nautonomous underwater vehicle (AUV) surveying the seabed using a side-looking\nsonar. We propose a coverage path planning method that adapts the AUV track\nspacing with the objective of collecting better data. We achieve this by\nshifting the coverage overlap at the tail of the sensor range where the lowest\ndata quality is expected. To assess the algorithm, we collected data from three\nat-sea experiments. The adaptive survey allowed the AUV to recover from a\nsituation where the sensor range was overestimated and resulted in reducing\narea coverage gaps. In another experiment,the adaptive survey showed a 4.2%\nimprovement in data quality for nearly 30% of the 'worst' data.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jun 2020 11:04:32 GMT"}], "update_date": "2020-06-24", "authors_parsed": [["Yordanova", "Veronika", ""], ["Gips", "Bart", ""]]}, {"id": "2006.12903", "submitter": "Arthur Aubret", "authors": "Arthur Aubret, Laetitia Matignon and Salima Hassas", "title": "ELSIM: End-to-end learning of reusable skills through intrinsic\n  motivation", "comments": "Accepted at ECML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Taking inspiration from developmental learning, we present a novel\nreinforcement learning architecture which hierarchically learns and represents\nself-generated skills in an end-to-end way. With this architecture, an agent\nfocuses only on task-rewarded skills while keeping the learning process of\nskills bottom-up. This bottom-up approach allows to learn skills that 1- are\ntransferable across tasks, 2- improves exploration when rewards are sparse. To\ndo so, we combine a previously defined mutual information objective with a\nnovel curriculum learning algorithm, creating an unlimited and explorable tree\nof skills. We test our agent on simple gridworld environments to understand and\nvisualize how the agent distinguishes between its skills. Then we show that our\napproach can scale on more difficult MuJoCo environments in which our agent is\nable to build a representation of skills which improve over a baseline both\ntransfer learning and exploration when rewards are sparse.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jun 2020 11:20:46 GMT"}], "update_date": "2020-06-24", "authors_parsed": [["Aubret", "Arthur", ""], ["Matignon", "Laetitia", ""], ["Hassas", "Salima", ""]]}, {"id": "2006.12964", "submitter": "Beren Millidge Mr", "authors": "Beren Millidge, Alexander Tschantz, Anil K Seth, Christopher L Buckley", "title": "On the Relationship Between Active Inference and Control as Inference", "comments": "final workshop version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Active Inference (AIF) is an emerging framework in the brain sciences which\nsuggests that biological agents act to minimise a variational bound on model\nevidence. Control-as-Inference (CAI) is a framework within reinforcement\nlearning which casts decision making as a variational inference problem. While\nthese frameworks both consider action selection through the lens of variational\ninference, their relationship remains unclear. Here, we provide a formal\ncomparison between them and demonstrate that the primary difference arises from\nhow value is incorporated into their respective generative models. In the\ncontext of this comparison, we highlight several ways in which these frameworks\ncan inform one another.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jun 2020 13:03:58 GMT"}, {"version": "v2", "created": "Wed, 24 Jun 2020 11:33:41 GMT"}, {"version": "v3", "created": "Mon, 29 Jun 2020 14:52:52 GMT"}], "update_date": "2020-06-30", "authors_parsed": [["Millidge", "Beren", ""], ["Tschantz", "Alexander", ""], ["Seth", "Anil K", ""], ["Buckley", "Christopher L", ""]]}, {"id": "2006.12983", "submitter": "Yuval Tassa", "authors": "Yuval Tassa, Saran Tunyasuvunakool, Alistair Muldal, Yotam Doron,\n  Piotr Trochim, Siqi Liu, Steven Bohez, Josh Merel, Tom Erez, Timothy\n  Lillicrap, Nicolas Heess", "title": "dm_control: Software and Tasks for Continuous Control", "comments": "arXiv admin note: text overlap with arXiv:1801.00690", "journal-ref": null, "doi": "10.1016/j.simpa.2020.100022", "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The dm_control software package is a collection of Python libraries and task\nsuites for reinforcement learning agents in an articulated-body simulation. A\nMuJoCo wrapper provides convenient bindings to functions and data structures.\nThe PyMJCF and Composer libraries enable procedural model manipulation and task\nauthoring. The Control Suite is a fixed set of tasks with standardised\nstructure, intended to serve as performance benchmarks. The Locomotion\nframework provides high-level abstractions and examples of locomotion tasks. A\nset of configurable manipulation tasks with a robot arm and snap-together\nbricks is also included. dm_control is publicly available at\nhttps://www.github.com/deepmind/dm_control\n", "versions": [{"version": "v1", "created": "Mon, 22 Jun 2020 17:52:00 GMT"}, {"version": "v2", "created": "Mon, 7 Sep 2020 14:28:10 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Tassa", "Yuval", ""], ["Tunyasuvunakool", "Saran", ""], ["Muldal", "Alistair", ""], ["Doron", "Yotam", ""], ["Trochim", "Piotr", ""], ["Liu", "Siqi", ""], ["Bohez", "Steven", ""], ["Merel", "Josh", ""], ["Erez", "Tom", ""], ["Lillicrap", "Timothy", ""], ["Heess", "Nicolas", ""]]}, {"id": "2006.12999", "submitter": "Ziming Li", "authors": "Ziming Li, Julia Kiseleva, Alekh Agarwal, Maarten de Rijke, Ryen W.\n  White", "title": "Optimizing Interactive Systems via Data-Driven Objectives", "comments": "30 pages, 12 figures. arXiv admin note: text overlap with\n  arXiv:1802.06306", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Effective optimization is essential for real-world interactive systems to\nprovide a satisfactory user experience in response to changing user behavior.\nHowever, it is often challenging to find an objective to optimize for\ninteractive systems (e.g., policy learning in task-oriented dialog systems).\nGenerally, such objectives are manually crafted and rarely capture complex user\nneeds in an accurate manner. We propose an approach that infers the objective\ndirectly from observed user interactions. These inferences can be made\nregardless of prior knowledge and across different types of user behavior. We\nintroduce Interactive System Optimizer (ISO), a novel algorithm that uses these\ninferred objectives for optimization. Our main contribution is a new general\nprincipled approach to optimizing interactive systems using data-driven\nobjectives. We demonstrate the high effectiveness of ISO over several\nsimulations.\n", "versions": [{"version": "v1", "created": "Fri, 19 Jun 2020 20:49:14 GMT"}], "update_date": "2020-06-24", "authors_parsed": [["Li", "Ziming", ""], ["Kiseleva", "Julia", ""], ["Agarwal", "Alekh", ""], ["de Rijke", "Maarten", ""], ["White", "Ryen W.", ""]]}, {"id": "2006.13155", "submitter": "Ryan Riegel", "authors": "Ryan Riegel, Alexander Gray, Francois Luus, Naweed Khan, Ndivhuwo\n  Makondo, Ismail Yunus Akhalwaya, Haifeng Qian, Ronald Fagin, Francisco\n  Barahona, Udit Sharma, Shajith Ikbal, Hima Karanam, Sumit Neelam, Ankita\n  Likhyani, Santosh Srivastava", "title": "Logical Neural Networks", "comments": "10 pages (incl. references), 38 pages supplementary, 7 figures, 9\n  tables, 6 algorithms. In submission to NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel framework seamlessly providing key properties of both\nneural nets (learning) and symbolic logic (knowledge and reasoning). Every\nneuron has a meaning as a component of a formula in a weighted real-valued\nlogic, yielding a highly intepretable disentangled representation. Inference is\nomnidirectional rather than focused on predefined target variables, and\ncorresponds to logical reasoning, including classical first-order logic theorem\nproving as a special case. The model is end-to-end differentiable, and learning\nminimizes a novel loss function capturing logical contradiction, yielding\nresilience to inconsistent knowledge. It also enables the open-world assumption\nby maintaining bounds on truth values which can have probabilistic semantics,\nyielding resilience to incomplete knowledge.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jun 2020 16:55:45 GMT"}], "update_date": "2020-06-24", "authors_parsed": [["Riegel", "Ryan", ""], ["Gray", "Alexander", ""], ["Luus", "Francois", ""], ["Khan", "Naweed", ""], ["Makondo", "Ndivhuwo", ""], ["Akhalwaya", "Ismail Yunus", ""], ["Qian", "Haifeng", ""], ["Fagin", "Ronald", ""], ["Barahona", "Francisco", ""], ["Sharma", "Udit", ""], ["Ikbal", "Shajith", ""], ["Karanam", "Hima", ""], ["Neelam", "Sumit", ""], ["Likhyani", "Ankita", ""], ["Srivastava", "Santosh", ""]]}, {"id": "2006.13165", "submitter": "Quanquan Gu", "authors": "Dongruo Zhou and Jiafan He and Quanquan Gu", "title": "Provably Efficient Reinforcement Learning for Discounted MDPs with\n  Feature Mapping", "comments": "31 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern tasks in reinforcement learning have large state and action spaces. To\ndeal with them efficiently, one often uses predefined feature mapping to\nrepresent states and actions in a low-dimensional space. In this paper, we\nstudy reinforcement learning for discounted Markov Decision Processes (MDPs),\nwhere the transition kernel can be parameterized as a linear function of\ncertain feature mapping. We propose a novel algorithm that makes use of the\nfeature mapping and obtains a $\\tilde O(d\\sqrt{T}/(1-\\gamma)^2)$ regret, where\n$d$ is the dimension of the feature space, $T$ is the time horizon and $\\gamma$\nis the discount factor of the MDP. To the best of our knowledge, this is the\nfirst polynomial regret bound without accessing the generative model or making\nstrong assumptions such as ergodicity of the MDP. By constructing a special\nclass of MDPs, we also show that for any algorithms, the regret is lower\nbounded by $\\Omega(d\\sqrt{T}/(1-\\gamma)^{1.5})$. Our upper and lower bound\nresults together suggest that the proposed reinforcement learning algorithm is\nnear-optimal up to a $(1-\\gamma)^{-0.5}$ factor.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jun 2020 17:08:54 GMT"}, {"version": "v2", "created": "Tue, 21 Jul 2020 04:52:19 GMT"}, {"version": "v3", "created": "Wed, 7 Oct 2020 00:20:30 GMT"}, {"version": "v4", "created": "Mon, 22 Feb 2021 23:10:12 GMT"}], "update_date": "2021-02-24", "authors_parsed": [["Zhou", "Dongruo", ""], ["He", "Jiafan", ""], ["Gu", "Quanquan", ""]]}, {"id": "2006.13169", "submitter": "Jiaming Song", "authors": "Samarth Sinha and Jiaming Song and Animesh Garg and Stefano Ermon", "title": "Experience Replay with Likelihood-free Importance Weights", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The use of past experiences to accelerate temporal difference (TD) learning\nof value functions, or experience replay, is a key component in deep\nreinforcement learning. Prioritization or reweighting of important experiences\nhas shown to improve performance of TD learning algorithms.In this work, we\npropose to reweight experiences based on their likelihood under the stationary\ndistribution of the current policy. Using the corresponding reweighted TD\nobjective, we implicitly encourage small approximation errors on the value\nfunction over frequently encountered states. We use a likelihood-free density\nratio estimator over the replay buffer to assign the prioritization weights. We\napply the proposed approach empirically on two competitive methods, Soft Actor\nCritic (SAC) and Twin Delayed Deep Deterministic policy gradient (TD3) -- over\na suite of OpenAI gym tasks and achieve superior sample complexity compared to\nother baseline approaches.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jun 2020 17:17:44 GMT"}], "update_date": "2020-06-24", "authors_parsed": [["Sinha", "Samarth", ""], ["Song", "Jiaming", ""], ["Garg", "Animesh", ""], ["Ermon", "Stefano", ""]]}, {"id": "2006.13189", "submitter": "Aaron Sonabend", "authors": "Aaron Sonabend-W, Junwei Lu, Leo A. Celi, Tianxi Cai, Peter Szolovits", "title": "Expert-Supervised Reinforcement Learning for Offline Policy Learning and\n  Evaluation", "comments": "to be published in NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Offline Reinforcement Learning (RL) is a promising approach for learning\noptimal policies in environments where direct exploration is expensive or\nunfeasible. However, the adoption of such policies in practice is often\nchallenging, as they are hard to interpret within the application context, and\nlack measures of uncertainty for the learned policy value and its decisions. To\novercome these issues, we propose an Expert-Supervised RL (ESRL) framework\nwhich uses uncertainty quantification for offline policy learning. In\nparticular, we have three contributions: 1) the method can learn safe and\noptimal policies through hypothesis testing, 2) ESRL allows for different\nlevels of risk averse implementations tailored to the application context, and\nfinally, 3) we propose a way to interpret ESRL's policy at every state through\nposterior distributions, and use this framework to compute off-policy value\nfunction posteriors. We provide theoretical guarantees for our estimators and\nregret bounds consistent with Posterior Sampling for RL (PSRL). Sample\nefficiency of ESRL is independent of the chosen risk aversion threshold and\nquality of the behavior policy.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jun 2020 17:43:44 GMT"}, {"version": "v2", "created": "Fri, 30 Oct 2020 19:14:14 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Sonabend-W", "Aaron", ""], ["Lu", "Junwei", ""], ["Celi", "Leo A.", ""], ["Cai", "Tianxi", ""], ["Szolovits", "Peter", ""]]}, {"id": "2006.13205", "submitter": "Oleh Rybkin", "authors": "Karl Pertsch, Oleh Rybkin, Frederik Ebert, Chelsea Finn, Dinesh\n  Jayaraman, Sergey Levine", "title": "Long-Horizon Visual Planning with Goal-Conditioned Hierarchical\n  Predictors", "comments": "Project page: orybkin.github.io/video-gcp. KP and OR contributed\n  equally", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ability to predict and plan into the future is fundamental for agents\nacting in the world. To reach a faraway goal, we predict trajectories at\nmultiple timescales, first devising a coarse plan towards the goal and then\ngradually filling in details. In contrast, current learning approaches for\nvisual prediction and planning fail on long-horizon tasks as they generate\npredictions (1) without considering goal information, and (2) at the finest\ntemporal resolution, one step at a time. In this work we propose a framework\nfor visual prediction and planning that is able to overcome both of these\nlimitations. First, we formulate the problem of predicting towards a goal and\npropose the corresponding class of latent space goal-conditioned predictors\n(GCPs). GCPs significantly improve planning efficiency by constraining the\nsearch space to only those trajectories that reach the goal. Further, we show\nhow GCPs can be naturally formulated as hierarchical models that, given two\nobservations, predict an observation between them, and by recursively\nsubdividing each part of the trajectory generate complete sequences. This\ndivide-and-conquer strategy is effective at long-term prediction, and enables\nus to design an effective hierarchical planning algorithm that optimizes\ntrajectories in a coarse-to-fine manner. We show that by using both\ngoal-conditioning and hierarchical prediction, GCPs enable us to solve visual\nplanning tasks with much longer horizon than previously possible.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jun 2020 17:58:56 GMT"}, {"version": "v2", "created": "Fri, 27 Nov 2020 22:34:30 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Pertsch", "Karl", ""], ["Rybkin", "Oleh", ""], ["Ebert", "Frederik", ""], ["Finn", "Chelsea", ""], ["Jayaraman", "Dinesh", ""], ["Levine", "Sergey", ""]]}, {"id": "2006.13208", "submitter": "Andreea Bobu", "authors": "Andreea Bobu, Marius Wiggert, Claire Tomlin, Anca D. Dragan", "title": "Feature Expansive Reward Learning: Rethinking Human Input", "comments": "13 pages, 14 figures", "journal-ref": null, "doi": "10.1145/3434073.3444667", "report-no": null, "categories": "cs.RO cs.AI cs.HC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When a person is not satisfied with how a robot performs a task, they can\nintervene to correct it. Reward learning methods enable the robot to adapt its\nreward function online based on such human input, but they rely on handcrafted\nfeatures. When the correction cannot be explained by these features, recent\nwork in deep Inverse Reinforcement Learning (IRL) suggests that the robot could\nask for task demonstrations and recover a reward defined over the raw state\nspace. Our insight is that rather than implicitly learning about the missing\nfeature(s) from demonstrations, the robot should instead ask for data that\nexplicitly teaches it about what it is missing. We introduce a new type of\nhuman input in which the person guides the robot from states where the feature\nbeing taught is highly expressed to states where it is not. We propose an\nalgorithm for learning the feature from the raw state space and integrating it\ninto the reward function. By focusing the human input on the missing feature,\nour method decreases sample complexity and improves generalization of the\nlearned reward over the above deep IRL baseline. We show this in experiments\nwith a physical 7DOF robot manipulator, as well as in a user study conducted in\na simulated environment.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jun 2020 17:59:34 GMT"}, {"version": "v2", "created": "Tue, 12 Jan 2021 18:59:50 GMT"}], "update_date": "2021-01-13", "authors_parsed": [["Bobu", "Andreea", ""], ["Wiggert", "Marius", ""], ["Tomlin", "Claire", ""], ["Dragan", "Anca D.", ""]]}, {"id": "2006.13253", "submitter": "Thao Nguyen", "authors": "Thao Nguyen, Nakul Gopalan, Roma Patel, Matt Corsaro, Ellie Pavlick,\n  Stefanie Tellex", "title": "Robot Object Retrieval with Contextual Natural Language Queries", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.CL cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Natural language object retrieval is a highly useful yet challenging task for\nrobots in human-centric environments. Previous work has primarily focused on\ncommands specifying the desired object's type such as \"scissors\" and/or visual\nattributes such as \"red,\" thus limiting the robot to only known object classes.\nWe develop a model to retrieve objects based on descriptions of their usage.\nThe model takes in a language command containing a verb, for example \"Hand me\nsomething to cut,\" and RGB images of candidate objects and selects the object\nthat best satisfies the task specified by the verb. Our model directly predicts\nan object's appearance from the object's use specified by a verb phrase. We do\nnot need to explicitly specify an object's class label. Our approach allows us\nto predict high level concepts like an object's utility based on the language\nquery. Based on contextual information present in the language commands, our\nmodel can generalize to unseen object classes and unknown nouns in the\ncommands. Our model correctly selects objects out of sets of five candidates to\nfulfill natural language commands, and achieves an average accuracy of 62.3% on\na held-out test set of unseen ImageNet object classes and 53.0% on unseen\nobject classes and unknown nouns. Our model also achieves an average accuracy\nof 54.7% on unseen YCB object classes, which have a different image\ndistribution from ImageNet objects. We demonstrate our model on a KUKA LBR iiwa\nrobot arm, enabling the robot to retrieve objects based on natural language\ndescriptions of their usage. We also present a new dataset of 655 verb-object\npairs denoting object usage over 50 verbs and 216 object classes.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jun 2020 18:13:40 GMT"}], "update_date": "2020-06-25", "authors_parsed": [["Nguyen", "Thao", ""], ["Gopalan", "Nakul", ""], ["Patel", "Roma", ""], ["Corsaro", "Matt", ""], ["Pavlick", "Ellie", ""], ["Tellex", "Stefanie", ""]]}, {"id": "2006.13258", "submitter": "Paul Barde", "authors": "Paul Barde, Julien Roy, Wonseok Jeon, Joelle Pineau, Christopher Pal,\n  Derek Nowrouzezahrai", "title": "Adversarial Soft Advantage Fitting: Imitation Learning without Policy\n  Optimization", "comments": null, "journal-ref": "Advances in Neural Information Processing Systems 33 (2020)", "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial Imitation Learning alternates between learning a discriminator --\nwhich tells apart expert's demonstrations from generated ones -- and a\ngenerator's policy to produce trajectories that can fool this discriminator.\nThis alternated optimization is known to be delicate in practice since it\ncompounds unstable adversarial training with brittle and sample-inefficient\nreinforcement learning. We propose to remove the burden of the policy\noptimization steps by leveraging a novel discriminator formulation.\nSpecifically, our discriminator is explicitly conditioned on two policies: the\none from the previous generator's iteration and a learnable policy. When\noptimized, this discriminator directly learns the optimal generator's policy.\nConsequently, our discriminator's update solves the generator's optimization\nproblem for free: learning a policy that imitates the expert does not require\nan additional optimization loop. This formulation effectively cuts by half the\nimplementation and computational burden of Adversarial Imitation Learning\nalgorithms by removing the Reinforcement Learning phase altogether. We show on\na variety of tasks that our simpler approach is competitive to prevalent\nImitation Learning methods.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jun 2020 18:29:13 GMT"}, {"version": "v2", "created": "Thu, 29 Oct 2020 15:59:43 GMT"}, {"version": "v3", "created": "Fri, 6 Nov 2020 21:51:39 GMT"}, {"version": "v4", "created": "Fri, 13 Nov 2020 08:43:41 GMT"}, {"version": "v5", "created": "Thu, 10 Dec 2020 10:03:40 GMT"}, {"version": "v6", "created": "Fri, 16 Apr 2021 10:09:13 GMT"}], "update_date": "2021-04-19", "authors_parsed": [["Barde", "Paul", ""], ["Roy", "Julien", ""], ["Jeon", "Wonseok", ""], ["Pineau", "Joelle", ""], ["Pal", "Christopher", ""], ["Nowrouzezahrai", "Derek", ""]]}, {"id": "2006.13326", "submitter": "Mohammad Fereydounian", "authors": "Mohammad Fereydounian, Zebang Shen, Aryan Mokhtari, Amin Karbasi,\n  Hamed Hassani", "title": "Safe Learning under Uncertain Objectives and Constraints", "comments": "42 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider non-convex optimization problems under\n\\textit{unknown} yet safety-critical constraints. Such problems naturally arise\nin a variety of domains including robotics, manufacturing, and medical\nprocedures, where it is infeasible to know or identify all the constraints.\nTherefore, the parameter space should be explored in a conservative way to\nensure that none of the constraints are violated during the optimization\nprocess once we start from a safe initialization point. To this end, we develop\nan algorithm called Reliable Frank-Wolfe (Reliable-FW). Given a general\nnon-convex function and an unknown polytope constraint, Reliable-FW\nsimultaneously learns the landscape of the objective function and the boundary\nof the safety polytope. More precisely, by assuming that Reliable-FW has access\nto a (stochastic) gradient oracle of the objective function and a noisy\nfeasibility oracle of the safety polytope, it finds an $\\epsilon$-approximate\nfirst-order stationary point with the optimal ${\\mathcal{O}}({1}/{\\epsilon^2})$\ngradient oracle complexity (resp. $\\tilde{\\mathcal{O}}({1}/{\\epsilon^3})$ (also\noptimal) in the stochastic gradient setting), while ensuring the safety of all\nthe iterates. Rather surprisingly, Reliable-FW only makes\n$\\tilde{\\mathcal{O}}(({d^2}/{\\epsilon^2})\\log 1/\\delta)$ queries to the noisy\nfeasibility oracle (resp. $\\tilde{\\mathcal{O}}(({d^2}/{\\epsilon^4})\\log\n1/\\delta)$ in the stochastic gradient setting) where $d$ is the dimension and\n$\\delta$ is the reliability parameter, tightening the existing bounds even for\nsafe minimization of convex functions. We further specialize our results to the\ncase that the objective function is convex. A crucial component of our analysis\nis to introduce and apply a technique called geometric shrinkage in the context\nof safe optimization.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jun 2020 20:51:00 GMT"}], "update_date": "2020-06-25", "authors_parsed": [["Fereydounian", "Mohammad", ""], ["Shen", "Zebang", ""], ["Mokhtari", "Aryan", ""], ["Karbasi", "Amin", ""], ["Hassani", "Hamed", ""]]}, {"id": "2006.13365", "submitter": "Mehdi Ali", "authors": "Mehdi Ali, Max Berrendorf, Charles Tapley Hoyt, Laurent Vermue,\n  Mikhail Galkin, Sahand Sharifzadeh, Asja Fischer, Volker Tresp, Jens Lehmann", "title": "Bringing Light Into the Dark: A Large-scale Evaluation of Knowledge\n  Graph Embedding Models Under a Unified Framework", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The heterogeneity in recently published knowledge graph embedding models'\nimplementations, training, and evaluation has made fair and thorough\ncomparisons difficult. In order to assess the reproducibility of previously\npublished results, we re-implemented and evaluated 21 interaction models in the\nPyKEEN software package. Here, we outline which results could be reproduced\nwith their reported hyper-parameters, which could only be reproduced with\nalternate hyper-parameters, and which could not be reproduced at all as well as\nprovide insight as to why this might be the case.\n  We then performed a large-scale benchmarking on four datasets with several\nthousands of experiments and 24,804 GPU hours of computation time. We present\ninsights gained as to best practices, best configurations for each model, and\nwhere improvements could be made over previously published best configurations.\nOur results highlight that the combination of model architecture, training\napproach, loss function, and the explicit modeling of inverse relations is\ncrucial for a model's performances, and not only determined by the model\narchitecture. We provide evidence that several architectures can obtain results\ncompetitive to the state-of-the-art when configured carefully. We have made all\ncode, experimental configurations, results, and analyses that lead to our\ninterpretations available at https://github.com/pykeen/pykeen and\nhttps://github.com/pykeen/benchmarking\n", "versions": [{"version": "v1", "created": "Tue, 23 Jun 2020 22:30:52 GMT"}, {"version": "v2", "created": "Fri, 7 Aug 2020 07:53:07 GMT"}, {"version": "v3", "created": "Tue, 29 Dec 2020 08:24:40 GMT"}, {"version": "v4", "created": "Fri, 25 Jun 2021 06:20:20 GMT"}], "update_date": "2021-06-28", "authors_parsed": [["Ali", "Mehdi", ""], ["Berrendorf", "Max", ""], ["Hoyt", "Charles Tapley", ""], ["Vermue", "Laurent", ""], ["Galkin", "Mikhail", ""], ["Sharifzadeh", "Sahand", ""], ["Fischer", "Asja", ""], ["Tresp", "Volker", ""], ["Lehmann", "Jens", ""]]}, {"id": "2006.13408", "submitter": "Yinlam Chow", "authors": "Brandon Cui and Yinlam Chow and Mohammad Ghavamzadeh", "title": "Control-Aware Representations for Model-based Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A major challenge in modern reinforcement learning (RL) is efficient control\nof dynamical systems from high-dimensional sensory observations. Learning\ncontrollable embedding (LCE) is a promising approach that addresses this\nchallenge by embedding the observations into a lower-dimensional latent space,\nestimating the latent dynamics, and utilizing it to perform control in the\nlatent space. Two important questions in this area are how to learn a\nrepresentation that is amenable to the control problem at hand, and how to\nachieve an end-to-end framework for representation learning and control. In\nthis paper, we take a few steps towards addressing these questions. We first\nformulate a LCE model to learn representations that are suitable to be used by\na policy iteration style algorithm in the latent space. We call this model\ncontrol-aware representation learning (CARL). We derive a loss function for\nCARL that has close connection to the prediction, consistency, and curvature\n(PCC) principle for representation learning. We derive three implementations of\nCARL. In the offline implementation, we replace the locally-linear control\nalgorithm (e.g.,~iLQR) used by the existing LCE methods with a RL algorithm,\nnamely model-based soft actor-critic, and show that it results in significant\nimprovement. In online CARL, we interleave representation learning and control,\nand demonstrate further gain in performance. Finally, we propose value-guided\nCARL, a variation in which we optimize a weighted version of the CARL loss\nfunction, where the weights depend on the TD-error of the current policy. We\nevaluate the proposed algorithms by extensive experiments on benchmark tasks\nand compare them with several LCE baselines.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jun 2020 01:00:32 GMT"}], "update_date": "2020-06-25", "authors_parsed": [["Cui", "Brandon", ""], ["Chow", "Yinlam", ""], ["Ghavamzadeh", "Mohammad", ""]]}, {"id": "2006.13427", "submitter": "Lichin Chen", "authors": "Lichin Chen, Yu Tsao, Ji-Tian Sheu", "title": "Using Deep Learning and Explainable Artificial Intelligence in Patients'\n  Choices of Hospital Levels", "comments": "19 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In countries that enabled patients to choose their own providers, a common\nproblem is that the patients did not make rational decisions, and hence, fail\nto use healthcare resources efficiently. This might cause problems such as\noverwhelming tertiary facilities with mild condition patients, thus limiting\ntheir capacity of treating acute and critical patients. To address such\nmaldistributed patient volume, it is essential to oversee patients choices\nbefore further evaluation of a policy or resource allocation. This study used\nnationwide insurance data, accumulated possible features discussed in existing\nliterature, and used a deep neural network to predict the patients choices of\nhospital levels. This study also used explainable artificial intelligence\nmethods to interpret the contribution of features for the general public and\nindividuals. In addition, we explored the effectiveness of changing data\nrepresentations. The results showed that the model was able to predict with\nhigh area under the receiver operating characteristics curve (AUC) (0.90),\naccuracy (0.90), sensitivity (0.94), and specificity (0.97) with highly\nimbalanced label. Generally, social approval of the provider by the general\npublic (positive or negative) and the number of practicing physicians serving\nper ten thousand people of the located area are listed as the top effecting\nfeatures. The changing data representation had a positive effect on the\nprediction improvement. Deep learning methods can process highly imbalanced\ndata and achieve high accuracy. The effecting features affect the general\npublic and individuals differently. Addressing the sparsity and discrete nature\nof insurance data leads to better prediction. Applications using deep learning\ntechnology are promising in health policy making. More work is required to\ninterpret models and practice implementation.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jun 2020 02:15:15 GMT"}], "update_date": "2020-06-25", "authors_parsed": [["Chen", "Lichin", ""], ["Tsao", "Yu", ""], ["Sheu", "Ji-Tian", ""]]}, {"id": "2006.13438", "submitter": "Diego Chialva", "authors": "Diego Chialva, Alexis-Michel Mugabushaka", "title": "DINGO: an ontology for projects and grants linked data", "comments": "Accepted for the SKG2020 Workshop co-located with TPDL 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL cs.AI cs.CY cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present DINGO (Data INtegration for Grants Ontology), an ontology that\nprovides a machine readable extensible framework to model data for\nsemantically-enabled applications relative to projects, funding, actors, and,\nnotably, funding policies in the research landscape. DINGO is designed to yield\nhigh modeling power and elasticity to cope with the huge variety in funding,\nresearch and policy practices, which makes it applicable also to other areas\nbesides research where funding is an important aspect. We discuss its main\nfeatures, the principles followed for its development, its community uptake,\nits maintenance and evolution.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jun 2020 02:47:40 GMT"}], "update_date": "2020-06-25", "authors_parsed": [["Chialva", "Diego", ""], ["Mugabushaka", "Alexis-Michel", ""]]}, {"id": "2006.13462", "submitter": "Chang Xu", "authors": "Yao Cheng, Chang Xu, Zhen Hai, Yingjiu Li", "title": "DeepMnemonic: Password Mnemonic Generation via Deep Attentive\n  Encoder-Decoder Model", "comments": "Published in IEEE Transactions on Dependable and Secure Computing\n  (TDSC)", "journal-ref": null, "doi": "10.1109/TDSC.2020.2987025", "report-no": null, "categories": "cs.CR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Strong passwords are fundamental to the security of password-based user\nauthentication systems. In recent years, much effort has been made to evaluate\npassword strength or to generate strong passwords. Unfortunately, the usability\nor memorability of the strong passwords has been largely neglected. In this\npaper, we aim to bridge the gap between strong password generation and the\nusability of strong passwords. We propose to automatically generate textual\npassword mnemonics, i.e., natural language sentences, which are intended to\nhelp users better memorize passwords. We introduce \\textit{DeepMnemonic}, a\ndeep attentive encoder-decoder framework which takes a password as input and\nthen automatically generates a mnemonic sentence for the password. We conduct\nextensive experiments to evaluate DeepMnemonic on the real-world data sets. The\nexperimental results demonstrate that DeepMnemonic outperforms a well-known\nbaseline for generating semantically meaningful mnemonic sentences. Moreover,\nthe user study further validates that the generated mnemonic sentences by\nDeepMnemonic are useful in helping users memorize strong passwords.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jun 2020 04:05:48 GMT"}], "update_date": "2020-06-25", "authors_parsed": [["Cheng", "Yao", ""], ["Xu", "Chang", ""], ["Hai", "Zhen", ""], ["Li", "Yingjiu", ""]]}, {"id": "2006.13463", "submitter": "Shengding Hu", "authors": "Shengding Hu, Zheng Xiong, Meng Qu, Xingdi Yuan, Marc-Alexandre\n  C\\^ot\\'e, Zhiyuan Liu and Jian Tang", "title": "Graph Policy Network for Transferable Active Learning on Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph neural networks (GNNs) have been attracting increasing popularity due\nto their simplicity and effectiveness in a variety of fields. However, a large\nnumber of labeled data is generally required to train these networks, which\ncould be very expensive to obtain in some domains. In this paper, we study\nactive learning for GNNs, i.e., how to efficiently label the nodes on a graph\nto reduce the annotation cost of training GNNs. We formulate the problem as a\nsequential decision process on graphs and train a GNN-based policy network with\nreinforcement learning to learn the optimal query strategy. By jointly training\non several source graphs with full labels, we learn a transferable active\nlearning policy which can directly generalize to unlabeled target graphs.\nExperimental results on multiple datasets from different domains prove the\neffectiveness of the learned policy in promoting active learning performance in\nboth settings of transferring between graphs in the same domain and across\ndifferent domains.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jun 2020 04:07:25 GMT"}, {"version": "v2", "created": "Fri, 23 Oct 2020 12:53:41 GMT"}], "update_date": "2020-10-26", "authors_parsed": [["Hu", "Shengding", ""], ["Xiong", "Zheng", ""], ["Qu", "Meng", ""], ["Yuan", "Xingdi", ""], ["C\u00f4t\u00e9", "Marc-Alexandre", ""], ["Liu", "Zhiyuan", ""], ["Tang", "Jian", ""]]}, {"id": "2006.13473", "submitter": "Chenwei Zhang", "authors": "Xin Luna Dong, Xiang He, Andrey Kan, Xian Li, Yan Liang, Jun Ma, Yifan\n  Ethan Xu, Chenwei Zhang, Tong Zhao, Gabriel Blanco Saldana, Saurabh\n  Deshpande, Alexandre Michetti Manduca, Jay Ren, Surender Pal Singh, Fan Xiao,\n  Haw-Shiuan Chang, Giannis Karamanolakis, Yuning Mao, Yaqing Wang, Christos\n  Faloutsos, Andrew McCallum, Jiawei Han", "title": "AutoKnow: Self-Driving Knowledge Collection for Products of Thousands of\n  Types", "comments": "KDD 2020", "journal-ref": null, "doi": "10.1145/3394486.3403323", "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Can one build a knowledge graph (KG) for all products in the world? Knowledge\ngraphs have firmly established themselves as valuable sources of information\nfor search and question answering, and it is natural to wonder if a KG can\ncontain information about products offered at online retail sites. There have\nbeen several successful examples of generic KGs, but organizing information\nabout products poses many additional challenges, including sparsity and noise\nof structured data for products, complexity of the domain with millions of\nproduct types and thousands of attributes, heterogeneity across large number of\ncategories, as well as large and constantly growing number of products. We\ndescribe AutoKnow, our automatic (self-driving) system that addresses these\nchallenges. The system includes a suite of novel techniques for taxonomy\nconstruction, product property identification, knowledge extraction, anomaly\ndetection, and synonym discovery. AutoKnow is (a) automatic, requiring little\nhuman intervention, (b) multi-scalable, scalable in multiple dimensions (many\ndomains, many products, and many attributes), and (c) integrative, exploiting\nrich customer behavior logs. AutoKnow has been operational in collecting\nproduct knowledge for over 11K product types.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jun 2020 04:35:17 GMT"}], "update_date": "2020-06-25", "authors_parsed": [["Dong", "Xin Luna", ""], ["He", "Xiang", ""], ["Kan", "Andrey", ""], ["Li", "Xian", ""], ["Liang", "Yan", ""], ["Ma", "Jun", ""], ["Xu", "Yifan Ethan", ""], ["Zhang", "Chenwei", ""], ["Zhao", "Tong", ""], ["Saldana", "Gabriel Blanco", ""], ["Deshpande", "Saurabh", ""], ["Manduca", "Alexandre Michetti", ""], ["Ren", "Jay", ""], ["Singh", "Surender Pal", ""], ["Xiao", "Fan", ""], ["Chang", "Haw-Shiuan", ""], ["Karamanolakis", "Giannis", ""], ["Mao", "Yuning", ""], ["Wang", "Yaqing", ""], ["Faloutsos", "Christos", ""], ["McCallum", "Andrew", ""], ["Han", "Jiawei", ""]]}, {"id": "2006.13534", "submitter": "Ehsan Asali", "authors": "Ehsan Asali, Farzin Negahbani, Shahriyar Bamaei, Zahra Abbasi", "title": "Namira Soccer 2D Simulation Team Description Paper 2020", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this article, we will discuss methods and ideas which are implemented on\nNamira 2D Soccer Simulation team in the recent year. Numerous scientific and\nprogramming activities were done in the process of code development, but we\nwill mention the most outstanding ones in details. A Kalman filtering method\nfor localization and two helpful software packages will be discussed here.\nNamira uses agent2d-3.1.1 as base code and librcsc-4.1.0 as library with some\ndeliberate changes.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jun 2020 07:40:44 GMT"}], "update_date": "2020-06-25", "authors_parsed": [["Asali", "Ehsan", ""], ["Negahbani", "Farzin", ""], ["Bamaei", "Shahriyar", ""], ["Abbasi", "Zahra", ""]]}, {"id": "2006.13607", "submitter": "Forrest Bao", "authors": "Youbiao He, Forrest Sheng Bao", "title": "Circuit Routing Using Monte Carlo Tree Search and Deep Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Circuit routing is a fundamental problem in designing electronic systems such\nas integrated circuits (ICs) and printed circuit boards (PCBs) which form the\nhardware of electronics and computers. Like finding paths between pairs of\nlocations, circuit routing generates traces of wires to connect contacts or\nleads of circuit components. It is challenging because finding paths between\ndense and massive electronic components involves a very large search space.\nExisting solutions are either manually designed with domain knowledge or\ntailored to specific design rules, hence, difficult to adapt to new problems or\ndesign needs. Therefore, a general routing approach is highly desired. In this\npaper, we model the circuit routing as a sequential decision-making problem,\nand solve it by Monte Carlo tree search (MCTS) with deep neural network (DNN)\nguided rollout. It could be easily extended to routing cases with more routing\nconstraints and optimization goals. Experiments on randomly generated\nsingle-layer circuits show the potential to route complex circuits. The\nproposed approach can solve the problems that benchmark methods such as\nsequential A* method and Lee's algorithm cannot solve, and can also outperform\nthe vanilla MCTS approach.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jun 2020 10:34:57 GMT"}], "update_date": "2020-06-25", "authors_parsed": [["He", "Youbiao", ""], ["Bao", "Forrest Sheng", ""]]}, {"id": "2006.13615", "submitter": "Francisco Cruz", "authors": "Francisco Cruz and Richard Dazeley and Peter Vamplew", "title": "Explainable robotic systems: Understanding goal-driven actions in a\n  reinforcement learning scenario", "comments": "24 pages, 21 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Robotic systems are more present in our society everyday. In human-robot\nenvironments, it is crucial that end-users may correctly understand their\nrobotic team-partners, in order to collaboratively complete a task. To increase\naction understanding, users demand more explainability about the decisions by\nthe robot in particular situations. Recently, explainable robotic systems have\nemerged as an alternative focused not only on completing a task satisfactorily,\nbut also in justifying, in a human-like manner, the reasons that lead to making\na decision. In reinforcement learning scenarios, a great effort has been\nfocused on providing explanations using data-driven approaches, particularly\nfrom the visual input modality in deep learning-based systems. In this work, we\nfocus on the decision-making process of a reinforcement learning agent\nperforming a simple navigation task in a robotic scenario. As a way to explain\nthe goal-driven robot's actions, we use the probability of success computed by\nthree different proposed approaches: memory-based, learning-based, and\nintrospection-based. The difference between these approaches is the amount of\nmemory required to compute or estimate the probability of success as well as\nthe kind of reinforcement learning representation where they could be used. In\nthis regard, we use the memory-based approach as a baseline since it is\nobtained directly from the agent's observations. When comparing the\nlearning-based and the introspection-based approaches to this baseline, both\nare found to be suitable alternatives to compute the probability of success,\nobtaining high levels of similarity when compared using both the Pearson's\ncorrelation and the mean squared error.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jun 2020 10:51:14 GMT"}, {"version": "v2", "created": "Wed, 29 Jul 2020 05:47:44 GMT"}], "update_date": "2020-07-30", "authors_parsed": [["Cruz", "Francisco", ""], ["Dazeley", "Richard", ""], ["Vamplew", "Peter", ""]]}, {"id": "2006.13664", "submitter": "Natesh Ganesh", "authors": "Natesh Ganesh", "title": "No Substitute for Functionalism -- A Reply to 'Falsification &\n  Consciousness'", "comments": "This paper replaced an earlier version that was on arXiv under the\n  title -- C-Wars: The Unfolding Argument Strikes Back - A Reply to\n  'Falsification & Consciousness'", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.OH cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In their paper 'Falsification and Consciousness' [1], Kleiner and Hoel\nintroduced a formal mathematical model of the process of generating observable\ndata from experiments and using that data to generate inferences and\npredictions onto an experience space. The resulting substitution argument built\non this framework was used to show that any theory of consciousness with\nindependent inference and prediction data are pre-falsified, if the inference\nreports are considered valid. If this argument does indeed pre-falsify many of\nthe leading theories of consciousness, it would indicate a fundamental problem\naffecting the field of consciousness as a whole that would require radical\nchanges to how consciousness science is performed. In this reply, the author\nwill identify avenues of expansion for the model proposed in [1], allowing us\nto distinguish between different types of variation. Motivated by examples from\nneural networks, state machines and Turing machines, we will prove that\nsubstitutions do not exist for a very broad class of Level-1 functionalist\ntheories, rendering them immune to the aforementioned substitution argument.\n", "versions": [{"version": "v1", "created": "Thu, 28 May 2020 08:12:07 GMT"}, {"version": "v2", "created": "Tue, 20 Apr 2021 18:38:39 GMT"}, {"version": "v3", "created": "Fri, 30 Apr 2021 21:54:25 GMT"}], "update_date": "2021-05-04", "authors_parsed": [["Ganesh", "Natesh", ""]]}, {"id": "2006.13704", "submitter": "Liting Sun", "authors": "Zheng Wu, Liting Sun, Wei Zhan, Chenyu Yang, Masayoshi Tomizuka", "title": "Efficient Sampling-Based Maximum Entropy Inverse Reinforcement Learning\n  with Application to Autonomous Driving", "comments": "Accepted by IEEE Robotics and Automation Letters. June 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the past decades, we have witnessed significant progress in the domain of\nautonomous driving. Advanced techniques based on optimization and reinforcement\nlearning (RL) become increasingly powerful at solving the forward problem:\ngiven designed reward/cost functions, how should we optimize them and obtain\ndriving policies that interact with the environment safely and efficiently.\nSuch progress has raised another equally important question: \\emph{what should\nwe optimize}? Instead of manually specifying the reward functions, it is\ndesired that we can extract what human drivers try to optimize from real\ntraffic data and assign that to autonomous vehicles to enable more naturalistic\nand transparent interaction between humans and intelligent agents. To address\nthis issue, we present an efficient sampling-based maximum-entropy inverse\nreinforcement learning (IRL) algorithm in this paper. Different from existing\nIRL algorithms, by introducing an efficient continuous-domain trajectory\nsampler, the proposed algorithm can directly learn the reward functions in the\ncontinuous domain while considering the uncertainties in demonstrated\ntrajectories from human drivers. We evaluate the proposed algorithm on real\ndriving data, including both non-interactive and interactive scenarios. The\nexperimental results show that the proposed algorithm achieves more accurate\nprediction performance with faster convergence speed and better generalization\ncompared to other baseline IRL algorithms.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jun 2020 01:41:13 GMT"}], "update_date": "2020-06-25", "authors_parsed": [["Wu", "Zheng", ""], ["Sun", "Liting", ""], ["Zhan", "Wei", ""], ["Yang", "Chenyu", ""], ["Tomizuka", "Masayoshi", ""]]}, {"id": "2006.13735", "submitter": "Pranav Ashok", "authors": "Pranav Ashok and Vahid Hashemi and Jan K\\v{r}et\\'insk\\'y and Stefanie\n  Mohr", "title": "DeepAbstract: Neural Network Abstraction for Accelerating Verification", "comments": "Accepted at ATVA 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While abstraction is a classic tool of verification to scale it up, it is not\nused very often for verifying neural networks. However, it can help with the\nstill open task of scaling existing algorithms to state-of-the-art network\narchitectures. We introduce an abstraction framework applicable to\nfully-connected feed-forward neural networks based on clustering of neurons\nthat behave similarly on some inputs. For the particular case of ReLU, we\nadditionally provide error bounds incurred by the abstraction. We show how the\nabstraction reduces the size of the network, while preserving its accuracy, and\nhow verification results on the abstract network can be transferred back to the\noriginal network.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jun 2020 13:51:03 GMT"}], "update_date": "2020-06-25", "authors_parsed": [["Ashok", "Pranav", ""], ["Hashemi", "Vahid", ""], ["K\u0159et\u00ednsk\u00fd", "Jan", ""], ["Mohr", "Stefanie", ""]]}, {"id": "2006.13760", "submitter": "Heinrich K\\\"uttler", "authors": "Heinrich K\\\"uttler and Nantas Nardelli and Alexander H. Miller and\n  Roberta Raileanu and Marco Selvatici and Edward Grefenstette and Tim\n  Rockt\\\"aschel", "title": "The NetHack Learning Environment", "comments": "28 pages. Accepted at NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Progress in Reinforcement Learning (RL) algorithms goes hand-in-hand with the\ndevelopment of challenging environments that test the limits of current\nmethods. While existing RL environments are either sufficiently complex or\nbased on fast simulation, they are rarely both. Here, we present the NetHack\nLearning Environment (NLE), a scalable, procedurally generated, stochastic,\nrich, and challenging environment for RL research based on the popular\nsingle-player terminal-based roguelike game, NetHack. We argue that NetHack is\nsufficiently complex to drive long-term research on problems such as\nexploration, planning, skill acquisition, and language-conditioned RL, while\ndramatically reducing the computational resources required to gather a large\namount of experience. We compare NLE and its task suite to existing\nalternatives, and discuss why it is an ideal medium for testing the robustness\nand systematic generalization of RL agents. We demonstrate empirical success\nfor early stages of the game using a distributed Deep RL baseline and Random\nNetwork Distillation exploration, alongside qualitative analysis of various\nagents trained in the environment. NLE is open source at\nhttps://github.com/facebookresearch/nle.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jun 2020 14:12:56 GMT"}, {"version": "v2", "created": "Tue, 1 Dec 2020 11:05:57 GMT"}], "update_date": "2020-12-02", "authors_parsed": [["K\u00fcttler", "Heinrich", ""], ["Nardelli", "Nantas", ""], ["Miller", "Alexander H.", ""], ["Raileanu", "Roberta", ""], ["Selvatici", "Marco", ""], ["Grefenstette", "Edward", ""], ["Rockt\u00e4schel", "Tim", ""]]}, {"id": "2006.13763", "submitter": "Ahmad Beirami", "authors": "Sofia M Nikolakaki and Ogheneovo Dibie and Ahmad Beirami and Nicholas\n  Peterson and Navid Aghdaie and Kazi Zaman", "title": "Competitive Balance in Team Sports Games", "comments": "2020 IEEE Conference in Games (COG 2020), 8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.AI cs.HC cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Competition is a primary driver of player satisfaction and engagement in\nmultiplayer online games. Traditional matchmaking systems aim at creating\nmatches involving teams of similar aggregated individual skill levels, such as\nElo score or TrueSkill. However, team dynamics cannot be solely captured using\nsuch linear predictors. Recently, it has been shown that nonlinear predictors\nthat target to learn probability of winning as a function of player and team\nfeatures significantly outperforms these linear skill-based methods. In this\npaper, we show that using final score difference provides yet a better\nprediction metric for competitive balance. We also show that a linear model\ntrained on a carefully selected set of team and individual features achieves\nalmost the performance of the more powerful neural network model while offering\ntwo orders of magnitude inference speed improvement. This shows significant\npromise for implementation in online matchmaking systems.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jun 2020 14:19:07 GMT"}], "update_date": "2020-06-25", "authors_parsed": [["Nikolakaki", "Sofia M", ""], ["Dibie", "Ogheneovo", ""], ["Beirami", "Ahmad", ""], ["Peterson", "Nicholas", ""], ["Aghdaie", "Navid", ""], ["Zaman", "Kazi", ""]]}, {"id": "2006.13774", "submitter": "David Chang", "authors": "David Chang, Ivana Balazevic, Carl Allen, Daniel Chawla, Cynthia\n  Brandt, Richard Andrew Taylor", "title": "Benchmark and Best Practices for Biomedical Knowledge Graph Embeddings", "comments": "Accepted to BioNLP 2020 at ACL", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Much of biomedical and healthcare data is encoded in discrete, symbolic form\nsuch as text and medical codes. There is a wealth of expert-curated biomedical\ndomain knowledge stored in knowledge bases and ontologies, but the lack of\nreliable methods for learning knowledge representation has limited their\nusefulness in machine learning applications. While text-based representation\nlearning has significantly improved in recent years through advances in natural\nlanguage processing, attempts to learn biomedical concept embeddings so far\nhave been lacking. A recent family of models called knowledge graph embeddings\nhave shown promising results on general domain knowledge graphs, and we explore\ntheir capabilities in the biomedical domain. We train several state-of-the-art\nknowledge graph embedding models on the SNOMED-CT knowledge graph, provide a\nbenchmark with comparison to existing methods and in-depth discussion on best\npractices, and make a case for the importance of leveraging the\nmulti-relational nature of knowledge graphs for learning biomedical knowledge\nrepresentation. The embeddings, code, and materials will be made available to\nthe communitY.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jun 2020 14:47:33 GMT"}], "update_date": "2020-06-25", "authors_parsed": [["Chang", "David", ""], ["Balazevic", "Ivana", ""], ["Allen", "Carl", ""], ["Chawla", "Daniel", ""], ["Brandt", "Cynthia", ""], ["Taylor", "Richard Andrew", ""]]}, {"id": "2006.13796", "submitter": "Michael Hind", "authors": "John Richards, David Piorkowski, Michael Hind, Stephanie Houde,\n  Aleksandra Mojsilovi\\'c", "title": "A Methodology for Creating AI FactSheets", "comments": "18 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As AI models and services are used in a growing number of highstakes areas, a\nconsensus is forming around the need for a clearer record of how these models\nand services are developed to increase trust. Several proposals for higher\nquality and more consistent AI documentation have emerged to address ethical\nand legal concerns and general social impacts of such systems. However, there\nis little published work on how to create this documentation. This is the first\nwork to describe a methodology for creating the form of AI documentation we\ncall FactSheets. We have used this methodology to create useful FactSheets for\nnearly two dozen models. This paper describes this methodology and shares the\ninsights we have gathered. Within each step of the methodology, we describe the\nissues to consider and the questions to explore with the relevant people in an\norganization who will be creating and consuming the AI facts in a FactSheet.\nThis methodology will accelerate the broader adoption of transparent AI\ndocumentation.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jun 2020 15:08:59 GMT"}, {"version": "v2", "created": "Sun, 28 Jun 2020 01:47:46 GMT"}], "update_date": "2020-06-30", "authors_parsed": [["Richards", "John", ""], ["Piorkowski", "David", ""], ["Hind", "Michael", ""], ["Houde", "Stephanie", ""], ["Mojsilovi\u0107", "Aleksandra", ""]]}, {"id": "2006.13799", "submitter": "Lucas Zimmer", "authors": "Lucas Zimmer, Marius Lindauer, Frank Hutter", "title": "Auto-PyTorch Tabular: Multi-Fidelity MetaLearning for Efficient and\n  Robust AutoDL", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While early AutoML frameworks focused on optimizing traditional ML pipelines\nand their hyperparameters, a recent trend in AutoML is to focus on neural\narchitecture search. In this paper, we introduce Auto-PyTorch, which brings the\nbest of these two worlds together by jointly and robustly optimizing the\narchitecture of networks and the training hyperparameters to enable fully\nautomated deep learning (AutoDL). Auto-PyTorch achieves state-of-the-art\nperformance on several tabular benchmarks by combining multi-fidelity\noptimization with portfolio construction for warmstarting and ensembling of\ndeep neural networks (DNNs) and common baselines for tabular data. To\nthoroughly study our assumptions on how to design such an AutoDL system, we\nadditionally introduce a new benchmark on learning curves for DNNs, dubbed\nLCBench, and run extensive ablation studies of the full Auto-PyTorch on typical\nAutoML benchmarks, eventually showing that Auto-PyTorch performs better than\nseveral state-of-the-art competitors on average.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jun 2020 15:15:17 GMT"}, {"version": "v2", "created": "Mon, 24 Aug 2020 12:10:48 GMT"}, {"version": "v3", "created": "Mon, 26 Apr 2021 10:36:34 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["Zimmer", "Lucas", ""], ["Lindauer", "Marius", ""], ["Hutter", "Frank", ""]]}, {"id": "2006.13823", "submitter": "Hassam Sheikh", "authors": "Hassam Ullah Sheikh, Mariano Phielipp, Ladislau B\\\"ol\\\"oni", "title": "Maximizing Ensemble Diversity in Deep Q-Learning", "comments": "Accepted in Deep Reinforcement Learning Workshop at NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The classic DQN algorithm is limited by the overestimation bias of the\nlearned Q-function. Subsequent algorithms have proposed techniques to reduce\nthis problem, without fully eliminating it. Recently, the Maxmin and Ensemble\nQ-learning algorithms have used different estimates provided by the ensembles\nof learners to reduce the overestimation bias. Unfortunately, these learners\ncan converge to the same point in the parametric or representation space,\nfalling back to the classic single neural network DQN. In this paper, we\ndescribe a regularization technique to maximize ensemble diversity in these\nalgorithms. We propose and compare five regularization functions inspired from\neconomics theory and consensus optimization. We show that the regularized\napproach significantly outperforms the Maxmin and Ensemble Q-learning\nalgorithms as well as non-ensemble baselines.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jun 2020 15:53:20 GMT"}, {"version": "v2", "created": "Tue, 6 Jul 2021 17:51:46 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Sheikh", "Hassam Ullah", ""], ["Phielipp", "Mariano", ""], ["B\u00f6l\u00f6ni", "Ladislau", ""]]}, {"id": "2006.13843", "submitter": "Vaidyanathan Peruvemba Ramaswamy", "authors": "Vaidyanathan P. R. and Stefan Szeider", "title": "Turbocharging Treewidth-Bounded Bayesian Network Structure Learning", "comments": "15 pages, 4 figures, 3 tables. To be published in AAAI 2021. Updated:\n  synced with AAAI version. Source code available at\n  http://github.com/aditya95sriram/bn-slim", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new approach for learning the structure of a treewidth-bounded\nBayesian Network (BN). The key to our approach is applying an exact method\n(based on MaxSAT) locally, to improve the score of a heuristically computed BN.\nThis approach allows us to scale the power of exact methods -- so far only\napplicable to BNs with several dozens of random variables -- to large BNs with\nseveral thousands of random variables. Our experiments show that our method\nimproves the score of BNs provided by state-of-the-art heuristic methods, often\nsignificantly.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jun 2020 16:13:10 GMT"}, {"version": "v2", "created": "Fri, 5 Feb 2021 16:02:25 GMT"}], "update_date": "2021-02-08", "authors_parsed": [["R.", "Vaidyanathan P.", ""], ["Szeider", "Stefan", ""]]}, {"id": "2006.13900", "submitter": "Adam Gleave", "authors": "Adam Gleave, Michael Dennis, Shane Legg, Stuart Russell, Jan Leike", "title": "Quantifying Differences in Reward Functions", "comments": "Published at ICLR 2021. 9 pages main paper, 42 pages total", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For many tasks, the reward function is inaccessible to introspection or too\ncomplex to be specified procedurally, and must instead be learned from user\ndata. Prior work has evaluated learned reward functions by evaluating policies\noptimized for the learned reward. However, this method cannot distinguish\nbetween the learned reward function failing to reflect user preferences and the\npolicy optimization process failing to optimize the learned reward. Moreover,\nthis method can only tell us about behavior in the evaluation environment, but\nthe reward may incentivize very different behavior in even a slightly different\ndeployment environment. To address these problems, we introduce the\nEquivalent-Policy Invariant Comparison (EPIC) distance to quantify the\ndifference between two reward functions directly, without a policy optimization\nstep. We prove EPIC is invariant on an equivalence class of reward functions\nthat always induce the same optimal policy. Furthermore, we find EPIC can be\nefficiently approximated and is more robust than baselines to the choice of\ncoverage distribution. Finally, we show that EPIC distance bounds the regret of\noptimal policies even under different transition dynamics, and we confirm\nempirically that it predicts policy training success. Our source code is\navailable at https://github.com/HumanCompatibleAI/evaluating-rewards.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jun 2020 17:35:15 GMT"}, {"version": "v2", "created": "Thu, 8 Oct 2020 14:35:42 GMT"}, {"version": "v3", "created": "Wed, 17 Mar 2021 21:54:55 GMT"}], "update_date": "2021-03-19", "authors_parsed": [["Gleave", "Adam", ""], ["Dennis", "Michael", ""], ["Legg", "Shane", ""], ["Russell", "Stuart", ""], ["Leike", "Jan", ""]]}, {"id": "2006.13913", "submitter": "Matthew O'Shaughnessy", "authors": "Matthew O'Shaughnessy, Gregory Canal, Marissa Connor, Mark Davenport,\n  Christopher Rozell", "title": "Generative causal explanations of black-box classifiers", "comments": "Camera-ready version to appear at NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a method for generating causal post-hoc explanations of black-box\nclassifiers based on a learned low-dimensional representation of the data. The\nexplanation is causal in the sense that changing learned latent factors\nproduces a change in the classifier output statistics. To construct these\nexplanations, we design a learning framework that leverages a generative model\nand information-theoretic measures of causal influence. Our objective function\nencourages both the generative model to faithfully represent the data\ndistribution and the latent factors to have a large causal influence on the\nclassifier output. Our method learns both global and local explanations, is\ncompatible with any classifier that admits class probabilities and a gradient,\nand does not require labeled attributes or knowledge of causal structure. Using\ncarefully controlled test cases, we provide intuition that illuminates the\nfunction of our objective. We then demonstrate the practical utility of our\nmethod on image recognition tasks.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jun 2020 17:45:52 GMT"}, {"version": "v2", "created": "Thu, 22 Oct 2020 17:26:18 GMT"}], "update_date": "2020-10-23", "authors_parsed": [["O'Shaughnessy", "Matthew", ""], ["Canal", "Gregory", ""], ["Connor", "Marissa", ""], ["Davenport", "Mark", ""], ["Rozell", "Christopher", ""]]}, {"id": "2006.13916", "submitter": "Benjamin Eysenbach", "authors": "Benjamin Eysenbach, Swapnil Asawa, Shreyas Chaudhari, Sergey Levine,\n  Ruslan Salakhutdinov", "title": "Off-Dynamics Reinforcement Learning: Training for Transfer with Domain\n  Classifiers", "comments": "Published at ICLR 2021. Code\n  (https://github.com/google-research/google-research/tree/master/darc) and\n  blog post\n  (https://blog.ml.cmu.edu/2020/07/31/maintaining-the-illusion-of-reality-transfer-in-rl-by-keeping-agents-in-the-darc)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a simple, practical, and intuitive approach for domain adaptation\nin reinforcement learning. Our approach stems from the idea that the agent's\nexperience in the source domain should look similar to its experience in the\ntarget domain. Building off of a probabilistic view of RL, we formally show\nthat we can achieve this goal by compensating for the difference in dynamics by\nmodifying the reward function. This modified reward function is simple to\nestimate by learning auxiliary classifiers that distinguish source-domain\ntransitions from target-domain transitions. Intuitively, the modified reward\nfunction penalizes the agent for visiting states and taking actions in the\nsource domain which are not possible in the target domain. Said another way,\nthe agent is penalized for transitions that would indicate that the agent is\ninteracting with the source domain, rather than the target domain. Our approach\nis applicable to domains with continuous states and actions and does not\nrequire learning an explicit model of the dynamics. On discrete and continuous\ncontrol tasks, we illustrate the mechanics of our approach and demonstrate its\nscalability to high-dimensional tasks.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jun 2020 17:47:37 GMT"}, {"version": "v2", "created": "Wed, 14 Apr 2021 23:38:31 GMT"}], "update_date": "2021-04-16", "authors_parsed": [["Eysenbach", "Benjamin", ""], ["Asawa", "Swapnil", ""], ["Chaudhari", "Shreyas", ""], ["Levine", "Sergey", ""], ["Salakhutdinov", "Ruslan", ""]]}, {"id": "2006.14032", "submitter": "Jesse Mu", "authors": "Jesse Mu, Jacob Andreas", "title": "Compositional Explanations of Neurons", "comments": "NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe a procedure for explaining neurons in deep representations by\nidentifying compositional logical concepts that closely approximate neuron\nbehavior. Compared to prior work that uses atomic labels as explanations,\nanalyzing neurons compositionally allows us to more precisely and expressively\ncharacterize their behavior. We use this procedure to answer several questions\non interpretability in models for vision and natural language processing.\nFirst, we examine the kinds of abstractions learned by neurons. In image\nclassification, we find that many neurons learn highly abstract but\nsemantically coherent visual concepts, while other polysemantic neurons detect\nmultiple unrelated features; in natural language inference (NLI), neurons learn\nshallow lexical heuristics from dataset biases. Second, we see whether\ncompositional explanations give us insight into model performance: vision\nneurons that detect human-interpretable concepts are positively correlated with\ntask performance, while NLI neurons that fire for shallow heuristics are\nnegatively correlated with task performance. Finally, we show how compositional\nexplanations provide an accessible way for end users to produce simple\n\"copy-paste\" adversarial examples that change model behavior in predictable\nways.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jun 2020 20:37:05 GMT"}, {"version": "v2", "created": "Tue, 2 Feb 2021 23:46:51 GMT"}], "update_date": "2021-02-04", "authors_parsed": [["Mu", "Jesse", ""], ["Andreas", "Jacob", ""]]}, {"id": "2006.14091", "submitter": "Erdem B{\\i}y{\\i}k", "authors": "Erdem B{\\i}y{\\i}k, Dylan P. Losey, Malayandi Palan, Nicholas C.\n  Landolfi, Gleb Shevchuk, Dorsa Sadigh", "title": "Learning Reward Functions from Diverse Sources of Human Feedback:\n  Optimally Integrating Demonstrations and Preferences", "comments": "19 pages, 17 figures. Submitted to The International Journal of\n  Robotics Research (IJRR)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reward functions are a common way to specify the objective of a robot. As\ndesigning reward functions can be extremely challenging, a more promising\napproach is to directly learn reward functions from human teachers.\nImportantly, humans provide data in a variety of forms: these include\ninstructions (e.g., natural language), demonstrations, (e.g., kinesthetic\nguidance), and preferences (e.g., comparative rankings). Prior research has\nindependently applied reward learning to each of these different data sources.\nHowever, there exist many domains where some of these information sources are\nnot applicable or inefficient -- while multiple sources are complementary and\nexpressive. Motivated by this general problem, we present a framework to\nintegrate multiple sources of information, which are either passively or\nactively collected from human users. In particular, we present an algorithm\nthat first utilizes user demonstrations to initialize a belief about the reward\nfunction, and then proactively probes the user with preference queries to\nzero-in on their true reward. This algorithm not only enables us combine\nmultiple data sources, but it also informs the robot when it should leverage\neach type of information. Further, our approach accounts for the human's\nability to provide data: yielding user-friendly preference queries which are\nalso theoretically optimal. Our extensive simulated experiments and user\nstudies on a Fetch mobile manipulator demonstrate the superiority and the\nusability of our integrated framework.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jun 2020 22:45:27 GMT"}], "update_date": "2020-06-26", "authors_parsed": [["B\u0131y\u0131k", "Erdem", ""], ["Losey", "Dylan P.", ""], ["Palan", "Malayandi", ""], ["Landolfi", "Nicholas C.", ""], ["Shevchuk", "Gleb", ""], ["Sadigh", "Dorsa", ""]]}, {"id": "2006.14109", "submitter": "Nikolay Laptev", "authors": "Paulo Tanaka, Sameet Sapra, Nikolay Laptev", "title": "Scalable Data Classification for Security and Privacy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Content based data classification is an open challenge. Traditional Data Loss\nPrevention (DLP)-like systems solve this problem by fingerprinting the data in\nquestion and monitoring endpoints for the fingerprinted data. With a large\nnumber of constantly changing data assets in Facebook, this approach is both\nnot scalable and ineffective in discovering what data is where. This paper is\nabout an end-to-end system built to detect sensitive semantic types within\nFacebook at scale and enforce data retention and access controls automatically.\n  The approach described here is our first end-to-end privacy system that\nattempts to solve this problem by incorporating data signals, machine learning,\nand traditional fingerprinting techniques to map out and classify all data\nwithin Facebook. The described system is in production achieving a 0.9+ average\nF2 scores across various privacy classes while handling a large number of data\nassets across dozens of data stores.\n", "versions": [{"version": "v1", "created": "Thu, 25 Jun 2020 00:19:34 GMT"}, {"version": "v2", "created": "Sun, 28 Jun 2020 22:44:47 GMT"}, {"version": "v3", "created": "Tue, 30 Jun 2020 16:28:04 GMT"}, {"version": "v4", "created": "Wed, 1 Jul 2020 19:40:55 GMT"}, {"version": "v5", "created": "Mon, 6 Jul 2020 20:03:21 GMT"}], "update_date": "2020-07-08", "authors_parsed": [["Tanaka", "Paulo", ""], ["Sapra", "Sameet", ""], ["Laptev", "Nikolay", ""]]}, {"id": "2006.14171", "submitter": "Shengyi Huang", "authors": "Shengyi Huang, Santiago Onta\\~n\\'on", "title": "A Closer Look at Invalid Action Masking in Policy Gradient Algorithms", "comments": "Preprint. Corrected a major issue of the withdrawn version submitted\n  to NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, Deep Reinforcement Learning (DRL) algorithms have achieved\nstate-of-the-art performance in many challenging strategy games. Because these\ngames have complicated rules, an action sampled from the full discrete action\nspace will typically be invalid. The usual approach to deal with this problem\nin policy gradient algorithms is to \"mask out\" invalid actions and just sample\nfrom the set of valid actions. The implications of this process, however,\nremain under-investigated. In this paper, we show that the standard working\nmechanism of invalid action masking corresponds to valid policy gradient\nupdates. More interestingly, it works by applying a state-dependent\ndifferentiable function during the calculation of action probability\ndistribution. Additionally, we show its critical importance to the performance\nof policy gradient algorithms. Specifically, our experiments show that invalid\naction masking scales well when the space of invalid actions is large, while\nthe common approach of giving negative rewards for invalid actions will fail.\nFinally, we provide further insights by evaluating different action masking\nregimes, such as removing masking after an agent has been trained using\nmasking.\n", "versions": [{"version": "v1", "created": "Thu, 25 Jun 2020 04:47:09 GMT"}, {"version": "v2", "created": "Fri, 26 Jun 2020 19:15:38 GMT"}], "update_date": "2020-06-30", "authors_parsed": [["Huang", "Shengyi", ""], ["Onta\u00f1\u00f3n", "Santiago", ""]]}, {"id": "2006.14223", "submitter": "Alex Sokolov", "authors": "Alex Sokolov, Denis Filimonov", "title": "Neural Machine Translation For Paraphrase Generation", "comments": "Published in NIPS 2018: 2nd Conversational AI workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Training a spoken language understanding system, as the one in Alexa,\ntypically requires a large human-annotated corpus of data. Manual annotations\nare expensive and time consuming. In Alexa Skill Kit (ASK) user experience with\nthe skill greatly depends on the amount of data provided by skill developer. In\nthis work, we present an automatic natural language generation system, capable\nof generating both human-like interactions and annotations by the means of\nparaphrasing. Our approach consists of machine translation (MT) inspired\nencoder-decoder deep recurrent neural network. We evaluate our model on the\nimpact it has on ASK skill, intent, named entity classification accuracy and\nsentence level coverage, all of which demonstrate significant improvements for\nunseen skills on natural language understanding (NLU) models, trained on the\ndata augmented with paraphrases.\n", "versions": [{"version": "v1", "created": "Thu, 25 Jun 2020 07:38:00 GMT"}], "update_date": "2020-06-30", "authors_parsed": [["Sokolov", "Alex", ""], ["Filimonov", "Denis", ""]]}, {"id": "2006.14363", "submitter": "Chenghao Li", "authors": "Chenghao Li, Xiaoteng Ma, Chongjie Zhang, Jun Yang, Li Xia and\n  Qianchuan Zhao", "title": "SOAC: The Soft Option Actor-Critic Architecture", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The option framework has shown great promise by automatically extracting\ntemporally-extended sub-tasks from a long-horizon task. Methods have been\nproposed for concurrently learning low-level intra-option policies and\nhigh-level option selection policy. However, existing methods typically suffer\nfrom two major challenges: ineffective exploration and unstable updates. In\nthis paper, we present a novel and stable off-policy approach that builds on\nthe maximum entropy model to address these challenges. Our approach introduces\nan information-theoretical intrinsic reward for encouraging the identification\nof diverse and effective options. Meanwhile, we utilize a probability inference\nmodel to simplify the optimization problem as fitting optimal trajectories.\nExperimental results demonstrate that our approach significantly outperforms\nprior on-policy and off-policy methods in a range of Mujoco benchmark tasks\nwhile still providing benefits for transfer learning. In these tasks, our\napproach learns a diverse set of options, each of whose state-action space has\nstrong coherence.\n", "versions": [{"version": "v1", "created": "Thu, 25 Jun 2020 13:06:59 GMT"}], "update_date": "2020-06-26", "authors_parsed": [["Li", "Chenghao", ""], ["Ma", "Xiaoteng", ""], ["Zhang", "Chongjie", ""], ["Yang", "Jun", ""], ["Xia", "Li", ""], ["Zhao", "Qianchuan", ""]]}, {"id": "2006.14423", "submitter": "Pascal Kerschke", "authors": "Vera Steinhoff and Pascal Kerschke and Christian Grimme", "title": "Empirical Study on the Benefits of Multiobjectivization for Solving\n  Single-Objective Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When dealing with continuous single-objective problems, multimodality poses\none of the biggest difficulties for global optimization. Local optima are often\npreventing algorithms from making progress and thus pose a severe threat. In\nthis paper we analyze how single-objective optimization can benefit from\nmultiobjectivization by considering an additional objective. With the use of a\nsophisticated visualization technique based on the multi-objective gradients,\nthe properties of the arising multi-objective landscapes are illustrated and\nexamined. We will empirically show that the multi-objective optimizer MOGSA is\nable to exploit these properties to overcome local traps. The performance of\nMOGSA is assessed on a testbed of several functions provided by the COCO\nplatform. The results are compared to the local optimizer Nelder-Mead.\n", "versions": [{"version": "v1", "created": "Thu, 25 Jun 2020 14:04:37 GMT"}], "update_date": "2020-06-26", "authors_parsed": [["Steinhoff", "Vera", ""], ["Kerschke", "Pascal", ""], ["Grimme", "Christian", ""]]}, {"id": "2006.14437", "submitter": "V\\'ictor Guti\\'errez-Basulto", "authors": "Yazm\\'in Ib\\'a\\~nez-Garc\\'ia, V\\'ictor Guti\\'errez-Basulto, Steven\n  Schockaert", "title": "Plausible Reasoning about EL-Ontologies using Concept Interpolation", "comments": "16 pages, 3 figures, accepted at KR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Description logics (DLs) are standard knowledge representation languages for\nmodelling ontologies, i.e. knowledge about concepts and the relations between\nthem. Unfortunately, DL ontologies are difficult to learn from data and\ntime-consuming to encode manually. As a result, ontologies for broad domains\nare almost inevitably incomplete. In recent years, several data-driven\napproaches have been proposed for automatically extending such ontologies. One\nfamily of methods rely on characterizations of concepts that are derived from\ntext descriptions. While such characterizations do not capture ontological\nknowledge directly, they encode information about the similarity between\ndifferent concepts, which can be exploited for filling in the gaps in existing\nontologies. To this end, several inductive inference mechanisms have already\nbeen proposed, but these have been defined and used in a heuristic fashion. In\nthis paper, we instead propose an inductive inference mechanism which is based\non a clear model-theoretic semantics, and can thus be tightly integrated with\nstandard deductive reasoning. We particularly focus on interpolation, a\npowerful commonsense reasoning mechanism which is closely related to cognitive\nmodels of category-based induction. Apart from the formalization of the\nunderlying semantics, as our main technical contribution we provide\ncomputational complexity bounds for reasoning in EL with this interpolation\nmechanism.\n", "versions": [{"version": "v1", "created": "Thu, 25 Jun 2020 14:19:41 GMT"}], "update_date": "2020-06-26", "authors_parsed": [["Ib\u00e1\u00f1ez-Garc\u00eda", "Yazm\u00edn", ""], ["Guti\u00e9rrez-Basulto", "V\u00edctor", ""], ["Schockaert", "Steven", ""]]}, {"id": "2006.14448", "submitter": "Reuben Feinman", "authors": "Reuben Feinman, Brenden M. Lake", "title": "Learning Task-General Representations with Generative Neuro-Symbolic\n  Modeling", "comments": null, "journal-ref": "International Conference on Learning Representations (ICLR 2021)", "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  People can learn rich, general-purpose conceptual representations from only\nraw perceptual inputs. Current machine learning approaches fall well short of\nthese human standards, although different modeling traditions often have\ncomplementary strengths. Symbolic models can capture the compositional and\ncausal knowledge that enables flexible generalization, but they struggle to\nlearn from raw inputs, relying on strong abstractions and simplifying\nassumptions. Neural network models can learn directly from raw data, but they\nstruggle to capture compositional and causal structure and typically must\nretrain to tackle new tasks. We bring together these two traditions to learn\ngenerative models of concepts that capture rich compositional and causal\nstructure, while learning from raw data. We develop a generative neuro-symbolic\n(GNS) model of handwritten character concepts that uses the control flow of a\nprobabilistic program, coupled with symbolic stroke primitives and a symbolic\nimage renderer, to represent the causal and compositional processes by which\ncharacters are formed. The distributions of parts (strokes), and correlations\nbetween parts, are modeled with neural network subroutines, allowing the model\nto learn directly from raw data and express nonparametric statistical\nrelationships. We apply our model to the Omniglot challenge of human-level\nconcept learning, using a background set of alphabets to learn an expressive\nprior distribution over character drawings. In a subsequent evaluation, our GNS\nmodel uses probabilistic inference to learn rich conceptual representations\nfrom a single training image that generalize to 4 unique tasks, succeeding\nwhere previous work has fallen short.\n", "versions": [{"version": "v1", "created": "Thu, 25 Jun 2020 14:41:27 GMT"}, {"version": "v2", "created": "Sat, 23 Jan 2021 16:40:59 GMT"}], "update_date": "2021-01-26", "authors_parsed": [["Feinman", "Reuben", ""], ["Lake", "Brenden M.", ""]]}, {"id": "2006.14512", "submitter": "Kaizhao Liang", "authors": "Kaizhao Liang, Jacky Y. Zhang, Boxin Wang, Zhuolin Yang, Oluwasanmi\n  Koyejo, Bo Li", "title": "Uncovering the Connections Between Adversarial Transferability and\n  Knowledge Transferability", "comments": "Accepted to ICML 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Knowledge transferability, or transfer learning, has been widely adopted to\nallow a pre-trained model in the source domain to be effectively adapted to\ndownstream tasks in the target domain. It is thus important to explore and\nunderstand the factors affecting knowledge transferability. In this paper, as\nthe first work, we analyze and demonstrate the connections between knowledge\ntransferability and another important phenomenon--adversarial transferability,\n\\emph{i.e.}, adversarial examples generated against one model can be\ntransferred to attack other models. Our theoretical studies show that\nadversarial transferability indicates knowledge transferability and vice versa.\nMoreover, based on the theoretical insights, we propose two practical\nadversarial transferability metrics to characterize this process, serving as\nbidirectional indicators between adversarial and knowledge transferability. We\nconduct extensive experiments for different scenarios on diverse datasets,\nshowing a positive correlation between adversarial transferability and\nknowledge transferability. Our findings will shed light on future research\nabout effective knowledge transfer learning and adversarial transferability\nanalyses.\n", "versions": [{"version": "v1", "created": "Thu, 25 Jun 2020 16:04:47 GMT"}, {"version": "v2", "created": "Sat, 12 Jun 2021 19:42:53 GMT"}, {"version": "v3", "created": "Tue, 15 Jun 2021 17:14:16 GMT"}, {"version": "v4", "created": "Thu, 8 Jul 2021 19:17:09 GMT"}], "update_date": "2021-07-12", "authors_parsed": [["Liang", "Kaizhao", ""], ["Zhang", "Jacky Y.", ""], ["Wang", "Boxin", ""], ["Yang", "Zhuolin", ""], ["Koyejo", "Oluwasanmi", ""], ["Li", "Bo", ""]]}, {"id": "2006.14662", "submitter": "Abhishek Gupta", "authors": "Abhishek Gupta (1 and 2), Camylle Lanteigne (1 and 3), Victoria Heath\n  (1 and 4), Marianna Bergamaschi Ganapini (1 and 5), Erick Galinkin (1 and 6),\n  Allison Cohen (1 and 7), Tania De Gasperis (1 and 8), Mo Akif (1 and 3),\n  Renjie Butalid (1) ((1) Montreal AI Ethics Institute, (2) Microsoft, (3)\n  McGill University, (4) Creative Commons, (5) Union College, (6) Rapid7, (7)\n  AI Global, (8) OCAD University)", "title": "The State of AI Ethics Report (June 2020)", "comments": "128 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  These past few months have been especially challenging, and the deployment of\ntechnology in ways hitherto untested at an unrivalled pace has left the\ninternet and technology watchers aghast. Artificial intelligence has become the\nbyword for technological progress and is being used in everything from helping\nus combat the COVID-19 pandemic to nudging our attention in different\ndirections as we all spend increasingly larger amounts of time online. It has\nnever been more important that we keep a sharp eye out on the development of\nthis field and how it is shaping our society and interactions with each other.\nWith this inaugural edition of the State of AI Ethics we hope to bring forward\nthe most important developments that caught our attention at the Montreal AI\nEthics Institute this past quarter. Our goal is to help you navigate this\never-evolving field swiftly and allow you and your organization to make\ninformed decisions. This pulse-check for the state of discourse, research, and\ndevelopment is geared towards researchers and practitioners alike who are\nmaking decisions on behalf of their organizations in considering the societal\nimpacts of AI-enabled solutions. We cover a wide set of areas in this report\nspanning Agency and Responsibility, Security and Risk, Disinformation, Jobs and\nLabor, the Future of AI Ethics, and more. Our staff has worked tirelessly over\nthe past quarter surfacing signal from the noise so that you are equipped with\nthe right tools and knowledge to confidently tread this complex yet\nconsequential domain.\n", "versions": [{"version": "v1", "created": "Thu, 25 Jun 2020 19:00:41 GMT"}], "update_date": "2020-06-29", "authors_parsed": [["Gupta", "Abhishek", "", "1 and 2"], ["Lanteigne", "Camylle", "", "1 and 3"], ["Heath", "Victoria", "", "1 and 4"], ["Ganapini", "Marianna Bergamaschi", "", "1 and 5"], ["Galinkin", "Erick", "", "1 and 6"], ["Cohen", "Allison", "", "1 and 7"], ["De Gasperis", "Tania", "", "1 and 8"], ["Akif", "Mo", "", "1 and 3"], ["Butalid", "Renjie", ""]]}, {"id": "2006.14722", "submitter": "Satyam Mohla Mr.", "authors": "Satyam Mohla, Anshul Nasery, Biplab Banerjee and Subhasis Chaudhari", "title": "CognitiveCNN: Mimicking Human Cognitive Models to resolve Texture-Shape\n  Bias", "comments": "5 Pages; LaTeX; Published at ICLR 2020 Workshop on Bridging AI and\n  Cognitive Science", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent works demonstrate the texture bias in Convolutional Neural Networks\n(CNNs), conflicting with early works claiming that networks identify objects\nusing shape. It is commonly believed that the cost function forces the network\nto take a greedy route to increase accuracy using texture, failing to explore\nany global statistics. We propose a novel intuitive architecture, namely\nCognitiveCNN, inspired from feature integration theory in psychology to utilise\nhuman-interpretable feature like shape, texture, edges etc. to reconstruct, and\nclassify the image. We define two metrics, namely TIC and RIC to quantify the\nimportance of each stream using attention maps. We introduce a regulariser\nwhich ensures that the contribution of each feature is same for any task, as it\nis for reconstruction; and perform experiments to show the resulting boost in\naccuracy and robustness besides imparting explainability. Lastly, we adapt\nthese ideas to conventional CNNs and propose Augmented Cognitive CNN to achieve\nsuperior performance in object recognition.\n", "versions": [{"version": "v1", "created": "Thu, 25 Jun 2020 22:32:54 GMT"}], "update_date": "2020-06-29", "authors_parsed": [["Mohla", "Satyam", ""], ["Nasery", "Anshul", ""], ["Banerjee", "Biplab", ""], ["Chaudhari", "Subhasis", ""]]}, {"id": "2006.14769", "submitter": "Mitchell Wortsman", "authors": "Mitchell Wortsman, Vivek Ramanujan, Rosanne Liu, Aniruddha Kembhavi,\n  Mohammad Rastegari, Jason Yosinski, Ali Farhadi", "title": "Supermasks in Superposition", "comments": "NeurIPS 2020 Camera Ready", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present the Supermasks in Superposition (SupSup) model, capable of\nsequentially learning thousands of tasks without catastrophic forgetting. Our\napproach uses a randomly initialized, fixed base network and for each task\nfinds a subnetwork (supermask) that achieves good performance. If task identity\nis given at test time, the correct subnetwork can be retrieved with minimal\nmemory usage. If not provided, SupSup can infer the task using gradient-based\noptimization to find a linear superposition of learned supermasks which\nminimizes the output entropy. In practice we find that a single gradient step\nis often sufficient to identify the correct mask, even among 2500 tasks. We\nalso showcase two promising extensions. First, SupSup models can be trained\nentirely without task identity information, as they may detect when they are\nuncertain about new data and allocate an additional supermask for the new\ntraining distribution. Finally the entire, growing set of supermasks can be\nstored in a constant-sized reservoir by implicitly storing them as attractors\nin a fixed-sized Hopfield network.\n", "versions": [{"version": "v1", "created": "Fri, 26 Jun 2020 03:16:44 GMT"}, {"version": "v2", "created": "Tue, 30 Jun 2020 16:57:02 GMT"}, {"version": "v3", "created": "Thu, 22 Oct 2020 00:32:49 GMT"}], "update_date": "2020-10-23", "authors_parsed": [["Wortsman", "Mitchell", ""], ["Ramanujan", "Vivek", ""], ["Liu", "Rosanne", ""], ["Kembhavi", "Aniruddha", ""], ["Rastegari", "Mohammad", ""], ["Yosinski", "Jason", ""], ["Farhadi", "Ali", ""]]}, {"id": "2006.14779", "submitter": "Gagan Bansal", "authors": "Gagan Bansal, Tongshuang Wu, Joyce Zhou, Raymond Fok, Besmira Nushi,\n  Ece Kamar, Marco Tulio Ribeiro, Daniel S. Weld", "title": "Does the Whole Exceed its Parts? The Effect of AI Explanations on\n  Complementary Team Performance", "comments": "CHI'21", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many researchers motivate explainable AI with studies showing that human-AI\nteam performance on decision-making tasks improves when the AI explains its\nrecommendations. However, prior studies observed improvements from explanations\nonly when the AI, alone, outperformed both the human and the best team. Can\nexplanations help lead to complementary performance, where team accuracy is\nhigher than either the human or the AI working solo? We conduct mixed-method\nuser studies on three datasets, where an AI with accuracy comparable to humans\nhelps participants solve a task (explaining itself in some conditions). While\nwe observed complementary improvements from AI augmentation, they were not\nincreased by explanations. Rather, explanations increased the chance that\nhumans will accept the AI's recommendation, regardless of its correctness. Our\nresult poses new challenges for human-centered AI: Can we develop explanatory\napproaches that encourage appropriate trust in AI, and therefore help generate\n(or improve) complementary performance?\n", "versions": [{"version": "v1", "created": "Fri, 26 Jun 2020 03:34:04 GMT"}, {"version": "v2", "created": "Tue, 30 Jun 2020 21:23:55 GMT"}, {"version": "v3", "created": "Tue, 12 Jan 2021 22:50:34 GMT"}], "update_date": "2021-01-14", "authors_parsed": [["Bansal", "Gagan", ""], ["Wu", "Tongshuang", ""], ["Zhou", "Joyce", ""], ["Fok", "Raymond", ""], ["Nushi", "Besmira", ""], ["Kamar", "Ece", ""], ["Ribeiro", "Marco Tulio", ""], ["Weld", "Daniel S.", ""]]}, {"id": "2006.14796", "submitter": "Yuqing Du", "authors": "Yuqing Du, Stas Tiomkin, Emre Kiciman, Daniel Polani, Pieter Abbeel,\n  Anca Dragan", "title": "AvE: Assistance via Empowerment", "comments": "Final version from NeurIPS 2020 Conference Proceedings", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One difficulty in using artificial agents for human-assistive applications\nlies in the challenge of accurately assisting with a person's goal(s). Existing\nmethods tend to rely on inferring the human's goal, which is challenging when\nthere are many potential goals or when the set of candidate goals is difficult\nto identify. We propose a new paradigm for assistance by instead increasing the\nhuman's ability to control their environment, and formalize this approach by\naugmenting reinforcement learning with human empowerment. This task-agnostic\nobjective preserves the person's autonomy and ability to achieve any eventual\nstate. We test our approach against assistance based on goal inference,\nhighlighting scenarios where our method overcomes failure modes stemming from\ngoal ambiguity or misspecification. As existing methods for estimating\nempowerment in continuous domains are computationally hard, precluding its use\nin real time learned assistance, we also propose an efficient\nempowerment-inspired proxy metric. Using this, we are able to successfully\ndemonstrate our method in a shared autonomy user study for a challenging\nsimulated teleoperation task with human-in-the-loop training.\n", "versions": [{"version": "v1", "created": "Fri, 26 Jun 2020 04:40:11 GMT"}, {"version": "v2", "created": "Wed, 1 Jul 2020 02:16:27 GMT"}, {"version": "v3", "created": "Thu, 9 Jul 2020 22:11:44 GMT"}, {"version": "v4", "created": "Sun, 2 Aug 2020 04:20:40 GMT"}, {"version": "v5", "created": "Thu, 7 Jan 2021 20:54:48 GMT"}], "update_date": "2021-01-11", "authors_parsed": [["Du", "Yuqing", ""], ["Tiomkin", "Stas", ""], ["Kiciman", "Emre", ""], ["Polani", "Daniel", ""], ["Abbeel", "Pieter", ""], ["Dragan", "Anca", ""]]}, {"id": "2006.14804", "submitter": "Lin Guan", "authors": "Lin Guan, Mudit Verma, Sihang Guo, Ruohan Zhang, Subbarao Kambhampati", "title": "Explanation Augmented Feedback in Human-in-the-Loop Reinforcement\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Human-in-the-loop Reinforcement Learning (HRL) aims to integrate human\nguidance with Reinforcement Learning (RL) algorithms to improve sample\nefficiency and performance. A common type of human guidance in HRL is binary\nevaluative \"good\" or \"bad\" feedback for queried states and actions. However,\nthis type of learning scheme suffers from the problems of weak supervision and\npoor efficiency in leveraging human feedback. To address this, we present\nEXPAND (EXPlanation AugmeNted feeDback) which provides a visual explanation in\nthe form of saliency maps from humans in addition to the binary feedback.\nEXPAND employs a state perturbation approach based on salient information in\nthe state to augment the binary feedback. We choose five tasks, namely\nPixel-Taxi and four Atari games, to evaluate this approach. We demonstrate the\neffectiveness of our method using two metrics: environment sample efficiency\nand human feedback sample efficiency. We show that our method significantly\noutperforms previous methods. We also analyze the results qualitatively by\nvisualizing the agent's attention. Finally, we present an ablation study to\nconfirm our hypothesis that augmenting binary feedback with state salient\ninformation results in a boost in performance.\n", "versions": [{"version": "v1", "created": "Fri, 26 Jun 2020 05:40:05 GMT"}, {"version": "v2", "created": "Thu, 16 Jul 2020 23:08:58 GMT"}, {"version": "v3", "created": "Fri, 25 Sep 2020 23:59:18 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Guan", "Lin", ""], ["Verma", "Mudit", ""], ["Guo", "Sihang", ""], ["Zhang", "Ruohan", ""], ["Kambhampati", "Subbarao", ""]]}, {"id": "2006.14824", "submitter": "Marian-Andrei Rizoiu", "authors": "Adriana-Simona Mihaita, Zac Papachatgis and Marian-Andrei Rizoiu", "title": "Graph modelling approaches for motorway traffic flow prediction", "comments": null, "journal-ref": "In 23rd IEEE International Conference on Intelligent\n  Transportation Systems (ITSC'20) (pp. 1--8). Rhodes, Greece (2020)", "doi": null, "report-no": null, "categories": "eess.SP cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traffic flow prediction, particularly in areas that experience highly dynamic\nflows such as motorways, is a major issue faced in traffic management. Due to\nincreasingly large volumes of data sets being generated every minute, deep\nlearning methods have been used extensively in the latest years for both short\nand long term prediction. However, such models, despite their efficiency, need\nlarge amounts of historical information to be provided, and they take a\nconsiderable amount of time and computing resources to train, validate and\ntest. This paper presents two new spatial-temporal approaches for building\naccurate short-term prediction along a popular motorway in Sydney, by making\nuse of the graph structure of the motorway network (including exits and\nentries). The methods are built on proximity-based approaches, denoted\nbacktracking and interpolation, which uses the most recent and closest traffic\nflow information for each of the target counting stations along the motorway.\nThe results indicate that for short-term predictions (less than 10 minutes into\nthe future), the proposed graph-based approaches outperform state-of-the-art\ndeep learning models, such as long-term short memory, convolutional neuronal\nnetworks or hybrid models.\n", "versions": [{"version": "v1", "created": "Fri, 26 Jun 2020 06:54:14 GMT"}, {"version": "v2", "created": "Sat, 4 Jul 2020 05:28:58 GMT"}], "update_date": "2020-07-07", "authors_parsed": [["Mihaita", "Adriana-Simona", ""], ["Papachatgis", "Zac", ""], ["Rizoiu", "Marian-Andrei", ""]]}, {"id": "2006.14923", "submitter": "Manfred Jaeger", "authors": "Manfred Jaeger, Giorgio Bacci, Giovanni Bacci, Kim Guldstrand Larsen,\n  and Peter Gj{\\o}l Jensen", "title": "Approximating Euclidean by Imprecise Markov Decision Processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Euclidean Markov decision processes are a powerful tool for modeling control\nproblems under uncertainty over continuous domains. Finite state imprecise,\nMarkov decision processes can be used to approximate the behavior of these\ninfinite models. In this paper we address two questions: first, we investigate\nwhat kind of approximation guarantees are obtained when the Euclidean process\nis approximated by finite state approximations induced by increasingly fine\npartitions of the continuous state space. We show that for cost functions over\nfinite time horizons the approximations become arbitrarily precise. Second, we\nuse imprecise Markov decision process approximations as a tool to analyse and\nvalidate cost functions and strategies obtained by reinforcement learning. We\nfind that, on the one hand, our new theoretical results validate basic design\nchoices of a previously proposed reinforcement learning approach. On the other\nhand, the imprecise Markov decision process approximations reveal some\ninaccuracies in the learned cost functions.\n", "versions": [{"version": "v1", "created": "Fri, 26 Jun 2020 11:58:04 GMT"}], "update_date": "2020-06-29", "authors_parsed": [["Jaeger", "Manfred", ""], ["Bacci", "Giorgio", ""], ["Bacci", "Giovanni", ""], ["Larsen", "Kim Guldstrand", ""], ["Jensen", "Peter Gj\u00f8l", ""]]}, {"id": "2006.14937", "submitter": "Alvaro Correia", "authors": "Alvaro H. C. Correia, Robert Peharz, Cassio de Campos", "title": "Joints in Random Forests", "comments": null, "journal-ref": "Advances in Neural Information Processing Systems 33 (2020)", "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Decision Trees (DTs) and Random Forests (RFs) are powerful discriminative\nlearners and tools of central importance to the everyday machine learning\npractitioner and data scientist. Due to their discriminative nature, however,\nthey lack principled methods to process inputs with missing features or to\ndetect outliers, which requires pairing them with imputation techniques or a\nseparate generative model. In this paper, we demonstrate that DTs and RFs can\nnaturally be interpreted as generative models, by drawing a connection to\nProbabilistic Circuits, a prominent class of tractable probabilistic models.\nThis reinterpretation equips them with a full joint distribution over the\nfeature space and leads to Generative Decision Trees (GeDTs) and Generative\nForests (GeFs), a family of novel hybrid generative-discriminative models. This\nfamily of models retains the overall characteristics of DTs and RFs while\nadditionally being able to handle missing features by means of marginalisation.\nUnder certain assumptions, frequently made for Bayes consistency results, we\nshow that consistency in GeDTs and GeFs extend to any pattern of missing input\nfeatures, if missing at random. Empirically, we show that our models often\noutperform common routines to treat missing data, such as K-nearest neighbour\nimputation, and moreover, that our models can naturally detect outliers by\nmonitoring the marginal probability of input features.\n", "versions": [{"version": "v1", "created": "Thu, 25 Jun 2020 14:17:19 GMT"}, {"version": "v2", "created": "Sat, 11 Jul 2020 16:50:45 GMT"}, {"version": "v3", "created": "Thu, 19 Nov 2020 16:15:10 GMT"}], "update_date": "2020-11-20", "authors_parsed": [["Correia", "Alvaro H. C.", ""], ["Peharz", "Robert", ""], ["de Campos", "Cassio", ""]]}, {"id": "2006.14953", "submitter": "Rahma Chaabouni", "authors": "Eugene Kharitonov and Rahma Chaabouni", "title": "What they do when in doubt: a study of inductive biases in seq2seq\n  learners", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sequence-to-sequence (seq2seq) learners are widely used, but we still have\nonly limited knowledge about what inductive biases shape the way they\ngeneralize. We address that by investigating how popular seq2seq learners\ngeneralize in tasks that have high ambiguity in the training data. We use SCAN\nand three new tasks to study learners' preferences for memorization,\narithmetic, hierarchical, and compositional reasoning. Further, we connect to\nSolomonoff's theory of induction and propose to use description length as a\nprincipled and sensitive measure of inductive biases.\n  In our experimental study, we find that LSTM-based learners can learn to\nperform counting, addition, and multiplication by a constant from a single\ntraining example. Furthermore, Transformer and LSTM-based learners show a bias\ntoward the hierarchical induction over the linear one, while CNN-based learners\nprefer the opposite. On the SCAN dataset, we find that CNN-based, and, to a\nlesser degree, Transformer- and LSTM-based learners have a preference for\ncompositional generalization over memorization. Finally, across all our\nexperiments, description length proved to be a sensitive measure of inductive\nbiases.\n", "versions": [{"version": "v1", "created": "Fri, 26 Jun 2020 12:43:10 GMT"}, {"version": "v2", "created": "Mon, 29 Mar 2021 09:43:36 GMT"}], "update_date": "2021-03-30", "authors_parsed": [["Kharitonov", "Eugene", ""], ["Chaabouni", "Rahma", ""]]}, {"id": "2006.15009", "submitter": "Thomas Moerland", "authors": "Thomas M. Moerland, Joost Broekens, Catholijn M. Jonker", "title": "A Framework for Reinforcement Learning and Planning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sequential decision making, commonly formalized as Markov Decision Process\noptimization, is a key challenge in artificial intelligence. Two successful\napproaches to MDP optimization are planning and reinforcement learning. Both\nresearch fields largely have their own research communities. However, if both\nresearch fields solve the same problem, then we should be able to disentangle\nthe common factors in their solution approaches. Therefore, this paper presents\na unifying framework for reinforcement learning and planning (FRAP), which\nidentifies the underlying dimensions on which any planning or learning\nalgorithm has to decide. At the end of the paper, we compare - in a single\ntable - a variety of well-known planning, model-free and model-based RL\nalgorithms along the dimensions of our framework, illustrating the validity of\nthe framework. Altogether, FRAP provides deeper insight into the algorithmic\nspace of planning and reinforcement learning, and also suggests new approaches\nto integration of both fields.\n", "versions": [{"version": "v1", "created": "Fri, 26 Jun 2020 14:30:41 GMT"}, {"version": "v2", "created": "Thu, 2 Jul 2020 08:52:43 GMT"}, {"version": "v3", "created": "Thu, 23 Jul 2020 15:02:03 GMT"}], "update_date": "2020-07-24", "authors_parsed": [["Moerland", "Thomas M.", ""], ["Broekens", "Joost", ""], ["Jonker", "Catholijn M.", ""]]}, {"id": "2006.15061", "submitter": "Xingrui Yu", "authors": "Xingrui Yu, Yueming Lyu and Ivor W. Tsang", "title": "Intrinsic Reward Driven Imitation Learning via Generative Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Imitation learning in a high-dimensional environment is challenging. Most\ninverse reinforcement learning (IRL) methods fail to outperform the\ndemonstrator in such a high-dimensional environment, e.g., Atari domain. To\naddress this challenge, we propose a novel reward learning module to generate\nintrinsic reward signals via a generative model. Our generative method can\nperform better forward state transition and backward action encoding, which\nimproves the module's dynamics modeling ability in the environment. Thus, our\nmodule provides the imitation agent both the intrinsic intention of the\ndemonstrator and a better exploration ability, which is critical for the agent\nto outperform the demonstrator. Empirical results show that our method\noutperforms state-of-the-art IRL methods on multiple Atari games, even with\none-life demonstration. Remarkably, our method achieves performance that is up\nto 5 times the performance of the demonstration.\n", "versions": [{"version": "v1", "created": "Fri, 26 Jun 2020 15:39:40 GMT"}, {"version": "v2", "created": "Thu, 9 Jul 2020 09:34:29 GMT"}, {"version": "v3", "created": "Sun, 16 Aug 2020 05:52:22 GMT"}, {"version": "v4", "created": "Fri, 11 Sep 2020 09:40:12 GMT"}], "update_date": "2020-09-14", "authors_parsed": [["Yu", "Xingrui", ""], ["Lyu", "Yueming", ""], ["Tsang", "Ivor W.", ""]]}, {"id": "2006.15085", "submitter": "Khimya Khetarpal", "authors": "Khimya Khetarpal, Zafarali Ahmed, Gheorghe Comanici, David Abel, Doina\n  Precup", "title": "What can I do here? A Theory of Affordances in Reinforcement Learning", "comments": "Thirty-seventh International Conference on Machine Learning (ICML\n  2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning algorithms usually assume that all actions are always\navailable to an agent. However, both people and animals understand the general\nlink between the features of their environment and the actions that are\nfeasible. Gibson (1977) coined the term \"affordances\" to describe the fact that\ncertain states enable an agent to do certain actions, in the context of\nembodied agents. In this paper, we develop a theory of affordances for agents\nwho learn and plan in Markov Decision Processes. Affordances play a dual role\nin this case. On one hand, they allow faster planning, by reducing the number\nof actions available in any given situation. On the other hand, they facilitate\nmore efficient and precise learning of transition models from data, especially\nwhen such models require function approximation. We establish these properties\nthrough theoretical results as well as illustrative examples. We also propose\nan approach to learn affordances and use it to estimate transition models that\nare simpler and generalize better.\n", "versions": [{"version": "v1", "created": "Fri, 26 Jun 2020 16:34:53 GMT"}], "update_date": "2020-06-29", "authors_parsed": [["Khetarpal", "Khimya", ""], ["Ahmed", "Zafarali", ""], ["Comanici", "Gheorghe", ""], ["Abel", "David", ""], ["Precup", "Doina", ""]]}, {"id": "2006.15134", "submitter": "Ziyu Wang", "authors": "Ziyu Wang, Alexander Novikov, Konrad Zolna, Jost Tobias Springenberg,\n  Scott Reed, Bobak Shahriari, Noah Siegel, Josh Merel, Caglar Gulcehre,\n  Nicolas Heess, Nando de Freitas", "title": "Critic Regularized Regression", "comments": "23 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Offline reinforcement learning (RL), also known as batch RL, offers the\nprospect of policy optimization from large pre-recorded datasets without online\nenvironment interaction. It addresses challenges with regard to the cost of\ndata collection and safety, both of which are particularly pertinent to\nreal-world applications of RL. Unfortunately, most off-policy algorithms\nperform poorly when learning from a fixed dataset. In this paper, we propose a\nnovel offline RL algorithm to learn policies from data using a form of\ncritic-regularized regression (CRR). We find that CRR performs surprisingly\nwell and scales to tasks with high-dimensional state and action spaces --\noutperforming several state-of-the-art offline RL algorithms by a significant\nmargin on a wide range of benchmark tasks.\n", "versions": [{"version": "v1", "created": "Fri, 26 Jun 2020 17:50:26 GMT"}, {"version": "v2", "created": "Sat, 5 Sep 2020 17:44:55 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Wang", "Ziyu", ""], ["Novikov", "Alexander", ""], ["Zolna", "Konrad", ""], ["Springenberg", "Jost Tobias", ""], ["Reed", "Scott", ""], ["Shahriari", "Bobak", ""], ["Siegel", "Noah", ""], ["Merel", "Josh", ""], ["Gulcehre", "Caglar", ""], ["Heess", "Nicolas", ""], ["de Freitas", "Nando", ""]]}, {"id": "2006.15175", "submitter": "Sainath Ganesh", "authors": "Sainath G, Vignesh S, Siddarth S, G Suganya", "title": "Application of Neuroevolution in Autonomous Cars", "comments": "13 pages, 9 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the onset of Electric vehicles, and them becoming more and more popular,\nautonomous cars are the future in the travel/driving experience. The barrier to\nreaching level 5 autonomy is the difficulty in the collection of data that\nincorporates good driving habits and the lack thereof. The problem with current\nimplementations of self-driving cars is the need for massively large datasets\nand the need to evaluate the driving in the dataset. We propose a system that\nrequires no data for its training. An evolutionary model would have the\ncapability to optimize itself towards the fitness function. We have implemented\nNeuroevolution, a form of genetic algorithm, to train/evolve self-driving cars\nin a simulated virtual environment with the help of Unreal Engine 4, which\nutilizes Nvidia's PhysX Physics Engine to portray real-world vehicle dynamics\naccurately. We were able to observe the serendipitous nature of evolution and\nhave exploited it to reach our optimal solution. We also demonstrate the ease\nin generalizing attributes brought about by genetic algorithms and how they may\nbe used as a boilerplate upon which other machine learning techniques may be\nused to improve the overall driving experience.\n", "versions": [{"version": "v1", "created": "Fri, 26 Jun 2020 19:06:32 GMT"}], "update_date": "2020-06-30", "authors_parsed": [["G", "Sainath", ""], ["S", "Vignesh", ""], ["S", "Siddarth", ""], ["Suganya", "G", ""]]}, {"id": "2006.15223", "submitter": "Adam Stooke", "authors": "Adam Stooke, Valentin Dalibard, Siddhant M. Jayakumar, Wojciech M.\n  Czarnecki, and Max Jaderberg", "title": "Perception-Prediction-Reaction Agents for Deep Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new recurrent agent architecture and associated auxiliary\nlosses which improve reinforcement learning in partially observable tasks\nrequiring long-term memory. We employ a temporal hierarchy, using a\nslow-ticking recurrent core to allow information to flow more easily over long\ntime spans, and three fast-ticking recurrent cores with connections designed to\ncreate an information asymmetry. The \\emph{reaction} core incorporates new\nobservations with input from the slow core to produce the agent's policy; the\n\\emph{perception} core accesses only short-term observations and informs the\nslow core; lastly, the \\emph{prediction} core accesses only long-term memory.\nAn auxiliary loss regularizes policies drawn from all three cores against each\nother, enacting the prior that the policy should be expressible from either\nrecent or long-term memory. We present the resulting\n\\emph{Perception-Prediction-Reaction} (PPR) agent and demonstrate its improved\nperformance over a strong LSTM-agent baseline in DMLab-30, particularly in\ntasks requiring long-term memory. We further show significant improvements in\nCapture the Flag, an environment requiring agents to acquire a complicated\nmixture of skills over long time scales. In a series of ablation experiments,\nwe probe the importance of each component of the PPR agent, establishing that\nthe entire, novel combination is necessary for this intriguing result.\n", "versions": [{"version": "v1", "created": "Fri, 26 Jun 2020 21:53:47 GMT"}], "update_date": "2020-06-30", "authors_parsed": [["Stooke", "Adam", ""], ["Dalibard", "Valentin", ""], ["Jayakumar", "Siddhant M.", ""], ["Czarnecki", "Wojciech M.", ""], ["Jaderberg", "Max", ""]]}, {"id": "2006.15233", "submitter": "Honghua Zhang", "authors": "Honghua Zhang, Steven Holtzen, Guy Van den Broeck", "title": "On the Relationship Between Probabilistic Circuits and Determinantal\n  Point Processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Scaling probabilistic models to large realistic problems and datasets is a\nkey challenge in machine learning. Central to this effort is the development of\ntractable probabilistic models (TPMs): models whose structure guarantees\nefficient probabilistic inference algorithms. The current landscape of TPMs is\nfragmented: there exist various kinds of TPMs with different strengths and\nweaknesses. Two of the most prominent classes of TPMs are determinantal point\nprocesses (DPPs) and probabilistic circuits (PCs). This paper provides the\nfirst systematic study of their relationship. We propose a unified analysis and\nshared language for discussing DPPs and PCs. Then we establish theoretical\nbarriers for the unification of these two families, and prove that there are\ncases where DPPs have no compact representation as a class of PCs. We close\nwith a perspective on the central problem of unifying these tractable models.\n", "versions": [{"version": "v1", "created": "Fri, 26 Jun 2020 22:35:13 GMT"}], "update_date": "2020-06-30", "authors_parsed": [["Zhang", "Honghua", ""], ["Holtzen", "Steven", ""], ["Broeck", "Guy Van den", ""]]}, {"id": "2006.15311", "submitter": "Rakshitha Godahewa", "authors": "Rakshitha Godahewa, Trevor Yann, Christoph Bergmeir, Francois\n  Petitjean", "title": "Seasonal Averaged One-Dependence Estimators: A Novel Algorithm to\n  Address Seasonal Concept Drift in High-Dimensional Stream Classification", "comments": null, "journal-ref": "International Joint Conference on Neural Networks (IJCNN 2020)", "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stream classification methods classify a continuous stream of data as new\nlabelled samples arrive. They often also have to deal with concept drift. This\npaper focuses on seasonal drift in stream classification, which can be found in\nmany real-world application data sources. Traditional approaches of stream\nclassification consider seasonal drift by including seasonal dummy/indicator\nvariables or building separate models for each season. But these approaches\nhave strong limitations in high-dimensional classification problems, or with\ncomplex seasonal patterns. This paper explores how to best handle seasonal\ndrift in the specific context of news article categorization (or\nclassification/tagging), where seasonal drift is overwhelmingly the main type\nof drift present in the data, and for which the data are high-dimensional. We\nintroduce a novel classifier named Seasonal Averaged One-Dependence Estimators\n(SAODE), which extends the AODE classifier to handle seasonal drift by\nincluding time as a super parent. We assess our SAODE model using two large\nreal-world text mining related datasets each comprising approximately a million\nrecords, against nine state-of-the-art stream and concept drift classification\nmodels, with and without seasonal indicators and with separate models built for\neach season. Across five different evaluation techniques, we show that our\nmodel consistently outperforms other methods by a large margin where the\nresults are statistically significant.\n", "versions": [{"version": "v1", "created": "Sat, 27 Jun 2020 08:04:53 GMT"}], "update_date": "2020-06-30", "authors_parsed": [["Godahewa", "Rakshitha", ""], ["Yann", "Trevor", ""], ["Bergmeir", "Christoph", ""], ["Petitjean", "Francois", ""]]}, {"id": "2006.15410", "submitter": "Caleb Belth", "authors": "Caleb Belth, Xinyi Zheng, Danai Koutra", "title": "Mining Persistent Activity in Continually Evolving Networks", "comments": "9 pages, plus 2 pages of supplementary material. Accepted at KDD 2020", "journal-ref": null, "doi": "10.1145/3394486.3403136", "report-no": null, "categories": "cs.SI cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Frequent pattern mining is a key area of study that gives insights into the\nstructure and dynamics of evolving networks, such as social or road networks.\nHowever, not only does a network evolve, but often the way that it evolves,\nitself evolves. Thus, knowing, in addition to patterns' frequencies, for how\nlong and how regularly they have occurred---i.e., their persistence---can add\nto our understanding of evolving networks. In this work, we propose the problem\nof mining activity that persists through time in continually evolving\nnetworks---i.e., activity that repeatedly and consistently occurs. We extend\nthe notion of temporal motifs to capture activity among specific nodes, in what\nwe call activity snippets, which are small sequences of edge-updates that\nreoccur. We propose axioms and properties that a measure of persistence should\nsatisfy, and develop such a persistence measure. We also propose PENminer, an\nefficient framework for mining activity snippets' Persistence in Evolving\nNetworks, and design both offline and streaming algorithms. We apply PENminer\nto numerous real, large-scale evolving networks and edge streams, and find\nactivity that is surprisingly regular over a long period of time, but too\ninfrequent to be discovered by aggregate count alone, and bursts of activity\nexposed by their lack of persistence. Our findings with PENminer include\nneighborhoods in NYC where taxi traffic persisted through Hurricane Sandy, the\nopening of new bike-stations, characteristics of social network users, and\nmore. Moreover, we use PENminer towards identifying anomalies in multiple\nnetworks, outperforming baselines at identifying subtle anomalies by 9.8-48% in\nAUC.\n", "versions": [{"version": "v1", "created": "Sat, 27 Jun 2020 17:29:45 GMT"}], "update_date": "2020-06-30", "authors_parsed": [["Belth", "Caleb", ""], ["Zheng", "Xinyi", ""], ["Koutra", "Danai", ""]]}, {"id": "2006.15417", "submitter": "Ruihan Zhang", "authors": "Ruihan Zhang, Prashan Madumal, Tim Miller, Krista A. Ehinger, Benjamin\n  I. P. Rubinstein", "title": "Invertible Concept-based Explanations for CNN Models with Non-negative\n  Concept Activation Vectors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional neural network (CNN) models for computer vision are powerful\nbut lack explainability in their most basic form. This deficiency remains a key\nchallenge when applying CNNs in important domains. Recent work on explanations\nthrough feature importance of approximate linear models has moved from\ninput-level features (pixels or segments) to features from mid-layer feature\nmaps in the form of concept activation vectors (CAVs). CAVs contain\nconcept-level information and could be learned via clustering. In this work, we\nrethink the ACE algorithm of Ghorbani et~al., proposing an alternative\ninvertible concept-based explanation (ICE) framework to overcome its\nshortcomings. Based on the requirements of fidelity (approximate models to\ntarget models) and interpretability (being meaningful to people), we design\nmeasurements and evaluate a range of matrix factorization methods with our\nframework. We find that non-negative concept activation vectors (NCAVs) from\nnon-negative matrix factorization provide superior performance in\ninterpretability and fidelity based on computational and human subject\nexperiments. Our framework provides both local and global concept-level\nexplanations for pre-trained CNN models.\n", "versions": [{"version": "v1", "created": "Sat, 27 Jun 2020 17:57:26 GMT"}, {"version": "v2", "created": "Tue, 7 Jul 2020 10:13:10 GMT"}, {"version": "v3", "created": "Thu, 4 Feb 2021 13:54:53 GMT"}, {"version": "v4", "created": "Thu, 17 Jun 2021 12:31:21 GMT"}], "update_date": "2021-06-18", "authors_parsed": [["Zhang", "Ruihan", ""], ["Madumal", "Prashan", ""], ["Miller", "Tim", ""], ["Ehinger", "Krista A.", ""], ["Rubinstein", "Benjamin I. P.", ""]]}, {"id": "2006.15469", "submitter": "Abdelkader Nasreddine Belkacem", "authors": "Abdelkader Nasreddine Belkacem, Sofia Ouhbi, Abderrahmane Lakas,\n  Elhadj Benkhelifa, Chao Chen", "title": "End-to-End AI-Based Point-of-Care Diagnosis System for Classifying\n  Respiratory Illnesses and Early Detection of COVID-19", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.AI cs.AR cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Respiratory symptoms can be a caused by different underlying conditions, and\nare often caused by viral infections, such as Influenza-like illnesses or other\nemerging viruses like the Coronavirus. These respiratory viruses, often, have\ncommon symptoms, including coughing, high temperature, congested nose, and\ndifficulty breathing. However, early diagnosis of the type of the virus, can be\ncrucial, especially in cases such as the recent COVID-19 pandemic. One of the\nfactors that contributed to the spread of the pandemic, was the late diagnosis\nor confusing it with regular flu-like symptoms. Science has proved that one of\nthe possible differentiators of the underlying causes of these different\nrespiratory diseases is coughing, which comes in different types and forms.\nTherefore, a reliable lab-free tool for early and more accurate diagnosis that\ncan differentiate between different respiratory diseases is very much needed.\nThis paper proposes an end-to-end portable system that can record data from\npatients with symptom, including coughs (voluntary or involuntary) and\ntranslate them into health data for diagnosis, and with the aid of machine\nlearning, classify them into different respiratory illnesses, including\nCOVID-19. With the ongoing efforts to stop the spread of the COVID-19 disease\neverywhere today, and against similar diseases in the future, our proposed low\ncost and user-friendly solution can play an important part in the early\ndiagnosis.\n", "versions": [{"version": "v1", "created": "Sun, 28 Jun 2020 00:06:48 GMT"}], "update_date": "2020-07-02", "authors_parsed": [["Belkacem", "Abdelkader Nasreddine", ""], ["Ouhbi", "Sofia", ""], ["Lakas", "Abderrahmane", ""], ["Benkhelifa", "Elhadj", ""], ["Chen", "Chao", ""]]}, {"id": "2006.15509", "submitter": "Chen Liang", "authors": "Chen Liang, Yue Yu, Haoming Jiang, Siawpeng Er, Ruijia Wang, Tuo Zhao,\n  Chao Zhang", "title": "BOND: BERT-Assisted Open-Domain Named Entity Recognition with Distant\n  Supervision", "comments": "Proceedings of the 26th ACM SIGKDD Conference on Knowledge Discovery\n  and Data Mining (KDD '20)", "journal-ref": null, "doi": "10.1145/3394486.3403149", "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the open-domain named entity recognition (NER) problem under distant\nsupervision. The distant supervision, though does not require large amounts of\nmanual annotations, yields highly incomplete and noisy distant labels via\nexternal knowledge bases. To address this challenge, we propose a new\ncomputational framework -- BOND, which leverages the power of pre-trained\nlanguage models (e.g., BERT and RoBERTa) to improve the prediction performance\nof NER models. Specifically, we propose a two-stage training algorithm: In the\nfirst stage, we adapt the pre-trained language model to the NER tasks using the\ndistant labels, which can significantly improve the recall and precision; In\nthe second stage, we drop the distant labels, and propose a self-training\napproach to further improve the model performance. Thorough experiments on 5\nbenchmark datasets demonstrate the superiority of BOND over existing distantly\nsupervised NER methods. The code and distantly labeled data have been released\nin https://github.com/cliang1453/BOND.\n", "versions": [{"version": "v1", "created": "Sun, 28 Jun 2020 04:55:39 GMT"}], "update_date": "2020-06-30", "authors_parsed": [["Liang", "Chen", ""], ["Yu", "Yue", ""], ["Jiang", "Haoming", ""], ["Er", "Siawpeng", ""], ["Wang", "Ruijia", ""], ["Zhao", "Tuo", ""], ["Zhang", "Chao", ""]]}, {"id": "2006.15647", "submitter": "Chayan Sarkar", "authors": "Hrishav Bakul Barua, Chayan Sarkar, Achanna Anil Kumar, Arpan Pal,\n  Balamuralidhar P", "title": "I can attend a meeting too! Towards a human-like telepresence avatar\n  robot to attend meeting on your behalf", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Telepresence robots are used in various forms in various use-cases that helps\nto avoid physical human presence at the scene of action. In this work, we focus\non a telepresence robot that can be used to attend a meeting remotely with a\ngroup of people. Unlike a one-to-one meeting, participants in a group meeting\ncan be located at a different part of the room, especially in an informal\nsetup. As a result, all of them may not be at the viewing angle of the robot,\na.k.a. the remote participant. In such a case, to provide a better meeting\nexperience, the robot should localize the speaker and bring the speaker at the\ncenter of the viewing angle. Though sound source localization can easily be\ndone using a microphone-array, bringing the speaker or set of speakers at the\nviewing angle is not a trivial task. First of all, the robot should react only\nto a human voice, but not to the random noises. Secondly, if there are multiple\nspeakers, to whom the robot should face or should it rotate continuously with\nevery new speaker? Lastly, most robotic platforms are resource-constrained and\nto achieve a real-time response, i.e., avoiding network delay, all the\nalgorithms should be implemented within the robot itself. This article presents\na study and implementation of an attention shifting scheme in a telepresence\nmeeting scenario which best suits the needs and expectations of the collocated\nand remote attendees. We define a policy to decide when a robot should rotate\nand how much based on real-time speaker localization. Using user satisfaction\nstudy, we show the efficacy and usability of our system in the meeting\nscenario. Moreover, our system can be easily adapted to other scenarios where\nmultiple people are located.\n", "versions": [{"version": "v1", "created": "Sun, 28 Jun 2020 16:43:04 GMT"}], "update_date": "2020-06-30", "authors_parsed": [["Barua", "Hrishav Bakul", ""], ["Sarkar", "Chayan", ""], ["Kumar", "Achanna Anil", ""], ["Pal", "Arpan", ""], ["P", "Balamuralidhar", ""]]}, {"id": "2006.15673", "submitter": "Ferdinando Fioretto", "authors": "Ferdinando Fioretto, Pascal Van Hentenryck, Keyu Zhu", "title": "Differential Privacy of Hierarchical Census Data: An Optimization\n  Approach", "comments": "Corrected a claim in the Introduction and a typo in Model 1", "journal-ref": "Artificial Intelligence 296 (2021): 103475", "doi": "10.1016/j.artint.2021.103475", "report-no": null, "categories": "cs.DB cs.AI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper is motivated by applications of a Census Bureau interested in\nreleasing aggregate socio-economic data about a large population without\nrevealing sensitive information about any individual. The released information\ncan be the number of individuals living alone, the number of cars they own, or\ntheir salary brackets. Recent events have identified some of the privacy\nchallenges faced by these organizations. To address them, this paper presents a\nnovel differential-privacy mechanism for releasing hierarchical counts of\nindividuals. The counts are reported at multiple granularities (e.g., the\nnational, state, and county levels) and must be consistent across all levels.\nThe core of the mechanism is an optimization model that redistributes the noise\nintroduced to achieve differential privacy in order to meet the consistency\nconstraints between the hierarchical levels. The key technical contribution of\nthe paper shows that this optimization problem can be solved in polynomial time\nby exploiting the structure of its cost functions. Experimental results on very\nlarge, real datasets show that the proposed mechanism provides improvements of\nup to two orders of magnitude in terms of computational efficiency and accuracy\nwith respect to other state-of-the-art techniques.\n", "versions": [{"version": "v1", "created": "Sun, 28 Jun 2020 18:19:55 GMT"}, {"version": "v2", "created": "Sun, 9 May 2021 20:02:56 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Fioretto", "Ferdinando", ""], ["Van Hentenryck", "Pascal", ""], ["Zhu", "Keyu", ""]]}, {"id": "2006.15714", "submitter": "Zhe Xu", "authors": "Zhe Xu, Bo Wu, Aditya Ojha, Daniel Neider, Ufuk Topcu", "title": "Active Finite Reward Automaton Inference and Reinforcement Learning\n  Using Queries and Counterexamples", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the fact that deep reinforcement learning (RL) has surpassed\nhuman-level performances in various tasks, it still has several fundamental\nchallenges. First, most RL methods require intensive data from the exploration\nof the environment to achieve satisfactory performance. Second, the use of\nneural networks in RL renders it hard to interpret the internals of the system\nin a way that humans can understand. To address these two challenges, we\npropose a framework that enables an RL agent to reason over its exploration\nprocess and distill high-level knowledge for effectively guiding its future\nexplorations. Specifically, we propose a novel RL algorithm that learns\nhigh-level knowledge in the form of a finite reward automaton by using the L*\nlearning algorithm. We prove that in episodic RL, a finite reward automaton can\nexpress any non-Markovian bounded reward functions with finitely many reward\nvalues and approximate any non-Markovian bounded reward function (with\ninfinitely many reward values) with arbitrary precision. We also provide a\nlower bound for the episode length such that the proposed RL approach almost\nsurely converges to an optimal policy in the limit. We test this approach on\ntwo RL environments with non-Markovian reward functions, choosing a variety of\ntasks with increasing complexity for each environment. We compare our algorithm\nwith the state-of-the-art RL algorithms for non-Markovian reward functions,\nsuch as Joint Inference of Reward machines and Policies for RL (JIRP), Learning\nReward Machine (LRM), and Proximal Policy Optimization (PPO2). Our results show\nthat our algorithm converges to an optimal policy faster than other baseline\nmethods.\n", "versions": [{"version": "v1", "created": "Sun, 28 Jun 2020 21:13:08 GMT"}, {"version": "v2", "created": "Sat, 17 Apr 2021 20:42:32 GMT"}, {"version": "v3", "created": "Thu, 17 Jun 2021 20:02:21 GMT"}, {"version": "v4", "created": "Sat, 3 Jul 2021 01:51:29 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Xu", "Zhe", ""], ["Wu", "Bo", ""], ["Ojha", "Aditya", ""], ["Neider", "Daniel", ""], ["Topcu", "Ufuk", ""]]}, {"id": "2006.15757", "submitter": "Nikka Mofid", "authors": "Rui Aguiar, Nikka Mofid, Hyunji Alex Nam", "title": "Exploring Optimal Control With Observations at a Cost", "comments": "8 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There has been a current trend in reinforcement learning for healthcare\nliterature, where in order to prepare clinical datasets, researchers will carry\nforward the last results of the non-administered test known as the\nlast-observation-carried-forward (LOCF) value to fill in gaps, assuming that it\nis still an accurate indicator of the patient's current state. These values are\ncarried forward without maintaining information about exactly how these values\nwere imputed, leading to ambiguity. Our approach models this problem using\nOpenAI Gym's Mountain Car and aims to address when to observe the patient's\nphysiological state and partly how to intervene, as we have assumed we can only\nact after following an observation. So far, we have found that for a\nlast-observation-carried-forward implementation of the state space, augmenting\nthe state with counters for each state variable tracking the time since last\nobservation was made, improves the predictive performance of an agent,\nsupporting the notion of \"informative missingness\", and using a neural network\nbased Dynamics Model to predict the most probable next state value of\nnon-observed state variables instead of carrying forward the last observed\nvalue through LOCF further improves the agent's performance, leading to faster\nconvergence and reduced variance.\n", "versions": [{"version": "v1", "created": "Mon, 29 Jun 2020 00:42:05 GMT"}], "update_date": "2020-06-30", "authors_parsed": [["Aguiar", "Rui", ""], ["Mofid", "Nikka", ""], ["Nam", "Hyunji Alex", ""]]}, {"id": "2006.15762", "submitter": "Kenneth Marino", "authors": "Kenneth Marino, Rob Fergus, Arthur Szlam, Abhinav Gupta", "title": "Empirically Verifying Hypotheses Using Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper formulates hypothesis verification as an RL problem. Specifically,\nwe aim to build an agent that, given a hypothesis about the dynamics of the\nworld, can take actions to generate observations which can help predict whether\nthe hypothesis is true or false. Existing RL algorithms fail to solve this\ntask, even for simple environments. In order to train the agents, we exploit\nthe underlying structure of many hypotheses, factorizing them as\n{pre-condition, action sequence, post-condition} triplets. By leveraging this\nstructure we show that RL agents are able to succeed at the task. Furthermore,\nsubsequent fine-tuning of the policies allows the agent to correctly verify\nhypotheses not amenable to the above factorization.\n", "versions": [{"version": "v1", "created": "Mon, 29 Jun 2020 01:01:10 GMT"}], "update_date": "2020-06-30", "authors_parsed": [["Marino", "Kenneth", ""], ["Fergus", "Rob", ""], ["Szlam", "Arthur", ""], ["Gupta", "Abhinav", ""]]}, {"id": "2006.15807", "submitter": "Zahi Kakish", "authors": "Zahi M. Kakish, Karthik Elamvazhuthi, Spring Berman", "title": "Using Reinforcement Learning to Herd a Robotic Swarm to a Target\n  Distribution", "comments": "Paper was submitted to Conference on Robot Learning 2019 and IEEE\n  Robotics and Automation Letters 2020 Revised, updated, and submitted to\n  DARS/SWARMS 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present a reinforcement learning approach to designing a\ncontrol policy for a \"leader\" agent that herds a swarm of \"follower\" agents,\nvia repulsive interactions, as quickly as possible to a target probability\ndistribution over a strongly connected graph. The leader control policy is a\nfunction of the swarm distribution, which evolves over time according to a\nmean-field model in the form of an ordinary difference equation. The dependence\nof the policy on agent populations at each graph vertex, rather than on\nindividual agent activity, simplifies the observations required by the leader\nand enables the control strategy to scale with the number of agents. Two\nTemporal-Difference learning algorithms, SARSA and Q-Learning, are used to\ngenerate the leader control policy based on the follower agent distribution and\nthe leader's location on the graph. A simulation environment corresponding to a\ngrid graph with 4 vertices was used to train and validate the control policies\nfor follower agent populations ranging from 10 to 100. Finally, the control\npolicies trained on 100 simulated agents were used to successfully redistribute\na physical swarm of 10 small robots to a target distribution among 4 spatial\nregions.\n", "versions": [{"version": "v1", "created": "Mon, 29 Jun 2020 04:55:59 GMT"}, {"version": "v2", "created": "Sat, 12 Dec 2020 20:52:26 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["Kakish", "Zahi M.", ""], ["Elamvazhuthi", "Karthik", ""], ["Berman", "Spring", ""]]}, {"id": "2006.15811", "submitter": "Jake Chandler", "authors": "Jake Chandler, Richard Booth", "title": "Revision by Conditionals: From Hook to Arrow", "comments": "Extended version of a paper accepted to KR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The belief revision literature has largely focussed on the issue of how to\nrevise one's beliefs in the light of information regarding matters of fact.\nHere we turn to an important but comparatively neglected issue: How might one\nextend a revision operator to handle conditionals as input? Our approach to\nthis question of 'conditional revision' is distinctive insofar as it abstracts\nfrom the controversial details of how to revise by factual sentences. We\nintroduce a 'plug and play' method for uniquely extending any iterated belief\nrevision operator to the conditional case. The flexibility of our approach is\nachieved by having the result of a conditional revision by a Ramsey Test\nconditional ('arrow') determined by that of a plain revision by its\ncorresponding material conditional ('hook'). It is shown to satisfy a number of\nnew constraints that are of independent interest.\n", "versions": [{"version": "v1", "created": "Mon, 29 Jun 2020 05:12:30 GMT"}], "update_date": "2020-06-30", "authors_parsed": [["Chandler", "Jake", ""], ["Booth", "Richard", ""]]}, {"id": "2006.15820", "submitter": "Binghong Chen", "authors": "Binghong Chen, Chengtao Li, Hanjun Dai, Le Song", "title": "Retro*: Learning Retrosynthetic Planning with Neural Guided A* Search", "comments": "Presented at ICML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Retrosynthetic planning is a critical task in organic chemistry which\nidentifies a series of reactions that can lead to the synthesis of a target\nproduct. The vast number of possible chemical transformations makes the size of\nthe search space very big, and retrosynthetic planning is challenging even for\nexperienced chemists. However, existing methods either require expensive return\nestimation by rollout with high variance, or optimize for search speed rather\nthan the quality. In this paper, we propose Retro*, a neural-based A*-like\nalgorithm that finds high-quality synthetic routes efficiently. It maintains\nthe search as an AND-OR tree, and learns a neural search bias with off-policy\ndata. Then guided by this neural network, it performs best-first search\nefficiently during new planning episodes. Experiments on benchmark USPTO\ndatasets show that, our proposed method outperforms existing state-of-the-art\nwith respect to both the success rate and solution quality, while being more\nefficient at the same time.\n", "versions": [{"version": "v1", "created": "Mon, 29 Jun 2020 05:53:33 GMT"}], "update_date": "2020-06-30", "authors_parsed": [["Chen", "Binghong", ""], ["Li", "Chengtao", ""], ["Dai", "Hanjun", ""], ["Song", "Le", ""]]}, {"id": "2006.15826", "submitter": "Tianbo Gu", "authors": "Tianbo Gu, Allaukik Abhishek, Hao Fu, Huanle Zhang, Debraj Basu,\n  Prasant Mohapatra", "title": "Towards Learning-automation IoT Attack Detection through Reinforcement\n  Learning", "comments": "11 pages, 8 figures, 2 tables, to appear in the 21st IEEE\n  International Symposium on a World of Wireless, Mobile and Multimedia\n  Networks (IEEE WoWMoM 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As a massive number of the Internet of Things (IoT) devices are deployed, the\nsecurity and privacy issues in IoT arouse more and more attention. The IoT\nattacks are causing tremendous loss to the IoT networks and even threatening\nhuman safety. Compared to traditional networks, IoT networks have unique\ncharacteristics, which make the attack detection more challenging. First, the\nheterogeneity of platforms, protocols, software, and hardware exposes various\nvulnerabilities. Second, in addition to the traditional high-rate attacks, the\nlow-rate attacks are also extensively used by IoT attackers to obfuscate the\nlegitimate and malicious traffic. These low-rate attacks are challenging to\ndetect and can persist in the networks. Last, the attackers are evolving to be\nmore intelligent and can dynamically change their attack strategies based on\nthe environment feedback to avoid being detected, making it more challenging\nfor the defender to discover a consistent pattern to identify the attack.\n  In order to adapt to the new characteristics in IoT attacks, we propose a\nreinforcement learning-based attack detection model that can automatically\nlearn and recognize the transformation of the attack pattern. Therefore, we can\ncontinuously detect IoT attacks with less human intervention. In this paper, we\nexplore the crucial features of IoT traffics and utilize the entropy-based\nmetrics to detect both the high-rate and low-rate IoT attacks. Afterward, we\nleverage the reinforcement learning technique to continuously adjust the attack\ndetection threshold based on the detection feedback, which optimizes the\ndetection and the false alarm rate. We conduct extensive experiments over a\nreal IoT attack dataset and demonstrate the effectiveness of our IoT attack\ndetection framework.\n", "versions": [{"version": "v1", "created": "Mon, 29 Jun 2020 06:12:45 GMT"}], "update_date": "2020-06-30", "authors_parsed": [["Gu", "Tianbo", ""], ["Abhishek", "Allaukik", ""], ["Fu", "Hao", ""], ["Zhang", "Huanle", ""], ["Basu", "Debraj", ""], ["Mohapatra", "Prasant", ""]]}, {"id": "2006.15830", "submitter": "Jinhyuk Lee", "authors": "Jinhyuk Lee, Sean S. Yi, Minbyul Jeong, Mujeen Sung, Wonjin Yoon,\n  Yonghwa Choi, Miyoung Ko, Jaewoo Kang", "title": "Answering Questions on COVID-19 in Real-Time", "comments": "10 pages, EMNLP NLP-COVID Workshop 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recent outbreak of the novel coronavirus is wreaking havoc on the world\nand researchers are struggling to effectively combat it. One reason why the\nfight is difficult is due to the lack of information and knowledge. In this\nwork, we outline our effort to contribute to shrinking this knowledge vacuum by\ncreating covidAsk, a question answering (QA) system that combines biomedical\ntext mining and QA techniques to provide answers to questions in real-time. Our\nsystem also leverages information retrieval (IR) approaches to provide\nentity-level answers that are complementary to QA models. Evaluation of\ncovidAsk is carried out by using a manually created dataset called COVID-19\nQuestions which is based on information from various sources, including the CDC\nand the WHO. We hope our system will be able to aid researchers in their search\nfor knowledge and information not only for COVID-19, but for future pandemics\nas well.\n", "versions": [{"version": "v1", "created": "Mon, 29 Jun 2020 06:34:35 GMT"}, {"version": "v2", "created": "Fri, 9 Oct 2020 08:42:30 GMT"}], "update_date": "2020-10-12", "authors_parsed": [["Lee", "Jinhyuk", ""], ["Yi", "Sean S.", ""], ["Jeong", "Minbyul", ""], ["Sung", "Mujeen", ""], ["Yoon", "Wonjin", ""], ["Choi", "Yonghwa", ""], ["Ko", "Miyoung", ""], ["Kang", "Jaewoo", ""]]}, {"id": "2006.15865", "submitter": "Aditi Shenvi", "authors": "Aditi Shenvi and Jim Q. Smith", "title": "Propagation for Dynamic Continuous Time Chain Event Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Chain Event Graphs (CEGs) are a family of event-based graphical models that\nrepresent context-specific conditional independences typically exhibited by\nasymmetric state space problems. The class of continuous time dynamic CEGs\n(CT-DCEGs) provides a factored representation of longitudinally evolving\ntrajectories of a process in continuous time. Temporal evidence in a CT-DCEG\nintroduces dependence between its transition and holding time distributions. We\npresent a tractable exact inferential scheme analogous to the scheme in\nKj{\\ae}rulff (1992) for discrete Dynamic Bayesian Networks (DBNs) which employs\nstandard junction tree inference by \"unrolling\" the DBN. To enable this scheme,\nwe present an extension of the standard CEG propagation algorithm (Thwaites et\nal., 2008). Interestingly, the CT-DCEG benefits from simplification of its\ngraph on observing compatible evidence while preserving the still relevant\nsymmetries within the asymmetric network. Our results indicate that the CT-DCEG\nis preferred to DBNs and continuous time BNs under contexts involving\nsignificant asymmetry and a natural total ordering of the process evolution.\n", "versions": [{"version": "v1", "created": "Mon, 29 Jun 2020 08:24:57 GMT"}], "update_date": "2020-06-30", "authors_parsed": [["Shenvi", "Aditi", ""], ["Smith", "Jim Q.", ""]]}, {"id": "2006.15920", "submitter": "Quanshi Zhang", "authors": "Jie Ren, Mingjie Li, Zexu Liu, Quanshi Zhang", "title": "Interpreting and Disentangling Feature Components of Various Complexity\n  from DNNs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper aims to define, quantify, and analyze the feature complexity that\nis learned by a DNN. We propose a generic definition for the feature\ncomplexity. Given the feature of a certain layer in the DNN, our method\ndisentangles feature components of different complexity orders from the\nfeature. We further design a set of metrics to evaluate the reliability, the\neffectiveness, and the significance of over-fitting of these feature\ncomponents. Furthermore, we successfully discover a close relationship between\nthe feature complexity and the performance of DNNs. As a generic mathematical\ntool, the feature complexity and the proposed metrics can also be used to\nanalyze the success of network compression and knowledge distillation.\n", "versions": [{"version": "v1", "created": "Mon, 29 Jun 2020 10:24:27 GMT"}], "update_date": "2020-06-30", "authors_parsed": [["Ren", "Jie", ""], ["Li", "Mingjie", ""], ["Liu", "Zexu", ""], ["Zhang", "Quanshi", ""]]}, {"id": "2006.15960", "submitter": "Emmanuel Dauc\\'e", "authors": "Emmanuel Dauc\\'e", "title": "End-Effect Exploration Drive for Effective Motor Learning", "comments": "6 pages, 3 figures, submitted to IWAI 2020 (1st International\n  Workshop on Active Inference)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.NE cs.RO q-bio.NC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Stemming on the idea that a key objective in reinforcement learning is to\ninvert a target distribution of effects, end-effect drives are proposed as an\neffective way to implement goal-directed motor learning, in the absence of an\nexplicit forward model. An end-effect model relies on a simple statistical\nrecording of the effect of the current policy, here used as a substitute for\nthe more resource-demanding forward models. When combined with a reward\nstructure, it forms the core of a lightweight variational free energy\nminimization setup. The main difficulty lies in the maintenance of this\nsimplified effect model together with the online update of the policy. When the\nprior target distribution is uniform, it provides a ways to learn an efficient\nexploration policy, consistently with the intrinsic curiosity principles. When\ncombined with an extrinsic reward, our approach is finally shown to provide a\nfaster training than traditional off-policy techniques.\n", "versions": [{"version": "v1", "created": "Mon, 29 Jun 2020 11:59:34 GMT"}, {"version": "v2", "created": "Mon, 5 Oct 2020 14:43:05 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Dauc\u00e9", "Emmanuel", ""]]}, {"id": "2006.15983", "submitter": "Gabrielle Ras", "authors": "Gabri\\\"elle Ras, Luca Ambrogioni, Pim Haselager, Marcel A.J. van\n  Gerven, Umut G\\\"u\\c{c}l\\\"u", "title": "Explainable 3D Convolutional Neural Networks by Learning Temporal\n  Transformations", "comments": "10 pages, 5 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we introduce the temporally factorized 3D convolution (3TConv)\nas an interpretable alternative to the regular 3D convolution (3DConv). In a\n3TConv the 3D convolutional filter is obtained by learning a 2D filter and a\nset of temporal transformation parameters, resulting in a sparse filter where\nthe 2D slices are sequentially dependent on each other in the temporal\ndimension. We demonstrate that 3TConv learns temporal transformations that\nafford a direct interpretation. The temporal parameters can be used in\ncombination with various existing 2D visualization methods. We also show that\ninsight about what the model learns can be achieved by analyzing the\ntransformation parameter statistics on a layer and model level. Finally, we\nimplicitly demonstrate that, in popular ConvNets, the 2DConv can be replaced\nwith a 3TConv and that the weights can be transferred to yield pretrained\n3TConvs. pretrained 3TConvnets leverage more than a decade of work on\ntraditional 2DConvNets by being able to make use of features that have been\nproven to deliver excellent results on image classification benchmarks.\n", "versions": [{"version": "v1", "created": "Mon, 29 Jun 2020 12:29:30 GMT"}], "update_date": "2020-06-30", "authors_parsed": [["Ras", "Gabri\u00eblle", ""], ["Ambrogioni", "Luca", ""], ["Haselager", "Pim", ""], ["van Gerven", "Marcel A. J.", ""], ["G\u00fc\u00e7l\u00fc", "Umut", ""]]}, {"id": "2006.16035", "submitter": "Dalcimar Casanova", "authors": "Kallil M. C. Zielinski and Marcelo Teixeira and Richardson Ribeiro and\n  Dalcimar Casanova", "title": "Concept and the implementation of a tool to convert industry 4.0\n  environments modeled as FSM to an OpenAI Gym wrapper", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.FL cs.SY eess.SY stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Industry 4.0 systems have a high demand for optimization in their tasks,\nwhether to minimize cost, maximize production, or even synchronize their\nactuators to finish or speed up the manufacture of a product. Those challenges\nmake industrial environments a suitable scenario to apply all modern\nreinforcement learning (RL) concepts. The main difficulty, however, is the lack\nof that industrial environments. In this way, this work presents the concept\nand the implementation of a tool that allows us to convert any dynamic system\nmodeled as an FSM to the open-source Gym wrapper. After that, it is possible to\nemploy any RL methods to optimize any desired task. In the first tests of the\nproposed tool, we show traditional Q-learning and Deep Q-learning methods\nrunning over two simple environments.\n", "versions": [{"version": "v1", "created": "Mon, 29 Jun 2020 13:28:41 GMT"}], "update_date": "2020-06-30", "authors_parsed": [["Zielinski", "Kallil M. C.", ""], ["Teixeira", "Marcelo", ""], ["Ribeiro", "Richardson", ""], ["Casanova", "Dalcimar", ""]]}, {"id": "2006.16068", "submitter": "Shuyue Hu", "authors": "Shuyue Hu, Chin-Wing Leung, Ho-fung Leung, Harold Soh", "title": "The Evolutionary Dynamics of Independent Learning Agents in Population\n  Games", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding the evolutionary dynamics of reinforcement learning under\nmulti-agent settings has long remained an open problem. While previous works\nprimarily focus on 2-player games, we consider population games, which model\nthe strategic interactions of a large population comprising small and anonymous\nagents. This paper presents a formal relation between stochastic processes and\nthe dynamics of independent learning agents who reason based on the reward\nsignals. Using a master equation approach, we provide a novel unified framework\nfor characterising population dynamics via a single partial differential\nequation (Theorem 1). Through a case study involving Cross learning agents, we\nillustrate that Theorem 1 allows us to identify qualitatively different\nevolutionary dynamics, to analyse steady states, and to gain insights into the\nexpected behaviour of a population. In addition, we present extensive\nexperimental results validating that Theorem 1 holds for a variety of learning\nmethods and population games.\n", "versions": [{"version": "v1", "created": "Mon, 29 Jun 2020 14:22:23 GMT"}], "update_date": "2020-06-30", "authors_parsed": [["Hu", "Shuyue", ""], ["Leung", "Chin-Wing", ""], ["Leung", "Ho-fung", ""], ["Soh", "Harold", ""]]}, {"id": "2006.16171", "submitter": "Yulong Gu", "authors": "Yulong Gu, Yu Guan, Paolo Missier", "title": "Building Rule Hierarchies for Efficient Logical Rule Learning from\n  Knowledge Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many systems have been developed in recent years to mine logical rules from\nlarge-scale Knowledge Graphs (KGs), on the grounds that representing\nregularities as rules enables both the interpretable inference of new facts,\nand the explanation of known facts. Among these systems, the walk-based methods\nthat generate the instantiated rules containing constants by abstracting\nsampled paths in KGs demonstrate strong predictive performance and\nexpressivity. However, due to the large volume of possible rules, these systems\ndo not scale well where computational resources are often wasted on generating\nand evaluating unpromising rules. In this work, we address such scalability\nissues by proposing new methods for pruning unpromising rules using rule\nhierarchies. The approach consists of two phases. Firstly, since rule\nhierarchies are not readily available in walk-based methods, we have built a\nRule Hierarchy Framework (RHF), which leverages a collection of subsumption\nframeworks to build a proper rule hierarchy from a set of learned rules. And\nsecondly, we adapt RHF to an existing rule learner where we design and\nimplement two methods for Hierarchical Pruning (HPMs), which utilize the\ngenerated hierarchies to remove irrelevant and redundant rules. Through\nexperiments over four public benchmark datasets, we show that the application\nof HPMs is effective in removing unpromising rules, which leads to significant\nreductions in the runtime as well as in the number of learned rules, without\ncompromising the predictive performance.\n", "versions": [{"version": "v1", "created": "Mon, 29 Jun 2020 16:33:30 GMT"}, {"version": "v2", "created": "Tue, 30 Jun 2020 10:14:30 GMT"}, {"version": "v3", "created": "Thu, 22 Oct 2020 23:32:53 GMT"}], "update_date": "2020-10-26", "authors_parsed": [["Gu", "Yulong", ""], ["Guan", "Yu", ""], ["Missier", "Paolo", ""]]}, {"id": "2006.16309", "submitter": "Bibek Paudel", "authors": "Mario Arduini, Lorenzo Noci, Federico Pirovano, Ce Zhang, Yash Raj\n  Shrestha, Bibek Paudel", "title": "Adversarial Learning for Debiasing Knowledge Graph Embeddings", "comments": "MLG 2020 at the ACM SIGKDD Conference on Knowledge Discovery and Data\n  Mining (KDD) 2020", "journal-ref": "MLG 2020 at the ACM SIGKDD Conference on Knowledge Discovery and\n  Data Mining (KDD) 2020", "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge Graphs (KG) are gaining increasing attention in both academia and\nindustry. Despite their diverse benefits, recent research have identified\nsocial and cultural biases embedded in the representations learned from KGs.\nSuch biases can have detrimental consequences on different population and\nminority groups as applications of KG begin to intersect and interact with\nsocial spheres. This paper aims at identifying and mitigating such biases in\nKnowledge Graph (KG) embeddings. As a first step, we explore popularity bias --\nthe relationship between node popularity and link prediction accuracy. In case\nof node2vec graph embeddings, we find that prediction accuracy of the embedding\nis negatively correlated with the degree of the node. However, in case of\nknowledge-graph embeddings (KGE), we observe an opposite trend. As a second\nstep, we explore gender bias in KGE, and a careful examination of popular KGE\nalgorithms suggest that sensitive attribute like the gender of a person can be\npredicted from the embedding. This implies that such biases in popular KGs is\ncaptured by the structural properties of the embedding. As a preliminary\nsolution to debiasing KGs, we introduce a novel framework to filter out the\nsensitive attribute information from the KG embeddings, which we call FAN\n(Filtering Adversarial Network). We also suggest the applicability of FAN for\ndebiasing other network embeddings which could be explored in future work.\n", "versions": [{"version": "v1", "created": "Mon, 29 Jun 2020 18:36:15 GMT"}, {"version": "v2", "created": "Thu, 18 Feb 2021 02:16:59 GMT"}], "update_date": "2021-02-22", "authors_parsed": [["Arduini", "Mario", ""], ["Noci", "Lorenzo", ""], ["Pirovano", "Federico", ""], ["Zhang", "Ce", ""], ["Shrestha", "Yash Raj", ""], ["Paudel", "Bibek", ""]]}, {"id": "2006.16318", "submitter": "Abhishek Naik", "authors": "Yi Wan, Abhishek Naik, Richard S. Sutton", "title": "Learning and Planning in Average-Reward Markov Decision Processes", "comments": "In Proceedings of ICML 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce learning and planning algorithms for average-reward MDPs,\nincluding 1) the first general proven-convergent off-policy model-free control\nalgorithm without reference states, 2) the first proven-convergent off-policy\nmodel-free prediction algorithm, and 3) the first off-policy learning algorithm\nthat converges to the actual value function rather than to the value function\nplus an offset. All of our algorithms are based on using the\ntemporal-difference error rather than the conventional error when updating the\nestimate of the average reward. Our proof techniques are a slight\ngeneralization of those by Abounadi, Bertsekas, and Borkar (2001). In\nexperiments with an Access-Control Queuing Task, we show some of the\ndifficulties that can arise when using methods that rely on reference states\nand argue that our new algorithms can be significantly easier to use.\n", "versions": [{"version": "v1", "created": "Mon, 29 Jun 2020 19:03:24 GMT"}, {"version": "v2", "created": "Fri, 19 Feb 2021 22:38:49 GMT"}, {"version": "v3", "created": "Mon, 28 Jun 2021 10:06:53 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Wan", "Yi", ""], ["Naik", "Abhishek", ""], ["Sutton", "Richard S.", ""]]}, {"id": "2006.16322", "submitter": "Subham Sekhar Sahoo", "authors": "Subham Sekhar Sahoo, Subhashini Venugopalan, Li Li, Rishabh Singh,\n  Patrick Riley", "title": "Scaling Symbolic Methods using Gradients for Neural Model Explanation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Symbolic techniques based on Satisfiability Modulo Theory (SMT) solvers have\nbeen proposed for analyzing and verifying neural network properties, but their\nusage has been fairly limited owing to their poor scalability with larger\nnetworks. In this work, we propose a technique for combining gradient-based\nmethods with symbolic techniques to scale such analyses and demonstrate its\napplication for model explanation. In particular, we apply this technique to\nidentify minimal regions in an input that are most relevant for a neural\nnetwork's prediction. Our approach uses gradient information (based on\nIntegrated Gradients) to focus on a subset of neurons in the first layer, which\nallows our technique to scale to large networks. The corresponding SMT\nconstraints encode the minimal input mask discovery problem such that after\nmasking the input, the activations of the selected neurons are still above a\nthreshold. After solving for the minimal masks, our approach scores the mask\nregions to generate a relative ordering of the features within the mask. This\nproduces a saliency map which explains \"where a model is looking\" when making a\nprediction. We evaluate our technique on three datasets - MNIST, ImageNet, and\nBeer Reviews, and demonstrate both quantitatively and qualitatively that the\nregions generated by our approach are sparser and achieve higher saliency\nscores compared to the gradient-based methods alone. Code and examples are at -\nhttps://github.com/google-research/google-research/tree/master/smug_saliency\n", "versions": [{"version": "v1", "created": "Mon, 29 Jun 2020 19:12:22 GMT"}, {"version": "v2", "created": "Sat, 3 Oct 2020 00:45:28 GMT"}, {"version": "v3", "created": "Mon, 15 Mar 2021 19:19:35 GMT"}, {"version": "v4", "created": "Wed, 5 May 2021 14:13:39 GMT"}], "update_date": "2021-05-06", "authors_parsed": [["Sahoo", "Subham Sekhar", ""], ["Venugopalan", "Subhashini", ""], ["Li", "Li", ""], ["Singh", "Rishabh", ""], ["Riley", "Patrick", ""]]}, {"id": "2006.16341", "submitter": "Pasha Khosravi", "authors": "Pasha Khosravi, Antonio Vergari, YooJung Choi, Yitao Liang, Guy Van\n  den Broeck", "title": "Handling Missing Data in Decision Trees: A Probabilistic Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Decision trees are a popular family of models due to their attractive\nproperties such as interpretability and ability to handle heterogeneous data.\nConcurrently, missing data is a prevalent occurrence that hinders performance\nof machine learning models. As such, handling missing data in decision trees is\na well studied problem. In this paper, we tackle this problem by taking a\nprobabilistic approach. At deployment time, we use tractable density estimators\nto compute the \"expected prediction\" of our models. At learning time, we\nfine-tune parameters of already learned trees by minimizing their \"expected\nprediction loss\" w.r.t.\\ our density estimators. We provide brief experiments\nshowcasing effectiveness of our methods compared to few baselines.\n", "versions": [{"version": "v1", "created": "Mon, 29 Jun 2020 19:54:54 GMT"}], "update_date": "2020-07-01", "authors_parsed": [["Khosravi", "Pasha", ""], ["Vergari", "Antonio", ""], ["Choi", "YooJung", ""], ["Liang", "Yitao", ""], ["Broeck", "Guy Van den", ""]]}, {"id": "2006.16365", "submitter": "Hung Nghiep Tran", "authors": "Hung Nghiep Tran and Atsuhiro Takasu", "title": "Multi-Partition Embedding Interaction with Block Term Format for\n  Knowledge Graph Completion", "comments": "ECAI 2020. Including state-of-the-art results for very small models\n  in appendix", "journal-ref": "European Conference on Artificial Intelligence (ECAI 2020)", "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge graph completion is an important task that aims to predict the\nmissing relational link between entities. Knowledge graph embedding methods\nperform this task by representing entities and relations as embedding vectors\nand modeling their interactions to compute the matching score of each triple.\nPrevious work has usually treated each embedding as a whole and has modeled the\ninteractions between these whole embeddings, potentially making the model\nexcessively expensive or requiring specially designed interaction mechanisms.\nIn this work, we propose the multi-partition embedding interaction (MEI) model\nwith block term format to systematically address this problem. MEI divides each\nembedding into a multi-partition vector to efficiently restrict the\ninteractions. Each local interaction is modeled with the Tucker tensor format\nand the full interaction is modeled with the block term tensor format, enabling\nMEI to control the trade-off between expressiveness and computational cost,\nlearn the interaction mechanisms from data automatically, and achieve\nstate-of-the-art performance on the link prediction task. In addition, we\ntheoretically study the parameter efficiency problem and derive a simple\nempirically verified criterion for optimal parameter trade-off. We also apply\nthe framework of MEI to provide a new generalized explanation for several\nspecially designed interaction mechanisms in previous models.\n", "versions": [{"version": "v1", "created": "Mon, 29 Jun 2020 20:37:11 GMT"}], "update_date": "2020-07-01", "authors_parsed": [["Tran", "Hung Nghiep", ""], ["Takasu", "Atsuhiro", ""]]}, {"id": "2006.16395", "submitter": "Olivier Buffet", "authors": "Olivier Buffet, Jilles Dibangoye, Aur\\'elien Delage, Abdallah\n  Saffidine, Vincent Thomas", "title": "On Bellman's Optimality Principle for zs-POSGs", "comments": "18 pages, 0 figures, 1 algorithm", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many non-trivial sequential decision-making problems are efficiently solved\nby relying on Bellman's optimality principle, i.e., exploiting the fact that\nsub-problems are nested recursively within the original problem. Here we show\nhow it can apply to (infinite horizon) 2-player zero-sum partially observable\nstochastic games (zs-POSGs) by (i) taking a central planner's viewpoint, which\ncan only reason on a sufficient statistic called occupancy state, and (ii)\nturning such problems into zero-sum occupancy Markov games (zs-OMGs). Then,\nexploiting the Lipschitz-continuity of the value function in occupancy space,\none can derive a version of the HSVI algorithm (Heuristic Search Value\nIteration) that provably finds an $\\epsilon$-Nash equilibrium in finite time.\n", "versions": [{"version": "v1", "created": "Mon, 29 Jun 2020 21:23:10 GMT"}], "update_date": "2020-07-01", "authors_parsed": [["Buffet", "Olivier", ""], ["Dibangoye", "Jilles", ""], ["Delage", "Aur\u00e9lien", ""], ["Saffidine", "Abdallah", ""], ["Thomas", "Vincent", ""]]}, {"id": "2006.16404", "submitter": "Davide Lanza", "authors": "Davide Lanza, Paolo Solinas, Fulvio Mastrogiovanni", "title": "Multi-sensory Integration in a Quantum-Like Robot Perception Model", "comments": "Paper submitted to the 17th International Symposium on Experimental\n  Robotics, Malta, Nov. 9-12, 2020", "journal-ref": null, "doi": "10.1007/978-3-030-71151-1_44", "report-no": null, "categories": "cs.RO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Formalisms inspired by Quantum theory have been used in Cognitive Science for\ndecades. Indeed, Quantum-Like (QL) approaches provide descriptive features that\nare inherently suitable for perception, cognition, and decision processing. A\npreliminary study on the feasibility of a QL robot perception model has been\ncarried out for a robot with limited sensing capabilities. In this paper, we\ngeneralize such a model for multi-sensory inputs, creating a multidimensional\nworld representation directly based on sensor readings. Given a 3-dimensional\ncase study, we highlight how this model provides a compact and elegant\nrepresentation, embodying features that are extremely useful for modeling\nuncertainty and decision. Moreover, the model enables to naturally define query\noperators to inspect any world state, which answers quantifies the robot's\ndegree of belief on that state.\n", "versions": [{"version": "v1", "created": "Mon, 29 Jun 2020 21:47:33 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Lanza", "Davide", ""], ["Solinas", "Paolo", ""], ["Mastrogiovanni", "Fulvio", ""]]}, {"id": "2006.16437", "submitter": "Steven Jecmen", "authors": "Steven Jecmen, Hanrui Zhang, Ryan Liu, Nihar B. Shah, Vincent\n  Conitzer, Fei Fang", "title": "Mitigating Manipulation in Peer Review via Randomized Reviewer\n  Assignments", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider three important challenges in conference peer review: (i)\nreviewers maliciously attempting to get assigned to certain papers to provide\npositive reviews, possibly as part of quid-pro-quo arrangements with the\nauthors; (ii) \"torpedo reviewing,\" where reviewers deliberately attempt to get\nassigned to certain papers that they dislike in order to reject them; (iii)\nreviewer de-anonymization on release of the similarities and the\nreviewer-assignment code. On the conceptual front, we identify connections\nbetween these three problems and present a framework that brings all these\nchallenges under a common umbrella. We then present a (randomized) algorithm\nfor reviewer assignment that can optimally solve the reviewer-assignment\nproblem under any given constraints on the probability of assignment for any\nreviewer-paper pair. We further consider the problem of restricting the joint\nprobability that certain suspect pairs of reviewers are assigned to certain\npapers, and show that this problem is NP-hard for arbitrary constraints on\nthese joint probabilities but efficiently solvable for a practical special\ncase. Finally, we experimentally evaluate our algorithms on datasets from past\nconferences, where we observe that they can limit the chance that any malicious\nreviewer gets assigned to their desired paper to 50% while producing\nassignments with over 90% of the total optimal similarity. Our algorithms still\nachieve this similarity while also preventing reviewers with close associations\nfrom being assigned to the same paper.\n", "versions": [{"version": "v1", "created": "Mon, 29 Jun 2020 23:55:53 GMT"}, {"version": "v2", "created": "Fri, 23 Oct 2020 20:08:50 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Jecmen", "Steven", ""], ["Zhang", "Hanrui", ""], ["Liu", "Ryan", ""], ["Shah", "Nihar B.", ""], ["Conitzer", "Vincent", ""], ["Fang", "Fei", ""]]}, {"id": "2006.16469", "submitter": "Fnu Suya", "authors": "Fnu Suya, Saeed Mahloujifar, Anshuman Suri, David Evans, Yuan Tian", "title": "Model-Targeted Poisoning Attacks with Provable Convergence", "comments": "32 pages, code available at:\n  https://github.com/suyeecav/model-targeted-poisoning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a poisoning attack, an adversary with control over a small fraction of the\ntraining data attempts to select that data in a way that induces a corrupted\nmodel that misbehaves in favor of the adversary. We consider poisoning attacks\nagainst convex machine learning models and propose an efficient poisoning\nattack designed to induce a specified model. Unlike previous model-targeted\npoisoning attacks, our attack comes with provable convergence to {\\it any}\nattainable target classifier. The distance from the induced classifier to the\ntarget classifier is inversely proportional to the square root of the number of\npoisoning points. We also provide a lower bound on the minimum number of\npoisoning points needed to achieve a given target classifier. Our method uses\nonline convex optimization, so finds poisoning points incrementally. This\nprovides more flexibility than previous attacks which require a priori\nassumption about the number of poisoning points. Our attack is the first\nmodel-targeted poisoning attack that provides provable convergence for convex\nmodels, and in our experiments, it either exceeds or matches state-of-the-art\nattacks in terms of attack success rate and distance to the target model.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jun 2020 01:56:35 GMT"}, {"version": "v2", "created": "Wed, 21 Apr 2021 13:40:37 GMT"}], "update_date": "2021-04-22", "authors_parsed": [["Suya", "Fnu", ""], ["Mahloujifar", "Saeed", ""], ["Suri", "Anshuman", ""], ["Evans", "David", ""], ["Tian", "Yuan", ""]]}, {"id": "2006.16472", "submitter": "Bilal Farooq", "authors": "Lama Alfaseeh and Bilal Farooq", "title": "Deep Learning Based Proactive Multi-Objective Eco-Routing Strategies for\n  Connected and Automated Vehicles", "comments": null, "journal-ref": "Frontiers in Future Transportation, 2020", "doi": "10.3389/ffutr.2020.594608", "report-no": null, "categories": "math.OC cs.AI cs.LG cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This study exploits the advancements in information and communication\ntechnology (ICT), connected and automated vehicles (CAVs), and sensing, to\ndevelop proactive multi-objective eco-routing strategies. For a robust\napplication, several GHG costing approaches are examined. The predictive models\nfor the link level traffic and emission states are developed using long short\nterm memory deep network with exogenous predictors. It is found that proactive\nrouting strategies outperformed the myopic strategies, regardless of the\nrouting objective. Whether myopic or proactive, the multi-objective routing,\nwith travel time and GHG minimization as objectives, outperformed the single\nobjective routing strategies, causing a reduction in the average travel time\n(TT), average vehicle kilometre travelled (VKT), total GHG and total NOx by\n17%, 21%, 18%, and 20%, respectively. Finally, the additional TT and VKT\nexperienced by the vehicles in the network contributed adversely to the amount\nof GHG and NOx produced in the network.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jun 2020 02:07:10 GMT"}, {"version": "v2", "created": "Sun, 27 Dec 2020 15:12:53 GMT"}], "update_date": "2020-12-29", "authors_parsed": [["Alfaseeh", "Lama", ""], ["Farooq", "Bilal", ""]]}, {"id": "2006.16507", "submitter": "Seungki Min", "authors": "Seungki Min, Ciamac C. Moallemi, Daniel J. Russo", "title": "Policy Gradient Optimization of Thompson Sampling Policies", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the use of policy gradient algorithms to optimize over a class of\ngeneralized Thompson sampling policies. Our central insight is to view the\nposterior parameter sampled by Thompson sampling as a kind of pseudo-action.\nPolicy gradient methods can then be tractably applied to search over a class of\nsampling policies, which determine a probability distribution over\npseudo-actions (i.e., sampled parameters) as a function of observed data. We\nalso propose and compare policy gradient estimators that are specialized to\nBayesian bandit problems. Numerical experiments demonstrate that direct policy\nsearch on top of Thompson sampling automatically corrects for some of the\nalgorithm's known shortcomings and offers meaningful improvements even in long\nhorizon problems where standard Thompson sampling is extremely effective.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jun 2020 03:27:22 GMT"}], "update_date": "2020-07-01", "authors_parsed": [["Min", "Seungki", ""], ["Moallemi", "Ciamac C.", ""], ["Russo", "Daniel J.", ""]]}, {"id": "2006.16679", "submitter": "Zhongxiang Dai", "authors": "Zhongxiang Dai, Yizhou Chen, Kian Hsiang Low, Patrick Jaillet,\n  Teck-Hua Ho", "title": "R2-B2: Recursive Reasoning-Based Bayesian Optimization for No-Regret\n  Learning in Games", "comments": "Accepted to 37th International Conference on Machine Learning (ICML\n  2020), Extended version with proofs and additional experimental details and\n  results, 27 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.GT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a recursive reasoning formalism of Bayesian optimization\n(BO) to model the reasoning process in the interactions between boundedly\nrational, self-interested agents with unknown, complex, and costly-to-evaluate\npayoff functions in repeated games, which we call Recursive Reasoning-Based BO\n(R2-B2). Our R2-B2 algorithm is general in that it does not constrain the\nrelationship among the payoff functions of different agents and can thus be\napplied to various types of games such as constant-sum, general-sum, and\ncommon-payoff games. We prove that by reasoning at level 2 or more and at one\nlevel higher than the other agents, our R2-B2 agent can achieve faster\nasymptotic convergence to no regret than that without utilizing recursive\nreasoning. We also propose a computationally cheaper variant of R2-B2 called\nR2-B2-Lite at the expense of a weaker convergence guarantee. The performance\nand generality of our R2-B2 algorithm are empirically demonstrated using\nsynthetic games, adversarial machine learning, and multi-agent reinforcement\nlearning.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jun 2020 10:54:06 GMT"}], "update_date": "2020-07-01", "authors_parsed": [["Dai", "Zhongxiang", ""], ["Chen", "Yizhou", ""], ["Low", "Kian Hsiang", ""], ["Jaillet", "Patrick", ""], ["Ho", "Teck-Hua", ""]]}, {"id": "2006.16709", "submitter": "Benjamin Doerr", "authors": "Benjamin Doerr and Frank Neumann", "title": "A Survey on Recent Progress in the Theory of Evolutionary Algorithms for\n  Discrete Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The theory of evolutionary computation for discrete search spaces has made\nsignificant progress in the last ten years. This survey summarizes some of the\nmost important recent results in this research area. It discusses fine-grained\nmodels of runtime analysis of evolutionary algorithms, highlights recent\ntheoretical insights on parameter tuning and parameter control, and summarizes\nthe latest advances for stochastic and dynamic problems. We regard how\nevolutionary algorithms optimize submodular functions and we give an overview\nover the large body of recent results on estimation of distribution algorithms.\nFinally, we present the state of the art of drift analysis, one of the most\npowerful analysis technique developed in this field.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jun 2020 12:03:40 GMT"}, {"version": "v2", "created": "Tue, 6 Apr 2021 07:42:19 GMT"}, {"version": "v3", "created": "Thu, 8 Jul 2021 06:15:26 GMT"}], "update_date": "2021-07-09", "authors_parsed": [["Doerr", "Benjamin", ""], ["Neumann", "Frank", ""]]}, {"id": "2006.16711", "submitter": "\\v{S}t\\v{e}p\\'an Holub", "authors": "\\v{S}t\\v{e}p\\'an Holub and \\v{S}t\\v{e}p\\'an Starosta", "title": "Binary intersection formalized", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.FL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide a reformulation and a formalization of the classical result by\nJuhani Karhum\\\"aki characterizing intersections of two languages of the form\n$\\{x,y\\}^*\\cap \\{u,v\\}^*$. We use the terminology of morphisms which allows to\nformulate the result in a shorter and more transparent way, and we formalize\nthe result in the proof assistant Isabelle/HOL.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jun 2020 12:08:33 GMT"}], "update_date": "2020-07-01", "authors_parsed": [["Holub", "\u0160t\u011bp\u00e1n", ""], ["Starosta", "\u0160t\u011bp\u00e1n", ""]]}, {"id": "2006.16712", "submitter": "Thomas Moerland", "authors": "Thomas M. Moerland, Joost Broekens, Catholijn M. Jonker", "title": "Model-based Reinforcement Learning: A Survey", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sequential decision making, commonly formalized as Markov Decision Process\n(MDP) optimization, is a key challenge in artificial intelligence. Two key\napproaches to this problem are reinforcement learning (RL) and planning. This\npaper presents a survey of the integration of both fields, better known as\nmodel-based reinforcement learning. Model-based RL has two main steps. First,\nwe systematically cover approaches to dynamics model learning, including\nchallenges like dealing with stochasticity, uncertainty, partial observability,\nand temporal abstraction. Second, we present a systematic categorization of\nplanning-learning integration, including aspects like: where to start planning,\nwhat budgets to allocate to planning and real data collection, how to plan, and\nhow to integrate planning in the learning and acting loop. After these two\nsection, we also discuss implicit model-based RL as an end-to-end alternative\nfor model learning and planning, and we cover the potential benefits of\nmodel-based RL, like enhanced data efficiency, targeted exploration, and\nimproved stability. The survey also draws connection to several related RL\nfields, like hierarchical RL and transfer. Altogether, the survey presents a\nbroad conceptual overview of planning-learning combinations for MDP\noptimization.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jun 2020 12:10:07 GMT"}, {"version": "v2", "created": "Thu, 23 Jul 2020 15:04:03 GMT"}, {"version": "v3", "created": "Thu, 25 Feb 2021 15:09:38 GMT"}], "update_date": "2021-02-26", "authors_parsed": [["Moerland", "Thomas M.", ""], ["Broekens", "Joost", ""], ["Jonker", "Catholijn M.", ""]]}, {"id": "2006.16722", "submitter": "Huanhuan Chen", "authors": "Xinyan Zhao, Xiao Feng, Haoming Zhong, Jun Yao, Huanhuan Chen", "title": "Correction of Faulty Background Knowledge based on Condition Aware and\n  Revise Transformer for Question Answering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The study of question answering has received increasing attention in recent\nyears. This work focuses on providing an answer that compatible with both user\nintent and conditioning information corresponding to the question, such as\ndelivery status and stock information in e-commerce. However, these conditions\nmay be wrong or incomplete in real-world applications. Although existing\nquestion answering systems have considered the external information, such as\ncategorical attributes and triples in knowledge base, they all assume that the\nexternal information is correct and complete. To alleviate the effect of\ndefective condition values, this paper proposes condition aware and revise\nTransformer (CAR-Transformer). CAR-Transformer (1) revises each condition value\nbased on the whole conversation and original conditions values, and (2) it\nencodes the revised conditions and utilizes the conditions embedding to select\nan answer. Experimental results on a real-world customer service dataset\ndemonstrate that the CAR-Transformer can still select an appropriate reply when\nconditions corresponding to the question exist wrong or missing values, and\nsubstantially outperforms baseline models on automatic and human evaluations.\nThe proposed CAR-Transformer can be extended to other NLP tasks which need to\nconsider conditioning information.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jun 2020 12:24:35 GMT"}], "update_date": "2020-07-01", "authors_parsed": [["Zhao", "Xinyan", ""], ["Feng", "Xiao", ""], ["Zhong", "Haoming", ""], ["Yao", "Jun", ""], ["Chen", "Huanhuan", ""]]}, {"id": "2006.16723", "submitter": "Hongyuan Mei", "authors": "Hongyuan Mei and Guanghui Qin and Minjie Xu and Jason Eisner", "title": "Neural Datalog Through Time: Informed Temporal Modeling via Logical\n  Specification", "comments": "ICML 2020 camera-ready (new Appendix A.3, rewritten Appendix F)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.DB cs.LO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning how to predict future events from patterns of past events is\ndifficult when the set of possible event types is large. Training an\nunrestricted neural model might overfit to spurious patterns. To exploit\ndomain-specific knowledge of how past events might affect an event's present\nprobability, we propose using a temporal deductive database to track structured\nfacts over time. Rules serve to prove facts from other facts and from past\nevents. Each fact has a time-varying state---a vector computed by a neural net\nwhose topology is determined by the fact's provenance, including its experience\nof past events. The possible event types at any time are given by special\nfacts, whose probabilities are neurally modeled alongside their states. In both\nsynthetic and real-world domains, we show that neural probabilistic models\nderived from concise Datalog programs improve prediction by encoding\nappropriate domain knowledge in their architecture.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jun 2020 12:26:04 GMT"}, {"version": "v2", "created": "Mon, 17 Aug 2020 02:58:01 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Mei", "Hongyuan", ""], ["Qin", "Guanghui", ""], ["Xu", "Minjie", ""], ["Eisner", "Jason", ""]]}, {"id": "2006.16745", "submitter": "Sami Zhioua", "authors": "Karima Makhlouf, Sami Zhioua, Catuscia Palamidessi", "title": "On the Applicability of ML Fairness Notions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  ML-based predictive systems are increasingly used to support decisions with a\ncritical impact on individuals' lives such as college admission, job hiring,\nchild custody, criminal risk assessment, etc. As a result, fairness emerged as\nan important requirement to guarantee that predictive systems do not\ndiscriminate against specific individuals or entire sub-populations, in\nparticular, minorities. Given the inherent subjectivity of viewing the concept\nof fairness, several notions of fairness have been introduced in the\nliterature. This paper is a survey of fairness notions that, unlike other\nsurveys in the literature, addresses the question of \"which notion of fairness\nis most suited to a given real-world scenario and why?\". Our attempt to answer\nthis question consists in (1) identifying the set of fairness-related\ncharacteristics of the real-world scenario at hand, (2) analyzing the behavior\nof each fairness notion, and then (3) fitting these two elements to recommend\nthe most suitable fairness notion in every specific setup. The results are\nsummarized in a decision diagram that can be used by practitioners and policy\nmakers to navigate the relatively large catalogue of fairness notions.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jun 2020 13:01:06 GMT"}, {"version": "v2", "created": "Mon, 19 Oct 2020 07:50:19 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["Makhlouf", "Karima", ""], ["Zhioua", "Sami", ""], ["Palamidessi", "Catuscia", ""]]}, {"id": "2006.16763", "submitter": "Vyacheslav Yukalov", "authors": "V.I. Yukalov", "title": "Evolutionary Processes in Quantum Decision Theory", "comments": "Latex file, 39 pages", "journal-ref": "Entropy 22 (2020) 681", "doi": "10.3390/e22060681", "report-no": null, "categories": "cs.AI physics.soc-ph quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The review presents the basics of quantum decision theory, with the emphasis\non temporary processes in decision making. The aim is to explain the principal\npoints of the theory. The difference of an operationally testable rational\nchoice between alternatives from a choice decorated by irrational feelings is\nelucidated. Quantum-classical correspondence is emphasized. A model of quantum\nintelligence network is described. Dynamic inconsistencies are shown to be\nresolved in the frame of the quantum decision theory.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jun 2020 10:19:28 GMT"}], "update_date": "2020-07-15", "authors_parsed": [["Yukalov", "V. I.", ""]]}, {"id": "2006.16785", "submitter": "Lionel Blond\\'e", "authors": "Lionel Blond\\'e, Pablo Strasser, Alexandros Kalousis", "title": "Lipschitzness Is All You Need To Tame Off-policy Generative Adversarial\n  Imitation Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the recent success of reinforcement learning in various domains,\nthese approaches remain, for the most part, deterringly sensitive to\nhyper-parameters and are often riddled with essential engineering feats\nallowing their success. We consider the case of off-policy generative\nadversarial imitation learning, and perform an in-depth review, qualitative and\nquantitative, of the method. We show that forcing the learned reward function\nto be local Lipschitz-continuous is a sine qua non condition for the method to\nperform well. We then study the effects of this necessary condition and provide\nseveral theoretical results involving the local Lipschitzness of the\nstate-value function. We complement these guarantees with empirical evidence\nattesting to the strong positive effect that the consistent satisfaction of the\nLipschitzness constraint on the reward has on imitation performance. Finally,\nwe tackle a generic pessimistic reward preconditioning add-on spawning a large\nclass of reward shaping methods, which makes the base method it is plugged into\nprovably more robust, as shown in several additional theoretical guarantees. We\nthen discuss these through a fine-grained lens and share our insights.\nCrucially, the guarantees derived and reported in this work are valid for any\nreward satisfying the Lipschitzness condition, nothing is specific to\nimitation. As such, these may be of independent interest.\n", "versions": [{"version": "v1", "created": "Sun, 28 Jun 2020 20:55:31 GMT"}, {"version": "v2", "created": "Sat, 3 Jul 2021 09:45:29 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Blond\u00e9", "Lionel", ""], ["Strasser", "Pablo", ""], ["Kalousis", "Alexandros", ""]]}, {"id": "2006.16789", "submitter": "Guandong Xu", "authors": "Guandong Xu, Tri Dung Duong, Qian Li, Shaowu Liu, Xianzhi Wang", "title": "Causality Learning: A New Perspective for Interpretable Machine Learning", "comments": "8 Pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent years have witnessed the rapid growth of machine learning in a wide\nrange of fields such as image recognition, text classification, credit scoring\nprediction, recommendation system, etc. In spite of their great performance in\ndifferent sectors, researchers still concern about the mechanism under any\nmachine learning (ML) techniques that are inherently black-box and becoming\nmore complex to achieve higher accuracy. Therefore, interpreting machine\nlearning model is currently a mainstream topic in the research community.\nHowever, the traditional interpretable machine learning focuses on the\nassociation instead of the causality. This paper provides an overview of causal\nanalysis with the fundamental background and key concepts, and then summarizes\nmost recent causal approaches for interpretable machine learning. The\nevaluation techniques for assessing method quality, and open problems in causal\ninterpretability are also discussed in this paper.\n", "versions": [{"version": "v1", "created": "Sat, 27 Jun 2020 13:01:28 GMT"}], "update_date": "2020-07-01", "authors_parsed": [["Xu", "Guandong", ""], ["Duong", "Tri Dung", ""], ["Li", "Qian", ""], ["Liu", "Shaowu", ""], ["Wang", "Xianzhi", ""]]}, {"id": "2006.16858", "submitter": "Mark Christopher Ballandies", "authors": "Mark Christopher Ballandies, Evangelos Pournaras", "title": "Mobile Link Prediction: Automated Creation and Crowd-sourced Validation\n  of Knowledge Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Building trustworthy knowledge graphs for cyber-physical social systems\n(CPSS) is a challenge. In particular, current approaches relying on human\nexperts have limited scalability, while automated approaches are often not\naccountable to users resulting in knowledge graphs of questionable quality.\nThis paper introduces a novel pervasive knowledge graph builder that brings\ntogether automation, experts' and crowd-sourced citizens' knowledge. The\nknowledge graph grows via automated link predictions using genetic programming\nthat are validated by humans for improving transparency and calibrating\naccuracy. The knowledge graph builder is designed for pervasive devices such as\nsmartphones and preserves privacy by localizing all computations. The accuracy,\npracticality, and usability of the knowledge graph builder is evaluated in a\nreal-world social experiment that involves a smartphone implementation and a\nSmart City application scenario. The proposed knowledge graph building\nmethodology outperforms the baseline method in terms of accuracy while\ndemonstrating its efficient calculations on smartphones and the feasibility of\nthe pervasive human supervision process in terms of high interactions\nthroughput. These findings promise new opportunities to crowd-source and\noperate pervasive reasoning systems for cyber-physical social systems in Smart\nCities.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jun 2020 14:50:34 GMT"}], "update_date": "2020-07-01", "authors_parsed": [["Ballandies", "Mark Christopher", ""], ["Pournaras", "Evangelos", ""]]}, {"id": "2006.16869", "submitter": "V\\'ictor Guti\\'errez-Basulto", "authors": "Tomasz Gogacz, V\\'ictor Guti\\'errez-Basulto, Albert Gutowski, Yazm\\'in\n  Ib\\'a\\~nez-Garc\\'ia, Filip Murlak", "title": "On Finite Entailment of Non-Local Queries in Description Logics", "comments": "25 pages, 4 Figures, Accepted at KR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of finite entailment of ontology-mediated queries. Going\nbeyond local queries, we allow transitive closure over roles. We focus on\nontologies formulated in the description logics ALCOI and ALCOQ, extended with\ntransitive closure. For both logics, we show 2EXPTIME upper bounds for finite\nentailment of unions of conjunctive queries with transitive closure. We also\nprovide a matching lower bound by showing that finite entailment of conjunctive\nqueries with transitive closure in ALC is 2EXPTIME-hard.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jun 2020 14:57:12 GMT"}], "update_date": "2020-07-01", "authors_parsed": [["Gogacz", "Tomasz", ""], ["Guti\u00e9rrez-Basulto", "V\u00edctor", ""], ["Gutowski", "Albert", ""], ["Ib\u00e1\u00f1ez-Garc\u00eda", "Yazm\u00edn", ""], ["Murlak", "Filip", ""]]}, {"id": "2006.16910", "submitter": "Jean-Baptiste Lamy", "authors": "Jean-Baptiste Lamy", "title": "A data science approach to drug safety: Semantic and visual mining of\n  adverse drug events from clinical trials of pain treatments", "comments": "13 pages, 15 figures", "journal-ref": "Artificial Intelligence in Medicine 2021;115:102074", "doi": "10.1016/j.artmed.2021.102074", "report-no": null, "categories": "cs.CY cs.AI q-bio.QM", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Clinical trials are the basis of Evidence-Based Medicine. Trial results are\nreviewed by experts and consensus panels for producing meta-analyses and\nclinical practice guidelines. However, reviewing these results is a long and\ntedious task, hence the meta-analyses and guidelines are not updated each time\na new trial is published. Moreover, the independence of experts may be\ndifficult to appraise. On the contrary, in many other domains, including\nmedical risk analysis, the advent of data science, big data and visual\nanalytics allowed moving from expert-based to fact-based knowledge. Since 12\nyears, many trial results are publicly available online in trial registries.\nNevertheless, data science methods have not yet been applied widely to trial\ndata. In this paper, we present a platform for analyzing the safety events\nreported during clinical trials and published in trial registries. This\nplatform is based on an ontological model including 582 trials on pain\ntreatments, and uses semantic web technologies for querying this dataset at\nvarious levels of granularity. It also relies on a 26-dimensional flower glyph\nfor the visualization of the Adverse Drug Events (ADE) rates in 13 categories\nand 2 levels of seriousness. We illustrate the interest of this platform\nthrough several use cases and we were able to find back conclusions that were\ninitially found during meta-analyses. The platform was presented to four\nexperts in drug safety, and is publicly available online, with the ontology of\npain treatment ADE.\n", "versions": [{"version": "v1", "created": "Fri, 19 Jun 2020 14:37:36 GMT"}, {"version": "v2", "created": "Sat, 17 Apr 2021 12:25:33 GMT"}], "update_date": "2021-04-21", "authors_parsed": [["Lamy", "Jean-Baptiste", ""]]}, {"id": "2006.16913", "submitter": "Adish Singla", "authors": "Umair Z. Ahmed, Maria Christakis, Aleksandr Efremov, Nigel Fernandez,\n  Ahana Ghosh, Abhik Roychoudhury, Adish Singla", "title": "Synthesizing Tasks for Block-based Programming", "comments": "NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Block-based visual programming environments play a critical role in\nintroducing computing concepts to K-12 students. One of the key pedagogical\nchallenges in these environments is in designing new practice tasks for a\nstudent that match a desired level of difficulty and exercise specific\nprogramming concepts. In this paper, we formalize the problem of synthesizing\nvisual programming tasks. In particular, given a reference visual task $\\rm\nT^{in}$ and its solution code $\\rm C^{in}$, we propose a novel methodology to\nautomatically generate a set $\\{(\\rm T^{out}, \\rm C^{out})\\}$ of new tasks\nalong with solution codes such that tasks $\\rm T^{in}$ and $\\rm T^{out}$ are\nconceptually similar but visually dissimilar. Our methodology is based on the\nrealization that the mapping from the space of visual tasks to their solution\ncodes is highly discontinuous; hence, directly mutating reference task $\\rm\nT^{in}$ to generate new tasks is futile. Our task synthesis algorithm operates\nby first mutating code $\\rm C^{in}$ to obtain a set of codes $\\{\\rm C^{out}\\}$.\nThen, the algorithm performs symbolic execution over a code $\\rm C^{out}$ to\nobtain a visual task $\\rm T^{out}$; this step uses the Monte Carlo Tree Search\n(MCTS) procedure to guide the search in the symbolic tree. We demonstrate the\neffectiveness of our algorithm through an extensive empirical evaluation and\nuser study on reference tasks taken from the \\emph{Hour of Code: Classic Maze}\nchallenge by \\emph{Code.org} and the \\emph{Intro to Programming with Karel}\ncourse by \\emph{CodeHS.com}.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jun 2020 15:04:37 GMT"}, {"version": "v2", "created": "Wed, 1 Jul 2020 22:37:26 GMT"}, {"version": "v3", "created": "Thu, 5 Nov 2020 00:00:55 GMT"}], "update_date": "2020-11-06", "authors_parsed": [["Ahmed", "Umair Z.", ""], ["Christakis", "Maria", ""], ["Efremov", "Aleksandr", ""], ["Fernandez", "Nigel", ""], ["Ghosh", "Ahana", ""], ["Roychoudhury", "Abhik", ""], ["Singla", "Adish", ""]]}, {"id": "2006.16915", "submitter": "Hanshuang Tong", "authors": "Hanshuang Tong, Zhen Wang, Qi Liu, Yun Zhou and Wenyuan Han", "title": "HGKT: Introducing Hierarchical Exercise Graph for Knowledge Tracing", "comments": "10 pages, 11 figures, submitted to SIGIR 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge tracing (KT) which aims at predicting learner's knowledge mastery\nplays an important role in the computer-aided educational system. In recent\nyears, many deep learning models have been applied to tackle the KT task, which\nhave shown promising results. However, limitations still exist. Most existing\nmethods simplify the exercising records as knowledge sequences, which fail to\nexplore rich information that existed in exercises. Besides, the existing\ndiagnosis results of knowledge tracing are not convincing enough since they\nneglect prior relations between exercises. To solve the above problems, we\npropose a hierarchical graph knowledge tracing model called HGKT to explore the\nlatent hierarchical relations between exercises. Specifically, we introduce the\nconcept of problem schema to construct a hierarchical exercise graph that could\nmodel the exercise learning dependencies. Moreover, we employ two attention\nmechanisms to highlight the important historical states of learners. In the\ntesting stage, we present a K\\&S diagnosis matrix that could trace the\ntransition of mastery of knowledge and problem schema, which can be more easily\napplied to different applications. Extensive experiments show the effectiveness\nand interpretability of our proposed models.\n", "versions": [{"version": "v1", "created": "Sat, 13 Jun 2020 07:09:52 GMT"}, {"version": "v2", "created": "Sat, 4 Jul 2020 02:43:10 GMT"}, {"version": "v3", "created": "Fri, 23 Oct 2020 13:49:28 GMT"}, {"version": "v4", "created": "Mon, 8 Feb 2021 12:24:39 GMT"}, {"version": "v5", "created": "Wed, 21 Apr 2021 12:22:56 GMT"}], "update_date": "2021-04-22", "authors_parsed": [["Tong", "Hanshuang", ""], ["Wang", "Zhen", ""], ["Liu", "Qi", ""], ["Zhou", "Yun", ""], ["Han", "Wenyuan", ""]]}, {"id": "2006.16917", "submitter": "Jiaoyan Chen", "authors": "Jiaoyan Chen and Freddy Lecue and Yuxia Geng and Jeff Z. Pan and\n  Huajun Chen", "title": "Ontology-guided Semantic Composition for Zero-Shot Learning", "comments": "Accepted by KR 2020 - 17th International Conference on Principles of\n  Knowledge Representation and Reasoning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Zero-shot learning (ZSL) is a popular research problem that aims at\npredicting for those classes that have never appeared in the training stage by\nutilizing the inter-class relationship with some side information. In this\nstudy, we propose to model the compositional and expressive semantics of class\nlabels by an OWL (Web Ontology Language) ontology, and further develop a new\nZSL framework with ontology embedding. The effectiveness has been verified by\nsome primary experiments on animal image classification and visual question\nanswering.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jun 2020 15:49:12 GMT"}], "update_date": "2020-07-01", "authors_parsed": [["Chen", "Jiaoyan", ""], ["Lecue", "Freddy", ""], ["Geng", "Yuxia", ""], ["Pan", "Jeff Z.", ""], ["Chen", "Huajun", ""]]}, {"id": "2006.16950", "submitter": "Xinming Liu", "authors": "Xinming Liu, Joseph Y. Halpern", "title": "Bounded Rationality in Las Vegas: Probabilistic Finite Automata\n  PlayMulti-Armed Bandits", "comments": "10 pages, 4 pages, Proceedings of the 36th Conference on Uncertainty\n  in Artificial Intelligence (UAI), PMLR volume 124, 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While traditional economics assumes that humans are fully rational agents who\nalways maximize their expected utility, in practice, we constantly observe\napparently irrational behavior. One explanation is that people have limited\ncomputational power, so that they are, quite rationally, making the best\ndecisions they can, given their computational limitations. To test this\nhypothesis, we consider the multi-armed bandit (MAB) problem. We examine a\nsimple strategy for playing an MAB that can be implemented easily by a\nprobabilistic finite automaton (PFA). Roughly speaking, the PFA sets certain\nexpectations, and plays an arm as long as it meets them. If the PFA has\nsufficiently many states, it performs near-optimally. Its performance degrades\ngracefully as the number of states decreases. Moreover, the PFA acts in a\n\"human-like\" way, exhibiting a number of standard human biases, like an\noptimism bias and a negativity bias.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jun 2020 16:42:08 GMT"}], "update_date": "2020-07-01", "authors_parsed": [["Liu", "Xinming", ""], ["Halpern", "Joseph Y.", ""]]}, {"id": "2006.16977", "submitter": "Yongfeng Zhang", "authors": "Shuyuan Xu, Yunqi Li, Shuchang Liu, Zuohui Fu, Xu Chen, Yongfeng Zhang", "title": "Learning Post-Hoc Causal Explanations for Recommendation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  State-of-the-art recommender systems have the ability to generate\nhigh-quality recommendations, but usually cannot provide intuitive explanations\nto humans due to the usage of black-box prediction models. The lack of\ntransparency has highlighted the critical importance of improving the\nexplainability of recommender systems. In this paper, we propose to extract\ncausal rules from the user interaction history as post-hoc explanations for the\nblack-box sequential recommendation mechanisms, whilst maintain the predictive\naccuracy of the recommendation model. Our approach firstly achieves\ncounterfactual examples with the aid of a perturbation model, and then extracts\npersonalized causal relationships for the recommendation model through a causal\nrule mining algorithm. Experiments are conducted on several state-of-the-art\nsequential recommendation models and real-world datasets to verify the\nperformance of our model on generating causal explanations. Meanwhile, We\nevaluate the discovered causal explanations in terms of quality and fidelity,\nwhich show that compared with conventional association rules, causal rules can\nprovide personalized and more effective explanations for the behavior of\nblack-box recommendation models.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jun 2020 17:14:12 GMT"}, {"version": "v2", "created": "Tue, 23 Feb 2021 17:32:32 GMT"}], "update_date": "2021-02-24", "authors_parsed": [["Xu", "Shuyuan", ""], ["Li", "Yunqi", ""], ["Liu", "Shuchang", ""], ["Fu", "Zuohui", ""], ["Chen", "Xu", ""], ["Zhang", "Yongfeng", ""]]}]