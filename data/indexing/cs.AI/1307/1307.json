[{"id": "1307.0024", "submitter": "Daan Wilmer", "authors": "Daan Wilmer", "title": "Investigation of \"Enhancing flexibility and robustness in multi-agent\n  task scheduling\"", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Wilson et al. propose a measure of flexibility in project scheduling problems\nand propose several ways of distributing flexibility over tasks without\noverrunning the deadline. These schedules prove quite robust: delays of some\ntasks do not necessarily lead to delays of subsequent tasks. The number of\ntasks that finish late depends, among others, on the way of distributing\nflexibility.\n  In this paper I study the different flexibility distributions proposed by\nWilson et al. and the differences in number of violations (tasks that finish\ntoo late). I show one factor in the instances that causes differences in the\nnumber of violations, as well as two properties of the flexibility distribution\nthat cause them to behave differently. Based on these findings, I propose three\nnew flexibility distributions. Depending on the nature of the delays, these new\nflexibility distributions perform as good as or better than the distributions\nby Wilson et al.\n", "versions": [{"version": "v1", "created": "Fri, 28 Jun 2013 20:20:27 GMT"}], "update_date": "2013-07-02", "authors_parsed": [["Wilmer", "Daan", ""]]}, {"id": "1307.0060", "submitter": "Tejas Kulkarni", "authors": "Vikash K. Mansinghka, Tejas D. Kulkarni, Yura N. Perov, Joshua B.\n  Tenenbaum", "title": "Approximate Bayesian Image Interpretation using Generative Probabilistic\n  Graphics Programs", "comments": "The first two authors contributed equally to this work", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The idea of computer vision as the Bayesian inverse problem to computer\ngraphics has a long history and an appealing elegance, but it has proved\ndifficult to directly implement. Instead, most vision tasks are approached via\ncomplex bottom-up processing pipelines. Here we show that it is possible to\nwrite short, simple probabilistic graphics programs that define flexible\ngenerative models and to automatically invert them to interpret real-world\nimages. Generative probabilistic graphics programs consist of a stochastic\nscene generator, a renderer based on graphics software, a stochastic likelihood\nmodel linking the renderer's output and the data, and latent variables that\nadjust the fidelity of the renderer and the tolerance of the likelihood model.\nRepresentations and algorithms from computer graphics, originally designed to\nproduce high-quality images, are instead used as the deterministic backbone for\nhighly approximate and stochastic generative models. This formulation combines\nprobabilistic programming, computer graphics, and approximate Bayesian\ncomputation, and depends only on general-purpose, automatic inference\ntechniques. We describe two applications: reading sequences of degraded and\nadversarially obscured alphanumeric characters, and inferring 3D road models\nfrom vehicle-mounted camera images. Each of the probabilistic graphics programs\nwe present relies on under 20 lines of probabilistic code, and supports\naccurate, approximately Bayesian inferences about ambiguous real-world images.\n", "versions": [{"version": "v1", "created": "Sat, 29 Jun 2013 02:36:45 GMT"}], "update_date": "2013-07-02", "authors_parsed": [["Mansinghka", "Vikash K.", ""], ["Kulkarni", "Tejas D.", ""], ["Perov", "Yura N.", ""], ["Tenenbaum", "Joshua B.", ""]]}, {"id": "1307.0201", "submitter": "Magnus Lie Hetland", "authors": "Magnus Lie Hetland", "title": "Simulating Ability: Representing Skills in Games", "comments": null, "journal-ref": "Serious Games Development and Applications. Lecture Notes in\n  Computer Science Volume 8101, 2013, pp 226-238", "doi": "10.1007/978-3-642-40790-1_22", "report-no": null, "categories": "cs.GT cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Throughout the history of games, representing the abilities of the various\nagents acting on behalf of the players has been a central concern. With\nincreasingly sophisticated games emerging, these simulations have become more\nrealistic, but the underlying mechanisms are still, to a large extent, of an ad\nhoc nature. This paper proposes using a logistic model from psychometrics as a\nunified mechanism for task resolution in simulation-oriented games.\n", "versions": [{"version": "v1", "created": "Sun, 30 Jun 2013 13:10:01 GMT"}, {"version": "v2", "created": "Fri, 26 Jul 2013 08:43:46 GMT"}], "update_date": "2013-10-04", "authors_parsed": [["Hetland", "Magnus Lie", ""]]}, {"id": "1307.0339", "submitter": "Cheng-Yuan Liou", "authors": "Cheng-Yuan Liou, Bo-Shiang Huang, Daw-Ran Liou and Alex A. Simak", "title": "Syntactic sensitive complexity for symbol-free sequence", "comments": "11 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work uses the L-system to construct a tree structure for the text\nsequence and derives its complexity. It serves as a measure of structural\ncomplexity of the text. It is applied to anomaly detection in data\ntransmission.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jul 2013 12:00:59 GMT"}, {"version": "v2", "created": "Tue, 2 Jul 2013 02:08:48 GMT"}], "update_date": "2013-07-03", "authors_parsed": [["Liou", "Cheng-Yuan", ""], ["Huang", "Bo-Shiang", ""], ["Liou", "Daw-Ran", ""], ["Simak", "Alex A.", ""]]}, {"id": "1307.0426", "submitter": "Thomas Lampert", "authors": "Thomas A. Lampert, Andr\\'e Stumpf, Pierre Gan\\c{c}arski", "title": "An Empirical Study into Annotator Agreement, Ground Truth Estimation,\n  and Algorithm Evaluation", "comments": "16 pages", "journal-ref": "IEEE Transactions on Image Processing 25(6), 2557-2572, 2016", "doi": "10.1109/TIP.2016.2544703", "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although agreement between annotators has been studied in the past from a\nstatistical viewpoint, little work has attempted to quantify the extent to\nwhich this phenomenon affects the evaluation of computer vision (CV) object\ndetection algorithms. Many researchers utilise ground truth (GT) in experiments\nand more often than not this GT is derived from one annotator's opinion. How\ndoes the difference in opinion affect an algorithm's evaluation? Four examples\nof typical CV problems are chosen, and a methodology is applied to each to\nquantify the inter-annotator variance and to offer insight into the mechanisms\nbehind agreement and the use of GT. It is found that when detecting linear\nobjects annotator agreement is very low. The agreement in object position,\nlinear or otherwise, can be partially explained through basic image properties.\nAutomatic object detectors are compared to annotator agreement and it is found\nthat a clear relationship exists. Several methods for calculating GTs from a\nnumber of annotations are applied and the resulting differences in the\nperformance of the object detectors are quantified. It is found that the rank\nof a detector is highly dependent upon the method used to form the GT. It is\nalso found that although the STAPLE and LSML GT estimation methods appear to\nrepresent the mean of the performance measured using the individual\nannotations, when there are few annotations, or there is a large variance in\nthem, these estimates tend to degrade. Furthermore, one of the most commonly\nadopted annotation combination methods--consensus voting--accentuates more\nobvious features, which results in an overestimation of the algorithm's\nperformance. Finally, it is concluded that in some datasets it may not be\npossible to state with any confidence that one algorithm outperforms another\nwhen evaluating upon one GT and a method for calculating confidence bounds is\ndiscussed.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jul 2013 16:16:40 GMT"}, {"version": "v2", "created": "Sat, 26 Oct 2013 14:39:01 GMT"}, {"version": "v3", "created": "Tue, 26 Apr 2016 11:05:18 GMT"}], "update_date": "2018-10-26", "authors_parsed": [["Lampert", "Thomas A.", ""], ["Stumpf", "Andr\u00e9", ""], ["Gan\u00e7arski", "Pierre", ""]]}, {"id": "1307.0802", "submitter": "Jonathan Huggins", "authors": "Jonathan H. Huggins and Cynthia Rudin", "title": "A Statistical Learning Theory Framework for Supervised Pattern Discovery", "comments": "12 pages, 1 figure. Title change. Full version. Appearing at the SIAM\n  International Conference on Data Mining (SDM) 2014", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper formalizes a latent variable inference problem we call {\\em\nsupervised pattern discovery}, the goal of which is to find sets of\nobservations that belong to a single ``pattern.'' We discuss two versions of\nthe problem and prove uniform risk bounds for both. In the first version,\ncollections of patterns can be generated in an arbitrary manner and the data\nconsist of multiple labeled collections. In the second version, the patterns\nare assumed to be generated independently by identically distributed processes.\nThese processes are allowed to take an arbitrary form, so observations within a\npattern are not in general independent of each other. The bounds for the second\nversion of the problem are stated in terms of a new complexity measure, the\nquasi-Rademacher complexity.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jul 2013 19:32:17 GMT"}, {"version": "v2", "created": "Fri, 7 Feb 2014 15:41:23 GMT"}], "update_date": "2014-02-10", "authors_parsed": [["Huggins", "Jonathan H.", ""], ["Rudin", "Cynthia", ""]]}, {"id": "1307.0803", "submitter": "Marinka Zitnik", "authors": "Marinka \\v{Z}itnik and Bla\\v{z} Zupan", "title": "Data Fusion by Matrix Factorization", "comments": "Short preprint, 13 pages, 3 Figures, 3 Tables. Full paper in\n  10.1109/TPAMI.2014.2343973", "journal-ref": "Marinka Zitnik and Blaz Zupan. IEEE Transactions on Pattern\n  Analysis and Machine Intelligence, 37(1):41-53 (2015)", "doi": "10.1109/TPAMI.2014.2343973", "report-no": null, "categories": "cs.LG cs.AI cs.DB stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For most problems in science and engineering we can obtain data sets that\ndescribe the observed system from various perspectives and record the behavior\nof its individual components. Heterogeneous data sets can be collectively mined\nby data fusion. Fusion can focus on a specific target relation and exploit\ndirectly associated data together with contextual data and data about system's\nconstraints. In the paper we describe a data fusion approach with penalized\nmatrix tri-factorization (DFMF) that simultaneously factorizes data matrices to\nreveal hidden associations. The approach can directly consider any data that\ncan be expressed in a matrix, including those from feature-based\nrepresentations, ontologies, associations and networks. We demonstrate the\nutility of DFMF for gene function prediction task with eleven different data\nsources and for prediction of pharmacologic actions by fusing six data sources.\nOur data fusion algorithm compares favorably to alternative data integration\napproaches and achieves higher accuracy than can be obtained from any single\ndata source alone.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jul 2013 19:35:21 GMT"}, {"version": "v2", "created": "Fri, 6 Feb 2015 16:15:38 GMT"}], "update_date": "2015-02-09", "authors_parsed": [["\u017ditnik", "Marinka", ""], ["Zupan", "Bla\u017e", ""]]}, {"id": "1307.0813", "submitter": "Marc Deisenroth", "authors": "Marc Peter Deisenroth, Peter Englert, Jan Peters and Dieter Fox", "title": "Multi-Task Policy Search", "comments": "8 pages, double column. IEEE International Conference on Robotics and\n  Automation, 2014", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning policies that generalize across multiple tasks is an important and\nchallenging research topic in reinforcement learning and robotics. Training\nindividual policies for every single potential task is often impractical,\nespecially for continuous task variations, requiring more principled approaches\nto share and transfer knowledge among similar tasks. We present a novel\napproach for learning a nonlinear feedback policy that generalizes across\nmultiple tasks. The key idea is to define a parametrized policy as a function\nof both the state and the task, which allows learning a single policy that\ngeneralizes across multiple known and unknown tasks. Applications of our novel\napproach to reinforcement and imitation learning in real-robot experiments are\nshown.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jul 2013 07:59:32 GMT"}, {"version": "v2", "created": "Wed, 12 Feb 2014 09:17:52 GMT"}], "update_date": "2014-02-13", "authors_parsed": [["Deisenroth", "Marc Peter", ""], ["Englert", "Peter", ""], ["Peters", "Jan", ""], ["Fox", "Dieter", ""]]}, {"id": "1307.0845", "submitter": "J. G. Wolff", "authors": "J Gerard Wolff", "title": "The SP theory of intelligence: benefits and applications", "comments": "arXiv admin note: substantial text overlap with arXiv:1212.0229", "journal-ref": "J G Wolff, Information, 5 (1), 1-27, 2014", "doi": "10.3390/info5010001", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article describes existing and expected benefits of the \"SP theory of\nintelligence\", and some potential applications. The theory aims to simplify and\nintegrate ideas across artificial intelligence, mainstream computing, and human\nperception and cognition, with information compression as a unifying theme. It\ncombines conceptual simplicity with descriptive and explanatory power across\nseveral areas of computing and cognition. In the \"SP machine\" -- an expression\nof the SP theory which is currently realized in the form of a computer model --\nthere is potential for an overall simplification of computing systems,\nincluding software. The SP theory promises deeper insights and better solutions\nin several areas of application including, most notably, unsupervised learning,\nnatural language processing, autonomous robots, computer vision, intelligent\ndatabases, software engineering, information compression, medical diagnosis and\nbig data. There is also potential in areas such as the semantic web,\nbioinformatics, structuring of documents, the detection of computer viruses,\ndata fusion, new kinds of computer, and the development of scientific theories.\nThe theory promises seamless integration of structures and functions within and\nbetween different areas of application. The potential value, worldwide, of\nthese benefits and applications is at least $190 billion each year. Further\ndevelopment would be facilitated by the creation of a high-parallel,\nopen-source version of the SP machine, available to researchers everywhere.\n", "versions": [{"version": "v1", "created": "Thu, 13 Jun 2013 13:31:47 GMT"}, {"version": "v2", "created": "Mon, 23 Dec 2013 09:58:18 GMT"}], "update_date": "2013-12-30", "authors_parsed": [["Wolff", "J Gerard", ""]]}, {"id": "1307.1070", "submitter": "Uwe Aickelin", "authors": "Naisan Benatar, Uwe Aickelin, Jonathan M. Garibaldi", "title": "A Comparison of Non-stationary, Type-2 and Dual Surface Fuzzy Control", "comments": "2011 IEEE International Conference on Fuzzy Systems, pp 1193-1200", "journal-ref": null, "doi": "10.1109/FUZZY.2011.6007602", "report-no": null, "categories": "cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Type-1 fuzzy logic has frequently been used in control systems. However this\nmethod is sometimes shown to be too restrictive and unable to adapt in the\npresence of uncertainty. In this paper we compare type-1 fuzzy control with\nseveral other fuzzy approaches under a range of uncertain conditions. Interval\ntype-2 and non-stationary fuzzy controllers are compared, along with 'dual\nsurface' type-2 control, named due to utilising both the lower and upper values\nproduced from standard interval type-2 systems. We tune a type-1 controller,\nthen derive the membership functions and footprints of uncertainty from the\ntype-1 system and evaluate them using a simulated autonomous sailing problem\nwith varying amounts of environmental uncertainty. We show that while these\nmore sophisticated controllers can produce better performance than the type-1\ncontroller, this is not guaranteed and that selection of Footprint of\nUncertainty (FOU) size has a large effect on this relative performance.\n", "versions": [{"version": "v1", "created": "Wed, 3 Jul 2013 16:34:00 GMT"}], "update_date": "2016-11-15", "authors_parsed": [["Benatar", "Naisan", ""], ["Aickelin", "Uwe", ""], ["Garibaldi", "Jonathan M.", ""]]}, {"id": "1307.1277", "submitter": "David Fern\\'andez-Duque", "authors": "Johan van Benthem and David Fern\\'andez-Duque and Eric Pacuit", "title": "Evidence and plausibility in neighborhood structures", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.LO cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The intuitive notion of evidence has both semantic and syntactic features. In\nthis paper, we develop an {\\em evidence logic} for epistemic agents faced with\npossibly contradictory evidence from different sources. The logic is based on a\nneighborhood semantics, where a neighborhood $N$ indicates that the agent has\nreason to believe that the true state of the world lies in $N$. Further notions\nof relative plausibility between worlds and beliefs based on the latter\nordering are then defined in terms of this evidence structure, yielding our\nintended models for evidence-based beliefs. In addition, we also consider a\nsecond more general flavor, where belief and plausibility are modeled using\nadditional primitive relations, and we prove a representation theorem showing\nthat each such general model is a $p$-morphic image of an intended one. This\nsemantics invites a number of natural special cases, depending on how uniform\nwe make the evidence sets, and how coherent their total structure. We give a\nstructural study of the resulting `uniform' and `flat' models. Our main result\nare sound and complete axiomatizations for the logics of all four major model\nclasses with respect to the modal language of evidence, belief and safe belief.\nWe conclude with an outlook toward logics for the dynamics of changing\nevidence, and the resulting language extensions and connections with logics of\nplausibility change.\n", "versions": [{"version": "v1", "created": "Thu, 4 Jul 2013 11:22:31 GMT"}], "update_date": "2013-07-05", "authors_parsed": [["van Benthem", "Johan", ""], ["Fern\u00e1ndez-Duque", "David", ""], ["Pacuit", "Eric", ""]]}, {"id": "1307.1388", "submitter": "Hong Qiao", "authors": "Qiao Hong, Li Yinlin, Tang Tang, Wang Peng", "title": "Introducing Memory and Association Mechanism into a Biologically\n  Inspired Visual Model", "comments": "9 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A famous biologically inspired hierarchical model firstly proposed by\nRiesenhuber and Poggio has been successfully applied to multiple visual\nrecognition tasks. The model is able to achieve a set of position- and\nscale-tolerant recognition, which is a central problem in pattern recognition.\nIn this paper, based on some other biological experimental results, we\nintroduce the Memory and Association Mechanisms into the above biologically\ninspired model. The main motivations of the work are (a) to mimic the active\nmemory and association mechanism and add the 'top down' adjustment to the above\nbiologically inspired hierarchical model and (b) to build up an algorithm which\ncan save the space and keep a good recognition performance. The new model is\nalso applied to object recognition processes. The primary experimental results\nshow that our method is efficient with much less memory requirement.\n", "versions": [{"version": "v1", "created": "Thu, 4 Jul 2013 16:08:56 GMT"}], "update_date": "2013-07-05", "authors_parsed": [["Hong", "Qiao", ""], ["Yinlin", "Li", ""], ["Tang", "Tang", ""], ["Peng", "Wang", ""]]}, {"id": "1307.1408", "submitter": "Uwe Aickelin", "authors": "Naisan Benatar, Uwe Aickelin, Jonathan M. Garibaldi", "title": "An investigation into the relationship between type-2 FOU size and\n  environmental uncertainty in robotic control", "comments": "2012 IEEE International Conference on Fuzzy Systems (FUZZ-IEEE), pp\n  1-8, 2012", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It has been suggested that, when faced with large amounts of uncertainty in\nsituations of automated control, type-2 fuzzy logic based controllers will\nout-perform the simpler type-1 varieties due to the latter lacking the\nflexibility to adapt accordingly. This paper aims to investigate this problem\nin detail in order to analyse when a type-2 controller will improve upon type-1\nperformance. A robotic sailing boat is subjected to several experiments in\nwhich the uncertainty and difficulty of the sailing problem is increased in\norder to observe the effects on measured performance. Improved performance is\nobserved but not in every case. The size of the FOU is shown to be have a large\neffect on performance with potentially severe performance penalties for\nincorrectly sized footprints.\n", "versions": [{"version": "v1", "created": "Thu, 4 Jul 2013 16:57:37 GMT"}, {"version": "v2", "created": "Mon, 8 Jul 2013 13:44:11 GMT"}], "update_date": "2013-07-09", "authors_parsed": [["Benatar", "Naisan", ""], ["Aickelin", "Uwe", ""], ["Garibaldi", "Jonathan M.", ""]]}, {"id": "1307.1482", "submitter": "Lavindra de Silva", "authors": "Lavindra de Silva and Amit Kumar Pandey and Mamoun Gharbi and Rachid\n  Alami", "title": "Towards Combining HTN Planning and Geometric Task Planning", "comments": "RSS Workshop on Combined Robot Motion Planning and AI Planning for\n  Practical Applications, June 2013", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we present an interface between a symbolic planner and a\ngeometric task planner, which is different to a standard trajectory planner in\nthat the former is able to perform geometric reasoning on abstract\nentities---tasks. We believe that this approach facilitates a more principled\ninterface to symbolic planning, while also leaving more room for the geometric\nplanner to make independent decisions. We show how the two planners could be\ninterfaced, and how their planning and backtracking could be interleaved. We\nalso provide insights for a methodology for using the combined system, and\nexperimental results to use as a benchmark with future extensions to both the\ncombined system, as well as to the geometric task planner.\n", "versions": [{"version": "v1", "created": "Thu, 4 Jul 2013 20:28:40 GMT"}], "update_date": "2013-07-08", "authors_parsed": [["de Silva", "Lavindra", ""], ["Pandey", "Amit Kumar", ""], ["Gharbi", "Mamoun", ""], ["Alami", "Rachid", ""]]}, {"id": "1307.1568", "submitter": "Chau Do", "authors": "Chau Do and Eric J. Pauwels", "title": "Using MathML to Represent Units of Measurement for Improved Ontology\n  Alignment", "comments": "Conferences on Intelligent Computer Mathematics (CICM 2013), Bath,\n  England", "journal-ref": "CICM 2013, LNAI (7961), Springer, 2013", "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ontologies provide a formal description of concepts and their relationships\nin a knowledge domain. The goal of ontology alignment is to identify\nsemantically matching concepts and relationships across independently developed\nontologies that purport to describe the same knowledge. In order to handle the\nwidest possible class of ontologies, many alignment algorithms rely on\nterminological and structural meth- ods, but the often fuzzy nature of concepts\ncomplicates the matching process. However, one area that should provide clear\nmatching solutions due to its mathematical nature, is units of measurement.\nSeveral on- tologies for units of measurement are available, but there has been\nno attempt to align them, notwithstanding the obvious importance for tech-\nnical interoperability. We propose a general strategy to map these (and\nsimilar) ontologies by introducing MathML to accurately capture the semantic\ndescription of concepts specified therein. We provide mapping results for three\nontologies, and show that our approach improves on lexical comparisons.\n", "versions": [{"version": "v1", "created": "Fri, 5 Jul 2013 10:05:34 GMT"}], "update_date": "2013-07-08", "authors_parsed": [["Do", "Chau", ""], ["Pauwels", "Eric J.", ""]]}, {"id": "1307.1790", "submitter": "Evgenij Thorstensen", "authors": "Evgenij Thorstensen", "title": "Lifting Structural Tractability to CSP with Global Constraints", "comments": "To appear in proceedings of CP'13, LNCS 8124", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A wide range of problems can be modelled as constraint satisfaction problems\n(CSPs), that is, a set of constraints that must be satisfied simultaneously.\nConstraints can either be represented extensionally, by explicitly listing\nallowed combinations of values, or implicitly, by special-purpose algorithms\nprovided by a solver. Such implicitly represented constraints, known as global\nconstraints, are widely used; indeed, they are one of the key reasons for the\nsuccess of constraint programming in solving real-world problems.\n  In recent years, a variety of restrictions on the structure of CSP instances\nthat yield tractable classes have been identified. However, many such\nrestrictions fail to guarantee tractability for CSPs with global constraints.\nIn this paper, we investigate the properties of extensionally represented\nconstraints that these restrictions exploit to achieve tractability, and show\nthat there are large classes of global constraints that also possess these\nproperties. This allows us to lift these restrictions to the global case, and\nidentify new tractable classes of CSPs with global constraints.\n", "versions": [{"version": "v1", "created": "Sat, 6 Jul 2013 14:54:18 GMT"}], "update_date": "2013-07-09", "authors_parsed": [["Thorstensen", "Evgenij", ""]]}, {"id": "1307.1890", "submitter": "Arindam Chaudhuri AC", "authors": "Arindam Chaudhuri", "title": "Solution of Rectangular Fuzzy Games by Principle of Dominance Using\n  LR-type Trapezoidal Fuzzy Numbers", "comments": "Proceedings of 2nd International Conference on Advanced Computing &\n  Communication Technologies, Asia Pacific Institute of Information Technology,\n  Panipat, Haryana, India, 2007", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fuzzy Set Theory has been applied in many fields such as Operations Research,\nControl Theory, and Management Sciences etc. In particular, an application of\nthis theory in Managerial Decision Making Problems has a remarkable\nsignificance. In this Paper, we consider a solution of Rectangular Fuzzy game\nwith pay-off as imprecise numbers instead of crisp numbers viz., interval and\nLR-type Trapezoidal Fuzzy Numbers. The solution of such Fuzzy games with pure\nstrategies by minimax-maximin principle is discussed. The Algebraic Method to\nsolve Fuzzy games without saddle point by using mixed strategies is also\nillustrated. Here, pay-off matrix is reduced to pay-off matrix by Dominance\nMethod. This fact is illustrated by means of Numerical Example.\n", "versions": [{"version": "v1", "created": "Sun, 7 Jul 2013 18:07:03 GMT"}], "update_date": "2013-07-09", "authors_parsed": [["Chaudhuri", "Arindam", ""]]}, {"id": "1307.1891", "submitter": "Arindam Chaudhuri AC", "authors": "Arindam Chaudhuri, Kajal De", "title": "A Comparative study of Transportation Problem under Probabilistic and\n  Fuzzy Uncertainties", "comments": "GANIT, Journal of Bangladesh Mathematical Society, Bangladesh\n  Mathematical Society, Dhaka, Bangladesh, 2010 (In Press)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transportation Problem is an important aspect which has been widely studied\nin Operations Research domain. It has been studied to simulate different real\nlife problems. In particular, application of this Problem in NP- Hard Problems\nhas a remarkable significance. In this Paper, we present a comparative study of\nTransportation Problem through Probabilistic and Fuzzy Uncertainties. Fuzzy\nLogic is a computational paradigm that generalizes classical two-valued logic\nfor reasoning under uncertainty. In order to achieve this, the notation of\nmembership in a set needs to become a matter of degree. By doing this we\naccomplish two things viz., (i) ease of describing human knowledge involving\nvague concepts and (ii) enhanced ability to develop cost-effective solution to\nreal-world problem. The multi-valued nature of Fuzzy Sets allows handling\nuncertain and vague information. It is a model-less approach and a clever\ndisguise of Probability Theory. We give comparative simulation results of both\napproaches and discuss the Computational Complexity. To the best of our\nknowledge, this is the first work on comparative study of Transportation\nProblem using Probabilistic and Fuzzy Uncertainties.\n", "versions": [{"version": "v1", "created": "Sun, 7 Jul 2013 18:18:25 GMT"}], "update_date": "2013-07-09", "authors_parsed": [["Chaudhuri", "Arindam", ""], ["De", "Kajal", ""]]}, {"id": "1307.1893", "submitter": "Arindam Chaudhuri AC", "authors": "Arindam Chaudhuri, Kajal De, Dipak Chatterjee, Pabitra Mitra", "title": "Trapezoidal Fuzzy Numbers for the Transportation Problem", "comments": "International Journal of Intelligent Computing and Applications,\n  Volume 1, Number 2, 2009", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transportation Problem is an important problem which has been widely studied\nin Operations Research domain. It has been often used to simulate different\nreal life problems. In particular, application of this Problem in NP Hard\nProblems has a remarkable significance. In this Paper, we present the closed,\nbounded and non empty feasible region of the transportation problem using fuzzy\ntrapezoidal numbers which ensures the existence of an optimal solution to the\nbalanced transportation problem. The multivalued nature of Fuzzy Sets allows\nhandling of uncertainty and vagueness involved in the cost values of each cells\nin the transportation table. For finding the initial solution of the\ntransportation problem we use the Fuzzy Vogel Approximation Method and for\ndetermining the optimality of the obtained solution Fuzzy Modified Distribution\nMethod is used. The fuzzification of the cost of the transportation problem is\ndiscussed with the help of a numerical example. Finally, we discuss the\ncomputational complexity involved in the problem. To the best of our knowledge,\nthis is the first work on obtaining the solution of the transportation problem\nusing fuzzy trapezoidal numbers.\n", "versions": [{"version": "v1", "created": "Sun, 7 Jul 2013 18:32:23 GMT"}], "update_date": "2013-07-09", "authors_parsed": [["Chaudhuri", "Arindam", ""], ["De", "Kajal", ""], ["Chatterjee", "Dipak", ""], ["Mitra", "Pabitra", ""]]}, {"id": "1307.1895", "submitter": "Arindam Chaudhuri AC", "authors": "Arindam Chaudhuri, Kajal De, Dipak Chatterjee", "title": "Discovering Stock Price Prediction Rules of Bombay Stock Exchange Using\n  Rough Fuzzy Multi Layer Perception Networks", "comments": "Book Chapter: Forecasting Financial Markets in India, Rudra P.\n  Pradhan, Indian Institute of Technology Kharagpur, (Editor), Allied\n  Publishers, India, 2009", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In India financial markets have existed for many years. A functionally\naccented, diverse, efficient and flexible financial system is vital to the\nnational objective of creating a market driven, productive and competitive\neconomy. Today markets of varying maturity exist in equity, debt, commodities\nand foreign exchange. In this work we attempt to generate prediction rules\nscheme for stock price movement at Bombay Stock Exchange using an important\nSoft Computing paradigm viz., Rough Fuzzy Multi Layer Perception. The use of\nComputational Intelligence Systems such as Neural Networks, Fuzzy Sets, Genetic\nAlgorithms, etc. for Stock Market Predictions has been widely established. The\nprocess is to extract knowledge in the form of rules from daily stock\nmovements. These rules can then be used to guide investors. To increase the\nefficiency of the prediction process, Rough Sets is used to discretize the\ndata. The methodology uses a Genetic Algorithm to obtain a structured network\nsuitable for both classification and rule extraction. The modular concept,\nbased on divide and conquer strategy, provides accelerated training and a\ncompact network suitable for generating a minimum number of rules with high\ncertainty values. The concept of variable mutation operator is introduced for\npreserving the localized structure of the constituting Knowledge Based\nsub-networks, while they are integrated and evolved. Rough Set Dependency Rules\nare generated directly from the real valued attribute table containing Fuzzy\nmembership values. The paradigm is thus used to develop a rule extraction\nalgorithm. The extracted rules are compared with some of the related rule\nextraction techniques on the basis of some quantitative performance indices.\nThe proposed methodology extracts rules which are less in number, are accurate,\nhave high certainty factor and have low confusion with less computation time.\n", "versions": [{"version": "v1", "created": "Sun, 7 Jul 2013 18:47:19 GMT"}], "update_date": "2013-07-09", "authors_parsed": [["Chaudhuri", "Arindam", ""], ["De", "Kajal", ""], ["Chatterjee", "Dipak", ""]]}, {"id": "1307.1900", "submitter": "Arindam Chaudhuri AC", "authors": "Arindam Chaudhuri, Kajal De", "title": "Fuzzy Integer Linear Programming Mathematical Models for Examination\n  Timetable Problem", "comments": "International Journal of Innovative Computing, Information and\n  Control (Special Issue), Volume 7, Number 5, 2011", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  ETP is NP Hard combinatorial optimization problem. It has received tremendous\nresearch attention during the past few years given its wide use in\nuniversities. In this Paper, we develop three mathematical models for NSOU,\nKolkata, India using FILP technique. To deal with impreciseness and vagueness\nwe model various allocation variables through fuzzy numbers. The solution to\nthe problem is obtained using Fuzzy number ranking method. Each feasible\nsolution has fuzzy number obtained by Fuzzy objective function. The different\nFILP technique performance are demonstrated by experimental data generated\nthrough extensive simulation from NSOU, Kolkata, India in terms of its\nexecution times. The proposed FILP models are compared with commonly used\nheuristic viz. ILP approach on experimental data which gives an idea about\nquality of heuristic. The techniques are also compared with different\nArtificial Intelligence based heuristics for ETP with respect to best and mean\ncost as well as execution time measures on Carter benchmark datasets to\nillustrate its effectiveness. FILP takes an appreciable amount of time to\ngenerate satisfactory solution in comparison to other heuristics. The\nformulation thus serves as good benchmark for other heuristics. The\nexperimental study presented here focuses on producing a methodology that\ngeneralizes well over spectrum of techniques that generates significant results\nfor one or more datasets. The performance of FILP model is finally compared to\nthe best results cited in literature for Carter benchmarks to assess its\npotential. The problem can be further reduced by formulating with lesser number\nof allocation variables it without affecting optimality of solution obtained.\nFLIP model for ETP can also be adapted to solve other ETP as well as\ncombinatorial optimization problems.\n", "versions": [{"version": "v1", "created": "Sun, 7 Jul 2013 19:09:03 GMT"}], "update_date": "2013-07-09", "authors_parsed": [["Chaudhuri", "Arindam", ""], ["De", "Kajal", ""]]}, {"id": "1307.1903", "submitter": "Arindam Chaudhuri AC", "authors": "Arindam Chaudhuri, Kajal De", "title": "Achieving greater Explanatory Power and Forecasting Accuracy with\n  Non-uniform spread Fuzzy Linear Regression", "comments": "Proceedings of 13th Conference of Society of Operations Management,\n  Department of Management Studies, Indian Institute of Technology, Madras,\n  Tamilnadu, India, 2009", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fuzzy regression models have been applied to several Operations Research\napplications viz., forecasting and prediction. Earlier works on fuzzy\nregression analysis obtain crisp regression coefficients for eliminating the\nproblem of increasing spreads for the estimated fuzzy responses as the\nmagnitude of the independent variable increases. But they cannot deal with the\nproblem of non-uniform spreads. In this work, a three-phase approach is\ndiscussed to construct the fuzzy regression model with non-uniform spreads to\ndeal with this problem. The first phase constructs the membership functions of\nthe least-squares estimates of regression coefficients based on extension\nprinciple to completely conserve the fuzziness of observations. They are then\ndefuzzified by the centre of area method to obtain crisp regression\ncoefficients in the second phase. Finally, the error terms of the method are\ndetermined by setting each estimated spread equal to its corresponding observed\nspread. The Tagaki-Sugeno inference system is used for improving the accuracy\nof forecasts. The simulation example demonstrates the strength of fuzzy linear\nregression model in terms of higher explanatory power and forecasting\nperformance.\n", "versions": [{"version": "v1", "created": "Sun, 7 Jul 2013 19:20:01 GMT"}], "update_date": "2013-07-09", "authors_parsed": [["Chaudhuri", "Arindam", ""], ["De", "Kajal", ""]]}, {"id": "1307.1905", "submitter": "Arindam Chaudhuri AC", "authors": "Arindam Chaudhuri", "title": "A Dynamic Algorithm for the Longest Common Subsequence Problem using Ant\n  Colony Optimization Technique", "comments": "Proceedings of 2nd International Conference on Mathematics: Trends\n  and Developments, Al Azhar University, Cairo, Egypt, 2007", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a dynamic algorithm for solving the Longest Common Subsequence\nProblem using Ant Colony Optimization Technique. The Ant Colony Optimization\nTechnique has been applied to solve many problems in Optimization Theory,\nMachine Learning and Telecommunication Networks etc. In particular, application\nof this theory in NP-Hard Problems has a remarkable significance. Given two\nstrings, the traditional technique for finding Longest Common Subsequence is\nbased on Dynamic Programming which consists of creating a recurrence relation\nand filling a table of size . The proposed algorithm draws analogy with\nbehavior of ant colonies function and this new computational paradigm is known\nas Ant System. It is a viable new approach to Stochastic Combinatorial\nOptimization. The main characteristics of this model are positive feedback,\ndistributed computation, and the use of constructive greedy heuristic. Positive\nfeedback accounts for rapid discovery of good solutions, distributed\ncomputation avoids premature convergence and greedy heuristic helps find\nacceptable solutions in minimum number of stages. We apply the proposed\nmethodology to Longest Common Subsequence Problem and give the simulation\nresults. The effectiveness of this approach is demonstrated by efficient\nComputational Complexity. To the best of our knowledge, this is the first Ant\nColony Optimization Algorithm for Longest Common Subsequence Problem.\n", "versions": [{"version": "v1", "created": "Sun, 7 Jul 2013 19:30:54 GMT"}], "update_date": "2013-07-09", "authors_parsed": [["Chaudhuri", "Arindam", ""]]}, {"id": "1307.1944", "submitter": "EPTCS", "authors": "Makarius Wenzel", "title": "READ-EVAL-PRINT in Parallel and Asynchronous Proof-checking", "comments": "In Proceedings UITP 2012, arXiv:1307.1528", "journal-ref": "EPTCS 118, 2013, pp. 57-71", "doi": "10.4204/EPTCS.118.4", "report-no": null, "categories": "cs.LO cs.AI cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The LCF tradition of interactive theorem proving, which was started by Milner\nin the 1970-ies, appears to be tied to the classic READ-EVAL-PRINT-LOOP of\nsequential and synchronous evaluation of prover commands. We break up this loop\nand retrofit the read-eval-print phases into a model of parallel and\nasynchronous proof processing. Thus we explain some key concepts of the\nIsabelle/Scala approach to prover interaction and integration, and the\nIsabelle/jEdit Prover IDE as front-end technology. We hope to open up the\nscientific discussion about non-trivial interaction models for ITP systems\nagain, and help getting other old-school proof assistants on a similar track.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jul 2013 04:41:45 GMT"}], "update_date": "2013-07-09", "authors_parsed": [["Wenzel", "Makarius", ""]]}, {"id": "1307.2191", "submitter": "Marcia Shamo", "authors": "Yoram Moses (1) and Marcia K. Shamo ((1) Technion - Israel Institute\n  of Technology)", "title": "A Knowledge-based Treatment of Human-Automation Systems", "comments": "39 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a supervisory control system the human agent knowledge of past, current,\nand future system behavior is critical for system performance. Being able to\nreason about that knowledge in a precise and structured manner is central to\neffective system design. In this paper we introduce the application of a\nwell-established formal approach to reasoning about knowledge to the modeling\nand analysis of complex human-automation systems. An intuitive notion of\nknowledge in human-automation systems is sketched and then cast as a formal\nmodel. We present a case study in which the approach is used to model and\nreason about a classic problem from the human-automation systems literature;\nthe results of our analysis provide evidence for the validity and value of\nreasoning about complex systems in terms of the knowledge of the system agents.\nTo conclude, we discuss research directions that will extend this approach, and\nnote several systems in the aviation and human-robot team domains that are of\nparticular interest.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jul 2013 18:07:31 GMT"}], "update_date": "2013-07-09", "authors_parsed": [["Moses", "Yoram", ""], ["Shamo", "Marcia K.", ""]]}, {"id": "1307.2200", "submitter": "Hang Dinh", "authors": "Hang Dinh and Hieu Dinh", "title": "Inconsistency and Accuracy of Heuristics with A* Search", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many studies in heuristic search suggest that the accuracy of the heuristic\nused has a positive impact on improving the performance of the search. In\nanother direction, historical research perceives that the performance of\nheuristic search algorithms, such as A* and IDA*, can be improved by requiring\nthe heuristics to be consistent -- a property satisfied by any perfect\nheuristic. However, a few recent studies show that inconsistent heuristics can\nalso be used to achieve a large improvement in these heuristic search\nalgorithms. These results leave us a natural question: which property of\nheuristics, accuracy or consistency/inconsistency, should we focus on when\nbuilding heuristics? While there are studies on the heuristic accuracy with the\nassumption of consistency, no studies on both the inconsistency and the\naccuracy of heuristics are known to our knowledge.\n  In this study, we investigate the relationship between the inconsistency and\nthe accuracy of heuristics with A* search. Our analytical result reveals a\ncorrelation between these two properties. We then run experiments on the domain\nfor the Knapsack problem with a family of practical heuristics. Our empirical\nresults show that in many cases, the more accurate heuristics also have higher\nlevel of inconsistency and result in fewer node expansions by A*.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jul 2013 18:53:07 GMT"}], "update_date": "2013-07-09", "authors_parsed": [["Dinh", "Hang", ""], ["Dinh", "Hieu", ""]]}, {"id": "1307.2541", "submitter": "Mehul Bhatt", "authors": "Mehul Bhatt and Jan Oliver Wallgruen", "title": "Geospatial Narratives and their Spatio-Temporal Dynamics: Commonsense\n  Reasoning for High-level Analyses in Geographic Information Systems", "comments": "ISPRS International Journal of Geo-Information (ISSN 2220-9964);\n  Special Issue on: Geospatial Monitoring and Modelling of Environmental\n  Change}. IJGI. Editor: Duccio Rocchini. (pre-print of article in press)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.ET cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The modelling, analysis, and visualisation of dynamic geospatial phenomena\nhas been identified as a key developmental challenge for next-generation\nGeographic Information Systems (GIS). In this context, the envisaged\nparadigmatic extensions to contemporary foundational GIS technology raises\nfundamental questions concerning the ontological, formal representational, and\n(analytical) computational methods that would underlie their spatial\ninformation theoretic underpinnings.\n  We present the conceptual overview and architecture for the development of\nhigh-level semantic and qualitative analytical capabilities for dynamic\ngeospatial domains. Building on formal methods in the areas of commonsense\nreasoning, qualitative reasoning, spatial and temporal representation and\nreasoning, reasoning about actions and change, and computational models of\nnarrative, we identify concrete theoretical and practical challenges that\naccrue in the context of formal reasoning about `space, events, actions, and\nchange'. With this as a basis, and within the backdrop of an illustrated\nscenario involving the spatio-temporal dynamics of urban narratives, we address\nspecific problems and solutions techniques chiefly involving `qualitative\nabstraction', `data integration and spatial consistency', and `practical\ngeospatial abduction'. From a broad topical viewpoint, we propose that\nnext-generation dynamic GIS technology demands a transdisciplinary scientific\nperspective that brings together Geography, Artificial Intelligence, and\nCognitive Science.\n  Keywords: artificial intelligence; cognitive systems; human-computer\ninteraction; geographic information systems; spatio-temporal dynamics;\ncomputational models of narrative; geospatial analysis; geospatial modelling;\nontology; qualitative spatial modelling and reasoning; spatial assistance\nsystems\n", "versions": [{"version": "v1", "created": "Tue, 9 Jul 2013 18:54:29 GMT"}, {"version": "v2", "created": "Mon, 16 Dec 2013 12:14:01 GMT"}], "update_date": "2013-12-17", "authors_parsed": [["Bhatt", "Mehul", ""], ["Wallgruen", "Jan Oliver", ""]]}, {"id": "1307.2579", "submitter": "Jonathan Huang", "authors": "Chris Piech, Jonathan Huang, Zhenghao Chen, Chuong Do, Andrew Ng,\n  Daphne Koller", "title": "Tuned Models of Peer Assessment in MOOCs", "comments": "Proceedings of The 6th International Conference on Educational Data\n  Mining (EDM 2013)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.HC stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In massive open online courses (MOOCs), peer grading serves as a critical\ntool for scaling the grading of complex, open-ended assignments to courses with\ntens or hundreds of thousands of students. But despite promising initial\ntrials, it does not always deliver accurate results compared to human experts.\nIn this paper, we develop algorithms for estimating and correcting for grader\nbiases and reliabilities, showing significant improvement in peer grading\naccuracy on real data with 63,199 peer grades from Coursera's HCI course\nofferings --- the largest peer grading networks analysed to date. We relate\ngrader biases and reliabilities to other student factors such as student\nengagement, performance as well as commenting style. We also show that our\nmodel can lead to more intelligent assignment of graders to gradees.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jul 2013 20:03:51 GMT"}], "update_date": "2013-07-11", "authors_parsed": [["Piech", "Chris", ""], ["Huang", "Jonathan", ""], ["Chen", "Zhenghao", ""], ["Do", "Chuong", ""], ["Ng", "Andrew", ""], ["Koller", "Daphne", ""]]}, {"id": "1307.2704", "submitter": "Hua Yao", "authors": "Hua Yao, William Zhu", "title": "Applications of repeat degree on coverings of neighborhoods", "comments": "14", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In covering based rough sets, the neighborhood of an element is the\nintersection of all the covering blocks containing the element. All the\nneighborhoods form a new covering called a covering of neighborhoods. In the\ncourse of studying under what condition a covering of neighborhoods is a\npartition, the concept of repeat degree is proposed, with the help of which the\nissue is addressed. This paper studies further the application of repeat degree\non coverings of neighborhoods. First, we investigate under what condition a\ncovering of neighborhoods is the reduct of the covering inducing it. As a\npreparation for addressing this issue, we give a necessary and sufficient\ncondition for a subset of a set family to be the reduct of the set family. Then\nwe study under what condition two coverings induce a same relation and a same\ncovering of neighborhoods. Finally, we give the method of calculating the\ncovering according to repeat degree.\n", "versions": [{"version": "v1", "created": "Wed, 10 Jul 2013 07:43:57 GMT"}], "update_date": "2013-07-11", "authors_parsed": [["Yao", "Hua", ""], ["Zhu", "William", ""]]}, {"id": "1307.2867", "submitter": "Evgenij Thorstensen", "authors": "David A. Cohen and Peter G. Jeavons and Evgenij Thorstensen and\n  Stanislav \\v{Z}ivn\\'y", "title": "Tractable Combinations of Global Constraints", "comments": "To appear in proceedings of CP'13, LNCS 8124. arXiv admin note: text\n  overlap with arXiv:1307.1790", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the complexity of constraint satisfaction problems involving global\nconstraints, i.e., special-purpose constraints provided by a solver and\nrepresented implicitly by a parametrised algorithm. Such constraints are widely\nused; indeed, they are one of the key reasons for the success of constraint\nprogramming in solving real-world problems.\n  Previous work has focused on the development of efficient propagators for\nindividual constraints. In this paper, we identify a new tractable class of\nconstraint problems involving global constraints of unbounded arity. To do so,\nwe combine structural restrictions with the observation that some important\ntypes of global constraint do not distinguish between large classes of\nequivalent solutions.\n", "versions": [{"version": "v1", "created": "Wed, 10 Jul 2013 18:01:30 GMT"}], "update_date": "2013-07-11", "authors_parsed": [["Cohen", "David A.", ""], ["Jeavons", "Peter G.", ""], ["Thorstensen", "Evgenij", ""], ["\u017divn\u00fd", "Stanislav", ""]]}, {"id": "1307.2982", "submitter": "Mohammad Norouzi", "authors": "Mohammad Norouzi, Ali Punjani, David J. Fleet", "title": "Fast Exact Search in Hamming Space with Multi-Index Hashing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.DS cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is growing interest in representing image data and feature descriptors\nusing compact binary codes for fast near neighbor search. Although binary codes\nare motivated by their use as direct indices (addresses) into a hash table,\ncodes longer than 32 bits are not being used as such, as it was thought to be\nineffective. We introduce a rigorous way to build multiple hash tables on\nbinary code substrings that enables exact k-nearest neighbor search in Hamming\nspace. The approach is storage efficient and straightforward to implement.\nTheoretical analysis shows that the algorithm exhibits sub-linear run-time\nbehavior for uniformly distributed codes. Empirical results show dramatic\nspeedups over a linear scan baseline for datasets of up to one billion codes of\n64, 128, or 256 bits.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jul 2013 05:52:21 GMT"}, {"version": "v2", "created": "Sun, 15 Dec 2013 02:36:21 GMT"}, {"version": "v3", "created": "Fri, 25 Apr 2014 01:31:55 GMT"}], "update_date": "2014-04-28", "authors_parsed": [["Norouzi", "Mohammad", ""], ["Punjani", "Ali", ""], ["Fleet", "David J.", ""]]}, {"id": "1307.3004", "submitter": "Sharad Sharma", "authors": "Sharad Sharma, Shakti Kumar and Brahmjit Singh", "title": "Routing in Wireless Mesh Networks: Two Soft Computing Based Approaches", "comments": "11 Pages, 7 Figures", "journal-ref": "International Journal of Mobile Network Communications &\n  Telematics ( IJMNCT) Vol. 3, No.3, June 2013", "doi": "10.5121/ijmnct.2013.3304", "report-no": null, "categories": "cs.NI cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to dynamic network conditions, routing is the most critical part in WMNs\nand needs to be optimised. The routing strategies developed for WMNs must be\nefficient to make it an operationally self configurable network. Thus we need\nto resort to near shortest path evaluation. This lays down the requirement of\nsome soft computing approaches such that a near shortest path is available in\nan affordable computing time. This paper proposes a Fuzzy Logic based\nintegrated cost measure in terms of delay, throughput and jitter. Based upon\nthis distance (cost) between two adjacent nodes we evaluate minimal shortest\npath that updates routing tables. We apply two recent soft computing approaches\nnamely Big Bang Big Crunch (BB-BC) and Biogeography Based Optimization (BBO)\napproaches to enumerate shortest or near short paths. BB-BC theory is related\nwith the evolution of the universe whereas BBO is inspired by dynamical\nequilibrium in the number of species on an island. Both the algorithms have low\ncomputational time and high convergence speed. Simulation results show that the\nproposed routing algorithms find the optimal shortest path taking into account\nthree most important parameters of network dynamics. It has been further\nobserved that for the shortest path problem BB-BC outperforms BBO in terms of\nspeed and percent error between the evaluated minimal path and the actual\nshortest path.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jul 2013 07:51:58 GMT"}], "update_date": "2013-07-12", "authors_parsed": [["Sharma", "Sharad", ""], ["Kumar", "Shakti", ""], ["Singh", "Brahmjit", ""]]}, {"id": "1307.3011", "submitter": "Sharad Sharma", "authors": "Shakti Kumar, Brahmjit Singh, Sharad Sharma", "title": "Soft Computing Framework for Routing in Wireless Mesh Networks: An\n  Integrated Cost Function Approach", "comments": "8 pages, 19 Figures", "journal-ref": "International Journal of Electronics, Computer and Communication\n  Technologies (IJECCT), 2013, Vol.3(3),pp.25-32, 2013", "doi": null, "report-no": null, "categories": "cs.NI cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dynamic behaviour of a WMN imposes stringent constraints on the routing\npolicy of the network. In the shortest path based routing the shortest paths\nneeds to be evaluated within a given time frame allowed by the WMN dynamics.\nThe exact reasoning based shortest path evaluation methods usually fail to meet\nthis rigid requirement. Thus, requiring some soft computing based approaches\nwhich can replace \"best for sure\" solutions with \"good enough\" solutions. This\npaper proposes a framework for optimal routing in the WMNs; where we\ninvestigate the suitability of Big Bang-Big Crunch (BB-BC), a soft computing\nbased approach to evaluate shortest/near-shortest path. In order to make\nrouting optimal we first propose to replace distance between the adjacent nodes\nwith an integrated cost measure that takes into account throughput, delay,\njitter and residual energy of a node. A fuzzy logic based inference mechanism\nevaluates this cost measure at each node. Using this distance measure we apply\nBB-BC optimization algorithm to evaluate shortest/near shortest path to update\nthe routing tables periodically as dictated by network requirements. A large\nnumber of simulations were conducted and it has been observed that BB-BC\nalgorithm appears to be a high potential candidate suitable for routing in\nWMNs.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jul 2013 08:22:16 GMT"}], "update_date": "2013-07-12", "authors_parsed": [["Kumar", "Shakti", ""], ["Singh", "Brahmjit", ""], ["Sharma", "Sharad", ""]]}, {"id": "1307.3040", "submitter": "Mehul Bhatt", "authors": "Mehul Bhatt", "title": "Between Sense and Sensibility: Declarative narrativisation of mental\n  models as a basis and benchmark for visuo-spatial cognition and computation\n  focussed collaborative cognitive systems", "comments": "5 pages, research statement summarising recent publications", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.CV cs.HC cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  What lies between `\\emph{sensing}' and `\\emph{sensibility}'? In other words,\nwhat kind of cognitive processes mediate sensing capability, and the formation\nof sensible impressions ---e.g., abstractions, analogies, hypotheses and theory\nformation, beliefs and their revision, argument formation--- in domain-specific\nproblem solving, or in regular activities of everyday living, working and\nsimply going around in the environment? How can knowledge and reasoning about\nsuch capabilities, as exhibited by humans in particular problem contexts, be\nused as a model and benchmark for the development of collaborative cognitive\n(interaction) systems concerned with human assistance, assurance, and\nempowerment?\n  We pose these questions in the context of a range of assistive technologies\nconcerned with \\emph{visuo-spatial perception and cognition} tasks encompassing\naspects such as commonsense, creativity, and the application of specialist\ndomain knowledge and problem-solving thought processes. Assistive technologies\nbeing considered include: (a) human activity interpretation; (b) high-level\ncognitive rovotics; (c) people-centred creative design in domains such as\narchitecture & digital media creation, and (d) qualitative analyses geographic\ninformation systems. Computational narratives not only provide a rich cognitive\nbasis, but they also serve as a benchmark of functional performance in our\ndevelopment of computational cognitive assistance systems. We posit that\ncomputational narrativisation pertaining to space, actions, and change provides\na useful model of \\emph{visual} and \\emph{spatio-temporal thinking} within a\nwide-range of problem-solving tasks and application areas where collaborative\ncognitive systems could serve an assistive and empowering function.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jul 2013 10:01:29 GMT"}, {"version": "v2", "created": "Mon, 31 Mar 2014 10:22:29 GMT"}], "update_date": "2014-04-01", "authors_parsed": [["Bhatt", "Mehul", ""]]}, {"id": "1307.3091", "submitter": "Gra\\c{c}a Marietto Dr", "authors": "Maria das Gra\\c{c}as Bruno Marietto, Rafael Varago de Aguiar, Gislene\n  de Oliveira Barbosa, Wagner Tanaka Botelho, Edson Pimentel, Robson dos Santos\n  Fran\\c{c}a and Vera L\\'ucia da Silva", "title": "Artificial Intelligence MArkup Language: A Brief Tutorial", "comments": "International Journal of Computer science and engineering Survey\n  (IJCSES) - 2013", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The purpose of this paper is to serve as a reference guide for the\ndevelopment of chatterbots implemented with the AIML language. In order to\nachieve this, the main concepts in Pattern Recognition area are described\nbecause the AIML uses such theoretical framework in their syntactic and\nsemantic structures. After that, AIML language is described and each AIML\ncommand/tag is followed by an application example. Also, the usage of AIML\nembedded tags for the handling of sequence dialogue limitations between humans\nand machines is shown. Finally, computer systems that assist in the design of\nchatterbots with the AIML language are classified and described.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jul 2013 12:49:43 GMT"}], "update_date": "2013-07-12", "authors_parsed": [["Marietto", "Maria das Gra\u00e7as Bruno", ""], ["de Aguiar", "Rafael Varago", ""], ["Barbosa", "Gislene de Oliveira", ""], ["Botelho", "Wagner Tanaka", ""], ["Pimentel", "Edson", ""], ["Fran\u00e7a", "Robson dos Santos", ""], ["da Silva", "Vera L\u00facia", ""]]}, {"id": "1307.3195", "submitter": "Stavros Vassos", "authors": "Davide Aversa, Stavros Vassos", "title": "Action-based Character AI in Video-games with CogBots Architecture: A\n  Preliminary Report", "comments": "7 pages, for associated code repositories see\n  https://github.com/THeK3nger/gridworld and\n  https://github.com/THeK3nger/unity-cogbot", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we propose an architecture for specifying the interaction of\nnon-player characters (NPCs) in the game-world in a way that abstracts common\ntasks in four main conceptual components, namely perception, deliberation,\ncontrol, action. We argue that this architecture, inspired by AI research on\nautonomous agents and robots, can offer a number of benefits in the form of\nabstraction, modularity, re-usability and higher degrees of personalization for\nthe behavior of each NPC. We also show how this architecture can be used to\ntackle a simple scenario related to the navigation of NPCs under incomplete\ninformation about the obstacles that may obstruct the various way-points in the\ngame, in a simple and effective way.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jul 2013 17:38:24 GMT"}], "update_date": "2013-07-12", "authors_parsed": [["Aversa", "Davide", ""], ["Vassos", "Stavros", ""]]}, {"id": "1307.3435", "submitter": "Hadi Mohasel Afshar", "authors": "Hadi Mohasel Afshar and Peter Sunehag", "title": "On Nicod's Condition, Rules of Induction and the Raven Paradox", "comments": "On raven paradox, Nicod's condition, projectability, induction", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Philosophers writing about the ravens paradox often note that Nicod's\nCondition (NC) holds given some set of background information, and fails to\nhold against others, but rarely go any further. That is, it is usually not\nexplored which background information makes NC true or false. The present paper\naims to fill this gap. For us, \"(objective) background knowledge\" is restricted\nto information that can be expressed as probability events. Any other\nconfiguration is regarded as being subjective and a property of the a priori\nprobability distribution. We study NC in two specific settings. In the first\ncase, a complete description of some individuals is known, e.g. one knows of\neach of a group of individuals whether they are black and whether they are\nravens. In the second case, the number of individuals having a particular\nproperty is given, e.g. one knows how many ravens or how many black things\nthere are (in the relevant population). While some of the most famous answers\nto the paradox are measure-dependent, our discussion is not restricted to any\nparticular probability measure. Our most interesting result is that in the\nsecond setting, NC violates a simple kind of inductive inference (namely\nprojectability). Since relative to NC, this latter rule is more closely related\nto, and more directly justified by our intuitive notion of inductive reasoning,\nthis tension makes a case against the plausibility of NC. In the end, we\nsuggest that the informal representation of NC may seem to be intuitively\nplausible because it can easily be mistaken for reasoning by analogy.\n", "versions": [{"version": "v1", "created": "Fri, 12 Jul 2013 12:28:38 GMT"}, {"version": "v2", "created": "Tue, 16 Jul 2013 02:22:09 GMT"}], "update_date": "2013-07-17", "authors_parsed": [["Afshar", "Hadi Mohasel", ""], ["Sunehag", "Peter", ""]]}, {"id": "1307.3585", "submitter": "Bertrand Mazure", "authors": "\\'Eric Gr\\'egoire, Jean-Marie Lagniez, Bertrand Mazure", "title": "Improving MUC extraction thanks to local search", "comments": "17 pages, 5 figures, 1 table, 3 algorithms, 33 references", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  ExtractingMUCs(MinimalUnsatisfiableCores)fromanunsatisfiable constraint\nnetwork is a useful process when causes of unsatisfiability must be understood\nso that the network can be re-engineered and relaxed to become sat- isfiable.\nDespite bad worst-case computational complexity results, various MUC- finding\napproaches that appear tractable for many real-life instances have been\nproposed. Many of them are based on the successive identification of so-called\ntransition constraints. In this respect, we show how local search can be used\nto possibly extract additional transition constraints at each main iteration\nstep. The approach is shown to outperform a technique based on a form of model\nrotation imported from the SAT-related technology and that also exhibits\nadditional transi- tion constraints. Our extensive computational\nexperimentations show that this en- hancement also boosts the performance of\nstate-of-the-art DC(WCORE)-like MUC extractors.\n", "versions": [{"version": "v1", "created": "Fri, 12 Jul 2013 21:28:05 GMT"}], "update_date": "2013-07-16", "authors_parsed": [["Gr\u00e9goire", "\u00c9ric", ""], ["Lagniez", "Jean-Marie", ""], ["Mazure", "Bertrand", ""]]}, {"id": "1307.3626", "submitter": "Sadegh Aliakbary", "authors": "Sadegh Aliakbary, Sadegh Motallebi, Jafar Habibi, Ali Movaghar", "title": "Learning an Integrated Distance Metric for Comparing Structure of\n  Complex Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.AI physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph comparison plays a major role in many network applications. We often\nneed a similarity metric for comparing networks according to their structural\nproperties. Various network features - such as degree distribution and\nclustering coefficient - provide measurements for comparing networks from\ndifferent points of view, but a global and integrated distance metric is still\nmissing. In this paper, we employ distance metric learning algorithms in order\nto construct an integrated distance metric for comparing structural properties\nof complex networks. According to natural witnesses of network similarities\n(such as network categories) the distance metric is learned by the means of a\ndataset of some labeled real networks. For evaluating our proposed method which\nis called NetDistance, we applied it as the distance metric in\nK-nearest-neighbors classification. Empirical results show that NetDistance\noutperforms previous methods, at least 20 percent, with respect to precision.\n", "versions": [{"version": "v1", "created": "Sat, 13 Jul 2013 07:53:19 GMT"}], "update_date": "2013-07-16", "authors_parsed": [["Aliakbary", "Sadegh", ""], ["Motallebi", "Sadegh", ""], ["Habibi", "Jafar", ""], ["Movaghar", "Ali", ""]]}, {"id": "1307.3667", "submitter": "Marcelo Coniglio", "authors": "Marcelo Coniglio, Francesc Esteva, Llu\\'is Godo", "title": "Logics of formal inconsistency arising from systems of fuzzy logic", "comments": "Revised and improved final version. 33 pages, 3 figures", "journal-ref": "Logic Journal of the IGPL 22(6):880-904, 2014", "doi": "10.1093/jigpal/jzu016", "report-no": null, "categories": "math.LO cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes the meeting of fuzzy logic with paraconsistency in a very\nprecise and foundational way. Specifically, in this paper we introduce\nexpansions of the fuzzy logic MTL by means of primitive operators for\nconsistency and inconsistency in the style of the so-called Logics of Formal\nInconsistency (LFIs). The main novelty of the present approach is the\ndefinition of postulates for this type of operators over MTL-algebras, leading\nto the definition and axiomatization of a family of logics, expansions of MTL,\nwhose degree-preserving counterpart are paraconsistent and moreover LFIs.\n", "versions": [{"version": "v1", "created": "Sat, 13 Jul 2013 18:25:52 GMT"}, {"version": "v2", "created": "Wed, 25 Sep 2013 23:45:00 GMT"}, {"version": "v3", "created": "Sat, 8 Mar 2014 13:07:10 GMT"}], "update_date": "2021-03-15", "authors_parsed": [["Coniglio", "Marcelo", ""], ["Esteva", "Francesc", ""], ["Godo", "Llu\u00eds", ""]]}, {"id": "1307.3802", "submitter": "Joseph Norman", "authors": "Joseph W. Norman", "title": "Probability Distinguishes Different Types of Conditional Statements", "comments": "Fixed a few typographical errors", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.LO cs.AI math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The language of probability is used to define several different types of\nconditional statements. There are four principal types: subjunctive, material,\nexistential, and feasibility. Two further types of conditionals are defined\nusing the propositional calculus and Boole's mathematical logic:\ntruth-functional and Boolean feasibility (which turn out to be special cases of\nprobabilistic conditionals). Each probabilistic conditional is quantified by a\nfractional parameter between zero and one that says whether it is purely\naffirmative, purely negative, or intermediate in its sense. Conditionals can be\nspecialized further by their content to express factuality and\ncounterfactuality, and revised or reformulated to account for exceptions and\nconfounding factors. The various conditionals have distinct mathematical\nrepresentations: through intermediate probability expressions and logical\nformulas, each conditional is eventually translated into a set of polynomial\nequations and inequalities (with real coefficients). The polynomial systems\nfrom different types of conditionals exhibit different patterns of behavior,\nconcerning for example opposing conditionals or false antecedents. Interesting\nresults can be computed from the relevant polynomial systems using well-known\nmethods from algebra and computer science. Among other benefits, the proposed\nframework of analysis offers paraconsistent procedures for logical deduction\nthat produce such familiar results as modus ponens, transitivity, disjunction\nintroduction, and disjunctive syllogism; all while avoiding any explosion of\nconsequences from inconsistent premises. Several example problems from Goodman\nand Adams are analyzed. A new perspective called polylogicism is presented:\nmathematical logic that respects the diversity among conditionals in particular\nand logic problems in general.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jul 2013 01:35:19 GMT"}, {"version": "v2", "created": "Sat, 20 Jul 2013 23:25:27 GMT"}, {"version": "v3", "created": "Wed, 5 Feb 2014 04:14:57 GMT"}, {"version": "v4", "created": "Fri, 26 Sep 2014 03:58:20 GMT"}], "update_date": "2014-09-29", "authors_parsed": [["Norman", "Joseph W.", ""]]}, {"id": "1307.3824", "submitter": "Keki Burjorjee", "authors": "Keki M. Burjorjee", "title": "The Fundamental Learning Problem that Genetic Algorithms with Uniform\n  Crossover Solve Efficiently and Repeatedly As Evolution Proceeds", "comments": "For an easy introduction to implicit concurrency (with animations),\n  visit\n  http://blog.hackingevolution.net/2013/03/24/implicit-concurrency-in-genetic-algorithms/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.CC cs.DM cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper establishes theoretical bonafides for implicit concurrent\nmultivariate effect evaluation--implicit concurrency for short---a broad and\nversatile computational learning efficiency thought to underlie\ngeneral-purpose, non-local, noise-tolerant optimization in genetic algorithms\nwith uniform crossover (UGAs). We demonstrate that implicit concurrency is\nindeed a form of efficient learning by showing that it can be used to obtain\nclose-to-optimal bounds on the time and queries required to approximately\ncorrectly solve a constrained version (k=7, \\eta=1/5) of a recognizable\ncomputational learning problem: learning parities with noisy membership\nqueries. We argue that a UGA that treats the noisy membership query oracle as a\nfitness function can be straightforwardly used to approximately correctly learn\nthe essential attributes in O(log^1.585 n) queries and O(n log^1.585 n) time,\nwhere n is the total number of attributes. Our proof relies on an accessible\nsymmetry argument and the use of statistical hypothesis testing to reject a\nglobal null hypothesis at the 10^-100 level of significance. It is, to the best\nof our knowledge, the first relatively rigorous identification of efficient\ncomputational learning in an evolutionary algorithm on a non-trivial learning\nproblem.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jul 2013 06:32:52 GMT"}], "update_date": "2013-07-16", "authors_parsed": [["Burjorjee", "Keki M.", ""]]}, {"id": "1307.3964", "submitter": "Alejandro Edera", "authors": "Alejandro Edera, Federico Schl\\\"uter, Facundo Bromberg", "title": "Learning Markov networks with context-specific independences", "comments": "8 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning the Markov network structure from data is a problem that has\nreceived considerable attention in machine learning, and in many other\napplication fields. This work focuses on a particular approach for this purpose\ncalled independence-based learning. Such approach guarantees the learning of\nthe correct structure efficiently, whenever data is sufficient for representing\nthe underlying distribution. However, an important issue of such approach is\nthat the learned structures are encoded in an undirected graph. The problem\nwith graphs is that they cannot encode some types of independence relations,\nsuch as the context-specific independences. They are a particular case of\nconditional independences that is true only for a certain assignment of its\nconditioning set, in contrast to conditional independences that must hold for\nall its assignments. In this work we present CSPC, an independence-based\nalgorithm for learning structures that encode context-specific independences,\nand encoding them in a log-linear model, instead of a graph. The central idea\nof CSPC is combining the theoretical guarantees provided by the\nindependence-based approach with the benefits of representing complex\nstructures by using features in a log-linear model. We present experiments in a\nsynthetic case, showing that CSPC is more accurate than the state-of-the-art IB\nalgorithms when the underlying distribution contains CSIs.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jul 2013 14:31:44 GMT"}], "update_date": "2013-07-16", "authors_parsed": [["Edera", "Alejandro", ""], ["Schl\u00fcter", "Federico", ""], ["Bromberg", "Facundo", ""]]}, {"id": "1307.4101", "submitter": "Jose Acacio de Barros", "authors": "J. Acacio de Barros", "title": "Decision Making for Inconsistent Expert Judgments Using Negative\n  Probabilities", "comments": "14 pages, revised version to appear in the Proceedings of the QI2013\n  (Quantum Interactions) conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.OT cs.AI math.ST quant-ph stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we provide a simple random-variable example of inconsistent\ninformation, and analyze it using three different approaches: Bayesian,\nquantum-like, and negative probabilities. We then show that, at least for this\nparticular example, both the Bayesian and the quantum-like approaches have less\nnormative power than the negative probabilities one.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jul 2013 20:53:57 GMT"}, {"version": "v2", "created": "Thu, 26 Sep 2013 03:47:47 GMT"}], "update_date": "2013-09-27", "authors_parsed": [["de Barros", "J. Acacio", ""]]}, {"id": "1307.4440", "submitter": "Ronald de Haan", "authors": "Ronald de Haan, Anna Roub\\'i\\v{c}kov\\'a, Stefan Szeider", "title": "Parameterized Complexity Results for Plan Reuse", "comments": "Proceedings of AAAI 2013, pp. 224-231, AAAI Press, 2013", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Planning is a notoriously difficult computational problem of high worst-case\ncomplexity. Researchers have been investing significant efforts to develop\nheuristics or restrictions to make planning practically feasible. Case-based\nplanning is a heuristic approach where one tries to reuse previous experience\nwhen solving similar problems in order to avoid some of the planning effort.\nPlan reuse may offer an interesting alternative to plan generation in some\nsettings.\n  We provide theoretical results that identify situations in which plan reuse\nis provably tractable. We perform our analysis in the framework of\nparameterized complexity, which supports a rigorous worst-case complexity\nanalysis that takes structural properties of the input into account in terms of\nparameters. A central notion of parameterized complexity is fixed-parameter\ntractability which extends the classical notion of polynomial-time tractability\nby utilizing the effect of structural properties of the problem input.\n  We draw a detailed map of the parameterized complexity landscape of several\nvariants of problems that arise in the context of case-based planning. In\nparticular, we consider the problem of reusing an existing plan, imposing\nvarious restrictions in terms of parameters, such as the number of steps that\ncan be added to the existing plan to turn it into a solution of the planning\ninstance at hand.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jul 2013 22:35:15 GMT"}], "update_date": "2013-07-18", "authors_parsed": [["de Haan", "Ronald", ""], ["Roub\u00ed\u010dkov\u00e1", "Anna", ""], ["Szeider", "Stefan", ""]]}, {"id": "1307.4479", "submitter": "EPTCS", "authors": "Dario Della Monica, Margherita Napoli, Mimmo Parente", "title": "Model checking coalitional games in shortage resource scenarios", "comments": "In Proceedings GandALF 2013, arXiv:1307.4162", "journal-ref": "EPTCS 119, 2013, pp. 240-255", "doi": "10.4204/EPTCS.119.20", "report-no": null, "categories": "cs.LO cs.AI cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Verification of multi-agents systems (MAS) has been recently studied taking\ninto account the need of expressing resource bounds. Several logics for\nspecifying properties of MAS have been presented in quite a variety of\nscenarios with bounded resources. In this paper, we study a different\nformalism, called Priced Resource-Bounded Alternating-time Temporal Logic\n(PRBATL), whose main novelty consists in moving the notion of resources from a\nsyntactic level (part of the formula) to a semantic one (part of the model).\nThis allows us to track the evolution of the resource availability along the\ncomputations and provides us with a formalisms capable to model a number of\nreal-world scenarios. Two relevant aspects are the notion of global\navailability of the resources on the market, that are shared by the agents, and\nthe notion of price of resources, depending on their availability. In a\nprevious work of ours, an initial step towards this new formalism was\nintroduced, along with an EXPTIME algorithm for the model checking problem. In\nthis paper we better analyze the features of the proposed formalism, also in\ncomparison with previous approaches. The main technical contribution is the\nproof of the EXPTIME-hardness of the the model checking problem for PRBATL,\nbased on a reduction from the acceptance problem for Linearly-Bounded\nAlternating Turing Machines. In particular, since the problem has multiple\nparameters, we show two fixed-parameter reductions.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jul 2013 01:43:23 GMT"}], "update_date": "2013-07-18", "authors_parsed": [["Della Monica", "Dario", ""], ["Napoli", "Margherita", ""], ["Parente", "Mimmo", ""]]}, {"id": "1307.4514", "submitter": "Aur\\'elien Bellet", "authors": "Aur\\'elien Bellet", "title": "Supervised Metric Learning with Generalization Guarantees", "comments": "PhD thesis defended on December 11, 2012 (Laboratoire Hubert Curien,\n  University of Saint-Etienne)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The crucial importance of metrics in machine learning algorithms has led to\nan increasing interest in optimizing distance and similarity functions, an area\nof research known as metric learning. When data consist of feature vectors, a\nlarge body of work has focused on learning a Mahalanobis distance. Less work\nhas been devoted to metric learning from structured objects (such as strings or\ntrees), most of it focusing on optimizing a notion of edit distance. We\nidentify two important limitations of current metric learning approaches.\nFirst, they allow to improve the performance of local algorithms such as\nk-nearest neighbors, but metric learning for global algorithms (such as linear\nclassifiers) has not been studied so far. Second, the question of the\ngeneralization ability of metric learning methods has been largely ignored. In\nthis thesis, we propose theoretical and algorithmic contributions that address\nthese limitations. Our first contribution is the derivation of a new kernel\nfunction built from learned edit probabilities. Our second contribution is a\nnovel framework for learning string and tree edit similarities inspired by the\nrecent theory of (e,g,t)-good similarity functions. Using uniform stability\narguments, we establish theoretical guarantees for the learned similarity that\ngive a bound on the generalization error of a linear classifier built from that\nsimilarity. In our third contribution, we extend these ideas to metric learning\nfrom feature vectors by proposing a bilinear similarity learning method that\nefficiently optimizes the (e,g,t)-goodness. Generalization guarantees are\nderived for our approach, highlighting that our method minimizes a tighter\nbound on the generalization error of the classifier. Our last contribution is a\nframework for establishing generalization bounds for a large class of existing\nmetric learning algorithms based on a notion of algorithmic robustness.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jul 2013 06:42:00 GMT"}, {"version": "v2", "created": "Tue, 23 Jul 2013 17:42:26 GMT"}], "update_date": "2019-01-25", "authors_parsed": [["Bellet", "Aur\u00e9lien", ""]]}, {"id": "1307.4689", "submitter": "Yuri Malitsky", "authors": "Giovanni Di Liberto and Serdar Kadioglu and Kevin Leo and Yuri\n  Malitsky", "title": "DASH: Dynamic Approach for Switching Heuristics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Complete tree search is a highly effective method for tackling MIP problems,\nand over the years, a plethora of branching heuristics have been introduced to\nfurther refine the technique for varying problems. Recently, portfolio\nalgorithms have taken the process a step further, trying to predict the best\nheuristic for each instance at hand. However, the motivation behind algorithm\nselection can be taken further still, and used to dynamically choose the most\nappropriate algorithm for each encountered subproblem. In this paper we\nidentify a feature space that captures both the evolution of the problem in the\nbranching tree and the similarity among subproblems of instances from the same\nMIP models. We show how to exploit these features to decide the best time to\nswitch the branching heuristic and then show how such a system can be trained\nefficiently. Experiments on a highly heterogeneous collection of MIP instances\nshow significant gains over the pure algorithm selection approach that for a\ngiven instance uses only a single heuristic throughout the search.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jul 2013 16:31:14 GMT"}], "update_date": "2013-07-19", "authors_parsed": [["Di Liberto", "Giovanni", ""], ["Kadioglu", "Serdar", ""], ["Leo", "Kevin", ""], ["Malitsky", "Yuri", ""]]}, {"id": "1307.4847", "submitter": "Zheng Wen", "authors": "Zheng Wen and Benjamin Van Roy", "title": "Efficient Reinforcement Learning in Deterministic Systems with Value\n  Function Generalization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of reinforcement learning over episodes of a\nfinite-horizon deterministic system and as a solution propose optimistic\nconstraint propagation (OCP), an algorithm designed to synthesize efficient\nexploration and value function generalization. We establish that when the true\nvalue function lies within a given hypothesis class, OCP selects optimal\nactions over all but at most K episodes, where K is the eluder dimension of the\ngiven hypothesis class. We establish further efficiency and asymptotic\nperformance guarantees that apply even if the true value function does not lie\nin the given hypothesis class, for the special case where the hypothesis class\nis the span of pre-specified indicator functions over disjoint sets. We also\ndiscuss the computational complexity of OCP and present computational results\ninvolving two illustrative examples.\n", "versions": [{"version": "v1", "created": "Thu, 18 Jul 2013 07:22:39 GMT"}, {"version": "v2", "created": "Tue, 1 Oct 2013 23:05:18 GMT"}, {"version": "v3", "created": "Sun, 8 May 2016 20:10:21 GMT"}, {"version": "v4", "created": "Wed, 6 Jul 2016 23:56:50 GMT"}], "update_date": "2016-07-08", "authors_parsed": [["Wen", "Zheng", ""], ["Van Roy", "Benjamin", ""]]}, {"id": "1307.5322", "submitter": "Emanuel Santos ES", "authors": "Emanuel Santos, Daniel Faria, C\\'atia Pesquita and Francisco Couto", "title": "Ontology alignment repair through modularization and confidence-based\n  heuristics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ontology Matching aims to find a set of semantic correspondences, called an\nalignment, between related ontologies. In recent years, there has been a\ngrowing interest in efficient and effective matching methods for large\nontologies. However, most of the alignments produced for large ontologies are\nlogically incoherent. It was only recently that the use of repair techniques to\nimprove the quality of ontology alignments has been explored. In this paper we\npresent a novel technique for detecting incoherent concepts based on ontology\nmodularization, and a new repair algorithm that minimizes the incoherence of\nthe resulting alignment and the number of matches removed from the input\nalignment. An implementation was done as part of a lightweight version of\nAgreementMaker system, a successful ontology matching platform, and evaluated\nusing a set of four benchmark biomedical ontology matching tasks. Our results\nshow that our implementation is efficient and produces better alignments with\nrespect to their coherence and f-measure than the state of the art repairing\ntools. They also show that our implementation is a better alternative for\nproducing coherent silver standard alignments.\n", "versions": [{"version": "v1", "created": "Fri, 19 Jul 2013 16:15:41 GMT"}], "update_date": "2013-07-23", "authors_parsed": [["Santos", "Emanuel", ""], ["Faria", "Daniel", ""], ["Pesquita", "C\u00e1tia", ""], ["Couto", "Francisco", ""]]}, {"id": "1307.5636", "submitter": "Marloes H. Maathuis", "authors": "Marloes H. Maathuis, Diego Colombo", "title": "A generalized back-door criterion", "comments": "Published at http://dx.doi.org/10.1214/14-AOS1295 in the Annals of\n  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2015, Vol. 43, No. 3, 1060-1088", "doi": "10.1214/14-AOS1295", "report-no": "IMS-AOS-AOS1295", "categories": "stat.ME cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We generalize Pearl's back-door criterion for directed acyclic graphs (DAGs)\nto more general types of graphs that describe Markov equivalence classes of\nDAGs and/or allow for arbitrarily many hidden variables. We also give easily\ncheckable necessary and sufficient graphical criteria for the existence of a\nset of variables that satisfies our generalized back-door criterion, when\nconsidering a single intervention and a single outcome variable. Moreover, if\nsuch a set exists, we provide an explicit set that fulfills the criterion. We\nillustrate the results in several examples. R-code is available in the\nR-package pcalg.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jul 2013 09:54:01 GMT"}, {"version": "v2", "created": "Mon, 7 Oct 2013 13:13:40 GMT"}, {"version": "v3", "created": "Wed, 3 Jun 2015 07:04:21 GMT"}], "update_date": "2015-06-04", "authors_parsed": [["Maathuis", "Marloes H.", ""], ["Colombo", "Diego", ""]]}, {"id": "1307.5713", "submitter": "Lucas Paletta", "authors": "Min Zhao, Andre G. Marquez", "title": "Understanding Humans' Strategies in Maze Solving", "comments": null, "journal-ref": null, "doi": null, "report-no": "ISACS/2013/06", "categories": "cs.CV cs.AI q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Navigating through a visual maze relies on the strategic use of eye movements\nto select and identify the route. When navigating the maze, there are\ntrade-offs between exploring to the environment and relying on memory. This\nstudy examined strategies used to navigating through novel and familiar mazes\nthat were viewed from above and traversed by a mouse cursor. Eye and mouse\nmovements revealed two modes that almost never occurred concurrently:\nexploration and guidance. Analyses showed that people learned mazes and were\nable to devise and carry out complex, multi-faceted strategies that traded-off\nvisual exploration against active motor performance. These strategies took into\naccount available visual information, memory, confidence, the estimated cost in\ntime for exploration, and idiosyncratic tolerance for error. Understanding the\nstrategies humans used for maze solving is valuable for applications in\ncognitive neuroscience as well as in AI, robotics and human-robot interactions.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jul 2013 13:57:10 GMT"}], "update_date": "2013-07-23", "authors_parsed": [["Zhao", "Min", ""], ["Marquez", "Andre G.", ""]]}, {"id": "1307.5837", "submitter": "Robert R. Tucci", "authors": "Robert R. Tucci", "title": "An Information Theoretic Measure of Judea Pearl's Identifiability and\n  Causal Influence", "comments": "54 pages(32 files: 1 .tex, 1 .sty,30 .eps)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.AI math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we define a new information theoretic measure that we call the\n\"uprooted information\". We show that a necessary and sufficient condition for a\nprobability $P(s|do(t))$ to be \"identifiable\" (in the sense of Pearl) in a\ngraph $G$ is that its uprooted information be non-negative for all models of\nthe graph $G$. In this paper, we also give a new algorithm for deciding, for a\nBayesian net that is semi-Markovian, whether a probability $P(s|do(t))$ is\nidentifiable, and, if it is identifiable, for expressing it without allusions\nto confounding variables. Our algorithm is closely based on a previous\nalgorithm by Tian and Pearl, but seems to correct a small flaw in theirs. In\nthis paper, we also find a {\\it necessary and sufficient graphical condition}\nfor a probability $P(s|do(t))$ to be identifiable when $t$ is a singleton set.\nSo far, in the prior literature, it appears that only a {\\it sufficient\ngraphical condition} has been given for this. By \"graphical\" we mean that it is\ndirectly based on Judea Pearl's 3 rules of do-calculus.\n", "versions": [{"version": "v1", "created": "Sun, 21 Jul 2013 21:47:26 GMT"}], "update_date": "2013-07-24", "authors_parsed": [["Tucci", "Robert R.", ""]]}, {"id": "1307.5910", "submitter": "A Idrissi", "authors": "Abdellah Idrissi", "title": "How to minimize the energy consumption in mobile ad-hoc networks", "comments": null, "journal-ref": "International Journal of Artificial Intelligence & Applications\n  (IJAIA), Vol.3, No.2, March 2012", "doi": "10.5121/ijaia.2012.3201", "report-no": null, "categories": "cs.AI cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we are interested in the problem of energy management in Mobile\nAd-hoc Network (MANET). The solving and optimization of MANET allow assisting\nthe users to efficiently use their devices in order to minimize the batteries\npower consumption. In this framework, we propose a modelling of the MANET in\nform of a Constraint Optimization Problem called COMANET. Then, in the\nobjective to minimize the consumption of batteries power, we present an\napproach based on an adaptation of the A star algorithm to the MANET problem\ncalled MANED. Finally, we expose some experimental results showing utility of\nthis approach.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jul 2013 23:56:38 GMT"}], "update_date": "2013-07-24", "authors_parsed": [["Idrissi", "Abdellah", ""]]}, {"id": "1307.6023", "submitter": "Najla Al-Saati", "authors": "Dr. Najla Akram AL-Saati and Marwa Abd-AlKareem", "title": "The Use of Cuckoo Search in Estimating the Parameters of Software\n  Reliability Growth Models", "comments": null, "journal-ref": "(IJCSIS) International Journal of Computer Science and Information\n  Security, Vol. 11, No. 6, June 2013", "doi": null, "report-no": null, "categories": "cs.AI cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work aims to investigate the reliability of software products as an\nimportant attribute of computer programs; it helps to decide the degree of\ntrustworthiness a program has in accomplishing its specific functions. This is\ndone using the Software Reliability Growth Models (SRGMs) through the\nestimation of their parameters. The parameters are estimated in this work based\non the available failure data and with the search techniques of Swarm\nIntelligence, namely, the Cuckoo Search (CS) due to its efficiency,\neffectiveness and robustness. A number of SRGMs is studied, and the results are\ncompared to Particle Swarm Optimization (PSO), Ant Colony Optimization (ACO)\nand extended ACO. Results show that CS outperformed both PSO and ACO in finding\nbetter parameters tested using identical datasets. It was sometimes\noutperformed by the extended ACO. Also in this work, the percentages of\ntraining data to testing data are investigated to show their impact on the\nresults.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jul 2013 11:22:31 GMT"}], "update_date": "2013-07-24", "authors_parsed": [["AL-Saati", "Dr. Najla Akram", ""], ["Abd-AlKareem", "Marwa", ""]]}, {"id": "1307.6291", "submitter": "Qixin Wang", "authors": "Xili Wang", "title": "A novel approach of solving the CNF-SAT problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we discussed CNF-SAT problem (NP-Complete problem) and\nanalysis two solutions that can solve the problem, the PL-Resolution algorithm\nand the WalkSAT algorithm. PL-Resolution is a sound and complete algorithm that\ncan be used to determine satisfiability and unsatisfiability with certainty.\nWalkSAT can determine satisfiability if it finds a model, but it cannot\nguarantee to find a model even there exists one. However, WalkSAT is much\nfaster than PL-Resolution, which makes WalkSAT more practical; and we have\nanalysis the performance between these two algorithms, and the performance of\nWalkSAT is acceptable if the problem is not so hard.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jul 2013 03:48:49 GMT"}], "update_date": "2013-07-25", "authors_parsed": [["Wang", "Xili", ""]]}, {"id": "1307.6365", "submitter": "Josif Grabocka", "authors": "Josif Grabocka, Martin Wistuba, Lars Schmidt-Thieme", "title": "Time-Series Classification Through Histograms of Symbolic Polynomials", "comments": null, "journal-ref": null, "doi": "10.1109/TKDE.2014.2377746", "report-no": null, "categories": "cs.AI cs.DB cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Time-series classification has attracted considerable research attention due\nto the various domains where time-series data are observed, ranging from\nmedicine to econometrics. Traditionally, the focus of time-series\nclassification has been on short time-series data composed of a unique pattern\nwith intraclass pattern distortions and variations, while recently there have\nbeen attempts to focus on longer series composed of various local patterns.\nThis study presents a novel method which can detect local patterns in long\ntime-series via fitting local polynomial functions of arbitrary degrees. The\ncoefficients of the polynomial functions are converted to symbolic words via\nequivolume discretizations of the coefficients' distributions. The symbolic\npolynomial words enable the detection of similar local patterns by assigning\nthe same words to similar polynomials. Moreover, a histogram of the frequencies\nof the words is constructed from each time-series' bag of words. Each row of\nthe histogram enables a new representation for the series and symbolize the\nexistence of local patterns and their frequencies. Experimental evidence\ndemonstrates outstanding results of our method compared to the state-of-art\nbaselines, by exhibiting the best classification accuracies in all the datasets\nand having statistically significant improvements in the absolute majority of\nexperiments.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jul 2013 10:07:50 GMT"}, {"version": "v2", "created": "Thu, 25 Jul 2013 03:40:27 GMT"}, {"version": "v3", "created": "Wed, 31 Jul 2013 10:58:02 GMT"}, {"version": "v4", "created": "Mon, 23 Dec 2013 22:26:35 GMT"}], "update_date": "2015-03-12", "authors_parsed": [["Grabocka", "Josif", ""], ["Wistuba", "Martin", ""], ["Schmidt-Thieme", "Lars", ""]]}, {"id": "1307.6883", "submitter": "Eug\\'enio Rodrigues", "authors": "Eug\\'enio Rodrigues (1), Ad\\'elio Rodrigues Gaspar (1) and \\'Alvaro\n  Gomes (2) ((1) ADAI-LAETA Department of Mechanical Engineering University of\n  Coimbra (2) INESCC Department of Electrical and Computer Engineering,\n  University of Coimbra)", "title": "A gradient descent technique coupled with a dynamic simulation to\n  determine the near optimum orientation of floor plan designs", "comments": "10 pages, 6 figures, conference paper; Proceedings of CLIMA 2013\n  16-19 June 2013 Prague Czech Republic (2013)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A prototype tool to assist architects during the early design stage of floor\nplans has been developed, consisting of an Evolutionary Program for the Space\nAllocation Problem (EPSAP), which generates sets of floor plan alternatives\naccording to the architect's preferences; and a Floor Plan Performance\nOptimization Program (FPOP), which optimizes the selected solutions according\nto thermal performance criteria. The design variables subject to optimization\nare window position and size, overhangs, fins, wall positioning, and building\norientation. A procedure using a transformation operator with gradient descent,\nsuch as behavior, coupled with a dynamic simulation engine was developed for\nthe thermal evaluation and optimization process. However, the need to evaluate\nall possible alternatives regarding designing variables being used during the\noptimization process leads to an intensive use of thermal simulation, which\ndramatically increases the simulation time, rendering it unpractical. An\nalternative approach is a smart optimization approach, which utilizes an\noriented and adaptive search technique to efficiently find the near optimum\nsolution. This paper presents the search methodology for the building\norientation of floor plan designs, and the corresponding efficiency and\neffectiveness indicators. The calculations are based on 100 floor plan designs\ngenerated by EPSAP. All floor plans have the same design program, location, and\nweather data, changing only their geometry. Dynamic simulation of buildings was\neffectively used together with the optimization procedure in this approach to\nsignificantly improve the designs. The use of the orientation variable has been\nincluded in the algorithm.\n", "versions": [{"version": "v1", "created": "Thu, 25 Jul 2013 21:24:53 GMT"}, {"version": "v2", "created": "Sun, 4 Aug 2013 16:37:33 GMT"}], "update_date": "2013-08-06", "authors_parsed": [["Rodrigues", "Eug\u00e9nio", ""], ["Gaspar", "Ad\u00e9lio Rodrigues", ""], ["Gomes", "\u00c1lvaro", ""]]}, {"id": "1307.7127", "submitter": "Piyush Ahuja", "authors": "Piyush Ahuja", "title": "Man and Machine: Questions of Risk, Trust and Accountability in Today's\n  AI Technology", "comments": "Preprint", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Artificial Intelligence began as a field probing some of the most fundamental\nquestions of science - the nature of intelligence and the design of intelligent\nartifacts. But it has grown into a discipline that is deeply entwined with\ncommerce and society. Today's AI technology, such as expert systems and\nintelligent assistants, pose some difficult questions of risk, trust and\naccountability. In this paper, we present these concerns, examining them in the\ncontext of historical developments that have shaped the nature and direction of\nAI research. We also suggest the exploration and further development of two\nparadigms, human intelligence-machine cooperation, and a sociological view of\nintelligence, which might help address some of these concerns.\n", "versions": [{"version": "v1", "created": "Fri, 26 Jul 2013 19:17:19 GMT"}], "update_date": "2013-07-29", "authors_parsed": [["Ahuja", "Piyush", ""]]}, {"id": "1307.7129", "submitter": "Naoyuki Nide", "authors": "Megumi Fujita, Yuki Goto, Naoyuki Nide, Ken Satoh, Hiroshi Hosobe", "title": "An Architecture for Autonomously Controlling Robot with Embodiment in\n  Real World", "comments": "Submission for proc. of KRR-ICLP2013 (resubmitted using LLNCS style)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the real world, robots with embodiment face various issues such as dynamic\ncontinuous changes of the environment and input/output disturbances. The key to\nsolving these issues can be found in daily life; people `do actions associated\nwith sensing' and `dynamically change their plans when necessary'. We propose\nthe use of a new concept, enabling robots to do these two things, for\nautonomously controlling mobile robots. We implemented our concept to make two\nexperiments under static/dynamic environments. The results of these experiments\nshow that our idea provides a way to adapt to dynamic changes of the\nenvironment in the real world.\n", "versions": [{"version": "v1", "created": "Fri, 26 Jul 2013 19:25:58 GMT"}], "update_date": "2013-07-29", "authors_parsed": [["Fujita", "Megumi", ""], ["Goto", "Yuki", ""], ["Nide", "Naoyuki", ""], ["Satoh", "Ken", ""], ["Hosobe", "Hiroshi", ""]]}, {"id": "1307.7198", "submitter": "Kenji Okuma", "authors": "Kenji Okuma and David G. Lowe and James J. Little", "title": "Self-Learning for Player Localization in Sports Video", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces a novel self-learning framework that automates the\nlabel acquisition process for improving models for detecting players in\nbroadcast footage of sports games. Unlike most previous self-learning\napproaches for improving appearance-based object detectors from videos, we\nallow an unknown, unconstrained number of target objects in a more generalized\nvideo sequence with non-static camera views. Our self-learning approach uses a\nlatent SVM learning algorithm and deformable part models to represent the shape\nand colour information of players, constraining their motions, and learns the\ncolour of the playing field by a gentle Adaboost algorithm. We combine those\nimage cues and discover additional labels automatically from unlabelled data.\nIn our experiments, our approach exploits both labelled and unlabelled data in\nsparsely labelled videos of sports games, providing a mean performance\nimprovement of over 20% in the average precision for detecting sports players\nand improved tracking, when videos contain very few labelled images.\n", "versions": [{"version": "v1", "created": "Sat, 27 Jul 2013 00:34:41 GMT"}], "update_date": "2013-07-30", "authors_parsed": [["Okuma", "Kenji", ""], ["Lowe", "David G.", ""], ["Little", "James J.", ""]]}, {"id": "1307.7303", "submitter": "Martin Mueller", "authors": "Martin E. Mueller and Madhura D. Thosar", "title": "Learning to Understand by Evolving Theories", "comments": "KRR Workshop at ICLP 2013", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we describe an approach that enables an autonomous system to\ninfer the semantics of a command (i.e. a symbol sequence representing an\naction) in terms of the relations between changes in the observations and the\naction instances. We present a method of how to induce a theory (i.e. a\nsemantic description) of the meaning of a command in terms of a minimal set of\nbackground knowledge. The only thing we have is a sequence of observations from\nwhich we extract what kinds of effects were caused by performing the command.\nThis way, we yield a description of the semantics of the action and, hence, a\ndefinition.\n", "versions": [{"version": "v1", "created": "Sat, 27 Jul 2013 20:33:34 GMT"}], "update_date": "2013-07-30", "authors_parsed": [["Mueller", "Martin E.", ""], ["Thosar", "Madhura D.", ""]]}, {"id": "1307.7351", "submitter": "Guglielmo Gemignani", "authors": "Emanuele Bastianelli, Domenico Bloisi, Roberto Capobianco, Guglielmo\n  Gemignani, Luca Iocchi, Daniele Nardi", "title": "Knowledge Representation for Robots through Human-Robot Interaction", "comments": "Knowledge Representation and Reasoning in Robotics Workshop at ICLP\n  2013", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The representation of the knowledge needed by a robot to perform complex\ntasks is restricted by the limitations of perception. One possible way of\novercoming this situation and designing \"knowledgeable\" robots is to rely on\nthe interaction with the user. We propose a multi-modal interaction framework\nthat allows to effectively acquire knowledge about the environment where the\nrobot operates. In particular, in this paper we present a rich representation\nframework that can be automatically built from the metric map annotated with\nthe indications provided by the user. Such a representation, allows then the\nrobot to ground complex referential expressions for motion commands and to\ndevise topological navigation plans to achieve the target locations.\n", "versions": [{"version": "v1", "created": "Sun, 28 Jul 2013 10:45:57 GMT"}, {"version": "v2", "created": "Thu, 1 Aug 2013 16:54:15 GMT"}], "update_date": "2013-08-02", "authors_parsed": [["Bastianelli", "Emanuele", ""], ["Bloisi", "Domenico", ""], ["Capobianco", "Roberto", ""], ["Gemignani", "Guglielmo", ""], ["Iocchi", "Luca", ""], ["Nardi", "Daniele", ""]]}, {"id": "1307.7398", "submitter": "Benjamin Andres", "authors": "Benjamin Andres, Philipp Obermeier, Orkunt Sabuncu, Torsten Schaub,\n  and David Rajaratnam", "title": "ROSoClingo: A ROS package for ASP-based robot control", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge representation and reasoning capacities are vital to cognitive\nrobotics because they provide higher level cognitive functions for reasoning\nabout actions, environments, goals, perception, etc. Although Answer Set\nProgramming (ASP) is well suited for modelling such functions, there was so far\nno seamless way to use ASP in a robotic environment. We address this\nshortcoming and show how a recently developed reactive ASP system can be\nharnessed to provide appropriate reasoning capacities within a robotic system.\nTo be more precise, we furnish a package integrating the reactive ASP solver\noClingo with the popular open-source robotic middleware ROS. The resulting\nsystem, ROSoClingo, provides a generic way by which an ASP program can be used\nto control the behaviour of a robot and to respond to the results of the\nrobot's actions.\n", "versions": [{"version": "v1", "created": "Sun, 28 Jul 2013 20:10:51 GMT"}], "update_date": "2013-07-30", "authors_parsed": [["Andres", "Benjamin", ""], ["Obermeier", "Philipp", ""], ["Sabuncu", "Orkunt", ""], ["Schaub", "Torsten", ""], ["Rajaratnam", "David", ""]]}, {"id": "1307.7405", "submitter": "Przemys{\\l}aw Wa{\\l}{\\ke}ga", "authors": "P. A. Wa{\\l}\\c{e}ga", "title": "Reasoning for Moving Blocks Problem: Formal Representation and\n  Implementation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The combined approach of the Qualitative Reasoning and Probabilistic\nFunctions for the knowledge representation is proposed. The method aims at\nrepresent uncertain, qualitative knowledge that is essential for the moving\nblocks task's execution. The attempt to formalize the commonsense knowledge is\nperformed with the Situation Calculus language for reasoning and robot's\nbeliefs representation. The method is implemented in the Prolog programming\nlanguage and tested for a specific simulated scenario. In most cases the\nimplementation enables us to solve a given task, i.e., move blocks to desired\npositions. The example of robot's reasoning and main parts of the implemented\nprogram's code are presented.\n", "versions": [{"version": "v1", "created": "Sun, 28 Jul 2013 21:14:29 GMT"}], "update_date": "2013-07-30", "authors_parsed": [["Wa\u0142\u0229ga", "P. A.", ""]]}, {"id": "1307.7461", "submitter": "Peter Sch\\\"uller", "authors": "Esra Erdem, Volkan Patoglu, Peter Sch\\\"uller", "title": "Levels of Integration between Low-Level Reasoning and Task Planning", "comments": "In Workshop on Knowledge Representation and Reasoning in Robotics\n  (KRR) (International Conference on Logic Programming (ICLP) 2013)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide a systematic analysis of levels of integration between discrete\nhigh-level reasoning and continuous low-level reasoning to address hybrid\nplanning problems in robotics. We identify four distinct strategies for such an\nintegration: (i) low-level checks are done for all possible cases in advance\nand then this information is used during plan generation, (ii) low-level checks\nare done exactly when they are needed during the search for a plan, (iii) first\nall plans are computed and then infeasible ones are filtered, and (iv) by means\nof replanning, after finding a plan, low-level checks identify whether it is\ninfeasible or not; if it is infeasible, a new plan is computed considering the\nresults of previous low- level checks. We perform experiments on hybrid\nplanning problems in robotic manipulation and legged locomotion domains\nconsidering these four methods of integration, as well as some of their\ncombinations. We analyze the usefulness of levels of integration in these\ndomains, both from the point of view of computational efficiency (in time and\nspace) and from the point of view of plan quality relative to its feasibility.\nWe discuss advantages and disadvantages of each strategy in the light of\nexperimental results and provide some guidelines on choosing proper strategies\nfor a given domain.\n", "versions": [{"version": "v1", "created": "Mon, 29 Jul 2013 05:07:57 GMT"}], "update_date": "2013-07-30", "authors_parsed": [["Erdem", "Esra", ""], ["Patoglu", "Volkan", ""], ["Sch\u00fcller", "Peter", ""]]}, {"id": "1307.7466", "submitter": "Damien Duff", "authors": "Damien Jade Duff and Esra Erdem and Volkan Patoglu", "title": "Integration of 3D Object Recognition and Planning for Robotic\n  Manipulation: A Preliminary Report", "comments": "Knowledge Representation and Reasoning in Robotics Workshop at ICLP\n  2013, Istanbul, Turkey", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CV cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate different approaches to integrating object recognition and\nplanning in a tabletop manipulation domain with the set of objects used in the\n2012 RoboCup@Work competition. Results of our preliminary experiments show\nthat, with some approaches, close integration of perception and planning\nimproves the quality of plans, as well as the computation times of feasible\nplans.\n", "versions": [{"version": "v1", "created": "Mon, 29 Jul 2013 05:40:49 GMT"}], "update_date": "2013-07-31", "authors_parsed": [["Duff", "Damien Jade", ""], ["Erdem", "Esra", ""], ["Patoglu", "Volkan", ""]]}, {"id": "1307.7494", "submitter": "Volkan Patoglu", "authors": "Zeynep Dogmus and Esra Erdem and Volkan Patoglu", "title": "ReAct! An Interactive Tool for Hybrid Planning in Robotics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present ReAct!, an interactive tool for high-level reasoning for cognitive\nrobotic applications. ReAct! enables robotic researchers to describe robots'\nactions and change in dynamic domains, without having to know about the\nsyntactic and semantic details of the underlying formalism in advance, and\nsolve planning problems using state-of-the-art automated reasoners, without\nhaving to learn about their input/output language or usage. In particular,\nReAct! can be used to represent sophisticated dynamic domains that feature\nconcurrency, indirect effects of actions, and state/transition constraints. It\nallows for embedding externally defined calculations (e.g., checking for\ncollision-free continuous trajectories) into representations of hybrid domains\nthat require a tight integration of (discrete) high-level reasoning with\n(continuous) geometric reasoning. ReAct! also enables users to solve planning\nproblems that involve complex goals. Such variety of utilities are useful for\nrobotic researchers to work on interesting and challenging domains, ranging\nfrom service robotics to cognitive factories. ReAct! provides sample\nformalizations of some action domains (e.g., multi-agent path planning, Tower\nof Hanoi), as well as dynamic simulations of plans computed by a\nstate-of-the-art automated reasoner (e.g., a SAT solver or an ASP solver).\n", "versions": [{"version": "v1", "created": "Mon, 29 Jul 2013 08:26:37 GMT"}], "update_date": "2013-07-30", "authors_parsed": [["Dogmus", "Zeynep", ""], ["Erdem", "Esra", ""], ["Patoglu", "Volkan", ""]]}, {"id": "1307.7720", "submitter": "Kartik Talamadupula", "authors": "Kartik Talamadupula and Subbarao Kambhampati", "title": "Herding the Crowd: Automated Planning for Crowdsourced Planning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There has been significant interest in crowdsourcing and human computation.\nOne subclass of human computation applications are those directed at tasks that\ninvolve planning (e.g. travel planning) and scheduling (e.g. conference\nscheduling). Much of this work appears outside the traditional automated\nplanning forums, and at the outset it is not clear whether automated planning\nhas much of a role to play in these human computation systems. Interestingly\nhowever, work on these systems shows that even primitive forms of automated\noversight of the human planner does help in significantly improving the\neffectiveness of the humans/crowd. In this paper, we will argue that the\nautomated oversight used in these systems can be viewed as a primitive\nautomated planner, and that there are several opportunities for more\nsophisticated automated planning in effectively steering crowdsourced planning.\nStraightforward adaptation of current planning technology is however hampered\nby the mismatch between the capabilities of human workers and automated\nplanners. We identify two important challenges that need to be overcome before\nsuch adaptation of planning technology can occur: (i) interpreting the inputs\nof the human workers (and the requester) and (ii) steering or critiquing the\nplans being produced by the human workers armed only with incomplete domain and\npreference models. In this paper, we discuss approaches for handling these\nchallenges, and characterize existing human computation systems in terms of the\nspecific choices they make in handling these challenges.\n", "versions": [{"version": "v1", "created": "Mon, 29 Jul 2013 20:02:03 GMT"}], "update_date": "2013-07-31", "authors_parsed": [["Talamadupula", "Kartik", ""], ["Kambhampati", "Subbarao", ""]]}, {"id": "1307.7793", "submitter": "Yongsub  Lim", "authors": "Yongsub Lim, Kyomin Jung, Pushmeet Kohli", "title": "Multi-dimensional Parametric Mincuts for Constrained MAP Inference", "comments": "19 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose novel algorithms for inferring the Maximum a\nPosteriori (MAP) solution of discrete pairwise random field models under\nmultiple constraints. We show how this constrained discrete optimization\nproblem can be formulated as a multi-dimensional parametric mincut problem via\nits Lagrangian dual, and prove that our algorithm isolates all constraint\ninstances for which the problem can be solved exactly. These multiple solutions\nenable us to even deal with `soft constraints' (higher order penalty\nfunctions). Moreover, we propose two practical variants of our algorithm to\nsolve problems with hard constraints. We also show how our method can be\napplied to solve various constrained discrete optimization problems such as\nsubmodular minimization and shortest path computation. Experimental evaluation\nusing the foreground-background image segmentation problem with statistic\nconstraints reveals that our method is faster and its results are closer to the\nground truth labellings compared with the popular continuous relaxation based\nmethods.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jul 2013 03:02:44 GMT"}], "update_date": "2013-08-02", "authors_parsed": [["Lim", "Yongsub", ""], ["Jung", "Kyomin", ""], ["Kohli", "Pushmeet", ""]]}, {"id": "1307.7808", "submitter": "Carlos Sarraute", "authors": "Carlos Sarraute (Instituto Tecnologico de Buenos Aires)", "title": "Automated Attack Planning", "comments": "PhD Thesis. 171 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CR", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  Penetration Testing is a methodology for assessing network security, by\ngenerating and executing possible attacks. Doing so automatically allows for\nregular and systematic testing. A key question then is how to automatically\ngenerate the attacks. A natural way to address this issue is as an attack\nplanning problem. In this thesis, we are concerned with the specific context of\nregular automated pentesting, and use the term \"attack planning\" in that sense.\nThe following three research directions are investigated.\n  First, we introduce a conceptual model of computer network attacks, based on\nan analysis of the penetration testing practices. We study how this attack\nmodel can be represented in the PDDL language. Then we describe an\nimplementation that integrates a classical planner with a penetration testing\ntool. This allows us to automatically generate attack paths for real world\npentesting scenarios, and to validate these attacks by executing them.\n  Secondly, we present efficient probabilistic planning algorithms,\nspecifically designed for this problem, that achieve industrial-scale runtime\nperformance (able to solve scenarios with several hundred hosts and exploits).\nThese algorithms take into account the probability of success of the actions\nand their expected cost (for example in terms of execution time, or network\ntraffic generated).\n  Finally, we take a different direction: instead of trying to improve the\nefficiency of the solutions developed, we focus on improving the model of the\nattacker. We model the attack planning problem in terms of partially observable\nMarkov decision processes (POMDP). This grounds penetration testing in a\nwell-researched formalism. POMDPs allow the modelling of information gathering\nas an integral part of the problem, thus providing for the first time a means\nto intelligently mix scanning actions with actual exploits.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jul 2013 04:19:25 GMT"}], "update_date": "2013-07-31", "authors_parsed": [["Sarraute", "Carlos", "", "Instituto Tecnologico de Buenos Aires"]]}, {"id": "1307.7809", "submitter": "Carlos Sarraute", "authors": "Carlos Sarraute (1 and 2), Olivier Buffet (3), Joerg Hoffmann (3) ((1)\n  Core Security Technologies, (2) ITBA (Instituto Tecnologico de Buenos Aires),\n  (3) INRIA)", "title": "Les POMDP font de meilleurs hackers: Tenir compte de l'incertitude dans\n  les tests de penetration", "comments": "JFPDA 2012 (7\\`emes Journ\\'ees Francophones Planification,\n  D\\'ecision, et Apprentissage pour la conduite de syst\\`emes), Nancy, France", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CR", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  Penetration Testing is a methodology for assessing network security, by\ngenerating and executing possible hacking attacks. Doing so automatically\nallows for regular and systematic testing. A key question is how to generate\nthe attacks. This is naturally formulated as planning under uncertainty, i.e.,\nunder incomplete knowledge about the network configuration. Previous work uses\nclassical planning, and requires costly pre-processes reducing this uncertainty\nby extensive application of scanning methods. By contrast, we herein model the\nattack planning problem in terms of partially observable Markov decision\nprocesses (POMDP). This allows to reason about the knowledge available, and to\nintelligently employ scanning actions as part of the attack. As one would\nexpect, this accurate solution does not scale. We devise a method that relies\non POMDPs to find good attacks on individual machines, which are then composed\ninto an attack on the network as a whole. This decomposition exploits network\nstructure to the extent possible, making targeted approximations (only) where\nneeded. Evaluating this method on a suitably adapted industrial test suite, we\ndemonstrate its effectiveness in both runtime and solution quality.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jul 2013 04:21:54 GMT"}], "update_date": "2013-07-31", "authors_parsed": [["Sarraute", "Carlos", "", "1 and 2"], ["Buffet", "Olivier", ""], ["Hoffmann", "Joerg", ""]]}, {"id": "1307.8049", "submitter": "Stefanie Jegelka", "authors": "Xinghao Pan, Joseph E. Gonzalez, Stefanie Jegelka, Tamara Broderick,\n  Michael I. Jordan", "title": "Optimistic Concurrency Control for Distributed Unsupervised Learning", "comments": "25 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Research on distributed machine learning algorithms has focused primarily on\none of two extremes - algorithms that obey strict concurrency constraints or\nalgorithms that obey few or no such constraints. We consider an intermediate\nalternative in which algorithms optimistically assume that conflicts are\nunlikely and if conflicts do arise a conflict-resolution protocol is invoked.\nWe view this \"optimistic concurrency control\" paradigm as particularly\nappropriate for large-scale machine learning algorithms, particularly in the\nunsupervised setting. We demonstrate our approach in three problem areas:\nclustering, feature learning and online facility location. We evaluate our\nmethods via large-scale experiments in a cluster computing environment.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jul 2013 17:07:58 GMT"}], "update_date": "2013-07-31", "authors_parsed": [["Pan", "Xinghao", ""], ["Gonzalez", "Joseph E.", ""], ["Jegelka", "Stefanie", ""], ["Broderick", "Tamara", ""], ["Jordan", "Michael I.", ""]]}, {"id": "1307.8084", "submitter": "Shiqi Zhang", "authors": "Shiqi Zhang and Mohan Sridharan", "title": "Combining Answer Set Programming and POMDPs for Knowledge Representation\n  and Reasoning on Mobile Robots", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For widespread deployment in domains characterized by partial observability,\nnon-deterministic actions and unforeseen changes, robots need to adapt sensing,\nprocessing and interaction with humans to the tasks at hand. While robots\ntypically cannot process all sensor inputs or operate without substantial\ndomain knowledge, it is a challenge to provide accurate domain knowledge and\nhumans may not have the time and expertise to provide elaborate and accurate\nfeedback. The architecture described in this paper combines declarative\nprogramming and probabilistic reasoning to address these challenges, enabling\nrobots to: (a) represent and reason with incomplete domain knowledge, resolving\nambiguities and revising existing knowledge using sensor inputs and minimal\nhuman feedback; and (b) probabilistically model the uncertainty in sensor input\nprocessing and navigation. Specifically, Answer Set Programming (ASP), a\ndeclarative programming paradigm, is combined with hierarchical partially\nobservable Markov decision processes (POMDPs), using domain knowledge to revise\nprobabilistic beliefs, and using positive and negative observations for early\ntermination of tasks that can no longer be pursued. All algorithms are\nevaluated in simulation and on mobile robots locating target objects in indoor\ndomains.\n", "versions": [{"version": "v1", "created": "Mon, 29 Jul 2013 18:55:00 GMT"}], "update_date": "2013-08-05", "authors_parsed": [["Zhang", "Shiqi", ""], ["Sridharan", "Mohan", ""]]}, {"id": "1307.8182", "submitter": "Carlos Sarraute", "authors": "Carlos Sarraute (1 and 2), Olivier Buffet (3), Joerg Hoffmann (4) ((1)\n  Core Security Technologies, (2) ITBA (Instituto Tecnologico de Buenos Aires),\n  (3) INRIA, (4) Saarland University)", "title": "POMDPs Make Better Hackers: Accounting for Uncertainty in Penetration\n  Testing", "comments": "Twenty-Sixth Conference on Artificial Intelligence (AAAI-12),\n  Toronto, Canada", "journal-ref": "Proceedings of AAAI Conference on Artificial Intelligence, pp\n  1816-1824, Toronto, Ontario, Canada (2012)", "doi": null, "report-no": null, "categories": "cs.AI cs.CR", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  Penetration Testing is a methodology for assessing network security, by\ngenerating and executing possible hacking attacks. Doing so automatically\nallows for regular and systematic testing. A key question is how to generate\nthe attacks. This is naturally formulated as planning under uncertainty, i.e.,\nunder incomplete knowledge about the network configuration. Previous work uses\nclassical planning, and requires costly pre-processes reducing this uncertainty\nby extensive application of scanning methods. By contrast, we herein model the\nattack planning problem in terms of partially observable Markov decision\nprocesses (POMDP). This allows to reason about the knowledge available, and to\nintelligently employ scanning actions as part of the attack. As one would\nexpect, this accurate solution does not scale. We devise a method that relies\non POMDPs to find good attacks on individual machines, which are then composed\ninto an attack on the network as a whole. This decomposition exploits network\nstructure to the extent possible, making targeted approximations (only) where\nneeded. Evaluating this method on a suitably adapted industrial test suite, we\ndemonstrate its effectiveness in both runtime and solution quality.\n", "versions": [{"version": "v1", "created": "Wed, 31 Jul 2013 01:03:00 GMT"}], "update_date": "2017-07-06", "authors_parsed": [["Sarraute", "Carlos", "", "1 and 2"], ["Buffet", "Olivier", ""], ["Hoffmann", "Joerg", ""]]}, {"id": "1307.8279", "submitter": "Alireza Rezvanian", "authors": "Somayeh Nabizadeh, Alireza Rezvanian, Mohammad Reza Meybodi", "title": "Tracking Extrema in Dynamic Environment using Multi-Swarm Cellular PSO\n  with Local Search", "comments": "8 pages, 3 figures", "journal-ref": "int j electron inform 1 (2012) 29-37", "doi": null, "report-no": null, "categories": "cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many real-world phenomena can be modelled as dynamic optimization problems.\nIn such cases, the environment problem changes dynamically and therefore,\nconventional methods are not capable of dealing with such problems. In this\npaper, a novel multi-swarm cellular particle swarm optimization algorithm is\nproposed by clustering and local search. In the proposed algorithm, the search\nspace is partitioned into cells, while the particles identify changes in the\nsearch space and form clusters to create sub-swarms. Then a local search is\napplied to improve the solutions in the each cell. Simulation results for\nstatic standard benchmarks and dynamic environments show superiority of the\nproposed method over other alternative approaches.\n", "versions": [{"version": "v1", "created": "Wed, 31 Jul 2013 10:57:47 GMT"}], "update_date": "2013-08-01", "authors_parsed": [["Nabizadeh", "Somayeh", ""], ["Rezvanian", "Alireza", ""], ["Meybodi", "Mohammad Reza", ""]]}]