[{"id": "1803.00091", "submitter": "Murat Cubuktepe", "authors": "Murat Cubuktepe and Ufuk Topcu", "title": "Verification of Markov Decision Processes with Risk-Sensitive Measures", "comments": "7 pages, to appear in ACC 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a method for computing policies in Markov decision processes with\nrisk-sensitive measures subject to temporal logic constraints. Specifically, we\nuse a particular risk-sensitive measure from cumulative prospect theory, which\nhas been previously adopted in psychology and economics. The nonlinear\ntransformation of the probabilities and utility functions yields a nonlinear\nprogramming problem, which makes computation of optimal policies typically\nchallenging. We show that this nonlinear weighting function can be accurately\napproximated by the difference of two convex functions. This observation\nenables efficient policy computation using convex-concave programming. We\ndemonstrate the effectiveness of the approach on several scenarios.\n", "versions": [{"version": "v1", "created": "Wed, 28 Feb 2018 21:14:37 GMT"}, {"version": "v2", "created": "Sun, 19 Apr 2020 22:11:10 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Cubuktepe", "Murat", ""], ["Topcu", "Ufuk", ""]]}, {"id": "1803.00094", "submitter": "Quynh Nguyen", "authors": "Quynh Nguyen, Mahesh Chandra Mukkamala, Matthias Hein", "title": "Neural Networks Should Be Wide Enough to Learn Disconnected Decision\n  Regions", "comments": "Accepted at ICML 2018. Added discussion for non-pyramidal networks\n  and ReLU activation function", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the recent literature the important role of depth in deep learning has\nbeen emphasized. In this paper we argue that sufficient width of a feedforward\nnetwork is equally important by answering the simple question under which\nconditions the decision regions of a neural network are connected. It turns out\nthat for a class of activation functions including leaky ReLU, neural networks\nhaving a pyramidal structure, that is no layer has more hidden units than the\ninput dimension, produce necessarily connected decision regions. This implies\nthat a sufficiently wide hidden layer is necessary to guarantee that the\nnetwork can produce disconnected decision regions. We discuss the implications\nof this result for the construction of neural networks, in particular the\nrelation to the problem of adversarial manipulation of classifiers.\n", "versions": [{"version": "v1", "created": "Wed, 28 Feb 2018 21:28:28 GMT"}, {"version": "v2", "created": "Wed, 6 Jun 2018 10:47:26 GMT"}, {"version": "v3", "created": "Fri, 8 Jun 2018 09:14:57 GMT"}], "update_date": "2018-06-11", "authors_parsed": [["Nguyen", "Quynh", ""], ["Mukkamala", "Mahesh Chandra", ""], ["Hein", "Matthias", ""]]}, {"id": "1803.00101", "submitter": "Vladimir Feinberg", "authors": "Vladimir Feinberg, Alvin Wan, Ion Stoica, Michael I. Jordan, Joseph E.\n  Gonzalez, Sergey Levine", "title": "Model-Based Value Estimation for Efficient Model-Free Reinforcement\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recent model-free reinforcement learning algorithms have proposed\nincorporating learned dynamics models as a source of additional data with the\nintention of reducing sample complexity. Such methods hold the promise of\nincorporating imagined data coupled with a notion of model uncertainty to\naccelerate the learning of continuous control tasks. Unfortunately, they rely\non heuristics that limit usage of the dynamics model. We present model-based\nvalue expansion, which controls for uncertainty in the model by only allowing\nimagination to fixed depth. By enabling wider use of learned dynamics models\nwithin a model-free reinforcement learning algorithm, we improve value\nestimation, which, in turn, reduces the sample complexity of learning.\n", "versions": [{"version": "v1", "created": "Wed, 28 Feb 2018 21:43:37 GMT"}], "update_date": "2018-03-02", "authors_parsed": [["Feinberg", "Vladimir", ""], ["Wan", "Alvin", ""], ["Stoica", "Ion", ""], ["Jordan", "Michael I.", ""], ["Gonzalez", "Joseph E.", ""], ["Levine", "Sergey", ""]]}, {"id": "1803.00116", "submitter": "Benito van der Zander", "authors": "Benito van der Zander (1), Maciej Li\\'skiewicz (1), Johannes Textor\n  (2) ((1) Institute for Theoretical Computer Science, Universit\\\"at zu\n  L\\\"ubeck, Germany, (2) Institute for Computing and Information Sciences,\n  Radboud University Nijmegen, Nijmegen, The Netherlands)", "title": "Separators and Adjustment Sets in Causal Graphs: Complete Criteria and\n  an Algorithmic Framework", "comments": "52 pages, 20 figures, 12 tables", "journal-ref": "Artificial Intelligence 270 (2019) 1-40", "doi": "10.1016/j.artint.2018.12.006", "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Principled reasoning about the identifiability of causal effects from\nnon-experimental data is an important application of graphical causal models.\nThis paper focuses on effects that are identifiable by covariate adjustment, a\ncommonly used estimation approach. We present an algorithmic framework for\nefficiently testing, constructing, and enumerating $m$-separators in ancestral\ngraphs (AGs), a class of graphical causal models that can represent uncertainty\nabout the presence of latent confounders. Furthermore, we prove a reduction\nfrom causal effect identification by covariate adjustment to $m$-separation in\na subgraph for directed acyclic graphs (DAGs) and maximal ancestral graphs\n(MAGs). Jointly, these results yield constructive criteria that characterize\nall adjustment sets as well as all minimal and minimum adjustment sets for\nidentification of a desired causal effect with multivariate exposures and\noutcomes in the presence of latent confounding. Our results extend several\nexisting solutions for special cases of these problems. Our efficient\nalgorithms allowed us to empirically quantify the identifiability gap between\ncovariate adjustment and the do-calculus in random DAGs and MAGs, covering a\nwide range of scenarios. Implementations of our algorithms are provided in the\nR package dagitty.\n", "versions": [{"version": "v1", "created": "Wed, 28 Feb 2018 22:28:08 GMT"}, {"version": "v2", "created": "Fri, 2 Mar 2018 15:42:44 GMT"}, {"version": "v3", "created": "Thu, 24 Jan 2019 16:33:53 GMT"}], "update_date": "2019-01-25", "authors_parsed": [["van der Zander", "Benito", ""], ["Li\u015bkiewicz", "Maciej", ""], ["Textor", "Johannes", ""]]}, {"id": "1803.00119", "submitter": "Rohan Chitnis", "authors": "Rohan Chitnis, Leslie Pack Kaelbling, and Tom\\'as Lozano-P\\'erez", "title": "Integrating Human-Provided Information Into Belief State Representation\n  Using Dynamic Factorization", "comments": "IROS 2018 final version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In partially observed environments, it can be useful for a human to provide\nthe robot with declarative information that represents probabilistic relational\nconstraints on properties of objects in the world, augmenting the robot's\nsensory observations. For instance, a robot tasked with a search-and-rescue\nmission may be informed by the human that two victims are probably in the same\nroom. An important question arises: how should we represent the robot's\ninternal knowledge so that this information is correctly processed and combined\nwith raw sensory information? In this paper, we provide an efficient belief\nstate representation that dynamically selects an appropriate factoring,\ncombining aspects of the belief when they are correlated through information\nand separating them when they are not. This strategy works in open domains, in\nwhich the set of possible objects is not known in advance, and provides\nsignificant improvements in inference time over a static factoring, leading to\nmore efficient planning for complex partially observed tasks. We validate our\napproach experimentally in two open-domain planning problems: a 2D discrete\ngridworld task and a 3D continuous cooking task. A supplementary video can be\nfound at http://tinyurl.com/chitnis-iros-18.\n", "versions": [{"version": "v1", "created": "Wed, 28 Feb 2018 22:29:29 GMT"}, {"version": "v2", "created": "Fri, 15 Jun 2018 19:29:13 GMT"}, {"version": "v3", "created": "Tue, 26 Jun 2018 16:47:23 GMT"}, {"version": "v4", "created": "Mon, 30 Jul 2018 13:46:48 GMT"}], "update_date": "2018-07-31", "authors_parsed": [["Chitnis", "Rohan", ""], ["Kaelbling", "Leslie Pack", ""], ["Lozano-P\u00e9rez", "Tom\u00e1s", ""]]}, {"id": "1803.00144", "submitter": "Trieu Trinh", "authors": "Trieu H. Trinh, Andrew M. Dai, Minh-Thang Luong, Quoc V. Le", "title": "Learning Longer-term Dependencies in RNNs with Auxiliary Losses", "comments": "ICML 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite recent advances in training recurrent neural networks (RNNs),\ncapturing long-term dependencies in sequences remains a fundamental challenge.\nMost approaches use backpropagation through time (BPTT), which is difficult to\nscale to very long sequences. This paper proposes a simple method that improves\nthe ability to capture long term dependencies in RNNs by adding an unsupervised\nauxiliary loss to the original objective. This auxiliary loss forces RNNs to\neither reconstruct previous events or predict next events in a sequence, making\ntruncated backpropagation feasible for long sequences and also improving full\nBPTT. We evaluate our method on a variety of settings, including pixel-by-pixel\nimage classification with sequence lengths up to 16\\,000, and a real document\nclassification benchmark. Our results highlight good performance and resource\nefficiency of this approach over competitive baselines, including other\nrecurrent models and a comparable sized Transformer. Further analyses reveal\nbeneficial effects of the auxiliary loss on optimization and regularization, as\nwell as extreme cases where there is little to no backpropagation.\n", "versions": [{"version": "v1", "created": "Thu, 1 Mar 2018 00:28:07 GMT"}, {"version": "v2", "created": "Fri, 1 Jun 2018 17:49:15 GMT"}, {"version": "v3", "created": "Wed, 13 Jun 2018 08:35:57 GMT"}], "update_date": "2018-06-14", "authors_parsed": [["Trinh", "Trieu H.", ""], ["Dai", "Andrew M.", ""], ["Luong", "Minh-Thang", ""], ["Le", "Quoc V.", ""]]}, {"id": "1803.00158", "submitter": "Guihua Wen", "authors": "Li Huihui and Wen Guihua", "title": "Modeling reverse thinking for machine learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Human inertial thinking schemes can be formed through learning, which are\nthen applied to quickly solve similar problems later. However, when problems\nare significantly different, inertial thinking generally presents the solutions\nthat are definitely imperfect. In such cases, people will apply creative\nthinking, such as reverse thinking, to solve problems. Similarly, machine\nlearning methods also form inertial thinking schemes through learning the\nknowledge from a large amount of data. However, when the testing data are\nvastly difference, the formed inertial thinking schemes will inevitably\ngenerate errors. This kind of inertial thinking is called illusion inertial\nthinking. Because all machine learning methods do not consider illusion\ninertial thinking, in this paper we propose a new method that uses reverse\nthinking to correct illusion inertial thinking, which increases the\ngeneralization ability of machine learning methods. Experimental results on\nbenchmark datasets are used to validate the proposed method.\n", "versions": [{"version": "v1", "created": "Thu, 1 Mar 2018 01:45:30 GMT"}], "update_date": "2018-03-02", "authors_parsed": [["Huihui", "Li", ""], ["Guihua", "Wen", ""]]}, {"id": "1803.00162", "submitter": "Weixun Wang", "authors": "Weixun Wang, Jianye Hao, Yixi Wang, Matthew Taylor", "title": "Towards Cooperation in Sequential Prisoner's Dilemmas: a Deep Multiagent\n  Reinforcement Learning Approach", "comments": "13 pages, 21 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.GT cs.LG cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Iterated Prisoner's Dilemma has guided research on social dilemmas for\ndecades. However, it distinguishes between only two atomic actions: cooperate\nand defect. In real-world prisoner's dilemmas, these choices are temporally\nextended and different strategies may correspond to sequences of actions,\nreflecting grades of cooperation. We introduce a Sequential Prisoner's Dilemma\n(SPD) game to better capture the aforementioned characteristics. In this work,\nwe propose a deep multiagent reinforcement learning approach that investigates\nthe evolution of mutual cooperation in SPD games. Our approach consists of two\nphases. The first phase is offline: it synthesizes policies with different\ncooperation degrees and then trains a cooperation degree detection network. The\nsecond phase is online: an agent adaptively selects its policy based on the\ndetected degree of opponent cooperation. The effectiveness of our approach is\ndemonstrated in two representative SPD 2D games: the Apple-Pear game and the\nFruit Gathering game. Experimental results show that our strategy can avoid\nbeing exploited by exploitative opponents and achieve cooperation with\ncooperative opponents.\n", "versions": [{"version": "v1", "created": "Thu, 1 Mar 2018 01:53:52 GMT"}], "update_date": "2018-03-02", "authors_parsed": [["Wang", "Weixun", ""], ["Hao", "Jianye", ""], ["Wang", "Yixi", ""], ["Taylor", "Matthew", ""]]}, {"id": "1803.00185", "submitter": "Yang Hu Dr.", "authors": "Tianyuan Chang, Guihua Wen, Yang Hu, JiaJiong Ma", "title": "Facial Expression Recognition Based on Complexity Perception\n  Classification Algorithm", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Facial expression recognition (FER) has always been a challenging issue in\ncomputer vision. The different expressions of emotion and uncontrolled\nenvironmental factors lead to inconsistencies in the complexity of FER and\nvariability of between expression categories, which is often overlooked in most\nfacial expression recognition systems. In order to solve this problem\neffectively, we presented a simple and efficient CNN model to extract facial\nfeatures, and proposed a complexity perception classification (CPC) algorithm\nfor FER. The CPC algorithm divided the dataset into an easy classification\nsample subspace and a complex classification sample subspace by evaluating the\ncomplexity of facial features that are suitable for classification. The\nexperimental results of our proposed algorithm on Fer2013 and CK-plus datasets\ndemonstrated the algorithm's effectiveness and superiority over other\nstate-of-the-art approaches.\n", "versions": [{"version": "v1", "created": "Thu, 1 Mar 2018 03:05:50 GMT"}], "update_date": "2018-03-02", "authors_parsed": [["Chang", "Tianyuan", ""], ["Wen", "Guihua", ""], ["Hu", "Yang", ""], ["Ma", "JiaJiong", ""]]}, {"id": "1803.00196", "submitter": "Roberto Calandra", "authors": "Brian Yang, Grant Wang, Roberto Calandra, Daniel Contreras, Sergey\n  Levine and Kristofer Pister", "title": "Learning Flexible and Reusable Locomotion Primitives for a Microrobot", "comments": "8 pages. Accepted at RAL+ICRA2018", "journal-ref": null, "doi": "10.1109/LRA.2018.2806083", "report-no": null, "categories": "cs.RO cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The design of gaits for robot locomotion can be a daunting process which\nrequires significant expert knowledge and engineering. This process is even\nmore challenging for robots that do not have an accurate physical model, such\nas compliant or micro-scale robots. Data-driven gait optimization provides an\nautomated alternative to analytical gait design. In this paper, we propose a\nnovel approach to efficiently learn a wide range of locomotion tasks with\nwalking robots. This approach formalizes locomotion as a contextual policy\nsearch task to collect data, and subsequently uses that data to learn\nmulti-objective locomotion primitives that can be used for planning. As a\nproof-of-concept we consider a simulated hexapod modeled after a recently\ndeveloped microrobot, and we thoroughly evaluate the performance of this\nmicrorobot on different tasks and gaits. Our results validate the proposed\ncontroller and learning scheme on single and multi-objective locomotion tasks.\nMoreover, the experimental simulations show that without any prior knowledge\nabout the robot used (e.g., dynamics model), our approach is capable of\nlearning locomotion primitives within 250 trials and subsequently using them to\nsuccessfully navigate through a maze.\n", "versions": [{"version": "v1", "created": "Thu, 1 Mar 2018 03:48:06 GMT"}], "update_date": "2018-03-02", "authors_parsed": [["Yang", "Brian", ""], ["Wang", "Grant", ""], ["Calandra", "Roberto", ""], ["Contreras", "Daniel", ""], ["Levine", "Sergey", ""], ["Pister", "Kristofer", ""]]}, {"id": "1803.00204", "submitter": "Chen Wang", "authors": "Chen Wang, Xiaomei Yang, Shaomin Fei, Kai Zhou, Xiaofeng Gong, Miao\n  Du, Ruisen Luo", "title": "Scalar Quantization as Sparse Least Square Optimization", "comments": null, "journal-ref": "IEEE Transactions on Pattern Analysis and Machine Intelligence,\n  2019", "doi": "10.1109/TPAMI.2019.2952096", "report-no": null, "categories": "cs.LG cs.AI cs.NA stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Quantization can be used to form new vectors/matrices with shared values\nclose to the original. In recent years, the popularity of scalar quantization\nfor value-sharing applications has been soaring as it has been found huge\nutilities in reducing the complexity of neural networks. Existing\nclustering-based quantization techniques, while being well-developed, have\nmultiple drawbacks including the dependency of the random seed, empty or\nout-of-the-range clusters, and high time complexity for a large number of\nclusters. To overcome these problems, in this paper, the problem of scalar\nquantization is examined from a new perspective, namely sparse least square\noptimization. Specifically, inspired by the property of sparse least square\nregression, several quantization algorithms based on $l_1$ least square are\nproposed. In addition, similar schemes with $l_1 + l_2$ and $l_0$\nregularization are proposed. Furthermore, to compute quantization results with\na given amount of values/clusters, this paper designed an iterative method and\na clustering-based method, and both of them are built on sparse least square.\nThe paper shows that the latter method is mathematically equivalent to an\nimproved version of k-means clustering-based quantization algorithm, although\nthe two algorithms originated from different intuitions. The algorithms\nproposed were tested with three types of data and their computational\nperformances, including information loss, time consumption, and the\ndistribution of the values of the sparse vectors, were compared and analyzed.\nThe paper offers a new perspective to probe the area of quantization, and the\nalgorithms proposed can outperform existing methods especially under some\nbit-width reduction scenarios, when the required post-quantization resolution\n(number of values) is not significantly lower than the original number.\n", "versions": [{"version": "v1", "created": "Thu, 1 Mar 2018 04:07:40 GMT"}, {"version": "v2", "created": "Mon, 24 Sep 2018 16:24:26 GMT"}, {"version": "v3", "created": "Wed, 25 Sep 2019 17:32:25 GMT"}, {"version": "v4", "created": "Wed, 6 Nov 2019 04:12:41 GMT"}], "update_date": "2019-12-11", "authors_parsed": [["Wang", "Chen", ""], ["Yang", "Xiaomei", ""], ["Fei", "Shaomin", ""], ["Zhou", "Kai", ""], ["Gong", "Xiaofeng", ""], ["Du", "Miao", ""], ["Luo", "Ruisen", ""]]}, {"id": "1803.00219", "submitter": "Yang Hu Dr.", "authors": "Jiajiong Ma, Guihua Wen, Yang Hu, Tianyuan Chang, Haibin Zeng, Lijun\n  Jiang, Jianzeng Qin", "title": "Tongue image constitution recognition based on Complexity Perception\n  method", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Background and Object: In China, body constitution is highly related to\nphysiological and pathological functions of human body and determines the\ntendency of the disease, which is of great importance for treatment in clinical\nmedicine. Tongue diagnosis, as a key part of Traditional Chinese Medicine\ninspection, is an important way to recognize the type of constitution.In order\nto deploy tongue image constitution recognition system on non-invasive mobile\ndevice to achieve fast, efficient and accurate constitution recognition, an\nefficient method is required to deal with the challenge of this kind of complex\nenvironment. Methods: In this work, we perform the tongue area detection,\ntongue area calibration and constitution classification using methods which are\nbased on deep convolutional neural network. Subject to the variation of\ninconstant environmental condition, the distribution of the picture is uneven,\nwhich has a bad effect on classification performance. To solve this problem, we\npropose a method based on the complexity of individual instances to divide\ndataset into two subsets and classify them separately, which is capable of\nimproving classification accuracy. To evaluate the performance of our proposed\nmethod, we conduct experiments on three sizes of tongue datasets, in which deep\nconvolutional neural network method and traditional digital image analysis\nmethod are respectively applied to extract features for tongue images. The\nproposed method is combined with the base classifier Softmax, SVM, and\nDecisionTree respectively. Results: As the experiments results shown, our\nproposed method improves the classification accuracy by 1.135% on average and\nachieves 59.99% constitution classification accuracy. Conclusions: Experimental\nresults on three datasets show that our proposed method can effectively improve\nthe classification accuracy of tongue constitution recognition.\n", "versions": [{"version": "v1", "created": "Thu, 1 Mar 2018 05:32:43 GMT"}], "update_date": "2018-03-02", "authors_parsed": [["Ma", "Jiajiong", ""], ["Wen", "Guihua", ""], ["Hu", "Yang", ""], ["Chang", "Tianyuan", ""], ["Zeng", "Haibin", ""], ["Jiang", "Lijun", ""], ["Qin", "Jianzeng", ""]]}, {"id": "1803.00259", "submitter": "Jun Zhao", "authors": "Jun Zhao, Guang Qiu, Ziyu Guan, Wei Zhao, Xiaofei He", "title": "Deep Reinforcement Learning for Sponsored Search Real-time Bidding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bidding optimization is one of the most critical problems in online\nadvertising. Sponsored search (SS) auction, due to the randomness of user query\nbehavior and platform nature, usually adopts keyword-level bidding strategies.\nIn contrast, the display advertising (DA), as a relatively simpler scenario for\nauction, has taken advantage of real-time bidding (RTB) to boost the\nperformance for advertisers. In this paper, we consider the RTB problem in\nsponsored search auction, named SS-RTB. SS-RTB has a much more complex dynamic\nenvironment, due to stochastic user query behavior and more complex bidding\npolicies based on multiple keywords of an ad. Most previous methods for DA\ncannot be applied. We propose a reinforcement learning (RL) solution for\nhandling the complex dynamic environment. Although some RL methods have been\nproposed for online advertising, they all fail to address the \"environment\nchanging\" problem: the state transition probabilities vary between two days.\nMotivated by the observation that auction sequences of two days share similar\ntransition patterns at a proper aggregation level, we formulate a robust MDP\nmodel at hour-aggregation level of the auction data and propose a\ncontrol-by-model framework for SS-RTB. Rather than generating bid prices\ndirectly, we decide a bidding model for impressions of each hour and perform\nreal-time bidding accordingly. We also extend the method to handle the\nmulti-agent problem. We deployed the SS-RTB system in the e-commerce search\nauction platform of Alibaba. Empirical experiments of offline evaluation and\nonline A/B test demonstrate the effectiveness of our method.\n", "versions": [{"version": "v1", "created": "Thu, 1 Mar 2018 09:04:37 GMT"}], "update_date": "2018-03-02", "authors_parsed": [["Zhao", "Jun", ""], ["Qiu", "Guang", ""], ["Guan", "Ziyu", ""], ["Zhao", "Wei", ""], ["He", "Xiaofei", ""]]}, {"id": "1803.00268", "submitter": "Thibaut Kulak", "authors": "Thibaut Kulak and Michael Garcia Ortiz", "title": "Representation Learning in Partially Observable Environments using\n  Sensorimotor Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In order to explore and act autonomously in an environment, an agent needs to\nlearn from the sensorimotor information that is captured while acting. By\nextracting the regularities in this sensorimotor stream, it can learn a model\nof the world, which in turn can be used as a basis for action and exploration.\n  This requires the acquisition of compact representations from a possibly high\ndimensional raw observation, which is noisy and ambiguous. In this paper, we\nlearn sensory representations from sensorimotor prediction. We propose a model\nwhich integrates sensorimotor information over time, and project it in a\nsensory representation which is useful for prediction. We emphasize on a simple\nexample the role of motor and memory for learning sensory representations.\n", "versions": [{"version": "v1", "created": "Thu, 1 Mar 2018 09:28:56 GMT"}, {"version": "v2", "created": "Thu, 26 Apr 2018 06:26:19 GMT"}], "update_date": "2018-04-27", "authors_parsed": [["Kulak", "Thibaut", ""], ["Ortiz", "Michael Garcia", ""]]}, {"id": "1803.00297", "submitter": "Francesco Riccio Mr.", "authors": "Francesco Riccio and Roberto Capobianco and Daniele Nardi", "title": "Q-CP: Learning Action Values for Cooperative Planning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Research on multi-robot systems has demonstrated promising results in\nmanifold applications and domains. Still, efficiently learning an effective\nrobot behaviors is very difficult, due to unstructured scenarios, high\nuncertainties, and large state dimensionality (e.g. hyper-redundant and groups\nof robot). To alleviate this problem, we present Q-CP a cooperative model-based\nreinforcement learning algorithm, which exploits action values to both (1)\nguide the exploration of the state space and (2) generate effective policies.\nSpecifically, we exploit Q-learning to attack the curse-of-dimensionality in\nthe iterations of a Monte-Carlo Tree Search. We implement and evaluate Q-CP on\ndifferent stochastic cooperative (general-sum) games: (1) a simple cooperative\nnavigation problem among 3 robots, (2) a cooperation scenario between a pair of\nKUKA YouBots performing hand-overs, and (3) a coordination task between two\nmobile robots entering a door. The obtained results show the effectiveness of\nQ-CP in the chosen applications, where action values drive the exploration and\nreduce the computational demand of the planning process while achieving good\nperformance.\n", "versions": [{"version": "v1", "created": "Thu, 1 Mar 2018 10:53:04 GMT"}], "update_date": "2018-03-02", "authors_parsed": [["Riccio", "Francesco", ""], ["Capobianco", "Roberto", ""], ["Nardi", "Daniele", ""]]}, {"id": "1803.00344", "submitter": "Gangeshwar Krishnamurthy", "authors": "Gangeshwar Krishnamurthy, Navonil Majumder, Soujanya Poria, Erik\n  Cambria", "title": "A Deep Learning Approach for Multimodal Deception Detection", "comments": "Accepted at the 19th International Conference on Computational\n  Linguistics and Intelligent Text Processing (CICLing), 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic deception detection is an important task that has gained momentum\nin computational linguistics due to its potential applications. In this paper,\nwe propose a simple yet tough to beat multi-modal neural model for deception\ndetection. By combining features from different modalities such as video,\naudio, and text along with Micro-Expression features, we show that detecting\ndeception in real life videos can be more accurate. Experimental results on a\ndataset of real-life deception videos show that our model outperforms existing\ntechniques for deception detection with an accuracy of 96.14% and ROC-AUC of\n0.9799.\n", "versions": [{"version": "v1", "created": "Thu, 1 Mar 2018 12:38:13 GMT"}], "update_date": "2018-03-21", "authors_parsed": [["Krishnamurthy", "Gangeshwar", ""], ["Majumder", "Navonil", ""], ["Poria", "Soujanya", ""], ["Cambria", "Erik", ""]]}, {"id": "1803.00444", "submitter": "Adrian \\v{S}o\\v{s}i\\'c", "authors": "Adrian \\v{S}o\\v{s}i\\'c, Elmar Rueckert, Jan Peters, Abdelhak M.\n  Zoubir, Heinz Koeppl", "title": "Inverse Reinforcement Learning via Nonparametric Spatio-Temporal Subgoal\n  Modeling", "comments": "45 pages, 14 figures; ### Version 3 ### published in the Journal of\n  Machine Learning Research", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO cs.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Advances in the field of inverse reinforcement learning (IRL) have led to\nsophisticated inference frameworks that relax the original modeling assumption\nof observing an agent behavior that reflects only a single intention. Instead\nof learning a global behavioral model, recent IRL methods divide the\ndemonstration data into parts, to account for the fact that different\ntrajectories may correspond to different intentions, e.g., because they were\ngenerated by different domain experts. In this work, we go one step further:\nusing the intuitive concept of subgoals, we build upon the premise that even a\nsingle trajectory can be explained more efficiently locally within a certain\ncontext than globally, enabling a more compact representation of the observed\nbehavior. Based on this assumption, we build an implicit intentional model of\nthe agent's goals to forecast its behavior in unobserved situations. The result\nis an integrated Bayesian prediction framework that significantly outperforms\nexisting IRL solutions and provides smooth policy estimates consistent with the\nexpert's plan. Most notably, our framework naturally handles situations where\nthe intentions of the agent change over time and classical IRL algorithms fail.\nIn addition, due to its probabilistic nature, the model can be\nstraightforwardly applied in active learning scenarios to guide the\ndemonstration process of the expert.\n", "versions": [{"version": "v1", "created": "Thu, 1 Mar 2018 15:31:28 GMT"}, {"version": "v2", "created": "Thu, 4 Oct 2018 16:30:20 GMT"}, {"version": "v3", "created": "Fri, 30 Nov 2018 10:52:08 GMT"}], "update_date": "2018-12-03", "authors_parsed": [["\u0160o\u0161i\u0107", "Adrian", ""], ["Rueckert", "Elmar", ""], ["Peters", "Jan", ""], ["Zoubir", "Abdelhak M.", ""], ["Koeppl", "Heinz", ""]]}, {"id": "1803.00512", "submitter": "Adam Lerer", "authors": "Amy Zhang, Adam Lerer, Sainbayar Sukhbaatar, Rob Fergus, Arthur Szlam", "title": "Composable Planning with Attributes", "comments": null, "journal-ref": "International Conference on Machine Learning, 2018", "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The tasks that an agent will need to solve often are not known during\ntraining. However, if the agent knows which properties of the environment are\nimportant then, after learning how its actions affect those properties, it may\nbe able to use this knowledge to solve complex tasks without training\nspecifically for them. Towards this end, we consider a setup in which an\nenvironment is augmented with a set of user defined attributes that\nparameterize the features of interest. We propose a method that learns a policy\nfor transitioning between \"nearby\" sets of attributes, and maintains a graph of\npossible transitions. Given a task at test time that can be expressed in terms\nof a target set of attributes, and a current state, our model infers the\nattributes of the current state and searches over paths through attribute space\nto get a high level plan, and then uses its low level policy to execute the\nplan. We show in 3D block stacking, grid-world games, and StarCraft that our\nmodel is able to generalize to longer, more complex tasks at test time by\ncomposing simpler learned policies.\n", "versions": [{"version": "v1", "created": "Thu, 1 Mar 2018 17:21:03 GMT"}, {"version": "v2", "created": "Thu, 25 Apr 2019 20:14:27 GMT"}], "update_date": "2019-04-29", "authors_parsed": [["Zhang", "Amy", ""], ["Lerer", "Adam", ""], ["Sukhbaatar", "Sainbayar", ""], ["Fergus", "Rob", ""], ["Szlam", "Arthur", ""]]}, {"id": "1803.00546", "submitter": "Evangelos Michelioudakis", "authors": "Evangelos Michelioudakis and Alexander Artikis and Georgios Paliouras", "title": "Semi-Supervised Online Structure Learning for Composite Event\n  Recognition", "comments": null, "journal-ref": null, "doi": "10.1007/s10994-019-05780-8", "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Online structure learning approaches, such as those stemming from Statistical\nRelational Learning, enable the discovery of complex relations in noisy data\nstreams. However, these methods assume the existence of fully-labelled training\ndata, which is unrealistic for most real-world applications. We present a novel\napproach for completing the supervision of a semi-supervised structure learning\ntask. We incorporate graph-cut minimisation, a technique that derives labels\nfor unlabelled data, based on their distance to their labelled counterparts. In\norder to adapt graph-cut minimisation to first order logic, we employ a\nsuitable structural distance for measuring the distance between sets of logical\natoms. The labelling process is achieved online (single-pass) by means of a\ncaching mechanism and the Hoeffding bound, a statistical tool to approximate\nglobally-optimal decisions from locally-optimal ones. We evaluate our approach\non the task of composite event recognition by using a benchmark dataset for\nhuman activity recognition, as well as a real dataset for maritime monitoring.\nThe evaluation suggests that our approach can effectively complete the missing\nlabels and eventually, improve the accuracy of the underlying structure\nlearning system.\n", "versions": [{"version": "v1", "created": "Thu, 1 Mar 2018 18:31:07 GMT"}, {"version": "v2", "created": "Wed, 20 Feb 2019 09:13:50 GMT"}], "update_date": "2019-02-21", "authors_parsed": [["Michelioudakis", "Evangelos", ""], ["Artikis", "Alexander", ""], ["Paliouras", "Georgios", ""]]}, {"id": "1803.00590", "submitter": "Hoang M. Le", "authors": "Hoang M. Le, Nan Jiang, Alekh Agarwal, Miroslav Dud\\'ik, Yisong Yue,\n  Hal Daum\\'e III", "title": "Hierarchical Imitation and Reinforcement Learning", "comments": "Proceedings of the 35th International Conference on Machine Learning\n  (ICML 2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study how to effectively leverage expert feedback to learn sequential\ndecision-making policies. We focus on problems with sparse rewards and long\ntime horizons, which typically pose significant challenges in reinforcement\nlearning. We propose an algorithmic framework, called hierarchical guidance,\nthat leverages the hierarchical structure of the underlying problem to\nintegrate different modes of expert interaction. Our framework can incorporate\ndifferent combinations of imitation learning (IL) and reinforcement learning\n(RL) at different levels, leading to dramatic reductions in both expert effort\nand cost of exploration. Using long-horizon benchmarks, including Montezuma's\nRevenge, we demonstrate that our approach can learn significantly faster than\nhierarchical RL, and be significantly more label-efficient than standard IL. We\nalso theoretically analyze labeling cost for certain instantiations of our\nframework.\n", "versions": [{"version": "v1", "created": "Thu, 1 Mar 2018 19:12:27 GMT"}, {"version": "v2", "created": "Sat, 9 Jun 2018 08:41:37 GMT"}], "update_date": "2018-06-12", "authors_parsed": [["Le", "Hoang M.", ""], ["Jiang", "Nan", ""], ["Agarwal", "Alekh", ""], ["Dud\u00edk", "Miroslav", ""], ["Yue", "Yisong", ""], ["Daum\u00e9", "Hal", "III"]]}, {"id": "1803.00607", "submitter": "Sam Ganzfried", "authors": "Sam Ganzfried", "title": "Optimization-Based Algorithm for Evolutionarily Stable Strategies\n  against Pure Mutations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.AI econ.TH math.OC q-bio.PE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Evolutionarily stable strategy (ESS) is an important solution concept in game\ntheory which has been applied frequently to biological models. Informally an\nESS is a strategy that if followed by the population cannot be taken over by a\nmutation strategy that is initially rare. Finding such a strategy has been\nshown to be difficult from a theoretical complexity perspective. We present an\nalgorithm for the case where mutations are restricted to pure strategies, and\npresent experiments on several game classes including random and a\nrecently-proposed cancer model. Our algorithm is based on a mixed-integer\nnon-convex feasibility program formulation, which constitutes the first general\noptimization formulation for this problem. It turns out that the vast majority\nof the games included in the experiments contain ESS with small support, and\nour algorithm is outperformed by a support-enumeration based approach. However\nwe suspect our algorithm may be useful in the future as games are studied that\nhave ESS with potentially larger and unknown support size.\n", "versions": [{"version": "v1", "created": "Thu, 1 Mar 2018 20:08:21 GMT"}, {"version": "v2", "created": "Mon, 14 Jan 2019 01:44:36 GMT"}], "update_date": "2019-01-18", "authors_parsed": [["Ganzfried", "Sam", ""]]}, {"id": "1803.00612", "submitter": "Yang Yu", "authors": "Yang Yu, Kazi Saidul Hasan, Mo Yu, Wei Zhang, Zhiguo Wang", "title": "Knowledge Base Relation Detection via Multi-View Matching", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Relation detection is a core component for Knowledge Base Question Answering\n(KBQA). In this paper, we propose a KB relation detection model via multi-view\nmatching which utilizes more useful information extracted from question and KB.\nThe matching inside each view is through multiple perspectives to compare two\ninput texts thoroughly. All these components are designed in an end-to-end\ntrainable neural network model. Experiments on SimpleQuestions and WebQSP yield\nstate-of-the-art results.\n", "versions": [{"version": "v1", "created": "Thu, 1 Mar 2018 20:17:02 GMT"}, {"version": "v2", "created": "Mon, 9 Apr 2018 14:19:18 GMT"}], "update_date": "2018-04-10", "authors_parsed": [["Yu", "Yang", ""], ["Hasan", "Kazi Saidul", ""], ["Yu", "Mo", ""], ["Zhang", "Wei", ""], ["Wang", "Zhiguo", ""]]}, {"id": "1803.00653", "submitter": "Alexey Dosovitskiy", "authors": "Nikolay Savinov, Alexey Dosovitskiy, Vladlen Koltun", "title": "Semi-parametric Topological Memory for Navigation", "comments": "Published at International Conference on Learning Representations\n  (ICLR) 2018. Project website at https://sites.google.com/view/SPTM", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new memory architecture for navigation in previously unseen\nenvironments, inspired by landmark-based navigation in animals. The proposed\nsemi-parametric topological memory (SPTM) consists of a (non-parametric) graph\nwith nodes corresponding to locations in the environment and a (parametric)\ndeep network capable of retrieving nodes from the graph based on observations.\nThe graph stores no metric information, only connectivity of locations\ncorresponding to the nodes. We use SPTM as a planning module in a navigation\nsystem. Given only 5 minutes of footage of a previously unseen maze, an\nSPTM-based navigation agent can build a topological map of the environment and\nuse it to confidently navigate towards goals. The average success rate of the\nSPTM agent in goal-directed navigation across test environments is higher than\nthe best-performing baseline by a factor of three. A video of the agent is\navailable at https://youtu.be/vRF7f4lhswo\n", "versions": [{"version": "v1", "created": "Thu, 1 Mar 2018 22:50:35 GMT"}], "update_date": "2018-03-05", "authors_parsed": [["Savinov", "Nikolay", ""], ["Dosovitskiy", "Alexey", ""], ["Koltun", "Vladlen", ""]]}, {"id": "1803.00722", "submitter": "EPTCS", "authors": "Pedro Quaresma (University of Coimbra), Walther Neuper (IICM at Graz\n  University of Technology)", "title": "Proceedings 6th International Workshop on Theorem proving components for\n  Educational software", "comments": null, "journal-ref": "EPTCS 267, 2018", "doi": "10.4204/EPTCS.267", "report-no": null, "categories": "cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The 6th International Workshop on Theorem proving components for Educational\nsoftware (ThEdu'17) was held in Gothenburg, Sweden, on 6 Aug 2017. It was\nassociated to the conference CADE26. Topics of interest include: methods of\nautomated deduction applied to checking students' input; methods of automated\ndeduction applied to prove post-conditions for particular problem solutions;\ncombinations of deduction and computation enabling systems to propose next\nsteps; automated provers specific for dynamic geometry systems; proof and\nproving in mathematics education.\n  ThEdu'17 was a vibrant workshop, with one invited talk and eight\ncontributions. It triggered the post-proceedings at hand.\n", "versions": [{"version": "v1", "created": "Fri, 2 Mar 2018 05:23:45 GMT"}], "update_date": "2018-03-05", "authors_parsed": [["Quaresma", "Pedro", "", "University of Coimbra"], ["Neuper", "Walther", "", "IICM at Graz\n  University of Technology"]]}, {"id": "1803.00729", "submitter": "Yu Gong", "authors": "Yu Gong, Kaiqi Zhao, Kenny Q. Zhu", "title": "Representing Verbs as Argument Concepts", "comments": "7 pages, 2 figures, AAAI 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Verbs play an important role in the understanding of natural language text.\nThis paper studies the problem of abstracting the subject and object arguments\nof a verb into a set of noun concepts, known as the \"argument concepts\". This\nset of concepts, whose size is parameterized, represents the fine-grained\nsemantics of a verb. For example, the object of \"enjoy\" can be abstracted into\ntime, hobby and event, etc. We present a novel framework to automatically infer\nhuman readable and machine computable action concepts with high accuracy.\n", "versions": [{"version": "v1", "created": "Fri, 2 Mar 2018 06:18:40 GMT"}], "update_date": "2018-04-04", "authors_parsed": [["Gong", "Yu", ""], ["Zhao", "Kaiqi", ""], ["Zhu", "Kenny Q.", ""]]}, {"id": "1803.00781", "submitter": "Alexandre P\\'er\\'e", "authors": "Alexandre P\\'er\\'e, S\\'ebastien Forestier, Olivier Sigaud, Pierre-Yves\n  Oudeyer", "title": "Unsupervised Learning of Goal Spaces for Intrinsically Motivated Goal\n  Exploration", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Intrinsically motivated goal exploration algorithms enable machines to\ndiscover repertoires of policies that produce a diversity of effects in complex\nenvironments. These exploration algorithms have been shown to allow real world\nrobots to acquire skills such as tool use in high-dimensional continuous state\nand action spaces. However, they have so far assumed that self-generated goals\nare sampled in a specifically engineered feature space, limiting their\nautonomy. In this work, we propose to use deep representation learning\nalgorithms to learn an adequate goal space. This is a developmental 2-stage\napproach: first, in a perceptual learning stage, deep learning algorithms use\npassive raw sensor observations of world changes to learn a corresponding\nlatent space; then goal exploration happens in a second stage by sampling goals\nin this latent space. We present experiments where a simulated robot arm\ninteracts with an object, and we show that exploration algorithms using such\nlearned representations can match the performance obtained using engineered\nrepresentations.\n", "versions": [{"version": "v1", "created": "Fri, 2 Mar 2018 09:45:53 GMT"}, {"version": "v2", "created": "Tue, 6 Mar 2018 09:32:30 GMT"}, {"version": "v3", "created": "Tue, 9 Oct 2018 18:30:41 GMT"}], "update_date": "2018-10-11", "authors_parsed": [["P\u00e9r\u00e9", "Alexandre", ""], ["Forestier", "S\u00e9bastien", ""], ["Sigaud", "Olivier", ""], ["Oudeyer", "Pierre-Yves", ""]]}, {"id": "1803.00832", "submitter": "Dennis Diefenbach", "authors": "Dennis Diefenbach and Andreas Both and Kamal Singh and Pierre Maret", "title": "Towards a Question Answering System over the Semantic Web", "comments": "There is a Patent Pending for the presented approach. It was\n  submitted the 18 January 2018 at the EPO and has the number EP18305035.0", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Thanks to the development of the Semantic Web, a lot of new structured data\nhas become available on the Web in the form of knowledge bases (KBs). Making\nthis valuable data accessible and usable for end-users is one of the main goals\nof Question Answering (QA) over KBs. Most current QA systems query one KB, in\none language (namely English). The existing approaches are not designed to be\neasily adaptable to new KBs and languages. We first introduce a new approach\nfor translating natural language questions to SPARQL queries. It is able to\nquery several KBs simultaneously, in different languages, and can easily be\nported to other KBs and languages. In our evaluation, the impact of our\napproach is proven using 5 different well-known and large KBs: Wikidata,\nDBpedia, MusicBrainz, DBLP and Freebase as well as 5 different languages namely\nEnglish, German, French, Italian and Spanish. Second, we show how we integrated\nour approach, to make it easily accessible by the research community and by\nend-users. To summarize, we provided a conceptional solution for multilingual,\nKB-agnostic Question Answering over the Semantic Web. The provided first\napproximation validates this concept.\n", "versions": [{"version": "v1", "created": "Fri, 2 Mar 2018 12:59:50 GMT"}], "update_date": "2018-03-05", "authors_parsed": [["Diefenbach", "Dennis", ""], ["Both", "Andreas", ""], ["Singh", "Kamal", ""], ["Maret", "Pierre", ""]]}, {"id": "1803.00874", "submitter": "Azlan Iqbal", "authors": "Azlan Iqbal", "title": "Estimating Total Search Space Size for Specific Piece Sets in Chess", "comments": "3 Pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic chess problem or puzzle composition typically involves generating\nand testing various different positions, sometimes using particular piece sets.\nOnce a position has been generated, it is then usually tested for positional\nlegality based on the game rules. However, it is useful to be able to estimate\nwhat the search space size for particular piece combinations is to begin with.\nSo if a desirable chess problem was successfully generated by examining\n'merely' 100,000 or so positions in a theoretical search space of about 100\nbillion, this would imply the composing approach used was quite viable and\nperhaps even impressive. In this article, I explain a method of calculating the\nsize of this search space using a combinatorics and permutations approach.\nWhile the mathematics itself may already be established, a precise method and\njustification of applying it with regard to the chessboard and chess pieces has\nnot been documented, to the best of our knowledge. Additionally, the method\ncould serve as a useful starting point for further estimations of search space\nsize which filter out positions for legality and rotation, depending on how the\nautomatic composer is allowed to place pieces on the board (because this\naffects its total search space size).\n", "versions": [{"version": "v1", "created": "Tue, 27 Feb 2018 07:35:55 GMT"}], "update_date": "2018-03-05", "authors_parsed": [["Iqbal", "Azlan", ""]]}, {"id": "1803.00885", "submitter": "Felix Draxler", "authors": "Felix Draxler, Kambis Veschgini, Manfred Salmhofer, Fred A. Hamprecht", "title": "Essentially No Barriers in Neural Network Energy Landscape", "comments": "In Proceedings of 35th International Conference on Machine Learning\n  (ICML 2018)", "journal-ref": "Proceedings of the 35th International Conference on Machine\n  Learning, PMLR 80:1308-1317, 2018", "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Training neural networks involves finding minima of a high-dimensional\nnon-convex loss function. Knowledge of the structure of this energy landscape\nis sparse. Relaxing from linear interpolations, we construct continuous paths\nbetween minima of recent neural network architectures on CIFAR10 and CIFAR100.\nSurprisingly, the paths are essentially flat in both the training and test\nlandscapes. This implies that neural networks have enough capacity for\nstructural changes, or that these changes are small between minima. Also, each\nminimum has at least one vanishing Hessian eigenvalue in addition to those\nresulting from trivial invariance.\n", "versions": [{"version": "v1", "created": "Fri, 2 Mar 2018 15:22:10 GMT"}, {"version": "v2", "created": "Thu, 8 Mar 2018 21:59:03 GMT"}, {"version": "v3", "created": "Thu, 22 Mar 2018 17:45:05 GMT"}, {"version": "v4", "created": "Mon, 25 Jun 2018 14:55:25 GMT"}, {"version": "v5", "created": "Fri, 22 Feb 2019 11:20:22 GMT"}], "update_date": "2019-02-25", "authors_parsed": [["Draxler", "Felix", ""], ["Veschgini", "Kambis", ""], ["Salmhofer", "Manfred", ""], ["Hamprecht", "Fred A.", ""]]}, {"id": "1803.00907", "submitter": "Oggi Rudovic", "authors": "Adria Ruiz, Ognjen Rudovic, Xavier Binefa and Maja Pantic", "title": "Multi-Instance Dynamic Ordinal Random Fields for Weakly-supervised\n  Facial Behavior Analysis", "comments": "submitted TIP (June 2017). arXiv admin note: text overlap with\n  arXiv:1609.01465", "journal-ref": null, "doi": "10.1109/TIP.2018.2830189", "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a Multi-Instance-Learning (MIL) approach for weakly-supervised\nlearning problems, where a training set is formed by bags (sets of feature\nvectors or instances) and only labels at bag-level are provided. Specifically,\nwe consider the Multi-Instance Dynamic-Ordinal-Regression (MI-DOR) setting,\nwhere the instance labels are naturally represented as ordinal variables and\nbags are structured as temporal sequences. To this end, we propose\nMulti-Instance Dynamic Ordinal Random Fields (MI-DORF). In this framework, we\ntreat instance-labels as temporally-dependent latent variables in an Undirected\nGraphical Model. Different MIL assumptions are modelled via newly introduced\nhigh-order potentials relating bag and instance-labels within the energy\nfunction of the model. We also extend our framework to address the\nPartially-Observed MI-DOR problems, where a subset of instance labels are\navailable during training. We show on the tasks of weakly-supervised facial\nbehavior analysis, Facial Action Unit (DISFA dataset) and Pain (UNBC dataset)\nIntensity estimation, that the proposed framework outperforms alternative\nlearning approaches. Furthermore, we show that MIDORF can be employed to reduce\nthe data annotation efforts in this context by large-scale.\n", "versions": [{"version": "v1", "created": "Thu, 1 Mar 2018 04:13:47 GMT"}], "update_date": "2018-07-04", "authors_parsed": [["Ruiz", "Adria", ""], ["Rudovic", "Ognjen", ""], ["Binefa", "Xavier", ""], ["Pantic", "Maja", ""]]}, {"id": "1803.00909", "submitter": "Shiyu Liang", "authors": "Shiyu Liang, Ruoyu Sun, Yixuan Li, R. Srikant", "title": "Understanding the Loss Surface of Neural Networks for Binary\n  Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is widely conjectured that the reason that training algorithms for neural\nnetworks are successful because all local minima lead to similar performance,\nfor example, see (LeCun et al., 2015, Choromanska et al., 2015, Dauphin et al.,\n2014). Performance is typically measured in terms of two metrics: training\nperformance and generalization performance. Here we focus on the training\nperformance of single-layered neural networks for binary classification, and\nprovide conditions under which the training error is zero at all local minima\nof a smooth hinge loss function. Our conditions are roughly in the following\nform: the neurons have to be strictly convex and the surrogate loss function\nshould be a smooth version of hinge loss. We also provide counterexamples to\nshow that when the loss function is replaced with quadratic loss or logistic\nloss, the result may not hold.\n", "versions": [{"version": "v1", "created": "Mon, 19 Feb 2018 02:13:38 GMT"}, {"version": "v2", "created": "Mon, 5 Mar 2018 18:20:37 GMT"}], "update_date": "2018-03-06", "authors_parsed": [["Liang", "Shiyu", ""], ["Sun", "Ruoyu", ""], ["Li", "Yixuan", ""], ["Srikant", "R.", ""]]}, {"id": "1803.00952", "submitter": "Miten Mistry", "authors": "Miten Mistry, Dimitrios Letsios, Gerhard Krennrich, Robert M. Lee, and\n  Ruth Misener", "title": "Mixed-Integer Convex Nonlinear Optimization with Gradient-Boosted Trees\n  Embedded", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Decision trees usefully represent sparse, high dimensional and noisy data.\nHaving learned a function from this data, we may want to thereafter integrate\nthe function into a larger decision-making problem, e.g., for picking the best\nchemical process catalyst. We study a large-scale, industrially-relevant\nmixed-integer nonlinear nonconvex optimization problem involving both\ngradient-boosted trees and penalty functions mitigating risk. This\nmixed-integer optimization problem with convex penalty terms broadly applies to\noptimizing pre-trained regression tree models. Decision makers may wish to\noptimize discrete models to repurpose legacy predictive models, or they may\nwish to optimize a discrete model that particularly well-represents a data set.\nWe develop several heuristic methods to find feasible solutions, and an exact,\nbranch-and-bound algorithm leveraging structural properties of the\ngradient-boosted trees and penalty functions. We computationally test our\nmethods on concrete mixture design instance and a chemical catalysis industrial\ninstance.\n", "versions": [{"version": "v1", "created": "Fri, 2 Mar 2018 17:10:21 GMT"}, {"version": "v2", "created": "Fri, 5 Oct 2018 12:16:50 GMT"}, {"version": "v3", "created": "Wed, 25 Sep 2019 13:00:14 GMT"}], "update_date": "2019-09-26", "authors_parsed": [["Mistry", "Miten", ""], ["Letsios", "Dimitrios", ""], ["Krennrich", "Gerhard", ""], ["Lee", "Robert M.", ""], ["Misener", "Ruth", ""]]}, {"id": "1803.00967", "submitter": "Zi Wang", "authors": "Zi Wang and Caelan Reed Garrett and Leslie Pack Kaelbling and Tom\\'as\n  Lozano-P\\'erez", "title": "Active model learning and diverse action sampling for task and motion\n  planning", "comments": "Proceedings of the 2018 IEEE/RSJ International Conference on\n  Intelligent Robots and Systems (IROS), Madrid, Spain.\n  https://www.youtube.com/playlist?list=PLoWhBFPMfSzDbc8CYelsbHZa1d3uz-W_c", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The objective of this work is to augment the basic abilities of a robot by\nlearning to use new sensorimotor primitives to enable the solution of complex\nlong-horizon problems. Solving long-horizon problems in complex domains\nrequires flexible generative planning that can combine primitive abilities in\nnovel combinations to solve problems as they arise in the world. In order to\nplan to combine primitive actions, we must have models of the preconditions and\neffects of those actions: under what circumstances will executing this\nprimitive achieve some particular effect in the world?\n  We use, and develop novel improvements on, state-of-the-art methods for\nactive learning and sampling. We use Gaussian process methods for learning the\nconditions of operator effectiveness from small numbers of expensive training\nexamples collected by experimentation on a robot. We develop adaptive sampling\nmethods for generating diverse elements of continuous sets (such as robot\nconfigurations and object poses) during planning for solving a new task, so\nthat planning is as efficient as possible. We demonstrate these methods in an\nintegrated system, combining newly learned models with an efficient\ncontinuous-space robot task and motion planner to learn to solve long horizon\nproblems more efficiently than was previously possible.\n", "versions": [{"version": "v1", "created": "Fri, 2 Mar 2018 17:40:18 GMT"}, {"version": "v2", "created": "Sun, 12 Aug 2018 16:08:00 GMT"}], "update_date": "2018-08-14", "authors_parsed": [["Wang", "Zi", ""], ["Garrett", "Caelan Reed", ""], ["Kaelbling", "Leslie Pack", ""], ["Lozano-P\u00e9rez", "Tom\u00e1s", ""]]}, {"id": "1803.01016", "submitter": "Zhiyuan Xu", "authors": "Teng Li, Zhiyuan Xu, Jian Tang, Yanzhi Wang", "title": "Model-Free Control for Distributed Stream Data Processing using Deep\n  Reinforcement Learning", "comments": "14 pages, this paper has been accepted by VLDB 2018", "journal-ref": null, "doi": "10.14778/3184470.3184474", "report-no": null, "categories": "cs.DC cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we focus on general-purpose Distributed Stream Data Processing\nSystems (DSDPSs), which deal with processing of unbounded streams of continuous\ndata at scale distributedly in real or near-real time. A fundamental problem in\na DSDPS is the scheduling problem with the objective of minimizing average\nend-to-end tuple processing time. A widely-used solution is to distribute\nworkload evenly over machines in the cluster in a round-robin manner, which is\nobviously not efficient due to lack of consideration for communication delay.\nModel-based approaches do not work well either due to the high complexity of\nthe system environment. We aim to develop a novel model-free approach that can\nlearn to well control a DSDPS from its experience rather than accurate and\nmathematically solvable system models, just as a human learns a skill (such as\ncooking, driving, swimming, etc). Specifically, we, for the first time, propose\nto leverage emerging Deep Reinforcement Learning (DRL) for enabling model-free\ncontrol in DSDPSs; and present design, implementation and evaluation of a novel\nand highly effective DRL-based control framework, which minimizes average\nend-to-end tuple processing time by jointly learning the system environment via\ncollecting very limited runtime statistics data and making decisions under the\nguidance of powerful Deep Neural Networks. To validate and evaluate the\nproposed framework, we implemented it based on a widely-used DSDPS, Apache\nStorm, and tested it with three representative applications. Extensive\nexperimental results show 1) Compared to Storm's default scheduler and the\nstate-of-the-art model-based method, the proposed framework reduces average\ntuple processing by 33.5% and 14.0% respectively on average. 2) The proposed\nframework can quickly reach a good scheduling solution during online learning,\nwhich justifies its practicability for online control in DSDPSs.\n", "versions": [{"version": "v1", "created": "Fri, 2 Mar 2018 19:30:55 GMT"}], "update_date": "2018-03-06", "authors_parsed": [["Li", "Teng", ""], ["Xu", "Zhiyuan", ""], ["Tang", "Jian", ""], ["Wang", "Yanzhi", ""]]}, {"id": "1803.01044", "submitter": "Raunak Bhattacharyya", "authors": "Raunak P. Bhattacharyya, Derek J. Phillips, Blake Wulfe, Jeremy\n  Morton, Alex Kuefler, Mykel J. Kochenderfer", "title": "Multi-Agent Imitation Learning for Driving Simulation", "comments": "6 pages, 3 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Simulation is an appealing option for validating the safety of autonomous\nvehicles. Generative Adversarial Imitation Learning (GAIL) has recently been\nshown to learn representative human driver models. These human driver models\nwere learned through training in single-agent environments, but they have\ndifficulty in generalizing to multi-agent driving scenarios. We argue these\ndifficulties arise because observations at training and test time are sampled\nfrom different distributions. This difference makes such models unsuitable for\nthe simulation of driving scenes, where multiple agents must interact\nrealistically over long time horizons. We extend GAIL to address these\nshortcomings through a parameter-sharing approach grounded in curriculum\nlearning. Compared with single-agent GAIL policies, policies generated by our\nPS-GAIL method prove superior at interacting stably in a multi-agent setting\nand capturing the emergent behavior of human drivers.\n", "versions": [{"version": "v1", "created": "Fri, 2 Mar 2018 21:18:16 GMT"}], "update_date": "2018-03-06", "authors_parsed": [["Bhattacharyya", "Raunak P.", ""], ["Phillips", "Derek J.", ""], ["Wulfe", "Blake", ""], ["Morton", "Jeremy", ""], ["Kuefler", "Alex", ""], ["Kochenderfer", "Mykel J.", ""]]}, {"id": "1803.01092", "submitter": "Timo Nolle", "authors": "Timo Nolle, Stefan Luettgen, Alexander Seeliger, Max M\\\"uhlh\\\"auser", "title": "Analyzing Business Process Anomalies Using Autoencoders", "comments": "20 pages, 5 figures", "journal-ref": null, "doi": "10.1007/s10994-018-5702-8", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Businesses are naturally interested in detecting anomalies in their internal\nprocesses, because these can be indicators for fraud and inefficiencies. Within\nthe domain of business intelligence, classic anomaly detection is not very\nfrequently researched. In this paper, we propose a method, using autoencoders,\nfor detecting and analyzing anomalies occurring in the execution of a business\nprocess. Our method does not rely on any prior knowledge about the process and\ncan be trained on a noisy dataset already containing the anomalies. We\ndemonstrate its effectiveness by evaluating it on 700 different datasets and\ntesting its performance against three state-of-the-art anomaly detection\nmethods. This paper is an extension of our previous work from 2016 [30].\nCompared to the original publication we have further refined the approach in\nterms of performance and conducted an elaborate evaluation on more\nsophisticated datasets including real-life event logs from the Business Process\nIntelligence Challenges of 2012 and 2017. In our experiments our approach\nreached an F1 score of 0.87, whereas the best unaltered state-of-the-art\napproach reached an F1 score of 0.72. Furthermore, our approach can be used to\nanalyze the detected anomalies in terms of which event within one execution of\nthe process causes the anomaly.\n", "versions": [{"version": "v1", "created": "Sat, 3 Mar 2018 02:26:28 GMT"}], "update_date": "2018-05-01", "authors_parsed": [["Nolle", "Timo", ""], ["Luettgen", "Stefan", ""], ["Seeliger", "Alexander", ""], ["M\u00fchlh\u00e4user", "Max", ""]]}, {"id": "1803.01118", "submitter": "Bradly Stadie", "authors": "Bradly C. Stadie, Ge Yang, Rein Houthooft, Xi Chen, Yan Duan, Yuhuai\n  Wu, Pieter Abbeel, Ilya Sutskever", "title": "Some Considerations on Learning to Explore via Meta-Reinforcement\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of exploration in meta reinforcement learning. Two\nnew meta reinforcement learning algorithms are suggested: E-MAML and\nE-$\\text{RL}^2$. Results are presented on a novel environment we call `Krazy\nWorld' and a set of maze environments. We show E-MAML and E-$\\text{RL}^2$\ndeliver better performance on tasks where exploration is important.\n", "versions": [{"version": "v1", "created": "Sat, 3 Mar 2018 07:13:43 GMT"}, {"version": "v2", "created": "Fri, 11 Jan 2019 20:26:59 GMT"}], "update_date": "2019-01-15", "authors_parsed": [["Stadie", "Bradly C.", ""], ["Yang", "Ge", ""], ["Houthooft", "Rein", ""], ["Chen", "Xi", ""], ["Duan", "Yan", ""], ["Wu", "Yuhuai", ""], ["Abbeel", "Pieter", ""], ["Sutskever", "Ilya", ""]]}, {"id": "1803.01206", "submitter": "Simon Du", "authors": "Simon S. Du and Jason D. Lee", "title": "On the Power of Over-parametrization in Neural Networks with Quadratic\n  Activation", "comments": "Accepted by ICML 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide new theoretical insights on why over-parametrization is effective\nin learning neural networks. For a $k$ hidden node shallow network with\nquadratic activation and $n$ training data points, we show as long as $ k \\ge\n\\sqrt{2n}$, over-parametrization enables local search algorithms to find a\n\\emph{globally} optimal solution for general smooth and convex loss functions.\nFurther, despite that the number of parameters may exceed the sample size,\nusing theory of Rademacher complexity, we show with weight decay, the solution\nalso generalizes well if the data is sampled from a regular distribution such\nas Gaussian. To prove when $k\\ge \\sqrt{2n}$, the loss function has benign\nlandscape properties, we adopt an idea from smoothed analysis, which may have\nother applications in studying loss surfaces of neural networks.\n", "versions": [{"version": "v1", "created": "Sat, 3 Mar 2018 17:37:57 GMT"}, {"version": "v2", "created": "Thu, 14 Jun 2018 23:59:37 GMT"}], "update_date": "2018-06-18", "authors_parsed": [["Du", "Simon S.", ""], ["Lee", "Jason D.", ""]]}, {"id": "1803.01252", "submitter": "Corey Kiassat", "authors": "Nima Safaei, Corey Kiassat", "title": "A Swift Heuristic Method for Work Order Scheduling under the\n  Skilled-Workforce Constraint", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The considered problem is how to optimally allocate a set of jobs to\ntechnicians of different skills such that the number of technicians of each\nskill does not exceed the number of persons with that skill designation. The\nkey motivation is the quick sensitivity analysis in terms of the workforce size\nwhich is quite necessary in many industries in the presence of unexpected work\norders. A time-indexed mathematical model is proposed to minimize the total\nweighted completion time of the jobs. The proposed model is decomposed into a\nnumber of single-skill sub-problems so that each one is a combination of a\nseries of nested binary Knapsack problems. A heuristic procedure is proposed to\nsolve the problem. Our experimental results, based on a real-world case study,\nreveal that the proposed method quickly produces a schedule statistically close\nto the optimal one while the classical optimal procedure is very\ntime-consuming.\n", "versions": [{"version": "v1", "created": "Sat, 3 Mar 2018 22:19:42 GMT"}], "update_date": "2018-03-06", "authors_parsed": [["Safaei", "Nima", ""], ["Kiassat", "Corey", ""]]}, {"id": "1803.01271", "submitter": "Shaojie Bai", "authors": "Shaojie Bai, J. Zico Kolter, Vladlen Koltun", "title": "An Empirical Evaluation of Generic Convolutional and Recurrent Networks\n  for Sequence Modeling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For most deep learning practitioners, sequence modeling is synonymous with\nrecurrent networks. Yet recent results indicate that convolutional\narchitectures can outperform recurrent networks on tasks such as audio\nsynthesis and machine translation. Given a new sequence modeling task or\ndataset, which architecture should one use? We conduct a systematic evaluation\nof generic convolutional and recurrent architectures for sequence modeling. The\nmodels are evaluated across a broad range of standard tasks that are commonly\nused to benchmark recurrent networks. Our results indicate that a simple\nconvolutional architecture outperforms canonical recurrent networks such as\nLSTMs across a diverse range of tasks and datasets, while demonstrating longer\neffective memory. We conclude that the common association between sequence\nmodeling and recurrent networks should be reconsidered, and convolutional\nnetworks should be regarded as a natural starting point for sequence modeling\ntasks. To assist related work, we have made code available at\nhttp://github.com/locuslab/TCN .\n", "versions": [{"version": "v1", "created": "Sun, 4 Mar 2018 00:20:29 GMT"}, {"version": "v2", "created": "Thu, 19 Apr 2018 14:32:38 GMT"}], "update_date": "2018-04-20", "authors_parsed": [["Bai", "Shaojie", ""], ["Kolter", "J. Zico", ""], ["Koltun", "Vladlen", ""]]}, {"id": "1803.01316", "submitter": "Johannes F\\\"urnkranz", "authors": "Johannes F\\\"urnkranz, Tom\\'a\\v{s} Kliegr, Heiko Paulheim", "title": "On Cognitive Preferences and the Plausibility of Rule-based Models", "comments": "V4: Another rewrite of section on interpretability to clarify focus\n  on plausibility and relation to interpretability, comprehensibility, and\n  justifiability", "journal-ref": "Machine Learning 109(4):853-898, 2020", "doi": "10.1007/s10994-019-05856-5", "report-no": null, "categories": "cs.LG cs.AI cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is conventional wisdom in machine learning and data mining that logical\nmodels such as rule sets are more interpretable than other models, and that\namong such rule-based models, simpler models are more interpretable than more\ncomplex ones. In this position paper, we question this latter assumption by\nfocusing on one particular aspect of interpretability, namely the plausibility\nof models. Roughly speaking, we equate the plausibility of a model with the\nlikeliness that a user accepts it as an explanation for a prediction. In\nparticular, we argue that, all other things being equal, longer explanations\nmay be more convincing than shorter ones, and that the predominant bias for\nshorter models, which is typically necessary for learning powerful\ndiscriminative models, may not be suitable when it comes to user acceptance of\nthe learned models. To that end, we first recapitulate evidence for and against\nthis postulate, and then report the results of an evaluation in a\ncrowd-sourcing study based on about 3.000 judgments. The results do not reveal\na strong preference for simple rules, whereas we can observe a weak preference\nfor longer rules in some domains. We then relate these results to well-known\ncognitive biases such as the conjunction fallacy, the representative heuristic,\nor the recogition heuristic, and investigate their relation to rule length and\nplausibility.\n", "versions": [{"version": "v1", "created": "Sun, 4 Mar 2018 08:26:43 GMT"}, {"version": "v2", "created": "Sat, 10 Mar 2018 14:03:06 GMT"}, {"version": "v3", "created": "Sat, 18 Aug 2018 15:02:51 GMT"}, {"version": "v4", "created": "Mon, 22 Apr 2019 08:37:58 GMT"}], "update_date": "2020-12-09", "authors_parsed": [["F\u00fcrnkranz", "Johannes", ""], ["Kliegr", "Tom\u00e1\u0161", ""], ["Paulheim", "Heiko", ""]]}, {"id": "1803.01364", "submitter": "Arief Koesdwiady", "authors": "Arief Koesdwiady and Fakhri Karray", "title": "SAFE: Spectral Evolution Analysis Feature Extraction for Non-Stationary\n  Time Series Prediction", "comments": "submitted to IEEE Trans Cybernetics", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a practical approach for detecting non-stationarity in\ntime series prediction. This method is called SAFE and works by monitoring the\nevolution of the spectral contents of time series through a distance function.\nThis method is designed to work in combination with state-of-the-art machine\nlearning methods in real time by informing the online predictors to perform\nnecessary adaptation when a non-stationarity presents. We also propose an\nalgorithm to proportionally include some past data in the adaption process to\novercome the Catastrophic Forgetting problem. To validate our hypothesis and\ntest the effectiveness of our approach, we present comprehensive experiments in\ndifferent elements of the approach involving artificial and real-world\ndatasets. The experiments show that the proposed method is able to\nsignificantly save computational resources in term of processor or GPU cycles\nwhile maintaining high prediction performances.\n", "versions": [{"version": "v1", "created": "Sun, 4 Mar 2018 14:55:33 GMT"}, {"version": "v2", "created": "Wed, 16 May 2018 19:39:25 GMT"}], "update_date": "2018-05-18", "authors_parsed": [["Koesdwiady", "Arief", ""], ["Karray", "Fakhri", ""]]}, {"id": "1803.01365", "submitter": "Arief Koesdwiady", "authors": "Arief Koesdwiady, and Fakhri Karray", "title": "New Results on Multi-Step Traffic Flow Prediction", "comments": "submitted to IEEE Trans on ITS", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In its simplest form, the traffic flow prediction problem is restricted to\npredicting a single time-step into the future. Multi-step traffic flow\nprediction extends this set-up to the case where predicting multiple time-steps\ninto the future based on some finite history is of interest. This problem is\nsignificantly more difficult than its single-step variant and is known to\nsuffer from degradation in predictions as the time step increases. In this\npaper, two approaches to improve multi-step traffic flow prediction performance\nin recursive and multi-output settings are introduced. In particular, a model\nthat allows recursive prediction approaches to take into account the temporal\ncontext in term of time-step index when making predictions is introduced. In\naddition, a conditional generative adversarial network-based data augmentation\nmethod is proposed to improve prediction performance in the multi-output\nsetting. The experiments on a real-world traffic flow dataset show that the two\nmethods improve on multi-step traffic flow prediction in recursive and\nmulti-output settings, respectively.\n", "versions": [{"version": "v1", "created": "Sun, 4 Mar 2018 14:59:55 GMT"}, {"version": "v2", "created": "Wed, 16 May 2018 19:35:10 GMT"}], "update_date": "2018-05-18", "authors_parsed": [["Koesdwiady", "Arief", ""], ["Karray", "Fakhri", ""]]}, {"id": "1803.01378", "submitter": "Samer Nashed", "authors": "Samer B. Nashed, David M. Ilstrup, Joydeep Biswas", "title": "Localization under Topological Uncertainty for Lane Identification of\n  Autonomous Vehicles", "comments": "6 pages, to appear in ICRA 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Autonomous vehicles (AVs) require accurate metric and topological location\nestimates for safe, effective navigation and decision-making. Although many\nhigh-definition (HD) roadmaps exist, they are not always accurate since public\nroads are dynamic, shaped unpredictably by both human activity and nature.\nThus, AVs must be able to handle situations in which the topology specified by\nthe map does not agree with reality. We present the Variable Structure Multiple\nHidden Markov Model (VSM-HMM) as a framework for localizing in the presence of\ntopological uncertainty, and demonstrate its effectiveness on an AV where lane\nmembership is modeled as a topological localization process. VSM-HMMs use a\ndynamic set of HMMs to simultaneously reason about location within a set of\nmost likely current topologies and therefore may also be applied to topological\nstructure estimation as well as AV lane estimation. In addition, we present an\nextension to the Earth Mover's Distance which allows uncertainty to be taken\ninto account when computing the distance between belief distributions on\nsimplices of arbitrary relative sizes.\n", "versions": [{"version": "v1", "created": "Sun, 4 Mar 2018 16:49:37 GMT"}], "update_date": "2018-03-06", "authors_parsed": [["Nashed", "Samer B.", ""], ["Ilstrup", "David M.", ""], ["Biswas", "Joydeep", ""]]}, {"id": "1803.01403", "submitter": "Swen Gaudl", "authors": "Swen E. Gaudl, Mark J. Nelson, Simon Colton, Rob Saunders, Edward J.\n  Powley, Peter Ivey, Blanca Perez Ferrer, Michael Cook", "title": "Exploring Novel Game Spaces with Fluidic Games", "comments": "AISB: Games AI & VR, 4 pages, 4 figures, game design, tools,\n  creativity", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the growing integration of smartphones into our daily lives, and their\nincreased ease of use, mobile games have become highly popular across all\ndemographics. People listen to music, play games or read the news while in\ntransit or bridging gap times. While mobile gaming is gaining popularity,\nmobile expression of creativity is still in its early stages. We present here a\nnew type of mobile app -- fluidic games -- and illustrate our iterative\napproach to their design. This new type of app seamlessly integrates\nexploration of the design space into the actual user experience of playing the\ngame, and aims to enrich the user experience. To better illustrate the game\ndomain and our approach, we discuss one specific fluidic game, which is\navailable as a commercial product. We also briefly discuss open challenges such\nas player support and how generative techniques can aid the exploration of the\ngame space further.\n", "versions": [{"version": "v1", "created": "Sun, 4 Mar 2018 18:58:07 GMT"}], "update_date": "2018-03-06", "authors_parsed": [["Gaudl", "Swen E.", ""], ["Nelson", "Mark J.", ""], ["Colton", "Simon", ""], ["Saunders", "Rob", ""], ["Powley", "Edward J.", ""], ["Ivey", "Peter", ""], ["Ferrer", "Blanca Perez", ""], ["Cook", "Michael", ""]]}, {"id": "1803.01412", "submitter": "Mehdi Ghatee Dr.", "authors": "Shadi Abpeykar and Mehdi Ghatee", "title": "A real-time decision support system for bridge management based on the\n  rules generalized by CART decision tree and SMO algorithms", "comments": "11 pages, 5 figures, extracted form an MSc project in Department of\n  Computer Science, Amirkabir University of Technology, Tehran, Iran This paper\n  has been accepted for publication in AUT Journal of Mathematics and Computing\n  (AJMC), http://ajmc.aut.ac.ir/, 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Under dynamic conditions on bridges, we need a real-time management. To this\nend, this paper presents a rule-based decision support system in which the\nnecessary rules are extracted from simulation results made by Aimsun traffic\nmicro-simulation software. Then, these rules are generalized by the aid of\nfuzzy rule generation algorithms. Then, they are trained by a set of supervised\nand the unsupervised learning algorithms to get an ability to make decision in\nreal cases. As a pilot case study, Nasr Bridge in Tehran is simulated in Aimsun\nand WEKA data mining software is used to execute the learning algorithms. Based\non this experiment, the accuracy of the supervised algorithms to generalize the\nrules is greater than 80%. In addition, CART decision tree and sequential\nminimal optimization (SMO) provides 100% accuracy for normal data and these\nalgorithms are so reliable for crisis management on bridge. This means that, it\nis possible to use such machine learning methods to manage bridges in the\nreal-time conditions.\n", "versions": [{"version": "v1", "created": "Sun, 4 Mar 2018 20:10:01 GMT"}, {"version": "v2", "created": "Sat, 30 Jun 2018 14:58:08 GMT"}], "update_date": "2018-07-03", "authors_parsed": [["Abpeykar", "Shadi", ""], ["Ghatee", "Mehdi", ""]]}, {"id": "1803.01422", "submitter": "Bryon Aragam", "authors": "Xun Zheng, Bryon Aragam, Pradeep Ravikumar, Eric P. Xing", "title": "DAGs with NO TEARS: Continuous Optimization for Structure Learning", "comments": "22 pages, 8 figures, accepted to NIPS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Estimating the structure of directed acyclic graphs (DAGs, also known as\nBayesian networks) is a challenging problem since the search space of DAGs is\ncombinatorial and scales superexponentially with the number of nodes. Existing\napproaches rely on various local heuristics for enforcing the acyclicity\nconstraint. In this paper, we introduce a fundamentally different strategy: We\nformulate the structure learning problem as a purely \\emph{continuous}\noptimization problem over real matrices that avoids this combinatorial\nconstraint entirely. This is achieved by a novel characterization of acyclicity\nthat is not only smooth but also exact. The resulting problem can be\nefficiently solved by standard numerical algorithms, which also makes\nimplementation effortless. The proposed method outperforms existing ones,\nwithout imposing any structural assumptions on the graph such as bounded\ntreewidth or in-degree. Code implementing the proposed algorithm is open-source\nand publicly available at https://github.com/xunzheng/notears.\n", "versions": [{"version": "v1", "created": "Sun, 4 Mar 2018 21:09:13 GMT"}, {"version": "v2", "created": "Sat, 3 Nov 2018 01:29:29 GMT"}], "update_date": "2018-11-06", "authors_parsed": [["Zheng", "Xun", ""], ["Aragam", "Bryon", ""], ["Ravikumar", "Pradeep", ""], ["Xing", "Eric P.", ""]]}, {"id": "1803.01468", "submitter": "EPTCS", "authors": "Ludovic Font (\\'Ecole Polytechnique de Montr\\'eal), Philippe R.\n  Richard (Universit\\'e de Montr\\'eal), Michel Gagnon (\\'Ecole Polytechnique de\n  Montr\\'eal)", "title": "Improving QED-Tutrix by Automating the Generation of Proofs", "comments": "In Proceedings ThEdu'17, arXiv:1803.00722", "journal-ref": "EPTCS 267, 2018, pp. 38-58", "doi": "10.4204/EPTCS.267.3", "report-no": null, "categories": "cs.AI cs.CY cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The idea of assisting teachers with technological tools is not new.\nMathematics in general, and geometry in particular, provide interesting\nchallenges when developing educative softwares, both in the education and\ncomputer science aspects. QED-Tutrix is an intelligent tutor for geometry\noffering an interface to help high school students in the resolution of\ndemonstration problems. It focuses on specific goals: 1) to allow the student\nto freely explore the problem and its figure, 2) to accept proofs elements in\nany order, 3) to handle a variety of proofs, which can be customized by the\nteacher, and 4) to be able to help the student at any step of the resolution of\nthe problem, if the need arises. The software is also independent from the\nintervention of the teacher. QED-Tutrix offers an interesting approach to\ngeometry education, but is currently crippled by the lengthiness of the process\nof implementing new problems, a task that must still be done manually.\nTherefore, one of the main focuses of the QED-Tutrix' research team is to ease\nthe implementation of new problems, by automating the tedious step of finding\nall possible proofs for a given problem. This automation must follow\nfundamental constraints in order to create problems compatible with QED-Tutrix:\n1) readability of the proofs, 2) accessibility at a high school level, and 3)\npossibility for the teacher to modify the parameters defining the\n\"acceptability\" of a proof. We present in this paper the result of our\npreliminary exploration of possible avenues for this task. Automated theorem\nproving in geometry is a widely studied subject, and various provers exist.\nHowever, our constraints are quite specific and some adaptation would be\nrequired to use an existing prover. We have therefore implemented a prototype\nof automated prover to suit our needs. The future goal is to compare\nperformances and usability in our specific use-case between the existing\nprovers and our implementation.\n", "versions": [{"version": "v1", "created": "Mon, 5 Mar 2018 02:46:13 GMT"}], "update_date": "2018-03-06", "authors_parsed": [["Font", "Ludovic", "", "\u00c9cole Polytechnique de Montr\u00e9al"], ["Richard", "Philippe R.", "", "Universit\u00e9 de Montr\u00e9al"], ["Gagnon", "Michel", "", "\u00c9cole Polytechnique de\n  Montr\u00e9al"]]}, {"id": "1803.01489", "submitter": "Ahmed Hefny", "authors": "Ahmed Hefny, Zita Marinho, Wen Sun, Siddhartha Srinivasa, Geoffrey\n  Gordon", "title": "Recurrent Predictive State Policy Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce Recurrent Predictive State Policy (RPSP) networks, a recurrent\narchitecture that brings insights from predictive state representations to\nreinforcement learning in partially observable environments. Predictive state\npolicy networks consist of a recursive filter, which keeps track of a belief\nabout the state of the environment, and a reactive policy that directly maps\nbeliefs to actions, to maximize the cumulative reward. The recursive filter\nleverages predictive state representations (PSRs) (Rosencrantz and Gordon,\n2004; Sun et al., 2016) by modeling predictive state-- a prediction of the\ndistribution of future observations conditioned on history and future actions.\nThis representation gives rise to a rich class of statistically consistent\nalgorithms (Hefny et al., 2018) to initialize the recursive filter. Predictive\nstate serves as an equivalent representation of a belief state. Therefore, the\npolicy component of the RPSP-network can be purely reactive, simplifying\ntraining while still allowing optimal behaviour. Moreover, we use the PSR\ninterpretation during training as well, by incorporating prediction error in\nthe loss function. The entire network (recursive filter and reactive policy) is\nstill differentiable and can be trained using gradient based methods. We\noptimize our policy using a combination of policy gradient based on rewards\n(Williams, 1992) and gradient descent based on prediction error. We show the\nefficacy of RPSP-networks under partial observability on a set of robotic\ncontrol tasks from OpenAI Gym. We empirically show that RPSP-networks perform\nwell compared with memory-preserving networks such as GRUs, as well as finite\nmemory models, being the overall best performing method.\n", "versions": [{"version": "v1", "created": "Mon, 5 Mar 2018 03:59:48 GMT"}], "update_date": "2018-03-06", "authors_parsed": [["Hefny", "Ahmed", ""], ["Marinho", "Zita", ""], ["Sun", "Wen", ""], ["Srinivasa", "Siddhartha", ""], ["Gordon", "Geoffrey", ""]]}, {"id": "1803.01571", "submitter": "Marc Aiguier", "authors": "Marc Aiguier and Jamal Atif and Isabelle Bloch and Ram\\'on\n  Pino-P\\'erez", "title": "Explanatory relations in arbitrary logics based on satisfaction systems,\n  cutting and retraction", "comments": "30 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The aim of this paper is to introduce a new framework for defining abductive\nreasoning operators based on a notion of retraction in arbitrary logics defined\nas satisfaction systems. We show how this framework leads to the design of\nexplanatory relations satisfying properties of abductive reasoning, and discuss\nits application to several logics. This extends previous work on propositional\nlogics where retraction was defined as a morphological erosion. Here weaker\nproperties are required for retraction, leading to a larger set of suitable\noperators for abduction for different logics.\n", "versions": [{"version": "v1", "created": "Mon, 5 Mar 2018 09:32:04 GMT"}], "update_date": "2018-03-06", "authors_parsed": [["Aiguier", "Marc", ""], ["Atif", "Jamal", ""], ["Bloch", "Isabelle", ""], ["Pino-P\u00e9rez", "Ram\u00f3n", ""]]}, {"id": "1803.01588", "submitter": "Risi Kondor", "authors": "Risi Kondor", "title": "N-body Networks: a Covariant Hierarchical Neural Network Architecture\n  for Learning Atomic Potentials", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe N-body networks, a neural network architecture for learning the\nbehavior and properties of complex many body physical systems. Our specific\napplication is to learn atomic potential energy surfaces for use in molecular\ndynamics simulations. Our architecture is novel in that (a) it is based on a\nhierarchical decomposition of the many body system into subsytems, (b) the\nactivations of the network correspond to the internal state of each subsystem,\n(c) the \"neurons\" in the network are constructed explicitly so as to guarantee\nthat each of the activations is covariant to rotations, (d) the neurons operate\nentirely in Fourier space, and the nonlinearities are realized by tensor\nproducts followed by Clebsch-Gordan decompositions. As part of the description\nof our network, we give a characterization of what way the weights of the\nnetwork may interact with the activations so as to ensure that the covariance\nproperty is maintained.\n", "versions": [{"version": "v1", "created": "Mon, 5 Mar 2018 10:17:01 GMT"}], "update_date": "2018-03-06", "authors_parsed": [["Kondor", "Risi", ""]]}, {"id": "1803.01648", "submitter": "Swen Gaudl", "authors": "Swen E. Gaudl", "title": "A Genetic Programming Framework for 2D Platform AI", "comments": "Genetic Programming, GP, Game AI, Agent Design, Platformer, AISB,\n  JGAP, platformerAI, symbolic learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There currently exists a wide range of techniques to model and evolve\nartificial players for games. Existing techniques range from black box neural\nnetworks to entirely hand-designed solutions. In this paper, we demonstrate the\nfeasibility of a genetic programming framework using human controller input to\nderive meaningful artificial players which can, later on, be optimised by hand.\nThe current state of the art in game character design relies heavily on human\ndesigners to manually create and edit scripts and rules for game characters. To\naddress this manual editing bottleneck, current computational intelligence\ntechniques approach the issue with fully autonomous character generators,\nreplacing most of the design process using black box solutions such as neural\nnetworks or the like. Our GP approach to this problem creates character\ncontrollers which can be further authored and developed by a designer it also\noffers designers to included their play style without the need to use a\nprogramming language. This keeps the designer in the loop while reducing\nrepetitive manual labour. Our system also provides insights into how players\nexpress themselves in games and into deriving appropriate models for\nrepresenting those insights. We present our framework, supporting findings and\nopen challenges.\n", "versions": [{"version": "v1", "created": "Mon, 5 Mar 2018 13:11:22 GMT"}], "update_date": "2018-03-06", "authors_parsed": [["Gaudl", "Swen E.", ""]]}, {"id": "1803.01690", "submitter": "Kieran Greer Dr", "authors": "Kieran Greer", "title": "New Ideas for Brain Modelling 5", "comments": null, "journal-ref": "AIMS Biophysics, Vol. 8, Issue 1, pp. 41-56, 2021", "doi": "10.3934/biophy.2021003", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes a process for combining patterns and features, to guide\na search process and make predictions. It is based on the functionality that a\nhuman brain might have, which is a highly distributed network of simple\nneuronal components that can apply some level of matching and cross-referencing\nover retrieved patterns. The process uses memory in a dynamic way and it is\ndirected through the pattern matching. The paper firstly describes the\nmechanisms for neuronal search, memory and prediction. The paper then presents\na formal language for defining cognitive processes, that is, pattern-based\nsequences and transitions. The language can define an outer framework for\nconcept sets that are linked to perform the cognitive act. The language also\nhas a mathematical basis, allowing for the rule construction to be consistent.\nNow, both static memory and dynamic process hierarchies can be built as tree\nstructures. The new information can also be used to further integrate the\ncognitive model and the ensemble-hierarchy structure becomes an essential part.\nA theory about linking can suggest that nodes in different regions link\ntogether when generally they represent the same thing.\n", "versions": [{"version": "v1", "created": "Mon, 5 Mar 2018 14:46:19 GMT"}, {"version": "v10", "created": "Sun, 29 Dec 2019 16:15:17 GMT"}, {"version": "v11", "created": "Mon, 5 Oct 2020 08:13:25 GMT"}, {"version": "v2", "created": "Mon, 23 Jul 2018 11:29:42 GMT"}, {"version": "v3", "created": "Sun, 9 Dec 2018 19:40:20 GMT"}, {"version": "v4", "created": "Wed, 2 Jan 2019 21:11:32 GMT"}, {"version": "v5", "created": "Sun, 30 Jun 2019 11:27:35 GMT"}, {"version": "v6", "created": "Sat, 3 Aug 2019 15:43:20 GMT"}, {"version": "v7", "created": "Fri, 9 Aug 2019 17:51:41 GMT"}, {"version": "v8", "created": "Tue, 5 Nov 2019 15:58:38 GMT"}, {"version": "v9", "created": "Wed, 6 Nov 2019 09:53:23 GMT"}], "update_date": "2021-01-05", "authors_parsed": [["Greer", "Kieran", ""]]}, {"id": "1803.01798", "submitter": "Xintao Wu", "authors": "Panpan Zheng and Shuhan Yuan and Xintao Wu and Jun Li and Aidong Lu", "title": "One-Class Adversarial Nets for Fraud Detection", "comments": "Update Fig 2, add Fig 7, and add references", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many online applications, such as online social networks or knowledge bases,\nare often attacked by malicious users who commit different types of actions\nsuch as vandalism on Wikipedia or fraudulent reviews on eBay. Currently, most\nof the fraud detection approaches require a training dataset that contains\nrecords of both benign and malicious users. However, in practice, there are\noften no or very few records of malicious users. In this paper, we develop\none-class adversarial nets (OCAN) for fraud detection using training data with\nonly benign users. OCAN first uses LSTM-Autoencoder to learn the\nrepresentations of benign users from their sequences of online activities. It\nthen detects malicious users by training a discriminator with a complementary\nGAN model that is different from the regular GAN model. Experimental results\nshow that our OCAN outperforms the state-of-the-art one-class classification\nmodels and achieves comparable performance with the latest multi-source LSTM\nmodel that requires both benign and malicious users in the training phase.\n", "versions": [{"version": "v1", "created": "Mon, 5 Mar 2018 17:40:24 GMT"}, {"version": "v2", "created": "Tue, 5 Jun 2018 19:56:53 GMT"}], "update_date": "2018-06-07", "authors_parsed": [["Zheng", "Panpan", ""], ["Yuan", "Shuhan", ""], ["Wu", "Xintao", ""], ["Li", "Jun", ""], ["Lu", "Aidong", ""]]}, {"id": "1803.01842", "submitter": "Ahmed Fadhil", "authors": "Ahmed Fadhil", "title": "Towards Automatic & Personalised Mobile Health Interventions: An\n  Interactive Machine Learning Perspective", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.HC", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Machine learning (ML) is the fastest growing field in computer science and\nhealthcare, providing future benefits in improved medical diagnoses, disease\nanalyses and prevention. In this paper, we introduce an application of\ninteractive machine learning (iML) in a telemedicine system, to enable\nautomatic and personalised interventions for lifestyle promotion. We first\npresent the high level architecture of the system and the components forming\nthe overall architecture. We then illustrate the interactive machine learning\nprocess design. Prediction models are expected to be trained through the\nparticipants' profiles, activity performance, and feedback from the caregiver.\nFinally, we show some preliminary results during the system implementation and\ndiscuss future directions. We envisage the proposed system to be digitally\nimplemented, and behaviourally designed to promote healthy lifestyle and\nactivities, and hence prevent users from the risk of chronic diseases.\n", "versions": [{"version": "v1", "created": "Sat, 3 Mar 2018 10:30:56 GMT"}], "update_date": "2018-03-07", "authors_parsed": [["Fadhil", "Ahmed", ""]]}, {"id": "1803.01901", "submitter": "Xintao Wu", "authors": "Yongkai Wu and Lu Zhang and Xintao Wu", "title": "On Discrimination Discovery and Removal in Ranked Data using Causal\n  Graph", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Predictive models learned from historical data are widely used to help\ncompanies and organizations make decisions. However, they may digitally\nunfairly treat unwanted groups, raising concerns about fairness and\ndiscrimination. In this paper, we study the fairness-aware ranking problem\nwhich aims to discover discrimination in ranked datasets and reconstruct the\nfair ranking. Existing methods in fairness-aware ranking are mainly based on\nstatistical parity that cannot measure the true discriminatory effect since\ndiscrimination is causal. On the other hand, existing methods in causal-based\nanti-discrimination learning focus on classification problems and cannot be\ndirectly applied to handle the ranked data. To address these limitations, we\npropose to map the rank position to a continuous score variable that represents\nthe qualification of the candidates. Then, we build a causal graph that\nconsists of both the discrete profile attributes and the continuous score. The\npath-specific effect technique is extended to the mixed-variable causal graph\nto identify both direct and indirect discrimination. The relationship between\nthe path-specific effects for the ranked data and those for the binary decision\nis theoretically analyzed. Finally, algorithms for discovering and removing\ndiscrimination from a ranked dataset are developed. Experiments using the real\ndataset show the effectiveness of our approaches.\n", "versions": [{"version": "v1", "created": "Mon, 5 Mar 2018 19:53:40 GMT"}], "update_date": "2018-03-07", "authors_parsed": [["Wu", "Yongkai", ""], ["Zhang", "Lu", ""], ["Wu", "Xintao", ""]]}, {"id": "1803.01937", "submitter": "Kavita Ganesan", "authors": "Kavita Ganesan", "title": "ROUGE 2.0: Updated and Improved Measures for Evaluation of Summarization\n  Tasks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Evaluation of summarization tasks is extremely crucial to determining the\nquality of machine generated summaries. Over the last decade, ROUGE has become\nthe standard automatic evaluation measure for evaluating summarization tasks.\nWhile ROUGE has been shown to be effective in capturing n-gram overlap between\nsystem and human composed summaries, there are several limitations with the\nexisting ROUGE measures in terms of capturing synonymous concepts and coverage\nof topics. Thus, often times ROUGE scores do not reflect the true quality of\nsummaries and prevents multi-faceted evaluation of summaries (i.e. by topics,\nby overall content coverage and etc). In this paper, we introduce ROUGE 2.0,\nwhich has several updated measures of ROUGE: ROUGE-N+Synonyms, ROUGE-Topic,\nROUGE-Topic+Synonyms, ROUGE-TopicUniq and ROUGE-TopicUniq+Synonyms; all of\nwhich are improvements over the core ROUGE measures.\n", "versions": [{"version": "v1", "created": "Mon, 5 Mar 2018 21:35:04 GMT"}], "update_date": "2018-03-07", "authors_parsed": [["Ganesan", "Kavita", ""]]}, {"id": "1803.02018", "submitter": "Siyuan Qi", "authors": "Siyuan Qi, Song-Chun Zhu", "title": "Intent-aware Multi-agent Reinforcement Learning", "comments": "ICRA 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes an intent-aware multi-agent planning framework as well as\na learning algorithm. Under this framework, an agent plans in the goal space to\nmaximize the expected utility. The planning process takes the belief of other\nagents' intents into consideration. Instead of formulating the learning problem\nas a partially observable Markov decision process (POMDP), we propose a simple\nbut effective linear function approximation of the utility function. It is\nbased on the observation that for humans, other people's intents will pose an\ninfluence on our utility for a goal. The proposed framework has several major\nadvantages: i) it is computationally feasible and guaranteed to converge. ii)\nIt can easily integrate existing intent prediction and low-level planning\nalgorithms. iii) It does not suffer from sparse feedbacks in the action space.\nWe experiment our algorithm in a real-world problem that is non-episodic, and\nthe number of agents and goals can vary over time. Our algorithm is trained in\na scene in which aerial robots and humans interact, and tested in a novel scene\nwith a different environment. Experimental results show that our algorithm\nachieves the best performance and human-like behaviors emerge during the\ndynamic process.\n", "versions": [{"version": "v1", "created": "Tue, 6 Mar 2018 04:53:50 GMT"}], "update_date": "2018-03-07", "authors_parsed": [["Qi", "Siyuan", ""], ["Zhu", "Song-Chun", ""]]}, {"id": "1803.02088", "submitter": "David Robb", "authors": "Francisco J. Chiyah Garcia, David A. Robb, Xingkun Liu, Atanas Laskov,\n  Pedro Patron and Helen Hastie", "title": "Explain Yourself: A Natural Language Interface for Scrutable Autonomous\n  Robots", "comments": "2 pages. Peer reviewed position paper accepted in the Explainable\n  Robotic Systems Workshop, ACM Human-Robot Interaction conference, March 2018,\n  Chicago, IL USA", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Autonomous systems in remote locations have a high degree of autonomy and\nthere is a need to explain what they are doing and why in order to increase\ntransparency and maintain trust. Here, we describe a natural language chat\ninterface that enables vehicle behaviour to be queried by the user. We obtain\nan interpretable model of autonomy through having an expert 'speak out-loud'\nand provide explanations during a mission. This approach is agnostic to the\ntype of autonomy model and as expert and operator are from the same user-group,\nwe predict that these explanations will align well with the operator's mental\nmodel, increase transparency and assist with operator training.\n", "versions": [{"version": "v1", "created": "Tue, 6 Mar 2018 10:13:29 GMT"}], "update_date": "2018-03-07", "authors_parsed": [["Garcia", "Francisco J. Chiyah", ""], ["Robb", "David A.", ""], ["Liu", "Xingkun", ""], ["Laskov", "Atanas", ""], ["Patron", "Pedro", ""], ["Hastie", "Helen", ""]]}, {"id": "1803.02096", "submitter": "Maarten Bieshaar", "authors": "G\\\"unther Reitberger and Stefan Zernetsch and Maarten Bieshaar and\n  Bernhard Sick and Konrad Doll and Erich Fuchs", "title": "Cooperative Tracking of Cyclists Based on Smart Devices and\n  Infrastructure", "comments": "7 pages, 6 figures. submitted (accepted for publication) IEEE\n  Conference on Intelligent Transportation Systems(ITSC) 2018, Maui, HI", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In future traffic scenarios, vehicles and other traffic participants will be\ninterconnected and equipped with various types of sensors, allowing for\ncooperation based on data or information exchange. This article presents an\napproach to cooperative tracking of cyclists using smart devices and\ninfrastructure-based sensors. A smart device is carried by the cyclists and an\nintersection is equipped with a wide angle stereo camera system. Two tracking\nmodels are presented and compared. The first model is based on the stereo\ncamera system detections only, whereas the second model cooperatively combines\nthe camera based detections with velocity and yaw rate data provided by the\nsmart device. Our aim is to overcome limitations of tracking approaches based\non single data sources. We show in numerical evaluations on scenes where\ncyclists are starting or turning right that the cooperation leads to an\nimprovement in both the ability to keep track of a cyclist and the accuracy of\nthe track particularly when it comes to occlusions in the visual system. We,\ntherefore, contribute to the safety of vulnerable road users in future traffic.\n", "versions": [{"version": "v1", "created": "Tue, 6 Mar 2018 10:33:35 GMT"}, {"version": "v2", "created": "Tue, 3 Jul 2018 08:13:51 GMT"}], "update_date": "2018-07-04", "authors_parsed": [["Reitberger", "G\u00fcnther", ""], ["Zernetsch", "Stefan", ""], ["Bieshaar", "Maarten", ""], ["Sick", "Bernhard", ""], ["Doll", "Konrad", ""], ["Fuchs", "Erich", ""]]}, {"id": "1803.02097", "submitter": "Maarten Bieshaar", "authors": "Maarten Bieshaar", "title": "Where is my Device? - Detecting the Smart Device's Wearing Location in\n  the Context of Active Safety for Vulnerable Road Users", "comments": "10 pages, 3 figures, accepted for publication in Organic Computing:\n  Doctoral Dissertation Colloquium 2017. Volume 11 of Intelligent Embedded\n  Systems. Kassel University Press, Kassel", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article describes an approach to detect the wearing location of smart\ndevices worn by pedestrians and cyclists. The detection, which is based solely\non the sensors of the smart devices, is important context-information which can\nbe used to parametrize subsequent algorithms, e.g. for dead reckoning or\nintention detection to improve the safety of vulnerable road users. The wearing\nlocation recognition can in terms of Organic Computing (OC) be seen as a step\ntowards self-awareness and self-adaptation. For the wearing location detection\na two-stage process is presented. It is subdivided into moving detection\nfollowed by the wearing location classification. Finally, the approach is\nevaluated on a real world dataset consisting of pedestrians and cyclists.\n", "versions": [{"version": "v1", "created": "Tue, 6 Mar 2018 10:34:47 GMT"}], "update_date": "2018-03-07", "authors_parsed": [["Bieshaar", "Maarten", ""]]}, {"id": "1803.02100", "submitter": "David Robb", "authors": "Helen Hastie, Katrin Lohan, Mike Chantler, David A. Robb, Subramanian\n  Ramamoorthy, Ron Petrick, Sethu Vijayakumar and David Lane", "title": "The ORCA Hub: Explainable Offshore Robotics through Intelligent\n  Interfaces", "comments": "2 pages. Peer reviewed position paper accepted in the Explainable\n  Robotic Systems Workshop, ACM Human-Robot Interaction conference, March 2018,\n  Chicago, IL USA", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.HC cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present the UK Robotics and Artificial Intelligence Hub for Offshore\nRobotics for Certification of Assets (ORCA Hub), a 3.5 year EPSRC funded,\nmulti-site project. The ORCA Hub vision is to use teams of robots and\nautonomous intelligent systems (AIS) to work on offshore energy platforms to\nenable cheaper, safer and more efficient working practices. The ORCA Hub will\nresearch, integrate, validate and deploy remote AIS solutions that can operate\nwith existing and future offshore energy assets and sensors, interacting safely\nin autonomous or semi-autonomous modes in complex and cluttered environments,\nco-operating with remote operators. The goal is that through the use of such\nrobotic systems offshore, the need for personnel will decrease. To enable this\nto happen, the remote operator will need a high level of situation awareness\nand key to this is the transparency of what the autonomous systems are doing\nand why. This increased transparency will facilitate a trusting relationship,\nwhich is particularly key in high-stakes, hazardous situations.\n", "versions": [{"version": "v1", "created": "Tue, 6 Mar 2018 10:43:38 GMT"}], "update_date": "2018-03-07", "authors_parsed": [["Hastie", "Helen", ""], ["Lohan", "Katrin", ""], ["Chantler", "Mike", ""], ["Robb", "David A.", ""], ["Ramamoorthy", "Subramanian", ""], ["Petrick", "Ron", ""], ["Vijayakumar", "Sethu", ""], ["Lane", "David", ""]]}, {"id": "1803.02124", "submitter": "David Robb", "authors": "Helen Hastie, Francisco J. Chiyah Garcia, David A. Robb, Pedro Patron\n  and Atanas Laskov", "title": "MIRIAM: A Multimodal Chat-Based Interface for Autonomous Systems", "comments": "2 pages, ICMI'17, 19th ACM International Conference on Multimodal\n  Interaction, November 13-17 2017, Glasgow, UK", "journal-ref": null, "doi": "10.1145/3136755.3143022", "report-no": null, "categories": "cs.AI cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present MIRIAM (Multimodal Intelligent inteRactIon for Autonomous\nsysteMs), a multimodal interface to support situation awareness of autonomous\nvehicles through chat-based interaction. The user is able to chat about the\nvehicle's plan, objectives, previous activities and mission progress. The\nsystem is mixed initiative in that it pro-actively sends messages about key\nevents, such as fault warnings. We will demonstrate MIRIAM using SeeByte's\nSeeTrack command and control interface and Neptune autonomy simulator.\n", "versions": [{"version": "v1", "created": "Tue, 6 Mar 2018 11:33:04 GMT"}], "update_date": "2018-03-07", "authors_parsed": [["Hastie", "Helen", ""], ["Garcia", "Francisco J. Chiyah", ""], ["Robb", "David A.", ""], ["Patron", "Pedro", ""], ["Laskov", "Atanas", ""]]}, {"id": "1803.02208", "submitter": "Yantian Zha", "authors": "Hankz Hankui Zhuo, Yantian Zha, Subbarao Kambhampati", "title": "Discovering Underlying Plans Based on Shallow Models", "comments": "arXiv admin note: substantial text overlap with arXiv:1511.05662", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Plan recognition aims to discover target plans (i.e., sequences of actions)\nbehind observed actions, with history plan libraries or domain models in hand.\nPrevious approaches either discover plans by maximally \"matching\" observed\nactions to plan libraries, assuming target plans are from plan libraries, or\ninfer plans by executing domain models to best explain the observed actions,\nassuming that complete domain models are available. In real world applications,\nhowever, target plans are often not from plan libraries, and complete domain\nmodels are often not available, since building complete sets of plans and\ncomplete domain models are often difficult or expensive. In this paper we view\nplan libraries as corpora and learn vector representations of actions using the\ncorpora, we then discover target plans based on the vector representations.\nSpecifically, we propose two approaches, DUP and RNNPlanner, to discover target\nplans based on vector representations of actions. DUP explores the EM-style\nframework to capture local contexts of actions and discover target plans by\noptimizing the probability of target plans, while RNNPlanner aims to leverage\nlong-short term contexts of actions based on RNNs (recurrent neural networks)\nframework to help recognize target plans. In the experiments, we empirically\nshow that our approaches are capable of discovering underlying plans that are\nnot from plan libraries, without requiring domain models provided. We\ndemonstrate the effectiveness of our approaches by comparing its performance to\ntraditional plan recognition approaches in three planning domains. We also\ncompare DUP and RNNPlanner to see their advantages and disadvantages.\n", "versions": [{"version": "v1", "created": "Sun, 4 Mar 2018 03:18:22 GMT"}], "update_date": "2018-03-07", "authors_parsed": [["Zhuo", "Hankz Hankui", ""], ["Zha", "Yantian", ""], ["Kambhampati", "Subbarao", ""]]}, {"id": "1803.02232", "submitter": "Suttinee Sawadsitang", "authors": "Suttinee Sawadsitang, Siwei Jiang, Dusit Niyato, Ping Wang", "title": "Optimal Stochastic Package Delivery Planning with Deadline: A\n  Cardinality Minimization in Routing", "comments": "7 pages, 6 figures, Vehicular Technology Conference (VTC fall), 2017\n  IEEE 86th", "journal-ref": null, "doi": "10.1109/VTCFall.2017.8288239", "report-no": null, "categories": "cs.AI math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Vehicle Routing Problem with Private fleet and common Carrier (VRPPC) has\nbeen proposed to help a supplier manage package delivery services from a single\ndepot to multiple customers. Most of the existing VRPPC works consider\ndeterministic parameters which may not be practical and uncertainty has to be\ntaken into account. In this paper, we propose the Optimal Stochastic Delivery\nPlanning with Deadline (ODPD) to help a supplier plan and optimize the package\ndelivery. The aim of ODPD is to service all customers within a given deadline\nwhile considering the randomness in customer demands and traveling time. We\nformulate the ODPD as a stochastic integer programming, and use the cardinality\nminimization approach for calculating the deadline violation probability. To\naccelerate computation, the L-shaped decomposition method is adopted. We\nconduct extensive performance evaluation based on real customer locations and\ntraveling time from Google Map.\n", "versions": [{"version": "v1", "created": "Wed, 28 Feb 2018 02:01:43 GMT"}], "update_date": "2018-05-21", "authors_parsed": [["Sawadsitang", "Suttinee", ""], ["Jiang", "Siwei", ""], ["Niyato", "Dusit", ""], ["Wang", "Ping", ""]]}, {"id": "1803.02291", "submitter": "Juan Camilo Gamboa Higuera", "authors": "Juan Camilo Gamboa Higuera and David Meger and Gregory Dudek", "title": "Synthesizing Neural Network Controllers with Probabilistic Model based\n  Reinforcement Learning", "comments": "8 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We present an algorithm for rapidly learning controllers for robotics\nsystems. The algorithm follows the model-based reinforcement learning paradigm,\nand improves upon existing algorithms; namely Probabilistic learning in Control\n(PILCO) and a sample-based version of PILCO with neural network dynamics\n(Deep-PILCO). We propose training a neural network dynamics model using\nvariational dropout with truncated Log-Normal noise. This allows us to obtain a\ndynamics model with calibrated uncertainty, which can be used to simulate\ncontroller executions via rollouts. We also describe set of techniques,\ninspired by viewing PILCO as a recurrent neural network model, that are crucial\nto improve the convergence of the method. We test our method on a variety of\nbenchmark tasks, demonstrating data-efficiency that is competitive with PILCO,\nwhile being able to optimize complex neural network controllers. Finally, we\nassess the performance of the algorithm for learning motor controllers for a\nsix legged autonomous underwater vehicle. This demonstrates the potential of\nthe algorithm for scaling up the dimensionality and dataset sizes, in more\ncomplex control tasks.\n", "versions": [{"version": "v1", "created": "Tue, 6 Mar 2018 16:42:46 GMT"}, {"version": "v2", "created": "Fri, 27 Jul 2018 22:06:43 GMT"}, {"version": "v3", "created": "Wed, 1 Aug 2018 14:39:13 GMT"}], "update_date": "2018-08-02", "authors_parsed": [["Higuera", "Juan Camilo Gamboa", ""], ["Meger", "David", ""], ["Dudek", "Gregory", ""]]}, {"id": "1803.02324", "submitter": "Suchin Gururangan", "authors": "Suchin Gururangan, Swabha Swayamdipta, Omer Levy, Roy Schwartz, Samuel\n  R. Bowman, Noah A. Smith", "title": "Annotation Artifacts in Natural Language Inference Data", "comments": "6 pages, 1 figure, NAACL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Large-scale datasets for natural language inference are created by presenting\ncrowd workers with a sentence (premise), and asking them to generate three new\nsentences (hypotheses) that it entails, contradicts, or is logically neutral\nwith respect to. We show that, in a significant portion of such data, this\nprotocol leaves clues that make it possible to identify the label by looking\nonly at the hypothesis, without observing the premise. Specifically, we show\nthat a simple text categorization model can correctly classify the hypothesis\nalone in about 67% of SNLI (Bowman et. al, 2015) and 53% of MultiNLI (Williams\net. al, 2017). Our analysis reveals that specific linguistic phenomena such as\nnegation and vagueness are highly correlated with certain inference classes.\nOur findings suggest that the success of natural language inference models to\ndate has been overestimated, and that the task remains a hard open problem.\n", "versions": [{"version": "v1", "created": "Tue, 6 Mar 2018 18:23:08 GMT"}, {"version": "v2", "created": "Mon, 16 Apr 2018 22:14:06 GMT"}], "update_date": "2018-04-18", "authors_parsed": [["Gururangan", "Suchin", ""], ["Swayamdipta", "Swabha", ""], ["Levy", "Omer", ""], ["Schwartz", "Roy", ""], ["Bowman", "Samuel R.", ""], ["Smith", "Noah A.", ""]]}, {"id": "1803.02348", "submitter": "Ofir Nachum", "authors": "Ofir Nachum, Mohammad Norouzi, George Tucker, Dale Schuurmans", "title": "Smoothed Action Value Functions for Learning Gaussian Policies", "comments": "ICML 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  State-action value functions (i.e., Q-values) are ubiquitous in reinforcement\nlearning (RL), giving rise to popular algorithms such as SARSA and Q-learning.\nWe propose a new notion of action value defined by a Gaussian smoothed version\nof the expected Q-value. We show that such smoothed Q-values still satisfy a\nBellman equation, making them learnable from experience sampled from an\nenvironment. Moreover, the gradients of expected reward with respect to the\nmean and covariance of a parameterized Gaussian policy can be recovered from\nthe gradient and Hessian of the smoothed Q-value function. Based on these\nrelationships, we develop new algorithms for training a Gaussian policy\ndirectly from a learned smoothed Q-value approximator. The approach is\nadditionally amenable to proximal optimization by augmenting the objective with\na penalty on KL-divergence from a previous policy. We find that the ability to\nlearn both a mean and covariance during training leads to significantly\nimproved results on standard continuous control benchmarks.\n", "versions": [{"version": "v1", "created": "Tue, 6 Mar 2018 04:58:20 GMT"}, {"version": "v2", "created": "Mon, 11 Jun 2018 22:56:38 GMT"}, {"version": "v3", "created": "Wed, 25 Jul 2018 17:07:23 GMT"}], "update_date": "2018-07-26", "authors_parsed": [["Nachum", "Ofir", ""], ["Norouzi", "Mohammad", ""], ["Tucker", "George", ""], ["Schuurmans", "Dale", ""]]}, {"id": "1803.02349", "submitter": "Jizhe Wang", "authors": "Jizhe Wang, Pipei Huang, Huan Zhao, Zhibo Zhang, Binqiang Zhao, Dik\n  Lun Lee", "title": "Billion-scale Commodity Embedding for E-commerce Recommendation in\n  Alibaba", "comments": "10 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recommender systems (RSs) have been the most important technology for\nincreasing the business in Taobao, the largest online consumer-to-consumer\n(C2C) platform in China. The billion-scale data in Taobao creates three major\nchallenges to Taobao's RS: scalability, sparsity and cold start. In this paper,\nwe present our technical solutions to address these three challenges. The\nmethods are based on the graph embedding framework. We first construct an item\ngraph from users' behavior history. Each item is then represented as a vector\nusing graph embedding. The item embeddings are employed to compute pairwise\nsimilarities between all items, which are then used in the recommendation\nprocess. To alleviate the sparsity and cold start problems, side information is\nincorporated into the embedding framework. We propose two aggregation methods\nto integrate the embeddings of items and the corresponding side information.\nExperimental results from offline experiments show that methods incorporating\nside information are superior to those that do not. Further, we describe the\nplatform upon which the embedding methods are deployed and the workflow to\nprocess the billion-scale data in Taobao. Using online A/B test, we show that\nthe online Click-Through-Rate (CTRs) are improved comparing to the previous\nrecommendation methods widely used in Taobao, further demonstrating the\neffectiveness and feasibility of our proposed methods in Taobao's live\nproduction environment.\n", "versions": [{"version": "v1", "created": "Tue, 6 Mar 2018 05:20:14 GMT"}, {"version": "v2", "created": "Thu, 24 May 2018 06:03:31 GMT"}], "update_date": "2018-05-25", "authors_parsed": [["Wang", "Jizhe", ""], ["Huang", "Pipei", ""], ["Zhao", "Huan", ""], ["Zhang", "Zhibo", ""], ["Zhao", "Binqiang", ""], ["Lee", "Dik Lun", ""]]}, {"id": "1803.02476", "submitter": "Sergio Miguel Tom\\'e", "authors": "Sergio Miguel-Tom\\'e", "title": "Decision-making processes in the Cognitive Theory of True Conditions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Cognitive Theory of True Conditions (CTTC) is a proposal to design the\nimplementation of cognitive abilities and to describe the model-theoretic\nsemantics of symbolic cognitive architectures. The CTTC is formulated\nmathematically using the multi-optional many-sorted past present future(MMPPF)\nstructures. This article discussed how decision-making processes are described\nin the CTTC.\n", "versions": [{"version": "v1", "created": "Tue, 6 Mar 2018 23:46:55 GMT"}], "update_date": "2018-03-08", "authors_parsed": [["Miguel-Tom\u00e9", "Sergio", ""]]}, {"id": "1803.02509", "submitter": "Yen-lung Tsai", "authors": "Tse-Yu Lin and Yen-Lung Tsai", "title": "An Application of HodgeRank to Online Peer Assessment", "comments": "7 pages. To appear in MLRec 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bias and heterogeneity in peer assessment can lead to the issue of unfair\nscoring in the educational field. To deal with this problem, we propose a\nreference ranking method for an online peer assessment system using HodgeRank.\nSuch a scheme provides instructors with an objective scoring reference based on\nmathematics.\n", "versions": [{"version": "v1", "created": "Wed, 7 Mar 2018 02:53:54 GMT"}], "update_date": "2018-03-08", "authors_parsed": [["Lin", "Tse-Yu", ""], ["Tsai", "Yen-Lung", ""]]}, {"id": "1803.02544", "submitter": "Chengliang Yang", "authors": "Chengliang Yang, Anand Rangarajan, Sanjay Ranka", "title": "Visual Explanations From Deep 3D Convolutional Neural Networks for\n  Alzheimer's Disease Classification", "comments": "Accepted by 2018 American Medical Informatics Association Annual\n  Symposium (AMIA2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop three efficient approaches for generating visual explanations from\n3D convolutional neural networks (3D-CNNs) for Alzheimer's disease\nclassification. One approach conducts sensitivity analysis on hierarchical 3D\nimage segmentation, and the other two visualize network activations on a\nspatial map. Visual checks and a quantitative localization benchmark indicate\nthat all approaches identify important brain parts for Alzheimer's disease\ndiagnosis. Comparative analysis show that the sensitivity analysis based\napproach has difficulty handling loosely distributed cerebral cortex, and\napproaches based on visualization of activations are constrained by the\nresolution of the convolutional layer. The complementarity of these methods\nimproves the understanding of 3D-CNNs in Alzheimer's disease classification\nfrom different perspectives.\n", "versions": [{"version": "v1", "created": "Wed, 7 Mar 2018 07:07:39 GMT"}, {"version": "v2", "created": "Thu, 8 Mar 2018 01:29:14 GMT"}, {"version": "v3", "created": "Fri, 6 Jul 2018 00:28:49 GMT"}], "update_date": "2018-07-09", "authors_parsed": [["Yang", "Chengliang", ""], ["Rangarajan", "Anand", ""], ["Ranka", "Sanjay", ""]]}, {"id": "1803.02590", "submitter": "Wenyu Du", "authors": "Wenyu Du, Shuai Yu, Min Yang, Qiang Qu, Jia Zhu", "title": "GPSP: Graph Partition and Space Projection based Approach for\n  Heterogeneous Network Embedding", "comments": "WWW 2018 Poster", "journal-ref": null, "doi": "10.1145/3184558.3186928", "report-no": null, "categories": "cs.SI cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose GPSP, a novel Graph Partition and Space Projection\nbased approach, to learn the representation of a heterogeneous network that\nconsists of multiple types of nodes and links. Concretely, we first partition\nthe heterogeneous network into homogeneous and bipartite subnetworks. Then, the\nprojective relations hidden in bipartite subnetworks are extracted by learning\nthe projective embedding vectors. Finally, we concatenate the projective\nvectors from bipartite subnetworks with the ones learned from homogeneous\nsubnetworks to form the final representation of the heterogeneous network.\nExtensive experiments are conducted on a real-life dataset. The results\ndemonstrate that GPSP outperforms the state-of-the-art baselines in two key\nnetwork mining tasks: node classification and clustering.\n", "versions": [{"version": "v1", "created": "Wed, 7 Mar 2018 10:54:25 GMT"}], "update_date": "2018-03-08", "authors_parsed": [["Du", "Wenyu", ""], ["Yu", "Shuai", ""], ["Yang", "Min", ""], ["Qu", "Qiang", ""], ["Zhu", "Jia", ""]]}, {"id": "1803.02627", "submitter": "Tobias Hinz", "authors": "Tobias Hinz, Stefan Wermter", "title": "Inferencing Based on Unsupervised Learning of Disentangled\n  Representations", "comments": "Accepted as a conference paper at the European Symposium on\n  Artificial Neural Networks, Computational Intelligence and Machine Learning\n  (ESANN) 2018, 6 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Combining Generative Adversarial Networks (GANs) with encoders that learn to\nencode data points has shown promising results in learning data representations\nin an unsupervised way. We propose a framework that combines an encoder and a\ngenerator to learn disentangled representations which encode meaningful\ninformation about the data distribution without the need for any labels. While\ncurrent approaches focus mostly on the generative aspects of GANs, our\nframework can be used to perform inference on both real and generated data\npoints. Experiments on several data sets show that the encoder learns\ninterpretable, disentangled representations which encode descriptive properties\nand can be used to sample images that exhibit specific characteristics.\n", "versions": [{"version": "v1", "created": "Wed, 7 Mar 2018 12:58:53 GMT"}], "update_date": "2018-03-08", "authors_parsed": [["Hinz", "Tobias", ""], ["Wermter", "Stefan", ""]]}, {"id": "1803.02632", "submitter": "Wenfeng Feng", "authors": "Wenfeng Feng, Hankz Hankui Zhuo, Subbarao Kambhampati", "title": "Extracting Action Sequences from Texts Based on Deep Reinforcement\n  Learning", "comments": "7pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Extracting action sequences from natural language texts is challenging, as it\nrequires commonsense inferences based on world knowledge. Although there has\nbeen work on extracting action scripts, instructions, navigation actions, etc.,\nthey require that either the set of candidate actions be provided in advance,\nor that action descriptions are restricted to a specific form, e.g.,\ndescription templates. In this paper, we aim to extract action sequences from\ntexts in free natural language, i.e., without any restricted templates,\nprovided the candidate set of actions is unknown. We propose to extract action\nsequences from texts based on the deep reinforcement learning framework.\nSpecifically, we view \"selecting\" or \"eliminating\" words from texts as\n\"actions\", and the texts associated with actions as \"states\". We then build\nQ-networks to learn the policy of extracting actions and extract plans from the\nlabeled texts. We demonstrate the effectiveness of our approach on several\ndatasets with comparison to state-of-the-art approaches, including online\nexperiments interacting with humans.\n", "versions": [{"version": "v1", "created": "Wed, 7 Mar 2018 13:13:16 GMT"}, {"version": "v2", "created": "Fri, 11 May 2018 15:57:08 GMT"}], "update_date": "2018-05-14", "authors_parsed": [["Feng", "Wenfeng", ""], ["Zhuo", "Hankz Hankui", ""], ["Kambhampati", "Subbarao", ""]]}, {"id": "1803.02710", "submitter": "Yikang Shen", "authors": "Yikang Shen, Shawn Tan, Chin-Wei Huang, Aaron Courville", "title": "Generating Contradictory, Neutral, and Entailing Sentences", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning distributed sentence representations remains an interesting problem\nin the field of Natural Language Processing (NLP). We want to learn a model\nthat approximates the conditional latent space over the representations of a\nlogical antecedent of the given statement. In our paper, we propose an approach\nto generating sentences, conditioned on an input sentence and a logical\ninference label. We do this by modeling the different possibilities for the\noutput sentence as a distribution over the latent representation, which we\ntrain using an adversarial objective. We evaluate the model using two\nstate-of-the-art models for the Recognizing Textual Entailment (RTE) task, and\nmeasure the BLEU scores against the actual sentences as a probe for the\ndiversity of sentences produced by our model. The experiment results show that,\ngiven our framework, we have clear ways to improve the quality and diversity of\ngenerated sentences.\n", "versions": [{"version": "v1", "created": "Wed, 7 Mar 2018 15:18:03 GMT"}], "update_date": "2018-03-08", "authors_parsed": [["Shen", "Yikang", ""], ["Tan", "Shawn", ""], ["Huang", "Chin-Wei", ""], ["Courville", "Aaron", ""]]}, {"id": "1803.02765", "submitter": "Paul Yaworsky", "authors": "Paul Yaworsky", "title": "Realizing Intelligence", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Order exists in the world. The intelligence process enables us to realize\nthat order, to some extent. We provide a high level description of intelligence\nusing simple definitions, basic building blocks, a conceptual framework and\ngeneral hierarchy. This perspective includes multiple levels of abstraction\noccurring in space and in time. The resulting model offers simple, useful ways\nto help realize the essence of intelligence.\n", "versions": [{"version": "v1", "created": "Wed, 7 Mar 2018 17:40:06 GMT"}], "update_date": "2018-03-09", "authors_parsed": [["Yaworsky", "Paul", ""]]}, {"id": "1803.02808", "submitter": "Dilek K\\\"u\\c{c}\\\"uk", "authors": "Dilek K\\\"u\\c{c}\\\"uk and Do\\u{g}an K\\\"u\\c{c}\\\"uk", "title": "OntoWind: An Improved and Extended Wind Energy Ontology", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ontologies are critical sources of semantic information for many application\ndomains. Hence, there are ontologies proposed and utilized for domains such as\nmedicine, chemical engineering, and electrical energy. In this paper, we\npresent an improved and extended version of a wind energy ontology previously\nproposed. First, the ontology is restructured to increase its understandability\nand coverage. Secondly, it is enriched with new concepts, crisp/fuzzy\nattributes, and instances to increase its usability in semantic applications\nregarding wind energy. The ultimate ontology is utilized within a Web-based\nsemantic portal application for wind energy, in order to showcase its\ncontribution in a genuine application. Hence, the current study is a\nsignificant to wind and thereby renewable energy informatics, with the\npresented publicly-available wind energy ontology and the implemented\nproof-of-concept system.\n", "versions": [{"version": "v1", "created": "Wed, 7 Mar 2018 18:34:44 GMT"}], "update_date": "2018-03-08", "authors_parsed": [["K\u00fc\u00e7\u00fck", "Dilek", ""], ["K\u00fc\u00e7\u00fck", "Do\u011fan", ""]]}, {"id": "1803.02811", "submitter": "Adam Stooke", "authors": "Adam Stooke and Pieter Abbeel", "title": "Accelerated Methods for Deep Reinforcement Learning", "comments": "v2: -Added game performance statistics summary for algorithm scaling\n  across full Atari game set. -Added full set of learning curves (appendix).\n  -Fixed images to remove phantom borders. -Streamlined some discussion, moved\n  some details to appendix", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep reinforcement learning (RL) has achieved many recent successes, yet\nexperiment turn-around time remains a key bottleneck in research and in\npractice. We investigate how to optimize existing deep RL algorithms for modern\ncomputers, specifically for a combination of CPUs and GPUs. We confirm that\nboth policy gradient and Q-value learning algorithms can be adapted to learn\nusing many parallel simulator instances. We further find it possible to train\nusing batch sizes considerably larger than are standard, without negatively\naffecting sample complexity or final performance. We leverage these facts to\nbuild a unified framework for parallelization that dramatically hastens\nexperiments in both classes of algorithm. All neural network computations use\nGPUs, accelerating both data collection and training. Our results include using\nan entire DGX-1 to learn successful strategies in Atari games in mere minutes,\nusing both synchronous and asynchronous algorithms.\n", "versions": [{"version": "v1", "created": "Wed, 7 Mar 2018 18:39:12 GMT"}, {"version": "v2", "created": "Thu, 10 Jan 2019 20:48:11 GMT"}], "update_date": "2019-01-14", "authors_parsed": [["Stooke", "Adam", ""], ["Abbeel", "Pieter", ""]]}, {"id": "1803.02815", "submitter": "Gautam Kamath", "authors": "Ilias Diakonikolas, Gautam Kamath, Daniel M. Kane, Jerry Li, Jacob\n  Steinhardt, Alistair Stewart", "title": "Sever: A Robust Meta-Algorithm for Stochastic Optimization", "comments": "To appear in ICML 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In high dimensions, most machine learning methods are brittle to even a small\nfraction of structured outliers. To address this, we introduce a new\nmeta-algorithm that can take in a base learner such as least squares or\nstochastic gradient descent, and harden the learner to be resistant to\noutliers. Our method, Sever, possesses strong theoretical guarantees yet is\nalso highly scalable -- beyond running the base learner itself, it only\nrequires computing the top singular vector of a certain $n \\times d$ matrix. We\napply Sever on a drug design dataset and a spam classification dataset, and\nfind that in both cases it has substantially greater robustness than several\nbaselines. On the spam dataset, with $1\\%$ corruptions, we achieved $7.4\\%$\ntest error, compared to $13.4\\%-20.5\\%$ for the baselines, and $3\\%$ error on\nthe uncorrupted dataset. Similarly, on the drug design dataset, with $10\\%$\ncorruptions, we achieved $1.42$ mean-squared error test error, compared to\n$1.51$-$2.33$ for the baselines, and $1.23$ error on the uncorrupted dataset.\n", "versions": [{"version": "v1", "created": "Wed, 7 Mar 2018 18:47:48 GMT"}, {"version": "v2", "created": "Wed, 29 May 2019 20:51:06 GMT"}], "update_date": "2019-05-31", "authors_parsed": [["Diakonikolas", "Ilias", ""], ["Kamath", "Gautam", ""], ["Kane", "Daniel M.", ""], ["Li", "Jerry", ""], ["Steinhardt", "Jacob", ""], ["Stewart", "Alistair", ""]]}, {"id": "1803.02839", "submitter": "Sean Cantrell", "authors": "Sean A. Cantrell", "title": "The emergent algebraic structure of RNNs and embeddings in NLP", "comments": "24 pages, 16 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We examine the algebraic and geometric properties of a uni-directional GRU\nand word embeddings trained end-to-end on a text classification task. A\nhyperparameter search over word embedding dimension, GRU hidden dimension, and\na linear combination of the GRU outputs is performed. We conclude that words\nnaturally embed themselves in a Lie group and that RNNs form a nonlinear\nrepresentation of the group. Appealing to these results, we propose a novel\nclass of recurrent-like neural networks and a word embedding scheme.\n", "versions": [{"version": "v1", "created": "Wed, 7 Mar 2018 19:06:08 GMT"}], "update_date": "2018-03-09", "authors_parsed": [["Cantrell", "Sean A.", ""]]}, {"id": "1803.02852", "submitter": "Daniel Estrada", "authors": "Daniel Estrada", "title": "Value Alignment, Fair Play, and the Rights of Service Robots", "comments": null, "journal-ref": "ACM/AIES 2018", "doi": "10.1145/3278721.3278730", "report-no": null, "categories": "cs.CY cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ethics and safety research in artificial intelligence is increasingly framed\nin terms of \"alignment\" with human values and interests. I argue that Turing's\ncall for \"fair play for machines\" is an early and often overlooked contribution\nto the alignment literature. Turing's appeal to fair play suggests a need to\ncorrect human behavior to accommodate our machines, a surprising inversion of\nhow value alignment is treated today. Reflections on \"fair play\" motivate a\nnovel interpretation of Turing's notorious \"imitation game\" as a condition not\nof intelligence but instead of value alignment: a machine demonstrates a\nminimal degree of alignment (with the norms of conversation, for instance) when\nit can go undetected when interrogated by a human. I carefully distinguish this\ninterpretation from the Moral Turing Test, which is not motivated by a\nprinciple of fair play, but instead depends on imitation of human moral\nbehavior. Finally, I consider how the framework of fair play can be used to\nsituate the debate over robot rights within the alignment literature. I argue\nthat extending rights to service robots operating in public spaces is \"fair\" in\nprecisely the sense that it encourages an alignment of interests between humans\nand machines.\n", "versions": [{"version": "v1", "created": "Wed, 7 Mar 2018 19:33:08 GMT"}], "update_date": "2018-12-07", "authors_parsed": [["Estrada", "Daniel", ""]]}, {"id": "1803.02855", "submitter": "Daniel Russo", "authors": "Daniel Russo and Benjamin Van Roy", "title": "Satisficing in Time-Sensitive Bandit Learning", "comments": "This submission largely supersedes earlier work in arXiv:1704.09028", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Much of the recent literature on bandit learning focuses on algorithms that\naim to converge on an optimal action. One shortcoming is that this orientation\ndoes not account for time sensitivity, which can play a crucial role when\nlearning an optimal action requires much more information than near-optimal\nones. Indeed, popular approaches such as upper-confidence-bound methods and\nThompson sampling can fare poorly in such situations. We consider instead\nlearning a satisficing action, which is near-optimal while requiring less\ninformation, and propose satisficing Thompson sampling, an algorithm that\nserves this purpose. We establish a general bound on expected discounted regret\nand study the application of satisficing Thompson sampling to linear and\ninfinite-armed bandits, demonstrating arbitrarily large benefits over Thompson\nsampling. We also discuss the relation between the notion of satisficing and\nthe theory of rate distortion, which offers guidance on the selection of\nsatisficing actions.\n", "versions": [{"version": "v1", "created": "Wed, 7 Mar 2018 19:41:44 GMT"}, {"version": "v2", "created": "Tue, 7 Jan 2020 19:23:18 GMT"}], "update_date": "2020-01-09", "authors_parsed": [["Russo", "Daniel", ""], ["Van Roy", "Benjamin", ""]]}, {"id": "1803.02865", "submitter": "Xiaoixa Wu", "authors": "Xiaoxia Wu and Rachel Ward and L\\'eon Bottou", "title": "WNGrad: Learn the Learning Rate in Gradient Descent", "comments": "10 pages, 3 figures, conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG cs.NA math.NA math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adjusting the learning rate schedule in stochastic gradient methods is an\nimportant unresolved problem which requires tuning in practice. If certain\nparameters of the loss function such as smoothness or strong convexity\nconstants are known, theoretical learning rate schedules can be applied.\nHowever, in practice, such parameters are not known, and the loss function of\ninterest is not convex in any case. The recently proposed batch normalization\nreparametrization is widely adopted in most neural network architectures today\nbecause, among other advantages, it is robust to the choice of Lipschitz\nconstant of the gradient in loss function, allowing one to set a large learning\nrate without worry. Inspired by batch normalization, we propose a general\nnonlinear update rule for the learning rate in batch and stochastic gradient\ndescent so that the learning rate can be initialized at a high value, and is\nsubsequently decreased according to gradient observations along the way. The\nproposed method is shown to achieve robustness to the relationship between the\nlearning rate and the Lipschitz constant, and near-optimal convergence rates in\nboth the batch and stochastic settings ($O(1/T)$ for smooth loss in the batch\nsetting, and $O(1/\\sqrt{T})$ for convex loss in the stochastic setting). We\nalso show through numerical evidence that such robustness of the proposed\nmethod extends to highly nonconvex and possibly non-smooth loss function in\ndeep learning problems.Our analysis establishes some first theoretical\nunderstanding into the observed robustness for batch normalization and weight\nnormalization.\n", "versions": [{"version": "v1", "created": "Wed, 7 Mar 2018 20:30:35 GMT"}, {"version": "v2", "created": "Thu, 19 Nov 2020 20:31:14 GMT"}], "update_date": "2020-11-23", "authors_parsed": [["Wu", "Xiaoxia", ""], ["Ward", "Rachel", ""], ["Bottou", "L\u00e9on", ""]]}, {"id": "1803.02884", "submitter": "Nils Jansen", "authors": "Murat Cubuktepe, Nils Jansen, Sebastian Junges, Joost-Pieter Katoen,\n  Ufuk Topcu", "title": "Synthesis in pMDPs: A Tale of 1001 Parameters", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper considers parametric Markov decision processes (pMDPs) whose\ntransitions are equipped with affine functions over a finite set of parameters.\nThe synthesis problem is to find a parameter valuation such that the\ninstantiated pMDP satisfies a specification under all strategies. We show that\nthis problem can be formulated as a quadratically-constrained quadratic program\n(QCQP) and is non-convex in general. To deal with the NP-hardness of such\nproblems, we exploit a convex-concave procedure (CCP) to iteratively obtain\nlocal optima. An appropriate interplay between CCP solvers and probabilistic\nmodel checkers creates a procedure --- realized in the open-source tool\nPROPhESY --- that solves the synthesis problem for models with thousands of\nparameters.\n", "versions": [{"version": "v1", "created": "Mon, 5 Mar 2018 20:55:33 GMT"}, {"version": "v2", "created": "Sun, 15 Apr 2018 15:28:09 GMT"}, {"version": "v3", "created": "Mon, 14 May 2018 19:58:54 GMT"}, {"version": "v4", "created": "Tue, 31 Jul 2018 10:25:55 GMT"}], "update_date": "2018-08-01", "authors_parsed": [["Cubuktepe", "Murat", ""], ["Jansen", "Nils", ""], ["Junges", "Sebastian", ""], ["Katoen", "Joost-Pieter", ""], ["Topcu", "Ufuk", ""]]}, {"id": "1803.02893", "submitter": "Lajanugen Logeswaran", "authors": "Lajanugen Logeswaran, Honglak Lee", "title": "An efficient framework for learning sentence representations", "comments": "ICLR 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we propose a simple and efficient framework for learning\nsentence representations from unlabelled data. Drawing inspiration from the\ndistributional hypothesis and recent work on learning sentence representations,\nwe reformulate the problem of predicting the context in which a sentence\nappears as a classification problem. Given a sentence and its context, a\nclassifier distinguishes context sentences from other contrastive sentences\nbased on their vector representations. This allows us to efficiently learn\ndifferent types of encoding functions, and we show that the model learns\nhigh-quality sentence representations. We demonstrate that our sentence\nrepresentations outperform state-of-the-art unsupervised and supervised\nrepresentation learning methods on several downstream NLP tasks that involve\nunderstanding sentence semantics while achieving an order of magnitude speedup\nin training time.\n", "versions": [{"version": "v1", "created": "Wed, 7 Mar 2018 22:02:10 GMT"}], "update_date": "2018-03-09", "authors_parsed": [["Logeswaran", "Lajanugen", ""], ["Lee", "Honglak", ""]]}, {"id": "1803.02906", "submitter": "Nick Hawes", "authors": "Fatma Faruq, Bruno Lacerda, Nick Hawes and David Parker", "title": "Simultaneous Task Allocation and Planning Under Uncertainty", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose novel techniques for task allocation and planning in multi-robot\nsystems operating in uncertain environments. Task allocation is performed\nsimultaneously with planning, which provides more detailed information about\nindividual robot behaviour, but also exploits independence between tasks to do\nso efficiently. We use Markov decision processes to model robot behaviour and\nlinear temporal logic to specify tasks and safety constraints. Building upon\ntechniques and tools from formal verification, we show how to generate a\nsequence of multi-robot policies, iteratively refining them to reallocate tasks\nif individual robots fail, and providing probabilistic guarantees on the\nperformance (and safe operation) of the team of robots under the resulting\npolicy. We implement our approach and evaluate it on a benchmark multi-robot\nexample.\n", "versions": [{"version": "v1", "created": "Wed, 7 Mar 2018 22:47:52 GMT"}, {"version": "v2", "created": "Fri, 10 Aug 2018 07:51:19 GMT"}], "update_date": "2018-08-13", "authors_parsed": [["Faruq", "Fatma", ""], ["Lacerda", "Bruno", ""], ["Hawes", "Nick", ""], ["Parker", "David", ""]]}, {"id": "1803.02912", "submitter": "Atrisha Sarkar", "authors": "Atrisha Sarkar", "title": "A Brandom-ian view of Reinforcement Learning towards strong-AI", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The analytic philosophy of Robert Brandom, based on the ideas of pragmatism,\npaints a picture of sapience, through inferentialism. In this paper, we present\na theory, that utilizes essential elements of Brandom's philosophy, towards the\nobjective of achieving strong-AI. We do this by connecting the constitutive\nelements of reinforcement learning and the Game Of Giving and Asking For\nReasons. Further, following Brandom's prescriptive thoughts, we restructure the\npopular reinforcement learning algorithm A3C, and show that RL algorithms can\nbe tuned towards the objective of strong-AI.\n", "versions": [{"version": "v1", "created": "Wed, 7 Mar 2018 23:26:49 GMT"}], "update_date": "2018-03-09", "authors_parsed": [["Sarkar", "Atrisha", ""]]}, {"id": "1803.02965", "submitter": "Thanh Thi Nguyen", "authors": "Thanh Thi Nguyen, Ngoc Duy Nguyen, Peter Vamplew, Saeid Nahavandi,\n  Richard Dazeley, Chee Peng Lim", "title": "A Multi-Objective Deep Reinforcement Learning Framework", "comments": "21 pages", "journal-ref": "Engineering Applications of Artificial Intelligence, 2020", "doi": "10.1016/j.engappai.2020.103915", "report-no": "Volume 96, November 2020, 103915", "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces a new scalable multi-objective deep reinforcement\nlearning (MODRL) framework based on deep Q-networks. We develop a\nhigh-performance MODRL framework that supports both single-policy and\nmulti-policy strategies, as well as both linear and non-linear approaches to\naction selection. The experimental results on two benchmark problems\n(two-objective deep sea treasure environment and three-objective Mountain Car\nproblem) indicate that the proposed framework is able to find the\nPareto-optimal solutions effectively. The proposed framework is generic and\nhighly modularized, which allows the integration of different deep\nreinforcement learning algorithms in different complex problem domains. This\ntherefore overcomes many disadvantages involved with standard multi-objective\nreinforcement learning methods in the current literature. The proposed\nframework acts as a testbed platform that accelerates the development of MODRL\nfor solving increasingly complicated multi-objective problems.\n", "versions": [{"version": "v1", "created": "Thu, 8 Mar 2018 04:50:21 GMT"}, {"version": "v2", "created": "Wed, 27 Jun 2018 17:20:52 GMT"}, {"version": "v3", "created": "Fri, 19 Jun 2020 16:04:41 GMT"}], "update_date": "2020-09-09", "authors_parsed": [["Nguyen", "Thanh Thi", ""], ["Nguyen", "Ngoc Duy", ""], ["Vamplew", "Peter", ""], ["Nahavandi", "Saeid", ""], ["Dazeley", "Richard", ""], ["Lim", "Chee Peng", ""]]}, {"id": "1803.02998", "submitter": "Burak Demirel", "authors": "Burak Demirel, Arunselvan Ramaswamy, Daniel E. Quevedo and Holger Karl", "title": "DeepCAS: A Deep Reinforcement Learning Algorithm for Control-Aware\n  Scheduling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SY cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider networked control systems consisting of multiple independent\ncontrolled subsystems, operating over a shared communication network. Such\nsystems are ubiquitous in cyber-physical systems, Internet of Things, and\nlarge-scale industrial systems. In many large-scale settings, the size of the\ncommunication network is smaller than the size of the system. In consequence,\nscheduling issues arise. The main contribution of this paper is to develop a\ndeep reinforcement learning-based \\emph{control-aware} scheduling\n(\\textsc{DeepCAS}) algorithm to tackle these issues. We use the following\n(optimal) design strategy: First, we synthesize an optimal controller for each\nsubsystem; next, we design a learning algorithm that adapts to the chosen\nsubsystems (plants) and controllers. As a consequence of this adaptation, our\nalgorithm finds a schedule that minimizes the \\emph{control loss}. We present\nempirical results to show that \\textsc{DeepCAS} finds schedules with better\nperformance than periodic ones.\n", "versions": [{"version": "v1", "created": "Thu, 8 Mar 2018 08:20:43 GMT"}, {"version": "v2", "created": "Wed, 13 Jun 2018 06:31:09 GMT"}], "update_date": "2018-06-14", "authors_parsed": [["Demirel", "Burak", ""], ["Ramaswamy", "Arunselvan", ""], ["Quevedo", "Daniel E.", ""], ["Karl", "Holger", ""]]}, {"id": "1803.03021", "submitter": "Chengwei Zhang", "authors": "Chengwei Zhang and Xiaohong Li and Jianye Hao and Siqi Chen and Karl\n  Tuyls and Wanli Xue", "title": "SA-IGA: A Multiagent Reinforcement Learning Method Towards Socially\n  Optimal Outcomes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In multiagent environments, the capability of learning is important for an\nagent to behave appropriately in face of unknown opponents and dynamic\nenvironment. From the system designer's perspective, it is desirable if the\nagents can learn to coordinate towards socially optimal outcomes, while also\navoiding being exploited by selfish opponents. To this end, we propose a novel\ngradient ascent based algorithm (SA-IGA) which augments the basic\ngradient-ascent algorithm by incorporating social awareness into the policy\nupdate process. We theoretically analyze the learning dynamics of SA-IGA using\ndynamical system theory and SA-IGA is shown to have linear dynamics for a wide\nrange of games including symmetric games. The learning dynamics of two\nrepresentative games (the prisoner's dilemma game and the coordination game)\nare analyzed in details. Based on the idea of SA-IGA, we further propose a\npractical multiagent learning algorithm, called SA-PGA, based on Q-learning\nupdate rule. Simulation results show that SA-PGA agent can achieve higher\nsocial welfare than previous social-optimality oriented Conditional Joint\nAction Learner (CJAL) and also is robust against individually rational\nopponents by reaching Nash equilibrium solutions.\n", "versions": [{"version": "v1", "created": "Thu, 8 Mar 2018 10:02:42 GMT"}], "update_date": "2018-03-09", "authors_parsed": [["Zhang", "Chengwei", ""], ["Li", "Xiaohong", ""], ["Hao", "Jianye", ""], ["Chen", "Siqi", ""], ["Tuyls", "Karl", ""], ["Xue", "Wanli", ""]]}, {"id": "1803.03067", "submitter": "Drew A. Hudson", "authors": "Drew A. Hudson and Christopher D. Manning", "title": "Compositional Attention Networks for Machine Reasoning", "comments": "Published as a conference paper at ICLR 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present the MAC network, a novel fully differentiable neural network\narchitecture, designed to facilitate explicit and expressive reasoning. MAC\nmoves away from monolithic black-box neural architectures towards a design that\nencourages both transparency and versatility. The model approaches problems by\ndecomposing them into a series of attention-based reasoning steps, each\nperformed by a novel recurrent Memory, Attention, and Composition (MAC) cell\nthat maintains a separation between control and memory. By stringing the cells\ntogether and imposing structural constraints that regulate their interaction,\nMAC effectively learns to perform iterative reasoning processes that are\ndirectly inferred from the data in an end-to-end approach. We demonstrate the\nmodel's strength, robustness and interpretability on the challenging CLEVR\ndataset for visual reasoning, achieving a new state-of-the-art 98.9% accuracy,\nhalving the error rate of the previous best model. More importantly, we show\nthat the model is computationally-efficient and data-efficient, in particular\nrequiring 5x less data than existing models to achieve strong results.\n", "versions": [{"version": "v1", "created": "Thu, 8 Mar 2018 12:37:14 GMT"}, {"version": "v2", "created": "Tue, 24 Apr 2018 10:25:07 GMT"}], "update_date": "2018-04-25", "authors_parsed": [["Hudson", "Drew A.", ""], ["Manning", "Christopher D.", ""]]}, {"id": "1803.03114", "submitter": "Faisal Abu-Khzam", "authors": "Faisal N. Abu-Khzam and Rana H. Mouawi", "title": "Concise Fuzzy Representation of Big Graphs: a Dimensionality Reduction\n  Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The enormous amount of data to be represented using large graphs exceeds in\nsome cases the resources of a conventional computer. Edges in particular can\ntake up a considerable amount of memory as compared to the number of nodes.\nHowever, rigorous edge storage might not always be essential to be able to draw\nthe needed conclusions. A similar problem takes records with many variables and\nattempts to extract the most discernible features. It is said that the\n\"dimension\" of this data is reduced. Following an approach with the same\nobjective in mind, we can map a graph representation to a k-dimensional space\nand answer queries of neighboring nodes by measuring Euclidean distances. The\naccuracy of our answers would decrease but would be compensated for by fuzzy\nlogic which gives an idea about the likelihood of error. This method allows for\nreasonable representation in memory while maintaining a fair amount of useful\ninformation. Promising preliminary results are obtained and reported by testing\nthe proposed approach on a number of Facebook graphs.\n", "versions": [{"version": "v1", "created": "Thu, 8 Mar 2018 14:44:56 GMT"}], "update_date": "2018-03-09", "authors_parsed": [["Abu-Khzam", "Faisal N.", ""], ["Mouawi", "Rana H.", ""]]}, {"id": "1803.03146", "submitter": "Jade Shi", "authors": "Jade Shi (EteRNA players), Rhiju Das, and Vijay S. Pande", "title": "SentRNA: Improving computational RNA design by incorporating a prior of\n  human design strategies", "comments": "27 pages (not including Supplementary Information), 9 figures, 7\n  tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Solving the RNA inverse folding problem is a critical prerequisite to RNA\ndesign, an emerging field in bioengineering with a broad range of applications\nfrom reaction catalysis to cancer therapy. Although significant progress has\nbeen made in developing machine-based inverse RNA folding algorithms, current\napproaches still have difficulty designing sequences for large or complex\ntargets. On the other hand, human players of the online RNA design game EteRNA\nhave consistently shown superior performance in this regard, being able to\nreadily design sequences for targets that are challenging for machine\nalgorithms. Here we present a novel approach to the RNA design problem,\nSentRNA, a design agent consisting of a fully-connected neural network trained\nend-to-end using human-designed RNA sequences. We show that through this\napproach, SentRNA can solve complex targets previously unsolvable by any\nmachine-based approach and achieve state-of-the-art performance on two separate\nchallenging test sets. Our results demonstrate that incorporating human design\nstrategies into a design algorithm can significantly boost machine performance\nand suggests a new paradigm for machine-based RNA design.\n", "versions": [{"version": "v1", "created": "Thu, 8 Mar 2018 15:12:16 GMT"}, {"version": "v2", "created": "Wed, 6 Mar 2019 01:01:53 GMT"}], "update_date": "2019-03-07", "authors_parsed": [["Shi", "Jade", "", "EteRNA players"], ["Das", "Rhiju", ""], ["Pande", "Vijay S.", ""]]}, {"id": "1803.03232", "submitter": "Inigo Casanueva", "authors": "I\\~nigo Casanueva, Pawe{\\l} Budzianowski, Pei-Hao Su, Stefan Ultes,\n  Lina Rojas-Barahona, Bo-Hsiang Tseng and Milica Ga\\v{s}i\\'c", "title": "Feudal Reinforcement Learning for Dialogue Management in Large Domains", "comments": "Accepted as a short paper in NAACL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning (RL) is a promising approach to solve dialogue policy\noptimisation. Traditional RL algorithms, however, fail to scale to large\ndomains due to the curse of dimensionality. We propose a novel Dialogue\nManagement architecture, based on Feudal RL, which decomposes the decision into\ntwo steps; a first step where a master policy selects a subset of primitive\nactions, and a second step where a primitive action is chosen from the selected\nsubset. The structural information included in the domain ontology is used to\nabstract the dialogue state space, taking the decisions at each step using\ndifferent parts of the abstracted state. This, combined with an information\nsharing mechanism between slots, increases the scalability to large domains. We\nshow that an implementation of this approach, based on Deep-Q Networks,\nsignificantly outperforms previous state of the art in several dialogue domains\nand environments, without the need of any additional reward signal.\n", "versions": [{"version": "v1", "created": "Thu, 8 Mar 2018 18:05:18 GMT"}], "update_date": "2018-03-09", "authors_parsed": [["Casanueva", "I\u00f1igo", ""], ["Budzianowski", "Pawe\u0142", ""], ["Su", "Pei-Hao", ""], ["Ultes", "Stefan", ""], ["Rojas-Barahona", "Lina", ""], ["Tseng", "Bo-Hsiang", ""], ["Ga\u0161i\u0107", "Milica", ""]]}, {"id": "1803.03241", "submitter": "Pravesh K Kothari", "authors": "Adam Klivans and Pravesh K. Kothari and Raghu Meka", "title": "Efficient Algorithms for Outlier-Robust Regression", "comments": "27 pages. Appeared in COLT 2018. This update removes Lemma 6.2 that\n  erroneously claimed an information-theoretic lower bound on error rate as a\n  function of fraction of outliers", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give the first polynomial-time algorithm for performing linear or\npolynomial regression resilient to adversarial corruptions in both examples and\nlabels.\n  Given a sufficiently large (polynomial-size) training set drawn i.i.d. from\ndistribution D and subsequently corrupted on some fraction of points, our\nalgorithm outputs a linear function whose squared error is close to the squared\nerror of the best-fitting linear function with respect to D, assuming that the\nmarginal distribution of D over the input space is \\emph{certifiably\nhypercontractive}. This natural property is satisfied by many well-studied\ndistributions such as Gaussian, strongly log-concave distributions and, uniform\ndistribution on the hypercube among others. We also give a simple statistical\nlower bound showing that some distributional assumption is necessary to succeed\nin this setting.\n  These results are the first of their kind and were not known to be even\ninformation-theoretically possible prior to our work.\n  Our approach is based on the sum-of-squares (SoS) method and is inspired by\nthe recent applications of the method for parameter recovery problems in\nunsupervised learning. Our algorithm can be seen as a natural convex relaxation\nof the following conceptually simple non-convex optimization problem: find a\nlinear function and a large subset of the input corrupted sample such that the\nleast squares loss of the function over the subset is minimized over all\npossible large subsets.\n", "versions": [{"version": "v1", "created": "Thu, 8 Mar 2018 18:30:31 GMT"}, {"version": "v2", "created": "Fri, 9 Mar 2018 04:04:29 GMT"}, {"version": "v3", "created": "Thu, 4 Jun 2020 15:42:45 GMT"}], "update_date": "2020-06-05", "authors_parsed": [["Klivans", "Adam", ""], ["Kothari", "Pravesh K.", ""], ["Meka", "Raghu", ""]]}, {"id": "1803.03289", "submitter": "Yuhui Xu", "authors": "Yuhui Xu, Yongzhuang Wang, Aojun Zhou, Weiyao Lin, Hongkai Xiong", "title": "Deep Neural Network Compression with Single and Multiple Level\n  Quantization", "comments": "Published in AAAI18. Code is available at\n  https://github.com/yuhuixu1993/SLQ", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Network quantization is an effective solution to compress deep neural\nnetworks for practical usage. Existing network quantization methods cannot\nsufficiently exploit the depth information to generate low-bit compressed\nnetwork. In this paper, we propose two novel network quantization approaches,\nsingle-level network quantization (SLQ) for high-bit quantization and\nmulti-level network quantization (MLQ) for extremely low-bit quantization\n(ternary).We are the first to consider the network quantization from both width\nand depth level. In the width level, parameters are divided into two parts: one\nfor quantization and the other for re-training to eliminate the quantization\nloss. SLQ leverages the distribution of the parameters to improve the width\nlevel. In the depth level, we introduce incremental layer compensation to\nquantize layers iteratively which decreases the quantization loss in each\niteration. The proposed approaches are validated with extensive experiments\nbased on the state-of-the-art neural networks including AlexNet, VGG-16,\nGoogleNet and ResNet-18. Both SLQ and MLQ achieve impressive results.\n", "versions": [{"version": "v1", "created": "Tue, 6 Mar 2018 01:47:52 GMT"}, {"version": "v2", "created": "Sat, 15 Dec 2018 08:29:21 GMT"}], "update_date": "2018-12-18", "authors_parsed": [["Xu", "Yuhui", ""], ["Wang", "Yongzhuang", ""], ["Zhou", "Aojun", ""], ["Lin", "Weiyao", ""], ["Xiong", "Hongkai", ""]]}, {"id": "1803.03370", "submitter": "Qi Zhu", "authors": "Huan Gui, Qi Zhu, Liyuan Liu, Aston Zhang, Jiawei Han", "title": "Expert Finding in Heterogeneous Bibliographic Networks with\n  Locally-trained Embeddings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.CL cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Expert finding is an important task in both industry and academia. It is\nchallenging to rank candidates with appropriate expertise for various queries.\nIn addition, different types of objects interact with one another, which\nnaturally forms heterogeneous information networks. We study the task of expert\nfinding in heterogeneous bibliographical networks based on two aspects: textual\ncontent analysis and authority ranking. Regarding the textual content analysis,\nwe propose a new method for query expansion via locally-trained embedding\nlearning with concept hierarchy as guidance, which is particularly tailored for\nspecific queries with narrow semantic meanings. Compared with global embedding\nlearning, locally-trained embedding learning projects the terms into a latent\nsemantic space constrained on relevant topics, therefore it preserves more\nprecise and subtle information for specific queries. Considering the candidate\nranking, the heterogeneous information network structure, while being largely\nignored in the previous studies of expert finding, provides additional\ninformation. Specifically, different types of interactions among objects play\ndifferent roles. We propose a ranking algorithm to estimate the authority of\nobjects in the network, treating each strongly-typed edge type individually. To\ndemonstrate the effectiveness of the proposed framework, we apply the proposed\nmethod to a large-scale bibliographical dataset with over two million entries\nand one million researcher candidates. The experiment results show that the\nproposed framework outperforms existing methods for both general and specific\nqueries.\n", "versions": [{"version": "v1", "created": "Fri, 9 Mar 2018 03:28:36 GMT"}], "update_date": "2018-03-12", "authors_parsed": [["Gui", "Huan", ""], ["Zhu", "Qi", ""], ["Liu", "Liyuan", ""], ["Zhang", "Aston", ""], ["Han", "Jiawei", ""]]}, {"id": "1803.03407", "submitter": "Giovanni Sileno", "authors": "Alexander Boer and Giovanni Sileno", "title": "Institutional Metaphors for Designing Large-Scale Distributed AI versus\n  AI Techniques for Running Institutions", "comments": "invited chapter, before proofread", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Artificial Intelligence (AI) started out with an ambition to reproduce the\nhuman mind, but, as the sheer scale of that ambition became manifest, it\nquickly retreated into either studying specialized intelligent behaviours, or\nproposing over-arching architectural concepts for interfacing specialized\nintelligent behaviour components, conceived of as agents in a kind of\norganization. This agent-based modeling paradigm, in turn, proves to have\ninteresting applications in understanding, simulating, and predicting the\nbehaviour of social and legal structures on an aggregate level. For these\nreasons, this chapter examines a number of relevant cross-cutting concerns,\nconceptualizations, modeling problems and design challenges in large-scale\ndistributed Artificial Intelligence, as well as in institutional systems, and\nidentifies potential grounds for novel advances.\n", "versions": [{"version": "v1", "created": "Fri, 9 Mar 2018 07:59:21 GMT"}, {"version": "v2", "created": "Tue, 15 Jun 2021 19:11:23 GMT"}], "update_date": "2021-06-17", "authors_parsed": [["Boer", "Alexander", ""], ["Sileno", "Giovanni", ""]]}, {"id": "1803.03479", "submitter": "Maarten Bieshaar", "authors": "Maarten Bieshaar and G\\\"unther Reitberger and Viktor Kre{\\ss} and\n  Stefan Zernetsch and Konrad Doll and Erich Fuchs and Bernhard Sick", "title": "Highly Automated Learning for Improved Active Safety of Vulnerable Road\n  Users", "comments": "4 pages, 1 figure", "journal-ref": "published in ACM Chapters Computer Science in Cars Symposium\n  (CSCS-17). Munich, Germany. 2017", "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Highly automated driving requires precise models of traffic participants.\nMany state of the art models are currently based on machine learning\ntechniques. Among others, the required amount of labeled data is one major\nchallenge. An autonomous learning process addressing this problem is proposed.\nThe initial models are iteratively refined in three steps: (1) detection and\ncontext identification, (2) novelty detection and active learning and (3)\nonline model adaption.\n", "versions": [{"version": "v1", "created": "Fri, 9 Mar 2018 11:57:36 GMT"}], "update_date": "2018-03-12", "authors_parsed": [["Bieshaar", "Maarten", ""], ["Reitberger", "G\u00fcnther", ""], ["Kre\u00df", "Viktor", ""], ["Zernetsch", "Stefan", ""], ["Doll", "Konrad", ""], ["Fuchs", "Erich", ""], ["Sick", "Bernhard", ""]]}, {"id": "1803.03481", "submitter": "Akira Taniguchi", "authors": "Akira Taniguchi, Yoshinobu Hagiwara, Tadahiro Taniguchi, and Tetsunari\n  Inamura", "title": "Improved and Scalable Online Learning of Spatial Concepts and Language\n  Models with Mapping", "comments": "Accepted to Autonomous Robots (24 January 2020)", "journal-ref": null, "doi": "10.1007/s10514-020-09905-0", "report-no": null, "categories": "cs.RO cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel online learning algorithm, called SpCoSLAM 2.0, for\nspatial concepts and lexical acquisition with high accuracy and scalability.\nPreviously, we proposed SpCoSLAM as an online learning algorithm based on\nunsupervised Bayesian probabilistic model that integrates multimodal place\ncategorization, lexical acquisition, and SLAM. However, our original algorithm\nhad limited estimation accuracy owing to the influence of the early stages of\nlearning, and increased computational complexity with added training data.\nTherefore, we introduce techniques such as fixed-lag rejuvenation to reduce the\ncalculation time while maintaining an accuracy higher than that of the original\nalgorithm. The results show that, in terms of estimation accuracy, the proposed\nalgorithm exceeds the original algorithm and is comparable to batch learning.\nIn addition, the calculation time of the proposed algorithm does not depend on\nthe amount of training data and becomes constant for each step of the scalable\nalgorithm. Our approach will contribute to the realization of long-term spatial\nlanguage interactions between humans and robots.\n", "versions": [{"version": "v1", "created": "Fri, 9 Mar 2018 12:06:04 GMT"}, {"version": "v2", "created": "Fri, 4 Jan 2019 07:36:32 GMT"}, {"version": "v3", "created": "Mon, 10 Feb 2020 12:17:54 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Taniguchi", "Akira", ""], ["Hagiwara", "Yoshinobu", ""], ["Taniguchi", "Tadahiro", ""], ["Inamura", "Tetsunari", ""]]}, {"id": "1803.03487", "submitter": "Maarten Bieshaar", "authors": "Maarten Bieshaar and Stefan Zernetsch and Andreas Hubert and Bernhard\n  Sick and Konrad Doll", "title": "Cooperative Starting Movement Detection of Cyclists Using Convolutional\n  Neural Networks and a Boosted Stacking Ensemble", "comments": "10 Pages, 22 figures, accepted for Special Issue of IEEE Transactions\n  on Intelligent Vehicles", "journal-ref": "IEEE Transactions on Intelligent Vehicles 3 (2018), Nr. 4", "doi": "10.1109/TIV.2018.2873900", "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In future, vehicles and other traffic participants will be interconnected and\nequipped with various types of sensors, allowing for cooperation on different\nlevels, such as situation prediction or intention detection. In this article we\npresent a cooperative approach for starting movement detection of cyclists\nusing a boosted stacking ensemble approach realizing feature- and decision\nlevel cooperation. We introduce a novel method based on a 3D Convolutional\nNeural Network (CNN) to detect starting motions on image sequences by learning\nspatio-temporal features. The CNN is complemented by a smart device based\nstarting movement detection originating from smart devices carried by the\ncyclist. Both model outputs are combined in a stacking ensemble approach using\nan extreme gradient boosting classifier resulting in a fast and yet robust\ncooperative starting movement detector. We evaluate our cooperative approach on\nreal-world data originating from experiments with 49 test subjects consisting\nof 84 starting motions.\n", "versions": [{"version": "v1", "created": "Fri, 9 Mar 2018 12:27:14 GMT"}, {"version": "v2", "created": "Tue, 9 Oct 2018 13:05:43 GMT"}], "update_date": "2018-10-10", "authors_parsed": [["Bieshaar", "Maarten", ""], ["Zernetsch", "Stefan", ""], ["Hubert", "Andreas", ""], ["Sick", "Bernhard", ""], ["Doll", "Konrad", ""]]}, {"id": "1803.03491", "submitter": "Hussain Kazmi", "authors": "Hussain Kazmi, Johan Suykens, Johan Driesen", "title": "Valuing knowledge, information and agency in Multi-agent Reinforcement\n  Learning: a case study in smart buildings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Increasing energy efficiency in buildings can reduce costs and emissions\nsubstantially. Historically, this has been treated as a local, or single-agent,\noptimization problem. However, many buildings utilize the same types of thermal\nequipment e.g. electric heaters and hot water vessels. During operation,\noccupants in these buildings interact with the equipment differently thereby\ndriving them to diverse regions in the state-space. Reinforcement learning\nagents can learn from these interactions, recorded as sensor data, to optimize\nthe overall energy efficiency. However, if these agents operate individually at\na household level, they can not exploit the replicated structure in the\nproblem. In this paper, we demonstrate that this problem can indeed benefit\nfrom multi-agent collaboration by making use of targeted exploration of the\nstate-space allowing for better generalization. We also investigate trade-offs\nbetween integrating human knowledge and additional sensors. Results show that\nsavings of over 40% are possible with collaborative multi-agent systems making\nuse of either expert knowledge or additional sensors with no loss of occupant\ncomfort. We find that such multi-agent systems comfortably outperform\ncomparable single agent systems.\n", "versions": [{"version": "v1", "created": "Fri, 9 Mar 2018 12:48:03 GMT"}], "update_date": "2018-03-12", "authors_parsed": [["Kazmi", "Hussain", ""], ["Suykens", "Johan", ""], ["Driesen", "Johan", ""]]}, {"id": "1803.03635", "submitter": "Jonathan Frankle", "authors": "Jonathan Frankle and Michael Carbin", "title": "The Lottery Ticket Hypothesis: Finding Sparse, Trainable Neural Networks", "comments": "ICLR camera ready", "journal-ref": "ICLR 2019", "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural network pruning techniques can reduce the parameter counts of trained\nnetworks by over 90%, decreasing storage requirements and improving\ncomputational performance of inference without compromising accuracy. However,\ncontemporary experience is that the sparse architectures produced by pruning\nare difficult to train from the start, which would similarly improve training\nperformance.\n  We find that a standard pruning technique naturally uncovers subnetworks\nwhose initializations made them capable of training effectively. Based on these\nresults, we articulate the \"lottery ticket hypothesis:\" dense,\nrandomly-initialized, feed-forward networks contain subnetworks (\"winning\ntickets\") that - when trained in isolation - reach test accuracy comparable to\nthe original network in a similar number of iterations. The winning tickets we\nfind have won the initialization lottery: their connections have initial\nweights that make training particularly effective.\n  We present an algorithm to identify winning tickets and a series of\nexperiments that support the lottery ticket hypothesis and the importance of\nthese fortuitous initializations. We consistently find winning tickets that are\nless than 10-20% of the size of several fully-connected and convolutional\nfeed-forward architectures for MNIST and CIFAR10. Above this size, the winning\ntickets that we find learn faster than the original network and reach higher\ntest accuracy.\n", "versions": [{"version": "v1", "created": "Fri, 9 Mar 2018 18:51:28 GMT"}, {"version": "v2", "created": "Mon, 23 Apr 2018 19:58:09 GMT"}, {"version": "v3", "created": "Sun, 20 May 2018 19:46:47 GMT"}, {"version": "v4", "created": "Tue, 27 Nov 2018 20:03:01 GMT"}, {"version": "v5", "created": "Mon, 4 Mar 2019 15:51:11 GMT"}], "update_date": "2019-03-05", "authors_parsed": [["Frankle", "Jonathan", ""], ["Carbin", "Michael", ""]]}, {"id": "1803.03639", "submitter": "Nesime Tatbul", "authors": "Nesime Tatbul, Tae Jun Lee, Stan Zdonik, Mejbah Alam, Justin\n  Gottschlich", "title": "Precision and Recall for Time Series", "comments": "11 pages, 32nd Conference on Neural Information Processing Systems\n  (NeurIPS 2018), Montreal, Canada", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Classical anomaly detection is principally concerned with point-based\nanomalies, those anomalies that occur at a single point in time. Yet, many\nreal-world anomalies are range-based, meaning they occur over a period of time.\nMotivated by this observation, we present a new mathematical model to evaluate\nthe accuracy of time series classification algorithms. Our model expands the\nwell-known Precision and Recall metrics to measure ranges, while simultaneously\nenabling customization support for domain-specific preferences.\n", "versions": [{"version": "v1", "created": "Thu, 8 Mar 2018 21:49:38 GMT"}, {"version": "v2", "created": "Sun, 28 Oct 2018 02:20:01 GMT"}, {"version": "v3", "created": "Wed, 2 Jan 2019 19:48:46 GMT"}], "update_date": "2019-01-04", "authors_parsed": [["Tatbul", "Nesime", ""], ["Lee", "Tae Jun", ""], ["Zdonik", "Stan", ""], ["Alam", "Mejbah", ""], ["Gottschlich", "Justin", ""]]}, {"id": "1803.03664", "submitter": "Vishwajeet Kumar", "authors": "Vishwajeet Kumar, Kireeti Boorla, Yogesh Meena, Ganesh Ramakrishnan\n  and Yuan-Fang Li", "title": "Automating Reading Comprehension by Generating Question and Answer Pairs", "comments": "12 pages, 3 figures, 2 tables, Accepted for publication at 22nd\n  Pacific-Asia Conference on Knowledge Discovery and Data Mining (PAKDD), 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural network-based methods represent the state-of-the-art in question\ngeneration from text. Existing work focuses on generating only questions from\ntext without concerning itself with answer generation. Moreover, our analysis\nshows that handling rare words and generating the most appropriate question\ngiven a candidate answer are still challenges facing existing approaches. We\npresent a novel two-stage process to generate question-answer pairs from the\ntext. For the first stage, we present alternatives for encoding the span of the\npivotal answer in the sentence using Pointer Networks. In our second stage, we\nemploy sequence to sequence models for question generation, enhanced with rich\nlinguistic features. Finally, global attention and answer encoding are used for\ngenerating the question most relevant to the answer. We motivate and\nlinguistically analyze the role of each component in our framework and consider\ncompositions of these. This analysis is supported by extensive experimental\nevaluations. Using standard evaluation metrics as well as human evaluations,\nour experimental results validate the significant improvement in the quality of\nquestions generated by our framework over the state-of-the-art. The technique\npresented here represents another step towards more automated reading\ncomprehension assessment. We also present a live system \\footnote{Demo of the\nsystem is available at\n\\url{https://www.cse.iitb.ac.in/~vishwajeet/autoqg.html}.} to demonstrate the\neffectiveness of our approach.\n", "versions": [{"version": "v1", "created": "Wed, 7 Mar 2018 07:55:11 GMT"}], "update_date": "2018-03-13", "authors_parsed": [["Kumar", "Vishwajeet", ""], ["Boorla", "Kireeti", ""], ["Meena", "Yogesh", ""], ["Ramakrishnan", "Ganesh", ""], ["Li", "Yuan-Fang", ""]]}, {"id": "1803.03719", "submitter": "Pooyan Fazli", "authors": "Mahmoud Hamandi, Mike D'Arcy, and Pooyan Fazli", "title": "DeepMoTIon: Learning to Navigate Like Humans", "comments": "7 pages, In Proceedings of the IEEE International Conference on Robot\n  and Human Interactive Communication, RO-MAN 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel human-aware navigation approach, where the robot learns to\nmimic humans to navigate safely in crowds. The presented model, referred to as\nDeepMoTIon, is trained with pedestrian surveillance data to predict human\nvelocity in the environment. The robot processes LiDAR scans via the trained\nnetwork to navigate to the target location. We conduct extensive experiments to\nassess the components of our network and prove their necessity to imitate\nhumans. Our experiments show that DeepMoTIion outperforms all the benchmarks in\nterms of human imitation, achieving a 24% reduction in time series-based path\ndeviation over the next best approach. In addition, while many other approaches\noften failed to reach the target, our method reached the target in 100% of the\ntest cases while complying with social norms and ensuring human safety.\n", "versions": [{"version": "v1", "created": "Fri, 9 Mar 2018 23:36:38 GMT"}, {"version": "v2", "created": "Sat, 2 Mar 2019 09:36:46 GMT"}, {"version": "v3", "created": "Thu, 1 Aug 2019 23:48:46 GMT"}], "update_date": "2019-08-05", "authors_parsed": [["Hamandi", "Mahmoud", ""], ["D'Arcy", "Mike", ""], ["Fazli", "Pooyan", ""]]}, {"id": "1803.03735", "submitter": "Kiran Koshy Thekumparampil", "authors": "Kiran K. Thekumparampil, Chong Wang, Sewoong Oh, Li-Jia Li", "title": "Attention-based Graph Neural Network for Semi-supervised Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently popularized graph neural networks achieve the state-of-the-art\naccuracy on a number of standard benchmark datasets for graph-based\nsemi-supervised learning, improving significantly over existing approaches.\nThese architectures alternate between a propagation layer that aggregates the\nhidden states of the local neighborhood and a fully-connected layer. Perhaps\nsurprisingly, we show that a linear model, that removes all the intermediate\nfully-connected layers, is still able to achieve a performance comparable to\nthe state-of-the-art models. This significantly reduces the number of\nparameters, which is critical for semi-supervised learning where number of\nlabeled examples are small. This in turn allows a room for designing more\ninnovative propagation layers. Based on this insight, we propose a novel graph\nneural network that removes all the intermediate fully-connected layers, and\nreplaces the propagation layers with attention mechanisms that respect the\nstructure of the graph. The attention mechanism allows us to learn a dynamic\nand adaptive local summary of the neighborhood to achieve more accurate\npredictions. In a number of experiments on benchmark citation networks\ndatasets, we demonstrate that our approach outperforms competing methods. By\nexamining the attention weights among neighbors, we show that our model\nprovides some interesting insights on how neighbors influence each other.\n", "versions": [{"version": "v1", "created": "Sat, 10 Mar 2018 02:01:35 GMT"}], "update_date": "2018-03-13", "authors_parsed": [["Thekumparampil", "Kiran K.", ""], ["Wang", "Chong", ""], ["Oh", "Sewoong", ""], ["Li", "Li-Jia", ""]]}, {"id": "1803.03745", "submitter": "Jason Liang", "authors": "Jason Liang, Elliot Meyerson, and Risto Miikkulainen", "title": "Evolutionary Architecture Search For Deep Multitask Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multitask learning, i.e. learning several tasks at once with the same neural\nnetwork, can improve performance in each of the tasks. Designing deep neural\nnetwork architectures for multitask learning is a challenge: There are many\nways to tie the tasks together, and the design choices matter. The size and\ncomplexity of this problem exceeds human design ability, making it a compelling\ndomain for evolutionary optimization. Using the existing state of the art soft\nordering architecture as the starting point, methods for evolving the modules\nof this architecture and for evolving the overall topology or routing between\nmodules are evaluated in this paper. A synergetic approach of evolving custom\nroutings with evolved, shared modules for each task is found to be very\npowerful, significantly improving the state of the art in the Omniglot\nmultitask, multialphabet character recognition domain. This result demonstrates\nhow evolution can be instrumental in advancing deep neural network and complex\nsystem design in general.\n", "versions": [{"version": "v1", "created": "Sat, 10 Mar 2018 03:02:09 GMT"}, {"version": "v2", "created": "Tue, 17 Apr 2018 18:46:05 GMT"}], "update_date": "2018-04-19", "authors_parsed": [["Liang", "Jason", ""], ["Meyerson", "Elliot", ""], ["Miikkulainen", "Risto", ""]]}, {"id": "1803.03800", "submitter": "Pramod Kompalli", "authors": "Srayanta Mukherjee, Devashish Shankar, Atin Ghosh, Nilam Tathawadekar,\n  Pramod Kompalli, Sunita Sarawagi, Krishnendu Chaudhury", "title": "ARMDN: Associative and Recurrent Mixture Density Networks for eRetail\n  Demand Forecasting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Accurate demand forecasts can help on-line retail organizations better plan\ntheir supply-chain processes. The challenge, however, is the large number of\nassociative factors that result in large, non-stationary shifts in demand,\nwhich traditional time series and regression approaches fail to model. In this\npaper, we propose a Neural Network architecture called AR-MDN, that\nsimultaneously models associative factors, time-series trends and the variance\nin the demand. We first identify several causal features and use a combination\nof feature embeddings, MLP and LSTM to represent them. We then model the output\ndensity as a learned mixture of Gaussian distributions. The AR-MDN can be\ntrained end-to-end without the need for additional supervision. We experiment\non a dataset of an year's worth of data over tens-of-thousands of products from\nFlipkart. The proposed architecture yields a significant improvement in\nforecasting accuracy when compared with existing alternatives.\n", "versions": [{"version": "v1", "created": "Sat, 10 Mar 2018 12:45:11 GMT"}, {"version": "v2", "created": "Fri, 16 Mar 2018 04:49:15 GMT"}], "update_date": "2018-03-19", "authors_parsed": [["Mukherjee", "Srayanta", ""], ["Shankar", "Devashish", ""], ["Ghosh", "Atin", ""], ["Tathawadekar", "Nilam", ""], ["Kompalli", "Pramod", ""], ["Sarawagi", "Sunita", ""], ["Chaudhury", "Krishnendu", ""]]}, {"id": "1803.03827", "submitter": "Albert Gatt", "authors": "Albert Gatt, Marc Tanti, Adrian Muscat, Patrizia Paggio, Reuben A.\n  Farrugia, Claudia Borg, Kenneth P. Camilleri, Mike Rosner, Lonneke van der\n  Plas", "title": "Face2Text: Collecting an Annotated Image Description Corpus for the\n  Generation of Rich Face Descriptions", "comments": "Proceedings of the 11th edition of the Language Resources and\n  Evaluation Conference (LREC'18)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The past few years have witnessed renewed interest in NLP tasks at the\ninterface between vision and language. One intensively-studied problem is that\nof automatically generating text from images. In this paper, we extend this\nproblem to the more specific domain of face description. Unlike scene\ndescriptions, face descriptions are more fine-grained and rely on attributes\nextracted from the image, rather than objects and relations. Given that no data\nexists for this task, we present an ongoing crowdsourcing study to collect a\ncorpus of descriptions of face images taken `in the wild'. To gain a better\nunderstanding of the variation we find in face description and the possible\nissues that this may raise, we also conducted an annotation study on a subset\nof the corpus. Primarily, we found descriptions to refer to a mixture of\nattributes, not only physical, but also emotional and inferential, which is\nbound to create further challenges for current image-to-text methods.\n", "versions": [{"version": "v1", "created": "Sat, 10 Mar 2018 15:52:08 GMT"}, {"version": "v2", "created": "Fri, 5 Mar 2021 07:32:51 GMT"}], "update_date": "2021-03-08", "authors_parsed": [["Gatt", "Albert", ""], ["Tanti", "Marc", ""], ["Muscat", "Adrian", ""], ["Paggio", "Patrizia", ""], ["Farrugia", "Reuben A.", ""], ["Borg", "Claudia", ""], ["Camilleri", "Kenneth P.", ""], ["Rosner", "Mike", ""], ["van der Plas", "Lonneke", ""]]}, {"id": "1803.03834", "submitter": "Paul Smolensky", "authors": "Roland Fernandez, Asli Celikyilmaz, Rishabh Singh, Paul Smolensky", "title": "Learning and analyzing vector encoding of symbolic representations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a formal language with expressions denoting general symbol\nstructures and queries which access information in those structures. A\nsequence-to-sequence network processing this language learns to encode symbol\nstructures and query them. The learned representation (approximately) shares a\nsimple linearity property with theoretical techniques for performing this task.\n", "versions": [{"version": "v1", "created": "Sat, 10 Mar 2018 16:44:58 GMT"}], "update_date": "2018-03-13", "authors_parsed": [["Fernandez", "Roland", ""], ["Celikyilmaz", "Asli", ""], ["Singh", "Rishabh", ""], ["Smolensky", "Paul", ""]]}, {"id": "1803.03849", "submitter": "Arda Senocak", "authors": "Arda Senocak, Tae-Hyun Oh, Junsik Kim, Ming-Hsuan Yang, In So Kweon", "title": "Learning to Localize Sound Source in Visual Scenes", "comments": "To appear in CVPR 2018. Total 9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Visual events are usually accompanied by sounds in our daily lives. We pose\nthe question: Can the machine learn the correspondence between visual scene and\nthe sound, and localize the sound source only by observing sound and visual\nscene pairs like human? In this paper, we propose a novel unsupervised\nalgorithm to address the problem of localizing the sound source in visual\nscenes. A two-stream network structure which handles each modality, with\nattention mechanism is developed for sound source localization. Moreover,\nalthough our network is formulated within the unsupervised learning framework,\nit can be extended to a unified architecture with a simple modification for the\nsupervised and semi-supervised learning settings as well. Meanwhile, a new\nsound source dataset is developed for performance evaluation. Our empirical\nevaluation shows that the unsupervised method eventually go through false\nconclusion in some cases. We show that even with a few supervision, false\nconclusion is able to be corrected and the source of sound in a visual scene\ncan be localized effectively.\n", "versions": [{"version": "v1", "created": "Sat, 10 Mar 2018 18:19:02 GMT"}], "update_date": "2019-02-18", "authors_parsed": [["Senocak", "Arda", ""], ["Oh", "Tae-Hyun", ""], ["Kim", "Junsik", ""], ["Yang", "Ming-Hsuan", ""], ["Kweon", "In So", ""]]}, {"id": "1803.03999", "submitter": "Kurt Riedel", "authors": "Kurt S. Riedel, A. Sidorenko", "title": "Function Estimation Using Data Adaptive Kernel Estimation - How Much\n  Smoothing?", "comments": "Available at https://aip.scitation.org/doi/pdf/10.1063/1.4823316", "journal-ref": "Computers in Physics Volume 8 Issue 4, July/Aug. 1994 Pages\n  402-409", "doi": "10.1063/1.4823316", "report-no": null, "categories": "stat.ME cs.AI eess.SP math.ST physics.data-an stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We determine the expected error by smoothing the data locally. Then we\noptimize the shape of the kernel smoother to minimize the error. Because the\noptimal estimator depends on the unknown function, our scheme automatically\nadjusts to the unknown function. By self-consistently adjusting the kernel\nsmoother, the total estimator adapts to the data.\n  Goodness of fit estimators select a kernel halfwidth by minimizing a function\nof the halfwidth which is based on the average square residual fit error:\n$ASR(h)$. A penalty term is included to adjust for using the same data to\nestimate the function and to evaluate the mean square error. Goodness of fit\nestimators are relatively simple to implement, but the minimum (of the goodness\nof fit functional) tends to be sensitive to small perturbations. To remedy this\nsensitivity problem, we fit the mean square error %goodness of fit functional\nto a two parameter model prior to determining the optimal halfwidth.\n  Plug-in derivative estimators estimate the second derivative of the unknown\nfunction in an initial step, and then substitute this estimate into the\nasymptotic formula.\n", "versions": [{"version": "v1", "created": "Sun, 11 Mar 2018 18:03:07 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Riedel", "Kurt S.", ""], ["Sidorenko", "A.", ""]]}, {"id": "1803.04119", "submitter": "Gabriel Sepulveda", "authors": "Gabriel Sepulveda, Juan Carlos Niebles and Alvaro Soto", "title": "A Deep Learning Based Behavioral Approach to Indoor Autonomous\n  Navigation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a semantically rich graph representation for indoor robotic\nnavigation. Our graph representation encodes: semantic locations such as\noffices or corridors as nodes, and navigational behaviors such as enter office\nor cross a corridor as edges. In particular, our navigational behaviors operate\ndirectly from visual inputs to produce motor controls and are implemented with\ndeep learning architectures. This enables the robot to avoid explicit\ncomputation of its precise location or the geometry of the environment, and\nenables navigation at a higher level of semantic abstraction. We evaluate the\neffectiveness of our representation by simulating navigation tasks in a large\nnumber of virtual environments. Our results show that using a simple sets of\nperceptual and navigational behaviors, the proposed approach can successfully\nguide the way of the robot as it completes navigational missions such as going\nto a specific office. Furthermore, our implementation shows to be effective to\ncontrol the selection and switching of behaviors.\n", "versions": [{"version": "v1", "created": "Mon, 12 Mar 2018 05:27:07 GMT"}], "update_date": "2018-03-13", "authors_parsed": [["Sepulveda", "Gabriel", ""], ["Niebles", "Juan Carlos", ""], ["Soto", "Alvaro", ""]]}, {"id": "1803.04263", "submitter": "Gagan Bansal", "authors": "Daniel S. Weld and Gagan Bansal", "title": "The Challenge of Crafting Intelligible Intelligence", "comments": "arXiv admin note: text overlap with arXiv:1603.08507 by other authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Since Artificial Intelligence (AI) software uses techniques like deep\nlookahead search and stochastic optimization of huge neural networks to fit\nmammoth datasets, it often results in complex behavior that is difficult for\npeople to understand. Yet organizations are deploying AI algorithms in many\nmission-critical settings. To trust their behavior, we must make AI\nintelligible, either by using inherently interpretable models or by developing\nnew methods for explaining and controlling otherwise overwhelmingly complex\ndecisions using local approximation, vocabulary alignment, and interactive\nexplanation. This paper argues that intelligibility is essential, surveys\nrecent work on building such systems, and highlights key directions for\nresearch.\n", "versions": [{"version": "v1", "created": "Fri, 9 Mar 2018 06:38:55 GMT"}, {"version": "v2", "created": "Tue, 3 Jul 2018 00:31:25 GMT"}, {"version": "v3", "created": "Mon, 15 Oct 2018 06:10:30 GMT"}], "update_date": "2018-10-16", "authors_parsed": [["Weld", "Daniel S.", ""], ["Bansal", "Gagan", ""]]}, {"id": "1803.04459", "submitter": "Rayyan Ahmad Khan", "authors": "Rayyan Ahmad Khan, Rana Ali Amjad, Martin Kleinsteuber", "title": "Extended Affinity Propagation: Global Discovery and Local Insights", "comments": "Submitted to TKDE", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.SI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We propose a new clustering algorithm, Extended Affinity Propagation, based\non pairwise similarities. Extended Affinity Propagation is developed by\nmodifying Affinity Propagation such that the desirable features of Affinity\nPropagation, e.g., exemplars, reasonable computational complexity and no need\nto specify number of clusters, are preserved while the shortcomings, e.g., the\nlack of global structure discovery, that limit the applicability of Affinity\nPropagation are overcome. Extended Affinity Propagation succeeds not only in\nachieving this goal but can also provide various additional insights into the\ninternal structure of the individual clusters, e.g., refined confidence values,\nrelative cluster densities and local cluster strength in different regions of a\ncluster, which are valuable for an analyst. We briefly discuss how these\ninsights can help in easily tuning the hyperparameters. We also illustrate\nthese desirable features and the performance of Extended Affinity Propagation\non various synthetic and real world datasets.\n", "versions": [{"version": "v1", "created": "Mon, 12 Mar 2018 18:56:38 GMT"}, {"version": "v2", "created": "Mon, 15 Apr 2019 18:43:44 GMT"}], "update_date": "2019-04-17", "authors_parsed": [["Khan", "Rayyan Ahmad", ""], ["Amjad", "Rana Ali", ""], ["Kleinsteuber", "Martin", ""]]}, {"id": "1803.04474", "submitter": "Amilcar Soares Junior", "authors": "Fateha Khanam Bappee and Amilcar Soares Junior and Stan Matwin", "title": "Predicting Crime Using Spatial Features", "comments": "Paper accepted to 31st Canadian Conference in Artificial\n  Intelligence, 2018", "journal-ref": null, "doi": "10.1007/978-3-319-89656-4_42", "report-no": null, "categories": "cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Our study aims to build a machine learning model for crime prediction using\ngeospatial features for different categories of crime. The reverse geocoding\ntechnique is applied to retrieve open street map (OSM) spatial data. This study\nalso proposes finding hotpoints extracted from crime hotspots area found by\nHierarchical Density-Based Spatial Clustering of Applications with Noise\n(HDBSCAN). A spatial distance feature is then computed based on the position of\ndifferent hotpoints for various types of crime and this value is used as a\nfeature for classifiers. We test the engineered features in crime data from\nRoyal Canadian Mounted Police of Halifax, NS. We observed a significant\nperformance improvement in crime prediction using the new generated spatial\nfeatures.\n", "versions": [{"version": "v1", "created": "Mon, 12 Mar 2018 19:23:27 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["Bappee", "Fateha Khanam", ""], ["Junior", "Amilcar Soares", ""], ["Matwin", "Stan", ""]]}, {"id": "1803.04488", "submitter": "Tommaso Soru", "authors": "Faisal Alshargi, Saeedeh Shekarpour, Tommaso Soru, Amit Sheth", "title": "Concept2vec: Metrics for Evaluating Quality of Embeddings for\n  Ontological Concepts", "comments": "Spring Symposium on Combining Machine Learning with Knowledge\n  Engineering (AAAI-MAKE 2019)", "journal-ref": "CEUR-WS 2350 (2019) 26", "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although there is an emerging trend towards generating embeddings for\nprimarily unstructured data and, recently, for structured data, no systematic\nsuite for measuring the quality of embeddings has been proposed yet. This\ndeficiency is further sensed with respect to embeddings generated for\nstructured data because there are no concrete evaluation metrics measuring the\nquality of the encoded structure as well as semantic patterns in the embedding\nspace. In this paper, we introduce a framework containing three distinct tasks\nconcerned with the individual aspects of ontological concepts: (i) the\ncategorization aspect, (ii) the hierarchical aspect, and (iii) the relational\naspect. Then, in the scope of each task, a number of intrinsic metrics are\nproposed for evaluating the quality of the embeddings. Furthermore, w.r.t. this\nframework, multiple experimental studies were run to compare the quality of the\navailable embedding models. Employing this framework in future research can\nreduce misjudgment and provide greater insight about quality comparisons of\nembeddings for ontological concepts. We positioned our sampled data and code at\nhttps://github.com/alshargi/Concept2vec under GNU General Public License v3.0.\n", "versions": [{"version": "v1", "created": "Mon, 12 Mar 2018 19:46:10 GMT"}, {"version": "v2", "created": "Thu, 26 Jul 2018 09:16:45 GMT"}, {"version": "v3", "created": "Fri, 8 May 2020 09:15:17 GMT"}], "update_date": "2020-05-11", "authors_parsed": [["Alshargi", "Faisal", ""], ["Shekarpour", "Saeedeh", ""], ["Soru", "Tommaso", ""], ["Sheth", "Amit", ""]]}, {"id": "1803.04551", "submitter": "Pan Wei", "authors": "Pan Wei, John E. Ball, Derek T. Anderson", "title": "Multi-Sensor Conflict Measurement and Information Fusion", "comments": "15 pages, 9 figures, conference paper", "journal-ref": "SPIE Defense, Security, and Sensing, April, 2016", "doi": null, "report-no": null, "categories": "eess.SP cs.AI", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  In sensing applications where multiple sensors observe the same scene, fusing\nsensor outputs can provide improved results. However, if some of the sensors\nare providing lower quality outputs, the fused results can be degraded. In this\nwork, a multi-sensor conflict measure is proposed which estimates multi-sensor\nconflict by representing each sensor output as interval-valued information and\nexamines the sensor output overlaps on all possible n-tuple sensor\ncombinations. The conflict is based on the sizes of the intervals and how many\nsensors output values lie in these intervals. In this work, conflict is defined\nin terms of how little the output from multiple sensors overlap. That is, high\ndegrees of overlap mean low sensor conflict, while low degrees of overlap mean\nhigh conflict. This work is a preliminary step towards a robust conflict and\nsensor fusion framework. In addition, a sensor fusion algorithm is proposed\nbased on a weighted sum of sensor outputs, where the weights for each sensor\ndiminish as the conflict measure increases. The proposed methods can be\nutilized to (1) assess a measure of multi-sensor conflict, and (2) improve\nsensor output fusion by lessening weighting for sensors with high conflict.\nUsing this measure, a simulated example is given to explain the mechanics of\ncalculating the conflict measure, and stereo camera 3D outputs are analyzed and\nfused. In the stereo camera case, the sensor output is corrupted by additive\nimpulse noise, DC offset, and Gaussian noise. Impulse noise is common in\nsensors due to intermittent interference, a DC offset a sensor bias or\nregistration error, and Gaussian noise represents a sensor output with low SNR.\nThe results show that sensor output fusion based on the conflict measure shows\nimproved accuracy over a simple averaging fusion strategy.\n", "versions": [{"version": "v1", "created": "Mon, 12 Mar 2018 22:10:14 GMT"}], "update_date": "2018-03-14", "authors_parsed": [["Wei", "Pan", ""], ["Ball", "John E.", ""], ["Anderson", "Derek T.", ""]]}, {"id": "1803.04556", "submitter": "Pan Wei", "authors": "Pan Wei, John E. Ball, Derek T. Anderson, Archit Harsh, Christopher\n  Archibald", "title": "Measuring Conflict in a Multi-Source Environment as a Normal Measure", "comments": "4 pages, 8 figures, conference paper", "journal-ref": "IEEE International Workshop on Computational Advances in\n  Multi-Sensor Adaptive Processing (CAMSAP), December, 2015", "doi": null, "report-no": null, "categories": "eess.SP cs.AI cs.CV eess.IV", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  In a multi-source environment, each source has its own credibility. If there\nis no external knowledge about credibility then we can use the information\nprovided by the sources to assess their credibility. In this paper, we propose\na way to measure conflict in a multi-source environment as a normal measure. We\nexamine our algorithm using three simulated examples of increasing conflict and\none experimental example. The results demonstrate that the proposed measure can\nrepresent conflict in a meaningful way similar to what a human might expect and\nfrom it we can identify conflict within our sources.\n", "versions": [{"version": "v1", "created": "Mon, 12 Mar 2018 22:27:11 GMT"}], "update_date": "2018-03-14", "authors_parsed": [["Wei", "Pan", ""], ["Ball", "John E.", ""], ["Anderson", "Derek T.", ""], ["Harsh", "Archit", ""], ["Archibald", "Christopher", ""]]}, {"id": "1803.04565", "submitter": "Sasa Grbic", "authors": "Sebastian Guendel, Sasa Grbic, Bogdan Georgescu, Kevin Zhou, Ludwig\n  Ritschl, Andreas Meier and Dorin Comaniciu", "title": "Learning to recognize Abnormalities in Chest X-Rays with Location-Aware\n  Dense Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Chest X-ray is the most common medical imaging exam used to assess multiple\npathologies. Automated algorithms and tools have the potential to support the\nreading workflow, improve efficiency, and reduce reading errors. With the\navailability of large scale data sets, several methods have been proposed to\nclassify pathologies on chest X-ray images. However, most methods report\nperformance based on random image based splitting, ignoring the high\nprobability of the same patient appearing in both training and test set. In\naddition, most methods fail to explicitly incorporate the spatial information\nof abnormalities or utilize the high resolution images. We propose a novel\napproach based on location aware Dense Networks (DNetLoc), whereby we\nincorporate both high-resolution image data and spatial information for\nabnormality classification. We evaluate our method on the largest data set\nreported in the community, containing a total of 86,876 patients and 297,541\nchest X-ray images. We achieve (i) the best average AUC score for published\ntraining and test splits on the single benchmarking data set (ChestX-Ray14),\nand (ii) improved AUC scores when the pathology location information is\nexplicitly used. To foster future research we demonstrate the limitations of\nthe current benchmarking setup and provide new reference patient-wise splits\nfor the used data sets. This could support consistent and meaningful\nbenchmarking of future methods on the largest publicly available data sets.\n", "versions": [{"version": "v1", "created": "Mon, 12 Mar 2018 22:57:18 GMT"}], "update_date": "2018-03-14", "authors_parsed": [["Guendel", "Sebastian", ""], ["Grbic", "Sasa", ""], ["Georgescu", "Bogdan", ""], ["Zhou", "Kevin", ""], ["Ritschl", "Ludwig", ""], ["Meier", "Andreas", ""], ["Comaniciu", "Dorin", ""]]}, {"id": "1803.04585", "submitter": "David Manheim", "authors": "David Manheim and Scott Garrabrant", "title": "Categorizing Variants of Goodhart's Law", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI q-fin.GN stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  There are several distinct failure modes for overoptimization of systems on\nthe basis of metrics. This occurs when a metric which can be used to improve a\nsystem is used to an extent that further optimization is ineffective or\nharmful, and is sometimes termed Goodhart's Law. This class of failure is often\npoorly understood, partly because terminology for discussing them is ambiguous,\nand partly because discussion using this ambiguous terminology ignores\ndistinctions between different failure modes of this general type. This paper\nexpands on an earlier discussion by Garrabrant, which notes there are \"(at\nleast) four different mechanisms\" that relate to Goodhart's Law. This paper is\nintended to explore these mechanisms further, and specify more clearly how they\noccur. This discussion should be helpful in better understanding these types of\nfailures in economic regulation, in public policy, in machine learning, and in\nArtificial Intelligence alignment. The importance of Goodhart effects depends\non the amount of power directed towards optimizing the proxy, and so the\nincreased optimization power offered by artificial intelligence makes it\nespecially critical for that field.\n", "versions": [{"version": "v1", "created": "Tue, 13 Mar 2018 01:15:39 GMT"}, {"version": "v2", "created": "Tue, 27 Mar 2018 14:28:19 GMT"}, {"version": "v3", "created": "Mon, 9 Apr 2018 13:39:19 GMT"}, {"version": "v4", "created": "Sun, 24 Feb 2019 08:12:46 GMT"}], "update_date": "2019-02-26", "authors_parsed": [["Manheim", "David", ""], ["Garrabrant", "Scott", ""]]}, {"id": "1803.04596", "submitter": "Tom De Smedt", "authors": "Tom De Smedt, Guy De Pauw, Pieter Van Ostaeyen", "title": "Automatic Detection of Online Jihadist Hate Speech", "comments": "31 pages", "journal-ref": "CLiPS Technical Report Series 7 (2018) 1-31", "doi": null, "report-no": "CTRS-007", "categories": "cs.CL cs.AI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We have developed a system that automatically detects online jihadist hate\nspeech with over 80% accuracy, by using techniques from Natural Language\nProcessing and Machine Learning. The system is trained on a corpus of 45,000\nsubversive Twitter messages collected from October 2014 to December 2016. We\npresent a qualitative and quantitative analysis of the jihadist rhetoric in the\ncorpus, examine the network of Twitter users, outline the technical procedure\nused to train the system, and discuss examples of use.\n", "versions": [{"version": "v1", "created": "Tue, 13 Mar 2018 02:09:06 GMT"}], "update_date": "2018-03-14", "authors_parsed": [["De Smedt", "Tom", ""], ["De Pauw", "Guy", ""], ["Van Ostaeyen", "Pieter", ""]]}, {"id": "1803.04646", "submitter": "Alexander Semenov", "authors": "Alexander Semenov, Oleg Zaikin, Ilya Otpuschennikov, Stepan\n  Kochemazov, Alexey Ignatiev", "title": "On Cryptographic Attacks Using Backdoors for SAT", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Propositional satisfiability (SAT) is at the nucleus of state-of-the-art\napproaches to a variety of computationally hard problems, one of which is\ncryptanalysis. Moreover, a number of practical applications of SAT can only be\ntackled efficiently by identifying and exploiting a subset of formula's\nvariables called backdoor set (or simply backdoors). This paper proposes a new\nclass of backdoor sets for SAT used in the context of cryptographic attacks,\nnamely guess-and-determine attacks. The idea is to identify the best set of\nbackdoor variables subject to a statistically estimated hardness of the\nguess-and-determine attack using a SAT solver. Experimental results on weakened\nvariants of the renowned encryption algorithms exhibit advantage of the\nproposed approach compared to the state of the art in terms of the estimated\nhardness of the resulting guess-and-determine attacks.\n", "versions": [{"version": "v1", "created": "Tue, 13 Mar 2018 06:29:50 GMT"}], "update_date": "2018-03-14", "authors_parsed": [["Semenov", "Alexander", ""], ["Zaikin", "Oleg", ""], ["Otpuschennikov", "Ilya", ""], ["Kochemazov", "Stepan", ""], ["Ignatiev", "Alexey", ""]]}, {"id": "1803.04674", "submitter": "Tom Zahavy", "authors": "Tom Zahavy, Avinatan Hasidim, Haim Kaplan, Yishay Mansour", "title": "Hierarchical Reinforcement Learning: Approximating Optimal Discounted\n  TSP Using Local Policies", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we provide theoretical guarantees for reward decomposition in\ndeterministic MDPs. Reward decomposition is a special case of Hierarchical\nReinforcement Learning, that allows one to learn many policies in parallel and\ncombine them into a composite solution. Our approach builds on mapping this\nproblem into a Reward Discounted Traveling Salesman Problem, and then deriving\napproximate solutions for it. In particular, we focus on approximate solutions\nthat are local, i.e., solutions that only observe information about the current\nstate. Local policies are easy to implement and do not require substantial\ncomputational resources as they do not perform planning. While local\ndeterministic policies, like Nearest Neighbor, are being used in practice for\nhierarchical reinforcement learning, we propose three stochastic policies that\nguarantee better performance than any deterministic policy.\n", "versions": [{"version": "v1", "created": "Tue, 13 Mar 2018 08:13:11 GMT"}], "update_date": "2018-03-14", "authors_parsed": [["Zahavy", "Tom", ""], ["Hasidim", "Avinatan", ""], ["Kaplan", "Haim", ""], ["Mansour", "Yishay", ""]]}, {"id": "1803.04837", "submitter": "Luchen Liu", "authors": "Luchen Liu, Jianhao Shen, Ming Zhang, Zichang Wang and Jian Tang", "title": "Learning the Joint Representation of Heterogeneous Temporal Events for\n  Clinical Endpoint Prediction", "comments": "8 pages, this paper has been accepted by AAAI 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The availability of a large amount of electronic health records (EHR)\nprovides huge opportunities to improve health care service by mining these\ndata. One important application is clinical endpoint prediction, which aims to\npredict whether a disease, a symptom or an abnormal lab test will happen in the\nfuture according to patients' history records. This paper develops deep\nlearning techniques for clinical endpoint prediction, which are effective in\nmany practical applications. However, the problem is very challenging since\npatients' history records contain multiple heterogeneous temporal events such\nas lab tests, diagnosis, and drug administrations. The visiting patterns of\ndifferent types of events vary significantly, and there exist complex nonlinear\nrelationships between different events. In this paper, we propose a novel model\nfor learning the joint representation of heterogeneous temporal events. The\nmodel adds a new gate to control the visiting rates of different events which\neffectively models the irregular patterns of different events and their\nnonlinear correlations. Experiment results with real-world clinical data on the\ntasks of predicting death and abnormal lab tests prove the effectiveness of our\nproposed approach over competitive baselines.\n", "versions": [{"version": "v1", "created": "Tue, 13 Mar 2018 14:32:38 GMT"}, {"version": "v2", "created": "Wed, 14 Mar 2018 21:56:32 GMT"}, {"version": "v3", "created": "Thu, 10 May 2018 12:12:48 GMT"}, {"version": "v4", "created": "Sat, 17 Nov 2018 06:20:12 GMT"}], "update_date": "2018-11-20", "authors_parsed": [["Liu", "Luchen", ""], ["Shen", "Jianhao", ""], ["Zhang", "Ming", ""], ["Wang", "Zichang", ""], ["Tang", "Jian", ""]]}, {"id": "1803.04848", "submitter": "Esther Derman", "authors": "Esther Derman, Daniel J. Mankowitz, Timothy A. Mann, Shie Mannor", "title": "Soft-Robust Actor-Critic Policy-Gradient", "comments": "UAI 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Robust Reinforcement Learning aims to derive optimal behavior that accounts\nfor model uncertainty in dynamical systems. However, previous studies have\nshown that by considering the worst case scenario, robust policies can be\noverly conservative. Our soft-robust framework is an attempt to overcome this\nissue. In this paper, we present a novel Soft-Robust Actor-Critic algorithm\n(SR-AC). It learns an optimal policy with respect to a distribution over an\nuncertainty set and stays robust to model uncertainty but avoids the\nconservativeness of robust strategies. We show the convergence of SR-AC and\ntest the efficiency of our approach on different domains by comparing it\nagainst regular learning methods and their robust formulations.\n", "versions": [{"version": "v1", "created": "Sun, 11 Mar 2018 09:43:20 GMT"}, {"version": "v2", "created": "Wed, 24 Oct 2018 06:01:45 GMT"}], "update_date": "2018-10-25", "authors_parsed": [["Derman", "Esther", ""], ["Mankowitz", "Daniel J.", ""], ["Mann", "Timothy A.", ""], ["Mannor", "Shie", ""]]}, {"id": "1803.04927", "submitter": "Ali Shirzadi Babakan", "authors": "A. Shirzadi Babakan, A. Alimohammadi", "title": "An Agent-Based Simulation of Residential Location Choice of Tenants in\n  Tehran, Iran", "comments": null, "journal-ref": "Transactions in GIS 20(1), 2016, 101-125", "doi": "10.1111/tgis.12144", "report-no": null, "categories": "cs.MA cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Residential location choice modeling is one of the substantial components of\nland use and transportation models. While numerous aggregated mathematical and\nstatistical approaches have been developed to model the residence choice\nbehavior of households, disaggregated approaches such as the agent-based\nmodeling have shown interesting capabilities. In this article, a novel\nagent-based approach is developed to simulate the residential location choice\nof tenants in Tehran, the capital of Iran. Tenants are considered as agents who\nselect their desired residential alternatives according to their\ncharacteristics and preferences for various criteria such as the rent,\naccessibility to different services and facilities, environmental pollution,\nand distance from their workplace and former residence. The choice set of\nagents is limited to their desired residential alternatives by applying a\nconstrained NSGA-II algorithm. Then, agents compete with each other to select\ntheir final residence among their alternatives. Results of the proposed\napproach are validated by comparing simulated and actual residences of a sample\nof tenants. Results show that the proposed approach is able to accurately\nsimulate the residence of 59.3% of tenants at the traffic analysis zone level.\n", "versions": [{"version": "v1", "created": "Tue, 13 Mar 2018 16:36:10 GMT"}], "update_date": "2018-03-14", "authors_parsed": [["Babakan", "A. Shirzadi", ""], ["Alimohammadi", "A.", ""]]}, {"id": "1803.04932", "submitter": "Ali Shirzadi Babakan", "authors": "A. S. Babakan, M. Taleai", "title": "Impacts of transport development on residence choice of renter\n  households: An agent-based evaluation", "comments": null, "journal-ref": "Habitat International 49 (2015) 275-285", "doi": "10.1016/j.habitatint.2015.05.033", "report-no": null, "categories": "cs.MA cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Because of improving accessibility, transport developments play an important\nrole in residence choice of renter households. In this paper, an agent-based\nmodel is developed to investigate impacts of different transport developments\non residence choice of renter households in Tehran, the capital of Iran. In the\nproposed model, renter households are considered as agents who make a\nmulti-objective decision and compete with each other to rent a preferred\nresidential zone. Then, three transport development scenarios including\nconstruction a new highway, subway and bus rapid transit (BRT) line are\nsimulated and resulting changes in residence choice of agents are evaluated.\nResults show that transport development scenarios significantly affect\nresidence choice behavior of different socio-economic categories of renter\nhouseholds and lead to considerable changes in the residential demand,\ncomposition of residents, mean income level and mean car ownership in their\nvicinities.\n", "versions": [{"version": "v1", "created": "Tue, 13 Mar 2018 16:45:33 GMT"}], "update_date": "2018-03-14", "authors_parsed": [["Babakan", "A. S.", ""], ["Taleai", "M.", ""]]}, {"id": "1803.04934", "submitter": "Ali Shirzadi Babakan", "authors": "A. Shirzadi Babakan, A. Alimohammadi, M. Taleai", "title": "An agent-based evaluation of impacts of transport developments on the\n  modal shift in Tehran, Iran", "comments": null, "journal-ref": "Journal of Development Effectiveness 7(2), 2015, 230-251", "doi": "10.1080/19439342.2014.994656", "report-no": null, "categories": "cs.MA cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Changes in travel modes used by people, particularly reduction of the private\ncar use, is an important determinant of effectiveness of transportation plans.\nBecause of dependencies between the choices of residential location and travel\nmode, integrated modelling of these choices has been proposed by some\nresearchers. In this paper, an agent-based microsimulation model has been\ndeveloped to evaluate impacts of different transport development plans on\nchoices of residential location and commuting mode of tenant households in\nTehran, the capital of Iran. In the proposed model, households are considered\nas agents who select their desired residential location using a constrained\nNSGA-II algorithm and in a competition with other households. In addition, they\nchoose their commuting mode by applying a multi-criteria decision making\nmethod. Afterwards, effects of development of a new highway, subway and bus\nrapid transit (BRT) line on their residential location and commuting mode\nchoices are evaluated. Results show that despite the residential self-selection\neffects, these plans result in considerable changes in the commuting mode of\ndifferent socioeconomic categories of households. Development of the new subway\nline shows promising results by reducing the private car use among the all\nsocio-economic categories of households. But the new highway development\nunsatisfactorily results in increase in the private car use. In addition,\ndevelopment of the new BRT line does not show significant effects on the\ncommuting mode change, particularly on decrease in the private car use.\n", "versions": [{"version": "v1", "created": "Tue, 13 Mar 2018 16:53:50 GMT"}], "update_date": "2018-04-10", "authors_parsed": [["Babakan", "A. Shirzadi", ""], ["Alimohammadi", "A.", ""], ["Taleai", "M.", ""]]}, {"id": "1803.04994", "submitter": "Subhash Kak", "authors": "Subhash Kak", "title": "On the Algebra in Boole's Laws of Thought", "comments": "11 pages", "journal-ref": "Current Science, vol.. 114, pp. 2570-2573, 2018", "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article explores the ideas that went into George Boole's development of\nan algebra for logical inference in his book The Laws of Thought. We explore in\nparticular his wife Mary Boole's claim that he was deeply influenced by Indian\nlogic and argue that his work was more than a framework for processing\npropositions. By exploring parallels between his work and Indian logic, we are\nable to explain several peculiarities of this work.\n", "versions": [{"version": "v1", "created": "Tue, 13 Mar 2018 18:13:08 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Kak", "Subhash", ""]]}, {"id": "1803.05027", "submitter": "Mohamed El Halaby", "authors": "Mohamed El Halaby", "title": "Solving the Course-timetabling Problem of Cairo University Using Max-SAT", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to the good performance of current SAT (satisfiability) and Max-SAT\n(maximum ssatisfiability) solvers, many real-life optimization problems such as\nscheduling can be solved by encoding them into Max-SAT. In this paper we tackle\nthe course timetabling problem of the department of mathematics, Cairo\nUniversity by encoding it into Max-SAT. Generating timetables for the\ndepartment by hand has proven to be cumbersome and the generated timetable\nalmost always contains conflicts. We show how the constraints can be modelled\nas a Max-SAT instance.\n", "versions": [{"version": "v1", "created": "Sun, 11 Feb 2018 23:40:25 GMT"}], "update_date": "2018-03-15", "authors_parsed": [["Halaby", "Mohamed El", ""]]}, {"id": "1803.05044", "submitter": "Tianbing Xu", "authors": "Tianbing Xu, Qiang Liu, Liang Zhao, Jian Peng", "title": "Learning to Explore with Meta-Policy Gradient", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The performance of off-policy learning, including deep Q-learning and deep\ndeterministic policy gradient (DDPG), critically depends on the choice of the\nexploration policy. Existing exploration methods are mostly based on adding\nnoise to the on-going actor policy and can only explore \\emph{local} regions\nclose to what the actor policy dictates. In this work, we develop a simple\nmeta-policy gradient algorithm that allows us to adaptively learn the\nexploration policy in DDPG. Our algorithm allows us to train flexible\nexploration behaviors that are independent of the actor policy, yielding a\n\\emph{global exploration} that significantly speeds up the learning process.\nWith an extensive study, we show that our method significantly improves the\nsample-efficiency of DDPG on a variety of reinforcement learning tasks.\n", "versions": [{"version": "v1", "created": "Tue, 13 Mar 2018 21:04:17 GMT"}, {"version": "v2", "created": "Mon, 26 Mar 2018 00:02:21 GMT"}], "update_date": "2018-03-28", "authors_parsed": [["Xu", "Tianbing", ""], ["Liu", "Qiang", ""], ["Zhao", "Liang", ""], ["Peng", "Jian", ""]]}, {"id": "1803.05049", "submitter": "Sergio Hernandez", "authors": "Sergio Hernandez Cerezo and Guillem Duran Ballester", "title": "Fractal AI: A fragile theory of intelligence", "comments": "57 pages, python code on https://github.com/FragileTheory/FractalAI,\n  V4: typo in formula at 2.2.3, V4.1 typo in pseudocode at 4.3", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Fractal AI is a theory for general artificial intelligence. It allows\nderiving new mathematical tools that constitute the foundations for a new kind\nof stochastic calculus, by modelling information using cellular automaton-like\nstructures instead of smooth functions. In the repository included we are\npresenting a new Agent, derived from the first principles of the theory, which\nis capable of solving Atari games several orders of magnitude more efficiently\nthan other similar techniques, like Monte Carlo Tree Search. The code provided\nshows how it is now possible to beat some of the current State of The Art\nbenchmarks on Atari games, without previous learning and using less than 1000\nsamples to calculate each one of the actions when standard MCTS uses 3 Million\nsamples. Among other things, Fractal AI makes it possible to generate a huge\ndatabase of top performing examples with a very little amount of computation\nrequired, transforming Reinforcement Learning into a supervised problem. The\nalgorithm presented is capable of solving the exploration vs exploitation\ndilemma on both the discrete and continuous cases, while maintaining control\nover any aspect of the behaviour of the Agent. From a general approach, new\ntechniques presented here have direct applications to other areas such as\nNon-equilibrium thermodynamics, chemistry, quantum physics, economics,\ninformation theory, and non-linear control theory.\n", "versions": [{"version": "v1", "created": "Tue, 13 Mar 2018 21:17:26 GMT"}, {"version": "v2", "created": "Tue, 19 Jun 2018 11:46:15 GMT"}, {"version": "v3", "created": "Mon, 30 Jul 2018 10:54:18 GMT"}, {"version": "v4", "created": "Mon, 9 Dec 2019 15:11:29 GMT"}, {"version": "v5", "created": "Thu, 30 Jul 2020 09:52:44 GMT"}], "update_date": "2020-07-31", "authors_parsed": [["Cerezo", "Sergio Hernandez", ""], ["Ballester", "Guillem Duran", ""]]}, {"id": "1803.05098", "submitter": "Bryan Wilder", "authors": "Bryan Wilder", "title": "Algorithmic Social Intervention", "comments": "Thesis proposal. 21 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CY cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Social and behavioral interventions are a critical tool for governments and\ncommunities to tackle deep-rooted societal challenges such as homelessness,\ndisease, and poverty. However, real-world interventions are almost always\nplagued by limited resources and limited data, which creates a computational\nchallenge: how can we use algorithmic techniques to enhance the targeting and\ndelivery of social and behavioral interventions? The goal of my thesis is to\nprovide a unified study of such questions, collectively considered under the\nname \"algorithmic social intervention\". This proposal introduces algorithmic\nsocial intervention as a distinct area with characteristic technical\nchallenges, presents my published research in the context of these challenges,\nand outlines open problems for future work. A common technical theme is\ndecision making under uncertainty: how can we find actions which will impact a\nsocial system in desirable ways under limitations of knowledge and resources?\nThe primary application area for my work thus far is public health, e.g. HIV or\ntuberculosis prevention. For instance, I have developed a series of algorithms\nwhich optimize social network interventions for HIV prevention. Two of these\nalgorithms have been pilot-tested in collaboration with LA-area service\nproviders for homeless youth, with preliminary results showing substantial\nimprovement over status-quo approaches. My work also spans other topics in\ninfectious disease prevention and underlying algorithmic questions in robust\nand risk-aware submodular optimization.\n", "versions": [{"version": "v1", "created": "Wed, 14 Mar 2018 02:00:54 GMT"}], "update_date": "2018-03-15", "authors_parsed": [["Wilder", "Bryan", ""]]}, {"id": "1803.05131", "submitter": "Alex James Dr", "authors": "Olga Krestinskaya, Alex Pappachen James", "title": "Feature extraction without learning in an analog Spatial Pooler\n  memristive-CMOS circuit design of Hierarchical Temporal Memory", "comments": null, "journal-ref": "Analog Integrated Circuits and Signal Processing, 2018", "doi": null, "report-no": null, "categories": "cs.ET cs.AI cs.AR cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hierarchical Temporal Memory (HTM) is a neuromorphic algorithm that emulates\nsparsity, hierarchy and modularity resembling the working principles of\nneocortex. Feature encoding is an important step to create sparse binary\npatterns. This sparsity is introduced by the binary weights and random weight\nassignment in the initialization stage of the HTM. We propose the alternative\ndeterministic method for the HTM initialization stage, which connects the HTM\nweights to the input data and preserves natural sparsity of the input\ninformation. Further, we introduce the hardware implementation of the\ndeterministic approach and compare it to the traditional HTM and existing\nhardware implementation. We test the proposed approach on the face recognition\nproblem and show that it outperforms the conventional HTM approach.\n", "versions": [{"version": "v1", "created": "Wed, 14 Mar 2018 04:18:47 GMT"}], "update_date": "2018-03-15", "authors_parsed": [["Krestinskaya", "Olga", ""], ["James", "Alex Pappachen", ""]]}, {"id": "1803.05156", "submitter": "Matthew Stephenson", "authors": "Matthew Stephenson, Jochen Renz, Xiaoyu Ge, Peng Zhang", "title": "The 2017 AIBIRDS Competition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents an overview of the sixth AIBIRDS competition, held at the\n26th International Joint Conference on Artificial Intelligence. This\ncompetition tasked participants with developing an intelligent agent which can\nplay the physics-based puzzle game Angry Birds. This game uses a sophisticated\nphysics engine that requires agents to reason and predict the outcome of\nactions with only limited environmental information. Agents entered into this\ncompetition were required to solve a wide assortment of previously unseen\nlevels within a set time limit. The physical reasoning and planning required to\nsolve these levels are very similar to those of many real-world problems. This\nyear's competition featured some of the best agents developed so far and even\nincluded several new AI techniques such as deep reinforcement learning. Within\nthis paper we describe the framework, rules, submitted agents and results for\nthis competition. We also provide some background information on related work\nand other video game AI competitions, as well as discussing some potential\nideas for future AIBIRDS competitions and agent improvements.\n", "versions": [{"version": "v1", "created": "Wed, 14 Mar 2018 07:53:31 GMT"}], "update_date": "2018-03-15", "authors_parsed": [["Stephenson", "Matthew", ""], ["Renz", "Jochen", ""], ["Ge", "Xiaoyu", ""], ["Zhang", "Peng", ""]]}, {"id": "1803.05181", "submitter": "Rizwan Ahmed Khan", "authors": "Muhammad Shoaib Jaliawala, Rizwan Ahmed Khan", "title": "Can Autism be Catered with Artificial Intelligence-Assisted Intervention\n  Technology? A Literature Review", "comments": null, "journal-ref": "Artificial Intelligence Review 2019", "doi": "10.1007/s10462-019-09686-8", "report-no": null, "categories": "cs.HC cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article presents an extensive literature review of technology based\nintervention methodologies for individuals facing Autism Spectrum Disorder\n(ASD). Reviewed methodologies include: contemporary Computer Aided Systems\n(CAS), Computer Vision Assisted Technologies (CVAT) and Virtual Reality (VR) or\nArtificial Intelligence (AI)-Assisted interventions. The research over the past\ndecade has provided enough demonstrations that individuals with ASD have a\nstrong interest in technology based interventions, which are useful in both,\nclinical settings as well as at home and classrooms. Despite showing great\npromise, research in developing an advanced technology based intervention that\nis clinically quantitative for ASD is minimal. Moreover, the clinicians are\ngenerally not convinced about the potential of the technology based\ninterventions due to non-empirical nature of published results. A major reason\nbehind this lack of acceptability is that a vast majority of studies on\ndistinct intervention methodologies do not follow any specific standard or\nresearch design. We conclude from our findings that there remains a gap between\nthe research community of computer science, psychology and neuroscience to\ndevelop an AI assisted intervention technology for individuals suffering from\nASD. Following the development of a standardized AI based intervention\ntechnology, a database needs to be developed, to devise effective AI\nalgorithms.\n", "versions": [{"version": "v1", "created": "Wed, 14 Mar 2018 09:56:39 GMT"}, {"version": "v2", "created": "Fri, 16 Mar 2018 04:37:12 GMT"}, {"version": "v3", "created": "Sat, 10 Nov 2018 18:54:34 GMT"}, {"version": "v4", "created": "Fri, 23 Nov 2018 05:15:02 GMT"}, {"version": "v5", "created": "Sat, 19 Jan 2019 16:16:32 GMT"}], "update_date": "2019-02-21", "authors_parsed": [["Jaliawala", "Muhammad Shoaib", ""], ["Khan", "Rizwan Ahmed", ""]]}, {"id": "1803.05262", "submitter": "William Woof", "authors": "William Woof and Ke Chen", "title": "Learning to Play General Video-Games via an Object Embedding Network", "comments": "To appear in IEEE CIG2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep reinforcement learning (DRL) has proven to be an effective tool for\ncreating general video-game AI. However most current DRL video-game agents\nlearn end-to-end from the video-output of the game, which is superfluous for\nmany applications and creates a number of additional problems. More\nimportantly, directly working on pixel-based raw video data is substantially\ndistinct from what a human player does.In this paper, we present a novel method\nwhich enables DRL agents to learn directly from object information. This is\nobtained via use of an object embedding network (OEN) that compresses a set of\nobject feature vectors of different lengths into a single fixed-length unified\nfeature vector representing the current game-state and fulfills the DRL\nsimultaneously. We evaluate our OEN-based DRL agent by comparing to several\nstate-of-the-art approaches on a selection of games from the GVG-AI\nCompetition. Experimental results suggest that our object-based DRL agent\nyields performance comparable to that of those approaches used in our\ncomparative study.\n", "versions": [{"version": "v1", "created": "Wed, 14 Mar 2018 13:26:44 GMT"}, {"version": "v2", "created": "Mon, 28 May 2018 11:25:06 GMT"}], "update_date": "2018-05-29", "authors_parsed": [["Woof", "William", ""], ["Chen", "Ke", ""]]}, {"id": "1803.05263", "submitter": "Kai Yi", "authors": "Kai Yi, Zhiqiang Jian, Shitao Chen and Nanning Zheng", "title": "Feature Selective Small Object Detection via Knowledge-based Recurrent\n  Attentive Neural Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  At present, the performance of deep neural network in general object\ndetection is comparable to or even surpasses that of human beings. However, due\nto the limitations of deep learning itself, the small proportion of feature\npixels, and the occurence of blur and occlusion, the detection of small objects\nin complex scenes is still an open question. But we can not deny that real-time\nand accurate object detection is fundamental to automatic perception and\nsubsequent perception-based decision-making and planning tasks of autonomous\ndriving.\n  Considering the characteristics of small objects in autonomous driving scene,\nwe proposed a novel method named KB-RANN, which based on domain knowledge,\nintuitive experience and feature attentive selection. It can focus on\nparticular parts of image features, and then it tries to stress the importance\nof these features and strengthenes the learning parameters of them. Our\ncomparative experiments on KITTI and COCO datasets show that our proposed\nmethod can achieve considerable results both in speed and accuracy, and can\nimprove the effect of small object detection through self-selection of\nimportant features and continuous enhancement of proposed method, and deployed\nit in our self-developed autonomous driving car.\n", "versions": [{"version": "v1", "created": "Tue, 13 Mar 2018 12:45:55 GMT"}, {"version": "v2", "created": "Thu, 15 Mar 2018 13:55:00 GMT"}, {"version": "v3", "created": "Wed, 2 May 2018 15:04:28 GMT"}, {"version": "v4", "created": "Sat, 20 Apr 2019 08:31:05 GMT"}], "update_date": "2019-04-23", "authors_parsed": [["Yi", "Kai", ""], ["Jian", "Zhiqiang", ""], ["Chen", "Shitao", ""], ["Zheng", "Nanning", ""]]}, {"id": "1803.05339", "submitter": "Yilong Yang", "authors": "Run Han, Yilong Yang, Xiaoshan Li, Defang Ouyang", "title": "Predicting Oral Disintegrating Tablet Formulations by Neural Network\n  Techniques", "comments": "This is a post-peer-review, pre-copyedit version of an article\n  published in Asian Journal of Pharmaceutical Sciences. The final\n  authenticated version is available online at:\n  https://doi.org/10.1016/j.ajps.2018.01.003", "journal-ref": null, "doi": "10.1016/j.ajps.2018.01.003", "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Oral Disintegrating Tablets (ODTs) is a novel dosage form that can be\ndissolved on the tongue within 3min or less especially for geriatric and\npediatric patients. Current ODT formulation studies usually rely on the\npersonal experience of pharmaceutical experts and trial-and-error in the\nlaboratory, which is inefficient and time-consuming. The aim of current\nresearch was to establish the prediction model of ODT formulations with direct\ncompression process by Artificial Neural Network (ANN) and Deep Neural Network\n(DNN) techniques. 145 formulation data were extracted from Web of Science. All\ndata sets were divided into three parts: training set (105 data), validation\nset (20) and testing set (20). ANN and DNN were compared for the prediction of\nthe disintegrating time. The accuracy of the ANN model has reached 85.60%,\n80.00% and 75.00% on the training set, validation set and testing set\nrespectively, whereas that of the DNN model was 85.60%, 85.00% and 80.00%,\nrespectively. Compared with the ANN, DNN showed the better prediction for ODT\nformulations. It is the first time that deep neural network with the improved\ndataset selection algorithm is applied to formulation prediction on small data.\nThe proposed predictive approach could evaluate the critical parameters about\nquality control of formulation, and guide research and process development. The\nimplementation of this prediction model could effectively reduce drug product\ndevelopment timeline and material usage, and proactively facilitate the\ndevelopment of a robust drug product.\n", "versions": [{"version": "v1", "created": "Wed, 14 Mar 2018 15:05:11 GMT"}], "update_date": "2018-06-08", "authors_parsed": [["Han", "Run", ""], ["Yang", "Yilong", ""], ["Li", "Xiaoshan", ""], ["Ouyang", "Defang", ""]]}, {"id": "1803.05340", "submitter": "Lucas Lamata", "authors": "F. Albarr\\'an-Arriagada, J. C. Retamal, E. Solano, L. Lamata", "title": "Measurement-based adaptation protocol with quantum reinforcement\n  learning", "comments": null, "journal-ref": "Phys. Rev. A 98, 042315 (2018)", "doi": "10.1103/PhysRevA.98.042315", "report-no": null, "categories": "quant-ph cond-mat.mes-hall cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning employs dynamical algorithms that mimic the human capacity\nto learn, where the reinforcement learning ones are among the most similar to\nhumans in this respect. On the other hand, adaptability is an essential aspect\nto perform any task efficiently in a changing environment, and it is\nfundamental for many purposes, such as natural selection. Here, we propose an\nalgorithm based on successive measurements to adapt one quantum state to a\nreference unknown state, in the sense of achieving maximum overlap. The\nprotocol naturally provides many identical copies of the reference state, such\nthat in each measurement iteration more information about it is obtained. In\nour protocol, we consider a system composed of three parts, the \"environment\"\nsystem, which provides the reference state copies; the register, which is an\nauxiliary subsystem that interacts with the environment to acquire information\nfrom it; and the agent, which corresponds to the quantum state that is adapted\nby digital feedback with input corresponding to the outcome of the measurements\non the register. With this proposal we can achieve an average fidelity between\nthe environment and the agent of more than $90\\% $ with less than $30$\niterations of the protocol. In addition, we extend the formalism to $ d\n$-dimensional states, reaching an average fidelity of around $80\\% $ in less\nthan $400$ iterations for $d=$ 11, for a variety of genuinely quantum and\nsemiclassical states. This work paves the way for the development of quantum\nreinforcement learning protocols using quantum data and for the future\ndeployment of semi-autonomous quantum systems.\n", "versions": [{"version": "v1", "created": "Wed, 14 Mar 2018 15:06:11 GMT"}, {"version": "v2", "created": "Fri, 12 Oct 2018 06:01:22 GMT"}], "update_date": "2018-10-15", "authors_parsed": [["Albarr\u00e1n-Arriagada", "F.", ""], ["Retamal", "J. C.", ""], ["Solano", "E.", ""], ["Lamata", "L.", ""]]}, {"id": "1803.05402", "submitter": "Jack Harmer PhD", "authors": "Jack Harmer, Linus Gissl\\'en, Jorge del Val, Henrik Holst, Joakim\n  Bergdahl, Tom Olsson, Kristoffer Sj\\\"o\\\"o, Magnus Nordin", "title": "Imitation Learning with Concurrent Actions in 3D Games", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we describe a novel deep reinforcement learning architecture\nthat allows multiple actions to be selected at every time-step in an efficient\nmanner. Multi-action policies allow complex behaviours to be learnt that would\notherwise be hard to achieve when using single action selection techniques. We\nuse both imitation learning and temporal difference (TD) reinforcement learning\n(RL) to provide a 4x improvement in training time and 2.5x improvement in\nperformance over single action selection TD RL. We demonstrate the capabilities\nof this network using a complex in-house 3D game. Mimicking the behavior of the\nexpert teacher significantly improves world state exploration and allows the\nagents vision system to be trained more rapidly than TD RL alone. This initial\ntraining technique kick-starts TD learning and the agent quickly learns to\nsurpass the capabilities of the expert.\n", "versions": [{"version": "v1", "created": "Wed, 14 Mar 2018 16:59:17 GMT"}, {"version": "v2", "created": "Thu, 15 Mar 2018 17:35:18 GMT"}, {"version": "v3", "created": "Wed, 28 Mar 2018 20:48:42 GMT"}, {"version": "v4", "created": "Thu, 31 May 2018 10:12:40 GMT"}, {"version": "v5", "created": "Thu, 6 Sep 2018 12:16:17 GMT"}], "update_date": "2018-09-07", "authors_parsed": [["Harmer", "Jack", ""], ["Gissl\u00e9n", "Linus", ""], ["del Val", "Jorge", ""], ["Holst", "Henrik", ""], ["Bergdahl", "Joakim", ""], ["Olsson", "Tom", ""], ["Sj\u00f6\u00f6", "Kristoffer", ""], ["Nordin", "Magnus", ""]]}, {"id": "1803.05407", "submitter": "Andrew Wilson", "authors": "Pavel Izmailov, Dmitrii Podoprikhin, Timur Garipov, Dmitry Vetrov,\n  Andrew Gordon Wilson", "title": "Averaging Weights Leads to Wider Optima and Better Generalization", "comments": "Appears at the Conference on Uncertainty in Artificial Intelligence\n  (UAI), 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks are typically trained by optimizing a loss function with\nan SGD variant, in conjunction with a decaying learning rate, until\nconvergence. We show that simple averaging of multiple points along the\ntrajectory of SGD, with a cyclical or constant learning rate, leads to better\ngeneralization than conventional training. We also show that this Stochastic\nWeight Averaging (SWA) procedure finds much flatter solutions than SGD, and\napproximates the recent Fast Geometric Ensembling (FGE) approach with a single\nmodel. Using SWA we achieve notable improvement in test accuracy over\nconventional SGD training on a range of state-of-the-art residual networks,\nPyramidNets, DenseNets, and Shake-Shake networks on CIFAR-10, CIFAR-100, and\nImageNet. In short, SWA is extremely easy to implement, improves\ngeneralization, and has almost no computational overhead.\n", "versions": [{"version": "v1", "created": "Wed, 14 Mar 2018 17:09:27 GMT"}, {"version": "v2", "created": "Wed, 8 Aug 2018 08:49:15 GMT"}, {"version": "v3", "created": "Mon, 25 Feb 2019 14:18:11 GMT"}], "update_date": "2019-02-26", "authors_parsed": [["Izmailov", "Pavel", ""], ["Podoprikhin", "Dmitrii", ""], ["Garipov", "Timur", ""], ["Vetrov", "Dmitry", ""], ["Wilson", "Andrew Gordon", ""]]}, {"id": "1803.05457", "submitter": "Carissa Schoenick", "authors": "Peter Clark, Isaac Cowhey, Oren Etzioni, Tushar Khot, Ashish\n  Sabharwal, Carissa Schoenick, Oyvind Tafjord", "title": "Think you have Solved Question Answering? Try ARC, the AI2 Reasoning\n  Challenge", "comments": "10 pages, 7 tables, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new question set, text corpus, and baselines assembled to\nencourage AI research in advanced question answering. Together, these\nconstitute the AI2 Reasoning Challenge (ARC), which requires far more powerful\nknowledge and reasoning than previous challenges such as SQuAD or SNLI. The ARC\nquestion set is partitioned into a Challenge Set and an Easy Set, where the\nChallenge Set contains only questions answered incorrectly by both a\nretrieval-based algorithm and a word co-occurence algorithm. The dataset\ncontains only natural, grade-school science questions (authored for human\ntests), and is the largest public-domain set of this kind (7,787 questions). We\ntest several baselines on the Challenge Set, including leading neural models\nfrom the SQuAD and SNLI tasks, and find that none are able to significantly\noutperform a random baseline, reflecting the difficult nature of this task. We\nare also releasing the ARC Corpus, a corpus of 14M science sentences relevant\nto the task, and implementations of the three neural baseline models tested.\nCan your model perform better? We pose ARC as a challenge to the community.\n", "versions": [{"version": "v1", "created": "Wed, 14 Mar 2018 18:04:21 GMT"}], "update_date": "2018-03-16", "authors_parsed": [["Clark", "Peter", ""], ["Cowhey", "Isaac", ""], ["Etzioni", "Oren", ""], ["Khot", "Tushar", ""], ["Sabharwal", "Ashish", ""], ["Schoenick", "Carissa", ""], ["Tafjord", "Oyvind", ""]]}, {"id": "1803.05649", "submitter": "Jakub Tomczak Ph.D.", "authors": "Rianne van den Berg and Leonard Hasenclever and Jakub M. Tomczak and\n  Max Welling", "title": "Sylvester Normalizing Flows for Variational Inference", "comments": "Published at UAI 2018, 12 pages, 3 figures, code at:\n  https://github.com/riannevdberg/sylvester-flows", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Variational inference relies on flexible approximate posterior distributions.\nNormalizing flows provide a general recipe to construct flexible variational\nposteriors. We introduce Sylvester normalizing flows, which can be seen as a\ngeneralization of planar flows. Sylvester normalizing flows remove the\nwell-known single-unit bottleneck from planar flows, making a single\ntransformation much more flexible. We compare the performance of Sylvester\nnormalizing flows against planar flows and inverse autoregressive flows and\ndemonstrate that they compare favorably on several datasets.\n", "versions": [{"version": "v1", "created": "Thu, 15 Mar 2018 09:15:14 GMT"}, {"version": "v2", "created": "Wed, 20 Feb 2019 18:36:23 GMT"}], "update_date": "2019-02-21", "authors_parsed": [["Berg", "Rianne van den", ""], ["Hasenclever", "Leonard", ""], ["Tomczak", "Jakub M.", ""], ["Welling", "Max", ""]]}, {"id": "1803.05752", "submitter": "Weihao Yuan", "authors": "Weihao Yuan, Johannes A. Stork, Danica Kragic, Michael Y. Wang and\n  Kaiyu Hang", "title": "Rearrangement with Nonprehensile Manipulation Using Deep Reinforcement\n  Learning", "comments": "2018 International Conference on Robotics and Automation", "journal-ref": null, "doi": "10.1109/ICRA.2018.8462863", "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Rearranging objects on a tabletop surface by means of nonprehensile\nmanipulation is a task which requires skillful interaction with the physical\nworld. Usually, this is achieved by precisely modeling physical properties of\nthe objects, robot, and the environment for explicit planning. In contrast, as\nexplicitly modeling the physical environment is not always feasible and\ninvolves various uncertainties, we learn a nonprehensile rearrangement strategy\nwith deep reinforcement learning based on only visual feedback. For this, we\nmodel the task with rewards and train a deep Q-network. Our potential\nfield-based heuristic exploration strategy reduces the amount of collisions\nwhich lead to suboptimal outcomes and we actively balance the training set to\navoid bias towards poor examples. Our training process leads to quicker\nlearning and better performance on the task as compared to uniform exploration\nand standard experience replay. We demonstrate empirical evidence from\nsimulation that our method leads to a success rate of 85%, show that our system\ncan cope with sudden changes of the environment, and compare our performance\nwith human level performance.\n", "versions": [{"version": "v1", "created": "Thu, 15 Mar 2018 14:00:24 GMT"}], "update_date": "2018-09-21", "authors_parsed": [["Yuan", "Weihao", ""], ["Stork", "Johannes A.", ""], ["Kragic", "Danica", ""], ["Wang", "Michael Y.", ""], ["Hang", "Kaiyu", ""]]}, {"id": "1803.05760", "submitter": "Boliang Lin", "authors": "Boliang Lin", "title": "A Study of Car-to-Train Assignment Problem for Rail Express Cargos on\n  Scheduled and Unscheduled Train Service Network", "comments": "12 pages, 1 figure", "journal-ref": null, "doi": "10.1371/journal.pone.0204598", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Freight train services in a railway network system are generally divided into\ntwo categories: one is the unscheduled train, whose operating frequency\nfluctuates with origin-destination (OD) demands; the other is the scheduled\ntrain, which is running based on regular timetable just like the passenger\ntrains. The timetable will be released to the public if determined and it would\nnot be influenced by OD demands. Typically, the total capacity of scheduled\ntrains can usually satisfy the predicted demands of express cargos in average.\nHowever, the demands are changing in practice. Therefore, how to distribute the\nshipments between different stations to unscheduled and scheduled train\nservices has become an important research field in railway transportation. This\npaper focuses on the coordinated optimization of the rail express cargos\ndistribution in two service networks. On the premise of fully utilizing the\ncapacity of scheduled service network first, we established a Car-to-Train\n(CTT) assignment model to assign rail express cargos to scheduled and\nunscheduled trains scientifically. The objective function is to maximize the\nnet income of transporting the rail express cargos. The constraints include the\ncapacity restriction on the service arcs, flow balance constraints, logical\nrelationship constraint between two groups of decision variables and the due\ndate constraint. The last constraint is to ensure that the total transportation\ntime of a shipment would not be longer than its predefined due date. Finally,\nwe discuss the linearization techniques to simplify the model proposed in this\npaper, which make it possible for obtaining global optimal solution by using\nthe commercial software.\n", "versions": [{"version": "v1", "created": "Wed, 14 Mar 2018 07:32:14 GMT"}], "update_date": "2018-11-21", "authors_parsed": [["Lin", "Boliang", ""]]}, {"id": "1803.05768", "submitter": "Ondrej Kuzelka", "authors": "Ondrej Kuzelka, Yuyi Wang, Jesse Davis, Steven Schockaert", "title": "PAC-Reasoning in Relational Domains", "comments": "Longer version of paper appearing in UAI 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of predicting plausible missing facts in relational\ndata, given a set of imperfect logical rules. In particular, our aim is to\nprovide bounds on the (expected) number of incorrect inferences that are made\nin this way. Since for classical inference it is in general impossible to bound\nthis number in a non-trivial way, we consider two inference relations that\nweaken, but remain close in spirit to classical inference.\n", "versions": [{"version": "v1", "created": "Thu, 15 Mar 2018 14:20:06 GMT"}, {"version": "v2", "created": "Sat, 17 Mar 2018 11:59:27 GMT"}, {"version": "v3", "created": "Wed, 4 Jul 2018 13:37:05 GMT"}], "update_date": "2018-07-05", "authors_parsed": [["Kuzelka", "Ondrej", ""], ["Wang", "Yuyi", ""], ["Davis", "Jesse", ""], ["Schockaert", "Steven", ""]]}, {"id": "1803.05849", "submitter": "Renzo Andri", "authors": "Andrawes Al Bahou, Geethan Karunaratne, Renzo Andri, Lukas Cavigelli,\n  Luca Benini", "title": "XNORBIN: A 95 TOp/s/W Hardware Accelerator for Binary Convolutional\n  Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.AR cs.NE eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deploying state-of-the-art CNNs requires power-hungry processors and off-chip\nmemory. This precludes the implementation of CNNs in low-power embedded\nsystems. Recent research shows CNNs sustain extreme quantization, binarizing\ntheir weights and intermediate feature maps, thereby saving 8-32\\x memory and\ncollapsing energy-intensive sum-of-products into XNOR-and-popcount operations.\n  We present XNORBIN, an accelerator for binary CNNs with computation tightly\ncoupled to memory for aggressive data reuse. Implemented in UMC 65nm technology\nXNORBIN achieves an energy efficiency of 95 TOp/s/W and an area efficiency of\n2.0 TOp/s/MGE at 0.8 V.\n", "versions": [{"version": "v1", "created": "Mon, 5 Mar 2018 15:41:28 GMT"}], "update_date": "2018-09-12", "authors_parsed": [["Bahou", "Andrawes Al", ""], ["Karunaratne", "Geethan", ""], ["Andri", "Renzo", ""], ["Cavigelli", "Lukas", ""], ["Benini", "Luca", ""]]}, {"id": "1803.05859", "submitter": "Oscar Chang", "authors": "Oscar Chang, Hod Lipson", "title": "Neural Network Quine", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Self-replication is a key aspect of biological life that has been largely\noverlooked in Artificial Intelligence systems. Here we describe how to build\nand train self-replicating neural networks. The network replicates itself by\nlearning to output its own weights. The network is designed using a loss\nfunction that can be optimized with either gradient-based or non-gradient-based\nmethods. We also describe a method we call regeneration to train the network\nwithout explicit optimization, by injecting the network with predictions of its\nown parameters. The best solution for a self-replicating network was found by\nalternating between regeneration and optimization steps. Finally, we describe a\ndesign for a self-replicating neural network that can solve an auxiliary task\nsuch as MNIST image classification. We observe that there is a trade-off\nbetween the network's ability to classify images and its ability to replicate,\nbut training is biased towards increasing its specialization at image\nclassification at the expense of replication. This is analogous to the\ntrade-off between reproduction and other tasks observed in nature. We suggest\nthat a self-replication mechanism for artificial intelligence is useful because\nit introduces the possibility of continual improvement through natural\nselection.\n", "versions": [{"version": "v1", "created": "Thu, 15 Mar 2018 16:54:43 GMT"}, {"version": "v2", "created": "Sat, 17 Mar 2018 09:47:43 GMT"}, {"version": "v3", "created": "Sat, 31 Mar 2018 21:18:58 GMT"}, {"version": "v4", "created": "Thu, 24 May 2018 19:23:35 GMT"}], "update_date": "2018-05-28", "authors_parsed": [["Chang", "Oscar", ""], ["Lipson", "Hod", ""]]}, {"id": "1803.05983", "submitter": "Didier Barradas-Bautista", "authors": "Didier Barradas-Bautista and Mat\\'ias Alvarado", "title": "Unraveling Go gaming nature by Ising Hamiltonian and common fate graphs:\n  tactics and statistics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI physics.app-ph physics.data-an", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Go gaming is a struggle between adversaries, black and white simple stones,\nand aim to control the most Go board territory for success. Rules are simple\nbut Go game fighting is highly intricate. Stones placement and interaction on\nboard is random-appearance, likewise interaction phenomena among basic elements\nin physics thermodynamics, chemistry, biology, or social issues. We model the\nGo game dynamic employing an Ising model energy function, whose interaction\ncoefficients reflect the application of rules and tactics to build long-term\nstrategies. At any step of the game, the energy function of the model assesses\nthe control and strength of a player over the board. A close fit between\npredictions of the model with actual game's scores is obtained. AlphaGo\ncomputer is the current top Go player, but its behavior does not wholly reveal\nthe Go gaming nature. The Ising function allows for precisely model the\nstochastic evolutions of Go gaming patterns, so, to advance the understanding\non Go own-dynamic -beyond the player`s abilities. The analysis of the frequency\nand combination of tactics shows the formation of patterns in the groups of\nstones during a game, regarding the turn of each player, or if human or\ncomputer adversaries are confronted.\n", "versions": [{"version": "v1", "created": "Thu, 15 Mar 2018 20:08:01 GMT"}], "update_date": "2018-03-19", "authors_parsed": [["Barradas-Bautista", "Didier", ""], ["Alvarado", "Mat\u00edas", ""]]}, {"id": "1803.06000", "submitter": "Ahmed Fadhil", "authors": "Ahmed Fadhil", "title": "Beyond Patient Monitoring: Conversational Agents Role in Telemedicine &\n  Healthcare Support For Home-Living Elderly Individuals", "comments": "7 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  There is a need for systems to dynamically interact with ageing populations\nto gather information, monitor health condition and provide support, especially\nafter hospital discharge or at-home settings. Several smart devices have been\ndelivered by digital health, bundled with telemedicine systems, smartphone and\nother digital services. While such solutions offer personalised data and\nsuggestions, the real disruptive step comes from the interaction of new digital\necosystem, represented by chatbots. Chatbots will play a leading role by\nembodying the function of a virtual assistant and bridging the gap between\npatients and clinicians. Powered by AI and machine learning algorithms,\nchatbots are forecasted to save healthcare costs when used in place of a human\nor assist them as a preliminary step of helping to assess a condition and\nproviding self-care recommendations. This paper describes integrating chatbots\ninto telemedicine systems intended for elderly patient after their hospital\ndischarge. The paper discusses possible ways to utilise chatbots to assist\nhealthcare providers and support patients with their condition.\n", "versions": [{"version": "v1", "created": "Sat, 3 Mar 2018 13:45:08 GMT"}], "update_date": "2018-03-19", "authors_parsed": [["Fadhil", "Ahmed", ""]]}, {"id": "1803.06024", "submitter": "Tom Zahavy", "authors": "Tom Zahavy, Alex Dikopoltsev, Oren Cohen, Shie Mannor and Mordechai\n  Segev", "title": "Deep Learning Reconstruction of Ultra-Short Pulses", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.optics cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ultra-short laser pulses with femtosecond to attosecond pulse duration are\nthe shortest systematic events humans can create. Characterization (amplitude\nand phase) of these pulses is a key ingredient in ultrafast science, e.g.,\nexploring chemical reactions and electronic phase transitions. Here, we propose\nand demonstrate, numerically and experimentally, the first deep neural network\ntechnique to reconstruct ultra-short optical pulses. We anticipate that this\napproach will extend the range of ultrashort laser pulses that can be\ncharacterized, e.g., enabling to diagnose very weak attosecond pulses.\n", "versions": [{"version": "v1", "created": "Thu, 15 Mar 2018 22:37:31 GMT"}], "update_date": "2018-03-19", "authors_parsed": [["Zahavy", "Tom", ""], ["Dikopoltsev", "Alex", ""], ["Cohen", "Oren", ""], ["Mannor", "Shie", ""], ["Segev", "Mordechai", ""]]}, {"id": "1803.06062", "submitter": "T\\'ulio A. M. Toffolo", "authors": "T\\'ulio A. M. Toffolo, Thibaut Vidal, Tony Wauters", "title": "Heuristics for vehicle routing problems: Sequence or set optimization?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate a structural decomposition for the capacitated vehicle routing\nproblem (CVRP) based on vehicle-to-customer \"assignment\" and visits\n\"sequencing\" decision variables. We show that an heuristic search focused on\nassignment decisions with a systematic optimal choice of sequences (using\nConcorde TSP solver) during each move evaluation is promising but requires a\nprohibitive computational effort. We therefore introduce an intermediate search\nspace, based on the dynamic programming procedure of Balas & Simonetti, which\nfinds a good compromise between intensification and computational efficiency. A\nvariety of speed-up techniques are proposed for a fast exploration:\nneighborhood reductions, dynamic move filters, memory structures, and\nconcatenation techniques. Finally, a tunneling strategy is designed to reshape\nthe search space as the algorithm progresses.\n  The combination of these techniques within a classical local search, as well\nas in the unified hybrid genetic search (UHGS) leads to significant\nimprovements of solution accuracy. New best solutions are found for\nsurprisingly small instances with as few as 256 customers. These solutions had\nnot been attained up to now with classic neighborhoods. Overall, this research\npermits to better evaluate the respective impact of sequence and assignment\noptimization, proposes new ways of combining the optimization of these two\ndecision sets, and opens promising research perspectives for the CVRP and its\nvariants.\n", "versions": [{"version": "v1", "created": "Fri, 16 Mar 2018 03:00:18 GMT"}], "update_date": "2018-03-19", "authors_parsed": [["Toffolo", "T\u00falio A. M.", ""], ["Vidal", "Thibaut", ""], ["Wauters", "Tony", ""]]}, {"id": "1803.06064", "submitter": "Chao-Chun Liang", "authors": "Chao-Chun Liang, Yu-Shiang Wong, Yi-Chung Lin and Keh-Yih Su", "title": "A Meaning-based Statistical English Math Word Problem Solver", "comments": "Accepted as a long paper at NAACL HLT 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce MeSys, a meaning-based approach, for solving English math word\nproblems (MWPs) via understanding and reasoning in this paper. It first\nanalyzes the text, transforms both body and question parts into their\ncorresponding logic forms, and then performs inference on them. The associated\ncontext of each quantity is represented with proposed role-tags (e.g., nsubj,\nverb, etc.), which provides the flexibility for annotating an extracted math\nquantity with its associated context information (i.e., the physical meaning of\nthis quantity). Statistical models are proposed to select the operator and\noperands. A noisy dataset is designed to assess if a solver solves MWPs mainly\nvia understanding or mechanical pattern matching. Experimental results show\nthat our approach outperforms existing systems on both benchmark datasets and\nthe noisy dataset, which demonstrates that the proposed approach understands\nthe meaning of each quantity in the text more.\n", "versions": [{"version": "v1", "created": "Fri, 16 Mar 2018 03:07:06 GMT"}, {"version": "v2", "created": "Fri, 6 Jul 2018 00:37:36 GMT"}], "update_date": "2018-07-09", "authors_parsed": [["Liang", "Chao-Chun", ""], ["Wong", "Yu-Shiang", ""], ["Lin", "Yi-Chung", ""], ["Su", "Keh-Yih", ""]]}, {"id": "1803.06092", "submitter": "Guangyu Robert Yang", "authors": "Guangyu Robert Yang, Igor Ganichev, Xiao-Jing Wang, Jonathon Shlens,\n  David Sussillo", "title": "A Dataset and Architecture for Visual Reasoning with a Working Memory", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A vexing problem in artificial intelligence is reasoning about events that\noccur in complex, changing visual stimuli such as in video analysis or game\nplay. Inspired by a rich tradition of visual reasoning and memory in cognitive\npsychology and neuroscience, we developed an artificial, configurable visual\nquestion and answer dataset (COG) to parallel experiments in humans and\nanimals. COG is much simpler than the general problem of video analysis, yet it\naddresses many of the problems relating to visual and logical reasoning and\nmemory -- problems that remain challenging for modern deep learning\narchitectures. We additionally propose a deep learning architecture that\nperforms competitively on other diagnostic VQA datasets (i.e. CLEVR) as well as\neasy settings of the COG dataset. However, several settings of COG result in\ndatasets that are progressively more challenging to learn. After training, the\nnetwork can zero-shot generalize to many new tasks. Preliminary analyses of the\nnetwork architectures trained on COG demonstrate that the network accomplishes\nthe task in a manner interpretable to humans.\n", "versions": [{"version": "v1", "created": "Fri, 16 Mar 2018 06:53:45 GMT"}, {"version": "v2", "created": "Fri, 20 Jul 2018 14:12:49 GMT"}], "update_date": "2018-07-23", "authors_parsed": [["Yang", "Guangyu Robert", ""], ["Ganichev", "Igor", ""], ["Wang", "Xiao-Jing", ""], ["Shlens", "Jonathon", ""], ["Sussillo", "David", ""]]}, {"id": "1803.06111", "submitter": "Richard Kenway", "authors": "Richard Kenway", "title": "Vulnerability of Deep Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cond-mat.dis-nn cond-mat.stat-mech cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Renormalisation Group (RG) provides a framework in which it is possible\nto assess whether a deep-learning network is sensitive to small changes in the\ninput data and hence prone to error, or susceptible to adversarial attack.\nDistinct classification outputs are associated with different RG fixed points\nand sensitivity to small changes in the input data is due to the presence of\nrelevant operators at a fixed point. A numerical scheme, based on Monte Carlo\nRG ideas, is proposed for identifying the existence of relevant operators and\nthe corresponding directions of greatest sensitivity in the input data. Thus, a\ntrained deep-learning network may be tested for its robustness and, if it is\nvulnerable to attack, dangerous perturbations of the input data identified.\n", "versions": [{"version": "v1", "created": "Fri, 16 Mar 2018 08:52:04 GMT"}], "update_date": "2018-03-19", "authors_parsed": [["Kenway", "Richard", ""]]}, {"id": "1803.06127", "submitter": "Roman Kalkreuth", "authors": "Roman Kalkreuth", "title": "Towards Advanced Phenotypic Mutations in Cartesian Genetic Programming", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cartesian Genetic Programming is often used with a point mutation as the sole\ngenetic operator. In this paper, we propose two phenotypic mutation techniques\nand take a step towards advanced phenotypic mutations in Cartesian Genetic\nProgramming. The functionality of the proposed mutations is inspired by\nbiological evolution which mutates DNA sequences by inserting and deleting\nnucleotides. Experiments with symbolic regression and boolean functions\nproblems show a better search performance when the proposed mutations are in\nuse. The results of our experiments indicate that the use of phenotypic\nmutations could be beneficial for the use of Cartesian Genetic Programming.\n", "versions": [{"version": "v1", "created": "Fri, 16 Mar 2018 09:43:47 GMT"}], "update_date": "2018-03-19", "authors_parsed": [["Kalkreuth", "Roman", ""]]}, {"id": "1803.06174", "submitter": "Michael Veale", "authors": "Michael Veale, Reuben Binns and Max Van Kleek", "title": "Some HCI Priorities for GDPR-Compliant Machine Learning", "comments": "8 pages, 0 figures, The General Data Protection Regulation: An\n  Opportunity for the CHI Community? (CHI-GDPR 2018), Workshop at ACM CHI'18,\n  22 April 2018, Montreal, Canada", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this short paper, we consider the roles of HCI in enabling the better\ngovernance of consequential machine learning systems using the rights and\nobligations laid out in the recent 2016 EU General Data Protection Regulation\n(GDPR)---a law which involves heavy interaction with people and systems.\nFocussing on those areas that relate to algorithmic systems in society, we\npropose roles for HCI in legal contexts in relation to fairness, bias and\ndiscrimination; data protection by design; data protection impact assessments;\ntransparency and explanations; the mitigation and understanding of automation\nbias; and the communication of envisaged consequences of processing.\n", "versions": [{"version": "v1", "created": "Fri, 16 Mar 2018 11:40:33 GMT"}], "update_date": "2018-03-19", "authors_parsed": [["Veale", "Michael", ""], ["Binns", "Reuben", ""], ["Van Kleek", "Max", ""]]}, {"id": "1803.06288", "submitter": "David Heeger", "authors": "David J. Heeger and Wayne E. Mackey", "title": "ORGaNICs: A Theory of Working Memory in Brains and Machines", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Working memory is a cognitive process that is responsible for temporarily\nholding and manipulating information. Most of the empirical neuroscience\nresearch on working memory has focused on measuring sustained activity in\nprefrontal cortex (PFC) and/or parietal cortex during simple delayed-response\ntasks, and most of the models of working memory have been based on neural\nintegrators. But working memory means much more than just holding a piece of\ninformation online. We describe a new theory of working memory, based on a\nrecurrent neural circuit that we call ORGaNICs (Oscillatory Recurrent GAted\nNeural Integrator Circuits). ORGaNICs are a variety of Long Short Term Memory\nunits (LSTMs), imported from machine learning and artificial intelligence.\nORGaNICs can be used to explain the complex dynamics of delay-period activity\nin prefrontal cortex (PFC) during a working memory task. The theory is\nanalytically tractable so that we can characterize the dynamics, and the theory\nprovides a means for reading out information from the dynamically varying\nresponses at any point in time, in spite of the complex dynamics. ORGaNICs can\nbe implemented with a biophysical (electrical circuit) model of pyramidal\ncells, combined with shunting inhibition via a thalamocortical loop. Although\nintroduced as a computational theory of working memory, ORGaNICs are also\napplicable to models of sensory processing, motor preparation and motor\ncontrol. ORGaNICs offer computational advantages compared to other varieties of\nLSTMs that are commonly used in AI applications. Consequently, ORGaNICs are a\nframework for canonical computation in brains and machines.\n", "versions": [{"version": "v1", "created": "Fri, 16 Mar 2018 16:04:09 GMT"}, {"version": "v2", "created": "Wed, 21 Mar 2018 20:04:04 GMT"}, {"version": "v3", "created": "Sun, 22 Apr 2018 15:55:23 GMT"}, {"version": "v4", "created": "Fri, 25 May 2018 18:25:38 GMT"}], "update_date": "2018-05-29", "authors_parsed": [["Heeger", "David J.", ""], ["Mackey", "Wayne E.", ""]]}, {"id": "1803.06333", "submitter": "Celestine D\\\"unner", "authors": "Celestine D\\\"unner, Thomas Parnell, Dimitrios Sarigiannis, Nikolas\n  Ioannou, Andreea Anghel, Gummadi Ravi, Madhusudanan Kandasamy, Haralampos\n  Pozidis", "title": "Snap ML: A Hierarchical Framework for Machine Learning", "comments": "in Proceedings of the Thirty-Second Conference on Neural Information\n  Processing Systems (NeurIPS 2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe a new software framework for fast training of generalized linear\nmodels. The framework, named Snap Machine Learning (Snap ML), combines recent\nadvances in machine learning systems and algorithms in a nested manner to\nreflect the hierarchical architecture of modern computing systems. We prove\ntheoretically that such a hierarchical system can accelerate training in\ndistributed environments where intra-node communication is cheaper than\ninter-node communication. Additionally, we provide a review of the\nimplementation of Snap ML in terms of GPU acceleration, pipelining,\ncommunication patterns and software architecture, highlighting aspects that\nwere critical for achieving high performance. We evaluate the performance of\nSnap ML in both single-node and multi-node environments, quantifying the\nbenefit of the hierarchical scheme and the data streaming functionality, and\ncomparing with other widely-used machine learning software frameworks. Finally,\nwe present a logistic regression benchmark on the Criteo Terabyte Click Logs\ndataset and show that Snap ML achieves the same test loss an order of magnitude\nfaster than any of the previously reported results, including those obtained\nusing TensorFlow and scikit-learn.\n", "versions": [{"version": "v1", "created": "Fri, 16 Mar 2018 17:37:12 GMT"}, {"version": "v2", "created": "Mon, 18 Jun 2018 11:30:36 GMT"}, {"version": "v3", "created": "Thu, 29 Nov 2018 17:17:55 GMT"}], "update_date": "2018-11-30", "authors_parsed": [["D\u00fcnner", "Celestine", ""], ["Parnell", "Thomas", ""], ["Sarigiannis", "Dimitrios", ""], ["Ioannou", "Nikolas", ""], ["Anghel", "Andreea", ""], ["Ravi", "Gummadi", ""], ["Kandasamy", "Madhusudanan", ""], ["Pozidis", "Haralampos", ""]]}, {"id": "1803.06422", "submitter": "Marco Valtorta", "authors": "Othar Hansson and Andrew Mayer and Marco Valtorta", "title": "A New Result on the Complexity of Heuristic Estimates for the A*\n  Algorithm", "comments": null, "journal-ref": "Artificial Intelligence, 55, 1 (May 1992), 129-143", "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Relaxed models are abstract problem descriptions generated by ignoring\nconstraints that are present in base-level problems. They play an important\nrole in planning and search algorithms, as it has been shown that the length of\nan optimal solution to a relaxed model yields a monotone heuristic for an A?\nsearch of a base-level problem. Optimal solutions to a relaxed model may be\ncomputed algorithmically or by search in a further relaxed model, leading to a\nsearch that explores a hierarchy of relaxed models. In this paper, we review\nthe traditional definition of problem relaxation and show that searching in the\nabstraction hierarchy created by problem relaxation will not reduce the\ncomputational effort required to find optimal solutions to the base- level\nproblem, unless the relaxed problem found in the hierarchy can be transformed\nby some optimization (e.g., subproblem factoring). Specifically, we prove that\nany A* search of the base-level using a heuristic h2 will largely dominate an\nA* search of the base-level using a heuristic h1, if h1 must be computed by an\nA* search of the relaxed model using h2.\n", "versions": [{"version": "v1", "created": "Fri, 16 Mar 2018 22:57:32 GMT"}], "update_date": "2018-03-20", "authors_parsed": [["Hansson", "Othar", ""], ["Mayer", "Andrew", ""], ["Valtorta", "Marco", ""]]}, {"id": "1803.06445", "submitter": "Leopoldo Bertossi", "authors": "Leopoldo Bertossi, Georg Gottlob and Reinhard Pichler", "title": "Datalog: Bag Semantics via Set Semantics", "comments": "Extended version of paper appearing in Proc. ICDT 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Duplicates in data management are common and problematic. In this work, we\npresent a translation of Datalog under bag semantics into a well-behaved\nextension of Datalog, the so-called {\\em warded Datalog}$^\\pm$, under set\nsemantics. From a theoretical point of view, this allows us to reason on bag\nsemantics by making use of the well-established theoretical foundations of set\nsemantics. From a practical point of view, this allows us to handle the bag\nsemantics of Datalog by powerful, existing query engines for the required\nextension of Datalog. This use of Datalog$^\\pm$ is extended to give a set\nsemantics to duplicates in Datalog$^\\pm$ itself. We investigate the properties\nof the resulting Datalog$^\\pm$ programs, the problem of deciding\nmultiplicities, and expressibility of some bag operations. Moreover, the\nproposed translation has the potential for interesting applications such as to\nMultiset Relational Algebra and the semantic web query language SPARQL with bag\nsemantics.\n", "versions": [{"version": "v1", "created": "Sat, 17 Mar 2018 02:00:47 GMT"}, {"version": "v2", "created": "Wed, 25 Jul 2018 18:30:24 GMT"}, {"version": "v3", "created": "Tue, 12 Feb 2019 16:16:36 GMT"}], "update_date": "2019-02-13", "authors_parsed": [["Bertossi", "Leopoldo", ""], ["Gottlob", "Georg", ""], ["Pichler", "Reinhard", ""]]}, {"id": "1803.06459", "submitter": "Yen-Chang Hsu", "authors": "Yen-Chang Hsu, Zheng Xu, Zsolt Kira, Jiawei Huang", "title": "Learning to Cluster for Proposal-Free Instance Segmentation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work proposed a novel learning objective to train a deep neural network\nto perform end-to-end image pixel clustering. We applied the approach to\ninstance segmentation, which is at the intersection of image semantic\nsegmentation and object detection. We utilize the most fundamental property of\ninstance labeling -- the pairwise relationship between pixels -- as the\nsupervision to formulate the learning objective, then apply it to train a fully\nconvolutional network (FCN) for learning to perform pixel-wise clustering. The\nresulting clusters can be used as the instance labeling directly. To support\nlabeling of an unlimited number of instance, we further formulate ideas from\ngraph coloring theory into the proposed learning objective. The evaluation on\nthe Cityscapes dataset demonstrates strong performance and therefore proof of\nthe concept. Moreover, our approach won the second place in the lane detection\ncompetition of 2017 CVPR Autonomous Driving Challenge, and was the top\nperformer without using external data.\n", "versions": [{"version": "v1", "created": "Sat, 17 Mar 2018 04:35:21 GMT"}], "update_date": "2018-03-20", "authors_parsed": [["Hsu", "Yen-Chang", ""], ["Xu", "Zheng", ""], ["Kira", "Zsolt", ""], ["Huang", "Jiawei", ""]]}, {"id": "1803.06500", "submitter": "Joseph Corneli", "authors": "Joseph Corneli, Ursula Martin, Dave Murray-Rust, Gabriela Rino Nesin,\n  and Alison Pease", "title": "Argumentation theory for mathematical argument", "comments": "44 pages; to appear in Argumentation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To adequately model mathematical arguments the analyst must be able to\nrepresent the mathematical objects under discussion and the relationships\nbetween them, as well as inferences drawn about these objects and relationships\nas the discourse unfolds. We introduce a framework with these properties, which\nhas been used to analyse mathematical dialogues and expository texts. The\nframework can recover salient elements of discourse at, and within, the\nsentence level, as well as the way mathematical content connects to form larger\nargumentative structures. We show how the framework might be used to support\ncomputational reasoning, and argue that it provides a more natural way to\nexamine the process of proving theorems than do Lamport's structured proofs.\n", "versions": [{"version": "v1", "created": "Sat, 17 Mar 2018 13:20:37 GMT"}, {"version": "v2", "created": "Sun, 15 Jul 2018 14:16:51 GMT"}], "update_date": "2018-07-17", "authors_parsed": [["Corneli", "Joseph", ""], ["Martin", "Ursula", ""], ["Murray-Rust", "Dave", ""], ["Nesin", "Gabriela Rino", ""], ["Pease", "Alison", ""]]}, {"id": "1803.06554", "submitter": "Pan Wei", "authors": "Pan Wei, John E. Ball, Derek T. Anderson", "title": "Fusion of an Ensemble of Augmented Image Detectors for Robust Object\n  Detection", "comments": "21 pages, 12 figures, journal paper, MDPI Sensors, 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI eess.IV", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  A significant challenge in object detection is accurate identification of an\nobject's position in image space, whereas one algorithm with one set of\nparameters is usually not enough, and the fusion of multiple algorithms and/or\nparameters can lead to more robust results. Herein, a new computational\nintelligence fusion approach based on the dynamic analysis of agreement among\nobject detection outputs is proposed. Furthermore, we propose an online versus\njust in training image augmentation strategy. Experiments comparing the results\nboth with and without fusion are presented. We demonstrate that the augmented\nand fused combination results are the best, with respect to higher accuracy\nrates and reduction of outlier influences. The approach is demonstrated in the\ncontext of cone, pedestrian and box detection for Advanced Driver Assistance\nSystems (ADAS) applications.\n", "versions": [{"version": "v1", "created": "Sat, 17 Mar 2018 19:16:26 GMT"}], "update_date": "2018-03-20", "authors_parsed": [["Wei", "Pan", ""], ["Ball", "John E.", ""], ["Anderson", "Derek T.", ""]]}, {"id": "1803.06555", "submitter": "Sumit Bhatia", "authors": "Sumit Bhatia, Purusharth Dwivedi and Avneet Kaur", "title": "Tell Me Why Is It So? Explaining Knowledge Graph Relationships by\n  Finding Descriptive Support Passages", "comments": "12 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the problem of finding descriptive explanations of facts stored in\na knowledge graph. This is important in high-risk domains such as healthcare,\nintelligence, etc. where users need additional information for decision making\nand is especially crucial for applications that rely on automatically\nconstructed knowledge bases where machine learned systems extract facts from an\ninput corpus and working of the extractors is opaque to the end-user. We follow\nan approach inspired from information retrieval and propose a simple and\nefficient, yet effective solution that takes into account passage level as well\nas document level properties to produce a ranked list of passages describing a\ngiven input relation. We test our approach using Wikidata as the knowledge base\nand Wikipedia as the source corpus and report results of user studies conducted\nto study the effectiveness of our proposed model.\n", "versions": [{"version": "v1", "created": "Sat, 17 Mar 2018 19:26:26 GMT"}], "update_date": "2018-03-20", "authors_parsed": [["Bhatia", "Sumit", ""], ["Dwivedi", "Purusharth", ""], ["Kaur", "Avneet", ""]]}, {"id": "1803.06563", "submitter": "Spyridon Samothrakis", "authors": "Spyridon Samothrakis", "title": "Viewpoint: Artificial Intelligence and Labour", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The welfare of modern societies has been intrinsically linked to wage labour.\nWith some exceptions, the modern human has to sell her labour-power to be able\nreproduce biologically and socially. Thus, a lingering fear of technological\nunemployment features predominately as a theme among Artificial Intelligence\nresearchers. In this short paper we show that, if past trends are anything to\ngo by, this fear is irrational. On the contrary, we argue that the main problem\nhumanity will be facing is the normalisation of extremely long working hours.\n", "versions": [{"version": "v1", "created": "Sat, 17 Mar 2018 20:08:49 GMT"}], "update_date": "2018-03-20", "authors_parsed": [["Samothrakis", "Spyridon", ""]]}, {"id": "1803.06581", "submitter": "Wenhu Chen", "authors": "Wenhu Chen, Wenhan Xiong, Xifeng Yan, William Wang", "title": "Variational Knowledge Graph Reasoning", "comments": "Accepted to NAACL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inferring missing links in knowledge graphs (KG) has attracted a lot of\nattention from the research community. In this paper, we tackle a practical\nquery answering task involving predicting the relation of a given entity pair.\nWe frame this prediction problem as an inference problem in a probabilistic\ngraphical model and aim at resolving it from a variational inference\nperspective. In order to model the relation between the query entity pair, we\nassume that there exists an underlying latent variable (paths connecting two\nnodes) in the KG, which carries the equivalent semantics of their relations.\nHowever, due to the intractability of connections in large KGs, we propose to\nuse variation inference to maximize the evidence lower bound. More\nspecifically, our framework (\\textsc{Diva}) is composed of three modules, i.e.\na posterior approximator, a prior (path finder), and a likelihood (path\nreasoner). By using variational inference, we are able to incorporate them\nclosely into a unified architecture and jointly optimize them to perform KG\nreasoning. With active interactions among these sub-modules, \\textsc{Diva} is\nbetter at handling noise and coping with more complex reasoning scenarios. In\norder to evaluate our method, we conduct the experiment of the link prediction\ntask on multiple datasets and achieve state-of-the-art performances on both\ndatasets.\n", "versions": [{"version": "v1", "created": "Sat, 17 Mar 2018 22:08:10 GMT"}, {"version": "v2", "created": "Thu, 5 Apr 2018 19:57:05 GMT"}, {"version": "v3", "created": "Tue, 23 Oct 2018 04:51:29 GMT"}], "update_date": "2018-10-24", "authors_parsed": [["Chen", "Wenhu", ""], ["Xiong", "Wenhan", ""], ["Yan", "Xifeng", ""], ["Wang", "William", ""]]}, {"id": "1803.06622", "submitter": "Christopher Kim", "authors": "Christopher Kim and Carson Chow", "title": "Learning recurrent dynamics in spiking networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.AI cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spiking activity of neurons engaged in learning and performing a task show\ncomplex spatiotemporal dynamics. While the output of recurrent network models\ncan learn to perform various tasks, the possible range of recurrent dynamics\nthat emerge after learning remains unknown. Here we show that modifying the\nrecurrent connectivity with a recursive least squares algorithm provides\nsufficient flexibility for synaptic and spiking rate dynamics of spiking\nnetworks to produce a wide range of spatiotemporal activity. We apply the\ntraining method to learn arbitrary firing patterns, stabilize irregular spiking\nactivity of a balanced network, and reproduce the heterogeneous spiking rate\npatterns of cortical neurons engaged in motor planning and movement. We\nidentify sufficient conditions for successful learning, characterize two types\nof learning errors, and assess the network capacity. Our findings show that\nsynaptically-coupled recurrent spiking networks possess a vast computational\ncapability that can support the diverse activity patterns in the brain.\n", "versions": [{"version": "v1", "created": "Sun, 18 Mar 2018 07:51:19 GMT"}, {"version": "v2", "created": "Sat, 18 Aug 2018 14:13:37 GMT"}], "update_date": "2018-08-21", "authors_parsed": [["Kim", "Christopher", ""], ["Chow", "Carson", ""]]}, {"id": "1803.06643", "submitter": "Alon Talmor", "authors": "Alon Talmor, Jonathan Berant", "title": "The Web as a Knowledge-base for Answering Complex Questions", "comments": "accepted as a long paper at NAACL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Answering complex questions is a time-consuming activity for humans that\nrequires reasoning and integration of information. Recent work on reading\ncomprehension made headway in answering simple questions, but tackling complex\nquestions is still an ongoing research challenge. Conversely, semantic parsers\nhave been successful at handling compositionality, but only when the\ninformation resides in a target knowledge-base. In this paper, we present a\nnovel framework for answering broad and complex questions, assuming answering\nsimple questions is possible using a search engine and a reading comprehension\nmodel. We propose to decompose complex questions into a sequence of simple\nquestions, and compute the final answer from the sequence of answers. To\nillustrate the viability of our approach, we create a new dataset of complex\nquestions, ComplexWebQuestions, and present a model that decomposes questions\nand interacts with the web to compute an answer. We empirically demonstrate\nthat question decomposition improves performance from 20.8 precision@1 to 27.5\nprecision@1 on this new dataset.\n", "versions": [{"version": "v1", "created": "Sun, 18 Mar 2018 11:28:12 GMT"}], "update_date": "2018-03-20", "authors_parsed": [["Talmor", "Alon", ""], ["Berant", "Jonathan", ""]]}, {"id": "1803.06644", "submitter": "Haris Aziz", "authors": "Haris Aziz and Jerome Lang and Jerome Monnot", "title": "Computing and Testing Pareto Optimal Committees", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.AI cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Selecting a set of alternatives based on the preferences of agents is an\nimportant problem in committee selection and beyond. Among the various criteria\nput forth for the desirability of a committee, Pareto optimality is a minimal\nand important requirement. As asking agents to specify their preferences over\nexponentially many subsets of alternatives is practically infeasible, we assume\nthat each agent specifies a weak order on single alternatives, from which a\npreference relation over subsets is derived using some preference extension. We\nconsider five prominent extensions (responsive, downward lexicographic, upward\nlexicographic, best, and worst). For each of them, we consider the\ncorresponding Pareto optimality notion, and we study the complexity of\ncomputing and verifying Pareto optimal outcomes. We also consider strategic\nissues: for four of the set extensions, we present a linear-time, Pareto\noptimal and strategyproof algorithm that even works for weak preferences.\n", "versions": [{"version": "v1", "created": "Sun, 18 Mar 2018 11:35:36 GMT"}], "update_date": "2018-03-20", "authors_parsed": [["Aziz", "Haris", ""], ["Lang", "Jerome", ""], ["Monnot", "Jerome", ""]]}, {"id": "1803.06773", "submitter": "Tuomas Haarnoja", "authors": "Tuomas Haarnoja, Vitchyr Pong, Aurick Zhou, Murtaza Dalal, Pieter\n  Abbeel, Sergey Levine", "title": "Composable Deep Reinforcement Learning for Robotic Manipulation", "comments": "Videos: https://sites.google.com/view/composing-real-world-policies/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Model-free deep reinforcement learning has been shown to exhibit good\nperformance in domains ranging from video games to simulated robotic\nmanipulation and locomotion. However, model-free methods are known to perform\npoorly when the interaction time with the environment is limited, as is the\ncase for most real-world robotic tasks. In this paper, we study how maximum\nentropy policies trained using soft Q-learning can be applied to real-world\nrobotic manipulation. The application of this method to real-world manipulation\nis facilitated by two important features of soft Q-learning. First, soft\nQ-learning can learn multimodal exploration strategies by learning policies\nrepresented by expressive energy-based models. Second, we show that policies\nlearned with soft Q-learning can be composed to create new policies, and that\nthe optimality of the resulting policy can be bounded in terms of the\ndivergence between the composed policies. This compositionality provides an\nespecially valuable tool for real-world manipulation, where constructing new\npolicies by composing existing skills can provide a large gain in efficiency\nover training from scratch. Our experimental evaluation demonstrates that soft\nQ-learning is substantially more sample efficient than prior model-free deep\nreinforcement learning methods, and that compositionality can be performed for\nboth simulated and real-world tasks.\n", "versions": [{"version": "v1", "created": "Mon, 19 Mar 2018 01:17:16 GMT"}], "update_date": "2018-03-20", "authors_parsed": [["Haarnoja", "Tuomas", ""], ["Pong", "Vitchyr", ""], ["Zhou", "Aurick", ""], ["Dalal", "Murtaza", ""], ["Abbeel", "Pieter", ""], ["Levine", "Sergey", ""]]}, {"id": "1803.06775", "submitter": "Davide Venturelli", "authors": "Kyle E. C. Booth, Minh Do, J. Christopher Beck, Eleanor Rieffel,\n  Davide Venturelli and Jeremy Frank", "title": "Comparing and Integrating Constraint Programming and Temporal Planning\n  for Quantum Circuit Compilation", "comments": "9 pages, 2 figures, Proceedings of the 28th International Conference\n  of Automated Planning and Scheduling 2018 (ICAPS-18)", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.AI cs.ET cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, the makespan-minimization problem of compiling a general class of\nquantum algorithms into near-term quantum processors has been introduced to the\nAI community. The research demonstrated that temporal planning is a strong\napproach for a class of quantum circuit compilation (QCC) problems. In this\npaper, we explore the use of constraint programming (CP) as an alternative and\ncomplementary approach to temporal planning. We extend previous work by\nintroducing two new problem variations that incorporate important\ncharacteristics identified by the quantum computing community. We apply\ntemporal planning and CP to the baseline and extended QCC problems as both\nstand-alone and hybrid approaches. Our hybrid methods use solutions found by\ntemporal planning to warm start CP, leveraging the ability of the former to\nfind satisficing solutions to problems with a high degree of task optionality,\nan area that CP typically struggles with. The CP model, benefiting from\ninferred bounds on planning horizon length and task counts provided by the warm\nstart, is then used to find higher quality solutions. Our empirical evaluation\nindicates that while stand-alone CP is only competitive for the smallest\nproblems, CP in our hybridization with temporal planning out-performs\nstand-alone temporal planning in the majority of problem classes.\n", "versions": [{"version": "v1", "created": "Mon, 19 Mar 2018 01:29:02 GMT"}], "update_date": "2018-03-20", "authors_parsed": [["Booth", "Kyle E. C.", ""], ["Do", "Minh", ""], ["Beck", "J. Christopher", ""], ["Rieffel", "Eleanor", ""], ["Venturelli", "Davide", ""], ["Frank", "Jeremy", ""]]}, {"id": "1803.06818", "submitter": "Majd Latah", "authors": "Majd Latah, Levent Toker", "title": "Artificial Intelligence Enabled Software Defined Networking: A\n  Comprehensive Overview", "comments": "This manuscript has been accepted for publication in IET Networks", "journal-ref": "https://digital-library.theiet.org/content/journals/10.1049/iet-net.2018.5082", "doi": "10.1049/iet-net.2018.5082", "report-no": null, "categories": "cs.AI cs.NI", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Software defined networking (SDN) represents a promising networking\narchitecture that combines central management and network programmability. SDN\nseparates the control plane from the data plane and moves the network\nmanagement to a central point, called the controller, that can be programmed\nand used as the brain of the network. Recently, the research community has\nshowed an increased tendency to benefit from the recent advancements in the\nartificial intelligence (AI) field to provide learning abilities and better\ndecision making in SDN. In this study, we provide a detailed overview of the\nrecent efforts to include AI in SDN. Our study showed that the research efforts\nfocused on three main sub-fields of AI namely: machine learning,\nmeta-heuristics and fuzzy inference systems. Accordingly, in this work we\ninvestigate their different application areas and potential use, as well as the\nimprovements achieved by including AI-based techniques in the SDN paradigm.\n", "versions": [{"version": "v1", "created": "Mon, 19 Mar 2018 07:05:25 GMT"}, {"version": "v2", "created": "Sun, 30 Sep 2018 12:16:36 GMT"}, {"version": "v3", "created": "Tue, 6 Nov 2018 17:00:40 GMT"}], "update_date": "2019-05-09", "authors_parsed": [["Latah", "Majd", ""], ["Toker", "Levent", ""]]}, {"id": "1803.06916", "submitter": "Xun Liang", "authors": "Xun Liang", "title": "Simulating the future urban growth in Xiongan New Area: a upcoming big\n  city in China", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.soc-ph cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  China made the announement to create the Xiongan New Area in Hebei in April\n1,2017. Thus a new magacity about 110km south west of Beijing will emerge.\nXiongan New Area is of great practial significant and historical significant\nfor transferring Beijing's non-capital function. Simulating the urban dynamics\nin Xiongan New Area can help planners to decide where to build the new urban\nand further manage the future urban growth. However, only a little research\nfocus on the future urban development in Xiongan New Area. In addition,\nprevious models are unable to simulate the urban dynamics in Xiongan New Area.\nBecause there are no original high density urbna for these models to learn the\ntransition rules.In this study, we proposed a C-FLUS model to solve such\nproblems. This framework was implemented by coupling a modified Cellular\nautomata(CA). An elaborately designed random planted seeds machanism based on\nlocal maximums is addressed in the CA model to better simulate the occurrence\nof the new urban. Through an analysis of the current driving forces, the C-FLUS\ncan detect the potential start zone and simulate the urban development under\ndifferent scenarios in Xiongan New Area. Our study shows that the new urban is\nmost likely to occur in northwest of Xiongxian, and it will rapidly extend to\nRongcheng and Anxin until almost cover the northern part of Xiongan New Area.\nMoreover, the method can help planners to evaluate the impact of urban\nexpansion in Xiongan New Area.\n", "versions": [{"version": "v1", "created": "Fri, 16 Mar 2018 15:32:54 GMT"}], "update_date": "2018-03-20", "authors_parsed": [["Liang", "Xun", ""]]}, {"id": "1803.06959", "submitter": "Ari Morcos", "authors": "Ari S. Morcos, David G.T. Barrett, Neil C. Rabinowitz, Matthew\n  Botvinick", "title": "On the importance of single directions for generalization", "comments": "ICLR 2018 conference paper; added additional methodological details", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite their ability to memorize large datasets, deep neural networks often\nachieve good generalization performance. However, the differences between the\nlearned solutions of networks which generalize and those which do not remain\nunclear. Additionally, the tuning properties of single directions (defined as\nthe activation of a single unit or some linear combination of units in response\nto some input) have been highlighted, but their importance has not been\nevaluated. Here, we connect these lines of inquiry to demonstrate that a\nnetwork's reliance on single directions is a good predictor of its\ngeneralization performance, across networks trained on datasets with different\nfractions of corrupted labels, across ensembles of networks trained on datasets\nwith unmodified labels, across different hyperparameters, and over the course\nof training. While dropout only regularizes this quantity up to a point, batch\nnormalization implicitly discourages single direction reliance, in part by\ndecreasing the class selectivity of individual units. Finally, we find that\nclass selectivity is a poor predictor of task importance, suggesting not only\nthat networks which generalize well minimize their dependence on individual\nunits by reducing their selectivity, but also that individually selective units\nmay not be necessary for strong network performance.\n", "versions": [{"version": "v1", "created": "Mon, 19 Mar 2018 14:42:19 GMT"}, {"version": "v2", "created": "Tue, 15 May 2018 10:03:34 GMT"}, {"version": "v3", "created": "Mon, 21 May 2018 10:48:45 GMT"}, {"version": "v4", "created": "Tue, 22 May 2018 09:55:52 GMT"}], "update_date": "2018-05-23", "authors_parsed": [["Morcos", "Ari S.", ""], ["Barrett", "David G. T.", ""], ["Rabinowitz", "Neil C.", ""], ["Botvinick", "Matthew", ""]]}, {"id": "1803.07055", "submitter": "Horia Mania", "authors": "Horia Mania, Aurelia Guy, Benjamin Recht", "title": "Simple random search provides a competitive approach to reinforcement\n  learning", "comments": "22 pages, 5 figures, 9 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A common belief in model-free reinforcement learning is that methods based on\nrandom search in the parameter space of policies exhibit significantly worse\nsample complexity than those that explore the space of actions. We dispel such\nbeliefs by introducing a random search method for training static, linear\npolicies for continuous control problems, matching state-of-the-art sample\nefficiency on the benchmark MuJoCo locomotion tasks. Our method also finds a\nnearly optimal controller for a challenging instance of the Linear Quadratic\nRegulator, a classical problem in control theory, when the dynamics are not\nknown. Computationally, our random search algorithm is at least 15 times more\nefficient than the fastest competing model-free methods on these benchmarks. We\ntake advantage of this computational efficiency to evaluate the performance of\nour method over hundreds of random seeds and many different hyperparameter\nconfigurations for each benchmark task. Our simulations highlight a high\nvariability in performance in these benchmark tasks, suggesting that commonly\nused estimations of sample efficiency do not adequately evaluate the\nperformance of RL algorithms.\n", "versions": [{"version": "v1", "created": "Mon, 19 Mar 2018 17:35:14 GMT"}], "update_date": "2018-03-20", "authors_parsed": [["Mania", "Horia", ""], ["Guy", "Aurelia", ""], ["Recht", "Benjamin", ""]]}, {"id": "1803.07067", "submitter": "Ashique Rupam Mahmood", "authors": "A. Rupam Mahmood, Dmytro Korenkevych, Brent J. Komer, James Bergstra", "title": "Setting up a Reinforcement Learning Task with a Real-World Robot", "comments": "Submitted to 2018 IEEE/RSJ International Conference on Intelligent\n  Robots and Systems (IROS)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning is a promising approach to developing hard-to-engineer\nadaptive solutions for complex and diverse robotic tasks. However, learning\nwith real-world robots is often unreliable and difficult, which resulted in\ntheir low adoption in reinforcement learning research. This difficulty is\nworsened by the lack of guidelines for setting up learning tasks with robots.\nIn this work, we develop a learning task with a UR5 robotic arm to bring to\nlight some key elements of a task setup and study their contributions to the\nchallenges with robots. We find that learning performance can be highly\nsensitive to the setup, and thus oversights and omissions in setup details can\nmake effective learning, reproducibility, and fair comparison hard. Our study\nsuggests some mitigating steps to help future experimenters avoid difficulties\nand pitfalls. We show that highly reliable and repeatable experiments can be\nperformed in our setup, indicating the possibility of reinforcement learning\nresearch extensively based on real-world robots.\n", "versions": [{"version": "v1", "created": "Mon, 19 Mar 2018 17:59:05 GMT"}], "update_date": "2018-03-20", "authors_parsed": [["Mahmood", "A. Rupam", ""], ["Korenkevych", "Dmytro", ""], ["Komer", "Brent J.", ""], ["Bergstra", "James", ""]]}, {"id": "1803.07131", "submitter": "Niels Justesen", "authors": "Niels Justesen, Sebastian Risi", "title": "Automated Curriculum Learning by Rewarding Temporally Rare Events", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reward shaping allows reinforcement learning (RL) agents to accelerate\nlearning by receiving additional reward signals. However, these signals can be\ndifficult to design manually, especially for complex RL tasks. We propose a\nsimple and general approach that determines the reward of pre-defined events by\ntheir rarity alone. Here events become less rewarding as they are experienced\nmore often, which encourages the agent to continually explore new types of\nevents as it learns. The adaptiveness of this reward function results in a form\nof automated curriculum learning that does not have to be specified by the\nexperimenter. We demonstrate that this \\emph{Rarity of Events} (RoE) approach\nenables the agent to succeed in challenging VizDoom scenarios without access to\nthe extrinsic reward from the environment. Furthermore, the results demonstrate\nthat RoE learns a more versatile policy that adapts well to critical changes in\nthe environment. Rewarding events based on their rarity could help in many\nunsolved RL environments that are characterized by sparse extrinsic rewards but\na plethora of known event types.\n", "versions": [{"version": "v1", "created": "Mon, 19 Mar 2018 19:35:44 GMT"}, {"version": "v2", "created": "Fri, 8 Jun 2018 12:11:35 GMT"}], "update_date": "2018-06-11", "authors_parsed": [["Justesen", "Niels", ""], ["Risi", "Sebastian", ""]]}, {"id": "1803.07133", "submitter": "Sidi Lu", "authors": "Sidi Lu, Yaoming Zhu, Weinan Zhang, Jun Wang, Yong Yu", "title": "Neural Text Generation: Past, Present and Beyond", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a systematic survey on recent development of neural text\ngeneration models. Specifically, we start from recurrent neural network\nlanguage models with the traditional maximum likelihood estimation training\nscheme and point out its shortcoming for text generation. We thus introduce the\nrecently proposed methods for text generation based on reinforcement learning,\nre-parametrization tricks and generative adversarial nets (GAN) techniques. We\ncompare different properties of these models and the corresponding techniques\nto handle their common problems such as gradient vanishing and generation\ndiversity. Finally, we conduct a benchmarking experiment with different types\nof neural text generation models on two well-known datasets and discuss the\nempirical results along with the aforementioned model properties.\n", "versions": [{"version": "v1", "created": "Thu, 15 Mar 2018 07:54:30 GMT"}], "update_date": "2018-03-21", "authors_parsed": [["Lu", "Sidi", ""], ["Zhu", "Yaoming", ""], ["Zhang", "Weinan", ""], ["Wang", "Jun", ""], ["Yu", "Yong", ""]]}, {"id": "1803.07139", "submitter": "No\\'e Casas", "authors": "Marta R. Costa-juss\\`a, Noe Casas, Maite Melero", "title": "English-Catalan Neural Machine Translation in the Biomedical Domain\n  through the cascade approach", "comments": "Full workshop proceedings can be found at\n  https://multilingualbio.bsc.es/wp-content/uploads/2018/03/LREC-2018-PROCEEDINGS-MultilingualBIO.pdf", "journal-ref": "Proceedings of workshop \"MultilingualBIO: Multilingual Biomedical\n  Text Processing\" of the 11th Edition of the Language Resources and Evaluation\n  Conference, 2018", "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes the methodology followed to build a neural machine\ntranslation system in the biomedical domain for the English-Catalan language\npair. This task can be considered a low-resourced task from the point of view\nof the domain and the language pair. To face this task, this paper reports\nexperiments on a cascade pivot strategy through Spanish for the neural machine\ntranslation using the English-Spanish SCIELO and Spanish-Catalan El Peri\\'odico\ndatabase. To test the final performance of the system, we have created a new\ntest data set for English-Catalan in the biomedical domain which is freely\navailable on request.\n", "versions": [{"version": "v1", "created": "Mon, 19 Mar 2018 19:48:48 GMT"}, {"version": "v2", "created": "Thu, 26 Apr 2018 15:22:04 GMT"}], "update_date": "2018-04-27", "authors_parsed": [["Costa-juss\u00e0", "Marta R.", ""], ["Casas", "Noe", ""], ["Melero", "Maite", ""]]}, {"id": "1803.07170", "submitter": "Edmond Awad", "authors": "Edmond Awad, Sydney Levine, Max Kleiman-Weiner, Sohan Dsouza, Joshua\n  B. Tenenbaum, Azim Shariff, Jean-Fran\\c{c}ois Bonnefon, Iyad Rahwan", "title": "Blaming humans in autonomous vehicle accidents: Shared responsibility\n  across levels of automation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When a semi-autonomous car crashes and harms someone, how are blame and\ncausal responsibility distributed across the human and machine drivers? In this\narticle, we consider cases in which a pedestrian was hit and killed by a car\nbeing operated under shared control of a primary and a secondary driver. We\nfind that when only one driver makes an error, that driver receives the blame\nand is considered causally responsible for the harm, regardless of whether that\ndriver is a machine or a human. However, when both drivers make errors in cases\nof shared control between a human and a machine, the blame and responsibility\nattributed to the machine is reduced. This finding portends a public\nunder-reaction to the malfunctioning AI components of semi-autonomous cars and\ntherefore has a direct policy implication: a bottom-up regulatory scheme (which\noperates through tort law that is adjudicated through the jury system) could\nfail to properly regulate the safety of shared-control vehicles; instead, a\ntop-down scheme (enacted through federal laws) may be called for.\n", "versions": [{"version": "v1", "created": "Mon, 19 Mar 2018 21:20:56 GMT"}, {"version": "v2", "created": "Wed, 21 Mar 2018 04:12:03 GMT"}], "update_date": "2018-03-22", "authors_parsed": [["Awad", "Edmond", ""], ["Levine", "Sydney", ""], ["Kleiman-Weiner", "Max", ""], ["Dsouza", "Sohan", ""], ["Tenenbaum", "Joshua B.", ""], ["Shariff", "Azim", ""], ["Bonnefon", "Jean-Fran\u00e7ois", ""], ["Rahwan", "Iyad", ""]]}, {"id": "1803.07233", "submitter": "Ziv Epstein", "authors": "Ziv Epstein, Blakeley H. Payne, Judy Hanwen Shen, Abhimanyu Dubey,\n  Bjarke Felbo, Matthew Groh, Nick Obradovich, Manuel Cebrian and Iyad Rahwan", "title": "Closing the AI Knowledge Gap", "comments": "8 pages, 3 figures, under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  AI researchers employ not only the scientific method, but also methodology\nfrom mathematics and engineering. However, the use of the scientific method -\nspecifically hypothesis testing - in AI is typically conducted in service of\nengineering objectives. Growing interest in topics such as fairness and\nalgorithmic bias show that engineering-focused questions only comprise a subset\nof the important questions about AI systems. This results in the AI Knowledge\nGap: the number of unique AI systems grows faster than the number of studies\nthat characterize these systems' behavior. To close this gap, we argue that the\nstudy of AI could benefit from the greater inclusion of researchers who are\nwell positioned to formulate and test hypotheses about the behavior of AI\nsystems. We examine the barriers preventing social and behavioral scientists\nfrom conducting such studies. Our diagnosis suggests that accelerating the\nscientific study of AI systems requires new incentives for academia and\nindustry, mediated by new tools and institutions. To address these needs, we\npropose a two-sided marketplace called TuringBox. On one side, AI contributors\nupload existing and novel algorithms to be studied scientifically by others. On\nthe other side, AI examiners develop and post machine intelligence tasks\ndesigned to evaluate and characterize algorithmic behavior. We discuss this\nmarket's potential to democratize the scientific study of AI behavior, and thus\nnarrow the AI Knowledge Gap.\n", "versions": [{"version": "v1", "created": "Tue, 20 Mar 2018 03:16:10 GMT"}], "update_date": "2018-03-21", "authors_parsed": [["Epstein", "Ziv", ""], ["Payne", "Blakeley H.", ""], ["Shen", "Judy Hanwen", ""], ["Dubey", "Abhimanyu", ""], ["Felbo", "Bjarke", ""], ["Groh", "Matthew", ""], ["Obradovich", "Nick", ""], ["Cebrian", "Manuel", ""], ["Rahwan", "Iyad", ""]]}, {"id": "1803.07244", "submitter": "Justin Gottschlich", "authors": "Justin Gottschlich, Armando Solar-Lezama, Nesime Tatbul, Michael\n  Carbin, Martin Rinard, Regina Barzilay, Saman Amarasinghe, Joshua B\n  Tenenbaum, Tim Mattson", "title": "The Three Pillars of Machine Programming", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.PL cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this position paper, we describe our vision of the future of machine\nprogramming through a categorical examination of three pillars of research.\nThose pillars are: (i) intention, (ii) invention, and(iii) adaptation.\nIntention emphasizes advancements in the human-to-computer and\ncomputer-to-machine-learning interfaces. Invention emphasizes the creation or\nrefinement of algorithms or core hardware and software building blocks through\nmachine learning (ML). Adaptation emphasizes advances in the use of ML-based\nconstructs to autonomously evolve software.\n", "versions": [{"version": "v1", "created": "Tue, 20 Mar 2018 03:51:29 GMT"}, {"version": "v2", "created": "Tue, 8 May 2018 22:48:14 GMT"}, {"version": "v3", "created": "Sat, 26 Jun 2021 16:11:04 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Gottschlich", "Justin", ""], ["Solar-Lezama", "Armando", ""], ["Tatbul", "Nesime", ""], ["Carbin", "Michael", ""], ["Rinard", "Martin", ""], ["Barzilay", "Regina", ""], ["Amarasinghe", "Saman", ""], ["Tenenbaum", "Joshua B", ""], ["Mattson", "Tim", ""]]}, {"id": "1803.07246", "submitter": "Cathy Wu", "authors": "Cathy Wu, Aravind Rajeswaran, Yan Duan, Vikash Kumar, Alexandre M\n  Bayen, Sham Kakade, Igor Mordatch, Pieter Abbeel", "title": "Variance Reduction for Policy Gradient with Action-Dependent Factorized\n  Baselines", "comments": "Accepted to ICLR 2018, Oral (2%)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Policy gradient methods have enjoyed great success in deep reinforcement\nlearning but suffer from high variance of gradient estimates. The high variance\nproblem is particularly exasperated in problems with long horizons or\nhigh-dimensional action spaces. To mitigate this issue, we derive a bias-free\naction-dependent baseline for variance reduction which fully exploits the\nstructural form of the stochastic policy itself and does not make any\nadditional assumptions about the MDP. We demonstrate and quantify the benefit\nof the action-dependent baseline through both theoretical analysis as well as\nnumerical results, including an analysis of the suboptimality of the optimal\nstate-dependent baseline. The result is a computationally efficient policy\ngradient algorithm, which scales to high-dimensional control problems, as\ndemonstrated by a synthetic 2000-dimensional target matching task. Our\nexperimental results indicate that action-dependent baselines allow for faster\nlearning on standard reinforcement learning benchmarks and high-dimensional\nhand manipulation and synthetic tasks. Finally, we show that the general idea\nof including additional information in baselines for improved variance\nreduction can be extended to partially observed and multi-agent tasks.\n", "versions": [{"version": "v1", "created": "Tue, 20 Mar 2018 03:52:04 GMT"}], "update_date": "2018-03-21", "authors_parsed": [["Wu", "Cathy", ""], ["Rajeswaran", "Aravind", ""], ["Duan", "Yan", ""], ["Kumar", "Vikash", ""], ["Bayen", "Alexandre M", ""], ["Kakade", "Sham", ""], ["Mordatch", "Igor", ""], ["Abbeel", "Pieter", ""]]}, {"id": "1803.07347", "submitter": "Li He", "authors": "Li He, Liang Wang, Kaipeng Liu, Bo Wu, Weinan Zhang", "title": "Optimizing Sponsored Search Ranking Strategy by Deep Reinforcement\n  Learning", "comments": "revise some content", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sponsored search is an indispensable business model and a major revenue\ncontributor of almost all the search engines. From the advertisers' side,\nparticipating in ranking the search results by paying for the sponsored search\nadvertisement to attract more awareness and purchase facilitates their\ncommercial goal. From the users' side, presenting personalized advertisement\nreflecting their propensity would make their online search experience more\nsatisfactory. Sponsored search platforms rank the advertisements by a ranking\nfunction to determine the list of advertisements to show and the charging price\nfor the advertisers. Hence, it is crucial to find a good ranking function which\ncan simultaneously satisfy the platform, the users and the advertisers.\nMoreover, advertisements showing positions under different queries from\ndifferent users may associate with advertisement candidates of different bid\nprice distributions and click probability distributions, which requires the\nranking functions to be optimized adaptively to the traffic characteristics. In\nthis work, we proposed a generic framework to optimize the ranking functions by\ndeep reinforcement learning methods. The framework is composed of two parts: an\noffline learning part which initializes the ranking functions by learning from\na simulated advertising environment, allowing adequate exploration of the\nranking function parameter space without hurting the performance of the\ncommercial platform. An online learning part which further optimizes the\nranking functions by adapting to the online data distribution. Experimental\nresults on a large-scale sponsored search platform confirm the effectiveness of\nthe proposed method.\n", "versions": [{"version": "v1", "created": "Tue, 20 Mar 2018 10:18:26 GMT"}, {"version": "v2", "created": "Wed, 21 Mar 2018 09:29:59 GMT"}, {"version": "v3", "created": "Mon, 26 Mar 2018 05:01:47 GMT"}], "update_date": "2018-03-28", "authors_parsed": [["He", "Li", ""], ["Wang", "Liang", ""], ["Liu", "Kaipeng", ""], ["Wu", "Bo", ""], ["Zhang", "Weinan", ""]]}, {"id": "1803.07438", "submitter": "Marcello Balduccini", "authors": "Marcello Balduccini, Edward Griffor, Michael Huth, Claire Vishik,\n  Martin Burns, David Wollman", "title": "Ontology-Based Reasoning about the Trustworthiness of Cyber-Physical\n  Systems", "comments": "IET PETRAS 2018 conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It has been challenging for the technical and regulatory communities to\nformulate requirements for trustworthiness of the cyber-physical systems (CPS)\ndue to the complexity of the issues associated with their design, deployment,\nand operations. The US National Institute of Standards and Technology (NIST),\nthrough a public working group, has released a CPS Framework that adopts a\nbroad and integrated view of CPS and positions trustworthiness among other\naspects of CPS. This paper takes the model created by the CPS Framework and its\nfurther developments one step further, by applying ontological approaches and\nreasoning techniques in order to achieve greater understanding of CPS. The\nexample analyzed in the paper demonstrates the enrichment of the original CPS\nmodel obtained through ontology and reasoning and its ability to deliver\nadditional insights to the developers and operators of CPS.\n", "versions": [{"version": "v1", "created": "Tue, 20 Mar 2018 13:55:07 GMT"}], "update_date": "2018-03-21", "authors_parsed": [["Balduccini", "Marcello", ""], ["Griffor", "Edward", ""], ["Huth", "Michael", ""], ["Vishik", "Claire", ""], ["Burns", "Martin", ""], ["Wollman", "David", ""]]}, {"id": "1803.07482", "submitter": "Ethan Knight", "authors": "Ethan Knight, Osher Lerner", "title": "Natural Gradient Deep Q-learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel algorithm to train a deep Q-learning agent using\nnatural-gradient techniques. We compare the original deep Q-network (DQN)\nalgorithm to its natural-gradient counterpart, which we refer to as NGDQN, on a\ncollection of classic control domains. Without employing target networks, NGDQN\nsignificantly outperforms DQN without target networks, and performs no worse\nthan DQN with target networks, suggesting that NGDQN stabilizes training and\ncan help reduce the need for additional hyperparameter tuning. We also find\nthat NGDQN is less sensitive to hyperparameter optimization relative to DQN.\nTogether these results suggest that natural-gradient techniques can improve\nvalue-function optimization in deep reinforcement learning.\n", "versions": [{"version": "v1", "created": "Tue, 20 Mar 2018 15:22:52 GMT"}, {"version": "v2", "created": "Tue, 13 Nov 2018 20:10:03 GMT"}], "update_date": "2018-11-15", "authors_parsed": [["Knight", "Ethan", ""], ["Lerner", "Osher", ""]]}, {"id": "1803.07517", "submitter": "Gabrielle Ras", "authors": "Gabrielle Ras, Marcel van Gerven, Pim Haselager", "title": "Explanation Methods in Deep Learning: Users, Values, Concerns and\n  Challenges", "comments": "14 pages, 1 figure, This article will appear as a chapter in\n  Explainable and Interpretable Models in Computer Vision and Machine Learning\n  Springer series on Challenges in Machine Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Issues regarding explainable AI involve four components: users, laws &\nregulations, explanations and algorithms. Together these components provide a\ncontext in which explanation methods can be evaluated regarding their adequacy.\nThe goal of this chapter is to bridge the gap between expert users and lay\nusers. Different kinds of users are identified and their concerns revealed,\nrelevant statements from the General Data Protection Regulation are analyzed in\nthe context of Deep Neural Networks (DNNs), a taxonomy for the classification\nof existing explanation methods is introduced, and finally, the various classes\nof explanation methods are analyzed to verify if user concerns are justified.\nOverall, it is clear that (visual) explanations can be given about various\naspects of the influence of the input on the output. However, it is noted that\nexplanation methods or interfaces for lay users are missing and we speculate\nwhich criteria these methods / interfaces should satisfy. Finally it is noted\nthat two important concerns are difficult to address with explanation methods:\nthe concern about bias in datasets that leads to biased DNNs, as well as the\nsuspicion about unfair outcomes.\n", "versions": [{"version": "v1", "created": "Tue, 20 Mar 2018 16:44:47 GMT"}, {"version": "v2", "created": "Thu, 29 Mar 2018 15:06:04 GMT"}], "update_date": "2018-03-30", "authors_parsed": [["Ras", "Gabrielle", ""], ["van Gerven", "Marcel", ""], ["Haselager", "Pim", ""]]}, {"id": "1803.07540", "submitter": "Michael Veale", "authors": "Lilian Edwards and Michael Veale", "title": "Enslaving the Algorithm: From a \"Right to an Explanation\" to a \"Right to\n  Better Decisions\"?", "comments": "14 pages, 0 figures", "journal-ref": "IEEE Security & Privacy (2018) 16(3), 46--54", "doi": "10.1109/MSP.2018.2701152", "report-no": null, "categories": "cs.AI cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As concerns about unfairness and discrimination in \"black box\" machine\nlearning systems rise, a legal \"right to an explanation\" has emerged as a\ncompellingly attractive approach for challenge and redress. We outline recent\ndebates on the limited provisions in European data protection law, and\nintroduce and analyze newer explanation rights in French administrative law and\nthe draft modernized Council of Europe Convention 108. While individual rights\ncan be useful, in privacy law they have historically unreasonably burdened the\naverage data subject. \"Meaningful information\" about algorithmic logics is more\ntechnically possible than commonly thought, but this exacerbates a new\n\"transparency fallacy\"---an illusion of remedy rather than anything\nsubstantively helpful. While rights-based approaches deserve a firm place in\nthe toolbox, other forms of governance, such as impact assessments, \"soft law,\"\njudicial review, and model repositories deserve more attention, alongside\ncatalyzing agencies acting for users to control algorithmic system design.\n", "versions": [{"version": "v1", "created": "Tue, 20 Mar 2018 17:27:03 GMT"}, {"version": "v2", "created": "Mon, 2 Jul 2018 08:39:07 GMT"}], "update_date": "2018-07-03", "authors_parsed": [["Edwards", "Lilian", ""], ["Veale", "Michael", ""]]}, {"id": "1803.07616", "submitter": "Ronan Riochet", "authors": "Ronan Riochet, Mario Ynocente Castro, Mathieu Bernard, Adam Lerer, Rob\n  Fergus, V\\'eronique Izard and Emmanuel Dupoux", "title": "IntPhys: A Framework and Benchmark for Visual Intuitive Physics\n  Reasoning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In order to reach human performance on complexvisual tasks, artificial\nsystems need to incorporate a sig-nificant amount of understanding of the world\nin termsof macroscopic objects, movements, forces, etc. Inspiredby work on\nintuitive physics in infants, we propose anevaluation benchmark which diagnoses\nhow much a givensystem understands about physics by testing whether itcan tell\napart well matched videos of possible versusimpossible events constructed with\na game engine. Thetest requires systems to compute a physical plausibilityscore\nover an entire video. It is free of bias and cantest a range of basic physical\nreasoning concepts. Wethen describe two Deep Neural Networks systems aimedat\nlearning intuitive physics in an unsupervised way,using only physically\npossible videos. The systems aretrained with a future semantic mask prediction\nobjectiveand tested on the possible versus impossible discrimi-nation task. The\nanalysis of their results compared tohuman data gives novel insights in the\npotentials andlimitations of next frame prediction architectures.\n", "versions": [{"version": "v1", "created": "Tue, 20 Mar 2018 19:29:46 GMT"}, {"version": "v2", "created": "Tue, 26 Jun 2018 09:20:37 GMT"}, {"version": "v3", "created": "Tue, 11 Feb 2020 10:05:20 GMT"}], "update_date": "2020-02-12", "authors_parsed": [["Riochet", "Ronan", ""], ["Castro", "Mario Ynocente", ""], ["Bernard", "Mathieu", ""], ["Lerer", "Adam", ""], ["Fergus", "Rob", ""], ["Izard", "V\u00e9ronique", ""], ["Dupoux", "Emmanuel", ""]]}, {"id": "1803.07710", "submitter": "KiJung Yoon", "authors": "KiJung Yoon, Renjie Liao, Yuwen Xiong, Lisa Zhang, Ethan Fetaya,\n  Raquel Urtasun, Richard Zemel, Xaq Pitkow", "title": "Inference in Probabilistic Graphical Models by Graph Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A fundamental computation for statistical inference and accurate\ndecision-making is to compute the marginal probabilities or most probable\nstates of task-relevant variables. Probabilistic graphical models can\nefficiently represent the structure of such complex data, but performing these\ninferences is generally difficult. Message-passing algorithms, such as belief\npropagation, are a natural way to disseminate evidence amongst correlated\nvariables while exploiting the graph structure, but these algorithms can\nstruggle when the conditional dependency graphs contain loops. Here we use\nGraph Neural Networks (GNNs) to learn a message-passing algorithm that solves\nthese inference tasks. We first show that the architecture of GNNs is\nwell-matched to inference tasks. We then demonstrate the efficacy of this\ninference approach by training GNNs on a collection of graphical models and\nshowing that they substantially outperform belief propagation on loopy graphs.\nOur message-passing algorithms generalize out of the training set to larger\ngraphs and graphs with different structure.\n", "versions": [{"version": "v1", "created": "Wed, 21 Mar 2018 01:09:07 GMT"}, {"version": "v2", "created": "Thu, 22 Mar 2018 14:09:34 GMT"}, {"version": "v3", "created": "Fri, 25 May 2018 21:26:30 GMT"}, {"version": "v4", "created": "Wed, 26 Jun 2019 15:02:25 GMT"}, {"version": "v5", "created": "Thu, 27 Jun 2019 15:10:06 GMT"}], "update_date": "2019-06-28", "authors_parsed": [["Yoon", "KiJung", ""], ["Liao", "Renjie", ""], ["Xiong", "Yuwen", ""], ["Zhang", "Lisa", ""], ["Fetaya", "Ethan", ""], ["Urtasun", "Raquel", ""], ["Zemel", "Richard", ""], ["Pitkow", "Xaq", ""]]}, {"id": "1803.07712", "submitter": "Furui Liu", "authors": "Furui Liu, Laiwan Chan", "title": "Causal Inference on Discrete Data via Estimating Distance Correlations", "comments": null, "journal-ref": "Neural Computation, Vol. 28, No. 5, 2016", "doi": "10.1162/NECO_a_00820", "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we deal with the problem of inferring causal directions when\nthe data is on discrete domain. By considering the distribution of the cause\n$P(X)$ and the conditional distribution mapping cause to effect $P(Y|X)$ as\nindependent random variables, we propose to infer the causal direction via\ncomparing the distance correlation between $P(X)$ and $P(Y|X)$ with the\ndistance correlation between $P(Y)$ and $P(X|Y)$. We infer \"$X$ causes $Y$\" if\nthe dependence coefficient between $P(X)$ and $P(Y|X)$ is smaller. Experiments\nare performed to show the performance of the proposed method.\n", "versions": [{"version": "v1", "created": "Wed, 21 Mar 2018 01:39:08 GMT"}, {"version": "v2", "created": "Thu, 22 Mar 2018 15:47:04 GMT"}, {"version": "v3", "created": "Tue, 7 Aug 2018 03:04:11 GMT"}], "update_date": "2018-08-08", "authors_parsed": [["Liu", "Furui", ""], ["Chan", "Laiwan", ""]]}, {"id": "1803.07724", "submitter": "Jasdeep Singh", "authors": "Jasdeep Singh, Vincent Ying, Alex Nutkiewicz", "title": "Attention on Attention: Architectures for Visual Question Answering\n  (VQA)", "comments": "Visual Question Answering Project", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Visual Question Answering (VQA) is an increasingly popular topic in deep\nlearning research, requiring coordination of natural language processing and\ncomputer vision modules into a single architecture. We build upon the model\nwhich placed first in the VQA Challenge by developing thirteen new attention\nmechanisms and introducing a simplified classifier. We performed 300 GPU hours\nof extensive hyperparameter and architecture searches and were able to achieve\nan evaluation score of 64.78%, outperforming the existing state-of-the-art\nsingle model's validation score of 63.15%.\n", "versions": [{"version": "v1", "created": "Wed, 21 Mar 2018 03:05:58 GMT"}], "update_date": "2018-03-22", "authors_parsed": [["Singh", "Jasdeep", ""], ["Ying", "Vincent", ""], ["Nutkiewicz", "Alex", ""]]}, {"id": "1803.07729", "submitter": "Xin Wang", "authors": "Xin Wang, Wenhan Xiong, Hongmin Wang, William Yang Wang", "title": "Look Before You Leap: Bridging Model-Free and Model-Based Reinforcement\n  Learning for Planned-Ahead Vision-and-Language Navigation", "comments": "21 pages, 7 figures, with supplementary material", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CL cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing research studies on vision and language grounding for robot\nnavigation focus on improving model-free deep reinforcement learning (DRL)\nmodels in synthetic environments. However, model-free DRL models do not\nconsider the dynamics in the real-world environments, and they often fail to\ngeneralize to new scenes. In this paper, we take a radical approach to bridge\nthe gap between synthetic studies and real-world practices---We propose a\nnovel, planned-ahead hybrid reinforcement learning model that combines\nmodel-free and model-based reinforcement learning to solve a real-world\nvision-language navigation task. Our look-ahead module tightly integrates a\nlook-ahead policy model with an environment model that predicts the next state\nand the reward. Experimental results suggest that our proposed method\nsignificantly outperforms the baselines and achieves the best on the real-world\nRoom-to-Room dataset. Moreover, our scalable method is more generalizable when\ntransferring to unseen environments.\n", "versions": [{"version": "v1", "created": "Wed, 21 Mar 2018 03:21:38 GMT"}, {"version": "v2", "created": "Thu, 26 Jul 2018 06:10:27 GMT"}], "update_date": "2018-07-27", "authors_parsed": [["Wang", "Xin", ""], ["Xiong", "Wenhan", ""], ["Wang", "Hongmin", ""], ["Wang", "William Yang", ""]]}, {"id": "1803.07738", "submitter": "Zhilei Liu", "authors": "Haotian Guan, Zhilei Liu, Longbiao Wang, Jianwu Dang, Ruiguo Yu", "title": "Speech Emotion Recognition Considering Local Dynamic Features", "comments": "10 pages, 3 figures, accepted by ISSP 2017", "journal-ref": null, "doi": "10.1007/978-3-030-00126-1_2", "report-no": null, "categories": "cs.HC cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, increasing attention has been directed to the study of the speech\nemotion recognition, in which global acoustic features of an utterance are\nmostly used to eliminate the content differences. However, the expression of\nspeech emotion is a dynamic process, which is reflected through dynamic\ndurations, energies, and some other prosodic information when one speaks. In\nthis paper, a novel local dynamic pitch probability distribution feature, which\nis obtained by drawing the histogram, is proposed to improve the accuracy of\nspeech emotion recognition. Compared with most of the previous works using\nglobal features, the proposed method takes advantage of the local dynamic\ninformation conveyed by the emotional speech. Several experiments on Berlin\nDatabase of Emotional Speech are conducted to verify the effectiveness of the\nproposed method. The experimental results demonstrate that the local dynamic\ninformation obtained with the proposed method is more effective for speech\nemotion recognition than the traditional global features.\n", "versions": [{"version": "v1", "created": "Wed, 21 Mar 2018 03:52:26 GMT"}], "update_date": "2018-11-21", "authors_parsed": [["Guan", "Haotian", ""], ["Liu", "Zhilei", ""], ["Wang", "Longbiao", ""], ["Dang", "Jianwu", ""], ["Yu", "Ruiguo", ""]]}, {"id": "1803.07770", "submitter": "Christopher J. Cueva", "authors": "Christopher J. Cueva and Xue-Xin Wei", "title": "Emergence of grid-like representations by training recurrent neural\n  networks to perform spatial localization", "comments": null, "journal-ref": "International Conference on Learning Representations (ICLR) 2018", "doi": null, "report-no": null, "categories": "q-bio.NC cs.AI cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Decades of research on the neural code underlying spatial navigation have\nrevealed a diverse set of neural response properties. The Entorhinal Cortex\n(EC) of the mammalian brain contains a rich set of spatial correlates,\nincluding grid cells which encode space using tessellating patterns. However,\nthe mechanisms and functional significance of these spatial representations\nremain largely mysterious. As a new way to understand these neural\nrepresentations, we trained recurrent neural networks (RNNs) to perform\nnavigation tasks in 2D arenas based on velocity inputs. Surprisingly, we find\nthat grid-like spatial response patterns emerge in trained networks, along with\nunits that exhibit other spatial correlates, including border cells and\nband-like cells. All these different functional types of neurons have been\nobserved experimentally. The order of the emergence of grid-like and border\ncells is also consistent with observations from developmental studies.\nTogether, our results suggest that grid cells, border cells and others as\nobserved in EC may be a natural solution for representing space efficiently\ngiven the predominant recurrent connections in the neural circuits.\n", "versions": [{"version": "v1", "created": "Wed, 21 Mar 2018 07:09:57 GMT"}], "update_date": "2018-05-11", "authors_parsed": [["Cueva", "Christopher J.", ""], ["Wei", "Xue-Xin", ""]]}, {"id": "1803.07828", "submitter": "Tommaso Soru", "authors": "Tommaso Soru, Stefano Ruberto, Diego Moussallem, Andr\\'e Valdestilhas,\n  Alexander Bigerl, Edgard Marx, Diego Esteves", "title": "Expeditious Generation of Knowledge Graph Embeddings", "comments": "Submitted to the Archives of Data Science, Series A; 14 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge Graph Embedding methods aim at representing entities and relations\nin a knowledge base as points or vectors in a continuous vector space. Several\napproaches using embeddings have shown promising results on tasks such as link\nprediction, entity recommendation, question answering, and triplet\nclassification. However, only a few methods can compute low-dimensional\nembeddings of very large knowledge bases without needing state-of-the-art\ncomputational resources. In this paper, we propose KG2Vec, a simple and fast\napproach to Knowledge Graph Embedding based on the skip-gram model. Instead of\nusing a predefined scoring function, we learn it relying on Long Short-Term\nMemories. We show that our embeddings achieve results comparable with the most\nscalable approaches on knowledge graph completion as well as on a new metric.\nYet, KG2Vec can embed large graphs in lesser time by processing more than 250\nmillion triples in less than 7 hours on common hardware.\n", "versions": [{"version": "v1", "created": "Wed, 21 Mar 2018 10:06:28 GMT"}, {"version": "v2", "created": "Fri, 9 Nov 2018 14:26:16 GMT"}], "update_date": "2018-11-12", "authors_parsed": [["Soru", "Tommaso", ""], ["Ruberto", "Stefano", ""], ["Moussallem", "Diego", ""], ["Valdestilhas", "Andr\u00e9", ""], ["Bigerl", "Alexander", ""], ["Marx", "Edgard", ""], ["Esteves", "Diego", ""]]}, {"id": "1803.07847", "submitter": "Giacomo Kahn", "authors": "Alexandre Bazin (LIP6), Jessie Carbonnel (MAREL), Marianne Huchard\n  (MAREL), Giacomo Kahn (LIMOS)", "title": "On-demand Relational Concept Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.AI cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Formal Concept Analysis and its associated conceptual structures have been\nused to support exploratory search through conceptual navigation. Relational\nConcept Analysis (RCA) is an extension of Formal Concept Analysis to process\nrelational datasets. RCA and its multiple interconnected structures represent\ngood candidates to support exploratory search in relational datasets, as they\nare enabling navigation within a structure as well as between the connected\nstructures. However, building the entire structures does not present an\nefficient solution to explore a small localised area of the dataset, for\ninstance to retrieve the closest alternatives to a given query. In these cases,\ngenerating only a concept and its neighbour concepts at each navigation step\nappears as a less costly alternative. In this paper, we propose an algorithm to\ncompute a concept and its neighbourhood in extended concept lattices. The\nconcepts are generated directly from the relational context family, and possess\nboth formal and relational attributes. The algorithm takes into account two RCA\nscaling operators. We illustrate it on an example.\n", "versions": [{"version": "v1", "created": "Wed, 21 Mar 2018 10:50:26 GMT"}], "update_date": "2018-03-22", "authors_parsed": [["Bazin", "Alexandre", "", "LIP6"], ["Carbonnel", "Jessie", "", "MAREL"], ["Huchard", "Marianne", "", "MAREL"], ["Kahn", "Giacomo", "", "LIMOS"]]}, {"id": "1803.07980", "submitter": "Tianchen Zhao Mr.", "authors": "Tianchen Zhao", "title": "Information Theoretic Interpretation of Deep learning", "comments": "17 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.IT math.IT stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We interpret part of the experimental results of Shwartz-Ziv and Tishby\n[2017]. Inspired by these results, we established a conjecture of the dynamics\nof the machinary of deep neural network. This conjecture can be used to explain\nthe counterpart result by Saxe et al. [2018].\n", "versions": [{"version": "v1", "created": "Wed, 21 Mar 2018 16:03:29 GMT"}, {"version": "v2", "created": "Thu, 22 Mar 2018 02:36:59 GMT"}], "update_date": "2018-03-23", "authors_parsed": [["Zhao", "Tianchen", ""]]}, {"id": "1803.08024", "submitter": "Kuang-Huei Lee", "authors": "Kuang-Huei Lee, Xi Chen, Gang Hua, Houdong Hu, Xiaodong He", "title": "Stacked Cross Attention for Image-Text Matching", "comments": "Accepted to ECCV 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study the problem of image-text matching. Inferring the\nlatent semantic alignment between objects or other salient stuff (e.g. snow,\nsky, lawn) and the corresponding words in sentences allows to capture\nfine-grained interplay between vision and language, and makes image-text\nmatching more interpretable. Prior work either simply aggregates the similarity\nof all possible pairs of regions and words without attending differentially to\nmore and less important words or regions, or uses a multi-step attentional\nprocess to capture limited number of semantic alignments which is less\ninterpretable. In this paper, we present Stacked Cross Attention to discover\nthe full latent alignments using both image regions and words in a sentence as\ncontext and infer image-text similarity. Our approach achieves the\nstate-of-the-art results on the MS-COCO and Flickr30K datasets. On Flickr30K,\nour approach outperforms the current best methods by 22.1% relatively in text\nretrieval from image query, and 18.2% relatively in image retrieval with text\nquery (based on Recall@1). On MS-COCO, our approach improves sentence retrieval\nby 17.8% relatively and image retrieval by 16.6% relatively (based on Recall@1\nusing the 5K test set). Code has been made available at:\nhttps://github.com/kuanghuei/SCAN.\n", "versions": [{"version": "v1", "created": "Wed, 21 Mar 2018 17:22:27 GMT"}, {"version": "v2", "created": "Mon, 23 Jul 2018 04:41:57 GMT"}], "update_date": "2018-07-24", "authors_parsed": [["Lee", "Kuang-Huei", ""], ["Chen", "Xi", ""], ["Hua", "Gang", ""], ["Hu", "Houdong", ""], ["He", "Xiaodong", ""]]}, {"id": "1803.08037", "submitter": "Pedro Felzenszwalb", "authors": "Pedro F. Felzenszwalb", "title": "Similar Elements and Metric Labeling on Complete Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a problem that involves finding similar elements in a collection\nof sets. The problem is motivated by applications in machine learning and\npattern recognition. We formulate the similar elements problem as an\noptimization and give an efficient approximation algorithm that finds a\nsolution within a factor of 2 of the optimal. The similar elements problem is a\nspecial case of the metric labeling problem and we also give an efficient\n2-approximation algorithm for the metric labeling problem on complete graphs.\n", "versions": [{"version": "v1", "created": "Wed, 21 Mar 2018 17:55:02 GMT"}, {"version": "v2", "created": "Sat, 24 Mar 2018 13:38:50 GMT"}], "update_date": "2018-03-28", "authors_parsed": [["Felzenszwalb", "Pedro F.", ""]]}, {"id": "1803.08137", "submitter": "Sathya N. Ravi", "authors": "Sathya N. Ravi, Ronak Mehta, Vikas Singh", "title": "Robust Blind Deconvolution via Mirror Descent", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We revisit the Blind Deconvolution problem with a focus on understanding its\nrobustness and convergence properties. Provable robustness to noise and other\nperturbations is receiving recent interest in vision, from obtaining immunity\nto adversarial attacks to assessing and describing failure modes of algorithms\nin mission critical applications. Further, many blind deconvolution methods\nbased on deep architectures internally make use of or optimize the basic\nformulation, so a clearer understanding of how this sub-module behaves, when it\ncan be solved, and what noise injection it can tolerate is a first order\nrequirement. We derive new insights into the theoretical underpinnings of blind\ndeconvolution. The algorithm that emerges has nice convergence guarantees and\nis provably robust in a sense we formalize in the paper. Interestingly, these\ntechnical results play out very well in practice, where on standard datasets\nour algorithm yields results competitive with or superior to the state of the\nart. Keywords: blind deconvolution, robust continuous optimization\n", "versions": [{"version": "v1", "created": "Wed, 21 Mar 2018 20:55:26 GMT"}], "update_date": "2018-03-23", "authors_parsed": [["Ravi", "Sathya N.", ""], ["Mehta", "Ronak", ""], ["Singh", "Vikas", ""]]}, {"id": "1803.08240", "submitter": "Stephen Merity", "authors": "Stephen Merity, Nitish Shirish Keskar, Richard Socher", "title": "An Analysis of Neural Language Modeling at Multiple Scales", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many of the leading approaches in language modeling introduce novel, complex\nand specialized architectures. We take existing state-of-the-art word level\nlanguage models based on LSTMs and QRNNs and extend them to both larger\nvocabularies as well as character-level granularity. When properly tuned, LSTMs\nand QRNNs achieve state-of-the-art results on character-level (Penn Treebank,\nenwik8) and word-level (WikiText-103) datasets, respectively. Results are\nobtained in only 12 hours (WikiText-103) to 2 days (enwik8) using a single\nmodern GPU.\n", "versions": [{"version": "v1", "created": "Thu, 22 Mar 2018 06:25:47 GMT"}], "update_date": "2018-03-23", "authors_parsed": [["Merity", "Stephen", ""], ["Keskar", "Nitish Shirish", ""], ["Socher", "Richard", ""]]}, {"id": "1803.08287", "submitter": "Felix Berkenkamp", "authors": "Torsten Koller, Felix Berkenkamp, Matteo Turchetta, Andreas Krause", "title": "Learning-based Model Predictive Control for Safe Exploration", "comments": "Proc. of the Conference on Decision and Control, 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SY cs.AI cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning-based methods have been successful in solving complex control tasks\nwithout significant prior knowledge about the system. However, these methods\ntypically do not provide any safety guarantees, which prevents their use in\nsafety-critical, real-world applications. In this paper, we present a\nlearning-based model predictive control scheme that can provide provable\nhigh-probability safety guarantees. To this end, we exploit regularity\nassumptions on the dynamics in terms of a Gaussian process prior to construct\nprovably accurate confidence intervals on predicted trajectories. Unlike\nprevious approaches, we do not assume that model uncertainties are independent.\nBased on these predictions, we guarantee that trajectories satisfy safety\nconstraints. Moreover, we use a terminal set constraint to recursively\nguarantee the existence of safe control actions at every iteration. In our\nexperiments, we show that the resulting algorithm can be used to safely and\nefficiently explore and learn about dynamic systems.\n", "versions": [{"version": "v1", "created": "Thu, 22 Mar 2018 09:41:45 GMT"}, {"version": "v2", "created": "Tue, 25 Sep 2018 14:58:17 GMT"}, {"version": "v3", "created": "Wed, 7 Nov 2018 11:08:25 GMT"}], "update_date": "2018-11-08", "authors_parsed": [["Koller", "Torsten", ""], ["Berkenkamp", "Felix", ""], ["Turchetta", "Matteo", ""], ["Krause", "Andreas", ""]]}, {"id": "1803.08343", "submitter": "Antonio Sgorbissa", "authors": "Barbara Bruno, Fulvio Mastrogiovanni, Federico Pecora, Antonio\n  Sgorbissa and Alessandro Saffiotti", "title": "A framework for Culture-aware Robots based on Fuzzy Logic", "comments": "Presented at: 2017 IEEE International Conference on Fuzzy Systems\n  (FUZZ-IEEE), Naples, Italy, 2017", "journal-ref": "Proc. 2017 IEEE International Conference on Fuzzy Systems\n  (FUZZ-IEEE), Naples, Italy, 2017", "doi": "10.1109/FUZZ-IEEE.2017.8015750", "report-no": null, "categories": "cs.RO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cultural adaptation, i.e., the matching of a robot's behaviours to the\ncultural norms and preferences of its user, is a well known key requirement for\nthe success of any assistive application. However, culture-dependent robot\nbehaviours are often implicitly set by designers, thus not allowing for an easy\nand automatic adaptation to different cultures. This paper presents a method\nfor the design of culture-aware robots, that can automatically adapt their\nbehaviour to conform to a given culture. We propose a mapping from cultural\nfactors to related parameters of robot behaviours which relies on linguistic\nvariables to encode heterogeneous cultural factors in a uniform formalism, and\non fuzzy rules to encode qualitative relations among multiple variables. We\nillustrate the approach in two practical case studies.\n", "versions": [{"version": "v1", "created": "Thu, 22 Mar 2018 13:29:52 GMT"}], "update_date": "2018-03-23", "authors_parsed": [["Bruno", "Barbara", ""], ["Mastrogiovanni", "Fulvio", ""], ["Pecora", "Federico", ""], ["Sgorbissa", "Antonio", ""], ["Saffiotti", "Alessandro", ""]]}, {"id": "1803.08355", "submitter": "Alexandre Garcia", "authors": "Alexandre Garcia, Slim Essid, Chlo\\'e Clavel, Florence d'Alch\\'e-Buc", "title": "Structured Output Learning with Abstention: Application to Accurate\n  Opinion Prediction", "comments": null, "journal-ref": "Proceedings of Machine Learning Research 80 (2018) 1695-1703", "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by Supervised Opinion Analysis, we propose a novel framework\ndevoted to Structured Output Learning with Abstention (SOLA). The structure\nprediction model is able to abstain from predicting some labels in the\nstructured output at a cost chosen by the user in a flexible way. For that\npurpose, we decompose the problem into the learning of a pair of predictors,\none devoted to structured abstention and the other, to structured output\nprediction. To compare fully labeled training data with predictions potentially\ncontaining abstentions, we define a wide class of asymmetric abstention-aware\nlosses. Learning is achieved by surrogate regression in an appropriate feature\nspace while prediction with abstention is performed by solving a new pre-image\nproblem. Thus, SOLA extends recent ideas about Structured Output Prediction via\nsurrogate problems and calibration theory and enjoys statistical guarantees on\nthe resulting excess risk. Instantiated on a hierarchical abstention-aware\nloss, SOLA is shown to be relevant for fine-grained opinion mining and gives\nstate-of-the-art results on this task. Moreover, the abstention-aware\nrepresentations can be used to competitively predict user-review ratings based\non a sentence-level opinion predictor.\n", "versions": [{"version": "v1", "created": "Thu, 22 Mar 2018 13:48:30 GMT"}, {"version": "v2", "created": "Fri, 8 Jun 2018 13:31:51 GMT"}], "update_date": "2019-01-16", "authors_parsed": [["Garcia", "Alexandre", ""], ["Essid", "Slim", ""], ["Clavel", "Chlo\u00e9", ""], ["d'Alch\u00e9-Buc", "Florence", ""]]}, {"id": "1803.08419", "submitter": "Vinayak Mathur", "authors": "Vinayak Mathur and Arpit Singh", "title": "The Rapidly Changing Landscape of Conversational Agents", "comments": "14 pages, 7 figures. arXiv admin note: text overlap with\n  arXiv:1704.07130, arXiv:1507.04808, arXiv:1603.06155, arXiv:1611.06997,\n  arXiv:1704.08966 by other authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conversational agents have become ubiquitous, ranging from goal-oriented\nsystems for helping with reservations to chit-chat models found in modern\nvirtual assistants. In this survey paper, we explore this fascinating field. We\nlook at some of the pioneering work that defined the field and gradually move\nto the current state-of-the-art models. We look at statistical, neural,\ngenerative adversarial network based and reinforcement learning based\napproaches and how they evolved. Along the way we discuss various challenges\nthat the field faces, lack of context in utterances, not having a good\nquantitative metric to compare models, lack of trust in agents because they do\nnot have a consistent persona etc. We structure this paper in a way that\nanswers these pertinent questions and discusses competing approaches to solve\nthem.\n", "versions": [{"version": "v1", "created": "Thu, 22 Mar 2018 15:53:59 GMT"}, {"version": "v2", "created": "Sat, 24 Mar 2018 16:52:27 GMT"}], "update_date": "2018-03-29", "authors_parsed": [["Mathur", "Vinayak", ""], ["Singh", "Arpit", ""]]}, {"id": "1803.08456", "submitter": "Stephan Alaniz", "authors": "Stephan Alaniz", "title": "Deep Reinforcement Learning with Model Learning and Monte Carlo Tree\n  Search in Minecraft", "comments": "The 3rd Multidisciplinary Conference on Reinforcement Learning and\n  Decision Making (RLDM) 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep reinforcement learning has been successfully applied to several\nvisual-input tasks using model-free methods. In this paper, we propose a\nmodel-based approach that combines learning a DNN-based transition model with\nMonte Carlo tree search to solve a block-placing task in Minecraft. Our learned\ntransition model predicts the next frame and the rewards one step ahead given\nthe last four frames of the agent's first-person-view image and the current\naction. Then a Monte Carlo tree search algorithm uses this model to plan the\nbest sequence of actions for the agent to perform. On the proposed task in\nMinecraft, our model-based approach reaches the performance comparable to the\nDeep Q-Network's, but learns faster and, thus, is more training sample\nefficient.\n", "versions": [{"version": "v1", "created": "Thu, 22 Mar 2018 16:53:34 GMT"}], "update_date": "2018-03-23", "authors_parsed": [["Alaniz", "Stephan", ""]]}, {"id": "1803.08460", "submitter": "Yi Zhu", "authors": "Yi Zhu, Yang Long, Yu Guan, Shawn Newsam, Ling Shao", "title": "Towards Universal Representation for Unseen Action Recognition", "comments": "Accepted at CVPR 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unseen Action Recognition (UAR) aims to recognise novel action categories\nwithout training examples. While previous methods focus on inner-dataset\nseen/unseen splits, this paper proposes a pipeline using a large-scale training\nsource to achieve a Universal Representation (UR) that can generalise to a more\nrealistic Cross-Dataset UAR (CD-UAR) scenario. We first address UAR as a\nGeneralised Multiple-Instance Learning (GMIL) problem and discover\n'building-blocks' from the large-scale ActivityNet dataset using distribution\nkernels. Essential visual and semantic components are preserved in a shared\nspace to achieve the UR that can efficiently generalise to new datasets.\nPredicted UR exemplars can be improved by a simple semantic adaptation, and\nthen an unseen action can be directly recognised using UR during the test.\nWithout further training, extensive experiments manifest significant\nimprovements over the UCF101 and HMDB51 benchmarks.\n", "versions": [{"version": "v1", "created": "Thu, 22 Mar 2018 17:02:45 GMT"}], "update_date": "2018-03-23", "authors_parsed": [["Zhu", "Yi", ""], ["Long", "Yang", ""], ["Guan", "Yu", ""], ["Newsam", "Shawn", ""], ["Shao", "Ling", ""]]}, {"id": "1803.08495", "submitter": "Kevin Chen", "authors": "Kevin Chen, Christopher B. Choy, Manolis Savva, Angel X. Chang, Thomas\n  Funkhouser, Silvio Savarese", "title": "Text2Shape: Generating Shapes from Natural Language by Learning Joint\n  Embeddings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.GR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a method for generating colored 3D shapes from natural language.\nTo this end, we first learn joint embeddings of freeform text descriptions and\ncolored 3D shapes. Our model combines and extends learning by association and\nmetric learning approaches to learn implicit cross-modal connections, and\nproduces a joint representation that captures the many-to-many relations\nbetween language and physical properties of 3D shapes such as color and shape.\nTo evaluate our approach, we collect a large dataset of natural language\ndescriptions for physical 3D objects in the ShapeNet dataset. With this learned\njoint embedding we demonstrate text-to-shape retrieval that outperforms\nbaseline approaches. Using our embeddings with a novel conditional Wasserstein\nGAN framework, we generate colored 3D shapes from text. Our method is the first\nto connect natural language text with realistic 3D objects exhibiting rich\nvariations in color, texture, and shape detail. See video at\nhttps://youtu.be/zraPvRdl13Q\n", "versions": [{"version": "v1", "created": "Thu, 22 Mar 2018 17:57:47 GMT"}], "update_date": "2018-03-23", "authors_parsed": [["Chen", "Kevin", ""], ["Choy", "Christopher B.", ""], ["Savva", "Manolis", ""], ["Chang", "Angel X.", ""], ["Funkhouser", "Thomas", ""], ["Savarese", "Silvio", ""]]}, {"id": "1803.08554", "submitter": "Ramin M. Hasani", "authors": "Mathias Lechner, Ramin M. Hasani, Radu Grosu", "title": "Neuronal Circuit Policies", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.AI cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an effective way to create interpretable control agents, by\nre-purposing the function of a biological neural circuit model, to govern\nsimulated and real world reinforcement learning (RL) test-beds. We model the\ntap-withdrawal (TW) neural circuit of the nematode, C. elegans, a circuit\nresponsible for the worm's reflexive response to external mechanical touch\nstimulations, and learn its synaptic and neuronal parameters as a policy for\ncontrolling basic RL tasks. We also autonomously park a real rover robot on a\npre-defined trajectory, by deploying such neuronal circuit policies learned in\na simulated environment. For reconfiguration of the purpose of the TW neural\ncircuit, we adopt a search-based RL algorithm. We show that our neuronal\npolicies perform as good as deep neural network policies with the advantage of\nrealizing interpretable dynamics at the cell level.\n", "versions": [{"version": "v1", "created": "Thu, 22 Mar 2018 19:23:32 GMT"}], "update_date": "2018-03-26", "authors_parsed": [["Lechner", "Mathias", ""], ["Hasani", "Ramin M.", ""], ["Grosu", "Radu", ""]]}, {"id": "1803.08604", "submitter": "Jennifer Ortiz", "authors": "Jennifer Ortiz, Magdalena Balazinska, Johannes Gehrke, S. Sathiya\n  Keerthi", "title": "Learning State Representations for Query Optimization with Deep\n  Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep reinforcement learning is quickly changing the field of artificial\nintelligence. These models are able to capture a high level understanding of\ntheir environment, enabling them to learn difficult dynamic tasks in a variety\nof domains. In the database field, query optimization remains a difficult\nproblem. Our goal in this work is to explore the capabilities of deep\nreinforcement learning in the context of query optimization. At each state, we\nbuild queries incrementally and encode properties of subqueries through a\nlearned representation. The challenge here lies in the formation of the state\ntransition function, which defines how the current subquery state combines with\nthe next query operation (action) to yield the next state. As a first step in\nthis direction, we focus the state representation problem and the formation of\nthe state transition function. We describe our approach and show preliminary\nresults. We further discuss how we can use the state representation to improve\nquery optimization using reinforcement learning.\n", "versions": [{"version": "v1", "created": "Thu, 22 Mar 2018 22:39:32 GMT"}], "update_date": "2018-03-26", "authors_parsed": [["Ortiz", "Jennifer", ""], ["Balazinska", "Magdalena", ""], ["Gehrke", "Johannes", ""], ["Keerthi", "S. Sathiya", ""]]}, {"id": "1803.08625", "submitter": "Kuo-Kai Hsieh", "authors": "Kuo-Kai Hsieh and Li-C. Wang", "title": "A Concept Learning Tool Based On Calculating Version Space Cardinality", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In this paper, we proposed VeSC-CoL (Version Space Cardinality based Concept\nLearning) to deal with concept learning on extremely imbalanced datasets,\nespecially when cross-validation is not a viable option. VeSC-CoL uses version\nspace cardinality as a measure for model quality to replace cross-validation.\nInstead of naive enumeration of the version space, Ordered Binary Decision\nDiagram and Boolean Satisfiability are used to compute the version space.\nExperiments show that VeSC-CoL can accurately learn the target concept when\ncomputational resource is allowed.\n", "versions": [{"version": "v1", "created": "Fri, 23 Mar 2018 01:11:01 GMT"}], "update_date": "2018-03-26", "authors_parsed": [["Hsieh", "Kuo-Kai", ""], ["Wang", "Li-C.", ""]]}, {"id": "1803.08631", "submitter": "Jiawei Zhang", "authors": "Jiawei Zhang and Limeng Cui and Fisher B. Gouza", "title": "SEGEN: Sample-Ensemble Genetic Evolutional Network Model", "comments": "12 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning, a rebranding of deep neural network research works, has\nachieved a remarkable success in recent years. With multiple hidden layers,\ndeep learning models aim at computing the hierarchical feature representations\nof the observational data. Meanwhile, due to its severe disadvantages in data\nconsumption, computational resources, parameter tuning costs and the lack of\nresult explainability, deep learning has also suffered from lots of criticism.\nIn this paper, we will introduce a new representation learning model, namely\n\"Sample-Ensemble Genetic Evolutionary Network\" (SEGEN), which can serve as an\nalternative approach to deep learning models. Instead of building one single\ndeep model, based on a set of sampled sub-instances, SEGEN adopts a\ngenetic-evolutionary learning strategy to build a group of unit models\ngenerations by generations. The unit models incorporated in SEGEN can be either\ntraditional machine learning models or the recent deep learning models with a\nmuch \"narrower\" and \"shallower\" architecture. The learning results of each\ninstance at the final generation will be effectively combined from each unit\nmodel via diffusive propagation and ensemble learning strategies. From the\ncomputational perspective, SEGEN requires far less data, fewer computational\nresources and parameter tuning efforts, but has sound theoretic\ninterpretability of the learning process and results. Extensive experiments\nhave been done on several different real-world benchmark datasets, and the\nexperimental results obtained by SEGEN have demonstrated its advantages over\nthe state-of-the-art representation learning models.\n", "versions": [{"version": "v1", "created": "Fri, 23 Mar 2018 01:43:37 GMT"}, {"version": "v2", "created": "Tue, 5 Jun 2018 04:39:53 GMT"}], "update_date": "2018-06-06", "authors_parsed": [["Zhang", "Jiawei", ""], ["Cui", "Limeng", ""], ["Gouza", "Fisher B.", ""]]}, {"id": "1803.08636", "submitter": "Chunbiao Zhu", "authors": "Chunbiao Zhu, Xing Cai, Kan Huang, Thomas H Li, Ge Li", "title": "PDNet: Prior-model Guided Depth-enhanced Network for Salient Object\n  Detection", "comments": "This paper is under review. Project website:\n  https://github.com/ChunbiaoZhu/PDNet/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fully convolutional neural networks (FCNs) have shown outstanding performance\nin many computer vision tasks including salient object detection. However,\nthere still remains two issues needed to be addressed in deep learning based\nsaliency detection. One is the lack of tremendous amount of annotated data to\ntrain a network. The other is the lack of robustness for extracting salient\nobjects in images containing complex scenes. In this paper, we present a new\narchitecture$ - $PDNet, a robust prior-model guided depth-enhanced network for\nRGB-D salient object detection. In contrast to existing works, in which RGB-D\nvalues of image pixels are fed directly to a network, the proposed architecture\nis composed of a master network for processing RGB values, and a sub-network\nmaking full use of depth cues and incorporate depth-based features into the\nmaster network. To overcome the limited size of the labeled RGB-D dataset for\ntraining, we employ a large conventional RGB dataset to pre-train the master\nnetwork, which proves to contribute largely to the final accuracy. Extensive\nevaluations over five benchmark datasets demonstrate that our proposed method\nperforms favorably against the state-of-the-art approaches.\n", "versions": [{"version": "v1", "created": "Fri, 23 Mar 2018 02:04:47 GMT"}, {"version": "v2", "created": "Sat, 13 Oct 2018 13:53:32 GMT"}], "update_date": "2018-10-16", "authors_parsed": [["Zhu", "Chunbiao", ""], ["Cai", "Xing", ""], ["Huang", "Kan", ""], ["Li", "Thomas H", ""], ["Li", "Ge", ""]]}, {"id": "1803.08666", "submitter": "Shipra Sharma Ms.", "authors": "Shipra Sharma, Balwinder Sodhi", "title": "APR: Architectural Pattern Recommender", "comments": "6 Pages, 1 Figure. Published in SAC 2017 in Software Engineering\n  Track", "journal-ref": "Sharma, S., & Sodhi, B. (2017, April). APR: architectural pattern\n  recommender. In Proceedings of the Symposium on Applied Computing (pp.\n  1225-1230). ACM", "doi": null, "report-no": null, "categories": "cs.SE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes Architectural Pattern Recommender (APR) system which\nhelps in such architecture selection process. Main contribution of this work is\nin replacing the manual effort required to identify and analyse relevant\narchitectural patterns in context of a particular set of software requirements.\nKey input to APR is a set of architecturally significant use cases concerning\nthe application being developed. Central idea of APR's design is two folds: a)\ntransform the unstructured information about software architecture design into\na structured form which is suitable for recognizing textual entailment between\na requirement scenario and a potential architectural pattern. b) leverage the\nrich experiential knowledge embedded in discussions on professional developer\nsupport forums such as Stackoverflow to check the sentiment about a design\ndecision. APR makes use of both the above elements to identify a suitable\narchitectural pattern and assess its suitability for a given set of\nrequirements. Efficacy of APR has been evaluated by comparing its\nrecommendations for \"ground truth\" scenarios (comprising of applications whose\narchitecture is well known).\n", "versions": [{"version": "v1", "created": "Fri, 23 Mar 2018 06:20:58 GMT"}], "update_date": "2018-09-13", "authors_parsed": [["Sharma", "Shipra", ""], ["Sodhi", "Balwinder", ""]]}, {"id": "1803.08706", "submitter": "Irene Teinemaa", "authors": "Irene Teinemaa, Niek Tax, Massimiliano de Leoni, Marlon Dumas,\n  Fabrizio Maria Maggi", "title": "Alarm-Based Prescriptive Process Monitoring", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Predictive process monitoring is concerned with the analysis of events\nproduced during the execution of a process in order to predict the future state\nof ongoing cases thereof. Existing techniques in this field are able to\npredict, at each step of a case, the likelihood that the case will end up in an\nundesired outcome. These techniques, however, do not take into account what\nprocess workers may do with the generated predictions in order to decrease the\nlikelihood of undesired outcomes. This paper proposes a framework for\nprescriptive process monitoring, which extends predictive process monitoring\napproaches with the concepts of alarms, interventions, compensations, and\nmitigation effects. The framework incorporates a parameterized cost model to\nassess the cost-benefit tradeoffs of applying prescriptive process monitoring\nin a given setting. The paper also outlines an approach to optimize the\ngeneration of alarms given a dataset and a set of cost model parameters. The\nproposed approach is empirically evaluated using a range of real-life event\nlogs.\n", "versions": [{"version": "v1", "created": "Fri, 23 Mar 2018 09:27:38 GMT"}, {"version": "v2", "created": "Tue, 19 Jun 2018 20:08:32 GMT"}], "update_date": "2018-06-21", "authors_parsed": [["Teinemaa", "Irene", ""], ["Tax", "Niek", ""], ["de Leoni", "Massimiliano", ""], ["Dumas", "Marlon", ""], ["Maggi", "Fabrizio Maria", ""]]}, {"id": "1803.08740", "submitter": "Elisa Maiettini", "authors": "Elisa Maiettini, Giulia Pasquale, Lorenzo Rosasco and Lorenzo Natale", "title": "Speeding-up Object Detection Training for Robotics with FALKON", "comments": null, "journal-ref": "IEEE/RSJ International Conference on Intelligent Robots and\n  Systems (IROS), 2018", "doi": "10.1109/IROS.2018.8593990", "report-no": null, "categories": "cs.RO cs.AI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Latest deep learning methods for object detection provide remarkable\nperformance, but have limits when used in robotic applications. One of the most\nrelevant issues is the long training time, which is due to the large size and\nimbalance of the associated training sets, characterized by few positive and a\nlarge number of negative examples (i.e. background). Proposed approaches are\nbased on end-to-end learning by back-propagation [22] or kernel methods trained\nwith Hard Negatives Mining on top of deep features [8]. These solutions are\neffective, but prohibitively slow for on-line applications. In this paper we\npropose a novel pipeline for object detection that overcomes this problem and\nprovides comparable performance, with a 60x training speedup. Our pipeline\ncombines (i) the Region Proposal Network and the deep feature extractor from\n[22] to efficiently select candidate RoIs and encode them into powerful\nrepresentations, with (ii) the FALKON [23] algorithm, a novel kernel-based\nmethod that allows fast training on large scale problems (millions of points).\nWe address the size and imbalance of training data by exploiting the stochastic\nsubsampling intrinsic into the method and a novel, fast, bootstrapping\napproach. We assess the effectiveness of the approach on a standard Computer\nVision dataset (PASCAL VOC 2007 [5]) and demonstrate its applicability to a\nreal robotic scenario with the iCubWorld Transformations [18] dataset.\n", "versions": [{"version": "v1", "created": "Fri, 23 Mar 2018 11:13:29 GMT"}, {"version": "v2", "created": "Mon, 27 Aug 2018 15:19:38 GMT"}], "update_date": "2021-06-30", "authors_parsed": [["Maiettini", "Elisa", ""], ["Pasquale", "Giulia", ""], ["Rosasco", "Lorenzo", ""], ["Natale", "Lorenzo", ""]]}, {"id": "1803.08784", "submitter": "Stephan Bongers", "authors": "Stephan Bongers, Joris M. Mooij", "title": "From Random Differential Equations to Structural Causal Models: the\n  stochastic case", "comments": "Submitted to UAI 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Random Differential Equations provide a natural extension of Ordinary\nDifferential Equations to the stochastic setting. We show how, and under which\nconditions, every equilibrium state of a Random Differential Equation (RDE) can\nbe described by a Structural Causal Model (SCM), while pertaining the causal\nsemantics. This provides an SCM that captures the stochastic and causal\nbehavior of the RDE, which can model both cycles and confounders. This enables\nthe study of the equilibrium states of the RDE by applying the theory and\nstatistical tools available for SCMs, for example, marginalizations and Markov\nproperties, as we illustrate by means of an example. Our work thus provides a\ndirect connection between two fields that so far have been developing in\nisolation.\n", "versions": [{"version": "v1", "created": "Fri, 23 Mar 2018 13:20:56 GMT"}, {"version": "v2", "created": "Tue, 27 Mar 2018 09:09:52 GMT"}], "update_date": "2018-03-29", "authors_parsed": [["Bongers", "Stephan", ""], ["Mooij", "Joris M.", ""]]}, {"id": "1803.08857", "submitter": "Nicola Pellicano", "authors": "Nicola Pellican\\`o, Sylvie Le H\\'egarat-Mascle, Emanuel Aldea", "title": "2CoBel : An Efficient Belief Function Extension for Two-dimensional\n  Continuous Spaces", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces an innovative approach for handling 2D compound\nhypotheses within the Belief Function Theory framework. We propose a\npolygon-based generic rep- resentation which relies on polygon clipping\noperators. This approach allows us to account in the computational cost for the\nprecision of the representation independently of the cardinality of the\ndiscernment frame. For the BBA combination and decision making, we propose\nefficient algorithms which rely on hashes for fast lookup, and on a topological\nordering of the focal elements within a directed acyclic graph encoding their\ninterconnections. Additionally, an implementation of the functionalities\nproposed in this paper is provided as an open source library. Experimental\nresults on a pedestrian localization problem are reported. The experiments show\nthat the solution is accurate and that it fully benefits from the scalability\nof the 2D search space granularity provided by our representation.\n", "versions": [{"version": "v1", "created": "Fri, 23 Mar 2018 16:05:07 GMT"}], "update_date": "2018-03-26", "authors_parsed": [["Pellican\u00f2", "Nicola", ""], ["H\u00e9garat-Mascle", "Sylvie Le", ""], ["Aldea", "Emanuel", ""]]}, {"id": "1803.08874", "submitter": "James F. Glazebrook PhD", "authors": "Chris Fields and James F. Glazebrook", "title": "A mosaic of Chu spaces and Channel Theory with applications to Object\n  Identification and Mereological Complexity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.IT cs.MA math.CT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Chu Spaces and Channel Theory are well established areas of investigation in\nthe general context of category theory. We review a range of examples and\napplications of these methods in logic and computer science, including Formal\nConcept Analysis, distributed systems and ontology development. We then employ\nthese methods to describe human object perception, beginning with the\nconstruction of uncategorized object files and proceeding through\ncategorization, individual object identification and the tracking of object\nidentity through time. We investigate the relationship between abstraction and\nmereological categorization, particularly as these affect object identity\ntracking. This we accomplish in terms of information flow that is semantically\nstructured in terms of local logics, while at the same time this framework also\nprovides an inferential mechanism towards identification and perception. We\nshow how a mereotopology naturally emerges from the representation of\nclassifications by simplicial complexes, and briefly explore the emergence of\ngeometric relations and interactions between objects.\n", "versions": [{"version": "v1", "created": "Fri, 23 Mar 2018 16:41:36 GMT"}], "update_date": "2018-03-26", "authors_parsed": [["Fields", "Chris", ""], ["Glazebrook", "James F.", ""]]}, {"id": "1803.08884", "submitter": "Joel Leibo", "authors": "Edward Hughes, Joel Z. Leibo, Matthew G. Phillips, Karl Tuyls, Edgar\n  A. Du\\'e\\~nez-Guzm\\'an, Antonio Garc\\'ia Casta\\~neda, Iain Dunning, Tina Zhu,\n  Kevin R. McKee, Raphael Koster, Heather Roff, Thore Graepel", "title": "Inequity aversion improves cooperation in intertemporal social dilemmas", "comments": "15 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.GT cs.MA q-bio.PE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Groups of humans are often able to find ways to cooperate with one another in\ncomplex, temporally extended social dilemmas. Models based on behavioral\neconomics are only able to explain this phenomenon for unrealistic stateless\nmatrix games. Recently, multi-agent reinforcement learning has been applied to\ngeneralize social dilemma problems to temporally and spatially extended Markov\ngames. However, this has not yet generated an agent that learns to cooperate in\nsocial dilemmas as humans do. A key insight is that many, but not all, human\nindividuals have inequity averse social preferences. This promotes a particular\nresolution of the matrix game social dilemma wherein inequity-averse\nindividuals are personally pro-social and punish defectors. Here we extend this\nidea to Markov games and show that it promotes cooperation in several types of\nsequential social dilemma, via a profitable interaction with policy\nlearnability. In particular, we find that inequity aversion improves temporal\ncredit assignment for the important class of intertemporal social dilemmas.\nThese results help explain how large-scale cooperation may emerge and persist.\n", "versions": [{"version": "v1", "created": "Fri, 23 Mar 2018 17:05:38 GMT"}, {"version": "v2", "created": "Tue, 25 Sep 2018 18:50:44 GMT"}, {"version": "v3", "created": "Thu, 27 Sep 2018 13:03:57 GMT"}], "update_date": "2018-09-28", "authors_parsed": [["Hughes", "Edward", ""], ["Leibo", "Joel Z.", ""], ["Phillips", "Matthew G.", ""], ["Tuyls", "Karl", ""], ["Du\u00e9\u00f1ez-Guzm\u00e1n", "Edgar A.", ""], ["Casta\u00f1eda", "Antonio Garc\u00eda", ""], ["Dunning", "Iain", ""], ["Zhu", "Tina", ""], ["McKee", "Kevin R.", ""], ["Koster", "Raphael", ""], ["Roff", "Heather", ""], ["Graepel", "Thore", ""]]}, {"id": "1803.08885", "submitter": "Laura Giordano", "authors": "Laura Giordano, Daniele Theseider Dupr\\'e", "title": "Defeasible Reasoning in SROEL: from Rational Entailment to Rational\n  Closure", "comments": "Accepted for publication on Fundamenta Informaticae", "journal-ref": "Fundamenta Informaticae, vol. 161, no. 1-2, pp. 135-161, 2018, IOS\n  Press", "doi": "10.3233/FI-2018-1698", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we study a rational extension $SROEL^R T$ of the low complexity\ndescription logic SROEL, which underlies the OWL EL ontology language. The\nextension involves a typicality operator T, whose semantics is based on Lehmann\nand Magidor's ranked models and allows for the definition of defeasible\ninclusions. We consider both rational entailment and minimal entailment. We\nshow that deciding instance checking under minimal entailment is in general\n$\\Pi^P_2$-hard, while, under rational entailment, instance checking can be\ncomputed in polynomial time. We develop a Datalog calculus for instance\nchecking under rational entailment and exploit it, with stratified negation,\nfor computing the rational closure of simple KBs in polynomial time.\n", "versions": [{"version": "v1", "created": "Fri, 23 Mar 2018 17:06:02 GMT"}], "update_date": "2018-10-16", "authors_parsed": [["Giordano", "Laura", ""], ["Dupr\u00e9", "Daniele Theseider", ""]]}, {"id": "1803.08971", "submitter": "Tim Hwang", "authors": "Tim Hwang", "title": "Computational Power and the Social Impact of Artificial Intelligence", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Machine learning is a computational process. To that end, it is inextricably\ntied to computational power - the tangible material of chips and semiconductors\nthat the algorithms of machine intelligence operate on. Most obviously,\ncomputational power and computing architectures shape the speed of training and\ninference in machine learning, and therefore influence the rate of progress in\nthe technology. But, these relationships are more nuanced than that: hardware\nshapes the methods used by researchers and engineers in the design and\ndevelopment of machine learning models. Characteristics such as the power\nconsumption of chips also define where and how machine learning can be used in\nthe real world.\n  Despite this, many analyses of the social impact of the current wave of\nprogress in AI have not substantively brought the dimension of hardware into\ntheir accounts. While a common trope in both the popular press and scholarly\nliterature is to highlight the massive increase in computational power that has\nenabled the recent breakthroughs in machine learning, the analysis frequently\ngoes no further than this observation around magnitude. This paper aims to dig\nmore deeply into the relationship between computational power and the\ndevelopment of machine learning. Specifically, it examines how changes in\ncomputing architectures, machine learning methodologies, and supply chains\nmight influence the future of AI. In doing so, it seeks to trace a set of\nspecific relationships between this underlying hardware layer and the broader\nsocial impacts and risks around AI.\n", "versions": [{"version": "v1", "created": "Fri, 23 Mar 2018 20:39:04 GMT"}], "update_date": "2018-03-28", "authors_parsed": [["Hwang", "Tim", ""]]}, {"id": "1803.08983", "submitter": "Patrick Huber", "authors": "Patrick Huber and Jan Niehues and Alex Waibel", "title": "Automated Evaluation of Out-of-Context Errors", "comments": "LREC 2018, 5 pages, Out-of-Context Error Recognition, Automatic\n  Evaluation Dataset, Text Understanding, TEDTalk", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new approach to evaluate computational models for the task of\ntext understanding by the means of out-of-context error detection. Through the\nnovel design of our automated modification process, existing large-scale data\nsources can be adopted for a vast number of text understanding tasks. The data\nis thereby altered on a semantic level, allowing models to be tested against a\nchallenging set of modified text passages that require to comprise a broader\nnarrative discourse. Our newly introduced task targets actual real-world\nproblems of transcription and translation systems by inserting authentic\nout-of-context errors. The automated modification process is applied to the\n2016 TEDTalk corpus. Entirely automating the process allows the adoption of\ncomplete datasets at low cost, facilitating supervised learning procedures and\ndeeper networks to be trained and tested. To evaluate the quality of the\nmodification algorithm a language model and a supervised binary classification\nmodel are trained and tested on the altered dataset. A human baseline\nevaluation is examined to compare the results with human performance. The\noutcome of the evaluation task indicates the difficulty to detect semantic\nerrors for machine-learning algorithms and humans, showing that the errors\ncannot be identified when limited to a single sentence.\n", "versions": [{"version": "v1", "created": "Fri, 23 Mar 2018 21:20:00 GMT"}], "update_date": "2018-03-28", "authors_parsed": [["Huber", "Patrick", ""], ["Niehues", "Jan", ""], ["Waibel", "Alex", ""]]}, {"id": "1803.08986", "submitter": "Bokai Cao", "authors": "Bokai Cao, Lei Zheng, Chenwei Zhang, Philip S. Yu, Andrea Piscitello,\n  John Zulueta, Olu Ajilore, Kelly Ryan and Alex D. Leow", "title": "DeepMood: Modeling Mobile Phone Typing Dynamics for Mood Detection", "comments": "KDD 2017", "journal-ref": null, "doi": "10.1145/3097983.3098086", "report-no": null, "categories": "cs.HC cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The increasing use of electronic forms of communication presents new\nopportunities in the study of mental health, including the ability to\ninvestigate the manifestations of psychiatric diseases unobtrusively and in the\nsetting of patients' daily lives. A pilot study to explore the possible\nconnections between bipolar affective disorder and mobile phone usage was\nconducted. In this study, participants were provided a mobile phone to use as\ntheir primary phone. This phone was loaded with a custom keyboard that\ncollected metadata consisting of keypress entry time and accelerometer\nmovement. Individual character data with the exceptions of the backspace key\nand space bar were not collected due to privacy concerns. We propose an\nend-to-end deep architecture based on late fusion, named DeepMood, to model the\nmulti-view metadata for the prediction of mood scores. Experimental results\nshow that 90.31% prediction accuracy on the depression score can be achieved\nbased on session-level mobile phone typing dynamics which is typically less\nthan one minute. It demonstrates the feasibility of using mobile phone metadata\nto infer mood disturbance and severity.\n", "versions": [{"version": "v1", "created": "Fri, 23 Mar 2018 21:29:21 GMT"}], "update_date": "2018-03-28", "authors_parsed": [["Cao", "Bokai", ""], ["Zheng", "Lei", ""], ["Zhang", "Chenwei", ""], ["Yu", "Philip S.", ""], ["Piscitello", "Andrea", ""], ["Zulueta", "John", ""], ["Ajilore", "Olu", ""], ["Ryan", "Kelly", ""], ["Leow", "Alex D.", ""]]}, {"id": "1803.08999", "submitter": "Chuhang Zou", "authors": "Chuhang Zou, Alex Colburn, Qi Shan, Derek Hoiem", "title": "LayoutNet: Reconstructing the 3D Room Layout from a Single RGB Image", "comments": "CVPR2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an algorithm to predict room layout from a single image that\ngeneralizes across panoramas and perspective images, cuboid layouts and more\ngeneral layouts (e.g. L-shape room). Our method operates directly on the\npanoramic image, rather than decomposing into perspective images as do recent\nworks. Our network architecture is similar to that of RoomNet, but we show\nimprovements due to aligning the image based on vanishing points, predicting\nmultiple layout elements (corners, boundaries, size and translation), and\nfitting a constrained Manhattan layout to the resulting predictions. Our method\ncompares well in speed and accuracy to other existing work on panoramas,\nachieves among the best accuracy for perspective images, and can handle both\ncuboid-shaped and more general Manhattan layouts.\n", "versions": [{"version": "v1", "created": "Fri, 23 Mar 2018 22:25:52 GMT"}], "update_date": "2018-03-28", "authors_parsed": [["Zou", "Chuhang", ""], ["Colburn", "Alex", ""], ["Shan", "Qi", ""], ["Hoiem", "Derek", ""]]}, {"id": "1803.09001", "submitter": "Craig Sherstan", "authors": "Craig Sherstan, Marlos C. Machado, Patrick M. Pilarski", "title": "Accelerating Learning in Constructive Predictive Frameworks with the\n  Successor Representation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Here we propose using the successor representation (SR) to accelerate\nlearning in a constructive knowledge system based on general value functions\n(GVFs). In real-world settings like robotics for unstructured and dynamic\nenvironments, it is infeasible to model all meaningful aspects of a system and\nits environment by hand due to both complexity and size. Instead, robots must\nbe capable of learning and adapting to changes in their environment and task,\nincrementally constructing models from their own experience. GVFs, taken from\nthe field of reinforcement learning (RL), are a way of modeling the world as\npredictive questions. One approach to such models proposes a massive network of\ninterconnected and interdependent GVFs, which are incrementally added over\ntime. It is reasonable to expect that new, incrementally added predictions can\nbe learned more swiftly if the learning process leverages knowledge gained from\npast experience. The SR provides such a means of separating the dynamics of the\nworld from the prediction targets and thus capturing regularities that can be\nreused across multiple GVFs. As a primary contribution of this work, we show\nthat using SR-based predictions can improve sample efficiency and learning\nspeed in a continual learning setting where new predictions are incrementally\nadded and learned over time. We analyze our approach in a grid-world and then\ndemonstrate its potential on data from a physical robot arm.\n", "versions": [{"version": "v1", "created": "Fri, 23 Mar 2018 22:40:22 GMT"}], "update_date": "2018-03-28", "authors_parsed": [["Sherstan", "Craig", ""], ["Machado", "Marlos C.", ""], ["Pilarski", "Patrick M.", ""]]}, {"id": "1803.09010", "submitter": "Hanna Wallach", "authors": "Timnit Gebru, Jamie Morgenstern, Briana Vecchione, Jennifer Wortman\n  Vaughan, Hanna Wallach, Hal Daum\\'e III, and Kate Crawford", "title": "Datasheets for Datasets", "comments": "Working Paper, comments are encouraged", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The machine learning community currently has no standardized process for\ndocumenting datasets, which can lead to severe consequences in high-stakes\ndomains. To address this gap, we propose datasheets for datasets. In the\nelectronics industry, every component, no matter how simple or complex, is\naccompanied with a datasheet that describes its operating characteristics, test\nresults, recommended uses, and other information. By analogy, we propose that\nevery dataset be accompanied with a datasheet that documents its motivation,\ncomposition, collection process, recommended uses, and so on. Datasheets for\ndatasets will facilitate better communication between dataset creators and\ndataset consumers, and encourage the machine learning community to prioritize\ntransparency and accountability.\n", "versions": [{"version": "v1", "created": "Fri, 23 Mar 2018 23:22:18 GMT"}, {"version": "v2", "created": "Sat, 19 May 2018 03:22:43 GMT"}, {"version": "v3", "created": "Mon, 9 Jul 2018 18:26:32 GMT"}, {"version": "v4", "created": "Sun, 14 Apr 2019 22:03:18 GMT"}, {"version": "v5", "created": "Thu, 9 Jan 2020 00:59:24 GMT"}, {"version": "v6", "created": "Tue, 14 Jan 2020 01:36:33 GMT"}, {"version": "v7", "created": "Thu, 19 Mar 2020 17:26:37 GMT"}], "update_date": "2020-03-20", "authors_parsed": [["Gebru", "Timnit", ""], ["Morgenstern", "Jamie", ""], ["Vecchione", "Briana", ""], ["Vaughan", "Jennifer Wortman", ""], ["Wallach", "Hanna", ""], ["Daum\u00e9", "Hal", "III"], ["Crawford", "Kate", ""]]}, {"id": "1803.09074", "submitter": "Yi Tay", "authors": "Yi Tay, Luu Anh Tuan, Siu Cheung Hui", "title": "Multi-range Reasoning for Machine Comprehension", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose MRU (Multi-Range Reasoning Units), a new fast compositional\nencoder for machine comprehension (MC). Our proposed MRU encoders are\ncharacterized by multi-ranged gating, executing a series of parameterized\ncontract-and-expand layers for learning gating vectors that benefit from long\nand short-term dependencies. The aims of our approach are as follows: (1)\nlearning representations that are concurrently aware of long and short-term\ncontext, (2) modeling relationships between intra-document blocks and (3) fast\nand efficient sequence encoding. We show that our proposed encoder demonstrates\npromising results both as a standalone encoder and as well as a complementary\nbuilding block. We conduct extensive experiments on three challenging MC\ndatasets, namely RACE, SearchQA and NarrativeQA, achieving highly competitive\nperformance on all. On the RACE benchmark, our model outperforms DFN (Dynamic\nFusion Networks) by 1.5%-6% without using any recurrent or convolution layers.\nSimilarly, we achieve competitive performance relative to AMANDA on the\nSearchQA benchmark and BiDAF on the NarrativeQA benchmark without using any\nLSTM/GRU layers. Finally, incorporating MRU encoders with standard BiLSTM\narchitectures further improves performance, achieving state-of-the-art results.\n", "versions": [{"version": "v1", "created": "Sat, 24 Mar 2018 08:10:04 GMT"}], "update_date": "2018-03-28", "authors_parsed": [["Tay", "Yi", ""], ["Tuan", "Luu Anh", ""], ["Hui", "Siu Cheung", ""]]}, {"id": "1803.09099", "submitter": "Chris Martens", "authors": "Chris Martens, Eric Butler, and Joseph C. Osborn", "title": "A Resourceful Reframing of Behavior Trees", "comments": "17 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Designers of autonomous agents, whether in physical or virtual environments,\nneed to express nondeterminisim, failure, and parallelism in behaviors, as well\nas accounting for synchronous coordination between agents. Behavior Trees are a\nsemi-formalism deployed widely for this purpose in the games industry, but with\nchallenges to scalability, reasoning, and reuse of common sub-behaviors.\n  We present an alternative formulation of behavior trees through a language\ndesign perspective, giving a formal operational semantics, type system, and\ncorresponding implementation. We express specifications for atomic behaviors as\nlinear logic formulas describing how they transform the environment, and our\ntype system uses linear sequent calculus to derive a compositional type\nassignment to behavior tree expressions. These types expose the conditions\nrequired for behaviors to succeed and allow abstraction over parameters to\nbehaviors, enabling the development of behavior \"building blocks\" amenable to\ncompositional reasoning and reuse.\n", "versions": [{"version": "v1", "created": "Sat, 24 Mar 2018 12:28:04 GMT"}], "update_date": "2018-03-28", "authors_parsed": [["Martens", "Chris", ""], ["Butler", "Eric", ""], ["Osborn", "Joseph C.", ""]]}, {"id": "1803.09156", "submitter": "Yuan Gong", "authors": "Yuan Gong and Christian Poellabauer", "title": "An Overview of Vulnerabilities of Voice Controlled Systems", "comments": "1st International Workshop on Security and Privacy for the\n  Internet-of-Things (IoTSec)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Over the last few years, a rapidly increasing number of Internet-of-Things\n(IoT) systems that adopt voice as the primary user input have emerged. These\nsystems have been shown to be vulnerable to various types of voice spoofing\nattacks. However, how exactly these techniques differ or relate to each other\nhas not been extensively studied. In this paper, we provide a survey of recent\nattack and defense techniques for voice controlled systems and propose a\nclassification of these techniques. We also discuss the need for a universal\ndefense strategy that protects a system from various types of attacks.\n", "versions": [{"version": "v1", "created": "Sat, 24 Mar 2018 19:41:25 GMT"}], "update_date": "2018-03-28", "authors_parsed": [["Gong", "Yuan", ""], ["Poellabauer", "Christian", ""]]}, {"id": "1803.09203", "submitter": "Pin Wang", "authors": "Pin Wang, Ching-Yao Chan", "title": "Autonomous Ramp Merge Maneuver Based on Reinforcement Learning with\n  Continuous Action Space", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ramp merging is a critical maneuver for road safety and traffic efficiency.\nMost of the current automated driving systems developed by multiple automobile\nmanufacturers and suppliers are typically limited to restricted access freeways\nonly. Extending the automated mode to ramp merging zones presents substantial\nchallenges. One is that the automated vehicle needs to incorporate a future\nobjective (e.g. a successful and smooth merge) and optimize a long-term reward\nthat is impacted by subsequent actions when executing the current action.\nFurthermore, the merging process involves interaction between the merging\nvehicle and its surrounding vehicles whose behavior may be cooperative or\nadversarial, leading to distinct merging countermeasures that are crucial to\nsuccessfully complete the merge. In place of the conventional rule-based\napproaches, we propose to apply reinforcement learning algorithm on the\nautomated vehicle agent to find an optimal driving policy by maximizing the\nlong-term reward in an interactive driving environment. Most importantly, in\ncontrast to most reinforcement learning applications in which the action space\nis resolved as discrete, our approach treats the action space as well as the\nstate space as continuous without incurring additional computational costs. Our\nunique contribution is the design of the Q-function approximation whose format\nis structured as a quadratic function, by which simple but effective neural\nnetworks are used to estimate its coefficients. The results obtained through\nthe implementation of our training platform demonstrate that the vehicle agent\nis able to learn a safe, smooth and timely merging policy, indicating the\neffectiveness and practicality of our approach.\n", "versions": [{"version": "v1", "created": "Sun, 25 Mar 2018 05:10:10 GMT"}], "update_date": "2018-03-28", "authors_parsed": [["Wang", "Pin", ""], ["Chan", "Ching-Yao", ""]]}, {"id": "1803.09211", "submitter": "Sumit Bhatia", "authors": "Vinith Misra and Sumit Bhatia", "title": "Bernoulli Embeddings for Graphs", "comments": "The Thirty-Second AAAI Conference on Artificial Intelligence\n  (AAAI-18)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Just as semantic hashing can accelerate information retrieval, binary valued\nembeddings can significantly reduce latency in the retrieval of graphical data.\nWe introduce a simple but effective model for learning such binary vectors for\nnodes in a graph. By imagining the embeddings as independent coin flips of\nvarying bias, continuous optimization techniques can be applied to the\napproximate expected loss. Embeddings optimized in this fashion consistently\noutperform the quantization of both spectral graph embeddings and various\nlearned real-valued embeddings, on both ranking and pre-ranking tasks for a\nvariety of datasets.\n", "versions": [{"version": "v1", "created": "Sun, 25 Mar 2018 07:19:47 GMT"}], "update_date": "2018-03-28", "authors_parsed": [["Misra", "Vinith", ""], ["Bhatia", "Sumit", ""]]}, {"id": "1803.09425", "submitter": "Makoto Naruse", "authors": "Makoto Naruse, Takatomo Mihana, Hirokazu Hori, Hayato Saigo, Kazuya\n  Okamura, Mikio Hasegawa and Atsushi Uchida", "title": "Scalable photonic reinforcement learning by time-division multiplexing\n  of laser chaos", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.ET cs.AI physics.data-an physics.optics", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning involves decision making in dynamic and uncertain\nenvironments and constitutes a crucial element of artificial intelligence. In\nour previous work, we experimentally demonstrated that the ultrafast chaotic\noscillatory dynamics of lasers can be used to solve the two-armed bandit\nproblem efficiently, which requires decision making concerning a class of\ndifficult trade-offs called the exploration-exploitation dilemma. However, only\ntwo selections were employed in that research; thus, the scalability of the\nlaser-chaos-based reinforcement learning should be clarified. In this study, we\ndemonstrated a scalable, pipelined principle of resolving the multi-armed\nbandit problem by introducing time-division multiplexing of chaotically\noscillated ultrafast time-series. The experimental demonstrations in which\nbandit problems with up to 64 arms were successfully solved are presented in\nthis report. Detailed analyses are also provided that include performance\ncomparisons among laser chaos signals generated in different physical\nconditions, which coincide with the diffusivity inherent in the time series.\nThis study paves the way for ultrafast reinforcement learning by taking\nadvantage of the ultrahigh bandwidths of light wave and practical enabling\ntechnologies.\n", "versions": [{"version": "v1", "created": "Mon, 26 Mar 2018 05:56:54 GMT"}], "update_date": "2018-03-28", "authors_parsed": [["Naruse", "Makoto", ""], ["Mihana", "Takatomo", ""], ["Hori", "Hirokazu", ""], ["Saigo", "Hayato", ""], ["Okamura", "Kazuya", ""], ["Hasegawa", "Mikio", ""], ["Uchida", "Atsushi", ""]]}, {"id": "1803.09473", "submitter": "Uri Alon", "authors": "Uri Alon, Meital Zilberstein, Omer Levy, Eran Yahav", "title": "code2vec: Learning Distributed Representations of Code", "comments": "Accepted in POPL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.PL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a neural model for representing snippets of code as continuous\ndistributed vectors (\"code embeddings\"). The main idea is to represent a code\nsnippet as a single fixed-length $\\textit{code vector}$, which can be used to\npredict semantic properties of the snippet. This is performed by decomposing\ncode to a collection of paths in its abstract syntax tree, and learning the\natomic representation of each path $\\textit{simultaneously}$ with learning how\nto aggregate a set of them. We demonstrate the effectiveness of our approach by\nusing it to predict a method's name from the vector representation of its body.\nWe evaluate our approach by training a model on a dataset of 14M methods. We\nshow that code vectors trained on this dataset can predict method names from\nfiles that were completely unobserved during training. Furthermore, we show\nthat our model learns useful method name vectors that capture semantic\nsimilarities, combinations, and analogies. Comparing previous techniques over\nthe same data set, our approach obtains a relative improvement of over 75%,\nbeing the first to successfully predict method names based on a large,\ncross-project, corpus. Our trained model, visualizations and vector\nsimilarities are available as an interactive online demo at\nhttp://code2vec.org. The code, data, and trained models are available at\nhttps://github.com/tech-srl/code2vec.\n", "versions": [{"version": "v1", "created": "Mon, 26 Mar 2018 09:05:30 GMT"}, {"version": "v2", "created": "Wed, 28 Mar 2018 11:57:57 GMT"}, {"version": "v3", "created": "Sun, 22 Apr 2018 10:00:14 GMT"}, {"version": "v4", "created": "Mon, 29 Oct 2018 09:38:16 GMT"}, {"version": "v5", "created": "Tue, 30 Oct 2018 09:45:07 GMT"}], "update_date": "2018-10-31", "authors_parsed": [["Alon", "Uri", ""], ["Zilberstein", "Meital", ""], ["Levy", "Omer", ""], ["Yahav", "Eran", ""]]}, {"id": "1803.09535", "submitter": "Zachary Pardos", "authors": "Zachary A. Pardos, Zihao Fan, Weijie Jiang", "title": "Connectionist Recommendation in the Wild: On the utility and\n  scrutability of neural networks for personalized course guidance", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The aggregate behaviors of users can collectively encode deep semantic\ninformation about the objects with which they interact. In this paper, we\ndemonstrate novel ways in which the synthesis of these data can illuminate the\nterrain of users' environment and support them in their decision making and\nwayfinding. A novel application of Recurrent Neural Networks and skip-gram\nmodels, approaches popularized by their application to modeling language, are\nbrought to bear on student university enrollment sequences to create vector\nrepresentations of courses and map out traversals across them. We present\ndemonstrations of how scrutability from these neural networks can be gained and\nhow the combination of these techniques can be seen as an evolution of content\ntagging and a means for a recommender to balance user preferences inferred from\ndata with those explicitly specified. From validation of the models to the\ndevelopment of a UI, we discuss additional requisite functionality informed by\nthe results of a usability study leading to the ultimate deployment of the\nsystem at a university.\n", "versions": [{"version": "v1", "created": "Mon, 26 Mar 2018 12:08:28 GMT"}, {"version": "v2", "created": "Sat, 15 Sep 2018 03:40:11 GMT"}, {"version": "v3", "created": "Mon, 31 Dec 2018 20:25:14 GMT"}], "update_date": "2019-01-03", "authors_parsed": [["Pardos", "Zachary A.", ""], ["Fan", "Zihao", ""], ["Jiang", "Weijie", ""]]}, {"id": "1803.09551", "submitter": "Guang-Neng Hu", "authors": "Guang-Neng Hu, Xin-Yu Dai, Feng-Yu Qiu, Rui Xia, Tao Li, Shu-Jian\n  Huang, Jia-Jun Chen", "title": "Collaborative Filtering with Topic and Social Latent Factors\n  Incorporating Implicit Feedback", "comments": "27 pages, 11 figures, 6 tables, ACM TKDD 2018", "journal-ref": null, "doi": "10.1145/3127873", "report-no": null, "categories": "cs.IR cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recommender systems (RSs) provide an effective way of alleviating the\ninformation overload problem by selecting personalized items for different\nusers. Latent factors based collaborative filtering (CF) has become the popular\napproaches for RSs due to its accuracy and scalability. Recently, online social\nnetworks and user-generated content provide diverse sources for recommendation\nbeyond ratings. Although {\\em social matrix factorization} (Social MF) and {\\em\ntopic matrix factorization} (Topic MF) successfully exploit social relations\nand item reviews, respectively, both of them ignore some useful information. In\nthis paper, we investigate the effective data fusion by combining the\naforementioned approaches. First, we propose a novel model {\\em \\mbox{MR3}} to\njointly model three sources of information (i.e., ratings, item reviews, and\nsocial relations) effectively for rating prediction by aligning the latent\nfactors and hidden topics. Second, we incorporate the implicit feedback from\nratings into the proposed model to enhance its capability and to demonstrate\nits flexibility. We achieve more accurate rating prediction on real-life\ndatasets over various state-of-the-art methods. Furthermore, we measure the\ncontribution from each of the three data sources and the impact of implicit\nfeedback from ratings, followed by the sensitivity analysis of hyperparameters.\nEmpirical studies demonstrate the effectiveness and efficacy of our proposed\nmodel and its extension.\n", "versions": [{"version": "v1", "created": "Mon, 26 Mar 2018 12:46:13 GMT"}], "update_date": "2021-01-15", "authors_parsed": [["Hu", "Guang-Neng", ""], ["Dai", "Xin-Yu", ""], ["Qiu", "Feng-Yu", ""], ["Xia", "Rui", ""], ["Li", "Tao", ""], ["Huang", "Shu-Jian", ""], ["Chen", "Jia-Jun", ""]]}, {"id": "1803.09578", "submitter": "Nils Reimers", "authors": "Nils Reimers, Iryna Gurevych", "title": "Why Comparing Single Performance Scores Does Not Allow to Draw\n  Conclusions About Machine Learning Approaches", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Developing state-of-the-art approaches for specific tasks is a major driving\nforce in our research community. Depending on the prestige of the task,\npublishing it can come along with a lot of visibility. The question arises how\nreliable are our evaluation methodologies to compare approaches?\n  One common methodology to identify the state-of-the-art is to partition data\ninto a train, a development and a test set. Researchers can train and tune\ntheir approach on some part of the dataset and then select the model that\nworked best on the development set for a final evaluation on unseen test data.\nTest scores from different approaches are compared, and performance differences\nare tested for statistical significance.\n  In this publication, we show that there is a high risk that a statistical\nsignificance in this type of evaluation is not due to a superior learning\napproach. Instead, there is a high risk that the difference is due to chance.\nFor example for the CoNLL 2003 NER dataset we observed in up to 26% of the\ncases type I errors (false positives) with a threshold of p < 0.05, i.e.,\nfalsely concluding a statistically significant difference between two identical\napproaches.\n  We prove that this evaluation setup is unsuitable to compare learning\napproaches. We formalize alternative evaluation setups based on score\ndistributions.\n", "versions": [{"version": "v1", "created": "Mon, 26 Mar 2018 13:35:14 GMT"}], "update_date": "2018-03-28", "authors_parsed": [["Reimers", "Nils", ""], ["Gurevych", "Iryna", ""]]}, {"id": "1803.09587", "submitter": "Malte Ludewig", "authors": "Malte Ludewig, Dietmar Jannach", "title": "Evaluation of Session-based Recommendation Algorithms", "comments": null, "journal-ref": null, "doi": "10.1007/s11257-018-9209-6", "report-no": null, "categories": "cs.IR cs.AI cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recommender systems help users find relevant items of interest, for example\non e-commerce or media streaming sites. Most academic research is concerned\nwith approaches that personalize the recommendations according to long-term\nuser profiles. In many real-world applications, however, such long-term\nprofiles often do not exist and recommendations therefore have to be made\nsolely based on the observed behavior of a user during an ongoing session.\nGiven the high practical relevance of the problem, an increased interest in\nthis problem can be observed in recent years, leading to a number of proposals\nfor session-based recommendation algorithms that typically aim to predict the\nuser's immediate next actions. In this work, we present the results of an\nin-depth performance comparison of a number of such algorithms, using a variety\nof datasets and evaluation measures. Our comparison includes the most recent\napproaches based on recurrent neural networks like GRU4REC, factorized Markov\nmodel approaches such as FISM or FOSSIL, as well as simpler methods based,\ne.g., on nearest neighbor schemes. Our experiments reveal that algorithms of\nthis latter class, despite their sometimes almost trivial nature, often perform\nequally well or significantly better than today's more complex approaches based\non deep neural networks. Our results therefore suggest that there is\nsubstantial room for improvement regarding the development of more\nsophisticated session-based recommendation algorithms.\n", "versions": [{"version": "v1", "created": "Mon, 26 Mar 2018 13:46:07 GMT"}, {"version": "v2", "created": "Tue, 30 Oct 2018 10:14:57 GMT"}], "update_date": "2018-10-31", "authors_parsed": [["Ludewig", "Malte", ""], ["Jannach", "Dietmar", ""]]}, {"id": "1803.09681", "submitter": "Christoph Benzm\\\"uller", "authors": "Christoph Benzm\\\"uller and Xavier Parent", "title": "I/O Logic in HOL --- First Steps", "comments": "7 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A semantical embedding of input/output logic in classical higher-order logic\nis presented. This embedding enables the mechanisation and automation of\nreasoning tasks in input/output logic with off-the-shelf higher-order theorem\nprovers and proof assistants. The key idea for the solution presented here\nresults from the analysis of an inaccurate previous embedding attempt, which we\nwill discuss as well.\n", "versions": [{"version": "v1", "created": "Mon, 26 Mar 2018 15:53:31 GMT"}, {"version": "v2", "created": "Thu, 19 Apr 2018 17:39:45 GMT"}], "update_date": "2018-04-20", "authors_parsed": [["Benzm\u00fcller", "Christoph", ""], ["Parent", "Xavier", ""]]}, {"id": "1803.09689", "submitter": "Cem Eteke", "authors": "Cem Eteke, Hayati Havlucu, Nisa \\.Irem K{\\i}rba\\c{c}, Mehmet Cengiz\n  Onba\\c{s}l{\\i}, Aykut Co\\c{s}kun, Terry Eskenazi, O\\u{g}uzhan \\\"Ozcan,\n  Bar{\\i}\\c{s} Akg\\\"un", "title": "Flow From Motion: A Deep Learning Approach", "comments": "7 pages, 2 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.HC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Wearable devices have the potential to enhance sports performance, yet they\nare not fulfilling this promise. Our previous studies with 6 professional\ntennis coaches and 20 players indicate that this could be due the lack of\npsychological or mental state feedback, which the coaches claim to provide.\nTowards this end, we propose to detect the flow state, mental state of optimal\nperformance, using wearables data to be later used in training. We performed a\nstudy with a professional tennis coach and two players. The coach provided\nlabels about the players' flow state while each player had a wearable device on\ntheir racket holding wrist. We trained multiple models using the wearables data\nand the coach labels. Our deep neural network models achieved around 98%\ntesting accuracy for a variety of conditions. This suggests that the flow state\nor what coaches recognize as flow, can be detected using wearables data in\ntennis which is a novel result. The implication for the HCI community is that\nhaving access to such information would allow for design of novel hardware and\ninteraction paradigms that would be helpful in professional athlete training.\n", "versions": [{"version": "v1", "created": "Mon, 26 Mar 2018 16:12:48 GMT"}], "update_date": "2018-03-28", "authors_parsed": [["Eteke", "Cem", ""], ["Havlucu", "Hayati", ""], ["K\u0131rba\u00e7", "Nisa \u0130rem", ""], ["Onba\u015fl\u0131", "Mehmet Cengiz", ""], ["Co\u015fkun", "Aykut", ""], ["Eskenazi", "Terry", ""], ["\u00d6zcan", "O\u011fuzhan", ""], ["Akg\u00fcn", "Bar\u0131\u015f", ""]]}, {"id": "1803.09702", "submitter": "Olivier Deiss", "authors": "Olivier Deiss, Siddharth Biswal, Jing Jin, Haoqi Sun, M. Brandon\n  Westover, Jimeng Sun", "title": "HAMLET: Interpretable Human And Machine co-LEarning Technique", "comments": "Removed KDD template", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.HC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Efficient label acquisition processes are key to obtaining robust\nclassifiers. However, data labeling is often challenging and subject to high\nlevels of label noise. This can arise even when classification targets are well\ndefined, if instances to be labeled are more difficult than the prototypes used\nto define the class, leading to disagreements among the expert community. Here,\nwe enable efficient training of deep neural networks. From low-confidence\nlabels, we iteratively improve their quality by simultaneous learning of\nmachines and experts. We call it Human And Machine co-LEarning Technique\n(HAMLET). Throughout the process, experts become more consistent, while the\nalgorithm provides them with explainable feedback for confirmation. HAMLET uses\na neural embedding function and a memory module filled with diverse reference\nembeddings from different classes. Its output includes classification labels\nand highly relevant reference embeddings as explanation. We took the study of\nbrain monitoring at intensive care unit (ICU) as an application of HAMLET on\ncontinuous electroencephalography (cEEG) data. Although cEEG monitoring yields\nlarge volumes of data, labeling costs and difficulty make it hard to build a\nclassifier. Additionally, while experts agree on the labels of clear-cut\nexamples of cEEG patterns, labeling many real-world cEEG data can be extremely\nchallenging. Thus, a large minority of sequences might be mislabeled. HAMLET\nhas shown significant performance gain against deep learning and other\nbaselines, increasing accuracy from 7.03% to 68.75% on challenging inputs.\nBesides improved performance, clinical experts confirmed the interpretability\nof those reference embeddings in helping explaining the classification results\nby HAMLET.\n", "versions": [{"version": "v1", "created": "Mon, 26 Mar 2018 16:29:03 GMT"}, {"version": "v2", "created": "Tue, 17 Apr 2018 13:28:50 GMT"}, {"version": "v3", "created": "Tue, 21 Aug 2018 05:41:09 GMT"}], "update_date": "2018-08-22", "authors_parsed": [["Deiss", "Olivier", ""], ["Biswal", "Siddharth", ""], ["Jin", "Jing", ""], ["Sun", "Haoqi", ""], ["Westover", "M. Brandon", ""], ["Sun", "Jimeng", ""]]}, {"id": "1803.09760", "submitter": "Andrew Jaegle", "authors": "Andrew Jaegle, Oleh Rybkin, Konstantinos G. Derpanis, Kostas\n  Daniilidis", "title": "Predicting the Future with Transformational States", "comments": "24 pages, including supplement", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An intelligent observer looks at the world and sees not only what is, but\nwhat is moving and what can be moved. In other words, the observer sees how the\npresent state of the world can transform in the future. We propose a model that\npredicts future images by learning to represent the present state and its\ntransformation given only a sequence of images. To do so, we introduce an\narchitecture with a latent state composed of two components designed to capture\n(i) the present image state and (ii) the transformation between present and\nfuture states, respectively. We couple this latent state with a recurrent\nneural network (RNN) core that predicts future frames by transforming past\nstates into future states by applying the accumulated state transformation with\na learned operator. We describe how this model can be integrated into an\nencoder-decoder convolutional neural network (CNN) architecture that uses\nweighted residual connections to integrate representations of the past with\nrepresentations of the future. Qualitatively, our approach generates image\nsequences that are stable and capture realistic motion over multiple predicted\nframes, without requiring adversarial training. Quantitatively, our method\nachieves prediction results comparable to state-of-the-art results on standard\nimage prediction benchmarks (Moving MNIST, KTH, and UCF101).\n", "versions": [{"version": "v1", "created": "Mon, 26 Mar 2018 18:00:07 GMT"}], "update_date": "2018-03-28", "authors_parsed": [["Jaegle", "Andrew", ""], ["Rybkin", "Oleh", ""], ["Derpanis", "Konstantinos G.", ""], ["Daniilidis", "Kostas", ""]]}, {"id": "1803.09785", "submitter": "Daniel Karapetyan Dr", "authors": "Daniel Karapetyan and Andrew J. Parkes and Thomas St\\\"utzle", "title": "Algorithm Configuration: Learning policies for the quick termination of\n  poor performers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One way to speed up the algorithm configuration task is to use short runs\ninstead of long runs as much as possible, but without discarding the\nconfigurations that eventually do well on the long runs. We consider the\nproblem of selecting the top performing configurations of the Conditional\nMarkov Chain Search (CMCS), a general algorithm schema that includes, for\nexamples, VNS. We investigate how the structure of performance on short tests\nlinks with those on long tests, showing that significant differences arise\nbetween test domains. We propose a \"performance envelope\" method to exploit the\nlinks; that learns when runs should be terminated, but that automatically\nadapts to the domain.\n", "versions": [{"version": "v1", "created": "Mon, 26 Mar 2018 18:38:35 GMT"}], "update_date": "2018-03-28", "authors_parsed": [["Karapetyan", "Daniel", ""], ["Parkes", "Andrew J.", ""], ["St\u00fctzle", "Thomas", ""]]}, {"id": "1803.09789", "submitter": "Biplav Srivastava", "authors": "Biplav Srivastava", "title": "On Chatbots Exhibiting Goal-Directed Autonomy in Dynamic Environments", "comments": "3 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conversation interfaces (CIs), or chatbots, are a popular form of intelligent\nagents that engage humans in task-oriented or informal conversation. In this\nposition paper and demonstration, we argue that chatbots working in dynamic\nenvironments, like with sensor data, can not only serve as a promising platform\nto research issues at the intersection of learning, reasoning, representation\nand execution for goal-directed autonomy; but also handle non-trivial business\napplications. We explore the underlying issues in the context of Water Advisor,\na preliminary multi-modal conversation system that can access and explain water\nquality data.\n", "versions": [{"version": "v1", "created": "Mon, 26 Mar 2018 18:51:33 GMT"}], "update_date": "2018-03-28", "authors_parsed": [["Srivastava", "Biplav", ""]]}, {"id": "1803.09840", "submitter": "Valentina Presutti", "authors": "Luigi Asprino, Valerio Basile, Paolo Ciancarini, Valentina Presutti", "title": "Empirical Analysis of Foundational Distinctions in Linked Open Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The Web and its Semantic extension (i.e. Linked Open Data) contain open\nglobal-scale knowledge and make it available to potentially intelligent\nmachines that want to benefit from it. Nevertheless, most of Linked Open Data\nlack ontological distinctions and have sparse axiomatisation. For example,\ndistinctions such as whether an entity is inherently a class or an individual,\nor whether it is a physical object or not, are hardly expressed in the data,\nalthough they have been largely studied and formalised by foundational\nontologies (e.g. DOLCE, SUMO). These distinctions belong to common sense too,\nwhich is relevant for many artificial intelligence tasks such as natural\nlanguage understanding, scene recognition, and the like. There is a gap between\nfoundational ontologies, that often formalise or are inspired by pre-existing\nphilosophical theories and are developed with a top-down approach, and Linked\nOpen Data that mostly derive from existing databases or crowd-based effort\n(e.g. DBpedia, Wikidata). We investigate whether machines can learn\nfoundational distinctions over Linked Open Data entities, and if they match\ncommon sense. We want to answer questions such as \"does the DBpedia entity for\ndog refer to a class or to an instance?\". We report on a set of experiments\nbased on machine learning and crowdsourcing that show promising results.\n", "versions": [{"version": "v1", "created": "Mon, 26 Mar 2018 20:56:30 GMT"}, {"version": "v2", "created": "Wed, 23 May 2018 09:54:38 GMT"}], "update_date": "2018-05-24", "authors_parsed": [["Asprino", "Luigi", ""], ["Basile", "Valerio", ""], ["Ciancarini", "Paolo", ""], ["Presutti", "Valentina", ""]]}, {"id": "1803.09844", "submitter": "Ahmed Fadhil", "authors": "Ahmed Fadhil", "title": "A Conversational Interface to Improve Medication Adherence: Towards AI\n  Support in Patient's Treatment", "comments": "7 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Medication adherence is of utmost importance for many chronic conditions,\nregardless of the disease type. Engaging patients in self-tracking their\nmedication is a big challenge. One way to potentially reduce this burden is to\nuse reminders to promote wellness throughout all stages of life and improve\nmedication adherence. Chatbots have proven effectiveness in triggering users to\nengage in certain activity, such as medication adherence. In this paper, we\ndiscuss \"Roborto\", a chatbot to create an engaging interactive and intelligent\nenvironment for patients and assist in positive lifestyle modification. We\nintroduce a way for healthcare providers to track patients adherence and\nintervene whenever necessary. We describe the health, technical and behavioural\napproaches to the problem of medication non-adherence and propose a diagnostic\nand decision support tool. The proposed study will be implemented and validated\nthrough a pilot experiment with users to measure the efficacy of the proposed\napproach.\n", "versions": [{"version": "v1", "created": "Sat, 3 Mar 2018 10:07:21 GMT"}], "update_date": "2018-03-28", "authors_parsed": [["Fadhil", "Ahmed", ""]]}, {"id": "1803.09853", "submitter": "Christoph Salge", "authors": "Christoph Salge, Michael Cerny Green, Rodrigo Canaan and Julian\n  Togelius", "title": "Generative Design in Minecraft (GDMC), Settlement Generation Competition", "comments": "10 pages, 5 figures, Part of the Foundations of Digital Games 2018\n  proceedings, as part of the workshop on Procedural Content Generation", "journal-ref": "In Foundations of Digital Games 2018 (FDG18), August 7-10, 2018,\n  Malm\\\"o, Sweden. ACM, New York, NY, USA, 10 pages", "doi": "10.1145/3235765.3235814", "report-no": null, "categories": "cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces the settlement generation competition for Minecraft,\nthe first part of the Generative Design in Minecraft challenge. The settlement\ngeneration competition is about creating Artificial Intelligence (AI) agents\nthat can produce functional, aesthetically appealing and believable settlements\nadapted to a given Minecraft map - ideally at a level that can compete with\nhuman created designs. The aim of the competition is to advance procedural\ncontent generation for games, especially in overcoming the challenges of\nadaptive and holistic PCG. The paper introduces the technical details of the\nchallenge, but mostly focuses on what challenges this competition provides and\nwhy they are scientifically relevant.\n", "versions": [{"version": "v1", "created": "Tue, 27 Mar 2018 02:35:02 GMT"}, {"version": "v2", "created": "Tue, 31 Jul 2018 03:55:50 GMT"}], "update_date": "2018-08-01", "authors_parsed": [["Salge", "Christoph", ""], ["Green", "Michael Cerny", ""], ["Canaan", "Rodrigo", ""], ["Togelius", "Julian", ""]]}, {"id": "1803.09866", "submitter": "Christoph Salge", "authors": "Christoph Salge, Christian Guckelsberger, Rodrigo Canaan and Tobias\n  Mahlmann", "title": "Accelerating Empowerment Computation with UCT Tree Search", "comments": "8ish pages, 6 figures, data for graphs included in sources", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.IT cs.PF math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Models of intrinsic motivation present an important means to produce sensible\nbehaviour in the absence of extrinsic rewards. Applications in video games are\nvaried, and range from intrinsically motivated general game-playing agents to\nnon-player characters such as companions and enemies. The information-theoretic\nquantity of Empowerment is a particularly promising candidate motivation to\nproduce believable, generic and robust behaviour. However, while it can be used\nin the absence of external reward functions that would need to be crafted and\nlearned, empowerment is computationally expensive. In this paper, we propose a\nmodified UCT tree search method to mitigate empowerment's computational\ncomplexity in discrete and deterministic scenarios. We demonstrate how to\nmodify a Monte-Carlo Search Tree with UCT to realise empowerment maximisation,\nand discuss three additional modifications that facilitate better sampling. We\nevaluate the approach both quantitatively, by analysing how close our approach\ngets to the baseline of exhaustive empowerment computation with varying amounts\nof computational resources, and qualitatively, by analysing the resulting\nbehaviour in a Minecraft-like scenario.\n", "versions": [{"version": "v1", "created": "Tue, 27 Mar 2018 03:05:35 GMT"}], "update_date": "2018-03-28", "authors_parsed": [["Salge", "Christoph", ""], ["Guckelsberger", "Christian", ""], ["Canaan", "Rodrigo", ""], ["Mahlmann", "Tobias", ""]]}, {"id": "1803.09887", "submitter": "Jie Liu", "authors": "Jie Liu, Hao Zheng", "title": "MLE-induced Likelihood for Markov Random Fields", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to the intractable partition function, the exact likelihood function for\na Markov random field (MRF), in many situations, can only be approximated.\nMajor approximation approaches include pseudolikelihood and Laplace\napproximation. In this paper, we propose a novel way of approximating the\nlikelihood function through first approximating the marginal likelihood\nfunctions of individual parameters and then reconstructing the joint likelihood\nfunction from these marginal likelihood functions. For approximating the\nmarginal likelihood functions, we derive a particular likelihood function from\na modified scenario of coin tossing which is useful for capturing how one\nparameter interacts with the remaining parameters in the likelihood function.\nFor reconstructing the joint likelihood function, we use an appropriate copula\nto link up these marginal likelihood functions. Numerical investigation\nsuggests the superior performance of our approach. Especially as the size of\nthe MRF increases, both the numerical performance and the computational cost of\nour approach remain consistently satisfactory, whereas Laplace approximation\ndeteriorates and pseudolikelihood becomes computationally unbearable.\n", "versions": [{"version": "v1", "created": "Tue, 27 Mar 2018 04:05:44 GMT"}], "update_date": "2018-03-28", "authors_parsed": [["Liu", "Jie", ""], ["Zheng", "Hao", ""]]}, {"id": "1803.09928", "submitter": "Tanvi Verma", "authors": "Tanvi Verma, Pradeep Varakantham and Hoong Chuin Lau", "title": "Entropy based Independent Learning in Anonymous Multi-Agent Settings", "comments": null, "journal-ref": "Vol 29 (2019): Proceedings of the Twenty-Ninth International\n  Conference on Automated Planning and Scheduling", "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Efficient sequential matching of supply and demand is a problem of interest\nin many online to offline services. For instance, Uber, Lyft, Grab for matching\ntaxis to customers; Ubereats, Deliveroo, FoodPanda etc for matching restaurants\nto customers. In these online to offline service problems, individuals who are\nresponsible for supply (e.g., taxi drivers, delivery bikes or delivery van\ndrivers) earn more by being at the \"right\" place at the \"right\" time. We are\ninterested in developing approaches that learn to guide individuals to be in\nthe \"right\" place at the \"right\" time (to maximize revenue) in the presence of\nother similar \"learning\" individuals and only local aggregated observation of\nother agents states (e.g., only number of other taxis in same zone as current\nagent).\n  A key characteristic of the domains of interest is that the interactions\nbetween individuals are anonymous, i.e., the outcome of an interaction\n(competing for demand) is dependent only on the number and not on the identity\nof the agents. We model these problems using the Anonymous MARL (AyMARL) model.\nThe key contribution of this paper is in employing principle of maximum entropy\nto provide a general framework of independent learning that is both empirically\neffective (even with only local aggregated information of agent population\ndistribution) and theoretically justified.\n  Finally, our approaches provide a significant improvement with respect to\njoint and individual revenue on a generic simulator for online to offline\nservices and a real world taxi problem over existing approaches. More\nimportantly, this is achieved while having the least variance in revenues\nearned by the learning individuals, an indicator of fairness.\n", "versions": [{"version": "v1", "created": "Tue, 27 Mar 2018 07:10:20 GMT"}, {"version": "v2", "created": "Sun, 27 May 2018 08:21:10 GMT"}, {"version": "v3", "created": "Wed, 20 Feb 2019 09:07:50 GMT"}, {"version": "v4", "created": "Mon, 3 Feb 2020 06:25:50 GMT"}], "update_date": "2020-02-04", "authors_parsed": [["Verma", "Tanvi", ""], ["Varakantham", "Pradeep", ""], ["Lau", "Hoong Chuin", ""]]}, {"id": "1803.09932", "submitter": "Jianbo Wang", "authors": "Dasong Li, Jianbo Wang", "title": "Image Semantic Transformation: Faster, Lighter and Stronger", "comments": "ECCV 2018 submission, 14 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We propose Image-Semantic-Transformation-Reconstruction-Circle(ISTRC) model,\na novel and powerful method using facenet's Euclidean latent space to\nunderstand the images. As the name suggests, ISTRC construct the circle, able\nto perfectly reconstruct images. One powerful Euclidean latent space embedded\nin ISTRC is FaceNet's last layer with the power of distinguishing and\nunderstanding images. Our model will reconstruct the images and manipulate\nEuclidean latent vectors to achieve semantic transformations and semantic\nimages arthimetic calculations. In this paper, we show that ISTRC performs 10\nhigh-level semantic transformations like \"Male and female\",\"add smile\",\"open\nmouth\", \"deduct beard or add mustache\", \"bigger/smaller nose\", \"make older and\nyounger\", \"bigger lips\", \"bigger eyes\", \"bigger/smaller mouths\" and \"more\nattractive\". It just takes 3 hours(GTX 1080) to train the models of 10 semantic\ntransformations.\n", "versions": [{"version": "v1", "created": "Tue, 27 Mar 2018 07:20:46 GMT"}], "update_date": "2018-03-28", "authors_parsed": [["Li", "Dasong", ""], ["Wang", "Jianbo", ""]]}, {"id": "1803.09956", "submitter": "Andy Zeng", "authors": "Andy Zeng, Shuran Song, Stefan Welker, Johnny Lee, Alberto Rodriguez,\n  Thomas Funkhouser", "title": "Learning Synergies between Pushing and Grasping with Self-supervised\n  Deep Reinforcement Learning", "comments": "To appear at the International Conference On Intelligent Robots and\n  Systems (IROS) 2018. Project webpage: http://vpg.cs.princeton.edu Summary\n  video: https://youtu.be/-OkyX7ZlhiU", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Skilled robotic manipulation benefits from complex synergies between\nnon-prehensile (e.g. pushing) and prehensile (e.g. grasping) actions: pushing\ncan help rearrange cluttered objects to make space for arms and fingers;\nlikewise, grasping can help displace objects to make pushing movements more\nprecise and collision-free. In this work, we demonstrate that it is possible to\ndiscover and learn these synergies from scratch through model-free deep\nreinforcement learning. Our method involves training two fully convolutional\nnetworks that map from visual observations to actions: one infers the utility\nof pushes for a dense pixel-wise sampling of end effector orientations and\nlocations, while the other does the same for grasping. Both networks are\ntrained jointly in a Q-learning framework and are entirely self-supervised by\ntrial and error, where rewards are provided from successful grasps. In this\nway, our policy learns pushing motions that enable future grasps, while\nlearning grasps that can leverage past pushes. During picking experiments in\nboth simulation and real-world scenarios, we find that our system quickly\nlearns complex behaviors amid challenging cases of clutter, and achieves better\ngrasping success rates and picking efficiencies than baseline alternatives\nafter only a few hours of training. We further demonstrate that our method is\ncapable of generalizing to novel objects. Qualitative results (videos), code,\npre-trained models, and simulation environments are available at\nhttp://vpg.cs.princeton.edu\n", "versions": [{"version": "v1", "created": "Tue, 27 Mar 2018 08:31:28 GMT"}, {"version": "v2", "created": "Mon, 16 Apr 2018 03:39:11 GMT"}, {"version": "v3", "created": "Sun, 30 Sep 2018 20:34:49 GMT"}], "update_date": "2018-10-02", "authors_parsed": [["Zeng", "Andy", ""], ["Song", "Shuran", ""], ["Welker", "Stefan", ""], ["Lee", "Johnny", ""], ["Rodriguez", "Alberto", ""], ["Funkhouser", "Thomas", ""]]}, {"id": "1803.09967", "submitter": "Juan Duque Rodriguez", "authors": "Roberto Maestre, Juan Duque, Alberto Rubio, Juan Ar\\'evalo", "title": "Reinforcement Learning for Fair Dynamic Pricing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unfair pricing policies have been shown to be one of the most negative\nperceptions customers can have concerning pricing, and may result in long-term\nlosses for a company. Despite the fact that dynamic pricing models help\ncompanies maximize revenue, fairness and equality should be taken into account\nin order to avoid unfair price differences between groups of customers. This\npaper shows how to solve dynamic pricing by using Reinforcement Learning (RL)\ntechniques so that prices are maximized while keeping a balance between revenue\nand fairness. We demonstrate that RL provides two main features to support\nfairness in dynamic pricing: on the one hand, RL is able to learn from recent\nexperience, adapting the pricing policy to complex market environments; on the\nother hand, it provides a trade-off between short and long-term objectives,\nhence integrating fairness into the model's core. Considering these two\nfeatures, we propose the application of RL for revenue optimization, with the\nadditional integration of fairness as part of the learning procedure by using\nJain's index as a metric. Results in a simulated environment show a significant\nimprovement in fairness while at the same time maintaining optimisation of\nrevenue.\n", "versions": [{"version": "v1", "created": "Tue, 27 Mar 2018 09:00:48 GMT"}], "update_date": "2018-03-28", "authors_parsed": [["Maestre", "Roberto", ""], ["Duque", "Juan", ""], ["Rubio", "Alberto", ""], ["Ar\u00e9valo", "Juan", ""]]}, {"id": "1803.09992", "submitter": "Alberto Perez Veiga", "authors": "Alberto Perez Veiga", "title": "Applications of Artificial Intelligence to Network Security", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Attacks to networks are becoming more complex and sophisticated every day.\nBeyond the so-called script-kiddies and hacking newbies, there is a myriad of\nprofessional attackers seeking to make serious profits infiltrating in\ncorporate networks. Either hostile governments, big corporations or mafias are\nconstantly increasing their resources and skills in cybercrime in order to spy,\nsteal or cause damage more effectively. traditional approaches to Network\nSecurity seem to start hitting their limits and it is being recognized the need\nfor a smarter approach to threat detections. This paper provides an\nintroduction on the need for evolution of Cyber Security techniques and how\nArtificial Intelligence could be of application to help solving some of the\nproblems. It provides also, a high-level overview of some state of the art AI\nNetwork Security techniques, to finish analysing what is the foreseeable future\nof the application of AI to Network Security.\n", "versions": [{"version": "v1", "created": "Tue, 27 Mar 2018 09:54:30 GMT"}], "update_date": "2018-03-28", "authors_parsed": [["Veiga", "Alberto Perez", ""]]}, {"id": "1803.10056", "submitter": "Carl-Johan Hoel", "authors": "Carl-Johan Hoel, Krister Wolff, Leo Laine", "title": "Automated Speed and Lane Change Decision Making using Deep Reinforcement\n  Learning", "comments": null, "journal-ref": "IEEE International Conference on Intelligent Transportation\n  Systems (ITSC), 2018, pp. 2148-2155", "doi": "10.1109/ITSC.2018.8569568", "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces a method, based on deep reinforcement learning, for\nautomatically generating a general purpose decision making function. A Deep\nQ-Network agent was trained in a simulated environment to handle speed and lane\nchange decisions for a truck-trailer combination. In a highway driving case, it\nis shown that the method produced an agent that matched or surpassed the\nperformance of a commonly used reference model. To demonstrate the generality\nof the method, the exact same algorithm was also tested by training it for an\novertaking case on a road with oncoming traffic. Furthermore, a novel way of\napplying a convolutional neural network to high level input that represents\ninterchangeable objects is also introduced.\n", "versions": [{"version": "v1", "created": "Wed, 14 Mar 2018 18:25:44 GMT"}, {"version": "v2", "created": "Thu, 1 Nov 2018 15:18:22 GMT"}], "update_date": "2019-05-10", "authors_parsed": [["Hoel", "Carl-Johan", ""], ["Wolff", "Krister", ""], ["Laine", "Leo", ""]]}, {"id": "1803.10081", "submitter": "Bharath Bhushan Damodaran", "authors": "Bharath Bhushan Damodaran, Benjamin Kellenberger, R\\'emi Flamary,\n  Devis Tuia, Nicolas Courty", "title": "DeepJDOT: Deep Joint Distribution Optimal Transport for Unsupervised\n  Domain Adaptation", "comments": "European Conference on Computer Vision 2018 (ECCV-2018)", "journal-ref": "in Proceedings of European Conference on Computer Vision 2018\n  (ECCV-2018)", "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In computer vision, one is often confronted with problems of domain shifts,\nwhich occur when one applies a classifier trained on a source dataset to target\ndata sharing similar characteristics (e.g. same classes), but also different\nlatent data structures (e.g. different acquisition conditions). In such a\nsituation, the model will perform poorly on the new data, since the classifier\nis specialized to recognize visual cues specific to the source domain. In this\nwork we explore a solution, named DeepJDOT, to tackle this problem: through a\nmeasure of discrepancy on joint deep representations/labels based on optimal\ntransport, we not only learn new data representations aligned between the\nsource and target domain, but also simultaneously preserve the discriminative\ninformation used by the classifier. We applied DeepJDOT to a series of visual\nrecognition tasks, where it compares favorably against state-of-the-art deep\ndomain adaptation methods.\n", "versions": [{"version": "v1", "created": "Tue, 27 Mar 2018 13:54:05 GMT"}, {"version": "v2", "created": "Fri, 27 Jul 2018 07:32:54 GMT"}, {"version": "v3", "created": "Wed, 5 Sep 2018 09:57:46 GMT"}], "update_date": "2018-09-06", "authors_parsed": [["Damodaran", "Bharath Bhushan", ""], ["Kellenberger", "Benjamin", ""], ["Flamary", "R\u00e9mi", ""], ["Tuia", "Devis", ""], ["Courty", "Nicolas", ""]]}, {"id": "1803.10133", "submitter": "Mirco Musolesi", "authors": "Beatrice Perez, Mirco Musolesi, Gianluca Stringhini", "title": "You are your Metadata: Identification and Obfuscation of Social Media\n  Users using Metadata Information", "comments": "11 pages, 13 figures. Published in the Proceedings of the 12th\n  International AAAI Conference on Web and Social Media (ICWSM 2018). June\n  2018. Stanford, CA, USA", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Metadata are associated to most of the information we produce in our daily\ninteractions and communication in the digital world. Yet, surprisingly,\nmetadata are often still catergorized as non-sensitive. Indeed, in the past,\nresearchers and practitioners have mainly focused on the problem of the\nidentification of a user from the content of a message.\n  In this paper, we use Twitter as a case study to quantify the uniqueness of\nthe association between metadata and user identity and to understand the\neffectiveness of potential obfuscation strategies. More specifically, we\nanalyze atomic fields in the metadata and systematically combine them in an\neffort to classify new tweets as belonging to an account using different\nmachine learning algorithms of increasing complexity. We demonstrate that\nthrough the application of a supervised learning algorithm, we are able to\nidentify any user in a group of 10,000 with approximately 96.7% accuracy.\nMoreover, if we broaden the scope of our search and consider the 10 most likely\ncandidates we increase the accuracy of the model to 99.22%. We also found that\ndata obfuscation is hard and ineffective for this type of data: even after\nperturbing 60% of the training data, it is still possible to classify users\nwith an accuracy higher than 95%. These results have strong implications in\nterms of the design of metadata obfuscation strategies, for example for data\nset release, not only for Twitter, but, more generally, for most social media\nplatforms.\n", "versions": [{"version": "v1", "created": "Tue, 27 Mar 2018 15:23:53 GMT"}, {"version": "v2", "created": "Mon, 14 May 2018 08:07:03 GMT"}], "update_date": "2018-05-15", "authors_parsed": [["Perez", "Beatrice", ""], ["Musolesi", "Mirco", ""], ["Stringhini", "Gianluca", ""]]}, {"id": "1803.10136", "submitter": "Md Saiful Islam", "authors": "Md Mahadi Hasan Nahid, Md. Ashraful Islam, Bishwajit Purkaystha, and\n  Md Saiful Islam", "title": "Comprehending Real Numbers: Development of Bengali Real Number Speech\n  Corpus", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.AI cs.SD", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Speech recognition has received a less attention in Bengali literature due to\nthe lack of a comprehensive dataset. In this paper, we describe the development\nprocess of the first comprehensive Bengali speech dataset on real numbers. It\ncomprehends all the possible words that may arise in uttering any Bengali real\nnumber. The corpus has ten speakers from the different regions of Bengali\nnative people. It comprises of more than two thousands of speech samples in a\ntotal duration of closed to four hours. We also provide a deep analysis of our\ncorpus, highlight some of the notable features of it, and finally evaluate the\nperformances of two of the notable Bengali speech recognizers on it.\n", "versions": [{"version": "v1", "created": "Tue, 27 Mar 2018 15:27:07 GMT"}], "update_date": "2018-03-28", "authors_parsed": [["Nahid", "Md Mahadi Hasan", ""], ["Islam", "Md. Ashraful", ""], ["Purkaystha", "Bishwajit", ""], ["Islam", "Md Saiful", ""]]}, {"id": "1803.10150", "submitter": "Ellen Vitercik", "authors": "Maria-Florina Balcan, Travis Dick, Tuomas Sandholm, and Ellen Vitercik", "title": "Learning to Branch", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tree search algorithms, such as branch-and-bound, are the most widely used\ntools for solving combinatorial and nonconvex problems. For example, they are\nthe foremost method for solving (mixed) integer programs and constraint\nsatisfaction problems. Tree search algorithms recursively partition the search\nspace to find an optimal solution. In order to keep the tree size small, it is\ncrucial to carefully decide, when expanding a tree node, which question\n(typically variable) to branch on at that node in order to partition the\nremaining space. Numerous partitioning techniques (e.g., variable selection)\nhave been proposed, but there is no theory describing which technique is\noptimal. We show how to use machine learning to determine an optimal weighting\nof any set of partitioning procedures for the instance distribution at hand\nusing samples from the distribution. We provide the first sample complexity\nguarantees for tree search algorithm configuration. These guarantees bound the\nnumber of samples sufficient to ensure that the empirical performance of an\nalgorithm over the samples nearly matches its expected performance on the\nunknown instance distribution. This thorough theoretical investigation\nnaturally gives rise to our learning algorithm. Via experiments, we show that\nlearning an optimal weighting of partitioning procedures can dramatically\nreduce tree size, and we prove that this reduction can even be exponential.\nThrough theory and experiments, we show that learning to branch is both\npractical and hugely beneficial.\n", "versions": [{"version": "v1", "created": "Tue, 27 Mar 2018 15:47:24 GMT"}, {"version": "v2", "created": "Wed, 16 May 2018 20:53:11 GMT"}], "update_date": "2018-05-18", "authors_parsed": [["Balcan", "Maria-Florina", ""], ["Dick", "Travis", ""], ["Sandholm", "Tuomas", ""], ["Vitercik", "Ellen", ""]]}, {"id": "1803.10227", "submitter": "Ashley Edwards", "authors": "Ashley D. Edwards, Laura Downs, James C. Davidson", "title": "Forward-Backward Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Goals for reinforcement learning problems are typically defined through\nhand-specified rewards. To design such problems, developers of learning\nalgorithms must inherently be aware of what the task goals are, yet we often\nrequire agents to discover them on their own without any supervision beyond\nthese sparse rewards. While much of the power of reinforcement learning derives\nfrom the concept that agents can learn with little guidance, this requirement\ngreatly burdens the training process. If we relax this one restriction and\nendow the agent with knowledge of the reward function, and in particular of the\ngoal, we can leverage backwards induction to accelerate training. To achieve\nthis, we propose training a model to learn to take imagined reversal steps from\nknown goal states. Rather than training an agent exclusively to determine how\nto reach a goal while moving forwards in time, our approach travels backwards\nto jointly predict how we got there. We evaluate our work in Gridworld and\nTowers of Hanoi and empirically demonstrate that it yields better performance\nthan standard DDQN.\n", "versions": [{"version": "v1", "created": "Tue, 27 Mar 2018 04:33:08 GMT"}], "update_date": "2018-03-29", "authors_parsed": [["Edwards", "Ashley D.", ""], ["Downs", "Laura", ""], ["Davidson", "James C.", ""]]}, {"id": "1803.10288", "submitter": "Aavaas Gajurel", "authors": "Aavaas Gajurel, Sushil J Louis, Daniel J Mendez, Siming Liu", "title": "Neuroevolution for RTS Micro", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper uses neuroevolution of augmenting topologies to evolve control\ntactics for groups of units in real-time strategy games. In such games, players\nbuild economies to generate armies composed of multiple types of units with\ndifferent attack and movement characteristics to combat each other. This paper\nevolves neural networks to control movement and attack commands, also called\nmicro, for a group of ranged units skirmishing with a group of melee units. Our\nresults show that neuroevolution of augmenting topologies can effectively\ngenerate neural networks capable of good micro for our ranged units against a\ngroup of hand-coded melee units. The evolved neural networks lead to kiting\nbehavior for the ranged units which is a common tactic used by professional\nplayers in ranged versus melee skirmishes in popular real-time strategy games\nlike Starcraft. The evolved neural networks also generalized well to other\nstarting positions and numbers of units. We believe these results indicate the\npotential of neuroevolution for generating effective micro in real-time\nstrategy games.\n", "versions": [{"version": "v1", "created": "Tue, 27 Mar 2018 19:48:21 GMT"}], "update_date": "2018-03-29", "authors_parsed": [["Gajurel", "Aavaas", ""], ["Louis", "Sushil J", ""], ["Mendez", "Daniel J", ""], ["Liu", "Siming", ""]]}, {"id": "1803.10402", "submitter": "Zhengxing Chen", "authors": "Zhengxing Chen, Yuyu Xu, Truong-Huy D. Nguyen, Yizhou Sun, Magy Seif\n  El-Nasr", "title": "Modeling Game Avatar Synergy and Opposition through Embedding in\n  Multiplayer Online Battle Arena Games", "comments": "Note: this is a draft rejected by AIIDE 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multiplayer Online Battle Arena (MOBA) games have received increasing\nworldwide popularity recently. In such games, players compete in teams against\neach other by controlling selected game avatars, each of which is designed with\ndifferent strengths and weaknesses. Intuitively, putting together game avatars\nthat complement each other (synergy) and suppress those of opponents\n(opposition) would result in a stronger team. In-depth understanding of synergy\nand opposition relationships among game avatars benefits player in making\ndecisions in game avatar drafting and gaining better prediction of match\nevents. However, due to intricate design and complex interactions between game\navatars, thorough understanding of their relationships is not a trivial task.\n  In this paper, we propose a latent variable model, namely Game Avatar\nEmbedding (GAE), to learn avatars' numerical representations which encode\nsynergy and opposition relationships between pairs of avatars. The merits of\nour model are twofold: (1) the captured synergy and opposition relationships\nare sensible to experienced human players' perception; (2) the learned\nnumerical representations of game avatars allow many important downstream\ntasks, such as similar avatar search, match outcome prediction, and avatar pick\nrecommender. To our best knowledge, no previous model is able to simultaneously\nsupport both features. Our quantitative and qualitative evaluations on real\nmatch data from three commercial MOBA games illustrate the benefits of our\nmodel.\n", "versions": [{"version": "v1", "created": "Wed, 28 Mar 2018 03:50:10 GMT"}], "update_date": "2018-06-27", "authors_parsed": [["Chen", "Zhengxing", ""], ["Xu", "Yuyu", ""], ["Nguyen", "Truong-Huy D.", ""], ["Sun", "Yizhou", ""], ["El-Nasr", "Magy Seif", ""]]}, {"id": "1803.10470", "submitter": "Jaan Aru", "authors": "Jaan Aru and Raul Vicente", "title": "What deep learning can tell us about higher cognitive functions like\n  mindreading?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG q-bio.NC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Can deep learning (DL) guide our understanding of computations happening in\nbiological brain? We will first briefly consider how DL has contributed to the\nresearch on visual object recognition. In the main part we will assess whether\nDL could also help us to clarify the computations underlying higher cognitive\nfunctions such as Theory of Mind. In addition, we will compare the objectives\nand learning signals of brains and machines, leading us to conclude that simply\nscaling up the current DL algorithms will most likely not lead to human level\nTheory of Mind.\n", "versions": [{"version": "v1", "created": "Wed, 28 Mar 2018 08:58:49 GMT"}, {"version": "v2", "created": "Thu, 4 Jul 2019 05:44:47 GMT"}], "update_date": "2019-07-05", "authors_parsed": [["Aru", "Jaan", ""], ["Vicente", "Raul", ""]]}, {"id": "1803.10508", "submitter": "Yanjing Wang", "authors": "Anantha Padmanabha, R. Ramanujam, Yanjing Wang", "title": "Bundled fragments of first-order modal logic: (un)decidability", "comments": "20 pages, under submission", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quantified modal logic provides a natural logical language for reasoning\nabout modal attitudes even while retaining the richness of quantification for\nreferring to predicates over domains. But then most fragments of the logic are\nundecidable, over many model classes. Over the years, only a few fragments\n(such as the monodic) have been shown to be decidable. In this paper, we study\nfragments that bundle quantifiers and modalities together, inspired by earlier\nwork on epistemic logics of know-how/why/what. As always with quantified modal\nlogics, it makes a significant difference whether the domain stays the same\nacross worlds, or not. In particular, we show that the bundle $\\forall \\Box$ is\nundecidable over constant domain interpretations, even with only monadic\npredicates, whereas $\\exists \\Box$ bundle is decidable. On the other hand, over\nincreasing domain interpretations, we get decidability with both $\\forall \\Box$\nand $\\exists \\Box$ bundles with unrestricted predicates. In these cases, we\nalso obtain tableau based procedures that run in \\PSPACE. We further show that\nthe $\\exists \\Box$ bundle cannot distinguish between constant domain and\nincreasing domain interpretations.\n", "versions": [{"version": "v1", "created": "Wed, 28 Mar 2018 10:20:13 GMT"}], "update_date": "2018-03-29", "authors_parsed": [["Padmanabha", "Anantha", ""], ["Ramanujam", "R.", ""], ["Wang", "Yanjing", ""]]}, {"id": "1803.10567", "submitter": "Tobias Hinz", "authors": "Tobias Hinz, Stefan Wermter", "title": "Image Generation and Translation with Disentangled Representations", "comments": "Accepted as a conference paper at the International Joint Conference\n  on Neural Networks (IJCNN) 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative models have made significant progress in the tasks of modeling\ncomplex data distributions such as natural images. The introduction of\nGenerative Adversarial Networks (GANs) and auto-encoders lead to the\npossibility of training on big data sets in an unsupervised manner. However,\nfor many generative models it is not possible to specify what kind of image\nshould be generated and it is not possible to translate existing images into\nnew images of similar domains. Furthermore, models that can perform\nimage-to-image translation often need distinct models for each domain, making\nit hard to scale these systems to multiple domain image-to-image translation.\nWe introduce a model that can do both, controllable image generation and\nimage-to-image translation between multiple domains. We split our image\nrepresentation into two parts encoding unstructured and structured information\nrespectively. The latter is designed in a disentangled manner, so that\ndifferent parts encode different image characteristics. We train an encoder to\nencode images into these representations and use a small amount of labeled data\nto specify what kind of information should be encoded in the disentangled part.\nA generator is trained to generate images from these representations using the\ncharacteristics provided by the disentangled part of the representation.\nThrough this we can control what kind of images the generator generates,\ntranslate images between different domains, and even learn unknown\ndata-generating factors while only using one single model.\n", "versions": [{"version": "v1", "created": "Wed, 28 Mar 2018 12:53:01 GMT"}], "update_date": "2018-03-29", "authors_parsed": [["Hinz", "Tobias", ""], ["Wermter", "Stefan", ""]]}, {"id": "1803.10609", "submitter": "Emmanuel Vincent", "authors": "Jon Barker, Shinji Watanabe (CLSP), Emmanuel Vincent (MULTISPEECH),\n  Jan Trmal (CLSP)", "title": "The fifth 'CHiME' Speech Separation and Recognition Challenge: Dataset,\n  task and baselines", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.AI eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The CHiME challenge series aims to advance robust automatic speech\nrecognition (ASR) technology by promoting research at the interface of speech\nand language processing, signal processing , and machine learning. This paper\nintroduces the 5th CHiME Challenge, which considers the task of distant\nmulti-microphone conversational ASR in real home environments. Speech material\nwas elicited using a dinner party scenario with efforts taken to capture data\nthat is representative of natural conversational speech and recorded by 6\nKinect microphone arrays and 4 binaural microphone pairs. The challenge\nfeatures a single-array track and a multiple-array track and, for each track,\ndistinct rankings will be produced for systems focusing on robustness with\nrespect to distant-microphone capture vs. systems attempting to address all\naspects of the task including conversational language modeling. We discuss the\nrationale for the challenge and provide a detailed description of the data\ncollection procedure, the task, and the baseline systems for array\nsynchronization, speech enhancement, and conventional and end-to-end ASR.\n", "versions": [{"version": "v1", "created": "Wed, 28 Mar 2018 13:51:09 GMT"}], "update_date": "2018-03-29", "authors_parsed": [["Barker", "Jon", "", "CLSP"], ["Watanabe", "Shinji", "", "CLSP"], ["Vincent", "Emmanuel", "", "MULTISPEECH"], ["Trmal", "Jan", "", "CLSP"]]}, {"id": "1803.10648", "submitter": "Luis A. Pineda", "authors": "Luis A. Pineda", "title": "A Distributed Extension of the Turing Machine", "comments": "37 pages, 15 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Turing Machine has two implicit properties that depend on its underlying\nnotion of computing: the format is fully determinate and computations are\ninformation preserving. Distributed representations lack these properties and\ncannot be fully captured by Turing's standard model. To address this limitation\na distributed extension of the Turing Machine is introduced in this paper. In\nthe extended machine, functions and abstractions are expressed extensionally\nand computations are entropic. The machine is applied to the definition of an\nassociative memory, with its corresponding memory register, recognition and\nretrieval operations. The memory is tested with an experiment for storing and\nrecognizing hand written digits with satisfactory results. The experiment can\nbe seen as a proof of concept that information can be stored and processed\neffectively in a highly distributed fashion using a symbolic but not fully\ndeterminate format. The new machine augments the symbolic mode of computing\nwith consequences on the way Church Thesis is understood. The paper is\nconcluded with a discussion of some implications of the extended machine for\nArtificial Intelligence and Cognition.\n", "versions": [{"version": "v1", "created": "Wed, 28 Mar 2018 14:36:54 GMT"}], "update_date": "2018-03-29", "authors_parsed": [["Pineda", "Luis A.", ""]]}, {"id": "1803.10684", "submitter": "Kyrylo Malakhov", "authors": "A. V. Palagin, N. G. Petrenko, V. Yu. Velychko, K. S. Malakhov", "title": "Development of formal models, algorithms, procedures, engineering and\n  functioning of the software system \"Instrumental complex for ontological\n  engineering purpose\"", "comments": "in Russian", "journal-ref": "Problems in programming 2-3 (2014) 221-232", "doi": null, "report-no": null, "categories": "cs.SE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The given paper considered a generalized model representation of the software\nsystem \"Instrumental complex for ontological engineering purpose\". Represented\ncomplete software system development process. Developed relevant formal models\nof the software system \"Instrumental complex for ontological engineering\npurpose\", represented as mathematical expressions, UML diagrams, and also\ndescribed the three-tier architecture of the software system \"Instrumental\ncomplex for ontological engineering purpose\" in a client-server environment.\n", "versions": [{"version": "v1", "created": "Sat, 24 Mar 2018 07:14:00 GMT"}], "update_date": "2018-03-29", "authors_parsed": [["Palagin", "A. V.", ""], ["Petrenko", "N. G.", ""], ["Velychko", "V. Yu.", ""], ["Malakhov", "K. S.", ""]]}, {"id": "1803.10813", "submitter": "Daniele Ravi'", "authors": "Javier Andreu-Perez, Fani Deligianni, Daniele Ravi and Guang-Zhong\n  Yang", "title": "Artificial Intelligence and Robotics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recent successes of AI have captured the wildest imagination of both the\nscientific communities and the general public. Robotics and AI amplify human\npotentials, increase productivity and are moving from simple reasoning towards\nhuman-like cognitive abilities. Current AI technologies are used in a set area\nof applications, ranging from healthcare, manufacturing, transport, energy, to\nfinancial services, banking, advertising, management consulting and government\nagencies. The global AI market is around 260 billion USD in 2016 and it is\nestimated to exceed 3 trillion by 2024. To understand the impact of AI, it is\nimportant to draw lessons from it's past successes and failures and this white\npaper provides a comprehensive explanation of the evolution of AI, its current\nstatus and future directions.\n", "versions": [{"version": "v1", "created": "Wed, 28 Mar 2018 19:11:24 GMT"}], "update_date": "2020-08-07", "authors_parsed": [["Andreu-Perez", "Javier", ""], ["Deligianni", "Fani", ""], ["Ravi", "Daniele", ""], ["Yang", "Guang-Zhong", ""]]}, {"id": "1803.10937", "submitter": "Aditya Grover", "authors": "Aditya Grover, Todor Markov, Peter Attia, Norman Jin, Nicholas\n  Perkins, Bryan Cheong, Michael Chen, Zi Yang, Stephen Harris, William Chueh,\n  Stefano Ermon", "title": "Best arm identification in multi-armed bandits with delayed feedback", "comments": "AISTATS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a generalization of the best arm identification problem in\nstochastic multi-armed bandits (MAB) to the setting where every pull of an arm\nis associated with delayed feedback. The delay in feedback increases the\neffective sample complexity of standard algorithms, but can be offset if we\nhave access to partial feedback received before a pull is completed. We propose\na general framework to model the relationship between partial and delayed\nfeedback, and as a special case we introduce efficient algorithms for settings\nwhere the partial feedback are biased or unbiased estimators of the delayed\nfeedback. Additionally, we propose a novel extension of the algorithms to the\nparallel MAB setting where an agent can control a batch of arms. Our\nexperiments in real-world settings, involving policy search and hyperparameter\noptimization in computational sustainability domains for fast charging of\nbatteries and wildlife corridor construction, demonstrate that exploiting the\nstructure of partial feedback can lead to significant improvements over\nbaselines in both sequential and parallel MAB.\n", "versions": [{"version": "v1", "created": "Thu, 29 Mar 2018 06:46:38 GMT"}], "update_date": "2018-03-30", "authors_parsed": [["Grover", "Aditya", ""], ["Markov", "Todor", ""], ["Attia", "Peter", ""], ["Jin", "Norman", ""], ["Perkins", "Nicholas", ""], ["Cheong", "Bryan", ""], ["Chen", "Michael", ""], ["Yang", "Zi", ""], ["Harris", "Stephen", ""], ["Chueh", "William", ""], ["Ermon", "Stefano", ""]]}, {"id": "1803.10953", "submitter": "Jixin Liu", "authors": "Jixin Liu, Yanjing Wang, Yifeng Ding", "title": "Weakly Aggregative Modal Logic: Characterization and Interpolation (new\n  version)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Weakly Aggregative Modal Logic (WAML) is a collection of disguised polyadic\nmodal logics with n-ary modalities whose arguments are all the same. WAML has\nsome interesting applications on epistemic logic and logic of games, so we\nstudy some basic model theoretical aspects of WAML in this paper. Specifically,\nwe give a van Benthem-Rosen characterization theorem of WAML based on an\nintuitive notion of bisimulation and show that each basic WAML system K_n lacks\nCraig Interpolation.\n", "versions": [{"version": "v1", "created": "Thu, 29 Mar 2018 08:13:20 GMT"}, {"version": "v2", "created": "Sat, 6 Oct 2018 03:13:08 GMT"}, {"version": "v3", "created": "Thu, 30 May 2019 14:20:21 GMT"}], "update_date": "2019-05-31", "authors_parsed": [["Liu", "Jixin", ""], ["Wang", "Yanjing", ""], ["Ding", "Yifeng", ""]]}, {"id": "1803.10981", "submitter": "Peter Nightingale", "authors": "Ian P. Gent and Ciaran McCreesh and Ian Miguel and Neil C.A. Moore and\n  Peter Nightingale and Patrick Prosser and Chris Unsworth", "title": "A Review of Literature on Parallel Constraint Solving", "comments": "Under consideration in Theory and Practice of Logic Programming\n  (TPLP)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As multicore computing is now standard, it seems irresponsible for\nconstraints researchers to ignore the implications of it. Researchers need to\naddress a number of issues to exploit parallelism, such as: investigating which\nconstraint algorithms are amenable to parallelisation; whether to use shared\nmemory or distributed computation; whether to use static or dynamic\ndecomposition; and how to best exploit portfolios and cooperating search. We\nreview the literature, and see that we can sometimes do quite well, some of the\ntime, on some instances, but we are far from a general solution. Yet there\nseems to be little overall guidance that can be given on how best to exploit\nmulticore computers to speed up constraint solving. We hope at least that this\nsurvey will provide useful pointers to future researchers wishing to correct\nthis situation.\n  Under consideration in Theory and Practice of Logic Programming (TPLP).\n", "versions": [{"version": "v1", "created": "Thu, 29 Mar 2018 09:34:09 GMT"}], "update_date": "2018-03-30", "authors_parsed": [["Gent", "Ian P.", ""], ["McCreesh", "Ciaran", ""], ["Miguel", "Ian", ""], ["Moore", "Neil C. A.", ""], ["Nightingale", "Peter", ""], ["Prosser", "Patrick", ""], ["Unsworth", "Chris", ""]]}, {"id": "1803.10995", "submitter": "Richard Kenway", "authors": "Richard Kenway", "title": "Protection against Cloning for Deep Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cond-mat.dis-nn cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The susceptibility of deep learning to adversarial attack can be understood\nin the framework of the Renormalisation Group (RG) and the vulnerability of a\nspecific network may be diagnosed provided the weights in each layer are known.\nAn adversary with access to the inputs and outputs could train a second network\nto clone these weights and, having identified a weakness, use them to compute\nthe perturbation of the input data which exploits it. However, the RG framework\nalso provides a means to poison the outputs of the network imperceptibly,\nwithout affecting their legitimate use, so as to prevent such cloning of its\nweights and thereby foil the generation of adversarial data.\n", "versions": [{"version": "v1", "created": "Thu, 29 Mar 2018 10:02:09 GMT"}], "update_date": "2018-03-30", "authors_parsed": [["Kenway", "Richard", ""]]}, {"id": "1803.11002", "submitter": "Mehdi Ghatee Dr.", "authors": "Sima Sharifirad and Azra Nazari and Mehdi Ghatee", "title": "Modified SMOTE Using Mutual Information and Different Sorts of Entropies", "comments": "10 Pages, 4 Tables, 8 Figures, Extracted from an MSc project with\n  Department of Computer Science, Amirkabir University of Technology, Tehran,\n  Iran", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  SMOTE is one of the oversampling techniques for balancing the datasets and it\nis considered as a pre-processing step in learning algorithms. In this paper,\nfour new enhanced SMOTE are proposed that include an improved version of KNN in\nwhich the attribute weights are defined by mutual information firstly and then\nthey are replaced by maximum entropy, Renyi entropy and Tsallis entropy. These\nfour pre-processing methods are combined with 1NN and J48 classifiers and their\nperformance are compared with the previous methods on 11 imbalanced datasets\nfrom KEEL repository. The results show that these pre-processing methods\nimproves the accuracy compared with the previous stablished works. In addition,\nas a case study, the first pre-processing method is applied on transportation\ndata of Tehran-Bazargan Highway in Iran with IR equal to 36.\n", "versions": [{"version": "v1", "created": "Thu, 29 Mar 2018 10:41:19 GMT"}], "update_date": "2018-04-04", "authors_parsed": [["Sharifirad", "Sima", ""], ["Nazari", "Azra", ""], ["Ghatee", "Mehdi", ""]]}, {"id": "1803.11060", "submitter": "Toon Van Craenendonck", "authors": "Toon Van Craenendonck, Sebastijan Duman\\v{c}i\\'c, Elia Van Wolputte\n  and Hendrik Blockeel", "title": "COBRAS: Fast, Iterative, Active Clustering with Pairwise Constraints", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Constraint-based clustering algorithms exploit background knowledge to\nconstruct clusterings that are aligned with the interests of a particular user.\nThis background knowledge is often obtained by allowing the clustering system\nto pose pairwise queries to the user: should these two elements be in the same\ncluster or not? Active clustering methods aim to minimize the number of queries\nneeded to obtain a good clustering by querying the most informative pairs\nfirst. Ideally, a user should be able to answer a couple of these queries,\ninspect the resulting clustering, and repeat these two steps until a\nsatisfactory result is obtained. We present COBRAS, an approach to active\nclustering with pairwise constraints that is suited for such an interactive\nclustering process. A core concept in COBRAS is that of a super-instance: a\nlocal region in the data in which all instances are assumed to belong to the\nsame cluster. COBRAS constructs such super-instances in a top-down manner to\nproduce high-quality results early on in the clustering process, and keeps\nrefining these super-instances as more pairwise queries are given to get more\ndetailed clusterings later on. We experimentally demonstrate that COBRAS\nproduces good clusterings at fast run times, making it an excellent candidate\nfor the iterative clustering scenario outlined above.\n", "versions": [{"version": "v1", "created": "Thu, 29 Mar 2018 13:52:59 GMT"}], "update_date": "2018-03-30", "authors_parsed": [["Van Craenendonck", "Toon", ""], ["Duman\u010di\u0107", "Sebastijan", ""], ["Van Wolputte", "Elia", ""], ["Blockeel", "Hendrik", ""]]}, {"id": "1803.11070", "submitter": "Piji Li", "authors": "Piji Li, Lidong Bing, Wai Lam", "title": "Actor-Critic based Training Framework for Abstractive Summarization", "comments": "10 pages. arXiv admin note: text overlap with arXiv:1708.00625", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a training framework for neural abstractive summarization based on\nactor-critic approaches from reinforcement learning. In the traditional neural\nnetwork based methods, the objective is only to maximize the likelihood of the\npredicted summaries, no other assessment constraints are considered, which may\ngenerate low-quality summaries or even incorrect sentences. To alleviate this\nproblem, we employ an actor-critic framework to enhance the training procedure.\nFor the actor, we employ the typical attention based sequence-to-sequence\n(seq2seq) framework as the policy network for summary generation. For the\ncritic, we combine the maximum likelihood estimator with a well designed global\nsummary quality estimator which is a neural network based binary classifier\naiming to make the generated summaries indistinguishable from the human-written\nones. Policy gradient method is used to conduct the parameter learning. An\nalternating training strategy is proposed to conduct the joint training of the\nactor and critic models. Extensive experiments on some benchmark datasets in\ndifferent languages show that our framework achieves improvements over the\nstate-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Wed, 28 Mar 2018 02:47:51 GMT"}, {"version": "v2", "created": "Wed, 15 Aug 2018 15:59:46 GMT"}], "update_date": "2018-08-16", "authors_parsed": [["Li", "Piji", ""], ["Bing", "Lidong", ""], ["Lam", "Wai", ""]]}, {"id": "1803.11080", "submitter": "Qiao Zheng", "authors": "Qiao Zheng, Herv\\'e Delingette, Nicolas Duchateau, Nicholas Ayache", "title": "3D Consistent Biventricular Myocardial Segmentation Using Deep Learning\n  for Mesh Generation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel automated method to segment the myocardium of both left\nand right ventricles in MRI volumes. The segmentation is consistent in 3D\nacross the slices such that it can be directly used for mesh generation. Two\nspecific neural networks with multi-scale coarse-to-fine prediction structure\nare proposed to cope with the small training dataset and trained using an\noriginal loss function. The former segments a slice in the middle of the\nvolume. Then the latter iteratively propagates the slice segmentations towards\nthe base and the apex, in a spatially consistent way. We perform 5-fold\ncross-validation on the 15 cases from STACOM to validate the method. For\ntraining, we use real cases and their synthetic variants generated by combining\nmotion simulation and image synthesis. Accurate and consistent testing results\nare obtained.\n", "versions": [{"version": "v1", "created": "Thu, 29 Mar 2018 14:08:12 GMT"}], "update_date": "2018-03-30", "authors_parsed": [["Zheng", "Qiao", ""], ["Delingette", "Herv\u00e9", ""], ["Duchateau", "Nicolas", ""], ["Ayache", "Nicholas", ""]]}, {"id": "1803.11115", "submitter": "Xiaoyuan Liang", "authors": "Xiaoyuan Liang, Xunsheng Du, Guiling Wang, Zhu Han", "title": "Deep Reinforcement Learning for Traffic Light Control in Vehicular\n  Networks", "comments": null, "journal-ref": "IEEE Transactions on Vehicular Technology ( Volume: 68 , Issue: 2\n  , Feb. 2019 )", "doi": "10.1109/TVT.2018.2890726", "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing inefficient traffic light control causes numerous problems, such as\nlong delay and waste of energy. To improve efficiency, taking real-time traffic\ninformation as an input and dynamically adjusting the traffic light duration\naccordingly is a must. In terms of how to dynamically adjust traffic signals'\nduration, existing works either split the traffic signal into equal duration or\nextract limited traffic information from the real data. In this paper, we study\nhow to decide the traffic signals' duration based on the collected data from\ndifferent sensors and vehicular networks. We propose a deep reinforcement\nlearning model to control the traffic light. In the model, we quantify the\ncomplex traffic scenario as states by collecting data and dividing the whole\nintersection into small grids. The timing changes of a traffic light are the\nactions, which are modeled as a high-dimension Markov decision process. The\nreward is the cumulative waiting time difference between two cycles. To solve\nthe model, a convolutional neural network is employed to map the states to\nrewards. The proposed model is composed of several components to improve the\nperformance, such as dueling network, target network, double Q-learning\nnetwork, and prioritized experience replay. We evaluate our model via\nsimulation in the Simulation of Urban MObility (SUMO) in a vehicular network,\nand the simulation results show the efficiency of our model in controlling\ntraffic lights.\n", "versions": [{"version": "v1", "created": "Thu, 29 Mar 2018 15:24:28 GMT"}], "update_date": "2019-02-19", "authors_parsed": [["Liang", "Xiaoyuan", ""], ["Du", "Xunsheng", ""], ["Wang", "Guiling", ""], ["Han", "Zhu", ""]]}, {"id": "1803.11256", "submitter": "Alexander Kott", "authors": "Alexander Kott", "title": "Challenges and Characteristics of Intelligent Autonomy for Internet of\n  Battle Things in Highly Adversarial Environments", "comments": "This is a version of the paper that was presented at, and will appear\n  in the Proceedings of the 2018 Spring Symposium of AAAI, March 26-28, 2018,\n  Palo Alto, CA", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Numerous, artificially intelligent, networked things will populate the\nbattlefield of the future, operating in close collaboration with human\nwarfighters, and fighting as teams in highly adversarial environments. This\npaper explores the characteristics, capabilities and intelligence required of\nsuch a network of intelligent things and humans - Internet of Battle Things\n(IOBT). It will experience unique challenges that are not yet well addressed by\nthe current generation of AI and machine learning.\n", "versions": [{"version": "v1", "created": "Tue, 20 Mar 2018 22:15:14 GMT"}, {"version": "v2", "created": "Fri, 13 Apr 2018 19:36:14 GMT"}], "update_date": "2018-04-17", "authors_parsed": [["Kott", "Alexander", ""]]}, {"id": "1803.11261", "submitter": "Kush Varshney", "authors": "Kush R. Varshney", "title": "How an Electrical Engineer Became an Artificial Intelligence Researcher,\n  a Multiphase Active Contours Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This essay examines how what is considered to be artificial intelligence (AI)\nhas changed over time and come to intersect with the expertise of the author.\nInitially, AI developed on a separate trajectory, both topically and\ninstitutionally, from pattern recognition, neural information processing,\ndecision and control systems, and allied topics by focusing on symbolic systems\nwithin computer science departments rather than on continuous systems in\nelectrical engineering departments. The separate evolutions continued\nthroughout the author's lifetime, with some crossover in reinforcement learning\nand graphical models, but were shocked into converging by the virality of deep\nlearning, thus making an electrical engineer into an AI researcher. Now that\nthis convergence has happened, opportunity exists to pursue an agenda that\ncombines learning and reasoning bridged by interpretable machine learning\nmodels.\n", "versions": [{"version": "v1", "created": "Thu, 29 Mar 2018 21:11:32 GMT"}], "update_date": "2018-04-02", "authors_parsed": [["Varshney", "Kush R.", ""]]}, {"id": "1803.11284", "submitter": "Bodhisattwa Prasad Majumder", "authors": "Bodhisattwa Prasad Majumder, Aditya Subramanian, Abhinandan Krishnan,\n  Shreyansh Gandhi, Ajinkya More", "title": "Deep Recurrent Neural Networks for Product Attribute Extraction in\n  eCommerce", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Extracting accurate attribute qualities from product titles is a vital\ncomponent in delivering eCommerce customers with a rewarding online shopping\nexperience via an enriched faceted search. We demonstrate the potential of Deep\nRecurrent Networks in this domain, primarily models such as Bidirectional LSTMs\nand Bidirectional LSTM-CRF with or without an attention mechanism. These have\nimproved overall F1 scores, as compared to the previous benchmarks (More et\nal.) by at least 0.0391, showcasing an overall precision of 97.94%, recall of\n94.12% and the F1 score of 0.9599. This has made us achieve a significant\ncoverage of important facets or attributes of products which not only shows the\nefficacy of deep recurrent models over previous machine learning benchmarks but\nalso greatly enhances the overall customer experience while shopping online.\n", "versions": [{"version": "v1", "created": "Thu, 29 Mar 2018 23:21:11 GMT"}], "update_date": "2018-09-07", "authors_parsed": [["Majumder", "Bodhisattwa Prasad", ""], ["Subramanian", "Aditya", ""], ["Krishnan", "Abhinandan", ""], ["Gandhi", "Shreyansh", ""], ["More", "Ajinkya", ""]]}, {"id": "1803.11288", "submitter": "Andrew Davison", "authors": "Andrew J. Davison", "title": "FutureMapping: The Computational Structure of Spatial AI Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CV cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We discuss and predict the evolution of Simultaneous Localisation and Mapping\n(SLAM) into a general geometric and semantic `Spatial AI' perception capability\nfor intelligent embodied devices. A big gap remains between the visual\nperception performance that devices such as augmented reality eyewear or\ncomsumer robots will require and what is possible within the constraints\nimposed by real products. Co-design of algorithms, processors and sensors will\nbe needed. We explore the computational structure of current and future Spatial\nAI algorithms and consider this within the landscape of ongoing hardware\ndevelopments.\n", "versions": [{"version": "v1", "created": "Thu, 29 Mar 2018 23:46:34 GMT"}], "update_date": "2018-04-02", "authors_parsed": [["Davison", "Andrew J.", ""]]}, {"id": "1803.11373", "submitter": "Nicholas Guttenberg", "authors": "Nicholas Guttenberg, Ryota Kanai", "title": "Learning to generate classifiers", "comments": "11 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We train a network to generate mappings between training sets and\nclassification policies (a 'classifier generator') by conditioning on the\nentire training set via an attentional mechanism. The network is directly\noptimized for test set performance on an training set of related tasks, which\nis then transferred to unseen 'test' tasks. We use this to optimize for\nperformance in the low-data and unsupervised learning regimes, and obtain\nsignificantly better performance in the 10-50 datapoint regime than support\nvector classifiers, random forests, XGBoost, and k-nearest neighbors on a range\nof small datasets.\n", "versions": [{"version": "v1", "created": "Fri, 30 Mar 2018 07:43:35 GMT"}], "update_date": "2018-04-02", "authors_parsed": [["Guttenberg", "Nicholas", ""], ["Kanai", "Ryota", ""]]}, {"id": "1803.11437", "submitter": "Haris Aziz", "authors": "Haris Aziz", "title": "A Rule for Committee Selection with Soft Diversity Constraints", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Committee selection with diversity or distributional constraints is a\nubiquitous problem. However, many of the formal approaches proposed so far have\ncertain drawbacks including (1) computationally intractability in general, and\n(2) inability to suggest a solution for certain instances where the hard\nconstraints cannot be met. We propose a practical and polynomial-time algorithm\nfor diverse committee selection that draws on the idea of using soft bounds and\nsatisfies natural axioms.\n", "versions": [{"version": "v1", "created": "Fri, 30 Mar 2018 12:36:36 GMT"}], "update_date": "2018-04-02", "authors_parsed": [["Aziz", "Haris", ""]]}, {"id": "1803.11439", "submitter": "Xinpeng Chen", "authors": "Xinpeng Chen and Lin Ma and Wenhao Jiang and Jian Yao and Wei Liu", "title": "Regularizing RNNs for Caption Generation by Reconstructing The Past with\n  The Present", "comments": "Accepted by CVPR 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, caption generation with an encoder-decoder framework has been\nextensively studied and applied in different domains, such as image captioning,\ncode captioning, and so on. In this paper, we propose a novel architecture,\nnamely Auto-Reconstructor Network (ARNet), which, coupling with the\nconventional encoder-decoder framework, works in an end-to-end fashion to\ngenerate captions. ARNet aims at reconstructing the previous hidden state with\nthe present one, besides behaving as the input-dependent transition operator.\nTherefore, ARNet encourages the current hidden state to embed more information\nfrom the previous one, which can help regularize the transition dynamics of\nrecurrent neural networks (RNNs). Extensive experimental results show that our\nproposed ARNet boosts the performance over the existing encoder-decoder models\non both image captioning and source code captioning tasks. Additionally, ARNet\nremarkably reduces the discrepancy between training and inference processes for\ncaption generation. Furthermore, the performance on permuted sequential MNIST\ndemonstrates that ARNet can effectively regularize RNN, especially on modeling\nlong-term dependencies. Our code is available at:\nhttps://github.com/chenxinpeng/ARNet\n", "versions": [{"version": "v1", "created": "Fri, 30 Mar 2018 13:15:56 GMT"}, {"version": "v2", "created": "Sat, 7 Apr 2018 01:49:44 GMT"}], "update_date": "2018-04-10", "authors_parsed": [["Chen", "Xinpeng", ""], ["Ma", "Lin", ""], ["Jiang", "Wenhao", ""], ["Yao", "Jian", ""], ["Liu", "Wei", ""]]}, {"id": "1803.11493", "submitter": "Alexander Grabner", "authors": "Alexander Grabner, Peter M. Roth and Vincent Lepetit", "title": "3D Pose Estimation and 3D Model Retrieval for Objects in the Wild", "comments": "Accepted to Conference on Computer Vision and Pattern Recognition\n  (CVPR) 2018", "journal-ref": "Conference on Computer Vision and Pattern Recognition 2018", "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a scalable, efficient and accurate approach to retrieve 3D models\nfor objects in the wild. Our contribution is twofold. We first present a 3D\npose estimation approach for object categories which significantly outperforms\nthe state-of-the-art on Pascal3D+. Second, we use the estimated pose as a prior\nto retrieve 3D models which accurately represent the geometry of objects in RGB\nimages. For this purpose, we render depth images from 3D models under our\npredicted pose and match learned image descriptors of RGB images against those\nof rendered depth images using a CNN-based multi-view metric learning approach.\nIn this way, we are the first to report quantitative results for 3D model\nretrieval on Pascal3D+, where our method chooses the same models as human\nannotators for 50% of the validation images on average. In addition, we show\nthat our method, which was trained purely on Pascal3D+, retrieves rich and\naccurate 3D models from ShapeNet given RGB images of objects in the wild.\n", "versions": [{"version": "v1", "created": "Fri, 30 Mar 2018 14:47:49 GMT"}], "update_date": "2018-04-02", "authors_parsed": [["Grabner", "Alexander", ""], ["Roth", "Peter M.", ""], ["Lepetit", "Vincent", ""]]}, {"id": "1803.11556", "submitter": "Zhongzheng Ren", "authors": "Zhongzheng Ren, Yong Jae Lee, Michael S. Ryoo", "title": "Learning to Anonymize Faces for Privacy Preserving Action Detection", "comments": "ECCV'18 camera ready", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is an increasing concern in computer vision devices invading users'\nprivacy by recording unwanted videos. On the one hand, we want the camera\nsystems to recognize important events and assist human daily lives by\nunderstanding its videos, but on the other hand we want to ensure that they do\nnot intrude people's privacy. In this paper, we propose a new principled\napproach for learning a video \\emph{face anonymizer}. We use an adversarial\ntraining setting in which two competing systems fight: (1) a video anonymizer\nthat modifies the original video to remove privacy-sensitive information while\nstill trying to maximize spatial action detection performance, and (2) a\ndiscriminator that tries to extract privacy-sensitive information from the\nanonymized videos. The end result is a video anonymizer that performs\npixel-level modifications to anonymize each person's face, with minimal effect\non action detection performance. We experimentally confirm the benefits of our\napproach compared to conventional hand-crafted anonymization methods including\nmasking, blurring, and noise adding. Code, demo, and more results can be found\non our project page https://jason718.github.io/project/privacy/main.html.\n", "versions": [{"version": "v1", "created": "Fri, 30 Mar 2018 17:55:04 GMT"}, {"version": "v2", "created": "Thu, 26 Jul 2018 18:40:52 GMT"}], "update_date": "2018-07-30", "authors_parsed": [["Ren", "Zhongzheng", ""], ["Lee", "Yong Jae", ""], ["Ryoo", "Michael S.", ""]]}]