[{"id": "0904.0019", "submitter": "Josep Argelich", "authors": "Josep Argelich, Ines Lynce, and Joao Marques-Silva", "title": "On Solving Boolean Multilevel Optimization Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many combinatorial optimization problems entail a number of hierarchically\ndependent optimization problems. An often used solution is to associate a\nsuitably large cost with each individual optimization problem, such that the\nsolution of the resulting aggregated optimization problem solves the original\nset of hierarchically dependent optimization problems. This paper starts by\nstudying the package upgradeability problem in software distributions.\nStraightforward solutions based on Maximum Satisfiability (MaxSAT) and\npseudo-Boolean (PB) optimization are shown to be ineffective, and unlikely to\nscale for large problem instances. Afterwards, the package upgradeability\nproblem is related to multilevel optimization. The paper then develops new\nalgorithms for Boolean Multilevel Optimization (BMO) and highlights a large\nnumber of potential applications. The experimental results indicate that the\nproposed algorithms for BMO allow solving optimization problems that existing\nMaxSAT and PB solvers would otherwise be unable to solve.\n", "versions": [{"version": "v1", "created": "Tue, 31 Mar 2009 21:01:07 GMT"}], "update_date": "2009-04-02", "authors_parsed": [["Argelich", "Josep", ""], ["Lynce", "Ines", ""], ["Marques-Silva", "Joao", ""]]}, {"id": "0904.0027", "submitter": "Marko A. Rodriguez", "authors": "Marko A. Rodriguez and Jennifer H. Watkins", "title": "Faith in the Algorithm, Part 2: Computational Eudaemonics", "comments": null, "journal-ref": "Proceedings of the International Conference on Knowledge-Based and\n  Intelligent Information & Engineering Systems, Invited Session: Innovations\n  in Intelligent Systems, Lecture Notes in Artificial Intelligence,\n  Springer-Verlag, October 2009.", "doi": null, "report-no": "LA-UR-09-02095", "categories": "cs.CY cs.AI", "license": "http://creativecommons.org/licenses/publicdomain/", "abstract": "  Eudaemonics is the study of the nature, causes, and conditions of human\nwell-being. According to the ethical theory of eudaemonia, reaping satisfaction\nand fulfillment from life is not only a desirable end, but a moral\nresponsibility. However, in modern society, many individuals struggle to meet\nthis responsibility. Computational mechanisms could better enable individuals\nto achieve eudaemonia by yielding practical real-world systems that embody\nalgorithms that promote human flourishing. This article presents eudaemonic\nsystems as the evolutionary goal of the present day recommender system.\n", "versions": [{"version": "v1", "created": "Wed, 1 Apr 2009 16:28:20 GMT"}], "update_date": "2009-05-13", "authors_parsed": [["Rodriguez", "Marko A.", ""], ["Watkins", "Jennifer H.", ""]]}, {"id": "0904.0029", "submitter": "Lakhdar Sais", "authors": "Youssef Hamadi, Said Jabbour, Lakhdar Sais", "title": "Learning for Dynamic subsumption", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper a new dynamic subsumption technique for Boolean CNF formulae is\nproposed. It exploits simple and sufficient conditions to detect during\nconflict analysis, clauses from the original formula that can be reduced by\nsubsumption. During the learnt clause derivation, and at each step of the\nresolution process, we simply check for backward subsumption between the\ncurrent resolvent and clauses from the original formula and encoded in the\nimplication graph. Our approach give rise to a strong and dynamic\nsimplification technique that exploits learning to eliminate literals from the\noriginal clauses. Experimental results show that the integration of our dynamic\nsubsumption approach within the state-of-the-art SAT solvers Minisat and Rsat\nachieves interesting improvements particularly on crafted instances.\n", "versions": [{"version": "v1", "created": "Tue, 31 Mar 2009 23:14:05 GMT"}], "update_date": "2009-04-02", "authors_parsed": [["Hamadi", "Youssef", ""], ["Jabbour", "Said", ""], ["Sais", "Lakhdar", ""]]}, {"id": "0904.0228", "submitter": "Genady Grabarnik", "authors": "Genady Grabarnik, Aaron Kershenbaum (IBM TJ Watson Research)", "title": "Safe Reasoning Over Ontologies", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As ontologies proliferate and automatic reasoners become more powerful, the\nproblem of protecting sensitive information becomes more serious. In\nparticular, as facts can be inferred from other facts, it becomes increasingly\nlikely that information included in an ontology, while not itself deemed\nsensitive, may be able to be used to infer other sensitive information.\n  We first consider the problem of testing an ontology for safeness defined as\nits not being able to be used to derive any sensitive facts using a given\ncollection of inference rules. We then consider the problem of optimizing an\nontology based on the criterion of making as much useful information as\npossible available without revealing any sensitive facts.\n", "versions": [{"version": "v1", "created": "Wed, 1 Apr 2009 18:46:04 GMT"}], "update_date": "2009-04-02", "authors_parsed": [["Grabarnik", "Genady", "", "IBM TJ Watson Research"], ["Kershenbaum", "Aaron", "", "IBM TJ Watson Research"]]}, {"id": "0904.0300", "submitter": "Petar Kormushev", "authors": "Petar Kormushev", "title": "Design, development and implementation of a tool for construction of\n  declarative functional descriptions of semantic web services based on WSMO\n  methodology", "comments": "Master's Thesis in Artificial Intelligence, 105 pages, in Bulgarian.\n  Submitted to Faculty of Mathematics and Informatics, Sofia University, 2005", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Semantic web services (SWS) are self-contained, self-describing, semantically\nmarked-up software resources that can be published, discovered, composed and\nexecuted across the Web in a semi-automatic way. They are a key component of\nthe future Semantic Web, in which networked computer programs become providers\nand users of information at the same time. This work focuses on developing a\nfull-life-cycle software toolset for creating and maintaining Semantic Web\nServices (SWSs) based on the Web Service Modelling Ontology (WSMO) framework. A\nmain part of WSMO-based SWS is service capability - a declarative description\nof Web service functionality. A formal syntax and semantics for such a\ndescription is provided by Web Service Modeling Language (WSML), which is based\non different logical formalisms, namely, Description Logics, First-Order Logic\nand Logic Programming. A WSML description of a Web service capability is\nrepresented as a set of complex logical expressions (axioms). We develop a\nspecialized user-friendly tool for constructing and editing WSMO-based SWS\ncapabilities. Since the users of this tool are not specialists in first-order\nlogic, a graphical way for constricting and editing axioms is proposed. The\ndesigned process for constructing logical expressions is ontology-driven, which\nabstracts away as much as possible from any concrete syntax of logical\nlanguage. We propose several mechanisms to guarantees the semantic consistency\nof the produced logical expressions. The tool is implemented in Java using\nEclipse for IDE and GEF (Graphical Editing Framework) for visualization.\n", "versions": [{"version": "v1", "created": "Thu, 2 Apr 2009 05:34:17 GMT"}], "update_date": "2009-04-03", "authors_parsed": [["Kormushev", "Petar", ""]]}, {"id": "0904.0545", "submitter": "Petar Kormushev", "authors": "Petar Kormushev, Kohei Nomoto, Fangyan Dong, Kaoru Hirota", "title": "Time Hopping technique for faster reinforcement learning in simulations", "comments": "This preprint has been withdrawn by the author for revision", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This preprint has been withdrawn by the author for revision\n", "versions": [{"version": "v1", "created": "Fri, 3 Apr 2009 10:38:06 GMT"}, {"version": "v2", "created": "Tue, 6 Sep 2011 15:24:24 GMT"}], "update_date": "2011-09-07", "authors_parsed": [["Kormushev", "Petar", ""], ["Nomoto", "Kohei", ""], ["Dong", "Fangyan", ""], ["Hirota", "Kaoru", ""]]}, {"id": "0904.0546", "submitter": "Petar Kormushev", "authors": "Petar Kormushev, Kohei Nomoto, Fangyan Dong, Kaoru Hirota", "title": "Eligibility Propagation to Speed up Time Hopping for Reinforcement\n  Learning", "comments": "7 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A mechanism called Eligibility Propagation is proposed to speed up the Time\nHopping technique used for faster Reinforcement Learning in simulations.\nEligibility Propagation provides for Time Hopping similar abilities to what\neligibility traces provide for conventional Reinforcement Learning. It\npropagates values from one state to all of its temporal predecessors using a\nstate transitions graph. Experiments on a simulated biped crawling robot\nconfirm that Eligibility Propagation accelerates the learning process more than\n3 times.\n", "versions": [{"version": "v1", "created": "Fri, 3 Apr 2009 10:42:28 GMT"}], "update_date": "2009-04-06", "authors_parsed": [["Kormushev", "Petar", ""], ["Nomoto", "Kohei", ""], ["Dong", "Fangyan", ""], ["Hirota", "Kaoru", ""]]}, {"id": "0904.0570", "submitter": "Andreas Schnabl", "authors": "Georg Moser (University of Innsbruck), Andreas Schnabl (University of\n  Innsbruck)", "title": "The Derivational Complexity Induced by the Dependency Pair Method", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 7, Issue 3 (July 13,\n  2011) lmcs:805", "doi": "10.2168/LMCS-7(3:1)2011", "report-no": null, "categories": "cs.LO cs.AI cs.CC cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the derivational complexity induced by the dependency pair method,\nenhanced with standard refinements. We obtain upper bounds on the derivational\ncomplexity induced by the dependency pair method in terms of the derivational\ncomplexity of the base techniques employed. In particular we show that the\nderivational complexity induced by the dependency pair method based on some\ndirect technique, possibly refined by argument filtering, the usable rules\ncriterion, or dependency graphs, is primitive recursive in the derivational\ncomplexity induced by the direct method. This implies that the derivational\ncomplexity induced by a standard application of the dependency pair method\nbased on traditional termination orders like KBO, LPO, and MPO is exactly the\nsame as if those orders were applied as the only termination technique.\n", "versions": [{"version": "v1", "created": "Fri, 3 Apr 2009 15:10:50 GMT"}, {"version": "v2", "created": "Fri, 26 Jun 2009 11:33:52 GMT"}, {"version": "v3", "created": "Tue, 21 Sep 2010 08:52:40 GMT"}, {"version": "v4", "created": "Wed, 1 Jun 2011 17:22:27 GMT"}, {"version": "v5", "created": "Mon, 11 Jul 2011 21:10:44 GMT"}], "update_date": "2015-07-01", "authors_parsed": [["Moser", "Georg", "", "University of Innsbruck"], ["Schnabl", "Andreas", "", "University of\n  Innsbruck"]]}, {"id": "0904.0643", "submitter": "David N. Levin", "authors": "David N. Levin (University of Chicago)", "title": "Performing Nonlinear Blind Source Separation with Signal Invariants", "comments": "8 pages, 3 figures", "journal-ref": null, "doi": "10.1109/TSP.2009.2034916", "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a time series of multicomponent measurements x(t), the usual objective\nof nonlinear blind source separation (BSS) is to find a \"source\" time series\ns(t), comprised of statistically independent combinations of the measured\ncomponents. In this paper, the source time series is required to have a density\nfunction in (s,ds/dt)-space that is equal to the product of density functions\nof individual components. This formulation of the BSS problem has a solution\nthat is unique, up to permutations and component-wise transformations.\nSeparability is shown to impose constraints on certain locally invariant\n(scalar) functions of x, which are derived from local higher-order correlations\nof the data's velocity dx/dt. The data are separable if and only if they\nsatisfy these constraints, and, if the constraints are satisfied, the sources\ncan be explicitly constructed from the data. The method is illustrated by using\nit to separate two speech-like sounds recorded with a single microphone.\n", "versions": [{"version": "v1", "created": "Fri, 3 Apr 2009 19:29:47 GMT"}], "update_date": "2015-05-13", "authors_parsed": [["Levin", "David N.", "", "University of Chicago"]]}, {"id": "0904.0721", "submitter": "Linh Anh Nguyen D.Sc.", "authors": "Linh Anh Nguyen and Andrzej Sza{\\l}as", "title": "Optimal Tableau Decision Procedures for PDL", "comments": null, "journal-ref": "Fund. Inform. 104(4), pp. 349-384, 2010", "doi": null, "report-no": null, "categories": "cs.LO cs.AI cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We reformulate Pratt's tableau decision procedure of checking satisfiability\nof a set of formulas in PDL. Our formulation is simpler and more direct for\nimplementation. Extending the method we give the first EXPTIME (optimal)\ntableau decision procedure not based on transformation for checking consistency\nof an ABox w.r.t. a TBox in PDL (here, PDL is treated as a description logic).\nWe also prove the new result that the data complexity of the instance checking\nproblem in PDL is coNP-complete.\n", "versions": [{"version": "v1", "created": "Sat, 4 Apr 2009 15:20:07 GMT"}, {"version": "v2", "created": "Mon, 1 Jun 2009 09:39:45 GMT"}], "update_date": "2011-04-12", "authors_parsed": [["Nguyen", "Linh Anh", ""], ["Sza\u0142as", "Andrzej", ""]]}, {"id": "0904.0981", "submitter": "Martin Avanzini", "authors": "Martin Avanzini and Georg Moser", "title": "Dependency Pairs and Polynomial Path Orders", "comments": "23 pages, conference version accepted at RTA 2009", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI cs.CC cs.SC", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  We show how polynomial path orders can be employed efficiently in conjunction\nwith weak innermost dependency pairs to automatically certify polynomial\nruntime complexity of term rewrite systems and the polytime computability of\nthe functions computed. The established techniques have been implemented and we\nprovide ample experimental data to assess the new method.\n", "versions": [{"version": "v1", "created": "Mon, 6 Apr 2009 18:10:53 GMT"}, {"version": "v2", "created": "Mon, 22 Jun 2009 14:44:02 GMT"}, {"version": "v3", "created": "Wed, 8 Jun 2011 07:03:03 GMT"}], "update_date": "2011-06-09", "authors_parsed": [["Avanzini", "Martin", ""], ["Moser", "Georg", ""]]}, {"id": "0904.1258", "submitter": "Jinzhong Niu", "authors": "Jinzhong Niu, Simon Parsons", "title": "An Investigation Report on Auction Mechanism Design", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Auctions are markets with strict regulations governing the information\navailable to traders in the market and the possible actions they can take.\nSince well designed auctions achieve desirable economic outcomes, they have\nbeen widely used in solving real-world optimization problems, and in\nstructuring stock or futures exchanges. Auctions also provide a very valuable\ntesting-ground for economic theory, and they play an important role in\ncomputer-based control systems.\n  Auction mechanism design aims to manipulate the rules of an auction in order\nto achieve specific goals. Economists traditionally use mathematical methods,\nmainly game theory, to analyze auctions and design new auction forms. However,\ndue to the high complexity of auctions, the mathematical models are typically\nsimplified to obtain results, and this makes it difficult to apply results\nderived from such models to market environments in the real world. As a result,\nresearchers are turning to empirical approaches.\n  This report aims to survey the theoretical and empirical approaches to\ndesigning auction mechanisms and trading strategies with more weights on\nempirical ones, and build the foundation for further research in the field.\n", "versions": [{"version": "v1", "created": "Wed, 8 Apr 2009 03:41:39 GMT"}, {"version": "v2", "created": "Tue, 14 Apr 2009 00:14:53 GMT"}], "update_date": "2009-04-14", "authors_parsed": [["Niu", "Jinzhong", ""], ["Parsons", "Simon", ""]]}, {"id": "0904.1579", "submitter": "Fedor Zhdanov", "authors": "Fedor Zhdanov, Vladimir Vovk, Brian Burford, Dmitry Devetyarov, Ilia\n  Nouretdinov and Alex Gammerman", "title": "Online prediction of ovarian cancer", "comments": "11 pages, 4 figures, uses llncs.cls", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we apply computer learning methods to diagnosing ovarian cancer\nusing the level of the standard biomarker CA125 in conjunction with information\nprovided by mass-spectrometry. We are working with a new data set collected\nover a period of 7 years. Using the level of CA125 and mass-spectrometry peaks,\nour algorithm gives probability predictions for the disease. To estimate\nclassification accuracy we convert probability predictions into strict\npredictions. Our algorithm makes fewer errors than almost any linear\ncombination of the CA125 level and one peak's intensity (taken on the log\nscale). To check the power of our algorithm we use it to test the hypothesis\nthat CA125 and the peaks do not contain useful information for the prediction\nof the disease at a particular time before the diagnosis. Our algorithm\nproduces $p$-values that are better than those produced by the algorithm that\nhas been previously applied to this data set. Our conclusion is that the\nproposed algorithm is more reliable for prediction on new data.\n", "versions": [{"version": "v1", "created": "Thu, 9 Apr 2009 18:26:36 GMT"}], "update_date": "2009-04-10", "authors_parsed": [["Zhdanov", "Fedor", ""], ["Vovk", "Vladimir", ""], ["Burford", "Brian", ""], ["Devetyarov", "Dmitry", ""], ["Nouretdinov", "Ilia", ""], ["Gammerman", "Alex", ""]]}, {"id": "0904.1629", "submitter": "Petar Kormushev", "authors": "Yoichi Yamazaki, Fangyan Dong, Yuta Masuda, Yukiko Uehara, Petar\n  Kormushev, Hai An Vu, Phuc Quang Le, Kaoru Hirota", "title": "Fuzzy inference based mentality estimation for eye robot agent", "comments": "2 pages, in Japanese", "journal-ref": "Proceedings of 23rd Fuzzy System Symposium (FSS 2007), pp.\n  387-388, 2007", "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Household robots need to communicate with human beings in a friendly fashion.\nTo achieve better understanding of displayed information, an importance and a\ncertainty of the information should be communicated together with the main\ninformation. The proposed intent expression system aims to convey this\nadditional information using an eye robot. The eye motions are represented as\nstates in a pleasure-arousal space model. Change of the model state is\ncalculated by fuzzy inference according to the importance and certainty of the\ndisplayed information. This change influences the arousal-sleep coordinate in\nthe space which corresponds to activeness in communication. The eye robot\nprovides a basic interface for the mascot robot system which is an easy to\nunderstand information terminal for home environments in a humatronics society.\n", "versions": [{"version": "v1", "created": "Fri, 10 Apr 2009 03:17:39 GMT"}], "update_date": "2009-04-13", "authors_parsed": [["Yamazaki", "Yoichi", ""], ["Dong", "Fangyan", ""], ["Masuda", "Yuta", ""], ["Uehara", "Yukiko", ""], ["Kormushev", "Petar", ""], ["Vu", "Hai An", ""], ["Le", "Phuc Quang", ""], ["Hirota", "Kaoru", ""]]}, {"id": "0904.1631", "submitter": "Petar Kormushev", "authors": "Yoichi Yamazaki, Fangyan Dong, Yuta Masuda, Yukiko Uehara, Petar\n  Kormushev, Hai An Vu, Phuc Quang Le, Kaoru Hirota", "title": "Intent expression using eye robot for mascot robot system", "comments": "5 pages", "journal-ref": "8th International Symposium on Advanced Intelligent Systems\n  (ISIS2007), pp. 576-580, 2007", "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An intent expression system using eye robots is proposed for a mascot robot\nsystem from a viewpoint of humatronics. The eye robot aims at providing a basic\ninterface method for an information terminal robot system. To achieve better\nunderstanding of the displayed information, the importance and the degree of\ncertainty of the information should be communicated along with the main\ncontent. The proposed intent expression system aims at conveying this\nadditional information using the eye robot system. Eye motions are represented\nas the states in a pleasure-arousal space model. Changes in the model state are\ncalculated by fuzzy inference according to the importance and degree of\ncertainty of the displayed information. These changes influence the\narousal-sleep coordinates in the space that corresponds to levels of liveliness\nduring communication. The eye robot provides a basic interface for the mascot\nrobot system that is easy to be understood as an information terminal for home\nenvironments in a humatronics society.\n", "versions": [{"version": "v1", "created": "Fri, 10 Apr 2009 03:35:33 GMT"}], "update_date": "2009-04-13", "authors_parsed": [["Yamazaki", "Yoichi", ""], ["Dong", "Fangyan", ""], ["Masuda", "Yuta", ""], ["Uehara", "Yukiko", ""], ["Kormushev", "Petar", ""], ["Vu", "Hai An", ""], ["Le", "Phuc Quang", ""], ["Hirota", "Kaoru", ""]]}, {"id": "0904.1672", "submitter": "Joost Vennekens", "authors": "Joost Vennekens, Marc Denecker, Maurice Bruynooghe", "title": "CP-logic: A Language of Causal Probabilistic Events and Its Relation to\n  Logic Programming", "comments": "To be published in Theory and Practice of Logic Programming (TPLP)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This papers develops a logical language for representing probabilistic causal\nlaws. Our interest in such a language is twofold. First, it can be motivated as\na fundamental study of the representation of causal knowledge. Causality has an\ninherent dynamic aspect, which has been studied at the semantical level by\nShafer in his framework of probability trees. In such a dynamic context, where\nthe evolution of a domain over time is considered, the idea of a causal law as\nsomething which guides this evolution is quite natural. In our formalization, a\nset of probabilistic causal laws can be used to represent a class of\nprobability trees in a concise, flexible and modular way. In this way, our work\nextends Shafer's by offering a convenient logical representation for his\nsemantical objects.\n  Second, this language also has relevance for the area of probabilistic logic\nprogramming. In particular, we prove that the formal semantics of a theory in\nour language can be equivalently defined as a probability distribution over the\nwell-founded models of certain logic programs, rendering it formally quite\nsimilar to existing languages such as ICL or PRISM. Because we can motivate and\nexplain our language in a completely self-contained way as a representation of\nprobabilistic causal laws, this provides a new way of explaining the intuitions\nbehind such probabilistic logic programs: we can say precisely which knowledge\nsuch a program expresses, in terms that are equally understandable by a\nnon-logician. Moreover, we also obtain an additional piece of knowledge\nrepresentation methodology for probabilistic logic programs, by showing how\nthey can express probabilistic causal laws.\n", "versions": [{"version": "v1", "created": "Fri, 10 Apr 2009 10:00:55 GMT"}], "update_date": "2009-04-13", "authors_parsed": [["Vennekens", "Joost", ""], ["Denecker", "Marc", ""], ["Bruynooghe", "Maurice", ""]]}, {"id": "0904.1931", "submitter": "Byron Gao", "authors": "Obi L. Griffith, Byron J. Gao, Mikhail Bilenky, Yuliya Prichyna,\n  Martin Ester, Steven J.M. Jones", "title": "KiWi: A Scalable Subspace Clustering Algorithm for Gene Expression\n  Analysis", "comments": "International Conference on Bioinformatics and Biomedical Engineering\n  (iCBBE), 2009", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.AI q-bio.GN", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Subspace clustering has gained increasing popularity in the analysis of gene\nexpression data. Among subspace cluster models, the recently introduced\norder-preserving sub-matrix (OPSM) has demonstrated high promise. An OPSM,\nessentially a pattern-based subspace cluster, is a subset of rows and columns\nin a data matrix for which all the rows induce the same linear ordering of\ncolumns. Existing OPSM discovery methods do not scale well to increasingly\nlarge expression datasets. In particular, twig clusters having few genes and\nmany experiments incur explosive computational costs and are completely pruned\noff by existing methods. However, it is of particular interest to determine\nsmall groups of genes that are tightly coregulated across many conditions. In\nthis paper, we present KiWi, an OPSM subspace clustering algorithm that is\nscalable to massive datasets, capable of discovering twig clusters and\nidentifying negative as well as positive correlations. We extensively validate\nKiWi using relevant biological datasets and show that KiWi correctly assigns\nredundant probes to the same cluster, groups experiments with common clinical\nannotations, differentiates real promoter sequences from negative control\nsequences, and shows good association with cis-regulatory motif predictions.\n", "versions": [{"version": "v1", "created": "Mon, 13 Apr 2009 08:16:53 GMT"}], "update_date": "2009-04-14", "authors_parsed": [["Griffith", "Obi L.", ""], ["Gao", "Byron J.", ""], ["Bilenky", "Mikhail", ""], ["Prichyna", "Yuliya", ""], ["Ester", "Martin", ""], ["Jones", "Steven J. M.", ""]]}, {"id": "0904.2595", "submitter": "Mark Levene", "authors": "Mark Levene and Trevor Fenner", "title": "A Methodology for Learning Players' Styles from Game Records", "comments": "15 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe a preliminary investigation into learning a Chess player's style\nfrom game records. The method is based on attempting to learn features of a\nplayer's individual evaluation function using the method of temporal\ndifferences, with the aid of a conventional Chess engine architecture. Some\nencouraging results were obtained in learning the styles of two recent Chess\nworld champions, and we report on our attempt to use the learnt styles to\ndiscriminate between the players from game records by trying to detect who was\nplaying white and who was playing black. We also discuss some limitations of\nour approach and propose possible directions for future research. The method we\nhave presented may also be applicable to other strategic games, and may even be\ngeneralisable to other domains where sequences of agents' actions are recorded.\n", "versions": [{"version": "v1", "created": "Thu, 16 Apr 2009 21:30:30 GMT"}], "update_date": "2009-04-20", "authors_parsed": [["Levene", "Mark", ""], ["Fenner", "Trevor", ""]]}, {"id": "0904.2623", "submitter": "James Petterson", "authors": "James Petterson, Tiberio Caetano, Julian McAuley, Jin Yu", "title": "Exponential Family Graph Matching and Ranking", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a method for learning max-weight matching predictors in bipartite\ngraphs. The method consists of performing maximum a posteriori estimation in\nexponential families with sufficient statistics that encode permutations and\ndata features. Although inference is in general hard, we show that for one very\nrelevant application - web page ranking - exact inference is efficient. For\ngeneral model instances, an appropriate sampler is readily available. Contrary\nto existing max-margin matching models, our approach is statistically\nconsistent and, in addition, experiments with increasing sample sizes indicate\nsuperior improvement over such models. We apply the method to graph matching in\ncomputer vision as well as to a standard benchmark dataset for learning web\npage ranking, in which we obtain state-of-the-art results, in particular\nimproving on max-margin variants. The drawback of this method with respect to\nmax-margin alternatives is its runtime for large graphs, which is comparatively\nhigh.\n", "versions": [{"version": "v1", "created": "Fri, 17 Apr 2009 03:48:02 GMT"}, {"version": "v2", "created": "Fri, 5 Jun 2009 03:54:58 GMT"}], "update_date": "2009-06-05", "authors_parsed": [["Petterson", "James", ""], ["Caetano", "Tiberio", ""], ["McAuley", "Julian", ""], ["Yu", "Jin", ""]]}, {"id": "0904.2827", "submitter": "Elena Wishnevskaya S.", "authors": "Elena S. Vishnevksaya", "title": "Principle of development", "comments": "This paper has been withdrawn by the author", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Today, science have a powerful tool for the description of reality - the\nnumbers. However, the concept of number was not immediately, lets try to trace\nthe evolution of the concept. The numbers emerged as the need for accurate\nestimates of the amount in order to permit a comparison of some objects. So if\nyou see to it how many times a day a person uses the numbers and compare, it\nbecomes evident that the comparison is used much more frequently. However, the\ncomparison is not possible without two opposite basic standards. Thus, to\nintroduce the concept of comparison, must have two opposing standards, in turn,\nthe operation of comparison is necessary to introduce the concept of number.\nArguably, the scientific description of reality is impossible without the\nconcept of opposites.\n  In this paper analyzes the concept of opposites, as the basis for the\nintroduction of the principle of development.\n", "versions": [{"version": "v1", "created": "Sat, 18 Apr 2009 10:49:05 GMT"}, {"version": "v2", "created": "Tue, 21 Apr 2009 09:49:52 GMT"}, {"version": "v3", "created": "Mon, 16 May 2011 08:12:00 GMT"}, {"version": "v4", "created": "Wed, 12 Oct 2011 03:02:38 GMT"}, {"version": "v5", "created": "Thu, 13 Oct 2011 08:13:19 GMT"}], "update_date": "2011-10-14", "authors_parsed": [["Vishnevksaya", "Elena S.", ""]]}, {"id": "0904.2953", "submitter": "Fahem Kebair", "authors": "Fahem Kebair and Frederic Serin", "title": "Towards an Intelligent System for Risk Prevention and Management", "comments": "11 pages", "journal-ref": "Proceedings of the 5th International ISCRAM Conference. 526-535,\n  Washington, DC, USA May 2008", "doi": null, "report-no": null, "categories": "cs.AI cs.MA", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  Making a decision in a changeable and dynamic environment is an arduous task\nowing to the lack of information, their uncertainties and the unawareness of\nplanners about the future evolution of incidents. The use of a decision support\nsystem is an efficient solution of this issue. Such a system can help emergency\nplanners and responders to detect possible emergencies, as well as to suggest\nand evaluate possible courses of action to deal with the emergency. We are\ninterested in our work to the modeling of a monitoring preventive and emergency\nmanagement system, wherein we stress the generic aspect. In this paper we\npropose an agent-based architecture of this system and we describe a first step\nof our approach which is the modeling of information and their representation\nusing a multiagent system.\n", "versions": [{"version": "v1", "created": "Mon, 20 Apr 2009 07:02:54 GMT"}], "update_date": "2009-04-21", "authors_parsed": [["Kebair", "Fahem", ""], ["Serin", "Frederic", ""]]}, {"id": "0904.2954", "submitter": "Fahem Kebair", "authors": "Fahem Kebair and Frederic Serin", "title": "Agent-Based Decision Support System to Prevent and Manage Risk\n  Situations", "comments": "5 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.MA", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  The topic of risk prevention and emergency response has become a key social\nand political concern. One approach to address this challenge is to develop\nDecision Support Systems (DSS) that can help emergency planners and responders\nto detect emergencies, as well as to suggest possible course of actions to deal\nwith the emergency. Our research work comes in this framework and aims to\ndevelop a DSS that must be generic as much as possible and independent from the\ncase study.\n", "versions": [{"version": "v1", "created": "Mon, 20 Apr 2009 07:12:01 GMT"}], "update_date": "2009-04-21", "authors_parsed": [["Kebair", "Fahem", ""], ["Serin", "Frederic", ""]]}, {"id": "0904.3310", "submitter": "Shariq Bashir Mr.", "authors": "Shariq Bashir, Abdul Rauf Baig", "title": "FastLMFI: An Efficient Approach for Local Maximal Patterns Propagation\n  and Maximal Patterns Superset Checking", "comments": "8 Pages, In the proceedings of 4th ACS/IEEE International Conference\n  on Computer Systems and Applications 2006, March 8, 2006, Dubai/Sharjah, UAE,\n  2006, Page(s) 452-459", "journal-ref": null, "doi": "10.1109/AICCSA.2006.205130", "report-no": null, "categories": "cs.DB cs.AI cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Maximal frequent patterns superset checking plays an important role in the\nefficient mining of complete Maximal Frequent Itemsets (MFI) and maximal search\nspace pruning. In this paper we present a new indexing approach, FastLMFI for\nlocal maximal frequent patterns (itemset) propagation and maximal patterns\nsuperset checking. Experimental results on different sparse and dense datasets\nshow that our work is better than the previous well known progressive focusing\ntechnique. We have also integrated our superset checking approach with an\nexisting state of the art maximal itemsets algorithm Mafia, and compare our\nresults with current best maximal itemsets algorithms afopt-max and FP\n(zhu)-max. Our results outperform afopt-max and FP (zhu)-max on dense (chess\nand mushroom) datasets on almost all support thresholds, which shows the\neffectiveness of our approach.\n", "versions": [{"version": "v1", "created": "Tue, 21 Apr 2009 18:33:04 GMT"}], "update_date": "2016-11-17", "authors_parsed": [["Bashir", "Shariq", ""], ["Baig", "Abdul Rauf", ""]]}, {"id": "0904.3312", "submitter": "Shariq Bashir Mr.", "authors": "Shariq Bashir, and Abdul Rauf Baig", "title": "HybridMiner: Mining Maximal Frequent Itemsets Using Hybrid Database\n  Representation Approach", "comments": "8 Pages In the proceedings of 9th IEEE-INMIC 2005, Karachi, Pakistan,\n  2005", "journal-ref": null, "doi": "10.1109/INMIC.2005.334484", "report-no": null, "categories": "cs.DB cs.AI cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we present a novel hybrid (arraybased layout and vertical\nbitmap layout) database representation approach for mining complete Maximal\nFrequent Itemset (MFI) on sparse and large datasets. Our work is novel in terms\nof scalability, item search order and two horizontal and vertical projection\ntechniques. We also present a maximal algorithm using this hybrid database\nrepresentation approach. Different experimental results on real and sparse\nbenchmark datasets show that our approach is better than previous state of art\nmaximal algorithms.\n", "versions": [{"version": "v1", "created": "Tue, 21 Apr 2009 18:38:25 GMT"}], "update_date": "2016-11-17", "authors_parsed": [["Bashir", "Shariq", ""], ["Baig", "Abdul Rauf", ""]]}, {"id": "0904.3316", "submitter": "Shariq Bashir Mr.", "authors": "Shariq Bashir, and Abdul Rauf Baig", "title": "Ramp: Fast Frequent Itemset Mining with Efficient Bit-Vector Projection\n  Technique", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.AI cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mining frequent itemset using bit-vector representation approach is very\nefficient for dense type datasets, but highly inefficient for sparse datasets\ndue to lack of any efficient bit-vector projection technique. In this paper we\npresent a novel efficient bit-vector projection technique, for sparse and dense\ndatasets. To check the efficiency of our bit-vector projection technique, we\npresent a new frequent itemset mining algorithm Ramp (Real Algorithm for Mining\nPatterns) build upon our bit-vector projection technique. The performance of\nthe Ramp is compared with the current best (all, maximal and closed) frequent\nitemset mining algorithms on benchmark datasets. Different experimental results\non sparse and dense datasets show that mining frequent itemset using Ramp is\nfaster than the current best algorithms, which show the effectiveness of our\nbit-vector projection idea. We also present a new local maximal frequent\nitemsets propagation and maximal itemset superset checking approach FastLMFI,\nbuild upon our PBR bit-vector projection technique. Our different computational\nexperiments suggest that itemset maximality checking using FastLMFI is fast and\nefficient than a previous will known progressive focusing approach.\n", "versions": [{"version": "v1", "created": "Tue, 21 Apr 2009 18:49:13 GMT"}], "update_date": "2009-04-22", "authors_parsed": [["Bashir", "Shariq", ""], ["Baig", "Abdul Rauf", ""]]}, {"id": "0904.3319", "submitter": "Shariq Bashir Mr.", "authors": "Shariq Bashir, Zahoor Jan, Abdul Rauf Baig", "title": "Fast Algorithms for Mining Interesting Frequent Itemsets without Minimum\n  Support", "comments": "25 Pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.AI cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Real world datasets are sparse, dirty and contain hundreds of items. In such\nsituations, discovering interesting rules (results) using traditional frequent\nitemset mining approach by specifying a user defined input support threshold is\nnot appropriate. Since without any domain knowledge, setting support threshold\nsmall or large can output nothing or a large number of redundant uninteresting\nresults. Recently a novel approach of mining only N-most/Top-K interesting\nfrequent itemsets has been proposed, which discovers the top N interesting\nresults without specifying any user defined support threshold. However, mining\ninteresting frequent itemsets without minimum support threshold are more costly\nin terms of itemset search space exploration and processing cost. Thereby, the\nefficiency of their mining highly depends upon three main factors (1) Database\nrepresentation approach used for itemset frequency counting, (2) Projection of\nrelevant transactions to lower level nodes of search space and (3) Algorithm\nimplementation technique. Therefore, to improve the efficiency of mining\nprocess, in this paper we present two novel algorithms called (N-MostMiner and\nTop-K-Miner) using the bit-vector representation approach which is very\nefficient in terms of itemset frequency counting and transactions projection.\nIn addition to this, several efficient implementation techniques of N-MostMiner\nand Top-K-Miner are also present which we experienced in our implementation.\nOur experimental results on benchmark datasets suggest that the NMostMiner and\nTop-K-Miner are very efficient in terms of processing time as compared to\ncurrent best algorithms BOMO and TFP.\n", "versions": [{"version": "v1", "created": "Tue, 21 Apr 2009 19:07:35 GMT"}], "update_date": "2009-04-22", "authors_parsed": [["Bashir", "Shariq", ""], ["Jan", "Zahoor", ""], ["Baig", "Abdul Rauf", ""]]}, {"id": "0904.3320", "submitter": "Shariq Bashir Mr.", "authors": "Shariq Bashir, Saad Razzaq, Umer Maqbool, Sonya Tahir, Abdul Rauf Baig", "title": "Using Association Rules for Better Treatment of Missing Values", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.AI cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The quality of training data for knowledge discovery in databases (KDD) and\ndata mining depends upon many factors, but handling missing values is\nconsidered to be a crucial factor in overall data quality. Today real world\ndatasets contains missing values due to human, operational error, hardware\nmalfunctioning and many other factors. The quality of knowledge extracted,\nlearning and decision problems depend directly upon the quality of training\ndata. By considering the importance of handling missing values in KDD and data\nmining tasks, in this paper we propose a novel Hybrid Missing values Imputation\nTechnique (HMiT) using association rules mining and hybrid combination of\nk-nearest neighbor approach. To check the effectiveness of our HMiT missing\nvalues imputation technique, we also perform detail experimental results on\nreal world datasets. Our results suggest that the HMiT technique is not only\nbetter in term of accuracy but it also take less processing time as compared to\ncurrent best missing values imputation technique based on k-nearest neighbor\napproach, which shows the effectiveness of our missing values imputation\ntechnique.\n", "versions": [{"version": "v1", "created": "Tue, 21 Apr 2009 19:09:57 GMT"}], "update_date": "2009-04-22", "authors_parsed": [["Bashir", "Shariq", ""], ["Razzaq", "Saad", ""], ["Maqbool", "Umer", ""], ["Tahir", "Sonya", ""], ["Baig", "Abdul Rauf", ""]]}, {"id": "0904.3321", "submitter": "Shariq Bashir Mr.", "authors": "Shariq Bashir, Saad Razzaq, Umer Maqbool, Sonya Tahir, Abdul Rauf Baig", "title": "Introducing Partial Matching Approach in Association Rules for Better\n  Treatment of Missing Values", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.AI cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Handling missing values in training datasets for constructing learning models\nor extracting useful information is considered to be an important research task\nin data mining and knowledge discovery in databases. In recent years, lot of\ntechniques are proposed for imputing missing values by considering attribute\nrelationships with missing value observation and other observations of training\ndataset. The main deficiency of such techniques is that, they depend upon\nsingle approach and do not combine multiple approaches, that why they are less\naccurate. To improve the accuracy of missing values imputation, in this paper\nwe introduce a novel partial matching concept in association rules mining,\nwhich shows better results as compared to full matching concept that we\ndescribed in our previous work. Our imputation technique combines the partial\nmatching concept in association rules with k-nearest neighbor approach. Since\nthis is a hybrid technique, therefore its accuracy is much better than as\ncompared to those techniques which depend upon single approach. To check the\nefficiency of our technique, we also provide detail experimental results on\nnumber of benchmark datasets which show better results as compared to previous\napproaches.\n", "versions": [{"version": "v1", "created": "Tue, 21 Apr 2009 19:16:00 GMT"}], "update_date": "2009-04-22", "authors_parsed": [["Bashir", "Shariq", ""], ["Razzaq", "Saad", ""], ["Maqbool", "Umer", ""], ["Tahir", "Sonya", ""], ["Baig", "Abdul Rauf", ""]]}, {"id": "0904.3352", "submitter": "Istvan Szita", "authors": "Istvan Szita, Andras Lorincz", "title": "Optimistic Initialization and Greediness Lead to Polynomial Time\n  Learning in Factored MDPs - Extended Version", "comments": "This paper is the extended version of a similarly named paper\n  appearing in ICML'09, containing the rigorous proofs of the main theorem", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we propose an algorithm for polynomial-time reinforcement\nlearning in factored Markov decision processes (FMDPs). The factored optimistic\ninitial model (FOIM) algorithm, maintains an empirical model of the FMDP in a\nconventional way, and always follows a greedy policy with respect to its model.\nThe only trick of the algorithm is that the model is initialized\noptimistically. We prove that with suitable initialization (i) FOIM converges\nto the fixed point of approximate value iteration (AVI); (ii) the number of\nsteps when the agent makes non-near-optimal decisions (with respect to the\nsolution of AVI) is polynomial in all relevant quantities; (iii) the per-step\ncosts of the algorithm are also polynomial. To our best knowledge, FOIM is the\nfirst algorithm with these properties. This extended version contains the\nrigorous proofs of the main theorem. A version of this paper appeared in\nICML'09.\n", "versions": [{"version": "v1", "created": "Tue, 21 Apr 2009 22:07:24 GMT"}], "update_date": "2009-04-23", "authors_parsed": [["Szita", "Istvan", ""], ["Lorincz", "Andras", ""]]}, {"id": "0904.3356", "submitter": "Yoav Freund", "authors": "Yoav Freund", "title": "A method for Hedging in continuous time", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.AI math.IT math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a method for hedging in continuous time.\n", "versions": [{"version": "v1", "created": "Tue, 21 Apr 2009 22:34:08 GMT"}, {"version": "v2", "created": "Fri, 24 Apr 2009 17:07:14 GMT"}, {"version": "v3", "created": "Wed, 14 Oct 2009 00:04:59 GMT"}], "update_date": "2009-10-14", "authors_parsed": [["Freund", "Yoav", ""]]}, {"id": "0904.3469", "submitter": "Giorgi Japaridze", "authors": "Giorgi Japaridze", "title": "Toggling operators in computability logic", "comments": null, "journal-ref": "Theoretical Computer Science 412 (2011), pp. 971-1004", "doi": "10.1016/j.tcs.2010.11.037", "report-no": null, "categories": "cs.LO cs.AI math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computability logic (CL) (see http://www.cis.upenn.edu/~giorgi/cl.html ) is a\nresearch program for redeveloping logic as a formal theory of computability, as\nopposed to the formal theory of truth which it has more traditionally been.\nFormulas in CL stand for interactive computational problems, seen as games\nbetween a machine and its environment; logical operators represent operations\non such entities; and \"truth\" is understood as existence of an effective\nsolution. The formalism of CL is open-ended, and may undergo series of\nextensions as the studies of the subject advance. So far three -- parallel,\nsequential and choice -- sorts of conjunction and disjunction have been\nstudied. The present paper adds one more natural kind to this collection,\ntermed toggling. The toggling operations can be characterized as lenient\nversions of choice operations where choices are retractable, being allowed to\nbe reconsidered any finite number of times. This way, they model\ntrial-and-error style decision steps in interactive computation. The main\ntechnical result of this paper is constructing a sound and complete\naxiomatization for the propositional fragment of computability logic whose\nvocabulary, together with negation, includes all four -- parallel, toggling,\nsequential and choice -- kinds of conjunction and disjunction. Along with\ntoggling conjunction and disjunction, the paper also introduces the toggling\nversions of quantifiers and recurrence operations.\n", "versions": [{"version": "v1", "created": "Wed, 22 Apr 2009 14:32:01 GMT"}, {"version": "v2", "created": "Sat, 1 May 2010 21:40:22 GMT"}], "update_date": "2011-02-08", "authors_parsed": [["Japaridze", "Giorgi", ""]]}, {"id": "0904.3612", "submitter": "Martin Ziegler", "authors": "Florentin Neumann, Andrea Reichenberger, Martin Ziegler", "title": "Variations of the Turing Test in the Age of Internet and Virtual Reality", "comments": null, "journal-ref": "pp.355-362 in Proc. 32nd Annual Conference on Artificial\n  Intelligence (KI2009), Springer LNCS/LNAI vol.5803", "doi": "10.1007/978-3-642-04617-9_45", "report-no": null, "categories": "cs.AI cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inspired by Hofstadter's Coffee-House Conversation (1982) and by the science\nfiction short story SAM by Schattschneider (1988), we propose and discuss\ncriteria for non-mechanical intelligence. Firstly, we emphasize the practical\nneed for such tests in view of massively multiuser online role-playing games\n(MMORPGs) and virtual reality systems like Second Life. Secondly, we\ndemonstrate Second Life as a useful framework for implementing (some iterations\nof) that test.\n", "versions": [{"version": "v1", "created": "Thu, 23 Apr 2009 07:56:11 GMT"}], "update_date": "2010-05-10", "authors_parsed": [["Neumann", "Florentin", ""], ["Reichenberger", "Andrea", ""], ["Ziegler", "Martin", ""]]}, {"id": "0904.3667", "submitter": "Florentina Pintea", "authors": "Alin Munteanu, Cristina Ofelia Sofran", "title": "Considerations upon the Machine Learning Technologies", "comments": "6 pages,exposed on 1st \"European Conference on Computer Sciences &\n  Applications\" - XA2006, Timisoara, Romania", "journal-ref": "Ann. Univ. Tibiscus Comp. Sci. Series IV (2006), 133-138", "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Artificial intelligence offers superior techniques and methods by which\nproblems from diverse domains may find an optimal solution. The Machine\nLearning technologies refer to the domain of artificial intelligence aiming to\ndevelop the techniques allowing the computers to \"learn\". Some systems based on\nMachine Learning technologies tend to eliminate the necessity of the human\nintelligence while the others adopt a man-machine collaborative approach.\n", "versions": [{"version": "v1", "created": "Thu, 23 Apr 2009 11:48:38 GMT"}], "update_date": "2009-04-24", "authors_parsed": [["Munteanu", "Alin", ""], ["Sofran", "Cristina Ofelia", ""]]}, {"id": "0904.3701", "submitter": "Fabien Gandon", "authors": "Guillaume Er\\'et\\'eo (INRIA Sophia Antipolis), Fabien Gandon (INRIA\n  Sophia Antipolis), Olivier Corby (INRIA Sophia Antipolis), Michel Buffa", "title": "Semantic Social Network Analysis", "comments": "published in Web Science (2009)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Social Network Analysis (SNA) tries to understand and exploit the key\nfeatures of social networks in order to manage their life cycle and predict\ntheir evolution. Increasingly popular web 2.0 sites are forming huge social\nnetwork. Classical methods from social network analysis (SNA) have been applied\nto such online networks. In this paper, we propose leveraging semantic web\ntechnologies to merge and exploit the best features of each domain. We present\nhow to facilitate and enhance the analysis of online social networks,\nexploiting the power of semantic social network analysis.\n", "versions": [{"version": "v1", "created": "Thu, 23 Apr 2009 14:22:05 GMT"}], "update_date": "2009-04-24", "authors_parsed": [["Er\u00e9t\u00e9o", "Guillaume", "", "INRIA Sophia Antipolis"], ["Gandon", "Fabien", "", "INRIA\n  Sophia Antipolis"], ["Corby", "Olivier", "", "INRIA Sophia Antipolis"], ["Buffa", "Michel", ""]]}, {"id": "0904.3808", "submitter": "Forrest Sheng Bao", "authors": "Forrest Sheng Bao, Jue-Ming Gao, Jing Hu, Donald Y.-C. Lie, Yuanlin\n  Zhang and K. J. Oommen", "title": "Automated Epilepsy Diagnosis Using Interictal Scalp EEG", "comments": "5 pages, 4 figures, 3 tables, based on our IEEE ICTAI'08 paper,\n  submitted to IEEE EMBC'09", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CV", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  Approximately over 50 million people worldwide suffer from epilepsy.\nTraditional diagnosis of epilepsy relies on tedious visual screening by highly\ntrained clinicians from lengthy EEG recording that contains the presence of\nseizure (ictal) activities. Nowadays, there are many automatic systems that can\nrecognize seizure-related EEG signals to help the diagnosis. However, it is\nvery costly and inconvenient to obtain long-term EEG data with seizure\nactivities, especially in areas short of medical resources. We demonstrate in\nthis paper that we can use the interictal scalp EEG data, which is much easier\nto collect than the ictal data, to automatically diagnose whether a person is\nepileptic. In our automated EEG recognition system, we extract three classes of\nfeatures from the EEG data and build Probabilistic Neural Networks (PNNs) fed\nwith these features. We optimize the feature extraction parameters and combine\nthese PNNs through a voting mechanism. As a result, our system achieves an\nimpressive 94.07% accuracy, which is very close to reported human recognition\naccuracy by experienced medical professionals.\n", "versions": [{"version": "v1", "created": "Fri, 24 Apr 2009 07:15:49 GMT"}, {"version": "v2", "created": "Fri, 24 Apr 2009 20:27:43 GMT"}], "update_date": "2009-04-27", "authors_parsed": [["Bao", "Forrest Sheng", ""], ["Gao", "Jue-Ming", ""], ["Hu", "Jing", ""], ["Lie", "Donald Y. -C.", ""], ["Zhang", "Yuanlin", ""], ["Oommen", "K. J.", ""]]}, {"id": "0904.3953", "submitter": "Victor Marek", "authors": "V.W. Marek and J.B. Remmel", "title": "Guarded resolution for answer set programming", "comments": "13 pages, some results added. Accepted for publication at TPLP", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe a variant of resolution rule of proof and show that it is\ncomplete for stable semantics of logic programs. We show applications of this\nresult.\n", "versions": [{"version": "v1", "created": "Sat, 25 Apr 2009 00:28:07 GMT"}, {"version": "v2", "created": "Sat, 2 May 2009 10:34:13 GMT"}, {"version": "v3", "created": "Sat, 14 Nov 2009 22:59:07 GMT"}, {"version": "v4", "created": "Sun, 21 Feb 2010 17:57:51 GMT"}], "update_date": "2010-02-21", "authors_parsed": [["Marek", "V. W.", ""], ["Remmel", "J. B.", ""]]}, {"id": "0904.4587", "submitter": "Juan-Manuel Torres-Moreno", "authors": "Juan-Manuel Torres-Moreno and Mirta B. Gordon", "title": "Adaptive Learning with Binary Neurons", "comments": "29 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A efficient incremental learning algorithm for classification tasks, called\nNetLines, well adapted for both binary and real-valued input patterns is\npresented. It generates small compact feedforward neural networks with one\nhidden layer of binary units and binary output units. A convergence theorem\nensures that solutions with a finite number of hidden units exist for both\nbinary and real-valued input patterns. An implementation for problems with more\nthan two classes, valid for any binary classifier, is proposed. The\ngeneralization error and the size of the resulting networks are compared to the\nbest published results on well-known classification benchmarks. Early stopping\nis shown to decrease overfitting, without improving the generalization\nperformance.\n", "versions": [{"version": "v1", "created": "Wed, 29 Apr 2009 11:49:45 GMT"}], "update_date": "2009-04-30", "authors_parsed": [["Torres-Moreno", "Juan-Manuel", ""], ["Gordon", "Mirta B.", ""]]}, {"id": "0904.4708", "submitter": "George Tsatsaronis", "authors": "George Tsatsaronis, Maria Halkidi, Emmanouel A. Giakoumakis", "title": "Quality Classifiers for Open Source Software Repositories", "comments": "10 pages, 2 Tables, 7 equations, 13 references. Appeared in 2nd\n  Artificial Intelligence Techniques in Software Engineering Workshop, AIAI\n  2009", "journal-ref": "2nd Artificial Intelligence Techniques in Software Engineering\n  Workshop, 5th IFIP Conference on Artificial Intelligence Applications and\n  Innovations, April 23-25, 2009, Thessaloniki, Greece", "doi": null, "report-no": null, "categories": "cs.SE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Open Source Software (OSS) often relies on large repositories, like\nSourceForge, for initial incubation. The OSS repositories offer a large variety\nof meta-data providing interesting information about projects and their\nsuccess. In this paper we propose a data mining approach for training\nclassifiers on the OSS meta-data provided by such data repositories. The\nclassifiers learn to predict the successful continuation of an OSS project. The\n`successfulness' of projects is defined in terms of the classifier confidence\nwith which it predicts that they could be ported in popular OSS projects (such\nas FreeBSD, Gentoo Portage).\n", "versions": [{"version": "v1", "created": "Wed, 29 Apr 2009 21:33:39 GMT"}], "update_date": "2009-05-01", "authors_parsed": [["Tsatsaronis", "George", ""], ["Halkidi", "Maria", ""], ["Giakoumakis", "Emmanouel A.", ""]]}, {"id": "0904.4717", "submitter": "Aram Galstyan", "authors": "Aram Galstyan", "title": "Continuous Strategy Replicator Dynamics for Multi--Agent Learning", "comments": "12 pages, 15 figures, accepted for publication in JAAMAS", "journal-ref": null, "doi": "10.1007/s10458-011-9181-6", "report-no": null, "categories": "cs.LG cs.AI cs.GT nlin.AO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of multi-agent learning and adaptation has attracted a great deal\nof attention in recent years. It has been suggested that the dynamics of multi\nagent learning can be studied using replicator equations from population\nbiology. Most existing studies so far have been limited to discrete strategy\nspaces with a small number of available actions. In many cases, however, the\nchoices available to agents are better characterized by continuous spectra.\nThis paper suggests a generalization of the replicator framework that allows to\nstudy the adaptive dynamics of Q-learning agents with continuous strategy\nspaces. Instead of probability vectors, agents strategies are now characterized\nby probability measures over continuous variables. As a result, the ordinary\ndifferential equations for the discrete case are replaced by a system of\ncoupled integral--differential replicator equations that describe the mutual\nevolution of individual agent strategies. We derive a set of functional\nequations describing the steady state of the replicator dynamics, examine their\nsolutions for several two-player games, and confirm our analytical results\nusing simulations.\n", "versions": [{"version": "v1", "created": "Wed, 29 Apr 2009 23:00:03 GMT"}, {"version": "v2", "created": "Thu, 22 Sep 2011 20:32:36 GMT"}], "update_date": "2011-09-26", "authors_parsed": [["Galstyan", "Aram", ""]]}, {"id": "0904.4727", "submitter": "Yi-Dong Shen", "authors": "Yi-Dong Shen, Jia-Huai You, Li-Yan Yuan", "title": "Characterizations of Stable Model Semantics for Logic Programs with\n  Arbitrary Constraint Atoms", "comments": "34 pages. To appear in Theory and Practice of Logic Programming\n  (TPLP)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies the stable model semantics of logic programs with\n(abstract) constraint atoms and their properties. We introduce a succinct\nabstract representation of these constraint atoms in which a constraint atom is\nrepresented compactly. We show two applications. First, under this\nrepresentation of constraint atoms, we generalize the Gelfond-Lifschitz\ntransformation and apply it to define stable models (also called answer sets)\nfor logic programs with arbitrary constraint atoms. The resulting semantics\nturns out to coincide with the one defined by Son et al., which is based on a\nfixpoint approach. One advantage of our approach is that it can be applied, in\na natural way, to define stable models for disjunctive logic programs with\nconstraint atoms, which may appear in the disjunctive head as well as in the\nbody of a rule. As a result, our approach to the stable model semantics for\nlogic programs with constraint atoms generalizes a number of previous\napproaches. Second, we show that our abstract representation of constraint\natoms provides a means to characterize dependencies of atoms in a program with\nconstraint atoms, so that some standard characterizations and properties\nrelying on these dependencies in the past for logic programs with ordinary\natoms can be extended to logic programs with constraint atoms.\n", "versions": [{"version": "v1", "created": "Thu, 30 Apr 2009 01:15:51 GMT"}], "update_date": "2009-05-01", "authors_parsed": [["Shen", "Yi-Dong", ""], ["You", "Jia-Huai", ""], ["Yuan", "Li-Yan", ""]]}, {"id": "0904.4836", "submitter": "Nikolaos Mavridis", "authors": "Nikolaos Mavridis, Shervin Emami, Chandan Datta, Wajahat Kamzi, Chiraz\n  BenAbdelkader, Panos Toulis, Andry Tanoto, Tamer Rabie", "title": "FaceBots: Steps Towards Enhanced Long-Term Human-Robot Interaction by\n  Utilizing and Publishing Online Social Information", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Our project aims at supporting the creation of sustainable and meaningful\nlonger-term human-robot relationships through the creation of embodied robots\nwith face recognition and natural language dialogue capabilities, which exploit\nand publish social information available on the web (Facebook). Our main\nunderlying experimental hypothesis is that such relationships can be\nsignificantly enhanced if the human and the robot are gradually creating a pool\nof shared episodic memories that they can co-refer to (shared memories), and if\nthey are both embedded in a social web of other humans and robots they both\nknow and encounter (shared friends). In this paper, we are presenting such a\nrobot, which as we will see achieves two significant novelties.\n", "versions": [{"version": "v1", "created": "Thu, 30 Apr 2009 13:02:35 GMT"}], "update_date": "2009-05-01", "authors_parsed": [["Mavridis", "Nikolaos", ""], ["Emami", "Shervin", ""], ["Datta", "Chandan", ""], ["Kamzi", "Wajahat", ""], ["BenAbdelkader", "Chiraz", ""], ["Toulis", "Panos", ""], ["Tanoto", "Andry", ""], ["Rabie", "Tamer", ""]]}]