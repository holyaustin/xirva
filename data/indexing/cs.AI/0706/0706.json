[{"id": "0706.0022", "submitter": "Marko Antonio Rodriguez", "authors": "Marko A. Rodriguez and Johan Bollen", "title": "Modeling Computations in a Semantic Network", "comments": "project website: http://neno.lanl.gov", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.GL", "license": null, "abstract": "  Semantic network research has seen a resurgence from its early history in the\ncognitive sciences with the inception of the Semantic Web initiative. The\nSemantic Web effort has brought forth an array of technologies that support the\nencoding, storage, and querying of the semantic network data structure at the\nworld stage. Currently, the popular conception of the Semantic Web is that of a\ndata modeling medium where real and conceptual entities are related in\nsemantically meaningful ways. However, new models have emerged that explicitly\nencode procedural information within the semantic network substrate. With these\nnew technologies, the Semantic Web has evolved from a data modeling medium to a\ncomputational medium. This article provides a classification of existing\ncomputational modeling efforts and the requirements of supporting technologies\nthat will aid in the further growth of this burgeoning domain.\n", "versions": [{"version": "v1", "created": "Thu, 31 May 2007 21:56:25 GMT"}], "update_date": "2007-06-04", "authors_parsed": [["Rodriguez", "Marko A.", ""], ["Bollen", "Johan", ""]]}, {"id": "0706.0465", "submitter": "Donald Sofge", "authors": "D. A. Sofge", "title": "Virtual Sensor Based Fault Detection and Classification on a Plasma Etch\n  Reactor", "comments": "7 pages", "journal-ref": "D. Sofge, \"Virtual Sensor Based Fault Detection and Classification\n  on a Plasma Etch Reactor,\" The 2nd Joint Mexico-US Int'l. Workshop on Neural\n  Networks and Neurocontrol (poster), 1997", "doi": null, "report-no": null, "categories": "cs.AI cs.CV", "license": null, "abstract": "  The SEMATECH sponsored J-88-E project teaming Texas Instruments with\nNeuroDyne (et al.) focused on Fault Detection and Classification (FDC) on a Lam\n9600 aluminum plasma etch reactor, used in the process of semiconductor\nfabrication. Fault classification was accomplished by implementing a series of\nvirtual sensor models which used data from real sensors (Lam Station sensors,\nOptical Emission Spectroscopy, and RF Monitoring) to predict recipe setpoints\nand wafer state characteristics. Fault detection and classification were\nperformed by comparing predicted recipe and wafer state values with expected\nvalues. Models utilized include linear PLS, Polynomial PLS, and Neural Network\nPLS. Prediction of recipe setpoints based upon sensor data provides a\ncapability for cross-checking that the machine is maintaining the desired\nsetpoints. Wafer state characteristics such as Line Width Reduction and\nRemaining Oxide were estimated on-line using these same process sensors (Lam,\nOES, RFM). Wafer-to-wafer measurement of these characteristics in a production\nsetting (where typically this information may be only sparsely available, if at\nall, after batch processing runs with numerous wafers have been completed)\nwould provide important information to the operator that the process is or is\nnot producing wafers within acceptable bounds of product quality. Production\nyield is increased, and correspondingly per unit cost is reduced, by providing\nthe operator with the opportunity to adjust the process or machine before\netching more wafers.\n", "versions": [{"version": "v1", "created": "Mon, 4 Jun 2007 15:55:27 GMT"}], "update_date": "2007-06-05", "authors_parsed": [["Sofge", "D. A.", ""]]}, {"id": "0706.0585", "submitter": "Zhendong Zhao", "authors": "Zhendong Zhao, Lei Yuan, Yuxuan Wang, Forrest Sheng Bao, Shunyi Zhang\n  Yanfei Sun", "title": "A Novel Model of Working Set Selection for SMO Decomposition Methods", "comments": "8 pages, 12 figures, it was submitted to IEEE International\n  conference of Tools on Artificial Intelligence", "journal-ref": null, "doi": "10.1109/ICTAI.2007.99", "report-no": null, "categories": "cs.LG cs.AI", "license": null, "abstract": "  In the process of training Support Vector Machines (SVMs) by decomposition\nmethods, working set selection is an important technique, and some exciting\nschemes were employed into this field. To improve working set selection, we\npropose a new model for working set selection in sequential minimal\noptimization (SMO) decomposition methods. In this model, it selects B as\nworking set without reselection. Some properties are given by simple proof, and\nexperiments demonstrate that the proposed method is in general faster than\nexisting methods.\n", "versions": [{"version": "v1", "created": "Tue, 5 Jun 2007 05:55:07 GMT"}], "update_date": "2016-11-15", "authors_parsed": [["Zhao", "Zhendong", ""], ["Yuan", "Lei", ""], ["Wang", "Yuxuan", ""], ["Bao", "Forrest Sheng", ""], ["Sun", "Shunyi Zhang Yanfei", ""]]}, {"id": "0706.1001", "submitter": "Krzysztof R. Apt", "authors": "Krzysztof R. Apt", "title": "Epistemic Analysis of Strategic Games with Arbitrary Strategy Sets", "comments": "8 pages Proc. of the 11th Conference on Theoretical Aspects of\n  Rationality and Knowledge (TARK XI), 2007. To appear", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.AI", "license": null, "abstract": "  We provide here an epistemic analysis of arbitrary strategic games based on\nthe possibility correspondences. Such an analysis calls for the use of\ntransfinite iterations of the corresponding operators. Our approach is based on\nTarski's Fixpoint Theorem and applies both to the notions of rationalizability\nand the iterated elimination of strictly dominated strategies.\n", "versions": [{"version": "v1", "created": "Thu, 7 Jun 2007 12:57:21 GMT"}], "update_date": "2007-06-08", "authors_parsed": [["Apt", "Krzysztof R.", ""]]}, {"id": "0706.1137", "submitter": "Thierry Poibeau", "authors": "Amanda Bouffier (LIPN), Thierry Poibeau (LIPN)", "title": "Automatically Restructuring Practice Guidelines using the GEM DTD", "comments": null, "journal-ref": "Proceedings of Biomedical Natural Language Processing (BioNLP)\n  (2007) -", "doi": null, "report-no": null, "categories": "cs.AI", "license": null, "abstract": "  This paper describes a system capable of semi-automatically filling an XML\ntemplate from free texts in the clinical domain (practice guidelines). The XML\ntemplate includes semantic information not explicitly encoded in the text\n(pairs of conditions and actions/recommendations). Therefore, there is a need\nto compute the exact scope of conditions over text sequences expressing the\nrequired actions. We present a system developed for this task. We show that it\nyields good performance when applied to the analysis of French practice\nguidelines.\n", "versions": [{"version": "v1", "created": "Fri, 8 Jun 2007 15:39:49 GMT"}], "update_date": "2007-06-11", "authors_parsed": [["Bouffier", "Amanda", "", "LIPN"], ["Poibeau", "Thierry", "", "LIPN"]]}, {"id": "0706.1290", "submitter": "Sylviane Schwer", "authors": "Sylviane R. Schwer (LIPN)", "title": "Temporal Reasoning without Transitive Tables", "comments": "rapport interne", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": null, "abstract": "  Representing and reasoning about qualitative temporal information is an\nessential part of many artificial intelligence tasks. Lots of models have been\nproposed in the litterature for representing such temporal information. All\nderive from a point-based or an interval-based framework. One fundamental\nreasoning task that arises in applications of these frameworks is given by the\nfollowing scheme: given possibly indefinite and incomplete knowledge of the\nbinary relationships between some temporal objects, find the consistent\nscenarii between all these objects. All these models require transitive tables\n-- or similarly inference rules-- for solving such tasks. We have defined an\nalternative model, S-languages - to represent qualitative temporal information,\nbased on the only two relations of \\emph{precedence} and \\emph{simultaneity}.\nIn this paper, we show how this model enables to avoid transitive tables or\ninference rules to handle this kind of problem.\n", "versions": [{"version": "v1", "created": "Sat, 9 Jun 2007 06:57:05 GMT"}], "update_date": "2007-06-12", "authors_parsed": [["Schwer", "Sylviane R.", "", "LIPN"]]}, {"id": "0706.3639", "submitter": "Marcus Hutter", "authors": "Shane Legg and Marcus Hutter", "title": "A Collection of Definitions of Intelligence", "comments": "12 LaTeX pages", "journal-ref": "Frontiers in Artificial Intelligence and Applications, Vol.157\n  (2007) 17-24", "doi": null, "report-no": "IDSIA-07-07", "categories": "cs.AI", "license": null, "abstract": "  This paper is a survey of a large number of informal definitions of\n``intelligence'' that the authors have collected over the years. Naturally,\ncompiling a complete list would be impossible as many definitions of\nintelligence are buried deep inside articles and books. Nevertheless, the\n70-odd definitions presented here are, to the authors' knowledge, the largest\nand most well referenced collection there is.\n", "versions": [{"version": "v1", "created": "Mon, 25 Jun 2007 13:40:56 GMT"}], "update_date": "2007-06-26", "authors_parsed": [["Legg", "Shane", ""], ["Hutter", "Marcus", ""]]}, {"id": "0706.4323", "submitter": "Khalil Djelloul", "authors": "Khalil Djelloul, Thi-bich-hanh Dao and Thom Fruehwirth", "title": "Theory of Finite or Infinite Trees Revisited", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI", "license": null, "abstract": "  We present in this paper a first-order axiomatization of an extended theory\n$T$ of finite or infinite trees, built on a signature containing an infinite\nset of function symbols and a relation $\\fini(t)$ which enables to distinguish\nbetween finite or infinite trees. We show that $T$ has at least one model and\nprove its completeness by giving not only a decision procedure, but a full\nfirst-order constraint solver which gives clear and explicit solutions for any\nfirst-order constraint satisfaction problem in $T$. The solver is given in the\nform of 16 rewriting rules which transform any first-order constraint $\\phi$\ninto an equivalent disjunction $\\phi$ of simple formulas such that $\\phi$ is\neither the formula $\\true$ or the formula $\\false$ or a formula having at least\none free variable, being equivalent neither to $\\true$ nor to $\\false$ and\nwhere the solutions of the free variables are expressed in a clear and explicit\nway. The correctness of our rules implies the completeness of $T$. We also\ndescribe an implementation of our algorithm in CHR (Constraint Handling Rules)\nand compare the performance with an implementation in C++ and that of a recent\ndecision procedure for decomposable theories.\n", "versions": [{"version": "v1", "created": "Thu, 28 Jun 2007 21:18:19 GMT"}], "update_date": "2007-07-02", "authors_parsed": [["Djelloul", "Khalil", ""], ["Dao", "Thi-bich-hanh", ""], ["Fruehwirth", "Thom", ""]]}, {"id": "0706.4375", "submitter": "Thierry Hamon", "authors": "Thierry Hamon (LIPN), Adeline Nazarenko (LIPN), Thierry Poibeau\n  (LIPN), Sophie Aubin (LIPN), Julien Derivi\\`ere (LIPN)", "title": "A Robust Linguistic Platform for Efficient and Domain specific Web\n  Content Analysis", "comments": null, "journal-ref": "Proceedings of RIAO 2007 (30/05/2007)", "doi": null, "report-no": null, "categories": "cs.AI", "license": null, "abstract": "  Web semantic access in specific domains calls for specialized search engines\nwith enhanced semantic querying and indexing capacities, which pertain both to\ninformation retrieval (IR) and to information extraction (IE). A rich\nlinguistic analysis is required either to identify the relevant semantic units\nto index and weight them according to linguistic specific statistical\ndistribution, or as the basis of an information extraction process. Recent\ndevelopments make Natural Language Processing (NLP) techniques reliable enough\nto process large collections of documents and to enrich them with semantic\nannotations. This paper focuses on the design and the development of a text\nprocessing platform, Ogmios, which has been developed in the ALVIS project. The\nOgmios platform exploits existing NLP modules and resources, which may be tuned\nto specific domains and produces linguistically annotated documents. We show\nhow the three constraints of genericity, domain semantic awareness and\nperformance can be handled all together.\n", "versions": [{"version": "v1", "created": "Fri, 29 Jun 2007 08:58:02 GMT"}], "update_date": "2007-07-02", "authors_parsed": [["Hamon", "Thierry", "", "LIPN"], ["Nazarenko", "Adeline", "", "LIPN"], ["Poibeau", "Thierry", "", "LIPN"], ["Aubin", "Sophie", "", "LIPN"], ["Derivi\u00e8re", "Julien", "", "LIPN"]]}]