[{"id": "1210.0074", "submitter": "Aiping  Huang", "authors": "Aiping Huang, William Zhu", "title": "Topological characterizations to three types of covering approximation\n  operators", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Covering-based rough set theory is a useful tool to deal with inexact,\nuncertain or vague knowledge in information systems. Topology, one of the most\nimportant subjects in mathematics, provides mathematical tools and interesting\ntopics in studying information systems and rough sets. In this paper, we\npresent the topological characterizations to three types of covering\napproximation operators. First, we study the properties of topology induced by\nthe sixth type of covering lower approximation operator. Second, some\ntopological characterizations to the covering lower approximation operator to\nbe an interior operator are established. We find that the topologies induced by\nthis operator and by the sixth type of covering lower approximation operator\nare the same. Third, we study the conditions which make the first type of\ncovering upper approximation operator be a closure operator, and find that the\ntopology induced by the operator is the same as the topology induced by the\nfifth type of covering upper approximation operator. Forth, the conditions of\nthe second type of covering upper approximation operator to be a closure\noperator and the properties of topology induced by it are established. Finally,\nthese three topologies space are compared. In a word, topology provides a\nuseful method to study the covering-based rough sets.\n", "versions": [{"version": "v1", "created": "Sat, 29 Sep 2012 03:16:49 GMT"}], "update_date": "2012-10-02", "authors_parsed": [["Huang", "Aiping", ""], ["Zhu", "William", ""]]}, {"id": "1210.0075", "submitter": "Aiping  Huang", "authors": "Aiping Huang, William Zhu", "title": "Geometric lattice structure of covering-based rough sets through\n  matroids", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Covering-based rough set theory is a useful tool to deal with inexact,\nuncertain or vague knowledge in information systems. Geometric lattice has\nwidely used in diverse fields, especially search algorithm design which plays\nimportant role in covering reductions. In this paper, we construct four\ngeometric lattice structures of covering-based rough sets through matroids, and\ncompare their relationships. First, a geometric lattice structure of\ncovering-based rough sets is established through the transversal matroid\ninduced by the covering, and its characteristics including atoms, modular\nelements and modular pairs are studied. We also construct a one-to-one\ncorrespondence between this type of geometric lattices and transversal matroids\nin the context of covering-based rough sets. Second, sufficient and necessary\nconditions for three types of covering upper approximation operators to be\nclosure operators of matroids are presented. We exhibit three types of matroids\nthrough closure axioms, and then obtain three geometric lattice structures of\ncovering-based rough sets. Third, these four geometric lattice structures are\ncompared. Some core concepts such as reducible elements in covering-based rough\nsets are investigated with geometric lattices. In a word, this work points out\nan interesting view, namely geometric lattice, to study covering-based rough\nsets.\n", "versions": [{"version": "v1", "created": "Sat, 29 Sep 2012 03:26:18 GMT"}], "update_date": "2012-10-02", "authors_parsed": [["Huang", "Aiping", ""], ["Zhu", "William", ""]]}, {"id": "1210.0077", "submitter": "Marcus Hutter", "authors": "Peter Sunehag and Marcus Hutter", "title": "Optimistic Agents are Asymptotically Optimal", "comments": "13 LaTeX pages", "journal-ref": "Proc. 25th Australasian Joint Conference on Artificial\n  Intelligence (AusAI 2012) 15-26", "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We use optimism to introduce generic asymptotically optimal reinforcement\nlearning agents. They achieve, with an arbitrary finite or compact class of\nenvironments, asymptotically optimal behavior. Furthermore, in the finite\ndeterministic case we provide finite error bounds.\n", "versions": [{"version": "v1", "created": "Sat, 29 Sep 2012 04:58:22 GMT"}], "update_date": "2013-05-17", "authors_parsed": [["Sunehag", "Peter", ""], ["Hutter", "Marcus", ""]]}, {"id": "1210.0091", "submitter": "Hong Zhao", "authors": "Hong Zhao, Fan Min, William Zhu", "title": "Test-cost-sensitive attribute reduction of data with normal distribution\n  measurement errors", "comments": "This paper has been withdrawn by the author due to the error of the\n  title", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The measurement error with normal distribution is universal in applications.\nGenerally, smaller measurement error requires better instrument and higher test\ncost. In decision making based on attribute values of objects, we shall select\nan attribute subset with appropriate measurement error to minimize the total\ntest cost. Recently, error-range-based covering rough set with uniform\ndistribution error was proposed to investigate this issue. However, the\nmeasurement errors satisfy normal distribution instead of uniform distribution\nwhich is rather simple for most applications. In this paper, we introduce\nnormal distribution measurement errors to covering-based rough set model, and\ndeal with test-cost-sensitive attribute reduction problem in this new model.\nThe major contributions of this paper are four-fold. First, we build a new data\nmodel based on normal distribution measurement errors. With the new data model,\nthe error range is an ellipse in a two-dimension space. Second, the\ncovering-based rough set with normal distribution measurement errors is\nconstructed through the \"3-sigma\" rule. Third, the test-cost-sensitive\nattribute reduction problem is redefined on this covering-based rough set.\nFourth, a heuristic algorithm is proposed to deal with this problem. The\nalgorithm is tested on ten UCI (University of California - Irvine) datasets.\nThe experimental results show that the algorithm is more effective and\nefficient than the existing one. This study is a step toward realistic\napplications of cost-sensitive learning.\n", "versions": [{"version": "v1", "created": "Sat, 29 Sep 2012 10:22:55 GMT"}, {"version": "v2", "created": "Mon, 3 Jun 2013 03:15:51 GMT"}], "update_date": "2013-06-04", "authors_parsed": [["Zhao", "Hong", ""], ["Min", "Fan", ""], ["Zhu", "William", ""]]}, {"id": "1210.0167", "submitter": "L.T. Handoko", "authors": "A.A. Waskita, H. Suhartanto, Z. Akbar, L.T. Handoko", "title": "Exhaustive Search-based Model for Hybrid Sensor Network", "comments": "6 pages, Proceeding of the International Conference on Intelligent &\n  Advanced Systems 2012 pp. 557-561", "journal-ref": null, "doi": "10.1109/ICIAS.2012.6306077", "report-no": "FISIKALIPI-12011", "categories": "cs.AI cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A new model for a cluster of hybrid sensors network with multi sub-clusters\nis proposed. The model is in particular relevant to the early warning system in\na large scale monitoring system in, for example, a nuclear power plant. It\nmainly addresses to a safety critical system which requires real-time processes\nwith high accuracy. The mathematical model is based on the extended\nconventional search algorithm with certain interactions among the nearest\nneighborhood of sensors. It is argued that the model could realize a highly\naccurate decision support system with less number of parameters. A case of one\ndimensional interaction function is discussed, and a simple algorithm for the\nmodel is also given.\n", "versions": [{"version": "v1", "created": "Sun, 30 Sep 2012 04:33:56 GMT"}], "update_date": "2012-10-02", "authors_parsed": [["Waskita", "A. A.", ""], ["Suhartanto", "H.", ""], ["Akbar", "Z.", ""], ["Handoko", "L. T.", ""]]}, {"id": "1210.0252", "submitter": "Fethi Fkih", "authors": "Fethi Fkih, Mohamed Nazih Omri and Imen Toumia", "title": "A Linguistic Model for Terminology Extraction based Conditional Random\n  Fields", "comments": "This paper has been withdrawn by the author due to the poor\n  readability and the low quality of the English", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  In this paper, we show the possibility of using a linear Conditional Random\nFields (CRF) for terminology extraction from a specialized text corpus.\n", "versions": [{"version": "v1", "created": "Sun, 30 Sep 2012 22:55:45 GMT"}, {"version": "v2", "created": "Sat, 15 Feb 2014 11:25:46 GMT"}], "update_date": "2014-02-18", "authors_parsed": [["Fkih", "Fethi", ""], ["Omri", "Mohamed Nazih", ""], ["Toumia", "Imen", ""]]}, {"id": "1210.0690", "submitter": "Santiago Videla", "authors": "Santiago Videla (INRIA - IRISA), Carito Guziolowski (IRCCyN), Federica\n  Eduati (DEI, EBI), Sven Thiele (INRIA - IRISA), Niels Grabe, Julio\n  Saez-Rodriguez (EBI), Anne Siegel (INRIA - IRISA)", "title": "Revisiting the Training of Logic Models of Protein Signaling Networks\n  with a Formal Approach based on Answer Set Programming", "comments": null, "journal-ref": "CMSB - 10th Computational Methods in Systems Biology 2012 7605\n  (2012) 342-361", "doi": "10.1007/978-3-642-33636-2_20", "report-no": null, "categories": "q-bio.QM cs.AI cs.CE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A fundamental question in systems biology is the construction and training to\ndata of mathematical models. Logic formalisms have become very popular to model\nsignaling networks because their simplicity allows us to model large systems\nencompassing hundreds of proteins. An approach to train (Boolean) logic models\nto high-throughput phospho-proteomics data was recently introduced and solved\nusing optimization heuristics based on stochastic methods. Here we demonstrate\nhow this problem can be solved using Answer Set Programming (ASP), a\ndeclarative problem solving paradigm, in which a problem is encoded as a\nlogical program such that its answer sets represent solutions to the problem.\nASP has significant improvements over heuristic methods in terms of efficiency\nand scalability, it guarantees global optimality of solutions as well as\nprovides a complete set of solutions. We illustrate the application of ASP with\nin silico cases based on realistic networks and data.\n", "versions": [{"version": "v1", "created": "Tue, 2 Oct 2012 07:52:52 GMT"}, {"version": "v2", "created": "Sat, 22 Dec 2012 07:39:43 GMT"}], "update_date": "2012-12-27", "authors_parsed": [["Videla", "Santiago", "", "INRIA - IRISA"], ["Guziolowski", "Carito", "", "IRCCyN"], ["Eduati", "Federica", "", "DEI, EBI"], ["Thiele", "Sven", "", "INRIA - IRISA"], ["Grabe", "Niels", "", "EBI"], ["Saez-Rodriguez", "Julio", "", "EBI"], ["Siegel", "Anne", "", "INRIA - IRISA"]]}, {"id": "1210.0772", "submitter": "Yanfang Liu", "authors": "Yanfang Liu and William Zhu", "title": "Relationship between the second type of covering-based rough set and\n  matroid via closure operator", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, in order to broad the application and theoretical areas of rough\nsets and matroids, some authors have combined them from many different\nviewpoints, such as circuits, rank function, spanning sets and so on. In this\npaper, we connect the second type of covering-based rough sets and matroids\nfrom the view of closure operators. On one hand, we establish a closure system\nthrough the fixed point family of the second type of covering lower\napproximation operator, and then construct a closure operator. For a covering\nof a universe, the closure operator is a closure one of a matroid if and only\nif the reduct of the covering is a partition of the universe. On the other\nhand, we investigate the sufficient and necessary condition that the second\ntype of covering upper approximation operation is a closure one of a matroid.\n", "versions": [{"version": "v1", "created": "Tue, 2 Oct 2012 13:40:23 GMT"}], "update_date": "2012-10-03", "authors_parsed": [["Liu", "Yanfang", ""], ["Zhu", "William", ""]]}, {"id": "1210.0794", "submitter": "Nahla Jlaiel", "authors": "Nahla Jlaiel, Khouloud Madhbouh, Mohamed Ben Ahmed", "title": "A Semantic Approach for Automatic Structuring and Analysis of Software\n  Process Patterns", "comments": "08 pages, 10 figures, Published with International Journal of\n  Computer Applications (IJCA)", "journal-ref": "Nahla Jlaiel, Khouloud Madhbouh and Mohamed Ben Ahmed. Article: A\n  Semantic Approach for Automatic Structuring and Analysis of Software Process\n  Patterns. International Journal of Computer Applications 54(15):24-31,\n  September 2012", "doi": "10.5120/8643-2503", "report-no": null, "categories": "cs.AI cs.CL", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  The main contribution of this paper, is to propose a novel semantic approach\nbased on a Natural Language Processing technique in order to ensure a semantic\nunification of unstructured process patterns which are expressed not only in\ndifferent formats but also, in different forms. This approach is implemented\nusing the GATE text engineering framework and then evaluated leading up to\nhigh-quality results motivating us to continue in this direction.\n", "versions": [{"version": "v1", "created": "Tue, 2 Oct 2012 14:56:07 GMT"}], "update_date": "2012-10-03", "authors_parsed": [["Jlaiel", "Nahla", ""], ["Madhbouh", "Khouloud", ""], ["Ahmed", "Mohamed Ben", ""]]}, {"id": "1210.0887", "submitter": "Dimiter Dobrev", "authors": "Dimiter Dobrev", "title": "The Definition of AI in Terms of Multi Agent Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The questions which we will consider here are \"What is AI?\" and \"How can we\nmake AI?\". Here we will present the definition of AI in terms of multi-agent\nsystems. This means that here you will not find a new answer to the question\n\"What is AI?\", but an old answer in a new form.\n  This new form of the definition of AI is of interest for the theory of\nmulti-agent systems because it gives us better understanding of this theory.\nMore important is that this work will help us answer the second question. We\nwant to make a program which is capable of constructing a model of its\nenvironment. Every multi-agent model is equivalent to a single-agent model but\nmulti-agent models are more natural and accordingly more easily discoverable.\n", "versions": [{"version": "v1", "created": "Tue, 2 Oct 2012 19:28:42 GMT"}], "update_date": "2012-10-03", "authors_parsed": [["Dobrev", "Dimiter", ""]]}, {"id": "1210.1161", "submitter": "Efi Papaptheocharous", "authors": "Efi Papatheocharous, Harris Papadopoulos and Andreas S. Andreou", "title": "Feature Subset Selection for Software Cost Modelling and Estimation", "comments": "Engineering Intelligent Systems Vol 18 (3/4) September/December 2010", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Feature selection has been recently used in the area of software engineering\nfor improving the accuracy and robustness of software cost models. The idea\nbehind selecting the most informative subset of features from a pool of\navailable cost drivers stems from the hypothesis that reducing the\ndimensionality of datasets will significantly minimise the complexity and time\nrequired to reach to an estimation using a particular modelling technique. This\nwork investigates the appropriateness of attributes, obtained from empirical\nproject databases and aims to reduce the cost drivers used while preserving\nperformance. Finding suitable subset selections that may cater improved\npredictions may be considered as a pre-processing step of a particular\ntechnique employed for cost estimation (filter or wrapper) or an internal\n(embedded) step to minimise the fitting error. This paper compares nine\nrelatively popular feature selection methods and uses the empirical values of\nselected attributes recorded in the ISBSG and Desharnais datasets to estimate\nsoftware development effort.\n", "versions": [{"version": "v1", "created": "Wed, 3 Oct 2012 16:12:07 GMT"}], "update_date": "2012-10-04", "authors_parsed": [["Papatheocharous", "Efi", ""], ["Papadopoulos", "Harris", ""], ["Andreou", "Andreas S.", ""]]}, {"id": "1210.1184", "submitter": "Christopher Simons", "authors": "Christopher L. Simons and Ian C. Parmee", "title": "Elegant Object-oriented Software Design via Interactive, Evolutionary\n  Computation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Design is fundamental to software development but can be demanding to\nperform. Thus to assist the software designer, evolutionary computing is being\nincreasingly applied using machine-based, quantitative fitness functions to\nevolve software designs. However, in nature, elegance and symmetry play a\ncrucial role in the reproductive fitness of various organisms. In addition,\nsubjective evaluation has also been exploited in Interactive Evolutionary\nComputation (IEC). Therefore to investigate the role of elegance and symmetry\nin software design, four novel elegance measures are proposed based on the\nevenness of distribution of design elements. In controlled experiments in a\ndynamic interactive evolutionary computation environment, designers are\npresented with visualizations of object-oriented software designs, which they\nrank according to a subjective assessment of elegance. For three out of the\nfour elegance measures proposed, it is found that a significant correlation\nexists between elegance values and reward elicited. These three elegance\nmeasures assess the evenness of distribution of (a) attributes and methods\namong classes, (b) external couples between classes, and (c) the ratio of\nattributes to methods. It is concluded that symmetrical elegance is in some way\nsignificant in software design, and that this can be exploited in dynamic,\nmulti-objective interactive evolutionary computation to produce elegant\nsoftware designs.\n", "versions": [{"version": "v1", "created": "Wed, 3 Oct 2012 17:57:01 GMT"}], "update_date": "2012-10-04", "authors_parsed": [["Simons", "Christopher L.", ""], ["Parmee", "Ian C.", ""]]}, {"id": "1210.1207", "submitter": "Hema Swetha Koppula", "authors": "Hema Swetha Koppula, Rudhir Gupta, Ashutosh Saxena", "title": "Learning Human Activities and Object Affordances from RGB-D Videos", "comments": "arXiv admin note: substantial text overlap with arXiv:1208.0967", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding human activities and object affordances are two very important\nskills, especially for personal robots which operate in human environments. In\nthis work, we consider the problem of extracting a descriptive labeling of the\nsequence of sub-activities being performed by a human, and more importantly, of\ntheir interactions with the objects in the form of associated affordances.\nGiven a RGB-D video, we jointly model the human activities and object\naffordances as a Markov random field where the nodes represent objects and\nsub-activities, and the edges represent the relationships between object\naffordances, their relations with sub-activities, and their evolution over\ntime. We formulate the learning problem using a structural support vector\nmachine (SSVM) approach, where labelings over various alternate temporal\nsegmentations are considered as latent variables. We tested our method on a\nchallenging dataset comprising 120 activity videos collected from 4 subjects,\nand obtained an accuracy of 79.4% for affordance, 63.4% for sub-activity and\n75.0% for high-level activity labeling. We then demonstrate the use of such\ndescriptive labeling in performing assistive tasks by a PR2 robot.\n", "versions": [{"version": "v1", "created": "Thu, 4 Oct 2012 04:53:42 GMT"}, {"version": "v2", "created": "Mon, 6 May 2013 01:13:39 GMT"}], "update_date": "2013-05-07", "authors_parsed": [["Koppula", "Hema Swetha", ""], ["Gupta", "Rudhir", ""], ["Saxena", "Ashutosh", ""]]}, {"id": "1210.1317", "submitter": "Phong Nguyen", "authors": "Phong Nguyen, Jun Wang, Melanie Hilario and Alexandros Kalousis", "title": "Learning Heterogeneous Similarity Measures for Hybrid-Recommendations in\n  Meta-Mining", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The notion of meta-mining has appeared recently and extends the traditional\nmeta-learning in two ways. First it does not learn meta-models that provide\nsupport only for the learning algorithm selection task but ones that support\nthe whole data-mining process. In addition it abandons the so called black-box\napproach to algorithm description followed in meta-learning. Now in addition to\nthe datasets, algorithms also have descriptors, workflows as well. For the\nlatter two these descriptions are semantic, describing properties of the\nalgorithms. With the availability of descriptors both for datasets and data\nmining workflows the traditional modelling techniques followed in\nmeta-learning, typically based on classification and regression algorithms, are\nno longer appropriate. Instead we are faced with a problem the nature of which\nis much more similar to the problems that appear in recommendation systems. The\nmost important meta-mining requirements are that suggestions should use only\ndatasets and workflows descriptors and the cold-start problem, e.g. providing\nworkflow suggestions for new datasets.\n  In this paper we take a different view on the meta-mining modelling problem\nand treat it as a recommender problem. In order to account for the meta-mining\nspecificities we derive a novel metric-based-learning recommender approach. Our\nmethod learns two homogeneous metrics, one in the dataset and one in the\nworkflow space, and a heterogeneous one in the dataset-workflow space. All\nlearned metrics reflect similarities established from the dataset-workflow\npreference matrix. We demonstrate our method on meta-mining over biological\n(microarray datasets) problems. The application of our method is not limited to\nthe meta-mining problem, its formulations is general enough so that it can be\napplied on problems with similar requirements.\n", "versions": [{"version": "v1", "created": "Thu, 4 Oct 2012 07:17:37 GMT"}], "update_date": "2012-10-05", "authors_parsed": [["Nguyen", "Phong", ""], ["Wang", "Jun", ""], ["Hilario", "Melanie", ""], ["Kalousis", "Alexandros", ""]]}, {"id": "1210.1568", "submitter": "Dimiter Dobrev", "authors": "Dimiter Dobrev", "title": "A Definition of Artificial Intelligence", "comments": null, "journal-ref": "Dobrev D. A Definition of Artificial Intelligence. In: Mathematica\n  Balkanica, New Series, Vol. 19, 2005, Fasc. 1-2, pp.67-74", "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we offer a formal definition of Artificial Intelligence and\nthis directly gives us an algorithm for construction of this object. Really,\nthis algorithm is useless due to the combinatory explosion.\n  The main innovation in our definition is that it does not include the\nknowledge as a part of the intelligence. So according to our definition a newly\nborn baby also is an Intellect. Here we differs with Turing's definition which\nsuggests that an Intellect is a person with knowledge gained through the years.\n", "versions": [{"version": "v1", "created": "Wed, 3 Oct 2012 20:46:10 GMT"}], "update_date": "2012-10-08", "authors_parsed": [["Dobrev", "Dimiter", ""]]}, {"id": "1210.1649", "submitter": "Thomas Krennwallner", "authors": "Thomas Eiter, Michael Fink, Thomas Krennwallner, Christoph Redl", "title": "Conflict-driven ASP Solving with External Sources", "comments": "To appear in Theory and Practice of Logic Programming", "journal-ref": "Theor. Pract. Log. Prog. 12:4-5 (2012) 659-679", "doi": "10.1017/S1471068412000233", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Answer Set Programming (ASP) is a well-known problem solving approach based\non nonmonotonic logic programs and efficient solvers. To enable access to\nexternal information, HEX-programs extend programs with external atoms, which\nallow for a bidirectional communication between the logic program and external\nsources of computation (e.g., description logic reasoners and Web resources).\nCurrent solvers evaluate HEX-programs by a translation to ASP itself, in which\nvalues of external atoms are guessed and verified after the ordinary answer set\ncomputation. This elegant approach does not scale with the number of external\naccesses in general, in particular in presence of nondeterminism (which is\ninstrumental for ASP). In this paper, we present a novel, native algorithm for\nevaluating HEX-programs which uses learning techniques. In particular, we\nextend conflict-driven ASP solving techniques, which prevent the solver from\nrunning into the same conflict again, from ordinary to HEX-programs. We show\nhow to gain additional knowledge from external source evaluations and how to\nuse it in a conflict-driven algorithm. We first target the uninformed case,\ni.e., when we have no extra information on external sources, and then extend\nour approach to the case where additional meta-information is available.\nExperiments show that learning from external sources can significantly decrease\nboth the runtime and the number of considered candidate compatible sets.\n", "versions": [{"version": "v1", "created": "Fri, 5 Oct 2012 06:12:59 GMT"}], "update_date": "2012-10-08", "authors_parsed": [["Eiter", "Thomas", ""], ["Fink", "Michael", ""], ["Krennwallner", "Thomas", ""], ["Redl", "Christoph", ""]]}, {"id": "1210.1753", "submitter": "Murphy Choy", "authors": "Murphy Choy, Michelle Cheong", "title": "Intelligent Search Heuristics for Cost Based Scheduling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nurse scheduling is a difficult optimization problem with multiple\nconstraints. There is extensive research in the literature solving the problem\nusing meta-heuristics approaches. In this paper, we will investigate an\nintelligent search heuristics that handles cost based scheduling problem. The\nheuristics demonstrated superior performances compared to the original\nalgorithms used to solve the problems described in Li et. Al. (2003) and\nOzkarahan (1989) in terms of time needed to establish a feasible solution. Both\nproblems can be formulated as a cost problem. The search heuristic consists of\nseveral phrases of search and input based on the cost of each assignment and\nhow the assignment will interact with the cost of the resources.\n", "versions": [{"version": "v1", "created": "Thu, 4 Oct 2012 03:49:21 GMT"}], "update_date": "2012-10-08", "authors_parsed": [["Choy", "Murphy", ""], ["Cheong", "Michelle", ""]]}, {"id": "1210.1766", "submitter": "Jun Zhu", "authors": "Jun Zhu, Ning Chen, and Eric P. Xing", "title": "Bayesian Inference with Posterior Regularization and applications to\n  Infinite Latent SVMs", "comments": "49 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing Bayesian models, especially nonparametric Bayesian methods, rely on\nspecially conceived priors to incorporate domain knowledge for discovering\nimproved latent representations. While priors can affect posterior\ndistributions through Bayes' rule, imposing posterior regularization is\narguably more direct and in some cases more natural and general. In this paper,\nwe present regularized Bayesian inference (RegBayes), a novel computational\nframework that performs posterior inference with a regularization term on the\ndesired post-data posterior distribution under an information theoretical\nformulation. RegBayes is more flexible than the procedure that elicits expert\nknowledge via priors, and it covers both directed Bayesian networks and\nundirected Markov networks whose Bayesian formulation results in hybrid chain\ngraph models. When the regularization is induced from a linear operator on the\nposterior distributions, such as the expectation operator, we present a general\nconvex-analysis theorem to characterize the solution of RegBayes. Furthermore,\nwe present two concrete examples of RegBayes, infinite latent support vector\nmachines (iLSVM) and multi-task infinite latent support vector machines\n(MT-iLSVM), which explore the large-margin idea in combination with a\nnonparametric Bayesian model for discovering predictive latent features for\nclassification and multi-task learning, respectively. We present efficient\ninference methods and report empirical studies on several benchmark datasets,\nwhich appear to demonstrate the merits inherited from both large-margin\nlearning and Bayesian nonparametrics. Such results were not available until\nnow, and contribute to push forward the interface between these two important\nsubfields, which have been largely treated as isolated in the community.\n", "versions": [{"version": "v1", "created": "Fri, 5 Oct 2012 14:10:20 GMT"}, {"version": "v2", "created": "Mon, 8 Apr 2013 09:33:44 GMT"}, {"version": "v3", "created": "Wed, 12 Feb 2014 06:31:12 GMT"}], "update_date": "2014-02-13", "authors_parsed": [["Zhu", "Jun", ""], ["Chen", "Ning", ""], ["Xing", "Eric P.", ""]]}, {"id": "1210.1785", "submitter": "Michael Maher", "authors": "Michael Maher", "title": "Relative Expressiveness of Defeasible Logics", "comments": null, "journal-ref": "Theory and Practice of Logic Programming 12 (4-5), 793--810, 2012", "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the relative expressiveness of defeasible logics in the framework\nDL. Relative expressiveness is formulated as the ability to simulate the\nreasoning of one logic within another logic. We show that such simulations must\nbe modular, in the sense that they also work if applied only to part of a\ntheory, in order to achieve a useful notion of relative expressiveness. We\npresent simulations showing that logics in DL with and without the capability\nof team defeat are equally expressive. We also show that logics that handle\nambiguity differently -- ambiguity blocking versus ambiguity propagating --\nhave distinct expressiveness, with neither able to simulate the other under a\ndifferent formulation of expressiveness.\n", "versions": [{"version": "v1", "created": "Fri, 5 Oct 2012 15:27:53 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Maher", "Michael", ""]]}, {"id": "1210.1791", "submitter": "Jasper De Bock", "authors": "Jasper De Bock and Gert de Cooman", "title": "An efficient algorithm for estimating state sequences in imprecise\n  hidden Markov models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an efficient exact algorithm for estimating state sequences from\noutputs (or observations) in imprecise hidden Markov models (iHMM), where both\nthe uncertainty linking one state to the next, and that linking a state to its\noutput, are represented using coherent lower previsions. The notion of\nindependence we associate with the credal network representing the iHMM is that\nof epistemic irrelevance. We consider as best estimates for state sequences the\n(Walley--Sen) maximal sequences for the posterior joint state model conditioned\non the observed output sequence, associated with a gain function that is the\nindicator of the state sequence. This corresponds to (and generalises) finding\nthe state sequence with the highest posterior probability in HMMs with precise\ntransition and output probabilities (pHMMs). We argue that the computational\ncomplexity is at worst quadratic in the length of the Markov chain, cubic in\nthe number of states, and essentially linear in the number of maximal state\nsequences. For binary iHMMs, we investigate experimentally how the number of\nmaximal state sequences depends on the model parameters. We also present a\nsimple toy application in optical character recognition, demonstrating that our\nalgorithm can be used to robustify the inferences made by precise probability\nmodels.\n", "versions": [{"version": "v1", "created": "Fri, 5 Oct 2012 15:41:11 GMT"}], "update_date": "2012-10-08", "authors_parsed": [["De Bock", "Jasper", ""], ["de Cooman", "Gert", ""]]}, {"id": "1210.1928", "submitter": "Shrihari Vasudevan", "authors": "Shrihari Vasudevan and Arman Melkumyan and Steven Scheding", "title": "Information fusion in multi-task Gaussian processes", "comments": "53 pages, 33 figures; improved presentation", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper evaluates heterogeneous information fusion using multi-task\nGaussian processes in the context of geological resource modeling.\nSpecifically, it empirically demonstrates that information integration across\nheterogeneous information sources leads to superior estimates of all the\nquantities being modeled, compared to modeling them individually. Multi-task\nGaussian processes provide a powerful approach for simultaneous modeling of\nmultiple quantities of interest while taking correlations between these\nquantities into consideration. Experiments are performed on large scale real\nsensor data.\n", "versions": [{"version": "v1", "created": "Sat, 6 Oct 2012 08:11:01 GMT"}, {"version": "v2", "created": "Mon, 15 Oct 2012 04:25:31 GMT"}, {"version": "v3", "created": "Thu, 5 Sep 2013 03:42:50 GMT"}], "update_date": "2013-09-06", "authors_parsed": [["Vasudevan", "Shrihari", ""], ["Melkumyan", "Arman", ""], ["Scheding", "Steven", ""]]}, {"id": "1210.1931", "submitter": "Bernhard Bliem", "authors": "Bernhard Bliem, Michael Morak and Stefan Woltran", "title": "D-FLAT: Declarative Problem Solving Using Tree Decompositions and\n  Answer-Set Programming", "comments": "18 pages, 5 figures. To appear in Theory and Practice of Logic\n  Programming (TPLP)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we propose Answer-Set Programming (ASP) as a tool for rapid\nprototyping of dynamic programming algorithms based on tree decompositions. In\nfact, many such algorithms have been designed, but only a few of them found\ntheir way into implementation. The main obstacle is the lack of easy-to-use\nsystems which (i) take care of building a tree decomposition and (ii) provide\nan interface for declarative specifications of dynamic programming algorithms.\nIn this paper, we present D-FLAT, a novel tool that relieves the user of having\nto handle all the technical details concerned with parsing, tree decomposition,\nthe handling of data structures, etc. Instead, it is only the dynamic\nprogramming algorithm itself which has to be specified in the ASP language.\nD-FLAT employs an ASP solver in order to compute the local solutions in the\ndynamic programming algorithm. In the paper, we give a few examples\nillustrating the use of D-FLAT and describe the main features of the system.\nMoreover, we report experiments which show that ASP-based D-FLAT encodings for\nsome problems outperform monolithic ASP encodings on instances of small\ntreewidth.\n", "versions": [{"version": "v1", "created": "Sat, 6 Oct 2012 08:39:26 GMT"}], "update_date": "2012-10-09", "authors_parsed": [["Bliem", "Bernhard", ""], ["Morak", "Michael", ""], ["Woltran", "Stefan", ""]]}, {"id": "1210.2164", "submitter": "Yuheng Hu", "authors": "Yuheng Hu, Ajita John, Fei Wang, Doree Duncan Seligmann, Subbarao\n  Kambhampati", "title": "ET-LDA: Joint Topic Modeling For Aligning, Analyzing and Sensemaking of\n  Public Events and Their Twitter Feeds", "comments": "errors in reference, delete for now", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.SI physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Social media channels such as Twitter have emerged as popular platforms for\ncrowds to respond to public events such as speeches, sports and debates. While\nthis promises tremendous opportunities to understand and make sense of the\nreception of an event from the social media, the promises come entwined with\nsignificant technical challenges. In particular, given an event and an\nassociated large scale collection of tweets, we need approaches to effectively\nalign tweets and the parts of the event they refer to. This in turn raises\nquestions about how to segment the event into smaller yet meaningful parts, and\nhow to figure out whether a tweet is a general one about the entire event or\nspecific one aimed at a particular segment of the event. In this work, we\npresent ET-LDA, an effective method for aligning an event and its tweets\nthrough joint statistical modeling of topical influences from the events and\ntheir associated tweets. The model enables the automatic segmentation of the\nevents and the characterization of tweets into two categories: (1) episodic\ntweets that respond specifically to the content in the segments of the events,\nand (2) steady tweets that respond generally about the events. We present an\nefficient inference method for this model, and a comprehensive evaluation of\nits effectiveness over existing methods. In particular, through a user study,\nwe demonstrate that users find the topics, the segments, the alignment, and the\nepisodic tweets discovered by ET-LDA to be of higher quality and more\ninteresting as compared to the state-of-the-art, with improvements in the range\nof 18-41%.\n", "versions": [{"version": "v1", "created": "Mon, 8 Oct 2012 07:24:38 GMT"}, {"version": "v2", "created": "Sun, 21 Oct 2012 08:57:20 GMT"}, {"version": "v3", "created": "Fri, 21 Dec 2012 05:48:55 GMT"}], "update_date": "2012-12-24", "authors_parsed": [["Hu", "Yuheng", ""], ["John", "Ajita", ""], ["Wang", "Fei", ""], ["Seligmann", "Doree Duncan", ""], ["Kambhampati", "Subbarao", ""]]}, {"id": "1210.2195", "submitter": "J\\\"org P\\\"uhrer", "authors": "Marina De Vos, Do\\u{g}a Gizem K{\\i}za, Johannes Oetsch, J\\\"org\n  P\\\"uhrer, Hans Tompits", "title": "Annotating Answer-Set Programs in LANA?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While past research in answer-set programming (ASP) mainly focused on theory,\nASP solver technology, and applications, the present work situates itself in\nthe context of a quite recent research trend: development support for ASP. In\nparticular, we propose to augment answer-set programs with additional\nmeta-information formulated in a dedicated annotation language, called LANA.\nThis language allows the grouping of rules into coherent blocks and to specify\nlanguage signatures, types, pre- and postconditions, as well as unit tests for\nsuch blocks. While these annotations are invisible to an ASP solver, as they\ntake the form of program comments, they can be interpreted by tools for\ndocumentation, testing, and verification purposes, as well as to eliminate\nsources of common programming errors by realising syntax checking or code\ncompletion features. To demonstrate its versatility, we introduce two such\ntools, viz. (i) ASPDOC, for generating an HTML documentation for a program\nbased on the annotated information, and (ii) ASPUNIT, for running and\nmonitoring unit tests on program blocks. LANA is also exploited in the SeaLion\nsystem, an integrated development environment for ASP based on Eclipse. To\nappear in Theory and Practice of Logic Programming\n", "versions": [{"version": "v1", "created": "Mon, 8 Oct 2012 09:26:15 GMT"}], "update_date": "2012-10-09", "authors_parsed": [["De Vos", "Marina", ""], ["K\u0131za", "Do\u011fa Gizem", ""], ["Oetsch", "Johannes", ""], ["P\u00fchrer", "J\u00f6rg", ""], ["Tompits", "Hans", ""]]}, {"id": "1210.2316", "submitter": "Mario Alviano", "authors": "Mario Alviano, Wolfgang Faber, Nicola Leone and Marco Manna", "title": "Disjunctive Datalog with Existential Quantifiers: Semantics,\n  Decidability, and Complexity Issues", "comments": "18 pages, 1 figure, 1 table, 1 procedure, presented at ICLP 2012", "journal-ref": "Theory and Practice of Logic Programming 12 (4-5): 701-718, 2012", "doi": "10.1017/S1471068412000257", "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Datalog is one of the best-known rule-based languages, and extensions of it\nare used in a wide context of applications. An important Datalog extension is\nDisjunctive Datalog, which significantly increases the expressivity of the\nbasic language. Disjunctive Datalog is useful in a wide range of applications,\nranging from Databases (e.g., Data Integration) to Artificial Intelligence\n(e.g., diagnosis and planning under incomplete knowledge). However, in recent\nyears an important shortcoming of Datalog-based languages became evident, e.g.\nin the context of data-integration (consistent query-answering, ontology-based\ndata access) and Semantic Web applications: The language does not permit any\ngeneration of and reasoning with unnamed individuals in an obvious way. In\ngeneral, it is weak in supporting many cases of existential quantification. To\novercome this problem, Datalogex has recently been proposed, which extends\ntraditional Datalog by existential quantification in rule heads. In this work,\nwe propose a natural extension of Disjunctive Datalog and Datalogex, called\nDatalogexor, which allows both disjunctions and existential quantification in\nrule heads and is therefore an attractive language for knowledge representation\nand reasoning, especially in domains where ontology-based reasoning is needed.\nWe formally define syntax and semantics of the language Datalogexor, and\nprovide a notion of instantiation, which we prove to be adequate for\nDatalogexor. A main issue of Datalogex and hence also of Datalogexor is that\ndecidability is no longer guaranteed for typical reasoning tasks. In order to\naddress this issue, we identify many decidable fragments of the language, which\nextend, in a natural way, analog classes defined in the non-disjunctive case.\nMoreover, we carry out an in-depth complexity analysis, deriving interesting\nresults which range from Logarithmic Space to Exponential Time.\n", "versions": [{"version": "v1", "created": "Mon, 8 Oct 2012 15:49:41 GMT"}], "update_date": "2012-10-09", "authors_parsed": [["Alviano", "Mario", ""], ["Faber", "Wolfgang", ""], ["Leone", "Nicola", ""], ["Manna", "Marco", ""]]}, {"id": "1210.2421", "submitter": "Mohammed El-Dosuky", "authors": "M. A. El-Dosuky, M. Z. Rashad, T. T. Hamza, A.H. EL-Bassiouny", "title": "Simulated Tom Thumb, the Rule Of Thumb for Autonomous Robots", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For a mobile robot to be truly autonomous, it must solve the simultaneous\nlocalization and mapping (SLAM) problem. We develop a new metaheuristic\nalgorithm called Simulated Tom Thumb (STT), based on the detailed adventure of\nthe clever Tom Thumb and advances in researches relating to path planning based\non potential functions. Investigations show that it is very promising and could\nbe seen as an optimization of the powerful solution of SLAM with data\nassociation and learning capabilities. STT outperform JCBB. The performance is\n100 % match.\n", "versions": [{"version": "v1", "created": "Mon, 8 Oct 2012 21:06:59 GMT"}], "update_date": "2012-10-10", "authors_parsed": [["El-Dosuky", "M. A.", ""], ["Rashad", "M. Z.", ""], ["Hamza", "T. T.", ""], ["EL-Bassiouny", "A. H.", ""]]}, {"id": "1210.2429", "submitter": "Mario Frank", "authors": "Mario Frank, Ben Dong, Adrienne Porter Felt, Dawn Song", "title": "Mining Permission Request Patterns from Android and Facebook\n  Applications (extended author version)", "comments": "To be presented at the IEEE International Conference on Data Mining\n  (ICDM) in Brussels, Belgium. This extended author version contains additional\n  analysis of the dataset(price distribution, rating distribution), more\n  details about model-order selection, and more experiments. Please download\n  the dataset from http://www.mariofrank.net/andrApps/index.html", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Android and Facebook provide third-party applications with access to users'\nprivate data and the ability to perform potentially sensitive operations (e.g.,\npost to a user's wall or place phone calls). As a security measure, these\nplatforms restrict applications' privileges with permission systems: users must\napprove the permissions requested by applications before the applications can\nmake privacy- or security-relevant API calls. However, recent studies have\nshown that users often do not understand permission requests and lack a notion\nof typicality of requests. As a first step towards simplifying permission\nsystems, we cluster a corpus of 188,389 Android applications and 27,029\nFacebook applications to find patterns in permission requests. Using a method\nfor Boolean matrix factorization for finding overlapping clusters, we find that\nFacebook permission requests follow a clear structure that exhibits high\nstability when fitted with only five clusters, whereas Android applications\ndemonstrate more complex permission requests. We also find that low-reputation\napplications often deviate from the permission request patterns that we\nidentified for high-reputation applications suggesting that permission request\npatterns are indicative for user satisfaction or application quality.\n", "versions": [{"version": "v1", "created": "Mon, 8 Oct 2012 21:54:22 GMT"}], "update_date": "2012-10-10", "authors_parsed": [["Frank", "Mario", ""], ["Dong", "Ben", ""], ["Felt", "Adrienne Porter", ""], ["Song", "Dawn", ""]]}, {"id": "1210.2629", "submitter": "Dimitris Arabadjis", "authors": "Dimitris Arabadjis, Panayiotis Rousopoulos, Constantin Papaodysseus,\n  Michalis Exarhos, Michalis Panagopoulos and Lena Papazoglou-Manioudaki", "title": "Optimization in Differentiable Manifolds in Order to Determine the\n  Method of Construction of Prehistoric Wall-Paintings", "comments": null, "journal-ref": "IEEE Transactions on Pattern Analysis and Machine Intelligence,\n  vol. 33, no. 11, pp. 2229-2244, November 2011", "doi": "10.1109/TPAMI.2011.65", "report-no": null, "categories": "cs.CV cs.AI cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper a general methodology is introduced for the determination of\npotential prototype curves used for the drawing of prehistoric wall-paintings.\nThe approach includes a) preprocessing of the wall-paintings contours to\nproperly partition them, according to their curvature, b) choice of prototype\ncurves families, c) analysis and optimization in 4-manifold for a first\nestimation of the form of these prototypes, d) clustering of the contour parts\nand the prototypes, to determine a minimal number of potential guides, e)\nfurther optimization in 4-manifold, applied to each cluster separately, in\norder to determine the exact functional form of the potential guides, together\nwith the corresponding drawn contour parts. The introduced methodology\nsimultaneously deals with two problems: a) the arbitrariness in data-points\norientation and b) the determination of one proper form for a prototype curve\nthat optimally fits the corresponding contour data. Arbitrariness in\norientation has been dealt with a novel curvature based error, while the proper\nforms of curve prototypes have been exhaustively determined by embedding\ncurvature deformations of the prototypes into 4-manifolds. Application of this\nmethodology to celebrated wall-paintings excavated at Tyrins, Greece and the\nGreek island of Thera, manifests it is highly probable that these\nwall-paintings had been drawn by means of geometric guides that correspond to\nlinear spirals and hyperbolae. These geometric forms fit the drawings' lines\nwith an exceptionally low average error, less than 0.39mm. Hence, the approach\nsuggests the existence of accurate realizations of complicated geometric\nentities, more than 1000 years before their axiomatic formulation in Classical\nAges.\n", "versions": [{"version": "v1", "created": "Tue, 9 Oct 2012 15:03:16 GMT"}], "update_date": "2016-11-15", "authors_parsed": [["Arabadjis", "Dimitris", ""], ["Rousopoulos", "Panayiotis", ""], ["Papaodysseus", "Constantin", ""], ["Exarhos", "Michalis", ""], ["Panagopoulos", "Michalis", ""], ["Papazoglou-Manioudaki", "Lena", ""]]}, {"id": "1210.2640", "submitter": "Eric Eaton", "authors": "Eric Eaton, Marie desJardins, Sara Jacob", "title": "Multi-view constrained clustering with an incomplete mapping between\n  views", "comments": null, "journal-ref": "Knowledge and Information Systems 38(1): 231-257, 2014", "doi": "10.1007/s10115-012-0577-7", "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-view learning algorithms typically assume a complete bipartite mapping\nbetween the different views in order to exchange information during the\nlearning process. However, many applications provide only a partial mapping\nbetween the views, creating a challenge for current methods. To address this\nproblem, we propose a multi-view algorithm based on constrained clustering that\ncan operate with an incomplete mapping. Given a set of pairwise constraints in\neach view, our approach propagates these constraints using a local similarity\nmeasure to those instances that can be mapped to the other views, allowing the\npropagated constraints to be transferred across views via the partial mapping.\nIt uses co-EM to iteratively estimate the propagation within each view based on\nthe current clustering model, transfer the constraints across views, and then\nupdate the clustering model. By alternating the learning process between views,\nthis approach produces a unified clustering model that is consistent with all\nviews. We show that this approach significantly improves clustering performance\nover several other methods for transferring constraints and allows multi-view\nclustering to be reliably applied when given a limited mapping between the\nviews. Our evaluation reveals that the propagated constraints have high\nprecision with respect to the true clusters in the data, explaining their\nbenefit to clustering performance in both single- and multi-view learning\nscenarios.\n", "versions": [{"version": "v1", "created": "Tue, 9 Oct 2012 15:25:01 GMT"}], "update_date": "2014-11-03", "authors_parsed": [["Eaton", "Eric", ""], ["desJardins", "Marie", ""], ["Jacob", "Sara", ""]]}, {"id": "1210.2646", "submitter": "Dimitris Arabadjis", "authors": "Dimitris Arabadjis, Panayiotis Rousopoulos, Constantin Papaodysseus,\n  Michalis Panagopoulos, Panayiota Loumou and Georgios Theodoropoulos", "title": "A General Methodology for the Determination of 2D Bodies Elastic\n  Deformation Invariants. Application to the Automatic Identification of\n  Parasites", "comments": null, "journal-ref": "IEEE Transactions on Pattern Analysis and Machine Intelligence,\n  vol. 32, no. 5, pp. 799-814, 2010", "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A novel methodology is introduced here that exploits 2D images of arbitrary\nelastic body deformation instances, so as to quantify mechano-elastic\ncharacteristics that are deformation invariant. Determination of such\ncharacteristics allows for developing methods offering an image of the\nundeformed body. General assumptions about the mechano-elastic properties of\nthe bodies are stated, which lead to two different approaches for obtaining\nbodies' deformation invariants. One was developed to spot deformed body's\nneutral line and its cross sections, while the other solves deformation PDEs by\nperforming a set of equivalent image operations on the deformed body images.\nBoth these processes may furnish a body undeformed version from its deformed\nimage. This was confirmed by obtaining the undeformed shape of deformed\nparasites, cells (protozoa), fibers and human lips. In addition, the method has\nbeen applied to the important problem of parasite automatic classification from\ntheir microscopic images. To achieve this, we first apply the previous method\nto straighten the highly deformed parasites and then we apply a dedicated curve\nclassification method to the straightened parasite contours. It is demonstrated\nthat essentially different deformations of the same parasite give rise to\npractically the same undeformed shape, thus confirming the consistency of the\nintroduced methodology. Finally, the developed pattern recognition method\nclassifies the unwrapped parasites into 6 families, with an accuracy rate of\n97.6 %.\n", "versions": [{"version": "v1", "created": "Tue, 9 Oct 2012 15:45:23 GMT"}], "update_date": "2012-10-10", "authors_parsed": [["Arabadjis", "Dimitris", ""], ["Rousopoulos", "Panayiotis", ""], ["Papaodysseus", "Constantin", ""], ["Panagopoulos", "Michalis", ""], ["Loumou", "Panayiota", ""], ["Theodoropoulos", "Georgios", ""]]}, {"id": "1210.2715", "submitter": "Dimiter Dobrev", "authors": "Dimiter Dobrev", "title": "AI in arbitrary world", "comments": null, "journal-ref": "5th Panhellenic Logic Symposium, July 2005, University of Athens,\n  Athens, Greece, pp. 62-67", "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In order to build AI we have to create a program which copes well in an\narbitrary world. In this paper we will restrict our attention on one concrete\nworld, which represents the game Tick-Tack-Toe. This world is a very simple one\nbut it is sufficiently complicated for our task because most people cannot\nmanage with it. The main difficulty in this world is that the player cannot see\nthe entire internal state of the world so he has to build a model in order to\nunderstand the world. The model which we will offer will consist of final\nautomata and first order formulas.\n", "versions": [{"version": "v1", "created": "Tue, 9 Oct 2012 08:58:12 GMT"}], "update_date": "2012-10-11", "authors_parsed": [["Dobrev", "Dimiter", ""]]}, {"id": "1210.2984", "submitter": "Francesca A. Lisi", "authors": "Francesca A. Lisi", "title": "Learning Onto-Relational Rules with Inductive Logic Programming", "comments": "18 pages. arXiv admin note: text overlap with arXiv:1003.2586", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.DB cs.LG cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Rules complement and extend ontologies on the Semantic Web. We refer to these\nrules as onto-relational since they combine DL-based ontology languages and\nKnowledge Representation formalisms supporting the relational data model within\nthe tradition of Logic Programming and Deductive Databases. Rule authoring is a\nvery demanding Knowledge Engineering task which can be automated though\npartially by applying Machine Learning algorithms. In this chapter we show how\nInductive Logic Programming (ILP), born at the intersection of Machine Learning\nand Logic Programming and considered as a major approach to Relational\nLearning, can be adapted to Onto-Relational Learning. For the sake of\nillustration, we provide details of a specific Onto-Relational Learning\nsolution to the problem of learning rule-based definitions of DL concepts and\nroles with ILP.\n", "versions": [{"version": "v1", "created": "Wed, 10 Oct 2012 16:56:41 GMT"}, {"version": "v2", "created": "Mon, 29 Oct 2012 18:25:34 GMT"}], "update_date": "2012-10-30", "authors_parsed": [["Lisi", "Francesca A.", ""]]}, {"id": "1210.3241", "submitter": "Vit Novacek", "authors": "Vit Novacek", "title": "Distributional Framework for Emergent Knowledge Acquisition and its\n  Application to Automated Document Annotation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper introduces a framework for representation and acquisition of\nknowledge emerging from large samples of textual data. We utilise a\ntensor-based, distributional representation of simple statements extracted from\ntext, and show how one can use the representation to infer emergent knowledge\npatterns from the textual data in an unsupervised manner. Examples of the\npatterns we investigate in the paper are implicit term relationships or\nconjunctive IF-THEN rules. To evaluate the practical relevance of our approach,\nwe apply it to annotation of life science articles with terms from MeSH (a\ncontrolled biomedical vocabulary and thesaurus).\n", "versions": [{"version": "v1", "created": "Thu, 11 Oct 2012 14:10:25 GMT"}], "update_date": "2012-10-12", "authors_parsed": [["Novacek", "Vit", ""]]}, {"id": "1210.3265", "submitter": "Martin Gebser", "authors": "Martin Gebser, Benjamin Kaufmann, Torsten Schaub", "title": "Multi-threaded ASP Solving with clasp", "comments": "19 pages, 5 figures, to appear in Theory and Practice of Logic\n  Programming", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present the new multi-threaded version of the state-of-the-art answer set\nsolver clasp. We detail its component and communication architecture and\nillustrate how they support the principal functionalities of clasp. Also, we\nprovide some insights into the data representation used for different\nconstraint types handled by clasp. All this is accompanied by an extensive\nexperimental analysis of the major features related to multi-threading in\nclasp.\n", "versions": [{"version": "v1", "created": "Thu, 11 Oct 2012 15:06:28 GMT"}], "update_date": "2012-10-12", "authors_parsed": [["Gebser", "Martin", ""], ["Kaufmann", "Benjamin", ""], ["Schaub", "Torsten", ""]]}, {"id": "1210.3312", "submitter": "Juan Manuel Torres Moreno", "authors": "Juan-Manuel Torres-Moreno", "title": "Artex is AnotheR TEXt summarizer", "comments": "11 pages, 5 figures. arXiv admin note: substantial text overlap with\n  arXiv:1209.3126", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.CL", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  This paper describes Artex, another algorithm for Automatic Text\nSummarization. In order to rank sentences, a simple inner product is calculated\nbetween each sentence, a document vector (text topic) and a lexical vector\n(vocabulary used by a sentence). Summaries are then generated by assembling the\nhighest ranked sentences. No ruled-based linguistic post-processing is\nnecessary in order to obtain summaries. Tests over several datasets (coming\nfrom Document Understanding Conferences (DUC), Text Analysis Conferences (TAC),\nevaluation campaigns, etc.) in French, English and Spanish have shown that\nsummarizer achieves interesting results.\n", "versions": [{"version": "v1", "created": "Thu, 11 Oct 2012 18:21:01 GMT"}], "update_date": "2012-10-12", "authors_parsed": [["Torres-Moreno", "Juan-Manuel", ""]]}, {"id": "1210.3375", "submitter": "Ben Aissa  Ezzeddine", "authors": "Benaissa Ezzeddine and Benabdelhafid Abdellatif and Benaissa Mounir", "title": "An Agent-based framework for cooperation in Supply Chain", "comments": "IJCSI International Journal of Computer Science Issues, Vol. 9, Issue\n  5, No 3, September 2012", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Supply Chain coordination has become a critical success factor for Supply\nChain management (SCM) and effectively improving the performance of\norganizations in various industries. Companies are increasingly located at the\nintersection of one or more corporate networks which are designated by \"Supply\nChain\". Managing this chain is mainly based on an 'information sharing' and\nredeployment activities between the various links that comprise it. Several\nattempts have been made by industrialists and researchers to educate\npolicymakers about the gains to be made by the implementation of cooperative\nrelationships. The approach presented in this paper here is among the works\nthat aim to propose solutions related to information systems distributed Supply\nChains to enable the different actors of the chain to improve their\nperformance. We propose in particular solutions that focus on cooperation\nbetween actors in the Supply Chain.\n", "versions": [{"version": "v1", "created": "Thu, 11 Oct 2012 21:10:41 GMT"}], "update_date": "2012-10-15", "authors_parsed": [["Ezzeddine", "Benaissa", ""], ["Abdellatif", "Benabdelhafid", ""], ["Mounir", "Benaissa", ""]]}, {"id": "1210.3587", "submitter": "Bo Zong", "authors": "Bo Zong, Yinghui Wu, Ambuj K. Singh, Xifeng Yan", "title": "Inferring the Underlying Structure of Information Cascades", "comments": "The extended version of the paper \"Inferring the Underlying Structure\n  of Information Cascades\", to appear in ICDM'12", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.AI physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In social networks, information and influence diffuse among users as\ncascades. While the importance of studying cascades has been recognized in\nvarious applications, it is difficult to observe the complete structure of\ncascades in practice. Moreover, much less is known on how to infer cascades\nbased on partial observations. In this paper we study the cascade inference\nproblem following the independent cascade model, and provide a full treatment\nfrom complexity to algorithms: (a) We propose the idea of consistent trees as\nthe inferred structures for cascades; these trees connect source nodes and\nobserved nodes with paths satisfying the constraints from the observed temporal\ninformation. (b) We introduce metrics to measure the likelihood of consistent\ntrees as inferred cascades, as well as several optimization problems for\nfinding them. (c) We show that the decision problems for consistent trees are\nin general NP-complete, and that the optimization problems are hard to\napproximate. (d) We provide approximation algorithms with performance\nguarantees on the quality of the inferred cascades, as well as heuristics. We\nexperimentally verify the efficiency and effectiveness of our inference\nalgorithms, using real and synthetic data.\n", "versions": [{"version": "v1", "created": "Fri, 12 Oct 2012 18:04:45 GMT"}], "update_date": "2012-10-15", "authors_parsed": [["Zong", "Bo", ""], ["Wu", "Yinghui", ""], ["Singh", "Ambuj K.", ""], ["Yan", "Xifeng", ""]]}, {"id": "1210.3634", "submitter": "Robert Wahsltedt", "authors": "Robert Wahlstedt", "title": "Quick Summary", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  Quick Summary is an innovate implementation of an automatic document\nsummarizer that inputs a document in the English language and evaluates each\nsentence. The scanner or evaluator determines criteria based on its grammatical\nstructure and place in the paragraph. The program then asks the user to specify\nthe number of sentences the person wishes to highlight. For example should the\nuser ask to have three of the most important sentences, it would highlight the\nfirst and most important sentence in green. Commonly this is the sentence\ncontaining the conclusion. Then Quick Summary finds the second most important\nsentence usually called a satellite and highlights it in yellow. This is\nusually the topic sentence. Then the program finds the third most important\nsentence and highlights it in red. The implementations of this technology are\nuseful in a society of information overload when a person typically receives 42\nemails a day (Microsoft). The paper also is a candid look at difficulty that\nmachine learning has in textural translating. However, it speaks on how to\novercome the obstacles that historically prevented progress. This paper\nproposes mathematical meta-data criteria that justify the place of importance\nof a sentence. Just as tools for the study of relational symmetry in\nbio-informatics, this tool seeks to classify words with greater clarity.\n\"Survey Finds Workers Average Only Three Productive Days per Week.\" Microsoft\nNews Center. Microsoft. Web. 31 Mar. 2012.\n", "versions": [{"version": "v1", "created": "Fri, 12 Oct 2012 20:55:39 GMT"}], "update_date": "2012-10-16", "authors_parsed": [["Wahlstedt", "Robert", ""]]}, {"id": "1210.3865", "submitter": "Chao-Lin Liu", "authors": "Chien-Liang Chen, Chao-Lin Liu, Yuan-Chen Chang, and Hsiang-Ping Tsai", "title": "Opinion Mining for Relating Subjective Expressions and Annual Earnings\n  in US Financial Statements", "comments": "24 pages, 3 figures, 13 tables, partially appeared in two conference\n  proceedings: (1) Proceedings of the IEEE International Conference on\n  e-Business Engineering 2011 and (2) Proceedings of the 2011 Conference on\n  Technologies and Applications of Artificial Intelligence; Journal of\n  Information Science and Engineering, 29(3), May 2013", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR q-fin.GN", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Financial statements contain quantitative information and manager's\nsubjective evaluation of firm's financial status. Using information released in\nU.S. 10-K filings. Both qualitative and quantitative appraisals are crucial for\nquality financial decisions. To extract such opinioned statements from the\nreports, we built tagging models based on the conditional random field (CRF)\ntechniques, considering a variety of combinations of linguistic factors\nincluding morphology, orthography, predicate-argument structure, syntax, and\nsimple semantics. Our results show that the CRF models are reasonably effective\nto find opinion holders in experiments when we adopted the popular MPQA corpus\nfor training and testing. The contribution of our paper is to identify opinion\npatterns in multiword expressions (MWEs) forms rather than in single word\nforms.\n  We find that the managers of corporations attempt to use more optimistic\nwords to obfuscate negative financial performance and to accentuate the\npositive financial performance. Our results also show that decreasing earnings\nwere often accompanied by ambiguous and mild statements in the reporting year\nand that increasing earnings were stated in assertive and positive way.\n", "versions": [{"version": "v1", "created": "Mon, 15 Oct 2012 00:58:11 GMT"}], "update_date": "2012-10-23", "authors_parsed": [["Chen", "Chien-Liang", ""], ["Liu", "Chao-Lin", ""], ["Chang", "Yuan-Chen", ""], ["Tsai", "Hsiang-Ping", ""]]}, {"id": "1210.3937", "submitter": "V\\'itor Santos Costa", "authors": "Agostino Dovier, V\\'itor Santos Costa", "title": "Introduction to the 28th International Conference on Logic Programming\n  Special Issue", "comments": null, "journal-ref": "TPLP 12 (4-5): 421-426, 2012", "doi": "10.1017/S1471068412000300", "report-no": null, "categories": "cs.PL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We are proud to introduce this special issue of the Journal of Theory and\nPractice of Logic Programming (TPLP), dedicated to the full papers accepted for\nthe 28th International Conference on Logic Programming (ICLP). The ICLP\nmeetings started in Marseille in 1982 and since then constitute the main venue\nfor presenting and discussing work in the area of logic programming.\n", "versions": [{"version": "v1", "created": "Mon, 15 Oct 2012 08:31:38 GMT"}], "update_date": "2012-10-16", "authors_parsed": [["Dovier", "Agostino", ""], ["Costa", "V\u00edtor Santos", ""]]}, {"id": "1210.3946", "submitter": "Sebastien Verel", "authors": "Fabio Daolio (ISI), S\\'ebastien Verel (INRIA Lille - Nord Europe),\n  Gabriela Ochoa, Marco Tomassini (ISI)", "title": "Local optima networks and the performance of iterated local search", "comments": "Proceedings of the fourteenth international conference on Genetic and\n  evolutionary computation conference, Philadelphia : United States (2012)", "journal-ref": null, "doi": "10.1145/2330163.2330217", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Local Optima Networks (LONs) have been recently proposed as an alternative\nmodel of combinatorial fitness landscapes. The model compresses the information\ngiven by the whole search space into a smaller mathematical object that is the\ngraph having as vertices the local optima and as edges the possible weighted\ntransitions between them. A new set of metrics can be derived from this model\nthat capture the distribution and connectivity of the local optima in the\nunderlying configuration space. This paper departs from the descriptive\nanalysis of local optima networks, and actively studies the correlation between\nnetwork features and the performance of a local search heuristic. The NK family\nof landscapes and the Iterated Local Search metaheuristic are considered. With\na statistically-sound approach based on multiple linear regression, it is shown\nthat some LONs' features strongly influence and can even partly predict the\nperformance of a heuristic search algorithm. This study validates the\nexpressive power of LONs as a model of combinatorial fitness landscapes.\n", "versions": [{"version": "v1", "created": "Mon, 15 Oct 2012 09:11:57 GMT"}], "update_date": "2012-10-16", "authors_parsed": [["Daolio", "Fabio", "", "ISI"], ["Verel", "S\u00e9bastien", "", "INRIA Lille - Nord Europe"], ["Ochoa", "Gabriela", "", "ISI"], ["Tomassini", "Marco", "", "ISI"]]}, {"id": "1210.4021", "submitter": "Sebastien Verel", "authors": "Francisco Chicano, Fabio Daolio (ISI), Gabriela Ochoa, S\\'ebastien\n  Verel (INRIA Lille - Nord Europe), Marco Tomassini (ISI), Enrique Alba", "title": "Local Optima Networks, Landscape Autocorrelation and Heuristic Search\n  Performance", "comments": "Parallel Problem Solving from Nature - PPSN XII, Taormina : Italy\n  (2012)", "journal-ref": null, "doi": "10.1007/978-3-642-32964-7_34", "report-no": null, "categories": "cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent developments in fitness landscape analysis include the study of Local\nOptima Networks (LON) and applications of the Elementary Landscapes theory.\nThis paper represents a first step at combining these two tools to explore\ntheir ability to forecast the performance of search algorithms. We base our\nanalysis on the Quadratic Assignment Problem (QAP) and conduct a large\nstatistical study over 600 generated instances of different types. Our results\nreveal interesting links between the network measures, the autocorrelation\nmeasures and the performance of heuristic search algorithms.\n", "versions": [{"version": "v1", "created": "Mon, 15 Oct 2012 13:28:11 GMT"}], "update_date": "2012-10-16", "authors_parsed": [["Chicano", "Francisco", "", "ISI"], ["Daolio", "Fabio", "", "ISI"], ["Ochoa", "Gabriela", "", "INRIA Lille - Nord Europe"], ["Verel", "S\u00e9bastien", "", "INRIA Lille - Nord Europe"], ["Tomassini", "Marco", "", "ISI"], ["Alba", "Enrique", ""]]}, {"id": "1210.4130", "submitter": "Fangkai Yang", "authors": "Vladimir Lifschitz, Karl Pichotta, and Fangkai Yang", "title": "Relational Theories with Null Values and Non-Herbrand Stable Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generalized relational theories with null values in the sense of Reiter are\nfirst-order theories that provide a semantics for relational databases with\nincomplete information. In this paper we show that any such theory can be\nturned into an equivalent logic program, so that models of the theory can be\ngenerated using computational methods of answer set programming. As a step\ntowards this goal, we develop a general method for calculating stable models\nunder the domain closure assumption but without the unique name assumption.\n", "versions": [{"version": "v1", "created": "Mon, 15 Oct 2012 18:10:13 GMT"}], "update_date": "2012-10-16", "authors_parsed": [["Lifschitz", "Vladimir", ""], ["Pichotta", "Karl", ""], ["Yang", "Fangkai", ""]]}, {"id": "1210.4184", "submitter": "Sotirios Chatzis", "authors": "Sotirios P. Chatzis and Dimitrios Korkinof and Yiannis Demiris", "title": "The Kernel Pitman-Yor Process", "comments": "This is a Technical Report summarizing our ongoing work on the Kernel\n  Pitman-Yor Process. Experiments will be added by D. Korkinof prior to journal\n  or conference submission", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we propose the kernel Pitman-Yor process (KPYP) for\nnonparametric clustering of data with general spatial or temporal\ninterdependencies. The KPYP is constructed by first introducing an infinite\nsequence of random locations. Then, based on the stick-breaking construction of\nthe Pitman-Yor process, we define a predictor-dependent random probability\nmeasure by considering that the discount hyperparameters of the\nBeta-distributed random weights (stick variables) of the process are not\nuniform among the weights, but controlled by a kernel function expressing the\nproximity between the location assigned to each weight and the given\npredictors.\n", "versions": [{"version": "v1", "created": "Mon, 15 Oct 2012 20:14:23 GMT"}], "update_date": "2012-10-17", "authors_parsed": [["Chatzis", "Sotirios P.", ""], ["Korkinof", "Dimitrios", ""], ["Demiris", "Yiannis", ""]]}, {"id": "1210.4231", "submitter": "Alban  Grastien", "authors": "Alban Grastien", "title": "An example illustrating the imprecision of the efficient approach for\n  diagnosis of Petri nets via integer linear programming", "comments": "3 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SY cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This document demonstrates that the efficient approach for diagnosis of Petri\nnets via integer linear programming may be unable to detect a fault even if the\nsystem is diagnosable.\n", "versions": [{"version": "v1", "created": "Tue, 16 Oct 2012 02:10:38 GMT"}], "update_date": "2012-10-17", "authors_parsed": [["Grastien", "Alban", ""]]}, {"id": "1210.4840", "submitter": "Guy Van den Broeck", "authors": "Guy Van den Broeck, Arthur Choi, Adnan Darwiche", "title": "Lifted Relax, Compensate and then Recover: From Approximate to Exact\n  Lifted Probabilistic Inference", "comments": "Appears in Proceedings of the Twenty-Eighth Conference on Uncertainty\n  in Artificial Intelligence (UAI2012)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2012-PG-131-141", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an approach to lifted approximate inference for first-order\nprobabilistic models, such as Markov logic networks. It is based on performing\nexact lifted inference in a simplified first-order model, which is found by\nrelaxing first-order constraints, and then compensating for the relaxation.\nThese simplified models can be incrementally improved by carefully recovering\nconstraints that have been relaxed, also at the first-order level. This leads\nto a spectrum of approximations, with lifted belief propagation on one end, and\nexact lifted inference on the other. We discuss how relaxation, compensation,\nand recovery can be performed, all at the firstorder level, and show\nempirically that our approach substantially improves on the approximations of\nboth propositional solvers and lifted belief propagation.\n", "versions": [{"version": "v1", "created": "Tue, 16 Oct 2012 17:32:23 GMT"}], "update_date": "2012-10-19", "authors_parsed": [["Broeck", "Guy Van den", ""], ["Choi", "Arthur", ""], ["Darwiche", "Adnan", ""]]}, {"id": "1210.4841", "submitter": "Dhruv Batra", "authors": "Dhruv Batra", "title": "An Efficient Message-Passing Algorithm for the M-Best MAP Problem", "comments": "Appears in Proceedings of the Twenty-Eighth Conference on Uncertainty\n  in Artificial Intelligence (UAI2012)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2012-PG-121-130", "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Much effort has been directed at algorithms for obtaining the highest\nprobability configuration in a probabilistic random field model known as the\nmaximum a posteriori (MAP) inference problem. In many situations, one could\nbenefit from having not just a single solution, but the top M most probable\nsolutions known as the M-Best MAP problem. In this paper, we propose an\nefficient message-passing based algorithm for solving the M-Best MAP problem.\nSpecifically, our algorithm solves the recently proposed Linear Programming\n(LP) formulation of M-Best MAP [7], while being orders of magnitude faster than\na generic LP-solver. Our approach relies on studying a particular partial\nLagrangian relaxation of the M-Best MAP LP which exposes a natural\ncombinatorial structure of the problem that we exploit.\n", "versions": [{"version": "v1", "created": "Tue, 16 Oct 2012 17:32:34 GMT"}], "update_date": "2012-10-19", "authors_parsed": [["Batra", "Dhruv", ""]]}, {"id": "1210.4842", "submitter": "Elias Bareinboim", "authors": "Elias Bareinboim, Judea Pearl", "title": "Causal Inference by Surrogate Experiments: z-Identifiability", "comments": "Appears in Proceedings of the Twenty-Eighth Conference on Uncertainty\n  in Artificial Intelligence (UAI2012)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2012-PG-113-120", "categories": "cs.AI stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the problem of estimating the effect of intervening on a set of\nvariables X from experiments on a different set, Z, that is more accessible to\nmanipulation. This problem, which we call z-identifiability, reduces to\nordinary identifiability when Z = empty and, like the latter, can be given\nsyntactic characterization using the do-calculus [Pearl, 1995; 2000]. We\nprovide a graphical necessary and sufficient condition for z-identifiability\nfor arbitrary sets X,Z, and Y (the outcomes). We further develop a complete\nalgorithm for computing the causal effect of X on Y using information provided\nby experiments on Z. Finally, we use our results to prove completeness of\ndo-calculus relative to z-identifiability, a result that does not follow from\ncompleteness relative to ordinary identifiability.\n", "versions": [{"version": "v1", "created": "Tue, 16 Oct 2012 17:32:47 GMT"}], "update_date": "2012-10-19", "authors_parsed": [["Bareinboim", "Elias", ""], ["Pearl", "Judea", ""]]}, {"id": "1210.4845", "submitter": "Udi Apsel", "authors": "Udi Apsel, Ronen I. Brafman", "title": "Exploiting Uniform Assignments in First-Order MPE", "comments": "Appears in Proceedings of the Twenty-Eighth Conference on Uncertainty\n  in Artificial Intelligence (UAI2012)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2012-PG-74-83", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The MPE (Most Probable Explanation) query plays an important role in\nprobabilistic inference. MPE solution algorithms for probabilistic relational\nmodels essentially adapt existing belief assessment method, replacing summation\nwith maximization. But the rich structure and symmetries captured by relational\nmodels together with the properties of the maximization operator offer an\nopportunity for additional simplification with potentially significant\ncomputational ramifications. Specifically, these models often have groups of\nvariables that define symmetric distributions over some population of formulas.\nThe maximizing choice for different elements of this group is the same. If we\ncan realize this ahead of time, we can significantly reduce the size of the\nmodel by eliminating a potentially significant portion of random variables.\nThis paper defines the notion of uniformly assigned and partially uniformly\nassigned sets of variables, shows how one can recognize these sets efficiently,\nand how the model can be greatly simplified once we recognize them, with little\ncomputational effort. We demonstrate the effectiveness of these ideas\nempirically on a number of models.\n", "versions": [{"version": "v1", "created": "Tue, 16 Oct 2012 17:34:35 GMT"}], "update_date": "2012-10-19", "authors_parsed": [["Apsel", "Udi", ""], ["Brafman", "Ronen I.", ""]]}, {"id": "1210.4849", "submitter": "Lucas Agussurja", "authors": "Lucas Agussurja, Hoong Chuin Lau", "title": "Toward Large-Scale Agent Guidance in an Urban Taxi Service", "comments": "Appears in Proceedings of the Twenty-Eighth Conference on Uncertainty\n  in Artificial Intelligence (UAI2012)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2012-PG-36-43", "categories": "cs.MA cs.AI cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Empty taxi cruising represents a wastage of resources in the context of urban\ntaxi services. In this work, we seek to minimize such wastage. An analysis of a\nlarge trace of taxi operations reveals that the services' inefficiency is\ncaused by drivers' greedy cruising behavior. We model the existing system as a\ncontinuous time Markov chain. To address the problem, we propose that each taxi\nbe equipped with an intelligent agent that will guide the driver when cruising\nfor passengers. Then, drawing from AI literature on multiagent planning, we\nexplore two possible ways to compute such guidance. The first formulation\nassumes fully cooperative drivers. This allows us, in principle, to compute\nsystemwide optimal cruising policy. This is modeled as a Markov decision\nprocess. The second formulation assumes rational drivers, seeking to maximize\ntheir own profit. This is modeled as a stochastic congestion game, a\nspecialization of stochastic games. Nash equilibrium policy is proposed as the\nsolution to the game, where no driver has the incentive to singly deviate from\nit. Empirical result shows that both formulations improve the efficiency of the\nservice significantly.\n", "versions": [{"version": "v1", "created": "Tue, 16 Oct 2012 17:35:25 GMT"}], "update_date": "2012-10-19", "authors_parsed": [["Agussurja", "Lucas", ""], ["Lau", "Hoong Chuin", ""]]}, {"id": "1210.4852", "submitter": "Judea Pearl", "authors": "Judea Pearl", "title": "The Do-Calculus Revisited", "comments": "Appears in Proceedings of the Twenty-Eighth Conference on Uncertainty\n  in Artificial Intelligence (UAI2012)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2012-PG-3-11", "categories": "cs.AI stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The do-calculus was developed in 1995 to facilitate the identification of\ncausal effects in non-parametric models. The completeness proofs of [Huang and\nValtorta, 2006] and [Shpitser and Pearl, 2006] and the graphical criteria of\n[Tian and Shpitser, 2010] have laid this identification problem to rest. Recent\nexplorations unveil the usefulness of the do-calculus in three additional\nareas: mediation analysis [Pearl, 2012], transportability [Pearl and\nBareinboim, 2011] and metasynthesis. Meta-synthesis (freshly coined) is the\ntask of fusing empirical results from several diverse studies, conducted on\nheterogeneous populations and under different conditions, so as to synthesize\nan estimate of a causal relation in some target environment, potentially\ndifferent from those under study. The talk surveys these results with emphasis\non the challenges posed by meta-synthesis. For background material, see\nhttp://bayes.cs.ucla.edu/csl_papers.html\n", "versions": [{"version": "v1", "created": "Tue, 16 Oct 2012 17:36:07 GMT"}], "update_date": "2012-10-19", "authors_parsed": [["Pearl", "Judea", ""]]}, {"id": "1210.4853", "submitter": "Joseph Y. Halpern", "authors": "Joseph Y. Halpern, Samantha Leung", "title": "Weighted Sets of Probabilities and MinimaxWeighted Expected Regret: New\n  Approaches for Representing Uncertainty and Making Decisions", "comments": "Appears in Proceedings of the Twenty-Eighth Conference on Uncertainty\n  in Artificial Intelligence (UAI2012). For full version of this article, see\n  arXiv:1302.5681", "journal-ref": null, "doi": null, "report-no": "UAI-P-2012-PG-336-345", "categories": "cs.GT cs.AI q-fin.TR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a setting where an agent's uncertainty is represented by a set of\nprobability measures, rather than a single measure. Measure-bymeasure updating\nof such a set of measures upon acquiring new information is well-known to\nsuffer from problems; agents are not always able to learn appropriately. To\ndeal with these problems, we propose using weighted sets of probabilities: a\nrepresentation where each measure is associated with a weight, which denotes\nits significance. We describe a natural approach to updating in such a\nsituation and a natural approach to determining the weights. We then show how\nthis representation can be used in decision-making, by modifying a standard\napproach to decision making-minimizing expected regret-to obtain minimax\nweighted expected regret (MWER).We provide an axiomatization that characterizes\npreferences induced by MWER both in the static and dynamic case.\n", "versions": [{"version": "v1", "created": "Tue, 16 Oct 2012 17:37:06 GMT"}], "update_date": "2013-02-26", "authors_parsed": [["Halpern", "Joseph Y.", ""], ["Leung", "Samantha", ""]]}, {"id": "1210.4854", "submitter": "Hannaneh Hajishirzi", "authors": "Hannaneh Hajishirzi, Mohammad Rastegari, Ali Farhadi, Jessica K.\n  Hodgins", "title": "Semantic Understanding of Professional Soccer Commentaries", "comments": "Appears in Proceedings of the Twenty-Eighth Conference on Uncertainty\n  in Artificial Intelligence (UAI2012)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2012-PG-326-335", "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a novel approach to the problem of semantic parsing via\nlearning the correspondences between complex sentences and rich sets of events.\nOur main intuition is that correct correspondences tend to occur more\nfrequently. Our model benefits from a discriminative notion of similarity to\nlearn the correspondence between sentence and an event and a ranking machinery\nthat scores the popularity of each correspondence. Our method can discover a\ngroup of events (called macro-events) that best describes a sentence. We\nevaluate our method on our novel dataset of professional soccer commentaries.\nThe empirical results show that our method significantly outperforms the\nstate-of-theart.\n", "versions": [{"version": "v1", "created": "Tue, 16 Oct 2012 17:37:21 GMT"}], "update_date": "2012-10-19", "authors_parsed": [["Hajishirzi", "Hannaneh", ""], ["Rastegari", "Mohammad", ""], ["Farhadi", "Ali", ""], ["Hodgins", "Jessica K.", ""]]}, {"id": "1210.4857", "submitter": "Andrew E. Gelfand", "authors": "Andrew E. Gelfand, Max Welling", "title": "Generalized Belief Propagation on Tree Robust Structured Region Graphs", "comments": "Appears in Proceedings of the Twenty-Eighth Conference on Uncertainty\n  in Artificial Intelligence (UAI2012)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2012-PG-296-305", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper provides some new guidance in the construction of region graphs\nfor Generalized Belief Propagation (GBP). We connect the problem of choosing\nthe outer regions of a LoopStructured Region Graph (SRG) to that of finding a\nfundamental cycle basis of the corresponding Markov network. We also define a\nnew class of tree-robust Loop-SRG for which GBP on any induced (spanning) tree\nof the Markov network, obtained by setting to zero the off-tree interactions,\nis exact. This class of SRG is then mapped to an equivalent class of\ntree-robust cycle bases on the Markov network. We show that a treerobust cycle\nbasis can be identified by proving that for every subset of cycles, the graph\nobtained from the edges that participate in a single cycle only, is multiply\nconnected. Using this we identify two classes of tree-robust cycle bases:\nplanar cycle bases and \"star\" cycle bases. In experiments we show that\ntree-robustness can be successfully exploited as a design principle to improve\nthe accuracy and convergence of GBP.\n", "versions": [{"version": "v1", "created": "Tue, 16 Oct 2012 17:37:52 GMT"}], "update_date": "2012-10-19", "authors_parsed": [["Gelfand", "Andrew E.", ""], ["Welling", "Max", ""]]}, {"id": "1210.4861", "submitter": "Stefano Ermon", "authors": "Stefano Ermon, Carla P. Gomes, Bart Selman", "title": "Uniform Solution Sampling Using a Constraint Solver As an Oracle", "comments": "Appears in Proceedings of the Twenty-Eighth Conference on Uncertainty\n  in Artificial Intelligence (UAI2012)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2012-PG-255-264", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of sampling from solutions defined by a set of hard\nconstraints on a combinatorial space. We propose a new sampling technique that,\nwhile enforcing a uniform exploration of the search space, leverages the\nreasoning power of a systematic constraint solver in a black-box scheme. We\npresent a series of challenging domains, such as energy barriers and highly\nasymmetric spaces, that reveal the difficulties introduced by hard constraints.\nWe demonstrate that standard approaches such as Simulated Annealing and Gibbs\nSampling are greatly affected, while our new technique can overcome many of\nthese difficulties. Finally, we show that our sampling scheme naturally defines\na new approximate model counting technique, which we empirically show to be\nvery accurate on a range of benchmark problems.\n", "versions": [{"version": "v1", "created": "Tue, 16 Oct 2012 17:38:34 GMT"}], "update_date": "2012-10-19", "authors_parsed": [["Ermon", "Stefano", ""], ["Gomes", "Carla P.", ""], ["Selman", "Bart", ""]]}, {"id": "1210.4865", "submitter": "Jilles S. Dibangoye", "authors": "Jilles S. Dibangoye, Christopher Amato, Arnoud Doniec", "title": "Scaling Up Decentralized MDPs Through Heuristic Search", "comments": "Appears in Proceedings of the Twenty-Eighth Conference on Uncertainty\n  in Artificial Intelligence (UAI2012)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2012-PG-217-226", "categories": "cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Decentralized partially observable Markov decision processes (Dec-POMDPs) are\nrich models for cooperative decision-making under uncertainty, but are often\nintractable to solve optimally (NEXP-complete). The transition and observation\nindependent Dec-MDP is a general subclass that has been shown to have\ncomplexity in NP, but optimal algorithms for this subclass are still\ninefficient in practice. In this paper, we first provide an updated proof that\nan optimal policy does not depend on the histories of the agents, but only the\nlocal observations. We then present a new algorithm based on heuristic search\nthat is able to expand search nodes by using constraint optimization. We show\nexperimental results comparing our approach with the state-of-the-art DecMDP\nand Dec-POMDP solvers. These results show a reduction in computation time and\nan increase in scalability by multiple orders of magnitude in a number of\nbenchmarks.\n", "versions": [{"version": "v1", "created": "Tue, 16 Oct 2012 17:39:17 GMT"}], "update_date": "2012-10-19", "authors_parsed": [["Dibangoye", "Jilles S.", ""], ["Amato", "Christopher", ""], ["Doniec", "Arnoud", ""]]}, {"id": "1210.4866", "submitter": "Tom Claassen", "authors": "Tom Claassen, Tom Heskes", "title": "A Bayesian Approach to Constraint Based Causal Inference", "comments": "Appears in Proceedings of the Twenty-Eighth Conference on Uncertainty\n  in Artificial Intelligence (UAI2012)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2012-PG-207-216", "categories": "cs.AI stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We target the problem of accuracy and robustness in causal inference from\nfinite data sets. Some state-of-the-art algorithms produce clear output\ncomplete with solid theoretical guarantees but are susceptible to propagating\nerroneous decisions, while others are very adept at handling and representing\nuncertainty, but need to rely on undesirable assumptions. Our aim is to combine\nthe inherent robustness of the Bayesian approach with the theoretical strength\nand clarity of constraint-based methods. We use a Bayesian score to obtain\nprobability estimates on the input statements used in a constraint-based\nprocedure. These are subsequently processed in decreasing order of reliability,\nletting more reliable decisions take precedence in case of con icts, until a\nsingle output model is obtained. Tests show that a basic implementation of the\nresulting Bayesian Constraint-based Causal Discovery (BCCD) algorithm already\noutperforms established procedures such as FCI and Conservative PC. It can also\nindicate which causal decisions in the output have high reliability and which\ndo not.\n", "versions": [{"version": "v1", "created": "Tue, 16 Oct 2012 17:39:28 GMT"}], "update_date": "2012-10-19", "authors_parsed": [["Claassen", "Tom", ""], ["Heskes", "Tom", ""]]}, {"id": "1210.4870", "submitter": "Christopher H. Lin", "authors": "Christopher H. Lin, Mausam, Daniel Weld", "title": "Crowdsourcing Control: Moving Beyond Multiple Choice", "comments": "Appears in Proceedings of the Twenty-Eighth Conference on Uncertainty\n  in Artificial Intelligence (UAI2012)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2012-PG-491-500", "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To ensure quality results from crowdsourced tasks, requesters often aggregate\nworker responses and use one of a plethora of strategies to infer the correct\nanswer from the set of noisy responses. However, all current models assume\nprior knowledge of all possible outcomes of the task. While not an unreasonable\nassumption for tasks that can be posited as multiple-choice questions (e.g.\nn-ary classification), we observe that many tasks do not naturally fit this\nparadigm, but instead demand a free-response formulation where the outcome\nspace is of infinite size (e.g. audio transcription). We model such tasks with\na novel probabilistic graphical model, and design and implement LazySusan, a\ndecision-theoretic controller that dynamically requests responses as necessary\nin order to infer answers to these tasks. We also design an EM algorithm to\njointly learn the parameters of our model while inferring the correct answers\nto multiple tasks at a time. Live experiments on Amazon Mechanical Turk\ndemonstrate the superiority of LazySusan at solving SAT Math questions,\neliminating 83.2% of the error and achieving greater net utility compared to\nthe state-ofthe-art strategy, majority-voting. We also show in live experiments\nthat our EM algorithm outperforms majority-voting on a visualization task that\nwe design.\n", "versions": [{"version": "v1", "created": "Tue, 16 Oct 2012 17:41:19 GMT"}], "update_date": "2012-10-19", "authors_parsed": [["Lin", "Christopher H.", ""], ["Mausam", "", ""], ["Weld", "Daniel", ""]]}, {"id": "1210.4874", "submitter": "Hoong Chuin Lau", "authors": "Hoong Chuin Lau, William Yeoh, Pradeep Varakantham, Duc Thien Nguyen,\n  Huaxing Chen", "title": "Dynamic Stochastic Orienteering Problems for Risk-Aware Applications", "comments": "Appears in Proceedings of the Twenty-Eighth Conference on Uncertainty\n  in Artificial Intelligence (UAI2012)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2012-PG-448-458", "categories": "cs.AI cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Orienteering problems (OPs) are a variant of the well-known prize-collecting\ntraveling salesman problem, where the salesman needs to choose a subset of\ncities to visit within a given deadline. OPs and their extensions with\nstochastic travel times (SOPs) have been used to model vehicle routing problems\nand tourist trip design problems. However, they suffer from two limitations\ntravel times between cities are assumed to be time independent and the route\nprovided is independent of the risk preference (with respect to violating the\ndeadline) of the user. To address these issues, we make the following\ncontributions: We introduce (1) a dynamic SOP (DSOP) model, which is an\nextension of SOPs with dynamic (time-dependent) travel times; (2) a\nrisk-sensitive criterion to allow for different risk preferences; and (3) a\nlocal search algorithm to solve DSOPs with this risk-sensitive criterion. We\nevaluated our algorithms on a real-world dataset for a theme park navigation\nproblem as well as synthetic datasets employed in the literature.\n", "versions": [{"version": "v1", "created": "Tue, 16 Oct 2012 17:42:27 GMT"}], "update_date": "2012-10-19", "authors_parsed": [["Lau", "Hoong Chuin", ""], ["Yeoh", "William", ""], ["Varakantham", "Pradeep", ""], ["Nguyen", "Duc Thien", ""], ["Chen", "Huaxing", ""]]}, {"id": "1210.4875", "submitter": "Andrey Kolobov", "authors": "Andrey Kolobov, Mausam, Daniel Weld", "title": "A Theory of Goal-Oriented MDPs with Dead Ends", "comments": "Appears in Proceedings of the Twenty-Eighth Conference on Uncertainty\n  in Artificial Intelligence (UAI2012)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2012-PG-438-447", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stochastic Shortest Path (SSP) MDPs is a problem class widely studied in AI,\nespecially in probabilistic planning. They describe a wide range of scenarios\nbut make the restrictive assumption that the goal is reachable from any state,\ni.e., that dead-end states do not exist. Because of this, SSPs are unable to\nmodel various scenarios that may have catastrophic events (e.g., an airplane\npossibly crashing if it flies into a storm). Even though MDP algorithms have\nbeen used for solving problems with dead ends, a principled theory of SSP\nextensions that would allow dead ends, including theoretically sound algorithms\nfor solving such MDPs, has been lacking. In this paper, we propose three new\nMDP classes that admit dead ends under increasingly weaker assumptions. We\npresent Value Iteration-based as well as the more efficient heuristic search\nalgorithms for optimally solving each class, and explore theoretical\nrelationships between these classes. We also conduct a preliminary empirical\nstudy comparing the performance of our algorithms on different MDP classes,\nespecially on scenarios with unavoidable dead ends.\n", "versions": [{"version": "v1", "created": "Tue, 16 Oct 2012 17:42:41 GMT"}], "update_date": "2012-10-19", "authors_parsed": [["Kolobov", "Andrey", ""], ["Mausam", "", ""], ["Weld", "Daniel", ""]]}, {"id": "1210.4878", "submitter": "Alexander T. Ihler", "authors": "Alexander T. Ihler, Natalia Flerova, Rina Dechter, Lars Otten", "title": "Join-graph based cost-shifting schemes", "comments": "Appears in Proceedings of the Twenty-Eighth Conference on Uncertainty\n  in Artificial Intelligence (UAI2012)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2012-PG-397-406", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop several algorithms taking advantage of two common approaches for\nbounding MPE queries in graphical models: minibucket elimination and\nmessage-passing updates for linear programming relaxations. Both methods are\nquite similar, and offer useful perspectives for the other; our hybrid\napproaches attempt to balance the advantages of each. We demonstrate the power\nof our hybrid algorithms through extensive empirical evaluation. Most notably,\na Branch and Bound search guided by the heuristic function calculated by one of\nour new algorithms has recently won first place in the PASCAL2 inference\nchallenge.\n", "versions": [{"version": "v1", "created": "Tue, 16 Oct 2012 17:43:24 GMT"}], "update_date": "2012-10-19", "authors_parsed": [["Ihler", "Alexander T.", ""], ["Flerova", "Natalia", ""], ["Dechter", "Rina", ""], ["Otten", "Lars", ""]]}, {"id": "1210.4879", "submitter": "Antti Hyttinen", "authors": "Antti Hyttinen, Frederick Eberhardt, Patrik O. Hoyer", "title": "Causal Discovery of Linear Cyclic Models from Multiple Experimental Data\n  Sets with Overlapping Variables", "comments": "Appears in Proceedings of the Twenty-Eighth Conference on Uncertainty\n  in Artificial Intelligence (UAI2012)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2012-PG-387-396", "categories": "stat.ME cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Much of scientific data is collected as randomized experiments intervening on\nsome and observing other variables of interest. Quite often, a given phenomenon\nis investigated in several studies, and different sets of variables are\ninvolved in each study. In this article we consider the problem of integrating\nsuch knowledge, inferring as much as possible concerning the underlying causal\nstructure with respect to the union of observed variables from such\nexperimental or passive observational overlapping data sets. We do not assume\nacyclicity or joint causal sufficiency of the underlying data generating model,\nbut we do restrict the causal relationships to be linear and use only second\norder statistics of the data. We derive conditions for full model\nidentifiability in the most generic case, and provide novel techniques for\nincorporating an assumption of faithfulness to aid in inference. In each case\nwe seek to establish what is and what is not determined by the data at hand.\n", "versions": [{"version": "v1", "created": "Tue, 16 Oct 2012 17:43:35 GMT"}], "update_date": "2012-10-19", "authors_parsed": [["Hyttinen", "Antti", ""], ["Eberhardt", "Frederick", ""], ["Hoyer", "Patrik O.", ""]]}, {"id": "1210.4880", "submitter": "Jesse Hostetler", "authors": "Jesse Hostetler, Ethan W. Dereszynski, Thomas G. Dietterich, Alan Fern", "title": "Inferring Strategies from Limited Reconnaissance in Real-time Strategy\n  Games", "comments": "Appears in Proceedings of the Twenty-Eighth Conference on Uncertainty\n  in Artificial Intelligence (UAI2012)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2012-PG-367-376", "categories": "cs.AI cs.GT cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In typical real-time strategy (RTS) games, enemy units are visible only when\nthey are within sight range of a friendly unit. Knowledge of an opponent's\ndisposition is limited to what can be observed through scouting. Information is\ncostly, since units dedicated to scouting are unavailable for other purposes,\nand the enemy will resist scouting attempts. It is important to infer as much\nas possible about the opponent's current and future strategy from the available\nobservations. We present a dynamic Bayes net model of strategies in the RTS\ngame Starcraft that combines a generative model of how strategies relate to\nobservable quantities with a principled framework for incorporating evidence\ngained via scouting. We demonstrate the model's ability to infer unobserved\naspects of the game from realistic observations.\n", "versions": [{"version": "v1", "created": "Tue, 16 Oct 2012 17:43:47 GMT"}], "update_date": "2012-10-19", "authors_parsed": [["Hostetler", "Jesse", ""], ["Dereszynski", "Ethan W.", ""], ["Dietterich", "Thomas G.", ""], ["Fern", "Alan", ""]]}, {"id": "1210.4882", "submitter": "Ariel D. Procaccia", "authors": "Ariel D. Procaccia, Sashank J. Reddi, Nisarg Shah", "title": "A Maximum Likelihood Approach For Selecting Sets of Alternatives", "comments": "Appears in Proceedings of the Twenty-Eighth Conference on Uncertainty\n  in Artificial Intelligence (UAI2012)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2012-PG-695-704", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of selecting a subset of alternatives given noisy\nevaluations of the relative strength of different alternatives. We wish to\nselect a k-subset (for a given k) that provides a maximum likelihood estimate\nfor one of several objectives, e.g., containing the strongest alternative.\nAlthough this problem is NP-hard, we show that when the noise level is\nsufficiently high, intuitive methods provide the optimal solution. We thus\ngeneralize classical results about singling out one alternative and identifying\nthe hidden ranking of alternatives by strength. Extensive experiments show that\nour methods perform well in practical settings.\n", "versions": [{"version": "v1", "created": "Tue, 16 Oct 2012 17:44:59 GMT"}], "update_date": "2012-10-19", "authors_parsed": [["Procaccia", "Ariel D.", ""], ["Reddi", "Sashank J.", ""], ["Shah", "Nisarg", ""]]}, {"id": "1210.4885", "submitter": "Lars Otten", "authors": "Lars Otten, Rina Dechter", "title": "A Case Study in Complexity Estimation: Towards Parallel Branch-and-Bound\n  over Graphical Models", "comments": "Appears in Proceedings of the Twenty-Eighth Conference on Uncertainty\n  in Artificial Intelligence (UAI2012)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2012-PG-665-674", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of complexity estimation in the context of parallelizing\nan advanced Branch and Bound-type algorithm over graphical models. The\nalgorithm's pruning power makes load balancing, one crucial element of every\ndistributed system, very challenging. We propose using a statistical regression\nmodel to identify and tackle disproportionally complex parallel subproblems,\nthe cause of load imbalance, ahead of time. The proposed model is evaluated and\nanalyzed on various levels and shown to yield robust predictions. We then\ndemonstrate its effectiveness for load balancing in practice.\n", "versions": [{"version": "v1", "created": "Tue, 16 Oct 2012 17:45:42 GMT"}], "update_date": "2012-10-19", "authors_parsed": [["Otten", "Lars", ""], ["Dechter", "Rina", ""]]}, {"id": "1210.4886", "submitter": "Frans A. Oliehoek", "authors": "Frans A. Oliehoek, Shimon Whiteson, Matthijs T. J. Spaan", "title": "Exploiting Structure in Cooperative Bayesian Games", "comments": "Appears in Proceedings of the Twenty-Eighth Conference on Uncertainty\n  in Artificial Intelligence (UAI2012)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2012-PG-654-665", "categories": "cs.GT cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cooperative Bayesian games (BGs) can model decision-making problems for teams\nof agents under imperfect information, but require space and computation time\nthat is exponential in the number of agents. While agent independence has been\nused to mitigate these problems in perfect information settings, we propose a\nnovel approach for BGs based on the observation that BGs additionally possess a\ndifferent types of structure, which we call type independence. We propose a\nfactor graph representation that captures both forms of independence and\npresent a theoretical analysis showing that non-serial dynamic programming\ncannot effectively exploit type independence, while Max-Sum can. Experimental\nresults demonstrate that our approach can tackle cooperative Bayesian games of\nunprecedented size.\n", "versions": [{"version": "v1", "created": "Tue, 16 Oct 2012 17:45:55 GMT"}], "update_date": "2012-10-19", "authors_parsed": [["Oliehoek", "Frans A.", ""], ["Whiteson", "Shimon", ""], ["Spaan", "Matthijs T. J.", ""]]}, {"id": "1210.4887", "submitter": "Yu Nishiyama", "authors": "Yu Nishiyama, Abdeslam Boularias, Arthur Gretton, Kenji Fukumizu", "title": "Hilbert Space Embeddings of POMDPs", "comments": "Appears in Proceedings of the Twenty-Eighth Conference on Uncertainty\n  in Artificial Intelligence (UAI2012)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2012-PG-644-653", "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A nonparametric approach for policy learning for POMDPs is proposed. The\napproach represents distributions over the states, observations, and actions as\nembeddings in feature spaces, which are reproducing kernel Hilbert spaces.\nDistributions over states given the observations are obtained by applying the\nkernel Bayes' rule to these distribution embeddings. Policies and value\nfunctions are defined on the feature space over states, which leads to a\nfeature space expression for the Bellman equation. Value iteration may then be\nused to estimate the optimal value function and associated policy. Experimental\nresults confirm that the correct policy is learned using the feature space\nrepresentation.\n", "versions": [{"version": "v1", "created": "Tue, 16 Oct 2012 17:46:07 GMT"}], "update_date": "2012-10-19", "authors_parsed": [["Nishiyama", "Yu", ""], ["Boularias", "Abdeslam", ""], ["Gretton", "Arthur", ""], ["Fukumizu", "Kenji", ""]]}, {"id": "1210.4888", "submitter": "Teppo Niinimaki", "authors": "Teppo Niinimaki, Pekka Parviainen", "title": "Local Structure Discovery in Bayesian Networks", "comments": "Appears in Proceedings of the Twenty-Eighth Conference on Uncertainty\n  in Artificial Intelligence (UAI2012)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2012-PG-634-643", "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning a Bayesian network structure from data is an NP-hard problem and\nthus exact algorithms are feasible only for small data sets. Therefore, network\nstructures for larger networks are usually learned with various heuristics.\nAnother approach to scaling up the structure learning is local learning. In\nlocal learning, the modeler has one or more target variables that are of\nspecial interest; he wants to learn the structure near the target variables and\nis not interested in the rest of the variables. In this paper, we present a\nscore-based local learning algorithm called SLL. We conjecture that our\nalgorithm is theoretically sound in the sense that it is optimal in the limit\nof large sample size. Empirical results suggest that SLL is competitive when\ncompared to the constraint-based HITON algorithm. We also study the prospects\nof constructing the network structure for the whole node set based on local\nresults by presenting two algorithms and comparing them to several heuristics.\n", "versions": [{"version": "v1", "created": "Tue, 16 Oct 2012 17:46:17 GMT"}], "update_date": "2012-10-19", "authors_parsed": [["Niinimaki", "Teppo", ""], ["Parviainen", "Pekka", ""]]}, {"id": "1210.4889", "submitter": "Kira Mourao", "authors": "Kira Mourao, Luke S. Zettlemoyer, Ronald P. A. Petrick, Mark Steedman", "title": "Learning STRIPS Operators from Noisy and Incomplete Observations", "comments": "Appears in Proceedings of the Twenty-Eighth Conference on Uncertainty\n  in Artificial Intelligence (UAI2012)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2012-PG-614-623", "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Agents learning to act autonomously in real-world domains must acquire a\nmodel of the dynamics of the domain in which they operate. Learning domain\ndynamics can be challenging, especially where an agent only has partial access\nto the world state, and/or noisy external sensors. Even in standard STRIPS\ndomains, existing approaches cannot learn from noisy, incomplete observations\ntypical of real-world domains. We propose a method which learns STRIPS action\nmodels in such domains, by decomposing the problem into first learning a\ntransition function between states in the form of a set of classifiers, and\nthen deriving explicit STRIPS rules from the classifiers' parameters. We\nevaluate our approach on simulated standard planning domains from the\nInternational Planning Competition, and show that it learns useful domain\ndescriptions from noisy, incomplete observations.\n", "versions": [{"version": "v1", "created": "Tue, 16 Oct 2012 17:46:26 GMT"}], "update_date": "2012-10-19", "authors_parsed": [["Mourao", "Kira", ""], ["Zettlemoyer", "Luke S.", ""], ["Petrick", "Ronald P. A.", ""], ["Steedman", "Mark", ""]]}, {"id": "1210.4890", "submitter": "Denis D. Maua", "authors": "Denis D. Maua, Cassio Polpo de Campos, Marco Zaffalon", "title": "The Complexity of Approximately Solving Influence Diagrams", "comments": "Appears in Proceedings of the Twenty-Eighth Conference on Uncertainty\n  in Artificial Intelligence (UAI2012)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2012-PG-604-613", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Influence diagrams allow for intuitive and yet precise description of complex\nsituations involving decision making under uncertainty. Unfortunately, most of\nthe problems described by influence diagrams are hard to solve. In this paper\nwe discuss the complexity of approximately solving influence diagrams. We do\nnot assume no-forgetting or regularity, which makes the class of problems we\naddress very broad. Remarkably, we show that when both the tree-width and the\ncardinality of the variables are bounded the problem admits a fully\npolynomial-time approximation scheme.\n", "versions": [{"version": "v1", "created": "Tue, 16 Oct 2012 17:46:41 GMT"}], "update_date": "2012-10-19", "authors_parsed": [["Maua", "Denis D.", ""], ["de Campos", "Cassio Polpo", ""], ["Zaffalon", "Marco", ""]]}, {"id": "1210.4894", "submitter": "Thomas Lukasiewicz", "authors": "Thomas Lukasiewicz, Maria Vanina Martinez, Giorgio Orsi, Gerardo I.\n  Simari", "title": "Heuristic Ranking in Tightly Coupled Probabilistic Description Logics", "comments": "Appears in Proceedings of the Twenty-Eighth Conference on Uncertainty\n  in Artificial Intelligence (UAI2012)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2012-PG-554-563", "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Semantic Web effort has steadily been gaining traction in the recent\nyears. In particular,Web search companies are recently realizing that their\nproducts need to evolve towards having richer semantic search capabilities.\nDescription logics (DLs) have been adopted as the formal underpinnings for\nSemantic Web languages used in describing ontologies. Reasoning under\nuncertainty has recently taken a leading role in this arena, given the nature\nof data found on theWeb. In this paper, we present a probabilistic extension of\nthe DL EL++ (which underlies the OWL2 EL profile) using Markov logic networks\n(MLNs) as probabilistic semantics. This extension is tightly coupled, meaning\nthat probabilistic annotations in formulas can refer to objects in the\nontology. We show that, even though the tightly coupled nature of our language\nmeans that many basic operations are data-intractable, we can leverage a\nsublanguage of MLNs that allows to rank the atomic consequences of an ontology\nrelative to their probability values (called ranking queries) even when these\nvalues are not fully computed. We present an anytime algorithm to answer\nranking queries, and provide an upper bound on the error that it incurs, as\nwell as a criterion to decide when results are guaranteed to be correct.\n", "versions": [{"version": "v1", "created": "Tue, 16 Oct 2012 17:47:44 GMT"}], "update_date": "2012-10-19", "authors_parsed": [["Lukasiewicz", "Thomas", ""], ["Martinez", "Maria Vanina", ""], ["Orsi", "Giorgio", ""], ["Simari", "Gerardo I.", ""]]}, {"id": "1210.4896", "submitter": "Daniel Lowd", "authors": "Daniel Lowd", "title": "Closed-Form Learning of Markov Networks from Dependency Networks", "comments": "Appears in Proceedings of the Twenty-Eighth Conference on Uncertainty\n  in Artificial Intelligence (UAI2012)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2012-PG-533-542", "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Markov networks (MNs) are a powerful way to compactly represent a joint\nprobability distribution, but most MN structure learning methods are very slow,\ndue to the high cost of evaluating candidates structures. Dependency networks\n(DNs) represent a probability distribution as a set of conditional probability\ndistributions. DNs are very fast to learn, but the conditional distributions\nmay be inconsistent with each other and few inference algorithms support DNs.\nIn this paper, we present a closed-form method for converting a DN into an MN,\nallowing us to enjoy both the efficiency of DN learning and the convenience of\nthe MN representation. When the DN is consistent, this conversion is exact. For\ninconsistent DNs, we present averaging methods that significantly improve the\napproximation. In experiments on 12 standard datasets, our methods are orders\nof magnitude faster than and often more accurate than combining conditional\ndistributions using weight learning.\n", "versions": [{"version": "v1", "created": "Tue, 16 Oct 2012 17:48:08 GMT"}], "update_date": "2012-10-19", "authors_parsed": [["Lowd", "Daniel", ""]]}, {"id": "1210.4897", "submitter": "Qiang Liu", "authors": "Qiang Liu, Alexander T. Ihler", "title": "Belief Propagation for Structured Decision Making", "comments": "Appears in Proceedings of the Twenty-Eighth Conference on Uncertainty\n  in Artificial Intelligence (UAI2012)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2012-PG-523-532", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Variational inference algorithms such as belief propagation have had\ntremendous impact on our ability to learn and use graphical models, and give\nmany insights for developing or understanding exact and approximate inference.\nHowever, variational approaches have not been widely adoped for decision making\nin graphical models, often formulated through influence diagrams and including\nboth centralized and decentralized (or multi-agent) decisions. In this work, we\npresent a general variational framework for solving structured cooperative\ndecision-making problems, use it to propose several belief propagation-like\nalgorithms, and analyze them both theoretically and empirically.\n", "versions": [{"version": "v1", "created": "Tue, 16 Oct 2012 17:48:18 GMT"}], "update_date": "2012-10-19", "authors_parsed": [["Liu", "Qiang", ""], ["Ihler", "Alexander T.", ""]]}, {"id": "1210.4900", "submitter": "Wei Sun", "authors": "Wei Sun, Robin Hanson, Kathryn Blackmond Laskey, Charles Twardy", "title": "Probability and Asset Updating using Bayesian Networks for Combinatorial\n  Prediction Markets", "comments": "Appears in Proceedings of the Twenty-Eighth Conference on Uncertainty\n  in Artificial Intelligence (UAI2012)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2012-PG-815-824", "categories": "cs.AI q-fin.TR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A market-maker-based prediction market lets forecasters aggregate information\nby editing a consensus probability distribution either directly or by trading\nsecurities that pay off contingent on an event of interest. Combinatorial\nprediction markets allow trading on any event that can be specified as a\ncombination of a base set of events. However, explicitly representing the full\njoint distribution is infeasible for markets with more than a few base events.\nA factored representation such as a Bayesian network (BN) can achieve tractable\ncomputation for problems with many related variables. Standard BN inference\nalgorithms, such as the junction tree algorithm, can be used to update a\nrepresentation of the entire joint distribution given a change to any local\nconditional probability. However, in order to let traders reuse assets from\nprior trades while never allowing assets to become negative, a BN based\nprediction market also needs to update a representation of each user's assets\nand find the conditional state in which a user has minimum assets. Users also\nfind it useful to see their expected assets given an edit outcome. We show how\nto generalize the junction tree algorithm to perform all these computations.\n", "versions": [{"version": "v1", "created": "Tue, 16 Oct 2012 17:50:37 GMT"}], "update_date": "2012-10-19", "authors_parsed": [["Sun", "Wei", ""], ["Hanson", "Robin", ""], ["Laskey", "Kathryn Blackmond", ""], ["Twardy", "Charles", ""]]}, {"id": "1210.4901", "submitter": "Marek Petrik", "authors": "Marek Petrik, Dharmashankar Subramanian", "title": "An Approximate Solution Method for Large Risk-Averse Markov Decision\n  Processes", "comments": "Appears in Proceedings of the Twenty-Eighth Conference on Uncertainty\n  in Artificial Intelligence (UAI2012)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2012-PG-805-814", "categories": "q-fin.PM cs.AI cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stochastic domains often involve risk-averse decision makers. While recent\nwork has focused on how to model risk in Markov decision processes using risk\nmeasures, it has not addressed the problem of solving large risk-averse\nformulations. In this paper, we propose and analyze a new method for solving\nlarge risk-averse MDPs with hybrid continuous-discrete state spaces and\ncontinuous action spaces. The proposed method iteratively improves a bound on\nthe value function using a linearity structure of the MDP. We demonstrate the\nutility and properties of the method on a portfolio optimization problem.\n", "versions": [{"version": "v1", "created": "Tue, 16 Oct 2012 17:51:11 GMT"}], "update_date": "2012-10-19", "authors_parsed": [["Petrik", "Marek", ""], ["Subramanian", "Dharmashankar", ""]]}, {"id": "1210.4906", "submitter": "Bogdan Savchynskyy", "authors": "Bogdan Savchynskyy, Stefan Schmidt, Joerg Kappes, Christoph Schnoerr", "title": "Efficient MRF Energy Minimization via Adaptive Diminishing Smoothing", "comments": "Appears in Proceedings of the Twenty-Eighth Conference on Uncertainty\n  in Artificial Intelligence (UAI2012)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2012-PG-746-755", "categories": "cs.AI cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the linear programming relaxation of an energy minimization\nproblem for Markov Random Fields. The dual objective of this problem can be\ntreated as a concave and unconstrained, but non-smooth function. The idea of\nsmoothing the objective prior to optimization was recently proposed in a series\nof papers. Some of them suggested the idea to decrease the amount of smoothing\n(so called temperature) while getting closer to the optimum. However, no\ntheoretical substantiation was provided. We propose an adaptive smoothing\ndiminishing algorithm based on the duality gap between relaxed primal and dual\nobjectives and demonstrate the efficiency of our approach with a smoothed\nversion of Sequential Tree-Reweighted Message Passing (TRW-S) algorithm. The\nstrategy is applicable to other algorithms as well, avoids adhoc tuning of the\nsmoothing during iterations, and provably guarantees convergence to the\noptimum.\n", "versions": [{"version": "v1", "created": "Tue, 16 Oct 2012 17:52:03 GMT"}], "update_date": "2012-10-19", "authors_parsed": [["Savchynskyy", "Bogdan", ""], ["Schmidt", "Stefan", ""], ["Kappes", "Joerg", ""], ["Schnoerr", "Christoph", ""]]}, {"id": "1210.4907", "submitter": "Giuseppe Sanfilippo", "authors": "Giuseppe Sanfilippo", "title": "From imprecise probability assessments to conditional probabilities with\n  quasi additive classes of conditioning events", "comments": "Appears in Proceedings of the Twenty-Eighth Conference on Uncertainty\n  in Artificial Intelligence (UAI2012)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2012-PG-736-745", "categories": "cs.AI math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, starting from a generalized coherent (i.e. avoiding uniform\nloss) intervalvalued probability assessment on a finite family of conditional\nevents, we construct conditional probabilities with quasi additive classes of\nconditioning events which are consistent with the given initial assessment.\nQuasi additivity assures coherence for the obtained conditional probabilities.\nIn order to reach our goal we define a finite sequence of conditional\nprobabilities by exploiting some theoretical results on g-coherence. In\nparticular, we use solutions of a finite sequence of linear systems.\n", "versions": [{"version": "v1", "created": "Tue, 16 Oct 2012 17:52:38 GMT"}], "update_date": "2012-10-19", "authors_parsed": [["Sanfilippo", "Giuseppe", ""]]}, {"id": "1210.4910", "submitter": "Khaled S. Refaat", "authors": "Khaled S. Refaat, Arthur Choi, Adnan Darwiche", "title": "New Advances and Theoretical Insights into EDML", "comments": "Appears in Proceedings of the Twenty-Eighth Conference on Uncertainty\n  in Artificial Intelligence (UAI2012)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2012-PG-705-714", "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  EDML is a recently proposed algorithm for learning MAP parameters in Bayesian\nnetworks. In this paper, we present a number of new advances and insights on\nthe EDML algorithm. First, we provide the multivalued extension of EDML,\noriginally proposed for Bayesian networks over binary variables. Next, we\nidentify a simplified characterization of EDML that further implies a simple\nfixed-point algorithm for the convex optimization problem that underlies it.\nThis characterization further reveals a connection between EDML and EM: a fixed\npoint of EDML is a fixed point of EM, and vice versa. We thus identify also a\nnew characterization of EM fixed points, but in the semantics of EDML. Finally,\nwe propose a hybrid EDML/EM algorithm that takes advantage of the improved\nempirical convergence behavior of EDML, while maintaining the monotonic\nimprovement property of EM.\n", "versions": [{"version": "v1", "created": "Tue, 16 Oct 2012 17:53:29 GMT"}], "update_date": "2012-10-19", "authors_parsed": [["Refaat", "Khaled S.", ""], ["Choi", "Arthur", ""], ["Darwiche", "Adnan", ""]]}, {"id": "1210.4911", "submitter": "Radu Marinescu", "authors": "Radu Marinescu, Abdul Razak, Nic Wilson", "title": "Multi-objective Influence Diagrams", "comments": "Appears in Proceedings of the Twenty-Eighth Conference on Uncertainty\n  in Artificial Intelligence (UAI2012)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2012-PG-574-583", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe multi-objective influence diagrams, based on a set of p\nobjectives, where utility values are vectors in Rp, and are typically only\npartially ordered. These can still be solved by a variable elimination\nalgorithm, leading to a set of maximal values of expected utility. If the\nPareto ordering is used this set can often be prohibitively large. We consider\napproximate representations of the Pareto set based on e-coverings, allowing\nmuch larger problems to be solved. In addition, we define a method for\nincorporating user tradeoffs, which also greatly improves the efficiency.\n", "versions": [{"version": "v1", "created": "Tue, 16 Oct 2012 17:55:38 GMT"}], "update_date": "2012-10-19", "authors_parsed": [["Marinescu", "Radu", ""], ["Razak", "Abdul", ""], ["Wilson", "Nic", ""]]}, {"id": "1210.4912", "submitter": "Zhongzhang Zhang", "authors": "Zhongzhang Zhang, Xiaoping Chen", "title": "FHHOP: A Factored Hybrid Heuristic Online Planning Algorithm for Large\n  POMDPs", "comments": "Appears in Proceedings of the Twenty-Eighth Conference on Uncertainty\n  in Artificial Intelligence (UAI2012)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2012-PG-934-943", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Planning in partially observable Markov decision processes (POMDPs) remains a\nchallenging topic in the artificial intelligence community, in spite of recent\nimpressive progress in approximation techniques. Previous research has\nindicated that online planning approaches are promising in handling large-scale\nPOMDP domains efficiently as they make decisions \"on demand\" instead of\nproactively for the entire state space. We present a Factored Hybrid Heuristic\nOnline Planning (FHHOP) algorithm for large POMDPs. FHHOP gets its power by\ncombining a novel hybrid heuristic search strategy with a recently developed\nfactored state representation. On several benchmark problems, FHHOP\nsubstantially outperformed state-of-the-art online heuristic search approaches\nin terms of both scalability and quality.\n", "versions": [{"version": "v1", "created": "Tue, 16 Oct 2012 17:55:47 GMT"}], "update_date": "2012-10-19", "authors_parsed": [["Zhang", "Zhongzhang", ""], ["Chen", "Xiaoping", ""]]}, {"id": "1210.4913", "submitter": "Changhe Yuan", "authors": "Changhe Yuan, Brandon Malone", "title": "An Improved Admissible Heuristic for Learning Optimal Bayesian Networks", "comments": "Appears in Proceedings of the Twenty-Eighth Conference on Uncertainty\n  in Artificial Intelligence (UAI2012)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2012-PG-924-933", "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently two search algorithms, A* and breadth-first branch and bound\n(BFBnB), were developed based on a simple admissible heuristic for learning\nBayesian network structures that optimize a scoring function. The heuristic\nrepresents a relaxation of the learning problem such that each variable chooses\noptimal parents independently. As a result, the heuristic may contain many\ndirected cycles and result in a loose bound. This paper introduces an improved\nadmissible heuristic that tries to avoid directed cycles within small groups of\nvariables. A sparse representation is also introduced to store only the unique\noptimal parent choices. Empirical results show that the new techniques\nsignificantly improved the efficiency and scalability of A* and BFBnB on most\nof datasets tested in this paper.\n", "versions": [{"version": "v1", "created": "Tue, 16 Oct 2012 17:55:57 GMT"}], "update_date": "2012-10-19", "authors_parsed": [["Yuan", "Changhe", ""], ["Malone", "Brandon", ""]]}, {"id": "1210.4916", "submitter": "Max Welling", "authors": "Max Welling, Andrew E. Gelfand, Alexander T. Ihler", "title": "A Cluster-Cumulant Expansion at the Fixed Points of Belief Propagation", "comments": "Appears in Proceedings of the Twenty-Eighth Conference on Uncertainty\n  in Artificial Intelligence (UAI2012)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2012-PG-883-892", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new cluster-cumulant expansion (CCE) based on the fixed points\nof iterative belief propagation (IBP). This expansion is similar in spirit to\nthe loop-series (LS) recently introduced in [1]. However, in contrast to the\nlatter, the CCE enjoys the following important qualities: 1) it is defined for\narbitrary state spaces 2) it is easily extended to fixed points of generalized\nbelief propagation (GBP), 3) disconnected groups of variables will not\ncontribute to the CCE and 4) the accuracy of the expansion empirically improves\nupon that of the LS. The CCE is based on the same M\\\"obius transform as the\nKikuchi approximation, but unlike GBP does not require storing the beliefs of\nthe GBP-clusters nor does it suffer from convergence issues during belief\nupdating.\n", "versions": [{"version": "v1", "created": "Tue, 16 Oct 2012 17:56:32 GMT"}], "update_date": "2012-10-19", "authors_parsed": [["Welling", "Max", ""], ["Gelfand", "Andrew E.", ""], ["Ihler", "Alexander T.", ""]]}, {"id": "1210.4918", "submitter": "Thomas J. Walsh", "authors": "Thomas J. Walsh, Sergiu Goschin", "title": "Dynamic Teaching in Sequential Decision Making Environments", "comments": "Appears in Proceedings of the Twenty-Eighth Conference on Uncertainty\n  in Artificial Intelligence (UAI2012)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2012-PG-863-872", "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe theoretical bounds and a practical algorithm for teaching a model\nby demonstration in a sequential decision making environment. Unlike previous\nefforts that have optimized learners that watch a teacher demonstrate a static\npolicy, we focus on the teacher as a decision maker who can dynamically choose\ndifferent policies to teach different parts of the environment. We develop\nseveral teaching frameworks based on previously defined supervised protocols,\nsuch as Teaching Dimension, extending them to handle noise and sequences of\ninputs encountered in an MDP.We provide theoretical bounds on the learnability\nof several important model classes in this setting and suggest a practical\nalgorithm for dynamic teaching.\n", "versions": [{"version": "v1", "created": "Tue, 16 Oct 2012 17:56:54 GMT"}], "update_date": "2012-10-19", "authors_parsed": [["Walsh", "Thomas J.", ""], ["Goschin", "Sergiu", ""]]}, {"id": "1210.5118", "submitter": "Matthew Butler", "authors": "Matthew Butler and Dimitar Kazakov", "title": "Creating a level playing field for all symbols in a discretization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In time series analysis research there is a strong interest in discrete\nrepresentations of real valued data streams. One approach that emerged over a\ndecade ago and is still considered state-of-the-art is the Symbolic Aggregate\nApproximation algorithm. This discretization algorithm was the first symbolic\napproach that mapped a real-valued time series to a symbolic representation\nthat was guaranteed to lower-bound Euclidean distance. The interest of this\npaper concerns the SAX assumption of data being highly Gaussian and the use of\nthe standard normal curve to choose partitions to discretize the data. Though\nnot necessarily, but generally, and certainly in its canonical form, the SAX\napproach chooses partitions on the standard normal curve that would produce an\nequal probability for each symbol in a finite alphabet to occur. This procedure\nis generally valid as a time series is normalized before the rest of the SAX\nalgorithm is applied. However there exists a caveat to this assumption of\nequi-probability due to the intermediate step of Piecewise Aggregate\nApproximation (PAA). What we will show in this paper is that when PAA is\napplied the distribution of the data is indeed altered, resulting in a\nshrinking standard deviation that is proportional to the number of points used\nto create a segment of the PAA representation and the degree of\nauto-correlation within the series. Data that exhibits statistically\nsignificant auto-correlation is less affected by this shrinking distribution.\nAs the standard deviation of the data contracts, the mean remains the same,\nhowever the distribution is no longer standard normal and therefore the\npartitions based on the standard normal curve are no longer valid for the\nassumption of equal probability.\n", "versions": [{"version": "v1", "created": "Thu, 18 Oct 2012 13:44:45 GMT"}], "update_date": "2012-10-19", "authors_parsed": [["Butler", "Matthew", ""], ["Kazakov", "Dimitar", ""]]}, {"id": "1210.5222", "submitter": "Joohyung Lee", "authors": "Joseph Babb and Joohyung Lee", "title": "Module Theorem for The General Theory of Stable Models", "comments": "To appear in Theory and Practice of Logic Programming (TPLP)", "journal-ref": null, "doi": "10.1017/S1471068412000269", "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The module theorem by Janhunen et al. demonstrates how to provide a modular\nstructure in answer set programming, where each module has a well-defined\ninput/output interface which can be used to establish the compositionality of\nanswer sets. The theorem is useful in the analysis of answer set programs, and\nis a basis of incremental grounding and reactive answer set programming. We\nextend the module theorem to the general theory of stable models by Ferraris et\nal. The generalization applies to non-ground logic programs allowing useful\nconstructs in answer set programming, such as choice rules, the count\naggregate, and nested expressions. Our extension is based on relating the\nmodule theorem to the symmetric splitting theorem by Ferraris et al. Based on\nthis result, we reformulate and extend the theory of incremental answer set\ncomputation to a more general class of programs.\n", "versions": [{"version": "v1", "created": "Thu, 18 Oct 2012 18:54:09 GMT"}], "update_date": "2012-10-19", "authors_parsed": [["Babb", "Joseph", ""], ["Lee", "Joohyung", ""]]}, {"id": "1210.5560", "submitter": "Santiago M. Mola-Velasco", "authors": "Santiago M. Mola-Velasco", "title": "Wikipedia Vandalism Detection Through Machine Learning: Feature Review\n  and New Proposals: Lab Report for PAN at CLEF 2010", "comments": "Published in CLEF 2010 LABs and Workshops, Notebook Papers, 22-23\n  September 2010, Padua, Italy. 2010, ISBN 978-88-904810-0-0. First position at\n  the 1st International Competition on Wikipedia Vandalism Detection (PAN @\n  CLEF 2010)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  Wikipedia is an online encyclopedia that anyone can edit. In this open model,\nsome people edits with the intent of harming the integrity of Wikipedia. This\nis known as vandalism. We extend the framework presented in (Potthast, Stein,\nand Gerling, 2008) for Wikipedia vandalism detection. In this approach, several\nvandalism indicating features are extracted from edits in a vandalism corpus\nand are fed to a supervised learning algorithm. The best performing classifiers\nwere LogitBoost and Random Forest. Our classifier, a Random Forest, obtained an\nAUC of 0.92236, ranking in the first place of the PAN'10 Wikipedia vandalism\ndetection task.\n", "versions": [{"version": "v1", "created": "Fri, 19 Oct 2012 23:12:43 GMT"}], "update_date": "2012-10-23", "authors_parsed": [["Mola-Velasco", "Santiago M.", ""]]}, {"id": "1210.5644", "submitter": "Philipp Kr\\\"ahenb\\\"uhl", "authors": "Philipp Kr\\\"ahenb\\\"uhl and Vladlen Koltun", "title": "Efficient Inference in Fully Connected CRFs with Gaussian Edge\n  Potentials", "comments": "NIPS 2011", "journal-ref": "Advances in Neural Information Processing Systems 24 (2011)\n  109-117", "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most state-of-the-art techniques for multi-class image segmentation and\nlabeling use conditional random fields defined over pixels or image regions.\nWhile region-level models often feature dense pairwise connectivity,\npixel-level models are considerably larger and have only permitted sparse graph\nstructures. In this paper, we consider fully connected CRF models defined on\nthe complete set of pixels in an image. The resulting graphs have billions of\nedges, making traditional inference algorithms impractical. Our main\ncontribution is a highly efficient approximate inference algorithm for fully\nconnected CRF models in which the pairwise edge potentials are defined by a\nlinear combination of Gaussian kernels. Our experiments demonstrate that dense\nconnectivity at the pixel level substantially improves segmentation and\nlabeling accuracy.\n", "versions": [{"version": "v1", "created": "Sat, 20 Oct 2012 17:41:23 GMT"}], "update_date": "2012-10-23", "authors_parsed": [["Kr\u00e4henb\u00fchl", "Philipp", ""], ["Koltun", "Vladlen", ""]]}, {"id": "1210.5670", "submitter": "Chitta Baral", "authors": "Chitta Baral, Juraj Dzifcak, Marcos A. Gonzalez and Aaron Gottesman", "title": "Typed Answer Set Programming and Inverse Lambda Algorithms", "comments": "To appear in Theory and Practice of Logic Programming", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Our broader goal is to automatically translate English sentences into\nformulas in appropriate knowledge representation languages as a step towards\nunderstanding and thus answering questions with respect to English text. Our\nfocus in this paper is on the language of Answer Set Programming (ASP). Our\napproach to translate sentences to ASP rules is inspired by Montague's use of\nlambda calculus formulas as meaning of words and phrases. With ASP as the\ntarget language the meaning of words and phrases are ASP-lambda formulas. In an\nearlier work we illustrated our approach by manually developing a dictionary of\nwords and their ASP-lambda formulas. However such an approach is not scalable.\nIn this paper our focus is on two algorithms that allow one to construct\nASP-lambda formulas in an inverse manner. In particular the two algorithms take\nas input two lambda-calculus expressions G and H and compute a lambda-calculus\nexpression F such that F with input as G, denoted by F@G, is equal to H; and\nsimilarly G@F = H. We present correctness and complexity results about these\nalgorithms. To do that we develop the notion of typed ASP-lambda calculus\ntheories and their orders and use it in developing the completeness results.\n(To appear in Theory and Practice of Logic Programming.)\n", "versions": [{"version": "v1", "created": "Sun, 21 Oct 2012 00:42:19 GMT"}], "update_date": "2012-10-23", "authors_parsed": [["Baral", "Chitta", ""], ["Dzifcak", "Juraj", ""], ["Gonzalez", "Marcos A.", ""], ["Gottesman", "Aaron", ""]]}, {"id": "1210.6128", "submitter": "Tarun Sharma  Kumar", "authors": "Tarun Kumar Sharma, Millie Pant, V.P.Singh", "title": "Improved Local Search in Artificial Bee Colony using Golden Section\n  Search", "comments": "6 Pages, Journal of Engineering (JOE), World Science Publisher 2012", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CE", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  Artificial bee colony (ABC), an optimization algorithm is a recent addition\nto the family of population based search algorithm. ABC has taken its\ninspiration from the collective intelligent foraging behavior of honey bees. In\nthis study we have incorporated golden section search mechanism in the\nstructure of basic ABC to improve the global convergence and prevent to stick\non a local solution. The proposed variant is termed as ILS-ABC. Comparative\nnumerical results with the state-of-art algorithms show the performance of the\nproposal when applied to the set of unconstrained engineering design problems.\nThe simulated results show that the proposed variant can be successfully\napplied to solve real life problems.\n", "versions": [{"version": "v1", "created": "Tue, 23 Oct 2012 04:57:04 GMT"}], "update_date": "2012-10-24", "authors_parsed": [["Sharma", "Tarun Kumar", ""], ["Pant", "Millie", ""], ["Singh", "V. P.", ""]]}, {"id": "1210.6209", "submitter": "Yanfang Liu", "authors": "Yanfang Liu and William Zhu", "title": "Characteristic of partition-circuit matroid through approximation number", "comments": "12 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Rough set theory is a useful tool to deal with uncertain, granular and\nincomplete knowledge in information systems. And it is based on equivalence\nrelations or partitions. Matroid theory is a structure that generalizes linear\nindependence in vector spaces, and has a variety of applications in many\nfields. In this paper, we propose a new type of matroids, namely,\npartition-circuit matroids, which are induced by partitions. Firstly, a\npartition satisfies circuit axioms in matroid theory, then it can induce a\nmatroid which is called a partition-circuit matroid. A partition and an\nequivalence relation on the same universe are one-to-one corresponding, then\nsome characteristics of partition-circuit matroids are studied through rough\nsets. Secondly, similar to the upper approximation number which is proposed by\nWang and Zhu, we define the lower approximation number. Some characteristics of\npartition-circuit matroids and the dual matroids of them are investigated\nthrough the lower approximation number and the upper approximation number.\n", "versions": [{"version": "v1", "created": "Tue, 23 Oct 2012 11:50:42 GMT"}], "update_date": "2012-10-24", "authors_parsed": [["Liu", "Yanfang", ""], ["Zhu", "William", ""]]}, {"id": "1210.6275", "submitter": "Jo\\~ao Eugenio Marynowski", "authors": "Jo\\~ao Eugenio Marynowski", "title": "Ambiente de Planejamento Ip\\^e", "comments": "MSc dissertation involving Artificial Intelligence, Planning, Petri\n  Net, Plangraph, Intelig\\^encia Artificial, Planejamento, Redes de Petri e\n  Grafo de Planos", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we investigate the systems that implements algorithms for the\nplanning problem in Artificial Intelligence, called planners, with especial\nattention to the planners based on the plan graph. We analyze the problem of\ncomparing the performance of the different algorithms and we propose an\nenvironment for the development and analysis of planners.\n", "versions": [{"version": "v1", "created": "Tue, 23 Oct 2012 15:54:00 GMT"}, {"version": "v2", "created": "Wed, 24 Oct 2012 20:03:00 GMT"}], "update_date": "2012-10-26", "authors_parsed": [["Marynowski", "Jo\u00e3o Eugenio", ""]]}, {"id": "1210.6415", "submitter": "EPTCS", "authors": "Stefan Edelkamp, Peter Kissmann, \\'Alvaro Torralba", "title": "Lex-Partitioning: A New Option for BDD Search", "comments": "In Proceedings GRAPHITE 2012, arXiv:1210.6118", "journal-ref": "EPTCS 99, 2012, pp. 66-82", "doi": "10.4204/EPTCS.99.8", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For the exploration of large state spaces, symbolic search using binary\ndecision diagrams (BDDs) can save huge amounts of memory and computation time.\nState sets are represented and modified by accessing and manipulating their\ncharacteristic functions. BDD partitioning is used to compute the image as the\ndisjunction of smaller subimages.\n  In this paper, we propose a novel BDD partitioning option. The partitioning\nis lexicographical in the binary representation of the states contained in the\nset that is represented by a BDD and uniform with respect to the number of\nstates represented. The motivation of controlling the state set sizes in the\npartitioning is to eventually bridge the gap between explicit and symbolic\nsearch.\n  Let n be the size of the binary state vector. We propose an O(n) ranking and\nunranking scheme that supports negated edges and operates on top of precomputed\nsatcount values. For the uniform split of a BDD, we then use unranking to\nprovide paths along which we partition the BDDs. In a shared BDD representation\nthe efforts are O(n). The algorithms are fully integrated in the CUDD library\nand evaluated in strongly solving general game playing benchmarks.\n", "versions": [{"version": "v1", "created": "Wed, 24 Oct 2012 00:33:28 GMT"}], "update_date": "2012-10-25", "authors_parsed": [["Edelkamp", "Stefan", ""], ["Kissmann", "Peter", ""], ["Torralba", "\u00c1lvaro", ""]]}, {"id": "1210.6539", "submitter": "Heiko Hamann", "authors": "Heiko Hamann", "title": "Towards Swarm Calculus: Urn Models of Collective Decisions and Universal\n  Properties of Swarm Performance", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Methods of general applicability are searched for in swarm intelligence with\nthe aim of gaining new insights about natural swarms and to develop design\nmethodologies for artificial swarms. An ideal solution could be a `swarm\ncalculus' that allows to calculate key features of swarms such as expected\nswarm performance and robustness based on only a few parameters. To work\ntowards this ideal, one needs to find methods and models with high degrees of\ngenerality. In this paper, we report two models that might be examples of\nexceptional generality. First, an abstract model is presented that describes\nswarm performance depending on swarm density based on the dichotomy between\ncooperation and interference. Typical swarm experiments are given as examples\nto show how the model fits to several different results. Second, we give an\nabstract model of collective decision making that is inspired by urn models.\nThe effects of positive feedback probability, that is increasing over time in a\ndecision making system, are understood by the help of a parameter that controls\nthe feedback based on the swarm's current consensus. Several applicable\nmethods, such as the description as Markov process, calculation of splitting\nprobabilities, mean first passage times, and measurements of positive feedback,\nare discussed and applications to artificial and natural swarms are reported.\n", "versions": [{"version": "v1", "created": "Wed, 24 Oct 2012 14:18:26 GMT"}, {"version": "v2", "created": "Thu, 7 Feb 2013 15:02:00 GMT"}, {"version": "v3", "created": "Mon, 18 Mar 2013 09:28:11 GMT"}], "update_date": "2013-03-19", "authors_parsed": [["Hamann", "Heiko", ""]]}, {"id": "1210.6855", "submitter": "Michal \\v{C}\\'ap", "authors": "Michal \\v{C}\\'ap and Peter Nov\\'ak and Ji\\v{r}\\'i Vok\\v{r}\\'inek and\n  Michal P\\v{e}chou\\v{c}ek", "title": "Asynchronous Decentralized Algorithm for Space-Time Cooperative\n  Pathfinding", "comments": null, "journal-ref": "Spatio-Temporal Dynamics (STeDy 2012). Editors: Mehul Bhatt, Hans\n  Guesgen, and Ernest Davis. Workshop Proceedings of the European Conference on\n  Articial Intelligence (ECAI 2012), Montpellier, France", "doi": null, "report-no": null, "categories": "cs.AI cs.DC cs.RO", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  Cooperative pathfinding is a multi-agent path planning problem where a group\nof vehicles searches for a corresponding set of non-conflicting space-time\ntrajectories. Many of the practical methods for centralized solving of\ncooperative pathfinding problems are based on the prioritized planning\nstrategy. However, in some domains (e.g., multi-robot teams of unmanned aerial\nvehicles, autonomous underwater vehicles, or unmanned ground vehicles) a\ndecentralized approach may be more desirable than a centralized one due to\ncommunication limitations imposed by the domain and/or privacy concerns.\n  In this paper we present an asynchronous decentralized variant of prioritized\nplanning ADPP and its interruptible version IADPP. The algorithm exploits the\ninherent parallelism of distributed systems and allows for a speed up of the\ncomputation process. Unlike the synchronized planning approaches, the algorithm\nallows an agent to react to updates about other agents' paths immediately and\ninvoke its local spatio-temporal path planner to find the best trajectory, as\nresponse to the other agents' choices. We provide a proof of correctness of the\nalgorithms and experimentally evaluate them on synthetic domains.\n", "versions": [{"version": "v1", "created": "Thu, 25 Oct 2012 14:35:27 GMT"}], "update_date": "2012-10-26", "authors_parsed": [["\u010c\u00e1p", "Michal", ""], ["Nov\u00e1k", "Peter", ""], ["Vok\u0159\u00ednek", "Ji\u0159\u00ed", ""], ["P\u011bchou\u010dek", "Michal", ""]]}, {"id": "1210.7002", "submitter": "Abdelmalek Amine", "authors": "Mohamed Hamou, Abdelmalek Amine and Ahmed Chaouki Lokbani", "title": "A Biomimetic Approach Based on Immune Systems for Classification of\n  Unstructured Data", "comments": "10 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we present the results of unstructured data clustering in this\ncase a textual data from Reuters 21578 corpus with a new biomimetic approach\nusing immune system. Before experimenting our immune system, we digitalized\ntextual data by the n-grams approach. The novelty lies on hybridization of\nn-grams and immune systems for clustering. The experimental results show that\nthe recommended ideas are promising and prove that this method can solve the\ntext clustering problem.\n", "versions": [{"version": "v1", "created": "Thu, 25 Oct 2012 21:24:06 GMT"}], "update_date": "2012-10-29", "authors_parsed": [["Hamou", "Mohamed", ""], ["Amine", "Abdelmalek", ""], ["Lokbani", "Ahmed Chaouki", ""]]}, {"id": "1210.7038", "submitter": "Reza Oji", "authors": "Reza Oji and Farshad Tajeripour", "title": "Full Object Boundary Detection by Applying Scale Invariant Features in a\n  Region Merging Segmentation Algorithm", "comments": "10 pages - 7 figures", "journal-ref": "International Journal of Artificial Intelligence & Applications\n  (IJAIA) (2012) Volume 3, Number 5, pp: 41-50", "doi": "10.5121/ijaia.2012.3504", "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Object detection is a fundamental task in computer vision and has many\napplications in image processing. This paper proposes a new approach for object\ndetection by applying scale invariant feature transform (SIFT) in an automatic\nsegmentation algorithm. SIFT is an invariant algorithm respect to scale,\ntranslation and rotation. The features are very distinct and provide stable\nkeypoints that can be used for matching an object in different images. At\nfirst, an object is trained with different aspects for finding best keypoints.\nThe object can be recognized in the other images by using achieved keypoints.\nThen, a robust segmentation algorithm is used to detect the object with full\nboundary based on SIFT keypoints. In segmentation algorithm, a merging role is\ndefined to merge the regions in image with the assistance of keypoints. The\nresults show that the proposed approach is reliable for object detection and\ncan extract object boundary well.\n", "versions": [{"version": "v1", "created": "Fri, 26 Oct 2012 01:15:38 GMT"}], "update_date": "2012-10-29", "authors_parsed": [["Oji", "Reza", ""], ["Tajeripour", "Farshad", ""]]}, {"id": "1210.7053", "submitter": "Khoat Than", "authors": "Khoat Than and Tu Bao Ho", "title": "Managing sparsity, time, and quality of inference in topic models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.CV stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inference is an integral part of probabilistic topic models, but is often\nnon-trivial to derive an efficient algorithm for a specific model. It is even\nmuch more challenging when we want to find a fast inference algorithm which\nalways yields sparse latent representations of documents. In this article, we\nintroduce a simple framework for inference in probabilistic topic models,\ndenoted by FW. This framework is general and flexible enough to be easily\nadapted to mixture models. It has a linear convergence rate, offers an easy way\nto incorporate prior knowledge, and provides us an easy way to directly trade\noff sparsity against quality and time. We demonstrate the goodness and\nflexibility of FW over existing inference methods by a number of tasks.\nFinally, we show how inference in topic models with nonconjugate priors can be\ndone efficiently.\n", "versions": [{"version": "v1", "created": "Fri, 26 Oct 2012 05:23:25 GMT"}, {"version": "v2", "created": "Mon, 15 Apr 2013 00:09:46 GMT"}], "update_date": "2013-04-16", "authors_parsed": [["Than", "Khoat", ""], ["Ho", "Tu Bao", ""]]}, {"id": "1210.7154", "submitter": "Patrick Lambrix", "authors": "Patrick Lambrix, Zlatan Dragisic, Valentina Ivanova", "title": "Get my pizza right: Repairing missing is-a relations in ALC ontologies\n  (extended version)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the increased use of ontologies in semantically-enabled applications,\nthe issue of debugging defects in ontologies has become increasingly important.\nThese defects can lead to wrong or incomplete results for the applications.\nDebugging consists of the phases of detection and repairing. In this paper we\nfocus on the repairing phase of a particular kind of defects, i.e. the missing\nrelations in the is-a hierarchy. Previous work has dealt with the case of\ntaxonomies. In this work we extend the scope to deal with ALC ontologies that\ncan be represented using acyclic terminologies. We present algorithms and\ndiscuss a system.\n", "versions": [{"version": "v1", "created": "Fri, 26 Oct 2012 14:27:01 GMT"}], "update_date": "2012-10-29", "authors_parsed": [["Lambrix", "Patrick", ""], ["Dragisic", "Zlatan", ""], ["Ivanova", "Valentina", ""]]}, {"id": "1210.7495", "submitter": "Eduardo Mizraji", "authors": "Eduardo Mizraji", "title": "Illustrating a neural model of logic computations: The case of Sherlock\n  Holmes' old maxim", "comments": "Corrected version with new references", "journal-ref": "THEORIA 31/1 (2016): 7-25", "doi": "10.1387/theoria.13959", "report-no": null, "categories": "q-bio.NC cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Natural languages can express some logical propositions that humans are able\nto understand. We illustrate this fact with a famous text that Conan Doyle\nattributed to Holmes: 'It is an old maxim of mine that when you have excluded\nthe impossible, whatever remains, however improbable, must be the truth'. This\nis a subtle logical statement usually felt as an evident truth. The problem we\nare trying to solve is the cognitive reason for such a feeling. We postulate\nhere that we accept Holmes' maxim as true because our adult brains are equipped\nwith neural modules that naturally perform modal logical computations.\n", "versions": [{"version": "v1", "created": "Sun, 28 Oct 2012 19:37:33 GMT"}, {"version": "v2", "created": "Fri, 2 Nov 2012 12:00:10 GMT"}, {"version": "v3", "created": "Sat, 27 Feb 2016 14:45:52 GMT"}], "update_date": "2016-03-01", "authors_parsed": [["Mizraji", "Eduardo", ""]]}, {"id": "1210.7599", "submitter": "Krunoslav Zubrinic", "authors": "Krunoslav Zubrinic, Damir Kalpic, Mario Milicevic", "title": "The automatic creation of concept maps from documents written using\n  morphologically rich languages", "comments": "ISSN 0957-4174", "journal-ref": "Expert Systems with Applications, Volume 39, Issue 16, 2012, Pages\n  12709-12718", "doi": "10.1016/j.eswa.2012.04.065", "report-no": null, "categories": "cs.IR cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Concept map is a graphical tool for representing knowledge. They have been\nused in many different areas, including education, knowledge management,\nbusiness and intelligence. Constructing of concept maps manually can be a\ncomplex task; an unskilled person may encounter difficulties in determining and\npositioning concepts relevant to the problem area. An application that\nrecommends concept candidates and their position in a concept map can\nsignificantly help the user in that situation. This paper gives an overview of\ndifferent approaches to automatic and semi-automatic creation of concept maps\nfrom textual and non-textual sources. The concept map mining process is\ndefined, and one method suitable for the creation of concept maps from\nunstructured textual sources in highly inflected languages such as the Croatian\nlanguage is described in detail. Proposed method uses statistical and data\nmining techniques enriched with linguistic tools. With minor adjustments, that\nmethod can also be used for concept map mining from textual sources in other\nmorphologically rich languages.\n", "versions": [{"version": "v1", "created": "Mon, 29 Oct 2012 09:18:34 GMT"}, {"version": "v2", "created": "Sat, 27 Sep 2014 17:46:02 GMT"}], "update_date": "2014-09-30", "authors_parsed": [["Zubrinic", "Krunoslav", ""], ["Kalpic", "Damir", ""], ["Milicevic", "Mario", ""]]}, {"id": "1210.7959", "submitter": "Lars Kotthoff", "authors": "Lars Kotthoff", "title": "Algorithm Selection for Combinatorial Search Problems: A Survey", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Algorithm Selection Problem is concerned with selecting the best\nalgorithm to solve a given problem on a case-by-case basis. It has become\nespecially relevant in the last decade, as researchers are increasingly\ninvestigating how to identify the most suitable existing algorithm for solving\na problem instead of developing new algorithms. This survey presents an\noverview of this work focusing on the contributions made in the area of\ncombinatorial search problems, where Algorithm Selection techniques have\nachieved significant performance improvements. We unify and organise the vast\nliterature according to criteria that determine Algorithm Selection systems in\npractice. The comprehensive classification of approaches identifies and\nanalyses the different directions from which Algorithm Selection has been\napproached. This paper contrasts and compares different methods for solving the\nproblem as well as ways of using these solutions. It closes by identifying\ndirections of current and future research.\n", "versions": [{"version": "v1", "created": "Tue, 30 Oct 2012 10:48:21 GMT"}], "update_date": "2012-10-31", "authors_parsed": [["Kotthoff", "Lars", ""]]}, {"id": "1210.8099", "submitter": "Lane A. Hemaspaandra", "authors": "Lane A. Hemaspaandra and Ryan Williams", "title": "An Atypical Survey of Typical-Case Heuristic Algorithms", "comments": "This article is currently scheduled to appear in the December 2012\n  issue of SIGACT News", "journal-ref": null, "doi": null, "report-no": "URCS-TR-2012-984", "categories": "cs.CC cs.AI cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Heuristic approaches often do so well that they seem to pretty much always\ngive the right answer. How close can heuristic algorithms get to always giving\nthe right answer, without inducing seismic complexity-theoretic consequences?\nThis article first discusses how a series of results by Berman, Buhrman,\nHartmanis, Homer, Longpr\\'{e}, Ogiwara, Sch\\\"{o}ening, and Watanabe, from the\nearly 1970s through the early 1990s, explicitly or implicitly limited how well\nheuristic algorithms can do on NP-hard problems. In particular, many desirable\nlevels of heuristic success cannot be obtained unless severe, highly unlikely\ncomplexity class collapses occur. Second, we survey work initiated by Goldreich\nand Wigderson, who showed how under plausible assumptions deterministic\nheuristics for randomized computation can achieve a very high frequency of\ncorrectness. Finally, we consider formal ways in which theory can help explain\nthe effectiveness of heuristics that solve NP-hard problems in practice.\n", "versions": [{"version": "v1", "created": "Tue, 30 Oct 2012 17:50:49 GMT"}], "update_date": "2012-10-31", "authors_parsed": [["Hemaspaandra", "Lane A.", ""], ["Williams", "Ryan", ""]]}, {"id": "1210.8124", "submitter": "Habib Dhahri", "authors": "Habib Dhahri, Mohamed Adel Alimi", "title": "Hierarchical Learning Algorithm for the Beta Basis Function Neural\n  Network", "comments": null, "journal-ref": "Third International Conference on Systems, Signals & Device, March\n  21-24, 2005 , Sousse, Tunisia", "doi": null, "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper presents a two-level learning method for the design of the Beta\nBasis Function Neural Network BBFNN. A Genetic Algorithm is employed at the\nupper level to construct BBFNN, while the key learning parameters :the width,\nthe centers and the Beta form are optimised using the gradient algorithm at the\nlower level. In order to demonstrate the effectiveness of this hierarchical\nlearning algorithm HLABBFNN, we need to validate our algorithm for the\napproximation of non-linear function.\n", "versions": [{"version": "v1", "created": "Tue, 30 Oct 2012 19:11:06 GMT"}], "update_date": "2012-10-31", "authors_parsed": [["Dhahri", "Habib", ""], ["Alimi", "Mohamed Adel", ""]]}, {"id": "1210.8260", "submitter": "Serge Massar", "authors": "Marc Massar, Serge Massar", "title": "Mean Field Theory of Dynamical Systems Driven by External Signals", "comments": "7 pages, 6 figures", "journal-ref": "Physical Review E 87, 042809 (2013)", "doi": "10.1103/PhysRevE.87.042809", "report-no": null, "categories": "nlin.CD cond-mat.dis-nn cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dynamical systems driven by strong external signals are ubiquituous in nature\nand engineering. Here we study \"echo state networks\", networks of a large\nnumber of randomly connected nodes, which represent a simple model of a neural\nnetwork, and have important applications in machine learning. We develop a mean\nfield theory of echo state networks. The dynamics of the network is captured by\nthe evolution law, similar to a logistic map, for a single collective variable.\nWhen the network is driven by many independent external signals, this\ncollective variable reaches a steady state. But when the network is driven by a\nsingle external signal, the collective variable is nonstationnary but can be\ncharacterised by its time averaged distribution. The predictions of the mean\nfield theory, including the value of the largest Lyaponuov exponent, are\ncompared with the numerical integration of the equations of motion.\n", "versions": [{"version": "v1", "created": "Wed, 31 Oct 2012 08:22:48 GMT"}, {"version": "v2", "created": "Wed, 13 Mar 2013 09:08:43 GMT"}], "update_date": "2013-11-07", "authors_parsed": [["Massar", "Marc", ""], ["Massar", "Serge", ""]]}, {"id": "1210.8291", "submitter": "Huanhuan Chen", "authors": "Huanhuan Chen, Peter Tino, Xin Yao, and Ali Rodan", "title": "Learning in the Model Space for Fault Diagnosis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The emergence of large scaled sensor networks facilitates the collection of\nlarge amounts of real-time data to monitor and control complex engineering\nsystems. However, in many cases the collected data may be incomplete or\ninconsistent, while the underlying environment may be time-varying or\nun-formulated. In this paper, we have developed an innovative cognitive fault\ndiagnosis framework that tackles the above challenges. This framework\ninvestigates fault diagnosis in the model space instead of in the signal space.\nLearning in the model space is implemented by fitting a series of models using\na series of signal segments selected with a rolling window. By investigating\nthe learning techniques in the fitted model space, faulty models can be\ndiscriminated from healthy models using one-class learning algorithm. The\nframework enables us to construct fault library when unknown faults occur,\nwhich can be regarded as cognitive fault isolation. This paper also\ntheoretically investigates how to measure the pairwise distance between two\nmodels in the model space and incorporates the model distance into the learning\nalgorithm in the model space. The results on three benchmark applications and\none simulated model for the Barcelona water distribution network have confirmed\nthe effectiveness of the proposed framework.\n", "versions": [{"version": "v1", "created": "Wed, 31 Oct 2012 10:42:32 GMT"}], "update_date": "2012-11-01", "authors_parsed": [["Chen", "Huanhuan", ""], ["Tino", "Peter", ""], ["Yao", "Xin", ""], ["Rodan", "Ali", ""]]}, {"id": "1210.8353", "submitter": "Alex Susemihl", "authors": "Chris H\\\"ausler, Alex Susemihl", "title": "Temporal Autoencoding Restricted Boltzmann Machine", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Much work has been done refining and characterizing the receptive fields\nlearned by deep learning algorithms. A lot of this work has focused on the\ndevelopment of Gabor-like filters learned when enforcing sparsity constraints\non a natural image dataset. Little work however has investigated how these\nfilters might expand to the temporal domain, namely through training on natural\nmovies. Here we investigate exactly this problem in established temporal deep\nlearning algorithms as well as a new learning paradigm suggested here, the\nTemporal Autoencoding Restricted Boltzmann Machine (TARBM).\n", "versions": [{"version": "v1", "created": "Wed, 31 Oct 2012 14:55:50 GMT"}], "update_date": "2012-11-01", "authors_parsed": [["H\u00e4usler", "Chris", ""], ["Susemihl", "Alex", ""]]}, {"id": "1210.8385", "submitter": "Rupesh Kumar Srivastava", "authors": "Rupesh Kumar Srivastava, Bas R. Steunebrink and J\\\"urgen Schmidhuber", "title": "First Experiments with PowerPlay", "comments": "13 pages, 6 figures. Extends preliminary work presented at\n  ICDL-EpiRob 2012", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  Like a scientist or a playing child, PowerPlay not only learns new skills to\nsolve given problems, but also invents new interesting problems by itself. By\ndesign, it continually comes up with the fastest to find, initially novel, but\neventually solvable tasks. It also continually simplifies or compresses or\nspeeds up solutions to previous tasks. Here we describe first experiments with\nPowerPlay. A self-delimiting recurrent neural network SLIM RNN is used as a\ngeneral computational problem solving architecture. Its connection weights can\nencode arbitrary, self-delimiting, halting or non-halting programs affecting\nboth environment (through effectors) and internal states encoding abstractions\nof event sequences. Our PowerPlay-driven SLIM RNN learns to become an\nincreasingly general solver of self-invented problems, continually adding new\nproblem solving procedures to its growing skill repertoire. Extending a recent\nconference paper, we identify interesting, emerging, developmental stages of\nour open-ended system. We also show how it automatically self-modularizes,\nfrequently re-using code for previously invented skills, always trying to\ninvent novel tasks that can be quickly validated because they do not require\ntoo many weight changes affecting too many previous tasks.\n", "versions": [{"version": "v1", "created": "Wed, 31 Oct 2012 16:41:37 GMT"}], "update_date": "2012-11-01", "authors_parsed": [["Srivastava", "Rupesh Kumar", ""], ["Steunebrink", "Bas R.", ""], ["Schmidhuber", "J\u00fcrgen", ""]]}, {"id": "1210.8442", "submitter": "Louis Shao", "authors": "Louis Yuanlong Shao", "title": "Linear-Nonlinear-Poisson Neuron Networks Perform Bayesian Inference On\n  Boltzmann Machines", "comments": "Submitted to International Conference of Learning Representation\n  (ICLR) 2013", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.NE q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One conjecture in both deep learning and classical connectionist viewpoint is\nthat the biological brain implements certain kinds of deep networks as its\nback-end. However, to our knowledge, a detailed correspondence has not yet been\nset up, which is important if we want to bridge between neuroscience and\nmachine learning. Recent researches emphasized the biological plausibility of\nLinear-Nonlinear-Poisson (LNP) neuron model. We show that with neurally\nplausible settings, the whole network is capable of representing any Boltzmann\nmachine and performing a semi-stochastic Bayesian inference algorithm lying\nbetween Gibbs sampling and variational inference.\n", "versions": [{"version": "v1", "created": "Wed, 31 Oct 2012 19:14:41 GMT"}, {"version": "v2", "created": "Tue, 15 Jan 2013 01:23:04 GMT"}, {"version": "v3", "created": "Sun, 27 Jan 2013 05:30:35 GMT"}], "update_date": "2013-01-29", "authors_parsed": [["Shao", "Louis Yuanlong", ""]]}]