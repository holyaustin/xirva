[{"id": "2005.00110", "submitter": "Shane Steinert-Threlkeld", "authors": "Nur Geffen Lan, Emmanuel Chemla, Shane Steinert-Threlkeld", "title": "On the Spontaneous Emergence of Discrete and Compositional Signals", "comments": "ACL 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a general framework to study language emergence through signaling\ngames with neural agents. Using a continuous latent space, we are able to (i)\ntrain using backpropagation, (ii) show that discrete messages nonetheless\nnaturally emerge. We explore whether categorical perception effects follow and\nshow that the messages are not compositional.\n", "versions": [{"version": "v1", "created": "Thu, 30 Apr 2020 21:15:19 GMT"}], "update_date": "2020-05-04", "authors_parsed": [["Lan", "Nur Geffen", ""], ["Chemla", "Emmanuel", ""], ["Steinert-Threlkeld", "Shane", ""]]}, {"id": "2005.00115", "submitter": "Sarthak Jain", "authors": "Sarthak Jain, Sarah Wiegreffe, Yuval Pinter, Byron C. Wallace", "title": "Learning to Faithfully Rationalize by Construction", "comments": "ACL2020 Camera Ready Submission", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many settings it is important for one to be able to understand why a model\nmade a particular prediction. In NLP this often entails extracting snippets of\nan input text `responsible for' corresponding model output; when such a snippet\ncomprises tokens that indeed informed the model's prediction, it is a faithful\nexplanation. In some settings, faithfulness may be critical to ensure\ntransparency. Lei et al. (2016) proposed a model to produce faithful rationales\nfor neural text classification by defining independent snippet extraction and\nprediction modules. However, the discrete selection over input tokens performed\nby this method complicates training, leading to high variance and requiring\ncareful hyperparameter tuning. We propose a simpler variant of this approach\nthat provides faithful explanations by construction. In our scheme, named\nFRESH, arbitrary feature importance scores (e.g., gradients from a trained\nmodel) are used to induce binary labels over token inputs, which an extractor\ncan be trained to predict. An independent classifier module is then trained\nexclusively on snippets provided by the extractor; these snippets thus\nconstitute faithful explanations, even if the classifier is arbitrarily\ncomplex. In both automatic and manual evaluations we find that variants of this\nsimple framework yield predictive performance superior to `end-to-end'\napproaches, while being more general and easier to train. Code is available at\nhttps://github.com/successar/FRESH\n", "versions": [{"version": "v1", "created": "Thu, 30 Apr 2020 21:45:40 GMT"}], "update_date": "2020-05-04", "authors_parsed": [["Jain", "Sarthak", ""], ["Wiegreffe", "Sarah", ""], ["Pinter", "Yuval", ""], ["Wallace", "Byron C.", ""]]}, {"id": "2005.00130", "submitter": "Thanos Tagaris", "authors": "Thanos Tagaris, Andreas Stafylopatis", "title": "Hide-and-Seek: A Template for Explainable AI", "comments": "24 pages, 14 figures. Submitted on a special issue for Explainable\n  AI, on Elsevier's \"Artificial Intelligence\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Lack of transparency has been the Achilles heal of Neural Networks and their\nwider adoption in industry. Despite significant interest this shortcoming has\nnot been adequately addressed. This study proposes a novel framework called\nHide-and-Seek (HnS) for training Interpretable Neural Networks and establishes\na theoretical foundation for exploring and comparing similar ideas. Extensive\nexperimentation indicates that a high degree of interpretability can be imputed\ninto Neural Networks, without sacrificing their predictive power.\n", "versions": [{"version": "v1", "created": "Thu, 30 Apr 2020 22:34:37 GMT"}], "update_date": "2020-05-04", "authors_parsed": [["Tagaris", "Thanos", ""], ["Stafylopatis", "Andreas", ""]]}, {"id": "2005.00153", "submitter": "Gong Cheng", "authors": "Shuxin Li, Zixian Huang, Gong Cheng, Evgeny Kharlamov, Kalpa Gunaratna", "title": "Enriching Documents with Compact, Representative, Relevant Knowledge\n  Graphs", "comments": "7 pages, accepted to IJCAI-PRICAI 2020. The paper is temporarily\n  withdrawn due to company policies", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.IR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  A prominent application of knowledge graph (KG) is document enrichment.\nExisting methods identify mentions of entities in a background KG and enrich\ndocuments with entity types and direct relations. We compute an entity relation\nsubgraph (ERG) that can more expressively represent indirect relations among a\nset of mentioned entities. To find compact, representative, and relevant ERGs\nfor effective enrichment, we propose an efficient best-first search algorithm\nto solve a new combinatorial optimization problem that achieves a trade-off\nbetween representativeness and compactness, and then we exploit ontological\nknowledge to rank ERGs by entity-based document-KG and intra-KG relevance.\nExtensive experiments and user studies show the promising performance of our\napproach.\n", "versions": [{"version": "v1", "created": "Fri, 1 May 2020 00:18:31 GMT"}, {"version": "v2", "created": "Sun, 10 May 2020 08:29:28 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["Li", "Shuxin", ""], ["Huang", "Zixian", ""], ["Cheng", "Gong", ""], ["Kharlamov", "Evgeny", ""], ["Gunaratna", "Kalpa", ""]]}, {"id": "2005.00158", "submitter": "Mohammed Belkhatir", "authors": "M. Maree, M. Belkhatir", "title": "On the Merging of Domain-Specific Heterogeneous Ontologies using Wordnet\n  and Web Pattern-based Queries", "comments": null, "journal-ref": null, "doi": "10.1142/S0219649211002808", "report-no": null, "categories": "cs.IR cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ontologies form the basic interest in various computer science disciplines\nsuch as semantic web, information retrieval, database design, etc. They aim at\nproviding a formal, explicit and shared conceptualization and understanding of\ncommon domains between different communities. In addition, they allow for\nconcepts and their constraints of a specific domain to be explicitly defined.\nHowever, the distributed nature of ontology development and the differences in\nviewpoints of the ontology engineers have resulted in the so called \"semantic\nheterogeneity\" between ontologies. Semantic heterogeneity constitutes the major\nobstacle against achieving interoperability between ontologies. To overcome\nthis obstacle, we present a multi-purpose framework which exploits the WordNet\ngeneric knowledge base for: i) Discovering and correcting the incorrect\nsemantic relations between the concepts of the ontology in a specific domain.\nThis step is a primary step of ontology merging. ii) Merging domain-specific\nontologies through computing semantic relations between their concepts. iii)\nHandling the issue of missing concepts in WordNet through the acquisition of\nstatistical information on the Web. And iv) Enriching WordNet with these\nmissing concepts. An experimental instantiation of the framework and\ncomparisons with state-of-the-art syntactic and semantic-based systems validate\nour proposal.\n", "versions": [{"version": "v1", "created": "Thu, 30 Apr 2020 05:03:50 GMT"}], "update_date": "2020-05-04", "authors_parsed": [["Maree", "M.", ""], ["Belkhatir", "M.", ""]]}, {"id": "2005.00171", "submitter": "Muhao Chen", "authors": "Muhao Chen, Weijia Shi, Ben Zhou, Dan Roth", "title": "Cross-lingual Entity Alignment with Incidental Supervision", "comments": "EACL 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Much research effort has been put to multilingual knowledge graph (KG)\nembedding methods to address the entity alignment task, which seeks to match\nentities in different languagespecific KGs that refer to the same real-world\nobject. Such methods are often hindered by the insufficiency of seed alignment\nprovided between KGs. Therefore, we propose an incidentally supervised model,\nJEANS , which jointly represents multilingual KGs and text corpora in a shared\nembedding scheme, and seeks to improve entity alignment with incidental\nsupervision signals from text. JEANS first deploys an entity grounding process\nto combine each KG with the monolingual text corpus. Then, two learning\nprocesses are conducted: (i) an embedding learning process to encode the KG and\ntext of each language in one embedding space, and (ii) a selflearning based\nalignment learning process to iteratively induce the matching of entities and\nthat of lexemes between embeddings. Experiments on benchmark datasets show that\nJEANS leads to promising improvement on entity alignment with incidental\nsupervision, and significantly outperforms state-of-the-art methods that solely\nrely on internal information of KGs.\n", "versions": [{"version": "v1", "created": "Fri, 1 May 2020 01:53:56 GMT"}, {"version": "v2", "created": "Tue, 26 Jan 2021 05:15:45 GMT"}], "update_date": "2021-01-27", "authors_parsed": [["Chen", "Muhao", ""], ["Shi", "Weijia", ""], ["Zhou", "Ben", ""], ["Roth", "Dan", ""]]}, {"id": "2005.00206", "submitter": "Hongming Zhang", "authors": "Hongming Zhang, Daniel Khashabi, Yangqiu Song, Dan Roth", "title": "TransOMCS: From Linguistic Graphs to Commonsense Knowledge", "comments": "Accepted by IJCAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Commonsense knowledge acquisition is a key problem for artificial\nintelligence. Conventional methods of acquiring commonsense knowledge generally\nrequire laborious and costly human annotations, which are not feasible on a\nlarge scale. In this paper, we explore a practical way of mining commonsense\nknowledge from linguistic graphs, with the goal of transferring cheap knowledge\nobtained with linguistic patterns into expensive commonsense knowledge. The\nresult is a conversion of ASER [Zhang et al., 2020], a large-scale selectional\npreference knowledge resource, into TransOMCS, of the same representation as\nConceptNet [Liu and Singh, 2004] but two orders of magnitude larger.\nExperimental results demonstrate the transferability of linguistic knowledge to\ncommonsense knowledge and the effectiveness of the proposed approach in terms\nof quantity, novelty, and quality. TransOMCS is publicly available at:\nhttps://github.com/HKUST-KnowComp/TransOMCS.\n", "versions": [{"version": "v1", "created": "Fri, 1 May 2020 04:03:58 GMT"}], "update_date": "2020-05-04", "authors_parsed": [["Zhang", "Hongming", ""], ["Khashabi", "Daniel", ""], ["Song", "Yangqiu", ""], ["Roth", "Dan", ""]]}, {"id": "2005.00316", "submitter": "Pratyay Banerjee", "authors": "Pratyay Banerjee, Chitta Baral", "title": "Self-supervised Knowledge Triplet Learning for Zero-shot Question\n  Answering", "comments": "Accepted to EMNLP 2020 Long Papers", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The aim of all Question Answering (QA) systems is to be able to generalize to\nunseen questions. Current supervised methods are reliant on expensive data\nannotation. Moreover, such annotations can introduce unintended annotator bias\nwhich makes systems focus more on the bias than the actual task. In this work,\nwe propose Knowledge Triplet Learning (KTL), a self-supervised task over\nknowledge graphs. We propose heuristics to create synthetic graphs for\ncommonsense and scientific knowledge. We propose methods of how to use KTL to\nperform zero-shot QA and our experiments show considerable improvements over\nlarge pre-trained transformer models.\n", "versions": [{"version": "v1", "created": "Fri, 1 May 2020 11:24:18 GMT"}, {"version": "v2", "created": "Thu, 17 Sep 2020 20:49:29 GMT"}], "update_date": "2020-09-21", "authors_parsed": [["Banerjee", "Pratyay", ""], ["Baral", "Chitta", ""]]}, {"id": "2005.00329", "submitter": "Lei Shen", "authors": "Lei Shen, Yang Feng", "title": "CDL: Curriculum Dual Learning for Emotion-Controllable Response\n  Generation", "comments": "To appear at ACL 2020 (long paper)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Emotion-controllable response generation is an attractive and valuable task\nthat aims to make open-domain conversations more empathetic and engaging.\nExisting methods mainly enhance the emotion expression by adding regularization\nterms to standard cross-entropy loss and thus influence the training process.\nHowever, due to the lack of further consideration of content consistency, the\ncommon problem of response generation tasks, safe response, is intensified.\nBesides, query emotions that can help model the relationship between query and\nresponse are simply ignored in previous models, which would further hurt the\ncoherence. To alleviate these problems, we propose a novel framework named\nCurriculum Dual Learning (CDL) which extends the emotion-controllable response\ngeneration to a dual task to generate emotional responses and emotional queries\nalternatively. CDL utilizes two rewards focusing on emotion and content to\nimprove the duality. Additionally, it applies curriculum learning to gradually\ngenerate high-quality responses based on the difficulties of expressing various\nemotions. Experimental results show that CDL significantly outperforms the\nbaselines in terms of coherence, diversity, and relation to emotion factors.\n", "versions": [{"version": "v1", "created": "Fri, 1 May 2020 12:16:44 GMT"}, {"version": "v2", "created": "Tue, 5 May 2020 04:31:34 GMT"}, {"version": "v3", "created": "Thu, 28 May 2020 09:39:15 GMT"}, {"version": "v4", "created": "Wed, 3 Jun 2020 11:31:47 GMT"}, {"version": "v5", "created": "Sun, 7 Jun 2020 12:54:28 GMT"}], "update_date": "2020-06-09", "authors_parsed": [["Shen", "Lei", ""], ["Feng", "Yang", ""]]}, {"id": "2005.00330", "submitter": "Shailaja Keyur Sampat", "authors": "Shailaja Keyur Sampat, Yezhou Yang and Chitta Baral", "title": "Visuo-Linguistic Question Answering (VLQA) Challenge", "comments": "Findings of EMNLP 2020 (22 pages, 13 figures)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding images and text together is an important aspect of cognition\nand building advanced Artificial Intelligence (AI) systems. As a community, we\nhave achieved good benchmarks over language and vision domains separately,\nhowever joint reasoning is still a challenge for state-of-the-art computer\nvision and natural language processing (NLP) systems. We propose a novel task\nto derive joint inference about a given image-text modality and compile the\nVisuo-Linguistic Question Answering (VLQA) challenge corpus in a question\nanswering setting. Each dataset item consists of an image and a reading\npassage, where questions are designed to combine both visual and textual\ninformation i.e., ignoring either modality would make the question\nunanswerable. We first explore the best existing vision-language architectures\nto solve VLQA subsets and show that they are unable to reason well. We then\ndevelop a modular method with slightly better baseline performance, but it is\nstill far behind human performance. We believe that VLQA will be a good\nbenchmark for reasoning over a visuo-linguistic context. The dataset, code and\nleaderboard is available at https://shailaja183.github.io/vlqa/.\n", "versions": [{"version": "v1", "created": "Fri, 1 May 2020 12:18:55 GMT"}, {"version": "v2", "created": "Thu, 8 Oct 2020 01:06:30 GMT"}, {"version": "v3", "created": "Wed, 18 Nov 2020 07:45:20 GMT"}], "update_date": "2020-11-19", "authors_parsed": [["Sampat", "Shailaja Keyur", ""], ["Yang", "Yezhou", ""], ["Baral", "Chitta", ""]]}, {"id": "2005.00463", "submitter": "George Awad", "authors": "Keith Curtis, George Awad, Shahzad Rajput, and Ian Soboroff", "title": "HLVU : A New Challenge to Test Deep Understanding of Movies the Way\n  Humans do", "comments": null, "journal-ref": null, "doi": "10.1145/3372278.3390742", "report-no": null, "categories": "cs.AI cs.CL cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we propose a new evaluation challenge and direction in the area\nof High-level Video Understanding. The challenge we are proposing is designed\nto test automatic video analysis and understanding, and how accurately systems\ncan comprehend a movie in terms of actors, entities, events and their\nrelationship to each other. A pilot High-Level Video Understanding (HLVU)\ndataset of open source movies were collected for human assessors to build a\nknowledge graph representing each of them. A set of queries will be derived\nfrom the knowledge graph to test systems on retrieving relationships among\nactors, as well as reasoning and retrieving non-visual concepts. The objective\nis to benchmark if a computer system can \"understand\" non-explicit but obvious\nrelationships the same way humans do when they watch the same movies. This is\nlong-standing problem that is being addressed in the text domain and this\nproject moves similar research to the video domain. Work of this nature is\nfoundational to future video analytics and video understanding technologies.\nThis work can be of interest to streaming services and broadcasters hoping to\nprovide more intuitive ways for their customers to interact with and consume\nvideo content.\n", "versions": [{"version": "v1", "created": "Fri, 1 May 2020 15:58:13 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Curtis", "Keith", ""], ["Awad", "George", ""], ["Rajput", "Shahzad", ""], ["Soboroff", "Ian", ""]]}, {"id": "2005.00527", "submitter": "Ruosong Wang", "authors": "Ruosong Wang, Simon S. Du, Lin F. Yang, Sham M. Kakade", "title": "Is Long Horizon Reinforcement Learning More Difficult Than Short Horizon\n  Reinforcement Learning?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning to plan for long horizons is a central challenge in episodic\nreinforcement learning problems. A fundamental question is to understand how\nthe difficulty of the problem scales as the horizon increases. Here the natural\nmeasure of sample complexity is a normalized one: we are interested in the\nnumber of episodes it takes to provably discover a policy whose value is\n$\\varepsilon$ near to that of the optimal value, where the value is measured by\nthe normalized cumulative reward in each episode. In a COLT 2018 open problem,\nJiang and Agarwal conjectured that, for tabular, episodic reinforcement\nlearning problems, there exists a sample complexity lower bound which exhibits\na polynomial dependence on the horizon -- a conjecture which is consistent with\nall known sample complexity upper bounds. This work refutes this conjecture,\nproving that tabular, episodic reinforcement learning is possible with a sample\ncomplexity that scales only logarithmically with the planning horizon. In other\nwords, when the values are appropriately normalized (to lie in the unit\ninterval), this results shows that long horizon RL is no more difficult than\nshort horizon RL, at least in a minimax sense. Our analysis introduces two\nideas: (i) the construction of an $\\varepsilon$-net for optimal policies whose\nlog-covering number scales only logarithmically with the planning horizon, and\n(ii) the Online Trajectory Synthesis algorithm, which adaptively evaluates all\npolicies in a given policy class using sample complexity that scales with the\nlog-covering number of the given policy class. Both may be of independent\ninterest.\n", "versions": [{"version": "v1", "created": "Fri, 1 May 2020 17:56:38 GMT"}, {"version": "v2", "created": "Thu, 9 Jul 2020 16:20:06 GMT"}], "update_date": "2020-07-10", "authors_parsed": [["Wang", "Ruosong", ""], ["Du", "Simon S.", ""], ["Yang", "Lin F.", ""], ["Kakade", "Sham M.", ""]]}, {"id": "2005.00545", "submitter": "Ines Chami", "authors": "Ines Chami, Adva Wolf, Da-Cheng Juan, Frederic Sala, Sujith Ravi and\n  Christopher R\\'e", "title": "Low-Dimensional Hyperbolic Knowledge Graph Embeddings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge graph (KG) embeddings learn low-dimensional representations of\nentities and relations to predict missing facts. KGs often exhibit hierarchical\nand logical patterns which must be preserved in the embedding space. For\nhierarchical data, hyperbolic embedding methods have shown promise for\nhigh-fidelity and parsimonious representations. However, existing hyperbolic\nembedding methods do not account for the rich logical patterns in KGs. In this\nwork, we introduce a class of hyperbolic KG embedding models that\nsimultaneously capture hierarchical and logical patterns. Our approach combines\nhyperbolic reflections and rotations with attention to model complex relational\npatterns. Experimental results on standard KG benchmarks show that our method\nimproves over previous Euclidean- and hyperbolic-based efforts by up to 6.1% in\nmean reciprocal rank (MRR) in low dimensions. Furthermore, we observe that\ndifferent geometric transformations capture different types of relations while\nattention-based transformations generalize to multiple relations. In high\ndimensions, our approach yields new state-of-the-art MRRs of 49.6% on WN18RR\nand 57.7% on YAGO3-10.\n", "versions": [{"version": "v1", "created": "Fri, 1 May 2020 18:00:02 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Chami", "Ines", ""], ["Wolf", "Adva", ""], ["Juan", "Da-Cheng", ""], ["Sala", "Frederic", ""], ["Ravi", "Sujith", ""], ["R\u00e9", "Christopher", ""]]}, {"id": "2005.00558", "submitter": "Yizhe Zhang", "authors": "Yizhe Zhang, Guoyin Wang, Chunyuan Li, Zhe Gan, Chris Brockett, Bill\n  Dolan", "title": "POINTER: Constrained Progressive Text Generation via Insertion-based\n  Generative Pre-training", "comments": "EMNLP 2020 long paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large-scale pre-trained language models, such as BERT and GPT-2, have\nachieved excellent performance in language representation learning and\nfree-form text generation. However, these models cannot be directly employed to\ngenerate text under specified lexical constraints. To address this challenge,\nwe present POINTER (PrOgressive INsertion-based TransformER), a simple yet\nnovel insertion-based approach for hard-constrained text generation. The\nproposed method operates by progressively inserting new tokens between existing\ntokens in a parallel manner. This procedure is recursively applied until a\nsequence is completed. The resulting coarse-to-fine hierarchy makes the\ngeneration process intuitive and interpretable. We pre-train our model with the\nproposed progressive insertion-based objective on a 12GB Wikipedia dataset, and\nfine-tune it on downstream hard-constrained generation tasks.\nNon-autoregressive decoding yields an empirically logarithmic time complexity\nduring inference time. Experimental results on both News and Yelp datasets\ndemonstrate that POINTER achieves state-of-the-art performance on constrained\ntext generation. We released the pre-trained models and the source code to\nfacilitate future research (https://github.com/dreasysnail/POINTER).\n", "versions": [{"version": "v1", "created": "Fri, 1 May 2020 18:11:54 GMT"}, {"version": "v2", "created": "Sun, 27 Sep 2020 00:07:39 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Zhang", "Yizhe", ""], ["Wang", "Guoyin", ""], ["Li", "Chunyuan", ""], ["Gan", "Zhe", ""], ["Brockett", "Chris", ""], ["Dolan", "Bill", ""]]}, {"id": "2005.00565", "submitter": "Wouter van Heeswijk PhD", "authors": "Wouter van Heeswijk", "title": "Smart Containers With Bidding Capacity: A Policy Gradient Algorithm for\n  Semi-Cooperative Learning", "comments": "15 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Smart modular freight containers -- as propagated in the Physical Internet\nparadigm -- are equipped with sensors, data storage capability and intelligence\nthat enable them to route themselves from origin to destination without manual\nintervention or central governance. In this self-organizing setting, containers\ncan autonomously place bids on transport services in a spot market setting.\nHowever, for individual containers it may be difficult to learn good bidding\npolicies due to limited observations. By sharing information and costs between\none another, smart containers can jointly learn bidding policies, even though\nsimultaneously competing for the same transport capacity. We replicate this\nbehavior by learning stochastic bidding policies in a semi-cooperative multi\nagent setting. To this end, we develop a reinforcement learning algorithm based\non the policy gradient framework. Numerical experiments show that sharing\nsolely bids and acceptance decisions leads to stable bidding policies.\nAdditional system information only marginally improves performance; individual\njob properties suffice to place appropriate bids. Furthermore, we find that\ncarriers may have incentives not to share information with the smart\ncontainers. The experiments give rise to several directions for follow-up\nresearch, in particular the interaction between smart containers and transport\nservices in self-organizing logistics.\n", "versions": [{"version": "v1", "created": "Fri, 1 May 2020 18:37:38 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["van Heeswijk", "Wouter", ""]]}, {"id": "2005.00571", "submitter": "Deren Lei", "authors": "Deren Lei and Gangrong Jiang and Xiaotao Gu and Kexuan Sun and Yuning\n  Mao and Xiang Ren", "title": "Learning Collaborative Agents with Rule Guidance for Knowledge Graph\n  Reasoning", "comments": "EMNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Walk-based models have shown their advantages in knowledge graph (KG)\nreasoning by achieving decent performance while providing interpretable\ndecisions. However, the sparse reward signals offered by the KG during\ntraversal are often insufficient to guide a sophisticated walk-based\nreinforcement learning (RL) model. An alternate approach is to use traditional\nsymbolic methods (e.g., rule induction), which achieve good performance but can\nbe hard to generalize due to the limitation of symbolic representation. In this\npaper, we propose RuleGuider, which leverages high-quality rules generated by\nsymbolic-based methods to provide reward supervision for walk-based agents.\nExperiments on benchmark datasets show that RuleGuider improves the performance\nof walk-based models without losing interpretability.\n", "versions": [{"version": "v1", "created": "Fri, 1 May 2020 18:57:14 GMT"}, {"version": "v2", "created": "Tue, 6 Oct 2020 10:13:30 GMT"}], "update_date": "2020-10-07", "authors_parsed": [["Lei", "Deren", ""], ["Jiang", "Gangrong", ""], ["Gu", "Xiaotao", ""], ["Sun", "Kexuan", ""], ["Mao", "Yuning", ""], ["Ren", "Xiang", ""]]}, {"id": "2005.00582", "submitter": "Bryan Wilder", "authors": "Bryan Wilder, Eric Horvitz, Ece Kamar", "title": "Learning to Complement Humans", "comments": "Accepted at IJCAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A rising vision for AI in the open world centers on the development of\nsystems that can complement humans for perceptual, diagnostic, and reasoning\ntasks. To date, systems aimed at complementing the skills of people have\nemployed models trained to be as accurate as possible in isolation. We\ndemonstrate how an end-to-end learning strategy can be harnessed to optimize\nthe combined performance of human-machine teams by considering the distinct\nabilities of people and machines. The goal is to focus machine learning on\nproblem instances that are difficult for humans, while recognizing instances\nthat are difficult for the machine and seeking human input on them. We\ndemonstrate in two real-world domains (scientific discovery and medical\ndiagnosis) that human-machine teams built via these methods outperform the\nindividual performance of machines and people. We then analyze conditions under\nwhich this complementarity is strongest, and which training methods amplify it.\nTaken together, our work provides the first systematic investigation of how\nmachine learning systems can be trained to complement human reasoning.\n", "versions": [{"version": "v1", "created": "Fri, 1 May 2020 20:00:23 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Wilder", "Bryan", ""], ["Horvitz", "Eric", ""], ["Kamar", "Ece", ""]]}, {"id": "2005.00603", "submitter": "Gustavo Olague Dr.", "authors": "Francisco Fern\\'andez de Vega, Gustavo Olague, Francisco Ch\\'avez,\n  Daniel Lanza, Wolfgang Banzhaf, and Erik Goodman", "title": "It is Time for New Perspectives on How to Fight Bloat in GP", "comments": null, "journal-ref": "Genetic Programming Theory and Practice XVII, 8 May 2020", "doi": "10.1007/978-3-030-39958-0_2", "report-no": null, "categories": "cs.NE cs.AI cs.SC", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The present and future of evolutionary algorithms depends on the proper use\nof modern parallel and distributed computing infrastructures. Although still\nsequential approaches dominate the landscape, available multi-core, many-core\nand distributed systems will make users and researchers to more frequently\ndeploy parallel version of the algorithms. In such a scenario, new\npossibilities arise regarding the time saved when parallel evaluation of\nindividuals are performed. And this time saving is particularly relevant in\nGenetic Programming. This paper studies how evaluation time influences not only\ntime to solution in parallel/distributed systems, but may also affect size\nevolution of individuals in the population, and eventually will reduce the\nbloat phenomenon GP features. This paper considers time and space as two sides\nof a single coin when devising a more natural method for fighting bloat. This\nnew perspective allows us to understand that new methods for bloat control can\nbe derived, and the first of such a method is described and tested.\nExperimental data confirms the strength of the approach: using computing time\nas a measure of individuals' complexity allows to control the growth in size of\ngenetic programming individuals.\n", "versions": [{"version": "v1", "created": "Fri, 1 May 2020 20:59:24 GMT"}], "update_date": "2021-03-02", "authors_parsed": [["de Vega", "Francisco Fern\u00e1ndez", ""], ["Olague", "Gustavo", ""], ["Ch\u00e1vez", "Francisco", ""], ["Lanza", "Daniel", ""], ["Banzhaf", "Wolfgang", ""], ["Goodman", "Erik", ""]]}, {"id": "2005.00610", "submitter": "Joris Mooij", "authors": "Joris M. Mooij and Tom Claassen", "title": "Constraint-Based Causal Discovery using Partial Ancestral Graphs in the\n  presence of Cycles", "comments": "Major revision. To appear in Proceedings of the 36 th Conference on\n  Uncertainty in Artificial Intelligence (UAI), PMLR volume 124, 2020", "journal-ref": "Proceedings of Machine Learning Research 124 (2020) 1159-1168", "doi": null, "report-no": null, "categories": "math.ST cs.AI cs.LG stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While feedback loops are known to play important roles in many complex\nsystems, their existence is ignored in a large part of the causal discovery\nliterature, as systems are typically assumed to be acyclic from the outset.\nWhen applying causal discovery algorithms designed for the acyclic setting on\ndata generated by a system that involves feedback, one would not expect to\nobtain correct results. In this work, we show that---surprisingly---the output\nof the Fast Causal Inference (FCI) algorithm is correct if it is applied to\nobservational data generated by a system that involves feedback. More\nspecifically, we prove that for observational data generated by a simple and\n$\\sigma$-faithful Structural Causal Model (SCM), FCI is sound and complete, and\ncan be used to consistently estimate (i) the presence and absence of causal\nrelations, (ii) the presence and absence of direct causal relations, (iii) the\nabsence of confounders, and (iv) the absence of specific cycles in the causal\ngraph of the SCM. We extend these results to constraint-based causal discovery\nalgorithms that exploit certain forms of background knowledge, including the\ncausally sufficient setting (e.g., the PC algorithm) and the Joint Causal\nInference setting (e.g., the FCI-JCI algorithm).\n", "versions": [{"version": "v1", "created": "Fri, 1 May 2020 21:10:31 GMT"}, {"version": "v2", "created": "Fri, 19 Jun 2020 21:28:26 GMT"}], "update_date": "2020-10-08", "authors_parsed": [["Mooij", "Joris M.", ""], ["Claassen", "Tom", ""]]}, {"id": "2005.00631", "submitter": "Umang Bhatt", "authors": "Umang Bhatt, Adrian Weller, and Jos\\'e M. F. Moura", "title": "Evaluating and Aggregating Feature-based Model Explanations", "comments": "Accepted at IJCAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A feature-based model explanation denotes how much each input feature\ncontributes to a model's output for a given data point. As the number of\nproposed explanation functions grows, we lack quantitative evaluation criteria\nto help practitioners know when to use which explanation function. This paper\nproposes quantitative evaluation criteria for feature-based explanations: low\nsensitivity, high faithfulness, and low complexity. We devise a framework for\naggregating explanation functions. We develop a procedure for learning an\naggregate explanation function with lower complexity and then derive a new\naggregate Shapley value explanation function that minimizes sensitivity.\n", "versions": [{"version": "v1", "created": "Fri, 1 May 2020 21:56:36 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Bhatt", "Umang", ""], ["Weller", "Adrian", ""], ["Moura", "Jos\u00e9 M. F.", ""]]}, {"id": "2005.00653", "submitter": "Wasi Ahmad", "authors": "Wasi Uddin Ahmad and Saikat Chakraborty and Baishakhi Ray and Kai-Wei\n  Chang", "title": "A Transformer-based Approach for Source Code Summarization", "comments": "This paper is accepted at ACL2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generating a readable summary that describes the functionality of a program\nis known as source code summarization. In this task, learning code\nrepresentation by modeling the pairwise relationship between code tokens to\ncapture their long-range dependencies is crucial. To learn code representation\nfor summarization, we explore the Transformer model that uses a self-attention\nmechanism and has shown to be effective in capturing long-range dependencies.\nIn this work, we show that despite the approach is simple, it outperforms the\nstate-of-the-art techniques by a significant margin. We perform extensive\nanalysis and ablation studies that reveal several important findings, e.g., the\nabsolute encoding of source code tokens' position hinders, while relative\nencoding significantly improves the summarization performance. We have made our\ncode publicly available to facilitate future research.\n", "versions": [{"version": "v1", "created": "Fri, 1 May 2020 23:29:36 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Ahmad", "Wasi Uddin", ""], ["Chakraborty", "Saikat", ""], ["Ray", "Baishakhi", ""], ["Chang", "Kai-Wei", ""]]}, {"id": "2005.00660", "submitter": "Peter Clark", "authors": "Sumithra Bhakthavatsalam, Chloe Anastasiades, Peter Clark", "title": "GenericsKB: A Knowledge Base of Generic Statements", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new resource for the NLP community, namely a large (3.5M+\nsentence) knowledge base of *generic statements*, e.g., \"Trees remove carbon\ndioxide from the atmosphere\", collected from multiple corpora. This is the\nfirst large resource to contain *naturally occurring* generic sentences, as\nopposed to extracted or crowdsourced triples, and thus is rich in high-quality,\ngeneral, semantically complete statements. All GenericsKB sentences are\nannotated with their topical term, surrounding context (sentences), and a\n(learned) confidence. We also release GenericsKB-Best (1M+ sentences),\ncontaining the best-quality generics in GenericsKB augmented with selected,\nsynthesized generics from WordNet and ConceptNet. In tests on two existing\ndatasets requiring multihop reasoning (OBQA and QASC), we find using GenericsKB\ncan result in higher scores and better explanations than using a much larger\ncorpus. This demonstrates that GenericsKB can be a useful resource for NLP\napplications, as well as providing data for linguistic studies of generics and\ntheir semantics. GenericsKB is available at\nhttps://allenai.org/data/genericskb.\n", "versions": [{"version": "v1", "created": "Sat, 2 May 2020 00:08:42 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Bhakthavatsalam", "Sumithra", ""], ["Anastasiades", "Chloe", ""], ["Clark", "Peter", ""]]}, {"id": "2005.00669", "submitter": "Tassilo Klein", "authors": "Tassilo Klein and Moin Nabi", "title": "Contrastive Self-Supervised Learning for Commonsense Reasoning", "comments": "To appear at ACL2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a self-supervised method to solve Pronoun Disambiguation and\nWinograd Schema Challenge problems. Our approach exploits the characteristic\nstructure of training corpora related to so-called \"trigger\" words, which are\nresponsible for flipping the answer in pronoun disambiguation. We achieve such\ncommonsense reasoning by constructing pair-wise contrastive auxiliary\npredictions. To this end, we leverage a mutual exclusive loss regularized by a\ncontrastive margin. Our architecture is based on the recently introduced\ntransformer networks, BERT, that exhibits strong performance on many NLP\nbenchmarks. Empirical results show that our method alleviates the limitation of\ncurrent supervised approaches for commonsense reasoning. This study opens up\navenues for exploiting inexpensive self-supervision to achieve performance gain\nin commonsense reasoning tasks.\n", "versions": [{"version": "v1", "created": "Sat, 2 May 2020 00:39:09 GMT"}], "update_date": "2020-05-06", "authors_parsed": [["Klein", "Tassilo", ""], ["Nabi", "Moin", ""]]}, {"id": "2005.00683", "submitter": "Bill Yuchen Lin", "authors": "Bill Yuchen Lin, Seyeon Lee, Rahul Khanna, Xiang Ren", "title": "Birds have four legs?! NumerSense: Probing Numerical Commonsense\n  Knowledge of Pre-trained Language Models", "comments": "To appear in Proceedings of EMNLP 2020. Project page:\n  http://inklab.usc.edu/NumerSense/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent works show that pre-trained language models (PTLMs), such as BERT,\npossess certain commonsense and factual knowledge. They suggest that it is\npromising to use PTLMs as \"neural knowledge bases\" via predicting masked words.\nSurprisingly, we find that this may not work for numerical commonsense\nknowledge (e.g., a bird usually has two legs). In this paper, we investigate\nwhether and to what extent we can induce numerical commonsense knowledge from\nPTLMs as well as the robustness of this process. To study this, we introduce a\nnovel probing task with a diagnostic dataset, NumerSense, containing 13.6k\nmasked-word-prediction probes (10.5k for fine-tuning and 3.1k for testing). Our\nanalysis reveals that: (1) BERT and its stronger variant RoBERTa perform poorly\non the diagnostic dataset prior to any fine-tuning; (2) fine-tuning with\ndistant supervision brings some improvement; (3) the best supervised model\nstill performs poorly as compared to human performance (54.06% vs 96.3% in\naccuracy).\n", "versions": [{"version": "v1", "created": "Sat, 2 May 2020 02:47:02 GMT"}, {"version": "v2", "created": "Fri, 18 Sep 2020 00:42:25 GMT"}], "update_date": "2020-09-21", "authors_parsed": [["Lin", "Bill Yuchen", ""], ["Lee", "Seyeon", ""], ["Khanna", "Rahul", ""], ["Ren", "Xiang", ""]]}, {"id": "2005.00689", "submitter": "Ziyu Yao", "authors": "Ziyu Yao, Yiqi Tang, Wen-tau Yih, Huan Sun, Yu Su", "title": "An Imitation Game for Learning Semantic Parsers from User Interaction", "comments": "Accepted to EMNLP 2020. 21 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the widely successful applications, bootstrapping and fine-tuning\nsemantic parsers are still a tedious process with challenges such as costly\ndata annotation and privacy risks. In this paper, we suggest an alternative,\nhuman-in-the-loop methodology for learning semantic parsers directly from\nusers. A semantic parser should be introspective of its uncertainties and\nprompt for user demonstration when uncertain. In doing so it also gets to\nimitate the user behavior and continue improving itself autonomously with the\nhope that eventually it may become as good as the user in interpreting their\nquestions. To combat the sparsity of demonstration, we propose a novel\nannotation-efficient imitation learning algorithm, which iteratively collects\nnew datasets by mixing demonstrated states and confident predictions and\nre-trains the semantic parser in a Dataset Aggregation fashion (Ross et al.,\n2011). We provide a theoretical analysis of its cost bound and also empirically\ndemonstrate its promising performance on the text-to-SQL problem. Code will be\navailable at https://github.com/sunlab-osu/MISP.\n", "versions": [{"version": "v1", "created": "Sat, 2 May 2020 03:30:49 GMT"}, {"version": "v2", "created": "Tue, 6 Oct 2020 03:46:18 GMT"}, {"version": "v3", "created": "Thu, 15 Oct 2020 18:31:26 GMT"}], "update_date": "2020-10-19", "authors_parsed": [["Yao", "Ziyu", ""], ["Tang", "Yiqi", ""], ["Yih", "Wen-tau", ""], ["Sun", "Huan", ""], ["Su", "Yu", ""]]}, {"id": "2005.00691", "submitter": "Peifeng Wang", "authors": "Peifeng Wang, Nanyun Peng, Filip Ilievski, Pedro Szekely, Xiang Ren", "title": "Connecting the Dots: A Knowledgeable Path Generator for Commonsense\n  Question Answering", "comments": "12 pages, 4 figures. Accepted to EMNLP'20 Findings", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Commonsense question answering (QA) requires background knowledge which is\nnot explicitly stated in a given context. Prior works use commonsense knowledge\ngraphs (KGs) to obtain this knowledge for reasoning. However, relying entirely\non these KGs may not suffice, considering their limited coverage and the\ncontextual dependence of their knowledge. In this paper, we augment a general\ncommonsense QA framework with a knowledgeable path generator. By extrapolating\nover existing paths in a KG with a state-of-the-art language model, our\ngenerator learns to connect a pair of entities in text with a dynamic, and\npotentially novel, multi-hop relational path. Such paths can provide structured\nevidence for solving commonsense questions without fine-tuning the path\ngenerator. Experiments on two datasets show the superiority of our method over\nprevious works which fully rely on knowledge from KGs (with up to 6%\nimprovement in accuracy), across various amounts of training data. Further\nevaluation suggests that the generated paths are typically interpretable,\nnovel, and relevant to the task.\n", "versions": [{"version": "v1", "created": "Sat, 2 May 2020 03:53:21 GMT"}, {"version": "v2", "created": "Sat, 19 Sep 2020 16:38:45 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Wang", "Peifeng", ""], ["Peng", "Nanyun", ""], ["Ilievski", "Filip", ""], ["Szekely", "Pedro", ""], ["Ren", "Xiang", ""]]}, {"id": "2005.00693", "submitter": "Gerard de Melo", "authors": "Abu Shoeb, Gerard de Melo", "title": "Are Emojis Emotional? A Study to Understand the Association between\n  Emojis and Emotions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given the growing ubiquity of emojis in language, there is a need for methods\nand resources that shed light on their meaning and communicative role. One\nconspicuous aspect of emojis is their use to convey affect in ways that may\notherwise be non-trivial to achieve. In this paper, we seek to explore the\nconnection between emojis and emotions by means of a new dataset consisting of\nhuman-solicited association ratings. We additionally conduct experiments to\nassess to what extent such associations can be inferred from existing data,\nsuch that similar associations can be predicted for a larger set of emojis. Our\nexperiments show that this succeeds when high-quality word-level information is\navailable.\n", "versions": [{"version": "v1", "created": "Sat, 2 May 2020 04:04:42 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Shoeb", "Abu", ""], ["de Melo", "Gerard", ""]]}, {"id": "2005.00695", "submitter": "Hongyang Zhang", "authors": "Sen Wu, Hongyang R. Zhang, Gregory Valiant, Christopher R\\'e", "title": "On the Generalization Effects of Linear Transformations in Data\n  Augmentation", "comments": "International Conference on Machine learning (ICML) 2020. Added\n  experimental results on ImageNet", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data augmentation is a powerful technique to improve performance in\napplications such as image and text classification tasks. Yet, there is little\nrigorous understanding of why and how various augmentations work. In this work,\nwe consider a family of linear transformations and study their effects on the\nridge estimator in an over-parametrized linear regression setting. First, we\nshow that transformations which preserve the labels of the data can improve\nestimation by enlarging the span of the training data. Second, we show that\ntransformations which mix data can improve estimation by playing a\nregularization effect. Finally, we validate our theoretical insights on MNIST.\nBased on the insights, we propose an augmentation scheme that searches over the\nspace of transformations by how uncertain the model is about the transformed\ndata. We validate our proposed scheme on image and text datasets. For example,\nour method outperforms RandAugment by 1.24% on CIFAR-100 using\nWide-ResNet-28-10. Furthermore, we achieve comparable accuracy to the SoTA\nAdversarial AutoAugment on CIFAR datasets.\n", "versions": [{"version": "v1", "created": "Sat, 2 May 2020 04:10:21 GMT"}, {"version": "v2", "created": "Tue, 7 Jul 2020 06:00:23 GMT"}], "update_date": "2020-07-09", "authors_parsed": [["Wu", "Sen", ""], ["Zhang", "Hongyang R.", ""], ["Valiant", "Gregory", ""], ["R\u00e9", "Christopher", ""]]}, {"id": "2005.00697", "submitter": "Qingqing Cao", "authors": "Qingqing Cao, Harsh Trivedi, Aruna Balasubramanian, Niranjan\n  Balasubramanian", "title": "DeFormer: Decomposing Pre-trained Transformers for Faster Question\n  Answering", "comments": "ACL 2020 camera ready", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transformer-based QA models use input-wide self-attention -- i.e. across both\nthe question and the input passage -- at all layers, causing them to be slow\nand memory-intensive. It turns out that we can get by without input-wide\nself-attention at all layers, especially in the lower layers. We introduce\nDeFormer, a decomposed transformer, which substitutes the full self-attention\nwith question-wide and passage-wide self-attentions in the lower layers. This\nallows for question-independent processing of the input text representations,\nwhich in turn enables pre-computing passage representations reducing runtime\ncompute drastically. Furthermore, because DeFormer is largely similar to the\noriginal model, we can initialize DeFormer with the pre-training weights of a\nstandard transformer, and directly fine-tune on the target QA dataset. We show\nDeFormer versions of BERT and XLNet can be used to speed up QA by over 4.3x and\nwith simple distillation-based losses they incur only a 1% drop in accuracy. We\nopen source the code at https://github.com/StonyBrookNLP/deformer.\n", "versions": [{"version": "v1", "created": "Sat, 2 May 2020 04:28:22 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Cao", "Qingqing", ""], ["Trivedi", "Harsh", ""], ["Balasubramanian", "Aruna", ""], ["Balasubramanian", "Niranjan", ""]]}, {"id": "2005.00700", "submitter": "Daniel Khashabi Mr.", "authors": "Daniel Khashabi, Sewon Min, Tushar Khot, Ashish Sabharwal, Oyvind\n  Tafjord, Peter Clark, Hannaneh Hajishirzi", "title": "UnifiedQA: Crossing Format Boundaries With a Single QA System", "comments": "EMNLP 2020 (Findings)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Question answering (QA) tasks have been posed using a variety of formats,\nsuch as extractive span selection, multiple choice, etc. This has led to\nformat-specialized models, and even to an implicit division in the QA\ncommunity. We argue that such boundaries are artificial and perhaps\nunnecessary, given the reasoning abilities we seek to teach are not governed by\nthe format. As evidence, we use the latest advances in language modeling to\nbuild a single pre-trained QA model, UnifiedQA, that performs surprisingly well\nacross 17 QA datasets spanning 4 diverse formats. UnifiedQA performs on par\nwith 9 different models that were trained on individual datasets themselves.\nEven when faced with 12 unseen datasets of observed formats, UnifiedQA performs\nsurprisingly well, showing strong generalization from its out-of-format\ntraining data. Finally, simply fine-tuning this pre-trained QA model into\nspecialized models results in a new state of the art on 6 datasets,\nestablishing UnifiedQA as a strong starting point for building QA systems.\n", "versions": [{"version": "v1", "created": "Sat, 2 May 2020 04:42:14 GMT"}, {"version": "v2", "created": "Tue, 6 Oct 2020 07:46:48 GMT"}, {"version": "v3", "created": "Wed, 7 Oct 2020 03:12:45 GMT"}], "update_date": "2020-10-08", "authors_parsed": [["Khashabi", "Daniel", ""], ["Min", "Sewon", ""], ["Khot", "Tushar", ""], ["Sabharwal", "Ashish", ""], ["Tafjord", "Oyvind", ""], ["Clark", "Peter", ""], ["Hajishirzi", "Hannaneh", ""]]}, {"id": "2005.00705", "submitter": "Thuy Vu", "authors": "Thuy Vu and Alessandro Moschitti", "title": "AVA: an Automatic eValuation Approach to Question Answering Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce AVA, an automatic evaluation approach for Question Answering,\nwhich given a set of questions associated with Gold Standard answers, can\nestimate system Accuracy. AVA uses Transformer-based language models to encode\nquestion, answer, and reference text. This allows for effectively measuring the\nsimilarity between the reference and an automatic answer, biased towards the\nquestion semantics. To design, train and test AVA, we built multiple large\ntraining, development, and test sets on both public and industrial benchmarks.\nOur innovative solutions achieve up to 74.7% in F1 score in predicting human\njudgement for single answers. Additionally, AVA can be used to evaluate the\noverall system Accuracy with an RMSE, ranging from 0.02 to 0.09, depending on\nthe availability of multiple references.\n", "versions": [{"version": "v1", "created": "Sat, 2 May 2020 05:00:16 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Vu", "Thuy", ""], ["Moschitti", "Alessandro", ""]]}, {"id": "2005.00724", "submitter": "Sanjay Subramanian", "authors": "Sanjay Subramanian, Ben Bogin, Nitish Gupta, Tomer Wolfson, Sameer\n  Singh, Jonathan Berant, Matt Gardner", "title": "Obtaining Faithful Interpretations from Compositional Neural Networks", "comments": "ACL 2020; first three authors contributed equally", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural module networks (NMNs) are a popular approach for modeling\ncompositionality: they achieve high accuracy when applied to problems in\nlanguage and vision, while reflecting the compositional structure of the\nproblem in the network architecture. However, prior work implicitly assumed\nthat the structure of the network modules, describing the abstract reasoning\nprocess, provides a faithful explanation of the model's reasoning; that is,\nthat all modules perform their intended behaviour. In this work, we propose and\nconduct a systematic evaluation of the intermediate outputs of NMNs on NLVR2\nand DROP, two datasets which require composing multiple reasoning steps. We\nfind that the intermediate outputs differ from the expected output,\nillustrating that the network structure does not provide a faithful explanation\nof model behaviour. To remedy that, we train the model with auxiliary\nsupervision and propose particular choices for module architecture that yield\nmuch better faithfulness, at a minimal cost to accuracy.\n", "versions": [{"version": "v1", "created": "Sat, 2 May 2020 06:50:35 GMT"}, {"version": "v2", "created": "Tue, 8 Sep 2020 15:52:28 GMT"}], "update_date": "2020-09-09", "authors_parsed": [["Subramanian", "Sanjay", ""], ["Bogin", "Ben", ""], ["Gupta", "Nitish", ""], ["Wolfson", "Tomer", ""], ["Singh", "Sameer", ""], ["Berant", "Jonathan", ""], ["Gardner", "Matt", ""]]}, {"id": "2005.00728", "submitter": "Jesse Thomason", "authors": "Homero Roman Roman, Yonatan Bisk, Jesse Thomason, Asli Celikyilmaz,\n  Jianfeng Gao", "title": "RMM: A Recursive Mental Model for Dialog Navigation", "comments": "Findings of Empirical Methods in Natural Language Processing (EMNLP\n  Findings), 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.CV cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Language-guided robots must be able to both ask humans questions and\nunderstand answers. Much existing work focuses only on the latter. In this\npaper, we go beyond instruction following and introduce a two-agent task where\none agent navigates and asks questions that a second, guiding agent answers.\nInspired by theory of mind, we propose the Recursive Mental Model (RMM). The\nnavigating agent models the guiding agent to simulate answers given candidate\ngenerated questions. The guiding agent in turn models the navigating agent to\nsimulate navigation steps it would take to generate answers. We use the\nprogress agents make towards the goal as a reinforcement learning reward signal\nto directly inform not only navigation actions, but also both question and\nanswer generation. We demonstrate that RMM enables better generalization to\nnovel environments. Interlocutor modelling may be a way forward for human-agent\ndialogue where robots need to both ask and answer questions.\n", "versions": [{"version": "v1", "created": "Sat, 2 May 2020 06:57:14 GMT"}, {"version": "v2", "created": "Tue, 6 Oct 2020 02:16:27 GMT"}], "update_date": "2020-10-07", "authors_parsed": [["Roman", "Homero Roman", ""], ["Bisk", "Yonatan", ""], ["Thomason", "Jesse", ""], ["Celikyilmaz", "Asli", ""], ["Gao", "Jianfeng", ""]]}, {"id": "2005.00769", "submitter": "Shray Bansal", "authors": "Shray Bansal, Rhys Newbury, Wesley Chan, Akansel Cosgun, Aimee Allen,\n  Dana Kuli\\'c, Tom Drummond and Charles Isbell", "title": "Supportive Actions for Manipulation in Human-Robot Coworker Teams", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The increasing presence of robots alongside humans, such as in human-robot\nteams in manufacturing, gives rise to research questions about the kind of\nbehaviors people prefer in their robot counterparts. We term actions that\nsupport interaction by reducing future interference with others as supportive\nrobot actions and investigate their utility in a co-located manipulation\nscenario. We compare two robot modes in a shared table pick-and-place task: (1)\nTask-oriented: the robot only takes actions to further its own task objective\nand (2) Supportive: the robot sometimes prefers supportive actions to\ntask-oriented ones when they reduce future goal-conflicts. Our experiments in\nsimulation, using a simplified human model, reveal that supportive actions\nreduce the interference between agents, especially in more difficult tasks, but\nalso cause the robot to take longer to complete the task. We implemented these\nmodes on a physical robot in a user study where a human and a robot perform\nobject placement on a shared table. Our results show that a supportive robot\nwas perceived as a more favorable coworker by the human and also reduced\ninterference with the human in the more difficult of two scenarios. However, it\nalso took longer to complete the task highlighting an interesting trade-off\nbetween task-efficiency and human-preference that needs to be considered before\ndesigning robot behavior for close-proximity manipulation scenarios.\n", "versions": [{"version": "v1", "created": "Sat, 2 May 2020 09:37:10 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Bansal", "Shray", ""], ["Newbury", "Rhys", ""], ["Chan", "Wesley", ""], ["Cosgun", "Akansel", ""], ["Allen", "Aimee", ""], ["Kuli\u0107", "Dana", ""], ["Drummond", "Tom", ""], ["Isbell", "Charles", ""]]}, {"id": "2005.00782", "submitter": "Pei Zhou", "authors": "Pei Zhou, Rahul Khanna, Seyeon Lee, Bill Yuchen Lin, Daniel Ho, Jay\n  Pujara, Xiang Ren", "title": "RICA: Evaluating Robust Inference Capabilities Based on Commonsense\n  Axioms", "comments": "18 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pre-trained language models (PTLMs) have achieved impressive performance on\ncommonsense inference benchmarks, but their ability to employ commonsense to\nmake robust inferences, which is crucial for effective communications with\nhumans, is debated. In the pursuit of advancing fluid human-AI communication,\nwe propose a new challenge, RICA: Robust Inference capability based on\nCommonsense Axioms, that evaluates robust commonsense inference despite textual\nperturbations. To generate data for this challenge, we develop a systematic and\nscalable procedure using commonsense knowledge bases and probe PTLMs across two\ndifferent evaluation settings. Extensive experiments on our generated probe\nsets with more than 10k statements show that PTLMs perform no better than\nrandom guessing on the zero-shot setting, are heavily impacted by statistical\nbiases, and are not robust to perturbation attacks. We also find that\nfine-tuning on similar statements offer limited gains, as PTLMs still fail to\ngeneralize to unseen inferences. Our new large-scale benchmark exposes a\nsignificant gap between PTLMs and human-level language understanding and offers\na new challenge for PTLMs to demonstrate commonsense.\n", "versions": [{"version": "v1", "created": "Sat, 2 May 2020 10:36:55 GMT"}, {"version": "v2", "created": "Wed, 23 Sep 2020 04:11:53 GMT"}, {"version": "v3", "created": "Tue, 13 Apr 2021 23:40:23 GMT"}], "update_date": "2021-04-15", "authors_parsed": [["Zhou", "Pei", ""], ["Khanna", "Rahul", ""], ["Lee", "Seyeon", ""], ["Lin", "Bill Yuchen", ""], ["Ho", "Daniel", ""], ["Pujara", "Jay", ""], ["Ren", "Xiang", ""]]}, {"id": "2005.00789", "submitter": "Harsh Trivedi", "authors": "Harsh Trivedi, Niranjan Balasubramanian, Tushar Khot, Ashish Sabharwal", "title": "Is Multihop QA in DiRe Condition? Measuring and Reducing Disconnected\n  Reasoning", "comments": "Accepted at EMNLP'20", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Has there been real progress in multi-hop question-answering? Models often\nexploit dataset artifacts to produce correct answers, without connecting\ninformation across multiple supporting facts. This limits our ability to\nmeasure true progress and defeats the purpose of building multi-hop QA\ndatasets. We make three contributions towards addressing this. First, we\nformalize such undesirable behavior as disconnected reasoning across subsets of\nsupporting facts. This allows developing a model-agnostic probe for measuring\nhow much any model can cheat via disconnected reasoning. Second, using a notion\nof \\emph{contrastive support sufficiency}, we introduce an automatic\ntransformation of existing datasets that reduces the amount of disconnected\nreasoning. Third, our experiments suggest that there hasn't been much progress\nin multi-hop QA in the reading comprehension setting. For a recent large-scale\nmodel (XLNet), we show that only 18 points out of its answer F1 score of 72 on\nHotpotQA are obtained through multifact reasoning, roughly the same as that of\na simpler RNN baseline. Our transformation substantially reduces disconnected\nreasoning (19 points in answer F1). It is complementary to adversarial\napproaches, yielding further reductions in conjunction.\n", "versions": [{"version": "v1", "created": "Sat, 2 May 2020 11:01:07 GMT"}, {"version": "v2", "created": "Wed, 16 Sep 2020 17:54:00 GMT"}, {"version": "v3", "created": "Tue, 17 Nov 2020 04:18:51 GMT"}], "update_date": "2020-11-18", "authors_parsed": [["Trivedi", "Harsh", ""], ["Balasubramanian", "Niranjan", ""], ["Khot", "Tushar", ""], ["Sabharwal", "Ashish", ""]]}, {"id": "2005.00804", "submitter": "Prachi Jain", "authors": "Prachi Jain, Sushant Rathi, Mausam, Soumen Chakrabarti", "title": "Knowledge Base Completion: Baseline strikes back (Again)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge Base Completion (KBC) has been a very active area lately. Several\nrecent KBCpapers propose architectural changes, new training methods, or even\nnew formulations. KBC systems are usually evaluated on standard benchmark\ndatasets: FB15k, FB15k-237, WN18, WN18RR, and Yago3-10. Most existing methods\ntrain with a small number of negative samples for each positive instance in\nthese datasets to save computational costs. This paper discusses how recent\ndevelopments allow us to use all available negative samples for training. We\nshow that Complex, when trained using all available negative samples, gives\nnear state-of-the-art performance on all the datasets. We call this approach\nCOMPLEX-V2. We also highlight how various multiplicative KBC methods, recently\nproposed in the literature, benefit from this train-ing regime and become\nindistinguishable in terms of performance on most datasets. Our work calls for\na reassessment of their individual value, in light of these findings.\n", "versions": [{"version": "v1", "created": "Sat, 2 May 2020 11:53:22 GMT"}, {"version": "v2", "created": "Tue, 20 Oct 2020 11:33:11 GMT"}], "update_date": "2020-10-21", "authors_parsed": [["Jain", "Prachi", ""], ["Rathi", "Sushant", ""], ["Mausam", "", ""], ["Chakrabarti", "Soumen", ""]]}, {"id": "2005.00811", "submitter": "Keerthiram Murugesan", "authors": "Keerthiram Murugesan, Mattia Atzeni, Pushkar Shukla, Mrinmaya Sachan,\n  Pavan Kapanipathi, Kartik Talamadupula", "title": "Enhancing Text-based Reinforcement Learning Agents with Commonsense\n  Knowledge", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider the recent trend of evaluating progress on\nreinforcement learning technology by using text-based environments and games as\nevaluation environments. This reliance on text brings advances in natural\nlanguage processing into the ambit of these agents, with a recurring thread\nbeing the use of external knowledge to mimic and better human-level\nperformance. We present one such instantiation of agents that use commonsense\nknowledge from ConceptNet to show promising performance on two text-based\nenvironments.\n", "versions": [{"version": "v1", "created": "Sat, 2 May 2020 12:07:02 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Murugesan", "Keerthiram", ""], ["Atzeni", "Mattia", ""], ["Shukla", "Pushkar", ""], ["Sachan", "Mrinmaya", ""], ["Kapanipathi", "Pavan", ""], ["Talamadupula", "Kartik", ""]]}, {"id": "2005.00813", "submitter": "Vinodkumar Prabhakaran", "authors": "Ben Hutchinson, Vinodkumar Prabhakaran, Emily Denton, Kellie Webster,\n  Yu Zhong, Stephen Denuyl", "title": "Social Biases in NLP Models as Barriers for Persons with Disabilities", "comments": "ACL 2020 short paper. 5 pages", "journal-ref": "ACL 2020", "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Building equitable and inclusive NLP technologies demands consideration of\nwhether and how social attitudes are represented in ML models. In particular,\nrepresentations encoded in models often inadvertently perpetuate undesirable\nsocial biases from the data on which they are trained. In this paper, we\npresent evidence of such undesirable biases towards mentions of disability in\ntwo different English language models: toxicity prediction and sentiment\nanalysis. Next, we demonstrate that the neural embeddings that are the critical\nfirst step in most NLP pipelines similarly contain undesirable biases towards\nmentions of disability. We end by highlighting topical biases in the discourse\nabout disability which may contribute to the observed model biases; for\ninstance, gun violence, homelessness, and drug addiction are over-represented\nin texts discussing mental illness.\n", "versions": [{"version": "v1", "created": "Sat, 2 May 2020 12:16:54 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Hutchinson", "Ben", ""], ["Prabhakaran", "Vinodkumar", ""], ["Denton", "Emily", ""], ["Webster", "Kellie", ""], ["Zhong", "Yu", ""], ["Denuyl", "Stephen", ""]]}, {"id": "2005.00840", "submitter": "Hendrik Burwinkel", "authors": "Hendrik Burwinkel, Matthias Keicher, David Bani-Harouni, Tobias\n  Zellner, Florian Eyer, Nassir Navab, Seyed-Ahmad Ahmadi", "title": "Decision Support for Intoxication Prediction Using Graph Convolutional\n  Networks", "comments": "10 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Every day, poison control centers (PCC) are called for immediate\nclassification and treatment recommendations if an acute intoxication is\nsuspected. Due to the time-sensitive nature of these cases, doctors are\nrequired to propose a correct diagnosis and intervention within a minimal time\nframe. Usually the toxin is known and recommendations can be made accordingly.\nHowever, in challenging cases only symptoms are mentioned and doctors have to\nrely on their clinical experience. Medical experts and our analyses of a\nregional dataset of intoxication records provide evidence that this is\nchallenging, since occurring symptoms may not always match the textbook\ndescription due to regional distinctions, inter-rater variance, and\ninstitutional workflow. Computer-aided diagnosis (CADx) can provide decision\nsupport, but approaches so far do not consider additional information of the\nreported cases like age or gender, despite their potential value towards a\ncorrect diagnosis. In this work, we propose a new machine learning based CADx\nmethod which fuses symptoms and meta information of the patients using graph\nconvolutional networks. We further propose a novel symptom matching method that\nallows the effective incorporation of prior knowledge into the learning process\nand evidently stabilizes the poison prediction. We validate our method against\n10 medical doctors with different experience diagnosing intoxication cases for\n10 different toxins from the PCC in Munich and show our method's superiority in\nperformance for poison prediction.\n", "versions": [{"version": "v1", "created": "Sat, 2 May 2020 14:20:32 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Burwinkel", "Hendrik", ""], ["Keicher", "Matthias", ""], ["Bani-Harouni", "David", ""], ["Zellner", "Tobias", ""], ["Eyer", "Florian", ""], ["Navab", "Nassir", ""], ["Ahmadi", "Seyed-Ahmad", ""]]}, {"id": "2005.00856", "submitter": "Wentao Xu", "authors": "Wentao Xu, Shun Zheng, Liang He, Bin Shao, Jian Yin, Tie-Yan Liu", "title": "SEEK: Segmented Embedding of Knowledge Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, knowledge graph embedding becomes a pretty hot research\ntopic of artificial intelligence and plays increasingly vital roles in various\ndownstream applications, such as recommendation and question answering.\nHowever, existing methods for knowledge graph embedding can not make a proper\ntrade-off between the model complexity and the model expressiveness, which\nmakes them still far from satisfactory. To mitigate this problem, we propose a\nlightweight modeling framework that can achieve highly competitive relational\nexpressiveness without increasing the model complexity. Our framework focuses\non the design of scoring functions and highlights two critical characteristics:\n1) facilitating sufficient feature interactions; 2) preserving both symmetry\nand antisymmetry properties of relations. It is noteworthy that owing to the\ngeneral and elegant design of scoring functions, our framework can incorporate\nmany famous existing methods as special cases. Moreover, extensive experiments\non public benchmarks demonstrate the efficiency and effectiveness of our\nframework. Source codes and data can be found at\n\\url{https://github.com/Wentao-Xu/SEEK}.\n", "versions": [{"version": "v1", "created": "Sat, 2 May 2020 15:15:50 GMT"}, {"version": "v2", "created": "Wed, 17 Jun 2020 10:51:55 GMT"}, {"version": "v3", "created": "Tue, 23 Jun 2020 03:27:31 GMT"}], "update_date": "2020-06-24", "authors_parsed": [["Xu", "Wentao", ""], ["Zheng", "Shun", ""], ["He", "Liang", ""], ["Shao", "Bin", ""], ["Yin", "Jian", ""], ["Liu", "Tie-Yan", ""]]}, {"id": "2005.00863", "submitter": "Pranab K. Muhuri Dr.", "authors": "Zubair Ashraf, Pranab K. Muhuri, Q. M. Danish Lohani, and Mukul L. Roy", "title": "Type-2 fuzzy reliability redundancy allocation problem and its solution\n  using particle swarm optimization algorithm", "comments": null, "journal-ref": "Granular Computing, 4(2), 145-166 (2019)", "doi": "10.1007/s41066-018-0106-5", "report-no": null, "categories": "cs.NE cs.AI math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, the fuzzy multi-objective reliability redundancy allocation\nproblem (FMORRAP) is proposed, which maximizes the system reliability while\nsimultaneously minimizing the system cost under the type 2 fuzzy uncertainty.\nIn the proposed formulation, the higher order uncertainties (such as\nparametric, manufacturing, environmental, and designers uncertainty) associated\nwith the system are modeled with interval type 2 fuzzy sets (IT2 FS). The\nfootprint of uncertainty of the interval type 2 membership functions (IT2 MFs)\naccommodates these uncertainties by capturing the multiple opinions from\nseveral system experts. We consider IT2 MFs to represent the subsystem\nreliability and cost, which are to be further aggregated using extension\nprinciple to evaluate the total system reliability and cost according to their\nconfigurations, i.e., series parallel and parallel series. We proposed a\nparticle swarm optimization (PSO) based novel solution approach to solve the\nFMORRAP. To demonstrate the applicability of two formulations, namely, series\nparallel FMORRAP and parallel series FMORRAP, we performed experimental\nsimulations on various numerical data sets. The decision makers/system experts\nassign different importance to the objectives (system reliability and cost),\nand these preferences are represented by sets of weights. The optimal results\nare obtained from our solution approach, and the Pareto optimal front is\nestablished using these different weight sets. The genetic algorithm (GA) was\nimplemented to compare the results obtained from our proposed solution\napproach. A statistical analysis was conducted between PSO and GA, and it was\nfound that the PSO based Pareto solution outperforms the GA.\n", "versions": [{"version": "v1", "created": "Sat, 2 May 2020 15:39:54 GMT"}], "update_date": "2020-06-28", "authors_parsed": [["Ashraf", "Zubair", ""], ["Muhuri", "Pranab K.", ""], ["Lohani", "Q. M. Danish", ""], ["Roy", "Mukul L.", ""]]}, {"id": "2005.00868", "submitter": "Pranab K. Muhuri Dr.", "authors": "Prashant K Gupta, and Pranab K. Muhuri", "title": "Computing With Words for Student Strategy Evaluation in an Examination", "comments": null, "journal-ref": "Granular Computing 4, no. 2 (2019): 167-184", "doi": "10.1007/s41066-018-0109-2", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the framework of Granular Computing (GC), Interval type 2 Fuzzy Sets (IT2\nFSs) play a prominent role by facilitating a better representation of uncertain\nlinguistic information. Perceptual Computing (Per C), a well known computing\nwith words (CWW) approach, and its various applications have nicely exploited\nthis advantage. This paper reports a novel Per C based approach for student\nstrategy evaluation. Examinations are generally oriented to test the subject\nknowledge of students. The number of questions that they are able to solve\naccurately judges success rates of students in the examinations. However, we\nfeel that not only the solutions of questions, but also the strategy adopted\nfor finding those solutions are equally important. More marks should be awarded\nto a student, who solves a question with a better strategy compared to a\nstudent, whose strategy is relatively not that good. Furthermore, the students\nstrategy can be taken as a measure of his or her learning outcome as perceived\nby a faculty member. This can help to identify students, whose learning\noutcomes are not good, and, thus, can be provided with any relevant help, for\nimprovement. The main contribution of this paper is to illustrate the use of\nCWW for student strategy evaluation and present a comparison of the\nrecommendations generated by different CWW approaches. CWW provides us with two\nmajor advantages. First, it generates a numeric score for the overall\nevaluation of strategy adopted by a student in the examination. This enables\ncomparison and ranking of the students based on their performances. Second, a\nlinguistic evaluation describing the student strategy is also obtained from the\nsystem. Both these numeric score and linguistic recommendation are together\nused to assess the quality of a students strategy. We found that Per-C\ngenerates unique recommendations in all cases and outperforms other CWW\napproaches.\n", "versions": [{"version": "v1", "created": "Sat, 2 May 2020 15:57:54 GMT"}], "update_date": "2020-06-28", "authors_parsed": [["Gupta", "Prashant K", ""], ["Muhuri", "Pranab K.", ""]]}, {"id": "2005.00887", "submitter": "Leopoldo Lusquino Filho", "authors": "Aluizio S. Lima Filho and Gabriel P. Guarisa and Leopoldo A. D.\n  Lusquino Filho and Luiz F. R. Oliveira and Felipe M. G. Franca and Priscila\n  M. V. Lima", "title": "wisardpkg -- A library for WiSARD-based models", "comments": "9 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  In order to facilitate the production of codes using WiSARD-based models,\nLabZero developed an ML library C++/Python called wisardpkg. This library is an\nMIT-licensed open-source package hosted on GitHub under the license.\n", "versions": [{"version": "v1", "created": "Sat, 2 May 2020 17:03:40 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Filho", "Aluizio S. Lima", ""], ["Guarisa", "Gabriel P.", ""], ["Filho", "Leopoldo A. D. Lusquino", ""], ["Oliveira", "Luiz F. R.", ""], ["Franca", "Felipe M. G.", ""], ["Lima", "Priscila M. V.", ""]]}, {"id": "2005.00904", "submitter": "Mark Law", "authors": "Mark Law, Alessandra Russo, Krysia Broda", "title": "The ILASP system for Inductive Learning of Answer Set Programs", "comments": "Submitted to the ALP newsletter", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The goal of Inductive Logic Programming (ILP) is to learn a program that\nexplains a set of examples in the context of some pre-existing background\nknowledge. Until recently, most research on ILP targeted learning Prolog\nprograms. Our own ILASP system instead learns Answer Set Programs, including\nnormal rules, choice rules and hard and weak constraints. Learning such\nexpressive programs widens the applicability of ILP considerably; for example,\nenabling preference learning, learning common-sense knowledge, including\ndefaults and exceptions, and learning non-deterministic theories. In this\npaper, we first give a general overview of ILASP's learning framework and its\ncapabilities. This is followed by a comprehensive summary of the evolution of\nthe ILASP system, presenting the strengths and weaknesses of each version, with\na particular emphasis on scalability.\n", "versions": [{"version": "v1", "created": "Sat, 2 May 2020 19:04:12 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Law", "Mark", ""], ["Russo", "Alessandra", ""], ["Broda", "Krysia", ""]]}, {"id": "2005.00928", "submitter": "Samira Abnar", "authors": "Samira Abnar and Willem Zuidema", "title": "Quantifying Attention Flow in Transformers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the Transformer model, \"self-attention\" combines information from attended\nembeddings into the representation of the focal embedding in the next layer.\nThus, across layers of the Transformer, information originating from different\ntokens gets increasingly mixed. This makes attention weights unreliable as\nexplanations probes. In this paper, we consider the problem of quantifying this\nflow of information through self-attention. We propose two methods for\napproximating the attention to input tokens given attention weights, attention\nrollout and attention flow, as post hoc methods when we use attention weights\nas the relative relevance of the input tokens. We show that these methods give\ncomplementary views on the flow of information, and compared to raw attention,\nboth yield higher correlations with importance scores of input tokens obtained\nusing an ablation method and input gradients.\n", "versions": [{"version": "v1", "created": "Sat, 2 May 2020 21:45:27 GMT"}, {"version": "v2", "created": "Sun, 31 May 2020 16:59:40 GMT"}], "update_date": "2020-06-02", "authors_parsed": [["Abnar", "Samira", ""], ["Zuidema", "Willem", ""]]}, {"id": "2005.00961", "submitter": "Hiroyuki Kido", "authors": "Hiroyuki Kido", "title": "Bayesian Entailment Hypothesis: How Brains Implement Monotonic and\n  Non-monotonic Reasoning", "comments": "This paper was submitted to IJCAI 2020 and rejected", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent success of Bayesian methods in neuroscience and artificial\nintelligence gives rise to the hypothesis that the brain is a Bayesian machine.\nSince logic, as the laws of thought, is a product and practice of the human\nbrain, it leads to another hypothesis that there is a Bayesian algorithm and\ndata-structure for logical reasoning. In this paper, we give a Bayesian account\nof entailment and characterize its abstract inferential properties. The\nBayesian entailment is shown to be a monotonic consequence relation in an\nextreme case. In general, it is a sort of non-monotonic consequence relation\nwithout Cautious monotony or Cut. The preferential entailment, which is a\nrepresentative non-monotonic consequence relation, is shown to be maximum a\nposteriori entailment, which is an approximation of the Bayesian entailment. We\nfinally discuss merits of our proposals in terms of encoding preferences on\ndefaults, handling change and contradiction, and modeling human entailment.\n", "versions": [{"version": "v1", "created": "Sun, 3 May 2020 01:26:02 GMT"}, {"version": "v2", "created": "Wed, 6 May 2020 09:04:54 GMT"}, {"version": "v3", "created": "Wed, 27 Jan 2021 18:00:03 GMT"}], "update_date": "2021-01-28", "authors_parsed": [["Kido", "Hiroyuki", ""]]}, {"id": "2005.00986", "submitter": "Mengyun Shi", "authors": "Mengyun Shi, Van Dyk Lewis", "title": "Using Artificial Intelligence to Analyze Fashion Trends", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Analyzing fashion trends is essential in the fashion industry. Current\nfashion forecasting firms, such as WGSN, utilize the visual information from\naround the world to analyze and predict fashion trends. However, analyzing\nfashion trends is time-consuming and extremely labor intensive, requiring\nindividual employees' manual editing and classification. To improve the\nefficiency of data analysis of such image-based information and lower the cost\nof analyzing fashion images, this study proposes a data-driven quantitative\nabstracting approach using an artificial intelligence (A.I.) algorithm.\nSpecifically, an A.I. model was trained on fashion images from a large-scale\ndataset under different scenarios, for example in online stores and street\nsnapshots. This model was used to detect garments and classify clothing\nattributes such as textures, garment style, and details for runway photos and\nvideos. It was found that the A.I. model can generate rich attribute\ndescriptions of detected regions and accurately bind the garments in the\nimages. Adoption of A.I. algorithm demonstrated promising results and the\npotential to classify garment types and details automatically, which can make\nthe process of trend forecasting more cost-effective and faster.\n", "versions": [{"version": "v1", "created": "Sun, 3 May 2020 04:46:12 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Shi", "Mengyun", ""], ["Lewis", "Van Dyk", ""]]}, {"id": "2005.01075", "submitter": "Wouter Verbeke", "authors": "Sam Verboven, Jeroen Berrevoets, Chris Wuytens, Bart Baesens, Wouter\n  Verbeke", "title": "Autoencoders for strategic decision support", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the majority of executive domains, a notion of normality is involved in\nmost strategic decisions. However, few data-driven tools that support strategic\ndecision-making are available. We introduce and extend the use of autoencoders\nto provide strategically relevant granular feedback. A first experiment\nindicates that experts are inconsistent in their decision making, highlighting\nthe need for strategic decision support. Furthermore, using two large\nindustry-provided human resources datasets, the proposed solution is evaluated\nin terms of ranking accuracy, synergy with human experts, and dimension-level\nfeedback. This three-point scheme is validated using (a) synthetic data, (b)\nthe perspective of data quality, (c) blind expert validation, and (d)\ntransparent expert evaluation. Our study confirms several principal weaknesses\nof human decision-making and stresses the importance of synergy between a model\nand humans. Moreover, unsupervised learning and in particular the autoencoder\nare shown to be valuable tools for strategic decision-making.\n", "versions": [{"version": "v1", "created": "Sun, 3 May 2020 12:54:06 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Verboven", "Sam", ""], ["Berrevoets", "Jeroen", ""], ["Wuytens", "Chris", ""], ["Baesens", "Bart", ""], ["Verbeke", "Wouter", ""]]}, {"id": "2005.01081", "submitter": "Fabio Angelo Maccheroni", "authors": "Carlo Baldassi, Simone Cerreia-Vioglio, Fabio Maccheroni, Massimo\n  Marinacci, Marco Pirazzini", "title": "Multialternative Neural Decision Processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI econ.TH q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce an algorithmic decision process for multialternative choice that\ncombines binary comparisons and Markovian exploration. We show that a\npreferential property, transitivity, makes it testable.\n", "versions": [{"version": "v1", "created": "Sun, 3 May 2020 13:19:37 GMT"}, {"version": "v2", "created": "Sat, 16 May 2020 11:26:26 GMT"}, {"version": "v3", "created": "Mon, 19 Apr 2021 08:56:58 GMT"}, {"version": "v4", "created": "Wed, 19 May 2021 15:37:48 GMT"}, {"version": "v5", "created": "Thu, 20 May 2021 10:55:52 GMT"}], "update_date": "2021-05-21", "authors_parsed": [["Baldassi", "Carlo", ""], ["Cerreia-Vioglio", "Simone", ""], ["Maccheroni", "Fabio", ""], ["Marinacci", "Massimo", ""], ["Pirazzini", "Marco", ""]]}, {"id": "2005.01117", "submitter": "Kshitija Taywade", "authors": "Kshitija Taywade, Judy Goldsmith, Brent Harrison", "title": "Multi-agent Reinforcement Learning for Decentralized Stable Matching", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the real world, people/entities usually find matches independently and\nautonomously, such as finding jobs, partners, roommates, etc. It is possible\nthat this search for matches starts with no initial knowledge of the\nenvironment. We propose the use of a multi-agent reinforcement learning (MARL)\nparadigm for a spatially formulated decentralized two-sided matching market\nwith independent and autonomous agents. Having autonomous agents acting\nindependently makes our environment very dynamic and uncertain. Moreover,\nagents lack the knowledge of preferences of other agents and have to explore\nthe environment and interact with other agents to discover their own\npreferences through noisy rewards. We think such a setting better approximates\nthe real world and we study the usefulness of our MARL approach for it. Along\nwith conventional stable matching case where agents have strictly ordered\npreferences, we check the applicability of our approach for stable matching\nwith incomplete lists and ties. We investigate our results for stability, level\nof instability (for unstable results), and fairness. Our MARL approach mostly\nyields stable and fair outcomes.\n", "versions": [{"version": "v1", "created": "Sun, 3 May 2020 15:28:41 GMT"}, {"version": "v2", "created": "Fri, 1 Jan 2021 00:21:07 GMT"}], "update_date": "2021-01-05", "authors_parsed": [["Taywade", "Kshitija", ""], ["Goldsmith", "Judy", ""], ["Harrison", "Brent", ""]]}, {"id": "2005.01138", "submitter": "Samin Yeasar Arnob", "authors": "Samin Yeasar Arnob", "title": "Off-Policy Adversarial Inverse Reinforcement Learning", "comments": "15 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial Imitation Learning (AIL) is a class of algorithms in\nReinforcement learning (RL), which tries to imitate an expert without taking\nany reward from the environment and does not provide expert behavior directly\nto the policy training. Rather, an agent learns a policy distribution that\nminimizes the difference from expert behavior in an adversarial setting.\nAdversarial Inverse Reinforcement Learning (AIRL) leverages the idea of AIL,\nintegrates a reward function approximation along with learning the policy, and\nshows the utility of IRL in the transfer learning setting. But the reward\nfunction approximator that enables transfer learning does not perform well in\nimitation tasks. We propose an Off-Policy Adversarial Inverse Reinforcement\nLearning (Off-policy-AIRL) algorithm which is sample efficient as well as gives\ngood imitation performance compared to the state-of-the-art AIL algorithm in\nthe continuous control tasks. For the same reward function approximator, we\nshow the utility of learning our algorithm over AIL by using the learned reward\nfunction to retrain the policy over a task under significant variation where\nexpert demonstrations are absent.\n", "versions": [{"version": "v1", "created": "Sun, 3 May 2020 16:51:40 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Arnob", "Samin Yeasar", ""]]}, {"id": "2005.01157", "submitter": "Matan Orbach", "authors": "Matan Orbach, Yonatan Bilu, Assaf Toledo, Dan Lahav, Michal Jacovi,\n  Ranit Aharonov and Noam Slonim", "title": "Out of the Echo Chamber: Detecting Countering Debate Speeches", "comments": "Accepted to ACL 2020 as Long Paper. For the associated debate\n  speeches corpus, see\n  https://www.research.ibm.com/haifa/dept/vst/debating_data.shtml#Debate%20Speech%20Analysis", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An educated and informed consumption of media content has become a challenge\nin modern times. With the shift from traditional news outlets to social media\nand similar venues, a major concern is that readers are becoming encapsulated\nin \"echo chambers\" and may fall prey to fake news and disinformation, lacking\neasy access to dissenting views. We suggest a novel task aiming to alleviate\nsome of these concerns -- that of detecting articles that most effectively\ncounter the arguments -- and not just the stance -- made in a given text. We\nstudy this problem in the context of debate speeches. Given such a speech, we\naim to identify, from among a set of speeches on the same topic and with an\nopposing stance, the ones that directly counter it. We provide a large dataset\nof 3,685 such speeches (in English), annotated for this relation, which\nhopefully would be of general interest to the NLP community. We explore several\nalgorithms addressing this task, and while some are successful, all fall short\nof expert human performance, suggesting room for further research. All data\ncollected during this work is freely available for research.\n", "versions": [{"version": "v1", "created": "Sun, 3 May 2020 18:02:10 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Orbach", "Matan", ""], ["Bilu", "Yonatan", ""], ["Toledo", "Assaf", ""], ["Lahav", "Dan", ""], ["Jacovi", "Michal", ""], ["Aharonov", "Ranit", ""], ["Slonim", "Noam", ""]]}, {"id": "2005.01192", "submitter": "Patrik Christen", "authors": "Patrik Christen", "title": "Model Creation and Equivalence Proofs of Cellular Automata and\n  Artificial Neural Networks", "comments": "13 pages, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI math.DS", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Computational methods and mathematical models have invaded arguably every\nscientific discipline forming its own field of research called computational\nscience. Mathematical models are the theoretical foundation of computational\nscience. Since Newton's time, differential equations in mathematical models\nhave been widely and successfully used to describe the macroscopic or global\nbehaviour of systems. With spatially inhomogeneous, time-varying, local\nelement-specific, and often non-linear interactions, the dynamics of complex\nsystems is in contrast more efficiently described by local rules and thus in an\nalgorithmic and local or microscopic manner. The theory of mathematical\nmodelling taking into account these characteristics of complex systems has to\nbe established still. We recently presented a so-called allagmatic method\nincluding a system metamodel to provide a framework for describing, modelling,\nsimulating, and interpreting complex systems. Implementations of cellular\nautomata and artificial neural networks were described and created with that\nmethod. Guidance from philosophy were helpful in these first studies focusing\non programming and feasibility. A rigorous mathematical formalism, however, is\nstill missing. This would not only more precisely describe and define the\nsystem metamodel, it would also further generalise it and with that extend its\nreach to formal treatment in applied mathematics and theoretical aspects of\ncomputational science as well as extend its applicability to other mathematical\nand computational models such as agent-based models. Here, a mathematical\ndefinition of the system metamodel is provided. Based on the presented\nformalism, model creation and equivalence of cellular automata and artificial\nneural networks are proved. It thus provides a formal approach for studying the\ncreation of mathematical models as well as their structural and operational\ncomparison.\n", "versions": [{"version": "v1", "created": "Sun, 3 May 2020 21:20:30 GMT"}, {"version": "v2", "created": "Mon, 31 Aug 2020 21:38:00 GMT"}, {"version": "v3", "created": "Wed, 28 Oct 2020 22:20:02 GMT"}], "update_date": "2020-10-30", "authors_parsed": [["Christen", "Patrik", ""]]}, {"id": "2005.01246", "submitter": "Raviteja Anantha", "authors": "Raviteja Anantha, Stephen Pulman, and Srinivas Chappidi", "title": "Generalized Reinforcement Meta Learning for Few-Shot Optimization", "comments": "10 pages, 4 figures, 4 tables, 2 algorithms, ICML conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a generic and flexible Reinforcement Learning (RL) based\nmeta-learning framework for the problem of few-shot learning. During training,\nit learns the best optimization algorithm to produce a learner\n(ranker/classifier, etc) by exploiting stable patterns in loss surfaces. Our\nmethod implicitly estimates the gradients of a scaled loss function while\nretaining the general properties intact for parameter updates. Besides\nproviding improved performance on few-shot tasks, our framework could be easily\nextended to do network architecture search. We further propose a novel dual\nencoder, affinity-score based decoder topology that achieves additional\nimprovements to performance. Experiments on an internal dataset, MQ2007, and\nAwA2 show our approach outperforms existing alternative approaches by 21%, 8%,\nand 4% respectively on accuracy and NDCG metrics. On Mini-ImageNet dataset our\napproach achieves comparable results with Prototypical Networks. Empirical\nevaluations demonstrate that our approach provides a unified and effective\nframework.\n", "versions": [{"version": "v1", "created": "Mon, 4 May 2020 03:21:05 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Anantha", "Raviteja", ""], ["Pulman", "Stephen", ""], ["Chappidi", "Srinivas", ""]]}, {"id": "2005.01278", "submitter": "Zhiqiang Zhan", "authors": "Zhiqiang Zhan, Zifeng Hou, Yang Zhang", "title": "A New Data Normalization Method to Improve Dialogue Generation by\n  Minimizing Long Tail Effect", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent neural models have shown significant progress in dialogue generation.\nMost generation models are based on language models. However, due to the Long\nTail Phenomenon in linguistics, the trained models tend to generate words that\nappear frequently in training datasets, leading to a monotonous issue. To\naddress this issue, we analyze a large corpus from Wikipedia and propose three\nfrequency-based data normalization methods. We conduct extensive experiments\nbased on transformers and three datasets respectively collected from social\nmedia, subtitles, and the industrial application. Experimental results\ndemonstrate significant improvements in diversity and informativeness (defined\nas the numbers of nouns and verbs) of generated responses. More specifically,\nthe unigram and bigram diversity are increased by 2.6%-12.6% and 2.2%-18.9% on\nthe three datasets, respectively. Moreover, the informativeness, i.e. the\nnumbers of nouns and verbs, are increased by 4.0%-7.0% and 1.4%-12.1%,\nrespectively. Additionally, the simplicity and effectiveness enable our methods\nto be adapted to different generation models without much extra computational\ncost.\n", "versions": [{"version": "v1", "created": "Mon, 4 May 2020 05:20:19 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Zhan", "Zhiqiang", ""], ["Hou", "Zifeng", ""], ["Zhang", "Yang", ""]]}, {"id": "2005.01291", "submitter": "Pedram Daee", "authors": "Fabio Colella, Pedram Daee, Jussi Jokinen, Antti Oulasvirta, Samuel\n  Kaski", "title": "Human Strategic Steering Improves Performance of Interactive\n  Optimization", "comments": "10 pages, 5 figures, The paper is published in the proceedings of\n  UMAP 2020. Codes available at\n  https://github.com/fcole90/interactive_bayesian_optimisation", "journal-ref": null, "doi": "10.1145/3340631.3394883", "report-no": null, "categories": "cs.HC cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A central concern in an interactive intelligent system is optimization of its\nactions, to be maximally helpful to its human user. In recommender systems for\ninstance, the action is to choose what to recommend, and the optimization task\nis to recommend items the user prefers. The optimization is done based on\nearlier user's feedback (e.g. \"likes\" and \"dislikes\"), and the algorithms\nassume the feedback to be faithful. That is, when the user clicks \"like,\" they\nactually prefer the item. We argue that this fundamental assumption can be\nextensively violated by human users, who are not passive feedback sources.\nInstead, they are in control, actively steering the system towards their goal.\nTo verify this hypothesis, that humans steer and are able to improve\nperformance by steering, we designed a function optimization task where a human\nand an optimization algorithm collaborate to find the maximum of a\n1-dimensional function. At each iteration, the optimization algorithm queries\nthe user for the value of a hidden function $f$ at a point $x$, and the user,\nwho sees the hidden function, provides an answer about $f(x)$. Our study on 21\nparticipants shows that users who understand how the optimization works,\nstrategically provide biased answers (answers not equal to $f(x)$), which\nresults in the algorithm finding the optimum significantly faster. Our work\nhighlights that next-generation intelligent systems will need user models\ncapable of helping users who steer systems to pursue their goals.\n", "versions": [{"version": "v1", "created": "Mon, 4 May 2020 06:56:52 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Colella", "Fabio", ""], ["Daee", "Pedram", ""], ["Jokinen", "Jussi", ""], ["Oulasvirta", "Antti", ""], ["Kaski", "Samuel", ""]]}, {"id": "2005.01399", "submitter": "Adriano Lucieri", "authors": "Adriano Lucieri, Muhammad Naseer Bajwa, Andreas Dengel and Sheraz\n  Ahmed", "title": "Explaining AI-based Decision Support Systems using Concept Localization\n  Maps", "comments": "Submitted to ICANN2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Human-centric explainability of AI-based Decision Support Systems (DSS) using\nvisual input modalities is directly related to reliability and practicality of\nsuch algorithms. An otherwise accurate and robust DSS might not enjoy trust of\nexperts in critical application areas if it is not able to provide reasonable\njustification of its predictions. This paper introduces Concept Localization\nMaps (CLMs), which is a novel approach towards explainable image classifiers\nemployed as DSS. CLMs extend Concept Activation Vectors (CAVs) by locating\nsignificant regions corresponding to a learned concept in the latent space of a\ntrained image classifier. They provide qualitative and quantitative assurance\nof a classifier's ability to learn and focus on similar concepts important for\nhumans during image recognition. To better understand the effectiveness of the\nproposed method, we generated a new synthetic dataset called Simple Concept\nDataBase (SCDB) that includes annotations for 10 distinguishable concepts, and\nmade it publicly available. We evaluated our proposed method on SCDB as well as\na real-world dataset called CelebA. We achieved localization recall of above\n80% for most relevant concepts and average recall above 60% for all concepts\nusing SE-ResNeXt-50 on SCDB. Our results on both datasets show great promise of\nCLMs for easing acceptance of DSS in practice.\n", "versions": [{"version": "v1", "created": "Mon, 4 May 2020 11:33:00 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Lucieri", "Adriano", ""], ["Bajwa", "Muhammad Naseer", ""], ["Dengel", "Andreas", ""], ["Ahmed", "Sheraz", ""]]}, {"id": "2005.01427", "submitter": "Kacper Sokol", "authors": "Kacper Sokol and Peter Flach", "title": "LIMEtree: Interactively Customisable Explanations Based on Local\n  Surrogate Multi-output Regression Trees", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Systems based on artificial intelligence and machine learning models should\nbe transparent, in the sense of being capable of explaining their decisions to\ngain humans' approval and trust. While there are a number of explainability\ntechniques that can be used to this end, many of them are only capable of\noutputting a single one-size-fits-all explanation that simply cannot address\nall of the explainees' diverse needs. In this work we introduce a\nmodel-agnostic and post-hoc local explainability technique for black-box\npredictions called LIMEtree, which employs surrogate multi-output regression\ntrees. We validate our algorithm on a deep neural network trained for object\ndetection in images and compare it against Local Interpretable Model-agnostic\nExplanations (LIME). Our method comes with local fidelity guarantees and can\nproduce a range of diverse explanation types, including contrastive and\ncounterfactual explanations praised in the literature. Some of these\nexplanations can be interactively personalised to create bespoke, meaningful\nand actionable insights into the model's behaviour. While other methods may\ngive an illusion of customisability by wrapping, otherwise static, explanations\nin an interactive interface, our explanations are truly interactive, in the\nsense of allowing the user to \"interrogate\" a black-box model. LIMEtree can\ntherefore produce consistent explanations on which an interactive exploratory\nprocess can be built.\n", "versions": [{"version": "v1", "created": "Mon, 4 May 2020 12:31:29 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Sokol", "Kacper", ""], ["Flach", "Peter", ""]]}, {"id": "2005.01525", "submitter": "Jesse Dunietz", "authors": "Jesse Dunietz, Gregory Burnham, Akash Bharadwaj, Owen Rambow, Jennifer\n  Chu-Carroll, David Ferrucci", "title": "To Test Machine Comprehension, Start by Defining Comprehension", "comments": "Camera-ready ACL 2020 paper (Theme track). 9 pages; 3 figures; 1\n  table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Many tasks aim to measure machine reading comprehension (MRC), often focusing\non question types presumed to be difficult. Rarely, however, do task designers\nstart by considering what systems should in fact comprehend. In this paper we\nmake two key contributions. First, we argue that existing approaches do not\nadequately define comprehension; they are too unsystematic about what content\nis tested. Second, we present a detailed definition of comprehension -- a\n\"Template of Understanding\" -- for a widely useful class of texts, namely short\nnarratives. We then conduct an experiment that strongly suggests existing\nsystems are not up to the task of narrative understanding as we define it.\n", "versions": [{"version": "v1", "created": "Mon, 4 May 2020 14:36:07 GMT"}, {"version": "v2", "created": "Mon, 11 May 2020 14:57:54 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["Dunietz", "Jesse", ""], ["Burnham", "Gregory", ""], ["Bharadwaj", "Akash", ""], ["Rambow", "Owen", ""], ["Chu-Carroll", "Jennifer", ""], ["Ferrucci", "David", ""]]}, {"id": "2005.01539", "submitter": "Spyridon Samothrakis", "authors": "Spyridon Samothrakis", "title": "Open Loop In Natura Economic Planning", "comments": "10 pages, 3 Figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The debate between the optimal way of allocating societal surplus (i.e.\nproducts and services) has been raging, in one form or another, practically\nforever; following the collapse of the Soviet Union in 1991, the market became\nthe only legitimate form of organisation -- there was no other alternative.\nWorking within the tradition of Marx, Leontief, Kantorovich, Beer and\nCockshott, we propose what we deem an automated planning system that aims to\noperate on unit level (e.g., factories and citizens), rather than on aggregate\ndemand and sectors. We explain why it is both a viable and desirable\nalternative to current market conditions and position our solution within\ncurrent societal structures. Our experiments show that it would be trivial to\nplan for up to 50K industrial goods and 5K final goods in commodity hardware.\n", "versions": [{"version": "v1", "created": "Mon, 4 May 2020 14:50:01 GMT"}, {"version": "v2", "created": "Thu, 14 May 2020 14:28:48 GMT"}], "update_date": "2020-05-15", "authors_parsed": [["Samothrakis", "Spyridon", ""]]}, {"id": "2005.01556", "submitter": "Lei Shen", "authors": "Lei Shen, Xiaoyu Guo, Meng Chen", "title": "Compose Like Humans: Jointly Improving the Coherence and Novelty for\n  Modern Chinese Poetry Generation", "comments": "To appear at IJCNN 2020 (long paper)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Chinese poetry is an important part of worldwide culture, and classical and\nmodern sub-branches are quite different. The former is a unique genre and has\nstrict constraints, while the latter is very flexible in length, optional to\nhave rhymes, and similar to modern poetry in other languages. Thus, it requires\nmore to control the coherence and improve the novelty. In this paper, we\npropose a generate-retrieve-then-refine paradigm to jointly improve the\ncoherence and novelty. In the first stage, a draft is generated given keywords\n(i.e., topics) only. The second stage produces a \"refining vector\" from\nretrieval lines. At last, we take into consideration both the draft and the\n\"refining vector\" to generate a new poem. The draft provides future\nsentence-level information for a line to be generated. Meanwhile, the \"refining\nvector\" points out the direction of refinement based on impressive words\ndetection mechanism which can learn good patterns from references and then\ncreate new ones via insertion operation. Experimental results on a collected\nlarge-scale modern Chinese poetry dataset show that our proposed approach can\nnot only generate more coherent poems, but also improve the diversity and\nnovelty.\n", "versions": [{"version": "v1", "created": "Mon, 4 May 2020 15:16:10 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Shen", "Lei", ""], ["Guo", "Xiaoyu", ""], ["Chen", "Meng", ""]]}, {"id": "2005.01574", "submitter": "Hao Zheng", "authors": "Yuting Cao, Parijat Mukherjee, Mahesh Ketkar, Jin Yang, Hao Zheng", "title": "Mining Message Flows using Recurrent Neural Networks for System-on-Chip\n  Designs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Comprehensive specifications are essential for various activities across the\nentire validation continuum for system-on-chip (SoC) designs. However,\nspecifications are often ambiguous, incomplete, or even contain inconsistencies\nor errors. This paper addresses this problem by developing a specification\nmining approach that automatically extracts sequential patterns from SoC\ntransaction-level traces such that the mined patterns collectively characterize\nsystem-level specifications for SoC designs. This approach exploits long\nshort-term memory (LSTM) networks trained with the collected SoC execution\ntraces to capture sequential dependencies among various communication events.\nThen, a novel algorithm is developed to efficiently extract sequential patterns\non system-level communications from the trained LSTM models. Several trace\nprocessing techniques are also proposed to enhance the mining performance. We\nevaluate the proposed approach on simulation traces of a non-trivial multi-core\nSoC prototype. Initial results show that the proposed approach is capable of\nextracting various patterns on system-level specifications from the highly\nconcurrent SoC execution traces.\n", "versions": [{"version": "v1", "created": "Wed, 29 Apr 2020 17:52:53 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Cao", "Yuting", ""], ["Mukherjee", "Parijat", ""], ["Ketkar", "Mahesh", ""], ["Yang", "Jin", ""], ["Zheng", "Hao", ""]]}, {"id": "2005.01627", "submitter": "Dimitri Bertsekas", "authors": "Dimitri Bertsekas", "title": "Multiagent Value Iteration Algorithms in Dynamic Programming and\n  Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.AI cs.LG cs.MA cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider infinite horizon dynamic programming problems, where the control\nat each stage consists of several distinct decisions, each one made by one of\nseveral agents. In an earlier work we introduced a policy iteration algorithm,\nwhere the policy improvement is done one-agent-at-a-time in a given order, with\nknowledge of the choices of the preceding agents in the order. As a result, the\namount of computation for each policy improvement grows linearly with the\nnumber of agents, as opposed to exponentially for the standard\nall-agents-at-once method. For the case of a finite-state discounted problem,\nwe showed convergence to an agent-by-agent optimal policy. In this paper, this\nresult is extended to value iteration and optimistic versions of policy\niteration, as well as to more general DP problems where the Bellman operator is\na contraction mapping, such as stochastic shortest path problems with all\npolicies being proper.\n", "versions": [{"version": "v1", "created": "Mon, 4 May 2020 16:34:24 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Bertsekas", "Dimitri", ""]]}, {"id": "2005.01633", "submitter": "Veronique Ventos", "authors": "V\\'eronique Ventos, Daniel Braun, Colin Deheeger, Jean Pierre\n  Desmoulins, Jean Baptiste Fantun, Swann Legras, Alexis Rimbaud, C\\'eline\n  Rouveirol and Henry Soldano", "title": "Construction and Elicitation of a Black Box Model in the Game of Bridge", "comments": "vventos@nukk.ai", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the problem of building a decision model for a specific bidding\nsituation in the game of Bridge. We propose the following multi-step\nmethodology i) Build a set of examples for the decision problem and use\nsimulations to associate a decision to each example ii) Use supervised\nrelational learning to build an accurate and readable model iii) Perform a\njoint analysis between domain experts and data scientists to improve the\nlearning language, including the production by experts of a handmade model iv)\nBuild a better, more readable and accurate model.\n", "versions": [{"version": "v1", "created": "Mon, 4 May 2020 16:44:45 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Ventos", "V\u00e9ronique", ""], ["Braun", "Daniel", ""], ["Deheeger", "Colin", ""], ["Desmoulins", "Jean Pierre", ""], ["Fantun", "Jean Baptiste", ""], ["Legras", "Swann", ""], ["Rimbaud", "Alexis", ""], ["Rouveirol", "C\u00e9line", ""], ["Soldano", "Henry", ""]]}, {"id": "2005.01642", "submitter": "Shayegan Omidshafiei", "authors": "Shayegan Omidshafiei, Karl Tuyls, Wojciech M. Czarnecki, Francisco C.\n  Santos, Mark Rowland, Jerome Connor, Daniel Hennes, Paul Muller, Julien\n  Perolat, Bart De Vylder, Audrunas Gruslys, Remi Munos", "title": "Navigating the Landscape of Multiplayer Games", "comments": null, "journal-ref": null, "doi": "10.1038/s41467-020-19244-4", "report-no": null, "categories": "cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multiplayer games have long been used as testbeds in artificial intelligence\nresearch, aptly referred to as the Drosophila of artificial intelligence.\nTraditionally, researchers have focused on using well-known games to build\nstrong agents. This progress, however, can be better informed by characterizing\ngames and their topological landscape. Tackling this latter question can\nfacilitate understanding of agents and help determine what game an agent should\ntarget next as part of its training. Here, we show how network measures applied\nto response graphs of large-scale games enable the creation of a landscape of\ngames, quantifying relationships between games of varying sizes and\ncharacteristics. We illustrate our findings in domains ranging from canonical\ngames to complex empirical games capturing the performance of trained agents\npitted against one another. Our results culminate in a demonstration leveraging\nthis information to generate new and interesting games, including mixtures of\nempirical games synthesized from real world games.\n", "versions": [{"version": "v1", "created": "Mon, 4 May 2020 16:58:17 GMT"}, {"version": "v2", "created": "Mon, 24 Aug 2020 15:47:57 GMT"}, {"version": "v3", "created": "Tue, 17 Nov 2020 17:22:03 GMT"}], "update_date": "2020-12-02", "authors_parsed": [["Omidshafiei", "Shayegan", ""], ["Tuyls", "Karl", ""], ["Czarnecki", "Wojciech M.", ""], ["Santos", "Francisco C.", ""], ["Rowland", "Mark", ""], ["Connor", "Jerome", ""], ["Hennes", "Daniel", ""], ["Muller", "Paul", ""], ["Perolat", "Julien", ""], ["De Vylder", "Bart", ""], ["Gruslys", "Audrunas", ""], ["Munos", "Remi", ""]]}, {"id": "2005.01643", "submitter": "Sergey Levine", "authors": "Sergey Levine, Aviral Kumar, George Tucker, Justin Fu", "title": "Offline Reinforcement Learning: Tutorial, Review, and Perspectives on\n  Open Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this tutorial article, we aim to provide the reader with the conceptual\ntools needed to get started on research on offline reinforcement learning\nalgorithms: reinforcement learning algorithms that utilize previously collected\ndata, without additional online data collection. Offline reinforcement learning\nalgorithms hold tremendous promise for making it possible to turn large\ndatasets into powerful decision making engines. Effective offline reinforcement\nlearning methods would be able to extract policies with the maximum possible\nutility out of the available data, thereby allowing automation of a wide range\nof decision-making domains, from healthcare and education to robotics. However,\nthe limitations of current algorithms make this difficult. We will aim to\nprovide the reader with an understanding of these challenges, particularly in\nthe context of modern deep reinforcement learning methods, and describe some\npotential solutions that have been explored in recent work to mitigate these\nchallenges, along with recent applications, and a discussion of perspectives on\nopen problems in the field.\n", "versions": [{"version": "v1", "created": "Mon, 4 May 2020 17:00:15 GMT"}, {"version": "v2", "created": "Tue, 20 Oct 2020 17:37:01 GMT"}, {"version": "v3", "created": "Sun, 1 Nov 2020 23:50:25 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Levine", "Sergey", ""], ["Kumar", "Aviral", ""], ["Tucker", "George", ""], ["Fu", "Justin", ""]]}, {"id": "2005.01654", "submitter": "Jonathan Spring", "authors": "Rawan Al-Shaer and Jonathan M. Spring and Eliana Christou", "title": "Learning the Associations of MITRE ATT&CK Adversarial Techniques", "comments": "13 pages, 15 figures. Pre-print / expanded version of paper accepted\n  for publication at IEEE CNS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The MITRE ATT&CK Framework provides a rich and actionable repository of\nadversarial tactics, techniques, and procedures (TTP). However, this\ninformation would be highly useful for attack diagnosis (i.e., forensics) and\nmitigation (i.e., intrusion response) if we can reliably construct technique\nassociations that will enable predicting unobserved attack techniques based on\nobserved ones. In this paper, we present our statistical machine learning\nanalysis on APT and Software attack data reported by MITRE ATT&CK to infer the\ntechnique clustering that represents the significant correlation that can be\nused for technique prediction. Due to the complex multidimensional\nrelationships between techniques, many of the traditional clustering methods\ncould not obtain usable associations. Our approach, using hierarchical\nclustering for inferring attack technique associations with 95% confidence,\nprovides statistically significant and explainable technique correlations. Our\nanalysis discovers 98 different technique associations (i.e., clusters) for\nboth APT and Software attacks. Our evaluation results show that 78% of the\ntechniques associated by our algorithm exhibit significant mutual information\nthat indicates reasonably high predictability.\n", "versions": [{"version": "v1", "created": "Thu, 16 Apr 2020 19:55:31 GMT"}, {"version": "v2", "created": "Tue, 12 May 2020 20:41:32 GMT"}], "update_date": "2020-05-14", "authors_parsed": [["Al-Shaer", "Rawan", ""], ["Spring", "Jonathan M.", ""], ["Christou", "Eliana", ""]]}, {"id": "2005.01777", "submitter": "Ngoc Thang Vu", "authors": "Chia-Yu Li, Daniel Ortega, Dirk V\\\"ath, Florian Lux, Lindsey\n  Vanderlyn, Maximilian Schmidt, Michael Neumann, Moritz V\\\"olkel, Pavel\n  Denisov, Sabrina Jenne, Zorica Kacarevic and Ngoc Thang Vu", "title": "ADVISER: A Toolkit for Developing Multi-modal, Multi-domain and\n  Socially-engaged Conversational Agents", "comments": "All authors contributed equally. Accepted to be presented at ACL -\n  System demonstrations - 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present ADVISER - an open-source, multi-domain dialog system toolkit that\nenables the development of multi-modal (incorporating speech, text and vision),\nsocially-engaged (e.g. emotion recognition, engagement level prediction and\nbackchanneling) conversational agents. The final Python-based implementation of\nour toolkit is flexible, easy to use, and easy to extend not only for\ntechnically experienced users, such as machine learning researchers, but also\nfor less technically experienced users, such as linguists or cognitive\nscientists, thereby providing a flexible platform for collaborative research.\nLink to open-source code: https://github.com/DigitalPhonetics/adviser\n", "versions": [{"version": "v1", "created": "Mon, 4 May 2020 18:27:58 GMT"}], "update_date": "2020-05-06", "authors_parsed": [["Li", "Chia-Yu", ""], ["Ortega", "Daniel", ""], ["V\u00e4th", "Dirk", ""], ["Lux", "Florian", ""], ["Vanderlyn", "Lindsey", ""], ["Schmidt", "Maximilian", ""], ["Neumann", "Michael", ""], ["V\u00f6lkel", "Moritz", ""], ["Denisov", "Pavel", ""], ["Jenne", "Sabrina", ""], ["Kacarevic", "Zorica", ""], ["Vu", "Ngoc Thang", ""]]}, {"id": "2005.01795", "submitter": "Kundan Krishna", "authors": "Kundan Krishna, Sopan Khosla, Jeffrey P. Bigham, Zachary C. Lipton", "title": "Generating SOAP Notes from Doctor-Patient Conversations Using Modular\n  Summarization Techniques", "comments": "Published at ACL 2021 Main Conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Following each patient visit, physicians draft long semi-structured clinical\nsummaries called SOAP notes. While invaluable to clinicians and researchers,\ncreating digital SOAP notes is burdensome, contributing to physician burnout.\nIn this paper, we introduce the first complete pipelines to leverage deep\nsummarization models to generate these notes based on transcripts of\nconversations between physicians and patients. After exploring a spectrum of\nmethods across the extractive-abstractive spectrum, we propose Cluster2Sent, an\nalgorithm that (i) extracts important utterances relevant to each summary\nsection; (ii) clusters together related utterances; and then (iii) generates\none summary sentence per cluster. Cluster2Sent outperforms its purely\nabstractive counterpart by 8 ROUGE-1 points, and produces significantly more\nfactual and coherent sentences as assessed by expert human evaluators. For\nreproducibility, we demonstrate similar benefits on the publicly available AMI\ndataset. Our results speak to the benefits of structuring summaries into\nsections and annotating supporting evidence when constructing summarization\ncorpora.\n", "versions": [{"version": "v1", "created": "Mon, 4 May 2020 19:10:26 GMT"}, {"version": "v2", "created": "Sat, 24 Oct 2020 04:09:10 GMT"}, {"version": "v3", "created": "Wed, 2 Jun 2021 14:48:09 GMT"}], "update_date": "2021-06-03", "authors_parsed": [["Krishna", "Kundan", ""], ["Khosla", "Sopan", ""], ["Bigham", "Jeffrey P.", ""], ["Lipton", "Zachary C.", ""]]}, {"id": "2005.01810", "submitter": "Josef Klafka", "authors": "Josef Klafka and Allyson Ettinger", "title": "Spying on your neighbors: Fine-grained probing of contextual embeddings\n  for information about surrounding words", "comments": "ACL 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although models using contextual word embeddings have achieved\nstate-of-the-art results on a host of NLP tasks, little is known about exactly\nwhat information these embeddings encode about the context words that they are\nunderstood to reflect. To address this question, we introduce a suite of\nprobing tasks that enable fine-grained testing of contextual embeddings for\nencoding of information about surrounding words. We apply these tasks to\nexamine the popular BERT, ELMo and GPT contextual encoders, and find that each\nof our tested information types is indeed encoded as contextual information\nacross tokens, often with near-perfect recoverability-but the encoders vary in\nwhich features they distribute to which tokens, how nuanced their distributions\nare, and how robust the encoding of each feature is to distance. We discuss\nimplications of these results for how different types of models breakdown and\nprioritize word-level context information when constructing token embeddings.\n", "versions": [{"version": "v1", "created": "Mon, 4 May 2020 19:34:46 GMT"}], "update_date": "2020-05-06", "authors_parsed": [["Klafka", "Josef", ""], ["Ettinger", "Allyson", ""]]}, {"id": "2005.01831", "submitter": "Peter Hase", "authors": "Peter Hase, Mohit Bansal", "title": "Evaluating Explainable AI: Which Algorithmic Explanations Help Users\n  Predict Model Behavior?", "comments": "ACL 2020 (13 pages)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Algorithmic approaches to interpreting machine learning models have\nproliferated in recent years. We carry out human subject tests that are the\nfirst of their kind to isolate the effect of algorithmic explanations on a key\naspect of model interpretability, simulatability, while avoiding important\nconfounding experimental factors. A model is simulatable when a person can\npredict its behavior on new inputs. Through two kinds of simulation tests\ninvolving text and tabular data, we evaluate five explanations methods: (1)\nLIME, (2) Anchor, (3) Decision Boundary, (4) a Prototype model, and (5) a\nComposite approach that combines explanations from each method. Clear evidence\nof method effectiveness is found in very few cases: LIME improves\nsimulatability in tabular classification, and our Prototype method is effective\nin counterfactual simulation tests. We also collect subjective ratings of\nexplanations, but we do not find that ratings are predictive of how helpful\nexplanations are. Our results provide the first reliable and comprehensive\nestimates of how explanations influence simulatability across a variety of\nexplanation methods and data domains. We show that (1) we need to be careful\nabout the metrics we use to evaluate explanation methods, and (2) there is\nsignificant room for improvement in current methods. All our supporting code,\ndata, and models are publicly available at:\nhttps://github.com/peterbhase/InterpretableNLP-ACL2020\n", "versions": [{"version": "v1", "created": "Mon, 4 May 2020 20:35:17 GMT"}], "update_date": "2020-05-06", "authors_parsed": [["Hase", "Peter", ""], ["Bansal", "Mohit", ""]]}, {"id": "2005.01908", "submitter": "Randy Goebel", "authors": "S. Atakishiyev, H. Babiker, N. Farruque, R. Goebel1, M-Y. Kima, M.H.\n  Motallebi, J. Rabelo, T. Syed, O. R. Za\\\"iane", "title": "A multi-component framework for the analysis and design of explainable\n  artificial intelligence", "comments": "39 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The rapid growth of research in explainable artificial intelligence (XAI)\nfollows on two substantial developments. First, the enormous application\nsuccess of modern machine learning methods, especially deep and reinforcement\nlearning, which have created high expectations for industrial, commercial and\nsocial value. Second, the emergence of concern for creating trusted AI systems,\nincluding the creation of regulatory principles to ensure transparency and\ntrust of AI systems.These two threads have created a kind of \"perfect storm\" of\nresearch activity, all eager to create and deliver it any set of tools and\ntechniques to address the XAI demand. As some surveys of current XAI suggest,\nthere is yet to appear a principled framework that respects the literature of\nexplainability in the history of science, and which provides a basis for the\ndevelopment of a framework for transparent XAI. Here we intend to provide a\nstrategic inventory of XAI requirements, demonstrate their connection to a\nhistory of XAI ideas, and synthesize those ideas into a simple framework to\ncalibrate five successive levels of XAI.\n", "versions": [{"version": "v1", "created": "Tue, 5 May 2020 01:48:40 GMT"}], "update_date": "2020-05-06", "authors_parsed": [["Atakishiyev", "S.", ""], ["Babiker", "H.", ""], ["Farruque", "N.", ""], ["Goebel1", "R.", ""], ["Kima", "M-Y.", ""], ["Motallebi", "M. H.", ""], ["Rabelo", "J.", ""], ["Syed", "T.", ""], ["Za\u00efane", "O. R.", ""]]}, {"id": "2005.01935", "submitter": "Peide Cai", "authors": "Peide Cai, Sukai Wang, Yuxiang Sun, Ming Liu", "title": "Probabilistic End-to-End Vehicle Navigation in Complex Dynamic\n  Environments with Multimodal Sensor Fusion", "comments": "8 pages, 6 figures, 3 tables. IEEE Robotics and Automation Letters\n  (RA-L)", "journal-ref": null, "doi": "10.1109/LRA.2020.2994027", "report-no": null, "categories": "cs.RO cs.AI cs.LG cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  All-day and all-weather navigation is a critical capability for autonomous\ndriving, which requires proper reaction to varied environmental conditions and\ncomplex agent behaviors. Recently, with the rise of deep learning, end-to-end\ncontrol for autonomous vehicles has been well studied. However, most works are\nsolely based on visual information, which can be degraded by challenging\nillumination conditions such as dim light or total darkness. In addition, they\nusually generate and apply deterministic control commands without considering\nthe uncertainties in the future. In this paper, based on imitation learning, we\npropose a probabilistic driving model with ultiperception capability utilizing\nthe information from the camera, lidar and radar. We further evaluate its\ndriving performance online on our new driving benchmark, which includes various\nenvironmental conditions (e.g., urban and rural areas, traffic densities,\nweather and times of the day) and dynamic obstacles (e.g., vehicles,\npedestrians, motorcyclists and bicyclists). The results suggest that our\nproposed model outperforms baselines and achieves excellent generalization\nperformance in unseen environments with heavy traffic and extreme weather.\n", "versions": [{"version": "v1", "created": "Tue, 5 May 2020 03:48:10 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Cai", "Peide", ""], ["Wang", "Sukai", ""], ["Sun", "Yuxiang", ""], ["Liu", "Ming", ""]]}, {"id": "2005.01992", "submitter": "Milad Moradi", "authors": "Milad Moradi, Matthias Samwald", "title": "Post-hoc explanation of black-box classifiers using confident itemsets", "comments": null, "journal-ref": "Expert Systems with Applications, vol. 165, p. 113941, 2021", "doi": "10.1016/j.eswa.2020.113941", "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Black-box Artificial Intelligence (AI) methods, e.g. deep neural networks,\nhave been widely utilized to build predictive models that can extract complex\nrelationships in a dataset and make predictions for new unseen data records.\nHowever, it is difficult to trust decisions made by such methods since their\ninner working and decision logic is hidden from the user. Explainable\nArtificial Intelligence (XAI) refers to systems that try to explain how a\nblack-box AI model produces its outcomes. Post-hoc XAI methods approximate the\nbehavior of a black-box by extracting relationships between feature values and\nthe predictions. Perturbation-based and decision set methods are among commonly\nused post-hoc XAI systems. The former explanators rely on random perturbations\nof data records to build local or global linear models that explain individual\npredictions or the whole model. The latter explanators use those feature values\nthat appear more frequently to construct a set of decision rules that produces\nthe same outcomes as the target black-box. However, these two classes of XAI\nmethods have some limitations. Random perturbations do not take into account\nthe distribution of feature values in different subspaces, leading to\nmisleading approximations. Decision sets only pay attention to frequent feature\nvalues and miss many important correlations between features and class labels\nthat appear less frequently but accurately represent decision boundaries of the\nmodel. In this paper, we address the above challenges by proposing an\nexplanation method named Confident Itemsets Explanation (CIE). We introduce\nconfident itemsets, a set of feature values that are highly correlated to a\nspecific class label. CIE utilizes confident itemsets to discretize the whole\ndecision space of a model to smaller subspaces.\n", "versions": [{"version": "v1", "created": "Tue, 5 May 2020 08:11:24 GMT"}, {"version": "v2", "created": "Sun, 20 Sep 2020 21:24:58 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Moradi", "Milad", ""], ["Samwald", "Matthias", ""]]}, {"id": "2005.02006", "submitter": "Dominique Mercier", "authors": "Dominique Mercier, Andreas Dengel, Sheraz Ahmed", "title": "P2ExNet: Patch-based Prototype Explanation Network", "comments": "12 pages (11 + 1 references), 7 figures. The 27th International\n  Conference on Neural Information Processing (ICONIP2020)", "journal-ref": null, "doi": "10.1007/978-3-030-63836-8_27", "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning methods have shown great success in several domains as they\nprocess a large amount of data efficiently, capable of solving complex\nclassification, forecast, segmentation, and other tasks. However, they come\nwith the inherent drawback of inexplicability limiting their applicability and\ntrustworthiness. Although there exists work addressing this perspective, most\nof the existing approaches are limited to the image modality due to the\nintuitive and prominent concepts. Conversely, the concepts in the time-series\ndomain are more complex and non-comprehensive but these and an explanation for\nthe network decision are pivotal in critical domains like medical, financial,\nor industry. Addressing the need for an explainable approach, we propose a\nnovel interpretable network scheme, designed to inherently use an explainable\nreasoning process inspired by the human cognition without the need of\nadditional post-hoc explainability methods. Therefore, class-specific patches\nare used as they cover local concepts relevant to the classification to reveal\nsimilarities with samples of the same class. In addition, we introduce a novel\nloss concerning interpretability and accuracy that constraints P2ExNet to\nprovide viable explanations of the data including relevant patches, their\nposition, class similarities, and comparison methods without compromising\naccuracy. Analysis of the results on eight publicly available time-series\ndatasets reveals that P2ExNet reaches comparable performance when compared to\nits counterparts while inherently providing understandable and traceable\ndecisions.\n", "versions": [{"version": "v1", "created": "Tue, 5 May 2020 08:45:43 GMT"}, {"version": "v2", "created": "Thu, 19 Nov 2020 13:02:36 GMT"}], "update_date": "2020-11-20", "authors_parsed": [["Mercier", "Dominique", ""], ["Dengel", "Andreas", ""], ["Ahmed", "Sheraz", ""]]}, {"id": "2005.02008", "submitter": "Hongfei Xu", "authors": "Hongfei Xu and Josef van Genabith and Deyi Xiong and Qiuhui Liu", "title": "Dynamically Adjusting Transformer Batch Size by Monitoring Gradient\n  Direction Change", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The choice of hyper-parameters affects the performance of neural models.\nWhile much previous research (Sutskever et al., 2013; Duchi et al., 2011;\nKingma and Ba, 2015) focuses on accelerating convergence and reducing the\neffects of the learning rate, comparatively few papers concentrate on the\neffect of batch size. In this paper, we analyze how increasing batch size\naffects gradient direction, and propose to evaluate the stability of gradients\nwith their angle change. Based on our observations, the angle change of\ngradient direction first tends to stabilize (i.e. gradually decrease) while\naccumulating mini-batches, and then starts to fluctuate. We propose to\nautomatically and dynamically determine batch sizes by accumulating gradients\nof mini-batches and performing an optimization step at just the time when the\ndirection of gradients starts to fluctuate. To improve the efficiency of our\napproach for large models, we propose a sampling approach to select gradients\nof parameters sensitive to the batch size. Our approach dynamically determines\nproper and efficient batch sizes during training. In our experiments on the WMT\n14 English to German and English to French tasks, our approach improves the\nTransformer with a fixed 25k batch size by +0.73 and +0.82 BLEU respectively.\n", "versions": [{"version": "v1", "created": "Tue, 5 May 2020 08:47:34 GMT"}], "update_date": "2020-05-06", "authors_parsed": [["Xu", "Hongfei", ""], ["van Genabith", "Josef", ""], ["Xiong", "Deyi", ""], ["Liu", "Qiuhui", ""]]}, {"id": "2005.02073", "submitter": "Valentin Mayer-Eichberger", "authors": "Ignasi Ab\\'io, Valentin Mayer-Eichberger, Peter Stuckey", "title": "Encoding Linear Constraints into SAT", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Linear integer constraints are one of the most important constraints in\ncombinatorial problems since they are commonly found in many practical\napplications. Typically, encodings to Boolean satisfiability (SAT) format of\nconjunctive normal form perform poorly in problems with these constraints in\ncomparison with SAT modulo theories (SMT), lazy clause generation (LCG) or\nmixed integer programming (MIP) solvers.\n  In this paper we explore and categorize SAT encodings for linear integer\nconstraints. We define new SAT encodings based on multi-valued decision\ndiagrams, and sorting networks. We compare different SAT encodings of linear\nconstraints and demonstrate where one may be preferable to another. We also\ncompare SAT encodings against other solving methods and show they can be better\nthan linear integer (MIP) solvers and sometimes better than LCG or SMT solvers\non appropriate problems. Combining the new encoding with lazy decomposition,\nwhich during runtime only encodes constraints that are important to the solving\nprocess that occurs, gives the best option for many highly combinatorial\nproblems involving linear constraints.\n", "versions": [{"version": "v1", "created": "Tue, 5 May 2020 11:37:43 GMT"}], "update_date": "2020-05-06", "authors_parsed": [["Ab\u00edo", "Ignasi", ""], ["Mayer-Eichberger", "Valentin", ""], ["Stuckey", "Peter", ""]]}, {"id": "2005.02074", "submitter": "Siyuan Liu", "authors": "Xiuyi Fan and Siyuan Liu and Thomas C. Henderson", "title": "Explainable AI for Classification using Probabilistic Logic Inference", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The overarching goal of Explainable AI is to develop systems that not only\nexhibit intelligent behaviours, but also are able to explain their rationale\nand reveal insights. In explainable machine learning, methods that produce a\nhigh level of prediction accuracy as well as transparent explanations are\nvaluable. In this work, we present an explainable classification method. Our\nmethod works by first constructing a symbolic Knowledge Base from the training\ndata, and then performing probabilistic inferences on such Knowledge Base with\nlinear programming. Our approach achieves a level of learning performance\ncomparable to that of traditional classifiers such as random forests, support\nvector machines and neural networks. It identifies decisive features that are\nresponsible for a classification as explanations and produces results similar\nto the ones found by SHAP, a state of the art Shapley Value based method. Our\nalgorithms perform well on a range of synthetic and non-synthetic data sets.\n", "versions": [{"version": "v1", "created": "Tue, 5 May 2020 11:39:23 GMT"}], "update_date": "2020-05-06", "authors_parsed": [["Fan", "Xiuyi", ""], ["Liu", "Siyuan", ""], ["Henderson", "Thomas C.", ""]]}, {"id": "2005.02094", "submitter": "Bentkamp, A.", "authors": "Alexander Bentkamp, Jasmin Blanchette, Simon Cruanes, Uwe Waldmann", "title": "Superposition for Lambda-Free Higher-Order Logic", "comments": "arXiv admin note: text overlap with arXiv:2102.00453", "journal-ref": "Logical Methods in Computer Science, Volume 17, Issue 2 (April 12,\n  2021) lmcs:7349", "doi": null, "report-no": null, "categories": "cs.LO cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We introduce refutationally complete superposition calculi for intentional\nand extensional clausal $\\lambda$-free higher-order logic, two formalisms that\nallow partial application and applied variables. The calculi are parameterized\nby a term order that need not be fully monotonic, making it possible to employ\nthe $\\lambda$-free higher-order lexicographic path and Knuth-Bendix orders. We\nimplemented the calculi in the Zipperposition prover and evaluated them on\nIsabelle/HOL and TPTP benchmarks. They appear promising as a stepping stone\ntowards complete, highly efficient automatic theorem provers for full\nhigher-order logic.\n", "versions": [{"version": "v1", "created": "Tue, 5 May 2020 12:10:21 GMT"}, {"version": "v2", "created": "Tue, 20 Oct 2020 17:01:55 GMT"}, {"version": "v3", "created": "Sat, 20 Feb 2021 11:36:57 GMT"}, {"version": "v4", "created": "Fri, 9 Apr 2021 10:29:29 GMT"}], "update_date": "2021-07-01", "authors_parsed": [["Bentkamp", "Alexander", ""], ["Blanchette", "Jasmin", ""], ["Cruanes", "Simon", ""], ["Waldmann", "Uwe", ""]]}, {"id": "2005.02181", "submitter": "Wei Ji Ma", "authors": "Wei Ji Ma and Benjamin Peters", "title": "A neural network walks into a lab: towards using deep nets as models for\n  human behavior", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CV cs.LG q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  What might sound like the beginning of a joke has become an attractive\nprospect for many cognitive scientists: the use of deep neural network models\n(DNNs) as models of human behavior in perceptual and cognitive tasks. Although\nDNNs have taken over machine learning, attempts to use them as models of human\nbehavior are still in the early stages. Can they become a versatile model class\nin the cognitive scientist's toolbox? We first argue why DNNs have the\npotential to be interesting models of human behavior. We then discuss how that\npotential can be more fully realized. On the one hand, we argue that the cycle\nof training, testing, and revising DNNs needs to be revisited through the lens\nof the cognitive scientist's goals. Specifically, we argue that methods for\nassessing the goodness of fit between DNN models and human behavior have to\ndate been impoverished. On the other hand, cognitive science might have to\nstart using more complex tasks (including richer stimulus spaces), but doing so\nmight be beneficial for DNN-independent reasons as well. Finally, we highlight\navenues where traditional cognitive process models and DNNs may show productive\nsynergy.\n", "versions": [{"version": "v1", "created": "Sat, 2 May 2020 11:17:36 GMT"}], "update_date": "2020-05-06", "authors_parsed": [["Ma", "Wei Ji", ""], ["Peters", "Benjamin", ""]]}, {"id": "2005.02230", "submitter": "Jheng-Hong Yang", "authors": "Sheng-Chieh Lin, Jheng-Hong Yang, Rodrigo Nogueira, Ming-Feng Tsai,\n  Chuan-Ju Wang and Jimmy Lin", "title": "Multi-Stage Conversational Passage Retrieval: An Approach to Fusing Term\n  Importance Estimation and Neural Query Rewriting", "comments": "28 pages. Accepted to ACM Transactions on Information Systems,\n  Special Issue on Conversational Search and Recommendation. The first two\n  authors contributed equally. Code: https://github.com/castorini/chatty-goose", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conversational search plays a vital role in conversational information\nseeking. As queries in information seeking dialogues are ambiguous for\ntraditional ad-hoc information retrieval (IR) systems due to the coreference\nand omission resolution problems inherent in natural language dialogue,\nresolving these ambiguities is crucial. In this paper, we tackle conversational\npassage retrieval (ConvPR), an important component of conversational search, by\naddressing query ambiguities with query reformulation integrated into a\nmulti-stage ad-hoc IR system. Specifically, we propose two conversational query\nreformulation (CQR) methods: (1) term importance estimation and (2) neural\nquery rewriting. For the former, we expand conversational queries using\nimportant terms extracted from the conversational context with frequency-based\nsignals. For the latter, we reformulate conversational queries into natural,\nstandalone, human-understandable queries with a pretrained sequence-tosequence\nmodel. Detailed analyses of the two CQR methods are provided quantitatively and\nqualitatively, explaining their advantages, disadvantages, and distinct\nbehaviors. Moreover, to leverage the strengths of both CQR methods, we propose\ncombining their output with reciprocal rank fusion, yielding state-of-the-art\nretrieval effectiveness, 30% improvement in terms of NDCG@3 compared to the\nbest submission of TREC CAsT 2019.\n", "versions": [{"version": "v1", "created": "Tue, 5 May 2020 14:30:20 GMT"}, {"version": "v2", "created": "Thu, 11 Mar 2021 14:33:53 GMT"}], "update_date": "2021-03-12", "authors_parsed": [["Lin", "Sheng-Chieh", ""], ["Yang", "Jheng-Hong", ""], ["Nogueira", "Rodrigo", ""], ["Tsai", "Ming-Feng", ""], ["Wang", "Chuan-Ju", ""], ["Lin", "Jimmy", ""]]}, {"id": "2005.02259", "submitter": "Andrew Cropper", "authors": "Andrew Cropper and Rolf Morel", "title": "Learning programs by learning from failures", "comments": "Accepted for the machine learning journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe an inductive logic programming (ILP) approach called learning\nfrom failures. In this approach, an ILP system (the learner) decomposes the\nlearning problem into three separate stages: generate, test, and constrain. In\nthe generate stage, the learner generates a hypothesis (a logic program) that\nsatisfies a set of hypothesis constraints (constraints on the syntactic form of\nhypotheses). In the test stage, the learner tests the hypothesis against\ntraining examples. A hypothesis fails when it does not entail all the positive\nexamples or entails a negative example. If a hypothesis fails, then, in the\nconstrain stage, the learner learns constraints from the failed hypothesis to\nprune the hypothesis space, i.e. to constrain subsequent hypothesis generation.\nFor instance, if a hypothesis is too general (entails a negative example), the\nconstraints prune generalisations of the hypothesis. If a hypothesis is too\nspecific (does not entail all the positive examples), the constraints prune\nspecialisations of the hypothesis. This loop repeats until either (i) the\nlearner finds a hypothesis that entails all the positive and none of the\nnegative examples, or (ii) there are no more hypotheses to test. We introduce\nPopper, an ILP system that implements this approach by combining answer set\nprogramming and Prolog. Popper supports infinite problem domains, reasoning\nabout lists and numbers, learning textually minimal programs, and learning\nrecursive programs. Our experimental results on three domains (toy game\nproblems, robot strategies, and list transformations) show that (i) constraints\ndrastically improve learning performance, and (ii) Popper can outperform\nexisting ILP systems, both in terms of predictive accuracies and learning\ntimes.\n", "versions": [{"version": "v1", "created": "Tue, 5 May 2020 14:55:07 GMT"}, {"version": "v2", "created": "Mon, 5 Oct 2020 14:09:52 GMT"}, {"version": "v3", "created": "Wed, 25 Nov 2020 08:45:50 GMT"}], "update_date": "2020-11-26", "authors_parsed": [["Cropper", "Andrew", ""], ["Morel", "Rolf", ""]]}, {"id": "2005.02269", "submitter": "Agnieszka Miko{\\l}ajczyk", "authors": "Agnieszka Miko{\\l}ajczyk, Micha{\\l} Grochowski, Arkadiusz Kwasigroch", "title": "Towards explainable classifiers using the counterfactual approach --\n  global explanations for discovering bias in data", "comments": "Accepted for publication in Journal of Artificial Intelligence and\n  Soft Computing Research; 12 pages, 4 figures, code available, 8-pages\n  appendix", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper proposes summarized attribution-based post-hoc explanations for the\ndetection and identification of bias in data. A global explanation is proposed,\nand a step-by-step framework on how to detect and test bias is introduced.\nSince removing unwanted bias is often a complicated and tremendous task, it is\nautomatically inserted, instead. Then, the bias is evaluated with the proposed\ncounterfactual approach. The obtained results are validated on a sample skin\nlesion dataset. Using the proposed method, a number of possible bias causing\nartifacts are successfully identified and confirmed in dermoscopy images. In\nparticular, it is confirmed that black frames have a strong influence on\nConvolutional Neural Network's prediction: 22% of them changed the prediction\nfrom benign to malignant.\n", "versions": [{"version": "v1", "created": "Tue, 5 May 2020 15:05:33 GMT"}, {"version": "v2", "created": "Fri, 23 Oct 2020 11:47:07 GMT"}], "update_date": "2020-10-26", "authors_parsed": [["Miko\u0142ajczyk", "Agnieszka", ""], ["Grochowski", "Micha\u0142", ""], ["Kwasigroch", "Arkadiusz", ""]]}, {"id": "2005.02305", "submitter": "Or Rivlin", "authors": "Or Rivlin, Tamir Hazan, Erez Karpas", "title": "Generalized Planning With Deep Reinforcement Learning", "comments": "13 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A hallmark of intelligence is the ability to deduce general principles from\nexamples, which are correct beyond the range of those observed. Generalized\nPlanning deals with finding such principles for a class of planning problems,\nso that principles discovered using small instances of a domain can be used to\nsolve much larger instances of the same domain. In this work we study the use\nof Deep Reinforcement Learning and Graph Neural Networks to learn such\ngeneralized policies and demonstrate that they can generalize to instances that\nare orders of magnitude larger than those they were trained on.\n", "versions": [{"version": "v1", "created": "Tue, 5 May 2020 16:06:57 GMT"}], "update_date": "2020-05-06", "authors_parsed": [["Rivlin", "Or", ""], ["Hazan", "Tamir", ""], ["Karpas", "Erez", ""]]}, {"id": "2005.02335", "submitter": "Mahsan Nourani", "authors": "Mahsan Nourani, Chiradeep Roy, Tahrima Rahman, Eric D. Ragan, Nicholas\n  Ruozzi, Vibhav Gogate", "title": "Don't Explain without Verifying Veracity: An Evaluation of Explainable\n  AI with Video Activity Recognition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Explainable machine learning and artificial intelligence models have been\nused to justify a model's decision-making process. This added transparency aims\nto help improve user performance and understanding of the underlying model.\nHowever, in practice, explainable systems face many open questions and\nchallenges. Specifically, designers might reduce the complexity of deep\nlearning models in order to provide interpretability. The explanations\ngenerated by these simplified models, however, might not accurately justify and\nbe truthful to the model. This can further add confusion to the users as they\nmight not find the explanations meaningful with respect to the model\npredictions. Understanding how these explanations affect user behavior is an\nongoing challenge. In this paper, we explore how explanation veracity affects\nuser performance and agreement in intelligent systems. Through a controlled\nuser study with an explainable activity recognition system, we compare\nvariations in explanation veracity for a video review and querying task. The\nresults suggest that low veracity explanations significantly decrease user\nperformance and agreement compared to both accurate explanations and a system\nwithout explanations. These findings demonstrate the importance of accurate and\nunderstandable explanations and caution that poor explanations can sometimes be\nworse than no explanations with respect to their effect on user performance and\nreliance on an AI system.\n", "versions": [{"version": "v1", "created": "Tue, 5 May 2020 17:06:46 GMT"}], "update_date": "2020-05-06", "authors_parsed": [["Nourani", "Mahsan", ""], ["Roy", "Chiradeep", ""], ["Rahman", "Tahrima", ""], ["Ragan", "Eric D.", ""], ["Ruozzi", "Nicholas", ""], ["Gogate", "Vibhav", ""]]}, {"id": "2005.02342", "submitter": "Ryan Steed", "authors": "Ryan Steed, Benjamin Williams", "title": "Heuristic-Based Weak Learning for Automated Decision-Making", "comments": "5 pages, 3 figures. Camera-ready version for Participatory Approaches\n  to Machine Learning @ ICML 2020. Last updated Dec. 2020: fixed bug in Figure\n  3 - \"always intervene\" heuristic should be \"never intervene.\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Machine learning systems impact many stakeholders and groups of users, often\ndisparately. Prior studies have reconciled conflicting user preferences by\naggregating a high volume of manually labeled pairwise comparisons, but this\ntechnique may be costly or impractical. How can we lower the barrier to\nparticipation in algorithm design? Instead of creating a simplified labeling\ntask for a crowd, we suggest collecting ranked decision-making heuristics from\na focused sample of affected users. With empirical data from two use cases, we\nshow that our weak learning approach, which requires little to no manual\nlabeling, agrees with participants' pairwise choices nearly as often as fully\nsupervised approaches.\n", "versions": [{"version": "v1", "created": "Tue, 5 May 2020 17:22:52 GMT"}, {"version": "v2", "created": "Wed, 8 Jul 2020 18:53:24 GMT"}, {"version": "v3", "created": "Wed, 2 Dec 2020 22:55:01 GMT"}], "update_date": "2020-12-04", "authors_parsed": [["Steed", "Ryan", ""], ["Williams", "Benjamin", ""]]}, {"id": "2005.02431", "submitter": "Ekaterina Kochmar", "authors": "Ekaterina Kochmar, Dung Do Vu, Robert Belfer, Varun Gupta, Iulian Vlad\n  Serban, and Joelle Pineau", "title": "Automated Personalized Feedback Improves Learning Gains in an\n  Intelligent Tutoring System", "comments": "To be published in Proceedings of the the 21st International\n  Conference on Artificial Intelligence in Education (AIED 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate how automated, data-driven, personalized feedback in a\nlarge-scale intelligent tutoring system (ITS) improves student learning\noutcomes. We propose a machine learning approach to generate personalized\nfeedback, which takes individual needs of students into account. We utilize\nstate-of-the-art machine learning and natural language processing techniques to\nprovide the students with personalized hints, Wikipedia-based explanations, and\nmathematical hints. Our model is used in Korbit, a large-scale dialogue-based\nITS with thousands of students launched in 2019, and we demonstrate that the\npersonalized feedback leads to considerable improvement in student learning\noutcomes and in the subjective evaluation of the feedback.\n", "versions": [{"version": "v1", "created": "Tue, 5 May 2020 18:30:08 GMT"}, {"version": "v2", "created": "Thu, 7 May 2020 18:18:54 GMT"}], "update_date": "2020-05-11", "authors_parsed": [["Kochmar", "Ekaterina", ""], ["Vu", "Dung Do", ""], ["Belfer", "Robert", ""], ["Gupta", "Varun", ""], ["Serban", "Iulian Vlad", ""], ["Pineau", "Joelle", ""]]}, {"id": "2005.02480", "submitter": "Maxime Peyrard", "authors": "Maxime Peyrard and Robert West", "title": "A Ladder of Causal Distances", "comments": "13 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Causal discovery, the task of automatically constructing a causal model from\ndata, is of major significance across the sciences. Evaluating the performance\nof causal discovery algorithms should ideally involve comparing the inferred\nmodels to ground-truth models available for benchmark datasets, which in turn\nrequires a notion of distance between causal models. While such distances have\nbeen proposed previously, they are limited by focusing on graphical properties\nof the causal models being compared. Here, we overcome this limitation by\ndefining distances derived from the causal distributions induced by the models,\nrather than exclusively from their graphical structure. Pearl and Mackenzie\n(2018) have arranged the properties of causal models in a hierarchy called the\n\"ladder of causation\" spanning three rungs: observational, interventional, and\ncounterfactual. Following this organization, we introduce a hierarchy of three\ndistances, one for each rung of the ladder. Our definitions are intuitively\nappealing as well as efficient to compute approximately. We put our causal\ndistances to use by benchmarking standard causal discovery systems on both\nsynthetic and real-world datasets for which ground-truth causal models are\navailable. Finally, we highlight the usefulness of our causal distances by\nbriefly discussing further applications beyond the evaluation of causal\ndiscovery techniques.\n", "versions": [{"version": "v1", "created": "Tue, 5 May 2020 20:39:07 GMT"}], "update_date": "2020-05-07", "authors_parsed": [["Peyrard", "Maxime", ""], ["West", "Robert", ""]]}, {"id": "2005.02525", "submitter": "Henrique Lemos", "authors": "Henrique Lemos and Pedro Avelar and Marcelo Prates and Lu\\'is Lamb and\n  Artur Garcez", "title": "Neural-Symbolic Relational Reasoning on Graph Models: Effective Link\n  Inference and Computation from Knowledge Bases", "comments": "Under review: ICANN 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recent developments and growing interest in neural-symbolic models has\nshown that hybrid approaches can offer richer models for Artificial\nIntelligence. The integration of effective relational learning and reasoning\nmethods is one of the key challenges in this direction, as neural learning and\nsymbolic reasoning offer complementary characteristics that can benefit the\ndevelopment of AI systems. Relational labelling or link prediction on knowledge\ngraphs has become one of the main problems in deep learning-based natural\nlanguage processing research. Moreover, other fields which make use of\nneural-symbolic techniques may also benefit from such research endeavours.\nThere have been several efforts towards the identification of missing facts\nfrom existing ones in knowledge graphs. Two lines of research try and predict\nknowledge relations between two entities by considering all known facts\nconnecting them or several paths of facts connecting them. We propose a\nneural-symbolic graph neural network which applies learning over all the paths\nby feeding the model with the embedding of the minimal subset of the knowledge\ngraph containing such paths. By learning to produce representations for\nentities and facts corresponding to word embeddings, we show how the model can\nbe trained end-to-end to decode these representations and infer relations\nbetween entities in a multitask approach. Our contribution is two-fold: a\nneural-symbolic methodology leverages the resolution of relational inference in\nlarge graphs, and we also demonstrate that such neural-symbolic model is shown\nmore effective than path-based approaches\n", "versions": [{"version": "v1", "created": "Tue, 5 May 2020 22:46:39 GMT"}], "update_date": "2020-05-07", "authors_parsed": [["Lemos", "Henrique", ""], ["Avelar", "Pedro", ""], ["Prates", "Marcelo", ""], ["Lamb", "Lu\u00eds", ""], ["Garcez", "Artur", ""]]}, {"id": "2005.02530", "submitter": "Hao-Tsung Yang", "authors": "Peyman Afshani, Mark De Berg, Kevin Buchin, Jie Gao, Maarten Loffler,\n  Amir Nayyeri, Benjamin Raichel, Rik Sarkar, Haotian Wang, Hao-Tsung Yang", "title": "Approximation Algorithms for Multi-Robot Patrol-Scheduling with Min-Max\n  Latency", "comments": "Proceedings of the 14th International Workshop on the Algorithmic\n  Foundations of Robotics (WAFR 20)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.AI cs.CG cs.MA cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of finding patrol schedules for $k$ robots to visit a\ngiven set of $n$ sites in a metric space. Each robot has the same maximum speed\nand the goal is to minimize the weighted maximum latency of any site, where the\nlatency of a site is defined as the maximum time duration between consecutive\nvisits of that site. The problem is NP-hard, as it has the traveling salesman\nproblem as a special case (when $k=1$ and all sites have the same weight). We\npresent a polynomial-time algorithm with an approximation factor of $O(k^2 \\log\n\\frac{w_{\\max}}{w_{\\min}})$ to the optimal solution, where $w_{\\max}$ and\n$w_{\\min}$ are the maximum and minimum weight of the sites respectively.\nFurther, we consider the special case where the sites are in 1D. When all sites\nhave the same weight, we present a polynomial-time algorithm to solve the\nproblem exactly. If the sites may have different weights, we present a\n$12$-approximate solution, which runs in polynomial time when the number of\nrobots, $k$, is a constant.\n", "versions": [{"version": "v1", "created": "Tue, 5 May 2020 23:18:53 GMT"}, {"version": "v2", "created": "Sat, 23 May 2020 15:28:03 GMT"}, {"version": "v3", "created": "Tue, 14 Jul 2020 02:39:07 GMT"}], "update_date": "2020-07-15", "authors_parsed": [["Afshani", "Peyman", ""], ["De Berg", "Mark", ""], ["Buchin", "Kevin", ""], ["Gao", "Jie", ""], ["Loffler", "Maarten", ""], ["Nayyeri", "Amir", ""], ["Raichel", "Benjamin", ""], ["Sarkar", "Rik", ""], ["Wang", "Haotian", ""], ["Yang", "Hao-Tsung", ""]]}, {"id": "2005.02558", "submitter": "Desheng Wang", "authors": "Desheng Wang, Jiawei Liu, Xiang Qi, Baolin Sun, Peng Zhang", "title": "Revisiting Regex Generation for Modeling Industrial Applications by\n  Incorporating Byte Pair Encoder", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.IR", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Regular expression is important for many natural language processing tasks\nespecially when used to deal with unstructured and semi-structured data. This\nwork focuses on automatically generating regular expressions and proposes a\nnovel genetic algorithm to deal with this problem. Different from the methods\nwhich generate regular expressions from character level, we first utilize byte\npair encoder (BPE) to extract some frequent items, which are then used to\nconstruct regular expressions. The fitness function of our genetic algorithm\ncontains multi objectives and is solved based on evolutionary procedure\nincluding crossover and mutation operation. In the fitness function, we take\nthe length of generated regular expression, the maximum matching characters and\nsamples for positive training samples, and the minimum matching characters and\nsamples for negative training samples into consideration. In addition, to\naccelerate the training process, we do exponential decay on the population size\nof the genetic algorithm. Our method together with a strong baseline is tested\non 13 kinds of challenging datasets. The results demonstrate the effectiveness\nof our method, which outperforms the baseline on 10 kinds of data and achieves\nnearly 50 percent improvement on average. By doing exponential decay, the\ntraining speed is approximately 100 times faster than the methods without using\nexponential decay. In summary, our method possesses both effectiveness and\nefficiency, and can be implemented for the industry application.\n", "versions": [{"version": "v1", "created": "Wed, 6 May 2020 02:09:10 GMT"}, {"version": "v2", "created": "Wed, 24 Jun 2020 07:52:25 GMT"}], "update_date": "2020-06-25", "authors_parsed": [["Wang", "Desheng", ""], ["Liu", "Jiawei", ""], ["Qi", "Xiang", ""], ["Sun", "Baolin", ""], ["Zhang", "Peng", ""]]}, {"id": "2005.02573", "submitter": "John Licato", "authors": "Zaid Marji, Animesh Nighojkar, John Licato", "title": "Probing the Natural Language Inference Task with Automated Reasoning\n  Tools", "comments": "Accepted to Proceedings of The 33rd International Florida Artificial\n  Intelligence Research Society Conference (FLAIRS-33, 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.SC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Natural Language Inference (NLI) task is an important task in modern NLP,\nas it asks a broad question to which many other tasks may be reducible: Given a\npair of sentences, does the first entail the second? Although the\nstate-of-the-art on current benchmark datasets for NLI are deep learning-based,\nit is worthwhile to use other techniques to examine the logical structure of\nthe NLI task. We do so by testing how well a machine-oriented controlled\nnatural language (Attempto Controlled English) can be used to parse NLI\nsentences, and how well automated theorem provers can reason over the resulting\nformulae. To improve performance, we develop a set of syntactic and semantic\ntransformation rules. We report their performance, and discuss implications for\nNLI and logic-based NLP.\n", "versions": [{"version": "v1", "created": "Wed, 6 May 2020 03:18:11 GMT"}], "update_date": "2020-05-07", "authors_parsed": [["Marji", "Zaid", ""], ["Nighojkar", "Animesh", ""], ["Licato", "John", ""]]}, {"id": "2005.02575", "submitter": "Erdem B{\\i}y{\\i}k", "authors": "Erdem B{\\i}y{\\i}k, Nicolas Huynh, Mykel J. Kochenderfer, Dorsa Sadigh", "title": "Active Preference-Based Gaussian Process Regression for Reward Learning", "comments": "Proceedings of Robotics: Science and Systems (RSS), July 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Designing reward functions is a challenging problem in AI and robotics.\nHumans usually have a difficult time directly specifying all the desirable\nbehaviors that a robot needs to optimize. One common approach is to learn\nreward functions from collected expert demonstrations. However, learning reward\nfunctions from demonstrations introduces many challenges: some methods require\nhighly structured models, e.g. reward functions that are linear in some\npredefined set of features, while others adopt less structured reward functions\nthat on the other hand require tremendous amount of data. In addition, humans\ntend to have a difficult time providing demonstrations on robots with high\ndegrees of freedom, or even quantifying reward values for given demonstrations.\nTo address these challenges, we present a preference-based learning approach,\nwhere as an alternative, the human feedback is only in the form of comparisons\nbetween trajectories. Furthermore, we do not assume highly constrained\nstructures on the reward function. Instead, we model the reward function using\na Gaussian Process (GP) and propose a mathematical formulation to actively find\na GP using only human preferences. Our approach enables us to tackle both\ninflexibility and data-inefficiency problems within a preference-based learning\nframework. Our results in simulations and a user study suggest that our\napproach can efficiently learn expressive reward functions for robotics tasks.\n", "versions": [{"version": "v1", "created": "Wed, 6 May 2020 03:29:27 GMT"}, {"version": "v2", "created": "Wed, 3 Jun 2020 23:08:00 GMT"}], "update_date": "2020-06-05", "authors_parsed": [["B\u0131y\u0131k", "Erdem", ""], ["Huynh", "Nicolas", ""], ["Kochenderfer", "Mykel J.", ""], ["Sadigh", "Dorsa", ""]]}, {"id": "2005.02576", "submitter": "John Licato", "authors": "Elijah Malaby, Bradley Dragun, John Licato", "title": "Towards Concise, Machine-discovered Proofs of G\\\"odel's Two\n  Incompleteness Theorems", "comments": null, "journal-ref": "In Proceedings of The 2020 International Florida Artificial\n  Intelligence Research Society Conference (FLAIRS-33)", "doi": null, "report-no": null, "categories": "cs.LO cs.AI cs.SC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is an increasing interest in applying recent advances in AI to\nautomated reasoning, as it may provide useful heuristics in reasoning over\nformalisms in first-order, second-order, or even meta-logics. To facilitate\nthis research, we present MATR, a new framework for automated theorem proving\nexplicitly designed to easily adapt to unusual logics or integrate new\nreasoning processes. MATR is formalism-agnostic, highly modular, and\nprogrammer-friendly. We explain the high-level design of MATR as well as some\ndetails of its implementation. To demonstrate MATR's utility, we then describe\na formalized metalogic suitable for proofs of G\\\"odel's Incompleteness\nTheorems, and report on our progress using our metalogic in MATR to\nsemi-autonomously generate proofs of both the First and Second Incompleteness\nTheorems.\n", "versions": [{"version": "v1", "created": "Wed, 6 May 2020 03:29:34 GMT"}], "update_date": "2020-05-07", "authors_parsed": [["Malaby", "Elijah", ""], ["Dragun", "Bradley", ""], ["Licato", "John", ""]]}, {"id": "2005.02597", "submitter": "Raunak Bhattacharyya", "authors": "Raunak Bhattacharyya, Ransalu Senanayake, Kyle Brown, and Mykel\n  Kochenderfer", "title": "Online Parameter Estimation for Human Driver Behavior Prediction", "comments": "Accepted to the 2020 American Control Conference (ACC). 6 pages, 6\n  figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Driver models are invaluable for planning in autonomous vehicles as well as\nvalidating their safety in simulation. Highly parameterized black-box driver\nmodels are very expressive, and can capture nuanced behavior. However, they\nusually lack interpretability and sometimes exhibit unrealistic-even\ndangerous-behavior. Rule-based models are interpretable, and can be designed to\nguarantee \"safe\" behavior, but are less expressive due to their low number of\nparameters. In this article, we show that online parameter estimation applied\nto the Intelligent Driver Model captures nuanced individual driving behavior\nwhile providing collision free trajectories. We solve the online parameter\nestimation problem using particle filtering, and benchmark performance against\nrule-based and black-box driver models on two real world driving data sets. We\nevaluate the closeness of our driver model to ground truth data demonstration\nand also assess the safety of the resulting emergent driving behavior.\n", "versions": [{"version": "v1", "created": "Wed, 6 May 2020 05:15:23 GMT"}], "update_date": "2020-05-07", "authors_parsed": [["Bhattacharyya", "Raunak", ""], ["Senanayake", "Ransalu", ""], ["Brown", "Kyle", ""], ["Kochenderfer", "Mykel", ""]]}, {"id": "2005.02618", "submitter": "Paul Diac", "authors": "Cosmin Pascaru, Paul Diac", "title": "Vehicle Routing and Scheduling for Regular Mobile Healthcare Services", "comments": "International Conference on Tools with Artificial Intelligence\n  (ICTAI) 8 pages 1 figure", "journal-ref": null, "doi": "10.1109/ICTAI.2018.00080", "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose our solution to a particular practical problem in the domain of\nvehicle routing and scheduling. The generic task is finding the best allocation\nof the minimum number of \\emph{mobile resources} that can provide periodical\nservices in remote locations. These \\emph{mobile resources} are based at a\nsingle central location. Specifications have been defined initially for a\nreal-life application that is the starting point of an ongoing project.\nParticularly, the goal is to mitigate health problems in rural areas around a\ncity in Romania. Medically equipped vans are programmed to start daily routes\nfrom county capital, provide a given number of examinations in townships within\nthe county and return to the capital city in the same day. From the health care\nperspective, each van is equipped with an ultrasound scanner, and they are\nscheduled to investigate pregnant woman each trimester aiming to diagnose\npotential problems. The project is motivated by reports currently ranking\nRomania as the country with the highest infant mortality rate in the European\nUnion.\n  We developed our solution in two phases: modeling of the most relevant\nparameters and data available for our goal and then design and implement an\nalgorithm that provides an optimized solution. The most important metric of an\noutput scheduling is the number of vans that are necessary to provide a given\namount of examination time per township, followed by total travel time or fuel\nconsumption, number of different routes, and others. Our solution implements\ntwo probabilistic algorithms out of which we chose the one that performs the\nbest.\n", "versions": [{"version": "v1", "created": "Wed, 6 May 2020 07:06:28 GMT"}], "update_date": "2020-05-07", "authors_parsed": [["Pascaru", "Cosmin", ""], ["Diac", "Paul", ""]]}, {"id": "2005.02623", "submitter": "Hao Fang", "authors": "Hao Fang", "title": "Building A User-Centric and Content-Driven Socialbot", "comments": "PhD thesis", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To build Sounding Board, we develop a system architecture that is capable of\naccommodating dialog strategies that we designed for socialbot conversations.\nThe architecture consists of a multi-dimensional language understanding module\nfor analyzing user utterances, a hierarchical dialog management framework for\ndialog context tracking and complex dialog control, and a language generation\nprocess that realizes the response plan and makes adjustments for speech\nsynthesis. Additionally, we construct a new knowledge base to power the\nsocialbot by collecting social chat content from a variety of sources. An\nimportant contribution of the system is the synergy between the knowledge base\nand the dialog management, i.e., the use of a graph structure to organize the\nknowledge base that makes dialog control very efficient in bringing related\ncontent to the discussion. Using the data collected from Sounding Board during\nthe competition, we carry out in-depth analyses of socialbot conversations and\nuser ratings which provide valuable insights in evaluation methods for\nsocialbots. We additionally investigate a new approach for system evaluation\nand diagnosis that allows scoring individual dialog segments in the\nconversation. Finally, observing that socialbots suffer from the issue of\nshallow conversations about topics associated with unstructured data, we study\nthe problem of enabling extended socialbot conversations grounded on a\ndocument. To bring together machine reading and dialog control techniques, a\ngraph-based document representation is proposed, together with methods for\nautomatically constructing the graph. Using the graph-based representation,\ndialog control can be carried out by retrieving nodes or moving along edges in\nthe graph. To illustrate the usage, a mixed-initiative dialog strategy is\ndesigned for socialbot conversations on news articles.\n", "versions": [{"version": "v1", "created": "Wed, 6 May 2020 07:11:57 GMT"}], "update_date": "2020-05-07", "authors_parsed": [["Fang", "Hao", ""]]}, {"id": "2005.02632", "submitter": "Andrea Franceschetti", "authors": "Andrea Franceschetti, Elisa Tosello, Nicola Castaman and Stefano\n  Ghidoni", "title": "Robotic Arm Control and Task Training through Deep Reinforcement\n  Learning", "comments": "Submitted to IEEE/RSJ International Conference on Intelligent Robots\n  and Systems (IROS) 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a detailed and extensive comparison of the Trust Region\nPolicy Optimization and DeepQ-Network with Normalized Advantage Functions with\nrespect to other state of the art algorithms, namely Deep Deterministic Policy\nGradient and Vanilla Policy Gradient. Comparisons demonstrate that the former\nhave better performances then the latter when asking robotic arms to accomplish\nmanipulation tasks such as reaching a random target pose and pick &placing an\nobject. Both simulated and real-world experiments are provided. Simulation lets\nus show the procedures that we adopted to precisely estimate the algorithms\nhyper-parameters and to correctly design good policies. Real-world experiments\nlet show that our polices, if correctly trained on simulation, can be\ntransferred and executed in a real environment with almost no changes.\n", "versions": [{"version": "v1", "created": "Wed, 6 May 2020 07:34:28 GMT"}], "update_date": "2020-05-07", "authors_parsed": [["Franceschetti", "Andrea", ""], ["Tosello", "Elisa", ""], ["Castaman", "Nicola", ""], ["Ghidoni", "Stefano", ""]]}, {"id": "2005.02645", "submitter": "Kazuyuki Amano", "authors": "Riona Tadaki and Kazuyuki Amano", "title": "Search for developments of a box having multiple ways of folding by SAT\n  solver", "comments": "12 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DM cs.AI cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A polyomino is called a development if it can make a box by folding edges of\nunit squares forming the polyomino. It is known that there are developments\nthat can fold into a box (or boxes) in multiple ways. In this work, we\nconducted a computer search for finding such developments by using a SAT\nsolver. As a result, we found thousands of such developments including a\npolyomino of area 52 that can fold into a box of size $1 \\times 2 \\times 8$ in\nfive different ways.\n", "versions": [{"version": "v1", "created": "Wed, 6 May 2020 08:15:07 GMT"}], "update_date": "2020-05-07", "authors_parsed": [["Tadaki", "Riona", ""], ["Amano", "Kazuyuki", ""]]}, {"id": "2005.02659", "submitter": "Samira Babalou", "authors": "Samira Babalou, Birgitta K\\\"onig-Ries", "title": "Towards Building Knowledge by Merging Multiple Ontologies with CoMerger:\n  A Partitioning-based Approach", "comments": "A further improved version of this paper will be submitted to the\n  International Semantic Web Conference (ISWC) 2020 conference. The paper has\n  23 pages including appendix and 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ontologies are the prime way of organizing data in the Semantic Web. Often,\nit is necessary to combine several, independently developed ontologies to\nobtain a knowledge graph fully representing a domain of interest. The\ncomplementarity of existing ontologies can be leveraged by merging them.\nExisting approaches for ontology merging mostly implement a binary merge.\nHowever, with the growing number and size of relevant ontologies across\ndomains, scalability becomes a central challenge. A multi-ontology merging\ntechnique offers a potential solution to this problem. We present CoMerger, a\nscalable multiple ontologies merging method. For efficient processing, rather\nthan successively merging complete ontologies pairwise, we group related\nconcepts across ontologies into partitions and merge first within and then\nacross those partitions. The experimental results on well-known datasets\nconfirm the feasibility of our approach and demonstrate its superiority over\nbinary strategies. A prototypical implementation is freely accessible through a\nlive web portal.\n", "versions": [{"version": "v1", "created": "Wed, 6 May 2020 08:45:00 GMT"}], "update_date": "2020-05-07", "authors_parsed": [["Babalou", "Samira", ""], ["K\u00f6nig-Ries", "Birgitta", ""]]}, {"id": "2005.02777", "submitter": "Katalin Feher", "authors": "Katalin Feher and Asta Zelenkauskaite", "title": "AI in society and culture: decision making and values", "comments": "5 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.OH cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the increased expectation of artificial intelligence, academic research\nface complex questions of human-centred, responsible and trustworthy technology\nembedded into society and culture. Several academic debates, social\nconsultations and impact studies are available to reveal the key aspects of the\nchanging human-machine ecosystem. To contribute to these studies, hundreds of\nrelated academic sources are summarized below regarding AI-driven decisions and\nvaluable AI. In details, sociocultural filters, taxonomy of human-machine\ndecisions and perspectives of value-based AI are in the focus of this\nliterature review. For better understanding, it is proposed to invite\nstakeholders in the prepared large-scale survey about the next generation AI\nthat investigates issues that go beyond the technology.\n", "versions": [{"version": "v1", "created": "Wed, 29 Apr 2020 07:09:39 GMT"}], "update_date": "2020-05-07", "authors_parsed": [["Feher", "Katalin", ""], ["Zelenkauskaite", "Asta", ""]]}, {"id": "2005.02794", "submitter": "Deajin Jo", "authors": "DaeJin Jo", "title": "Token Manipulation Generative Adversarial Network for Text Generation", "comments": "5 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  MaskGAN opens the query for the conditional language model by filling in the\nblanks between the given tokens. In this paper, we focus on addressing the\nlimitations caused by having to specify blanks to be filled. We decompose\nconditional text generation problem into two tasks, make-a-blank and\nfill-in-the-blank, and extend the former to handle more complex manipulations\non the given tokens. We cast these tasks as a hierarchical multi agent RL\nproblem and introduce a conditional adversarial learning that allows the agents\nto reach a goal, producing realistic texts, in cooperative setting. We show\nthat the proposed model not only addresses the limitations but also provides\ngood results without compromising the performance in terms of quality and\ndiversity.\n", "versions": [{"version": "v1", "created": "Wed, 6 May 2020 13:10:43 GMT"}, {"version": "v2", "created": "Mon, 11 May 2020 12:17:28 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["Jo", "DaeJin", ""]]}, {"id": "2005.02801", "submitter": "Natesh Ganesh", "authors": "Natesh Ganesh", "title": "A Non-equilibrium Thermodynamic Framework of Consciousness", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cond-mat.stat-mech", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we take a brief look at the advantages and disadvantages of\ndominant frameworks in consciousness studies -- functionalist and causal\nstructure theories, and use it to motivate a new non-equilibrium thermodynamic\nframework of consciousness. The main hypothesis in this paper will be two\nthermodynamic conditions obtained from the non-equilibrium fluctuation theorems\n-- TCC 1 and 2, that the author proposes as necessary conditions that a system\nwill have to satisfy in order to be 'conscious'. These descriptions will look\nto specify the functions achieved by a conscious system and restrict the\nphysical structures that achieve them without presupposing either of the two.\nThese represent an attempt to integrate consciousness into established physical\nlaw (without invoking untested novel frameworks in quantum mechanics and/or\ngeneral relativity). We will also discuss it's implications on a wide range of\nexisting questions, including a stance on the hard problem. The paper will also\nexplore why this framework might offer a serious path forward to understanding\nconsciousness (and perhaps even realizing it in artificial systems) as well as\nlaying out some problems and challenges that lie ahead.\n", "versions": [{"version": "v1", "created": "Mon, 4 May 2020 20:01:53 GMT"}], "update_date": "2020-05-07", "authors_parsed": [["Ganesh", "Natesh", ""]]}, {"id": "2005.02810", "submitter": "Juan Afanador", "authors": "Juan Afanador", "title": "A Formal Critique of the Value of the Colombian P\\'aramo", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article presents conceptual and methodological frameworks to prioritise\ninterventions on the Colombian P\\'aramo. The mode of analysis that our work\ntakes up is that of questioning value and related categories as definite\nempirically perceived phenomena. We contend that the valuation of ecosystem\nservices -- even in its post-normal forms -- and the ecosystem services\nframework not only fail to examine value-based categories, but reproduce the\nproblematic aspects of value-based social relations, which ultimately bear on\nthe ecological issues affecting the P\\'aramo. Upon this premise we set out to\nformalise a (computational) dialogical scenario where arguments stating\ndistinct, and often contradictory, actions delineate possible forms of\nappropriating the P\\'aramo, while motivating the examination of their defining\nsociality.\n", "versions": [{"version": "v1", "created": "Sun, 3 May 2020 11:49:16 GMT"}], "update_date": "2020-05-07", "authors_parsed": [["Afanador", "Juan", ""]]}, {"id": "2005.02811", "submitter": "Romit Beed Mr", "authors": "Romit S Beed, Sunita Sarkar, Arindam Roy and Durba Bhattacharya", "title": "Hierarchical Bayesian Approach for Improving Weights for Solving\n  Multi-Objective Route Optimization Problem", "comments": "16 pages, 3 figures, 5 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The weighted sum method is a simple and widely used technique that scalarizes\nmultiple conflicting objectives into a single objective function. It suffers\nfrom the problem of determining the appropriate weights corresponding to the\nobjectives. This paper proposes a novel Hierarchical Bayesian model based on\nMultinomial distribution and Dirichlet prior to refine the weights for solving\nsuch multi-objective route optimization problems. The model and methodologies\nrevolve around data obtained from a small scale pilot survey. The method aims\nat improving the existing methods of weight determination in the field of\nIntelligent Transport Systems as data driven choice of weights through\nappropriate probabilistic modelling ensures, on an average, much reliable\nresults than non-probabilistic techniques. Application of this model and\nmethodologies to simulated as well as real data sets revealed quite encouraging\nperformances with respect to stabilizing the estimates of weights.\n", "versions": [{"version": "v1", "created": "Sun, 3 May 2020 06:13:52 GMT"}], "update_date": "2020-05-07", "authors_parsed": [["Beed", "Romit S", ""], ["Sarkar", "Sunita", ""], ["Roy", "Arindam", ""], ["Bhattacharya", "Durba", ""]]}, {"id": "2005.02824", "submitter": "Maryam Alimardani", "authors": "Andrea Kuijt and Maryam Alimardani", "title": "Prediction of Human Empathy based on EEG Cortical Asymmetry", "comments": "Accepted in the 1st IEEE International Conference on Human-Machine\n  Systems", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Humans constantly interact with digital devices that disregard their\nfeelings. However, the synergy between human and technology can be strengthened\nif the technology is able to distinguish and react to human emotions. Models\nthat rely on unconscious indications of human emotions, such as\n(neuro)physiological signals, hold promise in personalization of feedback and\nadaptation of the interaction. The current study elaborated on adopting a\npredictive approach in studying human emotional processing based on brain\nactivity. More specifically, we investigated the proposition of predicting\nself-reported human empathy based on EEG cortical asymmetry in different areas\nof the brain. Different types of predictive models i.e. multiple linear\nregression analyses as well as binary and multiclass classifications were\nevaluated. Results showed that lateralization of brain oscillations at specific\nfrequency bands is an important predictor of self-reported empathy scores.\nAdditionally, prominent classification performance was found during\nresting-state which suggests that emotional stimulation is not required for\naccurate prediction of empathy -- as a personality trait -- based on EEG data.\nOur findings not only contribute to the general understanding of the mechanisms\nof empathy, but also facilitate a better grasp on the advantages of applying a\npredictive approach compared to hypothesis-driven studies in neuropsychological\nresearch. More importantly, our results could be employed in the development of\nbrain-computer interfaces that assist people with difficulties in expressing or\nrecognizing emotions.\n", "versions": [{"version": "v1", "created": "Wed, 6 May 2020 13:49:56 GMT"}], "update_date": "2020-05-07", "authors_parsed": [["Kuijt", "Andrea", ""], ["Alimardani", "Maryam", ""]]}, {"id": "2005.02863", "submitter": "Loris Nanni", "authors": "Lorenzo Mantovan and Loris Nanni", "title": "The computerization of archaeology: survey on AI techniques", "comments": null, "journal-ref": "SN Computer Science, 2020", "doi": "10.1007/s42979-020-00286-w", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper analyses the application of artificial intelligence techniques to\nvarious areas of archaeology and more specifically: a) The use of software\ntools as a creative stimulus for the organization of exhibitions; the use of\nhumanoid robots and holographic displays as guides that interact and involve\nmuseum visitors; b) The analysis of methods for the classification of fragments\nfound in archaeological excavations and for the reconstruction of ceramics,\nwith the recomposition of the parts of text missing from historical documents\nand epigraphs; c) The cataloguing and study of human remains to understand the\nsocial and historical context of belonging with the demonstration of the\neffectiveness of the AI techniques used; d) The detection of particularly\ndifficult terrestrial archaeological sites with the analysis of the\narchitectures of the Artificial Neural Networks most suitable for solving the\nproblems presented by the site; the design of a study for the exploration of\nmarine archaeological sites, located at depths that cannot be reached by man,\nthrough the construction of a freely explorable 3D version.\n", "versions": [{"version": "v1", "created": "Tue, 5 May 2020 17:09:48 GMT"}, {"version": "v2", "created": "Tue, 30 Jun 2020 23:50:14 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Mantovan", "Lorenzo", ""], ["Nanni", "Loris", ""]]}, {"id": "2005.02878", "submitter": "Kaiyu Zheng", "authors": "Kaiyu Zheng, Yoonchang Sung, George Konidaris, Stefanie Tellex", "title": "Multi-Resolution POMDP Planning for Multi-Object Search in 3D", "comments": "7 pages, 6 figures. Preprint. Under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Robots operating in household environments must find objects on shelves,\nunder tables, and in cupboards. Previous work often formulates the object\nsearch problem as a POMDP Partially Observable Markov Decision Process), yet\nconstrain the search space in 2D to reduce computational complexity, although\nobjects exist in a rich 3D environment. We present a POMDP formulation for\nmulti-object search in a 3D region with a frustum-shaped field-of-view and an\nefficient multi-resolution planning algorithm to solve this POMDP. To achieve\nefficient planning, our algorithm uses a new octree-based representation that\ncaptures beliefs at different resolution levels, enabling the agent to induce\nabstract POMDPs with dramatically smaller state and observation spaces. Our\nevaluation in a simulated 3D domain shows that our approach achieves\nsignificantly higher reward ($\\geq$ 51% in the largest instance) and finds more\nobjects compared to baselines without a resolution hierarchy, as the search\nspace becomes larger, and as the sensor uncertainty increases. We show that our\napproach enables a mobile robot to automatically find objects placed at\ndifferent heights in two 10m$^2\\times$2m regions by moving its base and\nactuating its torso.\n", "versions": [{"version": "v1", "created": "Wed, 6 May 2020 14:54:01 GMT"}, {"version": "v2", "created": "Thu, 7 May 2020 02:34:19 GMT"}, {"version": "v3", "created": "Mon, 7 Dec 2020 19:28:43 GMT"}], "update_date": "2020-12-09", "authors_parsed": [["Zheng", "Kaiyu", ""], ["Sung", "Yoonchang", ""], ["Konidaris", "George", ""], ["Tellex", "Stefanie", ""]]}, {"id": "2005.02880", "submitter": "Jessica Hamrick", "authors": "Eliza Kosoy, Jasmine Collins, David M. Chan, Sandy Huang, Deepak\n  Pathak, Pulkit Agrawal, John Canny, Alison Gopnik, Jessica B. Hamrick", "title": "Exploring Exploration: Comparing Children with RL Agents in Unified\n  Environments", "comments": "Published as a workshop paper at \"Bridging AI and Cognitive Science\"\n  (ICLR 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Research in developmental psychology consistently shows that children explore\nthe world thoroughly and efficiently and that this exploration allows them to\nlearn. In turn, this early learning supports more robust generalization and\nintelligent behavior later in life. While much work has gone into developing\nmethods for exploration in machine learning, artificial agents have not yet\nreached the high standard set by their human counterparts. In this work we\npropose using DeepMind Lab (Beattie et al., 2016) as a platform to directly\ncompare child and agent behaviors and to develop new exploration techniques. We\noutline two ongoing experiments to demonstrate the effectiveness of a direct\ncomparison, and outline a number of open research questions that we believe can\nbe tested using this methodology.\n", "versions": [{"version": "v1", "created": "Wed, 6 May 2020 14:54:31 GMT"}, {"version": "v2", "created": "Wed, 1 Jul 2020 09:26:18 GMT"}], "update_date": "2020-07-02", "authors_parsed": [["Kosoy", "Eliza", ""], ["Collins", "Jasmine", ""], ["Chan", "David M.", ""], ["Huang", "Sandy", ""], ["Pathak", "Deepak", ""], ["Agrawal", "Pulkit", ""], ["Canny", "John", ""], ["Gopnik", "Alison", ""], ["Hamrick", "Jessica B.", ""]]}, {"id": "2005.02934", "submitter": "Pierre-Alexandre Kamienny Mr", "authors": "Pierre-Alexandre Kamienny, Matteo Pirotta, Alessandro Lazaric,\n  Thibault Lavril, Nicolas Usunier, Ludovic Denoyer", "title": "Learning Adaptive Exploration Strategies in Dynamic Environments Through\n  Informed Policy Regularization", "comments": "18 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of learning exploration-exploitation strategies that\neffectively adapt to dynamic environments, where the task may change over time.\nWhile RNN-based policies could in principle represent such strategies, in\npractice their training time is prohibitive and the learning process often\nconverges to poor solutions. In this paper, we consider the case where the\nagent has access to a description of the task (e.g., a task id or task\nparameters) at training time, but not at test time. We propose a novel\nalgorithm that regularizes the training of an RNN-based policy using informed\npolicies trained to maximize the reward in each task. This dramatically reduces\nthe sample complexity of training RNN-based policies, without losing their\nrepresentational power. As a result, our method learns exploration strategies\nthat efficiently balance between gathering information about the unknown and\nchanging task and maximizing the reward over time. We test the performance of\nour algorithm in a variety of environments where tasks may vary within each\nepisode.\n", "versions": [{"version": "v1", "created": "Wed, 6 May 2020 16:14:48 GMT"}], "update_date": "2020-05-07", "authors_parsed": [["Kamienny", "Pierre-Alexandre", ""], ["Pirotta", "Matteo", ""], ["Lazaric", "Alessandro", ""], ["Lavril", "Thibault", ""], ["Usunier", "Nicolas", ""], ["Denoyer", "Ludovic", ""]]}, {"id": "2005.02940", "submitter": "Remi Geraud-Stewart", "authors": "Marc Beunardeau, \\'Eric Brier, No\\'emie Cartier, Aisling Connolly,\n  Nathana\\\"el Courant, R\\'emi G\\'eraud-Stewart, David Naccache, Ofer\n  Yifrach-Stav", "title": "Optimal Covid-19 Pool Testing with a priori Information", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.DM q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As humanity struggles to contain the global Covid-19 infection, prophylactic\nactions are grandly slowed down by the shortage of testing kits. Governments\nhave taken several measures to work around this shortage: the FDA has become\nmore liberal on the approval of Covid-19 tests in the US. In the UK emergency\nmeasures allowed to increase the daily number of locally produced test kits to\n100,000. China has recently launched a massive test manufacturing program.\nHowever, all those efforts are very insufficient and many poor countries are\nstill under threat. A popular method for reducing the number of tests consists\nin pooling samples, i.e. mixing patient samples and testing the mixed samples\nonce. If all the samples are negative, pooling succeeds at a unitary cost.\nHowever, if a single sample is positive, failure does not indicate which\npatient is infected. This paper describes how to optimally detect infected\npatients in pools, i.e. using a minimal number of tests to precisely identify\nthem, given the a priori probabilities that each of the patients is healthy.\nThose probabilities can be estimated using questionnaires, supervised machine\nlearning or clinical examinations. The resulting algorithms, which can be\ninterpreted as informed divide-and-conquer strategies, are non-intuitive and\nquite surprising. They are patent-free. Co-authors are listed in alphabetical\norder.\n", "versions": [{"version": "v1", "created": "Wed, 6 May 2020 17:08:56 GMT"}, {"version": "v2", "created": "Mon, 11 May 2020 09:25:25 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["Beunardeau", "Marc", ""], ["Brier", "\u00c9ric", ""], ["Cartier", "No\u00e9mie", ""], ["Connolly", "Aisling", ""], ["Courant", "Nathana\u00ebl", ""], ["G\u00e9raud-Stewart", "R\u00e9mi", ""], ["Naccache", "David", ""], ["Yifrach-Stav", "Ofer", ""]]}, {"id": "2005.02963", "submitter": "Maayan Shvo", "authors": "Maayan Shvo, Toryn Q. Klassen, Sheila A. McIlraith", "title": "Towards the Role of Theory of Mind in Explanation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Theory of Mind is commonly defined as the ability to attribute mental states\n(e.g., beliefs, goals) to oneself, and to others. A large body of previous work\n- from the social sciences to artificial intelligence - has observed that\nTheory of Mind capabilities are central to providing an explanation to another\nagent or when explaining that agent's behaviour. In this paper, we build and\nexpand upon previous work by providing an account of explanation in terms of\nthe beliefs of agents and the mechanism by which agents revise their beliefs\ngiven possible explanations. We further identify a set of desiderata for\nexplanations that utilize Theory of Mind. These desiderata inform our\nbelief-based account of explanation.\n", "versions": [{"version": "v1", "created": "Wed, 6 May 2020 17:13:46 GMT"}], "update_date": "2020-05-07", "authors_parsed": [["Shvo", "Maayan", ""], ["Klassen", "Toryn Q.", ""], ["McIlraith", "Sheila A.", ""]]}, {"id": "2005.02979", "submitter": "Anthony Corso", "authors": "Anthony Corso, Robert J. Moss, Mark Koren, Ritchie Lee, Mykel J.\n  Kochenderfer", "title": "A Survey of Algorithms for Black-Box Safety Validation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Autonomous and semi-autonomous systems for safety-critical applications\nrequire rigorous testing before deployment. Due to the complexity of these\nsystems, formal verification may be impossible and real-world testing may be\ndangerous during development. Therefore, simulation-based techniques have been\ndeveloped that treat the system under test as a black box during testing.\nSafety validation tasks include finding disturbances to the system that cause\nit to fail (falsification), finding the most-likely failure, and estimating the\nprobability that the system fails. Motivated by the prevalence of\nsafety-critical artificial intelligence, this work provides a survey of\nstate-of-the-art safety validation techniques with a focus on applied\nalgorithms and their modifications for the safety validation problem. We\npresent and discuss algorithms in the domains of optimization, path planning,\nreinforcement learning, and importance sampling. Problem decomposition\ntechniques are presented to help scale algorithms to large state spaces, and a\nbrief overview of safety-critical applications is given, including autonomous\nvehicles and aircraft collision avoidance systems. Finally, we present a survey\nof existing academic and commercially available safety validation tools.\n", "versions": [{"version": "v1", "created": "Wed, 6 May 2020 17:31:51 GMT"}, {"version": "v2", "created": "Sat, 11 Jul 2020 16:18:28 GMT"}], "update_date": "2020-07-14", "authors_parsed": [["Corso", "Anthony", ""], ["Moss", "Robert J.", ""], ["Koren", "Mark", ""], ["Lee", "Ritchie", ""], ["Kochenderfer", "Mykel J.", ""]]}, {"id": "2005.02986", "submitter": "Ramon Fraga Pereira", "authors": "Kin Max Piamolini Gusm\\~ao, Ramon Fraga Pereira, Felipe Meneguzzi", "title": "The More the Merrier?! Evaluating the Effect of Landmark Extraction\n  Algorithms on Landmark-Based Goal Recognition", "comments": "This paper has been published at the AAAI 2020 workshop on Plan,\n  Activity, and Intent Recognition (PAIR)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent approaches to goal and plan recognition using classical planning\ndomains have achieved state of the art results in terms of both recognition\ntime and accuracy by using heuristics based on planning landmarks. To achieve\nsuch fast recognition time these approaches use efficient, but incomplete,\nalgorithms to extract only a subset of landmarks for planning domains and\nproblems, at the cost of some accuracy. In this paper, we investigate the\nimpact and effect of using various landmark extraction algorithms capable of\nextracting a larger proportion of the landmarks for each given planning\nproblem, up to exhaustive landmark extraction. We perform an extensive\nempirical evaluation of various landmark-based heuristics when using different\npercentages of the full set of landmarks. Results show that having more\nlandmarks does not necessarily mean achieving higher accuracy and lower spread,\nas the additional extracted landmarks may not necessarily increase be helpful\ntowards the goal recognition task.\n", "versions": [{"version": "v1", "created": "Wed, 6 May 2020 17:41:19 GMT"}], "update_date": "2020-05-07", "authors_parsed": [["Gusm\u00e3o", "Kin Max Piamolini", ""], ["Pereira", "Ramon Fraga", ""], ["Meneguzzi", "Felipe", ""]]}, {"id": "2005.03003", "submitter": "Martin Barrere", "authors": "Mart\\'in Barr\\`ere and Chris Hankin", "title": "Fault Tree Analysis: Identifying Maximum Probability Minimal Cut Sets\n  with MaxSAT", "comments": "Accepted for publication at the 50th IEEE/IFIP International\n  Conference on Dependable Systems and Networks (DSN 2020), Fast Abstracts\n  Track, 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CR cs.DM cs.LO cs.NI cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present a novel MaxSAT-based technique to compute Maximum\nProbability Minimal Cut Sets (MPMCSs) in fault trees. We model the MPMCS\nproblem as a Weighted Partial MaxSAT problem and solve it using a parallel\nSAT-solving architecture. The results obtained with our open source tool\nindicate that the approach is effective and efficient.\n", "versions": [{"version": "v1", "created": "Tue, 5 May 2020 19:47:15 GMT"}], "update_date": "2020-05-08", "authors_parsed": [["Barr\u00e8re", "Mart\u00edn", ""], ["Hankin", "Chris", ""]]}, {"id": "2005.03063", "submitter": "Don Dini", "authors": "Don M. Dini", "title": "Learning, transferring, and recommending performance knowledge with\n  Monte Carlo tree search and neural networks", "comments": "8 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Making changes to a program to optimize its performance is an unscalable task\nthat relies entirely upon human intuition and experience. In addition,\ncompanies operating at large scale are at a stage where no single individual\nunderstands the code controlling its systems, and for this reason, making\nchanges to improve performance can become intractably difficult. In this paper,\na learning system is introduced that provides AI assistance for finding\nrecommended changes to a program. Specifically, it is shown how the evaluative\nfeedback, delayed-reward performance programming domain can be effectively\nformulated via the Monte Carlo tree search (MCTS) framework. It is then shown\nthat established methods from computational games for using learning to\nexpedite tree-search computation can be adapted to speed up computing\nrecommended program alterations. Estimates of expected utility from MCTS trees\nbuilt for previous problems are used to learn a sampling policy that remains\neffective across new problems, thus demonstrating transferability of\noptimization knowledge. This formulation is applied to the Apache Spark\ndistributed computing environment, and a preliminary result is observed that\nthe time required to build a search tree for finding recommendations is reduced\nby up to a factor of 10x.\n", "versions": [{"version": "v1", "created": "Wed, 6 May 2020 18:26:03 GMT"}], "update_date": "2020-05-08", "authors_parsed": [["Dini", "Don M.", ""]]}, {"id": "2005.03066", "submitter": "Danushka Bollegala", "authors": "Asir Saeed, Khai Mai, Pham Minh, Nguyen Tuan Duc, Danushka Bollegala", "title": "Weakly-Supervised Neural Response Selection from an Ensemble of\n  Task-Specialised Dialogue Agents", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dialogue engines that incorporate different types of agents to converse with\nhumans are popular.\n  However, conversations are dynamic in the sense that a selected response will\nchange the conversation on-the-fly, influencing the subsequent utterances in\nthe conversation, which makes the response selection a challenging problem.\n  We model the problem of selecting the best response from a set of responses\ngenerated by a heterogeneous set of dialogue agents by taking into account the\nconversational history, and propose a \\emph{Neural Response Selection} method.\n  The proposed method is trained to predict a coherent set of responses within\na single conversation, considering its own predictions via a curriculum\ntraining mechanism.\n  Our experimental results show that the proposed method can accurately select\nthe most appropriate responses, thereby significantly improving the user\nexperience in dialogue systems.\n", "versions": [{"version": "v1", "created": "Wed, 6 May 2020 18:40:26 GMT"}], "update_date": "2020-05-08", "authors_parsed": [["Saeed", "Asir", ""], ["Mai", "Khai", ""], ["Minh", "Pham", ""], ["Duc", "Nguyen Tuan", ""], ["Bollegala", "Danushka", ""]]}, {"id": "2005.03086", "submitter": "Hao Tan", "authors": "Yubo Zhang, Hao Tan, Mohit Bansal", "title": "Diagnosing the Environment Bias in Vision-and-Language Navigation", "comments": "IJCAI 2020 (9 pages; first two authors contributed equally)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Vision-and-Language Navigation (VLN) requires an agent to follow\nnatural-language instructions, explore the given environments, and reach the\ndesired target locations. These step-by-step navigational instructions are\ncrucial when the agent is navigating new environments about which it has no\nprior knowledge. Most recent works that study VLN observe a significant\nperformance drop when tested on unseen environments (i.e., environments not\nused in training), indicating that the neural agent models are highly biased\ntowards training environments. Although this issue is considered as one of the\nmajor challenges in VLN research, it is still under-studied and needs a clearer\nexplanation. In this work, we design novel diagnosis experiments via\nenvironment re-splitting and feature replacement, looking into possible reasons\nfor this environment bias. We observe that neither the language nor the\nunderlying navigational graph, but the low-level visual appearance conveyed by\nResNet features directly affects the agent model and contributes to this\nenvironment bias in results. According to this observation, we explore several\nkinds of semantic representations that contain less low-level visual\ninformation, hence the agent learned with these features could be better\ngeneralized to unseen testing environments. Without modifying the baseline\nagent model and its training method, our explored semantic features\nsignificantly decrease the performance gaps between seen and unseen on multiple\ndatasets (i.e. R2R, R4R, and CVDN) and achieve competitive unseen results to\nprevious state-of-the-art models. Our code and features are available at:\nhttps://github.com/zhangybzbo/EnvBiasVLN\n", "versions": [{"version": "v1", "created": "Wed, 6 May 2020 19:24:33 GMT"}], "update_date": "2020-05-08", "authors_parsed": [["Zhang", "Yubo", ""], ["Tan", "Hao", ""], ["Bansal", "Mohit", ""]]}, {"id": "2005.03098", "submitter": "Arne Decadt", "authors": "Arne Decadt, Jasper De Bock, Gert de Cooman", "title": "Inference with Choice Functions Made Practical", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study how to infer new choices from previous choices in a conservative\nmanner. To make such inferences, we use the theory of choice functions: a\nunifying mathematical framework for conservative decision making that allows\none to impose axioms directly on the represented decisions. We here adopt the\ncoherence axioms of De Bock and De Cooman (2019). We show how to naturally\nextend any given choice assessment to such a coherent choice function, whenever\npossible, and use this natural extension to make new choices. We present a\npractical algorithm to compute this natural extension and provide several\nmethods that can be used to improve its scalability.\n", "versions": [{"version": "v1", "created": "Thu, 7 May 2020 12:58:05 GMT"}, {"version": "v2", "created": "Sun, 10 May 2020 14:34:25 GMT"}, {"version": "v3", "created": "Wed, 15 Jul 2020 14:08:00 GMT"}], "update_date": "2020-07-16", "authors_parsed": [["Decadt", "Arne", ""], ["De Bock", "Jasper", ""], ["de Cooman", "Gert", ""]]}, {"id": "2005.03182", "submitter": "Thomas Da Silva Paula", "authors": "David Murphy and Thomas S. Paula and Wagston Staehler and Juliano\n  Vacaro and Gabriel Paz and Guilherme Marques and Bruna Oliveira", "title": "A Proposal for Intelligent Agents with Episodic Memory", "comments": "7 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In the future we can expect that artificial intelligent agents, once\ndeployed, will be required to learn continually from their experience during\ntheir operational lifetime. Such agents will also need to communicate with\nhumans and other agents regarding the content of their experience, in the\ncontext of passing along their learnings, for the purpose of explaining their\nactions in specific circumstances or simply to relate more naturally to humans\nconcerning experiences the agent acquires that are not necessarily related to\ntheir assigned tasks. We argue that to support these goals, an agent would\nbenefit from an episodic memory; that is, a memory that encodes the agent's\nexperience in such a way that the agent can relive the experience, communicate\nabout it and use its past experience, inclusive of the agents own past actions,\nto learn more effective models and policies. In this short paper, we propose\none potential approach to provide an AI agent with such capabilities. We draw\nupon the ever-growing body of work examining the function and operation of the\nMedial Temporal Lobe (MTL) in mammals to guide us in adding an episodic memory\ncapability to an AI agent composed of artificial neural networks (ANNs). Based\non that, we highlight important aspects to be considered in the memory\norganization and we propose an architecture combining ANNs and standard\nComputer Science techniques for supporting storage and retrieval of episodic\nmemories. Despite being initial work, we hope this short paper can spark\ndiscussions around the creation of intelligent agents with memory or, at least,\nprovide a different point of view on the subject.\n", "versions": [{"version": "v1", "created": "Thu, 7 May 2020 00:26:42 GMT"}], "update_date": "2020-05-08", "authors_parsed": [["Murphy", "David", ""], ["Paula", "Thomas S.", ""], ["Staehler", "Wagston", ""], ["Vacaro", "Juliano", ""], ["Paz", "Gabriel", ""], ["Marques", "Guilherme", ""], ["Oliveira", "Bruna", ""]]}, {"id": "2005.03186", "submitter": "Isaac Ross", "authors": "I. M. Ross, R. J. Proulx, M. Karpenko", "title": "An Optimal Control Theory for the Traveling Salesman Problem and Its\n  Variants", "comments": "24 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.AI cs.DM cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that the traveling salesman problem (TSP) and its many variants may\nbe modeled as functional optimization problems over a graph. In this\nformulation, all vertices and arcs of the graph are functionals; i.e., a\nmapping from a space of measurable functions to the field of real numbers. Many\nvariants of the TSP, such as those with neighborhoods, with forbidden\nneighborhoods, with time-windows and with profits, can all be framed under this\nconstruct. In sharp contrast to their discrete-optimization counterparts, the\nmodeling constructs presented in this paper represent a fundamentally new\ndomain of analysis and computation for TSPs and their variants. Beyond its\napparent mathematical unification of a class of problems in graph theory, the\nmain advantage of the new approach is that it facilitates the modeling of\ncertain application-specific problems in their home space of measurable\nfunctions. Consequently, certain elements of economic system theory such as\ndynamical models and continuous-time cost/profit functionals can be directly\nincorporated in the new optimization problem formulation. Furthermore, subtour\nelimination constraints, prevalent in discrete optimization formulations, are\nnaturally enforced through continuity requirements. The price for the new\nmodeling framework is nonsmooth functionals. Although a number of theoretical\nissues remain open in the proposed mathematical framework, we demonstrate the\ncomputational viability of the new modeling constructs over a sample set of\nproblems to illustrate the rapid production of end-to-end TSP solutions to\nextensively-constrained practical problems.\n", "versions": [{"version": "v1", "created": "Thu, 7 May 2020 00:44:27 GMT"}], "update_date": "2020-05-08", "authors_parsed": [["Ross", "I. M.", ""], ["Proulx", "R. J.", ""], ["Karpenko", "M.", ""]]}, {"id": "2005.03230", "submitter": "Matin Hosseini", "authors": "Matin Hosseini, Anthony Maida", "title": "Hierarchical Predictive Coding Models in a Deep-Learning Framework", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian predictive coding is a putative neuromorphic method for acquiring\nhigher-level neural representations to account for sensory input. Although\noriginating in the neuroscience community, there are also efforts in the\nmachine learning community to study these models. This paper reviews some of\nthe more well known models. Our review analyzes module connectivity and\npatterns of information transfer, seeking to find general principles used\nacross the models. We also survey some recent attempts to cast these models\nwithin a deep learning framework. A defining feature of Bayesian predictive\ncoding is that it uses top-down, reconstructive mechanisms to predict incoming\nsensory inputs or their lower-level representations. Discrepancies between the\npredicted and the actual inputs, known as prediction errors, then give rise to\nfuture learning that refines and improves the predictive accuracy of learned\nhigher-level representations. Predictive coding models intended to describe\ncomputations in the neocortex emerged prior to the development of deep learning\nand used a communication structure between modules that we name the Rao-Ballard\nprotocol. This protocol was derived from a Bayesian generative model with some\nrather strong statistical assumptions. The RB protocol provides a rubric to\nassess the fidelity of deep learning models that claim to implement predictive\ncoding.\n", "versions": [{"version": "v1", "created": "Thu, 7 May 2020 03:39:57 GMT"}, {"version": "v2", "created": "Wed, 23 Sep 2020 00:42:39 GMT"}], "update_date": "2020-09-24", "authors_parsed": [["Hosseini", "Matin", ""], ["Maida", "Anthony", ""]]}, {"id": "2005.03233", "submitter": "Sebastian Risi", "authors": "Djordje Grbic and Sebastian Risi", "title": "Safe Reinforcement Learning through Meta-learned Instincts", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An important goal in reinforcement learning is to create agents that can\nquickly adapt to new goals while avoiding situations that might cause damage to\nthemselves or their environments. One way agents learn is through exploration\nmechanisms, which are needed to discover new policies. However, in deep\nreinforcement learning, exploration is normally done by injecting noise in the\naction space. While performing well in many domains, this setup has the\ninherent risk that the noisy actions performed by the agent lead to unsafe\nstates in the environment. Here we introduce a novel approach called\nMeta-Learned Instinctual Networks (MLIN) that allows agents to safely learn\nduring their lifetime while avoiding potentially hazardous states. At the core\nof the approach is a plastic network trained through reinforcement learning and\nan evolved \"instinctual\" network, which does not change during the agent's\nlifetime but can modulate the noisy output of the plastic network. We test our\nidea on a simple 2D navigation task with no-go zones, in which the agent has to\nlearn to approach new targets during deployment. MLIN outperforms standard\nmeta-trained networks and allows agents to learn to navigate to new targets\nwithout colliding with any of the no-go zones. These results suggest that\nmeta-learning augmented with an instinctual network is a promising new approach\nfor safe AI, which may enable progress in this area on a variety of different\ndomains.\n", "versions": [{"version": "v1", "created": "Wed, 6 May 2020 17:31:53 GMT"}], "update_date": "2020-05-08", "authors_parsed": [["Grbic", "Djordje", ""], ["Risi", "Sebastian", ""]]}, {"id": "2005.03299", "submitter": "Yan Cao", "authors": "Yan Cao, Keting Lu, Xiaoping Chen, Shiqi Zhang", "title": "Adaptive Dialog Policy Learning with Hindsight and User Modeling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning methods have been used to compute dialog policies from\nlanguage-based interaction experiences. Efficiency is of particular importance\nin dialog policy learning, because of the considerable cost of interacting with\npeople, and the very poor user experience from low-quality conversations.\nAiming at improving the efficiency of dialog policy learning, we develop\nalgorithm LHUA (Learning with Hindsight, User modeling, and Adaptation) that,\nfor the first time, enables dialog agents to adaptively learn with hindsight\nfrom both simulated and real users. Simulation and hindsight provide the dialog\nagent with more experience and more (positive) reinforcements respectively.\nExperimental results suggest that, in success rate and policy quality, LHUA\noutperforms competitive baselines from the literature, including its\nno-simulation, no-adaptation, and no-hindsight counterparts.\n", "versions": [{"version": "v1", "created": "Thu, 7 May 2020 07:43:43 GMT"}], "update_date": "2020-05-08", "authors_parsed": [["Cao", "Yan", ""], ["Lu", "Keting", ""], ["Chen", "Xiaoping", ""], ["Zhang", "Shiqi", ""]]}, {"id": "2005.03350", "submitter": "Lkhagvadorj Munkhdalai", "authors": "Lkhagvadorj Munkhdalai, Tsendsuren Munkhdalai and Keun Ho Ryu", "title": "A Locally Adaptive Interpretable Regression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Machine learning models with both good predictability and high\ninterpretability are crucial for decision support systems. Linear regression is\none of the most interpretable prediction models. However, the linearity in a\nsimple linear regression worsens its predictability. In this work, we introduce\na locally adaptive interpretable regression (LoAIR). In LoAIR, a metamodel\nparameterized by neural networks predicts percentile of a Gaussian distribution\nfor the regression coefficients for a rapid adaptation. Our experimental\nresults on public benchmark datasets show that our model not only achieves\ncomparable or better predictive performance than the other state-of-the-art\nbaselines but also discovers some interesting relationships between input and\ntarget variables such as a parabolic relationship between CO2 emissions and\nGross National Product (GNP). Therefore, LoAIR is a step towards bridging the\ngap between econometrics, statistics, and machine learning by improving the\npredictive ability of linear regression without depreciating its\ninterpretability.\n", "versions": [{"version": "v1", "created": "Thu, 7 May 2020 09:26:14 GMT"}, {"version": "v2", "created": "Thu, 14 May 2020 01:42:57 GMT"}], "update_date": "2020-05-15", "authors_parsed": [["Munkhdalai", "Lkhagvadorj", ""], ["Munkhdalai", "Tsendsuren", ""], ["Ryu", "Keun Ho", ""]]}, {"id": "2005.03356", "submitter": "Seongho Choi", "authors": "Seongho Choi, Kyoung-Woon On, Yu-Jung Heo, Ahjeong Seo, Youwon Jang,\n  Minsu Lee, Byoung-Tak Zhang", "title": "DramaQA: Character-Centered Video Story Understanding with Hierarchical\n  QA", "comments": "15 pages, 11 figures, accepted to AAAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite recent progress on computer vision and natural language processing,\ndeveloping a machine that can understand video story is still hard to achieve\ndue to the intrinsic difficulty of video story. Moreover, researches on how to\nevaluate the degree of video understanding based on human cognitive process\nhave not progressed as yet. In this paper, we propose a novel video question\nanswering (Video QA) task, DramaQA, for a comprehensive understanding of the\nvideo story. The DramaQA focuses on two perspectives: 1) Hierarchical QAs as an\nevaluation metric based on the cognitive developmental stages of human\nintelligence. 2) Character-centered video annotations to model local coherence\nof the story. Our dataset is built upon the TV drama \"Another Miss Oh\" and it\ncontains 17,983 QA pairs from 23,928 various length video clips, with each QA\npair belonging to one of four difficulty levels. We provide 217,308 annotated\nimages with rich character-centered annotations, including visual bounding\nboxes, behaviors and emotions of main characters, and coreference resolved\nscripts. Additionally, we suggest Multi-level Context Matching model which\nhierarchically understands character-centered representations of video to\nanswer questions. We release our dataset and model publicly for research\npurposes, and we expect our work to provide a new perspective on video story\nunderstanding research.\n", "versions": [{"version": "v1", "created": "Thu, 7 May 2020 09:44:58 GMT"}, {"version": "v2", "created": "Thu, 17 Dec 2020 02:59:37 GMT"}], "update_date": "2020-12-18", "authors_parsed": [["Choi", "Seongho", ""], ["On", "Kyoung-Woon", ""], ["Heo", "Yu-Jung", ""], ["Seo", "Ahjeong", ""], ["Jang", "Youwon", ""], ["Lee", "Minsu", ""], ["Zhang", "Byoung-Tak", ""]]}, {"id": "2005.03374", "submitter": "Anssi Kanervisto", "authors": "Anssi Kanervisto, Janne Karttunen, Ville Hautam\\\"aki", "title": "Playing Minecraft with Behavioural Cloning", "comments": "To appear in Post Proceedings of the Competitions & Demonstrations\n  Track @ NeurIPS2019. Source code available at\n  https://github.com/Miffyli/minecraft-bc", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  MineRL 2019 competition challenged participants to train sample-efficient\nagents to play Minecraft, by using a dataset of human gameplay and a limit\nnumber of steps the environment. We approached this task with behavioural\ncloning by predicting what actions human players would take, and reached fifth\nplace in the final ranking. Despite being a simple algorithm, we observed the\nperformance of such an approach can vary significantly, based on when the\ntraining is stopped. In this paper, we detail our submission to the\ncompetition, run further experiments to study how performance varied over\ntraining and study how different engineering decisions affected these results.\n", "versions": [{"version": "v1", "created": "Thu, 7 May 2020 10:48:51 GMT"}], "update_date": "2020-05-08", "authors_parsed": [["Kanervisto", "Anssi", ""], ["Karttunen", "Janne", ""], ["Hautam\u00e4ki", "Ville", ""]]}, {"id": "2005.03453", "submitter": "Ofer Strichman", "authors": "Tomer Cohen, Lior Finkelman, Gal Grimberg, Gadi Shenhar, Ofer\n  Strichman, Yonatan Strichman, Stav Yeger", "title": "A combination of 'pooling' with a prediction model can reduce by 73% the\n  number of COVID-19 (Corona-virus) tests", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that combining a prediction model (based on neural networks), with a\nnew method of test pooling (better than the original Dorfman method, and better\nthan double-pooling) called 'Grid', we can reduce the number of Covid-19 tests\nby 73%.\n", "versions": [{"version": "v1", "created": "Sun, 3 May 2020 17:33:10 GMT"}, {"version": "v2", "created": "Sat, 9 May 2020 18:16:01 GMT"}, {"version": "v3", "created": "Tue, 12 May 2020 11:48:46 GMT"}], "update_date": "2020-05-13", "authors_parsed": [["Cohen", "Tomer", ""], ["Finkelman", "Lior", ""], ["Grimberg", "Gal", ""], ["Shenhar", "Gadi", ""], ["Strichman", "Ofer", ""], ["Strichman", "Yonatan", ""], ["Yeger", "Stav", ""]]}, {"id": "2005.03461", "submitter": "Chi-Hua Chen", "authors": "Chi-Hua Chen", "title": "ExpDNN: Explainable Deep Neural Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, deep neural networks have been applied to obtain high\nperformance of prediction, classification, and pattern recognition. However,\nthe weights in these deep neural networks are difficult to be explained.\nAlthough a linear regression method can provide explainable results, the method\nis not suitable in the case of input interaction. Therefore, an explainable\ndeep neural network (ExpDNN) with explainable layers is proposed to obtain\nexplainable results in the case of input interaction. Three cases were given to\nevaluate the proposed ExpDNN, and the results showed that the absolute value of\nweight in an explainable layer can be used to explain the weight of\ncorresponding input for feature extraction.\n", "versions": [{"version": "v1", "created": "Sun, 26 Apr 2020 07:57:24 GMT"}], "update_date": "2020-05-08", "authors_parsed": [["Chen", "Chi-Hua", ""]]}, {"id": "2005.03474", "submitter": "Arpita Biswas", "authors": "Arpita Biswas, Suvam Mukherjee", "title": "Ensuring Fairness under Prior Probability Shifts", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study the problem of fair classification in the presence of\nprior probability shifts, where the training set distribution differs from the\ntest set. This phenomenon can be observed in the yearly records of several\nreal-world datasets, such as recidivism records and medical expenditure\nsurveys. If unaccounted for, such shifts can cause the predictions of a\nclassifier to become unfair towards specific population subgroups. While the\nfairness notion called Proportional Equality (PE) accounts for such shifts, a\nprocedure to ensure PE-fairness was unknown.\n  In this work, we propose a method, called CAPE, which provides a\ncomprehensive solution to the aforementioned problem. CAPE makes novel use of\nprevalence estimation techniques, sampling and an ensemble of classifiers to\nensure fair predictions under prior probability shifts. We introduce a metric,\ncalled prevalence difference (PD), which CAPE attempts to minimize in order to\nensure PE-fairness. We theoretically establish that this metric exhibits\nseveral desirable properties.\n  We evaluate the efficacy of CAPE via a thorough empirical evaluation on\nsynthetic datasets. We also compare the performance of CAPE with several\npopular fair classifiers on real-world datasets like COMPAS (criminal risk\nassessment) and MEPS (medical expenditure panel survey). The results indicate\nthat CAPE ensures PE-fair predictions, while performing well on other\nperformance metrics.\n", "versions": [{"version": "v1", "created": "Wed, 6 May 2020 13:07:05 GMT"}], "update_date": "2020-05-08", "authors_parsed": [["Biswas", "Arpita", ""], ["Mukherjee", "Suvam", ""]]}, {"id": "2005.03529", "submitter": "Shrestha Ghosh", "authors": "Shrestha Ghosh, Simon Razniewski, Gerhard Weikum", "title": "CounQER: A System for Discovering and Linking Count Information in\n  Knowledge Bases", "comments": "Accepted at ESWC 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Predicate constraints of general-purpose knowledge bases (KBs) like Wikidata,\nDBpedia and Freebase are often limited to subproperty, domain and range\nconstraints. In this demo we showcase CounQER, a system that illustrates the\nalignment of counting predicates, like staffSize, and enumerating predicates,\nlike workInstitution^{-1} . In the demonstration session, attendees can inspect\nthese alignments, and will learn about the importance of these alignments for\nKB question answering and curation. CounQER is available at\nhttps://counqer.mpi-inf.mpg.de/spo.\n", "versions": [{"version": "v1", "created": "Thu, 7 May 2020 14:53:11 GMT"}], "update_date": "2020-05-08", "authors_parsed": [["Ghosh", "Shrestha", ""], ["Razniewski", "Simon", ""], ["Weikum", "Gerhard", ""]]}, {"id": "2005.03597", "submitter": "Kai Jia", "authors": "Kai Jia, Martin Rinard", "title": "Efficient Exact Verification of Binarized Neural Networks", "comments": "To be published in NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CV cs.LG cs.LO cs.SC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Concerned with the reliability of neural networks, researchers have developed\nverification techniques to prove their robustness. Most verifiers work with\nreal-valued networks. Unfortunately, the exact (complete and sound) verifiers\nface scalability challenges and provide no correctness guarantees due to\nfloating point errors. We argue that Binarized Neural Networks (BNNs) provide\ncomparable robustness and allow exact and significantly more efficient\nverification. We present a new system, EEV, for efficient and exact\nverification of BNNs. EEV consists of two parts: (i) a novel SAT solver that\nspeeds up BNN verification by natively handling the reified cardinality\nconstraints arising in BNN encodings; and (ii) strategies to train\nsolver-friendly robust BNNs by inducing balanced layer-wise sparsity and low\ncardinality bounds, and adaptively cancelling the gradients. We demonstrate the\neffectiveness of EEV by presenting the first exact verification results for\nL-inf-bounded adversarial robustness of nontrivial convolutional BNNs on the\nMNIST and CIFAR10 datasets. Compared to exact verification of real-valued\nnetworks of the same architectures on the same tasks, EEV verifies BNNs\nhundreds to thousands of times faster, while delivering comparable verifiable\naccuracy in most cases.\n", "versions": [{"version": "v1", "created": "Thu, 7 May 2020 16:34:30 GMT"}, {"version": "v2", "created": "Tue, 27 Oct 2020 04:00:16 GMT"}], "update_date": "2020-10-28", "authors_parsed": [["Jia", "Kai", ""], ["Rinard", "Martin", ""]]}, {"id": "2005.03620", "submitter": "Marcos Cramer", "authors": "Marcos Cramer, Meghna Bhadra", "title": "Technical Report of \"Deductive Joint Support for Rational Unrestricted\n  Rebuttal\"", "comments": "New version with some minor corrections based on the reviews of the\n  associated paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  In ASPIC-style structured argumentation an argument can rebut another\nargument by attacking its conclusion. Two ways of formalizing rebuttal have\nbeen proposed: In restricted rebuttal, the attacked conclusion must have been\narrived at with a defeasible rule, whereas in unrestricted rebuttal, it may\nhave been arrived at with a strict rule, as long as at least one of the\nantecedents of this strict rule was already defeasible. One systematic way of\nchoosing between various possible definitions of a framework for structured\nargumentation is to study what rationality postulates are satisfied by which\ndefinition, for example whether the closure postulate holds, i.e. whether the\naccepted conclusions are closed under strict rules. While having some benefits,\nthe proposal to use unrestricted rebuttal faces the problem that the closure\npostulate only holds for the grounded semantics but fails when other\nargumentation semantics are applied, whereas with restricted rebuttal the\nclosure postulate always holds. In this paper we propose that ASPIC-style\nargumentation can benefit from keeping track not only of the attack relation\nbetween arguments, but also the relation of deductive joint support that holds\nbetween a set of arguments and an argument that was constructed from that set\nusing a strict rule. By taking this deductive joint support relation into\naccount while determining the extensions, the closure postulate holds with\nunrestricted rebuttal under all admissibility-based semantics. We define the\nsemantics of deductive joint support through the flattening method.\n", "versions": [{"version": "v1", "created": "Thu, 7 May 2020 17:19:18 GMT"}, {"version": "v2", "created": "Thu, 9 Jul 2020 17:18:26 GMT"}], "update_date": "2020-07-10", "authors_parsed": [["Cramer", "Marcos", ""], ["Bhadra", "Meghna", ""]]}, {"id": "2005.03632", "submitter": "Sreejita Ghosh", "authors": "Sreejita Ghosh, Peter Tino, Kerstin Bunte", "title": "Visualisation and knowledge discovery from interpretable models", "comments": "Accepted for proceedings of the International Joint Conference on\n  Neural Networks (IJCNN) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Increasing number of sectors which affect human lives, are using Machine\nLearning (ML) tools. Hence the need for understanding their working mechanism\nand evaluating their fairness in decision-making, are becoming paramount,\nushering in the era of Explainable AI (XAI). In this contribution we introduced\na few intrinsically interpretable models which are also capable of dealing with\nmissing values, in addition to extracting knowledge from the dataset and about\nthe problem. These models are also capable of visualisation of the classifier\nand decision boundaries: they are the angle based variants of Learning Vector\nQuantization. We have demonstrated the algorithms on a synthetic dataset and a\nreal-world one (heart disease dataset from the UCI repository). The newly\ndeveloped classifiers helped in investigating the complexities of the UCI\ndataset as a multiclass problem. The performance of the developed classifiers\nwere comparable to those reported in literature for this dataset, with\nadditional value of interpretability, when the dataset was treated as a binary\nclass problem.\n", "versions": [{"version": "v1", "created": "Thu, 7 May 2020 17:37:06 GMT"}, {"version": "v2", "created": "Fri, 8 May 2020 08:22:02 GMT"}], "update_date": "2020-05-11", "authors_parsed": [["Ghosh", "Sreejita", ""], ["Tino", "Peter", ""], ["Bunte", "Kerstin", ""]]}, {"id": "2005.03648", "submitter": "Ge Yang", "authors": "Ge Yang, Amy Zhang, Ari S. Morcos, Joelle Pineau, Pieter Abbeel,\n  Roberto Calandra", "title": "Plan2Vec: Unsupervised Representation Learning by Latent Plans", "comments": "code available at https://geyang.github.io/plan2vec", "journal-ref": "Proceedings of Machine Learning Research, the 2nd Annual\n  Conference on Learning for Dynamics and Control (2020) Volume 120, 1-12", "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we introduce plan2vec, an unsupervised representation learning\napproach that is inspired by reinforcement learning. Plan2vec constructs a\nweighted graph on an image dataset using near-neighbor distances, and then\nextrapolates this local metric to a global embedding by distilling\npath-integral over planned path. When applied to control, plan2vec offers a way\nto learn goal-conditioned value estimates that are accurate over long horizons\nthat is both compute and sample efficient. We demonstrate the effectiveness of\nplan2vec on one simulated and two challenging real-world image datasets.\nExperimental results show that plan2vec successfully amortizes the planning\ncost, enabling reactive planning that is linear in memory and computation\ncomplexity rather than exhaustive over the entire state space.\n", "versions": [{"version": "v1", "created": "Thu, 7 May 2020 17:52:23 GMT"}], "update_date": "2020-05-08", "authors_parsed": [["Yang", "Ge", ""], ["Zhang", "Amy", ""], ["Morcos", "Ari S.", ""], ["Pineau", "Joelle", ""], ["Abbeel", "Pieter", ""], ["Calandra", "Roberto", ""]]}, {"id": "2005.03742", "submitter": "Bert Wang-Chak Chan", "authors": "Bert Wang-Chak Chan", "title": "Lenia and Expanded Universe", "comments": "8 pages, 5 figures, 1 table; submitted to ALIFE 2020 conference", "journal-ref": "Artificial Life Conference Proceedings 2020, (32), 221-229", "doi": "10.1162/isal_a_00297", "report-no": null, "categories": "nlin.CG cs.AI nlin.PS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We report experimental extensions of Lenia, a continuous cellular automata\nfamily capable of producing lifelike self-organizing autonomous patterns. The\nrule of Lenia was generalized into higher dimensions, multiple kernels, and\nmultiple channels. The final architecture approaches what can be seen as a\nrecurrent convolutional neural network. Using semi-automatic search e.g.\ngenetic algorithm, we discovered new phenomena like polyhedral symmetries,\nindividuality, self-replication, emission, growth by ingestion, and saw the\nemergence of \"virtual eukaryotes\" that possess internal division of labor and\ntype differentiation. We discuss the results in the contexts of biology,\nartificial life, and artificial intelligence.\n", "versions": [{"version": "v1", "created": "Thu, 7 May 2020 20:41:13 GMT"}], "update_date": "2021-07-12", "authors_parsed": [["Chan", "Bert Wang-Chak", ""]]}, {"id": "2005.03789", "submitter": "Christoph Dann", "authors": "Christoph Dann, Yishay Mansour, Mehryar Mohri, Ayush Sekhari, Karthik\n  Sridharan", "title": "Reinforcement Learning with Feedback Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study episodic reinforcement learning in Markov decision processes when\nthe agent receives additional feedback per step in the form of several\ntransition observations. Such additional observations are available in a range\nof tasks through extended sensors or prior knowledge about the environment\n(e.g., when certain actions yield similar outcome). We formalize this setting\nusing a feedback graph over state-action pairs and show that model-based\nalgorithms can leverage the additional feedback for more sample-efficient\nlearning. We give a regret bound that, ignoring logarithmic factors and\nlower-order terms, depends only on the size of the maximum acyclic subgraph of\nthe feedback graph, in contrast with a polynomial dependency on the number of\nstates and actions in the absence of a feedback graph. Finally, we highlight\nchallenges when leveraging a small dominating set of the feedback graph as\ncompared to the bandit setting and propose a new algorithm that can use\nknowledge of such a dominating set for more sample-efficient learning of a\nnear-optimal policy.\n", "versions": [{"version": "v1", "created": "Thu, 7 May 2020 22:35:37 GMT"}], "update_date": "2020-05-11", "authors_parsed": [["Dann", "Christoph", ""], ["Mansour", "Yishay", ""], ["Mohri", "Mehryar", ""], ["Sekhari", "Ayush", ""], ["Sridharan", "Karthik", ""]]}, {"id": "2005.03818", "submitter": "Byungsoo Kim", "authors": "Youngduck Choi, Yoonho Na, Youngjik Yoon, Jonghun Shin, Chan Bae,\n  Hongseok Suh, Byungsoo Kim, Jaewe Heo", "title": "Choose Your Own Question: Encouraging Self-Personalization in Learning\n  Path Construction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning Path Recommendation is the heart of adaptive learning, the\neducational paradigm of an Interactive Educational System (IES) providing a\npersonalized learning experience based on the student's history of learning\nactivities. In typical existing IESs, the student must fully consume a\nrecommended learning item to be provided a new recommendation. This workflow\ncomes with several limitations. For example, there is no opportunity for the\nstudent to give feedback on the choice of learning items made by the IES.\nFurthermore, the mechanism by which the choice is made is opaque to the\nstudent, limiting the student's ability to track their learning. To this end,\nwe introduce Rocket, a Tinder-like User Interface for a general class of IESs.\nRocket provides a visual representation of Artificial Intelligence\n(AI)-extracted features of learning materials, allowing the student to quickly\ndecide whether the material meets their needs. The student can choose between\nengaging with the material and receiving a new recommendation by swiping or\ntapping. Rocket offers the following potential improvements for IES User\nInterfaces: First, Rocket enhances the explainability of IES recommendations by\nshowing students a visual summary of the meaningful AI-extracted features used\nin the decision-making process. Second, Rocket enables self-personalization of\nthe learning experience by leveraging the students' knowledge of their own\nabilities and needs. Finally, Rocket provides students with fine-grained\ninformation on their learning path, giving them an avenue to assess their own\nskills and track their learning progress. We present the source code of Rocket,\nin which we emphasize the independence and extensibility of each component, and\nmake it publicly available for all purposes.\n", "versions": [{"version": "v1", "created": "Fri, 8 May 2020 01:53:04 GMT"}], "update_date": "2020-05-11", "authors_parsed": [["Choi", "Youngduck", ""], ["Na", "Yoonho", ""], ["Yoon", "Youngjik", ""], ["Shin", "Jonghun", ""], ["Bae", "Chan", ""], ["Suh", "Hongseok", ""], ["Kim", "Byungsoo", ""], ["Heo", "Jaewe", ""]]}, {"id": "2005.03863", "submitter": "Jingke Wang", "authors": "Jingke Wang, Yue Wang, Dongkun Zhang, Yezhou Yang, Rong Xiong", "title": "Learning hierarchical behavior and motion planning for autonomous\n  driving", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning-based driving solution, a new branch for autonomous driving, is\nexpected to simplify the modeling of driving by learning the underlying\nmechanisms from data. To improve the tactical decision-making for\nlearning-based driving solution, we introduce hierarchical behavior and motion\nplanning (HBMP) to explicitly model the behavior in learning-based solution.\nDue to the coupled action space of behavior and motion, it is challenging to\nsolve HBMP problem using reinforcement learning (RL) for long-horizon driving\ntasks. We transform HBMP problem by integrating a classical sampling-based\nmotion planner, of which the optimal cost is regarded as the rewards for\nhigh-level behavior learning. As a result, this formulation reduces action\nspace and diversifies the rewards without losing the optimality of HBMP. In\naddition, we propose a sharable representation for input sensory data across\nsimulation platforms and real-world environment, so that models trained in a\nfast event-based simulator, SUMO, can be used to initialize and accelerate the\nRL training in a dynamics based simulator, CARLA. Experimental results\ndemonstrate the effectiveness of the method. Besides, the model is successfully\ntransferred to the real-world, validating the generalization capability.\n", "versions": [{"version": "v1", "created": "Fri, 8 May 2020 05:34:55 GMT"}], "update_date": "2020-05-11", "authors_parsed": [["Wang", "Jingke", ""], ["Wang", "Yue", ""], ["Zhang", "Dongkun", ""], ["Yang", "Yezhou", ""], ["Xiong", "Rong", ""]]}, {"id": "2005.03898", "submitter": "Lenz Belzner", "authors": "Lenz Belzner and Martin Wirsing", "title": "Synthesizing Safe Policies under Probabilistic Constraints with\n  Reinforcement Learning and Bayesian Model Checking", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.NE cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose to leverage epistemic uncertainty about constraint satisfaction of\na reinforcement learner in safety critical domains. We introduce a framework\nfor specification of requirements for reinforcement learners in constrained\nsettings, including confidence about results. We show that an agent's\nconfidence in constraint satisfaction provides a useful signal for balancing\noptimization and safety in the learning process.\n", "versions": [{"version": "v1", "created": "Fri, 8 May 2020 08:11:31 GMT"}, {"version": "v2", "created": "Sat, 6 Feb 2021 10:13:36 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["Belzner", "Lenz", ""], ["Wirsing", "Martin", ""]]}, {"id": "2005.03947", "submitter": "Bao Trung Nguyen", "authors": "Trung B. Nguyen, Will N. Browne, Mengjie Zhang", "title": "Relatedness Measures to Aid the Transfer of Building Blocks among\n  Multiple Tasks", "comments": "accepted by The Genetic and Evolutionary Computation Conference\n  (GECCO 2020)", "journal-ref": null, "doi": "10.1145/3377930.3390169", "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multitask Learning is a learning paradigm that deals with multiple different\ntasks in parallel and transfers knowledge among them. XOF, a Learning\nClassifier System using tree-based programs to encode building blocks\n(meta-features), constructs and collects features with rich discriminative\ninformation for classification tasks in an observed list. This paper seeks to\nfacilitate the automation of feature transferring in between tasks by utilising\nthe observed list. We hypothesise that the best discriminative features of a\nclassification task carry its characteristics. Therefore, the relatedness\nbetween any two tasks can be estimated by comparing their most appropriate\npatterns. We propose a multiple-XOF system, called mXOF, that can dynamically\nadapt feature transfer among XOFs. This system utilises the observed list to\nestimate the task relatedness. This method enables the automation of\ntransferring features. In terms of knowledge discovery, the resemblance\nestimation provides insightful relations among multiple data. We experimented\nmXOF on various scenarios, e.g. representative Hierarchical Boolean problems,\nclassification of distinct classes in the UCI Zoo dataset, and unrelated tasks,\nto validate its abilities of automatic knowledge-transfer and estimating task\nrelatedness. Results show that mXOF can estimate the relatedness reasonably\nbetween multiple tasks to aid the learning performance with the dynamic feature\ntransferring.\n", "versions": [{"version": "v1", "created": "Fri, 8 May 2020 10:26:59 GMT"}, {"version": "v2", "created": "Sun, 17 May 2020 14:20:48 GMT"}], "update_date": "2020-09-14", "authors_parsed": [["Nguyen", "Trung B.", ""], ["Browne", "Will N.", ""], ["Zhang", "Mengjie", ""]]}, {"id": "2005.03954", "submitter": "Zheng-Yu Niu", "authors": "Zeming Liu, Haifeng Wang, Zheng-Yu Niu, Hua Wu, Wanxiang Che, Ting Liu", "title": "Towards Conversational Recommendation over Multi-Type Dialogs", "comments": "Accepted by ACL 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new task of conversational recommendation over multi-type\ndialogs, where the bots can proactively and naturally lead a conversation from\na non-recommendation dialog (e.g., QA) to a recommendation dialog, taking into\naccount user's interests and feedback. To facilitate the study of this task, we\ncreate a human-to-human Chinese dialog dataset \\emph{DuRecDial} (about 10k\ndialogs, 156k utterances), which contains multiple sequential dialogs for every\npair of a recommendation seeker (user) and a recommender (bot). In each dialog,\nthe recommender proactively leads a multi-type dialog to approach\nrecommendation targets and then makes multiple recommendations with rich\ninteraction behavior. This dataset allows us to systematically investigate\ndifferent parts of the overall problem, e.g., how to naturally lead a dialog,\nhow to interact with users for recommendation. Finally we establish baseline\nresults on DuRecDial for future studies. Dataset and codes are publicly\navailable at\nhttps://github.com/PaddlePaddle/models/tree/develop/PaddleNLP/Research/ACL2020-DuRecDial.\n", "versions": [{"version": "v1", "created": "Fri, 8 May 2020 11:01:21 GMT"}, {"version": "v2", "created": "Fri, 15 May 2020 03:06:47 GMT"}, {"version": "v3", "created": "Fri, 22 May 2020 08:54:45 GMT"}], "update_date": "2020-05-25", "authors_parsed": [["Liu", "Zeming", ""], ["Wang", "Haifeng", ""], ["Niu", "Zheng-Yu", ""], ["Wu", "Hua", ""], ["Che", "Wanxiang", ""], ["Liu", "Ting", ""]]}, {"id": "2005.03977", "submitter": "Ha-Vu Tran", "authors": "Ha-Vu Tran, Georges Kaddoum, Hany Elgala, Chadi Abou-Rjeily and Hemani\n  Kaushal", "title": "Lightwave Power Transfer for Federated Learning-based Wireless Networks", "comments": "Accepted for publication in IEEE Communications Letters", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.AI cs.IT cs.SY eess.SY math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated Learning (FL) has been recently presented as a new technique for\ntraining shared machine learning models in a distributed manner while\nrespecting data privacy. However, implementing FL in wireless networks may\nsignificantly reduce the lifetime of energy-constrained mobile devices due to\ntheir involvement in the construction of the shared learning models. To handle\nthis issue, we propose a novel approach at the physical layer based on the\napplication of lightwave power transfer in the FL-based wireless network and a\nresource allocation scheme to manage the network's power efficiency. Hence, we\nformulate the corresponding optimization problem and then propose a method to\nobtain the optimal solution. Numerical results reveal that, the proposed scheme\ncan provide sufficient energy to a mobile device for performing FL tasks\nwithout using any power from its own battery. Hence, the proposed approach can\nsupport the FL-based wireless network to overcome the issue of limited energy\nin mobile devices.\n", "versions": [{"version": "v1", "created": "Sat, 11 Apr 2020 16:27:17 GMT"}], "update_date": "2020-05-11", "authors_parsed": [["Tran", "Ha-Vu", ""], ["Kaddoum", "Georges", ""], ["Elgala", "Hany", ""], ["Abou-Rjeily", "Chadi", ""], ["Kaushal", "Hemani", ""]]}, {"id": "2005.04016", "submitter": "Abderrahmane Maaradji", "authors": "Abderrahmane Maaradji, Marlon Dumas, Marcello La Rosa, and Alireza\n  Ostovar", "title": "Detecting sudden and gradual drifts in business processes from execution\n  traces", "comments": null, "journal-ref": "IEEE Transactions on Knowledge and Data Engineering 29, no. 10\n  (2017)", "doi": "10.1109/TKDE.2017.2720601", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Business processes are prone to unexpected changes, as process workers may\nsuddenly or gradually start executing a process differently in order to adjust\nto changes in workload, season, or other external factors. Early detection of\nbusiness process changes enables managers to identify and act upon changes that\nmay otherwise affect process performance. Business process drift detection\nrefers to a family of methods to detect changes in a business process by\nanalyzing event logs extracted from the systems that support the execution of\nthe process. Existing methods for business process drift detection are based on\nan explorative analysis of a potentially large feature space and in some cases\nthey require users to manually identify specific features that characterize the\ndrift. Depending on the explored feature space, these methods miss various\ntypes of changes. Moreover, they are either designed to detect sudden drifts or\ngradual drifts but not both. This paper proposes an automated and statistically\ngrounded method for detecting sudden and gradual business process drifts under\na unified framework. An empirical evaluation shows that the method detects\ntypical change patterns with significantly higher accuracy and lower detection\ndelay than existing methods, while accurately distinguishing between sudden and\ngradual drifts.\n", "versions": [{"version": "v1", "created": "Thu, 7 May 2020 16:22:11 GMT"}], "update_date": "2020-05-11", "authors_parsed": [["Maaradji", "Abderrahmane", ""], ["Dumas", "Marlon", ""], ["La Rosa", "Marcello", ""], ["Ostovar", "Alireza", ""]]}, {"id": "2005.04022", "submitter": "Jan-Hendrik Lorenz", "authors": "Jan-Hendrik Lorenz and Florian W\\\"orz", "title": "On the Effect of Learned Clauses on Stochastic Local Search", "comments": "Accepted at 'The 23rd International Conference on Theory and\n  Applications of Satisfiability Testing'", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There are two competing paradigms in successful SAT solvers: Conflict-driven\nclause learning (CDCL) and stochastic local search (SLS). CDCL uses systematic\nexploration of the search space and has the ability to learn new clauses. SLS\nexamines the neighborhood of the current complete assignment. Unlike CDCL, it\nlacks the ability to learn from its mistakes. This work revolves around the\nquestion whether it is beneficial for SLS to add new clauses to the original\nformula. We experimentally demonstrate that clauses with a large number of\ncorrect literals w. r. t. a fixed solution are beneficial to the runtime of\nSLS. We call such clauses high-quality clauses.\n  Empirical evaluations show that short clauses learned by CDCL possess the\nhigh-quality attribute. We study several domains of randomly generated\ninstances and deduce the most beneficial strategies to add high-quality clauses\nas a preprocessing step. The strategies are implemented in an SLS solver, and\nit is shown that this considerably improves the state-of-the-art on randomly\ngenerated instances. The results are statistically significant.\n", "versions": [{"version": "v1", "created": "Thu, 7 May 2020 13:33:16 GMT"}], "update_date": "2020-05-11", "authors_parsed": [["Lorenz", "Jan-Hendrik", ""], ["W\u00f6rz", "Florian", ""]]}, {"id": "2005.04067", "submitter": "Nils Wilde", "authors": "Nils Wilde, Dana Kulic, and Stephen L. Smith", "title": "Active Preference Learning using Maximum Regret", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study active preference learning as a framework for intuitively specifying\nthe behaviour of autonomous robots. In active preference learning, a user\nchooses the preferred behaviour from a set of alternatives, from which the\nrobot learns the user's preferences, modeled as a parameterized cost function.\nPrevious approaches present users with alternatives that minimize the\nuncertainty over the parameters of the cost function. However, different\nparameters might lead to the same optimal behaviour; as a consequence the\nsolution space is more structured than the parameter space. We exploit this by\nproposing a query selection that greedily reduces the maximum error ratio over\nthe solution space. In simulations we demonstrate that the proposed approach\noutperforms other state of the art techniques in both learning efficiency and\nease of queries for the user. Finally, we show that evaluating the learning\nbased on the similarities of solutions instead of the similarities of weights\nallows for better predictions for different scenarios.\n", "versions": [{"version": "v1", "created": "Fri, 8 May 2020 14:31:31 GMT"}, {"version": "v2", "created": "Mon, 28 Sep 2020 19:27:27 GMT"}], "update_date": "2020-09-30", "authors_parsed": [["Wilde", "Nils", ""], ["Kulic", "Dana", ""], ["Smith", "Stephen L.", ""]]}, {"id": "2005.04095", "submitter": "Thanh Pham Dinh", "authors": "Pham Dinh Thanh, Huynh Thi Thanh Binh, Do Dinh Dac, Nguyen Binh Long,\n  Le Minh Hai Phong", "title": "A Heuristic Based on Randomized Greedy Algorithms for the Clustered\n  Shortest-Path Tree Problem", "comments": null, "journal-ref": null, "doi": "10.1109/CEC.2019.8790070", "report-no": null, "categories": "cs.DC cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Randomized Greedy Algorithms (RGAs) are interesting approaches to solve\nproblems whose structures are not well understood as well as problems in\ncombinatorial optimization which incorporate the random processes and the\ngreedy algorithms. This paper introduces a new algorithm that combines the\nmajor features of RGAs and Shortest Path Tree Algorithm (SPTA) to deal with the\nClustered Shortest-Path Tree Problem (CluSPT). In our algorithm, SPTA is used\nto determine the shortest path tree in each cluster while the combination\nbetween characteristics of the RGAs and search strategy of SPTA is used to\nconstructed the edges connecting clusters. To evaluate the performance of the\nproposed algorithm, Euclidean benchmarks are selected. The experimental\ninvestigations show the strengths of the proposed algorithm in comparison with\nsome existing algorithms. We also analyze the influence of the parameters on\nthe performance of the algorithm.\n", "versions": [{"version": "v1", "created": "Tue, 5 May 2020 08:34:58 GMT"}], "update_date": "2020-05-11", "authors_parsed": [["Thanh", "Pham Dinh", ""], ["Binh", "Huynh Thi Thanh", ""], ["Dac", "Do Dinh", ""], ["Long", "Nguyen Binh", ""], ["Phong", "Le Minh Hai", ""]]}, {"id": "2005.04108", "submitter": "Subhadip Basu", "authors": "Sovan Saha, Anup Kumar Halder, Soumyendu Sekhar Bandyopadhyay, Piyali\n  Chatterjee, Mita Nasipuri and Subhadip Basu", "title": "Computational modeling of Human-nCoV protein-protein interaction network", "comments": "Total number of pages is 12. Total number of figures is 7. Total\n  number of tables is 1", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.MN cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  COVID-19 has created a global pandemic with high morbidity and mortality in\n2020. Novel coronavirus (nCoV), also known as Severe Acute Respiratory Syndrome\nCoronavirus 2 (SARS-CoV2), is responsible for this deadly disease.\nInternational Committee on Taxonomy of Viruses (ICTV) has declared that nCoV is\nhighly genetically similar to SARS-CoV epidemic in 2003 (89% similarity).\nLimited number of clinically validated Human-nCoV protein interaction data is\navailable in the literature. With this hypothesis, the present work focuses on\ndeveloping a computational model for nCoV-Human protein interaction network,\nusing the experimentally validated SARS-CoV-Human protein interactions.\nInitially, level-1 and level-2 human spreader proteins are identified in\nSARS-CoV-Human interaction network, using Susceptible-Infected-Susceptible\n(SIS) model. These proteins are considered as potential human targets for nCoV\nbait proteins. A gene-ontology based fuzzy affinity function has been used to\nconstruct the nCoV-Human protein interaction network at 99.98% specificity\nthreshold. This also identifies the level-1 human spreaders for COVID-19 in\nhuman protein-interaction network. Level-2 human spreaders are subsequently\nidentified using the SIS model. The derived host-pathogen interaction network\nis finally validated using 7 potential FDA listed drugs for COVID-19 with\nsignificant overlap between the known drug target proteins and the identified\nspreader proteins.\n", "versions": [{"version": "v1", "created": "Tue, 5 May 2020 04:16:21 GMT"}], "update_date": "2020-05-11", "authors_parsed": [["Saha", "Sovan", ""], ["Halder", "Anup Kumar", ""], ["Bandyopadhyay", "Soumyendu Sekhar", ""], ["Chatterjee", "Piyali", ""], ["Nasipuri", "Mita", ""], ["Basu", "Subhadip", ""]]}, {"id": "2005.04120", "submitter": "Cheul Young Park", "authors": "Cheul Young Park, Narae Cha, Soowon Kang, Auk Kim, Ahsan Habib\n  Khandoker, Leontios Hadjileontiadis, Alice Oh, Yong Jeong, Uichin Lee", "title": "K-EmoCon, a multimodal sensor dataset for continuous emotion recognition\n  in naturalistic conversations", "comments": "20 pages, 4 figures, for associated dataset, see\n  https://doi.org/10.5281/zenodo.3814370", "journal-ref": "Sci Data 7, (2020) 293", "doi": "10.1038/s41597-020-00630-y", "report-no": null, "categories": "cs.HC cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recognizing emotions during social interactions has many potential\napplications with the popularization of low-cost mobile sensors, but a\nchallenge remains with the lack of naturalistic affective interaction data.\nMost existing emotion datasets do not support studying idiosyncratic emotions\narising in the wild as they were collected in constrained environments.\nTherefore, studying emotions in the context of social interactions requires a\nnovel dataset, and K-EmoCon is such a multimodal dataset with comprehensive\nannotations of continuous emotions during naturalistic conversations. The\ndataset contains multimodal measurements, including audiovisual recordings,\nEEG, and peripheral physiological signals, acquired with off-the-shelf devices\nfrom 16 sessions of approximately 10-minute long paired debates on a social\nissue. Distinct from previous datasets, it includes emotion annotations from\nall three available perspectives: self, debate partner, and external observers.\nRaters annotated emotional displays at intervals of every 5 seconds while\nviewing the debate footage, in terms of arousal-valence and 18 additional\ncategorical emotions. The resulting K-EmoCon is the first publicly available\nemotion dataset accommodating the multiperspective assessment of emotions\nduring social interactions.\n", "versions": [{"version": "v1", "created": "Fri, 8 May 2020 15:51:12 GMT"}, {"version": "v2", "created": "Tue, 19 May 2020 08:25:29 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Park", "Cheul Young", ""], ["Cha", "Narae", ""], ["Kang", "Soowon", ""], ["Kim", "Auk", ""], ["Khandoker", "Ahsan Habib", ""], ["Hadjileontiadis", "Leontios", ""], ["Oh", "Alice", ""], ["Jeong", "Yong", ""], ["Lee", "Uichin", ""]]}, {"id": "2005.04123", "submitter": "Paolo Liberatore", "authors": "Paolo Liberatore", "title": "The ghosts of forgotten things: A study on size after forgetting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI cs.CC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Forgetting is removing variables from a logical formula while preserving the\nconstraints on the other variables. In spite of being a form of reduction, it\ndoes not always decrease the size of the formula and may sometimes increase it.\nThis article discusses the implications of such an increase and analyzes the\ncomputational properties of the phenomenon. Given a propositional Horn formula,\na set of variables and a maximum allowed size, deciding whether forgetting the\nvariables from the formula can be expressed in that size is $D^p$-hard in\n$\\Sigma^p_2$. The same problem for unrestricted propositional formulae is\n$D^p_2$-hard in $\\Sigma^p_3$. The hardness results employ superredundancy: a\nsuperirredundant clause is in all formulae of minimal size equivalent to a\ngiven one. This concept may be useful outside forgetting.\n", "versions": [{"version": "v1", "created": "Fri, 8 May 2020 15:56:01 GMT"}, {"version": "v2", "created": "Wed, 10 Mar 2021 07:39:00 GMT"}], "update_date": "2021-03-11", "authors_parsed": [["Liberatore", "Paolo", ""]]}, {"id": "2005.04151", "submitter": "Tapas Si", "authors": "Tapas Si", "title": "Swarm Programming Using Moth-Flame Optimization and Whale Optimization\n  Algorithms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Automatic programming (AP) is an important area of Machine Learning (ML)\nwhere computer programs are generated automatically. Swarm Programming (SP), a\nnewly emerging research area in AP, automatically generates the computer\nprograms using Swarm Intelligence (SI) algorithms. This paper presents two\ngrammar-based SP methods named as Grammatical Moth-Flame Optimizer (GMFO) and\nGrammatical Whale Optimizer (GWO). The Moth-Flame Optimizer and Whale\nOptimization algorithm are used as search engines or learning algorithms in\nGMFO and GWO respectively. The proposed methods are tested on Santa Fe Ant\nTrail, quartic symbolic regression, and 3-input multiplexer problems. The\nresults are compared with Grammatical Bee Colony (GBC) and Grammatical\nFireworks algorithm (GFWA). The experimental results demonstrate that the\nproposed SP methods can be used in automatic computer program generation.\n", "versions": [{"version": "v1", "created": "Sat, 25 Apr 2020 08:15:37 GMT"}], "update_date": "2020-05-11", "authors_parsed": [["Si", "Tapas", ""]]}, {"id": "2005.04157", "submitter": "Ivars Dzalbs Mr", "authors": "Ivars Dzalbs, Tatiana Kalganova", "title": "Hybrid 2-stage Imperialist Competitive Algorithm with Ant Colony\n  Optimization for Solving Multi-Depot Vehicle Routing Problem", "comments": "PPSN2020 Submission", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Multi-Depot Vehicle Routing Problem (MDVRP) is a real-world model of the\nsimplistic Vehicle Routing Problem (VRP) that considers how to satisfy multiple\ncustomer demands from numerous depots. This paper introduces a hybrid 2-stage\napproach based on two population-based algorithms - Ant Colony Optimization\n(ACO) that mimics ant behaviour in nature and the Imperialist Competitive\nAlgorithm (ICA) that is based on geopolitical relationships between countries.\nIn the proposed hybrid algorithm, ICA is responsible for customer assignment to\nthe depots while ACO is routing and sequencing the customers. The algorithm is\ncompared to non-hybrid ACO and ICA as well as four other state-of-the-art\nmethods across 23 common Cordreaus benchmark instances. Results show clear\nimprovement over simple ACO and ICA and demonstrate very competitive results\nwhen compared to other rival algorithms.\n", "versions": [{"version": "v1", "created": "Tue, 7 Apr 2020 17:43:06 GMT"}], "update_date": "2020-05-11", "authors_parsed": [["Dzalbs", "Ivars", ""], ["Kalganova", "Tatiana", ""]]}, {"id": "2005.04166", "submitter": "Gongjin Lan", "authors": "Gongjin Lan, Jakub M. Tomczak, Diederik M. Roijers, A.E. Eiben", "title": "Time Efficiency in Optimization with a Bayesian-Evolutionary Algorithm", "comments": "13 pages, 10 Figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Not all generate-and-test search algorithms are created equal. Bayesian\nOptimization (BO) invests a lot of computation time to generate the candidate\nsolution that best balances the predicted value and the uncertainty given all\nprevious data, taking increasingly more time as the number of evaluations\nperformed grows. Evolutionary Algorithms (EA) on the other hand rely on search\nheuristics that typically do not depend on all previous data and can be done in\nconstant time. Both the BO and EA community typically assess their performance\nas a function of the number of evaluations. However, this is unfair once we\nstart to compare the efficiency of these classes of algorithms, as the overhead\ntimes to generate candidate solutions are significantly different. We suggest\nto measure the efficiency of generate-and-test search algorithms as the\nexpected gain in the objective value per unit of computation time spent. We\nobserve that the preference of an algorithm to be used can change after a\nnumber of function evaluations. We therefore propose a new algorithm, a\ncombination of Bayesian optimization and an Evolutionary Algorithm, BEA for\nshort, that starts with BO, then transfers knowledge to an EA, and subsequently\nruns the EA. We compare the BEA with BO and the EA. The results show that BEA\noutperforms both BO and the EA in terms of time efficiency, and ultimately\nleads to better performance on well-known benchmark objective functions with\nmany local optima. Moreover, we test the three algorithms on nine test cases of\nrobot learning problems and here again we find that BEA outperforms the other\nalgorithms.\n", "versions": [{"version": "v1", "created": "Mon, 4 May 2020 15:29:22 GMT"}], "update_date": "2020-05-11", "authors_parsed": [["Lan", "Gongjin", ""], ["Tomczak", "Jakub M.", ""], ["Roijers", "Diederik M.", ""], ["Eiben", "A. E.", ""]]}, {"id": "2005.04209", "submitter": "Ramy Mounir", "authors": "Ramy Mounir, Redwan Alqasemi, Rajiv Dubey", "title": "BCI-Controlled Hands-Free Wheelchair Navigation with Obstacle Avoidance", "comments": "Accepted by IROS 2018 workshop on \"Haptic-enabled shared control of\n  robotic systems: a compromise between teleoperation and autonomy\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Brain-Computer interfaces (BCI) are widely used in reading brain signals and\nconverting them into real-world motion. However, the signals produced from the\nBCI are noisy and hard to analyze. This paper looks specifically towards\ncombining the BCI's latest technology with ultrasonic sensors to provide a\nhands-free wheelchair that can efficiently navigate through crowded\nenvironments. This combination provides safety and obstacle avoidance features\nnecessary for the BCI Navigation system to gain more confidence and operate the\nwheelchair at a relatively higher velocity. A population of six human subjects\ntested the BCI-controller and obstacle avoidance features. Subjects were able\nto mentally control the destination of the wheelchair, by moving the target\nfrom the starting position to a predefined position, in an average of 287.12\nseconds and a standard deviation of 48.63 seconds after 10 minutes of training.\nThe wheelchair successfully avoided all obstacles placed by the subjects during\nthe test.\n", "versions": [{"version": "v1", "created": "Fri, 8 May 2020 17:56:11 GMT"}], "update_date": "2020-05-11", "authors_parsed": [["Mounir", "Ramy", ""], ["Alqasemi", "Redwan", ""], ["Dubey", "Rajiv", ""]]}, {"id": "2005.04269", "submitter": "Pavel Shvechikov", "authors": "Arsenii Kuznetsov, Pavel Shvechikov, Alexander Grishin, Dmitry Vetrov", "title": "Controlling Overestimation Bias with Truncated Mixture of Continuous\n  Distributional Quantile Critics", "comments": "Under review by the International Conference on Machine Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The overestimation bias is one of the major impediments to accurate\noff-policy learning. This paper investigates a novel way to alleviate the\noverestimation bias in a continuous control setting. Our method---Truncated\nQuantile Critics, TQC,---blends three ideas: distributional representation of a\ncritic, truncation of critics prediction, and ensembling of multiple critics.\nDistributional representation and truncation allow for arbitrary granular\noverestimation control, while ensembling provides additional score\nimprovements. TQC outperforms the current state of the art on all environments\nfrom the continuous control benchmark suite, demonstrating 25% improvement on\nthe most challenging Humanoid environment.\n", "versions": [{"version": "v1", "created": "Fri, 8 May 2020 19:52:26 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["Kuznetsov", "Arsenii", ""], ["Shvechikov", "Pavel", ""], ["Grishin", "Alexander", ""], ["Vetrov", "Dmitry", ""]]}, {"id": "2005.04306", "submitter": "Peter Clark", "authors": "Peter Clark, John Thompson, Bruce Porter", "title": "Knowledge Patterns", "comments": "Published in the Handbook of Ontologies, 2004, pp 191-207. (This is\n  an updated and extended version of the paper by the same name in Proc.\n  KR'2000)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes a new technique, called \"knowledge patterns\", for\nhelping construct axiom-rich, formal ontologies, based on identifying and\nexplicitly representing recurring patterns of knowledge (theory schemata) in\nthe ontology, and then stating how those patterns map onto domain-specific\nconcepts in the ontology. From a modeling perspective, knowledge patterns\nprovide an important insight into the structure of a formal ontology: rather\nthan viewing a formal ontology simply as a list of terms and axioms, knowledge\npatterns views it as a collection of abstract, modular theories (the \"knowledge\npatterns\") plus a collection of modeling decisions stating how different\naspects of the world can be modeled using those theories. Knowledge patterns\nmake both those abstract theories and their mappings to the domain of interest\nexplicit, thus making modeling decisions clear, and avoiding some of the\nontological confusion that can otherwise arise. In addition, from a\ncomputational perspective, knowledge patterns provide a simple and\ncomputationally efficient mechanism for facilitating knowledge reuse. We\ndescribe the technique and an application built using them, and then critique\nits strengths and weaknesses. We conclude that this technique enables us to\nbetter explicate both the structure and modeling decisions made when\nconstructing a formal axiom-rich ontology.\n", "versions": [{"version": "v1", "created": "Fri, 8 May 2020 22:33:30 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["Clark", "Peter", ""], ["Thompson", "John", ""], ["Porter", "Bruce", ""]]}, {"id": "2005.04318", "submitter": "Andrew Lampinen", "authors": "Andrew K. Lampinen and James L. McClelland", "title": "Transforming task representations to perform novel tasks", "comments": "45 pages", "journal-ref": "PNAS December 29, 2020 117 (52) 32970-32981;", "doi": "10.1073/pnas.2008852117", "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An important aspect of intelligence is the ability to adapt to a novel task\nwithout any direct experience (zero-shot), based on its relationship to\nprevious tasks. Humans can exhibit this cognitive flexibility. By contrast,\nmodels that achieve superhuman performance in specific tasks often fail to\nadapt to even slight task alterations. To address this, we propose a general\ncomputational framework for adapting to novel tasks based on their relationship\nto prior tasks. We begin by learning vector representations of tasks. To adapt\nto new tasks, we propose meta-mappings, higher-order tasks that transform basic\ntask representations. We demonstrate the effectiveness of this framework across\na wide variety of tasks and computational paradigms, ranging from regression to\nimage classification and reinforcement learning. We compare to both human\nadaptability and language-based approaches to zero-shot learning. Across these\ndomains, meta-mapping is successful, often achieving 80-90% performance,\nwithout any data, on a novel task, even when the new task directly contradicts\nprior experience. We further show that meta-mapping can not only generalize to\nnew tasks via learned relationships, but can also generalize using novel\nrelationships unseen during training. Finally, using meta-mapping as a starting\npoint can dramatically accelerate later learning on a new task, and reduce\nlearning time and cumulative error substantially. Our results provide insight\ninto a possible computational basis of intelligent adaptability and offer a\npossible framework for modeling cognitive flexibility and building more\nflexible artificial intelligence systems.\n", "versions": [{"version": "v1", "created": "Fri, 8 May 2020 23:41:57 GMT"}, {"version": "v2", "created": "Thu, 1 Oct 2020 22:26:39 GMT"}, {"version": "v3", "created": "Tue, 6 Oct 2020 18:35:56 GMT"}], "update_date": "2021-03-17", "authors_parsed": [["Lampinen", "Andrew K.", ""], ["McClelland", "James L.", ""]]}, {"id": "2005.04364", "submitter": "Samson Tan", "authors": "Samson Tan, Shafiq Joty, Min-Yen Kan, Richard Socher", "title": "It's Morphin' Time! Combating Linguistic Discrimination with\n  Inflectional Perturbations", "comments": "To appear in the Proceedings of the 58th Annual Meeting of the\n  Association for Computational Linguistics (ACL 2020)", "journal-ref": null, "doi": "10.18653/v1/2020.acl-main.263", "report-no": null, "categories": "cs.CL cs.AI cs.CY cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Training on only perfect Standard English corpora predisposes pre-trained\nneural networks to discriminate against minorities from non-standard linguistic\nbackgrounds (e.g., African American Vernacular English, Colloquial Singapore\nEnglish, etc.). We perturb the inflectional morphology of words to craft\nplausible and semantically similar adversarial examples that expose these\nbiases in popular NLP models, e.g., BERT and Transformer, and show that\nadversarially fine-tuning them for a single epoch significantly improves\nrobustness without sacrificing performance on clean data.\n", "versions": [{"version": "v1", "created": "Sat, 9 May 2020 04:01:43 GMT"}], "update_date": "2021-05-10", "authors_parsed": [["Tan", "Samson", ""], ["Joty", "Shafiq", ""], ["Kan", "Min-Yen", ""], ["Socher", "Richard", ""]]}, {"id": "2005.04369", "submitter": "Di Zhuang", "authors": "Di Zhuang and J. Morris Chang", "title": "Utility-aware Privacy-preserving Data Releasing", "comments": "9 pages, 2 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the big data era, more and more cloud-based data-driven applications are\ndeveloped that leverage individual data to provide certain valuable services\n(the utilities). On the other hand, since the same set of individual data could\nbe utilized to infer the individual's certain sensitive information, it creates\nnew channels to snoop the individual's privacy. Hence it is of great importance\nto develop techniques that enable the data owners to release privatized data,\nthat can still be utilized for certain premised intended purpose. Existing data\nreleasing approaches, however, are either privacy-emphasized (no consideration\non utility) or utility-driven (no guarantees on privacy). In this work, we\npropose a two-step perturbation-based utility-aware privacy-preserving data\nreleasing framework. First, certain predefined privacy and utility problems are\nlearned from the public domain data (background knowledge). Later, our approach\nleverages the learned knowledge to precisely perturb the data owners' data into\nprivatized data that can be successfully utilized for certain intended purpose\n(learning to succeed), without jeopardizing certain predefined privacy\n(training to fail). Extensive experiments have been conducted on Human Activity\nRecognition, Census Income and Bank Marketing datasets to demonstrate the\neffectiveness and practicality of our framework.\n", "versions": [{"version": "v1", "created": "Sat, 9 May 2020 05:32:46 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["Zhuang", "Di", ""], ["Chang", "J. Morris", ""]]}, {"id": "2005.04374", "submitter": "Yashwanth Kumar Nakka", "authors": "Yashwanth Kumar Nakka, Anqi Liu, Guanya Shi, Anima Anandkumar, Yisong\n  Yue, and Soon-Jo Chung", "title": "Chance-Constrained Trajectory Optimization for Safe Exploration and\n  Learning of Nonlinear Systems", "comments": "Accepted IEEE Robotics and Automation Letters 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.SY eess.SY math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning-based control algorithms require data collection with abundant\nsupervision for training. Safe exploration algorithms ensure the safety of this\ndata collection process even when only partial knowledge is available. We\npresent a new approach for optimal motion planning with safe exploration that\nintegrates chance-constrained stochastic optimal control with dynamics learning\nand feedback control. We derive an iterative convex optimization algorithm that\nsolves an \\underline{Info}rmation-cost \\underline{S}tochastic\n\\underline{N}onlinear \\underline{O}ptimal \\underline{C}ontrol problem\n(Info-SNOC). The optimization objective encodes control cost for performance\nand exploration cost for learning, and the safety is incorporated as\ndistributionally robust chance constraints. The dynamics are predicted from a\nrobust regression model that is learned from data. The Info-SNOC algorithm is\nused to compute a sub-optimal pool of safe motion plans that aid in exploration\nfor learning unknown residual dynamics under safety constraints. A stable\nfeedback controller is used to execute the motion plan and collect data for\nmodel learning. We prove the safety of rollout from our exploration method and\nreduction in uncertainty over epochs, thereby guaranteeing the consistency of\nour learning method. We validate the effectiveness of Info-SNOC by designing\nand implementing a pool of safe trajectories for a planar robot. We demonstrate\nthat our approach has higher success rate in ensuring safety when compared to a\ndeterministic trajectory optimization approach.\n", "versions": [{"version": "v1", "created": "Sat, 9 May 2020 05:57:43 GMT"}, {"version": "v2", "created": "Wed, 2 Sep 2020 01:56:50 GMT"}, {"version": "v3", "created": "Tue, 27 Oct 2020 19:46:23 GMT"}], "update_date": "2020-10-29", "authors_parsed": [["Nakka", "Yashwanth Kumar", ""], ["Liu", "Anqi", ""], ["Shi", "Guanya", ""], ["Anandkumar", "Anima", ""], ["Yue", "Yisong", ""], ["Chung", "Soon-Jo", ""]]}, {"id": "2005.04379", "submitter": "Xinting Huang", "authors": "Xinting Huang, Jianzhong Qi, Yu Sun, Rui Zhang", "title": "Semi-Supervised Dialogue Policy Learning via Stochastic Reward\n  Estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dialogue policy optimization often obtains feedback until task completion in\ntask-oriented dialogue systems. This is insufficient for training intermediate\ndialogue turns since supervision signals (or rewards) are only provided at the\nend of dialogues. To address this issue, reward learning has been introduced to\nlearn from state-action pairs of an optimal policy to provide turn-by-turn\nrewards. This approach requires complete state-action annotations of\nhuman-to-human dialogues (i.e., expert demonstrations), which is labor\nintensive. To overcome this limitation, we propose a novel reward learning\napproach for semi-supervised policy learning. The proposed approach learns a\ndynamics model as the reward function which models dialogue progress (i.e.,\nstate-action sequences) based on expert demonstrations, either with or without\nannotations. The dynamics model computes rewards by predicting whether the\ndialogue progress is consistent with expert demonstrations. We further propose\nto learn action embeddings for a better generalization of the reward function.\nThe proposed approach outperforms competitive policy learning baselines on\nMultiWOZ, a benchmark multi-domain dataset.\n", "versions": [{"version": "v1", "created": "Sat, 9 May 2020 06:28:44 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["Huang", "Xinting", ""], ["Qi", "Jianzhong", ""], ["Sun", "Yu", ""], ["Zhang", "Rui", ""]]}, {"id": "2005.04397", "submitter": "Jiannan Zhao", "authors": "Jiannan Zhao, Hongxin Wang, and Shigang Yue", "title": "Enhancing LGMD's Looming Selectivity for UAV with Spatial-temporal\n  Distributed Presynaptic Connections", "comments": "15 pages, 17 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CV cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Collision detection is one of the most challenging tasks for Unmanned Aerial\nVehicles (UAVs). This is especially true for small or micro UAVs, due to their\nlimited computational power. In nature, flying insects with compact and simple\nvisual systems demonstrate their remarkable ability to navigate and avoid\ncollision in complex environments. A good example of this is provided by\nlocusts. They can avoid collisions in a dense swarm through the activity of a\nmotion based visual neuron called the Lobula Giant Movement Detector (LGMD).\nThe defining feature of the LGMD neuron is its preference for looming. As a\nflying insect's visual neuron, LGMD is considered to be an ideal basis for\nbuilding UAV's collision detecting system. However, existing LGMD models cannot\ndistinguish looming clearly from other visual cues such as complex background\nmovements caused by UAV agile flights. To address this issue, we proposed a new\nmodel implementing distributed spatial-temporal synaptic interactions, which is\ninspired by recent findings in locusts' synaptic morphology. We first\nintroduced the locally distributed excitation to enhance the excitation caused\nby visual motion with preferred velocities. Then radially extending temporal\nlatency for inhibition is incorporated to compete with the distributed\nexcitation and selectively suppress the non-preferred visual motions.\nSystematic experiments have been conducted to verify the performance of the\nproposed model for UAV agile flights. The results have demonstrated that this\nnew model enhances the looming selectivity in complex flying scenes\nconsiderably, and has potential to be implemented on embedded collision\ndetection systems for small or micro UAVs.\n", "versions": [{"version": "v1", "created": "Sat, 9 May 2020 09:15:02 GMT"}, {"version": "v2", "created": "Tue, 19 May 2020 02:55:02 GMT"}, {"version": "v3", "created": "Sat, 17 Apr 2021 04:38:13 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Zhao", "Jiannan", ""], ["Wang", "Hongxin", ""], ["Yue", "Shigang", ""]]}, {"id": "2005.04466", "submitter": "Romain Wallon", "authors": "Daniel Le Berre, Pierre Marquis, Romain Wallon", "title": "On Weakening Strategies for PB Solvers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current pseudo-Boolean solvers implement different variants of the cutting\nplanes proof system to infer new constraints during conflict analysis. One of\nthese variants is generalized resolution, which allows to infer strong\nconstraints, but suffers from the growth of coefficients it generates while\ncombining pseudo-Boolean constraints. Another variant consists in using\nweakening and division, which is more efficient in practice but may infer\nweaker constraints. In both cases, weakening is mandatory to derive conflicting\nconstraints. However, its impact on the performance of pseudo-Boolean solvers\nhas not been assessed so far. In this paper, new application strategies for\nthis rule are studied, aiming to infer strong constraints with small\ncoefficients. We implemented them in Sat4j and observed that each of them\nimproves the runtime of the solver. While none of them performs better than the\nothers on all benchmarks, applying weakening on the conflict side has\nsurprising good performance, whereas applying partial weakening and division on\nboth the conflict and the reason sides provides the best results overall.\n", "versions": [{"version": "v1", "created": "Sat, 9 May 2020 15:40:55 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["Berre", "Daniel Le", ""], ["Marquis", "Pierre", ""], ["Wallon", "Romain", ""]]}, {"id": "2005.04536", "submitter": "Alexis Asseman", "authors": "Alexis Asseman, Nicolas Antoine and Ahmet S. Ozcan", "title": "Accelerating Deep Neuroevolution on Distributed FPGAs for Reinforcement\n  Learning Problems", "comments": "12 pages. Submitted to ACM Journal on Emerging Technologies in\n  Computing Systems: Special Issue on Hardware and Algorithms for Efficient\n  Machine Learning", "journal-ref": null, "doi": "10.1145/3425500", "report-no": null, "categories": "cs.NE cs.AI cs.AR cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning augmented by the representational power of deep neural\nnetworks, has shown promising results on high-dimensional problems, such as\ngame playing and robotic control. However, the sequential nature of these\nproblems poses a fundamental challenge for computational efficiency. Recently,\nalternative approaches such as evolutionary strategies and deep neuroevolution\ndemonstrated competitive results with faster training time on distributed CPU\ncores. Here, we report record training times (running at about 1 million frames\nper second) for Atari 2600 games using deep neuroevolution implemented on\ndistributed FPGAs. Combined hardware implementation of the game console, image\npre-processing and the neural network in an optimized pipeline, multiplied with\nthe system level parallelism enabled the acceleration. These results are the\nfirst application demonstration on the IBM Neural Computer, which is a custom\ndesigned system that consists of 432 Xilinx FPGAs interconnected in a 3D mesh\nnetwork topology. In addition to high performance, experiments also showed\nimprovement in accuracy for all games compared to the CPU-implementation of the\nsame algorithm.\n", "versions": [{"version": "v1", "created": "Sun, 10 May 2020 00:41:39 GMT"}], "update_date": "2021-05-10", "authors_parsed": [["Asseman", "Alexis", ""], ["Antoine", "Nicolas", ""], ["Ozcan", "Ahmet S.", ""]]}, {"id": "2005.04543", "submitter": "Yang Liu", "authors": "Yang Liu, Michael Gordon, Juntao Wang, Michael Bishop, Yiling Chen,\n  Thomas Pfeiffer, Charles Twardy and Domenico Viganola", "title": "Replication Markets: Results, Lessons, Challenges and Opportunities in\n  AI Replication", "comments": "Appeared at AAAI workshop on Reproducible AI (RAI), 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The last decade saw the emergence of systematic large-scale replication\nprojects in the social and behavioral sciences, (Camerer et al., 2016, 2018;\nEbersole et al., 2016; Klein et al., 2014, 2018; Collaboration, 2015). These\nprojects were driven by theoretical and conceptual concerns about a high\nfraction of \"false positives\" in the scientific publications (Ioannidis, 2005)\n(and a high prevalence of \"questionable research practices\" (Simmons, Nelson,\nand Simonsohn, 2011). Concerns about the credibility of research findings are\nnot unique to the behavioral and social sciences; within Computer Science,\nArtificial Intelligence (AI) and Machine Learning (ML) are areas of particular\nconcern (Lucic et al., 2018; Freire, Bonnet, and Shasha, 2012; Gundersen and\nKjensmo, 2018; Henderson et al., 2018). Given the pioneering role of the\nbehavioral and social sciences in the promotion of novel methodologies to\nimprove the credibility of research, it is a promising approach to analyze the\nlessons learned from this field and adjust strategies for Computer Science, AI\nand ML In this paper, we review approaches used in the behavioral and social\nsciences and in the DARPA SCORE project. We particularly focus on the role of\nhuman forecasting of replication outcomes, and how forecasting can leverage the\ninformation gained from relatively labor and resource-intensive replications.\nWe will discuss opportunities and challenges of using these approaches to\nmonitor and improve the credibility of research areas in Computer Science, AI,\nand ML.\n", "versions": [{"version": "v1", "created": "Sun, 10 May 2020 01:41:56 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["Liu", "Yang", ""], ["Gordon", "Michael", ""], ["Wang", "Juntao", ""], ["Bishop", "Michael", ""], ["Chen", "Yiling", ""], ["Pfeiffer", "Thomas", ""], ["Twardy", "Charles", ""], ["Viganola", "Domenico", ""]]}, {"id": "2005.04544", "submitter": "Baihan Lin", "authors": "Baihan Lin, Guillermo Cecchi, Djallel Bouneffouf, Jenna Reinen, Irina\n  Rish", "title": "An Empirical Study of Human Behavioral Agents in Bandits, Contextual\n  Bandits and Reinforcement Learning", "comments": "This article supersedes and extends our work arXiv:1706.02897 (MAB)\n  and arXiv:1906.11286 (RL) into the Contextual Bandit (CB) framework. It\n  generalized extensively into multi-armed bandits, contextual bandits and RL\n  settings to create a unified framework of human behavioral agents", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Artificial behavioral agents are often evaluated based on their consistent\nbehaviors and performance to take sequential actions in an environment to\nmaximize some notion of cumulative reward. However, human decision making in\nreal life usually involves different strategies and behavioral trajectories\nthat lead to the same empirical outcome. Motivated by clinical literature of a\nwide range of neurological and psychiatric disorders, we propose here a more\ngeneral and flexible parametric framework for sequential decision making that\ninvolves a two-stream reward processing mechanism. We demonstrated that this\nframework is flexible and unified enough to incorporate a family of problems\nspanning multi-armed bandits (MAB), contextual bandits (CB) and reinforcement\nlearning (RL), which decompose the sequential decision making process in\ndifferent levels. Inspired by the known reward processing abnormalities of many\nmental disorders, our clinically-inspired agents demonstrated interesting\nbehavioral trajectories and comparable performance on simulated tasks with\nparticular reward distributions, a real-world dataset capturing human\ndecision-making in gambling tasks, and the PacMan game across different reward\nstationarities in a lifelong learning setting.\n", "versions": [{"version": "v1", "created": "Sun, 10 May 2020 01:43:39 GMT"}, {"version": "v2", "created": "Tue, 12 May 2020 01:55:54 GMT"}, {"version": "v3", "created": "Thu, 10 Sep 2020 10:14:12 GMT"}, {"version": "v4", "created": "Mon, 14 Sep 2020 15:23:22 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Lin", "Baihan", ""], ["Cecchi", "Guillermo", ""], ["Bouneffouf", "Djallel", ""], ["Reinen", "Jenna", ""], ["Rish", "Irina", ""]]}, {"id": "2005.04560", "submitter": "Xiang Lisa Li", "authors": "Xiang Lisa Li and Alexander M. Rush", "title": "Posterior Control of Blackbox Generation", "comments": "Accepted for publication at ACL 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Text generation often requires high-precision output that obeys task-specific\nrules. This fine-grained control is difficult to enforce with off-the-shelf\ndeep learning models. In this work, we consider augmenting neural generation\nmodels with discrete control states learned through a structured\nlatent-variable approach. Under this formulation, task-specific knowledge can\nbe encoded through a range of rich, posterior constraints that are effectively\ntrained into the model. This approach allows users to ground internal model\ndecisions based on prior knowledge, without sacrificing the representational\npower of neural generative models. Experiments consider applications of this\napproach for text generation. We find that this method improves over standard\nbenchmarks, while also providing fine-grained control.\n", "versions": [{"version": "v1", "created": "Sun, 10 May 2020 03:22:45 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["Li", "Xiang Lisa", ""], ["Rush", "Alexander M.", ""]]}, {"id": "2005.04570", "submitter": "Abhijit Pathak", "authors": "Abhijit Pathak and Abrar Hossain Tasin", "title": "Belief Rule Based Expert System to Identify the Crime Zones", "comments": "6 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.RO cs.SY eess.SY", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  This paper focuses on Crime zone Identification. Then, it clarifies how we\nconducted the Belief Rule Base algorithm to produce interesting frequent\npatterns for crime hotspots. The paper also shows how we used an expert system\nto forecast potential types of crime. In order to further analyze the crime\ndatasets, the paper introduces an analysis study by combining our findings of\nthe Chittagong crime dataset with demographic information to capture factors\nthat could affect neighborhood safety. The results of this solution could be\nused to raise awareness of the dangerous locations and to help agencies predict\nfuture crimes at a specific location in a given time.\n", "versions": [{"version": "v1", "created": "Sun, 10 May 2020 04:07:38 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["Pathak", "Abhijit", ""], ["Tasin", "Abrar Hossain", ""]]}, {"id": "2005.04589", "submitter": "Benjamin Goertzel", "authors": "Ben Goertzel", "title": "Maximal Algorithmic Caliber and Algorithmic Causal Network Inference:\n  General Principles of Real-World General Intelligence?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ideas and formalisms from far-from-equilibrium thermodynamics are ported to\nthe context of stochastic computational processes, via following and extending\nTadaki's algorithmic thermodynamics. A Principle of Maximum Algorithmic Caliber\nis proposed, providing guidance as to what computational processes one should\nhypothesize if one is provided constraints to work within. It is conjectured\nthat, under suitable assumptions, computational processes obeying algorithmic\nMarkov conditions will maximize algorithmic caliber. It is proposed that in\naccordance with this, real-world cognitive systems may operate in substantial\npart by modeling their environments and choosing their actions to be\n(approximate and compactly represented) algorithmic Markov networks. These\nideas are suggested as potential early steps toward a general theory of the\noperation of pragmatic generally intelligent systems.\n", "versions": [{"version": "v1", "created": "Sun, 10 May 2020 06:14:59 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["Goertzel", "Ben", ""]]}, {"id": "2005.04599", "submitter": "Ritam Guha Mr.", "authors": "Devroop Kar, Manosij Ghosh, Ritam Guha, Ram Sarkar, Laura\n  Garc\\'ia-Hern\\'andez, Ajith Abraham", "title": "Fuzzy Mutation Embedded Hybrids of Gravitational Search and Particle\n  Swarm Optimization Methods for Engineering Design Problems", "comments": "33 pages, 18 figures, submitted to Engineering Applications of\n  Artificial Intelligence, Elsevier", "journal-ref": null, "doi": "10.1016/j.engappai.2020.103847", "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gravitational Search Algorithm (GSA) and Particle Swarm Optimization (PSO)\nare nature-inspired, swarm-based optimization algorithms respectively. Though\nthey have been widely used for single-objective optimization since their\ninception, they suffer from premature convergence. Even though the hybrids of\nGSA and PSO perform much better, the problem remains. Hence, to solve this\nissue we have proposed a fuzzy mutation model for two hybrid versions of PSO\nand GSA - Gravitational Particle Swarm (GPS) and PSOGSA. The developed\nalgorithms are called Mutation based GPS (MGPS) and Mutation based PSOGSA\n(MPSOGSA). The mutation operator is based on a fuzzy model where the\nprobability of mutation has been calculated based on the closeness of particle\nto population centroid and improvement in the particle value. We have evaluated\nthese two new algorithms on 23 benchmark functions of three categories\n(unimodal, multi-modal and multi-modal with fixed dimension). The experimental\noutcome shows that our proposed model outperforms their corresponding\nancestors, MGPS outperforms GPS 13 out of 23 times (56.52%) and MPSOGSA\noutperforms PSOGSA 17 times out of 23 (73.91 %). We have also compared our\nresults against those of recent optimization algorithms such as Sine Cosine\nAlgorithm (SCA), Opposition-Based SCA, and Volleyball Premier League Algorithm\n(VPL). In addition, we have applied our proposed algorithms on some classic\nengineering design problems and the outcomes are satisfactory. The related\ncodes of the proposed algorithms can be found in this link:\nFuzzy-Mutation-Embedded-Hybrids-of-GSA-and-PSO.\n", "versions": [{"version": "v1", "created": "Sun, 10 May 2020 07:42:36 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Kar", "Devroop", ""], ["Ghosh", "Manosij", ""], ["Guha", "Ritam", ""], ["Sarkar", "Ram", ""], ["Garc\u00eda-Hern\u00e1ndez", "Laura", ""], ["Abraham", "Ajith", ""]]}, {"id": "2005.04625", "submitter": "Wang Zhu", "authors": "Wang Zhu, Hexiang Hu, Jiacheng Chen, Zhiwei Deng, Vihan Jain, Eugene\n  Ie, Fei Sha", "title": "BabyWalk: Going Farther in Vision-and-Language Navigation by Taking Baby\n  Steps", "comments": "Accepted by ACL 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.CV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Learning to follow instructions is of fundamental importance to autonomous\nagents for vision-and-language navigation (VLN). In this paper, we study how an\nagent can navigate long paths when learning from a corpus that consists of\nshorter ones. We show that existing state-of-the-art agents do not generalize\nwell. To this end, we propose BabyWalk, a new VLN agent that is learned to\nnavigate by decomposing long instructions into shorter ones (BabySteps) and\ncompleting them sequentially. A special design memory buffer is used by the\nagent to turn its past experiences into contexts for future steps. The learning\nprocess is composed of two phases. In the first phase, the agent uses imitation\nlearning from demonstration to accomplish BabySteps. In the second phase, the\nagent uses curriculum-based reinforcement learning to maximize rewards on\nnavigation tasks with increasingly longer instructions. We create two new\nbenchmark datasets (of long navigation tasks) and use them in conjunction with\nexisting ones to examine BabyWalk's generalization ability. Empirical results\nshow that BabyWalk achieves state-of-the-art results on several metrics, in\nparticular, is able to follow long instructions better. The codes and the\ndatasets are released on our project page https://github.com/Sha-Lab/babywalk.\n", "versions": [{"version": "v1", "created": "Sun, 10 May 2020 10:46:41 GMT"}, {"version": "v2", "created": "Sun, 14 Jun 2020 22:02:05 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["Zhu", "Wang", ""], ["Hu", "Hexiang", ""], ["Chen", "Jiacheng", ""], ["Deng", "Zhiwei", ""], ["Jain", "Vihan", ""], ["Ie", "Eugene", ""], ["Sha", "Fei", ""]]}, {"id": "2005.04726", "submitter": "Shreyansh Bhatt", "authors": "Shreyansh Bhatt, Amit Sheth, Valerie Shalin, Jinjin Zhao", "title": "Knowledge Graph semantic enhancement of input data for improving AI", "comments": null, "journal-ref": "IEEE Internet Computing, 24(2), 66-72 (2020)", "doi": "10.1109/MIC.2020.2979620", "report-no": null, "categories": "cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Intelligent systems designed using machine learning algorithms require a\nlarge number of labeled data. Background knowledge provides complementary, real\nworld factual information that can augment the limited labeled data to train a\nmachine learning algorithm. The term Knowledge Graph (KG) is in vogue as for\nmany practical applications, it is convenient and useful to organize this\nbackground knowledge in the form of a graph. Recent academic research and\nimplemented industrial intelligent systems have shown promising performance for\nmachine learning algorithms that combine training data with a knowledge graph.\nIn this article, we discuss the use of relevant KGs to enhance input data for\ntwo applications that use machine learning -- recommendation and community\ndetection. The KG improves both accuracy and explainability.\n", "versions": [{"version": "v1", "created": "Sun, 10 May 2020 17:37:38 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["Bhatt", "Shreyansh", ""], ["Sheth", "Amit", ""], ["Shalin", "Valerie", ""], ["Zhao", "Jinjin", ""]]}, {"id": "2005.04729", "submitter": "Hykel Hosni", "authors": "Hykel Hosni and Angelo Vulpiani", "title": "Random thoughts about Complexity, Data and Models", "comments": "arXiv admin note: substantial text overlap with arXiv:1709.07062", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI math.DS nlin.CD physics.hist-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data Science and Machine learning have been growing strong for the past\ndecade. We argue that to make the most of this exciting field we should resist\nthe temptation of assuming that forecasting can be reduced to brute-force data\nanalytics. This owes to the fact that modelling, as we illustrate below,\nrequires mastering the art of selecting relevant variables. More specifically,\nwe investigate the subtle relation between \"data and models\" by focussing on\nthe role played by algorithmic complexity, which contributed to making\nmathematically rigorous the long-standing idea that to understand empirical\nphenomena is to describe the rules which generate the data in terms which are\n\"simpler\" than the data itself.\n  A key issue for the appraisal of the relation between algorithmic complexity\nand algorithmic learning is to do with a much needed clarification on the\nrelated but distinct concepts of compressibility, determinism and\npredictability. To this end we will illustrate that the evolution law of a\nchaotic system is compressibile, but a generic initial condition for it is not,\nmaking the time series generated by chaotic systems incompressible in general.\nHence knowledge of the rules which govern an empirical phenomenon are not\nsufficient for predicting its outcomes. In turn this implies that there is more\nto understanding phenomena than learning -- even from data alone -- such rules.\nThis can be achieved only in those cases when we are capable of \"good\nmodelling\".\n  Clearly, the very idea of algorithmic complexity rests on Turing's seminal\nanalysis of computation. This motivates our remarks on this extremely telling\nexample of analogy-based abstract modelling which is nonetheless heavily\ninformed by empirical facts.\n", "versions": [{"version": "v1", "created": "Thu, 16 Apr 2020 14:27:22 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["Hosni", "Hykel", ""], ["Vulpiani", "Angelo", ""]]}, {"id": "2005.04735", "submitter": "Dan Shiebler", "authors": "Dan Shiebler", "title": "Categorical Stochastic Processes and Likelihood", "comments": null, "journal-ref": "Compositionality 3, 1 (2021)", "doi": "10.32408/compositionality-3-1", "report-no": null, "categories": "cs.AI math.CT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we take a Category Theoretic perspective on the relationship\nbetween probabilistic modeling and function approximation. We begin by defining\ntwo extensions of function composition to stochastic process subordination: one\nbased on the co-Kleisli category under the comonad (Omega x -) and one based on\nthe parameterization of a category with a Lawvere theory. We show how these\nextensions relate to the category Stoch and other Markov Categories. Next, we\napply the Para construction to extend stochastic processes to parameterized\nstatistical models and we define a way to compose the likelihood functions of\nthese models. We conclude with a demonstration of how the Maximum Likelihood\nEstimation procedure defines an identity-on-objects functor from the category\nof statistical models to the category of Learners. Code to accompany this paper\ncan be found at\nhttps://github.com/dshieble/Categorical_Stochastic_Processes_and_Likelihood\n", "versions": [{"version": "v1", "created": "Sun, 10 May 2020 18:00:56 GMT"}, {"version": "v2", "created": "Thu, 3 Sep 2020 03:43:39 GMT"}, {"version": "v3", "created": "Tue, 2 Mar 2021 06:10:23 GMT"}, {"version": "v4", "created": "Thu, 8 Apr 2021 20:56:59 GMT"}], "update_date": "2021-04-12", "authors_parsed": [["Shiebler", "Dan", ""]]}, {"id": "2005.04790", "submitter": "Douwe Kiela", "authors": "Douwe Kiela, Hamed Firooz, Aravind Mohan, Vedanuj Goswami, Amanpreet\n  Singh, Pratik Ringshia, Davide Testuggine", "title": "The Hateful Memes Challenge: Detecting Hate Speech in Multimodal Memes", "comments": "NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work proposes a new challenge set for multimodal classification,\nfocusing on detecting hate speech in multimodal memes. It is constructed such\nthat unimodal models struggle and only multimodal models can succeed: difficult\nexamples (\"benign confounders\") are added to the dataset to make it hard to\nrely on unimodal signals. The task requires subtle reasoning, yet is\nstraightforward to evaluate as a binary classification problem. We provide\nbaseline performance numbers for unimodal models, as well as for multimodal\nmodels with various degrees of sophistication. We find that state-of-the-art\nmethods perform poorly compared to humans (64.73% vs. 84.7% accuracy),\nillustrating the difficulty of the task and highlighting the challenge that\nthis important problem poses to the community.\n", "versions": [{"version": "v1", "created": "Sun, 10 May 2020 21:31:00 GMT"}, {"version": "v2", "created": "Mon, 8 Jun 2020 18:01:54 GMT"}, {"version": "v3", "created": "Wed, 7 Apr 2021 18:43:54 GMT"}], "update_date": "2021-04-09", "authors_parsed": [["Kiela", "Douwe", ""], ["Firooz", "Hamed", ""], ["Mohan", "Aravind", ""], ["Goswami", "Vedanuj", ""], ["Singh", "Amanpreet", ""], ["Ringshia", "Pratik", ""], ["Testuggine", "Davide", ""]]}, {"id": "2005.04855", "submitter": "Toby Walsh", "authors": "Toby Walsh", "title": "Fair Division: The Computer Scientist's Perspective", "comments": "To appear in Proceedings of IJCAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.GT cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  I survey recent progress on a classic and challenging problem in social\nchoice: the fair division of indivisible items. I discuss how a computational\nperspective has provided interesting insights into and understanding of how to\ndivide items fairly and efficiently. This has involved bringing to bear tools\nsuch as those used in knowledge representation, computational complexity,\napproximation methods, game theory, online analysis and communication\ncomplexity\n", "versions": [{"version": "v1", "created": "Mon, 11 May 2020 04:19:38 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["Walsh", "Toby", ""]]}, {"id": "2005.04912", "submitter": "Yash Satsangi", "authors": "Yash Satsangi, Sungsu Lim, Shimon Whiteson, Frans Oliehoek, Martha\n  White", "title": "Maximizing Information Gain in Partially Observable Environments via\n  Prediction Reward", "comments": null, "journal-ref": "AAMAS 2020", "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Information gathering in a partially observable environment can be formulated\nas a reinforcement learning (RL), problem where the reward depends on the\nagent's uncertainty. For example, the reward can be the negative entropy of the\nagent's belief over an unknown (or hidden) variable. Typically, the rewards of\nan RL agent are defined as a function of the state-action pairs and not as a\nfunction of the belief of the agent; this hinders the direct application of\ndeep RL methods for such tasks. This paper tackles the challenge of using\nbelief-based rewards for a deep RL agent, by offering a simple insight that\nmaximizing any convex function of the belief of the agent can be approximated\nby instead maximizing a prediction reward: a reward based on prediction\naccuracy. In particular, we derive the exact error between negative entropy and\nthe expected prediction reward. This insight provides theoretical motivation\nfor several fields using prediction rewards---namely visual attention, question\nanswering systems, and intrinsic motivation---and highlights their connection\nto the usually distinct fields of active perception, active sensing, and sensor\nplacement. Based on this insight we present deep anticipatory networks (DANs),\nwhich enables an agent to take actions to reduce its uncertainty without\nperforming explicit belief inference. We present two applications of DANs:\nbuilding a sensor selection system for tracking people in a shopping mall and\nlearning discrete models of attention on fashion MNIST and MNIST digit\nclassification.\n", "versions": [{"version": "v1", "created": "Mon, 11 May 2020 08:13:49 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["Satsangi", "Yash", ""], ["Lim", "Sungsu", ""], ["Whiteson", "Shimon", ""], ["Oliehoek", "Frans", ""], ["White", "Martha", ""]]}, {"id": "2005.04949", "submitter": "Evgeni Aizenberg", "authors": "Evgeni Aizenberg and Jeroen van den Hoven", "title": "Designing for Human Rights in AI", "comments": "30 pages, 2 figures, pre-print of the paper accepted for publication\n  in the journal Big Data & Society", "journal-ref": "Big Data & Society 7(2) (2020)", "doi": "10.1177/2053951720949566", "report-no": null, "categories": "cs.CY cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the age of big data, companies and governments are increasingly using\nalgorithms to inform hiring decisions, employee management, policing, credit\nscoring, insurance pricing, and many more aspects of our lives. AI systems can\nhelp us make evidence-driven, efficient decisions, but can also confront us\nwith unjustified, discriminatory decisions wrongly assumed to be accurate\nbecause they are made automatically and quantitatively. It is becoming evident\nthat these technological developments are consequential to people's fundamental\nhuman rights. Despite increasing attention to these urgent challenges in recent\nyears, technical solutions to these complex socio-ethical problems are often\ndeveloped without empirical study of societal context and the critical input of\nsocietal stakeholders who are impacted by the technology. On the other hand,\ncalls for more ethically- and socially-aware AI often fail to provide answers\nfor how to proceed beyond stressing the importance of transparency,\nexplainability, and fairness. Bridging these socio-technical gaps and the deep\ndivide between abstract value language and design requirements is essential to\nfacilitate nuanced, context-dependent design choices that will support moral\nand social values. In this paper, we bridge this divide through the framework\nof Design for Values, drawing on methodologies of Value Sensitive Design and\nParticipatory Design to present a roadmap for proactively engaging societal\nstakeholders to translate fundamental human rights into context-dependent\ndesign requirements through a structured, inclusive, and transparent process.\n", "versions": [{"version": "v1", "created": "Mon, 11 May 2020 09:21:10 GMT"}, {"version": "v2", "created": "Mon, 6 Jul 2020 17:00:46 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Aizenberg", "Evgeni", ""], ["Hoven", "Jeroen van den", ""]]}, {"id": "2005.04954", "submitter": "Tatsuya Hayashi", "authors": "Tatsuya Hayashi and Atsuyoshi Nakamura", "title": "Propagation Graph Estimation by Pairwise Alignment of Time Series\n  Observation Sequences", "comments": "7 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Various things propagate through the medium of individuals. Some biological\ncells fire right after the firing of their neighbor cells, and such firing\npropagates from cells to cells. In this paper, we study the problem of\nestimating the firing propagation order of cells from the $\\{0,1 \\}$-state\nsequences of all the cells, where '1' at the $i$-th position means the firing\nstate of the cell at time step $i$. We propose a method to estimate the\npropagation direction between cells by the sum of one cell's time delay of the\nmatched positions from the other cell averaged over the minimum cost alignments\nand show how to calculate it efficiently. The propagation order estimated by\nour proposed method is demonstrated to be correct for our synthetic datasets,\nand also to be consistent with visually recognizable firing order for the\ndataset of soil-dwelling amoeba's chemical signal emitting state sequences.\n", "versions": [{"version": "v1", "created": "Mon, 11 May 2020 09:31:44 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["Hayashi", "Tatsuya", ""], ["Nakamura", "Atsuyoshi", ""]]}, {"id": "2005.04987", "submitter": "Daniele Silvestro", "authors": "Daniele Silvestro and Tobias Andermann", "title": "Prior choice affects ability of Bayesian neural networks to identify\n  unknowns", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Bayesian neural networks (BNNs) are a powerful tool, though\ncomputationally demanding, to perform parameter estimation while jointly\nestimating uncertainty around predictions. BNNs are typically implemented using\narbitrary normal-distributed prior distributions on the model parameters. Here,\nwe explore the effects of different prior distributions on classification tasks\nin BNNs and evaluate the evidence supporting the predictions based on posterior\nprobabilities approximated by Markov Chain Monte Carlo sampling and by\ncomputing Bayes factors. We show that the choice of priors has a substantial\nimpact on the ability of the model to confidently assign data to the correct\nclass (true positive rates). Prior choice also affects significantly the\nability of a BNN to identify out-of-distribution instances as unknown (false\npositive rates). When comparing our results against neural networks (NN) with\nMonte Carlo dropout we found that BNNs generally outperform NNs. Finally, in\nour tests we did not find a single best choice as prior distribution. Instead,\neach dataset yielded the best results under a different prior, indicating that\ntesting alternative options can improve the performance of BNNs.\n", "versions": [{"version": "v1", "created": "Mon, 11 May 2020 10:32:47 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["Silvestro", "Daniele", ""], ["Andermann", "Tobias", ""]]}, {"id": "2005.05019", "submitter": "Jelle Van Dijk", "authors": "Jelle van Dijk", "title": "Post-human interaction design, yes, but cautiously", "comments": "A \"provocation\" contribution to the acm Designing Interactive Systems\n  2020 Conference, Eindhoven, July 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Post-human design runs the risk of obscuring the fact that AI technology\nactually imports a Cartesian humanist logic, which subsequently influences how\nwe design and conceive of so-called smart or intelligent objects. This leads to\nunwanted metaphorical attributions of human qualities to smart objects.\nInstead, starting from an embodied sensemaking perspective, designers should\ndemand of engineers to radically transform the very structure of AI technology,\nin order to truly support critical posthuman values of collectivity,\nrelationality and community building.\n", "versions": [{"version": "v1", "created": "Fri, 8 May 2020 09:17:19 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["van Dijk", "Jelle", ""]]}, {"id": "2005.05021", "submitter": "Youngnam Lee", "authors": "Youngnam Lee, Byungsoo Kim, Dongmin Shin, JungHoon Kim, Jineon Baek,\n  Jinhwan Lee, Youngduck Choi", "title": "Prescribing Deep Attentive Score Prediction Attracts Improved Student\n  Engagement", "comments": "EDM 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Intelligent Tutoring Systems (ITSs) have been developed to provide students\nwith personalized learning experiences by adaptively generating learning paths\noptimized for each individual. Within the vast scope of ITS, score prediction\nstands out as an area of study that enables students to construct individually\nrealistic goals based on their current position. Via the expected score\nprovided by the ITS, a student can instantaneously compare one's expected score\nto one's actual score, which directly corresponds to the reliability that the\nITS can instill. In other words, refining the precision of predicted scores\nstrictly correlates to the level of confidence that a student may have with an\nITS, which will evidently ensue improved student engagement. However, previous\nstudies have solely concentrated on improving the performance of a prediction\nmodel, largely lacking focus on the benefits generated by its practical\napplication. In this paper, we demonstrate that the accuracy of the score\nprediction model deployed in a real-world setting significantly impacts user\nengagement by providing empirical evidence. To that end, we apply a\nstate-of-the-art deep attentive neural network-based score prediction model to\nSanta, a multi-platform English ITS with approximately 780K users in South\nKorea that exclusively focuses on the TOEIC (Test of English for International\nCommunications) standardized examinations. We run a controlled A/B test on the\nITS with two models, respectively based on collaborative filtering and deep\nattentive neural networks, to verify whether the more accurate model engenders\nany student engagement. The results conclude that the attentive model not only\ninduces high student morale (e.g. higher diagnostic test completion ratio,\nnumber of questions answered, etc.) but also encourages active engagement (e.g.\nhigher purchase rate, improved total profit, etc.) on Santa.\n", "versions": [{"version": "v1", "created": "Mon, 27 Apr 2020 02:05:40 GMT"}, {"version": "v2", "created": "Fri, 15 May 2020 01:06:03 GMT"}, {"version": "v3", "created": "Tue, 19 May 2020 06:44:37 GMT"}, {"version": "v4", "created": "Thu, 25 Jun 2020 05:02:29 GMT"}, {"version": "v5", "created": "Wed, 1 Jul 2020 06:51:20 GMT"}], "update_date": "2020-07-02", "authors_parsed": [["Lee", "Youngnam", ""], ["Kim", "Byungsoo", ""], ["Shin", "Dongmin", ""], ["Kim", "JungHoon", ""], ["Baek", "Jineon", ""], ["Lee", "Jinhwan", ""], ["Choi", "Youngduck", ""]]}, {"id": "2005.05051", "submitter": "Lu\\'is M. S. Russo", "authors": "Lu\\'is M. S. Russo, Tobias Dietz, Jos\\'e Rui Figueira, Alexandre P.\n  Francisco, Stefan Ruzika", "title": "Sparsifying Parity-Check Matrices", "comments": "This work was supported by Funda\\c{c}\\~ao para a Ci\\^encia e\n  Tecnologia (FCT) ref. UID/CEC/50021/2019; European Union's Horizon 2020,\n  Marie Sk{\\l}odowska-Curie Actions grant agreement No 690941; The DAAD-CRUP\n  Luso-German bilateral cooperation 2017-2018 research project MONO-EMC; The\n  DFG (project-ID: RU 1524/2-3). Jos{\\'e} Rui Figueira acknowledges FCT grant\n  SFRH/BSAB/139892/2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.AI math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Parity check matrices (PCMs) are used to define linear error correcting codes\nand ensure reliable information transmission over noisy channels. The set of\ncodewords of such a code is the null space of this binary matrix.\n  We consider the problem of minimizing the number of one-entries in\nparity-check matrices. In the maximum-likelihood (ML) decoding method, the\nnumber of ones in PCMs is directly related to the time required to decode\nmessages. We propose a simple matrix row manipulation heuristic which alters\nthe PCM, but not the code itself. We apply simulated annealing and greedy local\nsearches to obtain PCMs with a small number of one entries quickly, i.e. in a\ncouple of minutes or hours when using mainstream hardware. The resulting\nmatrices provide faster ML decoding procedures, especially for large codes.\n", "versions": [{"version": "v1", "created": "Fri, 8 May 2020 05:51:40 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["Russo", "Lu\u00eds M. S.", ""], ["Dietz", "Tobias", ""], ["Figueira", "Jos\u00e9 Rui", ""], ["Francisco", "Alexandre P.", ""], ["Ruzika", "Stefan", ""]]}, {"id": "2005.05065", "submitter": "Kaustubh Joshi", "authors": "Kaustubh K Joshi", "title": "Neighbourhood Evaluation Criteria for Vertex Cover Problem", "comments": "8 pages, 4 figures, 2 tables, 1 algorithm section", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.OH cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neighbourhood Evaluation Criteria is a heuristical approximate algorithm that\nattempts to solve the Minimum Vertex Cover. degree count is kept in check for\neach vertex and the highest count based vertex is included in our cover set. In\nthe case of multiple equivalent vertices, the one with the lowest neighbourhood\ninfluence is selected. In the case of still existing multiple equivalent\nvertices, the one with the lowest remaining active vertex count (the highest\nIndependent Set enabling count) is selected as a tie-breaker.\n", "versions": [{"version": "v1", "created": "Thu, 7 May 2020 05:30:01 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["Joshi", "Kaustubh K", ""]]}, {"id": "2005.05066", "submitter": "Eneko Osaba", "authors": "Eneko Osaba, Aritz D. Martinez, Jesus L. Lobo, Ibai La\\~na and Javier\n  Del Ser", "title": "On the Transferability of Knowledge among Vehicle Routing Problems by\n  using Cellular Evolutionary Multitasking", "comments": "8 pages, 1 figure, paper accepted for presentation in the 23rd IEEE\n  International Conference on Intelligent Transportation Systems 2020 (IEEE\n  ITSC 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multitasking optimization is a recently introduced paradigm, focused on the\nsimultaneous solving of multiple optimization problem instances (tasks). The\ngoal of multitasking environments is to dynamically exploit existing\ncomplementarities and synergies among tasks, helping each other through the\ntransfer of genetic material. More concretely, Evolutionary Multitasking (EM)\nregards to the resolution of multitasking scenarios using concepts inherited\nfrom Evolutionary Computation. EM approaches such as the well-known\nMultifactorial Evolutionary Algorithm (MFEA) are lately gaining a notable\nresearch momentum when facing with multiple optimization problems. This work is\nfocused on the application of the recently proposed Multifactorial Cellular\nGenetic Algorithm (MFCGA) to the well-known Capacitated Vehicle Routing Problem\n(CVRP). In overall, 11 different multitasking setups have been built using 12\ndatasets. The contribution of this research is twofold. On the one hand, it is\nthe first application of the MFCGA to the Vehicle Routing Problem family of\nproblems. On the other hand, equally interesting is the second contribution,\nwhich is focused on the quantitative analysis of the positive genetic\ntransferability among the problem instances. To do that, we provide an\nempirical demonstration of the synergies arisen between the different\noptimization tasks.\n", "versions": [{"version": "v1", "created": "Mon, 11 May 2020 12:58:00 GMT"}, {"version": "v2", "created": "Sun, 17 May 2020 08:09:31 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Osaba", "Eneko", ""], ["Martinez", "Aritz D.", ""], ["Lobo", "Jesus L.", ""], ["La\u00f1a", "Ibai", ""], ["Del Ser", "Javier", ""]]}, {"id": "2005.05069", "submitter": "Eric L. Manibardo", "authors": "Eric L. Manibardo, Ibai La\\~na, Javier Del Ser", "title": "Transfer Learning and Online Learning for Traffic Forecasting under\n  Different Data Availability Conditions: Alternatives and Pitfalls", "comments": "Conference paper at ITSC 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  This work aims at unveiling the potential of Transfer Learning (TL) for\ndeveloping a traffic flow forecasting model in scenarios of absent data.\nKnowledge transfer from high-quality predictive models becomes feasible under\nthe TL paradigm, enabling the generation of new proper models with few data. In\norder to explore this capability, we identify three different levels of data\nabsent scenarios, where TL techniques are applied among Deep Learning (DL)\nmethods for traffic forecasting. Then, traditional batch learning is compared\nagainst TL based models using real traffic flow data, collected by deployed\nloops managed by the City Council of Madrid (Spain). In addition, we apply\nOnline Learning (OL) techniques, where model receives an update after each\nprediction, in order to adapt to traffic flow trend changes and incrementally\nlearn from new incoming traffic data. The obtained experimental results shed\nlight on the advantages of transfer and online learning for traffic flow\nforecasting, and draw practical insights on their interplay with the amount of\navailable training data at the location of interest.\n", "versions": [{"version": "v1", "created": "Fri, 8 May 2020 10:53:49 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["Manibardo", "Eric L.", ""], ["La\u00f1a", "Ibai", ""], ["Del Ser", "Javier", ""]]}, {"id": "2005.05085", "submitter": "Luo Chunjie", "authors": "Chunjie Luo, Xiwen He, Jianfeng Zhan, Lei Wang, Wanling Gao, Jiahui\n  Dai", "title": "Comparison and Benchmarking of AI Models and Frameworks on Mobile\n  Devices", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.PF eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to increasing amounts of data and compute resources, deep learning\nachieves many successes in various domains. The application of deep learning on\nthe mobile and embedded devices is taken more and more attentions, benchmarking\nand ranking the AI abilities of mobile and embedded devices becomes an urgent\nproblem to be solved. Considering the model diversity and framework diversity,\nwe propose a benchmark suite, AIoTBench, which focuses on the evaluation of the\ninference abilities of mobile and embedded devices. AIoTBench covers three\ntypical heavy-weight networks: ResNet50, InceptionV3, DenseNet121, as well as\nthree light-weight networks: SqueezeNet, MobileNetV2, MnasNet. Each network is\nimplemented by three frameworks which are designed for mobile and embedded\ndevices: Tensorflow Lite, Caffe2, Pytorch Mobile. To compare and rank the AI\ncapabilities of the devices, we propose two unified metrics as the AI scores:\nValid Images Per Second (VIPS) and Valid FLOPs Per Second (VOPS). Currently, we\nhave compared and ranked 5 mobile devices using our benchmark. This list will\nbe extended and updated soon after.\n", "versions": [{"version": "v1", "created": "Thu, 7 May 2020 15:05:23 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["Luo", "Chunjie", ""], ["He", "Xiwen", ""], ["Zhan", "Jianfeng", ""], ["Wang", "Lei", ""], ["Gao", "Wanling", ""], ["Dai", "Jiahui", ""]]}, {"id": "2005.05098", "submitter": "Valentin Mayer-Eichberger", "authors": "Valentin Mayer-Eichberger, Abdallah Saffidine", "title": "Positional Games and QBF: The Corrective Encoding", "comments": "Accepted for publication in the 23rd International Conference on\n  Theory and Applications of Satisfiability Testing (SAT2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI cs.GT cs.SC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Positional games are a mathematical class of two-player games comprising\nTic-tac-toe and its generalizations. We propose a novel encoding of these games\ninto Quantified Boolean Formulas (QBF) such that a game instance admits a\nwinning strategy for first player if and only if the corresponding formula is\ntrue. Our approach improves over previous QBF encodings of games in multiple\nways. First, it is generic and lets us encode other positional games, such as\nHex. Second, structural properties of positional games together with a careful\ntreatment of illegal moves let us generate more compact instances that can be\nsolved faster by state-of-the-art QBF solvers. We establish the latter fact\nthrough extensive experiments. Finally, the compactness of our new encoding\nmakes it feasible to translate realistic game problems. We identify a few such\nproblems of historical significance and put them forward to the QBF community\nas milestones of increasing difficulty.\n", "versions": [{"version": "v1", "created": "Mon, 11 May 2020 13:32:03 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["Mayer-Eichberger", "Valentin", ""], ["Saffidine", "Abdallah", ""]]}, {"id": "2005.05131", "submitter": "Kuruge Darshana Abeyrathna", "authors": "K. Darshana Abeyrathna, Ole-Christoffer Granmo, Morten Goodwin", "title": "Extending the Tsetlin Machine With Integer-Weighted Clauses for\n  Increased Interpretability", "comments": "20 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite significant effort, building models that are both interpretable and\naccurate is an unresolved challenge for many pattern recognition problems. In\ngeneral, rule-based and linear models lack accuracy, while deep learning\ninterpretability is based on rough approximations of the underlying inference.\nUsing a linear combination of conjunctive clauses in propositional logic,\nTsetlin Machines (TMs) have shown competitive performance on diverse\nbenchmarks. However, to do so, many clauses are needed, which impacts\ninterpretability. Here, we address the accuracy-interpretability challenge in\nmachine learning by equipping the TM clauses with integer weights. The\nresulting Integer Weighted TM (IWTM) deals with the problem of learning which\nclauses are inaccurate and thus must team up to obtain high accuracy as a team\n(low weight clauses), and which clauses are sufficiently accurate to operate\nmore independently (high weight clauses). Since each TM clause is formed\nadaptively by a team of Tsetlin Automata, identifying effective weights becomes\na challenging online learning problem. We address this problem by extending\neach team of Tsetlin Automata with a stochastic searching on the line (SSL)\nautomaton. In our novel scheme, the SSL automaton learns the weight of its\nclause in interaction with the corresponding Tsetlin Automata team, which, in\nturn, adapts the composition of the clause by the adjusting weight. We evaluate\nIWTM empirically using five datasets, including a study of interpetability. On\naverage, IWTM uses 6.5 times fewer literals than the vanilla TM and 120 times\nfewer literals than a TM with real-valued weights. Furthermore, in terms of\naverage F1-Score, IWTM outperforms simple Multi-Layered Artificial Neural\nNetworks, Decision Trees, Support Vector Machines, K-Nearest Neighbor, Random\nForest, XGBoost, Explainable Boosting Machines, and standard and real-value\nweighted TMs.\n", "versions": [{"version": "v1", "created": "Mon, 11 May 2020 14:18:09 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["Abeyrathna", "K. Darshana", ""], ["Granmo", "Ole-Christoffer", ""], ["Goodwin", "Morten", ""]]}, {"id": "2005.05137", "submitter": "Kieran Greer Dr", "authors": "Kieran Greer", "title": "New Ideas for Brain Modelling 6", "comments": null, "journal-ref": "AIMS Biophysics, Vol. 7, Issue 4, pp. 308-322 (2020)", "doi": "10.3934/biophy.2020022.", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes implementation details for a 3-level cognitive model,\ndescribed in the paper series. The whole architecture is now modular, with\ndifferent levels using different types of information. The ensemble-hierarchy\nrelationship is maintained and placed in the bottom optimising and middle\naggregating levels, to store memory objects and their relations. The top-level\ncognitive layer has been re-designed to model the Cognitive Process Language\n(CPL) of an earlier paper, by refactoring it into a network structure with a\nlight scheduler. The cortex brain region is thought to be hierarchical -\nclustering from simple to more complex features. The refactored network might\ntherefore challenge conventional thinking on that brain region. It is also\nargued that the function and structure in particular, of the new top level, is\nsimilar to the psychology theory of chunking. The model is still only a\nframework and does not have enough information for real intelligence. But a\nframework is now implemented over the whole design and so can give a more\ncomplete picture about the potential for results.\n", "versions": [{"version": "v1", "created": "Mon, 11 May 2020 14:28:34 GMT"}], "update_date": "2020-07-31", "authors_parsed": [["Greer", "Kieran", ""]]}, {"id": "2005.05151", "submitter": "Louis Annabi", "authors": "Louis Annabi (ETIS), Alexandre Pitti (ETIS), Mathias Quoy (ETIS)", "title": "Autonomous learning and chaining of motor primitives using the Free\n  Energy Principle", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this article, we apply the Free-Energy Principle to the question of motor\nprimitives learning. An echo-state network is used to generate motor\ntrajectories. We combine this network with a perception module and a controller\nthat can influence its dynamics. This new compound network permits the\nautonomous learning of a repertoire of motor trajectories. To evaluate the\nrepertoires built with our method, we exploit them in a handwriting task where\nprimitives are chained to produce long-range sequences.\n", "versions": [{"version": "v1", "created": "Mon, 11 May 2020 14:43:55 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["Annabi", "Louis", "", "ETIS"], ["Pitti", "Alexandre", "", "ETIS"], ["Quoy", "Mathias", "", "ETIS"]]}, {"id": "2005.05154", "submitter": "Noah Topper", "authors": "Noah Topper", "title": "Functional Decision Theory in an Evolutionary Environment", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "econ.TH cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Functional decision theory (FDT) is a fairly new mode of decision theory and\na normative viewpoint on how an agent should maximize expected utility. The\ncurrent standard in decision theory and computer science is causal decision\ntheory (CDT), largely seen as superior to the main alternative evidential\ndecision theory (EDT). These theories prescribe three distinct methods for\nmaximizing utility. We explore how FDT differs from CDT and EDT, and what\nimplications it has on the behavior of FDT agents and humans. It has been shown\nin previous research how FDT can outperform CDT and EDT. We additionally show\nFDT performing well on more classical game theory problems and argue for its\nextension to human problems to show that its potential for superiority is\nrobust. We also make FDT more concrete by displaying it in an evolutionary\nenvironment, competing directly against other theories.\n", "versions": [{"version": "v1", "created": "Wed, 6 May 2020 19:38:54 GMT"}, {"version": "v2", "created": "Mon, 26 Apr 2021 16:59:57 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["Topper", "Noah", ""]]}, {"id": "2005.05178", "submitter": "Trent Weiss", "authors": "Trent Weiss, Madhur Behl", "title": "DeepRacing: Parameterized Trajectories for Autonomous Racing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the challenging problem of high speed autonomous racing in a\nrealistic Formula One environment. DeepRacing is a novel end-to-end framework,\nand a virtual testbed for training and evaluating algorithms for autonomous\nracing. The virtual testbed is implemented using the realistic F1 series of\nvideo games, developed by Codemasters, which many Formula One drivers use for\ntraining. This virtual testbed is released under an open-source license both as\na standalone C++ API and as a binding to the popular Robot Operating System 2\n(ROS2) framework. This open-source API allows anyone to use the high fidelity\nphysics and photo-realistic capabilities of the F1 game as a simulator, and\nwithout hacking any game engine code. We use this framework to evaluate several\nneural network methodologies for autonomous racing. Specifically, we consider\nseveral fully end-to-end models that directly predict steering and acceleration\ncommands for an autonomous race car as well as a model that predicts a list of\nwaypoints to follow in the car's local coordinate system, with the task of\nselecting a steering/throttle angle left to a classical control algorithm. We\nalso present a novel method of autonomous racing by training a deep neural\nnetwork to predict a parameterized representation of a trajectory rather than a\nlist of waypoints. We evaluate these models performance in our open-source\nsimulator and show that trajectory prediction far outperforms end-to-end\ndriving. Additionally, we show that open-loop performance for an end-to-end\nmodel, i.e. root-mean-square error for a model's predicted control values, does\nnot necessarily correlate with increased driving performance in the closed-loop\nsense, i.e. actual ability to race around a track. Finally, we show that our\nproposed model of parameterized trajectory prediction outperforms both\nend-to-end control and waypoint prediction.\n", "versions": [{"version": "v1", "created": "Wed, 6 May 2020 21:35:48 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["Weiss", "Trent", ""], ["Behl", "Madhur", ""]]}, {"id": "2005.05239", "submitter": "James Miller", "authors": "Kyle Miller and Artur Dubrawski", "title": "System-Level Predictive Maintenance: Review of Research Literature and\n  Gap Analysis", "comments": "24 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper reviews current literature in the field of predictive maintenance\nfrom the system point of view. We differentiate the existing capabilities of\ncondition estimation and failure risk forecasting as currently applied to\nsimple components, from the capabilities needed to solve the same tasks for\ncomplex assets. System-level analysis faces more complex latent degradation\nstates, it has to comprehensively account for active maintenance programs at\neach component level and consider coupling between different maintenance\nactions, while reflecting increased monetary and safety costs for system\nfailures. As a result, methods that are effective for forecasting risk and\ninforming maintenance decisions regarding individual components do not readily\nscale to provide reliable sub-system or system level insights. A novel holistic\nmodeling approach is needed to incorporate available structural and physical\nknowledge and naturally handle the complexities of actively fielded and\nmaintained assets.\n", "versions": [{"version": "v1", "created": "Mon, 11 May 2020 16:30:54 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["Miller", "Kyle", ""], ["Dubrawski", "Artur", ""]]}, {"id": "2005.05240", "submitter": "Ye Liu", "authors": "Ye Liu, Tao Yang, Zeyu You, Wei Fan and Philip S. Yu", "title": "Commonsense Evidence Generation and Injection in Reading Comprehension", "comments": "Accepted by SIGDIAL 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Human tackle reading comprehension not only based on the given context itself\nbut often rely on the commonsense beyond. To empower the machine with\ncommonsense reasoning, in this paper, we propose a Commonsense Evidence\nGeneration and Injection framework in reading comprehension, named CEGI. The\nframework injects two kinds of auxiliary commonsense evidence into\ncomprehensive reading to equip the machine with the ability of rational\nthinking. Specifically, we build two evidence generators: the first generator\naims to generate textual evidence via a language model; the other generator\naims to extract factual evidence (automatically aligned text-triples) from a\ncommonsense knowledge graph after graph completion. Those evidences incorporate\ncontextual commonsense and serve as the additional inputs to the model.\nThereafter, we propose a deep contextual encoder to extract semantic\nrelationships among the paragraph, question, option, and evidence. Finally, we\nemploy a capsule network to extract different linguistic units (word and\nphrase) from the relations, and dynamically predict the optimal option based on\nthe extracted units. Experiments on the CosmosQA dataset demonstrate that the\nproposed CEGI model outperforms the current state-of-the-art approaches and\nachieves the accuracy (83.6%) on the leaderboard.\n", "versions": [{"version": "v1", "created": "Mon, 11 May 2020 16:31:08 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["Liu", "Ye", ""], ["Yang", "Tao", ""], ["You", "Zeyu", ""], ["Fan", "Wei", ""], ["Yu", "Philip S.", ""]]}, {"id": "2005.05256", "submitter": "Abhilasha Sancheti", "authors": "Abhilasha Sancheti, Kundan Krishna, Balaji Vasan Srinivasan,\n  Anandhavelu Natarajan", "title": "Reinforced Rewards Framework for Text Style Transfer", "comments": "ECIR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Style transfer deals with the algorithms to transfer the stylistic properties\nof a piece of text into that of another while ensuring that the core content is\npreserved. There has been a lot of interest in the field of text style transfer\ndue to its wide application to tailored text generation. Existing works\nevaluate the style transfer models based on content preservation and transfer\nstrength. In this work, we propose a reinforcement learning based framework\nthat directly rewards the framework on these target metrics yielding a better\ntransfer of the target style. We show the improved performance of our proposed\nframework based on automatic and human evaluation on three independent tasks:\nwherein we transfer the style of text from formal to informal, high excitement\nto low excitement, modern English to Shakespearean English, and vice-versa in\nall the three cases. Improved performance of the proposed framework over\nexisting state-of-the-art frameworks indicates the viability of the approach.\n", "versions": [{"version": "v1", "created": "Mon, 11 May 2020 16:54:28 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["Sancheti", "Abhilasha", ""], ["Krishna", "Kundan", ""], ["Srinivasan", "Balaji Vasan", ""], ["Natarajan", "Anandhavelu", ""]]}, {"id": "2005.05268", "submitter": "Uzay \\c{C}etin", "authors": "Uzay Cetin and Yunus Emre Gundogmus", "title": "Feature Selection with Evolving, Fast and Slow Using Two Parallel\n  Genetic Algorithms", "comments": null, "journal-ref": "Conference: 2019 4th International Conference on Computer Science\n  and Engineering (UBMK)", "doi": "10.1109/UBMK.2019.8907165", "report-no": null, "categories": "cs.NE cs.AI cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Feature selection is one of the most challenging issues in machine learning,\nespecially while working with high dimensional data. In this paper, we address\nthe problem of feature selection and propose a new approach called Evolving\nFast and Slow. This new approach is based on using two parallel genetic\nalgorithms having high and low mutation rates, respectively. Evolving Fast and\nSlow requires a new parallel architecture combining an automatic system that\nevolves fast and an effortful system that evolves slow. With this architecture,\nexploration and exploitation can be done simultaneously and in unison. Evolving\nfast, with high mutation rate, can be useful to explore new unknown places in\nthe search space with long jumps; and Evolving Slow, with low mutation rate,\ncan be useful to exploit previously known places in the search space with short\nmovements. Our experiments show that Evolving Fast and Slow achieves very good\nresults in terms of both accuracy and feature elimination.\n", "versions": [{"version": "v1", "created": "Mon, 11 May 2020 17:10:39 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["Cetin", "Uzay", ""], ["Gundogmus", "Yunus Emre", ""]]}, {"id": "2005.05298", "submitter": "Baolin Peng", "authors": "Baolin Peng and Chunyuan Li and Jinchao Li and Shahin Shayandeh and\n  Lars Liden and Jianfeng Gao", "title": "SOLOIST: Building Task Bots at Scale with Transfer Learning and Machine\n  Teaching", "comments": "18 pages; To appear at TACL; Project Website: https://aka.ms/soloist", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new method SOLOIST that uses transfer learning and machine\nteaching to build task bots at scale. We parameterize classical modular\ntask-oriented dialog systems using a Transformer-based auto-regressive language\nmodel, which subsumes different dialog modules into a single neural model. We\npre-train, on heterogeneous dialog corpora, a task-grounded response generation\nmodel, which can generate dialog responses grounded in user goals and\nreal-world knowledge for task completion. The pre-trained model can be\nefficiently adapted to accomplish new tasks with a handful of task-specific\ndialogs via machine teaching, where training samples are generated by human\nteachers interacting with the system. Experiments show that (i) SOLOIST creates\nnew state-of-the-art on well-studied task-oriented dialog benchmarks, including\nCamRest676 and MultiWOZ; (ii) in the few-shot fine-tuning settings, SOLOIST\nsignificantly outperforms existing methods, and (iii) the use of machine\nteaching substantially reduces the labeling cost of fine-tuning. The\npre-trained models and codes are available at https://aka.ms/soloist.\n", "versions": [{"version": "v1", "created": "Mon, 11 May 2020 17:58:34 GMT"}, {"version": "v2", "created": "Thu, 14 May 2020 17:42:40 GMT"}, {"version": "v3", "created": "Mon, 22 Jun 2020 03:02:50 GMT"}, {"version": "v4", "created": "Fri, 9 Apr 2021 03:14:57 GMT"}], "update_date": "2021-04-12", "authors_parsed": [["Peng", "Baolin", ""], ["Li", "Chunyuan", ""], ["Li", "Jinchao", ""], ["Shayandeh", "Shahin", ""], ["Liden", "Lars", ""], ["Gao", "Jianfeng", ""]]}, {"id": "2005.05339", "submitter": "Chris Donahue", "authors": "Chris Donahue, Mina Lee, Percy Liang", "title": "Enabling Language Models to Fill in the Blanks", "comments": "Published as a conference paper at ACL 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a simple approach for text infilling, the task of predicting\nmissing spans of text at any position in a document. While infilling could\nenable rich functionality especially for writing assistance tools, more\nattention has been devoted to language modeling---a special case of infilling\nwhere text is predicted at the end of a document. In this paper, we aim to\nextend the capabilities of language models (LMs) to the more general task of\ninfilling. To this end, we train (or fine-tune) off-the-shelf LMs on sequences\ncontaining the concatenation of artificially-masked text and the text which was\nmasked. We show that this approach, which we call infilling by language\nmodeling, can enable LMs to infill entire sentences effectively on three\ndifferent domains: short stories, scientific abstracts, and lyrics.\nFurthermore, we show that humans have difficulty identifying sentences infilled\nby our approach as machine-generated in the domain of short stories.\n", "versions": [{"version": "v1", "created": "Mon, 11 May 2020 18:00:03 GMT"}, {"version": "v2", "created": "Thu, 10 Sep 2020 18:03:11 GMT"}], "update_date": "2020-09-14", "authors_parsed": [["Donahue", "Chris", ""], ["Lee", "Mina", ""], ["Liang", "Percy", ""]]}, {"id": "2005.05418", "submitter": "Giannis Fikioris", "authors": "Giannis Fikioris, Kostas Patroumpas, Alexander Artikis", "title": "Optimizing Vessel Trajectory Compression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In previous work we introduced a trajectory detection module that can provide\nsummarized representations of vessel trajectories by consuming AIS positional\nmessages online. This methodology can provide reliable trajectory synopses with\nlittle deviations from the original course by discarding at least 70% of the\nraw data as redundant. However, such trajectory compression is very sensitive\nto parametrization. In this paper, our goal is to fine-tune the selection of\nthese parameter values. We take into account the type of each vessel in order\nto provide a suitable configuration that can yield improved trajectory\nsynopses, both in terms of approximation error and compression ratio.\nFurthermore, we employ a genetic algorithm converging to a suitable\nconfiguration per vessel type. Our tests against a publicly available AIS\ndataset have shown that compression efficiency is comparable or even better\nthan the one with default parametrization without resorting to a laborious data\ninspection.\n", "versions": [{"version": "v1", "created": "Mon, 11 May 2020 20:38:56 GMT"}], "update_date": "2020-05-13", "authors_parsed": [["Fikioris", "Giannis", ""], ["Patroumpas", "Kostas", ""], ["Artikis", "Alexander", ""]]}, {"id": "2005.05420", "submitter": "Zhe Liu", "authors": "Binyu Wang and Zhe Liu and Qingbiao Li and Amanda Prorok", "title": "Mobile Robot Path Planning in Dynamic Environments through Globally\n  Guided Reinforcement Learning", "comments": "8 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Path planning for mobile robots in large dynamic environments is a\nchallenging problem, as the robots are required to efficiently reach their\ngiven goals while simultaneously avoiding potential conflicts with other robots\nor dynamic objects. In the presence of dynamic obstacles, traditional solutions\nusually employ re-planning strategies, which re-call a planning algorithm to\nsearch for an alternative path whenever the robot encounters a conflict.\nHowever, such re-planning strategies often cause unnecessary detours. To\naddress this issue, we propose a learning-based technique that exploits\nenvironmental spatio-temporal information. Different from existing\nlearning-based methods, we introduce a globally guided reinforcement learning\napproach (G2RL), which incorporates a novel reward structure that generalizes\nto arbitrary environments. We apply G2RL to solve the multi-robot path planning\nproblem in a fully distributed reactive manner. We evaluate our method across\ndifferent map types, obstacle densities, and the number of robots. Experimental\nresults show that G2RL generalizes well, outperforming existing distributed\nmethods, and performing very similarly to fully centralized state-of-the-art\nbenchmarks.\n", "versions": [{"version": "v1", "created": "Mon, 11 May 2020 20:42:29 GMT"}, {"version": "v2", "created": "Fri, 11 Sep 2020 21:14:15 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Wang", "Binyu", ""], ["Liu", "Zhe", ""], ["Li", "Qingbiao", ""], ["Prorok", "Amanda", ""]]}, {"id": "2005.05440", "submitter": "Baiming Chen", "authors": "Baiming Chen, Mengdi Xu, Liang Li, Ding Zhao", "title": "Delay-Aware Model-Based Reinforcement Learning for Continuous Control", "comments": null, "journal-ref": "Neurocomputing Volume 450, 25 August 2021, Pages 119-128", "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Action delays degrade the performance of reinforcement learning in many\nreal-world systems. This paper proposes a formal definition of delay-aware\nMarkov Decision Process and proves it can be transformed into standard MDP with\naugmented states using the Markov reward process. We develop a delay-aware\nmodel-based reinforcement learning framework that can incorporate the\nmulti-step delay into the learned system models without learning effort.\nExperiments with the Gym and MuJoCo platforms show that the proposed\ndelay-aware model-based algorithm is more efficient in training and\ntransferable between systems with various durations of delay compared with\noff-policy model-free reinforcement learning methods. Codes available at:\nhttps://github.com/baimingc/dambrl.\n", "versions": [{"version": "v1", "created": "Mon, 11 May 2020 21:13:37 GMT"}], "update_date": "2021-05-10", "authors_parsed": [["Chen", "Baiming", ""], ["Xu", "Mengdi", ""], ["Li", "Liang", ""], ["Zhao", "Ding", ""]]}, {"id": "2005.05490", "submitter": "David Suter", "authors": "David Suter, Ruwan Tennakoon, Erchuan Zhang, Tat-Jun Chin and Alireza\n  Bab-Hadiashar", "title": "Monotone Boolean Functions, Feasibility/Infeasibility, LP-type problems\n  and MaxCon", "comments": "Parts under conference review, work in progress. Keywords: Monotone\n  Boolean Functions, Consensus Maximisation, LP-Type Problem, Computer Vision,\n  Robust Fitting, Matroid, Simplicial Complex, Independence Systems", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper outlines connections between Monotone Boolean Functions, LP-Type\nproblems and the Maximum Consensus Problem. The latter refers to a particular\ntype of robust fitting characterisation, popular in Computer Vision (MaxCon).\nIndeed, this is our main motivation but we believe the results of the study of\nthese connections are more widely applicable to LP-type problems (at least\n'thresholded versions', as we describe), and perhaps even more widely. We\nillustrate, with examples from Computer Vision, how the resulting perspectives\nsuggest new algorithms. Indeed, we focus, in the experimental part, on how the\nInfluence (a property of Boolean Functions that takes on a special form if the\nfunction is Monotone) can guide a search for the MaxCon solution.\n", "versions": [{"version": "v1", "created": "Mon, 11 May 2020 23:51:15 GMT"}], "update_date": "2020-05-14", "authors_parsed": [["Suter", "David", ""], ["Tennakoon", "Ruwan", ""], ["Zhang", "Erchuan", ""], ["Chin", "Tat-Jun", ""], ["Bab-Hadiashar", "Alireza", ""]]}, {"id": "2005.05512", "submitter": "David  McAllester", "authors": "David McAllester", "title": "MathZero, The Classification Problem, and Set-Theoretic Type Theory", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  AlphaZero learns to play go, chess and shogi at a superhuman level through\nself play given only the rules of the game. This raises the question of whether\na similar thing could be done for mathematics -- a MathZero. MathZero would\nrequire a formal foundation and an objective. We propose the foundation of\nset-theoretic dependent type theory and an objective defined in terms of the\nclassification problem -- the problem of classifying concept instances up to\nisomorphism. The natural numbers arise as the solution to the classification\nproblem for finite sets. Here we generalize classical Bourbaki set-theoretic\nisomorphism to set-theoretic dependent type theory. To our knowledge we give\nthe first isomorphism inference rules for set-theoretic dependent type theory\nwith propositional set-theoretic equality. The presentation is intended to be\naccessible to mathematicians with no prior exposure to type theory.\n", "versions": [{"version": "v1", "created": "Tue, 12 May 2020 01:48:48 GMT"}, {"version": "v2", "created": "Mon, 18 May 2020 16:30:57 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["McAllester", "David", ""]]}, {"id": "2005.05519", "submitter": "Kaijie Xu", "authors": "Kaijie Xu, Witold Pedrycz, Zhiwu Li, Yinghui Quan, and Weike Nie", "title": "A Novel Granular-Based Bi-Clustering Method of Deep Mining the\n  Co-Expressed Genes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditional clustering methods are limited when dealing with huge and\nheterogeneous groups of gene expression data, which motivates the development\nof bi-clustering methods. Bi-clustering methods are used to mine bi-clusters\nwhose subsets of samples (genes) are co-regulated under their test conditions.\nStudies show that mining bi-clusters of consistent trends and trends with\nsimilar degrees of fluctuations from the gene expression data is essential in\nbioinformatics research. Unfortunately, traditional bi-clustering methods are\nnot fully effective in discovering such bi-clusters. Therefore, we propose a\nnovel bi-clustering method by involving here the theory of Granular Computing.\nIn the proposed scheme, the gene data matrix, considered as a group of time\nseries, is transformed into a series of ordered information granules. With the\ninformation granules we build a characteristic matrix of the gene data to\ncapture the fluctuation trend of the expression value between consecutive\nconditions to mine the ideal bi-clusters. The experimental results are in\nagreement with the theoretical analysis, and show the excellent performance of\nthe proposed method.\n", "versions": [{"version": "v1", "created": "Tue, 12 May 2020 02:04:40 GMT"}], "update_date": "2020-05-13", "authors_parsed": [["Xu", "Kaijie", ""], ["Pedrycz", "Witold", ""], ["Li", "Zhiwu", ""], ["Quan", "Yinghui", ""], ["Nie", "Weike", ""]]}, {"id": "2005.05538", "submitter": "Nicholas Kluge Corr\\^ea", "authors": "Nicholas Kluge Corr\\^ea and Nythamar de Oliveira", "title": "Dynamic Cognition Applied to Value Learning in Artificial Intelligence", "comments": null, "journal-ref": null, "doi": "10.13140/RG.2.2.35369.01126/3", "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Experts in Artificial Intelligence (AI) development predict that advances in\nthe development of intelligent systems and agents will reshape vital areas in\nour society. Nevertheless, if such an advance isn't done with prudence, it can\nresult in negative outcomes for humanity. For this reason, several researchers\nin the area are trying to develop a robust, beneficial, and safe concept of\nartificial intelligence. Currently, several of the open problems in the field\nof AI research arise from the difficulty of avoiding unwanted behaviors of\nintelligent agents, and at the same time specifying what we want such systems\nto do. It is of utmost importance that artificial intelligent agents have their\nvalues aligned with human values, given the fact that we cannot expect an AI to\ndevelop our moral preferences simply because of its intelligence, as discussed\nin the Orthogonality Thesis. Perhaps this difficulty comes from the way we are\naddressing the problem of expressing objectives, values, and ends, using\nrepresentational cognitive methods. A solution to this problem would be the\ndynamic cognitive approach proposed by Dreyfus, whose phenomenological\nphilosophy defends that the human experience of being-in-the-world cannot be\nrepresented by the symbolic or connectionist cognitive methods. A possible\napproach to this problem would be to use theoretical models such as SED\n(situated embodied dynamics) to address the values learning problem in AI.\n", "versions": [{"version": "v1", "created": "Tue, 12 May 2020 03:58:52 GMT"}, {"version": "v2", "created": "Fri, 14 Aug 2020 01:51:35 GMT"}, {"version": "v3", "created": "Thu, 27 Aug 2020 19:41:56 GMT"}, {"version": "v4", "created": "Sun, 25 Oct 2020 20:49:17 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Corr\u00eaa", "Nicholas Kluge", ""], ["de Oliveira", "Nythamar", ""]]}, {"id": "2005.05579", "submitter": "Michal Bou\\v{s}ka", "authors": "Michal Bou\\v{s}ka, Anton\\'in Nov\\'ak, P\\v{r}emysl \\v{S}\\r{u}cha,\n  Istv\\'an M\\'odos, and Zden\\v{e}k Hanz\\'alek", "title": "Data-driven Algorithm for Scheduling with Total Tardiness", "comments": null, "journal-ref": null, "doi": "10.5220/0008915300590068", "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we investigate the use of deep learning for solving a\nclassical NP-Hard single machine scheduling problem where the criterion is to\nminimize the total tardiness. Instead of designing an end-to-end machine\nlearning model, we utilize well known decomposition of the problem and we\nenhance it with a data-driven approach. We have designed a regressor containing\na deep neural network that learns and predicts the criterion of a given set of\njobs. The network acts as a polynomial-time estimator of the criterion that is\nused in a single-pass scheduling algorithm based on Lawler's decomposition\ntheorem. Essentially, the regressor guides the algorithm to select the best\nposition for each job. The experimental results show that our data-driven\napproach can efficiently generalize information from the training phase to\nsignificantly larger instances (up to 350 jobs) where it achieves an optimality\ngap of about 0.5%, which is four times less than the gap of the\nstate-of-the-art NBR heuristic.\n", "versions": [{"version": "v1", "created": "Tue, 12 May 2020 07:16:43 GMT"}], "update_date": "2020-05-13", "authors_parsed": [["Bou\u0161ka", "Michal", ""], ["Nov\u00e1k", "Anton\u00edn", ""], ["\u0160\u016fcha", "P\u0159emysl", ""], ["M\u00f3dos", "Istv\u00e1n", ""], ["Hanz\u00e1lek", "Zden\u011bk", ""]]}, {"id": "2005.05672", "submitter": "Sven Buechel", "authors": "Sven Buechel, Susanna R\\\"ucker, Udo Hahn", "title": "Learning and Evaluating Emotion Lexicons for 91 Languages", "comments": "ACL 2020 Camera-Ready", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Emotion lexicons describe the affective meaning of words and thus constitute\na centerpiece for advanced sentiment and emotion analysis. Yet, manually\ncurated lexicons are only available for a handful of languages, leaving most\nlanguages of the world without such a precious resource for downstream\napplications. Even worse, their coverage is often limited both in terms of the\nlexical units they contain and the emotional variables they feature. In order\nto break this bottleneck, we here introduce a methodology for creating almost\narbitrarily large emotion lexicons for any target language. Our approach\nrequires nothing but a source language emotion lexicon, a bilingual word\ntranslation model, and a target language embedding model. Fulfilling these\nrequirements for 91 languages, we are able to generate representationally rich\nhigh-coverage lexicons comprising eight emotional variables with more than 100k\nlexical entries each. We evaluated the automatically generated lexicons against\nhuman judgment from 26 datasets, spanning 12 typologically diverse languages,\nand found that our approach produces results in line with state-of-the-art\nmonolingual approaches to lexicon creation and even surpasses human reliability\nfor some languages and variables. Code and data are available at\nhttps://github.com/JULIELab/MEmoLon archived under DOI\nhttps://doi.org/10.5281/zenodo.3779901.\n", "versions": [{"version": "v1", "created": "Tue, 12 May 2020 10:32:03 GMT"}], "update_date": "2020-05-13", "authors_parsed": [["Buechel", "Sven", ""], ["R\u00fccker", "Susanna", ""], ["Hahn", "Udo", ""]]}, {"id": "2005.05684", "submitter": "Xinting Zhu", "authors": "Xinting Zhu and Lishuai Li", "title": "Flight Time Prediction for Fuel Loading Decisions with a Deep Learning\n  Approach", "comments": null, "journal-ref": null, "doi": "10.1016/j.trc.2021.103179", "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Under increasing economic and environmental pressure, airlines are constantly\nseeking new technologies and optimizing flight operations to reduce fuel\nconsumption. However, the current practice on fuel loading, which has a\nsignificant impact on aircraft weight and fuel consumption, has yet to be\nthoroughly addressed by existing studies. Excess fuel is loaded by dispatchers\nand (or) pilots to handle fuel consumption uncertainties, primarily caused by\nflight time uncertainties, which cannot be predicted by current Flight Planning\nSystems. In this paper, we develop a novel spatial weighted recurrent neural\nnetwork model to provide better flight time predictions by capturing air\ntraffic information at a national scale based on multiple data sources,\nincluding Automatic Dependent Surveillance-Broadcast, Meteorological Aerodrome\nReports, and airline records. In this model, a spatial weighted layer is\ndesigned to extract spatial dependences among network delay states. Then, a new\ntraining procedure associated with the spatial weighted layer is introduced to\nextract OD-specific spatial weights. Long short-term memory networks are used\nto extract the temporal behavior patterns of network delay states. Finally,\nfeatures from delays, weather, and flight schedules are fed into a fully\nconnected neural network to predict the flight time of a particular flight. The\nproposed model was evaluated using one year of historical data from an\nairline's real operations. Results show that our model can provide more\naccurate flight time predictions than baseline methods, especially for flights\nwith extreme delays. We also show that, with the improved flight time\nprediction, fuel loading can be optimized and resulting in reduced fuel\nconsumption by 0.016%-1.915% without increasing the fuel depletion risk.\n", "versions": [{"version": "v1", "created": "Tue, 12 May 2020 11:05:42 GMT"}, {"version": "v2", "created": "Sun, 9 May 2021 07:29:15 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Zhu", "Xinting", ""], ["Li", "Lishuai", ""]]}, {"id": "2005.05712", "submitter": "Ramon Fraga Pereira", "authors": "Ramon Fraga Pereira", "title": "Goal Recognition over Imperfect Domain Models", "comments": "Ph. D. Thesis defended in February of 2020, PUCRS, Porto Alegre,\n  Brazil", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Goal recognition is the problem of recognizing the intended goal of\nautonomous agents or humans by observing their behavior in an environment. Over\nthe past years, most existing approaches to goal and plan recognition have been\nignoring the need to deal with imperfections regarding the domain model that\nformalizes the environment where autonomous agents behave. In this thesis, we\nintroduce the problem of goal recognition over imperfect domain models, and\ndevelop solution approaches that explicitly deal with two distinct types of\nimperfect domains models: (1) incomplete discrete domain models that have\npossible, rather than known, preconditions and effects in action descriptions;\nand (2) approximate continuous domain models, where the transition function is\napproximated from past observations and not well-defined. We develop novel goal\nrecognition approaches over imperfect domains models by leveraging and adapting\nexisting recognition approaches from the literature. Experiments and evaluation\nover these two types of imperfect domains models show that our novel goal\nrecognition approaches are accurate in comparison to baseline approaches from\nthe literature, at several levels of observability and imperfections.\n", "versions": [{"version": "v1", "created": "Tue, 12 May 2020 12:11:53 GMT"}], "update_date": "2020-05-13", "authors_parsed": [["Pereira", "Ramon Fraga", ""]]}, {"id": "2005.05721", "submitter": "Quratul-Ain Mahesar", "authors": "Quratul-ain Mahesar, Nir Oren and Wamberto W. Vasconcelos", "title": "Preference Elicitation in Assumption-Based Argumentation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Various structured argumentation frameworks utilize preferences as part of\ntheir standard inference procedure to enable reasoning with preferences. In\nthis paper, we consider an inverse of the standard reasoning problem, seeking\nto identify what preferences over assumptions could lead to a given set of\nconclusions being drawn. We ground our work in the Assumption-Based\nArgumentation (ABA) framework, and present an algorithm which computes and\nenumerates all possible sets of preferences over the assumptions in the system\nfrom which a desired conflict free set of conclusions can be obtained under a\ngiven semantic. After describing our algorithm, we establish its soundness,\ncompleteness and complexity.\n", "versions": [{"version": "v1", "created": "Tue, 12 May 2020 12:31:27 GMT"}], "update_date": "2020-05-13", "authors_parsed": [["Mahesar", "Quratul-ain", ""], ["Oren", "Nir", ""], ["Vasconcelos", "Wamberto W.", ""]]}, {"id": "2005.05763", "submitter": "Hongming Zhang", "authors": "Hongming Zhang, Xinran Zhao, Yangqiu Song", "title": "WinoWhy: A Deep Diagnosis of Essential Commonsense Knowledge for\n  Answering Winograd Schema Challenge", "comments": "Accepted by ACL 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present the first comprehensive categorization of essential\ncommonsense knowledge for answering the Winograd Schema Challenge (WSC). For\neach of the questions, we invite annotators to first provide reasons for making\ncorrect decisions and then categorize them into six major knowledge categories.\nBy doing so, we better understand the limitation of existing methods (i.e.,\nwhat kind of knowledge cannot be effectively represented or inferred with\nexisting methods) and shed some light on the commonsense knowledge that we need\nto acquire in the future for better commonsense reasoning. Moreover, to\ninvestigate whether current WSC models can understand the commonsense or they\nsimply solve the WSC questions based on the statistical bias of the dataset, we\nleverage the collected reasons to develop a new task called WinoWhy, which\nrequires models to distinguish plausible reasons from very similar but wrong\nreasons for all WSC questions. Experimental results prove that even though\npre-trained language representation models have achieved promising progress on\nthe original WSC dataset, they are still struggling at WinoWhy. Further\nexperiments show that even though supervised models can achieve better\nperformance, the performance of these models can be sensitive to the dataset\ndistribution. WinoWhy and all codes are available at:\nhttps://github.com/HKUST-KnowComp/WinoWhy.\n", "versions": [{"version": "v1", "created": "Tue, 12 May 2020 13:40:06 GMT"}], "update_date": "2020-05-13", "authors_parsed": [["Zhang", "Hongming", ""], ["Zhao", "Xinran", ""], ["Song", "Yangqiu", ""]]}, {"id": "2005.05815", "submitter": "Aditya M. Deshpande", "authors": "Aditya M. Deshpande and Ali A. Minai and Manish Kumar", "title": "One-Shot Recognition of Manufacturing Defects in Steel Surfaces", "comments": "Accepted for publication in NAMRC 48", "journal-ref": "Procedia Manufacturing 48 (2020) 1064-1071", "doi": "10.1016/j.promfg.2020.05.146", "report-no": null, "categories": "cs.CV cs.AI cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quality control is an essential process in manufacturing to make the product\ndefect-free as well as to meet customer needs. The automation of this process\nis important to maintain high quality along with the high manufacturing\nthroughput. With recent developments in deep learning and computer vision\ntechnologies, it has become possible to detect various features from the images\nwith near-human accuracy. However, many of these approaches are data intensive.\nTraining and deployment of such a system on manufacturing floors may become\nexpensive and time-consuming. The need for large amounts of training data is\none of the limitations of the applicability of these approaches in real-world\nmanufacturing systems. In this work, we propose the application of a Siamese\nconvolutional neural network to do one-shot recognition for such a task. Our\nresults demonstrate how one-shot learning can be used in quality control of\nsteel by identification of defects on the steel surface. This method can\nsignificantly reduce the requirements of training data and can also be run in\nreal-time.\n", "versions": [{"version": "v1", "created": "Tue, 12 May 2020 14:30:03 GMT"}], "update_date": "2020-07-03", "authors_parsed": [["Deshpande", "Aditya M.", ""], ["Minai", "Ali A.", ""], ["Kumar", "Manish", ""]]}, {"id": "2005.05842", "submitter": "Matteo Iovino", "authors": "Matteo Iovino, Edvards Scukins, Jonathan Styrud, Petter \\\"Ogren and\n  Christian Smith", "title": "A Survey of Behavior Trees in Robotics and AI", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Behavior Trees (BTs) were invented as a tool to enable modular AI in computer\ngames, but have received an increasing amount of attention in the robotics\ncommunity in the last decade. With rising demands on agent AI complexity, game\nprogrammers found that the Finite State Machines (FSM) that they used scaled\npoorly and were difficult to extend, adapt and reuse. In BTs, the state\ntransition logic is not dispersed across the individual states, but organized\nin a hierarchical tree structure, with the states as leaves. This has a\nsignificant effect on modularity, which in turn simplifies both synthesis and\nanalysis by humans and algorithms alike. These advantages are needed not only\nin game AI design, but also in robotics, as is evident from the research being\ndone. In this paper we present a comprehensive survey of the topic of BTs in\nArtificial Intelligence and Robotic applications. The existing literature is\ndescribed and categorized based on methods, application areas and\ncontributions, and the paper is concluded with a list of open research\nchallenges.\n", "versions": [{"version": "v1", "created": "Tue, 12 May 2020 15:03:20 GMT"}, {"version": "v2", "created": "Wed, 13 May 2020 12:21:00 GMT"}], "update_date": "2020-05-14", "authors_parsed": [["Iovino", "Matteo", ""], ["Scukins", "Edvards", ""], ["Styrud", "Jonathan", ""], ["\u00d6gren", "Petter", ""], ["Smith", "Christian", ""]]}, {"id": "2005.05849", "submitter": "Quratul-Ain Mahesar", "authors": "Quratul-ain Mahesar and Simon Parsons", "title": "Argument Schemes for Explainable Planning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Artificial Intelligence (AI) is being increasingly used to develop systems\nthat produce intelligent solutions. However, there is a major concern that\nwhether the systems built will be trusted by humans. In order to establish\ntrust in AI systems, there is a need for the user to understand the reasoning\nbehind their solutions and therefore, the system should be able to explain and\njustify its output. In this paper, we use argumentation to provide explanations\nin the domain of AI planning. We present argument schemes to create arguments\nthat explain a plan and its components; and a set of critical questions that\nallow interaction between the arguments and enable the user to obtain further\ninformation regarding the key elements of the plan. Finally, we present some\nproperties of the plan arguments.\n", "versions": [{"version": "v1", "created": "Tue, 12 May 2020 15:09:50 GMT"}], "update_date": "2020-05-13", "authors_parsed": [["Mahesar", "Quratul-ain", ""], ["Parsons", "Simon", ""]]}, {"id": "2005.05886", "submitter": "Julien Corman", "authors": "Diego Calvanese and Julien Corman and Davide Lanti and Simon\n  Razniewski", "title": "Counting Query Answers over a DL-Lite Knowledge Base (extended version)", "comments": "Extended version of an article published at IJCAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.AI", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Counting answers to a query is an operation supported by virtually all\ndatabase management systems. In this paper we focus on counting answers over a\nKnowledge Base (KB), which may be viewed as a database enriched with background\nknowledge about the domain under consideration. In particular, we place our\nwork in the context of Ontology-Mediated Query Answering/Ontology-based Data\nAccess (OMQA/OBDA), where the language used for the ontology is a member of the\nDL-Lite family and the data is a (usually virtual) set of assertions. We study\nthe data complexity of query answering, for different members of the DL-Lite\nfamily that include number restrictions, and for variants of conjunctive\nqueries with counting that differ with respect to their shape (connected,\nbranching, rooted). We improve upon existing results by providing a PTIME and\ncoNP lower bounds, and upper bounds in PTIME and LOGSPACE. For the latter case,\nwe define a novel query rewriting technique into first-order logic with\ncounting.\n", "versions": [{"version": "v1", "created": "Tue, 12 May 2020 16:01:09 GMT"}, {"version": "v2", "created": "Mon, 25 May 2020 17:39:27 GMT"}, {"version": "v3", "created": "Fri, 17 Jul 2020 05:23:03 GMT"}], "update_date": "2020-07-20", "authors_parsed": [["Calvanese", "Diego", ""], ["Corman", "Julien", ""], ["Lanti", "Davide", ""], ["Razniewski", "Simon", ""]]}, {"id": "2005.05906", "submitter": "Brent Mittelstadt", "authors": "Sandra Wachter, Brent Mittelstadt, Chris Russell", "title": "Why Fairness Cannot Be Automated: Bridging the Gap Between EU\n  Non-Discrimination Law and AI", "comments": null, "journal-ref": null, "doi": "10.2139/ssrn.3547922", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article identifies a critical incompatibility between European notions\nof discrimination and existing statistical measures of fairness. First, we\nreview the evidential requirements to bring a claim under EU non-discrimination\nlaw. Due to the disparate nature of algorithmic and human discrimination, the\nEU's current requirements are too contextual, reliant on intuition, and open to\njudicial interpretation to be automated. Second, we show how the legal\nprotection offered by non-discrimination law is challenged when AI, not humans,\ndiscriminate. Humans discriminate due to negative attitudes (e.g. stereotypes,\nprejudice) and unintentional biases (e.g. organisational practices or\ninternalised stereotypes) which can act as a signal to victims that\ndiscrimination has occurred. Finally, we examine how existing work on fairness\nin machine learning lines up with procedures for assessing cases under EU\nnon-discrimination law. We propose \"conditional demographic disparity\" (CDD) as\na standard baseline statistical measurement that aligns with the European Court\nof Justice's \"gold standard.\" Establishing a standard set of statistical\nevidence for automated discrimination cases can help ensure consistent\nprocedures for assessment, but not judicial interpretation, of cases involving\nAI and automated systems. Through this proposal for procedural regularity in\nthe identification and assessment of automated discrimination, we clarify how\nto build considerations of fairness into automated systems as far as possible\nwhile still respecting and enabling the contextual approach to judicial\ninterpretation practiced under EU non-discrimination law.\n  N.B. Abridged abstract\n", "versions": [{"version": "v1", "created": "Tue, 12 May 2020 16:30:12 GMT"}], "update_date": "2020-05-13", "authors_parsed": [["Wachter", "Sandra", ""], ["Mittelstadt", "Brent", ""], ["Russell", "Chris", ""]]}, {"id": "2005.05909", "submitter": "John Morris", "authors": "John X. Morris, Eli Lifland, Jin Yong Yoo, Jake Grigsby, Di Jin and\n  Yanjun Qi", "title": "TextAttack: A Framework for Adversarial Attacks, Data Augmentation, and\n  Adversarial Training in NLP", "comments": "6 pages. More details are shared at\n  https://github.com/QData/TextAttack", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While there has been substantial research using adversarial attacks to\nanalyze NLP models, each attack is implemented in its own code repository. It\nremains challenging to develop NLP attacks and utilize them to improve model\nperformance. This paper introduces TextAttack, a Python framework for\nadversarial attacks, data augmentation, and adversarial training in NLP.\nTextAttack builds attacks from four components: a goal function, a set of\nconstraints, a transformation, and a search method. TextAttack's modular design\nenables researchers to easily construct attacks from combinations of novel and\nexisting components. TextAttack provides implementations of 16 adversarial\nattacks from the literature and supports a variety of models and datasets,\nincluding BERT and other transformers, and all GLUE tasks. TextAttack also\nincludes data augmentation and adversarial training modules for using\ncomponents of adversarial attacks to improve model accuracy and robustness.\nTextAttack is democratizing NLP: anyone can try data augmentation and\nadversarial training on any model or dataset, with just a few lines of code.\nCode and tutorials are available at https://github.com/QData/TextAttack.\n", "versions": [{"version": "v1", "created": "Wed, 29 Apr 2020 21:33:35 GMT"}, {"version": "v2", "created": "Wed, 13 May 2020 17:37:21 GMT"}, {"version": "v3", "created": "Wed, 22 Jul 2020 19:33:10 GMT"}, {"version": "v4", "created": "Mon, 5 Oct 2020 00:10:24 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Morris", "John X.", ""], ["Lifland", "Eli", ""], ["Yoo", "Jin Yong", ""], ["Grigsby", "Jake", ""], ["Jin", "Di", ""], ["Qi", "Yanjun", ""]]}, {"id": "2005.05951", "submitter": "Aravind Rajeswaran", "authors": "Rahul Kidambi, Aravind Rajeswaran, Praneeth Netrapalli, Thorsten\n  Joachims", "title": "MOReL : Model-Based Offline Reinforcement Learning", "comments": "First two authors contributed equally. Published at NeurIPS 2020.\n  After publication at NeurIPS 2020, (1) D4RL benchmark results have been\n  added; (2) hyper-parameter ablation studies have been added; (3) scope of\n  Lemma 3 has been extended", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In offline reinforcement learning (RL), the goal is to learn a highly\nrewarding policy based solely on a dataset of historical interactions with the\nenvironment. The ability to train RL policies offline can greatly expand the\napplicability of RL, its data efficiency, and its experimental velocity. Prior\nwork in offline RL has been confined almost exclusively to model-free RL\napproaches. In this work, we present MOReL, an algorithmic framework for\nmodel-based offline RL. This framework consists of two steps: (a) learning a\npessimistic MDP (P-MDP) using the offline dataset; and (b) learning a\nnear-optimal policy in this P-MDP. The learned P-MDP has the property that for\nany policy, the performance in the real environment is approximately\nlower-bounded by the performance in the P-MDP. This enables it to serve as a\ngood surrogate for purposes of policy evaluation and learning, and overcome\ncommon pitfalls of model-based RL like model exploitation. Theoretically, we\nshow that MOReL is minimax optimal (up to log factors) for offline RL. Through\nexperiments, we show that MOReL matches or exceeds state-of-the-art results in\nwidely studied offline RL benchmarks. Moreover, the modular design of MOReL\nenables future advances in its components (e.g. generative modeling,\nuncertainty estimation, planning etc.) to directly translate into advances for\noffline RL.\n", "versions": [{"version": "v1", "created": "Tue, 12 May 2020 17:52:43 GMT"}, {"version": "v2", "created": "Mon, 20 Jul 2020 19:00:20 GMT"}, {"version": "v3", "created": "Tue, 2 Mar 2021 04:35:04 GMT"}], "update_date": "2021-03-03", "authors_parsed": [["Kidambi", "Rahul", ""], ["Rajeswaran", "Aravind", ""], ["Netrapalli", "Praneeth", ""], ["Joachims", "Thorsten", ""]]}, {"id": "2005.05960", "submitter": "Deepak Pathak", "authors": "Ramanan Sekar, Oleh Rybkin, Kostas Daniilidis, Pieter Abbeel, Danijar\n  Hafner, Deepak Pathak", "title": "Planning to Explore via Self-Supervised World Models", "comments": "Accepted at ICML 2020. Videos and code at\n  https://ramanans1.github.io/plan2explore/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.NE cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning allows solving complex tasks, however, the learning\ntends to be task-specific and the sample efficiency remains a challenge. We\npresent Plan2Explore, a self-supervised reinforcement learning agent that\ntackles both these challenges through a new approach to self-supervised\nexploration and fast adaptation to new tasks, which need not be known during\nexploration. During exploration, unlike prior methods which retrospectively\ncompute the novelty of observations after the agent has already reached them,\nour agent acts efficiently by leveraging planning to seek out expected future\nnovelty. After exploration, the agent quickly adapts to multiple downstream\ntasks in a zero or a few-shot manner. We evaluate on challenging control tasks\nfrom high-dimensional image inputs. Without any training supervision or\ntask-specific interaction, Plan2Explore outperforms prior self-supervised\nexploration methods, and in fact, almost matches the performances oracle which\nhas access to rewards. Videos and code at\nhttps://ramanans1.github.io/plan2explore/\n", "versions": [{"version": "v1", "created": "Tue, 12 May 2020 17:59:45 GMT"}, {"version": "v2", "created": "Tue, 30 Jun 2020 23:05:50 GMT"}], "update_date": "2020-07-02", "authors_parsed": [["Sekar", "Ramanan", ""], ["Rybkin", "Oleh", ""], ["Daniilidis", "Kostas", ""], ["Abbeel", "Pieter", ""], ["Hafner", "Danijar", ""], ["Pathak", "Deepak", ""]]}, {"id": "2005.06022", "submitter": "Carlos Toxtli", "authors": "Carlos Toxtli, Angela Richmond-Fuller, Saiph Savage", "title": "Reputation Agent: Prompting Fair Reviews in Gig Markets", "comments": "12 pages, 5 figures, The Web Conference 2020, ACM WWW 2020", "journal-ref": null, "doi": "10.1145/3366423.3380199", "report-no": null, "categories": "cs.HC cs.AI cs.LG", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Our study presents a new tool, Reputation Agent, to promote fairer reviews\nfrom requesters (employers or customers) on gig markets. Unfair reviews,\ncreated when requesters consider factors outside of a worker's control, are\nknown to plague gig workers and can result in lost job opportunities and even\ntermination from the marketplace. Our tool leverages machine learning to\nimplement an intelligent interface that: (1) uses deep learning to\nautomatically detect when an individual has included unfair factors into her\nreview (factors outside the worker's control per the policies of the market);\nand (2) prompts the individual to reconsider her review if she has incorporated\nunfair factors. To study the effectiveness of Reputation Agent, we conducted a\ncontrolled experiment over different gig markets. Our experiment illustrates\nthat across markets, Reputation Agent, in contrast with traditional approaches,\nmotivates requesters to review gig workers' performance more fairly. We discuss\nhow tools that bring more transparency to employers about the policies of a gig\nmarket can help build empathy thus resulting in reasoned discussions around\npotential injustices towards workers generated by these interfaces. Our vision\nis that with tools that promote truth and transparency we can bring fairer\ntreatment to gig workers.\n", "versions": [{"version": "v1", "created": "Fri, 8 May 2020 01:56:10 GMT"}], "update_date": "2020-05-14", "authors_parsed": [["Toxtli", "Carlos", ""], ["Richmond-Fuller", "Angela", ""], ["Savage", "Saiph", ""]]}, {"id": "2005.06060", "submitter": "Marius Buliga", "authors": "M. Buliga", "title": "Artificial life properties of directed interaction combinators vs.\n  chemlambda", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.ET q-bio.MN", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide a framework for experimentation at\nhttps://mbuliga.github.io/quinegraphs/ic-vs-chem.html#icvschem with two\nartificial chemistries: directed interaction combinators (dirIC, defined in\nsection 2) and chemlambda. We are interested if these chemistries allow for\nartificial life behaviour: replication, metabolism and death.\n  The main conclusion of these experiments is that graph rewrites systems which\nallow conflicting rewrites are better than those which don't, as concerns their\nartificial life properties. This is in contradiction with the search for good\ngraph rewrite systems for decentralized computing, where non-conflicting graph\nrewrite systems are historically preferred.\n  This continues the artificial chemistry experiments with chemlambda, lambda\ncalculus or interaction combinators, available from the entry page at\nhttps://chemlambda.github.io/index.html and described in arXiv:2003.14332.\n", "versions": [{"version": "v1", "created": "Tue, 12 May 2020 21:28:31 GMT"}], "update_date": "2020-05-14", "authors_parsed": [["Buliga", "M.", ""]]}, {"id": "2005.06061", "submitter": "Zhaoheng Yin", "authors": "Zhao-Heng Yin, Wu-Jun Li", "title": "TOMA: Topological Map Abstraction for Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Animals are able to discover the topological map (graph) of surrounding\nenvironment, which will be used for navigation. Inspired by this biological\nphenomenon, researchers have recently proposed to generate graph representation\nfor Markov decision process (MDP) and use such graphs for planning in\nreinforcement learning (RL). However, existing graph generation methods suffer\nfrom many drawbacks. One drawback is that existing methods do not learn an\nabstraction for graphs, which results in high memory and computation cost. This\ndrawback also makes generated graph non-robust, which degrades the planning\nperformance. Another drawback is that existing methods cannot be used for\nfacilitating exploration which is important in RL. In this paper, we propose a\nnew method, called topological map abstraction (TOMA), for graph generation.\nTOMA can generate an abstract graph representation for MDP, which costs much\nless memory and computation cost than existing methods. Furthermore, TOMA can\nbe used for facilitating exploration. In particular, we propose planning to\nexplore, in which TOMA is used to accelerate exploration by guiding the agent\ntowards unexplored states. A novel experience replay module called vertex\nmemory is also proposed to improve exploration performance. Experimental\nresults show that TOMA can outperform existing methods to achieve the\nstate-of-the-art performance.\n", "versions": [{"version": "v1", "created": "Mon, 11 May 2020 05:24:47 GMT"}, {"version": "v2", "created": "Tue, 23 Jun 2020 11:12:44 GMT"}], "update_date": "2020-06-24", "authors_parsed": [["Yin", "Zhao-Heng", ""], ["Li", "Wu-Jun", ""]]}, {"id": "2005.06105", "submitter": "Han Cha", "authors": "Han Cha, Jihong Park, Hyesung Kim, Mehdi Bennis, Seong-Lyun Kim", "title": "Proxy Experience Replay: Federated Distillation for Distributed\n  Reinforcement Learning", "comments": "8 pages, 5 figures, This paper is accepted to IEEE Intelligent\n  Systems special issue of July/Aug 2020 - Federated Machine Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditional distributed deep reinforcement learning (RL) commonly relies on\nexchanging the experience replay memory (RM) of each agent. Since the RM\ncontains all state observations and action policy history, it may incur huge\ncommunication overhead while violating the privacy of each agent.\nAlternatively, this article presents a communication-efficient and\nprivacy-preserving distributed RL framework, coined federated reinforcement\ndistillation (FRD). In FRD, each agent exchanges its proxy experience replay\nmemory (ProxRM), in which policies are locally averaged with respect to proxy\nstates clustering actual states. To provide FRD design insights, we present\nablation studies on the impact of ProxRM structures, neural network\narchitectures, and communication intervals. Furthermore, we propose an improved\nversion of FRD, coined mixup augmented FRD (MixFRD), in which ProxRM is\ninterpolated using the mixup data augmentation algorithm. Simulations in a\nCartpole environment validate the effectiveness of MixFRD in reducing the\nvariance of mission completion time and communication cost, compared to the\nbenchmark schemes, vanilla FRD, federated reinforcement learning (FRL), and\npolicy distillation (PD).\n", "versions": [{"version": "v1", "created": "Wed, 13 May 2020 01:36:34 GMT"}, {"version": "v2", "created": "Fri, 15 May 2020 12:44:25 GMT"}], "update_date": "2020-05-18", "authors_parsed": [["Cha", "Han", ""], ["Park", "Jihong", ""], ["Kim", "Hyesung", ""], ["Bennis", "Mehdi", ""], ["Kim", "Seong-Lyun", ""]]}, {"id": "2005.06117", "submitter": "Vivek Gupta", "authors": "Vivek Gupta, Maitrey Mehta, Pegah Nokhiz and Vivek Srikumar", "title": "INFOTABS: Inference on Tables as Semi-structured Data", "comments": "16 pages, 6 figures, 14 Tables, ACL 2020, Project Page:\n  https://infotabs.github.io/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we observe that semi-structured tabulated text is ubiquitous;\nunderstanding them requires not only comprehending the meaning of text\nfragments, but also implicit relationships between them. We argue that such\ndata can prove as a testing ground for understanding how we reason about\ninformation. To study this, we introduce a new dataset called INFOTABS,\ncomprising of human-written textual hypotheses based on premises that are\ntables extracted from Wikipedia info-boxes. Our analysis shows that the\nsemi-structured, multi-domain and heterogeneous nature of the premises admits\ncomplex, multi-faceted reasoning. Experiments reveal that, while human\nannotators agree on the relationships between a table-hypothesis pair, several\nstandard modeling strategies are unsuccessful at the task, suggesting that\nreasoning about tables can pose a difficult modeling challenge.\n", "versions": [{"version": "v1", "created": "Wed, 13 May 2020 02:07:54 GMT"}], "update_date": "2020-05-14", "authors_parsed": [["Gupta", "Vivek", ""], ["Mehta", "Maitrey", ""], ["Nokhiz", "Pegah", ""], ["Srikumar", "Vivek", ""]]}, {"id": "2005.06139", "submitter": "Yu Lu", "authors": "Yu Lu, Deliang Wang, Qinggang Meng, Penghe Chen", "title": "Towards Interpretable Deep Learning Models for Knowledge Tracing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As an important technique for modeling the knowledge states of learners, the\ntraditional knowledge tracing (KT) models have been widely used to support\nintelligent tutoring systems and MOOC platforms. Driven by the fast\nadvancements of deep learning techniques, deep neural network has been recently\nadopted to design new KT models for achieving better prediction performance.\nHowever, the lack of interpretability of these models has painfully impeded\ntheir practical applications, as their outputs and working mechanisms suffer\nfrom the intransparent decision process and complex inner structures. We thus\npropose to adopt the post-hoc method to tackle the interpretability issue for\ndeep learning based knowledge tracing (DLKT) models. Specifically, we focus on\napplying the layer-wise relevance propagation (LRP) method to interpret\nRNN-based DLKT model by backpropagating the relevance from the model's output\nlayer to its input layer. The experiment results show the feasibility using the\nLRP method for interpreting the DLKT model's predictions, and partially\nvalidate the computed relevance scores from both question level and concept\nlevel. We believe it can be a solid step towards fully interpreting the DLKT\nmodels and promote their practical applications in the education domain.\n", "versions": [{"version": "v1", "created": "Wed, 13 May 2020 04:03:21 GMT"}], "update_date": "2020-05-14", "authors_parsed": [["Lu", "Yu", ""], ["Wang", "Deliang", ""], ["Meng", "Qinggang", ""], ["Chen", "Penghe", ""]]}, {"id": "2005.06148", "submitter": "Jialin Liu Ph.D", "authors": "Tianye Shu, Ziqi Wang, Jialin Liu, Xin Yao", "title": "A Novel CNet-assisted Evolutionary Level Repairer and Its Applications\n  to Super Mario Bros", "comments": "Accepted at IEEE CEC2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Applying latent variable evolution to game level design has become more and\nmore popular as little human expert knowledge is required. However, defective\nlevels with illegal patterns may be generated due to the violation of\nconstraints for level design. A traditional way of repairing the defective\nlevels is programming specific rule-based repairers to patch the flaw. However,\nprogramming these constraints is sometimes complex and not straightforward. An\nautonomous level repairer which is capable of learning the constraints is\nneeded. In this paper, we propose a novel approach, CNet, to learn the\nprobability distribution of tiles giving its surrounding tiles on a set of real\nlevels, and then detect the illegal tiles in generated new levels. Then, an\nevolutionary repairer is designed to search for optimal replacement schemes\nequipped with a novel search space being constructed with the help of CNet and\na novel heuristic function. The proposed approaches are proved to be effective\nin our case study of repairing GAN-generated and artificially destroyed levels\nof Super Mario Bros. game. Our CNet-assisted evolutionary repairer can also be\neasily applied to other games of which the levels can be represented by a\nmatrix of objects or tiles.\n", "versions": [{"version": "v1", "created": "Wed, 13 May 2020 04:27:18 GMT"}, {"version": "v2", "created": "Thu, 14 May 2020 16:17:39 GMT"}], "update_date": "2020-05-15", "authors_parsed": [["Shu", "Tianye", ""], ["Wang", "Ziqi", ""], ["Liu", "Jialin", ""], ["Yao", "Xin", ""]]}, {"id": "2005.06223", "submitter": "Stephane Doncieux", "authors": "Stephane Doncieux (ISIR), Nicolas Bredeche (ISIR), L\\'eni Le Goff\n  (ISIR), Beno\\^it Girard (ISIR), Alexandre Coninx (ISIR), Olivier Sigaud\n  (ISIR), Mehdi Khamassi (ISIR), Natalia D\\'iaz-Rodr\\'iguez (U2IS), David\n  Filliat (U2IS), Timothy Hospedales (ICSA), A. Eiben (VU), Richard Duro", "title": "DREAM Architecture: a Developmental Approach to Open-Ended Learning in\n  Robotics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.NE cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Robots are still limited to controlled conditions, that the robot designer\nknows with enough details to endow the robot with the appropriate models or\nbehaviors. Learning algorithms add some flexibility with the ability to\ndiscover the appropriate behavior given either some demonstrations or a reward\nto guide its exploration with a reinforcement learning algorithm. Reinforcement\nlearning algorithms rely on the definition of state and action spaces that\ndefine reachable behaviors. Their adaptation capability critically depends on\nthe representations of these spaces: small and discrete spaces result in fast\nlearning while large and continuous spaces are challenging and either require a\nlong training period or prevent the robot from converging to an appropriate\nbehavior. Beside the operational cycle of policy execution and the learning\ncycle, which works at a slower time scale to acquire new policies, we introduce\nthe redescription cycle, a third cycle working at an even slower time scale to\ngenerate or adapt the required representations to the robot, its environment\nand the task. We introduce the challenges raised by this cycle and we present\nDREAM (Deferred Restructuring of Experience in Autonomous Machines), a\ndevelopmental cognitive architecture to bootstrap this redescription process\nstage by stage, build new state representations with appropriate motivations,\nand transfer the acquired knowledge across domains or tasks or even across\nrobots. We describe results obtained so far with this approach and end up with\na discussion of the questions it raises in Neuroscience.\n", "versions": [{"version": "v1", "created": "Wed, 13 May 2020 09:29:40 GMT"}], "update_date": "2020-05-14", "authors_parsed": [["Doncieux", "Stephane", "", "ISIR"], ["Bredeche", "Nicolas", "", "ISIR"], ["Goff", "L\u00e9ni Le", "", "ISIR"], ["Girard", "Beno\u00eet", "", "ISIR"], ["Coninx", "Alexandre", "", "ISIR"], ["Sigaud", "Olivier", "", "ISIR"], ["Khamassi", "Mehdi", "", "ISIR"], ["D\u00edaz-Rodr\u00edguez", "Natalia", "", "U2IS"], ["Filliat", "David", "", "U2IS"], ["Hospedales", "Timothy", "", "ICSA"], ["Eiben", "A.", "", "VU"], ["Duro", "Richard", ""]]}, {"id": "2005.06224", "submitter": "Stephane Doncieux", "authors": "Stephane Doncieux (ISIR), Giuseppe Paolo (ISIR), Alban Laflaqui\\`ere,\n  Alexandre Coninx (ISIR)", "title": "Novelty Search makes Evolvability Inevitable", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Evolvability is an important feature that impacts the ability of evolutionary\nprocesses to find interesting novel solutions and to deal with changing\nconditions of the problem to solve. The estimation of evolvability is not\nstraightforward and is generally too expensive to be directly used as selective\npressure in the evolutionary process. Indirectly promoting evolvability as a\nside effect of other easier and faster to compute selection pressures would\nthus be advantageous. In an unbounded behavior space, it has already been shown\nthat evolvable individuals naturally appear and tend to be selected as they are\nmore likely to invade empty behavior niches. Evolvability is thus a natural\nbyproduct of the search in this context. However, practical agents and\nenvironments often impose limits on the reach-able behavior space. How do these\nboundaries impact evolvability? In this context, can evolvability still be\npromoted without explicitly rewarding it? We show that Novelty Search\nimplicitly creates a pressure for high evolvability even in bounded behavior\nspaces, and explore the reasons for such a behavior. More precisely we show\nthat, throughout the search, the dynamic evaluation of novelty rewards\nindividuals which are very mobile in the behavior space, which in turn promotes\nevolvability.\n", "versions": [{"version": "v1", "created": "Wed, 13 May 2020 09:32:07 GMT"}], "update_date": "2020-05-14", "authors_parsed": [["Doncieux", "Stephane", "", "ISIR"], ["Paolo", "Giuseppe", "", "ISIR"], ["Laflaqui\u00e8re", "Alban", "", "ISIR"], ["Coninx", "Alexandre", "", "ISIR"]]}, {"id": "2005.06249", "submitter": "Zhuosheng Zhang", "authors": "Zhuosheng Zhang, Hai Zhao, Rui Wang", "title": "Machine Reading Comprehension: The Role of Contextualized Language\n  Models and Beyond", "comments": "51 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine reading comprehension (MRC) aims to teach machines to read and\ncomprehend human languages, which is a long-standing goal of natural language\nprocessing (NLP). With the burst of deep neural networks and the evolution of\ncontextualized language models (CLMs), the research of MRC has experienced two\nsignificant breakthroughs. MRC and CLM, as a phenomenon, have a great impact on\nthe NLP community. In this survey, we provide a comprehensive and comparative\nreview on MRC covering overall research topics about 1) the origin and\ndevelopment of MRC and CLM, with a particular focus on the role of CLMs; 2) the\nimpact of MRC and CLM to the NLP community; 3) the definition, datasets, and\nevaluation of MRC; 4) general MRC architecture and technical methods in the\nview of two-stage Encoder-Decoder solving architecture from the insights of the\ncognitive process of humans; 5) previous highlights, emerging topics, and our\nempirical analysis, among which we especially focus on what works in different\nperiods of MRC researches. We propose a full-view categorization and new\ntaxonomies on these topics. The primary views we have arrived at are that 1)\nMRC boosts the progress from language processing to understanding; 2) the rapid\nimprovement of MRC systems greatly benefits from the development of CLMs; 3)\nthe theme of MRC is gradually moving from shallow text matching to cognitive\nreasoning.\n", "versions": [{"version": "v1", "created": "Wed, 13 May 2020 10:58:50 GMT"}], "update_date": "2020-05-14", "authors_parsed": [["Zhang", "Zhuosheng", ""], ["Zhao", "Hai", ""], ["Wang", "Rui", ""]]}, {"id": "2005.06274", "submitter": "Neng-Fa Zhou", "authors": "Neng-Fa Zhou", "title": "Yet Another Comparison of SAT Encodings for the At-Most-K Constraint", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  The at-most-k constraint is ubiquitous in combinatorial problems, and\nnumerous SAT encodings are available for the constraint. Prior experiments have\nshown the competitiveness of the sequential-counter encoding for k $>$ 1, and\nhave excluded the parallel-counter encoding, which is more compact that the\nbinary-adder encoding, from consideration due to its incapability of enforcing\narc consistency through unit propagation. This paper presents an experiment\nthat shows astounding performance of the binary-adder encoding for the\nat-most-k constraint.\n", "versions": [{"version": "v1", "created": "Tue, 12 May 2020 03:23:00 GMT"}], "update_date": "2020-05-14", "authors_parsed": [["Zhou", "Neng-Fa", ""]]}, {"id": "2005.06282", "submitter": "Sudipto Mukherjee", "authors": "Sudipto Mukherjee, Subhabrata Mukherjee, Marcello Hasegawa, Ahmed\n  Hassan Awadallah, Ryen White", "title": "Smart To-Do : Automatic Generation of To-Do Items from Emails", "comments": "58th annual meeting of the Association for Computational Linguistics\n  (ACL), 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Intelligent features in email service applications aim to increase\nproductivity by helping people organize their folders, compose their emails and\nrespond to pending tasks. In this work, we explore a new application,\nSmart-To-Do, that helps users with task management over emails. We introduce a\nnew task and dataset for automatically generating To-Do items from emails where\nthe sender has promised to perform an action. We design a two-stage process\nleveraging recent advances in neural text generation and sequence-to-sequence\nlearning, obtaining BLEU and ROUGE scores of 0:23 and 0:63 for this task. To\nthe best of our knowledge, this is the first work to address the problem of\ncomposing To-Do items from emails.\n", "versions": [{"version": "v1", "created": "Tue, 5 May 2020 02:21:40 GMT"}], "update_date": "2020-05-14", "authors_parsed": [["Mukherjee", "Sudipto", ""], ["Mukherjee", "Subhabrata", ""], ["Hasegawa", "Marcello", ""], ["Awadallah", "Ahmed Hassan", ""], ["White", "Ryen", ""]]}, {"id": "2005.06293", "submitter": "Anastasia Dimou", "authors": "Anastasia Dimou", "title": "R2RML and RML Comparison for RDF Generation, their Rules Validation and\n  Inconsistency Resolution", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, an overview of the state of the art on knowledge graph\ngeneration is provided, with focus on the two prevalent mapping languages: the\nW3C recommended R2RML and its generalisation RML. We look into details on their\ndifferences and explain how knowledge graphs, in the form of RDF graphs, can be\ngenerated with each one of the two mapping languages. Then we assess if the\nvocabulary terms were properly applied to the data and no violations occurred\non their use, either using R2RML or RML to generate the desired knowledge\ngraph.\n", "versions": [{"version": "v1", "created": "Wed, 13 May 2020 12:53:04 GMT"}], "update_date": "2020-05-14", "authors_parsed": [["Dimou", "Anastasia", ""]]}, {"id": "2005.06369", "submitter": "Mayalen Etcheverry", "authors": "Mayalen Etcheverry, Pierre-Yves Oudeyer, Chris Reinke", "title": "Progressive growing of self-organized hierarchical representations for\n  exploration", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Designing agent that can autonomously discover and learn a diversity of\nstructures and skills in unknown changing environments is key for lifelong\nmachine learning. A central challenge is how to learn incrementally\nrepresentations in order to progressively build a map of the discovered\nstructures and re-use it to further explore. To address this challenge, we\nidentify and target several key functionalities. First, we aim to build lasting\nrepresentations and avoid catastrophic forgetting throughout the exploration\nprocess. Secondly we aim to learn a diversity of representations allowing to\ndiscover a \"diversity of diversity\" of structures (and associated skills) in\ncomplex high-dimensional environments. Thirdly, we target representations that\ncan structure the agent discoveries in a coarse-to-fine manner. Finally, we\ntarget the reuse of such representations to drive exploration toward an\n\"interesting\" type of diversity, for instance leveraging human guidance.\nCurrent approaches in state representation learning rely generally on\nmonolithic architectures which do not enable all these functionalities.\nTherefore, we present a novel technique to progressively construct a Hierarchy\nof Observation Latent Models for Exploration Stratification, called HOLMES.\nThis technique couples the use of a dynamic modular model architecture for\nrepresentation learning with intrinsically-motivated goal exploration processes\n(IMGEPs). The paper shows results in the domain of automated discovery of\ndiverse self-organized patterns, considering as testbed the experimental\nframework from Reinke et al. (2019).\n", "versions": [{"version": "v1", "created": "Wed, 13 May 2020 15:24:42 GMT"}], "update_date": "2020-05-14", "authors_parsed": [["Etcheverry", "Mayalen", ""], ["Oudeyer", "Pierre-Yves", ""], ["Reinke", "Chris", ""]]}, {"id": "2005.06510", "submitter": "Mohamed Wiem Mkaouer", "authors": "Mohamed Wiem Mkaouer, Marouane Kessentini, Adnan Shaout, Patrice\n  Koligheu, Slim Bechikh, Kalyanmoy Deb, and Ali Ouni", "title": "Many-Objective Software Remodularization using NSGA-III", "comments": "Mkaouer, Wiem, et al. \"Many-objective software remodularization using\n  NSGA-III.\" ACM Transactions on Software Engineering and Methodology (TOSEM)\n  24.3 (2015): 1-45", "journal-ref": "ACM Transactions on Software Engineering and Methodology (TOSEM)\n  24, no. 3 (2015): 1-45", "doi": "10.1145/2729974", "report-no": null, "categories": "cs.SE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Software systems nowadays are complex and difficult to maintain due to\ncontinuous changes and bad design choices. To handle the complexity of systems,\nsoftware products are, in general, decomposed in terms of packages/modules\ncontaining classes that are dependent. However, it is challenging to\nautomatically remodularize systems to improve their maintainability. The\nmajority of existing remodularization work mainly satisfy one objective which\nis improving the structure of packages by optimizing coupling and cohesion. In\naddition, most of existing studies are limited to only few operation types such\nas move class and split packages. Many other objectives, such as the design\nsemantics, reducing the number of changes and maximizing the consistency with\ndevelopment change history, are important to improve the quality of the\nsoftware by remodularizing it. In this paper, we propose a novel many-objective\nsearch-based approach using NSGA-III. The process aims at finding the optimal\nremodularization solutions that improve the structure of packages, minimize the\nnumber of changes, preserve semantics coherence, and re-use the history of\nchanges. We evaluate the efficiency of our approach using four different\nopen-source systems and one automotive industry project, provided by our\nindustrial partner, through a quantitative and qualitative study conducted with\nsoftware engineers.\n", "versions": [{"version": "v1", "created": "Wed, 13 May 2020 18:34:15 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Mkaouer", "Mohamed Wiem", ""], ["Kessentini", "Marouane", ""], ["Shaout", "Adnan", ""], ["Koligheu", "Patrice", ""], ["Bechikh", "Slim", ""], ["Deb", "Kalyanmoy", ""], ["Ouni", "Ali", ""]]}, {"id": "2005.06527", "submitter": "Artuur Leeuwenberg", "authors": "Artuur Leeuwenberg, Marie-Francine Moens", "title": "A Survey on Temporal Reasoning for Temporal Information Extraction from\n  Text (Extended Abstract)", "comments": "Extended abstract of a JAIR article, which is to appear in the\n  proceedings of IJCAI 2020 (the copyright of this abstract is held by IJCAI\n  2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Time is deeply woven into how people perceive, and communicate about the\nworld. Almost unconsciously, we provide our language utterances with temporal\ncues, like verb tenses, and we can hardly produce sentences without such cues.\nExtracting temporal cues from text, and constructing a global temporal view\nabout the order of described events is a major challenge of automatic natural\nlanguage understanding. Temporal reasoning, the process of combining different\ntemporal cues into a coherent temporal view, plays a central role in temporal\ninformation extraction. This article presents a comprehensive survey of the\nresearch from the past decades on temporal reasoning for automatic temporal\ninformation extraction from text, providing a case study on the integration of\nsymbolic reasoning with machine learning-based information extraction systems.\n", "versions": [{"version": "v1", "created": "Wed, 13 May 2020 18:53:15 GMT"}, {"version": "v2", "created": "Fri, 15 May 2020 11:35:51 GMT"}], "update_date": "2020-05-18", "authors_parsed": [["Leeuwenberg", "Artuur", ""], ["Moens", "Marie-Francine", ""]]}, {"id": "2005.06584", "submitter": "Yusan Lin", "authors": "Maryam Moosaei, Yusan Lin, Hao Yang", "title": "Fashion Recommendation and Compatibility Prediction Using Relational\n  Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Fashion is an inherently visual concept and computer vision and artificial\nintelligence (AI) are playing an increasingly important role in shaping the\nfuture of this domain. Many research has been done on recommending fashion\nproducts based on the learned user preferences. However, in addition to\nrecommending single items, AI can also help users create stylish outfits from\nitems they already have, or purchase additional items that go well with their\ncurrent wardrobe. Compatibility is the key factor in creating stylish outfits\nfrom single items. Previous studies have mostly focused on modeling pair-wise\ncompatibility. There are a few approaches that consider an entire outfit, but\nthese approaches have limitations such as requiring rich semantic information,\ncategory labels, and fixed order of items. Thus, they fail to effectively\ndetermine compatibility when such information is not available. In this work,\nwe adopt a Relation Network (RN) to develop new compatibility learning models,\nFashion RN and FashionRN-VSE, that addresses the limitations of existing\napproaches. FashionRN learns the compatibility of an entire outfit, with an\narbitrary number of items, in an arbitrary order. We evaluated our model using\na large dataset of 49,740 outfits that we collected from Polyvore website.\nQuantitatively, our experimental results demonstrate state of the art\nperformance compared with alternative methods in the literature in both\ncompatibility prediction and fill-in-the-blank test. Qualitatively, we also\nshow that the item embedding learned by FashionRN indicate the compatibility\namong fashion items.\n", "versions": [{"version": "v1", "created": "Wed, 13 May 2020 21:00:54 GMT"}], "update_date": "2020-05-15", "authors_parsed": [["Moosaei", "Maryam", ""], ["Lin", "Yusan", ""], ["Yang", "Hao", ""]]}, {"id": "2005.06587", "submitter": "Bhanu Pratap Singh Rawat", "authors": "Bhanu Pratap Singh Rawat, Wei-Hung Weng, So Yeon Min, Preethi\n  Raghavan, Peter Szolovits", "title": "Entity-Enriched Neural Models for Clinical Question Answering", "comments": null, "journal-ref": "BioNLP Workshop, ACL'2020", "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We explore state-of-the-art neural models for question answering on\nelectronic medical records and improve their ability to generalize better on\npreviously unseen (paraphrased) questions at test time. We enable this by\nlearning to predict logical forms as an auxiliary task along with the main task\nof answer span detection. The predicted logical forms also serve as a rationale\nfor the answer. Further, we also incorporate medical entity information in\nthese models via the ERNIE architecture. We train our models on the large-scale\nemrQA dataset and observe that our multi-task entity-enriched models generalize\nto paraphrased questions ~5% better than the baseline BERT model.\n", "versions": [{"version": "v1", "created": "Wed, 13 May 2020 21:04:29 GMT"}, {"version": "v2", "created": "Sat, 20 Feb 2021 00:50:27 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Rawat", "Bhanu Pratap Singh", ""], ["Weng", "Wei-Hung", ""], ["Min", "So Yeon", ""], ["Raghavan", "Preethi", ""], ["Szolovits", "Peter", ""]]}, {"id": "2005.06612", "submitter": "Siyuan Liu", "authors": "Xiuyi Fan, Siyuan Liu, Jiarong Chen, Thomas C. Henderson", "title": "An Investigation of COVID-19 Spreading Factors with Explainable AI\n  Techniques", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Since COVID-19 was first identified in December 2019, various public health\ninterventions have been implemented across the world. As different measures are\nimplemented at different countries at different times, we conduct an assessment\nof the relative effectiveness of the measures implemented in 18 countries and\nregions using data from 22/01/2020 to 02/04/2020. We compute the top one and\ntwo measures that are most effective for the countries and regions studied\nduring the period. Two Explainable AI techniques, SHAP and ECPI, are used in\nour study; such that we construct (machine learning) models for predicting the\ninstantaneous reproduction number ($R_t$) and use the models as surrogates to\nthe real world and inputs that the greatest influence to our models are seen as\nmeasures that are most effective. Across-the-board, city lockdown and contact\ntracing are the two most effective measures. For ensuring $R_t<1$, public\nwearing face masks is also important. Mass testing alone is not the most\neffective measure although when paired with other measures, it can be\neffective. Warm temperature helps for reducing the transmission.\n", "versions": [{"version": "v1", "created": "Tue, 5 May 2020 12:01:12 GMT"}], "update_date": "2020-05-15", "authors_parsed": [["Fan", "Xiuyi", ""], ["Liu", "Siyuan", ""], ["Chen", "Jiarong", ""], ["Henderson", "Thomas C.", ""]]}, {"id": "2005.06616", "submitter": "Iulian Vlad Serban", "authors": "Iulian Vlad Serban, Varun Gupta, Ekaterina Kochmar, Dung D. Vu, Robert\n  Belfer, Joelle Pineau, Aaron Courville, Laurent Charlin, Yoshua Bengio", "title": "A Large-Scale, Open-Domain, Mixed-Interface Dialogue-Based ITS for STEM", "comments": "6 pages, 1 figure, 1 table, accepted for publication in the 21st\n  International Conference on Artificial Intelligence in Education (AIED 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.CL cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present Korbit, a large-scale, open-domain, mixed-interface,\ndialogue-based intelligent tutoring system (ITS). Korbit uses machine learning,\nnatural language processing and reinforcement learning to provide interactive,\npersonalized learning online. Korbit has been designed to easily scale to\nthousands of subjects, by automating, standardizing and simplifying the content\ncreation process. Unlike other ITS, a teacher can develop new learning modules\nfor Korbit in a matter of hours. To facilitate learning across a widerange of\nSTEM subjects, Korbit uses a mixed-interface, which includes videos,\ninteractive dialogue-based exercises, question-answering, conceptual diagrams,\nmathematical exercises and gamification elements. Korbit has been built to\nscale to millions of students, by utilizing a state-of-the-art cloud-based\nmicro-service architecture. Korbit launched its first course in 2019 on machine\nlearning, and since then over 7,000 students have enrolled. Although Korbit was\ndesigned to be open-domain and highly scalable, A/B testing experiments with\nreal-world students demonstrate that both student learning outcomes and student\nmotivation are substantially improved compared to typical online courses.\n", "versions": [{"version": "v1", "created": "Wed, 6 May 2020 02:45:43 GMT"}], "update_date": "2020-05-15", "authors_parsed": [["Serban", "Iulian Vlad", ""], ["Gupta", "Varun", ""], ["Kochmar", "Ekaterina", ""], ["Vu", "Dung D.", ""], ["Belfer", "Robert", ""], ["Pineau", "Joelle", ""], ["Courville", "Aaron", ""], ["Charlin", "Laurent", ""], ["Bengio", "Yoshua", ""]]}, {"id": "2005.06641", "submitter": "Noga Zaslavsky", "authors": "Noga Zaslavsky, Jennifer Hu, Roger P. Levy", "title": "A Rate-Distortion view of human pragmatic reasoning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  What computational principles underlie human pragmatic reasoning? A prominent\napproach to pragmatics is the Rational Speech Act (RSA) framework, which\nformulates pragmatic reasoning as probabilistic speakers and listeners\nrecursively reasoning about each other. While RSA enjoys broad empirical\nsupport, it is not yet clear whether the dynamics of such recursive reasoning\nmay be governed by a general optimization principle. Here, we present a novel\nanalysis of the RSA framework that addresses this question. First, we show that\nRSA recursion implements an alternating maximization for optimizing a tradeoff\nbetween expected utility and communicative effort. On that basis, we study the\ndynamics of RSA recursion and disconfirm the conjecture that expected utility\nis guaranteed to improve with recursion depth. Second, we show that RSA can be\ngrounded in Rate-Distortion theory, while maintaining a similar ability to\naccount for human behavior and avoiding a bias of RSA toward random utterance\nproduction. This work furthers the mathematical understanding of RSA models,\nand suggests that general information-theoretic principles may give rise to\nhuman pragmatic reasoning.\n", "versions": [{"version": "v1", "created": "Wed, 13 May 2020 22:04:27 GMT"}], "update_date": "2020-05-15", "authors_parsed": [["Zaslavsky", "Noga", ""], ["Hu", "Jennifer", ""], ["Levy", "Roger P.", ""]]}, {"id": "2005.06695", "submitter": "Conrad Sanderson", "authors": "Majid Namazi, Conrad Sanderson, M.A. Hakim Newton, Abdul Sattar", "title": "Surrogate Assisted Optimisation for Travelling Thief Problems", "comments": null, "journal-ref": "Symposium on Combinatorial Search (SoCS) 2020", "doi": null, "report-no": null, "categories": "cs.AI math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The travelling thief problem (TTP) is a multi-component optimisation problem\ninvolving two interdependent NP-hard components: the travelling salesman\nproblem (TSP) and the knapsack problem (KP). Recent state-of-the-art TTP\nsolvers modify the underlying TSP and KP solutions in an iterative and\ninterleaved fashion. The TSP solution (cyclic tour) is typically changed in a\ndeterministic way, while changes to the KP solution typically involve a random\nsearch, effectively resulting in a quasi-meandering exploration of the TTP\nsolution space. Once a plateau is reached, the iterative search of the TTP\nsolution space is restarted by using a new initial TSP tour. We propose to make\nthe search more efficient through an adaptive surrogate model (based on a\ncustomised form of Support Vector Regression) that learns the characteristics\nof initial TSP tours that lead to good TTP solutions. The model is used to\nfilter out non-promising initial TSP tours, in effect reducing the amount of\ntime spent to find a good TTP solution. Experiments on a broad range of\nbenchmark TTP instances indicate that the proposed approach filters out a\nconsiderable number of non-promising initial tours, at the cost of omitting\nonly a small number of the best TTP solutions.\n", "versions": [{"version": "v1", "created": "Thu, 14 May 2020 02:49:16 GMT"}], "update_date": "2020-06-03", "authors_parsed": [["Namazi", "Majid", ""], ["Sanderson", "Conrad", ""], ["Newton", "M. A. Hakim", ""], ["Sattar", "Abdul", ""]]}, {"id": "2005.06764", "submitter": "Diego Perez Liebana Dr.", "authors": "Diego Perez-Liebana, Muhammad Sajid Alam, Raluca D. Gaina", "title": "Rolling Horizon NEAT for General Video Game Playing", "comments": "8 pages, 5 figures, accepted for publication in IEEE Conference on\n  Games (CoG) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper presents a new Statistical Forward Planning (SFP) method, Rolling\nHorizon NeuroEvolution of Augmenting Topologies (rhNEAT). Unlike traditional\nRolling Horizon Evolution, where an evolutionary algorithm is in charge of\nevolving a sequence of actions, rhNEAT evolves weights and connections of a\nneural network in real-time, planning several steps ahead before returning an\naction to execute in the game. Different versions of the algorithm are explored\nin a collection of 20 GVGAI games, and compared with other SFP methods and\nstate of the art results. Although results are overall not better than other\nSFP methods, the nature of rhNEAT to adapt to changing game features has\nallowed to establish new state of the art records in games that other methods\nhave traditionally struggled with. The algorithm proposed here is general and\nintroduces a new way of representing information within rolling horizon\nevolution techniques.\n", "versions": [{"version": "v1", "created": "Thu, 14 May 2020 07:25:23 GMT"}], "update_date": "2020-05-15", "authors_parsed": [["Perez-Liebana", "Diego", ""], ["Alam", "Muhammad Sajid", ""], ["Gaina", "Raluca D.", ""]]}, {"id": "2005.06850", "submitter": "Thomas Hiessl", "authors": "Thomas Hiessl, Daniel Schall, Jana Kemnitz, Stefan Schulte", "title": "Industrial Federated Learning -- Requirements and System Design", "comments": "12 pages, accepted for https://www.paams.net/workshops/agedai", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated Learning (FL) is a very promising approach for improving\ndecentralized Machine Learning (ML) models by exchanging knowledge between\nparticipating clients without revealing private data. Nevertheless, FL is still\nnot tailored to the industrial context as strong data similarity is assumed for\nall FL tasks. This is rarely the case in industrial machine data with\nvariations in machine type, operational- and environmental conditions.\nTherefore, we introduce an Industrial Federated Learning (IFL) system\nsupporting knowledge exchange in continuously evaluated and updated FL cohorts\nof learning tasks with sufficient data similarity. This enables optimal\ncollaboration of business partners in common ML problems, prevents negative\nknowledge transfer, and ensures resource optimization of involved edge devices.\n", "versions": [{"version": "v1", "created": "Thu, 14 May 2020 10:07:48 GMT"}], "update_date": "2020-05-15", "authors_parsed": [["Hiessl", "Thomas", ""], ["Schall", "Daniel", ""], ["Kemnitz", "Jana", ""], ["Schulte", "Stefan", ""]]}, {"id": "2005.06852", "submitter": "Pieter Delobelle", "authors": "Pieter Delobelle and Paul Temple and Gilles Perrouin and Beno\\^it\n  Fr\\'enay and Patrick Heymans and Bettina Berendt", "title": "Ethical Adversaries: Towards Mitigating Unfairness with Adversarial\n  Machine Learning", "comments": "15 pages, 3 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning is being integrated into a growing number of critical\nsystems with far-reaching impacts on society. Unexpected behaviour and unfair\ndecision processes are coming under increasing scrutiny due to this widespread\nuse and its theoretical considerations. Individuals, as well as organisations,\nnotice, test, and criticize unfair results to hold model designers and\ndeployers accountable. We offer a framework that assists these groups in\nmitigating unfair representations stemming from the training datasets. Our\nframework relies on two inter-operating adversaries to improve fairness. First,\na model is trained with the goal of preventing the guessing of protected\nattributes' values while limiting utility losses. This first step optimizes the\nmodel's parameters for fairness. Second, the framework leverages evasion\nattacks from adversarial machine learning to generate new examples that will be\nmisclassified. These new examples are then used to retrain and improve the\nmodel in the first step. These two steps are iteratively applied until a\nsignificant improvement in fairness is obtained. We evaluated our framework on\nwell-studied datasets in the fairness literature -- including COMPAS -- where\nit can surpass other approaches concerning demographic parity, equality of\nopportunity and also the model's utility. We also illustrate our findings on\nthe subtle difficulties when mitigating unfairness and highlight how our\nframework can assist model designers.\n", "versions": [{"version": "v1", "created": "Thu, 14 May 2020 10:10:19 GMT"}, {"version": "v2", "created": "Tue, 1 Sep 2020 16:47:17 GMT"}], "update_date": "2020-09-02", "authors_parsed": [["Delobelle", "Pieter", ""], ["Temple", "Paul", ""], ["Perrouin", "Gilles", ""], ["Fr\u00e9nay", "Beno\u00eet", ""], ["Heymans", "Patrick", ""], ["Berendt", "Bettina", ""]]}, {"id": "2005.06879", "submitter": "Shikui Tu", "authors": "Zhihao Xing, Shikui Tu, Lei Xu", "title": "Solve Traveling Salesman Problem by Monte Carlo Tree Search and Deep\n  Neural Network", "comments": "Was previously submitted to ICAPS2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a self-learning approach that combines deep reinforcement learning\nand Monte Carlo tree search to solve the traveling salesman problem. The\nproposed approach has two advantages. First, it adopts deep reinforcement\nlearning to compute the value functions for decision, which removes the need of\nhand-crafted features and labelled data. Second, it uses Monte Carlo tree\nsearch to select the best policy by comparing different value functions, which\nincreases its generalization ability. Experimental results show that the\nproposed method performs favorably against other methods in small-to-medium\nproblem settings. And it shows comparable performance as state-of-the-art in\nlarge problem setting.\n", "versions": [{"version": "v1", "created": "Thu, 14 May 2020 11:36:40 GMT"}], "update_date": "2020-05-15", "authors_parsed": [["Xing", "Zhihao", ""], ["Tu", "Shikui", ""], ["Xu", "Lei", ""]]}, {"id": "2005.06885", "submitter": "Bing Huang", "authors": "Bing Huang, Athman Bouguettaya, Hai Dong", "title": "Enabling Edge Cloud Intelligence for Activity Learning in Smart Home", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel activity learning framework based on Edge Cloud\narchitecture for the purpose of recognizing and predicting human activities.\nAlthough activity recognition has been vastly studied by many researchers, the\ntemporal features that constitute an activity, which can provide useful\ninsights for activity models, have not been exploited to their full potentials\nby mining algorithms. In this paper, we utilize temporal features for activity\nrecognition and prediction in a single smart home setting. We discover activity\npatterns and temporal relations such as the order of activities from real data\nto develop a prompting system. Analysis of real data collected from smart homes\nwas used to validate the proposed method.\n", "versions": [{"version": "v1", "created": "Thu, 14 May 2020 11:43:20 GMT"}], "update_date": "2020-05-15", "authors_parsed": [["Huang", "Bing", ""], ["Bouguettaya", "Athman", ""], ["Dong", "Hai", ""]]}, {"id": "2005.06895", "submitter": "Bing Huang", "authors": "Bing Huang, Athman Bouguettaya", "title": "Service mining for Internet of Things", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A service mining framework is proposed that enables discovering interesting\nrelationships in Internet of Things services bottom-up. The service\nrelationships are modeled based on spatial-temporal aspects, environment,\npeople, and operation. An ontology-based service model is proposed to describe\nservices. We present a set of metrics to evaluate the interestingness of\ndiscovered service relationships. Analytical and simulation results are\npresented to show the effectiveness of the proposed evaluation measures.\n", "versions": [{"version": "v1", "created": "Thu, 14 May 2020 11:58:34 GMT"}, {"version": "v2", "created": "Tue, 9 Jun 2020 01:44:15 GMT"}], "update_date": "2020-06-11", "authors_parsed": [["Huang", "Bing", ""], ["Bouguettaya", "Athman", ""]]}, {"id": "2005.06914", "submitter": "Bing Huang", "authors": "Bing Huang, Athman Bouguettaya, Azadeh Ghari Neiat", "title": "Cognitive Amplifier for Internet of Things", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a Cognitive Amplifier framework to augment things part of an IoT,\nwith cognitive capabilities for the purpose of improving life convenience.\nSpecifically, the Cognitive Amplifier consists of knowledge discovery and\nprediction components. The knowledge discovery component focuses on finding\nnatural activity patterns considering their regularity, variations, and\ntransitions in real life setting. The prediction component takes the discovered\nknowledge as the base for inferring what, when, and where the next activity\nwill happen. Experimental results on real-life data validate the feasibility\nand applicability of the proposed approach.\n", "versions": [{"version": "v1", "created": "Thu, 14 May 2020 12:30:42 GMT"}], "update_date": "2020-05-15", "authors_parsed": [["Huang", "Bing", ""], ["Bouguettaya", "Athman", ""], ["Neiat", "Azadeh Ghari", ""]]}, {"id": "2005.06922", "submitter": "Priyanka Golia", "authors": "Priyanka Golia, Subhajit Roy, and Kuldeep S. Meel", "title": "Manthan: A Data Driven Approach for Boolean Function Synthesis", "comments": "24 pages including references, and 8 figures. To be published in 32nd\n  International Conference on Computer-Aided Verification (CAV-2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Boolean functional synthesis is a fundamental problem in computer science\nwith wide-ranging applications and has witnessed a surge of interest resulting\nin progressively improved techniques over the past decade. Despite intense\nalgorithmic development, a large number of problems remain beyond the reach of\nthe state of the art techniques. Motivated by the progress in machine learning,\nwe propose Manthan, a novel data-driven approach to Boolean functional\nsynthesis. Manthan views functional synthesis as a classification problem,\nrelying on advances in constrained sampling for data generation, and advances\nin automated reasoning for a novel proof-guided refinement and provable\nverification. On an extensive and rigorous evaluation over 609 benchmarks, we\ndemonstrate that Manthan significantly improves upon the current state of the\nart, solving 356 benchmarks in comparison to 280, which is the most solved by a\nstate of the art technique; thereby, we demonstrate an increase of 76\nbenchmarks over the current state of the art. Furthermore, Manthan solves 60\nbenchmarks that none of the current state of the art techniques could solve.\nThe significant performance improvements, along with our detailed analysis,\nhighlights several interesting avenues of future work at the intersection of\nmachine learning, constrained sampling, and automated reasoning.\n", "versions": [{"version": "v1", "created": "Thu, 14 May 2020 12:44:21 GMT"}], "update_date": "2020-05-15", "authors_parsed": [["Golia", "Priyanka", ""], ["Roy", "Subhajit", ""], ["Meel", "Kuldeep S.", ""]]}, {"id": "2005.07023", "submitter": "Alessandro Paolo Capasso", "authors": "Alessandro Paolo Capasso, Giulio Bacchiani, Alberto Broggi", "title": "From Simulation to Real World Maneuver Execution using Deep\n  Reinforcement Learning", "comments": "Intelligent Vehicle Symposium 2020 (IV2020)", "journal-ref": "2020 IEEE Intelligent Vehicles Symposium (IV)", "doi": "10.1109/IV47402.2020.9304593", "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Reinforcement Learning has proved to be able to solve many control tasks\nin different fields, but the behavior of these systems is not always as\nexpected when deployed in real-world scenarios. This is mainly due to the lack\nof domain adaptation between simulated and real-world data together with the\nabsence of distinction between train and test datasets. In this work, we\ninvestigate these problems in the autonomous driving field, especially for a\nmaneuver planning module for roundabout insertions. In particular, we present a\nsystem based on multiple environments in which agents are trained\nsimultaneously, evaluating the behavior of the model in different scenarios.\nFinally, we analyze techniques aimed at reducing the gap between simulated and\nreal-world data showing that this increased the generalization capabilities of\nthe system both on unseen and real-world scenarios.\n", "versions": [{"version": "v1", "created": "Wed, 13 May 2020 14:22:20 GMT"}, {"version": "v2", "created": "Tue, 30 Jun 2020 11:57:30 GMT"}, {"version": "v3", "created": "Sat, 26 Dec 2020 18:19:21 GMT"}, {"version": "v4", "created": "Wed, 28 Apr 2021 08:11:02 GMT"}], "update_date": "2021-04-29", "authors_parsed": [["Capasso", "Alessandro Paolo", ""], ["Bacchiani", "Giulio", ""], ["Broggi", "Alberto", ""]]}, {"id": "2005.07025", "submitter": "Kun Zhou", "authors": "Kun Zhou, Berrak Sisman, Mingyang Zhang and Haizhou Li", "title": "Converting Anyone's Emotion: Towards Speaker-Independent Emotional Voice\n  Conversion", "comments": "Accepted by Interspeech 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.AI cs.CL eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Emotional voice conversion aims to convert the emotion of speech from one\nstate to another while preserving the linguistic content and speaker identity.\nThe prior studies on emotional voice conversion are mostly carried out under\nthe assumption that emotion is speaker-dependent. We consider that there is a\ncommon code between speakers for emotional expression in a spoken language,\ntherefore, a speaker-independent mapping between emotional states is possible.\nIn this paper, we propose a speaker-independent emotional voice conversion\nframework, that can convert anyone's emotion without the need for parallel\ndata. We propose a VAW-GAN based encoder-decoder structure to learn the\nspectrum and prosody mapping. We perform prosody conversion by using continuous\nwavelet transform (CWT) to model the temporal dependencies. We also investigate\nthe use of F0 as an additional input to the decoder to improve emotion\nconversion performance. Experiments show that the proposed speaker-independent\nframework achieves competitive results for both seen and unseen speakers.\n", "versions": [{"version": "v1", "created": "Wed, 13 May 2020 13:36:34 GMT"}, {"version": "v2", "created": "Fri, 7 Aug 2020 13:37:48 GMT"}, {"version": "v3", "created": "Tue, 13 Oct 2020 06:07:16 GMT"}], "update_date": "2020-10-14", "authors_parsed": [["Zhou", "Kun", ""], ["Sisman", "Berrak", ""], ["Zhang", "Mingyang", ""], ["Li", "Haizhou", ""]]}, {"id": "2005.07050", "submitter": "Gustavo Bodanza", "authors": "Gustavo A. Bodanza", "title": "On abstract F-systems. A graph-theoretic model for paradoxes involving a\n  falsity predicate and its application to argumentation frameworks", "comments": "16 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.LO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  F-systems are digraphs that enable to model sentences that predicate the\nfalsity of other sentences. Paradoxes like the Liar and Yablo's can be analyzed\nwith that tool to find graph-theoretic patterns. In this paper we present the\nF-systems model abstracting from all the features of the language in which the\nrepresented sentences are expressed. All that is assumed is the existence of\nsentences and the binary relation '... affirms the falsity of ...' among them.\nThe possible existence of non-referential sentences is also considered. To\nmodel the sets of all the sentences that can jointly be valued as true we\nintroduce the notion of conglomerate, the existence of which guarantees the\nabsence of paradox. Conglomerates also enable to characterize referential\ncontradictions, i.e. sentences that can only be false under a classical\nvaluation due to the interactions with other sentences in the model. A Kripke's\nstyle fixed point characterization of groundedness is offered and fixed points\nwhich are complete (meaning that every sentence is deemed either true or false)\nand consistent (meaning that no sentence is deemed true and false) are put in\ncorrespondence with conglomerates. Furthermore, argumentation frameworks are\nspecial cases of F-systems. We show the relation between local conglomerates\nand admissible sets of arguments and argue about the usefulness of the concept\nfor argumentation theory.\n", "versions": [{"version": "v1", "created": "Thu, 14 May 2020 15:07:11 GMT"}], "update_date": "2020-05-15", "authors_parsed": [["Bodanza", "Gustavo A.", ""]]}, {"id": "2005.07064", "submitter": "Angeliki  Lazaridou", "authors": "Angeliki Lazaridou, Anna Potapenko, Olivier Tieleman", "title": "Multi-agent Communication meets Natural Language: Synergies between\n  Functional and Structural Language Learning", "comments": "to appear at ACL 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a method for combining multi-agent communication and traditional\ndata-driven approaches to natural language learning, with an end goal of\nteaching agents to communicate with humans in natural language. Our starting\npoint is a language model that has been trained on generic, not task-specific\nlanguage data. We then place this model in a multi-agent self-play environment\nthat generates task-specific rewards used to adapt or modulate the model,\nturning it into a task-conditional language model. We introduce a new way for\ncombining the two types of learning based on the idea of reranking language\nmodel samples, and show that this method outperforms others in communicating\nwith humans in a visual referential communication task. Finally, we present a\ntaxonomy of different types of language drift that can occur alongside a set of\nmeasures to detect them.\n", "versions": [{"version": "v1", "created": "Thu, 14 May 2020 15:32:23 GMT"}], "update_date": "2020-05-15", "authors_parsed": [["Lazaridou", "Angeliki", ""], ["Potapenko", "Anna", ""], ["Tieleman", "Olivier", ""]]}, {"id": "2005.07073", "submitter": "Edoardo Bacci", "authors": "Edoardo Bacci and David Parker", "title": "Probabilistic Guarantees for Safe Deep Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep reinforcement learning has been successfully applied to many control\ntasks, but the application of such agents in safety-critical scenarios has been\nlimited due to safety concerns. Rigorous testing of these controllers is\nchallenging, particularly when they operate in probabilistic environments due\nto, for example, hardware faults or noisy sensors. We propose MOSAIC, an\nalgorithm for measuring the safety of deep reinforcement learning agents in\nstochastic settings. Our approach is based on the iterative construction of a\nformal abstraction of a controller's execution in an environment, and leverages\nprobabilistic model checking of Markov decision processes to produce\nprobabilistic guarantees on safe behaviour over a finite time horizon. It\nproduces bounds on the probability of safe operation of the controller for\ndifferent initial configurations and identifies regions where correct behaviour\ncan be guaranteed. We implement and evaluate our approach on agents trained for\nseveral benchmark control problems.\n", "versions": [{"version": "v1", "created": "Thu, 14 May 2020 15:42:19 GMT"}, {"version": "v2", "created": "Wed, 8 Jul 2020 09:55:04 GMT"}], "update_date": "2020-07-09", "authors_parsed": [["Bacci", "Edoardo", ""], ["Parker", "David", ""]]}, {"id": "2005.07099", "submitter": "Jianwen Sun Dr", "authors": "Jianwen Sun, Tianwei Zhang, Xiaofei Xie, Lei Ma, Yan Zheng, Kangjie\n  Chen, Yang Liu", "title": "Stealthy and Efficient Adversarial Attacks against Deep Reinforcement\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial attacks against conventional Deep Learning (DL) systems and\nalgorithms have been widely studied, and various defenses were proposed.\nHowever, the possibility and feasibility of such attacks against Deep\nReinforcement Learning (DRL) are less explored. As DRL has achieved great\nsuccess in various complex tasks, designing effective adversarial attacks is an\nindispensable prerequisite towards building robust DRL algorithms. In this\npaper, we introduce two novel adversarial attack techniques to\n\\emph{stealthily} and \\emph{efficiently} attack the DRL agents. These two\ntechniques enable an adversary to inject adversarial samples in a minimal set\nof critical moments while causing the most severe damage to the agent. The\nfirst technique is the \\emph{critical point attack}: the adversary builds a\nmodel to predict the future environmental states and agent's actions, assesses\nthe damage of each possible attack strategy, and selects the optimal one. The\nsecond technique is the \\emph{antagonist attack}: the adversary automatically\nlearns a domain-agnostic model to discover the critical moments of attacking\nthe agent in an episode. Experimental results demonstrate the effectiveness of\nour techniques. Specifically, to successfully attack the DRL agent, our\ncritical point technique only requires 1 (TORCS) or 2 (Atari Pong and Breakout)\nsteps, and the antagonist technique needs fewer than 5 steps (4 Mujoco tasks),\nwhich are significant improvements over state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Thu, 14 May 2020 16:06:38 GMT"}], "update_date": "2020-05-15", "authors_parsed": [["Sun", "Jianwen", ""], ["Zhang", "Tianwei", ""], ["Xie", "Xiaofei", ""], ["Ma", "Lei", ""], ["Zheng", "Yan", ""], ["Chen", "Kangjie", ""], ["Liu", "Yang", ""]]}, {"id": "2005.07156", "submitter": "Jack Reinhardt", "authors": "Jack Reinhardt", "title": "Competing in a Complex Hidden Role Game with Information Set Monte Carlo\n  Tree Search", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.MA", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Advances in intelligent game playing agents have led to successes in perfect\ninformation games like Go and imperfect information games like Poker. The\nInformation Set Monte Carlo Tree Search (ISMCTS) family of algorithms\noutperforms previous algorithms using Monte Carlo methods in imperfect\ninformation games. In this paper, Single Observer Information Set Monte Carlo\nTree Search (SO-ISMCTS) is applied to Secret Hitler, a popular social deduction\nboard game that combines traditional hidden role mechanics with the randomness\nof a card deck. This combination leads to a more complex information model than\nthe hidden role and card deck mechanics alone. It is shown in 10108 simulated\ngames that SO-ISMCTS plays as well as simpler rule based agents, and\ndemonstrates the potential of ISMCTS algorithms in complicated information set\ndomains.\n", "versions": [{"version": "v1", "created": "Thu, 14 May 2020 17:21:10 GMT"}], "update_date": "2020-05-15", "authors_parsed": [["Reinhardt", "Jack", ""]]}, {"id": "2005.07235", "submitter": "Antonio Mora Dr.", "authors": "A.M. Mora, A.I. Esparcia-Alc\\'azar", "title": "Evo* 2020 -- Late-Breaking Abstracts Volume", "comments": "LBAs accepted in Evo* 2020. Part of the Conference Proceedings", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This volume contains the Late-Breaking Abstracts submitted to the Evo* 2020\nConference, that took place online, from 15 to 17 of April 2020. These papers\nwhere presented as short talks and also at the poster session of the conference\ntogether with other regular submissions. All of them present ongoing research\nand preliminary results investigating on the application of different\napproaches of Bioinspired Methods (mainly Evolutionary Computation) to\ndifferent problems, most of them real world ones.\n", "versions": [{"version": "v1", "created": "Thu, 14 May 2020 19:37:34 GMT"}], "update_date": "2020-05-18", "authors_parsed": [["Mora", "A. M.", ""], ["Esparcia-Alc\u00e1zar", "A. I.", ""]]}, {"id": "2005.07293", "submitter": "Ninareh Mehrabi", "authors": "Ninareh Mehrabi, Yuzhong Huang, Fred Morstatter", "title": "Statistical Equity: A Fairness Classification Objective", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning systems have been shown to propagate the societal errors of\nthe past. In light of this, a wealth of research focuses on designing solutions\nthat are \"fair.\" Even with this abundance of work, there is no singular\ndefinition of fairness, mainly because fairness is subjective and context\ndependent. We propose a new fairness definition, motivated by the principle of\nequity, that considers existing biases in the data and attempts to make\nequitable decisions that account for these previous historical biases. We\nformalize our definition of fairness, and motivate it with its appropriate\ncontexts. Next, we operationalize it for equitable classification. We perform\nmultiple automatic and human evaluations to show the effectiveness of our\ndefinition and demonstrate its utility for aspects of fairness, such as the\nfeedback loop.\n", "versions": [{"version": "v1", "created": "Thu, 14 May 2020 23:19:38 GMT"}], "update_date": "2020-05-18", "authors_parsed": [["Mehrabi", "Ninareh", ""], ["Huang", "Yuzhong", ""], ["Morstatter", "Fred", ""]]}, {"id": "2005.07328", "submitter": "Devi Parikh", "authors": "Devi Parikh and C. Lawrence Zitnick", "title": "Exploring Crowd Co-creation Scenarios for Sketches", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As a first step towards studying the ability of human crowds and machines to\neffectively co-create, we explore several human-only collaborative co-creation\nscenarios. The goal in each scenario is to create a digital sketch using a\nsimple web interface. We find that settings in which multiple humans\niteratively add strokes and vote on the best additions result in the sketches\nwith highest perceived creativity (value + novelty). Lack of collaboration\nleads to a higher variance in quality and lower novelty or surprise.\nCollaboration without voting leads to high novelty but low quality.\n", "versions": [{"version": "v1", "created": "Fri, 15 May 2020 02:28:35 GMT"}, {"version": "v2", "created": "Fri, 22 May 2020 02:12:21 GMT"}], "update_date": "2020-05-25", "authors_parsed": [["Parikh", "Devi", ""], ["Zitnick", "C. Lawrence", ""]]}, {"id": "2005.07362", "submitter": "Ryuichi Takanobu", "authors": "Ryuichi Takanobu, Qi Zhu, Jinchao Li, Baolin Peng, Jianfeng Gao,\n  Minlie Huang", "title": "Is Your Goal-Oriented Dialog Model Performing Really Well? Empirical\n  Analysis of System-wise Evaluation", "comments": "SIGDIAL 2020 long paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is a growing interest in developing goal-oriented dialog systems which\nserve users in accomplishing complex tasks through multi-turn conversations.\nAlthough many methods are devised to evaluate and improve the performance of\nindividual dialog components, there is a lack of comprehensive empirical study\non how different components contribute to the overall performance of a dialog\nsystem. In this paper, we perform a system-wise evaluation and present an\nempirical analysis on different types of dialog systems which are composed of\ndifferent modules in different settings. Our results show that (1) a pipeline\ndialog system trained using fine-grained supervision signals at different\ncomponent levels often obtains better performance than the systems that use\njoint or end-to-end models trained on coarse-grained labels, (2)\ncomponent-wise, single-turn evaluation results are not always consistent with\nthe overall performance of a dialog system, and (3) despite the discrepancy\nbetween simulators and human users, simulated evaluation is still a valid\nalternative to the costly human evaluation especially in the early stage of\ndevelopment.\n", "versions": [{"version": "v1", "created": "Fri, 15 May 2020 05:20:06 GMT"}], "update_date": "2020-05-18", "authors_parsed": [["Takanobu", "Ryuichi", ""], ["Zhu", "Qi", ""], ["Li", "Jinchao", ""], ["Peng", "Baolin", ""], ["Gao", "Jianfeng", ""], ["Huang", "Minlie", ""]]}, {"id": "2005.07371", "submitter": "Jiaoyang Li", "authors": "Jiaoyang Li, Andrew Tinka, Scott Kiesel, Joseph W. Durham, T. K.\n  Satish Kumar and Sven Koenig", "title": "Lifelong Multi-Agent Path Finding in Large-Scale Warehouses", "comments": "Published at AAAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.MA cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-Agent Path Finding (MAPF) is the problem of moving a team of agents to\ntheir goal locations without collisions. In this paper, we study the lifelong\nvariant of MAPF, where agents are constantly engaged with new goal locations,\nsuch as in large-scale automated warehouses. We propose a new framework\nRolling-Horizon Collision Resolution (RHCR) for solving lifelong MAPF by\ndecomposing the problem into a sequence of Windowed MAPF instances, where a\nWindowed MAPF solver resolves collisions among the paths of the agents only\nwithin a bounded time horizon and ignores collisions beyond it. RHCR is\nparticularly well suited to generating pliable plans that adapt to continually\narriving new goal locations. We empirically evaluate RHCR with a variety of\nMAPF solvers and show that it can produce high-quality solutions for up to\n1,000 agents (= 38.9\\% of the empty cells on the map) for simulated warehouse\ninstances, significantly outperforming existing work.\n", "versions": [{"version": "v1", "created": "Fri, 15 May 2020 06:07:15 GMT"}, {"version": "v2", "created": "Fri, 12 Mar 2021 18:56:15 GMT"}], "update_date": "2021-03-15", "authors_parsed": [["Li", "Jiaoyang", ""], ["Tinka", "Andrew", ""], ["Kiesel", "Scott", ""], ["Durham", "Joseph W.", ""], ["Kumar", "T. K. Satish", ""], ["Koenig", "Sven", ""]]}, {"id": "2005.07376", "submitter": "Zimeng Lyu", "authors": "Zimeng Lyu, Joshua Karns, AbdElRahman ElSaid, Travis Desell", "title": "Improving Neuroevolution Using Island Extinction and Repopulation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neuroevolution commonly uses speciation strategies to better explore the\nsearch space of neural network architectures. One such speciation strategy is\nthrough the use of islands, which are also popular in improving performance and\nconvergence of distributed evolutionary algorithms. However, in this approach\nsome islands can become stagnant and not find new best solutions. In this\npaper, we propose utilizing extinction events and island repopulation to avoid\npremature convergence. We explore this with the Evolutionary eXploration of\nAugmenting Memory Models (EXAMM) neuro-evolution algorithm. In this strategy,\nall members of the worst performing island are killed of periodically and\nrepopulated with mutated versions of the global best genome. This island based\nstrategy is additionally compared to NEAT's (NeuroEvolution of Augmenting\nTopologies) speciation strategy. Experiments were performed using two different\nreal world time series datasets (coal-fired power plant and aviation flight\ndata). The results show that with statistical significance, this island\nextinction and repopulation strategy evolves better global best genomes than\nboth EXAMM's original island based strategy and NEAT's speciation strategy.\n", "versions": [{"version": "v1", "created": "Fri, 15 May 2020 06:47:41 GMT"}], "update_date": "2020-05-18", "authors_parsed": [["Lyu", "Zimeng", ""], ["Karns", "Joshua", ""], ["ElSaid", "AbdElRahman", ""], ["Desell", "Travis", ""]]}, {"id": "2005.07385", "submitter": "Mattias Tiger", "authors": "Mattias Tiger, David Bergstr\\\"om, Andreas Norrstig, Fredrik Heintz", "title": "Enhancing Lattice-based Motion Planning with Introspective Learning and\n  Reasoning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Lattice-based motion planning is a hybrid planning method where a plan made\nup of discrete actions simultaneously is a physically feasible trajectory. The\nplanning takes both discrete and continuous aspects into account, for example\naction pre-conditions and collision-free action-duration in the configuration\nspace. Safe motion planing rely on well-calibrated safety-margins for collision\nchecking. The trajectory tracking controller must further be able to reliably\nexecute the motions within this safety margin for the execution to be safe. In\nthis work we are concerned with introspective learning and reasoning about\ncontroller performance over time. Normal controller execution of the different\nactions is learned using reliable and uncertainty-aware machine learning\ntechniques. By correcting for execution bias we manage to substantially reduce\nthe safety margin of motion actions. Reasoning takes place to both verify that\nthe learned models stays safe and to improve collision checking effectiveness\nin the motion planner by the use of more accurate execution predictions with a\nsmaller safety margin. The presented approach allows for explicit awareness of\ncontroller performance under normal circumstances, and timely detection of\nincorrect performance in abnormal circumstances. Evaluation is made on the\nnonlinear dynamics of a quadcopter in 3D using simulation. Video:\nhttps://youtu.be/STmZduvSUMM\n", "versions": [{"version": "v1", "created": "Fri, 15 May 2020 07:16:51 GMT"}], "update_date": "2020-05-18", "authors_parsed": [["Tiger", "Mattias", ""], ["Bergstr\u00f6m", "David", ""], ["Norrstig", "Andreas", ""], ["Heintz", "Fredrik", ""]]}, {"id": "2005.07404", "submitter": "Thomas Moerland", "authors": "Thomas M. Moerland, Anna Deichler, Simone Baldi, Joost Broekens and\n  Catholijn M. Jonker", "title": "Think Too Fast Nor Too Slow: The Computational Trade-off Between\n  Planning And Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Planning and reinforcement learning are two key approaches to sequential\ndecision making. Multi-step approximate real-time dynamic programming, a\nrecently successful algorithm class of which AlphaZero [Silver et al., 2018] is\nan example, combines both by nesting planning within a learning loop. However,\nthe combination of planning and learning introduces a new question: how should\nwe balance time spend on planning, learning and acting? The importance of this\ntrade-off has not been explicitly studied before. We show that it is actually\nof key importance, with computational results indicating that we should neither\nplan too long nor too short. Conceptually, we identify a new spectrum of\nplanning-learning algorithms which ranges from exhaustive search (long\nplanning) to model-free RL (no planning), with optimal performance achieved\nmidway.\n", "versions": [{"version": "v1", "created": "Fri, 15 May 2020 08:20:08 GMT"}], "update_date": "2020-05-18", "authors_parsed": [["Moerland", "Thomas M.", ""], ["Deichler", "Anna", ""], ["Baldi", "Simone", ""], ["Broekens", "Joost", ""], ["Jonker", "Catholijn M.", ""]]}, {"id": "2005.07415", "submitter": "Marcelo Rodrigues de Holanda Maia", "authors": "Marcelo Rodrigues de Holanda Maia (1) and Alexandre Plastino (1) and\n  Puca Huachi Vaz Penna (2) ((1) Universidade Federal Fluminense, (2)\n  Universidade Federal de Ouro Preto)", "title": "MineReduce: an approach based on data mining for problem size reduction", "comments": null, "journal-ref": null, "doi": "10.1016/j.cor.2020.104995", "report-no": null, "categories": "cs.AI math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hybrid variations of metaheuristics that include data mining strategies have\nbeen utilized to solve a variety of combinatorial optimization problems, with\nsuperior and encouraging results. Previous hybrid strategies applied mined\npatterns to guide the construction of initial solutions, leading to more\neffective exploration of the solution space. Solving a combinatorial\noptimization problem is usually a hard task because its solution space grows\nexponentially with its size. Therefore, problem size reduction is also a useful\nstrategy in this context, especially in the case of large-scale problems. In\nthis paper, we build upon these ideas by presenting an approach named\nMineReduce, which uses mined patterns to perform problem size reduction. We\npresent an application of MineReduce to improve a heuristic for the\nheterogeneous fleet vehicle routing problem. The results obtained in\ncomputational experiments show that this proposed heuristic demonstrates\nsuperior performance compared to the original heuristic and other\nstate-of-the-art heuristics, achieving better solution costs with shorter run\ntimes.\n", "versions": [{"version": "v1", "created": "Fri, 15 May 2020 08:49:50 GMT"}, {"version": "v2", "created": "Fri, 22 May 2020 16:36:54 GMT"}], "update_date": "2020-05-25", "authors_parsed": [["Maia", "Marcelo Rodrigues de Holanda", ""], ["Plastino", "Alexandre", ""], ["Penna", "Puca Huachi Vaz", ""]]}, {"id": "2005.07464", "submitter": "Joel Colloc", "authors": "Jo\\\"el Colloc (IDEES), Danielle Boulanger", "title": "An Object Model for the Representation of Empirical Knowledge", "comments": "in French. Colloque International ICO'89, Jun 1989, Quebec, Canada", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We are currently designing an object oriented model which describes static\nand dynamical knowledge in diff{\\'e}rent domains. It provides a twin conceptual\nlevel. The internal level proposes: the object structure composed of\nsub-objects hierarchy, structure evolution with dynamical functions, same type\nobjects comparison with evaluation functions. It uses multiple upward\ninheritance from sub-objects properties to the Object. The external level\ndescribes: object environment, it enforces object types and uses external\nsimple inheritance from the type to the sub-types.\n", "versions": [{"version": "v1", "created": "Fri, 15 May 2020 10:45:58 GMT"}], "update_date": "2020-05-18", "authors_parsed": [["Colloc", "Jo\u00ebl", "", "IDEES"], ["Boulanger", "Danielle", ""]]}, {"id": "2005.07478", "submitter": "Sean Walton", "authors": "Sean P. Walton and Alma A. M. Rahat and James Stovold", "title": "Evaluating Mixed-Initiative Procedural Level Design Tools using a\n  Triple-Blind Mixed-Method User Study", "comments": "Accepted to be Published in: IEEE Transactions on Games", "journal-ref": null, "doi": "10.1109/TG.2021.3086215", "report-no": null, "categories": "cs.NE cs.AI cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Results from a triple-blind mixed-method user study into the effectiveness of\nmixed-initiative tools for the procedural generation of game levels are\npresented. A tool which generates levels using interactive evolutionary\noptimisation was designed for this study which (a) is focused on supporting the\ndesigner to explore the design space and (b) only requires the designer to\ninteract with it by designing levels. The tool identifies level design patterns\nin an initial hand-designed map and uses that information to drive an\ninteractive optimisation algorithm. A rigorous user study was designed which\ncompared the experiences of designers using the mixed-initiative tool to\ndesigners who were given a tool which provided completely random level\nsuggestions. The designers using the mixed-initiative tool showed an increased\nengagement in the level design task, reporting that it was effective in\ninspiring new ideas and design directions. This provides significant evidence\nthat procedural content generation can be used as a powerful tool to support\nthe human design process.\n", "versions": [{"version": "v1", "created": "Fri, 15 May 2020 11:40:53 GMT"}, {"version": "v2", "created": "Wed, 2 Jun 2021 08:46:49 GMT"}], "update_date": "2021-06-03", "authors_parsed": [["Walton", "Sean P.", ""], ["Rahat", "Alma A. M.", ""], ["Stovold", "James", ""]]}, {"id": "2005.07493", "submitter": "Shubham Agarwal", "authors": "Shubham Agarwal, Trung Bui, Joon-Young Lee, Ioannis Konstas, Verena\n  Rieser", "title": "History for Visual Dialog: Do we really need it?", "comments": "ACL'20", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Visual Dialog involves \"understanding\" the dialog history (what has been\ndiscussed previously) and the current question (what is asked), in addition to\ngrounding information in the image, to generate the correct response. In this\npaper, we show that co-attention models which explicitly encode dialog history\noutperform models that don't, achieving state-of-the-art performance (72 % NDCG\non val set). However, we also expose shortcomings of the crowd-sourcing dataset\ncollection procedure by showing that history is indeed only required for a\nsmall amount of the data and that the current evaluation metric encourages\ngeneric replies. To that end, we propose a challenging subset (VisDialConv) of\nthe VisDial val set and provide a benchmark of 63% NDCG.\n", "versions": [{"version": "v1", "created": "Fri, 8 May 2020 14:58:09 GMT"}], "update_date": "2020-05-18", "authors_parsed": [["Agarwal", "Shubham", ""], ["Bui", "Trung", ""], ["Lee", "Joon-Young", ""], ["Konstas", "Ioannis", ""], ["Rieser", "Verena", ""]]}, {"id": "2005.07513", "submitter": "Sandy Huang", "authors": "Abbas Abdolmaleki, Sandy H. Huang, Leonard Hasenclever, Michael\n  Neunert, H. Francis Song, Martina Zambelli, Murilo F. Martins, Nicolas Heess,\n  Raia Hadsell, Martin Riedmiller", "title": "A Distributional View on Multi-Objective Policy Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many real-world problems require trading off multiple competing objectives.\nHowever, these objectives are often in different units and/or scales, which can\nmake it challenging for practitioners to express numerical preferences over\nobjectives in their native units. In this paper we propose a novel algorithm\nfor multi-objective reinforcement learning that enables setting desired\npreferences for objectives in a scale-invariant way. We propose to learn an\naction distribution for each objective, and we use supervised learning to fit a\nparametric policy to a combination of these distributions. We demonstrate the\neffectiveness of our approach on challenging high-dimensional real and\nsimulated robotics tasks, and show that setting different preferences in our\nframework allows us to trace out the space of nondominated solutions.\n", "versions": [{"version": "v1", "created": "Fri, 15 May 2020 13:02:17 GMT"}], "update_date": "2020-05-18", "authors_parsed": [["Abdolmaleki", "Abbas", ""], ["Huang", "Sandy H.", ""], ["Hasenclever", "Leonard", ""], ["Neunert", "Michael", ""], ["Song", "H. Francis", ""], ["Zambelli", "Martina", ""], ["Martins", "Murilo F.", ""], ["Heess", "Nicolas", ""], ["Hadsell", "Raia", ""], ["Riedmiller", "Martin", ""]]}, {"id": "2005.07541", "submitter": "Tim Hertweck", "authors": "Tim Hertweck, Martin Riedmiller, Michael Bloesch, Jost Tobias\n  Springenberg, Noah Siegel, Markus Wulfmeier, Roland Hafner, Nicolas Heess", "title": "Simple Sensor Intentions for Exploration", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern reinforcement learning algorithms can learn solutions to increasingly\ndifficult control problems while at the same time reduce the amount of prior\nknowledge needed for their application. One of the remaining challenges is the\ndefinition of reward schemes that appropriately facilitate exploration without\nbiasing the solution in undesirable ways, and that can be implemented on real\nrobotic systems without expensive instrumentation. In this paper we focus on a\nsetting in which goal tasks are defined via simple sparse rewards, and\nexploration is facilitated via agent-internal auxiliary tasks. We introduce the\nidea of simple sensor intentions (SSIs) as a generic way to define auxiliary\ntasks. SSIs reduce the amount of prior knowledge that is required to define\nsuitable rewards. They can further be computed directly from raw sensor streams\nand thus do not require expensive and possibly brittle state estimation on real\nsystems. We demonstrate that a learning system based on these rewards can solve\ncomplex robotic tasks in simulation and in real world settings. In particular,\nwe show that a real robotic arm can learn to grasp and lift and solve a\nBall-in-a-Cup task from scratch, when only raw sensor streams are used for both\ncontroller input and in the auxiliary reward definition.\n", "versions": [{"version": "v1", "created": "Fri, 15 May 2020 13:46:55 GMT"}], "update_date": "2020-05-18", "authors_parsed": [["Hertweck", "Tim", ""], ["Riedmiller", "Martin", ""], ["Bloesch", "Michael", ""], ["Springenberg", "Jost Tobias", ""], ["Siegel", "Noah", ""], ["Wulfmeier", "Markus", ""], ["Hafner", "Roland", ""], ["Heess", "Nicolas", ""]]}, {"id": "2005.07647", "submitter": "Xavier Suau Cuadros", "authors": "Xavier Suau, Luca Zappella, Nicholas Apostoloff", "title": "Finding Experts in Transformer Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  In this work we study the presence of expert units in pre-trained Transformer\nModels (TM), and how they impact a model's performance. We define expert units\nto be neurons that are able to classify a concept with a given average\nprecision, where a concept is represented by a binary set of sentences\ncontaining the concept (or not). Leveraging the OneSec dataset (Scarlini et\nal., 2019), we compile a dataset of 1641 concepts that allows diverse expert\nunits in TM to be discovered. We show that expert units are important in\nseveral ways: (1) The presence of expert units is correlated ($r^2=0.833$) with\nthe generalization power of TM, which allows ranking TM without requiring\nfine-tuning on suites of downstream tasks. We further propose an empirical\nmethod to decide how accurate such experts should be to evaluate\ngeneralization. (2) The overlap of top experts between concepts provides a\nsensible way to quantify concept co-learning, which can be used for\nexplainability of unknown concepts. (3) We show how to self-condition\noff-the-shelf pre-trained language models to generate text with a given concept\nby forcing the top experts to be active, without requiring re-training the\nmodel or using additional parameters.\n", "versions": [{"version": "v1", "created": "Fri, 15 May 2020 17:07:02 GMT"}], "update_date": "2020-05-18", "authors_parsed": [["Suau", "Xavier", ""], ["Zappella", "Luca", ""], ["Apostoloff", "Nicholas", ""]]}, {"id": "2005.07648", "submitter": "Pierre Sermanet", "authors": "Corey Lynch and Pierre Sermanet", "title": "Language Conditioned Imitation Learning over Unstructured Data", "comments": "Published at RSS 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.CL cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Natural language is perhaps the most flexible and intuitive way for humans to\ncommunicate tasks to a robot. Prior work in imitation learning typically\nrequires each task be specified with a task id or goal image -- something that\nis often impractical in open-world environments. On the other hand, previous\napproaches in instruction following allow agent behavior to be guided by\nlanguage, but typically assume structure in the observations, actuators, or\nlanguage that limit their applicability to complex settings like robotics. In\nthis work, we present a method for incorporating free-form natural language\nconditioning into imitation learning. Our approach learns perception from\npixels, natural language understanding, and multitask continuous control\nend-to-end as a single neural network. Unlike prior work in imitation learning,\nour method is able to incorporate unlabeled and unstructured demonstration data\n(i.e. no task or language labels). We show this dramatically improves language\nconditioned performance, while reducing the cost of language annotation to less\nthan 1% of total data. At test time, a single language conditioned visuomotor\npolicy trained with our method can perform a wide variety of robotic\nmanipulation skills in a 3D environment, specified only with natural language\ndescriptions of each task (e.g. \"open the drawer...now pick up the block...now\npress the green button...\"). To scale up the number of instructions an agent\ncan follow, we propose combining text conditioned policies with large\npretrained neural language models. We find this allows a policy to be robust to\nmany out-of-distribution synonym instructions, without requiring new\ndemonstrations. See videos of a human typing live text commands to our agent at\nlanguage-play.github.io\n", "versions": [{"version": "v1", "created": "Fri, 15 May 2020 17:08:50 GMT"}, {"version": "v2", "created": "Wed, 7 Jul 2021 23:43:24 GMT"}], "update_date": "2021-07-09", "authors_parsed": [["Lynch", "Corey", ""], ["Sermanet", "Pierre", ""]]}, {"id": "2005.07654", "submitter": "Asan Agibetov", "authors": "Asan Agibetov, Matthias Samwald", "title": "Benchmarking neural embeddings for link prediction in knowledge graphs\n  under semantic and structural changes", "comments": null, "journal-ref": null, "doi": "10.1016/j.websem.2020.100590", "report-no": null, "categories": "cs.AI cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, link prediction algorithms based on neural embeddings have gained\ntremendous popularity in the Semantic Web community, and are extensively used\nfor knowledge graph completion. While algorithmic advances have strongly\nfocused on efficient ways of learning embeddings, fewer attention has been\ndrawn to the different ways their performance and robustness can be evaluated.\nIn this work we propose an open-source evaluation pipeline, which benchmarks\nthe accuracy of neural embeddings in situations where knowledge graphs may\nexperience semantic and structural changes. We define relation-centric\nconnectivity measures that allow us to connect the link prediction capacity to\nthe structure of the knowledge graph. Such an evaluation pipeline is especially\nimportant to simulate the accuracy of embeddings for knowledge graphs that are\nexpected to be frequently updated.\n", "versions": [{"version": "v1", "created": "Fri, 15 May 2020 17:15:45 GMT"}, {"version": "v2", "created": "Thu, 28 May 2020 08:11:29 GMT"}], "update_date": "2020-08-31", "authors_parsed": [["Agibetov", "Asan", ""], ["Samwald", "Matthias", ""]]}, {"id": "2005.07666", "submitter": "Tegg Sung", "authors": "Tegg Taekyong Sung, Jeongsoo Ha, Jeewoo Kim, Alex Yahja, Chae-Bong\n  Sohn, Bo Ryu", "title": "DeepSoCS: A Neural Scheduler for Heterogeneous System-on-Chip (SoC)\n  Resource Scheduling", "comments": "18 pages, Accepted by Electronics 2020", "journal-ref": null, "doi": "10.3390/electronics9060936", "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we~present a novel scheduling solution for a class of\nSystem-on-Chip (SoC) systems where heterogeneous chip resources (DSP, FPGA,\nGPU, etc.) must be efficiently scheduled for continuously arriving hierarchical\njobs with their tasks represented by a directed acyclic graph. Traditionally,\nheuristic algorithms have been widely used for many resource scheduling\ndomains, and Heterogeneous Earliest Finish Time (HEFT) has been a dominating\nstate-of-the-art technique across a broad range of heterogeneous resource\nscheduling domains over many years. Despite their long-standing popularity,\nHEFT-like algorithms are known to be vulnerable to a small amount of noise\nadded to the environment. Our Deep Reinforcement Learning (DRL)-based SoC\nScheduler (DeepSoCS), capable of learning the \"best\" task ordering under\ndynamic environment changes, overcomes the brittleness of rule-based schedulers\nsuch as HEFT with significantly higher performance across different types of\njobs. We~describe a DeepSoCS design process using a real-time heterogeneous SoC\nscheduling emulator, discuss major challenges, and present two novel neural\nnetwork design features that lead to outperforming HEFT: (i) hierarchical job-\nand task-graph embedding; and (ii) efficient use of real-time task information\nin the state space. Furthermore, we~introduce effective techniques to address\ntwo fundamental challenges present in our environment: delayed consequences and\njoint actions. Through an extensive simulation study, we~show that our DeepSoCS\nexhibits the significantly higher performance of job execution time than that\nof HEFT with a higher level of robustness under realistic noise conditions.\nWe~conclude with a discussion of the potential improvements for our DeepSoCS\nneural scheduler.\n", "versions": [{"version": "v1", "created": "Fri, 15 May 2020 17:31:27 GMT"}, {"version": "v2", "created": "Fri, 5 Jun 2020 09:53:01 GMT"}], "update_date": "2020-06-08", "authors_parsed": [["Sung", "Tegg Taekyong", ""], ["Ha", "Jeongsoo", ""], ["Kim", "Jeewoo", ""], ["Yahja", "Alex", ""], ["Sohn", "Chae-Bong", ""], ["Ryu", "Bo", ""]]}, {"id": "2005.07667", "submitter": "Jovan Kalajdjieski", "authors": "Jovan Kalajdjieski, Martina Toshevska, Frosina Stojanovska", "title": "Recent Advances in SQL Query Generation: A Survey", "comments": "Part of the 17th International Conference on Informatics and\n  Information Technologies. Received best paper award", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Natural language is hypothetically the best user interface for many domains.\nHowever, general models that provide an interface between natural language and\nany other domain still do not exist. Providing natural language interface to\nrelational databases could possibly attract a vast majority of users that are\nor are not proficient with query languages. With the rise of deep learning\ntechniques, there is extensive ongoing research in designing a suitable natural\nlanguage interface to relational databases.\n  This survey aims to overview some of the latest methods and models proposed\nin the area of SQL query generation from natural language. We describe models\nwith various architectures such as convolutional neural networks, recurrent\nneural networks, pointer networks, reinforcement learning, etc. Several\ndatasets intended to address the problem of SQL query generation are\ninterpreted and briefly overviewed. In the end, evaluation metrics utilized in\nthe field are presented mainly as a combination of execution accuracy and\nlogical form accuracy.\n", "versions": [{"version": "v1", "created": "Fri, 15 May 2020 17:31:29 GMT"}], "update_date": "2020-05-18", "authors_parsed": [["Kalajdjieski", "Jovan", ""], ["Toshevska", "Martina", ""], ["Stojanovska", "Frosina", ""]]}, {"id": "2005.07677", "submitter": "Miguel Gonz\\'alez-Duque", "authors": "Miguel Gonz\\'alez-Duque, Rasmus Berg Palm, David Ha, Sebastian Risi", "title": "Finding Game Levels with the Right Difficulty in a Few Trials through\n  Intelligent Trial-and-Error", "comments": "To be presented in the Conference on Games 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Methods for dynamic difficulty adjustment allow games to be tailored to\nparticular players to maximize their engagement. However, current methods often\nonly modify a limited set of game features such as the difficulty of the\nopponents, or the availability of resources. Other approaches, such as\nexperience-driven Procedural Content Generation (PCG), can generate complete\nlevels with desired properties such as levels that are neither too hard nor too\neasy, but require many iterations. This paper presents a method that can\ngenerate and search for complete levels with a specific target difficulty in\nonly a few trials. This advance is enabled by through an Intelligent\nTrial-and-Error algorithm, originally developed to allow robots to adapt\nquickly. Our algorithm first creates a large variety of different levels that\nvary across predefined dimensions such as leniency or map coverage. The\nperformance of an AI playing agent on these maps gives a proxy for how\ndifficult the level would be for another AI agent (e.g. one that employs Monte\nCarlo Tree Search instead of Greedy Tree Search); using this information, a\nBayesian Optimization procedure is deployed, updating the difficulty of the\nprior map to reflect the ability of the agent. The approach can reliably find\nlevels with a specific target difficulty for a variety of planning agents in\nonly a few trials, while maintaining an understanding of their skill landscape.\n", "versions": [{"version": "v1", "created": "Fri, 15 May 2020 17:48:18 GMT"}, {"version": "v2", "created": "Thu, 25 Jun 2020 12:55:08 GMT"}], "update_date": "2020-06-29", "authors_parsed": [["Gonz\u00e1lez-Duque", "Miguel", ""], ["Palm", "Rasmus Berg", ""], ["Ha", "David", ""], ["Risi", "Sebastian", ""]]}, {"id": "2005.07782", "submitter": "Huihui Zhang", "authors": "Huihui Zhang and Wu Huang", "title": "Unbiased Deep Reinforcement Learning: A General Training Framework for\n  Existing and Future Algorithms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years deep neural networks have been successfully applied to the\ndomains of reinforcement learning\n\\cite{bengio2009learning,krizhevsky2012imagenet,hinton2006reducing}. Deep\nreinforcement learning \\cite{mnih2015human} is reported to have the advantage\nof learning effective policies directly from high-dimensional sensory inputs\nover traditional agents. However, within the scope of the literature, there is\nno fundamental change or improvement on the existing training framework. Here\nwe propose a novel training framework that is conceptually comprehensible and\npotentially easy to be generalized to all feasible algorithms for reinforcement\nlearning. We employ Monte-carlo sampling to achieve raw data inputs, and train\nthem in batch to achieve Markov decision process sequences and synchronously\nupdate the network parameters instead of experience replay. This training\nframework proves to optimize the unbiased approximation of loss function whose\nestimation exactly matches the real probability distribution data inputs\nfollow, and thus have overwhelming advantages of sample efficiency and\nconvergence rate over existing deep reinforcement learning after evaluating it\non both discrete action spaces and continuous control problems. Besides, we\npropose several algorithms embedded with our new framework to deal with typical\ndiscrete and continuous scenarios. These algorithms prove to be far more\nefficient than their original versions under the framework of deep\nreinforcement learning, and provide examples for existing and future algorithms\nto generalize to our new framework.\n", "versions": [{"version": "v1", "created": "Tue, 12 May 2020 01:51:08 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Zhang", "Huihui", ""], ["Huang", "Wu", ""]]}, {"id": "2005.07842", "submitter": "Hao Peng", "authors": "Hao Peng, Pei Chen, Rui Liu", "title": "Multi-step-ahead Prediction from Short-term Data by\n  Delay-embedding-based Forecast Machine", "comments": "18 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Making accurate multi-step-ahead prediction for a complex system is a\nchallenge for many practical applications, especially when only short-term\ntime-series data are available. In this work, we proposed a novel framework,\nDelay-Embedding-based Forecast Machine (DEFM), to predict the future values of\na target variable in an accurate and multi-step-ahead manner based on the\nhigh-dimensional short-term measurements. With a three-module spatiotemporal\narchitecture, DEFM leverages deep learning to effectively extract both the\nspatially and sequentially associated information from the short-term dynamics\neven with time-varying parameters or additive noise. Being trained through a\nself-supervised scheme, DEFM well fits a nonlinear transformation that maps\nfrom the observed high-dimensional information to the delay embeddings of a\ntarget variable, thus predicting the future information. The effectiveness and\naccuracy of DEFM is demonstrated by applications on both representative models\nand six real-world datasets. The comparison with four traditional prediction\nmethods exhibits the superiority and robustness of DEFM.\n", "versions": [{"version": "v1", "created": "Sat, 16 May 2020 01:48:33 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Peng", "Hao", ""], ["Chen", "Pei", ""], ["Liu", "Rui", ""]]}, {"id": "2005.07845", "submitter": "Zitao Liu", "authors": "Gale Yan Huang, Jiahao Chen, Haochen Liu, Weiping Fu, Wenbiao Ding,\n  Jiliang Tang, Songfan Yang, Guoliang Li, Zitao Liu", "title": "Neural Multi-Task Learning for Teacher Question Detection in Online\n  Classrooms", "comments": "The 21th International Conference on Artificial Intelligence in\n  Education(AIED), 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Asking questions is one of the most crucial pedagogical techniques used by\nteachers in class. It not only offers open-ended discussions between teachers\nand students to exchange ideas but also provokes deeper student thought and\ncritical analysis. Providing teachers with such pedagogical feedback will\nremarkably help teachers improve their overall teaching quality over time in\nclassrooms. Therefore, in this work, we build an end-to-end neural framework\nthat automatically detects questions from teachers' audio recordings. Compared\nwith traditional methods, our approach not only avoids cumbersome feature\nengineering, but also adapts to the task of multi-class question detection in\nreal education scenarios. By incorporating multi-task learning techniques, we\nare able to strengthen the understanding of semantic relations among different\ntypes of questions. We conducted extensive experiments on the question\ndetection tasks in a real-world online classroom dataset and the results\ndemonstrate the superiority of our model in terms of various evaluation\nmetrics.\n", "versions": [{"version": "v1", "created": "Sat, 16 May 2020 02:17:04 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Huang", "Gale Yan", ""], ["Chen", "Jiahao", ""], ["Liu", "Haochen", ""], ["Fu", "Weiping", ""], ["Ding", "Wenbiao", ""], ["Tang", "Jiliang", ""], ["Yang", "Songfan", ""], ["Li", "Guoliang", ""], ["Liu", "Zitao", ""]]}, {"id": "2005.07870", "submitter": "Diego Fernando Gomez Noriega", "authors": "Diego Gomez, Nicanor Quijano, Luis Felipe Giraldo", "title": "Learning Transferable Concepts in Deep Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While humans and animals learn incrementally during their lifetimes and\nexploit their experience to solve new tasks, standard deep reinforcement\nlearning methods specialize to solve only one task at a time and, as a result,\nthe information they acquire is hardly reusable in new situations. Here, we\nintroduce a new perspective on the problem of leveraging prior knowledge to\nsolve future unknown tasks. We show that learning discrete concept-like\nrepresentations of sensory inputs can provide a high-level abstraction that is\ncommon across multiple tasks, thus facilitating the transference of\ninformation. In particular, we show that it is possible to learn such\nrepresentations by self-supervision, following an information theoretic\napproach, and that they improve the sample efficiency by providing prior\npolicies that guide the policy learning process. Our method is able to learn\nconcepts in locomotive tasks that reduce the number of optimization steps in\nboth known and unknown tasks, opening a new path to endow artificial agents\nwith generalization abilities.\n", "versions": [{"version": "v1", "created": "Sat, 16 May 2020 04:45:51 GMT"}, {"version": "v2", "created": "Tue, 19 May 2020 15:05:31 GMT"}, {"version": "v3", "created": "Thu, 25 Feb 2021 01:33:54 GMT"}], "update_date": "2021-02-26", "authors_parsed": [["Gomez", "Diego", ""], ["Quijano", "Nicanor", ""], ["Giraldo", "Luis Felipe", ""]]}, {"id": "2005.07916", "submitter": "Dongxiao Zhang", "authors": "Hao Xu, Dongxiao Zhang, and Junsheng Zeng", "title": "Deep-learning of Parametric Partial Differential Equations from Sparse\n  and Noisy Data", "comments": "30 pages, 6 figures, and 7 tables", "journal-ref": "Phys. Fluids, 33, 037132, 10.1063/5.0042868, 2021", "doi": "10.1063/5.0042868", "report-no": null, "categories": "physics.comp-ph cs.AI cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data-driven methods have recently made great progress in the discovery of\npartial differential equations (PDEs) from spatial-temporal data. However,\nseveral challenges remain to be solved, including sparse noisy data, incomplete\ncandidate library, and spatially- or temporally-varying coefficients. In this\nwork, a new framework, which combines neural network, genetic algorithm and\nadaptive methods, is put forward to address all of these challenges\nsimultaneously. In the framework, a trained neural network is utilized to\ncalculate derivatives and generate a large amount of meta-data, which solves\nthe problem of sparse noisy data. Next, genetic algorithm is utilized to\ndiscover the form of PDEs and corresponding coefficients with an incomplete\ncandidate library. Finally, a two-step adaptive method is introduced to\ndiscover parametric PDEs with spatially- or temporally-varying coefficients. In\nthis method, the structure of a parametric PDE is first discovered, and then\nthe general form of varying coefficients is identified. The proposed algorithm\nis tested on the Burgers equation, the convection-diffusion equation, the wave\nequation, and the KdV equation. The results demonstrate that this method is\nrobust to sparse and noisy data, and is able to discover parametric PDEs with\nan incomplete candidate library.\n", "versions": [{"version": "v1", "created": "Sat, 16 May 2020 09:09:57 GMT"}], "update_date": "2021-05-03", "authors_parsed": [["Xu", "Hao", ""], ["Zhang", "Dongxiao", ""], ["Zeng", "Junsheng", ""]]}, {"id": "2005.07941", "submitter": "Md Ferdous Pervej", "authors": "Md Ferdous Pervej, Le Thanh Tan, Rose Qingyang Hu", "title": "Artificial Intelligence Assisted Collaborative Edge Caching in Small\n  Cell Networks", "comments": "This is the technical report of our Globecom 2020 paper - \"Artificial\n  Intelligence Assisted Collaborative Edge Caching in Small Cell Networks\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.AI cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Edge caching is a new paradigm that has been exploited over the past several\nyears to reduce the load for the core network and to enhance the content\ndelivery performance. Many existing caching solutions only consider homogeneous\ncaching placement due to the immense complexity associated with the\nheterogeneous caching models. Unlike these legacy modeling paradigms, this\npaper considers heterogeneous content preference of the users with\nheterogeneous caching models at the edge nodes. Besides, aiming to maximize the\ncache hit ratio (CHR) in a two-tier heterogeneous network, we let the edge\nnodes collaborate. However, due to complex combinatorial decision variables,\nthe formulated problem is hard to solve in the polynomial time. Moreover, there\ndoes not even exist a ready-to-use tool or software to solve the problem. We\npropose a modified particle swarm optimization (M-PSO) algorithm that\nefficiently solves the complex constraint problem in a reasonable time. Using\nnumerical analysis and simulation, we validate that the proposed algorithm\nsignificantly enhances the CHR performance when comparing to that of the\nexisting baseline caching schemes.\n", "versions": [{"version": "v1", "created": "Sat, 16 May 2020 10:39:46 GMT"}, {"version": "v2", "created": "Wed, 16 Sep 2020 01:38:02 GMT"}], "update_date": "2020-09-17", "authors_parsed": [["Pervej", "Md Ferdous", ""], ["Tan", "Le Thanh", ""], ["Hu", "Rose Qingyang", ""]]}, {"id": "2005.07960", "submitter": "George Vouros", "authors": "Alevizos Bastas, Theocharis Kravaris and George A. Vouros", "title": "Data Driven Aircraft Trajectory Prediction with Deep Imitation Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The current Air Traffic Management (ATM) system worldwide has reached its\nlimits in terms of predictability, efficiency and cost effectiveness. Different\ninitiatives worldwide propose trajectory-oriented transformations that require\nhigh fidelity aircraft trajectory planning and prediction capabilities,\nsupporting the trajectory life cycle at all stages efficiently. Recently\nproposed data-driven trajectory prediction approaches provide promising\nresults. In this paper we approach the data-driven trajectory prediction\nproblem as an imitation learning task, where we aim to imitate experts\n\"shaping\" the trajectory. Towards this goal we present a comprehensive\nframework comprising the Generative Adversarial Imitation Learning state of the\nart method, in a pipeline with trajectory clustering and classification\nmethods. This approach, compared to other approaches, can provide accurate\npredictions for the whole trajectory (i.e. with a prediction horizon until\nreaching the destination) both at the pre-tactical (i.e. starting at the\ndeparture airport at a specific time instant) and at the tactical (i.e. from\nany state while flying) stages, compared to state of the art approaches.\n", "versions": [{"version": "v1", "created": "Sat, 16 May 2020 11:53:19 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Bastas", "Alevizos", ""], ["Kravaris", "Theocharis", ""], ["Vouros", "George A.", ""]]}, {"id": "2005.07979", "submitter": "Ehsaneddin Asgari", "authors": "Ehsaneddin Asgari and Christoph Ringlstetter and Hinrich Sch\\\"utze", "title": "Unsupervised Embedding-based Detection of Lexical Semantic Changes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  This paper describes EmbLexChange, a system introduced by the \"Life-Language\"\nteam for SemEval-2020 Task 1, on unsupervised detection of lexical-semantic\nchanges. EmbLexChange is defined as the divergence between the embedding based\nprofiles of word w (calculated with respect to a set of reference words) in the\nsource and the target domains (source and target domains can be simply two time\nframes t1 and t2). The underlying assumption is that the lexical-semantic\nchange of word w would affect its co-occurring words and subsequently alters\nthe neighborhoods in the embedding spaces. We show that using a resampling\nframework for the selection of reference words, we can reliably detect\nlexical-semantic changes in English, German, Swedish, and Latin. EmbLexChange\nachieved second place in the binary detection of semantic changes in the\nSemEval-2020.\n", "versions": [{"version": "v1", "created": "Sat, 16 May 2020 13:05:47 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Asgari", "Ehsaneddin", ""], ["Ringlstetter", "Christoph", ""], ["Sch\u00fctze", "Hinrich", ""]]}, {"id": "2005.08006", "submitter": "Ioannis Boukas", "authors": "Simone Totaro, Ioannis Boukas, Anders Jonsson and Bertrand\n  Corn\\'elusse", "title": "Lifelong Control of Off-grid Microgrid with Model Based Reinforcement\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.AI cs.LG cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The lifelong control problem of an off-grid microgrid is composed of two\ntasks, namely estimation of the condition of the microgrid devices and\noperational planning accounting for the uncertainties by forecasting the future\nconsumption and the renewable production. The main challenge for the effective\ncontrol arises from the various changes that take place over time. In this\npaper, we present an open-source reinforcement framework for the modeling of an\noff-grid microgrid for rural electrification. The lifelong control problem of\nan isolated microgrid is formulated as a Markov Decision Process (MDP). We\ncategorize the set of changes that can occur in progressive and abrupt changes.\nWe propose a novel model based reinforcement learning algorithm that is able to\naddress both types of changes. In particular the proposed algorithm\ndemonstrates generalisation properties, transfer capabilities and better\nrobustness in case of fast-changing system dynamics. The proposed algorithm is\ncompared against a rule-based policy and a model predictive controller with\nlook-ahead. The results show that the trained agent is able to outperform both\nbenchmarks in the lifelong setting where the system dynamics are changing over\ntime.\n", "versions": [{"version": "v1", "created": "Sat, 16 May 2020 14:45:55 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Totaro", "Simone", ""], ["Boukas", "Ioannis", ""], ["Jonsson", "Anders", ""], ["Corn\u00e9lusse", "Bertrand", ""]]}, {"id": "2005.08016", "submitter": "Hongwei Huang", "authors": "Hongwei Huang, Weiqi Luo, Guoqiang Zeng, Jian Weng, Yue Zhang, Anjia\n  Yang", "title": "DAMIA: Leveraging Domain Adaptation as a Defense against Membership\n  Inference Attacks", "comments": "The article contains 14 pages and 9 figures, and is submitted to IEEE\n  Transactions on Dependable and Secure Computing (TDSC)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Learning (DL) techniques allow ones to train models from a dataset to\nsolve tasks. DL has attracted much interest given its fancy performance and\npotential market value, while security issues are amongst the most colossal\nconcerns. However, the DL models may be prone to the membership inference\nattack, where an attacker determines whether a given sample is from the\ntraining dataset. Efforts have been made to hinder the attack but\nunfortunately, they may lead to a major overhead or impaired usability. In this\npaper, we propose and implement DAMIA, leveraging Domain Adaptation (DA) as a\ndefense aginist membership inference attacks. Our observation is that during\nthe training process, DA obfuscates the dataset to be protected using another\nrelated dataset, and derives a model that underlyingly extracts the features\nfrom both datasets. Seeing that the model is obfuscated, membership inference\nfails, while the extracted features provide supports for usability. Extensive\nexperiments have been conducted to validates our intuition. The model trained\nby DAMIA has a negligible footprint to the usability. Our experiment also\nexcludes factors that may hinder the performance of DAMIA, providing a\npotential guideline to vendors and researchers to benefit from our solution in\na timely manner.\n", "versions": [{"version": "v1", "created": "Sat, 16 May 2020 15:24:28 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Huang", "Hongwei", ""], ["Luo", "Weiqi", ""], ["Zeng", "Guoqiang", ""], ["Weng", "Jian", ""], ["Zhang", "Yue", ""], ["Yang", "Anjia", ""]]}, {"id": "2005.08068", "submitter": "Ignasi Clavera", "authors": "Ignasi Clavera, Violet Fu, Pieter Abbeel", "title": "Model-Augmented Actor-Critic: Backpropagating through Paths", "comments": "Accepted paper at ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current model-based reinforcement learning approaches use the model simply as\na learned black-box simulator to augment the data for policy optimization or\nvalue function learning. In this paper, we show how to make more effective use\nof the model by exploiting its differentiability. We construct a policy\noptimization algorithm that uses the pathwise derivative of the learned model\nand policy across future timesteps. Instabilities of learning across many\ntimesteps are prevented by using a terminal value function, learning the policy\nin an actor-critic fashion. Furthermore, we present a derivation on the\nmonotonic improvement of our objective in terms of the gradient error in the\nmodel and value function. We show that our approach (i) is consistently more\nsample efficient than existing state-of-the-art model-based algorithms, (ii)\nmatches the asymptotic performance of model-free algorithms, and (iii) scales\nto long horizons, a regime where typically past model-based approaches have\nstruggled.\n", "versions": [{"version": "v1", "created": "Sat, 16 May 2020 19:18:10 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Clavera", "Ignasi", ""], ["Fu", "Violet", ""], ["Abbeel", "Pieter", ""]]}, {"id": "2005.08078", "submitter": "David Limbaugh", "authors": "David Limbaugh, Jobst Landgrebe, David Kasmier, Ronald Rudnicki, James\n  Llinas, Barry Smith", "title": "Ontology and Cognitive Outcomes", "comments": "19 pages, 6 figures", "journal-ref": "Journal of Knowledge Structures & Systems, 1(1), 3-22 (2020)", "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Here we understand 'intelligence' as referring to items of knowledge\ncollected for the sake of assessing and maintaining national security. The\nintelligence community (IC) of the United States (US) is a community of\norganizations that collaborate in collecting and processing intelligence for\nthe US. The IC relies on human-machine-based analytic strategies that 1) access\nand integrate vast amounts of information from disparate sources, 2)\ncontinuously process this information, so that, 3) a maximally comprehensive\nunderstanding of world actors and their behaviors can be developed and updated.\nHerein we describe an approach to utilizing outcomes-based learning (OBL) to\nsupport these efforts that is based on an ontology of the cognitive processes\nperformed by intelligence analysts. Of particular importance to the Cognitive\nProcess Ontology is the class Representation that is Warranted. Such a\nrepresentation is descriptive in nature and deserving of trust in its\nveridicality. The latter is because a Representation that is Warranted is\nalways produced by a process that was vetted (or successfully designed) to\nreliably produce veridical representations. As such, Representations that are\nWarranted are what in other contexts we might refer to as 'items of knowledge'.\n", "versions": [{"version": "v1", "created": "Sat, 16 May 2020 19:50:26 GMT"}, {"version": "v2", "created": "Thu, 13 Aug 2020 17:18:40 GMT"}, {"version": "v3", "created": "Fri, 8 Jan 2021 14:49:58 GMT"}], "update_date": "2021-01-11", "authors_parsed": [["Limbaugh", "David", ""], ["Landgrebe", "Jobst", ""], ["Kasmier", "David", ""], ["Rudnicki", "Ronald", ""], ["Llinas", "James", ""], ["Smith", "Barry", ""]]}, {"id": "2005.08083", "submitter": "Alex De Sa'", "authors": "Alex G. C. de S\\'a, Cristiano G. Pimenta, Gisele L. Pappa and Alex A.\n  Freitas", "title": "A Robust Experimental Evaluation of Automated Multi-Label Classification\n  Methods", "comments": "GECCO'2020 paper: Submitted and accepted", "journal-ref": null, "doi": "10.1145/3377930.3390231", "report-no": null, "categories": "cs.LG cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automated Machine Learning (AutoML) has emerged to deal with the selection\nand configuration of algorithms for a given learning task. With the progression\nof AutoML, several effective methods were introduced, especially for\ntraditional classification and regression problems. Apart from the AutoML\nsuccess, several issues remain open. One issue, in particular, is the lack of\nability of AutoML methods to deal with different types of data. Based on this\nscenario, this paper approaches AutoML for multi-label classification (MLC)\nproblems. In MLC, each example can be simultaneously associated to several\nclass labels, unlike the standard classification task, where an example is\nassociated to just one class label. In this work, we provide a general\ncomparison of five automated multi-label classification methods -- two\nevolutionary methods, one Bayesian optimization method, one random search and\none greedy search -- on 14 datasets and three designed search spaces. Overall,\nwe observe that the most prominent method is the one based on a canonical\ngrammar-based genetic programming (GGP) search method, namely\nAuto-MEKA$_{GGP}$. Auto-MEKA$_{GGP}$ presented the best average results in our\ncomparison and was statistically better than all the other methods in different\nsearch spaces and evaluated measures, except when compared to the greedy search\nmethod.\n", "versions": [{"version": "v1", "created": "Sat, 16 May 2020 20:08:04 GMT"}, {"version": "v2", "created": "Fri, 31 Jul 2020 16:48:27 GMT"}], "update_date": "2020-08-03", "authors_parsed": [["de S\u00e1", "Alex G. C.", ""], ["Pimenta", "Cristiano G.", ""], ["Pappa", "Gisele L.", ""], ["Freitas", "Alex A.", ""]]}, {"id": "2005.08090", "submitter": "Daniel Karl I. Weidele", "authors": "Loraine Franke, Daniel Karl I. Weidele, Fan Zhang, Suheyla\n  Cetin-Karayumak, Steve Pieper, Lauren J. O'Donnell, Yogesh Rathi, Daniel\n  Haehn", "title": "FiberStars: Visual Comparison of Diffusion Tractography Data between\n  Multiple Subjects", "comments": "10 pages, 9 figures", "journal-ref": "2021 IEEE 14th Pacific Visualization Symposium (PacificVis)", "doi": "10.1109/PacificVis52677.2021.00023", "report-no": null, "categories": "cs.HC cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tractography from high-dimensional diffusion magnetic resonance imaging\n(dMRI) data allows brain's structural connectivity analysis. Recent dMRI\nstudies aim to compare connectivity patterns across subject groups and disease\npopulations to understand subtle abnormalities in the brain's white matter\nconnectivity and distributions of biologically sensitive dMRI derived metrics.\nExisting software products focus solely on the anatomy, are not intuitive or\nrestrict the comparison of multiple subjects. In this paper, we present the\ndesign and implementation of FiberStars, a visual analysis tool for\ntractography data that allows the interactive visualization of brain fiber\nclusters combining existing 3D anatomy with compact 2D visualizations. With\nFiberStars, researchers can analyze and compare multiple subjects in large\ncollections of brain fibers using different views. To evaluate the usability of\nour software, we performed a quantitative user study. We asked domain experts\nand non-experts to find patterns in a tractography dataset with either\nFiberStars or an existing dMRI exploration tool. Our results show that\nparticipants using FiberStars can navigate extensive collections of\ntractography faster and more accurately. All our research, software, and\nresults are available openly.\n", "versions": [{"version": "v1", "created": "Sat, 16 May 2020 20:23:46 GMT"}, {"version": "v2", "created": "Mon, 21 Jun 2021 16:57:13 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Franke", "Loraine", ""], ["Weidele", "Daniel Karl I.", ""], ["Zhang", "Fan", ""], ["Cetin-Karayumak", "Suheyla", ""], ["Pieper", "Steve", ""], ["O'Donnell", "Lauren J.", ""], ["Rathi", "Yogesh", ""], ["Haehn", "Daniel", ""]]}, {"id": "2005.08092", "submitter": "Fotios Fitsilis", "authors": "Fotios Fitsilis", "title": "Imposing Regulation on Advanced Algorithms", "comments": "XXI, 82 pages, 5 figures. Cham: Springer", "journal-ref": null, "doi": "10.1007/978-3-030-27979-0", "report-no": null, "categories": "cs.CY cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This book discusses the necessity and perhaps urgency for the regulation of\nalgorithms on which new technologies rely; technologies that have the potential\nto re-shape human societies. From commerce and farming to medical care and\neducation, it is difficult to find any aspect of our lives that will not be\naffected by these emerging technologies. At the same time, artificial\nintelligence, deep learning, machine learning, cognitive computing, blockchain,\nvirtual reality and augmented reality, belong to the fields most likely to\naffect law and, in particular, administrative law. The book examines\nuniversally applicable patterns in administrative decisions and judicial\nrulings. First, similarities and divergence in behavior among the different\ncases are identified by analyzing parameters ranging from geographical location\nand administrative decisions to judicial reasoning and legal basis. As it turns\nout, in several of the cases presented, sources of general law, such as\ncompetition or labor law, are invoked as a legal basis, due to the lack of\ncurrent specialized legislation. This book also investigates the role and\nsignificance of national and indeed supranational regulatory bodies for\nadvanced algorithms and considers ENISA, an EU agency that focuses on network\nand information security, as an interesting candidate for a European regulator\nof advanced algorithms. Lastly, it discusses the involvement of representative\ninstitutions in algorithmic regulation.\n", "versions": [{"version": "v1", "created": "Sat, 16 May 2020 20:26:54 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Fitsilis", "Fotios", ""]]}, {"id": "2005.08114", "submitter": "Ignasi Clavera", "authors": "Yiming Ding, Ignasi Clavera, Pieter Abbeel", "title": "Mutual Information Maximization for Robust Plannable Representations", "comments": "Accepted at NeurIPS 2019 Workshop on Robot Learning: Control and\n  Interaction in the Real World", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Extending the capabilities of robotics to real-world complex, unstructured\nenvironments requires the need of developing better perception systems while\nmaintaining low sample complexity. When dealing with high-dimensional state\nspaces, current methods are either model-free or model-based based on\nreconstruction objectives. The sample inefficiency of the former constitutes a\nmajor barrier for applying them to the real-world. The later, while they\npresent low sample complexity, they learn latent spaces that need to\nreconstruct every single detail of the scene. In real environments, the task\ntypically just represents a small fraction of the scene. Reconstruction\nobjectives suffer in such scenarios as they capture all the unnecessary\ncomponents. In this work, we present MIRO, an information theoretic\nrepresentational learning algorithm for model-based reinforcement learning. We\ndesign a latent space that maximizes the mutual information with the future\ninformation while being able to capture all the information needed for\nplanning. We show that our approach is more robust than reconstruction\nobjectives in the presence of distractors and cluttered scenes\n", "versions": [{"version": "v1", "created": "Sat, 16 May 2020 21:58:47 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Ding", "Yiming", ""], ["Clavera", "Ignasi", ""], ["Abbeel", "Pieter", ""]]}, {"id": "2005.08129", "submitter": "Yongfeng Zhang", "authors": "Hanxiong Chen, Shaoyun Shi, Yunqi Li, Yongfeng Zhang", "title": "Neural Collaborative Reasoning", "comments": "Accepted to the 30th Web Conference (WWW 2021)", "journal-ref": null, "doi": "10.1145/3442381.3449973", "report-no": null, "categories": "cs.IR cs.AI cs.LG cs.SC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing Collaborative Filtering (CF) methods are mostly designed based on\nthe idea of matching, i.e., by learning user and item embeddings from data\nusing shallow or deep models, they try to capture the associative relevance\npatterns in data, so that a user embedding can be matched with relevant item\nembeddings using designed or learned similarity functions. However, as a\ncognition rather than a perception intelligent task, recommendation requires\nnot only the ability of pattern recognition and matching from data, but also\nthe ability of cognitive reasoning in data. In this paper, we propose to\nadvance Collaborative Filtering (CF) to Collaborative Reasoning (CR), which\nmeans that each user knows part of the reasoning space, and they collaborate\nfor reasoning in the space to estimate preferences for each other. Technically,\nwe propose a Neural Collaborative Reasoning (NCR) framework to bridge learning\nand reasoning. Specifically, we integrate the power of representation learning\nand logical reasoning, where representations capture similarity patterns in\ndata from perceptual perspectives, and logic facilitates cognitive reasoning\nfor informed decision making. An important challenge, however, is to bridge\ndifferentiable neural networks and symbolic reasoning in a shared architecture\nfor optimization and inference. To solve the problem, we propose a modularized\nreasoning architecture, which learns logical operations such as AND ($\\wedge$),\nOR ($\\vee$) and NOT ($\\neg$) as neural modules for implication reasoning\n($\\rightarrow$). In this way, logical expressions can be equivalently organized\nas neural networks, so that logical reasoning and prediction can be conducted\nin a continuous space. Experiments on real-world datasets verified the\nadvantages of our framework compared with both shallow, deep and reasoning\nmodels.\n", "versions": [{"version": "v1", "created": "Sat, 16 May 2020 23:29:31 GMT"}, {"version": "v2", "created": "Tue, 2 Jun 2020 17:58:21 GMT"}, {"version": "v3", "created": "Thu, 11 Jun 2020 23:03:39 GMT"}, {"version": "v4", "created": "Tue, 20 Apr 2021 23:16:22 GMT"}, {"version": "v5", "created": "Mon, 3 May 2021 02:06:05 GMT"}], "update_date": "2021-05-04", "authors_parsed": [["Chen", "Hanxiong", ""], ["Shi", "Shaoyun", ""], ["Li", "Yunqi", ""], ["Zhang", "Yongfeng", ""]]}, {"id": "2005.08211", "submitter": "Sarah McDaid PhD", "authors": "Edward McDaid and Sarah McDaid", "title": "Quantifying the Impact on Software Complexity of Composable Inductive\n  Programming using Zoea", "comments": "8 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.AI cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Composable inductive programming as implemented in the Zoea programming\nlanguage is a simple declarative approach to software development. At the\nlanguage level it is evident that Zoea is significantly simpler than all\nmainstream languages. However, until now we have only had anecdotal evidence\nthat software produced with Zoea is also simpler than equivalent software\nproduced with conventional languages. This paper presents the results of a\nquantitative comparison of the software complexity of equivalent code\nimplemented in Zoea and also in a conventional programming language. The study\nuses a varied set of programming tasks from a popular programming language\nchrestomathy. Results are presented for relative program complexity using two\nestablished metrics and also for relative program size. It was found that Zoea\nprograms are approximately 50% the complexity of equivalent programs in a\nconventional language and on average equal in size. The results suggest that\ncurrent programming languages (as opposed to software requirements) are the\nlargest contributor to software complexity and that significant complexity\ncould be avoided through an inductive programming approach.\n", "versions": [{"version": "v1", "created": "Sun, 17 May 2020 10:44:39 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["McDaid", "Edward", ""], ["McDaid", "Sarah", ""]]}, {"id": "2005.08225", "submitter": "Fanzhen Liu", "authors": "Fanzhen Liu, Shan Xue, Jia Wu, Chuan Zhou, Wenbin Hu, Cecile Paris,\n  Surya Nepal, Jian Yang, Philip S. Yu", "title": "Deep Learning for Community Detection: Progress, Challenges and\n  Opportunities", "comments": "Accepted Paper in the 29th International Joint Conference on\n  Artificial Intelligence (IJCAI 20), Survey Track", "journal-ref": "IJCAI 2020: 4981-4987", "doi": "10.24963/ijcai.2020/693", "report-no": null, "categories": "cs.SI cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As communities represent similar opinions, similar functions, similar\npurposes, etc., community detection is an important and extremely useful tool\nin both scientific inquiry and data analytics. However, the classic methods of\ncommunity detection, such as spectral clustering and statistical inference, are\nfalling by the wayside as deep learning techniques demonstrate an increasing\ncapacity to handle high-dimensional graph data with impressive performance.\nThus, a survey of current progress in community detection through deep learning\nis timely. Structured into three broad research streams in this domain - deep\nneural networks, deep graph embedding, and graph neural networks, this article\nsummarizes the contributions of the various frameworks, models, and algorithms\nin each stream along with the current challenges that remain unsolved and the\nfuture research opportunities yet to be explored.\n", "versions": [{"version": "v1", "created": "Sun, 17 May 2020 11:22:11 GMT"}, {"version": "v2", "created": "Wed, 23 Sep 2020 09:34:17 GMT"}], "update_date": "2020-09-24", "authors_parsed": [["Liu", "Fanzhen", ""], ["Xue", "Shan", ""], ["Wu", "Jia", ""], ["Zhou", "Chuan", ""], ["Hu", "Wenbin", ""], ["Paris", "Cecile", ""], ["Nepal", "Surya", ""], ["Yang", "Jian", ""], ["Yu", "Philip S.", ""]]}, {"id": "2005.08231", "submitter": "Johanna Johansen Ms", "authors": "Johanna Johansen, Tore Pedersen, Christian Johansen", "title": "Studying the Transfer of Biases from Programmers to Programs", "comments": "40 pages of which 7 pages of Appendix, 26 Figures, 2 Tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI cs.CY", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  It is generally agreed that one origin of machine bias is resulting from\ncharacteristics within the dataset on which the algorithms are trained, i.e.,\nthe data does not warrant a generalized inference. We, however, hypothesize\nthat a different `mechanism', hitherto not articulated in the literature, may\nalso be responsible for machine's bias, namely that biases may originate from\n(i) the programmers' cultural background, such as education or line of work, or\n(ii) the contextual programming environment, such as software requirements or\ndeveloper tools. Combining an experimental and comparative design, we studied\nthe effects of cultural metaphors and contextual metaphors, and tested whether\neach of these would `transfer' from the programmer to program, thus\nconstituting a machine bias. The results show (i) that cultural metaphors\ninfluence the programmer's choices and (ii) that `induced' contextual metaphors\ncan be used to moderate or exacerbate the effects of the cultural metaphors.\nThis supports our hypothesis that biases in automated systems do not always\noriginate from within the machine's training data. Instead, machines may also\n`replicate' and `reproduce' biases from the programmers' cultural background by\nthe transfer of cultural metaphors into the programming process. Implications\nfor academia and professional practice range from the micro programming-level\nto the macro national-regulations or educational level, and span across all\nsocietal domains where software-based systems are operating such as the popular\nAI-based automated decision support systems.\n", "versions": [{"version": "v1", "created": "Sun, 17 May 2020 11:51:06 GMT"}, {"version": "v2", "created": "Sun, 13 Dec 2020 17:06:25 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["Johansen", "Johanna", ""], ["Pedersen", "Tore", ""], ["Johansen", "Christian", ""]]}, {"id": "2005.08245", "submitter": "Liming Jiang", "authors": "Liming Jiang, Yuanchang Xie, Danjue Chen, Tienan Li, Nicholas G. Evans", "title": "Dampen the Stop-and-Go Traffic with Connected and Automated Vehicles --\n  A Deep Reinforcement Learning Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stop-and-go traffic poses many challenges to tranportation system, but its\nformation and mechanism are still under exploration.however, it has been proved\nthat by introducing Connected Automated Vehicles(CAVs) with carefully designed\ncontrollers one could dampen the stop-and-go waves in the vehicle fleet.\nInstead of using analytical model, this study adopts reinforcement learning to\ncontrol the behavior of CAV and put a single CAV at the 2nd position of a\nvehicle fleet with the purpose to dampen the speed oscillation from the fleet\nleader and help following human drivers adopt more smooth driving behavior. The\nresult show that our controller could decrease the spped oscillation of the CAV\nby 54% and 8%-28% for those following human-driven vehicles. Significant fuel\nconsumption savings are also observed. Additionally, the result suggest that\nCAVs may act as a traffic stabilizer if they choose to behave slightly\naltruistically.\n", "versions": [{"version": "v1", "created": "Sun, 17 May 2020 12:46:22 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Jiang", "Liming", ""], ["Xie", "Yuanchang", ""], ["Chen", "Danjue", ""], ["Li", "Tienan", ""], ["Evans", "Nicholas G.", ""]]}, {"id": "2005.08350", "submitter": "Mahboobeh Parsapoor", "authors": "M.Parsapoor, U.Bilstrup, B.Svensson", "title": "Forecasting Solar Activity with Two Computational Intelligence Models (A\n  Comparative Study)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Solar activity It is vital to accurately predict solar activity, in order to\ndecrease the plausible damage of electronic equipment in the event of a large\nhigh-intensity solar eruption. Recently, we have proposed BELFIS (Brain\nEmotional Learning-based Fuzzy Inference System) as a tool for the forecasting\nof chaotic systems. The structure of BELFIS is designed based on the neural\nstructure of fear conditioning. The function of BELFIS is implemented by\nassigning adaptive networks to the components of the BELFIS structure. This\npaper especially focuses on performance evaluation of BELFIS as a predictor by\nforecasting solar cycles 16 to 24. The performance of BELFIS is compared with\nother computational models used for this purpose, and in particular with\nadaptive neuro-fuzzy inference system (ANFIS).\n", "versions": [{"version": "v1", "created": "Sun, 17 May 2020 19:29:15 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Parsapoor", "M.", ""], ["Bilstrup", "U.", ""], ["Svensson", "B.", ""]]}, {"id": "2005.08368", "submitter": "Ahmed Khalifa", "authors": "Ahmed Khalifa and Julian Togelius", "title": "Multi-Objective level generator generation with Marahel", "comments": "Published at the PCGWorkshop 2020, 8pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces a new system to design constructive level generators by\nsearching the space of constructive level generators defined by Marahel\nlanguage. We use NSGA-II, a multi-objective optimization algorithm, to search\nfor generators for three different problems (Binary, Zelda, and Sokoban). We\nrestrict the representation to a subset of Marahel language to push the\nevolution to find more efficient generators. The results show that the\ngenerated generators were able to achieve good performance on most of the\nfitness functions over these three problems. However, on Zelda and Sokoban,\nthey tend to depend on the initial state than modifying the map.\n", "versions": [{"version": "v1", "created": "Sun, 17 May 2020 20:56:33 GMT"}, {"version": "v2", "created": "Wed, 22 Jul 2020 00:03:10 GMT"}], "update_date": "2020-07-23", "authors_parsed": [["Khalifa", "Ahmed", ""], ["Togelius", "Julian", ""]]}, {"id": "2005.08384", "submitter": "Christian Anti\\'c", "authors": "Christian Anti\\'c", "title": "Fixed Point Semantics for Stream Reasoning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI cs.CL cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reasoning over streams of input data is an essential part of human\nintelligence. During the last decade {\\em stream reasoning} has emerged as a\nresearch area within the AI-community with many potential applications. In\nfact, the increased availability of streaming data via services like Google and\nFacebook has raised the need for reasoning engines coping with data that\nchanges at high rate. Recently, the rule-based formalism {\\em LARS} for\nnon-monotonic stream reasoning under the answer set semantics has been\nintroduced. Syntactically, LARS programs are logic programs with negation\nincorporating operators for temporal reasoning, most notably {\\em window\noperators} for selecting relevant time points. Unfortunately, by preselecting\n{\\em fixed} intervals for the semantic evaluation of programs, the rigid\nsemantics of LARS programs is not flexible enough to {\\em constructively} cope\nwith rapidly changing data dependencies. Moreover, we show that defining the\nanswer set semantics of LARS in terms of FLP reducts leads to undesirable\ncircular justifications similar to other ASP extensions. This paper fixes all\nof the aforementioned shortcomings of LARS. More precisely, we contribute to\nthe foundations of stream reasoning by providing an operational fixed point\nsemantics for a fully flexible variant of LARS and we show that our semantics\nis sound and constructive in the sense that answer sets are derivable bottom-up\nand free of circular justifications.\n", "versions": [{"version": "v1", "created": "Sun, 17 May 2020 22:25:24 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Anti\u0107", "Christian", ""]]}, {"id": "2005.08502", "submitter": "Yun William Yu", "authors": "Hannah Alsdurf, Edmond Belliveau, Yoshua Bengio, Tristan Deleu,\n  Prateek Gupta, Daphne Ippolito, Richard Janda, Max Jarvie, Tyler Kolody,\n  Sekoul Krastev, Tegan Maharaj, Robert Obryk, Dan Pilat, Valerie Pisano,\n  Benjamin Prud'homme, Meng Qu, Nasim Rahaman, Irina Rish, Jean-Francois\n  Rousseau, Abhinav Sharma, Brooke Struck, Jian Tang, Martin Weiss, Yun William\n  Yu", "title": "COVI White Paper", "comments": "64 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The SARS-CoV-2 (Covid-19) pandemic has caused significant strain on public\nhealth institutions around the world. Contact tracing is an essential tool to\nchange the course of the Covid-19 pandemic. Manual contact tracing of Covid-19\ncases has significant challenges that limit the ability of public health\nauthorities to minimize community infections. Personalized peer-to-peer contact\ntracing through the use of mobile apps has the potential to shift the paradigm.\nSome countries have deployed centralized tracking systems, but more\nprivacy-protecting decentralized systems offer much of the same benefit without\nconcentrating data in the hands of a state authority or for-profit\ncorporations. Machine learning methods can circumvent some of the limitations\nof standard digital tracing by incorporating many clues and their uncertainty\ninto a more graded and precise estimation of infection risk. The estimated risk\ncan provide early risk awareness, personalized recommendations and relevant\ninformation to the user. Finally, non-identifying risk data can inform\nepidemiological models trained jointly with the machine learning predictor.\nThese models can provide statistical evidence for the importance of factors\ninvolved in disease transmission. They can also be used to monitor, evaluate\nand optimize health policy and (de)confinement scenarios according to medical\nand economic productivity indicators. However, such a strategy based on mobile\napps and machine learning should proactively mitigate potential ethical and\nprivacy risks, which could have substantial impacts on society (not only\nimpacts on health but also impacts such as stigmatization and abuse of personal\ndata). Here, we present an overview of the rationale, design, ethical\nconsiderations and privacy strategy of `COVI,' a Covid-19 public peer-to-peer\ncontact tracing and risk awareness mobile application developed in Canada.\n", "versions": [{"version": "v1", "created": "Mon, 18 May 2020 07:40:49 GMT"}, {"version": "v2", "created": "Mon, 27 Jul 2020 15:41:17 GMT"}], "update_date": "2020-07-28", "authors_parsed": [["Alsdurf", "Hannah", ""], ["Belliveau", "Edmond", ""], ["Bengio", "Yoshua", ""], ["Deleu", "Tristan", ""], ["Gupta", "Prateek", ""], ["Ippolito", "Daphne", ""], ["Janda", "Richard", ""], ["Jarvie", "Max", ""], ["Kolody", "Tyler", ""], ["Krastev", "Sekoul", ""], ["Maharaj", "Tegan", ""], ["Obryk", "Robert", ""], ["Pilat", "Dan", ""], ["Pisano", "Valerie", ""], ["Prud'homme", "Benjamin", ""], ["Qu", "Meng", ""], ["Rahaman", "Nasim", ""], ["Rish", "Irina", ""], ["Rousseau", "Jean-Francois", ""], ["Sharma", "Abhinav", ""], ["Struck", "Brooke", ""], ["Tang", "Jian", ""], ["Weiss", "Martin", ""], ["Yu", "Yun William", ""]]}, {"id": "2005.08516", "submitter": "Swaroop Mishra", "authors": "Swaroop Mishra, Arindam Mitra, Neeraj Varshney, Bhavdeep Sachdeva and\n  Chitta Baral", "title": "Towards Question Format Independent Numerical Reasoning: A Set of\n  Prerequisite Tasks", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Numerical reasoning is often important to accurately understand the world.\nRecently, several format-specific datasets have been proposed, such as\nnumerical reasoning in the settings of Natural Language Inference (NLI),\nReading Comprehension (RC), and Question Answering (QA). Several\nformat-specific models and architectures in response to those datasets have\nalso been proposed. However, there exists a strong need for a benchmark which\ncan evaluate the abilities of models, in performing question format independent\nnumerical reasoning, as (i) the numerical reasoning capabilities we want to\nteach are not controlled by question formats, (ii) for numerical reasoning\ntechnology to have the best possible application, it must be able to process\nlanguage and reason in a way that is not exclusive to a single format, task,\ndataset or domain. In pursuit of this goal, we introduce NUMBERGAME, a\nmultifaceted benchmark to evaluate model performance across numerical reasoning\ntasks of eight diverse formats. We add four existing question types in our\ncompilation. Two of the new types we add are about questions that require\nexternal numerical knowledge, commonsense knowledge and domain knowledge. For\nbuilding a more practical numerical reasoning system, NUMBERGAME demands four\ncapabilities beyond numerical reasoning: (i) detecting question format directly\nfrom data (ii) finding intermediate common format to which every format can be\nconverted (iii) incorporating commonsense knowledge (iv) handling data\nimbalance across formats. We build several baselines, including a new model\nbased on knowledge hunting using a cheatsheet. However, all baselines perform\npoorly in contrast to the human baselines, indicating the hardness of our\nbenchmark. Our work takes forward the recent progress in generic system\ndevelopment, demonstrating the scope of these under-explored tasks.\n", "versions": [{"version": "v1", "created": "Mon, 18 May 2020 08:14:04 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Mishra", "Swaroop", ""], ["Mitra", "Arindam", ""], ["Varshney", "Neeraj", ""], ["Sachdeva", "Bhavdeep", ""], ["Baral", "Chitta", ""]]}, {"id": "2005.08517", "submitter": "Joel Colloc", "authors": "Jo\\\"el Colloc (IDEES), Danielle Boulanger", "title": "Automatic Knowledge Acquisition for Object-Oriented Expert Systems", "comments": null, "journal-ref": "AVIGNON'93 Thirteenth International Conference Artificial\n  Intelligence, Expert Systems, Natural Language, May 1993, Avignon, France", "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe an Object Oriented Model for building Expert Systems. This model\nand the detection of similarities allow to implement reasoning modes as\ninduction, deduction and simulation. We specially focus on similarity and its\nuse in induction. We propose original algorithms which deal with total and\npartial structural similitude of objects to facilitate knowledge acquisition.\n", "versions": [{"version": "v1", "created": "Mon, 18 May 2020 08:16:48 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Colloc", "Jo\u00ebl", "", "IDEES"], ["Boulanger", "Danielle", ""]]}, {"id": "2005.08636", "submitter": "Divyam Aggarwal", "authors": "Divyam Aggarwal, Dhish Kumar Saxena, Saaju Pualose, Thomas B\\\"ack,\n  Michael Emmerich", "title": "A Novel Column Generation Heuristic for Airline Crew Pairing\n  Optimization with Large-scale Complex Flight Networks", "comments": "26 pages, 8 figures, 6 tables, 5 Algorithms", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.AI cs.DM", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Crew Pairing Optimization (CPO) is critical for an airlines' business\nviability, given that the crew operating cost is second only to the fuel cost.\nCPO aims at generating a set of flight sequences (crew pairings) to cover all\nscheduled flights, at minimum cost, while satisfying several legality\nconstraints. The state-of-the-art heavily relies on relaxing the underlying\nInteger Programming Problem into a Linear Programming Problem, which in turn is\nsolved through the Column Generation (CG) technique. However, with the\nalarmingly expanding airlines' operations, CPO is marred by the curse of\ndimensionality, rendering the exact CG-implementations obsolete, and\nnecessitating the heuristic-based CG-implementations. Yet, in literature, the\nmuch prevalent large-scale complex flight networks involving multiple { crew\nbases and/or hub-and-spoke sub-networks, largely remain uninvestigated. This\npaper proposes a novel CG heuristic, which has enabled the in-house development\nof an Airline Crew Pairing Optimizer (AirCROP). The efficacy of the\nheuristic/AirCROP has been tested on real-world, large-scale, complex network\ninstances with over 4,200 flights, 15 crew bases, and multiple hub-and-spoke\nsub-networks (resulting in billion-plus possible pairings). Notably, this paper\nhas a dedicated focus on the proposed CG heuristic (not the entire AirCROP\nframework) based on balancing random exploration of pairings; exploitation of\ndomain knowledge (on optimal solution features); and utilization of the past\ncomputational & search effort through archiving. Though this paper has an\nairline context, the proposed CG heuristic may find wider applications across\ndifferent domains, by serving as a template on how to utilize domain knowledge\nto better tackle combinatorial optimization problems.\n", "versions": [{"version": "v1", "created": "Mon, 18 May 2020 12:19:02 GMT"}, {"version": "v2", "created": "Sat, 23 May 2020 23:27:02 GMT"}, {"version": "v3", "created": "Mon, 20 Jul 2020 00:39:18 GMT"}, {"version": "v4", "created": "Fri, 2 Jul 2021 11:48:45 GMT"}], "update_date": "2021-07-05", "authors_parsed": [["Aggarwal", "Divyam", ""], ["Saxena", "Dhish Kumar", ""], ["Pualose", "Saaju", ""], ["B\u00e4ck", "Thomas", ""], ["Emmerich", "Michael", ""]]}, {"id": "2005.08679", "submitter": "Emiliano De Cristofaro", "authors": "Emiliano De Cristofaro", "title": "An Overview of Privacy in Machine Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Over the past few years, providers such as Google, Microsoft, and Amazon have\nstarted to provide customers with access to software interfaces allowing them\nto easily embed machine learning tasks into their applications. Overall,\norganizations can now use Machine Learning as a Service (MLaaS) engines to\noutsource complex tasks, e.g., training classifiers, performing predictions,\nclustering, etc. They can also let others query models trained on their data.\nNaturally, this approach can also be used (and is often advocated) in other\ncontexts, including government collaborations, citizen science projects, and\nbusiness-to-business partnerships. However, if malicious users were able to\nrecover data used to train these models, the resulting information leakage\nwould create serious issues. Likewise, if the inner parameters of the model are\nconsidered proprietary information, then access to the model should not allow\nan adversary to learn such parameters. In this document, we set to review\nprivacy challenges in this space, providing a systematic review of the relevant\nresearch literature, also exploring possible countermeasures. More\nspecifically, we provide ample background information on relevant concepts\naround machine learning and privacy. Then, we discuss possible adversarial\nmodels and settings, cover a wide range of attacks that relate to private\nand/or sensitive information leakage, and review recent results attempting to\ndefend against such attacks. Finally, we conclude with a list of open problems\nthat require more work, including the need for better evaluations, more\ntargeted defenses, and the study of the relation to policy and data protection\nefforts.\n", "versions": [{"version": "v1", "created": "Mon, 18 May 2020 13:05:17 GMT"}], "update_date": "2020-05-20", "authors_parsed": [["De Cristofaro", "Emiliano", ""]]}, {"id": "2005.08792", "submitter": "David Kinney", "authors": "David Kinney and David Watson", "title": "Causal Feature Learning for Utility-Maximizing Agents", "comments": "Forthcoming in the Proceedings of the 10th International Conference\n  on Probabilistic Graphical Models", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Discovering high-level causal relations from low-level data is an important\nand challenging problem that comes up frequently in the natural and social\nsciences. In a series of papers, Chalupka et al. (2015, 2016a, 2016b, 2017)\ndevelop a procedure for causal feature learning (CFL) in an effort to automate\nthis task. We argue that CFL does not recommend coarsening in cases where\npragmatic considerations rule in favor of it, and recommends coarsening in\ncases where pragmatic considerations rule against it. We propose a new\ntechnique, pragmatic causal feature learning (PCFL), which extends the original\nCFL algorithm in useful and intuitive ways. We show that PCFL has the same\nattractive measure-theoretic properties as the original CFL algorithm. We\ncompare the performance of both methods through theoretical analysis and\nexperiments.\n", "versions": [{"version": "v1", "created": "Mon, 18 May 2020 15:13:59 GMT"}, {"version": "v2", "created": "Sat, 6 Jun 2020 11:38:12 GMT"}, {"version": "v3", "created": "Fri, 21 Aug 2020 10:31:05 GMT"}, {"version": "v4", "created": "Thu, 27 Aug 2020 18:56:41 GMT"}], "update_date": "2020-08-31", "authors_parsed": [["Kinney", "David", ""], ["Watson", "David", ""]]}, {"id": "2005.08874", "submitter": "Tobias Huber", "authors": "Tobias Huber, Katharina Weitz, Elisabeth Andr\\'e, Ofra Amir", "title": "Local and Global Explanations of Agent Behavior: Integrating Strategy\n  Summaries with Saliency Maps", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.HC cs.NE stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  With advances in reinforcement learning (RL), agents are now being developed\nin high-stakes application domains such as healthcare and transportation.\nExplaining the behavior of these agents is challenging, as the environments in\nwhich they act have large state spaces, and their decision-making can be\naffected by delayed rewards, making it difficult to analyze their behavior. To\naddress this problem, several approaches have been developed. Some approaches\nattempt to convey the $\\textit{global}$ behavior of the agent, describing the\nactions it takes in different states. Other approaches devised $\\textit{local}$\nexplanations which provide information regarding the agent's decision-making in\na particular state. In this paper, we combine global and local explanation\nmethods, and evaluate their joint and separate contributions, providing (to the\nbest of our knowledge) the first user study of combined local and global\nexplanations for RL agents. Specifically, we augment strategy summaries that\nextract important trajectories of states from simulations of the agent with\nsaliency maps which show what information the agent attends to. Our results\nshow that the choice of what states to include in the summary (global\ninformation) strongly affects people's understanding of agents: participants\nshown summaries that included important states significantly outperformed\nparticipants who were presented with agent behavior in a randomly set of chosen\nworld-states. We find mixed results with respect to augmenting demonstrations\nwith saliency maps (local information), as the addition of saliency maps did\nnot significantly improve performance in most cases. However, we do find some\nevidence that saliency maps can help users better understand what information\nthe agent relies on in its decision making, suggesting avenues for future work\nthat can further improve explanations of RL agents.\n", "versions": [{"version": "v1", "created": "Mon, 18 May 2020 16:44:55 GMT"}, {"version": "v2", "created": "Tue, 19 May 2020 17:34:10 GMT"}, {"version": "v3", "created": "Fri, 29 May 2020 17:54:59 GMT"}], "update_date": "2020-06-01", "authors_parsed": [["Huber", "Tobias", ""], ["Weitz", "Katharina", ""], ["Andr\u00e9", "Elisabeth", ""], ["Amir", "Ofra", ""]]}, {"id": "2005.08954", "submitter": "Toby Walsh", "authors": "Toby Walsh", "title": "On the Complexity of Breaking Symmetry", "comments": "Appears in Proceedings of the 11th International Workshop on Symmetry\n  in Constraint Satisfaction Problems (SymCon'11). Held alongside the\n  International Conference on the Principles and Practice of Constraint\n  Programming (CP 2011). arXiv admin note: text overlap with arXiv:1306.5053", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We can break symmetry by eliminating solutions within a symmetry class that\nare not least in the lexicographical ordering. This is often referred to as the\nlex-leader method. Unfortunately, as symmetry groups can be large, the\nlexleader method is not tractable in general. We prove that using other total\norderings besides the usual lexicographical ordering will not reduce the\ncomputational complexity of breaking symmetry in general. It follows that\nbreaking symmetry with other orderings like the Gray code ordering or the\nSnake-Lex ordering is intractable in general.\n", "versions": [{"version": "v1", "created": "Sat, 16 May 2020 23:54:06 GMT"}], "update_date": "2020-05-20", "authors_parsed": [["Walsh", "Toby", ""]]}, {"id": "2005.09020", "submitter": "Anthony Constantinou", "authors": "Anthony C. Constantinou, Yang Liu, Kiattikun Chobtham, Zhigao Guo and\n  Neville K. Kitson", "title": "Large-scale empirical validation of Bayesian Network structure learning\n  algorithms with noisy data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Numerous Bayesian Network (BN) structure learning algorithms have been\nproposed in the literature over the past few decades. Each publication makes an\nempirical or theoretical case for the algorithm proposed in that publication\nand results across studies are often inconsistent in their claims about which\nalgorithm is 'best'. This is partly because there is no agreed evaluation\napproach to determine their effectiveness. Moreover, each algorithm is based on\na set of assumptions, such as complete data and causal sufficiency, and tend to\nbe evaluated with data that conforms to these assumptions, however unrealistic\nthese assumptions may be in the real world. As a result, it is widely accepted\nthat synthetic performance overestimates real performance, although to what\ndegree this may happen remains unknown. This paper investigates the performance\nof 15 structure learning algorithms. We propose a methodology that applies the\nalgorithms to data that incorporates synthetic noise, in an effort to better\nunderstand the performance of structure learning algorithms when applied to\nreal data. Each algorithm is tested over multiple case studies, sample sizes,\ntypes of noise, and assessed with multiple evaluation criteria. This work\ninvolved approximately 10,000 graphs with a total structure learning runtime of\nseven months. It provides the first large-scale empirical validation of BN\nstructure learning algorithms under different assumptions of data noise. The\nresults suggest that traditional synthetic performance may overestimate\nreal-world performance by anywhere between 10% and more than 50%. They also\nshow that while score-based learning is generally superior to constraint-based\nlearning, a higher fitting score does not necessarily imply a more accurate\ncausal graph. To facilitate comparisons with future studies, we have made all\ndata, raw results, graphs and BN models freely available online.\n", "versions": [{"version": "v1", "created": "Mon, 18 May 2020 18:40:09 GMT"}, {"version": "v2", "created": "Fri, 11 Sep 2020 13:12:00 GMT"}], "update_date": "2020-09-14", "authors_parsed": [["Constantinou", "Anthony C.", ""], ["Liu", "Yang", ""], ["Chobtham", "Kiattikun", ""], ["Guo", "Zhigao", ""], ["Kitson", "Neville K.", ""]]}, {"id": "2005.09046", "submitter": "Kevin Moran P", "authors": "Kevin Moran, David N. Palacio, Carlos Bernal-C\\'ardenas, Daniel\n  McCrystal, Denys Poshyvanyk, Chris Shenefiel, Jeff Johnson", "title": "Improving the Effectiveness of Traceability Link Recovery using\n  Hierarchical Bayesian Networks", "comments": "Accepted in the Proceedings of the 42nd International Conference on\n  Software Engineering (ICSE'20), 13 pages", "journal-ref": null, "doi": "10.1145/3377811.3380418", "report-no": null, "categories": "cs.SE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traceability is a fundamental component of the modern software development\nprocess that helps to ensure properly functioning, secure programs. Due to the\nhigh cost of manually establishing trace links, researchers have developed\nautomated approaches that draw relationships between pairs of textual software\nartifacts using similarity measures. However, the effectiveness of such\ntechniques are often limited as they only utilize a single measure of artifact\nsimilarity and cannot simultaneously model (implicit and explicit)\nrelationships across groups of diverse development artifacts.\n  In this paper, we illustrate how these limitations can be overcome through\nthe use of a tailored probabilistic model. To this end, we design and implement\na HierarchiCal PrObabilistic Model for SoftwarE Traceability (Comet) that is\nable to infer candidate trace links. Comet is capable of modeling relationships\nbetween artifacts by combining the complementary observational prowess of\nmultiple measures of textual similarity. Additionally, our model can\nholistically incorporate information from a diverse set of sources, including\ndeveloper feedback and transitive (often implicit) relationships among groups\nof software artifacts, to improve inference accuracy. We conduct a\ncomprehensive empirical evaluation of Comet that illustrates an improvement\nover a set of optimally configured baselines of $\\approx$14% in the best case\nand $\\approx$5% across all subjects in terms of average precision. The\ncomparative effectiveness of Comet in practice, where optimal configuration is\ntypically not possible, is likely to be higher. Finally, we illustrate Comets\npotential for practical applicability in a survey with developers from Cisco\nSystems who used a prototype Comet Jenkins plugin.\n", "versions": [{"version": "v1", "created": "Mon, 18 May 2020 19:38:29 GMT"}], "update_date": "2020-05-20", "authors_parsed": [["Moran", "Kevin", ""], ["Palacio", "David N.", ""], ["Bernal-C\u00e1rdenas", "Carlos", ""], ["McCrystal", "Daniel", ""], ["Poshyvanyk", "Denys", ""], ["Shenefiel", "Chris", ""], ["Johnson", "Jeff", ""]]}, {"id": "2005.09109", "submitter": "Liangbei Xu", "authors": "Liangbei Xu, Mark A. Davenport", "title": "Dynamic Knowledge embedding and tracing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The goal of knowledge tracing is to track the state of a student's knowledge\nas it evolves over time. This plays a fundamental role in understanding the\nlearning process and is a key task in the development of an intelligent\ntutoring system. In this paper we propose a novel approach to knowledge tracing\nthat combines techniques from matrix factorization with recent progress in\nrecurrent neural networks (RNNs) to effectively track the state of a student's\nknowledge. The proposed \\emph{DynEmb} framework enables the tracking of student\nknowledge even without the concept/skill tag information that other knowledge\ntracing models require while simultaneously achieving superior performance. We\nprovide experimental evaluations demonstrating that DynEmb achieves improved\nperformance compared to baselines and illustrating the robustness and\neffectiveness of the proposed framework. We also evaluate our approach using\nseveral real-world datasets showing that the proposed model outperforms the\nprevious state-of-the-art. These results suggest that combining embedding\nmodels with sequential models such as RNNs is a promising new direction for\nknowledge tracing.\n", "versions": [{"version": "v1", "created": "Mon, 18 May 2020 21:56:42 GMT"}], "update_date": "2020-05-20", "authors_parsed": [["Xu", "Liangbei", ""], ["Davenport", "Mark A.", ""]]}, {"id": "2005.09162", "submitter": "Shahabeddin Sotudian", "authors": "Mohammad Hossein Fazel Zarandi, Shahabeddin Sotudian, Oscar Castillo", "title": "A New Validity Index for Fuzzy-Possibilistic C-Means Clustering", "comments": "The following article has been accepted by Scientia Iranica", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In some complicated datasets, due to the presence of noisy data points and\noutliers, cluster validity indices can give conflicting results in determining\nthe optimal number of clusters. This paper presents a new validity index for\nfuzzy-possibilistic c-means clustering called Fuzzy-Possibilistic (FP) index,\nwhich works well in the presence of clusters that vary in shape and density.\nMoreover, FPCM like most of the clustering algorithms is susceptible to some\ninitial parameters. In this regard, in addition to the number of clusters, FPCM\nrequires a priori selection of the degree of fuzziness and the degree of\ntypicality. Therefore, we presented an efficient procedure for determining\ntheir optimal values. The proposed approach has been evaluated using several\nsynthetic and real-world datasets. Final computational results demonstrate the\ncapabilities and reliability of the proposed approach compared with several\nwell-known fuzzy validity indices in the literature. Furthermore, to clarify\nthe ability of the proposed method in real applications, the proposed method is\nimplemented in microarray gene expression data clustering and medical image\nsegmentation.\n", "versions": [{"version": "v1", "created": "Tue, 19 May 2020 01:48:13 GMT"}], "update_date": "2020-05-20", "authors_parsed": [["Zarandi", "Mohammad Hossein Fazel", ""], ["Sotudian", "Shahabeddin", ""], ["Castillo", "Oscar", ""]]}, {"id": "2005.09175", "submitter": "Feng Qi", "authors": "Feng Qi, Guanjun Jiang", "title": "Human-like general language processing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Using language makes human beings surpass animals in wisdom. To let machines\nunderstand, learn, and use language flexibly, we propose a human-like general\nlanguage processing (HGLP) architecture, which contains sensorimotor,\nassociation, and cognitive systems. The HGLP network learns from easy to hard\nlike a child, understands word meaning by coactivating multimodal neurons,\ncomprehends and generates sentences by real-time constructing a virtual world\nmodel, and can express the whole thinking process verbally. HGLP rapidly\nlearned 10+ different tasks including object recognition, sentence\ncomprehension, imagination, attention control, query, inference, motion\njudgement, mixed arithmetic operation, digit tracing and writing, and\nhuman-like iterative thinking process guided by language. Language in the HGLP\nframework is not matching nor correlation statistics, but a script that can\ndescribe and control the imagination.\n", "versions": [{"version": "v1", "created": "Tue, 19 May 2020 02:44:55 GMT"}, {"version": "v2", "created": "Fri, 29 May 2020 08:08:02 GMT"}], "update_date": "2020-06-01", "authors_parsed": [["Qi", "Feng", ""], ["Jiang", "Guanjun", ""]]}, {"id": "2005.09198", "submitter": "Ozgur Ozmen", "authors": "James Nutaro and Ozgur Ozmen", "title": "Quantifying the Uncertainty of Precision Estimates for Rule based Text\n  Classifiers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Rule based classifiers that use the presence and absence of key sub-strings\nto make classification decisions have a natural mechanism for quantifying the\nuncertainty of their precision. For a binary classifier, the key insight is to\ntreat partitions of the sub-string set induced by the documents as Bernoulli\nrandom variables. The mean value of each random variable is an estimate of the\nclassifier's precision when presented with a document inducing that partition.\nThese means can be compared, using standard statistical tests, to a desired or\nexpected classifier precision. A set of binary classifiers can be combined into\na single, multi-label classifier by an application of the Dempster-Shafer\ntheory of evidence. The utility of this approach is demonstrated with a\nbenchmark problem.\n", "versions": [{"version": "v1", "created": "Tue, 19 May 2020 03:51:47 GMT"}], "update_date": "2020-05-20", "authors_parsed": [["Nutaro", "James", ""], ["Ozmen", "Ozgur", ""]]}, {"id": "2005.09220", "submitter": "Pierre-Alexandre Kamienny Mr", "authors": "Pierre-Alexandre Kamienny, Kai Arulkumaran, Feryal Behbahani, Wendelin\n  Boehmer, Shimon Whiteson", "title": "Privileged Information Dropout in Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Using privileged information during training can improve the sample\nefficiency and performance of machine learning systems. This paradigm has been\napplied to reinforcement learning (RL), primarily in the form of distillation\nor auxiliary tasks, and less commonly in the form of augmenting the inputs of\nagents. In this work, we investigate Privileged Information Dropout (\\pid) for\nachieving the latter which can be applied equally to value-based and\npolicy-based RL algorithms. Within a simple partially-observed environment, we\ndemonstrate that \\pid outperforms alternatives for leveraging privileged\ninformation, including distillation and auxiliary tasks, and can successfully\nutilise different types of privileged information. Finally, we analyse its\neffect on the learned representations.\n", "versions": [{"version": "v1", "created": "Tue, 19 May 2020 05:32:33 GMT"}], "update_date": "2020-05-20", "authors_parsed": [["Kamienny", "Pierre-Alexandre", ""], ["Arulkumaran", "Kai", ""], ["Behbahani", "Feryal", ""], ["Boehmer", "Wendelin", ""], ["Whiteson", "Shimon", ""]]}, {"id": "2005.09253", "submitter": "Guillermo P\\'erez", "authors": "Damien Busatto-Gaston, Debraj Chakraborty, Shibashis Guha, Guillermo\n  A. P\\'erez, Jean-Fran\\c{c}ois Raskin", "title": "Safe Learning for Near Optimal Scheduling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we investigate the combination of synthesis, model-based\nlearning, and online sampling techniques to obtain safe and near-optimal\nschedulers for a preemptible task scheduling problem. Our algorithms can handle\nMarkov decision processes (MDPs) that have 1020 states and beyond which cannot\nbe handled with state-of-the art probabilistic model-checkers. We provide\nprobably approximately correct (PAC) guarantees for learning the model.\nAdditionally, we extend Monte-Carlo tree search with advice, computed using\nsafety games or obtained using the earliest-deadline-first scheduler, to safely\nexplore the learned model online. Finally, we implemented and compared our\nalgorithms empirically against shielded deep Q-learning on large task systems.\n", "versions": [{"version": "v1", "created": "Tue, 19 May 2020 07:17:22 GMT"}, {"version": "v2", "created": "Tue, 13 Jul 2021 14:56:39 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["Busatto-Gaston", "Damien", ""], ["Chakraborty", "Debraj", ""], ["Guha", "Shibashis", ""], ["P\u00e9rez", "Guillermo A.", ""], ["Raskin", "Jean-Fran\u00e7ois", ""]]}, {"id": "2005.09280", "submitter": "Anton Kolonin Dr.", "authors": "Anton Kolonin", "title": "Controlled Language and Baby Turing Test for General Conversational\n  Intelligence", "comments": "10 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  General conversational intelligence appears to be an important part of\nartificial general intelligence. Respectively, it requires accessible measures\nof the intelligence quality and controllable ways of its achievement, ideally -\nhaving the linguistic and semantic models represented in a reasonable way. Our\nwork is suggesting to use Baby Turing Test approach to extend the classic\nTuring Test for conversational intelligence and controlled language based on\nsemantic graph representation extensible for arbitrary subject domain. We\ndescribe how the two can be used together to build a general-purpose\nconversational system such as an intelligent assistant for online media and\nsocial network data processing.\n", "versions": [{"version": "v1", "created": "Tue, 19 May 2020 08:27:26 GMT"}], "update_date": "2020-05-20", "authors_parsed": [["Kolonin", "Anton", ""]]}, {"id": "2005.09330", "submitter": "Zhixin Liu", "authors": "Mingxiang Chen, Lei Gao, Qichang Chen, Zhixin Liu", "title": "Dynamic Partial Removal: A Neural Network Heuristic for Large\n  Neighborhood Search", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a novel neural network design that learns the heuristic\nfor Large Neighborhood Search (LNS). LNS consists of a destroy operator and a\nrepair operator that specify a way to carry out the neighborhood search to\nsolve the Combinatorial Optimization problems. The proposed approach in this\npaper applies a Hierarchical Recurrent Graph Convolutional Network (HRGCN) as a\nLNS heuristic, namely Dynamic Partial Removal, with the advantage of adaptive\ndestruction and the potential to search across a large scale, as well as the\ncontext-awareness in both spatial and temporal perspective. This model is\ngeneralized as an efficient heuristic approach to different combinatorial\noptimization problems, especially to the problems with relatively tight\nconstraints. We apply this model to vehicle routing problem (VRP) in this paper\nas an example. The experimental results show that this approach outperforms the\ntraditional LNS heuristics on the same problem as well. The source code is\navailable at\n\\href{https://github.com/water-mirror/DPR}{https://github.com/water-mirror/DPR}.\n", "versions": [{"version": "v1", "created": "Tue, 19 May 2020 09:50:35 GMT"}], "update_date": "2020-05-20", "authors_parsed": [["Chen", "Mingxiang", ""], ["Gao", "Lei", ""], ["Chen", "Qichang", ""], ["Liu", "Zhixin", ""]]}, {"id": "2005.09331", "submitter": "Athina Georgara", "authors": "Athina Georgara, Carles Sierra, Juan A. Rodr\\'iguez-Aguilar", "title": "TAIP: an anytime algorithm for allocating student teams to internship\n  programs", "comments": "10 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In scenarios that require teamwork, we usually have at hand a variety of\nspecific tasks, for which we need to form a team in order to carry out each\none. Here we target the problem of matching teams with tasks within the context\nof education, and specifically in the context of forming teams of students and\nallocating them to internship programs. First we provide a formalization of the\nTeam Allocation for Internship Programs Problem, and show the computational\nhardness of solving it optimally. Thereafter, we propose TAIP, a heuristic\nalgorithm that generates an initial team allocation which later on attempts to\nimprove in an iterative process. Moreover, we conduct a systematic evaluation\nto show that TAIP reaches optimality, and outperforms CPLEX in terms of time.\n", "versions": [{"version": "v1", "created": "Tue, 19 May 2020 09:50:38 GMT"}], "update_date": "2020-05-20", "authors_parsed": [["Georgara", "Athina", ""], ["Sierra", "Carles", ""], ["Rodr\u00edguez-Aguilar", "Juan A.", ""]]}, {"id": "2005.09343", "submitter": "Hong-Bin Liu", "authors": "Hong-Bin Liu, Ickjai Lee", "title": "Bridging the Gap Between Training and Inference for Spatio-Temporal\n  Forecasting", "comments": "ECAI 2020 Accepted, preprint", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spatio-temporal sequence forecasting is one of the fundamental tasks in\nspatio-temporal data mining. It facilitates many real world applications such\nas precipitation nowcasting, citywide crowd flow prediction and air pollution\nforecasting. Recently, a few Seq2Seq based approaches have been proposed, but\none of the drawbacks of Seq2Seq models is that, small errors can accumulate\nquickly along the generated sequence at the inference stage due to the\ndifferent distributions of training and inference phase. That is because\nSeq2Seq models minimise single step errors only during training, however the\nentire sequence has to be generated during the inference phase which generates\na discrepancy between training and inference. In this work, we propose a novel\ncurriculum learning based strategy named Temporal Progressive Growing Sampling\nto effectively bridge the gap between training and inference for\nspatio-temporal sequence forecasting, by transforming the training process from\na fully-supervised manner which utilises all available previous ground-truth\nvalues to a less-supervised manner which replaces some of the ground-truth\ncontext with generated predictions. To do that we sample the target sequence\nfrom midway outputs from intermediate models trained with bigger timescales\nthrough a carefully designed decaying strategy. Experimental results\ndemonstrate that our proposed method better models long term dependencies and\noutperforms baseline approaches on two competitive datasets.\n", "versions": [{"version": "v1", "created": "Tue, 19 May 2020 10:14:43 GMT"}], "update_date": "2020-05-20", "authors_parsed": [["Liu", "Hong-Bin", ""], ["Lee", "Ickjai", ""]]}, {"id": "2005.09406", "submitter": "Sebastian Garcia-Valencia", "authors": "Sebastian Garcia-Valencia", "title": "Embeddings as representation for symbolic music", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  A representation technique that allows encoding music in a way that contains\nmusical meaning would improve the results of any model trained for computer\nmusic tasks like generation of melodies and harmonies of better quality. The\nfield of natural language processing has done a lot of work in finding a way to\ncapture the semantic meaning of words and sentences, and word embeddings have\nsuccessfully shown the capabilities for such a task. In this paper, we\nexperiment with embeddings to represent musical notes from 3 different\nvariations of a dataset and analyze if the model can capture useful musical\npatterns. To do this, the resulting embeddings are visualized in projections\nusing the t-SNE technique.\n", "versions": [{"version": "v1", "created": "Tue, 19 May 2020 13:04:02 GMT"}], "update_date": "2020-05-20", "authors_parsed": [["Garcia-Valencia", "Sebastian", ""]]}, {"id": "2005.09436", "submitter": "Siamak Parhizkari", "authors": "Siamak Parhizkari, Mohammad Bagher Menhaj", "title": "A cognitive based Intrusion detection system", "comments": "18 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Intrusion detection is one of the primary mechanisms to provide computer\nnetworks with security. With an increase in attacks and growing dependence on\nvarious fields such as medicine, commercial, and engineering to give services\nover a network, securing networks have become a significant issue. The purpose\nof Intrusion Detection Systems (IDS) is to make models which can recognize\nregular communications from abnormal ones and take necessary actions. Among\ndifferent methods in this field, Artificial Neural Networks (ANNs) have been\nwidely used. However, ANN-based IDS, has two main disadvantages: 1- Low\ndetection precision. 2- Weak detection stability. To overcome these issues,\nthis paper proposes a new approach based on Deep Neural Network (DNN. The\ngeneral mechanism of our model is as follows: first, some of the data in\ndataset is properly ranked, afterwards, dataset is normalized with Min-Max\nnormalizer to fit in the limited domain. Then dimensionality reduction is\napplied to decrease the amount of both useless dimensions and computational\ncost. After the preprocessing part, Mean-Shift clustering algorithm is the used\nto create different subsets and reduce the complexity of dataset. Based on each\nsubset, two models are trained by Support Vector Machine (SVM) and deep\nlearning method. Between two models for each subset, the model with a higher\naccuracy is chosen. This idea is inspired from philosophy of divide and\nconquer. Hence, the DNN can learn each subset quickly and robustly. Finally, to\nreduce the error from the previous step, an ANN model is trained to gain and\nuse the results in order to be able to predict the attacks. We can reach to\n95.4 percent of accuracy. Possessing a simple structure and less number of\ntunable parameters, the proposed model still has a grand generalization with a\nhigh level of accuracy in compared to other methods such as SVM, Bayes network,\nand STL.\n", "versions": [{"version": "v1", "created": "Tue, 19 May 2020 13:30:30 GMT"}], "update_date": "2020-05-20", "authors_parsed": [["Parhizkari", "Siamak", ""], ["Menhaj", "Mohammad Bagher", ""]]}, {"id": "2005.09453", "submitter": "Zhenhui Ye", "authors": "Zhenhui Ye, Yining Chen, Guanghua Song, Bowei Yang, Shen Fan", "title": "Experience Augmentation: Boosting and Accelerating Off-Policy\n  Multi-Agent Reinforcement Learning", "comments": "10 pages, 4 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Exploration of the high-dimensional state action space is one of the biggest\nchallenges in Reinforcement Learning (RL), especially in multi-agent domain. We\npresent a novel technique called Experience Augmentation, which enables a\ntime-efficient and boosted learning based on a fast, fair and thorough\nexploration to the environment. It can be combined with arbitrary off-policy\nMARL algorithms and is applicable to either homogeneous or heterogeneous\nenvironments. We demonstrate our approach by combining it with MADDPG and\nverifing the performance in two homogeneous and one heterogeneous environments.\nIn the best performing scenario, the MADDPG with experience augmentation\nreaches to the convergence reward of vanilla MADDPG with 1/4 realistic time,\nand its convergence beats the original model by a significant margin. Our\nablation studies show that experience augmentation is a crucial ingredient\nwhich accelerates the training process and boosts the convergence.\n", "versions": [{"version": "v1", "created": "Tue, 19 May 2020 13:57:11 GMT"}, {"version": "v2", "created": "Wed, 20 May 2020 02:12:08 GMT"}], "update_date": "2020-05-21", "authors_parsed": [["Ye", "Zhenhui", ""], ["Chen", "Yining", ""], ["Song", "Guanghua", ""], ["Yang", "Bowei", ""], ["Fan", "Shen", ""]]}, {"id": "2005.09460", "submitter": "Carole Adam", "authors": "Carole Adam", "title": "VigiFlood: evaluating the impact of a change of perspective on flood\n  vigilance", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Emergency managers receive communication training about the importance of\nbeing 'first, right and credible', and taking into account the psychology of\ntheir audience and their particular reasoning under stress and risk. But we\nbelieve that citizens should be similarly trained about how to deal with risk\ncommunication. In particular, such messages necessarily carry a part of\nuncertainty since most natural risks are difficult to accurately forecast ahead\nof time. Yet, citizens should keep trusting the emergency communicators even\nafter they made forecasting errors in the past.\n  We have designed a serious game called Vigiflood, based on a real case study\nof flash floods hitting the South West of France in October 2018. In this game,\nthe user changes perspective by taking the role of an emergency communicator,\nhaving to set the level of vigilance to alert the population, based on\nuncertain clues. Our hypothesis is that this change of perspective can improve\nthe player's awareness and response to future flood vigilance announcements. We\nevaluated this game through an online survey where people were asked to answer\na questionnaire about flood risk awareness and behavioural intentions before\nand after playing the game, in order to assess its impact.\n", "versions": [{"version": "v1", "created": "Tue, 19 May 2020 14:05:11 GMT"}], "update_date": "2020-05-20", "authors_parsed": [["Adam", "Carole", ""]]}, {"id": "2005.09512", "submitter": "Frederico Gadelha Guimaraes", "authors": "Leonardo Augusto Ferreira and Frederico Gadelha Guimar\\~aes and\n  Rodrigo Silva", "title": "Applying Genetic Programming to Improve Interpretability in Machine\n  Learning Models", "comments": "8 pages, 8 figures, submitted and accepted to 2020 IEEE Congress on\n  Evolutionary Computation (IEEE CEC 2020). Copyright 2020 IEEE. Personal use\n  of this material is permitted. Permission from IEEE must be obtained for all\n  other uses", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE cs.SC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Explainable Artificial Intelligence (or xAI) has become an important research\ntopic in the fields of Machine Learning and Deep Learning. In this paper, we\npropose a Genetic Programming (GP) based approach, named Genetic Programming\nExplainer (GPX), to the problem of explaining decisions computed by AI systems.\nThe method generates a noise set located in the neighborhood of the point of\ninterest, whose prediction should be explained, and fits a local explanation\nmodel for the analyzed sample. The tree structure generated by GPX provides a\ncomprehensible analytical, possibly non-linear, symbolic expression which\nreflects the local behavior of the complex model. We considered three machine\nlearning techniques that can be recognized as complex black-box models: Random\nForest, Deep Neural Network and Support Vector Machine in twenty data sets for\nregression and classifications problems. Our results indicate that the GPX is\nable to produce more accurate understanding of complex models than the state of\nthe art. The results validate the proposed approach as a novel way to deploy GP\nto improve interpretability.\n", "versions": [{"version": "v1", "created": "Mon, 18 May 2020 16:09:49 GMT"}], "update_date": "2020-05-20", "authors_parsed": [["Ferreira", "Leonardo Augusto", ""], ["Guimar\u00e3es", "Frederico Gadelha", ""], ["Silva", "Rodrigo", ""]]}, {"id": "2005.09611", "submitter": "Daniel Larsson", "authors": "Daniel T. Larsson and Dipankar Maity and Panagiotis Tsiotras", "title": "Information-Theoretic Abstractions for Planning in Agents with\n  Computational Constraints", "comments": null, "journal-ref": "2021 IEEE Robotics and Automation Letters (RA-L)", "doi": "10.1109/LRA.2021.3099995", "report-no": null, "categories": "cs.RO cs.AI cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we develop a framework for path-planning on abstractions that\nare not provided to the agent a priori but instead emerge as a function of the\navailable computational resources. We show how a path-planning problem in an\nenvironment can be systematically approximated by solving a sequence of easier\nto solve problems on abstractions of the original space. The properties of the\nproblem are analyzed, and a number of theoretical results are presented and\ndiscussed. A numerical example is presented to show the utility of the approach\nand to corroborate the theoretical findings. We conclude by providing a\ndiscussion detailing the connections of the proposed approach to anytime\nalgorithms and bounded rationality.\n", "versions": [{"version": "v1", "created": "Tue, 19 May 2020 17:32:10 GMT"}, {"version": "v2", "created": "Tue, 23 Feb 2021 23:29:56 GMT"}], "update_date": "2021-07-29", "authors_parsed": [["Larsson", "Daniel T.", ""], ["Maity", "Dipankar", ""], ["Tsiotras", "Panagiotis", ""]]}, {"id": "2005.09617", "submitter": "Rajesh Bordawekar", "authors": "Apoorva Nitsure and Rajesh Bordawekar and Jose Neves", "title": "Unlocking New York City Crime Insights using Relational Database\n  Embeddings", "comments": "arXiv admin note: This version withdrawn by arXiv administrators\n  because the author did not have the right to agree to our license at the time\n  of submission", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.AI cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This version withdrawn by arXiv administrators because the author did not\nhave the right to agree to our license at the time of submission.\n", "versions": [{"version": "v1", "created": "Tue, 19 May 2020 17:46:34 GMT"}, {"version": "v2", "created": "Wed, 20 May 2020 14:09:11 GMT"}], "update_date": "2020-05-29", "authors_parsed": [["Nitsure", "Apoorva", ""], ["Bordawekar", "Rajesh", ""], ["Neves", "Jose", ""]]}, {"id": "2005.09624", "submitter": "Yueh-Hua Wu", "authors": "Yueh-Hua Wu, I-Hau Yeh, David Hu, Hong-Yuan Mark Liao", "title": "Batch-Augmented Multi-Agent Reinforcement Learning for Efficient Traffic\n  Signal Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The goal of this work is to provide a viable solution based on reinforcement\nlearning for traffic signal control problems. Although the state-of-the-art\nreinforcement learning approaches have yielded great success in a variety of\ndomains, directly applying it to alleviate traffic congestion can be\nchallenging, considering the requirement of high sample efficiency and how\ntraining data is gathered. In this work, we address several challenges that we\nencountered when we attempted to mitigate serious traffic congestion occurring\nin a metropolitan area. Specifically, we are required to provide a solution\nthat is able to (1) handle the traffic signal control when certain surveillance\ncameras that retrieve information for reinforcement learning are down, (2)\nlearn from batch data without a traffic simulator, and (3) make control\ndecisions without shared information across intersections. We present a\ntwo-stage framework to deal with the above-mentioned situations. The framework\ncan be decomposed into an Evolution Strategies approach that gives a fixed-time\ntraffic signal control schedule and a multi-agent off-policy reinforcement\nlearning that is capable of learning from batch data with the aid of three\nproposed components, bounded action, batch augmentation, and surrogate reward\nclipping. Our experiments show that the proposed framework reduces traffic\ncongestion by 36% in terms of waiting time compared with the currently used\nfixed-time traffic signal plan. Furthermore, the framework requires only 600\nqueries to a simulator to achieve the result.\n", "versions": [{"version": "v1", "created": "Tue, 19 May 2020 17:53:05 GMT"}], "update_date": "2020-05-20", "authors_parsed": [["Wu", "Yueh-Hua", ""], ["Yeh", "I-Hau", ""], ["Hu", "David", ""], ["Liao", "Hong-Yuan Mark", ""]]}, {"id": "2005.09645", "submitter": "Thomas Moerland", "authors": "Thomas M Moerland, Joost Broekens, Aske Plaat, Catholijn M Jonker", "title": "The Second Type of Uncertainty in Monte Carlo Tree Search", "comments": "arXiv admin note: text overlap with arXiv:1805.09218", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Monte Carlo Tree Search (MCTS) efficiently balances exploration and\nexploitation in tree search based on count-derived uncertainty. However, these\nlocal visit counts ignore a second type of uncertainty induced by the size of\nthe subtree below an action. We first show how, due to the lack of this second\nuncertainty type, MCTS may completely fail in well-known sparse exploration\nproblems, known from the reinforcement learning community. We then introduce a\nnew algorithm, which estimates the size of the subtree below an action, and\nleverages this information in the UCB formula to better direct exploration.\nSubsequently, we generalize these ideas by showing that loops, i.e., the\nrepeated occurrence of (approximately) the same state in the same trace, are\nactually a special case of subtree depth variation. Testing on a variety of\ntasks shows that our algorithms increase sample efficiency, especially when the\nplanning budget per timestep is small.\n", "versions": [{"version": "v1", "created": "Tue, 19 May 2020 09:10:51 GMT"}], "update_date": "2020-05-21", "authors_parsed": [["Moerland", "Thomas M", ""], ["Broekens", "Joost", ""], ["Plaat", "Aske", ""], ["Jonker", "Catholijn M", ""]]}, {"id": "2005.09755", "submitter": "Rachel Freedman", "authors": "Rachel Freedman, Jana Schaich Borg, Walter Sinnott-Armstrong, John P.\n  Dickerson, Vincent Conitzer", "title": "Adapting a Kidney Exchange Algorithm to Align with Human Values", "comments": null, "journal-ref": "Artificial Intelligence 283 (2020) 103261", "doi": "10.1016/j.artint.2020.103261 10.1145/3278721.3278727", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The efficient and fair allocation of limited resources is a classical problem\nin economics and computer science. In kidney exchanges, a central market maker\nallocates living kidney donors to patients in need of an organ. Patients and\ndonors in kidney exchanges are prioritized using ad-hoc weights decided on by\ncommittee and then fed into an allocation algorithm that determines who gets\nwhat--and who does not. In this paper, we provide an end-to-end methodology for\nestimating weights of individual participant profiles in a kidney exchange. We\nfirst elicit from human subjects a list of patient attributes they consider\nacceptable for the purpose of prioritizing patients (e.g., medical\ncharacteristics, lifestyle choices, and so on). Then, we ask subjects\ncomparison queries between patient profiles and estimate weights in a\nprincipled way from their responses. We show how to use these weights in kidney\nexchange market clearing algorithms. We then evaluate the impact of the weights\nin simulations and find that the precise numerical values of the weights we\ncomputed matter little, other than the ordering of profiles that they imply.\nHowever, compared to not prioritizing patients at all, there is a significant\neffect, with certain classes of patients being (de)prioritized based on the\nhuman-elicited value judgments.\n", "versions": [{"version": "v1", "created": "Tue, 19 May 2020 21:00:29 GMT"}], "update_date": "2020-05-21", "authors_parsed": [["Freedman", "Rachel", ""], ["Borg", "Jana Schaich", ""], ["Sinnott-Armstrong", "Walter", ""], ["Dickerson", "John P.", ""], ["Conitzer", "Vincent", ""]]}, {"id": "2005.09814", "submitter": "Manan Tomar Mr.", "authors": "Manan Tomar, Lior Shani, Yonathan Efroni, Mohammad Ghavamzadeh", "title": "Mirror Descent Policy Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mirror descent (MD), a well-known first-order method in constrained convex\noptimization, has recently been shown as an important tool to analyze\ntrust-region algorithms in reinforcement learning (RL). However, there remains\na considerable gap between such theoretically analyzed algorithms and the ones\nused in practice. Inspired by this, we propose an efficient RL algorithm,\ncalled {\\em mirror descent policy optimization} (MDPO). MDPO iteratively\nupdates the policy by {\\em approximately} solving a trust-region problem, whose\nobjective function consists of two terms: a linearization of the standard RL\nobjective and a proximity term that restricts two consecutive policies to be\nclose to each other. Each update performs this approximation by taking multiple\ngradient steps on this objective function. We derive {\\em on-policy} and {\\em\noff-policy} variants of MDPO, while emphasizing important design choices\nmotivated by the existing theory of MD in RL. We highlight the connections\nbetween on-policy MDPO and two popular trust-region RL algorithms: TRPO and\nPPO, and show that explicitly enforcing the trust-region constraint is in fact\n{\\em not} a necessity for high performance gains in TRPO. We then show how the\npopular soft actor-critic (SAC) algorithm can be derived by slight\nmodifications of off-policy MDPO. Overall, MDPO is derived from the MD\nprinciples, offers a unified approach to viewing a number of popular RL\nalgorithms, and performs better than or on-par with TRPO, PPO, and SAC in a\nnumber of continuous control tasks. Code is available at\n\\url{https://github.com/manantomar/Mirror-Descent-Policy-Optimization}.\n", "versions": [{"version": "v1", "created": "Wed, 20 May 2020 01:30:43 GMT"}, {"version": "v2", "created": "Tue, 9 Jun 2020 23:50:29 GMT"}, {"version": "v3", "created": "Sat, 31 Oct 2020 14:37:24 GMT"}, {"version": "v4", "created": "Fri, 19 Feb 2021 10:05:24 GMT"}, {"version": "v5", "created": "Mon, 7 Jun 2021 13:44:15 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Tomar", "Manan", ""], ["Shani", "Lior", ""], ["Efroni", "Yonathan", ""], ["Ghavamzadeh", "Mohammad", ""]]}, {"id": "2005.09833", "submitter": "Shiqi Zhang", "authors": "Keting Lu, Shiqi Zhang, Peter Stone, Xiaoping Chen", "title": "Learning and Reasoning for Robot Dialog and Navigation Tasks", "comments": "arXiv admin note: substantial text overlap with arXiv:1809.11074", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning and probabilistic reasoning algorithms aim at learning\nfrom interaction experiences and reasoning with probabilistic contextual\nknowledge respectively. In this research, we develop algorithms for robot task\ncompletions, while looking into the complementary strengths of reinforcement\nlearning and probabilistic reasoning techniques. The robots learn from\ntrial-and-error experiences to augment their declarative knowledge base, and\nthe augmented knowledge can be used for speeding up the learning process in\npotentially different tasks. We have implemented and evaluated the developed\nalgorithms using mobile robots conducting dialog and navigation tasks. From the\nresults, we see that our robot's performance can be improved by both reasoning\nwith human knowledge and learning from task-completion experience. More\ninterestingly, the robot was able to learn from navigation tasks to improve its\ndialog strategies.\n", "versions": [{"version": "v1", "created": "Wed, 20 May 2020 03:20:42 GMT"}, {"version": "v2", "created": "Mon, 31 Aug 2020 02:07:43 GMT"}], "update_date": "2020-09-02", "authors_parsed": [["Lu", "Keting", ""], ["Zhang", "Shiqi", ""], ["Stone", "Peter", ""], ["Chen", "Xiaoping", ""]]}, {"id": "2005.09867", "submitter": "Kim Phuc Tran", "authors": "Zhenglei He (GEMTEX), Kim Phuc Tran (GEMTEX), S\\'ebastien Thomassey\n  (GEMTEX), Xianyi Zeng (GEMTEX), Changhai Yi", "title": "A reinforcement learning based decision support system in textile\n  manufacturing process", "comments": null, "journal-ref": "15th International Conference on Intelligent Systems and Knowledge\n  Engineering (ISKE2020), Aug 2020, Cologne, Germany", "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduced a reinforcement learning based decision support system\nin textile manufacturing process. A solution optimization problem of color\nfading ozonation is discussed and set up as a Markov Decision Process (MDP) in\nterms of tuple {S, A, P, R}. Q-learning is used to train an agent in the\ninteraction with the setup environment by accumulating the reward R. According\nto the application result, it is found that the proposed MDP model has well\nexpressed the optimization problem of textile manufacturing process discussed\nin this paper, therefore the use of reinforcement learning to support decision\nmaking in this sector is conducted and proven that is applicable with promising\nprospects.\n", "versions": [{"version": "v1", "created": "Wed, 20 May 2020 06:33:47 GMT"}], "update_date": "2020-05-21", "authors_parsed": [["He", "Zhenglei", "", "GEMTEX"], ["Tran", "Kim Phuc", "", "GEMTEX"], ["Thomassey", "S\u00e9bastien", "", "GEMTEX"], ["Zeng", "Xianyi", "", "GEMTEX"], ["Yi", "Changhai", ""]]}, {"id": "2005.09900", "submitter": "Deepak P", "authors": "Deepak P and Savitha Sam Abraham", "title": "Fair Outlier Detection", "comments": "In Proceedings of The 21th International Conference on Web\n  Information Systems Engineering (WISE 2020), Amsterdam and Leiden, The\n  Netherlands", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An outlier detection method may be considered fair over specified sensitive\nattributes if the results of outlier detection are not skewed towards\nparticular groups defined on such sensitive attributes. In this task, we\nconsider, for the first time to our best knowledge, the task of fair outlier\ndetection. In this work, we consider the task of fair outlier detection over\nmultiple multi-valued sensitive attributes (e.g., gender, race, religion,\nnationality, marital status etc.). We propose a fair outlier detection method,\nFairLOF, that is inspired by the popular LOF formulation for neighborhood-based\noutlier detection. We outline ways in which unfairness could be induced within\nLOF and develop three heuristic principles to enhance fairness, which form the\nbasis of the FairLOF method. Being a novel task, we develop an evaluation\nframework for fair outlier detection, and use that to benchmark FairLOF on\nquality and fairness of results. Through an extensive empirical evaluation over\nreal-world datasets, we illustrate that FairLOF is able to achieve significant\nimprovements in fairness at sometimes marginal degradations on result quality\nas measured against the fairness-agnostic LOF method.\n", "versions": [{"version": "v1", "created": "Wed, 20 May 2020 08:02:41 GMT"}, {"version": "v2", "created": "Tue, 4 Aug 2020 20:18:41 GMT"}], "update_date": "2020-08-06", "authors_parsed": [["P", "Deepak", ""], ["Abraham", "Savitha Sam", ""]]}, {"id": "2005.09961", "submitter": "Tristan Cazenave", "authors": "Tristan Cazenave and Thomas Fournier", "title": "Monte Carlo Inverse Folding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The RNA Inverse Folding problem comes from computational biology. The goal is\nto find a molecule that has a given folding. It is important for scientific\nfields such as bioengineering, pharmaceutical research, biochemistry, synthetic\nbiology and RNA nanostructures. Nested Monte Carlo Search has given excellent\nresults for this problem. We propose to adapt and evaluate different Monte\nCarlo Search algorithms for the RNA Inverse Folding problem.\n", "versions": [{"version": "v1", "created": "Wed, 20 May 2020 11:07:20 GMT"}], "update_date": "2020-05-21", "authors_parsed": [["Cazenave", "Tristan", ""], ["Fournier", "Thomas", ""]]}, {"id": "2005.09971", "submitter": "Paul Hofmann", "authors": "Paul Hofmann and Zaid Tashman", "title": "Hidden Markov Models and their Application for Predicting Failure Events", "comments": "Will be published in the proceedings of ICCS 2020;\n  @Booklet{EasyChair:3183, author = {Paul Hofmann and Zaid Tashman}, title =\n  {Hidden Markov Models and their Application for Predicting Failure Events},\n  howpublished = {EasyChair Preprint no. 3183}, year = {EasyChair, 2020}}", "journal-ref": null, "doi": "10.1007/978-3-030-50420-5_35", "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show how Markov mixed membership models (MMMM) can be used to predict the\ndegradation of assets. We model the degradation path of individual assets, to\npredict overall failure rates. Instead of a separate distribution for each\nhidden state, we use hierarchical mixtures of distributions in the exponential\nfamily. In our approach the observation distribution of the states is a finite\nmixture distribution of a small set of (simpler) distributions shared across\nall states. Using tied-mixture observation distributions offers several\nadvantages. The mixtures act as a regularization for typically very sparse\nproblems, and they reduce the computational effort for the learning algorithm\nsince there are fewer distributions to be found. Using shared mixtures enables\nsharing of statistical strength between the Markov states and thus transfer\nlearning. We determine for individual assets the trade-off between the risk of\nfailure and extended operating hours by combining a MMMM with a partially\nobservable Markov decision process (POMDP) to dynamically optimize the policy\nfor when and how to maintain the asset.\n", "versions": [{"version": "v1", "created": "Wed, 20 May 2020 11:30:16 GMT"}], "update_date": "2020-06-03", "authors_parsed": [["Hofmann", "Paul", ""], ["Tashman", "Zaid", ""]]}, {"id": "2005.09980", "submitter": "Nils K\\\"obis C", "authors": "Nils K\\\"obis, Luca Mossink", "title": "Artificial Intelligence versus Maya Angelou: Experimental evidence that\n  people cannot differentiate AI-generated from human-written poetry", "comments": "Computers in Human Behavior 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL econ.GN q-fin.EC", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The release of openly available, robust natural language generation\nalgorithms (NLG) has spurred much public attention and debate. One reason lies\nin the algorithms' purported ability to generate human-like text across various\ndomains. Empirical evidence using incentivized tasks to assess whether people\n(a) can distinguish and (b) prefer algorithm-generated versus human-written\ntext is lacking. We conducted two experiments assessing behavioral reactions to\nthe state-of-the-art Natural Language Generation algorithm GPT-2 (Ntotal =\n830). Using the identical starting lines of human poems, GPT-2 produced samples\nof poems. From these samples, either a random poem was chosen\n(Human-out-of-the-loop) or the best one was selected (Human-in-the-loop) and in\nturn matched with a human-written poem. In a new incentivized version of the\nTuring Test, participants failed to reliably detect the\nalgorithmically-generated poems in the Human-in-the-loop treatment, yet\nsucceeded in the Human-out-of-the-loop treatment. Further, people reveal a\nslight aversion to algorithm-generated poetry, independent on whether\nparticipants were informed about the algorithmic origin of the poem\n(Transparency) or not (Opacity). We discuss what these results convey about the\nperformance of NLG algorithms to produce human-like text and propose\nmethodologies to study such learning algorithms in human-agent experimental\nsettings.\n", "versions": [{"version": "v1", "created": "Wed, 20 May 2020 11:52:28 GMT"}, {"version": "v2", "created": "Tue, 8 Sep 2020 19:31:44 GMT"}], "update_date": "2020-09-10", "authors_parsed": [["K\u00f6bis", "Nils", ""], ["Mossink", "Luca", ""]]}, {"id": "2005.09998", "submitter": "Bram Aerts", "authors": "Bram Aerts, Simon Vandevelde, and Joost Vennekens", "title": "Tackling the DMN Challenges with cDMN: a Tight Integration of DMN and\n  constraint reasoning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.DB cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes an extension to the DMN standard, called cDMN. It aims\nto enlarge the expressivity of DMN in order to solve more complex problems,\nwhile retaining DMN's goal of being readable by domain experts. We test cDMN by\nsolving the most complex challenges posted on the DM Community website. We\ncompare our own cDMN solutions to the solutions that have been submitted to the\nwebsite and find that our approach is competitive, both in readability and\ncompactness. Moreover, cDMN is able to solve more challenges than any other\napproach.\n", "versions": [{"version": "v1", "created": "Sun, 17 May 2020 14:50:34 GMT"}], "update_date": "2020-05-21", "authors_parsed": [["Aerts", "Bram", ""], ["Vandevelde", "Simon", ""], ["Vennekens", "Joost", ""]]}, {"id": "2005.10000", "submitter": "Jianwen Sun Dr", "authors": "Jianwen Sun, Yan Zheng, Jianye Hao, Zhaopeng Meng, Yang Liu", "title": "Continuous Multiagent Control using Collective Behavior Entropy for\n  Large-Scale Home Energy Management", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.AI cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the increasing popularity of electric vehicles, distributed energy\ngeneration and storage facilities in smart grid systems, an efficient\nDemand-Side Management (DSM) is urgent for energy savings and peak loads\nreduction. Traditional DSM works focusing on optimizing the energy activities\nfor a single household can not scale up to large-scale home energy management\nproblems. Multi-agent Deep Reinforcement Learning (MA-DRL) shows a potential\nway to solve the problem of scalability, where modern homes interact together\nto reduce energy consumers consumption while striking a balance between energy\ncost and peak loads reduction. However, it is difficult to solve such an\nenvironment with the non-stationarity, and existing MA-DRL approaches cannot\neffectively give incentives for expected group behavior. In this paper, we\npropose a collective MA-DRL algorithm with continuous action space to provide\nfine-grained control on a large scale microgrid. To mitigate the\nnon-stationarity of the microgrid environment, a novel predictive model is\nproposed to measure the collective market behavior. Besides, a collective\nbehavior entropy is introduced to reduce the high peak loads incurred by the\ncollective behaviors of all householders in the smart grid. Empirical results\nshow that our approach significantly outperforms the state-of-the-art methods\nregarding power cost reduction and daily peak loads optimization.\n", "versions": [{"version": "v1", "created": "Thu, 14 May 2020 16:07:55 GMT"}], "update_date": "2020-05-21", "authors_parsed": [["Sun", "Jianwen", ""], ["Zheng", "Yan", ""], ["Hao", "Jianye", ""], ["Meng", "Zhaopeng", ""], ["Liu", "Yang", ""]]}, {"id": "2005.10050", "submitter": "Samaneh Abbasi Sureshjani", "authors": "Samaneh Abbasi-Sureshjani, Ralf Raumanns, Britt E. J. Michels, Gerard\n  Schouten, Veronika Cheplygina", "title": "Risk of Training Diagnostic Algorithms on Data with Demographic Bias", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the critical challenges in machine learning applications is to have\nfair predictions. There are numerous recent examples in various domains that\nconvincingly show that algorithms trained with biased datasets can easily lead\nto erroneous or discriminatory conclusions. This is even more crucial in\nclinical applications where the predictive algorithms are designed mainly based\non a limited or given set of medical images and demographic variables such as\nage, sex and race are not taken into account. In this work, we conduct a survey\nof the MICCAI 2018 proceedings to investigate the common practice in medical\nimage analysis applications. Surprisingly, we found that papers focusing on\ndiagnosis rarely describe the demographics of the datasets used, and the\ndiagnosis is purely based on images. In order to highlight the importance of\nconsidering the demographics in diagnosis tasks, we used a publicly available\ndataset of skin lesions. We then demonstrate that a classifier with an overall\narea under the curve (AUC) of 0.83 has variable performance between 0.76 and\n0.91 on subgroups based on age and sex, even though the training set was\nrelatively balanced. Moreover, we show that it is possible to learn unbiased\nfeatures by explicitly using demographic variables in an adversarial training\nsetup, which leads to balanced scores per subgroups. Finally, we discuss the\nimplications of these results and provide recommendations for further research.\n", "versions": [{"version": "v1", "created": "Wed, 20 May 2020 13:51:01 GMT"}, {"version": "v2", "created": "Wed, 17 Jun 2020 11:33:59 GMT"}], "update_date": "2020-06-18", "authors_parsed": [["Abbasi-Sureshjani", "Samaneh", ""], ["Raumanns", "Ralf", ""], ["Michels", "Britt E. J.", ""], ["Schouten", "Gerard", ""], ["Cheplygina", "Veronika", ""]]}, {"id": "2005.10131", "submitter": "Joseph Y. Halpern", "authors": "Meir Friedenberg and Joseph Y. Halpern", "title": "Combining the Causal Judgments of Experts with Possibly Different Focus\n  Areas", "comments": "Appear in the Proceedings of the Sixteenth International Conference\n  on Principles of Knowledge Representation and Reasoning (KR2018}, 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many real-world settings, a decision-maker must combine information\nprovided by different experts in order to decide on an effective policy.\nAlrajeh, Chockler, and Halpern [2018] showed how to combine causal models that\nare compatible in the sense that, for variables that appear in both models, the\nexperts agree on the causal structure. In this work we show how causal models\ncan be combined in cases where the experts might disagree on the causal\nstructure for variables that appear in both models due to having different\nfocus areas. We provide a new formal definition of compatibility of models in\nthis setting and show how compatible models can be combined. We also consider\nthe complexity of determining whether models are compatible. We believe that\nthe notions defined in this work are of direct relevance to many practical\ndecision making scenarios that come up in natural, social, and medical science\nsettings.\n", "versions": [{"version": "v1", "created": "Wed, 20 May 2020 15:28:08 GMT"}], "update_date": "2020-05-21", "authors_parsed": [["Friedenberg", "Meir", ""], ["Halpern", "Joseph Y.", ""]]}, {"id": "2005.10180", "submitter": "Joseph Y. Halpern", "authors": "Dalal Alrajeh, Hana Chockler, and Joseph Y. Halpern", "title": "Combining Experts' Causal Judgments", "comments": "A preliminary version of the paper appeared in \\emph{Proceedings of\n  the Thirty-Second AAAI Conference on Artificial Intelligence (AAAI-18)},\n  2018}", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Consider a policymaker who wants to decide which intervention to perform in\norder to change a currently undesirable situation. The policymaker has at her\ndisposal a team of experts, each with their own understanding of the causal\ndependencies between different factors contributing to the outcome. The\npolicymaker has varying degrees of confidence in the experts' opinions. She\nwants to combine their opinions in order to decide on the most effective\nintervention. We formally define the notion of an effective intervention, and\nthen consider how experts' causal judgments can be combined in order to\ndetermine the most effective intervention. We define a notion of two causal\nmodels being \\emph{compatible}, and show how compatible causal models can be\nmerged. We then use it as the basis for combining experts' causal judgments. We\nalso provide a definition of decomposition for causal models to cater for cases\nwhen models are incompatible. We illustrate our approach on a number of\nreal-life examples.\n", "versions": [{"version": "v1", "created": "Wed, 20 May 2020 16:41:07 GMT"}], "update_date": "2020-05-21", "authors_parsed": [["Alrajeh", "Dalal", ""], ["Chockler", "Hana", ""], ["Halpern", "Joseph Y.", ""]]}, {"id": "2005.10284", "submitter": "Arash Rahnama", "authors": "Arash Rahnama and Andrew Tseng", "title": "An Adversarial Approach for Explaining the Predictions of Deep Neural\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning models have been successfully applied to a wide range of\napplications including computer vision, natural language processing, and speech\nrecognition. A successful implementation of these models however, usually\nrelies on deep neural networks (DNNs) which are treated as opaque black-box\nsystems due to their incomprehensible complexity and intricate internal\nmechanism. In this work, we present a novel algorithm for explaining the\npredictions of a DNN using adversarial machine learning. Our approach\nidentifies the relative importance of input features in relation to the\npredictions based on the behavior of an adversarial attack on the DNN. Our\nalgorithm has the advantage of being fast, consistent, and easy to implement\nand interpret. We present our detailed analysis that demonstrates how the\nbehavior of an adversarial attack, given a DNN and a task, stays consistent for\nany input test data point proving the generality of our approach. Our analysis\nenables us to produce consistent and efficient explanations. We illustrate the\neffectiveness of our approach by conducting experiments using a variety of\nDNNs, tasks, and datasets. Finally, we compare our work with other well-known\ntechniques in the current literature.\n", "versions": [{"version": "v1", "created": "Wed, 20 May 2020 18:06:53 GMT"}, {"version": "v2", "created": "Wed, 27 May 2020 19:42:44 GMT"}, {"version": "v3", "created": "Mon, 22 Jun 2020 15:43:34 GMT"}, {"version": "v4", "created": "Mon, 28 Sep 2020 16:17:36 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Rahnama", "Arash", ""], ["Tseng", "Andrew", ""]]}, {"id": "2005.10297", "submitter": "Joseph Y. Halpern", "authors": "Natasha Alechina, Joseph Y. Halpern, and Brian Logan", "title": "Causality, Responsibility and Blame in Team Plans", "comments": "{\\em Proceedings of the Sixteenth Appears in \\emph{Proceedings of the\n  International Joint Conference on Autonomous Agents and Multiagent Systems\n  (AAMAS 2017)}, 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many objectives can be achieved (or may be achieved more effectively) only by\na group of agents executing a team plan. If a team plan fails, it is often of\ninterest to determine what caused the failure, the degree of responsibility of\neach agent for the failure, and the degree of blame attached to each agent. We\nshow how team plans can be represented in terms of structural equations, and\nthen apply the definitions of causality introduced by Halpern [2015] and degree\nof responsibility and blame introduced by Chockler and Halpern [2004] to\ndetermine the agent(s) who caused the failure and what their degree of\nresponsibility/blame is. We also prove new results on the complexity of\ncomputing causality and degree of responsibility and blame, showing that they\ncan be determined in polynomial time for many team plans of interest.\n", "versions": [{"version": "v1", "created": "Wed, 20 May 2020 18:21:19 GMT"}], "update_date": "2020-05-22", "authors_parsed": [["Alechina", "Natasha", ""], ["Halpern", "Joseph Y.", ""], ["Logan", "Brian", ""]]}, {"id": "2005.10327", "submitter": "James Wootton", "authors": "James R. Wootton", "title": "A quantum procedure for map generation", "comments": "To be published in the proceedings of the IEEE Conference on Games", "journal-ref": null, "doi": "10.1109/CoG47356.2020.9231571", "report-no": null, "categories": "cs.AI cs.ET quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quantum computation is an emerging technology that promises a wide range of\npossible use cases. This promise is primarily based on algorithms that are\nunlikely to be viable over the coming decade. For near-term applications,\nquantum software needs to be carefully tailored to the hardware available. In\nthis paper, we begin to explore whether near-term quantum computers could\nprovide tools that are useful in the creation and implementation of computer\ngames. The procedural generation of geopolitical maps and their associated\nhistory is considered as a motivating example. This is performed by encoding a\nrudimentary decision making process for the nations within a quantum procedure\nthat is well-suited to near-term devices. Given the novelty of quantum\ncomputing within the field of procedural generation, we also provide an\nintroduction to the basic concepts involved.\n", "versions": [{"version": "v1", "created": "Wed, 20 May 2020 19:29:29 GMT"}], "update_date": "2020-12-04", "authors_parsed": [["Wootton", "James R.", ""]]}, {"id": "2005.10329", "submitter": "Hui-Po Wang", "authors": "Hui-Po Wang, Tribhuvanesh Orekondy, Mario Fritz", "title": "InfoScrub: Towards Attribute Privacy by Targeted Obfuscation", "comments": "20 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Personal photos of individuals when shared online, apart from exhibiting a\nmyriad of memorable details, also reveals a wide range of private information\nand potentially entails privacy risks (e.g., online harassment, tracking). To\nmitigate such risks, it is crucial to study techniques that allow individuals\nto limit the private information leaked in visual data. We tackle this problem\nin a novel image obfuscation framework: to maximize entropy on inferences over\ntargeted privacy attributes, while retaining image fidelity. We approach the\nproblem based on an encoder-decoder style architecture, with two key novelties:\n(a) introducing a discriminator to perform bi-directional translation\nsimultaneously from multiple unpaired domains; (b) predicting an image\ninterpolation which maximizes uncertainty over a target set of attributes. We\nfind our approach generates obfuscated images faithful to the original input\nimages, and additionally increase uncertainty by 6.2$\\times$ (or up to 0.85\nbits) over the non-obfuscated counterparts.\n", "versions": [{"version": "v1", "created": "Wed, 20 May 2020 19:48:04 GMT"}, {"version": "v2", "created": "Tue, 1 Jun 2021 13:55:02 GMT"}], "update_date": "2021-06-02", "authors_parsed": [["Wang", "Hui-Po", ""], ["Orekondy", "Tribhuvanesh", ""], ["Fritz", "Mario", ""]]}, {"id": "2005.10349", "submitter": "Benjamin Dutton", "authors": "Benjamin Dutton", "title": "Adversarial Canonical Correlation Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Canonical Correlation Analysis (CCA) is a statistical technique used to\nextract common information from multiple data sources or views. It has been\nused in various representation learning problems, such as dimensionality\nreduction, word embedding, and clustering. Recent work has given CCA\nprobabilistic footing in a deep learning context and uses a variational lower\nbound for the data log likelihood to estimate model parameters. Alternatively,\nadversarial techniques have arisen in recent years as a powerful alternative to\nvariational Bayesian methods in autoencoders. In this work, we explore\nstraightforward adversarial alternatives to recent work in Deep Variational CCA\n(VCCA and VCCA-Private) we call ACCA and ACCA-Private and show how these\napproaches offer a stronger and more flexible way to match the approximate\nposteriors coming from encoders to much larger classes of priors than the VCCA\nand VCCA-Private models. This allows new priors for what constitutes a good\nrepresentation, such as disentangling underlying factors of variation, to be\nmore directly pursued. We offer further analysis on the multi-level\ndisentangling properties of VCCA-Private and ACCA-Private through the use of a\nnewly designed dataset we call Tangled MNIST. We also design a validation\ncriteria for these models that is theoretically grounded, task-agnostic, and\nworks well in practice. Lastly, we fill a minor research gap by deriving an\nadditional variational lower bound for VCCA that allows the representation to\nuse view-specific information from both input views.\n", "versions": [{"version": "v1", "created": "Wed, 20 May 2020 20:46:35 GMT"}, {"version": "v2", "created": "Tue, 9 Jun 2020 21:31:21 GMT"}], "update_date": "2020-06-18", "authors_parsed": [["Dutton", "Benjamin", ""]]}, {"id": "2005.10381", "submitter": "Joseph Y. Halpern", "authors": "Nan Rong, Joseph Y. Halpern, Ashutosh Saxena", "title": "MDPs with Unawareness in Robotics", "comments": "Appears in Proceedings of the 32nd Conference on Uncertainty in AI\n  (UAI 2016), 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We formalize decision-making problems in robotics and automated control using\ncontinuous MDPs and actions that take place over continuous time intervals. We\nthen approximate the continuous MDP using finer and finer discretizations.\nDoing this results in a family of systems, each of which has an extremely large\naction space, although only a few actions are \"interesting\". We can view the\ndecision maker as being unaware of which actions are \"interesting\". We can\nmodel this using MDPUs, MDPs with unawareness, where the action space is much\nsmaller. As we show, MDPUs can be used as a general framework for learning\ntasks in robotic problems. We prove results on the difficulty of learning a\nnear-optimal policy in an an MDPU for a continuous task. We apply these ideas\nto the problem of having a humanoid robot learn on its own how to walk.\n", "versions": [{"version": "v1", "created": "Wed, 20 May 2020 22:48:02 GMT"}], "update_date": "2020-05-22", "authors_parsed": [["Rong", "Nan", ""], ["Halpern", "Joseph Y.", ""], ["Saxena", "Ashutosh", ""]]}, {"id": "2005.10383", "submitter": "Joseph Y. Halpern", "authors": "Matvey Soloviev, Joseph Y. Halpern", "title": "Information Acquisition Under Resource Limitations in a Noisy\n  Environment", "comments": "A preliminary version of the paper appeared in \\emph{Proceedings of\n  the Thirty-Second AAAI Conference on Artificial Intelligence (AAAI-18)}, 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a theoretical model of information acquisition under resource\nlimitations in a noisy environment. An agent must guess the truth value of a\ngiven Boolean formula $\\varphi$ after performing a bounded number of noisy\ntests of the truth values of variables in the formula. We observe that, in\ngeneral, the problem of finding an optimal testing strategy for $\\phi$ is hard,\nbut we suggest a useful heuristic. The techniques we use also give insight into\ntwo apparently unrelated, but well-studied problems: (1) \\emph{rational\ninattention}, that is, when it is rational to ignore pertinent information (the\noptimal strategy may involve hardly ever testing variables that are clearly\nrelevant to $\\phi$), and (2) what makes a formula hard to learn/remember.\n", "versions": [{"version": "v1", "created": "Wed, 20 May 2020 22:49:48 GMT"}], "update_date": "2020-05-22", "authors_parsed": [["Soloviev", "Matvey", ""], ["Halpern", "Joseph Y.", ""]]}, {"id": "2005.10411", "submitter": "Zixuan Huang", "authors": "Zixuan Huang, Yin Li", "title": "Interpretable and Accurate Fine-grained Recognition via Region Grouping", "comments": "Accepted to CVPR 2020 (Oral)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an interpretable deep model for fine-grained visual recognition.\nAt the core of our method lies the integration of region-based part discovery\nand attribution within a deep neural network. Our model is trained using\nimage-level object labels, and provides an interpretation of its results via\nthe segmentation of object parts and the identification of their contributions\ntowards classification. To facilitate the learning of object parts without\ndirect supervision, we explore a simple prior of the occurrence of object\nparts. We demonstrate that this prior, when combined with our region-based part\ndiscovery and attribution, leads to an interpretable model that remains highly\naccurate. Our model is evaluated on major fine-grained recognition datasets,\nincluding CUB-200, CelebA and iNaturalist. Our results compare favorably to\nstate-of-the-art methods on classification tasks, and our method outperforms\nprevious approaches on the localization of object parts.\n", "versions": [{"version": "v1", "created": "Thu, 21 May 2020 01:18:26 GMT"}], "update_date": "2020-05-22", "authors_parsed": [["Huang", "Zixuan", ""], ["Li", "Yin", ""]]}, {"id": "2005.10416", "submitter": "Abdelrahman Abdallah", "authors": "Abdelrahman Abdallah, Mahmoud Kasem, Mohamed Hamada, and Shaymaa Sdeek", "title": "Automated Question Answer medical model based on Deep Learning\n  Technology", "comments": null, "journal-ref": "ICEMIS'20: Proceedings of the 6th International Conference on\n  Engineering & MIS 2020", "doi": "10.1145/3410352.3410744", "report-no": "13", "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Artificial intelligence can now provide more solutions for different\nproblems, especially in the medical field. One of those problems the lack of\nanswers to any given medical/health-related question. The Internet is full of\nforums that allow people to ask some specific questions and get great answers\nfor them. Nevertheless, browsing these questions in order to locate one similar\nto your own, also finding a satisfactory answer is a difficult and\ntime-consuming task. This research will introduce a solution to this problem by\nautomating the process of generating qualified answers to these questions and\ncreating a kind of digital doctor. Furthermore, this research will train an\nend-to-end model using the framework of RNN and the encoder-decoder to generate\nsensible and useful answers to a small set of medical/health issues. The\nproposed model was trained and evaluated using data from various online\nservices, such as WebMD, HealthTap, eHealthForums, and iCliniq.\n", "versions": [{"version": "v1", "created": "Thu, 21 May 2020 01:40:01 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Abdallah", "Abdelrahman", ""], ["Kasem", "Mahmoud", ""], ["Hamada", "Mohamed", ""], ["Sdeek", "Shaymaa", ""]]}, {"id": "2005.10430", "submitter": "Jungseock Joo", "authors": "Jungseock Joo, Kimmo K\\\"arkk\\\"ainen", "title": "Gender Slopes: Counterfactual Fairness for Computer Vision Models by\n  Attribute Manipulation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automated computer vision systems have been applied in many domains including\nsecurity, law enforcement, and personal devices, but recent reports suggest\nthat these systems may produce biased results, discriminating against people in\ncertain demographic groups. Diagnosing and understanding the underlying true\ncauses of model biases, however, are challenging tasks because modern computer\nvision systems rely on complex black-box models whose behaviors are hard to\ndecode. We propose to use an encoder-decoder network developed for image\nattribute manipulation to synthesize facial images varying in the dimensions of\ngender and race while keeping other signals intact. We use these synthesized\nimages to measure counterfactual fairness of commercial computer vision\nclassifiers by examining the degree to which these classifiers are affected by\ngender and racial cues controlled in the images, e.g., feminine faces may\nelicit higher scores for the concept of nurse and lower scores for STEM-related\nconcepts. We also report the skewed gender representations in an online search\nservice on profession-related keywords, which may explain the origin of the\nbiases encoded in the models.\n", "versions": [{"version": "v1", "created": "Thu, 21 May 2020 02:33:28 GMT"}], "update_date": "2020-05-22", "authors_parsed": [["Joo", "Jungseock", ""], ["K\u00e4rkk\u00e4inen", "Kimmo", ""]]}, {"id": "2005.10450", "submitter": "Feng Ji", "authors": "Shuke Peng, Feng Ji, Zehao Lin, Shaobo Cui, Haiqing Chen, Yin Zhang", "title": "MTSS: Learn from Multiple Domain Teachers and Become a Multi-domain\n  Dialogue Expert", "comments": "AAAI 2020, Spotlight Paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  How to build a high-quality multi-domain dialogue system is a challenging\nwork due to its complicated and entangled dialogue state space among each\ndomain, which seriously limits the quality of dialogue policy, and further\naffects the generated response. In this paper, we propose a novel method to\nacquire a satisfying policy and subtly circumvent the knotty dialogue state\nrepresentation problem in the multi-domain setting. Inspired by real school\nteaching scenarios, our method is composed of multiple domain-specific teachers\nand a universal student. Each individual teacher only focuses on one specific\ndomain and learns its corresponding domain knowledge and dialogue policy based\non a precisely extracted single domain dialogue state representation. Then,\nthese domain-specific teachers impart their domain knowledge and policies to a\nuniversal student model and collectively make this student model a multi-domain\ndialogue expert. Experiment results show that our method reaches competitive\nresults with SOTAs in both multi-domain and single domain setting.\n", "versions": [{"version": "v1", "created": "Thu, 21 May 2020 03:40:02 GMT"}], "update_date": "2020-05-22", "authors_parsed": [["Peng", "Shuke", ""], ["Ji", "Feng", ""], ["Lin", "Zehao", ""], ["Cui", "Shaobo", ""], ["Chen", "Haiqing", ""], ["Zhang", "Yin", ""]]}, {"id": "2005.10539", "submitter": "Paula Mu\\~noz Lago", "authors": "Paula Mu\\~noz-Lago, Gonzalo M\\'endez", "title": "An approach to Beethoven's 10th Symphony", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.AI eess.AS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Ludwig van Beethoven composed his symphonies between 1799 and 1825, when he\nwas writing his Tenth symphony. As we dispose of a great amount of data\nbelonging to his work, the purpose of this paper is to investigate the\npossibility of extracting patterns on his compositional model from symbolic\ndata and generate what would have been his last symphony, the Tenth. A neural\nnetwork model has been built based on the Long Short-Therm Memory (LSTM) neural\nnetworks. After training the model, the generated music has been analysed by\ncomparing the input data with the results, and establishing differences between\nthe generated outputs based on the training data used to obtain them. The\nstructure of the outputs strongly depends on the symphonies used to train the\nnetwork.\n", "versions": [{"version": "v1", "created": "Thu, 21 May 2020 09:36:24 GMT"}], "update_date": "2020-05-22", "authors_parsed": [["Mu\u00f1oz-Lago", "Paula", ""], ["M\u00e9ndez", "Gonzalo", ""]]}, {"id": "2005.10600", "submitter": "Steven Frank", "authors": "Steven J. Frank and Andrea M. Frank", "title": "A Neural Network Looks at Leonardo's(?) Salvator Mundi", "comments": "This is the author's final version. The article has been accepted for\n  publication in Leonardo (MIT Press)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We use convolutional neural networks (CNNs) to analyze authorship questions\nsurrounding the works of Leonardo da Vinci -- in particular, Salvator Mundi,\nthe world's most expensive painting and among the most controversial. Trained\non the works of an artist under study and visually comparable works of other\nartists, our system can identify likely forgeries and shed light on attribution\ncontroversies. Leonardo's few extant paintings test the limits of our system\nand require corroborative techniques of testing and analysis.\n", "versions": [{"version": "v1", "created": "Thu, 21 May 2020 12:27:40 GMT"}], "update_date": "2020-05-22", "authors_parsed": [["Frank", "Steven J.", ""], ["Frank", "Andrea M.", ""]]}, {"id": "2005.10619", "submitter": "Sindhu Padakandla", "authors": "Sindhu Padakandla", "title": "A Survey of Reinforcement Learning Algorithms for Dynamically Varying\n  Environments", "comments": null, "journal-ref": "ACM Computing Surveys 2021", "doi": "10.1145/3459991", "report-no": "Volume 54, Issue 6", "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning (RL) algorithms find applications in inventory\ncontrol, recommender systems, vehicular traffic management, cloud computing and\nrobotics. The real-world complications of many tasks arising in these domains\nmakes them difficult to solve with the basic assumptions underlying classical\nRL algorithms. RL agents in these applications often need to react and adapt to\nchanging operating conditions. A significant part of research on single-agent\nRL techniques focuses on developing algorithms when the underlying assumption\nof stationary environment model is relaxed. This paper provides a survey of RL\nmethods developed for handling dynamically varying environment models. The goal\nof methods not limited by the stationarity assumption is to help autonomous\nagents adapt to varying operating conditions. This is possible either by\nminimizing the rewards lost during learning by RL agent or by finding a\nsuitable policy for the RL agent which leads to efficient operation of the\nunderlying system. A representative collection of these algorithms is discussed\nin detail in this work along with their categorization and their relative\nmerits and demerits. Additionally we also review works which are tailored to\napplication domains. Finally, we discuss future enhancements for this field.\n", "versions": [{"version": "v1", "created": "Tue, 19 May 2020 09:42:42 GMT"}], "update_date": "2021-06-03", "authors_parsed": [["Padakandla", "Sindhu", ""]]}, {"id": "2005.10622", "submitter": "Bin Wang", "authors": "Cong Fei, Bin Wang, Yuzheng Zhuang, Zongzhang Zhang, Jianye Hao,\n  Hongbo Zhang, Xuewu Ji and Wulong Liu", "title": "Triple-GAIL: A Multi-Modal Imitation Learning Framework with Generative\n  Adversarial Nets", "comments": "7 papges, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative adversarial imitation learning (GAIL) has shown promising results\nby taking advantage of generative adversarial nets, especially in the field of\nrobot learning. However, the requirement of isolated single modal\ndemonstrations limits the scalability of the approach to real world scenarios\nsuch as autonomous vehicles' demand for a proper understanding of human\ndrivers' behavior. In this paper, we propose a novel multi-modal GAIL\nframework, named Triple-GAIL, that is able to learn skill selection and\nimitation jointly from both expert demonstrations and continuously generated\nexperiences with data augmentation purpose by introducing an auxiliary skill\nselector. We provide theoretical guarantees on the convergence to optima for\nboth of the generator and the selector respectively. Experiments on real driver\ntrajectories and real-time strategy game datasets demonstrate that Triple-GAIL\ncan better fit multi-modal behaviors close to the demonstrators and outperforms\nstate-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Tue, 19 May 2020 03:24:24 GMT"}, {"version": "v2", "created": "Fri, 22 May 2020 01:05:30 GMT"}], "update_date": "2020-05-25", "authors_parsed": [["Fei", "Cong", ""], ["Wang", "Bin", ""], ["Zhuang", "Yuzheng", ""], ["Zhang", "Zongzhang", ""], ["Hao", "Jianye", ""], ["Zhang", "Hongbo", ""], ["Ji", "Xuewu", ""], ["Liu", "Wulong", ""]]}, {"id": "2005.10674", "submitter": "Andrea Borghesi", "authors": "Michele Lombardi, Federico Baldo, Andrea Borghesi, Michela Milano", "title": "An Analysis of Regularized Approaches for Constrained Machine Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Regularization-based approaches for injecting constraints in Machine Learning\n(ML) were introduced to improve a predictive model via expert knowledge. We\ntackle the issue of finding the right balance between the loss (the accuracy of\nthe learner) and the regularization term (the degree of constraint\nsatisfaction). The key results of this paper is the formal demonstration that\nthis type of approach cannot guarantee to find all optimal solutions. In\nparticular, in the non-convex case there might be optima for the constrained\nproblem that do not correspond to any multiplier value.\n", "versions": [{"version": "v1", "created": "Wed, 20 May 2020 15:16:26 GMT"}], "update_date": "2020-05-22", "authors_parsed": [["Lombardi", "Michele", ""], ["Baldo", "Federico", ""], ["Borghesi", "Andrea", ""], ["Milano", "Michela", ""]]}, {"id": "2005.10691", "submitter": "Andrea Borghesi", "authors": "Andrea Borghesi, Federico Baldo, Michela Milano", "title": "Improving Deep Learning Models via Constraint-Based Domain Knowledge: a\n  Brief Survey", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Learning (DL) models proved themselves to perform extremely well on a\nwide variety of learning tasks, as they can learn useful patterns from large\ndata sets. However, purely data-driven models might struggle when very\ndifficult functions need to be learned or when there is not enough available\ntraining data. Fortunately, in many domains prior information can be retrieved\nand used to boost the performance of DL models. This paper presents a first\nsurvey of the approaches devised to integrate domain knowledge, expressed in\nthe form of constraints, in DL learning models to improve their performance, in\nparticular targeting deep neural networks. We identify five (non-mutually\nexclusive) categories that encompass the main approaches to inject domain\nknowledge: 1) acting on the features space, 2) modifications to the hypothesis\nspace, 3) data augmentation, 4) regularization schemes, 5) constrained\nlearning.\n", "versions": [{"version": "v1", "created": "Tue, 19 May 2020 15:34:09 GMT"}], "update_date": "2020-05-22", "authors_parsed": [["Borghesi", "Andrea", ""], ["Baldo", "Federico", ""], ["Milano", "Michela", ""]]}, {"id": "2005.10696", "submitter": "Hao Sun", "authors": "Hao Sun, Zhenghao Peng, Bo Dai, Jian Guo, Dahua Lin, Bolei Zhou", "title": "Novel Policy Seeking with Constrained Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In problem-solving, we humans can come up with multiple novel solutions to\nthe same problem. However, reinforcement learning algorithms can only produce a\nset of monotonous policies that maximize the cumulative reward but lack\ndiversity and novelty. In this work, we address the problem of generating novel\npolicies in reinforcement learning tasks. Instead of following the\nmulti-objective framework used in existing methods, we propose to rethink the\nproblem under a novel perspective of constrained optimization. We first\nintroduce a new metric to evaluate the difference between policies and then\ndesign two practical novel policy generation methods following the new\nperspective. The two proposed methods, namely the Constrained Task Novel\nBisector (CTNB) and the Interior Policy Differentiation (IPD), are derived from\nthe feasible direction method and the interior point method commonly known in\nthe constrained optimization literature. Experimental comparisons on the MuJoCo\ncontrol suite show our methods can achieve substantial improvement over\nprevious novelty-seeking methods in terms of both the novelty of policies and\ntheir performances in the primal task.\n", "versions": [{"version": "v1", "created": "Thu, 21 May 2020 14:39:14 GMT"}, {"version": "v2", "created": "Mon, 5 Jul 2021 07:18:38 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Sun", "Hao", ""], ["Peng", "Zhenghao", ""], ["Dai", "Bo", ""], ["Guo", "Jian", ""], ["Lin", "Dahua", ""], ["Zhou", "Bolei", ""]]}, {"id": "2005.10716", "submitter": "Weixin Liang", "authors": "Weixin Liang, James Zou, Zhou Yu", "title": "Beyond User Self-Reported Likert Scale Ratings: A Comparison Model for\n  Automatic Dialog Evaluation", "comments": null, "journal-ref": "ACL 2020", "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Open Domain dialog system evaluation is one of the most important challenges\nin dialog research. Existing automatic evaluation metrics, such as BLEU are\nmostly reference-based. They calculate the difference between the generated\nresponse and a limited number of available references. Likert-score based\nself-reported user rating is widely adopted by social conversational systems,\nsuch as Amazon Alexa Prize chatbots. However, self-reported user rating suffers\nfrom bias and variance among different users. To alleviate this problem, we\nformulate dialog evaluation as a comparison task. We also propose an automatic\nevaluation model CMADE (Comparison Model for Automatic Dialog Evaluation) that\nautomatically cleans self-reported user ratings as it trains on them.\nSpecifically, we first use a self-supervised method to learn better dialog\nfeature representation, and then use KNN and Shapley to remove confusing\nsamples. Our experiments show that CMADE achieves 89.2% accuracy in the dialog\ncomparison task.\n", "versions": [{"version": "v1", "created": "Thu, 21 May 2020 15:14:49 GMT"}, {"version": "v2", "created": "Fri, 12 Jun 2020 04:05:58 GMT"}], "update_date": "2020-09-23", "authors_parsed": [["Liang", "Weixin", ""], ["Zou", "James", ""], ["Yu", "Zhou", ""]]}, {"id": "2005.10738", "submitter": "Bruno Perez", "authors": "Bruno Perez, Julien Henriet, Christophe Lang, Laurent Philippe", "title": "Multi-agent model for risk prediction in surgery", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Risk management resulting from the actions and states of the different\nelements making up a operating room is a major concern during a surgical\nprocedure. Agent-based simulation shows an interest through its interaction\nconcepts, interactivity and autonomy of different simulator entities. We want\nin our study to implement a generator of alerts to listen the evolution of\ndifferent settings applied to the simulator of agents (human fatigue, material\nefficiency, infection rate ...). This article presents our model, its\nimplementation and the first results obtained. It should be noted that this\nstudy also made it possible to identify several scientific obstacles, such as\nthe integration of different levels of abstraction, the coupling of species,\nthe coexistence of several scales in the same environment and the deduction of\nunpredictable alerts. Case-based reasoning (CBR) is a beginning of response\nrelative to the last lock mentioned and will be discussed in this paper.\n", "versions": [{"version": "v1", "created": "Thu, 21 May 2020 15:45:27 GMT"}, {"version": "v2", "created": "Wed, 22 Jul 2020 13:39:15 GMT"}], "update_date": "2020-07-23", "authors_parsed": [["Perez", "Bruno", ""], ["Henriet", "Julien", ""], ["Lang", "Christophe", ""], ["Philippe", "Laurent", ""]]}, {"id": "2005.10872", "submitter": "Carlos Florensa", "authors": "Michelle A. Lee, Carlos Florensa, Jonathan Tremblay, Nathan Ratliff,\n  Animesh Garg, Fabio Ramos, Dieter Fox", "title": "Guided Uncertainty-Aware Policy Optimization: Combining Learning and\n  Model-Based Strategies for Sample-Efficient Policy Learning", "comments": null, "journal-ref": "International Conference in Robotics and Automation 2020", "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditional robotic approaches rely on an accurate model of the environment,\na detailed description of how to perform the task, and a robust perception\nsystem to keep track of the current state. On the other hand, reinforcement\nlearning approaches can operate directly from raw sensory inputs with only a\nreward signal to describe the task, but are extremely sample-inefficient and\nbrittle. In this work, we combine the strengths of model-based methods with the\nflexibility of learning-based methods to obtain a general method that is able\nto overcome inaccuracies in the robotics perception/actuation pipeline, while\nrequiring minimal interactions with the environment. This is achieved by\nleveraging uncertainty estimates to divide the space in regions where the given\nmodel-based policy is reliable, and regions where it may have flaws or not be\nwell defined. In these uncertain regions, we show that a locally learned-policy\ncan be used directly with raw sensory inputs. We test our algorithm, Guided\nUncertainty-Aware Policy Optimization (GUAPO), on a real-world robot performing\npeg insertion. Videos are available at https://sites.google.com/view/guapo-rl\n", "versions": [{"version": "v1", "created": "Thu, 21 May 2020 19:47:05 GMT"}, {"version": "v2", "created": "Tue, 26 May 2020 16:34:43 GMT"}], "update_date": "2020-05-27", "authors_parsed": [["Lee", "Michelle A.", ""], ["Florensa", "Carlos", ""], ["Tremblay", "Jonathan", ""], ["Ratliff", "Nathan", ""], ["Garg", "Animesh", ""], ["Ramos", "Fabio", ""], ["Fox", "Dieter", ""]]}, {"id": "2005.10934", "submitter": "Homanga Bharadhwaj", "authors": "Homanga Bharadhwaj, Animesh Garg, Florian Shkurti", "title": "LEAF: Latent Exploration Along the Frontier", "comments": "Published as a conference paper in ICRA 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Self-supervised goal proposal and reaching is a key component for exploration\nand efficient policy learning algorithms. Such a self-supervised approach\nwithout access to any oracle goal sampling distribution requires deep\nexploration and commitment so that long horizon plans can be efficiently\ndiscovered. In this paper, we propose an exploration framework, which learns a\ndynamics-aware manifold of reachable states. For a goal, our proposed method\ndeterministically visits a state at the current frontier of reachable states\n(commitment/reaching) and then stochastically explores to reach the goal\n(exploration). This allocates exploration budget near the frontier of the\nreachable region instead of its interior. We target the challenging problem of\npolicy learning from initial and goal states specified as images, and do not\nassume any access to the underlying ground-truth states of the robot and the\nenvironment. To keep track of reachable latent states, we propose a\ndistance-conditioned reachability network that is trained to infer whether one\nstate is reachable from another within the specified latent space distance.\nGiven an initial state, we obtain a frontier of reachable states from that\nstate. By incorporating a curriculum for sampling easier goals (closer to the\nstart state) before more difficult goals, we demonstrate that the proposed\nself-supervised exploration algorithm, superior performance compared to\nexisting baselines on a set of challenging robotic\nenvironments.https://sites.google.com/view/leaf-exploration\n", "versions": [{"version": "v1", "created": "Thu, 21 May 2020 22:46:31 GMT"}, {"version": "v2", "created": "Thu, 18 Jun 2020 22:06:21 GMT"}, {"version": "v3", "created": "Mon, 26 Apr 2021 18:05:56 GMT"}], "update_date": "2021-04-28", "authors_parsed": [["Bharadhwaj", "Homanga", ""], ["Garg", "Animesh", ""], ["Shkurti", "Florian", ""]]}, {"id": "2005.10956", "submitter": "Long Sha", "authors": "Tong Yang, Long Sha, Pengyu Hong", "title": "NagE: Non-Abelian Group Embedding for Knowledge Graphs", "comments": "work accepted the 29th ACM International Conference on Information\n  and Knowledge Management", "journal-ref": null, "doi": "10.1145/3340531.3411875", "report-no": null, "categories": "cs.AI cs.LG math.GR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We demonstrated the existence of a group algebraic structure hidden in\nrelational knowledge embedding problems, which suggests that a group-based\nembedding framework is essential for designing embedding models. Our\ntheoretical analysis explores merely the intrinsic property of the embedding\nproblem itself hence is model-independent. Motivated by the theoretical\nanalysis, we have proposed a group theory-based knowledge graph embedding\nframework, in which relations are embedded as group elements, and entities are\nrepresented by vectors in group action spaces. We provide a generic recipe to\nconstruct embedding models associated with two instantiating examples: SO3E and\nSU2E, both of which apply a continuous non-Abelian group as the relation\nembedding. Empirical experiments using these two exampling models have shown\nstate-of-the-art results on benchmark datasets.\n", "versions": [{"version": "v1", "created": "Fri, 22 May 2020 00:54:45 GMT"}, {"version": "v2", "created": "Mon, 20 Jul 2020 21:25:20 GMT"}, {"version": "v3", "created": "Thu, 3 Sep 2020 14:44:44 GMT"}], "update_date": "2020-09-04", "authors_parsed": [["Yang", "Tong", ""], ["Sha", "Long", ""], ["Hong", "Pengyu", ""]]}, {"id": "2005.10960", "submitter": "Harini Suresh", "authors": "Harini Suresh, Natalie Lao, Ilaria Liccardi", "title": "Misplaced Trust: Measuring the Interference of Machine Learning in Human\n  Decision-Making", "comments": "10 pages", "journal-ref": "12th ACM Conference on Web Science, July 6-10, 2020, Southampton,\n  United Kingdom", "doi": "10.1145/3394231.3397922", "report-no": null, "categories": "cs.HC cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  ML decision-aid systems are increasingly common on the web, but their\nsuccessful integration relies on people trusting them appropriately: they\nshould use the system to fill in gaps in their ability, but recognize signals\nthat the system might be incorrect. We measured how people's trust in ML\nrecommendations differs by expertise and with more system information through a\ntask-based study of 175 adults. We used two tasks that are difficult for\nhumans: comparing large crowd sizes and identifying similar-looking animals.\nOur results provide three key insights: (1) People trust incorrect ML\nrecommendations for tasks that they perform correctly the majority of the time,\neven if they have high prior knowledge about ML or are given information\nindicating the system is not confident in its prediction; (2) Four different\ntypes of system information all increased people's trust in recommendations;\nand (3) Math and logic skills may be as important as ML for decision-makers\nworking with ML recommendations.\n", "versions": [{"version": "v1", "created": "Fri, 22 May 2020 01:22:58 GMT"}], "update_date": "2020-05-25", "authors_parsed": [["Suresh", "Harini", ""], ["Lao", "Natalie", ""], ["Liccardi", "Ilaria", ""]]}, {"id": "2005.11014", "submitter": "Ajay Chatterjee", "authors": "Ajay Chatterjee and Shubhashis Sengupta", "title": "Intent Mining from past conversations for conversational agent", "comments": "8 pages, 2 figures", "journal-ref": "Proceedings of the 28th International Conference on Computational\n  Linguistics, 2020", "doi": null, "report-no": "https://www.aclweb.org/anthology/2020.coling-main.366", "categories": "cs.CL cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Conversational systems are of primary interest in the AI community. Chatbots\nare increasingly being deployed to provide round-the-clock support and to\nincrease customer engagement. Many of the commercial bot building frameworks\nfollow a standard approach that requires one to build and train an intent model\nto recognize a user input. Intent models are trained in a supervised setting\nwith a collection of textual utterance and intent label pairs. Gathering a\nsubstantial and wide coverage of training data for different intent is a\nbottleneck in the bot building process. Moreover, the cost of labeling a\nhundred to thousands of conversations with intent is a time consuming and\nlaborious job. In this paper, we present an intent discovery framework that\ninvolves 4 primary steps: Extraction of textual utterances from a conversation\nusing a pre-trained domain agnostic Dialog Act Classifier (Data Extraction),\nautomatic clustering of similar user utterances (Clustering), manual annotation\nof clusters with an intent label (Labeling) and propagation of intent labels to\nthe utterances from the previous step, which are not mapped to any cluster\n(Label Propagation); to generate intent training data from raw conversations.\nWe have introduced a novel density-based clustering algorithm ITER-DBSCAN for\nunbalanced data clustering. Subject Matter Expert (Annotators with domain\nexpertise) manually looks into the clustered user utterances and provides an\nintent label for discovery. We conducted user studies to validate the\neffectiveness of the trained intent model generated in terms of coverage of\nintents, accuracy and time saving concerning manual annotation. Although the\nsystem is developed for building an intent model for the conversational system,\nthis framework can also be used for a short text clustering or as a labeling\nframework.\n", "versions": [{"version": "v1", "created": "Fri, 22 May 2020 05:29:13 GMT"}, {"version": "v2", "created": "Wed, 11 Nov 2020 04:45:07 GMT"}, {"version": "v3", "created": "Thu, 12 Nov 2020 07:44:22 GMT"}, {"version": "v4", "created": "Mon, 18 Jan 2021 13:45:27 GMT"}], "update_date": "2021-01-19", "authors_parsed": [["Chatterjee", "Ajay", ""], ["Sengupta", "Shubhashis", ""]]}, {"id": "2005.11016", "submitter": "Anis Najar", "authors": "Anis Najar and Mohamed Chetouani", "title": "Reinforcement learning with human advice: a survey", "comments": "Under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we provide an overview of the existing methods for integrating\nhuman advice into a Reinforcement Learning process. We first propose a taxonomy\nof the different forms of advice that can be provided to a learning agent. We\nthen describe the methods that can be used for interpreting advice when its\nmeaning is not determined beforehand. Finally, we review different approaches\nfor integrating advice into the learning process.\n", "versions": [{"version": "v1", "created": "Fri, 22 May 2020 06:00:13 GMT"}, {"version": "v2", "created": "Tue, 24 Nov 2020 09:02:59 GMT"}], "update_date": "2020-11-25", "authors_parsed": [["Najar", "Anis", ""], ["Chetouani", "Mohamed", ""]]}, {"id": "2005.11019", "submitter": "Florian Richoux", "authors": "Florian Richoux", "title": "microPhantom: Playing microRTS under uncertainty and chaos", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This competition paper presents microPhantom, a bot playing microRTS and\nparticipating in the 2020 microRTS AI competition. microPhantom is based on our\nprevious bot POAdaptive which won the partially observable track of the 2018\nand 2019 microRTS AI competitions. In this paper, we focus on decision-making\nunder uncertainty, by tackling the Unit Production Problem with a method based\non a combination of Constraint Programming and decision theory. We show that\nusing our method to decide which units to train improves significantly the win\nrate against the second-best microRTS bot from the partially observable track.\nWe also show that our method is resilient in chaotic environments, with a very\nsmall loss of efficiency only. To allow replicability and to facilitate further\nresearch, the source code of microPhantom is available, as well as the\nConstraint Programming toolkit it uses.\n", "versions": [{"version": "v1", "created": "Fri, 22 May 2020 06:05:46 GMT"}, {"version": "v2", "created": "Wed, 17 Jun 2020 03:05:00 GMT"}], "update_date": "2020-06-18", "authors_parsed": [["Richoux", "Florian", ""]]}, {"id": "2005.11077", "submitter": "Zhezhang Ding", "authors": "Donghao Xu, Zhezhang Ding, Chenfeng Tu, Huijing Zhao, Mathieu Moze,\n  Fran\\c{c}ois Aioun, and Franck Guillemard", "title": "Driver Identification through Stochastic Multi-State Car-Following\n  Modeling", "comments": "13 pages, 4 figures. Submitted to T.ITS", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Intra-driver and inter-driver heterogeneity has been confirmed to exist in\nhuman driving behaviors by many studies. In this study, a joint model of the\ntwo types of heterogeneity in car-following behavior is proposed as an approach\nof driver profiling and identification. It is assumed that all drivers share a\npool of driver states; under each state a car-following data sequence obeys a\nspecific probability distribution in feature space; each driver has his/her own\nprobability distribution over the states, called driver profile, which\ncharacterize the intradriver heterogeneity, while the difference between the\ndriver profile of different drivers depict the inter-driver heterogeneity.\nThus, the driver profile can be used to distinguish a driver from others. Based\non the assumption, a stochastic car-following model is proposed to take both\nintra-driver and inter-driver heterogeneity into consideration, and a method is\nproposed to jointly learn parameters in behavioral feature extractor, driver\nstates and driver profiles. Experiments demonstrate the performance of the\nproposed method in driver identification on naturalistic car-following data:\naccuracy of 82.3% is achieved in an 8-driver experiment using 10 car-following\nsequences of duration 15 seconds for online inference. The potential of fast\nregistration of new drivers are demonstrated and discussed.\n", "versions": [{"version": "v1", "created": "Fri, 22 May 2020 09:39:00 GMT"}], "update_date": "2020-05-25", "authors_parsed": [["Xu", "Donghao", ""], ["Ding", "Zhezhang", ""], ["Tu", "Chenfeng", ""], ["Zhao", "Huijing", ""], ["Moze", "Mathieu", ""], ["Aioun", "Fran\u00e7ois", ""], ["Guillemard", "Franck", ""]]}, {"id": "2005.11081", "submitter": "Natalia Vesselinova", "authors": "Natalia Vesselinova, Rebecca Steinert, Daniel F. Perez-Ramirez, and\n  Magnus Boman", "title": "Learning Combinatorial Optimization on Graphs: A Survey with\n  Applications to Networking", "comments": "29 pages, 1 figure, open access journal publication", "journal-ref": "IEEE Access, vol. 8, 2020, pp. 120388--120416", "doi": "10.1109/ACCESS.2020.3004964", "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing approaches to solving combinatorial optimization problems on graphs\nsuffer from the need to engineer each problem algorithmically, with practical\nproblems recurring in many instances. The practical side of theoretical\ncomputer science, such as computational complexity, then needs to be addressed.\nRelevant developments in machine learning research on graphs are surveyed for\nthis purpose. We organize and compare the structures involved with learning to\nsolve combinatorial optimization problems, with a special eye on the\ntelecommunications domain and its continuous development of live and research\nnetworks.\n", "versions": [{"version": "v1", "created": "Fri, 22 May 2020 09:45:36 GMT"}, {"version": "v2", "created": "Mon, 13 Jul 2020 18:03:39 GMT"}], "update_date": "2020-07-15", "authors_parsed": [["Vesselinova", "Natalia", ""], ["Steinert", "Rebecca", ""], ["Perez-Ramirez", "Daniel F.", ""], ["Boman", "Magnus", ""]]}, {"id": "2005.11093", "submitter": "Yania Molina Souto", "authors": "Yania Molina Souto, Rafael Pereira, Roc\\'io Zorrilla, Anderson Chaves,\n  Brian Tsan, Florin Rusu, Eduardo Ogasawara, Artur Ziviani, Fabio Porto", "title": "DJEnsemble: On the Selection of a Disjoint Ensemble of Deep Learning\n  Black-Box Spatio-Temporal Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we present a cost-based approach for the automatic selection\nand allocation of a disjoint ensemble of black-box predictors to answer\npredictive spatio-temporal queries. Our approach is divided into two parts --\noffline and online. During the offline part, we preprocess the predictive\ndomain data -- transforming it into a regular grid -- and the black-box models\n-- computing their spatio-temporal learning function. In the online part, we\ncompute a DJEnsemble plan which minimizes a multivariate cost function based on\nestimates for the prediction error and the execution cost -- producing a model\nspatial allocation matrix -- and run the optimal ensemble plan. We conduct a\nset of extensive experiments that evaluate the DJEnsemble approach and\nhighlight its efficiency. We show that our cost model produces plans with\nperformance close to the actual best plan. When compared against the\ntraditional ensemble approach, DJEnsemble achieves up to $4X$ improvement in\nexecution time and almost $9X$ improvement in prediction accuracy. To the best\nof our knowledge, this is the first work to solve the problem of optimizing the\nallocation of black-box models to answer predictive spatio-temporal queries.\n", "versions": [{"version": "v1", "created": "Fri, 22 May 2020 10:37:16 GMT"}, {"version": "v2", "created": "Mon, 25 May 2020 15:36:51 GMT"}, {"version": "v3", "created": "Tue, 17 Nov 2020 15:56:46 GMT"}], "update_date": "2020-11-18", "authors_parsed": [["Souto", "Yania Molina", ""], ["Pereira", "Rafael", ""], ["Zorrilla", "Roc\u00edo", ""], ["Chaves", "Anderson", ""], ["Tsan", "Brian", ""], ["Rusu", "Florin", ""], ["Ogasawara", "Eduardo", ""], ["Ziviani", "Artur", ""], ["Porto", "Fabio", ""]]}, {"id": "2005.11151", "submitter": "Felix Hamza-Lup", "authors": "Felix G. Hamza-Lup, Adytia Suri, Ionut E. Iacob, Ioana R. Goldbach,\n  Lateef Rasheed and Paul N. Borza", "title": "Attention Patterns Detection using Brain Computer Interfaces", "comments": null, "journal-ref": "ACM SE 2020", "doi": null, "report-no": null, "categories": "cs.HC cs.AI eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The human brain provides a range of functions such as expressing emotions,\ncontrolling the rate of breathing, etc., and its study has attracted the\ninterest of scientists for many years. As machine learning models become more\nsophisticated, and bio-metric data becomes more readily available through new\nnon-invasive technologies, it becomes increasingly possible to gain access to\ninteresting biometric data that could revolutionize Human-Computer Interaction.\nIn this research, we propose a method to assess and quantify human attention\nlevels and their effects on learning. In our study, we employ a brain computer\ninterface (BCI) capable of detecting brain wave activity and displaying the\ncorresponding electroencephalograms (EEG). We train recurrent neural networks\n(RNNS) to identify the type of activity an individual is performing.\n", "versions": [{"version": "v1", "created": "Wed, 20 May 2020 11:55:37 GMT"}], "update_date": "2020-05-25", "authors_parsed": [["Hamza-Lup", "Felix G.", ""], ["Suri", "Adytia", ""], ["Iacob", "Ionut E.", ""], ["Goldbach", "Ioana R.", ""], ["Rasheed", "Lateef", ""], ["Borza", "Paul N.", ""]]}, {"id": "2005.11153", "submitter": "Hongyin Luo", "authors": "Hongyin Luo, Shang-Wen Li, James Glass", "title": "Prototypical Q Networks for Automatic Conversational Diagnosis and\n  Few-Shot New Disease Adaption", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spoken dialog systems have seen applications in many domains, including\nmedical for automatic conversational diagnosis. State-of-the-art dialog\nmanagers are usually driven by deep reinforcement learning models, such as deep\nQ networks (DQNs), which learn by interacting with a simulator to explore the\nentire action space since real conversations are limited. However, the\nDQN-based automatic diagnosis models do not achieve satisfying performances\nwhen adapted to new, unseen diseases with only a few training samples. In this\nwork, we propose the Prototypical Q Networks (ProtoQN) as the dialog manager\nfor the automatic diagnosis systems. The model calculates prototype embeddings\nwith real conversations between doctors and patients, learning from them and\nsimulator-augmented dialogs more efficiently. We create both supervised and\nfew-shot learning tasks with the Muzhi corpus. Experiments showed that the\nProtoQN significantly outperformed the baseline DQN model in both supervised\nand few-shot learning scenarios, and achieves state-of-the-art few-shot\nlearning performances.\n", "versions": [{"version": "v1", "created": "Tue, 19 May 2020 19:10:49 GMT"}], "update_date": "2020-05-25", "authors_parsed": [["Luo", "Hongyin", ""], ["Li", "Shang-Wen", ""], ["Glass", "James", ""]]}, {"id": "2005.11164", "submitter": "Malte Schilling", "authors": "Malte Schilling, Kai Konen, Frank W. Ohl, Timo Korthals", "title": "Decentralized Deep Reinforcement Learning for a Distributed and Adaptive\n  Locomotion Controller of a Hexapod Robot", "comments": "Submitted as an IEEE conference paper (updated to 15 seeds in\n  comparisons)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Locomotion is a prime example for adaptive behavior in animals and biological\ncontrol principles have inspired control architectures for legged robots. While\nmachine learning has been successfully applied to many tasks in recent years,\nDeep Reinforcement Learning approaches still appear to struggle when applied to\nreal world robots in continuous control tasks and in particular do not appear\nas robust solutions that can handle uncertainties well. Therefore, there is a\nnew interest in incorporating biological principles into such learning\narchitectures. While inducing a hierarchical organization as found in motor\ncontrol has shown already some success, we here propose a decentralized\norganization as found in insect motor control for coordination of different\nlegs. A decentralized and distributed architecture is introduced on a simulated\nhexapod robot and the details of the controller are learned through Deep\nReinforcement Learning. We first show that such a concurrent local structure is\nable to learn better walking behavior. Secondly, that the simpler organization\nis learned faster compared to holistic approaches.\n", "versions": [{"version": "v1", "created": "Thu, 21 May 2020 11:40:37 GMT"}], "update_date": "2020-05-25", "authors_parsed": [["Schilling", "Malte", ""], ["Konen", "Kai", ""], ["Ohl", "Frank W.", ""], ["Korthals", "Timo", ""]]}, {"id": "2005.11176", "submitter": "Irina Nikishina", "authors": "Irina Nikishina and Varvara Logacheva and Alexander Panchenko and\n  Natalia Loukachevitch", "title": "RUSSE'2020: Findings of the First Taxonomy Enrichment Task for the\n  Russian language", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes the results of the first shared task on taxonomy\nenrichment for the Russian language. The participants were asked to extend an\nexisting taxonomy with previously unseen words: for each new word their systems\nshould provide a ranked list of possible (candidate) hypernyms. In comparison\nto the previous tasks for other languages, our competition has a more realistic\ntask setting: new words were provided without definitions. Instead, we provided\na textual corpus where these new terms occurred. For this evaluation campaign,\nwe developed a new evaluation dataset based on unpublished RuWordNet data. The\nshared task features two tracks: \"nouns\" and \"verbs\". 16 teams participated in\nthe task demonstrating high results with more than half of them outperforming\nthe provided baseline.\n", "versions": [{"version": "v1", "created": "Fri, 22 May 2020 13:30:37 GMT"}], "update_date": "2020-05-25", "authors_parsed": [["Nikishina", "Irina", ""], ["Logacheva", "Varvara", ""], ["Panchenko", "Alexander", ""], ["Loukachevitch", "Natalia", ""]]}, {"id": "2005.11203", "submitter": "Alex Pitti Dr", "authors": "Alexandre Pitti, Mathias Quoy, Catherine Lavandier, Sofiane Boucenna", "title": "Digital Neural Networks in the Brain: From Mechanisms for Extracting\n  Structure in the World To Self-Structuring the Brain Itself", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In order to keep trace of information, the brain has to resolve the problem\nwhere information is and how to index new ones. We propose that the neural\nmechanism used by the prefrontal cortex (PFC) to detect structure in temporal\nsequences, based on the temporal order of incoming information, has served as\nsecond purpose to the spatial ordering and indexing of brain networks. We call\nthis process, apparent to the manipulation of neural 'addresses' to organize\nthe brain's own network, the 'digitalization' of information. Such tool is\nimportant for information processing and preservation, but also for memory\nformation and retrieval.\n", "versions": [{"version": "v1", "created": "Fri, 22 May 2020 14:29:51 GMT"}], "update_date": "2020-05-25", "authors_parsed": [["Pitti", "Alexandre", ""], ["Quoy", "Mathias", ""], ["Lavandier", "Catherine", ""], ["Boucenna", "Sofiane", ""]]}, {"id": "2005.11212", "submitter": "Max Tegmark", "authors": "Silviu-Marian Udrescu (MIT), Max Tegmark (MIT)", "title": "Symbolic Pregression: Discovering Physical Laws from Distorted Video", "comments": "Expanded and improved physics discussion, additional method details.\n  9 pages, 7 figs", "journal-ref": "Phys. Rev. E 103, 043307 (2021)", "doi": "10.1103/PhysRevE.103.043307", "report-no": null, "categories": "cs.CV cs.AI cs.LG physics.comp-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a method for unsupervised learning of equations of motion for\nobjects in raw and optionally distorted unlabeled video. We first train an\nautoencoder that maps each video frame into a low-dimensional latent space\nwhere the laws of motion are as simple as possible, by minimizing a combination\nof non-linearity, acceleration and prediction error. Differential equations\ndescribing the motion are then discovered using Pareto-optimal symbolic\nregression. We find that our pre-regression (\"pregression\") step is able to\nrediscover Cartesian coordinates of unlabeled moving objects even when the\nvideo is distorted by a generalized lens. Using intuition from multidimensional\nknot-theory, we find that the pregression step is facilitated by first adding\nextra latent space dimensions to avoid topological problems during training and\nthen removing these extra dimensions via principal component analysis.\n", "versions": [{"version": "v1", "created": "Tue, 19 May 2020 18:00:52 GMT"}, {"version": "v2", "created": "Fri, 11 Sep 2020 17:52:02 GMT"}], "update_date": "2021-04-28", "authors_parsed": [["Udrescu", "Silviu-Marian", "", "MIT"], ["Tegmark", "Max", "", "MIT"]]}, {"id": "2005.11247", "submitter": "Martin Balla", "authors": "Martin Balla and Simon M. Lucas and Diego Perez-Liebana", "title": "Evaluating Generalisation in General Video Game Playing", "comments": "accepted for publication in IEEE Conference on Games (CoG) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The General Video Game Artificial Intelligence (GVGAI) competition has been\nrunning for several years with various tracks. This paper focuses on the\nchallenge of the GVGAI learning track in which 3 games are selected and 2\nlevels are given for training, while 3 hidden levels are left for evaluation.\nThis setup poses a difficult challenge for current Reinforcement Learning (RL)\nalgorithms, as they typically require much more data. This work investigates 3\nversions of the Advantage Actor-Critic (A2C) algorithm trained on a maximum of\n2 levels from the available 5 from the GVGAI framework and compares their\nperformance on all levels. The selected sub-set of games have different\ncharacteristics, like stochasticity, reward distribution and objectives. We\nfound that stochasticity improves the generalisation, but too much can cause\nthe algorithms to fail to learn the training levels. The quality of the\ntraining levels also matters, different sets of training levels can boost\ngeneralisation over all levels. In the GVGAI competition agents are scored\nbased on their win rates and then their scores achieved in the games. We found\nthat solely using the rewards provided by the game might not encourage winning.\n", "versions": [{"version": "v1", "created": "Fri, 22 May 2020 15:57:52 GMT"}], "update_date": "2020-05-25", "authors_parsed": [["Balla", "Martin", ""], ["Lucas", "Simon M.", ""], ["Perez-Liebana", "Diego", ""]]}, {"id": "2005.11267", "submitter": "Tom Williams", "authors": "Poulomi Pal, Lixiao Zhu, Andrea Golden-Lasher, Akshay Swaminathan, Tom\n  Williams", "title": "Givenness Hierarchy Theoretic Cognitive Status Filtering", "comments": "To be published in the proceedings of the 2020 Annual Meeting of the\n  Cognitive Science Society (COGSCI). Supplemental materials available at\n  https://osf.io/qse7y/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For language-capable interactive robots to be effectively introduced into\nhuman society, they must be able to naturally and efficiently communicate about\nthe objects, locations, and people found in human environments. An important\naspect of natural language communication is the use of pronouns. Ac-cording to\nthe linguistic theory of the Givenness Hierarchy(GH), humans use pronouns due\nto implicit assumptions about the cognitive statuses their referents have in\nthe minds of their conversational partners. In previous work, Williams et al.\npresented the first computational implementation of the full GH for the purpose\nof robot language understanding, leveraging a set of rules informed by the GH\nliterature. However, that approach was designed specifically for language\nunderstanding,oriented around GH-inspired memory structures used to assess what\nentities are candidate referents given a particular cognitive status. In\ncontrast, language generation requires a model in which cognitive status can be\nassessed for a given entity. We present and compare two such models of\ncognitive status: a rule-based Finite State Machine model directly informed by\nthe GH literature and a Cognitive Status Filter designed to more flexibly\nhandle uncertainty. The models are demonstrated and evaluated using a\nsilver-standard English subset of the OFAI Multimodal Task Description Corpus.\n", "versions": [{"version": "v1", "created": "Fri, 22 May 2020 16:44:14 GMT"}], "update_date": "2020-05-25", "authors_parsed": [["Pal", "Poulomi", ""], ["Zhu", "Lixiao", ""], ["Golden-Lasher", "Andrea", ""], ["Swaminathan", "Akshay", ""], ["Williams", "Tom", ""]]}, {"id": "2005.11335", "submitter": "Arta Seify", "authors": "Arta Seify and Michael Buro", "title": "Single-Agent Optimization Through Policy Iteration Using Monte-Carlo\n  Tree Search", "comments": "Poster presentation at RL in Games Workshop, AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The combination of Monte-Carlo Tree Search (MCTS) and deep reinforcement\nlearning is state-of-the-art in two-player perfect-information games. In this\npaper, we describe a search algorithm that uses a variant of MCTS which we\nenhanced by 1) a novel action value normalization mechanism for games with\npotentially unbounded rewards (which is the case in many optimization\nproblems), 2) defining a virtual loss function that enables effective search\nparallelization, and 3) a policy network, trained by generations of self-play,\nto guide the search. We gauge the effectiveness of our method in \"SameGame\"---a\npopular single-player test domain. Our experimental results indicate that our\nmethod outperforms baseline algorithms on several board sizes. Additionally, it\nis competitive with state-of-the-art search algorithms on a public set of\npositions.\n", "versions": [{"version": "v1", "created": "Fri, 22 May 2020 18:02:36 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["Seify", "Arta", ""], ["Buro", "Michael", ""]]}, {"id": "2005.11729", "submitter": "Jianfeng Liu", "authors": "Jianfeng Liu, Feiyang Pan, Ling Luo", "title": "GoChat: Goal-oriented Chatbots with Hierarchical Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A chatbot that converses like a human should be goal-oriented (i.e., be\npurposeful in conversation), which is beyond language generation. However,\nexisting dialogue systems often heavily rely on cumbersome hand-crafted rules\nor costly labelled datasets to reach the goals. In this paper, we propose\nGoal-oriented Chatbots (GoChat), a framework for end-to-end training chatbots\nto maximize the longterm return from offline multi-turn dialogue datasets. Our\nframework utilizes hierarchical reinforcement learning (HRL), where the\nhigh-level policy guides the conversation towards the final goal by determining\nsome sub-goals, and the low-level policy fulfills the sub-goals by generating\nthe corresponding utterance for response. In our experiments on a real-world\ndialogue dataset for anti-fraud in financial, our approach outperforms previous\nmethods on both the quality of response generation as well as the success rate\nof accomplishing the goal.\n", "versions": [{"version": "v1", "created": "Sun, 24 May 2020 12:14:19 GMT"}, {"version": "v2", "created": "Tue, 26 May 2020 04:03:33 GMT"}], "update_date": "2020-05-27", "authors_parsed": [["Liu", "Jianfeng", ""], ["Pan", "Feiyang", ""], ["Luo", "Ling", ""]]}, {"id": "2005.11730", "submitter": "Julian Skirzynski", "authors": "Julian Skirzy\\'nski, Frederic Becker and Falk Lieder", "title": "Automatic Discovery of Interpretable Planning Strategies", "comments": "Submitted to the Special Issue on Reinforcement Learning for Real\n  Life in Machine Learning Journal (2021). Code available at\n  https://github.com/RationalityEnhancement/InterpretableStrategyDiscovery", "journal-ref": null, "doi": "10.1007/s10994-021-05963-2", "report-no": null, "categories": "cs.LG cs.AI cs.CY cs.HC stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  When making decisions, people often overlook critical information or are\noverly swayed by irrelevant information. A common approach to mitigate these\nbiases is to provide decision-makers, especially professionals such as medical\ndoctors, with decision aids, such as decision trees and flowcharts. Designing\neffective decision aids is a difficult problem. We propose that recently\ndeveloped reinforcement learning methods for discovering clever heuristics for\ngood decision-making can be partially leveraged to assist human experts in this\ndesign process. One of the biggest remaining obstacles to leveraging the\naforementioned methods is that the policies they learn are opaque to people. To\nsolve this problem, we introduce AI-Interpret: a general method for\ntransforming idiosyncratic policies into simple and interpretable descriptions.\nOur algorithm combines recent advances in imitation learning and program\ninduction with a new clustering method for identifying a large subset of\ndemonstrations that can be accurately described by a simple, high-performing\ndecision rule. We evaluate our new algorithm and employ it to translate\ninformation-acquisition policies discovered through metalevel reinforcement\nlearning. The results of large behavioral experiments showed that prividing the\ndecision rules generated by AI-Interpret as flowcharts significantly improved\npeople's planning strategies and decisions across three diferent classes of\nsequential decision problems. Moreover, another experiment revealed that this\napproach is significantly more effective than training people by giving them\nperformance feedback. Finally, a series of ablation studies confirmed that\nAI-Interpret is critical to the discovery of interpretable decision rules. We\nconclude that the methods and findings presented herein are an important step\ntowards leveraging automatic strategy discovery to improve human\ndecision-making.\n", "versions": [{"version": "v1", "created": "Sun, 24 May 2020 12:24:52 GMT"}, {"version": "v2", "created": "Fri, 16 Oct 2020 12:55:54 GMT"}, {"version": "v3", "created": "Sat, 10 Apr 2021 05:28:59 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Skirzy\u0144ski", "Julian", ""], ["Becker", "Frederic", ""], ["Lieder", "Falk", ""]]}, {"id": "2005.11797", "submitter": "Pranav Poduval", "authors": "Pranav Poduval, Hrushikesh Loya, Amit Sethi", "title": "Functional Space Variational Inference for Uncertainty Estimation in\n  Computer Aided Diagnosis", "comments": "Meaningful priors on the functional space rather than the weight\n  space, result in well calibrated uncertainty estimates", "journal-ref": "Medical Imaging with Deep Learning 2020", "doi": null, "report-no": "MIDL/2020/ExtendedAbstract/eLL-c_Xc0B", "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks have revolutionized medical image analysis and disease\ndiagnosis. Despite their impressive performance, it is difficult to generate\nwell-calibrated probabilistic outputs for such networks, which makes them\nuninterpretable black boxes. Bayesian neural networks provide a principled\napproach for modelling uncertainty and increasing patient safety, but they have\na large computational overhead and provide limited improvement in calibration.\nIn this work, by taking skin lesion classification as an example task, we show\nthat by shifting Bayesian inference to the functional space we can craft\nmeaningful priors that give better calibrated uncertainty estimates at a much\nlower computational cost.\n", "versions": [{"version": "v1", "created": "Sun, 24 May 2020 16:42:11 GMT"}, {"version": "v2", "created": "Thu, 28 May 2020 16:47:06 GMT"}], "update_date": "2020-05-29", "authors_parsed": [["Poduval", "Pranav", ""], ["Loya", "Hrushikesh", ""], ["Sethi", "Amit", ""]]}, {"id": "2005.11810", "submitter": "Ulrich Viereck", "authors": "Ulrich Viereck, Kate Saenko, Robert Platt", "title": "Learning visual servo policies via planner cloning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning control policies for visual servoing in novel environments is an\nimportant problem. However, standard model-free policy learning methods are\nslow. This paper explores planner cloning: using behavior cloning to learn\npolicies that mimic the behavior of a full-state motion planner in simulation.\nWe propose Penalized Q Cloning (PQC), a new behavior cloning algorithm. We show\nthat it outperforms several baselines and ablations on some challenging\nproblems involving visual servoing in novel environments while avoiding\nobstacles. Finally, we demonstrate that these policies can be transferred\neffectively onto a real robotic platform, achieving approximately an 87%\nsuccess rate both in simulation and on a real robot.\n", "versions": [{"version": "v1", "created": "Sun, 24 May 2020 17:56:57 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["Viereck", "Ulrich", ""], ["Saenko", "Kate", ""], ["Platt", "Robert", ""]]}, {"id": "2005.11816", "submitter": "Pasquale Antonante", "authors": "Pasquale Antonante, David I. Spivak, Luca Carlone", "title": "Monitoring and Diagnosability of Perception Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Perception is a critical component of high-integrity applications of robotics\nand autonomous systems, such as self-driving cars. In these applications,\nfailure of perception systems may put human life at risk, and a broad adoption\nof these technologies relies on the development of methodologies to guarantee\nand monitor safe operation as well as detect and mitigate failures. Despite the\nparamount importance of perception systems, currently there is no formal\napproach for system-level monitoring. In this work, we propose a mathematical\nmodel for runtime monitoring and fault detection of perception systems. Towards\nthis goal, we draw connections with the literature on self-diagnosability for\nmultiprocessor systems, and generalize it to (i) account for modules with\nheterogeneous outputs, and (ii) add a temporal dimension to the problem, which\nis crucial to model realistic perception systems where modules interact over\ntime. This contribution results in a graph-theoretic approach that, given a\nperception system, is able to detect faults at runtime and allows computing an\nupper-bound on the number of faulty modules that can be detected. Our second\ncontribution is to show that the proposed monitoring approach can be elegantly\ndescribed with the language of topos theory, which allows formulating\ndiagnosability over arbitrary time intervals.\n", "versions": [{"version": "v1", "created": "Sun, 24 May 2020 18:09:46 GMT"}, {"version": "v2", "created": "Wed, 27 May 2020 03:41:37 GMT"}, {"version": "v3", "created": "Mon, 16 Nov 2020 16:35:26 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Antonante", "Pasquale", ""], ["Spivak", "David I.", ""], ["Carlone", "Luca", ""]]}, {"id": "2005.11895", "submitter": "Maxime Bouton", "authors": "Maxime Bouton, Alireza Nakhaei, David Isele, Kikuo Fujimura, and Mykel\n  J. Kochenderfer", "title": "Reinforcement Learning with Iterative Reasoning for Merging in Dense\n  Traffic", "comments": "6pages, 5 figures", "journal-ref": "IEEE Intelligent Transportation Systems Conference (ITSC) 2020", "doi": null, "report-no": null, "categories": "cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Maneuvering in dense traffic is a challenging task for autonomous vehicles\nbecause it requires reasoning about the stochastic behaviors of many other\nparticipants. In addition, the agent must achieve the maneuver within a limited\ntime and distance. In this work, we propose a combination of reinforcement\nlearning and game theory to learn merging behaviors. We design a training\ncurriculum for a reinforcement learning agent using the concept of level-$k$\nbehavior. This approach exposes the agent to a broad variety of behaviors\nduring training, which promotes learning policies that are robust to model\ndiscrepancies. We show that our approach learns more efficient policies than\ntraditional training methods.\n", "versions": [{"version": "v1", "created": "Mon, 25 May 2020 02:57:19 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["Bouton", "Maxime", ""], ["Nakhaei", "Alireza", ""], ["Isele", "David", ""], ["Fujimura", "Kikuo", ""], ["Kochenderfer", "Mykel J.", ""]]}, {"id": "2005.11963", "submitter": "Mieczys{\\l}aw K{\\l}opotek", "authors": "Mieczys{\\l}aw A. K{\\l}opotek", "title": "Non-Destructive Sample Generation From Conditional Belief Functions", "comments": null, "journal-ref": "[in:]: Z. Bubnicki, A. Grzech eds: Proc. 13th International\n  Conference on Systems Science. September 15-18, 1998, Wroc{\\l}aw. Oficyna\n  Wydawnicza Politechniki Wroc{\\l}awskiej, Wroc{\\l}aw 1998, Vol. I, pp. 115-120", "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a new approach to generate samples from conditional\nbelief functions for a restricted but non trivial subset of conditional belief\nfunctions. It assumes the factorization (decomposition) of a belief function\nalong a bayesian network structure. It applies general conditional belief\nfunctions.\n", "versions": [{"version": "v1", "created": "Mon, 25 May 2020 08:18:45 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["K\u0142opotek", "Mieczys\u0142aw A.", ""]]}, {"id": "2005.11979", "submitter": "Mieczys{\\l}aw K{\\l}opotek", "authors": "Mieczyslaw A. Klopotek and Andrzej Matuszewski", "title": "On Irrelevance of Attributes in Flexible Prediction", "comments": null, "journal-ref": "Proc. 2nd Int. Conf. on New Techniques and Technologies for\n  Statistics (NTTS'95), Bonn, 19-22 Nov., 1995, Publisher: GMD Sankt Augustin,\n  pp. 282-293", "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper analyses properties of conceptual hierarchy obtained via\nincremental concept formation method called \"flexible prediction\" in order to\ndetermine what kind of \"relevance\" of participating attributes may be requested\nfor meaningful conceptual hierarchy. The impact of selection of simple and\ncombined attributes, of scaling and of distribution of individual attributes\nand of correlation strengths among them is investigated. Paradoxically, both:\nattributes weakly and strongly related with other attributes have deteriorating\nimpact onto the overall classification. Proper construction of derived\nattributes as well as selection of scaling of individual attributes strongly\ninfluences the obtained concept hierarchy. Attribute density of distribution\nseems to influence the classification weakly\n  It seems also, that concept hierarchies (taxonomies) reflect a compromise\nbetween the data and our interests in some objective truth about the data. To\nobtain classifications more suitable for one's purposes, breaking the symmetry\namong attributes (by dividing them into dependent and independent and applying\ndiffering evaluation formulas for their contribution) is suggested. Both\ncontinuous and discrete variables are considered. Some methodologies for the\nformer are considered.\n", "versions": [{"version": "v1", "created": "Mon, 25 May 2020 08:41:48 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["Klopotek", "Mieczyslaw A.", ""], ["Matuszewski", "Andrzej", ""]]}, {"id": "2005.12064", "submitter": "Shivesh Kumar", "authors": "Felix Wiebe and Shivesh Kumar and Daniel Harnack and Malte Langosz and\n  Hendrik W\\\"ohrle and Frank Kirchner", "title": "Combinatorics of a Discrete Trajectory Space for Robot Motion Planning", "comments": "8 pages, 3 figures, to be published in the proceedings of 2nd IMA\n  Conference on Mathematics of Robotics 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.CC cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motion planning is a difficult problem in robot control. The complexity of\nthe problem is directly related to the dimension of the robot's configuration\nspace. While in many theoretical calculations and practical applications the\nconfiguration space is modeled as a continuous space, we present a discrete\nrobot model based on the fundamental hardware specifications of a robot. Using\nlattice path methods, we provide estimates for the complexity of motion\nplanning by counting the number of possible trajectories in a discrete robot\nconfiguration space.\n", "versions": [{"version": "v1", "created": "Mon, 25 May 2020 12:14:20 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["Wiebe", "Felix", ""], ["Kumar", "Shivesh", ""], ["Harnack", "Daniel", ""], ["Langosz", "Malte", ""], ["W\u00f6hrle", "Hendrik", ""], ["Kirchner", "Frank", ""]]}, {"id": "2005.12069", "submitter": "Andreas Sedlmeier", "authors": "Andreas Sedlmeier and Robert M\\\"uller and Steffen Illium and Claudia\n  Linnhoff-Popien", "title": "Policy Entropy for Out-of-Distribution Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One critical prerequisite for the deployment of reinforcement learning\nsystems in the real world is the ability to reliably detect situations on which\nthe agent was not trained. Such situations could lead to potential safety risks\nwhen wrong predictions lead to the execution of harmful actions. In this work,\nwe propose PEOC, a new policy entropy based out-of-distribution classifier that\nreliably detects unencountered states in deep reinforcement learning. It is\nbased on using the entropy of an agent's policy as the classification score of\na one-class classifier. We evaluate our approach using a procedural environment\ngenerator. Results show that PEOC is highly competitive against\nstate-of-the-art one-class classification algorithms on the evaluated\nenvironments. Furthermore, we present a structured process for benchmarking\nout-of-distribution classification in reinforcement learning.\n", "versions": [{"version": "v1", "created": "Mon, 25 May 2020 12:18:20 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["Sedlmeier", "Andreas", ""], ["M\u00fcller", "Robert", ""], ["Illium", "Steffen", ""], ["Linnhoff-Popien", "Claudia", ""]]}, {"id": "2005.12132", "submitter": "Weixin Zeng", "authors": "Weixin Zeng, Xiang Zhao, Wei Wang, Jiuyang Tang, and Zhen Tan", "title": "Degree-Aware Alignment for Entities in Tail", "comments": "Accepted by SIGIR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Entity alignment (EA) is to discover equivalent entities in knowledge graphs\n(KGs), which bridges heterogeneous sources of information and facilitates the\nintegration of knowledge. Existing EA solutions mainly rely on structural\ninformation to align entities, typically through KG embedding. Nonetheless, in\nreal-life KGs, only a few entities are densely connected to others, and the\nrest majority possess rather sparse neighborhood structure. We refer to the\nlatter as long-tail entities, and observe that such phenomenon arguably limits\nthe use of structural information for EA. To mitigate the issue, we revisit and\ninvestigate into the conventional EA pipeline in pursuit of elegant\nperformance. For pre-alignment, we propose to amplify long-tail entities, which\nare of relatively weak structural information, with entity name information\nthat is generally available (but overlooked) in the form of concatenated power\nmean word embeddings. For alignment, under a novel complementary framework of\nconsolidating structural and name signals, we identify entity's degree as\nimportant guidance to effectively fuse two different sources of information. To\nthis end, a degree-aware co-attention network is conceived, which dynamically\nadjusts the significance of features in a degree-aware manner. For\npost-alignment, we propose to complement original KGs with facts from their\ncounterparts by using confident EA results as anchors via iterative training.\nComprehensive experimental evaluations validate the superiority of our proposed\ntechniques.\n", "versions": [{"version": "v1", "created": "Mon, 25 May 2020 14:15:49 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["Zeng", "Weixin", ""], ["Zhao", "Xiang", ""], ["Wang", "Wei", ""], ["Tang", "Jiuyang", ""], ["Tan", "Zhen", ""]]}, {"id": "2005.12150", "submitter": "Petar Radanliev", "authors": "Petar Radanliev, David De Roure, Kevin Page, Max Van Kleek, Omar\n  Santos, La Treall Maddox, Pete Burnap, Eirini Anthi, Carsten Maple", "title": "Design of a dynamic and self adapting system, supported with artificial\n  intelligence, machine learning and real time intelligence for predictive\n  cyber risk analytics in extreme environments, cyber risk in the colonisation\n  of Mars", "comments": "12 pages, 1 figure", "journal-ref": null, "doi": "10.1007/s42797-021-00025-1", "report-no": null, "categories": "cs.CY cs.AI cs.CR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Multiple governmental agencies and private organisations have made\ncommitments for the colonisation of Mars. Such colonisation requires complex\nsystems and infrastructure that could be very costly to repair or replace in\ncases of cyber attacks. This paper surveys deep learning algorithms, IoT cyber\nsecurity and risk models, and established mathematical formulas to identify the\nbest approach for developing a dynamic and self adapting system for predictive\ncyber risk analytics supported with Artificial Intelligence and Machine\nLearning and real time intelligence in edge computing. The paper presents a new\nmathematical approach for integrating concepts for cognition engine design,\nedge computing and Artificial Intelligence and Machine Learning to automate\nanomaly detection. This engine instigates a step change by applying Artificial\nIntelligence and Machine Learning embedded at the edge of IoT networks, to\ndeliver safe and functional real time intelligence for predictive cyber risk\nanalytics. This will enhance capacities for risk analytics and assists in the\ncreation of a comprehensive and systematic understanding of the opportunities\nand threats that arise when edge computing nodes are deployed, and when\nArtificial Intelligence and Machine Learning technologies are migrated to the\nperiphery of the internet and into local IoT networks.\n", "versions": [{"version": "v1", "created": "Tue, 19 May 2020 15:42:45 GMT"}, {"version": "v2", "created": "Thu, 11 Feb 2021 20:36:26 GMT"}], "update_date": "2021-02-15", "authors_parsed": [["Radanliev", "Petar", ""], ["De Roure", "David", ""], ["Page", "Kevin", ""], ["Van Kleek", "Max", ""], ["Santos", "Omar", ""], ["Maddox", "La Treall", ""], ["Burnap", "Pete", ""], ["Anthi", "Eirini", ""], ["Maple", "Carsten", ""]]}, {"id": "2005.12175", "submitter": "Guy Avni", "authors": "Parand Alizadeh Alamdari, Guy Avni, Thomas A. Henzinger, Anna Lukina", "title": "Formal Methods with a Touch of Magic", "comments": "Published in FMCAD 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning and formal methods have complimentary benefits and\ndrawbacks. In this work, we address the controller-design problem with a\ncombination of techniques from both fields. The use of black-box neural\nnetworks in deep reinforcement learning (deep RL) poses a challenge for such a\ncombination. Instead of reasoning formally about the output of deep RL, which\nwe call the {\\em wizard}, we extract from it a decision-tree based model, which\nwe refer to as the {\\em magic book}. Using the extracted model as an\nintermediary, we are able to handle problems that are infeasible for either\ndeep RL or formal methods by themselves. First, we suggest, for the first time,\ncombining a magic book in a synthesis procedure. We synthesize a stand-alone\ncorrect-by-design controller that enjoys the favorable performance of RL.\nSecond, we incorporate a magic book in a bounded model checking (BMC)\nprocedure. BMC allows us to find numerous traces of the plant under the control\nof the wizard, which a user can use to increase the trustworthiness of the\nwizard and direct further training.\n", "versions": [{"version": "v1", "created": "Mon, 25 May 2020 15:45:03 GMT"}, {"version": "v2", "created": "Mon, 24 Aug 2020 21:12:51 GMT"}], "update_date": "2020-08-26", "authors_parsed": [["Alamdari", "Parand Alizadeh", ""], ["Avni", "Guy", ""], ["Henzinger", "Thomas A.", ""], ["Lukina", "Anna", ""]]}, {"id": "2005.12196", "submitter": "Lionel Robert", "authors": "Rasha Alahmad, Lionel Robert", "title": "Artificial Intelligence (AI) and IT identity: Antecedents Identifying\n  with AI Applications", "comments": "10 pages, 1 Figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the age of Artificial Intelligence and automation, machines have taken\nover many key managerial tasks. Replacing managers with AI systems may have a\nnegative impact on workers outcomes. It is unclear if workers receive the same\nbenefits from their relationships with AI systems, raising the question: What\ndegree does the relationship between AI systems and workers impact worker\noutcomes? We draw on IT identity to understand the influence of identification\nwith AI systems on job performance. From this theoretical perspective, we\npropose a research model and conduct a survey of 97 MTurk workers to test the\nmodel. The findings reveal that work role identity and organizational identity\nare key determinants of identification with AI systems. Furthermore, the\nfindings show that identification with AI systems does increase job\nperformance.\n", "versions": [{"version": "v1", "created": "Fri, 15 May 2020 10:59:43 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["Alahmad", "Rasha", ""], ["Robert", "Lionel", ""]]}, {"id": "2005.12254", "submitter": "Jaskirat Singh", "authors": "Jaskirat Singh and Liang Zheng", "title": "Dynamic Value Estimation for Single-Task Multi-Scene Reinforcement\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Training deep reinforcement learning agents on environments with multiple\nlevels / scenes / conditions from the same task, has become essential for many\napplications aiming to achieve generalization and domain transfer from\nsimulation to the real world. While such a strategy is helpful with\ngeneralization, the use of multiple scenes significantly increases the variance\nof samples collected for policy gradient computations. Current methods continue\nto view this collection of scenes as a single Markov Decision Process (MDP)\nwith a common value function; however, we argue that it is better to treat the\ncollection as a single environment with multiple underlying MDPs. To this end,\nwe propose a dynamic value estimation (DVE) technique for these multiple-MDP\nenvironments, motivated by the clustering effect observed in the value function\ndistribution across different scenes. The resulting agent is able to learn a\nmore accurate and scene-specific value function estimate (and hence the\nadvantage function), leading to a lower sample variance. Our proposed approach\nis simple to accommodate with several existing implementations (like PPO, A3C)\nand results in consistent improvements for a range of ProcGen environments and\nthe AI2-THOR framework based visual navigation task.\n", "versions": [{"version": "v1", "created": "Mon, 25 May 2020 17:56:08 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["Singh", "Jaskirat", ""], ["Zheng", "Liang", ""]]}, {"id": "2005.12256", "submitter": "Devendra Singh Chaplot", "authors": "Devendra Singh Chaplot, Ruslan Salakhutdinov, Abhinav Gupta, Saurabh\n  Gupta", "title": "Neural Topological SLAM for Visual Navigation", "comments": "Published in CVPR 2020. See the project webpage at\n  https://devendrachaplot.github.io/projects/Neural-Topological-SLAM", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies the problem of image-goal navigation which involves\nnavigating to the location indicated by a goal image in a novel previously\nunseen environment. To tackle this problem, we design topological\nrepresentations for space that effectively leverage semantics and afford\napproximate geometric reasoning. At the heart of our representations are nodes\nwith associated semantic features, that are interconnected using coarse\ngeometric information. We describe supervised learning-based algorithms that\ncan build, maintain and use such representations under noisy actuation.\nExperimental study in visually and physically realistic simulation suggests\nthat our method builds effective representations that capture structural\nregularities and efficiently solve long-horizon navigation problems. We observe\na relative improvement of more than 50% over existing methods that study this\ntask.\n", "versions": [{"version": "v1", "created": "Mon, 25 May 2020 17:56:29 GMT"}, {"version": "v2", "created": "Thu, 28 May 2020 22:56:12 GMT"}], "update_date": "2020-06-01", "authors_parsed": [["Chaplot", "Devendra Singh", ""], ["Salakhutdinov", "Ruslan", ""], ["Gupta", "Abhinav", ""], ["Gupta", "Saurabh", ""]]}, {"id": "2005.12267", "submitter": "Fadi Salo", "authors": "Fadi Salo, MohammadNoor Injadat, Ali Bou Nassif, Aleksander Essex", "title": "Data Mining with Big Data in Intrusion Detection Systems: A Systematic\n  Literature Review", "comments": "8 Pages, 5 Figures, to be appeared in the proceedings of the\n  International Symposium on Big Data Management and Analytics. April 25-26,\n  2019, Calgary, Canada", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Cloud computing has become a powerful and indispensable technology for\ncomplex, high performance and scalable computation. The exponential expansion\nin the deployment of cloud technology has produced a massive amount of data\nfrom a variety of applications, resources and platforms. In turn, the rapid\nrate and volume of data creation has begun to pose significant challenges for\ndata management and security. The design and deployment of intrusion detection\nsystems (IDS) in the big data setting has, therefore, become a topic of\nimportance. In this paper, we conduct a systematic literature review (SLR) of\ndata mining techniques (DMT) used in IDS-based solutions through the period\n2013-2018. We employed criterion-based, purposive sampling identifying 32\narticles, which constitute the primary source of the present survey. After a\ncareful investigation of these articles, we identified 17 separate DMTs\ndeployed in an IDS context. This paper also presents the merits and\ndisadvantages of the various works of current research that implemented DMTs\nand distributed streaming frameworks (DSF) to detect and/or prevent malicious\nattacks in a big data environment.\n", "versions": [{"version": "v1", "created": "Sat, 23 May 2020 20:57:12 GMT"}], "update_date": "2020-05-27", "authors_parsed": [["Salo", "Fadi", ""], ["Injadat", "MohammadNoor", ""], ["Nassif", "Ali Bou", ""], ["Essex", "Aleksander", ""]]}, {"id": "2005.12327", "submitter": "Bashar Awwad Shiekh Hasan", "authors": "Bashar Awwad Shiekh Hasan and Kate Kelly", "title": "Bayesian Stress Testing of Models in a Classification Hierarchy", "comments": "12 pages, 8 figures, conference paper accepted in WCCI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Building a machine learning solution in real-life applications often involves\nthe decomposition of the problem into multiple models of various complexity.\nThis has advantages in terms of overall performance, better interpretability of\nthe outcomes, and easier model maintenance. In this work we propose a Bayesian\nframework to model the interaction amongst models in such a hierarchy. We show\nthat the framework can facilitate stress testing of the overall solution,\ngiving more confidence in its expected performance prior to active deployment.\nFinally, we test the proposed framework on a toy problem and financial fraud\ndetection dataset to demonstrate how it can be applied for any machine learning\nbased solution, regardless of the underlying modelling required.\n", "versions": [{"version": "v1", "created": "Mon, 25 May 2020 18:22:07 GMT"}], "update_date": "2020-05-27", "authors_parsed": [["Hasan", "Bashar Awwad Shiekh", ""], ["Kelly", "Kate", ""]]}, {"id": "2005.12339", "submitter": "Dan Roth", "authors": "Dan Roth", "title": "Incidental Supervision: Moving beyond Supervised Learning", "comments": "6 pages, 1 figure. Appeared in AAAI-17", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine Learning and Inference methods have become ubiquitous in our attempt\nto induce more abstract representations of natural language text, visual\nscenes, and other messy, naturally occurring data, and support decisions that\ndepend on it. However, learning models for these tasks is difficult partly\nbecause generating the necessary supervision signals for it is costly and does\nnot scale. This paper describes several learning paradigms that are designed to\nalleviate the supervision bottleneck. It will illustrate their benefit in the\ncontext of multiple problems, all pertaining to inducing various levels of\nsemantic representations from text.\n", "versions": [{"version": "v1", "created": "Mon, 25 May 2020 18:44:53 GMT"}], "update_date": "2020-05-27", "authors_parsed": [["Roth", "Dan", ""]]}, {"id": "2005.12360", "submitter": "Jalal Etesami", "authors": "Jalal Etesami, Christoph-Nikolas Straehle", "title": "Non-cooperative Multi-agent Systems with Exploring Agents", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-agent learning is a challenging problem in machine learning that has\napplications in different domains such as distributed control, robotics, and\neconomics. We develop a prescriptive model of multi-agent behavior using Markov\ngames. Since in many multi-agent systems, agents do not necessary select their\noptimum strategies against other agents (e.g., multi-pedestrian interaction),\nwe focus on models in which the agents play \"exploration but near optimum\nstrategies\". We model such policies using the Boltzmann-Gibbs distribution.\nThis leads to a set of coupled Bellman equations that describes the behavior of\nthe agents. We introduce a set of conditions under which the set of equations\nadmit a unique solution and propose two algorithms that provably provide the\nsolution in finite and infinite time horizon scenarios. We also study a\npractical setting in which the interactions can be described using the\noccupancy measures and propose a simplified Markov game with less complexity.\nFurthermore, we establish the connection between the Markov games with\nexploration strategies and the principle of maximum causal entropy for\nmulti-agent systems. Finally, we evaluate the performance of our algorithms via\nseveral well-known games from the literature and some games that are designed\nbased on real world applications.\n", "versions": [{"version": "v1", "created": "Mon, 25 May 2020 19:34:29 GMT"}], "update_date": "2020-05-27", "authors_parsed": [["Etesami", "Jalal", ""], ["Straehle", "Christoph-Nikolas", ""]]}, {"id": "2005.12364", "submitter": "Kezhi Wang", "authors": "Feibo Jiang and Li Dong and Kezhi Wang and Kun Yang and Cunhua Pan", "title": "Distributed Resource Scheduling for Large-Scale MEC Systems: A\n  Multi-Agent Ensemble Deep Reinforcement Learning with Imitation Acceleration", "comments": "Submitted for Review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.AI cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the optimization of distributed resource scheduling to minimize\nthe sum of task latency and energy consumption for all the Internet of things\ndevices (IoTDs) in a large-scale mobile edge computing (MEC) system. To address\nthis problem, we propose a distributed intelligent resource scheduling (DIRS)\nframework, which includes centralized training relying on the global\ninformation and distributed decision making by each agent deployed in each MEC\nserver. More specifically, we first introduce a novel multi-agent\nensemble-assisted distributed deep reinforcement learning (DRL) architecture,\nwhich can simplify the overall neural network structure of each agent by\npartitioning the state space and also improve the performance of a single agent\nby combining decisions of all the agents. Secondly, we apply action refinement\nto enhance the exploration ability of the proposed DIRS framework, where the\nnear-optimal state-action pairs are obtained by a novel L\\'evy flight search.\nFinally, an imitation acceleration scheme is presented to pre-train all the\nagents, which can significantly accelerate the learning process of the proposed\nframework through learning the professional experience from a small amount of\ndemonstration data. Extensive simulations are conducted to demonstrate that the\nproposed DIRS framework is efficient and outperforms the existing benchmark\nschemes.\n", "versions": [{"version": "v1", "created": "Thu, 21 May 2020 20:04:40 GMT"}], "update_date": "2020-05-27", "authors_parsed": [["Jiang", "Feibo", ""], ["Dong", "Li", ""], ["Wang", "Kezhi", ""], ["Yang", "Kun", ""], ["Pan", "Cunhua", ""]]}, {"id": "2005.12442", "submitter": "Shashank Sonkar", "authors": "Shashank Sonkar, Andrew E. Waters, Andrew S. Lan, Phillip J. Grimaldi,\n  Richard G. Baraniuk", "title": "qDKT: Question-centric Deep Knowledge Tracing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge tracing (KT) models, e.g., the deep knowledge tracing (DKT) model,\ntrack an individual learner's acquisition of skills over time by examining the\nlearner's performance on questions related to those skills. A practical\nlimitation in most existing KT models is that all questions nested under a\nparticular skill are treated as equivalent observations of a learner's ability,\nwhich is an inaccurate assumption in real-world educational scenarios. To\novercome this limitation we introduce qDKT, a variant of DKT that models every\nlearner's success probability on individual questions over time. First, qDKT\nincorporates graph Laplacian regularization to smooth predictions under each\nskill, which is particularly useful when the number of questions in the dataset\nis big. Second, qDKT uses an initialization scheme inspired by the fastText\nalgorithm, which has found success in a variety of language modeling tasks. Our\nexperiments on several real-world datasets show that qDKT achieves state-of-art\nperformance on predicting learner outcomes. Because of this, qDKT can serve as\na simple, yet tough-to-beat, baseline for new question-centric KT models.\n", "versions": [{"version": "v1", "created": "Mon, 25 May 2020 23:43:55 GMT"}], "update_date": "2020-05-27", "authors_parsed": [["Sonkar", "Shashank", ""], ["Waters", "Andrew E.", ""], ["Lan", "Andrew S.", ""], ["Grimaldi", "Phillip J.", ""], ["Baraniuk", "Richard G.", ""]]}, {"id": "2005.12474", "submitter": "Saideep Nannapaneni", "authors": "Sima E. Borujeni, Nam H. Nguyen, Saideep Nannapaneni, Elizabeth C.\n  Behrman, James E. Steck", "title": "Experimental evaluation of quantum Bayesian networks on IBM QX hardware", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.AI cs.ET", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian Networks (BN) are probabilistic graphical models that are widely\nused for uncertainty modeling, stochastic prediction and probabilistic\ninference. A Quantum Bayesian Network (QBN) is a quantum version of the\nBayesian network that utilizes the principles of quantum mechanical systems to\nimprove the computational performance of various analyses. In this paper, we\nexperimentally evaluate the performance of QBN on various IBM QX hardware\nagainst Qiskit simulator and classical analysis. We consider a 4-node BN for\nstock prediction for our experimental evaluation. We construct a quantum\ncircuit to represent the 4-node BN using Qiskit, and run the circuit on nine\nIBM quantum devices: Yorktown, Vigo, Ourense, Essex, Burlington, London, Rome,\nAthens and Melbourne. We will also compare the performance of each device\nacross the four levels of optimization performed by the IBM Transpiler when\nmapping a given quantum circuit to a given device. We use the root mean square\npercentage error as the metric for performance comparison of various hardware.\n", "versions": [{"version": "v1", "created": "Tue, 26 May 2020 01:25:39 GMT"}], "update_date": "2020-05-27", "authors_parsed": [["Borujeni", "Sima E.", ""], ["Nguyen", "Nam H.", ""], ["Nannapaneni", "Saideep", ""], ["Behrman", "Elizabeth C.", ""], ["Steck", "James E.", ""]]}, {"id": "2005.12501", "submitter": "Benjamin Kane", "authors": "Benjamin Kane, Georgiy Platonov, and Lenhart K. Schubert", "title": "History-Aware Question Answering in a Blocks World Dialogue System", "comments": "16 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is essential for dialogue-based spatial reasoning systems to maintain\nmemory of historical states of the world. In addition to conveying that the\ndialogue agent is mentally present and engaged with the task, referring to\nhistorical states may be crucial for enabling collaborative planning (e.g., for\nplanning to return to a previous state, or diagnosing a past misstep). In this\npaper, we approach the problem of spatial memory in a multi-modal spoken\ndialogue system capable of answering questions about interaction history in a\nphysical blocks world setting. This work builds upon a full spatial\nquestion-answering pipeline consisting of a vision system, speech input and\noutput mediated by an animated avatar, a dialogue system that robustly\ninterprets spatial queries, and a constraint solver that derives answers based\non 3-D spatial modelling. The contributions of this work include a symbolic\ndialogue context registering knowledge about discourse history and changes in\nthe world, as well as a natural language understanding module capable of\ninterpreting free-form historical questions and querying the dialogue context\nto form an answer.\n", "versions": [{"version": "v1", "created": "Tue, 26 May 2020 03:16:11 GMT"}], "update_date": "2020-05-27", "authors_parsed": [["Kane", "Benjamin", ""], ["Platonov", "Georgiy", ""], ["Schubert", "Lenhart K.", ""]]}, {"id": "2005.12508", "submitter": "Joseph Campbell", "authors": "Joseph Campbell, Katsu Yamane", "title": "Learning Whole-Body Human-Robot Haptic Interaction in Social Contexts", "comments": "Accepted to ICRA 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a learning-from-demonstration (LfD) framework for\nteaching human-robot social interactions that involve whole-body haptic\ninteraction, i.e. direct human-robot contact over the full robot body. The\nperformance of existing LfD frameworks suffers in such interactions due to the\nhigh dimensionality and spatiotemporal sparsity of the demonstration data. We\nshow that by leveraging this sparsity, we can reduce the data dimensionality\nwithout incurring a significant accuracy penalty, and introduce three\nstrategies for doing so. By combining these techniques with an LfD framework\nfor learning multimodal human-robot interactions, we can model the\nspatiotemporal relationship between the tactile and kinesthetic information\nduring whole-body haptic interactions. Using a teleoperated bimanual robot\nequipped with 61 force sensors, we experimentally demonstrate that a model\ntrained with 121 sample hugs from 4 participants generalizes well to unseen\ninputs and human partners.\n", "versions": [{"version": "v1", "created": "Tue, 26 May 2020 03:44:09 GMT"}], "update_date": "2020-05-27", "authors_parsed": [["Campbell", "Joseph", ""], ["Yamane", "Katsu", ""]]}, {"id": "2005.12529", "submitter": "Behnam Hedayatnia", "authors": "Behnam Hedayatnia, Karthik Gopalakrishnan, Seokhwan Kim, Yang Liu,\n  Mihail Eric, Dilek Hakkani-Tur", "title": "Policy-Driven Neural Response Generation for Knowledge-Grounded Dialogue\n  Systems", "comments": "Link to public dataset", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Open-domain dialogue systems aim to generate relevant, informative and\nengaging responses. Seq2seq neural response generation approaches do not have\nexplicit mechanisms to control the content or style of the generated response,\nand frequently result in uninformative utterances. In this paper, we propose\nusing a dialogue policy to plan the content and style of target responses in\nthe form of an action plan, which includes knowledge sentences related to the\ndialogue context, targeted dialogue acts, topic information, etc. The\nattributes within the action plan are obtained by automatically annotating the\npublicly released Topical-Chat dataset. We condition neural response generators\non the action plan which is then realized as target utterances at the turn and\nsentence levels. We also investigate different dialogue policy models to\npredict an action plan given the dialogue context. Through automated and human\nevaluation, we measure the appropriateness of the generated responses and check\nif the generation models indeed learn to realize the given action plans. We\ndemonstrate that a basic dialogue policy that operates at the sentence level\ngenerates better responses in comparison to turn level generation as well as\nbaseline models with no action plan. Additionally the basic dialogue policy has\nthe added effect of controllability.\n", "versions": [{"version": "v1", "created": "Tue, 26 May 2020 06:09:57 GMT"}, {"version": "v2", "created": "Sat, 6 Jun 2020 04:10:35 GMT"}, {"version": "v3", "created": "Tue, 9 Jun 2020 20:24:04 GMT"}, {"version": "v4", "created": "Mon, 24 Aug 2020 21:06:46 GMT"}], "update_date": "2020-08-26", "authors_parsed": [["Hedayatnia", "Behnam", ""], ["Gopalakrishnan", "Karthik", ""], ["Kim", "Seokhwan", ""], ["Liu", "Yang", ""], ["Eric", "Mihail", ""], ["Hakkani-Tur", "Dilek", ""]]}, {"id": "2005.12533", "submitter": "Benjamin Goertzel", "authors": "Ben Goertzel, Andres Suarez Madrigal, Gino Yu", "title": "Guiding Symbolic Natural Language Grammar Induction via\n  Transformer-Based Sequence Probabilities", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A novel approach to automated learning of syntactic rules governing natural\nlanguages is proposed, based on using probabilities assigned to sentences (and\npotentially longer word sequences) by transformer neural network language\nmodels to guide symbolic learning processes like clustering and rule induction.\nThis method exploits the learned linguistic knowledge in transformers, without\nany reference to their inner representations; hence, the technique is readily\nadaptable to the continuous appearance of more powerful language models. We\nshow a proof-of-concept example of our proposed technique, using it to guide\nunsupervised symbolic link-grammar induction methods drawn from our prior\nresearch.\n", "versions": [{"version": "v1", "created": "Tue, 26 May 2020 06:18:47 GMT"}], "update_date": "2020-05-27", "authors_parsed": [["Goertzel", "Ben", ""], ["Madrigal", "Andres Suarez", ""], ["Yu", "Gino", ""]]}, {"id": "2005.12535", "submitter": "Benjamin Goertzel", "authors": "Ben Goertzel, Mike Duncan, Debbie Duong, Nil Geisweiller, Hedra Seid,\n  Abdulrahman Semrie, Man Hin Leung, Matthew Ikle'", "title": "Embedding Vector Differences Can Be Aligned With Uncertain Intensional\n  Logic Differences", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The DeepWalk algorithm is used to assign embedding vectors to nodes in the\nAtomspace weighted, labeled hypergraph that is used to represent knowledge in\nthe OpenCog AGI system, in the context of an application to probabilistic\ninference regarding the causes of longevity based on data from biological\nontologies and genomic analyses. It is shown that vector difference operations\nbetween embedding vectors are, in appropriate conditions, approximately\nalignable with \"intensional difference\" operations between the hypergraph nodes\ncorresponding to the embedding vectors. This relationship hints at a broader\nfunctorial mapping between uncertain intensional logic and vector arithmetic,\nand opens the door for using embedding vector algebra to guide intensional\ninference control.\n", "versions": [{"version": "v1", "created": "Tue, 26 May 2020 06:20:32 GMT"}], "update_date": "2020-05-27", "authors_parsed": [["Goertzel", "Ben", ""], ["Duncan", "Mike", ""], ["Duong", "Debbie", ""], ["Geisweiller", "Nil", ""], ["Seid", "Hedra", ""], ["Semrie", "Abdulrahman", ""], ["Leung", "Man Hin", ""], ["Ikle'", "Matthew", ""]]}, {"id": "2005.12553", "submitter": "Chang Wang", "authors": "Hao Chen, Chang Wang, Jian Huang, Jianxing Gong", "title": "Efficient Use of heuristics for accelerating XCS-based Policy Learning\n  in Markov Games", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.GT cs.MA cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In Markov games, playing against non-stationary opponents with learning\nability is still challenging for reinforcement learning (RL) agents, because\nthe opponents can evolve their policies concurrently. This increases the\ncomplexity of the learning task and slows down the learning speed of the RL\nagents. This paper proposes efficient use of rough heuristics to speed up\npolicy learning when playing against concurrent learners. Specifically, we\npropose an algorithm that can efficiently learn explainable and generalized\naction selection rules by taking advantages of the representation of\nquantitative heuristics and an opponent model with an eXtended classifier\nsystem (XCS) in zero-sum Markov games. A neural network is used to model the\nopponent from their behaviors and the corresponding policy is inferred for\naction selection and rule evolution. In cases of multiple heuristic policies,\nwe introduce the concept of Pareto optimality for action selection. Besides,\ntaking advantages of the condition representation and matching mechanism of\nXCS, the heuristic policies and the opponent model can provide guidance for\nsituations with similar feature representation. Furthermore, we introduce an\naccuracy-based eligibility trace mechanism to speed up rule evolution, i.e.,\nclassifiers that can match the historical traces are reinforced according to\ntheir accuracy. We demonstrate the advantages of the proposed algorithm over\nseveral benchmark algorithms in a soccer and a thief-and-hunter scenarios.\n", "versions": [{"version": "v1", "created": "Tue, 26 May 2020 07:47:27 GMT"}], "update_date": "2020-05-27", "authors_parsed": [["Chen", "Hao", ""], ["Wang", "Chang", ""], ["Huang", "Jian", ""], ["Gong", "Jianxing", ""]]}, {"id": "2005.12579", "submitter": "Vanessa Volz", "authors": "Vanessa Volz and Niels Justesen and Sam Snodgrass and Sahar Asadi and\n  Sami Purmonen and Christoffer Holmg\\r{a}rd and Julian Togelius and Sebastian\n  Risi", "title": "Capturing Local and Global Patterns in Procedural Content Generation via\n  Machine Learning", "comments": "IEEE Conference on Games 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent procedural content generation via machine learning (PCGML) methods\nallow learning from existing content to produce similar content automatically.\nWhile these approaches are able to generate content for different games (e.g.\nSuper Mario Bros., DOOM, Zelda, and Kid Icarus), it is an open questions how\nwell these approaches can capture large-scale visual patterns such as symmetry.\nIn this paper, we propose match-three games as a domain to test PCGML\nalgorithms regarding their ability to generate suitable patterns. We\ndemonstrate that popular algorithm such as Generative Adversarial Networks\nstruggle in this domain and propose adaptations to improve their performance.\nIn particular we augment the neighborhood of a Markov Random Fields approach to\nnot only take local but also symmetric positional information into account. We\nconduct several empirical tests including a user study that show the\nimprovements achieved by the proposed modifications, and obtain promising\nresults.\n", "versions": [{"version": "v1", "created": "Tue, 26 May 2020 08:58:37 GMT"}], "update_date": "2020-05-27", "authors_parsed": [["Volz", "Vanessa", ""], ["Justesen", "Niels", ""], ["Snodgrass", "Sam", ""], ["Asadi", "Sahar", ""], ["Purmonen", "Sami", ""], ["Holmg\u00e5rd", "Christoffer", ""], ["Togelius", "Julian", ""], ["Risi", "Sebastian", ""]]}, {"id": "2005.12632", "submitter": "Fabio Massimo Zennaro", "authors": "Fabio Massimo Zennaro and Laszlo Erdodi", "title": "Modeling Penetration Testing with Reinforcement Learning Using\n  Capture-the-Flag Challenges: Trade-offs between Model-free Learning and A\n  Priori Knowledge", "comments": "13 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Penetration testing is a security exercise aimed at assessing the security of\na system by simulating attacks against it. So far, penetration testing has been\ncarried out mainly by trained human attackers and its success critically\ndepended on the available expertise. Automating this practice constitutes a\nnon-trivial problem, as the range of actions that a human expert may attempts\nagainst a system and the range of knowledge she relies on to take her decisions\nare hard to capture. In this paper, we focus our attention on simplified\npenetration testing problems expressed in the form of capture the flag hacking\nchallenges, and we analyze how model-free reinforcement learning algorithms may\nhelp to solve them. In modeling these capture the flag competitions as\nreinforcement learning problems we highlight that a specific challenge that\ncharacterize penetration testing is the problem of discovering the structure of\nthe problem at hand. We then show how this challenge may be eased by relying on\ndifferent forms of prior knowledge that may be provided to the agent. In this\nway we demonstrate how the feasibility of tackling penetration testing using\nreinforcement learning may rest on a careful trade-off between model-free and\nmodel-based algorithms. By using techniques to inject a priori knowledge, we\nshow it is possible to better direct the agent and restrict the space of its\nexploration problem, thus achieving solutions more efficiently.\n", "versions": [{"version": "v1", "created": "Tue, 26 May 2020 11:23:10 GMT"}, {"version": "v2", "created": "Sat, 22 May 2021 09:31:40 GMT"}], "update_date": "2021-05-25", "authors_parsed": [["Zennaro", "Fabio Massimo", ""], ["Erdodi", "Laszlo", ""]]}, {"id": "2005.12638", "submitter": "Anthony Strittmatter", "authors": "Dainis Zegners, Uwe Sunde, Anthony Strittmatter", "title": "Decisions and Performance Under Bounded Rationality: A Computational\n  Benchmarking Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "econ.GN cs.AI q-fin.EC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper presents a novel approach to analyze human decision-making that\ninvolves comparing the behavior of professional chess players relative to a\ncomputational benchmark of cognitively bounded rationality. This benchmark is\nconstructed using algorithms of modern chess engines and allows investigating\nbehavior at the level of individual move-by-move observations, thus\nrepresenting a natural benchmark for computationally bounded optimization. The\nanalysis delivers novel insights by isolating deviations from this benchmark of\nbounded rationality as well as their causes and consequences for performance.\nThe findings document the existence of several distinct dimensions of\nbehavioral deviations, which are related to asymmetric positional evaluation in\nterms of losses and gains, time pressure, fatigue, and complexity. The results\nalso document that deviations from the benchmark do not necessarily entail\nworse performance. Faster decisions are associated with more frequent\ndeviations from the benchmark, yet they are also associated with better\nperformance. The findings are consistent with an important influence of\nintuition and experience, thereby shedding new light on the recent debate about\ncomputational rationality in cognitive processes.\n", "versions": [{"version": "v1", "created": "Tue, 26 May 2020 11:39:39 GMT"}, {"version": "v2", "created": "Wed, 2 Dec 2020 15:50:58 GMT"}], "update_date": "2020-12-03", "authors_parsed": [["Zegners", "Dainis", ""], ["Sunde", "Uwe", ""], ["Strittmatter", "Anthony", ""]]}, {"id": "2005.12644", "submitter": "Jason R.C. Nurse Dr", "authors": "Rahime Belen Saglam and Jason R. C. Nurse", "title": "Is your chatbot GDPR compliant? Open issues in agent design", "comments": null, "journal-ref": "CUI 2020: International Conference on Conversational User\n  Interfaces, July, 2020", "doi": "10.1145/3405755.3406131", "report-no": null, "categories": "cs.CY cs.AI cs.HC cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conversational agents open the world to new opportunities for human\ninteraction and ubiquitous engagement. As their conversational abilities and\nknowledge has improved, these agents have begun to have access to an increasing\nvariety of personally identifiable information and intimate details on their\nuser base. This access raises crucial questions in light of regulations as\nrobust as the General Data Protection Regulation (GDPR). This paper explores\nsome of these questions, with the aim of defining relevant open issues in\nconversational agent design. We hope that this work can provoke further\nresearch into building agents that are effective at user interaction, but also\nrespectful of regulations and user privacy.\n", "versions": [{"version": "v1", "created": "Tue, 26 May 2020 11:54:44 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Saglam", "Rahime Belen", ""], ["Nurse", "Jason R. C.", ""]]}, {"id": "2005.12697", "submitter": "Colin Bellinger", "authors": "Colin Bellinger, Rory Coles, Mark Crowley, Isaac Tamblyn", "title": "Active Measure Reinforcement Learning for Observation Cost Minimization", "comments": "Under review at NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Standard reinforcement learning (RL) algorithms assume that the observation\nof the next state comes instantaneously and at no cost. In a wide variety of\nsequential decision making tasks ranging from medical treatment to scientific\ndiscovery, however, multiple classes of state observations are possible, each\nof which has an associated cost. We propose the active measure RL framework\n(Amrl) as an initial solution to this problem where the agent learns to\nmaximize the costed return, which we define as the discounted sum of rewards\nminus the sum of observation costs. Our empirical evaluation demonstrates that\nAmrl-Q agents are able to learn a policy and state estimator in parallel during\nonline training. During training the agent naturally shifts from its reliance\non costly measurements of the environment to its state estimator in order to\nincrease its reward. It does this without harm to the learned policy. Our\nresults show that the Amrl-Q agent learns at a rate similar to standard\nQ-learning and Dyna-Q. Critically, by utilizing an active strategy, Amrl-Q\nachieves a higher costed return.\n", "versions": [{"version": "v1", "created": "Tue, 26 May 2020 13:18:09 GMT"}], "update_date": "2020-05-27", "authors_parsed": [["Bellinger", "Colin", ""], ["Coles", "Rory", ""], ["Crowley", "Mark", ""], ["Tamblyn", "Isaac", ""]]}, {"id": "2005.12713", "submitter": "Christoph Beierle", "authors": "Christian Komo and Christoph Beierle", "title": "Nonmonotonic Inferences with Qualitative Conditionals based on Preferred\n  Structures on Worlds", "comments": "14 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A conditional knowledge base R is a set of conditionals of the form \"If A,\nthe usually B\". Using structural information derived from the conditionals in\nR, we introduce the preferred structure relation on worlds. The preferred\nstructure relation is the core ingredient of a new inference relation called\nsystem W inference that inductively completes the knowledge given explicitly in\nR. We show that system W exhibits desirable inference properties like\nsatisfying system P and avoiding, in contrast to e.g. system Z, the drowning\nproblem. It fully captures and strictly extends both system Z and skeptical\nc-inference. In contrast to skeptical c-inference, it does not require to solve\na complex constraint satisfaction problem, but is as tractable as system Z.\n", "versions": [{"version": "v1", "created": "Tue, 26 May 2020 13:32:00 GMT"}], "update_date": "2020-05-27", "authors_parsed": [["Komo", "Christian", ""], ["Beierle", "Christoph", ""]]}, {"id": "2005.12737", "submitter": "Yutaka Nagashima", "authors": "Yutaka Nagashima", "title": "Towards United Reasoning for Automatic Induction in Isabelle/HOL", "comments": "This is the pre-print of our short-paper accepted at the 34th Annual\n  Conference of the Japanese Society for Artificial Intelligence, 2020\n  (https://www.ai-gakkai.or.jp/jsai2020/en)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inductive theorem proving is an important long-standing challenge in computer\nscience. In this extended abstract, we first summarize the recent developments\nof proof by induction for Isabelle/HOL. Then, we propose united reasoning, a\nnovel approach to further automating inductive theorem proving. Upon success,\nunited reasoning takes the best of three schools of reasoning: deductive\nreasoning, inductive reasoning, and inductive reasoning, to prove difficult\ninductive problems automatically.\n", "versions": [{"version": "v1", "created": "Mon, 25 May 2020 08:30:05 GMT"}], "update_date": "2020-05-27", "authors_parsed": [["Nagashima", "Yutaka", ""]]}, {"id": "2005.12741", "submitter": "Mengmi Zhang", "authors": "Mengmi Zhang, Gabriel Kreiman", "title": "What am I Searching for: Zero-shot Target Identity Inference in Visual\n  Search", "comments": "this was a mistaken new submission and a pointer to arXiv:1807.11926", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Can we infer intentions from a person's actions? As an example problem, here\nwe consider how to decipher what a person is searching for by decoding their\neye movement behavior. We conducted two psychophysics experiments where we\nmonitored eye movements while subjects searched for a target object. We defined\nthe fixations falling on \\textit{non-target} objects as \"error fixations\".\nUsing those error fixations, we developed a model (InferNet) to infer what the\ntarget was. InferNet uses a pre-trained convolutional neural network to extract\nfeatures from the error fixations and computes a similarity map between the\nerror fixations and all locations across the search image. The model\nconsolidates the similarity maps across layers and integrates these maps across\nall error fixations. InferNet successfully identifies the subject's goal and\noutperforms competitive null models, even without any object-specific training\non the inference task.\n", "versions": [{"version": "v1", "created": "Mon, 25 May 2020 04:53:32 GMT"}, {"version": "v2", "created": "Thu, 28 May 2020 19:49:41 GMT"}], "update_date": "2020-06-01", "authors_parsed": [["Zhang", "Mengmi", ""], ["Kreiman", "Gabriel", ""]]}, {"id": "2005.12800", "submitter": "Eyke H\\\"ullermeier", "authors": "Eyke H\\\"ullermeier", "title": "Towards Analogy-Based Explanations in Machine Learning", "comments": "11 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Principles of analogical reasoning have recently been applied in the context\nof machine learning, for example to develop new methods for classification and\npreference learning. In this paper, we argue that, while analogical reasoning\nis certainly useful for constructing new learning algorithms with high\npredictive accuracy, is is arguably not less interesting from an\ninterpretability and explainability point of view. More specifically, we take\nthe view that an analogy-based approach is a viable alternative to existing\napproaches in the realm of explainable AI and interpretable machine learning,\nand that analogy-based explanations of the predictions produced by a machine\nlearning algorithm can complement similarity-based explanations in a meaningful\nway. To corroborate these claims, we outline the basic idea of an analogy-based\nexplanation and illustrate its potential usefulness by means of some examples.\n", "versions": [{"version": "v1", "created": "Sat, 23 May 2020 06:41:35 GMT"}], "update_date": "2020-05-27", "authors_parsed": [["H\u00fcllermeier", "Eyke", ""]]}, {"id": "2005.12801", "submitter": "Kiant\\'e Brantley", "authors": "Kiant\\'e Brantley, Amr Sharaf, Hal Daum\\'e III", "title": "Active Imitation Learning with Noisy Guidance", "comments": "ACL 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Imitation learning algorithms provide state-of-the-art results on many\nstructured prediction tasks by learning near-optimal search policies. Such\nalgorithms assume training-time access to an expert that can provide the\noptimal action at any queried state; unfortunately, the number of such queries\nis often prohibitive, frequently rendering these approaches impractical. To\ncombat this query complexity, we consider an active learning setting in which\nthe learning algorithm has additional access to a much cheaper noisy heuristic\nthat provides noisy guidance. Our algorithm, LEAQI, learns a difference\nclassifier that predicts when the expert is likely to disagree with the\nheuristic, and queries the expert only when necessary. We apply LEAQI to three\nsequence labeling tasks, demonstrating significantly fewer queries to the\nexpert and comparable (or better) accuracies over a passive approach.\n", "versions": [{"version": "v1", "created": "Tue, 26 May 2020 15:35:46 GMT"}], "update_date": "2020-05-27", "authors_parsed": [["Brantley", "Kiant\u00e9", ""], ["Sharaf", "Amr", ""], ["Daum\u00e9", "Hal", "III"]]}, {"id": "2005.12826", "submitter": "Tao Liu", "authors": "Tao Liu", "title": "BHN: A Brain-like Heterogeneous Network", "comments": "Improve the readability, and add an image experiment", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The human brain works in an unsupervised way, and more than one brain region\nis essential for lighting up intelligence. Inspired by this, we propose a\nbrain-like heterogeneous network (BHN), which can cooperatively learn a lot of\ndistributed representations and one global attention representation. By\noptimizing distributed, self-supervised, and gradient-isolated objective\nfunctions in a minimax fashion, our model improves its representations, which\nare generated from patches of pictures or frames of videos in experiments.\n", "versions": [{"version": "v1", "created": "Tue, 26 May 2020 16:02:38 GMT"}, {"version": "v2", "created": "Sat, 6 Jun 2020 09:07:15 GMT"}], "update_date": "2020-06-09", "authors_parsed": [["Liu", "Tao", ""]]}, {"id": "2005.12841", "submitter": "Antonio Prestes Garcia", "authors": "Antonio Prestes Garc\\'ia and Alfonso Rodr\\'iguez-Pat\\'on", "title": "Applying Evolutionary Metaheuristics for Parameter Estimation of\n  Individual-Based Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Individual-based models are complex and they have usually an elevated number\nof input parameters which must be tuned for reproducing the observed population\ndata or the experimental results as accurately as possible. Thus, one of the\nweakest points of this modelling approach lies on the fact that rarely the\nmodeler has the enough information about the correct values or even the\nacceptable range for the input parameters. Consequently, several parameter\ncombinations must be tried to find an acceptable set of input factors\nminimizing the deviations of simulated and the reference dataset. In practice,\nmost of times, it is computationally unfeasible to traverse the complete search\nspace trying all every possible combination to find the best of set of\nparameters. That is precisely an instance of a combinatorial problem which is\nsuitable for being solved by metaheuristics and evolutionary computation\ntechniques. In this work, we introduce EvoPER, an R package for simplifying the\nparameter estimation using evolutionary computation methods.\n", "versions": [{"version": "v1", "created": "Sun, 24 May 2020 07:48:27 GMT"}], "update_date": "2020-05-27", "authors_parsed": [["Garc\u00eda", "Antonio Prestes", ""], ["Rodr\u00edguez-Pat\u00f3n", "Alfonso", ""]]}, {"id": "2005.12974", "submitter": "Nasim Sonboli", "authors": "Nasim Sonboli, Farzad Eskandanian, Robin Burke, Weiwen Liu, Bamshad\n  Mobasher", "title": "Opportunistic Multi-aspect Fairness through Personalized Re-ranking", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  As recommender systems have become more widespread and moved into areas with\ngreater social impact, such as employment and housing, researchers have begun\nto seek ways to ensure fairness in the results that such systems produce. This\nwork has primarily focused on developing recommendation approaches in which\nfairness metrics are jointly optimized along with recommendation accuracy.\nHowever, the previous work had largely ignored how individual preferences may\nlimit the ability of an algorithm to produce fair recommendations. Furthermore,\nwith few exceptions, researchers have only considered scenarios in which\nfairness is measured relative to a single sensitive feature or attribute (such\nas race or gender). In this paper, we present a re-ranking approach to\nfairness-aware recommendation that learns individual preferences across\nmultiple fairness dimensions and uses them to enhance provider fairness in\nrecommendation results. Specifically, we show that our opportunistic and\nmetric-agnostic approach achieves a better trade-off between accuracy and\nfairness than prior re-ranking approaches and does so across multiple fairness\ndimensions.\n", "versions": [{"version": "v1", "created": "Thu, 21 May 2020 04:25:20 GMT"}], "update_date": "2020-05-28", "authors_parsed": [["Sonboli", "Nasim", ""], ["Eskandanian", "Farzad", ""], ["Burke", "Robin", ""], ["Liu", "Weiwen", ""], ["Mobasher", "Bamshad", ""]]}, {"id": "2005.12981", "submitter": "Weinan Xu", "authors": "Weinan Xu, Hengxu He, Minshi Tan, Yunming Li, Jun Lang, Dongbai Guo", "title": "Deep Interest with Hierarchical Attention Network for Click-Through Rate\n  Prediction", "comments": "4 pages, SIGIR 2020 short paper accepted", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Interest Network (DIN) is a state-of-the-art model which uses attention\nmechanism to capture user interests from historical behaviors. User interests\nintuitively follow a hierarchical pattern such that users generally show\ninterests from a higher-level then to a lower-level abstraction. Modeling such\nan interest hierarchy in an attention network can fundamentally improve the\nrepresentation of user behaviors. We, therefore, propose an improvement over\nDIN to model arbitrary interest hierarchy: Deep Interest with Hierarchical\nAttention Network (DHAN). In this model, a multi-dimensional hierarchical\nstructure is introduced on the first attention layer which attends to an\nindividual item, and the subsequent attention layers in the same dimension\nattend to higher-level hierarchy built on top of the lower corresponding\nlayers. To enable modeling of multiple dimensional hierarchies, an expanding\nmechanism is introduced to capture one to many hierarchies. This design enables\nDHAN to attend different importance to different hierarchical abstractions thus\ncan fully capture user interests at different dimensions (e.g. category, price,\nor brand).To validate our model, a simplified DHAN has applied to Click-Through\nRate (CTR) prediction and our experimental results on three public datasets\nwith two levels of the one-dimensional hierarchy only by category. It shows the\nsuperiority of DHAN with significant AUC uplift from 12% to 21% over DIN. DHAN\nis also compared with another state-of-the-art model Deep Interest Evolution\nNetwork (DIEN), which models temporal interest. The simplified DHAN also gets\nslight AUC uplift from 1.0% to 1.7% over DIEN. A potential future work can be a\ncombination of DHAN and DIEN to model both temporal and hierarchical interests.\n", "versions": [{"version": "v1", "created": "Fri, 22 May 2020 04:02:01 GMT"}], "update_date": "2020-05-28", "authors_parsed": [["Xu", "Weinan", ""], ["He", "Hengxu", ""], ["Tan", "Minshi", ""], ["Li", "Yunming", ""], ["Lang", "Jun", ""], ["Guo", "Dongbai", ""]]}, {"id": "2005.13109", "submitter": "Shushman Choudhury", "authors": "Shushman Choudhury, Jayesh K. Gupta, Mykel J. Kochenderfer, Dorsa\n  Sadigh, Jeannette Bohg", "title": "Dynamic Multi-Robot Task Allocation under Uncertainty and Temporal\n  Constraints", "comments": "Robotics Science and Systems (RSS) 2020; Source code at\n  https://github.com/sisl/SCoBA.jl", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of dynamically allocating tasks to multiple agents\nunder time window constraints and task completion uncertainty. Our objective is\nto minimize the number of unsuccessful tasks at the end of the operation\nhorizon. We present a multi-robot allocation algorithm that decouples the key\ncomputational challenges of sequential decision-making under uncertainty and\nmulti-agent coordination and addresses them in a hierarchical manner. The lower\nlayer computes policies for individual agents using dynamic programming with\ntree search, and the upper layer resolves conflicts in individual plans to\nobtain a valid multi-agent allocation. Our algorithm, Stochastic Conflict-Based\nAllocation (SCoBA), is optimal in expectation and complete under some\nreasonable assumptions. In practice, SCoBA is computationally efficient enough\nto interleave planning and execution online. On the metric of successful task\ncompletion, SCoBA consistently outperforms a number of baseline methods and\nshows strong competitive performance against an oracle with complete lookahead.\nIt also scales well with the number of tasks and agents. We validate our\nresults over a wide range of simulations on two distinct domains: multi-arm\nconveyor belt pick-and-place and multi-drone delivery dispatch in a city.\n", "versions": [{"version": "v1", "created": "Wed, 27 May 2020 01:10:41 GMT"}, {"version": "v2", "created": "Fri, 29 May 2020 00:00:22 GMT"}, {"version": "v3", "created": "Sat, 25 Jul 2020 19:30:21 GMT"}], "update_date": "2020-07-28", "authors_parsed": [["Choudhury", "Shushman", ""], ["Gupta", "Jayesh K.", ""], ["Kochenderfer", "Mykel J.", ""], ["Sadigh", "Dorsa", ""], ["Bohg", "Jeannette", ""]]}, {"id": "2005.13129", "submitter": "Lizi Liao Ms", "authors": "Lizi Liao, Yunshan Ma, Wenqiang Lei, Tat-Seng Chua", "title": "Rethinking Dialogue State Tracking with Reasoning", "comments": "further modification needed", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tracking dialogue states to better interpret user goals and feed downstream\npolicy learning is a bottleneck in dialogue management. Common practice has\nbeen to treat it as a problem of classifying dialogue content into a set of\npre-defined slot-value pairs, or generating values for different slots given\nthe dialogue history. Both have limitations on considering dependencies that\noccur on dialogues, and are lacking of reasoning capabilities. This paper\nproposes to track dialogue states gradually with reasoning over dialogue turns\nwith the help of the back-end data. Empirical results demonstrate that our\nmethod significantly outperforms the state-of-the-art methods by 38.6% in terms\nof joint belief accuracy for MultiWOZ 2.1, a large-scale human-human dialogue\ndataset across multiple domains.\n", "versions": [{"version": "v1", "created": "Wed, 27 May 2020 02:05:33 GMT"}, {"version": "v2", "created": "Wed, 3 Jun 2020 15:12:56 GMT"}], "update_date": "2020-06-04", "authors_parsed": [["Liao", "Lizi", ""], ["Ma", "Yunshan", ""], ["Lei", "Wenqiang", ""], ["Chua", "Tat-Seng", ""]]}, {"id": "2005.13139", "submitter": "Geoffrey Clark", "authors": "Geoffrey Clark, Joseph Campbell, Seyed Mostafa Rezayat Sorkhabadi,\n  Wenlong Zhang, Heni Ben Amor", "title": "Predictive Modeling of Periodic Behavior for Human-Robot Symbiotic\n  Walking", "comments": "Accepted to ICRA 2020. Accompanying video presentation:\n  https://www.youtube.com/watch?v=EjSVjueePyQ&t=1s", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose in this paper Periodic Interaction Primitives - a probabilistic\nframework that can be used to learn compact models of periodic behavior. Our\napproach extends existing formulations of Interaction Primitives to periodic\nmovement regimes, i.e., walking. We show that this model is particularly\nwell-suited for learning data-driven, customized models of human walking, which\ncan then be used for generating predictions over future states or for inferring\nlatent, biomechanical variables. We also demonstrate how the same framework can\nbe used to learn controllers for a robotic prosthesis using an imitation\nlearning approach. Results in experiments with human participants indicate that\nPeriodic Interaction Primitives efficiently generate predictions and ankle\nangle control signals for a robotic prosthetic ankle, with MAE of 2.21 degrees\nin 0.0008s per inference. Performance degrades gracefully in the presence of\nnoise or sensor fall outs. Compared to alternatives, this algorithm functions\n20 times faster and performed 4.5 times more accurately on test subjects.\n", "versions": [{"version": "v1", "created": "Wed, 27 May 2020 03:30:48 GMT"}], "update_date": "2020-05-28", "authors_parsed": [["Clark", "Geoffrey", ""], ["Campbell", "Joseph", ""], ["Sorkhabadi", "Seyed Mostafa Rezayat", ""], ["Zhang", "Wenlong", ""], ["Amor", "Heni Ben", ""]]}, {"id": "2005.13170", "submitter": "Haochen Liu", "authors": "Haochen Liu, Zhiwei Wang, Tyler Derr and Jiliang Tang", "title": "Chat as Expected: Learning to Manipulate Black-box Neural Dialogue\n  Models", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, neural network based dialogue systems have become ubiquitous in our\nincreasingly digitalized society. However, due to their inherent opaqueness,\nsome recently raised concerns about using neural models are starting to be\ntaken seriously. In fact, intentional or unintentional behaviors could lead to\na dialogue system to generate inappropriate responses. Thus, in this paper, we\ninvestigate whether we can learn to craft input sentences that result in a\nblack-box neural dialogue model being manipulated into having its outputs\ncontain target words or match target sentences. We propose a reinforcement\nlearning based model that can generate such desired inputs automatically.\nExtensive experiments on a popular well-trained state-of-the-art neural\ndialogue model show that our method can successfully seek out desired inputs\nthat lead to the target outputs in a considerable portion of cases.\nConsequently, our work reveals the potential of neural dialogue models to be\nmanipulated, which inspires and opens the door towards developing strategies to\ndefend them.\n", "versions": [{"version": "v1", "created": "Wed, 27 May 2020 05:34:12 GMT"}], "update_date": "2020-05-28", "authors_parsed": [["Liu", "Haochen", ""], ["Wang", "Zhiwei", ""], ["Derr", "Tyler", ""], ["Tang", "Jiliang", ""]]}, {"id": "2005.13186", "submitter": "Alex Cummaudo Mr", "authors": "Alex Cummaudo, Scott Barnett, Rajesh Vasa, John Grundy, Mohamed\n  Abdelrazek", "title": "Beware the evolving 'intelligent' web service! An integration\n  architecture tactic to guard AI-first components", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Intelligent services provide the power of AI to developers via simple RESTful\nAPI endpoints, abstracting away many complexities of machine learning. However,\nmost of these intelligent services-such as computer vision-continually learn\nwith time. When the internals within the abstracted 'black box' become hidden\nand evolve, pitfalls emerge in the robustness of applications that depend on\nthese evolving services. Without adapting the way developers plan and construct\nprojects reliant on intelligent services, significant gaps and risks result in\nboth project planning and development. Therefore, how can software engineers\nbest mitigate software evolution risk moving forward, thereby ensuring that\ntheir own applications maintain quality? Our proposal is an architectural\ntactic designed to improve intelligent service-dependent software robustness.\nThe tactic involves creating an application-specific benchmark dataset\nbaselined against an intelligent service, enabling evolutionary behaviour\nchanges to be mitigated. A technical evaluation of our implementation of this\narchitecture demonstrates how the tactic can identify 1,054 cases of\nsubstantial confidence evolution and 2,461 cases of substantial changes to\nresponse label sets using a dataset consisting of 331 images that evolve when\nsent to a service.\n", "versions": [{"version": "v1", "created": "Wed, 27 May 2020 06:15:18 GMT"}], "update_date": "2020-05-28", "authors_parsed": [["Cummaudo", "Alex", ""], ["Barnett", "Scott", ""], ["Vasa", "Rajesh", ""], ["Grundy", "John", ""], ["Abdelrazek", "Mohamed", ""]]}, {"id": "2005.13219", "submitter": "Yingying Deng", "authors": "Yingying Deng, Fan Tang, Weiming Dong, Wen Sun, Feiyue Huang,\n  Changsheng Xu", "title": "Arbitrary Style Transfer via Multi-Adaptation Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Arbitrary style transfer is a significant topic with research value and\napplication prospect. A desired style transfer, given a content image and\nreferenced style painting, would render the content image with the color tone\nand vivid stroke patterns of the style painting while synchronously maintaining\nthe detailed content structure information. Style transfer approaches would\ninitially learn content and style representations of the content and style\nreferences and then generate the stylized images guided by these\nrepresentations. In this paper, we propose the multi-adaptation network which\ninvolves two self-adaptation (SA) modules and one co-adaptation (CA) module:\nthe SA modules adaptively disentangle the content and style representations,\ni.e., content SA module uses position-wise self-attention to enhance content\nrepresentation and style SA module uses channel-wise self-attention to enhance\nstyle representation; the CA module rearranges the distribution of style\nrepresentation based on content representation distribution by calculating the\nlocal similarity between the disentangled content and style features in a\nnon-local fashion. Moreover, a new disentanglement loss function enables our\nnetwork to extract main style patterns and exact content structures to adapt to\nvarious input images, respectively. Various qualitative and quantitative\nexperiments demonstrate that the proposed multi-adaptation network leads to\nbetter results than the state-of-the-art style transfer methods.\n", "versions": [{"version": "v1", "created": "Wed, 27 May 2020 08:00:22 GMT"}, {"version": "v2", "created": "Sun, 16 Aug 2020 05:28:46 GMT"}], "update_date": "2020-08-19", "authors_parsed": [["Deng", "Yingying", ""], ["Tang", "Fan", ""], ["Dong", "Weiming", ""], ["Sun", "Wen", ""], ["Huang", "Feiyue", ""], ["Xu", "Changsheng", ""]]}, {"id": "2005.13239", "submitter": "Tianhe Yu", "authors": "Tianhe Yu, Garrett Thomas, Lantao Yu, Stefano Ermon, James Zou, Sergey\n  Levine, Chelsea Finn, Tengyu Ma", "title": "MOPO: Model-based Offline Policy Optimization", "comments": "NeurIPS 2020. First two authors contributed equally. Last two authors\n  advised equally", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Offline reinforcement learning (RL) refers to the problem of learning\npolicies entirely from a large batch of previously collected data. This problem\nsetting offers the promise of utilizing such datasets to acquire policies\nwithout any costly or dangerous active exploration. However, it is also\nchallenging, due to the distributional shift between the offline training data\nand those states visited by the learned policy. Despite significant recent\nprogress, the most successful prior methods are model-free and constrain the\npolicy to the support of data, precluding generalization to unseen states. In\nthis paper, we first observe that an existing model-based RL algorithm already\nproduces significant gains in the offline setting compared to model-free\napproaches. However, standard model-based RL methods, designed for the online\nsetting, do not provide an explicit mechanism to avoid the offline setting's\ndistributional shift issue. Instead, we propose to modify the existing\nmodel-based RL methods by applying them with rewards artificially penalized by\nthe uncertainty of the dynamics. We theoretically show that the algorithm\nmaximizes a lower bound of the policy's return under the true MDP. We also\ncharacterize the trade-off between the gain and risk of leaving the support of\nthe batch data. Our algorithm, Model-based Offline Policy Optimization (MOPO),\noutperforms standard model-based RL algorithms and prior state-of-the-art\nmodel-free offline RL algorithms on existing offline RL benchmarks and two\nchallenging continuous control tasks that require generalizing from data\ncollected for a different task. The code is available at\nhttps://github.com/tianheyu927/mopo.\n", "versions": [{"version": "v1", "created": "Wed, 27 May 2020 08:46:41 GMT"}, {"version": "v2", "created": "Wed, 1 Jul 2020 06:01:54 GMT"}, {"version": "v3", "created": "Sun, 6 Sep 2020 23:25:56 GMT"}, {"version": "v4", "created": "Wed, 23 Sep 2020 07:08:58 GMT"}, {"version": "v5", "created": "Tue, 29 Sep 2020 23:49:26 GMT"}, {"version": "v6", "created": "Sun, 22 Nov 2020 07:04:17 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Yu", "Tianhe", ""], ["Thomas", "Garrett", ""], ["Yu", "Lantao", ""], ["Ermon", "Stefano", ""], ["Zou", "James", ""], ["Levine", "Sergey", ""], ["Finn", "Chelsea", ""], ["Ma", "Tengyu", ""]]}, {"id": "2005.13270", "submitter": "Vinay Setty", "authors": "Bjarte Botnevik, Eirik Sakariassen, and Vinay Setty", "title": "BRENDA: Browser Extension for Fake News Detection", "comments": "Accepted as SIGIR demo", "journal-ref": "In Proceedings of the 43rd International ACM SIGIR Conference on\n  Research and Development in Information Retrieval (SIGIR 2020), July 25 to\n  30, 2020, Virtual Event, China. ACM, New York, NY, USA, 4 pages", "doi": "10.1145/3397271.3401396", "report-no": null, "categories": "cs.IR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Misinformation such as fake news has drawn a lot of attention in recent\nyears. It has serious consequences on society, politics and economy. This has\nlead to a rise of manually fact-checking websites such as Snopes and\nPolitifact. However, the scale of misinformation limits their ability for\nverification. In this demonstration, we propose BRENDA a browser extension\nwhich can be used to automate the entire process of credibility assessments of\nfalse claims. Behind the scenes BRENDA uses a tested deep neural network\narchitecture to automatically identify fact check worthy claims and classifies\nas well as presents the result along with evidence to the user. Since BRENDA is\na browser extension, it facilities fast automated fact checking for the end\nuser without having to leave the Webpage.\n", "versions": [{"version": "v1", "created": "Wed, 27 May 2020 10:29:14 GMT"}], "update_date": "2020-05-28", "authors_parsed": [["Botnevik", "Bjarte", ""], ["Sakariassen", "Eirik", ""], ["Setty", "Vinay", ""]]}, {"id": "2005.13275", "submitter": "Irene Celino", "authors": "Irene Celino", "title": "Who is this Explanation for? Human Intelligence and Knowledge Graphs for\n  eXplainable AI", "comments": "10 pages, 1 figure, book chapter", "journal-ref": "Ilaria Tiddi, Freddy Lecue, Pascal Hitzler (eds.), Knowledge\n  Graphs for eXplainable AI - Foundations, Applications and Challenges. Studies\n  on the Semantic Web, Volume 47, IOS Press, Amsterdam, 2020", "doi": null, "report-no": null, "categories": "cs.HC cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  eXplainable AI focuses on generating explanations for the output of an AI\nalgorithm to a user, usually a decision-maker. Such user needs to interpret the\nAI system in order to decide whether to trust the machine outcome. When\naddressing this challenge, therefore, proper attention should be given to\nproduce explanations that are interpretable by the target community of users.\nIn this chapter, we claim for the need to better investigate what constitutes a\nhuman explanation, i.e. a justification of the machine behaviour that is\ninterpretable and actionable by the human decision makers. In particular, we\nfocus on the contributions that Human Intelligence can bring to eXplainable AI,\nespecially in conjunction with the exploitation of Knowledge Graphs. Indeed, we\ncall for a better interplay between Knowledge Representation and Reasoning,\nSocial Sciences, Human Computation and Human-Machine Cooperation research -- as\nalready explored in other AI branches -- in order to support the goal of\neXplainable AI with the adoption of a Human-in-the-Loop approach.\n", "versions": [{"version": "v1", "created": "Wed, 27 May 2020 10:47:15 GMT"}], "update_date": "2020-05-28", "authors_parsed": [["Celino", "Irene", ""]]}, {"id": "2005.13289", "submitter": "Pascal Kerschke", "authors": "Jakob Bossek and Pascal Kerschke and Heike Trautmann", "title": "Anytime Behavior of Inexact TSP Solvers and Perspectives for Automated\n  Algorithm Selection", "comments": "This version has been accepted for publication at the IEEE Congress\n  on Evolutionary Computation (IEEE CEC) 2020, which is part of the IEEE World\n  Congress on Computational Intelligence (IEEE WCCI) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Traveling-Salesperson-Problem (TSP) is arguably one of the best-known\nNP-hard combinatorial optimization problems. The two sophisticated heuristic\nsolvers LKH and EAX and respective (restart) variants manage to calculate\nclose-to optimal or even optimal solutions, also for large instances with\nseveral thousand nodes in reasonable time. In this work we extend existing\nbenchmarking studies by addressing anytime behaviour of inexact TSP solvers\nbased on empirical runtime distributions leading to an increased understanding\nof solver behaviour and the respective relation to problem hardness. It turns\nout that performance ranking of solvers is highly dependent on the focused\napproximation quality. Insights on intersection points of performances offer\nhuge potential for the construction of hybridized solvers depending on instance\nfeatures. Moreover, instance features tailored to anytime performance and\ncorresponding performance indicators will highly improve automated algorithm\nselection models by including comprehensive information on solver quality.\n", "versions": [{"version": "v1", "created": "Wed, 27 May 2020 11:36:53 GMT"}], "update_date": "2020-05-28", "authors_parsed": [["Bossek", "Jakob", ""], ["Kerschke", "Pascal", ""], ["Trautmann", "Heike", ""]]}, {"id": "2005.13399", "submitter": "Lasha Abzianidze", "authors": "Lasha Abzianidze, Rik van Noord, Hessel Haagsma and Johan Bos", "title": "The First Shared Task on Discourse Representation Structure Parsing", "comments": "International Conference on Computational Semantics (IWCS)", "journal-ref": "Proceedings of the IWCS Shared Task on Semantic Parsing, IWCS,\n  SIGSEM, 2019, Association for Computational Linguistics", "doi": "10.18653/v1/W19-1201", "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  The paper presents the IWCS 2019 shared task on semantic parsing where the\ngoal is to produce Discourse Representation Structures (DRSs) for English\nsentences. DRSs originate from Discourse Representation Theory and represent\nscoped meaning representations that capture the semantics of negation, modals,\nquantification, and presupposition triggers. Additionally, concepts and\nevent-participants in DRSs are described with WordNet synsets and the thematic\nroles from VerbNet. To measure similarity between two DRSs, they are\nrepresented in a clausal form, i.e. as a set of tuples. Participant systems\nwere expected to produce DRSs in this clausal form. Taking into account the\nrich lexical information, explicit scope marking, a high number of shared\nvariables among clauses, and highly-constrained format of valid DRSs, all these\nmakes the DRS parsing a challenging NLP task. The results of the shared task\ndisplayed improvements over the existing state-of-the-art parser.\n", "versions": [{"version": "v1", "created": "Wed, 27 May 2020 14:52:21 GMT"}], "update_date": "2020-05-28", "authors_parsed": [["Abzianidze", "Lasha", ""], ["van Noord", "Rik", ""], ["Haagsma", "Hessel", ""], ["Bos", "Johan", ""]]}, {"id": "2005.13406", "submitter": "Sebastian Jaszczur", "authors": "Sebastian Jaszczur, Micha{\\l} {\\L}uszczyk, Henryk Michalewski", "title": "Neural heuristics for SAT solving", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We use neural graph networks with a message-passing architecture and an\nattention mechanism to enhance the branching heuristic in two SAT-solving\nalgorithms. We report improvements of learned neural heuristics compared with\ntwo standard human-designed heuristics.\n", "versions": [{"version": "v1", "created": "Wed, 27 May 2020 15:05:22 GMT"}], "update_date": "2020-05-28", "authors_parsed": [["Jaszczur", "Sebastian", ""], ["\u0141uszczyk", "Micha\u0142", ""], ["Michalewski", "Henryk", ""]]}, {"id": "2005.13407", "submitter": "Amir Feder", "authors": "Amir Feder, Nadav Oved, Uri Shalit, Roi Reichart", "title": "CausaLM: Causal Model Explanation Through Counterfactual Language Models", "comments": "Our code and data are available at:\n  https://amirfeder.github.io/CausaLM/ Accepted for publication in\n  Computational Linguistics journal", "journal-ref": null, "doi": "10.1162/coli_a_00404", "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding predictions made by deep neural networks is notoriously\ndifficult, but also crucial to their dissemination. As all machine learning\nbased methods, they are as good as their training data, and can also capture\nunwanted biases. While there are tools that can help understand whether such\nbiases exist, they do not distinguish between correlation and causation, and\nmight be ill-suited for text-based models and for reasoning about high level\nlanguage concepts. A key problem of estimating the causal effect of a concept\nof interest on a given model is that this estimation requires the generation of\ncounterfactual examples, which is challenging with existing generation\ntechnology. To bridge that gap, we propose CausaLM, a framework for producing\ncausal model explanations using counterfactual language representation models.\nOur approach is based on fine-tuning of deep contextualized embedding models\nwith auxiliary adversarial tasks derived from the causal graph of the problem.\nConcretely, we show that by carefully choosing auxiliary adversarial\npre-training tasks, language representation models such as BERT can effectively\nlearn a counterfactual representation for a given concept of interest, and be\nused to estimate its true causal effect on model performance. A byproduct of\nour method is a language representation model that is unaffected by the tested\nconcept, which can be useful in mitigating unwanted bias ingrained in the data.\n", "versions": [{"version": "v1", "created": "Wed, 27 May 2020 15:06:35 GMT"}, {"version": "v2", "created": "Wed, 3 Jun 2020 06:59:21 GMT"}, {"version": "v3", "created": "Sun, 14 Jun 2020 21:06:43 GMT"}, {"version": "v4", "created": "Sun, 9 May 2021 12:34:18 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Feder", "Amir", ""], ["Oved", "Nadav", ""], ["Shalit", "Uri", ""], ["Reichart", "Roi", ""]]}, {"id": "2005.13520", "submitter": "Mahboobeh Parsapoor", "authors": "Mahboobeh Parsapoor", "title": "Emotion-Inspired Deep Structure (EiDS) for EEG Time Series Forecasting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Accurate forecasting of an electroencephalogram (EEG) time series is crucial\nfor the correct diagnosis of neurological disorders such as seizures and\nepilepsy. Since the EEG time series is chaotic, most traditional machine\nlearning algorithms have failed to forecast its next steps accurately. Thus, we\nsuggest a model, which has formed by taking inspiration from the neural\nstructures that underlie feelings (emotional states), to forecast EEG time\nseries. The model, which is referred to as emotion-inspired deep structure\n(EiDS), can be used to predict both short- and long-term of EEG time series.\nThis paper also compares the performance of EiDS with other variations of long\nshort-term memory (LSTM) networks.\n", "versions": [{"version": "v1", "created": "Sat, 23 May 2020 13:48:18 GMT"}, {"version": "v2", "created": "Sat, 1 Aug 2020 13:31:01 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Parsapoor", "Mahboobeh", ""]]}, {"id": "2005.13596", "submitter": "Subhadeep Mukhopadhyay", "authors": "Subhadeep (DEEP) Mukhopadhyay and Kaijun Wang", "title": "Breiman's \"Two Cultures\" Revisited and Reconciled", "comments": "This paper celebrates the 70th anniversary of Statistical Machine\n  Learning--- how far we've come, and how far we have to go. Keywords:\n  Integrated statistical learning theory, Exploratory machine learning,\n  Uncertainty prediction machine, ML-powered modern applied statistics,\n  Information theory", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG econ.EM stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a landmark paper published in 2001, Leo Breiman described the tense\nstandoff between two cultures of data modeling: parametric statistical and\nalgorithmic machine learning. The cultural division between these two\nstatistical learning frameworks has been growing at a steady pace in recent\nyears. What is the way forward? It has become blatantly obvious that this\nwidening gap between \"the two cultures\" cannot be averted unless we find a way\nto blend them into a coherent whole. This article presents a solution by\nestablishing a link between the two cultures. Through examples, we describe the\nchallenges and potential gains of this new integrated statistical thinking.\n", "versions": [{"version": "v1", "created": "Wed, 27 May 2020 19:02:56 GMT"}], "update_date": "2020-05-29", "authors_parsed": [["Subhadeep", "", "", "DEEP"], ["Mukhopadhyay", "", ""], ["Wang", "Kaijun", ""]]}, {"id": "2005.13601", "submitter": "Eric Veith", "authors": "Eric MSP Veith, Nils Wenninghoff, and Emilie Frost", "title": "The Adversarial Resilience Learning Architecture for AI-based Modelling,\n  Exploration, and Operation of Complex Cyber-Physical Systems", "comments": "Submitted to NIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern algorithms in the domain of Deep Reinforcement Learning (DRL)\ndemonstrated remarkable successes; most widely known are those in game-based\nscenarios, from ATARI video games to Go and the StarCraft~\\textsc{II} real-time\nstrategy game. However, applications in the domain of modern Cyber-Physical\nSystems (CPS) that take advantage a vast variety of DRL algorithms are few. We\nassume that the benefits would be considerable: Modern CPS have become\nincreasingly complex and evolved beyond traditional methods of modelling and\nanalysis. At the same time, these CPS are confronted with an increasing amount\nof stochastic inputs, from volatile energy sources in power grids to broad user\nparticipation stemming from markets. Approaches of system modelling that use\ntechniques from the domain of Artificial Intelligence (AI) do not focus on\nanalysis and operation. In this paper, we describe the concept of Adversarial\nResilience Learning (ARL) that formulates a new approach to complex environment\nchecking and resilient operation: It defines two agent classes, attacker and\ndefender agents. The quintessence of ARL lies in both agents exploring the\nsystem and training each other without any domain knowledge. Here, we introduce\nthe ARL software architecture that allows to use a wide range of model-free as\nwell as model-based DRL-based algorithms, and document results of concrete\nexperiment runs on a complex power grid.\n", "versions": [{"version": "v1", "created": "Wed, 27 May 2020 19:19:57 GMT"}], "update_date": "2020-05-29", "authors_parsed": [["Veith", "Eric MSP", ""], ["Wenninghoff", "Nils", ""], ["Frost", "Emilie", ""]]}, {"id": "2005.13625", "submitter": "Justin Terry", "authors": "Justin K Terry, Nathaniel Grammel, Ananth Hari, Luis Santos, Benjamin\n  Black", "title": "Revisiting Parameter Sharing In Multi-Agent Deep Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  \"Nonstationarity\" is a fundamental problem in cooperative multi-agent\nreinforcement learning (MARL). It results from every agent's policy changing\nduring learning, while being part of the environment from the perspective of\nother agents. This causes information to inherently oscillate between agents\nduring learning, greatly slowing convergence. We use the MAILP model of\ninformation transfer during multi-agent learning to show that increasing\ncentralization during learning arbitrarily mitigates the slowing of convergence\ndue to nonstationarity. The most centralized case of learning is parameter\nsharing, an uncommonly used MARL method, specific to environments with\nhomogeneous agents. It bootstraps single-agent reinforcement learning (RL)\nmethods and learns an identical policy for each agent. We experimentally\nreplicate our theoretical result of increased learning centralization leading\nto better performance. We further apply parameter sharing to 8 more modern\nsingle-agent deep RL methods for the first time, achieving up to 44 times more\naverage reward in 16% as many episodes compared to previous parameter sharing\nexperiments. We finally give a formal proof of a set of methods that allow\nparameter sharing to serve in environments with heterogeneous agents.\n", "versions": [{"version": "v1", "created": "Wed, 27 May 2020 20:14:28 GMT"}, {"version": "v2", "created": "Fri, 5 Jun 2020 08:33:31 GMT"}, {"version": "v3", "created": "Tue, 7 Jul 2020 23:17:06 GMT"}, {"version": "v4", "created": "Fri, 24 Jul 2020 05:39:03 GMT"}, {"version": "v5", "created": "Wed, 11 Nov 2020 01:19:15 GMT"}, {"version": "v6", "created": "Thu, 25 Feb 2021 22:24:34 GMT"}], "update_date": "2021-03-01", "authors_parsed": [["Terry", "Justin K", ""], ["Grammel", "Nathaniel", ""], ["Hari", "Ananth", ""], ["Santos", "Luis", ""], ["Black", "Benjamin", ""]]}, {"id": "2005.13635", "submitter": "Johannes Schneider", "authors": "Johannes Schneider and Frank Breitinger", "title": "AI Forensics: Did the Artificial Intelligence System Do It? Why?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In an increasingly autonomous manner AI systems make decisions impacting our\ndaily life. Their actions might cause accidents, harm or, more generally,\nviolate regulations -- either intentionally or not. Thus, AI systems might be\nconsidered suspects for various events. Therefore, it is essential to relate\nparticular events to an AI, its owner and its creator. Given a multitude of AI\nsystems from multiple manufactures, potentially, altered by their owner or\nchanging through self-learning, this seems non-trivial. This paper discusses\nhow to identify AI systems responsible for incidents as well as their motives\nthat might be \"malicious by design\". In addition to a conceptualization, we\nconduct two case studies based on reinforcement learning and convolutional\nneural networks to illustrate our proposed methods and challenges. Our cases\nillustrate that \"catching AI systems\" seems often far from trivial and requires\nextensive expertise in machine learning. Legislative measures that enforce\nmandatory information to be collected during operation of AI systems as well as\nmeans to uniquely identify systems might facilitate the problem.\n", "versions": [{"version": "v1", "created": "Wed, 27 May 2020 20:28:19 GMT"}, {"version": "v2", "created": "Fri, 18 Sep 2020 16:21:00 GMT"}], "update_date": "2020-09-21", "authors_parsed": [["Schneider", "Johannes", ""], ["Breitinger", "Frank", ""]]}, {"id": "2005.13685", "submitter": "Ameer Haj-Ali", "authors": "Ameer Haj-Ali, Hasan Genc, Qijing Huang, William Moses, John\n  Wawrzynek, Krste Asanovi\\'c, Ion Stoica", "title": "ProTuner: Tuning Programs with Monte Carlo Tree Search", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.AI cs.LG cs.PF cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We explore applying the Monte Carlo Tree Search (MCTS) algorithm in a\nnotoriously difficult task: tuning programs for high-performance deep learning\nand image processing. We build our framework on top of Halide and show that\nMCTS can outperform the state-of-the-art beam-search algorithm. Unlike beam\nsearch, which is guided by greedy intermediate performance comparisons between\npartial and less meaningful schedules, MCTS compares complete schedules and\nlooks ahead before making any intermediate scheduling decision. We further\nexplore modifications to the standard MCTS algorithm as well as combining real\nexecution time measurements with the cost model. Our results show that MCTS can\noutperform beam search on a suite of 16 real benchmarks.\n", "versions": [{"version": "v1", "created": "Wed, 27 May 2020 22:25:10 GMT"}], "update_date": "2020-05-29", "authors_parsed": [["Haj-Ali", "Ameer", ""], ["Genc", "Hasan", ""], ["Huang", "Qijing", ""], ["Moses", "William", ""], ["Wawrzynek", "John", ""], ["Asanovi\u0107", "Krste", ""], ["Stoica", "Ion", ""]]}, {"id": "2005.13766", "submitter": "Risto Miikkulainen", "authors": "Risto Miikkulainen, Olivier Francon, Elliot Meyerson, Xin Qiu, Elisa\n  Canzani, and Babak Hodjat", "title": "From Prediction to Prescription: Evolutionary Optimization of\n  Non-Pharmaceutical Interventions in the COVID-19 Pandemic", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Several models have been developed to predict how the COVID-19 pandemic\nspreads, and how it could be contained with non-pharmaceutical interventions\n(NPIs) such as social distancing restrictions and school and business closures.\nThis paper demonstrates how evolutionary AI could be used to facilitate the\nnext step, i.e. determining most effective intervention strategies\nautomatically. Through evolutionary surrogate-assisted prescription (ESP), it\nis possible to generate a large number of candidate strategies and evaluate\nthem with predictive models. In principle, strategies can be customized for\ndifferent countries and locales, and balance the need to contain the pandemic\nand the need to minimize their economic impact. While still limited by\navailable data, early experiments suggest that workplace and school\nrestrictions are the most important and need to be designed carefully. It also\ndemonstrates that results of lifting restrictions can be unreliable, and\nsuggests creative ways in which restrictions can be implemented softly, e.g. by\nalternating them over time. As more data becomes available, the approach can be\nincreasingly useful in dealing with COVID-19 as well as possible future\npandemics.\n", "versions": [{"version": "v1", "created": "Thu, 28 May 2020 03:43:31 GMT"}, {"version": "v2", "created": "Sat, 30 May 2020 23:12:48 GMT"}, {"version": "v3", "created": "Sat, 1 Aug 2020 23:02:52 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Miikkulainen", "Risto", ""], ["Francon", "Olivier", ""], ["Meyerson", "Elliot", ""], ["Qiu", "Xin", ""], ["Canzani", "Elisa", ""], ["Hodjat", "Babak", ""]]}, {"id": "2005.13778", "submitter": "Parth Chadha", "authors": "Parth Chadha", "title": "Domain Knowledge Integration By Gradient Matching For Sample-Efficient\n  Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Model-free deep reinforcement learning (RL) agents can learn an effective\npolicy directly from repeated interactions with a black-box environment.\nHowever in practice, the algorithms often require large amounts of training\nexperience to learn and generalize well. In addition, classic model-free\nlearning ignores the domain information contained in the state transition\ntuples. Model-based RL, on the other hand, attempts to learn a model of the\nenvironment from experience and is substantially more sample efficient, but\nsuffers from significantly large asymptotic bias owing to the imperfect\ndynamics model. In this paper, we propose a gradient matching algorithm to\nimprove sample efficiency by utilizing target slope information from the\ndynamics predictor to aid the model-free learner. We demonstrate this by\npresenting a technique for matching the gradient information from the\nmodel-based learner with the model-free component in an abstract\nlow-dimensional space and validate the proposed technique through experimental\nresults that demonstrate the efficacy of this approach.\n", "versions": [{"version": "v1", "created": "Thu, 28 May 2020 05:02:47 GMT"}], "update_date": "2020-05-29", "authors_parsed": [["Chadha", "Parth", ""]]}, {"id": "2005.13857", "submitter": "Hartmut Surmann HaSu", "authors": "Hartmut Surmann, Christian Jestel, Robin Marchel, Franziska Musberg,\n  Houssem Elhadj and Mahbube Ardani", "title": "Deep Reinforcement learning for real autonomous mobile robot navigation\n  in indoor environments", "comments": "7 pages, report", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Deep Reinforcement Learning has been successfully applied in various computer\ngames [8]. However, it is still rarely used in real-world applications,\nespecially for the navigation and continuous control of real mobile robots\n[13]. Previous approaches lack safety and robustness and/or need a structured\nenvironment. In this paper we present our proof of concept for autonomous\nself-learning robot navigation in an unknown environment for a real robot\nwithout a map or planner. The input for the robot is only the fused data from a\n2D laser scanner and a RGB-D camera as well as the orientation to the goal. The\nmap of the environment is unknown. The output actions of an Asynchronous\nAdvantage Actor-Critic network (GA3C) are the linear and angular velocities for\nthe robot. The navigator/controller network is pretrained in a high-speed,\nparallel, and self-implemented simulation environment to speed up the learning\nprocess and then deployed to the real robot. To avoid overfitting, we train\nrelatively small networks, and we add random Gaussian noise to the input laser\ndata. The sensor data fusion with the RGB-D camera allows the robot to navigate\nin real environments with real 3D obstacle avoidance and without the need to\nfit the environment to the sensory capabilities of the robot. To further\nincrease the robustness, we train on environments of varying difficulties and\nrun 32 training instances simultaneously. Video: supplementary File / YouTube,\nCode: GitHub\n", "versions": [{"version": "v1", "created": "Thu, 28 May 2020 09:15:14 GMT"}], "update_date": "2020-05-29", "authors_parsed": [["Surmann", "Hartmut", ""], ["Jestel", "Christian", ""], ["Marchel", "Robin", ""], ["Musberg", "Franziska", ""], ["Elhadj", "Houssem", ""], ["Ardani", "Mahbube", ""]]}, {"id": "2005.13872", "submitter": "Jakob Bossek", "authors": "Jakob Bossek, Christian Grimme, Heike Trautmann", "title": "Dynamic Bi-Objective Routing of Multiple Vehicles", "comments": null, "journal-ref": null, "doi": "10.1145/3377930.3390146", "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In practice, e.g. in delivery and service scenarios, Vehicle-Routing-Problems\n(VRPs) often imply repeated decision making on dynamic customer requests. As in\nclassical VRPs, tours have to be planned short while the number of serviced\ncustomers has to be maximized at the same time resulting in a multi-objective\nproblem. Beyond that, however, dynamic requests lead to the need for\nre-planning of not yet realized tour parts, while already realized tour parts\nare irreversible. In this paper we study this type of bi-objective dynamic VRP\nincluding sequential decision making and concurrent realization of decisions.\nWe adopt a recently proposed Dynamic Evolutionary Multi-Objective Algorithm\n(DEMOA) for a related VRP problem and extend it to the more realistic (here\nconsidered) scenario of multiple vehicles. We empirically show that our DEMOA\nis competitive with a multi-vehicle offline and clairvoyant variant of the\nproposed DEMOA as well as with the dynamic single-vehicle approach proposed\nearlier.\n", "versions": [{"version": "v1", "created": "Thu, 28 May 2020 09:35:45 GMT"}], "update_date": "2020-05-29", "authors_parsed": [["Bossek", "Jakob", ""], ["Grimme", "Christian", ""], ["Trautmann", "Heike", ""]]}, {"id": "2005.13970", "submitter": "Olivier Teytaud", "authors": "Marie-Liesse Cauwet, Olivier Teytaud", "title": "Population Control meets Doob's Martingale Theorems: the Noise-free\n  Multimodal Case", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study a test-based population size adaptation (TBPSA) method, inspired\nfrom population control, in the noise-free multimodal case. In the noisy\nsetting, TBPSA usually recommends, at the end of the run, the center of the\nGaussian as an approximation of the optimum. We show that combined with a more\nnaive recommendation, namely recommending the visited point which had the best\nfitness value so far, TBPSA is also powerful in the noise-free multimodal\ncontext.\n  We demonstrate this experimentally and explore this mechanism theoretically:\nwe prove that TBPSA is able to escape plateaus with probability one in spite of\nthe fact that it can converge to local minima. This leads to an algorithm\neffective in the multimodal setting without resorting to a random restart from\nscratch.\n", "versions": [{"version": "v1", "created": "Sun, 24 May 2020 13:47:39 GMT"}], "update_date": "2020-05-29", "authors_parsed": [["Cauwet", "Marie-Liesse", ""], ["Teytaud", "Olivier", ""]]}, {"id": "2005.13976", "submitter": "Madhur Behl", "authors": "Hyun Jae Cho, and Madhur Behl", "title": "Towards Automated Safety Coverage and Testing for Autonomous Vehicles\n  with Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The kind of closed-loop verification likely to be required for autonomous\nvehicle (AV) safety testing is beyond the reach of traditional test\nmethodologies and discrete verification. Validation puts the autonomous vehicle\nsystem to the test in scenarios or situations that the system would likely\nencounter in everyday driving after its release. These scenarios can either be\ncontrolled directly in a physical (closed-course proving ground) or virtual\n(simulation of predefined scenarios) environment, or they can arise\nspontaneously during operation in the real world (open-road testing or\nsimulation of randomly generated scenarios).\n  In AV testing, simulation serves primarily two purposes: to assist the\ndevelopment of a robust autonomous vehicle and to test and validate the AV\nbefore release. A challenge arises from the sheer number of scenario variations\nthat can be constructed from each of the above sources due to the high number\nof variables involved (most of which are continuous). Even with continuous\nvariables discretized, the possible number of combinations becomes practically\ninfeasible to test. To overcome this challenge we propose using reinforcement\nlearning (RL) to generate failure examples and unexpected traffic situations\nfor the AV software implementation. Although reinforcement learning algorithms\nhave achieved notable results in games and some robotic manipulations, this\ntechnique has not been widely scaled up to the more challenging real world\napplications like autonomous driving.\n", "versions": [{"version": "v1", "created": "Fri, 22 May 2020 19:00:38 GMT"}], "update_date": "2020-05-29", "authors_parsed": [["Cho", "Hyun Jae", ""], ["Behl", "Madhur", ""]]}, {"id": "2005.13997", "submitter": "Mark Keane", "authors": "Mark T. Keane, Barry Smyth", "title": "Good Counterfactuals and Where to Find Them: A Case-Based Technique for\n  Generating Counterfactuals for Explainable AI (XAI)", "comments": "15 pages, 3 figures", "journal-ref": "28th International Conference on Case Based Reasoning (ICCBR2020),\n  2020", "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, a groundswell of research has identified the use of counterfactual\nexplanations as a potentially significant solution to the Explainable AI (XAI)\nproblem. It is argued that (a) technically, these counterfactual cases can be\ngenerated by permuting problem-features until a class change is found, (b)\npsychologically, they are much more causally informative than factual\nexplanations, (c) legally, they are GDPR-compliant. However, there are issues\naround the finding of good counterfactuals using current techniques (e.g.\nsparsity and plausibility). We show that many commonly-used datasets appear to\nhave few good counterfactuals for explanation purposes. So, we propose a new\ncase based approach for generating counterfactuals using novel ideas about the\ncounterfactual potential and explanatory coverage of a case-base. The new\ntechnique reuses patterns of good counterfactuals, present in a case-base, to\ngenerate analogous counterfactuals that can explain new problems and their\nsolutions. Several experiments show how this technique can improve the\ncounterfactual potential and explanatory coverage of case-bases that were\npreviously found wanting.\n", "versions": [{"version": "v1", "created": "Tue, 26 May 2020 14:05:10 GMT"}], "update_date": "2020-05-29", "authors_parsed": [["Keane", "Mark T.", ""], ["Smyth", "Barry", ""]]}, {"id": "2005.14026", "submitter": "Tajul Rosli Razak Mr", "authors": "Tajul Rosli Razak, Iman Hazwam Abd Halim, Muhammad Nabil Fikri\n  Jamaludin, Mohammad Hafiz Ismail, Shukor Sanim Mohd Fauzi", "title": "An Exploratory Study of Hierarchical Fuzzy Systems Approach in\n  Recommendation System", "comments": null, "journal-ref": "Jurnal Intelek Vol 14 No 2 December 2019", "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recommendation system or also known as a recommender system is a tool to help\nthe user in providing a suggestion of a specific dilemma. Thus, recently, the\ninterest in developing a recommendation system in many fields has increased.\nFuzzy Logic system (FLSs) is one of the approaches that can be used to model\nthe recommendation systems as it can deal with uncertainty and imprecise\ninformation. However, one of the fundamental issues in FLS is the problem of\nthe curse of dimensionality. That is, the number of rules in FLSs is increasing\nexponentially with the number of input variables. One effective way to overcome\nthis problem is by using Hierarchical Fuzzy System (HFSs). This paper aims to\nexplore the use of HFSs for Recommendation system. Specifically, we are\ninterested in exploring and comparing the HFS and FLS for the Career path\nrecommendation system (CPRS) based on four key criteria, namely topology, the\nnumber of rules, the rules structures and interpretability. The findings\nsuggested that the HFS has advantages over FLS towards improving the\ninterpretability models, in the context of a recommendation system example.\nThis study contributes to providing an insight into the development of\ninterpretable HFSs in the Recommendation systems.\n", "versions": [{"version": "v1", "created": "Wed, 27 May 2020 09:01:44 GMT"}], "update_date": "2020-05-29", "authors_parsed": [["Razak", "Tajul Rosli", ""], ["Halim", "Iman Hazwam Abd", ""], ["Jamaludin", "Muhammad Nabil Fikri", ""], ["Ismail", "Mohammad Hafiz", ""], ["Fauzi", "Shukor Sanim Mohd", ""]]}, {"id": "2005.14037", "submitter": "Mohammad-Ali Javidian", "authors": "Mohammad Ali Javidian, Marco Valtorta and Pooyan Jamshidi", "title": "Learning LWF Chain Graphs: an Order Independent Algorithm", "comments": "arXiv admin note: substantial text overlap with arXiv:2002.10870,\n  arXiv:1910.01067; substantial text overlap with arXiv:1211.3295 by other\n  authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  LWF chain graphs combine directed acyclic graphs and undirected graphs. We\npresent a PC-like algorithm that finds the structure of chain graphs under the\nfaithfulness assumption to resolve the problem of scalability of the proposed\nalgorithm by Studeny (1997). We prove that our PC-like algorithm is order\ndependent, in the sense that the output can depend on the order in which the\nvariables are given. This order dependence can be very pronounced in\nhigh-dimensional settings. We propose two modifications of the PC-like\nalgorithm that remove part or all of this order dependence. Simulation results\nunder a variety of settings demonstrate the competitive performance of the\nPC-like algorithms in comparison with the decomposition-based method, called\nLCD algorithm, proposed by Ma et al. (2008) in low-dimensional settings and\nimproved performance in high-dimensional settings.\n", "versions": [{"version": "v1", "created": "Wed, 27 May 2020 01:05:49 GMT"}], "update_date": "2020-05-29", "authors_parsed": [["Javidian", "Mohammad Ali", ""], ["Valtorta", "Marco", ""], ["Jamshidi", "Pooyan", ""]]}, {"id": "2005.14080", "submitter": "Paolo Torroni", "authors": "Daniela Loreti and Marco Lippi and Paolo Torroni", "title": "Parallelizing Machine Learning as a Service for the End-User", "comments": null, "journal-ref": "Future Generation Computer Systems 105 (2020) 275-286", "doi": "10.1016/j.future.2019.11.042", "report-no": null, "categories": "cs.DC cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As ML applications are becoming ever more pervasive, fully-trained systems\nare made increasingly available to a wide public, allowing end-users to submit\nqueries with their own data, and to efficiently retrieve results. With\nincreasingly sophisticated such services, a new challenge is how to scale up to\nevergrowing user bases. In this paper, we present a distributed architecture\nthat could be exploited to parallelize a typical ML system pipeline. We propose\na case study consisting of a text mining service and discuss how the method can\nbe generalized to many similar applications. We demonstrate the significance of\nthe computational gain boosted by the distributed architecture by way of an\nextensive experimental evaluation.\n", "versions": [{"version": "v1", "created": "Thu, 28 May 2020 15:22:50 GMT"}, {"version": "v2", "created": "Fri, 29 May 2020 09:13:36 GMT"}], "update_date": "2020-06-01", "authors_parsed": [["Loreti", "Daniela", ""], ["Lippi", "Marco", ""], ["Torroni", "Paolo", ""]]}, {"id": "2005.14156", "submitter": "Mohammad Sina Kiarostami", "authors": "Mohammad Sina Kiarostami and Saleh Khalaj Monfared and Mohammadreza\n  Daneshvaramoli and Ali Oliayi and Negar Yousefian and Dara Rahmati and Saeid\n  Gorgin", "title": "Unlucky Explorer: A Complete non-Overlapping Map Exploration", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.RO", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Nowadays, the field of Artificial Intelligence in Computer Games (AI in\nGames) is going to be more alluring since computer games challenge many aspects\nof AI with a wide range of problems, particularly general problems. One of\nthese kinds of problems is Exploration, which states that an unknown\nenvironment must be explored by one or several agents. In this work, we have\nfirst introduced the Maze Dash puzzle as an exploration problem where the agent\nmust find a Hamiltonian Path visiting all the cells. Then, we have investigated\nto find suitable methods by a focus on Monte-Carlo Tree Search (MCTS) and SAT\nto solve this puzzle quickly and accurately. An optimization has been applied\nto the proposed MCTS algorithm to obtain a promising result. Also, since the\nprefabricated test cases of this puzzle are not large enough to assay the\nproposed method, we have proposed and employed a technique to generate solvable\ntest cases to evaluate the approaches. Eventually, the MCTS-based method has\nbeen assessed by the auto-generated test cases and compared with our\nimplemented SAT approach that is considered a good rival. Our comparison\nindicates that the MCTS-based approach is an up-and-coming method that could\ncope with the test cases with small and medium sizes with faster run-time\ncompared to SAT. However, for certain discussed reasons, including the features\nof the problem, tree search organization, and also the approach of MCTS in the\nSimulation step, MCTS takes more time to execute in Large size scenarios.\nConsequently, we have found the bottleneck for the MCTS-based method in\nsignificant test cases that could be improved in two real-world problems.\n", "versions": [{"version": "v1", "created": "Thu, 28 May 2020 17:19:24 GMT"}], "update_date": "2020-05-29", "authors_parsed": [["Kiarostami", "Mohammad Sina", ""], ["Monfared", "Saleh Khalaj", ""], ["Daneshvaramoli", "Mohammadreza", ""], ["Oliayi", "Ali", ""], ["Yousefian", "Negar", ""], ["Rahmati", "Dara", ""], ["Gorgin", "Saeid", ""]]}, {"id": "2005.14212", "submitter": "Marc Bosch", "authors": "Ben Ortiz and Laura Kahn and Marc Bosch and Philip Bogden and Viveca\n  Pavon-Harr and Onur Savas and Ian McCulloh", "title": "Improving Community Resiliency and Emergency Response With Artificial\n  Intelligence", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  New crisis response and management approaches that incorporate the latest\ninformation technologies are essential in all phases of emergency preparedness\nand response, including the planning, response, recovery, and assessment\nphases. Accurate and timely information is as crucial as is rapid and coherent\ncoordination among the responding organizations. We are working towards a\nmultipronged emergency response tool that provide stakeholders timely access to\ncomprehensive, relevant, and reliable information. The faster emergency\npersonnel are able to analyze, disseminate and act on key information, the more\neffective and timelier their response will be and the greater the benefit to\naffected populations. Our tool consists of encoding multiple layers of open\nsource geospatial data including flood risk location, road network strength,\ninundation maps that proxy inland flooding and computer vision semantic\nsegmentation for estimating flooded areas and damaged infrastructure. These\ndata layers are combined and used as input data for machine learning algorithms\nsuch as finding the best evacuation routes before, during and after an\nemergency or providing a list of available lodging for first responders in an\nimpacted area for first. Even though our system could be used in a number of\nuse cases where people are forced from one location to another, we demonstrate\nthe feasibility of our system for the use case of Hurricane Florence in\nLumberton, North Carolina.\n", "versions": [{"version": "v1", "created": "Thu, 28 May 2020 18:05:08 GMT"}], "update_date": "2020-06-01", "authors_parsed": [["Ortiz", "Ben", ""], ["Kahn", "Laura", ""], ["Bosch", "Marc", ""], ["Bogden", "Philip", ""], ["Pavon-Harr", "Viveca", ""], ["Savas", "Onur", ""], ["McCulloh", "Ian", ""]]}, {"id": "2005.14214", "submitter": "Saikat Dutta", "authors": "Saikat Dutta", "title": "Depth-aware Blending of Smoothed Images for Bokeh Effect Generation", "comments": null, "journal-ref": "Journal of Visual Communication and Image Representation 2021", "doi": "10.1016/j.jvcir.2021.103089", "report-no": null, "categories": "cs.CV cs.AI eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bokeh effect is used in photography to capture images where the closer\nobjects look sharp and every-thing else stays out-of-focus. Bokeh photos are\ngenerally captured using Single Lens Reflex cameras using shallow\ndepth-of-field. Most of the modern smartphones can take bokeh images by\nleveraging dual rear cameras or a good auto-focus hardware. However, for\nsmartphones with single-rear camera without a good auto-focus hardware, we have\nto rely on software to generate bokeh images. This kind of system is also\nuseful to generate bokeh effect in already captured images. In this paper, an\nend-to-end deep learning framework is proposed to generate high-quality bokeh\neffect from images. The original image and different versions of smoothed\nimages are blended to generate Bokeh effect with the help of a monocular depth\nestimation network. The proposed approach is compared against a saliency\ndetection based baseline and a number of approaches proposed in AIM 2019\nChallenge on Bokeh Effect Synthesis. Extensive experiments are shown in order\nto understand different parts of the proposed algorithm. The network is\nlightweight and can process an HD image in 0.03 seconds. This approach ranked\nsecond in AIM 2019 Bokeh effect challenge-Perceptual Track.\n", "versions": [{"version": "v1", "created": "Thu, 28 May 2020 18:11:05 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Dutta", "Saikat", ""]]}, {"id": "2005.14223", "submitter": "\\\"Ozge Yal\\c{c}{\\i}n Nilay", "authors": "\u007fOzge Nilay Yalcin, Nouf Abukhodair and Steve DiPaola", "title": "Empathic AI Painter: A Computational Creativity System with Embodied\n  Conversational Interaction", "comments": "In press. NeurIPS 2019 Competition and Demonstration Track,\n  Proceedings of Machine Learning Research Vol. 123, 2020", "journal-ref": "Proceedings of the NeurIPS 2019 Competition and Demonstration\n  Track, PMLR 123:131-141, 2020", "doi": null, "report-no": null, "categories": "cs.AI cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is a growing recognition that artists use valuable ways to understand\nand work with cognitive and perceptual mechanisms to convey desired experiences\nand narrative in their created artworks (DiPaola et al., 2010; Zeki, 2001).\nThis paper documents our attempt to computationally model the creative process\nof a portrait painter, who relies on understanding human traits (i.e.,\npersonality and emotions) to inform their art. Our system includes an empathic\nconversational interaction component to capture the dominant personality\ncategory of the user and a generative AI Portraiture system that uses this\ncategorization to create a personalized stylization of the user's portrait.\nThis paper includes the description of our systems and the real-time\ninteraction results obtained during the demonstration session of the NeurIPS\n2019 Conference.\n", "versions": [{"version": "v1", "created": "Thu, 28 May 2020 18:35:42 GMT"}], "update_date": "2020-09-14", "authors_parsed": [["Yalcin", "\u007fOzge Nilay", ""], ["Abukhodair", "Nouf", ""], ["DiPaola", "Steve", ""]]}, {"id": "2005.14230", "submitter": "Nathaniel Bastian PhD", "authors": "Marc Chal\\'e, Nathaniel D. Bastian, Jeffery Weir", "title": "Algorithm Selection Framework for Cyber Attack Detection", "comments": "6 pages, 7 figures, 1 table, accepted to WiseML '20", "journal-ref": null, "doi": "10.1145/3395352.3402623", "report-no": null, "categories": "cs.CR cs.AI cs.LG stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The number of cyber threats against both wired and wireless computer systems\nand other components of the Internet of Things continues to increase annually.\nIn this work, an algorithm selection framework is employed on the NSL-KDD data\nset and a novel paradigm of machine learning taxonomy is presented. The\nframework uses a combination of user input and meta-features to select the best\nalgorithm to detect cyber attacks on a network. Performance is compared between\na rule-of-thumb strategy and a meta-learning strategy. The framework removes\nthe conjecture of the common trial-and-error algorithm selection method. The\nframework recommends five algorithms from the taxonomy. Both strategies\nrecommend a high-performing algorithm, though not the best performing. The work\ndemonstrates the close connectedness between algorithm selection and the\ntaxonomy for which it is premised.\n", "versions": [{"version": "v1", "created": "Thu, 28 May 2020 18:49:29 GMT"}], "update_date": "2020-06-01", "authors_parsed": [["Chal\u00e9", "Marc", ""], ["Bastian", "Nathaniel D.", ""], ["Weir", "Jeffery", ""]]}, {"id": "2005.14259", "submitter": "Alwyn Mathew", "authors": "Alwyn Mathew, Abhijit Roy, Jimson Mathew", "title": "Intelligent Residential Energy Management System using Deep\n  Reinforcement Learning", "comments": null, "journal-ref": null, "doi": "10.1109/JSYST.2020.2996547", "report-no": null, "categories": "eess.SP cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The rising demand for electricity and its essential nature in today's world\ncalls for intelligent home energy management (HEM) systems that can reduce\nenergy usage. This involves scheduling of loads from peak hours of the day when\nenergy consumption is at its highest to leaner off-peak periods of the day when\nenergy consumption is relatively lower thereby reducing the system's peak load\ndemand, which would consequently result in lesser energy bills, and improved\nload demand profile. This work introduces a novel way to develop a learning\nsystem that can learn from experience to shift loads from one time instance to\nanother and achieve the goal of minimizing the aggregate peak load. This paper\nproposes a Deep Reinforcement Learning (DRL) model for demand response where\nthe virtual agent learns the task like humans do. The agent gets feedback for\nevery action it takes in the environment; these feedbacks will drive the agent\nto learn about the environment and take much smarter steps later in its\nlearning stages. Our method outperformed the state of the art mixed integer\nlinear programming (MILP) for load peak reduction. The authors have also\ndesigned an agent to learn to minimize both consumers' electricity bills and\nutilities' system peak load demand simultaneously. The proposed model was\nanalyzed with loads from five different residential consumers; the proposed\nmethod increases the monthly savings of each consumer by reducing their\nelectricity bill drastically along with minimizing the peak load on the system\nwhen time shiftable loads are handled by the proposed method.\n", "versions": [{"version": "v1", "created": "Thu, 28 May 2020 19:51:22 GMT"}], "update_date": "2020-12-30", "authors_parsed": [["Mathew", "Alwyn", ""], ["Roy", "Abhijit", ""], ["Mathew", "Jimson", ""]]}, {"id": "2005.14299", "submitter": "Oskar Wysocki", "authors": "Oskar Wysocki, Malina Florea, Andre Freitas", "title": "What is SemEval evaluating? A Systematic Analysis of Evaluation\n  Campaigns in NLP", "comments": "12 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  SemEval is the primary venue in the NLP community for the proposal of new\nchallenges and for the systematic empirical evaluation of NLP systems. This\npaper provides a systematic quantitative analysis of SemEval aiming to evidence\nthe patterns of the contributions behind SemEval. By understanding the\ndistribution of task types, metrics, architectures, participation and citations\nover time we aim to answer the question on what is being evaluated by SemEval.\n", "versions": [{"version": "v1", "created": "Thu, 28 May 2020 21:17:43 GMT"}], "update_date": "2020-06-01", "authors_parsed": [["Wysocki", "Oskar", ""], ["Florea", "Malina", ""], ["Freitas", "Andre", ""]]}, {"id": "2005.14381", "submitter": "Kiattikun Chobtham", "authors": "Kiattikun Chobtham, Anthony C. Constantinou", "title": "Bayesian network structure learning with causal effects in the presence\n  of latent variables", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Latent variables may lead to spurious relationships that can be\nmisinterpreted as causal relationships. In Bayesian Networks (BNs), this\nchallenge is known as learning under causal insufficiency. Structure learning\nalgorithms that assume causal insufficiency tend to reconstruct the ancestral\ngraph of a BN, where bi-directed edges represent confounding and directed edges\nrepresent direct or ancestral relationships. This paper describes a hybrid\nstructure learning algorithm, called CCHM, which combines the constraint-based\npart of cFCI with hill-climbing score-based learning. The score-based process\nincorporates Pearl s do-calculus to measure causal effects and orientate edges\nthat would otherwise remain undirected, under the assumption the BN is a linear\nStructure Equation Model where data follow a multivariate Gaussian\ndistribution. Experiments based on both randomised and well-known networks show\nthat CCHM improves the state-of-the-art in terms of reconstructing the true\nancestral graph.\n", "versions": [{"version": "v1", "created": "Fri, 29 May 2020 04:42:28 GMT"}, {"version": "v2", "created": "Tue, 18 Aug 2020 06:17:56 GMT"}], "update_date": "2020-08-19", "authors_parsed": [["Chobtham", "Kiattikun", ""], ["Constantinou", "Anthony C.", ""]]}, {"id": "2005.14408", "submitter": "Xiao Yang", "authors": "Deepak Muralidharan, Joel Ruben Antony Moniz, Sida Gao, Xiao Yang, Lin\n  Li, Justine Kao, Stephen Pulman, Atish Kothari, Ray Shen, Yinying Pan, Vivek\n  Kaul, Mubarak Seyed Ibrahim, Gang Xiang, Nan Dun, Yidan Zhou, Andy O, Yuan\n  Zhang, Pooja Chitkara, Xuan Wang, Alkesh Patel, Kushal Tayal, Roger Zheng,\n  Peter Grasch, Jason Williams", "title": "Noise-robust Named Entity Understanding for Virtual Assistants", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Named Entity Understanding (NEU) plays an essential role in interactions\nbetween users and voice assistants, since successfully identifying entities and\ncorrectly linking them to their standard forms is crucial to understanding the\nuser's intent. NEU is a challenging task in voice assistants due to the\nambiguous nature of natural language and because noise introduced by speech\ntranscription and user errors occur frequently in spoken natural language\nqueries. In this paper, we propose an architecture with novel features that\njointly solves the recognition of named entities (a.k.a. Named Entity\nRecognition, or NER) and the resolution to their canonical forms (a.k.a. Entity\nLinking, or EL). We show that by combining NER and EL information in a joint\nreranking module, our proposed framework improves accuracy in both tasks. This\nimproved performance and the features that enable it, also lead to better\naccuracy in downstream tasks, such as domain classification and semantic\nparsing.\n", "versions": [{"version": "v1", "created": "Fri, 29 May 2020 06:14:53 GMT"}, {"version": "v2", "created": "Mon, 19 Oct 2020 20:32:55 GMT"}], "update_date": "2020-10-21", "authors_parsed": [["Muralidharan", "Deepak", ""], ["Moniz", "Joel Ruben Antony", ""], ["Gao", "Sida", ""], ["Yang", "Xiao", ""], ["Li", "Lin", ""], ["Kao", "Justine", ""], ["Pulman", "Stephen", ""], ["Kothari", "Atish", ""], ["Shen", "Ray", ""], ["Pan", "Yinying", ""], ["Kaul", "Vivek", ""], ["Ibrahim", "Mubarak Seyed", ""], ["Xiang", "Gang", ""], ["Dun", "Nan", ""], ["Zhou", "Yidan", ""], ["O", "Andy", ""], ["Zhang", "Yuan", ""], ["Chitkara", "Pooja", ""], ["Wang", "Xuan", ""], ["Patel", "Alkesh", ""], ["Tayal", "Kushal", ""], ["Zheng", "Roger", ""], ["Grasch", "Peter", ""], ["Williams", "Jason", ""]]}, {"id": "2005.14410", "submitter": "Niklas K\\\"uhl", "authors": "Lucia Schuler and Somaya Jamil and Niklas K\\\"uhl", "title": "AI-based Resource Allocation: Reinforcement Learning for Adaptive\n  Auto-scaling in Serverless Environments", "comments": "8 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Serverless computing has emerged as a compelling new paradigm of cloud\ncomputing models in recent years. It promises the user services at large scale\nand low cost while eliminating the need for infrastructure management. On cloud\nprovider side, flexible resource management is required to meet fluctuating\ndemand. It can be enabled through automated provisioning and deprovisioning of\nresources. A common approach among both commercial and open source serverless\ncomputing platforms is workload-based auto-scaling, where a designated\nalgorithm scales instances according to the number of incoming requests. In the\nrecently evolving serverless framework Knative a request-based policy is\nproposed, where the algorithm scales resources by a configured maximum number\nof requests that can be processed in parallel per instance, the so-called\nconcurrency. As we show in a baseline experiment, this predefined concurrency\nlevel can strongly influence the performance of a serverless application.\nHowever, identifying the concurrency configuration that yields the highest\npossible quality of service is a challenging task due to various factors, e.g.\nvarying workload and complex infrastructure characteristics, influencing\nthroughput and latency. While there has been considerable research into\nintelligent techniques for optimizing auto-scaling for virtual machine\nprovisioning, this topic has not yet been discussed in the area of serverless\ncomputing. For this reason, we investigate the applicability of a reinforcement\nlearning approach, which has been proven on dynamic virtual machine\nprovisioning, to request-based auto-scaling in a serverless framework. Our\nresults show that within a limited number of iterations our proposed model\nlearns an effective scaling policy per workload, improving the performance\ncompared to the default auto-scaling configuration.\n", "versions": [{"version": "v1", "created": "Fri, 29 May 2020 06:18:39 GMT"}], "update_date": "2020-06-01", "authors_parsed": [["Schuler", "Lucia", ""], ["Jamil", "Somaya", ""], ["K\u00fchl", "Niklas", ""]]}, {"id": "2005.14501", "submitter": "Kevin Fauvel", "authors": "Kevin Fauvel, V\\'eronique Masson, \\'Elisa Fromont", "title": "A Performance-Explainability Framework to Benchmark Machine Learning\n  Methods: Application to Multivariate Time Series Classifiers", "comments": "In Proceedings of the IJCAI-PRICAI 2020 Workshop on Explainable\n  Artificial Intelligence. An example of this framework in use is available in\n  arXiv:2005.03645", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Our research aims to propose a new performance-explainability analytical\nframework to assess and benchmark machine learning methods. The framework\ndetails a set of characteristics that systematize the\nperformance-explainability assessment of existing machine learning methods. In\norder to illustrate the use of the framework, we apply it to benchmark the\ncurrent state-of-the-art multivariate time series classifiers.\n", "versions": [{"version": "v1", "created": "Fri, 29 May 2020 11:08:31 GMT"}, {"version": "v2", "created": "Sat, 8 Aug 2020 10:49:05 GMT"}, {"version": "v3", "created": "Mon, 24 Aug 2020 06:45:12 GMT"}, {"version": "v4", "created": "Thu, 17 Dec 2020 10:44:26 GMT"}, {"version": "v5", "created": "Fri, 18 Dec 2020 17:29:31 GMT"}], "update_date": "2021-01-11", "authors_parsed": [["Fauvel", "Kevin", ""], ["Masson", "V\u00e9ronique", ""], ["Fromont", "\u00c9lisa", ""]]}, {"id": "2005.14549", "submitter": "Zachary Sunberg", "authors": "Zachary Sunberg and Mykel Kochenderfer", "title": "Improving Automated Driving through Planning with Human Internal States", "comments": "Preprint before submission to IEEE Transactions on Intelligent\n  Transportation Systems. arXiv admin note: text overlap with arXiv:1702.00858", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work examines the hypothesis that partially observable Markov decision\nprocess (POMDP) planning with human driver internal states can significantly\nimprove both safety and efficiency in autonomous freeway driving. We evaluate\nthis hypothesis in a simulated scenario where an autonomous car must safely\nperform three lane changes in rapid succession. Approximate POMDP solutions are\nobtained through the partially observable Monte Carlo planning with observation\nwidening (POMCPOW) algorithm. This approach outperforms over-confident and\nconservative MDP baselines and matches or outperforms QMDP. Relative to the MDP\nbaselines, POMCPOW typically cuts the rate of unsafe situations in half or\nincreases the success rate by 50%.\n", "versions": [{"version": "v1", "created": "Thu, 28 May 2020 03:16:53 GMT"}], "update_date": "2020-06-01", "authors_parsed": [["Sunberg", "Zachary", ""], ["Kochenderfer", "Mykel", ""]]}, {"id": "2005.14601", "submitter": "Jingfan Chen", "authors": "Jingfan Chen, Guanghui Zhu, Chunfeng Yuan, Yihua Huang", "title": "Semi-supervised Embedding Learning for High-dimensional Bayesian\n  Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian optimization is a broadly applied methodology to optimize the\nexpensive black-box function. Despite its success, it still faces the challenge\nfrom the high-dimensional search space. To alleviate this problem, we propose a\nnovel Bayesian optimization framework (termed SILBO), which finds a\nlow-dimensional space to perform Bayesian optimization iteratively through\nsemi-supervised dimension reduction. SILBO incorporates both labeled points and\nunlabeled points acquired from the acquisition function to guide the embedding\nspace learning. To accelerate the learning procedure, we present a randomized\nmethod for generating the projection matrix. Furthermore, to map from the\nlow-dimensional space to the high-dimensional original space, we propose two\nmapping strategies: $\\text{SILBO}_{FZ}$ and $\\text{SILBO}_{FX}$ according to\nthe evaluation overhead of the objective function. Experimental results on both\nsynthetic function and hyperparameter optimization tasks demonstrate that SILBO\noutperforms the existing state-of-the-art high-dimensional Bayesian\noptimization methods.\n", "versions": [{"version": "v1", "created": "Fri, 29 May 2020 14:37:12 GMT"}, {"version": "v2", "created": "Fri, 9 Oct 2020 11:48:16 GMT"}, {"version": "v3", "created": "Mon, 19 Oct 2020 05:36:39 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["Chen", "Jingfan", ""], ["Zhu", "Guanghui", ""], ["Yuan", "Chunfeng", ""], ["Huang", "Yihua", ""]]}, {"id": "2005.14621", "submitter": "Ibrahim Alabdulmohsin", "authors": "Ibrahim Alabdulmohsin", "title": "Fair Classification via Unconstrained Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Achieving the Bayes optimal binary classification rule subject to group\nfairness constraints is known to be reducible, in some cases, to learning a\ngroup-wise thresholding rule over the Bayes regressor. In this paper, we extend\nthis result by proving that, in a broader setting, the Bayes optimal fair\nlearning rule remains a group-wise thresholding rule over the Bayes regressor\nbut with a (possible) randomization at the thresholds. This provides a stronger\njustification to the post-processing approach in fair classification, in which\n(1) a predictor is learned first, after which (2) its output is adjusted to\nremove bias. We show how the post-processing rule in this two-stage approach\ncan be learned quite efficiently by solving an unconstrained optimization\nproblem. The proposed algorithm can be applied to any black-box machine\nlearning model, such as deep neural networks, random forests and support vector\nmachines. In addition, it can accommodate many fairness criteria that have been\npreviously proposed in the literature, such as equalized odds and statistical\nparity. We prove that the algorithm is Bayes consistent and motivate it,\nfurthermore, via an impossibility result that quantifies the tradeoff between\naccuracy and fairness across multiple demographic groups. Finally, we conclude\nby validating the algorithm on the Adult benchmark dataset.\n", "versions": [{"version": "v1", "created": "Thu, 21 May 2020 11:29:05 GMT"}], "update_date": "2020-06-01", "authors_parsed": [["Alabdulmohsin", "Ibrahim", ""]]}, {"id": "2005.14656", "submitter": "Takazumi Matsumoto", "authors": "Takazumi Matsumoto and Jun Tani", "title": "Goal-Directed Planning for Habituated Agents by Active Inference Using a\n  Variational Recurrent Neural Network", "comments": "30 pages, 19 figures", "journal-ref": "Entropy 2020, 22, 564", "doi": "10.3390/e22050564", "report-no": null, "categories": "cs.RO cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  It is crucial to ask how agents can achieve goals by generating action plans\nusing only partial models of the world acquired through habituated\nsensory-motor experiences. Although many existing robotics studies use a\nforward model framework, there are generalization issues with high degrees of\nfreedom. The current study shows that the predictive coding (PC) and active\ninference (AIF) frameworks, which employ a generative model, can develop better\ngeneralization by learning a prior distribution in a low dimensional latent\nstate space representing probabilistic structures extracted from well\nhabituated sensory-motor trajectories. In our proposed model, learning is\ncarried out by inferring optimal latent variables as well as synaptic weights\nfor maximizing the evidence lower bound, while goal-directed planning is\naccomplished by inferring latent variables for maximizing the estimated lower\nbound. Our proposed model was evaluated with both simple and complex robotic\ntasks in simulation, which demonstrated sufficient generalization in learning\nwith limited training data by setting an intermediate value for a\nregularization coefficient. Furthermore, comparative simulation results show\nthat the proposed model outperforms a conventional forward model in\ngoal-directed planning, due to the learned prior confining the search of motor\nplans within the range of habituated trajectories.\n", "versions": [{"version": "v1", "created": "Wed, 27 May 2020 06:43:59 GMT"}], "update_date": "2020-06-01", "authors_parsed": [["Matsumoto", "Takazumi", ""], ["Tani", "Jun", ""]]}, {"id": "2005.14662", "submitter": "Yusuke Takimoto", "authors": "Yusuke Takimoto, Yosuke Fukuchi, Shoya Matsumori, Michita Imai", "title": "SLAM-Inspired Simultaneous Contextualization and Interpreting for\n  Incremental Conversation Sentences", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distributed representation of words has improved the performance for many\nnatural language tasks. In many methods, however, only one meaning is\nconsidered for one label of a word, and multiple meanings of polysemous words\ndepending on the context are rarely handled. Although research works have dealt\nwith polysemous words, they determine the meanings of such words according to a\nbatch of large documents. Hence, there are two problems with applying these\nmethods to sequential sentences, as in a conversation that contains ambiguous\nexpressions. The first problem is that the methods cannot sequentially deal\nwith the interdependence between context and word interpretation, in which\ncontext is decided by word interpretations and the word interpretations are\ndecided by the context. Context estimation must thus be performed in parallel\nto pursue multiple interpretations. The second problem is that the previous\nmethods use large-scale sets of sentences for offline learning of new\ninterpretations, and the steps of learning and inference are clearly separated.\nSuch methods using offline learning cannot obtain new interpretations during a\nconversation. Hence, to dynamically estimate the conversation context and\ninterpretations of polysemous words in sequential sentences, we propose a\nmethod of Simultaneous Contextualization And INterpreting (SCAIN) based on the\ntraditional Simultaneous Localization And Mapping (SLAM) algorithm. By using\nthe SCAIN algorithm, we can sequentially optimize the interdependence between\ncontext and word interpretation while obtaining new interpretations online. For\nexperimental evaluation, we created two datasets: one from Wikipedia's\ndisambiguation pages and the other from real conversations. For both datasets,\nthe results confirmed that SCAIN could effectively achieve sequential\noptimization of the interdependence and acquisition of new interpretations.\n", "versions": [{"version": "v1", "created": "Fri, 29 May 2020 16:40:27 GMT"}], "update_date": "2020-06-01", "authors_parsed": [["Takimoto", "Yusuke", ""], ["Fukuchi", "Yosuke", ""], ["Matsumori", "Shoya", ""], ["Imai", "Michita", ""]]}, {"id": "2005.14664", "submitter": "Josef Urban", "authors": "Josef Urban and Jan Jakub\\r{u}v", "title": "First Neural Conjecturing Datasets and Experiments", "comments": "Accepted to CICM 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.LO cs.NE cs.SC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe several datasets and first experiments with creating conjectures\nby neural methods. The datasets are based on the Mizar Mathematical Library\nprocessed in several forms and the problems extracted from it by the MPTP\nsystem and proved by the E prover using the ENIGMA guidance. The conjecturing\nexperiments use the Transformer architecture and in particular its GPT-2\nimplementation.\n", "versions": [{"version": "v1", "created": "Fri, 29 May 2020 16:46:25 GMT"}], "update_date": "2020-06-01", "authors_parsed": [["Urban", "Josef", ""], ["Jakub\u016fv", "Jan", ""]]}, {"id": "2005.14684", "submitter": "Fei Shen", "authors": "Fei Shen, Jianqing Zhu, Xiaobin Zhu, Yi Xie, and Jingchang Huang", "title": "Exploring Spatial Significance via Hybrid Pyramidal Graph Network for\n  Vehicle Re-identification", "comments": null, "journal-ref": "IEEE Transactions on Intelligent Transportation Systems, 2021", "doi": "10.1109/TITS.2021.3086142", "report-no": "1-12", "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing vehicle re-identification methods commonly use spatial pooling\noperations to aggregate feature maps extracted via off-the-shelf backbone\nnetworks. They ignore exploring the spatial significance of feature maps,\neventually degrading the vehicle re-identification performance. In this paper,\nfirstly, an innovative spatial graph network (SGN) is proposed to elaborately\nexplore the spatial significance of feature maps. The SGN stacks multiple\nspatial graphs (SGs). Each SG assigns feature map's elements as nodes and\nutilizes spatial neighborhood relationships to determine edges among nodes.\nDuring the SGN's propagation, each node and its spatial neighbors on an SG are\naggregated to the next SG. On the next SG, each aggregated node is re-weighted\nwith a learnable parameter to find the significance at the corresponding\nlocation. Secondly, a novel pyramidal graph network (PGN) is designed to\ncomprehensively explore the spatial significance of feature maps at multiple\nscales. The PGN organizes multiple SGNs in a pyramidal manner and makes each\nSGN handles feature maps of a specific scale. Finally, a hybrid pyramidal graph\nnetwork (HPGN) is developed by embedding the PGN behind a ResNet-50 based\nbackbone network. Extensive experiments on three large scale vehicle databases\n(i.e., VeRi776, VehicleID, and VeRi-Wild) demonstrate that the proposed HPGN is\nsuperior to state-of-the-art vehicle re-identification approaches.\n", "versions": [{"version": "v1", "created": "Fri, 29 May 2020 17:21:12 GMT"}, {"version": "v2", "created": "Fri, 5 Jun 2020 02:23:37 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Shen", "Fei", ""], ["Zhu", "Jianqing", ""], ["Zhu", "Xiaobin", ""], ["Xie", "Yi", ""], ["Huang", "Jingchang", ""]]}]