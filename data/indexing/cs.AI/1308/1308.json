[{"id": "1308.0183", "submitter": "Patrick Prosser", "authors": "Chris Unsworth and Patrick Prosser", "title": "An n-ary Constraint for the Stable Marriage Problem", "comments": "7 pages. The Fifth Workshop on Modelling and Solving Problems with\n  Constraints, held at the 19th International Joint Conference on Artificial\n  Intelligence (IJCAI 2005)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an n-ary constraint for the stable marriage problem. This\nconstraint acts between two sets of integer variables where the domains of\nthose variables represent preferences. Our constraint enforces stability and\ndisallows bigamy. For a stable marriage instance with $n$ men and $n$ women we\nrequire only one of these constraints, and the complexity of enforcing\narc-consistency is $O(n^2)$ which is optimal in the size of input. Our\ncomputational studies show that our n-ary constraint is significantly faster\nand more space efficient than the encodings presented in \\cite{cp01}. We also\nintroduce a new problem to the constraint community, the sex-equal stable\nmarriage problem.\n", "versions": [{"version": "v1", "created": "Thu, 1 Aug 2013 12:56:47 GMT"}], "update_date": "2013-08-02", "authors_parsed": [["Unsworth", "Chris", ""], ["Prosser", "Patrick", ""]]}, {"id": "1308.0187", "submitter": "Stephen Pasteris", "authors": "Stephen Pasteris", "title": "A Time and Space Efficient Junction Tree Architecture", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The junction tree algorithm is a way of computing marginals of boolean\nmultivariate probability distributions that factorise over sets of random\nvariables. The junction tree algorithm first constructs a tree called a\njunction tree who's vertices are sets of random variables. The algorithm then\nperforms a generalised version of belief propagation on the junction tree. The\nShafer-Shenoy and Hugin architectures are two ways to perform this belief\npropagation that tradeoff time and space complexities in different ways: Hugin\npropagation is at least as fast as Shafer-Shenoy propagation and in the cases\nthat we have large vertices of high degree is significantly faster. However,\nthis speed increase comes at the cost of an increased space complexity. This\npaper first introduces a simple novel architecture, ARCH-1, which has the best\nof both worlds: the speed of Hugin propagation and the low space requirements\nof Shafer-Shenoy propagation. A more complicated novel architecture, ARCH-2, is\nthen introduced which has, up to a factor only linear in the maximum\ncardinality of any vertex, time and space complexities at least as good as\nARCH-1 and in the cases that we have large vertices of high degree is\nsignificantly faster than ARCH-1.\n", "versions": [{"version": "v1", "created": "Wed, 31 Jul 2013 16:56:59 GMT"}, {"version": "v2", "created": "Fri, 23 Aug 2013 19:58:11 GMT"}, {"version": "v3", "created": "Thu, 12 Sep 2013 18:52:49 GMT"}, {"version": "v4", "created": "Sun, 27 Oct 2013 11:00:46 GMT"}, {"version": "v5", "created": "Mon, 11 Nov 2013 20:51:14 GMT"}, {"version": "v6", "created": "Fri, 15 Nov 2013 20:55:47 GMT"}, {"version": "v7", "created": "Mon, 25 Nov 2013 20:30:34 GMT"}, {"version": "v8", "created": "Thu, 13 Mar 2014 14:52:01 GMT"}, {"version": "v9", "created": "Tue, 23 Dec 2014 20:21:52 GMT"}], "update_date": "2014-12-24", "authors_parsed": [["Pasteris", "Stephen", ""]]}, {"id": "1308.0227", "submitter": "Roberto Amadini", "authors": "Roberto Amadini and Maurizio Gabbrielli and Jacopo Mauro", "title": "An Enhanced Features Extractor for a Portfolio of Constraint Solvers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent research has shown that a single arbitrarily efficient solver can be\nsignificantly outperformed by a portfolio of possibly slower on-average\nsolvers. The solver selection is usually done by means of (un)supervised\nlearning techniques which exploit features extracted from the problem\nspecification. In this paper we present an useful and flexible framework that\nis able to extract an extensive set of features from a Constraint\n(Satisfaction/Optimization) Problem defined in possibly different modeling\nlanguages: MiniZinc, FlatZinc or XCSP. We also report some empirical results\nshowing that the performances that can be obtained using these features are\neffective and competitive with state of the art CSP portfolio techniques.\n", "versions": [{"version": "v1", "created": "Thu, 1 Aug 2013 14:40:14 GMT"}, {"version": "v2", "created": "Thu, 19 Sep 2013 14:53:58 GMT"}, {"version": "v3", "created": "Wed, 2 Oct 2013 07:33:15 GMT"}, {"version": "v4", "created": "Fri, 22 Nov 2013 00:53:57 GMT"}, {"version": "v5", "created": "Thu, 19 Dec 2013 23:57:50 GMT"}, {"version": "v6", "created": "Sat, 29 Mar 2014 07:54:42 GMT"}, {"version": "v7", "created": "Wed, 2 Apr 2014 03:02:51 GMT"}], "update_date": "2014-04-03", "authors_parsed": [["Amadini", "Roberto", ""], ["Gabbrielli", "Maurizio", ""], ["Mauro", "Jacopo", ""]]}, {"id": "1308.0299", "submitter": "Leonardo Borba", "authors": "Leonardo Borba and Marcus Ritt", "title": "Exact and Heuristic Methods for the Assembly Line Worker Assignment and\n  Balancing Problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.DM cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In traditional assembly lines, it is reasonable to assume that task execution\ntimes are the same for each worker. However, in sheltered work centres for\ndisabled this assumption is not valid: some workers may execute some tasks\nconsiderably slower or even be incapable of executing them. Worker\nheterogeneity leads to a problem called the assembly line worker assignment and\nbalancing problem (ALWABP). For a fixed number of workers the problem is to\nmaximize the production rate of an assembly line by assigning workers to\nstations and tasks to workers, while satisfying precedence constraints between\nthe tasks. This paper introduces new heuristic and exact methods to solve this\nproblem. We present a new MIP model, propose a novel heuristic algorithm based\non beam search, as well as a task-oriented branch-and-bound procedure which\nuses new reduction rules and lower bounds for solving the problem. Extensive\ncomputational tests on a large set of instances show that these methods are\neffective and improve over existing ones.\n", "versions": [{"version": "v1", "created": "Thu, 1 Aug 2013 18:49:07 GMT"}], "update_date": "2013-08-05", "authors_parsed": [["Borba", "Leonardo", ""], ["Ritt", "Marcus", ""]]}, {"id": "1308.0356", "submitter": "Shervan Fekri ershad", "authors": "Shervan Fekri-Ershad, Hadi Tajalizadeh, Shahram Jafari", "title": "Design and Development of an Expert System to Help Head of University\n  Departments", "comments": "4 pages, 2 figures, 2 tables", "journal-ref": "International Journal of Science and Modern Engineering (IJISME),\n  ISSN: 2319-6386, Volume-1, Issue-2, January 2013", "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  One of the basic tasks which is responded for head of each university\ndepartment, is employing lecturers based on some default factors such as\nexperience, evidences, qualifies and etc. In this respect, to help the heads,\nsome automatic systems have been proposed until now using machine learning\nmethods, decision support systems (DSS) and etc. According to advantages and\ndisadvantages of the previous methods, a full automatic system is designed in\nthis paper using expert systems. The proposed system is included two main\nsteps. In the first one, the human expert's knowledge is designed as decision\ntrees. The second step is included an expert system which is evaluated using\nextracted rules of these decision trees. Also, to improve the quality of the\nproposed system, a majority voting algorithm is proposed as post processing\nstep to choose the best lecturer which satisfied more expert's decision trees\nfor each course. The results are shown that the designed system average\naccuracy is 78.88. Low computational complexity, simplicity to program and are\nsome of other advantages of the proposed system.\n", "versions": [{"version": "v1", "created": "Thu, 1 Aug 2013 21:04:07 GMT"}], "update_date": "2013-08-05", "authors_parsed": [["Fekri-Ershad", "Shervan", ""], ["Tajalizadeh", "Hadi", ""], ["Jafari", "Shahram", ""]]}, {"id": "1308.0689", "submitter": "Johannes Borgstr", "authors": "Johannes Borgstr\\\"om (Uppsala University, Uppsala, Sweden), Andrew D\n  Gordon (Microsoft Research, Cambridge, UK), Michael Greenberg (University of\n  Pennsylvania, Philadelphia, PA, USA), James Margetson (Microsoft Research,\n  Cambridge, UK), Jurgen Van Gael (Microsoft FUSE Labs, Cambridge, UK)", "title": "Measure Transformer Semantics for Bayesian Machine Learning", "comments": "An abridged version of this paper appears in the proceedings of the\n  20th European Symposium on Programming (ESOP'11), part of ETAPS 2011", "journal-ref": "Logical Methods in Computer Science, Volume 9, Issue 3 (September\n  9, 2013) lmcs:815", "doi": "10.2168/LMCS-9(3:11)2013", "report-no": null, "categories": "cs.LO cs.AI cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Bayesian approach to machine learning amounts to computing posterior\ndistributions of random variables from a probabilistic model of how the\nvariables are related (that is, a prior distribution) and a set of observations\nof variables. There is a trend in machine learning towards expressing Bayesian\nmodels as probabilistic programs. As a foundation for this kind of programming,\nwe propose a core functional calculus with primitives for sampling prior\ndistributions and observing variables. We define measure-transformer\ncombinators inspired by theorems in measure theory, and use these to give a\nrigorous semantics to our core calculus. The original features of our semantics\ninclude its support for discrete, continuous, and hybrid measures, and, in\nparticular, for observations of zero-probability events. We compile our core\nlanguage to a small imperative language that is processed by an existing\ninference engine for factor graphs, which are data structures that enable many\nefficient inference algorithms. This allows efficient approximate inference of\nposterior marginal distributions, treating thousands of observations per second\nfor large instances of realistic models.\n", "versions": [{"version": "v1", "created": "Sat, 3 Aug 2013 12:28:23 GMT"}, {"version": "v2", "created": "Fri, 6 Sep 2013 11:45:21 GMT"}, {"version": "v3", "created": "Fri, 20 Sep 2013 18:48:34 GMT"}, {"version": "v4", "created": "Mon, 23 Sep 2013 08:01:06 GMT"}], "update_date": "2015-07-01", "authors_parsed": [["Borgstr\u00f6m", "Johannes", "", "Uppsala University, Uppsala, Sweden"], ["Gordon", "Andrew D", "", "Microsoft Research, Cambridge, UK"], ["Greenberg", "Michael", "", "University of\n  Pennsylvania, Philadelphia, PA, USA"], ["Margetson", "James", "", "Microsoft Research,\n  Cambridge, UK"], ["Van Gael", "Jurgen", "", "Microsoft FUSE Labs, Cambridge, UK"]]}, {"id": "1308.0702", "submitter": "Sergey Rodionov", "authors": "Alexey Potapov, Sergey Rodionov", "title": "Universal Empathy and Ethical Bias for Artificial General Intelligence", "comments": "AGI Impacts conference 2012 paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Rational agents are usually built to maximize rewards. However, AGI agents\ncan find undesirable ways of maximizing any prior reward function. Therefore\nvalue learning is crucial for safe AGI. We assume that generalized states of\nthe world are valuable - not rewards themselves, and propose an extension of\nAIXI, in which rewards are used only to bootstrap hierarchical value learning.\nThe modified AIXI agent is considered in the multi-agent environment, where\nother agents can be either humans or other \"mature\" agents, which values should\nbe revealed and adopted by the \"infant\" AGI agent. General framework for\ndesigning such empathic agent with ethical bias is proposed also as an\nextension of the universal intelligence model. Moreover, we perform experiments\nin the simple Markov environment, which demonstrate feasibility of our approach\nto value learning in safe AGI.\n", "versions": [{"version": "v1", "created": "Sat, 3 Aug 2013 14:40:36 GMT"}], "update_date": "2013-08-06", "authors_parsed": [["Potapov", "Alexey", ""], ["Rodionov", "Sergey", ""]]}, {"id": "1308.0725", "submitter": "D P Acharjya Ph.D", "authors": "Debi Prasanna Acharjya and Debarati Bhattacharjee", "title": "A Rough Computing based Performance Evaluation Approach for Educational\n  Institutions", "comments": "18 pages", "journal-ref": "International Journal of Software Engineering and Its\n  Applications, Vol. 7, No. 4, July, 2013", "doi": null, "report-no": null, "categories": "cs.CY cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Performance evaluation of various organizations especially educational\ninstitutions is a very important area of research and needs to be cultivated\nmore. In this paper, we propose a performance evaluation for educational\ninstitutions using rough set on fuzzy approximation spaces with ordering rules\nand information entropy. In order to measure the performance of educational\ninstitutions, we construct an evaluation index system. Rough set on fuzzy\napproximation spaces with ordering is applied to explore the evaluation index\ndata of each level. Furthermore, the concept of information entropy is used to\ndetermine the weighting coefficients of evaluation indexes. Also, we find the\nmost important indexes that influence the weighting coefficients. The proposed\napproach is validated and shows the practical viability. Moreover, the proposed\napproach can be applicable to any organizations.\n", "versions": [{"version": "v1", "created": "Sat, 3 Aug 2013 17:14:02 GMT"}], "update_date": "2013-08-06", "authors_parsed": [["Acharjya", "Debi Prasanna", ""], ["Bhattacharjee", "Debarati", ""]]}, {"id": "1308.0761", "submitter": "Alexander Semenov", "authors": "Alexander Semenov, Oleg Zaikin", "title": "On estimating total time to solve SAT in distributed computing\n  environments: Application to the SAT@home project", "comments": "This paper was submitted to SAT-2013 conference. Its materials were\n  reported in a poster session (the paper in its full variant was not\n  accepted). 16 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CR cs.DC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a method to estimate the total time required to solve SAT\nin distributed environments via partitioning approach. It is based on the\nobservation that for some simple forms of problem partitioning one can use the\nMonte Carlo approach to estimate the time required to solve an original\nproblem. The method proposed is based on an algorithm for searching for\npartitioning with an optimal solving time estimation. We applied this method to\nestimate the time required to perform logical cryptanalysis of the widely known\nstream ciphers A5/1 and Bivium. The paper also describes a volunteer computing\nproject SAT@home aimed at solving hard combinatorial problems reduced to SAT.\nIn this project during several months there were solved 10 problems of logical\ncryptanalysis of the A5/1 cipher thatcould not be solved using known rainbow\ntables.\n", "versions": [{"version": "v1", "created": "Sun, 4 Aug 2013 00:30:09 GMT"}], "update_date": "2013-08-06", "authors_parsed": [["Semenov", "Alexander", ""], ["Zaikin", "Oleg", ""]]}, {"id": "1308.0807", "submitter": "Matthias Thimm", "authors": "Matthias Thimm, Gabriele Kern-Isberner", "title": "Stratified Labelings for Abstract Argumentation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce stratified labelings as a novel semantical approach to abstract\nargumentation frameworks. Compared to standard labelings, stratified labelings\nprovide a more fine-grained assessment of the controversiality of arguments\nusing ranks instead of the usual labels in, out, and undecided. We relate the\nframework of stratified labelings to conditional logic and, in particular, to\nthe System Z ranking functions.\n", "versions": [{"version": "v1", "created": "Sun, 4 Aug 2013 13:08:50 GMT"}], "update_date": "2013-08-06", "authors_parsed": [["Thimm", "Matthias", ""], ["Kern-Isberner", "Gabriele", ""]]}, {"id": "1308.1262", "submitter": "Eraldo Marinho", "authors": "Eraldo Pereira Marinho", "title": "Pattern recognition issues on anisotropic smoothed particle\n  hydrodynamics", "comments": "Submitted to the International Conference on Mathematical Modeling in\n  Physical Sciences - 2013", "journal-ref": "2014 J. Phys.: Conf. Ser. 490 012063", "doi": "10.1088/1742-6596/490/1/012063", "report-no": null, "categories": "cs.AI cs.CG physics.comp-ph", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  This is a preliminary theoretical discussion on the computational\nrequirements of the state of the art smoothed particle hydrodynamics (SPH) from\nthe optics of pattern recognition and artificial intelligence. It is pointed\nout in the present paper that, when including anisotropy detection to improve\nresolution on shock layer, SPH is a very peculiar case of unsupervised machine\nlearning. On the other hand, the free particle nature of SPH opens an\nopportunity for artificial intelligence to study particles as agents acting in\na collaborative framework in which the timed outcomes of a fluid simulation\nforms a large knowledge base, which might be very attractive in computational\nastrophysics phenomenological problems like self-propagating star formation.\n", "versions": [{"version": "v1", "created": "Tue, 6 Aug 2013 13:04:28 GMT"}], "update_date": "2014-03-31", "authors_parsed": [["Marinho", "Eraldo Pereira", ""]]}, {"id": "1308.1484", "submitter": "Alireza Rezvanian", "authors": "Somayeh Nabizadeh, Alireza Rezvanian, Mohammd Reza Meybodi", "title": "A Multi-Swarm Cellular PSO based on Clonal Selection Algorithm in\n  Dynamic Environments", "comments": "5 pages, 3 figures, conference paper", "journal-ref": "2012 International Conference on Informatics, Electronics & Vision\n  (ICIEV 2012) 482-486", "doi": "10.1109/ICIEV.2012.6317524", "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many real-world problems are dynamic optimization problems. In this case, the\noptima in the environment change dynamically. Therefore, traditional\noptimization algorithms disable to track and find optima. In this paper, a new\nmulti-swarm cellular particle swarm optimization based on clonal selection\nalgorithm (CPSOC) is proposed for dynamic environments. In the proposed\nalgorithm, the search space is partitioned into cells by a cellular automaton.\nClustered particles in each cell, which make a sub-swarm, are evolved by the\nparticle swarm optimization and clonal selection algorithm. Experimental\nresults on Moving Peaks Benchmark demonstrate the superiority of the CPSOC its\npopular methods.\n", "versions": [{"version": "v1", "created": "Wed, 7 Aug 2013 05:46:55 GMT"}], "update_date": "2013-08-08", "authors_parsed": [["Nabizadeh", "Somayeh", ""], ["Rezvanian", "Alireza", ""], ["Meybodi", "Mohammd Reza", ""]]}, {"id": "1308.1603", "submitter": "Dietmar Volz", "authors": "Dietmar Volz", "title": "A Note on Topology Preservation in Classification, and the Construction\n  of a Universal Neuron Grid", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI nlin.AO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It will be shown that according to theorems of K. Menger, every neuron grid\nif identified with a curve is able to preserve the adopted qualitative\nstructure of a data space. Furthermore, if this identification is made, the\nneuron grid structure can always be mapped to a subset of a universal neuron\ngrid which is constructable in three space dimensions. Conclusions will be\ndrawn for established neuron grid types as well as neural fields.\n", "versions": [{"version": "v1", "created": "Wed, 7 Aug 2013 15:29:09 GMT"}, {"version": "v2", "created": "Thu, 8 Aug 2013 06:14:59 GMT"}, {"version": "v3", "created": "Mon, 22 Jan 2018 12:05:48 GMT"}, {"version": "v4", "created": "Thu, 1 Feb 2018 07:45:48 GMT"}], "update_date": "2018-02-02", "authors_parsed": [["Volz", "Dietmar", ""]]}, {"id": "1308.2116", "submitter": "Daniel Kuehlwein", "authors": "Daniel K\\\"uhlwein and Josef Urban", "title": "MaLeS: A Framework for Automatic Tuning of Automated Theorem Provers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  MaLeS is an automatic tuning framework for automated theorem provers. It\nprovides solutions for both the strategy finding as well as the strategy\nscheduling problem. This paper describes the tool and the methods used in it,\nand evaluates its performance on three automated theorem provers: E, LEO-II and\nSatallax. An evaluation on a subset of the TPTP library problems shows that on\naverage a MaLeS-tuned prover solves 8.67% more problems than the prover with\nits default settings.\n", "versions": [{"version": "v1", "created": "Fri, 9 Aug 2013 13:08:33 GMT"}, {"version": "v2", "created": "Mon, 12 Aug 2013 12:05:11 GMT"}, {"version": "v3", "created": "Sun, 1 Jun 2014 13:38:59 GMT"}], "update_date": "2014-06-03", "authors_parsed": [["K\u00fchlwein", "Daniel", ""], ["Urban", "Josef", ""]]}, {"id": "1308.2119", "submitter": "Mark Keane", "authors": "Mark Keane", "title": "Deconstructing analogy", "comments": "Published Chapter in Book from Conference; CogSc-12: ILCLI\n  International Workshop on Cognitive Science. Universidad del Pais Vasco\n  Press: San Sebastian, Spain. 2012", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Analogy has been shown to be important in many key cognitive abilities,\nincluding learning, problem solving, creativity and language change. For\ncognitive models of analogy, the fundamental computational question is how its\ninherent complexity (its NP-hardness) is solved by the human cognitive system.\nIndeed, different models of analogical processing can be categorized by the\nsimplification strategies they adopt to make this computational problem more\ntractable. In this paper, I deconstruct several of these models in terms of the\nsimplification-strategies they use; a deconstruction that provides some\ninteresting perspectives on the relative differences between them. Later, I\nconsider whether any of these computational simplifications reflect the actual\nstrategies used by people and sketch a new cognitive model that tries to\npresent a closer fit to the psychological evidence.\n", "versions": [{"version": "v1", "created": "Fri, 9 Aug 2013 13:26:57 GMT"}], "update_date": "2013-08-12", "authors_parsed": [["Keane", "Mark", ""]]}, {"id": "1308.2124", "submitter": "Alexander V Terekhov", "authors": "Alexander V. Terekhov and J. Kevin O'Regan", "title": "Space as an invention of biological organisms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The question of the nature of space around us has occupied thinkers since the\ndawn of humanity, with scientists and philosophers today implicitly assuming\nthat space is something that exists objectively. Here we show that this does\nnot have to be the case: the notion of space could emerge when biological\norganisms seek an economic representation of their sensorimotor flow. The\nemergence of spatial notions does not necessitate the existence of real\nphysical space, but only requires the presence of sensorimotor invariants\ncalled `compensable' sensory changes. We show mathematically and then in\nsimulations that na\\\"ive agents making no assumptions about the existence of\nspace are able to learn these invariants and to build the abstract notion that\nphysicists call rigid displacement, which is independent of what is being\ndisplaced. Rigid displacements may underly perception of space as an unchanging\nmedium within which objects are described by their relative positions. Our\nfindings suggest that the question of the nature of space, currently exclusive\nto philosophy and physics, should also be addressed from the standpoint of\nneuroscience and artificial intelligence.\n", "versions": [{"version": "v1", "created": "Fri, 9 Aug 2013 13:50:48 GMT"}], "update_date": "2013-08-12", "authors_parsed": [["Terekhov", "Alexander V.", ""], ["O'Regan", "J. Kevin", ""]]}, {"id": "1308.2234", "submitter": "Mark Keane", "authors": "Petra Ahrweiler and Mark T. Keane", "title": "Innovation networks", "comments": null, "journal-ref": "Mind & Society, 12, 73-90, 2013", "doi": "10.1007/s11299-013-0123-7", "report-no": null, "categories": "cs.AI cs.SI physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper advances a framework for modeling the component interactions\nbetween cognitive and social aspects of scientific creativity and technological\ninnovation. Specifically, it aims to characterize Innovation Networks; those\nnetworks that involve the interplay of people, ideas and organizations to\ncreate new, technologically feasible, commercially-realizable products,\nprocesses and organizational structures. The tri-partite framework captures\nnetworks of ideas (Concept Level), people (Individual Level) and social\nstructures (Social-Organizational Level) and the interactions between these\nlevels. At the concept level, new ideas are the nodes that are created and\nlinked, kept open for further investigation or closed if solved by actors at\nthe individual or organizational levels. At the individual level, the nodes are\nactors linked by shared worldviews (based on shared professional, educational,\nexperiential backgrounds) who are the builders of the concept level. At the\nsocial-organizational level, the nodes are organizations linked by common\nefforts on a given project (e.g., a company-university collaboration) that by\nvirtue of their intellectual property or rules of governance constrain the\nactions of individuals (at the Individual Level) or ideas (at the Concept\nLevel). After describing this framework and its implications we paint a number\nof scenarios to flesh out how it can be applied.\n", "versions": [{"version": "v1", "created": "Fri, 9 Aug 2013 20:13:34 GMT"}], "update_date": "2013-08-13", "authors_parsed": [["Ahrweiler", "Petra", ""], ["Keane", "Mark T.", ""]]}, {"id": "1308.2236", "submitter": "Mark Keane", "authors": "Meadhbh Foster and Mark T. Keane", "title": "Surprise: Youve got some explaining to do", "comments": "Proceedings of the Thirty-Fifth Annual Conference of the Cognitive\n  Science Society. Berlin, Germany (pp. 2321-2326), 2013", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Why are some events more surprising than others? We propose that events that\nare more difficult to explain are those that are more surprising. The two\nexperiments reported here test the impact of different event outcomes\n(Outcome-Type) and task demands (Task) on ratings of surprise for simple story\nscenarios. For the Outcome-Type variable, participants saw outcomes that were\neither known or less-known surprising outcomes for each scenario. For the Task\nvariable, participants either answered comprehension questions or provided an\nexplanation of the outcome. Outcome-Type reliably affected surprise judgments;\nknown outcomes were rated as less surprising than less-known outcomes. Task\nalso reliably affected surprise judgments; when people provided an explanation\nit lowered surprise judgments relative to simply answering comprehension\nquestions. Both experiments thus provide evidence on this less-explored\nexplanation aspect of surprise, specifically showing that ease of explanation\nis a key factor in determining the level of surprise experienced.\n", "versions": [{"version": "v1", "created": "Fri, 9 Aug 2013 20:20:46 GMT"}], "update_date": "2013-08-13", "authors_parsed": [["Foster", "Meadhbh", ""], ["Keane", "Mark T.", ""]]}, {"id": "1308.2240", "submitter": "Mark Keane", "authors": "Stephanie OToole and Mark T. Keane", "title": "Cognitive residues of similarity", "comments": "Long version of original abstract; In Proceedings of the Thirty-Fifth\n  Annual Conference of the Cognitive Science Society. Berlin, Germany (pp.\n  4070), 2013", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  What are the cognitive after-effects of making a similarity judgement? What,\ncognitively, is left behind and what effect might these residues have on\nsubsequent processing? In this paper, we probe for such after-effects using a\nvisual search task, performed after a task in which pictures of real-world\nobjects were compared. So, target objects were first presented in a comparison\ntask (e.g., rate the similarity of this object to another) thus, presumably,\nmodifying some of their features before asking people to visually search for\nthe same object in complex scenes (with distractors and camouflaged\nbackgrounds). As visual search is known to be influenced by the features of\ntarget objects, then any after-effects of the comparison task should be\nrevealed in subsequent visual searches. Results showed that when people\npreviously rated an object as being high on a scale (e.g., colour similarity or\ngeneral similarity) then visual search is inhibited (slower RTs and more\nsaccades in eye-tracking) relative to an object being rated as low in the same\nscale. There was also some evidence that different comparison tasks (e.g.,\ncompare on colour or compare on general similarity) have differential effects\non visual search.\n", "versions": [{"version": "v1", "created": "Fri, 9 Aug 2013 20:27:15 GMT"}], "update_date": "2013-08-13", "authors_parsed": [["OToole", "Stephanie", ""], ["Keane", "Mark T.", ""]]}, {"id": "1308.2309", "submitter": "Tshilidzi Marwala", "authors": "Satyakama Paul, Andreas Janecek, Fernando Buarque de Lima Neto and\n  Tshilidzi Marwala", "title": "Applying the Negative Selection Algorithm for Merger and Acquisition\n  Target Identification", "comments": "To appear in the proceedings of the 1st BRICS Countries & 11th CBIC\n  Brazilian Congress on Computational Intelligence", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a new methodology based on the Negative Selection\nAlgorithm that belongs to the field of Computational Intelligence,\nspecifically, Artificial Immune Systems to identify takeover targets. Although\nconsiderable research based on customary statistical techniques and some\ncontemporary Computational Intelligence techniques have been devoted to\nidentify takeover targets, most of the existing studies are based upon multiple\nprevious mergers and acquisitions. Contrary to previous research, the novelty\nof this proposal lies in its ability to suggest takeover targets for novice\nfirms that are at the beginning of their merger and acquisition spree. We first\ndiscuss the theoretical perspective and then provide a case study with details\nfor practical implementation, both capitalizing from unique generalization\ncapabilities of artificial immune systems algorithms.\n", "versions": [{"version": "v1", "created": "Sat, 10 Aug 2013 13:17:46 GMT"}], "update_date": "2013-08-13", "authors_parsed": [["Paul", "Satyakama", ""], ["Janecek", "Andreas", ""], ["Neto", "Fernando Buarque de Lima", ""], ["Marwala", "Tshilidzi", ""]]}, {"id": "1308.2350", "submitter": "Bonny Banerjee", "authors": "Jayanta K. Dutta, Bonny Banerjee", "title": "Learning Features and their Transformations by Spatial and Temporal\n  Spherical Clustering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.CV cs.LG q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning features invariant to arbitrary transformations in the data is a\nrequirement for any recognition system, biological or artificial. It is now\nwidely accepted that simple cells in the primary visual cortex respond to\nfeatures while the complex cells respond to features invariant to different\ntransformations. We present a novel two-layered feedforward neural model that\nlearns features in the first layer by spatial spherical clustering and\ninvariance to transformations in the second layer by temporal spherical\nclustering. Learning occurs in an online and unsupervised manner following the\nHebbian rule. When exposed to natural videos acquired by a camera mounted on a\ncat's head, the first and second layer neurons in our model develop simple and\ncomplex cell-like receptive field properties. The model can predict by learning\nlateral connections among the first layer neurons. A topographic map to their\nspatial features emerges by exponentially decaying the flow of activation with\ndistance from one neuron to another in the first layer that fire in close\ntemporal proximity, thereby minimizing the pooling length in an online manner\nsimultaneously with feature learning.\n", "versions": [{"version": "v1", "created": "Sat, 10 Aug 2013 22:56:26 GMT"}], "update_date": "2020-12-14", "authors_parsed": [["Dutta", "Jayanta K.", ""], ["Banerjee", "Bonny", ""]]}, {"id": "1308.2443", "submitter": "Tiancheng Li", "authors": "Tiancheng Li, Shudong Sun, Tariq P. Sattar and Juan M. Corchado", "title": "Fighting Sample Degeneracy and Impoverishment in Particle Filters: A\n  Review of Intelligent Approaches", "comments": "Expert Systems with Applications, 2014", "journal-ref": "Expert Systems with Applications, Volume 41, Issue 8, Pages\n  3944-3954 (15 June 2014)", "doi": "10.1016/j.eswa.2013.12.031", "report-no": null, "categories": "cs.AI stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  During the last two decades there has been a growing interest in Particle\nFiltering (PF). However, PF suffers from two long-standing problems that are\nreferred to as sample degeneracy and impoverishment. We are investigating\nmethods that are particularly efficient at Particle Distribution Optimization\n(PDO) to fight sample degeneracy and impoverishment, with an emphasis on\nintelligence choices. These methods benefit from such methods as Markov Chain\nMonte Carlo methods, Mean-shift algorithms, artificial intelligence algorithms\n(e.g., Particle Swarm Optimization, Genetic Algorithm and Ant Colony\nOptimization), machine learning approaches (e.g., clustering, splitting and\nmerging) and their hybrids, forming a coherent standpoint to enhance the\nparticle filter. The working mechanism, interrelationship, pros and cons of\nthese approaches are provided. In addition, Approaches that are effective for\ndealing with high-dimensionality are reviewed. While improving the filter\nperformance in terms of accuracy, robustness and convergence, it is noted that\nadvanced techniques employed in PF often causes additional computational\nrequirement that will in turn sacrifice improvement obtained in real life\nfiltering. This fact, hidden in pure simulations, deserves the attention of the\nusers and designers of new filters.\n", "versions": [{"version": "v1", "created": "Mon, 12 Aug 2013 01:38:17 GMT"}, {"version": "v2", "created": "Thu, 9 Jan 2014 02:32:06 GMT"}], "update_date": "2017-07-31", "authors_parsed": [["Li", "Tiancheng", ""], ["Sun", "Shudong", ""], ["Sattar", "Tariq P.", ""], ["Corchado", "Juan M.", ""]]}, {"id": "1308.2655", "submitter": "Loshchilov Ilya", "authors": "Ilya Loshchilov (LIS), Marc Schoenauer (INRIA Saclay - Ile de France,\n  LRI), Mich\\`ele Sebag (LRI)", "title": "KL-based Control of the Learning Schedule for Surrogate Black-Box\n  Optimization", "comments": null, "journal-ref": "Conf\\'erence sur l'Apprentissage Automatique (2013)", "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper investigates the control of an ML component within the Covariance\nMatrix Adaptation Evolution Strategy (CMA-ES) devoted to black-box\noptimization. The known CMA-ES weakness is its sample complexity, the number of\nevaluations of the objective function needed to approximate the global optimum.\nThis weakness is commonly addressed through surrogate optimization, learning an\nestimate of the objective function a.k.a. surrogate model, and replacing most\nevaluations of the true objective function with the (inexpensive) evaluation of\nthe surrogate model. This paper presents a principled control of the learning\nschedule (when to relearn the surrogate model), based on the Kullback-Leibler\ndivergence of the current search distribution and the training distribution of\nthe former surrogate model. The experimental validation of the proposed\napproach shows significant performance gains on a comprehensive set of\nill-conditioned benchmark problems, compared to the best state of the art\nincluding the quasi-Newton high-precision BFGS method.\n", "versions": [{"version": "v1", "created": "Mon, 12 Aug 2013 19:31:59 GMT"}, {"version": "v2", "created": "Sun, 18 Aug 2013 19:30:19 GMT"}], "update_date": "2013-08-20", "authors_parsed": [["Loshchilov", "Ilya", "", "LIS"], ["Schoenauer", "Marc", "", "INRIA Saclay - Ile de France,\n  LRI"], ["Sebag", "Mich\u00e8le", "", "LRI"]]}, {"id": "1308.2772", "submitter": "Mohammad Reza Mollakhalili meybodi", "authors": "M.R.Mollakhalili Meybodi and M.R.Meybodi", "title": "Extended Distributed Learning Automata:A New Method for Solving\n  Stochastic Graph Optimization Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, a new structure of cooperative learning automata so-called\nextended learning automata (eDLA) is introduced. Based on the proposed\nstructure, a new iterative randomized heuristic algorithm for finding optimal\nsub-graph in a stochastic edge-weighted graph through sampling is proposed. It\nhas been shown that the proposed algorithm based on new networked-structure can\nbe to solve the optimization problems on stochastic graph through less number\nof sampling in compare to standard sampling. Stochastic graphs are graphs in\nwhich the edges have an unknown distribution probability weights. Proposed\nalgorithm uses an eDLA to find a policy that leads to an induced sub-graph that\nsatisfies some restrictions such as minimum or maximum weight (length). At each\nstage of the proposed algorithm, eDLA determines which edges to be sampled.\nThis eDLA-based proposed sampling method may result in decreasing unnecessary\nsamples and hence decreasing the time that algorithm requires for finding the\noptimal sub-graph. It has been shown that proposed method converge to optimal\nsolution, furthermore the probability of this convergence can be made\narbitrarily close to 1 by using a sufficiently small learning rate. A new\nvariance-aware threshold value was proposed that can be improving significantly\nconvergence rate of the proposed eDLA-based algorithm. It has been shown that\nthe proposed algorithm is competitive in terms of the quality of the solution\n", "versions": [{"version": "v1", "created": "Tue, 13 Aug 2013 07:15:24 GMT"}], "update_date": "2013-08-14", "authors_parsed": [["Meybodi", "M. R. Mollakhalili", ""], ["Meybodi", "M. R.", ""]]}, {"id": "1308.3136", "submitter": "Richard Preen", "authors": "Richard J. Preen and Larry Bull", "title": "Toward the Coevolution of Novel Vertical-Axis Wind Turbines", "comments": "appears in IEEE Transactions on Evolutionary Computation (2014).\n  arXiv admin note: substantial text overlap with arXiv:1212.5271,\n  arXiv:1204.4107", "journal-ref": "IEEE Transactions on Evolutionary Computation (2015),\n  19(2):284-294", "doi": "10.1109/TEVC.2014.2316199", "report-no": null, "categories": "cs.NE cs.AI cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The production of renewable and sustainable energy is one of the most\nimportant challenges currently facing mankind. Wind has made an increasing\ncontribution to the world's energy supply mix, but still remains a long way\nfrom reaching its full potential. In this paper, we investigate the use of\nartificial evolution to design vertical-axis wind turbine prototypes that are\nphysically instantiated and evaluated under fan generated wind conditions.\nInitially a conventional evolutionary algorithm is used to explore the design\nspace of a single wind turbine and later a cooperative coevolutionary algorithm\nis used to explore the design space of an array of wind turbines. Artificial\nneural networks are used throughout as surrogate models to assist learning and\nfound to reduce the number of fabrications required to reach a higher\naerodynamic efficiency. Unlike in other approaches, such as computational fluid\ndynamics simulations, no mathematical formulations are used and no model\nassumptions are made.\n", "versions": [{"version": "v1", "created": "Tue, 13 Aug 2013 14:02:34 GMT"}, {"version": "v2", "created": "Thu, 15 Jan 2015 16:25:33 GMT"}], "update_date": "2015-07-02", "authors_parsed": [["Preen", "Richard J.", ""], ["Bull", "Larry", ""]]}, {"id": "1308.3309", "submitter": "Daniel Huntley", "authors": "Daniel Huntley and Vadim Bulitko", "title": "Search-Space Characterization for Real-time Heuristic Search", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent real-time heuristic search algorithms have demonstrated outstanding\nperformance in video-game pathfinding. However, their applications have been\nthus far limited to that domain. We proceed with the aim of facilitating wider\napplications of real-time search by fostering a greater understanding of the\nperformance of recent algorithms. We first introduce eight\nalgorithm-independent complexity measures for search spaces and correlate their\nvalues with algorithm performance. The complexity measures are statistically\nshown to be significant predictors of algorithm performance across a set of\ncommercial video-game maps. We then extend this analysis to a wider variety of\nsearch spaces in the first application of database-driven real-time search to\ndomains outside of video-game pathfinding. In doing so, we gain insight into\nalgorithm performance and possible enhancement as well as into search space\ncomplexity.\n", "versions": [{"version": "v1", "created": "Thu, 15 Aug 2013 05:50:19 GMT"}], "update_date": "2013-08-16", "authors_parsed": [["Huntley", "Daniel", ""], ["Bulitko", "Vadim", ""]]}, {"id": "1308.3324", "submitter": "Ahmadreza Ghaffarizadeh", "authors": "Ahmadreza Ghaffarizadeh and Vicki H. Allan", "title": "History Based Coalition Formation in Hedonic Context Using Trust", "comments": "8 pages", "journal-ref": "International Journal of Artificial Intelligence & Applications\n  (IJAIA), Vol. 4, No. 4, July 2013", "doi": "10.5121/ijaia.2013.4401", "report-no": null, "categories": "cs.MA cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  In this paper we address the problem of coalition formation in hedonic\ncontext. Our modelling tries to be as realistic as possible. In previous\nmodels, once an agent joins a coalition it would not be able to leave the\ncoalition and join the new one; in this research we made it possible to leave a\ncoalition but put some restrictions to control the behavior of agents. Leaving\nor staying of an agent in a coalition will affect on the trust of the other\nagents included in this coalition. Agents will use the trust values in\ncomputing the expected utility of coalitions. Three different risk behaviors\nare introduced for agents that want to initiate a coalition. Using these risk\nbehaviors, some simulations are made and results are analyzed.\n", "versions": [{"version": "v1", "created": "Thu, 15 Aug 2013 07:33:28 GMT"}], "update_date": "2013-08-16", "authors_parsed": [["Ghaffarizadeh", "Ahmadreza", ""], ["Allan", "Vicki H.", ""]]}, {"id": "1308.3513", "submitter": "George  Konidaris", "authors": "Finale Doshi-Velez and George Konidaris", "title": "Hidden Parameter Markov Decision Processes: A Semiparametric Regression\n  Approach for Discovering Latent Task Parametrizations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Control applications often feature tasks with similar, but not identical,\ndynamics. We introduce the Hidden Parameter Markov Decision Process (HiP-MDP),\na framework that parametrizes a family of related dynamical systems with a\nlow-dimensional set of latent factors, and introduce a semiparametric\nregression approach for learning its structure from data. In the control\nsetting, we show that a learned HiP-MDP rapidly identifies the dynamics of a\nnew task instance, allowing an agent to flexibly adapt to task variations.\n", "versions": [{"version": "v1", "created": "Thu, 15 Aug 2013 21:21:05 GMT"}], "update_date": "2013-08-19", "authors_parsed": [["Doshi-Velez", "Finale", ""], ["Konidaris", "George", ""]]}, {"id": "1308.3780", "submitter": "Joseph Y. Halpern", "authors": "Joseph Y. Halpern, Rafael Pass, and Lior Seeman", "title": "Decision Theory with Resource-Bounded Agents", "comments": "To appear, Topics in Cognitive Science", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There have been two major lines of research aimed at capturing\nresource-bounded players in game theory. The first, initiated by Rubinstein,\ncharges an agent for doing costly computation; the second, initiated by Neyman,\ndoes not charge for computation, but limits the computation that agents can do,\ntypically by modeling agents as finite automata. We review recent work on\napplying both approaches in the context of decision theory. For the first\napproach, we take the objects of choice in a decision problem to be Turing\nmachines, and charge players for the ``complexity'' of the Turing machine\nchosen (e.g., its running time). This approach can be used to explain\nwell-known phenomena like first-impression-matters biases (i.e., people tend to\nput more weight on evidence they hear early on) and belief polarization (two\npeople with different prior beliefs, hearing the same evidence, can end up with\ndiametrically opposed conclusions) as the outcomes of quite rational decisions.\nFor the second approach, we model people as finite automata, and provide a\nsimple algorithm that, on a problem that captures a number of settings of\ninterest, provably performs optimally as the number of states in the automaton\nincreases.\n", "versions": [{"version": "v1", "created": "Sat, 17 Aug 2013 12:40:42 GMT"}], "update_date": "2013-08-20", "authors_parsed": [["Halpern", "Joseph Y.", ""], ["Pass", "Rafael", ""], ["Seeman", "Lior", ""]]}, {"id": "1308.3784", "submitter": "Hojjat Emami", "authors": "Hojjat Emami and Shahriar Lotfi", "title": "Graph Colouring Problem Based on Discrete Imperialist Competitive\n  Algorithm", "comments": "12 pages", "journal-ref": "International Journal in Foundations of Computer Science &\n  Technology (IJFCST), Vol. 3, No.4, July 2013, pp. 1-12", "doi": "10.5121/ijfcst.2013.3401", "report-no": null, "categories": "cs.AI cs.NE", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  In graph theory, Graph Colouring Problem (GCP) is an assignment of colours to\nvertices of any given graph such that the colours on adjacent vertices are\ndifferent. The GCP is known to be an optimization and NP-hard problem.\nImperialist Competitive Algorithm (ICA) is a meta-heuristic optimization and\nstochastic search strategy which is inspired from socio-political phenomenon of\nimperialistic competition. The ICA contains two main operators: the\nassimilation and the imperialistic competition. The ICA has excellent\ncapabilities such as high convergence rate and better global optimum\nachievement. In this research, a discrete version of ICA is proposed to deal\nwith the solution of GCP. We call this algorithm as the DICA. The performance\nof the proposed method is compared with Genetic Algorithm (GA) on seven\nwell-known graph colouring benchmarks. Experimental results demonstrate the\nsuperiority of the DICA for the benchmarks. This means DICA can produce optimal\nand valid solutions for different GCP instances.\n", "versions": [{"version": "v1", "created": "Sat, 17 Aug 2013 14:02:36 GMT"}], "update_date": "2013-08-20", "authors_parsed": [["Emami", "Hojjat", ""], ["Lotfi", "Shahriar", ""]]}, {"id": "1308.3847", "submitter": "Roberto Bagnara", "authors": "Roberto Bagnara, Matthieu Carlier, Roberta Gori, Arnaud Gotlieb", "title": "Exploiting Binary Floating-Point Representations for Constraint\n  Propagation: The Complete Unabridged Version", "comments": "51 pages, 3 figures, 1 table, 1 listing", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Floating-point computations are quickly finding their way in the design of\nsafety- and mission-critical systems, despite the fact that designing\nfloating-point algorithms is significantly more difficult than designing\ninteger algorithms. For this reason, verification and validation of\nfloating-point computations is a hot research topic. An important verification\ntechnique, especially in some industrial sectors, is testing. However,\ngenerating test data for floating-point intensive programs proved to be a\nchallenging problem. Existing approaches usually resort to random or\nsearch-based test data generation, but without symbolic reasoning it is almost\nimpossible to generate test inputs that execute complex paths controlled by\nfloating-point computations. Moreover, as constraint solvers over the reals or\nthe rationals do not natively support the handling of rounding errors, the need\narises for efficient constraint solvers over floating-point domains. In this\npaper, we present and fully justify improved algorithms for the propagation of\narithmetic IEEE 754 binary floating-point constraints. The key point of these\nalgorithms is a generalization of an idea by B. Marre and C. Michel that\nexploits a property of the representation of floating-point numbers.\n", "versions": [{"version": "v1", "created": "Sun, 18 Aug 2013 09:43:14 GMT"}, {"version": "v2", "created": "Mon, 13 Jan 2014 14:37:53 GMT"}, {"version": "v3", "created": "Fri, 6 Feb 2015 16:47:24 GMT"}, {"version": "v4", "created": "Fri, 31 Jul 2015 16:26:45 GMT"}], "update_date": "2015-08-03", "authors_parsed": [["Bagnara", "Roberto", ""], ["Carlier", "Matthieu", ""], ["Gori", "Roberta", ""], ["Gotlieb", "Arnaud", ""]]}, {"id": "1308.3898", "submitter": "Xin-She Yang", "authors": "Xin-She Yang and Xingshi He", "title": "Firefly Algorithm: Recent Advances and Applications", "comments": "15 pages", "journal-ref": "Xin-She Yang and Xingshi He, (2013). `Firefly Algorithm: Recent\n  Advances and Applications', Int. J. Swarm Intelligence, Vol. 1, No. 1, pp.\n  36--50", "doi": "10.1504/IJSI.2013.055801", "report-no": null, "categories": "math.OC cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nature-inspired metaheuristic algorithms, especially those based on swarm\nintelligence, have attracted much attention in the last ten years. Firefly\nalgorithm appeared in about five years ago, its literature has expanded\ndramatically with diverse applications. In this paper, we will briefly review\nthe fundamentals of firefly algorithm together with a selection of recent\npublications. Then, we discuss the optimality associated with balancing\nexploration and exploitation, which is essential for all metaheuristic\nalgorithms. By comparing with intermittent search strategy, we conclude that\nmetaheuristics such as firefly algorithm are better than the optimal\nintermittent search strategy. We also analyse algorithms and their implications\nfor higher-dimensional optimization problems.\n", "versions": [{"version": "v1", "created": "Sun, 18 Aug 2013 21:47:08 GMT"}], "update_date": "2013-08-20", "authors_parsed": [["Yang", "Xin-She", ""], ["He", "Xingshi", ""]]}, {"id": "1308.3900", "submitter": "Xin-She Yang", "authors": "Xin-She Yang", "title": "Bat Algorithm: Literature Review and Applications", "comments": "10 pages", "journal-ref": "Xin-She Yang, Bat algorithm: literature review and applications,\n  Int. J. Bio-Inspired Computation, Vol. 5, No.3, pp. 141--149 (2013)", "doi": "10.1504/IJBIC.2013.055093", "report-no": null, "categories": "cs.AI math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bat algorithm (BA) is a bio-inspired algorithm developed by Yang in 2010 and\nBA has been found to be very efficient. As a result, the literature has\nexpanded significantly in the last 3 years. This paper provides a timely review\nof the bat algorithm and its new variants. A wide range of diverse applications\nand case studies are also reviewed and summarized briefly here. Further\nresearch topics are also discussed.\n", "versions": [{"version": "v1", "created": "Sun, 18 Aug 2013 22:18:14 GMT"}], "update_date": "2013-08-20", "authors_parsed": [["Yang", "Xin-She", ""]]}, {"id": "1308.4008", "submitter": "Xin-She Yang", "authors": "Momin Jamil and Xin-She Yang", "title": "A Literature Survey of Benchmark Functions For Global Optimization\n  Problems", "comments": "47 pages", "journal-ref": "Momin Jamil and Xin-She Yang, A literature survey of benchmark\n  functions for global optimization problems, Int. Journal of Mathematical\n  Modelling and Numerical Optimisation}, Vol. 4, No. 2, pp. 150--194 (2013)", "doi": "10.1504/IJMMNO.2013.055204", "report-no": null, "categories": "cs.AI math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Test functions are important to validate and compare the performance of\noptimization algorithms. There have been many test or benchmark functions\nreported in the literature; however, there is no standard list or set of\nbenchmark functions. Ideally, test functions should have diverse properties so\nthat can be truly useful to test new algorithms in an unbiased way. For this\npurpose, we have reviewed and compiled a rich set of 175 benchmark functions\nfor unconstrained optimization problems with diverse properties in terms of\nmodality, separability, and valley landscape. This is by far the most complete\nset of functions so far in the literature, and tt can be expected this complete\nset of functions can be used for validation of new optimization in the future.\n", "versions": [{"version": "v1", "created": "Mon, 19 Aug 2013 13:01:17 GMT"}], "update_date": "2013-08-20", "authors_parsed": [["Jamil", "Momin", ""], ["Yang", "Xin-She", ""]]}, {"id": "1308.4013", "submitter": "Adish Singla", "authors": "Adish Singla and Andreas Krause", "title": "Incentives for Privacy Tradeoff in Community Sensing", "comments": "Extended version of paper to appear in HCOMP'13", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Community sensing, fusing information from populations of privately-held\nsensors, presents a great opportunity to create efficient and cost-effective\nsensing applications. Yet, reasonable privacy concerns often limit the access\nto such data streams. How should systems valuate and negotiate access to\nprivate information, for example in return for monetary incentives? How should\nthey optimally choose the participants from a large population of strategic\nusers with privacy concerns, and compensate them for information shared? In\nthis paper, we address these questions and present a novel mechanism,\nSeqTGreedy, for budgeted recruitment of participants in community sensing. We\nfirst show that privacy tradeoffs in community sensing can be cast as an\nadaptive submodular optimization problem. We then design a budget feasible,\nincentive compatible (truthful) mechanism for adaptive submodular maximization,\nwhich achieves near-optimal utility for a large class of sensing applications.\nThis mechanism is general, and of independent interest. We demonstrate the\neffectiveness of our approach in a case study of air quality monitoring, using\ndata collected from the Mechanical Turk platform. Compared to the state of the\nart, our approach achieves up to 30% reduction in cost in order to achieve a\ndesired level of utility.\n", "versions": [{"version": "v1", "created": "Mon, 19 Aug 2013 13:23:59 GMT"}, {"version": "v2", "created": "Sat, 14 Sep 2013 02:01:32 GMT"}], "update_date": "2013-09-17", "authors_parsed": [["Singla", "Adish", ""], ["Krause", "Andreas", ""]]}, {"id": "1308.4189", "submitter": "Andrei Barbu", "authors": "N. Siddharth, Andrei Barbu, Jeffrey Mark Siskind", "title": "Seeing What You're Told: Sentence-Guided Activity Recognition In Video", "comments": "To appear in CVPR 2014", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a system that demonstrates how the compositional structure of\nevents, in concert with the compositional structure of language, can interplay\nwith the underlying focusing mechanisms in video action recognition, thereby\nproviding a medium, not only for top-down and bottom-up integration, but also\nfor multi-modal integration between vision and language. We show how the roles\nplayed by participants (nouns), their characteristics (adjectives), the actions\nperformed (verbs), the manner of such actions (adverbs), and changing spatial\nrelations between participants (prepositions) in the form of whole sentential\ndescriptions mediated by a grammar, guides the activity-recognition process.\nFurther, the utility and expressiveness of our framework is demonstrated by\nperforming three separate tasks in the domain of multi-activity videos:\nsentence-guided focus of attention, generation of sentential descriptions of\nvideo, and query-based video search, simply by leveraging the framework in\ndifferent manners.\n", "versions": [{"version": "v1", "created": "Mon, 19 Aug 2013 23:28:47 GMT"}, {"version": "v2", "created": "Wed, 28 May 2014 18:50:35 GMT"}], "update_date": "2014-05-29", "authors_parsed": [["Siddharth", "N.", ""], ["Barbu", "Andrei", ""], ["Siskind", "Jeffrey Mark", ""]]}, {"id": "1308.4526", "submitter": "Christoph Benzm\\\"uller", "authors": "Christoph Benzm\\\"uller and Bruno Woltzenlogel Paleo", "title": "Formalization, Mechanization and Automation of G\\\"odel's Proof of God's\n  Existence", "comments": "2 pages", "journal-ref": "Frontiers in Artificial Intelligence and Applications, Volume 263:\n  ECAI 2014", "doi": "10.3233/978-1-61499-419-0-93", "report-no": null, "categories": "cs.LO cs.AI math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  G\\\"odel's ontological proof has been analysed for the first-time with an\nunprecedent degree of detail and formality with the help of higher-order\ntheorem provers. The following has been done (and in this order): A detailed\nnatural deduction proof. A formalization of the axioms, definitions and\ntheorems in the TPTP THF syntax. Automatic verification of the consistency of\nthe axioms and definitions with Nitpick. Automatic demonstration of the\ntheorems with the provers LEO-II and Satallax. A step-by-step formalization\nusing the Coq proof assistant. A formalization using the Isabelle proof\nassistant, where the theorems (and some additional lemmata) have been automated\nwith Sledgehammer and Metis.\n", "versions": [{"version": "v1", "created": "Wed, 21 Aug 2013 09:56:57 GMT"}, {"version": "v2", "created": "Thu, 22 Aug 2013 09:47:54 GMT"}, {"version": "v3", "created": "Sun, 25 Aug 2013 07:54:38 GMT"}, {"version": "v4", "created": "Tue, 10 Sep 2013 19:21:22 GMT"}, {"version": "v5", "created": "Sun, 3 Sep 2017 18:43:28 GMT"}], "update_date": "2017-09-05", "authors_parsed": [["Benzm\u00fcller", "Christoph", ""], ["Paleo", "Bruno Woltzenlogel", ""]]}, {"id": "1308.4761", "submitter": "Tri Kurniawan Wijaya", "authors": "Tri Kurniawan Wijaya, Kate Larson and Karl Aberer", "title": "Matching Demand with Supply in the Smart Grid using Agent-Based\n  Multiunit Auction", "comments": null, "journal-ref": "2013 Fifth International Conference on Communication Systems and\n  Networks (COMSNETS), vol., no., pp.1,6, 7-10 Jan. 2013", "doi": "10.1109/COMSNETS.2013.6465595", "report-no": null, "categories": "cs.AI cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work has suggested reducing electricity generation cost by cutting the\npeak to average ratio (PAR) without reducing the total amount of the loads.\nHowever, most of these proposals rely on consumer's willingness to act. In this\npaper, we propose an approach to cut PAR explicitly from the supply side. The\nresulting cut loads are then distributed among consumers by the means of a\nmultiunit auction which is done by an intelligent agent on behalf of the\nconsumer. This approach is also in line with the future vision of the smart\ngrid to have the demand side matched with the supply side. Experiments suggest\nthat our approach reduces overall system cost and gives benefit to both\nconsumers and the energy provider.\n", "versions": [{"version": "v1", "created": "Thu, 22 Aug 2013 04:58:21 GMT"}], "update_date": "2013-08-23", "authors_parsed": [["Wijaya", "Tri Kurniawan", ""], ["Larson", "Kate", ""], ["Aberer", "Karl", ""]]}, {"id": "1308.4846", "submitter": "Martin Chmel\\'ik", "authors": "Krishnendu Chatterjee, Martin Chmel\\'ik", "title": "POMDPs under Probabilistic Semantics", "comments": "Full version of: POMDPs under Probabilistic Semantics, UAI 2013", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider partially observable Markov decision processes (POMDPs) with\nlimit-average payoff, where a reward value in the interval [0,1] is associated\nto every transition, and the payoff of an infinite path is the long-run average\nof the rewards. We consider two types of path constraints: (i) quantitative\nconstraint defines the set of paths where the payoff is at least a given\nthreshold {\\lambda} in (0, 1]; and (ii) qualitative constraint which is a\nspecial case of quantitative constraint with {\\lambda} = 1. We consider the\ncomputation of the almost-sure winning set, where the controller needs to\nensure that the path constraint is satisfied with probability 1. Our main\nresults for qualitative path constraint are as follows: (i) the problem of\ndeciding the existence of a finite-memory controller is EXPTIME-complete; and\n(ii) the problem of deciding the existence of an infinite-memory controller is\nundecidable. For quantitative path constraint we show that the problem of\ndeciding the existence of a finite-memory controller is undecidable.\n", "versions": [{"version": "v1", "created": "Thu, 22 Aug 2013 12:50:27 GMT"}], "update_date": "2013-08-23", "authors_parsed": [["Chatterjee", "Krishnendu", ""], ["Chmel\u00edk", "Martin", ""]]}, {"id": "1308.4943", "submitter": "Claus-Peter Wirth", "authors": "Claus-Peter Wirth, Frieder Stolzenburg", "title": "David Poole's Specificity Revised", "comments": "ii+34 pages", "journal-ref": null, "doi": null, "report-no": "SEKI-Report SR-2013-01", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the middle of the 1980s, David Poole introduced a semantical,\nmodel-theoretic notion of specificity to the artificial-intelligence community.\nSince then it has found further applications in non-monotonic reasoning, in\nparticular in defeasible reasoning. Poole tried to approximate the intuitive\nhuman concept of specificity, which seems to be essential for reasoning in\neveryday life with its partial and inconsistent information. His notion,\nhowever, turns out to be intricate and problematic, which --- as we show ---\ncan be overcome to some extent by a closer approximation of the intuitive human\nconcept of specificity. Besides the intuitive advantages of our novel\nspecificity ordering over Poole's specificity relation in the classical\nexamples of the literature, we also report some hard mathematical facts:\nContrary to what was claimed before, we show that Poole's relation is not\ntransitive. The present means to decide our novel specificity relation,\nhowever, show only a slight improvement over the known ones for Poole's\nrelation, and further work is needed in this aspect.\n", "versions": [{"version": "v1", "created": "Thu, 22 Aug 2013 18:28:21 GMT"}, {"version": "v2", "created": "Fri, 23 Aug 2013 09:51:46 GMT"}, {"version": "v3", "created": "Wed, 6 Nov 2013 10:44:05 GMT"}, {"version": "v4", "created": "Sun, 24 Nov 2013 17:08:51 GMT"}], "update_date": "2014-02-11", "authors_parsed": [["Wirth", "Claus-Peter", ""], ["Stolzenburg", "Frieder", ""]]}, {"id": "1308.5032", "submitter": "Liane Gabora", "authors": "Liane Gabora and Steve DiPaola", "title": "How Did Humans Become So Creative? A Computational Approach", "comments": "8 pages", "journal-ref": "Proceedings of the Third International Conference on Computational\n  Creativity (pp. 203-210). May 31 - June 1, 2012, Dublin, Ireland", "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.MA q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper summarizes efforts to computationally model two transitions in the\nevolution of human creativity: its origins about two million years ago, and the\n'big bang' of creativity about 50,000 years ago. Using a computational model of\ncultural evolution in which neural network based agents evolve ideas for\nactions through invention and imitation, we tested the hypothesis that human\ncreativity began with onset of the capacity for recursive recall. We compared\nruns in which agents were limited to single-step actions to runs in which they\nused recursive recall to chain simple actions into complex ones. Chaining\nresulted in higher diversity, open-ended novelty, no ceiling on the mean\nfitness of actions, and greater ability to make use of learning. Using a\ncomputational model of portrait painting, we tested the hypothesis that the\nexplosion of creativity in the Middle/Upper Paleolithic was due to onset of\ncon-textual focus: the capacity to shift between associative and analytic\nthought. This resulted in faster convergence on portraits that resembled the\nsitter, employed painterly techniques, and were rated as preferable. We\nconclude that recursive recall and contextual focus provide a computationally\nplausible explanation of how humans evolved the means to transform this planet.\n", "versions": [{"version": "v1", "created": "Fri, 23 Aug 2013 03:05:28 GMT"}, {"version": "v2", "created": "Sun, 30 Jun 2019 02:03:19 GMT"}, {"version": "v3", "created": "Fri, 5 Jul 2019 19:24:32 GMT"}, {"version": "v4", "created": "Tue, 9 Jul 2019 19:50:17 GMT"}], "update_date": "2019-07-11", "authors_parsed": [["Gabora", "Liane", ""], ["DiPaola", "Steve", ""]]}, {"id": "1308.5046", "submitter": "Jes\\'us Gir\\'aldez-Cru", "authors": "C. Ans\\'otegui (1), M. L. Bonet (2), J. Gir\\'aldez-Cru (3) and J. Levy\n  (3) ((1) DIEI, Univ. de Lleida, (2) LSI, UPC, (3) IIIA-CSIC)", "title": "The Fractal Dimension of SAT Formulas", "comments": "20 pages, 11 Postscript figures", "journal-ref": null, "doi": "10.1007/978-3-319-08587-6_8", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern SAT solvers have experienced a remarkable progress on solving\nindustrial instances. Most of the techniques have been developed after an\nintensive experimental testing process. Recently, there have been some attempts\nto analyze the structure of these formulas in terms of complex networks, with\nthe long-term aim of explaining the success of these SAT solving techniques,\nand possibly improving them.\n  We study the fractal dimension of SAT formulas, and show that most industrial\nfamilies of formulas are self-similar, with a small fractal dimension. We also\nshow that this dimension is not affected by the addition of learnt clauses. We\nexplore how the dimension of a formula, together with other graph properties\ncan be used to characterize SAT instances. Finally, we give empirical evidence\nthat these graph properties can be used in state-of-the-art portfolios.\n", "versions": [{"version": "v1", "created": "Fri, 23 Aug 2013 04:30:37 GMT"}], "update_date": "2017-07-21", "authors_parsed": [["Ans\u00f3tegui", "C.", "", "DIEI, Univ. de Lleida"], ["Bonet", "M. L.", "", "LSI, UPC"], ["Gir\u00e1ldez-Cru", "J.", "", "IIIA-CSIC"], ["Levy", "J.", "", "IIIA-CSIC"]]}, {"id": "1308.5136", "submitter": "Uwe Aickelin", "authors": "Josie McCulloch, Christian Wagner, Uwe Aickelin", "title": "Extending Similarity Measures of Interval Type-2 Fuzzy Sets to General\n  Type-2 Fuzzy Sets", "comments": "International Conference on Fuzzy Systems 2013 (Fuzz-IEEE 2013)", "journal-ref": null, "doi": "10.1109/FUZZ-IEEE.2013.6622408", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Similarity measures provide one of the core tools that enable reasoning about\nfuzzy sets. While many types of similarity measures exist for type-1 and\ninterval type-2 fuzzy sets, there are very few similarity measures that enable\nthe comparison of general type-2 fuzzy sets. In this paper, we introduce a\ngeneral method for extending existing interval type-2 similarity measures to\nsimilarity measures for general type-2 fuzzy sets. Specifically, we show how\nsimilarity measures for interval type-2 fuzzy sets can be employed in\nconjunction with the zSlices based general type-2 representation for fuzzy sets\nto provide measures of similarity which preserve all the common properties\n(i.e. reflexivity, symmetry, transitivity and overlapping) of the original\ninterval type-2 similarity measure. We demonstrate examples of such extended\nfuzzy measures and provide comparisons between (different types of) interval\nand general type-2 fuzzy measures.\n", "versions": [{"version": "v1", "created": "Fri, 23 Aug 2013 14:29:03 GMT"}], "update_date": "2016-11-17", "authors_parsed": [["McCulloch", "Josie", ""], ["Wagner", "Christian", ""], ["Aickelin", "Uwe", ""]]}, {"id": "1308.5137", "submitter": "Uwe Aickelin", "authors": "Josie McCulloch, Christian Wagner, Uwe Aickelin", "title": "Measuring the Directional Distance Between Fuzzy Sets", "comments": "UKCI 2013, the 13th Annual Workshop on Computational Intelligence,\n  Surrey University", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The measure of distance between two fuzzy sets is a fundamental tool within\nfuzzy set theory. However, current distance measures within the literature do\nnot account for the direction of change between fuzzy sets; a useful concept in\na variety of applications, such as Computing With Words. In this paper, we\nhighlight this utility and introduce a distance measure which takes the\ndirection between sets into account. We provide details of its application for\nnormal and non-normal, as well as convex and non-convex fuzzy sets. We\ndemonstrate the new distance measure using real data from the MovieLens dataset\nand establish the benefits of measuring the direction between fuzzy sets.\n", "versions": [{"version": "v1", "created": "Fri, 23 Aug 2013 14:31:10 GMT"}], "update_date": "2013-08-26", "authors_parsed": [["McCulloch", "Josie", ""], ["Wagner", "Christian", ""], ["Aickelin", "Uwe", ""]]}, {"id": "1308.5321", "submitter": "Seppo Ilari Tirri", "authors": "Seppo Ilari Tirri", "title": "Evolution Theory of Self-Evolving Autonomous Problem Solving Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The present study gives a mathematical framework for self-evolution within\nautonomous problem solving systems. Special attention is set on universal\nabstraction, thereof generation by net block homomorphism, consequently\nmultiple order solving systems and the overall decidability of the set of the\nsolutions. By overlapping presentation of nets new abstraction relation among\nnets is formulated alongside with consequent alphabetical net block renetting\nsystem proportional to normal forms of renetting systems regarding the\noperational power. A new structure in self-evolving problem solving is\nestablished via saturation by groups of equivalence relations and iterative\nclosures of generated quotient transducer algebras over the whole evolution.\n", "versions": [{"version": "v1", "created": "Sat, 24 Aug 2013 12:45:48 GMT"}], "update_date": "2013-08-27", "authors_parsed": [["Tirri", "Seppo Ilari", ""]]}, {"id": "1308.5332", "submitter": "EPTCS", "authors": "Elodie Chanthery, Pauline Ribot", "title": "An Integrated Framework for Diagnosis and Prognosis of Hybrid Systems", "comments": "In Proceedings HAS 2013, arXiv:1308.4904", "journal-ref": "EPTCS 124, 2013, pp. 14-25", "doi": "10.4204/EPTCS.124.4", "report-no": null, "categories": "cs.SY cs.AI cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Complex systems are naturally hybrid: their dynamic behavior is both\ncontinuous and discrete. For these systems, maintenance and repair are an\nincreasing part of the total cost of final product. Efficient diagnosis and\nprognosis techniques have to be adopted to detect, isolate and anticipate\nfaults. This paper presents an original integrated theoretical framework for\ndiagnosis and prognosis of hybrid systems. The formalism used for hybrid\ndiagnosis is enriched in order to be able to follow the evolution of an aging\nlaw for each fault of the system. The paper presents a methodology for\ninterleaving diagnosis and prognosis in a hybrid framework.\n", "versions": [{"version": "v1", "created": "Sat, 24 Aug 2013 14:33:45 GMT"}], "update_date": "2013-08-27", "authors_parsed": [["Chanthery", "Elodie", ""], ["Ribot", "Pauline", ""]]}, {"id": "1308.5374", "submitter": "Daniel Schwartz", "authors": "Daniel G. Schwartz", "title": "Dynamic Reasoning Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A {\\it dynamic reasoning system} (DRS) is an adaptation of a conventional\nformal logical system that explicitly portrays reasoning as a temporal\nactivity, with each extralogical input to the system and each inference rule\napplication being viewed as occurring at a distinct time step. Every DRS\nincorporates some well-defined logic together with a controller that serves to\nguide the reasoning process in response to user inputs. Logics are generic,\nwhereas controllers are application-specific. Every controller does,\nnonetheless, provide an algorithm for nonmonotonic belief revision. The general\nnotion of a DRS comprises a framework within which one can formulate the logic\nand algorithms for a given application and prove that the algorithms are\ncorrect, i.e., that they serve to (i) derive all salient information and (ii)\npreserve the consistency of the belief set. This paper illustrates the idea\nwith ordinary first-order predicate calculus, suitably modified for the present\npurpose, and two examples. The latter example revisits some classic\nnonmonotonic reasoning puzzles (Opus the Penguin, Nixon Diamond) and shows how\nthese can be resolved in the context of a DRS, using an expanded version of\nfirst-order logic that incorporates typed predicate symbols. All concepts are\nrigorously defined and effectively computable, thereby providing the foundation\nfor a future software implementation.\n", "versions": [{"version": "v1", "created": "Sun, 25 Aug 2013 03:48:08 GMT"}], "update_date": "2013-08-27", "authors_parsed": [["Schwartz", "Daniel G.", ""]]}, {"id": "1308.6206", "submitter": "Erich Teppan", "authors": "Erich Christian Teppan and Gerhard Friedrich", "title": "The Partner Units Configuration Problem: Completing the Picture", "comments": "30 pages, 14 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The partner units problem (PUP) is an acknowledged hard benchmark problem for\nthe Logic Programming community with various industrial application fields like\nsurveillance, electrical engineering, computer networks or railway safety\nsystems. However, computational complexity remained widely unclear so far. In\nthis paper we provide all missing complexity results making the PUP better\nexploitable for benchmark testing. Furthermore, we present QuickPup, a\nheuristic search algorithm for PUP instances which outperforms all\nstate-of-the-art solving approaches and which is already in use in real world\nindustrial configuration environments.\n", "versions": [{"version": "v1", "created": "Wed, 28 Aug 2013 16:29:42 GMT"}, {"version": "v2", "created": "Fri, 11 Oct 2013 11:41:40 GMT"}, {"version": "v3", "created": "Thu, 17 Oct 2013 11:37:23 GMT"}], "update_date": "2013-10-18", "authors_parsed": [["Teppan", "Erich Christian", ""], ["Friedrich", "Gerhard", ""]]}, {"id": "1308.6292", "submitter": "Marco Montali", "authors": "Babak Bagheri Hariri, Diego Calvanese, Marco Montali, Ario Santoso,\n  Dmitry Solomakhin", "title": "Verification of Semantically-Enhanced Artifact Systems (Extended\n  Version)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Artifact-Centric systems have emerged in the last years as a suitable\nframework to model business-relevant entities, by combining their static and\ndynamic aspects. In particular, the Guard-Stage-Milestone (GSM) approach has\nbeen recently proposed to model artifacts and their lifecycle in a declarative\nway. In this paper, we enhance GSM with a Semantic Layer, constituted by a\nfull-fledged OWL 2 QL ontology linked to the artifact information models\nthrough mapping specifications. The ontology provides a conceptual view of the\ndomain under study, and allows one to understand the evolution of the artifact\nsystem at a higher level of abstraction. In this setting, we present a\ntechnique to specify temporal properties expressed over the Semantic Layer, and\nverify them according to the evolution in the underlying GSM model. This\ntechnique has been implemented in a tool that exploits state-of-the-art\nontology-based data access technologies to manipulate the temporal properties\naccording to the ontology and the mappings, and that relies on the GSMC model\nchecker for verification.\n", "versions": [{"version": "v1", "created": "Wed, 28 Aug 2013 20:01:36 GMT"}], "update_date": "2013-08-30", "authors_parsed": [["Hariri", "Babak Bagheri", ""], ["Calvanese", "Diego", ""], ["Montali", "Marco", ""], ["Santoso", "Ario", ""], ["Solomakhin", "Dmitry", ""]]}, {"id": "1308.6415", "submitter": "Ke Chen", "authors": "Jonathan Roberts and Ke Chen", "title": "Learning-Based Procedural Content Generation", "comments": "13 pages, 9 figures, manuscript submitted to IEEE Transactions on\n  Computational Intelligence and AI Games (Also a technical report, School of\n  Computer Science, The University of Manchester)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.HC cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Procedural content generation (PCG) has recently become one of the hottest\ntopics in computational intelligence and AI game researches. Among a variety of\nPCG techniques, search-based approaches overwhelmingly dominate PCG development\nat present. While SBPCG leads to promising results and successful applications,\nit poses a number of challenges ranging from representation to evaluation of\nthe content being generated. In this paper, we present an alternative yet\ngeneric PCG framework, named learning-based procedure content generation\n(LBPCG), to provide potential solutions to several challenging problems in\nexisting PCG techniques. By exploring and exploiting information gained in game\ndevelopment and public beta test via data-driven learning, our framework can\ngenerate robust content adaptable to end-user or target players on-line with\nminimal interruption to their experience. Furthermore, we develop enabling\ntechniques to implement the various models required in our framework. For a\nproof of concept, we have developed a prototype based on the classic open\nsource first-person shooter game, Quake. Simulation results suggest that our\nframework is promising in generating quality content.\n", "versions": [{"version": "v1", "created": "Thu, 29 Aug 2013 10:06:38 GMT"}, {"version": "v2", "created": "Wed, 9 Oct 2013 10:49:29 GMT"}], "update_date": "2013-10-10", "authors_parsed": [["Roberts", "Jonathan", ""], ["Chen", "Ke", ""]]}, {"id": "1308.6823", "submitter": "Hui Miao", "authors": "Hui Miao, Xiangyang Liu, Bert Huang, Lise Getoor", "title": "A Hypergraph-Partitioned Vertex Programming Approach for Large-scale\n  Consensus Optimization", "comments": null, "journal-ref": null, "doi": "10.1109/BigData.2013.6691623", "report-no": null, "categories": "cs.AI cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In modern data science problems, techniques for extracting value from big\ndata require performing large-scale optimization over heterogenous, irregularly\nstructured data. Much of this data is best represented as multi-relational\ngraphs, making vertex programming abstractions such as those of Pregel and\nGraphLab ideal fits for modern large-scale data analysis. In this paper, we\ndescribe a vertex-programming implementation of a popular consensus\noptimization technique known as the alternating direction of multipliers\n(ADMM). ADMM consensus optimization allows elegant solution of complex\nobjectives such as inference in rich probabilistic models. We also introduce a\nnovel hypergraph partitioning technique that improves over state-of-the-art\npartitioning techniques for vertex programming and significantly reduces the\ncommunication cost by reducing the number of replicated nodes up to an order of\nmagnitude. We implemented our algorithm in GraphLab and measure scaling\nperformance on a variety of realistic bipartite graph distributions and a large\nsynthetic voter-opinion analysis application. In our experiments, we are able\nto achieve a 50% improvement in runtime over the current state-of-the-art\nGraphLab partitioning scheme.\n", "versions": [{"version": "v1", "created": "Fri, 30 Aug 2013 19:30:44 GMT"}], "update_date": "2014-06-10", "authors_parsed": [["Miao", "Hui", ""], ["Liu", "Xiangyang", ""], ["Huang", "Bert", ""], ["Getoor", "Lise", ""]]}]