[{"id": "1911.00061", "submitter": "Yuval Heffetz", "authors": "Yuval Heffetz, Roman Vainstein, Gilad Katz, Lior Rokach", "title": "DeepLine: AutoML Tool for Pipelines Generation using Deep Reinforcement\n  Learning and Hierarchical Actions Filtering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic machine learning (AutoML) is an area of research aimed at\nautomating machine learning (ML) activities that currently require human\nexperts. One of the most challenging tasks in this field is the automatic\ngeneration of end-to-end ML pipelines: combining multiple types of ML\nalgorithms into a single architecture used for end-to-end analysis of\npreviously-unseen data. This task has two challenging aspects: the first is the\nneed to explore a large search space of algorithms and pipeline architectures.\nThe second challenge is the computational cost of training and evaluating\nmultiple pipelines. In this study we present DeepLine, a reinforcement learning\nbased approach for automatic pipeline generation. Our proposed approach\nutilizes an efficient representation of the search space and leverages past\nknowledge gained from previously-analyzed datasets to make the problem more\ntractable. Additionally, we propose a novel hierarchical-actions algorithm that\nserves as a plugin, mediating the environment-agent interaction in deep\nreinforcement learning problems. The plugin significantly speeds up the\ntraining process of our model. Evaluation on 56 datasets shows that DeepLine\noutperforms state-of-the-art approaches both in accuracy and in computational\ncost.\n", "versions": [{"version": "v1", "created": "Thu, 31 Oct 2019 19:06:14 GMT"}], "update_date": "2019-11-04", "authors_parsed": [["Heffetz", "Yuval", ""], ["Vainstein", "Roman", ""], ["Katz", "Gilad", ""], ["Rokach", "Lior", ""]]}, {"id": "1911.00155", "submitter": "Ali Ayub", "authors": "Ali Ayub, Alan R. Wagner", "title": "Centroid Based Concept Learning for RGB-D Indoor Scene Classification", "comments": "Accepted at BMVC 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper contributes a novel cognitively-inspired method for RGB-D indoor\nscene classification. High intra-class variance and low inter-class variance\nmake indoor scene classification an extremely challenging task. To cope with\nthis problem, we propose a clustering approach inspired by the concept learning\nmodel of the hippocampus and the neocortex, to generate clusters and centroids\nfor different scene categories. Test images depicting different scenes are\nclassified by using their distance to the closest centroids (concepts).\nModeling of RGB-D scenes as centroids not only leads to state-of-the-art\nclassification performance on benchmark datasets (SUN RGB-D and NYU Depth V2),\nbut also offers a method for inspecting and interpreting the space of\ncentroids. Inspection of the centroids generated by our approach on RGB-D\ndatasets leads us to propose a method for merging conceptually similar\ncategories, resulting in improved accuracy for all approaches.\n", "versions": [{"version": "v1", "created": "Fri, 1 Nov 2019 00:09:37 GMT"}, {"version": "v2", "created": "Thu, 23 Jan 2020 00:03:56 GMT"}, {"version": "v3", "created": "Thu, 6 Aug 2020 22:25:22 GMT"}, {"version": "v4", "created": "Sat, 15 Aug 2020 01:26:48 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Ayub", "Ali", ""], ["Wagner", "Alan R.", ""]]}, {"id": "1911.00171", "submitter": "Vinicius G. Goecks", "authors": "Ritwik Bera, Vinicius G. Goecks, Gregory M. Gremillion, John Valasek,\n  and Nicholas R. Waytowich", "title": "PODNet: A Neural Network for Discovery of Plannable Options", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning from demonstration has been widely studied in machine learning but\nbecomes challenging when the demonstrated trajectories are unstructured and\nfollow different objectives. This short-paper proposes PODNet, Plannable Option\nDiscovery Network, addressing how to segment an unstructured set of\ndemonstrated trajectories for option discovery. This enables learning from\ndemonstration to perform multiple tasks and plan high-level trajectories based\non the discovered option labels. PODNet combines a custom categorical\nvariational autoencoder, a recurrent option inference network,\noption-conditioned policy network, and option dynamics model in an end-to-end\nlearning architecture. Due to the concurrently trained option-conditioned\npolicy network and option dynamics model, the proposed architecture has\nimplications in multi-task and hierarchical learning, explainable and\ninterpretable artificial intelligence, and applications where the agent is\nrequired to learn only from observations.\n", "versions": [{"version": "v1", "created": "Fri, 1 Nov 2019 01:09:46 GMT"}, {"version": "v2", "created": "Fri, 15 Nov 2019 07:04:21 GMT"}, {"version": "v3", "created": "Fri, 28 Feb 2020 14:51:39 GMT"}], "update_date": "2020-03-02", "authors_parsed": [["Bera", "Ritwik", ""], ["Goecks", "Vinicius G.", ""], ["Gremillion", "Gregory M.", ""], ["Valasek", "John", ""], ["Waytowich", "Nicholas R.", ""]]}, {"id": "1911.00226", "submitter": "Daniel Kasenberg", "authors": "Daniel Kasenberg, Antonio Roque, Ravenna Thielstrom, Meia\n  Chita-Tegmark, and Matthias Scheutz", "title": "Generating Justifications for Norm-Related Agent Decisions", "comments": "Accepted to the Proceedings of the 12th International Conference on\n  Natural Language Generation (INLG 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an approach to generating natural language justifications of\ndecisions derived from norm-based reasoning. Assuming an agent which maximally\nsatisfies a set of rules specified in an object-oriented temporal logic, the\nuser can ask factual questions (about the agent's rules, actions, and the\nextent to which the agent violated the rules) as well as \"why\" questions that\nrequire the agent comparing actual behavior to counterfactual trajectories with\nrespect to these rules. To produce natural-sounding explanations, we focus on\nthe subproblem of producing natural language clauses from statements in a\nfragment of temporal logic, and then describe how to embed these clauses into\nexplanatory sentences. We use a human judgment evaluation on a testbed task to\ncompare our approach to variants in terms of intelligibility, mental model and\nperceived trust.\n", "versions": [{"version": "v1", "created": "Fri, 1 Nov 2019 06:53:12 GMT"}], "update_date": "2019-11-04", "authors_parsed": [["Kasenberg", "Daniel", ""], ["Roque", "Antonio", ""], ["Thielstrom", "Ravenna", ""], ["Chita-Tegmark", "Meia", ""], ["Scheutz", "Matthias", ""]]}, {"id": "1911.00229", "submitter": "Daniel Kasenberg", "authors": "Daniel Kasenberg, Antonio Roque, Ravenna Thielstrom, and Matthias\n  Scheutz", "title": "Engaging in Dialogue about an Agent's Norms and Behaviors", "comments": "Accepted to the 1st Workshop on Interactive Natural Language\n  Technology for Explainable Artificial Intelligence (NL4XAI)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a set of capabilities allowing an agent planning with moral and\nsocial norms represented in temporal logic to respond to queries about its\nnorms and behaviors in natural language, and for the human user to add and\nremove norms directly in natural language. The user may also pose hypothetical\nmodifications to the agent's norms and inquire about their effects.\n", "versions": [{"version": "v1", "created": "Fri, 1 Nov 2019 07:01:52 GMT"}], "update_date": "2019-11-04", "authors_parsed": [["Kasenberg", "Daniel", ""], ["Roque", "Antonio", ""], ["Thielstrom", "Ravenna", ""], ["Scheutz", "Matthias", ""]]}, {"id": "1911.00238", "submitter": "Takato Horii", "authors": "Kyoichiro Kobayashi, Takato Horii, Ryo Iwaki, Yukie Nagai and Minoru\n  Asada", "title": "Situated GAIL: Multitask imitation using task-conditioned adversarial\n  inverse reinforcement learning", "comments": "Submitted to Advanced Robotics", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative adversarial imitation learning (GAIL) has attracted increasing\nattention in the field of robot learning. It enables robots to learn a policy\nto achieve a task demonstrated by an expert while simultaneously estimating the\nreward function behind the expert's behaviors. However, this framework is\nlimited to learning a single task with a single reward function. This study\nproposes an extended framework called situated GAIL (S-GAIL), in which a task\nvariable is introduced to both the discriminator and generator of the GAIL\nframework. The task variable has the roles of discriminating different contexts\nand making the framework learn different reward functions and policies for\nmultiple tasks. To achieve the early convergence of learning and robustness\nduring reward estimation, we introduce a term to adjust the entropy\nregularization coefficient in the generator's objective function. Our\nexperiments using two setups (navigation in a discrete grid world and arm\nreaching in a continuous space) demonstrate that the proposed framework can\nacquire multiple reward functions and policies more effectively than existing\nframeworks. The task variable enables our framework to differentiate contexts\nwhile sharing common knowledge among multiple tasks.\n", "versions": [{"version": "v1", "created": "Fri, 1 Nov 2019 07:50:30 GMT"}], "update_date": "2019-11-04", "authors_parsed": [["Kobayashi", "Kyoichiro", ""], ["Horii", "Takato", ""], ["Iwaki", "Ryo", ""], ["Nagai", "Yukie", ""], ["Asada", "Minoru", ""]]}, {"id": "1911.00357", "submitter": "Erik Wijmans", "authors": "Erik Wijmans, Abhishek Kadian, Ari Morcos, Stefan Lee, Irfan Essa,\n  Devi Parikh, Manolis Savva, Dhruv Batra", "title": "DD-PPO: Learning Near-Perfect PointGoal Navigators from 2.5 Billion\n  Frames", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present Decentralized Distributed Proximal Policy Optimization (DD-PPO), a\nmethod for distributed reinforcement learning in resource-intensive simulated\nenvironments. DD-PPO is distributed (uses multiple machines), decentralized\n(lacks a centralized server), and synchronous (no computation is ever stale),\nmaking it conceptually simple and easy to implement. In our experiments on\ntraining virtual robots to navigate in Habitat-Sim, DD-PPO exhibits near-linear\nscaling -- achieving a speedup of 107x on 128 GPUs over a serial\nimplementation. We leverage this scaling to train an agent for 2.5 Billion\nsteps of experience (the equivalent of 80 years of human experience) -- over 6\nmonths of GPU-time training in under 3 days of wall-clock time with 64 GPUs.\n  This massive-scale training not only sets the state of art on Habitat\nAutonomous Navigation Challenge 2019, but essentially solves the task\n--near-perfect autonomous navigation in an unseen environment without access to\na map, directly from an RGB-D camera and a GPS+Compass sensor. Fortuitously,\nerror vs computation exhibits a power-law-like distribution; thus, 90% of peak\nperformance is obtained relatively early (at 100 million steps) and relatively\ncheaply (under 1 day with 8 GPUs). Finally, we show that the scene\nunderstanding and navigation policies learned can be transferred to other\nnavigation tasks -- the analog of ImageNet pre-training + task-specific\nfine-tuning for embodied AI. Our model outperforms ImageNet pre-trained CNNs on\nthese transfer tasks and can serve as a universal resource (all models and code\nare publicly available).\n", "versions": [{"version": "v1", "created": "Fri, 1 Nov 2019 13:07:37 GMT"}, {"version": "v2", "created": "Mon, 20 Jan 2020 04:18:58 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Wijmans", "Erik", ""], ["Kadian", "Abhishek", ""], ["Morcos", "Ari", ""], ["Lee", "Stefan", ""], ["Essa", "Irfan", ""], ["Parikh", "Devi", ""], ["Savva", "Manolis", ""], ["Batra", "Dhruv", ""]]}, {"id": "1911.00384", "submitter": "Tuan Dam", "authors": "Tuan Dam, Pascal Klink, Carlo D'Eramo, Jan Peters, Joni Pajarinen", "title": "Generalized Mean Estimation in Monte-Carlo Tree Search", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider Monte-Carlo Tree Search (MCTS) applied to Markov Decision\nProcesses (MDPs) and Partially Observable MDPs (POMDPs), and the well-known\nUpper Confidence bound for Trees (UCT) algorithm. In UCT, a tree with nodes\n(states) and edges (actions) is incrementally built by the expansion of nodes,\nand the values of nodes are updated through a backup strategy based on the\naverage value of child nodes. However, it has been shown that with enough\nsamples the maximum operator yields more accurate node value estimates than\naveraging. Instead of settling for one of these value estimates, we go a step\nfurther proposing a novel backup strategy which uses the power mean operator,\nwhich computes a value between the average and maximum value. We call our new\napproach Power-UCT, and argue how the use of the power mean operator helps to\nspeed up the learning in MCTS. We theoretically analyze our method providing\nguarantees of convergence to the optimum. Finally, we empirically demonstrate\nthe effectiveness of our method in well-known MDP and POMDP benchmarks, showing\nsignificant improvement in performance and convergence speed w.r.t. state of\nthe art algorithms.\n", "versions": [{"version": "v1", "created": "Fri, 1 Nov 2019 14:02:36 GMT"}, {"version": "v2", "created": "Mon, 13 Jul 2020 14:40:08 GMT"}], "update_date": "2020-07-14", "authors_parsed": [["Dam", "Tuan", ""], ["Klink", "Pascal", ""], ["D'Eramo", "Carlo", ""], ["Peters", "Jan", ""], ["Pajarinen", "Joni", ""]]}, {"id": "1911.00397", "submitter": "Indu John", "authors": "Indu John, Chandramouli Kamanchi, Shalabh Bhatnagar", "title": "Generalized Speedy Q-learning", "comments": null, "journal-ref": "in IEEE Control Systems Letters, vol. 4, no. 3, pp. 524-529, July\n  2020", "doi": "10.1109/LCSYS.2020.2970555", "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we derive a generalization of the Speedy Q-learning (SQL)\nalgorithm that was proposed in the Reinforcement Learning (RL) literature to\nhandle slow convergence of Watkins' Q-learning. In most RL algorithms such as\nQ-learning, the Bellman equation and the Bellman operator play an important\nrole. It is possible to generalize the Bellman operator using the technique of\nsuccessive relaxation. We use the generalized Bellman operator to derive a\nsimple and efficient family of algorithms called Generalized Speedy Q-learning\n(GSQL-w) and analyze its finite time performance. We show that GSQL-w has an\nimproved finite time performance bound compared to SQL for the case when the\nrelaxation parameter w is greater than 1. This improvement is a consequence of\nthe contraction factor of the generalized Bellman operator being less than that\nof the standard Bellman operator. Numerical experiments are provided to\ndemonstrate the empirical performance of the GSQL-w algorithm.\n", "versions": [{"version": "v1", "created": "Fri, 1 Nov 2019 14:18:59 GMT"}, {"version": "v2", "created": "Thu, 13 Feb 2020 04:20:51 GMT"}], "update_date": "2020-02-14", "authors_parsed": [["John", "Indu", ""], ["Kamanchi", "Chandramouli", ""], ["Bhatnagar", "Shalabh", ""]]}, {"id": "1911.00449", "submitter": "Xixi Li", "authors": "Yun Bai, Suling Jia, Xixi Li", "title": "Research and application of time series algorithms in centralized\n  purchasing data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Based on the online transaction data of COSCO group's centralized procurement\nplatform, this paper studies the clustering method of time series type data.\nThe different methods of similarity calculation, different clustering methods\nwith different K values are analysed, and the best clustering method suitable\nfor centralized purchasing data is determined. The company list under the\ncorresponding cluster is obtained. The time series motif discovery algorithm is\nused to model the centroid of each cluster. Through ARIMA method, we also made\n12 periods of prediction for the centroid of each category. This paper\nconstructs a matrix of \"Customer Lifecycle Theory - Five Elements of Marketing\n\", and puts forward corresponding marketing suggestions for customers at\ndifferent life cycle stages.\n", "versions": [{"version": "v1", "created": "Fri, 1 Nov 2019 16:31:24 GMT"}], "update_date": "2019-11-04", "authors_parsed": [["Bai", "Yun", ""], ["Jia", "Suling", ""], ["Li", "Xixi", ""]]}, {"id": "1911.00467", "submitter": "Art Owen", "authors": "Masayoshi Mase and Art B. Owen and Benjamin Seiler", "title": "Explaining black box decisions by Shapley cohort refinement", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI econ.EM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a variable importance measure to quantify the impact of\nindividual input variables to a black box function. Our measure is based on the\nShapley value from cooperative game theory. Many measures of variable\nimportance operate by changing some predictor values with others held fixed,\npotentially creating unlikely or even logically impossible combinations. Our\ncohort Shapley measure uses only observed data points. Instead of changing the\nvalue of a predictor we include or exclude subjects similar to the target\nsubject on that predictor to form a similarity cohort. Then we apply Shapley\nvalue to the cohort averages. We connect variable importance measures from\nexplainable AI to function decompositions from global sensitivity analysis. We\nintroduce a squared cohort Shapley value that splits previously studied Shapley\neffects over subjects, consistent with a Shapley axiom.\n", "versions": [{"version": "v1", "created": "Fri, 1 Nov 2019 17:10:20 GMT"}, {"version": "v2", "created": "Thu, 1 Oct 2020 23:57:41 GMT"}], "update_date": "2020-10-05", "authors_parsed": [["Mase", "Masayoshi", ""], ["Owen", "Art B.", ""], ["Seiler", "Benjamin", ""]]}, {"id": "1911.00473", "submitter": "Emad Elwany", "authors": "Emad Elwany, Dave Moore, Gaurav Oberoi", "title": "BERT Goes to Law School: Quantifying the Competitive Advantage of Access\n  to Large Legal Corpora in Contract Understanding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fine-tuning language models, such as BERT, on domain specific corpora has\nproven to be valuable in domains like scientific papers and biomedical text. In\nthis paper, we show that fine-tuning BERT on legal documents similarly provides\nvaluable improvements on NLP tasks in the legal domain. Demonstrating this\noutcome is significant for analyzing commercial agreements, because obtaining\nlarge legal corpora is challenging due to their confidential nature. As such,\nwe show that having access to large legal corpora is a competitive advantage\nfor commercial applications, and academic research on analyzing contracts.\n", "versions": [{"version": "v1", "created": "Fri, 1 Nov 2019 17:30:21 GMT"}], "update_date": "2019-11-04", "authors_parsed": [["Elwany", "Emad", ""], ["Moore", "Dave", ""], ["Oberoi", "Gaurav", ""]]}, {"id": "1911.00483", "submitter": "Sumedha Singla", "authors": "Sumedha Singla, Brian Pollack, Junxiang Chen and Kayhan Batmanghelich", "title": "Explanation by Progressive Exaggeration", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  As machine learning methods see greater adoption and implementation in high\nstakes applications such as medical image diagnosis, the need for model\ninterpretability and explanation has become more critical. Classical approaches\nthat assess feature importance (e.g. saliency maps) do not explain how and why\na particular region of an image is relevant to the prediction. We propose a\nmethod that explains the outcome of a classification black-box by gradually\nexaggerating the semantic effect of a given class. Given a query input to a\nclassifier, our method produces a progressive set of plausible variations of\nthat query, which gradually changes the posterior probability from its original\nclass to its negation. These counter-factually generated samples preserve\nfeatures unrelated to the classification decision, such that a user can employ\nour method as a \"tuning knob\" to traverse a data manifold while crossing the\ndecision boundary. Our method is model agnostic and only requires the output\nvalue and gradient of the predictor with respect to its input.\n", "versions": [{"version": "v1", "created": "Fri, 1 Nov 2019 17:48:24 GMT"}, {"version": "v2", "created": "Tue, 5 Nov 2019 21:00:40 GMT"}, {"version": "v3", "created": "Mon, 10 Feb 2020 20:32:23 GMT"}], "update_date": "2020-02-12", "authors_parsed": [["Singla", "Sumedha", ""], ["Pollack", "Brian", ""], ["Chen", "Junxiang", ""], ["Batmanghelich", "Kayhan", ""]]}, {"id": "1911.00492", "submitter": "Saatviga Sudhahar", "authors": "Saatviga Sudhahar, Ian Roberts and Andrea Pierleoni", "title": "Reasoning Over Paths via Knowledge Base Completion", "comments": "Submitted at the TextGraphs2019 Workshop at EMNLP 2019 Conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reasoning over paths in large scale knowledge graphs is an important problem\nfor many applications. In this paper we discuss a simple approach to\nautomatically build and rank paths between a source and target entity pair with\nlearned embeddings using a knowledge base completion model (KBC). We assembled\na knowledge graph by mining the available biomedical scientific literature and\nextracted a set of high frequency paths to use for validation. We demonstrate\nthat our method is able to effectively rank a list of known paths between a\npair of entities and also come up with plausible paths that are not present in\nthe knowledge graph. For a given entity pair we are able to reconstruct the\nhighest ranking path 60% of the time within the the top 10 ranked paths and\nachieve 49% mean average precision. Our approach is compositional since any KBC\nmodel that can produce vector representations of entities can be used.\n", "versions": [{"version": "v1", "created": "Fri, 1 Nov 2019 17:59:38 GMT"}], "update_date": "2019-11-04", "authors_parsed": [["Sudhahar", "Saatviga", ""], ["Roberts", "Ian", ""], ["Pierleoni", "Andrea", ""]]}, {"id": "1911.00497", "submitter": "Nicholas Waytowich", "authors": "Nicholas Waytowich, Sean L. Barton, Vernon Lawhern, Garrett Warnell", "title": "A Narration-based Reward Shaping Approach using Grounded Natural\n  Language Commands", "comments": "Presented at the Imitation, Intent and Interaction (I3) workshop,\n  ICML 2019. arXiv admin note: substantial text overlap with arXiv:1906.02671", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While deep reinforcement learning techniques have led to agents that are\nsuccessfully able to learn to perform a number of tasks that had been\npreviously unlearnable, these techniques are still susceptible to the\nlongstanding problem of reward sparsity. This is especially true for tasks such\nas training an agent to play StarCraft II, a real-time strategy game where\nreward is only given at the end of a game which is usually very long. While\nthis problem can be addressed through reward shaping, such approaches typically\nrequire a human expert with specialized knowledge. Inspired by the vision of\nenabling reward shaping through the more-accessible paradigm of\nnatural-language narration, we develop a technique that can provide the\nbenefits of reward shaping using natural language commands. Our\nnarration-guided RL agent projects sequences of natural-language commands into\nthe same high-dimensional representation space as corresponding goal states. We\nshow that we can get improved performance with our method compared to\ntraditional reward-shaping approaches. Additionally, we demonstrate the ability\nof our method to generalize to unseen natural-language commands.\n", "versions": [{"version": "v1", "created": "Thu, 31 Oct 2019 22:37:54 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Waytowich", "Nicholas", ""], ["Barton", "Sean L.", ""], ["Lawhern", "Vernon", ""], ["Warnell", "Garrett", ""]]}, {"id": "1911.00523", "submitter": "Chenhao Tan", "authors": "David Atkinson, Kumar Bhargav Srinivasan, Chenhao Tan", "title": "What Gets Echoed? Understanding the \"Pointers\" in Explanations of\n  Persuasive Arguments", "comments": "19 pages, 3 figures, EMNLP 2019, the code and dataset are available\n  at https://chenhaot.com/papers/explanation-pointers.html", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.CY cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Explanations are central to everyday life, and are a topic of growing\ninterest in the AI community. To investigate the process of providing natural\nlanguage explanations, we leverage the dynamics of the /r/ChangeMyView\nsubreddit to build a dataset with 36K naturally occurring explanations of why\nan argument is persuasive. We propose a novel word-level prediction task to\ninvestigate how explanations selectively reuse, or echo, information from what\nis being explained (henceforth, explanandum). We develop features to capture\nthe properties of a word in the explanandum, and show that our proposed\nfeatures not only have relatively strong predictive power on the echoing of a\nword in an explanation, but also enhance neural methods of generating\nexplanations. In particular, while the non-contextual properties of a word\nitself are more valuable for stopwords, the interaction between the constituent\nparts of an explanandum is crucial in predicting the echoing of content words.\nWe also find intriguing patterns of a word being echoed. For example, although\nnouns are generally less likely to be echoed, subjects and objects can,\ndepending on their source, be more likely to be echoed in the explanations.\n", "versions": [{"version": "v1", "created": "Fri, 1 Nov 2019 18:00:05 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Atkinson", "David", ""], ["Srinivasan", "Kumar Bhargav", ""], ["Tan", "Chenhao", ""]]}, {"id": "1911.00572", "submitter": "Tomi Peltola", "authors": "Tomi Peltola, Jussi Jokinen, Samuel Kaski", "title": "Probabilistic Formulation of the Take The Best Heuristic", "comments": "Annual Meeting of the Cognitive Science Society, CogSci 2018\n  Proceedings", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The framework of cognitively bounded rationality treats problem solving as\nfundamentally rational, but emphasises that it is constrained by cognitive\narchitecture and the task environment. This paper investigates a simple\ndecision making heuristic, Take The Best (TTB), within that framework. We\nformulate TTB as a likelihood-based probabilistic model, where the decision\nstrategy arises by probabilistic inference based on the training data and the\nmodel constraints. The strengths of the probabilistic formulation, in addition\nto providing a bounded rational account of the learning of the heuristic,\ninclude natural extensibility with additional cognitively plausible constraints\nand prior information, and the possibility to embed the heuristic as a subpart\nof a larger probabilistic model. We extend the model to learn cue\ndiscrimination thresholds for continuous-valued cues and experiment with using\nthe model to account for biased preference feedback from a boundedly rational\nagent in a simulated interactive machine learning task.\n", "versions": [{"version": "v1", "created": "Fri, 1 Nov 2019 20:08:37 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Peltola", "Tomi", ""], ["Jokinen", "Jussi", ""], ["Kaski", "Samuel", ""]]}, {"id": "1911.00584", "submitter": "Timo Korthals", "authors": "Timo Korthals and Malte Schilling and J\\\"urgen Leitner", "title": "A Perceived Environment Design using a Multi-Modal Variational\n  Autoencoder for learning Active-Sensing", "comments": "Extended Abstract for the IROS 2019 Workshop on Deep Probabilistic\n  Generative Models for Cognitive Architecture in Robotics", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This contribution comprises the interplay between a multi-modal variational\nautoencoder and an environment to a perceived environment, on which an agent\ncan act. Furthermore, we conclude our work with a comparison to\ncuriosity-driven learning.\n", "versions": [{"version": "v1", "created": "Fri, 1 Nov 2019 20:38:37 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Korthals", "Timo", ""], ["Schilling", "Malte", ""], ["Leitner", "J\u00fcrgen", ""]]}, {"id": "1911.00598", "submitter": "Paolo Pareti Dr.", "authors": "Paolo Pareti, George Konstantinidis, Timothy J. Norman, Murat\n  \\c{S}ensoy", "title": "SHACL Constraints with Inference Rules", "comments": null, "journal-ref": "In International Semantic Web Conference, pp. 539-557. Springer,\n  Cham, 2019", "doi": "10.1007/978-3-030-30793-6_31", "report-no": null, "categories": "cs.AI cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Shapes Constraint Language (SHACL) has been recently introduced as a W3C\nrecommendation to define constraints that can be validated against RDF graphs.\nInteractions of SHACL with other Semantic Web technologies, such as ontologies\nor reasoners, is a matter of ongoing research. In this paper we study the\ninteraction of a subset of SHACL with inference rules expressed in datalog. On\nthe one hand, SHACL constraints can be used to define a \"schema\" for graph\ndatasets. On the other hand, inference rules can lead to the discovery of new\nfacts that do not match the original schema. Given a set of SHACL constraints\nand a set of datalog rules, we present a method to detect which constraints\ncould be violated by the application of the inference rules on some graph\ninstance of the schema, and update the original schema, i.e, the set of SHACL\nconstraints, in order to capture the new facts that can be inferred. We provide\ntheoretical and experimental results of the various components of our approach.\n", "versions": [{"version": "v1", "created": "Fri, 1 Nov 2019 21:49:49 GMT"}], "update_date": "2020-08-10", "authors_parsed": [["Pareti", "Paolo", ""], ["Konstantinidis", "George", ""], ["Norman", "Timothy J.", ""], ["\u015eensoy", "Murat", ""]]}, {"id": "1911.00617", "submitter": "Mikael Henaff", "authors": "Mikael Henaff", "title": "Explicit Explore-Exploit Algorithms in Continuous State Spaces", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new model-based algorithm for reinforcement learning (RL) which\nconsists of explicit exploration and exploitation phases, and is applicable in\nlarge or infinite state spaces. The algorithm maintains a set of dynamics\nmodels consistent with current experience and explores by finding policies\nwhich induce high disagreement between their state predictions. It then\nexploits using the refined set of models or experience gathered during\nexploration. We show that under realizability and optimal planning assumptions,\nour algorithm provably finds a near-optimal policy with a number of samples\nthat is polynomial in a structural complexity measure which we show to be low\nin several natural settings. We then give a practical approximation using\nneural networks and demonstrate its performance and sample efficiency in\npractice.\n", "versions": [{"version": "v1", "created": "Fri, 1 Nov 2019 23:58:05 GMT"}, {"version": "v2", "created": "Mon, 2 Dec 2019 16:21:13 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Henaff", "Mikael", ""]]}, {"id": "1911.00638", "submitter": "Samuel Daulton", "authors": "Samuel Daulton, Shaun Singh, Vashist Avadhanula, Drew Dimmery, Eytan\n  Bakshy", "title": "Thompson Sampling for Contextual Bandit Problems with Auxiliary Safety\n  Constraints", "comments": "To appear at NeurIPS 2019, Workshop on Safety and Robustness in\n  Decision Making. 11 pages (including references and appendix)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in contextual bandit optimization and reinforcement learning\nhave garnered interest in applying these methods to real-world sequential\ndecision making problems. Real-world applications frequently have constraints\nwith respect to a currently deployed policy. Many of the existing\nconstraint-aware algorithms consider problems with a single objective (the\nreward) and a constraint on the reward with respect to a baseline policy.\nHowever, many important applications involve multiple competing objectives and\nauxiliary constraints. In this paper, we propose a novel Thompson sampling\nalgorithm for multi-outcome contextual bandit problems with auxiliary\nconstraints. We empirically evaluate our algorithm on a synthetic problem.\nLastly, we apply our method to a real world video transcoding problem and\nprovide a practical way for navigating the trade-off between safety and\nperformance using Bayesian optimization.\n", "versions": [{"version": "v1", "created": "Sat, 2 Nov 2019 03:41:37 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Daulton", "Samuel", ""], ["Singh", "Shaun", ""], ["Avadhanula", "Vashist", ""], ["Dimmery", "Drew", ""], ["Bakshy", "Eytan", ""]]}, {"id": "1911.00696", "submitter": "Bartosz Bednarczyk", "authors": "Bartosz Bednarczyk", "title": "Statistical EL is ExpTime-complete", "comments": "Major revision of the previous version, extra lemma provided, a few\n  grammar corrections. Under submission to IPL", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that the consistency problem for Statistical EL ontologies, defined\nby Pe{\\~{n}}aloza and Potyka, is ExpTime-hard. Together with existing ExpTime\nupper bounds, we conclude ExpTime-completeness of the logic. Our proof goes via\na reduction from the consistency problem for EL extended with negation of\natomic concepts.\n", "versions": [{"version": "v1", "created": "Sat, 2 Nov 2019 11:17:42 GMT"}, {"version": "v2", "created": "Fri, 31 Jul 2020 17:22:06 GMT"}, {"version": "v3", "created": "Wed, 21 Oct 2020 18:48:14 GMT"}, {"version": "v4", "created": "Wed, 3 Mar 2021 11:19:59 GMT"}, {"version": "v5", "created": "Fri, 5 Mar 2021 13:22:38 GMT"}], "update_date": "2021-03-08", "authors_parsed": [["Bednarczyk", "Bartosz", ""]]}, {"id": "1911.00773", "submitter": "Changmao Li", "authors": "Changmao Li, Tianhao Liu, Jinho D. Choi", "title": "Design and Challenges of Cloze-Style Reading Comprehension Tasks on\n  Multiparty Dialogue", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper analyzes challenges in cloze-style reading comprehension on\nmultiparty dialogue and suggests two new tasks for more comprehensive\npredictions of personal entities in daily conversations. We first demonstrate\nthat there are substantial limitations to the evaluation methods of previous\nwork, namely that randomized assignment of samples to training and test data\nsubstantially decreases the complexity of cloze-style reading comprehension.\nAccording to our analysis, replacing the random data split with a chronological\ndata split reduces test accuracy on previous single-variable passage completion\ntask from 72\\% to 34\\%, that leaves much more room to improve. Our proposed\ntasks extend the previous single-variable passage completion task by replacing\nmore character mentions with variables. Several deep learning models are\ndeveloped to validate these three tasks. A thorough error analysis is provided\nto understand the challenges and guide the future direction of this research.\n", "versions": [{"version": "v1", "created": "Sat, 2 Nov 2019 19:19:28 GMT"}, {"version": "v2", "created": "Mon, 12 Jul 2021 20:48:25 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["Li", "Changmao", ""], ["Liu", "Tianhao", ""], ["Choi", "Jinho D.", ""]]}, {"id": "1911.00786", "submitter": "Pavel Naumov", "authors": "Pavel Naumov and Rui-Jie Yew", "title": "Ethical Dilemmas in Strategic Games", "comments": "Proceedings of 35th AAAI Conference on Artificial Intelligence (AAAI\n  21), February 2-9, 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.GT cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An agent, or a coalition of agents, faces an ethical dilemma between several\nstatements if she is forced to make a conscious choice between which of these\nstatements will be true. This paper proposes to capture ethical dilemmas as a\nmodality in strategic game settings with and without limit on sacrifice and for\nperfect and imperfect information games. The authors show that the dilemma\nmodality cannot be defined through the earlier proposed blameworthiness\nmodality. The main technical result is a sound and complete axiomatization of\nthe properties of this modality with sacrifice in games with perfect\ninformation.\n", "versions": [{"version": "v1", "created": "Sat, 2 Nov 2019 21:12:57 GMT"}, {"version": "v2", "created": "Sun, 13 Dec 2020 22:41:18 GMT"}, {"version": "v3", "created": "Tue, 2 Mar 2021 02:31:19 GMT"}], "update_date": "2021-03-03", "authors_parsed": [["Naumov", "Pavel", ""], ["Yew", "Rui-Jie", ""]]}, {"id": "1911.00792", "submitter": "Franz Heinsen", "authors": "Franz A. Heinsen", "title": "An Algorithm for Routing Capsules in All Domains", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Building on recent work on capsule networks, we propose a new,\ngeneral-purpose form of \"routing by agreement\" that activates output capsules\nin a layer as a function of their net benefit to use and net cost to ignore\ninput capsules from earlier layers. To illustrate the usefulness of our routing\nalgorithm, we present two capsule networks that apply it in different domains:\nvision and language. The first network achieves new state-of-the-art accuracy\nof 99.1% on the smallNORB visual recognition task with fewer parameters and an\norder of magnitude less training than previous capsule models, and we find\nevidence that it learns to perform a form of \"reverse graphics.\" The second\nnetwork achieves new state-of-the-art accuracies on the root sentences of the\nStanford Sentiment Treebank: 58.5% on fine-grained and 95.6% on binary labels\nwith a single-task model that routes frozen embeddings from a pretrained\ntransformer as capsules. In both domains, we train with the same regime. Code\nis available at https://github.com/glassroom/heinsen_routing along with\nreplication instructions.\n", "versions": [{"version": "v1", "created": "Sat, 2 Nov 2019 22:13:18 GMT"}, {"version": "v2", "created": "Tue, 5 Nov 2019 16:42:42 GMT"}, {"version": "v3", "created": "Fri, 8 Nov 2019 02:02:32 GMT"}, {"version": "v4", "created": "Sun, 8 Dec 2019 17:20:13 GMT"}, {"version": "v5", "created": "Sun, 15 Dec 2019 18:49:59 GMT"}, {"version": "v6", "created": "Fri, 28 Feb 2020 16:57:39 GMT"}], "update_date": "2020-03-02", "authors_parsed": [["Heinsen", "Franz A.", ""]]}, {"id": "1911.00828", "submitter": "Andrew Cohen", "authors": "Andrew Cohen and Lei Yu and Xingye Qiao and Xiangrong Tong", "title": "Maximum Entropy Diverse Exploration: Disentangling Maximum Entropy\n  Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Two hitherto disconnected threads of research, diverse exploration (DE) and\nmaximum entropy RL have addressed a wide range of problems facing reinforcement\nlearning algorithms via ostensibly distinct mechanisms. In this work, we\nidentify a connection between these two approaches. First, a\ndiscriminator-based diversity objective is put forward and connected to\ncommonly used divergence measures. We then extend this objective to the maximum\nentropy framework and propose an algorithm Maximum Entropy Diverse Exploration\n(MEDE) which provides a principled method to learn diverse behaviors. A\ntheoretical investigation shows that the set of policies learned by MEDE\ncapture the same modalities as the optimal maximum entropy policy. In effect,\nthe proposed algorithm disentangles the maximum entropy policy into its\ndiverse, constituent policies. Experiments show that MEDE is superior to the\nstate of the art in learning high performing and diverse policies.\n", "versions": [{"version": "v1", "created": "Sun, 3 Nov 2019 04:25:00 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Cohen", "Andrew", ""], ["Yu", "Lei", ""], ["Qiao", "Xingye", ""], ["Tong", "Xiangrong", ""]]}, {"id": "1911.00850", "submitter": "Sahana Ramnath", "authors": "Sahana Ramnath, Amrita Saha, Soumen Chakrabarti, Mitesh M. Khapra", "title": "Scene Graph based Image Retrieval -- A case study on the CLEVR Dataset", "comments": "3 pages including references, Accepted at the ICCV 2019 Workshop -\n  'Linguistics Meets Image and Video Retrieval' (received Best Paper Award)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the prolification of multimodal interaction in various domains, recently\nthere has been much interest in text based image retrieval in the computer\nvision community. However most of the state of the art techniques model this\nproblem in a purely neural way, which makes it difficult to incorporate\npragmatic strategies in searching a large scale catalog especially when the\nsearch requirements are insufficient and the model needs to resort to an\ninteractive retrieval process through multiple iterations of\nquestion-answering. Motivated by this, we propose a neural-symbolic approach\nfor a one-shot retrieval of images from a large scale catalog, given the\ncaption description. To facilitate this, we represent the catalog and caption\nas scene-graphs and model the retrieval task as a learnable graph matching\nproblem, trained end-to-end with a REINFORCE algorithm. Further, we briefly\ndescribe an extension of this pipeline to an iterative retrieval framework,\nbased on interactive questioning and answering.\n", "versions": [{"version": "v1", "created": "Sun, 3 Nov 2019 08:00:38 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Ramnath", "Sahana", ""], ["Saha", "Amrita", ""], ["Chakrabarti", "Soumen", ""], ["Khapra", "Mitesh M.", ""]]}, {"id": "1911.00891", "submitter": "Debanjan Ghosh", "authors": "Debanjan Ghosh, Elena Musi, Kartikeya Upasani, Smaranda Muresan", "title": "Interpreting Verbal Irony: Linguistic Strategies and the Connection to\n  the Type of Semantic Incongruity", "comments": "Accepted at Society for Computation in Linguistics (SCiL), 2020\n  Conference", "journal-ref": null, "doi": "10.7275/91ey-3n44", "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Human communication often involves the use of verbal irony or sarcasm, where\nthe speakers usually mean the opposite of what they say. To better understand\nhow verbal irony is expressed by the speaker and interpreted by the hearer we\nconduct a crowdsourcing task: given an utterance expressing verbal irony, users\nare asked to verbalize their interpretation of the speaker's ironic message. We\npropose a typology of linguistic strategies for verbal irony interpretation and\nlink it to various theoretical linguistic frameworks. We design computational\nmodels to capture these strategies and present empirical studies aimed to\nanswer three questions: (1) what is the distribution of linguistic strategies\nused by hearers to interpret ironic messages?; (2) do hearers adopt similar\nstrategies for interpreting the speaker's ironic intent?; and (3) does the type\nof semantic incongruity in the ironic message (explicit vs. implicit) influence\nthe choice of interpretation strategies by the hearers?\n", "versions": [{"version": "v1", "created": "Sun, 3 Nov 2019 14:05:55 GMT"}, {"version": "v2", "created": "Tue, 5 Nov 2019 12:25:55 GMT"}, {"version": "v3", "created": "Sat, 9 May 2020 18:49:28 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["Ghosh", "Debanjan", ""], ["Musi", "Elena", ""], ["Upasani", "Kartikeya", ""], ["Muresan", "Smaranda", ""]]}, {"id": "1911.00914", "submitter": "Saturnino Luz", "authors": "Bridget Kane, Jing Su, Saturnino Luz", "title": "Potential Applications of Machine Learning at Multidisciplinary Medical\n  Team Meetings", "comments": "5 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CY cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While machine learning (ML) systems have produced great advances in several\ndomains, their use in support of complex cooperative work remains a research\nchallenge. A particularly challenging setting, and one that may benefit from ML\nsupport is the work of multidisciplinary medical teams (MDTs). This paper\nfocuses on the activities performed during the multidisciplinary medical team\nmeeting (MDTM), reviewing their main characteristics in light of a longitudinal\nanalysis of several MDTs in a large teaching hospital over a period of ten\nyears and of our development of ML methods to support MDTMs, and identifying\nopportunities and possible pitfalls for the use of ML to support MDTMs.\n", "versions": [{"version": "v1", "created": "Sun, 3 Nov 2019 15:51:14 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Kane", "Bridget", ""], ["Su", "Jing", ""], ["Luz", "Saturnino", ""]]}, {"id": "1911.00926", "submitter": "Daniel Tanneberg", "authors": "Daniel Tanneberg, Elmar Rueckert, Jan Peters", "title": "Learning Algorithmic Solutions to Symbolic Planning Tasks with a Neural\n  Computer Architecture", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A key feature of intelligent behavior is the ability to learn abstract\nstrategies that transfer to unfamiliar problems. Therefore, we present a novel\narchitecture, based on memory-augmented networks, that is inspired by the von\nNeumann and Harvard architectures of modern computers. This architecture\nenables the learning of abstract algorithmic solutions via Evolution Strategies\nin a reinforcement learning setting. Applied to Sokoban, sliding block puzzle\nand robotic manipulation tasks, we show that the architecture can learn\nalgorithmic solutions with strong generalization and abstraction: scaling to\narbitrary task configurations and complexities, and being independent of both\nthe data representation and the task domain.\n", "versions": [{"version": "v1", "created": "Wed, 30 Oct 2019 17:02:13 GMT"}, {"version": "v2", "created": "Wed, 3 Jun 2020 11:21:39 GMT"}], "update_date": "2020-06-04", "authors_parsed": [["Tanneberg", "Daniel", ""], ["Rueckert", "Elmar", ""], ["Peters", "Jan", ""]]}, {"id": "1911.00954", "submitter": "Andrea Zanette", "authors": "Andrea Zanette, Emma Brunskill", "title": "Problem Dependent Reinforcement Learning Bounds Which Can Identify\n  Bandit Structure in MDPs", "comments": null, "journal-ref": "International Conference on Machine Learning, 2018", "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In order to make good decision under uncertainty an agent must learn from\nobservations. To do so, two of the most common frameworks are Contextual\nBandits and Markov Decision Processes (MDPs). In this paper, we study whether\nthere exist algorithms for the more general framework (MDP) which automatically\nprovide the best performance bounds for the specific problem at hand without\nuser intervention and without modifying the algorithm. In particular, it is\nfound that a very minor variant of a recently proposed reinforcement learning\nalgorithm for MDPs already matches the best possible regret bound $\\tilde O\n(\\sqrt{SAT})$ in the dominant term if deployed on a tabular Contextual Bandit\nproblem despite the agent being agnostic to such setting.\n", "versions": [{"version": "v1", "created": "Sun, 3 Nov 2019 19:44:30 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Zanette", "Andrea", ""], ["Brunskill", "Emma", ""]]}, {"id": "1911.00969", "submitter": "Lin Shao", "authors": "Lin Shao, Toki Migimatsu and Jeannette Bohg", "title": "Learning to Scaffold the Development of Robotic Manipulation Skills", "comments": "Accepted to IEEE International Conference on Robotics and Automation\n  (ICRA) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.CV cs.LG cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning contact-rich, robotic manipulation skills is a challenging problem\ndue to the high-dimensionality of the state and action space as well as\nuncertainty from noisy sensors and inaccurate motor control. To combat these\nfactors and achieve more robust manipulation, humans actively exploit contact\nconstraints in the environment. By adopting a similar strategy, robots can also\nachieve more robust manipulation. In this paper, we enable a robot to\nautonomously modify its environment and thereby discover how to ease\nmanipulation skill learning. Specifically, we provide the robot with fixtures\nthat it can freely place within the environment. These fixtures provide hard\nconstraints that limit the outcome of robot actions. Thereby, they funnel\nuncertainty from perception and motor control and scaffold manipulation skill\nlearning. We propose a learning system that consists of two learning loops. In\nthe outer loop, the robot positions the fixture in the workspace. In the inner\nloop, the robot learns a manipulation skill and after a fixed number of\nepisodes, returns the reward to the outer loop. Thereby, the robot is\nincentivised to place the fixture such that the inner loop quickly achieves a\nhigh reward. We demonstrate our framework both in simulation and in the real\nworld on three tasks: peg insertion, wrench manipulation and shallow-depth\ninsertion. We show that manipulation skill learning is dramatically sped up\nthrough this way of scaffolding.\n", "versions": [{"version": "v1", "created": "Sun, 3 Nov 2019 21:15:46 GMT"}, {"version": "v2", "created": "Thu, 3 Sep 2020 06:03:30 GMT"}, {"version": "v3", "created": "Mon, 5 Oct 2020 05:11:36 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Shao", "Lin", ""], ["Migimatsu", "Toki", ""], ["Bohg", "Jeannette", ""]]}, {"id": "1911.01005", "submitter": "Fan Yang", "authors": "Fan Yang, Zijian Zhang, Haofan Wang, Yuening Li, Xia Hu", "title": "XDeep: An Interpretation Tool for Deep Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  XDeep is an open-source Python package developed to interpret deep models for\nboth practitioners and researchers. Overall, XDeep takes a trained deep neural\nnetwork (DNN) as the input, and generates relevant interpretations as the\noutput with the post-hoc manner. From the functionality perspective, XDeep\nintegrates a wide range of interpretation algorithms from the\nstate-of-the-arts, covering different types of methodologies, and is capable of\nproviding both local explanation and global explanation for DNN when\ninterpreting model behaviours. With the well-documented API designed in XDeep,\nend-users can easily obtain the interpretations for their deep models at hand\nwith several lines of codes, and compare the results among different\nalgorithms. XDeep is generally compatible with Python 3, and can be installed\nthrough Python Package Index (PyPI). The source codes are available at:\nhttps://github.com/datamllab/xdeep.\n", "versions": [{"version": "v1", "created": "Mon, 4 Nov 2019 01:59:41 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Yang", "Fan", ""], ["Zhang", "Zijian", ""], ["Wang", "Haofan", ""], ["Li", "Yuening", ""], ["Hu", "Xia", ""]]}, {"id": "1911.01014", "submitter": "Muhammad Afzal", "authors": "Muhammad Afzal, S.M. Riazul Islam, Maqbool Hussain, and Sungyoung Lee", "title": "Precision Medicine Informatics: Principles, Prospects, and Challenges", "comments": "22 pages, 8 figures, 5 tables, journal paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Precision Medicine (PM) is an emerging approach that appears with the\nimpression of changing the existing paradigm of medical practice. Recent\nadvances in technological innovations and genetics, and the growing\navailability of health data have set a new pace of the research and imposes a\nset of new requirements on different stakeholders. To date, some studies are\navailable that discuss about different aspects of PM. Nevertheless, a holistic\nrepresentation of those aspects deemed to confer the technological perspective,\nin relation to applications and challenges, is mostly ignored. In this context,\nthis paper surveys advances in PM from informatics viewpoint and reviews the\nenabling tools and techniques in a categorized manner. In addition, the study\ndiscusses how other technological paradigms including big data, artificial\nintelligence, and internet of things can be exploited to advance the potentials\nof PM. Furthermore, the paper provides some guidelines for future research for\nseamless implementation and wide-scale deployment of PM based on identified\nopen issues and associated challenges. To this end, the paper proposes an\nintegrated holistic framework for PM motivating informatics researchers to\ndesign their relevant research works in an appropriate context.\n", "versions": [{"version": "v1", "created": "Mon, 4 Nov 2019 02:40:00 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Afzal", "Muhammad", ""], ["Islam", "S. M. Riazul", ""], ["Hussain", "Maqbool", ""], ["Lee", "Sungyoung", ""]]}, {"id": "1911.01058", "submitter": "Sheng Shi", "authors": "Sheng Shi, Xinfeng Zhang and Wei Fan", "title": "Explaining the Predictions of Any Image Classifier via Decision Trees", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite outstanding contribution to the significant progress of Artificial\nIntelligence (AI), deep learning models remain mostly black boxes, which are\nextremely weak in explainability of the reasoning process and prediction\nresults. Explainability is not only a gateway between AI and society but also a\npowerful tool to detect flaws in the model and biases in the data. Local\nInterpretable Model-agnostic Explanation (LIME) is a recent approach that uses\nan interpretable model to form a local explanation for the individual\nprediction result. The current implementation of LIME adopts the linear\nregression as its interpretable function. However, being so restricted and\nusually over-simplifying the relationships, linear models fail in situations\nwhere nonlinear associations and interactions exist among features and\nprediction results. This paper implements a decision Tree-based LIME approach,\nwhich uses a decision tree model to form an interpretable representation that\nis locally faithful to the original model. Tree-LIME approach can capture\nnonlinear interactions among features in the data and creates plausible\nexplanations. Various experiments show that the Tree-LIME explanation of\nmultiple black-box models can achieve more reliable performance in terms of\nunderstandability, fidelity, and efficiency.\n", "versions": [{"version": "v1", "created": "Mon, 4 Nov 2019 07:31:30 GMT"}, {"version": "v2", "created": "Mon, 10 Feb 2020 01:20:25 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Shi", "Sheng", ""], ["Zhang", "Xinfeng", ""], ["Fan", "Wei", ""]]}, {"id": "1911.01072", "submitter": "Byung Hyung Kim", "authors": "Byung Hyung Kim and Sungho Jo", "title": "Wearable Affective Life-Log System for Understanding Emotion Dynamics in\n  Daily Life", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.HC cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Past research on recognizing human affect has made use of a variety of\nphysiological sensors in many ways. Nonetheless, how affective dynamics are\ninfluenced in the context of human daily life has not yet been explored. In\nthis work, we present a wearable affective life-log system (ALIS), that is\nrobust as well as easy to use in daily life to detect emotional changes and\ndetermine their cause-and-effect relationship on users' lives. The proposed\nsystem records how a user feels in certain situations during long-term\nactivities with physiological sensors. Based on the long-term monitoring, the\nsystem analyzes how the contexts of the user's life affect his/her emotion\nchanges. Furthermore, real-world experimental results demonstrate that the\nproposed wearable life-log system enables us to build causal structures to find\neffective stress relievers suited to every stressful situation in school life.\n", "versions": [{"version": "v1", "created": "Mon, 4 Nov 2019 08:35:51 GMT"}, {"version": "v2", "created": "Tue, 5 Nov 2019 20:31:00 GMT"}], "update_date": "2019-11-07", "authors_parsed": [["Kim", "Byung Hyung", ""], ["Jo", "Sungho", ""]]}, {"id": "1911.01086", "submitter": "Hugo Cisneros", "authors": "Hugo Cisneros, Josef Sivic, Tomas Mikolov", "title": "Evolving Structures in Complex Systems", "comments": "IEEE Symposium Series on Computational Intelligence 2019 (IEEE SSCI\n  2019)", "journal-ref": "Proceedings of the 2019 IEEE Symposium Series on Computational\n  Intelligence", "doi": null, "report-no": null, "categories": "nlin.CG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we propose an approach for measuring growth of complexity of\nemerging patterns in complex systems such as cellular automata. We discuss\nseveral ways how a metric for measuring the complexity growth can be defined.\nThis includes approaches based on compression algorithms and artificial neural\nnetworks. We believe such a metric can be useful for designing systems that\ncould exhibit open-ended evolution, which itself might be a prerequisite for\ndevelopment of general artificial intelligence. We conduct experiments on 1D\nand 2D grid worlds and demonstrate that using the proposed metric we can\nautomatically construct computational models with emerging properties similar\nto those found in the Conway's Game of Life, as well as many other emergent\nphenomena. Interestingly, some of the patterns we observe resemble forms of\nartificial life. Our metric of structural complexity growth can be applied to a\nwide range of complex systems, as it is not limited to cellular automata.\n", "versions": [{"version": "v1", "created": "Mon, 4 Nov 2019 09:35:54 GMT"}, {"version": "v2", "created": "Wed, 18 Mar 2020 11:59:49 GMT"}], "update_date": "2020-03-19", "authors_parsed": [["Cisneros", "Hugo", ""], ["Sivic", "Josef", ""], ["Mikolov", "Tomas", ""]]}, {"id": "1911.01103", "submitter": "Stephen James", "authors": "Alessandro Bonardi, Stephen James, Andrew J. Davison", "title": "Learning One-Shot Imitation from Humans without Humans", "comments": "Videos can be found here:\n  https://sites.google.com/view/tecnets-humans", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Humans can naturally learn to execute a new task by seeing it performed by\nother individuals once, and then reproduce it in a variety of configurations.\nEndowing robots with this ability of imitating humans from third person is a\nvery immediate and natural way of teaching new tasks. Only recently, through\nmeta-learning, there have been successful attempts to one-shot imitation\nlearning from humans; however, these approaches require a lot of human\nresources to collect the data in the real world to train the robot. But is\nthere a way to remove the need for real world human demonstrations during\ntraining? We show that with Task-Embedded Control Networks, we can infer\ncontrol polices by embedding human demonstrations that can condition a control\npolicy and achieve one-shot imitation learning. Importantly, we do not use a\nreal human arm to supply demonstrations during training, but instead leverage\ndomain randomisation in an application that has not been seen before:\nsim-to-real transfer on humans. Upon evaluating our approach on pushing and\nplacing tasks in both simulation and in the real world, we show that in\ncomparison to a system that was trained on real-world data we are able to\nachieve similar results by utilising only simulation data.\n", "versions": [{"version": "v1", "created": "Mon, 4 Nov 2019 10:07:27 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Bonardi", "Alessandro", ""], ["James", "Stephen", ""], ["Davison", "Andrew J.", ""]]}, {"id": "1911.01156", "submitter": "Alun Preece", "authors": "Frank Stein, Alun Preece", "title": "AAAI FSS-19: Artificial Intelligence in Government and Public Sector\n  Proceedings", "comments": "Post-symposium proceedings including 18 papers", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Proceedings of the AAAI Fall Symposium on Artificial Intelligence in\nGovernment and Public Sector, Arlington, Virginia, USA, November 7-8, 2019\n", "versions": [{"version": "v1", "created": "Mon, 4 Nov 2019 12:26:51 GMT"}, {"version": "v2", "created": "Thu, 28 Nov 2019 08:07:11 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Stein", "Frank", ""], ["Preece", "Alun", ""]]}, {"id": "1911.01157", "submitter": "Luis Gal\\'arraga", "authors": "Luis Gal\\'arraga and Julien Delaunay and Jean-Louis Dessalles", "title": "REMI: Mining Intuitive Referring Expressions on Knowledge Bases", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  A referring expression (RE) is a description that identifies a set of\ninstances unambiguously. Mining REs from data finds applications in natural\nlanguage generation, algorithmic journalism, and data maintenance. Since there\nmay exist multiple REs for a given set of entities, it is common to focus on\nthe most intuitive ones, i.e., the most concise and informative. In this paper\nwe present REMI, a system that can mine intuitive REs on large RDF knowledge\nbases. Our experimental evaluation shows that REMI finds REs deemed intuitive\nby users. Moreover we show that REMI is several orders of magnitude faster than\nan approach based on inductive logic programming.\n", "versions": [{"version": "v1", "created": "Mon, 4 Nov 2019 12:30:33 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Gal\u00e1rraga", "Luis", ""], ["Delaunay", "Julien", ""], ["Dessalles", "Jean-Louis", ""]]}, {"id": "1911.01158", "submitter": "Byung Hyung Kim", "authors": "Byung Hyung Kim and Sungho Jo", "title": "An Affective Situation Labeling System from Psychological Behaviors in\n  Emotion Recognition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper presents a computational framework for providing affective labels\nto real-life situations, called A-Situ. We first define an affective situation,\nas a specific arrangement of affective entities relevant to emotion elicitation\nin a situation. Then, the affective situation is represented as a set of labels\nin the valence-arousal emotion space. Based on physiological behaviors in\nresponse to a situation, the proposed framework quantifies the expected emotion\nevoked by the interaction with a stimulus event. The accumulated result in a\nspatiotemporal situation is represented as a polynomial curve called the\naffective curve, which bridges the semantic gap between cognitive and affective\nperception in real-world situations. We show the efficacy of the curve for\nreliable emotion labeling in real-world experiments, respectively concerning 1)\na comparison between the results from our system and existing explicit\nassessments for measuring emotion, 2) physiological distinctiveness in\nemotional states, and 3) physiological characteristics correlated to continuous\nlabels. The efficiency of affective curves to discriminate emotional states is\nevaluated through subject-dependent classification performance using\nbicoherence features to represent discrete affective states in the\nvalence-arousal space. Furthermore, electroencephalography-based statistical\nanalysis revealed the physiological correlates of the affective curves.\n", "versions": [{"version": "v1", "created": "Mon, 4 Nov 2019 12:32:10 GMT"}, {"version": "v2", "created": "Tue, 5 Nov 2019 20:26:04 GMT"}], "update_date": "2019-11-07", "authors_parsed": [["Kim", "Byung Hyung", ""], ["Jo", "Sungho", ""]]}, {"id": "1911.01185", "submitter": "Sosuke Moriguchi", "authors": "Sosuke Moriguchi and Kazuko Takahashi", "title": "Compiling Arguments in an Argumentation Framework into Three-valued\n  Logical Expressions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a new method for computing general allocators\ndirectly from completeness conditions. A general allocator is an abstraction of\nall complete labelings for an argumentation framework. Any complete labeling is\nobtained from a general allocator by assigning logical constants to variables.\nWe proved the existence of the general allocators in our previous work.\nHowever, the construction requires us to enumerate all complete labelings for\nthe framework, which makes the computation prohibitively slow. The method\nproposed in this paper enables us to compute general allocators without\nenumerating complete labelings. It also provides the solutions of local\nallocation that yield semantics for subsets of the framework. We demonstrate\ntwo applications of general allocators, stability, and a new concept for\nframeworks, termed arity. Moreover, the method, including local allocation, is\napplicable to broad extensions of frameworks, such as argumentation frameworks\nwith set-attacks, bipolar argumentation frameworks, and abstract dialectical\nframeworks.\n", "versions": [{"version": "v1", "created": "Mon, 4 Nov 2019 13:19:19 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Moriguchi", "Sosuke", ""], ["Takahashi", "Kazuko", ""]]}, {"id": "1911.01205", "submitter": "Daniel Tarlow", "authors": "Daniel Tarlow, Subhodeep Moitra, Andrew Rice, Zimin Chen,\n  Pierre-Antoine Manzagol, Charles Sutton, Edward Aftandilian", "title": "Learning to Fix Build Errors with Graph2Diff Neural Networks", "comments": "Submitted for review on Aug 23, 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.SE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Professional software developers spend a significant amount of time fixing\nbuilds, but this has received little attention as a problem in automatic\nprogram repair. We present a new deep learning architecture, called Graph2Diff,\nfor automatically localizing and fixing build errors. We represent source code,\nbuild configuration files, and compiler diagnostic messages as a graph, and\nthen use a Graph Neural Network model to predict a diff. A diff specifies how\nto modify the code's abstract syntax tree, represented in the neural network as\na sequence of tokens and of pointers to code locations. Our network is an\ninstance of a more general abstraction that we call Graph2Tocopo, which is\npotentially useful in any development tool for predicting source code changes.\nWe evaluate the model on a dataset of over 500k real build errors and their\nresolutions from professional developers. Compared to the approach of DeepDelta\n(Mesbah et al., 2019), our approach tackles the harder task of predicting a\nmore precise diff but still achieves over double the accuracy.\n", "versions": [{"version": "v1", "created": "Mon, 4 Nov 2019 13:40:27 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Tarlow", "Daniel", ""], ["Moitra", "Subhodeep", ""], ["Rice", "Andrew", ""], ["Chen", "Zimin", ""], ["Manzagol", "Pierre-Antoine", ""], ["Sutton", "Charles", ""], ["Aftandilian", "Edward", ""]]}, {"id": "1911.01217", "submitter": "Nikhil Oswal", "authors": "Deepshi Mediratta and Nikhil Oswal", "title": "Detect Toxic Content to Improve Online Conversations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Social media is filled with toxic content. The aim of this paper is to build\na model that can detect insincere questions. We use the 'Quora Insincere\nQuestions Classification' dataset for our analysis. The dataset is composed of\nsincere and insincere questions, with the majority of sincere questions. The\ndataset is processed and analyzed using Python and its libraries such as\nsklearn, numpy, pandas, keras etc. The dataset is converted to vector form\nusing word embeddings such as GloVe, Wiki-news and TF-IDF. The imbalance in the\ndataset is handled by resampling techniques. We train and compare various\nmachine learning and deep learning models to come up with the best results.\nModels discussed include SVM, Naive Bayes, GRU and LSTM.\n", "versions": [{"version": "v1", "created": "Tue, 29 Oct 2019 01:42:22 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Mediratta", "Deepshi", ""], ["Oswal", "Nikhil", ""]]}, {"id": "1911.01366", "submitter": "Chainarong Amornbunchornvej", "authors": "Chainarong Amornbunchornvej and Tanya Berger-Wolf", "title": "Framework for Inferring Following Strategies from Time Series of\n  Movement Data", "comments": "This is the revised version of the preprint entitled \"Inferring\n  Coordination Strategies from Time Series of Movement Data\" following\n  reviewers' suggestions", "journal-ref": "ACM Transactions on Knowledge Discovery from Data (TKDD), 14(3),\n  35 (2020)", "doi": "10.1145/3385730", "report-no": null, "categories": "stat.ML cs.AI cs.LG cs.MA physics.data-an", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  How do groups of individuals achieve consensus in movement decisions? Do\nindividuals follow their friends, the one predetermined leader, or whomever\njust happens to be nearby? To address these questions computationally, we\nformalize \"Coordination Strategy Inference Problem\". In this setting, a group\nof multiple individuals moves in a coordinated manner towards a target path.\nEach individual uses a specific strategy to follow others (e.g. nearest\nneighbors, pre-defined leaders, preferred friends). Given a set of time series\nthat includes coordinated movement and a set of candidate strategies as inputs,\nwe provide the first methodology (to the best of our knowledge) to infer\nwhether each individual uses local-agreement-system or dictatorship-like\nstrategy to achieve movement coordination at the group level. We evaluate and\ndemonstrate the performance of the proposed framework by predicting the\ndirection of movement of an individual in a group in both simulated datasets as\nwell as two real-world datasets: a school of fish and a troop of baboons.\nMoreover, since there is no prior methodology for inferring individual-level\nstrategies, we compare our framework with the state-of-the-art approach for the\ntask of classification of group-level-coordination models. The results show\nthat our approach is highly accurate in inferring the correct strategy in\nsimulated datasets even in complicated mixed strategy settings, which no\nexisting method can infer. In the task of classification of\ngroup-level-coordination models, our framework performs better than the\nstate-of-the-art approach in all datasets. Animal data experiments show that\nfish, as expected, follow their neighbors, while baboons have a preference to\nfollow specific individuals. Our methodology generalizes to arbitrary time\nseries data of real numbers, beyond movement data.\n", "versions": [{"version": "v1", "created": "Mon, 4 Nov 2019 17:51:23 GMT"}, {"version": "v2", "created": "Sun, 12 Jan 2020 09:46:22 GMT"}], "update_date": "2020-05-20", "authors_parsed": [["Amornbunchornvej", "Chainarong", ""], ["Berger-Wolf", "Tanya", ""]]}, {"id": "1911.01417", "submitter": "Alexander Trott", "authors": "Alexander Trott, Stephan Zheng, Caiming Xiong, Richard Socher", "title": "Keeping Your Distance: Solving Sparse Reward Tasks Using Self-Balancing\n  Shaped Rewards", "comments": "NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While using shaped rewards can be beneficial when solving sparse reward\ntasks, their successful application often requires careful engineering and is\nproblem specific. For instance, in tasks where the agent must achieve some goal\nstate, simple distance-to-goal reward shaping often fails, as it renders\nlearning vulnerable to local optima. We introduce a simple and effective\nmodel-free method to learn from shaped distance-to-goal rewards on tasks where\nsuccess depends on reaching a goal state. Our method introduces an auxiliary\ndistance-based reward based on pairs of rollouts to encourage diverse\nexploration. This approach effectively prevents learning dynamics from\nstabilizing around local optima induced by the naive distance-to-goal reward\nshaping and enables policies to efficiently solve sparse reward tasks. Our\naugmented objective does not require any additional reward engineering or\ndomain expertise to implement and converges to the original sparse objective as\nthe agent learns to solve the task. We demonstrate that our method successfully\nsolves a variety of hard-exploration tasks (including maze navigation and 3D\nconstruction in a Minecraft environment), where naive distance-based reward\nshaping otherwise fails, and intrinsic curiosity and reward relabeling\nstrategies exhibit poor performance.\n", "versions": [{"version": "v1", "created": "Mon, 4 Nov 2019 18:58:06 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Trott", "Alexander", ""], ["Zheng", "Stephan", ""], ["Xiong", "Caiming", ""], ["Socher", "Richard", ""]]}, {"id": "1911.01468", "submitter": "Viktoriia Oliinyk", "authors": "Giulio Morina, Viktoriia Oliinyk, Julian Waton, Ines Marusic and\n  Konstantinos Georgatzis", "title": "Auditing and Achieving Intersectional Fairness in Classification\n  Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning algorithms are extensively used to make increasingly more\nconsequential decisions about people, so achieving optimal predictive\nperformance can no longer be the only focus. A particularly important\nconsideration is fairness with respect to race, gender, or any other sensitive\nattribute. This paper studies intersectional fairness, where intersections of\nmultiple sensitive attributes are considered. Prior research has mainly focused\non fairness with respect to a single sensitive attribute, with intersectional\nfairness being comparatively less studied despite its critical importance for\nthe safety of modern machine learning systems. We present a comprehensive\nframework for auditing and achieving intersectional fairness in classification\nproblems: we define a suite of metrics to assess intersectional fairness in the\ndata or model outputs by extending known single-attribute fairness metrics, and\npropose methods for robustly estimating them even when some intersectional\nsubgroups are underrepresented. Furthermore, we develop post-processing\ntechniques to mitigate any detected intersectional bias in a classification\nmodel. Our techniques do not rely on any assumptions regarding the underlying\nmodel and preserve predictive performance at a guaranteed level of fairness.\nFinally, we give guidance on a practical implementation, showing how the\nproposed methods perform on a real-world dataset.\n", "versions": [{"version": "v1", "created": "Mon, 4 Nov 2019 19:55:23 GMT"}, {"version": "v2", "created": "Mon, 8 Jun 2020 16:41:23 GMT"}], "update_date": "2020-06-09", "authors_parsed": [["Morina", "Giulio", ""], ["Oliinyk", "Viktoriia", ""], ["Waton", "Julian", ""], ["Marusic", "Ines", ""], ["Georgatzis", "Konstantinos", ""]]}, {"id": "1911.01474", "submitter": "Alborz Rezazadeh Sereshkeh", "authors": "Alborz Rezazadeh Sereshkeh, Gary Leung, Krish Perumal, Caleb Phillips,\n  Minfan Zhang, Afsaneh Fazly, Iqbal Mohomed", "title": "VASTA: A Vision and Language-assisted Smartphone Task Automation System", "comments": "Submitted to ACM IUI'20, 10 figures, 11 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI cs.CL cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present VASTA, a novel vision and language-assisted Programming By\nDemonstration (PBD) system for smartphone task automation. Development of a\nrobust PBD automation system requires overcoming three key challenges: first,\nhow to make a particular demonstration robust to positional and visual changes\nin the user interface (UI) elements; secondly, how to recognize changes in the\nautomation parameters to make the demonstration as generalizable as possible;\nand thirdly, how to recognize from the user utterance what automation the user\nwishes to carry out. To address the first challenge, VASTA leverages\nstate-of-the-art computer vision techniques, including object detection and\noptical character recognition, to accurately label interactions demonstrated by\na user, without relying on the underlying UI structures. To address the second\nand third challenges, VASTA takes advantage of advanced natural language\nunderstanding algorithms for analyzing the user utterance to trigger the VASTA\nautomation scripts, and to determine the automation parameters for\ngeneralization. We run an initial user study that demonstrates the\neffectiveness of VASTA at clustering user utterances, understanding changes in\nthe automation parameters, detecting desired UI elements, and, most\nimportantly, automating various tasks. A demo video of the system is available\nhere: http://y2u.be/kr2xE-FixjI\n", "versions": [{"version": "v1", "created": "Mon, 4 Nov 2019 20:21:32 GMT"}], "update_date": "2019-11-06", "authors_parsed": [["Sereshkeh", "Alborz Rezazadeh", ""], ["Leung", "Gary", ""], ["Perumal", "Krish", ""], ["Phillips", "Caleb", ""], ["Zhang", "Minfan", ""], ["Fazly", "Afsaneh", ""], ["Mohomed", "Iqbal", ""]]}, {"id": "1911.01485", "submitter": "Yi Chern Tan", "authors": "Yi Chern Tan, L. Elisa Celis", "title": "Assessing Social and Intersectional Biases in Contextualized Word\n  Representations", "comments": "NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.CY cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Social bias in machine learning has drawn significant attention, with work\nranging from demonstrations of bias in a multitude of applications, curating\ndefinitions of fairness for different contexts, to developing algorithms to\nmitigate bias. In natural language processing, gender bias has been shown to\nexist in context-free word embeddings. Recently, contextual word\nrepresentations have outperformed word embeddings in several downstream NLP\ntasks. These word representations are conditioned on their context within a\nsentence, and can also be used to encode the entire sentence. In this paper, we\nanalyze the extent to which state-of-the-art models for contextual word\nrepresentations, such as BERT and GPT-2, encode biases with respect to gender,\nrace, and intersectional identities. Towards this, we propose assessing bias at\nthe contextual word level. This novel approach captures the contextual effects\nof bias missing in context-free word embeddings, yet avoids confounding effects\nthat underestimate bias at the sentence encoding level. We demonstrate evidence\nof bias at the corpus level, find varying evidence of bias in embedding\nassociation tests, show in particular that racial bias is strongly encoded in\ncontextual word models, and observe that bias effects for intersectional\nminorities are exacerbated beyond their constituent minority identities.\nFurther, evaluating bias effects at the contextual word level captures biases\nthat are not captured at the sentence level, confirming the need for our novel\napproach.\n", "versions": [{"version": "v1", "created": "Mon, 4 Nov 2019 20:57:54 GMT"}], "update_date": "2019-11-06", "authors_parsed": [["Tan", "Yi Chern", ""], ["Celis", "L. Elisa", ""]]}, {"id": "1911.01546", "submitter": "Ramtin Keramati", "authors": "Ramtin Keramati, Christoph Dann, Alex Tamkin, Emma Brunskill", "title": "Being Optimistic to Be Conservative: Quickly Learning a CVaR Policy", "comments": null, "journal-ref": "Thirty-Fourth AAAI Conference on Artificial Intelligence (AAAI\n  2020)", "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While maximizing expected return is the goal in most reinforcement learning\napproaches, risk-sensitive objectives such as conditional value at risk (CVaR)\nare more suitable for many high-stakes applications. However, relatively little\nis known about how to explore to quickly learn policies with good CVaR. In this\npaper, we present the first algorithm for sample-efficient learning of\nCVaR-optimal policies in Markov decision processes based on the optimism in the\nface of uncertainty principle. This method relies on a novel optimistic version\nof the distributional Bellman operator that moves probability mass from the\nlower to the upper tail of the return distribution. We prove asymptotic\nconvergence and optimism of this operator for the tabular policy evaluation\ncase. We further demonstrate that our algorithm finds CVaR-optimal policies\nsubstantially faster than existing baselines in several simulated environments\nwith discrete and continuous state spaces.\n", "versions": [{"version": "v1", "created": "Tue, 5 Nov 2019 00:28:07 GMT"}, {"version": "v2", "created": "Thu, 2 Apr 2020 19:25:02 GMT"}], "update_date": "2020-04-06", "authors_parsed": [["Keramati", "Ramtin", ""], ["Dann", "Christoph", ""], ["Tamkin", "Alex", ""], ["Brunskill", "Emma", ""]]}, {"id": "1911.01547", "submitter": "Francois Chollet", "authors": "Fran\\c{c}ois Chollet", "title": "On the Measure of Intelligence", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To make deliberate progress towards more intelligent and more human-like\nartificial systems, we need to be following an appropriate feedback signal: we\nneed to be able to define and evaluate intelligence in a way that enables\ncomparisons between two systems, as well as comparisons with humans. Over the\npast hundred years, there has been an abundance of attempts to define and\nmeasure intelligence, across both the fields of psychology and AI. We summarize\nand critically assess these definitions and evaluation approaches, while making\napparent the two historical conceptions of intelligence that have implicitly\nguided them. We note that in practice, the contemporary AI community still\ngravitates towards benchmarking intelligence by comparing the skill exhibited\nby AIs and humans at specific tasks such as board games and video games. We\nargue that solely measuring skill at any given task falls short of measuring\nintelligence, because skill is heavily modulated by prior knowledge and\nexperience: unlimited priors or unlimited training data allow experimenters to\n\"buy\" arbitrary levels of skills for a system, in a way that masks the system's\nown generalization power. We then articulate a new formal definition of\nintelligence based on Algorithmic Information Theory, describing intelligence\nas skill-acquisition efficiency and highlighting the concepts of scope,\ngeneralization difficulty, priors, and experience. Using this definition, we\npropose a set of guidelines for what a general AI benchmark should look like.\nFinally, we present a benchmark closely following these guidelines, the\nAbstraction and Reasoning Corpus (ARC), built upon an explicit set of priors\ndesigned to be as close as possible to innate human priors. We argue that ARC\ncan be used to measure a human-like form of general fluid intelligence and that\nit enables fair general intelligence comparisons between AI systems and humans.\n", "versions": [{"version": "v1", "created": "Tue, 5 Nov 2019 00:31:38 GMT"}, {"version": "v2", "created": "Mon, 25 Nov 2019 13:02:04 GMT"}], "update_date": "2019-11-26", "authors_parsed": [["Chollet", "Fran\u00e7ois", ""]]}, {"id": "1911.01562", "submitter": "Bharathan Balaji", "authors": "Bharathan Balaji, Sunil Mallya, Sahika Genc, Saurabh Gupta, Leo Dirac,\n  Vineet Khare, Gourav Roy, Tao Sun, Yunzhe Tao, Brian Townsend, Eddie Calleja,\n  Sunil Muralidhara, Dhanasekar Karuppasamy", "title": "DeepRacer: Educational Autonomous Racing Platform for Experimentation\n  with Sim2Real Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  DeepRacer is a platform for end-to-end experimentation with RL and can be\nused to systematically investigate the key challenges in developing intelligent\ncontrol systems. Using the platform, we demonstrate how a 1/18th scale car can\nlearn to drive autonomously using RL with a monocular camera. It is trained in\nsimulation with no additional tuning in physical world and demonstrates: 1)\nformulation and solution of a robust reinforcement learning algorithm, 2)\nnarrowing the reality gap through joint perception and dynamics, 3) distributed\non-demand compute architecture for training optimal policies, and 4) a robust\nevaluation method to identify when to stop training. It is the first successful\nlarge-scale deployment of deep reinforcement learning on a robotic control\nagent that uses only raw camera images as observations and a model-free\nlearning method to perform robust path planning. We open source our code and\nvideo demo on GitHub: https://git.io/fjxoJ.\n", "versions": [{"version": "v1", "created": "Tue, 5 Nov 2019 01:40:42 GMT"}], "update_date": "2019-11-06", "authors_parsed": [["Balaji", "Bharathan", ""], ["Mallya", "Sunil", ""], ["Genc", "Sahika", ""], ["Gupta", "Saurabh", ""], ["Dirac", "Leo", ""], ["Khare", "Vineet", ""], ["Roy", "Gourav", ""], ["Sun", "Tao", ""], ["Tao", "Yunzhe", ""], ["Townsend", "Brian", ""], ["Calleja", "Eddie", ""], ["Muralidhara", "Sunil", ""], ["Karuppasamy", "Dhanasekar", ""]]}, {"id": "1911.01599", "submitter": "Nikolai Rozanov", "authors": "Edward Collins, Nikolai Rozanov, Bingbing Zhang", "title": "LIDA: Lightweight Interactive Dialogue Annotator", "comments": "9 pages, 7 figures, 1 table, EMNLP 2019", "journal-ref": "ACL, EMNLP(D19-3021), 121--126, (2019)", "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Dialogue systems have the potential to change how people interact with\nmachines but are highly dependent on the quality of the data used to train\nthem. It is therefore important to develop good dialogue annotation tools which\ncan improve the speed and quality of dialogue data annotation. With this in\nmind, we introduce LIDA, an annotation tool designed specifically for\nconversation data. As far as we know, LIDA is the first dialogue annotation\nsystem that handles the entire dialogue annotation pipeline from raw text, as\nmay be the output of transcription services, to structured conversation data.\nFurthermore it supports the integration of arbitrary machine learning models as\nannotation recommenders and also has a dedicated interface to resolve\ninter-annotator disagreements such as after crowdsourcing annotations for a\ndataset. LIDA is fully open source, documented and publicly available [\nhttps://github.com/Wluper/lida ]\n", "versions": [{"version": "v1", "created": "Tue, 5 Nov 2019 03:49:20 GMT"}], "update_date": "2019-11-06", "authors_parsed": [["Collins", "Edward", ""], ["Rozanov", "Nikolai", ""], ["Zhang", "Bingbing", ""]]}, {"id": "1911.01678", "submitter": "Amir Pouran Ben Veyseh", "authors": "Amir Pouran Ben Veyseh, Franck Dernoncourt, Dejing Dou, Thien Huu\n  Nguyen", "title": "A Joint Model for Definition Extraction with Syntactic Connection and\n  Semantic Consistency", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Definition Extraction (DE) is one of the well-known topics in Information\nExtraction that aims to identify terms and their corresponding definitions in\nunstructured texts. This task can be formalized either as a sentence\nclassification task (i.e., containing term-definition pairs or not) or a\nsequential labeling task (i.e., identifying the boundaries of the terms and\ndefinitions). The previous works for DE have only focused on one of the two\napproaches, failing to model the inter-dependencies between the two tasks. In\nthis work, we propose a novel model for DE that simultaneously performs the two\ntasks in a single framework to benefit from their inter-dependencies. Our model\nfeatures deep learning architectures to exploit the global structures of the\ninput sentences as well as the semantic consistencies between the terms and the\ndefinitions, thereby improving the quality of the representation vectors for\nDE. Besides the joint inference between sentence classification and sequential\nlabeling, the proposed model is fundamentally different from the prior work for\nDE in that the prior work has only employed the local structures of the input\nsentences (i.e., word-to-word relations), and not yet considered the semantic\nconsistencies between terms and definitions. In order to implement these novel\nideas, our model presents a multi-task learning framework that employs graph\nconvolutional neural networks and predicts the dependency paths between the\nterms and the definitions. We also seek to enforce the consistency between the\nrepresentations of the terms and definitions both globally (i.e., increasing\nsemantic consistency between the representations of the entire sentences and\nthe terms/definitions) and locally (i.e., promoting the similarity between the\nrepresentations of the terms and the definitions).\n", "versions": [{"version": "v1", "created": "Tue, 5 Nov 2019 09:23:58 GMT"}, {"version": "v2", "created": "Fri, 8 Nov 2019 20:28:01 GMT"}, {"version": "v3", "created": "Sun, 17 Nov 2019 23:54:37 GMT"}, {"version": "v4", "created": "Wed, 29 Apr 2020 19:24:15 GMT"}], "update_date": "2020-05-01", "authors_parsed": [["Veyseh", "Amir Pouran Ben", ""], ["Dernoncourt", "Franck", ""], ["Dou", "Dejing", ""], ["Nguyen", "Thien Huu", ""]]}, {"id": "1911.01680", "submitter": "Amir Pouran Ben Veyseh", "authors": "Amir Pouran Ben Veyseh, Franck Dernoncourt, Thien Huu Nguyen", "title": "Improving Slot Filling by Utilizing Contextual Information", "comments": "Accepted at NLP4ConvAI Workshop at ACL2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Slot Filling (SF) is one of the sub-tasks of Spoken Language Understanding\n(SLU) which aims to extract semantic constituents from a given natural language\nutterance. It is formulated as a sequence labeling task. Recently, it has been\nshown that contextual information is vital for this task. However, existing\nmodels employ contextual information in a restricted manner, e.g., using\nself-attention. Such methods fail to distinguish the effects of the context on\nthe word representation and the word label. To address this issue, in this\npaper, we propose a novel method to incorporate the contextual information in\ntwo different levels, i.e., representation level and task-specific (i.e.,\nlabel) level. Our extensive experiments on three benchmark datasets on SF show\nthe effectiveness of our model leading to new state-of-the-art results on all\nthree benchmark datasets for the task of SF.\n", "versions": [{"version": "v1", "created": "Tue, 5 Nov 2019 09:29:07 GMT"}, {"version": "v2", "created": "Sat, 30 May 2020 06:32:43 GMT"}], "update_date": "2020-06-02", "authors_parsed": [["Veyseh", "Amir Pouran Ben", ""], ["Dernoncourt", "Franck", ""], ["Nguyen", "Thien Huu", ""]]}, {"id": "1911.01774", "submitter": "Shu Qi Liu", "authors": "Shuqi Liu and Zhaoxia Wu", "title": "Efficient Multi-robot Exploration via Multi-head Attention-based\n  Cooperation Strategy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The goal of coordinated multi-robot exploration tasks is to employ a team of\nautonomous robots to explore an unknown environment as quickly as possible.\nCompared with human-designed methods, which began with heuristic and rule-based\napproaches, learning-based methods enable individual robots to learn\nsophisticated and hard-to-design cooperation strategies through deep\nreinforcement learning technologies. However, in decentralized multi-robot\nexploration tasks, learning-based algorithms are still far from being\nuniversally applicable to the continuous space due to the difficulties\nassociated with area calculation and reward function designing; moreover,\nexisting learning-based methods encounter problems when attempting to balance\nthe historical trajectory issue and target area conflict problem. Furthermore,\nthe scalability of these methods to a large number of agents is poor because of\nthe exponential explosion problem of state space. Accordingly, this paper\nproposes a novel approach - Multi-head Attention-based Multi-robot Exploration\nin Continuous Space (MAMECS) - aimed at reducing the state space and\nautomatically learning the cooperation strategies required for decentralized\nmulti-robot exploration tasks in continuous space. Computational geometry\nknowledge is applied to describe the environment in continuous space and to\ndesign an improved reward function to ensure a superior exploration rate.\nMoreover, the multi-head attention mechanism employed helps to solve the\nhistorical trajectory issue in the decentralized multi-robot exploration task,\nas well as to reduce the quadratic increase of action space.\n", "versions": [{"version": "v1", "created": "Tue, 5 Nov 2019 13:56:07 GMT"}], "update_date": "2019-11-06", "authors_parsed": [["Liu", "Shuqi", ""], ["Wu", "Zhaoxia", ""]]}, {"id": "1911.01875", "submitter": "Lora Aroyo", "authors": "Chris Welty, Praveen Paritosh, Lora Aroyo", "title": "Metrology for AI: From Benchmarks to Instruments", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we present the first steps towards hardening the science of\nmeasuring AI systems, by adopting metrology, the science of measurement and its\napplication, and applying it to human (crowd) powered evaluations. We begin\nwith the intuitive observation that evaluating the performance of an AI system\nis a form of measurement. In all other science and engineering disciplines, the\ndevices used to measure are called instruments, and all measurements are\nrecorded with respect to the characteristics of the instruments used. One does\nnot report mass, speed, or length, for example, of a studied object without\ndisclosing the precision (measurement variance) and resolution (smallest\ndetectable change) of the instrument used. It is extremely common in the AI\nliterature to compare the performance of two systems by using a crowd-sourced\ndataset as an instrument, but failing to report if the performance difference\nlies within the capability of that instrument to measure. To illustrate the\nadoption of metrology to benchmark datasets we use the word similarity\nbenchmark WS353 and several previously published experiments that use it for\nevaluation.\n", "versions": [{"version": "v1", "created": "Tue, 5 Nov 2019 15:30:08 GMT"}], "update_date": "2019-11-06", "authors_parsed": [["Welty", "Chris", ""], ["Paritosh", "Praveen", ""], ["Aroyo", "Lora", ""]]}, {"id": "1911.01892", "submitter": "Roberto Dess\\`i", "authors": "Roberto Dess\\`i, Diane Bouchacourt, Davide Crepaldi, Marco Baroni", "title": "Focus on What's Informative and Ignore What's not: Communication\n  Strategies in a Referential Game", "comments": "3rd NeurIPS Workshop on Emergent Communication", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Research in multi-agent cooperation has shown that artificial agents are able\nto learn to play a simple referential game while developing a shared lexicon.\nThis lexicon is not easy to analyze, as it does not show many properties of a\nnatural language. In a simple referential game with two neural network-based\nagents, we analyze the object-symbol mapping trying to understand what kind of\nstrategy was used to develop the emergent language. We see that, when the\nenvironment is uniformly distributed, the agents rely on a random subset of\nfeatures to describe the objects. When we modify the objects making one feature\nnon-uniformly distributed,the agents realize it is less informative and start\nto ignore it, and, surprisingly, they make a better use of the remaining\nfeatures. This interesting result suggests that more natural, less uniformly\ndistributed environments might aid in spurring the emergence of better-behaved\nlanguages.\n", "versions": [{"version": "v1", "created": "Tue, 5 Nov 2019 15:55:19 GMT"}], "update_date": "2019-11-06", "authors_parsed": [["Dess\u00ec", "Roberto", ""], ["Bouchacourt", "Diane", ""], ["Crepaldi", "Davide", ""], ["Baroni", "Marco", ""]]}, {"id": "1911.01917", "submitter": "John Licato", "authors": "John Licato, Zaid Marji, Sophia Abraham", "title": "Scenarios and Recommendations for Ethical Interpretive AI", "comments": "To appear in the Proceedings of the Human-Centered AI:\n  Trustworthiness of AI Models & Data (HAI) track at AAAI Fall Symposium, DC,\n  November 7-9, 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Artificially intelligent systems, given a set of non-trivial ethical rules to\nfollow, will inevitably be faced with scenarios which call into question the\nscope of those rules. In such cases, human reasoners typically will engage in\ninterpretive reasoning, where interpretive arguments are used to support or\nattack claims that some rule should be understood a certain way. Artificially\nintelligent reasoners, however, currently lack the ability to carry out\nhuman-like interpretive reasoning, and we argue that bridging this gulf is of\ntremendous importance to human-centered AI. In order to better understand how\nfuture artificial reasoners capable of human-like interpretive reasoning must\nbe developed, we have collected a dataset of ethical rules, scenarios designed\nto invoke interpretive reasoning, and interpretations of those scenarios. We\nperform a qualitative analysis of our dataset, and summarize our findings in\nthe form of practical recommendations.\n", "versions": [{"version": "v1", "created": "Tue, 5 Nov 2019 16:23:01 GMT"}], "update_date": "2019-11-06", "authors_parsed": [["Licato", "John", ""], ["Marji", "Zaid", ""], ["Abraham", "Sophia", ""]]}, {"id": "1911.01966", "submitter": "Mehdi El Krari", "authors": "Mehdi El Krari, Bela\\\"id Ahiod", "title": "A Memetic Algorithm Based on Breakout Local Search for the Generalized\n  Travelling Salesman Problem", "comments": null, "journal-ref": null, "doi": "10.1080/08839514.2020.1730629", "report-no": null, "categories": "cs.NE cs.AI math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Travelling Salesman Problem (TSP) is one of the most popular\nCombinatorial Optimization Problem. It is well solicited for the large variety\nof applications that it can solve, but also for its difficulty to find optimal\nsolutions. One of the variants of the TSP is the Generalized TSP (GTSP), where\nthe TSP is considered as a special case which makes the GTSP harder to solve.\nWe propose in this paper a new memetic algorithm based on the well-known\nBreakout Local Search (BLS) metaheuristic to provide good solutions for GTSP\ninstances. Our approach is competitive compared to other recent memetic\nalgorithms proposed for the GTSP and gives at the same time some improvements\nto BLS to reduce its runtime.\n", "versions": [{"version": "v1", "created": "Sat, 19 Oct 2019 19:03:38 GMT"}], "update_date": "2020-06-30", "authors_parsed": [["Krari", "Mehdi El", ""], ["Ahiod", "Bela\u00efd", ""]]}, {"id": "1911.02042", "submitter": "Thai Le", "authors": "Thai Le, Suhang Wang, Dongwon Lee", "title": "GRACE: Generating Concise and Informative Contrastive Sample to Explain\n  Neural Network Model's Prediction", "comments": "Accepted at the 26th SIGKDD Conference on Knowledge Discovery and\n  Data Mining (KDD 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the recent development in the topic of explainable AI/ML for image\nand text data, the majority of current solutions are not suitable to explain\nthe prediction of neural network models when the datasets are tabular and their\nfeatures are in high-dimensional vectorized formats. To mitigate this\nlimitation, therefore, we borrow two notable ideas (i.e., \"explanation by\nintervention\" from causality and \"explanation are contrastive\" from philosophy)\nand propose a novel solution, named as GRACE, that better explains neural\nnetwork models' predictions for tabular datasets. In particular, given a\nmodel's prediction as label X, GRACE intervenes and generates a\nminimally-modified contrastive sample to be classified as Y, with an intuitive\ntextual explanation, answering the question of \"Why X rather than Y?\" We carry\nout comprehensive experiments using eleven public datasets of different scales\nand domains (e.g., # of features ranges from 5 to 216) and compare GRACE with\ncompeting baselines on different measures: fidelity, conciseness, info-gain,\nand influence. The user-studies show that our generated explanation is not only\nmore intuitive and easy-to-understand but also facilitates end-users to make as\nmuch as 60% more accurate post-explanation decisions than that of Lime.\n", "versions": [{"version": "v1", "created": "Tue, 5 Nov 2019 19:06:29 GMT"}, {"version": "v2", "created": "Thu, 11 Jun 2020 15:08:19 GMT"}, {"version": "v3", "created": "Sun, 21 Jun 2020 17:49:01 GMT"}, {"version": "v4", "created": "Sun, 27 Sep 2020 10:17:36 GMT"}, {"version": "v5", "created": "Mon, 26 Oct 2020 11:43:03 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Le", "Thai", ""], ["Wang", "Suhang", ""], ["Lee", "Dongwon", ""]]}, {"id": "1911.02060", "submitter": "Pavan Kapanipathi", "authors": "Pavan Kapanipathi, Veronika Thost, Siva Sankalp Patel, Spencer\n  Whitehead, Ibrahim Abdelaziz, Avinash Balakrishnan, Maria Chang, Kshitij\n  Fadnis, Chulaka Gunasekara, Bassem Makni, Nicholas Mattei, Kartik\n  Talamadupula, Achille Fokoue", "title": "Infusing Knowledge into the Textual Entailment Task Using Graph\n  Convolutional Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Textual entailment is a fundamental task in natural language processing. Most\napproaches for solving the problem use only the textual content present in\ntraining data. A few approaches have shown that information from external\nknowledge sources like knowledge graphs (KGs) can add value, in addition to the\ntextual content, by providing background knowledge that may be critical for a\ntask. However, the proposed models do not fully exploit the information in the\nusually large and noisy KGs, and it is not clear how it can be effectively\nencoded to be useful for entailment. We present an approach that complements\ntext-based entailment models with information from KGs by (1) using\nPersonalized PageR- ank to generate contextual subgraphs with reduced noise and\n(2) encoding these subgraphs using graph convolutional networks to capture KG\nstructure. Our technique extends the capability of text models exploiting\nstructural and semantic information found in KGs. We evaluate our approach on\nmultiple textual entailment datasets and show that the use of external\nknowledge helps improve prediction accuracy. This is particularly evident in\nthe challenging BreakingNLI dataset, where we see an absolute improvement of\n5-20% over multiple text-based entailment models.\n", "versions": [{"version": "v1", "created": "Tue, 5 Nov 2019 19:52:34 GMT"}, {"version": "v2", "created": "Fri, 22 Nov 2019 00:20:31 GMT"}], "update_date": "2019-11-25", "authors_parsed": [["Kapanipathi", "Pavan", ""], ["Thost", "Veronika", ""], ["Patel", "Siva Sankalp", ""], ["Whitehead", "Spencer", ""], ["Abdelaziz", "Ibrahim", ""], ["Balakrishnan", "Avinash", ""], ["Chang", "Maria", ""], ["Fadnis", "Kshitij", ""], ["Gunasekara", "Chulaka", ""], ["Makni", "Bassem", ""], ["Mattei", "Nicholas", ""], ["Talamadupula", "Kartik", ""], ["Fokoue", "Achille", ""]]}, {"id": "1911.02065", "submitter": "Ibrahim Abdelaziz", "authors": "Maxwell Crouse, Ibrahim Abdelaziz, Bassem Makni, Spencer Whitehead,\n  Cristina Cornelio, Pavan Kapanipathi, Kavitha Srinivas, Veronika Thost,\n  Michael Witbrock, Achille Fokoue", "title": "A Deep Reinforcement Learning Approach to First-Order Logic Theorem\n  Proving", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automated theorem provers have traditionally relied on manually tuned\nheuristics to guide how they perform proof search. Deep reinforcement learning\nhas been proposed as a way to obviate the need for such heuristics, however,\nits deployment in automated theorem proving remains a challenge. In this paper\nwe introduce TRAIL, a system that applies deep reinforcement learning to\nsaturation-based theorem proving. TRAIL leverages (a) a novel neural\nrepresentation of the state of a theorem prover and (b) a novel\ncharacterization of the inference selection process in terms of an\nattention-based action policy. We show through systematic analysis that these\nmechanisms allow TRAIL to significantly outperform previous\nreinforcement-learning-based theorem provers on two benchmark datasets for\nfirst-order logic automated theorem proving (proving around 15% more theorems).\n", "versions": [{"version": "v1", "created": "Tue, 5 Nov 2019 20:03:58 GMT"}, {"version": "v2", "created": "Thu, 13 Feb 2020 18:14:22 GMT"}, {"version": "v3", "created": "Wed, 16 Sep 2020 01:22:17 GMT"}], "update_date": "2020-09-17", "authors_parsed": [["Crouse", "Maxwell", ""], ["Abdelaziz", "Ibrahim", ""], ["Makni", "Bassem", ""], ["Whitehead", "Spencer", ""], ["Cornelio", "Cristina", ""], ["Kapanipathi", "Pavan", ""], ["Srinivas", "Kavitha", ""], ["Thost", "Veronika", ""], ["Witbrock", "Michael", ""], ["Fokoue", "Achille", ""]]}, {"id": "1911.02085", "submitter": "Kshitij Fadnis", "authors": "Kshitij Fadnis, Kartik Talamadupula, Pavan Kapanipathi, Haque Ishfaq,\n  Salim Roukos, Achille Fokoue", "title": "Path-Based Contextualization of Knowledge Graphs for Textual Entailment", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we introduce the problem of knowledge graph contextualization\n-- that is, given a specific NLP task, the problem of extracting meaningful and\nrelevant sub-graphs from a given knowledge graph. The task in the case of this\npaper is the textual entailment problem, and the context is a relevant\nsub-graph for an instance of the textual entailment problem -- where given two\nsentences p and h, the entailment relationship between them has to be predicted\nautomatically. We base our methodology on finding paths in a cost-customized\nexternal knowledge graph, and building the most relevant sub-graph that\nconnects p and h. We show that our path selection mechanism to generate\nsub-graphs not only reduces noise, but also retrieves meaningful information\nfrom large knowledge graphs. Our evaluation shows that using information on\nentities as well as the relationships between them improves on the performance\nof purely text-based systems.\n", "versions": [{"version": "v1", "created": "Tue, 5 Nov 2019 21:06:04 GMT"}, {"version": "v2", "created": "Tue, 4 Feb 2020 04:17:44 GMT"}], "update_date": "2020-02-05", "authors_parsed": [["Fadnis", "Kshitij", ""], ["Talamadupula", "Kartik", ""], ["Kapanipathi", "Pavan", ""], ["Ishfaq", "Haque", ""], ["Roukos", "Salim", ""], ["Fokoue", "Achille", ""]]}, {"id": "1911.02140", "submitter": "Derek Yang", "authors": "Derek Yang, Li Zhao, Zichuan Lin, Tao Qin, Jiang Bian, Tieyan Liu", "title": "Fully Parameterized Quantile Function for Distributional Reinforcement\n  Learning", "comments": "NeurIPS 2019. Code at https://github.com/microsoft/FQF", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distributional Reinforcement Learning (RL) differs from traditional RL in\nthat, rather than the expectation of total returns, it estimates distributions\nand has achieved state-of-the-art performance on Atari Games. The key challenge\nin practical distributional RL algorithms lies in how to parameterize estimated\ndistributions so as to better approximate the true continuous distribution.\nExisting distributional RL algorithms parameterize either the probability side\nor the return value side of the distribution function, leaving the other side\nuniformly fixed as in C51, QR-DQN or randomly sampled as in IQN. In this paper,\nwe propose fully parameterized quantile function that parameterizes both the\nquantile fraction axis (i.e., the x-axis) and the value axis (i.e., y-axis) for\ndistributional RL. Our algorithm contains a fraction proposal network that\ngenerates a discrete set of quantile fractions and a quantile value network\nthat gives corresponding quantile values. The two networks are jointly trained\nto find the best approximation of the true distribution. Experiments on 55\nAtari Games show that our algorithm significantly outperforms existing\ndistributional RL algorithms and creates a new record for the Atari Learning\nEnvironment for non-distributed agents.\n", "versions": [{"version": "v1", "created": "Tue, 5 Nov 2019 23:38:57 GMT"}, {"version": "v2", "created": "Sat, 16 Nov 2019 03:48:25 GMT"}, {"version": "v3", "created": "Sun, 2 Aug 2020 09:13:34 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Yang", "Derek", ""], ["Zhao", "Li", ""], ["Lin", "Zichuan", ""], ["Qin", "Tao", ""], ["Bian", "Jiang", ""], ["Liu", "Tieyan", ""]]}, {"id": "1911.02166", "submitter": "Zichuan Lin", "authors": "Zichuan Lin, Li Zhao, Derek Yang, Tao Qin, Guangwen Yang and Tie-Yan\n  Liu", "title": "Distributional Reward Decomposition for Reinforcement Learning", "comments": "NeurlPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many reinforcement learning (RL) tasks have specific properties that can be\nleveraged to modify existing RL algorithms to adapt to those tasks and further\nimprove performance, and a general class of such properties is the multiple\nreward channel. In those environments the full reward can be decomposed into\nsub-rewards obtained from different channels. Existing work on reward\ndecomposition either requires prior knowledge of the environment to decompose\nthe full reward, or decomposes reward without prior knowledge but with degraded\nperformance. In this paper, we propose Distributional Reward Decomposition for\nReinforcement Learning (DRDRL), a novel reward decomposition algorithm which\ncaptures the multiple reward channel structure under distributional setting.\nEmpirically, our method captures the multi-channel structure and discovers\nmeaningful reward decomposition, without any requirements on prior knowledge.\nConsequently, our agent achieves better performance than existing methods on\nenvironments with multiple reward channels.\n", "versions": [{"version": "v1", "created": "Wed, 6 Nov 2019 02:13:50 GMT"}], "update_date": "2019-11-07", "authors_parsed": [["Lin", "Zichuan", ""], ["Zhao", "Li", ""], ["Yang", "Derek", ""], ["Qin", "Tao", ""], ["Yang", "Guangwen", ""], ["Liu", "Tie-Yan", ""]]}, {"id": "1911.02168", "submitter": "Quan Wang", "authors": "Quan Wang, Pingping Huang, Haifeng Wang, Songtai Dai, Wenbin Jiang,\n  Jing Liu, Yajuan Lyu, Yong Zhu, Hua Wu", "title": "CoKE: Contextualized Knowledge Graph Embedding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge graph embedding, which projects symbolic entities and relations\ninto continuous vector spaces, is gaining increasing attention. Previous\nmethods allow a single static embedding for each entity or relation, ignoring\ntheir intrinsic contextual nature, i.e., entities and relations may appear in\ndifferent graph contexts, and accordingly, exhibit different properties. This\nwork presents Contextualized Knowledge Graph Embedding (CoKE), a novel paradigm\nthat takes into account such contextual nature, and learns dynamic, flexible,\nand fully contextualized entity and relation embeddings. Two types of graph\ncontexts are studied: edges and paths, both formulated as sequences of entities\nand relations. CoKE takes a sequence as input and uses a Transformer encoder to\nobtain contextualized representations. These representations are hence\nnaturally adaptive to the input, capturing contextual meanings of entities and\nrelations therein. Evaluation on a wide variety of public benchmarks verifies\nthe superiority of CoKE in link prediction and path query answering. It\nperforms consistently better than, or at least equally well as current\nstate-of-the-art in almost every case, in particular offering an absolute\nimprovement of 21.0% in H@10 on path query answering. Our code is available at\n\\url{https://github.com/PaddlePaddle/Research/tree/master/KG/CoKE}.\n", "versions": [{"version": "v1", "created": "Wed, 6 Nov 2019 02:27:39 GMT"}, {"version": "v2", "created": "Sat, 4 Apr 2020 07:22:20 GMT"}], "update_date": "2020-04-07", "authors_parsed": [["Wang", "Quan", ""], ["Huang", "Pingping", ""], ["Wang", "Haifeng", ""], ["Dai", "Songtai", ""], ["Jiang", "Wenbin", ""], ["Liu", "Jing", ""], ["Lyu", "Yajuan", ""], ["Zhu", "Yong", ""], ["Wu", "Hua", ""]]}, {"id": "1911.02191", "submitter": "Lucas Oliveira Souza", "authors": "Lucas Oliveira Souza, Gabriel de Oliveira Ramos, Celia Ghedini Ralha", "title": "Experience Sharing Between Cooperative Reinforcement Learning Agents", "comments": "Published at the Proceedings of the 31st IEEE International\n  Conference on Tools with Artificial Intelligence", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The idea of experience sharing between cooperative agents naturally emerges\nfrom our understanding of how humans learn. Our evolution as a species is\ntightly linked to the ability to exchange learned knowledge with one another.\nIt follows that experience sharing (ES) between autonomous and independent\nagents could become the key to accelerate learning in cooperative multiagent\nsettings. We investigate if randomly selecting experiences to share can\nincrease the performance of deep reinforcement learning agents, and propose\nthree new methods for selecting experiences to accelerate the learning process.\nFirstly, we introduce Focused ES, which prioritizes unexplored regions of the\nstate space. Secondly, we present Prioritized ES, in which temporal-difference\nerror is used as a measure of priority. Finally, we devise Focused Prioritized\nES, which combines both previous approaches. The methods are empirically\nvalidated in a control problem. While sharing randomly selected experiences\nbetween two Deep Q-Network agents shows no improvement over a single agent\nbaseline, we show that the proposed ES methods can successfully outperform the\nbaseline. In particular, the Focused ES accelerates learning by a factor of 2,\nreducing by 51% the number of episodes required to complete the task.\n", "versions": [{"version": "v1", "created": "Wed, 6 Nov 2019 03:57:14 GMT"}], "update_date": "2019-11-07", "authors_parsed": [["Souza", "Lucas Oliveira", ""], ["Ramos", "Gabriel de Oliveira", ""], ["Ralha", "Celia Ghedini", ""]]}, {"id": "1911.02224", "submitter": "Naibo Wang", "authors": "Meng Xi, Zhiling Luo, Naibo Wang, Jianwei Yin", "title": "A Latent Feelings-aware RNN Model for User Churn Prediction with\n  Behavioral Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Predicting user churn and taking personalized measures to retain users is a\nset of common and effective practices for online game operators. However,\ndifferent from the traditional user churn relevant researches that can involve\ndemographic, economic, and behavioral data, most online games can only obtain\nlogs of user behavior and have no access to users' latent feelings. There are\nmainly two challenges in this work: 1. The latent feelings, which cannot be\ndirectly observed in this work, need to be estimated and verified; 2. User\nchurn needs to be predicted with only behavioral data. In this work, a\nRecurrent Neural Network(RNN) called LaFee (Latent Feeling) is proposed, which\ncan get the users' latent feelings while predicting user churn. Besides, we\nproposed a method named BMM-UCP (Behavior-based Modeling Method for User Churn\nPrediction) to help models predict user churn with only behavioral data. The\nlatent feelings are names as satisfaction and aspiration in this work. We\ndesigned experiments on a real dataset and the results show that our methods\noutperform baselines and are more suitable for long-term sequential learning.\nThe latent feelings learned are fully discussed and proven meaningful.\n", "versions": [{"version": "v1", "created": "Wed, 6 Nov 2019 06:49:36 GMT"}], "update_date": "2019-11-07", "authors_parsed": [["Xi", "Meng", ""], ["Luo", "Zhiling", ""], ["Wang", "Naibo", ""], ["Yin", "Jianwei", ""]]}, {"id": "1911.02268", "submitter": "Priyansh Saxena", "authors": "Devansh Verma, Priyansh Saxena and Ritu Tiwari", "title": "Robot navigation and target capturing using nature-inspired approaches\n  in a dynamic environment", "comments": "8 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Path Planning and target searching in a three-dimensional environment is a\nchallenging task in the field of robotics. It is an optimization problem as the\npath from source to destination has to be optimal. This paper aims to generate\na collision-free trajectory in a dynamic environment. The path planning problem\nhas sought to be of extreme importance in the military, search and rescue\nmissions and in life-saving tasks. During its operation, the unmanned air\nvehicle operates in a hostile environment, and faster replanning is needed to\nreach the target as optimally as possible. This paper presents a novel approach\nof hierarchical planning using multiresolution abstract levels for faster\nreplanning. Economic constraints like path length, total path planning time and\nthe number of turns are taken into consideration that mandate the use of cost\nfunctions. Experimental results show that the hierarchical version of GSO gives\nbetter performance compared to the BBO, IWO and their hierarchical versions.\n", "versions": [{"version": "v1", "created": "Wed, 6 Nov 2019 09:36:38 GMT"}], "update_date": "2019-11-07", "authors_parsed": [["Verma", "Devansh", ""], ["Saxena", "Priyansh", ""], ["Tiwari", "Ritu", ""]]}, {"id": "1911.02365", "submitter": "Tassilo Klein", "authors": "Tassilo Klein, Moin Nabi", "title": "Learning to Answer by Learning to Ask: Getting the Best of GPT-2 and\n  BERT Worlds", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic question generation aims at the generation of questions from a\ncontext, with the corresponding answers being sub-spans of the given passage.\nWhereas, most of the methods mostly rely on heuristic rules to generate\nquestions, more recently also neural network approaches have been proposed. In\nthis work, we propose a variant of the self-attention Transformer network\narchitectures model to generate meaningful and diverse questions. To this end,\nwe propose an easy to use model consisting of the conjunction of the\nTransformer decoder GPT-2 model with Transformer encoder BERT for the\ndownstream task for question answering. The model is trained in an end-to-end\nfashion, where the language model is trained to produce a question-answer-aware\ninput representation that facilitates to generate an answer focused question.\nOur result of neural question generation from text on the SQuAD 1.1 dataset\nsuggests that our method can produce semantically correct and diverse\nquestions. Additionally, we assessed the performance of our proposed method for\nthe downstream task of question answering. The analysis shows that our proposed\ngeneration & answering collaboration framework relatively improves both tasks\nand is particularly powerful in the semi-supervised setup. The results further\nsuggest a robust and comparably lean pipeline facilitating question generation\nin the small-data regime.\n", "versions": [{"version": "v1", "created": "Wed, 6 Nov 2019 13:23:41 GMT"}], "update_date": "2019-11-07", "authors_parsed": [["Klein", "Tassilo", ""], ["Nabi", "Moin", ""]]}, {"id": "1911.02391", "submitter": "Florian Pfisterer", "authors": "Florian Pfisterer, Janek Thomas, Bernd Bischl", "title": "Towards Human Centered AutoML", "comments": "4 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Building models from data is an integral part of the majority of data science\nworkflows. While data scientists are often forced to spend the majority of the\ntime available for a given project on data cleaning and exploratory analysis,\nthe time available to practitioners to build actual models from data is often\nrather short due to time constraints for a given project. AutoML systems are\ncurrently rising in popularity, as they can build powerful models without human\noversight. In this position paper, we aim to discuss the impact of the rising\npopularity of such systems and how a user-centered interface for such systems\ncould look like. More importantly, we also want to point out features that are\ncurrently missing in those systems and start to explore better usability of\nsuch systems from a data-scientists perspective.\n", "versions": [{"version": "v1", "created": "Wed, 6 Nov 2019 13:55:23 GMT"}], "update_date": "2019-11-07", "authors_parsed": [["Pfisterer", "Florian", ""], ["Thomas", "Janek", ""], ["Bischl", "Bernd", ""]]}, {"id": "1911.02405", "submitter": "Xu Chen", "authors": "Xuan Di, Xu Chen, Eric Talley", "title": "Liability Design for Autonomous Vehicles and Human-Driven Vehicles: A\n  Hierarchical Game-Theoretic Approach", "comments": null, "journal-ref": null, "doi": "10.1016/j.trc.2020.102710", "report-no": null, "categories": "cs.GT cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Autonomous vehicles (AVs) are inevitably entering our lives with potential\nbenefits for improved traffic safety, mobility, and accessibility. However,\nAVs' benefits also introduce a serious potential challenge, in the form of\ncomplex interactions with human-driven vehicles (HVs). The emergence of AVs\nintroduces uncertainty in the behavior of human actors and in the impact of the\nAV manufacturer on autonomous driving design. This paper thus aims to\ninvestigate how AVs affect road safety and to design socially optimal liability\nrules for AVs and human drivers. A unified game is developed, including a Nash\ngame between human drivers, a Stackelberg game between the AV manufacturer and\nHVs, and a Stackelberg game between the law maker and other users. We also\nestablish the existence and uniqueness of the equilibrium of the game. The game\nis then simulated with numerical examples to investigate the emergence of human\ndrivers' moral hazard, the AV manufacturer's role in traffic safety, and the\nlaw maker's role in liability design. Our findings demonstrate that human\ndrivers could develop moral hazard if they perceive their road environment has\nbecome safer and an optimal liability rule design is crucial to improve social\nwelfare with advanced transportation technologies. More generally, the\ngame-theoretic model developed in this paper provides an analytical tool to\nassist policy-makers in AV policymaking and hopefully mitigate uncertainty in\nthe existing regulation landscape about AV technologies.\n", "versions": [{"version": "v1", "created": "Tue, 5 Nov 2019 03:06:04 GMT"}, {"version": "v2", "created": "Mon, 11 Nov 2019 02:26:47 GMT"}, {"version": "v3", "created": "Mon, 7 Sep 2020 17:46:48 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Di", "Xuan", ""], ["Chen", "Xu", ""], ["Talley", "Eric", ""]]}, {"id": "1911.02479", "submitter": "Brian Nord", "authors": "Brian Nord, Andrew J. Connolly, Jamie Kinney, Jeremy Kubica, Gautaum\n  Narayan, Joshua E. G. Peek, Chad Schafer, Erik J. Tollerud, Camille Avestruz,\n  G. Jogesh Babu, Simon Birrer, Douglas Burke, Jo\\~ao Caldeira, Douglas A.\n  Caldwell, Joleen K. Carlberg, Yen-Chi Chen, Chuanfei Dong, Eric D. Feigelson,\n  V. Zach Golkhou, Vinay Kashyap, T. S. Li, Thomas Loredo, Luisa Lucie-Smith,\n  Kaisey S. Mandel, J. R. Mart\\'inez-Galarza, Adam A. Miller, Priyamvada\n  Natarajan, Michelle Ntampaka, Andy Ptak, David Rapetti, Lior Shamir, Aneta\n  Siemiginowska, Brigitta M. Sip\\H{o}cz, Arfon M. Smith, Nhan Tran, Ricardo\n  Vilalta, Lucianne M. Walkowicz, John ZuHone", "title": "Algorithms and Statistical Models for Scientific Discovery in the\n  Petabyte Era", "comments": "arXiv admin note: substantial text overlap with arXiv:1905.05116", "journal-ref": null, "doi": null, "report-no": "FERMILAB-FN-1093-A-AE-SCD", "categories": "astro-ph.IM cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The field of astronomy has arrived at a turning point in terms of size and\ncomplexity of both datasets and scientific collaboration. Commensurately,\nalgorithms and statistical models have begun to adapt --- e.g., via the onset\nof artificial intelligence --- which itself presents new challenges and\nopportunities for growth. This white paper aims to offer guidance and ideas for\nhow we can evolve our technical and collaborative frameworks to promote\nefficient algorithmic development and take advantage of opportunities for\nscientific discovery in the petabyte era. We discuss challenges for discovery\nin large and complex data sets; challenges and requirements for the next stage\nof development of statistical methodologies and algorithmic tool sets; how we\nmight change our paradigms of collaboration and education; and the ethical\nimplications of scientists' contributions to widely applicable algorithms and\ncomputational modeling. We start with six distinct recommendations that are\nsupported by the commentary following them. This white paper is related to a\nlarger corpus of effort that has taken place within and around the Petabytes to\nScience Workshops (https://petabytestoscience.github.io/).\n", "versions": [{"version": "v1", "created": "Tue, 5 Nov 2019 04:06:32 GMT"}], "update_date": "2019-11-07", "authors_parsed": [["Nord", "Brian", ""], ["Connolly", "Andrew J.", ""], ["Kinney", "Jamie", ""], ["Kubica", "Jeremy", ""], ["Narayan", "Gautaum", ""], ["Peek", "Joshua E. G.", ""], ["Schafer", "Chad", ""], ["Tollerud", "Erik J.", ""], ["Avestruz", "Camille", ""], ["Babu", "G. Jogesh", ""], ["Birrer", "Simon", ""], ["Burke", "Douglas", ""], ["Caldeira", "Jo\u00e3o", ""], ["Caldwell", "Douglas A.", ""], ["Carlberg", "Joleen K.", ""], ["Chen", "Yen-Chi", ""], ["Dong", "Chuanfei", ""], ["Feigelson", "Eric D.", ""], ["Golkhou", "V. Zach", ""], ["Kashyap", "Vinay", ""], ["Li", "T. S.", ""], ["Loredo", "Thomas", ""], ["Lucie-Smith", "Luisa", ""], ["Mandel", "Kaisey S.", ""], ["Mart\u00ednez-Galarza", "J. R.", ""], ["Miller", "Adam A.", ""], ["Natarajan", "Priyamvada", ""], ["Ntampaka", "Michelle", ""], ["Ptak", "Andy", ""], ["Rapetti", "David", ""], ["Shamir", "Lior", ""], ["Siemiginowska", "Aneta", ""], ["Sip\u0151cz", "Brigitta M.", ""], ["Smith", "Arfon M.", ""], ["Tran", "Nhan", ""], ["Vilalta", "Ricardo", ""], ["Walkowicz", "Lucianne M.", ""], ["ZuHone", "John", ""]]}, {"id": "1911.02508", "submitter": "Dylan Slack", "authors": "Dylan Slack, Sophie Hilgard, Emily Jia, Sameer Singh, Himabindu\n  Lakkaraju", "title": "Fooling LIME and SHAP: Adversarial Attacks on Post hoc Explanation\n  Methods", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As machine learning black boxes are increasingly being deployed in domains\nsuch as healthcare and criminal justice, there is growing emphasis on building\ntools and techniques for explaining these black boxes in an interpretable\nmanner. Such explanations are being leveraged by domain experts to diagnose\nsystematic errors and underlying biases of black boxes. In this paper, we\ndemonstrate that post hoc explanations techniques that rely on input\nperturbations, such as LIME and SHAP, are not reliable. Specifically, we\npropose a novel scaffolding technique that effectively hides the biases of any\ngiven classifier by allowing an adversarial entity to craft an arbitrary\ndesired explanation. Our approach can be used to scaffold any biased classifier\nin such a way that its predictions on the input data distribution still remain\nbiased, but the post hoc explanations of the scaffolded classifier look\ninnocuous. Using extensive evaluation with multiple real-world datasets\n(including COMPAS), we demonstrate how extremely biased (racist) classifiers\ncrafted by our framework can easily fool popular explanation techniques such as\nLIME and SHAP into generating innocuous explanations which do not reflect the\nunderlying biases.\n", "versions": [{"version": "v1", "created": "Wed, 6 Nov 2019 17:52:20 GMT"}, {"version": "v2", "created": "Mon, 3 Feb 2020 18:53:50 GMT"}], "update_date": "2020-02-04", "authors_parsed": [["Slack", "Dylan", ""], ["Hilgard", "Sophie", ""], ["Jia", "Emily", ""], ["Singh", "Sameer", ""], ["Lakkaraju", "Himabindu", ""]]}, {"id": "1911.02524", "submitter": "Georgiy Platonov", "authors": "Georgiy Platonov, Benjamin Kane, Aaron Gindi, Lenhart K. Schubert", "title": "A Spoken Dialogue System for Spatial Question Answering in a Physical\n  Blocks World", "comments": "9 pages (with references), 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The blocks world is a classic toy domain that has long been used to build and\ntest spatial reasoning systems. Despite its relative simplicity, tackling this\ndomain in its full complexity requires the agent to exhibit a rich set of\nfunctional capabilities, ranging from vision to natural language understanding.\nThere is currently a resurgence of interest in solving problems in such limited\ndomains using modern techniques. In this work we tackle spatial question\nanswering in a holistic way, using a vision system, speech input and output\nmediated by an animated avatar, a dialogue system that robustly interprets\nspatial queries, and a constraint solver that derives answers based on 3-D\nspatial modeling. The contributions of this work include a semantic parser that\nmaps spatial questions into logical forms consistent with a general approach to\nmeaning representation, a dialog manager based on a schema representation, and\na constraint solver for spatial questions that provides answers in agreement\nwith human perception. These and other components are integrated into a\nmulti-modal human-computer interaction pipeline.\n", "versions": [{"version": "v1", "created": "Wed, 6 Nov 2019 18:05:13 GMT"}], "update_date": "2019-11-07", "authors_parsed": [["Platonov", "Georgiy", ""], ["Kane", "Benjamin", ""], ["Gindi", "Aaron", ""], ["Schubert", "Lenhart K.", ""]]}, {"id": "1911.02547", "submitter": "Andrei Velichko", "authors": "A. A. Velichko, M. A. Belyaev, D. V. Ryabokon and S. D. Khanin", "title": "The non-capacitor model of leaky integrate-and-fire $VO_2$ neuron with\n  the thermal mechanism of the membrane potential", "comments": null, "journal-ref": "J. Phys.: Conf. Ser. 1399 022046 (2019)", "doi": "10.1088/1742-6596/1399/2/022046", "report-no": null, "categories": "cs.ET cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The study presents a numerical model of leaky integrate-and-fire neuron\ncreated on the basis of $VO_2$ switch. The analogue of the membrane potential\nin the model is the temperature of the switch channel, and the action potential\nfrom neighbouring neurons propagates along the substrate in the form of thermal\npulses. We simulated the operation of three neurons and demonstrated that the\ntotal effect happens due to interference of thermal waves in the region of the\nneuron switching channel. The thermal mechanism of the threshold function\noperates due to the effect of electrical switching, and the magnitude\n(temperature) of the threshold can vary by external voltage. The neuron circuit\ndoes not contain capacitor, making it possible to produce a network with a high\ndensity of components, and has the potential for 3D integration due to the\nthermal mechanism of neurons interaction.\n", "versions": [{"version": "v1", "created": "Mon, 7 Oct 2019 12:19:50 GMT"}], "update_date": "2020-01-07", "authors_parsed": [["Velichko", "A. A.", ""], ["Belyaev", "M. A.", ""], ["Ryabokon", "D. V.", ""], ["Khanin", "S. D.", ""]]}, {"id": "1911.02557", "submitter": "Pragaash Ponnusamy", "authors": "Pragaash Ponnusamy, Alireza Roshan Ghias, Chenlei Guo, Ruhi Sarikaya", "title": "Feedback-Based Self-Learning in Large-Scale Conversational AI Agents", "comments": "8 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Today, most large-scale conversational AI agents (e.g. Alexa, Siri, or Google\nAssistant) are built using manually annotated data to train the different\ncomponents of the system. Typically, the accuracy of the ML models in these\ncomponents are improved by manually transcribing and annotating data. As the\nscope of these systems increase to cover more scenarios and domains, manual\nannotation to improve the accuracy of these components becomes prohibitively\ncostly and time consuming. In this paper, we propose a system that leverages\nuser-system interaction feedback signals to automate learning without any\nmanual annotation. Users here tend to modify a previous query in hopes of\nfixing an error in the previous turn to get the right results. These\nreformulations, which are often preceded by defective experiences caused by\nerrors in ASR, NLU, ER or the application. In some cases, users may not\nproperly formulate their requests (e.g. providing partial title of a song), but\ngleaning across a wider pool of users and sessions reveals the underlying\nrecurrent patterns. Our proposed self-learning system automatically detects the\nerrors, generate reformulations and deploys fixes to the runtime system to\ncorrect different types of errors occurring in different components of the\nsystem. In particular, we propose leveraging an absorbing Markov Chain model as\na collaborative filtering mechanism in a novel attempt to mine these patterns.\nWe show that our approach is highly scalable, and able to learn reformulations\nthat reduce Alexa-user errors by pooling anonymized data across millions of\ncustomers. The proposed self-learning system achieves a win/loss ratio of 11.8\nand effectively reduces the defect rate by more than 30% on utterance level\nreformulations in our production A/B tests. To the best of our knowledge, this\nis the first self-learning large-scale conversational AI system in production.\n", "versions": [{"version": "v1", "created": "Wed, 6 Nov 2019 18:55:42 GMT"}], "update_date": "2019-11-07", "authors_parsed": [["Ponnusamy", "Pragaash", ""], ["Ghias", "Alireza Roshan", ""], ["Guo", "Chenlei", ""], ["Sarikaya", "Ruhi", ""]]}, {"id": "1911.02617", "submitter": "Yue Wu", "authors": "Yue Wu, Leman Akoglu, Ian Davidson", "title": "Coverage-based Outlier Explanation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Outlier detection is a core task in data mining with a plethora of algorithms\nthat have enjoyed wide scale usage. Existing algorithms are primarily focused\non detection, that is the identification of outliers in a given dataset. In\nthis paper we explore the relatively under-studied problem of the outlier\nexplanation problem. Our goal is, given a dataset that is already divided into\noutliers and normal instances, explain what characterizes the outliers. We\nexplore the novel direction of a semantic explanation that a domain expert or\npolicy maker is able to understand. We formulate this as an optimization\nproblem to find explanations that are both interpretable and pure. Through\nexperiments on real-world data sets, we quantitatively show that our method can\nefficiently generate better explanations compared with rule-based learners.\n", "versions": [{"version": "v1", "created": "Wed, 6 Nov 2019 20:19:00 GMT"}], "update_date": "2019-11-11", "authors_parsed": [["Wu", "Yue", ""], ["Akoglu", "Leman", ""], ["Davidson", "Ian", ""]]}, {"id": "1911.02637", "submitter": "Jun Rekimoto", "authors": "Jun Rekimoto", "title": "Homo Cyberneticus: The Era of Human-AI Integration", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article is submitted and accepted as ACM UIST 2019 Visions. UIST Visions\nis a venue for forward thinking ideas to inspire the community. The goal is not\nto report research but to project and propose new research directions. This\narticle, entitled \"Homo Cyberneticus: The Era of Human-AI Integration\",\nproposes HCI research directions, namely human-augmentation and\nhuman-AI-integration.\n", "versions": [{"version": "v1", "created": "Mon, 21 Oct 2019 12:30:17 GMT"}], "update_date": "2019-11-11", "authors_parsed": [["Rekimoto", "Jun", ""]]}, {"id": "1911.02648", "submitter": "Philippe Vincent-Lamarre", "authors": "Philippe Vincent-Lamarre and Vincent Larivi\\`ere", "title": "Textual analysis of artificial intelligence manuscripts reveals features\n  associated with peer review outcome", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL cs.AI cs.CL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We analysed a dataset of scientific manuscripts that were submitted to\nvarious conferences in artificial intelligence. We performed a combination of\nsemantic, lexical and psycholinguistic analyses of the full text of the\nmanuscripts and compared them with the outcome of the peer review process. We\nfound that accepted manuscripts scored lower than rejected manuscripts on two\nindicators of readability, and that they also used more scientific and\nartificial intelligence jargon. We also found that accepted manuscripts were\nwritten with words that are less frequent, that are acquired at an older age,\nand that are more abstract than rejected manuscripts. The analysis of\nreferences included in the manuscripts revealed that the subset of accepted\nsubmissions were more likely to cite the same publications. This finding was\nechoed by pairwise comparisons of the word content of the manuscripts (i.e. an\nindicator or semantic similarity), which were more similar in the subset of\naccepted manuscripts. Finally, we predicted the peer review outcome of\nmanuscripts with their word content, with words related to machine learning and\nneural networks positively related with acceptance, whereas words related to\nlogic, symbolic processing and knowledge-based systems negatively related with\nacceptance.\n", "versions": [{"version": "v1", "created": "Mon, 21 Oct 2019 16:36:51 GMT"}, {"version": "v2", "created": "Tue, 3 Mar 2020 21:07:13 GMT"}], "update_date": "2020-03-05", "authors_parsed": [["Vincent-Lamarre", "Philippe", ""], ["Larivi\u00e8re", "Vincent", ""]]}, {"id": "1911.02668", "submitter": "Julien Corman", "authors": "Julien Corman and Guohui Xiao", "title": "Certain Answers to a SPARQL Query over a Knowledge Base (extended\n  version)", "comments": "This is the extended version of a article published at the 9th Joint\n  International Semantic Technology Conference (JIST 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Ontology-Mediated Query Answering (OMQA) is a well-established framework to\nanswer queries over an RDFS or OWL Knowledge Base (KB). OMQA was originally\ndesigned for unions of conjunctive queries (UCQs), and based on certain\nanswers. More recently, OMQA has been extended to SPARQL queries, but to our\nknowledge, none of the efforts made in this direction (either in the\nliterature, or the so-called SPARQL entailment regimes) is able to capture both\ncertain answers for UCQs and the standard interpretation of SPARQL over a plain\ngraph. We formalize these as requirements to be met by any semantics aiming at\nconciliating certain answers and SPARQL answers, and define three additional\nrequirements, which generalize to KBs some basic properties of SPARQL answers.\nThen we show that a semantics can be defined that satisfies all requirements\nfor SPARQL queries with SELECT, UNION, and OPTIONAL, and for DLs with the\ncanonical model property. We also investigate combined complexity for query\nanswering under such a semantics over DL-Lite R KBs. In particular, we show for\ndifferent fragments of SPARQL that known upper-bounds for query answering over\na plain graph are matched.\n", "versions": [{"version": "v1", "created": "Wed, 6 Nov 2019 23:05:08 GMT"}, {"version": "v2", "created": "Tue, 19 Nov 2019 16:20:03 GMT"}, {"version": "v3", "created": "Thu, 21 Nov 2019 13:06:28 GMT"}], "update_date": "2019-11-22", "authors_parsed": [["Corman", "Julien", ""], ["Xiao", "Guohui", ""]]}, {"id": "1911.02690", "submitter": "Paul Crook", "authors": "Paul A. Crook, Shivani Poddar, Ankita De, Semir Shafi, David Whitney,\n  Alborz Geramifard, Rajen Subba", "title": "SIMMC: Situated Interactive Multi-Modal Conversational Data Collection\n  And Evaluation Platform", "comments": "ASRU 2019 (demonstration)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As digital virtual assistants become ubiquitous, it becomes increasingly\nimportant to understand the situated behaviour of users as they interact with\nthese assistants. To this end, we introduce SIMMC, an extension to ParlAI for\nmulti-modal conversational data collection and system evaluation. SIMMC\nsimulates an immersive setup, where crowd workers are able to interact with\nenvironments constructed in AI Habitat or Unity while engaging in a\nconversation. The assistant in SIMMC can be a crowd worker or Artificial\nIntelligent (AI) agent. This enables both (i) a multi-player / Wizard of Oz\nsetting for data collection, or (ii) a single player mode for model / system\nevaluation. We plan to open-source a situated conversational data-set collected\non this platform for the Conversational AI research community.\n", "versions": [{"version": "v1", "created": "Thu, 7 Nov 2019 00:52:38 GMT"}, {"version": "v2", "created": "Thu, 30 Jan 2020 19:07:39 GMT"}], "update_date": "2020-02-03", "authors_parsed": [["Crook", "Paul A.", ""], ["Poddar", "Shivani", ""], ["De", "Ankita", ""], ["Shafi", "Semir", ""], ["Whitney", "David", ""], ["Geramifard", "Alborz", ""], ["Subba", "Rajen", ""]]}, {"id": "1911.02695", "submitter": "Zhou Fang", "authors": "Zhou Fang, Pujana Paliyawan, Ruck Thawonmas and Tomohiro Harada", "title": "Towards An Angry-Birds-like Game System for Promoting Mental Well-being\n  of Players Using Art-Therapy-embedded PCG", "comments": "2019 IEEE 8th Global Conference on Consumer Electronics", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents an integration of a game system and the art therapy\nconcept for promoting the mental well-being of video game players. In the\nproposed game system, the player plays an Angry-Birds-like game in which levels\nin the game are generated based on images they draw. Upon finishing a game\nlevel, the player also receives positive feedback (praising words) toward their\ndrawing and the generated level from an Art Therapy AI. The proposed system is\ncomposed of three major parts: (1) a drawing recognizer that identifies what\nobject is drawn by the player (Sketcher), (2) a level generator that converts\nthe drawing image into a pixel image, then a set of blocks representing a game\nlevel (PCG AI), and (3) the Art Therapy AI that encourages the player and\nimproves their emotion. This paper describes an overview of the system and\nexplains how its major components function.\n", "versions": [{"version": "v1", "created": "Thu, 7 Nov 2019 01:06:04 GMT"}], "update_date": "2019-11-11", "authors_parsed": [["Fang", "Zhou", ""], ["Paliyawan", "Pujana", ""], ["Thawonmas", "Ruck", ""], ["Harada", "Tomohiro", ""]]}, {"id": "1911.02707", "submitter": "Houyu Zhang", "authors": "Houyu Zhang, Zhenghao Liu, Chenyan Xiong, Zhiyuan Liu", "title": "Grounded Conversation Generation as Guided Traverses in Commonsense\n  Knowledge Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Human conversations naturally evolve around related concepts and scatter to\nmulti-hop concepts. This paper presents a new conversation generation model,\nConceptFlow, which leverages commonsense knowledge graphs to explicitly model\nconversation flows. By grounding conversations to the concept space,\nConceptFlow represents the potential conversation flow as traverses in the\nconcept space along commonsense relations. The traverse is guided by graph\nattentions in the concept graph, moving towards more meaningful directions in\nthe concept space, in order to generate more semantic and informative\nresponses. Experiments on Reddit conversations demonstrate ConceptFlow's\neffectiveness over previous knowledge-aware conversation models and GPT-2 based\nmodels while using 70% fewer parameters, confirming the advantage of explicit\nmodeling conversation structures. All source codes of this work are available\nat https://github.com/thunlp/ConceptFlow.\n", "versions": [{"version": "v1", "created": "Thu, 7 Nov 2019 01:40:39 GMT"}, {"version": "v2", "created": "Mon, 6 Apr 2020 04:02:51 GMT"}, {"version": "v3", "created": "Tue, 5 May 2020 18:12:41 GMT"}], "update_date": "2020-05-07", "authors_parsed": [["Zhang", "Houyu", ""], ["Liu", "Zhenghao", ""], ["Xiong", "Chenyan", ""], ["Liu", "Zhiyuan", ""]]}, {"id": "1911.02714", "submitter": "Benjamin Caulfield", "authors": "Benjamin Caulfield, Sanjit A. Seshia", "title": "Modularity in Query-Based Concept Learning", "comments": "17 pages, 4 figures, submitted to TACAS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We define and study the problem of modular concept learning, that is,\nlearning a concept that is a cross product of component concepts. If an\nelement's membership in a concept depends solely on it's membership in the\ncomponents, learning the concept as a whole can be reduced to learning the\ncomponents. We analyze this problem with respect to different types of oracle\ninterfaces, defining different sets of queries. If a given oracle interface\ncannot answer questions about the components, learning can be difficult, even\nwhen the components are easy to learn with the same type of oracle queries.\nWhile learning from superset queries is easy, learning from membership,\nequivalence, or subset queries is harder. However, we show that these problems\nbecome tractable when oracles are given a positive example and are allowed to\nask membership queries.\n", "versions": [{"version": "v1", "created": "Thu, 7 Nov 2019 02:05:25 GMT"}], "update_date": "2019-11-11", "authors_parsed": [["Caulfield", "Benjamin", ""], ["Seshia", "Sanjit A.", ""]]}, {"id": "1911.02887", "submitter": "Javier Segovia Aguas", "authors": "Javier Segovia-Aguas and Sergio Jim\\'enez and Anders Jonsson", "title": "Hierarchical Finite State Controllers for Generalized Planning", "comments": "IJCAI-16 Distinguished Paper Awards, 7 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Finite State Controllers (FSCs) are an effective way to represent sequential\nplans compactly. By imposing appropriate conditions on transitions, FSCs can\nalso represent generalized plans that solve a range of planning problems from a\ngiven domain. In this paper we introduce the concept of {\\it hierarchical FSCs}\nfor planning by allowing controllers to call other controllers. We show that\nhierarchical FSCs can represent generalized plans more compactly than\nindividual FSCs. Moreover, our call mechanism makes it possible to generate\nhierarchical FSCs in a modular fashion, or even to apply recursion. We also\nintroduce a compilation that enables a classical planner to generate\nhierarchical FSCs that solve challenging generalized planning problems. The\ncompilation takes as input a set of planning problems from a given domain and\noutputs a single classical planning problem, whose solution corresponds to a\nhierarchical FSC.\n", "versions": [{"version": "v1", "created": "Thu, 7 Nov 2019 13:21:28 GMT"}], "update_date": "2019-11-11", "authors_parsed": [["Segovia-Aguas", "Javier", ""], ["Jim\u00e9nez", "Sergio", ""], ["Jonsson", "Anders", ""]]}, {"id": "1911.03020", "submitter": "Mohammad Yaghini", "authors": "Mohammad Yaghini, Andreas Krause, and Hoda Heidari", "title": "A Human-in-the-loop Framework to Construct Context-aware Mathematical\n  Notions of Outcome Fairness", "comments": "In the forth AAAI/ACM Conference on Artificial Intelligence, Ethics,\n  and Society (AIES-2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing mathematical notions of fairness fail to account for the context of\ndecision-making. We argue that moral consideration of contextual factors is an\ninherently human task. So we present a framework to learn context-aware\nmathematical formulations of fairness by eliciting people's situated fairness\nassessments. Our family of fairness notions corresponds to a new interpretation\nof economic models of Equality of Opportunity (EOP), and it includes most\nexisting notions of fairness as special cases. Our human-in-the-loop approach\nis designed to learn the appropriate parameters of the EOP family by utilizing\nhuman responses to pair-wise questions about decision subjects' circumstance\nand deservingness, and the harm/benefit imposed on them. We illustrate our\nframework in a hypothetical criminal risk assessment scenario by conducting a\nseries of human-subject experiments on Amazon Mechanical Turk. Our work takes\nan important initial step toward empowering stakeholders to have a voice in the\nformulation of fairness for Machine Learning.\n", "versions": [{"version": "v1", "created": "Fri, 8 Nov 2019 03:41:03 GMT"}, {"version": "v2", "created": "Tue, 18 May 2021 12:41:14 GMT"}], "update_date": "2021-05-19", "authors_parsed": [["Yaghini", "Mohammad", ""], ["Krause", "Andreas", ""], ["Heidari", "Hoda", ""]]}, {"id": "1911.03124", "submitter": "Conrad Sanderson", "authors": "Majid Namazi, Conrad Sanderson, M.A. Hakim Newton, Abdul Sattar", "title": "A Cooperative Coordination Solver for Travelling Thief Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The travelling thief problem (TTP) is a representative of multi-component\noptimisation problems with interacting components. TTP combines the knapsack\nproblem (KP) and the travelling salesman problem (TSP). A thief performs a\ncyclic tour through a set of cities, and pursuant to a collection plan,\ncollects a subset of items into a rented knapsack with finite capacity. The aim\nis to maximise profit while minimising renting cost. Existing TTP solvers\ntypically solve the KP and TSP components in an interleaved manner: the\nsolution of one component is kept fixed while the solution of the other\ncomponent is modified. This suggests low coordination between solving the two\ncomponents, possibly leading to low quality TTP solutions. The 2-OPT heuristic\nis often used for solving the TSP component, which reverses a segment in the\ntour. Within TTP, 2-OPT does not take into account the collection plan, which\ncan result in a lower objective value. This in turn can result in the tour\nmodification to be rejected by a solver. We propose an expanded form of 2-OPT\nto change the collection plan in coordination with tour modification. Items\nregarded as less profitable and collected in cities located earlier in the\nreversed segment are substituted by items that tend to be more profitable and\nnot collected in cities located later in the reversed segment. The collection\nplan is further changed through a modified form of the hill-climbing bit-flip\nsearch, where changes in the collection state are only permitted for boundary\nitems, which are defined as lowest profitable collected items or highest\nprofitable uncollected items. This restriction reduces the time spent on the KP\ncomponent, allowing more tours to be evaluated by the TSP component within a\ntime budget. The proposed approaches form the basis of a new cooperative\ncoordination solver, which is shown to outperform several state-of-the-art TTP\nsolvers.\n", "versions": [{"version": "v1", "created": "Fri, 8 Nov 2019 08:41:50 GMT"}, {"version": "v2", "created": "Mon, 10 Feb 2020 09:06:59 GMT"}, {"version": "v3", "created": "Mon, 14 Dec 2020 07:29:08 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["Namazi", "Majid", ""], ["Sanderson", "Conrad", ""], ["Newton", "M. A. Hakim", ""], ["Sattar", "Abdul", ""]]}, {"id": "1911.03216", "submitter": "Jevgenij Gamper", "authors": "Agnes Schim van der Loeff, Iggy Bassi, Sachin Kapila, Jevgenij Gamper", "title": "AI Ethics for Systemic Issues: A Structural Approach", "comments": null, "journal-ref": "NeurIPS AI for Social Good 2019", "doi": null, "report-no": null, "categories": "cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The debate on AI ethics largely focuses on technical improvements and\nstronger regulation to prevent accidents or misuse of AI, with solutions\nrelying on holding individual actors accountable for responsible AI\ndevelopment. While useful and necessary, we argue that this \"agency\" approach\ndisregards more indirect and complex risks resulting from AI's interaction with\nthe socio-economic and political context. This paper calls for a \"structural\"\napproach to assessing AI's effects in order to understand and prevent such\nsystemic risks where no individual can be held accountable for the broader\nnegative impacts. This is particularly relevant for AI applied to systemic\nissues such as climate change and food security which require political\nsolutions and global cooperation. To properly address the wide range of AI\nrisks and ensure 'AI for social good', agency-focused policies must be\ncomplemented by policies informed by a structural approach.\n", "versions": [{"version": "v1", "created": "Fri, 8 Nov 2019 12:31:49 GMT"}], "update_date": "2019-11-11", "authors_parsed": [["van der Loeff", "Agnes Schim", ""], ["Bassi", "Iggy", ""], ["Kapila", "Sachin", ""], ["Gamper", "Jevgenij", ""]]}, {"id": "1911.03233", "submitter": "Gali Noti", "authors": "Yoav Kolumbus and Gali Noti", "title": "Neural Networks for Predicting Human Interactions in Repeated Games", "comments": null, "journal-ref": "Published in: Proceedings of the 28th International Joint\n  Conference on Artificial Intelligence (IJCAI'19), AAAI Press, 2019, Pages\n  392-399", "doi": null, "report-no": null, "categories": "cs.GT cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of predicting human players' actions in repeated\nstrategic interactions. Our goal is to predict the dynamic step-by-step\nbehavior of individual players in previously unseen games. We study the ability\nof neural networks to perform such predictions and the information that they\nrequire. We show on a dataset of normal-form games from experiments with human\nparticipants that standard neural networks are able to learn functions that\nprovide more accurate predictions of the players' actions than established\nmodels from behavioral economics. The networks outperform the other models in\nterms of prediction accuracy and cross-entropy, and yield higher economic\nvalue. We show that if the available input is only of a short sequence of play,\neconomic information about the game is important for predicting behavior of\nhuman agents. However, interestingly, we find that when the networks are\ntrained with long enough sequences of history of play, action-based networks do\nwell and additional economic details about the game do not improve their\nperformance, indicating that the sequence of actions encode sufficient\ninformation for the success in the prediction task.\n", "versions": [{"version": "v1", "created": "Fri, 8 Nov 2019 13:05:02 GMT"}], "update_date": "2019-11-11", "authors_parsed": [["Kolumbus", "Yoav", ""], ["Noti", "Gali", ""]]}, {"id": "1911.03350", "submitter": "Jacopo Staiano", "authors": "Thomas Scialom, Jacopo Staiano", "title": "Ask to Learn: A Study on Curiosity-driven Question Generation", "comments": "13 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel text generation task, namely Curiosity-driven Question\nGeneration. We start from the observation that the Question Generation task has\ntraditionally been considered as the dual problem of Question Answering, hence\ntackling the problem of generating a question given the text that contains its\nanswer. Such questions can be used to evaluate machine reading comprehension.\nHowever, in real life, and especially in conversational settings, humans tend\nto ask questions with the goal of enriching their knowledge and/or clarifying\naspects of previously gathered information. We refer to these inquisitive\nquestions as Curiosity-driven: these questions are generated with the goal of\nobtaining new information (the answer) which is not present in the input text.\nIn this work, we experiment on this new task using a conversational Question\nAnswering (QA) dataset; further, since the majority of QA dataset are not built\nin a conversational manner, we describe a methodology to derive data for this\nnovel task from non-conversational QA data. We investigate several automated\nmetrics to measure the different properties of Curious Questions, and\nexperiment different approaches on the Curiosity-driven Question Generation\ntask, including model pre-training and reinforcement learning. Finally, we\nreport a qualitative evaluation of the generated outputs.\n", "versions": [{"version": "v1", "created": "Fri, 8 Nov 2019 16:17:40 GMT"}], "update_date": "2019-11-11", "authors_parsed": [["Scialom", "Thomas", ""], ["Staiano", "Jacopo", ""]]}, {"id": "1911.03378", "submitter": "Maryam Fazel-Zarandi", "authors": "Maryam Fazel-Zarandi, Longshaokan Wang, Aditya Tiwari, Spyros\n  Matsoukas", "title": "Investigation of Error Simulation Techniques for Learning Dialog\n  Policies for Conversational Error Recovery", "comments": "The 3rd Conversational AI workshop - today's practice and tomorrow's\n  potential", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Training dialog policies for speech-based virtual assistants requires a\nplethora of conversational data. The data collection phase is often expensive\nand time consuming due to human involvement. To address this issue, a common\nsolution is to build user simulators for data generation. For the successful\ndeployment of the trained policies into real world domains, it is vital that\nthe user simulator mimics realistic conditions. In particular, speech-based\nassistants are heavily affected by automatic speech recognition and language\nunderstanding errors, hence the user simulator should be able to simulate\nsimilar errors. In this paper, we review the existing error simulation methods\nthat induce errors at audio, phoneme, text, or semantic level; and conduct\ndetailed comparisons between the audio-level and text-level methods. In the\nprocess, we improve the existing text-level method by introducing confidence\nscore prediction and out-of-vocabulary word mapping. We also explore the impact\nof audio-level and text-level methods on learning a simple clarification dialog\npolicy to recover from errors to provide insight on future improvement for both\napproaches.\n", "versions": [{"version": "v1", "created": "Fri, 8 Nov 2019 16:59:17 GMT"}], "update_date": "2019-11-11", "authors_parsed": [["Fazel-Zarandi", "Maryam", ""], ["Wang", "Longshaokan", ""], ["Tiwari", "Aditya", ""], ["Matsoukas", "Spyros", ""]]}, {"id": "1911.03388", "submitter": "Ishan Srivastava", "authors": "Ishan Srivastava", "title": "A different take on the best-first game tree pruning algorithms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The alpha-beta pruning algorithms have been popular in game tree searching\never since they were discovered. Numerous enhancements are proposed in\nliterature and it is often overwhelming as to which would be the best for\nimplementation. A certain enhancement can take far too long to fine tune its\nhyper parameters or to decide whether it is going to not make much of a\ndifference due to the memory limitations. On the other hand are the best first\npruning techniques, mostly the counterparts of the infamous SSS* algorithm, the\nalgorithm which proved out to be disruptive at the time of its discovery but\ngradually became outcast as being too memory intensive and having a higher time\ncomplexity. Later research doesn't see the best first approaches to be\ncompletely different from the depth first based enhancements but both seem to\nbe transitionary in the sense that a best first approach could be looked as a\ndepth first approach with a certain set of enhancements and with the growing\npower of the computers, SSS* didn't seem to be as taxing on the memory either.\nEven so, there seems to be quite difficulty in understanding the nature of the\nSSS* algorithm, why it does what it does and it being termed as being too\ncomplex to fathom, visualize and understand on an intellectual level. This\narticle tries to bridge this gap and provide some experimental results\ncomparing the two with the most promising advances.\n", "versions": [{"version": "v1", "created": "Fri, 8 Nov 2019 17:13:09 GMT"}], "update_date": "2019-11-11", "authors_parsed": [["Srivastava", "Ishan", ""]]}, {"id": "1911.03429", "submitter": "Jay DeYoung", "authors": "Jay DeYoung, Sarthak Jain, Nazneen Fatema Rajani, Eric Lehman, Caiming\n  Xiong, Richard Socher, Byron C. Wallace", "title": "ERASER: A Benchmark to Evaluate Rationalized NLP Models", "comments": "Accepted as a long paper to ACL2020 Website and leaderboard available\n  at http://www.eraserbenchmark.com/ Code available at\n  https://github.com/jayded/eraserbenchmark", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  State-of-the-art models in NLP are now predominantly based on deep neural\nnetworks that are opaque in terms of how they come to make predictions. This\nlimitation has increased interest in designing more interpretable deep models\nfor NLP that reveal the `reasoning' behind model outputs. But work in this\ndirection has been conducted on different datasets and tasks with\ncorrespondingly unique aims and metrics; this makes it difficult to track\nprogress. We propose the Evaluating Rationales And Simple English Reasoning\n(ERASER) benchmark to advance research on interpretable models in NLP. This\nbenchmark comprises multiple datasets and tasks for which human annotations of\n\"rationales\" (supporting evidence) have been collected. We propose several\nmetrics that aim to capture how well the rationales provided by models align\nwith human rationales, and also how faithful these rationales are (i.e., the\ndegree to which provided rationales influenced the corresponding predictions).\nOur hope is that releasing this benchmark facilitates progress on designing\nmore interpretable NLP systems. The benchmark, code, and documentation are\navailable at https://www.eraserbenchmark.com/\n", "versions": [{"version": "v1", "created": "Fri, 8 Nov 2019 18:29:03 GMT"}, {"version": "v2", "created": "Fri, 24 Apr 2020 17:25:40 GMT"}], "update_date": "2020-04-27", "authors_parsed": [["DeYoung", "Jay", ""], ["Jain", "Sarthak", ""], ["Rajani", "Nazneen Fatema", ""], ["Lehman", "Eric", ""], ["Xiong", "Caiming", ""], ["Socher", "Richard", ""], ["Wallace", "Byron C.", ""]]}, {"id": "1911.03594", "submitter": "Florian Golemo", "authors": "Maxime Chevalier-Boisvert, Guillaume Alain, Florian Golemo, Derek\n  Nowrouzezahrai", "title": "Robo-PlaNet: Learning to Poke in a Day", "comments": "4 pages, 3 figures. Version 2: added reference and acknowledgement", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, the Deep Planning Network (PlaNet) approach was introduced as a\nmodel-based reinforcement learning method that learns environment dynamics\ndirectly from pixel observations. This architecture is useful for learning\ntasks in which either the agent does not have access to meaningful states (like\nposition/velocity of robotic joints) or where the observed states significantly\ndeviate from the physical state of the agent (which is commonly the case in\nlow-cost robots in the form of backlash or noisy joint readings). PlaNet, by\ndesign, interleaves phases of training the dynamics model with phases of\ncollecting more data on the target environment, leading to long training times.\nIn this work, we introduce Robo-PlaNet, an asynchronous version of PlaNet. This\nalgorithm consistently reaches higher performance in the same amount of time,\nwhich we demonstrate in both a simulated and a real robotic experiment.\n", "versions": [{"version": "v1", "created": "Sat, 9 Nov 2019 02:05:18 GMT"}, {"version": "v2", "created": "Tue, 19 Nov 2019 23:12:39 GMT"}], "update_date": "2019-11-21", "authors_parsed": [["Chevalier-Boisvert", "Maxime", ""], ["Alain", "Guillaume", ""], ["Golemo", "Florian", ""], ["Nowrouzezahrai", "Derek", ""]]}, {"id": "1911.03618", "submitter": "Yichuan Charlie Tang", "authors": "Yichuan Charlie Tang, Jian Zhang, Ruslan Salakhutdinov", "title": "Worst Cases Policy Gradients", "comments": "Conference on Robot Learning 2019 (CoRL 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in deep reinforcement learning have demonstrated the\ncapability of learning complex control policies from many types of\nenvironments. When learning policies for safety-critical applications, it is\nessential to be sensitive to risks and avoid catastrophic events. Towards this\ngoal, we propose an actor-critic framework that models the uncertainty of the\nfuture and simultaneously learns a policy based on that uncertainty model.\nSpecifically, given a distribution of the future return for any state and\naction, we optimize policies for varying levels of conditional Value-at-Risk.\nThe learned policy can map the same state to different actions depending on the\npropensity for risk. We demonstrate the effectiveness of our approach in the\ndomain of driving simulations, where we learn maneuvers in two scenarios. Our\nlearned controller can dynamically select actions along a continuous axis,\nwhere safe and conservative behaviors are found at one end while riskier\nbehaviors are found at the other. Finally, when testing with very different\nsimulation parameters, our risk-averse policies generalize significantly better\ncompared to other reinforcement learning approaches.\n", "versions": [{"version": "v1", "created": "Sat, 9 Nov 2019 06:24:43 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["Tang", "Yichuan Charlie", ""], ["Zhang", "Jian", ""], ["Salakhutdinov", "Ruslan", ""]]}, {"id": "1911.03663", "submitter": "Dongyeop Kang", "authors": "Dongyeop Kang, Eduard Hovy", "title": "Style is NOT a single variable: Case Studies for Cross-Style Language\n  Understanding", "comments": "Accepted to ACL 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Every natural text is written in some style. Style is formed by a complex\ncombination of different stylistic factors, including formality markers,\nemotions, metaphors, etc. One cannot form a complete understanding of a text\nwithout considering these factors. The factors combine and co-vary in complex\nways to form styles. Studying the nature of the co-varying combinations sheds\nlight on stylistic language in general, sometimes called cross-style language\nunderstanding. This paper provides the benchmark corpus (xSLUE) that combines\nexisting datasets and collects a new one for sentence-level cross-style\nlanguage understanding and evaluation. The benchmark contains text in 15\ndifferent styles under the proposed four theoretical groupings: figurative,\npersonal, affective, and interpersonal groups. For valid evaluation, we collect\nan additional diagnostic set by annotating all 15 styles on the same text.\nUsing xSLUE, we propose three interesting cross-style applications in\nclassification, correlation, and generation. First, our proposed cross-style\nclassifier trained with multiple styles together helps improve overall\nclassification performance against individually-trained style classifiers.\nSecond, our study shows that some styles are highly dependent on each other in\nhuman-written text. Finally, we find that combinations of some contradictive\nstyles likely generate stylistically less appropriate text. We believe our\nbenchmark and case studies help explore interesting future directions for\ncross-style research. The preprocessed datasets and code are publicly\navailable.\n", "versions": [{"version": "v1", "created": "Sat, 9 Nov 2019 10:55:34 GMT"}, {"version": "v2", "created": "Wed, 2 Jun 2021 00:41:40 GMT"}], "update_date": "2021-06-03", "authors_parsed": [["Kang", "Dongyeop", ""], ["Hovy", "Eduard", ""]]}, {"id": "1911.03679", "submitter": "Kevin Kappelmann", "authors": "Kevin Kappelmann", "title": "Decision Procedures for Guarded Logics", "comments": "A thesis submitted in partial fulfilment for the degree of MSc in\n  Mathematics and Foundations of Computer Science at the University of Oxford.\n  Update 25.03.2021: added missing constraint in definition of simple\n  saturation algorithm", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An important class of decidable first-order logic fragments are those\nsatisfying a guardedness condition, such as the guarded fragment (GF). Usually,\ndecidability for these logics is closely linked to the tree-like model property\n- the fact that satisfying models can be taken to have tree-like form. Decision\nprocedures for the guarded fragment based on the tree-like model property are\ndifficult to implement. An alternative approach, based on restricting\nfirst-order resolution, has been proposed, and this shows more promise from the\npoint of view of implementation. In this work, we connect the tree-like model\nproperty of the guarded fragment with the resolution-based approach. We derive\nefficient resolution-based rewriting algorithms that solve the Quantifier-Free\nQuery Answering Problem under Guarded Tuple Generating Dependencies (GTGDs) and\nDisjunctive Guarded Tuple Generating Dependencies (DisGTGDs). The Query\nAnswering Problem for these classes subsumes many cases of GF satisfiability.\nOur algorithms, in addition to making the connection to the tree-like model\nproperty clear, give a natural account of the selection and ordering strategies\nused by resolution procedures for the guarded fragment. We also believe that\nour rewriting algorithm for the special case of GTGDs may prove itself valuable\nin practice as it does not require any Skolemisation step and its theoretical\nruntime outperforms those of known GF resolution procedures in case of fixed\ndependencies. Moreover, we show a novel normalisation procedure for the widely\nused chase procedure in case of (disjunctive) GTGDs, which could be useful for\nfuture studies.\n", "versions": [{"version": "v1", "created": "Sat, 9 Nov 2019 12:44:21 GMT"}, {"version": "v2", "created": "Thu, 25 Mar 2021 13:50:53 GMT"}], "update_date": "2021-03-26", "authors_parsed": [["Kappelmann", "Kevin", ""]]}, {"id": "1911.03705", "submitter": "Bill Yuchen Lin", "authors": "Bill Yuchen Lin, Wangchunshu Zhou, Ming Shen, Pei Zhou, Chandra\n  Bhagavatula, Yejin Choi, Xiang Ren", "title": "CommonGen: A Constrained Text Generation Challenge for Generative\n  Commonsense Reasoning", "comments": "Accepted to EMNLP 2020 Findings. Add one more human reference for\n  each test example: Table 1,3 & Figure 4 & Section 3.3, 3.4 are updated.\n  Project page: https://inklab.usc.edu/CommonGen/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, large-scale pre-trained language models have demonstrated\nimpressive performance on several commonsense-reasoning benchmark datasets.\nHowever, building machines with commonsense to compose realistically plausible\nsentences remains challenging. In this paper, we present a constrained text\ngeneration task, CommonGen associated with a benchmark dataset, to explicitly\ntest machines for the ability of generative commonsense reasoning. Given a set\nof common concepts (e.g., {dog, frisbee, catch, throw}); the task is to\ngenerate a coherent sentence describing an everyday scenario using these\nconcepts (e.g., \"a man throws a frisbee and his dog catches it\").\n  The CommonGen task is challenging because it inherently requires 1)\nrelational reasoning with background commonsense knowledge, and 2)\ncompositional generalization ability to work on unseen concept combinations.\nOur dataset, constructed through a combination of crowdsourced and existing\ncaption corpora, consists of 79k commonsense descriptions over 35k unique\nconcept-sets. Experiments show that there is a large gap between\nstate-of-the-art text generation models (e.g., T5) and human performance.\nFurthermore, we demonstrate that the learned generative commonsense reasoning\ncapability can be transferred to improve downstream tasks such as CommonsenseQA\nby generating additional context.\n", "versions": [{"version": "v1", "created": "Sat, 9 Nov 2019 14:53:59 GMT"}, {"version": "v2", "created": "Sat, 2 May 2020 01:26:38 GMT"}, {"version": "v3", "created": "Fri, 18 Sep 2020 00:57:08 GMT"}, {"version": "v4", "created": "Mon, 30 Nov 2020 07:53:50 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Lin", "Bill Yuchen", ""], ["Zhou", "Wangchunshu", ""], ["Shen", "Ming", ""], ["Zhou", "Pei", ""], ["Bhagavatula", "Chandra", ""], ["Choi", "Yejin", ""], ["Ren", "Xiang", ""]]}, {"id": "1911.03731", "submitter": "Jonathan Baxter", "authors": "Jonathan Baxter", "title": "Learning Internal Representations (PhD Thesis)", "comments": "Phd Thesis, Jonathan Baxter, 1994", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most machine learning theory and practice is concerned with learning a single\ntask. In this thesis it is argued that in general there is insufficient\ninformation in a single task for a learner to generalise well and that what is\nrequired for good generalisation is information about many similar learning\ntasks. Similar learning tasks form a body of prior information that can be used\nto constrain the learner and make it generalise better. Examples of learning\nscenarios in which there are many similar tasks are handwritten character\nrecognition and spoken word recognition.\n  The concept of the environment of a learner is introduced as a probability\nmeasure over the set of learning problems the learner might be expected to\nlearn. It is shown how a sample from the environment may be used to learn a\nrepresentation, or recoding of the input space that is appropriate for the\nenvironment. Learning a representation can equivalently be thought of as\nlearning the appropriate features of the environment. Bounds are derived on the\nsample size required to ensure good generalisation from a representation\nlearning process. These bounds show that under certain circumstances learning a\nrepresentation appropriate for $n$ tasks reduces the number of examples\nrequired of each task by a factor of $n$.\n  Once a representation is learnt it can be used to learn novel tasks from the\nsame environment, with the result that far fewer examples are required of the\nnew tasks to ensure good generalisation. Bounds are given on the number of\ntasks and the number of samples from each task required to ensure that a\nrepresentation will be a good one for learning novel tasks.\n  The results on representation learning are generalised to cover any form of\nautomated hypothesis space bias.\n", "versions": [{"version": "v1", "created": "Sat, 9 Nov 2019 16:25:33 GMT"}, {"version": "v2", "created": "Fri, 22 Nov 2019 15:20:46 GMT"}], "update_date": "2019-11-25", "authors_parsed": [["Baxter", "Jonathan", ""]]}, {"id": "1911.03743", "submitter": "Homagni Saha", "authors": "Homagni Saha, Vijay Venkataraman, Alberto Speranzon, Soumik Sarkar", "title": "A perspective on multi-agent communication for information fusion", "comments": "NeuRIPS 2019, Workshop on Visually Grounded Interaction and Language,\n  Vancouver, CA", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Collaborative decision making in multi-agent systems typically requires a\npredefined communication protocol among agents. Usually, agent-level\nobservations are locally processed and information is exchanged using the\npredefined protocol, enabling the team to perform more efficiently than each\nagent operating in isolation. In this work, we consider the situation where\nagents, with complementary sensing modalities must co-operate to achieve a\ncommon goal/task by learning an efficient communication protocol. We frame the\nproblem within an actor-critic scheme, where the agents learn optimal policies\nin a centralized fashion, while taking action in a distributed manner. We\nprovide an interpretation of the emergent communication between the agents. We\nobserve that the information exchanged is not just an encoding of the raw\nsensor data but is, rather, a specific set of directive actions that depend on\nthe overall task. Simulation results demonstrate the interpretability of the\nlearnt communication in a variety of tasks.\n", "versions": [{"version": "v1", "created": "Sat, 9 Nov 2019 17:56:47 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["Saha", "Homagni", ""], ["Venkataraman", "Vijay", ""], ["Speranzon", "Alberto", ""], ["Sarkar", "Soumik", ""]]}, {"id": "1911.03768", "submitter": "Kurt Shuster", "authors": "Kurt Shuster, Da Ju, Stephen Roller, Emily Dinan, Y-Lan Boureau, Jason\n  Weston", "title": "The Dialogue Dodecathlon: Open-Domain Knowledge and Image Grounded\n  Conversational Agents", "comments": "ACL 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce dodecaDialogue: a set of 12 tasks that measures if a\nconversational agent can communicate engagingly with personality and empathy,\nask questions, answer questions by utilizing knowledge resources, discuss\ntopics and situations, and perceive and converse about images. By multi-tasking\non such a broad large-scale set of data, we hope to both move towards and\nmeasure progress in producing a single unified agent that can perceive, reason\nand converse with humans in an open-domain setting. We show that such\nmulti-tasking improves over a BERT pre-trained baseline, largely due to\nmulti-tasking with very large dialogue datasets in a similar domain, and that\nthe multi-tasking in general provides gains to both text and image-based tasks\nusing several metrics in both the fine-tune and task transfer settings. We\nobtain state-of-the-art results on many of the tasks, providing a strong\nbaseline for this challenge.\n", "versions": [{"version": "v1", "created": "Sat, 9 Nov 2019 20:05:06 GMT"}, {"version": "v2", "created": "Tue, 28 Apr 2020 19:38:03 GMT"}], "update_date": "2020-04-30", "authors_parsed": [["Shuster", "Kurt", ""], ["Ju", "Da", ""], ["Roller", "Stephen", ""], ["Dinan", "Emily", ""], ["Boureau", "Y-Lan", ""], ["Weston", "Jason", ""]]}, {"id": "1911.03849", "submitter": "Xinghua Qu", "authors": "Xinghua Qu, Zhu Sun, Yew-Soon Ong, Abhishek Gupta, Pengfei Wei", "title": "Minimalistic Attacks: How Little it Takes to Fool a Deep Reinforcement\n  Learning Policy", "comments": "Accepted by IEEE Transactions on Cognitive and Developmental System", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent studies have revealed that neural network-based policies can be easily\nfooled by adversarial examples. However, while most prior works analyze the\neffects of perturbing every pixel of every frame assuming white-box policy\naccess, in this paper we take a more restrictive view towards adversary\ngeneration - with the goal of unveiling the limits of a model's vulnerability.\nIn particular, we explore minimalistic attacks by defining three key settings:\n(1) black-box policy access: where the attacker only has access to the input\n(state) and output (action probability) of an RL policy; (2) fractional-state\nadversary: where only several pixels are perturbed, with the extreme case being\na single-pixel adversary; and (3) tactically-chanced attack: where only\nsignificant frames are tactically chosen to be attacked. We formulate the\nadversarial attack by accommodating the three key settings and explore their\npotency on six Atari games by examining four fully trained state-of-the-art\npolicies. In Breakout, for example, we surprisingly find that: (i) all policies\nshowcase significant performance degradation by merely modifying 0.01% of the\ninput state, and (ii) the policy trained by DQN is totally deceived by\nperturbation to only 1% frames.\n", "versions": [{"version": "v1", "created": "Sun, 10 Nov 2019 04:39:56 GMT"}, {"version": "v2", "created": "Fri, 22 Nov 2019 08:28:44 GMT"}, {"version": "v3", "created": "Fri, 21 Feb 2020 00:51:06 GMT"}, {"version": "v4", "created": "Fri, 6 Mar 2020 01:46:01 GMT"}, {"version": "v5", "created": "Thu, 29 Oct 2020 13:40:22 GMT"}], "update_date": "2020-10-30", "authors_parsed": [["Qu", "Xinghua", ""], ["Sun", "Zhu", ""], ["Ong", "Yew-Soon", ""], ["Gupta", "Abhishek", ""], ["Wei", "Pengfei", ""]]}, {"id": "1911.03850", "submitter": "Daniel Khashabi Mr.", "authors": "Erfan Sadeqi Azer, Daniel Khashabi, Ashish Sabharwal, Dan Roth", "title": "Not All Claims are Created Equal: Choosing the Right Statistical\n  Approach to Assess Hypotheses", "comments": "ACL 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Empirical research in Natural Language Processing (NLP) has adopted a narrow\nset of principles for assessing hypotheses, relying mainly on p-value\ncomputation, which suffers from several known issues. While alternative\nproposals have been well-debated and adopted in other fields, they remain\nrarely discussed or used within the NLP community. We address this gap by\ncontrasting various hypothesis assessment techniques, especially those not\ncommonly used in the field (such as evaluations based on Bayesian inference).\nSince these statistical techniques differ in the hypotheses they can support,\nwe argue that practitioners should first decide their target hypothesis before\nchoosing an assessment method. This is crucial because common fallacies,\nmisconceptions, and misinterpretation surrounding hypothesis assessment methods\noften stem from a discrepancy between what one would like to claim versus what\nthe method used actually assesses. Our survey reveals that these issues are\nomnipresent in the NLP research community. As a step forward, we provide best\npractices and guidelines tailored to NLP research, as well as an easy-to-use\npackage called 'HyBayes' for Bayesian assessment of hypotheses, complementing\nexisting tools.\n", "versions": [{"version": "v1", "created": "Sun, 10 Nov 2019 04:41:31 GMT"}, {"version": "v2", "created": "Tue, 28 Apr 2020 17:13:55 GMT"}, {"version": "v3", "created": "Tue, 5 May 2020 00:19:19 GMT"}], "update_date": "2020-05-06", "authors_parsed": [["Azer", "Erfan Sadeqi", ""], ["Khashabi", "Daniel", ""], ["Sabharwal", "Ashish", ""], ["Roth", "Dan", ""]]}, {"id": "1911.03868", "submitter": "Sewon Min", "authors": "Sewon Min, Danqi Chen, Luke Zettlemoyer, Hannaneh Hajishirzi", "title": "Knowledge Guided Text Retrieval and Reading for Open Domain Question\n  Answering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce an approach for open-domain question answering (QA) that\nretrieves and reads a passage graph, where vertices are passages of text and\nedges represent relationships that are derived from an external knowledge base\nor co-occurrence in the same article. Our goals are to boost coverage by using\nknowledge-guided retrieval to find more relevant passages than text-matching\nmethods, and to improve accuracy by allowing for better knowledge-guided fusion\nof information across related passages. Our graph retrieval method expands a\nset of seed keyword-retrieved passages by traversing the graph structure of the\nknowledge base. Our reader extends a BERT-based architecture and updates\npassage representations by propagating information from related passages and\ntheir relations, instead of reading each passage in isolation. Experiments on\nthree open-domain QA datasets, WebQuestions, Natural Questions and TriviaQA,\nshow improved performance over non-graph baselines by 2-11% absolute. Our\napproach also matches or exceeds the state-of-the-art in every case, without\nusing an expensive end-to-end training regime.\n", "versions": [{"version": "v1", "created": "Sun, 10 Nov 2019 06:58:44 GMT"}, {"version": "v2", "created": "Mon, 13 Apr 2020 16:25:54 GMT"}], "update_date": "2020-04-14", "authors_parsed": [["Min", "Sewon", ""], ["Chen", "Danqi", ""], ["Zettlemoyer", "Luke", ""], ["Hajishirzi", "Hannaneh", ""]]}, {"id": "1911.03927", "submitter": "Jinmingwu Jiang", "authors": "Jinmingwu Jiang, Kaigui Wu", "title": "Cooperative Pathfinding based on memory-efficient Multi-agent RRT*", "comments": "IROS 2020, October 25-29, Las Vegas, NV, USA", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In cooperative pathfinding problems, no-conflicts paths that bring several\nagents from their start location to their destination need to be planned. This\nproblem can be efficiently solved by Multi-agent RRT*(MA-RRT*) algorithm, which\nis still state-of-the-art in the field of coupled methods. However, the\nimplementation of this algorithm is hindered in systems with limited memory\nbecause the number of nodes in the tree grows indefinitely as the paths get\noptimized. This paper proposes an improved version of MA-RRT*, called\nMulti-agent RRT* Fixed Node(MA-RRT*FN), which limits the number of nodes stored\nin the tree by removing the weak nodes on the path which are not likely to\nreach the goal. The results show that MA-RRT*FN performs close to MA-RRT* in\nterms of scalability and solution quality while the memory required is much\nlower and fixed.\n", "versions": [{"version": "v1", "created": "Sun, 10 Nov 2019 13:21:14 GMT"}, {"version": "v2", "created": "Sat, 16 Nov 2019 12:45:44 GMT"}, {"version": "v3", "created": "Wed, 4 Mar 2020 03:19:25 GMT"}], "update_date": "2020-03-05", "authors_parsed": [["Jiang", "Jinmingwu", ""], ["Wu", "Kaigui", ""]]}, {"id": "1911.03977", "submitter": "Chao Zhang", "authors": "Chao Zhang, Zichao Yang, Xiaodong He, Li Deng", "title": "Multimodal Intelligence: Representation Learning, Information Fusion,\n  and Applications", "comments": null, "journal-ref": null, "doi": "10.1109/JSTSP.2020.2987728", "report-no": null, "categories": "cs.AI cs.CL cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning methods have revolutionized speech recognition, image\nrecognition, and natural language processing since 2010. Each of these tasks\ninvolves a single modality in their input signals. However, many applications\nin the artificial intelligence field involve multiple modalities. Therefore, it\nis of broad interest to study the more difficult and complex problem of\nmodeling and learning across multiple modalities. In this paper, we provide a\ntechnical review of available models and learning methods for multimodal\nintelligence. The main focus of this review is the combination of vision and\nnatural language modalities, which has become an important topic in both the\ncomputer vision and natural language processing research communities. This\nreview provides a comprehensive analysis of recent works on multimodal deep\nlearning from three perspectives: learning multimodal representations, fusing\nmultimodal signals at various levels, and multimodal applications. Regarding\nmultimodal representation learning, we review the key concepts of embedding,\nwhich unify multimodal signals into a single vector space and thereby enable\ncross-modality signal processing. We also review the properties of many types\nof embeddings that are constructed and learned for general downstream tasks.\nRegarding multimodal fusion, this review focuses on special architectures for\nthe integration of representations of unimodal signals for a particular task.\nRegarding applications, selected areas of a broad interest in the current\nliterature are covered, including image-to-text caption generation,\ntext-to-image generation, and visual question answering. We believe that this\nreview will facilitate future studies in the emerging field of multimodal\nintelligence for related communities.\n", "versions": [{"version": "v1", "created": "Sun, 10 Nov 2019 18:58:20 GMT"}, {"version": "v2", "created": "Mon, 23 Mar 2020 11:00:48 GMT"}, {"version": "v3", "created": "Fri, 10 Apr 2020 09:16:13 GMT"}], "update_date": "2020-07-15", "authors_parsed": [["Zhang", "Chao", ""], ["Yang", "Zichao", ""], ["He", "Xiaodong", ""], ["Deng", "Li", ""]]}, {"id": "1911.04021", "submitter": "Abdelrahman Hosny", "authors": "Abdelrahman Hosny, Soheil Hashemi, Mohamed Shalan and Sherief Reda", "title": "DRiLLS: Deep Reinforcement Learning for Logic Synthesis", "comments": "ASPDAC'2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Logic synthesis requires extensive tuning of the synthesis optimization flow\nwhere the quality of results (QoR) depends on the sequence of optimizations\nused. Efficient design space exploration is challenging due to the exponential\nnumber of possible optimization permutations. Therefore, automating the\noptimization process is necessary. In this work, we propose a novel\nreinforcement learning-based methodology that navigates the optimization space\nwithout human intervention. We demonstrate the training of an Advantage Actor\nCritic (A2C) agent that seeks to minimize area subject to a timing constraint.\nUsing the proposed methodology, designs can be optimized autonomously with\nno-humans in-loop. Evaluation on the comprehensive EPFL benchmark suite shows\nthat the agent outperforms existing exploration methodologies and improves QoRs\nby an average of 13%.\n", "versions": [{"version": "v1", "created": "Mon, 11 Nov 2019 00:38:39 GMT"}, {"version": "v2", "created": "Wed, 13 Nov 2019 04:07:24 GMT"}], "update_date": "2019-11-14", "authors_parsed": [["Hosny", "Abdelrahman", ""], ["Hashemi", "Soheil", ""], ["Shalan", "Mohamed", ""], ["Reda", "Sherief", ""]]}, {"id": "1911.04024", "submitter": "Swaminathan Gurumurthy", "authors": "Swaminathan Gurumurthy, Sumit Kumar, Katia Sycara", "title": "MAME : Model-Agnostic Meta-Exploration", "comments": "CoRL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Meta-Reinforcement learning approaches aim to develop learning procedures\nthat can adapt quickly to a distribution of tasks with the help of a few\nexamples. Developing efficient exploration strategies capable of finding the\nmost useful samples becomes critical in such settings. Existing approaches\ntowards finding efficient exploration strategies add auxiliary objectives to\npromote exploration by the pre-update policy, however, this makes the\nadaptation using a few gradient steps difficult as the pre-update (exploration)\nand post-update (exploitation) policies are often quite different. Instead, we\npropose to explicitly model a separate exploration policy for the task\ndistribution. Having two different policies gives more flexibility in training\nthe exploration policy and also makes adaptation to any specific task easier.\nWe show that using self-supervised or supervised learning objectives for\nadaptation allows for more efficient inner-loop updates and also demonstrate\nthe superior performance of our model compared to prior works in this domain.\n", "versions": [{"version": "v1", "created": "Mon, 11 Nov 2019 00:58:50 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["Gurumurthy", "Swaminathan", ""], ["Kumar", "Sumit", ""], ["Sycara", "Katia", ""]]}, {"id": "1911.04065", "submitter": "Yunan Zhang", "authors": "Yunan Zhang, Xiang Cheng, Yufeng Zhang, Zihan Wang, Zhengqi Fang,\n  Xiaoyan Wang, Zhenya Huang, Chengxiang Zhai", "title": "Learning to Order Sub-questions for Complex Question Answering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Answering complex questions involving multiple entities and relations is a\nchallenging task. Logically, the answer to a complex question should be derived\nby decomposing the complex question into multiple simple sub-questions and then\nanswering those sub-questions. Existing work has followed this strategy but has\nnot attempted to optimize the order of how those sub-questions are answered. As\na result, the sub-questions are answered in an arbitrary order, leading to\nlarger search space and a higher risk of missing an answer. In this paper, we\npropose a novel reinforcement learning(RL) approach to answering complex\nquestions that can learn a policy to dynamically decide which sub-question\nshould be answered at each stage of reasoning. We lever-age the expected\nvalue-variance criterion to enable the learned policy to balance between the\nrisk and utility of answering a sub-question. Experiment results show that the\nRL approach can substantially improve the optimality of ordering the\nsub-questions, leading to improved accuracy of question answering. The proposed\nmethod for learning to order sub-questions is general and can thus be\npotentially combined with many existing ideas for answering complex questions\nto enhance their performance.\n", "versions": [{"version": "v1", "created": "Mon, 11 Nov 2019 04:06:46 GMT"}, {"version": "v2", "created": "Tue, 12 Nov 2019 03:03:25 GMT"}], "update_date": "2019-11-13", "authors_parsed": [["Zhang", "Yunan", ""], ["Cheng", "Xiang", ""], ["Zhang", "Yufeng", ""], ["Wang", "Zihan", ""], ["Fang", "Zhengqi", ""], ["Wang", "Xiaoyan", ""], ["Huang", "Zhenya", ""], ["Zhai", "Chengxiang", ""]]}, {"id": "1911.04107", "submitter": "Gang Chen", "authors": "Gang Chen, Dingcheng Li and Ran Xu", "title": "Context-aware Active Multi-Step Reinforcement Learning", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning has attracted great attention recently, especially\npolicy gradient algorithms, which have been demonstrated on challenging\ndecision making and control tasks. In this paper, we propose an active\nmulti-step TD algorithm with adaptive stepsizes to learn actor and critic.\nSpecifically, our model consists of two components: active stepsize learning\nand adaptive multi-step TD algorithm. Firstly, we divide the time horizon into\nchunks and actively select state and action inside each chunk. Then given the\nselected samples, we propose the adaptive multi-step TD, which generalizes\nTD($\\lambda$), but adaptively switch on/off the backups from future returns of\ndifferent steps. Particularly, the adaptive multi-step TD introduces a\ncontext-aware mechanism, here a binary classifier, which decides whether or not\nto turn on its future backups based on the context changes. Thus, our model is\nkind of combination of active learning and multi-step TD algorithm, which has\nthe capacity for learning off-policy without the need of importance sampling.\nWe evaluate our approach on both discrete and continuous space tasks in an\noff-policy setting respectively, and demonstrate competitive results compared\nto other reinforcement learning baselines.\n", "versions": [{"version": "v1", "created": "Mon, 11 Nov 2019 06:37:47 GMT"}, {"version": "v2", "created": "Wed, 27 Nov 2019 06:47:54 GMT"}], "update_date": "2019-11-28", "authors_parsed": [["Chen", "Gang", ""], ["Li", "Dingcheng", ""], ["Xu", "Ran", ""]]}, {"id": "1911.04156", "submitter": "Jordan Boyd-Graber", "authors": "Benjamin Borschinger, Jordan Boyd-Graber, Christian Buck, Jannis\n  Bulian, Massimiliano Ciaramita, Michelle Chen Huebscher, Wojciech Gajewski,\n  Yannic Kilcher, Rodrigo Nogueira, Lierni Sestorain Saralegu", "title": "Meta Answering for Machine Reading", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate a framework for machine reading, inspired by real world\ninformation-seeking problems, where a meta question answering system interacts\nwith a black box environment. The environment encapsulates a competitive\nmachine reader based on BERT, providing candidate answers to questions, and\npossibly some context. To validate the realism of our formulation, we ask\nhumans to play the role of a meta-answerer. With just a small snippet of text\naround an answer, humans can outperform the machine reader, improving recall.\nSimilarly, a simple machine meta-answerer outperforms the environment,\nimproving both precision and recall on the Natural Questions dataset. The\nsystem relies on joint training of answer scoring and the selection of\nconditioning information.\n", "versions": [{"version": "v1", "created": "Mon, 11 Nov 2019 10:07:57 GMT"}, {"version": "v2", "created": "Thu, 30 Apr 2020 19:33:19 GMT"}], "update_date": "2020-05-04", "authors_parsed": [["Borschinger", "Benjamin", ""], ["Boyd-Graber", "Jordan", ""], ["Buck", "Christian", ""], ["Bulian", "Jannis", ""], ["Ciaramita", "Massimiliano", ""], ["Huebscher", "Michelle Chen", ""], ["Gajewski", "Wojciech", ""], ["Kilcher", "Yannic", ""], ["Nogueira", "Rodrigo", ""], ["Saralegu", "Lierni Sestorain", ""]]}, {"id": "1911.04175", "submitter": "Praveen Palanisamy", "authors": "Praveen Palanisamy", "title": "Multi-Agent Connected Autonomous Driving using Deep Reinforcement\n  Learning", "comments": "Accepted, Machine Learning for Autonomous Driving Workshop at the\n  33rd Conference on Neural Information Processing Systems(NeurIPS 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The capability to learn and adapt to changes in the driving environment is\ncrucial for developing autonomous driving systems that are scalable beyond\ngeo-fenced operational design domains. Deep Reinforcement Learning (RL)\nprovides a promising and scalable framework for developing adaptive learning\nbased solutions. Deep RL methods usually model the problem as a (Partially\nObservable) Markov Decision Process in which an agent acts in a stationary\nenvironment to learn an optimal behavior policy. However, driving involves\ncomplex interaction between multiple, intelligent (artificial or human) agents\nin a highly non-stationary environment. In this paper, we propose the use of\nPartially Observable Markov Games(POSG) for formulating the connected\nautonomous driving problems with realistic assumptions. We provide a taxonomy\nof multi-agent learning environments based on the nature of tasks, nature of\nagents and the nature of the environment to help in categorizing various\nautonomous driving problems that can be addressed under the proposed\nformulation. As our main contributions, we provide MACAD-Gym, a Multi-Agent\nConnected, Autonomous Driving agent learning platform for furthering research\nin this direction. Our MACAD-Gym platform provides an extensible set of\nConnected Autonomous Driving (CAD) simulation environments that enable the\nresearch and development of Deep RL- based integrated sensing, perception,\nplanning and control algorithms for CAD systems with unlimited operational\ndesign domain under realistic, multi-agent settings. We also share the\nMACAD-Agents that were trained successfully using the MACAD-Gym platform to\nlearn control policies for multiple vehicle agents in a partially observable,\nstop-sign controlled, 3-way urban intersection environment with raw (camera)\nsensor observations.\n", "versions": [{"version": "v1", "created": "Mon, 11 Nov 2019 10:55:25 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["Palanisamy", "Praveen", ""]]}, {"id": "1911.04180", "submitter": "M. Alex O. Vasilescu", "authors": "M. Alex O. Vasilescu and Eric Kim", "title": "Compositional Hierarchical Tensor Factorization: Representing\n  Hierarchical Intrinsic and Extrinsic Causal Factors", "comments": "VERS 2: Fixed out of sync ref. Added\n  [7,14,15,28,37,50,52,53,61,77,78] M.A.O. Vasilescu and E.Kim. Compositional\n  Hierarchical Tensor Factorization: Representing Hierarchical Intrinsic and\n  Extrinsic Causal Factors. In 25th ACM SIGKDD Conference on Knowledge\n  Discovery and Data Mining (KDD'19): Tensor Methods for Emerging Data Science\n  Challenges, August 04-08, 2019, Anchorage, AK.ACM, New York, NY", "journal-ref": "25th ACM SIGKDD Conference on Knowledge Discovery and Data Mining\n  (KDD'19): Tensor Methods for Emerging Data Science Challenges Workshop,\n  August 04-08, 2019, Anchorage, AK.ACM, New York, NY", "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG math.DG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Visual objects are composed of a recursive hierarchy of perceptual wholes and\nparts, whose properties, such as shape, reflectance, and color, constitute a\nhierarchy of intrinsic causal factors of object appearance. However, object\nappearance is the compositional consequence of both an object's intrinsic and\nextrinsic causal factors, where the extrinsic causal factors are related to\nillumination, and imaging conditions. Therefore, this paper proposes a unified\ntensor model of wholes and parts, and introduces a compositional hierarchical\ntensor factorization that disentangles the hierarchical causal structure of\nobject image formation, and subsumes multilinear block tensor decomposition as\na special case. The resulting object representation is an interpretable\ncombinatorial choice of wholes' and parts' representations that renders object\nrecognition robust to occlusion and reduces training data requirements. We\ndemonstrate ourapproach in the context of face recognition by training on an\nextremely reduced dataset of synthetic images, and report encouragingface\nverification results on two datasets - the Freiburg dataset, andthe Labeled\nFace in the Wild (LFW) dataset consisting of real world images, thus,\nsubstantiating the suitability of our approach for data starved domains.\n", "versions": [{"version": "v1", "created": "Mon, 11 Nov 2019 11:03:53 GMT"}, {"version": "v2", "created": "Wed, 1 Jan 2020 06:23:19 GMT"}], "update_date": "2021-03-01", "authors_parsed": [["Vasilescu", "M. Alex O.", ""], ["Kim", "Eric", ""]]}, {"id": "1911.04192", "submitter": "Ruize Wang", "authors": "Ruize Wang, Zhongyu Wei, Ying Cheng, Piji Li, Haijun Shan, Ji Zhang,\n  Qi Zhang, Xuanjing Huang", "title": "Keep it Consistent: Topic-Aware Storytelling from an Image Stream via\n  Iterative Multi-agent Communication", "comments": "Accepted to COLING 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Visual storytelling aims to generate a narrative paragraph from a sequence of\nimages automatically. Existing approaches construct text description\nindependently for each image and roughly concatenate them as a story, which\nleads to the problem of generating semantically incoherent content. In this\npaper, we propose a new way for visual storytelling by introducing a topic\ndescription task to detect the global semantic context of an image stream. A\nstory is then constructed with the guidance of the topic description. In order\nto combine the two generation tasks, we propose a multi-agent communication\nframework that regards the topic description generator and the story generator\nas two agents and learn them simultaneously via iterative updating mechanism.\nWe validate our approach on VIST dataset, where quantitative results,\nablations, and human evaluation demonstrate our method's good ability in\ngenerating stories with higher quality compared to state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Mon, 11 Nov 2019 11:35:21 GMT"}, {"version": "v2", "created": "Fri, 30 Oct 2020 07:08:10 GMT"}], "update_date": "2020-11-02", "authors_parsed": [["Wang", "Ruize", ""], ["Wei", "Zhongyu", ""], ["Cheng", "Ying", ""], ["Li", "Piji", ""], ["Shan", "Haijun", ""], ["Zhang", "Ji", ""], ["Zhang", "Qi", ""], ["Huang", "Xuanjing", ""]]}, {"id": "1911.04220", "submitter": "Xiangyuan Zhang", "authors": "Xiangyuan Zhang, Kaiqing Zhang, Erik Miehling, Tamer Ba\\c{s}ar", "title": "Non-Cooperative Inverse Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.AI cs.LG cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Making decisions in the presence of a strategic opponent requires one to take\ninto account the opponent's ability to actively mask its intended objective. To\ndescribe such strategic situations, we introduce the non-cooperative inverse\nreinforcement learning (N-CIRL) formalism. The N-CIRL formalism consists of two\nagents with completely misaligned objectives, where only one of the agents\nknows the true objective function. Formally, we model the N-CIRL formalism as a\nzero-sum Markov game with one-sided incomplete information. Through interacting\nwith the more informed player, the less informed player attempts to both infer,\nand act according to, the true objective function. As a result of the one-sided\nincomplete information, the multi-stage game can be decomposed into a sequence\nof single-stage games expressed by a recursive formula. Solving this recursive\nformula yields the value of the N-CIRL game and the more informed player's\nequilibrium strategy. Another recursive formula, constructed by forming an\nauxiliary game, termed the dual game, yields the less informed player's\nstrategy. Building upon these two recursive formulas, we develop a\ncomputationally tractable algorithm to approximately solve for the equilibrium\nstrategies. Finally, we demonstrate the benefits of our N-CIRL formalism over\nthe existing multi-agent IRL formalism via extensive numerical simulation in a\nnovel cyber security setting.\n", "versions": [{"version": "v1", "created": "Sun, 3 Nov 2019 16:59:57 GMT"}, {"version": "v2", "created": "Mon, 6 Jan 2020 08:56:59 GMT"}], "update_date": "2020-01-07", "authors_parsed": [["Zhang", "Xiangyuan", ""], ["Zhang", "Kaiqing", ""], ["Miehling", "Erik", ""], ["Ba\u015far", "Tamer", ""]]}, {"id": "1911.04266", "submitter": "Ryan Carey", "authors": "Vojt\\v{e}ch Kova\\v{r}\\'ik and Ryan Carey", "title": "(When) Is Truth-telling Favored in AI Debate?", "comments": "In SafeAI Workshop at AAAI, 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For some problems, humans may not be able to accurately judge the goodness of\nAI-proposed solutions. Irving et al. (2018) propose that in such cases, we may\nuse a debate between two AI systems to amplify the problem-solving capabilities\nof a human judge. We introduce a mathematical framework that can model debates\nof this type and propose that the quality of debate designs should be measured\nby the accuracy of the most persuasive answer. We describe a simple instance of\nthe debate framework called feature debate and analyze the degree to which such\ndebates track the truth. We argue that despite being very simple, feature\ndebates nonetheless capture many aspects of practical debates such as the\nincentives to confuse the judge or stall to prevent losing. We then outline how\nthese models should be generalized to analyze a wider range of debate\nphenomena.\n", "versions": [{"version": "v1", "created": "Mon, 11 Nov 2019 13:49:43 GMT"}, {"version": "v2", "created": "Sun, 15 Dec 2019 14:37:09 GMT"}, {"version": "v3", "created": "Tue, 16 Mar 2021 15:42:42 GMT"}], "update_date": "2021-03-17", "authors_parsed": [["Kova\u0159\u00edk", "Vojt\u011bch", ""], ["Carey", "Ryan", ""]]}, {"id": "1911.04326", "submitter": "Francesco Calimeri", "authors": "Francesco Calimeri, Wolfgang Faber, Martin Gebser, Giovambattista\n  Ianni, Roland Kaminski, Thomas Krennwallner, Nicola Leone, Marco Maratea,\n  Francesco Ricca, Torsten Schaub", "title": "ASP-Core-2 Input Language Format", "comments": null, "journal-ref": "Theory and Practice of Logic Programming 20 (2020) 294-309", "doi": "10.1017/S1471068419000450", "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Standardization of solver input languages has been a main driver for the\ngrowth of several areas within knowledge representation and reasoning,\nfostering the exploitation in actual applications. In this document we present\nthe ASP-Core-2 standard input language for Answer Set Programming, which has\nbeen adopted in ASP Competition events since 2013.\n", "versions": [{"version": "v1", "created": "Mon, 11 Nov 2019 15:14:00 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Calimeri", "Francesco", ""], ["Faber", "Wolfgang", ""], ["Gebser", "Martin", ""], ["Ianni", "Giovambattista", ""], ["Kaminski", "Roland", ""], ["Krennwallner", "Thomas", ""], ["Leone", "Nicola", ""], ["Maratea", "Marco", ""], ["Ricca", "Francesco", ""], ["Schaub", "Torsten", ""]]}, {"id": "1911.04400", "submitter": "Pietro Ferraro", "authors": "Meghana Rathi, Pietro Ferraro, Giovanni Russo", "title": "Driving Reinforcement Learning with Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we propose a new approach to complement reinforcement learning\n(RL) with model-based control (in particular, Model Predictive Control - MPC).\nWe introduce an algorithm, the MPC augmented RL (MPRL) that combines RL and MPC\nin a novel way so that they can augment each other's strengths. We demonstrate\nthe effectiveness of the MPRL by letting it play against the Atari game Pong.\nFor this task, the results highlight how MPRL is able to outperform both RL and\nMPC when these are used individually.\n", "versions": [{"version": "v1", "created": "Mon, 11 Nov 2019 17:14:56 GMT"}, {"version": "v2", "created": "Wed, 26 Feb 2020 15:25:52 GMT"}], "update_date": "2020-02-27", "authors_parsed": [["Rathi", "Meghana", ""], ["Ferraro", "Pietro", ""], ["Russo", "Giovanni", ""]]}, {"id": "1911.04464", "submitter": "Siddharth Bhatia", "authors": "Siddharth Bhatia, Bryan Hooi, Minji Yoon, Kijung Shin, Christos\n  Faloutsos", "title": "MIDAS: Microcluster-Based Detector of Anomalies in Edge Streams", "comments": "8 pages, Accepted at AAAI Conference on Artificial Intelligence\n  (AAAI), 2020 [oral paper]; minor fixes, updated experiments", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a stream of graph edges from a dynamic graph, how can we assign anomaly\nscores to edges in an online manner, for the purpose of detecting unusual\nbehavior, using constant time and memory? Existing approaches aim to detect\nindividually surprising edges. In this work, we propose MIDAS, which focuses on\ndetecting microcluster anomalies, or suddenly arriving groups of suspiciously\nsimilar edges, such as lockstep behavior, including denial of service attacks\nin network traffic data. MIDAS has the following properties: (a) it detects\nmicrocluster anomalies while providing theoretical guarantees about its false\npositive probability; (b) it is online, thus processing each edge in constant\ntime and constant memory, and also processes the data 162-644 times faster than\nstate-of-the-art approaches; (c) it provides 42%-48% higher accuracy (in terms\nof AUC) than state-of-the-art approaches.\n", "versions": [{"version": "v1", "created": "Mon, 11 Nov 2019 18:59:24 GMT"}, {"version": "v2", "created": "Wed, 13 Nov 2019 13:54:08 GMT"}, {"version": "v3", "created": "Thu, 6 Feb 2020 13:45:27 GMT"}, {"version": "v4", "created": "Tue, 21 Apr 2020 09:37:23 GMT"}, {"version": "v5", "created": "Sun, 23 Aug 2020 15:32:57 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Bhatia", "Siddharth", ""], ["Hooi", "Bryan", ""], ["Yoon", "Minji", ""], ["Shin", "Kijung", ""], ["Faloutsos", "Christos", ""]]}, {"id": "1911.04577", "submitter": "Caelan Garrett", "authors": "Caelan Reed Garrett, Chris Paxton, Tom\\'as Lozano-P\\'erez, Leslie Pack\n  Kaelbling, Dieter Fox", "title": "Online Replanning in Belief Space for Partially Observable Task and\n  Motion Problems", "comments": "IEEE International Conference on Robotics and Automation (ICRA), 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To solve multi-step manipulation tasks in the real world, an autonomous robot\nmust take actions to observe its environment and react to unexpected\nobservations. This may require opening a drawer to observe its contents or\nmoving an object out of the way to examine the space behind it. Upon receiving\na new observation, the robot must update its belief about the world and compute\na new plan of action. In this work, we present an online planning and execution\nsystem for robots faced with these challenges. We perform deterministic\ncost-sensitive planning in the space of hybrid belief states to select\nlikely-to-succeed observation actions and continuous control actions. After\nexecution and observation, we replan using our new state estimate. We initially\nenforce that planner reuses the structure of the unexecuted tail of the last\nplan. This both improves planning efficiency and ensures that the overall\npolicy does not undo its progress towards achieving the goal. Our approach is\nable to efficiently solve partially observable problems both in simulation and\nin a real-world kitchen.\n", "versions": [{"version": "v1", "created": "Mon, 11 Nov 2019 21:44:24 GMT"}, {"version": "v2", "created": "Mon, 23 Mar 2020 14:54:32 GMT"}], "update_date": "2020-03-24", "authors_parsed": [["Garrett", "Caelan Reed", ""], ["Paxton", "Chris", ""], ["Lozano-P\u00e9rez", "Tom\u00e1s", ""], ["Kaelbling", "Leslie Pack", ""], ["Fox", "Dieter", ""]]}, {"id": "1911.04606", "submitter": "Dongrui Wu", "authors": "Lubin Meng and Chin-Teng Lin and Tzyy-Ring Jung and Dongrui Wu", "title": "White-Box Target Attack for EEG-Based BCI Regression Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning has achieved great success in many applications, including\nelectroencephalogram (EEG) based brain-computer interfaces (BCIs).\nUnfortunately, many machine learning models are vulnerable to adversarial\nexamples, which are crafted by adding deliberately designed perturbations to\nthe original inputs. Many adversarial attack approaches for classification\nproblems have been proposed, but few have considered target adversarial attacks\nfor regression problems. This paper proposes two such approaches. More\nspecifically, we consider white-box target attacks for regression problems,\nwhere we know all information about the regression model to be attacked, and\nwant to design small perturbations to change the regression output by a\npre-determined amount. Experiments on two BCI regression problems verified that\nboth approaches are effective. Moreover, adversarial examples generated from\nboth approaches are also transferable, which means that we can use adversarial\nexamples generated from one known regression model to attack an unknown\nregression model, i.e., to perform black-box attacks. To our knowledge, this is\nthe first study on adversarial attacks for EEG-based BCI regression problems,\nwhich calls for more attention on the security of BCI systems.\n", "versions": [{"version": "v1", "created": "Thu, 7 Nov 2019 14:52:12 GMT"}], "update_date": "2019-11-13", "authors_parsed": [["Meng", "Lubin", ""], ["Lin", "Chin-Teng", ""], ["Jung", "Tzyy-Ring", ""], ["Wu", "Dongrui", ""]]}, {"id": "1911.04646", "submitter": "Li Ning Dr.", "authors": "Li Ning, Yong Zhang", "title": "LAC-Nav: Collision-Free Mutiagent Navigation Based on The Local Action\n  Cells", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Collision avoidance is one of the most primary requirement in the\ndecentralized multiagent navigations: while the agents are moving towards their\nown targets, attentions should be paid to avoid the collisions with the others.\nIn this paper, we introduce the concept of local action cell, which provides\nfor each agent a set of velocities that are safe to perform. Based on the\nrealtime updated local action cells, we propose the LAC-Nav approach to\nnavigate the agent with the properly selected velocity; and furthermore, we\ncoupled the local action cell with an adaptive learning framework, in which the\neffect of selections are evaluated and used as the references for making\ndecisions in the following updates. Through the experiments for three commonly\nconsidered scenarios, we demonstrated the efficiency of the proposed\napproaches, with the comparison to several widely studied strategies.\n", "versions": [{"version": "v1", "created": "Tue, 12 Nov 2019 03:07:36 GMT"}], "update_date": "2019-11-13", "authors_parsed": [["Ning", "Li", ""], ["Zhang", "Yong", ""]]}, {"id": "1911.04676", "submitter": "Indraneel Patil", "authors": "Indraneel Patil, B.K. Rout, V. Kalaichelvi", "title": "Prediction of Bottleneck Points for Manipulation Planning in Cluttered\n  Environment using a 3D Convolutional Neural Network", "comments": "7 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.DS cs.LG cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Latest research in industrial robotics is aimed at making human robot\ncollaboration possible seamlessly. For this purpose, industrial robots are\nexpected to work on the fly in unstructured and cluttered environments and\nhence the subject of perception driven motion planning plays a vital role.\nSampling based motion planners are proven to be the most effective for such\nhigh dimensional planning problems with real time constraints. Unluckily random\nstochastic samplers suffer from the phenomenon of 'narrow passages' or\nbottleneck regions which need targeted sampling to improve their convergence\nrate. Also identifying these bottleneck regions in a diverse set of planning\nproblems is a challenge. In this paper an attempt has been made to address\nthese two problems by designing an intelligent 'bottleneck guided' heuristic\nfor a Rapidly Exploring Random Tree Star (RRT*) planner which is based on\nrelevant context extracted from the planning scenario using a 3D Convolutional\nNeural Network and it is also proven that the proposed technique generalises to\nunseen problem instances. This paper benchmarks the technique (bottleneck\nguided RRT*) against a 10% Goal biased RRT star planner, shows significant\nimprovement in planning time and memory requirement and uses ABB 1410\nindustrial manipulator as a platform for implantation and validation of the\nresults.\n", "versions": [{"version": "v1", "created": "Tue, 12 Nov 2019 05:16:40 GMT"}], "update_date": "2019-11-13", "authors_parsed": [["Patil", "Indraneel", ""], ["Rout", "B. K.", ""], ["Kalaichelvi", "V.", ""]]}, {"id": "1911.04679", "submitter": "Toki Migimatsu", "authors": "Toki Migimatsu and Jeannette Bohg", "title": "Object-Centric Task and Motion Planning in Dynamic Environments", "comments": null, "journal-ref": "IEEE Robotics and Automation Letters (2020) vol. 5, issue 2, pp.\n  844-851", "doi": "10.1109/LRA.2020.2965875", "report-no": null, "categories": "cs.RO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the problem of applying Task and Motion Planning (TAMP) in real\nworld environments. TAMP combines symbolic and geometric reasoning to produce\nsequential manipulation plans, typically specified as joint-space trajectories,\nwhich are valid only as long as the environment is static and perception and\ncontrol are highly accurate. In case of any changes in the environment, slow\nre-planning is required. We propose a TAMP algorithm that optimizes over\nCartesian frames defined relative to target objects. The resulting plan then\nremains valid even if the objects are moving and can be executed by reactive\ncontrollers that adapt to these changes in real time. We apply our TAMP\nframework to a torque-controlled robot in a pick and place setting and\ndemonstrate its ability to adapt to changing environments, inaccurate\nperception, and imprecise control, both in simulation and the real world.\n", "versions": [{"version": "v1", "created": "Tue, 12 Nov 2019 05:28:03 GMT"}, {"version": "v2", "created": "Mon, 3 Feb 2020 02:47:03 GMT"}, {"version": "v3", "created": "Tue, 5 May 2020 17:47:12 GMT"}], "update_date": "2020-05-06", "authors_parsed": [["Migimatsu", "Toki", ""], ["Bohg", "Jeannette", ""]]}, {"id": "1911.04700", "submitter": "Yinhe Zheng Dr.", "authors": "Yinhe Zheng, Rongsheng Zhang, Xiaoxi Mao, Minlie Huang", "title": "A Pre-training Based Personalized Dialogue Generation Model with\n  Persona-sparse Data", "comments": "Long paper accepted at AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Endowing dialogue systems with personas is essential to deliver more\nhuman-like conversations. However, this problem is still far from well explored\ndue to the difficulties of both embodying personalities in natural languages\nand the persona sparsity issue observed in most dialogue corpora. This paper\nproposes a pre-training based personalized dialogue model that can generate\ncoherent responses using persona-sparse dialogue data. In this method, a\npre-trained language model is used to initialize an encoder and decoder, and\npersonal attribute embeddings are devised to model richer dialogue contexts by\nencoding speakers' personas together with dialogue histories. Further, to\nincorporate the target persona in the decoding process and to balance its\ncontribution, an attention routing structure is devised in the decoder to merge\nfeatures extracted from the target persona and dialogue contexts using\ndynamically predicted weights. Our model can utilize persona-sparse dialogues\nin a unified manner during the training process, and can also control the\namount of persona-related features to exhibit during the inference process.\nBoth automatic and manual evaluation demonstrates that the proposed model\noutperforms state-of-the-art methods for generating more coherent and persona\nconsistent responses with persona-sparse data.\n", "versions": [{"version": "v1", "created": "Tue, 12 Nov 2019 07:13:42 GMT"}], "update_date": "2019-11-13", "authors_parsed": [["Zheng", "Yinhe", ""], ["Zhang", "Rongsheng", ""], ["Mao", "Xiaoxi", ""], ["Huang", "Minlie", ""]]}, {"id": "1911.04710", "submitter": "Wishnu Prasetya", "authors": "I. S. W. B. Prasetya", "title": "Aplib: Tactical Programming of Intelligent Agents", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.PL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  This paper presents aplib, a Java library for programming intelligent agents,\nfeaturing BDI and multi agency, but adding on top of it a novel layer of\ntactical programming inspired by the domain of theorem proving. Aplib is also\nimplemented in such a way to provide the fluency of a Domain Specific Language\n(DSL). Compared to dedicated BDI agent programming languages such as JASON,\n2APL, or GOAL,aplib's embedded DSL approach does mean that \\aplib\\ programmers\nwill still be limited by Java syntax, but on other hand they get all the\nadvantages that Java programmers get: rich language features (object\norientation, static type checking, $\\lambda$-expression, libraries, etc), a\nwhole array of development tools, integration with other technologies, large\ncommunity, etc.\n", "versions": [{"version": "v1", "created": "Tue, 12 Nov 2019 07:39:07 GMT"}], "update_date": "2019-11-13", "authors_parsed": [["Prasetya", "I. S. W. B.", ""]]}, {"id": "1911.04743", "submitter": "Yukiko Yamauchi", "authors": "Shotaro Yoshimura and Yukiko Yamauchi", "title": "Network Creation Games with Local Information and Edge Swaps", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.DC cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the swap game (SG) selfish players, each of which is associated to a\nvertex, form a graph by edge swaps, i.e., a player changes its strategy by\nsimultaneously removing an adjacent edge and forming a new edge (Alon et al.,\n2013). The cost of a player considers the average distance to all other players\nor the maximum distance to other players. Any SG by $n$ players starting from a\ntree converges to an equilibrium with a constant Price of Anarchy (PoA) within\n$O(n^3)$ edge swaps (Lenzner, 2011). We focus on SGs where each player knows\nthe subgraph induced by players within distance $k$. Therefore, each player\ncannot compute its cost nor a best response. We first consider pessimistic\nplayers who consider the worst-case global graph. We show that any SG starting\nfrom a tree (i) always converges to an equilibrium within $O(n^3)$ edge swaps\nirrespective of the value of $k$, (ii) the PoA is $\\Theta(n)$ for $k=1,2,3$,\nand (iii) the PoA is constant for $k \\geq 4$. We then introduce weakly\npessimistic players and optimistic players and show that these less pessimistic\nplayers achieve constant PoA for $k \\leq 3$ at the cost of best response\ncycles.\n", "versions": [{"version": "v1", "created": "Tue, 12 Nov 2019 09:05:49 GMT"}], "update_date": "2019-11-13", "authors_parsed": [["Yoshimura", "Shotaro", ""], ["Yamauchi", "Yukiko", ""]]}, {"id": "1911.04759", "submitter": "Mehdi Mirzapour", "authors": "K\\'evin Cousot (TEXTE), Mehdi Mirzapour (TEXTE), Waleed Ragheb\n  (ADVANSE)", "title": "Prediction of Missing Semantic Relations in Lexical-Semantic Network\n  using Random Forest Classifier", "comments": null, "journal-ref": "CJC PRAXILING 2019, Nov 2019, Montpellier, France", "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This study focuses on the prediction of missing six semantic relations (such\nas is_a and has_part) between two given nodes in RezoJDM a French\nlexical-semantic network. The output of this prediction is a set of pairs in\nwhich the first entries are semantic relations and the second entries are the\nprobabilities of existence of such relations. Due to the statement of the\nproblem we choose the random forest (RF) predictor classifier approach to\ntackle this problem. We take for granted the existing semantic relations, for\ntraining/test dataset, gathered and validated by crowdsourcing. We describe how\nall of the mentioned ideas can be followed after using the node2vec approach in\nthe feature extraction phase. We show how this approach can lead to acceptable\nresults.\n", "versions": [{"version": "v1", "created": "Tue, 12 Nov 2019 09:41:44 GMT"}], "update_date": "2019-11-13", "authors_parsed": [["Cousot", "K\u00e9vin", "", "TEXTE"], ["Mirzapour", "Mehdi", "", "TEXTE"], ["Ragheb", "Waleed", "", "ADVANSE"]]}, {"id": "1911.04766", "submitter": "Tobias Geibinger", "authors": "Tobias Geibinger, Florian Mischek and Nysret Musliu", "title": "Investigating Constraint Programming and Hybrid Methods for Real World\n  Industrial Test Laboratory Scheduling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we deal with a complex real world scheduling problem closely\nrelated to the well-known Resource-Constrained Project Scheduling Problem\n(RCPSP). The problem concerns industrial test laboratories in which a large\nnumber of tests has to be performed by qualified personnel using specialised\nequipment, while respecting deadlines and other constraints. We present\ndifferent constraint programming models and search strategies for this problem.\nFurthermore, we propose a Very Large Neighborhood Search approach based on our\nCP methods. Our models are evaluated using CP solvers and a MIP solver both on\nreal-world test laboratory data and on a set of generated instances of\ndifferent sizes based on the real-world data. Further, we compare the exact\napproaches with VLNS and a Simulated Annealing heuristic. We could find\nfeasible solutions for all instances and several optimal solutions and we show\nthat using VLNS we can improve upon the results of the other approaches.\n", "versions": [{"version": "v1", "created": "Tue, 12 Nov 2019 10:03:16 GMT"}], "update_date": "2019-11-13", "authors_parsed": [["Geibinger", "Tobias", ""], ["Mischek", "Florian", ""], ["Musliu", "Nysret", ""]]}, {"id": "1911.04801", "submitter": "Ruoyun Chen", "authors": "Ruoyun Chen, Hancheng Lu, Yujiao Lu, Jinxue Liu", "title": "MSDF: A Deep Reinforcement Learning Framework for Service Function Chain\n  Migration", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Under dynamic traffic, service function chain (SFC) migration is considered\nas an effective way to improve resource utilization. However, the lack of\nfuture network information leads to non-optimal solutions, which motivates us\nto study reinforcement learning based SFC migration from a long-term\nperspective. In this paper, we formulate the SFC migration problem as a\nminimization problem with the objective of total network operation cost under\nconstraints of users' quality of service. We firstly design a deep Q-network\nbased algorithm to solve single SFC migration problem, which can adjust\nmigration strategy online without knowing future information. Further, a novel\nmulti-agent cooperative framework, called MSDF, is proposed to address the\nchallenge of considering multiple SFC migration on the basis of single SFC\nmigration. MSDF reduces the complexity thus accelerates the convergence speed,\nespecially in large scale networks. Experimental results demonstrate that MSDF\noutperforms typical heuristic algorithms under various scenarios.\n", "versions": [{"version": "v1", "created": "Tue, 12 Nov 2019 11:41:38 GMT"}, {"version": "v2", "created": "Wed, 13 Nov 2019 03:04:38 GMT"}], "update_date": "2019-11-14", "authors_parsed": [["Chen", "Ruoyun", ""], ["Lu", "Hancheng", ""], ["Lu", "Yujiao", ""], ["Liu", "Jinxue", ""]]}, {"id": "1911.04863", "submitter": "Daniela Briola", "authors": "Daniela Briola, Viviana Mascardi, Massimiliano Gioseffi", "title": "OntoScene, A Logic-based Scene Interpreter: Implementation and\n  Application in the Rock Art Domain", "comments": "Under consideration in Theory and Practice of Logic Programming\n  (TPLP)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CV cs.LO cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present OntoScene, a framework aimed at understanding the semantics of\nvisual scenes starting from the semantics of their elements and the spatial\nrelations holding between them. OntoScene exploits ontologies for representing\nknowledge and Prolog for specifying the interpretation rules that domain\nexperts may adopt, and for implementing the SceneInterpreter engine. Ontologies\nallow the designer to formalize the domain in a reusable way, and make the\nsystem modular and interoperable with existing multiagent systems, while Prolog\nprovides a solid basis to define complex rules of interpretation in a way that\ncan be affordable even for people with no background in Computational Logics.\nThe domain selected for experimenting OntoScene is that of prehistoric rock\nart, which provides us with a fascinating and challenging testbed. Under\nconsideration in Theory and Practice of Logic Programming (TPLP)\n", "versions": [{"version": "v1", "created": "Tue, 5 Nov 2019 13:22:05 GMT"}], "update_date": "2019-11-13", "authors_parsed": [["Briola", "Daniela", ""], ["Mascardi", "Viviana", ""], ["Gioseffi", "Massimiliano", ""]]}, {"id": "1911.04868", "submitter": "Changmao Li", "authors": "Changmao Li", "title": "Challenging On Car Racing Problem from OpenAI gym", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This project challenges the car racing problem from OpenAI gym environment.\nThe problem is very challenging since it requires computer to finish the\ncontinuous control task by learning from pixels. To tackle this challenging\nproblem, we explored two approaches including evolutionary algorithm based\ngenetic multi-layer perceptron and double deep Q-learning network. The result\nshows that the genetic multi-layer perceptron can converge fast but when\ntraining many episodes, double deep Q-learning can get better score. We analyze\nthe result and draw a conclusion that for limited hardware resources, using\ngenetic multi-layer perceptron sometimes can be more efficient.\n", "versions": [{"version": "v1", "created": "Sat, 2 Nov 2019 20:14:55 GMT"}], "update_date": "2019-11-13", "authors_parsed": [["Li", "Changmao", ""]]}, {"id": "1911.04869", "submitter": "EPTCS", "authors": "Severin Kacianka (TU Munich), Amjad Ibrahim (TU Munich), Alexander\n  Pretschner (TU Munich), Alexander Trende (Offis), Andreas L\\\"udtke (Offis)", "title": "Extending Causal Models from Machines into Humans", "comments": "In Proceedings CREST 2019, arXiv:1910.13641", "journal-ref": "EPTCS 308, 2019, pp. 17-31", "doi": "10.4204/EPTCS.308.2", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Causal Models are increasingly suggested as a means to reason about the\nbehavior of cyber-physical systems in socio-technical contexts. They allow us\nto analyze courses of events and reason about possible alternatives. Until now,\nhowever, such reasoning is confined to the technical domain and limited to\nsingle systems or at most groups of systems. The humans that are an integral\npart of any such socio-technical system are usually ignored or dealt with by\n\"expert judgment\". We show how a technical causal model can be extended with\nmodels of human behavior to cover the complexity and interplay between humans\nand technical systems. This integrated socio-technical causal model can then be\nused to reason not only about actions and decisions taken by the machine, but\nalso about those taken by humans interacting with the system. In this paper we\ndemonstrate the feasibility of merging causal models about machines with causal\nmodels about humans and illustrate the usefulness of this approach with a\nhighly automated vehicle example.\n", "versions": [{"version": "v1", "created": "Thu, 31 Oct 2019 02:30:07 GMT"}], "update_date": "2019-11-13", "authors_parsed": [["Kacianka", "Severin", "", "TU Munich"], ["Ibrahim", "Amjad", "", "TU Munich"], ["Pretschner", "Alexander", "", "TU Munich"], ["Trende", "Alexander", "", "Offis"], ["L\u00fcdtke", "Andreas", "", "Offis"]]}, {"id": "1911.04870", "submitter": "Elsa Rizk", "authors": "Elsa Rizk, Roula Nassif, Ali H. Sayed", "title": "Network Classifiers With Output Smoothing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work introduces two strategies for training network classifiers with\nheterogeneous agents. One strategy promotes global smoothing over the graph and\na second strategy promotes local smoothing over neighbourhoods. It is assumed\nthat the feature sizes can vary from one agent to another, with some agents\nobserving insufficient attributes to be able to make reliable decisions on\ntheir own. As a result, cooperation with neighbours is necessary. However, due\nto the fact that the feature dimensions are different across the agents, their\nclassifier dimensions will also be different. This means that cooperation\ncannot rely on combining the classifier parameters. We instead propose\nsmoothing the outputs of the classifiers, which are the predicted labels. By\ndoing so, the dynamics that describes the evolution of the network classifier\nbecomes more challenging than usual because the classifier parameters end up\nappearing as part of the regularization term as well. We illustrate performance\nby means of computer simulations.\n", "versions": [{"version": "v1", "created": "Wed, 30 Oct 2019 14:28:16 GMT"}], "update_date": "2019-11-13", "authors_parsed": [["Rizk", "Elsa", ""], ["Nassif", "Roula", ""], ["Sayed", "Ali H.", ""]]}, {"id": "1911.04871", "submitter": "Bernhard Nebel", "authors": "Bernhard Nebel", "title": "On the Computational Complexity of Multi-Agent Pathfinding on Directed\n  Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The determination of the computational complexity of multi-agent pathfinding\non directed graphs has been an open problem for many years. For undirected\ngraphs, solvability can be decided in polynomial time, as has been shown\nalready in the eighties. Further, recently it has been shown that a special\ncase on directed graphs is solvable in polynomial time. In this paper, we show\nthat the problem is NP-hard in the general case. In addition, some upper bounds\nare proven.\n", "versions": [{"version": "v1", "created": "Mon, 11 Nov 2019 10:55:19 GMT"}], "update_date": "2019-11-13", "authors_parsed": [["Nebel", "Bernhard", ""]]}, {"id": "1911.04873", "submitter": "Bartosz Piotrowski", "authors": "Bartosz Piotrowski, Josef Urban, Chad E. Brown, Cezary Kaliszyk", "title": "Can Neural Networks Learn Symbolic Rewriting?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work investigates if the current neural architectures are adequate for\nlearning symbolic rewriting. Two kinds of data sets are proposed for this\nresearch -- one based on automated proofs and the other being a synthetic set\nof polynomial terms. The experiments with use of the current neural machine\ntranslation models are performed and its results are discussed. Ideas for\nextending this line of research are proposed, and its relevance is motivated.\n", "versions": [{"version": "v1", "created": "Thu, 7 Nov 2019 11:22:44 GMT"}, {"version": "v2", "created": "Tue, 26 May 2020 23:43:51 GMT"}], "update_date": "2020-05-28", "authors_parsed": [["Piotrowski", "Bartosz", ""], ["Urban", "Josef", ""], ["Brown", "Chad E.", ""], ["Kaliszyk", "Cezary", ""]]}, {"id": "1911.04888", "submitter": "Vitaliy Tsyganok", "authors": "Sergii Kadenko and Vitaliy Tsyganok", "title": "Comparing Efficiency of Expert Data Aggregation Methods", "comments": "16 pages, 6 figures, 5 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Expert estimation of objects takes place when there are no benchmark values\nof object weights, but these weights still have to be defined. That is why it\nis problematic to define the efficiency of expert estimation methods. We\npropose to define efficiency of such methods based on stability of their\nresults under perturbations of input data. We compare two modifications of\ncombinatorial method of expert data aggregation (spanning tree enumeration).\nUsing the example of these two methods, we illustrate two approaches to\nefficiency evaluation. The first approach is based on usage of real data,\nobtained through estimation of a set of model objects by a group of experts.\nThe second approach is based on simulation of the whole expert examination\ncycle (including expert estimates). During evaluation of efficiency of the two\nlisted modifications of combinatorial expert data aggregation method the\nsimulation-based approach proved more robust and credible. Our experimental\nstudy confirms that if weights of spanning trees are taken into consideration,\nthe results of combinatorial data aggregation method become more stable. So,\nweighted spanning tree enumeration method has an advantage over non-weighted\nmethod (and, consequently, over logarithmic least squares and row geometric\nmean methods).\n", "versions": [{"version": "v1", "created": "Sat, 9 Nov 2019 10:26:26 GMT"}], "update_date": "2019-11-13", "authors_parsed": [["Kadenko", "Sergii", ""], ["Tsyganok", "Vitaliy", ""]]}, {"id": "1911.04910", "submitter": "Guangtao Wang", "authors": "Yun Tang, Jing Huang, Guangtao Wang, Xiaodong He, Bowen Zhou", "title": "Orthogonal Relation Transforms with Graph Context Modeling for Knowledge\n  Graph Embedding", "comments": "Accepted by ACL 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Translational distance-based knowledge graph embedding has shown progressive\nimprovements on the link prediction task, from TransE to the latest\nstate-of-the-art RotatE. However, N-1, 1-N and N-N predictions still remain\nchallenging. In this work, we propose a novel translational distance-based\napproach for knowledge graph link prediction. The proposed method includes\ntwo-folds, first we extend the RotatE from 2D complex domain to high dimension\nspace with orthogonal transforms to model relations for better modeling\ncapacity. Second, the graph context is explicitly modeled via two directed\ncontext representations. These context representations are used as part of the\ndistance scoring function to measure the plausibility of the triples during\ntraining and inference. The proposed approach effectively improves prediction\naccuracy on the difficult N-1, 1-N and N-N cases for knowledge graph link\nprediction task. The experimental results show that it achieves better\nperformance on two benchmark data sets compared to the baseline RotatE,\nespecially on data set (FB15k-237) with many high in-degree connection nodes.\n", "versions": [{"version": "v1", "created": "Sat, 9 Nov 2019 07:02:33 GMT"}, {"version": "v2", "created": "Thu, 9 Apr 2020 20:32:11 GMT"}, {"version": "v3", "created": "Wed, 15 Apr 2020 20:13:30 GMT"}], "update_date": "2020-04-17", "authors_parsed": [["Tang", "Yun", ""], ["Huang", "Jing", ""], ["Wang", "Guangtao", ""], ["He", "Xiaodong", ""], ["Zhou", "Bowen", ""]]}, {"id": "1911.04922", "submitter": "Shuai Wang", "authors": "Shuai Wang, Yik-Chung Wu, Minghua Xia, Rui Wang, and H. Vincent Poor", "title": "Machine Intelligence at the Edge with Learning Centric Power Allocation", "comments": "14 figures, 15 pages, to appear in IEEE Transactions on Wireless\n  Communications", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.AI cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While machine-type communication (MTC) devices generate considerable amounts\nof data, they often cannot process the data due to limited energy and\ncomputational power. To empower MTC with intelligence, edge machine learning\nhas been proposed. However, power allocation in this paradigm requires\nmaximizing the learning performance instead of the communication throughput,\nfor which the celebrated water-filling and max-min fairness algorithms become\ninefficient. To this end, this paper proposes learning centric power allocation\n(LCPA), which provides a new perspective on radio resource allocation in\nlearning driven scenarios. By employing 1) an empirical classification error\nmodel that is supported by learning theory and 2) an uncertainty sampling\nmethod that accounts for different distributions at users, LCPA is formulated\nas a nonconvex nonsmooth optimization problem, and is solved using a\nmajorization minimization (MM) framework. To get deeper insights into LCPA,\nasymptotic analysis shows that the transmit powers are inversely proportional\nto the channel gains, and scale exponentially with the learning parameters.\nThis is in contrast to traditional power allocations where quality of wireless\nchannels is the only consideration. Last but not least, a large-scale\noptimization algorithm termed mirror-prox LCPA is further proposed to enable\nLCPA in large-scale settings. Extensive numerical results demonstrate that the\nproposed LCPA algorithms outperform traditional power allocation algorithms,\nand the large-scale optimization algorithm reduces the computation time by\norders of magnitude compared with MM-based LCPA but still achieves competing\nlearning performance.\n", "versions": [{"version": "v1", "created": "Tue, 12 Nov 2019 15:10:34 GMT"}, {"version": "v2", "created": "Fri, 17 Jul 2020 03:00:39 GMT"}], "update_date": "2020-07-20", "authors_parsed": [["Wang", "Shuai", ""], ["Wu", "Yik-Chung", ""], ["Xia", "Minghua", ""], ["Wang", "Rui", ""], ["Poor", "H. Vincent", ""]]}, {"id": "1911.04929", "submitter": "Boris Ruf", "authors": "Vincent Grari, Boris Ruf, Sylvain Lamprier, Marcin Detyniecki", "title": "Fairness-Aware Neural R\\'eyni Minimization for Continuous Features", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The past few years have seen a dramatic rise of academic and societal\ninterest in fair machine learning. While plenty of fair algorithms have been\nproposed recently to tackle this challenge for discrete variables, only a few\nideas exist for continuous ones. The objective in this paper is to ensure some\nindependence level between the outputs of regression models and any given\ncontinuous sensitive variables. For this purpose, we use the\nHirschfeld-Gebelein-R\\'enyi (HGR) maximal correlation coefficient as a fairness\nmetric. We propose two approaches to minimize the HGR coefficient. First, by\nreducing an upper bound of the HGR with a neural network estimation of the\n$\\chi^{2}$ divergence. Second, by minimizing the HGR directly with an\nadversarial neural network architecture. The idea is to predict the output Y\nwhile minimizing the ability of an adversarial neural network to find the\nestimated transformations which are required to predict the HGR coefficient. We\nempirically assess and compare our approaches and demonstrate significant\nimprovements on previously presented work in the field.\n", "versions": [{"version": "v1", "created": "Tue, 12 Nov 2019 15:20:29 GMT"}], "update_date": "2019-11-13", "authors_parsed": [["Grari", "Vincent", ""], ["Ruf", "Boris", ""], ["Lamprier", "Sylvain", ""], ["Detyniecki", "Marcin", ""]]}, {"id": "1911.04942", "submitter": "Bailin Wang", "authors": "Bailin Wang, Richard Shin, Xiaodong Liu, Oleksandr Polozov, Matthew\n  Richardson", "title": "RAT-SQL: Relation-Aware Schema Encoding and Linking for Text-to-SQL\n  Parsers", "comments": "Fix some errors of ACL 2020 camera-ready; 12 pages, 5 figures, 7\n  tables. arXiv admin note: text overlap with arXiv:1906.11790", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When translating natural language questions into SQL queries to answer\nquestions from a database, contemporary semantic parsing models struggle to\ngeneralize to unseen database schemas. The generalization challenge lies in (a)\nencoding the database relations in an accessible way for the semantic parser,\nand (b) modeling alignment between database columns and their mentions in a\ngiven query. We present a unified framework, based on the relation-aware\nself-attention mechanism, to address schema encoding, schema linking, and\nfeature representation within a text-to-SQL encoder. On the challenging Spider\ndataset this framework boosts the exact match accuracy to 57.2%, surpassing its\nbest counterparts by 8.7% absolute improvement. Further augmented with BERT, it\nachieves the new state-of-the-art performance of 65.6% on the Spider\nleaderboard. In addition, we observe qualitative improvements in the model's\nunderstanding of schema linking and alignment. Our implementation will be\nopen-sourced at https://github.com/Microsoft/rat-sql.\n", "versions": [{"version": "v1", "created": "Sun, 10 Nov 2019 09:09:13 GMT"}, {"version": "v2", "created": "Tue, 5 May 2020 02:08:16 GMT"}, {"version": "v3", "created": "Sat, 20 Jun 2020 07:11:06 GMT"}, {"version": "v4", "created": "Sun, 5 Jul 2020 10:03:54 GMT"}], "update_date": "2020-07-07", "authors_parsed": [["Wang", "Bailin", ""], ["Shin", "Richard", ""], ["Liu", "Xiaodong", ""], ["Polozov", "Oleksandr", ""], ["Richardson", "Matthew", ""]]}, {"id": "1911.04964", "submitter": "George Monta\\~nez", "authors": "Julius Lauw, Dominique Macias, Akshay Trikha, Julia Vendemiatti,\n  George D. Montanez", "title": "The Bias-Expressivity Trade-off", "comments": "arXiv admin note: text overlap with arXiv:1907.06010", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning algorithms need bias to generalize and perform better than random\nguessing. We examine the flexibility (expressivity) of biased algorithms. An\nexpressive algorithm can adapt to changing training data, altering its outcome\nbased on changes in its input. We measure expressivity by using an\ninformation-theoretic notion of entropy on algorithm outcome distributions,\ndemonstrating a trade-off between bias and expressivity. To the degree an\nalgorithm is biased is the degree to which it can outperform uniform random\nsampling, but is also the degree to which is becomes inflexible. We derive\nbounds relating bias to expressivity, proving the necessary trade-offs inherent\nin trying to create strongly performing yet flexible algorithms.\n", "versions": [{"version": "v1", "created": "Sat, 9 Nov 2019 19:51:02 GMT"}], "update_date": "2019-11-13", "authors_parsed": [["Lauw", "Julius", ""], ["Macias", "Dominique", ""], ["Trikha", "Akshay", ""], ["Vendemiatti", "Julia", ""], ["Montanez", "George D.", ""]]}, {"id": "1911.04974", "submitter": "Benjamin Lengerich", "authors": "Benjamin Lengerich, Sarah Tan, Chun-Hao Chang, Giles Hooker, Rich\n  Caruana", "title": "Purifying Interaction Effects with the Functional ANOVA: An Efficient\n  Algorithm for Recovering Identifiable Additive Models", "comments": "AISTATS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Models which estimate main effects of individual variables alongside\ninteraction effects have an identifiability challenge: effects can be freely\nmoved between main effects and interaction effects without changing the model\nprediction. This is a critical problem for interpretability because it permits\n\"contradictory\" models to represent the same function. To solve this problem,\nwe propose pure interaction effects: variance in the outcome which cannot be\nrepresented by any smaller subset of features. This definition has an\nequivalence with the Functional ANOVA decomposition. To compute this\ndecomposition, we present a fast, exact algorithm that transforms any\npiecewise-constant function (such as a tree-based model) into a purified,\ncanonical representation. We apply this algorithm to Generalized Additive\nModels with interactions trained on several datasets and show large disparity,\nincluding contradictions, between the effects before and after purification.\nThese results underscore the need to specify data distributions and ensure\nidentifiability before interpreting model parameters.\n", "versions": [{"version": "v1", "created": "Tue, 12 Nov 2019 16:06:21 GMT"}, {"version": "v2", "created": "Sun, 19 Apr 2020 20:20:28 GMT"}, {"version": "v3", "created": "Fri, 1 May 2020 21:45:40 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Lengerich", "Benjamin", ""], ["Tan", "Sarah", ""], ["Chang", "Chun-Hao", ""], ["Hooker", "Giles", ""], ["Caruana", "Rich", ""]]}, {"id": "1911.05010", "submitter": "Tianyu Li", "authors": "Tianyu Li and Bogdan Mazoure and Doina Precup and Guillaume Rabusseau", "title": "Efficient Planning under Partial Observability with Unnormalized Q\n  Functions and Spectral Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning and planning in partially-observable domains is one of the most\ndifficult problems in reinforcement learning. Traditional methods consider\nthese two problems as independent, resulting in a classical two-stage paradigm:\nfirst learn the environment dynamics and then plan accordingly. This approach,\nhowever, disconnects the two problems and can consequently lead to algorithms\nthat are sample inefficient and time consuming. In this paper, we propose a\nnovel algorithm that combines learning and planning together. Our algorithm is\nclosely related to the spectral learning algorithm for predicitive state\nrepresentations and offers appealing theoretical guarantees and time\ncomplexity. We empirically show on two domains that our approach is more sample\nand time efficient compared to classical methods.\n", "versions": [{"version": "v1", "created": "Tue, 12 Nov 2019 16:56:37 GMT"}, {"version": "v2", "created": "Fri, 22 Nov 2019 02:37:51 GMT"}], "update_date": "2019-11-25", "authors_parsed": [["Li", "Tianyu", ""], ["Mazoure", "Bogdan", ""], ["Precup", "Doina", ""], ["Rabusseau", "Guillaume", ""]]}, {"id": "1911.05013", "submitter": "Vishaal Udandarao", "authors": "Abhishek Agarwal, Nikhil Sachdeva, Raj Kamal Yadav, Vishaal Udandarao,\n  Vrinda Mittal, Anubha Gupta, Abhinav Mathur", "title": "EDUQA: Educational Domain Question Answering System using Conceptual\n  Network Mapping", "comments": "Published in the 44th International Conference on Acoustics, Speech,\n  and Signal Processing (ICASSP) 2019", "journal-ref": "IEEE ICASSP (2019) 8137-8141", "doi": "10.1109/ICASSP.2019.8683538", "report-no": null, "categories": "cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most of the existing question answering models can be largely compiled into\ntwo categories: i) open domain question answering models that answer generic\nquestions and use large-scale knowledge base along with the targeted web-corpus\nretrieval and ii) closed domain question answering models that address focused\nquestioning area and use complex deep learning models. Both the above models\nderive answers through textual comprehension methods. Due to their inability to\ncapture the pedagogical meaning of textual content, these models are not\nappropriately suited to the educational field for pedagogy. In this paper, we\npropose an on-the-fly conceptual network model that incorporates educational\nsemantics. The proposed model preserves correlations between conceptual\nentities by applying intelligent indexing algorithms on the concept network so\nas to improve answer generation. This model can be utilized for building\ninteractive conversational agents for aiding classroom learning.\n", "versions": [{"version": "v1", "created": "Tue, 12 Nov 2019 17:11:55 GMT"}], "update_date": "2019-11-13", "authors_parsed": [["Agarwal", "Abhishek", ""], ["Sachdeva", "Nikhil", ""], ["Yadav", "Raj Kamal", ""], ["Udandarao", "Vishaal", ""], ["Mittal", "Vrinda", ""], ["Gupta", "Anubha", ""], ["Mathur", "Abhinav", ""]]}, {"id": "1911.05041", "submitter": "Maen Alzubi", "authors": "Maen Alzubi, Szilveszter Kovacs", "title": "Some Considerations and a Benchmark Related to the CNF Property of the\n  Koczy-Hirota Fuzzy Rule Interpolation", "comments": null, "journal-ref": "International Journal on Advanced Science, Engineering and\n  Information Technology 2019. Vol.9. No 5", "doi": "10.18517/ijaseit.9.5.8356", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The goal of this paper is twofold. Once to highlight some basic problematic\nproperties of the KH Fuzzy Rule Interpolation through examples, secondly to set\nup a brief Benchmark set of Examples, which is suitable for testing other Fuzzy\nRule Interpolation (FRI) methods against these ill conditions. Fuzzy Rule\nInterpolation methods were originally proposed to handle the situation of\nmissing fuzzy rules (sparse rule-bases) and to reduce the decision complexity.\nFuzzy Rule Interpolation is an important technique for implementing inference\nwith sparse fuzzy rule-bases. Even if a given observation has no overlap with\nthe antecedent of any rule from the rule-base, FRI may still conclude a\nconclusion. The first FRI method was the Koczy and Hirota proposed \"Linear\nInterpolation\", which was later renamed to \"KH Fuzzy Interpolation\" by the\nfollowers. There are several conditions and criteria have been suggested for\nunifying the common requirements an FRI methods have to satisfy. One of the\nmost common one is the demand for a convex and normal fuzzy (CNF) conclusion,\nif all the rule antecedents and consequents are CNF sets. The KH FRI is the\none, which cannot fulfill this condition. This paper is focusing on the\nconditions, where the KH FRI fails the demand for the CNF conclusion. By\nsetting up some CNF rule examples, the paper also defines a Benchmark, in which\nother FRI methods can be tested if they can produce CNF conclusion where the KH\nFRI fails.\n", "versions": [{"version": "v1", "created": "Tue, 12 Nov 2019 18:02:14 GMT"}], "update_date": "2019-11-18", "authors_parsed": [["Alzubi", "Maen", ""], ["Kovacs", "Szilveszter", ""]]}, {"id": "1911.05072", "submitter": "Zhe Li", "authors": "Zhe Li, Wieland Brendel, Edgar Y. Walker, Erick Cobos, Taliah\n  Muhammad, Jacob Reimer, Matthias Bethge, Fabian H. Sinz, Xaq Pitkow, Andreas\n  S. Tolias", "title": "Learning From Brains How to Regularize Machines", "comments": "14 pages, 7 figures, NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite impressive performance on numerous visual tasks, Convolutional Neural\nNetworks (CNNs) --- unlike brains --- are often highly sensitive to small\nperturbations of their input, e.g. adversarial noise leading to erroneous\ndecisions. We propose to regularize CNNs using large-scale neuroscience data to\nlearn more robust neural features in terms of representational similarity. We\npresented natural images to mice and measured the responses of thousands of\nneurons from cortical visual areas. Next, we denoised the notoriously variable\nneural activity using strong predictive models trained on this large corpus of\nresponses from the mouse visual system, and calculated the representational\nsimilarity for millions of pairs of images from the model's predictions. We\nthen used the neural representation similarity to regularize CNNs trained on\nimage classification by penalizing intermediate representations that deviated\nfrom neural ones. This preserved performance of baseline models when\nclassifying images under standard benchmarks, while maintaining substantially\nhigher performance compared to baseline or control models when classifying\nnoisy images. Moreover, the models regularized with cortical representations\nalso improved model robustness in terms of adversarial attacks. This\ndemonstrates that regularizing with neural data can be an effective tool to\ncreate an inductive bias towards more robust inference.\n", "versions": [{"version": "v1", "created": "Mon, 11 Nov 2019 21:53:26 GMT"}], "update_date": "2019-11-14", "authors_parsed": [["Li", "Zhe", ""], ["Brendel", "Wieland", ""], ["Walker", "Edgar Y.", ""], ["Cobos", "Erick", ""], ["Muhammad", "Taliah", ""], ["Reimer", "Jacob", ""], ["Bethge", "Matthias", ""], ["Sinz", "Fabian H.", ""], ["Pitkow", "Xaq", ""], ["Tolias", "Andreas S.", ""]]}, {"id": "1911.05076", "submitter": "Octavian-Eugen Ganea", "authors": "Gregor Bachmann, Gary B\\'ecigneul, Octavian-Eugen Ganea", "title": "Constant Curvature Graph Convolutional Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Interest has been rising lately towards methods representing data in\nnon-Euclidean spaces, e.g. hyperbolic or spherical, that provide specific\ninductive biases useful for certain real-world data properties, e.g.\nscale-free, hierarchical or cyclical. However, the popular graph neural\nnetworks are currently limited in modeling data only via Euclidean geometry and\nassociated vector space operations. Here, we bridge this gap by proposing\nmathematically grounded generalizations of graph convolutional networks (GCN)\nto (products of) constant curvature spaces. We do this by i) introducing a\nunified formalism that can interpolate smoothly between all geometries of\nconstant curvature, ii) leveraging gyro-barycentric coordinates that generalize\nthe classic Euclidean concept of the center of mass. Our class of models\nsmoothly recover their Euclidean counterparts when the curvature goes to zero\nfrom either side. Empirically, we outperform Euclidean GCNs in the tasks of\nnode classification and distortion minimization for symbolic data exhibiting\nnon-Euclidean behavior, according to their discrete curvature.\n", "versions": [{"version": "v1", "created": "Tue, 12 Nov 2019 16:57:00 GMT"}, {"version": "v2", "created": "Tue, 18 Feb 2020 23:20:10 GMT"}, {"version": "v3", "created": "Tue, 19 May 2020 17:48:48 GMT"}], "update_date": "2020-05-20", "authors_parsed": [["Bachmann", "Gregor", ""], ["B\u00e9cigneul", "Gary", ""], ["Ganea", "Octavian-Eugen", ""]]}, {"id": "1911.05109", "submitter": "Jeremy Weiss", "authors": "Yoonjung Kim and Jeremy C. Weiss", "title": "Harmonic Mean Point Processes: Proportional Rate Error Minimization for\n  Obtundation Prediction", "comments": "Machine Learning for Health (ML4H) at NeurIPS 2019 - Extended\n  Abstract", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In healthcare, the highest risk individuals for morbidity and mortality are\nrarely those with the greatest modifiable risk. By contrast, many machine\nlearning formulations implicitly attend to the highest risk individuals. We\nfocus on this problem in point processes, a popular modeling technique for the\nanalysis of the temporal event sequences in electronic health records (EHR)\ndata with applications in risk stratification and risk score systems. We show\nthat optimization of the log-likelihood function also gives disproportionate\nattention to high risk individuals and leads to poor prediction results for low\nrisk individuals compared to ones at high risk. We characterize the problem and\npropose an adjusted log-likelihood formulation as a new objective for point\nprocesses. We demonstrate the benefits of our method in simulations and in EHR\ndata of patients admitted to the critical care unit for intracerebral\nhemorrhage.\n", "versions": [{"version": "v1", "created": "Tue, 12 Nov 2019 19:19:36 GMT"}, {"version": "v2", "created": "Thu, 14 Nov 2019 18:45:13 GMT"}], "update_date": "2019-11-15", "authors_parsed": [["Kim", "Yoonjung", ""], ["Weiss", "Jeremy C.", ""]]}, {"id": "1911.05140", "submitter": "Kiret Dhindsa", "authors": "Umaseh Sivanesan and Luis H. Braga and Ranil R. Sonnadara and Kiret\n  Dhindsa", "title": "Unsupervised Medical Image Segmentation with Adversarial Networks: From\n  Edge Diagrams to Segmentation Maps", "comments": "16 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.AI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop and approach to unsupervised semantic medical image segmentation\nthat extends previous work with generative adversarial networks. We use\nexisting edge detection methods to construct simple edge diagrams, train a\ngenerative model to convert them into synthetic medical images, and construct a\ndataset of synthetic images with known segmentations using variations on\nextracted edge diagrams. This synthetic dataset is then used to train a\nsupervised image segmentation model. We test our approach on a clinical dataset\nof kidney ultrasound images and the benchmark ISIC 2018 skin lesion dataset. We\nshow that our unsupervised approach is more accurate than previous unsupervised\nmethods, and performs reasonably compared to supervised image segmentation\nmodels. All code and trained models are available at\nhttps://github.com/kiretd/Unsupervised-MIseg.\n", "versions": [{"version": "v1", "created": "Tue, 12 Nov 2019 20:56:33 GMT"}], "update_date": "2019-11-14", "authors_parsed": [["Sivanesan", "Umaseh", ""], ["Braga", "Luis H.", ""], ["Sonnadara", "Ranil R.", ""], ["Dhindsa", "Kiret", ""]]}, {"id": "1911.05146", "submitter": "Ammar Ahmad Awan", "authors": "Ammar Ahmad Awan, Arpan Jain, Quentin Anthony, Hari Subramoni, and\n  Dhabaleswar K. Panda", "title": "HyPar-Flow: Exploiting MPI and Keras for Scalable Hybrid-Parallel DNN\n  Training using TensorFlow", "comments": "18 pages, 10 figures, Accepted, to be presented at ISC '20", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.AI cs.LG cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To reduce training time of large-scale DNNs, scientists have started to\nexplore parallelization strategies like data-parallelism, model-parallelism,\nand hybrid-parallelism. While data-parallelism has been extensively studied and\ndeveloped, several problems exist in realizing model-parallelism and\nhybrid-parallelism efficiently. Four major problems we focus on are: 1)\ndefining a notion of a distributed model across processes, 2) implementing\nforward/back-propagation across process boundaries that requires explicit\ncommunication, 3) obtaining parallel speedup on an inherently sequential task,\nand 4) achieving scalability without losing out on a model's accuracy. To\naddress these problems, we create HyPar-Flow --- a model-size/-type agnostic,\nscalable, practical, and user-transparent system for hybrid-parallel training\nby exploiting MPI, Keras, and TensorFlow. HyPar-Flow provides a single API that\ncan be used to perform data, model, and hybrid parallel training of any Keras\nmodel at scale. We create an internal distributed representation of the\nuser-provided Keras model, utilize TF's Eager execution features for\ndistributed forward/back-propagation across processes, exploit pipelining to\nimprove performance and leverage efficient MPI primitives for scalable\ncommunication. Between model partitions, we use send and recv to exchange\nlayer-data/partial-errors while allreduce is used to accumulate/average\ngradients across model replicas. Beyond the design and implementation of\nHyPar-Flow, we also provide comprehensive correctness and performance results\non three state-of-the-art HPC systems including TACC Frontera (#5 on\nTop500.org). For ResNet-1001, an ultra-deep model, HyPar-Flow provides: 1) Up\nto 1.6x speedup over Horovod-based data-parallel training, 2) 110x speedup over\nsingle-node on 128 Stampede2 nodes, and 3) 481x speedup over single-node on 512\nFrontera nodes.\n", "versions": [{"version": "v1", "created": "Tue, 12 Nov 2019 21:07:42 GMT"}, {"version": "v2", "created": "Wed, 19 Feb 2020 15:16:53 GMT"}], "update_date": "2020-02-20", "authors_parsed": [["Awan", "Ammar Ahmad", ""], ["Jain", "Arpan", ""], ["Anthony", "Quentin", ""], ["Subramoni", "Hari", ""], ["Panda", "Dhabaleswar K.", ""]]}, {"id": "1911.05153", "submitter": "Arash Einolghozati", "authors": "Arash Einolghozati, Sonal Gupta, Mrinal Mohit, Rushin Shah", "title": "Improving Robustness of Task Oriented Dialog Systems", "comments": null, "journal-ref": "3rd Conversational AI Workshop at 33rd Conference on Neural\n  Information Processing Systems (NeurIPS 2019)", "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Task oriented language understanding in dialog systems is often modeled using\nintents (task of a query) and slots (parameters for that task). Intent\ndetection and slot tagging are, in turn, modeled using sentence classification\nand word tagging techniques respectively. Similar to adversarial attack\nproblems with computer vision models discussed in existing literature, these\nintent-slot tagging models are often over-sensitive to small variations in\ninput -- predicting different and often incorrect labels when small changes are\nmade to a query, thus reducing their accuracy and reliability. However,\nevaluating a model's robustness to these changes is harder for language since\nwords are discrete and an automated change (e.g. adding `noise') to a query\nsometimes changes the meaning and thus labels of a query. In this paper, we\nfirst describe how to create an adversarial test set to measure the robustness\nof these models. Furthermore, we introduce and adapt adversarial training\nmethods as well as data augmentation using back-translation to mitigate these\nissues. Our experiments show that both techniques improve the robustness of the\nsystem substantially and can be combined to yield the best results.\n", "versions": [{"version": "v1", "created": "Tue, 12 Nov 2019 21:34:15 GMT"}], "update_date": "2019-11-14", "authors_parsed": [["Einolghozati", "Arash", ""], ["Gupta", "Sonal", ""], ["Mohit", "Mrinal", ""], ["Shah", "Rushin", ""]]}, {"id": "1911.05202", "submitter": "Liangyi Kang", "authors": "Liangyi Kang, Jie Liu, Lingqiao Liu, Qinfeng Shi, and Dan Ye", "title": "Creating Auxiliary Representations from Charge Definitions for Criminal\n  Charge Prediction", "comments": "8 pages, 5figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Charge prediction, determining charges for criminal cases by analyzing the\ntextual fact descriptions, is a promising technology in legal assistant\nsystems. In practice, the fact descriptions could exhibit a significant\nintra-class variation due to factors like non-normative use of language, which\nmakes the prediction task very challenging, especially for charge classes with\ntoo few samples to cover the expression variation. In this work, we explore to\nuse the charge definitions from criminal law to alleviate this issue. The key\nidea is that the expressions in a fact description should have corresponding\nformal terms in charge definitions, and those terms are shared across classes\nand could account for the diversity in the fact descriptions. Thus, we propose\nto create auxiliary fact representations from charge definitions to augment\nfact descriptions representation. The generated auxiliary representations are\ncreated through the interaction of fact description with the relevant charge\ndefinitions and terms in those definitions by integrated sentence- and\nword-level attention scheme. Experimental results on two datasets show that our\nmodel achieves significant improvement than baselines, especially for classes\nwith few samples.\n", "versions": [{"version": "v1", "created": "Tue, 12 Nov 2019 23:31:12 GMT"}], "update_date": "2019-11-14", "authors_parsed": [["Kang", "Liangyi", ""], ["Liu", "Jie", ""], ["Liu", "Lingqiao", ""], ["Shi", "Qinfeng", ""], ["Ye", "Dan", ""]]}, {"id": "1911.05241", "submitter": "Sravan Babu Bodapati", "authors": "Sravan Bodapati, Hyokun Yun, Yaser Al-Onaizan", "title": "Robustness to Capitalization Errors in Named Entity Recognition", "comments": "Accepted to EMNLP 2019 Workshop : W-NUT 2019 5th Workshop on Noisy\n  User Generated Text", "journal-ref": "http://noisy-text.github.io/2019/", "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Robustness to capitalization errors is a highly desirable characteristic of\nnamed entity recognizers, yet we find standard models for the task are\nsurprisingly brittle to such noise. Existing methods to improve robustness to\nthe noise completely discard given orthographic information, mwhich\nsignificantly degrades their performance on well-formed text. We propose a\nsimple alternative approach based on data augmentation, which allows the model\nto \\emph{learn} to utilize or ignore orthographic information depending on its\nusefulness in the context. It achieves competitive robustness to capitalization\nerrors while making negligible compromise to its performance on well-formed\ntext and significantly improving generalization power on noisy user-generated\ntext. Our experiments clearly and consistently validate our claim across\ndifferent types of machine learning models, languages, and dataset sizes.\n", "versions": [{"version": "v1", "created": "Wed, 13 Nov 2019 01:52:27 GMT"}], "update_date": "2019-11-14", "authors_parsed": [["Bodapati", "Sravan", ""], ["Yun", "Hyokun", ""], ["Al-Onaizan", "Yaser", ""]]}, {"id": "1911.05248", "submitter": "Sara Hooker", "authors": "Sara Hooker, Aaron Courville, Gregory Clark, Yann Dauphin, Andrea\n  Frome", "title": "What Do Compressed Deep Neural Networks Forget?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.HC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural network pruning and quantization techniques have demonstrated it\nis possible to achieve high levels of compression with surprisingly little\ndegradation to test set accuracy. However, this measure of performance conceals\nsignificant differences in how different classes and images are impacted by\nmodel compression techniques. We find that models with radically different\nnumbers of weights have comparable top-line performance metrics but diverge\nconsiderably in behavior on a narrow subset of the dataset. This small subset\nof data points, which we term Pruning Identified Exemplars (PIEs) are\nsystematically more impacted by the introduction of sparsity. Compression\ndisproportionately impacts model performance on the underrepresented long-tail\nof the data distribution. PIEs over-index on atypical or noisy images that are\nfar more challenging for both humans and algorithms to classify. Our work\nprovides intuition into the role of capacity in deep neural networks and the\ntrade-offs incurred by compression. An understanding of this disparate impact\nis critical given the widespread deployment of compressed models in the wild.\n", "versions": [{"version": "v1", "created": "Wed, 13 Nov 2019 02:02:19 GMT"}, {"version": "v2", "created": "Mon, 13 Jul 2020 18:24:24 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Hooker", "Sara", ""], ["Courville", "Aaron", ""], ["Clark", "Gregory", ""], ["Dauphin", "Yann", ""], ["Frome", "Andrea", ""]]}, {"id": "1911.05268", "submitter": "Rey Wiyatno", "authors": "Rey Reza Wiyatno, Anqi Xu, Ousmane Dia, Archy de Berker", "title": "Adversarial Examples in Modern Machine Learning: A Review", "comments": "Work in progress, 97 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent research has found that many families of machine learning models are\nvulnerable to adversarial examples: inputs that are specifically designed to\ncause the target model to produce erroneous outputs. In this survey, we focus\non machine learning models in the visual domain, where methods for generating\nand detecting such examples have been most extensively studied. We explore a\nvariety of adversarial attack methods that apply to image-space content, real\nworld adversarial attacks, adversarial defenses, and the transferability\nproperty of adversarial examples. We also discuss strengths and weaknesses of\nvarious methods of adversarial attack and defense. Our aim is to provide an\nextensive coverage of the field, furnishing the reader with an intuitive\nunderstanding of the mechanics of adversarial attack and defense mechanisms and\nenlarging the community of researchers studying this fundamental set of\nproblems.\n", "versions": [{"version": "v1", "created": "Wed, 13 Nov 2019 03:09:40 GMT"}, {"version": "v2", "created": "Fri, 15 Nov 2019 23:07:01 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Wiyatno", "Rey Reza", ""], ["Xu", "Anqi", ""], ["Dia", "Ousmane", ""], ["de Berker", "Archy", ""]]}, {"id": "1911.05275", "submitter": "Gaurav Menghani", "authors": "Gaurav Menghani, Sujith Ravi", "title": "Learning from a Teacher using Unlabeled Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge distillation is a widely used technique for model compression. We\nposit that the teacher model used in a distillation setup, captures\nrelationships between classes, that extend beyond the original dataset. We\nempirically show that a teacher model can transfer this knowledge to a student\nmodel even on an {\\it out-of-distribution} dataset. Using this approach, we\nshow promising results on MNIST, CIFAR-10, and Caltech-256 datasets using\nunlabeled image data from different sources. Our results are encouraging and\nhelp shed further light from the perspective of understanding knowledge\ndistillation and utilizing unlabeled data to improve model quality.\n", "versions": [{"version": "v1", "created": "Wed, 13 Nov 2019 03:43:29 GMT"}], "update_date": "2019-11-14", "authors_parsed": [["Menghani", "Gaurav", ""], ["Ravi", "Sujith", ""]]}, {"id": "1911.05316", "submitter": "Ziqi Ke", "authors": "Ziqi Ke, Haris Vikalo", "title": "A Graph Auto-Encoder for Haplotype Assembly and Viral Quasispecies\n  Reconstruction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.GN cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reconstructing components of a genomic mixture from data obtained by means of\nDNA sequencing is a challenging problem encountered in a variety of\napplications including single individual haplotyping and studies of viral\ncommunities. High-throughput DNA sequencing platforms oversample mixture\ncomponents to provide massive amounts of reads whose relative positions can be\ndetermined by mapping the reads to a known reference genome; assembly of the\ncomponents, however, requires discovery of the reads' origin -- an NP-hard\nproblem that the existing methods struggle to solve with the required level of\naccuracy. In this paper, we present a learning framework based on a graph\nauto-encoder designed to exploit structural properties of sequencing data. The\nalgorithm is a neural network which essentially trains to ignore sequencing\nerrors and infers the posteriori probabilities of the origin of sequencing\nreads. Mixture components are then reconstructed by finding consensus of the\nreads determined to originate from the same genomic component. Results on\nrealistic synthetic as well as experimental data demonstrate that the proposed\nframework reliably assembles haplotypes and reconstructs viral communities,\noften significantly outperforming state-of-the-art techniques.\n", "versions": [{"version": "v1", "created": "Wed, 13 Nov 2019 06:32:48 GMT"}], "update_date": "2019-11-14", "authors_parsed": [["Ke", "Ziqi", ""], ["Vikalo", "Haris", ""]]}, {"id": "1911.05321", "submitter": "Ajay Mandlekar", "authors": "Ajay Mandlekar, Fabio Ramos, Byron Boots, Silvio Savarese, Li Fei-Fei,\n  Animesh Garg, Dieter Fox", "title": "IRIS: Implicit Reinforcement without Interaction at Scale for Learning\n  Control from Offline Robot Manipulation Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning from offline task demonstrations is a problem of great interest in\nrobotics. For simple short-horizon manipulation tasks with modest variation in\ntask instances, offline learning from a small set of demonstrations can produce\ncontrollers that successfully solve the task. However, leveraging a fixed batch\nof data can be problematic for larger datasets and longer-horizon tasks with\ngreater variations. The data can exhibit substantial diversity and consist of\nsuboptimal solution approaches. In this paper, we propose Implicit\nReinforcement without Interaction at Scale (IRIS), a novel framework for\nlearning from large-scale demonstration datasets. IRIS factorizes the control\nproblem into a goal-conditioned low-level controller that imitates short\ndemonstration sequences and a high-level goal selection mechanism that sets\ngoals for the low-level and selectively combines parts of suboptimal solutions\nleading to more successful task completions. We evaluate IRIS across three\ndatasets, including the RoboTurk Cans dataset collected by humans via\ncrowdsourcing, and show that performant policies can be learned from purely\noffline learning. Additional results at\nhttps://sites.google.com/stanford.edu/iris/ .\n", "versions": [{"version": "v1", "created": "Wed, 13 Nov 2019 06:56:21 GMT"}, {"version": "v2", "created": "Sun, 23 Feb 2020 02:33:41 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Mandlekar", "Ajay", ""], ["Ramos", "Fabio", ""], ["Boots", "Byron", ""], ["Savarese", "Silvio", ""], ["Fei-Fei", "Li", ""], ["Garg", "Animesh", ""], ["Fox", "Dieter", ""]]}, {"id": "1911.05369", "submitter": "Boris Ruf", "authors": "Vincent Grari, Boris Ruf, Sylvain Lamprier, Marcin Detyniecki", "title": "Fair Adversarial Gradient Tree Boosting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fair classification has become an important topic in machine learning\nresearch. While most bias mitigation strategies focus on neural networks, we\nnoticed a lack of work on fair classifiers based on decision trees even though\nthey have proven very efficient. In an up-to-date comparison of\nstate-of-the-art classification algorithms in tabular data, tree boosting\noutperforms deep learning. For this reason, we have developed a novel approach\nof adversarial gradient tree boosting. The objective of the algorithm is to\npredict the output $Y$ with gradient tree boosting while minimizing the ability\nof an adversarial neural network to predict the sensitive attribute $S$. The\napproach incorporates at each iteration the gradient of the neural network\ndirectly in the gradient tree boosting. We empirically assess our approach on 4\npopular data sets and compare against state-of-the-art algorithms. The results\nshow that our algorithm achieves a higher accuracy while obtaining the same\nlevel of fairness, as measured using a set of different common fairness\ndefinitions.\n", "versions": [{"version": "v1", "created": "Wed, 13 Nov 2019 09:43:55 GMT"}, {"version": "v2", "created": "Mon, 18 Nov 2019 10:28:37 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Grari", "Vincent", ""], ["Ruf", "Boris", ""], ["Lamprier", "Sylvain", ""], ["Detyniecki", "Marcin", ""]]}, {"id": "1911.05370", "submitter": "Sunil Mallya", "authors": "Sunil Mallya, Marc Overhage, Sravan Bodapati, Navneet Srivastava,\n  Sahika Genc", "title": "SAVEHR: Self Attention Vector Representations for EHR based Personalized\n  Chronic Disease Onset Prediction and Interpretability", "comments": "ML4H Workshop at Neurips 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Chronic disease progression is emerging as an important area of investment\nfor healthcare providers. As the quantity and richness of available clinical\ndata continue to increase along with advances in machine learning, there is\ngreat potential to advance our approaches to caring for patients. An ideal\napproach to this problem should generate good performance on at least three\naxes namely, a) perform across many clinical conditions without requiring deep\nclinical expertise or extensive data scientist effort, b) generalization across\npopulations, and c) be explainable (model interpretability). We present SAVEHR,\na self-attention based architecture on heterogeneous structured EHR data that\nachieves $>$ 0.51 AUC-PR and $>$ 0.87 AUC-ROC gains on predicting the onset of\nfour clinical conditions (CHF, Kidney Failure, Diabetes and COPD) 15-months in\nadvance, and transfers with high performance onto a new population. We\ndemonstrate that SAVEHR model performs superior to ten baselines on all three\naxes stated formerly.\n", "versions": [{"version": "v1", "created": "Wed, 13 Nov 2019 09:45:55 GMT"}], "update_date": "2019-11-14", "authors_parsed": [["Mallya", "Sunil", ""], ["Overhage", "Marc", ""], ["Bodapati", "Sravan", ""], ["Srivastava", "Navneet", ""], ["Genc", "Sahika", ""]]}, {"id": "1911.05403", "submitter": "Yavuz Koroglu", "authors": "Yavuz Koroglu and Alper Sen", "title": "Reinforcement Learning-Driven Test Generation for Android GUI\n  Applications using Formal Specifications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There have been many studies on automated test generation for mobile\nGraphical User Interface (GUI) applications. These studies successfully\ndemonstrate how to detect fatal exceptions and achieve high code and activity\ncoverage with fully automated test generation engines. However, it is unclear\nhow many GUI functions these engines manage to test. Furthermore, these engines\nimplement only implicit test oracles. We propose Fully Automated Reinforcement\nLEArning-Driven Specification-Based Test Generator for Android\n(FARLEAD-Android). FARLEAD-Android accepts a GUI-level formal specification as\na Linear-time Temporal Logic (LTL) formula. By dynamically executing the\nApplication Under Test (AUT), it learns how to generate a test that satisfies\nthe LTL formula using Reinforcement Learning (RL). The LTL formula does not\njust guide the test generation but also acts as a specified test oracle,\nenabling the developer to define automated test oracles for a wide variety of\nGUI functions by changing the formula. Our evaluation shows that\nFARLEAD-Android is more effective and achieves higher performance in generating\ntests for specified GUI functions than three known approaches, Random, Monkey,\nand QBEa. To the best of our knowledge, FARLEAD-Android is the first fully\nautomated mobile GUI testing engine that uses formal specifications.\n", "versions": [{"version": "v1", "created": "Wed, 13 Nov 2019 11:19:30 GMT"}, {"version": "v2", "created": "Wed, 27 Nov 2019 05:18:45 GMT"}], "update_date": "2019-11-28", "authors_parsed": [["Koroglu", "Yavuz", ""], ["Sen", "Alper", ""]]}, {"id": "1911.05441", "submitter": "Xinyu Fan", "authors": "Faen Zhang, Xinyu Fan, Hui Xu, Pengcheng Zhou, Yujian He, Junlong Liu", "title": "Regression via Arbitrary Quantile Modeling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the regression problem, L1 and L2 are the most commonly used loss\nfunctions, which produce mean predictions with different biases. However, the\npredictions are neither robust nor adequate enough since they only capture a\nfew conditional distributions instead of the whole distribution, especially for\nsmall datasets. To address this problem, we proposed arbitrary quantile\nmodeling to regulate the prediction, which achieved better performance compared\nto traditional loss functions. More specifically, a new distribution regression\nmethod, Deep Distribution Regression (DDR), is proposed to estimate arbitrary\nquantiles of the response variable. Our DDR method consists of two models: a Q\nmodel, which predicts the corresponding value for arbitrary quantile, and an F\nmodel, which predicts the corresponding quantile for arbitrary value.\nFurthermore, the duality between Q and F models enables us to design a novel\nloss function for joint training and perform a dual inference mechanism. Our\nexperiments demonstrate that our DDR-joint and DDR-disjoint methods outperform\nprevious methods such as AdaBoost, random forest, LightGBM, and neural networks\nboth in terms of mean and quantile prediction.\n", "versions": [{"version": "v1", "created": "Wed, 13 Nov 2019 13:11:30 GMT"}], "update_date": "2019-11-14", "authors_parsed": [["Zhang", "Faen", ""], ["Fan", "Xinyu", ""], ["Xu", "Hui", ""], ["Zhou", "Pengcheng", ""], ["He", "Yujian", ""], ["Liu", "Junlong", ""]]}, {"id": "1911.05443", "submitter": "Xinyu Fan", "authors": "Xinyu Fan", "title": "Dynamic Connected Neural Decision Classifier and Regressor with Dynamic\n  Softing Pruning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To deal with various datasets over different complexity, this paper presents\nan self-adaptive learning model that combines the proposed Dynamic Connected\nNeural Decision Networks (DNDN) and a new pruning method--Dynamic Soft Pruning\n(DSP). DNDN is a combination of random forests and deep neural networks that\nenjoys both the advantages of strong classification capability of tree-like\nstructure and representation learning capability of network structure. Based on\nDeep Neural Decision Forests (DNDF), this paper adopts an end-to-end training\napproach by representing the classification distribution with multiple randomly\ninitialized softmax layers, which further allows an ensemble of multiple random\nforests attached to layers of neural network with different depth. We also\npropose a soft pruning method DSP to reduce the redundant connections of the\nnetwork adaptively to avoid over-fitting simple dataset. The model demonstrates\nno performance loss compared with unpruned models and even higher robustness\nover different data and feature distribution. Extensive experiments on\ndifferent datasets demonstrate the superiority of the proposed model over other\npopular algorithms in solving classification tasks.\n", "versions": [{"version": "v1", "created": "Wed, 13 Nov 2019 13:21:10 GMT"}, {"version": "v2", "created": "Wed, 20 Nov 2019 15:12:09 GMT"}, {"version": "v3", "created": "Mon, 22 Feb 2021 07:35:07 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Fan", "Xinyu", ""]]}, {"id": "1911.05479", "submitter": "Asim Iqbal", "authors": "Asim Iqbal, Phil Dong, Christopher M Kim, Heeun Jang", "title": "Decoding Neural Responses in Mouse Visual Cortex through a Deep Neural\n  Network", "comments": null, "journal-ref": "2019 International Joint Conference on Neural Networks (IJCNN).\n  IEEE, 2019", "doi": "10.1109/IJCNN.2019.8852121", "report-no": null, "categories": "q-bio.NC cs.AI cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Finding a code to unravel the population of neural responses that leads to a\ndistinct animal behavior has been a long-standing question in the field of\nneuroscience. With the recent advances in machine learning, it is shown that\nthe hierarchically Deep Neural Networks (DNNs) perform optimally in decoding\nunique features out of complex datasets. In this study, we utilize the power of\na DNN to explore the computational principles in the mammalian brain by\nexploiting the Neuropixel data from Allen Brain Institute. We decode the neural\nresponses from mouse visual cortex to predict the presented stimuli to the\nanimal for natural (bear, trees, cheetah, etc.) and artificial (drifted\ngratings, orientated bars, etc.) classes. Our results indicate that neurons in\nmouse visual cortex encode the features of natural and artificial objects in a\ndistinct manner, and such neural code is consistent across animals. We\ninvestigate this by applying transfer learning to train a DNN on the neural\nresponses of a single animal and test its generalized performance across\nmultiple animals. Within a single animal, DNN is able to decode the neural\nresponses with as much as 100% classification accuracy. Across animals, this\naccuracy is reduced to 91%. This study demonstrates the potential of utilizing\nthe DNN models as a computational framework to understand the neural coding\nprinciples in the mammalian brain.\n", "versions": [{"version": "v1", "created": "Sat, 26 Oct 2019 05:02:33 GMT"}], "update_date": "2019-11-14", "authors_parsed": [["Iqbal", "Asim", ""], ["Dong", "Phil", ""], ["Kim", "Christopher M", ""], ["Jang", "Heeun", ""]]}, {"id": "1911.05485", "submitter": "Johannes Klicpera", "authors": "Johannes Klicpera, Stefan Wei{\\ss}enberger, Stephan G\\\"unnemann", "title": "Diffusion Improves Graph Learning", "comments": "Published as a conference paper at NeurIPS 2019", "journal-ref": "Thirty-third Conference on Neural Information Processing Systems\n  (NeurIPS), Vancouver, Canada, 2019", "doi": null, "report-no": null, "categories": "cs.SI cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph convolution is the core of most Graph Neural Networks (GNNs) and\nusually approximated by message passing between direct (one-hop) neighbors. In\nthis work, we remove the restriction of using only the direct neighbors by\nintroducing a powerful, yet spatially localized graph convolution: Graph\ndiffusion convolution (GDC). GDC leverages generalized graph diffusion,\nexamples of which are the heat kernel and personalized PageRank. It alleviates\nthe problem of noisy and often arbitrarily defined edges in real graphs. We\nshow that GDC is closely related to spectral-based models and thus combines the\nstrengths of both spatial (message passing) and spectral methods. We\ndemonstrate that replacing message passing with graph diffusion convolution\nconsistently leads to significant performance improvements across a wide range\nof models on both supervised and unsupervised tasks and a variety of datasets.\nFurthermore, GDC is not limited to GNNs but can trivially be combined with any\ngraph-based model or algorithm (e.g. spectral clustering) without requiring any\nchanges to the latter or affecting its computational complexity. Our\nimplementation is available online.\n", "versions": [{"version": "v1", "created": "Mon, 28 Oct 2019 17:51:46 GMT"}, {"version": "v2", "created": "Thu, 14 Nov 2019 08:41:14 GMT"}, {"version": "v3", "created": "Tue, 3 Dec 2019 14:42:37 GMT"}, {"version": "v4", "created": "Mon, 23 Dec 2019 21:13:40 GMT"}, {"version": "v5", "created": "Sun, 29 Dec 2019 22:33:56 GMT"}], "update_date": "2020-01-01", "authors_parsed": [["Klicpera", "Johannes", ""], ["Wei\u00dfenberger", "Stefan", ""], ["G\u00fcnnemann", "Stephan", ""]]}, {"id": "1911.05499", "submitter": "Damien Pellier", "authors": "D. H\\\"oller, G. Behnke, P. Bercher, S. Biundo, H. Fiorino, D. Pellier\n  and R. Alford", "title": "HDDL -- A Language to Describe Hierarchical Planning Problems", "comments": "International Workshop on HTN Planning (ICAPS), 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The research in hierarchical planning has made considerable progress in the\nlast few years. Many recent systems do not rely on hand-tailored advice anymore\nto find solutions, but are supposed to be domain-independent systems that come\nwith sophisticated solving techniques. In principle, this development would\nmake the comparison between systems easier (because the domains are not\ntailored to a single system anymore) and -- much more important -- also the\nintegration into other systems, because the modeling process is less tedious\n(due to the lack of advice) and there is no (or less) commitment to a certain\nplanning system the model is created for. However, these advantages are\ndestroyed by the lack of a common input language and feature set supported by\nthe different systems. In this paper, we propose an extension to PDDL, the\ndescription language used in non-hierarchical planning, to the needs of\nhierarchical planning systems. We restrict our language to a basic feature set\nshared by many recent systems, give an extension of PDDL's EBNF syntax\ndefinition, and discuss our extensions with respect to several planner-specific\ninput languages from related work.\n", "versions": [{"version": "v1", "created": "Wed, 13 Nov 2019 14:23:55 GMT"}], "update_date": "2019-11-14", "authors_parsed": [["H\u00f6ller", "D.", ""], ["Behnke", "G.", ""], ["Bercher", "P.", ""], ["Biundo", "S.", ""], ["Fiorino", "H.", ""], ["Pellier", "D.", ""], ["Alford", "R.", ""]]}, {"id": "1911.05586", "submitter": "Quanshi Zhang", "authors": "Li Chen, Hailun Ding, Qi Li, Zhuo Li, Jian Peng, Haifeng Li", "title": "Understanding the Importance of Single Directions via Representative\n  Substitution", "comments": "In AAAI-19 Workshop on Network Interpretability for Deep Learning.\n  Published version of arXiv:1811.11053", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding the internal representations of deep neural networks (DNNs) is\ncrucal to explain their behavior. The interpretation of individual units, which\nare neurons in MLPs or convolution kernels in convolutional networks, has been\npaid much attention given their fundamental role. However, recent research\n(Morcos et al. 2018) presented a counterintuitive phenomenon, which suggests\nthat an individual unit with high class selectivity, called interpretable\nunits, has poor contributions to generalization of DNNs. In this work, we\nprovide a new perspective to understand this counterintuitive phenomenon, which\nmakes sense when we introduce Representative Substitution (RS). Instead of\nindividually selective units with classes, the RS refers to the independence of\na unit's representations in the same layer without any annotation. Our\nexperiments demonstrate that interpretable units have high RS which are not\ncritical to network's generalization. The RS provides new insights into the\ninterpretation of DNNs and suggests that we need to focus on the independence\nand relationship of the representations.\n", "versions": [{"version": "v1", "created": "Sun, 20 Jan 2019 18:49:17 GMT"}], "update_date": "2019-11-14", "authors_parsed": [["Chen", "Li", ""], ["Ding", "Hailun", ""], ["Li", "Qi", ""], ["Li", "Zhuo", ""], ["Peng", "Jian", ""], ["Li", "Haifeng", ""]]}, {"id": "1911.05588", "submitter": "Quanshi Zhang", "authors": "A. Deliege, A. Cioppa and M. Van Droogenbroeck", "title": "An Effective Hit-or-Miss Layer Favoring Feature Interpretation as\n  Learned Prototypes Deformations", "comments": "In AAAI-19 Workshop on Network Interpretability for Deep Learning.\n  Published version of arXiv:1806.06519", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks designed for the task of classification have become a\ncommodity in recent years. Many works target the development of more effective\nnetworks, which results in a complexification of their architectures with more\nlayers, multiple sub-networks, or even the combination of multiple classifiers,\nbut this often comes at the expense of producing uninterpretable black boxes.\nIn this paper, we redesign a simple capsule network to enable it to synthesize\nclass-representative samples, called prototypes, by replacing the last layer\nwith a novel Hit-or-Miss layer. This layer contains activated vectors, called\ncapsules, that we train to hit or miss a fixed target capsule by tailoring a\nspecific centripetal loss function. This possibility allows to develop a data\naugmentation step combining information from the data space and the feature\nspace, resulting in a hybrid data augmentation process. We show that our\nnetwork, named HitNet, is able to reach better performances than those\nreproduced with the initial CapsNet on several datasets, while allowing to\nvisualize the nature of the features extracted as deformations of the\nprototypes, which provides a direct insight into the feature representation\nlearned by the network .\n", "versions": [{"version": "v1", "created": "Sat, 23 Feb 2019 01:28:27 GMT"}], "update_date": "2019-11-14", "authors_parsed": [["Deliege", "A.", ""], ["Cioppa", "A.", ""], ["Van Droogenbroeck", "M.", ""]]}, {"id": "1911.05649", "submitter": "Xin Zhang", "authors": "Songbin Xu, Yang Xue, Xin Zhang, Lianwen Jin", "title": "Air-Writing Translater: A Novel Unsupervised Domain Adaptation Method\n  for Inertia-Trajectory Translation of In-air Handwriting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As a new way of human-computer interaction, inertial sensor based in-air\nhandwriting can provide a natural and unconstrained interaction to express more\ncomplex and richer information in 3D space. However, most of the existing\nin-air handwriting work is mainly focused on handwritten character recognition,\nwhich makes these work suffer from poor readability of inertial signal and lack\nof labeled samples. To address these two problems, we use unsupervised domain\nadaptation method to reconstruct the trajectory of inertial signal and generate\ninertial samples using online handwritten trajectories. In this paper, we\npropose an AirWriting Translater model to learn the bi-directional translation\nbetween trajectory domain and inertial domain in the absence of paired inertial\nand trajectory samples. Through semantic-level adversarial training and latent\nclassification loss, the proposed model learns to extract domain-invariant\ncontent between inertial signal and trajectory, while preserving semantic\nconsistency during the translation across the two domains. We carefully design\nthe architecture, so that the proposed framework can accept inputs of arbitrary\nlength and translate between different sampling rates. We also conduct\nexperiments on two public datasets: 6DMG (in-air handwriting dataset) and CT\n(handwritten trajectory dataset), the results on the two datasets demonstrate\nthat the proposed network successes in both Inertia-to Trajectory and\nTrajectory-to-Inertia translation tasks.\n", "versions": [{"version": "v1", "created": "Fri, 1 Nov 2019 14:09:44 GMT"}], "update_date": "2019-11-14", "authors_parsed": [["Xu", "Songbin", ""], ["Xue", "Yang", ""], ["Zhang", "Xin", ""], ["Jin", "Lianwen", ""]]}, {"id": "1911.05695", "submitter": "Xinwen Hou", "authors": "Pei Yingjun, Hou Xinwen", "title": "Learning Representations in Reinforcement Learning:An Information\n  Bottleneck Approach", "comments": "22 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The information bottleneck principle is an elegant and useful approach to\nrepresentation learning. In this paper, we investigate the problem of\nrepresentation learning in the context of reinforcement learning using the\ninformation bottleneck framework, aiming at improving the sample efficiency of\nthe learning algorithms. %by accelerating the process of discarding irrelevant\ninformation when the %input states are extremely high-dimensional. We\nanalytically derive the optimal conditional distribution of the representation,\nand provide a variational lower bound. Then, we maximize this lower bound with\nthe Stein variational (SV) gradient method. We incorporate this framework in\nthe advantageous actor critic algorithm (A2C) and the proximal policy\noptimization algorithm (PPO). Our experimental results show that our framework\ncan improve the sample efficiency of vanilla A2C and PPO significantly.\nFinally, we study the information bottleneck (IB) perspective in deep RL with\nthe algorithm called mutual information neural estimation(MINE) . We\nexperimentally verify that the information extraction-compression process also\nexists in deep RL and our framework is capable of accelerating this process. We\nalso analyze the relationship between MINE and our method, through this\nrelationship, we theoretically derive an algorithm to optimize our IB framework\nwithout constructing the lower bound.\n", "versions": [{"version": "v1", "created": "Tue, 12 Nov 2019 02:51:55 GMT"}], "update_date": "2019-11-14", "authors_parsed": [["Yingjun", "Pei", ""], ["Xinwen", "Hou", ""]]}, {"id": "1911.05696", "submitter": "Adrien Hadj-Salah", "authors": "Adrien Hadj-Salah, R\\'emi Verdier, Cl\\'ement Caron, Mathieu Picard,\n  Mika\\\"el Capelle", "title": "Schedule Earth Observation satellites with Deep Reinforcement Learning", "comments": null, "journal-ref": "IWPSS 2019, Jul 2019, Berkeley, United States", "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Optical Earth observation satellites acquire images worldwide , covering up\nto several million square kilometers every day. The complexity of scheduling\nacquisitions for such systems increases exponentially when considering the\ninteroperabil-ity of several satellite constellations together with the\nuncertainties from weather forecasts. In order to deliver valid images to\ncustomers as fast as possible, it is crucial to acquire cloud-free images.\nDepending on weather forecasts, up to 50% of images acquired by operational\nsatellites can be trashed due to excessive cloud covers, showing there is room\nfor improvement. We propose an acquisition scheduling approach based on Deep\nReinforcement Learning and experiment on a simplified environment. We find that\nit challenges classical methods relying on human-expert heuristic.\n", "versions": [{"version": "v1", "created": "Tue, 12 Nov 2019 15:28:34 GMT"}], "update_date": "2019-11-14", "authors_parsed": [["Hadj-Salah", "Adrien", ""], ["Verdier", "R\u00e9mi", ""], ["Caron", "Cl\u00e9ment", ""], ["Picard", "Mathieu", ""], ["Capelle", "Mika\u00ebl", ""]]}, {"id": "1911.05698", "submitter": "Zichang Wang", "authors": "Zichang Wang, Haoran Li, Luchen Liu, Haoxian Wu and Ming Zhang", "title": "Predictive Multi-level Patient Representations from Electronic Health\n  Records", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The advent of the Internet era has led to an explosive growth in the\nElectronic Health Records (EHR) in the past decades. The EHR data can be\nregarded as a collection of clinical events, including laboratory results,\nmedication records, physiological indicators, etc, which can be used for\nclinical outcome prediction tasks to support constructions of intelligent\nhealth systems. Learning patient representation from these clinical events for\nthe clinical outcome prediction is an important but challenging step. Most\nrelated studies transform EHR data of a patient into a sequence of clinical\nevents in temporal order and then use sequential models to learn patient\nrepresentations for outcome prediction. However, clinical event sequence\ncontains thousands of event types and temporal dependencies. We further make an\nobservation that clinical events occurring in a short period are not\nconstrained by any temporal order but events in a long term are influenced by\ntemporal dependencies. The multi-scale temporal property makes it difficult for\ntraditional sequential models to capture the short-term co-occurrence and the\nlong-term temporal dependencies in clinical event sequences. In response to the\nabove challenges, this paper proposes a Multi-level Representation Model (MRM).\nMRM first uses a sparse attention mechanism to model the short-term\nco-occurrence, then uses interval-based event pooling to remove redundant\ninformation and reduce sequence length and finally predicts clinical outcomes\nthrough Long Short-Term Memory (LSTM). Experiments on real-world datasets\nindicate that our proposed model largely improves the performance of clinical\noutcome prediction tasks using EHR data.\n", "versions": [{"version": "v1", "created": "Tue, 12 Nov 2019 11:40:12 GMT"}], "update_date": "2019-11-14", "authors_parsed": [["Wang", "Zichang", ""], ["Li", "Haoran", ""], ["Liu", "Luchen", ""], ["Wu", "Haoxian", ""], ["Zhang", "Ming", ""]]}, {"id": "1911.05700", "submitter": "Jiaqi Ma", "authors": "Jiaqi Ma, Qiaozhu Mei", "title": "Graph Representation Learning via Multi-task Knowledge Distillation", "comments": "NeurIPS 2019 GRL Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning on graph structured data has attracted much research\ninterest due to its ubiquity in real world data. However, how to efficiently\nrepresent graph data in a general way is still an open problem. Traditional\nmethods use handcraft graph features in a tabular form but suffer from the\ndefects of domain expertise requirement and information loss. Graph\nrepresentation learning overcomes these defects by automatically learning the\ncontinuous representations from graph structures, but they require abundant\ntraining labels, which are often hard to fulfill for graph-level prediction\nproblems. In this work, we demonstrate that, if available, the domain expertise\nused for designing handcraft graph features can improve the graph-level\nrepresentation learning when training labels are scarce. Specifically, we\nproposed a multi-task knowledge distillation method. By incorporating\nnetwork-theory-based graph metrics as auxiliary tasks, we show on both\nsynthetic and real datasets that the proposed multi-task learning method can\nimprove the prediction performance of the original learning task, especially\nwhen the training data size is small.\n", "versions": [{"version": "v1", "created": "Mon, 11 Nov 2019 03:42:13 GMT"}], "update_date": "2019-11-14", "authors_parsed": [["Ma", "Jiaqi", ""], ["Mei", "Qiaozhu", ""]]}, {"id": "1911.05701", "submitter": "Hankz Hankui Zhuo", "authors": "Junyi Shen, Hankz Hankui Zhuo, Jin Xu, Bin Zhong, Sinno Jialin Pan", "title": "Transfer Value Iteration Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Value iteration networks (VINs) have been demonstrated to have a good\ngeneralization ability for reinforcement learning tasks across similar domains.\nHowever, based on our experiments, a policy learned by VINs still fail to\ngeneralize well on the domain whose action space and feature space are not\nidentical to those in the domain where it is trained. In this paper, we propose\na transfer learning approach on top of VINs, termed Transfer VINs (TVINs), such\nthat a learned policy from a source domain can be generalized to a target\ndomain with only limited training data, even if the source domain and the\ntarget domain have domain-specific actions and features. We empirically verify\nthat our proposed TVINs outperform VINs when the source and the target domains\nhave similar but not identical action and feature spaces. Furthermore, we show\nthat the performance improvement is consistent across different environments,\nmaze sizes, dataset sizes as well as different values of hyperparameters such\nas number of iteration and kernel size.\n", "versions": [{"version": "v1", "created": "Mon, 11 Nov 2019 08:07:49 GMT"}, {"version": "v2", "created": "Wed, 27 Nov 2019 01:55:19 GMT"}], "update_date": "2019-11-28", "authors_parsed": [["Shen", "Junyi", ""], ["Zhuo", "Hankz Hankui", ""], ["Xu", "Jin", ""], ["Zhong", "Bin", ""], ["Pan", "Sinno Jialin", ""]]}, {"id": "1911.05718", "submitter": "Alessandro Corbetta", "authors": "Alessandro Corbetta, Vlado Menkovski, Roberto Benzi, Federico Toschi", "title": "Deep learning velocity signals allows to quantify turbulence intensity", "comments": null, "journal-ref": "Science Advances 7, eaba7281, 2021", "doi": "10.1126/sciadv.aba7281", "report-no": null, "categories": "physics.flu-dyn cond-mat.stat-mech cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Turbulence, the ubiquitous and chaotic state of fluid motions, is\ncharacterized by strong and statistically non-trivial fluctuations of the\nvelocity field, over a wide range of length- and time-scales, and it can be\nquantitatively described only in terms of statistical averages. Strong\nnon-stationarities hinder the possibility to achieve statistical convergence,\nmaking it impossible to define the turbulence intensity and, in particular, its\nbasic dimensionless estimator, the Reynolds number.\n  Here we show that by employing Deep Neural Networks (DNN) we can accurately\nestimate the Reynolds number within $15\\%$ accuracy, from a statistical sample\nas small as two large-scale eddy-turnover times. In contrast, physics-based\nstatistical estimators are limited by the rate of convergence of the central\nlimit theorem, and provide, for the same statistical sample, an error at least\n$100$ times larger. Our findings open up new perspectives in the possibility to\nquantitatively define and, therefore, study highly non-stationary turbulent\nflows as ordinarily found in nature as well as in industrial processes.\n", "versions": [{"version": "v1", "created": "Wed, 13 Nov 2019 18:49:56 GMT"}, {"version": "v2", "created": "Thu, 14 Nov 2019 07:37:49 GMT"}], "update_date": "2021-03-31", "authors_parsed": [["Corbetta", "Alessandro", ""], ["Menkovski", "Vlado", ""], ["Benzi", "Roberto", ""], ["Toschi", "Federico", ""]]}, {"id": "1911.05796", "submitter": "Brian Nord", "authors": "J. Amundson, J. Annis, C. Avestruz, D. Bowring, J. Caldeira, G.\n  Cerati, C. Chang, S. Dodelson, D. Elvira, A. Farahi, K. Genser, L. Gray, O.\n  Gutsche, P. Harris, J. Kinney, J. B. Kowalkowski, R. Kutschke, S. Mrenna, B.\n  Nord, A. Para, K. Pedro, G. N. Perdue, A. Scheinker, P. Spentzouris, J. St.\n  John, N. Tran, S. Trivedi, L. Trouille, W. L. K. Wu, C. R. Bom", "title": "Response to NITRD, NCO, NSF Request for Information on \"Update to the\n  2016 National Artificial Intelligence Research and Development Strategic\n  Plan\"", "comments": null, "journal-ref": null, "doi": null, "report-no": "FERMILAB-FN-1092-SCD", "categories": "astro-ph.IM cs.AI physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a response to the 2018 Request for Information (RFI) from the\nNITRD, NCO, NSF regarding the \"Update to the 2016 National Artificial\nIntelligence Research and Development Strategic Plan.\" Through this document,\nwe provide a response to the question of whether and how the National\nArtificial Intelligence Research and Development Strategic Plan (NAIRDSP)\nshould be updated from the perspective of Fermilab, America's premier national\nlaboratory for High Energy Physics (HEP). We believe the NAIRDSP should be\nextended in light of the rapid pace of development and innovation in the field\nof Artificial Intelligence (AI) since 2016, and present our recommendations\nbelow. AI has profoundly impacted many areas of human life, promising to\ndramatically reshape society --- e.g., economy, education, science --- in the\ncoming years. We are still early in this process. It is critical to invest now\nin this technology to ensure it is safe and deployed ethically. Science and\nsociety both have a strong need for accuracy, efficiency, transparency, and\naccountability in algorithms, making investments in scientific AI particularly\nvaluable. Thus far the US has been a leader in AI technologies, and we believe\nas a national Laboratory it is crucial to help maintain and extend this\nleadership. Moreover, investments in AI will be important for maintaining US\nleadership in the physical sciences.\n", "versions": [{"version": "v1", "created": "Tue, 5 Nov 2019 04:04:25 GMT"}], "update_date": "2019-11-15", "authors_parsed": [["Amundson", "J.", ""], ["Annis", "J.", ""], ["Avestruz", "C.", ""], ["Bowring", "D.", ""], ["Caldeira", "J.", ""], ["Cerati", "G.", ""], ["Chang", "C.", ""], ["Dodelson", "S.", ""], ["Elvira", "D.", ""], ["Farahi", "A.", ""], ["Genser", "K.", ""], ["Gray", "L.", ""], ["Gutsche", "O.", ""], ["Harris", "P.", ""], ["Kinney", "J.", ""], ["Kowalkowski", "J. B.", ""], ["Kutschke", "R.", ""], ["Mrenna", "S.", ""], ["Nord", "B.", ""], ["Para", "A.", ""], ["Pedro", "K.", ""], ["Perdue", "G. N.", ""], ["Scheinker", "A.", ""], ["Spentzouris", "P.", ""], ["John", "J. St.", ""], ["Tran", "N.", ""], ["Trivedi", "S.", ""], ["Trouille", "L.", ""], ["Wu", "W. L. K.", ""], ["Bom", "C. R.", ""]]}, {"id": "1911.05864", "submitter": "De-An Huang", "authors": "De-An Huang, Yu-Wei Chao, Chris Paxton, Xinke Deng, Li Fei-Fei, Juan\n  Carlos Niebles, Animesh Garg, Dieter Fox", "title": "Motion Reasoning for Goal-Based Imitation Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address goal-based imitation learning, where the aim is to output the\nsymbolic goal from a third-person video demonstration. This enables the robot\nto plan for execution and reproduce the same goal in a completely different\nenvironment. The key challenge is that the goal of a video demonstration is\noften ambiguous at the level of semantic actions. The human demonstrators might\nunintentionally achieve certain subgoals in the demonstrations with their\nactions. Our main contribution is to propose a motion reasoning framework that\ncombines task and motion planning to disambiguate the true intention of the\ndemonstrator in the video demonstration. This allows us to robustly recognize\nthe goals that cannot be disambiguated by previous action-based approaches. We\nevaluate our approach by collecting a dataset of 96 video demonstrations in a\nmockup kitchen environment. We show that our motion reasoning plays an\nimportant role in recognizing the actual goal of the demonstrator and improves\nthe success rate by over 20%. We further show that by using the automatically\ninferred goal from the video demonstration, our robot is able to reproduce the\nsame task in a real kitchen environment.\n", "versions": [{"version": "v1", "created": "Wed, 13 Nov 2019 23:59:44 GMT"}], "update_date": "2019-11-15", "authors_parsed": [["Huang", "De-An", ""], ["Chao", "Yu-Wei", ""], ["Paxton", "Chris", ""], ["Deng", "Xinke", ""], ["Fei-Fei", "Li", ""], ["Niebles", "Juan Carlos", ""], ["Garg", "Animesh", ""], ["Fox", "Dieter", ""]]}, {"id": "1911.05876", "submitter": "Jennifer Nelson", "authors": "Jennifer M. Nelson and Rogelio E. Cardona-Rivera", "title": "Partial-Order, Partially-Seen Observations of Fluents or Actions for\n  Plan Recognition as Planning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work aims to make plan recognition as planning more ready for real-world\nscenarios by adapting previous compilations to work with partial-order,\nhalf-seen observations of both fluents and actions. We first redefine what\nobservations can be and what it means to satisfy each kind. We then provide a\ncompilation from plan recognition problem to classical planning problem,\nsimilar to original work by Ramirez and Geffner, but accommodating these more\ncomplex observation types. This compilation can be adapted towards other\nplanning-based plan recognition techniques. Lastly we evaluate this method\nagainst an \"ignore complexity\" strategy that uses the original method by\nRamirez and Geffner. Our experimental results suggest that, while slower, our\nmethod is equally or more accurate than baseline methods; our technique\nsometimes significantly reduces the size of the solution to the plan\nrecognition problem, i.e, the size of the optimal goal set. We discuss these\nfindings in the context of plan recognition problem difficulty and present an\navenue for future work.\n", "versions": [{"version": "v1", "created": "Thu, 14 Nov 2019 00:53:36 GMT"}], "update_date": "2019-11-15", "authors_parsed": [["Nelson", "Jennifer M.", ""], ["Cardona-Rivera", "Rogelio E.", ""]]}, {"id": "1911.05885", "submitter": "Andrew Estornell", "authors": "Andrew Estornell, Sanmay Das, Yevgeniy Vorobeychik", "title": "Deception through Half-Truths", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deception is a fundamental issue across a diverse array of settings, from\ncybersecurity, where decoys (e.g., honeypots) are an important tool, to\npolitics that can feature politically motivated \"leaks\" and fake news about\ncandidates.Typical considerations of deception view it as providing false\ninformation.However, just as important but less frequently studied is a more\ntacit form where information is strategically hidden or leaked.We consider the\nproblem of how much an adversary can affect a principal's decision by\n\"half-truths\", that is, by masking or hiding bits of information, when the\nprincipal is oblivious to the presence of the adversary. The principal's\nproblem can be modeled as one of predicting future states of variables in a\ndynamic Bayes network, and we show that, while theoretically the principal's\ndecisions can be made arbitrarily bad, the optimal attack is NP-hard to\napproximate, even under strong assumptions favoring the attacker. However, we\nalso describe an important special case where the dependency of future states\non past states is additive, in which we can efficiently compute an\napproximately optimal attack. Moreover, in networks with a linear transition\nfunction we can solve the problem optimally in polynomial time.\n", "versions": [{"version": "v1", "created": "Thu, 14 Nov 2019 01:36:05 GMT"}], "update_date": "2019-11-15", "authors_parsed": [["Estornell", "Andrew", ""], ["Das", "Sanmay", ""], ["Vorobeychik", "Yevgeniy", ""]]}, {"id": "1911.05889", "submitter": "Haoyu Song", "authors": "Haoyu Song, Wei-Nan Zhang, Jingwen Hu, Ting Liu", "title": "Generating Persona Consistent Dialogues by Exploiting Natural Language\n  Inference", "comments": "AAAI20. Update code links", "journal-ref": null, "doi": "10.1609/aaai.v34i05.6417", "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Consistency is one of the major challenges faced by dialogue agents. A\nhuman-like dialogue agent should not only respond naturally, but also maintain\na consistent persona. In this paper, we exploit the advantages of natural\nlanguage inference (NLI) technique to address the issue of generating persona\nconsistent dialogues. Different from existing work that re-ranks the retrieved\nresponses through an NLI model, we cast the task as a reinforcement learning\nproblem and propose to exploit the NLI signals from response-persona pairs as\nrewards for the process of dialogue generation. Specifically, our generator\nemploys an attention-based encoder-decoder to generate persona-based responses.\nOur evaluator consists of two components: an adversarially trained naturalness\nmodule and an NLI based consistency module. Moreover, we use another\nwell-performed NLI model in the evaluation of persona-consistency. Experimental\nresults on both human and automatic metrics, including the model-based\nconsistency evaluation, demonstrate that the proposed approach outperforms\nstrong generative baselines, especially in the persona-consistency of generated\nresponses.\n", "versions": [{"version": "v1", "created": "Thu, 14 Nov 2019 01:47:53 GMT"}, {"version": "v2", "created": "Sat, 16 Nov 2019 04:15:30 GMT"}, {"version": "v3", "created": "Mon, 2 Dec 2019 01:47:14 GMT"}, {"version": "v4", "created": "Mon, 22 Mar 2021 06:05:31 GMT"}], "update_date": "2021-03-23", "authors_parsed": [["Song", "Haoyu", ""], ["Zhang", "Wei-Nan", ""], ["Hu", "Jingwen", ""], ["Liu", "Ting", ""]]}, {"id": "1911.05975", "submitter": "Seyed Mostafa Mousavi", "authors": "S.Mostafa Mousavi and Gregory C. Beroza", "title": "A Machine-Learning Approach for Earthquake Magnitude Estimation", "comments": null, "journal-ref": null, "doi": "10.1029/2019GL085976", "report-no": null, "categories": "physics.geo-ph cs.AI cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this study we develop a single-station deep-learning approach for fast and\nreliable estimation of earthquake magnitude directly from raw waveforms. We\ndesign a regressor composed of convolutional and recurrent neural networks that\nis not sensitive to the data normalization, hence waveform amplitude\ninformation can be utilized during the training. Our network can predict\nearthquake magnitudes with an average error close to zero and standard\ndeviation of ~0.2 based on single-station waveforms without instrument response\ncorrection. We test the network for both local and duration magnitude scales\nand show a station-based learning can be an effective approach for improving\nthe performance. The proposed approach has a variety of potential applications\nfrom routine earthquake monitoring to early warning systems.\n", "versions": [{"version": "v1", "created": "Thu, 14 Nov 2019 07:33:49 GMT"}], "update_date": "2020-02-05", "authors_parsed": [["Mousavi", "S. Mostafa", ""], ["Beroza", "Gregory C.", ""]]}, {"id": "1911.06192", "submitter": "Li Zhou", "authors": "Li Zhou and Kevin Small", "title": "Multi-domain Dialogue State Tracking as Dynamic Knowledge Graph Enhanced\n  Question Answering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-domain dialogue state tracking (DST) is a critical component for\nconversational AI systems. The domain ontology (i.e., specification of domains,\nslots, and values) of a conversational AI system is generally incomplete,\nmaking the capability for DST models to generalize to new slots, values, and\ndomains during inference imperative. In this paper, we propose to model\nmulti-domain DST as a question answering problem, referred to as Dialogue State\nTracking via Question Answering (DSTQA). Within DSTQA, each turn generates a\nquestion asking for the value of a (domain, slot) pair, thus making it\nnaturally extensible to unseen domains, slots, and values. Additionally, we use\na dynamically-evolving knowledge graph to explicitly learn relationships\nbetween (domain, slot) pairs. Our model has a 5.80% and 12.21% relative\nimprovement over the current state-of-the-art model on MultiWOZ 2.0 and\nMultiWOZ 2.1 datasets, respectively. Additionally, our model consistently\noutperforms the state-of-the-art model in domain adaptation settings. (Code is\nreleased at https://github.com/alexa/dstqa )\n", "versions": [{"version": "v1", "created": "Thu, 7 Nov 2019 10:00:16 GMT"}, {"version": "v2", "created": "Sat, 20 Jun 2020 21:07:14 GMT"}], "update_date": "2020-06-23", "authors_parsed": [["Zhou", "Li", ""], ["Small", "Kevin", ""]]}, {"id": "1911.06198", "submitter": "Matteo Castiglioni", "authors": "Matteo Castiglioni, Nicola Gatti, Giulia Landriani, Diodato Ferraioli", "title": "Election Manipulation on Social Networks: Seeding, Edge Removal, Edge\n  Addition", "comments": "arXiv admin note: text overlap with arXiv:1902.03779", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We focus on the election manipulation problem through social influence, where\na manipulator exploits a social network to make her most preferred candidate\nwin an election. Influence is due to information in favor of and/or against one\nor multiple candidates, sent by seeds and spreading through the network\naccording to the independent cascade model. We provide a comprehensive study of\nthe election control problem, investigating two forms of manipulations: seeding\nto buy influencers given a social network, and removing or adding edges in the\nsocial network given the seeds and the information sent. In particular, we\nstudy a wide range of cases distinguishing for the number of candidates or the\nkind of information spread over the network. Our main result is positive for\ndemocracy, and it shows that the election manipulation problem is not\naffordable in the worst-case except for trivial classes of instances, even when\none accepts to approximate the margin of victory. In the case of seeding, we\nalso show that the manipulation is hard even if the graph is a line and that a\nlarge class of algorithms, including most of the approaches recently adopted\nfor social-influence problems, fail to compute a bounded approximation even on\nelementary networks, as undirected graphs with every node having a degree at\nmost two or directed trees. In the case of edge removal or addition, our\nhardness results also apply to the basic case of social influence\nmaximization/minimization. In contrast, the hardness of election manipulation\nholds even when the manipulator has an unlimited budget, being allowed to\nremove or add an arbitrary number of edges.\n", "versions": [{"version": "v1", "created": "Thu, 14 Nov 2019 15:49:18 GMT"}, {"version": "v2", "created": "Thu, 27 Feb 2020 10:06:14 GMT"}], "update_date": "2020-03-02", "authors_parsed": [["Castiglioni", "Matteo", ""], ["Gatti", "Nicola", ""], ["Landriani", "Giulia", ""], ["Ferraioli", "Diodato", ""]]}, {"id": "1911.06226", "submitter": "Hugo Gilbert", "authors": "Hugo Gilbert, Tom Portoleau, Olivier Spanjaard", "title": "Beyond Pairwise Comparisons in Social Choice: A Setwise Kemeny\n  Aggregation Problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we advocate the use of setwise contests for aggregating a set\nof input rankings into an output ranking. We propose a generalization of the\nKemeny rule where one minimizes the number of k-wise disagreements instead of\npairwise disagreements (one counts 1 disagreement each time the top choice in a\nsubset of alternatives of cardinality at most k differs between an input\nranking and the output ranking). After an algorithmic study of this k-wise\nKemeny aggregation problem, we introduce a k-wise counterpart of the majority\ngraph. It reveals useful to divide the aggregation problem into several\nsub-problems. We conclude with numerical tests.\n", "versions": [{"version": "v1", "created": "Thu, 14 Nov 2019 16:37:00 GMT"}], "update_date": "2019-11-15", "authors_parsed": [["Gilbert", "Hugo", ""], ["Portoleau", "Tom", ""], ["Spanjaard", "Olivier", ""]]}, {"id": "1911.06263", "submitter": "David Heckerman", "authors": "David Heckerman", "title": "Probabilistic Similarity Networks", "comments": null, "journal-ref": "Probabilistic Similarity Networks. MIT Press, Cambridge, MA, 1991", "doi": null, "report-no": "ISBN 0-262-01114-X", "categories": "cs.AI math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Normative expert systems have not become commonplace because they have been\ndifficult to build and use. Over the past decade, however, researchers have\ndeveloped the influence diagram, a graphical representation of a decision\nmaker's beliefs, alternatives, and preferences that serves as the knowledge\nbase of a normative expert system. Most people who have seen the representation\nfind it intuitive and easy to use. Consequently, the influence diagram has\novercome significantly the barriers to constructing normative expert systems.\nNevertheless, building influence diagrams is not practical for extremely large\nand complex domains. In this book, I address the difficulties associated with\nthe construction of the probabilistic portion of an influence diagram, called a\nknowledge map, belief network, or Bayesian network. I introduce two\nrepresentations that facilitate the generation of large knowledge maps. In\nparticular, I introduce the similarity network, a tool for building the network\nstructure of a knowledge map, and the partition, a tool for assessing the\nprobabilities associated with a knowledge map. I then use these representations\nto build Pathfinder, a large normative expert system for the diagnosis of\nlymph-node diseases (the domain contains over 60 diseases and over 100 disease\nfindings). In an early version of the system, I encoded the knowledge of the\nexpert using an erroneous assumption that all disease findings were\nindependent, given each disease. When the expert and I attempted to build a\nmore accurate knowledge map for the domain that would capture the dependencies\namong the disease findings, we failed. Using a similarity network, however, we\nbuilt the knowledge-map structure for the entire domain in approximately 40\nhours. Furthermore, the partition representation reduced the number of\nprobability assessments required by the expert from 75,000 to 14,000.\n", "versions": [{"version": "v1", "created": "Wed, 6 Nov 2019 20:13:56 GMT"}], "update_date": "2019-11-15", "authors_parsed": [["Heckerman", "David", ""]]}, {"id": "1911.06473", "submitter": "Himabindu Lakkaraju", "authors": "Himabindu Lakkaraju, Osbert Bastani", "title": "\"How do I fool you?\": Manipulating User Trust via Misleading Black Box\n  Explanations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As machine learning black boxes are increasingly being deployed in critical\ndomains such as healthcare and criminal justice, there has been a growing\nemphasis on developing techniques for explaining these black boxes in a human\ninterpretable manner. It has recently become apparent that a high-fidelity\nexplanation of a black box ML model may not accurately reflect the biases in\nthe black box. As a consequence, explanations have the potential to mislead\nhuman users into trusting a problematic black box. In this work, we rigorously\nexplore the notion of misleading explanations and how they influence user trust\nin black-box models. More specifically, we propose a novel theoretical\nframework for understanding and generating misleading explanations, and carry\nout a user study with domain experts to demonstrate how these explanations can\nbe used to mislead users. Our work is the first to empirically establish how\nuser trust in black box models can be manipulated via misleading explanations.\n", "versions": [{"version": "v1", "created": "Fri, 15 Nov 2019 04:20:11 GMT"}], "update_date": "2019-11-18", "authors_parsed": [["Lakkaraju", "Himabindu", ""], ["Bastani", "Osbert", ""]]}, {"id": "1911.06486", "submitter": "Sohini Roychowdhury", "authors": "Sohini Roy Chowdhury, Lars Tornberg, Robin Halvfordsson, Jonatan\n  Nordh, Adam Suhren Gustafsson, Joel Wall, Mattias Westerberg, Adam Wirehed,\n  Louis Tilloy, Zhanying Hu, Haoyuan Tan, Meng Pan and Jonas Sjoberg", "title": "Automated Augmentation with Reinforcement Learning and GANs for Robust\n  Identification of Traffic Signs using Front Camera Images", "comments": "5 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": "IEEE Asilomar SSC 2019", "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traffic sign identification using camera images from vehicles plays a\ncritical role in autonomous driving and path planning. However, the front\ncamera images can be distorted due to blurriness, lighting variations and\nvandalism which can lead to degradation of detection performances. As a\nsolution, machine learning models must be trained with data from multiple\ndomains, and collecting and labeling more data in each new domain is time\nconsuming and expensive. In this work, we present an end-to-end framework to\naugment traffic sign training data using optimal reinforcement learning\npolicies and a variety of Generative Adversarial Network (GAN) models, that can\nthen be used to train traffic sign detector modules. Our automated augmenter\nenables learning from transformed nightime, poor lighting, and varying degrees\nof occlusions using the LISA Traffic Sign and BDD-Nexar dataset. The proposed\nmethod enables mapping training data from one domain to another, thereby\nimproving traffic sign detection precision/recall from 0.70/0.66 to 0.83/0.71\nfor nighttime images.\n", "versions": [{"version": "v1", "created": "Fri, 15 Nov 2019 06:23:50 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Chowdhury", "Sohini Roy", ""], ["Tornberg", "Lars", ""], ["Halvfordsson", "Robin", ""], ["Nordh", "Jonatan", ""], ["Gustafsson", "Adam Suhren", ""], ["Wall", "Joel", ""], ["Westerberg", "Mattias", ""], ["Wirehed", "Adam", ""], ["Tilloy", "Louis", ""], ["Hu", "Zhanying", ""], ["Tan", "Haoyuan", ""], ["Pan", "Meng", ""], ["Sjoberg", "Jonas", ""]]}, {"id": "1911.06537", "submitter": "Graziano Mita", "authors": "Graziano Mita, Paolo Papotti, Maurizio Filippone, Pietro Michiardi", "title": "LIBRE: Learning Interpretable Boolean Rule Ensembles", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel method - LIBRE - to learn an interpretable classifier,\nwhich materializes as a set of Boolean rules. LIBRE uses an ensemble of\nbottom-up weak learners operating on a random subset of features, which allows\nfor the learning of rules that generalize well on unseen data even in\nimbalanced settings. Weak learners are combined with a simple union so that the\nfinal ensemble is also interpretable. Experimental results indicate that LIBRE\nefficiently strikes the right balance between prediction accuracy, which is\ncompetitive with black box methods, and interpretability, which is often\nsuperior to alternative methods from the literature.\n", "versions": [{"version": "v1", "created": "Fri, 15 Nov 2019 09:45:31 GMT"}], "update_date": "2019-11-18", "authors_parsed": [["Mita", "Graziano", ""], ["Papotti", "Paolo", ""], ["Filippone", "Maurizio", ""], ["Michiardi", "Pietro", ""]]}, {"id": "1911.06543", "submitter": "S\\\"oren Schwertfeger", "authors": "S\\\"oren Schwertfeger", "title": "Fine-grained Qualitative Spatial Reasoning about Point Positions", "comments": "Diploma Thesis of S\\\"oren Schwertfeger at University of Bremen.\n  August 2005", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.RO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The ability to persist in the spacial environment is, not only in the robotic\ncontext, an essential feature. Positional knowledge is one of the most\nimportant aspects of space and a number of methods to represent these\ninformation have been developed in the in the research area of spatial\ncognition. The basic qualitative spatial representation and reasoning\ntechniques are presented in this thesis and several calculi are briefly\nreviewed. Features and applications of qualitative calculi are summarized. A\nnew calculus for representing and reasoning about qualitative spatial\norientation and distances is being designed. It supports an arbitrary level of\ngranularity over ternary relations of points. Ways of improving the complexity\nof the composition are shown and an implementation of the calculus demonstrates\nits capabilities. Existing qualitative spatial calculi of positional\ninformation are compared to the new approach and possibilities for future\nresearch are outlined.\n", "versions": [{"version": "v1", "created": "Fri, 15 Nov 2019 09:54:59 GMT"}], "update_date": "2019-11-18", "authors_parsed": [["Schwertfeger", "S\u00f6ren", ""]]}, {"id": "1911.06602", "submitter": "Toby St Clere Smithe", "authors": "Toby B. St Clere Smithe", "title": "Radically Compositional Cognitive Concepts", "comments": "6 pages, 2 figures; NeurIPS 2019 Context and Compositionality\n  workshop. Work in progress", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.AI cs.CL cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Despite ample evidence that our concepts, our cognitive architecture, and\nmathematics itself are all deeply compositional, few models take advantage of\nthis structure. We therefore propose a radically compositional approach to\ncomputational neuroscience, drawing on the methods of applied category theory.\nWe describe how these tools grant us a means to overcome complexity and improve\ninterpretability, and supply a rigorous common language for scientific\nmodelling, analogous to the type theories of computer science. As a case study,\nwe sketch how to translate from compositional narrative concepts to neural\ncircuits and back again.\n", "versions": [{"version": "v1", "created": "Thu, 14 Nov 2019 18:20:36 GMT"}], "update_date": "2019-11-18", "authors_parsed": [["Smithe", "Toby B. St Clere", ""]]}, {"id": "1911.06636", "submitter": "Josh Merel", "authors": "Josh Merel, Saran Tunyasuvunakool, Arun Ahuja, Yuval Tassa, Leonard\n  Hasenclever, Vu Pham, Tom Erez, Greg Wayne, Nicolas Heess", "title": "Catch & Carry: Reusable Neural Controllers for Vision-Guided Whole-Body\n  Tasks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the longstanding challenge of producing flexible, realistic\nhumanoid character controllers that can perform diverse whole-body tasks\ninvolving object interactions. This challenge is central to a variety of\nfields, from graphics and animation to robotics and motor neuroscience. Our\nphysics-based environment uses realistic actuation and first-person perception\n-- including touch sensors and egocentric vision -- with a view to producing\nactive-sensing behaviors (e.g. gaze direction), transferability to real robots,\nand comparisons to the biology. We develop an integrated neural-network based\napproach consisting of a motor primitive module, human demonstrations, and an\ninstructed reinforcement learning regime with curricula and task variations. We\ndemonstrate the utility of our approach for several tasks, including\ngoal-conditioned box carrying and ball catching, and we characterize its\nbehavioral robustness. The resulting controllers can be deployed in real-time\non a standard PC. See overview video, https://youtu.be/2rQAW-8gQQk .\n", "versions": [{"version": "v1", "created": "Fri, 15 Nov 2019 13:57:35 GMT"}, {"version": "v2", "created": "Tue, 16 Jun 2020 09:13:58 GMT"}], "update_date": "2020-06-17", "authors_parsed": [["Merel", "Josh", ""], ["Tunyasuvunakool", "Saran", ""], ["Ahuja", "Arun", ""], ["Tassa", "Yuval", ""], ["Hasenclever", "Leonard", ""], ["Pham", "Vu", ""], ["Erez", "Tom", ""], ["Wayne", "Greg", ""], ["Heess", "Nicolas", ""]]}, {"id": "1911.06643", "submitter": "Andrew Cropper", "authors": "Andrew Cropper", "title": "Forgetting to learn logic programs", "comments": "AAAI20", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most program induction approaches require predefined, often hand-engineered,\nbackground knowledge (BK). To overcome this limitation, we explore methods to\nautomatically acquire BK through multi-task learning. In this approach, a\nlearner adds learned programs to its BK so that they can be reused to help\nlearn other programs. To improve learning performance, we explore the idea of\nforgetting, where a learner can additionally remove programs from its BK. We\nconsider forgetting in an inductive logic programming (ILP) setting. We show\nthat forgetting can significantly reduce both the size of the hypothesis space\nand the sample complexity of an ILP learner. We introduce Forgetgol, a\nmulti-task ILP learner which supports forgetting. We experimentally compare\nForgetgol against approaches that either remember or forget everything. Our\nexperimental results show that Forgetgol outperforms the alternative approaches\nwhen learning from over 10,000 tasks.\n", "versions": [{"version": "v1", "created": "Fri, 15 Nov 2019 14:05:23 GMT"}], "update_date": "2019-11-18", "authors_parsed": [["Cropper", "Andrew", ""]]}, {"id": "1911.06657", "submitter": "Paolo Pareti Dr.", "authors": "Paolo Pareti and George Konstantinidis and Timothy J. Norman", "title": "A Policy Editor for Semantic Sensor Networks", "comments": "Demo paper presented at the 18th International Semantic Web\n  Conference (ISWC 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An important use of sensors and actuator networks is to comply with health\nand safety policies in hazardous environments. In order to deal with\nincreasingly large and dynamic environments, and to quickly react to\nemergencies, tools are needed to simplify the process of translating high-level\npolicies into executable queries and rules. We present a framework to produce\nsuch tools, which uses rules to aggregate low-level sensor data, described\nusing the Semantic Sensor Network Ontology, into more useful and actionable\nabstractions. Using the schema of the underlying data sources as an input, we\nautomatically generate abstractions which are relevant to the use case at hand.\nIn this demonstration we present a policy editor tool and a simulation on which\npolicies can be tested.\n", "versions": [{"version": "v1", "created": "Fri, 15 Nov 2019 14:21:54 GMT"}], "update_date": "2019-11-18", "authors_parsed": [["Pareti", "Paolo", ""], ["Konstantinidis", "George", ""], ["Norman", "Timothy J.", ""]]}, {"id": "1911.06685", "submitter": "Drago Plecko", "authors": "Drago Ple\\v{c}ko, Nicolai Meinshausen", "title": "Fair Data Adaptation with Quantile Preservation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fairness of classification and regression has received much attention\nrecently and various, partially non-compatible, criteria have been proposed.\nThe fairness criteria can be enforced for a given classifier or, alternatively,\nthe data can be adapated to ensure that every classifier trained on the data\nwill adhere to desired fairness criteria. We present a practical data adaption\nmethod based on quantile preservation in causal structural equation models. The\ndata adaptation is based on a presumed counterfactual model for the data. While\nthe counterfactual model itself cannot be verified experimentally, we show that\ncertain population notions of fairness are still guaranteed even if the\ncounterfactual model is misspecified. The precise nature of the fulfilled\nnon-causal fairness notion (such as demographic parity, separation or\nsufficiency) depends on the structure of the underlying causal model and the\nchoice of resolving variables. We describe an implementation of the proposed\ndata adaptation procedure based on Random Forests and demonstrate its practical\nuse on simulated and real-world data.\n", "versions": [{"version": "v1", "created": "Fri, 15 Nov 2019 15:16:24 GMT"}], "update_date": "2019-11-18", "authors_parsed": [["Ple\u010dko", "Drago", ""], ["Meinshausen", "Nicolai", ""]]}, {"id": "1911.06747", "submitter": "Maryam Fazel-Zarandi", "authors": "Maryam Fazel-Zarandi, Sampat Biswas, Ryan Summers, Ahmed Elmalt, Andy\n  McCraw, Michael McPhilips, John Peach", "title": "Towards Personalized Dialog Policies for Conversational Skill Discovery", "comments": "The 3rd Conversational AI workshop - today's practice and tomorrow's\n  potential", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many businesses and consumers are extending the capabilities of voice-based\nservices such as Amazon Alexa, Google Home, Microsoft Cortana, and Apple Siri\nto create custom voice experiences (also known as skills). As the number of\nthese experiences increases, a key problem is the discovery of skills that can\nbe used to address a user's request. In this paper, we focus on conversational\nskill discovery and present a conversational agent which engages in a dialog\nwith users to help them find the skills that fulfill their needs. To this end,\nwe start with a rule-based agent and improve it by using reinforcement\nlearning. In this way, we enable the agent to adapt to different user\nattributes and conversational styles as it interacts with users. We evaluate\nour approach in a real production setting by deploying the agent to interact\nwith real users, and show the effectiveness of the conversational agent in\nhelping users find the skills that serve their request.\n", "versions": [{"version": "v1", "created": "Fri, 15 Nov 2019 16:56:17 GMT"}], "update_date": "2019-11-18", "authors_parsed": [["Fazel-Zarandi", "Maryam", ""], ["Biswas", "Sampat", ""], ["Summers", "Ryan", ""], ["Elmalt", "Ahmed", ""], ["McCraw", "Andy", ""], ["McPhilips", "Michael", ""], ["Peach", "John", ""]]}, {"id": "1911.06832", "submitter": "Kevin Sebastian Luck", "authors": "Kevin Sebastian Luck, Heni Ben Amor, Roberto Calandra", "title": "Data-efficient Co-Adaptation of Morphology and Behaviour with Deep\n  Reinforcement Learning", "comments": "Accepted for the Conference on Robot Learning 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Humans and animals are capable of quickly learning new behaviours to solve\nnew tasks. Yet, we often forget that they also rely on a highly specialized\nmorphology that co-adapted with motor control throughout thousands of years.\nAlthough compelling, the idea of co-adapting morphology and behaviours in\nrobots is often unfeasible because of the long manufacturing times, and the\nneed to re-design an appropriate controller for each morphology. In this paper,\nwe propose a novel approach to automatically and efficiently co-adapt a robot\nmorphology and its controller. Our approach is based on recent advances in deep\nreinforcement learning, and specifically the soft actor critic algorithm. Key\nto our approach is the possibility of leveraging previously tested morphologies\nand behaviors to estimate the performance of new candidate morphologies. As\nsuch, we can make full use of the information available for making more\ninformed decisions, with the ultimate goal of achieving a more data-efficient\nco-adaptation (i.e., reducing the number of morphologies and behaviors tested).\nSimulated experiments show that our approach requires drastically less design\nprototypes to find good morphology-behaviour combinations, making this method\nparticularly suitable for future co-adaptation of robot designs in the real\nworld.\n", "versions": [{"version": "v1", "created": "Fri, 15 Nov 2019 19:01:21 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Luck", "Kevin Sebastian", ""], ["Amor", "Heni Ben", ""], ["Calandra", "Roberto", ""]]}, {"id": "1911.06833", "submitter": "Kevin Sebastian Luck", "authors": "Kevin Sebastian Luck, Mel Vecerik, Simon Stepputtis, Heni Ben Amor,\n  Jonathan Scholz", "title": "Improved Exploration through Latent Trajectory Optimization in Deep\n  Deterministic Policy Gradient", "comments": "Accepted for IROS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Model-free reinforcement learning algorithms such as Deep Deterministic\nPolicy Gradient (DDPG) often require additional exploration strategies,\nespecially if the actor is of deterministic nature. This work evaluates the use\nof model-based trajectory optimization methods used for exploration in Deep\nDeterministic Policy Gradient when trained on a latent image embedding. In\naddition, an extension of DDPG is derived using a value function as critic,\nmaking use of a learned deep dynamics model to compute the policy gradient.\nThis approach leads to a symbiotic relationship between the deep reinforcement\nlearning algorithm and the latent trajectory optimizer. The trajectory\noptimizer benefits from the critic learned by the RL algorithm and the latter\nfrom the enhanced exploration generated by the planner. The developed methods\nare evaluated on two continuous control tasks, one in simulation and one in the\nreal world. In particular, a Baxter robot is trained to perform an insertion\ntask, while only receiving sparse rewards and images as observations from the\nenvironment.\n", "versions": [{"version": "v1", "created": "Fri, 15 Nov 2019 19:01:29 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Luck", "Kevin Sebastian", ""], ["Vecerik", "Mel", ""], ["Stepputtis", "Simon", ""], ["Amor", "Heni Ben", ""], ["Scholz", "Jonathan", ""]]}, {"id": "1911.06854", "submitter": "Cameron Voloshin", "authors": "Cameron Voloshin, Hoang M. Le, Nan Jiang, Yisong Yue", "title": "Empirical Study of Off-Policy Policy Evaluation for Reinforcement\n  Learning", "comments": "Main paper is 8 pages. The appendix contains many pages of tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The disparate experimental conditions in recent off-policy policy evaluation\n(OPE) literature make it difficult both for practitioners to choose a reliable\nestimator for their application domain, as well as for researchers to identify\nfruitful research directions. In this work, we present the first detailed\nempirical study of a broad suite of OPE methods. Based on thousands of\nexperiments and empirical analysis, we offer a summarized set of guidelines to\nadvance the understanding of OPE performance in practice, and suggest\ndirections for future research. Along the way, our empirical findings challenge\nseveral commonly held beliefs about which class of approaches tends to perform\nwell. Our accompanying software implementation serves as a first comprehensive\nbenchmark for OPE.\n", "versions": [{"version": "v1", "created": "Fri, 15 Nov 2019 19:58:42 GMT"}, {"version": "v2", "created": "Tue, 25 Feb 2020 02:24:05 GMT"}], "update_date": "2020-02-26", "authors_parsed": [["Voloshin", "Cameron", ""], ["Le", "Hoang M.", ""], ["Jiang", "Nan", ""], ["Yue", "Yisong", ""]]}, {"id": "1911.06876", "submitter": "Lawrence Phillips", "authors": "Lawrence Phillips, Garrett Goh, Nathan Hodas", "title": "Explanatory Masks for Neural Network Interpretability", "comments": "Presented at IJCAI-18 Workshop on Explainable Artificial Intelligence\n  (XAI)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural network interpretability is a vital component for applications across\na wide variety of domains. In such cases it is often useful to analyze a\nnetwork which has already been trained for its specific purpose. In this work,\nwe develop a method to produce explanation masks for pre-trained networks. The\nmask localizes the most important aspects of each input for prediction of the\noriginal network. Masks are created by a secondary network whose goal is to\ncreate as small an explanation as possible while still preserving the\npredictive accuracy of the original network. We demonstrate the applicability\nof our method for image classification with CNNs, sentiment analysis with RNNs,\nand chemical property prediction with mixed CNN/RNN architectures.\n", "versions": [{"version": "v1", "created": "Fri, 15 Nov 2019 21:10:50 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Phillips", "Lawrence", ""], ["Goh", "Garrett", ""], ["Hodas", "Nathan", ""]]}, {"id": "1911.06893", "submitter": "Ravi Kashyap", "authors": "Ravi Kashyap", "title": "Imitation in the Imitation Game", "comments": "arXiv admin note: substantial text overlap with arXiv:1907.04659,\n  arXiv:1703.08812", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.GT q-fin.GN q-fin.PM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We discuss the objectives of automation equipped with non-trivial decision\nmaking, or creating artificial intelligence, in the financial markets and\nprovide a possible alternative. Intelligence might be an unintended consequence\nof curiosity left to roam free, best exemplified by a frolicking infant. For\nthis unintentional yet welcome aftereffect to set in a foundational list of\nguiding principles needs to be present. A consideration of these requirements\nallows us to propose a test of intelligence for trading programs, on the lines\nof the Turing Test, long the benchmark for intelligent machines. We discuss the\napplication of this methodology to the dilemma in finance, which is whether,\nwhen and how much to Buy, Sell or Hold.\n", "versions": [{"version": "v1", "created": "Sun, 3 Nov 2019 05:07:47 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Kashyap", "Ravi", ""]]}, {"id": "1911.06904", "submitter": "Maxwell Crouse", "authors": "Maxwell Crouse, Ibrahim Abdelaziz, Cristina Cornelio, Veronika Thost,\n  Lingfei Wu, Kenneth Forbus, Achille Fokoue", "title": "Improving Graph Neural Network Representations of Logical Formulae with\n  Subgraph Pooling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.LO cs.SC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in the integration of deep learning with automated theorem\nproving have centered around the representation of logical formulae as inputs\nto deep learning systems. In particular, there has been a growing interest in\nadapting structure-aware neural methods to work with the underlying graph\nrepresentations of logical expressions. While more effective than character and\ntoken-level approaches, graph-based methods have often made representational\ntrade-offs that limited their ability to capture key structural properties of\ntheir inputs. In this work we propose a novel approach for embedding logical\nformulae that is designed to overcome the representational limitations of prior\napproaches. Our architecture works for logics of different expressivity; e.g.,\nfirst-order and higher-order logic. We evaluate our approach on two standard\ndatasets and show that the proposed architecture achieves state-of-the-art\nperformance on both premise selection and proof step classification.\n", "versions": [{"version": "v1", "created": "Fri, 15 Nov 2019 23:12:30 GMT"}, {"version": "v2", "created": "Tue, 11 Feb 2020 21:08:20 GMT"}, {"version": "v3", "created": "Fri, 5 Jun 2020 17:24:50 GMT"}], "update_date": "2020-06-08", "authors_parsed": [["Crouse", "Maxwell", ""], ["Abdelaziz", "Ibrahim", ""], ["Cornelio", "Cristina", ""], ["Thost", "Veronika", ""], ["Wu", "Lingfei", ""], ["Forbus", "Kenneth", ""], ["Fokoue", "Achille", ""]]}, {"id": "1911.06930", "submitter": "Tien Mai", "authors": "Tien Mai and Quoc Phong Nguyen and Kian Hsiang Low and Patrick Jaillet", "title": "Inverse Reinforcement Learning with Missing Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of recovering an expert's reward function with\ninverse reinforcement learning (IRL) when there are missing/incomplete\nstate-action pairs or observations in the demonstrated trajectories. This issue\nof missing trajectory data or information occurs in many situations, e.g., GPS\nsignals from vehicles moving on a road network are intermittent. In this paper,\nwe propose a tractable approach to directly compute the log-likelihood of\ndemonstrated trajectories with incomplete/missing data. Our algorithm is\nefficient in handling a large number of missing segments in the demonstrated\ntrajectories, as it performs the training with incomplete data by solving a\nsequence of systems of linear equations, and the number of such systems to be\nsolved does not depend on the number of missing segments. Empirical evaluation\non a real-world dataset shows that our training algorithm outperforms other\nconventional techniques.\n", "versions": [{"version": "v1", "created": "Sat, 16 Nov 2019 01:17:33 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Mai", "Tien", ""], ["Nguyen", "Quoc Phong", ""], ["Low", "Kian Hsiang", ""], ["Jaillet", "Patrick", ""]]}, {"id": "1911.06962", "submitter": "Komal Teru", "authors": "Komal K. Teru, Etienne Denis, William L. Hamilton", "title": "Inductive Relation Prediction by Subgraph Reasoning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The dominant paradigm for relation prediction in knowledge graphs involves\nlearning and operating on latent representations (i.e., embeddings) of entities\nand relations. However, these embedding-based methods do not explicitly capture\nthe compositional logical rules underlying the knowledge graph, and they are\nlimited to the transductive setting, where the full set of entities must be\nknown during training. Here, we propose a graph neural network based relation\nprediction framework, GraIL, that reasons over local subgraph structures and\nhas a strong inductive bias to learn entity-independent relational semantics.\nUnlike embedding-based models, GraIL is naturally inductive and can generalize\nto unseen entities and graphs after training. We provide theoretical proof and\nstrong empirical evidence that GraIL can represent a useful subset of\nfirst-order logic and show that GraIL outperforms existing rule-induction\nbaselines in the inductive setting. We also demonstrate significant gains\nobtained by ensembling GraIL with various knowledge graph embedding methods in\nthe transductive setting, highlighting the complementary inductive bias of our\nmethod.\n", "versions": [{"version": "v1", "created": "Sat, 16 Nov 2019 05:25:56 GMT"}, {"version": "v2", "created": "Wed, 12 Feb 2020 02:16:11 GMT"}], "update_date": "2020-02-13", "authors_parsed": [["Teru", "Komal K.", ""], ["Denis", "Etienne", ""], ["Hamilton", "William L.", ""]]}, {"id": "1911.06970", "submitter": "Komal Teru", "authors": "Riashat Islam, Komal K. Teru, Deepak Sharma, Joelle Pineau", "title": "Off-Policy Policy Gradient Algorithms by Constraining the State\n  Distribution Shift", "comments": "Accepted at NeurIPS 2019 workshop on Deep Reinforcement Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Off-policy deep reinforcement learning (RL) algorithms are incapable of\nlearning solely from batch offline data without online interactions with the\nenvironment, due to the phenomenon known as \\textit{extrapolation error}. This\nis often due to past data available in the replay buffer that may be quite\ndifferent from the data distribution under the current policy. We argue that\nmost off-policy learning methods fundamentally suffer from a \\textit{state\ndistribution shift} due to the mismatch between the state visitation\ndistribution of the data collected by the behavior and target policies. This\ndata distribution shift between current and past samples can significantly\nimpact the performance of most modern off-policy based policy optimization\nalgorithms. In this work, we first do a systematic analysis of state\ndistribution mismatch in off-policy learning, and then develop a novel\noff-policy policy optimization method to constraint the state distribution\nshift. To do this, we first estimate the state distribution based on features\nof the state, using a density estimator and then develop a novel constrained\noff-policy gradient objective that minimizes the state distribution shift. Our\nexperimental results on continuous control tasks show that minimizing this\ndistribution mismatch can significantly improve performance in most popular\npractical off-policy policy gradient algorithms.\n", "versions": [{"version": "v1", "created": "Sat, 16 Nov 2019 06:00:52 GMT"}, {"version": "v2", "created": "Sun, 1 Dec 2019 05:06:13 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Islam", "Riashat", ""], ["Teru", "Komal K.", ""], ["Sharma", "Deepak", ""], ["Pineau", "Joelle", ""]]}, {"id": "1911.06992", "submitter": "Rundong Wang", "authors": "Rundong Wang, Xu He, Runsheng Yu, Wei Qiu, Bo An, Zinovi Rabinovich", "title": "Learning Efficient Multi-agent Communication: An Information Bottleneck\n  Approach", "comments": "ICML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of the limited-bandwidth communication for\nmulti-agent reinforcement learning, where agents cooperate with the assistance\nof a communication protocol and a scheduler. The protocol and scheduler jointly\ndetermine which agent is communicating what message and to whom. Under the\nlimited bandwidth constraint, a communication protocol is required to generate\ninformative messages. Meanwhile, an unnecessary communication connection should\nnot be established because it occupies limited resources in vain. In this\npaper, we develop an Informative Multi-Agent Communication (IMAC) method to\nlearn efficient communication protocols as well as scheduling. First, from the\nperspective of communication theory, we prove that the limited bandwidth\nconstraint requires low-entropy messages throughout the transmission. Then\ninspired by the information bottleneck principle, we learn a valuable and\ncompact communication protocol and a weight-based scheduler. To demonstrate the\nefficiency of our method, we conduct extensive experiments in various\ncooperative and competitive multi-agent tasks with different numbers of agents\nand different bandwidths. We show that IMAC converges faster and leads to\nefficient communication among agents under the limited bandwidth as compared to\nmany baseline methods.\n", "versions": [{"version": "v1", "created": "Sat, 16 Nov 2019 08:32:49 GMT"}, {"version": "v2", "created": "Tue, 23 Jun 2020 07:55:05 GMT"}], "update_date": "2020-06-24", "authors_parsed": [["Wang", "Rundong", ""], ["He", "Xu", ""], ["Yu", "Runsheng", ""], ["Qiu", "Wei", ""], ["An", "Bo", ""], ["Rabinovich", "Zinovi", ""]]}, {"id": "1911.07027", "submitter": "Yang Yu", "authors": "Tian Xu, Ziniu Li, Yang Yu", "title": "On Value Discrepancy of Imitation Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Imitation learning trains a policy from expert demonstrations. Imitation\nlearning approaches have been designed from various principles, such as\nbehavioral cloning via supervised learning, apprenticeship learning via inverse\nreinforcement learning, and GAIL via generative adversarial learning. In this\npaper, we propose a framework to analyze the theoretical property of imitation\nlearning approaches based on discrepancy propagation analysis. Under the\ninfinite-horizon setting, the framework leads to the value discrepancy of\nbehavioral cloning in an order of O((1-\\gamma)^{-2}). We also show that the\nframework leads to the value discrepancy of GAIL in an order of\nO((1-\\gamma)^{-1}). It implies that GAIL has less compounding errors than\nbehavioral cloning, which is also verified empirically in this paper. To the\nbest of our knowledge, we are the first one to analyze GAIL's performance\ntheoretically. The above results indicate that the proposed framework is a\ngeneral tool to analyze imitation learning approaches. We hope our theoretical\nresults can provide insights for future improvements in imitation learning\nalgorithms.\n", "versions": [{"version": "v1", "created": "Sat, 16 Nov 2019 13:21:39 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Xu", "Tian", ""], ["Li", "Ziniu", ""], ["Yu", "Yang", ""]]}, {"id": "1911.07040", "submitter": "Marcel Gehrke", "authors": "Marcel Gehrke, Ralf M\\\"oller, and Tanya Braun", "title": "Taming Reasoning in Temporal Probabilistic Relational Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Evidence often grounds temporal probabilistic relational models over time,\nwhich makes reasoning infeasible. To counteract groundings over time and to\nkeep reasoning polynomial by restoring a lifted representation, we present\ntemporal approximate merging (TAMe), which incorporates (i) clustering for\ngrouping submodels as well as (ii) statistical significance checks to test the\nfitness of the clustering outcome. In exchange for faster runtimes, TAMe\nintroduces a bounded error that becomes negligible over time. Empirical results\nshow that TAMe significantly improves the runtime performance of inference,\nwhile keeping errors small.\n", "versions": [{"version": "v1", "created": "Sat, 16 Nov 2019 14:51:55 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Gehrke", "Marcel", ""], ["M\u00f6ller", "Ralf", ""], ["Braun", "Tanya", ""]]}, {"id": "1911.07068", "submitter": "Owain Evans", "authors": "Owain Evans", "title": "Sensory Optimization: Neural Networks as a Model for Understanding and\n  Creating Art", "comments": "27 pages. Web version with high-resolution images:\n  https://owainevans.github.io/visual_aesthetics/sensory-optimization.html", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article is about the cognitive science of visual art. Artists create\nphysical artifacts (such as sculptures or paintings) which depict people,\nobjects, and events. These depictions are usually stylized rather than\nphoto-realistic. How is it that humans are able to understand and create\nstylized representations? Does this ability depend on general cognitive\ncapacities or an evolutionary adaptation for art? What role is played by\nlearning and culture?\n  Machine Learning can shed light on these questions. It's possible to train\nconvolutional neural networks (CNNs) to recognize objects without training them\non any visual art. If such CNNs can generalize to visual art (by creating and\nunderstanding stylized representations), then CNNs provide a model for how\nhumans could understand art without innate adaptations or cultural learning. I\nargue that Deep Dream and Style Transfer show that CNNs can create a basic form\nof visual art, and that humans could create art by similar processes. This\nsuggests that artists make art by optimizing for effects on the human\nobject-recognition system. Physical artifacts are optimized to evoke real-world\nobjects for this system (e.g. to evoke people or landscapes) and to serve as\nsuperstimuli for this system.\n", "versions": [{"version": "v1", "created": "Sat, 16 Nov 2019 18:10:00 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Evans", "Owain", ""]]}, {"id": "1911.07084", "submitter": "Scott Fleming", "authors": "Scott L. Fleming, Kuhan Jeyapragasan, Tony Duan, Daisy Ding, Saurabh\n  Gombar, Nigam Shah, Emma Brunskill", "title": "Missingness as Stability: Understanding the Structure of Missingness in\n  Longitudinal EHR data and its Impact on Reinforcement Learning in Healthcare", "comments": "Machine Learning for Health (ML4H) at NeurIPS 2019 - Extended\n  Abstract", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is an emerging trend in the reinforcement learning for healthcare\nliterature. In order to prepare longitudinal, irregularly sampled, clinical\ndatasets for reinforcement learning algorithms, many researchers will resample\nthe time series data to short, regular intervals and use\nlast-observation-carried-forward (LOCF) imputation to fill in these gaps.\nTypically, they will not maintain any explicit information about which values\nwere imputed. In this work, we (1) call attention to this practice and discuss\nits potential implications; (2) propose an alternative representation of the\npatient state that addresses some of these issues; and (3) demonstrate in a\nnovel but representative clinical dataset that our alternative representation\nyields consistently better results for achieving optimal control, as measured\nby off-policy policy evaluation, compared to representations that do not\nincorporate missingness information.\n", "versions": [{"version": "v1", "created": "Sat, 16 Nov 2019 19:40:23 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Fleming", "Scott L.", ""], ["Jeyapragasan", "Kuhan", ""], ["Duan", "Tony", ""], ["Ding", "Daisy", ""], ["Gombar", "Saurabh", ""], ["Shah", "Nigam", ""], ["Brunskill", "Emma", ""]]}, {"id": "1911.07109", "submitter": "Xiaojian Ma", "authors": "Mingxuan Jing, Xiaojian Ma, Wenbing Huang, Fuchun Sun, Chao Yang, Bin\n  Fang, Huaping Liu", "title": "Reinforcement Learning from Imperfect Demonstrations under Soft Expert\n  Guidance", "comments": "Accepted to AAAI 2020. Xiaojian Ma and Mingxuan Jing contributed\n  equally to this work", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study Reinforcement Learning from Demonstrations (RLfD)\nthat improves the exploration efficiency of Reinforcement Learning (RL) by\nproviding expert demonstrations. Most of existing RLfD methods require\ndemonstrations to be perfect and sufficient, which yet is unrealistic to meet\nin practice. To work on imperfect demonstrations, we first define an imperfect\nexpert setting for RLfD in a formal way, and then point out that previous\nmethods suffer from two issues in terms of optimality and convergence,\nrespectively. Upon the theoretical findings we have derived, we tackle these\ntwo issues by regarding the expert guidance as a soft constraint on regulating\nthe policy exploration of the agent, which eventually leads to a constrained\noptimization problem. We further demonstrate that such problem is able to be\naddressed efficiently by performing a local linear search on its dual form.\nConsiderable empirical evaluations on a comprehensive collection of benchmarks\nindicate our method attains consistent improvement over other RLfD\ncounterparts.\n", "versions": [{"version": "v1", "created": "Sat, 16 Nov 2019 22:33:38 GMT"}, {"version": "v2", "created": "Sat, 23 Nov 2019 23:22:09 GMT"}], "update_date": "2019-11-26", "authors_parsed": [["Jing", "Mingxuan", ""], ["Ma", "Xiaojian", ""], ["Huang", "Wenbing", ""], ["Sun", "Fuchun", ""], ["Yang", "Chao", ""], ["Fang", "Bin", ""], ["Liu", "Huaping", ""]]}, {"id": "1911.07116", "submitter": "Ruoxi Jia", "authors": "Min Du, Ruoxi Jia, Dawn Song", "title": "Robust Anomaly Detection and Backdoor Attack Detection Via Differential\n  Privacy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Outlier detection and novelty detection are two important topics for anomaly\ndetection. Suppose the majority of a dataset are drawn from a certain\ndistribution, outlier detection and novelty detection both aim to detect data\nsamples that do not fit the distribution. Outliers refer to data samples within\nthis dataset, while novelties refer to new samples. In the meantime, backdoor\npoisoning attacks for machine learning models are achieved through injecting\npoisoning samples into the training dataset, which could be regarded as\n\"outliers\" that are intentionally added by attackers. Differential privacy has\nbeen proposed to avoid leaking any individual's information, when aggregated\nanalysis is performed on a given dataset. It is typically achieved by adding\nrandom noise, either directly to the input dataset, or to intermediate results\nof the aggregation mechanism. In this paper, we demonstrate that applying\ndifferential privacy can improve the utility of outlier detection and novelty\ndetection, with an extension to detect poisoning samples in backdoor attacks.\nWe first present a theoretical analysis on how differential privacy helps with\nthe detection, and then conduct extensive experiments to validate the\neffectiveness of differential privacy in improving outlier detection, novelty\ndetection, and backdoor attack detection.\n", "versions": [{"version": "v1", "created": "Sat, 16 Nov 2019 23:32:20 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Du", "Min", ""], ["Jia", "Ruoxi", ""], ["Song", "Dawn", ""]]}, {"id": "1911.07125", "submitter": "Fabian Filipp", "authors": "Fabian V. Filipp", "title": "Opportunities for artificial intelligence in advancing precision\n  medicine", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG q-bio.BM q-bio.GN q-bio.MN", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Machine learning (ML), deep learning (DL), and artificial intelligence (AI)\nare of increasing importance in biomedicine. The goal of this work is to show\nprogress in ML in digital health, to exemplify future needs and trends, and to\nidentify any essential prerequisites of AI and ML for precision health.\nHigh-throughput technologies are delivering growing volumes of biomedical data,\nsuch as large-scale genome-wide sequencing assays, libraries of medical images,\nor drug perturbation screens of healthy, developing, and diseased tissue.\nMulti-omics data in biomedicine is deep and complex, offering an opportunity\nfor data-driven insights and automated disease classification. Learning from\nthese data will open our understanding and definition of healthy baselines and\ndisease signatures. State-of-the-art applications of deep neural networks\ninclude digital image recognition, single cell clustering, and virtual drug\nscreens, demonstrating breadths and power of ML in biomedicine. Significantly,\nAI and systems biology have embraced big data challenges and may enable novel\nbiotechnology-derived therapies to facilitate the implementation of precision\nmedicine approaches.\n", "versions": [{"version": "v1", "created": "Sun, 17 Nov 2019 01:29:54 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Filipp", "Fabian V.", ""]]}, {"id": "1911.07141", "submitter": "Ricky Loynd", "authors": "Ricky Loynd, Roland Fernandez, Asli Celikyilmaz, Adith Swaminathan and\n  Matthew Hausknecht", "title": "Working Memory Graphs", "comments": "11 pages, 6 figures, 7 page appendix", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transformers have increasingly outperformed gated RNNs in obtaining new\nstate-of-the-art results on supervised tasks involving text sequences. Inspired\nby this trend, we study the question of how Transformer-based models can\nimprove the performance of sequential decision-making agents. We present the\nWorking Memory Graph (WMG), an agent that employs multi-head self-attention to\nreason over a dynamic set of vectors representing observed and recurrent state.\nWe evaluate WMG in three environments featuring factored observation spaces: a\nPathfinding environment that requires complex reasoning over past observations,\nBabyAI gridworld levels that involve variable goals, and Sokoban which\nemphasizes future planning. We find that the combination of WMG's\nTransformer-based architecture with factored observation spaces leads to\nsignificant gains in learning efficiency compared to baseline architectures\nacross all tasks. WMG demonstrates how Transformer-based models can\ndramatically boost sample efficiency in RL environments for which observations\ncan be factored.\n", "versions": [{"version": "v1", "created": "Sun, 17 Nov 2019 03:14:02 GMT"}, {"version": "v2", "created": "Thu, 20 Feb 2020 02:09:20 GMT"}, {"version": "v3", "created": "Wed, 8 Jul 2020 16:51:20 GMT"}, {"version": "v4", "created": "Tue, 18 Aug 2020 15:56:25 GMT"}], "update_date": "2020-08-19", "authors_parsed": [["Loynd", "Ricky", ""], ["Fernandez", "Roland", ""], ["Celikyilmaz", "Asli", ""], ["Swaminathan", "Adith", ""], ["Hausknecht", "Matthew", ""]]}, {"id": "1911.07147", "submitter": "Kui Yu", "authors": "Kui Yu, Xianjie Guo, Lin Liu, Jiuyong Li, Hao Wang, Zhaolong Ling,\n  Xindong Wu", "title": "Causality-based Feature Selection: Methods and Evaluations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Feature selection is a crucial preprocessing step in data analytics and\nmachine learning. Classical feature selection algorithms select features based\non the correlations between predictive features and the class variable and do\nnot attempt to capture causal relationships between them. It has been shown\nthat the knowledge about the causal relationships between features and the\nclass variable has potential benefits for building interpretable and robust\nprediction models, since causal relationships imply the underlying mechanism of\na system. Consequently, causality-based feature selection has gradually\nattracted greater attentions and many algorithms have been proposed. In this\npaper, we present a comprehensive review of recent advances in causality-based\nfeature selection. To facilitate the development of new algorithms in the\nresearch area and make it easy for the comparisons between new methods and\nexisting ones, we develop the first open-source package, called CausalFS, which\nconsists of most of the representative causality-based feature selection\nalgorithms (available at https://github.com/kuiy/CausalFS). Using CausalFS, we\nconduct extensive experiments to compare the representative algorithms with\nboth synthetic and real-world data sets. Finally, we discuss some challenging\nproblems to be tackled in future causality-based feature selection research.\n", "versions": [{"version": "v1", "created": "Sun, 17 Nov 2019 03:49:39 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Yu", "Kui", ""], ["Guo", "Xianjie", ""], ["Liu", "Lin", ""], ["Li", "Jiuyong", ""], ["Wang", "Hao", ""], ["Ling", "Zhaolong", ""], ["Wu", "Xindong", ""]]}, {"id": "1911.07229", "submitter": "Cosimo Persia", "authors": "Ana Ozaki, Cosimo Persia, Andrea Mazzullo", "title": "Learning Query Inseparable ELH Ontologies", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the complexity of learning query inseparable ELH ontologies in\na variant of Angluin's exact learning model. Given a fixed data instance A* and\na query language Q, we are interested in computing an ontology H that entails\nthe same queries as a target ontology T on A*, that is, H and T are inseparable\nw.r.t. A* and Q. The learner is allowed to pose two kinds of questions. The\nfirst is `Does (T,A)\\models q?', with A an arbitrary data instance and q and\nquery in Q. An oracle replies this question with `yes' or `no'. In the second,\nthe learner asks `Are H and T inseparable w.r.t. A* and Q?'. If so, the\nlearning process finishes, otherwise, the learner receives (A*,q) with q in Q,\n(T,A*)\\models q and (H,A*)\\not\\models q (or vice-versa). Then, we analyse\nconditions in which query inseparability is preserved if A* changes. Finally,\nwe consider the PAC learning model and a setting where the algorithms learn\nfrom a batch of classified data, limiting interactions with the oracles.\n", "versions": [{"version": "v1", "created": "Sun, 17 Nov 2019 13:05:38 GMT"}, {"version": "v2", "created": "Thu, 21 Nov 2019 09:38:02 GMT"}, {"version": "v3", "created": "Sun, 17 May 2020 15:59:24 GMT"}, {"version": "v4", "created": "Wed, 17 Jun 2020 10:54:13 GMT"}, {"version": "v5", "created": "Thu, 18 Jun 2020 06:53:13 GMT"}], "update_date": "2020-06-19", "authors_parsed": [["Ozaki", "Ana", ""], ["Persia", "Cosimo", ""], ["Mazzullo", "Andrea", ""]]}, {"id": "1911.07246", "submitter": "Youngwoon Lee", "authors": "Youngwoon Lee, Edward S. Hu, Zhengyu Yang, Alex Yin, and Joseph J. Lim", "title": "IKEA Furniture Assembly Environment for Long-Horizon Complex\n  Manipulation Tasks", "comments": "Simulator", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The IKEA Furniture Assembly Environment is one of the first benchmarks for\ntesting and accelerating the automation of complex manipulation tasks. The\nenvironment is designed to advance reinforcement learning from simple toy tasks\nto complex tasks requiring both long-term planning and sophisticated low-level\ncontrol. Our environment supports over 80 different furniture models, Sawyer\nand Baxter robot simulation, and domain randomization. The IKEA Furniture\nAssembly Environment is a testbed for methods aiming to solve complex\nmanipulation tasks. The environment is publicly available at\nhttps://clvrai.com/furniture\n", "versions": [{"version": "v1", "created": "Sun, 17 Nov 2019 14:32:20 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Lee", "Youngwoon", ""], ["Hu", "Edward S.", ""], ["Yang", "Zhengyu", ""], ["Yin", "Alex", ""], ["Lim", "Joseph J.", ""]]}, {"id": "1911.07318", "submitter": "Parisa Zehtabi", "authors": "Michael Cashmore, Alessandro Cimatti, Daniele Magazzeni, Andrea\n  Micheli, Parisa Zehtabi", "title": "Towards Efficient Anytime Computation and Execution of Decoupled\n  Robustness Envelopes for Temporal Plans", "comments": "8 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the major limitations for the employment of model-based planning and\nscheduling in practical applications is the need of costly re-planning when an\nincongruence between the observed reality and the formal model is encountered\nduring execution. Robustness Envelopes characterize the set of possible\ncontingencies that a plan is able to address without re-planning, but their\nexact computation is extremely expensive; furthermore, general robustness\nenvelopes are not amenable for efficient execution. In this paper, we present a\nnovel, anytime algorithm to approximate Robustness Envelopes, making them\nscalable and executable. This is proven by an experimental analysis showing the\nefficiency of the algorithm, and by a concrete case study where the execution\nof robustness envelopes significantly reduces the number of re-plannings.\n", "versions": [{"version": "v1", "created": "Sun, 17 Nov 2019 19:09:22 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Cashmore", "Michael", ""], ["Cimatti", "Alessandro", ""], ["Magazzeni", "Daniele", ""], ["Micheli", "Andrea", ""], ["Zehtabi", "Parisa", ""]]}, {"id": "1911.07405", "submitter": "Qiang Huang Huang", "authors": "Qiang Huang, Jianhui Bu, Weijian Xie, Shengwen Yang, Weijia Wu, Liping\n  Liu", "title": "Multi-task Sentence Encoding Model for Semantic Retrieval in Question\n  Answering Systems", "comments": "IJCNN 2019 - International Joint Conference on Neural Networks,\n  Budapest Hungary, 14-19 July 2019", "journal-ref": null, "doi": null, "report-no": "paper N-20437.pdf", "categories": "cs.CL cs.AI cs.IR", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Question Answering (QA) systems are used to provide proper responses to\nusers' questions automatically. Sentence matching is an essential task in the\nQA systems and is usually reformulated as a Paraphrase Identification (PI)\nproblem. Given a question, the aim of the task is to find the most similar\nquestion from a QA knowledge base. In this paper, we propose a Multi-task\nSentence Encoding Model (MSEM) for the PI problem, wherein a connected graph is\nemployed to depict the relation between sentences, and a multi-task learning\nmodel is applied to address both the sentence matching and sentence intent\nclassification problem. In addition, we implement a general semantic retrieval\nframework that combines our proposed model and the Approximate Nearest Neighbor\n(ANN) technology, which enables us to find the most similar question from all\navailable candidates very quickly during online serving. The experiments show\nthe superiority of our proposed method as compared with the existing sentence\nmatching models.\n", "versions": [{"version": "v1", "created": "Mon, 18 Nov 2019 03:11:36 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Huang", "Qiang", ""], ["Bu", "Jianhui", ""], ["Xie", "Weijian", ""], ["Yang", "Shengwen", ""], ["Wu", "Weijia", ""], ["Liu", "Liping", ""]]}, {"id": "1911.07421", "submitter": "Xiaofeng Liu", "authors": "Tong Che, Xiaofeng Liu, Site Li, Yubin Ge, Ruixiang Zhang, Caiming\n  Xiong, Yoshua Bengio", "title": "Deep Verifier Networks: Verification of Deep Discriminative Models with\n  Deep Generative Models", "comments": "Accepted to AAAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  AI Safety is a major concern in many deep learning applications such as\nautonomous driving. Given a trained deep learning model, an important natural\nproblem is how to reliably verify the model's prediction. In this paper, we\npropose a novel framework -- deep verifier networks (DVN) to verify the inputs\nand outputs of deep discriminative models with deep generative models. Our\nproposed model is based on conditional variational auto-encoders with\ndisentanglement constraints. We give both intuitive and theoretical\njustifications of the model. Our verifier network is trained independently with\nthe prediction model, which eliminates the need of retraining the verifier\nnetwork for a new model. We test the verifier network on out-of-distribution\ndetection and adversarial example detection problems, as well as anomaly\ndetection problems in structured prediction tasks such as image caption\ngeneration. We achieve state-of-the-art results in all of these problems.\n", "versions": [{"version": "v1", "created": "Mon, 18 Nov 2019 04:23:12 GMT"}, {"version": "v2", "created": "Sat, 8 Feb 2020 03:10:15 GMT"}, {"version": "v3", "created": "Fri, 1 Jan 2021 21:08:11 GMT"}], "update_date": "2021-01-05", "authors_parsed": [["Che", "Tong", ""], ["Liu", "Xiaofeng", ""], ["Li", "Site", ""], ["Ge", "Yubin", ""], ["Zhang", "Ruixiang", ""], ["Xiong", "Caiming", ""], ["Bengio", "Yoshua", ""]]}, {"id": "1911.07470", "submitter": "Deng Cai", "authors": "Deng Cai and Wai Lam", "title": "Graph Transformer for Graph-to-Sequence Learning", "comments": "accepted by AAAI2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The dominant graph-to-sequence transduction models employ graph neural\nnetworks for graph representation learning, where the structural information is\nreflected by the receptive field of neurons. Unlike graph neural networks that\nrestrict the information exchange between immediate neighborhood, we propose a\nnew model, known as Graph Transformer, that uses explicit relation encoding and\nallows direct communication between two distant nodes. It provides a more\nefficient way for global graph structure modeling. Experiments on the\napplications of text generation from Abstract Meaning Representation (AMR) and\nsyntax-based neural machine translation show the superiority of our proposed\nmodel. Specifically, our model achieves 27.4 BLEU on LDC2015E86 and 29.7 BLEU\non LDC2017T10 for AMR-to-text generation, outperforming the state-of-the-art\nresults by up to 2.2 points. On the syntax-based translation tasks, our model\nestablishes new single-model state-of-the-art BLEU scores, 21.3 for\nEnglish-to-German and 14.1 for English-to-Czech, improving over the existing\nbest results, including ensembles, by over 1 BLEU.\n", "versions": [{"version": "v1", "created": "Mon, 18 Nov 2019 07:45:19 GMT"}, {"version": "v2", "created": "Sat, 30 Nov 2019 12:49:24 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Cai", "Deng", ""], ["Lam", "Wai", ""]]}, {"id": "1911.07532", "submitter": "Michael Poli", "authors": "Michael Poli, Stefano Massaroli, Junyoung Park, Atsushi Yamashita,\n  Hajime Asama, Jinkyoo Park", "title": "Graph Neural Ordinary Differential Equations", "comments": "Accepted [Spotlight] at the AAAI workshop DLGMA20. For the extended\n  version, see \"Continuous-Depth Neural Models for Dynamic Graph Prediction\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce the framework of continuous--depth graph neural networks (GNNs).\nGraph neural ordinary differential equations (GDEs) are formalized as the\ncounterpart to GNNs where the input-output relationship is determined by a\ncontinuum of GNN layers, blending discrete topological structures and\ndifferential equations. The proposed framework is shown to be compatible with\nvarious static and autoregressive GNN models. Results prove general\neffectiveness of GDEs: in static settings they offer computational advantages\nby incorporating numerical methods in their forward pass; in dynamic settings,\non the other hand, they are shown to improve performance by exploiting the\ngeometry of the underlying dynamics.\n", "versions": [{"version": "v1", "created": "Mon, 18 Nov 2019 10:46:15 GMT"}, {"version": "v2", "created": "Sat, 15 Feb 2020 06:18:16 GMT"}, {"version": "v3", "created": "Tue, 16 Jun 2020 05:40:32 GMT"}, {"version": "v4", "created": "Tue, 22 Jun 2021 07:40:01 GMT"}], "update_date": "2021-06-23", "authors_parsed": [["Poli", "Michael", ""], ["Massaroli", "Stefano", ""], ["Park", "Junyoung", ""], ["Yamashita", "Atsushi", ""], ["Asama", "Hajime", ""], ["Park", "Jinkyoo", ""]]}, {"id": "1911.07585", "submitter": "Valentina Anita Carriero", "authors": "Valentina Anita Carriero and Aldo Gangemi and Maria Letizia Mancinelli\n  and Andrea Giovanni Nuzzolese and Valentina Presutti and Chiara Veninata", "title": "Pattern-based design applied to cultural heritage knowledge graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CY cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ontology Design Patterns (ODPs) have become an established and recognised\npractice for guaranteeing good quality ontology engineering. There are several\nODP repositories where ODPs are shared as well as ontology design methodologies\nrecommending their reuse. Performing rigorous testing is recommended as well\nfor supporting ontology maintenance and validating the resulting resource\nagainst its motivating requirements. Nevertheless, it is less than\nstraightforward to find guidelines on how to apply such methodologies for\ndeveloping domain-specific knowledge graphs. ArCo is the knowledge graph of\nItalian Cultural Heritage and has been developed by using eXtreme Design (XD),\nan ODP- and test-driven methodology. During its development, XD has been\nadapted to the need of the CH domain e.g. gathering requirements from an open,\ndiverse community of consumers, a new ODP has been defined and many have been\nspecialised to address specific CH requirements. This paper presents ArCo and\ndescribes how to apply XD to the development and validation of a CH knowledge\ngraph, also detailing the (intellectual) process implemented for matching the\nencountered modelling problems to ODPs. Relevant contributions also include a\nnovel web tool for supporting unit-testing of knowledge graphs, a rigorous\nevaluation of ArCo, and a discussion of methodological lessons learned during\nArCo development.\n", "versions": [{"version": "v1", "created": "Mon, 18 Nov 2019 12:33:33 GMT"}, {"version": "v2", "created": "Sat, 20 Jun 2020 08:51:59 GMT"}], "update_date": "2020-06-23", "authors_parsed": [["Carriero", "Valentina Anita", ""], ["Gangemi", "Aldo", ""], ["Mancinelli", "Maria Letizia", ""], ["Nuzzolese", "Andrea Giovanni", ""], ["Presutti", "Valentina", ""], ["Veninata", "Chiara", ""]]}, {"id": "1911.07588", "submitter": "Takuma Udagawa", "authors": "Takuma Udagawa, Akiko Aizawa", "title": "An Annotated Corpus of Reference Resolution for Interpreting Common\n  Grounding", "comments": "9 pages, 7 figures, 6 tables, Accepted by AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Common grounding is the process of creating, repairing and updating mutual\nunderstandings, which is a fundamental aspect of natural language conversation.\nHowever, interpreting the process of common grounding is a challenging task,\nespecially under continuous and partially-observable context where complex\nambiguity, uncertainty, partial understandings and misunderstandings are\nintroduced. Interpretation becomes even more challenging when we deal with\ndialogue systems which still have limited capability of natural language\nunderstanding and generation. To address this problem, we consider reference\nresolution as the central subtask of common grounding and propose a new\nresource to study its intermediate process. Based on a simple and general\nannotation schema, we collected a total of 40,172 referring expressions in\n5,191 dialogues curated from an existing corpus, along with multiple judgements\nof referent interpretations. We show that our annotation is highly reliable,\ncaptures the complexity of common grounding through a natural degree of\nreasonable disagreements, and allows for more detailed and quantitative\nanalyses of common grounding strategies. Finally, we demonstrate the advantages\nof our annotation for interpreting, analyzing and improving common grounding in\nbaseline dialogue systems.\n", "versions": [{"version": "v1", "created": "Mon, 18 Nov 2019 12:41:25 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Udagawa", "Takuma", ""], ["Aizawa", "Akiko", ""]]}, {"id": "1911.07605", "submitter": "Antonino Sabetta", "authors": "Roc\\`io Cabrera Lozoya, Arnaud Baumann, Antonino Sabetta, Michele\n  Bezzi", "title": "Commit2Vec: Learning Distributed Representations of Code Changes", "comments": "A previous version of this paper had the following title: \"patch2vec:\n  Distributed Representation of Code Changes\"; we updated the title to avoid\n  confusion with another approach, also called patch2vec, that we found in the\n  meantime and that is used in the domain of image processing", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning methods, which have found successful applications in fields\nlike image classification and natural language processing, have recently been\napplied to source code analysis too, due to the enormous amount of freely\navailable source code (e.g., from open-source software repositories).\n  In this work, we elaborate upon a state-of-the-art approach to the\nrepresentation of source code that uses information about its syntactic\nstructure, and we adapt it to represent source changes (i.e., commits). We use\nthis representation to classify security-relevant commits.\n  Because our method uses transfer learning (that is, we train a network on a\n\"pretext task\" for which abundant labeled data is available, and then we use\nsuch network for the target task of commit classification, for which fewer\nlabeled instances are available), we studied the impact of pre-training the\nnetwork using two different pretext tasks versus a randomly initialized model.\n  Our results indicate that representations that leverage the structural\ninformation obtained through code syntax outperform token-based\nrepresentations. Furthermore, the performance metrics obtained when\npre-training on a loosely related pretext task with a very large dataset\n($>10^6$ samples) were surpassed when pretraining on a smaller dataset ($>10^4$\nsamples) but for a pretext task that is more closely related to the target\ntask.\n", "versions": [{"version": "v1", "created": "Mon, 18 Nov 2019 13:23:57 GMT"}, {"version": "v2", "created": "Tue, 19 Nov 2019 15:02:03 GMT"}, {"version": "v3", "created": "Wed, 20 Nov 2019 09:55:48 GMT"}], "update_date": "2019-11-21", "authors_parsed": [["Lozoya", "Roc\u00eco Cabrera", ""], ["Baumann", "Arnaud", ""], ["Sabetta", "Antonino", ""], ["Bezzi", "Michele", ""]]}, {"id": "1911.07629", "submitter": "Atul Sahay", "authors": "Atul Sahay, Smita Gholkar, Kavi Arya", "title": "Selection-based Question Answering of an MOOC", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  e-Yantra Robotics Competition (eYRC) is a unique Robotics Competition hosted\nby IIT Bombay that is actually an Embedded Systems and Robotics MOOC.\nRegistrations have been growing exponentially in each year from 4500 in 2012 to\nover 34000 in 2019. In this 5-month long competition students learn complex\nskills under severe time pressure and have access to a discussion forum to post\ndoubts about the learning material. Responding to questions in real-time is a\nchallenge for project staff. Here, we illustrate the advantage of Deep Learning\nfor real-time question answering in the eYRC discussion forum. We illustrate\nthe advantage of Transformer based contextual embedding mechanisms such as\nBidirectional Encoder Representation From Transformer (BERT) over word\nembedding mechanisms such as Word2Vec. We propose a weighted similarity metric\nas a measure of matching and find it more reliable than Content-Content or\nTitle-Title similarities alone. The automation of replying to questions has\nbrought the turn around response time(TART) down from a minimum of 21 mins to a\nminimum of 0.3 secs.\n", "versions": [{"version": "v1", "created": "Fri, 15 Nov 2019 09:20:32 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Sahay", "Atul", ""], ["Gholkar", "Smita", ""], ["Arya", "Kavi", ""]]}, {"id": "1911.07673", "submitter": "Fabrizio Orlandi", "authors": "Ademar Crotti Junior and Fabrizio Orlandi and Declan O'Sullivan and\n  Christian Dirschl and Quentin Reul", "title": "Using Mapping Languages for Building Legal Knowledge Graphs from XML\n  Files", "comments": "Presented at the 2nd International Contextualized Knowledge Graphs\n  Workshop (CKG'19) at the 18th International Semantic Web Conference (ISWC)\n  2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.AI cs.IR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper presents our experience on building RDF knowledge graphs for an\nindustrial use case in the legal domain. The information contained in legal\ninformation systems are often accessed through simple keyword interfaces and\npresented as a simple list of hits. In order to improve search accuracy one may\navail of knowledge graphs, where the semantics of the data can be made\nexplicit. Significant research effort has been invested in the area of building\nknowledge graphs from semi-structured text documents, such as XML, with the\nprevailing approach being the use of mapping languages. In this paper, we\npresent a semantic model for representing legal documents together with an\nindustrial use case. We also present a set of use case requirements based on\nthe proposed semantic model, which are used to compare and discuss the use of\nstate-of-the-art mapping languages for building knowledge graphs for legal\ndata.\n", "versions": [{"version": "v1", "created": "Mon, 18 Nov 2019 14:50:31 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Junior", "Ademar Crotti", ""], ["Orlandi", "Fabrizio", ""], ["O'Sullivan", "Declan", ""], ["Dirschl", "Christian", ""], ["Reul", "Quentin", ""]]}, {"id": "1911.07690", "submitter": "M. Hadi Amini", "authors": "Ahmed Imteaj, M. Hadi Amini, Javad Mohammadi", "title": "Leveraging Decentralized Artificial Intelligence to Enhance Resilience\n  of Energy Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.DC cs.MA math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper reintroduces the notion of resilience in the context of recent\nissues originated from climate change triggered events including severe\nhurricanes and wildfires. A recent example is PG&E's forced power outage to\ncontain wildfire risk which led to widespread power disruption. This paper\nfocuses on answering two questions: who is responsible for resilience? and how\nto quantify the monetary value of resilience? To this end, we first provide\npreliminary definitions of resilience for power systems. We then investigate\nthe role of natural hazards, especially wildfire, on power system resilience.\nFinally, we will propose a decentralized strategy for a resilient management\nsystem using distributed storage and demand response resources. Our proposed\nhigh fidelity model provides utilities, operators, and policymakers with a\nclearer picture for strategic decision making and preventive decisions.\n", "versions": [{"version": "v1", "created": "Mon, 18 Nov 2019 15:13:48 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Imteaj", "Ahmed", ""], ["Amini", "M. Hadi", ""], ["Mohammadi", "Javad", ""]]}, {"id": "1911.07712", "submitter": "Shi Zhenyu", "authors": "Runsheng Yu, Zhenyu Shi, Xinrun Wang, Rundong Wang, Buhong Liu, Xinwen\n  Hou, Hanjiang Lai, Bo An", "title": "Inducing Cooperation via Team Regret Minimization based Multi-Agent Deep\n  Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing value-factorized based Multi-Agent deep Reinforce-ment Learning\n(MARL) approaches are well-performing invarious multi-agent cooperative\nenvironment under thecen-tralized training and decentralized execution(CTDE)\nscheme,where all agents are trained together by the centralized valuenetwork\nand each agent execute its policy independently. How-ever, an issue remains\nopen: in the centralized training process,when the environment for the team is\npartially observable ornon-stationary, i.e., the observation and action\ninformationof all the agents cannot represent the global states,\nexistingmethods perform poorly and sample inefficiently. Regret Min-imization\n(RM) can be a promising approach as it performswell in partially observable and\nfully competitive settings.However, it tends to model others as opponents and\nthus can-not work well under the CTDE scheme. In this work, wepropose a novel\nteam RM based Bayesian MARL with threekey contributions: (a) we design a novel\nRM method to traincooperative agents as a team and obtain a team\nregret-basedpolicy for that team; (b) we introduce a novel method to de-compose\nthe team regret to generate the policy for each agentfor decentralized\nexecution; (c) to further improve the perfor-mance, we leverage a differential\nparticle filter (a SequentialMonte Carlo method) network to get an accurate\nestimation ofthe state for each agent. Experimental results on two-step ma-trix\ngames (cooperative game) and battle games (large-scalemixed\ncooperative-competitive games) demonstrate that ouralgorithm significantly\noutperforms state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Mon, 18 Nov 2019 15:41:15 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Yu", "Runsheng", ""], ["Shi", "Zhenyu", ""], ["Wang", "Xinrun", ""], ["Wang", "Rundong", ""], ["Liu", "Buhong", ""], ["Hou", "Xinwen", ""], ["Lai", "Hanjiang", ""], ["An", "Bo", ""]]}, {"id": "1911.07749", "submitter": "Andr\\'e Artelt", "authors": "Andr\\'e Artelt, Barbara Hammer", "title": "On the computation of counterfactual explanations -- A survey", "comments": "In progress. arXiv admin note: text overlap with arXiv:1908.00735", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to the increasing use of machine learning in practice it becomes more and\nmore important to be able to explain the prediction and behavior of machine\nlearning models. An instance of explanations are counterfactual explanations\nwhich provide an intuitive and useful explanations of machine learning models.\nIn this survey we review model-specific methods for efficiently computing\ncounterfactual explanations of many different machine learning models and\npropose methods for models that have not been considered in literature so far.\n", "versions": [{"version": "v1", "created": "Fri, 15 Nov 2019 08:14:26 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Artelt", "Andr\u00e9", ""], ["Hammer", "Barbara", ""]]}, {"id": "1911.07750", "submitter": "Angelika Kimmig", "authors": "Efthymia Tsamoura, Victor Gutierrez-Basulto, Angelika Kimmig", "title": "Beyond the Grounding Bottleneck: Datalog Techniques for Inference in\n  Probabilistic Logic Programs (Technical Report)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  State-of-the-art inference approaches in probabilistic logic programming\ntypically start by computing the relevant ground program with respect to the\nqueries of interest, and then use this program for probabilistic inference\nusing knowledge compilation and weighted model counting. We propose an\nalternative approach that uses efficient Datalog techniques to integrate\nknowledge compilation with forward reasoning with a non-ground program. This\neffectively eliminates the grounding bottleneck that so far has prohibited the\napplication of probabilistic logic programming in query answering scenarios\nover knowledge graphs, while also providing fast approximations on classical\nbenchmarks in the field.\n", "versions": [{"version": "v1", "created": "Mon, 18 Nov 2019 16:29:52 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Tsamoura", "Efthymia", ""], ["Gutierrez-Basulto", "Victor", ""], ["Kimmig", "Angelika", ""]]}, {"id": "1911.07794", "submitter": "Craig Sherstan", "authors": "Craig Sherstan, Shibhansh Dohare, James MacGlashan, Johannes\n  G\\\"unther, Patrick M. Pilarski", "title": "Gamma-Nets: Generalizing Value Estimation over Timescale", "comments": "AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present $\\Gamma$-nets, a method for generalizing value function estimation\nover timescale. By using the timescale as one of the estimator's inputs we can\nestimate value for arbitrary timescales. As a result, the prediction target for\nany timescale is available and we are free to train on multiple timescales at\neach timestep. Here we empirically evaluate $\\Gamma$-nets in the policy\nevaluation setting. We first demonstrate the approach on a square wave and then\non a robot arm using linear function approximation. Next, we consider the deep\nreinforcement learning setting using several Atari video games. Our results\nshow that $\\Gamma$-nets can be effective for predicting arbitrary timescales,\nwith only a small cost in accuracy as compared to learning estimators for fixed\ntimescales. $\\Gamma$-nets provide a method for compactly making predictions at\nmany timescales without requiring a priori knowledge of the task, making it a\nvaluable contribution to ongoing work on model-based planning, representation\nlearning, and lifelong learning algorithms.\n", "versions": [{"version": "v1", "created": "Mon, 18 Nov 2019 17:49:06 GMT"}, {"version": "v2", "created": "Wed, 20 Nov 2019 19:34:12 GMT"}, {"version": "v3", "created": "Sat, 23 Nov 2019 23:34:23 GMT"}, {"version": "v4", "created": "Fri, 31 Jan 2020 16:28:51 GMT"}, {"version": "v5", "created": "Fri, 16 Oct 2020 21:19:11 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["Sherstan", "Craig", ""], ["Dohare", "Shibhansh", ""], ["MacGlashan", "James", ""], ["G\u00fcnther", "Johannes", ""], ["Pilarski", "Patrick M.", ""]]}, {"id": "1911.07840", "submitter": "Jinmingwu Jiang", "authors": "Jinmingwu Jiang, Kaigui Wu", "title": "Cooperative Pathfinding based on Multi-agent RRT* Fixed Node", "comments": "arXiv admin note: substantial text overlap with arXiv:1911.03927", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In cooperative pathfinding problems, non-conflict paths that bring several\nagents from their start location to their destination need to be planned. This\nproblem can be efficiently solved by Multi-agent RRT*(MA-RRT*) algorithm, which\nis still state-of-the-art in the field of coupled methods. However, the\nimplementation of this algorithm is hindered in systems with limited memory\nbecause the number of nodes in the tree of RRT* grows indefinitely as the paths\nget optimized. This paper proposes an improved version of MA-RRT*, called\nMulti-agent RRT* Fixed Node(MA-RRT*FN), which limits the number of nodes stored\nin the tree of RRT* by removing the weak nodes on the path which are not likely\nto reach the goal. The results show that MA-RRT*FN performs close to MA-RRT* in\nterms of scalability and solution quality while the memory required is much\nlower and fixed.\n", "versions": [{"version": "v1", "created": "Sat, 16 Nov 2019 13:02:59 GMT"}, {"version": "v2", "created": "Wed, 4 Mar 2020 03:09:06 GMT"}, {"version": "v3", "created": "Sun, 21 Feb 2021 09:39:03 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Jiang", "Jinmingwu", ""], ["Wu", "Kaigui", ""]]}, {"id": "1911.07893", "submitter": "Chengjin Xu", "authors": "Chengjin Xu and Mojtaba Nayyeri and Fouad Alkhoury and Hamed Shariat\n  Yazdi and Jens Lehmann", "title": "Temporal Knowledge Graph Embedding Model based on Additive Time Series\n  Decomposition", "comments": "This paper has been accepted by ISWC2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge Graph (KG) embedding has attracted more attention in recent years.\nMost KG embedding models learn from time-unaware triples. However, the\ninclusion of temporal information beside triples would further improve the\nperformance of a KGE model. In this regard, we propose ATiSE, a temporal KG\nembedding model which incorporates time information into entity/relation\nrepresentations by using Additive Time Series decomposition. Moreover,\nconsidering the temporal uncertainty during the evolution of entity/relation\nrepresentations over time, we map the representations of temporal KGs into the\nspace of multi-dimensional Gaussian distributions. The mean of each\nentity/relation embedding at a time step shows the current expected position,\nwhereas its covariance (which is temporally stationary) represents its temporal\nuncertainty. Experimental results show that ATiSE chieves the state-of-the-art\non link prediction over four temporal KGs.\n", "versions": [{"version": "v1", "created": "Mon, 18 Nov 2019 19:36:26 GMT"}, {"version": "v2", "created": "Wed, 27 May 2020 07:23:58 GMT"}, {"version": "v3", "created": "Fri, 2 Oct 2020 08:03:43 GMT"}, {"version": "v4", "created": "Tue, 6 Oct 2020 20:07:17 GMT"}, {"version": "v5", "created": "Sat, 24 Oct 2020 14:14:20 GMT"}, {"version": "v6", "created": "Wed, 28 Oct 2020 12:28:46 GMT"}], "update_date": "2020-10-29", "authors_parsed": [["Xu", "Chengjin", ""], ["Nayyeri", "Mojtaba", ""], ["Alkhoury", "Fouad", ""], ["Yazdi", "Hamed Shariat", ""], ["Lehmann", "Jens", ""]]}, {"id": "1911.07928", "submitter": "Wei Pang Xubu", "authors": "Wei Pang and Xiaojie Wang", "title": "Visual Dialogue State Tracking for Question Generation", "comments": "8 pages, 4 figures, Accept-Oral by AAAI-2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  GuessWhat?! is a visual dialogue task between a guesser and an oracle. The\nguesser aims to locate an object supposed by the oracle oneself in an image by\nasking a sequence of Yes/No questions. Asking proper questions with the\nprogress of dialogue is vital for achieving successful final guess. As a\nresult, the progress of dialogue should be properly represented and tracked.\nPrevious models for question generation pay less attention on the\nrepresentation and tracking of dialogue states, and therefore are prone to\nasking low quality questions such as repeated questions. This paper proposes\nvisual dialogue state tracking (VDST) based method for question generation. A\nvisual dialogue state is defined as the distribution on objects in the image as\nwell as representations of objects. Representations of objects are updated with\nthe change of the distribution on objects. An object-difference based attention\nis used to decode new question. The distribution on objects is updated by\ncomparing the question-answer pair and objects. Experimental results on\nGuessWhat?! dataset show that our model significantly outperforms existing\nmethods and achieves new state-of-the-art performance. It is also noticeable\nthat our model reduces the rate of repeated questions from more than 50% to\n21.9% compared with previous state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Tue, 12 Nov 2019 15:54:55 GMT"}, {"version": "v2", "created": "Mon, 25 Nov 2019 03:32:28 GMT"}], "update_date": "2019-11-26", "authors_parsed": [["Pang", "Wei", ""], ["Wang", "Xiaojie", ""]]}, {"id": "1911.07960", "submitter": "Tristan Cazenave", "authors": "Tristan Cazenave and V\\'eronique Ventos", "title": "The {\\alpha}{\\mu} Search Algorithm for the Game of Bridge", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  {\\alpha}{\\mu} is an anytime heuristic search algorithm for incomplete\ninformation games that assumes perfect information for the opponents.\n{\\alpha}{\\mu} addresses the strategy fusion and non-locality problems\nencountered by Perfect Information Monte Carlo sampling. In this paper\n{\\alpha}{\\mu} is applied to the game of Bridge.\n", "versions": [{"version": "v1", "created": "Mon, 18 Nov 2019 21:18:50 GMT"}], "update_date": "2019-11-20", "authors_parsed": [["Cazenave", "Tristan", ""], ["Ventos", "V\u00e9ronique", ""]]}, {"id": "1911.08044", "submitter": "Pin Wang", "authors": "Pin Wang, Dapeng Liu, Jiayu Chen, Hanhan Li, and Ching-Yao Chan", "title": "Decision Making for Autonomous Driving via Augmented Adversarial Inverse\n  Reinforcement Learning", "comments": "The 2021 International Conference on Robotics and Automation (ICRA\n  2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Making decisions in complex driving environments is a challenging task for\nautonomous agents. Imitation learning methods have great potentials for\nachieving such a goal. Adversarial Inverse Reinforcement Learning (AIRL) is one\nof the state-of-art imitation learning methods that can learn both a behavioral\npolicy and a reward function simultaneously, yet it is only demonstrated in\nsimple and static environments where no interactions are introduced. In this\npaper, we improve and stabilize AIRL's performance by augmenting it with\nsemantic rewards in the learning framework. Additionally, we adapt the\naugmented AIRL to a more practical and challenging decision-making task in a\nhighly interactive environment in autonomous driving. The proposed method is\ncompared with four baselines and evaluated by four performance metrics.\nSimulation results show that the augmented AIRL outperforms all the baseline\nmethods, and its performance is comparable with that of the experts on all of\nthe four metrics.\n", "versions": [{"version": "v1", "created": "Tue, 19 Nov 2019 02:06:16 GMT"}, {"version": "v2", "created": "Sun, 2 Feb 2020 22:57:56 GMT"}, {"version": "v3", "created": "Fri, 26 Mar 2021 04:55:47 GMT"}], "update_date": "2021-03-29", "authors_parsed": [["Wang", "Pin", ""], ["Liu", "Dapeng", ""], ["Chen", "Jiayu", ""], ["Li", "Hanhan", ""], ["Chan", "Ching-Yao", ""]]}, {"id": "1911.08068", "submitter": "Yangchen Pan", "authors": "Yangchen Pan, Kirby Banman, Martha White", "title": "Fuzzy Tiling Activations: A Simple Approach to Learning Sparse\n  Representations Online", "comments": "ICLR 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work has shown that sparse representations -- where only a small\npercentage of units are active -- can significantly reduce interference. Those\nworks, however, relied on relatively complex regularization or meta-learning\napproaches, that have only been used offline in a pre-training phase. In this\nwork, we pursue a direction that achieves sparsity by design, rather than by\nlearning. Specifically, we design an activation function that produces sparse\nrepresentations deterministically by construction, and so is more amenable to\nonline training. The idea relies on the simple approach of binning, but\novercomes the two key limitations of binning: zero gradients for the flat\nregions almost everywhere, and lost precision -- reduced discrimination -- due\nto coarse aggregation. We introduce a Fuzzy Tiling Activation (FTA) that\nprovides non-negligible gradients and produces overlap between bins that\nimproves discrimination. We first show that FTA is robust under covariate shift\nin a synthetic online supervised learning problem, where we can vary the level\nof correlation and drift. Then we move to the deep reinforcement learning\nsetting and investigate both value-based and policy gradient algorithms that\nuse neural networks with FTAs, in classic discrete control and Mujoco\ncontinuous control environments. We show that algorithms equipped with FTAs are\nable to learn a stable policy faster without needing target networks on most\ndomains.\n", "versions": [{"version": "v1", "created": "Tue, 19 Nov 2019 03:12:06 GMT"}, {"version": "v2", "created": "Sat, 15 Feb 2020 22:36:15 GMT"}, {"version": "v3", "created": "Tue, 16 Mar 2021 16:32:19 GMT"}], "update_date": "2021-03-17", "authors_parsed": [["Pan", "Yangchen", ""], ["Banman", "Kirby", ""], ["White", "Martha", ""]]}, {"id": "1911.08089", "submitter": "Joseph Futoma", "authors": "Mark Sendak, Madeleine Elish, Michael Gao, Joseph Futoma, William\n  Ratliff, Marshall Nichols, Armando Bedoya, Suresh Balu, Cara O'Brien", "title": "\"The Human Body is a Black Box\": Supporting Clinical Decision-Making\n  with Deep Learning", "comments": "To appear at ACM FAT* 2020, Barcelona. Updated to camera-ready\n  version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning technologies are increasingly developed for use in\nhealthcare. While research communities have focused on creating\nstate-of-the-art models, there has been less focus on real world implementation\nand the associated challenges to accuracy, fairness, accountability, and\ntransparency that come from actual, situated use. Serious questions remain\nunder examined regarding how to ethically build models, interpret and explain\nmodel output, recognize and account for biases, and minimize disruptions to\nprofessional expertise and work cultures. We address this gap in the literature\nand provide a detailed case study covering the development, implementation, and\nevaluation of Sepsis Watch, a machine learning-driven tool that assists\nhospital clinicians in the early diagnosis and treatment of sepsis. We, the\nteam that developed and evaluated the tool, discuss our conceptualization of\nthe tool not as a model deployed in the world but instead as a socio-technical\nsystem requiring integration into existing social and professional contexts.\nRather than focusing on model interpretability to ensure a fair and accountable\nmachine learning, we point toward four key values and practices that should be\nconsidered when developing machine learning to support clinical\ndecision-making: rigorously define the problem in context, build relationships\nwith stakeholders, respect professional discretion, and create ongoing feedback\nloops with stakeholders. Our work has significant implications for future\nresearch regarding mechanisms of institutional accountability and\nconsiderations for designing machine learning systems. Our work underscores the\nlimits of model interpretability as a solution to ensure transparency,\naccuracy, and accountability in practice. Instead, our work demonstrates other\nmeans and goals to achieve FATML values in design and in practice.\n", "versions": [{"version": "v1", "created": "Tue, 19 Nov 2019 04:28:47 GMT"}, {"version": "v2", "created": "Sat, 7 Dec 2019 03:42:06 GMT"}], "update_date": "2019-12-10", "authors_parsed": [["Sendak", "Mark", ""], ["Elish", "Madeleine", ""], ["Gao", "Michael", ""], ["Futoma", "Joseph", ""], ["Ratliff", "William", ""], ["Nichols", "Marshall", ""], ["Bedoya", "Armando", ""], ["Balu", "Suresh", ""], ["O'Brien", "Cara", ""]]}, {"id": "1911.08105", "submitter": "Megumi Nakao", "authors": "Megumi Nakao, Keiho Imanishi, Nobuhiro Ueda, Yuichiro Imai, Tadaaki\n  Kirita, Tetsuya Matsuda", "title": "Three-dimensional Generative Adversarial Nets for Unsupervised Metal\n  Artifact Reduction", "comments": null, "journal-ref": "IEEE Access, 8, 109453-109465 (2020)", "doi": "10.1109/ACCESS.2020.3002090", "report-no": null, "categories": "eess.IV cs.AI cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The reduction of metal artifacts in computed tomography (CT) images,\nspecifically for strong artifacts generated from multiple metal objects, is a\nchallenging issue in medical imaging research. Although there have been some\nstudies on supervised metal artifact reduction through the learning of\nsynthesized artifacts, it is difficult for simulated artifacts to cover the\ncomplexity of the real physical phenomena that may be observed in X-ray\npropagation. In this paper, we introduce metal artifact reduction methods based\non an unsupervised volume-to-volume translation learned from clinical CT\nimages. We construct three-dimensional adversarial nets with a regularized loss\nfunction designed for metal artifacts from multiple dental fillings. The\nresults of experiments using 915 CT volumes from real patients demonstrate that\nthe proposed framework has an outstanding capacity to reduce strong artifacts\nand to recover underlying missing voxels, while preserving the anatomical\nfeatures of soft tissues and tooth structures from the original images.\n", "versions": [{"version": "v1", "created": "Tue, 19 Nov 2019 05:56:54 GMT"}, {"version": "v2", "created": "Tue, 31 Mar 2020 03:40:43 GMT"}, {"version": "v3", "created": "Fri, 21 Aug 2020 04:50:09 GMT"}], "update_date": "2020-08-24", "authors_parsed": [["Nakao", "Megumi", ""], ["Imanishi", "Keiho", ""], ["Ueda", "Nobuhiro", ""], ["Imai", "Yuichiro", ""], ["Kirita", "Tadaaki", ""], ["Matsuda", "Tetsuya", ""]]}, {"id": "1911.08111", "submitter": "Jiangbin Lyu Dr.", "authors": "Jin Qiu, Jiangbin Lyu and Liqun Fu", "title": "Placement Optimization of Aerial Base Stations with Deep Reinforcement\n  Learning", "comments": "6 pages, 4 figures, accepted for publication in 2020 IEEE\n  International Conference on Communications (ICC 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.AI cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unmanned aerial vehicles (UAVs) can be utilized as aerial base stations\n(ABSs) to assist terrestrial infrastructure for keeping wireless connectivity\nin various emergency scenarios. To maximize the coverage rate of N ground users\n(GUs) by jointly placing multiple ABSs with limited coverage range is known to\nbe a NP-hard problem with exponential complexity in N. The problem is further\ncomplicated when the coverage range becomes irregular due to site-specific\nblockage (e.g., buildings) on the air-ground channel in the 3-dimensional (3D)\nspace. To tackle this challenging problem, this paper applies the Deep\nReinforcement Learning (DRL) method by 1) representing the state by a coverage\nbitmap to capture the spatial correlation of GUs/ABSs, whose dimension and\nassociated neural network complexity is invariant with arbitrarily large N; and\n2) designing the action and reward for the DRL agent to effectively learn from\nthe dynamic interactions with the complicated propagation environment\nrepresented by a 3D Terrain Map. Specifically, a novel two-level design\napproach is proposed, consisting of a preliminary design based on the dominant\nline-of-sight (LoS) channel model, and an advanced design to further refine the\nABS positions based on site-specific LoS/non-LoS channel states. The double\ndeep Q-network (DQN) with Prioritized Experience Replay (Prioritized Replay\nDDQN) algorithm is applied to train the policy of multi-ABS placement decision.\nNumerical results show that the proposed approach significantly improves the\ncoverage rate in complex environment, compared to the benchmark DQN and K-means\nalgorithms.\n", "versions": [{"version": "v1", "created": "Tue, 19 Nov 2019 06:35:15 GMT"}, {"version": "v2", "created": "Wed, 5 Feb 2020 07:53:53 GMT"}], "update_date": "2020-02-06", "authors_parsed": [["Qiu", "Jin", ""], ["Lyu", "Jiangbin", ""], ["Fu", "Liqun", ""]]}, {"id": "1911.08112", "submitter": "Hongwei Zeng", "authors": "Hongwei Zeng, Zhuo Zhi, Jun Liu, Bifan Wei", "title": "Extended Answer and Uncertainty Aware Neural Question Generation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study automatic question generation, the task of creating\nquestions from corresponding text passages where some certain spans of the text\ncan serve as the answers. We propose an Extended Answer-aware Network (EAN)\nwhich is trained with Word-based Coverage Mechanism (WCM) and decodes with\nUncertainty-aware Beam Search (UBS). The EAN represents the target answer by\nits surrounding sentence with an encoder, and incorporates the information of\nthe extended answer into paragraph representation with gated\nparagraph-to-answer attention to tackle the problem of the inadequate\nrepresentation of the target answer. To reduce undesirable repetition, the WCM\npenalizes repeatedly attending to the same words at different time-steps in the\ntraining stage. The UBS aims to seek a better balance between the model\nconfidence in copying words from an input text paragraph and the confidence in\ngenerating words from a vocabulary. We conduct experiments on the SQuAD\ndataset, and the results show our approach achieves significant performance\nimprovement.\n", "versions": [{"version": "v1", "created": "Tue, 19 Nov 2019 06:38:14 GMT"}], "update_date": "2019-11-20", "authors_parsed": [["Zeng", "Hongwei", ""], ["Zhi", "Zhuo", ""], ["Liu", "Jun", ""], ["Wei", "Bifan", ""]]}, {"id": "1911.08125", "submitter": "Preslav Nakov", "authors": "Momchil Hardalov, Ivan Koychev, Preslav Nakov", "title": "In Search of Credible News", "comments": "Credibility, veracity, fact checking, humor detection", "journal-ref": "AIMSA-2016", "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of finding fake online news. This is an important\nproblem as news of questionable credibility have recently been proliferating in\nsocial media at an alarming scale. As this is an understudied problem,\nespecially for languages other than English, we first collect and release to\nthe research community three new balanced credible vs. fake news datasets\nderived from four online sources. We then propose a language-independent\napproach for automatically distinguishing credible from fake news, based on a\nrich feature set. In particular, we use linguistic (n-gram),\ncredibility-related (capitalization, punctuation, pronoun use, sentiment\npolarity), and semantic (embeddings and DBPedia data) features. Our experiments\non three different testsets show that our model can distinguish credible from\nfake news with very high accuracy.\n", "versions": [{"version": "v1", "created": "Tue, 19 Nov 2019 07:06:22 GMT"}], "update_date": "2019-11-20", "authors_parsed": [["Hardalov", "Momchil", ""], ["Koychev", "Ivan", ""], ["Nakov", "Preslav", ""]]}, {"id": "1911.08145", "submitter": "Suguman Bansal", "authors": "Suguman Bansal, Yong Li, Lucas M. Tabajara, Moshe Y. Vardi", "title": "Hybrid Compositional Reasoning for Reactive Synthesis from\n  Finite-Horizon Specifications", "comments": "Accepted by AAAI 2020. Tool Lisa for (a). LTLf to DFA conversion, and\n  (b). LTLf synthesis can be found here: https://github.com/vardigroup/lisa", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  LTLf synthesis is the automated construction of a reactive system from a\nhigh-level description, expressed in LTLf, of its finite-horizon behavior. So\nfar, the conversion of LTLf formulas to deterministic finite-state automata\n(DFAs) has been identified as the primary bottleneck to the scalabity of\nsynthesis. Recent investigations have also shown that the size of the DFA state\nspace plays a critical role in synthesis as well.\n  Therefore, effective resolution of the bottleneck for synthesis requires the\nconversion to be time and memory performant, and prevent state-space explosion.\nCurrent conversion approaches, however, which are based either on\nexplicit-state representation or symbolic-state representation, fail to address\nthese necessities adequately at scale: Explicit-state approaches generate\nminimal DFA but are slow due to expensive DFA minimization. Symbolic-state\nrepresentations can be succinct, but due to the lack of DFA minimization they\ngenerate such large state spaces that even their symbolic representations\ncannot compensate for the blow-up.\n  This work proposes a hybrid representation approach for the conversion. Our\napproach utilizes both explicit and symbolic representations of the\nstate-space, and effectively leverages their complementary strengths. In doing\nso, we offer an LTLf to DFA conversion technique that addresses all three\nnecessities, hence resolving the bottleneck. A comprehensive empirical\nevaluation on conversion and synthesis benchmarks supports the merits of our\nhybrid approach.\n", "versions": [{"version": "v1", "created": "Tue, 19 Nov 2019 08:05:24 GMT"}, {"version": "v2", "created": "Mon, 9 Dec 2019 04:48:40 GMT"}, {"version": "v3", "created": "Mon, 17 Feb 2020 20:16:37 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Bansal", "Suguman", ""], ["Li", "Yong", ""], ["Tabajara", "Lucas M.", ""], ["Vardi", "Moshe Y.", ""]]}, {"id": "1911.08151", "submitter": "Jiahuan Pei", "authors": "Jiahuan Pei, Pengjie Ren, Christof Monz, Maarten de Rijke", "title": "Retrospective and Prospective Mixture-of-Generators for Task-oriented\n  Dialogue Response Generation", "comments": "The paper is accepted by 24th European Conference on Artificial\n  Intelligence", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dialogue response generation (DRG) is a critical component of task-oriented\ndialogue systems (TDSs). Its purpose is to generate proper natural language\nresponses given some context, e.g., historical utterances, system states, etc.\nState-of-the-art work focuses on how to better tackle DRG in an end-to-end way.\nTypically, such studies assume that each token is drawn from a single\ndistribution over the output vocabulary, which may not always be optimal.\nResponses vary greatly with different intents, e.g., domains, system actions.\n  We propose a novel mixture-of-generators network (MoGNet) for DRG, where we\nassume that each token of a response is drawn from a mixture of distributions.\nMoGNet consists of a chair generator and several expert generators. Each expert\nis specialized for DRG w.r.t. a particular intent. The chair coordinates\nmultiple experts and combines the output they have generated to produce more\nappropriate responses. We propose two strategies to help the chair make better\ndecisions, namely, a retrospective mixture-of-generators (RMoG) and prospective\nmixture-of-generators (PMoG). The former only considers the historical\nexpert-generated responses until the current time step while the latter also\nconsiders possible expert-generated responses in the future by encouraging\nexploration. In order to differentiate experts, we also devise a\nglobal-and-local (GL) learning scheme that forces each expert to be specialized\ntowards a particular intent using a local loss and trains the chair and all\nexperts to coordinate using a global loss.\n  We carry out extensive experiments on the MultiWOZ benchmark dataset. MoGNet\nsignificantly outperforms state-of-the-art methods in terms of both automatic\nand human evaluations, demonstrating its effectiveness for DRG.\n", "versions": [{"version": "v1", "created": "Tue, 19 Nov 2019 08:20:45 GMT"}, {"version": "v2", "created": "Wed, 19 Feb 2020 11:04:28 GMT"}], "update_date": "2020-02-20", "authors_parsed": [["Pei", "Jiahuan", ""], ["Ren", "Pengjie", ""], ["Monz", "Christof", ""], ["de Rijke", "Maarten", ""]]}, {"id": "1911.08196", "submitter": "Xiaowei Wu", "authors": "Minming Li, Long Tran-Thanh, Xiaowei Wu", "title": "Defending with Shared Resources on a Network", "comments": "16 pages, 3 figures, to appear in AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we consider a defending problem on a network. In the model, the\ndefender holds a total defending resource of R, which can be distributed to the\nnodes of the network. The defending resource allocated to a node can be shared\nby its neighbors. There is a weight associated with every edge that represents\nthe efficiency defending resources are shared between neighboring nodes. We\nconsider the setting when each attack can affect not only the target node, but\nits neighbors as well. Assuming that nodes in the network have different\ntreasures to defend and different defending requirements, the defender aims at\nallocating the defending resource to the nodes to minimize the loss due to\nattack. We give polynomial time exact algorithms for two important special\ncases of the network defending problem. For the case when an attack can only\naffect the target node, we present an LP-based exact algorithm. For the case\nwhen defending resources cannot be shared, we present a max-flow-based exact\nalgorithm. We show that the general problem is NP-hard, and we give a\n2-approximation algorithm based on LP-rounding. Moreover, by giving a matching\nlower bound of 2 on the integrality gap on the LP relaxation, we show that our\nrounding is tight.\n", "versions": [{"version": "v1", "created": "Tue, 19 Nov 2019 10:21:01 GMT"}], "update_date": "2019-11-20", "authors_parsed": [["Li", "Minming", ""], ["Tran-Thanh", "Long", ""], ["Wu", "Xiaowei", ""]]}, {"id": "1911.08225", "submitter": "Rodrigo Santos", "authors": "Marcio Ferreira Moreno, Rodrigo Costa Mesquita Santos, Wallas Henrique\n  Sousa dos Santos, Sandro Rama Fiorini, Reinaldo Mozart da Gama Silva", "title": "Multimedia Search and Temporal Reasoning", "comments": "International Conference on Information Systems (ICIS) 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Properly modelling dynamic information that changes over time still is an\nopen issue. Most modern knowledge bases are unable to represent relationships\nthat are valid only during a given time interval. In this work, we revisit a\nprevious extension to the hyperknowledge framework to deal with temporal facts\nand propose a temporal query language and engine. We validate our proposal by\ndiscussing a qualitative analysis of the modelling of a real-world use case in\nthe Oil & Gas industry.\n", "versions": [{"version": "v1", "created": "Tue, 19 Nov 2019 12:29:19 GMT"}], "update_date": "2019-11-20", "authors_parsed": [["Moreno", "Marcio Ferreira", ""], ["Santos", "Rodrigo Costa Mesquita", ""], ["Santos", "Wallas Henrique Sousa dos", ""], ["Fiorini", "Sandro Rama", ""], ["Silva", "Reinaldo Mozart da Gama", ""]]}, {"id": "1911.08286", "submitter": "Sarah McDaid PhD", "authors": "Edward McDaid, Sarah McDaid", "title": "Zoea -- Composable Inductive Programming Without Limits", "comments": "13 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic generation of software from some form of specification has been a\nlong standing goal of computer science research. To date successful results\nhave been reported for the production of relatively small programs. This paper\npresents Zoea which is a simple programming language that allows software to be\ngenerated from a specification format that closely resembles a set of automated\nfunctional tests. Zoea incorporates a number of advances that enable it to\ngenerate software that is large enough to have commercial value. Zoea also\nallows programs to be composed to form still larger programs. As a result Zoea\ncan be used to produce software of any size and complexity. An overview of the\ncore Zoea language is provided together with a high level description of the\nsymbolic AI based Zoea compiler.\n", "versions": [{"version": "v1", "created": "Wed, 13 Nov 2019 12:28:17 GMT"}], "update_date": "2019-11-20", "authors_parsed": [["McDaid", "Edward", ""], ["McDaid", "Sarah", ""]]}, {"id": "1911.08292", "submitter": "Xintao Wu", "authors": "Wen Huang, Yongkai Wu, Lu Zhang, Xintao Wu", "title": "Fairness through Equality of Effort", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fair machine learning is receiving an increasing attention in machine\nlearning fields. Researchers in fair learning have developed correlation or\nassociation-based measures such as demographic disparity, mistreatment\ndisparity, calibration, causal-based measures such as total effect, direct and\nindirect discrimination, and counterfactual fairness, and fairness notions such\nas equality of opportunity and equal odds that consider both decisions in the\ntraining data and decisions made by predictive models. In this paper, we\ndevelop a new causal-based fairness notation, called equality of effort.\nDifferent from existing fairness notions which mainly focus on discovering the\ndisparity of decisions between two groups of individuals, the proposed equality\nof effort notation helps answer questions like to what extend a legitimate\nvariable should change to make a particular individual achieve a certain\noutcome level and addresses the concerns whether the efforts made to achieve\nthe same outcome level for individuals from the protected group and that from\nthe unprotected group are different. We develop algorithms for determining\nwhether an individual or a group of individuals is discriminated in terms of\nequality of effort. We also develop an optimization-based method for removing\ndiscriminatory effects from the data if discrimination is detected. We conduct\nempirical evaluations to compare the equality of effort and existing fairness\nnotion and show the effectiveness of our proposed algorithms.\n", "versions": [{"version": "v1", "created": "Mon, 11 Nov 2019 18:49:45 GMT"}], "update_date": "2019-11-20", "authors_parsed": [["Huang", "Wen", ""], ["Wu", "Yongkai", ""], ["Zhang", "Lu", ""], ["Wu", "Xintao", ""]]}, {"id": "1911.08340", "submitter": "Martin Andrews", "authors": "Martin Andrews, Sam Witteveen", "title": "Unsupervised Natural Question Answering with a Small Model", "comments": "Accepted paper for FEVER workshop at EMNLP-IJCNLP 2019. (4 pages +\n  references)", "journal-ref": null, "doi": "10.18653/v1/D19-6606", "report-no": null, "categories": "cs.CL cs.AI cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recent (2019-02) demonstration of the power of huge language models such\nas GPT-2 to memorise the answers to factoid questions raises questions about\nthe extent to which knowledge is being embedded directly within these large\nmodels. This short paper describes an architecture through which much smaller\nmodels can also answer such questions - by making use of 'raw' external\nknowledge. The contribution of this work is that the methods presented here\nrely on unsupervised learning techniques, complementing the unsupervised\ntraining of the Language Model. The goal of this line of research is to be able\nto add knowledge explicitly, without extensive training.\n", "versions": [{"version": "v1", "created": "Tue, 19 Nov 2019 15:18:39 GMT"}], "update_date": "2019-11-22", "authors_parsed": [["Andrews", "Martin", ""], ["Witteveen", "Sam", ""]]}, {"id": "1911.08342", "submitter": "Max Berrendorf", "authors": "Max Berrendorf, Evgeniy Faerman, Valentyn Melnychuk, Volker Tresp,\n  Thomas Seidl", "title": "Knowledge Graph Entity Alignment with Graph Convolutional Networks:\n  Lessons Learned", "comments": null, "journal-ref": null, "doi": "10.1007/978-3-030-45442-5_1", "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we focus on the problem of entity alignment in Knowledge Graphs\n(KG) and we report on our experiences when applying a Graph Convolutional\nNetwork (GCN) based model for this task. Variants of GCN are used in multiple\nstate-of-the-art approaches and therefore it is important to understand the\nspecifics and limitations of GCN-based models. Despite serious efforts, we were\nnot able to fully reproduce the results from the original paper and after a\nthorough audit of the code provided by authors, we concluded, that their\nimplementation is different from the architecture described in the paper. In\naddition, several tricks are required to make the model work and some of them\nare not very intuitive. We provide an extensive ablation study to quantify the\neffects these tricks and changes of architecture have on final performance.\nFurthermore, we examine current evaluation approaches and systematize available\nbenchmark datasets. We believe that people interested in KG matching might\nprofit from our work, as well as novices entering the field\n", "versions": [{"version": "v1", "created": "Tue, 19 Nov 2019 15:20:53 GMT"}, {"version": "v2", "created": "Thu, 23 Jan 2020 12:20:45 GMT"}], "update_date": "2021-05-27", "authors_parsed": [["Berrendorf", "Max", ""], ["Faerman", "Evgeniy", ""], ["Melnychuk", "Valentyn", ""], ["Tresp", "Volker", ""], ["Seidl", "Thomas", ""]]}, {"id": "1911.08360", "submitter": "Guy Avni", "authors": "Guy Avni, Rasmus Ibsen-Jensen, and Josef Tkadlec", "title": "All-Pay Bidding Games on Graphs", "comments": "The full version of a paper published in AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we introduce and study {\\em all-pay bidding games}, a class of\ntwo player, zero-sum games on graphs. The game proceeds as follows. We place a\ntoken on some vertex in the graph and assign budgets to the two players. Each\nturn, each player submits a sealed legal bid (non-negative and below their\nremaining budget), which is deducted from their budget and the highest bidder\nmoves the token onto an adjacent vertex. The game ends once a sink is reached,\nand \\PO pays \\PT the outcome that is associated with the sink. The players\nattempt to maximize their expected outcome. Our games model settings where\neffort (of no inherent value) needs to be invested in an ongoing and stateful\nmanner. On the negative side, we show that even in simple games on DAGs,\noptimal strategies may require a distribution over bids with infinite support.\nA central quantity in bidding games is the {\\em ratio} of the players budgets.\nOn the positive side, we show a simple FPTAS for DAGs, that, for each budget\nratio, outputs an approximation for the optimal strategy for that ratio. We\nalso implement it, show that it performs well, and suggests interesting\nproperties of these games. Then, given an outcome $c$, we show an algorithm for\nfinding the necessary and sufficient initial ratio for guaranteeing outcome $c$\nwith probability~$1$ and a strategy ensuring such. Finally, while the general\ncase has not previously been studied, solving the specific game in which \\PO\nwins iff he wins the first two auctions, has been long stated as an open\nquestion, which we solve.\n", "versions": [{"version": "v1", "created": "Tue, 19 Nov 2019 15:42:00 GMT"}], "update_date": "2019-11-20", "authors_parsed": [["Avni", "Guy", ""], ["Ibsen-Jensen", "Rasmus", ""], ["Tkadlec", "Josef", ""]]}, {"id": "1911.08362", "submitter": "Kenneth Young", "authors": "Kenny Young", "title": "Variance Reduced Advantage Estimation with $\\delta$ Hindsight Credit\n  Assignment", "comments": "Removed incorrect sentence regarding policy gradients of any 2\n  different different actions necessarily being negative for softmax\n  parameterization", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hindsight Credit Assignment (HCA) refers to a recently proposed family of\nmethods for producing more efficient credit assignment in reinforcement\nlearning. These methods work by explicitly estimating the probability that\ncertain actions were taken in the past given present information. Prior work\nhas studied the properties of such methods and demonstrated their behaviour\nempirically. We extend this work by introducing a particular HCA algorithm\nwhich has provably lower variance than the conventional Monte-Carlo estimator\nwhen the necessary functions can be estimated exactly. This result provides a\nstrong theoretical basis for how HCA could be broadly useful.\n", "versions": [{"version": "v1", "created": "Tue, 19 Nov 2019 15:46:20 GMT"}, {"version": "v2", "created": "Mon, 23 Dec 2019 20:37:24 GMT"}, {"version": "v3", "created": "Thu, 9 Jan 2020 21:56:06 GMT"}, {"version": "v4", "created": "Mon, 28 Sep 2020 16:15:25 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Young", "Kenny", ""]]}, {"id": "1911.08363", "submitter": "Sasha Salter", "authors": "Sasha Salter, Dushyant Rao, Markus Wulfmeier, Raia Hadsell, Ingmar\n  Posner", "title": "Attention-Privileged Reinforcement Learning", "comments": "Published at Conference on Robot Learning (CoRL) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Image-based Reinforcement Learning is known to suffer from poor sample\nefficiency and generalisation to unseen visuals such as distractors\n(task-independent aspects of the observation space). Visual domain\nrandomisation encourages transfer by training over visual factors of variation\nthat may be encountered in the target domain. This increases learning\ncomplexity, can negatively impact learning rate and performance, and requires\nknowledge of potential variations during deployment. In this paper, we\nintroduce Attention-Privileged Reinforcement Learning (APRiL) which uses a\nself-supervised attention mechanism to significantly alleviate these drawbacks:\nby focusing on task-relevant aspects of the observations, attention provides\nrobustness to distractors as well as significantly increased learning\nefficiency. APRiL trains two attention-augmented actor-critic agents: one\npurely based on image observations, available across training and transfer\ndomains; and one with access to privileged information (such as environment\nstates) available only during training. Experience is shared between both\nagents and their attention mechanisms are aligned. The image-based policy can\nthen be deployed without access to privileged information. We experimentally\ndemonstrate accelerated and more robust learning on a diverse set of domains,\nleading to improved final performance for environments both within and outside\nthe training distribution.\n", "versions": [{"version": "v1", "created": "Tue, 19 Nov 2019 15:49:29 GMT"}, {"version": "v2", "created": "Wed, 11 Mar 2020 21:22:39 GMT"}, {"version": "v3", "created": "Mon, 11 Jan 2021 14:41:34 GMT"}], "update_date": "2021-01-12", "authors_parsed": [["Salter", "Sasha", ""], ["Rao", "Dushyant", ""], ["Wulfmeier", "Markus", ""], ["Hadsell", "Raia", ""], ["Posner", "Ingmar", ""]]}, {"id": "1911.08378", "submitter": "Rishiraj Saha Roy", "authors": "Azin Ghazimatin, Oana Balalau, Rishiraj Saha Roy, Gerhard Weikum", "title": "PRINCE: Provider-side Interpretability with Counterfactual Explanations\n  in Recommender Systems", "comments": "WSDM 2020, 9 pages", "journal-ref": null, "doi": "10.1145/3336191.3371824", "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Interpretable explanations for recommender systems and other machine learning\nmodels are crucial to gain user trust. Prior works that have focused on paths\nconnecting users and items in a heterogeneous network have several limitations,\nsuch as discovering relationships rather than true explanations, or\ndisregarding other users' privacy. In this work, we take a fresh perspective,\nand present PRINCE: a provider-side mechanism to produce tangible explanations\nfor end-users, where an explanation is defined to be a set of minimal actions\nperformed by the user that, if removed, changes the recommendation to a\ndifferent item. Given a recommendation, PRINCE uses a polynomial-time optimal\nalgorithm for finding this minimal set of a user's actions from an exponential\nsearch space, based on random walks over dynamic graphs. Experiments on two\nreal-world datasets show that PRINCE provides more compact explanations than\nintuitive baselines, and insights from a crowdsourced user-study demonstrate\nthe viability of such action-based explanations. We thus posit that PRINCE\nproduces scrutable, actionable, and concise explanations, owing to its use of\ncounterfactual evidence, a user's own actions, and minimal sets, respectively.\n", "versions": [{"version": "v1", "created": "Tue, 19 Nov 2019 16:23:02 GMT"}, {"version": "v2", "created": "Thu, 21 Nov 2019 09:23:52 GMT"}, {"version": "v3", "created": "Mon, 2 Dec 2019 13:08:49 GMT"}, {"version": "v4", "created": "Tue, 24 Dec 2019 07:31:30 GMT"}], "update_date": "2019-12-25", "authors_parsed": [["Ghazimatin", "Azin", ""], ["Balalau", "Oana", ""], ["Roy", "Rishiraj Saha", ""], ["Weikum", "Gerhard", ""]]}, {"id": "1911.08437", "submitter": "Mohammad Hashir", "authors": "Mohammad Hashir and Rapinder Sawhney", "title": "Towards unstructured mortality prediction with free-text clinical notes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Healthcare data continues to flourish yet a relatively small portion, mostly\nstructured, is being utilized effectively for predicting clinical outcomes. The\nrich subjective information available in unstructured clinical notes can\npossibly facilitate higher discrimination but tends to be under-utilized in\nmortality prediction. This work attempts to assess the gain in performance when\nmultiple notes that have been minimally preprocessed are used as an input for\nprediction. A hierarchical architecture consisting of both convolutional and\nrecurrent layers is used to concurrently model the different notes compiled in\nan individual hospital stay. This approach is evaluated on predicting\nin-hospital mortality on the MIMIC-III dataset. On comparison to approaches\nutilizing structured data, it achieved higher metrics despite requiring less\ncleaning and preprocessing. This demonstrates the potential of unstructured\ndata in enhancing mortality prediction and signifies the need to incorporate\nmore raw unstructured data into current clinical prediction methods.\n", "versions": [{"version": "v1", "created": "Tue, 19 Nov 2019 18:02:06 GMT"}], "update_date": "2019-11-20", "authors_parsed": [["Hashir", "Mohammad", ""], ["Sawhney", "Rapinder", ""]]}, {"id": "1911.08439", "submitter": "Rui Zhao", "authors": "Rui Zhao, Malcolm Atkinson", "title": "Towards a computer-interpretable actionable formal model to encode data\n  governance rules", "comments": "The non-draft version of this paper has been submitted and accepted\n  to BC2DC 19 (at IEEE eScience 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the needs of science and business, data sharing and re-use has become an\nintensive activity for various areas. In many cases, governance imposes rules\nconcerning data use, but there is no existing computational technique to help\ndata-users comply with such rules. We argue that intelligent systems can be\nused to improve the situation, by recording provenance records during\nprocessing, encoding the rules and performing reasoning. We present our initial\nwork, designing formal models for data rules and flow rules and the reasoning\nsystem, as the first step towards helping data providers and data users sustain\nproductive relationships.\n", "versions": [{"version": "v1", "created": "Tue, 19 Nov 2019 18:02:52 GMT"}], "update_date": "2019-11-20", "authors_parsed": [["Zhao", "Rui", ""], ["Atkinson", "Malcolm", ""]]}, {"id": "1911.08444", "submitter": "Homanga Bharadhwaj", "authors": "Homanga Bharadhwaj, Shoichiro Yamaguchi, Shin-ichi Maeda", "title": "MANGA: Method Agnostic Neural-policy Generalization and Adaptation", "comments": "Under Review. Video available at\n  https://drive.google.com/file/d/12GsDq3iQDXEutE-xpzXxqrEfD6dYhKjs/view?usp=sharing\n  Other details will be made available in the author's webpage\n  www.homangabharadhwaj.com", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we target the problem of transferring policies across multiple\nenvironments with different dynamics parameters and motor noise variations, by\nintroducing a framework that decouples the processes of policy learning and\nsystem identification. Efficiently transferring learned policies to an unknown\nenvironment with changes in dynamics configurations in the presence of motor\nnoise is very important for operating robots in the real world, and our work is\na novel attempt in that direction. We introduce MANGA: Method Agnostic\nNeural-policy Generalization and Adaptation, that trains dynamics conditioned\npolicies and efficiently learns to estimate the dynamics parameters of the\nenvironment given off-policy state-transition rollouts in the environment. Our\nscheme is agnostic to the type of training method used - both reinforcement\nlearning (RL) and imitation learning (IL) strategies can be used. We\ndemonstrate the effectiveness of our approach by experimenting with four\ndifferent MuJoCo agents and comparing against previously proposed transfer\nbaselines.\n", "versions": [{"version": "v1", "created": "Tue, 19 Nov 2019 18:10:56 GMT"}], "update_date": "2019-11-20", "authors_parsed": [["Bharadhwaj", "Homanga", ""], ["Yamaguchi", "Shoichiro", ""], ["Maeda", "Shin-ichi", ""]]}, {"id": "1911.08453", "submitter": "Soroush Nasiriany", "authors": "Soroush Nasiriany, Vitchyr H. Pong, Steven Lin, Sergey Levine", "title": "Planning with Goal-Conditioned Policies", "comments": "In Advances in Neural Information Processing Systems, 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Planning methods can solve temporally extended sequential decision making\nproblems by composing simple behaviors. However, planning requires suitable\nabstractions for the states and transitions, which typically need to be\ndesigned by hand. In contrast, model-free reinforcement learning (RL) can\nacquire behaviors from low-level inputs directly, but often struggles with\ntemporally extended tasks. Can we utilize reinforcement learning to\nautomatically form the abstractions needed for planning, thus obtaining the\nbest of both approaches? We show that goal-conditioned policies learned with RL\ncan be incorporated into planning, so that a planner can focus on which states\nto reach, rather than how those states are reached. However, with complex state\nobservations such as images, not all inputs represent valid states. We\ntherefore also propose using a latent variable model to compactly represent the\nset of valid states for the planner, so that the policies provide an\nabstraction of actions, and the latent variable model provides an abstraction\nof states. We compare our method with planning-based and model-free methods and\nfind that our method significantly outperforms prior work when evaluated on\nimage-based robot navigation and manipulation tasks that require non-greedy,\nmulti-staged behavior.\n", "versions": [{"version": "v1", "created": "Tue, 19 Nov 2019 18:25:22 GMT"}], "update_date": "2019-11-20", "authors_parsed": [["Nasiriany", "Soroush", ""], ["Pong", "Vitchyr H.", ""], ["Lin", "Steven", ""], ["Levine", "Sergey", ""]]}, {"id": "1911.08522", "submitter": "Omar U. Florez", "authors": "Omar U. Florez and Erik Mueller", "title": "Aging Memories Generate More Fluent Dialogue Responses with Memory\n  Augmented Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Memory Networks have emerged as effective models to incorporate Knowledge\nBases (KB) into neural networks. By storing KB embeddings into a memory\ncomponent, these models can learn meaningful representations that are grounded\nto external knowledge. However, as the memory unit becomes full, the oldest\nmemories are replaced by newer representations.\n  In this paper, we question this approach and provide experimental evidence\nthat conventional Memory Networks store highly correlated vectors during\ntraining. While increasing the memory size mitigates this problem, this also\nleads to overfitting as the memory stores a large number of training latent\nrepresentations. To address these issues, we propose a novel regularization\nmechanism named memory dropout which 1) Samples a single latent vector from the\ndistribution of redundant memories. 2) Ages redundant memories thus increasing\ntheir probability of overwriting them during training. This fully\ndifferentiable technique allows us to achieve state-of-the-art response\ngeneration in the Stanford Multi-Turn Dialogue and Cambridge Restaurant\ndatasets.\n", "versions": [{"version": "v1", "created": "Tue, 19 Nov 2019 19:34:15 GMT"}, {"version": "v2", "created": "Sun, 27 Sep 2020 02:42:46 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Florez", "Omar U.", ""], ["Mueller", "Erik", ""]]}, {"id": "1911.08553", "submitter": "Brian Gaudet", "authors": "Brian Gaudet, Richard Linares, Roberto Furfaro", "title": "Six Degree-of-Freedom Body-Fixed Hovering over Unmapped Asteroids via\n  LIDAR Altimetry and Reinforcement Meta-Learning", "comments": "Earlier version presented at 2020 AIAA Scitech conference. arXiv\n  admin note: substantial text overlap with arXiv:1907.06098, arXiv:1906.02113", "journal-ref": null, "doi": "10.1016/j.actaastro.2020.03.026", "report-no": null, "categories": "eess.SY cs.AI cs.LG cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We optimize a six degrees of freedom hovering policy using reinforcement\nmeta-learning. The policy maps flash LIDAR measurements directly to on/off\nspacecraft body-frame thrust commands, allowing hovering at a fixed position\nand attitude in the asteroid body-fixed reference frame. Importantly, the\npolicy does not require position and velocity estimates, and can operate in\nenvironments with unknown dynamics, and without an asteroid shape model or\nnavigation aids. Indeed, during optimization the agent is confronted with a new\nrandomly generated asteroid for each episode, insuring that it does not learn\nan asteroid's shape, texture, or environmental dynamics. This allows the\ndeployed policy to generalize well to novel asteroid characteristics, which we\ndemonstrate in our experiments. Moreover, our experiments show that the\noptimized policy adapts to actuator failure and sensor noise. Although the\npolicy is optimized using randomly generated synthetic asteroids, it is tested\non two shape models from actual asteroids: Bennu and Itokawa. We find that the\npolicy generalizes well to these shape models. The hovering controller has the\npotential to simplify mission planning by allowing asteroid body-fixed hovering\nimmediately upon the spacecraft's arrival to an asteroid. This in turn\nsimplifies shape model generation and allows resource mapping via remote\nsensing immediately upon arrival at the target asteroid.\n", "versions": [{"version": "v1", "created": "Sat, 16 Nov 2019 00:04:31 GMT"}, {"version": "v2", "created": "Sat, 8 Feb 2020 19:56:15 GMT"}], "update_date": "2020-09-16", "authors_parsed": [["Gaudet", "Brian", ""], ["Linares", "Richard", ""], ["Furfaro", "Roberto", ""]]}, {"id": "1911.08554", "submitter": "Sam Shleifer", "authors": "Sam Shleifer, Manish Chablani, Anitha Kannan, Namit Katariya, Xavier\n  Amatriain", "title": "Classification as Decoder: Trading Flexibility for Control in Medical\n  Dialogue", "comments": "Machine Learning for Health (ML4H) at NeurIPS 2019 - Extended\n  Abstract. arXiv admin note: substantial text overlap with arXiv:1910.03476", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative seq2seq dialogue systems are trained to predict the next word in\ndialogues that have already occurred. They can learn from large unlabeled\nconversation datasets, build a deeper understanding of conversational context,\nand generate a wide variety of responses. This flexibility comes at the cost of\ncontrol, a concerning tradeoff in doctor/patient interactions. Inaccuracies,\ntypos, or undesirable content in the training data will be reproduced by the\nmodel at inference time. We trade a small amount of labeling effort and some\nloss of response variety in exchange for quality control. More specifically, a\npretrained language model encodes the conversational context, and we finetune a\nclassification head to map an encoded conversational context to a response\nclass, where each class is a noisily labeled group of interchangeable\nresponses. Experts can update these exemplar responses over time as best\npractices change without retraining the classifier or invalidating old training\ndata. Expert evaluation of 775 unseen doctor/patient conversations shows that\nonly 12% of the discriminative model's responses are worse than the what the\ndoctor ended up writing, compared to 18% for the generative model.\n", "versions": [{"version": "v1", "created": "Sat, 16 Nov 2019 01:58:27 GMT"}], "update_date": "2019-11-21", "authors_parsed": [["Shleifer", "Sam", ""], ["Chablani", "Manish", ""], ["Kannan", "Anitha", ""], ["Katariya", "Namit", ""], ["Amatriain", "Xavier", ""]]}, {"id": "1911.08577", "submitter": "Vasco Portilheiro", "authors": "Vasco Portilheiro", "title": "Representation Learning with Multisets", "comments": "Under review as a conference paper at ICLR 2020. Preliminary version\n  accepted to the NeurIPS 2019 workshop on Sets and Partitions", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of learning permutation invariant representations that\ncan capture \"flexible\" notions of containment. We formalize this problem via a\nmeasure theoretic definition of multisets, and obtain a theoretically-motivated\nlearning model. We propose training this model on a novel task: predicting the\nsize of the symmetric difference (or intersection) between pairs of multisets.\nWe demonstrate that our model not only performs very well on predicting\ncontainment relations (and more effectively predicts the sizes of symmetric\ndifferences and intersections than DeepSets-based approaches with unconstrained\nobject representations), but that it also learns meaningful representations.\n", "versions": [{"version": "v1", "created": "Tue, 19 Nov 2019 20:50:20 GMT"}], "update_date": "2019-11-21", "authors_parsed": [["Portilheiro", "Vasco", ""]]}, {"id": "1911.08584", "submitter": "Eilif Muller", "authors": "Eilif B. Muller, Philippe Beaudoin", "title": "Neocortical plasticity: an unsupervised cake but no free lunch", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.AI cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The fields of artificial intelligence and neuroscience have a long history of\nfertile bi-directional interactions. On the one hand, important inspiration for\nthe development of artificial intelligence systems has come from the study of\nnatural systems of intelligence, the mammalian neocortex in particular. On the\nother, important inspiration for models and theories of the brain have emerged\nfrom artificial intelligence research. A central question at the intersection\nof these two areas is concerned with the processes by which neocortex learns,\nand the extent to which they are analogous to the back-propagation training\nalgorithm of deep networks. Matching the data efficiency, transfer and\ngeneralization properties of neocortical learning remains an area of active\nresearch in the field of deep learning. Recent advances in our understanding of\nneuronal, synaptic and dendritic physiology of the neocortex suggest new\napproaches for unsupervised representation learning, perhaps through a new\nclass of objective functions, which could act alongside or in lieu of\nback-propagation. Such local learning rules have implicit rather than explicit\nobjectives with respect to the training data, facilitating domain adaptation\nand generalization. Incorporating them into deep networks for representation\nlearning could better leverage unlabelled datasets to offer significant\nimprovements in data efficiency of downstream supervised readout learning, and\nreduce susceptibility to adversarial perturbations, at the cost of a more\nrestricted domain of applicability.\n", "versions": [{"version": "v1", "created": "Fri, 15 Nov 2019 18:32:42 GMT"}], "update_date": "2019-11-21", "authors_parsed": [["Muller", "Eilif B.", ""], ["Beaudoin", "Philippe", ""]]}, {"id": "1911.08603", "submitter": "Thilo Hagendorff", "authors": "Thilo Hagendorff", "title": "Forbidden knowledge in machine learning -- Reflections on the limits of\n  research and publication", "comments": null, "journal-ref": null, "doi": "10.1007/s00146-020-01045-4", "report-no": null, "categories": "cs.LG cs.AI cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Certain research strands can yield \"forbidden knowledge\". This term refers to\nknowledge that is considered too sensitive, dangerous or taboo to be produced\nor shared. Discourses about such publication restrictions are already\nentrenched in scientific fields like IT security, synthetic biology or nuclear\nphysics research. This paper makes the case for transferring this discourse to\nmachine learning research. Some machine learning applications can very easily\nbe misused and unfold harmful consequences, for instance with regard to\ngenerative video or text synthesis, personality analysis, behavior\nmanipulation, software vulnerability detection and the like. Up to now, the\nmachine learning research community embraces the idea of open access. However,\nthis is opposed to precautionary efforts to prevent the malicious use of\nmachine learning applications. Information about or from such applications may,\nif improperly disclosed, cause harm to people, organizations or whole\nsocieties. Hence, the goal of this work is to outline norms that can help to\ndecide whether and when the dissemination of such information should be\nprevented. It proposes review parameters for the machine learning community to\nestablish an ethical framework on how to deal with forbidden knowledge and\ndual-use applications.\n", "versions": [{"version": "v1", "created": "Tue, 19 Nov 2019 21:43:06 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Hagendorff", "Thilo", ""]]}, {"id": "1911.08610", "submitter": "Borislav Mavrin", "authors": "Borislav Mavrin, Daniel Graves, Alan Chan", "title": "Efficient decorrelation of features using Gramian in Reinforcement\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning good representations is a long standing problem in reinforcement\nlearning (RL). One of the conventional ways to achieve this goal in the\nsupervised setting is through regularization of the parameters. Extending some\nof these ideas to the RL setting has not yielded similar improvements in\nlearning. In this paper, we develop an online regularization framework for\ndecorrelating features in RL and demonstrate its utility in several test\nenvironments. We prove that the proposed algorithm converges in the linear\nfunction approximation setting and does not change the main objective of\nmaximizing cumulative reward. We demonstrate how to scale the approach to deep\nRL using the Gramian of the features achieving linear computational complexity\nin the number of features and squared complexity in size of the batch. We\nconduct an extensive empirical study of the new approach on Atari 2600 games\nand show a significant improvement in sample efficiency in 40 out of 49 games.\n", "versions": [{"version": "v1", "created": "Tue, 19 Nov 2019 22:10:08 GMT"}], "update_date": "2019-11-21", "authors_parsed": [["Mavrin", "Borislav", ""], ["Graves", "Daniel", ""], ["Chan", "Alan", ""]]}, {"id": "1911.08689", "submitter": "Thodoris Lykouris", "authors": "Thodoris Lykouris, Max Simchowitz, Aleksandrs Slivkins, Wen Sun", "title": "Corruption robust exploration in episodic reinforcement learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We initiate the study of multi-stage episodic reinforcement learning under\nadversarial corruptions in both the rewards and the transition probabilities of\nthe underlying system extending recent results for the special case of\nstochastic bandits. We provide a framework which modifies the aggressive\nexploration enjoyed by existing reinforcement learning approaches based on\n\"optimism in the face of uncertainty\", by complementing them with principles\nfrom \"action elimination\". Importantly, our framework circumvents the major\nchallenges posed by naively applying action elimination in the RL setting, as\nformalized by a lower bound we demonstrate. Our framework yields efficient\nalgorithms which (a) attain near-optimal regret in the absence of corruptions\nand (b) adapt to unknown levels corruption, enjoying regret guarantees which\ndegrade gracefully in the total corruption encountered. To showcase the\ngenerality of our approach, we derive results for both tabular settings (where\nstates and actions are finite) as well as linear-function-approximation\nsettings (where the dynamics and rewards admit a linear underlying\nrepresentation). Notably, our work provides the first sublinear regret\nguarantee which accommodates any deviation from purely i.i.d. transitions in\nthe bandit-feedback model for episodic reinforcement learning.\n", "versions": [{"version": "v1", "created": "Wed, 20 Nov 2019 03:49:13 GMT"}, {"version": "v2", "created": "Wed, 29 Apr 2020 21:20:40 GMT"}], "update_date": "2020-05-01", "authors_parsed": [["Lykouris", "Thodoris", ""], ["Simchowitz", "Max", ""], ["Slivkins", "Aleksandrs", ""], ["Sun", "Wen", ""]]}, {"id": "1911.08743", "submitter": "Preslav Nakov", "authors": "Todor Mihaylov, Preslav Nakov", "title": "SemanticZ at SemEval-2016 Task 3: Ranking Relevant Answers in Community\n  Question Answering Using Semantic Similarity Based on Fine-tuned Word\n  Embeddings", "comments": "community question answering, semantic similarity", "journal-ref": "SemEval-2016", "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe our system for finding good answers in a community forum, as\ndefined in SemEval-2016, Task 3 on Community Question Answering. Our approach\nrelies on several semantic similarity features based on fine-tuned word\nembeddings and topics similarities. In the main Subtask C, our primary\nsubmission was ranked third, with a MAP of 51.68 and accuracy of 69.94. In\nSubtask A, our primary submission was also third, with MAP of 77.58 and\naccuracy of 73.39.\n", "versions": [{"version": "v1", "created": "Wed, 20 Nov 2019 07:16:16 GMT"}], "update_date": "2019-11-21", "authors_parsed": [["Mihaylov", "Todor", ""], ["Nakov", "Preslav", ""]]}, {"id": "1911.08755", "submitter": "Preslav Nakov", "authors": "Shafiq Joty, Alberto Barr\\'on-Cede\\~no, Giovanni Da San Martino,\n  Simone Filice, Llu\\'is M\\`arquez, Alessandro Moschitti, Preslav Nakov", "title": "Global Thread-Level Inference for Comment Classification in Community\n  Question Answering", "comments": "community question answering, thread-level inference, graph-cut,\n  inductive logic programming", "journal-ref": "EMNLP-2015", "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Community question answering, a recent evolution of question answering in the\nWeb context, allows a user to quickly consult the opinion of a number of people\non a particular topic, thus taking advantage of the wisdom of the crowd. Here\nwe try to help the user by deciding automatically which answers are good and\nwhich are bad for a given question. In particular, we focus on exploiting the\noutput structure at the thread level in order to make more consistent global\ndecisions. More specifically, we exploit the relations between pairs of\ncomments at any distance in the thread, which we incorporate in a graph-cut and\nin an ILP frameworks. We evaluated our approach on the benchmark dataset of\nSemEval-2015 Task 3. Results improved over the state of the art, confirming the\nimportance of using thread level information.\n", "versions": [{"version": "v1", "created": "Wed, 20 Nov 2019 08:09:36 GMT"}], "update_date": "2019-11-21", "authors_parsed": [["Joty", "Shafiq", ""], ["Barr\u00f3n-Cede\u00f1o", "Alberto", ""], ["Martino", "Giovanni Da San", ""], ["Filice", "Simone", ""], ["M\u00e0rquez", "Llu\u00eds", ""], ["Moschitti", "Alessandro", ""], ["Nakov", "Preslav", ""]]}, {"id": "1911.08756", "submitter": "Jarom\\'ir Janisch", "authors": "Jarom\\'ir Janisch, Tom\\'a\\v{s} Pevn\\'y and Viliam Lis\\'y", "title": "Hierarchical Multiple-Instance Data Classification with Costly Features", "comments": "RL4RealLife @ ICML2021; code available at\n  https://github.com/jaromiru/rcwcf", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We extend the framework of Classification with Costly Features (CwCF) that\nworks with samples of fixed dimensions to trees of varying depth and breadth\n(similar to a JSON/XML file). In this setting, the sample is a tree - sets of\nsets of features. Individually for each sample, the task is to sequentially\nselect informative features that help the classification. Each feature has a\nreal-valued cost, and the objective is to maximize accuracy while minimizing\nthe total cost. The process is modeled as an MDP where the states represent the\nacquired features, and the actions select unknown features. We present a\nspecialized neural network architecture trained through deep reinforcement\nlearning that naturally fits the data and directly selects features in the\ntree. We demonstrate our method in seven datasets and compare it to two\nbaselines.\n", "versions": [{"version": "v1", "created": "Wed, 20 Nov 2019 08:15:09 GMT"}, {"version": "v2", "created": "Thu, 6 Feb 2020 13:20:38 GMT"}, {"version": "v3", "created": "Mon, 14 Sep 2020 13:21:42 GMT"}, {"version": "v4", "created": "Mon, 26 Jul 2021 13:59:18 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Janisch", "Jarom\u00edr", ""], ["Pevn\u00fd", "Tom\u00e1\u0161", ""], ["Lis\u00fd", "Viliam", ""]]}, {"id": "1911.08762", "submitter": "Preslav Nakov", "authors": "Preslav Nakov", "title": "Paraphrasing Verbs for Noun Compound Interpretation", "comments": "noun compounds, paraphrasing verbs, semantic interpretation,\n  multi-word expressions, MWEs", "journal-ref": "MWE-2008", "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An important challenge for the automatic analysis of English written text is\nthe abundance of noun compounds: sequences of nouns acting as a single noun. In\nour view, their semantics is best characterized by the set of all possible\nparaphrasing verbs, with associated weights, e.g., malaria mosquito is carry\n(23), spread (16), cause (12), transmit (9), etc. Using Amazon's Mechanical\nTurk, we collect paraphrasing verbs for 250 noun-noun compounds previously\nproposed in the linguistic literature, thus creating a valuable resource for\nnoun compound interpretation. Using these verbs, we further construct a dataset\nof pairs of sentences representing a special kind of textual entailment task,\nwhere a binary decision is to be made about whether an expression involving a\nverb and two nouns can be transformed into a noun compound, while preserving\nthe sentence meaning.\n", "versions": [{"version": "v1", "created": "Wed, 20 Nov 2019 08:29:10 GMT"}], "update_date": "2019-11-21", "authors_parsed": [["Nakov", "Preslav", ""]]}, {"id": "1911.08776", "submitter": "Siyu Yao", "authors": "Siyu Yao, Ruijie Wang, Shen Sun, Derui Bu, Jun Liu", "title": "Joint Embedding Learning of Educational Knowledge Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As an efficient model for knowledge organization, the knowledge graph has\nbeen widely adopted in several fields, e.g., biomedicine, sociology, and\neducation. And there is a steady trend of learning embedding representations of\nknowledge graphs to facilitate knowledge graph construction and downstream\ntasks. In general, knowledge graph embedding techniques aim to learn vectorized\nrepresentations which preserve the structural information of the graph. And\nconventional embedding learning models rely on structural relationships among\nentities and relations. However, in educational knowledge graphs, structural\nrelationships are not the focus. Instead, rich literals of the graphs are more\nvaluable. In this paper, we focus on this problem and propose a novel model for\nembedding learning of educational knowledge graphs. Our model considers both\nstructural and literal information and jointly learns embedding\nrepresentations. Three experimental graphs were constructed based on an\neducational knowledge graph which has been applied in real-world teaching. We\nconducted two experiments on the three graphs and other common benchmark\ngraphs. The experimental results proved the effectiveness of our model and its\nsuperiority over other baselines when processing educational knowledge graphs.\n", "versions": [{"version": "v1", "created": "Wed, 20 Nov 2019 09:05:11 GMT"}, {"version": "v2", "created": "Mon, 23 Dec 2019 14:52:03 GMT"}], "update_date": "2019-12-24", "authors_parsed": [["Yao", "Siyu", ""], ["Wang", "Ruijie", ""], ["Sun", "Shen", ""], ["Bu", "Derui", ""], ["Liu", "Jun", ""]]}, {"id": "1911.08780", "submitter": "Ioannis Mollas", "authors": "Ioannis Mollas, Nick Bassiliades, Ioannis Vlahavas, Grigorios\n  Tsoumakas", "title": "LionForests: Local Interpretation of Random Forests", "comments": "8 Pages, 4 Tables, 6 Figures, Submitted to NeHuAI-2020 Workshop of\n  ECAI2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Towards a future where machine learning systems will integrate into every\naspect of people's lives, researching methods to interpret such systems is\nnecessary, instead of focusing exclusively on enhancing their performance.\nEnriching the trust between these systems and people will accelerate this\nintegration process. Many medical and retail banking/finance applications use\nstate-of-the-art machine learning techniques to predict certain aspects of new\ninstances. Tree ensembles, like random forests, are widely acceptable solutions\non these tasks, while at the same time they are avoided due to their black-box\nuninterpretable nature, creating an unreasonable paradox. In this paper, we\nprovide a methodology for shedding light on the predictions of the misjudged\nfamily of tree ensemble algorithms. Using classic unsupervised learning\ntechniques and an enhanced similarity metric, to wander among transparent trees\ninside a forest following breadcrumbs, the interpretable essence of tree\nensembles arises. An interpretation provided by these systems using our\napproach, which we call \"LionForests\", can be a simple, comprehensive rule.\n", "versions": [{"version": "v1", "created": "Wed, 20 Nov 2019 09:18:25 GMT"}, {"version": "v2", "created": "Tue, 10 Mar 2020 13:12:20 GMT"}, {"version": "v3", "created": "Thu, 23 Jul 2020 13:19:52 GMT"}], "update_date": "2020-07-24", "authors_parsed": [["Mollas", "Ioannis", ""], ["Bassiliades", "Nick", ""], ["Vlahavas", "Ioannis", ""], ["Tsoumakas", "Grigorios", ""]]}, {"id": "1911.08799", "submitter": "Sanket Shah", "authors": "Sanket Shah, Arunesh Sinha, Pradeep Varakantham, Andrew Perrault,\n  Milind Tambe", "title": "Solving Online Threat Screening Games using Constrained Action Space\n  Reinforcement Learning", "comments": "Accepted to the Thirty-Fourth AAAI Conference on Artificial\n  Intelligence (AAAI-20)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large-scale screening for potential threats with limited resources and\ncapacity for screening is a problem of interest at airports, seaports, and\nother ports of entry. Adversaries can observe screening procedures and arrive\nat a time when there will be gaps in screening due to limited resource\ncapacities. To capture this game between ports and adversaries, this problem\nhas been previously represented as a Stackelberg game, referred to as a Threat\nScreening Game (TSG). Given the significant complexity associated with solving\nTSGs and uncertainty in arrivals of customers, existing work has assumed that\nscreenees arrive and are allocated security resources at the beginning of the\ntime window. In practice, screenees such as airport passengers arrive in bursts\ncorrelated with flight time and are not bound by fixed time windows. To address\nthis, we propose an online threat screening model in which screening strategy\nis determined adaptively as a passenger arrives while satisfying a hard bound\non acceptable risk of not screening a threat. To solve the online problem with\na hard bound on risk, we formulate it as a Reinforcement Learning (RL) problem\nwith constraints on the action space (hard bound on risk). We provide a novel\nway to efficiently enforce linear inequality constraints on the action output\nin Deep Reinforcement Learning. We show that our solution allows us to\nsignificantly reduce screenee wait time while guaranteeing a bound on risk.\n", "versions": [{"version": "v1", "created": "Wed, 20 Nov 2019 10:15:07 GMT"}], "update_date": "2019-11-21", "authors_parsed": [["Shah", "Sanket", ""], ["Sinha", "Arunesh", ""], ["Varakantham", "Pradeep", ""], ["Perrault", "Andrew", ""], ["Tambe", "Milind", ""]]}, {"id": "1911.08826", "submitter": "Akshay Dharmavaram", "authors": "Akshay Dharmavaram, Matthew Riemer, Shalabh Bhatnagar", "title": "Hierarchical Average Reward Policy Gradient Algorithms", "comments": "6 pages, 3 figures, to be published in Proceedings of the\n  Thirty-Fourth AAAI Conference on Artificial Intelligence", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Option-critic learning is a general-purpose reinforcement learning (RL)\nframework that aims to address the issue of long term credit assignment by\nleveraging temporal abstractions. However, when dealing with extended\ntimescales, discounting future rewards can lead to incorrect credit\nassignments. In this work, we address this issue by extending the hierarchical\noption-critic policy gradient theorem for the average reward criterion. Our\nproposed framework aims to maximize the long-term reward obtained in the\nsteady-state of the Markov chain defined by the agent's policy. Furthermore, we\nuse an ordinary differential equation based approach for our convergence\nanalysis and prove that the parameters of the intra-option policies,\ntermination functions, and value functions, converge to their corresponding\noptimal values, with probability one. Finally, we illustrate the competitive\nadvantage of learning options, in the average reward setting, on a grid-world\nenvironment with sparse rewards.\n", "versions": [{"version": "v1", "created": "Wed, 20 Nov 2019 11:13:48 GMT"}], "update_date": "2019-11-21", "authors_parsed": [["Dharmavaram", "Akshay", ""], ["Riemer", "Matthew", ""], ["Bhatnagar", "Shalabh", ""]]}, {"id": "1911.08833", "submitter": "Kai Sauerwald", "authors": "Kai Sauerwald and Gabriele Kern-Isberner and Christoph Beierle", "title": "A Conditional Perspective for Iterated Belief Contraction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  According to Boutillier, Darwiche, Pearl and others, principles for iterated\nrevision can be characterised in terms of changing beliefs about conditionals.\nFor iterated contraction a similar formulation is not known. This is especially\nbecause for iterated belief change the connection between revision and\ncontraction via the Levi and Harper identity is not straightforward, and\ntherefore, characterisation results do not transfer easily between iterated\nrevision and contraction. In this article, we develop an axiomatisation of\niterated contraction in terms of changing conditional beliefs. We prove that\nthe new set of postulates conforms semantically to the class of operators like\nthe ones given by Konieczny and Pino P\\'erez for iterated contraction.\n", "versions": [{"version": "v1", "created": "Wed, 20 Nov 2019 11:23:17 GMT"}], "update_date": "2019-11-21", "authors_parsed": [["Sauerwald", "Kai", ""], ["Kern-Isberner", "Gabriele", ""], ["Beierle", "Christoph", ""]]}, {"id": "1911.08842", "submitter": "Sanket Shah", "authors": "Sanket Shah, Meghna Lowalekar, Pradeep Varakantham", "title": "Neural Approximate Dynamic Programming for On-Demand Ride-Pooling", "comments": "Accepted for publication to the Thirty-Fourth AAAI Conference on\n  Artificial Intelligence (AAAI-20)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  On-demand ride-pooling (e.g., UberPool) has recently become popular because\nof its ability to lower costs for passengers while simultaneously increasing\nrevenue for drivers and aggregation companies. Unlike in Taxi on Demand (ToD)\nservices -- where a vehicle is only assigned one passenger at a time -- in\non-demand ride-pooling, each (possibly partially filled) vehicle can be\nassigned a group of passenger requests with multiple different origin and\ndestination pairs. To ensure near real-time response, existing solutions to the\nreal-time ride-pooling problem are myopic in that they optimise the objective\n(e.g., maximise the number of passengers served) for the current time step\nwithout considering its effect on future assignments. This is because even a\nmyopic assignment in ride-pooling involves considering what combinations of\npassenger requests that can be assigned to vehicles, which adds a layer of\ncombinatorial complexity to the ToD problem.\n  A popular approach that addresses the limitations of myopic assignments in\nToD problems is Approximate Dynamic Programming (ADP). Existing ADP methods for\nToD can only handle Linear Program (LP) based assignments, however, while the\nassignment problem in ride-pooling requires an Integer Linear Program (ILP)\nwith bad LP relaxations. To this end, our key technical contribution is in\nproviding a general ADP method that can learn from ILP-based assignments.\nAdditionally, we handle the extra combinatorial complexity from combinations of\npassenger requests by using a Neural Network based approximate value function\nand show a connection to Deep Reinforcement Learning that allows us to learn\nthis value-function with increased stability and sample-efficiency. We show\nthat our approach outperforms past approaches on a real-world dataset by up to\n16%, a significant improvement in city-scale transportation problems.\n", "versions": [{"version": "v1", "created": "Wed, 20 Nov 2019 11:52:00 GMT"}], "update_date": "2019-11-21", "authors_parsed": [["Shah", "Sanket", ""], ["Lowalekar", "Meghna", ""], ["Varakantham", "Pradeep", ""]]}, {"id": "1911.08872", "submitter": "Carl Corea", "authors": "Carl Corea, Matthias Thimm", "title": "Towards Inconsistency Measurement in Business Rule Bases", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the application of inconsistency measures to the problem of\nanalysing business rule bases. Due to some intricacies of the domain of\nbusiness rule bases, a straightforward application is not feasible. We\ntherefore develop some new rationality postulates for this setting as well as\nadapt and modify existing inconsistency measures. We further adapt the notion\nof inconsistency values (or culpability measures) for this setting and give a\ncomprehensive feasibility study.\n", "versions": [{"version": "v1", "created": "Tue, 19 Nov 2019 11:20:42 GMT"}], "update_date": "2019-11-21", "authors_parsed": [["Corea", "Carl", ""], ["Thimm", "Matthias", ""]]}, {"id": "1911.08927", "submitter": "Matteo Saveriano", "authors": "Pietro Falco, Abdallah Attawia, Matteo Saveriano and Dongheui Lee", "title": "On Policy Learning Robust to Irreversible Events: An Application to\n  Robotic In-Hand Manipulation", "comments": null, "journal-ref": null, "doi": "10.1109/LRA.2018.2800110", "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this letter, we present an approach for learning in-hand manipulation\nskills with a low-cost, underactuated prosthetic hand in the presence of\nirreversible events. Our approach combines reinforcement learning based on\nvisual perception with low-level reactive control based on tactile perception,\nwhich aims to avoid slipping. The objective of the reinforcement learning level\nconsists not only in fulfilling the in-hand manipulation goal, but also in\nminimizing the intervention of the tactile reactive control. This way, the\noccurrence of object slipping during the learning procedure, which we consider\nan irreversible event, is significantly reduced. When an irreversible event\noccurs, the learning process is considered failed. We show the performance in\ntwo tasks, which consist in reorienting a cup and a bottle only using the\nfingers. The experimental results show that the proposed architecture allows\nreaching the goal in the Cartesian space and reduces significantly the\noccurrence of object slipping during the learning procedure. Moreover, without\nthe proposed synergy between reactive control and reinforcement learning it was\nnot possible to avoid irreversible events and, therefore, to learn the task.\n", "versions": [{"version": "v1", "created": "Wed, 20 Nov 2019 14:19:03 GMT"}], "update_date": "2019-11-21", "authors_parsed": [["Falco", "Pietro", ""], ["Attawia", "Abdallah", ""], ["Saveriano", "Matteo", ""], ["Lee", "Dongheui", ""]]}, {"id": "1911.08935", "submitter": "Guanglin Niu", "authors": "Guanglin Niu, Yongfei Zhang, Bo Li, Peng Cui, Si Liu, Jingyang Li,\n  Xiaowei Zhang", "title": "Rule-Guided Compositional Representation Learning on Knowledge Graphs", "comments": "The full version of a paper accepted to AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Representation learning on a knowledge graph (KG) is to embed entities and\nrelations of a KG into low-dimensional continuous vector spaces. Early KG\nembedding methods only pay attention to structured information encoded in\ntriples, which would cause limited performance due to the structure sparseness\nof KGs. Some recent attempts consider paths information to expand the structure\nof KGs but lack explainability in the process of obtaining the path\nrepresentations. In this paper, we propose a novel Rule and Path-based Joint\nEmbedding (RPJE) scheme, which takes full advantage of the explainability and\naccuracy of logic rules, the generalization of KG embedding as well as the\nsupplementary semantic structure of paths. Specifically, logic rules of\ndifferent lengths (the number of relations in rule body) in the form of Horn\nclauses are first mined from the KG and elaborately encoded for representation\nlearning. Then, the rules of length 2 are applied to compose paths accurately\nwhile the rules of length 1 are explicitly employed to create semantic\nassociations among relations and constrain relation embeddings. Besides, the\nconfidence level of each rule is also considered in optimization to guarantee\nthe availability of applying the rule to representation learning. Extensive\nexperimental results illustrate that RPJE outperforms other state-of-the-art\nbaselines on KG completion task, which also demonstrate the superiority of\nutilizing logic rules as well as paths for improving the accuracy and\nexplainability of representation learning.\n", "versions": [{"version": "v1", "created": "Wed, 20 Nov 2019 14:38:58 GMT"}, {"version": "v2", "created": "Sat, 28 Dec 2019 15:33:17 GMT"}], "update_date": "2020-01-01", "authors_parsed": [["Niu", "Guanglin", ""], ["Zhang", "Yongfei", ""], ["Li", "Bo", ""], ["Cui", "Peng", ""], ["Liu", "Si", ""], ["Li", "Jingyang", ""], ["Zhang", "Xiaowei", ""]]}, {"id": "1911.08936", "submitter": "Wei Hu", "authors": "Zequn Sun, Chengming Wang, Wei Hu, Muhao Chen, Jian Dai, Wei Zhang,\n  Yuzhong Qu", "title": "Knowledge Graph Alignment Network with Gated Multi-hop Neighborhood\n  Aggregation", "comments": "Accepted by the 34th AAAI Conference on Artificial Intelligence (AAAI\n  2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph neural networks (GNNs) have emerged as a powerful paradigm for\nembedding-based entity alignment due to their capability of identifying\nisomorphic subgraphs. However, in real knowledge graphs (KGs), the counterpart\nentities usually have non-isomorphic neighborhood structures, which easily\ncauses GNNs to yield different representations for them. To tackle this\nproblem, we propose a new KG alignment network, namely AliNet, aiming at\nmitigating the non-isomorphism of neighborhood structures in an end-to-end\nmanner. As the direct neighbors of counterpart entities are usually dissimilar\ndue to the schema heterogeneity, AliNet introduces distant neighbors to expand\nthe overlap between their neighborhood structures. It employs an attention\nmechanism to highlight helpful distant neighbors and reduce noises. Then, it\ncontrols the aggregation of both direct and distant neighborhood information\nusing a gating mechanism. We further propose a relation loss to refine entity\nrepresentations. We perform thorough experiments with detailed ablation studies\nand analyses on five entity alignment datasets, demonstrating the effectiveness\nof AliNet.\n", "versions": [{"version": "v1", "created": "Wed, 20 Nov 2019 14:40:23 GMT"}], "update_date": "2019-11-21", "authors_parsed": [["Sun", "Zequn", ""], ["Wang", "Chengming", ""], ["Hu", "Wei", ""], ["Chen", "Muhao", ""], ["Dai", "Jian", ""], ["Zhang", "Wei", ""], ["Qu", "Yuzhong", ""]]}, {"id": "1911.08976", "submitter": "Martin Andrews", "authors": "Yew Ken Chia, Sam Witteveen, Martin Andrews", "title": "Red Dragon AI at TextGraphs 2019 Shared Task: Language Model Assisted\n  Explanation Generation", "comments": "Accepted paper for TextGraphs-13 workshop at EMNLP-IJCNLP 2019. (5\n  pages including references)", "journal-ref": null, "doi": "10.18653/v1/D19-5311", "report-no": null, "categories": "cs.CL cs.AI cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The TextGraphs-13 Shared Task on Explanation Regeneration asked participants\nto develop methods to reconstruct gold explanations for elementary science\nquestions. Red Dragon AI's entries used the language of the questions and\nexplanation text directly, rather than a constructing a separate graph-like\nrepresentation. Our leaderboard submission placed us 3rd in the competition,\nbut we present here three methods of increasing sophistication, each of which\nscored successively higher on the test set after the competition close.\n", "versions": [{"version": "v1", "created": "Wed, 20 Nov 2019 15:41:47 GMT"}], "update_date": "2019-11-26", "authors_parsed": [["Chia", "Yew Ken", ""], ["Witteveen", "Sam", ""], ["Andrews", "Martin", ""]]}, {"id": "1911.09005", "submitter": "Thomas Gilbert", "authors": "Roel Dobbe, Thomas Krendl Gilbert, Yonatan Mintz", "title": "Hard Choices in Artificial Intelligence: Addressing Normative\n  Uncertainty through Sociotechnical Commitments", "comments": "To be presented at the AI for Social Good workshop at NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CY cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As AI systems become prevalent in high stakes domains such as surveillance\nand healthcare, researchers now examine how to design and implement them in a\nsafe manner. However, the potential harms caused by systems to stakeholders in\ncomplex social contexts and how to address these remains unclear. In this\npaper, we explain the inherent normative uncertainty in debates about the\nsafety of AI systems. We then address this as a problem of vagueness by\nexamining its place in the design, training, and deployment stages of AI system\ndevelopment. We adopt Ruth Chang's theory of intuitive comparability to\nillustrate the dilemmas that manifest at each stage. We then discuss how\nstakeholders can navigate these dilemmas by incorporating distinct forms of\ndissent into the development pipeline, drawing on Elizabeth Anderson's work on\nthe epistemic powers of democratic institutions. We outline a framework of\nsociotechnical commitments to formal, substantive and discursive challenges\nthat address normative uncertainty across stakeholders, and propose the\ncultivation of related virtues by those responsible for development.\n", "versions": [{"version": "v1", "created": "Wed, 20 Nov 2019 16:21:12 GMT"}], "update_date": "2019-11-21", "authors_parsed": [["Dobbe", "Roel", ""], ["Gilbert", "Thomas Krendl", ""], ["Mintz", "Yonatan", ""]]}, {"id": "1911.09017", "submitter": "Quanshi Zhang", "authors": "Hao Zhang, Jiayi Chen, Haotian Xue, Quanshi Zhang", "title": "Towards a Unified Evaluation of Explanation Methods without Ground Truth", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a set of criteria to evaluate the objectiveness of\nexplanation methods of neural networks, which is crucial for the development of\nexplainable AI, but it also presents significant challenges. The core challenge\nis that people usually cannot obtain ground-truth explanations of the neural\nnetwork. To this end, we design four metrics to evaluate explanation results\nwithout ground-truth explanations. Our metrics can be broadly applied to nine\nbenchmark methods of interpreting neural networks, which provides new insights\nof explanation methods.\n", "versions": [{"version": "v1", "created": "Wed, 20 Nov 2019 16:44:48 GMT"}], "update_date": "2019-11-21", "authors_parsed": [["Zhang", "Hao", ""], ["Chen", "Jiayi", ""], ["Xue", "Haotian", ""], ["Zhang", "Quanshi", ""]]}, {"id": "1911.09032", "submitter": "Christian Schilling", "authors": "Thomas A. Henzinger and Anna Lukina and Christian Schilling", "title": "Outside the Box: Abstraction-Based Monitoring of Neural Networks", "comments": "accepted at ECAI 2020", "journal-ref": null, "doi": "10.3233/FAIA200375", "report-no": null, "categories": "cs.LG cs.AI cs.LO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks have demonstrated unmatched performance in a range of\nclassification tasks. Despite numerous efforts of the research community,\nnovelty detection remains one of the significant limitations of neural\nnetworks. The ability to identify previously unseen inputs as novel is crucial\nfor our understanding of the decisions made by neural networks. At runtime,\ninputs not falling into any of the categories learned during training cannot be\nclassified correctly by the neural network. Existing approaches treat the\nneural network as a black box and try to detect novel inputs based on the\nconfidence of the output predictions. However, neural networks are not trained\nto reduce their confidence for novel inputs, which limits the effectiveness of\nthese approaches. We propose a framework to monitor a neural network by\nobserving the hidden layers. We employ a common abstraction from program\nanalysis - boxes - to identify novel behaviors in the monitored layers, i.e.,\ninputs that cause behaviors outside the box. For each neuron, the boxes range\nover the values seen in training. The framework is efficient and flexible to\nachieve a desired trade-off between raising false warnings and detecting novel\ninputs. We illustrate the performance and the robustness to variability in the\nunknown classes on popular image-classification benchmarks.\n", "versions": [{"version": "v1", "created": "Wed, 20 Nov 2019 17:03:21 GMT"}, {"version": "v2", "created": "Fri, 29 Nov 2019 10:32:30 GMT"}, {"version": "v3", "created": "Wed, 19 Feb 2020 15:46:18 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Henzinger", "Thomas A.", ""], ["Lukina", "Anna", ""], ["Schilling", "Christian", ""]]}, {"id": "1911.09153", "submitter": "Tyler Lu", "authors": "Ivan Vendrov, Tyler Lu, Qingqing Huang, Craig Boutilier", "title": "Gradient-based Optimization for Bayesian Preference Elicitation", "comments": "To appear in the Thirty-Fourth AAAI Conference on Artificial\n  Intelligence (AAAI-20)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Effective techniques for eliciting user preferences have taken on added\nimportance as recommender systems (RSs) become increasingly interactive and\nconversational. A common and conceptually appealing Bayesian criterion for\nselecting queries is expected value of information (EVOI). Unfortunately, it is\ncomputationally prohibitive to construct queries with maximum EVOI in RSs with\nlarge item spaces. We tackle this issue by introducing a continuous formulation\nof EVOI as a differentiable network that can be optimized using gradient\nmethods available in modern machine learning (ML) computational frameworks\n(e.g., TensorFlow, PyTorch). We exploit this to develop a novel, scalable Monte\nCarlo method for EVOI optimization, which is more scalable for large item\nspaces than methods requiring explicit enumeration of items. While we emphasize\nthe use of this approach for pairwise (or k-wise) comparisons of items, we also\ndemonstrate how our method can be adapted to queries involving subsets of item\nattributes or \"partial items,\" which are often more cognitively manageable for\nusers. Experiments show that our gradient-based EVOI technique achieves\nstate-of-the-art performance across several domains while scaling to large item\nspaces.\n", "versions": [{"version": "v1", "created": "Wed, 20 Nov 2019 20:08:25 GMT"}], "update_date": "2019-11-22", "authors_parsed": [["Vendrov", "Ivan", ""], ["Lu", "Tyler", ""], ["Huang", "Qingqing", ""], ["Boutilier", "Craig", ""]]}, {"id": "1911.09194", "submitter": "Angela Fan", "authors": "Angela Fan, Jack Urbanek, Pratik Ringshia, Emily Dinan, Emma Qian,\n  Siddharth Karamcheti, Shrimai Prabhumoye, Douwe Kiela, Tim Rocktaschel,\n  Arthur Szlam, Jason Weston", "title": "Generating Interactive Worlds with Text", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Procedurally generating cohesive and interesting game environments is\nchallenging and time-consuming. In order for the relationships between the game\nelements to be natural, common-sense has to be encoded into arrangement of the\nelements. In this work, we investigate a machine learning approach for world\ncreation using content from the multi-player text adventure game environment\nLIGHT. We introduce neural network based models to compositionally arrange\nlocations, characters, and objects into a coherent whole. In addition to\ncreating worlds based on existing elements, our models can generate new game\ncontent. Humans can also leverage our models to interactively aid in\nworldbuilding. We show that the game environments created with our approach are\ncohesive, diverse, and preferred by human evaluators compared to other machine\nlearning based world construction algorithms.\n", "versions": [{"version": "v1", "created": "Wed, 20 Nov 2019 22:20:52 GMT"}, {"version": "v2", "created": "Wed, 4 Dec 2019 19:46:21 GMT"}], "update_date": "2019-12-06", "authors_parsed": [["Fan", "Angela", ""], ["Urbanek", "Jack", ""], ["Ringshia", "Pratik", ""], ["Dinan", "Emily", ""], ["Qian", "Emma", ""], ["Karamcheti", "Siddharth", ""], ["Prabhumoye", "Shrimai", ""], ["Kiela", "Douwe", ""], ["Rocktaschel", "Tim", ""], ["Szlam", "Arthur", ""], ["Weston", "Jason", ""]]}, {"id": "1911.09218", "submitter": "Yifeng Gao", "authors": "Yifeng Gao and Jessica Lin", "title": "Discovering Subdimensional Motifs of Different Lengths in Large-Scale\n  Multivariate Time Series", "comments": "Accepted by ICDM 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Detecting repeating patterns of different lengths in time series, also called\nvariable-length motifs, has received a great amount of attention by researchers\nand practitioners. Despite the significant progress that has been made in\nrecent single dimensional variable-length motif discovery work, detecting\nvariable-length \\textit{subdimensional motifs}---patterns that are\nsimultaneously occurring only in a subset of dimensions in multivariate time\nseries---remains a difficult task. The main challenge is scalability. On the\none hand, the brute-force enumeration solution, which searches for motifs of\nall possible lengths, is very time consuming even in single dimensional time\nseries. On the other hand, previous work show that index-based fixed-length\napproximate motif discovery algorithms such as random projection are not\nsuitable for detecting variable-length motifs due to memory requirement. In\nthis paper, we introduce an approximate variable-length subdimensional motif\ndiscovery algorithm called \\textbf{C}ollaborative \\textbf{HI}erarchy based\n\\textbf{M}otif \\textbf{E}numeration (CHIME) to efficiently detect\nvariable-length subdimensional motifs given a minimum motif length in\nlarge-scale multivariate time series. We show that the memory cost of the\napproach is significantly smaller than that of random projection. Moreover, the\nspeed of the proposed algorithm is significantly faster than that of the\nstate-of-the-art algorithms. We demonstrate that CHIME can efficiently detect\nmeaningful variable-length subdimensional motifs in large real world\nmultivariate time series datasets.\n", "versions": [{"version": "v1", "created": "Wed, 20 Nov 2019 23:35:15 GMT"}], "update_date": "2019-11-22", "authors_parsed": [["Gao", "Yifeng", ""], ["Lin", "Jessica", ""]]}, {"id": "1911.09219", "submitter": "Matthew Guzdial", "authors": "Andrew Hoyt, Matthew Guzdial, Yalini Kumar, Gillian Smith, and Mark O.\n  Riedl", "title": "Integrating Automated Play in Level Co-Creation", "comments": "2 pages, 2 figures, AIIDE Workshop on Experimental AI in Games", "journal-ref": "AIIDE Workshop on Experimental AI in Games 2019", "doi": null, "report-no": null, "categories": "cs.AI cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In level co-creation an AI and human work together to create a video game\nlevel. One open challenge in level co-creation is how to empower human users to\nensure particular qualities of the final level, such as challenge. There has\nbeen significant prior research into automated pathing and automated\nplaytesting for video game levels, but not in how to incorporate these into\ntools. In this demonstration we present an improvement of the Morai Maker\nmixed-initiative level editor for Super Mario Bros. that includes automated\npathing and challenge approximation features.\n", "versions": [{"version": "v1", "created": "Wed, 20 Nov 2019 23:36:42 GMT"}], "update_date": "2019-11-22", "authors_parsed": [["Hoyt", "Andrew", ""], ["Guzdial", "Matthew", ""], ["Kumar", "Yalini", ""], ["Smith", "Gillian", ""], ["Riedl", "Mark O.", ""]]}, {"id": "1911.09242", "submitter": "Son Doan <", "authors": "Son Doan, Amanda Ritchart, Nicholas Perry, Juan D Chaparro, Mike\n  Conway", "title": "How Do You #relax When You're #stressed? A Content Analysis and\n  Infodemiology Study of Stress-Related Tweets", "comments": "38 pages,12 figures, 6 tables, 5 Appendix (full version) -- shorter\n  version published in JMIR Public Health Surveill 2017;3(2):e35", "journal-ref": "JMIR Public Health Surveill 2017;3(2):e35", "doi": "10.2196/publichealth.5939", "report-no": null, "categories": "cs.CL cs.AI cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Background: Stress is a contributing factor to many major health problems in\nthe United States, such as heart disease, depression, and autoimmune diseases.\nRelaxation is often recommended in mental health treatment as a frontline\nstrategy to reduce stress, thereby improving health conditions.\n  Objective: The objective of our study was to understand how people express\ntheir feelings of stress and relaxation through Twitter messages.\n  Methods: We first performed a qualitative content analysis of 1326 and 781\ntweets containing the keywords \"stress\" and \"relax\", respectively. We then\ninvestigated the use of machine learning algorithms to automatically classify\ntweets as stress versus non stress and relaxation versus non relaxation.\nFinally, we applied these classifiers to sample datasets drawn from 4 cities\nwith the goal of evaluating the extent of any correlation between our automatic\nclassification of tweets and results from public stress surveys.\n  Results: Content analysis showed that the most frequent topic of stress\ntweets was education, followed by work and social relationships. The most\nfrequent topic of relaxation tweets was rest and vacation, followed by nature\nand water. When we applied the classifiers to the cities dataset, the\nproportion of stress tweets in New York and San Diego was substantially higher\nthan that in Los Angeles and San Francisco.\n  Conclusions: This content analysis and infodemiology study revealed that\nTwitter, when used in conjunction with natural language processing techniques,\nis a useful data source for understanding stress and stress management\nstrategies, and can potentially supplement infrequently collected survey-based\nstress data.\n", "versions": [{"version": "v1", "created": "Thu, 21 Nov 2019 02:08:14 GMT"}, {"version": "v2", "created": "Fri, 22 Nov 2019 19:06:20 GMT"}], "update_date": "2019-12-05", "authors_parsed": [["Doan", "Son", ""], ["Ritchart", "Amanda", ""], ["Perry", "Nicholas", ""], ["Chaparro", "Juan D", ""], ["Conway", "Mike", ""]]}, {"id": "1911.09291", "submitter": "Pablo Samuel Castro", "authors": "Pablo Samuel Castro", "title": "Scalable methods for computing state similarity in deterministic Markov\n  Decision Processes", "comments": "To appear in Proceedings of the Thirty-Fourth AAAI Conference on\n  Artificial Intelligence (AAAI-20)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present new algorithms for computing and approximating bisimulation\nmetrics in Markov Decision Processes (MDPs). Bisimulation metrics are an\nelegant formalism that capture behavioral equivalence between states and\nprovide strong theoretical guarantees on differences in optimal behaviour.\nUnfortunately, their computation is expensive and requires a tabular\nrepresentation of the states, which has thus far rendered them impractical for\nlarge problems. In this paper we present a new version of the metric that is\ntied to a behavior policy in an MDP, along with an analysis of its theoretical\nproperties. We then present two new algorithms for approximating bisimulation\nmetrics in large, deterministic MDPs. The first does so via sampling and is\nguaranteed to converge to the true metric. The second is a differentiable loss\nwhich allows us to learn an approximation even for continuous state MDPs, which\nprior to this work had not been possible.\n", "versions": [{"version": "v1", "created": "Thu, 21 Nov 2019 05:11:20 GMT"}], "update_date": "2019-11-22", "authors_parsed": [["Castro", "Pablo Samuel", ""]]}, {"id": "1911.09304", "submitter": "Hang Jiang", "authors": "Hang Jiang, Xianzhe Zhang, Jinho D. Choi", "title": "Automatic Text-based Personality Recognition on Monologues and\n  Multiparty Dialogues Using Attentive Networks and Contextual Embeddings", "comments": "Paper Accepted to AAAI-20 Student Abstract and Poster Program", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Previous works related to automatic personality recognition focus on using\ntraditional classification models with linguistic features. However, attentive\nneural networks with contextual embeddings, which have achieved huge success in\ntext classification, are rarely explored for this task. In this project, we\nhave two major contributions. First, we create the first dialogue-based\npersonality dataset, FriendsPersona, by annotating 5 personality traits of\nspeakers from Friends TV Show through crowdsourcing. Second, we present a novel\napproach to automatic personality recognition using pre-trained contextual\nembeddings (BERT and RoBERTa) and attentive neural networks. Our models largely\nimprove the state-of-art results on the monologue Essays dataset by 2.49%, and\nestablish a solid benchmark on our FriendsPersona. By comparing results in two\ndatasets, we demonstrate the challenges of modeling personality in multi-party\ndialogue.\n", "versions": [{"version": "v1", "created": "Thu, 21 Nov 2019 06:14:05 GMT"}], "update_date": "2019-11-22", "authors_parsed": [["Jiang", "Hang", ""], ["Zhang", "Xianzhe", ""], ["Choi", "Jinho D.", ""]]}, {"id": "1911.09315", "submitter": "Alberto Barbado Gonzalez", "authors": "Alberto Barbado, \\'Oscar Corcho, Richard Benjamins", "title": "Rule Extraction in Unsupervised Anomaly Detection for Model\n  Explainability: Application to OneClass SVM", "comments": "23 pages, 18 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  OneClass SVM is a popular method for unsupervised anomaly detection. As many\nother methods, it suffers from the black box problem: it is difficult to\njustify, in an intuitive and simple manner, why the decision frontier is\nidentifying data points as anomalous or non anomalous. Such type of problem is\nbeing widely addressed for supervised models. However, it is still an uncharted\narea for unsupervised learning. In this paper, we evaluate several rule\nextraction techniques over OneClass SVM models, as well as present alternative\ndesigns for some of those algorithms. Together with that, we propose algorithms\nto compute metrics related with eXplainable Artificial Intelligence (XAI)\nregarding the \"comprehensibility\", \"representativeness\", \"stability\" and\n\"diversity\" of the extracted rules. We evaluate our proposals with different\ndatasets, including real-world data coming from industry. With this, our\nproposal contributes to extend XAI techniques to unsupervised machine learning\nmodels.\n", "versions": [{"version": "v1", "created": "Thu, 21 Nov 2019 07:14:43 GMT"}, {"version": "v2", "created": "Wed, 1 Apr 2020 11:10:00 GMT"}, {"version": "v3", "created": "Sat, 6 Jun 2020 09:21:27 GMT"}, {"version": "v4", "created": "Mon, 29 Jun 2020 07:07:28 GMT"}, {"version": "v5", "created": "Thu, 1 Apr 2021 08:24:04 GMT"}], "update_date": "2021-04-02", "authors_parsed": [["Barbado", "Alberto", ""], ["Corcho", "\u00d3scar", ""], ["Benjamins", "Richard", ""]]}, {"id": "1911.09355", "submitter": "Weizhu Qian", "authors": "Weizhu Qian, Fabrice Lauri, Franck Gechter", "title": "A Probabilistic Approach for Discovering Daily Human Mobility Patterns\n  with Mobile Data", "comments": "10 pages, 14 figures, journal paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI eess.SP stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Discovering human mobility patterns with geo-location data collected from\nsmartphone users has been a hot research topic in recent years. In this paper,\nwe attempt to discover daily mobile patterns based on GPS data. We view this\nproblem from a probabilistic perspective in order to explore more information\nfrom the original GPS data compared to other conventional methods. A\nnon-parameter Bayesian modeling method, Infinite Gaussian Mixture Model, is\nused to estimate the probability density for the daily mobility. Then, we use\nKullback-Leibler divergence as the metrics to measure the similarity of\ndifferent probability distributions. And combining Infinite Gaussian Mixture\nModel and Kullback-Leibler divergence, we derived an automatic clustering\nalgorithm to discover mobility patterns for each individual user without\nsetting the number of clusters in advance. In the experiments, the\neffectiveness of our method is validated on the real user data collected from\ndifferent users. The results show that the IGMM-based algorithm outperforms the\nGMM-based algorithm. We also test our methods on the dataset with different\nlengths to discover the minimum data length for discovering mobility patterns.\n", "versions": [{"version": "v1", "created": "Thu, 21 Nov 2019 09:17:32 GMT"}], "update_date": "2020-07-02", "authors_parsed": [["Qian", "Weizhu", ""], ["Lauri", "Fabrice", ""], ["Gechter", "Franck", ""]]}, {"id": "1911.09356", "submitter": "Cristina Cornelio PhD", "authors": "Mustafa Canim, Cristina Cornelio, Arun Iyengar, Ryan Musa, Mariano\n  Rodrigez Muro", "title": "Schemaless Queries over Document Tables with Dependencies", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.AI cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unstructured enterprise data such as reports, manuals and guidelines often\ncontain tables. The traditional way of integrating data from these tables is\nthrough a two-step process of table detection/extraction and mapping the table\nlayouts to an appropriate schema. This can be an expensive process. In this\npaper we show that by using semantic technologies (RDF/SPARQL and database\ndependencies) paired with a simple but powerful way to transform tables with\nnon-relational layouts, it is possible to offer query answering services over\nthese tables with minimal manual work or domain-specific mappings. Our method\nenables users to exploit data in tables embedded in documents with little\neffort, not only for simple retrieval queries, but also for structured queries\nthat require joining multiple interrelated tables.\n", "versions": [{"version": "v1", "created": "Thu, 21 Nov 2019 09:20:24 GMT"}], "update_date": "2019-11-22", "authors_parsed": [["Canim", "Mustafa", ""], ["Cornelio", "Cristina", ""], ["Iyengar", "Arun", ""], ["Musa", "Ryan", ""], ["Muro", "Mariano Rodrigez", ""]]}, {"id": "1911.09365", "submitter": "Javier Segovia Aguas", "authors": "Javier Segovia-Aguas and Sergio Jim\\'enez and Anders Jonsson", "title": "Generalized Planning with Positive and Negative Examples", "comments": "Accepted at AAAI-20 (oral presentation)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generalized planning aims at computing an algorithm-like structure\n(generalized plan) that solves a set of multiple planning instances. In this\npaper we define negative examples for generalized planning as planning\ninstances that must not be solved by a generalized plan. With this regard the\npaper extends the notion of validation of a generalized plan as the problem of\nverifying that a given generalized plan solves the set of input positives\ninstances while it fails to solve a given input set of negative examples. This\nnotion of plan validation allows us to define quantitative metrics to asses the\ngeneralization capacity of generalized plans. The paper also shows how to\nincorporate this new notion of plan validation into a compilation for plan\nsynthesis that takes both positive and negative instances as input. Experiments\nshow that incorporating negative examples can accelerate plan synthesis in\nseveral domains and leverage quantitative metrics to evaluate the\ngeneralization capacity of the synthesized plans.\n", "versions": [{"version": "v1", "created": "Thu, 21 Nov 2019 09:41:56 GMT"}], "update_date": "2019-11-22", "authors_parsed": [["Segovia-Aguas", "Javier", ""], ["Jim\u00e9nez", "Sergio", ""], ["Jonsson", "Anders", ""]]}, {"id": "1911.09391", "submitter": "Eivind B{\\o}hn", "authors": "Eivind B{\\o}hn, Signe Moe, Tor Arne Johansen", "title": "Accelerating Reinforcement Learning with Suboptimal Guidance", "comments": "Submitted to IFAC 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement Learning in domains with sparse rewards is a difficult problem,\nand a large part of the training process is often spent searching the state\nspace in a more or less random fashion for any learning signals. For control\nproblems, we often have some controller readily available which might be\nsuboptimal but nevertheless solves the problem to some degree. This controller\ncan be used to guide the initial exploration phase of the learning controller\ntowards reward yielding states, reducing the time before refinement of a viable\npolicy can be initiated. In our work, the agent is guided through an auxiliary\nbehaviour cloning loss which is made conditional on a Q-filter, i.e. it is only\napplied in situations where the critic deems the guiding controller to be\nbetter than the agent. The Q-filter provides a natural way to adjust the\nguidance throughout the training process, allowing the agent to exceed the\nguiding controller in a manner that is adaptive to the task at hand and the\nproficiency of the guiding controller. The contribution of this paper lies in\nidentifying shortcomings in previously proposed implementations of the Q-filter\nconcept, and in suggesting some ways these issues can be mitigated. These\nmodifications are tested on the OpenAI Gym Fetch environments, showing clear\nimprovements in adaptivity and yielding increased performance in all robotic\nenvironments tested.\n", "versions": [{"version": "v1", "created": "Thu, 21 Nov 2019 10:27:46 GMT"}], "update_date": "2019-11-22", "authors_parsed": [["B\u00f8hn", "Eivind", ""], ["Moe", "Signe", ""], ["Johansen", "Tor Arne", ""]]}, {"id": "1911.09471", "submitter": "Sahan Bulathwela", "authors": "Sahan Bulathwela, Maria Perez-Ortiz, Emine Yilmaz and John\n  Shawe-Taylor", "title": "TrueLearn: A Family of Bayesian Algorithms to Match Lifelong Learners to\n  Open Educational Resources", "comments": "In Proceedings of AAAI Conference on Artificial Intelligence 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.IR cs.LG stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recent advances in computer-assisted learning systems and the\navailability of open educational resources today promise a pathway to providing\ncost-efficient, high-quality education to large masses of learners. One of the\nmost ambitious use cases of computer-assisted learning is to build a lifelong\nlearning recommendation system. Unlike short-term courses, lifelong learning\npresents unique challenges, requiring sophisticated recommendation models that\naccount for a wide range of factors such as background knowledge of learners or\nnovelty of the material while effectively maintaining knowledge states of\nmasses of learners for significantly longer periods of time (ideally, a\nlifetime). This work presents the foundations towards building a dynamic,\nscalable and transparent recommendation system for education, modelling\nlearner's knowledge from implicit data in the form of engagement with open\neducational resources. We i) use a text ontology based on Wikipedia to\nautomatically extract knowledge components of educational resources and, ii)\npropose a set of online Bayesian strategies inspired by the well-known areas of\nitem response theory and knowledge tracing. Our proposal, TrueLearn, focuses on\nrecommendations for which the learner has enough background knowledge (so they\nare able to understand and learn from the material), and the material has\nenough novelty that would help the learner improve their knowledge about the\nsubject and keep them engaged. We further construct a large open educational\nvideo lectures dataset and test the performance of the proposed algorithms,\nwhich show clear promise towards building an effective educational\nrecommendation system.\n", "versions": [{"version": "v1", "created": "Thu, 21 Nov 2019 13:56:40 GMT"}], "update_date": "2019-11-22", "authors_parsed": [["Bulathwela", "Sahan", ""], ["Perez-Ortiz", "Maria", ""], ["Yilmaz", "Emine", ""], ["Shawe-Taylor", "John", ""]]}, {"id": "1911.09476", "submitter": "Golnaz Habibi", "authors": "Golnaz Habibi, Nikita Japuria, Jonathan P. How", "title": "Incremental Learning of Motion Primitives for Pedestrian Trajectory\n  Prediction at Intersections", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a novel incremental learning algorithm for pedestrian\nmotion prediction, with the ability to improve the learned model over time when\ndata is incrementally available. In this setup, trajectories are modeled as\nsimple segments called motion primitives. Transitions between motion primitives\nare modeled as Gaussian Processes. When new data is available, the motion\nprimitives learned from the new data are compared with the previous ones by\nmeasuring the inner product of the motion primitive vectors. Similar motion\nprimitives and transitions are fused and novel motion primitives are added to\ncapture newly observed behaviors. The proposed approach is tested and compared\nwith other baselines in intersection scenarios where the data is incrementally\navailable either from a single intersection or from multiple intersections with\ndifferent geometries. In both cases, our method incrementally learns motion\npatterns and outperforms the offline learning approach in terms of prediction\nerrors. The results also show that the model size in our algorithm grows at a\nmuch lower rate than standard incremental learning, where newly learned motion\nprimitives and transitions are simply accumulated over time.\n", "versions": [{"version": "v1", "created": "Thu, 21 Nov 2019 14:06:18 GMT"}], "update_date": "2019-11-22", "authors_parsed": [["Habibi", "Golnaz", ""], ["Japuria", "Nikita", ""], ["How", "Jonathan P.", ""]]}, {"id": "1911.09478", "submitter": "Victor Petr\\'en Bach Hansen", "authors": "Victor Petr\\'en Bach Hansen, Anders S{\\o}gaard", "title": "What Do You Mean `Why?': Resolving Sluices in Conversations", "comments": "Accepted at the 34TH AAAI Conference on Artificial Intelligence\n  (AAAI-2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In conversation, we often ask one-word questions such as `Why?' or `Who?'.\nSuch questions are typically easy for humans to answer, but can be hard for\ncomputers, because their resolution requires retrieving both the right semantic\nframes and the right arguments from context. This paper introduces the novel\nellipsis resolution task of resolving such one-word questions, referred to as\nsluices in linguistics. We present a crowd-sourced dataset containing\nannotations of sluices from over 4,000 dialogues collected from conversational\nQA datasets, as well as a series of strong baseline architectures.\n", "versions": [{"version": "v1", "created": "Thu, 21 Nov 2019 14:09:33 GMT"}], "update_date": "2019-11-22", "authors_parsed": [["Hansen", "Victor Petr\u00e9n Bach", ""], ["S\u00f8gaard", "Anders", ""]]}, {"id": "1911.09488", "submitter": "Toby Walsh", "authors": "Martin Aleksandrov and Toby Walsh", "title": "Online Fair Division: A Survey", "comments": "Accepted by the 34th AAAI Conference on Artificial Intelligence (AAAI\n  2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We survey a burgeoning and promising new research area that considers the\nonline nature of many practical fair division problems. We identify wide\nvariety of such online fair division problems, as well as discuss new\nmechanisms and normative properties that apply to this online setting. The\nonline nature of such fair division problems provides both opportunities and\nchallenges such as the possibility to develop new online mechanisms as well as\nthe difficulty of dealing with an uncertain future.\n", "versions": [{"version": "v1", "created": "Thu, 21 Nov 2019 14:30:34 GMT"}], "update_date": "2019-11-22", "authors_parsed": [["Aleksandrov", "Martin", ""], ["Walsh", "Toby", ""]]}, {"id": "1911.09531", "submitter": "Joao Moreira", "authors": "Remzi Celebi, Joao Rebelo Moreira, Ahmed A. Hassan, Sandeep Ayyar,\n  Lars Ridder, Tobias Kuhn, and Michel Dumontier", "title": "Towards FAIR protocols and workflows: The OpenPREDICT case study", "comments": "Preprint. Submitted to PeerJ on 13th November 2019. 3 appendixes as\n  PDF files", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  It is essential for the advancement of science that scientists and\nresearchers share, reuse and reproduce workflows and protocols used by others.\nThe FAIR principles are a set of guidelines that aim to maximize the value and\nusefulness of research data, and emphasize a number of important points\nregarding the means by which digital objects are found and reused by others.\nThe question of how to apply these principles not just to the static input and\noutput data but also to the dynamic workflows and protocols that consume and\nproduce them is still under debate and poses a number of challenges. In this\npaper we describe our inclusive and overarching approach to apply the FAIR\nprinciples to workflows and protocols and demonstrate its benefits. We apply\nand evaluate our approach on a case study that consists of making the PREDICT\nworkflow, a highly cited drug repurposing workflow, open and FAIR. This\nincludes FAIRification of the involved datasets, as well as applying semantic\ntechnologies to represent and store data about the detailed versions of the\ngeneral protocol, of the concrete workflow instructions, and of their execution\ntraces. A semantic model was proposed to better address these specific\nrequirements and were evaluated by answering competency questions. This\nsemantic model consists of classes and relations from a number of existing\nontologies, including Workflow4ever, PROV, EDAM, and BPMN. This allowed us then\nto formulate and answer new kinds of competency questions. Our evaluation shows\nthe high degree to which our FAIRified OpenPREDICT workflow now adheres to the\nFAIR principles and the practicality and usefulness of being able to answer our\nnew competency questions.\n", "versions": [{"version": "v1", "created": "Wed, 20 Nov 2019 08:53:57 GMT"}], "update_date": "2019-11-22", "authors_parsed": [["Celebi", "Remzi", ""], ["Moreira", "Joao Rebelo", ""], ["Hassan", "Ahmed A.", ""], ["Ayyar", "Sandeep", ""], ["Ridder", "Lars", ""], ["Kuhn", "Tobias", ""], ["Dumontier", "Michel", ""]]}, {"id": "1911.09535", "submitter": "Oluwafemi Azeez", "authors": "Siddharth Ghiya, Oluwafemi Azeez, Brendan Miller", "title": "Agent Probing Interaction Policies", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning in a multi agent system is difficult because these\nsystems are inherently non-stationary in nature. In such a case, identifying\nthe type of the opposite agent is crucial and can help us address this\nnon-stationary environment. We have investigated if we can employ some probing\npolicies which help us better identify the type of the other agent in the\nenvironment. We've made a simplifying assumption that the other agent has a\nstationary policy that our probing policy is trying to approximate. Our work\nextends Environmental Probing Interaction Policy framework to handle multi\nagent environments.\n", "versions": [{"version": "v1", "created": "Thu, 21 Nov 2019 15:20:43 GMT"}, {"version": "v2", "created": "Tue, 26 Nov 2019 17:56:37 GMT"}, {"version": "v3", "created": "Fri, 13 Dec 2019 16:10:42 GMT"}], "update_date": "2019-12-16", "authors_parsed": [["Ghiya", "Siddharth", ""], ["Azeez", "Oluwafemi", ""], ["Miller", "Brendan", ""]]}, {"id": "1911.09539", "submitter": "Andr\\'e Hottung", "authors": "Andr\\'e Hottung and Kevin Tierney", "title": "Neural Large Neighborhood Search for the Capacitated Vehicle Routing\n  Problem", "comments": null, "journal-ref": "ECAI 2020: 443-450", "doi": "10.3233/FAIA200124", "report-no": null, "categories": "cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning how to automatically solve optimization problems has the potential\nto provide the next big leap in optimization technology. The performance of\nautomatically learned heuristics on routing problems has been steadily\nimproving in recent years, but approaches based purely on machine learning are\nstill outperformed by state-of-the-art optimization methods. To close this\nperformance gap, we propose a novel large neighborhood search (LNS) framework\nfor vehicle routing that integrates learned heuristics for generating new\nsolutions. The learning mechanism is based on a deep neural network with an\nattention mechanism and has been especially designed to be integrated into an\nLNS search setting. We evaluate our approach on the capacitated vehicle routing\nproblem (CVRP) and the split delivery vehicle routing problem (SDVRP). On CVRP\ninstances with up to 297 customers, our approach significantly outperforms an\nLNS that uses only handcrafted heuristics and a well-known heuristic from the\nliterature. Furthermore, we show for the CVRP and the SDVRP that our approach\nsurpasses the performance of existing machine learning approaches and comes\nclose to the performance of state-of-the-art optimization approaches.\n", "versions": [{"version": "v1", "created": "Thu, 21 Nov 2019 15:29:41 GMT"}, {"version": "v2", "created": "Mon, 30 Nov 2020 16:45:39 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Hottung", "Andr\u00e9", ""], ["Tierney", "Kevin", ""]]}, {"id": "1911.09587", "submitter": "Matthijs van Leeuwen", "authors": "Micky Faas and Matthijs van Leeuwen", "title": "Vouw: Geometric Pattern Mining using the MDL Principle", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce geometric pattern mining, the problem of finding recurring local\nstructure in discrete, geometric matrices. It differs from existing pattern\nmining problems by identifying complex spatial relations between elements,\nresulting in arbitrarily shaped patterns. After we formalise this new type of\npattern mining, we propose an approach to selecting a set of patterns using the\nMinimum Description Length principle. We demonstrate the potential of our\napproach by introducing Vouw, a heuristic algorithm for mining exact geometric\npatterns. We show that Vouw delivers high-quality results with a synthetic\nbenchmark.\n", "versions": [{"version": "v1", "created": "Thu, 21 Nov 2019 16:28:12 GMT"}, {"version": "v2", "created": "Fri, 22 Nov 2019 18:39:54 GMT"}], "update_date": "2019-11-25", "authors_parsed": [["Faas", "Micky", ""], ["van Leeuwen", "Matthijs", ""]]}, {"id": "1911.09606", "submitter": "Guilherme Lima", "authors": "Guilherme Lima, Rodrigo Costa, Marcio Ferreira Moreno", "title": "An Introduction to Symbolic Artificial Intelligence Applied to\n  Multimedia", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this chapter, we give an introduction to symbolic artificial intelligence\n(AI) and discuss its relation and application to multimedia. We begin by\ndefining what symbolic AI is, what distinguishes it from non-symbolic\napproaches, such as machine learning, and how it can used in the construction\nof advanced multimedia applications. We then introduce description logic (DL)\nand use it to discuss symbolic representation and reasoning. DL is the logical\nunderpinning of OWL, the most successful family of ontology languages. After\ndiscussing DL, we present OWL and related Semantic Web technologies, such as\nRDF and SPARQL. We conclude the chapter by discussing a hybrid model for\nmultimedia representation, called Hyperknowledge. Throughout the text, we make\nreferences to technologies and extensions specifically designed to solve the\nkinds of problems that arise in multimedia representation.\n", "versions": [{"version": "v1", "created": "Thu, 21 Nov 2019 17:01:36 GMT"}, {"version": "v2", "created": "Thu, 28 Nov 2019 13:11:21 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Lima", "Guilherme", ""], ["Costa", "Rodrigo", ""], ["Moreno", "Marcio Ferreira", ""]]}, {"id": "1911.09709", "submitter": "Reid Pryzant", "authors": "Reid Pryzant, Richard Diehl Martinez, Nathan Dass, Sadao Kurohashi,\n  Dan Jurafsky, Diyi Yang", "title": "Automatically Neutralizing Subjective Bias in Text", "comments": "To appear at AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Texts like news, encyclopedias, and some social media strive for objectivity.\nYet bias in the form of inappropriate subjectivity - introducing attitudes via\nframing, presupposing truth, and casting doubt - remains ubiquitous. This kind\nof bias erodes our collective trust and fuels social conflict. To address this\nissue, we introduce a novel testbed for natural language generation:\nautomatically bringing inappropriately subjective text into a neutral point of\nview (\"neutralizing\" biased text). We also offer the first parallel corpus of\nbiased language. The corpus contains 180,000 sentence pairs and originates from\nWikipedia edits that removed various framings, presuppositions, and attitudes\nfrom biased sentences. Last, we propose two strong encoder-decoder baselines\nfor the task. A straightforward yet opaque CONCURRENT system uses a BERT\nencoder to identify subjective words as part of the generation process. An\ninterpretable and controllable MODULAR algorithm separates these steps, using\n(1) a BERT-based classifier to identify problematic words and (2) a novel join\nembedding through which the classifier can edit the hidden states of the\nencoder. Large-scale human evaluation across four domains (encyclopedias, news\nheadlines, books, and political speeches) suggests that these algorithms are a\nfirst step towards the automatic identification and reduction of bias.\n", "versions": [{"version": "v1", "created": "Thu, 21 Nov 2019 19:15:03 GMT"}, {"version": "v2", "created": "Thu, 5 Dec 2019 16:30:40 GMT"}, {"version": "v3", "created": "Thu, 12 Dec 2019 16:04:17 GMT"}], "update_date": "2019-12-13", "authors_parsed": [["Pryzant", "Reid", ""], ["Martinez", "Richard Diehl", ""], ["Dass", "Nathan", ""], ["Kurohashi", "Sadao", ""], ["Jurafsky", "Dan", ""], ["Yang", "Diyi", ""]]}, {"id": "1911.09724", "submitter": "Xiuyuan Lu", "authors": "Xiuyuan Lu, Benjamin Van Roy", "title": "Information-Theoretic Confidence Bounds for Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We integrate information-theoretic concepts into the design and analysis of\noptimistic algorithms and Thompson sampling. By making a connection between\ninformation-theoretic quantities and confidence bounds, we obtain results that\nrelate the per-period performance of the agent with its information gain about\nthe environment, thus explicitly characterizing the exploration-exploitation\ntradeoff. The resulting cumulative regret bound depends on the agent's\nuncertainty over the environment and quantifies the value of prior information.\nWe show applicability of this approach to several environments, including\nlinear bandits, tabular MDPs, and factored MDPs. These examples demonstrate the\npotential of a general information-theoretic approach for the design and\nanalysis of reinforcement learning algorithms.\n", "versions": [{"version": "v1", "created": "Thu, 21 Nov 2019 19:48:43 GMT"}], "update_date": "2019-11-25", "authors_parsed": [["Lu", "Xiuyuan", ""], ["Van Roy", "Benjamin", ""]]}, {"id": "1911.09763", "submitter": "Arash Shaban-Nejad", "authors": "Nii Antiaye Addy, Arash Shaban-Nejad, David L. Buckeridge, Laurette\n  Dub\\'e", "title": "An Innovative Approach to Addressing Childhood Obesity: A\n  Knowledge-Based Infrastructure for Supporting Multi-Stakeholder Partnership\n  Decision-Making in Quebec, Canada", "comments": null, "journal-ref": "Int J Environ Res Public Health. 2015 Jan 23;12(2):1314-33", "doi": "10.3390/ijerph120201314", "report-no": null, "categories": "cs.CY cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The purpose of this paper is to describe and analyze the development of a\nknowledge-based infrastructure to support MSP decision-making processes. The\npaper emerged from a study to define specifications for a knowledge-based\ninfrastructure to provide decision support for community-level MSPs in the\nCanadian province of Quebec. As part of the study, a process assessment was\nconducted to understand the needs of communities as they collect, organize, and\nanalyze data to make decisions about their priorities. The result of this\nprocess is a portrait, which is an epidemiological profile of health and\nnutrition in their community. Portraits inform strategic planning and\ndevelopment of interventions and are used to assess the impact of\ninterventions. Our key findings indicate ambiguities and disagreement among MSP\ndecision-makers regarding causal relationships between actions and outcomes,\nand the relevant data needed for making decisions. MSP decision-makers\nexpressed a desire for easy-to-use tools that facilitate the collection,\norganization, synthesis, and analysis of data, to enable decision-making in a\ntimely manner. Findings inform conceptual modeling and ontological analysis to\ncapture the domain knowledge and specify relationships between actions and\noutcomes. This modeling and analysis provide the foundation for an ontology,\nencoded using OWL 2 Web Ontology Language. The ontology is developed to provide\nsemantic support for the MSP process, defining objectives, strategies, actions,\nindicators, and data sources. In the future, software interacting with the\nontology can facilitate interactive browsing by decision-makers in the MSP in\nthe form of concepts, instances, relationships, and axioms. Our ontology also\nfacilitates the integration and interpretation of community data and can help\nin managing semantic interoperability between different knowledge sources.\n", "versions": [{"version": "v1", "created": "Thu, 21 Nov 2019 21:42:38 GMT"}], "update_date": "2019-11-25", "authors_parsed": [["Addy", "Nii Antiaye", ""], ["Shaban-Nejad", "Arash", ""], ["Buckeridge", "David L.", ""], ["Dub\u00e9", "Laurette", ""]]}, {"id": "1911.09782", "submitter": "Jonathan Connell", "authors": "Jonathan Connell", "title": "Verbal Programming of Robot Behavior", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Home robots may come with many sophisticated built-in abilities, however\nthere will always be a degree of customization needed for each user and\nenvironment. Ideally this should be accomplished through one-shot learning, as\ncollecting the large number of examples needed for statistical inference is\ntedious. A particularly appealing approach is to simply explain to the robot,\nvia speech, what it should be doing. In this paper we describe the ALIA\ncognitive architecture that is able to effectively incorporate user-supplied\nadvice and prohibitions in this manner. The functioning of the implemented\nsystem on a small robot is illustrated by an associated video.\n", "versions": [{"version": "v1", "created": "Thu, 21 Nov 2019 23:13:25 GMT"}], "update_date": "2019-11-25", "authors_parsed": [["Connell", "Jonathan", ""]]}, {"id": "1911.09813", "submitter": "Barton Lee", "authors": "Haris Aziz, Hau Chan, Barton E. Lee, Bo Li, Toby Walsh", "title": "Facility Location Problem with Capacity Constraints: Algorithmic and\n  Mechanism Design Perspectives", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.AI econ.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the facility location problem in the one-dimensional setting\nwhere each facility can serve a limited number of agents from the algorithmic\nand mechanism design perspectives. From the algorithmic perspective, we prove\nthat the corresponding optimization problem, where the goal is to locate\nfacilities to minimize either the total cost to all agents or the maximum cost\nof any agent is NP-hard. However, we show that the problem is fixed-parameter\ntractable, and the optimal solution can be computed in polynomial time whenever\nthe number of facilities is bounded, or when all facilities have identical\ncapacities. We then consider the problem from a mechanism design perspective\nwhere the agents are strategic and need not reveal their true locations. We\nshow that several natural mechanisms studied in the uncapacitated setting\neither lose strategyproofness or a bound on the solution quality for the total\nor maximum cost objective. We then propose new mechanisms that are\nstrategyproof and achieve approximation guarantees that almost match the lower\nbounds.\n", "versions": [{"version": "v1", "created": "Fri, 22 Nov 2019 02:14:34 GMT"}], "update_date": "2019-11-25", "authors_parsed": [["Aziz", "Haris", ""], ["Chan", "Hau", ""], ["Lee", "Barton E.", ""], ["Li", "Bo", ""], ["Walsh", "Toby", ""]]}, {"id": "1911.09821", "submitter": "Canran Xu", "authors": "Canran Xu, Ming Wu", "title": "Learning Feature Interactions with Lorentzian Factorization Machine", "comments": "8 pages, 5 figures, accepted to AAAI-2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning representations for feature interactions to model user behaviors is\ncritical for recommendation system and click-trough rate (CTR) predictions.\nRecent advances in this area are empowered by deep learning methods which could\nlearn sophisticated feature interactions and achieve the state-of-the-art\nresult in an end-to-end manner. These approaches require large number of\ntraining parameters integrated with the low-level representations, and thus are\nmemory and computational inefficient. In this paper, we propose a new model\nnamed \"LorentzFM\" that can learn feature interactions embedded in a hyperbolic\nspace in which the violation of triangle inequality for Lorentz distances is\navailable. To this end, the learned representation is benefited by the peculiar\ngeometric properties of hyperbolic triangles, and result in a significant\nreduction in the number of parameters (20\\% to 80\\%) because all the top deep\nlearning layers are not required. With such a lightweight architecture,\nLorentzFM achieves comparable and even materially better results than the deep\nlearning methods such as DeepFM, xDeepFM and Deep \\& Cross in both\nrecommendation and CTR prediction tasks.\n", "versions": [{"version": "v1", "created": "Fri, 22 Nov 2019 02:43:39 GMT"}], "update_date": "2019-11-26", "authors_parsed": [["Xu", "Canran", ""], ["Wu", "Ming", ""]]}, {"id": "1911.09853", "submitter": "Sheikh Rabiul Islam", "authors": "Sheikh Rabiul Islam, William Eberle, Sheikh K. Ghafoor, Ambareen\n  Siraj, and Mike Rogers", "title": "Domain Knowledge Aided Explainable Artificial Intelligence for Intrusion\n  Detection and Response", "comments": "Accepted to be published in the Proceedings of the AAAI 2020 Spring\n  Symposium on Combining Machine Learning and Knowledge Engineering in Practice\n  (AAAI-MAKE 2020). Stanford University, Palo Alto, California, USA, March\n  23-25, 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Artificial Intelligence (AI) has become an integral part of modern-day\nsecurity solutions for its ability to learn very complex functions and handling\n\"Big Data\". However, the lack of explainability and interpretability of\nsuccessful AI models is a key stumbling block when trust in a model's\nprediction is critical. This leads to human intervention, which in turn results\nin a delayed response or decision. While there have been major advancements in\nthe speed and performance of AI-based intrusion detection systems, the response\nis still at human speed when it comes to explaining and interpreting a specific\nprediction or decision. In this work, we infuse popular domain knowledge (i.e.,\nCIA principles) in our model for better explainability and validate the\napproach on a network intrusion detection test case. Our experimental results\nsuggest that the infusion of domain knowledge provides better explainability as\nwell as a faster decision or response. In addition, the infused domain\nknowledge generalizes the model to work well with unknown attacks, as well as\nopens the path to adapt to a large stream of network traffic from numerous IoT\ndevices.\n", "versions": [{"version": "v1", "created": "Fri, 22 Nov 2019 04:36:46 GMT"}, {"version": "v2", "created": "Sat, 22 Feb 2020 18:11:36 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Islam", "Sheikh Rabiul", ""], ["Eberle", "William", ""], ["Ghafoor", "Sheikh K.", ""], ["Siraj", "Ambareen", ""], ["Rogers", "Mike", ""]]}, {"id": "1911.09882", "submitter": "Nikki Lijing Kuang", "authors": "Nikki Lijing Kuang and Clement H.C. Leung", "title": "Analysis of Evolutionary Behavior in Self-Learning Media Search Engines", "comments": "IEEE BigData 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.IR cs.LG cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The diversity of intrinsic qualities of multimedia entities tends to impede\ntheir effective retrieval. In a SelfLearning Search Engine architecture, the\nsubtle nuances of human perceptions and deep knowledge are taught and captured\nthrough unsupervised reinforcement learning, where the degree of reinforcement\nmay be suitably calibrated. Such architectural paradigm enables indexes to\nevolve naturally while accommodating the dynamic changes of user interests. It\noperates by continuously constructing indexes over time, while injecting\nprogressive improvement in search performance. For search operations to be\neffective, convergence of index learning is of crucial importance to ensure\nefficiency and robustness. In this paper, we develop a Self-Learning Search\nEngine architecture based on reinforcement learning using a Markov Decision\nProcess framework. The balance between exploration and exploitation is achieved\nthrough evolutionary exploration Strategies. The evolutionary index learning\nbehavior is then studied and formulated using stochastic analysis. Experimental\nresults are presented which corroborate the steady convergence of the index\nevolution mechanism. Index Term\n", "versions": [{"version": "v1", "created": "Fri, 22 Nov 2019 06:43:56 GMT"}], "update_date": "2019-11-25", "authors_parsed": [["Kuang", "Nikki Lijing", ""], ["Leung", "Clement H. C.", ""]]}, {"id": "1911.09969", "submitter": "Ruixue Liu", "authors": "Meng Chen, Ruixue Liu, Lei Shen, Shaozu Yuan, Jingyan Zhou, Youzheng\n  Wu, Xiaodong He, Bowen Zhou", "title": "The JDDC Corpus: A Large-Scale Multi-Turn Chinese Dialogue Dataset for\n  E-commerce Customer Service", "comments": "This paper is accepted by LREC 2020 (International Conference on\n  Language Resources and Evaluation )", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Human conversations are complicated and building a human-like dialogue agent\nis an extremely challenging task. With the rapid development of deep learning\ntechniques, data-driven models become more and more prevalent which need a huge\namount of real conversation data. In this paper, we construct a large-scale\nreal scenario Chinese E-commerce conversation corpus, JDDC, with more than 1\nmillion multi-turn dialogues, 20 million utterances, and 150 million words. The\ndataset reflects several characteristics of human-human conversations, e.g.,\ngoal-driven, and long-term dependency among the context. It also covers various\ndialogue types including task-oriented, chitchat and question-answering. Extra\nintent information and three well-annotated challenge sets are also provided.\nThen, we evaluate several retrieval-based and generative models to provide\nbasic benchmark performance on the JDDC corpus. And we hope JDDC can serve as\nan effective testbed and benefit the development of fundamental research in\ndialogue task\n", "versions": [{"version": "v1", "created": "Fri, 22 Nov 2019 10:55:50 GMT"}, {"version": "v2", "created": "Mon, 25 Nov 2019 08:38:17 GMT"}, {"version": "v3", "created": "Wed, 18 Mar 2020 08:12:30 GMT"}, {"version": "v4", "created": "Tue, 24 Mar 2020 15:09:18 GMT"}], "update_date": "2020-03-25", "authors_parsed": [["Chen", "Meng", ""], ["Liu", "Ruixue", ""], ["Shen", "Lei", ""], ["Yuan", "Shaozu", ""], ["Zhou", "Jingyan", ""], ["Wu", "Youzheng", ""], ["He", "Xiaodong", ""], ["Zhou", "Bowen", ""]]}, {"id": "1911.09994", "submitter": "Nikhil Koditala K", "authors": "Vinay Annam, Nikhil Koditala and Radhika Mamidi", "title": "Anaphora Resolution in Dialogue Systems for South Asian Languages", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Anaphora resolution is a challenging task which has been the interest of NLP\nresearchers for a long time. Traditional resolution techniques like eliminative\nconstraints and weighted preferences were successful in many languages.\nHowever, they are ineffective in free word order languages like most SouthAsian\nlanguages.Heuristic and rule-based techniques were typical in these languages,\nwhich are constrained to context and domain.In this paper, we venture a new\nstrategy us-ing neural networks for resolving anaphora in human-human\ndialogues. The architecture chiefly consists of three components, a shallow\nparser for extracting features, a feature vector generator which produces the\nword embed-dings, and a neural network model which will predict the antecedent\nmention of an anaphora.The system has been trained and tested on Telugu\nconversation corpus we generated. Given the advantage of the semantic\ninformation in word embeddings and appending actor, gender, number, person and\npart of plural features the model has reached an F1-score of 86.\n", "versions": [{"version": "v1", "created": "Fri, 22 Nov 2019 12:20:44 GMT"}], "update_date": "2019-11-25", "authors_parsed": [["Annam", "Vinay", ""], ["Koditala", "Nikhil", ""], ["Mamidi", "Radhika", ""]]}, {"id": "1911.10073", "submitter": "Abolfazl Asudeh", "authors": "Abolfazl Asudeh and H. V. Jagadish", "title": "Responsible Scoring Mechanisms Through Function Sampling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Human decision-makers often receive assistance from data-driven algorithmic\nsystems that provide a score for evaluating objects, including individuals. The\nscores are generated by a function (mechanism) that takes a set of features as\ninput and generates a score.The scoring functions are either machine-learned or\nhuman-designed and can be used for different decision purposes such as ranking\nor classification.\n  Given the potential impact of these scoring mechanisms on individuals' lives\nand on society, it is important to make sure these scores are computed\nresponsibly. Hence we need tools for responsible scoring mechanism design. In\nthis paper, focusing on linear scoring functions, we highlight the importance\nof unbiased function sampling and perturbation in the function space for\ndevising such tools. We provide unbiased samplers for the entire function\nspace, as well as a $\\theta$-vicinity around a given function.\n  We then illustrate the value of these samplers for designing effective\nalgorithms in three diverse problem scenarios in the context of ranking.\nFinally, as a fundamental method for designing responsible scoring mechanisms,\nwe propose a novel approach for approximating the construction of the\narrangement of hyperplanes. Despite the exponential complexity of an\narrangement in the number of dimensions, using function sampling, our algorithm\nis linear in the number of samples and hyperplanes, and independent of the\nnumber of dimensions.\n", "versions": [{"version": "v1", "created": "Fri, 22 Nov 2019 15:05:26 GMT"}], "update_date": "2019-11-25", "authors_parsed": [["Asudeh", "Abolfazl", ""], ["Jagadish", "H. V.", ""]]}, {"id": "1911.10074", "submitter": "Mariane Maynard", "authors": "Mariane Maynard, Thibault Duhamel, Froduald Kabanza", "title": "Cost-Based Goal Recognition Meets Deep Learning", "comments": "An earlier version of this paper was published in PAIR (AAAI 2019\n  workshop)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ability to observe the effects of actions performed by others and to\ninfer their intent, most likely goals, or course of action, is known as a plan\nor intention recognition cognitive capability and has long been one of the\nfundamental research challenges in AI. Deep learning has recently been making\nsignificant inroads on various pattern recognition problems, except for\nintention recognition. While extensively explored since the seventies, the\nproblem remains unsolved for most interesting cases in various areas, ranging\nfrom natural language understanding to human behavior understanding based on\nvideo feeds. This paper compares symbolic inverse planning, one of the most\ninvestigated approaches to goal recognition, to deep learning using CNN and\nLTSM neural network architectures, on five synthetic benchmarks often used in\nthe literature. The results show that the deep learning approach achieves\nbetter goal-prediction accuracy and timeliness than the symbolic cost-based\nplan recognizer in these domains. Although preliminary, these results point to\ninteresting future research avenues.\n", "versions": [{"version": "v1", "created": "Fri, 22 Nov 2019 15:09:14 GMT"}], "update_date": "2019-11-26", "authors_parsed": [["Maynard", "Mariane", ""], ["Duhamel", "Thibault", ""], ["Kabanza", "Froduald", ""]]}, {"id": "1911.10091", "submitter": "Yucheng Zhu", "authors": "Yucheng Zhu, Yanrong Ji, Yueying Zhang, Linxin Xu, Aven Le Zhou,\n  Ellick Chan", "title": "Machine: The New Art Connoisseur", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CV", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The process of identifying and understanding art styles to discover artistic\ninfluences is essential to the study of art history. Traditionally, trained\nexperts review fine details of the works and compare them to other known works.\nTo automate and scale this task, we use several state-of-the-art CNN\narchitectures to explore how a machine may help perceive and quantify art\nstyles. This study explores: (1) How accurately can a machine classify art\nstyles? (2) What may be the underlying relationships among different styles and\nartists? To help answer the first question, our best-performing model using\nInception V3 achieves a 9-class classification accuracy of 88.35%, which\noutperforms the model in Elgammal et al.'s study by more than 20 percent.\nVisualizations using Grad-CAM heat maps confirm that the model correctly\nfocuses on the characteristic parts of paintings. To help address the second\nquestion, we conduct network analysis on the influences among styles and\nartists by extracting 512 features from the best-performing classification\nmodel. Through 2D and 3D T-SNE visualizations, we observe clear chronological\npatterns of development and separation among the art styles. The network\nanalysis also appears to show anticipated artist level connections from an art\nhistorical perspective. This technique appears to help identify some previously\nunknown linkages that may shed light upon new directions for further\nexploration by art historians. We hope that humans and machines working in\nconcert may bring new opportunities to the field.\n", "versions": [{"version": "v1", "created": "Fri, 22 Nov 2019 15:44:56 GMT"}, {"version": "v2", "created": "Tue, 3 Dec 2019 18:19:34 GMT"}], "update_date": "2019-12-04", "authors_parsed": [["Zhu", "Yucheng", ""], ["Ji", "Yanrong", ""], ["Zhang", "Yueying", ""], ["Xu", "Linxin", ""], ["Zhou", "Aven Le", ""], ["Chan", "Ellick", ""]]}, {"id": "1911.10092", "submitter": "Jayanta Mandi", "authors": "Jaynta Mandi, Emir Demirovi\\'c, Peter. J Stuckey, Tias Guns", "title": "Smart Predict-and-Optimize for Hard Combinatorial Optimization Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Combinatorial optimization assumes that all parameters of the optimization\nproblem, e.g. the weights in the objective function is fixed. Often, these\nweights are mere estimates and increasingly machine learning techniques are\nused to for their estimation. Recently, Smart Predict and Optimize (SPO) has\nbeen proposed for problems with a linear objective function over the\npredictions, more specifically linear programming problems. It takes the regret\nof the predictions on the linear problem into account, by repeatedly solving it\nduring learning. We investigate the use of SPO to solve more realistic discrete\noptimization problems. The main challenge is the repeated solving of the\noptimization problem. To this end, we investigate ways to relax the problem as\nwell as warmstarting the learning and the solving. Our results show that even\nfor discrete problems it often suffices to train by solving the relaxation in\nthe SPO loss. Furthermore, this approach outperforms, for most instances, the\nstate-of-the-art approach of Wilder, Dilkina, and Tambe. We experiment with\nweighted knapsack problems as well as complex scheduling problems and show for\nthe first time that a predict-and-optimize approach can successfully be used on\nlarge-scale combinatorial optimization problems.\n", "versions": [{"version": "v1", "created": "Fri, 22 Nov 2019 15:45:26 GMT"}], "update_date": "2019-11-25", "authors_parsed": [["Mandi", "Jaynta", ""], ["Demirovi\u0107", "Emir", ""], ["Stuckey", "Peter. J", ""], ["Guns", "Tias", ""]]}, {"id": "1911.10104", "submitter": "Sheikh Rabiul Islam", "authors": "Sheikh Rabiul Islam, William Eberle, Sheikh K. Ghafoor", "title": "Towards Quantification of Explainability in Explainable Artificial\n  Intelligence Methods", "comments": "Submitted to FLAIRS-33", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI q-fin.RM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Artificial Intelligence (AI) has become an integral part of domains such as\nsecurity, finance, healthcare, medicine, and criminal justice. Explaining the\ndecisions of AI systems in human terms is a key challenge--due to the high\ncomplexity of the model, as well as the potential implications on human\ninterests, rights, and lives . While Explainable AI is an emerging field of\nresearch, there is no consensus on the definition, quantification, and\nformalization of explainability. In fact, the quantification of explainability\nis an open challenge. In our previous work, we incorporated domain knowledge\nfor better explainability, however, we were unable to quantify the extent of\nexplainability. In this work, we (1) briefly analyze the definitions of\nexplainability from the perspective of different disciplines (e.g., psychology,\nsocial science), properties of explanation, explanation methods, and\nhuman-friendly explanations; and (2) propose and formulate an approach to\nquantify the extent of explainability. Our experimental result suggests a\nreasonable and model-agnostic way to quantify explainability\n", "versions": [{"version": "v1", "created": "Fri, 22 Nov 2019 16:03:52 GMT"}], "update_date": "2019-11-25", "authors_parsed": [["Islam", "Sheikh Rabiul", ""], ["Eberle", "William", ""], ["Ghafoor", "Sheikh K.", ""]]}, {"id": "1911.10120", "submitter": "Timothy Verstraeten", "authors": "Timothy Verstraeten and Eugenio Bargiacchi and Pieter JK Libin and Jan\n  Helsen and Diederik M Roijers and Ann Now\\'e", "title": "Multi-Agent Thompson Sampling for Bandit Applications with Sparse\n  Neighbourhood Structures", "comments": null, "journal-ref": "Sci Rep 10, 6728 (2020)", "doi": "10.1038/s41598-020-62939-3", "report-no": null, "categories": "cs.LG cs.AI cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-agent coordination is prevalent in many real-world applications.\nHowever, such coordination is challenging due to its combinatorial nature. An\nimportant observation in this regard is that agents in the real world often\nonly directly affect a limited set of neighbouring agents. Leveraging such\nloose couplings among agents is key to making coordination in multi-agent\nsystems feasible. In this work, we focus on learning to coordinate.\nSpecifically, we consider the multi-agent multi-armed bandit framework, in\nwhich fully cooperative loosely-coupled agents must learn to coordinate their\ndecisions to optimize a common objective. We propose multi-agent Thompson\nsampling (MATS), a new Bayesian exploration-exploitation algorithm that\nleverages loose couplings. We provide a regret bound that is sublinear in time\nand low-order polynomial in the highest number of actions of a single agent for\nsparse coordination graphs. Additionally, we empirically show that MATS\noutperforms the state-of-the-art algorithm, MAUCE, on two synthetic benchmarks,\nand a novel benchmark with Poisson distributions. An example of a\nloosely-coupled multi-agent system is a wind farm. Coordination within the wind\nfarm is necessary to maximize power production. As upstream wind turbines only\naffect nearby downstream turbines, we can use MATS to efficiently learn the\noptimal control mechanism for the farm. To demonstrate the benefits of our\nmethod toward applications we apply MATS to a realistic wind farm control task.\nIn this task, wind turbines must coordinate their alignments with respect to\nthe incoming wind vector in order to optimize power production. Our results\nshow that MATS improves significantly upon state-of-the-art coordination\nmethods in terms of performance, demonstrating the value of using MATS in\npractical applications with sparse neighbourhood structures.\n", "versions": [{"version": "v1", "created": "Fri, 22 Nov 2019 16:21:25 GMT"}, {"version": "v2", "created": "Fri, 7 Feb 2020 10:42:24 GMT"}], "update_date": "2020-06-25", "authors_parsed": [["Verstraeten", "Timothy", ""], ["Bargiacchi", "Eugenio", ""], ["Libin", "Pieter JK", ""], ["Helsen", "Jan", ""], ["Roijers", "Diederik M", ""], ["Now\u00e9", "Ann", ""]]}, {"id": "1911.10121", "submitter": "Timothy Verstraeten", "authors": "Timothy Verstraeten and Pieter JK Libin and Ann Now\\'e", "title": "Fleet Control using Coregionalized Gaussian Process Policy Iteration", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many settings, as for example wind farms, multiple machines are\ninstantiated to perform the same task, which is called a fleet. The recent\nadvances with respect to the Internet of Things allow control devices and/or\nmachines to connect through cloud-based architectures in order to share\ninformation about their status and environment. Such an infrastructure allows\nseamless data sharing between fleet members, which could greatly improve the\nsample-efficiency of reinforcement learning techniques. However in practice,\nthese machines, while almost identical in design, have small discrepancies due\nto production errors or degradation, preventing control algorithms to simply\naggregate and employ all fleet data. We propose a novel reinforcement learning\nmethod that learns to transfer knowledge between similar fleet members and\ncreates member-specific dynamics models for control. Our algorithm uses\nGaussian processes to establish cross-member covariances. This is significantly\ndifferent from standard transfer learning methods, as the focus is not on\nsharing information over tasks, but rather over system specifications. We\ndemonstrate our approach on two benchmarks and a realistic wind farm setting.\nOur method significantly outperforms two baseline approaches, namely individual\nlearning and joint learning where all samples are aggregated, in terms of the\nmedian and variance of the results.\n", "versions": [{"version": "v1", "created": "Fri, 22 Nov 2019 16:23:34 GMT"}], "update_date": "2019-11-25", "authors_parsed": [["Verstraeten", "Timothy", ""], ["Libin", "Pieter JK", ""], ["Now\u00e9", "Ann", ""]]}, {"id": "1911.10134", "submitter": "Thibault Duhamel", "authors": "Thibault Duhamel, Mariane Maynard, Froduald Kabanza", "title": "A Transfer Learning Method for Goal Recognition Exploiting Cross-Domain\n  Spatial Features", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ability to infer the intentions of others, predict their goals, and\ndeduce their plans are critical features for intelligent agents. For a long\ntime, several approaches investigated the use of symbolic representations and\ninferences with limited success, principally because it is difficult to capture\nthe cognitive knowledge behind human decisions explicitly. The trend, nowadays,\nis increasingly focusing on learning to infer intentions directly from data,\nusing deep learning in particular. We are now observing interesting\napplications of intent classification in natural language processing, visual\nactivity recognition, and emerging approaches in other domains. This paper\ndiscusses a novel approach combining few-shot and transfer learning with\ncross-domain features, to learn to infer the intent of an agent navigating in\nphysical environments, executing arbitrary long sequences of actions to achieve\ntheir goals. Experiments in synthetic environments demonstrate improved\nperformance in terms of learning from few samples and generalizing to unseen\nconfigurations, compared to a deep-learning baseline approach.\n", "versions": [{"version": "v1", "created": "Fri, 22 Nov 2019 16:53:19 GMT"}], "update_date": "2019-11-25", "authors_parsed": [["Duhamel", "Thibault", ""], ["Maynard", "Mariane", ""], ["Kabanza", "Froduald", ""]]}, {"id": "1911.10154", "submitter": "Camilo Miguel Signorelli", "authors": "Camilo M. Signorelli, Xerxes D. Arsiwalla", "title": "Moral Dilemmas for Artificial Intelligence: a position paper on an\n  application of Compositional Quantum Cognition", "comments": "15 pages, 3 figures, Conference paper at Quantum Interaction 2018,\n  Nice, France. Published in Lecture Notes in Computer Science, vol 11690,\n  Springer, Cham. Online ISBN 978-3-030-35895-2", "journal-ref": "Quantum Interaction. QI 2018. Lecture Notes in Computer Science,\n  vol 11690", "doi": "10.1007/978-3-030-35895-2_9", "report-no": null, "categories": "cs.AI cs.CL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Traditionally, the way one evaluates the performance of an Artificial\nIntelligence (AI) system is via a comparison to human performance in specific\ntasks, treating humans as a reference for high-level cognition. However, these\ncomparisons leave out important features of human intelligence: the capability\nto transfer knowledge and make complex decisions based on emotional and\nrational reasoning. These decisions are influenced by current inferences as\nwell as prior experiences, making the decision process strongly subjective and\napparently biased. In this context, a definition of compositional intelligence\nis necessary to incorporate these features in future AI tests. Here, a concrete\nimplementation of this will be suggested, using recent developments in quantum\ncognition, natural language and compositional meaning of sentences, thanks to\ncategorical compositional models of meaning.\n", "versions": [{"version": "v1", "created": "Fri, 22 Nov 2019 17:25:32 GMT"}], "update_date": "2019-11-25", "authors_parsed": [["Signorelli", "Camilo M.", ""], ["Arsiwalla", "Xerxes D.", ""]]}, {"id": "1911.10164", "submitter": "Jacob Rafati", "authors": "Jacob Rafati, David C. Noelle", "title": "Efficient Exploration through Intrinsic Motivation Learning for\n  Unsupervised Subgoal Discovery in Model-Free Hierarchical Reinforcement\n  Learning", "comments": "arXiv admin note: substantial text overlap with arXiv:1810.10096", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Efficient exploration for automatic subgoal discovery is a challenging\nproblem in Hierarchical Reinforcement Learning (HRL). In this paper, we show\nthat intrinsic motivation learning increases the efficiency of exploration,\nleading to successful subgoal discovery. We introduce a model-free subgoal\ndiscovery method based on unsupervised learning over a limited memory of\nagent's experiences during intrinsic motivation. Additionally, we offer a\nunified approach to learning representations in model-free HRL.\n", "versions": [{"version": "v1", "created": "Mon, 18 Nov 2019 23:30:36 GMT"}], "update_date": "2019-11-25", "authors_parsed": [["Rafati", "Jacob", ""], ["Noelle", "David C.", ""]]}, {"id": "1911.10183", "submitter": "Edwin D. Simpson", "authors": "Edwin Simpson, Yang Gao, Iryna Gurevych", "title": "Interactive Text Ranking with Bayesian Optimisation: A Case Study on\n  Community QA and Summarisation", "comments": "Accepted to Transactions of the ACL", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For many NLP applications, such as question answering and summarisation, the\ngoal is to select the best solution from a large space of candidates to meet a\nparticular user's needs. To address the lack of user-specific training data, we\npropose an interactive text ranking approach that actively selects pairs of\ncandidates, from which the user selects the best. Unlike previous strategies,\nwhich attempt to learn a ranking across the whole candidate space, our method\nemploys Bayesian optimisation to focus the user's labelling effort on high\nquality candidates and integrates prior knowledge in a Bayesian manner to cope\nbetter with small data scenarios. We apply our method to community question\nanswering (cQA) and extractive summarisation, finding that it significantly\noutperforms existing interactive approaches. We also show that the ranking\nfunction learned by our method is an effective reward function for\nreinforcement learning, which improves the state of the art for interactive\nsummarisation.\n", "versions": [{"version": "v1", "created": "Fri, 22 Nov 2019 18:31:53 GMT"}, {"version": "v2", "created": "Fri, 29 Nov 2019 14:16:44 GMT"}, {"version": "v3", "created": "Sat, 12 Sep 2020 02:38:30 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Simpson", "Edwin", ""], ["Gao", "Yang", ""], ["Gurevych", "Iryna", ""]]}, {"id": "1911.10244", "submitter": "Daniel Kroening", "authors": "Mohammadhosein Hasanbeig, Natasha Yogananda Jeppu, Alessandro Abate,\n  Tom Melham, Daniel Kroening", "title": "DeepSynth: Automata Synthesis for Automatic Task Segmentation in Deep\n  Reinforcement Learning", "comments": "Extended version of AAAI 2021 paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.LO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes DeepSynth, a method for effective training of deep\nReinforcement Learning (RL) agents when the reward is sparse and non-Markovian,\nbut at the same time progress towards the reward requires achieving an unknown\nsequence of high-level objectives. Our method employs a novel algorithm for\nsynthesis of compact automata to uncover this sequential structure\nautomatically. We synthesise a human-interpretable automaton from trace data\ncollected by exploring the environment. The state space of the environment is\nthen enriched with the synthesised automaton so that the generation of a\ncontrol policy by deep RL is guided by the discovered structure encoded in the\nautomaton. The proposed approach is able to cope with both high-dimensional,\nlow-level features and unknown sparse non-Markovian rewards. We have evaluated\nDeepSynth's performance in a set of experiments that includes the Atari game\nMontezuma's Revenge. Compared to existing approaches, we obtain a reduction of\ntwo orders of magnitude in the number of iterations required for policy\nsynthesis, and also a significant improvement in scalability.\n", "versions": [{"version": "v1", "created": "Fri, 22 Nov 2019 20:44:27 GMT"}, {"version": "v2", "created": "Wed, 12 Feb 2020 13:51:38 GMT"}, {"version": "v3", "created": "Thu, 27 Feb 2020 17:46:02 GMT"}, {"version": "v4", "created": "Tue, 22 Sep 2020 19:58:16 GMT"}, {"version": "v5", "created": "Sat, 6 Mar 2021 09:53:15 GMT"}], "update_date": "2021-03-09", "authors_parsed": [["Hasanbeig", "Mohammadhosein", ""], ["Jeppu", "Natasha Yogananda", ""], ["Abate", "Alessandro", ""], ["Melham", "Tom", ""], ["Kroening", "Daniel", ""]]}, {"id": "1911.10322", "submitter": "Kiran Lekkala", "authors": "Kiran Lekkala and Sami Abu-El-Haija and Laurent Itti", "title": "Meta Adaptation using Importance Weighted Demonstrations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Imitation learning has gained immense popularity because of its high\nsample-efficiency. However, in real-world scenarios, where the trajectory\ndistribution of most of the tasks dynamically shifts, model fitting on\ncontinuously aggregated data alone would be futile. In some cases, the\ndistribution shifts, so much, that it is difficult for an agent to infer the\nnew task. We propose a novel algorithm to generalize on any related task by\nleveraging prior knowledge on a set of specific tasks, which involves assigning\nimportance weights to each past demonstration. We show experiments where the\nrobot is trained from a diversity of environmental tasks and is also able to\nadapt to an unseen environment, using few-shot learning. We also developed a\nprototype robot system to test our approach on the task of visual navigation,\nand experimental results obtained were able to confirm these suppositions.\n", "versions": [{"version": "v1", "created": "Sat, 23 Nov 2019 07:22:32 GMT"}], "update_date": "2019-11-26", "authors_parsed": [["Lekkala", "Kiran", ""], ["Abu-El-Haija", "Sami", ""], ["Itti", "Laurent", ""]]}, {"id": "1911.10421", "submitter": "Preslav Nakov", "authors": "Iris Hendrickx, Preslav Nakov, Stan Szpakowicz, Zornitsa Kozareva,\n  Diarmuid \\'O S\\'eaghdha, Tony Veale", "title": "SemEval-2013 Task 4: Free Paraphrases of Noun Compounds", "comments": "noun compounds, paraphrasing verbs, semantic interpretation,\n  multi-word expressions, MWEs", "journal-ref": "SemEval-2013", "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we describe SemEval-2013 Task 4: the definition, the data, the\nevaluation and the results. The task is to capture some of the meaning of\nEnglish noun compounds via paraphrasing. Given a two-word noun compound, the\nparticipating system is asked to produce an explicitly ranked list of its\nfree-form paraphrases. The list is automatically compared and evaluated against\na similarly ranked list of paraphrases proposed by human annotators, recruited\nand managed through Amazon's Mechanical Turk. The comparison of raw paraphrases\nis sensitive to syntactic and morphological variation. The \"gold\" ranking is\nbased on the relative popularity of paraphrases among annotators. To make the\nranking more reliable, highly similar paraphrases are grouped, so as to\ndownplay superficial differences in syntax and morphology. Three systems\nparticipated in the task. They all beat a simple baseline on one of the two\nevaluation measures, but not on both measures. This shows that the task is\ndifficult.\n", "versions": [{"version": "v1", "created": "Sat, 23 Nov 2019 21:42:23 GMT"}], "update_date": "2019-11-26", "authors_parsed": [["Hendrickx", "Iris", ""], ["Nakov", "Preslav", ""], ["Szpakowicz", "Stan", ""], ["Kozareva", "Zornitsa", ""], ["S\u00e9aghdha", "Diarmuid \u00d3", ""], ["Veale", "Tony", ""]]}, {"id": "1911.10422", "submitter": "Preslav Nakov", "authors": "Iris Hendrickx, Su Nam Kim, Zornitsa Kozareva, Preslav Nakov, Diarmuid\n  \\'O S\\'eaghdha, Sebastian Pad\\'o, Marco Pennacchiotti, Lorenza Romano, Stan\n  Szpakowicz", "title": "SemEval-2010 Task 8: Multi-Way Classification of Semantic Relations\n  Between Pairs of Nominals", "comments": "semantic relations, nominals", "journal-ref": "SemEval-2010", "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In response to the continuing research interest in computational semantic\nanalysis, we have proposed a new task for SemEval-2010: multi-way\nclassification of mutually exclusive semantic relations between pairs of\nnominals. The task is designed to compare different approaches to the problem\nand to provide a standard testbed for future research. In this paper, we define\nthe task, describe the creation of the datasets, and discuss the results of the\nparticipating 28 systems submitted by 10 teams.\n", "versions": [{"version": "v1", "created": "Sat, 23 Nov 2019 21:49:10 GMT"}], "update_date": "2019-11-26", "authors_parsed": [["Hendrickx", "Iris", ""], ["Kim", "Su Nam", ""], ["Kozareva", "Zornitsa", ""], ["Nakov", "Preslav", ""], ["S\u00e9aghdha", "Diarmuid \u00d3", ""], ["Pad\u00f3", "Sebastian", ""], ["Pennacchiotti", "Marco", ""], ["Romano", "Lorenza", ""], ["Szpakowicz", "Stan", ""]]}, {"id": "1911.10425", "submitter": "Nibraas Khan", "authors": "Nibraas Khan, Joshua Phillips", "title": "Combined Model for Partially-Observable and Non-Observable Task\n  Switching: Solving Hierarchical Reinforcement Learning Problems Statically\n  and Dynamically with Transfer Learning", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An integral function of fully autonomous robots and humans is the ability to\nfocus attention on a few relevant percepts to reach a certain goal while\ndisregarding irrelevant percepts. Humans and animals rely on the interactions\nbetween the Pre-Frontal Cortex (PFC) and the Basal Ganglia (BG) to achieve this\nfocus called Working Memory (WM). The Working Memory Toolkit (WMtk) was\ndeveloped based on a computational neuroscience model of this phenomenon with\nTemporal Difference (TD) Learning for autonomous systems. Recent adaptations of\nthe toolkit either utilize Abstract Task Representations (ATRs) to solve\nNon-Observable (NO) tasks or storage of past input features to solve\nPartially-Observable (PO) tasks, but not both. We propose a new model,\nPONOWMtk, which combines both approaches, ATRs and input storage, with a static\nor dynamic number of ATRs. The results of our experiments show that PONOWMtk\nperforms effectively for tasks that exhibit PO, NO, or both properties.\n", "versions": [{"version": "v1", "created": "Sat, 23 Nov 2019 22:01:52 GMT"}, {"version": "v2", "created": "Tue, 26 Nov 2019 06:11:23 GMT"}, {"version": "v3", "created": "Fri, 29 Nov 2019 23:53:57 GMT"}, {"version": "v4", "created": "Fri, 17 Apr 2020 22:20:58 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Khan", "Nibraas", ""], ["Phillips", "Joshua", ""]]}, {"id": "1911.10484", "submitter": "Yichi Zhang", "authors": "Yichi Zhang, Zhijian Ou, Zhou Yu", "title": "Task-Oriented Dialog Systems that Consider Multiple Appropriate\n  Responses under the Same Context", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conversations have an intrinsic one-to-many property, which means that\nmultiple responses can be appropriate for the same dialog context. In\ntask-oriented dialogs, this property leads to different valid dialog policies\ntowards task completion. However, none of the existing task-oriented dialog\ngeneration approaches takes this property into account. We propose a\nMulti-Action Data Augmentation (MADA) framework to utilize the one-to-many\nproperty to generate diverse appropriate dialog responses. Specifically, we\nfirst use dialog states to summarize the dialog history, and then discover all\npossible mappings from every dialog state to its different valid system\nactions. During dialog system training, we enable the current dialog state to\nmap to all valid system actions discovered in the previous process to create\nadditional state-action pairs. By incorporating these additional pairs, the\ndialog policy learns a balanced action distribution, which further guides the\ndialog model to generate diverse responses. Experimental results show that the\nproposed framework consistently improves dialog policy diversity, and results\nin improved response diversity and appropriateness. Our model obtains\nstate-of-the-art results on MultiWOZ.\n", "versions": [{"version": "v1", "created": "Sun, 24 Nov 2019 09:32:55 GMT"}, {"version": "v2", "created": "Mon, 2 Dec 2019 17:37:11 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Zhang", "Yichi", ""], ["Ou", "Zhijian", ""], ["Yu", "Zhou", ""]]}, {"id": "1911.10500", "submitter": "Bernhard Sch\\\"olkopf", "authors": "Bernhard Sch\\\"olkopf", "title": "Causality for Machine Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graphical causal inference as pioneered by Judea Pearl arose from research on\nartificial intelligence (AI), and for a long time had little connection to the\nfield of machine learning.\n  This article discusses where links have been and should be established,\nintroducing key concepts along the way. It argues that the hard open problems\nof machine learning and AI are intrinsically related to causality, and explains\nhow the field is beginning to understand them.\n", "versions": [{"version": "v1", "created": "Sun, 24 Nov 2019 11:04:56 GMT"}, {"version": "v2", "created": "Mon, 23 Dec 2019 16:20:53 GMT"}], "update_date": "2019-12-24", "authors_parsed": [["Sch\u00f6lkopf", "Bernhard", ""]]}, {"id": "1911.10521", "submitter": "Zining Liu", "authors": "Zining Liu, Chong Long, Xiaolu Lu, Zehong Hu, Jie Zhang, Yafang Wang", "title": "Which Channel to Ask My Question? Personalized Customer Service Request\n  Stream Routing using Deep Reinforcement Learning", "comments": "13 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Customer services are critical to all companies, as they may directly connect\nto the brand reputation. Due to a great number of customers, e-commerce\ncompanies often employ multiple communication channels to answer customers'\nquestions, for example, chatbot and hotline. On one hand, each channel has\nlimited capacity to respond to customers' requests, on the other hand,\ncustomers have different preferences over these channels. The current\nproduction systems are mainly built based on business rules, which merely\nconsiders tradeoffs between resources and customers' satisfaction. To achieve\nthe optimal tradeoff between resources and customers' satisfaction, we propose\na new framework based on deep reinforcement learning, which directly takes both\nresources and user model into account. In addition to the framework, we also\npropose a new deep-reinforcement-learning based routing method-double dueling\ndeep Q-learning with prioritized experience replay (PER-DoDDQN). We evaluate\nour proposed framework and method using both synthetic and a real customer\nservice log data from a large financial technology company. We show that our\nproposed deep-reinforcement-learning based framework is superior to the\nexisting production system. Moreover, we also show our proposed PER-DoDDQN is\nbetter than all other deep Q-learning variants in practice, which provides a\nmore optimal routing plan. These observations suggest that our proposed method\ncan seek the trade-off where both channel resources and customers' satisfaction\nare optimal.\n", "versions": [{"version": "v1", "created": "Sun, 24 Nov 2019 12:57:03 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Liu", "Zining", ""], ["Long", "Chong", ""], ["Lu", "Xiaolu", ""], ["Hu", "Zehong", ""], ["Zhang", "Jie", ""], ["Wang", "Yafang", ""]]}, {"id": "1911.10601", "submitter": "Alexander Tschantz", "authors": "Alexander Tschantz, Manuel Baltieri, Anil. K. Seth, Christopher L.\n  Buckley", "title": "Scaling active inference", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.IT cs.SY eess.SY math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In reinforcement learning (RL), agents often operate in partially observed\nand uncertain environments. Model-based RL suggests that this is best achieved\nby learning and exploiting a probabilistic model of the world. 'Active\ninference' is an emerging normative framework in cognitive and computational\nneuroscience that offers a unifying account of how biological agents achieve\nthis. On this framework, inference, learning and action emerge from a single\nimperative to maximize the Bayesian evidence for a niched model of the world.\nHowever, implementations of this process have thus far been restricted to\nlow-dimensional and idealized situations. Here, we present a working\nimplementation of active inference that applies to high-dimensional tasks, with\nproof-of-principle results demonstrating efficient exploration and an order of\nmagnitude increase in sample efficiency over strong model-free baselines. Our\nresults demonstrate the feasibility of applying active inference at scale and\nhighlight the operational homologies between active inference and current\nmodel-based approaches to RL.\n", "versions": [{"version": "v1", "created": "Sun, 24 Nov 2019 20:03:11 GMT"}], "update_date": "2019-11-26", "authors_parsed": [["Tschantz", "Alexander", ""], ["Baltieri", "Manuel", ""], ["Seth", "Anil. K.", ""], ["Buckley", "Christopher L.", ""]]}, {"id": "1911.10635", "submitter": "Kaiqing Zhang", "authors": "Kaiqing Zhang, Zhuoran Yang, and Tamer Ba\\c{s}ar", "title": "Multi-Agent Reinforcement Learning: A Selective Overview of Theories and\n  Algorithms", "comments": "Invited Chapter in Handbook on RL and Control (Springer Studies in\n  Systems, Decision and Control); Proofread version from the Publisher", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent years have witnessed significant advances in reinforcement learning\n(RL), which has registered great success in solving various sequential\ndecision-making problems in machine learning. Most of the successful RL\napplications, e.g., the games of Go and Poker, robotics, and autonomous\ndriving, involve the participation of more than one single agent, which\nnaturally fall into the realm of multi-agent RL (MARL), a domain with a\nrelatively long history, and has recently re-emerged due to advances in\nsingle-agent RL techniques. Though empirically successful, theoretical\nfoundations for MARL are relatively lacking in the literature. In this chapter,\nwe provide a selective overview of MARL, with focus on algorithms backed by\ntheoretical analysis. More specifically, we review the theoretical results of\nMARL algorithms mainly within two representative frameworks, Markov/stochastic\ngames and extensive-form games, in accordance with the types of tasks they\naddress, i.e., fully cooperative, fully competitive, and a mix of the two. We\nalso introduce several significant but challenging applications of these\nalgorithms. Orthogonal to the existing reviews on MARL, we highlight several\nnew angles and taxonomies of MARL theory, including learning in extensive-form\ngames, decentralized MARL with networked agents, MARL in the mean-field regime,\n(non-)convergence of policy-based methods for learning in games, etc. Some of\nthe new angles extrapolate from our own research endeavors and interests. Our\noverall goal with this chapter is, beyond providing an assessment of the\ncurrent state of the field on the mark, to identify fruitful future research\ndirections on theoretical studies of MARL. We expect this chapter to serve as\ncontinuing stimulus for researchers interested in working on this exciting\nwhile challenging topic.\n", "versions": [{"version": "v1", "created": "Sun, 24 Nov 2019 22:50:32 GMT"}, {"version": "v2", "created": "Wed, 28 Apr 2021 21:33:13 GMT"}], "update_date": "2021-04-30", "authors_parsed": [["Zhang", "Kaiqing", ""], ["Yang", "Zhuoran", ""], ["Ba\u015far", "Tamer", ""]]}, {"id": "1911.10640", "submitter": "Aria Khademi", "authors": "Aria Khademi and Vasant Honavar", "title": "Algorithmic Bias in Recidivism Prediction: A Causal Perspective", "comments": "Accepted for publication at the Thirty Fourth AAAI conference on\n  Artificial Intelligence (AAAI-20)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  ProPublica's analysis of recidivism predictions produced by Correctional\nOffender Management Profiling for Alternative Sanctions (COMPAS) software tool\nfor the task, has shown that the predictions were racially biased against\nAfrican American defendants. We analyze the COMPAS data using a causal\nreformulation of the underlying algorithmic fairness problem. Specifically, we\nassess whether COMPAS exhibits racial bias against African American defendants\nusing FACT, a recently introduced causality grounded measure of algorithmic\nfairness. We use the Neyman-Rubin potential outcomes framework for causal\ninference from observational data to estimate FACT from COMPAS data. Our\nanalysis offers strong evidence that COMPAS exhibits racial bias against\nAfrican American defendants. We further show that the FACT estimates from\nCOMPAS data are robust in the presence of unmeasured confounding.\n", "versions": [{"version": "v1", "created": "Sun, 24 Nov 2019 23:47:50 GMT"}], "update_date": "2019-11-26", "authors_parsed": [["Khademi", "Aria", ""], ["Honavar", "Vasant", ""]]}, {"id": "1911.10641", "submitter": "Bharathan Balaji", "authors": "Bharathan Balaji, Jordan Bell-Masterson, Enes Bilgin, Andreas\n  Damianou, Pablo Moreno Garcia, Arpit Jain, Runfei Luo, Alvaro Maggiar,\n  Balakrishnan Narayanaswamy, Chun Ye", "title": "ORL: Reinforcement Learning Benchmarks for Online Stochastic\n  Optimization Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement Learning (RL) has achieved state-of-the-art results in domains\nsuch as robotics and games. We build on this previous work by applying RL\nalgorithms to a selection of canonical online stochastic optimization problems\nwith a range of practical applications: Bin Packing, Newsvendor, and Vehicle\nRouting. While there is a nascent literature that applies RL to these problems,\nthere are no commonly accepted benchmarks which can be used to compare proposed\napproaches rigorously in terms of performance, scale, or generalizability. This\npaper aims to fill that gap. For each problem we apply both standard approaches\nas well as newer RL algorithms and analyze results. In each case, the\nperformance of the trained RL policy is competitive with or superior to the\ncorresponding baselines, while not requiring much in the way of domain\nknowledge. This highlights the potential of RL in real-world dynamic resource\nallocation problems.\n", "versions": [{"version": "v1", "created": "Sun, 24 Nov 2019 23:49:48 GMT"}, {"version": "v2", "created": "Sun, 1 Dec 2019 23:50:12 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Balaji", "Bharathan", ""], ["Bell-Masterson", "Jordan", ""], ["Bilgin", "Enes", ""], ["Damianou", "Andreas", ""], ["Garcia", "Pablo Moreno", ""], ["Jain", "Arpit", ""], ["Luo", "Runfei", ""], ["Maggiar", "Alvaro", ""], ["Narayanaswamy", "Balakrishnan", ""], ["Ye", "Chun", ""]]}, {"id": "1911.10684", "submitter": "Yuguang Yang", "authors": "Yuguang Yang", "title": "A Deep Reinforcement Learning Architecture for Multi-stage Optimal\n  Control", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep reinforcement learning for high dimensional, hierarchical control tasks\nusually requires the use of complex neural networks as functional\napproximators, which can lead to inefficiency, instability and even divergence\nin the training process. Here, we introduce stacked deep Q learning (SDQL), a\nflexible modularized deep reinforcement learning architecture, that can enable\nfinding of optimal control policy of control tasks consisting of multiple\nlinear stages in a stable and efficient way. SDQL exploits the linear stage\nstructure by approximating the Q function via a collection of deep Q\nsub-networks stacking along an axis marking the stage-wise progress of the\nwhole task. By back-propagating the learned state values from later stages to\nearlier stages, all sub-networks co-adapt to maximize the total reward of the\nwhole task, although each sub-network is responsible for learning optimal\ncontrol policy for its own stage. This modularized architecture offers\nconsiderable flexibility in terms of environment and policy modeling, as it\nallows choices of different state spaces, action spaces, reward structures, and\nQ networks for each stage, Further, the backward stage-wise training procedure\nof SDQL can offers additional transparency, stability, and flexibility to the\ntraining process, thus facilitating model fine-tuning and hyper-parameter\nsearch. We demonstrate that SDQL is capable of learning competitive strategies\nfor problems with characteristics of high-dimensional state space,\nheterogeneous action space(both discrete and continuous), multiple scales, and\nsparse and delayed rewards.\n", "versions": [{"version": "v1", "created": "Mon, 25 Nov 2019 03:36:47 GMT"}], "update_date": "2019-11-26", "authors_parsed": [["Yang", "Yuguang", ""]]}, {"id": "1911.10708", "submitter": "Idris Abdulmumin", "authors": "Idris Abdulmumin and Bashir Shehu Galadanci", "title": "hauWE: Hausa Words Embedding for Natural Language Processing", "comments": "In Proceedings of the 2019 2nd International Conference of the IEEE\n  Nigeria Computer Chapter", "journal-ref": null, "doi": "10.1109/NigeriaComputConf45974.2019.8949674", "report-no": null, "categories": "cs.CL cs.AI cs.IR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Words embedding (distributed word vector representations) have become an\nessential component of many natural language processing (NLP) tasks such as\nmachine translation, sentiment analysis, word analogy, named entity recognition\nand word similarity. Despite this, the only work that provides word vectors for\nHausa language is that of Bojanowski et al. [1] trained using fastText,\nconsisting of only a few words vectors. This work presents words embedding\nmodels using Word2Vec's Continuous Bag of Words (CBoW) and Skip Gram (SG)\nmodels. The models, hauWE (Hausa Words Embedding), are bigger and better than\nthe only previous model, making them more useful in NLP tasks. To compare the\nmodels, they were used to predict the 10 most similar words to 30 randomly\nselected Hausa words. hauWE CBoW's 88.7% and hauWE SG's 79.3% prediction\naccuracy greatly outperformed Bojanowski et al. [1]'s 22.3%.\n", "versions": [{"version": "v1", "created": "Mon, 25 Nov 2019 05:46:56 GMT"}], "update_date": "2020-01-08", "authors_parsed": [["Abdulmumin", "Idris", ""], ["Galadanci", "Bashir Shehu", ""]]}, {"id": "1911.10715", "submitter": "Weixun Wang", "authors": "Yong Liu, Weixun Wang, Yujing Hu, Jianye Hao, Xingguo Chen, Yang Gao", "title": "Multi-Agent Game Abstraction via Graph Attention Neural Network", "comments": "Accepted by AAAI2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In large-scale multi-agent systems, the large number of agents and complex\ngame relationship cause great difficulty for policy learning. Therefore,\nsimplifying the learning process is an important research issue. In many\nmulti-agent systems, the interactions between agents often happen locally,\nwhich means that agents neither need to coordinate with all other agents nor\nneed to coordinate with others all the time. Traditional methods attempt to use\npre-defined rules to capture the interaction relationship between agents.\nHowever, the methods cannot be directly used in a large-scale environment due\nto the difficulty of transforming the complex interactions between agents into\nrules. In this paper, we model the relationship between agents by a complete\ngraph and propose a novel game abstraction mechanism based on two-stage\nattention network (G2ANet), which can indicate whether there is an interaction\nbetween two agents and the importance of the interaction. We integrate this\ndetection mechanism into graph neural network-based multi-agent reinforcement\nlearning for conducting game abstraction and propose two novel learning\nalgorithms GA-Comm and GA-AC. We conduct experiments in Traffic Junction and\nPredator-Prey. The results indicate that the proposed methods can simplify the\nlearning process and meanwhile get better asymptotic performance compared with\nstate-of-the-art algorithms.\n", "versions": [{"version": "v1", "created": "Mon, 25 Nov 2019 06:24:46 GMT"}], "update_date": "2019-11-26", "authors_parsed": [["Liu", "Yong", ""], ["Wang", "Weixun", ""], ["Hu", "Yujing", ""], ["Hao", "Jianye", ""], ["Chen", "Xingguo", ""], ["Gao", "Yang", ""]]}, {"id": "1911.10735", "submitter": "Julien Girard-Satabin", "authors": "Julien Girard-Satabin (TAU, LIST), Guillaume Charpiat (LRI, TAU),\n  Zakaria Chihani (LIST), Marc Schoenauer (TAU)", "title": "CAMUS: A Framework to Build Formal Specifications for Deep Perception\n  Systems Using Simulators", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The topic of provable deep neural network robustness has raised considerable\ninterest in recent years. Most research has focused on adversarial robustness,\nwhich studies the robustness of perceptive models in the neighbourhood of\nparticular samples. However, other works have proved global properties of\nsmaller neural networks. Yet, formally verifying perception remains uncharted.\nThis is due notably to the lack of relevant properties to verify, as the\ndistribution of possible inputs cannot be formally specified. We propose to\ntake advantage of the simulators often used either to train machine learning\nmodels or to check them with statistical tests, a growing trend in industry.\nOur formulation allows us to formally express and verify safety properties on\nperception units, covering all cases that could ever be generated by the\nsimulator, to the difference of statistical tests which cover only seen\nexamples. Along with this theoretical formulation , we provide a tool to\ntranslate deep learning models into standard logical formulae. As a proof of\nconcept, we train a toy example mimicking an autonomous car perceptive unit,\nand we formally verify that it will never fail to capture the relevant\ninformation in the provided inputs.\n", "versions": [{"version": "v1", "created": "Mon, 25 Nov 2019 07:28:45 GMT"}], "update_date": "2019-11-26", "authors_parsed": [["Girard-Satabin", "Julien", "", "TAU, LIST"], ["Charpiat", "Guillaume", "", "LRI, TAU"], ["Chihani", "Zakaria", "", "LIST"], ["Schoenauer", "Marc", "", "TAU"]]}, {"id": "1911.10742", "submitter": "Yu Li", "authors": "Yu Li, Kun Qian, Weiyan Shi, Zhou Yu", "title": "End-to-End Trainable Non-Collaborative Dialog System", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  End-to-end task-oriented dialog models have achieved promising performance on\ncollaborative tasks where users willingly coordinate with the system to\ncomplete a given task. While in non-collaborative settings, for example,\nnegotiation and persuasion, users and systems do not share a common goal. As a\nresult, compared to collaborate tasks, people use social content to build\nrapport and trust in these non-collaborative settings in order to advance their\ngoals. To handle social content, we introduce a hierarchical intent annotation\nscheme, which can be generalized to different non-collaborative dialog tasks.\nBuilding upon TransferTransfo (Wolf et al. 2019), we propose an end-to-end\nneural network model to generate diverse coherent responses. Our model utilizes\nintent and semantic slots as the intermediate sentence representation to guide\nthe generation process. In addition, we design a filter to select appropriate\nresponses based on whether these intermediate representations fit the designed\ntask and conversation constraints. Our non-collaborative dialog model guides\nusers to complete the task while simultaneously keeps them engaged. We test our\napproach on our newly proposed ANTISCAM dataset and an existing\nPERSUASIONFORGOOD dataset. Both automatic and human evaluations suggest that\nour model outperforms multiple baselines in these two non-collaborative tasks.\n", "versions": [{"version": "v1", "created": "Mon, 25 Nov 2019 07:34:37 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Li", "Yu", ""], ["Qian", "Kun", ""], ["Shi", "Weiyan", ""], ["Yu", "Zhou", ""]]}, {"id": "1911.10763", "submitter": "Benjamin Sznajder", "authors": "Liat Ein-Dor, Eyal Shnarch, Lena Dankin, Alon Halfon, Benjamin\n  Sznajder, Ariel Gera, Carlos Alzate, Martin Gleize, Leshem Choshen, Yufang\n  Hou, Yonatan Bilu, Ranit Aharonov and Noam Slonim", "title": "Corpus Wide Argument Mining -- a Working Solution", "comments": null, "journal-ref": "AAAI 2020", "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the main tasks in argument mining is the retrieval of argumentative\ncontent pertaining to a given topic. Most previous work addressed this task by\nretrieving a relatively small number of relevant documents as the initial\nsource for such content. This line of research yielded moderate success, which\nis of limited use in a real-world system. Furthermore, for such a system to\nyield a comprehensive set of relevant arguments, over a wide range of topics,\nit requires leveraging a large and diverse corpus in an appropriate manner.\nHere we present a first end-to-end high-precision, corpus-wide argument mining\nsystem. This is made possible by combining sentence-level queries over an\nappropriate indexing of a very large corpus of newspaper articles, with an\niterative annotation scheme. This scheme addresses the inherent label bias in\nthe data and pinpoints the regions of the sample space whose manual labeling is\nrequired to obtain high-precision among top-ranked candidates.\n", "versions": [{"version": "v1", "created": "Mon, 25 Nov 2019 08:29:37 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Ein-Dor", "Liat", ""], ["Shnarch", "Eyal", ""], ["Dankin", "Lena", ""], ["Halfon", "Alon", ""], ["Sznajder", "Benjamin", ""], ["Gera", "Ariel", ""], ["Alzate", "Carlos", ""], ["Gleize", "Martin", ""], ["Choshen", "Leshem", ""], ["Hou", "Yufang", ""], ["Bilu", "Yonatan", ""], ["Aharonov", "Ranit", ""], ["Slonim", "Noam", ""]]}, {"id": "1911.10776", "submitter": "Xiyuan Zhang", "authors": "Xiyuan Zhang, Chengxi Li, Dian Yu, Samuel Davidson, Zhou Yu", "title": "Filling Conversation Ellipsis for Better Social Dialog Understanding", "comments": "Accepted to AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The phenomenon of ellipsis is prevalent in social conversations. Ellipsis\nincreases the difficulty of a series of downstream language understanding\ntasks, such as dialog act prediction and semantic role labeling. We propose to\nresolve ellipsis through automatic sentence completion to improve language\nunderstanding. However, automatic ellipsis completion can result in output\nwhich does not accurately reflect user intent. To address this issue, we\npropose a method which considers both the original utterance that has ellipsis\nand the automatically completed utterance in dialog act and semantic role\nlabeling tasks. Specifically, we first complete user utterances to resolve\nellipsis using an end-to-end pointer network model. We then train a prediction\nmodel using both utterances containing ellipsis and our automatically completed\nutterances. Finally, we combine the prediction results from these two\nutterances using a selection model that is guided by expert knowledge. Our\napproach improves dialog act prediction and semantic role labeling by 1.3% and\n2.5% in F1 score respectively in social conversations. We also present an\nopen-domain human-machine conversation dataset with manually completed user\nutterances and annotated semantic role labeling after manual completion.\n", "versions": [{"version": "v1", "created": "Mon, 25 Nov 2019 09:21:17 GMT"}], "update_date": "2019-11-26", "authors_parsed": [["Zhang", "Xiyuan", ""], ["Li", "Chengxi", ""], ["Yu", "Dian", ""], ["Davidson", "Samuel", ""], ["Yu", "Zhou", ""]]}, {"id": "1911.10868", "submitter": "Marin Toromanoff", "authors": "Marin Toromanoff, Emilie Wirbel, Fabien Moutarde", "title": "End-to-End Model-Free Reinforcement Learning for Urban Driving using\n  Implicit Affordances", "comments": "Accepted at main conference of CVPR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement Learning (RL) aims at learning an optimal behavior policy from\nits own experiments and not rule-based control methods. However, there is no RL\nalgorithm yet capable of handling a task as difficult as urban driving. We\npresent a novel technique, coined implicit affordances, to effectively leverage\nRL for urban driving thus including lane keeping, pedestrians and vehicles\navoidance, and traffic light detection. To our knowledge we are the first to\npresent a successful RL agent handling such a complex task especially regarding\nthe traffic light detection. Furthermore, we have demonstrated the\neffectiveness of our method by winning the Camera Only track of the CARLA\nchallenge.\n", "versions": [{"version": "v1", "created": "Mon, 25 Nov 2019 12:34:26 GMT"}, {"version": "v2", "created": "Mon, 16 Mar 2020 14:44:13 GMT"}], "update_date": "2020-03-17", "authors_parsed": [["Toromanoff", "Marin", ""], ["Wirbel", "Emilie", ""], ["Moutarde", "Fabien", ""]]}, {"id": "1911.10981", "submitter": "David Carral", "authors": "David Carral and Jacopo Urbani", "title": "Checking Chase Termination over Ontologies of Existential Rules with\n  Equality", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The chase is a sound and complete algorithm for conjunctive query answering\nover ontologies of existential rules with equality. To enable its effective\nuse, we can apply acyclicity notions; that is, sufficient conditions that\nguarantee chase termination. Unfortunately, most of these notions have only\nbeen defined for existential rule sets without equality. A proposed solution to\ncircumvent this issue is to treat equality as an ordinary predicate with an\nexplicit axiomatisation. We empirically show that this solution is not\nefficient in practice and propose an alternative approach. More precisely, we\nshow that, if the chase terminates for any equality axiomatisation of an\nontology, then it terminates for the original ontology (which may contain\nequality). Therefore, one can apply existing acyclicity notions to check chase\ntermination over an axiomatisation of an ontology and then use the original\nontology for reasoning. We show that, in practice, doing so results in a more\nefficient reasoning procedure. Furthermore, we present equality model-faithful\nacyclicity, a general acyclicity notion that can be directly applied to\nontologies with equality.\n", "versions": [{"version": "v1", "created": "Mon, 25 Nov 2019 15:29:25 GMT"}], "update_date": "2019-11-26", "authors_parsed": [["Carral", "David", ""], ["Urbani", "Jacopo", ""]]}, {"id": "1911.11005", "submitter": "Martin Aleksandrov D", "authors": "Martin Aleksandrov and Toby Walsh", "title": "Greedy Algorithms for Fair Division of Mixed Manna", "comments": "21 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a multi-agent model for fair division of mixed manna (i.e. items\nfor which agents can have positive, zero or negative utilities), in which\nagents have additive utilities for bundles of items. For this model, we give\nseveral general impossibility results and special possibility results for three\ncommon fairness concepts (i.e. EF1, EFX, EFX3) and one popular efficiency\nconcept (i.e. PO). We also study how these interact with common welfare\nobjectives such as the Nash, disutility Nash and egalitarian welfares. For\nexample, we show that maximizing the Nash welfare with mixed manna (or\nminimizing the disutility Nash welfare) does not ensure an EF1 allocation\nwhereas with goods and the Nash welfare it does. We also prove that an EFX3\nallocation may not exist even with identical utilities. By comparison, with\ntertiary utilities, EFX and PO allocations, or EFX3 and PO allocations always\nexist. Also, with identical utilities, EFX and PO allocations always exist. For\nthese cases, we give polynomial-time algorithms, returning such allocations and\napproximating further the Nash, disutility Nash and egalitarian welfares in\nspecial cases.\n", "versions": [{"version": "v1", "created": "Mon, 25 Nov 2019 15:52:28 GMT"}, {"version": "v2", "created": "Tue, 17 Dec 2019 16:53:34 GMT"}], "update_date": "2019-12-18", "authors_parsed": [["Aleksandrov", "Martin", ""], ["Walsh", "Toby", ""]]}, {"id": "1911.11053", "submitter": "Nicolas Maudet", "authors": "Parham Shams and Aur\\'elie Beynier and Sylvain Bouveret and Nicolas\n  Maudet", "title": "Fair in the Eyes of Others", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Envy-freeness is a widely studied notion in resource allocation, capturing\nsome aspects of fairness. The notion of envy being inherently subjective\nthough, it might be the case that an agent envies another agent, but that she\nobjectively has no reason to do so. The difficulty here is to define the notion\nof objectivity, since no ground-truth can properly serve as a basis of this\ndefinition. A natural approach is to consider the judgement of the other agents\nas a proxy for objectivity. Building on previous work by Parijs (who introduced\n\"unanimous envy\") we propose the notion of approval envy: an agent $a_i$\nexperiences approval envy towards $a_j$ if she is envious of $a_j$, and\nsufficiently many agents agree that this should be the case, from their own\nperspectives. Some interesting properties of this notion are put forward.\nComputing the minimal threshold guaranteeing approval envy clearly inherits\nwell-known intractable results from envy-freeness, but (i) we identify some\ntractable cases such as house allocation; and (ii) we provide a general method\nbased on a mixed integer programming encoding of the problem, which proves to\nbe efficient in practice. This allows us in particular to show experimentally\nthat existence of such allocations, with a rather small threshold, is very\noften observed.\n", "versions": [{"version": "v1", "created": "Mon, 25 Nov 2019 17:05:27 GMT"}], "update_date": "2019-11-26", "authors_parsed": [["Shams", "Parham", ""], ["Beynier", "Aur\u00e9lie", ""], ["Bouveret", "Sylvain", ""], ["Maudet", "Nicolas", ""]]}, {"id": "1911.11185", "submitter": "Xiaojian Ma", "authors": "Mark Edmonds, Xiaojian Ma, Siyuan Qi, Yixin Zhu, Hongjing Lu,\n  Song-Chun Zhu", "title": "Theory-based Causal Transfer: Integrating Instance-level Induction and\n  Abstract-level Structure Learning", "comments": "Accepted to AAAI 2020 as an oral", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning transferable knowledge across similar but different settings is a\nfundamental component of generalized intelligence. In this paper, we approach\nthe transfer learning challenge from a causal theory perspective. Our agent is\nendowed with two basic yet general theories for transfer learning: (i) a task\nshares a common abstract structure that is invariant across domains, and (ii)\nthe behavior of specific features of the environment remain constant across\ndomains. We adopt a Bayesian perspective of causal theory induction and use\nthese theories to transfer knowledge between environments. Given these general\ntheories, the goal is to train an agent by interactively exploring the problem\nspace to (i) discover, form, and transfer useful abstract and structural\nknowledge, and (ii) induce useful knowledge from the instance-level attributes\nobserved in the environment. A hierarchy of Bayesian structures is used to\nmodel abstract-level structural causal knowledge, and an instance-level\nassociative learning scheme learns which specific objects can be used to induce\nstate changes through interaction. This model-learning scheme is then\nintegrated with a model-based planner to achieve a task in the OpenLock\nenvironment, a virtual ``escape room'' with a complex hierarchy that requires\nagents to reason about an abstract, generalized causal structure. We compare\nperformances against a set of predominate model-free reinforcement learning(RL)\nalgorithms. RL agents showed poor ability transferring learned knowledge across\ndifferent trials. Whereas the proposed model revealed similar performance\ntrends as human learners, and more importantly, demonstrated transfer behavior\nacross trials and learning situations.\n", "versions": [{"version": "v1", "created": "Mon, 25 Nov 2019 19:36:28 GMT"}], "update_date": "2019-11-27", "authors_parsed": [["Edmonds", "Mark", ""], ["Ma", "Xiaojian", ""], ["Qi", "Siyuan", ""], ["Zhu", "Yixin", ""], ["Lu", "Hongjing", ""], ["Zhu", "Song-Chun", ""]]}, {"id": "1911.11253", "submitter": "Cassidy Laidlaw", "authors": "Cassidy Laidlaw and Soheil Feizi", "title": "Playing it Safe: Adversarial Robustness with an Abstain Option", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We explore adversarial robustness in the setting in which it is acceptable\nfor a classifier to abstain---that is, output no class---on adversarial\nexamples. Adversarial examples are small perturbations of normal inputs to a\nclassifier that cause the classifier to give incorrect output; they present\nsecurity and safety challenges for machine learning systems. In many\nsafety-critical applications, it is less costly for a classifier to abstain on\nadversarial examples than to give incorrect output for them. We first introduce\na novel objective function for adversarial robustness with an abstain option\nwhich characterizes an explicit tradeoff between robustness and accuracy. We\nthen present a simple baseline in which an adversarially-trained classifier\nabstains on all inputs within a certain distance of the decision boundary,\nwhich we theoretically and experimentally evaluate. Finally, we propose\nCombined Abstention Robustness Learning (CARL), a method for jointly learning a\nclassifier and the region of the input space on which it should abstain. We\nexplore different variations of the PGD and DeepFool adversarial attacks on\nCARL in the abstain setting. Evaluating against these attacks, we demonstrate\nthat training with CARL results in a more accurate, robust, and efficient\nclassifier than the baseline.\n", "versions": [{"version": "v1", "created": "Mon, 25 Nov 2019 21:59:37 GMT"}], "update_date": "2019-11-27", "authors_parsed": [["Laidlaw", "Cassidy", ""], ["Feizi", "Soheil", ""]]}, {"id": "1911.11260", "submitter": "Risto Vuorio", "authors": "John Holler, Risto Vuorio, Zhiwei Qin, Xiaocheng Tang, Yan Jiao,\n  Tiancheng Jin, Satinder Singh, Chenxi Wang and Jieping Ye", "title": "Deep Reinforcement Learning for Multi-Driver Vehicle Dispatching and\n  Repositioning Problem", "comments": "ICDM 2019 Short Paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Order dispatching and driver repositioning (also known as fleet management)\nin the face of spatially and temporally varying supply and demand are central\nto a ride-sharing platform marketplace. Hand-crafting heuristic solutions that\naccount for the dynamics in these resource allocation problems is difficult,\nand may be better handled by an end-to-end machine learning method. Previous\nworks have explored machine learning methods to the problem from a high-level\nperspective, where the learning method is responsible for either repositioning\nthe drivers or dispatching orders, and as a further simplification, the drivers\nare considered independent agents maximizing their own reward functions. In\nthis paper we present a deep reinforcement learning approach for tackling the\nfull fleet management and dispatching problems. In addition to treating the\ndrivers as individual agents, we consider the problem from a system-centric\nperspective, where a central fleet management agent is responsible for\ndecision-making for all drivers.\n", "versions": [{"version": "v1", "created": "Mon, 25 Nov 2019 22:28:21 GMT"}], "update_date": "2019-11-27", "authors_parsed": [["Holler", "John", ""], ["Vuorio", "Risto", ""], ["Qin", "Zhiwei", ""], ["Tang", "Xiaocheng", ""], ["Jiao", "Yan", ""], ["Jin", "Tiancheng", ""], ["Singh", "Satinder", ""], ["Wang", "Chenxi", ""], ["Ye", "Jieping", ""]]}, {"id": "1911.11298", "submitter": "Chuxu Zhang", "authors": "Chuxu Zhang, Huaxiu Yao, Chao Huang, Meng Jiang, Zhenhui Li, Nitesh V.\n  Chawla", "title": "Few-Shot Knowledge Graph Completion", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge graphs (KGs) serve as useful resources for various natural language\nprocessing applications. Previous KG completion approaches require a large\nnumber of training instances (i.e., head-tail entity pairs) for every relation.\nThe real case is that for most of the relations, very few entity pairs are\navailable. Existing work of one-shot learning limits method generalizability\nfor few-shot scenarios and does not fully use the supervisory information;\nhowever, few-shot KG completion has not been well studied yet. In this work, we\npropose a novel few-shot relation learning model (FSRL) that aims at\ndiscovering facts of new relations with few-shot references. FSRL can\neffectively capture knowledge from heterogeneous graph structure, aggregate\nrepresentations of few-shot references, and match similar entity pairs of\nreference set for every relation. Extensive experiments on two public datasets\ndemonstrate that FSRL outperforms the state-of-the-art.\n", "versions": [{"version": "v1", "created": "Tue, 26 Nov 2019 01:01:37 GMT"}], "update_date": "2019-11-27", "authors_parsed": [["Zhang", "Chuxu", ""], ["Yao", "Huaxiu", ""], ["Huang", "Chao", ""], ["Jiang", "Meng", ""], ["Li", "Zhenhui", ""], ["Chawla", "Nitesh V.", ""]]}, {"id": "1911.11359", "submitter": "Heng Zhang", "authors": "Heng Zhang, Yan Zhang, Jia-Huai You, Zhiyong Feng, Guifei Jiang", "title": "Towards Universal Languages for Tractable Ontology Mediated Query\n  Answering", "comments": "10 pages, 1 figure, the full version of a paper accepted for AAAI\n  2020. Some typos have been corrected", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.DB cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An ontology language for ontology mediated query answering (OMQA-language) is\nuniversal for a family of OMQA-languages if it is the most expressive one among\nthis family. In this paper, we focus on three families of tractable\nOMQA-languages, including first-order rewritable languages and languages whose\ndata complexity of the query answering is in AC0 or PTIME. On the negative\nside, we prove that there is, in general, no universal language for each of\nthese families of languages. On the positive side, we propose a novel property,\nthe locality, to approximate the first-order rewritability, and show that there\nexists a language of disjunctive embedded dependencies that is universal for\nthe family of OMQA-languages with locality. All of these results apply to OMQA\nwith query languages such as conjunctive queries, unions of conjunctive queries\nand acyclic conjunctive queries.\n", "versions": [{"version": "v1", "created": "Tue, 26 Nov 2019 06:07:20 GMT"}, {"version": "v2", "created": "Fri, 13 Dec 2019 12:37:48 GMT"}], "update_date": "2019-12-16", "authors_parsed": [["Zhang", "Heng", ""], ["Zhang", "Yan", ""], ["You", "Jia-Huai", ""], ["Feng", "Zhiyong", ""], ["Jiang", "Guifei", ""]]}, {"id": "1911.11361", "submitter": "Yifan Wu", "authors": "Yifan Wu, George Tucker, Ofir Nachum", "title": "Behavior Regularized Offline Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In reinforcement learning (RL) research, it is common to assume access to\ndirect online interactions with the environment. However in many real-world\napplications, access to the environment is limited to a fixed offline dataset\nof logged experience. In such settings, standard RL algorithms have been shown\nto diverge or otherwise yield poor performance. Accordingly, recent work has\nsuggested a number of remedies to these issues. In this work, we introduce a\ngeneral framework, behavior regularized actor critic (BRAC), to empirically\nevaluate recently proposed methods as well as a number of simple baselines\nacross a variety of offline continuous control tasks. Surprisingly, we find\nthat many of the technical complexities introduced in recent methods are\nunnecessary to achieve strong performance. Additional ablations provide\ninsights into which design choices matter most in the offline RL setting.\n", "versions": [{"version": "v1", "created": "Tue, 26 Nov 2019 06:11:34 GMT"}], "update_date": "2019-11-27", "authors_parsed": [["Wu", "Yifan", ""], ["Tucker", "George", ""], ["Nachum", "Ofir", ""]]}, {"id": "1911.11403", "submitter": "Preslav Nakov", "authors": "Preslav Nakov, Llu\\'is M\\`arquez, Walid Magdy, Alessandro Moschitti,\n  James Glass, Bilal Randeree", "title": "SemEval-2015 Task 3: Answer Selection in Community Question Answering", "comments": "community question answering, answer selection, English, Arabic", "journal-ref": "SemEval-2015", "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Community Question Answering (cQA) provides new interesting research\ndirections to the traditional Question Answering (QA) field, e.g., the\nexploitation of the interaction between users and the structure of related\nposts. In this context, we organized SemEval-2015 Task 3 on \"Answer Selection\nin cQA\", which included two subtasks: (a) classifying answers as \"good\", \"bad\",\nor \"potentially relevant\" with respect to the question, and (b) answering a\nYES/NO question with \"yes\", \"no\", or \"unsure\", based on the list of all\nanswers. We set subtask A for Arabic and English on two relatively different\ncQA domains, i.e., the Qatar Living website for English, and a Quran-related\nwebsite for Arabic. We used crowdsourcing on Amazon Mechanical Turk to label a\nlarge English training dataset, which we released to the research community.\nThirteen teams participated in the challenge with a total of 61 submissions: 24\nprimary and 37 contrastive. The best systems achieved an official score\n(macro-averaged F1) of 57.19 and 63.7 for the English subtasks A and B, and\n78.55 for the Arabic subtask A.\n", "versions": [{"version": "v1", "created": "Tue, 26 Nov 2019 08:40:49 GMT"}], "update_date": "2019-11-27", "authors_parsed": [["Nakov", "Preslav", ""], ["M\u00e0rquez", "Llu\u00eds", ""], ["Magdy", "Walid", ""], ["Moschitti", "Alessandro", ""], ["Glass", "James", ""], ["Randeree", "Bilal", ""]]}, {"id": "1911.11423", "submitter": "Stephen Merity", "authors": "Stephen Merity", "title": "Single Headed Attention RNN: Stop Thinking With Your Head", "comments": "Addition of citations and contextual results (no attention head,\n  single attention head, attention per layer), removal of wordpiece\n  WikiText-103 numbers due to normalization issues, fix of SHA attention figure\n  Q arrow, other minor fixes", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The leading approaches in language modeling are all obsessed with TV shows of\nmy youth - namely Transformers and Sesame Street. Transformers this,\nTransformers that, and over here a bonfire worth of GPU-TPU-neuromorphic wafer\nscale silicon. We opt for the lazy path of old and proven techniques with a\nfancy crypto inspired acronym: the Single Headed Attention RNN (SHA-RNN). The\nauthor's lone goal is to show that the entire field might have evolved a\ndifferent direction if we had instead been obsessed with a slightly different\nacronym and slightly different result. We take a previously strong language\nmodel based only on boring LSTMs and get it to within a stone's throw of a\nstone's throw of state-of-the-art byte level language model results on enwik8.\nThis work has undergone no intensive hyperparameter optimization and lived\nentirely on a commodity desktop machine that made the author's small studio\napartment far too warm in the midst of a San Franciscan summer. The final\nresults are achievable in plus or minus 24 hours on a single GPU as the author\nis impatient. The attention mechanism is also readily extended to large\ncontexts with minimal computation. Take that Sesame Street.\n", "versions": [{"version": "v1", "created": "Tue, 26 Nov 2019 09:45:33 GMT"}, {"version": "v2", "created": "Wed, 27 Nov 2019 12:00:15 GMT"}], "update_date": "2019-11-28", "authors_parsed": [["Merity", "Stephen", ""]]}, {"id": "1911.11444", "submitter": "Fabrizia Auletta", "authors": "Francesco De Lellis, Fabrizia Auletta, Giovanni Russo, Mario di\n  Bernardo", "title": "Control-Tutored Reinforcement Learning: an application to the Herding\n  Problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this extended abstract we introduce a novel control-tutored Q-learning\napproach (CTQL) as part of the ongoing effort in developing model-based and\nsafe RL for continuous state spaces. We validate our approach by applying it to\na challenging multi-agent herding control problem.\n", "versions": [{"version": "v1", "created": "Tue, 26 Nov 2019 10:40:30 GMT"}, {"version": "v2", "created": "Wed, 27 Nov 2019 11:16:25 GMT"}], "update_date": "2019-11-28", "authors_parsed": [["De Lellis", "Francesco", ""], ["Auletta", "Fabrizia", ""], ["Russo", "Giovanni", ""], ["di Bernardo", "Mario", ""]]}, {"id": "1911.11460", "submitter": "Maxime Lenormand", "authors": "Olivier Billaud, Maxence Soubeyrand, Sandra Luque and Maxime Lenormand", "title": "Comprehensive decision-strategy space exploration for efficient\n  territorial planning strategies", "comments": "12 pages, 7 figures + Appendix", "journal-ref": "Computers, Environment and Urban Systems 83, 101516 (2020)", "doi": "10.1016/j.compenvurbsys.2020.101516", "report-no": null, "categories": "stat.AP cs.AI math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  GIS-based Multi-Criteria Decision Analysis is a well-known decision support\ntool that can be used in a wide variety of contexts. It is particularly useful\nfor territorial planning in situations where several actors with different, and\nsometimes contradictory, point of views have to take a decision regarding land\nuse development. While the impact of the weights used to represent the relative\nimportance of criteria has been widely studied in the recent literature, the\nimpact of the order weights used to combine the criteria have rarely been\ninvestigated. This paper presents a spatial sensitivity analysis to assess the\nimpact of order weights determination in GIS-based Multi-Criteria Analysis by\nOrdered Weighted Averaging. We propose a methodology based on an efficient\nexploration of the decision-strategy space defined by the level of risk and\ntrade-off in the decision process. We illustrate our approach with a land use\nplanning process in the South of France. The objective is to find suitable\nareas for urban development while preserving green areas and their associated\necosystem services. The ecosystem service approach has indeed the potential to\nwiden the scope of traditional landscape-ecological planning by including\necosystem-based benefits, including social and economic benefits, green\ninfrastructures and biophysical parameters in urban and territorial planning.\nWe show that in this particular case the decision-strategy space can be divided\ninto four clusters. Each of them is associated with a map summarizing the\naverage spatial suitability distribution used to identify potential areas for\nurban development. We also demonstrate the pertinence of a spatial variance\nwithin-cluster analysis to disentangle the relationship between risk and\ntrade-off values. At the end, we perform a site suitability ranking analysis to\nassess the relationship between the four detected clusters.\n", "versions": [{"version": "v1", "created": "Tue, 26 Nov 2019 11:21:37 GMT"}, {"version": "v2", "created": "Sat, 4 Jul 2020 09:41:48 GMT"}], "update_date": "2020-07-07", "authors_parsed": [["Billaud", "Olivier", ""], ["Soubeyrand", "Maxence", ""], ["Luque", "Sandra", ""], ["Lenormand", "Maxime", ""]]}, {"id": "1911.11496", "submitter": "Tom Hanika", "authors": "Dominik D\\\"urrschnabel and Tom Hanika and Maximilian Stubbemann", "title": "FCA2VEC: Embedding Techniques for Formal Concept Analysis", "comments": "25 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Embedding large and high dimensional data into low dimensional vector spaces\nis a necessary task to computationally cope with contemporary data sets.\nSuperseding latent semantic analysis recent approaches like word2vec or\nnode2vec are well established tools in this realm. In the present paper we add\nto this line of research by introducing fca2vec, a family of embedding\ntechniques for formal concept analysis (FCA). Our investigation contributes to\ntwo distinct lines of research. First, we enable the application of FCA notions\nto large data sets. In particular, we demonstrate how the cover relation of a\nconcept lattice can be retrieved from a computational feasible embedding.\nSecondly, we show an enhancement for the classical node2vec approach in low\ndimension. For both directions the overall constraint of FCA of explainable\nresults is preserved. We evaluate our novel procedures by computing fca2vec on\ndifferent data sets like, wiki44 (a dense part of the Wikidata knowledge\ngraph), the Mushroom data set and a publication network derived from the FCA\ncommunity.\n", "versions": [{"version": "v1", "created": "Tue, 26 Nov 2019 12:36:47 GMT"}], "update_date": "2019-11-27", "authors_parsed": [["D\u00fcrrschnabel", "Dominik", ""], ["Hanika", "Tom", ""], ["Stubbemann", "Maximilian", ""]]}, {"id": "1911.11503", "submitter": "Preslav Nakov", "authors": "Georgi Georgiev, Valentin Zhikov, Petya Osenova, Kiril Simov, Preslav\n  Nakov", "title": "Feature-Rich Part-of-speech Tagging for Morphologically Complex\n  Languages: Application to Bulgarian", "comments": "part-of-speech tagging, POS tagging, morpho-syntactic tags, guided\n  learning, Bulgarian, Slavic", "journal-ref": "EACL-2012", "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present experiments with part-of-speech tagging for Bulgarian, a Slavic\nlanguage with rich inflectional and derivational morphology. Unlike most\nprevious work, which has used a small number of grammatical categories, we work\nwith 680 morpho-syntactic tags. We combine a large morphological lexicon with\nprior linguistic knowledge and guided learning from a POS-annotated corpus,\nachieving accuracy of 97.98%, which is a significant improvement over the\nstate-of-the-art for Bulgarian.\n", "versions": [{"version": "v1", "created": "Tue, 26 Nov 2019 13:05:33 GMT"}], "update_date": "2019-11-27", "authors_parsed": [["Georgiev", "Georgi", ""], ["Zhikov", "Valentin", ""], ["Osenova", "Petya", ""], ["Simov", "Kiril", ""], ["Nakov", "Preslav", ""]]}, {"id": "1911.11543", "submitter": "Shruti Jadon", "authors": "Tanvi Sahay, Ankita Mehta, Shruti Jadon", "title": "Schema Matching using Machine Learning", "comments": "7 pages, 2 figures, 2 tables", "journal-ref": null, "doi": "10.1109/SPIN48934.2020.9071272", "report-no": null, "categories": "cs.DB cs.AI cs.IR", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Schema Matching is a method of finding attributes that are either similar to\neach other linguistically or represent the same information. In this project,\nwe take a hybrid approach at solving this problem by making use of both the\nprovided data and the schema name to perform one to one schema matching and\nintroduce the creation of a global dictionary to achieve one to many schema\nmatching. We experiment with two methods of one to one matching and compare\nboth based on their F-scores, precision, and recall. We also compare our method\nwith the ones previously suggested and highlight differences between them.\n", "versions": [{"version": "v1", "created": "Sun, 24 Nov 2019 02:40:09 GMT"}], "update_date": "2020-04-22", "authors_parsed": [["Sahay", "Tanvi", ""], ["Mehta", "Ankita", ""], ["Jadon", "Shruti", ""]]}, {"id": "1911.11561", "submitter": "Yue Bai", "authors": "Yue Bai, Lichen Wang, Zhiqiang Tao, Sheng Li, Yun Fu", "title": "Correlative Channel-Aware Fusion for Multi-View Time Series\n  Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-view time series classification (MVTSC) aims to improve the performance\nby fusing the distinctive temporal information from multiple views. Existing\nmethods mainly focus on fusing multi-view information at an early stage, e.g.,\nby learning a common feature subspace among multiple views. However, these\nearly fusion methods may not fully exploit the unique temporal patterns of each\nview in complicated time series. Moreover, the label correlations of multiple\nviews, which are critical to boost-ing, are usually under-explored for the\nMVTSC problem. To address the aforementioned issues, we propose a Correlative\nChannel-Aware Fusion (C2AF) network. First, C2AF extracts comprehensive and\nrobust temporal patterns by a two-stream structured encoder for each view, and\ncaptures the intra-view and inter-view label correlations with a graph-based\ncorrelation matrix. Second, a channel-aware learnable fusion mechanism is\nimplemented through convolutional neural networks to further explore the global\ncorrelative patterns. These two steps are trained end-to-end in the proposed\nC2AF network. Extensive experimental results on three real-world datasets\ndemonstrate the superiority of our approach over the state-of-the-art methods.\nA detailed ablation study is also provided to show the effectiveness of each\nmodel component.\n", "versions": [{"version": "v1", "created": "Sun, 24 Nov 2019 20:22:57 GMT"}, {"version": "v2", "created": "Fri, 20 Nov 2020 23:05:52 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Bai", "Yue", ""], ["Wang", "Lichen", ""], ["Tao", "Zhiqiang", ""], ["Li", "Sheng", ""], ["Fu", "Yun", ""]]}, {"id": "1911.11573", "submitter": "Jeremy Charlier", "authors": "Jeremy Charlier", "title": "From Persistent Homology to Reinforcement Learning with Applications for\n  Retail Banking", "comments": "PhD thesis, Univ Luxembourg (2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The retail banking services are one of the pillars of the modern economic\ngrowth. However, the evolution of the client's habits in modern societies and\nthe recent European regulations promoting more competition mean the retail\nbanks will encounter serious challenges for the next few years, endangering\ntheir activities. They now face an impossible compromise: maximizing the\nsatisfaction of their hyper-connected clients while avoiding any risk of\ndefault and being regulatory compliant. Therefore, advanced and novel research\nconcepts are a serious game-changer to gain a competitive advantage. In this\ncontext, we investigate in this thesis different concepts bridging the gap\nbetween persistent homology, neural networks, recommender engines and\nreinforcement learning with the aim of improving the quality of the retail\nbanking services. Our contribution is threefold. First, we highlight how to\novercome insufficient financial data by generating artificial data using\ngenerative models and persistent homology. Then, we present how to perform\naccurate financial recommendations in multi-dimensions. Finally, we underline a\nreinforcement learning model-free approach to determine the optimal policy of\nmoney management based on the aggregated financial transactions of the clients.\nOur experimental data sets, extracted from well-known institutions where the\nprivacy and the confidentiality of the clients were not put at risk, support\nour contributions. In this work, we provide the motivations of our retail\nbanking research project, describe the theory employed to improve the financial\nservices quality and evaluate quantitatively and qualitatively our\nmethodologies for each of the proposed research scenarios.\n", "versions": [{"version": "v1", "created": "Sat, 23 Nov 2019 23:04:34 GMT"}], "update_date": "2019-11-27", "authors_parsed": [["Charlier", "Jeremy", ""]]}, {"id": "1911.11620", "submitter": "Jonathan Connell", "authors": "Jonathan Connell", "title": "Teaching Perception", "comments": "arXiv admin note: text overlap with arXiv:1911.09782", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CV cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The visual world is very rich and generally too complex to perceive in its\nentirety. Yet only certain features are typically required to adequately\nperform some task in a given situation. Rather than hardwire-in decisions about\nwhen and what to sense, this paper describes a robotic system whose behavioral\npolicy can be set by verbal instructions it receives. These capabilities are\ndemonstrated in an associated video showing the fully implemented system\nguiding the perception of a physical robot in simple scenario. The structure\nand functioning of the underlying natural language based symbolic reasoning\nsystem is also discussed.\n", "versions": [{"version": "v1", "created": "Thu, 21 Nov 2019 23:46:37 GMT"}], "update_date": "2019-11-27", "authors_parsed": [["Connell", "Jonathan", ""]]}, {"id": "1911.11629", "submitter": "Anton Fuxjaeger", "authors": "Anton Fuxjaeger, Vaishak Belle", "title": "Logical Interpretations of Autoencoders", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The unification of low-level perception and high-level reasoning is a\nlong-standing problem in artificial intelligence, which has the potential to\nnot only bring the areas of logic and learning closer together but also\ndemonstrate how abstract concepts might emerge from sensory data. Precisely\nbecause deep learning methods dominate perception-based learning, including\nvision, speech, and linguistic grammar, there is fast-growing literature on how\nto integrate symbolic reasoning and deep learning. Broadly, efforts seem to\nfall into three camps: those focused on defining a logic whose formulas capture\ndeep learning, ones that integrate symbolic constraints in deep learning, and\nothers that allow neural computations and symbolic reasoning to co-exist\nseparately, to enjoy the strengths of both worlds. In this paper, we identify\nanother dimension to this inquiry: what do the hidden layers really capture,\nand how can we reason about that logically? In particular, we consider\nautoencoders that are widely used for dimensionality reduction and inject a\nsymbolic generative framework onto the feature layer. This allows us, among\nother things, to generate example images for a class to get a sense of what was\nlearned. Moreover, the modular structure of the proposed model makes it\npossible to learn relations over multiple images at a time, as well as handle\nnoisy labels. Our empirical evaluations show the promise of this inquiry.\n", "versions": [{"version": "v1", "created": "Tue, 26 Nov 2019 15:20:32 GMT"}], "update_date": "2019-11-27", "authors_parsed": [["Fuxjaeger", "Anton", ""], ["Belle", "Vaishak", ""]]}, {"id": "1911.11631", "submitter": "Rodrigo Santos", "authors": "Marcio Ferreira Moreno, Guilherme Lima, Rodrigo Costa Mesquita Santos,\n  Roberto Azevedo, Markus Endler", "title": "Bridging the Gap between Semantics and Multimedia Processing", "comments": "1st International Workshop on Bridging the Gap between Semantics and\n  Multimedia Processing (SeMP 2019): http://semp.mybluemix.net/2019/. arXiv\n  admin note: text overlap with arXiv:1911.09606", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we give an overview of the semantic gap problem in multimedia\nand discuss how machine learning and symbolic AI can be combined to narrow this\ngap. We describe the gap in terms of a classical architecture for multimedia\nprocessing and discuss a structured approach to bridge it. This approach\ncombines machine learning (for mapping signals to objects) and symbolic AI (for\nlinking objects to meanings). Our main goal is to raise awareness and discuss\nthe challenges involved in this structured approach to multimedia\nunderstanding, especially in the view of the latest developments in machine\nlearning and symbolic AI.\n", "versions": [{"version": "v1", "created": "Mon, 25 Nov 2019 13:12:35 GMT"}, {"version": "v2", "created": "Mon, 2 Dec 2019 12:25:22 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Moreno", "Marcio Ferreira", ""], ["Lima", "Guilherme", ""], ["Santos", "Rodrigo Costa Mesquita", ""], ["Azevedo", "Roberto", ""], ["Endler", "Markus", ""]]}, {"id": "1911.11641", "submitter": "Yonatan Bisk", "authors": "Yonatan Bisk, Rowan Zellers, Ronan Le Bras, Jianfeng Gao, Yejin Choi", "title": "PIQA: Reasoning about Physical Commonsense in Natural Language", "comments": "AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To apply eyeshadow without a brush, should I use a cotton swab or a\ntoothpick? Questions requiring this kind of physical commonsense pose a\nchallenge to today's natural language understanding systems. While recent\npretrained models (such as BERT) have made progress on question answering over\nmore abstract domains - such as news articles and encyclopedia entries, where\ntext is plentiful - in more physical domains, text is inherently limited due to\nreporting bias. Can AI systems learn to reliably answer physical common-sense\nquestions without experiencing the physical world? In this paper, we introduce\nthe task of physical commonsense reasoning and a corresponding benchmark\ndataset Physical Interaction: Question Answering or PIQA. Though humans find\nthe dataset easy (95% accuracy), large pretrained models struggle (77%). We\nprovide analysis about the dimensions of knowledge that existing models lack,\nwhich offers significant opportunities for future research.\n", "versions": [{"version": "v1", "created": "Tue, 26 Nov 2019 15:31:46 GMT"}], "update_date": "2019-11-27", "authors_parsed": [["Bisk", "Yonatan", ""], ["Zellers", "Rowan", ""], ["Bras", "Ronan Le", ""], ["Gao", "Jianfeng", ""], ["Choi", "Yejin", ""]]}, {"id": "1911.11668", "submitter": "Travis LaCroix", "authors": "Travis LaCroix", "title": "Biology and Compositionality: Empirical Considerations for\n  Emergent-Communication Protocols", "comments": "Accepted for NeurIPS 2019 workshop Emergent Communication: Towards\n  Natural Language", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Significant advances have been made in artificial systems by using biological\nsystems as a guide. However, there is often little interaction between\ncomputational models for emergent communication and biological models of the\nemergence of language. Many researchers in language origins and emergent\ncommunication take compositionality as their primary target for explaining how\nsimple communication systems can become more like natural language. However,\nthere is reason to think that compositionality is the wrong target on the\nbiological side, and so too the wrong target on the machine-learning side. As\nsuch, the purpose of this paper is to explore this claim. This has theoretical\nimplications for language origins research more generally, but the focus here\nwill be the implications for research on emergent communication in computer\nscience and machine learning---specifically regarding the types of programmes\nthat might be expected to work and those which will not. I further suggest an\nalternative approach for future research which focuses on reflexivity, rather\nthan compositionality, as a target for explaining how simple communication\nsystems may become more like natural language. I end by providing some\nreference to the language origins literature that may be of some use to\nresearchers in machine learning.\n", "versions": [{"version": "v1", "created": "Tue, 26 Nov 2019 16:07:44 GMT"}, {"version": "v2", "created": "Fri, 27 Dec 2019 19:36:13 GMT"}], "update_date": "2020-01-01", "authors_parsed": [["LaCroix", "Travis", ""]]}, {"id": "1911.11689", "submitter": "Kurt Stockinger", "authors": "Jonas Heitz, Kurt Stockinger", "title": "Join Query Optimization with Deep Reinforcement Learning Algorithms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Join query optimization is a complex task and is central to the performance\nof query processing. In fact it belongs to the class of NP-hard problems.\nTraditional query optimizers use dynamic programming (DP) methods combined with\na set of rules and restrictions to avoid exhaustive enumeration of all possible\njoin orders. However, DP methods are very resource intensive. Moreover, given\nsimplifying assumptions of attribute independence, traditional query optimizers\nrely on erroneous cost estimations, which can lead to suboptimal query plans.\nRecent success of deep reinforcement learning (DRL) creates new opportunities\nfor the field of query optimization to tackle the above-mentioned problems. In\nthis paper, we present our DRL-based Fully Observed Optimizer (FOOP) which is a\ngeneric query optimization framework that enables plugging in different machine\nlearning algorithms. The main idea of FOOP is to use a data-adaptive learning\nquery optimizer that avoids exhaustive enumerations of join orders and is thus\nsignificantly faster than traditional approaches based on dynamic programming.\nIn particular, we evaluate various DRL-algorithms and show that Proximal Policy\nOptimization significantly outperforms Q-learning based algorithms. Finally we\ndemonstrate how ensemble learning techniques combined with DRL can further\nimprove the query optimizer.\n", "versions": [{"version": "v1", "created": "Tue, 26 Nov 2019 16:48:25 GMT"}], "update_date": "2019-11-27", "authors_parsed": [["Heitz", "Jonas", ""], ["Stockinger", "Kurt", ""]]}, {"id": "1911.11699", "submitter": "Jacopo Panerati", "authors": "Rupert Mitchell, Jenny Fletcher, Jacopo Panerati, Amanda Prorok\n  (University of Cambridge)", "title": "Multi-Vehicle Mixed-Reality Reinforcement Learning for Autonomous\n  Multi-Lane Driving", "comments": "10 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Autonomous driving promises to transform road transport. Multi-vehicle and\nmulti-lane scenarios, however, present unique challenges due to constrained\nnavigation and unpredictable vehicle interactions. Learning-based\nmethods---such as deep reinforcement learning---are emerging as a promising\napproach to automatically design intelligent driving policies that can cope\nwith these challenges. Yet, the process of safely learning multi-vehicle\ndriving behaviours is hard: while collisions---and their near-avoidance---are\nessential to the learning process, directly executing immature policies on\nautonomous vehicles raises considerable safety concerns. In this article, we\npresent a safe and efficient framework that enables the learning of driving\npolicies for autonomous vehicles operating in a shared workspace, where the\nabsence of collisions cannot be guaranteed. Key to our learning procedure is a\nsim2real approach that uses real-world online policy adaptation in a\nmixed-reality setup, where other vehicles and static obstacles exist in the\nvirtual domain. This allows us to perform safe learning by simulating (and\nlearning from) collisions between the learning agent(s) and other objects in\nvirtual reality. Our results demonstrate that, after only a few runs in\nmixed-reality, collisions are significantly reduced.\n", "versions": [{"version": "v1", "created": "Tue, 26 Nov 2019 17:08:40 GMT"}, {"version": "v2", "created": "Mon, 10 Feb 2020 21:06:43 GMT"}], "update_date": "2020-02-12", "authors_parsed": [["Mitchell", "Rupert", "", "University of Cambridge"], ["Fletcher", "Jenny", "", "University of Cambridge"], ["Panerati", "Jacopo", "", "University of Cambridge"], ["Prorok", "Amanda", "", "University of Cambridge"]]}, {"id": "1911.11746", "submitter": "Alison Jenkins", "authors": "Alison Jenkins", "title": "Defending Against Adversarial Machine Learning", "comments": "adversarial machine learning, accuracy, probability, feature mask,\n  genetic algorithm, authorship attribution system, GEFeS", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An Adversarial System to attack and an Authorship Attribution System (AAS) to\ndefend itself against the attacks are analyzed. Defending a system against\nattacks from an adversarial machine learner can be done by randomly switching\nbetween models for the system, by detecting and reacting to changes in the\ndistribution of normal inputs, or by using other methods. Adversarial machine\nlearning is used to identify a system that is being used to map system inputs\nto outputs. Three types of machine learners are using for the model that is\nbeing attacked. The machine learners that are used to model the system being\nattacked are a Radial Basis Function Support Vector Machine, a Linear Support\nVector Machine, and a Feedforward Neural Network. The feature masks are evolved\nusing accuracy as the fitness measure. The system defends itself against\nadversarial machine learning attacks by identifying inputs that do not match\nthe probability distribution of normal inputs. The system also defends itself\nagainst adversarial attacks by randomly switching between the feature masks\nbeing used to map system inputs to outputs.\n", "versions": [{"version": "v1", "created": "Tue, 26 Nov 2019 18:28:47 GMT"}], "update_date": "2019-11-27", "authors_parsed": [["Jenkins", "Alison", ""]]}, {"id": "1911.11800", "submitter": "Vinoj Yasanga Jayasundara Magalle Hewa", "authors": "Hirunima Jayasekara, Vinoj Jayasundara, Jathushan Rajasegaran, Sandaru\n  Jayasekara, Suranga Seneviratne, Ranga Rodrigo", "title": "TimeCaps: Learning From Time Series Data with Capsule Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Capsule networks excel in understanding spatial relationships in 2D data for\nvision related tasks. Even though they are not designed to capture 1D temporal\nrelationships, with TimeCaps we demonstrate that given the ability, capsule\nnetworks excel in understanding temporal relationships. To this end, we\ngenerate capsules along the temporal and channel dimensions creating two\ntemporal feature detectors which learn contrasting relationships. TimeCaps\nsurpasses the state-of-the-art results by achieving 96.21% accuracy on\nidentifying 13 Electrocardiogram (ECG) signal beat categories, while achieving\non-par results on identifying 30 classes of short audio commands. Further, the\ninstantiation parameters inherently learnt by the capsule networks allow us to\ncompletely parameterize 1D signals which opens various possibilities in signal\nprocessing.\n", "versions": [{"version": "v1", "created": "Tue, 26 Nov 2019 19:28:57 GMT"}, {"version": "v2", "created": "Fri, 3 Jan 2020 16:58:10 GMT"}, {"version": "v3", "created": "Sat, 11 Jan 2020 12:01:24 GMT"}], "update_date": "2020-01-14", "authors_parsed": [["Jayasekara", "Hirunima", ""], ["Jayasundara", "Vinoj", ""], ["Rajasegaran", "Jathushan", ""], ["Jayasekara", "Sandaru", ""], ["Seneviratne", "Suranga", ""], ["Rodrigo", "Ranga", ""]]}, {"id": "1911.11928", "submitter": "Yang Yu", "authors": "Rong-Jun Qin, Jing-Cheng Pang, Yang Yu", "title": "Improving Fictitious Play Reinforcement Learning with Expanding Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fictitious play with reinforcement learning is a general and effective\nframework for zero-sum games. However, using the current deep neural network\nmodels, the implementation of fictitious play faces crucial challenges. Neural\nnetwork model training employs gradient descent approaches to update all\nconnection weights, and thus is easy to forget the old opponents after training\nto beat the new opponents. Existing approaches often maintain a pool of\nhistorical policy models to avoid the forgetting. However, learning to beat a\npool in stochastic games, i.e., a wide distribution over policy models, is\neither sample-consuming or insufficient to exploit all models with limited\namount of samples. In this paper, we propose a learning process with neural\nfictitious play to alleviate the above issues. We train a single model as our\npolicy model, which consists of sub-models and a selector. Everytime facing a\nnew opponent, the model is expanded by adding a new sub-model, where only the\nnew sub-model is updated instead of the whole model. At the same time, the\nselector is also updated to mix up the new sub-model with the previous ones at\nthe state-level, so that the model is maintained as a behavior strategy instead\nof a wide distribution over policy models. Experiments on Kuhn poker, a\ngrid-world Treasure Hunting game, and Mini-RTS environments show that the\nproposed approach alleviates the forgetting problem, and consequently improves\nthe learning efficiency and the robustness of neural fictitious play.\n", "versions": [{"version": "v1", "created": "Wed, 27 Nov 2019 03:14:37 GMT"}, {"version": "v2", "created": "Thu, 28 Nov 2019 04:54:29 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Qin", "Rong-Jun", ""], ["Pang", "Jing-Cheng", ""], ["Yu", "Yang", ""]]}, {"id": "1911.11931", "submitter": "Xuhui Zhou", "authors": "Xuhui Zhou, Yue Zhang, Leyang Cui, Dandan Huang", "title": "Evaluating Commonsense in Pre-trained Language Models", "comments": "AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Contextualized representations trained over large raw text data have given\nremarkable improvements for NLP tasks including question answering and reading\ncomprehension. There have been works showing that syntactic, semantic and word\nsense knowledge are contained in such representations, which explains why they\nbenefit such tasks. However, relatively little work has been done investigating\ncommonsense knowledge contained in contextualized representations, which is\ncrucial for human question answering and reading comprehension. We study the\ncommonsense ability of GPT, BERT, XLNet, and RoBERTa by testing them on seven\nchallenging benchmarks, finding that language modeling and its variants are\neffective objectives for promoting models' commonsense ability while\nbi-directional context and larger training set are bonuses. We additionally\nfind that current models do poorly on tasks require more necessary inference\nsteps. Finally, we test the robustness of models by making dual test cases,\nwhich are correlated so that the correct prediction of one sample should lead\nto correct prediction of the other. Interestingly, the models show confusion on\nthese test cases, which suggests that they learn commonsense at the surface\nrather than the deep level. We release a test set, named CATs publicly, for\nfuture research.\n", "versions": [{"version": "v1", "created": "Wed, 27 Nov 2019 03:22:40 GMT"}, {"version": "v2", "created": "Thu, 11 Feb 2021 05:14:52 GMT"}], "update_date": "2021-02-12", "authors_parsed": [["Zhou", "Xuhui", ""], ["Zhang", "Yue", ""], ["Cui", "Leyang", ""], ["Huang", "Dandan", ""]]}, {"id": "1911.11938", "submitter": "T.S. Jayram", "authors": "T.S. Jayram and Vincent Marois and Tomasz Kornuta and Vincent Albouy\n  and Emre Sevgen and Ahmet S. Ozcan", "title": "Transfer Learning in Visual and Relational Reasoning", "comments": "18 pages; more baseline comparisons; additional clarifications", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transfer learning has become the de facto standard in computer vision and\nnatural language processing, especially where labeled data is scarce. Accuracy\ncan be significantly improved by using pre-trained models and subsequent\nfine-tuning. In visual reasoning tasks, such as image question answering,\ntransfer learning is more complex. In addition to transferring the capability\nto recognize visual features, we also expect to transfer the system's ability\nto reason. Moreover, for video data, temporal reasoning adds another dimension.\nIn this work, we formalize these unique aspects of transfer learning and\npropose a theoretical framework for visual reasoning, exemplified by the\nwell-established CLEVR and COG datasets. Furthermore, we introduce a new,\nend-to-end differentiable recurrent model (SAMNet), which shows\nstate-of-the-art accuracy and better performance in transfer learning on both\ndatasets. The improved performance of SAMNet stems from its capability to\ndecouple the abstract multi-step reasoning from the length of the sequence and\nits selective attention enabling to store only the question-relevant objects in\nthe external memory.\n", "versions": [{"version": "v1", "created": "Wed, 27 Nov 2019 03:54:15 GMT"}, {"version": "v2", "created": "Sat, 15 Feb 2020 04:26:42 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Jayram", "T. S.", ""], ["Marois", "Vincent", ""], ["Kornuta", "Tomasz", ""], ["Albouy", "Vincent", ""], ["Sevgen", "Emre", ""], ["Ozcan", "Ahmet S.", ""]]}, {"id": "1911.11972", "submitter": "Aron Laszka", "authors": "Taha Eghtesad, Yevgeniy Vorobeychik, Aron Laszka", "title": "Adversarial Deep Reinforcement Learning based Adaptive Moving Target\n  Defense", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Moving target defense (MTD) is a proactive defense approach that aims to\nthwart attacks by continuously changing the attack surface of a system (e.g.,\nchanging host or network configurations), thereby increasing the adversary's\nuncertainty and attack cost. To maximize the impact of MTD, a defender must\nstrategically choose when and what changes to make, taking into account both\nthe characteristics of its system as well as the adversary's observed\nactivities. Finding an optimal strategy for MTD presents a significant\nchallenge, especially when facing a resourceful and determined adversary who\nmay respond to the defender's actions. In this paper, we propose a multi-agent\npartially-observable Markov Decision Process model of MTD and formulate a\ntwo-player general-sum game between the adversary and the defender. Based on an\nestablished model of adaptive MTD, we propose a multi-agent reinforcement\nlearning framework based on the double oracle algorithm to solve the game. In\nthe experiments, we show the effectiveness of our framework in finding optimal\npolicies.\n", "versions": [{"version": "v1", "created": "Wed, 27 Nov 2019 06:13:20 GMT"}, {"version": "v2", "created": "Thu, 20 Aug 2020 04:32:49 GMT"}], "update_date": "2020-08-21", "authors_parsed": [["Eghtesad", "Taha", ""], ["Vorobeychik", "Yevgeniy", ""], ["Laszka", "Aron", ""]]}, {"id": "1911.12060", "submitter": "Jun Zhao", "authors": "Jun Zhao, Teng Wang, Tao Bai, Kwok-Yan Lam, Zhiying Xu, Shuyu Shi,\n  Xuebin Ren, Xinyu Yang, Yang Liu, Han Yu", "title": "Reviewing and Improving the Gaussian Mechanism for Differential Privacy", "comments": "23 Pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.CY cs.DB cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Differential privacy provides a rigorous framework to quantify data privacy,\nand has received considerable interest recently. A randomized mechanism\nsatisfying $(\\epsilon, \\delta)$-differential privacy (DP) roughly means that,\nexcept with a small probability $\\delta$, altering a record in a dataset cannot\nchange the probability that an output is seen by more than a multiplicative\nfactor $e^{\\epsilon} $. A well-known solution to $(\\epsilon, \\delta)$-DP is the\nGaussian mechanism initiated by Dwork et al. [1] in 2006 with an improvement by\nDwork and Roth [2] in 2014, where a Gaussian noise amount $\\sqrt{2\\ln\n\\frac{2}{\\delta}} \\times \\frac{\\Delta}{\\epsilon}$ of [1] or $\\sqrt{2\\ln\n\\frac{1.25}{\\delta}} \\times \\frac{\\Delta}{\\epsilon}$ of [2] is added\nindependently to each dimension of the query result, for a query with\n$\\ell_2$-sensitivity $\\Delta$. Although both classical Gaussian mechanisms\n[1,2] assume $0 < \\epsilon \\leq 1$, our review finds that many studies in the\nliterature have used the classical Gaussian mechanisms under values of\n$\\epsilon$ and $\\delta$ where the added noise amounts of [1,2] do not achieve\n$(\\epsilon,\\delta)$-DP. We obtain such result by analyzing the optimal noise\namount $\\sigma_{DP-OPT}$ for $(\\epsilon,\\delta)$-DP and identifying $\\epsilon$\nand $\\delta$ where the noise amounts of classical mechanisms are even less than\n$\\sigma_{DP-OPT}$.\n  Since $\\sigma_{DP-OPT}$ has no closed-form expression and needs to be\napproximated in an iterative manner, we propose Gaussian mechanisms by deriving\nclosed-form upper bounds for $\\sigma_{DP-OPT}$. Our mechanisms achieve\n$(\\epsilon,\\delta)$-DP for any $\\epsilon$, while the classical mechanisms [1,2]\ndo not achieve $(\\epsilon,\\delta)$-DP for large $\\epsilon$ given $\\delta$.\nMoreover, the utilities of our mechanisms improve those of [1,2] and are close\nto that of the optimal yet more computationally expensive Gaussian mechanism.\n", "versions": [{"version": "v1", "created": "Wed, 27 Nov 2019 10:26:50 GMT"}, {"version": "v2", "created": "Sat, 7 Dec 2019 04:13:50 GMT"}], "update_date": "2019-12-10", "authors_parsed": [["Zhao", "Jun", ""], ["Wang", "Teng", ""], ["Bai", "Tao", ""], ["Lam", "Kwok-Yan", ""], ["Xu", "Zhiying", ""], ["Shi", "Shuyu", ""], ["Ren", "Xuebin", ""], ["Yang", "Xinyu", ""], ["Liu", "Yang", ""], ["Yu", "Han", ""]]}, {"id": "1911.12063", "submitter": "Xinjie Yao", "authors": "Xinjie Yao, Ji Zhang and Jean Oh", "title": "Following Social Groups: Socially Compliant Autonomous Navigation in\n  Dense Crowds", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In densely populated environments, socially compliant navigation is critical\nfor autonomous robots as driving close to people is unavoidable. This manner of\nsocial navigation is challenging given the constraints of human comfort and\nsocial rules. Traditional methods based on hand-craft cost functions to achieve\nthis task have difficulties to operate in the complex real world. Other\nlearning-based approaches fail to address the naturalness aspect from the\nperspective of collective formation behaviors. We present an autonomous\nnavigation system capable of operating in dense crowds and utilizing\ninformation of social groups. The underlying system incorporates a deep neural\nnetwork to track social groups and join the flow of a social group in\nfacilitating the navigation. A collision avoidance layer in the system further\nensures navigation safety. In experiments, our method generates socially\ncompliant behaviors as state-of-the-art methods. More importantly, the system\nis capable of navigating safely in a densely populated area (10+ people in a\n10m x 20m area) following crowd flows to reach the goal.\n", "versions": [{"version": "v1", "created": "Wed, 27 Nov 2019 10:32:18 GMT"}], "update_date": "2019-11-28", "authors_parsed": [["Yao", "Xinjie", ""], ["Zhang", "Ji", ""], ["Oh", "Jean", ""]]}, {"id": "1911.12073", "submitter": "Cezary Kaliszyk", "authors": "Miroslav Ol\\v{s}\\'ak, Cezary Kaliszyk and Josef Urban", "title": "Property Invariant Embedding for Automated Reasoning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automated reasoning and theorem proving have recently become major challenges\nfor machine learning. In other domains, representations that are able to\nabstract over unimportant transformations, such as abstraction over\ntranslations and rotations in vision, are becoming more common. Standard\nmethods of embedding mathematical formulas for learning theorem proving are\nhowever yet unable to handle many important transformations. In particular,\nembedding previously unseen labels, that often arise in definitional encodings\nand in Skolemization, has been very weak so far. Similar problems appear when\ntransferring knowledge between known symbols.\n  We propose a novel encoding of formulas that extends existing graph neural\nnetwork models. This encoding represents symbols only by nodes in the graph,\nwithout giving the network any knowledge of the original labels. We provide\nadditional links between such nodes that allow the network to recover the\nmeaning and therefore correctly embed such nodes irrespective of the given\nlabels. We test the proposed encoding in an automated theorem prover based on\nthe tableaux connection calculus, and show that it improves on the best\ncharacterizations used so far. The encoding is further evaluated on the premise\nselection task and a newly introduced symbol guessing task, and shown to\ncorrectly predict 65% of the symbol names.\n", "versions": [{"version": "v1", "created": "Wed, 27 Nov 2019 10:55:23 GMT"}], "update_date": "2019-11-28", "authors_parsed": [["Ol\u0161\u00e1k", "Miroslav", ""], ["Kaliszyk", "Cezary", ""], ["Urban", "Josef", ""]]}, {"id": "1911.12085", "submitter": "Preslav Nakov", "authors": "Su Nam Kim, Preslav Nakov", "title": "Large-Scale Noun Compound Interpretation Using Bootstrapping and the Web\n  as a Corpus", "comments": "noun compounds, paraphrasing verbs, paraphrases, semantic\n  interpretation, bootstrapping, semi-supervised learning", "journal-ref": "EMNLP-2011", "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Responding to the need for semantic lexical resources in natural language\nprocessing applications, we examine methods to acquire noun compounds (NCs),\ne.g., \"orange juice\", together with suitable fine-grained semantic\ninterpretations, e.g., \"squeezed from\", which are directly usable as\nparaphrases. We employ bootstrapping and web statistics, and utilize the\nrelationship between NCs and paraphrasing patterns to jointly extract NCs and\nsuch patterns in multiple alternating iterations. In evaluation, we found that\nhaving one compound noun fixed yields both a higher number of semantically\ninterpreted NCs and improved accuracy due to stronger semantic restrictions.\n", "versions": [{"version": "v1", "created": "Wed, 27 Nov 2019 11:25:43 GMT"}], "update_date": "2019-11-28", "authors_parsed": [["Kim", "Su Nam", ""], ["Nakov", "Preslav", ""]]}, {"id": "1911.12091", "submitter": "Preslav Nakov", "authors": "Liane Guillou, Christian Hardmeier, Preslav Nakov, Sara Stymne, J\\\"org\n  Tiedemann, Yannick Versley, Mauro Cettolo, Bonnie Webber, Andrei\n  Popescu-Belis", "title": "Findings of the 2016 WMT Shared Task on Cross-lingual Pronoun Prediction", "comments": "cross-lingual pronoun prediction, WMT, shared task, English, German,\n  French", "journal-ref": "WMT-2016", "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe the design, the evaluation setup, and the results of the 2016 WMT\nshared task on cross-lingual pronoun prediction. This is a classification task\nin which participants are asked to provide predictions on what pronoun class\nlabel should replace a placeholder value in the target-language text, provided\nin lemmatised and PoS-tagged form. We provided four subtasks, for the\nEnglish-French and English-German language pairs, in both directions. Eleven\nteams participated in the shared task; nine for the English-French subtask,\nfive for French-English, nine for English-German, and six for German-English.\nMost of the submissions outperformed two strong language-model based baseline\nsystems, with systems using deep recurrent neural networks outperforming those\nusing other architectures for most language pairs.\n", "versions": [{"version": "v1", "created": "Wed, 27 Nov 2019 11:45:15 GMT"}], "update_date": "2019-11-28", "authors_parsed": [["Guillou", "Liane", ""], ["Hardmeier", "Christian", ""], ["Nakov", "Preslav", ""], ["Stymne", "Sara", ""], ["Tiedemann", "J\u00f6rg", ""], ["Versley", "Yannick", ""], ["Cettolo", "Mauro", ""], ["Webber", "Bonnie", ""], ["Popescu-Belis", "Andrei", ""]]}, {"id": "1911.12116", "submitter": "David M\\\"unch", "authors": "Vanessa Buhrmester, David M\\\"unch, Michael Arens", "title": "Analysis of Explainers of Black Box Deep Neural Networks for Computer\n  Vision: A Survey", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Learning is a state-of-the-art technique to make inference on extensive\nor complex data. As a black box model due to their multilayer nonlinear\nstructure, Deep Neural Networks are often criticized to be non-transparent and\ntheir predictions not traceable by humans. Furthermore, the models learn from\nartificial datasets, often with bias or contaminated discriminating content.\nThrough their increased distribution, decision-making algorithms can contribute\npromoting prejudge and unfairness which is not easy to notice due to lack of\ntransparency. Hence, scientists developed several so-called explanators or\nexplainers which try to point out the connection between input and output to\nrepresent in a simplified way the inner structure of machine learning black\nboxes. In this survey we differ the mechanisms and properties of explaining\nsystems for Deep Neural Networks for Computer Vision tasks. We give a\ncomprehensive overview about taxonomy of related studies and compare several\nsurvey papers that deal with explainability in general. We work out the\ndrawbacks and gaps and summarize further research ideas.\n", "versions": [{"version": "v1", "created": "Wed, 27 Nov 2019 12:58:52 GMT"}], "update_date": "2019-11-28", "authors_parsed": [["Buhrmester", "Vanessa", ""], ["M\u00fcnch", "David", ""], ["Arens", "Michael", ""]]}, {"id": "1911.12122", "submitter": "Dmitry Baranchuk", "authors": "Dmitry Baranchuk, Artem Babenko", "title": "Towards Similarity Graphs Constructed by Deep Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Similarity graphs are an active research direction for the nearest neighbor\nsearch (NNS) problem. New algorithms for similarity graph construction are\ncontinuously being proposed and analyzed by both theoreticians and\npractitioners. However, existing construction algorithms are mostly based on\nheuristics and do not explicitly maximize the target performance measure, i.e.,\nsearch recall. Therefore, at the moment it is not clear whether the performance\nof similarity graphs has plateaued or more effective graphs can be constructed\nwith more theoretically grounded methods. In this paper, we introduce a new\nprincipled algorithm, based on adjacency matrix optimization, which explicitly\nmaximizes search efficiency. Namely, we propose a probabilistic model of a\nsimilarity graph defined in terms of its edge probabilities and show how to\nlearn these probabilities from data as a reinforcement learning task. As\nconfirmed by experiments, the proposed construction method can be used to\nrefine the state-of-the-art similarity graphs, achieving higher recall rates\nfor the same number of distance computations. Furthermore, we analyze the\nlearned graphs and reveal the structural properties that are responsible for\nmore efficient search.\n", "versions": [{"version": "v1", "created": "Wed, 27 Nov 2019 13:08:30 GMT"}, {"version": "v2", "created": "Thu, 13 Feb 2020 18:59:16 GMT"}], "update_date": "2020-02-14", "authors_parsed": [["Baranchuk", "Dmitry", ""], ["Babenko", "Artem", ""]]}, {"id": "1911.12126", "submitter": "Xiangxiang Chu", "authors": "Xiangxiang Chu and Tianbao Zhou and Bo Zhang and Jixiang Li", "title": "Fair DARTS: Eliminating Unfair Advantages in Differentiable Architecture\n  Search", "comments": "Accepted to ECCV 2020, camera ready version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Differentiable Architecture Search (DARTS) is now a widely disseminated\nweight-sharing neural architecture search method. However, it suffers from\nwell-known performance collapse due to an inevitable aggregation of skip\nconnections. In this paper, we first disclose that its root cause lies in an\nunfair advantage in exclusive competition. Through experiments, we show that if\neither of two conditions is broken, the collapse disappears. Thereby, we\npresent a novel approach called Fair DARTS where the exclusive competition is\nrelaxed to be collaborative. Specifically, we let each operation's\narchitectural weight be independent of others. Yet there is still an important\nissue of discretization discrepancy. We then propose a zero-one loss to push\narchitectural weights towards zero or one, which approximates an expected\nmulti-hot solution. Our experiments are performed on two mainstream search\nspaces, and we derive new state-of-the-art results on CIFAR-10 and ImageNet.\nOur code is available on https://github.com/xiaomi-automl/fairdarts .\n", "versions": [{"version": "v1", "created": "Wed, 27 Nov 2019 13:10:25 GMT"}, {"version": "v2", "created": "Tue, 10 Mar 2020 11:31:52 GMT"}, {"version": "v3", "created": "Wed, 15 Jul 2020 02:37:59 GMT"}, {"version": "v4", "created": "Thu, 16 Jul 2020 01:16:52 GMT"}], "update_date": "2020-07-17", "authors_parsed": [["Chu", "Xiangxiang", ""], ["Zhou", "Tianbao", ""], ["Zhang", "Bo", ""], ["Li", "Jixiang", ""]]}, {"id": "1911.12128", "submitter": "Johan F. Hoorn", "authors": "Johan F. Hoorn and Johnny K. W. Ho", "title": "Robot Affect: the Amygdala as Bloch Sphere", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI q-bio.NC quant-ph", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In the design of artificially sentient robots, an obstacle always has been\nthat conventional computers cannot really process information in parallel,\nwhereas the human affective system is capable of producing experiences of\nemotional concurrency (e.g., happy and sad). Another schism that has been in\nthe way is the persistent Cartesian divide between cognition and affect,\nwhereas people easily can reflect on their emotions or have feelings about a\nthought. As an essentially theoretical exercise, we posit that quantum physics\nat the basis of neurology explains observations in cognitive emotion psychology\nfrom the belief that the construct of reality is partially imagined (Im) in the\ncomplex coordinate space C^3. We propose a quantum computational account to\nmixed states of reflection and affect, while transforming known psychological\ndimensions into the actual quantum dynamics of electromotive forces. As a\nprecursor to actual simulations, we show examples of possible robot behaviors,\nusing Einstein-Podolsky-Rosen circuits. Keywords: emotion, reflection,\nmodelling, quantum computing\n", "versions": [{"version": "v1", "created": "Fri, 22 Nov 2019 07:35:49 GMT"}, {"version": "v2", "created": "Mon, 2 Dec 2019 03:29:35 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Hoorn", "Johan F.", ""], ["Ho", "Johnny K. W.", ""]]}, {"id": "1911.12199", "submitter": "Ana Lucic", "authors": "Ana Lucic, Harrie Oosterhuis, Hinda Haned, Maarten de Rijke", "title": "FOCUS: Flexible Optimizable Counterfactual Explanations for Tree\n  Ensembles", "comments": "Under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Model interpretability has become an important problem in machine learning\n(ML) due to the increased effect algorithmic decisions have on humans.\nCounterfactual explanations can help users understand not only why ML models\nmake certain decisions, but also give insight into how these decisions can be\nmodified. We frame the problem of finding counterfactual explanations as an\noptimization task and extend previous work that could only be applied to\ndifferentiable models. In order to accommodate non-differentiable models such\nas tree ensembles, we propose using probabilistic model approximations in the\noptimization framework. We introduce a simple approximation technique that is\neffective for finding counterfactual explanations for predictions of the\noriginal model using a range of distance metrics. We show that our\ncounterfactual examples are significantly closer to the original instances\ncompared to other methods designed for tree ensembles for four distance\nmetrics.\n", "versions": [{"version": "v1", "created": "Wed, 27 Nov 2019 14:57:11 GMT"}, {"version": "v2", "created": "Thu, 9 Jul 2020 10:07:38 GMT"}, {"version": "v3", "created": "Wed, 14 Oct 2020 07:35:36 GMT"}], "update_date": "2020-10-15", "authors_parsed": [["Lucic", "Ana", ""], ["Oosterhuis", "Harrie", ""], ["Haned", "Hinda", ""], ["de Rijke", "Maarten", ""]]}, {"id": "1911.12200", "submitter": "Pawel Gomoluch", "authors": "Pawel Gomoluch, Dalal Alrajeh, Alessandra Russo, Antonio Bucchiarone", "title": "Learning Neural Search Policies for Classical Planning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Heuristic forward search is currently the dominant paradigm in classical\nplanning. Forward search algorithms typically rely on a single, relatively\nsimple variation of best-first search and remain fixed throughout the process\nof solving a planning problem. Existing work combining multiple search\ntechniques usually aims at supporting best-first search with an additional\nexploratory mechanism, triggered using a handcrafted criterion. A notable\nexception is very recent work which combines various search techniques using a\ntrainable policy. It is, however, confined to a discrete action space\ncomprising several fixed subroutines.\n  In this paper, we introduce a parametrized search algorithm template which\ncombines various search techniques within a single routine. The template's\nparameter space defines an infinite space of search algorithms, including,\namong others, BFS, local and random search. We further introduce a neural\narchitecture for designating the values of the search parameters given the\nstate of the search. This enables expressing neural search policies that change\nthe values of the parameters as the search progresses. The policies can be\nlearned automatically, with the objective of maximizing the planner's\nperformance on a given distribution of planning problems. We consider a\ntraining setting based on a stochastic optimization algorithm known as the\ncross-entropy method (CEM). Experimental evaluation of our approach shows that\nit is capable of finding effective distribution-specific search policies,\noutperforming the relevant baselines.\n", "versions": [{"version": "v1", "created": "Wed, 27 Nov 2019 14:58:41 GMT"}], "update_date": "2019-11-28", "authors_parsed": [["Gomoluch", "Pawel", ""], ["Alrajeh", "Dalal", ""], ["Russo", "Alessandra", ""], ["Bucchiarone", "Antonio", ""]]}, {"id": "1911.12247", "submitter": "Thomas Kipf", "authors": "Thomas Kipf, Elise van der Pol, Max Welling", "title": "Contrastive Learning of Structured World Models", "comments": "ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A structured understanding of our world in terms of objects, relations, and\nhierarchies is an important component of human cognition. Learning such a\nstructured world model from raw sensory data remains a challenge. As a step\ntowards this goal, we introduce Contrastively-trained Structured World Models\n(C-SWMs). C-SWMs utilize a contrastive approach for representation learning in\nenvironments with compositional structure. We structure each state embedding as\na set of object representations and their relations, modeled by a graph neural\nnetwork. This allows objects to be discovered from raw pixel observations\nwithout direct supervision as part of the learning process. We evaluate C-SWMs\non compositional environments involving multiple interacting objects that can\nbe manipulated independently by an agent, simple Atari games, and a\nmulti-object physics simulation. Our experiments demonstrate that C-SWMs can\novercome limitations of models based on pixel reconstruction and outperform\ntypical representatives of this model class in highly structured environments,\nwhile learning interpretable object-based representations.\n", "versions": [{"version": "v1", "created": "Wed, 27 Nov 2019 16:10:04 GMT"}, {"version": "v2", "created": "Sun, 5 Jan 2020 13:38:44 GMT"}], "update_date": "2020-01-07", "authors_parsed": [["Kipf", "Thomas", ""], ["van der Pol", "Elise", ""], ["Welling", "Max", ""]]}, {"id": "1911.12303", "submitter": "Shantanu Chakraborty D.Eng.", "authors": "Shantanu Chakraborty, Tim Baarslag, Michael Kaisers", "title": "Automated Peer-to-peer Negotiation for Energy Contract Settlements in\n  Residential Cooperatives", "comments": "arXiv admin note: substantial text overlap with arXiv:1807.10978", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents an automated peer-to-peer negotiation strategy for\nsettling energy contracts among prosumers in a Residential Energy Cooperative\nconsidering heterogeneity prosumer preferences. The heterogeneity arises from\nprosumers' evaluation of energy contracts through multiple societal and\nenvironmental criteria and the prosumers' private preferences over those\ncriteria. The prosumers engage in bilateral negotiations with peers to mutually\nagree on periodical energy contracts/loans consisting of the energy volume to\nbe exchanged at that period and the return time of the exchanged energy. The\nnegotiating prosumers navigate through a common negotiation domain consisting\nof potential energy contracts and evaluate those contracts from their\nvaluations on the entailed criteria against a utility function that is robust\nagainst generation and demand uncertainty. From the repeated interactions, a\nprosumer gradually learns about the compatibility of its peers in reaching\nenergy contracts that are closer to Nash solutions. Empirical evaluation on\nreal demand, generation and storage profiles -- in multiple system scales --\nillustrates that the proposed negotiation based strategy can increase the\nsystem efficiency (measured by utilitarian social welfare) and fairness\n(measured by Nash social welfare) over a baseline strategy and an individual\nflexibility control strategy representing the status quo strategy. We thus\nelicit system benefits from peer-to-peer flexibility exchange already without\nany central coordination and market operator, providing a simple yet flexible\nand effective paradigm that complements existing markets.\n", "versions": [{"version": "v1", "created": "Tue, 26 Nov 2019 02:28:01 GMT"}], "update_date": "2019-11-28", "authors_parsed": [["Chakraborty", "Shantanu", ""], ["Baarslag", "Tim", ""], ["Kaisers", "Michael", ""]]}, {"id": "1911.12399", "submitter": "Abdur Rakib", "authors": "Abba Lawan and Abdur Rakib", "title": "FT-SWRL: A Fuzzy-Temporal Extension of Semantic Web Rule Language", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present, FT-SWRL, a fuzzy temporal extension to the Semantic Web Rule\nLanguage (SWRL), which combines fuzzy theories based on the valid-time temporal\nmodel to provide a standard approach for modeling imprecise temporal domain\nknowledge in OWL ontologies. The proposal introduces a fuzzy temporal model for\nthe semantic web, which is syntactically defined as a fuzzy temporal SWRL\nontology (SWRL-FTO) with a new set of fuzzy temporal SWRL built-ins for\ndefining their semantics. The SWRL-FTO hierarchically defines the necessary\nlinguistic terminologies and variables for the fuzzy temporal model. An example\nmodel demonstrating the usefulness of the fuzzy temporal SWRL built-ins to\nmodel imprecise temporal information is also represented. Fuzzification process\nof interval-based temporal logic is further discussed as a reasoning paradigm\nfor our FT-SWRL rules, with the aim of achieving a complete OWL-based fuzzy\ntemporal reasoning. Literature review on fuzzy temporal representation\napproaches, both within and without the use of ontologies, led to the\nconclusion that the FT-SWRL model can authoritatively serve as a formal\nspecification for handling imprecise temporal expressions on the semantic web.\n", "versions": [{"version": "v1", "created": "Wed, 27 Nov 2019 19:51:19 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Lawan", "Abba", ""], ["Rakib", "Abdur", ""]]}, {"id": "1911.12441", "submitter": "Trent Kyono", "authors": "Trent Kyono and Mihaela van der Schaar", "title": "Improving Model Robustness Using Causal Knowledge", "comments": "14 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For decades, researchers in fields, such as the natural and social sciences,\nhave been verifying causal relationships and investigating hypotheses that are\nnow well-established or understood as truth. These causal mechanisms are\nproperties of the natural world, and thus are invariant conditions regardless\nof the collection domain or environment. We show in this paper how prior\nknowledge in the form of a causal graph can be utilized to guide model\nselection, i.e., to identify from a set of trained networks the models that are\nthe most robust and invariant to unseen domains. Our method incorporates prior\nknowledge (which can be incomplete) as a Structural Causal Model (SCM) and\ncalculates a score based on the likelihood of the SCM given the target\npredictions of a candidate model and the provided input variables. We show on\nboth publicly available and synthetic datasets that our method is able to\nidentify more robust models in terms of generalizability to unseen\nout-of-distribution test examples and domains where covariates have shifted.\n", "versions": [{"version": "v1", "created": "Wed, 27 Nov 2019 21:57:00 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Kyono", "Trent", ""], ["van der Schaar", "Mihaela", ""]]}, {"id": "1911.12473", "submitter": "Dang Nguyen", "authors": "Dang Nguyen, Sunil Gupta, Santu Rana, Alistair Shilton, Svetha\n  Venkatesh", "title": "Bayesian Optimization for Categorical and Category-Specific Continuous\n  Inputs", "comments": "To appear at AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many real-world functions are defined over both categorical and\ncategory-specific continuous variables and thus cannot be optimized by\ntraditional Bayesian optimization (BO) methods. To optimize such functions, we\npropose a new method that formulates the problem as a multi-armed bandit\nproblem, wherein each category corresponds to an arm with its reward\ndistribution centered around the optimum of the objective function in\ncontinuous variables. Our goal is to identify the best arm and the maximizer of\nthe corresponding continuous function simultaneously. Our algorithm uses a\nThompson sampling scheme that helps connecting both multi-arm bandit and BO in\na unified framework. We extend our method to batch BO to allow parallel\noptimization when multiple resources are available. We theoretically analyze\nour method for convergence and prove sub-linear regret bounds. We perform a\nvariety of experiments: optimization of several benchmark functions,\nhyper-parameter tuning of a neural network, and automatic selection of the best\nmachine learning model along with its optimal hyper-parameters (a.k.a automated\nmachine learning). Comparisons with other methods demonstrate the effectiveness\nof our proposed method.\n", "versions": [{"version": "v1", "created": "Thu, 28 Nov 2019 01:05:03 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Nguyen", "Dang", ""], ["Gupta", "Sunil", ""], ["Rana", "Santu", ""], ["Shilton", "Alistair", ""], ["Venkatesh", "Svetha", ""]]}, {"id": "1911.12504", "submitter": "Xing Xu", "authors": "Xing Xu, Rongpeng Li, Zhifeng Zhao, Honggang Zhang", "title": "Stigmergic Independent Reinforcement Learning for Multi-Agent\n  Collaboration", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the rapid evolution of wireless mobile devices, there emerges an\nincreased need to design effective collaboration mechanisms between intelligent\nagents, so as to gradually approach the final collective objective through\ncontinuously learning from the environment based on their individual\nobservations. In this regard, independent reinforcement learning (IRL) is often\ndeployed in multi-agent collaboration to alleviate the problem of a\nnon-stationary learning environment. However, behavioral strategies of\nintelligent agents in IRL can only be formulated upon their local individual\nobservations of the global environment, and appropriate communication\nmechanisms must be introduced to reduce their behavioral localities. In this\npaper, we address the problem of communication between intelligent agents in\nIRL by jointly adopting mechanisms with two different scales. For the large\nscale, we introduce the stigmergy mechanism as an indirect communication bridge\nbetween independent learning agents, and carefully design a mathematical method\nto indicate the impact of digital pheromone. For the small scale, we propose a\nconflict-avoidance mechanism between adjacent agents by implementing an\nadditionally embedded neural network to provide more opportunities for\nparticipants with higher action priorities. In addition, we present a federal\ntraining method to effectively optimize the neural network of each agent in a\ndecentralized manner. Finally, we establish a simulation scenario in which a\nnumber of mobile agents in a certain area move automatically to form a\nspecified target shape. Extensive simulations demonstrate the effectiveness of\nour proposed method.\n", "versions": [{"version": "v1", "created": "Thu, 28 Nov 2019 03:11:17 GMT"}, {"version": "v2", "created": "Sat, 10 Oct 2020 02:43:50 GMT"}, {"version": "v3", "created": "Sat, 30 Jan 2021 04:55:57 GMT"}], "update_date": "2021-02-02", "authors_parsed": [["Xu", "Xing", ""], ["Li", "Rongpeng", ""], ["Zhao", "Zhifeng", ""], ["Zhang", "Honggang", ""]]}, {"id": "1911.12511", "submitter": "Vishal Jain", "authors": "Vishal Jain, William Fedus, Hugo Larochelle, Doina Precup, Marc G.\n  Bellemare", "title": "Algorithmic Improvements for Deep Reinforcement Learning applied to\n  Interactive Fiction", "comments": "To appear in Proceedings of the Thirty-Fourth AAAI Conference on\n  Artificial Intelligence (AAAI-20). Accepted for Oral presentation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Text-based games are a natural challenge domain for deep reinforcement\nlearning algorithms. Their state and action spaces are combinatorially large,\ntheir reward function is sparse, and they are partially observable: the agent\nis informed of the consequences of its actions through textual feedback. In\nthis paper we emphasize this latter point and consider the design of a deep\nreinforcement learning agent that can play from feedback alone. Our design\nrecognizes and takes advantage of the structural characteristics of text-based\ngames. We first propose a contextualisation mechanism, based on accumulated\nreward, which simplifies the learning problem and mitigates partial\nobservability. We then study different methods that rely on the notion that\nmost actions are ineffectual in any given situation, following Zahavy et al.'s\nidea of an admissible action. We evaluate these techniques in a series of\ntext-based games of increasing difficulty based on the TextWorld framework, as\nwell as the iconic game Zork. Empirically, we find that these techniques\nimprove the performance of a baseline deep reinforcement learning agent applied\nto text-based games.\n", "versions": [{"version": "v1", "created": "Thu, 28 Nov 2019 03:32:31 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Jain", "Vishal", ""], ["Fedus", "William", ""], ["Larochelle", "Hugo", ""], ["Precup", "Doina", ""], ["Bellemare", "Marc G.", ""]]}, {"id": "1911.12547", "submitter": "Preslav Nakov", "authors": "Shafiq Joty, Francisco Guzman, Lluis Marquez, Preslav Nakov", "title": "DiscoTK: Using Discourse Structure for Machine Translation Evaluation", "comments": "machine translation evaluation, machine translation, tree kernels,\n  discourse, convolutional kernels, discourse tree, RST, rhetorical structure\n  theory, ASIYA", "journal-ref": "WMT-2014", "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present novel automatic metrics for machine translation evaluation that\nuse discourse structure and convolution kernels to compare the discourse tree\nof an automatic translation with that of the human reference. We experiment\nwith five transformations and augmentations of a base discourse tree\nrepresentation based on the rhetorical structure theory, and we combine the\nkernel scores for each of them into a single score. Finally, we add other\nmetrics from the ASIYA MT evaluation toolkit, and we tune the weights of the\ncombination on actual human judgments. Experiments on the WMT12 and WMT13\nmetrics shared task datasets show correlation with human judgments that\noutperforms what the best systems that participated in these years achieved,\nboth at the segment and at the system level.\n", "versions": [{"version": "v1", "created": "Thu, 28 Nov 2019 06:05:12 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Joty", "Shafiq", ""], ["Guzman", "Francisco", ""], ["Marquez", "Lluis", ""], ["Nakov", "Preslav", ""]]}, {"id": "1911.12553", "submitter": "Ashutosh Kumar Tiwari", "authors": "Ashutosh Kumar Tiwari and Sandeep Varma Nadimpalli", "title": "Augmented Random Search for Quadcopter Control: An alternative to\n  Reinforcement Learning", "comments": "10 pages. 11 figures, Published in International Journal of\n  Information Technology and Computer Science(IJITCS),\n  http://www.mecs-press.org/ijitcs", "journal-ref": "IJITCS Vol. 11, No. 11, Nov. 2019 , Page Range. 24-33", "doi": "10.5815/ijitcs.2019.11.03", "report-no": null, "categories": "cs.LG cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Model-based reinforcement learning strategies are believed to exhibit more\nsignificant sample complexity than model-free strategies to control dynamical\nsystems,such as quadcopters.This belief that Model-based strategies that\ninvolve the use of well-trained neural networks for making such high-level\ndecisions always give better performance can be dispelled by making use of\nModel-free policy search methods.This paper proposes the use of a model-free\nrandom searching strategy,called Augmented Random Search(ARS),which is a better\nand faster approach of linear policy training for continuous control tasks like\ncontrolling a Quadcopters flight.The method achieves state-of-the-art accuracy\nby eliminating the use of too much data for the training of neural networks\nthat are present in the previous approaches to the task of Quadcopter\ncontrol.The paper also highlights the performance results of the searching\nstrategy used for this task in a strategically designed task environment with\nthe help of simulations.Reward collection performance over 1000 episodes and\nagents behavior in flight for augmented random search is compared with that of\nthe behavior for reinforcement learning state-of-the-art algorithm,called Deep\nDeterministic policy gradient(DDPG).Our simulations and results manifest that a\nhigh variability in performance is observed in commonly used strategies for\nsample efficiency of such tasks but the built policy network of ARS-Quad can\nreact relatively accurately to step response providing a better performing\nalternative to reinforcement learning strategies.\n", "versions": [{"version": "v1", "created": "Thu, 28 Nov 2019 06:46:06 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Tiwari", "Ashutosh Kumar", ""], ["Nadimpalli", "Sandeep Varma", ""]]}, {"id": "1911.12607", "submitter": "Ole-Christoffer Granmo", "authors": "Adrian Phoulady, Ole-Christoffer Granmo, Saeed Rahimi Gorji, Hady\n  Ahmady Phoulady", "title": "The Weighted Tsetlin Machine: Compressed Representations with Weighted\n  Clauses", "comments": "Accepted at the Ninth International Workshop on Statistical\n  Relational AI", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Tsetlin Machine (TM) is an interpretable mechanism for pattern\nrecognition that constructs conjunctive clauses from data. The clauses capture\nfrequent patterns with high discriminating power, providing increasing\nexpression power with each additional clause. However, the resulting accuracy\ngain comes at the cost of linear growth in computation time and memory usage.\nIn this paper, we present the Weighted Tsetlin Machine (WTM), which reduces\ncomputation time and memory usage by weighting the clauses. Real-valued\nweighting allows one clause to replace multiple, and supports fine-tuning the\nimpact of each clause. Our novel scheme simultaneously learns both the\ncomposition of the clauses and their weights. Furthermore, we increase training\nefficiency by replacing $k$ Bernoulli trials of success probability $p$ with a\nuniform sample of average size $p k$, the size drawn from a binomial\ndistribution. In our empirical evaluation, the WTM achieved the same accuracy\nas the TM on MNIST, IMDb, and Connect-4, requiring only $1/4$, $1/3$, and\n$1/50$ of the clauses, respectively. With the same number of clauses, the WTM\noutperformed the TM, obtaining peak test accuracies of respectively $98.63\\%$,\n$90.37\\%$, and $87.91\\%$. Finally, our novel sampling scheme reduced sample\ngeneration time by a factor of $7$.\n", "versions": [{"version": "v1", "created": "Thu, 28 Nov 2019 09:23:09 GMT"}, {"version": "v2", "created": "Thu, 5 Dec 2019 08:00:42 GMT"}, {"version": "v3", "created": "Mon, 13 Jan 2020 07:50:16 GMT"}, {"version": "v4", "created": "Tue, 14 Jan 2020 17:51:02 GMT"}], "update_date": "2020-01-15", "authors_parsed": [["Phoulady", "Adrian", ""], ["Granmo", "Ole-Christoffer", ""], ["Gorji", "Saeed Rahimi", ""], ["Phoulady", "Hady Ahmady", ""]]}, {"id": "1911.12736", "submitter": "Xin Huang", "authors": "Xin Huang and Stephen G. McGill and Jonathan A. DeCastro and Luke\n  Fletcher and John J. Leonard and Brian C. Williams and Guy Rosman", "title": "DiversityGAN: Diversity-Aware Vehicle Motion Prediction via Latent\n  Semantic Sampling", "comments": "8 pages, 5 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Vehicle trajectory prediction is crucial for autonomous driving and advanced\ndriver assistant systems. While existing approaches may sample from a predicted\ndistribution of vehicle trajectories, they lack the ability to explore it -- a\nkey ability for evaluating safety from a planning and verification perspective.\nIn this work, we devise a novel approach for generating realistic and diverse\nvehicle trajectories. We extend the generative adversarial network (GAN)\nframework with a low-dimensional approximate semantic space, and shape that\nspace to capture semantics such as merging and turning. We sample from this\nspace in a way that mimics the predicted distribution, but allows us to control\ncoverage of semantically distinct outcomes. We validate our approach on a\npublicly available dataset and show results that achieve state-of-the-art\nprediction performance, while providing improved coverage of the space of\npredicted trajectory semantics.\n", "versions": [{"version": "v1", "created": "Thu, 28 Nov 2019 14:51:09 GMT"}, {"version": "v2", "created": "Sun, 22 Mar 2020 01:12:23 GMT"}], "update_date": "2020-03-24", "authors_parsed": [["Huang", "Xin", ""], ["McGill", "Stephen G.", ""], ["DeCastro", "Jonathan A.", ""], ["Fletcher", "Luke", ""], ["Leonard", "John J.", ""], ["Williams", "Brian C.", ""], ["Rosman", "Guy", ""]]}, {"id": "1911.12753", "submitter": "Jose Camacho-Collados", "authors": "Zied Bouraoui, Jose Camacho-Collados and Steven Schockaert", "title": "Inducing Relational Knowledge from BERT", "comments": "Accepted to AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the most remarkable properties of word embeddings is the fact that\nthey capture certain types of semantic and syntactic relationships. Recently,\npre-trained language models such as BERT have achieved groundbreaking results\nacross a wide range of Natural Language Processing tasks. However, it is\nunclear to what extent such models capture relational knowledge beyond what is\nalready captured by standard word embeddings. To explore this question, we\npropose a methodology for distilling relational knowledge from a pre-trained\nlanguage model. Starting from a few seed instances of a given relation, we\nfirst use a large text corpus to find sentences that are likely to express this\nrelation. We then use a subset of these extracted sentences as templates.\nFinally, we fine-tune a language model to predict whether a given word pair is\nlikely to be an instance of some relation, when given an instantiated template\nfor that relation as input.\n", "versions": [{"version": "v1", "created": "Thu, 28 Nov 2019 15:38:53 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Bouraoui", "Zied", ""], ["Camacho-Collados", "Jose", ""], ["Schockaert", "Steven", ""]]}, {"id": "1911.12825", "submitter": "Jhelum Chakravorty", "authors": "Jhelum Chakravorty, Nadeem Ward, Julien Roy, Maxime\n  Chevalier-Boisvert, Sumana Basu, Andrei Lupu, Doina Precup", "title": "Option-Critic in Cooperative Multi-agent Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.MA cs.SY eess.SY math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we investigate learning temporal abstractions in cooperative\nmulti-agent systems, using the options framework (Sutton et al, 1999). First,\nwe address the planning problem for the decentralized POMDP represented by the\nmulti-agent system, by introducing a \\emph{common information approach}. We use\nthe notion of \\emph{common beliefs} and broadcasting to solve an equivalent\ncentralized POMDP problem. Then, we propose the Distributed Option Critic (DOC)\nalgorithm, which uses centralized option evaluation and decentralized\nintra-option improvement. We theoretically analyze the asymptotic convergence\nof DOC and build a new multi-agent environment to demonstrate its validity. Our\nexperiments empirically show that DOC performs competitively against baselines\nand scales with the number of agents.\n", "versions": [{"version": "v1", "created": "Thu, 28 Nov 2019 18:38:19 GMT"}, {"version": "v2", "created": "Mon, 6 Jan 2020 05:50:51 GMT"}, {"version": "v3", "created": "Thu, 19 Mar 2020 23:11:08 GMT"}], "update_date": "2020-03-23", "authors_parsed": [["Chakravorty", "Jhelum", ""], ["Ward", "Nadeem", ""], ["Roy", "Julien", ""], ["Chevalier-Boisvert", "Maxime", ""], ["Basu", "Sumana", ""], ["Lupu", "Andrei", ""], ["Precup", "Doina", ""]]}, {"id": "1911.12851", "submitter": "Rui Silva", "authors": "Rui Silva, Miguel Vasco, Francisco S. Melo, Ana Paiva, Manuela Veloso", "title": "Playing Games in the Dark: An approach for cross-modality transfer in\n  reinforcement learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we explore the use of latent representations obtained from\nmultiple input sensory modalities (such as images or sounds) in allowing an\nagent to learn and exploit policies over different subsets of input modalities.\nWe propose a three-stage architecture that allows a reinforcement learning\nagent trained over a given sensory modality, to execute its task on a different\nsensory modality-for example, learning a visual policy over image inputs, and\nthen execute such policy when only sound inputs are available. We show that the\ngeneralized policies achieve better out-of-the-box performance when compared to\ndifferent baselines. Moreover, we show this holds in different OpenAI gym and\nvideo game environments, even when using different multimodal generative models\nand reinforcement learning algorithms.\n", "versions": [{"version": "v1", "created": "Thu, 28 Nov 2019 20:15:48 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Silva", "Rui", ""], ["Vasco", "Miguel", ""], ["Melo", "Francisco S.", ""], ["Paiva", "Ana", ""], ["Veloso", "Manuela", ""]]}, {"id": "1911.12905", "submitter": "Piotr Mi{\\l}o\\'s", "authors": "B{\\l}a\\.zej Osi\\'nski, Adam Jakubowski, Piotr Mi{\\l}o\\'s, Pawe{\\l}\n  Zi\\k{e}cina, Christopher Galias, Silviu Homoceanu, and Henryk Michalewski", "title": "Simulation-based reinforcement learning for real-world autonomous\n  driving", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We use reinforcement learning in simulation to obtain a driving system\ncontrolling a full-size real-world vehicle. The driving policy takes RGB images\nfrom a single camera and their semantic segmentation as input. We use mostly\nsynthetic data, with labelled real-world data appearing only in the training of\nthe segmentation network.\n  Using reinforcement learning in simulation and synthetic data is motivated by\nlowering costs and engineering effort.\n  In real-world experiments we confirm that we achieved successful sim-to-real\npolicy transfer. Based on the extensive evaluation, we analyze how design\ndecisions about perception, control, and training impact the real-world\nperformance.\n", "versions": [{"version": "v1", "created": "Fri, 29 Nov 2019 00:08:58 GMT"}, {"version": "v2", "created": "Thu, 26 Dec 2019 05:25:47 GMT"}, {"version": "v3", "created": "Wed, 4 Mar 2020 14:19:18 GMT"}], "update_date": "2020-03-05", "authors_parsed": [["Osi\u0144ski", "B\u0142a\u017cej", ""], ["Jakubowski", "Adam", ""], ["Mi\u0142o\u015b", "Piotr", ""], ["Zi\u0119cina", "Pawe\u0142", ""], ["Galias", "Christopher", ""], ["Homoceanu", "Silviu", ""], ["Michalewski", "Henryk", ""]]}, {"id": "1911.12949", "submitter": "Zhanhao Xiao", "authors": "Zhanhao Xiao, Hai Wan, Hankui Hankz Zhuo, Andreas Herzig, Laurent\n  Perrussel, Peilin Chen", "title": "Refining HTN Methods via Task Insertion with Preferences", "comments": "8 pages,7 figures, Accepted in AAAI-20", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hierarchical Task Network (HTN) planning is showing its power in real-world\nplanning. Although domain experts have partial hierarchical domain knowledge,\nit is time-consuming to specify all HTN methods, leaving them incomplete. On\nthe other hand, traditional HTN learning approaches focus only on declarative\ngoals, omitting the hierarchical domain knowledge. In this paper, we propose a\nnovel learning framework to refine HTN methods via task insertion with\ncompletely preserving the original methods. As it is difficult to identify\nincomplete methods without designating declarative goals for compound tasks, we\nintroduce the notion of prioritized preference to capture the incompleteness\npossibility of methods. Specifically, the framework first computes the\npreferred completion profile w.r.t. the prioritized preference to refine the\nincomplete methods. Then it finds the minimal set of refined methods via a\nmethod substitution operation. Experimental analysis demonstrates that our\napproach is effective, especially in solving new HTN planning instances.\n", "versions": [{"version": "v1", "created": "Fri, 29 Nov 2019 04:38:22 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Xiao", "Zhanhao", ""], ["Wan", "Hai", ""], ["Zhuo", "Hankui Hankz", ""], ["Herzig", "Andreas", ""], ["Perrussel", "Laurent", ""], ["Chen", "Peilin", ""]]}, {"id": "1911.13009", "submitter": "Manuel Lopes", "authors": "Manuel Lopes, Francisco Melo", "title": "Class Teaching for Inverse Reinforcement Learners", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we propose the first machine teaching algorithm for multiple\ninverse reinforcement learners. Specifically, our contributions are: (i) we\nformally introduce the problem of teaching a sequential task to a heterogeneous\ngroup of learners; (ii) we identify conditions under which it is possible to\nconduct such teaching using the same demonstration for all learners; and (iii)\nwe propose and evaluate a simple algorithm that computes a demonstration(s)\nensuring that all agents in a heterogeneous class learn a task description that\nis compatible with the target task. Our analysis shows that, contrary to other\nteaching problems, teaching a heterogeneous class with a single demonstration\nmay not be possible as the differences between agents increase. We also\nshowcase the advantages of our proposed machine teaching approach against\nseveral possible alternatives.\n", "versions": [{"version": "v1", "created": "Fri, 29 Nov 2019 09:22:51 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Lopes", "Manuel", ""], ["Melo", "Francisco", ""]]}, {"id": "1911.13024", "submitter": "Timotheus Kampik", "authors": "Timotheus Kampik and Juan Carlos Nieves", "title": "Abstract Argumentation and the Rational Man", "comments": "To appear in the Journal of Logic and Computation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Abstract argumentation has emerged as a method for non-monotonic reasoning\nthat has gained popularity in the symbolic artificial intelligence community.\nIn the literature, the different approaches to abstract argumentation that were\nrefined over the years are typically evaluated from a formal logics\nperspective; an analysis that is based on models of economically rational\ndecision-making does not exist. In this paper, we work towards addressing this\nissue by analyzing abstract argumentation from the perspective of the rational\nman paradigm in microeconomic theory. To assess under which conditions abstract\nargumentation-based decision-making can be considered economically rational, we\nderive reference independence as a non-monotonic inference property from a\nformal model of economic rationality and create a new argumentation principle\nthat ensures compliance with this property. We then compare the reference\nindependence principle with other reasoning principles, in particular with\ncautious monotony and rational monotony. We show that the argumentation\nsemantics as proposed in Dung's seminal paper, as well as other semantics we\nevaluate -- with the exception of naive semantics and the SCC-recursive CF2\nsemantics -- violate the reference independence principle. Consequently, we\ninvestigate how structural properties of argumentation frameworks impact the\nreference independence principle, and identify cyclic expansions (both even and\nodd cycles) as the root of the problem. Finally, we put reference independence\ninto the context of preference-based argumentation and show that for this\nargumentation variant, which explicitly models preferences, reference\nindependence cannot be ensured in a straight-forward manner.\n", "versions": [{"version": "v1", "created": "Fri, 29 Nov 2019 09:51:44 GMT"}, {"version": "v2", "created": "Fri, 13 Dec 2019 23:03:08 GMT"}, {"version": "v3", "created": "Tue, 17 Mar 2020 15:47:04 GMT"}, {"version": "v4", "created": "Thu, 6 Aug 2020 19:28:17 GMT"}, {"version": "v5", "created": "Mon, 30 Nov 2020 20:08:02 GMT"}, {"version": "v6", "created": "Fri, 8 Jan 2021 12:58:59 GMT"}], "update_date": "2021-01-11", "authors_parsed": [["Kampik", "Timotheus", ""], ["Nieves", "Juan Carlos", ""]]}, {"id": "1911.13056", "submitter": "Dmitry Akimov", "authors": "Dmitry Akimov", "title": "Distributed Soft Actor-Critic with Multivariate Reward Representation\n  and Knowledge Distillation", "comments": "9 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we describe NeurIPS 2019 Learning to Move - Walk Around\nchallenge physics-based environment and present our solution to this\ncompetition which scored 1303.727 mean reward points and took 3rd place. Our\nmethod combines recent advances from both continuous- and discrete-action space\nreinforcement learning, such as Soft Actor-Critic and Recurrent Experience\nReplay in Distributed Reinforcement Learning. We trained our agent in two\nstages: to move somewhere at the first stage and to follow the target velocity\nfield at the second stage. We also introduce novel Q-function split technique,\nwhich we believe facilitates the task of training an agent, allows critic\npretraining and reusing it for solving harder problems, and mitigate reward\nshaping design efforts.\n", "versions": [{"version": "v1", "created": "Fri, 29 Nov 2019 11:15:26 GMT"}, {"version": "v2", "created": "Fri, 10 Apr 2020 12:16:34 GMT"}], "update_date": "2020-04-13", "authors_parsed": [["Akimov", "Dmitry", ""]]}, {"id": "1911.13071", "submitter": "Sebastian Risi", "authors": "Sebastian Risi, Julian Togelius", "title": "Increasing Generality in Machine Learning through Procedural Content\n  Generation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Procedural Content Generation (PCG) refers to the practice, in videogames and\nother games, of generating content such as levels, quests, or characters\nalgorithmically. Motivated by the need to make games replayable, as well as to\nreduce authoring burden, limit storage space requirements, and enable\nparticular aesthetics, a large number of PCG methods have been devised by game\ndevelopers. Additionally, researchers have explored adapting methods from\nmachine learning, optimization, and constraint solving to PCG problems. Games\nhave been widely used in AI research since the inception of the field, and in\nrecent years have been used to develop and benchmark new machine learning\nalgorithms. Through this practice, it has become more apparent that these\nalgorithms are susceptible to overfitting. Often, an algorithm will not learn a\ngeneral policy, but instead a policy that will only work for a particular\nversion of a particular task with particular initial parameters. In response,\nresearchers have begun exploring randomization of problem parameters to\ncounteract such overfitting and to allow trained policies to more easily\ntransfer from one environment to another, such as from a simulated robot to a\nrobot in the real world. Here we review the large amount of existing work on\nPCG, which we believe has an important role to play in increasing the\ngenerality of machine learning methods. The main goal here is to present RL/AI\nwith new tools from the PCG toolbox, and its secondary goal is to explain to\ngame developers and researchers a way in which their work is relevant to AI\nresearch.\n", "versions": [{"version": "v1", "created": "Fri, 29 Nov 2019 11:55:10 GMT"}, {"version": "v2", "created": "Mon, 16 Mar 2020 22:00:52 GMT"}], "update_date": "2020-03-18", "authors_parsed": [["Risi", "Sebastian", ""], ["Togelius", "Julian", ""]]}, {"id": "1911.13101", "submitter": "William Shen", "authors": "William Shen, Felipe Trevizan, Sylvie Thi\\'ebaux", "title": "Learning Domain-Independent Planning Heuristics with Hypergraph Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present the first approach capable of learning domain-independent planning\nheuristics entirely from scratch. The heuristics we learn map the hypergraph\nrepresentation of the delete-relaxation of the planning problem at hand, to a\ncost estimate that approximates that of the least-cost path from the current\nstate to the goal through the hypergraph. We generalise Graph Networks to\nobtain a new framework for learning over hypergraphs, which we specialise to\nlearn planning heuristics by training over state/value pairs obtained from\noptimal cost plans. Our experiments show that the resulting architecture,\nSTRIPS-HGNs, is capable of learning heuristics that are competitive with\nexisting delete-relaxation heuristics including LM-cut. We show that the\nheuristics we learn are able to generalise across different problems and\ndomains, including to domains that were not seen during training.\n", "versions": [{"version": "v1", "created": "Fri, 29 Nov 2019 13:24:48 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Shen", "William", ""], ["Trevizan", "Felipe", ""], ["Thi\u00e9baux", "Sylvie", ""]]}, {"id": "1911.13135", "submitter": "Gabriel Turinici", "authors": "Gabriel Turinici (CEREMADE, Universit\\'e Paris Dauphine - PSL)", "title": "Radon Sobolev Variational Auto-Encoders", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.NE", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  The quality of generative models (such as Generative adversarial networks and\nVariational Auto-Encoders) depends heavily on the choice of a good probability\ndistance. However some popular metrics like the Wasserstein or the Sliced\nWasserstein distances, the Jensen-Shannon divergence, the Kullback-Leibler\ndivergence, lack convenient properties such as (geodesic) convexity, fast\nevaluation and so on. To address these shortcomings, we introduce a class of\ndistances that have built-in convexity. We investigate the relationship with\nsome known paradigms (sliced distances - a synonym for Radon distances -,\nreproducing kernel Hilbert spaces, energy distances). The distances are shown\nto possess fast implementations and are included in an adapted Variational\nAuto-Encoder termed Radon Sobolev Variational Auto-Encoder (RS-VAE) which\nproduces high quality results on standard generative datasets.\n  Keywords: Variational Auto-Encoder; Generative model; Sobolev spaces; Radon\nSobolev Variational Auto-Encoder;\n", "versions": [{"version": "v1", "created": "Fri, 29 Nov 2019 15:02:28 GMT"}, {"version": "v2", "created": "Mon, 16 Mar 2020 17:00:16 GMT"}, {"version": "v3", "created": "Wed, 14 Apr 2021 18:08:35 GMT"}], "update_date": "2021-04-16", "authors_parsed": [["Turinici", "Gabriel", "", "CEREMADE, Universit\u00e9 Paris Dauphine - PSL"]]}, {"id": "1911.13152", "submitter": "Daniel Furelos-Blanco", "authors": "Daniel Furelos-Blanco, Mark Law, Alessandra Russo, Krysia Broda and\n  Anders Jonsson", "title": "Induction of Subgoal Automata for Reinforcement Learning", "comments": "Preprint accepted for publication to the 34th AAAI Conference on\n  Artificial Intelligence (AAAI-20)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.LO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we present ISA, a novel approach for learning and exploiting\nsubgoals in reinforcement learning (RL). Our method relies on inducing an\nautomaton whose transitions are subgoals expressed as propositional formulas\nover a set of observable events. A state-of-the-art inductive logic programming\nsystem is used to learn the automaton from observation traces perceived by the\nRL agent. The reinforcement learning and automaton learning processes are\ninterleaved: a new refined automaton is learned whenever the RL agent generates\na trace not recognized by the current automaton. We evaluate ISA in several\ngridworld problems and show that it performs similarly to a method for which\nautomata are given in advance. We also show that the learned automata can be\nexploited to speed up convergence through reward shaping and transfer learning\nacross multiple tasks. Finally, we analyze the running time and the number of\ntraces that ISA needs to learn an automata, and the impact that the number of\nobservable events has on the learner's performance.\n", "versions": [{"version": "v1", "created": "Fri, 29 Nov 2019 15:28:54 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Furelos-Blanco", "Daniel", ""], ["Law", "Mark", ""], ["Russo", "Alessandra", ""], ["Broda", "Krysia", ""], ["Jonsson", "Anders", ""]]}, {"id": "1911.13182", "submitter": "Jie Wang", "authors": "Liming Deng, Jie Wang, Hangming Liang, Hui Chen, Zhiqiang Xie, Bojin\n  Zhuang, Shaojun Wang, Jing Xiao", "title": "An Iterative Polishing Framework based on Quality Aware Masked Language\n  Model for Chinese Poetry Generation", "comments": "accepted by AAAI-2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Owing to its unique literal and aesthetical characteristics, automatic\ngeneration of Chinese poetry is still challenging in Artificial Intelligence,\nwhich can hardly be straightforwardly realized by end-to-end methods. In this\npaper, we propose a novel iterative polishing framework for highly qualified\nChinese poetry generation. In the first stage, an encoder-decoder structure is\nutilized to generate a poem draft. Afterwards, our proposed Quality-Aware\nMasked Language Model (QAMLM) is employed to polish the draft towards higher\nquality in terms of linguistics and literalness. Based on a multi-task learning\nscheme, QA-MLM is able to determine whether polishing is needed based on the\npoem draft. Furthermore, QAMLM is able to localize improper characters of the\npoem draft and substitute with newly predicted ones accordingly. Benefited from\nthe masked language model structure, QAMLM incorporates global context\ninformation into the polishing process, which can obtain more appropriate\npolishing results than the unidirectional sequential decoding. Moreover, the\niterative polishing process will be terminated automatically when QA-MLM\nregards the processed poem as a qualified one. Both human and automatic\nevaluation have been conducted, and the results demonstrate that our approach\nis effective to improve the performance of encoder-decoder structure.\n", "versions": [{"version": "v1", "created": "Fri, 29 Nov 2019 16:34:00 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Deng", "Liming", ""], ["Wang", "Jie", ""], ["Liang", "Hangming", ""], ["Chen", "Hui", ""], ["Xie", "Zhiqiang", ""], ["Zhuang", "Bojin", ""], ["Wang", "Shaojun", ""], ["Xiao", "Jing", ""]]}, {"id": "1911.13229", "submitter": "Timo Nolle", "authors": "Timo Nolle, Alexander Seeliger, Nils Thoma, Max M\\\"uhlh\\\"auser", "title": "DeepAlign: Alignment-based Process Anomaly Correction using Recurrent\n  Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose DeepAlign, a novel approach to multi-perspective\nprocess anomaly correction, based on recurrent neural networks and\nbidirectional beam search. At the core of the DeepAlign algorithm are two\nrecurrent neural networks trained to predict the next event. One is reading\nsequences of process executions from left to right, while the other is reading\nthe sequences from right to left. By combining the predictive capabilities of\nboth neural networks, we show that it is possible to calculate sequence\nalignments, which are used to detect and correct anomalies. DeepAlign utilizes\nthe case-level and event-level attributes to closely model the decisions within\na process. We evaluate the performance of our approach on an elaborate data\ncorpus of 252 realistic synthetic event logs and compare it to three\nstate-of-the-art conformance checking methods. DeepAlign produces better\ncorrections than the rest of the field reaching an overall $F_1$ score of\n$0.9572$ across all datasets, whereas the best comparable state-of-the-art\nmethod reaches $0.6411$.\n", "versions": [{"version": "v1", "created": "Fri, 29 Nov 2019 17:34:52 GMT"}, {"version": "v2", "created": "Mon, 23 Mar 2020 20:48:29 GMT"}], "update_date": "2020-03-25", "authors_parsed": [["Nolle", "Timo", ""], ["Seeliger", "Alexander", ""], ["Thoma", "Nils", ""], ["M\u00fchlh\u00e4user", "Max", ""]]}]