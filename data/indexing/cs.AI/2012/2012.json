[{"id": "2012.00012", "submitter": "Liye Fu", "authors": "Liye Fu, Susan R. Fussell and Cristian Danescu-Niculescu-Mizil", "title": "Facilitating the Communication of Politeness through Fine-Grained\n  Paraphrasing", "comments": "Proceedings of EMNLP 2020, 14 pages. Data and code at\n  https://convokit.cornell.edu/ and\n  https://github.com/CornellNLP/politeness-paraphrase", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.CY cs.HC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Aided by technology, people are increasingly able to communicate across\ngeographical, cultural, and language barriers. This ability also results in new\nchallenges, as interlocutors need to adapt their communication approaches to\nincreasingly diverse circumstances. In this work, we take the first steps\ntowards automatically assisting people in adjusting their language to a\nspecific communication circumstance.\n  As a case study, we focus on facilitating the accurate transmission of\npragmatic intentions and introduce a methodology for suggesting paraphrases\nthat achieve the intended level of politeness under a given communication\ncircumstance. We demonstrate the feasibility of this approach by evaluating our\nmethod in two realistic communication scenarios and show that it can reduce the\npotential for misalignment between the speaker's intentions and the listener's\nperceptions in both cases.\n", "versions": [{"version": "v1", "created": "Mon, 30 Nov 2020 19:00:00 GMT"}], "update_date": "2020-12-02", "authors_parsed": [["Fu", "Liye", ""], ["Fussell", "Susan R.", ""], ["Danescu-Niculescu-Mizil", "Cristian", ""]]}, {"id": "2012.00053", "submitter": "Haoxiang Ma", "authors": "Haoxiang Ma, Jie Fu", "title": "Attention-Based Planning with Active Perception", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Attention control is a key cognitive ability for humans to select information\nrelevant to the current task. This paper develops a computational model of\nattention and an algorithm for attention-based probabilistic planning in Markov\ndecision processes. In attention-based planning, the robot decides to be in\ndifferent attention modes. An attention mode corresponds to a subset of state\nvariables monitored by the robot. By switching between different attention\nmodes, the robot actively perceives task-relevant information to reduce the\ncost of information acquisition and processing, while achieving near-optimal\ntask performance. Though planning with attention-based active perception\ninevitably introduces partial observations, a partially observable MDP\nformulation makes the problem computational expensive to solve. Instead, our\nproposed method employs a hierarchical planning framework in which the robot\ndetermines what to pay attention to and for how long the attention should be\nsustained before shifting to other information sources. During the attention\nsustaining phase, the robot carries out a sub-policy, computed from an\nabstraction of the original MDP given the current attention. We use an example\nwhere a robot is tasked to capture a set of intruders in a stochastic\ngridworld. The experimental results show that the proposed method enables\ninformation- and computation-efficient optimal planning in stochastic\nenvironments.\n", "versions": [{"version": "v1", "created": "Mon, 30 Nov 2020 19:07:28 GMT"}], "update_date": "2020-12-02", "authors_parsed": [["Ma", "Haoxiang", ""], ["Fu", "Jie", ""]]}, {"id": "2012.00057", "submitter": "Ayush Jain", "authors": "Zhaoyuan Fang, Ayush Jain, Gabriel Sarch, Adam W. Harley, Katerina\n  Fragkiadaki", "title": "Move to See Better: Self-Improving Embodied Object Detection", "comments": "First three authors contributed equally. Project Page:\n  https://ayushjain1144.github.io/SeeingByMoving/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Passive methods for object detection and segmentation treat images of the\nsame scene as individual samples and do not exploit object permanence across\nmultiple views. Generalization to novel or difficult viewpoints thus requires\nadditional training with lots of annotations. In contrast, humans often\nrecognize objects by simply moving around, to get more informative viewpoints.\nIn this paper, we propose a method for improving object detection in testing\nenvironments, assuming nothing but an embodied agent with a pre-trained 2D\nobject detector. Our agent collects multi-view data, generates 2D and 3D\npseudo-labels, and fine-tunes its detector in a self-supervised manner.\nExperiments on both indoor and outdoor datasets show that (1) our method\nobtains high-quality 2D and 3D pseudo-labels from multi-view RGB-D data; (2)\nfine-tuning with these pseudo-labels improves the 2D detector significantly in\nthe test environment; (3) training a 3D detector with our pseudo-labels\noutperforms a prior self-supervised method by a large margin; (4) given weak\nsupervision, our method can generate better pseudo-labels for novel objects.\n", "versions": [{"version": "v1", "created": "Mon, 30 Nov 2020 19:16:51 GMT"}, {"version": "v2", "created": "Mon, 29 Mar 2021 08:09:11 GMT"}], "update_date": "2021-03-30", "authors_parsed": [["Fang", "Zhaoyuan", ""], ["Jain", "Ayush", ""], ["Sarch", "Gabriel", ""], ["Harley", "Adam W.", ""], ["Fragkiadaki", "Katerina", ""]]}, {"id": "2012.00060", "submitter": "Dongrui Wu", "authors": "Zhenhua Shi, Dongrui Wu, Chenfeng Guo, Changming Zhao, Yuqi Cui, and\n  Fei-Yue Wang", "title": "FCM-RDpA: TSK Fuzzy Regression Model Construction Using Fuzzy C-Means\n  Clustering, Regularization, DropRule, and Powerball AdaBelief", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To effectively optimize Takagi-Sugeno-Kang (TSK) fuzzy systems for regression\nproblems, a mini-batch gradient descent with regularization, DropRule, and\nAdaBound (MBGD-RDA) algorithm was recently proposed. This paper further\nproposes FCM-RDpA, which improves MBGD-RDA by replacing the grid partition\napproach in rule initialization by fuzzy c-means clustering, and AdaBound by\nPowerball AdaBelief, which integrates recently proposed Powerball gradient and\nAdaBelief to further expedite and stabilize parameter optimization. Extensive\nexperiments on 22 regression datasets with various sizes and dimensionalities\nvalidated the superiority of FCM-RDpA over MBGD-RDA, especially when the\nfeature dimensionality is higher. We also propose an additional approach,\nFCM-RDpAx, that further improves FCM-RDpA by using augmented features in both\nthe antecedents and consequents of the rules.\n", "versions": [{"version": "v1", "created": "Mon, 30 Nov 2020 19:22:15 GMT"}], "update_date": "2020-12-02", "authors_parsed": [["Shi", "Zhenhua", ""], ["Wu", "Dongrui", ""], ["Guo", "Chenfeng", ""], ["Zhao", "Changming", ""], ["Cui", "Yuqi", ""], ["Wang", "Fei-Yue", ""]]}, {"id": "2012.00073", "submitter": "Pedro Saleiro", "authors": "Jo\\~ao Bento, Pedro Saleiro, Andr\\'e F. Cruz, M\\'ario A.T. Figueiredo,\n  Pedro Bizarro", "title": "TimeSHAP: Explaining Recurrent Models through Sequence Perturbations", "comments": "Accepted at KDD 2021", "journal-ref": null, "doi": "10.1145/3447548.3467166", "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although recurrent neural networks (RNNs) are state-of-the-art in numerous\nsequential decision-making tasks, there has been little research on explaining\ntheir predictions. In this work, we present TimeSHAP, a model-agnostic\nrecurrent explainer that builds upon KernelSHAP and extends it to the\nsequential domain. TimeSHAP computes feature-, timestep-, and cell-level\nattributions. As sequences may be arbitrarily long, we further propose a\npruning method that is shown to dramatically decrease both its computational\ncost and the variance of its attributions. We use TimeSHAP to explain the\npredictions of a real-world bank account takeover fraud detection RNN model,\nand draw key insights from its explanations: i) the model identifies important\nfeatures and events aligned with what fraud analysts consider cues for account\ntakeover; ii) positive predicted sequences can be pruned to only 10% of the\noriginal length, as older events have residual attribution values; iii) the\nmost recent input event of positive predictions only contributes on average to\n41% of the model's score; iv) notably high attribution to client's age,\nsuggesting a potential discriminatory reasoning, later confirmed as higher\nfalse positive rates for older clients.\n", "versions": [{"version": "v1", "created": "Mon, 30 Nov 2020 19:48:57 GMT"}, {"version": "v2", "created": "Sat, 26 Jun 2021 09:59:18 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Bento", "Jo\u00e3o", ""], ["Saleiro", "Pedro", ""], ["Cruz", "Andr\u00e9 F.", ""], ["Figueiredo", "M\u00e1rio A. T.", ""], ["Bizarro", "Pedro", ""]]}, {"id": "2012.00078", "submitter": "Zachary Taschdjian", "authors": "Zachary Taschdjian", "title": "Why Did the Robot Cross the Road? A User Study of Explanation in\n  Human-Robot Interaction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI cs.RO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This work documents a pilot user study evaluating the effectiveness of\ncontrastive, causal and example explanations in supporting human understanding\nof AI in a hypothetical commonplace human robot interaction HRI scenario. In\ndoing so, this work situates explainable AI XAI in the context of the social\nsciences and suggests that HRI explanations are improved when informed by the\nsocial sciences.\n", "versions": [{"version": "v1", "created": "Mon, 30 Nov 2020 20:02:19 GMT"}], "update_date": "2020-12-02", "authors_parsed": [["Taschdjian", "Zachary", ""]]}, {"id": "2012.00104", "submitter": "Hui Wei Dr.", "authors": "Hui Wei", "title": "A Neural Dynamic Model based on Activation Diffusion and a\n  Micro-Explanation for Cognitive Operations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.AI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  The neural mechanism of memory has a very close relation with the problem of\nrepresentation in artificial intelligence. In this paper a computational model\nwas proposed to simulate the network of neurons in brain and how they process\ninformation. The model refers to morphological and electrophysiological\ncharacteristics of neural information processing, and is based on the\nassumption that neurons encode their firing sequence. The network structure,\nfunctions for neural encoding at different stages, the representation of\nstimuli in memory, and an algorithm to form a memory were presented. It also\nanalyzed the stability and recall rate for learning and the capacity of memory.\nBecause neural dynamic processes, one succeeding another, achieve a\nneuron-level and coherent form by which information is represented and\nprocessed, it may facilitate examination of various branches of Artificial\nIntelligence, such as inference, problem solving, pattern recognition, natural\nlanguage processing and learning. The processes of cognitive manipulation\noccurring in intelligent behavior have a consistent representation while all\nbeing modeled from the perspective of computational neuroscience. Thus, the\ndynamics of neurons make it possible to explain the inner mechanisms of\ndifferent intelligent behaviors by a unified model of cognitive architecture at\na micro-level.\n", "versions": [{"version": "v1", "created": "Fri, 27 Nov 2020 01:34:08 GMT"}], "update_date": "2020-12-02", "authors_parsed": [["Wei", "Hui", ""]]}, {"id": "2012.00106", "submitter": "Joseph Near", "authors": "Ivoline C. Ngong, Krystal Maughan, Joseph P. Near", "title": "Towards Auditability for Fairness in Deep Learning", "comments": "Presented at the workshop on Algorithmic Fairness through the Lens of\n  Causality and Interpretability (AFCI'20)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Group fairness metrics can detect when a deep learning model behaves\ndifferently for advantaged and disadvantaged groups, but even models that score\nwell on these metrics can make blatantly unfair predictions. We present smooth\nprediction sensitivity, an efficiently computed measure of individual fairness\nfor deep learning models that is inspired by ideas from interpretability in\ndeep learning. smooth prediction sensitivity allows individual predictions to\nbe audited for fairness. We present preliminary experimental results suggesting\nthat smooth prediction sensitivity can help distinguish between fair and unfair\npredictions, and that it may be helpful in detecting blatantly unfair\npredictions from \"group-fair\" models.\n", "versions": [{"version": "v1", "created": "Mon, 30 Nov 2020 21:28:12 GMT"}], "update_date": "2020-12-02", "authors_parsed": [["Ngong", "Ivoline C.", ""], ["Maughan", "Krystal", ""], ["Near", "Joseph P.", ""]]}, {"id": "2012.00119", "submitter": "Gongbo Liang", "authors": "Xin Xing, Gongbo Liang, Hunter Blanton, Muhammad Usman Rafique, Chris\n  Wang, Ai-Ling Lin, Nathan Jacobs", "title": "Dynamic Image for 3D MRI Image Alzheimer's Disease Classification", "comments": "Accepted to ECCV2020 Workshop on BioImage Computing", "journal-ref": null, "doi": "10.1007/978-3-030-66415-2_23", "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose to apply a 2D CNN architecture to 3D MRI image Alzheimer's disease\nclassification. Training a 3D convolutional neural network (CNN) is\ntime-consuming and computationally expensive. We make use of approximate rank\npooling to transform the 3D MRI image volume into a 2D image to use as input to\na 2D CNN. We show our proposed CNN model achieves $9.5\\%$ better Alzheimer's\ndisease classification accuracy than the baseline 3D models. We also show that\nour method allows for efficient training, requiring only 20% of the training\ntime compared to 3D CNN models. The code is available online:\nhttps://github.com/UkyVision/alzheimer-project.\n", "versions": [{"version": "v1", "created": "Mon, 30 Nov 2020 21:39:32 GMT"}], "update_date": "2021-01-14", "authors_parsed": [["Xing", "Xin", ""], ["Liang", "Gongbo", ""], ["Blanton", "Hunter", ""], ["Rafique", "Muhammad Usman", ""], ["Wang", "Chris", ""], ["Lin", "Ai-Ling", ""], ["Jacobs", "Nathan", ""]]}, {"id": "2012.00124", "submitter": "Kanthashree Mysore Sathyendra", "authors": "Kanthashree Mysore Sathyendra, Samridhi Choudhary, Leah\n  Nicolich-Henkin", "title": "Extreme Model Compression for On-device Natural Language Understanding", "comments": "Long paper at COLING 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we propose and experiment with techniques for extreme\ncompression of neural natural language understanding (NLU) models, making them\nsuitable for execution on resource-constrained devices. We propose a\ntask-aware, end-to-end compression approach that performs word-embedding\ncompression jointly with NLU task learning. We show our results on a\nlarge-scale, commercial NLU system trained on a varied set of intents with huge\nvocabulary sizes. Our approach outperforms a range of baselines and achieves a\ncompression rate of 97.4% with less than 3.7% degradation in predictive\nperformance. Our analysis indicates that the signal from the downstream task is\nimportant for effective compression with minimal degradation in performance.\n", "versions": [{"version": "v1", "created": "Mon, 30 Nov 2020 21:47:48 GMT"}], "update_date": "2020-12-02", "authors_parsed": [["Sathyendra", "Kanthashree Mysore", ""], ["Choudhary", "Samridhi", ""], ["Nicolich-Henkin", "Leah", ""]]}, {"id": "2012.00190", "submitter": "Sven Buechel", "authors": "Sven Buechel, Luise Modersohn, and Udo Hahn", "title": "Towards a Unified Framework for Emotion Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present EmoCoder, a modular encoder-decoder architecture that generalizes\nemotion analysis over different tasks (sentence-level, word-level,\nlabel-to-label mapping), domains (natural languages and their registers), and\nlabel formats (e.g., polarity classes, basic emotions, and affective\ndimensions). Experiments on 14 datasets indicate that EmoCoder learns an\ninterpretable language-independent representation of emotions, allows seamless\nabsorption of state-of-the-art models, and maintains strong prediction quality,\neven when tested on unseen combinations of domains and label formats.\n", "versions": [{"version": "v1", "created": "Tue, 1 Dec 2020 00:54:13 GMT"}], "update_date": "2020-12-21", "authors_parsed": [["Buechel", "Sven", ""], ["Modersohn", "Luise", ""], ["Hahn", "Udo", ""]]}, {"id": "2012.00201", "submitter": "Michelle A. Lee", "authors": "Michelle A. Lee, Matthew Tan, Yuke Zhu, Jeannette Bohg", "title": "Detect, Reject, Correct: Crossmodal Compensation of Corrupted Sensors", "comments": "8 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Using sensor data from multiple modalities presents an opportunity to encode\nredundant and complementary features that can be useful when one modality is\ncorrupted or noisy. Humans do this everyday, relying on touch and\nproprioceptive feedback in visually-challenging environments. However, robots\nmight not always know when their sensors are corrupted, as even broken sensors\ncan return valid values. In this work, we introduce the Crossmodal Compensation\nModel (CCM), which can detect corrupted sensor modalities and compensate for\nthem. CMM is a representation model learned with self-supervision that\nleverages unimodal reconstruction loss for corruption detection. CCM then\ndiscards the corrupted modality and compensates for it with information from\nthe remaining sensors. We show that CCM learns rich state representations that\ncan be used for contact-rich manipulation policies, even when input modalities\nare corrupted in ways not seen during training time.\n", "versions": [{"version": "v1", "created": "Tue, 1 Dec 2020 01:09:22 GMT"}], "update_date": "2020-12-02", "authors_parsed": [["Lee", "Michelle A.", ""], ["Tan", "Matthew", ""], ["Zhu", "Yuke", ""], ["Bohg", "Jeannette", ""]]}, {"id": "2012.00211", "submitter": "Ying-Chiao Liao", "authors": "Chuan-Chi Wang, Ying-Chiao Liao, Ming-Chang Kao, Wen-Yew Liang,\n  Shih-Hao Hung", "title": "Toward Accurate Platform-Aware Performance Modeling for Deep Neural\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we provide a fine-grain machine learning-based method,\nPerfNetV2, which improves the accuracy of our previous work for modeling the\nneural network performance on a variety of GPU accelerators. Given an\napplication, the proposed method can be used to predict the inference time and\ntraining time of the convolutional neural networks used in the application,\nwhich enables the system developer to optimize the performance by choosing the\nneural networks and/or incorporating the hardware accelerators to deliver\nsatisfactory results in time. Furthermore, the proposed method is capable of\npredicting the performance of an unseen or non-existing device, e.g. a new GPU\nwhich has a higher operating frequency with less processor cores, but more\nmemory capacity. This allows a system developer to quickly search the hardware\ndesign space and/or fine-tune the system configuration. Compared to the\nprevious works, PerfNetV2 delivers more accurate results by modeling detailed\nhost-accelerator interactions in executing the full neural networks and\nimproving the architecture of the machine learning model used in the predictor.\nOur case studies show that PerfNetV2 yields a mean absolute percentage error\nwithin 13.1% on LeNet, AlexNet, and VGG16 on NVIDIA GTX-1080Ti, while the error\nrate on a previous work published in ICBD 2018 could be as large as 200%.\n", "versions": [{"version": "v1", "created": "Tue, 1 Dec 2020 01:42:23 GMT"}], "update_date": "2020-12-02", "authors_parsed": [["Wang", "Chuan-Chi", ""], ["Liao", "Ying-Chiao", ""], ["Kao", "Ming-Chang", ""], ["Liang", "Wen-Yew", ""], ["Hung", "Shih-Hao", ""]]}, {"id": "2012.00257", "submitter": "Andrew Shepley", "authors": "Andrew Shepley, Greg Falzon, Paul Kwan", "title": "Confluence: A Robust Non-IoU Alternative to Non-Maxima Suppression in\n  Object Detection", "comments": "13 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Confluence is a novel non-Intersection over Union (IoU) alternative to\nNon-Maxima Suppression (NMS) in bounding box post-processing in object\ndetection. It overcomes the inherent limitations of IoU-based NMS variants to\nprovide a more stable, consistent predictor of bounding box clustering by using\na normalized Manhattan Distance inspired proximity metric to represent bounding\nbox clustering. Unlike Greedy and Soft NMS, it does not rely solely on\nclassification confidence scores to select optimal bounding boxes, instead\nselecting the box which is closest to every other box within a given cluster\nand removing highly confluent neighboring boxes. Confluence is experimentally\nvalidated on the MS COCO and CrowdHuman benchmarks, improving Average Precision\nby up to 2.3-3.8% and Average Recall by up to 5.3-7.2% when compared against\nde-facto standard and state of the art NMS variants. Quantitative results are\nsupported by extensive qualitative analysis and threshold sensitivity analysis\nexperiments support the conclusion that Confluence is more robust than NMS\nvariants. Confluence represents a paradigm shift in bounding box processing,\nwith potential to replace IoU in bounding box regression processes.\n", "versions": [{"version": "v1", "created": "Tue, 1 Dec 2020 04:22:01 GMT"}, {"version": "v2", "created": "Wed, 28 Jul 2021 03:29:54 GMT"}], "update_date": "2021-07-29", "authors_parsed": [["Shepley", "Andrew", ""], ["Falzon", "Greg", ""], ["Kwan", "Paul", ""]]}, {"id": "2012.00360", "submitter": "Aythami Morales", "authors": "Alfonso Ortega and Julian Fierrez and Aythami Morales and Zilong Wang\n  and Tony Ribeiro", "title": "Symbolic AI for XAI: Evaluating LFIT Inductive Programming for Fair and\n  Explainable Automatic Recruitment", "comments": "WACV21 Workshop on Explainable & Interpretable Artificial\n  Intelligence for Biometrics (xAI4Biom)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning methods are growing in relevance for biometrics and personal\ninformation processing in domains such as forensics, e-health, recruitment, and\ne-learning. In these domains, white-box (human-readable) explanations of\nsystems built on machine learning methods can become crucial. Inductive Logic\nProgramming (ILP) is a subfield of symbolic AI aimed to automatically learn\ndeclarative theories about the process of data. Learning from Interpretation\nTransition (LFIT) is an ILP technique that can learn a propositional logic\ntheory equivalent to a given black-box system (under certain conditions). The\npresent work takes a first step to a general methodology to incorporate\naccurate declarative explanations to classic machine learning by checking the\nviability of LFIT in a specific AI application scenario: fair recruitment based\non an automatic tool generated with machine learning methods for ranking\nCurricula Vitae that incorporates soft biometric information (gender and\nethnicity). We show the expressiveness of LFIT for this specific problem and\npropose a scheme that can be applicable to other domains.\n", "versions": [{"version": "v1", "created": "Tue, 1 Dec 2020 09:36:59 GMT"}], "update_date": "2020-12-02", "authors_parsed": [["Ortega", "Alfonso", ""], ["Fierrez", "Julian", ""], ["Morales", "Aythami", ""], ["Wang", "Zilong", ""], ["Ribeiro", "Tony", ""]]}, {"id": "2012.00377", "submitter": "Joey Hong", "authors": "Joey Hong and David Dohan and Rishabh Singh and Charles Sutton and\n  Manzil Zaheer", "title": "Latent Programmer: Discrete Latent Codes for Program Synthesis", "comments": "15 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many sequence learning tasks, such as program synthesis and document\nsummarization, a key problem is searching over a large space of possible output\nsequences. We propose to learn representations of the outputs that are\nspecifically meant for search: rich enough to specify the desired output but\ncompact enough to make search more efficient. Discrete latent codes are\nappealing for this purpose, as they naturally allow sophisticated combinatorial\nsearch strategies. The latent codes are learned using a self-supervised\nlearning principle, in which first a discrete autoencoder is trained on the\noutput sequences, and then the resulting latent codes are used as intermediate\ntargets for the end-to-end sequence prediction task. Based on these insights,\nwe introduce the \\emph{Latent Programmer}, a program synthesis method that\nfirst predicts a discrete latent code from input/output examples, and then\ngenerates the program in the target language. We evaluate the Latent Programmer\non two domains: synthesis of string transformation programs, and generation of\nprograms from natural language descriptions. We demonstrate that the discrete\nlatent representation significantly improves synthesis accuracy.\n", "versions": [{"version": "v1", "created": "Tue, 1 Dec 2020 10:11:35 GMT"}], "update_date": "2020-12-02", "authors_parsed": [["Hong", "Joey", ""], ["Dohan", "David", ""], ["Singh", "Rishabh", ""], ["Sutton", "Charles", ""], ["Zaheer", "Manzil", ""]]}, {"id": "2012.00386", "submitter": "Joey Hong", "authors": "Joey Hong, Branislav Kveton, Manzil Zaheer, Yinlam Chow, Amr Ahmed,\n  Mohammad Ghavamzadeh, Craig Boutilier", "title": "Non-Stationary Latent Bandits", "comments": "15 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Users of recommender systems often behave in a non-stationary fashion, due to\ntheir evolving preferences and tastes over time. In this work, we propose a\npractical approach for fast personalization to non-stationary users. The key\nidea is to frame this problem as a latent bandit, where the prototypical models\nof user behavior are learned offline and the latent state of the user is\ninferred online from its interactions with the models. We call this problem a\nnon-stationary latent bandit. We propose Thompson sampling algorithms for\nregret minimization in non-stationary latent bandits, analyze them, and\nevaluate them on a real-world dataset. The main strength of our approach is\nthat it can be combined with rich offline-learned models, which can be\nmisspecified, and are subsequently fine-tuned online using posterior sampling.\nIn this way, we naturally combine the strengths of offline and online learning.\n", "versions": [{"version": "v1", "created": "Tue, 1 Dec 2020 10:31:57 GMT"}], "update_date": "2020-12-02", "authors_parsed": [["Hong", "Joey", ""], ["Kveton", "Branislav", ""], ["Zaheer", "Manzil", ""], ["Chow", "Yinlam", ""], ["Ahmed", "Amr", ""], ["Ghavamzadeh", "Mohammad", ""], ["Boutilier", "Craig", ""]]}, {"id": "2012.00398", "submitter": "Naveen Elango", "authors": "Naveen Elango, Pawan Prasad K", "title": "Introducing Inter-Relatedness between Wikipedia Articles in Explicit\n  Semantic Analysis", "comments": "16 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Explicit Semantic Analysis (ESA) is a technique used to represent a piece of\ntext as a vector in the space of concepts, such as Articles found in Wikipedia.\nWe propose a methodology to incorporate knowledge of Inter-relatedness between\nWikipedia Articles to the vectors obtained from ESA using a technique called\nRetrofitting to improve the performance of subsequent tasks that use ESA to\nform vector embeddings. Especially we use an undirected Graph to represent this\nknowledge with nodes as Articles and edges as inter relations between two\nArticles. Here, we also emphasize how the ESA step could be seen as a\npredominantly bottom-up approach using a corpus to come up with vector\nrepresentations and the incorporation of top-down knowledge which is the\nrelations between Articles to further improve it. We test our hypothesis on\nseveral smaller subsets of the Wikipedia corpus and show that our proposed\nmethodology leads to decent improvements in performance measures including\nSpearman's Rank correlation coefficient in most cases.\n", "versions": [{"version": "v1", "created": "Tue, 1 Dec 2020 10:55:07 GMT"}], "update_date": "2020-12-02", "authors_parsed": [["Elango", "Naveen", ""], ["K", "Pawan Prasad", ""]]}, {"id": "2012.00433", "submitter": "Yao Hu", "authors": "Yao Hu, Guohua Geng, Kang Li, Wei Zhou, Xingxing Hao, Xin Cao", "title": "SRG-Net: Unsupervised Segmentation for Terracotta Warrior Point Cloud\n  with 3D Pointwise CNN methods", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we present a seed-region-growing CNN(SRG-Net) for unsupervised\npart segmentation with 3D point clouds of terracotta warriors. Previous neural\nnetwork researches in 3D are mainly about supervised classification,\nclustering, unsupervised representation and reconstruction. There are few\nresearches focusing on unsupervised point cloud part segmentation. To address\nthese problems, we present a seed-region-growing CNN(SRG-Net) for unsupervised\npart segmentation with 3D point clouds of terracotta warriors. Firstly, we\npropose our customized seed region growing algorithm to coarsely segment the\npoint cloud. Then we present our supervised segmentation and unsupervised\nreconstruction networks to better understand the characteristics of 3D point\nclouds. Finally, we combine the SRG algorithm with our improved CNN using a\nrefinement method called SRG-Net to conduct the segmentation tasks on the\nterracotta warriors. Our proposed SRG-Net are evaluated on the terracotta\nwarriors data and the benchmark dataset of ShapeNet with measuring mean\nintersection over union(mIoU) and latency. The experimental results show that\nour SRG-Net outperforms the state-of-the-art methods. Our code is available at\nhttps://github.com/hyoau/SRG-Net.\n", "versions": [{"version": "v1", "created": "Tue, 1 Dec 2020 12:02:55 GMT"}], "update_date": "2020-12-02", "authors_parsed": [["Hu", "Yao", ""], ["Geng", "Guohua", ""], ["Li", "Kang", ""], ["Zhou", "Wei", ""], ["Hao", "Xingxing", ""], ["Cao", "Xin", ""]]}, {"id": "2012.00461", "submitter": "Nima Rafiee", "authors": "Nima Rafiee, Rahil Gholamipoor, Markus Kollmann", "title": "Unsupervised Anomaly Detection From Semantic Similarity Scores", "comments": "The reported AUROC values are wrong due to an implementation error.\n  In short, there was information leakage by Batch Normalisation during\n  training the discriminator", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Classifying samples as in-distribution or out-of-distribution (OOD) is a\nchallenging problem of anomaly detection and a strong test of the\ngeneralisation power for models of the in-distribution. In this paper, we\npresent a simple and generic framework, {\\it SemSAD}, that makes use of a\nsemantic similarity score to carry out anomaly detection. The idea is to first\nfind for any test example the semantically closest examples in the training\nset, where the semantic relation between examples is quantified by the cosine\nsimilarity between feature vectors that leave semantics unchanged under\ntransformations, such as geometric transformations (images), time shifts (audio\nsignals), and synonymous word substitutions (text). A trained discriminator is\nthen used to classify a test example as OOD if the semantic similarity to its\nnearest neighbours is significantly lower than the corresponding similarity for\ntest examples from the in-distribution. We are able to outperform previous\napproaches for anomaly, novelty, or out-of-distribution detection in the visual\ndomain by a large margin. In particular, we obtain AUROC values close to one\nfor the challenging task of detecting examples from CIFAR-10 as\nout-of-distribution given CIFAR-100 as in-distribution, without making use of\nlabel information.\n", "versions": [{"version": "v1", "created": "Tue, 1 Dec 2020 13:12:31 GMT"}, {"version": "v2", "created": "Wed, 24 Feb 2021 08:21:22 GMT"}, {"version": "v3", "created": "Fri, 26 Mar 2021 08:40:34 GMT"}], "update_date": "2021-03-29", "authors_parsed": [["Rafiee", "Nima", ""], ["Gholamipoor", "Rahil", ""], ["Kollmann", "Markus", ""]]}, {"id": "2012.00463", "submitter": "Faisal Hussain", "authors": "Faisal Hussain, Syed Ghazanfar Abbas, Ubaid U. Fayyaz, Ghalib A. Shah,\n  Abdullah Toqeer, Ahmad Ali", "title": "Towards a Universal Features Set for IoT Botnet Attacks Detection", "comments": "Accepted in 2020 IEEE 23rd International Multitopic Conference\n  (INMIC), 7 pages, 3 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The security pitfalls of IoT devices make it easy for the attackers to\nexploit the IoT devices and make them a part of a botnet. Once hundreds of\nthousands of IoT devices are compromised and become the part of a botnet, the\nattackers use this botnet to launch the large and complex distributed denial of\nservice (DDoS) attacks which take down the target websites or services and make\nthem unable to respond the legitimate users. So far, many botnet detection\ntechniques have been proposed but their performance is limited to a specific\ndataset on which they are trained. This is because the features used to train a\nmachine learning model on one botnet dataset, do not perform well on other\ndatasets due to the diversity of attack patterns. Therefore, in this paper, we\npropose a universal features set to better detect the botnet attacks regardless\nof the underlying dataset. The proposed features set manifest preeminent\nresults for detecting the botnet attacks when tested the trained machine\nlearning models over three different botnet attack datasets.\n", "versions": [{"version": "v1", "created": "Tue, 1 Dec 2020 13:15:57 GMT"}], "update_date": "2020-12-02", "authors_parsed": [["Hussain", "Faisal", ""], ["Abbas", "Syed Ghazanfar", ""], ["Fayyaz", "Ubaid U.", ""], ["Shah", "Ghalib A.", ""], ["Toqeer", "Abdullah", ""], ["Ali", "Ahmad", ""]]}, {"id": "2012.00481", "submitter": "Stan Z Li", "authors": "Stan Z. Li, Lirong Wu and Zelin Zang", "title": "Consistent Representation Learning for High Dimensional Data Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  High dimensional data analysis for exploration and discovery includes three\nfundamental tasks: dimensionality reduction, clustering, and visualization.\nWhen the three associated tasks are done separately, as is often the case thus\nfar, inconsistencies can occur among the tasks in terms of data geometry and\nothers. This can lead to confusing or misleading data interpretation. In this\npaper, we propose a novel neural network-based method, called Consistent\nRepresentation Learning (CRL), to accomplish the three associated tasks\nend-to-end and improve the consistencies. The CRL network consists of two\nnonlinear dimensionality reduction (NLDR) transformations: (1) one from the\ninput data space to the latent feature space for clustering, and (2) the other\nfrom the clustering space to the final 2D or 3D space for visualization.\nImportantly, the two NLDR transformations are performed to best satisfy local\ngeometry preserving (LGP) constraints across the spaces or network layers, to\nimprove data consistencies along with the processing flow. Also, we propose a\nnovel metric, clustering-visualization inconsistency (CVI), for evaluating the\ninconsistencies. Extensive comparative results show that the proposed CRL\nneural network method outperforms the popular t-SNE and UMAP-based and other\ncontemporary clustering and visualization algorithms in terms of evaluation\nmetrics and visualization.\n", "versions": [{"version": "v1", "created": "Tue, 1 Dec 2020 13:39:50 GMT"}], "update_date": "2020-12-02", "authors_parsed": [["Li", "Stan Z.", ""], ["Wu", "Lirong", ""], ["Zang", "Zelin", ""]]}, {"id": "2012.00483", "submitter": "Markus Leippold", "authors": "Francesco S. Varini and Jordan Boyd-Graber and Massimiliano Ciaramita\n  and Markus Leippold", "title": "ClimaText: A Dataset for Climate Change Topic Detection", "comments": "Accepted for the Tackling Climate Change with Machine Learning\n  Workshop at NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Climate change communication in the mass media and other textual sources may\naffect and shape public perception. Extracting climate change information from\nthese sources is an important task, e.g., for filtering content and\ne-discovery, sentiment analysis, automatic summarization, question-answering,\nand fact-checking. However, automating this process is a challenge, as climate\nchange is a complex, fast-moving, and often ambiguous topic with scarce\nresources for popular text-based AI tasks. In this paper, we introduce\n\\textsc{ClimaText}, a dataset for sentence-based climate change topic\ndetection, which we make publicly available. We explore different approaches to\nidentify the climate change topic in various text sources. We find that popular\nkeyword-based models are not adequate for such a complex and evolving task.\nContext-based algorithms like BERT \\cite{devlin2018bert} can detect, in\naddition to many trivial cases, a variety of complex and implicit topic\npatterns. Nevertheless, our analysis reveals a great potential for improvement\nin several directions, such as, e.g., capturing the discussion on indirect\neffects of climate change. Hence, we hope this work can serve as a good\nstarting point for further research on this topic.\n", "versions": [{"version": "v1", "created": "Tue, 1 Dec 2020 13:42:37 GMT"}, {"version": "v2", "created": "Sat, 2 Jan 2021 16:13:06 GMT"}], "update_date": "2021-01-05", "authors_parsed": [["Varini", "Francesco S.", ""], ["Boyd-Graber", "Jordan", ""], ["Ciaramita", "Massimiliano", ""], ["Leippold", "Markus", ""]]}, {"id": "2012.00500", "submitter": "Jiang Mingzhi", "authors": "Mingzhi Jiang, Tianhao Wu, Zhe Wang, Yi Gong, Lin Zhang, Ren Ping Liu", "title": "A Multi-intersection Vehicular Cooperative Control based on\n  End-Edge-Cloud Computing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cooperative Intelligent Transportation Systems (C-ITS) will change the modes\nof road safety and traffic management, especially at intersections without\ntraffic lights, namely unsignalized intersections. Existing researches focus on\nvehicle control within a small area around an unsignalized intersection. In\nthis paper, we expand the control domain to a large area with multiple\nintersections. In particular, we propose a Multi-intersection Vehicular\nCooperative Control (MiVeCC) to enable cooperation among vehicles in a large\narea with multiple unsignalized intersections. Firstly, a vehicular\nend-edge-cloud computing framework is proposed to facilitate end-edge-cloud\nvertical cooperation and horizontal cooperation among vehicles. Then, the\nvehicular cooperative control problems in the cloud and edge layers are\nformulated as Markov Decision Process (MDP) and solved by two-stage\nreinforcement learning. Furthermore, to deal with high-density traffic, vehicle\nselection methods are proposed to reduce the state space and accelerate\nalgorithm convergence without performance degradation. A multi-intersection\nsimulation platform is developed to evaluate the proposed scheme. Simulation\nresults show that the proposed MiVeCC can improve travel efficiency at multiple\nintersections by up to 4.59 times without collision compared with existing\nmethods.\n", "versions": [{"version": "v1", "created": "Tue, 1 Dec 2020 14:15:14 GMT"}], "update_date": "2020-12-02", "authors_parsed": [["Jiang", "Mingzhi", ""], ["Wu", "Tianhao", ""], ["Wang", "Zhe", ""], ["Gong", "Yi", ""], ["Zhang", "Lin", ""], ["Liu", "Ren Ping", ""]]}, {"id": "2012.00508", "submitter": "Rupert Mitchell", "authors": "Rupert Mitchell, Jan Blumenkamp and Amanda Prorok", "title": "Gaussian Process Based Message Filtering for Robust Multi-Agent\n  Cooperation in the Presence of Adversarial Communication", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider the problem of providing robustness to adversarial\ncommunication in multi-agent systems. Specifically, we propose a solution\ntowards robust cooperation, which enables the multi-agent system to maintain\nhigh performance in the presence of anonymous non-cooperative agents that\ncommunicate faulty, misleading or manipulative information. In pursuit of this\ngoal, we propose a communication architecture based on Graph Neural Networks\n(GNNs), which is amenable to a novel Gaussian Process (GP)-based probabilistic\nmodel characterizing the mutual information between the simultaneous\ncommunications of different agents due to their physical proximity and relative\nposition. This model allows agents to locally compute approximate posterior\nprobabilities, or confidences, that any given one of their communication\npartners is being truthful. These confidences can be used as weights in a\nmessage filtering scheme, thereby suppressing the influence of suspicious\ncommunication on the receiving agent's decisions. In order to assess the\nefficacy of our method, we introduce a taxonomy of non-cooperative agents,\nwhich distinguishes them by the amount of information available to them. We\ndemonstrate in two distinct experiments that our method performs well across\nthis taxonomy, outperforming alternative methods. For all but the best informed\nadversaries, our filtering method is able to reduce the impact that\nnon-cooperative agents cause, reducing it to the point of negligibility, and\nwith negligible cost to performance in the absence of adversaries.\n", "versions": [{"version": "v1", "created": "Tue, 1 Dec 2020 14:21:58 GMT"}], "update_date": "2020-12-02", "authors_parsed": [["Mitchell", "Rupert", ""], ["Blumenkamp", "Jan", ""], ["Prorok", "Amanda", ""]]}, {"id": "2012.00546", "submitter": "Peng Yang", "authors": "Peng Yang, Xing Xi, Tony Q. S. Quek, Xianbin Cao, Jingxuan Chen", "title": "Power Control for a URLLC-enabled UAV system incorporated with DNN-Based\n  Channel Estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.AI cs.LG cs.RO math.IT", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This letter is concerned with power control for a ultra-reliable and\nlow-latency communications (URLLC) enabled unmanned aerial vehicle (UAV) system\nincorporated with deep neural network (DNN) based channel estimation.\nParticularly, we formulate the power control problem for the UAV system as an\noptimization problem to accommodate the URLLC requirement of uplink control and\nnon-payload signal delivery while ensuring the downlink high-speed payload\ntransmission. This problem is challenging to be solved due to the requirement\nof analytically tractable channel models and the non-convex characteristic as\nwell. To address the challenges, we propose a novel power control algorithm,\nwhich constructs analytically tractable channel models based on DNN estimation\nresults and explores a semidefinite relaxation (SDR) scheme to tackle the\nnon-convexity. Simulation results demonstrate the accuracy of the DNN\nestimation and verify the effectiveness of the proposed algorithm.\n", "versions": [{"version": "v1", "created": "Sat, 14 Nov 2020 02:31:04 GMT"}], "update_date": "2020-12-02", "authors_parsed": [["Yang", "Peng", ""], ["Xi", "Xing", ""], ["Quek", "Tony Q. S.", ""], ["Cao", "Xianbin", ""], ["Chen", "Jingxuan", ""]]}, {"id": "2012.00555", "submitter": "Mohnish Dubey", "authors": "Nandana Mihindukulasooriya and Mohnish Dubey and Alfio Gliozzo and\n  Jens Lehmann and Axel-Cyrille Ngonga Ngomo and Ricardo Usbeck", "title": "SeMantic AnsweR Type prediction task (SMART) at ISWC 2020 Semantic Web\n  Challenge", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.IR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Each year the International Semantic Web Conference accepts a set of Semantic\nWeb Challenges to establish competitions that will advance the state of the art\nsolutions in any given problem domain. The SeMantic AnsweR Type prediction task\n(SMART) was part of ISWC 2020 challenges. Question type and answer type\nprediction can play a key role in knowledge base question answering systems\nproviding insights that are helpful to generate correct queries or rank the\nanswer candidates. More concretely, given a question in natural language, the\ntask of SMART challenge is, to predict the answer type using a target ontology\n(e.g., DBpedia or Wikidata).\n", "versions": [{"version": "v1", "created": "Tue, 1 Dec 2020 15:02:11 GMT"}], "update_date": "2020-12-02", "authors_parsed": [["Mihindukulasooriya", "Nandana", ""], ["Dubey", "Mohnish", ""], ["Gliozzo", "Alfio", ""], ["Lehmann", "Jens", ""], ["Ngomo", "Axel-Cyrille Ngonga", ""], ["Usbeck", "Ricardo", ""]]}, {"id": "2012.00557", "submitter": "Victor Boutin", "authors": "Victor Boutin, Aimen Zerroug, Minju Jung, Thomas Serre", "title": "Iterative VAE as a predictive brain model for out-of-distribution\n  generalization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Our ability to generalize beyond training data to novel, out-of-distribution,\nimage degradations is a hallmark of primate vision. The predictive brain,\nexemplified by predictive coding networks (PCNs), has become a prominent\nneuroscience theory of neural computation. Motivated by the recent successes of\nvariational autoencoders (VAEs) in machine learning, we rigorously derive a\ncorrespondence between PCNs and VAEs. This motivates us to consider iterative\nextensions of VAEs (iVAEs) as plausible variational extensions of the PCNs. We\nfurther demonstrate that iVAEs generalize to distributional shifts\nsignificantly better than both PCNs and VAEs. In addition, we propose a novel\nmeasure of recognizability for individual samples which can be tested against\nhuman psychophysical data. Overall, we hope this work will spur interest in\niVAEs as a promising new direction for modeling in neuroscience.\n", "versions": [{"version": "v1", "created": "Tue, 1 Dec 2020 15:02:38 GMT"}], "update_date": "2020-12-02", "authors_parsed": [["Boutin", "Victor", ""], ["Zerroug", "Aimen", ""], ["Jung", "Minju", ""], ["Serre", "Thomas", ""]]}, {"id": "2012.00583", "submitter": "Xiaohan Cheng", "authors": "Xiaohan Cheng", "title": "Obtain Employee Turnover Rate and Optimal Reduction Strategy Based On\n  Neural Network and Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nowadays, human resource is an important part of various resources of\nenterprises. For enterprises, high-loyalty and high-quality talented persons\nare often the core competitiveness of enterprises. Therefore, it is of great\npractical significance to predict whether employees leave and reduce the\nturnover rate of employees. First, this paper established a multi-layer\nperceptron predictive model of employee turnover rate. A model based on Sarsa\nwhich is a kind of reinforcement learning algorithm is proposed to\nautomatically generate a set of strategies to reduce the employee turnover\nrate. These strategies are a collection of strategies that can reduce the\nemployee turnover rate the most and cost less from the perspective of the\nenterprise, and can be used as a reference plan for the enterprise to optimize\nthe employee system. The experimental results show that the algorithm can\nindeed improve the efficiency and accuracy of the specific strategy.\n", "versions": [{"version": "v1", "created": "Tue, 1 Dec 2020 15:48:23 GMT"}], "update_date": "2020-12-02", "authors_parsed": [["Cheng", "Xiaohan", ""]]}, {"id": "2012.00596", "submitter": "Zhengang Li", "authors": "Zhengang Li, Geng Yuan, Wei Niu, Pu Zhao, Yanyu Li, Yuxuan Cai, Xuan\n  Shen, Zheng Zhan, Zhenglun Kong, Qing Jin, Zhiyu Chen, Sijia Liu, Kaiyuan\n  Yang, Bin Ren, Yanzhi Wang, Xue Lin", "title": "NPAS: A Compiler-aware Framework of Unified Network Pruning and\n  Architecture Search for Beyond Real-Time Mobile Acceleration", "comments": "Accepted as an oral paper in the Conference on Computer Vision and\n  Pattern Recognition (CVPR), 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the increasing demand to efficiently deploy DNNs on mobile edge devices,\nit becomes much more important to reduce unnecessary computation and increase\nthe execution speed. Prior methods towards this goal, including model\ncompression and network architecture search (NAS), are largely performed\nindependently and do not fully consider compiler-level optimizations which is a\nmust-do for mobile acceleration. In this work, we first propose (i) a general\ncategory of fine-grained structured pruning applicable to various DNN layers,\nand (ii) a comprehensive, compiler automatic code generation framework\nsupporting different DNNs and different pruning schemes, which bridge the gap\nof model compression and NAS. We further propose NPAS, a compiler-aware unified\nnetwork pruning, and architecture search. To deal with large search space, we\npropose a meta-modeling procedure based on reinforcement learning with fast\nevaluation and Bayesian optimization, ensuring the total number of training\nepochs comparable with representative NAS frameworks. Our framework achieves\n6.7ms, 5.9ms, 3.9ms ImageNet inference times with 78.2%, 75% (MobileNet-V3\nlevel), and 71% (MobileNet-V2 level) Top-1 accuracy respectively on an\noff-the-shelf mobile phone, consistently outperforming prior work.\n", "versions": [{"version": "v1", "created": "Tue, 1 Dec 2020 16:03:40 GMT"}, {"version": "v2", "created": "Sun, 25 Apr 2021 04:18:34 GMT"}, {"version": "v3", "created": "Thu, 17 Jun 2021 00:07:48 GMT"}], "update_date": "2021-06-18", "authors_parsed": [["Li", "Zhengang", ""], ["Yuan", "Geng", ""], ["Niu", "Wei", ""], ["Zhao", "Pu", ""], ["Li", "Yanyu", ""], ["Cai", "Yuxuan", ""], ["Shen", "Xuan", ""], ["Zhan", "Zheng", ""], ["Kong", "Zhenglun", ""], ["Jin", "Qing", ""], ["Chen", "Zhiyu", ""], ["Liu", "Sijia", ""], ["Yang", "Kaiyuan", ""], ["Ren", "Bin", ""], ["Wang", "Yanzhi", ""], ["Lin", "Xue", ""]]}, {"id": "2012.00600", "submitter": "Mustafa Jarrar", "authors": "Mustafa Jarrar, Eman Karajah, Muhammad Khalifa, Khaled Shaalan", "title": "Extracting Synonyms from Bilingual Dictionaries", "comments": "In Proceedings - 11th International Global Wordnet Conference\n  (GWC2021). Global Wordnet Association (2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  We present our progress in developing a novel algorithm to extract synonyms\nfrom bilingual dictionaries. Identification and usage of synonyms play a\nsignificant role in improving the performance of information access\napplications. The idea is to construct a translation graph from translation\npairs, then to extract and consolidate cyclic paths to form bilingual sets of\nsynonyms. The initial evaluation of this algorithm illustrates promising\nresults in extracting Arabic-English bilingual synonyms. In the evaluation, we\nfirst converted the synsets in the Arabic WordNet into translation pairs (i.e.,\nlosing word-sense memberships). Next, we applied our algorithm to rebuild these\nsynsets. We compared the original and extracted synsets obtaining an F-Measure\nof 82.3% and 82.1% for Arabic and English synsets extraction, respectively.\n", "versions": [{"version": "v1", "created": "Tue, 1 Dec 2020 16:09:22 GMT"}], "update_date": "2020-12-02", "authors_parsed": [["Jarrar", "Mustafa", ""], ["Karajah", "Eman", ""], ["Khalifa", "Muhammad", ""], ["Shaalan", "Khaled", ""]]}, {"id": "2012.00614", "submitter": "Markus Leippold", "authors": "Thomas Diggelmann and Jordan Boyd-Graber and Jannis Bulian and\n  Massimiliano Ciaramita and Markus Leippold", "title": "CLIMATE-FEVER: A Dataset for Verification of Real-World Climate Claims", "comments": "Accepted for the Tackling Climate Change with Machine Learning\n  Workshop at NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce CLIMATE-FEVER, a new publicly available dataset for verification\nof climate change-related claims. By providing a dataset for the research\ncommunity, we aim to facilitate and encourage work on improving algorithms for\nretrieving evidential support for climate-specific claims, addressing the\nunderlying language understanding challenges, and ultimately help alleviate the\nimpact of misinformation on climate change. We adapt the methodology of FEVER\n[1], the largest dataset of artificially designed claims, to real-life claims\ncollected from the Internet. While during this process, we could rely on the\nexpertise of renowned climate scientists, it turned out to be no easy task. We\ndiscuss the surprising, subtle complexity of modeling real-world\nclimate-related claims within the \\textsc{fever} framework, which we believe\nprovides a valuable challenge for general natural language understanding. We\nhope that our work will mark the beginning of a new exciting long-term joint\neffort by the climate science and AI community.\n", "versions": [{"version": "v1", "created": "Tue, 1 Dec 2020 16:32:54 GMT"}, {"version": "v2", "created": "Sat, 2 Jan 2021 16:07:48 GMT"}], "update_date": "2021-01-05", "authors_parsed": [["Diggelmann", "Thomas", ""], ["Boyd-Graber", "Jordan", ""], ["Bulian", "Jannis", ""], ["Ciaramita", "Massimiliano", ""], ["Leippold", "Markus", ""]]}, {"id": "2012.00632", "submitter": "Felix Sattler", "authors": "Felix Sattler and Arturo Marban and Roman Rischke and Wojciech Samek", "title": "Communication-Efficient Federated Distillation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Communication constraints are one of the major challenges preventing the\nwide-spread adoption of Federated Learning systems. Recently, Federated\nDistillation (FD), a new algorithmic paradigm for Federated Learning with\nfundamentally different communication properties, emerged. FD methods leverage\nensemble distillation techniques and exchange model outputs, presented as soft\nlabels on an unlabeled public data set, between the central server and the\nparticipating clients. While for conventional Federated Learning algorithms,\nlike Federated Averaging (FA), communication scales with the size of the\njointly trained model, in FD communication scales with the distillation data\nset size, resulting in advantageous communication properties, especially when\nlarge models are trained. In this work, we investigate FD from the perspective\nof communication efficiency by analyzing the effects of active\ndistillation-data curation, soft-label quantization and delta-coding\ntechniques. Based on the insights gathered from this analysis, we present\nCompressed Federated Distillation (CFD), an efficient Federated Distillation\nmethod. Extensive experiments on Federated image classification and language\nmodeling problems demonstrate that our method can reduce the amount of\ncommunication necessary to achieve fixed performance targets by more than two\norders of magnitude, when compared to FD and by more than four orders of\nmagnitude when compared with FA.\n", "versions": [{"version": "v1", "created": "Tue, 1 Dec 2020 16:57:25 GMT"}], "update_date": "2020-12-02", "authors_parsed": [["Sattler", "Felix", ""], ["Marban", "Arturo", ""], ["Rischke", "Roman", ""], ["Samek", "Wojciech", ""]]}, {"id": "2012.00633", "submitter": "Rahul Dubey Dr", "authors": "Shree Charran R, Rahul Kumar Dubey (Senior Member IEEE)", "title": "Meta-Embeddings for Natural Language Inference and Semantic Similarity\n  tasks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Word Representations form the core component for almost all advanced Natural\nLanguage Processing (NLP) applications such as text mining, question-answering,\nand text summarization, etc. Over the last two decades, immense research is\nconducted to come up with one single model to solve all major NLP tasks. The\nmajor problem currently is that there are a plethora of choices for different\nNLP tasks. Thus for NLP practitioners, the task of choosing the right model to\nbe used itself becomes a challenge. Thus combining multiple pre-trained word\nembeddings and forming meta embeddings has become a viable approach to improve\ntackle NLP tasks. Meta embedding learning is a process of producing a single\nword embedding from a given set of pre-trained input word embeddings. In this\npaper, we propose to use Meta Embedding derived from few State-of-the-Art\n(SOTA) models to efficiently tackle mainstream NLP tasks like classification,\nsemantic relatedness, and text similarity. We have compared both ensemble and\ndynamic variants to identify an efficient approach. The results obtained show\nthat even the best State-of-the-Art models can be bettered. Thus showing us\nthat meta-embeddings can be used for several NLP tasks by harnessing the power\nof several individual representations.\n", "versions": [{"version": "v1", "created": "Tue, 1 Dec 2020 16:58:01 GMT"}], "update_date": "2020-12-02", "authors_parsed": [["R", "Shree Charran", "", "Senior Member IEEE"], ["Dubey", "Rahul Kumar", "", "Senior Member IEEE"]]}, {"id": "2012.00641", "submitter": "Shiv Ram Dubey", "authors": "Shiv Ram Dubey", "title": "A Decade Survey of Content Based Image Retrieval using Deep Learning", "comments": "Published by IEEE Transactions on Circuits and Systems for Video\n  Technology", "journal-ref": null, "doi": "10.1109/TCSVT.2021.3080920", "report-no": null, "categories": "cs.CV cs.AI cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The content based image retrieval aims to find the similar images from a\nlarge scale dataset against a query image. Generally, the similarity between\nthe representative features of the query image and dataset images is used to\nrank the images for retrieval. In early days, various hand designed feature\ndescriptors have been investigated based on the visual cues such as color,\ntexture, shape, etc. that represent the images. However, the deep learning has\nemerged as a dominating alternative of hand-designed feature engineering from a\ndecade. It learns the features automatically from the data. This paper presents\na comprehensive survey of deep learning based developments in the past decade\nfor content based image retrieval. The categorization of existing\nstate-of-the-art methods from different perspectives is also performed for\ngreater understanding of the progress. The taxonomy used in this survey covers\ndifferent supervision, different networks, different descriptor type and\ndifferent retrieval type. A performance analysis is also performed using the\nstate-of-the-art methods. The insights are also presented for the benefit of\nthe researchers to observe the progress and to make the best choices. The\nsurvey presented in this paper will help in further research progress in image\nretrieval using deep learning.\n", "versions": [{"version": "v1", "created": "Mon, 23 Nov 2020 02:12:30 GMT"}, {"version": "v2", "created": "Thu, 20 May 2021 09:22:01 GMT"}], "update_date": "2021-05-21", "authors_parsed": [["Dubey", "Shiv Ram", ""]]}, {"id": "2012.00661", "submitter": "Hongda Wu", "authors": "Hongda Wu, Ping Wang", "title": "Fast-Convergent Federated Learning with Adaptive Weighting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Federated learning (FL) enables resource-constrained edge nodes to\ncollaboratively learn a global model under the orchestration of a central\nserver while keeping privacy-sensitive data locally. The\nnon-independent-and-identically-distributed (non-IID) data samples across\nparticipating nodes slow model training and impose additional communication\nrounds for FL to converge. In this paper, we propose Federated Adaptive\nWeighting (FedAdp) algorithm that aims to accelerate model convergence under\nthe presence of nodes with non-IID dataset. We observe the implicit connection\nbetween the node contribution to the global model aggregation and data\ndistribution on the local node through theoretical and empirical analysis. We\nthen propose to assign different weights for updating the global model based on\nnode contribution adaptively through each training round. The contribution of\nparticipating nodes is first measured by the angle between the local gradient\nvector and the global gradient vector, and then, weight is quantified by a\ndesigned non-linear mapping function subsequently. The simple yet effective\nstrategy can reinforce positive (suppress negative) node contribution\ndynamically, resulting in communication round reduction drastically. Its\nsuperiority over the commonly adopted Federated Averaging (FedAvg) is verified\nboth theoretically and experimentally. With extensive experiments performed in\nPytorch and PySyft, we show that FL training with FedAdp can reduce the number\nof communication rounds by up to 54.1% on MNIST dataset and up to 45.4% on\nFashionMNIST dataset, as compared to FedAvg algorithm.\n", "versions": [{"version": "v1", "created": "Tue, 1 Dec 2020 17:35:05 GMT"}, {"version": "v2", "created": "Tue, 6 Apr 2021 01:45:41 GMT"}], "update_date": "2021-04-07", "authors_parsed": [["Wu", "Hongda", ""], ["Wang", "Ping", ""]]}, {"id": "2012.00724", "submitter": "Arpan Kusari", "authors": "Arpan Kusari", "title": "Assessing and Accelerating Coverage in Deep Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Current deep reinforcement learning (DRL) algorithms utilize randomness in\nsimulation environments to assume complete coverage in the state space.\nHowever, particularly in high dimensions, relying on randomness may lead to\ngaps in coverage of the trained DRL neural network model, which in turn may\nlead to drastic and often fatal real-world situations. To the best of the\nauthor's knowledge, the assessment of coverage for DRL is lacking in current\nresearch literature. Therefore, in this paper, a novel measure, Approximate\nPseudo-Coverage (APC), is proposed for assessing the coverage in DRL\napplications. We propose to calculate APC by projecting the high dimensional\nstate space on to a lower dimensional manifold and quantifying the occupied\nspace. Furthermore, we utilize an exploration-exploitation strategy for\ncoverage maximization using Rapidly-Exploring Random Tree (RRT). The efficacy\nof the assessment and the acceleration of coverage is demonstrated on standard\ntasks such as Cartpole, highway-env.\n", "versions": [{"version": "v1", "created": "Tue, 1 Dec 2020 18:33:39 GMT"}], "update_date": "2020-12-02", "authors_parsed": [["Kusari", "Arpan", ""]]}, {"id": "2012.00743", "submitter": "Stefanos Antaris", "authors": "Dimitrios Rafailidis, Stefanos Antaris", "title": "Adaptive Neural Architectures for Recommender Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Deep learning has proved an effective means to capture the non-linear\nassociations of user preferences. However, the main drawback of existing deep\nlearning architectures is that they follow a fixed recommendation strategy,\nignoring users' real time-feedback. Recent advances of deep reinforcement\nstrategies showed that recommendation policies can be continuously updated\nwhile users interact with the system. In doing so, we can learn the optimal\npolicy that fits to users' preferences over the recommendation sessions. The\nmain drawback of deep reinforcement strategies is that are based on predefined\nand fixed neural architectures. To shed light on how to handle this issue, in\nthis study we first present deep reinforcement learning strategies for\nrecommendation and discuss the main limitations due to the fixed neural\narchitectures. Then, we detail how recent advances on progressive neural\narchitectures are used for consecutive tasks in other research domains.\nFinally, we present the key challenges to fill the gap between deep\nreinforcement learning and adaptive neural architectures. We provide guidelines\nfor searching for the best neural architecture based on each user feedback via\nreinforcement learning, while considering the prediction performance on\nreal-time recommendations and the model complexity.\n", "versions": [{"version": "v1", "created": "Wed, 11 Nov 2020 09:43:20 GMT"}], "update_date": "2020-12-02", "authors_parsed": [["Rafailidis", "Dimitrios", ""], ["Antaris", "Stefanos", ""]]}, {"id": "2012.00780", "submitter": "Abdul Fatir Ansari", "authors": "Abdul Fatir Ansari, Ming Liang Ang, Harold Soh", "title": "Refining Deep Generative Models via Discriminator Gradient Flow", "comments": "ICLR 2021 Camera Ready; Code available at\n  https://github.com/clear-nus/DGflow; Updated Related Work", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep generative modeling has seen impressive advances in recent years, to the\npoint where it is now commonplace to see simulated samples (e.g., images) that\nclosely resemble real-world data. However, generation quality is generally\ninconsistent for any given model and can vary dramatically between samples. We\nintroduce Discriminator Gradient flow (DGflow), a new technique that improves\ngenerated samples via the gradient flow of entropy-regularized f-divergences\nbetween the real and the generated data distributions. The gradient flow takes\nthe form of a non-linear Fokker-Plank equation, which can be easily simulated\nby sampling from the equivalent McKean-Vlasov process. By refining inferior\nsamples, our technique avoids wasteful sample rejection used by previous\nmethods (DRS & MH-GAN). Compared to existing works that focus on specific GAN\nvariants, we show our refinement approach can be applied to GANs with\nvector-valued critics and even other deep generative models such as VAEs and\nNormalizing Flows. Empirical results on multiple synthetic, image, and text\ndatasets demonstrate that DGflow leads to significant improvement in the\nquality of generated samples for a variety of generative models, outperforming\nthe state-of-the-art Discriminator Optimal Transport (DOT) and Discriminator\nDriven Latent Sampling (DDLS) methods.\n", "versions": [{"version": "v1", "created": "Tue, 1 Dec 2020 19:10:15 GMT"}, {"version": "v2", "created": "Thu, 28 Jan 2021 09:08:55 GMT"}, {"version": "v3", "created": "Wed, 17 Mar 2021 19:33:49 GMT"}, {"version": "v4", "created": "Sat, 5 Jun 2021 04:45:44 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Ansari", "Abdul Fatir", ""], ["Ang", "Ming Liang", ""], ["Soh", "Harold", ""]]}, {"id": "2012.00822", "submitter": "Haozheng Luo", "authors": "Haozheng Luo, Ruiyang Qin", "title": "Open-Ended Multi-Modal Relational Reason for Video Question Answering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.HC cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  People with visual impairments urgently need helps, not only on the basic\ntasks such as guiding and retrieving objects , but on the advanced tasks like\npicturing the new environments. More than a guiding dog, they might want some\ndevices which are able to provide linguistic interaction. Building on various\nresearch literature, we aim to conduct a research on the interaction between\nthe robot agent and visual impaired people. The robot agent, applied VQA\ntechniques, is able to analyze the environment, process and understand the\npronouncing questions, and provide feedback to the human user. In this paper,\nwe are going to discuss the related questions about this kind of interaction,\nthe techniques we used in this work, and how we conduct our research.\n", "versions": [{"version": "v1", "created": "Tue, 1 Dec 2020 20:49:59 GMT"}, {"version": "v2", "created": "Mon, 7 Dec 2020 03:31:34 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Luo", "Haozheng", ""], ["Qin", "Ruiyang", ""]]}, {"id": "2012.00845", "submitter": "Farid Ghareh Mohammadi", "authors": "Farid Ghareh Mohammadi, Farzan Shenavarmasouleh, M. Hadi Amini and\n  Hamid R. Arabnia", "title": "Malware Detection using Artificial Bee Colony Algorithm", "comments": null, "journal-ref": null, "doi": "10.1145/3410530.3414598", "report-no": null, "categories": "cs.CR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Malware detection has become a challenging task due to the increase in the\nnumber of malware families. Universal malware detection algorithms that can\ndetect all the malware families are needed to make the whole process feasible.\nHowever, the more universal an algorithm is, the higher number of feature\ndimensions it needs to work with, and that inevitably causes the emerging\nproblem of Curse of Dimensionality (CoD). Besides, it is also difficult to make\nthis solution work due to the real-time behavior of malware analysis. In this\npaper, we address this problem and aim to propose a feature selection based\nmalware detection algorithm using an evolutionary algorithm that is referred to\nas Artificial Bee Colony (ABC). The proposed algorithm enables researchers to\ndecrease the feature dimension and as a result, boost the process of malware\ndetection. The experimental results reveal that the proposed method outperforms\nthe state-of-the-art.\n", "versions": [{"version": "v1", "created": "Tue, 1 Dec 2020 21:32:09 GMT"}], "update_date": "2020-12-03", "authors_parsed": [["Mohammadi", "Farid Ghareh", ""], ["Shenavarmasouleh", "Farzan", ""], ["Amini", "M. Hadi", ""], ["Arabnia", "Hamid R.", ""]]}, {"id": "2012.00857", "submitter": "Yikang Shen", "authors": "Yikang Shen, Yi Tay, Che Zheng, Dara Bahri, Donald Metzler, Aaron\n  Courville", "title": "StructFormer: Joint Unsupervised Induction of Dependency and\n  Constituency Structure from Masked Language Modeling", "comments": "Published as a conference paper at ACL 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  There are two major classes of natural language grammar -- the dependency\ngrammar that models one-to-one correspondences between words and the\nconstituency grammar that models the assembly of one or several corresponded\nwords. While previous unsupervised parsing methods mostly focus on only\ninducing one class of grammars, we introduce a novel model, StructFormer, that\ncan simultaneously induce dependency and constituency structure. To achieve\nthis, we propose a new parsing framework that can jointly generate a\nconstituency tree and dependency graph. Then we integrate the induced\ndependency relations into the transformer, in a differentiable manner, through\na novel dependency-constrained self-attention mechanism. Experimental results\nshow that our model can achieve strong results on unsupervised constituency\nparsing, unsupervised dependency parsing, and masked language modeling at the\nsame time.\n", "versions": [{"version": "v1", "created": "Tue, 1 Dec 2020 21:54:51 GMT"}, {"version": "v2", "created": "Tue, 15 Dec 2020 20:55:53 GMT"}, {"version": "v3", "created": "Sun, 11 Jul 2021 01:10:26 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Shen", "Yikang", ""], ["Tay", "Yi", ""], ["Zheng", "Che", ""], ["Bahri", "Dara", ""], ["Metzler", "Donald", ""], ["Courville", "Aaron", ""]]}, {"id": "2012.00868", "submitter": "Srikar Appalaraju", "authors": "Srikar Appalaraju, Yi Zhu, Yusheng Xie, Istv\\'an Feh\\'erv\\'ari", "title": "Towards Good Practices in Self-supervised Representation Learning", "comments": null, "journal-ref": "Neural Information Processing Systems (NeurIPS Self-Supervision\n  Workshop 2020)", "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Self-supervised representation learning has seen remarkable progress in the\nlast few years. More recently, contrastive instance learning has shown\nimpressive results compared to its supervised learning counterparts. However,\neven with the ever increased interest in contrastive instance learning, it is\nstill largely unclear why these methods work so well. In this paper, we aim to\nunravel some of the mysteries behind their success, which are the good\npractices. Through an extensive empirical analysis, we hope to not only provide\ninsights but also lay out a set of best practices that led to the success of\nrecent work in self-supervised representation learning.\n", "versions": [{"version": "v1", "created": "Tue, 1 Dec 2020 22:13:43 GMT"}], "update_date": "2020-12-03", "authors_parsed": [["Appalaraju", "Srikar", ""], ["Zhu", "Yi", ""], ["Xie", "Yusheng", ""], ["Feh\u00e9rv\u00e1ri", "Istv\u00e1n", ""]]}, {"id": "2012.00885", "submitter": "Arvind Ramanathan", "authors": "Arvind Ramanathan and Heng Ma and Akash Parvatikar and Chakra S.\n  Chennubhotla", "title": "Artificial intelligence techniques for integrative structural biology of\n  intrinsically disordered proteins", "comments": "9 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.BM cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We outline recent developments in artificial intelligence (AI) and machine\nlearning (ML) techniques for integrative structural biology of intrinsically\ndisordered proteins (IDP) ensembles. IDPs challenge the traditional protein\nstructure-function paradigm by adapting their conformations in response to\nspecific binding partners leading them to mediate diverse, and often complex\ncellular functions such as biological signaling, self organization and\ncompartmentalization. Obtaining mechanistic insights into their function can\ntherefore be challenging for traditional structural determination techniques.\nOften, scientists have to rely on piecemeal evidence drawn from diverse\nexperimental techniques to characterize their functional mechanisms. Multiscale\nsimulations can help bridge critical knowledge gaps about IDP structure\nfunction relationships - however, these techniques also face challenges in\nresolving emergent phenomena within IDP conformational ensembles. We posit that\nscalable statistical inference techniques can effectively integrate information\ngleaned from multiple experimental techniques as well as from simulations, thus\nproviding access to atomistic details of these emergent phenomena.\n", "versions": [{"version": "v1", "created": "Tue, 1 Dec 2020 23:10:50 GMT"}], "update_date": "2020-12-03", "authors_parsed": [["Ramanathan", "Arvind", ""], ["Ma", "Heng", ""], ["Parvatikar", "Akash", ""], ["Chennubhotla", "Chakra S.", ""]]}, {"id": "2012.01010", "submitter": "Zhong Cao", "authors": "Zhong Cao, Shaobing Xu, Songan Zhang, Huei Peng, Diange Yang", "title": "Driving-Policy Adaptive Safeguard for Autonomous Vehicles Using\n  Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Safeguard functions such as those provided by advanced emergency braking\n(AEB) can provide another layer of safety for autonomous vehicles (AV). A smart\nsafeguard function should adapt the activation conditions to the driving\npolicy, to avoid unnecessary interventions as well as improve vehicle safety.\nThis paper proposes a driving-policy adaptive safeguard (DPAS) design,\nincluding a collision avoidance strategy and an activation function. The\ncollision avoidance strategy is designed in a reinforcement learning framework,\nobtained by Monte-Carlo Tree Search (MCTS). It can learn from past collisions\nand manipulate both braking and steering in stochastic traffics. The\ndriving-policy adaptive activation function should dynamically assess current\ndriving policy risk and kick in when an urgent threat is detected. To generate\nthis activation function, MCTS' exploration and rollout modules are designed to\nfully evaluate the AV's current driving policy, and then explore other safer\nactions. In this study, the DPAS is validated with two typical highway-driving\npolicies. The results are obtained through and 90,000 times in the stochastic\nand aggressive simulated traffic. The results are calibrated by naturalistic\ndriving data and show that the proposed safeguard reduces the collision rate\nsignificantly without introducing more interventions, compared with the\nstate-based benchmark safeguards. In summary, the proposed safeguard leverages\nthe learning-based method in stochastic and emergent scenarios and imposes\nminimal influence on the driving policy.\n", "versions": [{"version": "v1", "created": "Wed, 2 Dec 2020 08:01:53 GMT"}], "update_date": "2020-12-03", "authors_parsed": [["Cao", "Zhong", ""], ["Xu", "Shaobing", ""], ["Zhang", "Songan", ""], ["Peng", "Huei", ""], ["Yang", "Diange", ""]]}, {"id": "2012.01022", "submitter": "Ritwik Gupta", "authors": "Ritwik Gupta, Eric T. Heim", "title": "Proceedings of NeurIPS 2019 Workshop on Artificial Intelligence for\n  Humanitarian Assistance and Disaster Response", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  These are the \"proceedings\" of the 1st AI + HADR workshop which was held in\nVancouver, Canada on December 13, 2019 as part of the Neural Information\nProcessing Systems conference. These are non-archival and serve solely as a\ncollation of all the papers accepted to the workshop.\n", "versions": [{"version": "v1", "created": "Wed, 2 Dec 2020 08:19:55 GMT"}, {"version": "v2", "created": "Thu, 3 Dec 2020 17:43:43 GMT"}], "update_date": "2020-12-04", "authors_parsed": [["Gupta", "Ritwik", ""], ["Heim", "Eric T.", ""]]}, {"id": "2012.01027", "submitter": "Simon Schaefer", "authors": "Simon Schaefer, Karen Leung, Boris Ivanovic, Marco Pavone", "title": "Leveraging Neural Network Gradients within Trajectory Optimization for\n  Proactive Human-Robot Interactions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To achieve seamless human-robot interactions, robots need to intimately\nreason about complex interaction dynamics and future human behaviors within\ntheir motion planning process. However, there is a disconnect between\nstate-of-the-art neural network-based human behavior models and robot motion\nplanners -- either the behavior models are limited in their consideration of\ndownstream planning or a simplified behavior model is used to ensure\ntractability of the planning problem. In this work, we present a framework that\nfuses together the interpretability and flexibility of trajectory optimization\n(TO) with the predictive power of state-of-the-art human trajectory prediction\nmodels. In particular, we leverage gradient information from data-driven\nprediction models to explicitly reason about human-robot interaction dynamics\nwithin a gradient-based TO problem. We demonstrate the efficacy of our approach\nin a multi-agent scenario whereby a robot is required to safely and efficiently\nnavigate through a crowd of up to ten pedestrians. We compare against a variety\nof planning methods, and show that by explicitly accounting for interaction\ndynamics within the planner, our method offers safer and more efficient\nbehaviors, even yielding proactive and nuanced behaviors such as waiting for a\npedestrian to pass before moving.\n", "versions": [{"version": "v1", "created": "Wed, 2 Dec 2020 08:43:36 GMT"}], "update_date": "2020-12-03", "authors_parsed": [["Schaefer", "Simon", ""], ["Leung", "Karen", ""], ["Ivanovic", "Boris", ""], ["Pavone", "Marco", ""]]}, {"id": "2012.01031", "submitter": "Sendong Zhao", "authors": "Sendong Zhao, Bing Qin, Ting Liu, Fei Wang", "title": "Biomedical Knowledge Graph Refinement with Embedding and Logic Rules", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Currently, there is a rapidly increasing need for high-quality biomedical\nknowledge graphs (BioKG) that provide direct and precise biomedical knowledge.\nIn the context of COVID-19, this issue is even more necessary to be\nhighlighted. However, most BioKG construction inevitably includes numerous\nconflicts and noises deriving from incorrect knowledge descriptions in\nliterature and defective information extraction techniques. Many studies have\ndemonstrated that reasoning upon the knowledge graph is effective in\neliminating such conflicts and noises. This paper proposes a method BioGRER to\nimprove the BioKG's quality, which comprehensively combines the knowledge graph\nembedding and logic rules that support and negate triplets in the BioKG. In the\nproposed model, the BioKG refinement problem is formulated as the probability\nestimation for triplets in the BioKG. We employ the variational EM algorithm to\noptimize knowledge graph embedding and logic rule inference alternately. In\nthis way, our model could combine efforts from both the knowledge graph\nembedding and logic rules, leading to better results than using them alone. We\nevaluate our model over a COVID-19 knowledge graph and obtain competitive\nresults.\n", "versions": [{"version": "v1", "created": "Wed, 2 Dec 2020 08:55:07 GMT"}], "update_date": "2020-12-03", "authors_parsed": [["Zhao", "Sendong", ""], ["Qin", "Bing", ""], ["Liu", "Ting", ""], ["Wang", "Fei", ""]]}, {"id": "2012.01064", "submitter": "Stephane Gaiffas Pr", "authors": "Ibrahim Merad and Yiyang Yu and Emmanuel Bacry and St\\'ephane\n  Ga\\\"iffas", "title": "About contrastive unsupervised representation learning for\n  classification and its convergence", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Contrastive representation learning has been recently proved to be very\nefficient for self-supervised training. These methods have been successfully\nused to train encoders which perform comparably to supervised training on\ndownstream classification tasks. A few works have started to build a\ntheoretical framework around contrastive learning in which guarantees for its\nperformance can be proven. We provide extensions of these results to training\nwith multiple negative samples and for multiway classification. Furthermore, we\nprovide convergence guarantees for the minimization of the contrastive training\nerror with gradient descent of an overparametrized deep neural encoder, and\nprovide some numerical experiments that complement our theoretical findings\n", "versions": [{"version": "v1", "created": "Wed, 2 Dec 2020 10:08:57 GMT"}], "update_date": "2020-12-03", "authors_parsed": [["Merad", "Ibrahim", ""], ["Yu", "Yiyang", ""], ["Bacry", "Emmanuel", ""], ["Ga\u00efffas", "St\u00e9phane", ""]]}, {"id": "2012.01074", "submitter": "Giulia Cisotto", "authors": "Giulia Cisotto, Alessio Zanga, Joanna Chlebus, Italo Zoppis, Sara\n  Manzoni, and Urszula Markowska-Kaczmar", "title": "Comparison of Attention-based Deep Learning Models for EEG\n  Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.AI cs.LG q-bio.NC q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Objective: To evaluate the impact on Electroencephalography (EEG)\nclassification of different kinds of attention mechanisms in Deep Learning (DL)\nmodels. Methods: We compared three attention-enhanced DL models, the brand-new\nInstaGATs, an LSTM with attention and a CNN with attention. We used these\nmodels to classify normal and abnormal (i.e., artifactual or pathological) EEG\npatterns. Results: We achieved the state of the art in all classification\nproblems, regardless the large variability of the datasets and the simple\narchitecture of the attention-enhanced models. We could also prove that,\ndepending on how the attention mechanism is applied and where the attention\nlayer is located in the model, we can alternatively leverage the information\ncontained in the time, frequency or space domain of the dataset. Conclusions:\nwith this work, we shed light over the role of different attention mechanisms\nin the classification of normal and abnormal EEG patterns. Moreover, we\ndiscussed how they can exploit the intrinsic relationships in the temporal,\nfrequency and spatial domains of our brain activity. Significance: Attention\nrepresents a promising strategy to evaluate the quality of the EEG information,\nand its relevance, in different real-world scenarios. Moreover, it can make it\neasier to parallelize the computation and, thus, to speed up the analysis of\nbig electrophysiological (e.g., EEG) datasets.\n", "versions": [{"version": "v1", "created": "Wed, 2 Dec 2020 10:43:41 GMT"}], "update_date": "2020-12-03", "authors_parsed": [["Cisotto", "Giulia", ""], ["Zanga", "Alessio", ""], ["Chlebus", "Joanna", ""], ["Zoppis", "Italo", ""], ["Manzoni", "Sara", ""], ["Markowska-Kaczmar", "Urszula", ""]]}, {"id": "2012.01101", "submitter": "Kim Phuc Tran", "authors": "Zhenglei He, Kim Phuc Tran (GEMTEX), Sebastien Thomassey, Xianyi Zeng,\n  Jie Xu, Changhai Yi", "title": "Multi-Objective Optimization of the Textile Manufacturing Process Using\n  Deep-Q-Network Based Multi-Agent Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-objective optimization of the textile manufacturing process is an\nincreasing challenge because of the growing complexity involved in the\ndevelopment of the textile industry. The use of intelligent techniques has been\noften discussed in this domain, although a significant improvement from certain\nsuccessful applications has been reported, the traditional methods failed to\nwork with high-as well as human intervention. Upon which, this paper proposed a\nmulti-agent reinforcement learning (MARL) framework to transform the\noptimization process into a stochastic game and introduced the deep Q-networks\nalgorithm to train the multiple agents. A utilitarian selection mechanism was\nemployed in the stochastic game, which (-greedy policy) in each state to avoid\nthe interruption of multiple equilibria and achieve the correlated equilibrium\noptimal solutions of the optimizing process. The case study result reflects\nthat the proposed MARL system is possible to achieve the optimal solutions for\nthe textile ozonation process and it performs better than the traditional\napproaches.\n", "versions": [{"version": "v1", "created": "Wed, 2 Dec 2020 11:37:44 GMT"}], "update_date": "2020-12-03", "authors_parsed": [["He", "Zhenglei", "", "GEMTEX"], ["Tran", "Kim Phuc", "", "GEMTEX"], ["Thomassey", "Sebastien", ""], ["Zeng", "Xianyi", ""], ["Xu", "Jie", ""], ["Yi", "Changhai", ""]]}, {"id": "2012.01126", "submitter": "Swati Padhee", "authors": "Swati Padhee (1), Amanuel Alambo (1), Tanvi Banerjee (1), Arvind\n  Subramaniam (2), Daniel M. Abrams (3), Gary K.Nave Jr. (3), Nirmish Shah (2)\n  ((1) Wright State University, (2) Duke University, (3) Northwestern\n  University)", "title": "Pain Intensity Assessment in Sickle Cell Disease patients using Vital\n  Signs during Hospital Visits", "comments": "Accepted for presentation at the FIRST WORKSHOP ON COMPUTATIONAL &\n  AFFECTIVE INTELLIGENCE IN HEALTHCARE APPLICATIONS (VULNERABLE POPULATIONS) In\n  Conjunction with the International Conference on Pattern Recognition (ICPR)\n  2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pain in sickle cell disease (SCD) is often associated with increased\nmorbidity, mortality, and high healthcare costs. The standard method for\npredicting the absence, presence, and intensity of pain has long been\nself-report. However, medical providers struggle to manage patients based on\nsubjective pain reports correctly and pain medications often lead to further\ndifficulties in patient communication as they may cause sedation and\nsleepiness. Recent studies have shown that objective physiological measures can\npredict subjective self-reported pain scores for inpatient visits using machine\nlearning (ML) techniques. In this study, we evaluate the generalizability of ML\ntechniques to data collected from 50 patients over an extended period across\nthree types of hospital visits (i.e., inpatient, outpatient and outpatient\nevaluation). We compare five classification algorithms for various pain\nintensity levels at both intra-individual (within each patient) and\ninter-individual (between patients) level. While all the tested classifiers\nperform much better than chance, a Decision Tree (DT) model performs best at\npredicting pain on an 11-point severity scale (from 0-10) with an accuracy of\n0.728 at an inter-individual level and 0.653 at an intra-individual level. The\naccuracy of DT significantly improves to 0.941 on a 2-point rating scale (i.e.,\nno/mild pain: 0-5, severe pain: 6-10) at an intra-individual level. Our\nexperimental results demonstrate that ML techniques can provide an objective\nand quantitative evaluation of pain intensity levels for all three types of\nhospital visits.\n", "versions": [{"version": "v1", "created": "Tue, 24 Nov 2020 15:25:29 GMT"}], "update_date": "2020-12-03", "authors_parsed": [["Padhee", "Swati", ""], ["Alambo", "Amanuel", ""], ["Banerjee", "Tanvi", ""], ["Subramaniam", "Arvind", ""], ["Abrams", "Daniel M.", ""], ["Nave", "Gary K.", "Jr."], ["Shah", "Nirmish", ""]]}, {"id": "2012.01128", "submitter": "Francois Roewer-Despres", "authors": "Francois Roewer-Despres, Janelle Berscheid", "title": "Continuous Subject-in-the-Loop Integration: Centering AI on Marginalized\n  Communities", "comments": "4 pages, Accepted at the Resistance AI Workshop @ NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite its utopian promises as a disruptive equalizer, AI - like most tools\ndeployed under the guise of neutrality - has tended to simply reinforce\nexisting social structures. To counter this trend, radical AI calls for\ncentering on the marginalized. We argue that gaps in key infrastructure are\npreventing the widespread adoption of radical AI, and propose a guiding\nprinciple for both identifying these infrastructure gaps and evaluating whether\nproposals for new infrastructure effectively center marginalized voices.\n", "versions": [{"version": "v1", "created": "Mon, 30 Nov 2020 00:56:11 GMT"}], "update_date": "2020-12-04", "authors_parsed": [["Roewer-Despres", "Francois", ""], ["Berscheid", "Janelle", ""]]}, {"id": "2012.01148", "submitter": "Yilei Zeng", "authors": "Yilei Zeng, Aayush Shah, Jameson Thai, Michael Zyda", "title": "Applied Machine Learning for Games: A Graduate School Course", "comments": "The Eleventh Symposium on Educational Advances in Artificial\n  Intelligence (EAAI-21)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The game industry is moving into an era where old-style game engines are\nbeing replaced by re-engineered systems with embedded machine learning\ntechnologies for the operation, analysis and understanding of game play. In\nthis paper, we describe our machine learning course designed for graduate\nstudents interested in applying recent advances of deep learning and\nreinforcement learning towards gaming. This course serves as a bridge to foster\ninterdisciplinary collaboration among graduate schools and does not require\nprior experience designing or building games. Graduate students enrolled in\nthis course apply different fields of machine learning techniques such as\ncomputer vision, natural language processing, computer graphics, human computer\ninteraction, robotics and data analysis to solve open challenges in gaming.\nStudent projects cover use-cases such as training AI-bots in gaming benchmark\nenvironments and competitions, understanding human decision patterns in gaming,\nand creating intelligent non-playable characters or environments to foster\nengaging gameplay. Projects demos can help students open doors for an industry\ncareer, aim for publications, or lay the foundations of a future product. Our\nstudents gained hands-on experience in applying state of the art machine\nlearning techniques to solve real-life problems in gaming.\n", "versions": [{"version": "v1", "created": "Mon, 30 Nov 2020 05:46:14 GMT"}, {"version": "v2", "created": "Fri, 1 Jan 2021 18:06:59 GMT"}], "update_date": "2021-01-05", "authors_parsed": [["Zeng", "Yilei", ""], ["Shah", "Aayush", ""], ["Thai", "Jameson", ""], ["Zyda", "Michael", ""]]}, {"id": "2012.01174", "submitter": "Francesca Cuomo", "authors": "Pietro Spadaccino and Francesca Cuomo", "title": "Intrusion Detection Systems for IoT: opportunities and challenges\n  offered by Edge Computing", "comments": "Paper submitted for publication in the IEEE Communications Surveys &\n  Tutorials", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Key components of current cybersecurity methods are the Intrusion Detection\nSystems (IDSs) were different techniques and architectures are applied to\ndetect intrusions. IDSs can be based either on cross-checking monitored events\nwith a database of known intrusion experiences, known as signature-based, or on\nlearning the normal behavior of the system and reporting whether some anomalous\nevents occur, named anomaly-based. This work is dedicated to the application to\nthe Internet of Things (IoT) network where edge computing is used to support\nthe IDS implementation. New challenges that arise when deploying an IDS in an\nedge scenario are identified and remedies are proposed. We focus on\nanomaly-based IDSs, showing the main techniques that can be leveraged to detect\nanomalies and we present machine learning techniques and their application in\nthe context of an IDS, describing the expected advantages and disadvantages\nthat a specific technique could cause.\n", "versions": [{"version": "v1", "created": "Wed, 2 Dec 2020 13:07:27 GMT"}], "update_date": "2020-12-03", "authors_parsed": [["Spadaccino", "Pietro", ""], ["Cuomo", "Francesca", ""]]}, {"id": "2012.01176", "submitter": "EPTCS", "authors": "Matt Luckcuck (University of Manchester, UK), Marie Farrell\n  (University of Manchester, UK)", "title": "Proceedings Second Workshop on Formal Methods for Autonomous Systems", "comments": null, "journal-ref": "EPTCS 329, 2020", "doi": "10.4204/EPTCS.329", "report-no": null, "categories": "cs.LO cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Autonomous systems are highly complex and present unique challenges for the\napplication of formal methods. Autonomous systems act without human\nintervention, and are often embedded in a robotic system, so that they can\ninteract with the real world. As such, they exhibit the properties of\nsafety-critical, cyber-physical, hybrid, and real-time systems.\n  The goal of FMAS is to bring together leading researchers who are tackling\nthe unique challenges of autonomous systems using formal methods, to present\nrecent and ongoing work. We are interested in the use of formal methods to\nspecify, model, or verify autonomous or robotic systems; in whole or in part.\nWe are also interested in successful industrial applications and potential\nfuture directions for this emerging application of formal methods.\n", "versions": [{"version": "v1", "created": "Wed, 2 Dec 2020 13:08:57 GMT"}], "update_date": "2020-12-03", "authors_parsed": [["Luckcuck", "Matt", "", "University of Manchester, UK"], ["Farrell", "Marie", "", "University of Manchester, UK"]]}, {"id": "2012.01186", "submitter": "Hao Sheng", "authors": "Eric Li, Jingyi Su, Hao Sheng, Lawrence Wai", "title": "AGenT Zero: Zero-shot Automatic Multiple-Choice Question Generation for\n  Skill Assessments", "comments": "AAAI 2021 Workshop on AI Education/TIPCE 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multiple-choice questions (MCQs) offer the most promising avenue for skill\nevaluation in the era of virtual education and job recruiting, where\ntraditional performance-based alternatives such as projects and essays have\nbecome less viable, and grading resources are constrained. The automated\ngeneration of MCQs would allow assessment creation at scale. Recent advances in\nnatural language processing have given rise to many complex question generation\nmethods. However, the few methods that produce deployable results in specific\ndomains require a large amount of domain-specific training data that can be\nvery costly to acquire. Our work provides an initial foray into MCQ generation\nunder high data-acquisition cost scenarios by strategically emphasizing\nparaphrasing the question context (compared to the task). In addition to\nmaintaining semantic similarity between the question-answer pairs, our\npipeline, which we call AGenT Zero, consists of only pre-trained models and\nrequires no fine-tuning, minimizing data acquisition costs for question\ngeneration. AGenT Zero successfully outperforms other pre-trained methods in\nfluency and semantic similarity. Additionally, with some small changes, our\nassessment pipeline can be generalized to a broader question and answer space,\nincluding short answer or fill in the blank questions.\n", "versions": [{"version": "v1", "created": "Wed, 25 Nov 2020 04:06:57 GMT"}, {"version": "v2", "created": "Fri, 18 Dec 2020 23:46:56 GMT"}], "update_date": "2020-12-22", "authors_parsed": [["Li", "Eric", ""], ["Su", "Jingyi", ""], ["Sheng", "Hao", ""], ["Wai", "Lawrence", ""]]}, {"id": "2012.01187", "submitter": "Sepinoud Azimi", "authors": "Sepinoud Azimi, Carmen-Gabriela Popa, and Tatjana Cuci\\'c", "title": "Improving Students Performance in Small-Scale Online Courses -- A\n  Machine Learning-Based Intervention", "comments": null, "journal-ref": null, "doi": "10.3991/ijai.v2i2.19371", "report-no": null, "categories": "cs.CY cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The birth of massive open online courses (MOOCs) has had an undeniable effect\non how teaching is being delivered. It seems that traditional in class teaching\nis becoming less popular with the young generation, the generation that wants\nto choose when, where and at what pace they are learning. As such, many\nuniversities are moving towards taking their courses, at least partially,\nonline. However, online courses, although very appealing to the younger\ngeneration of learners, come at a cost. For example, the dropout rate of such\ncourses is higher than that of more traditional ones, and the reduced in person\ninteraction with the teachers results in less timely guidance and intervention\nfrom the educators. Machine learning (ML) based approaches have shown\nphenomenal successes in other domains. The existing stigma that applying ML\nbased techniques requires a large amount of data seems to be a bottleneck when\ndealing with small scale courses with limited amounts of produced data. In this\nstudy, we show not only that the data collected from an online learning\nmanagement system could be well utilized in order to predict students overall\nperformance but also that it could be used to propose timely intervention\nstrategies to boost the students performance level. The results of this study\nindicate that effective intervention strategies could be suggested as early as\nthe middle of the course to change the course of students progress for the\nbetter. We also present an assistive pedagogical tool based on the outcome of\nthis study, to assist in identifying challenging students and in suggesting\nearly intervention strategies.\n", "versions": [{"version": "v1", "created": "Mon, 23 Nov 2020 14:12:55 GMT"}], "update_date": "2020-12-03", "authors_parsed": [["Azimi", "Sepinoud", ""], ["Popa", "Carmen-Gabriela", ""], ["Cuci\u0107", "Tatjana", ""]]}, {"id": "2012.01189", "submitter": "Dawid Rymarczyk", "authors": "Adriana Borowa, Dawid Rymarczyk, Dorota Ocho\\'nska, Monika\n  Brzychczy-W{\\l}och, Bartosz Zieli\\'nski", "title": "Classifying bacteria clones using attention-based deep multiple instance\n  learning interpreted by persistence homology", "comments": "Published at the International Joint Conferences on Neural Networks", "journal-ref": "978-0-7381-3366-9/21, 2021", "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this work, we analyze if it is possible to distinguish between different\nclones of the same bacteria species (Klebsiella pneumoniae) based only on\nmicroscopic images. It is a challenging task, previously considered impossible\ndue to the high clones similarity. For this purpose, we apply a multi-step\nalgorithm with attention-based multiple instance learning. Except for obtaining\naccuracy at the level of 0.9, we introduce extensive interpretability based on\nCellProfiler and persistence homology, increasing the understandability and\ntrust in the model.\n", "versions": [{"version": "v1", "created": "Wed, 2 Dec 2020 13:20:39 GMT"}, {"version": "v2", "created": "Fri, 23 Jul 2021 11:27:58 GMT"}], "update_date": "2021-07-26", "authors_parsed": [["Borowa", "Adriana", ""], ["Rymarczyk", "Dawid", ""], ["Ocho\u0144ska", "Dorota", ""], ["Brzychczy-W\u0142och", "Monika", ""], ["Zieli\u0144ski", "Bartosz", ""]]}, {"id": "2012.01201", "submitter": "Chandan Gautam", "authors": "Sannidhi P Kumar, Chandan Gautam, Suresh Sundaram", "title": "Meta-Cognition-Based Simple And Effective Approach To Object Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, many researchers have attempted to improve deep learning-based\nobject detection models, both in terms of accuracy and operational speeds.\nHowever, frequently, there is a trade-off between speed and accuracy of such\nmodels, which encumbers their use in practical applications such as autonomous\nnavigation. In this paper, we explore a meta-cognitive learning strategy for\nobject detection to improve generalization ability while at the same time\nmaintaining detection speed. The meta-cognitive method selectively samples the\nobject instances in the training dataset to reduce overfitting. We use YOLO v3\nTiny as a base model for the work and evaluate the performance using the MS\nCOCO dataset. The experimental results indicate an improvement in absolute\nprecision of 2.6% (minimum), and 4.4% (maximum), with no overhead to inference\ntime.\n", "versions": [{"version": "v1", "created": "Wed, 2 Dec 2020 13:36:51 GMT"}], "update_date": "2020-12-03", "authors_parsed": [["Kumar", "Sannidhi P", ""], ["Gautam", "Chandan", ""], ["Sundaram", "Suresh", ""]]}, {"id": "2012.01206", "submitter": "Arturo Cruz-Maya", "authors": "Arturo Cruz-Maya", "title": "Target Reaching Behaviour for Unfreezing the Robot in a Semi-Static and\n  Crowded Environment", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Robot navigation in human semi-static and crowded environments can lead to\nthe freezing problem, where the robot can not move due to the presence of\nhumans standing on its path and no other path is available. Classical\napproaches of robot navigation do not provide a solution for this problem. In\nsuch situations, the robot could interact with the humans in order to clear its\npath instead of considering them as unanimated obstacles. In this work, we\npropose a robot behavior for a wheeled humanoid robot that complains with\nsocial norms for clearing its path when the robot is frozen due to the presence\nof humans. The behavior consists of two modules: 1) A detection module, which\nmake use of the Yolo v3 algorithm trained to detect human hands and human arms.\n2) A gesture module, which make use of a policy trained in simulation using the\nProximal Policy Optimization algorithm. Orchestration of the two models is done\nusing the ROS framework.\n", "versions": [{"version": "v1", "created": "Wed, 2 Dec 2020 13:43:59 GMT"}, {"version": "v2", "created": "Wed, 27 Jan 2021 08:44:03 GMT"}], "update_date": "2021-01-28", "authors_parsed": [["Cruz-Maya", "Arturo", ""]]}, {"id": "2012.01227", "submitter": "Taehyeong Kim", "authors": "Taehyeong Kim, Injune Hwang, Hyundo Lee, Hyunseo Kim, Won-Seok Choi,\n  Joseph J. Lim, Byoung-Tak Zhang", "title": "Message Passing Adaptive Resonance Theory for Online Active\n  Semi-supervised Learning", "comments": "Accepted to ICML 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Active learning is widely used to reduce labeling effort and training time by\nrepeatedly querying only the most beneficial samples from unlabeled data. In\nreal-world problems where data cannot be stored indefinitely due to limited\nstorage or privacy issues, the query selection and the model update should be\nperformed as soon as a new data sample is observed. Various online active\nlearning methods have been studied to deal with these challenges; however,\nthere are difficulties in selecting representative query samples and updating\nthe model efficiently without forgetting. In this study, we propose Message\nPassing Adaptive Resonance Theory (MPART) that learns the distribution and\ntopology of input data online. Through message passing on the topological\ngraph, MPART actively queries informative and representative samples, and\ncontinuously improves the classification performance using both labeled and\nunlabeled data. We evaluate our model in stream-based selective sampling\nscenarios with comparable query selection strategies, showing that MPART\nsignificantly outperforms competitive models.\n", "versions": [{"version": "v1", "created": "Wed, 2 Dec 2020 14:14:42 GMT"}, {"version": "v2", "created": "Wed, 24 Feb 2021 10:04:51 GMT"}, {"version": "v3", "created": "Sat, 10 Jul 2021 05:58:30 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Kim", "Taehyeong", ""], ["Hwang", "Injune", ""], ["Lee", "Hyundo", ""], ["Kim", "Hyunseo", ""], ["Choi", "Won-Seok", ""], ["Lim", "Joseph J.", ""], ["Zhang", "Byoung-Tak", ""]]}, {"id": "2012.01244", "submitter": "Anssi Kanervisto", "authors": "Anssi Kanervisto, Tomi Kinnunen, Ville Hautam\\\"aki", "title": "Policy Supervectors: General Characterization of Agents by their\n  Behaviour", "comments": "Code available at https://github.com/Miffyli/policy-supervectors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  By studying the underlying policies of decision-making agents, we can learn\nabout their shortcomings and potentially improve them. Traditionally, this has\nbeen done either by examining the agent's implementation, its behaviour while\nit is being executed, its performance with a reward/fitness function or by\nvisualizing the density of states the agent visits. However, these methods fail\nto describe the policy's behaviour in complex, high-dimensional environments or\ndo not scale to thousands of policies, which is required when studying training\nalgorithms. We propose policy supervectors for characterizing agents by the\ndistribution of states they visit, adopting successful techniques from the area\nof speech technology. Policy supervectors can characterize policies regardless\nof their design philosophy (e.g. rule-based vs. neural networks) and scale to\nthousands of policies on a single workstation machine. We demonstrate method's\napplicability by studying the evolution of policies during reinforcement\nlearning, evolutionary training and imitation learning, providing insight on\ne.g. how the search space of evolutionary algorithms is also reflected in\nagent's behaviour, not just in the parameters.\n", "versions": [{"version": "v1", "created": "Wed, 2 Dec 2020 14:43:16 GMT"}], "update_date": "2020-12-03", "authors_parsed": [["Kanervisto", "Anssi", ""], ["Kinnunen", "Tomi", ""], ["Hautam\u00e4ki", "Ville", ""]]}, {"id": "2012.01248", "submitter": "Micah Bowles", "authors": "Micah Bowles, Anna M. M. Scaife, Fiona Porter, Hongming Tang, David J.\n  Bastien", "title": "Attention-gating for improved radio galaxy classification", "comments": "18 pages, 16 figures, Published in MNRAS", "journal-ref": "MNRAS 501 (2021) 4579-4595", "doi": "10.1093/mnras/staa3946", "report-no": null, "categories": "astro-ph.GA astro-ph.IM cs.AI cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this work we introduce attention as a state of the art mechanism for\nclassification of radio galaxies using convolutional neural networks. We\npresent an attention-based model that performs on par with previous classifiers\nwhile using more than 50% fewer parameters than the next smallest classic CNN\napplication in this field. We demonstrate quantitatively how the selection of\nnormalisation and aggregation methods used in attention-gating can affect the\noutput of individual models, and show that the resulting attention maps can be\nused to interpret the classification choices made by the model. We observe that\nthe salient regions identified by the our model align well with the regions an\nexpert human classifier would attend to make equivalent classifications. We\nshow that while the selection of normalisation and aggregation may only\nminimally affect the performance of individual models, it can significantly\naffect the interpretability of the respective attention maps and by selecting a\nmodel which aligns well with how astronomers classify radio sources by eye, a\nuser can employ the model in a more effective manner.\n", "versions": [{"version": "v1", "created": "Wed, 2 Dec 2020 14:49:53 GMT"}, {"version": "v2", "created": "Mon, 1 Feb 2021 13:09:41 GMT"}], "update_date": "2021-02-02", "authors_parsed": [["Bowles", "Micah", ""], ["Scaife", "Anna M. M.", ""], ["Porter", "Fiona", ""], ["Tang", "Hongming", ""], ["Bastien", "David J.", ""]]}, {"id": "2012.01293", "submitter": "William Knauth", "authors": "William Knauth", "title": "The Self-Simplifying Machine: Exploiting the Structure of Piecewise\n  Linear Neural Networks to Create Interpretable Models", "comments": "38 pages, 32 figures, appendices A, B", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Today, it is more important than ever before for users to have trust in the\nmodels they use. As Machine Learning models fall under increased regulatory\nscrutiny and begin to see more applications in high-stakes situations, it\nbecomes critical to explain our models. Piecewise Linear Neural Networks (PLNN)\nwith the ReLU activation function have quickly become extremely popular models\ndue to many appealing properties; however, they still present many challenges\nin the areas of robustness and interpretation. To this end, we introduce novel\nmethodology toward simplification and increased interpretability of Piecewise\nLinear Neural Networks for classification tasks. Our methods include the use of\na trained, deep network to produce a well-performing, single-hidden-layer\nnetwork without further stochastic training, in addition to an algorithm to\nreduce flat networks to a smaller, more interpretable size with minimal loss in\nperformance. On these methods, we conduct preliminary studies of model\nperformance, as well as a case study on Wells Fargo's Home Lending dataset,\ntogether with visual model interpretation.\n", "versions": [{"version": "v1", "created": "Wed, 2 Dec 2020 16:02:14 GMT"}], "update_date": "2020-12-03", "authors_parsed": [["Knauth", "William", ""]]}, {"id": "2012.01303", "submitter": "Valentin Iovene", "authors": "Valentin Iovene (NEUROSPIN, PARIETAL), Gaston Zanitti (NEUROSPIN,\n  PARIETAL), Demian Wassermann (NEUROSPIN, PARIETAL)", "title": "Complex Coordinate-Based Meta-Analysis with Probabilistic Programming", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the growing number of published functional magnetic resonance imaging\n(fMRI) studies, meta-analysis databases and models have become an integral part\nof brain mapping research. Coordinate-based meta-analysis (CBMA) databases are\nbuilt by automatically extracting both coordinates of reported peak activations\nand term associations using natural language processing (NLP) techniques.\nSolving term-based queries on these databases make it possible to obtain\nstatistical maps of the brain related to specific cognitive processes. However,\nwith tools like Neurosynth, only singleterm queries lead to statistically\nreliable results. When solving richer queries, too few studies from the\ndatabase contribute to the statistical estimations. We design a probabilistic\ndomain-specific language (DSL) standing on Datalog and one of its probabilistic\nextensions, CP-Logic, for expressing and solving rich logic-based queries. We\nencode a CBMA database into a probabilistic program. Using the joint\ndistribution of its Bayesian network translation, we show that solutions of\nqueries on this program compute the right probability distributions of voxel\nactivations. We explain how recent lifted query processing algorithms make it\npossible to scale to the size of large neuroimaging data, where state of the\nart knowledge compilation (KC) techniques fail to solve queries fast enough for\npractical applications. Finally, we introduce a method for relating studies to\nterms probabilistically, leading to better solutions for conjunctive queries on\nsmaller databases. We demonstrate results for two-term conjunctive queries,\nboth on simulated meta-analysis databases and on the widely-used Neurosynth\ndatabase.\n", "versions": [{"version": "v1", "created": "Wed, 2 Dec 2020 16:16:26 GMT"}, {"version": "v2", "created": "Fri, 22 Jan 2021 13:36:50 GMT"}], "update_date": "2021-01-25", "authors_parsed": [["Iovene", "Valentin", "", "NEUROSPIN, PARIETAL"], ["Zanitti", "Gaston", "", "NEUROSPIN,\n  PARIETAL"], ["Wassermann", "Demian", "", "NEUROSPIN, PARIETAL"]]}, {"id": "2012.01323", "submitter": "Johannes Klaus Fichte", "authors": "Johannes K. Fichte and Markus Hecher and Florim Hamiti", "title": "The Model Counting Competition 2020", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many computational problems in modern society account to probabilistic\nreasoning, statistics, and combinatorics. A variety of these real-world\nquestions can be solved by representing the question in (Boolean) formulas and\nassociating the number of models of the formula directly with the answer to the\nquestion. Since there has been an increasing interest in practical problem\nsolving for model counting over the last years, the Model Counting (MC)\nCompetition was conceived in fall 2019. The competition aims to foster\napplications, identify new challenging benchmarks, and to promote new solvers\nand improve established solvers for the model counting problem and versions\nthereof. We hope that the results can be a good indicator of the current\nfeasibility of model counting and spark many new applications. In this paper,\nwe report on details of the Model Counting Competition 2020, about carrying out\nthe competition, and the results. The competition encompassed three versions of\nthe model counting problem, which we evaluated in separate tracks. The first\ntrack featured the model counting problem (MC), which asks for the number of\nmodels of a given Boolean formula. On the second track, we challenged\ndevelopers to submit programs that solve the weighted model counting problem\n(WMC). The last track was dedicated to projected model counting (PMC). In\ntotal, we received a surprising number of 9 solvers in 34 versions from 8\ngroups.\n", "versions": [{"version": "v1", "created": "Wed, 2 Dec 2020 16:52:07 GMT"}], "update_date": "2020-12-03", "authors_parsed": [["Fichte", "Johannes K.", ""], ["Hecher", "Markus", ""], ["Hamiti", "Florim", ""]]}, {"id": "2012.01365", "submitter": "Pedro Freire", "authors": "Pedro Freire, Adam Gleave, Sam Toyer, Stuart Russell", "title": "DERAIL: Diagnostic Environments for Reward And Imitation Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The objective of many real-world tasks is complex and difficult to\nprocedurally specify. This makes it necessary to use reward or imitation\nlearning algorithms to infer a reward or policy directly from human data.\nExisting benchmarks for these algorithms focus on realism, testing in complex\nenvironments. Unfortunately, these benchmarks are slow, unreliable and cannot\nisolate failures. As a complementary approach, we develop a suite of simple\ndiagnostic tasks that test individual facets of algorithm performance in\nisolation. We evaluate a range of common reward and imitation learning\nalgorithms on our tasks. Our results confirm that algorithm performance is\nhighly sensitive to implementation details. Moreover, in a case-study into a\npopular preference-based reward learning implementation, we illustrate how the\nsuite can pinpoint design flaws and rapidly evaluate candidate solutions. The\nenvironments are available at https://github.com/HumanCompatibleAI/seals .\n", "versions": [{"version": "v1", "created": "Wed, 2 Dec 2020 18:07:09 GMT"}], "update_date": "2020-12-03", "authors_parsed": [["Freire", "Pedro", ""], ["Gleave", "Adam", ""], ["Toyer", "Sam", ""], ["Russell", "Stuart", ""]]}, {"id": "2012.01369", "submitter": "Md. Musfiqur Rahman", "authors": "Md. Musfiqur Rahman, Mashrur Rashik, Md. Mamun-or-Rashid and Md.\n  Mosaddek Khan", "title": "Improving Solution Quality of Bounded Max-Sum Algorithm to Solve DCOPs\n  involving Hard and Soft Constraints", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.MA", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Bounded Max-Sum (BMS) is a message-passing algorithm that provides\napproximation solution to a specific form of de-centralized coordination\nproblems, namely Distributed Constrained Optimization Problems (DCOPs). In\nparticular, BMS algorithm is able to solve problems of this type having large\nsearch space at the expense of low computational cost. Notably, the traditional\nDCOP formulation does not consider those constraints that must be\nsatisfied(also known as hard constraints), rather it concentrates only on soft\nconstraints. Hence, although the presence of both types of constraints are\nobserved in a number of real-world applications, the BMS algorithm does not\nactively capitalize on the hard constraints. To address this issue, we tailor\nBMS in such a way that can deal with DCOPs having both type constraints. In so\ndoing, our approach improves the solution quality of the algorithm. The\nempirical results exhibit a marked improvement in the quality of the solutions\nof large DCOPs.\n", "versions": [{"version": "v1", "created": "Wed, 2 Dec 2020 18:10:14 GMT"}], "update_date": "2020-12-03", "authors_parsed": [["Rahman", "Md. Musfiqur", ""], ["Rashik", "Mashrur", ""], ["Mamun-or-Rashid", "Md.", ""], ["Khan", "Md. Mosaddek", ""]]}, {"id": "2012.01386", "submitter": "Nikhil Kapoor", "authors": "Nikhil Kapoor, Chun Yuan, Jonas L\\\"ohdefink, Roland Zimmermann, Serin\n  Varghese, Fabian H\\\"uger, Nico Schmidt, Peter Schlicht, Tim Fingscheidt", "title": "A Self-Supervised Feature Map Augmentation (FMA) Loss and Combined\n  Augmentations Finetuning to Efficiently Improve the Robustness of CNNs", "comments": "Accepted at ACM CSCS 2020 (8 pages, 4 figures)", "journal-ref": null, "doi": "10.1145/3385958.3430477", "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks are often not robust to semantically-irrelevant changes\nin the input. In this work we address the issue of robustness of\nstate-of-the-art deep convolutional neural networks (CNNs) against commonly\noccurring distortions in the input such as photometric changes, or the addition\nof blur and noise. These changes in the input are often accounted for during\ntraining in the form of data augmentation. We have two major contributions:\nFirst, we propose a new regularization loss called feature-map augmentation\n(FMA) loss which can be used during finetuning to make a model robust to\nseveral distortions in the input. Second, we propose a new combined\naugmentations (CA) finetuning strategy, that results in a single model that is\nrobust to several augmentation types at the same time in a data-efficient\nmanner. We use the CA strategy to improve an existing state-of-the-art method\ncalled stability training (ST). Using CA, on an image classification task with\ndistorted images, we achieve an accuracy improvement of on average 8.94% with\nFMA and 8.86% with ST absolute on CIFAR-10 and 8.04% with FMA and 8.27% with ST\nabsolute on ImageNet, compared to 1.98% and 2.12%, respectively, with the well\nknown data augmentation method, while keeping the clean baseline performance.\n", "versions": [{"version": "v1", "created": "Wed, 2 Dec 2020 18:32:14 GMT"}], "update_date": "2020-12-03", "authors_parsed": [["Kapoor", "Nikhil", ""], ["Yuan", "Chun", ""], ["L\u00f6hdefink", "Jonas", ""], ["Zimmermann", "Roland", ""], ["Varghese", "Serin", ""], ["H\u00fcger", "Fabian", ""], ["Schmidt", "Nico", ""], ["Schlicht", "Peter", ""], ["Fingscheidt", "Tim", ""]]}, {"id": "2012.01399", "submitter": "Markus Holzleitner", "authors": "Markus Holzleitner, Lukas Gruber, Jos\\'e Arjona-Medina, Johannes\n  Brandstetter, Sepp Hochreiter", "title": "Convergence Proof for Actor-Critic Methods Applied to PPO and RUDDER", "comments": "20 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove under commonly used assumptions the convergence of actor-critic\nreinforcement learning algorithms, which simultaneously learn a policy\nfunction, the actor, and a value function, the critic. Both functions can be\ndeep neural networks of arbitrary complexity. Our framework allows showing\nconvergence of the well known Proximal Policy Optimization (PPO) and of the\nrecently introduced RUDDER. For the convergence proof we employ recently\nintroduced techniques from the two time-scale stochastic approximation theory.\nOur results are valid for actor-critic methods that use episodic samples and\nthat have a policy that becomes more greedy during learning. Previous\nconvergence proofs assume linear function approximation, cannot treat episodic\nexamples, or do not consider that policies become greedy. The latter is\nrelevant since optimal policies are typically deterministic.\n", "versions": [{"version": "v1", "created": "Wed, 2 Dec 2020 18:47:06 GMT"}], "update_date": "2020-12-03", "authors_parsed": [["Holzleitner", "Markus", ""], ["Gruber", "Lukas", ""], ["Arjona-Medina", "Jos\u00e9", ""], ["Brandstetter", "Johannes", ""], ["Hochreiter", "Sepp", ""]]}, {"id": "2012.01403", "submitter": "Minke Xiu", "authors": "Minke Xiu, Ellis E. Eghan, Zhen Ming (Jack) Jiang, Bram Adams", "title": "Empirical Study on the Software Engineering Practices in Open Source ML\n  Package Repositories", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Recent advances in Artificial Intelligence (AI), especially in Machine\nLearning (ML), have introduced various practical applications (e.g., virtual\npersonal assistants and autonomous cars) that enhance the experience of\neveryday users. However, modern ML technologies like Deep Learning require\nconsiderable technical expertise and resources to develop, train and deploy\nsuch models, making effective reuse of the ML models a necessity. Such\ndiscovery and reuse by practitioners and researchers are being addressed by\npublic ML package repositories, which bundle up pre-trained models into\npackages for publication. Since such repositories are a recent phenomenon,\nthere is no empirical data on their current state and challenges. Hence, this\npaper conducts an exploratory study that analyzes the structure and contents of\ntwo popular ML package repositories, TFHub and PyTorch Hub, comparing their\ninformation elements (features and policies), package organization, package\nmanager functionalities and usage contexts against popular software package\nrepositories (npm, PyPI, and CRAN). Through these studies, we have identified\nunique SE practices and challenges for sharing ML packages. These findings and\nimplications would be useful for data scientists, researchers and software\ndevelopers who intend to use these shared ML packages.\n", "versions": [{"version": "v1", "created": "Wed, 2 Dec 2020 18:52:56 GMT"}, {"version": "v2", "created": "Tue, 8 Dec 2020 16:02:00 GMT"}], "update_date": "2020-12-09", "authors_parsed": [["Xiu", "Minke", "", "Jack"], ["Eghan", "Ellis E.", "", "Jack"], ["Ming", "Zhen", "", "Jack"], ["Jiang", "", ""], ["Adams", "Bram", ""]]}, {"id": "2012.01410", "submitter": "Daniele Francesco Santamaria", "authors": "Domenico Cantone, Carmelo Fabio Longo, Marianna Nicolosi-Asmundo,\n  Daniele Francesco Santamaria, Corrado Santoro", "title": "Ontological Smart Contracts in OASIS: Ontology for Agents, Systems, and\n  Integration of Services", "comments": "This work has been accepted for publication at The 14th International\n  Symposium on Intelligent Distributed Computing, 21--23 September 2020,\n  Scilla, Reggio Calabria, Italy. Proceedings and conference have been\n  postponed to September 2021. Paper accepted on 8 September 2020", "journal-ref": "The 14th International Symposium on Intelligent Distributed\n  Computing, 21--23 September 2020, Scilla, Reggio Calabria, Italy", "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this contribution we extend an ontology for modelling agents and their\ninteractions, called Ontology for Agents, Systems, and Integration of Services\n(in short, OASIS), with conditionals and ontological smart contracts (in short,\nOSCs). OSCs are ontological representations of smart contracts that allow to\nestablish responsibilities and authorizations among agents and set agreements,\nwhereas conditionals allow one to restrict and limit agent interactions, define\nactivation mechanisms that trigger agent actions, and define constraints and\ncontract terms on OSCs. Conditionals and OSCs, as defined in OASIS, are applied\nto extend with ontological capabilities digital public ledgers such as the\nblockchain and smart contracts implemented on it. We will also sketch the\narchitecture of a framework based on the OASIS definition of OSCs that exploits\nthe Ethereum platform and the Interplanetary File System.\n", "versions": [{"version": "v1", "created": "Wed, 2 Dec 2020 18:58:26 GMT"}], "update_date": "2020-12-03", "authors_parsed": [["Cantone", "Domenico", ""], ["Longo", "Carmelo Fabio", ""], ["Nicolosi-Asmundo", "Marianna", ""], ["Santamaria", "Daniele Francesco", ""], ["Santoro", "Corrado", ""]]}, {"id": "2012.01414", "submitter": "Revanth Reddy", "authors": "Revanth Gangi Reddy, Bhavani Iyer, Md Arafat Sultan, Rong Zhang, Avi\n  Sil, Vittorio Castelli, Radu Florian, Salim Roukos", "title": "End-to-End QA on COVID-19: Domain Adaptation with Synthetic Training", "comments": "Preprint", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  End-to-end question answering (QA) requires both information retrieval (IR)\nover a large document collection and machine reading comprehension (MRC) on the\nretrieved passages. Recent work has successfully trained neural IR systems\nusing only supervised question answering (QA) examples from open-domain\ndatasets. However, despite impressive performance on Wikipedia, neural IR lags\nbehind traditional term matching approaches such as BM25 in more specific and\nspecialized target domains such as COVID-19. Furthermore, given little or no\nlabeled data, effective adaptation of QA systems can also be challenging in\nsuch target domains. In this work, we explore the application of synthetically\ngenerated QA examples to improve performance on closed-domain retrieval and\nMRC. We combine our neural IR and MRC systems and show significant improvements\nin end-to-end QA on the CORD-19 collection over a state-of-the-art open-domain\nQA baseline.\n", "versions": [{"version": "v1", "created": "Wed, 2 Dec 2020 18:59:59 GMT"}], "update_date": "2020-12-03", "authors_parsed": [["Reddy", "Revanth Gangi", ""], ["Iyer", "Bhavani", ""], ["Sultan", "Md Arafat", ""], ["Zhang", "Rong", ""], ["Sil", "Avi", ""], ["Castelli", "Vittorio", ""], ["Florian", "Radu", ""], ["Roukos", "Salim", ""]]}, {"id": "2012.01526", "submitter": "Karttikeya Mangalam", "authors": "Karttikeya Mangalam, Yang An, Harshayu Girase, Jitendra Malik", "title": "From Goals, Waypoints & Paths To Long Term Human Trajectory Forecasting", "comments": "14 pages, 7 figures (including 2 GIFs)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.RO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Human trajectory forecasting is an inherently multi-modal problem.\nUncertainty in future trajectories stems from two sources: (a) sources that are\nknown to the agent but unknown to the model, such as long term goals and\n(b)sources that are unknown to both the agent & the model, such as intent of\nother agents & irreducible randomness indecisions. We propose to factorize this\nuncertainty into its epistemic & aleatoric sources. We model the epistemic\nun-certainty through multimodality in long term goals and the aleatoric\nuncertainty through multimodality in waypoints& paths. To exemplify this\ndichotomy, we also propose a novel long term trajectory forecasting setting,\nwith prediction horizons upto a minute, an order of magnitude longer than prior\nworks. Finally, we presentY-net, a scene com-pliant trajectory forecasting\nnetwork that exploits the pro-posed epistemic & aleatoric structure for diverse\ntrajectory predictions across long prediction horizons.Y-net significantly\nimproves previous state-of-the-art performance on both (a) The well studied\nshort prediction horizon settings on the Stanford Drone & ETH/UCY datasets and\n(b) The proposed long prediction horizon setting on the re-purposed Stanford\nDrone & Intersection Drone datasets.\n", "versions": [{"version": "v1", "created": "Wed, 2 Dec 2020 21:01:29 GMT"}], "update_date": "2020-12-04", "authors_parsed": [["Mangalam", "Karttikeya", ""], ["An", "Yang", ""], ["Girase", "Harshayu", ""], ["Malik", "Jitendra", ""]]}, {"id": "2012.01545", "submitter": "Ying-Cheng Lai", "authors": "Ling-Wei Kong, Hua-Wei Fan, Celso Grebogi, Ying-Cheng Lai", "title": "Machine learning prediction of critical transition and system collapse", "comments": "5 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI math.DS physics.data-an", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To predict a critical transition due to parameter drift without relying on\nmodel is an outstanding problem in nonlinear dynamics and applied fields. A\nclosely related problem is to predict whether the system is already in or if\nthe system will be in a transient state preceding its collapse. We develop a\nmodel free, machine learning based solution to both problems by exploiting\nreservoir computing to incorporate a parameter input channel. We demonstrate\nthat, when the machine is trained in the normal functioning regime with a\nchaotic attractor (i.e., before the critical transition), the transition point\ncan be predicted accurately. Remarkably, for a parameter drift through the\ncritical point, the machine with the input parameter channel is able to predict\nnot only that the system will be in a transient state, but also the average\ntransient time before the final collapse.\n", "versions": [{"version": "v1", "created": "Wed, 2 Dec 2020 21:38:54 GMT"}], "update_date": "2020-12-04", "authors_parsed": [["Kong", "Ling-Wei", ""], ["Fan", "Hua-Wei", ""], ["Grebogi", "Celso", ""], ["Lai", "Ying-Cheng", ""]]}, {"id": "2012.01569", "submitter": "Uwe Aickelin", "authors": "Hadi A. Khorshidi and Uwe Aickelin", "title": "Multicriteria Group Decision-Making Under Uncertainty Using Interval\n  Data and Cloud Models", "comments": "Journal of the Operational Research Society, 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this study, we propose a multicriteria group decision making (MCGDM)\nalgorithm under uncertainty where data is collected as intervals. The proposed\nMCGDM algorithm aggregates the data, determines the optimal weights for\ncriteria and ranks alternatives with no further input. The intervals give\nflexibility to experts in assessing alternatives against criteria and provide\nan opportunity to gain maximum information. We also propose a novel method to\naggregate expert judgements using cloud models. We introduce an experimental\napproach to check the validity of the aggregation method. After that, we use\nthe aggregation method for an MCGDM problem. Here, we find the optimal weights\nfor each criterion by proposing a bilevel optimisation model. Then, we extend\nthe technique for order of preference by similarity to ideal solution (TOPSIS)\nfor data based on cloud models to prioritise alternatives. As a result, the\nalgorithm can gain information from decision makers with different levels of\nuncertainty and examine alternatives with no more information from\ndecision-makers. The proposed MCGDM algorithm is implemented on a case study of\na cybersecurity problem to illustrate its feasibility and effectiveness. The\nresults verify the robustness and validity of the proposed MCGDM using\nsensitivity analysis and comparison with other existing algorithms.\n", "versions": [{"version": "v1", "created": "Tue, 1 Dec 2020 06:34:48 GMT"}], "update_date": "2020-12-04", "authors_parsed": [["Khorshidi", "Hadi A.", ""], ["Aickelin", "Uwe", ""]]}, {"id": "2012.01603", "submitter": "Maur\\'icio Gruppi", "authors": "Maur\\'icio Gruppi, Sibel Adali and Pin-Yu Chen", "title": "SChME at SemEval-2020 Task 1: A Model Ensemble for Detecting Lexical\n  Semantic Change", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes SChME (Semantic Change Detection with Model Ensemble), a\nmethod usedin SemEval-2020 Task 1 on unsupervised detection of lexical semantic\nchange. SChME usesa model ensemble combining signals of distributional models\n(word embeddings) and wordfrequency models where each model casts a vote\nindicating the probability that a word sufferedsemantic change according to\nthat feature. More specifically, we combine cosine distance of wordvectors\ncombined with a neighborhood-based metric we named Mapped Neighborhood\nDistance(MAP), and a word frequency differential metric as input signals to our\nmodel. Additionally,we explore alignment-based methods to investigate the\nimportance of the landmarks used in thisprocess. Our results show evidence that\nthe number of landmarks used for alignment has a directimpact on the predictive\nperformance of the model. Moreover, we show that languages that sufferless\nsemantic change tend to benefit from using a large number of landmarks, whereas\nlanguageswith more semantic change benefit from a more careful choice of\nlandmark number for alignment.\n", "versions": [{"version": "v1", "created": "Wed, 2 Dec 2020 23:56:34 GMT"}], "update_date": "2020-12-04", "authors_parsed": [["Gruppi", "Maur\u00edcio", ""], ["Adali", "Sibel", ""], ["Chen", "Pin-Yu", ""]]}, {"id": "2012.01604", "submitter": "Vinu Joseph", "authors": "Vinu Joseph, Shoaib Ahmed Siddiqui, Aditya Bhaskara, Ganesh\n  Gopalakrishnan, Saurav Muralidharan, Michael Garland, Sheraz Ahmed, Andreas\n  Dengel", "title": "Going Beyond Classification Accuracy Metrics in Model Compression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the rise in edge-computing devices, there has been an increasing demand\nto deploy energy and resource-efficient models. A large body of research has\nbeen devoted to developing methods that can reduce the size of the model\nconsiderably without affecting the standard metrics such as top-1 accuracy.\nHowever, these pruning approaches tend to result in a significant mismatch in\nother metrics such as fairness across classes and explainability. To combat\nsuch misalignment, we propose a novel multi-part loss function inspired by the\nknowledge-distillation literature. Through extensive experiments, we\ndemonstrate the effectiveness of our approach across different compression\nalgorithms, architectures, tasks as well as datasets. In particular, we obtain\nup to $4.1\\times$ reduction in the number of prediction mismatches between the\ncompressed and reference models, and up to $5.7\\times$ in cases where the\nreference model makes the correct prediction; all while making no changes to\nthe compression algorithm, and minor modifications to the loss function.\nFurthermore, we demonstrate how inducing simple alignment between the\npredictions of the models naturally improves the alignment on other metrics\nincluding fairness and attributions. Our framework can thus serve as a simple\nplug-and-play component for compression algorithms in the future.\n", "versions": [{"version": "v1", "created": "Thu, 3 Dec 2020 00:00:41 GMT"}, {"version": "v2", "created": "Mon, 14 Jun 2021 20:10:09 GMT"}], "update_date": "2021-06-16", "authors_parsed": [["Joseph", "Vinu", ""], ["Siddiqui", "Shoaib Ahmed", ""], ["Bhaskara", "Aditya", ""], ["Gopalakrishnan", "Ganesh", ""], ["Muralidharan", "Saurav", ""], ["Garland", "Michael", ""], ["Ahmed", "Sheraz", ""], ["Dengel", "Andreas", ""]]}, {"id": "2012.01606", "submitter": "Yuhong Guo", "authors": "Zhenpeng Li, Jianan Jiang, Yuhong Guo, Tiantian Tang, Chengxiang Zhuo,\n  Jieping Ye", "title": "Domain Adaptation with Incomplete Target Domains", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Domain adaptation, as a task of reducing the annotation cost in a target\ndomain by exploiting the existing labeled data in an auxiliary source domain,\nhas received a lot of attention in the research community. However, the\nstandard domain adaptation has assumed perfectly observed data in both domains,\nwhile in real world applications the existence of missing data can be\nprevalent. In this paper, we tackle a more challenging domain adaptation\nscenario where one has an incomplete target domain with partially observed\ndata. We propose an Incomplete Data Imputation based Adversarial Network\n(IDIAN) model to address this new domain adaptation challenge. In the proposed\nmodel, we design a data imputation module to fill the missing feature values\nbased on the partial observations in the target domain, while aligning the two\ndomains via deep adversarial adaption. We conduct experiments on both\ncross-domain benchmark tasks and a real world adaptation task with imperfect\ntarget domains. The experimental results demonstrate the effectiveness of the\nproposed method.\n", "versions": [{"version": "v1", "created": "Thu, 3 Dec 2020 00:07:40 GMT"}], "update_date": "2020-12-04", "authors_parsed": [["Li", "Zhenpeng", ""], ["Jiang", "Jianan", ""], ["Guo", "Yuhong", ""], ["Tang", "Tiantian", ""], ["Zhuo", "Chengxiang", ""], ["Ye", "Jieping", ""]]}, {"id": "2012.01608", "submitter": "Kyle Hatch", "authors": "Kyle Hatch, John Mern, Mykel Kochenderfer", "title": "Obstacle Avoidance Using a Monocular Camera", "comments": "AIAA SciTech Forum 2021 pre-print", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  A collision avoidance system based on simple digital cameras would help\nenable the safe integration of small UAVs into crowded, low-altitude\nenvironments. In this work, we present an obstacle avoidance system for small\nUAVs that uses a monocular camera with a hybrid neural network and path planner\ncontroller. The system is comprised of a vision network for estimating depth\nfrom camera images, a high-level control network, a collision prediction\nnetwork, and a contingency policy. This system is evaluated on a simulated UAV\nnavigating an obstacle course in a constrained flight pattern. Results show the\nproposed system achieves low collision rates while maintaining operationally\nrelevant flight speeds.\n", "versions": [{"version": "v1", "created": "Thu, 3 Dec 2020 00:12:10 GMT"}, {"version": "v2", "created": "Mon, 25 Jan 2021 23:43:13 GMT"}], "update_date": "2021-01-27", "authors_parsed": [["Hatch", "Kyle", ""], ["Mern", "John", ""], ["Kochenderfer", "Mykel", ""]]}, {"id": "2012.01614", "submitter": "Chakkrit Tantithamthavorn", "authors": "Chakkrit Tantithamthavorn, Jirayus Jiarpakdee, John Grundy", "title": "Explainable AI for Software Engineering", "comments": "Under Review at IEEE Computer Magazine", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.AI cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Artificial Intelligence/Machine Learning techniques have been widely used in\nsoftware engineering to improve developer productivity, the quality of software\nsystems, and decision-making. However, such AI/ML models for software\nengineering are still impractical, not explainable, and not actionable. These\nconcerns often hinder the adoption of AI/ML models in software engineering\npractices. In this article, we first highlight the need for explainable AI in\nsoftware engineering. Then, we summarize three successful case studies on how\nexplainable AI techniques can be used to address the aforementioned challenges\nby making software defect prediction models more practical, explainable, and\nactionable.\n", "versions": [{"version": "v1", "created": "Thu, 3 Dec 2020 00:42:29 GMT"}], "update_date": "2020-12-04", "authors_parsed": [["Tantithamthavorn", "Chakkrit", ""], ["Jiarpakdee", "Jirayus", ""], ["Grundy", "John", ""]]}, {"id": "2012.01631", "submitter": "Wei Zhang", "authors": "Wei Zhang and Murray Campbell and Yang Yu and Sadhana Kumaravel", "title": "Circles are like Ellipses, or Ellipses are like Circles? Measuring the\n  Degree of Asymmetry of Static and Contextual Embeddings and the Implications\n  to Representation Learning", "comments": "Accepted to AAAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Human judgments of word similarity have been a popular method of evaluating\nthe quality of word embedding. But it fails to measure the geometry properties\nsuch as asymmetry. For example, it is more natural to say \"Ellipses are like\nCircles\" than \"Circles are like Ellipses\". Such asymmetry has been observed\nfrom a psychoanalysis test called word evocation experiment, where one word is\nused to recall another. Although useful, such experimental data have been\nsignificantly understudied for measuring embedding quality. In this paper, we\nuse three well-known evocation datasets to gain insights into asymmetry\nencoding of embedding. We study both static embedding as well as contextual\nembedding, such as BERT. Evaluating asymmetry for BERT is generally hard due to\nthe dynamic nature of embedding. Thus, we probe BERT's conditional\nprobabilities (as a language model) using a large number of Wikipedia contexts\nto derive a theoretically justifiable Bayesian asymmetry score. The result\nshows that contextual embedding shows randomness than static embedding on\nsimilarity judgments while performing well on asymmetry judgment, which aligns\nwith its strong performance on \"extrinsic evaluations\" such as text\nclassification. The asymmetry judgment and the Bayesian approach provides a new\nperspective to evaluate contextual embedding on intrinsic evaluation, and its\ncomparison to similarity evaluation concludes our work with a discussion on the\ncurrent state and the future of representation learning.\n", "versions": [{"version": "v1", "created": "Thu, 3 Dec 2020 01:48:37 GMT"}], "update_date": "2020-12-04", "authors_parsed": [["Zhang", "Wei", ""], ["Campbell", "Murray", ""], ["Yu", "Yang", ""], ["Kumaravel", "Sadhana", ""]]}, {"id": "2012.01661", "submitter": "EPTCS", "authors": "Russ Harmer (Univ Lyon, EnsL, UCBL, CNRS, LIP, France), Eugenia\n  Oshurko (Univ Lyon, EnsL, UCBL, CNRS, LIP, France)", "title": "Reversibility and Composition of Rewriting in Hierarchies", "comments": "In Proceedings GCM 2020, arXiv:2012.01181", "journal-ref": "EPTCS 330, 2020, pp. 145-162", "doi": "10.4204/EPTCS.330.9", "report-no": null, "categories": "cs.LO cs.AI cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study how graph transformations based on sesqui-pushout\nrewriting can be reversed and how the composition of rewrites can be\nconstructed. We illustrate how such reversibility and composition can be used\nto design an audit trail system for individual graphs and graph hierarchies.\nThis provides us with a compact way to maintain the history of updates of an\nobject, including its multiple versions. The main application of the designed\nframework is an audit trail of updates to knowledge represented by hierarchies\nof graphs. Therefore, we introduce the notion of rule hierarchy that represents\na transformation of the entire hierarchy, study how rule hierarchies can be\napplied to hierarchies and analyse the conditions under which this application\nis reversible. We then present a theory for constructing the composition of\nconsecutive hierarchy rewrites. The prototype audit trail system for\ntransformations in hierarchies of simple graphs with attributes is implemented\nas part of the ReGraph Python library.\n", "versions": [{"version": "v1", "created": "Thu, 3 Dec 2020 02:29:28 GMT"}], "update_date": "2020-12-04", "authors_parsed": [["Harmer", "Russ", "", "Univ Lyon, EnsL, UCBL, CNRS, LIP, France"], ["Oshurko", "Eugenia", "", "Univ Lyon, EnsL, UCBL, CNRS, LIP, France"]]}, {"id": "2012.01684", "submitter": "Zhen Zeng", "authors": "Zhen Zeng, Jianzong Wang, Ning Cheng, Jing Xiao", "title": "MelGlow: Efficient Waveform Generative Network Based on\n  Location-Variable Convolution", "comments": "will be presented in SLT 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.AI eess.AS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recent neural vocoders usually use a WaveNet-like network to capture the\nlong-term dependencies of the waveform, but a large number of parameters are\nrequired to obtain good modeling capabilities. In this paper, an efficient\nnetwork, named location-variable convolution, is proposed to model the\ndependencies of waveforms. Different from the use of unified convolution\nkernels in WaveNet to capture the dependencies of arbitrary waveforms,\nlocation-variable convolutions utilizes a kernel predictor to generate multiple\nsets of convolution kernels based on the mel-spectrum, where each set of\nconvolution kernels is used to perform convolution operations on the associated\nwaveform intervals. Combining WaveGlow and location-variable convolutions, an\nefficient vocoder, named MelGlow, is designed. Experiments on the LJSpeech\ndataset show that MelGlow achieves better performance than WaveGlow at small\nmodel sizes, which verifies the effectiveness and potential optimization space\nof location-variable convolutions.\n", "versions": [{"version": "v1", "created": "Thu, 3 Dec 2020 03:43:22 GMT"}], "update_date": "2020-12-04", "authors_parsed": [["Zeng", "Zhen", ""], ["Wang", "Jianzong", ""], ["Cheng", "Ning", ""], ["Xiao", "Jing", ""]]}, {"id": "2012.01687", "submitter": "Guangsen Wang", "authors": "Genta Indra Winata, Guangsen Wang, Caiming Xiong, Steven Hoi", "title": "Adapt-and-Adjust: Overcoming the Long-Tail Problem of Multilingual\n  Speech Recognition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One crucial challenge of real-world multilingual speech recognition is the\nlong-tailed distribution problem, where some resource-rich languages like\nEnglish have abundant training data, but a long tail of low-resource languages\nhave varying amounts of limited training data. To overcome the long-tail\nproblem, in this paper, we propose Adapt-and-Adjust (A2), a transformer-based\nmulti-task learning framework for end-to-end multilingual speech recognition.\nThe A2 framework overcomes the long-tail problem via three techniques: (1)\nexploiting a pretrained multilingual language model (mBERT) to improve the\nperformance of low-resource languages; (2) proposing dual adapters consisting\nof both language-specific and language-agnostic adaptation with minimal\nadditional parameters; and (3) overcoming the class imbalance, either by\nimposing class priors in the loss during training or adjusting the logits of\nthe softmax output during inference. Extensive experiments on the CommonVoice\ncorpus show that A2 significantly outperforms conventional approaches.\n", "versions": [{"version": "v1", "created": "Thu, 3 Dec 2020 03:46:16 GMT"}], "update_date": "2020-12-04", "authors_parsed": [["Winata", "Genta Indra", ""], ["Wang", "Guangsen", ""], ["Xiong", "Caiming", ""], ["Hoi", "Steven", ""]]}, {"id": "2012.01690", "submitter": "Heming Yao", "authors": "Heming Yao, Ryan W. Stidham, Zijun Gao, Jonathan Gryak, Kayvan\n  Najarian", "title": "Motion-based Camera Localization System in Colonoscopy Videos", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Optical colonoscopy is an essential diagnostic and prognostic tool for many\ngastrointestinal diseases, including cancer screening and staging, intestinal\nbleeding, diarrhea, abdominal symptom evaluation, and inflammatory bowel\ndisease assessment. Automated assessment of colonoscopy is of interest\nconsidering the subjectivity present in qualitative human interpretations of\ncolonoscopy findings. Localization of the camera is essential to interpreting\nthe meaning and context of findings for diseases evaluated by colonoscopy. In\nthis study, we propose a camera localization system to estimate the relative\nlocation of the camera and classify the colon into anatomical segments. The\ncamera localization system begins with non-informative frame detection and\nremoval. Then a self-training end-to-end convolutional neural network is built\nto estimate the camera motion, where several strategies are proposed to improve\nits robustness and generalization on endoscopic videos. Using the estimated\ncamera motion a camera trajectory can be derived and a relative location index\ncalculated. Based on the estimated location index, anatomical colon segment\nclassification is performed by constructing a colon template. The proposed\nmotion estimation algorithm was evaluated on an external dataset containing the\nground truth for camera pose. The experimental results show that the\nperformance of the proposed method is superior to other published methods. The\nrelative location index estimation and anatomical region classification were\nfurther validated using colonoscopy videos collected from routine clinical\npractice. This validation yielded an average accuracy in classification of\n0.754, which is substantially higher than the performances obtained using\nlocation indices built from other methods.\n", "versions": [{"version": "v1", "created": "Thu, 3 Dec 2020 03:57:12 GMT"}, {"version": "v2", "created": "Fri, 4 Dec 2020 02:59:32 GMT"}, {"version": "v3", "created": "Thu, 11 Feb 2021 20:09:22 GMT"}], "update_date": "2021-02-15", "authors_parsed": [["Yao", "Heming", ""], ["Stidham", "Ryan W.", ""], ["Gao", "Zijun", ""], ["Gryak", "Jonathan", ""], ["Najarian", "Kayvan", ""]]}, {"id": "2012.01696", "submitter": "Yuji Roh", "authors": "Yuji Roh, Kangwook Lee, Steven Euijong Whang, Changho Suh", "title": "FairBatch: Batch Selection for Model Fairness", "comments": "In Proceedings of the 9th International Conference on Learning\n  Representations (ICLR), 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Training a fair machine learning model is essential to prevent demographic\ndisparity. Existing techniques for improving model fairness require broad\nchanges in either data preprocessing or model training, rendering themselves\ndifficult-to-adopt for potentially already complex machine learning systems. We\naddress this problem via the lens of bilevel optimization. While keeping the\nstandard training algorithm as an inner optimizer, we incorporate an outer\noptimizer so as to equip the inner problem with an additional functionality:\nAdaptively selecting minibatch sizes for the purpose of improving model\nfairness. Our batch selection algorithm, which we call FairBatch, implements\nthis optimization and supports prominent fairness measures: equal opportunity,\nequalized odds, and demographic parity. FairBatch comes with a significant\nimplementation benefit -- it does not require any modification to data\npreprocessing or model training. For instance, a single-line change of PyTorch\ncode for replacing batch selection part of model training suffices to employ\nFairBatch. Our experiments conducted both on synthetic and benchmark real data\ndemonstrate that FairBatch can provide such functionalities while achieving\ncomparable (or even greater) performances against the state of the arts.\nFurthermore, FairBatch can readily improve fairness of any pre-trained model\nsimply via fine-tuning. It is also compatible with existing batch selection\ntechniques intended for different purposes, such as faster convergence, thus\ngracefully achieving multiple purposes.\n", "versions": [{"version": "v1", "created": "Thu, 3 Dec 2020 04:36:04 GMT"}, {"version": "v2", "created": "Wed, 2 Jun 2021 14:55:19 GMT"}], "update_date": "2021-06-03", "authors_parsed": [["Roh", "Yuji", ""], ["Lee", "Kangwook", ""], ["Whang", "Steven Euijong", ""], ["Suh", "Changho", ""]]}, {"id": "2012.01707", "submitter": "Pavan Kapanipathi", "authors": "Pavan Kapanipathi, Ibrahim Abdelaziz, Srinivas Ravishankar, Salim\n  Roukos, Alexander Gray, Ramon Astudillo, Maria Chang, Cristina Cornelio,\n  Saswati Dana, Achille Fokoue, Dinesh Garg, Alfio Gliozzo, Sairam Gurajada,\n  Hima Karanam, Naweed Khan, Dinesh Khandelwal, Young-Suk Lee, Yunyao Li,\n  Francois Luus, Ndivhuwo Makondo, Nandana Mihindukulasooriya, Tahira Naseem,\n  Sumit Neelam, Lucian Popa, Revanth Reddy, Ryan Riegel, Gaetano Rossiello,\n  Udit Sharma, G P Shrivatsa Bhargav, Mo Yu", "title": "Leveraging Abstract Meaning Representation for Knowledge Base Question\n  Answering", "comments": "Accepted to Findings of ACL", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge base question answering (KBQA)is an important task in Natural\nLanguage Processing. Existing approaches face significant challenges including\ncomplex question understanding, necessity for reasoning, and lack of large\nend-to-end training datasets. In this work, we propose Neuro-Symbolic Question\nAnswering (NSQA), a modular KBQA system, that leverages (1) Abstract Meaning\nRepresentation (AMR) parses for task-independent question understanding; (2) a\nsimple yet effective graph transformation approach to convert AMR parses into\ncandidate logical queries that are aligned to the KB; (3) a pipeline-based\napproach which integrates multiple, reusable modules that are trained\nspecifically for their individual tasks (semantic parser, entity\nandrelationship linkers, and neuro-symbolic reasoner) and do not require\nend-to-end training data. NSQA achieves state-of-the-art performance on two\nprominent KBQA datasets based on DBpedia (QALD-9 and LC-QuAD1.0). Furthermore,\nour analysis emphasizes that AMR is a powerful tool for KBQA systems.\n", "versions": [{"version": "v1", "created": "Thu, 3 Dec 2020 05:17:55 GMT"}, {"version": "v2", "created": "Wed, 2 Jun 2021 16:04:04 GMT"}], "update_date": "2021-06-03", "authors_parsed": [["Kapanipathi", "Pavan", ""], ["Abdelaziz", "Ibrahim", ""], ["Ravishankar", "Srinivas", ""], ["Roukos", "Salim", ""], ["Gray", "Alexander", ""], ["Astudillo", "Ramon", ""], ["Chang", "Maria", ""], ["Cornelio", "Cristina", ""], ["Dana", "Saswati", ""], ["Fokoue", "Achille", ""], ["Garg", "Dinesh", ""], ["Gliozzo", "Alfio", ""], ["Gurajada", "Sairam", ""], ["Karanam", "Hima", ""], ["Khan", "Naweed", ""], ["Khandelwal", "Dinesh", ""], ["Lee", "Young-Suk", ""], ["Li", "Yunyao", ""], ["Luus", "Francois", ""], ["Makondo", "Ndivhuwo", ""], ["Mihindukulasooriya", "Nandana", ""], ["Naseem", "Tahira", ""], ["Neelam", "Sumit", ""], ["Popa", "Lucian", ""], ["Reddy", "Revanth", ""], ["Riegel", "Ryan", ""], ["Rossiello", "Gaetano", ""], ["Sharma", "Udit", ""], ["Bhargav", "G P Shrivatsa", ""], ["Yu", "Mo", ""]]}, {"id": "2012.01743", "submitter": "Kumar Ashutosh", "authors": "Kumar Ashutosh, Saurabh Kumar, Subhasis Chaudhuri", "title": "3D-NVS: A 3D Supervision Approach for Next View Selection", "comments": "Submitted to CVPR-21", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a classification based approach for the next best view selection\nand show how we can plausibly obtain a supervisory signal for this task. The\nproposed approach is end-to-end trainable and aims to get the best possible 3D\nreconstruction quality with a pair of passively acquired 2D views. The proposed\nmodel consists of two stages: a classifier and a reconstructor network trained\njointly via the indirect 3D supervision from ground truth voxels. While\ntesting, the proposed method assumes no prior knowledge of the underlying 3D\nshape for selecting the next best view. We demonstrate the proposed method's\neffectiveness via detailed experiments on synthetic and real images and show\nhow it provides improved reconstruction quality than the existing state of the\nart 3D reconstruction and the next best view prediction techniques.\n", "versions": [{"version": "v1", "created": "Thu, 3 Dec 2020 07:50:16 GMT"}], "update_date": "2020-12-04", "authors_parsed": [["Ashutosh", "Kumar", ""], ["Kumar", "Saurabh", ""], ["Chaudhuri", "Subhasis", ""]]}, {"id": "2012.01747", "submitter": "Prithwiraj Bhattacharjee", "authors": "Prithwiraj Bhattacharjee, Avi Mallick, Md Saiful Islam,\n  Marium-E-Jannat", "title": "Bengali Abstractive News Summarization(BANS): A Neural Attention\n  Approach", "comments": "10 Pages, 2 figures, 4 tables, 2nd International Conference on Trends\n  in Computational and Cognitive Engineering(TCCE-2020)", "journal-ref": "2nd International Conference on Trends in Computational and\n  Cognitive Engineering, 2020", "doi": "10.1007/978-981-33-4673-4_4", "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Abstractive summarization is the process of generating novel sentences based\non the information extracted from the original text document while retaining\nthe context. Due to abstractive summarization's underlying complexities, most\nof the past research work has been done on the extractive summarization\napproach. Nevertheless, with the triumph of the sequence-to-sequence (seq2seq)\nmodel, abstractive summarization becomes more viable. Although a significant\nnumber of notable research has been done in the English language based on\nabstractive summarization, only a couple of works have been done on Bengali\nabstractive news summarization (BANS). In this article, we presented a seq2seq\nbased Long Short-Term Memory (LSTM) network model with attention at\nencoder-decoder. Our proposed system deploys a local attention-based model that\nproduces a long sequence of words with lucid and human-like generated sentences\nwith noteworthy information of the original document. We also prepared a\ndataset of more than 19k articles and corresponding human-written summaries\ncollected from bangla.bdnews24.com1 which is till now the most extensive\ndataset for Bengali news document summarization and publicly published in\nKaggle2. We evaluated our model qualitatively and quantitatively and compared\nit with other published results. It showed significant improvement in terms of\nhuman evaluation scores with state-of-the-art approaches for BANS.\n", "versions": [{"version": "v1", "created": "Thu, 3 Dec 2020 08:17:31 GMT"}], "update_date": "2020-12-18", "authors_parsed": [["Bhattacharjee", "Prithwiraj", ""], ["Mallick", "Avi", ""], ["Islam", "Md Saiful", ""], ["Marium-E-Jannat", "", ""]]}, {"id": "2012.01759", "submitter": "Benjamin Goertzel", "authors": "Ben Goertzel", "title": "Folding and Unfolding on Metagraphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Typed metagraphs are defined as hypergraphs with types assigned to hyperedges\nand their targets, and the potential to have targets of hyperedges connect to\nwhole links as well as targets. Directed typed metagraphs (DTMGs) are\nintroduced via partitioning the targets of each edge in a typed metagraph into\ninput, output and lateral sets; one can then look at \"metapaths\" in which\nedges' output-sets are linked to other edges' input-sets. An initial algebra\napproach to DTMGs is presented, including introduction of constructors for\nbuilding up DTMGs and laws regarding relationships among multiple ways of using\nthese constructors. A menagerie of useful morphism types is then defined on\nDTMGs (catamorphisms, anamorphisms, histomorphisms, futumorphisms,\nhylomorphisms, chronomorphisms, metamorphisms and metachronomorphisms),\nproviding a general abstract framework for formulating a broad variety of\nmetagraph operations. Deterministic and stochastic processes on typed\nmetagraphs are represented in terms of forests of DTMGs defined over a common\nTMG, where the various morphisms can be straightforwardly extended to these\nforests. A variation of the approach to undirected typed metagraphs is\npresented; and it is indicated how the framework outlined can applied to\nrealistic metagraphs involving complexities like dependent and probabilistic\ntypes, multidimensional values and dynamic processing including insertion and\ndeletion of edges.\n", "versions": [{"version": "v1", "created": "Thu, 3 Dec 2020 08:47:49 GMT"}, {"version": "v2", "created": "Mon, 7 Dec 2020 18:42:09 GMT"}, {"version": "v3", "created": "Thu, 10 Dec 2020 19:45:55 GMT"}], "update_date": "2020-12-14", "authors_parsed": [["Goertzel", "Ben", ""]]}, {"id": "2012.01775", "submitter": "Xiaodong Gu", "authors": "Xiaodong Gu, Kang Min Yoo, Jung-Woo Ha", "title": "DialogBERT: Discourse-Aware Response Generation via Learning to Recover\n  and Rank Utterances", "comments": "Published as a conference paper at AAAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Recent advances in pre-trained language models have significantly improved\nneural response generation. However, existing methods usually view the dialogue\ncontext as a linear sequence of tokens and learn to generate the next word\nthrough token-level self-attention. Such token-level encoding hinders the\nexploration of discourse-level coherence among utterances. This paper presents\nDialogBERT, a novel conversational response generation model that enhances\nprevious PLM-based dialogue models. DialogBERT employs a hierarchical\nTransformer architecture. To efficiently capture the discourse-level coherence\namong utterances, we propose two training objectives, including masked\nutterance regression and distributed utterance order ranking in analogy to the\noriginal BERT training. Experiments on three multi-turn conversation datasets\nshow that our approach remarkably outperforms the baselines, such as BART and\nDialoGPT, in terms of quantitative evaluation. The human evaluation suggests\nthat DialogBERT generates more coherent, informative, and human-like responses\nthan the baselines with significant margins.\n", "versions": [{"version": "v1", "created": "Thu, 3 Dec 2020 09:06:23 GMT"}], "update_date": "2020-12-04", "authors_parsed": [["Gu", "Xiaodong", ""], ["Yoo", "Kang Min", ""], ["Ha", "Jung-Woo", ""]]}, {"id": "2012.01778", "submitter": "Konstantin Kobs", "authors": "Michael Fischer, Konstantin Kobs, Andreas Hotho", "title": "NICER: Aesthetic Image Enhancement with Humans in the Loop", "comments": "The code can be found at https://github.com/mr-Mojo/NICER", "journal-ref": "ACHI 2020, The Thirteenth International Conference on Advances in\n  Computer-Human Interactions; 2020; pages 357-362", "doi": null, "report-no": null, "categories": "cs.HC cs.AI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fully- or semi-automatic image enhancement software helps users to increase\nthe visual appeal of photos and does not require in-depth knowledge of manual\nimage editing. However, fully-automatic approaches usually enhance the image in\na black-box manner that does not give the user any control over the\noptimization process, possibly leading to edited images that do not\nsubjectively appeal to the user. Semi-automatic methods mostly allow for\ncontrolling which pre-defined editing step is taken, which restricts the users\nin their creativity and ability to make detailed adjustments, such as\nbrightness or contrast. We argue that incorporating user preferences by guiding\nan automated enhancement method simplifies image editing and increases the\nenhancement's focus on the user. This work thus proposes the Neural Image\nCorrection & Enhancement Routine (NICER), a neural network based approach to\nno-reference image enhancement in a fully-, semi-automatic or fully manual\nprocess that is interactive and user-centered. NICER iteratively adjusts image\nediting parameters in order to maximize an aesthetic score based on image style\nand content. Users can modify these parameters at any time and guide the\noptimization process towards a desired direction. This interactive workflow is\na novelty in the field of human-computer interaction for image enhancement\ntasks. In a user study, we show that NICER can improve image aesthetics without\nuser interaction and that allowing user interaction leads to diverse\nenhancement outcomes that are strongly preferred over the unedited image. We\nmake our code publicly available to facilitate further research in this\ndirection.\n", "versions": [{"version": "v1", "created": "Thu, 3 Dec 2020 09:14:10 GMT"}], "update_date": "2020-12-04", "authors_parsed": [["Fischer", "Michael", ""], ["Kobs", "Konstantin", ""], ["Hotho", "Andreas", ""]]}, {"id": "2012.01784", "submitter": "John Cai", "authors": "John Cai, Bill Cai, Sheng Mei Shen", "title": "SB-MTL: Score-based Meta Transfer-Learning for Cross-Domain Few-Shot\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While many deep learning methods have seen significant success in tackling\nthe problem of domain adaptation and few-shot learning separately, far fewer\nmethods are able to jointly tackle both problems in Cross-Domain Few-Shot\nLearning (CD-FSL). This problem is exacerbated under sharp domain shifts that\ntypify common computer vision applications. In this paper, we present a novel,\nflexible and effective method to address the CD-FSL problem. Our method, called\nScore-based Meta Transfer-Learning (SB-MTL), combines transfer-learning and\nmeta-learning by using a MAML-optimized feature encoder and a score-based Graph\nNeural Network. First, we have a feature encoder with specific layers designed\nto be fine-tuned. To do so, we apply a first-order MAML algorithm to find good\ninitializations. Second, instead of directly taking the classification scores\nafter fine-tuning, we interpret the scores as coordinates by mapping the\npre-softmax classification scores onto a metric space. Subsequently, we apply a\nGraph Neural Network to propagate label information from the support set to the\nquery set in our score-based metric space. We test our model on the Broader\nStudy of Cross-Domain Few-Shot Learning (BSCD-FSL) benchmark, which includes a\nrange of target domains with highly varying dissimilarity to the miniImagenet\nsource domain. We observe significant improvements in accuracy across 5, 20 and\n50 shot, and on the four target domains. In terms of average accuracy, our\nmodel outperforms previous transfer-learning methods by 5.93% and previous\nmeta-learning methods by 14.28%.\n", "versions": [{"version": "v1", "created": "Thu, 3 Dec 2020 09:29:35 GMT"}], "update_date": "2020-12-04", "authors_parsed": [["Cai", "John", ""], ["Cai", "Bill", ""], ["Shen", "Sheng Mei", ""]]}, {"id": "2012.01789", "submitter": "Jing Dong", "authors": "Jing Dong, Tan Li, Shaolei Ren, Linqi Song", "title": "Distributed Thompson Sampling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We study a cooperative multi-agent multi-armed bandits with M agents and K\narms. The goal of the agents is to minimized the cumulative regret. We adapt a\ntraditional Thompson Sampling algoirthm under the distributed setting. However,\nwith agent's ability to communicate, we note that communication may further\nreduce the upper bound of the regret for a distributed Thompson Sampling\napproach. To further improve the performance of distributed Thompson Sampling,\nwe propose a distributed Elimination based Thompson Sampling algorithm that\nallow the agents to learn collaboratively. We analyse the algorithm under\nBernoulli reward and derived a problem dependent upper bound on the cumulative\nregret.\n", "versions": [{"version": "v1", "created": "Thu, 3 Dec 2020 09:42:37 GMT"}], "update_date": "2020-12-04", "authors_parsed": [["Dong", "Jing", ""], ["Li", "Tan", ""], ["Ren", "Shaolei", ""], ["Song", "Linqi", ""]]}, {"id": "2012.01793", "submitter": "Kien Do", "authors": "Kien Do, Truyen Tran, Svetha Venkatesh", "title": "Semi-Supervised Learning with Variational Bayesian Inference and Maximum\n  Uncertainty Regularization", "comments": "Accepted to AAAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We propose two generic methods for improving semi-supervised learning (SSL).\nThe first integrates weight perturbation (WP) into existing \"consistency\nregularization\" (CR) based methods. We implement WP by leveraging variational\nBayesian inference (VBI). The second method proposes a novel consistency loss\ncalled \"maximum uncertainty regularization\" (MUR). While most consistency\nlosses act on perturbations in the vicinity of each data point, MUR actively\nsearches for \"virtual\" points situated beyond this region that cause the most\nuncertain class predictions. This allows MUR to impose smoothness on a wider\narea in the input-output manifold. Our experiments show clear improvements in\nclassification errors of various CR based methods when they are combined with\nVBI or MUR or both.\n", "versions": [{"version": "v1", "created": "Thu, 3 Dec 2020 09:49:35 GMT"}, {"version": "v2", "created": "Thu, 18 Mar 2021 22:58:26 GMT"}], "update_date": "2021-03-22", "authors_parsed": [["Do", "Kien", ""], ["Tran", "Truyen", ""], ["Venkatesh", "Svetha", ""]]}, {"id": "2012.01823", "submitter": "Jan Strohschein", "authors": "Jan Strohschein, Andreas Fischbach, Andreas Bunte, Heide\n  Faeskorn-Woyke, Natalia Moriz, Thomas Bartz-Beielstein", "title": "Cognitive Capabilities for the CAAI in Cyber-Physical Production Systems", "comments": null, "journal-ref": null, "doi": "10.1007/s00170-021-07248-3", "report-no": null, "categories": "cs.AI cs.DC cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents the cognitive module of the cognitive architecture for\nartificial intelligence (CAAI) in cyber-physical production systems (CPPS). The\ngoal of this architecture is to reduce the implementation effort of artificial\nintelligence (AI) algorithms in CPPS. Declarative user goals and the provided\nalgorithm-knowledge base allow the dynamic pipeline orchestration and\nconfiguration. A big data platform (BDP) instantiates the pipelines and\nmonitors the CPPS performance for further evaluation through the cognitive\nmodule. Thus, the cognitive module is able to select feasible and robust\nconfigurations for process pipelines in varying use cases. Furthermore, it\nautomatically adapts the models and algorithms based on model quality and\nresource consumption. The cognitive module also instantiates additional\npipelines to test algorithms from different classes. CAAI relies on\nwell-defined interfaces to enable the integration of additional modules and\nreduce implementation effort. Finally, an implementation based on Docker,\nKubernetes, and Kafka for the virtualization and orchestration of the\nindividual modules and as messaging-technology for module communication is used\nto evaluate a real-world use case.\n", "versions": [{"version": "v1", "created": "Thu, 3 Dec 2020 10:55:56 GMT"}], "update_date": "2021-06-09", "authors_parsed": [["Strohschein", "Jan", ""], ["Fischbach", "Andreas", ""], ["Bunte", "Andreas", ""], ["Faeskorn-Woyke", "Heide", ""], ["Moriz", "Natalia", ""], ["Bartz-Beielstein", "Thomas", ""]]}, {"id": "2012.01837", "submitter": "Haohan Guo", "authors": "Haohan Guo, Heng Lu, Na Hu, Chunlei Zhang, Shan Yang, Lei Xie, Dan Su,\n  Dong Yu", "title": "Phonetic Posteriorgrams based Many-to-Many Singing Voice Conversion via\n  Adversarial Training", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.AI cs.MM eess.AS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper describes an end-to-end adversarial singing voice conversion\n(EA-SVC) approach. It can directly generate arbitrary singing waveform by given\nphonetic posteriorgram (PPG) representing content, F0 representing pitch, and\nspeaker embedding representing timbre, respectively. Proposed system is\ncomposed of three modules: generator $G$, the audio generation discriminator\n$D_{A}$, and the feature disentanglement discriminator $D_F$. The generator $G$\nencodes the features in parallel and inversely transforms them into the target\nwaveform. In order to make timbre conversion more stable and controllable,\nspeaker embedding is further decomposed to the weighted sum of a group of\ntrainable vectors representing different timbre clusters. Further, to realize\nmore robust and accurate singing conversion, disentanglement discriminator\n$D_F$ is proposed to remove pitch and timbre related information that remains\nin the encoded PPG. Finally, a two-stage training is conducted to keep a stable\nand effective adversarial training process. Subjective evaluation results\ndemonstrate the effectiveness of our proposed methods. Proposed system\noutperforms conventional cascade approach and the WaveNet based end-to-end\napproach in terms of both singing quality and singer similarity. Further\nobjective analysis reveals that the model trained with the proposed two-stage\ntraining strategy can produce a smoother and sharper formant which leads to\nhigher audio quality.\n", "versions": [{"version": "v1", "created": "Thu, 3 Dec 2020 11:13:27 GMT"}], "update_date": "2020-12-04", "authors_parsed": [["Guo", "Haohan", ""], ["Lu", "Heng", ""], ["Hu", "Na", ""], ["Zhang", "Chunlei", ""], ["Yang", "Shan", ""], ["Xie", "Lei", ""], ["Su", "Dan", ""], ["Yu", "Dong", ""]]}, {"id": "2012.01872", "submitter": "Guoliang Dong", "authors": "Guoliang Dong, Jun Sun, Jingyi Wang, Xinyu Wang, Ting Dai", "title": "Towards Repairing Neural Networks Correctly", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks are increasingly applied to support decision making in\nsafety-critical applications (like autonomous cars, unmanned aerial vehicles\nand face recognition based authentication). While many impressive static\nverification techniques have been proposed to tackle the correctness problem of\nneural networks, it is possible that static verification may never be\nsufficiently scalable to handle real-world neural networks. In this work, we\npropose a runtime verification method to ensure the correctness of neural\nnetworks. Given a neural network and a desirable safety property, we adopt\nstate-of-the-art static verification techniques to identify strategically\nlocations to introduce additional gates which \"correct\" neural network\nbehaviors at runtime. Experiment results show that our approach effectively\ngenerates neural networks which are guaranteed to satisfy the properties,\nwhilst being consistent with the original neural network most of the time.\n", "versions": [{"version": "v1", "created": "Thu, 3 Dec 2020 12:31:07 GMT"}, {"version": "v2", "created": "Thu, 6 May 2021 02:52:49 GMT"}], "update_date": "2021-05-07", "authors_parsed": [["Dong", "Guoliang", ""], ["Sun", "Jun", ""], ["Wang", "Jingyi", ""], ["Wang", "Xinyu", ""], ["Dai", "Ting", ""]]}, {"id": "2012.01873", "submitter": "Kaustubh Dhole", "authors": "Ashish Shrivastava, Kaustubh Dhole, Abhinav Bhatt, Sharvani Raghunath", "title": "Saying No is An Art: Contextualized Fallback Responses for Unanswerable\n  Dialogue Queries", "comments": "ACL-IJCNLP 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Despite end-to-end neural systems making significant progress in the last\ndecade for task-oriented as well as chit-chat based dialogue systems, most\ndialogue systems rely on hybrid approaches which use a combination of\nrule-based, retrieval and generative approaches for generating a set of ranked\nresponses. Such dialogue systems need to rely on a fallback mechanism to\nrespond to out-of-domain or novel user queries which are not answerable within\nthe scope of the dialog system. While, dialog systems today rely on static and\nunnatural responses like \"I don't know the answer to that question\" or \"I'm not\nsure about that\", we design a neural approach which generates responses which\nare contextually aware with the user query as well as say no to the user. Such\ncustomized responses provide paraphrasing ability and contextualization as well\nas improve the interaction with the user and reduce dialogue monotonicity. Our\nsimple approach makes use of rules over dependency parses and a text-to-text\ntransformer fine-tuned on synthetic data of question-response pairs generating\nhighly relevant, grammatical as well as diverse questions. We perform automatic\nand manual evaluations to demonstrate the efficacy of the system.\n", "versions": [{"version": "v1", "created": "Thu, 3 Dec 2020 12:34:22 GMT"}, {"version": "v2", "created": "Thu, 17 Dec 2020 12:08:45 GMT"}, {"version": "v3", "created": "Thu, 6 May 2021 07:40:16 GMT"}], "update_date": "2021-05-07", "authors_parsed": [["Shrivastava", "Ashish", ""], ["Dhole", "Kaustubh", ""], ["Bhatt", "Abhinav", ""], ["Raghunath", "Sharvani", ""]]}, {"id": "2012.01879", "submitter": "Weisen Wang", "authors": "Weisen Wang, Xirong Li, Zhiyan Xu, Weihong Yu, Jianchun Zhao, Dayong\n  Ding, Youxin Chen", "title": "Learning Two-Stream CNN for Multi-Modal Age-related Macular Degeneration\n  Categorization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper tackles automated categorization of Age-related Macular\nDegeneration (AMD), a common macular disease among people over 50. Previous\nresearch efforts mainly focus on AMD categorization with a single-modal input,\nlet it be a color fundus image or an OCT image. By contrast, we consider AMD\ncategorization given a multi-modal input, a direction that is clinically\nmeaningful yet mostly unexplored. Contrary to the prior art that takes a\ntraditional approach of feature extraction plus classifier training that cannot\nbe jointly optimized, we opt for end-to-end multi-modal Convolutional Neural\nNetworks (MM-CNN). Our MM-CNN is instantiated by a two-stream CNN, with\nspatially-invariant fusion to combine information from the fundus and OCT\nstreams. In order to visually interpret the contribution of the individual\nmodalities to the final prediction, we extend the class activation mapping\n(CAM) technique to the multi-modal scenario. For effective training of MM-CNN,\nwe develop two data augmentation methods. One is GAN-based fundus / OCT image\nsynthesis, with our novel use of CAMs as conditional input of a high-resolution\nimage-to-image translation GAN. The other method is Loose Pairing, which pairs\na fundus image and an OCT image on the basis of their classes instead of eye\nidentities. Experiments on a clinical dataset consisting of 1,099 color fundus\nimages and 1,290 OCT images acquired from 1,099 distinct eyes verify the\neffectiveness of the proposed solution for multi-modal AMD categorization.\n", "versions": [{"version": "v1", "created": "Thu, 3 Dec 2020 12:50:36 GMT"}], "update_date": "2020-12-04", "authors_parsed": [["Wang", "Weisen", ""], ["Li", "Xirong", ""], ["Xu", "Zhiyan", ""], ["Yu", "Weihong", ""], ["Zhao", "Jianchun", ""], ["Ding", "Dayong", ""], ["Chen", "Youxin", ""]]}, {"id": "2012.01914", "submitter": "Alessandro Sestini", "authors": "Alessandro Sestini, Alexander Kuhnle and Andrew D. Bagdanov", "title": "DeepCrawl: Deep Reinforcement Learning for Turn-based Strategy Games", "comments": "Presented at AIIDE-19 Workshop on Experimental Artificial\n  Intelligence in Games", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we introduce DeepCrawl, a fully-playable Roguelike prototype\nfor iOS and Android in which all agents are controlled by policy networks\ntrained using Deep Reinforcement Learning (DRL). Our aim is to understand\nwhether recent advances in DRL can be used to develop convincing behavioral\nmodels for non-player characters in videogames. We begin with an analysis of\nrequirements that such an AI system should satisfy in order to be practically\napplicable in video game development, and identify the elements of the DRL\nmodel used in the DeepCrawl prototype. The successes and limitations of\nDeepCrawl are documented through a series of playability tests performed on the\nfinal game. We believe that the techniques we propose offer insight into\ninnovative new avenues for the development of behaviors for non-player\ncharacters in video games, as they offer the potential to overcome critical\nissues with\n", "versions": [{"version": "v1", "created": "Thu, 3 Dec 2020 13:53:29 GMT"}], "update_date": "2020-12-04", "authors_parsed": [["Sestini", "Alessandro", ""], ["Kuhnle", "Alexander", ""], ["Bagdanov", "Andrew D.", ""]]}, {"id": "2012.01915", "submitter": "Xiang Hui Nicholas Lim", "authors": "Nicholas Lim, Bryan Hooi, See-Kiong Ng, Xueou Wang, Yong Liang Goh,\n  Renrong Weng, Rui Tan", "title": "Origin-Aware Next Destination Recommendation with Personalized\n  Preference Attention", "comments": "To appear in the Proceedings of the 14th ACM International Conference\n  on Web Search and Data Mining (WSDM), 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.IR cs.LG cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Next destination recommendation is an important task in the transportation\ndomain of taxi and ride-hailing services, where users are recommended with\npersonalized destinations given their current origin location. However, recent\nrecommendation works do not satisfy this origin-awareness property, and only\nconsider learning from historical destination locations, without origin\ninformation. Thus, the resulting approaches are unable to learn and predict\norigin-aware recommendations based on the user's current location, leading to\nsub-optimal performance and poor real-world practicality. Hence, in this work,\nwe study the origin-aware next destination recommendation task. We propose the\nSpatial-Temporal Origin-Destination Personalized Preference Attention\n(STOD-PPA) encoder-decoder model to learn origin-origin (OO),\ndestination-destination (DD), and origin-destination (OD) relationships by\nfirst encoding both origin and destination sequences with spatial and temporal\nfactors in local and global views, then decoding them through personalized\npreference attention to predict the next destination. Experimental results on\nseven real-world user trajectory taxi datasets show that our model\nsignificantly outperforms baseline and state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Thu, 3 Dec 2020 13:53:36 GMT"}, {"version": "v2", "created": "Tue, 22 Dec 2020 08:01:15 GMT"}, {"version": "v3", "created": "Mon, 11 Jan 2021 10:30:27 GMT"}], "update_date": "2021-01-12", "authors_parsed": [["Lim", "Nicholas", ""], ["Hooi", "Bryan", ""], ["Ng", "See-Kiong", ""], ["Wang", "Xueou", ""], ["Goh", "Yong Liang", ""], ["Weng", "Renrong", ""], ["Tan", "Rui", ""]]}, {"id": "2012.01917", "submitter": "Davide Lanti", "authors": "Diego Calvanese and Avigdor Gal and Davide Lanti and Marco Montali and\n  Alessandro Mosca and Roee Shraga", "title": "Mapping Patterns for Virtual Knowledge Graphs", "comments": "18 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.DB", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Virtual Knowledge Graphs (VKG) constitute one of the most promising paradigms\nfor integrating and accessing legacy data sources. A critical bottleneck in the\nintegration process involves the definition, validation, and maintenance of\nmappings that link data sources to a domain ontology. To support the management\nof mappings throughout their entire lifecycle, we propose a comprehensive\ncatalog of sophisticated mapping patterns that emerge when linking databases to\nontologies. To do so, we build on well-established methodologies and patterns\nstudied in data management, data analysis, and conceptual modeling. These are\nextended and refined through the analysis of concrete VKG benchmarks and\nreal-world use cases, and considering the inherent impedance mismatch between\ndata sources and ontologies. We validate our catalog on the considered VKG\nscenarios, showing that it covers the vast majority of patterns present\ntherein.\n", "versions": [{"version": "v1", "created": "Thu, 3 Dec 2020 13:54:52 GMT"}], "update_date": "2020-12-04", "authors_parsed": [["Calvanese", "Diego", ""], ["Gal", "Avigdor", ""], ["Lanti", "Davide", ""], ["Montali", "Marco", ""], ["Mosca", "Alessandro", ""], ["Shraga", "Roee", ""]]}, {"id": "2012.01925", "submitter": "Tatiana L\\'opez-Guevara", "authors": "Tatiana Lopez-Guevara, Michael Burke, Nicholas K. Taylor, Kartic Subr", "title": "IV-Posterior: Inverse Value Estimation for Interpretable Policy\n  Certificates", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Model-free reinforcement learning (RL) is a powerful tool to learn a broad\nrange of robot skills and policies. However, a lack of policy interpretability\ncan inhibit their successful deployment in downstream applications,\nparticularly when differences in environmental conditions may result in\nunpredictable behaviour or generalisation failures. As a result, there has been\na growing emphasis in machine learning around the inclusion of stronger\ninductive biases in models to improve generalisation. This paper proposes an\nalternative strategy, inverse value estimation for interpretable policy\ncertificates (IV-Posterior), which seeks to identify the inductive biases or\nidealised conditions of operation already held by pre-trained policies, and\nthen use this information to guide their deployment. IV-Posterior uses\nMaskedAutoregressive Flows to fit distributions over the set of conditions or\nenvironmental parameters in which a policy is likely to be effective. This\ndistribution can then be used as a policy certificate in downstream\napplications. We illustrate the use of IV-Posterior across a two environments,\nand show that substantial performance gains can be obtained when policy\nselection incorporates knowledge of the inductive biases that these policies\nhold.\n", "versions": [{"version": "v1", "created": "Mon, 30 Nov 2020 21:45:49 GMT"}], "update_date": "2020-12-04", "authors_parsed": [["Lopez-Guevara", "Tatiana", ""], ["Burke", "Michael", ""], ["Taylor", "Nicholas K.", ""], ["Subr", "Kartic", ""]]}, {"id": "2012.01929", "submitter": "Gersende Fort", "authors": "Gersende Fort (IMT), Eric Moulines (X-DEP-MATHAPP), Hoi-To Wai", "title": "A Stochastic Path-Integrated Differential EstimatoR Expectation\n  Maximization Algorithm", "comments": null, "journal-ref": "Proceedings of the Conference on Neural Information Processing\n  Systems (NeurIPS 2020), 2020", "doi": null, "report-no": null, "categories": "cs.LG cs.AI math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Expectation Maximization (EM) algorithm is of key importance for\ninference in latent variable models including mixture of regressors and\nexperts, missing observations. This paper introduces a novel EM algorithm,\ncalled \\texttt{SPIDER-EM}, for inference from a training set of size $n$, $n\n\\gg 1$. At the core of our algorithm is an estimator of the full conditional\nexpectation in the {\\sf E}-step, adapted from the stochastic path-integrated\ndifferential estimator ({\\tt SPIDER}) technique. We derive finite-time\ncomplexity bounds for smooth non-convex likelihood: we show that for\nconvergence to an $\\epsilon$-approximate stationary point, the complexity\nscales as $K_{\\operatorname{Opt}} (n,\\epsilon )={\\cal O}(\\epsilon^{-1})$ and\n$K_{\\operatorname{CE}}( n,\\epsilon ) = n+ \\sqrt{n} {\\cal O}(\\epsilon^{-1} )$,\nwhere $K_{\\operatorname{Opt}}( n,\\epsilon )$ and $K_{\\operatorname{CE}}(n,\n\\epsilon )$ are respectively the number of {\\sf M}-steps and the number of\nper-sample conditional expectations evaluations. This improves over the\nstate-of-the-art algorithms. Numerical results support our findings.\n", "versions": [{"version": "v1", "created": "Mon, 30 Nov 2020 15:49:31 GMT"}], "update_date": "2020-12-04", "authors_parsed": [["Fort", "Gersende", "", "IMT"], ["Moulines", "Eric", "", "X-DEP-MATHAPP"], ["Wai", "Hoi-To", ""]]}, {"id": "2012.01932", "submitter": "Catarina Bel\\'em", "authors": "Vladimir Balayan, Pedro Saleiro, Catarina Bel\\'em, Ludwig Krippahl and\n  Pedro Bizarro", "title": "Teaching the Machine to Explain Itself using Domain Knowledge", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine Learning (ML) has been increasingly used to aid humans to make better\nand faster decisions. However, non-technical humans-in-the-loop struggle to\ncomprehend the rationale behind model predictions, hindering trust in\nalgorithmic decision-making systems. Considerable research work on AI\nexplainability attempts to win back trust in AI systems by developing\nexplanation methods but there is still no major breakthrough. At the same time,\npopular explanation methods (e.g., LIME, and SHAP) produce explanations that\nare very hard to understand for non-data scientist persona. To address this, we\npresent JOEL, a neural network-based framework to jointly learn a\ndecision-making task and associated explanations that convey domain knowledge.\nJOEL is tailored to human-in-the-loop domain experts that lack deep technical\nML knowledge, providing high-level insights about the model's predictions that\nvery much resemble the experts' own reasoning. Moreover, we collect the domain\nfeedback from a pool of certified experts and use it to ameliorate the model\n(human teaching), hence promoting seamless and better suited explanations.\nLastly, we resort to semantic mappings between legacy expert systems and domain\ntaxonomies to automatically annotate a bootstrap training set, overcoming the\nabsence of concept-based human annotations. We validate JOEL empirically on a\nreal-world fraud detection dataset. We show that JOEL can generalize the\nexplanations from the bootstrap dataset. Furthermore, obtained results indicate\nthat human teaching can further improve the explanations prediction quality by\napproximately $13.57\\%$.\n", "versions": [{"version": "v1", "created": "Fri, 27 Nov 2020 18:46:34 GMT"}], "update_date": "2020-12-04", "authors_parsed": [["Balayan", "Vladimir", ""], ["Saleiro", "Pedro", ""], ["Bel\u00e9m", "Catarina", ""], ["Krippahl", "Ludwig", ""], ["Bizarro", "Pedro", ""]]}, {"id": "2012.01933", "submitter": "Bojing Feng", "authors": "Bojing Feng, Haonan Xu, Wenfang Xue and Bindang Xue", "title": "Every Corporation Owns Its Structure: Corporate Credit Ratings via Graph\n  Neural Networks", "comments": "12 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Credit rating is an analysis of the credit risks associated with a\ncorporation, which reflects the level of the riskiness and reliability in\ninvesting, and plays a vital role in financial risk. There have emerged many\nstudies that implement machine learning and deep learning techniques which are\nbased on vector space to deal with corporate credit rating. Recently,\nconsidering the relations among enterprises such as loan guarantee network,\nsome graph-based models are applied in this field with the advent of graph\nneural networks. But these existing models build networks between corporations\nwithout taking the internal feature interactions into account. In this paper,\nto overcome such problems, we propose a novel model, Corporate Credit Rating\nvia Graph Neural Networks, CCR-GNN for brevity. We firstly construct individual\ngraphs for each corporation based on self-outer product and then use GNN to\nmodel the feature interaction explicitly, which includes both local and global\ninformation. Extensive experiments conducted on the Chinese public-listed\ncorporate rating dataset, prove that CCR-GNN outperforms the state-of-the-art\nmethods consistently.\n", "versions": [{"version": "v1", "created": "Fri, 27 Nov 2020 02:57:14 GMT"}], "update_date": "2020-12-04", "authors_parsed": [["Feng", "Bojing", ""], ["Xu", "Haonan", ""], ["Xue", "Wenfang", ""], ["Xue", "Bindang", ""]]}, {"id": "2012.01934", "submitter": "Zohreh Raziei", "authors": "Zohreh Raziei, Mohsen Moghaddam", "title": "Adaptable Automation with Modular Deep Reinforcement Learning and Policy\n  Transfer", "comments": "32 pages, 13 Figures, Presented at 2020 INFORMS Annual Meeting", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.HC cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in deep Reinforcement Learning (RL) have created\nunprecedented opportunities for intelligent automation, where a machine can\nautonomously learn an optimal policy for performing a given task. However,\ncurrent deep RL algorithms predominantly specialize in a narrow range of tasks,\nare sample inefficient, and lack sufficient stability, which in turn hinder\ntheir industrial adoption. This article tackles this limitation by developing\nand testing a Hyper-Actor Soft Actor-Critic (HASAC) RL framework based on the\nnotions of task modularization and transfer learning. The goal of the proposed\nHASAC is to enhance the adaptability of an agent to new tasks by transferring\nthe learned policies of former tasks to the new task via a \"hyper-actor\". The\nHASAC framework is tested on a new virtual robotic manipulation benchmark,\nMeta-World. Numerical experiments show superior performance by HASAC over\nstate-of-the-art deep RL algorithms in terms of reward value, success rate, and\ntask completion time.\n", "versions": [{"version": "v1", "created": "Fri, 27 Nov 2020 03:09:05 GMT"}], "update_date": "2021-05-27", "authors_parsed": [["Raziei", "Zohreh", ""], ["Moghaddam", "Mohsen", ""]]}, {"id": "2012.01935", "submitter": "Armin Salimi-Badr", "authors": "Armin Salimi-Badr and Mohammad Mehdi Ebadzadeh", "title": "Backpropagation-Free Learning Method for Correlated Fuzzy Neural\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, a novel stepwise learning approach based on estimating desired\npremise parts' outputs by solving a constrained optimization problem is\nproposed. This learning approach does not require backpropagating the output\nerror to learn the premise parts' parameters. Instead, the near best output\nvalues of the rules premise parts are estimated and their parameters are\nchanged to reduce the error between current premise parts' outputs and the\nestimated desired ones. Therefore, the proposed learning method avoids error\nbackpropagation, which lead to vanishing gradient and consequently getting\nstuck in a local optimum. The proposed method does not need any initialization\nmethod. This learning method is utilized to train a new Takagi-Sugeno-Kang\n(TSK) Fuzzy Neural Network with correlated fuzzy rules including many\nparameters in both premise and consequent parts, avoiding getting stuck in a\nlocal optimum due to vanishing gradient. To learn the proposed network\nparameters, first, a constrained optimization problem is introduced and solved\nto estimate the desired values of premise parts' output values. Next, the error\nbetween these values and the current ones is utilized to adapt the premise\nparts' parameters based on the gradient-descent (GD) approach. Afterward, the\nerror between the desired and network's outputs is used to learn consequent\nparts' parameters by the GD method. The proposed paradigm is successfully\napplied to real-world time-series prediction and regression problems. According\nto experimental results, its performance outperforms other methods with a more\nparsimonious structure.\n", "versions": [{"version": "v1", "created": "Wed, 25 Nov 2020 20:56:05 GMT"}], "update_date": "2020-12-04", "authors_parsed": [["Salimi-Badr", "Armin", ""], ["Ebadzadeh", "Mohammad Mehdi", ""]]}, {"id": "2012.01942", "submitter": "Fuqi Song", "authors": "Fuqi Song and \\'Eric de la Clergerie", "title": "Clustering-based Automatic Construction of Legal Entity Knowledge Base\n  from Contracts", "comments": "4 pages, 3 figures", "journal-ref": null, "doi": "10.1109/BigData50022.2020.9378166", "report-no": null, "categories": "cs.CL cs.AI cs.DS cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  In contract analysis and contract automation, a knowledge base (KB) of legal\nentities is fundamental for performing tasks such as contract verification,\ncontract generation and contract analytic. However, such a KB does not always\nexist nor can be produced in a short time. In this paper, we propose a\nclustering-based approach to automatically generate a reliable knowledge base\nof legal entities from given contracts without any supplemental references. The\nproposed method is robust to different types of errors brought by\npre-processing such as Optical Character Recognition (OCR) and Named Entity\nRecognition (NER), as well as editing errors such as typos. We evaluate our\nmethod on a dataset that consists of 800 real contracts with various qualities\nfrom 15 clients. Compared to the collected ground-truth data, our method is\nable to recall 84\\% of the knowledge.\n", "versions": [{"version": "v1", "created": "Wed, 18 Nov 2020 17:51:27 GMT"}, {"version": "v2", "created": "Mon, 7 Dec 2020 09:49:26 GMT"}], "update_date": "2021-03-30", "authors_parsed": [["Song", "Fuqi", ""], ["de la Clergerie", "\u00c9ric", ""]]}, {"id": "2012.01944", "submitter": "Miko{\\l}aj Ma{\\l}ki\\'nski", "authors": "Miko{\\l}aj Ma{\\l}ki\\'nski, Jacek Ma\\'ndziuk", "title": "Multi-Label Contrastive Learning for Abstract Visual Reasoning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For a long time the ability to solve abstract reasoning tasks was considered\none of the hallmarks of human intelligence. Recent advances in application of\ndeep learning (DL) methods led, as in many other domains, to surpassing human\nabstract reasoning performance, specifically in the most popular type of such\nproblems - the Raven's Progressive Matrices (RPMs). While the efficacy of DL\nsystems is indeed impressive, the way they approach the RPMs is very different\nfrom that of humans. State-of-the-art systems solving RPMs rely on massive\npattern-based training and sometimes on exploiting biases in the dataset,\nwhereas humans concentrate on identification of the rules / concepts underlying\nthe RPM (or generally a visual reasoning task) to be solved. Motivated by this\ncognitive difference, this work aims at combining DL with human way of solving\nRPMs and getting the best of both worlds. Specifically, we cast the problem of\nsolving RPMs into multi-label classification framework where each RPM is viewed\nas a multi-label data point, with labels determined by the set of abstract\nrules underlying the RPM. For efficient training of the system we introduce a\ngeneralisation of the Noise Contrastive Estimation algorithm to the case of\nmulti-label samples. Furthermore, we propose a new sparse rule encoding scheme\nfor RPMs which, besides the new training algorithm, is the key factor\ncontributing to the state-of-the-art performance. The proposed approach is\nevaluated on two most popular benchmark datasets (Balanced-RAVEN and PGM) and\non both of them demonstrates an advantage over the current state-of-the-art\nresults. Contrary to applications of contrastive learning methods reported in\nother domains, the state-of-the-art performance reported in the paper is\nachieved with no need for large batch sizes or strong data augmentation.\n", "versions": [{"version": "v1", "created": "Thu, 3 Dec 2020 14:18:15 GMT"}], "update_date": "2020-12-04", "authors_parsed": [["Ma\u0142ki\u0144ski", "Miko\u0142aj", ""], ["Ma\u0144dziuk", "Jacek", ""]]}, {"id": "2012.01953", "submitter": "Carlos Badenes-Olmedo", "authors": "Carlos Badenes-Olmedo, David Chaves-Fraga, Mar\\'Ia Poveda-Villal\\'On,\n  Ana Iglesias-Molina, Pablo Calleja, Socorro Bernardos, Patricia\n  Mart\\'In-Chozas, Alba Fern\\'andez-Izquierdo, Elvira Amador-Dom\\'inguez, Paola\n  Espinoza-Arias, Luis Pozo, Edna Ruckhaus, Esteban Gonz\\'alez-Guardia, Raquel\n  Cedazo, Beatriz L\\'opez-Centeno, and Oscar Corcho", "title": "Drugs4Covid: Drug-driven Knowledge Exploitation based on Scientific\n  Publications", "comments": "Ontology-based technologies, NLP, Bio-annotations, Drugs-catalogue,\n  Knowledge Graph, COVID-19", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In the absence of sufficient medication for COVID patients due to the\nincreased demand, disused drugs have been employed or the doses of those\navailable were modified by hospital pharmacists. Some evidences for the use of\nalternative drugs can be found in the existing scientific literature that could\nassist in such decisions. However, exploiting large corpus of documents in an\nefficient manner is not easy, since drugs may not appear explicitly related in\nthe texts and could be mentioned under different brand names. Drugs4Covid\ncombines word embedding techniques and semantic web technologies to enable a\ndrug-oriented exploration of large medical literature. Drugs and diseases are\nidentified according to the ATC classification and MeSH categories\nrespectively. More than 60K articles and 2M paragraphs have been processed from\nthe CORD-19 corpus with information of COVID-19, SARS, and other related\ncoronaviruses. An open catalogue of drugs has been created and results are\npublicly available through a drug browser, a keyword-guided text explorer, and\na knowledge graph.\n", "versions": [{"version": "v1", "created": "Thu, 3 Dec 2020 14:26:54 GMT"}], "update_date": "2020-12-04", "authors_parsed": [["Badenes-Olmedo", "Carlos", ""], ["Chaves-Fraga", "David", ""], ["Poveda-Villal\u00d3n", "Mar\u00cda", ""], ["Iglesias-Molina", "Ana", ""], ["Calleja", "Pablo", ""], ["Bernardos", "Socorro", ""], ["Mart\u00cdn-Chozas", "Patricia", ""], ["Fern\u00e1ndez-Izquierdo", "Alba", ""], ["Amador-Dom\u00ednguez", "Elvira", ""], ["Espinoza-Arias", "Paola", ""], ["Pozo", "Luis", ""], ["Ruckhaus", "Edna", ""], ["Gonz\u00e1lez-Guardia", "Esteban", ""], ["Cedazo", "Raquel", ""], ["L\u00f3pez-Centeno", "Beatriz", ""], ["Corcho", "Oscar", ""]]}, {"id": "2012.01959", "submitter": "Prateek Verma", "authors": "Elizabeth Bibit Bianchini, Prateek Verma and Kenneth Salisbury", "title": "Human Haptic Gesture Interpretation for Robotic Systems", "comments": "8 pages, 8 figures, Under Review IROS 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Physical human-robot interactions (pHRI) are less efficient and communicative\nthan human-human interactions, and a key reason is a lack of informative sense\nof touch in robotic systems. Interpreting human touch gestures is a nuanced,\nchallenging task with extreme gaps between human and robot capability. Among\nprior works that demonstrate human touch recognition capability, differences in\nsensors, gesture classes, feature sets, and classification algorithms yield a\nconglomerate of non-transferable results and a glaring lack of a standard. To\naddress this gap, this work presents 1) four proposed touch gesture classes\nthat cover the majority of the gesture characteristics identified in the\nliterature, 2) the collection of an extensive force dataset on a common pHRI\nrobotic arm with only its internal wrist force-torque sensor, and 3) an\nexhaustive performance comparison of combinations of feature sets and\nclassification algorithms on this dataset. We demonstrate high classification\naccuracies among our proposed gesture definitions on a test set, emphasizing\nthat neural network classifiers on the raw data outperform other combinations\nof feature sets and algorithms.\n", "versions": [{"version": "v1", "created": "Thu, 3 Dec 2020 14:33:57 GMT"}, {"version": "v2", "created": "Sun, 7 Mar 2021 23:03:21 GMT"}, {"version": "v3", "created": "Wed, 10 Mar 2021 02:43:43 GMT"}], "update_date": "2021-03-11", "authors_parsed": [["Bianchini", "Elizabeth Bibit", ""], ["Verma", "Prateek", ""], ["Salisbury", "Kenneth", ""]]}, {"id": "2012.01993", "submitter": "Simon Isele", "authors": "Simon T. Isele, Marcel P. Schilling, Fabian E. Klein, Sascha\n  Saralajew, J. Marius Zoellner", "title": "Radar Artifact Labeling Framework (RALF): Method for Plausible Radar\n  Detections in Datasets", "comments": "pre-print, currently under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Research on localization and perception for Autonomous Driving is mainly\nfocused on camera and LiDAR datasets, rarely on radar data. Manually labeling\nsparse radar point clouds is challenging. For a dataset generation, we propose\nthe cross sensor Radar Artifact Labeling Framework (RALF). Automatically\ngenerated labels for automotive radar data help to cure radar shortcomings like\nartifacts for the application of artificial intelligence. RALF provides\nplausibility labels for radar raw detections, distinguishing between artifacts\nand targets. The optical evaluation backbone consists of a generalized\nmonocular depth image estimation of surround view cameras plus LiDAR scans.\nModern car sensor sets of cameras and LiDAR allow to calibrate image-based\nrelative depth information in overlapping sensing areas. K-Nearest Neighbors\nmatching relates the optical perception point cloud with raw radar detections.\nIn parallel, a temporal tracking evaluation part considers the radar\ndetections' transient behavior. Based on the distance between matches,\nrespecting both sensor and model uncertainties, we propose a plausibility\nrating of every radar detection. We validate the results by evaluating error\nmetrics on semi-manually labeled ground truth dataset of $3.28\\cdot10^6$\npoints. Besides generating plausible radar detections, the framework enables\nfurther labeled low-level radar signal datasets for applications of perception\nand Autonomous Driving learning tasks.\n", "versions": [{"version": "v1", "created": "Thu, 3 Dec 2020 15:11:31 GMT"}], "update_date": "2020-12-04", "authors_parsed": [["Isele", "Simon T.", ""], ["Schilling", "Marcel P.", ""], ["Klein", "Fabian E.", ""], ["Saralajew", "Sascha", ""], ["Zoellner", "J. Marius", ""]]}, {"id": "2012.02007", "submitter": "Mahbubur Rahman", "authors": "Mahbubur Rahman", "title": "A Novel index-based multidimensional data organization model that\n  enhances the predictability of the machine learning algorithms", "comments": null, "journal-ref": "International Conference on Machine Learning Techniques and NLP\n  (MLNLP 2020), Volume 10, Number 12, October 2020, ISBN : 978-1-925953-26-8", "doi": "10.5121/csit.2020.101210", "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Learning from the multidimensional data has been an interesting concept in\nthe field of machine learning. However, such learning can be difficult,\ncomplex, expensive because of expensive data processing, manipulations as the\nnumber of dimension increases. As a result, we have introduced an ordered\nindex-based data organization model as the ordered data set provides easy and\nefficient access than the unordered one and finally, such organization can\nimprove the learning. The ordering maps the multidimensional dataset in the\nreduced space and ensures that the information associated with the learning can\nbe retrieved back and forth efficiently. We have found that such\nmultidimensional data storage can enhance the predictability for both the\nunsupervised and supervised machine learning algorithms.\n", "versions": [{"version": "v1", "created": "Thu, 3 Dec 2020 15:41:13 GMT"}], "update_date": "2020-12-04", "authors_parsed": [["Rahman", "Mahbubur", ""]]}, {"id": "2012.02026", "submitter": "ANtoine Marot", "authors": "Antoine Marot, Alexandre Rozier, Matthieu Dussartre, Laure\n  Crochepierre, Benjamin Donnot", "title": "Towards an AI assistant for human grid operators", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Power systems are becoming more complex to operate in the digital age. As a\nresult, real-time decision-making is getting more challenging as the human\noperator has to deal with more information, more uncertainty, more applications\nand more coordination. While supervision has been primarily used to help them\nmake decisions over the last decades, it cannot reasonably scale up anymore.\nThere is a great need for rethinking the human-machine interface under more\nunified and interactive frameworks. Taking advantage of the latest developments\nin Human-machine Interactions and Artificial intelligence, we share the vision\nof a new assistant framework relying on an hypervision interface and greater\nbidirectional interactions. We review the known principles of decision-making\nthat drives the assistant design and supporting assistance functions we\npresent. We finally share some guidelines to make progress towards the\ndevelopment of such an assistant.\n", "versions": [{"version": "v1", "created": "Thu, 3 Dec 2020 16:12:58 GMT"}], "update_date": "2020-12-04", "authors_parsed": [["Marot", "Antoine", ""], ["Rozier", "Alexandre", ""], ["Dussartre", "Matthieu", ""], ["Crochepierre", "Laure", ""], ["Donnot", "Benjamin", ""]]}, {"id": "2012.02044", "submitter": "Kang Wei", "authors": "Jun Li, Yumeng Shao, Ming Ding, Chuan Ma, Kang Wei, Zhu Han and H.\n  Vincent Poor", "title": "Blockchain Assisted Decentralized Federated Learning (BLADE-FL) with\n  Lazy Clients", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Federated learning (FL), as a distributed machine learning approach, has\ndrawn a great amount of attention in recent years. FL shows an inherent\nadvantage in privacy preservation, since users' raw data are processed locally.\nHowever, it relies on a centralized server to perform model aggregation.\nTherefore, FL is vulnerable to server malfunctions and external attacks. In\nthis paper, we propose a novel framework by integrating blockchain into FL,\nnamely, blockchain assisted decentralized federated learning (BLADE-FL), to\nenhance the security of FL. The proposed BLADE-FL has a good performance in\nterms of privacy preservation, tamper resistance, and effective cooperation of\nlearning. However, it gives rise to a new problem of training deficiency,\ncaused by lazy clients who plagiarize others' trained models and add artificial\nnoises to conceal their cheating behaviors. To be specific, we first develop a\nconvergence bound of the loss function with the presence of lazy clients and\nprove that it is convex with respect to the total number of generated blocks\n$K$. Then, we solve the convex problem by optimizing $K$ to minimize the loss\nfunction. Furthermore, we discover the relationship between the optimal $K$,\nthe number of lazy clients, and the power of artificial noises used by lazy\nclients. We conduct extensive experiments to evaluate the performance of the\nproposed framework using the MNIST and Fashion-MNIST datasets. Our analytical\nresults are shown to be consistent with the experimental results. In addition,\nthe derived optimal $K$ achieves the minimum value of loss function, and in\nturn the optimal accuracy performance.\n", "versions": [{"version": "v1", "created": "Wed, 2 Dec 2020 12:18:27 GMT"}], "update_date": "2020-12-04", "authors_parsed": [["Li", "Jun", ""], ["Shao", "Yumeng", ""], ["Ding", "Ming", ""], ["Ma", "Chuan", ""], ["Wei", "Kang", ""], ["Han", "Zhu", ""], ["Poor", "H. Vincent", ""]]}, {"id": "2012.02046", "submitter": "Meike Nauta", "authors": "Meike Nauta, Ron van Bree, Christin Seifert", "title": "Neural Prototype Trees for Interpretable Fine-grained Image Recognition", "comments": "Accepted to IEEE Conference on Computer Vision and Pattern\n  Recognition (CVPR) 2021. 11 pages, and 9 pages supplementary", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Prototype-based methods use interpretable representations to address the\nblack-box nature of deep learning models, in contrast to post-hoc explanation\nmethods that only approximate such models. We propose the Neural Prototype Tree\n(ProtoTree), an intrinsically interpretable deep learning method for\nfine-grained image recognition. ProtoTree combines prototype learning with\ndecision trees, and thus results in a globally interpretable model by design.\nAdditionally, ProtoTree can locally explain a single prediction by outlining a\ndecision path through the tree. Each node in our binary tree contains a\ntrainable prototypical part. The presence or absence of this learned prototype\nin an image determines the routing through a node. Decision making is therefore\nsimilar to human reasoning: Does the bird have a red throat? And an elongated\nbeak? Then it's a hummingbird! We tune the accuracy-interpretability trade-off\nusing ensemble methods, pruning and binarizing. We apply pruning without\nsacrificing accuracy, resulting in a small tree with only 8 learned prototypes\nalong a path to classify a bird from 200 species. An ensemble of 5 ProtoTrees\nachieves competitive accuracy on the CUB-200- 2011 and Stanford Cars data sets.\nCode is available at https://github.com/M-Nauta/ProtoTree\n", "versions": [{"version": "v1", "created": "Thu, 3 Dec 2020 16:28:04 GMT"}, {"version": "v2", "created": "Thu, 15 Apr 2021 08:49:31 GMT"}], "update_date": "2021-04-16", "authors_parsed": [["Nauta", "Meike", ""], ["van Bree", "Ron", ""], ["Seifert", "Christin", ""]]}, {"id": "2012.02076", "submitter": "Jinyan Wang", "authors": "Jinhuan Duan, Xianxian Li, Shiqi Gao, Jinyan Wang and Zili Zhong", "title": "SSGD: A safe and efficient method of gradient descent", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR cs.CV cs.DC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  With the vigorous development of artificial intelligence technology, various\nengineering technology applications have been implemented one after another.\nThe gradient descent method plays an important role in solving various\noptimization problems, due to its simple structure, good stability and easy\nimplementation. In multi-node machine learning system, the gradients usually\nneed to be shared. Shared gradients are generally unsafe. Attackers can obtain\ntraining data simply by knowing the gradient information. In this paper, to\nprevent gradient leakage while keeping the accuracy of model, we propose the\nsuper stochastic gradient descent approach to update parameters by concealing\nthe modulus length of gradient vectors and converting it or them into a unit\nvector. Furthermore, we analyze the security of super stochastic gradient\ndescent approach. Our algorithm can defend against attacks on the gradient.\nExperiment results show that our approach is obviously superior to prevalent\ngradient descent approaches in terms of accuracy, robustness, and adaptability\nto large-scale batches.\n", "versions": [{"version": "v1", "created": "Thu, 3 Dec 2020 17:09:20 GMT"}, {"version": "v2", "created": "Mon, 26 Apr 2021 04:33:08 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["Duan", "Jinhuan", ""], ["Li", "Xianxian", ""], ["Gao", "Shiqi", ""], ["Wang", "Jinyan", ""], ["Zhong", "Zili", ""]]}, {"id": "2012.02096", "submitter": "Michael Dennis", "authors": "Michael Dennis, Natasha Jaques, Eugene Vinitsky, Alexandre Bayen,\n  Stuart Russell, Andrew Critch, Sergey Levine", "title": "Emergent Complexity and Zero-shot Transfer via Unsupervised Environment\n  Design", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A wide range of reinforcement learning (RL) problems - including robustness,\ntransfer learning, unsupervised RL, and emergent complexity - require\nspecifying a distribution of tasks or environments in which a policy will be\ntrained. However, creating a useful distribution of environments is error\nprone, and takes a significant amount of developer time and effort. We propose\nUnsupervised Environment Design (UED) as an alternative paradigm, where\ndevelopers provide environments with unknown parameters, and these parameters\nare used to automatically produce a distribution over valid, solvable\nenvironments. Existing approaches to automatically generating environments\nsuffer from common failure modes: domain randomization cannot generate\nstructure or adapt the difficulty of the environment to the agent's learning\nprogress, and minimax adversarial training leads to worst-case environments\nthat are often unsolvable. To generate structured, solvable environments for\nour protagonist agent, we introduce a second, antagonist agent that is allied\nwith the environment-generating adversary. The adversary is motivated to\ngenerate environments which maximize regret, defined as the difference between\nthe protagonist and antagonist agent's return. We call our technique\nProtagonist Antagonist Induced Regret Environment Design (PAIRED). Our\nexperiments demonstrate that PAIRED produces a natural curriculum of\nincreasingly complex environments, and PAIRED agents achieve higher zero-shot\ntransfer performance when tested in highly novel environments.\n", "versions": [{"version": "v1", "created": "Thu, 3 Dec 2020 17:37:01 GMT"}, {"version": "v2", "created": "Thu, 4 Feb 2021 03:01:31 GMT"}], "update_date": "2021-02-05", "authors_parsed": [["Dennis", "Michael", ""], ["Jaques", "Natasha", ""], ["Vinitsky", "Eugene", ""], ["Bayen", "Alexandre", ""], ["Russell", "Stuart", ""], ["Critch", "Andrew", ""], ["Levine", "Sergey", ""]]}, {"id": "2012.02104", "submitter": "Manuel Francisco", "authors": "Manuel Francisco and Juan Luis Castro", "title": "Discriminatory Expressions to Produce Interpretable Models in Short\n  Documents", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.AI cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Social Networking Sites (SNS) are one of the most important ways of\ncommunication. In particular, microblogging sites are being used as analysis\navenues due to their peculiarities (promptness, short texts...). There are\ncountless researches that use SNS in novel manners, but machine learning has\nfocused mainly in classification performance rather than interpretability\nand/or other goodness metrics. Thus, state-of-the-art models are black boxes\nthat should not be used to solve problems that may have a social impact. When\nthe problem requires transparency, it is necessary to build interpretable\npipelines. Although the classifier may be interpretable, resulting models are\ntoo complex to be considered comprehensible, making it impossible for humans to\nunderstand the actual decisions. This paper presents a feature selection\nmechanism that is able to improve comprehensibility by using less but more\nmeaningful features while achieving good performance in microblogging contexts\nwhere interpretability is mandatory. Moreover, we present a ranking method to\nevaluate features in terms of statistical relevance and bias. We conducted\nexhaustive tests with five different datasets in order to evaluate\nclassification performance, generalisation capacity and complexity of the\nmodel. Results show that our proposal is better and the most stable one in\nterms of accuracy, generalisation and comprehensibility.\n", "versions": [{"version": "v1", "created": "Fri, 27 Nov 2020 19:00:50 GMT"}, {"version": "v2", "created": "Mon, 15 Feb 2021 14:25:09 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Francisco", "Manuel", ""], ["Castro", "Juan Luis", ""]]}, {"id": "2012.02108", "submitter": "Ritwik Gupta", "authors": "Ritwik Gupta, Eric T. Heim, Edoardo Nemni", "title": "Proceedings of NeurIPS 2020 Workshop on Artificial Intelligence for\n  Humanitarian Assistance and Disaster Response", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  These are the \"proceedings\" of the 2nd AI + HADR workshop which was held\nvirtually on December 12, 2020 as part of the Neural Information Processing\nSystems conference. These are non-archival and merely serve as a way to collate\nall the papers accepted to the workshop.\n", "versions": [{"version": "v1", "created": "Thu, 3 Dec 2020 17:44:26 GMT"}, {"version": "v2", "created": "Tue, 8 Dec 2020 04:23:15 GMT"}], "update_date": "2020-12-09", "authors_parsed": [["Gupta", "Ritwik", ""], ["Heim", "Eric T.", ""], ["Nemni", "Edoardo", ""]]}, {"id": "2012.02147", "submitter": "Hesam Hamledari", "authors": "Hesam Hamledari and Martin Fischer", "title": "The Application of Blockchain-Based Crypto Assets for Integrating the\n  Physical and Financial Supply Chains in the Construction & Engineering\n  Industry", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Supply chain integration remains an elusive goal for the construction and\nengineering industry. The high degree of fragmentation and the reliance on\nthird-party financial institutions has pushed the physical and financial supply\nchains apart. The paper demonstrates how blockchain-based crypto assets (crypto\ncurrencies and crypto tokens) can address this limitation when used for\nconditioning the flow of funds based on the flow of products. The paper\ncontrasts the integration between cash and product flows in supply chains that\nrely on fiat currencies and crypto assets for their payment settlement. Two\nfacets of crypto asset-enabled integration, atomicity and granularity, are\nfurther introduced. The thesis is validated in the context of construction\nprogress payments. The as-built data captured by unmanned aerial and ground\nvehicles was passed to an autonomous smart contract-based method that utilizes\ncrypto-currencies and crypto tokens for payment settlement; the resulting\npayment datasets, written to the Ethereum blockchain, were analyzed in terms of\ntheir integration of product and cash flow. The work is concluded with a\ndiscussion of findings and their implications for the industry.\n", "versions": [{"version": "v1", "created": "Thu, 3 Dec 2020 18:27:16 GMT"}], "update_date": "2020-12-04", "authors_parsed": [["Hamledari", "Hesam", ""], ["Fischer", "Martin", ""]]}, {"id": "2012.02175", "submitter": "Md Sirajus Salekin", "authors": "Md Sirajus Salekin, Ghada Zamzmi, Dmitry Goldgof, Rangachar Kasturi,\n  Thao Ho, Yu Sun", "title": "Multimodal Spatio-Temporal Deep Learning Approach for Neonatal\n  Postoperative Pain Assessment", "comments": "Accepted in Computers in Biology and Medicine, 2020", "journal-ref": null, "doi": "10.1016/j.compbiomed.2020.104150", "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  The current practice for assessing neonatal postoperative pain relies on\nbedside caregivers. This practice is subjective, inconsistent, slow, and\ndiscontinuous. To develop a reliable medical interpretation, several automated\napproaches have been proposed to enhance the current practice. These approaches\nare unimodal and focus mainly on assessing neonatal procedural (acute) pain. As\npain is a multimodal emotion that is often expressed through multiple\nmodalities, the multimodal assessment of pain is necessary especially in case\nof postoperative (acute prolonged) pain. Additionally, spatio-temporal analysis\nis more stable over time and has been proven to be highly effective at\nminimizing misclassification errors. In this paper, we present a novel\nmultimodal spatio-temporal approach that integrates visual and vocal signals\nand uses them for assessing neonatal postoperative pain. We conduct\ncomprehensive experiments to investigate the effectiveness of the proposed\napproach. We compare the performance of the multimodal and unimodal\npostoperative pain assessment, and measure the impact of temporal information\nintegration. The experimental results, on a real-world dataset, show that the\nproposed multimodal spatio-temporal approach achieves the highest AUC (0.87)\nand accuracy (79%), which are on average 6.67% and 6.33% higher than unimodal\napproaches. The results also show that the integration of temporal information\nmarkedly improves the performance as compared to the non-temporal approach as\nit captures changes in the pain dynamic. These results demonstrate that the\nproposed approach can be used as a viable alternative to manual assessment,\nwhich would tread a path toward fully automated pain monitoring in clinical\nsettings, point-of-care testing, and homes.\n", "versions": [{"version": "v1", "created": "Thu, 3 Dec 2020 18:52:35 GMT"}], "update_date": "2020-12-04", "authors_parsed": [["Salekin", "Md Sirajus", ""], ["Zamzmi", "Ghada", ""], ["Goldgof", "Dmitry", ""], ["Kasturi", "Rangachar", ""], ["Ho", "Thao", ""], ["Sun", "Yu", ""]]}, {"id": "2012.02178", "submitter": "George Atia", "authors": "George K. Atia, Andre Beckus, Ismail Alkhouri, Alvaro Velasquez", "title": "Verifiable Planning in Expected Reward Multichain MDPs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The planning domain has experienced increased interest in the formal\nsynthesis of decision-making policies. This formal synthesis typically entails\nfinding a policy which satisfies formal specifications in the form of some\nwell-defined logic, such as Linear Temporal Logic (LTL) or Computation Tree\nLogic (CTL), among others. While such logics are very powerful and expressive\nin their capacity to capture desirable agent behavior, their value is limited\nwhen deriving decision-making policies which satisfy certain types of\nasymptotic behavior. In particular, we are interested in specifying constraints\non the steady-state behavior of an agent, which captures the proportion of time\nan agent spends in each state as it interacts for an indefinite period of time\nwith its environment. This is sometimes called the average or expected behavior\nof the agent. In this paper, we explore the steady-state planning problem of\nderiving a decision-making policy for an agent such that constraints on its\nsteady-state behavior are satisfied. A linear programming solution for the\ngeneral case of multichain Markov Decision Processes (MDPs) is proposed and we\nprove that optimal solutions to the proposed programs yield stationary policies\nwith rigorous guarantees of behavior.\n", "versions": [{"version": "v1", "created": "Thu, 3 Dec 2020 18:54:24 GMT"}], "update_date": "2020-12-04", "authors_parsed": [["Atia", "George K.", ""], ["Beckus", "Andre", ""], ["Alkhouri", "Ismail", ""], ["Velasquez", "Alvaro", ""]]}, {"id": "2012.02194", "submitter": "Uwe Aickelin", "authors": "Justin Kane Gunn, Hadi Akbarzadeh Khorshidi, Uwe Aickelin", "title": "Methods of ranking for aggregated fuzzy numbers from interval-valued\n  data", "comments": "2020 IEEE International Conference on Fuzzy Systems (FUZZ-IEEE)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper primarily presents two methods of ranking aggregated fuzzy numbers\nfrom intervals using the Interval Agreement Approach (IAA). The two proposed\nranking methods within this study contain the combination and application of\npreviously proposed similarity measures, along with attributes novel to that of\naggregated fuzzy numbers from interval-valued data. The shortcomings of\nprevious measures, along with the improvements of the proposed methods, are\nillustrated using both a synthetic and real-world application. The real-world\napplication regards the Technique for Order of Preference by Similarity to\nIdeal Solution (TOPSIS) algorithm, modified to include both the previous and\nnewly proposed methods.\n", "versions": [{"version": "v1", "created": "Thu, 3 Dec 2020 02:56:15 GMT"}], "update_date": "2020-12-07", "authors_parsed": [["Gunn", "Justin Kane", ""], ["Khorshidi", "Hadi Akbarzadeh", ""], ["Aickelin", "Uwe", ""]]}, {"id": "2012.02248", "submitter": "Wanda Benesova", "authors": "Martin Stano, Wanda Benesova, Lukas Samuel Martak", "title": "Explaining Predictions of Deep Neural Classifier via Activation Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many practical applications, deep neural networks have been typically\ndeployed to operate as a black box predictor. Despite the high amount of work\non interpretability and high demand on the reliability of these systems, they\ntypically still have to include a human actor in the loop, to validate the\ndecisions and handle unpredictable failures and unexpected corner cases. This\nis true in particular for failure-critical application domains, such as medical\ndiagnosis. We present a novel approach to explain and support an interpretation\nof the decision-making process to a human expert operating a deep learning\nsystem based on Convolutional Neural Network (CNN). By modeling activation\nstatistics on selected layers of a trained CNN via Gaussian Mixture Models\n(GMM), we develop a novel perceptual code in binary vector space that describes\nhow the input sample is processed by the CNN. By measuring distances between\npairs of samples in this perceptual encoding space, for any new input sample,\nwe can now retrieve a set of most perceptually similar and dissimilar samples\nfrom an existing atlas of labeled samples, to support and clarify the decision\nmade by the CNN model. Possible uses of this approach include for example\nComputer-Aided Diagnosis (CAD) systems working with medical imaging data, such\nas Magnetic Resonance Imaging (MRI) or Computed Tomography (CT) scans. We\ndemonstrate the viability of our method in the domain of medical imaging for\npatient condition diagnosis, as the proposed decision explanation method via\nsimilar ground truth domain examples (e.g. from existing diagnosis archives)\nwill be interpretable by the operating medical personnel. Our results indicate\nthat our method is capable of detecting distinct prediction strategies that\nenable us to identify the most similar predictions from an existing atlas.\n", "versions": [{"version": "v1", "created": "Thu, 3 Dec 2020 20:36:19 GMT"}], "update_date": "2020-12-07", "authors_parsed": [["Stano", "Martin", ""], ["Benesova", "Wanda", ""], ["Martak", "Lukas Samuel", ""]]}, {"id": "2012.02260", "submitter": "Eric L. Manibardo", "authors": "Eric L. Manibardo, Ibai La\\~na and Javier Del Ser", "title": "Deep Learning for Road Traffic Forecasting: Does it Make a Difference?", "comments": "25 pages, 7 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Learning methods have been proven to be flexible to model complex\nphenomena. This has also been the case of Intelligent Transportation Systems\n(ITS), in which several areas such as vehicular perception and traffic analysis\nhave widely embraced Deep Learning as a core modeling technology. Particularly\nin short-term traffic forecasting, the capability of Deep Learning to deliver\ngood results has generated a prevalent inertia towards using Deep Learning\nmodels, without examining in depth their benefits and downsides. This paper\nfocuses on critically analyzing the state of the art in what refers to the use\nof Deep Learning for this particular ITS research area. To this end, we\nelaborate on the findings distilled from a review of publications from recent\nyears, based on two taxonomic criteria. A posterior critical analysis is held\nto formulate questions and trigger a necessary debate about the issues of Deep\nLearning for traffic forecasting. The study is completed with a benchmark of\ndiverse short-term traffic forecasting methods over traffic datasets of\ndifferent nature, aimed to cover a wide spectrum of possible scenarios. Our\nexperimentation reveals that Deep Learning could not be the best modeling\ntechnique for every case, which unveils some caveats unconsidered to date that\nshould be addressed by the community in prospective studies. These insights\nreveal new challenges and research opportunities in road traffic forecasting,\nwhich are enumerated and discussed thoroughly, with the intention of inspiring\nand guiding future research efforts in this field.\n", "versions": [{"version": "v1", "created": "Wed, 2 Dec 2020 15:56:11 GMT"}], "update_date": "2020-12-07", "authors_parsed": [["Manibardo", "Eric L.", ""], ["La\u00f1a", "Ibai", ""], ["Del Ser", "Javier", ""]]}, {"id": "2012.02275", "submitter": "Susmit Jha", "authors": "Karan Sikka, Indranil Sur, Susmit Jha, Anirban Roy and Ajay Divakaran", "title": "Detecting Trojaned DNNs Using Counterfactual Attributions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.IT math.IT", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We target the problem of detecting Trojans or backdoors in DNNs. Such models\nbehave normally with typical inputs but produce specific incorrect predictions\nfor inputs poisoned with a Trojan trigger. Our approach is based on a novel\nobservation that the trigger behavior depends on a few ghost neurons that\nactivate on trigger pattern and exhibit abnormally higher relative attribution\nfor wrong decisions when activated. Further, these trigger neurons are also\nactive on normal inputs of the target class. Thus, we use counterfactual\nattributions to localize these ghost neurons from clean inputs and then\nincrementally excite them to observe changes in the model's accuracy. We use\nthis information for Trojan detection by using a deep set encoder that enables\ninvariance to the number of model classes, architecture, etc. Our approach is\nimplemented in the TrinityAI tool that exploits the synergies between\ntrustworthiness, resilience, and interpretability challenges in deep learning.\nWe evaluate our approach on benchmarks with high diversity in model\narchitectures, triggers, etc. We show consistent gains (+10%) over\nstate-of-the-art methods that rely on the susceptibility of the DNN to specific\nadversarial attacks, which in turn requires strong assumptions on the nature of\nthe Trojan attack.\n", "versions": [{"version": "v1", "created": "Thu, 3 Dec 2020 21:21:33 GMT"}], "update_date": "2020-12-07", "authors_parsed": [["Sikka", "Karan", ""], ["Sur", "Indranil", ""], ["Jha", "Susmit", ""], ["Roy", "Anirban", ""], ["Divakaran", "Ajay", ""]]}, {"id": "2012.02282", "submitter": "Johannes Schneider", "authors": "Johannes Schneider and Marcus Basalla", "title": "Creativity of Deep Learning: Conceptualization and Assessment", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While the potential of deep learning(DL) for automating simple tasks is\nalready well explored, recent research started investigating the use of deep\nlearning for creative design, both for complete artifact creation and\nsupporting humans in the creation process. In this paper, we use insights from\ncomputational creativity to conceptualize and assess current applications of\ngenerative deep learning in creative domains identified in a literature review.\nWe highlight parallels between current systems and different models of human\ncreativity as well as their shortcomings. While deep learning yields results of\nhigh value, such as high quality images, their novelity is typically limited\ndue to multiple reasons such a being tied to a conceptual space defined by\ntraining data and humans. Current DL methods also do not allow for changes in\nthe internal problem representation and they lack the capability to identify\nconnections across highly different domains, both of which are seen as major\ndrivers of human creativity.\n", "versions": [{"version": "v1", "created": "Thu, 3 Dec 2020 21:44:07 GMT"}], "update_date": "2020-12-07", "authors_parsed": [["Schneider", "Johannes", ""], ["Basalla", "Marcus", ""]]}, {"id": "2012.02291", "submitter": "Anubha Kabra Ms", "authors": "Anubha Kabra, Anu Agarwal, Anil Singh Parihar", "title": "Cluster Based Deep Contextual Reinforcement Learning for top-k\n  Recommendations", "comments": "To be published in : Springer Lecture Notes in Networks and Systems\n  ISSN 2367-3370", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Rapid advancements in the E-commerce sector over the last few decades have\nled to an imminent need for personalised, efficient and dynamic recommendation\nsystems. To sufficiently cater to this need, we propose a novel method for\ngenerating top-k recommendations by creating an ensemble of clustering with\nreinforcement learning. We have incorporated DB Scan clustering to tackle vast\nitem space, hence in-creasing the efficiency multi-fold. Moreover, by using\ndeep contextual reinforcement learning, our proposed work leverages the user\nfeatures to its full potential. With partial updates and batch updates, the\nmodel learns user patterns continuously. The Duelling Bandit based exploration\nprovides robust exploration as compared to the state-of-art strategies due to\nits adaptive nature. Detailed experiments conducted on a public dataset verify\nour claims about the efficiency of our technique as com-pared to existing\ntechniques.\n", "versions": [{"version": "v1", "created": "Sun, 29 Nov 2020 20:24:39 GMT"}], "update_date": "2020-12-07", "authors_parsed": [["Kabra", "Anubha", ""], ["Agarwal", "Anu", ""], ["Parihar", "Anil Singh", ""]]}, {"id": "2012.02300", "submitter": "Damien Bouchabou", "authors": "Damien Bouchabou (IMT Atlantique - INFO), Sao Nguyen, Christophe Lohr,\n  Benoit Leduc, Ioannis Kanellos", "title": "Fully Convolutional Network Bootstrapped by Word Encoding and Embedding\n  for Activity Recognition in Smart Homes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Activity recognition in smart homes is essential when we wish to propose\nautomatic services for the inhabitants. However, it poses challenges in terms\nof variability of the environment, sensorimotor system, but also user habits.\nTherefore, endto-end systems fail at automatically extracting key features,\nwithout extensive pre-processing. We propose to tackle feature extraction for\nactivity recognition in smart homes by merging methods from the Natural\nLanguage Processing (NLP) and the Time Series Classification (TSC) domains. We\nevaluate the performance of our method on two datasets issued from the Center\nfor Advanced Studies in Adaptive Systems (CASAS). Moreover, we analyze the\ncontributions of the use of NLP encoding Bag-Of-Word with Embedding as well as\nthe ability of the FCN algorithm to automatically extract features and\nclassify. The method we propose shows good performance in offline activity\nclassification. Our analysis also shows that FCN is a suitable algorithm for\nsmart home activity recognition and hightlights the advantages of automatic\nfeature extraction.\n", "versions": [{"version": "v1", "created": "Tue, 1 Dec 2020 11:47:07 GMT"}], "update_date": "2020-12-07", "authors_parsed": [["Bouchabou", "Damien", "", "IMT Atlantique - INFO"], ["Nguyen", "Sao", ""], ["Lohr", "Christophe", ""], ["Leduc", "Benoit", ""], ["Kanellos", "Ioannis", ""]]}, {"id": "2012.02334", "submitter": "Yaofeng Desmond Zhong", "authors": "Yaofeng Desmond Zhong, Biswadip Dey, Amit Chakraborty", "title": "Benchmarking Energy-Conserving Neural Networks for Learning Dynamics\n  from Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.SY eess.SY math.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The last few years have witnessed an increased interest in incorporating\nphysics-informed inductive bias in deep learning frameworks. In particular, a\ngrowing volume of literature has been exploring ways to enforce energy\nconservation while using neural networks for learning dynamics from observed\ntime-series data. In this work, we survey ten recently proposed\nenergy-conserving neural network models, including HNN, LNN, DeLaN, SymODEN,\nCHNN, CLNN and their variants. We provide a compact derivation of the theory\nbehind these models and explain their similarities and differences. Their\nperformance are compared in 4 physical systems. We point out the possibility of\nleveraging some of these energy-conserving models to design energy-based\ncontrollers.\n", "versions": [{"version": "v1", "created": "Thu, 3 Dec 2020 23:53:08 GMT"}, {"version": "v2", "created": "Wed, 30 Dec 2020 18:34:04 GMT"}, {"version": "v3", "created": "Fri, 26 Feb 2021 18:13:21 GMT"}, {"version": "v4", "created": "Tue, 18 May 2021 19:24:55 GMT"}], "update_date": "2021-05-20", "authors_parsed": [["Zhong", "Yaofeng Desmond", ""], ["Dey", "Biswadip", ""], ["Chakraborty", "Amit", ""]]}, {"id": "2012.02342", "submitter": "Ali Ugur Guler", "authors": "Ali Ugur Guler, Emir Demirovic, Jeffrey Chan, James Bailey,\n  Christopher Leckie, Peter J. Stuckey", "title": "Divide and Learn: A Divide and Conquer Approach for Predict+Optimize", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI math.OC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The predict+optimize problem combines machine learning ofproblem coefficients\nwith a combinatorial optimization prob-lem that uses the predicted\ncoefficients. While this problemcan be solved in two separate stages, it is\nbetter to directlyminimize the optimization loss. However, this requires\ndif-ferentiating through a discrete, non-differentiable combina-torial\nfunction. Most existing approaches use some form ofsurrogate gradient.\nDemirovicet alshowed how to directlyexpress the loss of the optimization\nproblem in terms of thepredicted coefficients as a piece-wise linear function.\nHow-ever, their approach is restricted to optimization problemswith a dynamic\nprogramming formulation. In this work wepropose a novel divide and conquer\nalgorithm to tackle op-timization problems without this restriction and predict\nitscoefficients using the optimization loss. We also introduce agreedy version\nof this approach, which achieves similar re-sults with less computation. We\ncompare our approach withother approaches to the predict+optimize problem and\nshowwe can successfully tackle some hard combinatorial problemsbetter than\nother predict+optimize methods.\n", "versions": [{"version": "v1", "created": "Fri, 4 Dec 2020 00:26:56 GMT"}], "update_date": "2020-12-07", "authors_parsed": [["Guler", "Ali Ugur", ""], ["Demirovic", "Emir", ""], ["Chan", "Jeffrey", ""], ["Bailey", "James", ""], ["Leckie", "Christopher", ""], ["Stuckey", "Peter J.", ""]]}, {"id": "2012.02360", "submitter": "Jing Qin", "authors": "Jing Qin", "title": "Research Progress of News Recommendation Methods", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Due to researchers'aim to study personalized recommendations for different\nbusiness fields, the summary of recommendation methods in specific fields is of\npractical significance. News recommendation systems were the earliest research\nfield regarding recommendation systems, and were also the earliest\nrecommendation field to apply the collaborative filtering method. In addition,\nnews is real-time and rich in content, which makes news recommendation methods\nmore challenging than in other fields. Thus, this paper summarizes the research\nprogress regarding news recommendation methods. From 2018 to 2020, developed\nnews recommendation methods were mainly deep learning-based, attention-based,\nand knowledge graphs-based. As of 2020, there are many news recommendation\nmethods that combine attention mechanisms and knowledge graphs. However, these\nmethods were all developed based on basic methods (the collaborative filtering\nmethod, the content-based recommendation method, and a mixed recommendation\nmethod combining the two). In order to allow researchers to have a detailed\nunderstanding of the development process of news recommendation methods, the\nnews recommendation methods surveyed in this paper, which cover nearly 10\nyears, are divided into three categories according to the abovementioned basic\nmethods. Firstly, the paper introduces the basic ideas of each category of\nmethods and then summarizes the recommendation methods that are combined with\nother methods based on each category of methods and according to the time\nsequence of research results. Finally, this paper also summarizes the\nchallenges confronting news recommendation systems.\n", "versions": [{"version": "v1", "created": "Fri, 4 Dec 2020 01:47:24 GMT"}, {"version": "v2", "created": "Mon, 8 Mar 2021 01:53:42 GMT"}], "update_date": "2021-03-09", "authors_parsed": [["Qin", "Jing", ""]]}, {"id": "2012.02419", "submitter": "Keiran Paster", "authors": "Keiran Paster, Sheila A. McIlraith, Jimmy Ba", "title": "Planning from Pixels using Inverse Dynamics Models", "comments": "9 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning task-agnostic dynamics models in high-dimensional observation spaces\ncan be challenging for model-based RL agents. We propose a novel way to learn\nlatent world models by learning to predict sequences of future actions\nconditioned on task completion. These task-conditioned models adaptively focus\nmodeling capacity on task-relevant dynamics, while simultaneously serving as an\neffective heuristic for planning with sparse rewards. We evaluate our method on\nchallenging visual goal completion tasks and show a substantial increase in\nperformance compared to prior model-free approaches.\n", "versions": [{"version": "v1", "created": "Fri, 4 Dec 2020 06:07:36 GMT"}], "update_date": "2020-12-07", "authors_parsed": [["Paster", "Keiran", ""], ["McIlraith", "Sheila A.", ""], ["Ba", "Jimmy", ""]]}, {"id": "2012.02423", "submitter": "Mohamadreza Ahmadi", "authors": "Mohamadreza Ahmadi, Ugo Rosolia, Michel D. Ingham, Richard M. Murray,\n  and Aaron D. Ames", "title": "Constrained Risk-Averse Markov Decision Processes", "comments": "Draft Accepted for Presentation at The Thirty-Fifth AAAI Conference\n  on Artificial Intelligence (AAAI-21), Feb. 2-9, 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.RO cs.SY eess.SY math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of designing policies for Markov decision processes\n(MDPs) with dynamic coherent risk objectives and constraints. We begin by\nformulating the problem in a Lagrangian framework. Under the assumption that\nthe risk objectives and constraints can be represented by a Markov risk\ntransition mapping, we propose an optimization-based method to synthesize\nMarkovian policies that lower-bound the constrained risk-averse problem. We\ndemonstrate that the formulated optimization problems are in the form of\ndifference convex programs (DCPs) and can be solved by the disciplined\nconvex-concave programming (DCCP) framework. We show that these results\ngeneralize linear programs for constrained MDPs with total discounted expected\ncosts and constraints. Finally, we illustrate the effectiveness of the proposed\nmethod with numerical experiments on a rover navigation problem involving\nconditional-value-at-risk (CVaR) and entropic-value-at-risk (EVaR) coherent\nrisk measures.\n", "versions": [{"version": "v1", "created": "Fri, 4 Dec 2020 06:12:11 GMT"}, {"version": "v2", "created": "Sun, 28 Mar 2021 23:45:15 GMT"}], "update_date": "2021-03-30", "authors_parsed": [["Ahmadi", "Mohamadreza", ""], ["Rosolia", "Ugo", ""], ["Ingham", "Michel D.", ""], ["Murray", "Richard M.", ""], ["Ames", "Aaron D.", ""]]}, {"id": "2012.02472", "submitter": "Hengrong Lan", "authors": "Hengrong Lan, Changchun Yang, Fei Gao", "title": "A Jointed Feature Fusion Framework for Photoacoustic Reconstruction", "comments": "under the peer-review procedure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Photoacoustic (PA) computed tomography (PACT) reconstructs the initial\npressure distribution from raw PA signals. The standard reconstruction of\nmedical image could cause the artifacts due to interferences or ill-posed\nsetup. Recently, deep learning has been used to reconstruct the PA image with\nill-posed conditions. Most works remove the artifacts from image domain, and\ncompensate the limited-view from dataset. In this paper, we propose a jointed\nfeature fusion framework (JEFF-Net) based on deep learning to reconstruct the\nPA image using limited-view data. The cross-domain features from limited-view\nposition-wise data and the reconstructed image are fused by a backtracked\nsupervision. Specifically, our results could generate superior performance,\nwhose artifacts are drastically reduced in the output compared to ground-truth\n(full-view reconstructed result). In this paper, a quarter position-wise data\n(32 channels) is fed into model, which outputs another 3-quarters-view data (96\nchannels). Moreover, two novel losses are designed to restrain the artifacts by\nsufficiently manipulating superposed data. The numerical and in-vivo results\nhave demonstrated the superior performance of our method to reconstruct the\nfull-view image without artifacts. Finally, quantitative evaluations show that\nour proposed method outperformed the ground-truth in some metrics.\n", "versions": [{"version": "v1", "created": "Fri, 4 Dec 2020 08:53:46 GMT"}, {"version": "v2", "created": "Mon, 21 Dec 2020 01:54:11 GMT"}, {"version": "v3", "created": "Tue, 25 May 2021 15:44:00 GMT"}], "update_date": "2021-05-26", "authors_parsed": [["Lan", "Hengrong", ""], ["Yang", "Changchun", ""], ["Gao", "Fei", ""]]}, {"id": "2012.02476", "submitter": "Yn W", "authors": "Yanan Wang, Yong Ge, Li Li, Rui Chen, Tong Xu", "title": "Offline Meta-level Model-based Reinforcement Learning Approach for\n  Cold-Start Recommendation", "comments": "Accepted to Offline Reinforcement Learning Workshop at Neural\n  Information Processing Systems (2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning (RL) has shown great promise in optimizing long-term\nuser interest in recommender systems. However, existing RL-based recommendation\nmethods need a large number of interactions for each user to learn a robust\nrecommendation policy. The challenge becomes more critical when recommending to\nnew users who have a limited number of interactions. To that end, in this\npaper, we address the cold-start challenge in the RL-based recommender systems\nby proposing a meta-level model-based reinforcement learning approach for fast\nuser adaptation. In our approach, we learn to infer each user's preference with\na user context variable that enables recommendation systems to better adapt to\nnew users with few interactions. To improve adaptation efficiency, we learn to\nrecover the user policy and reward from only a few interactions via an inverse\nreinforcement learning method to assist a meta-level recommendation agent.\nMoreover, we model the interaction relationship between the user model and\nrecommendation agent from an information-theoretic perspective. Empirical\nresults show the effectiveness of the proposed method when adapting to new\nusers with only a single interaction sequence. We further provide a theoretical\nanalysis of the recommendation performance bound.\n", "versions": [{"version": "v1", "created": "Fri, 4 Dec 2020 08:58:35 GMT"}], "update_date": "2020-12-07", "authors_parsed": [["Wang", "Yanan", ""], ["Ge", "Yong", ""], ["Li", "Li", ""], ["Chen", "Rui", ""], ["Xu", "Tong", ""]]}, {"id": "2012.02486", "submitter": "Jiarong Xu", "authors": "Jiarong Xu, Yang Yang, Junru Chen, Chunping Wang, Xin Jiang, Jiangang\n  Lu, Yizhou Sun", "title": "Unsupervised Adversarially-Robust Representation Learning on Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Unsupervised/self-supervised pre-training methods for graph representation\nlearning have recently attracted increasing research interests, and they are\nshown to be able to generalize to various downstream applications. Yet, the\nadversarial robustness of such pre-trained graph learning models remains\nlargely unexplored. More importantly, most existing defense techniques designed\nfor end-to-end graph representation learning methods require pre-specified\nlabel definitions, and thus cannot be directly applied to the pre-training\nmethods. In this paper, we propose an unsupervised defense technique to\nrobustify pre-trained deep graph models, so that the perturbations on the input\ngraph can be successfully identified and blocked before the model is applied to\ndifferent downstream tasks. Specifically, we introduce a mutual\ninformation-based measure, \\textit{graph representation vulnerability (GRV)},\nto quantify the robustness of graph encoders on the representation space. We\nthen formulate an optimization problem to learn the graph representation by\ncarefully balancing the trade-off between the expressive power and the\nrobustness (\\emph{i.e.}, GRV) of the graph encoder. The discrete nature of\ngraph topology and the joint space of graph data make the optimization problem\nintractable to solve. To handle the above difficulty and to reduce\ncomputational expense, we further relax the problem and thus provide an\napproximate solution. Additionally, we explore a provable connection between\nthe robustness of the unsupervised graph encoder and that of models on\ndownstream tasks. Extensive experiments demonstrate that even without access to\nlabels and tasks, our model is still able to enhance robustness against\nadversarial attacks on three downstream tasks (node classification, link\nprediction, and community detection) by an average of +16.5% compared with\nexisting methods.\n", "versions": [{"version": "v1", "created": "Fri, 4 Dec 2020 09:29:16 GMT"}, {"version": "v2", "created": "Fri, 28 May 2021 13:05:06 GMT"}], "update_date": "2021-05-31", "authors_parsed": [["Xu", "Jiarong", ""], ["Yang", "Yang", ""], ["Chen", "Junru", ""], ["Wang", "Chunping", ""], ["Jiang", "Xin", ""], ["Lu", "Jiangang", ""], ["Sun", "Yizhou", ""]]}, {"id": "2012.02527", "submitter": "Alessandro Sestini", "authors": "Alessandro Sestini, Alexander Kuhnle and Andrew D. Bagdanov", "title": "Demonstration-efficient Inverse Reinforcement Learning in Procedurally\n  Generated Environments", "comments": "Presented at the AAAI-21 Workshop on Reinforcement Learning in Games", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Reinforcement Learning achieves very good results in domains where\nreward functions can be manually engineered. At the same time, there is growing\ninterest within the community in using games based on Procedurally Content\nGeneration (PCG) as benchmark environments since this type of environment is\nperfect for studying overfitting and generalization of agents under domain\nshift. Inverse Reinforcement Learning (IRL) can instead extrapolate reward\nfunctions from expert demonstrations, with good results even on\nhigh-dimensional problems, however there are no examples of applying these\ntechniques to procedurally-generated environments. This is mostly due to the\nnumber of demonstrations needed to find a good reward model. We propose a\ntechnique based on Adversarial Inverse Reinforcement Learning which can\nsignificantly decrease the need for expert demonstrations in PCG games. Through\nthe use of an environment with a limited set of initial seed levels, plus some\nmodifications to stabilize training, we show that our approach, DE-AIRL, is\ndemonstration-efficient and still able to extrapolate reward functions which\ngeneralize to the fully procedural domain. We demonstrate the effectiveness of\nour technique on two procedural environments, MiniGrid and DeepCrawl, for a\nvariety of tasks.\n", "versions": [{"version": "v1", "created": "Fri, 4 Dec 2020 11:18:02 GMT"}], "update_date": "2020-12-07", "authors_parsed": [["Sestini", "Alessandro", ""], ["Kuhnle", "Alexander", ""], ["Bagdanov", "Andrew D.", ""]]}, {"id": "2012.02532", "submitter": "Alper Ahmeto\\u{g}lu", "authors": "Alper Ahmetoglu, M. Yunus Seker, Justus Piater, Erhan Oztop, Emre Ugur", "title": "DeepSym: Deep Symbol Generation and Rule Learning from Unsupervised\n  Continuous Robot Interaction for Planning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Autonomous discovery of discrete symbols and rules from continuous\ninteraction experience is a crucial building block of robot AI, but remains a\nchallenging problem. Solving it will overcome the limitations in scalability,\nflexibility, and robustness of manually-designed symbols and rules, and will\nconstitute a substantial advance towards autonomous robots that can learn and\nreason at abstract levels in open-ended environments. Towards this goal, we\npropose a novel and general method that finds action-grounded, discrete object\nand effect categories and builds probabilistic rules over them that can be used\nin complex action planning. Our robot interacts with single and multiple\nobjects using a given action repertoire and observes the effects created in the\nenvironment. In order to form action-grounded object, effect, and relational\ncategories, we employ a binarized bottleneck layer of a predictive, deep\nencoder-decoder network that takes as input the image of the scene and the\naction applied, and generates the resulting object displacements in the scene\n(action effects) in pixel coordinates. The binary latent vector represents a\nlearned, action-driven categorization of objects. To distill the knowledge\nrepresented by the neural network into rules useful for symbolic reasoning, we\ntrain a decision tree to reproduce its decoder function. From its branches we\nextract probabilistic rules and represent them in PPDDL, allowing off-the-shelf\nplanners to operate on the robot's sensorimotor experience. Our system is\nverified in a physics-based 3d simulation environment where a robot arm-hand\nsystem learned symbols that can be interpreted as 'rollable', 'insertable',\n'larger-than' from its push and stack actions; and generated effective plans to\nachieve goals such as building towers from given cubes, balls, and cups using\noff-the-shelf probabilistic planners.\n", "versions": [{"version": "v1", "created": "Fri, 4 Dec 2020 11:26:06 GMT"}, {"version": "v2", "created": "Fri, 18 Jun 2021 21:38:53 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Ahmetoglu", "Alper", ""], ["Seker", "M. Yunus", ""], ["Piater", "Justus", ""], ["Oztop", "Erhan", ""], ["Ugur", "Emre", ""]]}, {"id": "2012.02592", "submitter": "Nadisha-Marie Aliman", "authors": "Nadisha-Marie Aliman, Leon Kester, and Roman Yampolskiy", "title": "Transdisciplinary AI Observatory -- Retrospective Analyses and\n  Future-Oriented Contradistinctions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the last years, AI safety gained international recognition in the light of\nheterogeneous safety-critical and ethical issues that risk overshadowing the\nbroad beneficial impacts of AI. In this context, the implementation of AI\nobservatory endeavors represents one key research direction. This paper\nmotivates the need for an inherently transdisciplinary AI observatory approach\nintegrating diverse retrospective and counterfactual views. We delineate aims\nand limitations while providing hands-on-advice utilizing concrete practical\nexamples. Distinguishing between unintentionally and intentionally triggered AI\nrisks with diverse socio-psycho-technological impacts, we exemplify a\nretrospective descriptive analysis followed by a retrospective counterfactual\nrisk analysis. Building on these AI observatory tools, we present near-term\ntransdisciplinary guidelines for AI safety. As further contribution, we discuss\ndifferentiated and tailored long-term directions through the lens of two\ndisparate modern AI safety paradigms. For simplicity, we refer to these two\ndifferent paradigms with the terms artificial stupidity (AS) and eternal\ncreativity (EC) respectively. While both AS and EC acknowledge the need for a\nhybrid cognitive-affective approach to AI safety and overlap with regard to\nmany short-term considerations, they differ fundamentally in the nature of\nmultiple envisaged long-term solution patterns. By compiling relevant\nunderlying contradistinctions, we aim to provide future-oriented incentives for\nconstructive dialectics in practical and theoretical AI safety research.\n", "versions": [{"version": "v1", "created": "Thu, 26 Nov 2020 16:01:49 GMT"}, {"version": "v2", "created": "Mon, 7 Dec 2020 02:23:13 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Aliman", "Nadisha-Marie", ""], ["Kester", "Leon", ""], ["Yampolskiy", "Roman", ""]]}, {"id": "2012.02619", "submitter": "Mohamed-Bachir Belaid", "authors": "Christian Bessiere, Mohamed-Bachir Belaid, Nadjib Lazaar", "title": "Computational Complexity of Three Central Problems in Itemset Mining", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.AI cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Itemset mining is one of the most studied tasks in knowledge discovery. In\nthis paper we analyze the computational complexity of three central itemset\nmining problems. We prove that mining confident rules with a given item in the\nhead is NP-hard. We prove that mining high utility itemsets is NP-hard. We\nfinally prove that mining maximal or closed itemsets is coNP-hard as soon as\nthe users can specify constraints on the kind of itemsets they are interested\nin.\n", "versions": [{"version": "v1", "created": "Fri, 4 Dec 2020 14:26:21 GMT"}, {"version": "v2", "created": "Mon, 7 Dec 2020 09:57:19 GMT"}, {"version": "v3", "created": "Tue, 8 Dec 2020 11:17:14 GMT"}], "update_date": "2020-12-09", "authors_parsed": [["Bessiere", "Christian", ""], ["Belaid", "Mohamed-Bachir", ""], ["Lazaar", "Nadjib", ""]]}, {"id": "2012.02640", "submitter": "Diego Elias Costa", "authors": "Ahmad Abdellatif, Khaled Badran, Diego Elias Costa, and Emad Shihab", "title": "A Comparison of Natural Language Understanding Platforms for Chatbots in\n  Software Engineering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Chatbots are envisioned to dramatically change the future of Software\nEngineering, allowing practitioners to chat and inquire about their software\nprojects and interact with different services using natural language. At the\nheart of every chatbot is a Natural Language Understanding (NLU) component that\nenables the chatbot to understand natural language input. Recently, many NLU\nplatforms were provided to serve as an off-the-shelf NLU component for\nchatbots, however, selecting the best NLU for Software Engineering chatbots\nremains an open challenge.\n  Therefore, in this paper, we evaluate four of the most commonly used NLUs,\nnamely IBM Watson, Google Dialogflow, Rasa, and Microsoft LUIS to shed light on\nwhich NLU should be used in Software Engineering based chatbots. Specifically,\nwe examine the NLUs' performance in classifying intents, confidence scores\nstability, and extracting entities. To evaluate the NLUs, we use two datasets\nthat reflect two common tasks performed by Software Engineering practitioners,\n1) the task of chatting with the chatbot to ask questions about software\nrepositories 2) the task of asking development questions on Q&A forums (e.g.,\nStack Overflow). According to our findings, IBM Watson is the best performing\nNLU when considering the three aspects (intents classification, confidence\nscores, and entity extraction). However, the results from each individual\naspect show that, in intents classification, IBM Watson performs the best with\nan F1-measure > 84%, but in confidence scores, Rasa comes on top with a median\nconfidence score higher than 0.91. Our results also show that all NLUs, except\nfor Dialogflow, generally provide trustable confidence scores. For entity\nextraction, Microsoft LUIS and IBM Watson outperform other NLUs in the two SE\ntasks. Our results provide guidance to software engineering practitioners when\ndeciding which NLU to use in their chatbots.\n", "versions": [{"version": "v1", "created": "Fri, 4 Dec 2020 14:59:08 GMT"}, {"version": "v2", "created": "Thu, 22 Jul 2021 13:32:53 GMT"}], "update_date": "2021-07-23", "authors_parsed": [["Abdellatif", "Ahmad", ""], ["Badran", "Khaled", ""], ["Costa", "Diego Elias", ""], ["Shihab", "Emad", ""]]}, {"id": "2012.02659", "submitter": "Shriraj Sawant", "authors": "Shriraj P. Sawant and Shruti Singh", "title": "Understanding Attention: In Minds and Machines", "comments": "Accepted at NeurIPS 2020 Workshop: ML Retrospectives, Surveys &\n  Meta-Analyses (ML-RSA)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Attention is a complex and broad concept, studied across multiple disciplines\nspanning artificial intelligence, cognitive science, psychology, neuroscience,\nand related fields. Although many of the ideas regarding attention do not\nsignificantly overlap among these fields, there is a common theme of adaptive\ncontrol of limited resources. In this work, we review the concept and variants\nof attention in artificial neural networks (ANNs). We also discuss the origin\nof attention from the neuroscience point of view parallel to that of ANNs.\nInstead of having seemingly disconnected dialogues between varied disciplines,\nwe suggest grounding the ideas on common conceptual frameworks for a systematic\nanalysis of attention and towards possible unification of ideas in AI and\nNeuroscience.\n", "versions": [{"version": "v1", "created": "Fri, 4 Dec 2020 15:35:17 GMT"}], "update_date": "2020-12-07", "authors_parsed": [["Sawant", "Shriraj P.", ""], ["Singh", "Shruti", ""]]}, {"id": "2012.02671", "submitter": "Adrian Hutter", "authors": "Adrian Hutter", "title": "Learning in two-player games between transparent opponents", "comments": "26 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.GT cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We consider a scenario in which two reinforcement learning agents repeatedly\nplay a matrix game against each other and update their parameters after each\nround. The agents' decision-making is transparent to each other, which allows\neach agent to predict how their opponent will play against them. To prevent an\ninfinite regress of both agents recursively predicting each other indefinitely,\neach agent is required to give an opponent-independent response with some\nprobability at least epsilon. Transparency also allows each agent to anticipate\nand shape the other agent's gradient step, i.e. to move to regions of parameter\nspace in which the opponent's gradient points in a direction favourable to\nthem. We study the resulting dynamics experimentally, using two algorithms from\nprevious literature (LOLA and SOS) for opponent-aware learning. We find that\nthe combination of mutually transparent decision-making and opponent-aware\nlearning robustly leads to mutual cooperation in a single-shot prisoner's\ndilemma. In a game of chicken, in which both agents try to manoeuvre their\nopponent towards their preferred equilibrium, converging to a mutually\nbeneficial outcome turns out to be much harder, and opponent-aware learning can\neven lead to worst-case outcomes for both agents. This highlights the need to\ndevelop opponent-aware learning algorithms that achieve acceptable outcomes in\nsocial dilemmas involving an equilibrium selection problem.\n", "versions": [{"version": "v1", "created": "Fri, 4 Dec 2020 15:41:07 GMT"}], "update_date": "2020-12-07", "authors_parsed": [["Hutter", "Adrian", ""]]}, {"id": "2012.02672", "submitter": "Ji Eun Kim", "authors": "Ji Eun Kim, Cory Henson, Kevin Huang, Tuan A. Tran, Wan-Yi Lin", "title": "Accelerating Road Sign Ground Truth Construction with Knowledge Graph\n  and Machine Learning", "comments": "12 pages, 5 figures", "journal-ref": "Computing Conference 2021", "doi": null, "report-no": null, "categories": "cs.AI cs.CV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Having a comprehensive, high-quality dataset of road sign annotation is\ncritical to the success of AI-based Road Sign Recognition (RSR) systems. In\npractice, annotators often face difficulties in learning road sign systems of\ndifferent countries; hence, the tasks are often time-consuming and produce poor\nresults. We propose a novel approach using knowledge graphs and a machine\nlearning algorithm - variational prototyping-encoder (VPE) - to assist human\nannotators in classifying road signs effectively. Annotators can query the Road\nSign Knowledge Graph using visual attributes and receive closest matching\ncandidates suggested by the VPE model. The VPE model uses the candidates from\nthe knowledge graph and a real sign image patch as inputs. We show that our\nknowledge graph approach can reduce sign search space by 98.9%. Furthermore,\nwith VPE, our system can propose the correct single candidate for 75% of signs\nin the tested datasets, eliminating the human search effort entirely in those\ncases.\n", "versions": [{"version": "v1", "created": "Fri, 4 Dec 2020 15:42:08 GMT"}], "update_date": "2020-12-07", "authors_parsed": [["Kim", "Ji Eun", ""], ["Henson", "Cory", ""], ["Huang", "Kevin", ""], ["Tran", "Tuan A.", ""], ["Lin", "Wan-Yi", ""]]}, {"id": "2012.02681", "submitter": "Noseong Park", "authors": "Jungeun Kim, Kookjin Lee, Dongeun Lee, Sheo Yon Jin, Noseong Park", "title": "DPM: A Novel Training Method for Physics-Informed Neural Networks in\n  Extrapolation", "comments": "Accepted by AAAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a method for learning dynamics of complex physical processes\ndescribed by time-dependent nonlinear partial differential equations (PDEs).\nOur particular interest lies in extrapolating solutions in time beyond the\nrange of temporal domain used in training. Our choice for a baseline method is\nphysics-informed neural network (PINN) [Raissi et al., J. Comput. Phys.,\n378:686--707, 2019] because the method parameterizes not only the solutions but\nalso the equations that describe the dynamics of physical processes. We\ndemonstrate that PINN performs poorly on extrapolation tasks in many benchmark\nproblems. To address this, we propose a novel method for better training PINN\nand demonstrate that our newly enhanced PINNs can accurately extrapolate\nsolutions in time. Our method shows up to 72% smaller errors than existing\nmethods in terms of the standard L2-norm metric.\n", "versions": [{"version": "v1", "created": "Fri, 4 Dec 2020 15:53:06 GMT"}], "update_date": "2020-12-07", "authors_parsed": [["Kim", "Jungeun", ""], ["Lee", "Kookjin", ""], ["Lee", "Dongeun", ""], ["Jin", "Sheo Yon", ""], ["Park", "Noseong", ""]]}, {"id": "2012.02684", "submitter": "Arnout Devos", "authors": "Arnout Devos, Yatin Dandi", "title": "Model-Agnostic Learning to Meta-Learn", "comments": "Published in Proceedings of Machine Learning Research, PMLR\n  148:155-175", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a learning algorithm that enables a model to\nquickly exploit commonalities among related tasks from an unseen task\ndistribution, before quickly adapting to specific tasks from that same\ndistribution. We investigate how learning with different task distributions can\nfirst improve adaptability by meta-finetuning on related tasks before improving\ngoal task generalization with finetuning. Synthetic regression experiments\nvalidate the intuition that learning to meta-learn improves adaptability and\nconsecutively generalization. Experiments on more complex image classification,\ncontinual regression, and reinforcement learning tasks demonstrate that\nlearning to meta-learn generally improves task-specific adaptation. The\nmethodology, setup, and hypotheses in this proposal were positively evaluated\nby peer review before conclusive experiments were carried out.\n", "versions": [{"version": "v1", "created": "Fri, 4 Dec 2020 15:55:08 GMT"}, {"version": "v2", "created": "Mon, 19 Jul 2021 19:48:57 GMT"}], "update_date": "2021-07-21", "authors_parsed": [["Devos", "Arnout", ""], ["Dandi", "Yatin", ""]]}, {"id": "2012.02757", "submitter": "Spencer Frazier", "authors": "Sahith Dambekodi, Spencer Frazier, Prithviraj Ammanabrolu, Mark O.\n  Riedl", "title": "Playing Text-Based Games with Common Sense", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Text based games are simulations in which an agent interacts with the world\npurely through natural language. They typically consist of a number of puzzles\ninterspersed with interactions with common everyday objects and locations. Deep\nreinforcement learning agents can learn to solve these puzzles. However, the\neveryday interactions with the environment, while trivial for human players,\npresent as additional puzzles to agents. We explore two techniques for\nincorporating commonsense knowledge into agents. Inferring possibly hidden\naspects of the world state with either a commonsense inference model COMET, or\na language model BERT. Biasing an agents exploration according to common\npatterns recognized by a language model. We test our technique in the 9to05\ngame, which is an extreme version of a text based game that requires numerous\ninteractions with common, everyday objects in common, everyday scenarios. We\nconclude that agents that augment their beliefs about the world state with\ncommonsense inferences are more robust to observational errors and omissions of\ncommon elements from text descriptions.\n", "versions": [{"version": "v1", "created": "Fri, 4 Dec 2020 18:22:59 GMT"}], "update_date": "2020-12-07", "authors_parsed": [["Dambekodi", "Sahith", ""], ["Frazier", "Spencer", ""], ["Ammanabrolu", "Prithviraj", ""], ["Riedl", "Mark O.", ""]]}, {"id": "2012.02763", "submitter": "Boya Yu", "authors": "Boya Yu, Konstantine Arkoudas, Wael Hamza", "title": "Delexicalized Paraphrase Generation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present a neural model for paraphrasing and train it to generate\ndelexicalized sentences. We achieve this by creating training data in which\neach input is paired with a number of reference paraphrases. These sets of\nreference paraphrases represent a weak type of semantic equivalence based on\nannotated slots and intents. To understand semantics from different types of\nslots, other than anonymizing slots, we apply convolutional neural networks\n(CNN) prior to pooling on slot values and use pointers to locate slots in the\noutput. We show empirically that the generated paraphrases are of high quality,\nleading to an additional 1.29% exact match on live utterances. We also show\nthat natural language understanding (NLU) tasks, such as intent classification\nand named entity recognition, can benefit from data augmentation using\nautomatically generated paraphrases.\n", "versions": [{"version": "v1", "created": "Fri, 4 Dec 2020 18:28:30 GMT"}], "update_date": "2020-12-07", "authors_parsed": [["Yu", "Boya", ""], ["Arkoudas", "Konstantine", ""], ["Hamza", "Wael", ""]]}, {"id": "2012.02788", "submitter": "Deepak Pathak", "authors": "Shikhar Bahl, Mustafa Mukadam, Abhinav Gupta, Deepak Pathak", "title": "Neural Dynamic Policies for End-to-End Sensorimotor Learning", "comments": "NeurIPS 2020 (Spotlight). Code and videos at\n  https://shikharbahl.github.io/neural-dynamic-policies/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The current dominant paradigm in sensorimotor control, whether imitation or\nreinforcement learning, is to train policies directly in raw action spaces such\nas torque, joint angle, or end-effector position. This forces the agent to make\ndecisions individually at each timestep in training, and hence, limits the\nscalability to continuous, high-dimensional, and long-horizon tasks. In\ncontrast, research in classical robotics has, for a long time, exploited\ndynamical systems as a policy representation to learn robot behaviors via\ndemonstrations. These techniques, however, lack the flexibility and\ngeneralizability provided by deep learning or reinforcement learning and have\nremained under-explored in such settings. In this work, we begin to close this\ngap and embed the structure of a dynamical system into deep neural\nnetwork-based policies by reparameterizing action spaces via second-order\ndifferential equations. We propose Neural Dynamic Policies (NDPs) that make\npredictions in trajectory distribution space as opposed to prior policy\nlearning methods where actions represent the raw control space. The embedded\nstructure allows end-to-end policy learning for both reinforcement and\nimitation learning setups. We show that NDPs outperform the prior\nstate-of-the-art in terms of either efficiency or performance across several\nrobotic control tasks for both imitation and reinforcement learning setups.\nProject video and code are available at\nhttps://shikharbahl.github.io/neural-dynamic-policies/\n", "versions": [{"version": "v1", "created": "Fri, 4 Dec 2020 18:59:32 GMT"}], "update_date": "2020-12-07", "authors_parsed": [["Bahl", "Shikhar", ""], ["Mukadam", "Mustafa", ""], ["Gupta", "Abhinav", ""], ["Pathak", "Deepak", ""]]}, {"id": "2012.02794", "submitter": "Juhee Bae", "authors": "John Aoga, Juhee Bae, Stefanija Veljanoska, Siegfried Nijssen, Pierre\n  Schaus", "title": "Impact of weather factors on migration intention using machine learning\n  algorithms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "econ.GN cs.AI q-fin.EC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  A growing attention in the empirical literature has been paid to the\nincidence of climate shocks and change in migration decisions. Previous\nliterature leads to different results and uses a multitude of traditional\nempirical approaches.\n  This paper proposes a tree-based Machine Learning (ML) approach to analyze\nthe role of the weather shocks towards an individual's intention to migrate in\nthe six agriculture-dependent-economy countries such as Burkina Faso, Ivory\nCoast, Mali, Mauritania, Niger, and Senegal. We perform several tree-based\nalgorithms (e.g., XGB, Random Forest) using the train-validation-test workflow\nto build robust and noise-resistant approaches. Then we determine the important\nfeatures showing in which direction they are influencing the migration\nintention. This ML-based estimation accounts for features such as weather\nshocks captured by the Standardized Precipitation-Evapotranspiration Index\n(SPEI) for different timescales and various socioeconomic features/covariates.\n  We find that (i) weather features improve the prediction performance although\nsocioeconomic characteristics have more influence on migration intentions, (ii)\ncountry-specific model is necessary, and (iii) international move is influenced\nmore by the longer timescales of SPEIs while general move (which includes\ninternal move) by that of shorter timescales.\n", "versions": [{"version": "v1", "created": "Fri, 4 Dec 2020 16:59:15 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Aoga", "John", ""], ["Bae", "Juhee", ""], ["Veljanoska", "Stefanija", ""], ["Nijssen", "Siegfried", ""], ["Schaus", "Pierre", ""]]}, {"id": "2012.02811", "submitter": "Jaelle Scheuerman", "authors": "Jaelle Scheuerman, Jason Harman, Nicholas Mattei, K. Brent Venable", "title": "Modeling Voters in Multi-Winner Approval Voting", "comments": "9 pages, 4 figures. To be published in the Proceedings of the\n  Thirty-Fifth AAAI Conference on Artificial Intelligence, AAAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many real world situations, collective decisions are made using voting\nand, in scenarios such as committee or board elections, employing voting rules\nthat return multiple winners. In multi-winner approval voting (AV), an agent\nsubmits a ballot consisting of approvals for as many candidates as they wish,\nand winners are chosen by tallying up the votes and choosing the top-$k$\ncandidates receiving the most approvals. In many scenarios, an agent may\nmanipulate the ballot they submit in order to achieve a better outcome by\nvoting in a way that does not reflect their true preferences. In complex and\nuncertain situations, agents may use heuristics instead of incurring the\nadditional effort required to compute the manipulation which most favors them.\nIn this paper, we examine voting behavior in single-winner and multi-winner\napproval voting scenarios with varying degrees of uncertainty using behavioral\ndata obtained from Mechanical Turk. We find that people generally manipulate\ntheir vote to obtain a better outcome, but often do not identify the optimal\nmanipulation. There are a number of predictive models of agent behavior in the\nCOMSOC and psychology literature that are based on cognitively plausible\nheuristic strategies. We show that the existing approaches do not adequately\nmodel real-world data. We propose a novel model that takes into account the\nsize of the winning set and human cognitive constraints, and demonstrate that\nthis model is more effective at capturing real-world behaviors in multi-winner\napproval voting scenarios.\n", "versions": [{"version": "v1", "created": "Fri, 4 Dec 2020 19:24:28 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Scheuerman", "Jaelle", ""], ["Harman", "Jason", ""], ["Mattei", "Nicholas", ""], ["Venable", "K. Brent", ""]]}, {"id": "2012.02813", "submitter": "Paul Pu Liang", "authors": "Paul Pu Liang, Peter Wu, Liu Ziyin, Louis-Philippe Morency, Ruslan\n  Salakhutdinov", "title": "Cross-Modal Generalization: Learning in Low Resource Modalities via\n  Meta-Alignment", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The natural world is abundant with concepts expressed via visual, acoustic,\ntactile, and linguistic modalities. Much of the existing progress in multimodal\nlearning, however, focuses primarily on problems where the same set of\nmodalities are present at train and test time, which makes learning in\nlow-resource modalities particularly difficult. In this work, we propose\nalgorithms for cross-modal generalization: a learning paradigm to train a model\nthat can (1) quickly perform new tasks in a target modality (i.e.\nmeta-learning) and (2) doing so while being trained on a different source\nmodality. We study a key research question: how can we ensure generalization\nacross modalities despite using separate encoders for different source and\ntarget modalities? Our solution is based on meta-alignment, a novel method to\nalign representation spaces using strongly and weakly paired cross-modal data\nwhile ensuring quick generalization to new tasks across different modalities.\nWe study this problem on 3 classification tasks: text to image, image to audio,\nand text to speech. Our results demonstrate strong performance even when the\nnew target modality has only a few (1-10) labeled samples and in the presence\nof noisy labels, a scenario particularly prevalent in low-resource modalities.\n", "versions": [{"version": "v1", "created": "Fri, 4 Dec 2020 19:27:26 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Liang", "Paul Pu", ""], ["Wu", "Peter", ""], ["Ziyin", "Liu", ""], ["Morency", "Louis-Philippe", ""], ["Salakhutdinov", "Ruslan", ""]]}, {"id": "2012.02825", "submitter": "Massimiliano Luca", "authors": "Massimiliano Luca, Gianni Barlacchi, Bruno Lepri, Luca Pappalardo", "title": "A Survey on Deep Learning for Human Mobility", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.GL cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The study of human mobility is crucial due to its impact on several aspects\nof our society, such as disease spreading, urban planning, well-being,\npollution, and more. The proliferation of digital mobility data, such as phone\nrecords, GPS traces, and social media posts, combined with the predictive power\nof artificial intelligence, triggered the application of deep learning to human\nmobility. Existing surveys focus on single tasks, data sources, mechanistic or\ntraditional machine learning approaches, while a comprehensive description of\ndeep learning solutions is missing. This survey provides a taxonomy of mobility\ntasks, a discussion on the challenges related to each task and how deep\nlearning may overcome the limitations of traditional models, a description of\nthe most relevant solutions to the mobility tasks described above and the\nrelevant challenges for the future. Our survey is a guide to the leading deep\nlearning solutions to next-location prediction, crowd flow prediction,\ntrajectory generation, and flow generation. At the same time, it helps deep\nlearning scientists and practitioners understand the fundamental concepts and\nthe open challenges of the study of human mobility.\n", "versions": [{"version": "v1", "created": "Fri, 4 Dec 2020 19:59:39 GMT"}, {"version": "v2", "created": "Sun, 27 Jun 2021 09:36:49 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Luca", "Massimiliano", ""], ["Barlacchi", "Gianni", ""], ["Lepri", "Bruno", ""], ["Pappalardo", "Luca", ""]]}, {"id": "2012.02840", "submitter": "Ziqi Chen", "authors": "Ziqi Chen, Martin Renqiang Min and Xia Ning", "title": "Ranking-based Convolutional Neural Network Models for Peptide-MHC\n  Binding Prediction", "comments": "17 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  T-cell receptors can recognize foreign peptides bound to major\nhistocompatibility complex (MHC) class-I proteins, and thus trigger the\nadaptive immune response. Therefore, identifying peptides that can bind to MHC\nclass-I molecules plays a vital role in the design of peptide vaccines. Many\ncomputational methods, for example, the state-of-the-art allele-specific method\nMHCflurry, have been developed to predict the binding affinities between\npeptides and MHC molecules. In this manuscript, we develop two allele-specific\nConvolutional Neural Network (CNN)-based methods named ConvM and SpConvM to\ntackle the binding prediction problem. Specifically, we formulate the problem\nas to optimize the rankings of peptide-MHC bindings via ranking-based learning\nobjectives. Such optimization is more robust and tolerant to the measurement\ninaccuracy of binding affinities, and therefore enables more accurate\nprioritization of binding peptides. In addition, we develop a new position\nencoding method in ConvM and SpConvM to better identify the most important\namino acids for the binding events. Our experimental results demonstrate that\nour models significantly outperform the state-of-the-art methods including\nMHCflurry with an average percentage improvement of 6.70% on AUC and 17.10% on\nROC5 across 128 alleles.\n", "versions": [{"version": "v1", "created": "Fri, 4 Dec 2020 20:40:36 GMT"}, {"version": "v2", "created": "Tue, 8 Dec 2020 04:18:20 GMT"}], "update_date": "2020-12-09", "authors_parsed": [["Chen", "Ziqi", ""], ["Min", "Martin Renqiang", ""], ["Ning", "Xia", ""]]}, {"id": "2012.02903", "submitter": "Christine Allen-Blanchette", "authors": "Christine Allen-Blanchette and Kostas Daniilidis", "title": "Joint Estimation of Image Representations and their Lie Invariants", "comments": "Resolves typographical errors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Images encode both the state of the world and its content. The former is\nuseful for tasks such as planning and control, and the latter for\nclassification. The automatic extraction of this information is challenging\nbecause of the high-dimensionality and entangled encoding inherent to the image\nrepresentation. This article introduces two theoretical approaches aimed at the\nresolution of these challenges. The approaches allow for the interpolation and\nextrapolation of images from an image sequence by joint estimation of the image\nrepresentation and the generators of the sequence dynamics. In the first\napproach, the image representations are learned using probabilistic PCA\n\\cite{tipping1999probabilistic}. The linear-Gaussian conditional distributions\nallow for a closed form analytical description of the latent distributions but\nassumes the underlying image manifold is a linear subspace. In the second\napproach, the image representations are learned using probabilistic nonlinear\nPCA which relieves the linear manifold assumption at the cost of requiring a\nvariational approximation of the latent distributions. In both approaches, the\nunderlying dynamics of the image sequence are modelled explicitly to\ndisentangle them from the image representations. The dynamics themselves are\nmodelled with Lie group structure which enforces the desirable properties of\nsmoothness and composability of inter-image transformations.\n", "versions": [{"version": "v1", "created": "Sat, 5 Dec 2020 00:07:41 GMT"}, {"version": "v2", "created": "Tue, 8 Dec 2020 13:28:42 GMT"}], "update_date": "2020-12-09", "authors_parsed": [["Allen-Blanchette", "Christine", ""], ["Daniilidis", "Kostas", ""]]}, {"id": "2012.02904", "submitter": "Jason Wilson", "authors": "Jason R. Wilson, Leilani Gilpin, Irina Rabkina", "title": "A Knowledge Driven Approach to Adaptive Assistance Using Preference\n  Reasoning and Explanation", "comments": "Accepted for presentation at the AAAI 2020 Fall Symposium Series, in\n  the symposium for Artificial Intelligence for Human-Robot Interaction: Trust\n  & Explainability in Artificial Intelligence for Human-Robot Interaction", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is a need for socially assistive robots (SARs) to provide transparency\nin their behavior by explaining their reasoning. Additionally, the reasoning\nand explanation should represent the user's preferences and goals. To work\ntowards satisfying this need for interpretable reasoning and representations,\nwe propose the robot uses Analogical Theory of Mind to infer what the user is\ntrying to do and uses the Hint Engine to find an appropriate assistance based\non what the user is trying to do. If the user is unsure or confused, the robot\nprovides the user with an explanation, generated by the Explanation\nSynthesizer. The explanation helps the user understand what the robot inferred\nabout the user's preferences and why the robot decided to provide the\nassistance it gave. A knowledge-driven approach provides transparency to\nreasoning about preferences, assistance, and explanations, thereby facilitating\nthe incorporation of user feedback and allowing the robot to learn and adapt to\nthe user.\n", "versions": [{"version": "v1", "created": "Sat, 5 Dec 2020 00:18:43 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Wilson", "Jason R.", ""], ["Gilpin", "Leilani", ""], ["Rabkina", "Irina", ""]]}, {"id": "2012.02909", "submitter": "Huan Wang", "authors": "Huan Wang, Suhas Lohit, Michael Jones, Yun Fu", "title": "Knowledge Distillation Thrives on Data Augmentation", "comments": "Code will be updated soon", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge distillation (KD) is a general deep neural network training\nframework that uses a teacher model to guide a student model. Many works have\nexplored the rationale for its success, however, its interplay with data\naugmentation (DA) has not been well recognized so far. In this paper, we are\nmotivated by an interesting observation in classification: KD loss can benefit\nfrom extended training iterations while the cross-entropy loss does not. We\nshow this disparity arises because of data augmentation: KD loss can tap into\nthe extra information from different input views brought by DA. By this\nexplanation, we propose to enhance KD via a stronger data augmentation scheme\n(e.g., mixup, CutMix). Furthermore, an even stronger new DA approach is\ndeveloped specifically for KD based on the idea of active learning. The\nfindings and merits of the proposed method are validated by extensive\nexperiments on CIFAR-100, Tiny ImageNet, and ImageNet datasets. We can achieve\nimproved performance simply by using the original KD loss combined with\nstronger augmentation schemes, compared to existing state-of-the-art methods,\nwhich employ more advanced distillation losses. In addition, when our\napproaches are combined with more advanced distillation losses, we can advance\nthe state-of-the-art performance even more. On top of the encouraging\nperformance, this paper also sheds some light on explaining the success of\nknowledge distillation. The discovered interplay between KD and DA may inspire\nmore advanced KD algorithms.\n", "versions": [{"version": "v1", "created": "Sat, 5 Dec 2020 00:32:04 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Wang", "Huan", ""], ["Lohit", "Suhas", ""], ["Jones", "Michael", ""], ["Fu", "Yun", ""]]}, {"id": "2012.02911", "submitter": "Huan Wang", "authors": "Huan Wang, Suhas Lohit, Michael Jones, Yun Fu", "title": "Multi-head Knowledge Distillation for Model Compression", "comments": "Copyright: 2020 IEEE. Personal use of this material is permitted.\n  Permission from IEEE must be obtained for all other uses, in any current or\n  future media, including reprinting/republishing this material for advertising\n  or promotional purposes, creating new collective works, for resale or\n  redistribution to servers or lists, or reuse of any copyrighted component of\n  this work in other works", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Several methods of knowledge distillation have been developed for neural\nnetwork compression. While they all use the KL divergence loss to align the\nsoft outputs of the student model more closely with that of the teacher, the\nvarious methods differ in how the intermediate features of the student are\nencouraged to match those of the teacher. In this paper, we propose a\nsimple-to-implement method using auxiliary classifiers at intermediate layers\nfor matching features, which we refer to as multi-head knowledge distillation\n(MHKD). We add loss terms for training the student that measure the\ndissimilarity between student and teacher outputs of the auxiliary classifiers.\nAt the same time, the proposed method also provides a natural way to measure\ndifferences at the intermediate layers even though the dimensions of the\ninternal teacher and student features may be different. Through several\nexperiments in image classification on multiple datasets we show that the\nproposed method outperforms prior relevant approaches presented in the\nliterature.\n", "versions": [{"version": "v1", "created": "Sat, 5 Dec 2020 00:49:14 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Wang", "Huan", ""], ["Lohit", "Suhas", ""], ["Jones", "Michael", ""], ["Fu", "Yun", ""]]}, {"id": "2012.02924", "submitter": "Bokui Shen", "authors": "Bokui Shen, Fei Xia, Chengshu Li, Roberto Mart\\'in-Mart\\'in, Linxi\n  Fan, Guanzhi Wang, Claudia P\\'erez-D'Arpino, Shyamal Buch, Sanjana\n  Srivastava, Lyne P. Tchapmi, Micael E. Tchapmi, Kent Vainio, Li Fei-Fei,\n  Silvio Savarese", "title": "iGibson 1.0: a Simulation Environment for Interactive Tasks in Large\n  Realistic Scenes", "comments": null, "journal-ref": "2021 IEEE/RSJ International Conference on Intelligent Robots and\n  Systems (IROS 2021)", "doi": null, "report-no": null, "categories": "cs.AI cs.CV cs.RO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present iGibson 1.0, a novel simulation environment to develop robotic\nsolutions for interactive tasks in large-scale realistic scenes. Our\nenvironment contains 15 fully interactive home-sized scenes with 108 rooms\npopulated with rigid and articulated objects. The scenes are replicas of\nreal-world homes, with distribution and the layout of objects aligned to those\nof the real world. iGibson 1.0 integrates several key features to facilitate\nthe study of interactive tasks: i) generation of high-quality virtual sensor\nsignals (RGB, depth, segmentation, LiDAR, flow and so on), ii) domain\nrandomization to change the materials of the objects (both visual and physical)\nand/or their shapes, iii) integrated sampling-based motion planners to generate\ncollision-free trajectories for robot bases and arms, and iv) intuitive\nhuman-iGibson interface that enables efficient collection of human\ndemonstrations. Through experiments, we show that the full interactivity of the\nscenes enables agents to learn useful visual representations that accelerate\nthe training of downstream manipulation tasks. We also show that iGibson 1.0\nfeatures enable the generalization of navigation agents, and that the\nhuman-iGibson interface and integrated motion planners facilitate efficient\nimitation learning of human demonstrated (mobile) manipulation behaviors.\niGibson 1.0 is open-source, equipped with comprehensive examples and\ndocumentation. For more information, visit our project website:\nhttp://svl.stanford.edu/igibson/\n", "versions": [{"version": "v1", "created": "Sat, 5 Dec 2020 02:14:17 GMT"}, {"version": "v2", "created": "Tue, 8 Dec 2020 02:44:59 GMT"}, {"version": "v3", "created": "Thu, 8 Jul 2021 20:45:12 GMT"}, {"version": "v4", "created": "Mon, 19 Jul 2021 21:24:52 GMT"}], "update_date": "2021-07-21", "authors_parsed": [["Shen", "Bokui", ""], ["Xia", "Fei", ""], ["Li", "Chengshu", ""], ["Mart\u00edn-Mart\u00edn", "Roberto", ""], ["Fan", "Linxi", ""], ["Wang", "Guanzhi", ""], ["P\u00e9rez-D'Arpino", "Claudia", ""], ["Buch", "Shyamal", ""], ["Srivastava", "Sanjana", ""], ["Tchapmi", "Lyne P.", ""], ["Tchapmi", "Micael E.", ""], ["Vainio", "Kent", ""], ["Fei-Fei", "Li", ""], ["Savarese", "Silvio", ""]]}, {"id": "2012.02939", "submitter": "Tunazzina Islam", "authors": "Tunazzina Islam, Dan Goldwasser", "title": "Does Yoga Make You Happy? Analyzing Twitter User Happiness using Textual\n  and Temporal Information", "comments": "accepted at IEEE BigData 2020", "journal-ref": null, "doi": "10.1109/BigData50022.2020.9378461", "report-no": null, "categories": "cs.CL cs.AI cs.CY cs.LG cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although yoga is a multi-component practice to hone the body and mind and be\nknown to reduce anxiety and depression, there is still a gap in understanding\npeople's emotional state related to yoga in social media. In this study, we\ninvestigate the causal relationship between practicing yoga and being happy by\nincorporating textual and temporal information of users using Granger\ncausality. To find out causal features from the text, we measure two variables\n(i) Yoga activity level based on content analysis and (ii) Happiness level\nbased on emotional state. To understand users' yoga activity, we propose a\njoint embedding model based on the fusion of neural networks with attention\nmechanism by leveraging users' social and textual information. For measuring\nthe emotional state of yoga users (target domain), we suggest a transfer\nlearning approach to transfer knowledge from an attention-based neural network\nmodel trained on a source domain. Our experiment on Twitter dataset\ndemonstrates that there are 1447 users where \"yoga Granger-causes happiness\".\n", "versions": [{"version": "v1", "created": "Sat, 5 Dec 2020 03:30:49 GMT"}], "update_date": "2021-04-19", "authors_parsed": [["Islam", "Tunazzina", ""], ["Goldwasser", "Dan", ""]]}, {"id": "2012.02947", "submitter": "Nikhil Krishnaswamy", "authors": "Nikhil Krishnaswamy and James Pustejovsky", "title": "Neurosymbolic AI for Situated Language Understanding", "comments": "18 pages + refs, 16 figures, presented at the 8th Annual Conference\n  on Advances in Cognitive Systems (ACS), 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, data-intensive AI, particularly the domain of natural\nlanguage processing and understanding, has seen significant progress driven by\nthe advent of large datasets and deep neural networks that have sidelined more\nclassic AI approaches to the field. These systems can apparently demonstrate\nsophisticated linguistic understanding or generation capabilities, but often\nfail to transfer their skills to situations they have not encountered before.\nWe argue that computational situated grounding provides a solution to some of\nthese learning challenges by creating situational representations that both\nserve as a formal model of the salient phenomena, and contain rich amounts of\nexploitable, task-appropriate data for training new, flexible computational\nmodels. Our model reincorporates some ideas of classic AI into a framework of\nneurosymbolic intelligence, using multimodal contextual modeling of interactive\nsituations, events, and object properties. We discuss how situated grounding\nprovides diverse data and multiple levels of modeling for a variety of AI\nlearning challenges, including learning how to interact with object\naffordances, learning semantics for novel structures and configurations, and\ntransferring such learned knowledge to new objects and situations.\n", "versions": [{"version": "v1", "created": "Sat, 5 Dec 2020 05:03:28 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Krishnaswamy", "Nikhil", ""], ["Pustejovsky", "James", ""]]}, {"id": "2012.02950", "submitter": "Guansong Pang", "authors": "Guansong Pang, Ngoc Thien Anh Pham, Emma Baker, Rebecca Bentley, Anton\n  van den Hengel", "title": "Deep Multi-task Learning for Depression Detection and Prediction in\n  Longitudinal Data", "comments": "9 pages, 3 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CY", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Depression is among the most prevalent mental disorders, affecting millions\nof people of all ages globally. Machine learning techniques have shown\neffective in enabling automated detection and prediction of depression for\nearly intervention and treatment. However, they are challenged by the relative\nscarcity of instances of depression in the data. In this work we introduce a\nnovel deep multi-task recurrent neural network to tackle this challenge, in\nwhich depression classification is jointly optimized with two auxiliary tasks,\nnamely one-class metric learning and anomaly ranking. The auxiliary tasks\nintroduce an inductive bias that improves the classification model's\ngeneralizability on small depression samples. Further, unlike existing studies\nthat focus on learning depression signs from static data without considering\ntemporal dynamics, we focus on longitudinal data because i) temporal changes in\npersonal development and family environment can provide critical cues for\npsychiatric disorders and ii) it may enable us to predict depression before the\nillness actually occurs. Extensive experimental results on child depression\ndata show that our model is able to i) achieve nearly perfect performance in\ndepression detection and ii) accurately predict depression 2-4 years before the\nclinical diagnosis, substantially outperforming seven competing methods.\n", "versions": [{"version": "v1", "created": "Sat, 5 Dec 2020 05:14:14 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Pang", "Guansong", ""], ["Pham", "Ngoc Thien Anh", ""], ["Baker", "Emma", ""], ["Bentley", "Rebecca", ""], ["Hengel", "Anton van den", ""]]}, {"id": "2012.02970", "submitter": "Tingwei Li", "authors": "Tingwei Li, Ruiwen Zhang, Qing Li", "title": "Multi Scale Temporal Graph Networks For Skeleton-based Action\n  Recognition", "comments": null, "journal-ref": "2020,Computer Science & Information Technology (CS & IT)", "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Graph convolutional networks (GCNs) can effectively capture the features of\nrelated nodes and improve the performance of the model. More attention is paid\nto employing GCN in Skeleton-Based action recognition. But existing methods\nbased on GCNs have two problems. First, the consistency of temporal and spatial\nfeatures is ignored for extracting features node by node and frame by frame. To\nobtain spatiotemporal features simultaneously, we design a generic\nrepresentation of skeleton sequences for action recognition and propose a novel\nmodel called Temporal Graph Networks (TGN). Secondly, the adjacency matrix of\nthe graph describing the relation of joints is mostly dependent on the physical\nconnection between joints. To appropriately describe the relations between\njoints in the skeleton graph, we propose a multi-scale graph strategy, adopting\na full-scale graph, part-scale graph, and core-scale graph to capture the local\nfeatures of each joint and the contour features of important joints.\nExperiments were carried out on two large datasets and results show that TGN\nwith our graph strategy outperforms state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Sat, 5 Dec 2020 08:08:25 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Li", "Tingwei", ""], ["Zhang", "Ruiwen", ""], ["Li", "Qing", ""]]}, {"id": "2012.02975", "submitter": "Minkai Xu", "authors": "Minkai Xu, Mingxuan Wang, Zhouhan Lin, Hao Zhou, Weinan Zhang, Lei Li", "title": "Reciprocal Supervised Learning Improves Neural Machine Translation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Despite the recent success on image classification, self-training has only\nachieved limited gains on structured prediction tasks such as neural machine\ntranslation (NMT). This is mainly due to the compositionality of the target\nspace, where the far-away prediction hypotheses lead to the notorious\nreinforced mistake problem. In this paper, we revisit the utilization of\nmultiple diverse models and present a simple yet effective approach named\nReciprocal-Supervised Learning (RSL). RSL first exploits individual models to\ngenerate pseudo parallel data, and then cooperatively trains each model on the\ncombined synthetic corpus. RSL leverages the fact that different parameterized\nmodels have different inductive biases, and better predictions can be made by\njointly exploiting the agreement among each other. Unlike the previous\nknowledge distillation methods built upon a much stronger teacher, RSL is\ncapable of boosting the accuracy of one model by introducing other comparable\nor even weaker models. RSL can also be viewed as a more efficient alternative\nto ensemble. Extensive experiments demonstrate the superior performance of RSL\non several benchmarks with significant margins.\n", "versions": [{"version": "v1", "created": "Sat, 5 Dec 2020 08:23:13 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Xu", "Minkai", ""], ["Wang", "Mingxuan", ""], ["Lin", "Zhouhan", ""], ["Zhou", "Hao", ""], ["Zhang", "Weinan", ""], ["Li", "Lei", ""]]}, {"id": "2012.03002", "submitter": "Hyunsung Lee", "authors": "Hyunsung Lee, Michael Wang and Honguk Woo", "title": "Fixed Priority Global Scheduling from a Deep Learning Perspective", "comments": "4 pages, 2 figures, accepted at 2021 AAAI Workshop on Learning and\n  Reasoning with Complex Graphs as an extended abstract", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Learning has been recently recognized as one of the feasible solutions\nto effectively address combinatorial optimization problems, which are often\nconsidered important yet challenging in various research domains. In this work,\nwe first present how to adopt Deep Learning for real-time task scheduling\nthrough our preliminary work upon fixed priority global scheduling (FPGS)\nproblems. We then briefly discuss possible generalizations of Deep Learning\nadoption for several realistic and complicated FPGS scenarios, e.g., scheduling\ntasks with dependency, mixed-criticality task scheduling. We believe that there\nare many opportunities for leveraging advanced Deep Learning technologies to\nimprove the quality of scheduling in various system configurations and problem\nscenarios.\n", "versions": [{"version": "v1", "created": "Sat, 5 Dec 2020 10:52:33 GMT"}, {"version": "v2", "created": "Mon, 14 Dec 2020 05:09:12 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["Lee", "Hyunsung", ""], ["Wang", "Michael", ""], ["Woo", "Honguk", ""]]}, {"id": "2012.03009", "submitter": "Claire Birnie PhD", "authors": "Claire Birnie and Fredrik Hansteen", "title": "Bidirectional recurrent neural networks for seismic event detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.geo-ph cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Real time, accurate passive seismic event detection is a critical safety\nmeasure across a range of monitoring applications from reservoir stability to\ncarbon storage to volcanic tremor detection. The most common detection\nprocedure remains the Short-Term-Average to Long-Term-Average (STA/LTA) trigger\ndespite its common pitfalls of requiring a signal-to-noise ratio greater than\none and being highly sensitive to the trigger parameters. Whilst numerous\nalternatives have been proposed, they often are tailored to a specific\nmonitoring setting and therefore cannot be globally applied, or they are too\ncomputationally expensive therefore cannot be run real time. This work\nintroduces a deep learning approach to event detection that is an alternative\nto the STA/LTA trigger. A bi-directional, long-short-term memory, neural\nnetwork is trained solely on synthetic traces. Evaluated on synthetic and field\ndata, the neural network approach significantly outperforms the STA/LTA trigger\nboth on the number of correctly detected arrivals as well as on reducing the\nnumber of falsely detected events. Its real time applicability is proven with\n600 traces processed in real time on a single processing unit.\n", "versions": [{"version": "v1", "created": "Sat, 5 Dec 2020 11:41:50 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Birnie", "Claire", ""], ["Hansteen", "Fredrik", ""]]}, {"id": "2012.03040", "submitter": "Yigit Baran Can", "authors": "Yigit Baran Can, Alexander Liniger, Ozan Unal, Danda Paudel, Luc Van\n  Gool", "title": "Understanding Bird's-Eye View Semantic HD-Maps Using an Onboard\n  Monocular Camera", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Autonomous navigation requires scene understanding of the action-space to\nmove or anticipate events. For planner agents moving on the ground plane, such\nas autonomous vehicles, this translates to scene understanding in the\nbird's-eye view. However, the onboard cameras of autonomous cars are\ncustomarily mounted horizontally for a better view of the surrounding. In this\nwork, we study scene understanding in the form of online estimation of semantic\nbird's-eye-view HD-maps using the video input from a single onboard camera. We\nstudy three key aspects of this task, image-level understanding, BEV level\nunderstanding, and the aggregation of temporal information. Based on these\nthree pillars we propose a novel architecture that combines these three\naspects. In our extensive experiments, we demonstrate that the considered\naspects are complementary to each other for HD-map understanding. Furthermore,\nthe proposed architecture significantly surpasses the current state-of-the-art.\n", "versions": [{"version": "v1", "created": "Sat, 5 Dec 2020 14:39:14 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Can", "Yigit Baran", ""], ["Liniger", "Alexander", ""], ["Unal", "Ozan", ""], ["Paudel", "Danda", ""], ["Van Gool", "Luc", ""]]}, {"id": "2012.03057", "submitter": "Kwan Hui Lim Dr", "authors": "Jerome Heng, Junhua Liu and Kwan Hui Lim", "title": "Urban Crowdsensing using Social Media: An Empirical Study on Transformer\n  and Recurrent Neural Networks", "comments": "Accepted at the 2020 IEEE International Conference on Big Data\n  (BigData'20), Poster Track", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  An important aspect of urban planning is understanding crowd levels at\nvarious locations, which typically require the use of physical sensors. Such\nsensors are potentially costly and time consuming to implement on a large\nscale. To address this issue, we utilize publicly available social media\ndatasets and use them as the basis for two urban sensing problems, namely event\ndetection and crowd level prediction. One main contribution of this work is our\ncollected dataset from Twitter and Flickr, alongside ground truth events. We\ndemonstrate the usefulness of this dataset with two preliminary supervised\nlearning approaches: firstly, a series of neural network models to determine if\na social media post is related to an event and secondly a regression model\nusing social media post counts to predict actual crowd levels. We discuss\npreliminary results from these tasks and highlight some challenges.\n", "versions": [{"version": "v1", "created": "Sat, 5 Dec 2020 15:36:50 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Heng", "Jerome", ""], ["Liu", "Junhua", ""], ["Lim", "Kwan Hui", ""]]}, {"id": "2012.03058", "submitter": "Xingyu Zhao", "authors": "Xingyu Zhao, Wei Huang, Xiaowei Huang, Valentin Robu, David Flynn", "title": "BayLIME: Bayesian Local Interpretable Model-Agnostic Explanations", "comments": "Preprint accepted by UAI2021. The final version to appear in the\n  UAI2021 volume of Proceedings of Machine Learning Research", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Given the pressing need for assuring algorithmic transparency, Explainable AI\n(XAI) has emerged as one of the key areas of AI research. In this paper, we\ndevelop a novel Bayesian extension to the LIME framework, one of the most\nwidely used approaches in XAI -- which we call BayLIME. Compared to LIME,\nBayLIME exploits prior knowledge and Bayesian reasoning to improve both the\nconsistency in repeated explanations of a single prediction and the robustness\nto kernel settings. BayLIME also exhibits better explanation fidelity than the\nstate-of-the-art (LIME, SHAP and GradCAM) by its ability to integrate prior\nknowledge from, e.g., a variety of other XAI techniques, as well as\nverification and validation (V&V) methods. We demonstrate the desirable\nproperties of BayLIME through both theoretical analysis and extensive\nexperiments.\n", "versions": [{"version": "v1", "created": "Sat, 5 Dec 2020 15:41:52 GMT"}, {"version": "v2", "created": "Thu, 13 May 2021 20:17:32 GMT"}, {"version": "v3", "created": "Wed, 19 May 2021 12:28:47 GMT"}, {"version": "v4", "created": "Thu, 20 May 2021 07:46:30 GMT"}, {"version": "v5", "created": "Sat, 29 May 2021 07:49:00 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Zhao", "Xingyu", ""], ["Huang", "Wei", ""], ["Huang", "Xiaowei", ""], ["Robu", "Valentin", ""], ["Flynn", "David", ""]]}, {"id": "2012.03063", "submitter": "Shubhranshu Shekhar", "authors": "Shubhranshu Shekhar, Neil Shah, Leman Akoglu", "title": "FAIROD: Fairness-aware Outlier Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fairness and Outlier Detection (OD) are closely related, as it is exactly the\ngoal of OD to spot rare, minority samples in a given population. When being a\nminority (as defined by protected variables, e.g. race/ethnicity/sex/age) does\nnot reflect positive-class membership (e.g. criminal/fraud), however, OD\nproduces unjust outcomes. Surprisingly, fairness-aware OD has been almost\nuntouched in prior work, as fair machine learning literature mainly focus on\nsupervised settings. Our work aims to bridge this gap. Specifically, we develop\ndesiderata capturing well-motivated fairness criteria for OD, and\nsystematically formalize the fair OD problem. Further, guided by our\ndesiderata, we propose FairOD, a fairness-aware outlier detector, which has the\nfollowing, desirable properties: FairOD (1) does not employ disparate treatment\nat test time, (2) aims to flag equal proportions of samples from all groups\n(i.e. obtain group fairness, via statistical parity), and (3) strives to flag\ntruly high-risk fraction of samples within each group. Extensive experiments on\na diverse set of synthetic and real world datasets show that FairOD produces\noutcomes that are fair with respect to protected variables, while performing\ncomparable to (and in some cases, even better than) fairness-agnostic detectors\nin terms of detection performance.\n", "versions": [{"version": "v1", "created": "Sat, 5 Dec 2020 15:58:38 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Shekhar", "Shubhranshu", ""], ["Shah", "Neil", ""], ["Akoglu", "Leman", ""]]}, {"id": "2012.03085", "submitter": "Federico Errica", "authors": "Federico Errica, Davide Bacciu, Alessio Micheli", "title": "Graph Mixture Density Networks", "comments": null, "journal-ref": "Proceedings of the 38th International Conference on Machine\n  Learning, PMLR 139 (2021)", "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce the Graph Mixture Density Networks, a new family of machine\nlearning models that can fit multimodal output distributions conditioned on\ngraphs of arbitrary topology. By combining ideas from mixture models and graph\nrepresentation learning, we address a broader class of challenging conditional\ndensity estimation problems that rely on structured data. In this respect, we\nevaluate our method on a new benchmark application that leverages random graphs\nfor stochastic epidemic simulations. We show a significant improvement in the\nlikelihood of epidemic outcomes when taking into account both multimodality and\nstructure. The empirical analysis is complemented by two real-world regression\ntasks showing the effectiveness of our approach in modeling the output\nprediction uncertainty. Graph Mixture Density Networks open appealing research\nopportunities in the study of structure-dependent phenomena that exhibit\nnon-trivial conditional output distributions.\n", "versions": [{"version": "v1", "created": "Sat, 5 Dec 2020 17:39:38 GMT"}, {"version": "v2", "created": "Tue, 8 Jun 2021 06:21:40 GMT"}, {"version": "v3", "created": "Fri, 25 Jun 2021 09:03:19 GMT"}], "update_date": "2021-06-28", "authors_parsed": [["Errica", "Federico", ""], ["Bacciu", "Davide", ""], ["Micheli", "Alessio", ""]]}, {"id": "2012.03091", "submitter": "Keith Cortis", "authors": "Keith Cortis and Brian Davis", "title": "Over a Decade of Social Opinion Mining: A Systematic Review", "comments": "170 pages, 3 figures. This is a preprint of an article published in\n  Artificial Intelligence Review (2021)", "journal-ref": null, "doi": "10.1007/s10462-021-10030-2", "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Social media popularity and importance is on the increase due to people using\nit for various types of social interaction across multiple channels. This\nsystematic review focuses on the evolving research area of Social Opinion\nMining, tasked with the identification of multiple opinion dimensions, such as\nsubjectivity, sentiment polarity, emotion, affect, sarcasm and irony, from\nuser-generated content represented across multiple social media platforms and\nin various media formats, like text, image, video and audio. Through Social\nOpinion Mining, natural language can be understood in terms of the different\nopinion dimensions, as expressed by humans. This contributes towards the\nevolution of Artificial Intelligence which in turn helps the advancement of\nseveral real-world use cases, such as customer service and decision making. A\nthorough systematic review was carried out on Social Opinion Mining research\nwhich totals 485 published studies and spans a period of twelve years between\n2007 and 2018. The in-depth analysis focuses on the social media platforms,\ntechniques, social datasets, language, modality, tools and technologies, and\nother aspects derived. Social Opinion Mining can be utilised in many\napplication areas, ranging from marketing, advertising and sales for\nproduct/service management, and in multiple domains and industries, such as\npolitics, technology, finance, healthcare, sports and government. The latest\ndevelopments in Social Opinion Mining beyond 2018 are also presented together\nwith future research directions, with the aim of leaving a wider academic and\nsocietal impact in several real-world applications.\n", "versions": [{"version": "v1", "created": "Sat, 5 Dec 2020 17:59:59 GMT"}, {"version": "v2", "created": "Tue, 6 Jul 2021 18:24:05 GMT"}], "update_date": "2021-07-08", "authors_parsed": [["Cortis", "Keith", ""], ["Davis", "Brian", ""]]}, {"id": "2012.03105", "submitter": "Vinayak Elangovan", "authors": "Poojith Kotikalapudi and Vinayak Elangovan", "title": "Obstacle avoidance and path finding for mobile robot navigation", "comments": "11 pages, 9 figures", "journal-ref": "7th International Conference on Artificial Intelligence &\n  Applications (ARIA 2020)", "doi": null, "report-no": null, "categories": "cs.RO cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  This paper investigates different methods to detect obstacles ahead of a\nrobot using a camera in the robot, an aerial camera, and an ultrasound sensor.\nWe also explored various efficient path finding methods for the robot to\nnavigate to the target source. Single and multi-iteration angle-based\nnavigation algorithms were developed. The theta-based path finding algorithms\nwere compared with the Dijkstra Algorithm and their performance were analyzed.\n", "versions": [{"version": "v1", "created": "Sat, 5 Dec 2020 19:25:09 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Kotikalapudi", "Poojith", ""], ["Elangovan", "Vinayak", ""]]}, {"id": "2012.03119", "submitter": "Nicolas Prevot", "authors": "Nicolas Prevot", "title": "GpuShareSat: a SAT solver using the GPU for clause sharing", "comments": "13 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We describe a SAT solver using both the GPU (CUDA) and the CPU with a new\nclause exchange strategy. The CPU runs a classic multithreaded CDCL SAT solver.\nEachCPU thread exports all the clauses it learns to the GPU. The GPU makes a\nheavy usage of bitwise operations. It notices when a clause would have been\nused by a CPU thread and notifies that thread, in which case it imports that\nclause. This relies on the GPU repeatedly testing millions of clauses against\nhundreds of assignments. All the clauses are tested independantly from each\nother (which allows the GPU massively parallel approach), but against all the\nassignments at once, using bitwise operations. This allows CPU threads to only\nimport clauses which would have been useful for them. Our solver is based upon\nglucose-syrup. Experiments show that this leads to a strong performance\nimprovement, with 22 more instances solved on the SAT 2020 competition than\nglucose-syrup.\n", "versions": [{"version": "v1", "created": "Sat, 5 Dec 2020 20:57:23 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Prevot", "Nicolas", ""]]}, {"id": "2012.03127", "submitter": "Stefan Neumann", "authors": "Pauli Miettinen, Stefan Neumann", "title": "Recent Developments in Boolean Matrix Factorization", "comments": "This technical report is the slightly extended version of a survey\n  which appeared at IJCAI'20", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The goal of Boolean Matrix Factorization (BMF) is to approximate a given\nbinary matrix as the product of two low-rank binary factor matrices, where the\nproduct of the factor matrices is computed under the Boolean algebra. While the\nproblem is computationally hard, it is also attractive because the binary\nnature of the factor matrices makes them highly interpretable. In the last\ndecade, BMF has received a considerable amount of attention in the data mining\nand formal concept analysis communities and, more recently, the machine\nlearning and the theory communities also started studying BMF. In this survey,\nwe give a concise summary of the efforts of all of these communities and raise\nsome open questions which in our opinion require further investigation.\n", "versions": [{"version": "v1", "created": "Sat, 5 Dec 2020 22:00:47 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Miettinen", "Pauli", ""], ["Neumann", "Stefan", ""]]}, {"id": "2012.03137", "submitter": "Chun Kai Ling", "authors": "Chun Kai Ling, Fei Fang, J. Zico Kolter", "title": "Deep Archimedean Copulas", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  A central problem in machine learning and statistics is to model joint\ndensities of random variables from data. Copulas are joint cumulative\ndistribution functions with uniform marginal distributions and are used to\ncapture interdependencies in isolation from marginals. Copulas are widely used\nwithin statistics, but have not gained traction in the context of modern deep\nlearning. In this paper, we introduce ACNet, a novel differentiable neural\nnetwork architecture that enforces structural properties and enables one to\nlearn an important class of copulas--Archimedean Copulas. Unlike Generative\nAdversarial Networks, Variational Autoencoders, or Normalizing Flow methods,\nwhich learn either densities or the generative process directly, ACNet learns a\ngenerator of the copula, which implicitly defines the cumulative distribution\nfunction of a joint distribution. We give a probabilistic interpretation of the\nnetwork parameters of ACNet and use this to derive a simple but efficient\nsampling algorithm for the learned copula. Our experiments show that ACNet is\nable to both approximate common Archimedean Copulas and generate new copulas\nwhich may provide better fits to data.\n", "versions": [{"version": "v1", "created": "Sat, 5 Dec 2020 22:58:37 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Ling", "Chun Kai", ""], ["Fang", "Fei", ""], ["Kolter", "J. Zico", ""]]}, {"id": "2012.03138", "submitter": "Stefan Neumann", "authors": "Stefan Neumann, Pauli Miettinen", "title": "Biclustering and Boolean Matrix Factorization in Data Streams", "comments": "This technical report is the slightly extended version of a paper\n  [34] which appeared at VLDB'20", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the clustering of bipartite graphs and Boolean matrix factorization\nin data streams. We consider a streaming setting in which the vertices from the\nleft side of the graph arrive one by one together with all of their incident\nedges. We provide an algorithm that, after one pass over the stream, recovers\nthe set of clusters on the right side of the graph using sublinear space; to\nthe best of our knowledge, this is the first algorithm with this property. We\nalso show that after a second pass over the stream, the left clusters of the\nbipartite graph can be recovered and we show how to extend our algorithm to\nsolve the Boolean matrix factorization problem (by exploiting the\ncorrespondence of Boolean matrices and bipartite graphs). We evaluate an\nimplementation of the algorithm on synthetic data and on real-world data. On\nreal-world datasets the algorithm is orders of magnitudes faster than a static\nbaseline algorithm while providing quality results within a factor 2 of the\nbaseline algorithm. Our algorithm scales linearly in the number of edges in the\ngraph. Finally, we analyze the algorithm theoretically and provide sufficient\nconditions under which the algorithm recovers a set of planted clusters under a\nstandard random graph model.\n", "versions": [{"version": "v1", "created": "Sat, 5 Dec 2020 23:02:43 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Neumann", "Stefan", ""], ["Miettinen", "Pauli", ""]]}, {"id": "2012.03143", "submitter": "Ahad N. Zehmakan", "authors": "Ahad N. Zehmakan", "title": "Majority Opinion Diffusion in Social Networks: An Adversarial Approach", "comments": "To appear in AAAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.AI cs.DM cs.SI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We introduce and study a novel majority-based opinion diffusion model.\nConsider a graph $G$, which represents a social network. Assume that initially\na subset of nodes, called seed nodes or early adopters, are colored either\nblack or white, which correspond to positive or negative opinion regarding a\nconsumer product or a technological innovation. Then, in each round an\nuncolored node, which is adjacent to at least one colored node, chooses the\nmost frequent color among its neighbors.\n  Consider a marketing campaign which advertises a product of poor quality and\nits ultimate goal is that more than half of the population believe in the\nquality of the product at the end of the opinion diffusion process. We focus on\nthree types of attackers which can select the seed nodes in a deterministic or\nrandom fashion and manipulate almost half of them to adopt a positive opinion\ntoward the product (that is, to choose black color). We say that an attacker\nsucceeds if a majority of nodes are black at the end of the process. Our main\npurpose is to characterize classes of graphs where an attacker cannot succeed.\nIn particular, we prove that if the maximum degree of the underlying graph is\nnot too large or if it has strong expansion properties, then it is fairly\nresilient to such attacks.\n  Furthermore, we prove tight bounds on the stabilization time of the process\n(that is, the number of rounds it needs to end) in both settings of choosing\nthe seed nodes deterministically and randomly. We also provide several hardness\nresults for some optimization problems regarding stabilization time and choice\nof seed nodes.\n", "versions": [{"version": "v1", "created": "Sat, 5 Dec 2020 23:30:16 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Zehmakan", "Ahad N.", ""]]}, {"id": "2012.03166", "submitter": "Nachuan Ma", "authors": "Nachuan Ma, Jiankun Wang, Max Q.-H. Meng", "title": "Conditional Generative Adversarial Networks for Optimal Path Planning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI eess.IV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Path planning plays an important role in autonomous robot systems. Effective\nunderstanding of the surrounding environment and efficient generation of\noptimal collision-free path are both critical parts for solving path planning\nproblem. Although conventional sampling-based algorithms, such as the\nrapidly-exploring random tree (RRT) and its improved optimal version (RRT*),\nhave been widely used in path planning problems because of their ability to\nfind a feasible path in even complex environments, they fail to find an optimal\npath efficiently. To solve this problem and satisfy the two aforementioned\nrequirements, we propose a novel learning-based path planning algorithm which\nconsists of a novel generative model based on the conditional generative\nadversarial networks (CGAN) and a modified RRT* algorithm (denoted by\nCGANRRT*). Given the map information, our CGAN model can generate an efficient\npossibility distribution of feasible paths, which can be utilized by the\nCGAN-RRT* algorithm to find the optimal path with a non-uniform sampling\nstrategy. The CGAN model is trained by learning from ground truth maps, each of\nwhich is generated by putting all the results of executing RRT algorithm 50\ntimes on one raw map. We demonstrate the efficient performance of this CGAN\nmodel by testing it on two groups of maps and comparing CGAN-RRT* algorithm\nwith conventional RRT* algorithm.\n", "versions": [{"version": "v1", "created": "Sun, 6 Dec 2020 02:53:50 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Ma", "Nachuan", ""], ["Wang", "Jiankun", ""], ["Meng", "Max Q. -H.", ""]]}, {"id": "2012.03170", "submitter": "Joshua Ball", "authors": "Joshua Ball", "title": "Food Classification with Convolutional Neural Networks and Multi-Class\n  Linear Discernment Analysis", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Convolutional neural networks (CNNs) have been successful in representing the\nfully-connected inferencing ability perceived to be seen in the human brain:\nthey take full advantage of the hierarchy-style patterns commonly seen in\ncomplex data and develop more patterns using simple features. Countless\nimplementations of CNNs have shown how strong their ability is to learn these\ncomplex patterns, particularly in the realm of image classification. However,\nthe cost of getting a high performance CNN to a so-called \"state of the art\"\nlevel is computationally costly. Even when using transfer learning, which\nutilize the very deep layers from models such as MobileNetV2, CNNs still take a\ngreat amount of time and resources. Linear discriminant analysis (LDA), a\ngeneralization of Fisher's linear discriminant, can be implemented in a\nmulti-class classification method to increase separability of class features\nwhile not needing a high performance system to do so for image classification.\nSimilarly, we also believe LDA has great promise in performing well. In this\npaper, we discuss our process of developing a robust CNN for food\nclassification as well as our effective implementation of multi-class LDA and\nprove that (1) CNN is superior to LDA for image classification and (2) why LDA\nshould not be left out of the races for image classification, particularly for\nbinary cases.\n", "versions": [{"version": "v1", "created": "Sun, 6 Dec 2020 03:28:58 GMT"}, {"version": "v2", "created": "Fri, 11 Dec 2020 04:27:23 GMT"}], "update_date": "2020-12-14", "authors_parsed": [["Ball", "Joshua", ""]]}, {"id": "2012.03177", "submitter": "Yixing Li", "authors": "Akshay Dua, Yixing Li, Fengbo Ren", "title": "Systolic-CNN: An OpenCL-defined Scalable Run-time-flexible FPGA\n  Accelerator Architecture for Accelerating Convolutional Neural Network\n  Inference in Cloud/Edge Computing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents Systolic-CNN, an OpenCL-defined scalable,\nrun-time-flexible FPGA accelerator architecture, optimized for accelerating the\ninference of various convolutional neural networks (CNNs) in multi-tenancy\ncloud/edge computing. The existing OpenCL-defined FPGA accelerators for CNN\ninference are insufficient due to limited flexibility for supporting multiple\nCNN models at run time and poor scalability resulting in underutilized FPGA\nresources and limited computational parallelism. Systolic-CNN adopts a highly\npipelined and paralleled 1-D systolic array architecture, which efficiently\nexplores both spatial and temporal parallelism for accelerating CNN inference\non FPGAs. Systolic-CNN is highly scalable and parameterized, which can be\neasily adapted by users to achieve up to 100% utilization of the coarse-grained\ncomputation resources (i.e., DSP blocks) for a given FPGA. Systolic-CNN is also\nrun-time-flexible in the context of multi-tenancy cloud/edge computing, which\ncan be time-shared to accelerate a variety of CNN models at run time without\nthe need of recompiling the FPGA kernel hardware nor reprogramming the FPGA.\nThe experiment results based on an Intel Arria/Stratix 10 GX FPGA Development\nboard show that the optimized single-precision implementation of Systolic-CNN\ncan achieve an average inference latency of 7ms/2ms, 84ms/33ms, 202ms/73ms,\n1615ms/873ms, and 900ms/498ms per image for accelerating AlexNet, ResNet-50,\nResNet-152, RetinaNet, and Light-weight RetinaNet, respectively. Codes are\navailable at https://github.com/PSCLab-ASU/Systolic-CNN.\n", "versions": [{"version": "v1", "created": "Sun, 6 Dec 2020 03:53:11 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Dua", "Akshay", ""], ["Li", "Yixing", ""], ["Ren", "Fengbo", ""]]}, {"id": "2012.03178", "submitter": "Peng Xiao", "authors": "Peng Xiao, Samuel Cheng", "title": "Probabilistic Federated Learning of Neural Networks Incorporated with\n  Global Posterior Information", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In federated learning, models trained on local clients are distilled into a\nglobal model. Due to the permutation invariance arises in neural networks, it\nis necessary to match the hidden neurons first when executing federated\nlearning with neural networks. Through the Bayesian nonparametric framework,\nProbabilistic Federated Neural Matching (PFNM) matches and fuses local neural\nnetworks so as to adapt to varying global model size and the heterogeneity of\nthe data. In this paper, we propose a new method which extends the PFNM with a\nKullback-Leibler (KL) divergence over neural components product, in order to\nmake inference exploiting posterior information in both local and global\nlevels. We also show theoretically that The additional part can be seamlessly\nconcatenated into the match-and-fuse progress. Through a series of simulations,\nit indicates that our new method outperforms popular state-of-the-art federated\nlearning methods in both single communication round and additional\ncommunication rounds situation.\n", "versions": [{"version": "v1", "created": "Sun, 6 Dec 2020 03:54:58 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Xiao", "Peng", ""], ["Cheng", "Samuel", ""]]}, {"id": "2012.03190", "submitter": "Xuejiao Tang", "authors": "Xuejiao Tang, Jiong Qiu, Ruijun Chen, Wenbin Zhang, Vasileios\n  Iosifidis, Zhen Liu, Wei Meng, Mingli Zhang and Ji Zhang", "title": "A Data-driven Human Responsibility Management System", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  An ideal safe workplace is described as a place where staffs fulfill\nresponsibilities in a well-organized order, potential hazardous events are\nbeing monitored in real-time, as well as the number of accidents and relevant\ndamages are minimized. However, occupational-related death and injury are still\nincreasing and have been highly attended in the last decades due to the lack of\ncomprehensive safety management. A smart safety management system is therefore\nurgently needed, in which the staffs are instructed to fulfill responsibilities\nas well as automating risk evaluations and alerting staffs and departments when\nneeded. In this paper, a smart system for safety management in the workplace\nbased on responsibility big data analysis and the internet of things (IoT) are\nproposed. The real world implementation and assessment demonstrate that the\nproposed systems have superior accountability performance and improve the\nresponsibility fulfillment through real-time supervision and self-reminder.\n", "versions": [{"version": "v1", "created": "Sun, 6 Dec 2020 06:16:51 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Tang", "Xuejiao", ""], ["Qiu", "Jiong", ""], ["Chen", "Ruijun", ""], ["Zhang", "Wenbin", ""], ["Iosifidis", "Vasileios", ""], ["Liu", "Zhen", ""], ["Meng", "Wei", ""], ["Zhang", "Mingli", ""], ["Zhang", "Ji", ""]]}, {"id": "2012.03204", "submitter": "Hangtian Jia", "authors": "Hangtian Jia, Yujing Hu, Yingfeng Chen, Chunxu Ren, Tangjie Lv,\n  Changjie Fan, Chongjie Zhang", "title": "Fever Basketball: A Complex, Flexible, and Asynchronized Sports Game\n  Environment for Multi-agent Reinforcement Learning", "comments": "7 pages,12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The development of deep reinforcement learning (DRL) has benefited from the\nemergency of a variety type of game environments where new challenging problems\nare proposed and new algorithms can be tested safely and quickly, such as Board\ngames, RTS, FPS, and MOBA games. However, many existing environments lack\ncomplexity and flexibility and assume the actions are synchronously executed in\nmulti-agent settings, which become less valuable. We introduce the Fever\nBasketball game, a novel reinforcement learning environment where agents are\ntrained to play basketball game. It is a complex and challenging environment\nthat supports multiple characters, multiple positions, and both the\nsingle-agent and multi-agent player control modes. In addition, to better\nsimulate real-world basketball games, the execution time of actions differs\namong players, which makes Fever Basketball a novel asynchronized environment.\nWe evaluate commonly used multi-agent algorithms of both independent learners\nand joint-action learners in three game scenarios with varying difficulties,\nand heuristically propose two baseline methods to diminish the extra\nnon-stationarity brought by asynchronism in Fever Basketball Benchmarks.\nBesides, we propose an integrated curricula training (ICT) framework to better\nhandle Fever Basketball problems, which includes several game-rule based\ncascading curricula learners and a coordination curricula switcher focusing on\nenhancing coordination within the team. The results show that the game remains\nchallenging and can be used as a benchmark environment for studies like\nlong-time horizon, sparse rewards, credit assignment, and non-stationarity,\netc. in multi-agent settings.\n", "versions": [{"version": "v1", "created": "Sun, 6 Dec 2020 07:51:59 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Jia", "Hangtian", ""], ["Hu", "Yujing", ""], ["Chen", "Yingfeng", ""], ["Ren", "Chunxu", ""], ["Lv", "Tangjie", ""], ["Fan", "Changjie", ""], ["Zhang", "Chongjie", ""]]}, {"id": "2012.03208", "submitter": "Byeonghwi Kim", "authors": "Kunal Pratap Singh, Suvaansh Bhambri, Byeonghwi Kim, Roozbeh Mottaghi,\n  Jonghyun Choi", "title": "MOCA: A Modular Object-Centric Approach for Interactive Instruction\n  Following", "comments": "12 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CV cs.RO", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Performing simple household tasks based on language directives is very\nnatural to humans, yet it remains an open challenge for an AI agent. Recently,\nan 'interactive instruction following' task has been proposed to foster\nresearch in reasoning over long instruction sequences that requires object\ninteractions in a simulated environment. It involves solving open problems in\nvision, language and navigation literature at each step. To address this\nmultifaceted problem, we propose a modular architecture that decouples the task\ninto visual perception and action policy, and name it as MOCA, a Modular\nObject-Centric Approach. We evaluate our method on the ALFRED benchmark and\nempirically validate that it outperforms prior arts by significant margins in\nall metrics with good generalization performance (high success rate in unseen\nenvironments). Our code is available at https://github.com/gistvision/moca.\n", "versions": [{"version": "v1", "created": "Sun, 6 Dec 2020 07:59:22 GMT"}, {"version": "v2", "created": "Sat, 29 May 2021 15:49:23 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Singh", "Kunal Pratap", ""], ["Bhambri", "Suvaansh", ""], ["Kim", "Byeonghwi", ""], ["Mottaghi", "Roozbeh", ""], ["Choi", "Jonghyun", ""]]}, {"id": "2012.03236", "submitter": "Defang Chen", "authors": "Defang Chen, Jian-Ping Mei, Yuan Zhang, Can Wang, Zhe Wang, Yan Feng,\n  Chun Chen", "title": "Cross-Layer Distillation with Semantic Calibration", "comments": "AAAI-2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently proposed knowledge distillation approaches based on feature-map\ntransfer validate that intermediate layers of a teacher model can serve as\neffective targets for training a student model to obtain better generalization\nability. Existing studies mainly focus on particular representation forms for\nknowledge transfer between manually specified pairs of teacher-student\nintermediate layers. However, semantics of intermediate layers may vary in\ndifferent networks and manual association of layers might lead to negative\nregularization caused by semantic mismatch between certain teacher-student\nlayer pairs. To address this problem, we propose Semantic Calibration for\nCross-layer Knowledge Distillation (SemCKD), which automatically assigns proper\ntarget layers of the teacher model for each student layer with an attention\nmechanism. With a learned attention distribution, each student layer distills\nknowledge contained in multiple layers rather than a single fixed intermediate\nlayer from the teacher model for appropriate cross-layer supervision in\ntraining. Consistent improvements over state-of-the-art approaches are observed\nin extensive experiments with various network architectures for teacher and\nstudent models, demonstrating the effectiveness and flexibility of the proposed\nattention based soft layer association mechanism for cross-layer distillation.\n", "versions": [{"version": "v1", "created": "Sun, 6 Dec 2020 11:16:07 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Chen", "Defang", ""], ["Mei", "Jian-Ping", ""], ["Zhang", "Yuan", ""], ["Wang", "Can", ""], ["Wang", "Zhe", ""], ["Feng", "Yan", ""], ["Chen", "Chun", ""]]}, {"id": "2012.03308", "submitter": "Weihao Xia", "authors": "Weihao Xia and Yujiu Yang and Jing-Hao Xue and Baoyuan Wu", "title": "TediGAN: Text-Guided Diverse Face Image Generation and Manipulation", "comments": "CVPR 2021. Code: https://github.com/weihaox/TediGAN Data:\n  https://github.com/weihaox/Multi-Modal-CelebA-HQ Video:\n  https://youtu.be/L8Na2f5viAM", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we propose TediGAN, a novel framework for multi-modal image\ngeneration and manipulation with textual descriptions. The proposed method\nconsists of three components: StyleGAN inversion module, visual-linguistic\nsimilarity learning, and instance-level optimization. The inversion module maps\nreal images to the latent space of a well-trained StyleGAN. The\nvisual-linguistic similarity learns the text-image matching by mapping the\nimage and text into a common embedding space. The instance-level optimization\nis for identity preservation in manipulation. Our model can produce diverse and\nhigh-quality images with an unprecedented resolution at 1024. Using a control\nmechanism based on style-mixing, our TediGAN inherently supports image\nsynthesis with multi-modal inputs, such as sketches or semantic labels, with or\nwithout instance guidance. To facilitate text-guided multi-modal synthesis, we\npropose the Multi-Modal CelebA-HQ, a large-scale dataset consisting of real\nface images and corresponding semantic segmentation map, sketch, and textual\ndescriptions. Extensive experiments on the introduced dataset demonstrate the\nsuperior performance of our proposed method. Code and data are available at\nhttps://github.com/weihaox/TediGAN.\n", "versions": [{"version": "v1", "created": "Sun, 6 Dec 2020 16:20:19 GMT"}, {"version": "v2", "created": "Wed, 17 Mar 2021 11:52:51 GMT"}, {"version": "v3", "created": "Mon, 29 Mar 2021 06:40:59 GMT"}], "update_date": "2021-03-30", "authors_parsed": [["Xia", "Weihao", ""], ["Yang", "Yujiu", ""], ["Xue", "Jing-Hao", ""], ["Wu", "Baoyuan", ""]]}, {"id": "2012.03322", "submitter": "Aymene Mohammed Bouayed", "authors": "Aymene Mohammed Bouayed and Karim Atif and Rachid Deriche and\n  Abdelhakim Saim", "title": "A Pseudo-labelling Auto-Encoder for unsupervised image classification", "comments": "13 pages, 17 figures, 9 tables, title simplified, references added", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  In this paper, we introduce a unique variant of the denoising Auto-Encoder\nand combine it with the perceptual loss to classify images in an unsupervised\nmanner. The proposed method, called Pseudo Labelling, consists of first\napplying a randomly sampled set of data augmentation transformations to each\ntraining image. As a result, each initial image can be considered as a\npseudo-label to its corresponding augmented ones. Then, an Auto-Encoder is used\nto learn the mapping between each set of the augmented images and its\ncorresponding pseudo-label. Furthermore, the perceptual loss is employed to\ntake into consideration the existing dependencies between the pixels in the\nsame neighbourhood of an image. This combination encourages the encoder to\noutput richer encodings that are highly informative of the input's class.\nConsequently, the Auto-Encoder's performance on unsupervised image\nclassification is improved in terms of stability, accuracy and consistency\nacross all tested datasets. Previous state-of-the-art accuracy on the MNIST,\nCIFAR-10 and SVHN datasets is improved by 0.3\\%, 3.11\\% and 9.21\\%\nrespectively.\n", "versions": [{"version": "v1", "created": "Sun, 6 Dec 2020 17:03:34 GMT"}, {"version": "v2", "created": "Mon, 31 May 2021 17:16:14 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Bouayed", "Aymene Mohammed", ""], ["Atif", "Karim", ""], ["Deriche", "Rachid", ""], ["Saim", "Abdelhakim", ""]]}, {"id": "2012.03324", "submitter": "Nabil Ibtehaz", "authors": "Nabil Ibtehaz, S. M. Shakhawat Hossain Sourav, Md. Shamsuzzoha Bayzid,\n  M. Sohel Rahman", "title": "Align-gram : Rethinking the Skip-gram Model for Protein Sequence\n  Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.AI cs.LG q-bio.GN", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Background: The inception of next generations sequencing technologies have\nexponentially increased the volume of biological sequence data. Protein\nsequences, being quoted as the `language of life', has been analyzed for a\nmultitude of applications and inferences.\n  Motivation: Owing to the rapid development of deep learning, in recent years\nthere have been a number of breakthroughs in the domain of Natural Language\nProcessing. Since these methods are capable of performing different tasks when\ntrained with a sufficient amount of data, off-the-shelf models are used to\nperform various biological applications. In this study, we investigated the\napplicability of the popular Skip-gram model for protein sequence analysis and\nmade an attempt to incorporate some biological insights into it.\n  Results: We propose a novel $k$-mer embedding scheme, Align-gram, which is\ncapable of mapping the similar $k$-mers close to each other in a vector space.\nFurthermore, we experiment with other sequence-based protein representations\nand observe that the embeddings derived from Align-gram aids modeling and\ntraining deep learning models better. Our experiments with a simple baseline\nLSTM model and a much complex CNN model of DeepGoPlus shows the potential of\nAlign-gram in performing different types of deep learning applications for\nprotein sequence analysis.\n", "versions": [{"version": "v1", "created": "Sun, 6 Dec 2020 17:04:17 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Ibtehaz", "Nabil", ""], ["Sourav", "S. M. Shakhawat Hossain", ""], ["Bayzid", "Md. Shamsuzzoha", ""], ["Rahman", "M. Sohel", ""]]}, {"id": "2012.03345", "submitter": "John Chiotellis", "authors": "Ioannis Chiotellis and Daniel Cremers", "title": "Neural Online Graph Exploration", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Can we learn how to explore unknown spaces efficiently? To answer this\nquestion, we study the problem of Online Graph Exploration, the online version\nof the Traveling Salesperson Problem. We reformulate graph exploration as a\nreinforcement learning problem and apply Direct Future Prediction (Dosovitskiy\nand Koltun, 2017) to solve it. As the graph is discovered online, the\ncorresponding Markov Decision Process entails a dynamic state space, namely the\nobservable graph and a dynamic action space, namely the nodes forming the\ngraph's frontier. To the best of our knowledge, this is the first attempt to\nsolve online graph exploration in a data-driven way. We conduct experiments on\nsix data sets of procedurally generated graphs and three real city road\nnetworks. We demonstrate that our agent can learn strategies superior to many\nwell known graph traversal algorithms, confirming that exploration can be\nlearned.\n", "versions": [{"version": "v1", "created": "Sun, 6 Dec 2020 18:19:05 GMT"}, {"version": "v2", "created": "Tue, 6 Apr 2021 12:47:00 GMT"}], "update_date": "2021-04-07", "authors_parsed": [["Chiotellis", "Ioannis", ""], ["Cremers", "Daniel", ""]]}, {"id": "2012.03354", "submitter": "Prithu Banerjee", "authors": "Prithu Banerjee, Wei Chen, Laks V.S. Lakshmanan", "title": "Maximizing Social Welfare in a Competitive Diffusion Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.AI cs.IT math.IT", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Influence maximization (IM) has garnered a lot of attention in the literature\nowing to applications such as viral marketing and infection containment. It\naims to select a small number of seed users to adopt an item such that adoption\npropagates to a large number of users in the network. Competitive IM focuses on\nthe propagation of competing items in the network. Existing works on\ncompetitive IM have several limitations. (1) They fail to incorporate economic\nincentives in users' decision making in item adoptions. (2) Majority of the\nworks aim to maximize the adoption of one particular item, and ignore the\ncollective role that different items play. (3) They focus mostly on one aspect\nof competition -- pure competition. To address these concerns we study\ncompetitive IM under a utility-driven propagation model called UIC, and study\nsocial welfare maximization. The problem in general is not only NP-hard but\nalso NP-hard to approximate within any constant factor. We, therefore, devise\ninstant dependent efficient approximation algorithms for the general case as\nwell as a $(1-1/e-\\epsilon)$-approximation algorithm for a restricted setting.\nOur algorithms outperform different baselines on competitive IM, both in terms\nof solution quality and running time on large real networks under both\nsynthetic and real utility configurations.\n", "versions": [{"version": "v1", "created": "Sun, 6 Dec 2020 19:09:12 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Banerjee", "Prithu", ""], ["Chen", "Wei", ""], ["Lakshmanan", "Laks V. S.", ""]]}, {"id": "2012.03362", "submitter": "Lu Yu", "authors": "Lu Yu, Xialei Liu, Joost van de Weijer", "title": "Self-Training for Class-Incremental Semantic Segmentation", "comments": "Submitted to TNNLS", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In class-incremental semantic segmentation we have no access to the labeled\ndata of previous tasks. Therefore, when incrementally learning new classes,\ndeep neural networks suffer from catastrophic forgetting of previously learned\nknowledge. To address this problem, we propose to apply a self-training\napproach that leverages unlabeled data, which is used for rehearsal of previous\nknowledge. Additionally, conflict reduction is proposed to resolve the\nconflicts of pseudo labels generated from both the old and new models. We show\nthat maximizing self-entropy can further improve results by smoothing the\noverconfident predictions. Interestingly, in the experiments we show that the\nauxiliary data can be different from the training data and that even\ngeneral-purpose but diverse auxiliary data can lead to large performance gains.\nThe experiments demonstrate state-of-the-art results: obtaining a relative gain\nof up to 114% on Pascal-VOC 2012 and 8.5% on the more challenging ADE20K\ncompared to previous state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Sun, 6 Dec 2020 19:48:35 GMT"}, {"version": "v2", "created": "Thu, 25 Mar 2021 09:49:26 GMT"}], "update_date": "2021-03-26", "authors_parsed": [["Yu", "Lu", ""], ["Liu", "Xialei", ""], ["van de Weijer", "Joost", ""]]}, {"id": "2012.03363", "submitter": "Chao Pan", "authors": "Chao Pan, Siheng Chen, Antonio Ortega", "title": "Spatio-Temporal Graph Scattering Transform", "comments": "18 pages, ICLR 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.AI cs.CV cs.LG eess.IV", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Although spatio-temporal graph neural networks have achieved great empirical\nsuccess in handling multiple correlated time series, they may be impractical in\nsome real-world scenarios due to a lack of sufficient high-quality training\ndata. Furthermore, spatio-temporal graph neural networks lack theoretical\ninterpretation. To address these issues, we put forth a novel mathematically\ndesigned framework to analyze spatio-temporal data. Our proposed\nspatio-temporal graph scattering transform (ST-GST) extends traditional\nscattering transforms to the spatio-temporal domain. It performs iterative\napplications of spatio-temporal graph wavelets and nonlinear activation\nfunctions, which can be viewed as a forward pass of spatio-temporal graph\nconvolutional networks without training. Since all the filter coefficients in\nST-GST are mathematically designed, it is promising for the real-world\nscenarios with limited training data, and also allows for a theoretical\nanalysis, which shows that the proposed ST-GST is stable to small perturbations\nof input signals and structures. Finally, our experiments show that i) ST-GST\noutperforms spatio-temporal graph convolutional networks by an increase of 35%\nin accuracy for MSR Action3D dataset; ii) it is better and computationally more\nefficient to design the transform based on separable spatio-temporal graphs\nthan the joint ones; and iii) the nonlinearity in ST-GST is critical to\nempirical performance.\n", "versions": [{"version": "v1", "created": "Sun, 6 Dec 2020 19:49:55 GMT"}, {"version": "v2", "created": "Thu, 10 Dec 2020 20:07:42 GMT"}, {"version": "v3", "created": "Tue, 9 Feb 2021 05:08:41 GMT"}], "update_date": "2021-02-10", "authors_parsed": [["Pan", "Chao", ""], ["Chen", "Siheng", ""], ["Ortega", "Antonio", ""]]}, {"id": "2012.03369", "submitter": "Dong Wang", "authors": "Dong Wang, Yuewei Yang, Chenyang Tao, Zhe Gan, Liqun Chen, Fanjie\n  Kong, Ricardo Henao, Lawrence Carin", "title": "Proactive Pseudo-Intervention: Causally Informed Contrastive Learning\n  For Interpretable Vision Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Deep neural networks excel at comprehending complex visual signals,\ndelivering on par or even superior performance to that of human experts.\nHowever, ad-hoc visual explanations of model decisions often reveal an alarming\nlevel of reliance on exploiting non-causal visual cues that strongly correlate\nwith the target label in training data. As such, deep neural nets suffer\ncompromised generalization to novel inputs collected from different sources,\nand the reverse engineering of their decision rules offers limited\ninterpretability. To overcome these limitations, we present a novel contrastive\nlearning strategy called {\\it Proactive Pseudo-Intervention} (PPI) that\nleverages proactive interventions to guard against image features with no\ncausal relevance. We also devise a novel causally informed salience mapping\nmodule to identify key image pixels to intervene, and show it greatly\nfacilitates model interpretability. To demonstrate the utility of our\nproposals, we benchmark on both standard natural images and challenging medical\nimage datasets. PPI-enhanced models consistently deliver superior performance\nrelative to competing solutions, especially on out-of-domain predictions and\ndata integration from heterogeneous sources. Further, our causally trained\nsaliency maps are more succinct and meaningful relative to their non-causal\ncounterparts.\n", "versions": [{"version": "v1", "created": "Sun, 6 Dec 2020 20:30:26 GMT"}, {"version": "v2", "created": "Thu, 29 Apr 2021 21:28:56 GMT"}], "update_date": "2021-05-03", "authors_parsed": [["Wang", "Dong", ""], ["Yang", "Yuewei", ""], ["Tao", "Chenyang", ""], ["Gan", "Zhe", ""], ["Chen", "Liqun", ""], ["Kong", "Fanjie", ""], ["Henao", "Ricardo", ""], ["Carin", "Lawrence", ""]]}, {"id": "2012.03372", "submitter": "Ansaf Salleb-Aouissi", "authors": "Samuel Marc Denton and Ansaf Salleb-Aouissi", "title": "A Weighted Solution to SVM Actionability and Interpretability", "comments": "20 pages; work in progress; 17 figures; 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Research in machine learning has successfully developed algorithms to build\naccurate classification models. However, in many real-world applications, such\nas healthcare, customer satisfaction, and environment protection, we want to be\nable to use the models to decide what actions to take.\n  We investigate the concept of actionability in the context of Support Vector\nMachines. Actionability is as important as interpretability or explainability\nof machine learning models, an ongoing and important research topic.\nActionability is the task that gives us ways to act upon machine learning\nmodels and their predictions.\n  This paper finds a solution to the question of actionability on both linear\nand non-linear SVM models. Additionally, we introduce a way to account for\nweighted actions that allow for more change in certain features than others. We\npropose a gradient descent solution on the linear, RBF, and polynomial kernels,\nand we test the effectiveness of our models on both synthetic and real\ndatasets. We are also able to explore the model's interpretability through the\nlens of actionability.\n", "versions": [{"version": "v1", "created": "Sun, 6 Dec 2020 20:35:25 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Denton", "Samuel Marc", ""], ["Salleb-Aouissi", "Ansaf", ""]]}, {"id": "2012.03377", "submitter": "Akshay Joshi", "authors": "Akshay Joshi, Ankit Agrawal, Sushmita Nair", "title": "Art Style Classification with Self-Trained Ensemble of AutoEncoding\n  Transformations", "comments": "6", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The artistic style of a painting is a rich descriptor that reveals both\nvisual and deep intrinsic knowledge about how an artist uniquely portrays and\nexpresses their creative vision. Accurate categorization of paintings across\ndifferent artistic movements and styles is critical for large-scale indexing of\nart databases. However, the automatic extraction and recognition of these\nhighly dense artistic features has received little to no attention in the field\nof computer vision research. In this paper, we investigate the use of deep\nself-supervised learning methods to solve the problem of recognizing complex\nartistic styles with high intra-class and low inter-class variation. Further,\nwe outperform existing approaches by almost 20% on a highly class imbalanced\nWikiArt dataset with 27 art categories. To achieve this, we train the EnAET\nsemi-supervised learning model (Wang et al., 2019) with limited annotated data\nsamples and supplement it with self-supervised representations learned from an\nensemble of spatial and non-spatial transformations.\n", "versions": [{"version": "v1", "created": "Sun, 6 Dec 2020 21:05:23 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Joshi", "Akshay", ""], ["Agrawal", "Ankit", ""], ["Nair", "Sushmita", ""]]}, {"id": "2012.03378", "submitter": "Rajesh Rao", "authors": "Rajesh P. N. Rao", "title": "Brain Co-Processors: Using AI to Restore and Augment Brain Function", "comments": "arXiv admin note: text overlap with arXiv:1811.11876", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.NE nlin.AO q-bio.NC", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Brain-computer interfaces (BCIs) use decoding algorithms to control\nprosthetic devices based on brain signals for restoration of lost function.\nComputer-brain interfaces (CBIs), on the other hand, use encoding algorithms to\ntransform external sensory signals into neural stimulation patterns for\nrestoring sensation or providing sensory feedback for closed-loop prosthetic\ncontrol. In this article, we introduce brain co-processors, devices that\ncombine decoding and encoding in a unified framework using artificial\nintelligence (AI) to supplement or augment brain function. Brain co-processors\ncan be used for a range of applications, from inducing Hebbian plasticity for\nrehabilitation after brain injury to reanimating paralyzed limbs and enhancing\nmemory. A key challenge is simultaneous multi-channel neural decoding and\nencoding for optimization of external behavioral or task-related goals. We\ndescribe a new framework for developing brain co-processors based on artificial\nneural networks, deep learning and reinforcement learning. These \"neural\nco-processors\" allow joint optimization of cost functions with the nervous\nsystem to achieve desired behaviors. By coupling artificial neural networks\nwith their biological counterparts, neural co-processors offer a new way of\nrestoring and augmenting the brain, as well as a new scientific tool for brain\nresearch. We conclude by discussing the potential applications and ethical\nimplications of brain co-processors.\n", "versions": [{"version": "v1", "created": "Sun, 6 Dec 2020 21:06:28 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Rao", "Rajesh P. N.", ""]]}, {"id": "2012.03405", "submitter": "Alexander Ororbia", "authors": "Alexander Ororbia and Daniel Kifer", "title": "The Neural Coding Framework for Learning Generative Models", "comments": "Major revisions/organization changes have been made, significant\n  edits made for clarity, appendix now added", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural generative models can be used to learn complex probability\ndistributions from data, to sample from them, and to produce probability\ndensity estimates. We propose a novel neural generative model inspired by the\ntheory of predictive processing in the brain. According to predictive\nprocessing theory, the neurons in the brain form a hierarchy in which neurons\nin one level form expectations about sensory inputs from another level. These\nneurons update their local models based on differences between their\nexpectations and the observed signals. In a similar way, artificial neurons in\nour generative model predict what neighboring neurons will do, and adjust their\nparameters based on how well the predictions matched reality. This neural\ngenerative model performs very well in practice. On a variety of benchmark\ndatasets and metrics, it either remains competitive with or significantly\noutperforms other generative models with similar functionality (such as the\nvariational auto-encoder).\n", "versions": [{"version": "v1", "created": "Mon, 7 Dec 2020 01:20:38 GMT"}, {"version": "v2", "created": "Thu, 24 Dec 2020 18:24:43 GMT"}, {"version": "v3", "created": "Fri, 25 Dec 2020 01:52:40 GMT"}], "update_date": "2020-12-29", "authors_parsed": [["Ororbia", "Alexander", ""], ["Kifer", "Daniel", ""]]}, {"id": "2012.03413", "submitter": "Alexander Rodr\\'iguez", "authors": "Alexander Rodr\\'iguez, Bijaya Adhikari, Andr\\'es D. Gonz\\'alez,\n  Charles Nicholson, Anil Vullikanti, B. Aditya Prakash", "title": "Mapping Network States Using Connectivity Queries", "comments": "Appears in IEEE BigData 2020. Preliminary version in NeurIPS 2020 AI\n  + HADR", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Can we infer all the failed components of an infrastructure network, given a\nsample of reachable nodes from supply nodes? One of the most critical\npost-disruption processes after a natural disaster is to quickly determine the\ndamage or failure states of critical infrastructure components. However, this\nis non-trivial, considering that often only a fraction of components may be\naccessible or observable after a disruptive event. Past work has looked into\ninferring failed components given point probes, i.e. with a direct sample of\nfailed components. In contrast, we study the harder problem of inferring failed\ncomponents given partial information of some `serviceable' reachable nodes and\na small sample of point probes, being the first often more practical to obtain.\nWe formulate this novel problem using the Minimum Description Length (MDL)\nprinciple, and then present a greedy algorithm that minimizes MDL cost\neffectively. We evaluate our algorithm on domain-expert simulations of real\nnetworks in the aftermath of an earthquake. Our algorithm successfully identify\nfailed components, especially the critical ones affecting the overall system\nperformance.\n", "versions": [{"version": "v1", "created": "Mon, 7 Dec 2020 02:04:33 GMT"}, {"version": "v2", "created": "Tue, 8 Dec 2020 03:33:33 GMT"}, {"version": "v3", "created": "Thu, 24 Dec 2020 03:15:06 GMT"}], "update_date": "2020-12-25", "authors_parsed": [["Rodr\u00edguez", "Alexander", ""], ["Adhikari", "Bijaya", ""], ["Gonz\u00e1lez", "Andr\u00e9s D.", ""], ["Nicholson", "Charles", ""], ["Vullikanti", "Anil", ""], ["Prakash", "B. Aditya", ""]]}, {"id": "2012.03418", "submitter": "Yixin Tan", "authors": "Yixin Tan, Xiaomeng Wang, Tao Jia", "title": "From syntactic structure to semantic relationship: hypernym extraction\n  from definitions by recurrent neural networks using the part of speech\n  information", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The hyponym-hypernym relation is an essential element in the semantic\nnetwork. Identifying the hypernym from a definition is an important task in\nnatural language processing and semantic analysis. While a public dictionary\nsuch as WordNet works for common words, its application in domain-specific\nscenarios is limited. Existing tools for hypernym extraction either rely on\nspecific semantic patterns or focus on the word representation, which all\ndemonstrate certain limitations.\n", "versions": [{"version": "v1", "created": "Mon, 7 Dec 2020 02:18:49 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Tan", "Yixin", ""], ["Wang", "Xiaomeng", ""], ["Jia", "Tao", ""]]}, {"id": "2012.03436", "submitter": "Jicong Fan", "authors": "Jicong Fan, Lijun Ding, Chengrun Yang, Madeleine Udell", "title": "Low-Rank Tensor Recovery with Euclidean-Norm-Induced Schatten-p\n  Quasi-Norm Regularization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The nuclear norm and Schatten-$p$ quasi-norm of a matrix are popular rank\nproxies in low-rank matrix recovery. Unfortunately, computing the nuclear norm\nor Schatten-$p$ quasi-norm of a tensor is NP-hard, which is a pity for low-rank\ntensor completion (LRTC) and tensor robust principal component analysis\n(TRPCA). In this paper, we propose a new class of rank regularizers based on\nthe Euclidean norms of the CP component vectors of a tensor and show that these\nregularizers are monotonic transformations of tensor Schatten-$p$ quasi-norm.\nThis connection enables us to minimize the Schatten-$p$ quasi-norm in LRTC and\nTRPCA implicitly. The methods do not use the singular value decomposition and\nhence scale to big tensors. Moreover, the methods are not sensitive to the\nchoice of initial rank and provide an arbitrarily sharper rank proxy for\nlow-rank tensor recovery compared to nuclear norm. We provide theoretical\nguarantees in terms of recovery error for LRTC and TRPCA, which show relatively\nsmaller $p$ of Schatten-$p$ quasi-norm leads to tighter error bounds.\nExperiments using LRTC and TRPCA on synthetic data and natural images verify\nthe effectiveness and superiority of our methods compared to baseline methods.\n", "versions": [{"version": "v1", "created": "Mon, 7 Dec 2020 03:34:03 GMT"}, {"version": "v2", "created": "Thu, 21 Jan 2021 04:42:12 GMT"}], "update_date": "2021-01-22", "authors_parsed": [["Fan", "Jicong", ""], ["Ding", "Lijun", ""], ["Yang", "Chengrun", ""], ["Udell", "Madeleine", ""]]}, {"id": "2012.03448", "submitter": "Paul Atzberger", "authors": "Ryan Lopez and Paul J. Atzberger", "title": "Variational Autoencoders for Learning Nonlinear Dynamics of Physical\n  Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.SY eess.SY math.DG math.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop data-driven methods for incorporating physical information for\npriors to learn parsimonious representations of nonlinear systems arising from\nparameterized PDEs and mechanics. Our approach is based on Variational\nAutoencoders (VAEs) for learning from observations nonlinear state space\nmodels. We develop ways to incorporate geometric and topological priors through\ngeneral manifold latent space representations. We investigate the performance\nof our methods for learning low dimensional representations for the nonlinear\nBurgers equation and constrained mechanical systems.\n", "versions": [{"version": "v1", "created": "Mon, 7 Dec 2020 05:00:22 GMT"}, {"version": "v2", "created": "Mon, 15 Mar 2021 18:58:18 GMT"}], "update_date": "2021-03-17", "authors_parsed": [["Lopez", "Ryan", ""], ["Atzberger", "Paul J.", ""]]}, {"id": "2012.03449", "submitter": "Zhaoting Li", "authors": "Zhaoting Li, Jiankun Wang and Max Q.-H. Meng", "title": "Efficient Heuristic Generation for Robot Path Planning with Recurrent\n  Generative Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Robot path planning is difficult to solve due to the contradiction between\noptimality of results and complexity of algorithms, even in 2D environments. To\nfind an optimal path, the algorithm needs to search all the state space, which\ncosts a lot of computation resource. To address this issue, we present a novel\nrecurrent generative model (RGM) which generates efficient heuristic to reduce\nthe search efforts of path planning algorithm. This RGM model adopts the\nframework of general generative adversarial networks (GAN), which consists of a\nnovel generator that can generate heuristic by refining the outputs recurrently\nand two discriminators that check the connectivity and safety properties of\nheuristic. We test the proposed RGM module in various 2D environments to\ndemonstrate its effectiveness and efficiency. The results show that the RGM\nsuccessfully generates appropriate heuristic in both seen and new unseen maps\nwith a high accuracy, demonstrating the good generalization ability of this\nmodel. We also compare the rapidly-exploring random tree star (RRT*) with\ngenerated heuristic and the conventional RRT* in four different maps, showing\nthat the generated heuristic can guide the algorithm to find both initial and\noptimal solution in a faster and more efficient way.\n", "versions": [{"version": "v1", "created": "Mon, 7 Dec 2020 05:03:03 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Li", "Zhaoting", ""], ["Wang", "Jiankun", ""], ["Meng", "Max Q. -H.", ""]]}, {"id": "2012.03466", "submitter": "Jiansheng Fang", "authors": "Jiansheng Fang, Yanwu Xu, Xiaoqing Zhang, Yan Hu, Jiang Liu", "title": "Attention-based Saliency Hashing for Ophthalmic Image Retrieval", "comments": "8 pages, 4 figures, BIBM2020 conference", "journal-ref": null, "doi": "10.1109/BIBM49941.2020.9313536", "report-no": null, "categories": "cs.CV cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Deep hashing methods have been proved to be effective for the large-scale\nmedical image search assisting reference-based diagnosis for clinicians.\nHowever, when the salient region plays a maximal discriminative role in\nophthalmic image, existing deep hashing methods do not fully exploit the\nlearning ability of the deep network to capture the features of salient regions\npointedly. The different grades or classes of ophthalmic images may be share\nsimilar overall performance but have subtle differences that can be\ndifferentiated by mining salient regions. To address this issue, we propose a\nnovel end-to-end network, named Attention-based Saliency Hashing (ASH), for\nlearning compact hash-code to represent ophthalmic images. ASH embeds a\nspatial-attention module to focus more on the representation of salient regions\nand highlights their essential role in differentiating ophthalmic images.\nBenefiting from the spatial-attention module, the information of salient\nregions can be mapped into the hash-code for similarity calculation. In the\ntraining stage, we input the image pairs to share the weights of the network,\nand a pairwise loss is designed to maximize the discriminability of the\nhash-code. In the retrieval stage, ASH obtains the hash-code by inputting an\nimage with an end-to-end manner, then the hash-code is used to similarity\ncalculation to return the most similar images. Extensive experiments on two\ndifferent modalities of ophthalmic image datasets demonstrate that the proposed\nASH can further improve the retrieval performance compared to the\nstate-of-the-art deep hashing methods due to the huge contributions of the\nspatial-attention module.\n", "versions": [{"version": "v1", "created": "Mon, 7 Dec 2020 06:04:12 GMT"}], "update_date": "2021-02-04", "authors_parsed": [["Fang", "Jiansheng", ""], ["Xu", "Yanwu", ""], ["Zhang", "Xiaoqing", ""], ["Hu", "Yan", ""], ["Liu", "Jiang", ""]]}, {"id": "2012.03482", "submitter": "Lin Song", "authors": "Lin Song, Yanwei Li, Zhengkai Jiang, Zeming Li, Xiangyu Zhang, Hongbin\n  Sun, Jian Sun, Nanning Zheng", "title": "Rethinking Learnable Tree Filter for Generic Feature Transform", "comments": "Accepted by NeurIPS-2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Learnable Tree Filter presents a remarkable approach to model\nstructure-preserving relations for semantic segmentation. Nevertheless, the\nintrinsic geometric constraint forces it to focus on the regions with close\nspatial distance, hindering the effective long-range interactions. To relax the\ngeometric constraint, we give the analysis by reformulating it as a Markov\nRandom Field and introduce a learnable unary term. Besides, we propose a\nlearnable spanning tree algorithm to replace the original non-differentiable\none, which further improves the flexibility and robustness. With the above\nimprovements, our method can better capture long-range dependencies and\npreserve structural details with linear complexity, which is extended to\nseveral vision tasks for more generic feature transform. Extensive experiments\non object detection/instance segmentation demonstrate the consistent\nimprovements over the original version. For semantic segmentation, we achieve\nleading performance (82.1% mIoU) on the Cityscapes benchmark without\nbells-and-whistles. Code is available at\nhttps://github.com/StevenGrove/LearnableTreeFilterV2.\n", "versions": [{"version": "v1", "created": "Mon, 7 Dec 2020 07:16:47 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Song", "Lin", ""], ["Li", "Yanwei", ""], ["Jiang", "Zhengkai", ""], ["Li", "Zeming", ""], ["Zhang", "Xiangyu", ""], ["Sun", "Hongbin", ""], ["Sun", "Jian", ""], ["Zheng", "Nanning", ""]]}, {"id": "2012.03483", "submitter": "Byunggill Joe", "authors": "Byunggill Joe, Jihun Hamm, Sung Ju Hwang, Sooel Son, Insik Shin", "title": "Learning to Separate Clusters of Adversarial Representations for Robust\n  Adversarial Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Although deep neural networks have shown promising performances on various\ntasks, they are susceptible to incorrect predictions induced by imperceptibly\nsmall perturbations in inputs. A large number of previous works proposed to\ndetect adversarial attacks. Yet, most of them cannot effectively detect them\nagainst adaptive whitebox attacks where an adversary has the knowledge of the\nmodel and the defense method. In this paper, we propose a new probabilistic\nadversarial detector motivated by a recently introduced non-robust feature. We\nconsider the non-robust features as a common property of adversarial examples,\nand we deduce it is possible to find a cluster in representation space\ncorresponding to the property. This idea leads us to probability estimate\ndistribution of adversarial representations in a separate cluster, and leverage\nthe distribution for a likelihood based adversarial detector.\n", "versions": [{"version": "v1", "created": "Mon, 7 Dec 2020 07:21:18 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Joe", "Byunggill", ""], ["Hamm", "Jihun", ""], ["Hwang", "Sung Ju", ""], ["Son", "Sooel", ""], ["Shin", "Insik", ""]]}, {"id": "2012.03485", "submitter": "Souvik Das", "authors": "Souvik Das, Anirudh Shankar, Vaneet Aggarwal", "title": "A multi-agent evolutionary robotics framework to train spiking neural\n  networks", "comments": "9 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  A novel multi-agent evolutionary robotics (ER) based framework, inspired by\ncompetitive evolutionary environments in nature, is demonstrated for training\nSpiking Neural Networks (SNN). The weights of a population of SNNs along with\nmorphological parameters of bots they control in the ER environment are treated\nas phenotypes. Rules of the framework select certain bots and their SNNs for\nreproduction and others for elimination based on their efficacy in capturing\nfood in a competitive environment. While the bots and their SNNs are given no\nexplicit reward to survive or reproduce via any loss function, these drives\nemerge implicitly as they evolve to hunt food and survive within these rules.\nTheir efficiency in capturing food as a function of generations exhibit the\nevolutionary signature of punctuated equilibria. Two evolutionary inheritance\nalgorithms on the phenotypes, Mutation and Crossover with Mutation, are\ndemonstrated. Performances of these algorithms are compared using ensembles of\n100 experiments for each algorithm. We find that Crossover with Mutation\npromotes 40% faster learning in the SNN than mere Mutation with a statistically\nsignificant margin.\n", "versions": [{"version": "v1", "created": "Mon, 7 Dec 2020 07:26:52 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Das", "Souvik", ""], ["Shankar", "Anirudh", ""], ["Aggarwal", "Vaneet", ""]]}, {"id": "2012.03487", "submitter": "Bonaventure F. P. Dossou", "authors": "Bonaventure F. P. Dossou, Alena Iureva, Sayali R. Rajhans, Vamsi S.\n  Pidikiti", "title": "An Approach to Intelligent Pneumonia Detection and Integration", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CV cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Each year, over 2.5 million people, most of them in developed countries, die\nfrom pneumonia [1]. Since many studies have proved pneumonia is successfully\ntreatable when timely and correctly diagnosed, many of diagnosis aids have been\ndeveloped, with AI-based methods achieving high accuracies [2]. However,\ncurrently, the usage of AI in pneumonia detection is limited, in particular,\ndue to challenges in generalizing a locally achieved result. In this report, we\npropose a roadmap for creating and integrating a system that attempts to solve\nthis challenge. We also address various technical, legal, ethical, and\nlogistical issues, with a blueprint of possible solutions.\n", "versions": [{"version": "v1", "created": "Mon, 7 Dec 2020 07:27:45 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Dossou", "Bonaventure F. P.", ""], ["Iureva", "Alena", ""], ["Rajhans", "Sayali R.", ""], ["Pidikiti", "Vamsi S.", ""]]}, {"id": "2012.03488", "submitter": "Lipeng Wan", "authors": "Lipeng Wan, Xuwei Song, Xuguang Lan, Nanning Zheng", "title": "Multi-agent Policy Optimization with Approximatively Synchronous\n  Advantage Estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Cooperative multi-agent tasks require agents to deduce their own\ncontributions with shared global rewards, known as the challenge of credit\nassignment. General methods for policy based multi-agent reinforcement learning\nto solve the challenge introduce differentiate value functions or advantage\nfunctions for individual agents. In multi-agent system, polices of different\nagents need to be evaluated jointly. In order to update polices synchronously,\nsuch value functions or advantage functions also need synchronous evaluation.\nHowever, in current methods, value functions or advantage functions use\ncounter-factual joint actions which are evaluated asynchronously, thus suffer\nfrom natural estimation bias. In this work, we propose the approximatively\nsynchronous advantage estimation. We first derive the marginal advantage\nfunction, an expansion from single-agent advantage function to multi-agent\nsystem. Further more, we introduce a policy approximation for synchronous\nadvantage estimation, and break down the multi-agent policy optimization\nproblem into multiple sub-problems of single-agent policy optimization. Our\nmethod is compared with baseline algorithms on StarCraft multi-agent\nchallenges, and shows the best performance on most of the tasks.\n", "versions": [{"version": "v1", "created": "Mon, 7 Dec 2020 07:29:19 GMT"}, {"version": "v2", "created": "Wed, 21 Apr 2021 05:13:09 GMT"}, {"version": "v3", "created": "Sat, 8 May 2021 07:13:37 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Wan", "Lipeng", ""], ["Song", "Xuwei", ""], ["Lan", "Xuguang", ""], ["Zheng", "Nanning", ""]]}, {"id": "2012.03490", "submitter": "Tianyi Zhang", "authors": "Tianyi Zhang, Jiankun Wang and Max Q.-H. Meng", "title": "Generative Adversarial Network based Heuristics for Sampling-based Path\n  Planning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Sampling-based path planning is a popular methodology for robot path\nplanning. With a uniform sampling strategy to explore the state space, a\nfeasible path can be found without the complex geometric modeling of the\nconfiguration space. However, the quality of initial solution is not guaranteed\nand the convergence speed to the optimal solution is slow. In this paper, we\npresent a novel image-based path planning algorithm to overcome these\nlimitations. Specifically, a generative adversarial network (GAN) is designed\nto take the environment map (denoted as RGB image) as the input without other\npreprocessing works. The output is also an RGB image where the promising region\n(where a feasible path probably exists) is segmented. This promising region is\nutilized as a heuristic to achieve nonuniform sampling for the path planner. We\nconduct a number of simulation experiments to validate the effectiveness of the\nproposed method, and the results demonstrate that our method performs much\nbetter in terms of the quality of initial solution and the convergence speed to\nthe optimal solution. Furthermore, apart from the environments similar to the\ntraining set, our method also works well on the environments which are very\ndifferent from the training set.\n", "versions": [{"version": "v1", "created": "Mon, 7 Dec 2020 07:29:57 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Zhang", "Tianyi", ""], ["Wang", "Jiankun", ""], ["Meng", "Max Q. -H.", ""]]}, {"id": "2012.03491", "submitter": "Anton Smerdov", "authors": "Anton Smerdov, Evgeny Burnaev, Andrey Somov", "title": "AI-enabled Prediction of eSports Player Performance Using the Data from\n  Heterogeneous Sensors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The emerging progress of eSports lacks the tools for ensuring high-quality\nanalytics and training in Pro and amateur eSports teams. We report on an\nArtificial Intelligence (AI) enabled solution for predicting the eSports player\nin-game performance using exclusively the data from sensors. For this reason,\nwe collected the physiological, environmental, and the game chair data from Pro\nand amateur players. The player performance is assessed from the game logs in a\nmultiplayer game for each moment of time using a recurrent neural network. We\nhave investigated that attention mechanism improves the generalization of the\nnetwork and provides the straightforward feature importance as well. The best\nmodel achieves ROC AUC score 0.73. The prediction of the performance of\nparticular player is realized although his data are not utilized in the\ntraining set. The proposed solution has a number of promising applications for\nPro eSports teams as well as a learning tool for amateur players.\n", "versions": [{"version": "v1", "created": "Mon, 7 Dec 2020 07:31:53 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Smerdov", "Anton", ""], ["Burnaev", "Evgeny", ""], ["Somov", "Andrey", ""]]}, {"id": "2012.03506", "submitter": "Sambaran Bandyopadhyay", "authors": "Anoushka Vyas, Sambaran Bandyopadhyay", "title": "Semi-supervised Soil Moisture Prediction through Graph Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.SI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recent improvement and availability of remote satellite and IoT data offers\ninteresting and diverse applications of artificial intelligence in precision\nagriculture. Soil moisture is an important component of multiple agricultural\nand food supply chain practices. It measures the amount of water stored in\nvarious depth of soil. Existing data driven approaches for soil moisture\nprediction use conventional models which fail to capture the dynamic dependency\nof soil moisture values in near-by locations over time. In this work, we\npropose to convert the problem of soil moisture prediction as a semi-supervised\nlearning on temporal graphs. We propose a dynamic graph neural network which\ncan use the dependency of related locations over a region to predict soil\nmoisture. However, unlike social or information networks, graph structure is\nnot explicitly given for soil moisture prediction. Hence, we incorporate the\nproblem of graph structure learning in the framework of dynamic GNN. Our\nalgorithm, referred as DGLR, provides an end-to-end learning which can predict\nsoil moisture over multiple locations in a region over time and also update the\ngraph structure in between. Our solution achieves state-of-the-art results on\nreal-world soil moisture datasets compared to existing machine learning\napproaches.\n", "versions": [{"version": "v1", "created": "Mon, 7 Dec 2020 07:56:11 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Vyas", "Anoushka", ""], ["Bandyopadhyay", "Sambaran", ""]]}, {"id": "2012.03513", "submitter": "Zhaoqiang Chen", "authors": "Qun Chen, Zhaoqiang Chen, Youcef Nafa, Tianyi Duan, Zhanhuai Li", "title": "Adaptive Deep Learning for Entity Resolution by Risk Analysis", "comments": "31 pages, 5 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The state-of-the-art performance on entity resolution (ER) has been achieved\nby deep learning. However, deep models are usually trained on large quantities\nof accurately labeled training data, and can not be easily tuned towards a\ntarget workload. Unfortunately, in real scenarios, there may not be sufficient\nlabeled training data, and even worse, their distribution is usually more or\nless different from the target workload even when they come from the same\ndomain.\n  To alleviate the said limitations, this paper proposes a novel risk-based\napproach to tune a deep model towards a target workload by its particular\ncharacteristics. Built on the recent advances on risk analysis for ER, the\nproposed approach first trains a deep model on labeled training data, and then\nfine-tunes it by minimizing its estimated misprediction risk on unlabeled\ntarget data. Our theoretical analysis shows that risk-based adaptive training\ncan correct the label status of a mispredicted instance with a fairly good\nchance. We have also empirically validated the efficacy of the proposed\napproach on real benchmark data by a comparative study. Our extensive\nexperiments show that it can considerably improve the performance of deep\nmodels. Furthermore, in the scenario of distribution misalignment, it can\nsimilarly outperform the state-of-the-art alternative of transfer learning by\nconsiderable margins. Using ER as a test case, we demonstrate that risk-based\nadaptive training is a promising approach potentially applicable to various\nchallenging classification tasks.\n", "versions": [{"version": "v1", "created": "Mon, 7 Dec 2020 08:05:46 GMT"}, {"version": "v2", "created": "Thu, 10 Dec 2020 09:33:34 GMT"}, {"version": "v3", "created": "Sat, 13 Mar 2021 03:18:58 GMT"}], "update_date": "2021-03-16", "authors_parsed": [["Chen", "Qun", ""], ["Chen", "Zhaoqiang", ""], ["Nafa", "Youcef", ""], ["Duan", "Tianyi", ""], ["Li", "Zhanhuai", ""]]}, {"id": "2012.03519", "submitter": "Lin Song", "authors": "Lin Song, Yanwei Li, Zhengkai Jiang, Zeming Li, Hongbin Sun, Jian Sun,\n  Nanning Zheng", "title": "Fine-Grained Dynamic Head for Object Detection", "comments": "Accepted by NeurIPS-2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Feature Pyramid Network (FPN) presents a remarkable approach to alleviate\nthe scale variance in object representation by performing instance-level\nassignments. Nevertheless, this strategy ignores the distinct characteristics\nof different sub-regions in an instance. To this end, we propose a fine-grained\ndynamic head to conditionally select a pixel-level combination of FPN features\nfrom different scales for each instance, which further releases the ability of\nmulti-scale feature representation. Moreover, we design a spatial gate with the\nnew activation function to reduce computational complexity dramatically through\nspatially sparse convolutions. Extensive experiments demonstrate the\neffectiveness and efficiency of the proposed method on several state-of-the-art\ndetection benchmarks. Code is available at\nhttps://github.com/StevenGrove/DynamicHead.\n", "versions": [{"version": "v1", "created": "Mon, 7 Dec 2020 08:16:32 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Song", "Lin", ""], ["Li", "Yanwei", ""], ["Jiang", "Zhengkai", ""], ["Li", "Zeming", ""], ["Sun", "Hongbin", ""], ["Sun", "Jian", ""], ["Zheng", "Nanning", ""]]}, {"id": "2012.03527", "submitter": "Sandi Baressi  \\v{S}egota", "authors": "Nikola An{\\dj}eli\\'c, Sandi Baressi \\v{S}egota, Ivan Lorencin and\n  Zlatan Car", "title": "Estimation of Gas Turbine Shaft Torque and Fuel Flow of a CODLAG\n  Propulsion System Using Genetic Programming Algorithm", "comments": "25 pages, 5 figures, 7 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, the publicly available dataset of condition based maintenance\nof combined diesel-electric and gas (CODLAG) propulsion system for ships has\nbeen utilized to obtain symbolic expressions which could estimate gas turbine\nshaft torque and fuel flow using genetic programming (GP) algorithm. The entire\ndataset consists of 11934 samples that was divided into training and testing\nportions of dataset in an 80:20 ratio. The training dataset used to train the\nGP algorithm to obtain symbolic expressions for gas turbine shaft torque and\nfuel flow estimation consisted of 9548 samples. The best symbolic expressions\nobtained for gas turbine shaft torque and fuel flow estimation were obtained\nbased on their $R^2$ score generated as a result of the application of the\ntesting portion of the dataset on the aforementioned symbolic expressions. The\ntesting portion of the dataset consisted of 2386 samples. The three best\nsymbolic expressions obtained for gas turbine shaft torque estimation generated\n$R^2$ scores of 0.999201, 0.999296, and 0.999374, respectively. The three best\nsymbolic expressions obtained for fuel flow estimation generated $R^2$ scores\nof 0.995495, 0.996465, and 0.996487, respectively.\n", "versions": [{"version": "v1", "created": "Mon, 7 Dec 2020 08:39:58 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["An\u0111eli\u0107", "Nikola", ""], ["\u0160egota", "Sandi Baressi", ""], ["Lorencin", "Ivan", ""], ["Car", "Zlatan", ""]]}, {"id": "2012.03531", "submitter": "Ellen De Mello Koch Ms", "authors": "Anita de Mello Koch, Ellen de Mello Koch, Robert de Mello Koch", "title": "Why Unsupervised Deep Networks Generalize", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Promising resolutions of the generalization puzzle observe that the actual\nnumber of parameters in a deep network is much smaller than naive estimates\nsuggest. The renormalization group is a compelling example of a problem which\nhas very few parameters, despite the fact that naive estimates suggest\notherwise. Our central hypothesis is that the mechanisms behind the\nrenormalization group are also at work in deep learning, and that this leads to\na resolution of the generalization puzzle. We show detailed quantitative\nevidence that proves the hypothesis for an RBM, by showing that the trained RBM\nis discarding high momentum modes. Specializing attention mainly to\nautoencoders, we give an algorithm to determine the network's parameters\ndirectly from the learning data set. The resulting autoencoder almost performs\nas well as one trained by deep learning, and it provides an excellent initial\ncondition for training, reducing training times by a factor between 4 and 100\nfor the experiments we considered. Further, we are able to suggest a simple\ncriterion to decide if a given problem can or can not be solved using a deep\nnetwork.\n", "versions": [{"version": "v1", "created": "Mon, 7 Dec 2020 08:45:20 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Koch", "Anita de Mello", ""], ["Koch", "Ellen de Mello", ""], ["Koch", "Robert de Mello", ""]]}, {"id": "2012.03532", "submitter": "Alessandro Sestini", "authors": "Alessandro Sestini, Alexander Kuhnle and Andrew D. Bagdanov", "title": "Deep Policy Networks for NPC Behaviors that Adapt to Changing Design\n  Parameters in Roguelike Games", "comments": "Presented at the AAAI-21 Workshop on Reinforcement Learning in Games", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in Deep Reinforcement Learning (DRL) have largely focused on\nimproving the performance of agents with the aim of replacing humans in known\nand well-defined environments. The use of these techniques as a game design\ntool for video game production, where the aim is instead to create Non-Player\nCharacter (NPC) behaviors, has received relatively little attention until\nrecently. Turn-based strategy games like Roguelikes, for example, present\nunique challenges to DRL. In particular, the categorical nature of their\ncomplex game state, composed of many entities with different attributes,\nrequires agents able to learn how to compare and prioritize these entities.\nMoreover, this complexity often leads to agents that overfit to states seen\nduring training and that are unable to generalize in the face of design changes\nmade during development. In this paper we propose two network architectures\nwhich, when combined with a \\emph{procedural loot generation} system, are able\nto better handle complex categorical state spaces and to mitigate the need for\nretraining forced by design decisions. The first is based on a dense embedding\nof the categorical input space that abstracts the discrete observation model\nand renders trained agents more able to generalize. The second proposed\narchitecture is more general and is based on a Transformer network able to\nreason relationally about input and input attributes. Our experimental\nevaluation demonstrates that new agents have better adaptation capacity with\nrespect to a baseline architecture, making this framework more robust to\ndynamic gameplay changes during development. Based on the results shown in this\npaper, we believe that these solutions represent a step forward towards making\nDRL more accessible to the gaming industry.\n", "versions": [{"version": "v1", "created": "Mon, 7 Dec 2020 08:47:25 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Sestini", "Alessandro", ""], ["Kuhnle", "Alexander", ""], ["Bagdanov", "Andrew D.", ""]]}, {"id": "2012.03540", "submitter": "Rong Zhu", "authors": "Rong Zhu, Andreas Pfadler, Ziniu Wu, Yuxing Han, Xiaoke Yang, Feng Ye,\n  Zhenping Qian, Jingren Zhou, Bin Cui", "title": "Efficient and Scalable Structure Learning for Bayesian Networks:\n  Algorithms and Applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.DB", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Structure Learning for Bayesian network (BN) is an important problem with\nextensive research. It plays central roles in a wide variety of applications in\nAlibaba Group. However, existing structure learning algorithms suffer from\nconsiderable limitations in real world applications due to their low efficiency\nand poor scalability. To resolve this, we propose a new structure learning\nalgorithm LEAST, which comprehensively fulfills our business requirements as it\nattains high accuracy, efficiency and scalability at the same time. The core\nidea of LEAST is to formulate the structure learning into a continuous\nconstrained optimization problem, with a novel differentiable constraint\nfunction measuring the acyclicity of the resulting graph. Unlike with existing\nwork, our constraint function is built on the spectral radius of the graph and\ncould be evaluated in near linear time w.r.t. the graph node size. Based on it,\nLEAST can be efficiently implemented with low storage overhead. According to\nour benchmark evaluation, LEAST runs 1 to 2 orders of magnitude faster than\nstate of the art method with comparable accuracy, and it is able to scale on\nBNs with up to hundreds of thousands of variables. In our production\nenvironment, LEAST is deployed and serves for more than 20 applications with\nthousands of executions per day. We describe a concrete scenario in a ticket\nbooking service in Alibaba, where LEAST is applied to build a near real-time\nautomatic anomaly detection and root error cause analysis system. We also show\nthat LEAST unlocks the possibility of applying BN structure learning in new\nareas, such as large-scale gene expression data analysis and explainable\nrecommendation system.\n", "versions": [{"version": "v1", "created": "Mon, 7 Dec 2020 09:11:08 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Zhu", "Rong", ""], ["Pfadler", "Andreas", ""], ["Wu", "Ziniu", ""], ["Han", "Yuxing", ""], ["Yang", "Xiaoke", ""], ["Ye", "Feng", ""], ["Qian", "Zhenping", ""], ["Zhou", "Jingren", ""], ["Cui", "Bin", ""]]}, {"id": "2012.03544", "submitter": "Jianfeng Wang", "authors": "Jianfeng Wang, Lin Song, Zeming Li, Hongbin Sun, Jian Sun, Nanning\n  Zheng", "title": "End-to-End Object Detection with Fully Convolutional Network", "comments": "Accepted to CVPR2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Mainstream object detectors based on the fully convolutional network has\nachieved impressive performance. While most of them still need a hand-designed\nnon-maximum suppression (NMS) post-processing, which impedes fully end-to-end\ntraining. In this paper, we give the analysis of discarding NMS, where the\nresults reveal that a proper label assignment plays a crucial role. To this\nend, for fully convolutional detectors, we introduce a Prediction-aware\nOne-To-One (POTO) label assignment for classification to enable end-to-end\ndetection, which obtains comparable performance with NMS. Besides, a simple 3D\nMax Filtering (3DMF) is proposed to utilize the multi-scale features and\nimprove the discriminability of convolutions in the local region. With these\ntechniques, our end-to-end framework achieves competitive performance against\nmany state-of-the-art detectors with NMS on COCO and CrowdHuman datasets. The\ncode is available at https://github.com/Megvii-BaseDetection/DeFCN .\n", "versions": [{"version": "v1", "created": "Mon, 7 Dec 2020 09:14:55 GMT"}, {"version": "v2", "created": "Thu, 25 Mar 2021 04:18:14 GMT"}, {"version": "v3", "created": "Fri, 26 Mar 2021 03:38:55 GMT"}], "update_date": "2021-03-29", "authors_parsed": [["Wang", "Jianfeng", ""], ["Song", "Lin", ""], ["Li", "Zeming", ""], ["Sun", "Hongbin", ""], ["Sun", "Jian", ""], ["Zheng", "Nanning", ""]]}, {"id": "2012.03547", "submitter": "Samim Ahmadi", "authors": "Samim Ahmadi, Jan Christian Hauffen, Linh K\\\"astner, Peter Jung,\n  Giuseppe Caire, Mathias Ziegler", "title": "Learned Block Iterative Shrinkage Thresholding Algorithm for\n  Photothermal Super Resolution Imaging", "comments": "This work has been submitted to the IEEE for possible publication.\n  Copyright may be transferred without notice, after which this version may no\n  longer be accessible. 11 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI physics.app-ph physics.comp-ph", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Block-sparse regularization is already well-known in active thermal imaging\nand is used for multiple measurement based inverse problems. The main\nbottleneck of this method is the choice of regularization parameters which\ndiffers for each experiment. To avoid time-consuming manually selected\nregularization parameter, we propose a learned block-sparse optimization\napproach using an iterative algorithm unfolded into a deep neural network. More\nprecisely, we show the benefits of using a learned block iterative shrinkage\nthresholding algorithm that is able to learn the choice of regularization\nparameters. In addition, this algorithm enables the determination of a suitable\nweight matrix to solve the underlying inverse problem. Therefore, in this paper\nwe present the algorithm and compare it with state of the art block iterative\nshrinkage thresholding using synthetically generated test data and experimental\ntest data from active thermography for defect reconstruction. Our results show\nthat the use of the learned block-sparse optimization approach provides smaller\nnormalized mean square errors for a small fixed number of iterations than\nwithout learning. Thus, this new approach allows to improve the convergence\nspeed and only needs a few iterations to generate accurate defect\nreconstruction in photothermal super resolution imaging.\n", "versions": [{"version": "v1", "created": "Mon, 7 Dec 2020 09:27:16 GMT"}, {"version": "v2", "created": "Thu, 10 Dec 2020 14:15:57 GMT"}], "update_date": "2020-12-11", "authors_parsed": [["Ahmadi", "Samim", ""], ["Hauffen", "Jan Christian", ""], ["K\u00e4stner", "Linh", ""], ["Jung", "Peter", ""], ["Caire", "Giuseppe", ""], ["Ziegler", "Mathias", ""]]}, {"id": "2012.03548", "submitter": "Kevin Lu", "authors": "Kevin Lu, Aditya Grover, Pieter Abbeel, Igor Mordatch", "title": "Reset-Free Lifelong Learning with Skill-Space Planning", "comments": "In the proceedings of the 7th International Conference on Learning\n  Representations (ICLR), Virtual, April 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The objective of lifelong reinforcement learning (RL) is to optimize agents\nwhich can continuously adapt and interact in changing environments. However,\ncurrent RL approaches fail drastically when environments are non-stationary and\ninteractions are non-episodic. We propose Lifelong Skill Planning (LiSP), an\nalgorithmic framework for non-episodic lifelong RL based on planning in an\nabstract space of higher-order skills. We learn the skills in an unsupervised\nmanner using intrinsic rewards and plan over the learned skills using a learned\ndynamics model. Moreover, our framework permits skill discovery even from\noffline data, thereby reducing the need for excessive real-world interactions.\nWe demonstrate empirically that LiSP successfully enables long-horizon planning\nand learns agents that can avoid catastrophic failures even in challenging\nnon-stationary and non-episodic environments derived from gridworld and MuJoCo\nbenchmarks.\n", "versions": [{"version": "v1", "created": "Mon, 7 Dec 2020 09:33:02 GMT"}, {"version": "v2", "created": "Fri, 1 Jan 2021 10:49:54 GMT"}, {"version": "v3", "created": "Tue, 15 Jun 2021 18:39:59 GMT"}], "update_date": "2021-06-17", "authors_parsed": [["Lu", "Kevin", ""], ["Grover", "Aditya", ""], ["Abbeel", "Pieter", ""], ["Mordatch", "Igor", ""]]}, {"id": "2012.03551", "submitter": "Bin He", "authors": "Bin He, Xin Jiang, Jinghui Xiao, Qun Liu", "title": "KgPLM: Knowledge-guided Language Model Pre-training via Generative and\n  Discriminative Learning", "comments": "10 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent studies on pre-trained language models have demonstrated their ability\nto capture factual knowledge and applications in knowledge-aware downstream\ntasks. In this work, we present a language model pre-training framework guided\nby factual knowledge completion and verification, and use the generative and\ndiscriminative approaches cooperatively to learn the model. Particularly, we\ninvestigate two learning schemes, named two-tower scheme and pipeline scheme,\nin training the generator and discriminator with shared parameter. Experimental\nresults on LAMA, a set of zero-shot cloze-style question answering tasks, show\nthat our model contains richer factual knowledge than the conventional\npre-trained language models. Furthermore, when fine-tuned and evaluated on the\nMRQA shared tasks which consists of several machine reading comprehension\ndatasets, our model achieves the state-of-the-art performance, and gains large\nimprovements on NewsQA (+1.26 F1) and TriviaQA (+1.56 F1) over RoBERTa.\n", "versions": [{"version": "v1", "created": "Mon, 7 Dec 2020 09:39:25 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["He", "Bin", ""], ["Jiang", "Xin", ""], ["Xiao", "Jinghui", ""], ["Liu", "Qun", ""]]}, {"id": "2012.03573", "submitter": "Bin He", "authors": "Bin He, Di Zhou, Jing Xie, Jinghui Xiao, Xin Jiang, Qun Liu", "title": "PPKE: Knowledge Representation Learning by Path-based Pre-training", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Entities may have complex interactions in a knowledge graph (KG), such as\nmulti-step relationships, which can be viewed as graph contextual information\nof the entities. Traditional knowledge representation learning (KRL) methods\nusually treat a single triple as a training unit, and neglect most of the graph\ncontextual information exists in the topological structure of KGs. In this\nstudy, we propose a Path-based Pre-training model to learn Knowledge\nEmbeddings, called PPKE, which aims to integrate more graph contextual\ninformation between entities into the KRL model. Experiments demonstrate that\nour model achieves state-of-the-art results on several benchmark datasets for\nlink prediction and relation prediction tasks, indicating that our model\nprovides a feasible way to take advantage of graph contextual information in\nKGs.\n", "versions": [{"version": "v1", "created": "Mon, 7 Dec 2020 10:29:30 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["He", "Bin", ""], ["Zhou", "Di", ""], ["Xie", "Jing", ""], ["Xiao", "Jinghui", ""], ["Jiang", "Xin", ""], ["Liu", "Qun", ""]]}, {"id": "2012.03612", "submitter": "Hiroyuki Kasai", "authors": "Jianming Huang, Zhongxi Fang, Hiroyuki Kasai", "title": "LCS Graph Kernel Based on Wasserstein Distance in Longest Common\n  Subsequence Metric Space", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For graph classification tasks, many methods use a common strategy to\naggregate information of vertex neighbors. Although this strategy provides an\nefficient means of extracting graph topological features, it brings excessive\namounts of information that might greatly reduce its accuracy when dealing with\nlarge-scale neighborhoods. Learning graphs using paths or walks will not suffer\nfrom this difficulty, but many have low utilization of each path or walk, which\nmight engender information loss and high computational costs. To solve this, we\npropose a graph kernel using a longest common subsequence (LCS kernel) to\ncompute more comprehensive similarity between paths and walks, which resolves\nsubstructure isomorphism difficulties. We also combine it with optimal\ntransport theory to extract more in-depth features of graphs. Furthermore, we\npropose an LCS metric space and apply an adjacent point merge operation to\nreduce its computational costs. Finally, we demonstrate that our proposed\nmethod outperforms many state-of-the-art graph kernel methods.\n", "versions": [{"version": "v1", "created": "Mon, 7 Dec 2020 11:59:14 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Huang", "Jianming", ""], ["Fang", "Zhongxi", ""], ["Kasai", "Hiroyuki", ""]]}, {"id": "2012.03624", "submitter": "Geoffrey Harris", "authors": "Geoff Harris", "title": "Improving Constraint Satisfaction Algorithm Efficiency for the\n  AllDifferent Constraint", "comments": "*sigh* - it has been gently and kindly pointed out to me that I have\n  simply re-discovered the channelling of constraints across alternate problem\n  specifications. Gosh this is oddly amusing albeit embarrassing!", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Combinatorial problems stated as Constraint Satisfaction Problems (CSP) are\nexamined. It is shown by example that any algorithm designed for the original\nCSP, and involving the AllDifferent constraint, has at least the same level of\nefficacy when simultaneously applied to both the original and its complementary\nproblem. The 1-to-1 mapping employed to transform a CSP to its complementary\nproblem, which is also a CSP, is introduced. This \"Dual CSP\" method and its\napplication are outlined. The analysis of several random problem instances\ndemonstrate the benefits of this method for variable domain reduction compared\nto the standard approach to CSP. Extensions to additional constraints other\nthan AllDifferent, as well as the use of hybrid algorithms, are proposed as\ncandidates for this Dual CSP method.\n", "versions": [{"version": "v1", "created": "Mon, 7 Dec 2020 12:14:55 GMT"}, {"version": "v2", "created": "Sun, 13 Dec 2020 09:59:33 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["Harris", "Geoff", ""]]}, {"id": "2012.03656", "submitter": "Saibo Geng", "authors": "Saibo Geng, Diego Antognini", "title": "An Enhanced MeanSum Method For Generating Hotel Multi-Review\n  Summarizations", "comments": "Work is not complete and may midlead readers", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-document summaritazion is the process of taking multiple texts as input\nand producing a short summary text based on the content of input texts. Up\nuntil recently, multi-document summarizers are mostly supervised extractive.\nHowever, supervised methods require datasets of large, paired document-summary\nexamples which are rare and expensive to produce. In 2018, an unsupervised\nmulti-document abstractive summarization method(Meansum) was proposed by Chu\nand Liu, and demonstrated competitive performances comparing to extractive\nmethods. Despite good evaluation results on automatic metrics, Meansum has\nmultiple limitations, notably the inability of dealing with multiple aspects.\nThe aim of this work was to use Multi-Aspect Masker(MAM) as content selector to\naddress the issue with multi-aspect. Moreover, we propose a regularizer to\ncontrol the length of the generated summaries. Through a series of experiments\non the hotel dataset from Trip Advisor, we validate our assumption and show\nthat our improved model achieves higher ROUGE, Sentiment Accuracy than the\noriginal Meansum method and also beats/ comprarable/close to the supervised\nbaseline.\n", "versions": [{"version": "v1", "created": "Mon, 7 Dec 2020 13:16:01 GMT"}, {"version": "v2", "created": "Tue, 20 Apr 2021 14:43:28 GMT"}], "update_date": "2021-04-21", "authors_parsed": [["Geng", "Saibo", ""], ["Antognini", "Diego", ""]]}, {"id": "2012.03661", "submitter": "Niklas K\\\"uhl Dr", "authors": "Niklas K\\\"uhl, Marc Goutier, Lucas Baier, Clemens Wolff, Dominik\n  Martin", "title": "Human vs. supervised machine learning: Who learns patterns faster?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  The capabilities of supervised machine learning (SML), especially compared to\nhuman abilities, are being discussed in scientific research and in the usage of\nSML. This study provides an answer to how learning performance differs between\nhumans and machines when there is limited training data. We have designed an\nexperiment in which 44 humans and three different machine learning algorithms\nidentify patterns in labeled training data and have to label instances\naccording to the patterns they find. The results show a high dependency between\nperformance and the underlying patterns of the task. Whereas humans perform\nrelatively similarly across all patterns, machines show large performance\ndifferences for the various patterns in our experiment. After seeing 20\ninstances in the experiment, human performance does not improve anymore, which\nwe relate to theories of cognitive overload. Machines learn slower but can\nreach the same level or may even outperform humans in 2 of the 4 of used\npatterns. However, machines need more instances compared to humans for the same\nresults. The performance of machines is comparably lower for the other 2\npatterns due to the difficulty of combining input features.\n", "versions": [{"version": "v1", "created": "Mon, 30 Nov 2020 13:39:26 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["K\u00fchl", "Niklas", ""], ["Goutier", "Marc", ""], ["Baier", "Lucas", ""], ["Wolff", "Clemens", ""], ["Martin", "Dominik", ""]]}, {"id": "2012.03665", "submitter": "Justin Ormont", "authors": "Phuong Pham, Vivek Jain, Lukas Dauterman, Justin Ormont, Navendu Jain", "title": "DeepTriage: Automated Transfer Assistance for Incidents in Cloud\n  Services", "comments": null, "journal-ref": "KDD '20: Proceedings of the 26th ACM SIGKDD International\n  Conference on Knowledge Discovery & Data Mining August 2020. Pages 3281-3289", "doi": "10.1145/3394486.3403380", "report-no": null, "categories": "cs.DC cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As cloud services are growing and generating high revenues, the cost of\ndowntime in these services is becoming significantly expensive. To reduce loss\nand service downtime, a critical primary step is to execute incident triage,\nthe process of assigning a service incident to the correct responsible team, in\na timely manner. An incorrect assignment risks additional incident reroutings\nand increases its time to mitigate by 10x. However, automated incident triage\nin large cloud services faces many challenges: (1) a highly imbalanced incident\ndistribution from a large number of teams, (2) wide variety in formats of input\ndata or data sources, (3) scaling to meet production-grade requirements, and\n(4) gaining engineers' trust in using machine learning recommendations. To\naddress these challenges, we introduce DeepTriage, an intelligent incident\ntransfer service combining multiple machine learning techniques - gradient\nboosted classifiers, clustering methods, and deep neural networks - in an\nensemble to recommend the responsible team to triage an incident. Experimental\nresults on real incidents in Microsoft Azure show that our service achieves\n82.9% F1 score. For highly impacted incidents, DeepTriage achieves F1 score\nfrom 76.3% - 91.3%. We have applied best practices and state-of-the-art\nframeworks to scale DeepTriage to handle incident routing for all cloud\nservices. DeepTriage has been deployed in Azure since October 2017 and is used\nby thousands of teams daily.\n", "versions": [{"version": "v1", "created": "Wed, 25 Nov 2020 03:10:11 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Pham", "Phuong", ""], ["Jain", "Vivek", ""], ["Dauterman", "Lukas", ""], ["Ormont", "Justin", ""], ["Jain", "Navendu", ""]]}, {"id": "2012.03678", "submitter": "Alkesh Patel", "authors": "Alkesh Patel, Akanksha Bindal, Hadas Kotek, Christopher Klein, Jason\n  Williams", "title": "Generating Natural Questions from Images for Multimodal Assistants", "comments": "4 pages, 1 reference page, 5 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generating natural, diverse, and meaningful questions from images is an\nessential task for multimodal assistants as it confirms whether they have\nunderstood the object and scene in the images properly. The research in visual\nquestion answering (VQA) and visual question generation (VQG) is a great step.\nHowever, this research does not capture questions that a visually-abled person\nwould ask multimodal assistants. Recently published datasets such as KB-VQA,\nFVQA, and OK-VQA try to collect questions that look for external knowledge\nwhich makes them appropriate for multimodal assistants. However, they still\ncontain many obvious and common-sense questions that humans would not usually\nask a digital assistant. In this paper, we provide a new benchmark dataset that\ncontains questions generated by human annotators keeping in mind what they\nwould ask multimodal digital assistants. Large scale annotations for several\nhundred thousand images are expensive and time-consuming, so we also present an\neffective way of automatically generating questions from unseen images. In this\npaper, we present an approach for generating diverse and meaningful questions\nthat consider image content and metadata of image (e.g., location, associated\nkeyword). We evaluate our approach using standard evaluation metrics such as\nBLEU, METEOR, ROUGE, and CIDEr to show the relevance of generated questions\nwith human-provided questions. We also measure the diversity of generated\nquestions using generative strength and inventiveness metrics. We report new\nstate-of-the-art results on the public and our datasets.\n", "versions": [{"version": "v1", "created": "Tue, 17 Nov 2020 19:12:23 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Patel", "Alkesh", ""], ["Bindal", "Akanksha", ""], ["Kotek", "Hadas", ""], ["Klein", "Christopher", ""], ["Williams", "Jason", ""]]}, {"id": "2012.03681", "submitter": "Ergin Isleyen", "authors": "Ergin Isleyen, Sebnem Duzgun, McKell R. Carter", "title": "Roof fall hazard detection with convolutional neural networks using\n  transfer learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Roof falls due to geological conditions are major safety hazards in mining\nand tunneling industries, causing lost work times, injuries, and fatalities.\nSeveral large-opening limestone mines in the Eastern and Midwestern United\nStates have roof fall problems caused by high horizontal stresses. The typical\nhazard management approach for this type of roof fall hazard relies heavily on\nvisual inspections and expert knowledge. In this study, we propose an\nartificial intelligence (AI) based system for the detection roof fall hazards\ncaused by high horizontal stresses. We use images depicting hazardous and\nnon-hazardous roof conditions to develop a convolutional neural network for\nautonomous detection of hazardous roof conditions. To compensate for limited\ninput data, we utilize a transfer learning approach. In transfer learning, an\nalready-trained network is used as a starting point for classification in a\nsimilar domain. Results confirm that this approach works well for classifying\nroof conditions as hazardous or safe, achieving a statistical accuracy of 86%.\nHowever, accuracy alone is not enough to ensure a reliable hazard management\nsystem. System constraints and reliability are improved when the features being\nused by the network are understood. Therefore, we used a deep learning\ninterpretation technique called integrated gradients to identify the important\ngeologic features in each image for prediction. The analysis of integrated\ngradients shows that the system mimics expert judgment on roof fall hazard\ndetection. The system developed in this paper demonstrates the potential of\ndeep learning in geological hazard management to complement human experts, and\nlikely to become an essential part of autonomous tunneling operations in those\ncases where hazard identification heavily depends on expert knowledge.\n", "versions": [{"version": "v1", "created": "Thu, 12 Nov 2020 17:16:36 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Isleyen", "Ergin", ""], ["Duzgun", "Sebnem", ""], ["Carter", "McKell R.", ""]]}, {"id": "2012.03682", "submitter": "Elnaz Soleimani", "authors": "Elnaz Soleimani, Ghazaleh Khodabandelou, Abdelghani Chibani, Yacine\n  Amirat", "title": "Generic Semi-Supervised Adversarial Subject Translation for Sensor-Based\n  Human Activity Recognition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The performance of Human Activity Recognition (HAR) models, particularly deep\nneural networks, is highly contingent upon the availability of the massive\namount of annotated training data which should be sufficiently labeled. Though,\ndata acquisition and manual annotation in the HAR domain are prohibitively\nexpensive due to skilled human resource requirements in both steps. Hence,\ndomain adaptation techniques have been proposed to adapt the knowledge from the\nexisting source of data. More recently, adversarial transfer learning methods\nhave shown very promising results in image classification, yet limited for\nsensor-based HAR problems, which are still prone to the unfavorable effects of\nthe imbalanced distribution of samples. This paper presents a novel generic and\nrobust approach for semi-supervised domain adaptation in HAR, which capitalizes\non the advantages of the adversarial framework to tackle the shortcomings, by\nleveraging knowledge from annotated samples exclusively from the source subject\nand unlabeled ones of the target subject. Extensive subject translation\nexperiments are conducted on three large, middle, and small-size datasets with\ndifferent levels of imbalance to assess the robustness and effectiveness of the\nproposed model to the scale as well as imbalance in the data. The results\ndemonstrate the effectiveness of our proposed algorithms over state-of-the-art\nmethods, which led in up to 13%, 4%, and 13% improvement of our high-level\nactivities recognition metrics for Opportunity, LISSI, and PAMAP2 datasets,\nrespectively. The LISSI dataset is the most challenging one owing to its less\npopulated and imbalanced distribution. Compared to the SA-GAN adversarial\ndomain adaptation method, the proposed approach enhances the final\nclassification performance with an average of 7.5% for the three datasets,\nwhich emphasizes the effectiveness of micro-mini-batch training.\n", "versions": [{"version": "v1", "created": "Wed, 11 Nov 2020 12:16:23 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Soleimani", "Elnaz", ""], ["Khodabandelou", "Ghazaleh", ""], ["Chibani", "Abdelghani", ""], ["Amirat", "Yacine", ""]]}, {"id": "2012.03690", "submitter": "Kevin Mayer", "authors": "Benjamin Rausch, Kevin Mayer, Marie-Louise Arlt, Gunther Gust, Philipp\n  Staudt, Christof Weinhardt, Dirk Neumann, Ram Rajagopal", "title": "An Enriched Automated PV Registry: Combining Image Recognition and 3D\n  Building Data", "comments": "Tackling Climate Change with Machine Learning at NeurIPS 2020\n  (Spotlight talk)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While photovoltaic (PV) systems are installed at an unprecedented rate,\nreliable information on an installation level remains scarce. As a result,\nautomatically created PV registries are a timely contribution to optimize grid\nplanning and operations. This paper demonstrates how aerial imagery and\nthree-dimensional building data can be combined to create an address-level PV\nregistry, specifying area, tilt, and orientation angles. We demonstrate the\nbenefits of this approach for PV capacity estimation. In addition, this work\npresents, for the first time, a comparison between automated and\nofficially-created PV registries. Our results indicate that our enriched\nautomated registry proves to be useful to validate, update, and complement\nofficial registries.\n", "versions": [{"version": "v1", "created": "Mon, 7 Dec 2020 13:45:08 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Rausch", "Benjamin", ""], ["Mayer", "Kevin", ""], ["Arlt", "Marie-Louise", ""], ["Gust", "Gunther", ""], ["Staudt", "Philipp", ""], ["Weinhardt", "Christof", ""], ["Neumann", "Dirk", ""], ["Rajagopal", "Ram", ""]]}, {"id": "2012.03707", "submitter": "Piotr Kicki", "authors": "Piotr Kicki, Tomasz Gawron, Krzysztof \\'Cwian, Mete Ozay, Piotr\n  Skrzypczy\\'nski", "title": "Learning from Experience for Rapid Generation of Local Car Maneuvers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Being able to rapidly respond to the changing scenes and traffic situations\nby generating feasible local paths is of pivotal importance for car autonomy.\nWe propose to train a deep neural network (DNN) to plan feasible and\nnearly-optimal paths for kinematically constrained vehicles in small constant\ntime. Our DNN model is trained using a novel weakly supervised approach and a\ngradient-based policy search. On real and simulated scenes and a large set of\nlocal planning problems, we demonstrate that our approach outperforms the\nexisting planners with respect to the number of successfully completed tasks.\nWhile the path generation time is about 40 ms, the generated paths are smooth\nand comparable to those obtained from conventional path planners.\n", "versions": [{"version": "v1", "created": "Mon, 7 Dec 2020 14:05:45 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Kicki", "Piotr", ""], ["Gawron", "Tomasz", ""], ["\u0106wian", "Krzysztof", ""], ["Ozay", "Mete", ""], ["Skrzypczy\u0144ski", "Piotr", ""]]}, {"id": "2012.03709", "submitter": "Yilin Zhao", "authors": "Yilin Zhao, Zhuosheng Zhang, Hai Zhao", "title": "Reference Knowledgeable Network for Machine Reading Comprehension", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-choice Machine Reading Comprehension (MRC) as a challenge requires\nmodel to select the most appropriate answer from a set of candidates given\npassage and question. Most of the existing researches focus on the modeling of\nthe task datasets without explicitly referring to external fine-grained\nknowledge sources, which is supposed to greatly make up the deficiency of the\ngiven passage. Thus we propose a novel reference-based knowledge enhancement\nmodel called Reference Knowledgeable Network (RekNet), which refines critical\ninformation from the passage and quote explicit knowledge in necessity. In\ndetail, RekNet refines fine-grained critical information and defines it as\nReference Span, then quotes explicit knowledge quadruples by the co-occurrence\ninformation of Reference Span and candidates. The proposed RekNet is evaluated\non three multi-choice MRC benchmarks: RACE, DREAM and Cosmos QA, which shows\nconsistent and remarkable performance improvement with observable statistical\nsignificance level over strong baselines.\n", "versions": [{"version": "v1", "created": "Mon, 7 Dec 2020 14:11:33 GMT"}, {"version": "v2", "created": "Wed, 14 Jul 2021 12:49:41 GMT"}], "update_date": "2021-07-15", "authors_parsed": [["Zhao", "Yilin", ""], ["Zhang", "Zhuosheng", ""], ["Zhao", "Hai", ""]]}, {"id": "2012.03721", "submitter": "Uwe Aickelin", "authors": "Justin Kane Gunn, Hadi Akbarzadeh Khorshidi, Uwe Aickelin", "title": "Similarity measure for aggregated fuzzy numbers from interval-valued\n  data", "comments": "Soft Computing Letters, 100002", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper presents a method to compute the degree of similarity between two\naggregated fuzzy numbers from intervals using the Interval Agreement Approach\n(IAA). The similarity measure proposed within this study contains several\nfeatures and attributes, of which are novel to aggregated fuzzy numbers. The\nattributes completely redefined or modified within this study include area,\nperimeter, centroids, quartiles and the agreement ratio. The recommended\nweighting for each feature has been learned using Principal Component Analysis\n(PCA). Furthermore, an illustrative example is provided to detail the\napplication and potential future use of the similarity measure.\n", "versions": [{"version": "v1", "created": "Fri, 4 Dec 2020 03:44:40 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Gunn", "Justin Kane", ""], ["Khorshidi", "Hadi Akbarzadeh", ""], ["Aickelin", "Uwe", ""]]}, {"id": "2012.03743", "submitter": "Marcos Baez", "authors": "Alessandro Pina, Marcos Baez, Florian Daniel", "title": "Bringing Cognitive Augmentation to Web Browsing Accessibility", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.HC cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we explore the opportunities brought by cognitive augmentation\nto provide a more natural and accessible web browsing experience. We explore\nthese opportunities through \\textit{conversational web browsing}, an emerging\ninteraction paradigm for the Web that enables blind and visually impaired users\n(BVIP), as well as regular users, to access the contents and features of\nwebsites through conversational agents. Informed by the literature, our\nprevious work and prototyping exercises, we derive a conceptual framework for\nsupporting BVIP conversational web browsing needs, to then focus on the\nchallenges of automatically providing this support, describing our early work\nand prototype that leverage heuristics that consider structural and content\nfeatures only.\n", "versions": [{"version": "v1", "created": "Mon, 7 Dec 2020 14:40:52 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Pina", "Alessandro", ""], ["Baez", "Marcos", ""], ["Daniel", "Florian", ""]]}, {"id": "2012.03749", "submitter": "Lara Marie Demajo Ms", "authors": "Lara Marie Demajo, Vince Vella and Alexiei Dingli", "title": "Explainable AI for Interpretable Credit Scoring", "comments": "19 pages, David C. Wyld et al. (Eds): ACITY, DPPR, VLSI, WeST, DSA,\n  CNDC, IoTE, AIAA, NLPTA - 2020", "journal-ref": null, "doi": "10.5121/csit.2020.101516", "report-no": null, "categories": "q-fin.RM cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  With the ever-growing achievements in Artificial Intelligence (AI) and the\nrecent boosted enthusiasm in Financial Technology (FinTech), applications such\nas credit scoring have gained substantial academic interest. Credit scoring\nhelps financial experts make better decisions regarding whether or not to\naccept a loan application, such that loans with a high probability of default\nare not accepted. Apart from the noisy and highly imbalanced data challenges\nfaced by such credit scoring models, recent regulations such as the `right to\nexplanation' introduced by the General Data Protection Regulation (GDPR) and\nthe Equal Credit Opportunity Act (ECOA) have added the need for model\ninterpretability to ensure that algorithmic decisions are understandable and\ncoherent. An interesting concept that has been recently introduced is\neXplainable AI (XAI), which focuses on making black-box models more\ninterpretable. In this work, we present a credit scoring model that is both\naccurate and interpretable. For classification, state-of-the-art performance on\nthe Home Equity Line of Credit (HELOC) and Lending Club (LC) Datasets is\nachieved using the Extreme Gradient Boosting (XGBoost) model. The model is then\nfurther enhanced with a 360-degree explanation framework, which provides\ndifferent explanations (i.e. global, local feature-based and local\ninstance-based) that are required by different people in different situations.\nEvaluation through the use of functionallygrounded, application-grounded and\nhuman-grounded analysis show that the explanations provided are simple,\nconsistent as well as satisfy the six predetermined hypotheses testing for\ncorrectness, effectiveness, easy understanding, detail sufficiency and\ntrustworthiness.\n", "versions": [{"version": "v1", "created": "Thu, 3 Dec 2020 18:44:03 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Demajo", "Lara Marie", ""], ["Vella", "Vince", ""], ["Dingli", "Alexiei", ""]]}, {"id": "2012.03754", "submitter": "Thanh Thi Nguyen", "authors": "Thanh Thi Nguyen, Hammad Tahir, Mohamed Abdelrazek, Ali Babar", "title": "Deep Learning Methods for Credit Card Fraud Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Credit card frauds are at an ever-increasing rate and have become a major\nproblem in the financial sector. Because of these frauds, card users are\nhesitant in making purchases and both the merchants and financial institutions\nbear heavy losses. Some major challenges in credit card frauds involve the\navailability of public data, high class imbalance in data, changing nature of\nfrauds and the high number of false alarms. Machine learning techniques have\nbeen used to detect credit card frauds but no fraud detection systems have been\nable to offer great efficiency to date. Recent development of deep learning has\nbeen applied to solve complex problems in various areas. This paper presents a\nthorough study of deep learning methods for the credit card fraud detection\nproblem and compare their performance with various machine learning algorithms\non three different financial datasets. Experimental results show great\nperformance of the proposed deep learning methods against traditional machine\nlearning models and imply that the proposed approaches can be implemented\neffectively for real-world credit card fraud detection systems.\n", "versions": [{"version": "v1", "created": "Mon, 7 Dec 2020 14:48:58 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Nguyen", "Thanh Thi", ""], ["Tahir", "Hammad", ""], ["Abdelrazek", "Mohamed", ""], ["Babar", "Ali", ""]]}, {"id": "2012.03774", "submitter": "Mohammad Nazmul Haque", "authors": "Pablo Moscato, Mohammad Nazmul Haque, Kevin Huang, Julia Sloan, Jon C.\n  de Oliveira", "title": "Learning to extrapolate using continued fractions: Predicting the\n  critical temperature of superconductor materials", "comments": "Submitted to IEEE Transactions on Artificial Intelligence (TAI)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cond-mat.supr-con cs.AI cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In Artificial Intelligence we often seek to identify an unknown target\nfunction of many variables $y=f(\\mathbf{x})$ giving a limited set of instances\n$S=\\{(\\mathbf{x^{(i)}},y^{(i)})\\}$ with $\\mathbf{x^{(i)}} \\in D$ where $D$ is a\ndomain of interest. We refer to $S$ as the training set and the final quest is\nto identify the mathematical model that approximates this target function for\nnew $\\mathbf{x}$; with the set $T=\\{ \\mathbf{x^{(j)}} \\} \\subset D$ with $T\n\\neq S$ (i.e. thus testing the model generalisation). However, for some\napplications, the main interest is approximating well the unknown function on a\nlarger domain $D'$ that contains $D$. In cases involving the design of new\nstructures, for instance, we may be interested in maximizing $f$; thus, the\nmodel derived from $S$ alone should also generalize well in $D'$ for samples\nwith values of $y$ larger than the largest observed in $S$. In that sense, the\nAI system would provide important information that could guide the design\nprocess, e.g., using the learned model as a surrogate function to design new\nlab experiments.\n  We introduce a method for multivariate regression based on iterative fitting\nof a continued fraction by incorporating additive spline models. We compared it\nwith established methods such as AdaBoost, Kernel Ridge, Linear Regression,\nLasso Lars, Linear Support Vector Regression, Multi-Layer Perceptrons, Random\nForests, Stochastic Gradient Descent and XGBoost. We tested the performance on\nthe important problem of predicting the critical temperature of superconductors\nbased on physical-chemical characteristics.\n", "versions": [{"version": "v1", "created": "Fri, 27 Nov 2020 04:57:40 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Moscato", "Pablo", ""], ["Haque", "Mohammad Nazmul", ""], ["Huang", "Kevin", ""], ["Sloan", "Julia", ""], ["de Oliveira", "Jon C.", ""]]}, {"id": "2012.03781", "submitter": "Fuxin Jiang", "authors": "Fuxin Jiang, Chengyuan Zhang, Shaolong Sun, Jingyun Sun", "title": "A Novel Hybrid Framework for Hourly PM2.5 Concentration Forecasting\n  Using CEEMDAN and Deep Temporal Convolutional Neural Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For hourly PM2.5 concentration prediction, accurately capturing the data\npatterns of external factors that affect PM2.5 concentration changes, and\nconstructing a forecasting model is one of efficient means to improve\nforecasting accuracy. In this study, a novel hybrid forecasting model based on\ncomplete ensemble empirical mode decomposition with adaptive noise (CEEMDAN)\nand deep temporal convolutional neural network (DeepTCN) is developed to\npredict PM2.5 concentration, by modelling the data patterns of historical\npollutant concentrations data, meteorological data, and discrete time\nvariables' data. Taking PM2.5 concentration of Beijing as the sample,\nexperimental results showed that the forecasting accuracy of the proposed\nCEEMDAN-DeepTCN model is verified to be the highest when compared with the time\nseries model, artificial neural network, and the popular deep learning models.\nThe new model has improved the capability to model the PM2.5-related factor\ndata patterns, and can be used as a promising tool for forecasting PM2.5\nconcentrations.\n", "versions": [{"version": "v1", "created": "Mon, 7 Dec 2020 15:22:01 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Jiang", "Fuxin", ""], ["Zhang", "Chengyuan", ""], ["Sun", "Shaolong", ""], ["Sun", "Jingyun", ""]]}, {"id": "2012.03793", "submitter": "Alexander Wong", "authors": "Andrew Hryniowski and Alexander Wong", "title": "Inter-layer Information Similarity Assessment of Deep Neural Networks\n  Via Topological Similarity and Persistence Analysis of Data Neighbour\n  Dynamics", "comments": "6 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The quantitative analysis of information structure through a deep neural\nnetwork (DNN) can unveil new insights into the theoretical performance of DNN\narchitectures. Two very promising avenues of research towards quantitative\ninformation structure analysis are: 1) layer similarity (LS) strategies focused\non the inter-layer feature similarity, and 2) intrinsic dimensionality (ID)\nstrategies focused on layer-wise data dimensionality using pairwise\ninformation. Inspired by both LS and ID strategies for quantitative information\nstructure analysis, we introduce two novel complimentary methods for\ninter-layer information similarity assessment premised on the interesting idea\nof studying a data sample's neighbourhood dynamics as it traverses through a\nDNN. More specifically, we introduce the concept of Nearest Neighbour\nTopological Similarity (NNTS) for quantifying the information topology\nsimilarity between layers of a DNN. Furthermore, we introduce the concept of\nNearest Neighbour Topological Persistence (NNTP) for quantifying the\ninter-layer persistence of data neighbourhood relationships throughout a DNN.\nThe proposed strategies facilitate the efficient inter-layer information\nsimilarity assessment by leveraging only local topological information, and we\ndemonstrate their efficacy in this study by performing analysis on a deep\nconvolutional neural network architecture on image data to study the insights\nthat can be gained with respect to the theoretical performance of a DNN.\n", "versions": [{"version": "v1", "created": "Mon, 7 Dec 2020 15:34:58 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Hryniowski", "Andrew", ""], ["Wong", "Alexander", ""]]}, {"id": "2012.03806", "submitter": "Sebastian H\\\"ofer", "authors": "Sebastian H\\\"ofer, Kostas Bekris, Ankur Handa, Juan Camilo Gamboa,\n  Florian Golemo, Melissa Mozifian, Chris Atkeson, Dieter Fox, Ken Goldberg,\n  John Leonard, C. Karen Liu, Jan Peters, Shuran Song, Peter Welinder, Martha\n  White", "title": "Perspectives on Sim2Real Transfer for Robotics: A Summary of the R:SS\n  2020 Workshop", "comments": "Summary of the \"2nd Workshop on Closing the Reality Gap in Sim2Real\n  Transfer for Robotics\" held in conjunction with \"Robotics: Science and System\n  2020\". Website: https://sim2real.github.io/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This report presents the debates, posters, and discussions of the Sim2Real\nworkshop held in conjunction with the 2020 edition of the \"Robotics: Science\nand System\" conference. Twelve leaders of the field took competing debate\npositions on the definition, viability, and importance of transferring skills\nfrom simulation to the real world in the context of robotics problems. The\ndebaters also joined a large panel discussion, answering audience questions and\noutlining the future of Sim2Real in robotics. Furthermore, we invited extended\nabstracts to this workshop which are summarized in this report. Based on the\nworkshop, this report concludes with directions for practitioners exploiting\nthis technology and for researchers further exploring open problems in this\narea.\n", "versions": [{"version": "v1", "created": "Mon, 7 Dec 2020 15:48:26 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["H\u00f6fer", "Sebastian", ""], ["Bekris", "Kostas", ""], ["Handa", "Ankur", ""], ["Gamboa", "Juan Camilo", ""], ["Golemo", "Florian", ""], ["Mozifian", "Melissa", ""], ["Atkeson", "Chris", ""], ["Fox", "Dieter", ""], ["Goldberg", "Ken", ""], ["Leonard", "John", ""], ["Liu", "C. Karen", ""], ["Peters", "Jan", ""], ["Song", "Shuran", ""], ["Welinder", "Peter", ""], ["White", "Martha", ""]]}, {"id": "2012.03809", "submitter": "Song Fang", "authors": "Song Fang and Quanyan Zhu", "title": "Independent Elliptical Distributions Minimize Their $\\mathcal{W}_2$\n  Wasserstein Distance from Independent Elliptical Distributions with the Same\n  Density Generator", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.AI cs.LG eess.SP stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This short note is on a property of the $\\mathcal{W}_2$ Wasserstein distance\nwhich indicates that independent elliptical distributions minimize their\n$\\mathcal{W}_2$ Wasserstein distance from given independent elliptical\ndistributions with the same density generators. Furthermore, we examine the\nimplications of this property in the Gelbrich bound when the distributions are\nnot necessarily elliptical. Meanwhile, we also generalize the results to the\ncases when the distributions are not independent. The primary purpose of this\nnote is for the referencing of papers that need to make use of this property or\nits implications.\n", "versions": [{"version": "v1", "created": "Mon, 7 Dec 2020 15:52:02 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Fang", "Song", ""], ["Zhu", "Quanyan", ""]]}, {"id": "2012.03812", "submitter": "Mohammad Mahdi Khalili", "authors": "Mohammad Mahdi Khalili, Xueru Zhang, Mahed Abroshan, Somayeh Sojoudi", "title": "Improving Fairness and Privacy in Selection Problems", "comments": "This paper has been accepted for publication in the 35th AAAI\n  Conference on Artificial Intelligence", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Supervised learning models have been increasingly used for making decisions\nabout individuals in applications such as hiring, lending, and college\nadmission. These models may inherit pre-existing biases from training datasets\nand discriminate against protected attributes (e.g., race or gender). In\naddition to unfairness, privacy concerns also arise when the use of models\nreveals sensitive personal information. Among various privacy notions,\ndifferential privacy has become popular in recent years. In this work, we study\nthe possibility of using a differentially private exponential mechanism as a\npost-processing step to improve both fairness and privacy of supervised\nlearning models. Unlike many existing works, we consider a scenario where a\nsupervised model is used to select a limited number of applicants as the number\nof available positions is limited. This assumption is well-suited for various\nscenarios, such as job application and college admission. We use ``equal\nopportunity'' as the fairness notion and show that the exponential mechanisms\ncan make the decision-making process perfectly fair. Moreover, the experiments\non real-world datasets show that the exponential mechanism can improve both\nprivacy and fairness, with a slight decrease in accuracy compared to the model\nwithout post-processing.\n", "versions": [{"version": "v1", "created": "Mon, 7 Dec 2020 15:55:28 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Khalili", "Mohammad Mahdi", ""], ["Zhang", "Xueru", ""], ["Abroshan", "Mahed", ""], ["Sojoudi", "Somayeh", ""]]}, {"id": "2012.03837", "submitter": "Michael Laskin", "authors": "Michael Laskin, Luke Metz, Seth Nabarro, Mark Saroufim, Badreddine\n  Noune, Carlo Luschi, Jascha Sohl-Dickstein, Pieter Abbeel", "title": "Parallel Training of Deep Networks with Local Updates", "comments": "First two authors - Michael Laskin and Luke Metz - contributed\n  equally. Order was determined by a coin flip", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Deep learning models trained on large data sets have been widely successful\nin both vision and language domains. As state-of-the-art deep learning\narchitectures have continued to grow in parameter count so have the compute\nbudgets and times required to train them, increasing the need for\ncompute-efficient methods that parallelize training. Two common approaches to\nparallelize the training of deep networks have been data and model parallelism.\nWhile useful, data and model parallelism suffer from diminishing returns in\nterms of compute efficiency for large batch sizes. In this paper, we\ninvestigate how to continue scaling compute efficiently beyond the point of\ndiminishing returns for large batches through local parallelism, a framework\nwhich parallelizes training of individual layers in deep networks by replacing\nglobal backpropagation with truncated layer-wise backpropagation. Local\nparallelism enables fully asynchronous layer-wise parallelism with a low memory\nfootprint, and requires little communication overhead compared with model\nparallelism. We show results in both vision and language domains across a\ndiverse set of architectures, and find that local parallelism is particularly\neffective in the high-compute regime.\n", "versions": [{"version": "v1", "created": "Mon, 7 Dec 2020 16:38:45 GMT"}, {"version": "v2", "created": "Tue, 15 Jun 2021 14:50:45 GMT"}], "update_date": "2021-06-16", "authors_parsed": [["Laskin", "Michael", ""], ["Metz", "Luke", ""], ["Nabarro", "Seth", ""], ["Saroufim", "Mark", ""], ["Noune", "Badreddine", ""], ["Luschi", "Carlo", ""], ["Sohl-Dickstein", "Jascha", ""], ["Abbeel", "Pieter", ""]]}, {"id": "2012.03861", "submitter": "Hector Budman", "authors": "Piyush Agarwal, Jorge Ivan Mireles Gonzalez, Ali Elkamel, Hector\n  Budman", "title": "Hierarchical Deep Recurrent Neural Network based Method for Fault\n  Detection and Diagnosis", "comments": "Under Review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A Deep Neural Network (DNN) based algorithm is proposed for the detection and\nclassification of faults in industrial plants. The proposed algorithm has the\nability to classify faults, especially incipient faults that are difficult to\ndetect and diagnose with traditional threshold based statistical methods or by\nconventional Artificial Neural Networks (ANNs). The algorithm is based on a\nSupervised Deep Recurrent Autoencoder Neural Network (Supervised DRAE-NN) that\nuses dynamic information of the process along the time horizon. Based on this\nnetwork a hierarchical structure is formulated by grouping faults based on\ntheir similarity into subsets of faults for detection and diagnosis. Further,\nan external pseudo-random binary signal (PRBS) is designed and injected into\nthe system to identify incipient faults. The hierarchical structure based\nstrategy improves the detection and classification accuracy significantly for\nboth incipient and non-incipient faults. The proposed approach is tested on the\nbenchmark Tennessee Eastman Process resulting in significant improvements in\nclassification as compared to both multivariate linear model-based strategies\nand non-hierarchical nonlinear model-based strategies.\n", "versions": [{"version": "v1", "created": "Mon, 7 Dec 2020 17:11:56 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Agarwal", "Piyush", ""], ["Gonzalez", "Jorge Ivan Mireles", ""], ["Elkamel", "Ali", ""], ["Budman", "Hector", ""]]}, {"id": "2012.03864", "submitter": "Olga Golovneva", "authors": "Lizhen Tan and Olga Golovneva", "title": "Evaluating Cross-Lingual Transfer Learning Approaches in Multilingual\n  Conversational Agent Models", "comments": "7 pages, 3 figures, 3 Tables. Accepted to be presented at COLING 2020\n  conference: https://coling2020.org/pages/accepted_papers_industry_track", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  With the recent explosion in popularity of voice assistant devices, there is\na growing interest in making them available to user populations in additional\ncountries and languages. However, to provide the highest accuracy and best\nperformance for specific user populations, most existing voice assistant models\nare developed individually for each region or language, which requires linear\ninvestment of effort. In this paper, we propose a general multilingual model\nframework for Natural Language Understanding (NLU) models, which can help\nbootstrap new language models faster and reduce the amount of effort required\nto develop each language separately. We explore how different deep learning\narchitectures affect multilingual NLU model performance. Our experimental\nresults show that these multilingual models can reach same or better\nperformance compared to monolingual models across language-specific test data\nwhile require less effort in creating features and model maintenance.\n", "versions": [{"version": "v1", "created": "Mon, 7 Dec 2020 17:14:52 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Tan", "Lizhen", ""], ["Golovneva", "Olga", ""]]}, {"id": "2012.03881", "submitter": "Chirag Vashist", "authors": "Avantika Singh, Chirag Vashist, Pratyush Gaurav, Aditya Nigam,\n  Rameshwar Pratap", "title": "IHashNet: Iris Hashing Network based on efficient multi-index hashing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Massive biometric deployments are pervasive in today's world. But despite the\nhigh accuracy of biometric systems, their computational efficiency degrades\ndrastically with an increase in the database size. Thus, it is essential to\nindex them. An ideal indexing scheme needs to generate codes that preserve the\nintra-subject similarity as well as inter-subject dissimilarity. Here, in this\npaper, we propose an iris indexing scheme using real-valued deep iris features\nbinarized to iris bar codes (IBC) compatible with the indexing structure.\nFirstly, for extracting robust iris features, we have designed a network\nutilizing the domain knowledge of ordinal filtering and learning their\nnonlinear combinations. Later these real-valued features are binarized.\nFinally, for indexing the iris dataset, we have proposed a loss that can\ntransform the binary feature into an improved feature compatible with the\nMulti-Index Hashing scheme. This loss function ensures the hamming distance\nequally distributed among all the contiguous disjoint sub-strings. To the best\nof our knowledge, this is the first work in the iris indexing domain that\npresents an end-to-end iris indexing structure. Experimental results on four\ndatasets are presented to depict the efficacy of the proposed approach.\n", "versions": [{"version": "v1", "created": "Mon, 7 Dec 2020 17:50:57 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Singh", "Avantika", ""], ["Vashist", "Chirag", ""], ["Gaurav", "Pratyush", ""], ["Nigam", "Aditya", ""], ["Pratap", "Rameshwar", ""]]}, {"id": "2012.03900", "submitter": "Govardana Sachithanandam Ramachandran", "authors": "Govardana Sachithanandam Ramachandran, Ivan Brugere, Lav R. Varshney,\n  and Caiming Xiong", "title": "GAEA: Graph Augmentation for Equitable Access via Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CY cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Disparate access to resources by different subpopulations is a prevalent\nissue in societal and sociotechnical networks. For example, urban\ninfrastructure networks may enable certain racial groups to more easily access\nresources such as high-quality schools, grocery stores, and polling places.\nSimilarly, social networks within universities and organizations may enable\ncertain groups to more easily access people with valuable information or\ninfluence. Here we introduce a new class of problems, Graph Augmentation for\nEquitable Access (GAEA), to enhance equity in networked systems by editing\ngraph edges under budget constraints. We prove such problems are NP-hard, and\ncannot be approximated within a factor of $(1-\\tfrac{1}{3e})$. We develop a\nprincipled, sample- and time- efficient Markov Reward Process (MRP)-based\nmechanism design framework for GAEA. Our algorithm outperforms baselines on a\ndiverse set of synthetic graphs. We further demonstrate the method on\nreal-world networks, by merging public census, school, and transportation\ndatasets for the city of Chicago and applying our algorithm to find\nhuman-interpretable edits to the bus network that enhance equitable access to\nhigh-quality schools across racial groups. Further experiments on Facebook\nnetworks of universities yield sets of new social connections that would\nincrease equitable access to certain attributed nodes across gender groups.\n", "versions": [{"version": "v1", "created": "Mon, 7 Dec 2020 18:29:32 GMT"}, {"version": "v2", "created": "Fri, 9 Apr 2021 11:27:25 GMT"}], "update_date": "2021-04-12", "authors_parsed": [["Ramachandran", "Govardana Sachithanandam", ""], ["Brugere", "Ivan", ""], ["Varshney", "Lav R.", ""], ["Xiong", "Caiming", ""]]}, {"id": "2012.03912", "submitter": "Saim Wani", "authors": "Saim Wani, Shivansh Patel, Unnat Jain, Angel X. Chang, Manolis Savva", "title": "MultiON: Benchmarking Semantic Map Memory using Multi-Object Navigation", "comments": "Project page: https://shivanshpatel35.github.io/multi-ON/ ; the first\n  three authors contributed equally", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.RO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Navigation tasks in photorealistic 3D environments are challenging because\nthey require perception and effective planning under partial observability.\nRecent work shows that map-like memory is useful for long-horizon navigation\ntasks. However, a focused investigation of the impact of maps on navigation\ntasks of varying complexity has not yet been performed. We propose the multiON\ntask, which requires navigation to an episode-specific sequence of objects in a\nrealistic environment. MultiON generalizes the ObjectGoal navigation task and\nexplicitly tests the ability of navigation agents to locate previously observed\ngoal objects. We perform a set of multiON experiments to examine how a variety\nof agent models perform across a spectrum of navigation task complexities. Our\nexperiments show that: i) navigation performance degrades dramatically with\nescalating task complexity; ii) a simple semantic map agent performs\nsurprisingly well relative to more complex neural image feature map agents; and\niii) even oracle map agents achieve relatively low performance, indicating the\npotential for future work in training embodied navigation agents using maps.\nVideo summary: https://youtu.be/yqTlHNIcgnY\n", "versions": [{"version": "v1", "created": "Mon, 7 Dec 2020 18:42:38 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Wani", "Saim", ""], ["Patel", "Shivansh", ""], ["Jain", "Unnat", ""], ["Chang", "Angel X.", ""], ["Savva", "Manolis", ""]]}, {"id": "2012.04027", "submitter": "Arantxa Casanova", "authors": "Arantxa Casanova, Michal Drozdzal, Adriana Romero-Soriano", "title": "Generating unseen complex scenes: are we there yet?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although recent complex scene conditional generation models generate\nincreasingly appealing scenes, it is very hard to assess which models perform\nbetter and why. This is often due to models being trained to fit different data\nsplits, and defining their own experimental setups. In this paper, we propose a\nmethodology to compare complex scene conditional generation models, and provide\nan in-depth analysis that assesses the ability of each model to (1) fit the\ntraining distribution and hence perform well on seen conditionings, (2) to\ngeneralize to unseen conditionings composed of seen object combinations, and\n(3) generalize to unseen conditionings composed of unseen object combinations.\nAs a result, we observe that recent methods are able to generate recognizable\nscenes given seen conditionings, and exploit compositionality to generalize to\nunseen conditionings with seen object combinations. However, all methods suffer\nfrom noticeable image quality degradation when asked to generate images from\nconditionings composed of unseen object combinations. Moreover, through our\nanalysis, we identify the advantages of different pipeline components, and find\nthat (1) encouraging compositionality through instance-wise spatial\nconditioning normalizations increases robustness to both types of unseen\nconditionings, (2) using semantically aware losses such as the scene-graph\nperceptual similarity helps improve some dimensions of the generation process,\nand (3) enhancing the quality of generated masks and the quality of the\nindividual objects are crucial steps to improve robustness to both types of\nunseen conditionings.\n", "versions": [{"version": "v1", "created": "Mon, 7 Dec 2020 20:04:39 GMT"}], "update_date": "2020-12-09", "authors_parsed": [["Casanova", "Arantxa", ""], ["Drozdzal", "Michal", ""], ["Romero-Soriano", "Adriana", ""]]}, {"id": "2012.04056", "submitter": "Viktor Schlegel", "authors": "Viktor Schlegel, Goran Nenadic, Riza Batista-Navarro", "title": "Semantics Altering Modifications for Evaluating Comprehension in Machine\n  Reading", "comments": "AAAI 2021, final version. 7 pages content + 2 pages references", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Advances in NLP have yielded impressive results for the task of machine\nreading comprehension (MRC), with approaches having been reported to achieve\nperformance comparable to that of humans. In this paper, we investigate whether\nstate-of-the-art MRC models are able to correctly process Semantics Altering\nModifications (SAM): linguistically-motivated phenomena that alter the\nsemantics of a sentence while preserving most of its lexical surface form. We\npresent a method to automatically generate and align challenge sets featuring\noriginal and altered examples. We further propose a novel evaluation\nmethodology to correctly assess the capability of MRC systems to process these\nexamples independent of the data they were optimised on, by discounting for\neffects introduced by domain shift. In a large-scale empirical study, we apply\nthe methodology in order to evaluate extractive MRC models with regard to their\ncapability to correctly process SAM-enriched data. We comprehensively cover 12\ndifferent state-of-the-art neural architecture configurations and four training\ndatasets and find that -- despite their well-known remarkable performance --\noptimised models consistently struggle to correctly process semantically\naltered data.\n", "versions": [{"version": "v1", "created": "Mon, 7 Dec 2020 21:00:42 GMT"}, {"version": "v2", "created": "Tue, 15 Jun 2021 10:21:07 GMT"}], "update_date": "2021-06-16", "authors_parsed": [["Schlegel", "Viktor", ""], ["Nenadic", "Goran", ""], ["Batista-Navarro", "Riza", ""]]}, {"id": "2012.04060", "submitter": "Andrey Kurenkov", "authors": "Andrey Kurenkov, Roberto Mart\\'in-Mart\\'in, Jeff Ichnowski, Ken\n  Goldberg, Silvio Savarese", "title": "Semantic and Geometric Modeling with Neural Message Passing in 3D Scene\n  Graphs for Hierarchical Mechanical Search", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.RO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Searching for objects in indoor organized environments such as homes or\noffices is part of our everyday activities. When looking for a target object,\nwe jointly reason about the rooms and containers the object is likely to be in;\nthe same type of container will have a different probability of having the\ntarget depending on the room it is in. We also combine geometric and semantic\ninformation to infer what container is best to search, or what other objects\nare best to move, if the target object is hidden from view. We propose to use a\n3D scene graph representation to capture the hierarchical, semantic, and\ngeometric aspects of this problem. To exploit this representation in a search\nprocess, we introduce Hierarchical Mechanical Search (HMS), a method that\nguides an agent's actions towards finding a target object specified with a\nnatural language description. HMS is based on a novel neural network\narchitecture that uses neural message passing of vectors with visual,\ngeometric, and linguistic information to allow HMS to reason across layers of\nthe graph while combining semantic and geometric cues. HMS is evaluated on a\nnovel dataset of 500 3D scene graphs with dense placements of semantically\nrelated objects in storage locations, and is shown to be significantly better\nthan several baselines at finding objects and close to the oracle policy in\nterms of the median number of actions required. Additional qualitative results\ncan be found at https://ai.stanford.edu/mech-search/hms.\n", "versions": [{"version": "v1", "created": "Mon, 7 Dec 2020 21:04:34 GMT"}, {"version": "v2", "created": "Sun, 23 May 2021 20:08:59 GMT"}], "update_date": "2021-05-25", "authors_parsed": [["Kurenkov", "Andrey", ""], ["Mart\u00edn-Mart\u00edn", "Roberto", ""], ["Ichnowski", "Jeff", ""], ["Goldberg", "Ken", ""], ["Savarese", "Silvio", ""]]}, {"id": "2012.04092", "submitter": "Milan Studeny", "authors": "Milan Studeny", "title": "Conditional independence structures over four discrete random variables\n  revisited: conditional Ingleton inequalities", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.AI math.CO math.IT", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  The paper deals with conditional linear information inequalities valid for\nentropy functions induced by discrete random variables. Specifically, the\nso-called conditional Ingleton inequalities are in the center of interest:\nthese are valid under conditional independence assumptions on the inducing\nrandom variables. We discuss five inequalities of this particular type, four of\nwhich has appeared earlier in the literature. Besides the proof of the new\nfifth inequality, simpler proofs of (some of) former inequalities are\npresented. These five information inequalities are used to characterize all\nconditional independence structures induced by four discrete random variables.\n", "versions": [{"version": "v1", "created": "Mon, 7 Dec 2020 22:23:52 GMT"}, {"version": "v2", "created": "Wed, 9 Dec 2020 13:40:29 GMT"}], "update_date": "2020-12-10", "authors_parsed": [["Studeny", "Milan", ""]]}, {"id": "2012.04099", "submitter": "Charith Peris", "authors": "Charith Peris, Gokmen Oz, Khadige Abboud, Venkata sai Varada, Prashan\n  Wanigasekara, Haidar Khan", "title": "Using multiple ASR hypotheses to boost i18n NLU performance", "comments": "9 pages, 4 Figures, 5 Tables, Accepted to ICON 2020 (17th\n  International Conference on Natural Language Processing)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Current voice assistants typically use the best hypothesis yielded by their\nAutomatic Speech Recognition (ASR) module as input to their Natural Language\nUnderstanding (NLU) module, thereby losing helpful information that might be\nstored in lower-ranked ASR hypotheses. We explore the change in performance of\nNLU associated tasks when utilizing five-best ASR hypotheses when compared to\nstatus quo for two language datasets, German and Portuguese. To harvest\ninformation from the ASR five-best, we leverage extractive summarization and\njoint extractive-abstractive summarization models for Domain Classification\n(DC) experiments while using a sequence-to-sequence model with a pointer\ngenerator network for Intent Classification (IC) and Named Entity Recognition\n(NER) multi-task experiments. For the DC full test set, we observe significant\nimprovements of up to 7.2% and 15.5% in micro-averaged F1 scores, for German\nand Portuguese, respectively. In cases where the best ASR hypothesis was not an\nexact match to the transcribed utterance (mismatched test set), we see\nimprovements of up to 6.7% and 8.8% micro-averaged F1 scores, for German and\nPortuguese, respectively. For IC and NER multi-task experiments, when\nevaluating on the mismatched test set, we see improvements across all domains\nin German and in 17 out of 19 domains in Portuguese (improvements based on\nchange in SeMER scores). Our results suggest that the use of multiple ASR\nhypotheses, as opposed to one, can lead to significant performance improvements\nin the DC task for these non-English datasets. In addition, it could lead to\nsignificant improvement in the performance of IC and NER tasks in cases where\nthe ASR model makes mistakes.\n", "versions": [{"version": "v1", "created": "Mon, 7 Dec 2020 22:37:38 GMT"}, {"version": "v2", "created": "Mon, 14 Dec 2020 18:44:37 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["Peris", "Charith", ""], ["Oz", "Gokmen", ""], ["Abboud", "Khadige", ""], ["Varada", "Venkata sai", ""], ["Wanigasekara", "Prashan", ""], ["Khan", "Haidar", ""]]}, {"id": "2012.04104", "submitter": "Fereshte Khani", "authors": "Fereshte Khani, Percy Liang", "title": "Removing Spurious Features can Hurt Accuracy and Affect Groups\n  Disproportionately", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The presence of spurious features interferes with the goal of obtaining\nrobust models that perform well across many groups within the population. A\nnatural remedy is to remove spurious features from the model. However, in this\nwork we show that removal of spurious features can decrease accuracy due to the\ninductive biases of overparameterized models. We completely characterize how\nthe removal of spurious features affects accuracy across different groups (more\ngenerally, test distributions) in noiseless overparameterized linear\nregression. In addition, we show that removal of spurious feature can decrease\nthe accuracy even in balanced datasets -- each target co-occurs equally with\neach spurious feature; and it can inadvertently make the model more susceptible\nto other spurious features. Finally, we show that robust self-training can\nremove spurious features without affecting the overall accuracy. Experiments on\nthe Toxic-Comment-Detectoin and CelebA datasets show that our results hold in\nnon-linear models.\n", "versions": [{"version": "v1", "created": "Mon, 7 Dec 2020 23:08:59 GMT"}], "update_date": "2020-12-09", "authors_parsed": [["Khani", "Fereshte", ""], ["Liang", "Percy", ""]]}, {"id": "2012.04115", "submitter": "Guillermo Valle-P\\'erez", "authors": "Guillermo Valle-P\\'erez, Ard A. Louis", "title": "Generalization bounds for deep learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Generalization in deep learning has been the topic of much recent theoretical\nand empirical research. Here we introduce desiderata for techniques that\npredict generalization errors for deep learning models in supervised learning.\nSuch predictions should 1) scale correctly with data complexity; 2) scale\ncorrectly with training set size; 3) capture differences between architectures;\n4) capture differences between optimization algorithms; 5) be quantitatively\nnot too far from the true error (in particular, be non-vacuous); 6) be\nefficiently computable; and 7) be rigorous. We focus on generalization error\nupper bounds, and introduce a categorisation of bounds depending on assumptions\non the algorithm and data. We review a wide range of existing approaches, from\nclassical VC dimension to recent PAC-Bayesian bounds, commenting on how well\nthey perform against the desiderata.\n  We next use a function-based picture to derive a marginal-likelihood\nPAC-Bayesian bound. This bound is, by one definition, optimal up to a\nmultiplicative constant in the asymptotic limit of large training sets, as long\nas the learning curve follows a power law, which is typically found in practice\nfor deep learning problems. Extensive empirical analysis demonstrates that our\nmarginal-likelihood PAC-Bayes bound fulfills desiderata 1-3 and 5. The results\nfor 6 and 7 are promising, but not yet fully conclusive, while only desideratum\n4 is currently beyond the scope of our bound. Finally, we comment on why this\nfunction-based bound performs significantly better than current parameter-based\nPAC-Bayes bounds.\n", "versions": [{"version": "v1", "created": "Mon, 7 Dec 2020 23:45:09 GMT"}, {"version": "v2", "created": "Wed, 9 Dec 2020 15:00:23 GMT"}], "update_date": "2020-12-10", "authors_parsed": [["Valle-P\u00e9rez", "Guillermo", ""], ["Louis", "Ard A.", ""]]}, {"id": "2012.04132", "submitter": "Neehar Kondapaneni", "authors": "Neehar Kondapaneni, Pietro Perona", "title": "A Number Sense as an Emergent Property of the Manipulating Brain", "comments": "15 pages, 6 figures, 8 supplemental figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.AI cs.CV cs.RO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The ability to understand and manipulate numbers and quantities emerges\nduring childhood, but the mechanism through which this ability is developed is\nstill poorly understood. In particular, it is not known whether acquiring such\na {\\em number sense} is possible without supervision from a teacher.\n  To explore this question, we propose a model in which spontaneous and\nundirected manipulation of small objects trains perception to predict the\nresulting scene changes. We find that, from this task, an image representation\nemerges that exhibits regularities that foreshadow numbers and quantity. These\ninclude distinct categories for zero and the first few natural numbers, a\nnotion of order, and a signal that correlates with numerical quantity. As a\nresult, our model acquires the ability to estimate the number of objects in the\nscene, as well as {\\em subitization}, i.e. the ability to recognize at a glance\nthe exact number of objects in small scenes. We conclude that important aspects\nof a facility with numbers and quantities may be learned without explicit\nteacher supervision.\n", "versions": [{"version": "v1", "created": "Tue, 8 Dec 2020 00:37:35 GMT"}, {"version": "v2", "created": "Mon, 22 Feb 2021 09:51:43 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Kondapaneni", "Neehar", ""], ["Perona", "Pietro", ""]]}, {"id": "2012.04195", "submitter": "Sha Hu", "authors": "Sha Hu, Zeshi Yang, Greg Mori", "title": "Neural fidelity warping for efficient robot morphology design", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of optimizing a robot morphology to achieve the best\nperformance for a target task, under computational resource limitations. The\nevaluation process for each morphological design involves learning a controller\nfor the design, which can consume substantial time and computational resources.\nTo address the challenge of expensive robot morphology evaluation, we present a\ncontinuous multi-fidelity Bayesian Optimization framework that efficiently\nutilizes computational resources via low-fidelity evaluations. We identify the\nproblem of non-stationarity over fidelity space. Our proposed fidelity warping\nmechanism can learn representations of learning epochs and tasks to model\nnon-stationary covariances between continuous fidelity evaluations which prove\nchallenging for off-the-shelf stationary kernels. Various experiments\ndemonstrate that our method can utilize the low-fidelity evaluations to\nefficiently search for the optimal robot morphology, outperforming\nstate-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Tue, 8 Dec 2020 03:41:22 GMT"}, {"version": "v2", "created": "Wed, 9 Dec 2020 18:44:49 GMT"}], "update_date": "2020-12-10", "authors_parsed": [["Hu", "Sha", ""], ["Yang", "Zeshi", ""], ["Mori", "Greg", ""]]}, {"id": "2012.04196", "submitter": "Swetava Ganguli", "authors": "Xuerong Xiao, Swetava Ganguli, Vipul Pandey", "title": "VAE-Info-cGAN: Generating Synthetic Images by Combining Pixel-level and\n  Feature-level Geospatial Conditional Inputs", "comments": "10 pages, 4 figures, Peer-reviewed and accepted version of the paper\n  published at the 13th ACM SIGSPATIAL International Workshop on Computational\n  Transportation Science (IWCTS 2020)", "journal-ref": "In Proceedings of the 13th ACM SIGSPATIAL International Workshop\n  on Computational Transportation Science, Article No. 1, Pages 1-10, November\n  03, 2020, Seattle, WA, USA", "doi": "10.1145/3423457.3429361", "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Training robust supervised deep learning models for many geospatial\napplications of computer vision is difficult due to dearth of class-balanced\nand diverse training data. Conversely, obtaining enough training data for many\napplications is financially prohibitive or may be infeasible, especially when\nthe application involves modeling rare or extreme events. Synthetically\ngenerating data (and labels) using a generative model that can sample from a\ntarget distribution and exploit the multi-scale nature of images can be an\ninexpensive solution to address scarcity of labeled data. Towards this goal, we\npresent a deep conditional generative model, called VAE-Info-cGAN, that\ncombines a Variational Autoencoder (VAE) with a conditional Information\nMaximizing Generative Adversarial Network (InfoGAN), for synthesizing\nsemantically rich images simultaneously conditioned on a pixel-level condition\n(PLC) and a macroscopic feature-level condition (FLC). Dimensionally, the PLC\ncan only vary in the channel dimension from the synthesized image and is meant\nto be a task-specific input. The FLC is modeled as an attribute vector in the\nlatent space of the generated image which controls the contributions of various\ncharacteristic attributes germane to the target distribution. An interpretation\nof the attribute vector to systematically generate synthetic images by varying\na chosen binary macroscopic feature is explored. Experiments on a GPS\ntrajectories dataset show that the proposed model can accurately generate\nvarious forms of spatio-temporal aggregates across different geographic\nlocations while conditioned only on a raster representation of the road\nnetwork. The primary intended application of the VAE-Info-cGAN is synthetic\ndata (and label) generation for targeted data augmentation for computer\nvision-based modeling of problems relevant to geospatial analysis and remote\nsensing.\n", "versions": [{"version": "v1", "created": "Tue, 8 Dec 2020 03:46:19 GMT"}], "update_date": "2020-12-09", "authors_parsed": [["Xiao", "Xuerong", ""], ["Ganguli", "Swetava", ""], ["Pandey", "Vipul", ""]]}, {"id": "2012.04216", "submitter": "Ben Hutchinson", "authors": "Angie Peng and Jeff Naecker and Ben Hutchinson and Andrew Smart and\n  Nyalleng Moorosi", "title": "Fairness Preferences, Actual and Hypothetical: A Study of Crowdworker\n  Incentives", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  How should we decide which fairness criteria or definitions to adopt in\nmachine learning systems? To answer this question, we must study the fairness\npreferences of actual users of machine learning systems. Stringent parity\nconstraints on treatment or impact can come with trade-offs, and may not even\nbe preferred by the social groups in question (Zafar et al., 2017). Thus it\nmight be beneficial to elicit what the group's preferences are, rather than\nrely on a priori defined mathematical fairness constraints. Simply asking for\nself-reported rankings of users is challenging because research has shown that\nthere are often gaps between people's stated and actual preferences(Bernheim et\nal., 2013).\n  This paper outlines a research program and experimental designs for\ninvestigating these questions. Participants in the experiments are invited to\nperform a set of tasks in exchange for a base payment--they are told upfront\nthat they may receive a bonus later on, and the bonus could depend on some\ncombination of output quantity and quality. The same group of workers then\nvotes on a bonus payment structure, to elicit preferences. The voting is\nhypothetical (not tied to an outcome) for half the group and actual (tied to\nthe actual payment outcome) for the other half, so that we can understand the\nrelation between a group's actual preferences and hypothetical (stated)\npreferences. Connections and lessons from fairness in machine learning are\nexplored.\n", "versions": [{"version": "v1", "created": "Tue, 8 Dec 2020 05:00:57 GMT"}], "update_date": "2020-12-09", "authors_parsed": [["Peng", "Angie", ""], ["Naecker", "Jeff", ""], ["Hutchinson", "Ben", ""], ["Smart", "Andrew", ""], ["Moorosi", "Nyalleng", ""]]}, {"id": "2012.04218", "submitter": "Mythreyi Velmurugan", "authors": "Mythreyi Velmurugan, Chun Ouyang, Catarina Moreira and Renuka\n  Sindhgatta", "title": "Evaluating Explainable Methods for Predictive Process Analytics: A\n  Functionally-Grounded Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Predictive process analytics focuses on predicting the future states of\nrunning instances of a business process. While advanced machine learning\ntechniques have been used to increase accuracy of predictions, the resulting\npredictive models lack transparency. Current explainable machine learning\nmethods, such as LIME and SHAP, can be used to interpret black box models.\nHowever, it is unclear how fit for purpose these methods are in explaining\nprocess predictive models. In this paper, we draw on evaluation measures used\nin the field of explainable AI and propose functionally-grounded evaluation\nmetrics for assessing explainable methods in predictive process analytics. We\napply the proposed metrics to evaluate the performance of LIME and SHAP in\ninterpreting process predictive models built on XGBoost, which has been shown\nto be relatively accurate in process predictions. We conduct the evaluation\nusing three open source, real-world event logs and analyse the evaluation\nresults to derive insights. The research contributes to understanding the\ntrustworthiness of explainable methods for predictive process analytics as a\nfundamental and key step towards human user-oriented evaluation.\n", "versions": [{"version": "v1", "created": "Tue, 8 Dec 2020 05:05:19 GMT"}], "update_date": "2020-12-09", "authors_parsed": [["Velmurugan", "Mythreyi", ""], ["Ouyang", "Chun", ""], ["Moreira", "Catarina", ""], ["Sindhgatta", "Renuka", ""]]}, {"id": "2012.04226", "submitter": "Terrance Boult", "authors": "T. E. Boult, P. A. Grabowicz, D. S. Prijatelj, R. Stern, L. Holder, J.\n  Alspector, M. Jafarzadeh, T. Ahmad, A. R. Dhamija, C.Li, S. Cruz, A.\n  Shrivastava, C. Vondrick, W. J. Scheirer", "title": "A Unifying Framework for Formal Theories of Novelty:Framework, Examples\n  and Discussion", "comments": "Extended version/preprint of a AAAI 2021 paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Managing inputs that are novel, unknown, or out-of-distribution is critical\nas an agent moves from the lab to the open world. Novelty-related problems\ninclude being tolerant to novel perturbations of the normal input, detecting\nwhen the input includes novel items, and adapting to novel inputs. While\nsignificant research has been undertaken in these areas, a noticeable gap\nexists in the lack of a formalized definition of novelty that transcends\nproblem domains. As a team of researchers spanning multiple research groups and\ndifferent domains, we have seen, first hand, the difficulties that arise from\nill-specified novelty problems, as well as inconsistent definitions and\nterminology. Therefore, we present the first unified framework for formal\ntheories of novelty and use the framework to formally define a family of\nnovelty types. Our framework can be applied across a wide range of domains,\nfrom symbolic AI to reinforcement learning, and beyond to open world image\nrecognition. Thus, it can be used to help kick-start new research efforts and\naccelerate ongoing work on these important novelty-related problems. This\nextended version of our AAAI 2021 paper included more details and examples in\nmultiple domains.\n", "versions": [{"version": "v1", "created": "Tue, 8 Dec 2020 05:24:51 GMT"}], "update_date": "2020-12-09", "authors_parsed": [["Boult", "T. E.", ""], ["Grabowicz", "P. A.", ""], ["Prijatelj", "D. S.", ""], ["Stern", "R.", ""], ["Holder", "L.", ""], ["Alspector", "J.", ""], ["Jafarzadeh", "M.", ""], ["Ahmad", "T.", ""], ["Dhamija", "A. R.", ""], ["Li", "C.", ""], ["Cruz", "S.", ""], ["Shrivastava", "A.", ""], ["Vondrick", "C.", ""], ["Scheirer", "W. J.", ""]]}, {"id": "2012.04276", "submitter": "Yinuo Guo", "authors": "Yinuo Guo, Hualei Zhu, Zeqi Lin, Bei Chen, Jian-Guang Lou, Dongmei\n  Zhang", "title": "Revisiting Iterative Back-Translation from the Perspective of\n  Compositional Generalization", "comments": "accepted in AAAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Human intelligence exhibits compositional generalization (i.e., the capacity\nto understand and produce unseen combinations of seen components), but current\nneural seq2seq models lack such ability. In this paper, we revisit iterative\nback-translation, a simple yet effective semi-supervised method, to investigate\nwhether and how it can improve compositional generalization. In this work: (1)\nWe first empirically show that iterative back-translation substantially\nimproves the performance on compositional generalization benchmarks (CFQ and\nSCAN). (2) To understand why iterative back-translation is useful, we carefully\nexamine the performance gains and find that iterative back-translation can\nincreasingly correct errors in pseudo-parallel data. (3) To further encourage\nthis mechanism, we propose curriculum iterative back-translation, which better\nimproves the quality of pseudo-parallel data, thus further improving the\nperformance.\n", "versions": [{"version": "v1", "created": "Tue, 8 Dec 2020 08:43:13 GMT"}], "update_date": "2020-12-09", "authors_parsed": [["Guo", "Yinuo", ""], ["Zhu", "Hualei", ""], ["Lin", "Zeqi", ""], ["Chen", "Bei", ""], ["Lou", "Jian-Guang", ""], ["Zhang", "Dongmei", ""]]}, {"id": "2012.04293", "submitter": "Aykut Erdem", "authors": "Tayfun Ates, Muhammed Samil Atesoglu, Cagatay Yigit, Ilker Kesen, Mert\n  Kobas, Erkut Erdem, Aykut Erdem, Tilbe Goksun, Deniz Yuret", "title": "CRAFT: A Benchmark for Causal Reasoning About Forces and inTeractions", "comments": "Submitted to the 35th Conference on Neural Information Processing\n  Systems (NeurIPS 2021) Track on Datasets and Benchmarks", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.CV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Humans are able to perceive, understand and reason about physical events.\nDeveloping models with similar physical understanding capabilities is a\nlong-standing goal of artificial intelligence. As a step towards this goal, in\nthis work, we introduce CRAFT, a new visual question answering dataset that\nrequires causal reasoning about physical forces and object interactions. It\ncontains 58K video and question pairs that are generated from 10K videos from\n20 different virtual environments, containing various objects in motion that\ninteract with each other and the scene. Two question categories from CRAFT\ninclude previously studied descriptive and counterfactual questions. Besides,\ninspired by the theories of force dynamics in cognitive linguistics, we\nintroduce new question categories that involve understanding the interactions\nof objects through the notions of cause, enable, and prevent. Our results\ndemonstrate that even though these tasks seem to be simple and intuitive for\nhumans, the evaluated baseline models, including existing state-of-the-art\nmethods, do not yet deal with the challenges posed in our benchmark dataset.\n", "versions": [{"version": "v1", "created": "Tue, 8 Dec 2020 09:11:32 GMT"}, {"version": "v2", "created": "Wed, 16 Jun 2021 10:55:23 GMT"}], "update_date": "2021-06-17", "authors_parsed": [["Ates", "Tayfun", ""], ["Atesoglu", "Muhammed Samil", ""], ["Yigit", "Cagatay", ""], ["Kesen", "Ilker", ""], ["Kobas", "Mert", ""], ["Erdem", "Erkut", ""], ["Erdem", "Aykut", ""], ["Goksun", "Tilbe", ""], ["Yuret", "Deniz", ""]]}, {"id": "2012.04324", "submitter": "Riccardo Volpi", "authors": "Riccardo Volpi, Diane Larlus, Gr\\'egory Rogez", "title": "Continual Adaptation of Visual Representations via Domain Randomization\n  and Meta-learning", "comments": "Accepted to CVPR 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most standard learning approaches lead to fragile models which are prone to\ndrift when sequentially trained on samples of a different nature - the\nwell-known \"catastrophic forgetting\" issue. In particular, when a model\nconsecutively learns from different visual domains, it tends to forget the past\ndomains in favor of the most recent ones. In this context, we show that one way\nto learn models that are inherently more robust against forgetting is domain\nrandomization - for vision tasks, randomizing the current domain's distribution\nwith heavy image manipulations. Building on this result, we devise a\nmeta-learning strategy where a regularizer explicitly penalizes any loss\nassociated with transferring the model from the current domain to different\n\"auxiliary\" meta-domains, while also easing adaptation to them. Such\nmeta-domains are also generated through randomized image manipulations. We\nempirically demonstrate in a variety of experiments - spanning from\nclassification to semantic segmentation - that our approach results in models\nthat are less prone to catastrophic forgetting when transferred to new domains.\n", "versions": [{"version": "v1", "created": "Tue, 8 Dec 2020 09:54:51 GMT"}, {"version": "v2", "created": "Thu, 8 Apr 2021 15:58:04 GMT"}], "update_date": "2021-04-09", "authors_parsed": [["Volpi", "Riccardo", ""], ["Larlus", "Diane", ""], ["Rogez", "Gr\u00e9gory", ""]]}, {"id": "2012.04337", "submitter": "Hwanjun Song", "authors": "Hwanjun Song, Minseok Kim, Dongmin Park, Yooju Shin, Jae-Gil Lee", "title": "Robust Learning by Self-Transition for Handling Noisy Labels", "comments": "Accepted at KDD 2021", "journal-ref": null, "doi": "10.1145/3447548.3467222", "report-no": null, "categories": "cs.LG cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Real-world data inevitably contains noisy labels, which induce the poor\ngeneralization of deep neural networks. It is known that the network typically\nbegins to rapidly memorize false-labeled samples after a certain point of\ntraining. Thus, to counter the label noise challenge, we propose a novel\nself-transitional learning method called MORPH, which automatically switches\nits learning phase at the transition point from seeding to evolution. In the\nseeding phase, the network is updated using all the samples to collect a seed\nof clean samples. Then, in the evolution phase, the network is updated using\nonly the set of arguably clean samples, which precisely keeps expanding by the\nupdated network. Thus, MORPH effectively avoids the overfitting to\nfalse-labeled samples throughout the entire training period. Extensive\nexperiments using five real-world or synthetic benchmark datasets demonstrate\nsubstantial improvements over state-of-the-art methods in terms of robustness\nand efficiency.\n", "versions": [{"version": "v1", "created": "Tue, 8 Dec 2020 10:25:29 GMT"}, {"version": "v2", "created": "Mon, 7 Jun 2021 10:29:02 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Song", "Hwanjun", ""], ["Kim", "Minseok", ""], ["Park", "Dongmin", ""], ["Shin", "Yooju", ""], ["Lee", "Jae-Gil", ""]]}, {"id": "2012.04344", "submitter": "Udo Schlegel", "authors": "Udo Schlegel, Daniela Oelke, Daniel A. Keim, Mennatallah El-Assady", "title": "An Empirical Study of Explainable AI Techniques on Deep Learning Models\n  For Time Series Tasks", "comments": "5 Pages, 2 Pages References, Pre-registration workshop NeurIPS\n  (2020), Vancouver, Canada", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Decision explanations of machine learning black-box models are often\ngenerated by applying Explainable AI (XAI) techniques. However, many proposed\nXAI methods produce unverified outputs. Evaluation and verification are usually\nachieved with a visual interpretation by humans on individual images or text.\nIn this preregistration, we propose an empirical study and benchmark framework\nto apply attribution methods for neural networks developed for images and text\ndata on time series. We present a methodology to automatically evaluate and\nrank attribution techniques on time series using perturbation methods to\nidentify reliable approaches.\n", "versions": [{"version": "v1", "created": "Tue, 8 Dec 2020 10:33:57 GMT"}], "update_date": "2020-12-09", "authors_parsed": [["Schlegel", "Udo", ""], ["Oelke", "Daniela", ""], ["Keim", "Daniel A.", ""], ["El-Assady", "Mennatallah", ""]]}, {"id": "2012.04345", "submitter": "Jicong Fan", "authors": "Jicong Fan", "title": "Large-Scale Subspace Clustering via k-Factorization", "comments": "Accepted to KDD'21", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Subspace clustering (SC) aims to cluster data lying in a union of\nlow-dimensional subspaces. Usually, SC learns an affinity matrix and then\nperforms spectral clustering. Both steps suffer from high time and space\ncomplexity, which leads to difficulty in clustering large datasets. This paper\npresents a method called k-Factorization Subspace Clustering (k-FSC) for\nlarge-scale subspace clustering. K-FSC directly factorizes the data into k\ngroups via pursuing structured sparsity in the matrix factorization model.\nThus, k-FSC avoids learning affinity matrix and performing eigenvalue\ndecomposition, and has low (linear) time and space complexity on large\ndatasets. This paper proves the effectiveness of the k-FSC model theoretically.\nAn efficient algorithm with convergence guarantee is proposed to solve the\noptimization of k-FSC. In addition, k-FSC is able to handle sparse noise,\noutliers, and missing data, which are pervasive in real applications. This\npaper also provides online extension and out-of-sample extension for k-FSC to\nhandle streaming data and cluster arbitrarily large datasets. Extensive\nexperiments on large-scale real datasets show that k-FSC and its extensions\noutperform state-of-the-art methods of subspace clustering.\n", "versions": [{"version": "v1", "created": "Tue, 8 Dec 2020 10:34:21 GMT"}, {"version": "v2", "created": "Sun, 30 May 2021 15:37:45 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Fan", "Jicong", ""]]}, {"id": "2012.04373", "submitter": "Zihan Liu", "authors": "Zihan Liu, Yan Xu, Tiezheng Yu, Wenliang Dai, Ziwei Ji, Samuel\n  Cahyawijaya, Andrea Madotto, Pascale Fung", "title": "CrossNER: Evaluating Cross-Domain Named Entity Recognition", "comments": "Accepted in AAAI-2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cross-domain named entity recognition (NER) models are able to cope with the\nscarcity issue of NER samples in target domains. However, most of the existing\nNER benchmarks lack domain-specialized entity types or do not focus on a\ncertain domain, leading to a less effective cross-domain evaluation. To address\nthese obstacles, we introduce a cross-domain NER dataset (CrossNER), a\nfully-labeled collection of NER data spanning over five diverse domains with\nspecialized entity categories for different domains. Additionally, we also\nprovide a domain-related corpus since using it to continue pre-training\nlanguage models (domain-adaptive pre-training) is effective for the domain\nadaptation. We then conduct comprehensive experiments to explore the\neffectiveness of leveraging different levels of the domain corpus and\npre-training strategies to do domain-adaptive pre-training for the cross-domain\ntask. Results show that focusing on the fractional corpus containing\ndomain-specialized entities and utilizing a more challenging pre-training\nstrategy in domain-adaptive pre-training are beneficial for the NER domain\nadaptation, and our proposed method can consistently outperform existing\ncross-domain NER baselines. Nevertheless, experiments also illustrate the\nchallenge of this cross-domain NER task. We hope that our dataset and baselines\nwill catalyze research in the NER domain adaptation area. The code and data are\navailable at https://github.com/zliucr/CrossNER.\n", "versions": [{"version": "v1", "created": "Tue, 8 Dec 2020 11:31:55 GMT"}, {"version": "v2", "created": "Sun, 13 Dec 2020 07:43:16 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["Liu", "Zihan", ""], ["Xu", "Yan", ""], ["Yu", "Tiezheng", ""], ["Dai", "Wenliang", ""], ["Ji", "Ziwei", ""], ["Cahyawijaya", "Samuel", ""], ["Madotto", "Andrea", ""], ["Fung", "Pascale", ""]]}, {"id": "2012.04380", "submitter": "Ryan Beal Mr.", "authors": "Ryan Beal, Stuart E. Middleton, Timothy J. Norman, Sarvapali D.\n  Ramchurn", "title": "Combining Machine Learning and Human Experts to Predict Match Outcomes\n  in Football: A Baseline Model", "comments": "Pre-print. Accepted at: The Thirty-Third Annual Conference on\n  Innovative Applications of Artificial Intelligence (IAAI-21). 5 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we present a new application-focused benchmark dataset and\nresults from a set of baseline Natural Language Processing and Machine Learning\nmodels for prediction of match outcomes for games of football (soccer). By\ndoing so we give a baseline for the prediction accuracy that can be achieved\nexploiting both statistical match data and contextual articles from human\nsports journalists. Our dataset is focuses on a representative time-period over\n6 seasons of the English Premier League, and includes newspaper match previews\nfrom The Guardian. The models presented in this paper achieve an accuracy of\n63.18% showing a 6.9% boost on the traditional statistical methods.\n", "versions": [{"version": "v1", "created": "Tue, 8 Dec 2020 11:52:14 GMT"}], "update_date": "2020-12-09", "authors_parsed": [["Beal", "Ryan", ""], ["Middleton", "Stuart E.", ""], ["Norman", "Timothy J.", ""], ["Ramchurn", "Sarvapali D.", ""]]}, {"id": "2012.04405", "submitter": "Ryan K. L. Ko", "authors": "Ryan K L Ko", "title": "Cyber Autonomy: Automating the Hacker- Self-healing, self-adaptive,\n  automatic cyber defense systems and their impact to the industry, society and\n  national security", "comments": "15 pages, 5 figures, preprint of chapter in edited book \"Emerging\n  Technologies and International Security: Machines, the State, and War\" edited\n  By Reuben Steff, Joe Burton, Simona R. Soare", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.CY cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper sets the context for the urgency for cyber autonomy, and the\ncurrent gaps of the cyber security industry. A novel framework proposing four\nphases of maturity for full cyber autonomy will be discussed. The paper also\nreviews new and emerging cyber security automation techniques and tools, and\ndiscusses their impact on society, the perceived cyber security skills\ngap/shortage and national security. We will also be discussing the delicate\nbalance between national security, human rights and ethics, and the potential\ndemise of the manual penetration testing industry in the face of automation.\n", "versions": [{"version": "v1", "created": "Tue, 8 Dec 2020 12:50:09 GMT"}], "update_date": "2020-12-09", "authors_parsed": [["Ko", "Ryan K L", ""]]}, {"id": "2012.04424", "submitter": "Stefan Mengel", "authors": "Danel Le Berre, Pierre Marquis, Stefan Mengel, Romain Wallon", "title": "On Irrelevant Literals in Pseudo-Boolean Constraint Learning", "comments": "published at IJCAI 2020", "journal-ref": null, "doi": "10.24963/ijcai.2020/160", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning pseudo-Boolean (PB) constraints in PB solvers exploiting cutting\nplanes based inference is not as well understood as clause learning in\nconflict-driven clause learning solvers. In this paper, we show that PB\nconstraints derived using cutting planes may contain \\emph{irrelevant\nliterals}, i.e., literals whose assigned values (whatever they are) never\nchange the truth value of the constraint. Such literals may lead to infer\nconstraints that are weaker than they should be, impacting the size of the\nproof built by the solver, and thus also affecting its performance. This\nsuggests that current implementations of PB solvers based on cutting planes\nshould be reconsidered to prevent the generation of irrelevant literals.\nIndeed, detecting and removing irrelevant literals is too expensive in practice\nto be considered as an option (the associated problem is NP-hard.\n", "versions": [{"version": "v1", "created": "Tue, 8 Dec 2020 13:52:09 GMT"}], "update_date": "2020-12-09", "authors_parsed": [["Berre", "Danel Le", ""], ["Marquis", "Pierre", ""], ["Mengel", "Stefan", ""], ["Wallon", "Romain", ""]]}, {"id": "2012.04442", "submitter": "Michael Neumann", "authors": "Michael Neumann, Sebastian Koralewski and Michael Beetz", "title": "URoboSim -- An Episodic Simulation Framework for Prospective Reasoning\n  in Robotic Agents", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Anticipating what might happen as a result of an action is an essential\nability humans have in order to perform tasks effectively. On the other hand,\nrobots capabilities in this regard are quite lacking. While machine learning is\nused to increase the ability of prospection it is still limiting for novel\nsituations. A possibility to improve the prospection ability of robots is\nthrough simulation of imagined motions and the physical results of these\nactions. Therefore, we present URoboSim, a robot simulator that allows robots\nto perform tasks as mental simulation before performing this task in reality.\nWe show the capabilities of URoboSim in form of mental simulations, generating\ndata for machine learning and the usage as belief state for a real robot.\n", "versions": [{"version": "v1", "created": "Tue, 8 Dec 2020 14:23:24 GMT"}], "update_date": "2020-12-09", "authors_parsed": [["Neumann", "Michael", ""], ["Koralewski", "Sebastian", ""], ["Beetz", "Michael", ""]]}, {"id": "2012.04454", "submitter": "Paul-Gauthier No\\'e", "authors": "Paul-Gauthier No\\'e, Mohammad Mohammadamini, Driss Matrouf, Titouan\n  Parcollet, Andreas Nautsch, Jean-Fran\\c{c}ois Bonastre", "title": "Adversarial Disentanglement of Speaker Representation for\n  Attribute-Driven Privacy Preservation", "comments": "Accepted to Interspeech 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.AI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In speech technologies, speaker's voice representation is used in many\napplications such as speech recognition, voice conversion, speech synthesis\nand, obviously, user authentication. Modern vocal representations of the\nspeaker are based on neural embeddings. In addition to the targeted\ninformation, these representations usually contain sensitive information about\nthe speaker, like the age, sex, physical state, education level or ethnicity.\nIn order to allow the user to choose which information to protect, we introduce\nin this paper the concept of attribute-driven privacy preservation in speaker\nvoice representation. It allows a person to hide one or more personal aspects\nto a potential malicious interceptor and to the application provider. As a\nfirst solution to this concept, we propose to use an adversarial autoencoding\nmethod that disentangles in the voice representation a given speaker attribute\nthus allowing its concealment. We focus here on the sex attribute for an\nAutomatic Speaker Verification (ASV) task. Experiments carried out using the\nVoxCeleb datasets have shown that the proposed method enables the concealment\nof this attribute while preserving ASV ability.\n", "versions": [{"version": "v1", "created": "Tue, 8 Dec 2020 14:47:23 GMT"}, {"version": "v2", "created": "Fri, 23 Apr 2021 09:26:53 GMT"}, {"version": "v3", "created": "Wed, 16 Jun 2021 08:40:07 GMT"}], "update_date": "2021-06-17", "authors_parsed": [["No\u00e9", "Paul-Gauthier", ""], ["Mohammadamini", "Mohammad", ""], ["Matrouf", "Driss", ""], ["Parcollet", "Titouan", ""], ["Nautsch", "Andreas", ""], ["Bonastre", "Jean-Fran\u00e7ois", ""]]}, {"id": "2012.04461", "submitter": "Jiongzhi Zheng", "authors": "Jiongzhi Zheng and Kun He and Jianrong Zhou and Yan Jin and Chu-Min Li", "title": "Combining Reinforcement Learning with Lin-Kernighan-Helsgaun Algorithm\n  for the Traveling Salesman Problem", "comments": "Accepted by AAAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We address the Traveling Salesman Problem (TSP), a famous NP-hard\ncombinatorial optimization problem. And we propose a variable strategy\nreinforced approach, denoted as VSR-LKH, which combines three reinforcement\nlearning methods (Q-learning, Sarsa and Monte Carlo) with the well-known TSP\nalgorithm, called Lin-Kernighan-Helsgaun (LKH). VSR-LKH replaces the inflexible\ntraversal operation in LKH, and lets the program learn to make choice at each\nsearch step by reinforcement learning. Experimental results on 111 TSP\nbenchmarks from the TSPLIB with up to 85,900 cities demonstrate the excellent\nperformance of the proposed method.\n", "versions": [{"version": "v1", "created": "Tue, 8 Dec 2020 14:58:36 GMT"}, {"version": "v2", "created": "Wed, 9 Dec 2020 08:02:45 GMT"}, {"version": "v3", "created": "Sun, 13 Dec 2020 14:25:16 GMT"}, {"version": "v4", "created": "Mon, 28 Dec 2020 05:30:11 GMT"}, {"version": "v5", "created": "Fri, 12 Mar 2021 07:26:17 GMT"}, {"version": "v6", "created": "Wed, 17 Mar 2021 08:02:11 GMT"}], "update_date": "2021-03-18", "authors_parsed": [["Zheng", "Jiongzhi", ""], ["He", "Kun", ""], ["Zhou", "Jianrong", ""], ["Jin", "Yan", ""], ["Li", "Chu-Min", ""]]}, {"id": "2012.04529", "submitter": "Lingbo Liu", "authors": "Lingbo Liu, Jiaqi Chen, Hefeng Wu, Guanbin Li, Chenglong Li, Liang Lin", "title": "Cross-Modal Collaborative Representation Learning and a Large-Scale RGBT\n  Benchmark for Crowd Counting", "comments": "Accepted by CVPR2021. Our code and benchmark for RGBT crowd counting\n  are released at {\\url{http://lingboliu.com/RGBT_Crowd_Counting.html}}", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Crowd counting is a fundamental yet challenging task, which desires rich\ninformation to generate pixel-wise crowd density maps. However, most previous\nmethods only used the limited information of RGB images and cannot well\ndiscover potential pedestrians in unconstrained scenarios. In this work, we\nfind that incorporating optical and thermal information can greatly help to\nrecognize pedestrians. To promote future researches in this field, we introduce\na large-scale RGBT Crowd Counting (RGBT-CC) benchmark, which contains 2,030\npairs of RGB-thermal images with 138,389 annotated people. Furthermore, to\nfacilitate the multimodal crowd counting, we propose a cross-modal\ncollaborative representation learning framework, which consists of multiple\nmodality-specific branches, a modality-shared branch, and an Information\nAggregation-Distribution Module (IADM) to capture the complementary information\nof different modalities fully. Specifically, our IADM incorporates two\ncollaborative information transfers to dynamically enhance the modality-shared\nand modality-specific representations with a dual information propagation\nmechanism. Extensive experiments conducted on the RGBT-CC benchmark demonstrate\nthe effectiveness of our framework for RGBT crowd counting. Moreover, the\nproposed approach is universal for multimodal crowd counting and is also\ncapable to achieve superior performance on the ShanghaiTechRGBD dataset.\nFinally, our source code and benchmark are released at\n{\\url{http://lingboliu.com/RGBT_Crowd_Counting.html}}.\n", "versions": [{"version": "v1", "created": "Tue, 8 Dec 2020 16:18:29 GMT"}, {"version": "v2", "created": "Tue, 6 Apr 2021 03:02:31 GMT"}], "update_date": "2021-04-07", "authors_parsed": [["Liu", "Lingbo", ""], ["Chen", "Jiaqi", ""], ["Wu", "Hefeng", ""], ["Li", "Guanbin", ""], ["Li", "Chenglong", ""], ["Lin", "Liang", ""]]}, {"id": "2012.04572", "submitter": "Joseph Turian", "authors": "Joseph Turian, Max Henry", "title": "I'm Sorry for Your Loss: Spectrally-Based Audio Distances Are Bad at\n  Pitch", "comments": "ICBINB@NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.AI cs.LG eess.AS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Growing research demonstrates that synthetic failure modes imply poor\ngeneralization. We compare commonly used audio-to-audio losses on a synthetic\nbenchmark, measuring the pitch distance between two stationary sinusoids. The\nresults are surprising: many have poor sense of pitch direction. These\nshortcomings are exposed using simple rank assumptions. Our task is trivial for\nhumans but difficult for these audio distances, suggesting significant progress\ncan be made in self-supervised audio learning by improving current losses.\n", "versions": [{"version": "v1", "created": "Tue, 8 Dec 2020 17:17:28 GMT"}, {"version": "v2", "created": "Wed, 9 Dec 2020 20:42:50 GMT"}], "update_date": "2020-12-11", "authors_parsed": [["Turian", "Joseph", ""], ["Henry", "Max", ""]]}, {"id": "2012.04626", "submitter": "Marc Rigter", "authors": "Marc Rigter, Bruno Lacerda, Nick Hawes", "title": "Minimax Regret Optimisation for Robust Planning in Uncertain Markov\n  Decision Processes", "comments": "Long version of paper to appear in AAAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The parameters for a Markov Decision Process (MDP) often cannot be specified\nexactly. Uncertain MDPs (UMDPs) capture this model ambiguity by defining sets\nwhich the parameters belong to. Minimax regret has been proposed as an\nobjective for planning in UMDPs to find robust policies which are not overly\nconservative. In this work, we focus on planning for Stochastic Shortest Path\n(SSP) UMDPs with uncertain cost and transition functions. We introduce a\nBellman equation to compute the regret for a policy. We propose a dynamic\nprogramming algorithm that utilises the regret Bellman equation, and show that\nit optimises minimax regret exactly for UMDPs with independent uncertainties.\nFor coupled uncertainties, we extend our approach to use options to enable a\ntrade off between computation and solution quality. We evaluate our approach on\nboth synthetic and real-world domains, showing that it significantly\noutperforms existing baselines.\n", "versions": [{"version": "v1", "created": "Tue, 8 Dec 2020 18:48:14 GMT"}], "update_date": "2020-12-09", "authors_parsed": [["Rigter", "Marc", ""], ["Lacerda", "Bruno", ""], ["Hawes", "Nick", ""]]}, {"id": "2012.04630", "submitter": "Ramprasaath R. Selvaraju", "authors": "Ramprasaath R. Selvaraju, Karan Desai, Justin Johnson, Nikhil Naik", "title": "CASTing Your Model: Learning to Localize Improves Self-Supervised\n  Representations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in self-supervised learning (SSL) have largely closed the gap\nwith supervised ImageNet pretraining. Despite their success these methods have\nbeen primarily applied to unlabeled ImageNet images, and show marginal gains\nwhen trained on larger sets of uncurated images. We hypothesize that current\nSSL methods perform best on iconic images, and struggle on complex scene images\nwith many objects. Analyzing contrastive SSL methods shows that they have poor\nvisual grounding and receive poor supervisory signal when trained on scene\nimages. We propose Contrastive Attention-Supervised Tuning(CAST) to overcome\nthese limitations. CAST uses unsupervised saliency maps to intelligently sample\ncrops, and to provide grounding supervision via a Grad-CAM attention loss.\nExperiments on COCO show that CAST significantly improves the features learned\nby SSL methods on scene images, and further experiments show that CAST-trained\nmodels are more robust to changes in backgrounds.\n", "versions": [{"version": "v1", "created": "Tue, 8 Dec 2020 18:50:18 GMT"}], "update_date": "2020-12-09", "authors_parsed": [["Selvaraju", "Ramprasaath R.", ""], ["Desai", "Karan", ""], ["Johnson", "Justin", ""], ["Naik", "Nikhil", ""]]}, {"id": "2012.04651", "submitter": "Ioanna Miliou", "authors": "Ioanna Miliou, Xinyue Xiong, Salvatore Rinzivillo, Qian Zhang, Giulio\n  Rossetti, Fosca Giannotti, Dino Pedreschi, Alessandro Vespignani", "title": "Predicting seasonal influenza using supermarket retail records", "comments": "17 pages, 2 figures, 4 tables (1 in appendix), 1 algorithm, submitted\n  to PLOS Computational Biology", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Increased availability of epidemiological data, novel digital data streams,\nand the rise of powerful machine learning approaches have generated a surge of\nresearch activity on real-time epidemic forecast systems. In this paper, we\npropose the use of a novel data source, namely retail market data to improve\nseasonal influenza forecasting. Specifically, we consider supermarket retail\ndata as a proxy signal for influenza, through the identification of sentinel\nbaskets, i.e., products bought together by a population of selected customers.\nWe develop a nowcasting and forecasting framework that provides estimates for\ninfluenza incidence in Italy up to 4 weeks ahead. We make use of the Support\nVector Regression (SVR) model to produce the predictions of seasonal flu\nincidence. Our predictions outperform both a baseline autoregressive model and\na second baseline based on product purchases. The results show quantitatively\nthe value of incorporating retail market data in forecasting models, acting as\na proxy that can be used for the real-time analysis of epidemics.\n", "versions": [{"version": "v1", "created": "Tue, 8 Dec 2020 16:30:43 GMT"}, {"version": "v2", "created": "Thu, 17 Dec 2020 14:17:25 GMT"}], "update_date": "2020-12-21", "authors_parsed": [["Miliou", "Ioanna", ""], ["Xiong", "Xinyue", ""], ["Rinzivillo", "Salvatore", ""], ["Zhang", "Qian", ""], ["Rossetti", "Giulio", ""], ["Giannotti", "Fosca", ""], ["Pedreschi", "Dino", ""], ["Vespignani", "Alessandro", ""]]}, {"id": "2012.04687", "submitter": "Thibault Cordier", "authors": "Thibault Cordier, Tanguy Urvoy, Lina M. Rojas-Barahona, Fabrice\n  Lef\\`evre", "title": "Diluted Near-Optimal Expert Demonstrations for Guiding Dialogue\n  Stochastic Policy Optimisation", "comments": "8 pages, Accepted at Human in the Loop Dialogue Systems Workshop,\n  NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A learning dialogue agent can infer its behaviour from interactions with the\nusers. These interactions can be taken from either human-to-human or\nhuman-machine conversations. However, human interactions are scarce and costly,\nmaking learning from few interactions essential. One solution to speedup the\nlearning process is to guide the agent's exploration with the help of an\nexpert. We present in this paper several imitation learning strategies for\ndialogue policy where the guiding expert is a near-optimal handcrafted policy.\nWe incorporate these strategies with state-of-the-art reinforcement learning\nmethods based on Q-learning and actor-critic. We notably propose a randomised\nexploration policy which allows for a seamless hybridisation of the learned\npolicy and the expert. Our experiments show that our hybridisation strategy\noutperforms several baselines, and that it can accelerate the learning when\nfacing real humans.\n", "versions": [{"version": "v1", "created": "Wed, 25 Nov 2020 15:00:36 GMT"}], "update_date": "2020-12-10", "authors_parsed": [["Cordier", "Thibault", ""], ["Urvoy", "Tanguy", ""], ["Rojas-Barahona", "Lina M.", ""], ["Lef\u00e8vre", "Fabrice", ""]]}, {"id": "2012.04689", "submitter": "Otto Brookes", "authors": "Otto Brookes, Tilo Burghardt", "title": "A Dataset and Application for Facial Recognition of Individual Gorillas\n  in Zoo Environments", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We put forward a video dataset with 5k+ facial bounding box annotations\nacross a troop of 7 western lowland gorillas at Bristol Zoo Gardens. Training\non this dataset, we implement and evaluate a standard deep learning pipeline on\nthe task of facially recognising individual gorillas in a zoo environment. We\nshow that a basic YOLOv3-powered application is able to perform identifications\nat 92% mAP when utilising single frames only. Tracking-by-detection-association\nand identity voting across short tracklets yields an improved robust\nperformance of 97% mAP. To facilitate easy utilisation for enriching the\nresearch capabilities of zoo environments, we publish the code, video dataset,\nweights, and ground-truth annotations at data.bris.ac.uk.\n", "versions": [{"version": "v1", "created": "Tue, 8 Dec 2020 19:23:22 GMT"}, {"version": "v2", "created": "Fri, 26 Mar 2021 17:38:09 GMT"}], "update_date": "2021-03-29", "authors_parsed": [["Brookes", "Otto", ""], ["Burghardt", "Tilo", ""]]}, {"id": "2012.04698", "submitter": "Nishtha Madaan", "authors": "Nishtha Madaan, Inkit Padhi, Naveen Panwar, Diptikalyan Saha", "title": "Generate Your Counterfactuals: Towards Controlled Counterfactual\n  Generation for Text", "comments": "Accepted at AAAI Conference on Artificial Intelligence (AAAI 2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine Learning has seen tremendous growth recently, which has led to larger\nadoption of ML systems for educational assessments, credit risk, healthcare,\nemployment, criminal justice, to name a few. The trustworthiness of ML and NLP\nsystems is a crucial aspect and requires a guarantee that the decisions they\nmake are fair and robust. Aligned with this, we propose a framework GYC, to\ngenerate a set of counterfactual text samples, which are crucial for testing\nthese ML systems. Our main contributions include a) We introduce GYC, a\nframework to generate counterfactual samples such that the generation is\nplausible, diverse, goal-oriented, and effective, b) We generate counterfactual\nsamples, that can direct the generation towards a corresponding condition such\nas named-entity tag, semantic role label, or sentiment. Our experimental\nresults on various domains show that GYC generates counterfactual text samples\nexhibiting the above four properties. GYC generates counterfactuals that can\nact as test cases to evaluate a model and any text debiasing algorithm.\n", "versions": [{"version": "v1", "created": "Tue, 8 Dec 2020 19:34:53 GMT"}, {"version": "v2", "created": "Wed, 17 Mar 2021 18:24:46 GMT"}], "update_date": "2021-03-19", "authors_parsed": [["Madaan", "Nishtha", ""], ["Padhi", "Inkit", ""], ["Panwar", "Naveen", ""], ["Saha", "Diptikalyan", ""]]}, {"id": "2012.04700", "submitter": "Yoonsuck Choe", "authors": "Khuong Nguyen and Yoonsuck Choe", "title": "Emergence of Different Modes of Tool Use in a Reaching and Dragging Task", "comments": "11 pages, 10 figures, 14 pdf-embedded animations", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG cs.NE", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Tool use is an important milestone in the evolution of intelligence. In this\npaper, we investigate different modes of tool use that emerge in a reaching and\ndragging task. In this task, a jointed arm with a gripper must grab a tool (T,\nI, or L-shaped) and drag an object down to the target location (the bottom of\nthe arena). The simulated environment had real physics such as gravity and\nfriction. We trained a deep-reinforcement learning based controller (with raw\nvisual and proprioceptive input) with minimal reward shaping information to\ntackle this task. We observed the emergence of a wide range of unexpected\nbehaviors, not directly encoded in the motor primitives or reward functions.\nExamples include hitting the object to the target location, correcting error of\ninitial contact, throwing the tool toward the object, as well as normal\nexpected behavior such as wide sweep. Also, we further analyzed these behaviors\nbased on the type of tool and the initial position of the target object. Our\nresults show a rich repertoire of behaviors, beyond the basic built-in\nmechanisms of the deep reinforcement learning method we used.\n", "versions": [{"version": "v1", "created": "Tue, 8 Dec 2020 19:37:58 GMT"}], "update_date": "2020-12-10", "authors_parsed": [["Nguyen", "Khuong", ""], ["Choe", "Yoonsuck", ""]]}, {"id": "2012.04715", "submitter": "Curtis Bright", "authors": "Curtis Bright, Kevin K. H. Cheung, Brett Stevens, Ilias Kotsireas,\n  Vijay Ganesh", "title": "A SAT-based Resolution of Lam's Problem", "comments": "To appear at the Thirty-Fifth AAAI Conference on Artificial\n  Intelligence", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DM cs.AI cs.LO cs.SC math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In 1989, computer searches by Lam, Thiel, and Swiercz experimentally resolved\nLam's problem from projective geometry$\\unicode{x2014}$the long-standing\nproblem of determining if a projective plane of order ten exists. Both the\noriginal search and an independent verification in 2011 discovered no such\nprojective plane. However, these searches were each performed using highly\nspecialized custom-written code and did not produce nonexistence certificates.\nIn this paper, we resolve Lam's problem by translating the problem into Boolean\nlogic and use satisfiability (SAT) solvers to produce nonexistence certificates\nthat can be verified by a third party. Our work uncovered consistency issues in\nboth previous searches$\\unicode{x2014}$highlighting the difficulty of relying\non special-purpose search code for nonexistence results.\n", "versions": [{"version": "v1", "created": "Tue, 8 Dec 2020 20:06:25 GMT"}], "update_date": "2020-12-10", "authors_parsed": [["Bright", "Curtis", ""], ["Cheung", "Kevin K. H.", ""], ["Stevens", "Brett", ""], ["Kotsireas", "Ilias", ""], ["Ganesh", "Vijay", ""]]}, {"id": "2012.04723", "submitter": "Tineke Blom", "authors": "Tineke Blom and Joris M. Mooij", "title": "Robustness of Model Predictions under Extension", "comments": "Accepted for oral presentation at the Causal Discovery &\n  Causality-Inspired Machine Learning Workshop at Neural Information Processing\n  Systems, 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Often, mathematical models of the real world are simplified representations\nof complex systems. A caveat to using models for analysis is that predicted\ncausal effects and conditional independences may not be robust under model\nextensions, and therefore applicability of such models is limited. In this\nwork, we consider conditions under which qualitative model predictions are\npreserved when two models are combined. We show how to use the technique of\ncausal ordering to efficiently assess the robustness of qualitative model\npredictions and characterize a large class of model extensions that preserve\nthese predictions. For dynamical systems at equilibrium, we demonstrate how\nnovel insights help to select appropriate model extensions and to reason about\nthe presence of feedback loops. We apply our ideas to a viral infection model\nwith immune responses.\n", "versions": [{"version": "v1", "created": "Tue, 8 Dec 2020 20:21:03 GMT"}], "update_date": "2020-12-10", "authors_parsed": [["Blom", "Tineke", ""], ["Mooij", "Joris M.", ""]]}, {"id": "2012.04734", "submitter": "Mohammed Hassanin", "authors": "Mohammed Hassanin, Nour Moustafa, Murat Tahtali", "title": "A Deep Marginal-Contrastive Defense against Adversarial Attacks on 1D\n  Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Deep learning algorithms have been recently targeted by attackers due to\ntheir vulnerability. Several research studies have been conducted to address\nthis issue and build more robust deep learning models. Non-continuous deep\nmodels are still not robust against adversarial, where most of the recent\nstudies have focused on developing attack techniques to evade the learning\nprocess of the models. One of the main reasons behind the vulnerability of such\nmodels is that a learning classifier is unable to slightly predict perturbed\nsamples. To address this issue, we propose a novel objective/loss function, the\nso-called marginal contrastive, which enforces the features to lie under a\nspecified margin to facilitate their prediction using deep convolutional\nnetworks (i.e., Char-CNN). Extensive experiments have been conducted on\ncontinuous cases (e.g., UNSW NB15 dataset) and discrete ones (i.e,\neight-large-scale datasets [32]) to prove the effectiveness of the proposed\nmethod. The results revealed that the regularization of the learning process\nbased on the proposed loss function can improve the performance of Char-CNN.\n", "versions": [{"version": "v1", "created": "Tue, 8 Dec 2020 20:51:43 GMT"}], "update_date": "2020-12-10", "authors_parsed": [["Hassanin", "Mohammed", ""], ["Moustafa", "Nour", ""], ["Tahtali", "Murat", ""]]}, {"id": "2012.04735", "submitter": "Muhammad Usman", "authors": "Vahid Azizi, Muhammad Usman, Honglu Zhou, Petros Faloutsos and\n  Mubbasir Kapadia", "title": "Graph-Based Generative Representation Learning of Semantically and\n  Behaviorally Augmented Floorplans", "comments": null, "journal-ref": null, "doi": "10.1007/s00371-021-02155-w", "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Floorplans are commonly used to represent the layout of buildings. In\ncomputer aided-design (CAD) floorplans are usually represented in the form of\nhierarchical graph structures. Research works towards computational techniques\nthat facilitate the design process, such as automated analysis and\noptimization, often use simple floorplan representations that ignore the\nsemantics of the space and do not take into account usage related analytics. We\npresent a floorplan embedding technique that uses an attributed graph to\nrepresent the geometric information as well as design semantics and behavioral\nfeatures of the inhabitants as node and edge attributes. A Long Short-Term\nMemory (LSTM) Variational Autoencoder (VAE) architecture is proposed and\ntrained to embed attributed graphs as vectors in a continuous space. A user\nstudy is conducted to evaluate the coupling of similar floorplans retrieved\nfrom the embedding space with respect to a given input (e.g., design layout).\nThe qualitative, quantitative and user-study evaluations show that our\nembedding framework produces meaningful and accurate vector representations for\nfloorplans. In addition, our proposed model is a generative model. We studied\nand showcased its effectiveness for generating new floorplans. We also release\nthe dataset that we have constructed and which, for each floorplan, includes\nthe design semantics attributes as well as simulation generated human\nbehavioral features for further study in the community.\n", "versions": [{"version": "v1", "created": "Tue, 8 Dec 2020 20:51:56 GMT"}], "update_date": "2021-06-04", "authors_parsed": [["Azizi", "Vahid", ""], ["Usman", "Muhammad", ""], ["Zhou", "Honglu", ""], ["Faloutsos", "Petros", ""], ["Kapadia", "Mubbasir", ""]]}, {"id": "2012.04740", "submitter": "Jacob Montiel", "authors": "Jacob Montiel, Max Halford, Saulo Martiello Mastelini, Geoffrey\n  Bolmier, Raphael Sourty, Robin Vaysse, Adil Zouitine, Heitor Murilo Gomes,\n  Jesse Read, Talel Abdessalem, Albert Bifet", "title": "River: machine learning for streaming data in Python", "comments": "Submitted to JMLR MLOSS", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  River is a machine learning library for dynamic data streams and continual\nlearning. It provides multiple state-of-the-art learning methods, data\ngenerators/transformers, performance metrics and evaluators for different\nstream learning problems. It is the result from the merger of the two most\npopular packages for stream learning in Python: Creme and scikit-multiflow.\nRiver introduces a revamped architecture based on the lessons learnt from the\nseminal packages. River's ambition is to be the go-to library for doing machine\nlearning on streaming data. Additionally, this open source package brings under\nthe same umbrella a large community of practitioners and researchers. The\nsource code is available at https://github.com/online-ml/river.\n", "versions": [{"version": "v1", "created": "Tue, 8 Dec 2020 21:04:44 GMT"}], "update_date": "2020-12-10", "authors_parsed": [["Montiel", "Jacob", ""], ["Halford", "Max", ""], ["Mastelini", "Saulo Martiello", ""], ["Bolmier", "Geoffrey", ""], ["Sourty", "Raphael", ""], ["Vaysse", "Robin", ""], ["Zouitine", "Adil", ""], ["Gomes", "Heitor Murilo", ""], ["Read", "Jesse", ""], ["Abdessalem", "Talel", ""], ["Bifet", "Albert", ""]]}, {"id": "2012.04750", "submitter": "Mohammed Hassanin", "authors": "Mohammed Hassanin, Ibrahim Radwan, Nour Moustafa, Murat Tahtali,\n  Neeraj Kumar", "title": "Mitigating the Impact of Adversarial Attacks in Very Deep Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Deep Neural Network (DNN) models have vulnerabilities related to security\nconcerns, with attackers usually employing complex hacking techniques to expose\ntheir structures. Data poisoning-enabled perturbation attacks are complex\nadversarial ones that inject false data into models. They negatively impact the\nlearning process, with no benefit to deeper networks, as they degrade a model's\naccuracy and convergence rates. In this paper, we propose an\nattack-agnostic-based defense method for mitigating their influence. In it, a\nDefensive Feature Layer (DFL) is integrated with a well-known DNN architecture\nwhich assists in neutralizing the effects of illegitimate perturbation samples\nin the feature space. To boost the robustness and trustworthiness of this\nmethod for correctly classifying attacked input samples, we regularize the\nhidden space of a trained model with a discriminative loss function called\nPolarized Contrastive Loss (PCL). It improves discrimination among samples in\ndifferent classes and maintains the resemblance of those in the same class.\nAlso, we integrate a DFL and PCL in a compact model for defending against data\npoisoning attacks. This method is trained and tested using the CIFAR-10 and\nMNIST datasets with data poisoning-enabled perturbation attacks, with the\nexperimental results revealing its excellent performance compared with those of\nrecent peer techniques.\n", "versions": [{"version": "v1", "created": "Tue, 8 Dec 2020 21:25:44 GMT"}], "update_date": "2020-12-10", "authors_parsed": [["Hassanin", "Mohammed", ""], ["Radwan", "Ibrahim", ""], ["Moustafa", "Nour", ""], ["Tahtali", "Murat", ""], ["Kumar", "Neeraj", ""]]}, {"id": "2012.04751", "submitter": "Sebastian Risi", "authors": "Djordje Grbic, Rasmus Berg Palm, Elias Najarro, Claire Glanois,\n  Sebastian Risi", "title": "EvoCraft: A New Challenge for Open-Endedness", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces EvoCraft, a framework for Minecraft designed to study\nopen-ended algorithms. We introduce an API that provides an open-source Python\ninterface for communicating with Minecraft to place and track blocks. In\ncontrast to previous work in Minecraft that focused on learning to play the\ngame, the grand challenge we pose here is to automatically search for\nincreasingly complex artifacts in an open-ended fashion. Compared to other\nenvironments used to study open-endedness, Minecraft allows the construction of\nalmost any kind of structure, including actuated machines with circuits and\nmechanical components. We present initial baseline results in evolving simple\nMinecraft creations through both interactive and automated evolution. While\nevolution succeeds when tasked to grow a structure towards a specific target,\nit is unable to find a solution when rewarded for creating a simple machine\nthat moves. Thus, EvoCraft offers a challenging new environment for automated\nsearch methods (such as evolution) to find complex artifacts that we hope will\nspur the development of more open-ended algorithms. A Python implementation of\nthe EvoCraft framework is available at:\nhttps://github.com/real-itu/Evocraft-py.\n", "versions": [{"version": "v1", "created": "Tue, 8 Dec 2020 21:36:18 GMT"}], "update_date": "2020-12-10", "authors_parsed": [["Grbic", "Djordje", ""], ["Palm", "Rasmus Berg", ""], ["Najarro", "Elias", ""], ["Glanois", "Claire", ""], ["Risi", "Sebastian", ""]]}, {"id": "2012.04759", "submitter": "Yiming Xu", "authors": "Yiming Xu, Diego Klabjan", "title": "Concept Drift and Covariate Shift Detection Ensemble with Lagged Labels", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In model serving, having one fixed model during the entire often life-long\ninference process is usually detrimental to model performance, as data\ndistribution evolves over time, resulting in lack of reliability of the model\ntrained on historical data. It is important to detect changes and retrain the\nmodel in time. The existing methods generally have three weaknesses: 1) using\nonly classification error rate as signal, 2) assuming ground truth labels are\nimmediately available after features from samples are received and 3) unable to\ndecide what data to use to retrain the model when change occurs. We address the\nfirst problem by utilizing six different signals to capture a wide range of\ncharacteristics of data, and we address the second problem by allowing lag of\nlabels, where labels of corresponding features are received after a lag in\ntime. For the third problem, our proposed method automatically decides what\ndata to use to retrain based on the signals. Extensive experiments on\nstructured and unstructured data for different type of data changes establish\nthat our method consistently outperforms the state-of-the-art methods by a\nlarge margin.\n", "versions": [{"version": "v1", "created": "Tue, 8 Dec 2020 21:57:05 GMT"}, {"version": "v2", "created": "Sat, 12 Dec 2020 20:48:31 GMT"}, {"version": "v3", "created": "Tue, 15 Dec 2020 03:49:59 GMT"}], "update_date": "2020-12-16", "authors_parsed": [["Xu", "Yiming", ""], ["Klabjan", "Diego", ""]]}, {"id": "2012.04776", "submitter": "Aref Darzi", "authors": "Chenfeng Xiong, Aref Darzi, Yixuan Pan, Sepehr Ghader, Lei Zhang", "title": "A Data-Driven Analytical Framework of Estimating Multimodal Travel\n  Demand Patterns using Mobile Device Location Data", "comments": "26 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  While benefiting people's daily life in so many ways, smartphones and their\nlocation-based services are generating massive mobile device location data that\nhas great potential to help us understand travel demand patterns and make\ntransportation planning for the future. While recent studies have analyzed\nhuman travel behavior using such new data sources, limited research has been\ndone to extract multimodal travel demand patterns out of them. This paper\npresents a data-driven analytical framework to bridge the gap. To be able to\nsuccessfully detect travel modes using the passively collected location\ninformation, we conduct a smartphone-based GPS survey to collect ground truth\nobservations. Then a jointly trained single-layer model and deep neural network\nfor travel mode imputation is developed. Being \"wide\" and \"deep\" at the same\ntime, this model combines the advantages of both types of models. The framework\nalso incorporates the multimodal transportation network in order to evaluate\nthe closeness of trip routes to the nearby rail, metro, highway and bus lines\nand therefore enhance the imputation accuracy. To showcase the applications of\nthe introduced framework in answering real-world planning needs, a separate\nmobile device location data is processed through trip end identification and\nattribute generation, in a way that the travel mode imputation can be directly\napplied. The estimated multimodal travel demand patterns are then validated\nagainst typical household travel surveys in the same Washington D.C. and\nBaltimore Metropolitan Regions.\n", "versions": [{"version": "v1", "created": "Tue, 8 Dec 2020 22:49:44 GMT"}], "update_date": "2020-12-10", "authors_parsed": [["Xiong", "Chenfeng", ""], ["Darzi", "Aref", ""], ["Pan", "Yixuan", ""], ["Ghader", "Sepehr", ""], ["Zhang", "Lei", ""]]}, {"id": "2012.04780", "submitter": "Sarthak Dash", "authors": "Sarthak Dash, Gaetano Rossiello, Nandana Mihindukulasooriya, Sugato\n  Bagchi, Alfio Gliozzo", "title": "Joint Entity and Relation Canonicalization in Open Knowledge Graphs\n  using Variational Autoencoders", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Noun phrases and relation phrases in open knowledge graphs are not\ncanonicalized, leading to an explosion of redundant and ambiguous\nsubject-relation-object triples. Existing approaches to face this problem take\na two-step approach: first, they generate embedding representations for both\nnoun and relation phrases, then a clustering algorithm is used to group them\nusing the embeddings as features. In this work, we propose Canonicalizing Using\nVariational AutoEncoders (CUVA), a joint model to learn both embeddings and\ncluster assignments in an end-to-end approach, which leads to a better vector\nrepresentation for the noun and relation phrases. Our evaluation over multiple\nbenchmarks shows that CUVA outperforms the existing state of the art\napproaches. Moreover, we introduce CanonicNell a novel dataset to evaluate\nentity canonicalization systems.\n", "versions": [{"version": "v1", "created": "Tue, 8 Dec 2020 22:58:30 GMT"}], "update_date": "2020-12-10", "authors_parsed": [["Dash", "Sarthak", ""], ["Rossiello", "Gaetano", ""], ["Mihindukulasooriya", "Nandana", ""], ["Bagchi", "Sugato", ""], ["Gliozzo", "Alfio", ""]]}, {"id": "2012.04794", "submitter": "Zhibo Zhang", "authors": "Zhibo Zhang, Chen Zeng, Maulikkumar Dhameliya, Souma Chowdhury, Rahul\n  Rai", "title": "Deep Learning based Multi-Modal Sensing for Tracking and State\n  Extraction of Small Quadcopters", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a multi-sensor based approach to detect, track, and\nlocalize a quadcopter unmanned aerial vehicle (UAV). Specifically, a pipeline\nis developed to process monocular RGB and thermal video (captured from a fixed\nplatform) to detect and track the UAV in our FoV. Subsequently, a 2D planar\nlidar is used to allow conversion of pixel data to actual distance\nmeasurements, and thereby enable localization of the UAV in global coordinates.\nThe monocular data is processed through a deep learning-based object detection\nmethod that computes an initial bounding box for the UAV. The thermal data is\nprocessed through a thresholding and Kalman filter approach to detect and track\nthe bounding box. Training and testing data are prepared by combining a set of\noriginal experiments conducted in a motion capture environment and publicly\navailable UAV image data. The new pipeline compares favorably to existing\nmethods and demonstrates promising tracking and localization capacity of sample\nexperiments.\n", "versions": [{"version": "v1", "created": "Tue, 8 Dec 2020 23:59:48 GMT"}], "update_date": "2020-12-10", "authors_parsed": [["Zhang", "Zhibo", ""], ["Zeng", "Chen", ""], ["Dhameliya", "Maulikkumar", ""], ["Chowdhury", "Souma", ""], ["Rai", "Rahul", ""]]}, {"id": "2012.04809", "submitter": "Aaron Sonabend", "authors": "Aaron Sonabend-W, Nilanjana Laha, Ashwin N. Ananthakrishnan, Tianxi\n  Cai, Rajarshi Mukherjee", "title": "Semi-Supervised Off Policy Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ME stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Reinforcement learning (RL) has shown great success in estimating sequential\ntreatment strategies which take into account patient heterogeneity. However,\nhealth-outcome information, which is used as the reward for reinforcement\nlearning methods, is often not well coded but rather embedded in clinical\nnotes. Extracting precise outcome information is a resource intensive task, so\nmost of the available well-annotated cohorts are small. To address this issue,\nwe propose a semi-supervised learning (SSL) approach that efficiently leverages\na small sized labeled data with true outcome observed, and a large unlabeled\ndata with outcome surrogates. In particular, we propose a semi-supervised,\nefficient approach to Q-learning and doubly robust off policy value estimation.\nGeneralizing SSL to sequential treatment regimes brings interesting challenges:\n1) Feature distribution for Q-learning is unknown as it includes previous\noutcomes. 2) The surrogate variables we leverage in the modified SSL framework\nare predictive of the outcome but not informative to the optimal policy or\nvalue function. We provide theoretical results for our Q-function and value\nfunction estimators to understand to what degree efficiency can be gained from\nSSL. Our method is at least as efficient as the supervised approach, and\nmoreover safe as it robust to mis-specification of the imputation models.\n", "versions": [{"version": "v1", "created": "Wed, 9 Dec 2020 00:59:12 GMT"}, {"version": "v2", "created": "Fri, 11 Dec 2020 15:43:46 GMT"}, {"version": "v3", "created": "Thu, 21 Jan 2021 02:54:08 GMT"}, {"version": "v4", "created": "Mon, 22 Feb 2021 14:15:13 GMT"}, {"version": "v5", "created": "Tue, 23 Feb 2021 02:35:02 GMT"}], "update_date": "2021-02-24", "authors_parsed": [["Sonabend-W", "Aaron", ""], ["Laha", "Nilanjana", ""], ["Ananthakrishnan", "Ashwin N.", ""], ["Cai", "Tianxi", ""], ["Mukherjee", "Rajarshi", ""]]}, {"id": "2012.04841", "submitter": "Rui Fan", "authors": "Rui Fan, Christopher Bowd, Nicole Brye, Mark Christopher, Robert N.\n  Weinreb, David Kriegman, Linda Zangwill", "title": "One-Vote Veto: Semi-Supervised Learning for Low-Shot Glaucoma Diagnosis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional neural networks (CNNs) are a promising technique for automated\nglaucoma diagnosis from images of the fundus, and these images are routinely\nacquired as part of an ophthalmic exam. Nevertheless, CNNs typically require a\nlarge amount of well-labeled data for training, which may not be available in\nmany biomedical image classification applications, especially when diseases are\nrare and where labeling by experts is costly.\n  This paper makes two contributions to address this issue: (1) It extends the\nconventional twin neural network and introduces a training method for low-shot\nlearning when labeled data are limited and imbalanced, and (2) it introduces a\nnovel semi-supervised learning strategy that uses additional unlabeled training\ndata to achieve greater accuracy. Our proposed multi-task twin neural network\n(MTTNN) can employ any backbone CNN, and we demonstrate with four backbone CNNs\nthat its accuracy with limited training data approaches the accuracy of\nbackbone CNNs trained with a dataset that is 50 times larger. We also introduce\nOne-Vote Veto (OVV) self-training, a semi-supervised learning strategy that is\ndesigned specifically for MTTNNs. By taking both self-predictions and\ncontrastive-predictions of the unlabeled training data into account, OVV\nself-training provides additional pseudo labels for fine tuning a pretrained\nMTTNN. Using a large (imbalanced) dataset with 66715 fundus photographs\nacquired over 15 years, extensive experimental results demonstrate the\neffectiveness of low-shot learning with MTTNN and semi-supervised learning with\nOVV self-training. Three additional, smaller clinical datasets of fundus images\nacquired under different conditions (cameras, instruments, locations,\npopulations) are used to demonstrate the generalizability of the proposed\nmethods. Source code and pretrained models will be publicly available upon\npublication.\n", "versions": [{"version": "v1", "created": "Wed, 9 Dec 2020 03:20:06 GMT"}, {"version": "v2", "created": "Tue, 19 Jan 2021 06:19:00 GMT"}, {"version": "v3", "created": "Fri, 26 Mar 2021 20:32:41 GMT"}], "update_date": "2021-03-30", "authors_parsed": [["Fan", "Rui", ""], ["Bowd", "Christopher", ""], ["Brye", "Nicole", ""], ["Christopher", "Mark", ""], ["Weinreb", "Robert N.", ""], ["Kriegman", "David", ""], ["Zangwill", "Linda", ""]]}, {"id": "2012.04842", "submitter": "Shuhan Tan", "authors": "Shuhan Tan, Yujun Shen, Bolei Zhou", "title": "Improving the Fairness of Deep Generative Models without Retraining", "comments": "Project page: https://genforce.github.io/fairgen/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative Adversarial Networks (GANs) advance face synthesis through\nlearning the underlying distribution of observed data. Despite the high-quality\ngenerated faces, some minority groups can be rarely generated from the trained\nmodels due to a biased image generation process. To study the issue, we first\nconduct an empirical study on a pre-trained face synthesis model. We observe\nthat after training the GAN model not only carries the biases in the training\ndata but also amplifies them to some degree in the image generation process. To\nfurther improve the fairness of image generation, we propose an interpretable\nbaseline method to balance the output facial attributes without retraining. The\nproposed method shifts the interpretable semantic distribution in the latent\nspace for a more balanced image generation while preserving the sample\ndiversity. Besides producing more balanced data regarding a particular\nattribute (e.g., race, gender, etc.), our method is generalizable to handle\nmore than one attribute at a time and synthesize samples of fine-grained\nsubgroups. We further show the positive applicability of the balanced data\nsampled from GANs to quantify the biases in other face recognition systems,\nlike commercial face attribute classifiers and face super-resolution\nalgorithms.\n", "versions": [{"version": "v1", "created": "Wed, 9 Dec 2020 03:20:41 GMT"}, {"version": "v2", "created": "Mon, 29 Mar 2021 08:55:12 GMT"}], "update_date": "2021-03-30", "authors_parsed": [["Tan", "Shuhan", ""], ["Shen", "Yujun", ""], ["Zhou", "Bolei", ""]]}, {"id": "2012.04858", "submitter": "Soumya Chatterjee", "authors": "Soumya Chatterjee, Pradeep Shenoy", "title": "Model-agnostic Fits for Understanding Information Seeking Patterns in\n  Humans", "comments": "8 pages, 9 figures. AAAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In decision making tasks under uncertainty, humans display characteristic\nbiases in seeking, integrating, and acting upon information relevant to the\ntask. Here, we reexamine data from previous carefully designed experiments,\ncollected at scale, that measured and catalogued these biases in aggregate\nform. We design deep learning models that replicate these biases in aggregate,\nwhile also capturing individual variation in behavior. A key finding of our\nwork is that paucity of data collected from each individual subject can be\novercome by sampling large numbers of subjects from the population, while still\ncapturing individual differences. In addition, we can predict human behavior\nwith high accuracy without making any assumptions about task goals, reward\nstructure, or individual biases, thus providing a model-agnostic fit to human\nbehavior in the task. Such an approach can sidestep potential limitations in\nmodeler-specified inductive biases, and has implications for computational\nmodeling of human cognitive function in general, and of human-AI interfaces in\nparticular.\n", "versions": [{"version": "v1", "created": "Wed, 9 Dec 2020 04:34:58 GMT"}, {"version": "v2", "created": "Thu, 4 Feb 2021 04:09:25 GMT"}], "update_date": "2021-02-05", "authors_parsed": [["Chatterjee", "Soumya", ""], ["Shenoy", "Pradeep", ""]]}, {"id": "2012.04863", "submitter": "Pengtao Xie", "authors": "Pengtao Xie, Xuefeng Du, Hao Ban", "title": "Skillearn: Machine Learning Inspired by Humans' Learning Skills", "comments": "arXiv admin note: substantial text overlap with arXiv:2011.15102,\n  arXiv:2012.12502, arXiv:2012.12899", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Humans, as the most powerful learners on the planet, have accumulated a lot\nof learning skills, such as learning through tests, interleaving learning,\nself-explanation, active recalling, to name a few. These learning skills and\nmethodologies enable humans to learn new topics more effectively and\nefficiently. We are interested in investigating whether humans' learning skills\ncan be borrowed to help machines to learn better. Specifically, we aim to\nformalize these skills and leverage them to train better machine learning (ML)\nmodels. To achieve this goal, we develop a general framework -- Skillearn,\nwhich provides a principled way to represent humans' learning skills\nmathematically and use the formally-represented skills to improve the training\nof ML models. In two case studies, we apply Skillearn to formalize two learning\nskills of humans: learning by passing tests and interleaving learning, and use\nthe formalized skills to improve neural architecture search. Experiments on\nvarious datasets show that trained using the skills formalized by Skillearn, ML\nmodels achieve significantly better performance.\n", "versions": [{"version": "v1", "created": "Wed, 9 Dec 2020 04:56:22 GMT"}, {"version": "v2", "created": "Fri, 12 Mar 2021 06:38:40 GMT"}], "update_date": "2021-03-15", "authors_parsed": [["Xie", "Pengtao", ""], ["Du", "Xuefeng", ""], ["Ban", "Hao", ""]]}, {"id": "2012.04884", "submitter": "Jakub Breier", "authors": "Jakub Breier and Adrian Baldwin and Helen Balinsky and Yang Liu", "title": "Risk Management Framework for Machine Learning Security", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial attacks for machine learning models have become a highly studied\ntopic both in academia and industry. These attacks, along with traditional\nsecurity threats, can compromise confidentiality, integrity, and availability\nof organization's assets that are dependent on the usage of machine learning\nmodels. While it is not easy to predict the types of new attacks that might be\ndeveloped over time, it is possible to evaluate the risks connected to using\nmachine learning models and design measures that help in minimizing these\nrisks.\n  In this paper, we outline a novel framework to guide the risk management\nprocess for organizations reliant on machine learning models. First, we define\nsets of evaluation factors (EFs) in the data domain, model domain, and security\ncontrols domain. We develop a method that takes the asset and task importance,\nsets the weights of EFs' contribution to confidentiality, integrity, and\navailability, and based on implementation scores of EFs, it determines the\noverall security state in the organization. Based on this information, it is\npossible to identify weak links in the implemented security measures and find\nout which measures might be missing completely. We believe our framework can\nhelp in addressing the security issues related to usage of machine learning\nmodels in organizations and guide them in focusing on the adequate security\nmeasures to protect their assets.\n", "versions": [{"version": "v1", "created": "Wed, 9 Dec 2020 06:21:34 GMT"}], "update_date": "2020-12-10", "authors_parsed": [["Breier", "Jakub", ""], ["Baldwin", "Adrian", ""], ["Balinsky", "Helen", ""], ["Liu", "Yang", ""]]}, {"id": "2012.04915", "submitter": "Chengchao Shen", "authors": "Chengchao Shen, Xinchao Wang, Youtan Yin, Jie Song, Sihui Luo, Mingli\n  Song", "title": "Progressive Network Grafting for Few-Shot Knowledge Distillation", "comments": "Accepted to AAAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Knowledge distillation has demonstrated encouraging performances in deep\nmodel compression. Most existing approaches, however, require massive labeled\ndata to accomplish the knowledge transfer, making the model compression a\ncumbersome and costly process. In this paper, we investigate the practical\nfew-shot knowledge distillation scenario, where we assume only a few samples\nwithout human annotations are available for each category. To this end, we\nintroduce a principled dual-stage distillation scheme tailored for few-shot\ndata. In the first step, we graft the student blocks one by one onto the\nteacher, and learn the parameters of the grafted block intertwined with those\nof the other teacher blocks. In the second step, the trained student blocks are\nprogressively connected and then together grafted onto the teacher network,\nallowing the learned student blocks to adapt themselves to each other and\neventually replace the teacher network. Experiments demonstrate that our\napproach, with only a few unlabeled samples, achieves gratifying results on\nCIFAR10, CIFAR100, and ILSVRC-2012. On CIFAR10 and CIFAR100, our performances\nare even on par with those of knowledge distillation schemes that utilize the\nfull datasets. The source code is available at\nhttps://github.com/zju-vipa/NetGraft.\n", "versions": [{"version": "v1", "created": "Wed, 9 Dec 2020 08:34:36 GMT"}, {"version": "v2", "created": "Fri, 11 Dec 2020 07:38:41 GMT"}], "update_date": "2020-12-14", "authors_parsed": [["Shen", "Chengchao", ""], ["Wang", "Xinchao", ""], ["Yin", "Youtan", ""], ["Song", "Jie", ""], ["Luo", "Sihui", ""], ["Song", "Mingli", ""]]}, {"id": "2012.04983", "submitter": "Eloi Zablocki", "authors": "H\\'edi Ben-Younes and \\'Eloi Zablocki and Patrick P\\'erez and Matthieu\n  Cord", "title": "Driving Behavior Explanation with Multi-level Fusion", "comments": "Accepted at NeurIPS Workshop ML4AD 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.RO", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  In this era of active development of autonomous vehicles, it becomes crucial\nto provide driving systems with the capacity to explain their decisions. In\nthis work, we focus on generating high-level driving explanations as the\nvehicle drives. We present BEEF, for BEhavior Explanation with Fusion, a deep\narchitecture which explains the behavior of a trajectory prediction model.\nSupervised by annotations of human driving decisions justifications, BEEF\nlearns to fuse features from multiple levels. Leveraging recent advances in the\nmulti-modal fusion literature, BEEF is carefully designed to model the\ncorrelations between high-level decisions features and mid-level perceptual\nfeatures. The flexibility and efficiency of our approach are validated with\nextensive experiments on the HDD and BDD-X datasets.\n", "versions": [{"version": "v1", "created": "Wed, 9 Dec 2020 11:19:50 GMT"}], "update_date": "2020-12-10", "authors_parsed": [["Ben-Younes", "H\u00e9di", ""], ["Zablocki", "\u00c9loi", ""], ["P\u00e9rez", "Patrick", ""], ["Cord", "Matthieu", ""]]}, {"id": "2012.04987", "submitter": "Biyang Guo", "authors": "Biyang Guo, Songqiao Han, Xiao Han, Hailiang Huang, Ting Lu", "title": "Label Confusion Learning to Enhance Text Classification Models", "comments": "8 pages,3 figures, 5 tables. Accepted by AAAI-21", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Representing a true label as a one-hot vector is a common practice in\ntraining text classification models. However, the one-hot representation may\nnot adequately reflect the relation between the instances and labels, as labels\nare often not completely independent and instances may relate to multiple\nlabels in practice. The inadequate one-hot representations tend to train the\nmodel to be over-confident, which may result in arbitrary prediction and model\noverfitting, especially for confused datasets (datasets with very similar\nlabels) or noisy datasets (datasets with labeling errors). While training\nmodels with label smoothing (LS) can ease this problem in some degree, it still\nfails to capture the realistic relation among labels. In this paper, we propose\na novel Label Confusion Model (LCM) as an enhancement component to current\npopular text classification models. LCM can learn label confusion to capture\nsemantic overlap among labels by calculating the similarity between instances\nand labels during training and generate a better label distribution to replace\nthe original one-hot label vector, thus improving the final classification\nperformance. Extensive experiments on five text classification benchmark\ndatasets reveal the effectiveness of LCM for several widely used deep learning\nclassification models. Further experiments also verify that LCM is especially\nhelpful for confused or noisy datasets and superior to the label smoothing\nmethod.\n", "versions": [{"version": "v1", "created": "Wed, 9 Dec 2020 11:34:35 GMT"}], "update_date": "2020-12-10", "authors_parsed": [["Guo", "Biyang", ""], ["Han", "Songqiao", ""], ["Han", "Xiao", ""], ["Huang", "Hailiang", ""], ["Lu", "Ting", ""]]}, {"id": "2012.05002", "submitter": "Matteo Castiglioni", "authors": "Matteo Castiglioni, Nicola Gatti", "title": "Persuading Voters in District-based Elections", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We focus on the scenario in which an agent can exploit his information\nadvantage to manipulate the outcome of an election. In particular, we study\ndistrict-based elections with two candidates, in which the winner of the\nelection is the candidate that wins in the majority of the districts.\nDistrict-based elections are adopted worldwide (e.g., UK and USA) and are a\nnatural extension of widely studied voting mechanisms (e.g., k-voting and\nplurality voting). We resort to the Bayesian persuasion framework, where the\nmanipulator (sender) strategically discloses information to the voters\n(receivers) that update their beliefs rationally. We study both private\nsignaling, in which the sender can use a private communication channel per\nreceiver, and public signaling, in which the sender can use a single\ncommunication channel for all the receivers. Furthermore, for the first time,\nwe introduce semi-public signaling in which the sender can use a single\ncommunication channel per district. We show that there is a sharp distinction\nbetween private and (semi-)public signaling. In particular, optimal private\nsignaling schemes can provide an arbitrarily better probability of victory than\n(semi-)public ones and can be computed efficiently, while optimal (semi-)public\nsignaling schemes cannot be approximated to within any factor in polynomial\ntime unless P=NP. However, we show that reasonable relaxations allow the design\nof multi-criteria PTASs for optimal (semi-)public signaling schemes. In doing\nso, we introduce a novel property, namely comparative stability, and we design\na bi-criteria PTAS for public signaling in general Bayesian persuasion problems\nbeyond elections when the sender's utility function is state-dependent.\n", "versions": [{"version": "v1", "created": "Wed, 9 Dec 2020 12:23:01 GMT"}, {"version": "v2", "created": "Thu, 10 Dec 2020 09:36:17 GMT"}], "update_date": "2020-12-11", "authors_parsed": [["Castiglioni", "Matteo", ""], ["Gatti", "Nicola", ""]]}, {"id": "2012.05011", "submitter": "Rishi Hazra", "authors": "Rishi Hazra, Sonu Dixit, Sayambhu Sen", "title": "Infinite use of finite means: Zero-Shot Generalization using\n  Compositional Emergent Protocols", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Human language has been described as a system that makes \\textit{use of\nfinite means to express an unlimited array of thoughts}. Of particular interest\nis the aspect of compositionality, whereby, the meaning of a compound language\nexpression can be deduced from the meaning of its constituent parts. If\nartificial agents can develop compositional communication protocols akin to\nhuman language, they can be made to seamlessly generalize to unseen\ncombinations. However, the real question is, how do we induce compositionality\nin emergent communication? Studies have recognized the role of curiosity in\nenabling linguistic development in children. It is this same intrinsic urge\nthat drives us to master complex tasks with decreasing amounts of explicit\nreward. In this paper, we seek to use this intrinsic feedback in inducing a\nsystematic and unambiguous protolanguage in artificial agents. We show how\nthese rewards can be leveraged in training agents to induce compositionality in\nabsence of any external feedback. Additionally, we introduce gComm, an\nenvironment for investigating grounded language acquisition in 2D-grid\nenvironments. Using this, we demonstrate how compositionality can enable agents\nto not only interact with unseen objects but also transfer skills from one task\nto another in a zero-shot setting: \\textit{Can an agent, trained to `pull' and\n`push twice', `pull twice'?}.\n", "versions": [{"version": "v1", "created": "Wed, 9 Dec 2020 12:47:20 GMT"}, {"version": "v2", "created": "Sun, 13 Dec 2020 04:19:33 GMT"}, {"version": "v3", "created": "Wed, 19 May 2021 19:46:42 GMT"}], "update_date": "2021-05-21", "authors_parsed": [["Hazra", "Rishi", ""], ["Dixit", "Sonu", ""], ["Sen", "Sayambhu", ""]]}, {"id": "2012.05023", "submitter": "Daniel Cunnington", "authors": "Daniel Cunnington, Alessandra Russo, Mark Law, Jorge Lobo, Lance\n  Kaplan", "title": "NSL: Hybrid Interpretable Learning From Noisy Raw Data", "comments": "This article has been replaced with arXiv:2106.13103", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Inductive Logic Programming (ILP) systems learn generalised, interpretable\nrules in a data-efficient manner utilising existing background knowledge.\nHowever, current ILP systems require training examples to be specified in a\nstructured logical format. Neural networks learn from unstructured data,\nalthough their learned models may be difficult to interpret and are vulnerable\nto data perturbations at run-time. This paper introduces a hybrid\nneural-symbolic learning framework, called NSL, that learns interpretable rules\nfrom labelled unstructured data. NSL combines pre-trained neural networks for\nfeature extraction with FastLAS, a state-of-the-art ILP system for rule\nlearning under the answer set semantics. Features extracted by the neural\ncomponents define the structured context of labelled examples and the\nconfidence of the neural predictions determines the level of noise of the\nexamples. Using the scoring function of FastLAS, NSL searches for short,\ninterpretable rules that generalise over such noisy examples. We evaluate our\nframework on propositional and first-order classification tasks using the MNIST\ndataset as raw data. Specifically, we demonstrate that NSL is able to learn\nrobust rules from perturbed MNIST data and achieve comparable or superior\naccuracy when compared to neural network and random forest baselines whilst\nbeing more general and interpretable.\n", "versions": [{"version": "v1", "created": "Wed, 9 Dec 2020 13:02:44 GMT"}, {"version": "v2", "created": "Fri, 25 Jun 2021 09:36:21 GMT"}], "update_date": "2021-06-28", "authors_parsed": [["Cunnington", "Daniel", ""], ["Russo", "Alessandra", ""], ["Law", "Mark", ""], ["Lobo", "Jorge", ""], ["Kaplan", "Lance", ""]]}, {"id": "2012.05123", "submitter": "Sander Beckers", "authors": "Sander Beckers", "title": "The Counterfactual NESS Definition of Causation", "comments": "Preprint of accepted AAAI2021 paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In previous work with Joost Vennekens I proposed a definition of actual\ncausation that is based on certain plausible principles, thereby allowing the\ndebate on causation to shift away from its heavy focus on examples towards a\nmore systematic analysis. This paper contributes to that analysis in two ways.\nFirst, I show that our definition is in fact a formalization of Wright's famous\nNESS definition of causation combined with a counterfactual difference-making\ncondition. This means that our definition integrates two highly influential\napproaches to causation that are claimed to stand in opposition to each other.\nSecond, I modify our definition to offer a substantial improvement: I weaken\nthe difference-making condition in such a way that it avoids the problematic\nanalysis of cases of preemption. The resulting Counterfactual NESS definition\nof causation forms a natural compromise between counterfactual approaches and\nthe NESS approach.\n", "versions": [{"version": "v1", "created": "Wed, 9 Dec 2020 15:57:56 GMT"}, {"version": "v2", "created": "Tue, 15 Dec 2020 21:46:12 GMT"}], "update_date": "2020-12-17", "authors_parsed": [["Beckers", "Sander", ""]]}, {"id": "2012.05208", "submitter": "Klaus Greff", "authors": "Klaus Greff, Sjoerd van Steenkiste, J\\\"urgen Schmidhuber", "title": "On the Binding Problem in Artificial Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Contemporary neural networks still fall short of human-level generalization,\nwhich extends far beyond our direct experiences. In this paper, we argue that\nthe underlying cause for this shortcoming is their inability to dynamically and\nflexibly bind information that is distributed throughout the network. This\nbinding problem affects their capacity to acquire a compositional understanding\nof the world in terms of symbol-like entities (like objects), which is crucial\nfor generalizing in predictable and systematic ways. To address this issue, we\npropose a unifying framework that revolves around forming meaningful entities\nfrom unstructured sensory inputs (segregation), maintaining this separation of\ninformation at a representational level (representation), and using these\nentities to construct new inferences, predictions, and behaviors (composition).\nOur analysis draws inspiration from a wealth of research in neuroscience and\ncognitive psychology, and surveys relevant mechanisms from the machine learning\nliterature, to help identify a combination of inductive biases that allow\nsymbolic information processing to emerge naturally in neural networks. We\nbelieve that a compositional approach to AI, in terms of grounded symbol-like\nrepresentations, is of fundamental importance for realizing human-level\ngeneralization, and we hope that this paper may contribute towards that goal as\na reference and inspiration.\n", "versions": [{"version": "v1", "created": "Wed, 9 Dec 2020 18:02:49 GMT"}], "update_date": "2020-12-10", "authors_parsed": [["Greff", "Klaus", ""], ["van Steenkiste", "Sjoerd", ""], ["Schmidhuber", "J\u00fcrgen", ""]]}, {"id": "2012.05213", "submitter": "Krzysztof Sornat", "authors": "Pallavi Jain, Krzysztof Sornat, Nimrod Talmon, Meirav Zehavi", "title": "Participatory Budgeting with Project Groups", "comments": "23 pages, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.AI cs.DS cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study a generalization of the standard approval-based model of\nparticipatory budgeting (PB), in which voters are providing approval ballots\nover a set of predefined projects and -- in addition to a global budget limit,\nthere are several groupings of the projects, each group with its own budget\nlimit. We study the computational complexity of identifying project bundles\nthat maximize voter satisfaction while respecting all budget limits. We show\nthat the problem is generally intractable and describe efficient exact\nalgorithms for several special cases, including instances with only few groups\nand instances where the group structure is close to be hierarchical, as well as\nefficient approximation algorithms. Our results could allow, e.g.,\nmunicipalities to hold richer PB processes that are thematically and\ngeographically inclusive.\n", "versions": [{"version": "v1", "created": "Wed, 9 Dec 2020 18:23:04 GMT"}], "update_date": "2020-12-10", "authors_parsed": [["Jain", "Pallavi", ""], ["Sornat", "Krzysztof", ""], ["Talmon", "Nimrod", ""], ["Zehavi", "Meirav", ""]]}, {"id": "2012.05225", "submitter": "Nataniel Ruiz", "authors": "Nataniel Ruiz, Barry-John Theobald, Anurag Ranjan, Ahmed Hussein\n  Abdelaziz, Nicholas Apostoloff", "title": "MorphGAN: One-Shot Face Synthesis GAN for Detecting Recognition Bias", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To detect bias in face recognition networks, it can be useful to probe a\nnetwork under test using samples in which only specific attributes vary in some\ncontrolled way. However, capturing a sufficiently large dataset with specific\ncontrol over the attributes of interest is difficult. In this work, we describe\na simulator that applies specific head pose and facial expression adjustments\nto images of previously unseen people. The simulator first fits a 3D morphable\nmodel to a provided image, applies the desired head pose and facial expression\ncontrols, then renders the model into an image. Next, a conditional Generative\nAdversarial Network (GAN) conditioned on the original image and the rendered\nmorphable model is used to produce the image of the original person with the\nnew facial expression and head pose. We call this conditional GAN -- MorphGAN.\nImages generated using MorphGAN conserve the identity of the person in the\noriginal image, and the provided control over head pose and facial expression\nallows test sets to be created to identify robustness issues of a facial\nrecognition deep network with respect to pose and expression. Images generated\nby MorphGAN can also serve as data augmentation when training data are scarce.\nWe show that by augmenting small datasets of faces with new poses and\nexpressions improves the recognition performance by up to 9% depending on the\naugmentation and data scarcity.\n", "versions": [{"version": "v1", "created": "Wed, 9 Dec 2020 18:43:03 GMT"}, {"version": "v2", "created": "Thu, 10 Dec 2020 18:48:22 GMT"}], "update_date": "2020-12-11", "authors_parsed": [["Ruiz", "Nataniel", ""], ["Theobald", "Barry-John", ""], ["Ranjan", "Anurag", ""], ["Abdelaziz", "Ahmed Hussein", ""], ["Apostoloff", "Nicholas", ""]]}, {"id": "2012.05267", "submitter": "Tom Hanika", "authors": "Tom Hanika and Johannes Hirth", "title": "On the Lattice of Conceptual Measurements", "comments": "19 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel approach for data set scaling based on scale-measures from\nformal concept analysis, i.e., continuous maps between closure systems, and\nderive a canonical representation. Moreover, we prove said scale-measures are\nlattice ordered with respect to the closure systems. This enables exploring the\nset of scale-measures through by the use of meet and join operations.\nFurthermore we show that the lattice of scale-measures is isomorphic to the\nlattice of sub-closure systems that arises from the original data. Finally, we\nprovide another representation of scale-measures using propositional logic in\nterms of data set features. Our theoretical findings are discussed by means of\nexamples.\n", "versions": [{"version": "v1", "created": "Wed, 9 Dec 2020 19:11:50 GMT"}], "update_date": "2020-12-11", "authors_parsed": [["Hanika", "Tom", ""], ["Hirth", "Johannes", ""]]}, {"id": "2012.05292", "submitter": "Kevin Chen", "authors": "Kevin Chen, Junshen K. Chen, Jo Chuang, Marynel V\\'azquez, Silvio\n  Savarese", "title": "Topological Planning with Transformers for Vision-and-Language\n  Navigation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.CL cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conventional approaches to vision-and-language navigation (VLN) are trained\nend-to-end but struggle to perform well in freely traversable environments.\nInspired by the robotics community, we propose a modular approach to VLN using\ntopological maps. Given a natural language instruction and topological map, our\napproach leverages attention mechanisms to predict a navigation plan in the\nmap. The plan is then executed with low-level actions (e.g. forward, rotate)\nusing a robust controller. Experiments show that our method outperforms\nprevious end-to-end approaches, generates interpretable navigation plans, and\nexhibits intelligent behaviors such as backtracking.\n", "versions": [{"version": "v1", "created": "Wed, 9 Dec 2020 20:02:03 GMT"}], "update_date": "2020-12-11", "authors_parsed": [["Chen", "Kevin", ""], ["Chen", "Junshen K.", ""], ["Chuang", "Jo", ""], ["V\u00e1zquez", "Marynel", ""], ["Savarese", "Silvio", ""]]}, {"id": "2012.05329", "submitter": "Dennis Ulmer", "authors": "Dennis Ulmer and Giovanni Cin\\`a", "title": "Know Your Limits: Uncertainty Estimation with ReLU Classifiers Fails at\n  Reliable OOD Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  A crucial requirement for reliable deployment of deep learning models for\nsafety-critical applications is the ability to identify out-of-distribution\n(OOD) data points, samples which differ from the training data and on which a\nmodel might underperform. Previous work has attempted to tackle this problem\nusing uncertainty estimation techniques. However, there is empirical evidence\nthat a large family of these techniques do not detect OOD reliably in\nclassification tasks.\n  This paper gives a theoretical explanation for said experimental findings and\nillustrates it on synthetic data. We prove that such techniques are not able to\nreliably identify OOD samples in a classification setting, since their level of\nconfidence is generalized to unseen areas of the feature space. This result\nstems from the interplay between the representation of ReLU networks as\npiece-wise affine transformations, the saturating nature of activation\nfunctions like softmax, and the most widely-used uncertainty metrics.\n", "versions": [{"version": "v1", "created": "Wed, 9 Dec 2020 21:35:55 GMT"}, {"version": "v2", "created": "Fri, 11 Dec 2020 09:42:26 GMT"}, {"version": "v3", "created": "Fri, 26 Feb 2021 09:56:51 GMT"}, {"version": "v4", "created": "Thu, 10 Jun 2021 07:47:09 GMT"}], "update_date": "2021-06-11", "authors_parsed": [["Ulmer", "Dennis", ""], ["Cin\u00e0", "Giovanni", ""]]}, {"id": "2012.05370", "submitter": "Ben Green", "authors": "Ben Green, Yiling Chen", "title": "Algorithmic risk assessments can alter human decision-making processes\n  in high-stakes government contexts", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Governments are increasingly turning to algorithmic risk assessments when\nmaking important decisions, believing that these algorithms will improve public\nservants' ability to make policy-relevant predictions and thereby lead to more\ninformed decisions. Yet because many policy decisions require balancing\nrisk-minimization with competing social goals, evaluating the impacts of risk\nassessments requires considering how public servants are influenced by risk\nassessments when making policy decisions rather than just how accurately these\nalgorithms make predictions. Through an online experiment with 2,140 lay\nparticipants simulating two high-stakes government contexts, we provide the\nfirst large-scale evidence that risk assessments can systematically alter\ndecision-making processes by increasing the salience of risk as a factor in\ndecisions and that these shifts could exacerbate racial disparities. These\nresults demonstrate that improving human prediction accuracy with algorithms\ndoes not necessarily improve human decisions and highlight the need to\nexperimentally test how government algorithms are used by human\ndecision-makers.\n", "versions": [{"version": "v1", "created": "Wed, 9 Dec 2020 23:44:45 GMT"}], "update_date": "2020-12-11", "authors_parsed": [["Green", "Ben", ""], ["Chen", "Yiling", ""]]}, {"id": "2012.05390", "submitter": "Jinsoo Yoo", "authors": "Jason Yoo, Tony Joseph, Dylan Yung, S. Ali Nasseri, Frank Wood", "title": "Ensemble Squared: A Meta AutoML System", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There are currently many barriers that prevent non-experts from exploiting\nmachine learning solutions ranging from the lack of intuition on statistical\nlearning techniques to the trickiness of hyperparameter tuning. Such barriers\nhave led to an explosion of interest in automated machine learning (AutoML),\nwhereby an off-the-shelf system can take care of many of the steps for\nend-users without the need for expertise in machine learning. This paper\npresents Ensemble Squared (Ensemble$^2$), an AutoML system that ensembles the\nresults of state-of-the-art open-source AutoML systems. Ensemble$^2$ exploits\nthe diversity of existing AutoML systems by leveraging the differences in their\nmodel search space and heuristics. Empirically, we show that diversity of each\nAutoML system is sufficient to justify ensembling at the AutoML system level.\nIn demonstrating this, we also establish new state-of-the-art AutoML results on\nthe OpenML tabular classification benchmark.\n", "versions": [{"version": "v1", "created": "Thu, 10 Dec 2020 01:09:00 GMT"}, {"version": "v2", "created": "Sat, 12 Jun 2021 19:56:03 GMT"}, {"version": "v3", "created": "Sat, 19 Jun 2021 19:48:11 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Yoo", "Jason", ""], ["Joseph", "Tony", ""], ["Yung", "Dylan", ""], ["Nasseri", "S. Ali", ""], ["Wood", "Frank", ""]]}, {"id": "2012.05410", "submitter": "Elisa Bertino", "authors": "Elisa Bertino and Sujata Banerjee", "title": "Artificial Intelligence at the Edge", "comments": "A Computing Community Consortium (CCC) white paper, 4 pages", "journal-ref": null, "doi": null, "report-no": "ccc2020whitepaper_3", "categories": "cs.CY cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The Internet of Things (IoT) and edge computing applications aim to support a\nvariety of societal needs, including the global pandemic situation that the\nentire world is currently experiencing and responses to natural disasters.\n  The need for real-time interactive applications such as immersive video\nconferencing, augmented/virtual reality, and autonomous vehicles, in education,\nhealthcare, disaster recovery and other domains, has never been higher. At the\nsame time, there have been recent technological breakthroughs in highly\nrelevant fields such as artificial intelligence (AI)/machine learning (ML),\nadvanced communication systems (5G and beyond), privacy-preserving\ncomputations, and hardware accelerators. 5G mobile communication networks\nincrease communication capacity, reduce transmission latency and error, and\nsave energy -- capabilities that are essential for new applications. The\nenvisioned future 6G technology will integrate many more technologies,\nincluding for example visible light communication, to support groundbreaking\napplications, such as holographic communications and high precision\nmanufacturing. Many of these applications require computations and analytics\nclose to application end-points: that is, at the edge of the network, rather\nthan in a centralized cloud. AI techniques applied at the edge have tremendous\npotential both to power new applications and to need more efficient operation\nof edge infrastructure. However, it is critical to understand where to deploy\nAI systems within complex ecosystems consisting of advanced applications and\nthe specific real-time requirements towards AI systems.\n", "versions": [{"version": "v1", "created": "Thu, 10 Dec 2020 02:08:47 GMT"}], "update_date": "2020-12-11", "authors_parsed": [["Bertino", "Elisa", ""], ["Banerjee", "Sujata", ""]]}, {"id": "2012.05417", "submitter": "Kyunghyun Lee", "authors": "Kyunghyun Lee, Byeong-Uk Lee, Ukcheol Shin and In So Kweon", "title": "An Efficient Asynchronous Method for Integrating Evolutionary and\n  Gradient-based Policy Search", "comments": null, "journal-ref": "NeurIPS 2020 (oral)", "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep reinforcement learning (DRL) algorithms and evolution strategies (ES)\nhave been applied to various tasks, showing excellent performances. These have\nthe opposite properties, with DRL having good sample efficiency and poor\nstability, while ES being vice versa. Recently, there have been attempts to\ncombine these algorithms, but these methods fully rely on synchronous update\nscheme, making it not ideal to maximize the benefits of the parallelism in ES.\nTo solve this challenge, asynchronous update scheme was introduced, which is\ncapable of good time-efficiency and diverse policy exploration. In this paper,\nwe introduce an Asynchronous Evolution Strategy-Reinforcement Learning (AES-RL)\nthat maximizes the parallel efficiency of ES and integrates it with policy\ngradient methods. Specifically, we propose 1) a novel framework to merge ES and\nDRL asynchronously and 2) various asynchronous update methods that can take all\nadvantages of asynchronism, ES, and DRL, which are exploration and time\nefficiency, stability, and sample efficiency, respectively. The proposed\nframework and update methods are evaluated in continuous control benchmark\nwork, showing superior performance as well as time efficiency compared to the\nprevious methods.\n", "versions": [{"version": "v1", "created": "Thu, 10 Dec 2020 02:30:48 GMT"}, {"version": "v2", "created": "Wed, 6 Jan 2021 05:12:47 GMT"}], "update_date": "2021-04-06", "authors_parsed": [["Lee", "Kyunghyun", ""], ["Lee", "Byeong-Uk", ""], ["Shin", "Ukcheol", ""], ["Kweon", "In So", ""]]}, {"id": "2012.05429", "submitter": "Xuefeng Liang", "authors": "Ying Zhou, Xuefeng Liang, Yu Gu, Yifei Yin, Longshan Yao", "title": "Multi-Classifier Interactive Learning for Ambiguous Speech Emotion\n  Recognition", "comments": "10 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.MM", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  In recent years, speech emotion recognition technology is of great\nsignificance in industrial applications such as call centers, social robots and\nhealth care. The combination of speech recognition and speech emotion\nrecognition can improve the feedback efficiency and the quality of service.\nThus, the speech emotion recognition has been attracted much attention in both\nindustry and academic. Since emotions existing in an entire utterance may have\nvaried probabilities, speech emotion is likely to be ambiguous, which poses\ngreat challenges to recognition tasks. However, previous studies commonly\nassigned a single-label or multi-label to each utterance in certain. Therefore,\ntheir algorithms result in low accuracies because of the inappropriate\nrepresentation. Inspired by the optimally interacting theory, we address the\nambiguous speech emotions by proposing a novel multi-classifier interactive\nlearning (MCIL) method. In MCIL, multiple different classifiers first mimic\nseveral individuals, who have inconsistent cognitions of ambiguous emotions,\nand construct new ambiguous labels (the emotion probability distribution).\nThen, they are retrained with the new labels to interact with their cognitions.\nThis procedure enables each classifier to learn better representations of\nambiguous data from others, and further improves the recognition ability. The\nexperiments on three benchmark corpora (MAS, IEMOCAP, and FAU-AIBO) demonstrate\nthat MCIL does not only improve each classifier's performance, but also raises\ntheir recognition consistency from moderate to substantial.\n", "versions": [{"version": "v1", "created": "Thu, 10 Dec 2020 02:58:34 GMT"}, {"version": "v2", "created": "Sat, 12 Dec 2020 14:59:33 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["Zhou", "Ying", ""], ["Liang", "Xuefeng", ""], ["Gu", "Yu", ""], ["Yin", "Yifei", ""], ["Yao", "Longshan", ""]]}, {"id": "2012.05438", "submitter": "Yu Sun", "authors": "Maxat Alibayev, David Paulius, and Yu Sun", "title": "Developing Motion Code Embedding for Action Recognition in Videos", "comments": "Accepted by 25th International Conference on Pattern Recognition\n  (ICPR2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we propose a motion embedding strategy known as motion codes,\nwhich is a vectorized representation of motions based on a manipulation's\nsalient mechanical attributes. These motion codes provide a robust motion\nrepresentation, and they are obtained using a hierarchy of features called the\nmotion taxonomy. We developed and trained a deep neural network model that\ncombines visual and semantic features to identify the features found in our\nmotion taxonomy to embed or annotate videos with motion codes. To demonstrate\nthe potential of motion codes as features for machine learning tasks, we\nintegrated the extracted features from the motion embedding model into the\ncurrent state-of-the-art action recognition model. The obtained model achieved\nhigher accuracy than the baseline model for the verb classification task on\negocentric videos from the EPIC-KITCHENS dataset.\n", "versions": [{"version": "v1", "created": "Thu, 10 Dec 2020 03:49:23 GMT"}], "update_date": "2020-12-11", "authors_parsed": [["Alibayev", "Maxat", ""], ["Paulius", "David", ""], ["Sun", "Yu", ""]]}, {"id": "2012.05442", "submitter": "Jiangxia Cao", "authors": "Jiangxia Cao, Xixun Lin, Shu Guo, Luchen Liu, Tingwen Liu, Bin Wang", "title": "Bipartite Graph Embedding via Mutual Information Maximization", "comments": "Accepted by WSDM 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bipartite graph embedding has recently attracted much attention due to the\nfact that bipartite graphs are widely used in various application domains. Most\nprevious methods, which adopt random walk-based or reconstruction-based\nobjectives, are typically effective to learn local graph structures. However,\nthe global properties of bipartite graph, including community structures of\nhomogeneous nodes and long-range dependencies of heterogeneous nodes, are not\nwell preserved. In this paper, we propose a bipartite graph embedding called\nBiGI to capture such global properties by introducing a novel local-global\ninfomax objective. Specifically, BiGI first generates a global representation\nwhich is composed of two prototype representations. BiGI then encodes sampled\nedges as local representations via the proposed subgraph-level attention\nmechanism. Through maximizing the mutual information between local and global\nrepresentations, BiGI enables nodes in bipartite graph to be globally relevant.\nOur model is evaluated on various benchmark datasets for the tasks of top-K\nrecommendation and link prediction. Extensive experiments demonstrate that BiGI\nachieves consistent and significant improvements over state-of-the-art\nbaselines. Detailed analyses verify the high effectiveness of modeling the\nglobal properties of bipartite graph.\n", "versions": [{"version": "v1", "created": "Thu, 10 Dec 2020 04:03:39 GMT"}], "update_date": "2020-12-11", "authors_parsed": [["Cao", "Jiangxia", ""], ["Lin", "Xixun", ""], ["Guo", "Shu", ""], ["Liu", "Luchen", ""], ["Liu", "Tingwen", ""], ["Wang", "Bin", ""]]}, {"id": "2012.05446", "submitter": "Ting Wang", "authors": "Ting Wang, Zongkai Wu, Donglin Wang", "title": "Visual Perception Generalization for Vision-and-Language Navigation via\n  Meta-Learning", "comments": "8 pages, 4 figures, preprinted version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Vision-and-language navigation (VLN) is a challenging task that requires an\nagent to navigate in real-world environments by understanding natural language\ninstructions and visual information received in real-time. Prior works have\nimplemented VLN tasks on continuous environments or physical robots, all of\nwhich use a fixed camera configuration due to the limitations of datasets, such\nas 1.5 meters height, 90 degrees horizontal field of view (HFOV), etc. However,\nreal-life robots with different purposes have multiple camera configurations,\nand the huge gap in visual information makes it difficult to directly transfer\nthe learned navigation model between various robots. In this paper, we propose\na visual perception generalization strategy based on meta-learning, which\nenables the agent to fast adapt to a new camera configuration with a few shots.\nIn the training phase, we first locate the generalization problem to the visual\nperception module, and then compare two meta-learning algorithms for better\ngeneralization in seen and unseen environments. One of them uses the\nModel-Agnostic Meta-Learning (MAML) algorithm that requires a few shot\nadaptation, and the other refers to a metric-based meta-learning method with a\nfeature-wise affine transformation layer. The experiment results show that our\nstrategy successfully adapts the learned navigation model to a new camera\nconfiguration, and the two algorithms show their advantages in seen and unseen\nenvironments respectively.\n", "versions": [{"version": "v1", "created": "Thu, 10 Dec 2020 04:10:04 GMT"}, {"version": "v2", "created": "Fri, 11 Dec 2020 10:10:58 GMT"}, {"version": "v3", "created": "Tue, 19 Jan 2021 02:39:00 GMT"}], "update_date": "2021-01-20", "authors_parsed": [["Wang", "Ting", ""], ["Wu", "Zongkai", ""], ["Wang", "Donglin", ""]]}, {"id": "2012.05453", "submitter": "Vivek Khetan", "authors": "Vivek Khetan, Roshni Ramnani, Mayuresh Anand, Shubhashis Sengupta and\n  Andrew E.Fano", "title": "Causal BERT : Language models for causality detection between events\n  expressed in text", "comments": "17 pages, 4 figures, to be published in Advances in Intelligent\n  Systems and Computing, Appendixed by Vivek Khetan", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Causality understanding between events is a critical natural language\nprocessing task that is helpful in many areas, including health care, business\nrisk management and finance. On close examination, one can find a huge amount\nof textual content both in the form of formal documents or in content arising\nfrom social media like Twitter, dedicated to communicating and exploring\nvarious types of causality in the real world. Recognizing these \"Cause-Effect\"\nrelationships between natural language events continues to remain a challenge\nsimply because it is often expressed implicitly. Implicit causality is hard to\ndetect through most of the techniques employed in literature and can also, at\ntimes be perceived as ambiguous or vague. Also, although well-known datasets do\nexist for this problem, the examples in them are limited in the range and\ncomplexity of the causal relationships they depict especially when related to\nimplicit relationships. Most of the contemporary methods are either based on\nlexico-semantic pattern matching or are feature-driven supervised methods.\nTherefore, as expected these methods are more geared towards handling explicit\ncausal relationships leading to limited coverage for implicit relationships and\nare hard to generalize. In this paper, we investigate the language model's\ncapabilities for causal association among events expressed in natural language\ntext using sentence context combined with event information, and by leveraging\nmasked event context with in-domain and out-of-domain data distribution. Our\nproposed methods achieve the state-of-art performance in three different data\ndistributions and can be leveraged for extraction of a causal diagram and/or\nbuilding a chain of events from unstructured text.\n", "versions": [{"version": "v1", "created": "Thu, 10 Dec 2020 04:59:12 GMT"}, {"version": "v2", "created": "Thu, 28 Jan 2021 21:15:26 GMT"}], "update_date": "2021-02-01", "authors_parsed": [["Khetan", "Vivek", ""], ["Ramnani", "Roshni", ""], ["Anand", "Mayuresh", ""], ["Sengupta", "Shubhashis", ""], ["Fano", "Andrew E.", ""]]}, {"id": "2012.05457", "submitter": "Guanya Shi", "authors": "Guanya Shi, Wolfgang H\\\"onig, Xichen Shi, Yisong Yue, Soon-Jo Chung", "title": "Neural-Swarm2: Planning and Control of Heterogeneous Multirotor Swarms\n  using Learned Interactions", "comments": "Accepted by IEEE Transactions on Robotics (T-RO), 2021. Video is\n  available at https://youtu.be/Y02juH6BDxo", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present Neural-Swarm2, a learning-based method for motion planning and\ncontrol that allows heterogeneous multirotors in a swarm to safely fly in close\nproximity. Such operation for drones is challenging due to complex aerodynamic\ninteraction forces, such as downwash generated by nearby drones and ground\neffect. Conventional planning and control methods neglect capturing these\ninteraction forces, resulting in sparse swarm configuration during flight. Our\napproach combines a physics-based nominal dynamics model with learned Deep\nNeural Networks (DNNs) with strong Lipschitz properties. We make use of two\ntechniques to accurately predict the aerodynamic interactions between\nheterogeneous multirotors: i) spectral normalization for stability and\ngeneralization guarantees of unseen data and ii) heterogeneous deep sets for\nsupporting any number of heterogeneous neighbors in a permutation-invariant\nmanner without reducing expressiveness. The learned residual dynamics benefit\nboth the proposed interaction-aware multi-robot motion planning and the\nnonlinear tracking control design because the learned interaction forces reduce\nthe modelling errors. Experimental results demonstrate that Neural-Swarm2 is\nable to generalize to larger swarms beyond training cases and significantly\noutperforms a baseline nonlinear tracking controller with up to three times\nreduction in worst-case tracking errors.\n", "versions": [{"version": "v1", "created": "Thu, 10 Dec 2020 05:08:31 GMT"}, {"version": "v2", "created": "Fri, 16 Jul 2021 01:24:46 GMT"}], "update_date": "2021-07-19", "authors_parsed": [["Shi", "Guanya", ""], ["H\u00f6nig", "Wolfgang", ""], ["Shi", "Xichen", ""], ["Yue", "Yisong", ""], ["Chung", "Soon-Jo", ""]]}, {"id": "2012.05462", "submitter": "Yujia Zheng", "authors": "Yujia Zheng, Siyi Liu, Zekun Li, Shu Wu", "title": "Cold-start Sequential Recommendation via Meta Learner", "comments": "Accepted at AAAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper explores meta-learning in sequential recommendation to alleviate\nthe item cold-start problem. Sequential recommendation aims to capture user's\ndynamic preferences based on historical behavior sequences and acts as a key\ncomponent of most online recommendation scenarios. However, most previous\nmethods have trouble recommending cold-start items, which are prevalent in\nthose scenarios. As there is generally no side information in the setting of\nsequential recommendation task, previous cold-start methods could not be\napplied when only user-item interactions are available. Thus, we propose a\nMeta-learning-based Cold-Start Sequential Recommendation Framework, namely\nMecos, to mitigate the item cold-start problem in sequential recommendation.\nThis task is non-trivial as it targets at an important problem in a novel and\nchallenging context. Mecos effectively extracts user preference from limited\ninteractions and learns to match the target cold-start item with the potential\nuser. Besides, our framework can be painlessly integrated with neural\nnetwork-based models. Extensive experiments conducted on three real-world\ndatasets verify the superiority of Mecos, with the average improvement up to\n99%, 91%, and 70% in HR@10 over state-of-the-art baseline methods.\n", "versions": [{"version": "v1", "created": "Thu, 10 Dec 2020 05:23:13 GMT"}], "update_date": "2020-12-11", "authors_parsed": [["Zheng", "Yujia", ""], ["Liu", "Siyi", ""], ["Li", "Zekun", ""], ["Wu", "Shu", ""]]}, {"id": "2012.05475", "submitter": "Xinyang Jiang", "authors": "Enwei Zhang, Xinyang Jiang, Hao Cheng, Ancong Wu, Fufu Yu, Ke Li,\n  Xiaowei Guo, Feng Zheng, Wei-Shi Zheng, Xing Sun", "title": "One for More: Selecting Generalizable Samples for Generalizable ReID\n  Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current training objectives of existing person Re-IDentification (ReID)\nmodels only ensure that the loss of the model decreases on selected training\nbatch, with no regards to the performance on samples outside the batch. It will\ninevitably cause the model to over-fit the data in the dominant position (e.g.,\nhead data in imbalanced class, easy samples or noisy samples). %We call the\nsample that updates the model towards generalizing on more data a generalizable\nsample. The latest resampling methods address the issue by designing specific\ncriterion to select specific samples that trains the model generalize more on\ncertain type of data (e.g., hard samples, tail data), which is not adaptive to\nthe inconsistent real world ReID data distributions. Therefore, instead of\nsimply presuming on what samples are generalizable, this paper proposes a\none-for-more training objective that directly takes the generalization ability\nof selected samples as a loss function and learn a sampler to automatically\nselect generalizable samples. More importantly, our proposed one-for-more based\nsampler can be seamlessly integrated into the ReID training framework which is\nable to simultaneously train ReID models and the sampler in an end-to-end\nfashion. The experimental results show that our method can effectively improve\nthe ReID model training and boost the performance of ReID models.\n", "versions": [{"version": "v1", "created": "Thu, 10 Dec 2020 06:37:09 GMT"}, {"version": "v2", "created": "Fri, 11 Dec 2020 06:37:21 GMT"}], "update_date": "2020-12-14", "authors_parsed": [["Zhang", "Enwei", ""], ["Jiang", "Xinyang", ""], ["Cheng", "Hao", ""], ["Wu", "Ancong", ""], ["Yu", "Fufu", ""], ["Li", "Ke", ""], ["Guo", "Xiaowei", ""], ["Zheng", "Feng", ""], ["Zheng", "Wei-Shi", ""], ["Sun", "Xing", ""]]}, {"id": "2012.05489", "submitter": "Musarrat Husssain", "authors": "Musarrat Hussain, Jamil Hussain, Taqdir Ali, Fahad Ahmed Satti,\n  Sungyoung Lee", "title": "AI Driven Knowledge Extraction from Clinical Practice Guidelines:\n  Turning Research into Practice", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Background and Objectives: Clinical Practice Guidelines (CPGs) represent the\nforemost methodology for sharing state-of-the-art research findings in the\nhealthcare domain with medical practitioners to limit practice variations,\nreduce clinical cost, improve the quality of care, and provide evidence based\ntreatment. However, extracting relevant knowledge from the plethora of CPGs is\nnot feasible for already burdened healthcare professionals, leading to large\ngaps between clinical findings and real practices. It is therefore imperative\nthat state-of-the-art Computing research, especially machine learning is used\nto provide artificial intelligence based solution for extracting the knowledge\nfrom CPGs and reducing the gap between healthcare research/guidelines and\npractice. Methods: This research presents a novel methodology for knowledge\nextraction from CPGs to reduce the gap and turn the latest research findings\ninto clinical practice. First, our system classifies the CPG sentences into\nfour classes such as condition-action, condition-consequences, action, and\nnot-applicable based on the information presented in a sentence. We use deep\nlearning with state-of-the-art word embedding, improved word vectors technique\nin classification process. Second, it identifies qualifier terms in the\nclassified sentences, which assist in recognizing the condition and action\nphrases in a sentence. Finally, the condition and action phrase are processed\nand transformed into plain rule If Condition(s) Then Action format. Results: We\nevaluate the methodology on three different domains guidelines including\nHypertension, Rhinosinusitis, and Asthma. The deep learning model classifies\nthe CPG sentences with an accuracy of 95%. While rule extraction was validated\nby user-centric approach, which achieved a Jaccard coefficient of 0.6, 0.7, and\n0.4 with three human experts extracted rules, respectively.\n", "versions": [{"version": "v1", "created": "Thu, 10 Dec 2020 07:23:02 GMT"}], "update_date": "2020-12-11", "authors_parsed": [["Hussain", "Musarrat", ""], ["Hussain", "Jamil", ""], ["Ali", "Taqdir", ""], ["Satti", "Fahad Ahmed", ""], ["Lee", "Sungyoung", ""]]}, {"id": "2012.05499", "submitter": "Daizong Liu", "authors": "Daizong Liu, Shuangjie Xu, Xiao-Yang Liu, Zichuan Xu, Wei Wei, Pan\n  Zhou", "title": "Spatiotemporal Graph Neural Network based Mask Reconstruction for Video\n  Object Segmentation", "comments": "Accepted by AAAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper addresses the task of segmenting class-agnostic objects in\nsemi-supervised setting. Although previous detection based methods achieve\nrelatively good performance, these approaches extract the best proposal by a\ngreedy strategy, which may lose the local patch details outside the chosen\ncandidate. In this paper, we propose a novel spatiotemporal graph neural\nnetwork (STG-Net) to reconstruct more accurate masks for video object\nsegmentation, which captures the local contexts by utilizing all proposals. In\nthe spatial graph, we treat object proposals of a frame as nodes and represent\ntheir correlations with an edge weight strategy for mask context aggregation.\nTo capture temporal information from previous frames, we use a memory network\nto refine the mask of current frame by retrieving historic masks in a temporal\ngraph. The joint use of both local patch details and temporal relationships\nallow us to better address the challenges such as object occlusion and missing.\nWithout online learning and fine-tuning, our STG-Net achieves state-of-the-art\nperformance on four large benchmarks (DAVIS, YouTube-VOS, SegTrack-v2, and\nYouTube-Objects), demonstrating the effectiveness of the proposed approach.\n", "versions": [{"version": "v1", "created": "Thu, 10 Dec 2020 07:57:44 GMT"}], "update_date": "2020-12-11", "authors_parsed": [["Liu", "Daizong", ""], ["Xu", "Shuangjie", ""], ["Liu", "Xiao-Yang", ""], ["Xu", "Zichuan", ""], ["Wei", "Wei", ""], ["Zhou", "Pan", ""]]}, {"id": "2012.05506", "submitter": "Debraj Basu", "authors": "Debraj Basu", "title": "On Shapley Credit Allocation for Interpretability", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  We emphasize the importance of asking the right question when interpreting\nthe decisions of a learning model. We discuss a natural extension of the\ntheoretical machinery from Janzing et. al. 2020, which answers the question\n\"Why did my model predict a person has cancer?\" for answering a more involved\nquestion, \"What caused my model to predict a person has cancer?\" While the\nformer quantifies the direct effects of variables on the model, the latter also\naccounts for indirect effects, thereby providing meaningful insights wherever\nhuman beings can reason in terms of cause and effect. We propose three broad\ncategories for interpretations: observational, model-specific and causal each\nof which are significant in their own right. Furthermore, this paper quantifies\nfeature relevance by weaving different natures of interpretations together with\ndifferent measures as characteristic functions for Shapley symmetrization.\nBesides the widely used expected value of the model, we also discuss measures\nof statistical uncertainty and dispersion as informative candidates, and their\nmerits in generating explanations for each data point, some of which are used\nin this context for the first time. These measures are not only useful for\nstudying the influence of variables on the model output, but also on the\npredictive performance of the model, and for that we propose relevant\ncharacteristic functions that are also used for the first time.\n", "versions": [{"version": "v1", "created": "Thu, 10 Dec 2020 08:25:32 GMT"}], "update_date": "2020-12-11", "authors_parsed": [["Basu", "Debraj", ""]]}, {"id": "2012.05516", "submitter": "Balaji Ganesan", "authors": "Balaji Ganesan, Hima Patel, Sameep Mehta", "title": "Explainable Link Prediction for Privacy-Preserving Contact Tracing", "comments": "8 pages, 7 figures, SpicyFL 2020 Workshop at NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.LG cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Contact Tracing has been used to identify people who were in close proximity\nto those infected with SARS-Cov2 coronavirus. A number of digital contract\ntracing applications have been introduced to facilitate or complement physical\ncontact tracing. However, there are a number of privacy issues in the\nimplementation of contract tracing applications, which make people reluctant to\ninstall or update their infection status on these applications. In this concept\npaper, we present ideas from Graph Neural Networks and explainability, that\ncould improve trust in these applications, and encourage adoption by people.\n", "versions": [{"version": "v1", "created": "Thu, 10 Dec 2020 08:58:24 GMT"}], "update_date": "2020-12-11", "authors_parsed": [["Ganesan", "Balaji", ""], ["Patel", "Hima", ""], ["Mehta", "Sameep", ""]]}, {"id": "2012.05541", "submitter": "Maria Zimina", "authors": "Maria Zimina-Poirot (CLILLAC-ARP), Nicolas Ballier (CLILLAC-ARP),\n  Jean-Baptiste Yun\\`es (IRIF)", "title": "Approches quantitatives de l'analyse des pr{\\'e}dictions en traduction\n  automatique neuronale (TAN)", "comments": "in French. JADT 2020 : 15{\\`e}mes Journ{\\'e}es Internationales\n  d'Analyse statistique des Donn{\\'e}es Textuelles, Universit{\\'e} de Toulouse,\n  Jun 2020, Toulouse, France", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As part of a larger project on optimal learning conditions in neural machine\ntranslation, we investigate characteristic training phases of translation\nengines. All our experiments are carried out using OpenNMT-Py: the\npre-processing step is implemented using the Europarl training corpus and the\nINTERSECT corpus is used for validation. Longitudinal analyses of training\nphases suggest that the progression of translations is not always linear.\nFollowing the results of textometric explorations, we identify the importance\nof the phenomena related to chronological progression, in order to map\ndifferent processes at work in neural machine translation (NMT).\n", "versions": [{"version": "v1", "created": "Thu, 10 Dec 2020 09:31:59 GMT"}], "update_date": "2020-12-11", "authors_parsed": [["Zimina-Poirot", "Maria", "", "CLILLAC-ARP"], ["Ballier", "Nicolas", "", "CLILLAC-ARP"], ["Yun\u00e8s", "Jean-Baptiste", "", "IRIF"]]}, {"id": "2012.05545", "submitter": "Zeliang Song", "authors": "Zeliang Song, Xiaofei Zhou, Zhendong Mao, Jianlong Tan", "title": "Image Captioning with Context-Aware Auxiliary Guidance", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Image captioning is a challenging computer vision task, which aims to\ngenerate a natural language description of an image. Most recent researches\nfollow the encoder-decoder framework which depends heavily on the previous\ngenerated words for the current prediction. Such methods can not effectively\ntake advantage of the future predicted information to learn complete semantics.\nIn this paper, we propose Context-Aware Auxiliary Guidance (CAAG) mechanism\nthat can guide the captioning model to perceive global contexts. Upon the\ncaptioning model, CAAG performs semantic attention that selectively\nconcentrates on useful information of the global predictions to reproduce the\ncurrent generation. To validate the adaptability of the method, we apply CAAG\nto three popular captioners and our proposal achieves competitive performance\non the challenging Microsoft COCO image captioning benchmark, e.g. 132.2\nCIDEr-D score on Karpathy split and 130.7 CIDEr-D (c40) score on official\nonline evaluation server.\n", "versions": [{"version": "v1", "created": "Thu, 10 Dec 2020 09:39:08 GMT"}, {"version": "v2", "created": "Mon, 4 Jan 2021 01:52:43 GMT"}], "update_date": "2021-01-05", "authors_parsed": [["Song", "Zeliang", ""], ["Zhou", "Xiaofei", ""], ["Mao", "Zhendong", ""], ["Tan", "Jianlong", ""]]}, {"id": "2012.05603", "submitter": "Sander Beckers", "authors": "Sander Beckers", "title": "Equivalent Causal Models", "comments": "Preprint of accepted AAAI2021 paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The aim of this paper is to offer the first systematic exploration and\ndefinition of equivalent causal models in the context where both models are not\nmade up of the same variables. The idea is that two models are equivalent when\nthey agree on all \"essential\" causal information that can be expressed using\ntheir common variables. I do so by focussing on the two main features of causal\nmodels, namely their structural relations and their functional relations. In\nparticular, I define several relations of causal ancestry and several relations\nof causal sufficiency, and require that the most general of these relations are\npreserved across equivalent models.\n", "versions": [{"version": "v1", "created": "Thu, 10 Dec 2020 11:43:35 GMT"}], "update_date": "2020-12-11", "authors_parsed": [["Beckers", "Sander", ""]]}, {"id": "2012.05660", "submitter": "Liang Hou", "authors": "Liang Hou, Zehuan Yuan, Lei Huang, Huawei Shen, Xueqi Cheng, Changhu\n  Wang", "title": "Slimmable Generative Adversarial Networks", "comments": "Accepted to AAAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative adversarial networks (GANs) have achieved remarkable progress in\nrecent years, but the continuously growing scale of models makes them\nchallenging to deploy widely in practical applications. In particular, for\nreal-time generation tasks, different devices require generators of different\nsizes due to varying computing power. In this paper, we introduce slimmable\nGANs (SlimGANs), which can flexibly switch the width of the generator to\naccommodate various quality-efficiency trade-offs at runtime. Specifically, we\nleverage multiple discriminators that share partial parameters to train the\nslimmable generator. To facilitate the \\textit{consistency} between generators\nof different widths, we present a stepwise inplace distillation technique that\nencourages narrow generators to learn from wide ones. As for class-conditional\ngeneration, we propose a sliceable conditional batch normalization that\nincorporates the label information into different widths. Our methods are\nvalidated, both quantitatively and qualitatively, by extensive experiments and\na detailed ablation study.\n", "versions": [{"version": "v1", "created": "Thu, 10 Dec 2020 13:35:22 GMT"}, {"version": "v2", "created": "Tue, 15 Dec 2020 10:57:25 GMT"}, {"version": "v3", "created": "Thu, 18 Mar 2021 03:14:01 GMT"}], "update_date": "2021-03-19", "authors_parsed": [["Hou", "Liang", ""], ["Yuan", "Zehuan", ""], ["Huang", "Lei", ""], ["Shen", "Huawei", ""], ["Cheng", "Xueqi", ""], ["Wang", "Changhu", ""]]}, {"id": "2012.05665", "submitter": "Hieu Le Trung", "authors": "Hieu Le Trung and Yiqing Xu and Wee Sun Lee", "title": "Factor Graph Molecule Network for Structure Elucidation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Designing a network to learn a molecule structure given its physical/chemical\nproperties is a hard problem, but is useful for drug discovery tasks. In this\npaper, we incorporate higher-order relational learning of Factor Graphs with\nstrong approximation power of Neural Networks to create a molecule-structure\nlearning network that has strong generalization power and can enforce\nhigher-order relationship and valence constraints. We further propose methods\nto tackle problems such as the efficient design of factor nodes, conditional\nparameter sharing among factors, and symmetry problems in molecule structure\nprediction. Our experiment evaluation shows that the factor learning is\neffective and outperforms related methods.\n", "versions": [{"version": "v1", "created": "Thu, 10 Dec 2020 13:45:17 GMT"}], "update_date": "2020-12-11", "authors_parsed": [["Trung", "Hieu Le", ""], ["Xu", "Yiqing", ""], ["Lee", "Wee Sun", ""]]}, {"id": "2012.05672", "submitter": "Timothy Lillicrap", "authors": "Josh Abramson, Arun Ahuja, Iain Barr, Arthur Brussee, Federico\n  Carnevale, Mary Cassin, Rachita Chhaparia, Stephen Clark, Bogdan Damoc,\n  Andrew Dudzik, Petko Georgiev, Aurelia Guy, Tim Harley, Felix Hill, Alden\n  Hung, Zachary Kenton, Jessica Landon, Timothy Lillicrap, Kory Mathewson,\n  So\\v{n}a Mokr\\'a, Alistair Muldal, Adam Santoro, Nikolay Savinov, Vikrant\n  Varma, Greg Wayne, Duncan Williams, Nathaniel Wong, Chen Yan, Rui Zhu", "title": "Imitating Interactive Intelligence", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A common vision from science fiction is that robots will one day inhabit our\nphysical spaces, sense the world as we do, assist our physical labours, and\ncommunicate with us through natural language. Here we study how to design\nartificial agents that can interact naturally with humans using the\nsimplification of a virtual environment. This setting nevertheless integrates a\nnumber of the central challenges of artificial intelligence (AI) research:\ncomplex visual perception and goal-directed physical control, grounded language\ncomprehension and production, and multi-agent social interaction. To build\nagents that can robustly interact with humans, we would ideally train them\nwhile they interact with humans. However, this is presently impractical.\nTherefore, we approximate the role of the human with another learned agent, and\nuse ideas from inverse reinforcement learning to reduce the disparities between\nhuman-human and agent-agent interactive behaviour. Rigorously evaluating our\nagents poses a great challenge, so we develop a variety of behavioural tests,\nincluding evaluation by humans who watch videos of agents or interact directly\nwith them. These evaluations convincingly demonstrate that interactive training\nand auxiliary losses improve agent behaviour beyond what is achieved by\nsupervised learning of actions alone. Further, we demonstrate that agent\ncapabilities generalise beyond literal experiences in the dataset. Finally, we\ntrain evaluation models whose ratings of agents agree well with human\njudgement, thus permitting the evaluation of new agent models without\nadditional effort. Taken together, our results in this virtual environment\nprovide evidence that large-scale human behavioural imitation is a promising\ntool to create intelligent, interactive agents, and the challenge of reliably\nevaluating such agents is possible to surmount.\n", "versions": [{"version": "v1", "created": "Thu, 10 Dec 2020 13:55:47 GMT"}, {"version": "v2", "created": "Thu, 21 Jan 2021 03:25:38 GMT"}], "update_date": "2021-01-22", "authors_parsed": [["Abramson", "Josh", ""], ["Ahuja", "Arun", ""], ["Barr", "Iain", ""], ["Brussee", "Arthur", ""], ["Carnevale", "Federico", ""], ["Cassin", "Mary", ""], ["Chhaparia", "Rachita", ""], ["Clark", "Stephen", ""], ["Damoc", "Bogdan", ""], ["Dudzik", "Andrew", ""], ["Georgiev", "Petko", ""], ["Guy", "Aurelia", ""], ["Harley", "Tim", ""], ["Hill", "Felix", ""], ["Hung", "Alden", ""], ["Kenton", "Zachary", ""], ["Landon", "Jessica", ""], ["Lillicrap", "Timothy", ""], ["Mathewson", "Kory", ""], ["Mokr\u00e1", "So\u0148a", ""], ["Muldal", "Alistair", ""], ["Santoro", "Adam", ""], ["Savinov", "Nikolay", ""], ["Varma", "Vikrant", ""], ["Wayne", "Greg", ""], ["Williams", "Duncan", ""], ["Wong", "Nathaniel", ""], ["Yan", "Chen", ""], ["Zhu", "Rui", ""]]}, {"id": "2012.05684", "submitter": "Kostadin Cvejoski", "authors": "Kostadin Cvejoski, Ramses J. Sanchez, Bogdan Georgiev, Christian\n  Bauckhage and Cesar Ojeda", "title": "Recurrent Point Review Models", "comments": "8 pages, 6 figures, Published in: 2020 International Joint Conference\n  on Neural Networks (IJCNN)", "journal-ref": "2020 International Joint Conference on Neural Networks (IJCNN),\n  Glasgow, United Kingdom, 2020, pp. 1-8", "doi": "10.1109/IJCNN48605.2020.9206768", "report-no": null, "categories": "cs.LG cs.AI cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Deep neural network models represent the state-of-the-art methodologies for\nnatural language processing. Here we build on top of these methodologies to\nincorporate temporal information and model how to review data changes with\ntime. Specifically, we use the dynamic representations of recurrent point\nprocess models, which encode the history of how business or service reviews are\nreceived in time, to generate instantaneous language models with improved\nprediction capabilities. Simultaneously, our methodologies enhance the\npredictive power of our point process models by incorporating summarized review\ncontent representations. We provide recurrent network and temporal convolution\nsolutions for modeling the review content. We deploy our methodologies in the\ncontext of recommender systems, effectively characterizing the change in\npreference and taste of users as time evolves. Source code is available at [1].\n", "versions": [{"version": "v1", "created": "Thu, 10 Dec 2020 14:11:42 GMT"}], "update_date": "2020-12-11", "authors_parsed": [["Cvejoski", "Kostadin", ""], ["Sanchez", "Ramses J.", ""], ["Georgiev", "Bogdan", ""], ["Bauckhage", "Christian", ""], ["Ojeda", "Cesar", ""]]}, {"id": "2012.05685", "submitter": "Bogdan Georgiev", "authors": "David Biesner, Kostadin Cvejoski, Bogdan Georgiev, Rafet Sifa, Erik\n  Krupicka", "title": "Generative Deep Learning Techniques for Password Generation", "comments": "25 pages, 13 figures. Comments welcome!", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Password guessing approaches via deep learning have recently been\ninvestigated with significant breakthroughs in their ability to generate novel,\nrealistic password candidates. In the present work we study a broad collection\nof deep learning and probabilistic based models in the light of password\nguessing: attention-based deep neural networks, autoencoding mechanisms and\ngenerative adversarial networks. We provide novel generative deep-learning\nmodels in terms of variational autoencoders exhibiting state-of-art sampling\nperformance, yielding additional latent-space features such as interpolations\nand targeted sampling. Lastly, we perform a thorough empirical analysis in a\nunified controlled framework over well-known datasets (RockYou, LinkedIn,\nYouku, Zomato, Pwnd). Our results not only identify the most promising schemes\ndriven by deep neural networks, but also illustrate the strengths of each\napproach in terms of generation variability and sample uniqueness.\n", "versions": [{"version": "v1", "created": "Thu, 10 Dec 2020 14:11:45 GMT"}, {"version": "v2", "created": "Wed, 16 Dec 2020 20:43:19 GMT"}], "update_date": "2020-12-18", "authors_parsed": [["Biesner", "David", ""], ["Cvejoski", "Kostadin", ""], ["Georgiev", "Bogdan", ""], ["Sifa", "Rafet", ""], ["Krupicka", "Erik", ""]]}, {"id": "2012.05694", "submitter": "Sayan Nag", "authors": "Sayan Nag", "title": "Lookahead optimizer improves the performance of Convolutional\n  Autoencoders for reconstruction of natural images", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.GR cs.LG physics.data-an", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Autoencoders are a class of artificial neural networks which have gained a\nlot of attention in the recent past. Using the encoder block of an autoencoder\nthe input image can be compressed into a meaningful representation. Then a\ndecoder is employed to reconstruct the compressed representation back to a\nversion which looks like the input image. It has plenty of applications in the\nfield of data compression and denoising. Another version of Autoencoders (AE)\nexist, called Variational AE (VAE) which acts as a generative model like GAN.\nRecently, an optimizer was introduced which is known as lookahead optimizer\nwhich significantly enhances the performances of Adam as well as SGD. In this\npaper, we implement Convolutional Autoencoders (CAE) and Convolutional\nVariational Autoencoders (CVAE) with lookahead optimizer (with Adam) and\ncompare them with the Adam (only) optimizer counterparts. For this purpose, we\nhave used a movie dataset comprising of natural images for the former case and\nCIFAR100 for the latter case. We show that lookahead optimizer (with Adam)\nimproves the performance of CAEs for reconstruction of natural images.\n", "versions": [{"version": "v1", "created": "Thu, 3 Dec 2020 03:18:28 GMT"}], "update_date": "2020-12-11", "authors_parsed": [["Nag", "Sayan", ""]]}, {"id": "2012.05715", "submitter": "Wlodek Zadrozny", "authors": "Wlodek W. Zadrozny", "title": "Towards Coinductive Models for Natural Language Understanding. Bringing\n  together Deep Learning and Deep Semantics", "comments": "32 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This article contains a proposal to add coinduction to the computational\napparatus of natural language understanding. This, we argue, will provide a\nbasis for more realistic, computationally sound, and scalable models of natural\nlanguage dialogue, syntax and semantics. Given that the bottom up, inductively\nconstructed, semantic and syntactic structures are brittle, and seemingly\nincapable of adequately representing the meaning of longer sentences or\nrealistic dialogues, natural language understanding is in need of a new\nfoundation. Coinduction, which uses top down constraints, has been successfully\nused in the design of operating systems and programming languages. Moreover,\nimplicitly it has been present in text mining, machine translation, and in some\nattempts to model intensionality and modalities, which provides evidence that\nit works. This article shows high level formalizations of some of such uses.\n  Since coinduction and induction can coexist, they can provide a common\nlanguage and a conceptual model for research in natural language understanding.\nIn particular, such an opportunity seems to be emerging in research on\ncompositionality. This article shows several examples of the joint appearance\nof induction and coinduction in natural language processing. We argue that the\nknown individual limitations of induction and coinduction can be overcome in\nempirical settings by a combination of the the two methods. We see an open\nproblem in providing a theory of their joint use.\n", "versions": [{"version": "v1", "created": "Wed, 9 Dec 2020 03:10:36 GMT"}], "update_date": "2020-12-11", "authors_parsed": [["Zadrozny", "Wlodek W.", ""]]}, {"id": "2012.05738", "submitter": "Nico Potyka", "authors": "Nico Potyka", "title": "Interpreting Neural Networks as Gradual Argumentation Frameworks\n  (Including Proof Appendix)", "comments": "Accepted at AAAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We show that an interesting class of feed-forward neural networks can be\nunderstood as quantitative argumentation frameworks. This connection creates a\nbridge between research in Formal Argumentation and Machine Learning. We\ngeneralize the semantics of feed-forward neural networks to acyclic graphs and\nstudy the resulting computational and semantical properties in argumentation\ngraphs. As it turns out, the semantics gives stronger guarantees than existing\nsemantics that have been tailor-made for the argumentation setting. From a\nmachine-learning perspective, the connection does not seem immediately helpful.\nWhile it gives intuitive meaning to some feed-forward-neural networks, they\nremain difficult to understand due to their size and density. However, the\nconnection seems helpful for combining background knowledge in form of sparse\nargumentation networks with dense neural networks that have been trained for\ncomplementary purposes and for learning the parameters of quantitative\nargumentation frameworks in an end-to-end fashion from data.\n", "versions": [{"version": "v1", "created": "Thu, 10 Dec 2020 15:18:15 GMT"}], "update_date": "2020-12-11", "authors_parsed": [["Potyka", "Nico", ""]]}, {"id": "2012.05740", "submitter": "Ruddy Th\\'eodose", "authors": "Ruddy Th\\'eodose, Dieumet Denis, Thierry Chateau, Vincent Fr\\'emont,\n  Paul Checchin", "title": "R-AGNO-RPN: A LIDAR-Camera Region Deep Network for Resolution-Agnostic\n  Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current neural networks-based object detection approaches processing LiDAR\npoint clouds are generally trained from one kind of LiDAR sensors. However,\ntheir performances decrease when they are tested with data coming from a\ndifferent LiDAR sensor than the one used for training, i.e., with a different\npoint cloud resolution. In this paper, R-AGNO-RPN, a region proposal network\nbuilt on fusion of 3D point clouds and RGB images is proposed for 3D object\ndetection regardless of point cloud resolution. As our approach is designed to\nbe also applied on low point cloud resolutions, the proposed method focuses on\nobject localization instead of estimating refined boxes on reduced data. The\nresilience to low-resolution point cloud is obtained through image features\naccurately mapped to Bird's Eye View and a specific data augmentation procedure\nthat improves the contribution of the RGB images. To show the proposed\nnetwork's ability to deal with different point clouds resolutions, experiments\nare conducted on both data coming from the KITTI 3D Object Detection and the\nnuScenes datasets. In addition, to assess its performances, our method is\ncompared to PointPillars, a well-known 3D detection network. Experimental\nresults show that even on point cloud data reduced by $80\\%$ of its original\npoints, our method is still able to deliver relevant proposals localization.\n", "versions": [{"version": "v1", "created": "Thu, 10 Dec 2020 15:22:58 GMT"}], "update_date": "2020-12-11", "authors_parsed": [["Th\u00e9odose", "Ruddy", ""], ["Denis", "Dieumet", ""], ["Chateau", "Thierry", ""], ["Fr\u00e9mont", "Vincent", ""], ["Checchin", "Paul", ""]]}, {"id": "2012.05750", "submitter": "Matthias Samwald", "authors": "Simon Ott, Laura Graf, Asan Agibetov, Christian Meilicke, Matthias\n  Samwald", "title": "Scalable and interpretable rule-based link prediction for large\n  heterogeneous knowledge graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural embedding-based machine learning models have shown promise for\npredicting novel links in biomedical knowledge graphs. Unfortunately, their\npractical utility is diminished by their lack of interpretability. Recently,\nthe fully interpretable, rule-based algorithm AnyBURL yielded highly\ncompetitive results on many general-purpose link prediction benchmarks.\nHowever, its applicability to large-scale prediction tasks on complex\nbiomedical knowledge bases is limited by long inference times and difficulties\nwith aggregating predictions made by multiple rules. We improve upon AnyBURL by\nintroducing the SAFRAN rule application framework which aggregates rules\nthrough a scalable clustering algorithm. SAFRAN yields new state-of-the-art\nresults for fully interpretable link prediction on the established\ngeneral-purpose benchmark FB15K-237 and the large-scale biomedical benchmark\nOpenBioLink. Furthermore, it exceeds the results of multiple established\nembedding-based algorithms on FB15K-237 and narrows the gap between rule-based\nand embedding-based algorithms on OpenBioLink. We also show that SAFRAN\nincreases inference speeds by up to two orders of magnitude.\n", "versions": [{"version": "v1", "created": "Thu, 10 Dec 2020 15:36:47 GMT"}], "update_date": "2020-12-11", "authors_parsed": [["Ott", "Simon", ""], ["Graf", "Laura", ""], ["Agibetov", "Asan", ""], ["Meilicke", "Christian", ""], ["Samwald", "Matthias", ""]]}, {"id": "2012.05760", "submitter": "Evgeniy Golikov", "authors": "Eugene A. Golikov", "title": "Notes on Deep Learning Theory", "comments": "68 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  These are the notes for the lectures that I was giving during Fall 2020 at\nthe Moscow Institute of Physics and Technology (MIPT) and at the Yandex School\nof Data Analysis (YSDA). The notes cover some aspects of initialization, loss\nlandscape, generalization, and a neural tangent kernel theory. While many other\ntopics (e.g. expressivity, a mean-field theory, a double descent phenomenon)\nare missing in the current version, we plan to add them in future revisions.\n", "versions": [{"version": "v1", "created": "Thu, 10 Dec 2020 15:44:18 GMT"}], "update_date": "2020-12-11", "authors_parsed": [["Golikov", "Eugene A.", ""]]}, {"id": "2012.05766", "submitter": "Antonio Rago", "authors": "Emanuele Albini, Piyawat Lertvittayakumjorn, Antonio Rago and\n  Francesca Toni", "title": "Deep Argumentative Explanations", "comments": "16 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the recent, widespread focus on eXplainable AI (XAI), explanations\ncomputed by XAI methods tend to provide little insight into the functioning of\nNeural Networks (NNs). We propose a novel framework for obtaining (local)\nexplanations from NNs while providing transparency about their inner workings,\nand show how to deploy it for various neural architectures and tasks. We refer\nto our novel explanations collectively as Deep Argumentative eXplanations (DAXs\nin short), given that they reflect the deep structure of the underlying NNs and\nthat they are defined in terms of notions from computational argumentation, a\nform of symbolic AI offering useful reasoning abstractions for explanation. We\nevaluate DAXs empirically showing that they exhibit deep fidelity and low\ncomputational cost. We also conduct human experiments indicating that DAXs are\ncomprehensible to humans and align with their judgement, while also being\ncompetitive, in terms of user acceptance, with some existing approaches to XAI\nthat also have an argumentative spirit.\n", "versions": [{"version": "v1", "created": "Thu, 10 Dec 2020 15:55:09 GMT"}, {"version": "v2", "created": "Mon, 1 Mar 2021 16:46:05 GMT"}, {"version": "v3", "created": "Wed, 10 Mar 2021 17:12:30 GMT"}, {"version": "v4", "created": "Mon, 14 Jun 2021 12:29:14 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Albini", "Emanuele", ""], ["Lertvittayakumjorn", "Piyawat", ""], ["Rago", "Antonio", ""], ["Toni", "Francesca", ""]]}, {"id": "2012.05773", "submitter": "Antonio Rago", "authors": "Antonio Rago, Emanuele Albini, Pietro Baroni and Francesca Toni", "title": "Influence-Driven Explanations for Bayesian Network Classifiers", "comments": "11 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the most pressing issues in AI in recent years has been the need to\naddress the lack of explainability of many of its models. We focus on\nexplanations for discrete Bayesian network classifiers (BCs), targeting greater\ntransparency of their inner workings by including intermediate variables in\nexplanations, rather than just the input and output variables as is standard\npractice. The proposed influence-driven explanations (IDXs) for BCs are\nsystematically generated using the causal relationships between variables\nwithin the BC, called influences, which are then categorised by logical\nrequirements, called relation properties, according to their behaviour. These\nrelation properties both provide guarantees beyond heuristic explanation\nmethods and allow the information underpinning an explanation to be tailored to\na particular context's and user's requirements, e.g., IDXs may be dialectical\nor counterfactual. We demonstrate IDXs' capability to explain various forms of\nBCs, e.g., naive or multi-label, binary or categorical, and also integrate\nrecent approaches to explanations for BCs from the literature. We evaluate IDXs\nwith theoretical and empirical analyses, demonstrating their considerable\nadvantages when compared with existing explanation methods.\n", "versions": [{"version": "v1", "created": "Thu, 10 Dec 2020 16:00:51 GMT"}, {"version": "v2", "created": "Mon, 1 Mar 2021 16:54:24 GMT"}, {"version": "v3", "created": "Wed, 10 Mar 2021 17:04:12 GMT"}], "update_date": "2021-03-11", "authors_parsed": [["Rago", "Antonio", ""], ["Albini", "Emanuele", ""], ["Baroni", "Pietro", ""], ["Toni", "Francesca", ""]]}, {"id": "2012.05787", "submitter": "Yassine Himeur", "authors": "Abdullah Alsalemi, Yassine Himeur, Faycal Bensaali, Abbes Amira", "title": "Appliance-Level Monitoring with Micro-Moment Smart Plugs", "comments": "This paper has been accepted in SCA2020: The Fifth international\n  conference on Smart City Applications", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Human population are striving against energy-related issues that not only\naffects society and the development of the world, but also causes global\nwarming. A variety of broad approaches have been developed by both industry and\nthe research community. However, there is an ever increasing need for\ncomprehensive, end-to-end solutions aimed at transforming human behavior rather\nthan device metrics and benchmarks. In this paper, a micro-moment-based smart\nplug system is proposed as part of a larger multi-appliance energy efficiency\nprogram. The smart plug, which includes two sub-units: the power consumption\nunit and environmental monitoring unit collect energy consumption of appliances\nalong with contextual information, such as temperature, humidity, luminosity\nand room occupancy respectively. The plug also allows home automation\ncapability. With the accompanying mobile application, end-users can visualize\nenergy consumption data along with ambient environmental information. Current\nimplementation results show that the proposed system delivers cost-effective\ndeployment while maintaining adequate computation and wireless performance.\n", "versions": [{"version": "v1", "created": "Thu, 10 Dec 2020 16:22:40 GMT"}], "update_date": "2020-12-11", "authors_parsed": [["Alsalemi", "Abdullah", ""], ["Himeur", "Yassine", ""], ["Bensaali", "Faycal", ""], ["Amira", "Abbes", ""]]}, {"id": "2012.05810", "submitter": "Zhibin Li PhD", "authors": "Chuanyu Yang, Kai Yuan, Qiuguo Zhu, Wanming Yu, Zhibin Li", "title": "Multi-expert learning of adaptive legged locomotion", "comments": null, "journal-ref": "Science Robotics, Vol. 5, Issue 49, eabb2174 (2020)", "doi": "10.1126/scirobotics.abb2174", "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Achieving versatile robot locomotion requires motor skills which can adapt to\npreviously unseen situations. We propose a Multi-Expert Learning Architecture\n(MELA) that learns to generate adaptive skills from a group of representative\nexpert skills. During training, MELA is first initialised by a distinct set of\npre-trained experts, each in a separate deep neural network (DNN). Then by\nlearning the combination of these DNNs using a Gating Neural Network (GNN),\nMELA can acquire more specialised experts and transitional skills across\nvarious locomotion modes. During runtime, MELA constantly blends multiple DNNs\nand dynamically synthesises a new DNN to produce adaptive behaviours in\nresponse to changing situations. This approach leverages the advantages of\ntrained expert skills and the fast online synthesis of adaptive policies to\ngenerate responsive motor skills during the changing tasks. Using a unified\nMELA framework, we demonstrated successful multi-skill locomotion on a real\nquadruped robot that performed coherent trotting, steering, and fall recovery\nautonomously, and showed the merit of multi-expert learning generating\nbehaviours which can adapt to unseen scenarios.\n", "versions": [{"version": "v1", "created": "Thu, 10 Dec 2020 16:40:44 GMT"}], "update_date": "2020-12-11", "authors_parsed": [["Yang", "Chuanyu", ""], ["Yuan", "Kai", ""], ["Zhu", "Qiuguo", ""], ["Yu", "Wanming", ""], ["Li", "Zhibin", ""]]}, {"id": "2012.05841", "submitter": "Michael Kapteyn", "authors": "Michael G. Kapteyn and Jacob V.R. Pretorius and Karen E. Willcox", "title": "A Probabilistic Graphical Model Foundation for Enabling Predictive\n  Digital Twins at Scale", "comments": "16 pages, 6 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE cs.AI cs.LG math.OC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  A unifying mathematical formulation is needed to move from one-off digital\ntwins built through custom implementations to robust digital twin\nimplementations at scale. This work proposes a probabilistic graphical model as\na formal mathematical representation of a digital twin and its associated\nphysical asset. We create an abstraction of the asset-twin system as a set of\ncoupled dynamical systems, evolving over time through their respective\nstate-spaces and interacting via observed data and control inputs. The formal\ndefinition of this coupled system as a probabilistic graphical model enables us\nto draw upon well-established theory and methods from Bayesian statistics,\ndynamical systems, and control theory. The declarative and general nature of\nthe proposed digital twin model make it rigorous yet flexible, enabling its\napplication at scale in a diverse range of application areas. We demonstrate\nhow the model is instantiated to enable a structural digital twin of an\nunmanned aerial vehicle (UAV). The digital twin is calibrated using\nexperimental data from a physical UAV asset. Its use in dynamic decision making\nis then illustrated in a synthetic example where the UAV undergoes an in-flight\ndamage event and the digital twin is dynamically updated using sensor data. The\ngraphical model foundation ensures that the digital twin calibration and\nupdating process is principled, unified, and able to scale to an entire fleet\nof digital twins.\n", "versions": [{"version": "v1", "created": "Thu, 10 Dec 2020 17:33:59 GMT"}, {"version": "v2", "created": "Tue, 9 Feb 2021 18:52:40 GMT"}, {"version": "v3", "created": "Tue, 13 Apr 2021 16:47:53 GMT"}], "update_date": "2021-04-14", "authors_parsed": [["Kapteyn", "Michael G.", ""], ["Pretorius", "Jacob V. R.", ""], ["Willcox", "Karen E.", ""]]}, {"id": "2012.05860", "submitter": "Daoming Zong", "authors": "Daoming Zong and Shiliang Sun", "title": "GNN-XML: Graph Neural Networks for Extreme Multi-label Text\n  Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Extreme multi-label text classification (XMTC) aims to tag a text instance\nwith the most relevant subset of labels from an extremely large label set. XMTC\nhas attracted much recent attention due to massive label sets yielded by modern\napplications, such as news annotation and product recommendation. The main\nchallenges of XMTC are the data scalability and sparsity, thereby leading to\ntwo issues: i) the intractability to scale to the extreme label setting, ii)\nthe presence of long-tailed label distribution, implying that a large fraction\nof labels have few positive training instances. To overcome these problems, we\npropose GNN-XML, a scalable graph neural network framework tailored for XMTC\nproblems. Specifically, we exploit label correlations via mining their\nco-occurrence patterns and build a label graph based on the correlation matrix.\nWe then conduct the attributed graph clustering by performing graph convolution\nwith a low-pass graph filter to jointly model label dependencies and label\nfeatures, which induces semantic label clusters. We further propose a\nbilateral-branch graph isomorphism network to decouple representation learning\nand classifier learning for better modeling tail labels. Experimental results\non multiple benchmark datasets show that GNN-XML significantly outperforms\nstate-of-the-art methods while maintaining comparable prediction efficiency and\nmodel size.\n", "versions": [{"version": "v1", "created": "Thu, 10 Dec 2020 18:18:34 GMT"}], "update_date": "2020-12-11", "authors_parsed": [["Zong", "Daoming", ""], ["Sun", "Shiliang", ""]]}, {"id": "2012.05874", "submitter": "Dustin Morrill", "authors": "Dustin Morrill, Ryan D'Orazio, Reca Sarfati, Marc Lanctot, James R.\n  Wright, Amy Greenwald, Michael Bowling", "title": "Hindsight and Sequential Rationality of Correlated Play", "comments": "Technical report for a paper in the proceedings of the thirty-fifth\n  AAAI Conference on Artificial Intelligence (AAAI-21), February 2-9, 2021,\n  Virtual. 26 pages and 15 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Driven by recent successes in two-player, zero-sum game solving and playing,\nartificial intelligence work on games has increasingly focused on algorithms\nthat produce equilibrium-based strategies. However, this approach has been less\neffective at producing competent players in general-sum games or those with\nmore than two players than in two-player, zero-sum games. An appealing\nalternative is to consider adaptive algorithms that ensure strong performance\nin hindsight relative to what could have been achieved with modified behavior.\nThis approach also leads to a game-theoretic analysis, but in the correlated\nplay that arises from joint learning dynamics rather than factored agent\nbehavior at equilibrium. We develop and advocate for this hindsight rationality\nframing of learning in general sequential decision-making settings. To this\nend, we re-examine mediated equilibrium and deviation types in extensive-form\ngames, thereby gaining a more complete understanding and resolving past\nmisconceptions. We present a set of examples illustrating the distinct\nstrengths and weaknesses of each type of equilibrium in the literature, and\nprove that no tractable concept subsumes all others. This line of inquiry\nculminates in the definition of the deviation and equilibrium classes that\ncorrespond to algorithms in the counterfactual regret minimization (CFR)\nfamily, relating them to all others in the literature. Examining CFR in greater\ndetail further leads to a new recursive definition of rationality in correlated\nplay that extends sequential rationality in a way that naturally applies to\nhindsight evaluation.\n", "versions": [{"version": "v1", "created": "Thu, 10 Dec 2020 18:30:21 GMT"}, {"version": "v2", "created": "Thu, 17 Dec 2020 01:13:53 GMT"}, {"version": "v3", "created": "Sat, 12 Jun 2021 03:41:04 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Morrill", "Dustin", ""], ["D'Orazio", "Ryan", ""], ["Sarfati", "Reca", ""], ["Lanctot", "Marc", ""], ["Wright", "James R.", ""], ["Greenwald", "Amy", ""], ["Bowling", "Michael", ""]]}, {"id": "2012.05876", "submitter": "Artur Garcez", "authors": "Artur d'Avila Garcez and Luis C. Lamb", "title": "Neurosymbolic AI: The 3rd Wave", "comments": "37 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Current advances in Artificial Intelligence (AI) and Machine Learning (ML)\nhave achieved unprecedented impact across research communities and industry.\nNevertheless, concerns about trust, safety, interpretability and accountability\nof AI were raised by influential thinkers. Many have identified the need for\nwell-founded knowledge representation and reasoning to be integrated with deep\nlearning and for sound explainability. Neural-symbolic computing has been an\nactive area of research for many years seeking to bring together robust\nlearning in neural networks with reasoning and explainability via symbolic\nrepresentations for network models. In this paper, we relate recent and early\nresearch results in neurosymbolic AI with the objective of identifying the key\ningredients of the next wave of AI systems. We focus on research that\nintegrates in a principled way neural network-based learning with symbolic\nknowledge representation and logical reasoning. The insights provided by 20\nyears of neural-symbolic computing are shown to shed new light onto the\nincreasingly prominent role of trust, safety, interpretability and\naccountability of AI. We also identify promising directions and challenges for\nthe next decade of AI research from the perspective of neural-symbolic systems.\n", "versions": [{"version": "v1", "created": "Thu, 10 Dec 2020 18:31:38 GMT"}, {"version": "v2", "created": "Wed, 16 Dec 2020 23:21:05 GMT"}], "update_date": "2020-12-18", "authors_parsed": [["Garcez", "Artur d'Avila", ""], ["Lamb", "Luis C.", ""]]}, {"id": "2012.05893", "submitter": "Sharada Mohanty", "authors": "Sharada Mohanty, Erik Nygren, Florian Laurent, Manuel Schneider,\n  Christian Scheller, Nilabha Bhattacharya, Jeremy Watson, Adrian Egli,\n  Christian Eichenberger, Christian Baumberger, Gereon Vienken, Irene Sturm,\n  Guillaume Sartoretti, Giacomo Spigler", "title": "Flatland-RL : Multi-Agent Reinforcement Learning on Trains", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Efficient automated scheduling of trains remains a major challenge for modern\nrailway systems. The underlying vehicle rescheduling problem (VRSP) has been a\nmajor focus of Operations Research (OR) since decades. Traditional approaches\nuse complex simulators to study VRSP, where experimenting with a broad range of\nnovel ideas is time consuming and has a huge computational overhead. In this\npaper, we introduce a two-dimensional simplified grid environment called\n\"Flatland\" that allows for faster experimentation. Flatland does not only\nreduce the complexity of the full physical simulation, but also provides an\neasy-to-use interface to test novel approaches for the VRSP, such as\nReinforcement Learning (RL) and Imitation Learning (IL). In order to probe the\npotential of Machine Learning (ML) research on Flatland, we (1) ran a first\nseries of RL and IL experiments and (2) design and executed a public Benchmark\nat NeurIPS 2020 to engage a large community of researchers to work on this\nproblem. Our own experimental results, on the one hand, demonstrate that ML has\npotential in solving the VRSP on Flatland. On the other hand, we identify key\ntopics that need further research. Overall, the Flatland environment has proven\nto be a robust and valuable framework to investigate the VRSP for railway\nnetworks. Our experiments provide a good starting point for further research\nand for the participants of the NeurIPS 2020 Flatland Benchmark. All of these\nefforts together have the potential to have a substantial impact on shaping the\nmobility of the future.\n", "versions": [{"version": "v1", "created": "Thu, 10 Dec 2020 18:54:27 GMT"}, {"version": "v2", "created": "Fri, 11 Dec 2020 14:51:22 GMT"}], "update_date": "2020-12-14", "authors_parsed": [["Mohanty", "Sharada", ""], ["Nygren", "Erik", ""], ["Laurent", "Florian", ""], ["Schneider", "Manuel", ""], ["Scheller", "Christian", ""], ["Bhattacharya", "Nilabha", ""], ["Watson", "Jeremy", ""], ["Egli", "Adrian", ""], ["Eichenberger", "Christian", ""], ["Baumberger", "Christian", ""], ["Vienken", "Gereon", ""], ["Sturm", "Irene", ""], ["Sartoretti", "Guillaume", ""], ["Spigler", "Giacomo", ""]]}, {"id": "2012.05894", "submitter": "Xinshuo Weng", "authors": "Xinshuo Weng, Kris Kitani", "title": "AutoSelect: Automatic and Dynamic Detection Selection for 3D\n  Multi-Object Tracking", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.MA cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  3D multi-object tracking is an important component in robotic perception\nsystems such as self-driving vehicles. Recent work follows a\ntracking-by-detection pipeline, which aims to match past tracklets with\ndetections in the current frame. To avoid matching with false positive\ndetections, prior work filters out detections with low confidence scores via a\nthreshold. However, finding a proper threshold is non-trivial, which requires\nextensive manual search via ablation study. Also, this threshold is sensitive\nto many factors such as target object category so we need to re-search the\nthreshold if these factors change. To ease this process, we propose to\nautomatically select high-quality detections and remove the efforts needed for\nmanual threshold search. Also, prior work often uses a single threshold per\ndata sequence, which is sub-optimal in particular frames or for certain\nobjects. Instead, we dynamically search threshold per frame or per object to\nfurther boost performance. Through experiments on KITTI and nuScenes, our\nmethod can filter out $45.7\\%$ false positives while maintaining the recall,\nachieving new S.O.T.A. performance and removing the need for manually threshold\ntuning.\n", "versions": [{"version": "v1", "created": "Thu, 10 Dec 2020 18:55:51 GMT"}], "update_date": "2020-12-11", "authors_parsed": [["Weng", "Xinshuo", ""], ["Kitani", "Kris", ""]]}, {"id": "2012.05906", "submitter": "Alessandro Provetti", "authors": "Justina Deveikyte, Helyette Geman, Carlo Piccari, Alessandro Provetti", "title": "A Sentiment Analysis Approach to the Prediction of Market Volatility", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.ST cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Prediction and quantification of future volatility and returns play an\nimportant role in financial modelling, both in portfolio optimization and risk\nmanagement. Natural language processing today allows to process news and social\nmedia comments to detect signals of investors' confidence. We have explored the\nrelationship between sentiment extracted from financial news and tweets and\nFTSE100 movements. We investigated the strength of the correlation between\nsentiment measures on a given day and market volatility and returns observed\nthe next day. The findings suggest that there is evidence of correlation\nbetween sentiment and stock market movements: the sentiment captured from news\nheadlines could be used as a signal to predict market returns; the same does\nnot apply for volatility. Also, in a surprising finding, for the sentiment\nfound in Twitter comments we obtained a correlation coefficient of -0.7, and\np-value below 0.05, which indicates a strong negative correlation between\npositive sentiment captured from the tweets on a given day and the volatility\nobserved the next day. We developed an accurate classifier for the prediction\nof market volatility in response to the arrival of new information by deploying\ntopic modelling, based on Latent Dirichlet Allocation, to extract feature\nvectors from a collection of tweets and financial news. The obtained features\nwere used as additional input to the classifier. Thanks to the combination of\nsentiment and topic modelling our classifier achieved a directional prediction\naccuracy for volatility of 63%.\n", "versions": [{"version": "v1", "created": "Thu, 10 Dec 2020 01:15:48 GMT"}], "update_date": "2020-12-14", "authors_parsed": [["Deveikyte", "Justina", ""], ["Geman", "Helyette", ""], ["Piccari", "Carlo", ""], ["Provetti", "Alessandro", ""]]}, {"id": "2012.05980", "submitter": "Haoteng Tang", "authors": "Haoteng Tang, Guixiang Ma, Lifang He, Heng Huang, Liang Zhan", "title": "CommPOOL: An Interpretable Graph Pooling Framework for Hierarchical\n  Graph Representation Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recent years have witnessed the emergence and flourishing of hierarchical\ngraph pooling neural networks (HGPNNs) which are effective graph representation\nlearning approaches for graph level tasks such as graph classification.\nHowever, current HGPNNs do not take full advantage of the graph's intrinsic\nstructures (e.g., community structure). Moreover, the pooling operations in\nexisting HGPNNs are difficult to be interpreted. In this paper, we propose a\nnew interpretable graph pooling framework - CommPOOL, that can capture and\npreserve the hierarchical community structure of graphs in the graph\nrepresentation learning process. Specifically, the proposed community pooling\nmechanism in CommPOOL utilizes an unsupervised approach for capturing the\ninherent community structure of graphs in an interpretable manner. CommPOOL is\na general and flexible framework for hierarchical graph representation learning\nthat can further facilitate various graph-level tasks. Evaluations on five\npublic benchmark datasets and one synthetic dataset demonstrate the superior\nperformance of CommPOOL in graph representation learning for graph\nclassification compared to the state-of-the-art baseline methods, and its\neffectiveness in capturing and preserving the community structure of graphs.\n", "versions": [{"version": "v1", "created": "Thu, 10 Dec 2020 21:14:18 GMT"}], "update_date": "2020-12-14", "authors_parsed": [["Tang", "Haoteng", ""], ["Ma", "Guixiang", ""], ["He", "Lifang", ""], ["Huang", "Heng", ""], ["Zhan", "Liang", ""]]}, {"id": "2012.05983", "submitter": "Zachary Brown", "authors": "Zachary C. Brown, Nathaniel Robinson, David Wingate, Nancy Fulda", "title": "Towards Neural Programming Interfaces", "comments": "24 pages total (13 for main paper and references, 11 for Appendix 1),\n  accepted for publication in Advances in Neural Information Processing Systems\n  33 (NeurIPS 2020)", "journal-ref": "Neural Information Processing Systems 33 (2020) 17416-17428", "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  It is notoriously difficult to control the behavior of artificial neural\nnetworks such as generative neural language models. We recast the problem of\ncontrolling natural language generation as that of learning to interface with a\npretrained language model, just as Application Programming Interfaces (APIs)\ncontrol the behavior of programs by altering hyperparameters. In this new\nparadigm, a specialized neural network (called a Neural Programming Interface\nor NPI) learns to interface with a pretrained language model by manipulating\nthe hidden activations of the pretrained model to produce desired outputs.\nImportantly, no permanent changes are made to the weights of the original\nmodel, allowing us to re-purpose pretrained models for new tasks without\noverwriting any aspect of the language model. We also contribute a new data set\nconstruction algorithm and GAN-inspired loss function that allows us to train\nNPI models to control outputs of autoregressive transformers. In experiments\nagainst other state-of-the-art approaches, we demonstrate the efficacy of our\nmethods using OpenAI's GPT-2 model, successfully controlling noun selection,\ntopic aversion, offensive speech filtering, and other aspects of language while\nlargely maintaining the controlled model's fluency under deterministic\nsettings.\n", "versions": [{"version": "v1", "created": "Thu, 10 Dec 2020 21:17:04 GMT"}, {"version": "v2", "created": "Thu, 18 Feb 2021 04:38:51 GMT"}], "update_date": "2021-04-14", "authors_parsed": [["Brown", "Zachary C.", ""], ["Robinson", "Nathaniel", ""], ["Wingate", "David", ""], ["Fulda", "Nancy", ""]]}, {"id": "2012.05997", "submitter": "Atefeh Keshavarzi Zafarghandi", "authors": "Atefeh Keshavarzi Zafarghandi, Rineke Verbrugge and Bart Verheij", "title": "Strong Admissibility for Abstract Dialectical Frameworks", "comments": "9 pages, 3 Figures, SAC '21 conference: The 36th ACM/SIGAPP Symposium\n  on Applied Computing", "journal-ref": null, "doi": "10.1145/3412841.3441962", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Abstract dialectical frameworks (ADFs) have been introduced as a formalism\nfor modeling and evaluating argumentation allowing general logical satisfaction\nconditions. Different criteria used to settle the acceptance of arguments are\ncalled semantics. Semantics of ADFs have so far mainly been defined based on\nthe concept of admissibility. However, the notion of strongly admissible\nsemantics studied for abstract argumentation frameworks has not yet been\nintroduced for ADFs. In the current work we present the concept of strong\nadmissibility of interpretations for ADFs. Further, we show that strongly\nadmissible interpretations of ADFs form a lattice with the grounded\ninterpretation as top element.\n", "versions": [{"version": "v1", "created": "Thu, 10 Dec 2020 21:50:35 GMT"}], "update_date": "2020-12-14", "authors_parsed": [["Zafarghandi", "Atefeh Keshavarzi", ""], ["Verbrugge", "Rineke", ""], ["Verheij", "Bart", ""]]}, {"id": "2012.05999", "submitter": "Mohammad Ayoub Khan Dr", "authors": "Mohammad Ayoub Khan", "title": "An IoT Framework for Heart Disease Prediction based on MDCNN Classifier", "comments": "AEHO; cuttlefish algorithm; MDCNN; IoT; Cleveland Dataset; Sensors;\n  Wearable device; CAGR; Electrocardiogram; LSTM and CNN", "journal-ref": "IEEE Access(2020) 34717-34727", "doi": "10.1109/ACCESS.2020.2974687", "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Nowadays, heart disease is the leading cause of death worldwide. Predicting\nheart disease is a complex task since it requires experience along with\nadvanced knowledge. Internet of Things (IoT) technology has lately been adopted\nin healthcare systems to collect sensor values for heart disease diagnosis and\nprediction. Many researchers have focused on the diagnosis of heart disease,\nyet the accuracy of the diagnosis results is low. To address this issue, an IoT\nframework is proposed to evaluate heart disease more accurately using a\nModified Deep Convolutional Neural Network (MDCNN). The smartwatch and heart\nmonitor device that is attached to the patient monitors the blood pressure and\nelectrocardiogram (ECG). The MDCNN is utilized for classifying the received\nsensor data into normal and abnormal. The performance of the system is analyzed\nby comparing the proposed MDCNN with existing deep learning neural networks and\nlogistic regression. The results demonstrate that the proposed MDCNN based\nheart disease prediction system performs better than other methods. The\nproposed method shows that for the maximum number of records, the MDCNN\nachieves an accuracy of 98.2 which is better than existing classifiers.\n", "versions": [{"version": "v1", "created": "Thu, 10 Dec 2020 22:00:56 GMT"}], "update_date": "2020-12-14", "authors_parsed": [["Khan", "Mohammad Ayoub", ""]]}, {"id": "2012.06000", "submitter": "Thomas P Quinn", "authors": "Thomas P. Quinn, Stephan Jacobs, Manisha Senadeera, Vuong Le, Simon\n  Coghlan", "title": "The Three Ghosts of Medical AI: Can the Black-Box Present Deliver?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Our title alludes to the three Christmas ghosts encountered by Ebenezer\nScrooge in \\textit{A Christmas Carol}, who guide Ebenezer through the past,\npresent, and future of Christmas holiday events. Similarly, our article will\ntake readers through a journey of the past, present, and future of medical AI.\nIn doing so, we focus on the crux of modern machine learning: the reliance on\npowerful but intrinsically opaque models. When applied to the healthcare\ndomain, these models fail to meet the needs for transparency that their\nclinician and patient end-users require. We review the implications of this\nfailure, and argue that opaque models (1) lack quality assurance, (2) fail to\nelicit trust, and (3) restrict physician-patient dialogue. We then discuss how\nupholding transparency in all aspects of model design and model validation can\nhelp ensure the reliability of medical AI.\n", "versions": [{"version": "v1", "created": "Thu, 10 Dec 2020 22:22:30 GMT"}], "update_date": "2020-12-14", "authors_parsed": [["Quinn", "Thomas P.", ""], ["Jacobs", "Stephan", ""], ["Senadeera", "Manisha", ""], ["Le", "Vuong", ""], ["Coghlan", "Simon", ""]]}, {"id": "2012.06002", "submitter": "Yiding Yang", "authors": "Huihui Liu, Yiding Yang, Xinchao Wang", "title": "Overcoming Catastrophic Forgetting in Graph Neural Networks", "comments": "Accepted by AAAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Catastrophic forgetting refers to the tendency that a neural network\n\"forgets\" the previous learned knowledge upon learning new tasks. Prior methods\nhave been focused on overcoming this problem on convolutional neural networks\n(CNNs), where the input samples like images lie in a grid domain, but have\nlargely overlooked graph neural networks (GNNs) that handle non-grid data. In\nthis paper, we propose a novel scheme dedicated to overcoming catastrophic\nforgetting problem and hence strengthen continual learning in GNNs. At the\nheart of our approach is a generic module, termed as topology-aware weight\npreserving~(TWP), applicable to arbitrary form of GNNs in a plug-and-play\nfashion. Unlike the main stream of CNN-based continual learning methods that\nrely on solely slowing down the updates of parameters important to the\ndownstream task, TWP explicitly explores the local structures of the input\ngraph, and attempts to stabilize the parameters playing pivotal roles in the\ntopological aggregation. We evaluate TWP on different GNN backbones over\nseveral datasets, and demonstrate that it yields performances superior to the\nstate of the art. Code is publicly available at\n\\url{https://github.com/hhliu79/TWP}.\n", "versions": [{"version": "v1", "created": "Thu, 10 Dec 2020 22:30:25 GMT"}], "update_date": "2020-12-14", "authors_parsed": [["Liu", "Huihui", ""], ["Yang", "Yiding", ""], ["Wang", "Xinchao", ""]]}, {"id": "2012.06005", "submitter": "Taoan Huang", "authors": "Taoan Huang, Bistra Dilkina, Sven Koenig", "title": "Learning to Resolve Conflicts for Multi-Agent Path Finding with\n  Conflict-Based Search", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conflict-Based Search (CBS) is a state-of-the-art algorithm for multi-agent\npath finding. At the high level, CBS repeatedly detects conflicts and resolves\none of them by splitting the current problem into two subproblems. Previous\nwork chooses the conflict to resolve by categorizing the conflict into three\nclasses and always picking a conflict from the highest-priority class. In this\nwork, we propose an oracle for conflict selection that results in smaller\nsearch tree sizes than the one used in previous work. However, the computation\nof the oracle is slow. Thus, we propose a machine-learning framework for\nconflict selection that observes the decisions made by the oracle and learns a\nconflict-selection strategy represented by a linear ranking function that\nimitates the oracle's decisions accurately and quickly. Experiments on\nbenchmark maps indicate that our method significantly improves the success\nrates, the search tree sizes and runtimes over the current state-of-the-art CBS\nsolver.\n", "versions": [{"version": "v1", "created": "Thu, 10 Dec 2020 22:44:35 GMT"}], "update_date": "2020-12-14", "authors_parsed": [["Huang", "Taoan", ""], ["Dilkina", "Bistra", ""], ["Koenig", "Sven", ""]]}, {"id": "2012.06006", "submitter": "Christian Bartelt", "authors": "Christiann Bartelt and Sascha Marton and Heiner Stuckenschmidt", "title": "xRAI: Explainable Representations through AI", "comments": "8 pages, 6 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We present xRAI an approach for extracting symbolic representations of the\nmathematical function a neural network was supposed to learn from the trained\nnetwork. The approach is based on the idea of training a so-called\ninterpretation network that receives the weights and biases of the trained\nnetwork as input and outputs the numerical representation of the function the\nnetwork was supposed to learn that can be directly translated into a symbolic\nrepresentation. We show that interpretation nets for different classes of\nfunctions can be trained on synthetic data offline using Boolean functions and\nlow-order polynomials as examples. We show that the training is rather\nefficient and the quality of the results are promising. Our work aims to\nprovide a contribution to the problem of better understanding neural decision\nmaking by making the target function explicit\n", "versions": [{"version": "v1", "created": "Thu, 10 Dec 2020 22:49:29 GMT"}], "update_date": "2020-12-14", "authors_parsed": [["Bartelt", "Christiann", ""], ["Marton", "Sascha", ""], ["Stuckenschmidt", "Heiner", ""]]}, {"id": "2012.06008", "submitter": "Liang Han", "authors": "Liang Han, Zhaozheng Yin, Zhurong Xia, Mingqian Tang, Rong Jin", "title": "Price Suggestion for Online Second-hand Items with Texts and Images", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents an intelligent price suggestion system for online\nsecond-hand listings based on their uploaded images and text descriptions. The\ngoal of price prediction is to help sellers set effective and reasonable prices\nfor their second-hand items with the images and text descriptions uploaded to\nthe online platforms. Specifically, we design a multi-modal price suggestion\nsystem which takes as input the extracted visual and textual features along\nwith some statistical item features collected from the second-hand item\nshopping platform to determine whether the image and text of an uploaded\nsecond-hand item are qualified for reasonable price suggestion with a binary\nclassification model, and provide price suggestions for second-hand items with\nqualified images and text descriptions with a regression model. To satisfy\ndifferent demands, two different constraints are added into the joint training\nof the classification model and the regression model. Moreover, a customized\nloss function is designed for optimizing the regression model to provide price\nsuggestions for second-hand items, which can not only maximize the gain of the\nsellers but also facilitate the online transaction. We also derive a set of\nmetrics to better evaluate the proposed price suggestion system. Extensive\nexperiments on a large real-world dataset demonstrate the effectiveness of the\nproposed multi-modal price suggestion system.\n", "versions": [{"version": "v1", "created": "Thu, 10 Dec 2020 22:50:42 GMT"}], "update_date": "2020-12-14", "authors_parsed": [["Han", "Liang", ""], ["Yin", "Zhaozheng", ""], ["Xia", "Zhurong", ""], ["Tang", "Mingqian", ""], ["Jin", "Rong", ""]]}, {"id": "2012.06009", "submitter": "Liang Han", "authors": "Liang Han, Zhaozheng Yin, Zhurong Xia, Li Guo, Mingqian Tang, Rong Jin", "title": "Vision-based Price Suggestion for Online Second-hand Items", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Different from shopping in physical stores, where people have the opportunity\nto closely check a product (e.g., touching the surface of a T-shirt or smelling\nthe scent of perfume) before making a purchase decision, online shoppers rely\ngreatly on the uploaded product images to make any purchase decision. The\ndecision-making is challenging when selling or purchasing second-hand items\nonline since estimating the items' prices is not trivial. In this work, we\npresent a vision-based price suggestion system for the online second-hand item\nshopping platform. The goal of vision-based price suggestion is to help sellers\nset effective prices for their second-hand listings with the images uploaded to\nthe online platforms.\n  First, we propose to better extract representative visual features from the\nimages with the aid of some other image-based item information (e.g., category,\nbrand). Then, we design a vision-based price suggestion module which takes the\nextracted visual features along with some statistical item features from the\nshopping platform as the inputs to determine whether an uploaded item image is\nqualified for price suggestion by a binary classification model, and provide\nprice suggestions for items with qualified images by a regression model.\nAccording to two demands from the platform, two different objective functions\nare proposed to jointly optimize the classification model and the regression\nmodel. For better model training, we also propose a warm-up training strategy\nfor the joint optimization. Extensive experiments on a large real-world dataset\ndemonstrate the effectiveness of our vision-based price prediction system.\n", "versions": [{"version": "v1", "created": "Thu, 10 Dec 2020 22:56:29 GMT"}], "update_date": "2020-12-14", "authors_parsed": [["Han", "Liang", ""], ["Yin", "Zhaozheng", ""], ["Xia", "Zhurong", ""], ["Guo", "Li", ""], ["Tang", "Mingqian", ""], ["Jin", "Rong", ""]]}, {"id": "2012.06023", "submitter": "Jinwook Huh", "authors": "Jinwook Huh, Volkan Isler, and Daniel D. Lee", "title": "Cost-to-Go Function Generating Networks for High Dimensional Motion\n  Planning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents c2g-HOF networks which learn to generate cost-to-go\nfunctions for manipulator motion planning. The c2g-HOF architecture consists of\na cost-to-go function over the configuration space represented as a neural\nnetwork (c2g-network) as well as a Higher Order Function (HOF) network which\noutputs the weights of the c2g-network for a given input workspace. Both\nnetworks are trained end-to-end in a supervised fashion using costs computed\nfrom traditional motion planners. Once trained, c2g-HOF can generate a smooth\nand continuous cost-to-go function directly from workspace sensor inputs\n(represented as a point cloud in 3D or an image in 2D). At inference time, the\nweights of the c2g-network are computed very efficiently and near-optimal\ntrajectories are generated by simply following the gradient of the cost-to-go\nfunction. We compare c2g-HOF with traditional planning algorithms for various\nrobots and planning scenarios. The experimental results indicate that planning\nwith c2g-HOF is significantly faster than other motion planning algorithms,\nresulting in orders of magnitude improvement when including collision checking.\nFurthermore, despite being trained from sparsely sampled trajectories in\nconfiguration space, c2g-HOF generalizes to generate smoother, and often lower\ncost, trajectories. We demonstrate cost-to-go based planning on a 7 DoF\nmanipulator arm where motion planning in a complex workspace requires only 0.13\nseconds for the entire trajectory.\n", "versions": [{"version": "v1", "created": "Thu, 10 Dec 2020 23:38:53 GMT"}], "update_date": "2020-12-14", "authors_parsed": [["Huh", "Jinwook", ""], ["Isler", "Volkan", ""], ["Lee", "Daniel D.", ""]]}, {"id": "2012.06024", "submitter": "Kenneth Co", "authors": "Alberto G. Matachana, Kenneth T. Co, Luis Mu\\~noz-Gonz\\'alez, David\n  Martinez, Emil C. Lupu", "title": "Robustness and Transferability of Universal Attacks on Compressed Models", "comments": "Accepted to AAAI 2021 Workshop: Towards Robust, Secure and Efficient\n  Machine Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Neural network compression methods like pruning and quantization are very\neffective at efficiently deploying Deep Neural Networks (DNNs) on edge devices.\nHowever, DNNs remain vulnerable to adversarial examples-inconspicuous inputs\nthat are specifically designed to fool these models. In particular, Universal\nAdversarial Perturbations (UAPs), are a powerful class of adversarial attacks\nwhich create adversarial perturbations that can generalize across a large set\nof inputs. In this work, we analyze the effect of various compression\ntechniques to UAP attacks, including different forms of pruning and\nquantization. We test the robustness of compressed models to white-box and\ntransfer attacks, comparing them with their uncompressed counterparts on\nCIFAR-10 and SVHN datasets. Our evaluations reveal clear differences between\npruning methods, including Soft Filter and Post-training Pruning. We observe\nthat UAP transfer attacks between pruned and full models are limited,\nsuggesting that the systemic vulnerabilities across these models are different.\nThis finding has practical implications as using different compression\ntechniques can blunt the effectiveness of black-box transfer attacks. We show\nthat, in some scenarios, quantization can produce gradient-masking, giving a\nfalse sense of security. Finally, our results suggest that conclusions about\nthe robustness of compressed models to UAP attacks is application dependent,\nobserving different phenomena in the two datasets used in our experiments.\n", "versions": [{"version": "v1", "created": "Thu, 10 Dec 2020 23:40:23 GMT"}], "update_date": "2020-12-14", "authors_parsed": [["Matachana", "Alberto G.", ""], ["Co", "Kenneth T.", ""], ["Mu\u00f1oz-Gonz\u00e1lez", "Luis", ""], ["Martinez", "David", ""], ["Lupu", "Emil C.", ""]]}, {"id": "2012.06031", "submitter": "Nancy Iskander", "authors": "Nancy Iskander, Aurelien Simoni, Eloi Alonso, Maxim Peter", "title": "Reinforcement Learning Agents for Ubisoft's Roller Champions", "comments": "Accepted to the NeurIPS 2020 Challenges of Real-World RL workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  In recent years, Reinforcement Learning (RL) has seen increasing popularity\nin research and popular culture. However, skepticism still surrounds the\npracticality of RL in modern video game development. In this paper, we\ndemonstrate by example that RL can be a great tool for Artificial Intelligence\n(AI) design in modern, non-trivial video games. We present our RL system for\nUbisoft's Roller Champions, a 3v3 Competitive Multiplayer Sports Game played on\nan oval-shaped skating arena. Our system is designed to keep up with agile,\nfast-paced development, taking 1--4 days to train a new model following\ngameplay changes. The AIs are adapted for various game modes, including a 2v2\nmode, a Training with Bots mode, in addition to the Classic game mode where\nthey replace players who have disconnected. We observe that the AIs develop\nsophisticated co-ordinated strategies, and can aid in balancing the game as an\nadded bonus. Please see the accompanying video at https://vimeo.com/466780171\n(password: rollerRWRL2020) for examples.\n", "versions": [{"version": "v1", "created": "Thu, 10 Dec 2020 23:53:15 GMT"}], "update_date": "2020-12-14", "authors_parsed": [["Iskander", "Nancy", ""], ["Simoni", "Aurelien", ""], ["Alonso", "Eloi", ""], ["Peter", "Maxim", ""]]}, {"id": "2012.06034", "submitter": "Elisa Bertino", "authors": "Elisa Bertino, Finale Doshi-Velez, Maria Gini, Daniel Lopresti, and\n  David Parkes", "title": "Artificial Intelligence & Cooperation", "comments": "A Computing Community Consortium (CCC) white paper, 4 pages", "journal-ref": null, "doi": null, "report-no": "ccc2020whitepaper_4", "categories": "cs.CY cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The rise of Artificial Intelligence (AI) will bring with it an\never-increasing willingness to cede decision-making to machines. But rather\nthan just giving machines the power to make decisions that affect us, we need\nways to work cooperatively with AI systems. There is a vital need for research\nin \"AI and Cooperation\" that seeks to understand the ways in which systems of\nAIs and systems of AIs with people can engender cooperative behavior. Trust in\nAI is also key: trust that is intrinsic and trust that can only be earned over\ntime. Here we use the term \"AI\" in its broadest sense, as employed by the\nrecent 20-Year Community Roadmap for AI Research (Gil and Selman, 2019),\nincluding but certainly not limited to, recent advances in deep learning.\n  With success, cooperation between humans and AIs can build society just as\nhuman-human cooperation has. Whether coming from an intrinsic willingness to be\nhelpful, or driven through self-interest, human societies have grown strong and\nthe human species has found success through cooperation. We cooperate \"in the\nsmall\" -- as family units, with neighbors, with co-workers, with strangers --\nand \"in the large\" as a global community that seeks cooperative outcomes around\nquestions of commerce, climate change, and disarmament. Cooperation has evolved\nin nature also, in cells and among animals. While many cases involving\ncooperation between humans and AIs will be asymmetric, with the human\nultimately in control, AI systems are growing so complex that, even today, it\nis impossible for the human to fully comprehend their reasoning,\nrecommendations, and actions when functioning simply as passive observers.\n", "versions": [{"version": "v1", "created": "Thu, 10 Dec 2020 23:54:31 GMT"}], "update_date": "2020-12-14", "authors_parsed": [["Bertino", "Elisa", ""], ["Doshi-Velez", "Finale", ""], ["Gini", "Maria", ""], ["Lopresti", "Daniel", ""], ["Parkes", "David", ""]]}, {"id": "2012.06043", "submitter": "Ang Li", "authors": "Jingwei Sun, Ang Li, Binghui Wang, Huanrui Yang, Hai Li, Yiran Chen", "title": "Provable Defense against Privacy Leakage in Federated Learning from\n  Representation Perspective", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated learning (FL) is a popular distributed learning framework that can\nreduce privacy risks by not explicitly sharing private data. However, recent\nworks demonstrated that sharing model updates makes FL vulnerable to inference\nattacks. In this work, we show our key observation that the data representation\nleakage from gradients is the essential cause of privacy leakage in FL. We also\nprovide an analysis of this observation to explain how the data presentation is\nleaked. Based on this observation, we propose a defense against model inversion\nattack in FL. The key idea of our defense is learning to perturb data\nrepresentation such that the quality of the reconstructed data is severely\ndegraded, while FL performance is maintained. In addition, we derive certified\nrobustness guarantee to FL and convergence guarantee to FedAvg, after applying\nour defense. To evaluate our defense, we conduct experiments on MNIST and\nCIFAR10 for defending against the DLG attack and GS attack. Without sacrificing\naccuracy, the results demonstrate that our proposed defense can increase the\nmean squared error between the reconstructed data and the raw data by as much\nas more than 160X for both DLG attack and GS attack, compared with baseline\ndefense methods. The privacy of the FL system is significantly improved.\n", "versions": [{"version": "v1", "created": "Tue, 8 Dec 2020 20:42:12 GMT"}], "update_date": "2020-12-14", "authors_parsed": [["Sun", "Jingwei", ""], ["Li", "Ang", ""], ["Wang", "Binghui", ""], ["Yang", "Huanrui", ""], ["Li", "Hai", ""], ["Chen", "Yiran", ""]]}, {"id": "2012.06046", "submitter": "Benedikt Boecking", "authors": "Benedikt Boecking, Willie Neiswanger, Eric Xing, Artur Dubrawski", "title": "Interactive Weak Supervision: Learning Useful Heuristics for Data\n  Labeling", "comments": "Accepted as a conference paper at ICLR 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Obtaining large annotated datasets is critical for training successful\nmachine learning models and it is often a bottleneck in practice. Weak\nsupervision offers a promising alternative for producing labeled datasets\nwithout ground truth annotations by generating probabilistic labels using\nmultiple noisy heuristics. This process can scale to large datasets and has\ndemonstrated state of the art performance in diverse domains such as healthcare\nand e-commerce. One practical issue with learning from user-generated\nheuristics is that their creation requires creativity, foresight, and domain\nexpertise from those who hand-craft them, a process which can be tedious and\nsubjective. We develop the first framework for interactive weak supervision in\nwhich a method proposes heuristics and learns from user feedback given on each\nproposed heuristic. Our experiments demonstrate that only a small number of\nfeedback iterations are needed to train models that achieve highly competitive\ntest set performance without access to ground truth training labels. We conduct\nuser studies, which show that users are able to effectively provide feedback on\nheuristics and that test set results track the performance of simulated\noracles.\n", "versions": [{"version": "v1", "created": "Fri, 11 Dec 2020 00:10:38 GMT"}, {"version": "v2", "created": "Mon, 25 Jan 2021 20:03:15 GMT"}], "update_date": "2021-01-27", "authors_parsed": [["Boecking", "Benedikt", ""], ["Neiswanger", "Willie", ""], ["Xing", "Eric", ""], ["Dubrawski", "Artur", ""]]}, {"id": "2012.06047", "submitter": "Jiaye Li", "authors": "Shichao Zhang and Jiaye Li", "title": "KNN Classification with One-step Computation", "comments": "13 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  KNN classification is a query triggered yet improvisational learning mode, in\nwhich they are carried out only when a test data is predicted that set a\nsuitable K value and search the K nearest neighbors from the whole training\nsample space, referred them to the lazy part of KNN classification. This lazy\npart has been the bottleneck problem of applying KNN classification. In this\npaper, a one-step computation is proposed to replace the lazy part of KNN\nclassification. The one-step computation actually transforms the lazy part to a\nmatrix computation as follows. Given a test data, training samples are first\napplied to fit the test data with the least squares loss function. And then, a\nrelationship matrix is generated by weighting all training samples according to\ntheir influence on the test data. Finally, a group lasso is employed to perform\nsparse learning of the relationship matrix. In this way, setting K value and\nsearching K nearest neighbors are both integrated to a unified computation. In\naddition, a new classification rule is proposed for improving the performance\nof one-step KNN classification. The proposed approach is experimentally\nevaluated, and demonstrated that the one-step KNN classification is efficient\nand promising.\n", "versions": [{"version": "v1", "created": "Wed, 9 Dec 2020 13:34:42 GMT"}], "update_date": "2020-12-14", "authors_parsed": [["Zhang", "Shichao", ""], ["Li", "Jiaye", ""]]}, {"id": "2012.06049", "submitter": "Ian Foster", "authors": "Ian Foster, David Parkes, and Stephan Zheng", "title": "The Rise of AI-Driven Simulators: Building a New Crystal Ball", "comments": "A Computing Community Consortium (CCC) white paper, 4 pages", "journal-ref": null, "doi": null, "report-no": "ccc2020whitepaper_6", "categories": "cs.CY cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The use of computational simulation is by now so pervasive in society that it\nis no exaggeration to say that continued U.S. and international prosperity,\nsecurity, and health depend in part on continued improvements in simulation\ncapabilities. What if we could predict weather two weeks out, guide the design\nof new drugs for new viral diseases, or manage new manufacturing processes that\ncut production costs and times by an order of magnitude? What if we could\npredict collective human behavior, for example, response to an evacuation\nrequest during a natural disaster, or labor response to fiscal stimulus? (See\nalso the companion CCC Quad Paper on Pandemic Informatics, which discusses\nfeatures that would be essential to solving large-scale problems like\npreparation for, and response to, the inevitable next pandemic.)\n  The past decade has brought remarkable advances in complementary areas: in\nsensors, which can now capture enormous amounts of data about the world, and in\nAI methods capable of learning to extract predictive patterns from those data.\nThese advances may lead to a new era in computational simulation, in which\nsensors of many kinds are used to produce vast quantities of data, AI methods\nidentify patterns in those data, and new AI-driven simulators combine\nmachine-learned and mathematical rules to make accurate and actionable\npredictions. At the same time, there are new challenges -- computers in some\nimportant regards are no longer getting faster, and in some areas we are\nreaching the limits of mathematical understanding, or at least of our ability\nto translate mathematical understanding into efficient simulation. In this\npaper, we lay out some themes that we envision forming part of a cohesive,\nmulti-disciplinary, and application-inspired research agenda on AI-driven\nsimulators.\n", "versions": [{"version": "v1", "created": "Fri, 11 Dec 2020 00:13:40 GMT"}], "update_date": "2020-12-14", "authors_parsed": [["Foster", "Ian", ""], ["Parkes", "David", ""], ["Zheng", "Stephan", ""]]}, {"id": "2012.06052", "submitter": "Zhenhao Gu", "authors": "Yang Yu, Zhenhao Gu, Rong Tao, Jingtian Ge, Kenglun Chang", "title": "Interactive Search Based on Deep Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  With the continuous development of machine learning technology, major\ne-commerce platforms have launched recommendation systems based on it to serve\na large number of customers with different needs more efficiently. Compared\nwith traditional supervised learning, reinforcement learning can better capture\nthe user's state transition in the decision-making process, and consider a\nseries of user actions, not just the static characteristics of the user at a\ncertain moment. In theory, it will have a long-term perspective, producing a\nmore effective recommendation. The special requirements of reinforcement\nlearning for data make it need to rely on an offline virtual system for\ntraining. Our project mainly establishes a virtual user environment for offline\ntraining. At the same time, we tried to improve a reinforcement learning\nalgorithm based on bi-clustering to expand the action space and recommended\npath space of the recommendation agent.\n", "versions": [{"version": "v1", "created": "Wed, 9 Dec 2020 15:23:53 GMT"}], "update_date": "2020-12-14", "authors_parsed": [["Yu", "Yang", ""], ["Gu", "Zhenhao", ""], ["Tao", "Rong", ""], ["Ge", "Jingtian", ""], ["Chang", "Kenglun", ""]]}, {"id": "2012.06057", "submitter": "Suresh Venkatasubramanian", "authors": "Suresh Venkatasubramanian, Nadya Bliss, Helen Nissenbaum, and Melanie\n  Moses", "title": "Interdisciplinary Approaches to Understanding Artificial Intelligence's\n  Impact on Society", "comments": "A Computing Community Consortium (CCC) white paper, 5 pages", "journal-ref": null, "doi": null, "report-no": "ccc2020whitepaper_5", "categories": "cs.CY cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Innovations in AI have focused primarily on the questions of \"what\" and\n\"how\"-algorithms for finding patterns in web searches, for instance-without\nadequate attention to the possible harms (such as privacy, bias, or\nmanipulation) and without adequate consideration of the societal context in\nwhich these systems operate. In part, this is driven by incentives and forces\nin the tech industry, where a more product-driven focus tends to drown out\nbroader reflective concerns about potential harms and misframings. But this\nfocus on what and how is largely a reflection of the engineering and\nmathematics-focused training in computer science, which emphasizes the building\nof tools and development of computational concepts.\n  As a result of this tight technical focus, and the rapid, worldwide explosion\nin its use, AI has come with a storm of unanticipated socio-technical problems,\nranging from algorithms that act in racially or gender-biased ways, get caught\nin feedback loops that perpetuate inequalities, or enable unprecedented\nbehavioral monitoring surveillance that challenges the fundamental values of\nfree, democratic societies.\n  Given that AI is no longer solely the domain of technologists but rather of\nsociety as a whole, we need tighter coupling of computer science and those\ndisciplines that study society and societal values.\n", "versions": [{"version": "v1", "created": "Fri, 11 Dec 2020 00:43:47 GMT"}], "update_date": "2020-12-14", "authors_parsed": [["Venkatasubramanian", "Suresh", ""], ["Bliss", "Nadya", ""], ["Nissenbaum", "Helen", ""], ["Moses", "Melanie", ""]]}, {"id": "2012.06058", "submitter": "Odest Chadwicke Jenkins", "authors": "Odest Chadwicke Jenkins, Daniel Lopresti, and Melanie Mitchell", "title": "Next Wave Artificial Intelligence: Robust, Explainable, Adaptable,\n  Ethical, and Accountable", "comments": "A Computing Community Consortium (CCC) white paper, 5 pages", "journal-ref": null, "doi": null, "report-no": "ccc2020whitepaper_7", "categories": "cs.CY cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The history of AI has included several \"waves\" of ideas. The first wave, from\nthe mid-1950s to the 1980s, focused on logic and symbolic hand-encoded\nrepresentations of knowledge, the foundations of so-called \"expert systems\".\nThe second wave, starting in the 1990s, focused on statistics and machine\nlearning, in which, instead of hand-programming rules for behavior, programmers\nconstructed \"statistical learning algorithms\" that could be trained on large\ndatasets. In the most recent wave research in AI has largely focused on deep\n(i.e., many-layered) neural networks, which are loosely inspired by the brain\nand trained by \"deep learning\" methods. However, while deep neural networks\nhave led to many successes and new capabilities in computer vision, speech\nrecognition, language processing, game-playing, and robotics, their potential\nfor broad application remains limited by several factors.\n  A concerning limitation is that even the most successful of today's AI\nsystems suffer from brittleness-they can fail in unexpected ways when faced\nwith situations that differ sufficiently from ones they have been trained on.\nThis lack of robustness also appears in the vulnerability of AI systems to\nadversarial attacks, in which an adversary can subtly manipulate data in a way\nto guarantee a specific wrong answer or action from an AI system. AI systems\nalso can absorb biases-based on gender, race, or other factors-from their\ntraining data and further magnify these biases in their subsequent\ndecision-making. Taken together, these various limitations have prevented AI\nsystems such as automatic medical diagnosis or autonomous vehicles from being\nsufficiently trustworthy for wide deployment. The massive proliferation of AI\nacross society will require radically new ideas to yield technology that will\nnot sacrifice our productivity, our quality of life, or our values.\n", "versions": [{"version": "v1", "created": "Fri, 11 Dec 2020 00:50:09 GMT"}], "update_date": "2020-12-14", "authors_parsed": [["Jenkins", "Odest Chadwicke", ""], ["Lopresti", "Daniel", ""], ["Mitchell", "Melanie", ""]]}, {"id": "2012.06060", "submitter": "Frederic Zhang", "authors": "Frederic Z. Zhang, Dylan Campbell, Stephen Gould", "title": "Spatially Conditioned Graphs for Detecting Human-Object Interactions", "comments": "12 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the problem of detecting human-object interactions in images using\ngraphical neural networks. Unlike conventional methods, where nodes send scaled\nbut otherwise identical messages to each of their neighbours, we propose to\ncondition messages between pairs of nodes on their spatial relationships,\nresulting in different messages going to neighbours of the same node. To this\nend, we explore various ways of applying spatial conditioning under a\nmulti-branch structure. Through extensive experimentation we demonstrate the\nadvantages of spatial conditioning for the computation of the adjacency\nstructure, messages and the refined graph features. In particular, we\nempirically show that as the quality of the bounding boxes increases, their\ncoarse appearance features contribute relatively less to the disambiguation of\ninteractions compared to the spatial information. Our method achieves an mAP of\n31.33% on HICO-DET and 54.2% on V-COCO, significantly outperforming\nstate-of-the-art on fine-tuned detections.\n", "versions": [{"version": "v1", "created": "Fri, 11 Dec 2020 00:55:47 GMT"}, {"version": "v2", "created": "Wed, 31 Mar 2021 05:34:25 GMT"}], "update_date": "2021-04-01", "authors_parsed": [["Zhang", "Frederic Z.", ""], ["Campbell", "Dylan", ""], ["Gould", "Stephen", ""]]}, {"id": "2012.06070", "submitter": "Shaojie Tang", "authors": "Shaojie Tang, Jing Yuan", "title": "Adaptive Submodular Meta-Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Meta-Learning has gained increasing attention in the machine learning and\nartificial intelligence communities. In this paper, we introduce and study an\nadaptive submodular meta-learning problem. The input of our problem is a set of\nitems, where each item has a random state which is initially unknown. The only\nway to observe an item's state is to select that item. Our objective is to\nadaptively select a group of items that achieve the best performance over a set\nof tasks, where each task is represented as an adaptive submodular function\nthat maps sets of items and their states to a real number. To reduce the\ncomputational cost while maintaining a personalized solution for each future\ntask, we first select an initial solution set based on previously observed\ntasks, then adaptively add the remaining items to the initial solution set when\na new task arrives. As compared to the solution where a brand new solution is\ncomputed for each new task, our meta-learning based approach leads to lower\ncomputational overhead at test time since the initial solution set is\npre-computed in the training stage. To solve this problem, we propose a\ntwo-phase greedy policy and show that it achieves a $1/2$ approximation ratio\nfor the monotone case. For the non-monotone case, we develop a two-phase\nrandomized greedy policy that achieves a $1/32$ approximation ratio.\n", "versions": [{"version": "v1", "created": "Fri, 11 Dec 2020 01:28:55 GMT"}, {"version": "v2", "created": "Thu, 25 Mar 2021 14:31:48 GMT"}], "update_date": "2021-03-26", "authors_parsed": [["Tang", "Shaojie", ""], ["Yuan", "Jing", ""]]}, {"id": "2012.06117", "submitter": "Erik Wijmans", "authors": "Erik Wijmans and Irfan Essa and Dhruv Batra", "title": "How to Train PointGoal Navigation Agents on a (Sample and Compute)\n  Budget", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  PointGoal navigation has seen significant recent interest and progress,\nspurred on by the Habitat platform and associated challenge. In this paper, we\nstudy PointGoal navigation under both a sample budget (75 million frames) and a\ncompute budget (1 GPU for 1 day). We conduct an extensive set of experiments,\ncumulatively totaling over 50,000 GPU-hours, that let us identify and discuss a\nnumber of ostensibly minor but significant design choices -- the advantage\nestimation procedure (a key component in training), visual encoder\narchitecture, and a seemingly minor hyper-parameter change. Overall, these\ndesign choices to lead considerable and consistent improvements over the\nbaselines present in Savva et al. Under a sample budget, performance for RGB-D\nagents improves 8 SPL on Gibson (14% relative improvement) and 20 SPL on\nMatterport3D (38% relative improvement). Under a compute budget, performance\nfor RGB-D agents improves by 19 SPL on Gibson (32% relative improvement) and 35\nSPL on Matterport3D (220% relative improvement). We hope our findings and\nrecommendations will make serve to make the community's experiments more\nefficient.\n", "versions": [{"version": "v1", "created": "Fri, 11 Dec 2020 04:28:48 GMT"}], "update_date": "2020-12-14", "authors_parsed": [["Wijmans", "Erik", ""], ["Essa", "Irfan", ""], ["Batra", "Dhruv", ""]]}, {"id": "2012.06136", "submitter": "Beibin Li", "authors": "Beibin Li, Ezgi Mercan, Sachin Mehta, Stevan Knezevich, Corey W.\n  Arnold, Donald L. Weaver, Joann G. Elmore, Linda G. Shapiro", "title": "Classifying Breast Histopathology Images with a Ductal Instance-Oriented\n  Pipeline", "comments": "ICPR 2020. Submitted July 15th, 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this study, we propose the Ductal Instance-Oriented Pipeline (DIOP) that\ncontains a duct-level instance segmentation model, a tissue-level semantic\nsegmentation model, and three-levels of features for diagnostic classification.\nBased on recent advancements in instance segmentation and the Mask R-CNN model,\nour duct-level segmenter tries to identify each ductal individual inside a\nmicroscopic image; then, it extracts tissue-level information from the\nidentified ductal instances. Leveraging three levels of information obtained\nfrom these ductal instances and also the histopathology image, the proposed\nDIOP outperforms previous approaches (both feature-based and CNN-based) in all\ndiagnostic tasks; for the four-way classification task, the DIOP achieves\ncomparable performance to general pathologists in this unique dataset. The\nproposed DIOP only takes a few seconds to run in the inference time, which\ncould be used interactively on most modern computers. More clinical\nexplorations are needed to study the robustness and generalizability of this\nsystem in the future.\n", "versions": [{"version": "v1", "created": "Fri, 11 Dec 2020 05:43:12 GMT"}], "update_date": "2020-12-14", "authors_parsed": [["Li", "Beibin", ""], ["Mercan", "Ezgi", ""], ["Mehta", "Sachin", ""], ["Knezevich", "Stevan", ""], ["Arnold", "Corey W.", ""], ["Weaver", "Donald L.", ""], ["Elmore", "Joann G.", ""], ["Shapiro", "Linda G.", ""]]}, {"id": "2012.06138", "submitter": "Rei Sato", "authors": "Rei Sato, Jun Sakuma, Youhei Akimoto", "title": "AdvantageNAS: Efficient Neural Architecture Search with Credit\n  Assignment", "comments": "The Thirty-Fifth AAAI Conference on Artificial Intelligence (AAAI-21)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural architecture search (NAS) is an approach for automatically designing a\nneural network architecture without human effort or expert knowledge. However,\nthe high computational cost of NAS limits its use in commercial applications.\nTwo recent NAS paradigms, namely one-shot and sparse propagation, which reduce\nthe time and space complexities, respectively, provide clues for solving this\nproblem. In this paper, we propose a novel search strategy for one-shot and\nsparse propagation NAS, namely AdvantageNAS, which further reduces the time\ncomplexity of NAS by reducing the number of search iterations. AdvantageNAS is\na gradient-based approach that improves the search efficiency by introducing\ncredit assignment in gradient estimation for architecture updates. Experiments\non the NAS-Bench-201 and PTB dataset show that AdvantageNAS discovers an\narchitecture with higher performance under a limited time budget compared to\nexisting sparse propagation NAS. To further reveal the reliabilities of\nAdvantageNAS, we investigate it theoretically and find that it monotonically\nimproves the expected loss and thus converges.\n", "versions": [{"version": "v1", "created": "Fri, 11 Dec 2020 05:45:03 GMT"}, {"version": "v2", "created": "Wed, 10 Mar 2021 03:02:38 GMT"}], "update_date": "2021-03-11", "authors_parsed": [["Sato", "Rei", ""], ["Sakuma", "Jun", ""], ["Akimoto", "Youhei", ""]]}, {"id": "2012.06146", "submitter": "Jie Gu", "authors": "Jie Gu, Feng Wang, Qinghui Sun, Zhiquan Ye, Xiaoxiao Xu, Jingmin Chen,\n  Jun Zhang", "title": "Exploiting Behavioral Consistence for Universal User Representation", "comments": "Preprint of accepted AAAI2021 paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  User modeling is critical for developing personalized services in industry. A\ncommon way for user modeling is to learn user representations that can be\ndistinguished by their interests or preferences. In this work, we focus on\ndeveloping universal user representation model. The obtained universal\nrepresentations are expected to contain rich information, and be applicable to\nvarious downstream applications without further modifications (e.g., user\npreference prediction and user profiling). Accordingly, we can be free from the\nheavy work of training task-specific models for every downstream task as in\nprevious works. In specific, we propose Self-supervised User Modeling Network\n(SUMN) to encode behavior data into the universal representation. It includes\ntwo key components. The first one is a new learning objective, which guides the\nmodel to fully identify and preserve valuable user information under a\nself-supervised learning framework. The other one is a multi-hop aggregation\nlayer, which benefits the model capacity in aggregating diverse behaviors.\nExtensive experiments on benchmark datasets show that our approach can\noutperform state-of-the-art unsupervised representation methods, and even\ncompete with supervised ones.\n", "versions": [{"version": "v1", "created": "Fri, 11 Dec 2020 06:10:14 GMT"}], "update_date": "2020-12-14", "authors_parsed": [["Gu", "Jie", ""], ["Wang", "Feng", ""], ["Sun", "Qinghui", ""], ["Ye", "Zhiquan", ""], ["Xu", "Xiaoxiao", ""], ["Chen", "Jingmin", ""], ["Zhang", "Jun", ""]]}, {"id": "2012.06148", "submitter": "Yuntian Chen", "authors": "Yuntian Chen, Dou Huang, Dongxiao Zhang, Junsheng Zeng, Nanzhe Wang,\n  Haoran Zhang, and Jinyue Yan", "title": "Theory-guided hard constraint projection (HCP): a knowledge-based\n  data-driven scientific machine learning method", "comments": "31 pages, 20 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning models have been successfully used in many scientific and\nengineering fields. However, it remains difficult for a model to simultaneously\nutilize domain knowledge and experimental observation data. The application of\nknowledge-based symbolic AI represented by an expert system is limited by the\nexpressive ability of the model, and data-driven connectionism AI represented\nby neural networks is prone to produce predictions that violate physical\nmechanisms. In order to fully integrate domain knowledge with observations, and\nmake full use of the prior information and the strong fitting ability of neural\nnetworks, this study proposes theory-guided hard constraint projection (HCP).\nThis model converts physical constraints, such as governing equations, into a\nform that is easy to handle through discretization, and then implements hard\nconstraint optimization through projection. Based on rigorous mathematical\nproofs, theory-guided HCP can ensure that model predictions strictly conform to\nphysical mechanisms in the constraint patch. The performance of the\ntheory-guided HCP is verified by experiments based on the heterogeneous\nsubsurface flow problem. Due to the application of hard constraints, compared\nwith fully connected neural networks and soft constraint models, such as\ntheory-guided neural networks and physics-informed neural networks,\ntheory-guided HCP requires fewer data, and achieves higher prediction accuracy\nand stronger robustness to noisy observations.\n", "versions": [{"version": "v1", "created": "Fri, 11 Dec 2020 06:17:43 GMT"}, {"version": "v2", "created": "Sat, 23 Jan 2021 14:52:50 GMT"}], "update_date": "2021-01-26", "authors_parsed": [["Chen", "Yuntian", ""], ["Huang", "Dou", ""], ["Zhang", "Dongxiao", ""], ["Zeng", "Junsheng", ""], ["Wang", "Nanzhe", ""], ["Zhang", "Haoran", ""], ["Yan", "Jinyue", ""]]}, {"id": "2012.06154", "submitter": "Daniel Khashabi Mr.", "authors": "Daniel Khashabi, Arman Cohan, Siamak Shakeri, Pedram Hosseini, Pouya\n  Pezeshkpour, Malihe Alikhani, Moin Aminnaseri, Marzieh Bitaab, Faeze Brahman,\n  Sarik Ghazarian, Mozhdeh Gheini, Arman Kabiri, Rabeeh Karimi Mahabadi, Omid\n  Memarrast, Ahmadreza Mosallanezhad, Erfan Noury, Shahab Raji, Mohammad Sadegh\n  Rasooli, Sepideh Sadeghi, Erfan Sadeqi Azer, Niloofar Safi Samghabadi, Mahsa\n  Shafaei, Saber Sheybani, Ali Tazarv, Yadollah Yaghoobzadeh", "title": "ParsiNLU: A Suite of Language Understanding Challenges for Persian", "comments": "To appear on Transactions of the Association for Computational\n  Linguistics (TACL), 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Despite the progress made in recent years in addressing natural language\nunderstanding (NLU) challenges, the majority of this progress remains to be\nconcentrated on resource-rich languages like English. This work focuses on\nPersian language, one of the widely spoken languages in the world, and yet\nthere are few NLU datasets available for this rich language. The availability\nof high-quality evaluation datasets is a necessity for reliable assessment of\nthe progress on different NLU tasks and domains. We introduce ParsiNLU, the\nfirst benchmark in Persian language that includes a range of high-level tasks\n-- Reading Comprehension, Textual Entailment, etc. These datasets are collected\nin a multitude of ways, often involving manual annotations by native speakers.\nThis results in over 14.5$k$ new instances across 6 distinct NLU tasks.\nBesides, we present the first results on state-of-the-art monolingual and\nmulti-lingual pre-trained language-models on this benchmark and compare them\nwith human performance, which provides valuable insights into our ability to\ntackle natural language understanding challenges in Persian. We hope ParsiNLU\nfosters further research and advances in Persian language understanding.\n", "versions": [{"version": "v1", "created": "Fri, 11 Dec 2020 06:31:42 GMT"}, {"version": "v2", "created": "Tue, 13 Jul 2021 17:02:32 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["Khashabi", "Daniel", ""], ["Cohan", "Arman", ""], ["Shakeri", "Siamak", ""], ["Hosseini", "Pedram", ""], ["Pezeshkpour", "Pouya", ""], ["Alikhani", "Malihe", ""], ["Aminnaseri", "Moin", ""], ["Bitaab", "Marzieh", ""], ["Brahman", "Faeze", ""], ["Ghazarian", "Sarik", ""], ["Gheini", "Mozhdeh", ""], ["Kabiri", "Arman", ""], ["Mahabadi", "Rabeeh Karimi", ""], ["Memarrast", "Omid", ""], ["Mosallanezhad", "Ahmadreza", ""], ["Noury", "Erfan", ""], ["Raji", "Shahab", ""], ["Rasooli", "Mohammad Sadegh", ""], ["Sadeghi", "Sepideh", ""], ["Azer", "Erfan Sadeqi", ""], ["Samghabadi", "Niloofar Safi", ""], ["Shafaei", "Mahsa", ""], ["Sheybani", "Saber", ""], ["Tazarv", "Ali", ""], ["Yaghoobzadeh", "Yadollah", ""]]}, {"id": "2012.06157", "submitter": "Rupam Acharyya", "authors": "Rupam Acharyya, Ankani Chattoraj, Shouman Das, Md. Iftekhar Tanveer,\n  Ehsan Hoque", "title": "Fairness in Rating Prediction by Awareness of Verbal and Gesture Quality\n  of Public Speeches", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  The role of verbal and non-verbal cues towards great public speaking has been\na topic of exploration for many decades. We identify a commonality across\npresent theories, the element of \"variety or heterogeneity\" in channels or\nmodes of communication (e.g. resorting to stories, scientific facts, emotional\nconnections, facial expressions etc.) which is essential for effectively\ncommunicating information. We use this observation to formalize a novel\nHEterogeneity Metric, HEM, that quantifies the quality of a talk both in the\nverbal and non-verbal domain (transcript and facial gestures). We use TED talks\nas an input repository of public speeches because it consists of speakers from\na diverse community besides having a wide outreach. We show that there is an\ninteresting relationship between HEM and the ratings of TED talks given to\nspeakers by viewers. It emphasizes that HEM inherently and successfully\nrepresents the quality of a talk based on \"variety or heterogeneity\". Further,\nwe also discover that HEM successfully captures the prevalent bias in ratings\nwith respect to race and gender, that we call sensitive attributes (because\nprediction based on these might result in unfair outcome). We incorporate the\nHEM metric into the loss function of a neural network with the goal to reduce\nunfairness in rating predictions with respect to race and gender. Our results\nshow that the modified loss function improves fairness in prediction without\nconsiderably affecting prediction accuracy of the neural network. Our work ties\ntogether a novel metric for public speeches in both verbal and non-verbal\ndomain with the computational power of a neural network to design a fair\nprediction system for speakers.\n", "versions": [{"version": "v1", "created": "Fri, 11 Dec 2020 06:36:55 GMT"}, {"version": "v2", "created": "Wed, 16 Dec 2020 20:48:35 GMT"}], "update_date": "2020-12-18", "authors_parsed": [["Acharyya", "Rupam", ""], ["Chattoraj", "Ankani", ""], ["Das", "Shouman", ""], ["Tanveer", "Md. Iftekhar", ""], ["Hoque", "Ehsan", ""]]}, {"id": "2012.06161", "submitter": "Nikhil Prakash", "authors": "Nikhil Prakash and Kory W. Mathewson", "title": "Conceptualization and Framework of Hybrid Intelligence Systems", "comments": "8 pages, 1 figure, HAMLETS (Human And Machine in-the-Loop Evaluation\n  and Learning Strategies) workshop at Thirty-fourth Conference on Neural\n  Information Processing Systems", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As artificial intelligence (AI) systems are getting ubiquitous within our\nsociety, issues related to its fairness, accountability, and transparency are\nincreasing rapidly. As a result, researchers are integrating humans with AI\nsystems to build robust and reliable hybrid intelligence systems. However, a\nproper conceptualization of these systems does not underpin this rapid growth.\nThis article provides a precise definition of hybrid intelligence systems as\nwell as explains its relation with other similar concepts through our proposed\nframework and examples from contemporary literature. The framework breakdowns\nthe relationship between a human and a machine in terms of the degree of\ncoupling and the directive authority of each party. Finally, we argue that all\nAI systems are hybrid intelligence systems, so human factors need to be\nexamined at every stage of such systems' lifecycle.\n", "versions": [{"version": "v1", "created": "Fri, 11 Dec 2020 06:42:06 GMT"}], "update_date": "2020-12-14", "authors_parsed": [["Prakash", "Nikhil", ""], ["Mathewson", "Kory W.", ""]]}, {"id": "2012.06168", "submitter": "Kai Li", "authors": "Kai Li, Hang Xu, Meng Zhang, Enmin Zhao, Zhe Wu, Junliang Xing, Kaiqi\n  Huang", "title": "OpenHoldem: An Open Toolkit for Large-Scale Imperfect-Information Game\n  Research", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Owning to the unremitting efforts by a few institutes, significant progress\nhas recently been made in designing superhuman AIs in No-limit Texas Hold'em\n(NLTH), the primary testbed for large-scale imperfect-information game\nresearch. However, it remains challenging for new researchers to study this\nproblem since there are no standard benchmarks for comparing with existing\nmethods, which seriously hinders further developments in this research area. In\nthis work, we present OpenHoldem, an integrated toolkit for large-scale\nimperfect-information game research using NLTH. OpenHoldem makes three main\ncontributions to this research direction: 1) a standardized evaluation protocol\nfor thoroughly evaluating different NLTH AIs, 2) three publicly available\nstrong baselines for NLTH AI, and 3) an online testing platform with\neasy-to-use APIs for public NLTH AI evaluation. We have released OpenHoldem at\nhttp://holdem.ia.ac.cn/, hoping it facilitates further studies on the unsolved\ntheoretical and computational issues in this area and cultivate crucial\nresearch problems like opponent modeling, large-scale equilibrium-finding, and\nhuman-computer interactive learning.\n", "versions": [{"version": "v1", "created": "Fri, 11 Dec 2020 07:24:08 GMT"}, {"version": "v2", "created": "Sat, 19 Dec 2020 14:23:46 GMT"}], "update_date": "2020-12-22", "authors_parsed": [["Li", "Kai", ""], ["Xu", "Hang", ""], ["Zhang", "Meng", ""], ["Zhao", "Enmin", ""], ["Wu", "Zhe", ""], ["Xing", "Junliang", ""], ["Huang", "Kaiqi", ""]]}, {"id": "2012.06240", "submitter": "Gangtao Xin", "authors": "Gangtao Xin and Pingyi Fan", "title": "Soft Compression for Lossless Image Coding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.AI eess.IV math.IT q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Soft compression is a lossless image compression method, which is committed\nto eliminating coding redundancy and spatial redundancy at the same time by\nadopting locations and shapes of codebook to encode an image from the\nperspective of information theory and statistical distribution. In this paper,\nwe propose a new concept, compressible indicator function with regard to image,\nwhich gives a threshold about the average number of bits required to represent\na location and can be used for revealing the performance of soft compression.\nWe investigate and analyze soft compression for binary image, gray image and\nmulti-component image by using specific algorithms and compressible indicator\nvalue. It is expected that the bandwidth and storage space needed when\ntransmitting and storing the same kind of images can be greatly reduced by\napplying soft compression.\n", "versions": [{"version": "v1", "created": "Fri, 11 Dec 2020 10:59:47 GMT"}], "update_date": "2020-12-14", "authors_parsed": [["Xin", "Gangtao", ""], ["Fan", "Pingyi", ""]]}, {"id": "2012.06246", "submitter": "Christian Requena-Mesa", "authors": "Christian Requena-Mesa, Vitus Benson, Joachim Denzler, Jakob Runge and\n  Markus Reichstein", "title": "EarthNet2021: A novel large-scale dataset and challenge for forecasting\n  localized climate impacts", "comments": "4 pages, presented at Tackling Climate Change with Machine Learning\n  at NeurIPS2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.DB", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Climate change is global, yet its concrete impacts can strongly vary between\ndifferent locations in the same region. Seasonal weather forecasts currently\noperate at the mesoscale (> 1 km). For more targeted mitigation and adaptation,\nmodelling impacts to < 100 m is needed. Yet, the relationship between driving\nvariables and Earth's surface at such local scales remains unresolved by\ncurrent physical models. Large Earth observation datasets now enable us to\ncreate machine learning models capable of translating coarse weather\ninformation into high-resolution Earth surface forecasts. Here, we define\nhigh-resolution Earth surface forecasting as video prediction of satellite\nimagery conditional on mesoscale weather forecasts. Video prediction has been\ntackled with deep learning models. Developing such models requires\nanalysis-ready datasets. We introduce EarthNet2021, a new, curated dataset\ncontaining target spatio-temporal Sentinel 2 satellite imagery at 20 m\nresolution, matched with high-resolution topography and mesoscale (1.28 km)\nweather variables. With over 32000 samples it is suitable for training deep\nneural networks. Comparing multiple Earth surface forecasts is not trivial.\nHence, we define the EarthNetScore, a novel ranking criterion for models\nforecasting Earth surface reflectance. For model intercomparison we frame\nEarthNet2021 as a challenge with four tracks based on different test sets.\nThese allow evaluation of model validity and robustness as well as model\napplicability to extreme events and the complete annual vegetation cycle. In\naddition to forecasting directly observable weather impacts through\nsatellite-derived vegetation indices, capable Earth surface models will enable\ndownstream applications such as crop yield prediction, forest health\nassessments, coastline management, or biodiversity monitoring. Find data, code,\nand how to participate at www.earthnet.tech .\n", "versions": [{"version": "v1", "created": "Fri, 11 Dec 2020 11:21:00 GMT"}], "update_date": "2020-12-14", "authors_parsed": [["Requena-Mesa", "Christian", ""], ["Benson", "Vitus", ""], ["Denzler", "Joachim", ""], ["Runge", "Jakob", ""], ["Reichstein", "Markus", ""]]}, {"id": "2012.06289", "submitter": "Lijun Wu", "authors": "Hongshun Tang, Lijun Wu, Weiqing Liu, Jiang Bian", "title": "ADD: Augmented Disentanglement Distillation Framework for Improving\n  Stock Trend Forecasting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Stock trend forecasting has become a popular research direction that attracts\nwidespread attention in the financial field. Though deep learning methods have\nachieved promising results, there are still many limitations, for example, how\nto extract clean features from the raw stock data. In this paper, we introduce\nan \\emph{Augmented Disentanglement Distillation (ADD)} approach to remove\ninterferential features from the noised raw data. Specifically, we present 1) a\ndisentanglement structure to separate excess and market information from the\nstock data to avoid the two factors disturbing each other's own prediction.\nBesides, by applying 2) a dynamic self-distillation method over the\ndisentanglement framework, other implicit interference factors can also be\nremoved. Further, thanks to the decoder module in our framework, 3) a novel\nstrategy is proposed to augment the training samples based on the different\nexcess and market features to improve performance. We conduct experiments on\nthe Chinese stock market data. Results show that our method significantly\nimproves the stock trend forecasting performances, as well as the actual\ninvestment income through backtesting, which strongly demonstrates the\neffectiveness of our approach.\n", "versions": [{"version": "v1", "created": "Fri, 11 Dec 2020 12:46:29 GMT"}], "update_date": "2020-12-14", "authors_parsed": [["Tang", "Hongshun", ""], ["Wu", "Lijun", ""], ["Liu", "Weiqing", ""], ["Bian", "Jiang", ""]]}, {"id": "2012.06306", "submitter": "Simon Gottschalk", "authors": "Simon Gottschalk and Elena Demidova", "title": "EventKG+BT: Generation of Interactive Biography Timelines from a\n  Knowledge Graph", "comments": "ESWC 2020 Satellite Events pp 91-97", "journal-ref": null, "doi": "10.1007/978-3-030-62327-2_16", "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Research on notable accomplishments and important events in the life of\npeople of public interest usually requires close reading of long encyclopedic\nor biographical sources, which is a tedious and time-consuming task. Whereas\nsemantic reference sources, such as the EventKG knowledge graph, provide\nstructured representations of relevant facts, they often include hundreds of\nevents and temporal relations for particular entities. In this paper, we\npresent EventKG+BT - a timeline generation system that creates concise and\ninteractive spatio-temporal representations of biographies from a knowledge\ngraph using distant supervision.\n", "versions": [{"version": "v1", "created": "Fri, 4 Dec 2020 13:06:27 GMT"}], "update_date": "2020-12-14", "authors_parsed": [["Gottschalk", "Simon", ""], ["Demidova", "Elena", ""]]}, {"id": "2012.06310", "submitter": "Shabir Parah Dr", "authors": "Parsa Sarosh, Shabir A. Parah, Romany F Mansur, G. M. Bhat", "title": "Artificial Intelligence for COVID-19 Detection -- A state-of-the-art\n  review", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The emergence of COVID-19 has necessitated many efforts by the scientific\ncommunity for its proper management. An urgent clinical reaction is required in\nthe face of the unending devastation being caused by the pandemic. These\nefforts include technological innovations for improvement in screening,\ntreatment, vaccine development, contact tracing and, survival prediction. The\nuse of Deep Learning (DL) and Artificial Intelligence (AI) can be sought in all\nof the above-mentioned spheres. This paper aims to review the role of Deep\nLearning and Artificial intelligence in various aspects of the overall COVID-19\nmanagement and particularly for COVID-19 detection and classification. The DL\nmodels are developed to analyze clinical modalities like CT scans and X-Ray\nimages of patients and predict their pathological condition. A DL model aims to\ndetect the COVID-19 pneumonia, classify and distinguish between COVID-19,\nCommunity-Acquired Pneumonia (CAP), Viral and Bacterial pneumonia, and normal\nconditions. Furthermore, sophisticated models can be built to segment the\naffected area in the lungs and quantify the infection volume for a better\nunderstanding of the extent of damage. Many models have been developed either\nindependently or with the help of pre-trained models like VGG19, ResNet50, and\nAlexNet leveraging the concept of transfer learning. Apart from model\ndevelopment, data preprocessing and augmentation are also performed to cope\nwith the challenge of insufficient data samples often encountered in medical\napplications. It can be evaluated that DL and AI can be effectively implemented\nto withstand the challenges posed by the global emergency\n", "versions": [{"version": "v1", "created": "Wed, 25 Nov 2020 07:02:14 GMT"}], "update_date": "2020-12-14", "authors_parsed": [["Sarosh", "Parsa", ""], ["Parah", "Shabir A.", ""], ["Mansur", "Romany F", ""], ["Bhat", "G. M.", ""]]}, {"id": "2012.06311", "submitter": "Oluwafemi Azeez", "authors": "Ibrahim Yusuf, George Igwegbe, Oluwafemi Azeez", "title": "Differentiable Histogram with Hard-Binning", "comments": "Accepted at Blacks in AI Workshop, NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The simplicity and expressiveness of a histogram render it a useful feature\nin different contexts including deep learning. Although the process of\ncomputing a histogram is non-differentiable, researchers have proposed\ndifferentiable approximations, which have some limitations. A differentiable\nhistogram that directly approximates the hard-binning operation in conventional\nhistograms is proposed. It combines the strength of existing differentiable\nhistograms and overcomes their individual challenges. In comparison to a\nhistogram computed using Numpy, the proposed histogram has an absolute\napproximation error of 0.000158.\n", "versions": [{"version": "v1", "created": "Fri, 20 Nov 2020 21:52:03 GMT"}], "update_date": "2020-12-14", "authors_parsed": [["Yusuf", "Ibrahim", ""], ["Igwegbe", "George", ""], ["Azeez", "Oluwafemi", ""]]}, {"id": "2012.06312", "submitter": "Signe Riemer-Sorensen", "authors": "Signe Riemer-Sorensen, Gjert H. Rosenlund", "title": "Deep Reinforcement Learning for Long Term Hydropower Production\n  Scheduling", "comments": "2020 International Conference on Smart Energy Systems and\n  Technologies (SEST)", "journal-ref": null, "doi": "10.1109/SEST48500.2020.9203208", "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We explore the use of deep reinforcement learning to provide strategies for\nlong term scheduling of hydropower production. We consider a use-case where the\naim is to optimise the yearly revenue given week-by-week inflows to the\nreservoir and electricity prices. The challenge is to decide between immediate\nwater release at the spot price of electricity and storing the water for later\npower production at an unknown price, given constraints on the system. We\nsuccessfully train a soft actor-critic algorithm on a simplified scenario with\nhistorical data from the Nordic power market. The presented model is not ready\nto substitute traditional optimisation tools but demonstrates the complementary\npotential of reinforcement learning in the data-rich field of hydropower\nscheduling.\n", "versions": [{"version": "v1", "created": "Wed, 9 Dec 2020 13:39:09 GMT"}], "update_date": "2020-12-14", "authors_parsed": [["Riemer-Sorensen", "Signe", ""], ["Rosenlund", "Gjert H.", ""]]}, {"id": "2012.06319", "submitter": "Maike Scholtes", "authors": "Maike Scholtes, Lukas Westhofen, Lara Ruth Turner, Katrin Lotto,\n  Michael Schuldes, Hendrik Weber, Nicolas Wagener, Christian Neurohr, Martin\n  Bollmann, Franziska K\\\"ortke, Johannes Hiller, Michael Hoss, Julian Bock,\n  Lutz Eckstein", "title": "6-Layer Model for a Structured Description and Categorization of Urban\n  Traffic and Environment", "comments": "16 pages, 7 figures, submitted to IEEE Access", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.OH cs.AI cs.SE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Verification and validation of automated driving functions impose large\nchallenges. Currently, scenario-based approaches are investigated in research\nand industry, aiming at a reduction of testing efforts by specifying safety\nrelevant scenarios. To define those scenarios and operate in a complex\nreal-world design domain, a structured description of the environment is\nneeded. Within the PEGASUS research project, the 6-Layer Model (6LM) was\nintroduced for the description of highway scenarios. This paper refines the 6LM\nand extends it to urban traffic and environment. As defined in PEGASUS, the 6LM\nprovides the possibility to categorize the environment and, therefore,\nfunctions as a structured basis for subsequent scenario description. The model\nenables a structured description and categorization of the general environment,\nwithout incorporating any knowledge or anticipating any functions of actors.\nBeyond that, there is a variety of other applications of the 6LM, which are\nelaborated in this paper. The 6LM includes a description of the road network\nand traffic guidance objects, roadside structures, temporary modifications of\nthe former, dynamic objects, environmental conditions and digital information.\nThe work at hand specifies each layer by categorizing its items. Guidelines are\nformulated and explanatory examples are given to standardize the application of\nthe model for an objective environment description. In contrast to previous\npublications, the model and its design are described in far more detail.\nFinally, the holistic description of the 6LM presented includes remarks on\npossible future work when expanding the concept to machine perception aspects.\n", "versions": [{"version": "v1", "created": "Wed, 9 Dec 2020 16:11:32 GMT"}, {"version": "v2", "created": "Tue, 2 Feb 2021 16:39:11 GMT"}], "update_date": "2021-02-03", "authors_parsed": [["Scholtes", "Maike", ""], ["Westhofen", "Lukas", ""], ["Turner", "Lara Ruth", ""], ["Lotto", "Katrin", ""], ["Schuldes", "Michael", ""], ["Weber", "Hendrik", ""], ["Wagener", "Nicolas", ""], ["Neurohr", "Christian", ""], ["Bollmann", "Martin", ""], ["K\u00f6rtke", "Franziska", ""], ["Hiller", "Johannes", ""], ["Hoss", "Michael", ""], ["Bock", "Julian", ""], ["Eckstein", "Lutz", ""]]}, {"id": "2012.06325", "submitter": "Hieu Le Trung", "authors": "Le Trung Hieu", "title": "Deep Reinforcement Learning for Stock Portfolio Optimization", "comments": null, "journal-ref": "International Journal of Modeling and Optimization vol. 10, no. 5,\n  pp. 139-144, 2020", "doi": "10.7763/IJMO.2020.V10.761", "report-no": null, "categories": "cs.LG cs.AI math.OC q-fin.ST", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Stock portfolio optimization is the process of constant re-distribution of\nmoney to a pool of various stocks. In this paper, we will formulate the problem\nsuch that we can apply Reinforcement Learning for the task properly. To\nmaintain a realistic assumption about the market, we will incorporate\ntransaction cost and risk factor into the state as well. On top of that, we\nwill apply various state-of-the-art Deep Reinforcement Learning algorithms for\ncomparison. Since the action space is continuous, the realistic formulation\nwere tested under a family of state-of-the-art continuous policy gradients\nalgorithms: Deep Deterministic Policy Gradient (DDPG), Generalized\nDeterministic Policy Gradient (GDPG) and Proximal Policy Optimization (PPO),\nwhere the former two perform much better than the last one. Next, we will\npresent the end-to-end solution for the task with Minimum Variance Portfolio\nTheory for stock subset selection, and Wavelet Transform for extracting\nmulti-frequency data pattern. Observations and hypothesis were discussed about\nthe results, as well as possible future research directions.1\n", "versions": [{"version": "v1", "created": "Wed, 9 Dec 2020 10:19:12 GMT"}], "update_date": "2020-12-14", "authors_parsed": [["Hieu", "Le Trung", ""]]}, {"id": "2012.06326", "submitter": "Alex B\\\"auerle", "authors": "Alex B\\\"auerle, Raphael St\\\"ork, and Timo Ropinski", "title": "exploRNN: Understanding Recurrent Neural Networks through Visual\n  Exploration", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.HC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Due to the success of deep learning and its growing job market, students and\nresearchers from many areas are getting interested in learning about deep\nlearning technologies. Visualization has proven to be of great help during this\nlearning process, while most current educational visualizations are targeted\ntowards one specific architecture or use case. Unfortunately, recurrent neural\nnetworks (RNNs), which are capable of processing sequential data, are not\ncovered yet, despite the fact that tasks on sequential data, such as text and\nfunction analysis, are at the forefront of deep learning research. Therefore,\nwe propose exploRNN, the first interactively explorable, educational\nvisualization for RNNs. exploRNN allows for interactive experimentation with\nRNNs, and provides in-depth information on their functionality and behavior\nduring training. By defining educational objectives targeted towards\nunderstanding RNNs, and using these as guidelines throughout the visual design\nprocess, we have designed exploRNN to communicate the most important concepts\nof RNNs directly within a web browser. By means of exploRNN, we provide an\noverview of the training process of RNNs at a coarse level, while also allowing\ndetailed inspection of the data-flow within LSTM cells. Within this paper, we\nmotivate our design of exploRNN, detail its realization, and discuss the\nresults of a user study investigating the benefits of exploRNN.\n", "versions": [{"version": "v1", "created": "Wed, 9 Dec 2020 15:06:01 GMT"}], "update_date": "2020-12-14", "authors_parsed": [["B\u00e4uerle", "Alex", ""], ["St\u00f6rk", "Raphael", ""], ["Ropinski", "Timo", ""]]}, {"id": "2012.06332", "submitter": "Ayush Goel", "authors": "Ayush Goel", "title": "An Empirical Review of Adversarial Defenses", "comments": "19 pages, 8 Figures, Report Reviewed by Vivek Menon", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  From face recognition systems installed in phones to self-driving cars, the\nfield of AI is witnessing rapid transformations and is being integrated into\nour everyday lives at an incredible pace. Any major failure in these system's\npredictions could be devastating, leaking sensitive information or even costing\nlives (as in the case of self-driving cars). However, deep neural networks,\nwhich form the basis of such systems, are highly susceptible to a specific type\nof attack, called adversarial attacks. A hacker can, even with bare minimum\ncomputation, generate adversarial examples (images or data points that belong\nto another class, but consistently fool the model to get misclassified as\ngenuine) and crumble the basis of such algorithms. In this paper, we compile\nand test numerous approaches to defend against such adversarial attacks. Out of\nthe ones explored, we found two effective techniques, namely Dropout and\nDenoising Autoencoders, and show their success in preventing such attacks from\nfooling the model. We demonstrate that these techniques are also resistant to\nboth higher noise levels as well as different kinds of adversarial attacks\n(although not tested against all). We also develop a framework for deciding the\nsuitable defense technique to use against attacks, based on the nature of the\napplication and resource constraints of the Deep Neural Network.\n", "versions": [{"version": "v1", "created": "Thu, 10 Dec 2020 09:34:41 GMT"}], "update_date": "2020-12-14", "authors_parsed": [["Goel", "Ayush", ""]]}, {"id": "2012.06337", "submitter": "Han Yu", "authors": "Lingjuan Lyu, Han Yu, Xingjun Ma, Lichao Sun, Jun Zhao, Qiang Yang,\n  Philip S. Yu", "title": "Privacy and Robustness in Federated Learning: Attacks and Defenses", "comments": "arXiv admin note: text overlap with arXiv:2003.02133; text overlap\n  with arXiv:1911.11815 by other authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  As data are increasingly being stored in different silos and societies\nbecoming more aware of data privacy issues, the traditional centralized\ntraining of artificial intelligence (AI) models is facing efficiency and\nprivacy challenges. Recently, federated learning (FL) has emerged as an\nalternative solution and continue to thrive in this new reality. Existing FL\nprotocol design has been shown to be vulnerable to adversaries within or\noutside of the system, compromising data privacy and system robustness. Besides\ntraining powerful global models, it is of paramount importance to design FL\nsystems that have privacy guarantees and are resistant to different types of\nadversaries. In this paper, we conduct the first comprehensive survey on this\ntopic. Through a concise introduction to the concept of FL, and a unique\ntaxonomy covering: 1) threat models; 2) poisoning attacks and defenses against\nrobustness; 3) inference attacks and defenses against privacy, we provide an\naccessible review of this important topic. We highlight the intuitions, key\ntechniques as well as fundamental assumptions adopted by various attacks and\ndefenses. Finally, we discuss promising future research directions towards\nrobust and privacy-preserving federated learning.\n", "versions": [{"version": "v1", "created": "Mon, 7 Dec 2020 12:11:45 GMT"}], "update_date": "2020-12-14", "authors_parsed": [["Lyu", "Lingjuan", ""], ["Yu", "Han", ""], ["Ma", "Xingjun", ""], ["Sun", "Lichao", ""], ["Zhao", "Jun", ""], ["Yang", "Qiang", ""], ["Yu", "Philip S.", ""]]}, {"id": "2012.06338", "submitter": "Alex James Dr", "authors": "Alex James", "title": "The Why, What and How of Artificial General Intelligence Chip\n  Development", "comments": "15 pages, 6 figures", "journal-ref": "IEEE Transactions on Cognitive and Developmental Systems, 2021", "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  The AI chips increasingly focus on implementing neural computing at low power\nand cost. The intelligent sensing, automation, and edge computing applications\nhave been the market drivers for AI chips. Increasingly, the generalisation,\nperformance, robustness, and scalability of the AI chip solutions are compared\nwith human-like intelligence abilities. Such a requirement to transit from\napplication-specific to general intelligence AI chip must consider several\nfactors. This paper provides an overview of this cross-disciplinary field of\nstudy, elaborating on the generalisation of intelligence as understood in\nbuilding artificial general intelligence (AGI) systems. This work presents a\nlisting of emerging AI chip technologies, classification of edge AI\nimplementations, and the funnel design flow for AGI chip development. Finally,\nthe design consideration required for building an AGI chip is listed along with\nthe methods for testing and validating it.\n", "versions": [{"version": "v1", "created": "Tue, 8 Dec 2020 02:36:04 GMT"}, {"version": "v2", "created": "Tue, 30 Mar 2021 14:39:25 GMT"}], "update_date": "2021-03-31", "authors_parsed": [["James", "Alex", ""]]}, {"id": "2012.06344", "submitter": "Raffaele Marino", "authors": "Raffaele Marino", "title": "Learning from Survey Propagation: a Neural Network for MAX-E-$3$-SAT", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Many natural optimization problems are NP-hard, which implies that they are\nprobably hard to solve exactly in the worst-case. However, it suffices to get\nreasonably good solutions for all (or even most) instances in practice. This\npaper presents a new algorithm for computing approximate solutions in\n${\\Theta(N})$ for the Maximum Exact 3-Satisfiability (MAX-E-$3$-SAT) problem by\nusing deep learning methodology. This methodology allows us to create a\nlearning algorithm able to fix Boolean variables by using local information\nobtained by the Survey Propagation algorithm. By performing an accurate\nanalysis, on random CNF instances of the MAX-E-$3$-SAT with several Boolean\nvariables, we show that this new algorithm, avoiding any decimation strategy,\ncan build assignments better than a random one, even if the convergence of the\nmessages is not found. Although this algorithm is not competitive with\nstate-of-the-art Maximum Satisfiability (MAX-SAT) solvers, it can solve\nsubstantially larger and more complicated problems than it ever saw during\ntraining.\n", "versions": [{"version": "v1", "created": "Thu, 10 Dec 2020 07:59:54 GMT"}, {"version": "v2", "created": "Sun, 14 Feb 2021 09:22:57 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Marino", "Raffaele", ""]]}, {"id": "2012.06373", "submitter": "Julien Launay", "authors": "Julien Launay, Iacopo Poli, Kilian M\\\"uller, Gustave Pariente, Igor\n  Carron, Laurent Daudet, Florent Krzakala, Sylvain Gigan", "title": "Hardware Beyond Backpropagation: a Photonic Co-Processor for Direct\n  Feedback Alignment", "comments": "6 pages, 2 figures, 1 table. Oral at the Beyond Backpropagation\n  Workshop, NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.AR cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The scaling hypothesis motivates the expansion of models past trillions of\nparameters as a path towards better performance. Recent significant\ndevelopments, such as GPT-3, have been driven by this conjecture. However, as\nmodels scale-up, training them efficiently with backpropagation becomes\ndifficult. Because model, pipeline, and data parallelism distribute parameters\nand gradients over compute nodes, communication is challenging to orchestrate:\nthis is a bottleneck to further scaling. In this work, we argue that\nalternative training methods can mitigate these issues, and can inform the\ndesign of extreme-scale training hardware. Indeed, using a synaptically\nasymmetric method with a parallelizable backward pass, such as Direct Feedback\nAlignement, communication needs are drastically reduced. We present a photonic\naccelerator for Direct Feedback Alignment, able to compute random projections\nwith trillions of parameters. We demonstrate our system on benchmark tasks,\nusing both fully-connected and graph convolutional networks. Our hardware is\nthe first architecture-agnostic photonic co-processor for training neural\nnetworks. This is a significant step towards building scalable hardware, able\nto go beyond backpropagation, and opening new avenues for deep learning.\n", "versions": [{"version": "v1", "created": "Fri, 11 Dec 2020 14:20:45 GMT"}], "update_date": "2020-12-14", "authors_parsed": [["Launay", "Julien", ""], ["Poli", "Iacopo", ""], ["M\u00fcller", "Kilian", ""], ["Pariente", "Gustave", ""], ["Carron", "Igor", ""], ["Daudet", "Laurent", ""], ["Krzakala", "Florent", ""], ["Gigan", "Sylvain", ""]]}, {"id": "2012.06390", "submitter": "Ferhat Ozgur Catak", "authors": "Omer Faruk Tuna, Ferhat Ozgur Catak, M. Taner Eskil", "title": "Closeness and Uncertainty Aware Adversarial Examples Detection in\n  Adversarial Machine Learning", "comments": "17 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While state-of-the-art Deep Neural Network (DNN) models are considered to be\nrobust to random perturbations, it was shown that these architectures are\nhighly vulnerable to deliberately crafted perturbations, albeit being\nquasi-imperceptible. These vulnerabilities make it challenging to deploy DNN\nmodels in security-critical areas. In recent years, many research studies have\nbeen conducted to develop new attack methods and come up with new defense\ntechniques that enable more robust and reliable models. In this work, we\nexplore and assess the usage of different type of metrics for detecting\nadversarial samples. We first leverage the usage of moment-based predictive\nuncertainty estimates of a DNN classifier obtained using Monte-Carlo Dropout\nSampling. And we also introduce a new method that operates in the subspace of\ndeep features extracted by the model. We verified the effectiveness of our\napproach on a range of standard datasets like MNIST (Digit), MNIST (Fashion)\nand CIFAR-10. Our experiments show that these two different approaches\ncomplement each other, and the combined usage of all the proposed metrics\nyields up to 99 \\% ROC-AUC scores regardless of the attack algorithm.\n", "versions": [{"version": "v1", "created": "Fri, 11 Dec 2020 14:44:59 GMT"}, {"version": "v2", "created": "Wed, 2 Jun 2021 10:02:47 GMT"}], "update_date": "2021-06-03", "authors_parsed": [["Tuna", "Omer Faruk", ""], ["Catak", "Ferhat Ozgur", ""], ["Eskil", "M. Taner", ""]]}, {"id": "2012.06405", "submitter": "Nathan Drenkow", "authors": "Nathan Drenkow, Neil Fendley, Philippe Burlina", "title": "Random Projections for Adversarial Attack Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Whilst adversarial attack detection has received considerable attention, it\nremains a fundamentally challenging problem from two perspectives. First, while\nthreat models can be well-defined, attacker strategies may still vary widely\nwithin those constraints. Therefore, detection should be considered as an\nopen-set problem, standing in contrast to most current detection strategies.\nThese methods take a closed-set view and train binary detectors, thus biasing\ndetection toward attacks seen during detector training. Second, information is\nlimited at test time and confounded by nuisance factors including the label and\nunderlying content of the image. Many of the current high-performing techniques\nuse training sets for dealing with some of these issues, but can be limited by\nthe overall size and diversity of those sets during the detection step. We\naddress these challenges via a novel strategy based on random subspace\nanalysis. We present a technique that makes use of special properties of random\nprojections, whereby we can characterize the behavior of clean and adversarial\nexamples across a diverse set of subspaces. We then leverage the\nself-consistency (or inconsistency) of model activations to discern clean from\nadversarial examples. Performance evaluation demonstrates that our technique\noutperforms ($>0.92$ AUC) competing state of the art (SOTA) attack strategies,\nwhile remaining truly agnostic to the attack method itself. It also requires\nsignificantly less training data, composed only of clean examples, when\ncompared to competing SOTA methods, which achieve only chance performance, when\nevaluated in a more rigorous testing scenario.\n", "versions": [{"version": "v1", "created": "Fri, 11 Dec 2020 15:02:28 GMT"}], "update_date": "2020-12-14", "authors_parsed": [["Drenkow", "Nathan", ""], ["Fendley", "Neil", ""], ["Burlina", "Philippe", ""]]}, {"id": "2012.06452", "submitter": "Piotr Kicki", "authors": "Piotr Kicki, Mete Ozay, Piotr Skrzypczy\\'nski", "title": "A New Neural Network Architecture Invariant to the Action of Symmetry\n  Subgroups", "comments": "Presented as contributed talk at NeurIPS 2020 workshop on\n  Differential Geometry meets Deep Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We propose a computationally efficient $G$-invariant neural network that\napproximates functions invariant to the action of a given permutation subgroup\n$G \\leq S_n$ of the symmetric group on input data. The key element of the\nproposed network architecture is a new $G$-invariant transformation module,\nwhich produces a $G$-invariant latent representation of the input data.\nTheoretical considerations are supported by numerical experiments, which\ndemonstrate the effectiveness and strong generalization properties of the\nproposed method in comparison to other $G$-invariant neural networks.\n", "versions": [{"version": "v1", "created": "Fri, 11 Dec 2020 16:19:46 GMT"}], "update_date": "2020-12-14", "authors_parsed": [["Kicki", "Piotr", ""], ["Ozay", "Mete", ""], ["Skrzypczy\u0144ski", "Piotr", ""]]}, {"id": "2012.06453", "submitter": "Subodip Biswas", "authors": "Subhodip Biswas, Adam D Cobb, Andreea Sistrunk, Naren Ramakrishnan,\n  Brian Jalaian", "title": "Better call Surrogates: A hybrid Evolutionary Algorithm for\n  Hyperparameter optimization", "comments": "Accepted at the black box optimization challenge at NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we propose a surrogate-assisted evolutionary algorithm (EA)\nfor hyperparameter optimization of machine learning (ML) models. The proposed\nSTEADE model initially estimates the objective function landscape using\nRadialBasis Function interpolation, and then transfers the knowledge to an EA\ntechnique called Differential Evolution that is used to evolve new solutions\nguided by a Bayesian optimization framework. We empirically evaluate our model\non the hyperparameter optimization problems as a part of the black box\noptimization challenge at NeurIPS 2020 and demonstrate the improvement brought\nabout by STEADE over the vanilla EA.\n", "versions": [{"version": "v1", "created": "Fri, 11 Dec 2020 16:19:59 GMT"}], "update_date": "2020-12-14", "authors_parsed": [["Biswas", "Subhodip", ""], ["Cobb", "Adam D", ""], ["Sistrunk", "Andreea", ""], ["Ramakrishnan", "Naren", ""], ["Jalaian", "Brian", ""]]}, {"id": "2012.06474", "submitter": "Alessandro Zonta", "authors": "A. Zonta, S.K. Smit and A.E. Eiben", "title": "Generating Human-Like Movement: A Comparison Between Two Approaches\n  Based on Environmental Features", "comments": "31 pages, 16 figures, submitted to Expert Systems with Applications", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Modelling realistic human behaviours in simulation is an ongoing challenge\nthat resides between several fields like social sciences, philosophy, and\nartificial intelligence. Human movement is a special type of behaviour driven\nby intent (e.g. to get groceries) and the surrounding environment (e.g.\ncuriosity to see new interesting places). Services available online and offline\ndo not normally consider the environment when planning a path, which is\ndecisive especially on a leisure trip. Two novel algorithms have been presented\nto generate human-like trajectories based on environmental features. The\nAttraction-Based A* algorithm includes in its computation information from the\nenvironmental features meanwhile, the Feature-Based A* algorithm also injects\ninformation from the real trajectories in its computation. The human-likeness\naspect has been tested by a human expert judging the final generated\ntrajectories as realistic. This paper presents a comparison between the two\napproaches in some key metrics like efficiency, efficacy, and hyper-parameters\nsensitivity. We show how, despite generating trajectories that are closer to\nthe real one according to our predefined metrics, the Feature-Based A*\nalgorithm fall short in time efficiency compared to the Attraction-Based A*\nalgorithm, hindering the usability of the model in the real world.\n", "versions": [{"version": "v1", "created": "Fri, 11 Dec 2020 16:45:32 GMT"}], "update_date": "2020-12-14", "authors_parsed": [["Zonta", "A.", ""], ["Smit", "S. K.", ""], ["Eiben", "A. E.", ""]]}, {"id": "2012.06492", "submitter": "Chinedu Ezenkwu Pascal", "authors": "Chinedu Pascal Ezenkwu and Andrew Starkey", "title": "Technical Opinion: From Animal Behaviour to Autonomous Robots", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  With the rising applications of robots in unstructured real-world\nenvironments, roboticists are increasingly concerned with the problems posed by\nthe complexity of such environments. One solution to these problems is robot\nautonomy. Since nature has already solved the problem of autonomy it can be a\nsuitable model for developing autonomous robots. This paper presents a concise\nreview on robot autonomy from the perspective of animal behaviour. It examines\nsome state-of-the-art techniques as well as suggesting possible research\ndirections.\n", "versions": [{"version": "v1", "created": "Fri, 11 Dec 2020 16:57:28 GMT"}], "update_date": "2020-12-14", "authors_parsed": [["Ezenkwu", "Chinedu Pascal", ""], ["Starkey", "Andrew", ""]]}, {"id": "2012.06509", "submitter": "Nathan Drenkow", "authors": "Nathan Drenkow, Philippe Burlina, Neil Fendley, Onyekachi Odoemene,\n  Jared Markowitz", "title": "Addressing Visual Search in Open and Closed Set Settings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Searching for small objects in large images is a task that is both\nchallenging for current deep learning systems and important in numerous\nreal-world applications, such as remote sensing and medical imaging. Thorough\nscanning of very large images is computationally expensive, particularly at\nresolutions sufficient to capture small objects. The smaller an object of\ninterest, the more likely it is to be obscured by clutter or otherwise deemed\ninsignificant. We examine these issues in the context of two complementary\nproblems: closed-set object detection and open-set target search. First, we\npresent a method for predicting pixel-level objectness from a low resolution\ngist image, which we then use to select regions for performing object detection\nlocally at high resolution. This approach has the benefit of not being fixed to\na predetermined grid, thereby requiring fewer costly high-resolution glimpses\nthan existing methods. Second, we propose a novel strategy for open-set visual\nsearch that seeks to find all instances of a target class which may be\npreviously unseen and is defined by a single image. We interpret both detection\nproblems through a probabilistic, Bayesian lens, whereby the objectness maps\nproduced by our method serve as priors in a maximum-a-posteriori approach to\nthe detection step. We evaluate the end-to-end performance of both the\ncombination of our patch selection strategy with this target search approach\nand the combination of our patch selection strategy with standard object\ndetection methods. Both elements of our approach are seen to significantly\noutperform baseline strategies.\n", "versions": [{"version": "v1", "created": "Fri, 11 Dec 2020 17:21:28 GMT"}, {"version": "v2", "created": "Wed, 14 Apr 2021 21:43:19 GMT"}], "update_date": "2021-04-16", "authors_parsed": [["Drenkow", "Nathan", ""], ["Burlina", "Philippe", ""], ["Fendley", "Neil", ""], ["Odoemene", "Onyekachi", ""], ["Markowitz", "Jared", ""]]}, {"id": "2012.06513", "submitter": "Bonny Banerjee", "authors": "Bonny Banerjee", "title": "String Tightening as a Self-Organizing Phenomenon: Computation of\n  Shortest Homotopic Path, Smooth Path, and Convex Hull", "comments": null, "journal-ref": "in IEEE Transactions on Neural Networks, vol. 18, no. 5, pp.\n  1463-1471, Sept. 2007", "doi": "10.1109/TNN.2007.891192", "report-no": null, "categories": "cs.AI cs.CG cs.LG cs.RO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The phenomenon of self-organization has been of special interest to the\nneural network community for decades. In this paper, we study a variant of the\nSelf-Organizing Map (SOM) that models the phenomenon of self-organization of\nthe particles forming a string when the string is tightened from one or both\nends. The proposed variant, called the String Tightening Self-Organizing Neural\nNetwork (STON), can be used to solve certain practical problems, such as\ncomputation of shortest homotopic paths, smoothing paths to avoid sharp turns,\nand computation of convex hull. These problems are of considerable interest in\ncomputational geometry, robotics path planning, AI (diagrammatic reasoning),\nVLSI routing, and geographical information systems. Given a set of obstacles\nand a string with two fixed terminal points in a two dimensional space, the\nSTON model continuously tightens the given string until the unique shortest\nconfiguration in terms of the Euclidean metric is reached. The STON minimizes\nthe total length of a string on convergence by dynamically creating and\nselecting feature vectors in a competitive manner. Proof of correctness of this\nanytime algorithm and experimental results obtained by its deployment are\npresented in the paper.\n", "versions": [{"version": "v1", "created": "Fri, 11 Dec 2020 17:33:11 GMT"}, {"version": "v2", "created": "Tue, 16 Feb 2021 01:56:47 GMT"}], "update_date": "2021-02-17", "authors_parsed": [["Banerjee", "Bonny", ""]]}, {"id": "2012.06523", "submitter": "Jan Kronenberger H", "authors": "Jan Kronenberger and Anselm Haselhoff", "title": "Dependency Decomposition and a Reject Option for Explainable Models", "comments": "Accepted at CVPR 2019 Workshop \"DThree19: Dependable Deep Detectors\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deploying machine learning models in safety-related do-mains (e.g. autonomous\ndriving, medical diagnosis) demands for approaches that are explainable, robust\nagainst adversarial attacks and aware of the model uncertainty. Recent deep\nlearning models perform extremely well in various inference tasks, but the\nblack-box nature of these approaches leads to a weakness regarding the three\nrequirements mentioned above. Recent advances offer methods to visualize\nfeatures, describe attribution of the input (e.g.heatmaps), provide textual\nexplanations or reduce dimensionality. However,are explanations for\nclassification tasks dependent or are they independent of each other? For\nin-stance, is the shape of an object dependent on the color? What is the effect\nof using the predicted class for generating explanations and vice versa? In the\ncontext of explainable deep learning models, we present the first analysis of\ndependencies regarding the probability distribution over the desired image\nclassification outputs and the explaining variables (e.g. attributes, texts,\nheatmaps). Therefore, we perform an Explanation Dependency Decomposition (EDD).\nWe analyze the implications of the different dependencies and propose two ways\nof generating the explanation. Finally, we use the explanation to verify\n(accept or reject) the prediction\n", "versions": [{"version": "v1", "created": "Fri, 11 Dec 2020 17:39:33 GMT"}], "update_date": "2020-12-14", "authors_parsed": [["Kronenberger", "Jan", ""], ["Haselhoff", "Anselm", ""]]}, {"id": "2012.06537", "submitter": "William Winlow Professor", "authors": "Andrew Simon Johnson and William Winlow", "title": "Does the brain function as a quantum phase computer using phase ternary\n  computation?", "comments": "16 pages, 7 figures. Key Words: Plasticity; Action potential; Timing;\n  Error redaction; Synchronization; Quantum phase computation; Phase ternary\n  computation; Retinal model", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Here we provide evidence that the fundamental basis of nervous communication\nis derived from a pressure pulse/soliton capable of computation with sufficient\ntemporal precision to overcome any processing errors. Signalling and computing\nwithin the nervous system are complex and different phenomena. Action\npotentials are plastic and this makes the action potential peak an\ninappropriate fixed point for neural computation, but the action potential\nthreshold is suitable for this purpose. Furthermore, neural models timed by\nspiking neurons operate below the rate necessary to overcome processing error.\nUsing retinal processing as our example, we demonstrate that the contemporary\ntheory of nerve conduction based on cable theory is inappropriate to account\nfor the short computational time necessary for the full functioning of the\nretina and by implication the rest of the brain. Moreover, cable theory cannot\nbe instrumental in the propagation of the action potential because at the\nactivation-threshold there is insufficient charge at the activation site for\nsuccessive ion channels to be electrostatically opened. Deconstruction of the\nbrain neural network suggests that it is a member of a group of Quantum phase\ncomputers of which the Turing machine is the simplest: the brain is another\nbased upon phase ternary computation. However, attempts to use Turing based\nmechanisms cannot resolve the coding of the retina or the computation of\nintelligence, as the technology of Turing based computers is fundamentally\ndifferent. We demonstrate that that coding in the brain neural network is\nquantum based, where the quanta have a temporal variable and a phase-base\nvariable enabling phase ternary computation as previously demonstrated in the\nretina.\n", "versions": [{"version": "v1", "created": "Fri, 4 Dec 2020 08:00:23 GMT"}], "update_date": "2020-12-14", "authors_parsed": [["Johnson", "Andrew Simon", ""], ["Winlow", "William", ""]]}, {"id": "2012.06538", "submitter": "Uwe Aickelin", "authors": "Ning Xue, Ruibin Bai, Rong Qu, Uwe Aickelin", "title": "A Hybrid Pricing and Cutting Approach for the Multi-Shift Full Truckload\n  Vehicle Routing Problem", "comments": "European Journal of Operational Research, 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI math.OC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Full truckload transportation (FTL) in the form of freight containers\nrepresents one of the most important transportation modes in international\ntrade. Due to large volume and scale, in FTL, delivery time is often less\ncritical but cost and service quality are crucial. Therefore, efficiently\nsolving large scale multiple shift FTL problems is becoming more and more\nimportant and requires further research. In one of our earlier studies, a set\ncovering model and a three-stage solution method were developed for a\nmulti-shift FTL problem. This paper extends the previous work and presents a\nsignificantly more efficient approach by hybridising pricing and cutting\nstrategies with metaheuristics (a variable neighbourhood search and a genetic\nalgorithm). The metaheuristics were adopted to find promising columns (vehicle\nroutes) guided by pricing and cuts are dynamically generated to eliminate\ninfeasible flow assignments caused by incompatible commodities. Computational\nexperiments on real-life and artificial benchmark FTL problems showed superior\nperformance both in terms of computational time and solution quality, when\ncompared with previous MIP based three-stage methods and two existing\nmetaheuristics. The proposed cutting and heuristic pricing approach can\nefficiently solve large scale real-life FTL problems.\n", "versions": [{"version": "v1", "created": "Thu, 3 Dec 2020 02:55:49 GMT"}], "update_date": "2020-12-14", "authors_parsed": [["Xue", "Ning", ""], ["Bai", "Ruibin", ""], ["Qu", "Rong", ""], ["Aickelin", "Uwe", ""]]}, {"id": "2012.06555", "submitter": "Tamal Maharaj", "authors": "Srinjoy Roy, Saptam Bakshi, Tamal Maharaj", "title": "OPAC: Opportunistic Actor-Critic", "comments": "10 pages. arXiv admin note: text overlap with arXiv:1812.05905 by\n  other authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Actor-critic methods, a type of model-free reinforcement learning (RL), have\nachieved state-of-the-art performances in many real-world domains in continuous\ncontrol. Despite their success, the wide-scale deployment of these models is\nstill a far cry. The main problems in these actor-critic methods are\ninefficient exploration and sub-optimal policies. Soft Actor-Critic (SAC) and\nTwin Delayed Deep Deterministic Policy Gradient (TD3), two cutting edge such\nalgorithms, suffer from these issues. SAC effectively addressed the problems of\nsample complexity and convergence brittleness to hyper-parameters and thus\noutperformed all state-of-the-art algorithms including TD3 in harder tasks,\nwhereas TD3 produced moderate results in all environments. SAC suffers from\ninefficient exploration owing to the Gaussian nature of its policy which causes\nborderline performance in simpler tasks. In this paper, we introduce\nOpportunistic Actor-Critic (OPAC), a novel model-free deep RL algorithm that\nemploys better exploration policy and lesser variance. OPAC combines some of\nthe most powerful features of TD3 and SAC and aims to optimize a stochastic\npolicy in an off-policy way. For calculating the target Q-values, instead of\ntwo critics, OPAC uses three critics and based on the environment complexity,\nopportunistically chooses how the target Q-value is computed from the critics'\nevaluation. We have systematically evaluated the algorithm on MuJoCo\nenvironments where it achieves state-of-the-art performance and outperforms or\nat least equals the performance of TD3 and SAC.\n", "versions": [{"version": "v1", "created": "Fri, 11 Dec 2020 18:33:35 GMT"}], "update_date": "2020-12-14", "authors_parsed": [["Roy", "Srinjoy", ""], ["Bakshi", "Saptam", ""], ["Maharaj", "Tamal", ""]]}, {"id": "2012.06561", "submitter": "Pavel Naumov", "authors": "Pavel Naumov, Kevin Ros", "title": "Comprehension and Knowledge", "comments": "To appear in Proceedings 35th AAAI Conference on Artificial\n  Intelligence (AAAI 21), February 2-9, 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ability of an agent to comprehend a sentence is tightly connected to the\nagent's prior experiences and background knowledge. The paper suggests to\ninterpret comprehension as a modality and proposes a complete bimodal logical\nsystem that describes an interplay between comprehension and knowledge\nmodalities.\n", "versions": [{"version": "v1", "created": "Fri, 11 Dec 2020 18:42:08 GMT"}, {"version": "v2", "created": "Mon, 1 Mar 2021 22:24:35 GMT"}], "update_date": "2021-03-03", "authors_parsed": [["Naumov", "Pavel", ""], ["Ros", "Kevin", ""]]}, {"id": "2012.06651", "submitter": "Pavel Naumov", "authors": "Sophia Epstein, Pavel Naumov", "title": "Epistemic Logic of Know-Who", "comments": "To appear in Proceedings of 35th AAAI Conference on Artificial\n  Intelligence (AAAI 21), February 2-9, 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper suggests a definition of \"know who\" as a modality using\nGrove-Halpern semantics of names. It also introduces a logical system that\ndescribes the interplay between modalities \"knows who\", \"knows\", and \"for all\nagents\". The main technical result is a completeness theorem for the proposed\nsystem.\n", "versions": [{"version": "v1", "created": "Fri, 11 Dec 2020 21:45:04 GMT"}, {"version": "v2", "created": "Wed, 3 Mar 2021 02:09:32 GMT"}], "update_date": "2021-03-04", "authors_parsed": [["Epstein", "Sophia", ""], ["Naumov", "Pavel", ""]]}, {"id": "2012.06678", "submitter": "Xin Huang", "authors": "Xin Huang, Ashish Khetan, Milan Cvitkovic, Zohar Karnin", "title": "TabTransformer: Tabular Data Modeling Using Contextual Embeddings", "comments": "7 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  We propose TabTransformer, a novel deep tabular data modeling architecture\nfor supervised and semi-supervised learning. The TabTransformer is built upon\nself-attention based Transformers. The Transformer layers transform the\nembeddings of categorical features into robust contextual embeddings to achieve\nhigher prediction accuracy. Through extensive experiments on fifteen publicly\navailable datasets, we show that the TabTransformer outperforms the\nstate-of-the-art deep learning methods for tabular data by at least 1.0% on\nmean AUC, and matches the performance of tree-based ensemble models.\nFurthermore, we demonstrate that the contextual embeddings learned from\nTabTransformer are highly robust against both missing and noisy data features,\nand provide better interpretability. Lastly, for the semi-supervised setting we\ndevelop an unsupervised pre-training procedure to learn data-driven contextual\nembeddings, resulting in an average 2.1% AUC lift over the state-of-the-art\nmethods.\n", "versions": [{"version": "v1", "created": "Fri, 11 Dec 2020 23:31:23 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["Huang", "Xin", ""], ["Khetan", "Ashish", ""], ["Cvitkovic", "Milan", ""], ["Karnin", "Zohar", ""]]}, {"id": "2012.06686", "submitter": "Raymond Anneborg", "authors": "Raymond Anneborg", "title": "Computing Machinery and Knowledge", "comments": "7 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The purpose of this paper is to discuss the possibilities for computing\nmachinery, or AI agents, to know and to possess knowledge. This is done mainly\nfrom a virtue epistemology perspective and definition of knowledge. However,\nthis inquiry also shed light on the human condition, what it means for a human\nto know, and to possess knowledge. The paper argues that it is possible for an\nAI agent to know and examines this from both current state-of-the-art in\nartificial intelligence as well as from the perspective of what the future AI\ndevelopment might bring in terms of superintelligent AI agents.\n", "versions": [{"version": "v1", "created": "Sat, 31 Oct 2020 09:27:53 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["Anneborg", "Raymond", ""]]}, {"id": "2012.06694", "submitter": "Shima Rahimi Moghaddam", "authors": "Shima Rahimi Moghaddam, Fanjun Bu, Christopher J. Honey", "title": "Learning Representations from Temporally Smooth Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Events in the real world are correlated across nearby points in time, and we\nmust learn from this temporally smooth data. However, when neural networks are\ntrained to categorize or reconstruct single items, the common practice is to\nrandomize the order of training items. What are the effects of temporally\nsmooth training data on the efficiency of learning? We first tested the effects\nof smoothness in training data on incremental learning in feedforward nets and\nfound that smoother data slowed learning. Moreover, sampling so as to minimize\ntemporal smoothness produced more efficient learning than sampling randomly. If\nsmoothness generally impairs incremental learning, then how can networks be\nmodified to benefit from smoothness in the training data? We hypothesized that\ntwo simple brain-inspired mechanisms, leaky memory in activation units and\nmemory-gating, could enable networks to rapidly extract useful representations\nfrom smooth data. Across all levels of data smoothness, these brain-inspired\narchitectures achieved more efficient category learning than feedforward\nnetworks. This advantage persisted, even when leaky memory networks with gating\nwere trained on smooth data and tested on randomly-ordered data. Finally, we\ninvestigated how these brain-inspired mechanisms altered the internal\nrepresentations learned by the networks. We found that networks with\nmulti-scale leaky memory and memory-gating could learn internal representations\nthat un-mixed data sources which vary on fast and slow timescales across\ntraining samples. Altogether, we identified simple mechanisms enabling neural\nnetworks to learn more quickly from temporally smooth data, and to generate\ninternal representations that separate timescales in the training signal.\n", "versions": [{"version": "v1", "created": "Sat, 12 Dec 2020 01:24:36 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["Moghaddam", "Shima Rahimi", ""], ["Bu", "Fanjun", ""], ["Honey", "Christopher J.", ""]]}, {"id": "2012.06723", "submitter": "Sahil Sidheekh", "authors": "Sahil Sidheekh, Aroof Aimen, Vineet Madan, Narayanan C. Krishnan", "title": "On Duality Gap as a Measure for Monitoring GAN Training", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative adversarial network (GAN) is among the most popular deep learning\nmodels for learning complex data distributions. However, training a GAN is\nknown to be a challenging task. This is often attributed to the lack of\ncorrelation between the training progress and the trajectory of the generator\nand discriminator losses and the need for the GAN's subjective evaluation. A\nrecently proposed measure inspired by game theory - the duality gap, aims to\nbridge this gap. However, as we demonstrate, the duality gap's capability\nremains constrained due to limitations posed by its estimation process. This\npaper presents a theoretical understanding of this limitation and proposes a\nmore dependable estimation process for the duality gap. At the crux of our\napproach is the idea that local perturbations can help agents in a zero-sum\ngame escape non-Nash saddle points efficiently. Through exhaustive\nexperimentation across GAN models and datasets, we establish the efficacy of\nour approach in capturing the GAN training progress with minimal increase to\nthe computational complexity. Further, we show that our estimate, with its\nability to identify model convergence/divergence, is a potential performance\nmeasure that can be used to tune the hyperparameters of a GAN.\n", "versions": [{"version": "v1", "created": "Sat, 12 Dec 2020 04:32:52 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["Sidheekh", "Sahil", ""], ["Aimen", "Aroof", ""], ["Madan", "Vineet", ""], ["Krishnan", "Narayanan C.", ""]]}, {"id": "2012.06731", "submitter": "Robin Swezey", "authors": "Robin Swezey, Aditya Grover, Bruno Charron, Stefano Ermon", "title": "PiRank: Learning To Rank via Differentiable Sorting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A key challenge with machine learning approaches for ranking is the gap\nbetween the performance metrics of interest and the surrogate loss functions\nthat can be optimized with gradient-based methods. This gap arises because\nranking metrics typically involve a sorting operation which is not\ndifferentiable w.r.t. the model parameters. Prior works have proposed\nsurrogates that are loosely related to ranking metrics or simple smoothed\nversions thereof. We propose PiRank, a new class of differentiable surrogates\nfor ranking, which employ a continuous, temperature-controlled relaxation to\nthe sorting operator. We show that PiRank exactly recovers the desired metrics\nin the limit of zero temperature and scales favorably with the problem size,\nboth in theory and practice. Empirically, we demonstrate that PiRank\nsignificantly improves over existing approaches on publicly available\ninternet-scale learning-to-rank benchmarks.\n", "versions": [{"version": "v1", "created": "Sat, 12 Dec 2020 05:07:36 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["Swezey", "Robin", ""], ["Grover", "Aditya", ""], ["Charron", "Bruno", ""], ["Ermon", "Stefano", ""]]}, {"id": "2012.06733", "submitter": "Ajay Mandlekar", "authors": "Ajay Mandlekar, Danfei Xu, Roberto Mart\\'in-Mart\\'in, Yuke Zhu, Li\n  Fei-Fei, Silvio Savarese", "title": "Human-in-the-Loop Imitation Learning using Remote Teleoperation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Imitation Learning is a promising paradigm for learning complex robot\nmanipulation skills by reproducing behavior from human demonstrations. However,\nmanipulation tasks often contain bottleneck regions that require a sequence of\nprecise actions to make meaningful progress, such as a robot inserting a pod\ninto a coffee machine to make coffee. Trained policies can fail in these\nregions because small deviations in actions can lead the policy into states not\ncovered by the demonstrations. Intervention-based policy learning is an\nalternative that can address this issue -- it allows human operators to monitor\ntrained policies and take over control when they encounter failures. In this\npaper, we build a data collection system tailored to 6-DoF manipulation\nsettings, that enables remote human operators to monitor and intervene on\ntrained policies. We develop a simple and effective algorithm to train the\npolicy iteratively on new data collected by the system that encourages the\npolicy to learn how to traverse bottlenecks through the interventions. We\ndemonstrate that agents trained on data collected by our intervention-based\nsystem and algorithm outperform agents trained on an equivalent number of\nsamples collected by non-interventional demonstrators, and further show that\nour method outperforms multiple state-of-the-art baselines for learning from\nthe human interventions on a challenging robot threading task and a coffee\nmaking task. Additional results and videos at\nhttps://sites.google.com/stanford.edu/iwr .\n", "versions": [{"version": "v1", "created": "Sat, 12 Dec 2020 05:30:35 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["Mandlekar", "Ajay", ""], ["Xu", "Danfei", ""], ["Mart\u00edn-Mart\u00edn", "Roberto", ""], ["Zhu", "Yuke", ""], ["Fei-Fei", "Li", ""], ["Savarese", "Silvio", ""]]}, {"id": "2012.06738", "submitter": "Ajay Mandlekar", "authors": "Albert Tung, Josiah Wong, Ajay Mandlekar, Roberto Mart\\'in-Mart\\'in,\n  Yuke Zhu, Li Fei-Fei, Silvio Savarese", "title": "Learning Multi-Arm Manipulation Through Collaborative Teleoperation", "comments": "First two authors contributed equally", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Imitation Learning (IL) is a powerful paradigm to teach robots to perform\nmanipulation tasks by allowing them to learn from human demonstrations\ncollected via teleoperation, but has mostly been limited to single-arm\nmanipulation. However, many real-world tasks require multiple arms, such as\nlifting a heavy object or assembling a desk. Unfortunately, applying IL to\nmulti-arm manipulation tasks has been challenging -- asking a human to control\nmore than one robotic arm can impose significant cognitive burden and is often\nonly possible for a maximum of two robot arms. To address these challenges, we\npresent Multi-Arm RoboTurk (MART), a multi-user data collection platform that\nallows multiple remote users to simultaneously teleoperate a set of robotic\narms and collect demonstrations for multi-arm tasks. Using MART, we collected\ndemonstrations for five novel two and three-arm tasks from several\ngeographically separated users. From our data we arrived at a critical insight:\nmost multi-arm tasks do not require global coordination throughout its full\nduration, but only during specific moments. We show that learning from such\ndata consequently presents challenges for centralized agents that directly\nattempt to model all robot actions simultaneously, and perform a comprehensive\nstudy of different policy architectures with varying levels of centralization\non our tasks. Finally, we propose and evaluate a base-residual policy framework\nthat allows trained policies to better adapt to the mixed coordination setting\ncommon in multi-arm manipulation, and show that a centralized policy augmented\nwith a decentralized residual model outperforms all other models on our set of\nbenchmark tasks. Additional results and videos at\nhttps://roboturk.stanford.edu/multiarm .\n", "versions": [{"version": "v1", "created": "Sat, 12 Dec 2020 05:43:43 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["Tung", "Albert", ""], ["Wong", "Josiah", ""], ["Mandlekar", "Ajay", ""], ["Mart\u00edn-Mart\u00edn", "Roberto", ""], ["Zhu", "Yuke", ""], ["Fei-Fei", "Li", ""], ["Savarese", "Silvio", ""]]}, {"id": "2012.06755", "submitter": "Davide Buffelli", "authors": "Davide Buffelli, Fabio Vandin", "title": "A Meta-Learning Approach for Graph Representation Learning in Multi-Task\n  Settings", "comments": "Accepted at the NeurIPS Workshop on Meta-Learning (MetaLearn) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph Neural Networks (GNNs) are a framework for graph representation\nlearning, where a model learns to generate low dimensional node embeddings that\nencapsulate structural and feature-related information. GNNs are usually\ntrained in an end-to-end fashion, leading to highly specialized node\nembeddings. However, generating node embeddings that can be used to perform\nmultiple tasks (with performance comparable to single-task models) is an open\nproblem. We propose a novel meta-learning strategy capable of producing\nmulti-task node embeddings. Our method avoids the difficulties arising when\nlearning to perform multiple tasks concurrently by, instead, learning to\nquickly (i.e. with a few steps of gradient descent) adapt to multiple tasks\nsingularly. We show that the embeddings produced by our method can be used to\nperform multiple tasks with comparable or higher performance than classically\ntrained models. Our method is model-agnostic and task-agnostic, thus applicable\nto a wide variety of multi-task domains.\n", "versions": [{"version": "v1", "created": "Sat, 12 Dec 2020 08:36:47 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["Buffelli", "Davide", ""], ["Vandin", "Fabio", ""]]}, {"id": "2012.06757", "submitter": "Jiarong Xu", "authors": "Jiarong Xu, Yizhou Sun, Xin Jiang, Yanhao Wang, Yang Yang, Chunping\n  Wang, Jiangang Lu", "title": "Query-free Black-box Adversarial Attacks on Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Many graph-based machine learning models are known to be vulnerable to\nadversarial attacks, where even limited perturbations on input data can result\nin dramatic performance deterioration. Most existing works focus on moderate\nsettings in which the attacker is either aware of the model structure and\nparameters (white-box), or able to send queries to fetch model information. In\nthis paper, we propose a query-free black-box adversarial attack on graphs, in\nwhich the attacker has no knowledge of the target model and no query access to\nthe model. With the mere observation of the graph topology, the proposed attack\nstrategy flips a limited number of links to mislead the graph models. We prove\nthat the impact of the flipped links on the target model can be quantified by\nspectral changes, and thus be approximated using the eigenvalue perturbation\ntheory. Accordingly, we model the proposed attack strategy as an optimization\nproblem, and adopt a greedy algorithm to select the links to be flipped. Due to\nits simplicity and scalability, the proposed model is not only generic in\nvarious graph-based models, but can be easily extended when different knowledge\nlevels are accessible as well. Extensive experiments demonstrate the\neffectiveness and efficiency of the proposed model on various downstream tasks,\nas well as several different graph-based learning models.\n", "versions": [{"version": "v1", "created": "Sat, 12 Dec 2020 08:52:56 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["Xu", "Jiarong", ""], ["Sun", "Yizhou", ""], ["Jiang", "Xin", ""], ["Wang", "Yanhao", ""], ["Yang", "Yang", ""], ["Wang", "Chunping", ""], ["Lu", "Jiangang", ""]]}, {"id": "2012.06789", "submitter": "Saisubramaniam Gopalakrishnan", "authors": "Saisubramaniam Gopalakrishnan, Pranshu Ranjan Singh, Haytham Fayek,\n  Savitha Ramasamy, Arulmurugan Ambikapathi", "title": "Knowledge Capture and Replay for Continual Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks have shown promise in several domains, and the learned\ndata (task) specific information is implicitly stored in the network\nparameters. Extraction and utilization of encoded knowledge representations are\nvital when data is no longer available in the future, especially in a continual\nlearning scenario. In this work, we introduce {\\em flashcards}, which are\nvisual representations that {\\em capture} the encoded knowledge of a network as\na recursive function of predefined random image patterns. In a continual\nlearning scenario, flashcards help to prevent catastrophic forgetting and\nconsolidating knowledge of all the previous tasks. Flashcards need to be\nconstructed only before learning the subsequent task, and hence, independent of\nthe number of tasks trained before. We demonstrate the efficacy of flashcards\nin capturing learned knowledge representation (as an alternative to the\noriginal dataset) and empirically validate on a variety of continual learning\ntasks: reconstruction, denoising, task-incremental learning, and new-instance\nlearning classification, using several heterogeneous benchmark datasets.\nExperimental evidence indicates that: (i) flashcards as a replay strategy is {\n\\em task agnostic}, (ii) performs better than generative replay, and (iii) is\non par with episodic replay without additional memory overhead.\n", "versions": [{"version": "v1", "created": "Sat, 12 Dec 2020 11:24:45 GMT"}, {"version": "v2", "created": "Thu, 29 Apr 2021 14:17:52 GMT"}], "update_date": "2021-04-30", "authors_parsed": [["Gopalakrishnan", "Saisubramaniam", ""], ["Singh", "Pranshu Ranjan", ""], ["Fayek", "Haytham", ""], ["Ramasamy", "Savitha", ""], ["Ambikapathi", "Arulmurugan", ""]]}, {"id": "2012.06810", "submitter": "David Sanchez", "authors": "Alberto Blanco-Justicia, Josep Domingo-Ferrer, Sergio Mart\\'inez,\n  David S\\'anchez, Adrian Flanagan and Kuan Eeik Tan", "title": "Achieving Security and Privacy in Federated Learning Systems: Survey,\n  Research Challenges and Future Directions", "comments": "40 pages, 19 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated learning (FL) allows a server to learn a machine learning (ML)\nmodel across multiple decentralized clients that privately store their own\ntraining data. In contrast with centralized ML approaches, FL saves computation\nto the server and does not require the clients to outsource their private data\nto the server. However, FL is not free of issues. On the one hand, the model\nupdates sent by the clients at each training epoch might leak information on\nthe clients' private data. On the other hand, the model learnt by the server\nmay be subjected to attacks by malicious clients; these security attacks might\npoison the model or prevent it from converging. In this paper, we first examine\nsecurity and privacy attacks to FL and critically survey solutions proposed in\nthe literature to mitigate each attack. Afterwards, we discuss the difficulty\nof simultaneously achieving security and privacy protection. Finally, we sketch\nways to tackle this open problem and attain both security and privacy.\n", "versions": [{"version": "v1", "created": "Sat, 12 Dec 2020 13:23:56 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["Blanco-Justicia", "Alberto", ""], ["Domingo-Ferrer", "Josep", ""], ["Mart\u00ednez", "Sergio", ""], ["S\u00e1nchez", "David", ""], ["Flanagan", "Adrian", ""], ["Tan", "Kuan Eeik", ""]]}, {"id": "2012.06822", "submitter": "Markus Borg", "authors": "Markus Borg, Raja Ben Abdessalem, Shiva Nejati, Francois-Xavier\n  Jegeden, Donghwan Shin", "title": "Digital Twins Are Not Monozygotic -- Cross-Replicating ADAS Testing in\n  Two Industry-Grade Automotive Simulators", "comments": "To appear in the Proc. of the IEEE International Conference on\n  Software Testing, Verification and Validation (ICST) 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The increasing levels of software- and data-intensive driving automation call\nfor an evolution of automotive software testing. As a recommended practice of\nthe Verification and Validation (V&V) process of ISO/PAS 21448, a candidate\nstandard for safety of the intended functionality for road vehicles,\nsimulation-based testing has the potential to reduce both risks and costs.\nThere is a growing body of research on devising test automation techniques\nusing simulators for Advanced Driver-Assistance Systems (ADAS). However, how\nsimilar are the results if the same test scenarios are executed in different\nsimulators? We conduct a replication study of applying a Search-Based Software\nTesting (SBST) solution to a real-world ADAS (PeVi, a pedestrian vision\ndetection system) using two different commercial simulators, namely,\nTASS/Siemens PreScan and ESI Pro-SiVIC. Based on a minimalistic scene, we\ncompare critical test scenarios generated using our SBST solution in these two\nsimulators. We show that SBST can be used to effectively and efficiently\ngenerate critical test scenarios in both simulators, and the test results\nobtained from the two simulators can reveal several weaknesses of the ADAS\nunder test. However, executing the same test scenarios in the two simulators\nleads to notable differences in the details of the test outputs, in particular,\nrelated to (1) safety violations revealed by tests, and (2) dynamics of cars\nand pedestrians. Based on our findings, we recommend future V&V plans to\ninclude multiple simulators to support robust simulation-based testing and to\nbase test objectives on measures that are less dependant on the internals of\nthe simulators.\n", "versions": [{"version": "v1", "created": "Sat, 12 Dec 2020 14:00:33 GMT"}, {"version": "v2", "created": "Thu, 28 Jan 2021 08:55:23 GMT"}], "update_date": "2021-01-29", "authors_parsed": [["Borg", "Markus", ""], ["Abdessalem", "Raja Ben", ""], ["Nejati", "Shiva", ""], ["Jegeden", "Francois-Xavier", ""], ["Shin", "Donghwan", ""]]}, {"id": "2012.06845", "submitter": "Yifan Xu", "authors": "Yifan Xu, Pan Xu, Jianping Pan and Jun Tao", "title": "A Unified Model for the Two-stage Offline-then-Online Resource\n  Allocation", "comments": "Accepted by IJCAI 2020\n  (http://static.ijcai.org/2020-accepted_papers.html) and SOLE copyright holder\n  is IJCAI (International Joint Conferences on Artificial Intelligence), all\n  rights reserved", "journal-ref": "IJCAI 2020", "doi": "10.24963/ijcai.2020/581", "report-no": null, "categories": "cs.AI cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the popularity of the Internet, traditional offline resource allocation\nhas evolved into a new form, called online resource allocation. It features the\nonline arrivals of agents in the system and the real-time decision-making\nrequirement upon the arrival of each online agent. Both offline and online\nresource allocation have wide applications in various real-world matching\nmarkets ranging from ridesharing to crowdsourcing. There are some emerging\napplications such as rebalancing in bike sharing and trip-vehicle dispatching\nin ridesharing, which involve a two-stage resource allocation process. The\nprocess consists of an offline phase and another sequential online phase, and\nboth phases compete for the same set of resources. In this paper, we propose a\nunified model which incorporates both offline and online resource allocation\ninto a single framework. Our model assumes non-uniform and known arrival\ndistributions for online agents in the second online phase, which can be\nlearned from historical data. We propose a parameterized linear programming\n(LP)-based algorithm, which is shown to be at most a constant factor of $1/4$\nfrom the optimal. Experimental results on the real dataset show that our\nLP-based approaches outperform the LP-agnostic heuristics in terms of\nrobustness and effectiveness.\n", "versions": [{"version": "v1", "created": "Sat, 12 Dec 2020 15:55:13 GMT"}], "update_date": "2020-12-17", "authors_parsed": [["Xu", "Yifan", ""], ["Xu", "Pan", ""], ["Pan", "Jianping", ""], ["Tao", "Jun", ""]]}, {"id": "2012.06850", "submitter": "Yifan Xu", "authors": "Yifan Xu and Pan Xu", "title": "Trading the System Efficiency for the Income Equality of Drivers in\n  Rideshare", "comments": "Accepted by IJCAI2020\n  (http://static.ijcai.org/2020-accepted_papers.html) and SOLE copyright holder\n  is IJCAI (International Joint Conferences on Artificial Intelligence), all\n  rights reserved", "journal-ref": "IJCAI 2020", "doi": "10.24963/ijcai.2020/580", "report-no": null, "categories": "cs.AI cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Several scientific studies have reported the existence of the income gap\namong rideshare drivers based on demographic factors such as gender, age, race,\netc. In this paper, we study the income inequality among rideshare drivers due\nto discriminative cancellations from riders, and the tradeoff between the\nincome inequality (called fairness objective) with the system efficiency\n(called profit objective). We proposed an online bipartite-matching model where\nriders are assumed to arrive sequentially following a distribution known in\nadvance. The highlight of our model is the concept of acceptance rate between\nany pair of driver-rider types, where types are defined based on demographic\nfactors. Specially, we assume each rider can accept or cancel the driver\nassigned to her, each occurs with a certain probability which reflects the\nacceptance degree from the rider type towards the driver type. We construct a\nbi-objective linear program as a valid benchmark and propose two LP-based\nparameterized online algorithms. Rigorous online competitive ratio analysis is\noffered to demonstrate the flexibility and efficiency of our online algorithms\nin balancing the two conflicting goals, promotions of fairness and profit.\nExperimental results on a real-world dataset are provided as well, which\nconfirm our theoretical predictions.\n", "versions": [{"version": "v1", "created": "Sat, 12 Dec 2020 16:04:06 GMT"}], "update_date": "2020-12-17", "authors_parsed": [["Xu", "Yifan", ""], ["Xu", "Pan", ""]]}, {"id": "2012.06876", "submitter": "Utkarsh Uppal", "authors": "Utkarsh Uppal, Bharat Giddwani", "title": "Normalized Label Distribution: Towards Learning Calibrated, Adaptable\n  and Efficient Activation Maps", "comments": "Accepted in AAAI 2021 Workshop on \"Towards Robust, Secure and\n  Efficient Machine Learning\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The vulnerability of models to data aberrations and adversarial attacks\ninfluences their ability to demarcate distinct class boundaries efficiently.\nThe network's confidence and uncertainty play a pivotal role in weight\nadjustments and the extent of acknowledging such attacks. In this paper, we\naddress the trade-off between the accuracy and calibration potential of a\nclassification network. We study the significance of ground-truth distribution\nchanges on the performance and generalizability of various state-of-the-art\nnetworks and compare the proposed method's response to unanticipated attacks.\nFurthermore, we demonstrate the role of label-smoothing regularization and\nnormalization in yielding better generalizability and calibrated probability\ndistribution by proposing normalized soft labels to enhance the calibration of\nfeature maps. Subsequently, we substantiate our inference by translating\nconventional convolutions to padding based partial convolution to establish the\ntangible impact of corrections in reinforcing the performance and convergence\nrate. We graphically elucidate the implication of such variations with the\ncritical purpose of corroborating the reliability and reproducibility for\nmultiple datasets.\n", "versions": [{"version": "v1", "created": "Sat, 12 Dec 2020 17:54:01 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["Uppal", "Utkarsh", ""], ["Giddwani", "Bharat", ""]]}, {"id": "2012.06898", "submitter": "Jonathan Frankle", "authors": "Jonathan Frankle", "title": "Revisiting \"Qualitatively Characterizing Neural Network Optimization\n  Problems\"", "comments": "Workshop on Deep Learning and Information Geometry (NeurIPS 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We revisit and extend the experiments of Goodfellow et al. (2014), who showed\nthat - for then state-of-the-art networks - \"the objective function has a\nsimple, approximately convex shape\" along the linear path between\ninitialization and the trained weights. We do not find this to be the case for\nmodern networks on CIFAR-10 and ImageNet. Instead, although loss is roughly\nmonotonically non-increasing along this path, it remains high until close to\nthe optimum. In addition, training quickly becomes linearly separated from the\noptimum by loss barriers. We conclude that, although Goodfellow et al.'s\nfindings describe the \"relatively easy to optimize\" MNIST setting, behavior is\nqualitatively different in modern settings.\n", "versions": [{"version": "v1", "created": "Sat, 12 Dec 2020 20:01:33 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["Frankle", "Jonathan", ""]]}, {"id": "2012.06899", "submitter": "Ksenia Konyushkova", "authors": "Ksenia Konyushkova, Konrad Zolna, Yusuf Aytar, Alexander Novikov,\n  Scott Reed, Serkan Cabi, Nando de Freitas", "title": "Semi-supervised reward learning for offline reinforcement learning", "comments": "Accepted to Offline Reinforcement Learning Workshop at Neural\n  Information Processing Systems (2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In offline reinforcement learning (RL) agents are trained using a logged\ndataset. It appears to be the most natural route to attack real-life\napplications because in domains such as healthcare and robotics interactions\nwith the environment are either expensive or unethical. Training agents usually\nrequires reward functions, but unfortunately, rewards are seldom available in\npractice and their engineering is challenging and laborious. To overcome this,\nwe investigate reward learning under the constraint of minimizing human reward\nannotations. We consider two types of supervision: timestep annotations and\ndemonstrations. We propose semi-supervised learning algorithms that learn from\nlimited annotations and incorporate unlabelled data. In our experiments with a\nsimulated robotic arm, we greatly improve upon behavioural cloning and closely\napproach the performance achieved with ground truth rewards. We further\ninvestigate the relationship between the quality of the reward model and the\nfinal policies. We notice, for example, that the reward models do not need to\nbe perfect to result in useful policies.\n", "versions": [{"version": "v1", "created": "Sat, 12 Dec 2020 20:06:15 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["Konyushkova", "Ksenia", ""], ["Zolna", "Konrad", ""], ["Aytar", "Yusuf", ""], ["Novikov", "Alexander", ""], ["Reed", "Scott", ""], ["Cabi", "Serkan", ""], ["de Freitas", "Nando", ""]]}, {"id": "2012.06901", "submitter": "Yao Zhou", "authors": "Yao Zhou, Jianpeng Xu, Jun Wu, Zeinab Taghavi Nasrabadi, Evren\n  Korpeoglu, Kannan Achan, Jingrui He", "title": "GAN-based Recommendation with Positive-Unlabeled Sampling", "comments": "12 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recommender systems are popular tools for information retrieval tasks on a\nlarge variety of web applications and personalized products. In this work, we\npropose a Generative Adversarial Network based recommendation framework using a\npositive-unlabeled sampling strategy. Specifically, we utilize the generator to\nlearn the continuous distribution of user-item tuples and design the\ndiscriminator to be a binary classifier that outputs the relevance score\nbetween each user and each item. Meanwhile, positive-unlabeled sampling is\napplied in the learning procedure of the discriminator. Theoretical bounds\nregarding positive-unlabeled sampling and optimalities of convergence for the\ndiscriminators and the generators are provided. We show the effectiveness and\nefficiency of our framework on three publicly accessible data sets with eight\nranking-based evaluation metrics in comparison with thirteen popular baselines.\n", "versions": [{"version": "v1", "created": "Sat, 12 Dec 2020 20:08:51 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["Zhou", "Yao", ""], ["Xu", "Jianpeng", ""], ["Wu", "Jun", ""], ["Nasrabadi", "Zeinab Taghavi", ""], ["Korpeoglu", "Evren", ""], ["Achan", "Kannan", ""], ["He", "Jingrui", ""]]}, {"id": "2012.06907", "submitter": "Wang Zhou", "authors": "Wang Zhou, Levente J. Klein, Siyuan Lu", "title": "PAIRS AutoGeo: an Automated Machine Learning Framework for Massive\n  Geospatial Data", "comments": null, "journal-ref": "IEEE International Conference on Big Data (IEEE BigData 2020)", "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An automated machine learning framework for geospatial data named PAIRS\nAutoGeo is introduced on IBM PAIRS Geoscope big data and analytics platform.\nThe framework simplifies the development of industrial machine learning\nsolutions leveraging geospatial data to the extent that the user inputs are\nminimized to merely a text file containing labeled GPS coordinates. PAIRS\nAutoGeo automatically gathers required data at the location coordinates,\nassembles the training data, performs quality check, and trains multiple\nmachine learning models for subsequent deployment. The framework is validated\nusing a realistic industrial use case of tree species classification.\nOpen-source tree species data are used as the input to train a random forest\nclassifier and a modified ResNet model for 10-way tree species classification\nbased on aerial imagery, which leads to an accuracy of $59.8\\%$ and $81.4\\%$,\nrespectively. This use case exemplifies how PAIRS AutoGeo enables users to\nleverage machine learning without extensive geospatial expertise.\n", "versions": [{"version": "v1", "created": "Sat, 12 Dec 2020 21:12:41 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["Zhou", "Wang", ""], ["Klein", "Levente J.", ""], ["Lu", "Siyuan", ""]]}, {"id": "2012.06943", "submitter": "Snehasish Mukherjee", "authors": "Snehasish Mukherjee, Phaniram Sayapaneni, Shankar Subramanya", "title": "Discriminative Pre-training for Low Resource Title Compression in\n  Conversational Grocery", "comments": "To be published in Proceedings of ACM SIGIR Workshop on eCommerce\n  (SIGIR eCom 20) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  The ubiquity of smart voice assistants has made conversational shopping\ncommonplace. This is especially true for low consideration segments like\ngrocery. A central problem in conversational grocery is the automatic\ngeneration of short product titles that can be read out fast during a\nconversation. Several supervised models have been proposed in the literature\nthat leverage manually labeled datasets and additional product features to\ngenerate short titles automatically. However, obtaining large amounts of\nlabeled data is expensive and most grocery item pages are not as feature-rich\nas other categories. To address this problem we propose a pre-training based\nsolution that makes use of unlabeled data to learn contextual product\nrepresentations which can then be fine-tuned to obtain better title compression\neven in a low resource setting. We use a self-attentive BiLSTM encoder network\nwith a time distributed softmax layer for the title compression task. We\novercome the vocabulary mismatch problem by using a hybrid embedding layer that\ncombines pre-trained word embeddings with trainable character level\nconvolutions. We pre-train this network as a discriminator on a replaced-token\ndetection task over a large number of unlabeled grocery product titles.\nFinally, we fine tune this network, without any modifications, with a small\nlabeled dataset for the title compression task. Experiments on Walmart's online\ngrocery catalog show our model achieves performance comparable to\nstate-of-the-art models like BERT and XLNet. When fine tuned on all of the\navailable training data our model attains an F1 score of 0.8558 which lags the\nbest performing model, BERT-Base, by 2.78% and XLNet by 0.28% only, while using\n55 times lesser parameters than both. Further, when allowed to fine tune on 5%\nof the training data only, our model outperforms BERT-Base by 24.3% in F1\nscore.\n", "versions": [{"version": "v1", "created": "Sun, 13 Dec 2020 02:34:56 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["Mukherjee", "Snehasish", ""], ["Sayapaneni", "Phaniram", ""], ["Subramanya", "Shankar", ""]]}, {"id": "2012.06954", "submitter": "Dmitry Kazhdan", "authors": "Dmitry Kazhdan, Botty Dimanov, Mateja Jamnik, Pietro Li\\`o", "title": "MEME: Generating RNN Model Explanations via Model Extraction", "comments": "Presented at the HAMLETS workshop at the 34th Conference on Neural\n  Information Processing Systems (NeurIPS 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recurrent Neural Networks (RNNs) have achieved remarkable performance on a\nrange of tasks. A key step to further empowering RNN-based approaches is\nimproving their explainability and interpretability. In this work we present\nMEME: a model extraction approach capable of approximating RNNs with\ninterpretable models represented by human-understandable concepts and their\ninteractions. We demonstrate how MEME can be applied to two multivariate,\ncontinuous data case studies: Room Occupation Prediction, and In-Hospital\nMortality Prediction. Using these case-studies, we show how our extracted\nmodels can be used to interpret RNNs both locally and globally, by\napproximating RNN decision-making via interpretable concept interactions.\n", "versions": [{"version": "v1", "created": "Sun, 13 Dec 2020 04:00:08 GMT"}], "update_date": "2021-04-15", "authors_parsed": [["Kazhdan", "Dmitry", ""], ["Dimanov", "Botty", ""], ["Jamnik", "Mateja", ""], ["Li\u00f2", "Pietro", ""]]}, {"id": "2012.06968", "submitter": "Kai Zhang", "authors": "Kai Zhang, Hao Qian, Qing Cui, Qi Liu, Longfei Li, Jun Zhou, Jianhui\n  Ma, Enhong Chen", "title": "Multi-Interactive Attention Network for Fine-grained Feature Learning in\n  CTR Prediction", "comments": "9 pages, 6 figures, WSDM2021, accepted", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In the Click-Through Rate (CTR) prediction scenario, user's sequential\nbehaviors are well utilized to capture the user interest in the recent\nliterature. However, despite being extensively studied, these sequential\nmethods still suffer from three limitations. First, existing methods mostly\nutilize attention on the behavior of users, which is not always suitable for\nCTR prediction, because users often click on new products that are irrelevant\nto any historical behaviors. Second, in the real scenario, there exist numerous\nusers that have operations a long time ago, but turn relatively inactive in\nrecent times. Thus, it is hard to precisely capture user's current preferences\nthrough early behaviors. Third, multiple representations of user's historical\nbehaviors in different feature subspaces are largely ignored. To remedy these\nissues, we propose a Multi-Interactive Attention Network (MIAN) to\ncomprehensively extract the latent relationship among all kinds of fine-grained\nfeatures (e.g., gender, age and occupation in user-profile). Specifically, MIAN\ncontains a Multi-Interactive Layer (MIL) that integrates three local\ninteraction modules to capture multiple representations of user preference\nthrough sequential behaviors and simultaneously utilize the fine-grained\nuser-specific as well as context information. In addition, we design a Global\nInteraction Module (GIM) to learn the high-order interactions and balance the\ndifferent impacts of multiple features. Finally, Offline experiment results\nfrom three datasets, together with an Online A/B test in a large-scale\nrecommendation system, demonstrate the effectiveness of our proposed approach.\n", "versions": [{"version": "v1", "created": "Sun, 13 Dec 2020 05:46:19 GMT"}, {"version": "v2", "created": "Sun, 7 Mar 2021 13:29:34 GMT"}], "update_date": "2021-03-09", "authors_parsed": [["Zhang", "Kai", ""], ["Qian", "Hao", ""], ["Cui", "Qing", ""], ["Liu", "Qi", ""], ["Li", "Longfei", ""], ["Zhou", "Jun", ""], ["Ma", "Jianhui", ""], ["Chen", "Enhong", ""]]}, {"id": "2012.06977", "submitter": "Wenhao Wu", "authors": "Wenhao Wu, Dongliang He, Tianwei Lin, Fu Li, Chuang Gan, Errui Ding", "title": "MVFNet: Multi-View Fusion Network for Efficient Video Recognition", "comments": "Accepted by AAAI2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conventionally, spatiotemporal modeling network and its complexity are the\ntwo most concentrated research topics in video action recognition. Existing\nstate-of-the-art methods have achieved excellent accuracy regardless of the\ncomplexity meanwhile efficient spatiotemporal modeling solutions are slightly\ninferior in performance. In this paper, we attempt to acquire both efficiency\nand effectiveness simultaneously. First of all, besides traditionally treating\nH x W x T video frames as space-time signal (viewing from the Height-Width\nspatial plane), we propose to also model video from the other two Height-Time\nand Width-Time planes, to capture the dynamics of video thoroughly. Secondly,\nour model is designed based on 2D CNN backbones and model complexity is well\nkept in mind by design. Specifically, we introduce a novel multi-view fusion\n(MVF) module to exploit video dynamics using separable convolution for\nefficiency. It is a plug-and-play module and can be inserted into off-the-shelf\n2D CNNs to form a simple yet effective model called MVFNet. Moreover, MVFNet\ncan be thought of as a generalized video modeling framework and it can\nspecialize to be existing methods such as C2D, SlowOnly, and TSM under\ndifferent settings. Extensive experiments are conducted on popular benchmarks\n(i.e., Something-Something V1 & V2, Kinetics, UCF-101, and HMDB-51) to show its\nsuperiority. The proposed MVFNet can achieve state-of-the-art performance with\n2D CNN's complexity.\n", "versions": [{"version": "v1", "created": "Sun, 13 Dec 2020 06:34:18 GMT"}, {"version": "v2", "created": "Tue, 5 Jan 2021 06:09:48 GMT"}], "update_date": "2021-01-06", "authors_parsed": [["Wu", "Wenhao", ""], ["He", "Dongliang", ""], ["Lin", "Tianwei", ""], ["Li", "Fu", ""], ["Gan", "Chuang", ""], ["Ding", "Errui", ""]]}, {"id": "2012.06985", "submitter": "Raviteja Vemulapalli", "authors": "Xiangyun Zhao, Raviteja Vemulapalli, Philip Mansfield, Boqing Gong,\n  Bradley Green, Lior Shapira, Ying Wu", "title": "Contrastive Learning for Label-Efficient Semantic Segmentation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Collecting labeled data for the task of semantic segmentation is expensive\nand time-consuming, as it requires dense pixel-level annotations. While recent\nConvolutional Neural Network (CNN) based semantic segmentation approaches have\nachieved impressive results by using large amounts of labeled training data,\ntheir performance drops significantly as the amount of labeled data decreases.\nThis happens because deep CNNs trained with the de facto cross-entropy loss can\neasily overfit to small amounts of labeled data. To address this issue, we\npropose a simple and effective contrastive learning-based training strategy in\nwhich we first pretrain the network using a pixel-wise, label-based contrastive\nloss, and then fine-tune it using the cross-entropy loss. This approach\nincreases intra-class compactness and inter-class separability, thereby\nresulting in a better pixel classifier. We demonstrate the effectiveness of the\nproposed training strategy using the Cityscapes and PASCAL VOC 2012\nsegmentation datasets. Our results show that pretraining with the proposed\ncontrastive loss results in large performance gains (more than 20% absolute\nimprovement in some settings) when the amount of labeled data is limited. In\nmany settings, the proposed contrastive pretraining strategy, which does not\nuse any additional data, is able to match or outperform the widely-used\nImageNet pretraining strategy that uses more than a million additional labeled\nimages.\n", "versions": [{"version": "v1", "created": "Sun, 13 Dec 2020 07:05:39 GMT"}, {"version": "v2", "created": "Wed, 23 Dec 2020 05:00:28 GMT"}, {"version": "v3", "created": "Tue, 6 Apr 2021 00:33:07 GMT"}], "update_date": "2021-04-07", "authors_parsed": [["Zhao", "Xiangyun", ""], ["Vemulapalli", "Raviteja", ""], ["Mansfield", "Philip", ""], ["Gong", "Boqing", ""], ["Green", "Bradley", ""], ["Shapira", "Lior", ""], ["Wu", "Ying", ""]]}, {"id": "2012.07000", "submitter": "Siyi Ma", "authors": "Dandan Song, Siyi Ma, Zhanchen Sun, Sicheng Yang, Lejian Liao", "title": "KVL-BERT: Knowledge Enhanced Visual-and-Linguistic BERT for Visual\n  Commonsense Reasoning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reasoning is a critical ability towards complete visual understanding. To\ndevelop machine with cognition-level visual understanding and reasoning\nabilities, the visual commonsense reasoning (VCR) task has been introduced. In\nVCR, given a challenging question about an image, a machine must answer\ncorrectly and then provide a rationale justifying its answer. The methods\nadopting the powerful BERT model as the backbone for learning joint\nrepresentation of image content and natural language have shown promising\nimprovements on VCR. However, none of the existing methods have utilized\ncommonsense knowledge in visual commonsense reasoning, which we believe will be\ngreatly helpful in this task. With the support of commonsense knowledge,\ncomplex questions even if the required information is not depicted in the image\ncan be answered with cognitive reasoning. Therefore, we incorporate commonsense\nknowledge into the cross-modal BERT, and propose a novel Knowledge Enhanced\nVisual-and-Linguistic BERT (KVL-BERT for short) model. Besides taking visual\nand linguistic contents as input, external commonsense knowledge extracted from\nConceptNet is integrated into the multi-layer Transformer. In order to reserve\nthe structural information and semantic representation of the original\nsentence, we propose using relative position embedding and mask-self-attention\nto weaken the effect between the injected commonsense knowledge and other\nunrelated components in the input sequence. Compared to other task-specific\nmodels and general task-agnostic pre-training models, our KVL-BERT outperforms\nthem by a large margin.\n", "versions": [{"version": "v1", "created": "Sun, 13 Dec 2020 08:22:33 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["Song", "Dandan", ""], ["Ma", "Siyi", ""], ["Sun", "Zhanchen", ""], ["Yang", "Sicheng", ""], ["Liao", "Lejian", ""]]}, {"id": "2012.07004", "submitter": "Yutai Hou", "authors": "Yutai Hou, Sanyuan Chen, Wanxiang Che, Cheng Chen, Ting Liu", "title": "C2C-GenDA: Cluster-to-Cluster Generation for Data Augmentation of Slot\n  Filling", "comments": "Accepted by AAAI-2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Slot filling, a fundamental module of spoken language understanding, often\nsuffers from insufficient quantity and diversity of training data. To remedy\nthis, we propose a novel Cluster-to-Cluster generation framework for Data\nAugmentation (DA), named C2C-GenDA. It enlarges the training set by\nreconstructing existing utterances into alternative expressions while keeping\nsemantic. Different from previous DA works that reconstruct utterances one by\none independently, C2C-GenDA jointly encodes multiple existing utterances of\nthe same semantics and simultaneously decodes multiple unseen expressions.\nJointly generating multiple new utterances allows to consider the relations\nbetween generated instances and encourages diversity. Besides, encoding\nmultiple existing utterances endows C2C with a wider view of existing\nexpressions, helping to reduce generation that duplicates existing data.\nExperiments on ATIS and Snips datasets show that instances augmented by\nC2C-GenDA improve slot filling by 7.99 (11.9%) and 5.76 (13.6%) F-scores\nrespectively, when there are only hundreds of training utterances.\n", "versions": [{"version": "v1", "created": "Sun, 13 Dec 2020 08:35:37 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["Hou", "Yutai", ""], ["Chen", "Sanyuan", ""], ["Che", "Wanxiang", ""], ["Chen", "Cheng", ""], ["Liu", "Ting", ""]]}, {"id": "2012.07011", "submitter": "Ziyue Qiao", "authors": "Ziyue Qiao, Zhiyuan Ning, Yi Du, Yuanchun Zhou", "title": "Context-Enhanced Entity and Relation Embedding for Knowledge Graph\n  Completion", "comments": "2 pages, accepted by AAAI-21 student abstract and poster program", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most researches for knowledge graph completion learn representations of\nentities and relations to predict missing links in incomplete knowledge graphs.\nHowever, these methods fail to take full advantage of both the contextual\ninformation of entity and relation. Here, we extract contexts of entities and\nrelations from the triplets which they compose. We propose a model named AggrE,\nwhich conducts efficient aggregations respectively on entity context and\nrelation context in multi-hops, and learns context-enhanced entity and relation\nembeddings for knowledge graph completion. The experiment results show that\nAggrE is competitive to existing models.\n", "versions": [{"version": "v1", "created": "Sun, 13 Dec 2020 09:20:42 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["Qiao", "Ziyue", ""], ["Ning", "Zhiyuan", ""], ["Du", "Yi", ""], ["Zhou", "Yuanchun", ""]]}, {"id": "2012.07023", "submitter": "Nghi D. Q. Bui", "authors": "Nghi D. Q. Bui, Yijun Yu, Lingxiao Jiang", "title": "InferCode: Self-Supervised Learning of Code Representations by\n  Predicting Subtrees", "comments": "Accepted at ICSE 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.AI cs.LG cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Building deep learning models on source code has found many successful\nsoftware engineering applications, such as code search, code comment\ngeneration, bug detection, code migration, and so on. Current learning\ntechniques, however, have a major drawback that these models are mostly trained\non datasets labeled for particular downstream tasks, and code representations\nmay not be suitable for other tasks. While some techniques produce\nrepresentations from unlabeled code, they are far from satisfactory when\napplied to downstream tasks. Although certain techniques generate\nrepresentations from unlabeled code when applied to downstream tasks they are\nfar from satisfactory. This paper proposes InferCode to overcome the limitation\nby adapting the self-supervised learning mechanism to build source code model.\nThe key novelty lies in training code representations by predicting\nautomatically identified subtrees from the context of the ASTs. Subtrees in\nASTs are treated with InferCode as the labels for training code representations\nwithout any human labeling effort or the overhead of expensive graph\nconstruction, and the trained representations are no longer tied to any\nspecific downstream tasks or code units. We trained an InferCode model instance\nusing the Tree-based CNN as the encoder of a large set of Java code and applied\nit to downstream unsupervised tasks such as code clustering, code clone\ndetection, cross-language code search or reused under a transfer learning\nscheme to continue training the model weights for supervised tasks such as code\nclassification and method name prediction. Compared to previous code learning\ntechniques applied to the same downstream tasks, such as Code2Vec, Code2Seq,\nASTNN, higher performance results are achieved using our pre-trained InferCode\nmodel with a significant margin for most tasks including those involving\ndifferent programming languages.\n", "versions": [{"version": "v1", "created": "Sun, 13 Dec 2020 10:33:41 GMT"}, {"version": "v2", "created": "Tue, 15 Dec 2020 16:37:23 GMT"}], "update_date": "2020-12-16", "authors_parsed": [["Bui", "Nghi D. Q.", ""], ["Yu", "Yijun", ""], ["Jiang", "Lingxiao", ""]]}, {"id": "2012.07119", "submitter": "Giang Dao", "authors": "Giang Dao and Minwoo Lee", "title": "Demystifying Deep Neural Networks Through Interpretation: A Survey", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern deep learning algorithms tend to optimize an objective metric, such as\nminimize a cross entropy loss on a training dataset, to be able to learn. The\nproblem is that the single metric is an incomplete description of the real\nworld tasks. The single metric cannot explain why the algorithm learn. When an\nerroneous happens, the lack of interpretability causes a hardness of\nunderstanding and fixing the error. Recently, there are works done to tackle\nthe problem of interpretability to provide insights into neural networks\nbehavior and thought process. The works are important to identify potential\nbias and to ensure algorithm fairness as well as expected performance.\n", "versions": [{"version": "v1", "created": "Sun, 13 Dec 2020 17:56:41 GMT"}, {"version": "v2", "created": "Tue, 5 Jan 2021 20:41:36 GMT"}], "update_date": "2021-01-07", "authors_parsed": [["Dao", "Giang", ""], ["Lee", "Minwoo", ""]]}, {"id": "2012.07121", "submitter": "Luis A. Pineda", "authors": "Luis A. Pineda, No\\'e Hern\\'andez, Arturo Rodr\\'iguez, Ricardo Cruz\n  and Gibr\\'an Fuentes", "title": "Deliberative and Conceptual Inference in Service Robots", "comments": "31 pages, 7 figures and 2 appendices", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Service robots need to reason to support people in daily life situations.\nReasoning is an expensive resource that should be used on demand whenever the\nexpectations of the robot do not match the situation of the world and the\nexecution of the task is broken down; in such scenarios the robot must perform\nthe common sense daily life inference cycle consisting on diagnosing what\nhappened, deciding what to do about it, and inducing and executing a plan,\nrecurring in such behavior until the service task can be resumed. Here we\nexamine two strategies to implement this cycle: (1) a pipe-line strategy\ninvolving abduction, decision-making and planning, which we call deliberative\ninference and (2) the use of the knowledge and preferences stored in the\nrobot's knowledge-base, which we call conceptual inference. The former involves\nan explicit definition of a problem space that is explored through heuristic\nsearch, and the latter is based on conceptual knowledge including the human\nuser preferences, and its representation requires a non-monotonic\nknowledge-based system. We compare the strengths and limitations of both\napproaches. We also describe a service robot conceptual model and architecture\ncapable of supporting the daily life inference cycle during the execution of a\nrobotics service task. The model is centered in the declarative specification\nand interpretation of robot's communication and task structure. We also show\nthe implementation of this framework in the fully autonomous robot Golem-III.\nThe framework is illustrated with two demonstration scenarios.\n", "versions": [{"version": "v1", "created": "Sun, 13 Dec 2020 18:30:15 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["Pineda", "Luis A.", ""], ["Hern\u00e1ndez", "No\u00e9", ""], ["Rodr\u00edguez", "Arturo", ""], ["Cruz", "Ricardo", ""], ["Fuentes", "Gibr\u00e1n", ""]]}, {"id": "2012.07138", "submitter": "Hongming Zhang", "authors": "Hongming Zhang, Yintong Huo, Xinran Zhao, Yangqiu Song, Dan Roth", "title": "Learning Contextual Causality from Time-consecutive Images", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.CV", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Causality knowledge is crucial for many artificial intelligence systems.\nConventional textual-based causality knowledge acquisition methods typically\nrequire laborious and expensive human annotations. As a result, their scale is\noften limited. Moreover, as no context is provided during the annotation, the\nresulting causality knowledge records (e.g., ConceptNet) typically do not take\nthe context into consideration. To explore a more scalable way of acquiring\ncausality knowledge, in this paper, we jump out of the textual domain and\ninvestigate the possibility of learning contextual causality from the visual\nsignal. Compared with pure text-based approaches, learning causality from the\nvisual signal has the following advantages: (1) Causality knowledge belongs to\nthe commonsense knowledge, which is rarely expressed in the text but rich in\nvideos; (2) Most events in the video are naturally time-ordered, which provides\na rich resource for us to mine causality knowledge from; (3) All the objects in\nthe video can be used as context to study the contextual property of causal\nrelations. In detail, we first propose a high-quality dataset Vis-Causal and\nthen conduct experiments to demonstrate that with good language and visual\nrepresentation models as well as enough training signals, it is possible to\nautomatically discover meaningful causal knowledge from the videos. Further\nanalysis also shows that the contextual property of causal relations indeed\nexists, taking which into consideration might be crucial if we want to use the\ncausality knowledge in real applications, and the visual signal could serve as\na good resource for learning such contextual causality.\n", "versions": [{"version": "v1", "created": "Sun, 13 Dec 2020 20:24:48 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["Zhang", "Hongming", ""], ["Huo", "Yintong", ""], ["Zhao", "Xinran", ""], ["Song", "Yangqiu", ""], ["Roth", "Dan", ""]]}, {"id": "2012.07172", "submitter": "Taylor Webb", "authors": "Ishan Sinha, Taylor W. Webb, Jonathan D. Cohen", "title": "A Memory-Augmented Neural Network Model of Abstract Rule Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Human intelligence is characterized by a remarkable ability to infer abstract\nrules from experience and apply these rules to novel domains. As such,\ndesigning neural network algorithms with this capacity is an important step\ntoward the development of deep learning systems with more human-like\nintelligence. However, doing so is a major outstanding challenge, one that some\nargue will require neural networks to use explicit symbol-processing\nmechanisms. In this work, we focus on neural networks' capacity for arbitrary\nrole-filler binding, the ability to associate abstract \"roles\" to\ncontext-specific \"fillers,\" which many have argued is an important mechanism\nunderlying the ability to learn and apply rules abstractly. Using a simplified\nversion of Raven's Progressive Matrices, a hallmark test of human intelligence,\nwe introduce a sequential formulation of a visual problem-solving task that\nrequires this form of binding. Further, we introduce the Emergent Symbol\nBinding Network (ESBN), a recurrent neural network model that learns to use an\nexternal memory as a binding mechanism. This mechanism enables symbol-like\nvariable representations to emerge through the ESBN's training process without\nthe need for explicit symbol-processing machinery. We empirically demonstrate\nthat the ESBN successfully learns the underlying abstract rule structure of our\ntask and perfectly generalizes this rule structure to novel fillers.\n", "versions": [{"version": "v1", "created": "Sun, 13 Dec 2020 22:40:07 GMT"}, {"version": "v2", "created": "Tue, 15 Dec 2020 03:35:19 GMT"}], "update_date": "2020-12-16", "authors_parsed": [["Sinha", "Ishan", ""], ["Webb", "Taylor W.", ""], ["Cohen", "Jonathan D.", ""]]}, {"id": "2012.07179", "submitter": "Harish Naik", "authors": "Harish Naik, Gy\\\"orgy Tur\\'an", "title": "Explanation from Specification", "comments": "8 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.HC stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Explainable components in XAI algorithms often come from a familiar set of\nmodels, such as linear models or decision trees. We formulate an approach where\nthe type of explanation produced is guided by a specification. Specifications\nare elicited from the user, possibly using interaction with the user and\ncontributions from other areas. Areas where a specification could be obtained\ninclude forensic, medical, and scientific applications. Providing a menu of\npossible types of specifications in an area is an exploratory knowledge\nrepresentation and reasoning task for the algorithm designer, aiming at\nunderstanding the possibilities and limitations of efficiently computable modes\nof explanations. Two examples are discussed: explanations for Bayesian networks\nusing the theory of argumentation, and explanations for graph neural networks.\nThe latter case illustrates the possibility of having a representation\nformalism available to the user for specifying the type of explanation\nrequested, for example, a chemical query language for classifying molecules.\nThe approach is motivated by a theory of explanation in the philosophy of\nscience, and it is related to current questions in the philosophy of science on\nthe role of machine learning.\n", "versions": [{"version": "v1", "created": "Sun, 13 Dec 2020 23:27:48 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["Naik", "Harish", ""], ["Tur\u00e1n", "Gy\u00f6rgy", ""]]}, {"id": "2012.07188", "submitter": "Thomas Bartz-Beielstein", "authors": "Thomas Bartz-Beielstein and Frederik Rehbach and Olaf Mersmann and Eva\n  Bartz", "title": "Hospital Capacity Planning Using Discrete Event Simulation Under Special\n  Consideration of the COVID-19 Pandemic", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP cs.AI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  We present a resource-planning tool for hospitals under special consideration\nof the COVID-19 pandemic, called babsim.hospital. It provides many advantages\nfor crisis teams, e.g., comparison with their own local planning, simulation of\nlocal events, simulation of several scenarios (worst / best case). There are\nbenefits for medical professionals, e.g, analysis of the pandemic at local,\nregional, state and federal level, the consideration of special risk groups,\ntools for validating the length of stays and transition probabilities. Finally,\nthere are potential advantages for administration, management, e.g., assessment\nof the situation of individual hospitals taking local events into account,\nconsideration of relevant resources such as beds, ventilators, rooms,\nprotective clothing, and personnel planning, e.g., medical and nursing staff.\nbabsim.hospital combines simulation, optimization, statistics, and artificial\nintelligence processes in a very efficient way. The core is a discrete,\nevent-based simulation model.\n", "versions": [{"version": "v1", "created": "Mon, 14 Dec 2020 00:17:26 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["Bartz-Beielstein", "Thomas", ""], ["Rehbach", "Frederik", ""], ["Mersmann", "Olaf", ""], ["Bartz", "Eva", ""]]}, {"id": "2012.07195", "submitter": "Qi Zhang", "authors": "Qi Zhang, Edmund H. Durfee, Satinder Singh", "title": "Efficient Querying for Cooperative Probabilistic Commitments", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Multiagent systems can use commitments as the core of a general coordination\ninfrastructure, supporting both cooperative and non-cooperative interactions.\nAgents whose objectives are aligned, and where one agent can help another\nachieve greater reward by sacrificing some of its own reward, should choose a\ncooperative commitment to maximize their joint reward. We present a solution to\nthe problem of how cooperative agents can efficiently find an (approximately)\noptimal commitment by querying about carefully-selected commitment choices. We\nprove structural properties of the agents' values as functions of the\nparameters of the commitment specification, and develop a greedy method for\ncomposing a query with provable approximation bounds, which we empirically show\ncan find nearly optimal commitments in a fraction of the time methods that lack\nour insights require.\n", "versions": [{"version": "v1", "created": "Mon, 14 Dec 2020 00:47:09 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["Zhang", "Qi", ""], ["Durfee", "Edmund H.", ""], ["Singh", "Satinder", ""]]}, {"id": "2012.07219", "submitter": "Mingqi Yang", "authors": "Mingqi Yang, Yanming Shen, Heng Qi, Baocai Yin", "title": "Breaking the Expressive Bottlenecks of Graph Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, the Weisfeiler-Lehman (WL) graph isomorphism test was used to\nmeasure the expressiveness of graph neural networks (GNNs), showing that the\nneighborhood aggregation GNNs were at most as powerful as 1-WL test in\ndistinguishing graph structures. There were also improvements proposed in\nanalogy to $k$-WL test ($k>1$). However, the aggregators in these GNNs are far\nfrom injective as required by the WL test, and suffer from weak distinguishing\nstrength, making it become expressive bottlenecks. In this paper, we improve\nthe expressiveness by exploring powerful aggregators. We reformulate\naggregation with the corresponding aggregation coefficient matrix, and then\nsystematically analyze the requirements of the aggregation coefficient matrix\nfor building more powerful aggregators and even injective aggregators. It can\nalso be viewed as the strategy for preserving the rank of hidden features, and\nimplies that basic aggregators correspond to a special case of low-rank\ntransformations. We also show the necessity of applying nonlinear units ahead\nof aggregation, which is different from most aggregation-based GNNs. Based on\nour theoretical analysis, we develop two GNN layers, ExpandingConv and\nCombConv. Experimental results show that our models significantly boost\nperformance, especially for large and densely connected graphs.\n", "versions": [{"version": "v1", "created": "Mon, 14 Dec 2020 02:36:46 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["Yang", "Mingqi", ""], ["Shen", "Yanming", ""], ["Qi", "Heng", ""], ["Yin", "Baocai", ""]]}, {"id": "2012.07228", "submitter": "Lei Li", "authors": "Lei Li, Minghe Xue, Huanhuan Chen, Xindong Wu", "title": "Trustworthy Preference Completion in Social Choice", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  As from time to time it is impractical to ask agents to provide linear orders\nover all alternatives, for these partial rankings it is necessary to conduct\npreference completion. Specifically, the personalized preference of each agent\nover all the alternatives can be estimated with partial rankings from\nneighboring agents over subsets of alternatives. However, since the agents'\nrankings are nondeterministic, where they may provide rankings with noise, it\nis necessary and important to conduct the trustworthy preference completion.\nHence, in this paper firstly, a trust-based anchor-kNN algorithm is proposed to\nfind $k$-nearest trustworthy neighbors of the agent with trust-oriented\nKendall-Tau distances, which will handle the cases when an agent exhibits\nirrational behaviors or provides only noisy rankings. Then, for alternative\npairs, a bijection can be built from the ranking space to the preference space,\nand its certainty and conflict can be evaluated based on a well-built\nstatistical measurement Probability-Certainty Density Function. Therefore, a\ncertain common voting rule for the first $k$ trustworthy neighboring agents\nbased on certainty and conflict can be taken to conduct the trustworthy\npreference completion. The properties of the proposed certainty and conflict\nhave been studied empirically, and the proposed approach has been\nexperimentally validated compared to state-of-arts approaches with several data\nsets.\n", "versions": [{"version": "v1", "created": "Mon, 14 Dec 2020 03:03:13 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["Li", "Lei", ""], ["Xue", "Minghe", ""], ["Chen", "Huanhuan", ""], ["Wu", "Xindong", ""]]}, {"id": "2012.07231", "submitter": "Weijie Zheng", "authors": "Benjamin Doerr, Weijie Zheng", "title": "Theoretical Analyses of Multi-Objective Evolutionary Algorithms on\n  Multi-Modal Objectives", "comments": "To appear at AAAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Previous theory work on multi-objective evolutionary algorithms considers\nmostly easy problems that are composed of unimodal objectives. This paper takes\na first step towards a deeper understanding of how evolutionary algorithms\nsolve multi-modal multi-objective problems. We propose the OneJumpZeroJump\nproblem, a bi-objective problem whose single objectives are isomorphic to the\nclassic jump functions benchmark. We prove that the simple evolutionary\nmulti-objective optimizer (SEMO) cannot compute the full Pareto front. In\ncontrast, for all problem sizes~$n$ and all jump sizes $k \\in [4..\\frac n2 -\n1]$, the global SEMO (GSEMO) covers the Pareto front in $\\Theta((n-2k)n^{k})$\niterations in expectation. To improve the performance, we combine the GSEMO\nwith two approaches, a heavy-tailed mutation operator and a stagnation\ndetection strategy, that showed advantages in single-objective multi-modal\nproblems. Runtime improvements of asymptotic order at least $k^{\\Omega(k)}$ are\nshown for both strategies. Our experiments verify the {substantial} runtime\ngains already for moderate problem sizes. Overall, these results show that the\nideas recently developed for single-objective evolutionary algorithms can be\neffectively employed also in multi-objective optimization.\n", "versions": [{"version": "v1", "created": "Mon, 14 Dec 2020 03:07:39 GMT"}, {"version": "v2", "created": "Wed, 16 Dec 2020 03:26:29 GMT"}, {"version": "v3", "created": "Mon, 19 Apr 2021 12:34:00 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Doerr", "Benjamin", ""], ["Zheng", "Weijie", ""]]}, {"id": "2012.07236", "submitter": "Fan Lyu", "authors": "Fan Lyu, Shuai Wang, Wei Feng, Zihan Ye, Fuyuan Hu, Song Wang", "title": "Multi-Domain Multi-Task Rehearsal for Lifelong Learning", "comments": "Accepted by AAAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Rehearsal, seeking to remind the model by storing old knowledge in lifelong\nlearning, is one of the most effective ways to mitigate catastrophic\nforgetting, i.e., biased forgetting of previous knowledge when moving to new\ntasks. However, the old tasks of the most previous rehearsal-based methods\nsuffer from the unpredictable domain shift when training the new task. This is\nbecause these methods always ignore two significant factors. First, the Data\nImbalance between the new task and old tasks that makes the domain of old tasks\nprone to shift. Second, the Task Isolation among all tasks will make the domain\nshift toward unpredictable directions; To address the unpredictable domain\nshift, in this paper, we propose Multi-Domain Multi-Task (MDMT) rehearsal to\ntrain the old tasks and new task parallelly and equally to break the isolation\namong tasks. Specifically, a two-level angular margin loss is proposed to\nencourage the intra-class/task compactness and inter-class/task discrepancy,\nwhich keeps the model from domain chaos. In addition, to further address domain\nshift of the old tasks, we propose an optional episodic distillation loss on\nthe memory to anchor the knowledge for each old task. Experiments on benchmark\ndatasets validate the proposed approach can effectively mitigate the\nunpredictable domain shift.\n", "versions": [{"version": "v1", "created": "Mon, 14 Dec 2020 03:36:25 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["Lyu", "Fan", ""], ["Wang", "Shuai", ""], ["Feng", "Wei", ""], ["Ye", "Zihan", ""], ["Hu", "Fuyuan", ""], ["Wang", "Song", ""]]}, {"id": "2012.07279", "submitter": "Sohee Bae", "authors": "Sohee Bae, Seungyul Han, and Youngchul Sung", "title": "A Reinforcement Learning Formulation of the Lyapunov Optimization:\n  Application to Edge Computing Systems with Queue Stability", "comments": "14 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, a deep reinforcement learning (DRL)-based approach to the\nLyapunov optimization is considered to minimize the time-average penalty while\nmaintaining queue stability. A proper construction of state and action spaces\nis provided to form a proper Markov decision process (MDP) for the Lyapunov\noptimization. A condition for the reward function of reinforcement learning\n(RL) for queue stability is derived. Based on the analysis and practical RL\nwith reward discounting, a class of reward functions is proposed for the\nDRL-based approach to the Lyapunov optimization. The proposed DRL-based\napproach to the Lyapunov optimization does not required complicated\noptimization at each time step and operates with general non-convex and\ndiscontinuous penalty functions. Hence, it provides an alternative to the\nconventional drift-plus-penalty (DPP) algorithm for the Lyapunov optimization.\nThe proposed DRL-based approach is applied to resource allocation in edge\ncomputing systems with queue stability and numerical results demonstrate its\nsuccessful operation.\n", "versions": [{"version": "v1", "created": "Mon, 14 Dec 2020 05:55:26 GMT"}, {"version": "v2", "created": "Tue, 15 Dec 2020 11:02:51 GMT"}], "update_date": "2020-12-16", "authors_parsed": [["Bae", "Sohee", ""], ["Han", "Seungyul", ""], ["Sung", "Youngchul", ""]]}, {"id": "2012.07291", "submitter": "Yi Luo", "authors": "Yi Luo, Cong Han, Nima Mesgarani", "title": "Group Communication with Context Codec for Lightweight Source Separation", "comments": "IEEE/ACM Transactions on Audio, Speech, and Language Processing\n  (TASLP)", "journal-ref": null, "doi": "10.1109/TASLP.2021.3078640", "report-no": null, "categories": "eess.AS cs.AI cs.LG cs.SD", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Despite the recent progress on neural network architectures for speech\nseparation, the balance between the model size, model complexity and model\nperformance is still an important and challenging problem for the deployment of\nsuch models to low-resource platforms. In this paper, we propose two simple\nmodules, group communication and context codec, that can be easily applied to a\nwide range of architectures to jointly decrease the model size and complexity\nwithout sacrificing the performance. A group communication module splits a\nhigh-dimensional feature into groups of low-dimensional features and captures\nthe inter-group dependency. A separation module with a significantly smaller\nmodel size can then be shared by all the groups. A context codec module,\ncontaining a context encoder and a context decoder, is designed as a learnable\ndownsampling and upsampling module to decrease the length of a sequential\nfeature processed by the separation module. The combination of the group\ncommunication and the context codec modules is referred to as the GC3 design.\nExperimental results show that applying GC3 on multiple network architectures\nfor speech separation can achieve on-par or better performance with as small as\n2.5% model size and 17.6% model complexity, respectively.\n", "versions": [{"version": "v1", "created": "Mon, 14 Dec 2020 06:57:58 GMT"}, {"version": "v2", "created": "Sun, 16 May 2021 05:11:52 GMT"}], "update_date": "2021-05-18", "authors_parsed": [["Luo", "Yi", ""], ["Han", "Cong", ""], ["Mesgarani", "Nima", ""]]}, {"id": "2012.07320", "submitter": "Aryan Deshwal", "authors": "Aryan Deshwal, Syrine Belakaria, Janardhan Rao Doppa, Alan Fern", "title": "Optimizing Discrete Spaces via Expensive Evaluations: A Learning to\n  Search Framework", "comments": "9 pages, 8 figures", "journal-ref": "Proceedings of the AAAI Conference on Artificial Intelligence. 34,\n  04 (Apr. 2020), 3773-3780", "doi": "10.1609/aaai.v34i04.5788", "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We consider the problem of optimizing expensive black-box functions over\ndiscrete spaces (e.g., sets, sequences, graphs). The key challenge is to select\na sequence of combinatorial structures to evaluate, in order to identify\nhigh-performing structures as quickly as possible. Our main contribution is to\nintroduce and evaluate a new learning-to-search framework for this problem\ncalled L2S-DISCO. The key insight is to employ search procedures guided by\ncontrol knowledge at each step to select the next structure and to improve the\ncontrol knowledge as new function evaluations are observed. We provide a\nconcrete instantiation of L2S-DISCO for local search procedure and empirically\nevaluate it on diverse real-world benchmarks. Results show the efficacy of\nL2S-DISCO over state-of-the-art algorithms in solving complex optimization\nproblems.\n", "versions": [{"version": "v1", "created": "Mon, 14 Dec 2020 08:04:44 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["Deshwal", "Aryan", ""], ["Belakaria", "Syrine", ""], ["Doppa", "Janardhan Rao", ""], ["Fern", "Alan", ""]]}, {"id": "2012.07330", "submitter": "Yaru Niu", "authors": "Yaru Niu, Yijun Gu", "title": "Active Hierarchical Imitation and Reinforcement Learning", "comments": "6 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Humans can leverage hierarchical structures to split a task into sub-tasks\nand solve problems efficiently. Both imitation and reinforcement learning or a\ncombination of them with hierarchical structures have been proven to be an\nefficient way for robots to learn complex tasks with sparse rewards. However,\nin the previous work of hierarchical imitation and reinforcement learning, the\ntested environments are in relatively simple 2D games, and the action spaces\nare discrete. Furthermore, many imitation learning works focusing on improving\nthe policies learned from the expert polices that are hard-coded or trained by\nreinforcement learning algorithms, rather than human experts. In the scenarios\nof human-robot interaction, humans can be required to provide demonstrations to\nteach the robot, so it is crucial to improve the learning efficiency to reduce\nexpert efforts, and know human's perception about the learning/training\nprocess. In this project, we explored different imitation learning algorithms\nand designed active learning algorithms upon the hierarchical imitation and\nreinforcement learning framework we have developed. We performed an experiment\nwhere five participants were asked to guide a randomly initialized agent to a\nrandom goal in a maze. Our experimental results showed that using DAgger and\nreward-based active learning method can achieve better performance while saving\nmore human efforts physically and mentally during the training process.\n", "versions": [{"version": "v1", "created": "Mon, 14 Dec 2020 08:27:27 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["Niu", "Yaru", ""], ["Gu", "Yijun", ""]]}, {"id": "2012.07335", "submitter": "Hao Fu", "authors": "Hao Fu, Shaojun Zhou, Qihong Yang, Junjie Tang, Guiquan Liu, Kaikui\n  Liu, Xiaolong Li", "title": "LRC-BERT: Latent-representation Contrastive Knowledge Distillation for\n  Natural Language Understanding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The pre-training models such as BERT have achieved great results in various\nnatural language processing problems. However, a large number of parameters\nneed significant amounts of memory and the consumption of inference time, which\nmakes it difficult to deploy them on edge devices. In this work, we propose a\nknowledge distillation method LRC-BERT based on contrastive learning to fit the\noutput of the intermediate layer from the angular distance aspect, which is not\nconsidered by the existing distillation methods. Furthermore, we introduce a\ngradient perturbation-based training architecture in the training phase to\nincrease the robustness of LRC-BERT, which is the first attempt in knowledge\ndistillation. Additionally, in order to better capture the distribution\ncharacteristics of the intermediate layer, we design a two-stage training\nmethod for the total distillation loss. Finally, by verifying 8 datasets on the\nGeneral Language Understanding Evaluation (GLUE) benchmark, the performance of\nthe proposed LRC-BERT exceeds the existing state-of-the-art methods, which\nproves the effectiveness of our method.\n", "versions": [{"version": "v1", "created": "Mon, 14 Dec 2020 08:39:38 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["Fu", "Hao", ""], ["Zhou", "Shaojun", ""], ["Yang", "Qihong", ""], ["Tang", "Junjie", ""], ["Liu", "Guiquan", ""], ["Liu", "Kaikui", ""], ["Li", "Xiaolong", ""]]}, {"id": "2012.07353", "submitter": "Xuesong Yang", "authors": "Hu Hu, Xuesong Yang, Zeynab Raeesy, Jinxi Guo, Gokce Keskin, Harish\n  Arsikere, Ariya Rastrow, Andreas Stolcke, Roland Maas", "title": "REDAT: Accent-Invariant Representation for End-to-End ASR by Domain\n  Adversarial Training with Relabeling", "comments": "accepted in ICASSP 2021; final camera-ready version", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.AI cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Accents mismatching is a critical problem for end-to-end ASR. This paper aims\nto address this problem by building an accent-robust RNN-T system with domain\nadversarial training (DAT). We unveil the magic behind DAT and provide, for the\nfirst time, a theoretical guarantee that DAT learns accent-invariant\nrepresentations. We also prove that performing the gradient reversal in DAT is\nequivalent to minimizing the Jensen-Shannon divergence between domain output\ndistributions. Motivated by the proof of equivalence, we introduce reDAT, a\nnovel technique based on DAT, which relabels data using either unsupervised\nclustering or soft labels. Experiments on 23K hours of multi-accent data show\nthat DAT achieves competitive results over accent-specific baselines on both\nnative and non-native English accents but up to 13% relative WER reduction on\nunseen accents; our reDAT yields further improvements over DAT by 3% and 8%\nrelatively on non-native accents of American and British English.\n", "versions": [{"version": "v1", "created": "Mon, 14 Dec 2020 09:09:08 GMT"}, {"version": "v2", "created": "Fri, 12 Feb 2021 06:44:12 GMT"}], "update_date": "2021-02-15", "authors_parsed": [["Hu", "Hu", ""], ["Yang", "Xuesong", ""], ["Raeesy", "Zeynab", ""], ["Guo", "Jinxi", ""], ["Keskin", "Gokce", ""], ["Arsikere", "Harish", ""], ["Rastrow", "Ariya", ""], ["Stolcke", "Andreas", ""], ["Maas", "Roland", ""]]}, {"id": "2012.07356", "submitter": "Xiaoyang Lyu", "authors": "Xiaoyang Lyu, Liang Liu, Mengmeng Wang, Xin Kong, Lina Liu, Yong Liu,\n  Xinxin Chen, Yi Yuan", "title": "HR-Depth: High Resolution Self-Supervised Monocular Depth Estimation", "comments": "9 pages, 5 figures. Accepted to 35th AAAI Conference on Artificial\n  Intelligence (AAAI 2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Self-supervised learning shows great potential in monoculardepth estimation,\nusing image sequences as the only source ofsupervision. Although people try to\nuse the high-resolutionimage for depth estimation, the accuracy of prediction\nhasnot been significantly improved. In this work, we find thecore reason comes\nfrom the inaccurate depth estimation inlarge gradient regions, making the\nbilinear interpolation er-ror gradually disappear as the resolution increases.\nTo obtainmore accurate depth estimation in large gradient regions, itis\nnecessary to obtain high-resolution features with spatialand semantic\ninformation. Therefore, we present an improvedDepthNet, HR-Depth, with two\neffective strategies: (1) re-design the skip-connection in DepthNet to get\nbetter high-resolution features and (2) propose feature fusion\nSqueeze-and-Excitation(fSE) module to fuse feature more efficiently.Using\nResnet-18 as the encoder, HR-Depth surpasses all pre-vious\nstate-of-the-art(SoTA) methods with the least param-eters at both high and low\nresolution. Moreover, previousstate-of-the-art methods are based on fairly\ncomplex and deepnetworks with a mass of parameters which limits their\nrealapplications. Thus we also construct a lightweight networkwhich uses\nMobileNetV3 as encoder. Experiments show thatthe lightweight network can\nperform on par with many largemodels like Monodepth2 at high-resolution with\nonly20%parameters. All codes and models will be available at\nhttps://github.com/shawLyu/HR-Depth.\n", "versions": [{"version": "v1", "created": "Mon, 14 Dec 2020 09:15:15 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["Lyu", "Xiaoyang", ""], ["Liu", "Liang", ""], ["Wang", "Mengmeng", ""], ["Kong", "Xin", ""], ["Liu", "Lina", ""], ["Liu", "Yong", ""], ["Chen", "Xinxin", ""], ["Yuan", "Yi", ""]]}, {"id": "2012.07412", "submitter": "Zhijing Jin", "authors": "Qipeng Guo, Zhijing Jin, Ziyu Wang, Xipeng Qiu, Weinan Zhang, Jun Zhu,\n  Zheng Zhang, David Wipf", "title": "Fork or Fail: Cycle-Consistent Training with Many-to-One Mappings", "comments": "A condensed version is accepted to AISTATS 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Cycle-consistent training is widely used for jointly learning a forward and\ninverse mapping between two domains of interest without the cumbersome\nrequirement of collecting matched pairs within each domain. In this regard, the\nimplicit assumption is that there exists (at least approximately) a\nground-truth bijection such that a given input from either domain can be\naccurately reconstructed from successive application of the respective\nmappings. But in many applications no such bijection can be expected to exist\nand large reconstruction errors can compromise the success of cycle-consistent\ntraining. As one important instance of this limitation, we consider\npractically-relevant situations where there exists a many-to-one or surjective\nmapping between domains. To address this regime, we develop a conditional\nvariational autoencoder (CVAE) approach that can be viewed as converting\nsurjective mappings to implicit bijections whereby reconstruction errors in\nboth directions can be minimized, and as a natural byproduct, realistic output\ndiversity can be obtained in the one-to-many direction. As theoretical\nmotivation, we analyze a simplified scenario whereby minima of the proposed\nCVAE-based energy function align with the recovery of ground-truth surjective\nmappings. On the empirical side, we consider a synthetic image dataset with\nknown ground-truth, as well as a real-world application involving natural\nlanguage generation from knowledge graphs and vice versa, a prototypical\nsurjective case. For the latter, our CVAE pipeline can capture such many-to-one\nmappings during cycle training while promoting textural diversity for\ngraph-to-text tasks. Our code is available at github.com/QipengGuo/CycleGT\n  *A condensed version of this paper has been accepted to AISTATS 2021. This\nversion contains additional content and updates.\n", "versions": [{"version": "v1", "created": "Mon, 14 Dec 2020 10:59:59 GMT"}, {"version": "v2", "created": "Wed, 16 Dec 2020 17:37:06 GMT"}, {"version": "v3", "created": "Mon, 25 Jan 2021 11:18:37 GMT"}], "update_date": "2021-01-26", "authors_parsed": [["Guo", "Qipeng", ""], ["Jin", "Zhijing", ""], ["Wang", "Ziyu", ""], ["Qiu", "Xipeng", ""], ["Zhang", "Weinan", ""], ["Zhu", "Jun", ""], ["Zhang", "Zheng", ""], ["Wipf", "David", ""]]}, {"id": "2012.07430", "submitter": "Vajira Thambawita", "authors": "Vajira Thambawita, Steven Hicks, P{\\aa}l Halvorsen, Michael A. Riegler", "title": "Pyramid-Focus-Augmentation: Medical Image Segmentation with Step-Wise\n  Focus", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.MM", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Segmentation of findings in the gastrointestinal tract is a challenging but\nalso an important task which is an important building stone for sufficient\nautomatic decision support systems. In this work, we present our solution for\nthe Medico 2020 task, which focused on the problem of colon polyp segmentation.\nWe present our simple but efficient idea of using an augmentation method that\nuses grids in a pyramid-like manner (large to small) for segmentation. Our\nresults show that the proposed methods work as indented and can also lead to\ncomparable results when competing with other methods.\n", "versions": [{"version": "v1", "created": "Mon, 14 Dec 2020 11:34:29 GMT"}], "update_date": "2021-02-04", "authors_parsed": [["Thambawita", "Vajira", ""], ["Hicks", "Steven", ""], ["Halvorsen", "P\u00e5l", ""], ["Riegler", "Michael A.", ""]]}, {"id": "2012.07436", "submitter": "Haoyi Zhou", "authors": "Haoyi Zhou, Shanghang Zhang, Jieqi Peng, Shuai Zhang, Jianxin Li, Hui\n  Xiong, Wancai Zhang", "title": "Informer: Beyond Efficient Transformer for Long Sequence Time-Series\n  Forecasting", "comments": "8 pages (main), 5 pages (appendix) and to be appeared in AAAI2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many real-world applications require the prediction of long sequence\ntime-series, such as electricity consumption planning. Long sequence\ntime-series forecasting (LSTF) demands a high prediction capacity of the model,\nwhich is the ability to capture precise long-range dependency coupling between\noutput and input efficiently. Recent studies have shown the potential of\nTransformer to increase the prediction capacity. However, there are several\nsevere issues with Transformer that prevent it from being directly applicable\nto LSTF, including quadratic time complexity, high memory usage, and inherent\nlimitation of the encoder-decoder architecture. To address these issues, we\ndesign an efficient transformer-based model for LSTF, named Informer, with\nthree distinctive characteristics: (i) a $ProbSparse$ self-attention mechanism,\nwhich achieves $O(L \\log L)$ in time complexity and memory usage, and has\ncomparable performance on sequences' dependency alignment. (ii) the\nself-attention distilling highlights dominating attention by halving cascading\nlayer input, and efficiently handles extreme long input sequences. (iii) the\ngenerative style decoder, while conceptually simple, predicts the long\ntime-series sequences at one forward operation rather than a step-by-step way,\nwhich drastically improves the inference speed of long-sequence predictions.\nExtensive experiments on four large-scale datasets demonstrate that Informer\nsignificantly outperforms existing methods and provides a new solution to the\nLSTF problem.\n", "versions": [{"version": "v1", "created": "Mon, 14 Dec 2020 11:43:09 GMT"}, {"version": "v2", "created": "Thu, 17 Dec 2020 03:05:27 GMT"}, {"version": "v3", "created": "Sun, 28 Mar 2021 14:45:04 GMT"}], "update_date": "2021-03-30", "authors_parsed": [["Zhou", "Haoyi", ""], ["Zhang", "Shanghang", ""], ["Peng", "Jieqi", ""], ["Zhang", "Shuai", ""], ["Li", "Jianxin", ""], ["Xiong", "Hui", ""], ["Zhang", "Wancai", ""]]}, {"id": "2012.07450", "submitter": "Xu Chen", "authors": "Qiong Wu and Xu Chen and Zhi Zhou and Junshan Zhang", "title": "FedHome: Cloud-Edge based Personalized Federated Learning for In-Home\n  Health Monitoring", "comments": "Accepted by IEEE Transactions on Mobile Computing", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.AI cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In-home health monitoring has attracted great attention for the ageing\npopulation worldwide. With the abundant user health data accessed by Internet\nof Things (IoT) devices and recent development in machine learning, smart\nhealthcare has seen many successful stories. However, existing approaches for\nin-home health monitoring do not pay sufficient attention to user data privacy\nand thus are far from being ready for large-scale practical deployment. In this\npaper, we propose FedHome, a novel cloud-edge based federated learning\nframework for in-home health monitoring, which learns a shared global model in\nthe cloud from multiple homes at the network edges and achieves data privacy\nprotection by keeping user data locally. To cope with the imbalanced and\nnon-IID distribution inherent in user's monitoring data, we design a generative\nconvolutional autoencoder (GCAE), which aims to achieve accurate and\npersonalized health monitoring by refining the model with a generated\nclass-balanced dataset from user's personal data. Besides, GCAE is lightweight\nto transfer between the cloud and edges, which is useful to reduce the\ncommunication cost of federated learning in FedHome. Extensive experiments\nbased on realistic human activity recognition data traces corroborate that\nFedHome significantly outperforms existing widely-adopted methods.\n", "versions": [{"version": "v1", "created": "Mon, 14 Dec 2020 12:04:44 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["Wu", "Qiong", ""], ["Chen", "Xu", ""], ["Zhou", "Zhi", ""], ["Zhang", "Junshan", ""]]}, {"id": "2012.07464", "submitter": "Alejandro Su\\'arez Hern\\'andez", "authors": "Alejandro Su\\'arez-Hern\\'andez and Javier Segovia-Aguas and Carme\n  Torras and Guillem Aleny\\`a", "title": "Online Action Recognition", "comments": "Accepted version soon to appear in AAAI 21", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recognition in planning seeks to find agent intentions, goals or activities\ngiven a set of observations and a knowledge library (e.g. goal states, plans or\ndomain theories). In this work we introduce the problem of Online Action\nRecognition. It consists in recognizing, in an open world, the planning action\nthat best explains a partially observable state transition from a knowledge\nlibrary of first-order STRIPS actions, which is initially empty. We frame this\nas an optimization problem, and propose two algorithms to address it: Action\nUnification (AU) and Online Action Recognition through Unification (OARU). The\nformer builds on logic unification and generalizes two input actions using\nweighted partial MaxSAT. The latter looks for an action within the library that\nexplains an observed transition. If there is such action, it generalizes it\nmaking use of AU, building in this way an AU hierarchy. Otherwise, OARU inserts\na Trivial Grounded Action (TGA) in the library that explains just that\ntransition. We report results on benchmarks from the International Planning\nCompetition and PDDLGym, where OARU recognizes actions accurately with respect\nto expert knowledge, and shows real-time performance.\n", "versions": [{"version": "v1", "created": "Mon, 14 Dec 2020 12:37:20 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["Su\u00e1rez-Hern\u00e1ndez", "Alejandro", ""], ["Segovia-Aguas", "Javier", ""], ["Torras", "Carme", ""], ["Aleny\u00e0", "Guillem", ""]]}, {"id": "2012.07499", "submitter": "Petar Milin", "authors": "Petar Milin, Benjamin V. Tucker, and Dagmar Divjak", "title": "A learning perspective on the emergence of abstractions: the curious\n  case of phonemes", "comments": "45 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the present paper we use a range of modeling techniques to investigate\nwhether an abstract phone could emerge from exposure to speech sounds. We test\ntwo opposing principles regarding the development of language knowledge in\nlinguistically untrained language users: Memory-Based Learning (MBL) and\nError-Correction Learning (ECL). A process of generalization underlies the\nabstractions linguists operate with, and we probed whether MBL and ECL could\ngive rise to a type of language knowledge that resembles linguistic\nabstractions. Each model was presented with a significant amount of\npre-processed speech produced by one speaker. We assessed the consistency or\nstability of what the models have learned and their ability to give rise to\nabstract categories. Both types of models fare differently with regard to these\ntests. We show that ECL learning models can learn abstractions and that at\nleast part of the phone inventory can be reliably identified from the input.\n", "versions": [{"version": "v1", "created": "Mon, 14 Dec 2020 13:33:34 GMT"}, {"version": "v2", "created": "Wed, 16 Dec 2020 15:08:48 GMT"}, {"version": "v3", "created": "Thu, 17 Dec 2020 14:06:59 GMT"}], "update_date": "2020-12-18", "authors_parsed": [["Milin", "Petar", ""], ["Tucker", "Benjamin V.", ""], ["Divjak", "Dagmar", ""]]}, {"id": "2012.07508", "submitter": "Dong Wang", "authors": "Dong Wang, Di Hu, Xingjian Li, Dejing Dou", "title": "Temporal Relational Modeling with Self-Supervision for Action\n  Segmentation", "comments": "Accepted by the Thirty-Fifth AAAI Conference on Artificial\n  Intelligence (AAAI-21)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Temporal relational modeling in video is essential for human action\nunderstanding, such as action recognition and action segmentation. Although\nGraph Convolution Networks (GCNs) have shown promising advantages in relation\nreasoning on many tasks, it is still a challenge to apply graph convolution\nnetworks on long video sequences effectively. The main reason is that large\nnumber of nodes (i.e., video frames) makes GCNs hard to capture and model\ntemporal relations in videos. To tackle this problem, in this paper, we\nintroduce an effective GCN module, Dilated Temporal Graph Reasoning Module\n(DTGRM), designed to model temporal relations and dependencies between video\nframes at various time spans. In particular, we capture and model temporal\nrelations via constructing multi-level dilated temporal graphs where the nodes\nrepresent frames from different moments in video. Moreover, to enhance temporal\nreasoning ability of the proposed model, an auxiliary self-supervised task is\nproposed to encourage the dilated temporal graph reasoning module to find and\ncorrect wrong temporal relations in videos. Our DTGRM model outperforms\nstate-of-the-art action segmentation models on three challenging datasets:\n50Salads, Georgia Tech Egocentric Activities (GTEA), and the Breakfast dataset.\nThe code is available at https://github.com/redwang/DTGRM.\n", "versions": [{"version": "v1", "created": "Mon, 14 Dec 2020 13:41:28 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["Wang", "Dong", ""], ["Hu", "Di", ""], ["Li", "Xingjian", ""], ["Dou", "Dejing", ""]]}, {"id": "2012.07513", "submitter": "Raanan Yehezkel Rohekar", "authors": "Raanan Y. Rohekar, Yaniv Gurwicz, Shami Nisimov, Gal Novik", "title": "A Single Iterative Step for Anytime Causal Discovery", "comments": "34th Conference on Neural Information Processing Systems (NeurIPS\n  2020), Vancouver, Canada, Workshop on Causal Discovery & Causality-Inspired\n  Machine Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a sound and complete algorithm for recovering causal graphs from\nobserved, non-interventional data, in the possible presence of latent\nconfounders and selection bias. We rely on the causal Markov and faithfulness\nassumptions and recover the equivalence class of the underlying causal graph by\nperforming a series of conditional independence (CI) tests between observed\nvariables. We propose a single step that is applied iteratively, such that the\nindependence and causal relations entailed from the resulting graph, after any\niteration, is correct and becomes more informative with successive iteration.\nEssentially, we tie the size of the CI condition set to its distance from the\ntested nodes on the resulting graph. Each iteration refines the skeleton and\norientation by performing CI tests having condition sets that are larger than\nin the preceding iteration. In an iteration, condition sets of CI tests are\nconstructed from nodes that are within a specified search distance, and the\nsizes of these condition sets is equal to this search distance. The algorithm\nthen iteratively increases the search distance along with the condition set\nsizes. Thus, each iteration refines a graph, that was recovered by previous\niterations having smaller condition sets -- having a higher statistical power.\nWe demonstrate that our algorithm requires significantly fewer CI tests and\nsmaller condition sets compared to the FCI algorithm. This is evident for both\nrecovering the true underlying graph using a perfect CI oracle, and accurately\nestimating the graph using limited observed data.\n", "versions": [{"version": "v1", "created": "Mon, 14 Dec 2020 13:46:01 GMT"}, {"version": "v2", "created": "Thu, 24 Dec 2020 11:29:06 GMT"}], "update_date": "2020-12-25", "authors_parsed": [["Rohekar", "Raanan Y.", ""], ["Gurwicz", "Yaniv", ""], ["Nisimov", "Shami", ""], ["Novik", "Gal", ""]]}, {"id": "2012.07532", "submitter": "Evan Hubinger", "authors": "Evan Hubinger", "title": "An overview of 11 proposals for building safe advanced AI", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper analyzes and compares 11 different proposals for building safe\nadvanced AI under the current machine learning paradigm, including major\ncontenders such as iterated amplification, AI safety via debate, and recursive\nreward modeling. Each proposal is evaluated on the four components of outer\nalignment, inner alignment, training competitiveness, and performance\ncompetitiveness, of which the distinction between the latter two is introduced\nin this paper. While prior literature has primarily focused on analyzing\nindividual proposals, or primarily focused on outer alignment at the expense of\ninner alignment, this analysis seeks to take a comparative look at a wide range\nof proposals including a comparative analysis across all four previously\nmentioned components.\n", "versions": [{"version": "v1", "created": "Fri, 4 Dec 2020 22:53:18 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["Hubinger", "Evan", ""]]}, {"id": "2012.07535", "submitter": "Yassir Fathullah", "authors": "Yassir Fathullah, Mark Gales, Andrey Malinin", "title": "Ensemble Distillation Approaches for Grammatical Error Correction", "comments": "Submitted to ICASSP 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Ensemble approaches are commonly used techniques to improving a system by\ncombining multiple model predictions. Additionally these schemes allow the\nuncertainty, as well as the source of the uncertainty, to be derived for the\nprediction. Unfortunately these benefits come at a computational and memory\ncost. To address this problem ensemble distillation (EnD) and more recently\nensemble distribution distillation (EnDD) have been proposed that compress the\nensemble into a single model, representing either the ensemble average\nprediction or prediction distribution respectively. This paper examines the\napplication of both these distillation approaches to a sequence prediction\ntask, grammatical error correction (GEC). This is an important application area\nfor language learning tasks as it can yield highly useful feedback to the\nlearner. It is, however, more challenging than the standard tasks investigated\nfor distillation as the prediction of any grammatical correction to a word will\nbe highly dependent on both the input sequence and the generated output history\nfor the word. The performance of both EnD and EnDD are evaluated on both\npublicly available GEC tasks as well as a spoken language task.\n", "versions": [{"version": "v1", "created": "Tue, 24 Nov 2020 15:00:45 GMT"}, {"version": "v2", "created": "Tue, 15 Dec 2020 09:45:47 GMT"}], "update_date": "2020-12-16", "authors_parsed": [["Fathullah", "Yassir", ""], ["Gales", "Mark", ""], ["Malinin", "Andrey", ""]]}, {"id": "2012.07553", "submitter": "Xiang Cheng", "authors": "Xiang Cheng, Mitchell Bowden, Bhushan Ramesh Bhange, Priyanka Goyal,\n  Thomas Packer, Faizan Javed", "title": "An End-to-End Solution for Named Entity Recognition in eCommerce Search", "comments": "Accepted by AAAI IAAI-2021 Highly Innovative Applications of AI track", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Named entity recognition (NER) is a critical step in modern search query\nunderstanding. In the domain of eCommerce, identifying the key entities, such\nas brand and product type, can help a search engine retrieve relevant products\nand therefore offer an engaging shopping experience. Recent research shows\npromising results on shared benchmark NER tasks using deep learning methods,\nbut there are still unique challenges in the industry regarding domain\nknowledge, training data, and model production. This paper demonstrates an\nend-to-end solution to address these challenges. The core of our solution is a\nnovel model training framework \"TripleLearn\" which iteratively learns from\nthree separate training datasets, instead of one training set as is\ntraditionally done. Using this approach, the best model lifts the F1 score from\n69.5 to 93.3 on the holdout test data. In our offline experiments, TripleLearn\nimproved the model performance compared to traditional training approaches\nwhich use a single set of training data. Moreover, in the online A/B test, we\nsee significant improvements in user engagement and revenue conversion. The\nmodel has been live on homedepot.com for more than 9 months, boosting search\nconversions and revenue. Beyond our application, this TripleLearn framework, as\nwell as the end-to-end process, is model-independent and problem-independent,\nso it can be generalized to more industrial applications, especially to the\neCommerce industry which has similar data foundations and problems.\n", "versions": [{"version": "v1", "created": "Fri, 11 Dec 2020 04:58:13 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["Cheng", "Xiang", ""], ["Bowden", "Mitchell", ""], ["Bhange", "Bhushan Ramesh", ""], ["Goyal", "Priyanka", ""], ["Packer", "Thomas", ""], ["Javed", "Faizan", ""]]}, {"id": "2012.07557", "submitter": "Long Phan", "authors": "Trung-Hieu Tran, Long Phan, Truong-Son Nguyen, Tien-Huy Nguyen", "title": "Leveraging Transfer Learning for Reliable Intelligence Identification on\n  Vietnamese SNSs (ReINTEL)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper proposed several transformer-based approaches for Reliable\nIntelligence Identification on Vietnamese social network sites at VLSP 2020\nevaluation campaign. We exploit both of monolingual and multilingual\npre-trained models. Besides, we utilize the ensemble method to improve the\nrobustness of different approaches. Our team achieved a score of 0.9378 at\nROC-AUC metric in the private test set which is competitive to other\nparticipants.\n", "versions": [{"version": "v1", "created": "Thu, 10 Dec 2020 15:43:50 GMT"}, {"version": "v2", "created": "Wed, 16 Dec 2020 15:10:07 GMT"}], "update_date": "2020-12-17", "authors_parsed": [["Tran", "Trung-Hieu", ""], ["Phan", "Long", ""], ["Nguyen", "Truong-Son", ""], ["Nguyen", "Tien-Huy", ""]]}, {"id": "2012.07563", "submitter": "Musarrat Husssain", "authors": "Musarrat Hussain, Fahad Ahmed Satti, Jamil Hussain, Taqdir Ali, Syed\n  Imran Ali, Hafiz Syed Muhammad Bilal, Gwang Hoon Park, Sungyoung Lee", "title": "A Practical Approach towards Causality Mining in Clinical Text using\n  Active Transfer Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Objective: Causality mining is an active research area, which requires the\napplication of state-of-the-art natural language processing techniques. In the\nhealthcare domain, medical experts create clinical text to overcome the\nlimitation of well-defined and schema driven information systems. The objective\nof this research work is to create a framework, which can convert clinical text\ninto causal knowledge. Methods: A practical approach based on term expansion,\nphrase generation, BERT based phrase embedding and semantic matching, semantic\nenrichment, expert verification, and model evolution has been used to construct\na comprehensive causality mining framework. This active transfer learning based\nframework along with its supplementary services, is able to extract and enrich,\ncausal relationships and their corresponding entities from clinical text.\nResults: The multi-model transfer learning technique when applied over multiple\niterations, gains performance improvements in terms of its accuracy and recall\nwhile keeping the precision constant. We also present a comparative analysis of\nthe presented techniques with their common alternatives, which demonstrate the\ncorrectness of our approach and its ability to capture most causal\nrelationships. Conclusion: The presented framework has provided cutting-edge\nresults in the healthcare domain. However, the framework can be tweaked to\nprovide causality detection in other domains, as well. Significance: The\npresented framework is generic enough to be utilized in any domain, healthcare\nservices can gain massive benefits due to the voluminous and various nature of\nits data. This causal knowledge extraction framework can be used to summarize\nclinical text, create personas, discover medical knowledge, and provide\nevidence to clinical decision making.\n", "versions": [{"version": "v1", "created": "Thu, 10 Dec 2020 06:51:13 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["Hussain", "Musarrat", ""], ["Satti", "Fahad Ahmed", ""], ["Hussain", "Jamil", ""], ["Ali", "Taqdir", ""], ["Ali", "Syed Imran", ""], ["Bilal", "Hafiz Syed Muhammad", ""], ["Park", "Gwang Hoon", ""], ["Lee", "Sungyoung", ""]]}, {"id": "2012.07580", "submitter": "Zied Bouraoui", "authors": "Na Li, Zied Bouraoui, Jose Camacho Collados, Luis Espinosa-Anke, Qing\n  Gu, Steven Schockaert", "title": "Modelling General Properties of Nouns by Selectively Averaging\n  Contextualised Embeddings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While the success of pre-trained language models has largely eliminated the\nneed for high-quality static word vectors in many NLP applications, such\nvectors continue to play an important role in tasks where words need to be\nmodelled in the absence of linguistic context. In this paper, we explore how\nthe contextualised embeddings predicted by BERT can be used to produce\nhigh-quality word vectors for such domains, in particular related to knowledge\nbase completion, where our focus is on capturing the semantic properties of\nnouns. We find that a simple strategy of averaging the contextualised\nembeddings of masked word mentions leads to vectors that outperform the static\nword vectors learned by BERT, as well as those from standard word embedding\nmodels, in property induction tasks. We notice in particular that masking\ntarget words is critical to achieve this strong performance, as the resulting\nvectors focus less on idiosyncratic properties and more on general semantic\nproperties. Inspired by this view, we propose a filtering strategy which is\naimed at removing the most idiosyncratic mention vectors, allowing us to obtain\nfurther performance gains in property induction.\n", "versions": [{"version": "v1", "created": "Fri, 4 Dec 2020 14:03:03 GMT"}, {"version": "v2", "created": "Mon, 17 May 2021 15:00:19 GMT"}], "update_date": "2021-05-18", "authors_parsed": [["Li", "Na", ""], ["Bouraoui", "Zied", ""], ["Collados", "Jose Camacho", ""], ["Espinosa-Anke", "Luis", ""], ["Gu", "Qing", ""], ["Schockaert", "Steven", ""]]}, {"id": "2012.07587", "submitter": "Ashwin Rachha", "authors": "Ashwin Rachha and Gaurav Vanmane", "title": "Detecting Insincere Questions from Text: A Transfer Learning Approach", "comments": "7 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The internet today has become an unrivalled source of information where\npeople converse on content based websites such as Quora, Reddit, StackOverflow\nand Twitter asking doubts and sharing knowledge with the world. A major arising\nproblem with such websites is the proliferation of toxic comments or instances\nof insincerity wherein the users instead of maintaining a sincere motive\nindulge in spreading toxic and divisive content. The straightforward course of\naction in confronting this situation is detecting such content beforehand and\npreventing it from subsisting online. In recent times Transfer Learning in\nNatural Language Processing has seen an unprecedented growth. Today with the\nexistence of transformers and various state of the art innovations, a\ntremendous growth has been made in various NLP domains. The introduction of\nBERT has caused quite a stir in the NLP community. As mentioned, when\npublished, BERT dominated performance benchmarks and thereby inspired many\nother authors to experiment with it and publish similar models. This led to the\ndevelopment of a whole BERT-family, each member being specialized on a\ndifferent task. In this paper we solve the Insincere Questions Classification\nproblem by fine tuning four cutting age models viz BERT, RoBERTa, DistilBERT\nand ALBERT.\n", "versions": [{"version": "v1", "created": "Mon, 7 Dec 2020 15:03:48 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["Rachha", "Ashwin", ""], ["Vanmane", "Gaurav", ""]]}, {"id": "2012.07617", "submitter": "Douglas Meneghetti", "authors": "Douglas De Rizzo Meneghetti, Reinaldo Augusto da Costa Bianchi", "title": "Specializing Inter-Agent Communication in Heterogeneous Multi-Agent\n  Reinforcement Learning using Agent Class Information", "comments": "Presented at the AAAI-21 Workshop on Artificial Intelligence in Games", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inspired by recent advances in agent communication with graph neural\nnetworks, this work proposes the representation of multi-agent communication\ncapabilities as a directed labeled heterogeneous agent graph, in which node\nlabels denote agent classes and edge labels, the communication type between two\nclasses of agents. We also introduce a neural network architecture that\nspecializes communication in fully cooperative heterogeneous multi-agent tasks\nby learning individual transformations to the exchanged messages between each\npair of agent classes. By also employing encoding and action selection modules\nwith parameter sharing for environments with heterogeneous agents, we\ndemonstrate comparable or superior performance in environments where a larger\nnumber of agent classes operates.\n", "versions": [{"version": "v1", "created": "Mon, 14 Dec 2020 15:09:57 GMT"}, {"version": "v2", "created": "Wed, 10 Mar 2021 15:19:56 GMT"}], "update_date": "2021-03-11", "authors_parsed": [["Meneghetti", "Douglas De Rizzo", ""], ["Bianchi", "Reinaldo Augusto da Costa", ""]]}, {"id": "2012.07619", "submitter": "Maartje ter Hoeve", "authors": "Maartje ter Hoeve, Julia Kiseleva, Maarten de Rijke", "title": "What Makes a Good Summary? Investigating the Focus of Automatic\n  Summarization in an Educational Context", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.HC cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic text summarization has enjoyed great progress over the last years.\nHowever, there is little research that investigates whether the current\nresearch focus adheres to users' needs. Importantly, these needs are dependent\non the envisioned target group of the generated summaries. One such important\ntarget group is formed by students, due to their usage of summaries in their\nstudy activities. For this reason, we investigate students' needs regarding\nautomatically generated summaries by means of a survey amongst university\nstudents and find that the current direction of the field does not fully align\nwith their needs. Motivated by our findings, we formulate three groups of\nimplications that together help us formulate a renewed perspective on future\nresearch on automatic summarization. First, the educational domain requires a\nbroader perspective on automatic summarization, beyond the approaches that are\ncurrently the standard. We illustrate how we can expand these approaches\nregarding the input material, the purpose of the summaries and their potential\nformat and we define requirements for datasets that can facilitate these\nresearch directions. Second, we propose a methodology to evaluate the\nusefulness of a summary based on the identified needs of a target group. Third,\nin more general terms, we hope that our survey will be reused to investigate\nthe needs of different user groups of automatically generated summaries to\nbroaden our perspective even further.\n", "versions": [{"version": "v1", "created": "Mon, 14 Dec 2020 15:12:35 GMT"}, {"version": "v2", "created": "Tue, 25 May 2021 19:08:43 GMT"}], "update_date": "2021-05-27", "authors_parsed": [["ter Hoeve", "Maartje", ""], ["Kiseleva", "Julia", ""], ["de Rijke", "Maarten", ""]]}, {"id": "2012.07652", "submitter": "Aditya Pal", "authors": "Aditya Pal, Abhijit Mustafi", "title": "Vartani Spellcheck -- Automatic Context-Sensitive Spelling Correction of\n  OCR-generated Hindi Text Using BERT and Levenshtein Distance", "comments": "5 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditional Optical Character Recognition (OCR) systems that generate text of\nhighly inflectional Indic languages like Hindi tend to suffer from poor\naccuracy due to a wide alphabet set, compound characters and difficulty in\nsegmenting characters in a word. Automatic spelling error detection and\ncontext-sensitive error correction can be used to improve accuracy by\npost-processing the text generated by these OCR systems. A majority of\npreviously developed language models for error correction of Hindi spelling\nhave been context-free. In this paper, we present Vartani Spellcheck - a\ncontext-sensitive approach for spelling correction of Hindi text using a\nstate-of-the-art transformer - BERT in conjunction with the Levenshtein\ndistance algorithm, popularly known as Edit Distance. We use a lookup\ndictionary and context-based named entity recognition (NER) for detection of\npossible spelling errors in the text. Our proposed technique has been tested on\na large corpus of text generated by the widely used Tesseract OCR on the Hindi\nepic Ramayana. With an accuracy of 81%, the results show a significant\nimprovement over some of the previously established context-sensitive error\ncorrection mechanisms for Hindi. We also explain how Vartani Spellcheck may be\nused for on-the-fly autocorrect suggestion during continuous typing in a text\neditor environment.\n", "versions": [{"version": "v1", "created": "Mon, 14 Dec 2020 15:49:54 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["Pal", "Aditya", ""], ["Mustafi", "Abhijit", ""]]}, {"id": "2012.07664", "submitter": "Dominique Chu", "authors": "Dominique Chu and Huy Le Nguyen", "title": "Constraints on Hebbian and STDP learned weights of a spiking neuron", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We analyse mathematically the constraints on weights resulting from Hebbian\nand STDP learning rules applied to a spiking neuron with weight normalisation.\nIn the case of pure Hebbian learning, we find that the normalised weights equal\nthe promotion probabilities of weights up to correction terms that depend on\nthe learning rate and are usually small. A similar relation can be derived for\nSTDP algorithms, where the normalised weight values reflect a difference\nbetween the promotion and demotion probabilities of the weight. These relations\nare practically useful in that they allow checking for convergence of Hebbian\nand STDP algorithms. Another application is novelty detection. We demonstrate\nthis using the MNIST dataset.\n", "versions": [{"version": "v1", "created": "Mon, 14 Dec 2020 16:09:12 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["Chu", "Dominique", ""], ["Nguyen", "Huy Le", ""]]}, {"id": "2012.07701", "submitter": "Mir Tafseer Nayeem", "authors": "Susmoy Chakraborty, Mir Tafseer Nayeem, Wasi Uddin Ahmad", "title": "Simple or Complex? Learning to Predict Readability of Bengali Texts", "comments": "Accepted for publication at AAAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Determining the readability of a text is the first step to its\nsimplification. In this paper, we present a readability analysis tool capable\nof analyzing text written in the Bengali language to provide in-depth\ninformation on its readability and complexity. Despite being the 7th most\nspoken language in the world with 230 million native speakers, Bengali suffers\nfrom a lack of fundamental resources for natural language processing.\nReadability related research of the Bengali language so far can be considered\nto be narrow and sometimes faulty due to the lack of resources. Therefore, we\ncorrectly adopt document-level readability formulas traditionally used for U.S.\nbased education system to the Bengali language with a proper age-to-age\ncomparison. Due to the unavailability of large-scale human-annotated corpora,\nwe further divide the document-level task into sentence-level and experiment\nwith neural architectures, which will serve as a baseline for the future works\nof Bengali readability prediction. During the process, we present several\nhuman-annotated corpora and dictionaries such as a document-level dataset\ncomprising 618 documents with 12 different grade levels, a large-scale\nsentence-level dataset comprising more than 96K sentences with simple and\ncomplex labels, a consonant conjunct count algorithm and a corpus of 341 words\nto validate the effectiveness of the algorithm, a list of 3,396 easy words, and\nan updated pronunciation dictionary with more than 67K words. These resources\ncan be useful for several other tasks of this low-resource language. We make\nour Code & Dataset publicly available at\nhttps://github.com/tafseer-nayeem/BengaliReadability} for reproduciblity.\n", "versions": [{"version": "v1", "created": "Wed, 9 Dec 2020 01:41:35 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["Chakraborty", "Susmoy", ""], ["Nayeem", "Mir Tafseer", ""], ["Ahmad", "Wasi Uddin", ""]]}, {"id": "2012.07719", "submitter": "Dongxiao Zhang", "authors": "Qiang Zheng and Dongxiao Zhang", "title": "Digital rock reconstruction with user-defined properties using\n  conditional generative adversarial networks", "comments": "36 pages, 20 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG physics.data-an", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Uncertainty is ubiquitous with flow in subsurface rocks because of their\ninherent heterogeneity and lack of in-situ measurements. To complete\nuncertainty analysis in a multi-scale manner, it is a prerequisite to provide\nsufficient rock samples. Even though the advent of digital rock technology\noffers opportunities to reproduce rocks, it still cannot be utilized to provide\nmassive samples due to its high cost, thus leading to the development of\ndiversified mathematical methods. Among them, two-point statistics (TPS) and\nmulti-point statistics (MPS) are commonly utilized, which feature incorporating\nlow-order and high-order statistical information, respectively. Recently,\ngenerative adversarial networks (GANs) are becoming increasingly popular since\nthey can reproduce training images with excellent visual and consequent\ngeologic realism. However, standard GANs can only incorporate information from\ndata, while leaving no interface for user-defined properties, and thus may\nlimit the representativeness of reconstructed samples. In this study, we\npropose conditional GANs for digital rock reconstruction, aiming to reproduce\nsamples not only similar to the real training data, but also satisfying\nuser-specified properties. In fact, the proposed framework can realize the\ntargets of MPS and TPS simultaneously by incorporating high-order information\ndirectly from rock images with the GANs scheme, while preserving low-order\ncounterparts through conditioning. We conduct three reconstruction experiments,\nand the results demonstrate that rock type, rock porosity, and correlation\nlength can be successfully conditioned to affect the reconstructed rock images.\nFurthermore, in contrast to existing GANs, the proposed conditioning enables\nlearning of multiple rock types simultaneously, and thus invisibly saves\ncomputational cost.\n", "versions": [{"version": "v1", "created": "Sun, 29 Nov 2020 10:55:58 GMT"}, {"version": "v2", "created": "Tue, 1 Jun 2021 06:32:43 GMT"}], "update_date": "2021-06-02", "authors_parsed": [["Zheng", "Qiang", ""], ["Zhang", "Dongxiao", ""]]}, {"id": "2012.07743", "submitter": "Michael Fromm", "authors": "Michael Fromm, Evgeniy Faerman, Max Berrendorf, Siddharth Bhargava,\n  Ruoxia Qi, Yao Zhang, Lukas Dennert, Sophia Selle, Yang Mao, Thomas Seidl", "title": "Argument Mining Driven Analysis of Peer-Reviews", "comments": null, "journal-ref": null, "doi": "10.5281/zenodo.4314390", "report-no": null, "categories": "cs.CY cs.AI cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Peer reviewing is a central process in modern research and essential for\nensuring high quality and reliability of published work. At the same time, it\nis a time-consuming process and increasing interest in emerging fields often\nresults in a high review workload, especially for senior researchers in this\narea. How to cope with this problem is an open question and it is vividly\ndiscussed across all major conferences. In this work, we propose an Argument\nMining based approach for the assistance of editors, meta-reviewers, and\nreviewers. We demonstrate that the decision process in the field of scientific\npublications is driven by arguments and automatic argument identification is\nhelpful in various use-cases. One of our findings is that arguments used in the\npeer-review process differ from arguments in other domains making the transfer\nof pre-trained models difficult. Therefore, we provide the community with a new\npeer-review dataset from different computer science conferences with annotated\narguments. In our extensive empirical evaluation, we show that Argument Mining\ncan be used to efficiently extract the most relevant parts from reviews, which\nare paramount for the publication decision. The process remains interpretable\nsince the extracted arguments can be highlighted in a review without detaching\nthem from their context.\n", "versions": [{"version": "v1", "created": "Thu, 10 Dec 2020 16:06:21 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["Fromm", "Michael", ""], ["Faerman", "Evgeniy", ""], ["Berrendorf", "Max", ""], ["Bhargava", "Siddharth", ""], ["Qi", "Ruoxia", ""], ["Zhang", "Yao", ""], ["Dennert", "Lukas", ""], ["Selle", "Sophia", ""], ["Mao", "Yang", ""], ["Seidl", "Thomas", ""]]}, {"id": "2012.07762", "submitter": "Aryan Deshwal", "authors": "Aryan Deshwal, Syrine Belakaria, Janardhan Rao Doppa", "title": "Mercer Features for Efficient Combinatorial Bayesian Optimization", "comments": "10 pages, 5 figures, Accepted at AAAI conference 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Bayesian optimization (BO) is an efficient framework for solving black-box\noptimization problems with expensive function evaluations. This paper addresses\nthe BO problem setting for combinatorial spaces (e.g., sequences and graphs)\nthat occurs naturally in science and engineering applications. A prototypical\nexample is molecular optimization guided by expensive experiments. The key\nchallenge is to balance the complexity of statistical models and tractability\nof search to select combinatorial structures for evaluation. In this paper, we\npropose an efficient approach referred as Mercer Features for Combinatorial\nBayesian Optimization (MerCBO). The key idea behind MerCBO is to provide\nexplicit feature maps for diffusion kernels over discrete objects by exploiting\nthe structure of their combinatorial graph representation. These Mercer\nfeatures combined with Thompson sampling as the acquisition function allows us\nto employ tractable solvers to find next structures for evaluation. Experiments\non diverse real-world benchmarks demonstrate that MerCBO performs similarly or\nbetter than prior methods. The source code is available at\nhttps://github.com/aryandeshwal/MerCBO .\n", "versions": [{"version": "v1", "created": "Mon, 14 Dec 2020 17:58:39 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["Deshwal", "Aryan", ""], ["Belakaria", "Syrine", ""], ["Doppa", "Janardhan Rao", ""]]}, {"id": "2012.07769", "submitter": "Tianhe Yu", "authors": "Tianhe Yu, Xinyang Geng, Chelsea Finn, Sergey Levine", "title": "Variable-Shot Adaptation for Online Meta-Learning", "comments": "First two authors contribute equally", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Few-shot meta-learning methods consider the problem of learning new tasks\nfrom a small, fixed number of examples, by meta-learning across static data\nfrom a set of previous tasks. However, in many real world settings, it is more\nnatural to view the problem as one of minimizing the total amount of\nsupervision --- both the number of examples needed to learn a new task and the\namount of data needed for meta-learning. Such a formulation can be studied in a\nsequential learning setting, where tasks are presented in sequence. When\nstudying meta-learning in this online setting, a critical question arises: can\nmeta-learning improve over the sample complexity and regret of standard\nempirical risk minimization methods, when considering both meta-training and\nadaptation together? The answer is particularly non-obvious for meta-learning\nalgorithms with complex bi-level optimizations that may demand large amounts of\nmeta-training data. To answer this question, we extend previous meta-learning\nalgorithms to handle the variable-shot settings that naturally arise in\nsequential learning: from many-shot learning at the start, to zero-shot\nlearning towards the end. On sequential learning problems, we find that\nmeta-learning solves the full task set with fewer overall labels and achieves\ngreater cumulative performance, compared to standard supervised methods. These\nresults suggest that meta-learning is an important ingredient for building\nlearning systems that continuously learn and improve over a sequence of\nproblems.\n", "versions": [{"version": "v1", "created": "Mon, 14 Dec 2020 18:05:24 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["Yu", "Tianhe", ""], ["Geng", "Xinyang", ""], ["Finn", "Chelsea", ""], ["Levine", "Sergey", ""]]}, {"id": "2012.07788", "submitter": "Niklas Muennighoff", "authors": "Niklas Muennighoff", "title": "Vilio: State-of-the-art Visio-Linguistic Models applied to Hateful Memes", "comments": "Presented at NIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work presents Vilio, an implementation of state-of-the-art\nvisio-linguistic models and their application to the Hateful Memes Dataset. The\nimplemented models have been fitted into a uniform code-base and altered to\nyield better performance. The goal of Vilio is to provide a user-friendly\nstarting point for any visio-linguistic problem. An ensemble of 5 different V+L\nmodels implemented in Vilio achieves 2nd place in the Hateful Memes Challenge\nout of 3,300 participants. The code is available at\nhttps://github.com/Muennighoff/vilio.\n", "versions": [{"version": "v1", "created": "Mon, 14 Dec 2020 18:25:03 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["Muennighoff", "Niklas", ""]]}, {"id": "2012.07827", "submitter": "Kate Baumli", "authors": "Kate Baumli, David Warde-Farley, Steven Hansen, Volodymyr Mnih", "title": "Relative Variational Intrinsic Control", "comments": "Accepted by AAAI2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the absence of external rewards, agents can still learn useful behaviors\nby identifying and mastering a set of diverse skills within their environment.\nExisting skill learning methods use mutual information objectives to\nincentivize each skill to be diverse and distinguishable from the rest.\nHowever, if care is not taken to constrain the ways in which the skills are\ndiverse, trivially diverse skill sets can arise. To ensure useful skill\ndiversity, we propose a novel skill learning objective, Relative Variational\nIntrinsic Control (RVIC), which incentivizes learning skills that are\ndistinguishable in how they change the agent's relationship to its environment.\nThe resulting set of skills tiles the space of affordances available to the\nagent. We qualitatively analyze skill behaviors on multiple environments and\nshow how RVIC skills are more useful than skills discovered by existing methods\nwhen used in hierarchical reinforcement learning.\n", "versions": [{"version": "v1", "created": "Mon, 14 Dec 2020 18:59:23 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["Baumli", "Kate", ""], ["Warde-Farley", "David", ""], ["Hansen", "Steven", ""], ["Mnih", "Volodymyr", ""]]}, {"id": "2012.07881", "submitter": "Denis Kleyko", "authors": "Denis Kleyko, Antonello Rosato, E. Paxon Frady, Massimo Panella,\n  Friedrich T. Sommer", "title": "Perceptron Theory for Predicting the Accuracy of Neural Networks", "comments": "12 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Many neural network models have been successful at classification problems,\nbut their operation is still treated as a black box. Here, we developed a\ntheory for one-layer perceptrons that can predict performance on classification\ntasks. This theory is a generalization of an existing theory for predicting the\nperformance of Echo State Networks and connectionist models for symbolic\nreasoning known as Vector Symbolic Architectures. In this paper, we first show\nthat the proposed perceptron theory can predict the performance of Echo State\nNetworks, which could not be described by the previous theory. Second, we apply\nour perceptron theory to the last layers of shallow randomly connected and deep\nmulti-layer networks. The full theory is based on Gaussian statistics, but it\nis analytically intractable. We explore numerical methods to predict network\nperformance for problems with a small number of classes. For problems with a\nlarge number of classes, we investigate stochastic sampling methods and a\ntractable approximation to the full theory. The quality of predictions is\nassessed in three experimental settings, using reservoir computing networks on\na memorization task, shallow randomly connected networks on a collection of\nclassification datasets, and deep convolutional networks with the ImageNet\ndataset. This study offers a simple, bipartite approach to understand deep\nneural networks: the input is encoded by the last-but-one layers into a\nhigh-dimensional representation. This representation is mapped through the\nweights of the last layer into the postsynaptic sums of the output neurons.\nSpecifically, the proposed perceptron theory uses the mean vector and\ncovariance matrix of the postsynaptic sums to compute classification accuracies\nfor the different classes. The first two moments of the distribution of the\npostsynaptic sums can predict the overall network performance quite accurately.\n", "versions": [{"version": "v1", "created": "Mon, 14 Dec 2020 19:02:26 GMT"}], "update_date": "2020-12-16", "authors_parsed": [["Kleyko", "Denis", ""], ["Rosato", "Antonello", ""], ["Frady", "E. Paxon", ""], ["Panella", "Massimo", ""], ["Sommer", "Friedrich T.", ""]]}, {"id": "2012.07885", "submitter": "Abhilash Nandy", "authors": "Abhilash Nandy, Chandan Kumar, Deepak Mewada, Soumya Sharma", "title": "Bayesian Optimization -- Multi-Armed Bandit Problem", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this report, we survey Bayesian Optimization methods focussed on the\nMulti-Armed Bandit Problem. We take the help of the paper \"Portfolio Allocation\nfor Bayesian Optimization\". We report a small literature survey on the\nacquisition functions and the types of portfolio strategies used in papers\ndiscussing Bayesian Optimization. We also replicate the experiments and report\nour findings and compare them to the results in the paper. Code link:\nhttps://colab.research.google.com/drive/1GZ14klEDoe3dcBeZKo5l8qqrKf_GmBDn?usp=sharing#scrollTo=XgIBau3O45_V.\n", "versions": [{"version": "v1", "created": "Mon, 14 Dec 2020 19:08:37 GMT"}], "update_date": "2020-12-16", "authors_parsed": [["Nandy", "Abhilash", ""], ["Kumar", "Chandan", ""], ["Mewada", "Deepak", ""], ["Sharma", "Soumya", ""]]}, {"id": "2012.07910", "submitter": "Li-Cheng Lan", "authors": "Li-Cheng Lan, Meng-Yu Tsai, Ti-Rong Wu, I-Chen Wu, Cho-Jui Hsieh", "title": "Learning to Stop: Dynamic Simulation Monte-Carlo Tree Search", "comments": "Proceedings of the Thirty-Fifth AAAI Conference on Artificial\n  Intelligence (AAAI-21)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Monte Carlo tree search (MCTS) has achieved state-of-the-art results in many\ndomains such as Go and Atari games when combining with deep neural networks\n(DNNs). When more simulations are executed, MCTS can achieve higher performance\nbut also requires enormous amounts of CPU and GPU resources. However, not all\nstates require a long searching time to identify the best action that the agent\ncan find. For example, in 19x19 Go and NoGo, we found that for more than half\nof the states, the best action predicted by DNN remains unchanged even after\nsearching 2 minutes. This implies that a significant amount of resources can be\nsaved if we are able to stop the searching earlier when we are confident with\nthe current searching result. In this paper, we propose to achieve this goal by\npredicting the uncertainty of the current searching status and use the result\nto decide whether we should stop searching. With our algorithm, called Dynamic\nSimulation MCTS (DS-MCTS), we can speed up a NoGo agent trained by AlphaZero\n2.5 times faster while maintaining a similar winning rate. Also, under the same\naverage simulation count, our method can achieve a 61% winning rate against the\noriginal program.\n", "versions": [{"version": "v1", "created": "Mon, 14 Dec 2020 19:49:25 GMT"}], "update_date": "2020-12-16", "authors_parsed": [["Lan", "Li-Cheng", ""], ["Tsai", "Meng-Yu", ""], ["Wu", "Ti-Rong", ""], ["Wu", "I-Chen", ""], ["Hsieh", "Cho-Jui", ""]]}, {"id": "2012.07962", "submitter": "Michalis Lazarou Mr", "authors": "Michalis Lazarou, Yannis Avrithis, Tania Stathaki", "title": "Iterative label cleaning for transductive and semi-supervised few-shot\n  learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Few-shot learning amounts to learning representations and acquiring knowledge\nsuch that novel tasks may be solved with both supervision and data being\nlimited. Improved performance is possible by transductive inference, where the\nentire test set is available concurrently, and semi-supervised learning, where\nmore unlabeled data is available. These problems are closely related because\nthere is little or no adaptation of the representation in novel tasks.\n  Focusing on these two settings, we introduce a new algorithm that leverages\nthe manifold structure of the labeled and unlabeled data distribution to\npredict pseudo-labels, while balancing over classes and using the loss value\ndistribution of a limited-capacity classifier to select the cleanest labels,\niterately improving the quality of pseudo-labels. Our solution sets new state\nof the art on four benchmark datasets, namely \\emph{mini}ImageNet,\n\\emph{tiered}ImageNet, CUB and CIFAR-FS, while being robust over feature space\npre-processing and the quantity of available data.\n", "versions": [{"version": "v1", "created": "Mon, 14 Dec 2020 21:54:11 GMT"}], "update_date": "2020-12-16", "authors_parsed": [["Lazarou", "Michalis", ""], ["Avrithis", "Yannis", ""], ["Stathaki", "Tania", ""]]}, {"id": "2012.07975", "submitter": "Albert Zhan", "authors": "Albert Zhan, Philip Zhao, Lerrel Pinto, Pieter Abbeel, Michael Laskin", "title": "A Framework for Efficient Robotic Manipulation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Data-efficient learning of manipulation policies from visual observations is\nan outstanding challenge for real-robot learning. While deep reinforcement\nlearning (RL) algorithms have shown success learning policies from visual\nobservations, they still require an impractical number of real-world data\nsamples to learn effective policies. However, recent advances in unsupervised\nrepresentation learning and data augmentation significantly improved the sample\nefficiency of training RL policies on common simulated benchmarks. Building on\nthese advances, we present a Framework for Efficient Robotic Manipulation\n(FERM) that utilizes data augmentation and unsupervised learning to achieve\nextremely sample-efficient training of robotic manipulation policies with\nsparse rewards. We show that, given only 10 demonstrations, a single robotic\narm can learn sparse-reward manipulation policies from pixels, such as\nreaching, picking, moving, pulling a large object, flipping a switch, and\nopening a drawer in just 15-50 minutes of real-world training time. We include\nvideos, code, and additional information on the project website --\nhttps://sites.google.com/view/efficient-robotic-manipulation.\n", "versions": [{"version": "v1", "created": "Mon, 14 Dec 2020 22:18:39 GMT"}], "update_date": "2020-12-16", "authors_parsed": [["Zhan", "Albert", ""], ["Zhao", "Philip", ""], ["Pinto", "Lerrel", ""], ["Abbeel", "Pieter", ""], ["Laskin", "Michael", ""]]}, {"id": "2012.07982", "submitter": "Huichen Yang", "authors": "Adedolapo Okanlawon, Huichen Yang, Avishek Bose, William Hsu, Dan\n  Andresen, Mohammed Tanash", "title": "Feature Selection for Learning to Predict Outcomes of Compute Cluster\n  Jobs with Application to Decision Support", "comments": "6 pages, Proceedings of the International Conference on Computational\n  Science and Computational Intelligence Symposium on Parallel & Distributed\n  Computing (CSCI-ISPD 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present a machine learning framework and a new test bed for data mining\nfrom the Slurm Workload Manager for high-performance computing (HPC) clusters.\nThe focus was to find a method for selecting features to support decisions:\nhelping users decide whether to resubmit failed jobs with boosted CPU and\nmemory allocations or migrate them to a computing cloud. This task was cast as\nboth supervised classification and regression learning, specifically,\nsequential problem solving suitable for reinforcement learning. Selecting\nrelevant features can improve training accuracy, reduce training time, and\nproduce a more comprehensible model, with an intelligent system that can\nexplain predictions and inferences. We present a supervised learning model\ntrained on a Simple Linux Utility for Resource Management (Slurm) data set of\nHPC jobs using three different techniques for selecting features: linear\nregression, lasso, and ridge regression. Our data set represented both HPC jobs\nthat failed and those that succeeded, so our model was reliable, less likely to\noverfit, and generalizable. Our model achieved an R^2 of 95\\% with 99\\%\naccuracy. We identified five predictors for both CPU and memory properties.\n", "versions": [{"version": "v1", "created": "Mon, 14 Dec 2020 22:35:02 GMT"}], "update_date": "2020-12-16", "authors_parsed": [["Okanlawon", "Adedolapo", ""], ["Yang", "Huichen", ""], ["Bose", "Avishek", ""], ["Hsu", "William", ""], ["Andresen", "Dan", ""], ["Tanash", "Mohammed", ""]]}, {"id": "2012.07983", "submitter": "Zhiwei Zhang", "authors": "Anastasios Kyrillidis, Moshe Y. Vardi, Zhiwei Zhang", "title": "On Continuous Local BDD-Based Search for Hybrid SAT Solving", "comments": "AAAI 21", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.IT cs.LG cs.LO math.IT math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We explore the potential of continuous local search (CLS) in SAT solving by\nproposing a novel approach for finding a solution of a hybrid system of Boolean\nconstraints. The algorithm is based on CLS combined with belief propagation on\nbinary decision diagrams (BDDs). Our framework accepts all Boolean constraints\nthat admit compact BDDs, including symmetric Boolean constraints and\nsmall-coefficient pseudo-Boolean constraints as interesting families. We\npropose a novel algorithm for efficiently computing the gradient needed by CLS.\nWe study the capabilities and limitations of our versatile CLS solver, GradSAT,\nby applying it on many benchmark instances. The experimental results indicate\nthat GradSAT can be a useful addition to the portfolio of existing SAT and\nMaxSAT solvers for solving Boolean satisfiability and optimization problems.\n", "versions": [{"version": "v1", "created": "Mon, 14 Dec 2020 22:36:20 GMT"}, {"version": "v2", "created": "Sat, 12 Jun 2021 22:38:47 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Kyrillidis", "Anastasios", ""], ["Vardi", "Moshe Y.", ""], ["Zhang", "Zhiwei", ""]]}, {"id": "2012.07988", "submitter": "Xiaohui Chen", "authors": "Xu Han, Xiaohui Chen, Li-Ping Liu", "title": "GAN Ensemble for Anomaly Detection", "comments": "8 pages, 6 figures. To appear in Proceedings 35th AAAI Conference on\n  Artificial Intelligence (AAAI 21)", "journal-ref": "Proceedings of the AAAI Conference on Artificial Intelligence,\n  35(5), 4090-4097 (2021). Retrieved from\n  https://ojs.aaai.org/index.php/AAAI/article/view/16530", "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  When formulated as an unsupervised learning problem, anomaly detection often\nrequires a model to learn the distribution of normal data. Previous works apply\nGenerative Adversarial Networks (GANs) to anomaly detection tasks and show good\nperformances from these models. Motivated by the observation that GAN ensembles\noften outperform single GANs in generation tasks, we propose to construct GAN\nensembles for anomaly detection. In the proposed method, a group of generators\nand a group of discriminators are trained together, so every generator gets\nfeedback from multiple discriminators, and vice versa. Compared to a single\nGAN, a GAN ensemble can better model the distribution of normal data and thus\nbetter detect anomalies. Our theoretical analysis of GANs and GAN ensembles\nexplains the role of a GAN discriminator in anomaly detection. In the empirical\nstudy, we evaluate ensembles constructed from four types of base models, and\nthe results show that these ensembles clearly outperform single models in a\nseries of tasks of anomaly detection.\n", "versions": [{"version": "v1", "created": "Mon, 14 Dec 2020 22:39:20 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Han", "Xu", ""], ["Chen", "Xiaohui", ""], ["Liu", "Li-Ping", ""]]}, {"id": "2012.07989", "submitter": "Shadrack Awah Buo", "authors": "Shadrack Awah Buo", "title": "The Emerging Threats of Deepfake Attacks and Countermeasures", "comments": "5", "journal-ref": null, "doi": "10.13140/RG.2.2.23089.81762", "report-no": null, "categories": "cs.CR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deepfake technology (DT) has taken a new level of sophistication.\nCybercriminals now can manipulate sounds, images, and videos to defraud and\nmisinform individuals and businesses. This represents a growing threat to\ninternational institutions and individuals which needs to be addressed. This\npaper provides an overview of deepfakes, their benefits to society, and how DT\nworks. Highlights the threats that are presented by deepfakes to businesses,\npolitics, and judicial systems worldwide. Additionally, the paper will explore\npotential solutions to deepfakes and conclude with future research direction.\n", "versions": [{"version": "v1", "created": "Mon, 14 Dec 2020 22:40:49 GMT"}], "update_date": "2020-12-16", "authors_parsed": [["Buo", "Shadrack Awah", ""]]}, {"id": "2012.08000", "submitter": "Sharan Srinivas", "authors": "Sharan Srinivas, Surya Ramachandiran", "title": "Discovering Airline-Specific Business Intelligence from Online Passenger\n  Reviews: An Unsupervised Text Analytics Approach", "comments": "34 pages, 8 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  To understand the important dimensions of service quality from the\npassenger's perspective and tailor service offerings for competitive advantage,\nairlines can capitalize on the abundantly available online customer reviews\n(OCR). The objective of this paper is to discover company- and\ncompetitor-specific intelligence from OCR using an unsupervised text analytics\napproach. First, the key aspects (or topics) discussed in the OCR are extracted\nusing three topic models - probabilistic latent semantic analysis (pLSA) and\ntwo variants of Latent Dirichlet allocation (LDA-VI and LDA-GS). Subsequently,\nwe propose an ensemble-assisted topic model (EA-TM), which integrates the\nindividual topic models, to classify each review sentence to the most\nrepresentative aspect. Likewise, to determine the sentiment corresponding to a\nreview sentence, an ensemble sentiment analyzer (E-SA), which combines the\npredictions of three opinion mining methods (AFINN, SentiStrength, and VADER),\nis developed. An aspect-based opinion summary (AOS), which provides a snapshot\nof passenger-perceived strengths and weaknesses of an airline, is established\nby consolidating the sentiments associated with each aspect. Furthermore, a\nbi-gram analysis of the labeled OCR is employed to perform root cause analysis\nwithin each identified aspect. A case study involving 99,147 airline reviews of\na US-based target carrier and four of its competitors is used to validate the\nproposed approach. The results indicate that a cost- and time-effective\nperformance summary of an airline and its competitors can be obtained from OCR.\nFinally, besides providing theoretical and managerial implications based on our\nresults, we also provide implications for post-pandemic preparedness in the\nairline industry considering the unprecedented impact of coronavirus disease\n2019 (COVID-19) and predictions on similar pandemics in the future.\n", "versions": [{"version": "v1", "created": "Mon, 14 Dec 2020 23:09:10 GMT"}], "update_date": "2020-12-16", "authors_parsed": [["Srinivas", "Sharan", ""], ["Ramachandiran", "Surya", ""]]}, {"id": "2012.08005", "submitter": "Andrea Zanette", "authors": "Andrea Zanette", "title": "Exponential Lower Bounds for Batch Reinforcement Learning: Batch RL can\n  be Exponentially Harder than Online RL", "comments": "Accepted to ICML 2021 as long talk", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Several practical applications of reinforcement learning involve an agent\nlearning from past data without the possibility of further exploration. Often\nthese applications require us to 1) identify a near optimal policy or to 2)\nestimate the value of a target policy. For both tasks we derive\n\\emph{exponential} information-theoretic lower bounds in discounted infinite\nhorizon MDPs with a linear function representation for the action value\nfunction even if 1) \\emph{realizability} holds, 2) the batch algorithm observes\nthe exact reward and transition \\emph{functions}, and 3) the batch algorithm is\ngiven the \\emph{best} a priori data distribution for the problem class. Our\nwork introduces a new `oracle + batch algorithm' framework to prove lower\nbounds that hold for every distribution. The work shows an exponential\nseparation between batch and online reinforcement learning.\n", "versions": [{"version": "v1", "created": "Mon, 14 Dec 2020 23:27:16 GMT"}, {"version": "v2", "created": "Tue, 9 Feb 2021 02:40:44 GMT"}, {"version": "v3", "created": "Sun, 25 Apr 2021 22:13:37 GMT"}, {"version": "v4", "created": "Sat, 19 Jun 2021 22:52:41 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Zanette", "Andrea", ""]]}, {"id": "2012.08009", "submitter": "Yae Jee Cho", "authors": "Yae Jee Cho, Samarth Gupta, Gauri Joshi, Osman Ya\\u{g}an", "title": "Bandit-based Communication-Efficient Client Selection Strategies for\n  Federated Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to communication constraints and intermittent client availability in\nfederated learning, only a subset of clients can participate in each training\nround. While most prior works assume uniform and unbiased client selection,\nrecent work on biased client selection has shown that selecting clients with\nhigher local losses can improve error convergence speed. However, previously\nproposed biased selection strategies either require additional communication\ncost for evaluating the exact local loss or utilize stale local loss, which can\neven make the model diverge. In this paper, we present a bandit-based\ncommunication-efficient client selection strategy UCB-CS that achieves faster\nconvergence with lower communication overhead. We also demonstrate how client\nselection can be used to improve fairness.\n", "versions": [{"version": "v1", "created": "Mon, 14 Dec 2020 23:35:03 GMT"}], "update_date": "2020-12-16", "authors_parsed": [["Cho", "Yae Jee", ""], ["Gupta", "Samarth", ""], ["Joshi", "Gauri", ""], ["Ya\u011fan", "Osman", ""]]}, {"id": "2012.08026", "submitter": "Miaowei Wang", "authors": "Miaowei Wang, Alexander William Mohacey, Hongyu Wang, James Apfel", "title": "Classification of Smoking and Calling using Deep Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Since 2014, very deep convolutional neural networks have been proposed and\nbecome the must-have weapon for champions in all kinds of competition. In this\nreport, a pipeline is introduced to perform the classification of smoking and\ncalling by modifying the pretrained inception V3. Brightness enhancing based on\ndeep learning is implemented to improve the classification of this\nclassification task along with other useful training tricks. Based on the\nquality and quantity results, it can be concluded that this pipeline with small\nbiased samples is practical and useful with high accuracy.\n", "versions": [{"version": "v1", "created": "Tue, 15 Dec 2020 00:59:57 GMT"}], "update_date": "2020-12-16", "authors_parsed": [["Wang", "Miaowei", ""], ["Mohacey", "Alexander William", ""], ["Wang", "Hongyu", ""], ["Apfel", "James", ""]]}, {"id": "2012.08033", "submitter": "Blai Bonet", "authors": "Blai Bonet and Hector Geffner", "title": "General Policies, Serializations, and Planning Width", "comments": "Longer version of AAAI-2021 paper that includes proofs and more\n  explanations", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  It has been observed that in many of the benchmark planning domains, atomic\ngoals can be reached with a simple polynomial exploration procedure, called IW,\nthat runs in time exponential in the problem width. Such problems have indeed a\nbounded width: a width that does not grow with the number of problem variables\nand is often no greater than two. Yet, while the notion of width has become\npart of the state-of-the-art planning algorithms like BFWS, there is still no\ngood explanation for why so many benchmark domains have bounded width. In this\nwork, we address this question by relating bounded width and serialized width\nto ideas of generalized planning, where general policies aim to solve multiple\ninstances of a planning problem all at once. We show that bounded width is a\nproperty of planning domains that admit optimal general policies in terms of\nfeatures that are explicitly or implicitly represented in the domain encoding.\nThe results are extended to much larger class of domains with bounded\nserialized width where the general policies do not have to be optimal. The\nstudy leads also to a new simple, meaningful, and expressive language for\nspecifying domain serializations in the form of policy sketches which can be\nused for encoding domain control knowledge by hand or for learning it from\ntraces. The use of sketches and the meaning of the theoretical results are all\nillustrated through a number of examples.\n", "versions": [{"version": "v1", "created": "Tue, 15 Dec 2020 01:33:59 GMT"}, {"version": "v2", "created": "Wed, 23 Dec 2020 16:14:01 GMT"}], "update_date": "2020-12-24", "authors_parsed": [["Bonet", "Blai", ""], ["Geffner", "Hector", ""]]}, {"id": "2012.08067", "submitter": "Manqing Ma", "authors": "Manqing Ma, Gyorgy Korniss, Boleslaw K. Szymanski", "title": "Learning Parameters for Balanced Index Influence Maximization", "comments": null, "journal-ref": "Proc 9th Int Conference on Complex Networks and Their\n  Applications, Madrid, Dec. 2020, pp. 167-177", "doi": "10.1007/978-3-030-65351-4_14", "report-no": null, "categories": "cs.AI cs.SI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Influence maximization is the task of finding the smallest set of nodes whose\nactivation in a social network can trigger an activation cascade that reaches\nthe targeted network coverage, where threshold rules determine the outcome of\ninfluence. This problem is NP-hard and it has generated a significant amount of\nrecent research on finding efficient heuristics. We focus on a {\\it Balance\nIndex} algorithm that relies on three parameters to tune its performance to the\ngiven network structure. We propose using a supervised machine-learning\napproach for such tuning. We select the most influential graph features for the\nparameter tuning. Then, using random-walk-based graph-sampling, we create small\nsnapshots from the given synthetic and large-scale real-world networks. Using\nexhaustive search, we find for these snapshots the high accuracy values of BI\nparameters to use as a ground truth. Then, we train our machine-learning model\non the snapshots and apply this model to the real-word network to find the best\nBI parameters. We apply these parameters to the sampled real-world network to\nmeasure the quality of the sets of initiators found this way. We use various\nreal-world networks to validate our approach against other heuristic.\n", "versions": [{"version": "v1", "created": "Tue, 15 Dec 2020 03:30:54 GMT"}], "update_date": "2021-04-16", "authors_parsed": [["Ma", "Manqing", ""], ["Korniss", "Gyorgy", ""], ["Szymanski", "Boleslaw K.", ""]]}, {"id": "2012.08105", "submitter": "Panpan Li", "authors": "Panpan Li, Yikun Gong, Chen Wang", "title": "Schema Extraction on Semi-structured Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the continuous development of NoSQL databases, more and more developers\nchoose to use semi-structured data for development and data management, which\nputs forward requirements for schema management of semi-structured data stored\nin NoSQL databases. Schema extraction plays an important role in understanding\nschemas, optimizing queries, and validating data consistency. Therefore, in\nthis survey we investigate structural methods based on tree and graph and\nstatistical methods based on distributed architecture and machine learning to\nextract schemas. The schemas obtained by the structural methods are more\ninterpretable, and the statistical methods have better applicability and\ngeneralization ability. Moreover, we also investigate tools and systems for\nschemas extraction. Schema extraction tools are mainly used for spark or NoSQL\ndatabases, and are suitable for small datasets or simple application\nenvironments. The system mainly focuses on the extraction and management of\nschemas in large data sets and complex application scenarios. Furthermore, we\nalso compare these techniques to facilitate data managers' choice.\n", "versions": [{"version": "v1", "created": "Tue, 15 Dec 2020 05:57:41 GMT"}], "update_date": "2020-12-16", "authors_parsed": [["Li", "Panpan", ""], ["Gong", "Yikun", ""], ["Wang", "Chen", ""]]}, {"id": "2012.08128", "submitter": "Yao Zhu", "authors": "Yao Zhu, Hongzhi Liu, Zhonghai Wu, Yingpeng Du", "title": "Relation-Aware Neighborhood Matching Model for Entity Alignment", "comments": "AAAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Entity alignment which aims at linking entities with the same meaning from\ndifferent knowledge graphs (KGs) is a vital step for knowledge fusion. Existing\nresearch focused on learning embeddings of entities by utilizing structural\ninformation of KGs for entity alignment. These methods can aggregate\ninformation from neighboring nodes but may also bring noise from neighbors.\nMost recently, several researchers attempted to compare neighboring nodes in\npairs to enhance the entity alignment. However, they ignored the relations\nbetween entities which are also important for neighborhood matching. In\naddition, existing methods paid less attention to the positive interactions\nbetween the entity alignment and the relation alignment. To deal with these\nissues, we propose a novel Relation-aware Neighborhood Matching model named RNM\nfor entity alignment. Specifically, we propose to utilize the neighborhood\nmatching to enhance the entity alignment. Besides comparing neighbor nodes when\nmatching neighborhood, we also try to explore useful information from the\nconnected relations. Moreover, an iterative framework is designed to leverage\nthe positive interactions between the entity alignment and the relation\nalignment in a semi-supervised manner. Experimental results on three real-world\ndatasets demonstrate that the proposed model RNM performs better than\nstate-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Tue, 15 Dec 2020 07:22:39 GMT"}], "update_date": "2020-12-16", "authors_parsed": [["Zhu", "Yao", ""], ["Liu", "Hongzhi", ""], ["Wu", "Zhonghai", ""], ["Du", "Yingpeng", ""]]}, {"id": "2012.08134", "submitter": "Saurav Manchanda", "authors": "Saurav Manchanda and Mohit Sharma and George Karypis", "title": "Distant-Supervised Slot-Filling for E-Commerce Queries", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Slot-filling refers to the task of annotating individual terms in a query\nwith the corresponding intended product characteristics (product type, brand,\ngender, size, color, etc.). These characteristics can then be used by a search\nengine to return results that better match the query's product intent.\nTraditional methods for slot-filling require the availability of training data\nwith ground truth slot-annotation information. However, generating such labeled\ndata, especially in e-commerce is expensive and time-consuming because the\nnumber of slots increases as new products are added. In this paper, we present\ndistant-supervised probabilistic generative models, that require no manual\nannotation. The proposed approaches leverage the readily available historical\nquery logs and the purchases that these queries led to, and also exploit\nco-occurrence information among the slots in order to identify intended product\ncharacteristics. We evaluate our approaches by considering how they affect\nretrieval performance, as well as how well they classify the slots. In terms of\nretrieval, our approaches achieve better ranking performance (up to 156%) over\nOkapi BM25. Moreover, our approach that leverages co-occurrence information\nleads to better performance than the one that does not on both the retrieval\nand slot classification tasks.\n", "versions": [{"version": "v1", "created": "Tue, 15 Dec 2020 07:46:07 GMT"}], "update_date": "2020-12-16", "authors_parsed": [["Manchanda", "Saurav", ""], ["Sharma", "Mohit", ""], ["Karypis", "George", ""]]}, {"id": "2012.08141", "submitter": "Mingkuan Xu", "authors": "Yuanming Hu, Mingkuan Xu, Ye Kuang, Fr\\'edo Durand", "title": "AsyncTaichi: On-the-fly Inter-kernel Optimizations for Imperative and\n  Spatially Sparse Programming", "comments": "18 pages, 20 figures, submitted to ACM SIGGRAPH Asia", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.AI cs.GR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Leveraging spatial sparsity has become a popular approach to accelerate 3D\ncomputer graphics applications. Spatially sparse data structures and efficient\nsparse kernels (such as parallel stencil operations on active voxels), are key\nto achieve high performance. Existing work focuses on improving performance\nwithin a single sparse computational kernel. We show that a system that looks\nbeyond a single kernel, plus additional domain-specific sparse data structure\nanalysis, opens up exciting new space for optimizing sparse computations.\nSpecifically, we propose a domain-specific data-flow graph model of imperative\nand sparse computation programs, which describes kernel relationships and\nenables easy analysis and optimization. Combined with an asynchronous execution\nengine that exposes a wide window of kernels, the inter-kernel optimizer can\nthen perform effective sparse computation optimizations, such as eliminating\nunnecessary voxel list generations and removing voxel activation checks. These\ndomain-specific optimizations further make way for classical general-purpose\noptimizations that are originally challenging to directly apply to computations\nwith sparse data structures. Without any computational code modification, our\nnew system leads to $4.02\\times$ fewer kernel launches and $1.87\\times$ speed\nup on our GPU benchmarks, including computations on Eulerian grids, Lagrangian\nparticles, meshes, and automatic differentiation.\n", "versions": [{"version": "v1", "created": "Tue, 15 Dec 2020 08:09:31 GMT"}, {"version": "v2", "created": "Tue, 22 Jun 2021 15:15:08 GMT"}], "update_date": "2021-06-23", "authors_parsed": [["Hu", "Yuanming", ""], ["Xu", "Mingkuan", ""], ["Kuang", "Ye", ""], ["Durand", "Fr\u00e9do", ""]]}, {"id": "2012.08148", "submitter": "Matteo Antonio Senese", "authors": "Matteo A. Senese, Alberto Benincasa, Barbara Caputo, Giuseppe Rizzo", "title": "A Response Retrieval Approach for Dialogue Using a Multi-Attentive\n  Transformer", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper presents our work for the ninth edition of the Dialogue System\nTechnology Challenge (DSTC9). Our solution addresses the track number four:\nSimulated Interactive MultiModal Conversations. The task consists in providing\nan algorithm able to simulate a shopping assistant that supports the user with\nhis/her requests. We address the task of response retrieval, that is the task\nof retrieving the most appropriate agent response from a pool of response\ncandidates. Our approach makes use of a neural architecture based on\ntransformer with a multi-attentive structure that conditions the response of\nthe agent on the request made by the user and on the product the user is\nreferring to. Final experiments on the SIMMC Fashion Dataset show that our\napproach achieves the second best scores on all the retrieval metrics defined\nby the organizers. The source code is available at\nhttps://github.com/D2KLab/dstc9-SIMMC.\n", "versions": [{"version": "v1", "created": "Tue, 15 Dec 2020 08:35:58 GMT"}], "update_date": "2020-12-16", "authors_parsed": [["Senese", "Matteo A.", ""], ["Benincasa", "Alberto", ""], ["Caputo", "Barbara", ""], ["Rizzo", "Giuseppe", ""]]}, {"id": "2012.08153", "submitter": "Han Zhang", "authors": "Han Zhang, Wenhao Zheng, Charley Chen, Kevin Gao, Yao Hu, Ling Huang,\n  and Wei Xu", "title": "Modeling Heterogeneous Statistical Patterns in High-dimensional Data by\n  Adversarial Distributions: An Unsupervised Generative Framework", "comments": null, "journal-ref": null, "doi": "10.1145/3366423.3380213", "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Since the label collecting is prohibitive and time-consuming, unsupervised\nmethods are preferred in applications such as fraud detection. Meanwhile, such\napplications usually require modeling the intrinsic clusters in\nhigh-dimensional data, which usually displays heterogeneous statistical\npatterns as the patterns of different clusters may appear in different\ndimensions. Existing methods propose to model the data clusters on selected\ndimensions, yet globally omitting any dimension may damage the pattern of\ncertain clusters. To address the above issues, we propose a novel unsupervised\ngenerative framework called FIRD, which utilizes adversarial distributions to\nfit and disentangle the heterogeneous statistical patterns. When applying to\ndiscrete spaces, FIRD effectively distinguishes the synchronized fraudsters\nfrom normal users. Besides, FIRD also provides superior performance on anomaly\ndetection datasets compared with SOTA anomaly detection methods (over 5%\naverage AUC improvement). The significant experiment results on various\ndatasets verify that the proposed method can better model the heterogeneous\nstatistical patterns in high-dimensional data and benefit downstream\napplications.\n", "versions": [{"version": "v1", "created": "Tue, 15 Dec 2020 08:51:20 GMT"}], "update_date": "2020-12-16", "authors_parsed": [["Zhang", "Han", ""], ["Zheng", "Wenhao", ""], ["Chen", "Charley", ""], ["Gao", "Kevin", ""], ["Hu", "Yao", ""], ["Huang", "Ling", ""], ["Xu", "Wei", ""]]}, {"id": "2012.08174", "submitter": "Georgios Papadopoulos Th.", "authors": "Georgios Th. Papadopoulos, Margherita Antona, Constantine Stephanidis", "title": "Towards open and expandable cognitive AI architectures for large-scale\n  multi-agent human-robot collaborative learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.HC cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Learning from Demonstration (LfD) constitutes one of the most robust\nmethodologies for constructing efficient cognitive robotic systems. Despite the\nlarge body of research works already reported, current key technological\nchallenges include those of multi-agent learning and long-term autonomy.\nTowards this direction, a novel cognitive architecture for multi-agent LfD\nrobotic learning is introduced, targeting to enable the reliable deployment of\nopen, scalable and expandable robotic systems in large-scale and complex\nenvironments. In particular, the designed architecture capitalizes on the\nrecent advances in the Artificial Intelligence (AI) field, by establishing a\nFederated Learning (FL)-based framework for incarnating a multi-human\nmulti-robot collaborative learning environment. The fundamental\nconceptualization relies on employing multiple AI-empowered cognitive processes\n(implementing various robotic tasks) that operate at the edge nodes of a\nnetwork of robotic platforms, while global AI models (underpinning the\naforementioned robotic tasks) are collectively created and shared among the\nnetwork, by elegantly combining information from a large number of human-robot\ninteraction instances. Regarding pivotal novelties, the designed cognitive\narchitecture a) introduces a new FL-based formalism that extends the\nconventional LfD learning paradigm to support large-scale multi-agent\noperational settings, b) elaborates previous FL-based self-learning robotic\nschemes so as to incorporate the human in the learning loop and c) consolidates\nthe fundamental principles of FL with additional sophisticated AI-enabled\nlearning methodologies for modelling the multi-level inter-dependencies among\nthe robotic tasks. The applicability of the proposed framework is explained\nusing an example of a real-world industrial case study for agile\nproduction-based Critical Raw Materials (CRM) recovery.\n", "versions": [{"version": "v1", "created": "Tue, 15 Dec 2020 09:49:22 GMT"}, {"version": "v2", "created": "Mon, 29 Mar 2021 17:15:00 GMT"}], "update_date": "2021-03-30", "authors_parsed": [["Papadopoulos", "Georgios Th.", ""], ["Antona", "Margherita", ""], ["Stephanidis", "Constantine", ""]]}, {"id": "2012.08178", "submitter": "Marcos Baez", "authors": "Maisie Badami, Marcos Baez, Shayan Zamanirad, Wei Kang", "title": "On how Cognitive Computing will plan your next Systematic Review", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL cs.AI cs.HC cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Systematic literature reviews (SLRs) are at the heart of evidence-based\nresearch, setting the foundation for future research and practice. However,\nproducing good quality timely contributions is a challenging and highly\ncognitive endeavor, which has lately motivated the exploration of automation\nand support in the SLR process. In this paper we address an often overlooked\nphase in this process, that of planning literature reviews, and explore under\nthe lenses of cognitive process augmentation how to overcome its most salient\nchallenges. In doing so, we report on the insights from 24 SLR authors on\nplanning practices, its challenges as well as feedback on support strategies\ninspired by recent advances in cognitive computing. We frame our findings under\nthe cognitive augmentation framework, and report on a prototype implementation\nand evaluation focusing on further informing the technical feasibility.\n", "versions": [{"version": "v1", "created": "Tue, 15 Dec 2020 09:56:09 GMT"}], "update_date": "2020-12-16", "authors_parsed": [["Badami", "Maisie", ""], ["Baez", "Marcos", ""], ["Zamanirad", "Shayan", ""], ["Kang", "Wei", ""]]}, {"id": "2012.08185", "submitter": "{\\DJ}or{\\dj}e \\v{Z}ikeli\\'c", "authors": "Thomas A. Henzinger, Mathias Lechner, {\\DJ}or{\\dj}e \\v{Z}ikeli\\'c", "title": "Scalable Verification of Quantized Neural Networks (Technical Report)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Formal verification of neural networks is an active topic of research, and\nrecent advances have significantly increased the size of the networks that\nverification tools can handle. However, most methods are designed for\nverification of an idealized model of the actual network which works over real\narithmetic and ignores rounding imprecisions. This idealization is in stark\ncontrast to network quantization, which is a technique that trades numerical\nprecision for computational efficiency and is, therefore, often applied in\npractice. Neglecting rounding errors of such low-bit quantized neural networks\nhas been shown to lead to wrong conclusions about the network's correctness.\nThus, the desired approach for verifying quantized neural networks would be one\nthat takes these rounding errors into account. In this paper, we show that\nverifying the bit-exact implementation of quantized neural networks with\nbit-vector specifications is PSPACE-hard, even though verifying idealized\nreal-valued networks and satisfiability of bit-vector specifications alone are\neach in NP. Furthermore, we explore several practical heuristics toward closing\nthe complexity gap between idealized and bit-exact verification. In particular,\nwe propose three techniques for making SMT-based verification of quantized\nneural networks more scalable. Our experiments demonstrate that our proposed\nmethods allow a speedup of up to three orders of magnitude over existing\napproaches.\n", "versions": [{"version": "v1", "created": "Tue, 15 Dec 2020 10:05:37 GMT"}], "update_date": "2020-12-16", "authors_parsed": [["Henzinger", "Thomas A.", ""], ["Lechner", "Mathias", ""], ["\u017dikeli\u0107", "\u0110or\u0111e", ""]]}, {"id": "2012.08196", "submitter": "Aijun Zhang", "authors": "Yifeng Guo, Yu Su, Zebin Yang and Aijun Zhang", "title": "Explainable Recommendation Systems by Generalized Additive Models with\n  Manifest and Latent Interactions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In recent years, the field of recommendation systems has attracted increasing\nattention to developing predictive models that provide explanations of why an\nitem is recommended to a user. The explanations can be either obtained by\npost-hoc diagnostics after fitting a relatively complex model or embedded into\nan intrinsically interpretable model. In this paper, we propose the explainable\nrecommendation systems based on a generalized additive model with manifest and\nlatent interactions (GAMMLI). This model architecture is intrinsically\ninterpretable, as it additively consists of the user and item main effects, the\nmanifest user-item interactions based on observed features, and the latent\ninteraction effects from residuals. Unlike conventional collaborative filtering\nmethods, the group effect of users and items are considered in GAMMLI. It is\nbeneficial for enhancing the model interpretability, and can also facilitate\nthe cold-start recommendation problem. A new Python package GAMMLI is developed\nfor efficient model training and visualized interpretation of the results. By\nnumerical experiments based on simulation data and real-world cases, the\nproposed method is shown to have advantages in both predictive performance and\nexplainable recommendation.\n", "versions": [{"version": "v1", "created": "Tue, 15 Dec 2020 10:29:12 GMT"}], "update_date": "2020-12-16", "authors_parsed": [["Guo", "Yifeng", ""], ["Su", "Yu", ""], ["Yang", "Zebin", ""], ["Zhang", "Aijun", ""]]}, {"id": "2012.08206", "submitter": "Carlos Badenes-Olmedo", "authors": "Carlos Badenes-Olmedo, Jose-Luis Redondo Garc\\'ia, Oscar Corcho", "title": "Efficient Clustering from Distributions over Topics", "comments": "Accepted at the 9th International Conference on Knowledge Capture\n  (K-CAP 2017)", "journal-ref": "ACM Proceedings of the Knowledge Capture Conference, article 17,\n  K-CAP 2017", "doi": "10.1145/3148011.3148019", "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  There are many scenarios where we may want to find pairs of textually similar\ndocuments in a large corpus (e.g. a researcher doing literature review, or an\nR&D project manager analyzing project proposals). To programmatically discover\nthose connections can help experts to achieve those goals, but brute-force\npairwise comparisons are not computationally adequate when the size of the\ndocument corpus is too large. Some algorithms in the literature divide the\nsearch space into regions containing potentially similar documents, which are\nlater processed separately from the rest in order to reduce the number of pairs\ncompared. However, this kind of unsupervised methods still incur in high\ntemporal costs. In this paper, we present an approach that relies on the\nresults of a topic modeling algorithm over the documents in a collection, as a\nmeans to identify smaller subsets of documents where the similarity function\ncan then be computed. This approach has proved to obtain promising results when\nidentifying similar documents in the domain of scientific publications. We have\ncompared our approach against state of the art clustering techniques and with\ndifferent configurations for the topic modeling algorithm. Results suggest that\nour approach outperforms (> 0.5) the other analyzed techniques in terms of\nefficiency.\n", "versions": [{"version": "v1", "created": "Tue, 15 Dec 2020 10:52:19 GMT"}], "update_date": "2020-12-16", "authors_parsed": [["Badenes-Olmedo", "Carlos", ""], ["Garc\u00eda", "Jose-Luis Redondo", ""], ["Corcho", "Oscar", ""]]}, {"id": "2012.08225", "submitter": "Alberto Maria Metelli", "authors": "Alberto Maria Metelli, Matteo Papini, Pierluca D'Oro, and Marcello\n  Restelli", "title": "Policy Optimization as Online Learning with Mediator Feedback", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Policy Optimization (PO) is a widely used approach to address continuous\ncontrol tasks. In this paper, we introduce the notion of mediator feedback that\nframes PO as an online learning problem over the policy space. The additional\navailable information, compared to the standard bandit feedback, allows reusing\nsamples generated by one policy to estimate the performance of other policies.\nBased on this observation, we propose an algorithm, RANDomized-exploration\npolicy Optimization via Multiple Importance Sampling with Truncation\n(RANDOMIST), for regret minimization in PO, that employs a randomized\nexploration strategy, differently from the existing optimistic approaches. When\nthe policy space is finite, we show that under certain circumstances, it is\npossible to achieve constant regret, while always enjoying logarithmic regret.\nWe also derive problem-dependent regret lower bounds. Then, we extend RANDOMIST\nto compact policy spaces. Finally, we provide numerical simulations on finite\nand compact policy spaces, in comparison with PO and bandit baselines.\n", "versions": [{"version": "v1", "created": "Tue, 15 Dec 2020 11:34:29 GMT"}], "update_date": "2020-12-16", "authors_parsed": [["Metelli", "Alberto Maria", ""], ["Papini", "Matteo", ""], ["D'Oro", "Pierluca", ""], ["Restelli", "Marcello", ""]]}, {"id": "2012.08231", "submitter": "Ruo Ando", "authors": "Ruo Ando, Yoshiyasu Takefuji", "title": "A new perspective of paramodulation complexity by solving massive 8\n  puzzles", "comments": "arXiv admin note: text overlap with arXiv:2011.00775", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A sliding puzzle is a combination puzzle where a player slide pieces along\ncertain routes on a board to reach a certain end-configuration. In this paper,\nwe propose a novel measurement of complexity of massive sliding puzzles with\nparamodulation which is an inference method of automated reasoning. It turned\nout that by counting the number of clauses yielded with paramodulation, we can\nevaluate the difficulty of each puzzle. In experiment, we have generated 100 *\n8 puzzles which passed the solvability checking by countering inversions. By\ndoing this, we can distinguish the complexity of 8 puzzles with the number of\ngenerated with paramodulation. For example, board [2,3,6,1,7,8,5,4, hole] is\nthe easiest with score 3008 and board [6,5,8,7,4,3,2,1, hole] is the most\ndifficult with score 48653. Besides, we have succeeded to obverse several\nlayers of complexity (the number of clauses generated) in 100 puzzles. We can\nconclude that proposal method can provide a new perspective of paramodulation\ncomplexity concerning sliding block puzzles.\n", "versions": [{"version": "v1", "created": "Tue, 15 Dec 2020 11:47:47 GMT"}], "update_date": "2020-12-16", "authors_parsed": [["Ando", "Ruo", ""], ["Takefuji", "Yoshiyasu", ""]]}, {"id": "2012.08254", "submitter": "Tanja Schneeberger", "authors": "Patrick Gebhard, Tanja Schneeberger, Michael Dietz, Elisabeth Andr\\'e,\n  Nida ul Habib Bajwa", "title": "Designing a Mobile Social and Vocational Reintegration Assistant for\n  Burn-out Outpatient Treatment", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Using Social Agents as health-care assistants or trainers is one focus area\nof IVA research. While their use as physical health-care agents is well\nestablished, their employment in the field of psychotherapeutic care comes with\ndaunting challenges. This paper presents our mobile Social Agent EmmA in the\nrole of a vocational reintegration assistant for burn-out outpatient treatment.\nWe follow a typical participatory design approach including experts and\npatients in order to address requirements from both sides. Since the success of\nsuch treatments is related to a patients emotion regulation capabilities, we\nemploy a real-time social signal interpretation together with a computational\nsimulation of emotion regulation that influences the agent's social behavior as\nwell as the situational selection of verbal treatment strategies. Overall, our\ninterdisciplinary approach enables a novel integrative concept for Social\nAgents as assistants for burn-out patients.\n", "versions": [{"version": "v1", "created": "Tue, 15 Dec 2020 12:41:56 GMT"}], "update_date": "2020-12-16", "authors_parsed": [["Gebhard", "Patrick", ""], ["Schneeberger", "Tanja", ""], ["Dietz", "Michael", ""], ["Andr\u00e9", "Elisabeth", ""], ["Bajwa", "Nida ul Habib", ""]]}, {"id": "2012.08285", "submitter": "Jakob Hoydis", "authors": "Jakob Hoydis, Fay\\c{c}al Ait Aoudia, Alvaro Valcarce, Harish\n  Viswanathan", "title": "Toward a 6G AI-Native Air Interface", "comments": "7 pages, 6 figures, accepted for publication in the IEEE\n  Communications Magazine", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.AI cs.IT cs.LG math.IT", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Each generation of cellular communication systems is marked by a defining\ndisruptive technology of its time, such as orthogonal frequency division\nmultiplexing (OFDM) for 4G or Massive multiple-input multiple-output (MIMO) for\n5G. Since artificial intelligence (AI) is the defining technology of our time,\nit is natural to ask what role it could play for 6G. While it is clear that 6G\nmust cater to the needs of large distributed learning systems, it is less\ncertain if AI will play a defining role in the design of 6G itself. The goal of\nthis article is to paint a vision of a new air interface which is partially\ndesigned by AI to enable optimized communication schemes for any hardware,\nradio environment, and application.\n", "versions": [{"version": "v1", "created": "Tue, 15 Dec 2020 13:46:04 GMT"}, {"version": "v2", "created": "Fri, 30 Apr 2021 09:21:45 GMT"}], "update_date": "2021-05-03", "authors_parsed": [["Hoydis", "Jakob", ""], ["Aoudia", "Fay\u00e7al Ait", ""], ["Valcarce", "Alvaro", ""], ["Viswanathan", "Harish", ""]]}, {"id": "2012.08288", "submitter": "Xin Wang", "authors": "Guangxi Li, Zhixin Song, Xin Wang", "title": "VSQL: Variational Shadow Quantum Learning for Classification", "comments": "20 pages. To appear in the Thirty-Fifth AAAI Conference on Artificial\n  Intelligence (AAAI 2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cond-mat.dis-nn cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Classification of quantum data is essential for quantum machine learning and\nnear-term quantum technologies. In this paper, we propose a new hybrid\nquantum-classical framework for supervised quantum learning, which we call\nVariational Shadow Quantum Learning (VSQL). Our method in particular utilizes\nthe classical shadows of quantum data, which fundamentally represent the side\ninformation of quantum data with respect to certain physical observables.\nSpecifically, we first use variational shadow quantum circuits to extract\nclassical features in a convolution way and then utilize a fully-connected\nneural network to complete the classification task. We show that this method\ncould sharply reduce the number of parameters and thus better facilitate\nquantum circuit training. Simultaneously, less noise will be introduced since\nfewer quantum gates are employed in such shadow circuits. Moreover, we show\nthat the Barren Plateau issue, a significant gradient vanishing problem in\nquantum machine learning, could be avoided in VSQL. Finally, we demonstrate the\nefficiency of VSQL in quantum classification via numerical experiments on the\nclassification of quantum states and the recognition of multi-labeled\nhandwritten digits. In particular, our VSQL approach outperforms existing\nvariational quantum classifiers in the test accuracy in the binary case of\nhandwritten digit recognition and notably requires much fewer parameters.\n", "versions": [{"version": "v1", "created": "Tue, 15 Dec 2020 13:51:01 GMT"}], "update_date": "2020-12-16", "authors_parsed": [["Li", "Guangxi", ""], ["Song", "Zhixin", ""], ["Wang", "Xin", ""]]}, {"id": "2012.08296", "submitter": "Karol Desnos", "authors": "Karol Desnos (UNIV-RENNES, INSA Rennes, IETR), Nicolas Sourbier (INSA\n  Rennes, UNIV-RENNES, IETR), Pierre-Yves Raumer (INSA Rennes, IETR), Olivier\n  Gesny, Maxime Pelcat (UNIV-RENNES, INSA Rennes, IETR)", "title": "Gegelati: Lightweight Artificial Intelligence through Generic and\n  Evolvable Tangled Program Graphs", "comments": null, "journal-ref": "Workshop on Design and Architectures for Signal and Image\n  Processing (DASIP), Jan 2021, Budapest, Hungary", "doi": "10.1145/3441110.3441575", "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tangled Program Graph (TPG) is a reinforcement learning technique based on\ngenetic programming concepts. On state-of-the-art learning environments, TPGs\nhave been shown to offer comparable competence with Deep Neural Networks\n(DNNs), for a fraction of their computational and storage cost. This lightness\nof TPGs, both for training and inference, makes them an interesting model to\nimplement Artificial Intelligences (AIs) on embedded systems with limited\ncomputational and storage resources. In this paper, we introduce the Gegelati\nlibrary for TPGs. Besides introducing the general concepts and features of the\nlibrary, two main contributions are detailed in the paper: 1/ The\nparallelization of the deterministic training process of TPGs, for supporting\nheterogeneous Multiprocessor Systems-on-Chips (MPSoCs). 2/ The support for\ncustomizable instruction sets and data types within the genetically evolved\nprograms of the TPG model. The scalability of the parallel training process is\ndemonstrated through experiments on architectures ranging from a high-end\n24-core processor to a low-power heterogeneous MPSoC. The impact of\ncustomizable instructions on the outcome of a training process is demonstrated\non a state-of-the-art reinforcement learning environment. CCS Concepts:\n$\\bullet$ Computer systems organization $\\rightarrow$ Embedded systems;\n$\\bullet$ Computing methodologies $\\rightarrow$ Machine learning.\n", "versions": [{"version": "v1", "created": "Tue, 15 Dec 2020 14:02:59 GMT"}], "update_date": "2020-12-16", "authors_parsed": [["Desnos", "Karol", "", "UNIV-RENNES, INSA Rennes, IETR"], ["Sourbier", "Nicolas", "", "INSA\n  Rennes, UNIV-RENNES, IETR"], ["Raumer", "Pierre-Yves", "", "INSA Rennes, IETR"], ["Gesny", "Olivier", "", "UNIV-RENNES, INSA Rennes, IETR"], ["Pelcat", "Maxime", "", "UNIV-RENNES, INSA Rennes, IETR"]]}, {"id": "2012.08298", "submitter": "David Kinney", "authors": "David H. Wolpert and David Kinney", "title": "Noisy Deductive Reasoning: How Humans Construct Math, and How Math\n  Constructs Universes", "comments": "Forthcoming in Undecidability, Uncomputability, and Unpredictability.\n  Springer. Ed. Anthony Aguirre, Zeeya Merali, and David Sloan. (Collection of\n  winning essays from FQXi's 2020 Essay Context)", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.LO cs.AI physics.hist-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a computational model of mathematical reasoning according to which\nmathematics is a fundamentally stochastic process. That is, on our model,\nwhether or not a given formula is deemed a theorem in some axiomatic system is\nnot a matter of certainty, but is instead governed by a probability\ndistribution. We then show that this framework gives a compelling account of\nseveral aspects of mathematical practice. These include: 1) the way in which\nmathematicians generate research programs, 2) the applicability of Bayesian\nmodels of mathematical heuristics, 3) the role of abductive reasoning in\nmathematics, 4) the way in which multiple proofs of a proposition can\nstrengthen our degree of belief in that proposition, and 5) the nature of the\nhypothesis that there are multiple formal systems that are isomorphic to\nphysically possible universes. Thus, by embracing a model of mathematics as not\nperfectly predictable, we generate a new and fruitful perspective on the\nepistemology and practice of mathematics.\n", "versions": [{"version": "v1", "created": "Wed, 28 Oct 2020 19:43:14 GMT"}], "update_date": "2020-12-16", "authors_parsed": [["Wolpert", "David H.", ""], ["Kinney", "David", ""]]}, {"id": "2012.08377", "submitter": "Peixiang Zhong", "authors": "Peixiang Zhong, Di Wang, Pengfei Li, Chen Zhang, Hao Wang, Chunyan\n  Miao", "title": "CARE: Commonsense-Aware Emotional Response Generation with Latent\n  Concepts", "comments": "AAAI-2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Rationality and emotion are two fundamental elements of humans. Endowing\nagents with rationality and emotion has been one of the major milestones in AI.\nHowever, in the field of conversational AI, most existing models only\nspecialize in one aspect and neglect the other, which often leads to dull or\nunrelated responses. In this paper, we hypothesize that combining rationality\nand emotion into conversational agents can improve response quality. To test\nthe hypothesis, we focus on one fundamental aspect of rationality, i.e.,\ncommonsense, and propose CARE, a novel model for commonsense-aware emotional\nresponse generation. Specifically, we first propose a framework to learn and\nconstruct commonsense-aware emotional latent concepts of the response given an\ninput message and a desired emotion. We then propose three methods to\ncollaboratively incorporate the latent concepts into response generation.\nExperimental results on two large-scale datasets support our hypothesis and\nshow that our model can produce more accurate and commonsense-aware emotional\nresponses and achieve better human ratings than state-of-the-art models that\nonly specialize in one aspect.\n", "versions": [{"version": "v1", "created": "Tue, 15 Dec 2020 15:47:30 GMT"}, {"version": "v2", "created": "Sun, 28 Feb 2021 05:53:41 GMT"}], "update_date": "2021-03-02", "authors_parsed": [["Zhong", "Peixiang", ""], ["Wang", "Di", ""], ["Li", "Pengfei", ""], ["Zhang", "Chen", ""], ["Wang", "Hao", ""], ["Miao", "Chunyan", ""]]}, {"id": "2012.08383", "submitter": "Peixiang Zhong", "authors": "Peixiang Zhong, Yong Liu, Hao Wang, Chunyan Miao", "title": "Keyword-Guided Neural Conversational Model", "comments": "AAAI-2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of imposing conversational goals/keywords on open-domain\nconversational agents, where the agent is required to lead the conversation to\na target keyword smoothly and fast. Solving this problem enables the\napplication of conversational agents in many real-world scenarios, e.g.,\nrecommendation and psychotherapy. The dominant paradigm for tackling this\nproblem is to 1) train a next-turn keyword classifier, and 2) train a\nkeyword-augmented response retrieval model. However, existing approaches in\nthis paradigm have two limitations: 1) the training and evaluation datasets for\nnext-turn keyword classification are directly extracted from conversations\nwithout human annotations, thus, they are noisy and have low correlation with\nhuman judgements, and 2) during keyword transition, the agents solely rely on\nthe similarities between word embeddings to move closer to the target keyword,\nwhich may not reflect how humans converse. In this paper, we assume that human\nconversations are grounded on commonsense and propose a keyword-guided neural\nconversational model that can leverage external commonsense knowledge graphs\n(CKG) for both keyword transition and response retrieval. Automatic evaluations\nsuggest that commonsense improves the performance of both next-turn keyword\nprediction and keyword-augmented response retrieval. In addition, both\nself-play and human evaluations show that our model produces responses with\nsmoother keyword transition and reaches the target keyword faster than\ncompetitive baselines.\n", "versions": [{"version": "v1", "created": "Tue, 15 Dec 2020 15:55:32 GMT"}, {"version": "v2", "created": "Sun, 27 Dec 2020 04:00:07 GMT"}, {"version": "v3", "created": "Sun, 28 Feb 2021 05:55:23 GMT"}], "update_date": "2021-03-02", "authors_parsed": [["Zhong", "Peixiang", ""], ["Liu", "Yong", ""], ["Wang", "Hao", ""], ["Miao", "Chunyan", ""]]}, {"id": "2012.08406", "submitter": "Kaleem Nawaz Khan Mr.", "authors": "Kaleem Nawaz Khan, Faiq Ahmad Khan, Anam Abid, Tamer Olmez, Zumray\n  Dokur, Amith Khandakar, Muhammad E. H. Chowdhury, Muhammad Salman Khan", "title": "Deep Learning Based Classification of Unsegmented Phonocardiogram\n  Spectrograms Leveraging Transfer Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cardiovascular diseases (CVDs) are the main cause of deaths all over the\nworld. Heart murmurs are the most common abnormalities detected during the\nauscultation process. The two widely used publicly available phonocardiogram\n(PCG) datasets are from the PhysioNet/CinC (2016) and PASCAL (2011) challenges.\nThe datasets are significantly different in terms of the tools used for data\nacquisition, clinical protocols, digital storages and signal qualities, making\nit challenging to process and analyze. In this work, we have used short-time\nFourier transform (STFT) based spectrograms to learn the representative\npatterns of the normal and abnormal PCG signals. Spectrograms generated from\nboth the datasets are utilized to perform three different studies: (i) train,\nvalidate and test different variants of convolutional neural network (CNN)\nmodels with PhysioNet dataset, (ii) train, validate and test the best\nperforming CNN structure on combined PhysioNet-PASCAL dataset and (iii)\nfinally, transfer learning technique is employed to train the best performing\npre-trained network from the first study with PASCAL dataset. We propose a\nnovel, less complex and relatively light custom CNN model for the\nclassification of PhysioNet, combined and PASCAL datasets. The first study\nachieves an accuracy, sensitivity, specificity, precision and F1 score of\n95.4%, 96.3%, 92.4%, 97.6% and 96.98% respectively while the second study shows\naccuracy, sensitivity, specificity, precision and F1 score of 94.2%, 95.5%,\n90.3%, 96.8% and 96.1% respectively. Finally, the third study shows a precision\nof 98.29% on the noisy PASCAL dataset with transfer learning approach. All the\nthree proposed approaches outperform most of the recent competing studies by\nachieving comparatively high classification accuracy and precision, which make\nthem suitable for screening CVDs using PCG signals.\n", "versions": [{"version": "v1", "created": "Tue, 15 Dec 2020 16:32:29 GMT"}, {"version": "v2", "created": "Fri, 26 Mar 2021 06:17:39 GMT"}, {"version": "v3", "created": "Mon, 19 Apr 2021 07:16:47 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Khan", "Kaleem Nawaz", ""], ["Khan", "Faiq Ahmad", ""], ["Abid", "Anam", ""], ["Olmez", "Tamer", ""], ["Dokur", "Zumray", ""], ["Khandakar", "Amith", ""], ["Chowdhury", "Muhammad E. H.", ""], ["Khan", "Muhammad Salman", ""]]}, {"id": "2012.08459", "submitter": "Sophie Burkhardt", "authors": "Sophie Burkhardt, Jannis Brugger, Nicolas Wagner, Zahra Ahmadi,\n  Kristian Kersting and Stefan Kramer", "title": "Rule Extraction from Binary Neural Networks with Convolutional Rules for\n  Model Validation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Most deep neural networks are considered to be black boxes, meaning their\noutput is hard to interpret. In contrast, logical expressions are considered to\nbe more comprehensible since they use symbols that are semantically close to\nnatural language instead of distributed representations. However, for\nhigh-dimensional input data such as images, the individual symbols, i.e.\npixels, are not easily interpretable. We introduce the concept of first-order\nconvolutional rules, which are logical rules that can be extracted using a\nconvolutional neural network (CNN), and whose complexity depends on the size of\nthe convolutional filter and not on the dimensionality of the input. Our\napproach is based on rule extraction from binary neural networks with\nstochastic local search. We show how to extract rules that are not necessarily\nshort, but characteristic of the input, and easy to visualize. Our experiments\nshow that the proposed approach is able to model the functionality of the\nneural network while at the same time producing interpretable logical rules.\n", "versions": [{"version": "v1", "created": "Tue, 15 Dec 2020 17:55:53 GMT"}], "update_date": "2020-12-16", "authors_parsed": [["Burkhardt", "Sophie", ""], ["Brugger", "Jannis", ""], ["Wagner", "Nicolas", ""], ["Ahmadi", "Zahra", ""], ["Kersting", "Kristian", ""], ["Kramer", "Stefan", ""]]}, {"id": "2012.08466", "submitter": "Dmitrii Avdiukhin", "authors": "Stanislav Naumov, Grigory Yaroslavtsev, Dmitrii Avdiukhin", "title": "Objective-Based Hierarchical Clustering of Deep Embedding Vectors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.DS stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We initiate a comprehensive experimental study of objective-based\nhierarchical clustering methods on massive datasets consisting of deep\nembedding vectors from computer vision and NLP applications. This includes a\nlarge variety of image embedding (ImageNet, ImageNetV2, NaBirds), word\nembedding (Twitter, Wikipedia), and sentence embedding (SST-2) vectors from\nseveral popular recent models (e.g. ResNet, ResNext, Inception V3, SBERT). Our\nstudy includes datasets with up to $4.5$ million entries with embedding\ndimensions up to $2048$.\n  In order to address the challenge of scaling up hierarchical clustering to\nsuch large datasets we propose a new practical hierarchical clustering\nalgorithm B++&C. It gives a 5%/20% improvement on average for the popular\nMoseley-Wang (MW) / Cohen-Addad et al. (CKMM) objectives (normalized) compared\nto a wide range of classic methods and recent heuristics. We also introduce a\ntheoretical algorithm B2SAT&C which achieves a $0.74$-approximation for the\nCKMM objective in polynomial time. This is the first substantial improvement\nover the trivial $2/3$-approximation achieved by a random binary tree. Prior to\nthis work, the best poly-time approximation of $\\approx 2/3 + 0.0004$ was due\nto Charikar et al. (SODA'19).\n", "versions": [{"version": "v1", "created": "Tue, 15 Dec 2020 18:08:34 GMT"}], "update_date": "2020-12-16", "authors_parsed": [["Naumov", "Stanislav", ""], ["Yaroslavtsev", "Grigory", ""], ["Avdiukhin", "Dmitrii", ""]]}, {"id": "2012.08478", "submitter": "Yao Fu", "authors": "Yao Fu, Chuanqi Tan, Mosha Chen, Songfang Huang, Fei Huang", "title": "Nested Named Entity Recognition with Partially-Observed TreeCRFs", "comments": "AAAI 2021 Camera Ready", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Named entity recognition (NER) is a well-studied task in natural language\nprocessing. However, the widely-used sequence labeling framework is difficult\nto detect entities with nested structures. In this work, we view nested NER as\nconstituency parsing with partially-observed trees and model it with\npartially-observed TreeCRFs. Specifically, we view all labeled entity spans as\nobserved nodes in a constituency tree, and other spans as latent nodes. With\nthe TreeCRF we achieve a uniform way to jointly model the observed and the\nlatent nodes. To compute the probability of partial trees with partial\nmarginalization, we propose a variant of the Inside algorithm, the\n\\textsc{Masked Inside} algorithm, that supports different inference operations\nfor different nodes (evaluation for the observed, marginalization for the\nlatent, and rejection for nodes incompatible with the observed) with efficient\nparallelized implementation, thus significantly speeding up training and\ninference. Experiments show that our approach achieves the state-of-the-art\n(SOTA) F1 scores on the ACE2004, ACE2005 dataset, and shows comparable\nperformance to SOTA models on the GENIA dataset. Our approach is implemented\nat: \\url{https://github.com/FranxYao/Partially-Observed-TreeCRFs}.\n", "versions": [{"version": "v1", "created": "Tue, 15 Dec 2020 18:20:36 GMT"}], "update_date": "2020-12-16", "authors_parsed": [["Fu", "Yao", ""], ["Tan", "Chuanqi", ""], ["Chen", "Mosha", ""], ["Huang", "Songfang", ""], ["Huang", "Fei", ""]]}, {"id": "2012.08479", "submitter": "Hiroyuki Kido", "authors": "Hiroyuki Kido, Keishi Okamoto", "title": "Bayes Meets Entailment and Prediction: Commonsense Reasoning with\n  Non-monotonicity, Paraconsistency and Predictive Accuracy", "comments": "This paper was submitted to AAAI 2021 and rejected", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recent success of Bayesian methods in neuroscience and artificial\nintelligence gives rise to the hypothesis that the brain is a Bayesian machine.\nSince logic and learning are both practices of the human brain, it leads to\nanother hypothesis that there is a Bayesian interpretation underlying both\nlogical reasoning and machine learning. In this paper, we introduce a\ngenerative model of logical consequence relations. It formalises the process of\nhow the truth value of a sentence is probabilistically generated from the\nprobability distribution over states of the world. We show that the generative\nmodel characterises a classical consequence relation, paraconsistent\nconsequence relation and nonmonotonic consequence relation. In particular, the\ngenerative model gives a new consequence relation that outperforms them in\nreasoning with inconsistent knowledge. We also show that the generative model\ngives a new classification algorithm that outperforms several representative\nalgorithms in predictive accuracy and complexity on the Kaggle Titanic dataset.\n", "versions": [{"version": "v1", "created": "Tue, 15 Dec 2020 18:22:27 GMT"}, {"version": "v2", "created": "Wed, 16 Dec 2020 02:18:21 GMT"}, {"version": "v3", "created": "Wed, 27 Jan 2021 18:13:00 GMT"}], "update_date": "2021-01-28", "authors_parsed": [["Kido", "Hiroyuki", ""], ["Okamoto", "Keishi", ""]]}, {"id": "2012.08485", "submitter": "Duncan McElfresh", "authors": "Duncan C McElfresh, Lok Chan, Kenzie Doyle, Walter Sinnott-Armstrong,\n  Vincent Conitzer, Jana Schaich Borg, John P Dickerson", "title": "Indecision Modeling", "comments": "Accepted at AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  AI systems are often used to make or contribute to important decisions in a\ngrowing range of applications, including criminal justice, hiring, and\nmedicine. Since these decisions impact human lives, it is important that the AI\nsystems act in ways which align with human values. Techniques for preference\nmodeling and social choice help researchers learn and aggregate peoples'\npreferences, which are used to guide AI behavior; thus, it is imperative that\nthese learned preferences are accurate. These techniques often assume that\npeople are willing to express strict preferences over alternatives; which is\nnot true in practice. People are often indecisive, and especially so when their\ndecision has moral implications. The philosophy and psychology literature shows\nthat indecision is a measurable and nuanced behavior -- and that there are\nseveral different reasons people are indecisive. This complicates the task of\nboth learning and aggregating preferences, since most of the relevant\nliterature makes restrictive assumptions on the meaning of indecision. We begin\nto close this gap by formalizing several mathematical \\emph{indecision} models\nbased on theories from philosophy, psychology, and economics; these models can\nbe used to describe (indecisive) agent decisions, both when they are allowed to\nexpress indecision and when they are not. We test these models using data\ncollected from an online survey where participants choose how to\n(hypothetically) allocate organs to patients waiting for a transplant.\n", "versions": [{"version": "v1", "created": "Tue, 15 Dec 2020 18:32:37 GMT"}, {"version": "v2", "created": "Fri, 12 Mar 2021 22:44:37 GMT"}], "update_date": "2021-03-16", "authors_parsed": [["McElfresh", "Duncan C", ""], ["Chan", "Lok", ""], ["Doyle", "Kenzie", ""], ["Sinnott-Armstrong", "Walter", ""], ["Conitzer", "Vincent", ""], ["Borg", "Jana Schaich", ""], ["Dickerson", "John P", ""]]}, {"id": "2012.08489", "submitter": "Valerio Perrone", "authors": "Valerio Perrone, Huibin Shen, Aida Zolic, Iaroslav Shcherbatyi, Amr\n  Ahmed, Tanya Bansal, Michele Donini, Fela Winkelmolen, Rodolphe Jenatton,\n  Jean Baptiste Faddoul, Barbara Pogorzelska, Miroslav Miladinovic, Krishnaram\n  Kenthapadi, Matthias Seeger, C\\'edric Archambeau", "title": "Amazon SageMaker Automatic Model Tuning: Scalable Gradient-Free\n  Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tuning complex machine learning systems is challenging. Machine learning\ntypically requires to set hyperparameters, be it regularization, architecture,\nor optimization parameters, whose tuning is critical to achieve good predictive\nperformance. To democratize access to machine learning systems, it is essential\nto automate the tuning. This paper presents Amazon SageMaker Automatic Model\nTuning (AMT), a fully managed system for gradient-free optimization at scale.\nAMT finds the best version of a trained machine learning model by repeatedly\nevaluating it with different hyperparameter configurations. It leverages either\nrandom search or Bayesian optimization to choose the hyperparameter values\nresulting in the best model, as measured by the metric chosen by the user. AMT\ncan be used with built-in algorithms, custom algorithms, and Amazon SageMaker\npre-built containers for machine learning frameworks. We discuss the core\nfunctionality, system architecture, our design principles, and lessons learned.\nWe also describe more advanced features of AMT, such as automated early\nstopping and warm-starting, showing in experiments their benefits to users.\n", "versions": [{"version": "v1", "created": "Tue, 15 Dec 2020 18:34:34 GMT"}, {"version": "v2", "created": "Fri, 18 Jun 2021 19:41:09 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Perrone", "Valerio", ""], ["Shen", "Huibin", ""], ["Zolic", "Aida", ""], ["Shcherbatyi", "Iaroslav", ""], ["Ahmed", "Amr", ""], ["Bansal", "Tanya", ""], ["Donini", "Michele", ""], ["Winkelmolen", "Fela", ""], ["Jenatton", "Rodolphe", ""], ["Faddoul", "Jean Baptiste", ""], ["Pogorzelska", "Barbara", ""], ["Miladinovic", "Miroslav", ""], ["Kenthapadi", "Krishnaram", ""], ["Seeger", "Matthias", ""], ["Archambeau", "C\u00e9dric", ""]]}, {"id": "2012.08492", "submitter": "Muhao Chen", "authors": "Cunchao Zhu, Muhao Chen, Changjun Fan, Guangquan Cheng, Yan Zhan", "title": "Learning from History: Modeling Temporal Knowledge Graphs with\n  Sequential Copy-Generation Networks", "comments": "AAAI 2021; Updated in accordance with camera ready", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large knowledge graphs often grow to store temporal facts that model the\ndynamic relations or interactions of entities along the timeline. Since such\ntemporal knowledge graphs often suffer from incompleteness, it is important to\ndevelop time-aware representation learning models that help to infer the\nmissing temporal facts. While the temporal facts are typically evolving, it is\nobserved that many facts often show a repeated pattern along the timeline, such\nas economic crises and diplomatic activities. This observation indicates that a\nmodel could potentially learn much from the known facts appeared in history. To\nthis end, we propose a new representation learning model for temporal knowledge\ngraphs, namely CyGNet, based on a novel timeaware copy-generation mechanism.\nCyGNet is not only able to predict future facts from the whole entity\nvocabulary, but also capable of identifying facts with repetition and\naccordingly predicting such future facts with reference to the known facts in\nthe past. We evaluate the proposed method on the knowledge graph completion\ntask using five benchmark datasets. Extensive experiments demonstrate the\neffectiveness of CyGNet for predicting future facts with repetition as well as\nde novo fact prediction.\n", "versions": [{"version": "v1", "created": "Tue, 15 Dec 2020 18:38:03 GMT"}, {"version": "v2", "created": "Fri, 5 Mar 2021 10:03:52 GMT"}], "update_date": "2021-03-08", "authors_parsed": [["Zhu", "Cunchao", ""], ["Chen", "Muhao", ""], ["Fan", "Changjun", ""], ["Cheng", "Guangquan", ""], ["Zhan", "Yan", ""]]}, {"id": "2012.08508", "submitter": "David Ding", "authors": "David Ding, Felix Hill, Adam Santoro, Malcolm Reynolds, Matt Botvinick", "title": "Attention over learned object embeddings enables complex visual\n  reasoning", "comments": "22 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks have achieved success in a wide array of perceptual tasks but\noften fail at tasks involving both perception and higher-level reasoning. On\nthese more challenging tasks, bespoke approaches (such as modular symbolic\ncomponents, independent dynamics models or semantic parsers) targeted towards\nthat specific type of task have typically performed better. The downside to\nthese targeted approaches, however, is that they can be more brittle than\ngeneral-purpose neural networks, requiring significant modification or even\nredesign according to the particular task at hand. Here, we propose a more\ngeneral neural-network-based approach to dynamic visual reasoning problems that\nobtains state-of-the-art performance on three different domains, in each case\noutperforming bespoke modular approaches tailored specifically to the task. Our\nmethod relies on learned object-centric representations, self-attention and\nself-supervised dynamics learning, and all three elements together are required\nfor strong performance to emerge. The success of this combination suggests that\nthere may be no need to trade off flexibility for performance on problems\ninvolving spatio-temporal or causal-style reasoning. With the right soft biases\nand learning objectives in a neural network we may be able to attain the best\nof both worlds.\n", "versions": [{"version": "v1", "created": "Tue, 15 Dec 2020 18:57:40 GMT"}, {"version": "v2", "created": "Tue, 6 Jul 2021 17:58:42 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Ding", "David", ""], ["Hill", "Felix", ""], ["Santoro", "Adam", ""], ["Reynolds", "Malcolm", ""], ["Botvinick", "Matt", ""]]}, {"id": "2012.08545", "submitter": "Eliu Huerta", "authors": "E. A. Huerta, Asad Khan, Xiaobo Huang, Minyang Tian, Maksim Levental,\n  Ryan Chard, Wei Wei, Maeve Heflin, Daniel S. Katz, Volodymyr Kindratenko,\n  Dawei Mu, Ben Blaiszik and Ian Foster", "title": "Accelerated, Scalable and Reproducible AI-driven Gravitational Wave\n  Detection", "comments": "17 pages, 5 figures; v2: 12 pages, 6 figures. Accepted to Nature\n  Astronomy. See also the Behind the Paper blog in Nature Astronomy\n  \"https://astronomycommunity.nature.com/posts/from-disruption-to-sustained-innovation-artificial-intelligence-for-gravitational-wave-astrophysics\"", "journal-ref": "Nat Astron (2021)", "doi": "10.1038/s41550-021-01405-0", "report-no": null, "categories": "gr-qc astro-ph.IM cs.AI cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The development of reusable artificial intelligence (AI) models for wider use\nand rigorous validation by the community promises to unlock new opportunities\nin multi-messenger astrophysics. Here we develop a workflow that connects the\nData and Learning Hub for Science, a repository for publishing AI models, with\nthe Hardware Accelerated Learning (HAL) cluster, using funcX as a universal\ndistributed computing service. Using this workflow, an ensemble of four openly\navailable AI models can be run on HAL to process an entire month's worth\n(August 2017) of advanced Laser Interferometer Gravitational-Wave Observatory\ndata in just seven minutes, identifying all four all four binary black hole\nmergers previously identified in this dataset and reporting no\nmisclassifications. This approach combines advances in AI, distributed\ncomputing, and scientific data infrastructure to open new pathways to conduct\nreproducible, accelerated, data-driven discovery.\n", "versions": [{"version": "v1", "created": "Tue, 15 Dec 2020 19:00:29 GMT"}, {"version": "v2", "created": "Fri, 9 Jul 2021 21:44:56 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Huerta", "E. A.", ""], ["Khan", "Asad", ""], ["Huang", "Xiaobo", ""], ["Tian", "Minyang", ""], ["Levental", "Maksim", ""], ["Chard", "Ryan", ""], ["Wei", "Wei", ""], ["Heflin", "Maeve", ""], ["Katz", "Daniel S.", ""], ["Kindratenko", "Volodymyr", ""], ["Mu", "Dawei", ""], ["Blaiszik", "Ben", ""], ["Foster", "Ian", ""]]}, {"id": "2012.08559", "submitter": "Sergio Hidalgo-Espinoza", "authors": "Sergio Hidalgo-Espinoza and Kevin Chamorro-Cupueran and Oscar\n  Chang-Tortolero", "title": "Intrusion detection in computer systems by using artificial neural\n  networks with Deep Learning approaches", "comments": null, "journal-ref": "10th International Conference on Advances in Computing and\n  Information Technology (ACITY 2020), November 28~29, 2020, London, United\n  Kingdom Volume Editors : David C. Wyld, Dhinaharan Nagamalai (Eds) ISBN :\n  978-1-925953-29-9", "doi": "10.5121/csit.2020.101501", "report-no": null, "categories": "cs.CR cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Intrusion detection into computer networks has become one of the most\nimportant issues in cybersecurity. Attackers keep on researching and coding to\ndiscover new vulnerabilities to penetrate information security system. In\nconsequence computer systems must be daily upgraded using up-to-date techniques\nto keep hackers at bay. This paper focuses on the design and implementation of\nan intrusion detection system based on Deep Learning architectures. As a first\nstep, a shallow network is trained with labelled log-in [into a computer\nnetwork] data taken from the Dataset CICIDS2017. The internal behaviour of this\nnetwork is carefully tracked and tuned by using plotting and exploring codes\nuntil it reaches a functional peak in intrusion prediction accuracy. As a\nsecond step, an autoencoder, trained with big unlabelled data, is used as a\nmiddle processor which feeds compressed information and abstract representation\nto the original shallow network. It is proven that the resultant deep\narchitecture has a better performance than any version of the shallow network\nalone. The resultant functional code scripts, written in MATLAB, represent a\nre-trainable system which has been proved using real data, producing good\nprecision and fast response.\n", "versions": [{"version": "v1", "created": "Tue, 15 Dec 2020 19:12:23 GMT"}], "update_date": "2020-12-17", "authors_parsed": [["Hidalgo-Espinoza", "Sergio", ""], ["Chamorro-Cupueran", "Kevin", ""], ["Chang-Tortolero", "Oscar", ""]]}, {"id": "2012.08564", "submitter": "Eleni Nisioti", "authors": "Eleni Nisioti and Cl\\'ement Moulin-Frier", "title": "Grounding Artificial Intelligence in the Origins of Human Behavior", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in Artificial Intelligence (AI) have revived the quest for\nagents able to acquire an open-ended repertoire of skills. However, although\nthis ability is fundamentally related to the characteristics of human\nintelligence, research in this field rarely considers the processes that may\nhave guided the emergence of complex cognitive capacities during the evolution\nof the species.\n  Research in Human Behavioral Ecology (HBE) seeks to understand how the\nbehaviors characterizing human nature can be conceived as adaptive responses to\nmajor changes in the structure of our ecological niche. In this paper, we\npropose a framework highlighting the role of environmental complexity in\nopen-ended skill acquisition, grounded in major hypotheses from HBE and recent\ncontributions in Reinforcement learning (RL). We use this framework to\nhighlight fundamental links between the two disciplines, as well as to identify\nfeedback loops that bootstrap ecological complexity and create promising\nresearch directions for AI researchers.\n", "versions": [{"version": "v1", "created": "Tue, 15 Dec 2020 19:28:45 GMT"}, {"version": "v2", "created": "Thu, 17 Dec 2020 14:07:50 GMT"}], "update_date": "2020-12-18", "authors_parsed": [["Nisioti", "Eleni", ""], ["Moulin-Frier", "Cl\u00e9ment", ""]]}, {"id": "2012.08594", "submitter": "Udayan Khurana", "authors": "Udayan Khurana and Sainyam Galhotra", "title": "Semantic Annotation for Tabular Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Detecting semantic concept of columns in tabular data is of particular\ninterest to many applications ranging from data integration, cleaning, search\nto feature engineering and model building in machine learning. Recently,\nseveral works have proposed supervised learning-based or heuristic\npattern-based approaches to semantic type annotation. Both have shortcomings\nthat prevent them from generalizing over a large number of concepts or\nexamples. Many neural network based methods also present scalability issues.\nAdditionally, none of the known methods works well for numerical data. We\npropose $C^2$, a column to concept mapper that is based on a maximum likelihood\nestimation approach through ensembles. It is able to effectively utilize vast\namounts of, albeit somewhat noisy, openly available table corpora in addition\nto two popular knowledge graphs to perform effective and efficient concept\nprediction for structured data. We demonstrate the effectiveness of $C^2$ over\navailable techniques on 9 datasets, the most comprehensive comparison on this\ntopic so far.\n", "versions": [{"version": "v1", "created": "Tue, 15 Dec 2020 20:08:19 GMT"}], "update_date": "2020-12-17", "authors_parsed": [["Khurana", "Udayan", ""], ["Galhotra", "Sainyam", ""]]}, {"id": "2012.08604", "submitter": "Qi Chang", "authors": "Qi Chang, Zhennan Yan, Lohendran Baskaran, Hui Qu, Yikai Zhang, Tong\n  Zhang, Shaoting Zhang, and Dimitris N. Metaxas", "title": "Multi-modal AsynDGAN: Learn From Distributed Medical Image Data without\n  Sharing Private Information", "comments": "arXiv admin note: text overlap with arXiv:2006.00080", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  As deep learning technologies advance, increasingly more data is necessary to\ngenerate general and robust models for various tasks. In the medical domain,\nhowever, large-scale and multi-parties data training and analyses are\ninfeasible due to the privacy and data security concerns. In this paper, we\npropose an extendable and elastic learning framework to preserve privacy and\nsecurity while enabling collaborative learning with efficient communication.\nThe proposed framework is named distributed Asynchronized Discriminator\nGenerative Adversarial Networks (AsynDGAN), which consists of a centralized\ngenerator and multiple distributed discriminators. The advantages of our\nproposed framework are five-fold: 1) the central generator could learn the real\ndata distribution from multiple datasets implicitly without sharing the image\ndata; 2) the framework is applicable for single-modality or multi-modality\ndata; 3) the learned generator can be used to synthesize samples for\ndown-stream learning tasks to achieve close-to-real performance as using actual\nsamples collected from multiple data centers; 4) the synthetic samples can also\nbe used to augment data or complete missing modalities for one single data\ncenter; 5) the learning process is more efficient and requires lower bandwidth\nthan other distributed deep learning methods.\n", "versions": [{"version": "v1", "created": "Tue, 15 Dec 2020 20:41:24 GMT"}], "update_date": "2020-12-17", "authors_parsed": [["Chang", "Qi", ""], ["Yan", "Zhennan", ""], ["Baskaran", "Lohendran", ""], ["Qu", "Hui", ""], ["Zhang", "Yikai", ""], ["Zhang", "Tong", ""], ["Zhang", "Shaoting", ""], ["Metaxas", "Dimitris N.", ""]]}, {"id": "2012.08621", "submitter": "Tianjun Zhang", "authors": "Tianjun Zhang, Huazhe Xu, Xiaolong Wang, Yi Wu, Kurt Keutzer, Joseph\n  E. Gonzalez, Yuandong Tian", "title": "BeBold: Exploration Beyond the Boundary of Explored Regions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Efficient exploration under sparse rewards remains a key challenge in deep\nreinforcement learning. To guide exploration, previous work makes extensive use\nof intrinsic reward (IR). There are many heuristics for IR, including\nvisitation counts, curiosity, and state-difference. In this paper, we analyze\nthe pros and cons of each method and propose the regulated difference of\ninverse visitation counts as a simple but effective criterion for IR. The\ncriterion helps the agent explore Beyond the Boundary of explored regions and\nmitigates common issues in count-based methods, such as short-sightedness and\ndetachment. The resulting method, BeBold, solves the 12 most challenging\nprocedurally-generated tasks in MiniGrid with just 120M environment steps,\nwithout any curriculum learning. In comparison, the previous SoTA only solves\n50% of the tasks. BeBold also achieves SoTA on multiple tasks in NetHack, a\npopular rogue-like game that contains more challenging procedurally-generated\nenvironments.\n", "versions": [{"version": "v1", "created": "Tue, 15 Dec 2020 21:26:54 GMT"}], "update_date": "2020-12-17", "authors_parsed": [["Zhang", "Tianjun", ""], ["Xu", "Huazhe", ""], ["Wang", "Xiaolong", ""], ["Wu", "Yi", ""], ["Keutzer", "Kurt", ""], ["Gonzalez", "Joseph E.", ""], ["Tian", "Yuandong", ""]]}, {"id": "2012.08622", "submitter": "Bilal Farooq", "authors": "Ali Yazdizadeh and Bilal Farooq", "title": "Smart Mobility Ontology: Current Trends and Future Directions", "comments": "Published as a book chapter in: Handbook of Smart Cities, Springer,\n  2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ontology is the explicit and formal representation of the concepts in a\ndomain and relations among them. Transportation science is a wide domain\ndealing with mobility over various complex and interconnected transportation\nsystems, such as land, aviation, and maritime transport, and can take\nconsiderable advantage from ontology development. While several studies can be\nfound in the recent literature, there exists a large potential to improve and\ndevelop a comprehensive smart mobility ontology. The current chapter aims to\npresent different aspects of ontology development in general, such as ontology\ndevelopment methods, languages, tools, and software. Subsequently, it presents\nthe currently available mobility-related ontologies developed across different\ndomains, such as transportation, smart cities, goods mobility, sensors. Current\ngaps in the available ontologies are identified, and future directions\nregarding ontology development are proposed that can incorporate the\nforthcoming autonomous and connected vehicles, mobility as a service (MaaS),\nand other disruptive transportation technologies and services.\n", "versions": [{"version": "v1", "created": "Tue, 15 Dec 2020 21:28:43 GMT"}], "update_date": "2020-12-17", "authors_parsed": [["Yazdizadeh", "Ali", ""], ["Farooq", "Bilal", ""]]}, {"id": "2012.08630", "submitter": "Kevin McKee", "authors": "Allan Dafoe and Edward Hughes and Yoram Bachrach and Tantum Collins\n  and Kevin R. McKee and Joel Z. Leibo and Kate Larson and Thore Graepel", "title": "Open Problems in Cooperative AI", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Problems of cooperation--in which agents seek ways to jointly improve their\nwelfare--are ubiquitous and important. They can be found at scales ranging from\nour daily routines--such as driving on highways, scheduling meetings, and\nworking collaboratively--to our global challenges--such as peace, commerce, and\npandemic preparedness. Arguably, the success of the human species is rooted in\nour ability to cooperate. Since machines powered by artificial intelligence are\nplaying an ever greater role in our lives, it will be important to equip them\nwith the capabilities necessary to cooperate and to foster cooperation.\n  We see an opportunity for the field of artificial intelligence to explicitly\nfocus effort on this class of problems, which we term Cooperative AI. The\nobjective of this research would be to study the many aspects of the problems\nof cooperation and to innovate in AI to contribute to solving these problems.\nCentral goals include building machine agents with the capabilities needed for\ncooperation, building tools to foster cooperation in populations of (machine\nand/or human) agents, and otherwise conducting AI research for insight relevant\nto problems of cooperation. This research integrates ongoing work on\nmulti-agent systems, game theory and social choice, human-machine interaction\nand alignment, natural-language processing, and the construction of social\ntools and platforms. However, Cooperative AI is not the union of these existing\nareas, but rather an independent bet about the productivity of specific kinds\nof conversations that involve these and other areas. We see opportunity to more\nexplicitly focus on the problem of cooperation, to construct unified theory and\nvocabulary, and to build bridges with adjacent communities working on\ncooperation, including in the natural, social, and behavioural sciences.\n", "versions": [{"version": "v1", "created": "Tue, 15 Dec 2020 21:39:50 GMT"}], "update_date": "2020-12-17", "authors_parsed": [["Dafoe", "Allan", ""], ["Hughes", "Edward", ""], ["Bachrach", "Yoram", ""], ["Collins", "Tantum", ""], ["McKee", "Kevin R.", ""], ["Leibo", "Joel Z.", ""], ["Larson", "Kate", ""], ["Graepel", "Thore", ""]]}, {"id": "2012.08637", "submitter": "Tianchen Ji", "authors": "Tianchen Ji, Sri Theja Vuppala, Girish Chowdhary, Katherine\n  Driggs-Campbell", "title": "Multi-Modal Anomaly Detection for Unstructured and Uncertain\n  Environments", "comments": "Conference on Robot Learning (CoRL) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To achieve high-levels of autonomy, modern robots require the ability to\ndetect and recover from anomalies and failures with minimal human supervision.\nMulti-modal sensor signals could provide more information for such anomaly\ndetection tasks; however, the fusion of high-dimensional and heterogeneous\nsensor modalities remains a challenging problem. We propose a deep learning\nneural network: supervised variational autoencoder (SVAE), for failure\nidentification in unstructured and uncertain environments. Our model leverages\nthe representational power of VAE to extract robust features from\nhigh-dimensional inputs for supervised learning tasks. The training objective\nunifies the generative model and the discriminative model, thus making the\nlearning a one-stage procedure. Our experiments on real field robot data\ndemonstrate superior failure identification performance than baseline methods,\nand that our model learns interpretable representations. Videos of our results\nare available on our website:\nhttps://sites.google.com/illinois.edu/supervised-vae .\n", "versions": [{"version": "v1", "created": "Tue, 15 Dec 2020 21:59:58 GMT"}], "update_date": "2020-12-17", "authors_parsed": [["Ji", "Tianchen", ""], ["Vuppala", "Sri Theja", ""], ["Chowdhary", "Girish", ""], ["Driggs-Campbell", "Katherine", ""]]}, {"id": "2012.08648", "submitter": "Kirthevasan Kandasamy", "authors": "Kirthevasan Kandasamy, Gur-Eyal Sela, Joseph E Gonzalez, Michael I\n  Jordan, Ion Stoica", "title": "Online Learning Demands in Max-min Fairness", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe mechanisms for the allocation of a scarce resource among multiple\nusers in a way that is efficient, fair, and strategy-proof, but when users do\nnot know their resource requirements. The mechanism is repeated for multiple\nrounds and a user's requirements can change on each round. At the end of each\nround, users provide feedback about the allocation they received, enabling the\nmechanism to learn user preferences over time. Such situations are common in\nthe shared usage of a compute cluster among many users in an organisation,\nwhere all teams may not precisely know the amount of resources needed to\nexecute their jobs. By understating their requirements, users will receive less\nthan they need and consequently not achieve their goals. By overstating them,\nthey may siphon away precious resources that could be useful to others in the\norganisation. We formalise this task of online learning in fair division via\nnotions of efficiency, fairness, and strategy-proofness applicable to this\nsetting, and study this problem under three types of feedback: when the users'\nobservations are deterministic, when they are stochastic and follow a\nparametric model, and when they are stochastic and nonparametric. We derive\nmechanisms inspired by the classical max-min fairness procedure that achieve\nthese requisites, and quantify the extent to which they are achieved via\nasymptotic rates. We corroborate these insights with an experimental evaluation\non synthetic problems and a web-serving task.\n", "versions": [{"version": "v1", "created": "Tue, 15 Dec 2020 22:15:20 GMT"}], "update_date": "2020-12-17", "authors_parsed": [["Kandasamy", "Kirthevasan", ""], ["Sela", "Gur-Eyal", ""], ["Gonzalez", "Joseph E", ""], ["Jordan", "Michael I", ""], ["Stoica", "Ion", ""]]}, {"id": "2012.08668", "submitter": "Rebecca Roelofs", "authors": "Rebecca Roelofs, Nicholas Cain, Jonathon Shlens, Michael C. Mozer", "title": "Mitigating Bias in Calibration Error Estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Building reliable machine learning systems requires that we correctly\nunderstand their level of confidence. Calibration measures the degree of\naccuracy in a model's confidence and most research in calibration focuses on\ntechniques to improve an empirical estimate of calibration error, ECE_bin. We\nintroduce a simulation framework that allows us to empirically show that\nECE_bin can systematically underestimate or overestimate the true calibration\nerror depending on the nature of model miscalibration, the size of the\nevaluation data set, and the number of bins. Critically, we find that ECE_bin\nis more strongly biased for perfectly calibrated models. We propose a simple\nalternative calibration error metric, ECE_sweep, in which the number of bins is\nchosen to be as large as possible while preserving monotonicity in the\ncalibration function. Evaluating our measure on distributions fit to neural\nnetwork confidence scores on CIFAR-10, CIFAR-100, and ImageNet, we show that\nECE_sweep produces a less biased estimator of calibration error and therefore\nshould be used by any researcher wishing to evaluate the calibration of models\ntrained on similar datasets.\n", "versions": [{"version": "v1", "created": "Tue, 15 Dec 2020 23:28:06 GMT"}, {"version": "v2", "created": "Wed, 24 Feb 2021 19:25:00 GMT"}], "update_date": "2021-02-26", "authors_parsed": [["Roelofs", "Rebecca", ""], ["Cain", "Nicholas", ""], ["Shlens", "Jonathon", ""], ["Mozer", "Michael C.", ""]]}, {"id": "2012.08687", "submitter": "Jinshan Zeng", "authors": "Jinshan Zeng, Qi Chen, Yunxin Liu, Mingwen Wang, Yuan Yao", "title": "StrokeGAN: Reducing Mode Collapse in Chinese Font Generation via Stroke\n  Encoding", "comments": "10 pages, our codes and data are available at:\n  https://github.com/JinshanZeng/StrokeGAN", "journal-ref": "AAAI 2021", "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The generation of stylish Chinese fonts is an important problem involved in\nmany applications. Most of existing generation methods are based on the deep\ngenerative models, particularly, the generative adversarial networks (GAN)\nbased models. However, these deep generative models may suffer from the mode\ncollapse issue, which significantly degrades the diversity and quality of\ngenerated results. In this paper, we introduce a one-bit stroke encoding to\ncapture the key mode information of Chinese characters and then incorporate it\ninto CycleGAN, a popular deep generative model for Chinese font generation. As\na result we propose an efficient method called StrokeGAN, mainly motivated by\nthe observation that the stroke encoding contains amount of mode information of\nChinese characters. In order to reconstruct the one-bit stroke encoding of the\nassociated generated characters, we introduce a stroke-encoding reconstruction\nloss imposed on the discriminator. Equipped with such one-bit stroke encoding\nand stroke-encoding reconstruction loss, the mode collapse issue of CycleGAN\ncan be significantly alleviated, with an improved preservation of strokes and\ndiversity of generated characters. The effectiveness of StrokeGAN is\ndemonstrated by a series of generation tasks over nine datasets with different\nfonts. The numerical results demonstrate that StrokeGAN generally outperforms\nthe state-of-the-art methods in terms of content and recognition accuracies, as\nwell as certain stroke error, and also generates more realistic characters.\n", "versions": [{"version": "v1", "created": "Wed, 16 Dec 2020 01:36:19 GMT"}, {"version": "v2", "created": "Mon, 11 Jan 2021 01:41:46 GMT"}], "update_date": "2021-01-12", "authors_parsed": [["Zeng", "Jinshan", ""], ["Chen", "Qi", ""], ["Liu", "Yunxin", ""], ["Wang", "Mingwen", ""], ["Yao", "Yuan", ""]]}, {"id": "2012.08695", "submitter": "Weizhou Shen", "authors": "Weizhou Shen, Junqing Chen, Xiaojun Quan and Zhixian Xie", "title": "DialogXL: All-in-One XLNet for Multi-Party Conversation Emotion\n  Recognition", "comments": "Accepted by AAAI 2021 main conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper presents our pioneering effort for emotion recognition in\nconversation (ERC) with pre-trained language models. Unlike regular documents,\nconversational utterances appear alternately from different parties and are\nusually organized as hierarchical structures in previous work. Such structures\nare not conducive to the application of pre-trained language models such as\nXLNet. To address this issue, we propose an all-in-one XLNet model, namely\nDialogXL, with enhanced memory to store longer historical context and\ndialog-aware self-attention to deal with the multi-party structures.\nSpecifically, we first modify the recurrence mechanism of XLNet from\nsegment-level to utterance-level in order to better model the conversational\ndata. Second, we introduce dialog-aware self-attention in replacement of the\nvanilla self-attention in XLNet to capture useful intra- and inter-speaker\ndependencies. Extensive experiments are conducted on four ERC benchmarks with\nmainstream models presented for comparison. The experimental results show that\nthe proposed model outperforms the baselines on all the datasets. Several other\nexperiments such as ablation study and error analysis are also conducted and\nthe results confirm the role of the critical modules of DialogXL.\n", "versions": [{"version": "v1", "created": "Wed, 16 Dec 2020 01:50:46 GMT"}], "update_date": "2020-12-17", "authors_parsed": [["Shen", "Weizhou", ""], ["Chen", "Junqing", ""], ["Quan", "Xiaojun", ""], ["Xie", "Zhixian", ""]]}, {"id": "2012.08704", "submitter": "Yuzhe Ma", "authors": "Yuzhe Ma, Jon Sharp, Ruizhe Wang, Earlence Fernandes, Xiaojin Zhu", "title": "Sequential Attacks on Kalman Filter-based Forward Collision Warning\n  Systems", "comments": "Accepted by AAAI21", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Kalman Filter (KF) is widely used in various domains to perform sequential\nlearning or variable estimation. In the context of autonomous vehicles, KF\nconstitutes the core component of many Advanced Driver Assistance Systems\n(ADAS), such as Forward Collision Warning (FCW). It tracks the states\n(distance, velocity etc.) of relevant traffic objects based on sensor\nmeasurements. The tracking output of KF is often fed into downstream logic to\nproduce alerts, which will then be used by human drivers to make driving\ndecisions in near-collision scenarios. In this paper, we study adversarial\nattacks on KF as part of the more complex machine-human hybrid system of\nForward Collision Warning. Our attack goal is to negatively affect human\nbraking decisions by causing KF to output incorrect state estimations that lead\nto false or delayed alerts. We accomplish this by sequentially manipulating\nmeasure ments fed into the KF, and propose a novel Model Predictive Control\n(MPC) approach to compute the optimal manipulation. Via experiments conducted\nin a simulated driving environment, we show that the attacker is able to\nsuccessfully change FCW alert signals through planned manipulation over\nmeasurements prior to the desired target time. These results demonstrate that\nour attack can stealthily mislead a distracted human driver and cause vehicle\ncollisions.\n", "versions": [{"version": "v1", "created": "Wed, 16 Dec 2020 02:26:27 GMT"}], "update_date": "2020-12-17", "authors_parsed": [["Ma", "Yuzhe", ""], ["Sharp", "Jon", ""], ["Wang", "Ruizhe", ""], ["Fernandes", "Earlence", ""], ["Zhu", "Xiaojin", ""]]}, {"id": "2012.08717", "submitter": "Gege Zhang", "authors": "Gege Zhang", "title": "A Deep Graph Neural Networks Architecture Design: From Global\n  Pyramid-like Shrinkage Skeleton to Local Topology Link Rewiring", "comments": "11 pages, 5 figures, conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Expressivity plays a fundamental role in evaluating deep neural networks, and\nit is closely related to understanding the limit of performance improvement. In\nthis paper, we propose a three-pipeline training framework based on critical\nexpressivity, including global model contraction, weight evolution, and link's\nweight rewiring. Specifically, we propose a pyramidal-like skeleton to overcome\nthe saddle points that affect information transfer. Then we analyze the reason\nfor the modularity (clustering) phenomenon in network topology and use it to\nrewire potential erroneous weighted links. We conduct numerical experiments on\nnode classification and the results confirm that the proposed training\nframework leads to a significantly improved performance in terms of fast\nconvergence and robustness to potential erroneous weighted links. The\narchitecture design on GNNs, in turn, verifies the expressivity of GNNs from\ndynamics and topological space aspects and provides useful guidelines in\ndesigning more efficient neural networks.\n", "versions": [{"version": "v1", "created": "Wed, 16 Dec 2020 03:14:31 GMT"}], "update_date": "2020-12-17", "authors_parsed": [["Zhang", "Gege", ""]]}, {"id": "2012.08723", "submitter": "Ninareh Mehrabi", "authors": "Ninareh Mehrabi, Muhammad Naveed, Fred Morstatter, Aram Galstyan", "title": "Exacerbating Algorithmic Bias through Fairness Attacks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Algorithmic fairness has attracted significant attention in recent years,\nwith many quantitative measures suggested for characterizing the fairness of\ndifferent machine learning algorithms. Despite this interest, the robustness of\nthose fairness measures with respect to an intentional adversarial attack has\nnot been properly addressed. Indeed, most adversarial machine learning has\nfocused on the impact of malicious attacks on the accuracy of the system,\nwithout any regard to the system's fairness. We propose new types of data\npoisoning attacks where an adversary intentionally targets the fairness of a\nsystem. Specifically, we propose two families of attacks that target fairness\nmeasures. In the anchoring attack, we skew the decision boundary by placing\npoisoned points near specific target points to bias the outcome. In the\ninfluence attack on fairness, we aim to maximize the covariance between the\nsensitive attributes and the decision outcome and affect the fairness of the\nmodel. We conduct extensive experiments that indicate the effectiveness of our\nproposed attacks.\n", "versions": [{"version": "v1", "created": "Wed, 16 Dec 2020 03:44:17 GMT"}], "update_date": "2020-12-17", "authors_parsed": [["Mehrabi", "Ninareh", ""], ["Naveed", "Muhammad", ""], ["Morstatter", "Fred", ""], ["Galstyan", "Aram", ""]]}, {"id": "2012.08733", "submitter": "Kecheng Zheng", "authors": "Kecheng Zheng, Cuiling Lan, Wenjun Zeng, Zhizheng Zhang and Zheng-Jun\n  Zha", "title": "Exploiting Sample Uncertainty for Domain Adaptive Person\n  Re-Identification", "comments": "9 pages. Accepted to 35th AAAI Conference on Artificial Intelligence\n  (AAAI 2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Many unsupervised domain adaptive (UDA) person re-identification (ReID)\napproaches combine clustering-based pseudo-label prediction with feature\nfine-tuning. However, because of domain gap, the pseudo-labels are not always\nreliable and there are noisy/incorrect labels. This would mislead the feature\nrepresentation learning and deteriorate the performance. In this paper, we\npropose to estimate and exploit the credibility of the assigned pseudo-label of\neach sample to alleviate the influence of noisy labels, by suppressing the\ncontribution of noisy samples. We build our baseline framework using the mean\nteacher method together with an additional contrastive loss. We have observed\nthat a sample with a wrong pseudo-label through clustering in general has a\nweaker consistency between the output of the mean teacher model and the student\nmodel. Based on this finding, we propose to exploit the uncertainty (measured\nby consistency levels) to evaluate the reliability of the pseudo-label of a\nsample and incorporate the uncertainty to re-weight its contribution within\nvarious ReID losses, including the identity (ID) classification loss per\nsample, the triplet loss, and the contrastive loss. Our uncertainty-guided\noptimization brings significant improvement and achieves the state-of-the-art\nperformance on benchmark datasets.\n", "versions": [{"version": "v1", "created": "Wed, 16 Dec 2020 04:09:04 GMT"}, {"version": "v2", "created": "Thu, 17 Dec 2020 06:08:08 GMT"}], "update_date": "2020-12-18", "authors_parsed": [["Zheng", "Kecheng", ""], ["Lan", "Cuiling", ""], ["Zeng", "Wenjun", ""], ["Zhang", "Zhizheng", ""], ["Zha", "Zheng-Jun", ""]]}, {"id": "2012.08773", "submitter": "Jiaxiang Hao", "authors": "Hao Jiaxiang", "title": "Building domain specific lexicon based on TikTok comment dataset", "comments": "10 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In the sentiment analysis task, predicting the sentiment tendency of a\nsentence is an important branch. Previous research focused more on sentiment\nanalysis in English, for example, analyzing the sentiment tendency of sentences\nbased on Valence, Arousal, Dominance of sentences. the emotional tendency is\ndifferent between the two languages. For example, the sentence order between\nChinese and English may present different emotions. This paper tried a method\nthat builds a domain-specific lexicon. In this way, the model can classify\nChinese words with emotional tendency. In this approach, based on the [13], an\nultra-dense space embedding table is trained through word embedding of Chinese\nTikTok review and emotional lexicon sources(seed words). The result of the\nmodel is a domain-specific lexicon, which presents the emotional tendency of\nwords. I collected Chinese TikTok comments as training data. By comparing The\ntraining results with the PCA method to evaluate the performance of the model\nin Chinese sentiment classification, the results show that the model has done\nwell in Chinese. The source code has released on\ngithub:https://github.com/h2222/douyin_comment_dataset\n", "versions": [{"version": "v1", "created": "Wed, 16 Dec 2020 07:26:43 GMT"}], "update_date": "2020-12-17", "authors_parsed": [["Jiaxiang", "Hao", ""]]}, {"id": "2012.08795", "submitter": "Fengli Gao", "authors": "Fengli Gao and Huicai Zhong", "title": "Study on the Large Batch Size Training of Neural Networks Based on the\n  Second Order Gradient", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large batch size training in deep neural networks (DNNs) possesses a\nwell-known 'generalization gap' that remarkably induces generalization\nperformance degradation. However, it remains unclear how varying batch size\naffects the structure of a NN. Here, we combine theory with experiments to\nexplore the evolution of the basic structural properties, including gradient,\nparameter update step length, and loss update step length of NNs under varying\nbatch sizes. We provide new guidance to improve generalization, which is\nfurther verified by two designed methods involving discarding small-loss\nsamples and scheduling batch size. A curvature-based learning rate (CBLR)\nalgorithm is proposed to better fit the curvature variation, a sensitive factor\naffecting large batch size training, across layers in a NN. As an approximation\nof CBLR, the median-curvature LR (MCLR) algorithm is found to gain comparable\nperformance to Layer-wise Adaptive Rate Scaling (LARS) algorithm. Our\ntheoretical results and algorithm offer geometry-based explanations to the\nexisting studies. Furthermore, we demonstrate that the layer wise LR\nalgorithms, for example LARS, can be regarded as special instances of CBLR.\nFinally, we deduce a theoretical geometric picture of large batch size\ntraining, and show that all the network parameters tend to center on their\nrelated minima.\n", "versions": [{"version": "v1", "created": "Wed, 16 Dec 2020 08:43:15 GMT"}], "update_date": "2020-12-17", "authors_parsed": [["Gao", "Fengli", ""], ["Zhong", "Huicai", ""]]}, {"id": "2012.08809", "submitter": "Qinglong Chang", "authors": "Dingwei Li, Qinglong Chang, Lixue Pang, Yanfang Zhang, Xudong Sun,\n  Jikun Ding, Liang Zhang", "title": "More Industry-friendly: Federated Learning with High Efficient Design", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although many achievements have been made since Google threw out the paradigm\nof federated learning (FL), there still exists much room for researchers to\noptimize its efficiency. In this paper, we propose a high efficient FL method\nequipped with the double head design aiming for personalization optimization\nover non-IID dataset, and the gradual model sharing design for communication\nsaving. Experimental results show that, our method has more stable accuracy\nperformance and better communication efficient across various data\ndistributions than other state of art methods (SOTAs), makes it more\nindustry-friendly.\n", "versions": [{"version": "v1", "created": "Wed, 16 Dec 2020 09:12:37 GMT"}], "update_date": "2020-12-17", "authors_parsed": [["Li", "Dingwei", ""], ["Chang", "Qinglong", ""], ["Pang", "Lixue", ""], ["Zhang", "Yanfang", ""], ["Sun", "Xudong", ""], ["Ding", "Jikun", ""], ["Zhang", "Liang", ""]]}, {"id": "2012.08830", "submitter": "Angelos-Christos Anadiotis", "authors": "Angelos-Christos Anadiotis, Oana Balalau, Catarina Conceicao, Helena\n  Galhardas, Mhd Yamen Haddad, Ioana Manolescu, Tayeb Merabti, Jingmao You", "title": "Graph integration of structured, semistructured and unstructured data\n  for data journalism", "comments": "40 pages, 9 figures. arXiv admin note: substantial text overlap with\n  arXiv:2007.12488, arXiv:2009.04283", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.AI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Digital data is a gold mine for modern journalism. However, datasets which\ninterest journalists are extremely heterogeneous, ranging from highly\nstructured (relational databases), semi-structured (JSON, XML, HTML), graphs\n(e.g., RDF), and text. Journalists (and other classes of users lacking advanced\nIT expertise, such as most non-governmental-organizations, or small public\nadministrations) need to be able to make sense of such heterogeneous corpora,\neven if they lack the ability to define and deploy custom\nextract-transform-load workflows, especially for dynamically varying sets of\ndata sources.\n  We describe a complete approach for integrating dynamic sets of heterogeneous\ndatasets along the lines described above: the challenges we faced to make such\ngraphs useful, allow their integration to scale, and the solutions we proposed\nfor these problems. Our approach is implemented within the ConnectionLens\nsystem; we validate it through a set of experiments.\n", "versions": [{"version": "v1", "created": "Wed, 16 Dec 2020 09:59:27 GMT"}], "update_date": "2020-12-17", "authors_parsed": [["Anadiotis", "Angelos-Christos", ""], ["Balalau", "Oana", ""], ["Conceicao", "Catarina", ""], ["Galhardas", "Helena", ""], ["Haddad", "Mhd Yamen", ""], ["Manolescu", "Ioana", ""], ["Merabti", "Tayeb", ""], ["You", "Jingmao", ""]]}, {"id": "2012.08858", "submitter": "Shuji Shinohara Shinohara", "authors": "Shuji Shinohara, Nobuhito Manome, Yoshihiro Nakajima, Yukio Pegio\n  Gunji, Toru Moriyama, Hiroshi Okamoto, Shunji Mitsuyoshi, Ung-il Chung", "title": "L\\'evy walks derived from a Bayesian decision-making model in\n  non-stationary environments", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.MA cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  L\\'evy walks are found in the migratory behaviour patterns of various\norganisms, and the reason for this phenomenon has been much discussed. We use\nsimulations to demonstrate that learning causes the changes in confidence level\nduring decision-making in non-stationary environments, and results in\nL\\'evy-walk-like patterns. One inference algorithm involving confidence is\nBayesian inference. We propose an algorithm that introduces the effects of\nlearning and forgetting into Bayesian inference, and simulate an imitation game\nin which two decision-making agents incorporating the algorithm estimate each\nother's internal models from their opponent's observational data. For\nforgetting without learning, agent confidence levels remained low due to a lack\nof information on the counterpart and Brownian walks occurred for a wide range\nof forgetting rates. Conversely, when learning was introduced, high confidence\nlevels occasionally occurred even at high forgetting rates, and Brownian walks\nuniversally became L\\'evy walks through a mixture of high- and low-confidence\nstates.\n", "versions": [{"version": "v1", "created": "Wed, 16 Dec 2020 10:59:22 GMT"}], "update_date": "2020-12-17", "authors_parsed": [["Shinohara", "Shuji", ""], ["Manome", "Nobuhito", ""], ["Nakajima", "Yoshihiro", ""], ["Gunji", "Yukio Pegio", ""], ["Moriyama", "Toru", ""], ["Okamoto", "Hiroshi", ""], ["Mitsuyoshi", "Shunji", ""], ["Chung", "Ung-il", ""]]}, {"id": "2012.08859", "submitter": "Bert Moons", "authors": "Bert Moons, Parham Noorzad, Andrii Skliar, Giovanni Mariani, Dushyant\n  Mehta, Chris Lott, Tijmen Blankevoort", "title": "Distilling Optimal Neural Networks: Rapid Search in Diverse Spaces", "comments": "Main text 9 pages, Full text 21 pages, 18 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.NE stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Today, state-of-the-art Neural Architecture Search (NAS) methods cannot scale\nto many hardware platforms or scenarios at a low training costs and/or can only\nhandle non-diverse, heavily constrained architectural search-spaces. To solve\nthese issues, we present DONNA (Distilling Optimal Neural Network\nArchitectures), a novel pipeline for rapid and diverse NAS, that scales to many\nuser scenarios. In DONNA, a search consists of three phases. First, an accuracy\npredictor is built using blockwise knowledge distillation. This predictor\nenables searching across diverse networks with varying macro-architectural\nparameters such as layer types and attention mechanisms as well as across\nmicro-architectural parameters such as block repeats and expansion rates.\nSecond, a rapid evolutionary search phase finds a set of Pareto-optimal\narchitectures for any scenario using the accuracy predictor and on-device\nmeasurements. Third, optimal models are quickly finetuned to\ntraining-from-scratch accuracy. With this approach, DONNA is up to 100x faster\nthan MNasNet in finding state-of-the-art architectures on-device. Classifying\nImageNet, DONNA architectures are 20% faster than EfficientNet-B0 and\nMobileNetV2 on a Nvidia V100 GPU and 10% faster with 0.5% higher accuracy than\nMobileNetV2-1.4x on a Samsung S20 smartphone. In addition to NAS, DONNA is used\nfor search-space extension and exploration, as well as hardware-aware model\ncompression.\n", "versions": [{"version": "v1", "created": "Wed, 16 Dec 2020 11:00:19 GMT"}, {"version": "v2", "created": "Fri, 14 May 2021 08:14:26 GMT"}], "update_date": "2021-05-17", "authors_parsed": [["Moons", "Bert", ""], ["Noorzad", "Parham", ""], ["Skliar", "Andrii", ""], ["Mariani", "Giovanni", ""], ["Mehta", "Dushyant", ""], ["Lott", "Chris", ""], ["Blankevoort", "Tijmen", ""]]}, {"id": "2012.08883", "submitter": "Lei Sha", "authors": "Lei Sha, Thomas Lukasiewicz", "title": "Multi-type Disentanglement without Adversarial Training", "comments": null, "journal-ref": "Thirty-Fifth AAAI Conference on Artificial Intelligence\n  (AAAI-2021)", "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Controlling the style of natural language by disentangling the latent space\nis an important step towards interpretable machine learning. After the latent\nspace is disentangled, the style of a sentence can be transformed by tuning the\nstyle representation without affecting other features of the sentence. Previous\nworks usually use adversarial training to guarantee that disentangled vectors\ndo not affect each other. However, adversarial methods are difficult to train.\nEspecially when there are multiple features (e.g., sentiment, or tense, which\nwe call style types in this paper), each feature requires a separate\ndiscriminator for extracting a disentangled style vector corresponding to that\nfeature. In this paper, we propose a unified distribution-controlling method,\nwhich provides each specific style value (the value of style types, e.g.,\npositive sentiment, or past tense) with a unique representation. This method\ncontributes a solid theoretical basis to avoid adversarial training in\nmulti-type disentanglement. We also propose multiple loss functions to achieve\na style-content disentanglement as well as a disentanglement among multiple\nstyle types. In addition, we observe that if two different style types always\nhave some specific style values that occur together in the dataset, they will\naffect each other when transferring the style values. We call this phenomenon\ntraining bias, and we propose a loss function to alleviate such training bias\nwhile disentangling multiple types. We conduct experiments on two datasets\n(Yelp service reviews and Amazon product reviews) to evaluate the\nstyle-disentangling effect and the unsupervised style transfer performance on\ntwo style types: sentiment and tense. The experimental results show the\neffectiveness of our model.\n", "versions": [{"version": "v1", "created": "Wed, 16 Dec 2020 11:47:18 GMT"}], "update_date": "2020-12-17", "authors_parsed": [["Sha", "Lei", ""], ["Lukasiewicz", "Thomas", ""]]}, {"id": "2012.08884", "submitter": "Lei Sha", "authors": "Lei Sha, Oana-Maria Camburu, and Thomas Lukasiewicz", "title": "Learning from the Best: Rationalizing Prediction by Adversarial\n  Information Calibration", "comments": null, "journal-ref": "Proceedings of the 35th AAAI Conference on Artificial\n  Intelligence, 2021", "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Explaining the predictions of AI models is paramount in safety-critical\napplications, such as in legal or medical domains. One form of explanation for\na prediction is an extractive rationale, i.e., a subset of features of an\ninstance that lead the model to give its prediction on the instance. Previous\nworks on generating extractive rationales usually employ a two-phase model: a\nselector that selects the most important features (i.e., the rationale)\nfollowed by a predictor that makes the prediction based exclusively on the\nselected features. One disadvantage of these works is that the main signal for\nlearning to select features comes from the comparison of the answers given by\nthe predictor and the ground-truth answers. In this work, we propose to squeeze\nmore information from the predictor via an information calibration method. More\nprecisely, we train two models jointly: one is a typical neural model that\nsolves the task at hand in an accurate but black-box manner, and the other is a\nselector-predictor model that additionally produces a rationale for its\nprediction. The first model is used as a guide to the second model. We use an\nadversarial-based technique to calibrate the information extracted by the two\nmodels such that the difference between them is an indicator of the missed or\nover-selected features. In addition, for natural language tasks, we propose to\nuse a language-model-based regularizer to encourage the extraction of fluent\nrationales. Experimental results on a sentiment analysis task as well as on\nthree tasks from the legal domain show the effectiveness of our approach to\nrationale extraction.\n", "versions": [{"version": "v1", "created": "Wed, 16 Dec 2020 11:54:15 GMT"}, {"version": "v2", "created": "Fri, 18 Dec 2020 10:07:27 GMT"}], "update_date": "2020-12-21", "authors_parsed": [["Sha", "Lei", ""], ["Camburu", "Oana-Maria", ""], ["Lukasiewicz", "Thomas", ""]]}, {"id": "2012.08888", "submitter": "Peipei Kang", "authors": "Lei Yang, Zitong Zhang, Xiaotian Jia, Peipei Kang, Wensheng Zhang,\n  Dongya Wang", "title": "Solving the Travelling Thief Problem based on Item Selection Weight and\n  Reverse Order Allocation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The Travelling Thief Problem (TTP) is a challenging combinatorial\noptimization problem that attracts many scholars. The TTP interconnects two\nwell-known NP-hard problems: the Travelling Salesman Problem (TSP) and the 0-1\nKnapsack Problem (KP). Increasingly algorithms have been proposed for solving\nthis novel problem that combines two interdependent sub-problems. In this\npaper, TTP is investigated theoretically and empirically. An algorithm based on\nthe score value calculated by our proposed formulation in picking items and\nsorting items in the reverse order in the light of the scoring value is\nproposed to solve the problem. Different approaches for solving the TTP are\ncompared and analyzed; the experimental investigations suggest that our\nproposed approach is very efficient in meeting or beating current\nstate-of-the-art heuristic solutions on a comprehensive set of benchmark TTP\ninstances.\n", "versions": [{"version": "v1", "created": "Wed, 16 Dec 2020 12:06:05 GMT"}], "update_date": "2020-12-17", "authors_parsed": [["Yang", "Lei", ""], ["Zhang", "Zitong", ""], ["Jia", "Xiaotian", ""], ["Kang", "Peipei", ""], ["Zhang", "Wensheng", ""], ["Wang", "Dongya", ""]]}, {"id": "2012.08906", "submitter": "Cunxi Yu", "authors": "Yingjie Li, Ruiyang Chen, Berardi Sensale Rodriguez, Weilu Gao, and\n  Cunxi Yu", "title": "Real-time Multi-Task Diffractive Deep Neural Networks via\n  Hardware-Software Co-design", "comments": "23 pages including references and Supplementary Information. To\n  appear in Nature Scientific Reports", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI physics.optics", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Deep neural networks (DNNs) have substantial computational requirements,\nwhich greatly limit their performance in resource-constrained environments.\nRecently, there are increasing efforts on optical neural networks and optical\ncomputing based DNNs hardware, which bring significant advantages for deep\nlearning systems in terms of their power efficiency, parallelism and\ncomputational speed. Among them, free-space diffractive deep neural networks\n(D$^2$NNs) based on the light diffraction, feature millions of neurons in each\nlayer interconnected with neurons in neighboring layers. However, due to the\nchallenge of implementing reconfigurability, deploying different DNNs\nalgorithms requires re-building and duplicating the physical diffractive\nsystems, which significantly degrades the hardware efficiency in practical\napplication scenarios. Thus, this work proposes a novel hardware-software\nco-design method that enables robust and noise-resilient Multi-task Learning in\nD$^2$NNs. Our experimental results demonstrate significant improvements in\nversatility and hardware efficiency, and also demonstrate the robustness of\nproposed multi-task D$^2$NN architecture under wide noise ranges of all system\ncomponents. In addition, we propose a domain-specific regularization algorithm\nfor training the proposed multi-task architecture, which can be used to\nflexibly adjust the desired performance for each task.\n", "versions": [{"version": "v1", "created": "Wed, 16 Dec 2020 12:29:54 GMT"}, {"version": "v2", "created": "Thu, 1 Apr 2021 20:15:41 GMT"}], "update_date": "2021-04-05", "authors_parsed": [["Li", "Yingjie", ""], ["Chen", "Ruiyang", ""], ["Rodriguez", "Berardi Sensale", ""], ["Gao", "Weilu", ""], ["Yu", "Cunxi", ""]]}, {"id": "2012.08911", "submitter": "Sijie Mai", "authors": "Sijie Mai, Shuangjia Zheng, Yuedong Yang, Haifeng Hu", "title": "Communicative Message Passing for Inductive Relation Reasoning", "comments": "Accepted by AAAI-2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Relation prediction for knowledge graphs aims at predicting missing\nrelationships between entities. Despite the importance of inductive relation\nprediction, most previous works are limited to a transductive setting and\ncannot process previously unseen entities. The recent proposed subgraph-based\nrelation reasoning models provided alternatives to predict links from the\nsubgraph structure surrounding a candidate triplet inductively. However, we\nobserve that these methods often neglect the directed nature of the extracted\nsubgraph and weaken the role of relation information in the subgraph modeling.\nAs a result, they fail to effectively handle the asymmetric/anti-symmetric\ntriplets and produce insufficient embeddings for the target triplets. To this\nend, we introduce a \\textbf{C}\\textbf{o}mmunicative \\textbf{M}essage\n\\textbf{P}assing neural network for \\textbf{I}nductive re\\textbf{L}ation\nr\\textbf{E}asoning, \\textbf{CoMPILE}, that reasons over local directed subgraph\nstructures and has a vigorous inductive bias to process entity-independent\nsemantic relations. In contrast to existing models, CoMPILE strengthens the\nmessage interactions between edges and entitles through a communicative kernel\nand enables a sufficient flow of relation information. Moreover, we demonstrate\nthat CoMPILE can naturally handle asymmetric/anti-symmetric relations without\nthe need for explosively increasing the number of model parameters by\nextracting the directed enclosing subgraphs. Extensive experiments show\nsubstantial performance gains in comparison to state-of-the-art methods on\ncommonly used benchmark datasets with variant inductive settings.\n", "versions": [{"version": "v1", "created": "Wed, 16 Dec 2020 12:42:06 GMT"}, {"version": "v2", "created": "Mon, 26 Jul 2021 12:18:21 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Mai", "Sijie", ""], ["Zheng", "Shuangjia", ""], ["Yang", "Yuedong", ""], ["Hu", "Haifeng", ""]]}, {"id": "2012.08919", "submitter": "Denisa A. O. Roberts", "authors": "Denisa A.O. Roberts", "title": "Multilingual Evidence Retrieval and Fact Verification to Combat Global\n  Disinformation: The Power of Polyglotism", "comments": "Accepted ECIR 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article investigates multilingual evidence retrieval and fact\nverification as a step to combat global disinformation, a first effort of this\nkind, to the best of our knowledge. The goal is building multilingual systems\nthat retrieve in evidence-rich languages to verify claims in evidence-poor\nlanguages that are more commonly targeted by disinformation. To this end, our\nEnmBERT fact verification system shows evidence of transfer learning ability\nand 400 example mixed English-Romanian dataset is made available for\ncross-lingual transfer learning evaluation.\n", "versions": [{"version": "v1", "created": "Wed, 16 Dec 2020 13:10:56 GMT"}, {"version": "v2", "created": "Tue, 19 Jan 2021 23:02:58 GMT"}], "update_date": "2021-01-21", "authors_parsed": [["Roberts", "Denisa A. O.", ""]]}, {"id": "2012.08920", "submitter": "Kun Zhang", "authors": "Kun Zhang, Le Wu, Guangyi Lv, Meng Wang, Enhong Chen, Shulan Ruan", "title": "R$^2$-Net: Relation of Relation Learning Network for Sentence Semantic\n  Matching", "comments": "This paper has been accepted to/by AAAI2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Sentence semantic matching is one of the fundamental tasks in natural\nlanguage processing, which requires an agent to determine the semantic relation\namong input sentences. Recently, deep neural networks have achieved impressive\nperformance in this area, especially BERT. Despite the effectiveness of these\nmodels, most of them treat output labels as meaningless one-hot vectors,\nunderestimating the semantic information and guidance of relations that these\nlabels reveal, especially for tasks with a small number of labels. To address\nthis problem, we propose a Relation of Relation Learning Network (R2-Net) for\nsentence semantic matching. Specifically, we first employ BERT to encode the\ninput sentences from a global perspective. Then a CNN-based encoder is designed\nto capture keywords and phrase information from a local perspective. To fully\nleverage labels for better relation information extraction, we introduce a\nself-supervised relation of relation classification task for guiding R2-Net to\nconsider more about labels. Meanwhile, a triplet loss is employed to\ndistinguish the intra-class and inter-class relations in a finer granularity.\nEmpirical experiments on two sentence semantic matching tasks demonstrate the\nsuperiority of our proposed model. As a byproduct, we have released the codes\nto facilitate other researches.\n", "versions": [{"version": "v1", "created": "Wed, 16 Dec 2020 13:11:30 GMT"}], "update_date": "2020-12-17", "authors_parsed": [["Zhang", "Kun", ""], ["Wu", "Le", ""], ["Lv", "Guangyi", ""], ["Wang", "Meng", ""], ["Chen", "Enhong", ""], ["Ruan", "Shulan", ""]]}, {"id": "2012.08922", "submitter": "Zhichao Wu", "authors": "Zhichao Wu and Lei Guo and Hao Zhang and Dan Xu", "title": "Unsupervised Image Segmentation using Mutual Mean-Teaching", "comments": "5 figures, 9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unsupervised image segmentation aims at assigning the pixels with similar\nfeature into a same cluster without annotation, which is an important task in\ncomputer vision. Due to lack of prior knowledge, most of existing model usually\nneed to be trained several times to obtain suitable results. To address this\nproblem, we propose an unsupervised image segmentation model based on the\nMutual Mean-Teaching (MMT) framework to produce more stable results. In\naddition, since the labels of pixels from two model are not matched, a label\nalignment algorithm based on the Hungarian algorithm is proposed to match the\ncluster labels. Experimental results demonstrate that the proposed model is\nable to segment various types of images and achieves better performance than\nthe existing methods.\n", "versions": [{"version": "v1", "created": "Wed, 16 Dec 2020 13:13:34 GMT"}], "update_date": "2020-12-17", "authors_parsed": [["Wu", "Zhichao", ""], ["Guo", "Lei", ""], ["Zhang", "Hao", ""], ["Xu", "Dan", ""]]}, {"id": "2012.08986", "submitter": "Huifeng Guo", "authors": "Huifeng Guo, Bo Chen, Ruiming Tang, Weinan Zhang, Zhenguo Li, Xiuqiang\n  He", "title": "An Embedding Learning Framework for Numerical Features in CTR Prediction", "comments": "9 pages", "journal-ref": null, "doi": "10.1145/3447548.3467077", "report-no": null, "categories": "cs.IR cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Click-Through Rate (CTR) prediction is critical for industrial recommender\nsystems, where most deep CTR models follow an Embedding \\& Feature Interaction\nparadigm. However, the majority of methods focus on designing network\narchitectures to better capture feature interactions while the feature\nembedding, especially for numerical features, has been overlooked. Existing\napproaches for numerical features are difficult to capture informative\nknowledge because of the low capacity or hard discretization based on the\noffline expertise feature engineering. In this paper, we propose a novel\nembedding learning framework for numerical features in CTR prediction (AutoDis)\nwith high model capacity, end-to-end training and unique representation\nproperties preserved. AutoDis consists of three core components:\nmeta-embeddings, automatic discretization and aggregation. Specifically, we\npropose meta-embeddings for each numerical field to learn global knowledge from\nthe perspective of field with a manageable number of parameters. Then the\ndifferentiable automatic discretization performs soft discretization and\ncaptures the correlations between the numerical features and meta-embeddings.\nFinally, distinctive and informative embeddings are learned via an aggregation\nfunction. Comprehensive experiments on two public and one industrial datasets\nare conducted to validate the effectiveness of AutoDis. Moreover, AutoDis has\nbeen deployed onto a mainstream advertising platform, where online A/B test\ndemonstrates the improvement over the base model by 2.1% and 2.7% in terms of\nCTR and eCPM, respectively. In addition, the code of our framework is publicly\navailable in\nMindSpore(https://gitee.com/mindspore/mindspore/tree/master/model_zoo/research/recommend/autodis).\n", "versions": [{"version": "v1", "created": "Wed, 16 Dec 2020 14:31:31 GMT"}, {"version": "v2", "created": "Sat, 22 May 2021 05:20:45 GMT"}], "update_date": "2021-05-25", "authors_parsed": [["Guo", "Huifeng", ""], ["Chen", "Bo", ""], ["Tang", "Ruiming", ""], ["Zhang", "Weinan", ""], ["Li", "Zhenguo", ""], ["He", "Xiuqiang", ""]]}, {"id": "2012.08987", "submitter": "Hanlei Zhang", "authors": "Hanlei Zhang, Hua Xu, Ting-En Lin, Rui Lyu", "title": "Discovering New Intents with Deep Aligned Clustering", "comments": "Accepted by AAAI 2021 (Main Track, Long Paper)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Discovering new intents is a crucial task in dialogue systems. Most existing\nmethods are limited in transferring the prior knowledge from known intents to\nnew intents. They also have difficulties in providing high-quality supervised\nsignals to learn clustering-friendly features for grouping unlabeled intents.\nIn this work, we propose an effective method, Deep Aligned Clustering, to\ndiscover new intents with the aid of the limited known intent data. Firstly, we\nleverage a few labeled known intent samples as prior knowledge to pre-train the\nmodel. Then, we perform k-means to produce cluster assignments as\npseudo-labels. Moreover, we propose an alignment strategy to tackle the label\ninconsistency problem during clustering assignments. Finally, we learn the\nintent representations under the supervision of the aligned pseudo-labels. With\nan unknown number of new intents, we predict the number of intent categories by\neliminating low-confidence intent-wise clusters. Extensive experiments on two\nbenchmark datasets show that our method is more robust and achieves substantial\nimprovements over the state-of-the-art methods. The codes are released at\nhttps://github.com/thuiar/DeepAligned-Clustering.\n", "versions": [{"version": "v1", "created": "Wed, 16 Dec 2020 14:32:06 GMT"}, {"version": "v2", "created": "Fri, 18 Dec 2020 09:45:17 GMT"}, {"version": "v3", "created": "Mon, 21 Dec 2020 01:19:56 GMT"}, {"version": "v4", "created": "Tue, 22 Dec 2020 02:20:28 GMT"}, {"version": "v5", "created": "Tue, 9 Feb 2021 15:27:51 GMT"}, {"version": "v6", "created": "Fri, 19 Mar 2021 03:03:33 GMT"}, {"version": "v7", "created": "Mon, 22 Mar 2021 02:35:17 GMT"}], "update_date": "2021-03-23", "authors_parsed": [["Zhang", "Hanlei", ""], ["Xu", "Hua", ""], ["Lin", "Ting-En", ""], ["Lyu", "Rui", ""]]}, {"id": "2012.09015", "submitter": "Nuno Fachada", "authors": "Nuno Fachada", "title": "ColorShapeLinks: A board game AI competition for educators and students", "comments": "The peer-reviewed version of this paper is published in Computers and\n  Education: Artificial Intelligence at\n  https://doi.org/10.1016/j.caeai.2021.100014. This version is typeset by the\n  author and differs only in pagination and typographical detail", "journal-ref": "Computers and Education: Artificial Intelligence, 2, 100014, 2021", "doi": "10.1016/j.caeai.2021.100014", "report-no": null, "categories": "cs.CY cs.AI cs.HC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  ColorShapeLinks is an AI board game competition framework specially designed\nfor students and educators in videogame development, with openness and\naccessibility in mind. The competition is based on an arbitrarily-sized version\nof the Simplexity board game, the motto of which, \"simple to learn, complex to\nmaster\", is curiously also applicable to AI agents. ColorShapeLinks offers\ngraphical and text-based frontends and a completely open and documented\ndevelopment framework built using industry standard tools and following\nsoftware engineering best practices. ColorShapeLinks is not only a competition,\nbut both a game and a framework which educators and students can extend and use\nto host their own competitions. It has been successfully used for running\ninternal competitions in AI classes, as well as for hosting an international AI\ncompetition at the IEEE Conference on Games.\n", "versions": [{"version": "v1", "created": "Wed, 16 Dec 2020 15:21:29 GMT"}, {"version": "v2", "created": "Fri, 26 Feb 2021 18:05:20 GMT"}], "update_date": "2021-03-01", "authors_parsed": [["Fachada", "Nuno", ""]]}, {"id": "2012.09020", "submitter": "Qing Wan", "authors": "Qing Wan, Yoonsuck Choe", "title": "AdjointBackMap: Reconstructing Effective Decision Hypersurfaces from CNN\n  Layers Using Adjoint Operators", "comments": "23 pages, 16 figures, 145MB. It may take some time to load", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There are several effective methods in explaining the inner workings of\nconvolutional neural networks (CNNs). However, in general, finding the inverse\nof the function performed by CNNs as a whole is an ill-posed problem. In this\npaper, we propose a method based on adjoint operators to reconstruct, given an\narbitrary unit in the CNN (except for the first convolutional layer), its\neffective hypersurface in the input space that replicates that unit's decision\nsurface conditioned on a particular input image. Our results show that the\nhypersurface reconstructed this way, when multiplied by the original input\nimage, would give nearly the exact output value of that unit. We find that the\nCNN unit's decision surface is largely conditioned on the input, and this may\nexplain why adversarial inputs can effectively deceive CNNs.\n", "versions": [{"version": "v1", "created": "Wed, 16 Dec 2020 15:35:47 GMT"}, {"version": "v2", "created": "Tue, 30 Mar 2021 02:13:37 GMT"}], "update_date": "2021-03-31", "authors_parsed": [["Wan", "Qing", ""], ["Choe", "Yoonsuck", ""]]}, {"id": "2012.09049", "submitter": "Jorge Martinez Gil Ph.D.", "authors": "Georg Buchgeher, David Gabauer, Jorge Martinez-Gil, Lisa Ehrlinger", "title": "Knowledge Graphs in Manufacturing and Production: A Systematic\n  Literature Review", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge graphs in manufacturing and production aim to make production lines\nmore efficient and flexible with higher quality output. This makes knowledge\ngraphs attractive for companies to reach Industry 4.0 goals. However, existing\nresearch in the field is quite preliminary, and more research effort on\nanalyzing how knowledge graphs can be applied in the field of manufacturing and\nproduction is needed. Therefore, we have conducted a systematic literature\nreview as an attempt to characterize the state-of-the-art in this field, i.e.,\nby identifying exiting research and by identifying gaps and opportunities for\nfurther research. To do that, we have focused on finding the primary studies in\nthe existing literature, which were classified and analyzed according to four\ncriteria: bibliometric key facts, research type facets, knowledge graph\ncharacteristics, and application scenarios. Besides, an evaluation of the\nprimary studies has also been carried out to gain deeper insights in terms of\nmethodology, empirical evidence, and relevance. As a result, we can offer a\ncomplete picture of the domain, which includes such interesting aspects as the\nfact that knowledge fusion is currently the main use case for knowledge graphs,\nthat empirical research and industrial application are still missing to a large\nextent, that graph embeddings are not fully exploited, and that technical\nliterature is fast-growing but seems to be still far from its peak.\n", "versions": [{"version": "v1", "created": "Wed, 16 Dec 2020 16:15:28 GMT"}], "update_date": "2020-12-17", "authors_parsed": [["Buchgeher", "Georg", ""], ["Gabauer", "David", ""], ["Martinez-Gil", "Jorge", ""], ["Ehrlinger", "Lisa", ""]]}, {"id": "2012.09077", "submitter": "Adrien Coulet", "authors": "Emmanuel Bresso, Pierre Monnin, C\\'edric Bousquet, Fran\\c{c}ois-Elie\n  Calvier, Ndeye-Coumba Ndiaye, Nadine Petitpain, Malika Sma\\\"il-Tabbone,\n  Adrien Coulet", "title": "Investigating ADR mechanisms with knowledge graph mining and explainable\n  AI", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.SC", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Adverse Drug Reactions (ADRs) are characterized within randomized clinical\ntrials and postmarketing pharmacovigilance, but their molecular mechanism\nremains unknown in most cases. Aside from clinical trials, many elements of\nknowledge about drug ingredients are available in open-access knowledge graphs.\nIn addition, drug classifications that label drugs as either causative or not\nfor several ADRs, have been established. We propose to mine knowledge graphs\nfor identifying biomolecular features that may enable reproducing automatically\nexpert classifications that distinguish drug causative or not for a given type\nof ADR. In an explainable AI perspective, we explore simple classification\ntechniques such as Decision Trees and Classification Rules because they provide\nhuman-readable models, which explain the classification itself, but may also\nprovide elements of explanation for molecular mechanisms behind ADRs. In\nsummary, we mine a knowledge graph for features; we train classifiers at\ndistinguishing, drugs associated or not with ADRs; we isolate features that are\nboth efficient in reproducing expert classifications and interpretable by\nexperts (i.e., Gene Ontology terms, drug targets, or pathway names); and we\nmanually evaluate how they may be explanatory. Extracted features reproduce\nwith a good fidelity classifications of drugs causative or not for DILI and\nSCAR. Experts fully agreed that 73% and 38% of the most discriminative features\nare possibly explanatory for DILI and SCAR, respectively; and partially agreed\n(2/3) for 90% and 77% of them. Knowledge graphs provide diverse features to\nenable simple and explainable models to distinguish between drugs that are\ncausative or not for ADRs. In addition to explaining classifications, most\ndiscriminative features appear to be good candidates for investigating ADR\nmechanisms further.\n", "versions": [{"version": "v1", "created": "Wed, 16 Dec 2020 16:59:25 GMT"}], "update_date": "2020-12-17", "authors_parsed": [["Bresso", "Emmanuel", ""], ["Monnin", "Pierre", ""], ["Bousquet", "C\u00e9dric", ""], ["Calvier", "Fran\u00e7ois-Elie", ""], ["Ndiaye", "Ndeye-Coumba", ""], ["Petitpain", "Nadine", ""], ["Sma\u00efl-Tabbone", "Malika", ""], ["Coulet", "Adrien", ""]]}, {"id": "2012.09090", "submitter": "Prateek Chaudhry", "authors": "Prateek Chaudhry and Matthew Lease", "title": "You Are What You Tweet: Profiling Users by Past Tweets to Improve Hate\n  Speech Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Hate speech detection research has predominantly focused on purely\ncontent-based methods, without exploiting any additional context. We briefly\ncritique pros and cons of this task formulation. We then investigate profiling\nusers by their past utterances as an informative prior to better predict\nwhether new utterances constitute hate speech. To evaluate this, we augment\nthree Twitter hate speech datasets with additional timeline data, then embed\nthis additional context into a strong baseline model. Promising results suggest\nmerit for further investigation, though analysis is complicated by differences\nin annotation schemes and processes, as well as Twitter API limitations and\ndata sharing policies.\n", "versions": [{"version": "v1", "created": "Wed, 16 Dec 2020 17:17:47 GMT"}], "update_date": "2020-12-17", "authors_parsed": [["Chaudhry", "Prateek", ""], ["Lease", "Matthew", ""]]}, {"id": "2012.09093", "submitter": "Huolin Xin", "authors": "Ruoqian Lin, Rui Zhang, Chunyang Wang, Xiao-Qing Yang, Huolin L. Xin", "title": "TEMImageNet Training Library and AtomSegNet Deep-Learning Models for\n  High-Precision Atom Segmentation, Localization, Denoising, and\n  Super-Resolution Processing of Atomic-Resolution Images", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cond-mat.mtrl-sci cs.AI cs.CV", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Atom segmentation and localization, noise reduction and deblurring of\natomic-resolution scanning transmission electron microscopy (STEM) images with\nhigh precision and robustness is a challenging task. Although several\nconventional algorithms, such has thresholding, edge detection and clustering,\ncan achieve reasonable performance in some predefined sceneries, they tend to\nfail when interferences from the background are strong and unpredictable.\nParticularly, for atomic-resolution STEM images, so far there is no\nwell-established algorithm that is robust enough to segment or detect all\natomic columns when there is large thickness variation in a recorded image.\nHerein, we report the development of a training library and a deep learning\nmethod that can perform robust and precise atom segmentation, localization,\ndenoising, and super-resolution processing of experimental images. Despite\nusing simulated images as training datasets, the deep-learning model can\nself-adapt to experimental STEM images and shows outstanding performance in\natom detection and localization in challenging contrast conditions and the\nprecision consistently outperforms the state-of-the-art two-dimensional\nGaussian fit method. Taking a step further, we have deployed our deep-learning\nmodels to a desktop app with a graphical user interface and the app is free and\nopen-source. We have also built a TEM ImageNet project website for easy\nbrowsing and downloading of the training data.\n", "versions": [{"version": "v1", "created": "Wed, 16 Dec 2020 17:21:23 GMT"}, {"version": "v2", "created": "Sat, 20 Feb 2021 06:14:18 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Lin", "Ruoqian", ""], ["Zhang", "Rui", ""], ["Wang", "Chunyang", ""], ["Yang", "Xiao-Qing", ""], ["Xin", "Huolin L.", ""]]}, {"id": "2012.09108", "submitter": "Paolo Notaro", "authors": "Paolo Notaro, Jorge Cardoso, and Michael Gerndt", "title": "A Systematic Mapping Study in AIOps", "comments": null, "journal-ref": "International Workshop on Artificial Intelligence for IT\n  Operations (AIOPS) 2020", "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.DC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  IT systems of today are becoming larger and more complex, rendering their\nhuman supervision more difficult. Artificial Intelligence for IT Operations\n(AIOps) has been proposed to tackle modern IT administration challenges thanks\nto AI and Big Data. However, past AIOps contributions are scattered,\nunorganized and missing a common terminology convention, which renders their\ndiscovery and comparison impractical. In this work, we conduct an in-depth\nmapping study to collect and organize the numerous scattered contributions to\nAIOps in a unique reference index. We create an AIOps taxonomy to build a\nfoundation for future contributions and allow an efficient comparison of AIOps\npapers treating similar problems. We investigate temporal trends and classify\nAIOps contributions based on the choice of algorithms, data sources and the\ntarget components. Our results show a recent and growing interest towards\nAIOps, specifically to those contributions treating failure-related tasks\n(62%), such as anomaly detection and root cause analysis.\n", "versions": [{"version": "v1", "created": "Tue, 15 Dec 2020 09:05:20 GMT"}], "update_date": "2020-12-17", "authors_parsed": [["Notaro", "Paolo", ""], ["Cardoso", "Jorge", ""], ["Gerndt", "Michael", ""]]}, {"id": "2012.09110", "submitter": "Kashif Ahmad", "authors": "Kashif Ahmad, Majdi Maabreh, Mohamed Ghaly, Khalil Khan, Junaid Qadir,\n  Ala Al-Fuqaha", "title": "Developing Future Human-Centered Smart Cities: Critical Analysis of\n  Smart City Security, Interpretability, and Ethical Challenges", "comments": "I withdraw this paper, as I uploaded it by mistake", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  As we make tremendous advances in machine learning and artificial\nintelligence technosciences, there is a renewed understanding in the AI\ncommunity that we must ensure that humans being are at the center of our\ndeliberations so that we don't end in technology-induced dystopias. As strongly\nargued by Green in his book Smart Enough City, the incorporation of technology\nin city environs does not automatically translate into prosperity, wellbeing,\nurban livability, or social justice. There is a great need to deliberate on the\nfuture of the cities worth living and designing. There are philosophical and\nethical questions involved along with various challenges that relate to the\nsecurity, safety, and interpretability of AI algorithms that will form the\ntechnological bedrock of future cities. Several research institutes on human\ncentered AI have been established at top international universities. Globally\nthere are calls for technology to be made more humane and human-compatible. For\nexample, Stuart Russell has a book called Human Compatible AI. The Center for\nHumane Technology advocates for regulators and technology companies to avoid\nbusiness models and product features that contribute to social problems such as\nextremism, polarization, misinformation, and Internet addiction. In this paper,\nwe analyze and explore key challenges including security, robustness,\ninterpretability, and ethical challenges to a successful deployment of AI or ML\nin human-centric applications, with a particular emphasis on the convergence of\nthese challenges. We provide a detailed review of existing literature on these\nkey challenges and analyze how one of these challenges may lead to others or\nhelp in solving other challenges. The paper also advises on the current\nlimitations, pitfalls, and future directions of research in these domains, and\nhow it can fill the current gaps and lead to better solutions.\n", "versions": [{"version": "v1", "created": "Mon, 14 Dec 2020 18:54:05 GMT"}, {"version": "v2", "created": "Tue, 22 Jun 2021 17:19:22 GMT"}, {"version": "v3", "created": "Wed, 30 Jun 2021 12:57:19 GMT"}], "update_date": "2021-07-01", "authors_parsed": [["Ahmad", "Kashif", ""], ["Maabreh", "Majdi", ""], ["Ghaly", "Mohamed", ""], ["Khan", "Khalil", ""], ["Qadir", "Junaid", ""], ["Al-Fuqaha", "Ala", ""]]}, {"id": "2012.09123", "submitter": "Lei Cao", "authors": "Lei Cao, Huijun Zhang, and Ling Feng", "title": "Building and Using Personal Knowledge Graph to Improve Suicidal Ideation\n  Detection on Social Media", "comments": "Accepted to IEEE Transaction on Multimedia", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  A large number of individuals are suffering from suicidal ideation in the\nworld. There are a number of causes behind why an individual might suffer from\nsuicidal ideation. As the most popular platform for self-expression, emotion\nrelease, and personal interaction, individuals may exhibit a number of symptoms\nof suicidal ideation on social media. Nevertheless, challenges from both data\nand knowledge aspects remain as obstacles, constraining the social media-based\ndetection performance. Data implicitness and sparsity make it difficult to\ndiscover the inner true intentions of individuals based on their posts.\nInspired by psychological studies, we build and unify a high-level\nsuicide-oriented knowledge graph with deep neural networks for suicidal\nideation detection on social media. We further design a two-layered attention\nmechanism to explicitly reason and establish key risk factors to individual's\nsuicidal ideation. The performance study on microblog and Reddit shows that: 1)\nwith the constructed personal knowledge graph, the social media-based suicidal\nideation detection can achieve over 93% accuracy; and 2) among the six\ncategories of personal factors, post, personality, and experience are the top-3\nkey indicators. Under these categories, posted text, stress level, stress\nduration, posted image, and ruminant thinking contribute to one's suicidal\nideation detection.\n", "versions": [{"version": "v1", "created": "Wed, 16 Dec 2020 18:09:32 GMT"}], "update_date": "2020-12-17", "authors_parsed": [["Cao", "Lei", ""], ["Zhang", "Huijun", ""], ["Feng", "Ling", ""]]}, {"id": "2012.09126", "submitter": "Andrea Dittadi", "authors": "Andrea Dittadi, Frederik K. Drachmann, Thomas Bolander", "title": "Planning from Pixels in Atari with Learned Symbolic Representations", "comments": "Published at AAAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Width-based planning methods have been shown to yield state-of-the-art\nperformance in the Atari 2600 domain using pixel input. One successful\napproach, RolloutIW, represents states with the B-PROST boolean feature set. An\naugmented version of RolloutIW, $\\pi$-IW, shows that learned features can be\ncompetitive with handcrafted ones for width-based search. In this paper, we\nleverage variational autoencoders (VAEs) to learn features directly from pixels\nin a principled manner, and without supervision. The inference model of the\ntrained VAEs extracts boolean features from pixels, and RolloutIW plans with\nthese features. The resulting combination outperforms the original RolloutIW\nand human professional play on Atari 2600 and drastically reduces the size of\nthe feature set.\n", "versions": [{"version": "v1", "created": "Wed, 16 Dec 2020 18:15:11 GMT"}, {"version": "v2", "created": "Mon, 15 Mar 2021 17:20:05 GMT"}], "update_date": "2021-03-16", "authors_parsed": [["Dittadi", "Andrea", ""], ["Drachmann", "Frederik K.", ""], ["Bolander", "Thomas", ""]]}, {"id": "2012.09135", "submitter": "Tarik A. Rashid", "authors": "Danial A. Muhammed, Tarik A. Rashid, Abeer Alsadoon, Nebojsa Bacanin,\n  Polla Fattah, Mokhtar Mohammadi and Indradip Banerjee", "title": "An Improved Simulation Model for Pedestrian Crowd Evacuation", "comments": "15 pages, accepted in Mathematics, MDPI, 2020", "journal-ref": null, "doi": "10.3390/math8122171", "report-no": null, "categories": "cs.MA cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper works on one of the most recent pedestrian crowd evacuation\nmodels, i.e., \"a simulation model for pedestrian crowd evacuation based on\nvarious AI techniques\", developed in late 2019. This study adds a new feature\nto the developed model by proposing a new method and integrating it with the\nmodel. This method enables the developed model to find a more appropriate\nevacuation area design, among others regarding safety due to selecting the best\nexit door location among many suggested locations. This method is completely\ndependent on the selected model's output, i.e., the evacuation time for each\nindividual within the evacuation process. The new method finds an average of\nthe evacuees' evacuation times of each exit door location; then, based on the\naverage evacuation time, it decides which exit door location would be the best\nexit door to be used for evacuation by the evacuees. To validate the method,\nvarious designs for the evacuation area with various written scenarios were\nused. The results showed that the model with this new method could predict a\nproper exit door location among many suggested locations. Lastly, from the\nresults of this research using the integration of this newly proposed method, a\nnew capability for the selected model in terms of safety allowed the right\ndecision in selecting the finest design for the evacuation area among other\ndesigns.\n", "versions": [{"version": "v1", "created": "Fri, 4 Dec 2020 18:25:03 GMT"}], "update_date": "2020-12-17", "authors_parsed": [["Muhammed", "Danial A.", ""], ["Rashid", "Tarik A.", ""], ["Alsadoon", "Abeer", ""], ["Bacanin", "Nebojsa", ""], ["Fattah", "Polla", ""], ["Mohammadi", "Mokhtar", ""], ["Banerjee", "Indradip", ""]]}, {"id": "2012.09136", "submitter": "Griffin Adams", "authors": "Griffin Adams, Sarguna Janani Padmanabhan, Shivang Shekhar", "title": "Resolving Implicit Coordination in Multi-Agent Deep Reinforcement\n  Learning with Deep Q-Networks & Game Theory", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address two major challenges of implicit coordination in multi-agent deep\nreinforcement learning: non-stationarity and exponential growth of state-action\nspace, by combining Deep-Q Networks for policy learning with Nash equilibrium\nfor action selection. Q-values proxy as payoffs in Nash settings, and mutual\nbest responses define joint action selection. Coordination is implicit because\nmultiple/no Nash equilibria are resolved deterministically. We demonstrate that\nknowledge of game type leads to an assumption of mirrored best responses and\nfaster convergence than Nash-Q. Specifically, the Friend-or-Foe algorithm\ndemonstrates signs of convergence to a Set Controller which jointly chooses\nactions for two agents. This encouraging given the highly unstable nature of\ndecentralized coordination over joint actions. Inspired by the dueling network\narchitecture, which decouples the Q-function into state and advantage streams,\nas well as residual networks, we learn both a single and joint agent\nrepresentation, and merge them via element-wise addition. This simplifies\ncoordination by recasting it is as learning a residual function. We also draw\nhigh level comparative insights on key MADRL and game theoretic variables:\ncompetitive vs. cooperative, asynchronous vs. parallel learning, greedy versus\nsocially optimal Nash equilibria tie breaking, and strategies for the no Nash\nequilibrium case. We evaluate on 3 custom environments written in Python using\nOpenAI Gym: a Predator Prey environment, an alternating Warehouse environment,\nand a Synchronization environment. Each environment requires successively more\ncoordination to achieve positive rewards.\n", "versions": [{"version": "v1", "created": "Tue, 8 Dec 2020 17:30:47 GMT"}], "update_date": "2020-12-17", "authors_parsed": [["Adams", "Griffin", ""], ["Padmanabhan", "Sarguna Janani", ""], ["Shekhar", "Shivang", ""]]}, {"id": "2012.09157", "submitter": "Xinyan Zhao", "authors": "Xinyan Zhao, V.G.Vinod Vydiswaran", "title": "LIREx: Augmenting Language Inference with Relevant Explanation", "comments": "Accepted at AAAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Natural language explanations (NLEs) are a special form of data annotation in\nwhich annotators identify rationales (most significant text tokens) when\nassigning labels to data instances, and write out explanations for the labels\nin natural language based on the rationales. NLEs have been shown to capture\nhuman reasoning better, but not as beneficial for natural language inference\n(NLI). In this paper, we analyze two primary flaws in the way NLEs are\ncurrently used to train explanation generators for language inference tasks. We\nfind that the explanation generators do not take into account the variability\ninherent in human explanation of labels, and that the current explanation\ngeneration models generate spurious explanations. To overcome these\nlimitations, we propose a novel framework, LIREx, that incorporates both a\nrationale-enabled explanation generator and an instance selector to select only\nrelevant, plausible NLEs to augment NLI models. When evaluated on the\nstandardized SNLI data set, LIREx achieved an accuracy of 91.87%, an\nimprovement of 0.32 over the baseline and matching the best-reported\nperformance on the data set. It also achieves significantly better performance\nthan previous studies when transferred to the out-of-domain MultiNLI data set.\nQualitative analysis shows that LIREx generates flexible, faithful, and\nrelevant NLEs that allow the model to be more robust to spurious explanations.\nThe code is available at https://github.com/zhaoxy92/LIREx.\n", "versions": [{"version": "v1", "created": "Wed, 16 Dec 2020 18:49:29 GMT"}], "update_date": "2020-12-17", "authors_parsed": [["Zhao", "Xinyan", ""], ["Vydiswaran", "V. G. Vinod", ""]]}, {"id": "2012.09220", "submitter": "Ashutosh Kakadiya", "authors": "Ashutosh Kakadiya and Sriraam Natarajan and Balaraman Ravindran", "title": "Relational Boosted Bandits", "comments": "8 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Contextual bandits algorithms have become essential in real-world user\ninteraction problems in recent years. However, these algorithms rely on context\nas attribute value representation, which makes them unfeasible for real-world\ndomains like social networks are inherently relational. We propose Relational\nBoosted Bandits(RB2), acontextual bandits algorithm for relational domains\nbased on (relational) boosted trees. RB2 enables us to learn interpretable and\nexplainable models due to the more descriptive nature of the relational\nrepresentation. We empirically demonstrate the effectiveness and\ninterpretability of RB2 on tasks such as link prediction, relational\nclassification, and recommendations.\n", "versions": [{"version": "v1", "created": "Wed, 16 Dec 2020 19:24:58 GMT"}], "update_date": "2020-12-18", "authors_parsed": [["Kakadiya", "Ashutosh", ""], ["Natarajan", "Sriraam", ""], ["Ravindran", "Balaraman", ""]]}, {"id": "2012.09237", "submitter": "Biagio Brattoli", "authors": "Biagio Brattoli, Uta Buechler, Michael Dorkenwald, Philipp Reiser,\n  Linard Filli, Fritjof Helmchen, Anna-Sophia Wahl, Bjoern Ommer", "title": "Unsupervised Behaviour Analysis and Magnification (uBAM) using Deep\n  Learning", "comments": "Published in Nature Machine Intelligence (2021),\n  https://rdcu.be/ch6pL", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motor behaviour analysis is essential to biomedical research and clinical\ndiagnostics as it provides a non-invasive strategy for identifying motor\nimpairment and its change caused by interventions. State-of-the-art\ninstrumented movement analysis is time- and cost-intensive, since it requires\nplacing physical or virtual markers. Besides the effort required for marking\nkeypoints or annotations necessary for training or finetuning a detector, users\nneed to know the interesting behaviour beforehand to provide meaningful\nkeypoints. We introduce unsupervised behaviour analysis and magnification\n(uBAM), an automatic deep learning algorithm for analysing behaviour by\ndiscovering and magnifying deviations. A central aspect is unsupervised\nlearning of posture and behaviour representations to enable an objective\ncomparison of movement. Besides discovering and quantifying deviations in\nbehaviour, we also propose a generative model for visually magnifying subtle\nbehaviour differences directly in a video without requiring a detour via\nkeypoints or annotations. Essential for this magnification of deviations even\nacross different individuals is a disentangling of appearance and behaviour.\nEvaluations on rodents and human patients with neurological diseases\ndemonstrate the wide applicability of our approach. Moreover, combining\noptogenetic stimulation with our unsupervised behaviour analysis shows its\nsuitability as a non-invasive diagnostic tool correlating function to brain\nplasticity.\n", "versions": [{"version": "v1", "created": "Wed, 16 Dec 2020 20:07:36 GMT"}, {"version": "v2", "created": "Wed, 31 Mar 2021 13:07:54 GMT"}, {"version": "v3", "created": "Tue, 6 Apr 2021 13:52:14 GMT"}], "update_date": "2021-04-07", "authors_parsed": [["Brattoli", "Biagio", ""], ["Buechler", "Uta", ""], ["Dorkenwald", "Michael", ""], ["Reiser", "Philipp", ""], ["Filli", "Linard", ""], ["Helmchen", "Fritjof", ""], ["Wahl", "Anna-Sophia", ""], ["Ommer", "Bjoern", ""]]}, {"id": "2012.09242", "submitter": "Ran Cheng", "authors": "Ran Cheng, Christopher Agia, Yuan Ren, Xinhai Li, Liu Bingbing", "title": "S3CNet: A Sparse Semantic Scene Completion Network for LiDAR Point\n  Clouds", "comments": "14 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.RO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  With the increasing reliance of self-driving and similar robotic systems on\nrobust 3D vision, the processing of LiDAR scans with deep convolutional neural\nnetworks has become a trend in academia and industry alike. Prior attempts on\nthe challenging Semantic Scene Completion task - which entails the inference of\ndense 3D structure and associated semantic labels from \"sparse\" representations\n- have been, to a degree, successful in small indoor scenes when provided with\ndense point clouds or dense depth maps often fused with semantic segmentation\nmaps from RGB images. However, the performance of these systems drop\ndrastically when applied to large outdoor scenes characterized by dynamic and\nexponentially sparser conditions. Likewise, processing of the entire sparse\nvolume becomes infeasible due to memory limitations and workarounds introduce\ncomputational inefficiency as practitioners are forced to divide the overall\nvolume into multiple equal segments and infer on each individually, rendering\nreal-time performance impossible. In this work, we formulate a method that\nsubsumes the sparsity of large-scale environments and present S3CNet, a sparse\nconvolution based neural network that predicts the semantically completed scene\nfrom a single, unified LiDAR point cloud. We show that our proposed method\noutperforms all counterparts on the 3D task, achieving state-of-the art results\non the SemanticKITTI benchmark. Furthermore, we propose a 2D variant of S3CNet\nwith a multi-view fusion strategy to complement our 3D network, providing\nrobustness to occlusions and extreme sparsity in distant regions. We conduct\nexperiments for the 2D semantic scene completion task and compare the results\nof our sparse 2D network against several leading LiDAR segmentation models\nadapted for bird's eye view segmentation on two open-source datasets.\n", "versions": [{"version": "v1", "created": "Wed, 16 Dec 2020 20:14:41 GMT"}], "update_date": "2020-12-18", "authors_parsed": [["Cheng", "Ran", ""], ["Agia", "Christopher", ""], ["Ren", "Yuan", ""], ["Li", "Xinhai", ""], ["Bingbing", "Liu", ""]]}, {"id": "2012.09243", "submitter": "Huan Wang", "authors": "Huan Wang, Can Qin, Yulun Zhang, Yun Fu", "title": "Neural Pruning via Growing Regularization", "comments": "Accepted by ICLR 2021", "journal-ref": "International Conference on Learning Representations (ICLR) 2021", "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Regularization has long been utilized to learn sparsity in deep neural\nnetwork pruning. However, its role is mainly explored in the small penalty\nstrength regime. In this work, we extend its application to a new scenario\nwhere the regularization grows large gradually to tackle two central problems\nof pruning: pruning schedule and weight importance scoring. (1) The former\ntopic is newly brought up in this work, which we find critical to the pruning\nperformance while receives little research attention. Specifically, we propose\nan L2 regularization variant with rising penalty factors and show it can bring\nsignificant accuracy gains compared with its one-shot counterpart, even when\nthe same weights are removed. (2) The growing penalty scheme also brings us an\napproach to exploit the Hessian information for more accurate pruning without\nknowing their specific values, thus not bothered by the common Hessian\napproximation problems. Empirically, the proposed algorithms are easy to\nimplement and scalable to large datasets and networks in both structured and\nunstructured pruning. Their effectiveness is demonstrated with modern deep\nneural networks on the CIFAR and ImageNet datasets, achieving competitive\nresults compared to many state-of-the-art algorithms. Our code and trained\nmodels are publicly available at\nhttps://github.com/mingsuntse/regularization-pruning.\n", "versions": [{"version": "v1", "created": "Wed, 16 Dec 2020 20:16:28 GMT"}, {"version": "v2", "created": "Mon, 5 Apr 2021 19:37:45 GMT"}], "update_date": "2021-04-07", "authors_parsed": [["Wang", "Huan", ""], ["Qin", "Can", ""], ["Zhang", "Yulun", ""], ["Fu", "Yun", ""]]}, {"id": "2012.09274", "submitter": "Stylianos Loukas Vasileiou", "authors": "Stylianos Loukas Vasileiou, Alessandro Previti, William Yeoh", "title": "On Exploiting Hitting Sets for Model Reconciliation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In human-aware planning, a planning agent may need to provide an explanation\nto a human user on why its plan is optimal. A popular approach to do this is\ncalled model reconciliation, where the agent tries to reconcile the differences\nin its model and the human's model such that the plan is also optimal in the\nhuman's model. In this paper, we present a logic-based framework for model\nreconciliation that extends beyond the realm of planning. More specifically,\ngiven a knowledge base $KB_1$ entailing a formula $\\varphi$ and a second\nknowledge base $KB_2$ not entailing it, model reconciliation seeks an\nexplanation, in the form of a cardinality-minimal subset of $KB_1$, whose\nintegration into $KB_2$ makes the entailment possible. Our approach, based on\nideas originating in the context of analysis of inconsistencies, exploits the\nexisting hitting set duality between minimal correction sets (MCSes) and\nminimal unsatisfiable sets (MUSes) in order to identify an appropriate\nexplanation. However, differently from those works targeting inconsistent\nformulas, which assume a single knowledge base, MCSes and MUSes are computed\nover two distinct knowledge bases. We conclude our paper with an empirical\nevaluation of the newly introduced approach on planning instances, where we\nshow how it outperforms an existing state-of-the-art solver, and generic\nnon-planning instances from recent SAT competitions, for which no other solver\nexists.\n", "versions": [{"version": "v1", "created": "Wed, 16 Dec 2020 21:25:53 GMT"}, {"version": "v2", "created": "Mon, 8 Mar 2021 23:19:36 GMT"}], "update_date": "2021-03-10", "authors_parsed": [["Vasileiou", "Stylianos Loukas", ""], ["Previti", "Alessandro", ""], ["Yeoh", "William", ""]]}, {"id": "2012.09276", "submitter": "Marc-Andr\\'e Carbonneau", "authors": "Julian Zaidi, Jonathan Boilard, Ghyslain Gagnon, Marc-Andr\\'e\n  Carbonneau", "title": "Measuring Disentanglement: A Review of Metrics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Learning to disentangle and represent factors of variation in data is an\nimportant problem in AI. While many advances are made to learn these\nrepresentations, it is still unclear how to quantify disentanglement. Several\nmetrics exist, however little is known on their implicit assumptions, what they\ntruly measure and their limits. As a result, it is difficult to interpret\nresults when comparing different representations. In this work, we survey\nsupervised disentanglement metrics and thoroughly analyze them. We propose a\nnew taxonomy in which all metrics fall into one of three families:\nintervention-based, predictor-based and information-based. We conduct extensive\nexperiments, where we isolate representation properties to compare all metrics\non many aspects. From experiment results and analysis, we provide insights on\nrelations between disentangled representation properties. Finally, we provide\nguidelines on how to measure disentanglement and report the results.\n", "versions": [{"version": "v1", "created": "Wed, 16 Dec 2020 21:28:25 GMT"}, {"version": "v2", "created": "Tue, 5 Jan 2021 22:37:16 GMT"}], "update_date": "2021-01-07", "authors_parsed": [["Zaidi", "Julian", ""], ["Boilard", "Jonathan", ""], ["Gagnon", "Ghyslain", ""], ["Carbonneau", "Marc-Andr\u00e9", ""]]}, {"id": "2012.09303", "submitter": "William D. Gropp", "authors": "William Gropp, Sujata Banerjee, and Ian Foster", "title": "Infrastructure for Artificial Intelligence, Quantum and High Performance\n  Computing", "comments": "A Computing Community Consortium (CCC) white paper, 3 pages", "journal-ref": null, "doi": null, "report-no": "ccc2020whitepaper_11", "categories": "cs.CY cs.AI cs.PF", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  High Performance Computing (HPC), Artificial Intelligence (AI)/Machine\nLearning (ML), and Quantum Computing (QC) and communications offer immense\nopportunities for innovation and impact on society. Researchers in these areas\ndepend on access to computing infrastructure, but these resources are in short\nsupply and are typically siloed in support of their research communities,\nmaking it more difficult to pursue convergent and interdisciplinary research.\nSuch research increasingly depends on complex workflows that require different\nresources for each stage. This paper argues that a more-holistic approach to\ncomputing infrastructure, one that recognizes both the convergence of some\ncapabilities and the complementary capabilities from new computing approaches,\nbe it commercial cloud to Quantum Computing, is needed to support computer\nscience research.\n", "versions": [{"version": "v1", "created": "Wed, 16 Dec 2020 22:41:24 GMT"}], "update_date": "2020-12-18", "authors_parsed": [["Gropp", "William", ""], ["Banerjee", "Sujata", ""], ["Foster", "Ian", ""]]}, {"id": "2012.09318", "submitter": "Daniel Elton", "authors": "Daniel C. Elton", "title": "Applying Deutsch's concept of good explanations to artificial\n  intelligence and neuroscience -- an initial exploration", "comments": "Accepted for a talk at BICA 2020 and for publication in Cognitive\n  Systems Research", "journal-ref": null, "doi": "10.1016/j.cogsys.2020.12.002", "report-no": null, "categories": "cs.AI cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Artificial intelligence has made great strides since the deep learning\nrevolution, but AI systems still struggle to extrapolate outside of their\ntraining data and adapt to new situations. For inspiration we look to the\ndomain of science, where scientists have been able to develop theories which\nshow remarkable ability to extrapolate and sometimes predict the existence of\nphenomena which have never been observed before. According to David Deutsch,\nthis type of extrapolation, which he calls \"reach\", is due to scientific\ntheories being hard to vary. In this work we investigate Deutsch's hard-to-vary\nprinciple and how it relates to more formalized principles in deep learning\nsuch as the bias-variance trade-off and Occam's razor. We distinguish internal\nvariability, how much a model/theory can be varied internally while still\nyielding the same predictions, with external variability, which is how much a\nmodel must be varied to accurately predict new, out-of-distribution data. We\ndiscuss how to measure internal variability using the size of the Rashomon set\nand how to measure external variability using Kolmogorov complexity. We explore\nwhat role hard-to-vary explanations play in intelligence by looking at the\nhuman brain and distinguish two learning systems in the brain. The first system\noperates similar to deep learning and likely underlies most of perception and\nmotor control while the second is a more creative system capable of generating\nhard-to-vary explanations of the world. We argue that figuring out how\nreplicate this second system, which is capable of generating hard-to-vary\nexplanations, is a key challenge which needs to be solved in order to realize\nartificial general intelligence. We make contact with the framework of\nPopperian epistemology which rejects induction and asserts that knowledge\ngeneration is an evolutionary process which proceeds through conjecture and\nrefutation.\n", "versions": [{"version": "v1", "created": "Wed, 16 Dec 2020 23:23:22 GMT"}, {"version": "v2", "created": "Thu, 24 Dec 2020 23:06:46 GMT"}], "update_date": "2020-12-29", "authors_parsed": [["Elton", "Daniel C.", ""]]}, {"id": "2012.09324", "submitter": "Wenbo Hu", "authors": "Qingyi Pan, Wenbo Hu, Jun Zhu", "title": "Series Saliency: Temporal Interpretation for Multivariate Time Series\n  Forecasting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Time series forecasting is an important yet challenging task. Though deep\nlearning methods have recently been developed to give superior forecasting\nresults, it is crucial to improve the interpretability of time series models.\nPrevious interpretation methods, including the methods for general neural\nnetworks and attention-based methods, mainly consider the interpretation in the\nfeature dimension while ignoring the crucial temporal dimension. In this paper,\nwe present the series saliency framework for temporal interpretation for\nmultivariate time series forecasting, which considers the forecasting\ninterpretation in both feature and temporal dimensions. By extracting the\n\"series images\" from the sliding windows of the time series, we apply the\nsaliency map segmentation following the smallest destroying region principle.\nThe series saliency framework can be employed to any well-defined deep learning\nmodels and works as a data augmentation to get more accurate forecasts.\nExperimental results on several real datasets demonstrate that our framework\ngenerates temporal interpretations for the time series forecasting task while\nproduces accurate time series forecast.\n", "versions": [{"version": "v1", "created": "Wed, 16 Dec 2020 23:48:00 GMT"}], "update_date": "2020-12-18", "authors_parsed": [["Pan", "Qingyi", ""], ["Hu", "Wenbo", ""], ["Zhu", "Jun", ""]]}, {"id": "2012.09332", "submitter": "Tunazzina Islam", "authors": "Tunazzina Islam, Dan Goldwasser", "title": "Do You Do Yoga? Understanding Twitter Users' Types and Motivations using\n  Social and Textual Information", "comments": "accepted at 2021 IEEE 15th International Conference on Semantic\n  Computing (ICSC), 4 pages. Minor changes for camera-ready version. arXiv\n  admin note: text overlap with arXiv:2012.02939", "journal-ref": null, "doi": "10.1109/ICSC50631.2021.00067", "report-no": null, "categories": "cs.CL cs.AI cs.CY cs.LG cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Leveraging social media data to understand people's lifestyle choices is an\nexciting domain to explore but requires a multiview formulation of the data. In\nthis paper, we propose a joint embedding model based on the fusion of neural\nnetworks with attention mechanism by incorporating social and textual\ninformation of users to understand their activities and motivations. We use\nwell-being related tweets from Twitter, focusing on 'Yoga'. We demonstrate our\nmodel on two downstream tasks: (i) finding user type such as either\npractitioner or promotional (promoting yoga studio/gym), other; (ii) finding\nuser motivation i.e. health benefit, spirituality, love to tweet/retweet about\nyoga but do not practice yoga.\n", "versions": [{"version": "v1", "created": "Thu, 17 Dec 2020 00:15:13 GMT"}, {"version": "v2", "created": "Fri, 18 Dec 2020 05:20:56 GMT"}, {"version": "v3", "created": "Wed, 27 Jan 2021 15:50:42 GMT"}], "update_date": "2021-04-19", "authors_parsed": [["Islam", "Tunazzina", ""], ["Goldwasser", "Dan", ""]]}, {"id": "2012.09369", "submitter": "Ravi Sharma", "authors": "Ravi Sharma, Sri Divya Pagadala, Pratool Bharti, Sriram Chellappan,\n  Trine Schmidt and Raj Goyal", "title": "Assessing COVID-19 Impacts on College Students via Automated Processing\n  of Free-form Text", "comments": "8 pages, 5 figures, HEALTHINF - 14th International Conference on\n  Health Informatics", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we report experimental results on assessing the impact of\nCOVID-19 on college students by processing free-form texts generated by them.\nBy free-form texts, we mean textual entries posted by college students\n(enrolled in a four year US college) via an app specifically designed to assess\nand improve their mental health. Using a dataset comprising of more than 9000\ntextual entries from 1451 students collected over four months (split between\npre and post COVID-19), and established NLP techniques, a) we assess how topics\nof most interest to student change between pre and post COVID-19, and b) we\nassess the sentiments that students exhibit in each topic between pre and post\nCOVID-19. Our analysis reveals that topics like Education became noticeably\nless important to students post COVID-19, while Health became much more\ntrending. We also found that across all topics, negative sentiment among\nstudents post COVID-19 was much higher compared to pre-COVID-19. We expect our\nstudy to have an impact on policy-makers in higher education across several\nspectra, including college administrators, teachers, parents, and mental health\ncounselors.\n", "versions": [{"version": "v1", "created": "Thu, 17 Dec 2020 02:46:48 GMT"}], "update_date": "2020-12-18", "authors_parsed": [["Sharma", "Ravi", ""], ["Pagadala", "Sri Divya", ""], ["Bharti", "Pratool", ""], ["Chellappan", "Sriram", ""], ["Schmidt", "Trine", ""], ["Goyal", "Raj", ""]]}, {"id": "2012.09390", "submitter": "Edward Raff", "authors": "Edward Raff, William Fleshman, Richard Zak, Hyrum S. Anderson, Bobby\n  Filar, Mark McLean", "title": "Classifying Sequences of Extreme Length with Constant Memory Applied to\n  Malware Detection", "comments": "To appear in AAAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent works within machine learning have been tackling inputs of\never-increasing size, with cybersecurity presenting sequence classification\nproblems of particularly extreme lengths. In the case of Windows executable\nmalware detection, inputs may exceed $100$ MB, which corresponds to a time\nseries with $T=100,000,000$ steps. To date, the closest approach to handling\nsuch a task is MalConv, a convolutional neural network capable of processing up\nto $T=2,000,000$ steps. The $\\mathcal{O}(T)$ memory of CNNs has prevented\nfurther application of CNNs to malware. In this work, we develop a new approach\nto temporal max pooling that makes the required memory invariant to the\nsequence length $T$. This makes MalConv $116\\times$ more memory efficient, and\nup to $25.8\\times$ faster to train on its original dataset, while removing the\ninput length restrictions to MalConv. We re-invest these gains into improving\nthe MalConv architecture by developing a new Global Channel Gating design,\ngiving us an attention mechanism capable of learning feature interactions\nacross 100 million time steps in an efficient manner, a capability lacked by\nthe original MalConv CNN. Our implementation can be found at\nhttps://github.com/NeuromorphicComputationResearchProgram/MalConv2\n", "versions": [{"version": "v1", "created": "Thu, 17 Dec 2020 04:45:33 GMT"}], "update_date": "2020-12-18", "authors_parsed": [["Raff", "Edward", ""], ["Fleshman", "William", ""], ["Zak", "Richard", ""], ["Anderson", "Hyrum S.", ""], ["Filar", "Bobby", ""], ["McLean", "Mark", ""]]}, {"id": "2012.09421", "submitter": "Matthieu Zimmer", "authors": "Matthieu Zimmer, Claire Glanois, Umer Siddique, Paul Weng", "title": "Learning Fair Policies in Decentralized Cooperative Multi-Agent\n  Reinforcement Learning", "comments": "International Conference on Machine Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of learning fair policies in (deep) cooperative\nmulti-agent reinforcement learning (MARL). We formalize it in a principled way\nas the problem of optimizing a welfare function that explicitly encodes two\nimportant aspects of fairness: efficiency and equity. As a solution method, we\npropose a novel neural network architecture, which is composed of two\nsub-networks specifically designed for taking into account the two aspects of\nfairness. In experiments, we demonstrate the importance of the two sub-networks\nfor fair optimization. Our overall approach is general as it can accommodate\nany (sub)differentiable welfare function. Therefore, it is compatible with\nvarious notions of fairness that have been proposed in the literature (e.g.,\nlexicographic maximin, generalized Gini social welfare function, proportional\nfairness). Our solution method is generic and can be implemented in various\nMARL settings: centralized training and decentralized execution, or fully\ndecentralized. Finally, we experimentally validate our approach in various\ndomains and show that it can perform much better than previous methods.\n", "versions": [{"version": "v1", "created": "Thu, 17 Dec 2020 07:17:36 GMT"}, {"version": "v2", "created": "Mon, 1 Mar 2021 05:32:23 GMT"}, {"version": "v3", "created": "Wed, 16 Jun 2021 06:40:20 GMT"}, {"version": "v4", "created": "Tue, 22 Jun 2021 07:20:24 GMT"}], "update_date": "2021-06-23", "authors_parsed": [["Zimmer", "Matthieu", ""], ["Glanois", "Claire", ""], ["Siddique", "Umer", ""], ["Weng", "Paul", ""]]}, {"id": "2012.09424", "submitter": "Zelong Yang", "authors": "Zelong Yang, Yan Wang, Piji Li, Shaobin Lin, Shuming Shi, Shao-Lun\n  Huang", "title": "Predicting Events in MOBA Games: Dataset, Attribution, and Evaluation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The multiplayer online battle arena (MOBA) games have become increasingly\npopular in recent years. Consequently, many efforts have been devoted to\nproviding pre-game or in-game predictions for them. However, these works are\nlimited in the following two aspects: 1) the lack of sufficient in-game\nfeatures; 2) the absence of interpretability in the prediction results. These\ntwo limitations greatly restrict the practical performance and industrial\napplication of the current works. In this work, we collect and release a\nlarge-scale dataset containing rich in-game features for the popular MOBA game\nHonor of Kings. We then propose to predict four types of important events in an\ninterpretable way by attributing the predictions to the input features using\ntwo gradient-based attribution methods: Integrated Gradients and SmoothGrad. To\nevaluate the explanatory power of different models and attribution methods, a\nfidelity-based evaluation metric is further proposed. Finally, we evaluate the\naccuracy and Fidelity of several competitive methods on the collected dataset\nto assess how well machines predict events in MOBA games.\n", "versions": [{"version": "v1", "created": "Thu, 17 Dec 2020 07:28:35 GMT"}, {"version": "v2", "created": "Wed, 23 Dec 2020 07:42:51 GMT"}, {"version": "v3", "created": "Thu, 24 Dec 2020 07:47:19 GMT"}], "update_date": "2020-12-25", "authors_parsed": [["Yang", "Zelong", ""], ["Wang", "Yan", ""], ["Li", "Piji", ""], ["Lin", "Shaobin", ""], ["Shi", "Shuming", ""], ["Huang", "Shao-Lun", ""]]}, {"id": "2012.09432", "submitter": "Sanjaya Lohani", "authors": "Sanjaya Lohani, Thomas A. Searles, Brian T. Kirby, and Ryan T. Glasser", "title": "On the experimental feasibility of quantum state reconstruction via\n  machine learning", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We determine the resource scaling of machine learning-based quantum state\nreconstruction methods, in terms of inference and training, for systems of up\nto four qubits when constrained to pure states. Further, we examine system\nperformance in the low-count regime, likely to be encountered in the tomography\nof high-dimensional systems. Finally, we implement our quantum state\nreconstruction method on an IBM Q quantum computer, and compare against both\nunconstrained and constrained MLE state reconstruction.\n", "versions": [{"version": "v1", "created": "Thu, 17 Dec 2020 07:51:47 GMT"}, {"version": "v2", "created": "Wed, 2 Jun 2021 03:36:43 GMT"}], "update_date": "2021-06-03", "authors_parsed": [["Lohani", "Sanjaya", ""], ["Searles", "Thomas A.", ""], ["Kirby", "Brian T.", ""], ["Glasser", "Ryan T.", ""]]}, {"id": "2012.09433", "submitter": "Ashish Kapoor", "authors": "Ashish Kapoor", "title": "Helping Reduce Environmental Impact of Aviation with Machine Learning", "comments": "Appeared in NeurIPS 2019 Workshop Tackling Climate Change with\n  Machine Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CY cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Commercial aviation is one of the biggest contributors towards climate\nchange. We propose to reduce environmental impact of aviation by considering\nsolutions that would reduce the flight time. Specifically, we first consider\nimproving winds aloft forecast so that flight planners could use better\ninformation to find routes that are efficient. Secondly, we propose an aircraft\nrouting method that seeks to find the fastest route to the destination by\nconsidering uncertainty in the wind forecasts and then optimally trading-off\nbetween exploration and exploitation.\n", "versions": [{"version": "v1", "created": "Thu, 17 Dec 2020 08:04:22 GMT"}], "update_date": "2020-12-18", "authors_parsed": [["Kapoor", "Ashish", ""]]}, {"id": "2012.09446", "submitter": "Patrick Huber", "authors": "Patrick Huber and Giuseppe Carenini", "title": "Unsupervised Learning of Discourse Structures using a Tree Autoencoder", "comments": "Accepted to AAAI 2021, 7 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Discourse information, as postulated by popular discourse theories, such as\nRST and PDTB, has been shown to improve an increasing number of downstream NLP\ntasks, showing positive effects and synergies of discourse with important\nreal-world applications. While methods for incorporating discourse become more\nand more sophisticated, the growing need for robust and general discourse\nstructures has not been sufficiently met by current discourse parsers, usually\ntrained on small scale datasets in a strictly limited number of domains. This\nmakes the prediction for arbitrary tasks noisy and unreliable. The overall\nresulting lack of high-quality, high-quantity discourse trees poses a severe\nlimitation to further progress. In order the alleviate this shortcoming, we\npropose a new strategy to generate tree structures in a task-agnostic,\nunsupervised fashion by extending a latent tree induction framework with an\nauto-encoding objective. The proposed approach can be applied to any\ntree-structured objective, such as syntactic parsing, discourse parsing and\nothers. However, due to the especially difficult annotation process to generate\ndiscourse trees, we initially develop a method to generate larger and more\ndiverse discourse treebanks. In this paper we are inferring general tree\nstructures of natural text in multiple domains, showing promising results on a\ndiverse set of tasks.\n", "versions": [{"version": "v1", "created": "Thu, 17 Dec 2020 08:40:34 GMT"}], "update_date": "2020-12-18", "authors_parsed": [["Huber", "Patrick", ""], ["Carenini", "Giuseppe", ""]]}, {"id": "2012.09451", "submitter": "Mingyu Xiao", "authors": "Zhenyu Guo, Mingyu Xiao, Yi Zhou, Dongxiang Zhang, Kian-Lee Tan", "title": "Enhancing Balanced Graph Edge Partition with Effective Local Search", "comments": "To appear in AAAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.AI", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Graph partition is a key component to achieve workload balance and reduce job\ncompletion time in parallel graph processing systems. Among the various\npartition strategies, edge partition has demonstrated more promising\nperformance in power-law graphs than vertex partition and thereby has been more\nwidely adopted as the default partition strategy by existing graph systems. The\ngraph edge partition problem, which is to split the edge set into multiple\nbalanced parts to minimize the total number of copied vertices, has been widely\nstudied from the view of optimization and algorithms. In this paper, we study\nlocal search algorithms for this problem to further improve the partition\nresults from existing methods. More specifically, we propose two novel\nconcepts, namely adjustable edges and blocks. Based on these, we develop a\ngreedy heuristic as well as an improved search algorithm utilizing the property\nof the max-flow model. To evaluate the performance of our algorithms, we first\nprovide adequate theoretical analysis in terms of the approximation quality. We\nsignificantly improve the previously known approximation ratio for this\nproblem. Then we conduct extensive experiments on a large number of benchmark\ndatasets and state-of-the-art edge partition strategies. The results show that\nour proposed local search framework can further improve the quality of graph\npartition by a wide margin.\n", "versions": [{"version": "v1", "created": "Thu, 17 Dec 2020 08:58:06 GMT"}], "update_date": "2020-12-18", "authors_parsed": [["Guo", "Zhenyu", ""], ["Xiao", "Mingyu", ""], ["Zhou", "Yi", ""], ["Zhang", "Dongxiang", ""], ["Tan", "Kian-Lee", ""]]}, {"id": "2012.09466", "submitter": "Minglun Han", "authors": "Minglun Han and Linhao Dong and Shiyu Zhou and Bo Xu", "title": "CIF-based Collaborative Decoding for End-to-end Contextual Speech\n  Recognition", "comments": "Accepted by ICASSP 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  End-to-end (E2E) models have achieved promising results on multiple speech\nrecognition benchmarks, and shown the potential to become the mainstream.\nHowever, the unified structure and the E2E training hamper injecting contextual\ninformation into them for contextual biasing. Though contextual LAS (CLAS)\ngives an excellent all-neural solution, the degree of biasing to given context\ninformation is not explicitly controllable. In this paper, we focus on\nincorporating context information into the continuous integrate-and-fire (CIF)\nbased model that supports contextual biasing in a more controllable fashion.\nSpecifically, an extra context processing network is introduced to extract\ncontextual embeddings, integrate acoustically relevant context information and\ndecode the contextual output distribution, thus forming a collaborative\ndecoding with the decoder of the CIF-based model. Evaluated on the named entity\nrich evaluation sets of HKUST/AISHELL-2, our method brings relative character\nerror rate (CER) reduction of 8.83%/21.13% and relative named entity character\nerror rate (NE-CER) reduction of 40.14%/51.50% when compared with a strong\nbaseline. Besides, it keeps the performance on original evaluation set without\ndegradation.\n", "versions": [{"version": "v1", "created": "Thu, 17 Dec 2020 09:40:11 GMT"}, {"version": "v2", "created": "Thu, 18 Feb 2021 07:42:44 GMT"}], "update_date": "2021-02-19", "authors_parsed": [["Han", "Minglun", ""], ["Dong", "Linhao", ""], ["Zhou", "Shiyu", ""], ["Xu", "Bo", ""]]}, {"id": "2012.09477", "submitter": "Abel Torres-Montoya", "authors": "Abel Torres Montoya", "title": "Computational principles of intelligence: learning and reasoning with\n  neural networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Despite significant achievements and current interest in machine learning and\nartificial intelligence, the quest for a theory of intelligence, allowing\ngeneral and efficient problem solving, has done little progress. This work\ntries to contribute in this direction by proposing a novel framework of\nintelligence based on three principles. First, the generative and mirroring\nnature of learned representations of inputs. Second, a grounded, intrinsically\nmotivated and iterative process for learning, problem solving and imagination.\nThird, an ad hoc tuning of the reasoning mechanism over causal compositional\nrepresentations using inhibition rules. Together, those principles create a\nsystems approach offering interpretability, continuous learning, common sense\nand more. This framework is being developed from the following perspectives: as\na general problem solving method, as a human oriented tool and finally, as\nmodel of information processing in the brain.\n", "versions": [{"version": "v1", "created": "Thu, 17 Dec 2020 10:03:26 GMT"}], "update_date": "2020-12-18", "authors_parsed": [["Montoya", "Abel Torres", ""]]}, {"id": "2012.09508", "submitter": "Tahar Nabil", "authors": "Adrien Le-Coz, Tahar Nabil, Francois Courtot", "title": "Towards Optimal District Heating Temperature Control in China with Deep\n  Reinforcement Learning", "comments": "Accepted at NeurIPS 2020 Workshop Tackling Climate Change with\n  Machine Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.AI cs.LG cs.SY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Achieving efficiency gains in Chinese district heating networks, thereby\nreducing their carbon footprint, requires new optimal control methods going\nbeyond current industry tools. Focusing on the secondary network, we propose a\ndata-driven deep reinforcement learning (DRL) approach to address this task. We\nbuild a recurrent neural network, trained on simulated data, to predict the\nindoor temperatures. This model is then used to train two DRL agents, with or\nwithout expert guidance, for the optimal control of the supply water\ntemperature. Our tests in a multi-apartment setting show that both agents can\nensure a higher thermal comfort and at the same time a smaller energy cost,\ncompared to an optimized baseline strategy.\n", "versions": [{"version": "v1", "created": "Thu, 17 Dec 2020 11:16:08 GMT"}, {"version": "v2", "created": "Fri, 18 Dec 2020 02:17:15 GMT"}], "update_date": "2020-12-21", "authors_parsed": [["Le-Coz", "Adrien", ""], ["Nabil", "Tahar", ""], ["Courtot", "Francois", ""]]}, {"id": "2012.09542", "submitter": "Novanto Yudistira", "authors": "Novanto Yudistira, Muthu Subash Kavitha, Takio Kurita", "title": "Weakly-Supervised Action Localization and Action Recognition using\n  Global-Local Attention of 3D CNN", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  3D Convolutional Neural Network (3D CNN) captures spatial and temporal\ninformation on 3D data such as video sequences. However, due to the convolution\nand pooling mechanism, the information loss seems unavoidable. To improve the\nvisual explanations and classification in 3D CNN, we propose two approaches; i)\naggregate layer-wise global to local (global-local) discrete gradients using\ntrained 3DResNext network, and ii) implement attention gating network to\nimprove the accuracy of the action recognition. The proposed approach intends\nto show the usefulness of every layer termed as global-local attention in 3D\nCNN via visual attribution, weakly-supervised action localization, and action\nrecognition. Firstly, the 3DResNext is trained and applied for action\nclassification using backpropagation concerning the maximum predicted class.\nThe gradients and activations of every layer are then up-sampled. Later,\naggregation is used to produce more nuanced attention, which points out the\nmost critical part of the predicted class's input videos. We use contour\nthresholding of final attention for final localization. We evaluate spatial and\ntemporal action localization in trimmed videos using fine-grained visual\nexplanation via 3DCam. Experimental results show that the proposed approach\nproduces informative visual explanations and discriminative attention.\nFurthermore, the action recognition via attention gating on each layer produces\nbetter classification results than the baseline model.\n", "versions": [{"version": "v1", "created": "Thu, 17 Dec 2020 12:29:16 GMT"}], "update_date": "2020-12-18", "authors_parsed": [["Yudistira", "Novanto", ""], ["Kavitha", "Muthu Subash", ""], ["Kurita", "Takio", ""]]}, {"id": "2012.09575", "submitter": "Rafael Peres Da Silva", "authors": "Rafael Peres da Silva, Chayaporn Suphavilai, Niranjan Nagarajan", "title": "Task Uncertainty Loss Reduce Negative Transfer in Asymmetric Multi-task\n  Feature Learning", "comments": "Accepted in AAAI 2021 Student Abstract and Poster Program", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI q-bio.GN", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Multi-task learning (MTL) is frequently used in settings where a target task\nhas to be learnt based on limited training data, but knowledge can be leveraged\nfrom related auxiliary tasks. While MTL can improve task performance overall\nrelative to single-task learning (STL), these improvements can hide negative\ntransfer (NT), where STL may deliver better performance for many individual\ntasks. Asymmetric multitask feature learning (AMTFL) is an approach that tries\nto address this by allowing tasks with higher loss values to have smaller\ninfluence on feature representations for learning other tasks. Task loss values\ndo not necessarily indicate reliability of models for a specific task. We\npresent examples of NT in two orthogonal datasets (image recognition and\npharmacogenomics) and tackle this challenge by using aleatoric homoscedastic\nuncertainty to capture the relative confidence between tasks, and set weights\nfor task loss. Our results show that this approach reduces NT providing a new\napproach to enable robust MTL.\n", "versions": [{"version": "v1", "created": "Thu, 17 Dec 2020 13:30:45 GMT"}], "update_date": "2020-12-18", "authors_parsed": [["da Silva", "Rafael Peres", ""], ["Suphavilai", "Chayaporn", ""], ["Nagarajan", "Niranjan", ""]]}, {"id": "2012.09608", "submitter": "Tapan Shah Mr", "authors": "Meinolf Sellmann and Tapan Shah", "title": "Cost-sensitive Hierarchical Clustering for Dynamic Classifier Selection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We consider the dynamic classifier selection (DCS) problem: Given an ensemble\nof classifiers, we are to choose which classifier to use depending on the\nparticular input vector that we get to classify. The problem is a special case\nof the general algorithm selection problem where we have multiple different\nalgorithms we can employ to process a given input. We investigate if a method\ndeveloped for general algorithm selection named cost-sensitive hierarchical\nclustering (CSHC) is suited for DCS. We introduce some additions to the\noriginal CSHC method for the special case of choosing a classification\nalgorithm and evaluate their impact on performance. We then compare with a\nnumber of state-of-the-art dynamic classifier selection methods. Our\nexperimental results show that our modified CSHC algorithm compares favorably\n", "versions": [{"version": "v1", "created": "Mon, 14 Dec 2020 18:44:51 GMT"}, {"version": "v2", "created": "Fri, 18 Dec 2020 16:56:07 GMT"}], "update_date": "2020-12-21", "authors_parsed": [["Sellmann", "Meinolf", ""], ["Shah", "Tapan", ""]]}, {"id": "2012.09635", "submitter": "Robert R. Tucci", "authors": "Robert R. Tucci", "title": "Quantum d-separation and quantum belief propagation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The goal of this paper is to generalize classical d-separation and classical\nBelief Propagation (BP) to the quantum realm. Classical d-separation is an\nessential ingredient of most of Judea Pearl's work. It is crucial to all 3\nrungs of what Pearl calls the 3 rungs of Causation. So having a quantum version\nof d-separation and BP probably implies that most of Pearl's Bayesian networks\nwork, including his theory of causality, can be translated in a straightforward\nmanner to the quantum realm.\n", "versions": [{"version": "v1", "created": "Tue, 15 Dec 2020 21:19:34 GMT"}], "update_date": "2020-12-18", "authors_parsed": [["Tucci", "Robert R.", ""]]}, {"id": "2012.09636", "submitter": "Nazanin Fouladgar", "authors": "Nazanin Fouladgar and Kary Fr\\\"amling", "title": "XAI-P-T: A Brief Review of Explainable Artificial Intelligence from\n  Practice to Theory", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this work, we report the practical and theoretical aspects of Explainable\nAI (XAI) identified in some fundamental literature. Although there is a vast\nbody of work on representing the XAI backgrounds, most of the corpuses pinpoint\na discrete direction of thoughts. Providing insights into literature in\npractice and theory concurrently is still a gap in this field. This is\nimportant as such connection facilitates a learning process for the early stage\nXAI researchers and give a bright stand for the experienced XAI scholars.\nRespectively, we first focus on the categories of black-box explanation and\ngive a practical example. Later, we discuss how theoretically explanation has\nbeen grounded in the body of multidisciplinary fields. Finally, some directions\nof future works are presented.\n", "versions": [{"version": "v1", "created": "Thu, 17 Dec 2020 14:51:08 GMT"}], "update_date": "2020-12-18", "authors_parsed": [["Fouladgar", "Nazanin", ""], ["Fr\u00e4mling", "Kary", ""]]}, {"id": "2012.09641", "submitter": "Mengzhang Li", "authors": "Mengzhang Li, Zhanxing Zhu", "title": "Spatial-Temporal Fusion Graph Neural Networks for Traffic Flow\n  Forecasting", "comments": "8 pages, 3 figures, to be published in AAAI2021. arXiv admin note:\n  text overlap with arXiv:1903.00919 by other authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spatial-temporal data forecasting of traffic flow is a challenging task\nbecause of complicated spatial dependencies and dynamical trends of temporal\npattern between different roads. Existing frameworks typically utilize given\nspatial adjacency graph and sophisticated mechanisms for modeling spatial and\ntemporal correlations. However, limited representations of given spatial graph\nstructure with incomplete adjacent connections may restrict effective\nspatial-temporal dependencies learning of those models. To overcome those\nlimitations, our paper proposes Spatial-Temporal Fusion Graph Neural Networks\n(STFGNN) for traffic flow forecasting. SFTGNN could effectively learn hidden\nspatial-temporal dependencies by a novel fusion operation of various spatial\nand temporal graphs, which is generated by a data-driven method. Meanwhile, by\nintegrating this fusion graph module and a novel gated convolution module into\na unified layer, SFTGNN could handle long sequences. Experimental results on\nseveral public traffic datasets demonstrate that our method achieves\nstate-of-the-art performance consistently than other baselines.\n", "versions": [{"version": "v1", "created": "Tue, 15 Dec 2020 14:03:17 GMT"}, {"version": "v2", "created": "Sat, 6 Mar 2021 08:44:45 GMT"}], "update_date": "2021-03-09", "authors_parsed": [["Li", "Mengzhang", ""], ["Zhu", "Zhanxing", ""]]}, {"id": "2012.09667", "submitter": "Sadique Adnan Siddiqui", "authors": "Sadique Adnan Siddiqui, Axel Vierling and Karsten Berns", "title": "Multi-Modal Depth Estimation Using Convolutional Neural Networks", "comments": "submitted to IEEE International Symposium on Safety, Security, and\n  Rescue Robotics (SSRR)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper addresses the problem of dense depth predictions from sparse\ndistance sensor data and a single camera image on challenging weather\nconditions. This work explores the significance of different sensor modalities\nsuch as camera, Radar, and Lidar for estimating depth by applying Deep Learning\napproaches. Although Lidar has higher depth-sensing abilities than Radar and\nhas been integrated with camera images in lots of previous works, depth\nestimation using CNN's on the fusion of robust Radar distance data and camera\nimages has not been explored much. In this work, a deep regression network is\nproposed utilizing a transfer learning approach consisting of an encoder where\na high performing pre-trained model has been used to initialize it for\nextracting dense features and a decoder for upsampling and predicting desired\ndepth. The results are demonstrated on Nuscenes, KITTI, and a Synthetic dataset\nwhich was created using the CARLA simulator. Also, top-view zoom-camera images\ncaptured from the crane on a construction site are evaluated to estimate the\ndistance of the crane boom carrying heavy loads from the ground to show the\nusability in safety-critical applications.\n", "versions": [{"version": "v1", "created": "Thu, 17 Dec 2020 15:31:49 GMT"}], "update_date": "2020-12-18", "authors_parsed": [["Siddiqui", "Sadique Adnan", ""], ["Vierling", "Axel", ""], ["Berns", "Karsten", ""]]}, {"id": "2012.09670", "submitter": "Christian Schroeder de Witt", "authors": "Christian Schroeder de Witt, Catherine Tong, Valentina Zantedeschi,\n  Daniele De Martini, Freddie Kalaitzis, Matthew Chantry, Duncan Watson-Parris,\n  Piotr Bilinski", "title": "RainBench: Towards Global Precipitation Forecasting from Satellite\n  Imagery", "comments": "Work completed during the 2020 Frontier Development Lab research\n  accelerator, a private-public partnership with NASA in the US, and ESA in\n  Europe. Accepted as a spotlight/long oral talk at both Climate Change and AI,\n  as well as AI for Earth Sciences Workshops at NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI physics.ao-ph", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Extreme precipitation events, such as violent rainfall and hail storms,\nroutinely ravage economies and livelihoods around the developing world. Climate\nchange further aggravates this issue. Data-driven deep learning approaches\ncould widen the access to accurate multi-day forecasts, to mitigate against\nsuch events. However, there is currently no benchmark dataset dedicated to the\nstudy of global precipitation forecasts. In this paper, we introduce\n\\textbf{RainBench}, a new multi-modal benchmark dataset for data-driven\nprecipitation forecasting. It includes simulated satellite data, a selection of\nrelevant meteorological data from the ERA5 reanalysis product, and IMERG\nprecipitation data. We also release \\textbf{PyRain}, a library to process large\nprecipitation datasets efficiently. We present an extensive analysis of our\nnovel dataset and establish baseline results for two benchmark medium-range\nprecipitation forecasting tasks. Finally, we discuss existing data-driven\nweather forecasting methodologies and suggest future research avenues.\n", "versions": [{"version": "v1", "created": "Thu, 17 Dec 2020 15:35:24 GMT"}], "update_date": "2020-12-18", "authors_parsed": [["de Witt", "Christian Schroeder", ""], ["Tong", "Catherine", ""], ["Zantedeschi", "Valentina", ""], ["De Martini", "Daniele", ""], ["Kalaitzis", "Freddie", ""], ["Chantry", "Matthew", ""], ["Watson-Parris", "Duncan", ""], ["Bilinski", "Piotr", ""]]}, {"id": "2012.09679", "submitter": "Marcel Wien\\\"obst", "authors": "Marcel Wien\\\"obst and Max Bannach and Maciej Li\\'skiewicz", "title": "Polynomial-Time Algorithms for Counting and Sampling Markov Equivalent\n  DAGs", "comments": "Extended version of paper accepted to the Proceedings of the 35th\n  AAAI Conference on Artificial Intelligence (AAAI-2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Counting and uniform sampling of directed acyclic graphs (DAGs) from a Markov\nequivalence class are fundamental tasks in graphical causal analysis. In this\npaper, we show that these tasks can be performed in polynomial time, solving a\nlong-standing open problem in this area. Our algorithms are effective and\neasily implementable. Experimental results show that the algorithms\nsignificantly outperform state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Thu, 17 Dec 2020 15:47:15 GMT"}], "update_date": "2020-12-18", "authors_parsed": [["Wien\u00f6bst", "Marcel", ""], ["Bannach", "Max", ""], ["Li\u015bkiewicz", "Maciej", ""]]}, {"id": "2012.09708", "submitter": "Harshit Rampal", "authors": "Harshit Rampal, Aman Mohanty", "title": "Efficient CNN-LSTM based Image Captioning using Neural Network\n  Compression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern Neural Networks are eminent in achieving state of the art performance\non tasks under Computer Vision, Natural Language Processing and related\nverticals. However, they are notorious for their voracious memory and compute\nappetite which further obstructs their deployment on resource limited edge\ndevices. In order to achieve edge deployment, researchers have developed\npruning and quantization algorithms to compress such networks without\ncompromising their efficacy. Such compression algorithms are broadly\nexperimented on standalone CNN and RNN architectures while in this work, we\npresent an unconventional end to end compression pipeline of a CNN-LSTM based\nImage Captioning model. The model is trained using VGG16 or ResNet50 as an\nencoder and an LSTM decoder on the flickr8k dataset. We then examine the\neffects of different compression architectures on the model and design a\ncompression architecture that achieves a 73.1% reduction in model size, 71.3%\nreduction in inference time and a 7.7% increase in BLEU score as compared to\nits uncompressed counterpart.\n", "versions": [{"version": "v1", "created": "Thu, 17 Dec 2020 16:25:09 GMT"}], "update_date": "2020-12-18", "authors_parsed": [["Rampal", "Harshit", ""], ["Mohanty", "Aman", ""]]}, {"id": "2012.09712", "submitter": "Mario Krenn", "authors": "Cynthia Shen, Mario Krenn, Sagi Eppel, Alan Aspuru-Guzik", "title": "Deep Molecular Dreaming: Inverse machine learning for de-novo molecular\n  design and interpretability with surjective representations", "comments": "9 pages, 6 figures; comments welcome", "journal-ref": "Machine Learning: Science and Technology 2, 03LT02 (2021)", "doi": "10.1088/2632-2153/ac09d6", "report-no": null, "categories": "cs.LG cs.AI physics.chem-ph", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Computer-based de-novo design of functional molecules is one of the most\nprominent challenges in cheminformatics today. As a result, generative and\nevolutionary inverse designs from the field of artificial intelligence have\nemerged at a rapid pace, with aims to optimize molecules for a particular\nchemical property. These models 'indirectly' explore the chemical space; by\nlearning latent spaces, policies, distributions or by applying mutations on\npopulations of molecules. However, the recent development of the SELFIES string\nrepresentation of molecules, a surjective alternative to SMILES, have made\npossible other potential techniques. Based on SELFIES, we therefore propose\nPASITHEA, a direct gradient-based molecule optimization that applies\ninceptionism techniques from computer vision. PASITHEA exploits the use of\ngradients by directly reversing the learning process of a neural network, which\nis trained to predict real-valued chemical properties. Effectively, this forms\nan inverse regression model, which is capable of generating molecular variants\noptimized for a certain property. Although our results are preliminary, we\nobserve a shift in distribution of a chosen property during inverse-training, a\nclear indication of PASITHEA's viability. A striking property of inceptionism\nis that we can directly probe the model's understanding of the chemical space\nit was trained on. We expect that extending PASITHEA to larger datasets,\nmolecules and more complex properties will lead to advances in the design of\nnew functional molecules as well as the interpretation and explanation of\nmachine learning models.\n", "versions": [{"version": "v1", "created": "Thu, 17 Dec 2020 16:34:59 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Shen", "Cynthia", ""], ["Krenn", "Mario", ""], ["Eppel", "Sagi", ""], ["Aspuru-Guzik", "Alan", ""]]}, {"id": "2012.09737", "submitter": "Simon Hirlaender", "authors": "Simon Hirlaender, Niky Bruchon", "title": "Model-free and Bayesian Ensembling Model-based Deep Reinforcement\n  Learning for Particle Accelerator Control Demonstrated on the FERMI FEL", "comments": "13 pages, 17 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.SY eess.SY physics.acc-ph", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Reinforcement learning holds tremendous promise in accelerator controls. The\nprimary goal of this paper is to show how this approach can be utilised on an\noperational level on accelerator physics problems. Despite the success of\nmodel-free reinforcement learning in several domains, sample-efficiency still\nis a bottle-neck, which might be encompassed by model-based methods. We compare\nwell-suited purely model-based to model-free reinforcement learning applied to\nthe intensity optimisation on the FERMI FEL system. We find that the\nmodel-based approach demonstrates higher representational power and\nsample-efficiency, while the asymptotic performance of the model-free method is\nslightly superior. The model-based algorithm is implemented in a DYNA-style\nusing an uncertainty aware model, and the model-free algorithm is based on\ntailored deep Q-learning. In both cases, the algorithms were implemented in a\nway, which presents increased noise robustness as omnipresent in accelerator\ncontrol problems. Code is released in\nhttps://github.com/MathPhysSim/FERMI_RL_Paper.\n", "versions": [{"version": "v1", "created": "Thu, 17 Dec 2020 16:57:27 GMT"}], "update_date": "2020-12-18", "authors_parsed": [["Hirlaender", "Simon", ""], ["Bruchon", "Niky", ""]]}, {"id": "2012.09759", "submitter": "Gabriel Istrate", "authors": "Gabriel Istrate", "title": "Game-theoretic Models of Moral and Other-Regarding Agents", "comments": null, "journal-ref": "Proceedings of TARK 2021, the 18th Conference of Theoretical\n  Aspects of Rationality and Knowledge", "doi": null, "report-no": null, "categories": "cs.GT cs.AI cs.MA cs.SI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We investigate Kantian equilibria in finite normal form games, a class of\nnon-Nashian, morally motivated courses of action that was recently proposed in\nthe economics literature. We highlight a number of problems with such\nequilibria, including computational intractability, a high price of\nmiscoordination, and expensive/problematic extension to general normal form\ngames. We point out that such a proper generalization will likely involve the\nconcept of program equilibrium. Finally we propose some general, intuitive,\ncomputationally tractable, other-regarding equilibria related to Kantian\nequilibria, as well as a class of courses of action that interpolates between\npurely self-regarding and Kantian behavior.\n", "versions": [{"version": "v1", "created": "Thu, 17 Dec 2020 17:16:50 GMT"}, {"version": "v2", "created": "Mon, 5 Apr 2021 20:40:50 GMT"}], "update_date": "2021-04-22", "authors_parsed": [["Istrate", "Gabriel", ""]]}, {"id": "2012.09812", "submitter": "Dhruv Shah", "authors": "Dhruv Shah, Benjamin Eysenbach, Gregory Kahn, Nicholas Rhinehart,\n  Sergey Levine", "title": "ViNG: Learning Open-World Navigation with Visual Goals", "comments": "Presented at International Conference on Robotics and Automation\n  (ICRA) 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We propose a learning-based navigation system for reaching visually indicated\ngoals and demonstrate this system on a real mobile robot platform. Learning\nprovides an appealing alternative to conventional methods for robotic\nnavigation: instead of reasoning about environments in terms of geometry and\nmaps, learning can enable a robot to learn about navigational affordances,\nunderstand what types of obstacles are traversable (e.g., tall grass) or not\n(e.g., walls), and generalize over patterns in the environment. However, unlike\nconventional planning algorithms, it is harder to change the goal for a learned\npolicy during deployment. We propose a method for learning to navigate towards\na goal image of the desired destination. By combining a learned policy with a\ntopological graph constructed out of previously observed data, our system can\ndetermine how to reach this visually indicated goal even in the presence of\nvariable appearance and lighting. Three key insights, waypoint proposal, graph\npruning and negative mining, enable our method to learn to navigate in\nreal-world environments using only offline data, a setting where prior methods\nstruggle. We instantiate our method on a real outdoor ground robot and show\nthat our system, which we call ViNG, outperforms previously-proposed methods\nfor goal-conditioned reinforcement learning, including other methods that\nincorporate reinforcement learning and search. We also study how \\sysName\ngeneralizes to unseen environments and evaluate its ability to adapt to such an\nenvironment with growing experience. Finally, we demonstrate ViNG on a number\nof real-world applications, such as last-mile delivery and warehouse\ninspection. We encourage the reader to visit the project website for videos of\nour experiments and demonstrations sites.google.com/view/ving-robot.\n", "versions": [{"version": "v1", "created": "Thu, 17 Dec 2020 18:22:32 GMT"}, {"version": "v2", "created": "Fri, 26 Mar 2021 11:12:28 GMT"}], "update_date": "2021-03-29", "authors_parsed": [["Shah", "Dhruv", ""], ["Eysenbach", "Benjamin", ""], ["Kahn", "Gregory", ""], ["Rhinehart", "Nicholas", ""], ["Levine", "Sergey", ""]]}, {"id": "2012.09823", "submitter": "Magdalena Biesialska", "authors": "Magdalena Biesialska and Katarzyna Biesialska and Marta R.\n  Costa-juss\\`a", "title": "Continual Lifelong Learning in Natural Language Processing: A Survey", "comments": "COLING 2020", "journal-ref": "Proceedings of the 28th International Conference on Computational\n  Linguistics (COLING 2020), Barcelona, Spain (Online), pp. 6523--6541", "doi": "10.18653/v1/2020.coling-main.574", "report-no": null, "categories": "cs.CL cs.AI cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Continual learning (CL) aims to enable information systems to learn from a\ncontinuous data stream across time. However, it is difficult for existing deep\nlearning architectures to learn a new task without largely forgetting\npreviously acquired knowledge. Furthermore, CL is particularly challenging for\nlanguage learning, as natural language is ambiguous: it is discrete,\ncompositional, and its meaning is context-dependent. In this work, we look at\nthe problem of CL through the lens of various NLP tasks. Our survey discusses\nmajor challenges in CL and current methods applied in neural network models. We\nalso provide a critical review of the existing CL evaluation methods and\ndatasets in NLP. Finally, we present our outlook on future research directions.\n", "versions": [{"version": "v1", "created": "Thu, 17 Dec 2020 18:44:36 GMT"}], "update_date": "2021-01-11", "authors_parsed": [["Biesialska", "Magdalena", ""], ["Biesialska", "Katarzyna", ""], ["Costa-juss\u00e0", "Marta R.", ""]]}, {"id": "2012.09830", "submitter": "C\\'edric Colas", "authors": "C\\'edric Colas, Tristan Karch, Olivier Sigaud, Pierre-Yves Oudeyer", "title": "Intrinsically Motivated Goal-Conditioned Reinforcement Learning: a Short\n  Survey", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Building autonomous machines that can explore open-ended environments,\ndiscover possible interactions and autonomously build repertoires of skills is\na general objective of artificial intelligence. Developmental approaches argue\nthat this can only be achieved by autonomous and intrinsically motivated\nlearning agents that can generate, select and learn to solve their own\nproblems. In recent years, we have seen a convergence of developmental\napproaches, and developmental robotics in particular, with deep reinforcement\nlearning (RL) methods, forming the new domain of developmental machine\nlearning. Within this new domain, we review here a set of methods where deep RL\nalgorithms are trained to tackle the developmental robotics problem of the\nautonomous acquisition of open-ended repertoires of skills. Intrinsically\nmotivated goal-conditioned RL algorithms train agents to learn to represent,\ngenerate and pursue their own goals. The self-generation of goals requires the\nlearning of compact goal encodings as well as their associated goal-achievement\nfunctions, which results in new challenges compared to traditional RL\nalgorithms designed to tackle pre-defined sets of goals using external reward\nsignals. This paper proposes a typology of these methods at the intersection of\ndeep RL and developmental approaches, surveys recent approaches and discusses\nfuture avenues.\n", "versions": [{"version": "v1", "created": "Thu, 17 Dec 2020 18:51:40 GMT"}, {"version": "v2", "created": "Tue, 16 Mar 2021 14:50:22 GMT"}, {"version": "v3", "created": "Mon, 19 Jul 2021 14:27:31 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Colas", "C\u00e9dric", ""], ["Karch", "Tristan", ""], ["Sigaud", "Olivier", ""], ["Oudeyer", "Pierre-Yves", ""]]}, {"id": "2012.09849", "submitter": "Iou-Jen Liu", "authors": "Iou-Jen Liu and Raymond A. Yeh and Alexander G. Schwing", "title": "High-Throughput Synchronous Deep RL", "comments": "Accepted to NeurIPS 2020; Project page:\n  https://ioujenliu.github.io/HTS-RL/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep reinforcement learning (RL) is computationally demanding and requires\nprocessing of many data points. Synchronous methods enjoy training stability\nwhile having lower data throughput. In contrast, asynchronous methods achieve\nhigh throughput but suffer from stability issues and lower sample efficiency\ndue to `stale policies.' To combine the advantages of both methods we propose\nHigh-Throughput Synchronous Deep Reinforcement Learning (HTS-RL). In HTS-RL, we\nperform learning and rollouts concurrently, devise a system design which avoids\n`stale policies' and ensure that actors interact with environment replicas in\nan asynchronous manner while maintaining full determinism. We evaluate our\napproach on Atari games and the Google Research Football environment. Compared\nto synchronous baselines, HTS-RL is 2-6$\\times$ faster. Compared to\nstate-of-the-art asynchronous methods, HTS-RL has competitive throughput and\nconsistently achieves higher average episode rewards.\n", "versions": [{"version": "v1", "created": "Thu, 17 Dec 2020 18:59:01 GMT"}], "update_date": "2020-12-18", "authors_parsed": [["Liu", "Iou-Jen", ""], ["Yeh", "Raymond A.", ""], ["Schwing", "Alexander G.", ""]]}, {"id": "2012.09852", "submitter": "Hanrui Wang", "authors": "Hanrui Wang and Zhekai Zhang and Song Han", "title": "SpAtten: Efficient Sparse Attention Architecture with Cascade Token and\n  Head Pruning", "comments": "Published as a conference paper in HPCA 2021; 15 pages, 23 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR cs.AI cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The attention mechanism is becoming increasingly popular in Natural Language\nProcessing (NLP) applications, showing superior performance than convolutional\nand recurrent architectures. However, general-purpose platforms such as CPUs\nand GPUs are inefficient when performing attention inference due to complicated\ndata movement and low arithmetic intensity. Moreover, existing NN accelerators\nmainly focus on optimizing convolutional or recurrent models, and cannot\nefficiently support attention. In this paper, we present SpAtten, an efficient\nalgorithm-architecture co-design that leverages token sparsity, head sparsity,\nand quantization opportunities to reduce the attention computation and memory\naccess. Inspired by the high redundancy of human languages, we propose the\nnovel cascade token pruning to prune away unimportant tokens in the sentence.\nWe also propose cascade head pruning to remove unessential heads. Cascade\npruning is fundamentally different from weight pruning since there is no\ntrainable weight in the attention mechanism, and the pruned tokens and heads\nare selected on the fly. To efficiently support them on hardware, we design a\nnovel top-k engine to rank token and head importance scores with high\nthroughput. Furthermore, we propose progressive quantization that first fetches\nMSBs only and performs the computation; if the confidence is low, it fetches\nLSBs and recomputes the attention outputs, trading computation for memory\nreduction.\n  Extensive experiments on 30 benchmarks show that, on average, SpAtten reduces\nDRAM access by 10.0x with no accuracy loss, and achieves 1.6x, 3.0x, 162x, 347x\nspeedup, and 1,4x, 3.2x, 1193x, 4059x energy savings over A3 accelerator,\nMNNFast accelerator, TITAN Xp GPU, Xeon CPU, respectively.\n", "versions": [{"version": "v1", "created": "Thu, 17 Dec 2020 18:59:07 GMT"}, {"version": "v2", "created": "Mon, 4 Jan 2021 03:49:57 GMT"}], "update_date": "2021-01-05", "authors_parsed": [["Wang", "Hanrui", ""], ["Zhang", "Zhekai", ""], ["Han", "Song", ""]]}, {"id": "2012.09854", "submitter": "Ronghang Hu", "authors": "Ronghang Hu, Nikhila Ravi, Alex Berg, Deepak Pathak", "title": "Worldsheet: Wrapping the World in a 3D Sheet for View Synthesis from a\n  Single Image", "comments": "v2 diff: Added occlusion handling via layered Wordsheets. Webpage at\n  https://worldsheet.github.io", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.GR cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present Worldsheet, a method for novel view synthesis using just a single\nRGB image as input. The main insight is that simply shrink-wrapping a planar\nmesh sheet onto the input image, consistent with the learned intermediate\ndepth, captures underlying geometry sufficient to generate photorealistic\nunseen views with large viewpoint changes. To operationalize this, we propose a\nnovel differentiable texture sampler that allows our wrapped mesh sheet to be\ntextured and rendered differentiably into an image from a target viewpoint. Our\napproach is category-agnostic, end-to-end trainable without using any 3D\nsupervision, and requires a single image at test time. We also explore a simple\nextension by stacking multiple layers of Worldsheets to better handle\nocclusions. Worldsheet consistently outperforms prior state-of-the-art methods\non single-image view synthesis across several datasets. Furthermore, this\nsimple idea captures novel views surprisingly well on a wide range of\nhigh-resolution in-the-wild images, converting them into navigable 3D pop-ups.\nVideo results and code at https://worldsheet.github.io.\n", "versions": [{"version": "v1", "created": "Thu, 17 Dec 2020 18:59:52 GMT"}, {"version": "v2", "created": "Sat, 17 Apr 2021 03:46:44 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Hu", "Ronghang", ""], ["Ravi", "Nikhila", ""], ["Berg", "Alex", ""], ["Pathak", "Deepak", ""]]}, {"id": "2012.09932", "submitter": "Edward Raff", "authors": "Edward Raff", "title": "Research Reproducibility as a Survival Analysis", "comments": "To appear in AAAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There has been increasing concern within the machine learning community that\nwe are in a reproducibility crisis. As many have begun to work on this problem,\nall work we are aware of treat the issue of reproducibility as an intrinsic\nbinary property: a paper is or is not reproducible. Instead, we consider\nmodeling the reproducibility of a paper as a survival analysis problem. We\nargue that this perspective represents a more accurate model of the underlying\nmeta-science question of reproducible research, and we show how a survival\nanalysis allows us to draw new insights that better explain prior longitudinal\ndata. The data and code can be found at\nhttps://github.com/EdwardRaff/Research-Reproducibility-Survival-Analysis\n", "versions": [{"version": "v1", "created": "Thu, 17 Dec 2020 20:56:53 GMT"}], "update_date": "2020-12-21", "authors_parsed": [["Raff", "Edward", ""]]}, {"id": "2012.09938", "submitter": "Pratyay Banerjee", "authors": "Pratyay Banerjee, Chitta Baral, Man Luo, Arindam Mitra, Kuntal Pal,\n  Tran C. Son, Neeraj Varshney", "title": "Can Transformers Reason About Effects of Actions?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  A recent work has shown that transformers are able to \"reason\" with facts and\nrules in a limited setting where the rules are natural language expressions of\nconjunctions of conditions implying a conclusion. Since this suggests that\ntransformers may be used for reasoning with knowledge given in natural\nlanguage, we do a rigorous evaluation of this with respect to a common form of\nknowledge and its corresponding reasoning -- the reasoning about effects of\nactions. Reasoning about action and change has been a top focus in the\nknowledge representation subfield of AI from the early days of AI and more\nrecently it has been a highlight aspect in common sense question answering. We\nconsider four action domains (Blocks World, Logistics, Dock-Worker-Robots and a\nGeneric Domain) in natural language and create QA datasets that involve\nreasoning about the effects of actions in these domains. We investigate the\nability of transformers to (a) learn to reason in these domains and (b)\ntransfer that learning from the generic domains to the other domains.\n", "versions": [{"version": "v1", "created": "Thu, 17 Dec 2020 21:12:58 GMT"}], "update_date": "2020-12-21", "authors_parsed": [["Banerjee", "Pratyay", ""], ["Baral", "Chitta", ""], ["Luo", "Man", ""], ["Mitra", "Arindam", ""], ["Pal", "Kuntal", ""], ["Son", "Tran C.", ""], ["Varshney", "Neeraj", ""]]}, {"id": "2012.09958", "submitter": "Josh Beal", "authors": "Josh Beal, Eric Kim, Eric Tzeng, Dong Huk Park, Andrew Zhai, Dmitry\n  Kislyuk", "title": "Toward Transformer-Based Object Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transformers have become the dominant model in natural language processing,\nowing to their ability to pretrain on massive amounts of data, then transfer to\nsmaller, more specific tasks via fine-tuning. The Vision Transformer was the\nfirst major attempt to apply a pure transformer model directly to images as\ninput, demonstrating that as compared to convolutional networks,\ntransformer-based architectures can achieve competitive results on benchmark\nclassification tasks. However, the computational complexity of the attention\noperator means that we are limited to low-resolution inputs. For more complex\ntasks such as detection or segmentation, maintaining a high input resolution is\ncrucial to ensure that models can properly identify and reflect fine details in\ntheir output. This naturally raises the question of whether or not\ntransformer-based architectures such as the Vision Transformer are capable of\nperforming tasks other than classification. In this paper, we determine that\nVision Transformers can be used as a backbone by a common detection task head\nto produce competitive COCO results. The model that we propose, ViT-FRCNN,\ndemonstrates several known properties associated with transformers, including\nlarge pretraining capacity and fast fine-tuning performance. We also\ninvestigate improvements over a standard detection backbone, including superior\nperformance on out-of-domain images, better performance on large objects, and a\nlessened reliance on non-maximum suppression. We view ViT-FRCNN as an important\nstepping stone toward a pure-transformer solution of complex vision tasks such\nas object detection.\n", "versions": [{"version": "v1", "created": "Thu, 17 Dec 2020 22:33:14 GMT"}], "update_date": "2020-12-21", "authors_parsed": [["Beal", "Josh", ""], ["Kim", "Eric", ""], ["Tzeng", "Eric", ""], ["Park", "Dong Huk", ""], ["Zhai", "Andrew", ""], ["Kislyuk", "Dmitry", ""]]}, {"id": "2012.09966", "submitter": "Reut Apel", "authors": "Reut Apel, Ido Erev, Roi Reichart, and Moshe Tennenholtz", "title": "Predicting Decisions in Language Based Persuasion Games", "comments": "Under review for the Journal of Artificial Intelligence Research\n  (JAIR)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sender-receiver interactions, and specifically persuasion games, are widely\nresearched in economic modeling and artificial intelligence, and serve as a\nsolid foundation for powerful applications. However, in the classic persuasion\ngames setting, the messages sent from the expert to the decision-maker are\nabstract or well-structured application-specific signals rather than natural\n(human) language messages, although natural language is a very common\ncommunication signal in real-world persuasion setups. This paper addresses the\nuse of natural language in persuasion games, exploring its impact on the\ndecisions made by the players and aiming to construct effective models for the\nprediction of these decisions. For this purpose, we conduct an online repeated\ninteraction experiment. At each trial of the interaction, an informed expert\naims to sell an uninformed decision-maker a vacation in a hotel, by sending her\na review that describes the hotel. While the expert is exposed to several\nscored reviews, the decision-maker observes only the single review sent by the\nexpert, and her payoff in case she chooses to take the hotel is a random draw\nfrom the review score distribution available to the expert only. The expert's\npayoff, in turn, depends on the number of times the decision-maker chooses the\nhotel. We consider a number of modeling approaches for this setup, differing\nfrom each other in the model type (deep neural network (DNN) vs. linear\nclassifier), the type of features used by the model (textual, behavioral or\nboth) and the source of the textual features (DNN-based vs. hand-crafted). Our\nresults demonstrate that given a prefix of the interaction sequence, our models\ncan predict the future decisions of the decision-maker, particularly when a\nsequential modeling approach and hand-crafted textual features are applied.\n", "versions": [{"version": "v1", "created": "Thu, 17 Dec 2020 22:52:47 GMT"}, {"version": "v2", "created": "Thu, 7 Jan 2021 09:08:52 GMT"}, {"version": "v3", "created": "Thu, 1 Jul 2021 18:27:09 GMT"}], "update_date": "2021-07-05", "authors_parsed": [["Apel", "Reut", ""], ["Erev", "Ido", ""], ["Reichart", "Roi", ""], ["Tennenholtz", "Moshe", ""]]}, {"id": "2012.09968", "submitter": "Omid Madani", "authors": "Omid Madani, Thanh Ngo, Weifei Zeng, Sai Ankith Averine, Sasidhar\n  Evuru, Varun Malhotra, Shashidhar Gandham, Navindra Yadav", "title": "Binomial Tails for Community Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  An important task of community discovery in networks is assessing\nsignificance of the results and robust ranking of the generated candidate\ngroups. Often in practice, numerous candidate communities are discovered, and\nfocusing the analyst's time on the most salient and promising findings is\ncrucial. We develop simple efficient group scoring functions derived from tail\nprobabilities using binomial models. Experiments on synthetic and numerous\nreal-world data provides evidence that binomial scoring leads to a more robust\nranking than other inexpensive scoring functions, such as conductance.\nFurthermore, we obtain confidence values ($p$-values) that can be used for\nfiltering and labeling the discovered groups. Our analyses shed light on\nvarious properties of the approach. The binomial tail is simple and versatile,\nand we describe two other applications for community analysis: degree of\ncommunity membership (which in turn yields group-scoring functions), and the\ndiscovery of significant edges in the community-induced graph.\n", "versions": [{"version": "v1", "created": "Thu, 17 Dec 2020 23:04:10 GMT"}], "update_date": "2020-12-21", "authors_parsed": [["Madani", "Omid", ""], ["Ngo", "Thanh", ""], ["Zeng", "Weifei", ""], ["Averine", "Sai Ankith", ""], ["Evuru", "Sasidhar", ""], ["Malhotra", "Varun", ""], ["Gandham", "Shashidhar", ""], ["Yadav", "Navindra", ""]]}, {"id": "2012.09990", "submitter": "Won-Yong Shin", "authors": "Cong Tran, Dung D. Vu, Won-Yong Shin", "title": "An Improved Approach for Estimating Social POI Boundaries With Textual\n  Attributes on Social Media", "comments": "13 pages, 6 figures, 5 tables; to appear in the Knowledge-Based\n  Systems (Please cite our journal version that will appear in an upcoming\n  issue.)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.AI cs.DS cs.LG cs.NI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  It has been insufficiently explored how to perform density-based clustering\nby exploiting textual attributes on social media. In this paper, we aim at\ndiscovering a social point-of-interest (POI) boundary, formed as a convex\npolygon. More specifically, we present a new approach and algorithm, built upon\nour earlier work on social POI boundary estimation (SoBEst). This SoBEst\napproach takes into account both relevant and irrelevant records within a\ngeographic area, where relevant records contain a POI name or its variations in\ntheir text field. Our study is motivated by the following empirical\nobservation: a fixed representative coordinate of each POI that SoBEst\nbasically assumes may be far away from the centroid of the estimated social POI\nboundary for certain POIs. Thus, using SoBEst in such cases may possibly result\nin unsatisfactory performance on the boundary estimation quality (BEQ), which\nis expressed as a function of the $F$-measure. To solve this problem, we\nformulate a joint optimization problem of simultaneously finding the radius of\na circle and the POI's representative coordinate $c$ by allowing to update $c$.\nSubsequently, we design an iterative SoBEst (I-SoBEst) algorithm, which enables\nus to achieve a higher degree of BEQ for some POIs. The computational\ncomplexity of the proposed I-SoBEst algorithm is shown to scale linearly with\nthe number of records. We demonstrate the superiority of our algorithm over\ncompeting clustering methods including the original SoBEst.\n", "versions": [{"version": "v1", "created": "Fri, 18 Dec 2020 00:41:44 GMT"}], "update_date": "2020-12-21", "authors_parsed": [["Tran", "Cong", ""], ["Vu", "Dung D.", ""], ["Shin", "Won-Yong", ""]]}, {"id": "2012.10020", "submitter": "Siddharth Biswal", "authors": "Siddharth Biswal, Soumya Ghosh, Jon Duke, Bradley Malin, Walter\n  Stewart and Jimeng Sun", "title": "EVA: Generating Longitudinal Electronic Health Records Using Conditional\n  Variational Autoencoders", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Researchers require timely access to real-world longitudinal electronic\nhealth records (EHR) to develop, test, validate, and implement machine learning\nsolutions that improve the quality and efficiency of healthcare. In contrast,\nhealth systems value deeply patient privacy and data security. De-identified\nEHRs do not adequately address the needs of health systems, as de-identified\ndata are susceptible to re-identification and its volume is also limited.\nSynthetic EHRs offer a potential solution. In this paper, we propose EHR\nVariational Autoencoder (EVA) for synthesizing sequences of discrete EHR\nencounters (e.g., clinical visits) and encounter features (e.g., diagnoses,\nmedications, procedures). We illustrate that EVA can produce realistic EHR\nsequences, account for individual differences among patients, and can be\nconditioned on specific disease conditions, thus enabling disease-specific\nstudies. We design efficient, accurate inference algorithms by combining\nstochastic gradient Markov Chain Monte Carlo with amortized variational\ninference. We assess the utility of the methods on large real-world EHR\nrepositories containing over 250, 000 patients. Our experiments, which include\nuser studies with knowledgeable clinicians, indicate the generated EHR\nsequences are realistic. We confirmed the performance of predictive models\ntrained on the synthetic data are similar with those trained on real EHRs.\nAdditionally, our findings indicate that augmenting real data with synthetic\nEHRs results in the best predictive performance - improving the best baseline\nby as much as 8% in top-20 recall.\n", "versions": [{"version": "v1", "created": "Fri, 18 Dec 2020 02:37:49 GMT"}], "update_date": "2020-12-21", "authors_parsed": [["Biswal", "Siddharth", ""], ["Ghosh", "Soumya", ""], ["Duke", "Jon", ""], ["Malin", "Bradley", ""], ["Stewart", "Walter", ""], ["Sun", "Jimeng", ""]]}, {"id": "2012.10033", "submitter": "Jerry Zikun Chen", "authors": "Jerry Zikun Chen, Shi Yu, Haoran Wang", "title": "Exploring Fluent Query Reformulations with Text-to-Text Transformers and\n  Reinforcement Learning", "comments": "Workshop on the 9th Dialog System Technology Challenge (DSTC-9), AAAI\n  2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Query reformulation aims to alter noisy or ambiguous text sequences into\ncoherent ones closer to natural language questions. This is to prevent errors\nfrom propagating in a client-facing pipeline and promote better communication\nwith users. Besides, it is crucial to maintain performance in downstream\nenvironments like question answering when rephrased queries are given as input.\nWe show that under the previous framework (AQA), attempts to alter RL\nalgorithms do not bring significant benefits to either reward acquisition or\nsequence fluency. Instead, we leverage a query-reformulating text-to-text\ntransformer (QRT5) and apply policy-based RL algorithms to further nudge this\nreformulator and obtain better answers downstream by generating\nreward-acquiring query trajectories. QRT5 shows better sample efficiency in RL\nto achieve the same level of QA performance as the previous approach. It can\ngenerate reformulations with more readability based on query well-formedness\nevaluations and can generalize to out-of-sample data. Our framework is\ndemonstrated to be flexible, allowing reward signals to be sourced from\ndifferent downstream environments such as intent classification.\n", "versions": [{"version": "v1", "created": "Fri, 18 Dec 2020 03:16:37 GMT"}, {"version": "v2", "created": "Sun, 4 Jul 2021 01:08:13 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Chen", "Jerry Zikun", ""], ["Yu", "Shi", ""], ["Wang", "Haoran", ""]]}, {"id": "2012.10034", "submitter": "Hezam Albaqami", "authors": "Hezam Albaqami, Ghulam Mubashar Hassan, Abdulhamit Subasi and Amitava\n  Datta", "title": "Automatic detection of abnormal EEG signals using wavelet feature\n  extraction and gradient boosting decision tree", "comments": null, "journal-ref": null, "doi": "10.1016/j.bspc.2021.102957", "report-no": null, "categories": "eess.SP cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Electroencephalography is frequently used for diagnostic evaluation of\nvarious brain-related disorders due to its excellent resolution, non-invasive\nnature and low cost. However, manual analysis of EEG signals could be strenuous\nand a time-consuming process for experts. It requires long training time for\nphysicians to develop expertise in it and additionally experts have low\ninter-rater agreement (IRA) among themselves. Therefore, many Computer Aided\nDiagnostic (CAD) based studies have considered the automation of interpreting\nEEG signals to alleviate the workload and support the final diagnosis. In this\npaper, we present an automatic binary classification framework for brain\nsignals in multichannel EEG recordings. We propose to use Wavelet Packet\nDecomposition (WPD) techniques to decompose the EEG signals into frequency\nsub-bands and extract a set of statistical features from each of the selected\ncoefficients. Moreover, we propose a novel method to reduce the dimension of\nthe feature space without compromising the quality of the extracted features.\nThe extracted features are classified using different Gradient Boosting\nDecision Tree (GBDT) based classification frameworks, which are CatBoost,\nXGBoost and LightGBM. We used Temple University Hospital EEG Abnormal Corpus\nV2.0.0 to test our proposed technique. We found that CatBoost classifier\nachieves the binary classification accuracy of 87.68%, and outperforms\nstate-of-the-art techniques on the same dataset by more than 1% in accuracy and\nmore than 3% in sensitivity. The obtained results in this research provide\nimportant insights into the usefulness of WPD feature extraction and GBDT\nclassifiers for EEG classification.\n", "versions": [{"version": "v1", "created": "Fri, 18 Dec 2020 03:36:52 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Albaqami", "Hezam", ""], ["Hassan", "Ghulam Mubashar", ""], ["Subasi", "Abdulhamit", ""], ["Datta", "Amitava", ""]]}, {"id": "2012.10043", "submitter": "Peter Schaldenbrand", "authors": "Peter Schaldenbrand and Jean Oh", "title": "Content Masked Loss: Human-Like Brush Stroke Planning in a Reinforcement\n  Learning Painting Agent", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The objective of most Reinforcement Learning painting agents is to minimize\nthe loss between a target image and the paint canvas. Human painter artistry\nemphasizes important features of the target image rather than simply\nreproducing it (DiPaola 2007). Using adversarial or L2 losses in the RL\npainting models, although its final output is generally a work of finesse,\nproduces a stroke sequence that is vastly different from that which a human\nwould produce since the model does not have knowledge about the abstract\nfeatures in the target image. In order to increase the human-like planning of\nthe model without the use of expensive human data, we introduce a new loss\nfunction for use with the model's reward function: Content Masked Loss. In the\ncontext of robot painting, Content Masked Loss employs an object detection\nmodel to extract features which are used to assign higher weight to regions of\nthe canvas that a human would find important for recognizing content. The\nresults, based on 332 human evaluators, show that the digital paintings\nproduced by our Content Masked model show detectable subject matter earlier in\nthe stroke sequence than existing methods without compromising on the quality\nof the final painting. Our code is available at\nhttps://github.com/pschaldenbrand/ContentMaskedLoss.\n", "versions": [{"version": "v1", "created": "Fri, 18 Dec 2020 04:02:13 GMT"}, {"version": "v2", "created": "Sat, 27 Feb 2021 16:28:47 GMT"}], "update_date": "2021-03-02", "authors_parsed": [["Schaldenbrand", "Peter", ""], ["Oh", "Jean", ""]]}, {"id": "2012.10047", "submitter": "Sifan Wang", "authors": "Sifan Wang, Hanwen Wang, Paris Perdikaris", "title": "On the eigenvector bias of Fourier feature networks: From regression to\n  solving multi-scale PDEs with physics-informed neural networks", "comments": "27 pages, 18 figures", "journal-ref": null, "doi": "10.1016/j.cma.2021.113938", "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Physics-informed neural networks (PINNs) are demonstrating remarkable promise\nin integrating physical models with gappy and noisy observational data, but\nthey still struggle in cases where the target functions to be approximated\nexhibit high-frequency or multi-scale features. In this work we investigate\nthis limitation through the lens of Neural Tangent Kernel (NTK) theory and\nelucidate how PINNs are biased towards learning functions along the dominant\neigen-directions of their limiting NTK. Using this observation, we construct\nnovel architectures that employ spatio-temporal and multi-scale random Fourier\nfeatures, and justify how such coordinate embedding layers can lead to robust\nand accurate PINN models. Numerical examples are presented for several\nchallenging cases where conventional PINN models fail, including wave\npropagation and reaction-diffusion dynamics, illustrating how the proposed\nmethods can be used to effectively tackle both forward and inverse problems\ninvolving partial differential equations with multi-scale behavior. All code an\ndata accompanying this manuscript will be made publicly available at\n\\url{https://github.com/PredictiveIntelligenceLab/MultiscalePINNs}.\n", "versions": [{"version": "v1", "created": "Fri, 18 Dec 2020 04:19:30 GMT"}], "update_date": "2021-06-16", "authors_parsed": [["Wang", "Sifan", ""], ["Wang", "Hanwen", ""], ["Perdikaris", "Paris", ""]]}, {"id": "2012.10053", "submitter": "Yuan Sun Dr", "authors": "Yuan Sun, Samuel Esler, Dhananjay Thiruvady, Andreas T. Ernst,\n  Xiaodong Li and Kerri Morgan", "title": "Instance Space Analysis for the Car Sequencing Problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we investigate an important research question in the car\nsequencing problem, that is, what characteristics make an instance hard to\nsolve? To do so, we carry out an Instance Space Analysis for the car sequencing\nproblem, by extracting a vector of problem features to characterize an instance\nand projecting feature vectors onto a two-dimensional space using principal\ncomponent analysis. The resulting two dimensional visualizations provide\ninsights into both the characteristics of the instances used for testing and to\ncompare how these affect different optimisation algorithms. This guides us in\nconstructing a new set of benchmark instances with a range of instance\nproperties. These are shown to be both more diverse than the previous\nbenchmarks and include many hard to solve instances. We systematically compare\nthe performance of six algorithms for solving the car sequencing problem. The\nmethods tested include three existing algorithms from the literature and three\nnew ones. Importantly, we build machine learning models to identify the niche\nin the instance space that an algorithm is expected to perform well on. Our\nresults show that the new algorithms are state-of-the-art. This analysis helps\nto understand problem hardness and select an appropriate algorithm for solving\na given car sequencing problem instance.\n", "versions": [{"version": "v1", "created": "Fri, 18 Dec 2020 05:26:13 GMT"}], "update_date": "2020-12-21", "authors_parsed": [["Sun", "Yuan", ""], ["Esler", "Samuel", ""], ["Thiruvady", "Dhananjay", ""], ["Ernst", "Andreas T.", ""], ["Li", "Xiaodong", ""], ["Morgan", "Kerri", ""]]}, {"id": "2012.10074", "submitter": "Jianqiang Ma", "authors": "Jianqiang Ma, Zeyu Yan, Shuai Pang, Yang Zhang, Jianping Shen", "title": "Mention Extraction and Linking for SQL Query Generation", "comments": "Accepted in EMNLP 2020. This work is also known as \"IE-SQL:\n  Text-to-SQL as Information Extraction\"", "journal-ref": null, "doi": "10.18653/v1/2020.emnlp-main.563", "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  On the WikiSQL benchmark, state-of-the-art text-to-SQL systems typically take\na slot-filling approach by building several dedicated models for each type of\nslots. Such modularized systems are not only complex butalso of limited\ncapacity for capturing inter-dependencies among SQL clauses. To solve these\nproblems, this paper proposes a novel extraction-linking approach, where a\nunified extractor recognizes all types of slot mentions appearing in the\nquestion sentence before a linker maps the recognized columns to the table\nschema to generate executable SQL queries. Trained with automatically generated\nannotations, the proposed method achieves the first place on the WikiSQL\nbenchmark.\n", "versions": [{"version": "v1", "created": "Fri, 18 Dec 2020 06:51:23 GMT"}], "update_date": "2020-12-21", "authors_parsed": [["Ma", "Jianqiang", ""], ["Yan", "Zeyu", ""], ["Pang", "Shuai", ""], ["Zhang", "Yang", ""], ["Shen", "Jianping", ""]]}, {"id": "2012.10076", "submitter": "Kieran Browne", "authors": "Kieran Browne, Ben Swift", "title": "Semantics and explanation: why counterfactual explanations produce\n  adversarial examples in deep neural networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent papers in explainable AI have made a compelling case for\ncounterfactual modes of explanation. While counterfactual explanations appear\nto be extremely effective in some instances, they are formally equivalent to\nadversarial examples. This presents an apparent paradox for explainability\nresearchers: if these two procedures are formally equivalent, what accounts for\nthe explanatory divide apparent between counterfactual explanations and\nadversarial examples? We resolve this paradox by placing emphasis back on the\nsemantics of counterfactual expressions. Producing satisfactory explanations\nfor deep learning systems will require that we find ways to interpret the\nsemantics of hidden layer representations in deep neural networks.\n", "versions": [{"version": "v1", "created": "Fri, 18 Dec 2020 07:04:04 GMT"}], "update_date": "2020-12-21", "authors_parsed": [["Browne", "Kieran", ""], ["Swift", "Ben", ""]]}, {"id": "2012.10140", "submitter": "Michael Lim", "authors": "Michael H. Lim, Claire J. Tomlin, Zachary N. Sunberg", "title": "Voronoi Progressive Widening: Efficient Online Solvers for Continuous\n  State, Action, and Observation POMDPs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO cs.SY eess.SY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper introduces Voronoi Progressive Widening (VPW), a generalization of\nVoronoi optimistic optimization (VOO) and action progressive widening to\npartially observable Markov decision processes (POMDPs). Tree search algorithms\ncan use VPW to effectively handle continuous or hybrid action spaces by\nefficiently balancing local and global action searching. This paper proposes\ntwo VPW-based algorithms and analyzes them from theoretical and simulation\nperspectives. Voronoi Optimistic Weighted Sparse Sampling (VOWSS) is a\ntheoretical tool that justifies VPW-based online solvers, and it is the first\nalgorithm with global convergence guarantees for continuous state, action, and\nobservation POMDPs. Voronoi Optimistic Monte Carlo Planning with Observation\nWeighting (VOMCPOW) is a versatile and efficient algorithm that consistently\noutperforms state-of-the-art POMDP algorithms in several simulation\nexperiments.\n", "versions": [{"version": "v1", "created": "Fri, 18 Dec 2020 10:05:43 GMT"}, {"version": "v2", "created": "Fri, 26 Mar 2021 13:00:12 GMT"}, {"version": "v3", "created": "Thu, 1 Apr 2021 09:47:32 GMT"}], "update_date": "2021-04-02", "authors_parsed": [["Lim", "Michael H.", ""], ["Tomlin", "Claire J.", ""], ["Sunberg", "Zachary N.", ""]]}, {"id": "2012.10141", "submitter": "Ioan Gabriel Bucur", "authors": "Ioan Gabriel Bucur, Tom Claassen and Tom Heskes", "title": "MASSIVE: Tractable and Robust Bayesian Learning of Many-Dimensional\n  Instrumental Variable Models", "comments": "14 pages, 7 figures, Published in the Proceedings of the 36th\n  Conference on Uncertainty in Artificial Intelligence (UAI)", "journal-ref": "PMLR 124:1049-1058, 2020", "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG q-bio.GN", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recent availability of huge, many-dimensional data sets, like those\narising from genome-wide association studies (GWAS), provides many\nopportunities for strengthening causal inference. One popular approach is to\nutilize these many-dimensional measurements as instrumental variables\n(instruments) for improving the causal effect estimate between other pairs of\nvariables. Unfortunately, searching for proper instruments in a\nmany-dimensional set of candidates is a daunting task due to the intractable\nmodel space and the fact that we cannot directly test which of these candidates\nare valid, so most existing search methods either rely on overly stringent\nmodeling assumptions or fail to capture the inherent model uncertainty in the\nselection process. We show that, as long as at least some of the candidates are\n(close to) valid, without knowing a priori which ones, they collectively still\npose enough restrictions on the target interaction to obtain a reliable causal\neffect estimate. We propose a general and efficient causal inference algorithm\nthat accounts for model uncertainty by performing Bayesian model averaging over\nthe most promising many-dimensional instrumental variable models, while at the\nsame time employing weaker assumptions regarding the data generating process.\nWe showcase the efficiency, robustness and predictive performance of our\nalgorithm through experimental results on both simulated and real-world data.\n", "versions": [{"version": "v1", "created": "Fri, 18 Dec 2020 10:06:55 GMT"}], "update_date": "2020-12-21", "authors_parsed": [["Bucur", "Ioan Gabriel", ""], ["Claassen", "Tom", ""], ["Heskes", "Tom", ""]]}, {"id": "2012.10147", "submitter": "Manfred Eppe", "authors": "Manfred Eppe, Christian Gumbsch, Matthias Kerzel, Phuong D.H. Nguyen,\n  Martin V. Butz and Stefan Wermter", "title": "Hierarchical principles of embodied reinforcement learning: A review", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cognitive Psychology and related disciplines have identified several critical\nmechanisms that enable intelligent biological agents to learn to solve complex\nproblems. There exists pressing evidence that the cognitive mechanisms that\nenable problem-solving skills in these species build on hierarchical mental\nrepresentations. Among the most promising computational approaches to provide\ncomparable learning-based problem-solving abilities for artificial agents and\nrobots is hierarchical reinforcement learning. However, so far the existing\ncomputational approaches have not been able to equip artificial agents with\nproblem-solving abilities that are comparable to intelligent animals, including\nhuman and non-human primates, crows, or octopuses. Here, we first survey the\nliterature in Cognitive Psychology, and related disciplines, and find that many\nimportant mental mechanisms involve compositional abstraction, curiosity, and\nforward models. We then relate these insights with contemporary hierarchical\nreinforcement learning methods, and identify the key machine intelligence\napproaches that realise these mechanisms. As our main result, we show that all\nimportant cognitive mechanisms have been implemented independently in isolated\ncomputational architectures, and there is simply a lack of approaches that\nintegrate them appropriately. We expect our results to guide the development of\nmore sophisticated cognitively inspired hierarchical methods, so that future\nartificial agents achieve a problem-solving performance on the level of\nintelligent animals.\n", "versions": [{"version": "v1", "created": "Fri, 18 Dec 2020 10:19:38 GMT"}], "update_date": "2020-12-21", "authors_parsed": [["Eppe", "Manfred", ""], ["Gumbsch", "Christian", ""], ["Kerzel", "Matthias", ""], ["Nguyen", "Phuong D. H.", ""], ["Butz", "Martin V.", ""], ["Wermter", "Stefan", ""]]}, {"id": "2012.10154", "submitter": "Jo\\~ao Lousada", "authors": "Jo\\~ao Lousada, Miguel Ribeiro", "title": "Neural Network Embeddings for Test Case Prioritization", "comments": "11 pages, 6 figures and 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In modern software engineering, Continuous Integration (CI) has become an\nindispensable step towards systematically managing the life cycles of software\ndevelopment. Large companies struggle with keeping the pipeline updated and\noperational, in useful time, due to the large amount of changes and addition of\nfeatures, that build on top of each other and have several developers, working\non different platforms. Associated with such software changes, there is always\na strong component of Testing. As teams and projects grow, exhaustive testing\nquickly becomes inhibitive, becoming adamant to select the most relevant test\ncases earlier, without compromising software quality. We have developed a new\ntool called Neural Network Embeeding for Test Case Prioritization (NNE-TCP) is\na novel Machine-Learning (ML) framework that analyses which files were modified\nwhen there was a test status transition and learns relationships between these\nfiles and tests by mapping them into multidimensional vectors and grouping them\nby similarity. When new changes are made, tests that are more likely to be\nlinked to the files modified are prioritized, reducing the resources needed to\nfind newly introduced faults. Furthermore, NNE-TCP enables entity visualization\nin low-dimensional space, allowing for other manners of grouping files and\ntests by similarity and to reduce redundancies. By applying NNE-TCP, we show\nfor the first time that the connection between modified files and tests is\nrelevant and competitive relative to other traditional methods.\n", "versions": [{"version": "v1", "created": "Fri, 18 Dec 2020 10:33:28 GMT"}, {"version": "v2", "created": "Mon, 21 Dec 2020 01:35:04 GMT"}], "update_date": "2020-12-22", "authors_parsed": [["Lousada", "Jo\u00e3o", ""], ["Ribeiro", "Miguel", ""]]}, {"id": "2012.10171", "submitter": "Menghui Zhu", "authors": "Sheng Chen, Menghui Zhu, Deheng Ye, Weinan Zhang, Qiang Fu, Wei Yang", "title": "Which Heroes to Pick? Learning to Draft in MOBA Games with Neural\n  Networks and Tree Search", "comments": "IEEE Transactions on Games", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hero drafting is essential in MOBA game playing as it builds the team of each\nside and directly affects the match outcome. State-of-the-art drafting methods\nfail to consider: 1) drafting efficiency when the hero pool is expanded; 2) the\nmulti-round nature of a MOBA 5v5 match series, i.e., two teams play best-of-N\nand the same hero is only allowed to be drafted once throughout the series. In\nthis paper, we formulate the drafting process as a multi-round combinatorial\ngame and propose a novel drafting algorithm based on neural networks and\nMonte-Carlo tree search, named JueWuDraft. Specifically, we design a long-term\nvalue estimation mechanism to handle the best-of-N drafting case. Taking Honor\nof Kings, one of the most popular MOBA games at present, as a running case, we\ndemonstrate the practicality and effectiveness of JueWuDraft when compared to\nstate-of-the-art drafting methods.\n", "versions": [{"version": "v1", "created": "Fri, 18 Dec 2020 11:19:00 GMT"}, {"version": "v2", "created": "Thu, 1 Jul 2021 03:34:40 GMT"}, {"version": "v3", "created": "Fri, 2 Jul 2021 03:48:24 GMT"}], "update_date": "2021-07-05", "authors_parsed": [["Chen", "Sheng", ""], ["Zhu", "Menghui", ""], ["Ye", "Deheng", ""], ["Zhang", "Weinan", ""], ["Fu", "Qiang", ""], ["Yang", "Wei", ""]]}, {"id": "2012.10189", "submitter": "Mingjie Wang", "authors": "Mingjie Wang, Hao Cai, Xianfeng Han, Jun Zhou, Minglun Gong", "title": "STNet: Scale Tree Network with Multi-level Auxiliator for Crowd Counting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Crowd counting remains a challenging task because the presence of drastic\nscale variation, density inconsistency, and complex background can seriously\ndegrade the counting accuracy. To battle the ingrained issue of accuracy\ndegradation, we propose a novel and powerful network called Scale Tree Network\n(STNet) for accurate crowd counting. STNet consists of two key components: a\nScale-Tree Diversity Enhancer and a Semi-supervised Multi-level Auxiliator.\nSpecifically, the Diversity Enhancer is designed to enrich scale diversity,\nwhich alleviates limitations of existing methods caused by insufficient level\nof scales. A novel tree structure is adopted to hierarchically parse\ncoarse-to-fine crowd regions. Furthermore, a simple yet effective Multi-level\nAuxiliator is presented to aid in exploiting generalisable shared\ncharacteristics at multiple levels, allowing more accurate pixel-wise\nbackground cognition. The overall STNet is trained in an end-to-end manner,\nwithout the needs for manually tuning loss weights between the main and the\nauxiliary tasks. Extensive experiments on four challenging crowd datasets\ndemonstrate the superiority of the proposed method.\n", "versions": [{"version": "v1", "created": "Fri, 18 Dec 2020 12:18:45 GMT"}], "update_date": "2020-12-21", "authors_parsed": [["Wang", "Mingjie", ""], ["Cai", "Hao", ""], ["Han", "Xianfeng", ""], ["Zhou", "Jun", ""], ["Gong", "Minglun", ""]]}, {"id": "2012.10191", "submitter": "Paolo Liberatore", "authors": "Paolo Liberatore", "title": "Reconstructing a single-head formula to facilitate logical forgetting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Logical forgetting may take exponential time in general, but it does not when\nits input is a single-head propositional definite Horn formula. Single-head\nmeans that no variable is the head of multiple clauses. An algorithm to make a\nformula single-head if possible is shown. It improves over a previous one by\nbeing complete: it always finds a single-head formula equivalent to the given\none if any.\n", "versions": [{"version": "v1", "created": "Fri, 18 Dec 2020 12:25:49 GMT"}], "update_date": "2020-12-21", "authors_parsed": [["Liberatore", "Paolo", ""]]}, {"id": "2012.10200", "submitter": "Sultan Javed Majeed", "authors": "Sultan Javed Majeed and Marcus Hutter", "title": "Exact Reduction of Huge Action Spaces in General Reinforcement Learning", "comments": "A variant of this paper was presented at the AAAI-2021 proceedings", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.SY eess.SY stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The reinforcement learning (RL) framework formalizes the notion of learning\nwith interactions. Many real-world problems have large state-spaces and/or\naction-spaces such as in Go, StarCraft, protein folding, and robotics or are\nnon-Markovian, which cause significant challenges to RL algorithms. In this\nwork we address the large action-space problem by sequentializing actions,\nwhich can reduce the action-space size significantly, even down to two actions\nat the expense of an increased planning horizon. We provide explicit and exact\nconstructions and equivalence proofs for all quantities of interest for\narbitrary history-based processes. In the case of MDPs, this could help RL\nalgorithms that bootstrap. In this work we show how action-binarization in the\nnon-MDP case can significantly improve Extreme State Aggregation (ESA) bounds.\nESA allows casting any (non-MDP, non-ergodic, history-based) RL problem into a\nfixed-sized non-Markovian state-space with the help of a surrogate Markovian\nprocess. On the upside, ESA enjoys similar optimality guarantees as Markovian\nmodels do. But a downside is that the size of the aggregated state-space\nbecomes exponential in the size of the action-space. In this work, we patch\nthis issue by binarizing the action-space. We provide an upper bound on the\nnumber of states of this binarized ESA that is logarithmic in the original\naction-space size, a double-exponential improvement.\n", "versions": [{"version": "v1", "created": "Fri, 18 Dec 2020 12:45:03 GMT"}], "update_date": "2020-12-21", "authors_parsed": [["Majeed", "Sultan Javed", ""], ["Hutter", "Marcus", ""]]}, {"id": "2012.10210", "submitter": "Tom Winterbottom", "authors": "Thomas Winterbottom, Sarah Xiao, Alistair McLean, Noura Al Moubayed", "title": "On Modality Bias in the TVQA Dataset", "comments": "10 pages, 4 Figures, 2 Tables, +Supp Mats, BMVC 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  TVQA is a large scale video question answering (video-QA) dataset based on\npopular TV shows. The questions were specifically designed to require \"both\nvision and language understanding to answer\". In this work, we demonstrate an\ninherent bias in the dataset towards the textual subtitle modality. We infer\nsaid bias both directly and indirectly, notably finding that models trained\nwith subtitles learn, on-average, to suppress video feature contribution. Our\nresults demonstrate that models trained on only the visual information can\nanswer ~45% of the questions, while using only the subtitles achieves ~68%. We\nfind that a bilinear pooling based joint representation of modalities damages\nmodel performance by 9% implying a reliance on modality specific information.\nWe also show that TVQA fails to benefit from the RUBi modality bias reduction\ntechnique popularised in VQA. By simply improving text processing using BERT\nembeddings with the simple model first proposed for TVQA, we achieve\nstate-of-the-art results (72.13%) compared to the highly complex STAGE model\n(70.50%). We recommend a multimodal evaluation framework that can highlight\nbiases in models and isolate visual and textual reliant subsets of data. Using\nthis framework we propose subsets of TVQA that respond exclusively to either or\nboth modalities in order to facilitate multimodal modelling as TVQA originally\nintended.\n", "versions": [{"version": "v1", "created": "Fri, 18 Dec 2020 13:06:23 GMT"}], "update_date": "2020-12-21", "authors_parsed": [["Winterbottom", "Thomas", ""], ["Xiao", "Sarah", ""], ["McLean", "Alistair", ""], ["Moubayed", "Noura Al", ""]]}, {"id": "2012.10232", "submitter": "Bata Vasic Dr", "authors": "Iva Vasic, Bata Vasic, and Zorica Nikolic", "title": "Artificial Intelligence ordered 3D vertex importance", "comments": "8 pages, 4 figures", "journal-ref": "FBIM Transactions, Vol. 8 No. 2, pp. 193-201, 2020", "doi": "10.12709/fbim.08.08.02.21", "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Ranking vertices of multidimensional networks is crucial in many areas of\nresearch, including selecting and determining the importance of decisions. Some\ndecisions are significantly more important than others, and their weight\ncategorization is also imortant. This paper defines a completely new method for\ndetermining the weight decisions using artificial intelligence for importance\nranking of three-dimensional network vertices, improving the existing Ordered\nStatistics Vertex Extraction and Tracking Algorithm (OSVETA) based on\nmodulation of quantized indices (QIM) and error correction codes. The technique\nwe propose in this paper offers significant improvements the efficiency of\ndetermination the importance of network vertices in relation to statistical\nOSVETA criteria, replacing heuristic methods with methods of precise prediction\nof modern neural networks. The new artificial intelligence technique enables a\nsignificantly better definition of the 3D meshes and a better assessment of\ntheir topological features. The new method contributions result in a greater\nprecision in defining stable vertices, significantly reducing the probability\nof deleting mesh vertices.\n", "versions": [{"version": "v1", "created": "Thu, 17 Dec 2020 06:54:59 GMT"}], "update_date": "2020-12-21", "authors_parsed": [["Vasic", "Iva", ""], ["Vasic", "Bata", ""], ["Nikolic", "Zorica", ""]]}, {"id": "2012.10251", "submitter": "Saja Khaled Tawalbeh", "authors": "Saja AL-Tawalbeh, Mohammad AL-Smadi", "title": "A Benchmark Arabic Dataset for Commonsense Explanation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Language comprehension and commonsense knowledge validation by machines are\nchallenging tasks that are still under researched and evaluated for Arabic\ntext. In this paper, we present a benchmark Arabic dataset for commonsense\nexplanation. The dataset consists of Arabic sentences that does not make sense\nalong with three choices to select among them the one that explains why the\nsentence is false. Furthermore, this paper presents baseline results to assist\nand encourage the future evaluation of research in this field. The dataset is\ndistributed under the Creative Commons CC-BY-SA 4.0 license and can be found on\nGitHub\n", "versions": [{"version": "v1", "created": "Fri, 18 Dec 2020 14:07:10 GMT"}], "update_date": "2020-12-21", "authors_parsed": [["AL-Tawalbeh", "Saja", ""], ["AL-Smadi", "Mohammad", ""]]}, {"id": "2012.10252", "submitter": "Qiang Liu", "authors": "Qiang Liu, Tao Han, Jiang (Linda) Xie, BaekGyu Kim", "title": "LiveMap: Real-Time Dynamic Map in Automotive Edge Computing", "comments": "This paper is accepted by INFOCOM 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.AI cs.SY eess.SY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Autonomous driving needs various line-of-sight sensors to perceive\nsurroundings that could be impaired under diverse environment uncertainties\nsuch as visual occlusion and extreme weather. To improve driving safety, we\nexplore to wirelessly share perception information among connected vehicles\nwithin automotive edge computing networks. Sharing massive perception data in\nreal time, however, is challenging under dynamic networking conditions and\nvarying computation workloads. In this paper, we propose LiveMap, a real-time\ndynamic map, that detects, matches, and tracks objects on the road with\ncrowdsourcing data from connected vehicles in sub-second. We develop the data\nplane of LiveMap that efficiently processes individual vehicle data with object\ndetection, projection, feature extraction, object matching, and effectively\nintegrates objects from multiple vehicles with object combination. We design\nthe control plane of LiveMap that allows adaptive offloading of vehicle\ncomputations, and develop an intelligent vehicle scheduling and offloading\nalgorithm to reduce the offloading latency of vehicles based on deep\nreinforcement learning (DRL) techniques. We implement LiveMap on a small-scale\ntestbed and develop a large-scale network simulator. We evaluate the\nperformance of LiveMap with both experiments and simulations, and the results\nshow LiveMap reduces 34.1% average latency than the baseline solution.\n", "versions": [{"version": "v1", "created": "Wed, 16 Dec 2020 15:00:49 GMT"}], "update_date": "2020-12-21", "authors_parsed": [["Liu", "Qiang", "", "Linda"], ["Han", "Tao", "", "Linda"], ["Jiang", "", "", "Linda"], ["Xie", "", ""], ["Kim", "BaekGyu", ""]]}, {"id": "2012.10289", "submitter": "Binny Mathew", "authors": "Binny Mathew, Punyajoy Saha, Seid Muhie Yimam, Chris Biemann, Pawan\n  Goyal, and Animesh Mukherjee", "title": "HateXplain: A Benchmark Dataset for Explainable Hate Speech Detection", "comments": "12 pages, 7 figues, 8 tables. Accepted at AAAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hate speech is a challenging issue plaguing the online social media. While\nbetter models for hate speech detection are continuously being developed, there\nis little research on the bias and interpretability aspects of hate speech. In\nthis paper, we introduce HateXplain, the first benchmark hate speech dataset\ncovering multiple aspects of the issue. Each post in our dataset is annotated\nfrom three different perspectives: the basic, commonly used 3-class\nclassification (i.e., hate, offensive or normal), the target community (i.e.,\nthe community that has been the victim of hate speech/offensive speech in the\npost), and the rationales, i.e., the portions of the post on which their\nlabelling decision (as hate, offensive or normal) is based. We utilize existing\nstate-of-the-art models and observe that even models that perform very well in\nclassification do not score high on explainability metrics like model\nplausibility and faithfulness. We also observe that models, which utilize the\nhuman rationales for training, perform better in reducing unintended bias\ntowards target communities. We have made our code and dataset public at\nhttps://github.com/punyajoy/HateXplain\n", "versions": [{"version": "v1", "created": "Fri, 18 Dec 2020 15:12:14 GMT"}], "update_date": "2020-12-21", "authors_parsed": [["Mathew", "Binny", ""], ["Saha", "Punyajoy", ""], ["Yimam", "Seid Muhie", ""], ["Biemann", "Chris", ""], ["Goyal", "Pawan", ""], ["Mukherjee", "Animesh", ""]]}, {"id": "2012.10348", "submitter": "Daniel Shapiro", "authors": "Daniel Shapiro", "title": "Small Business Classification By Name: Addressing Gender and Geographic\n  Origin Biases", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Small business classification is a difficult and important task within many\napplications, including customer segmentation. Training on small business names\nintroduces gender and geographic origin biases. A model for predicting one of\n66 business types based only upon the business name was developed in this work\n(top-1 f1-score = 60.2%). Two approaches to removing the bias from this model\nare explored: replacing given names with a placeholder token, and augmenting\nthe training data with gender-swapped examples. The results for these\napproaches is reported, and the bias in the model was reduced by hiding given\nnames from the model. However, bias reduction was accomplished at the expense\nof classification performance (top-1 f1-score = 56.6%). Augmentation of the\ntraining data with gender-swapping samples proved less effective at bias\nreduction than the name hiding approach on the evaluated dataset.\n", "versions": [{"version": "v1", "created": "Fri, 18 Dec 2020 16:46:42 GMT"}], "update_date": "2020-12-21", "authors_parsed": [["Shapiro", "Daniel", ""]]}, {"id": "2012.10390", "submitter": "Rufin VanRullen", "authors": "Rufin VanRullen and Ryota Kanai", "title": "Deep Learning and the Global Workspace Theory", "comments": "This version with improved text and figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.NE q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in deep learning have allowed Artificial Intelligence (AI) to\nreach near human-level performance in many sensory, perceptual, linguistic or\ncognitive tasks. There is a growing need, however, for novel, brain-inspired\ncognitive architectures. The Global Workspace theory refers to a large-scale\nsystem integrating and distributing information among networks of specialized\nmodules to create higher-level forms of cognition and awareness. We argue that\nthe time is ripe to consider explicit implementations of this theory using deep\nlearning techniques. We propose a roadmap based on unsupervised neural\ntranslation between multiple latent spaces (neural networks trained for\ndistinct tasks, on distinct sensory inputs and/or modalities) to create a\nunique, amodal global latent workspace (GLW). Potential functional advantages\nof GLW are reviewed, along with neuroscientific implications.\n", "versions": [{"version": "v1", "created": "Fri, 4 Dec 2020 11:36:01 GMT"}, {"version": "v2", "created": "Sat, 20 Feb 2021 00:33:38 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["VanRullen", "Rufin", ""], ["Kanai", "Ryota", ""]]}, {"id": "2012.10467", "submitter": "Sayna Ebrahimi", "authors": "Sayna Ebrahimi, William Gan, Dian Chen, Giscard Biamby, Kamyar Salahi,\n  Michael Laielli, Shizhan Zhu, Trevor Darrell", "title": "Minimax Active Learning", "comments": "Project page is available at\n  https://people.eecs.berkeley.edu/~sayna/mal.html", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Active learning aims to develop label-efficient algorithms by querying the\nmost representative samples to be labeled by a human annotator. Current active\nlearning techniques either rely on model uncertainty to select the most\nuncertain samples or use clustering or reconstruction to choose the most\ndiverse set of unlabeled examples. While uncertainty-based strategies are\nsusceptible to outliers, solely relying on sample diversity does not capture\nthe information available on the main task. In this work, we develop a\nsemi-supervised minimax entropy-based active learning algorithm that leverages\nboth uncertainty and diversity in an adversarial manner. Our model consists of\nan entropy minimizing feature encoding network followed by an entropy\nmaximizing classification layer. This minimax formulation reduces the\ndistribution gap between the labeled/unlabeled data, while a discriminator is\nsimultaneously trained to distinguish the labeled/unlabeled data. The highest\nentropy samples from the classifier that the discriminator predicts as\nunlabeled are selected for labeling. We evaluate our method on various image\nclassification and semantic segmentation benchmark datasets and show superior\nperformance over the state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Fri, 18 Dec 2020 19:03:40 GMT"}, {"version": "v2", "created": "Tue, 30 Mar 2021 15:31:03 GMT"}], "update_date": "2021-03-31", "authors_parsed": [["Ebrahimi", "Sayna", ""], ["Gan", "William", ""], ["Chen", "Dian", ""], ["Biamby", "Giscard", ""], ["Salahi", "Kamyar", ""], ["Laielli", "Michael", ""], ["Zhu", "Shizhan", ""], ["Darrell", "Trevor", ""]]}, {"id": "2012.10473", "submitter": "Tim Ritmeester", "authors": "Tim Ritmeester and Hildegard Meyer-Ortmanns", "title": "State Estimation of Power Flows for Smart Grids via Belief Propagation", "comments": "15 pages, 16 figures", "journal-ref": "Phys. Rev. E 102, 012311 (2020)", "doi": "10.1103/PhysRevE.102.012311", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Belief propagation is an algorithm that is known from statistical physics and\ncomputer science. It provides an efficient way of calculating marginals that\ninvolve large sums of products which are efficiently rearranged into nested\nproducts of sums to approximate the marginals. It allows a reliable estimation\nof the state and its variance of power grids that is needed for the control and\nforecast of power grid management. At prototypical examples of IEEE-grids we\nshow that belief propagation not only scales linearly with the grid size for\nthe state estimation itself, but also facilitates and accelerates the retrieval\nof missing data and allows an optimized positioning of measurement units. Based\non belief propagation, we give a criterion for how to assess whether other\nalgorithms, using only local information, are adequate for state estimation for\na given grid. We also demonstrate how belief propagation can be utilized for\ncoarse-graining power grids towards representations that reduce the\ncomputational effort when the coarse-grained version is integrated into a\nlarger grid. It provides a criterion for partitioning power grids into areas in\norder to minimize the error of flow estimates between different areas.\n", "versions": [{"version": "v1", "created": "Fri, 18 Dec 2020 19:22:03 GMT"}], "update_date": "2020-12-22", "authors_parsed": [["Ritmeester", "Tim", ""], ["Meyer-Ortmanns", "Hildegard", ""]]}, {"id": "2012.10485", "submitter": "Ren Wang", "authors": "Ren Wang, Tianqi Chen, Stephen Lindsly, Alnawaz Rehemtulla, Alfred\n  Hero, Indika Rajapakse", "title": "RAILS: A Robust Adversarial Immune-inspired Learning System", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial attacks against deep neural networks are continuously evolving.\nWithout effective defenses, they can lead to catastrophic failure. The\nlong-standing and arguably most powerful natural defense system is the\nmammalian immune system, which has successfully defended against attacks by\nnovel pathogens for millions of years. In this paper, we propose a new\nadversarial defense framework, called the Robust Adversarial Immune-inspired\nLearning System (RAILS). RAILS incorporates an Adaptive Immune System Emulation\n(AISE), which emulates in silico the biological mechanisms that are used to\ndefend the host against attacks by pathogens. We use RAILS to harden Deep\nk-Nearest Neighbor (DkNN) architectures against evasion attacks. Evolutionary\nprogramming is used to simulate processes in the natural immune system: B-cell\nflocking, clonal expansion, and affinity maturation. We show that the RAILS\nlearning curve exhibits similar diversity-selection learning phases as observed\nin our in vitro biological experiments. When applied to adversarial image\nclassification on three different datasets, RAILS delivers an additional\n5.62%/12.56%/4.74% robustness improvement as compared to applying DkNN alone,\nwithout appreciable loss of accuracy on clean data.\n", "versions": [{"version": "v1", "created": "Fri, 18 Dec 2020 19:47:12 GMT"}], "update_date": "2020-12-22", "authors_parsed": [["Wang", "Ren", ""], ["Chen", "Tianqi", ""], ["Lindsly", "Stephen", ""], ["Rehemtulla", "Alnawaz", ""], ["Hero", "Alfred", ""], ["Rajapakse", "Indika", ""]]}, {"id": "2012.10489", "submitter": "Joyjit Chatterjee", "authors": "Joyjit Chatterjee, Nina Dethlefs", "title": "XAI4Wind: A Multimodal Knowledge Graph Database for Explainable Decision\n  Support in Operations & Maintenance of Wind Turbines", "comments": "Updated version of knowledge graph resource paper - updates include\n  additions to the Appendix on more properties in the knowledge graph,\n  corrected typos/grammatical errors etc", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Condition-based monitoring (CBM) has been widely utilised in the wind\nindustry for monitoring operational inconsistencies and failures in turbines,\nwith techniques ranging from signal processing and vibration analysis to\nartificial intelligence (AI) models using Supervisory Control & Acquisition\n(SCADA) data. However, existing studies do not present a concrete basis to\nfacilitate explainable decision support in operations and maintenance (O&M),\nparticularly for automated decision support through recommendation of\nappropriate maintenance action reports corresponding to failures predicted by\nCBM techniques. Knowledge graph databases (KGs) model a collection of\ndomain-specific information and have played an intrinsic role for real-world\ndecision support in domains such as healthcare and finance, but have seen very\nlimited attention in the wind industry. We propose XAI4Wind, a multimodal\nknowledge graph for explainable decision support in real-world operational\nturbines and demonstrate through experiments several use-cases of the proposed\nKG towards O&M planning through interactive query and reasoning and providing\nnovel insights using graph data science algorithms. The proposed KG combines\nmultimodal knowledge like SCADA parameters and alarms with natural language\nmaintenance actions, images etc. By integrating our KG with an Explainable AI\nmodel for anomaly prediction, we show that it can provide effective\nhuman-intelligible O&M strategies for predicted operational inconsistencies in\nvarious turbine sub-components. This can help instil better trust and\nconfidence in conventionally black-box AI models. We make our KG publicly\navailable and envisage that it can serve as the building ground for providing\nautonomous decision support in the wind industry.\n", "versions": [{"version": "v1", "created": "Fri, 18 Dec 2020 19:54:19 GMT"}, {"version": "v2", "created": "Wed, 24 Feb 2021 04:38:47 GMT"}], "update_date": "2021-02-25", "authors_parsed": [["Chatterjee", "Joyjit", ""], ["Dethlefs", "Nina", ""]]}, {"id": "2012.10504", "submitter": "Zoltan Nagy", "authors": "Jose R Vazquez-Canteli, Sourav Dey, Gregor Henze, Zoltan Nagy", "title": "CityLearn: Standardizing Research in Multi-Agent Reinforcement Learning\n  for Demand Response and Urban Energy Management", "comments": "under revision", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Rapid urbanization, increasing integration of distributed renewable energy\nresources, energy storage, and electric vehicles introduce new challenges for\nthe power grid. In the US, buildings represent about 70% of the total\nelectricity demand and demand response has the potential for reducing peaks of\nelectricity by about 20%. Unlocking this potential requires control systems\nthat operate on distributed systems, ideally data-driven and model-free. For\nthis, reinforcement learning (RL) algorithms have gained increased interest in\nthe past years. However, research in RL for demand response has been lacking\nthe level of standardization that propelled the enormous progress in RL\nresearch in the computer science community. To remedy this, we created\nCityLearn, an OpenAI Gym Environment which allows researchers to implement,\nshare, replicate, and compare their implementations of RL for demand response.\nHere, we discuss this environment and The CityLearn Challenge, a RL competition\nwe organized to propel further progress in this field.\n", "versions": [{"version": "v1", "created": "Fri, 18 Dec 2020 20:41:53 GMT"}], "update_date": "2020-12-22", "authors_parsed": [["Vazquez-Canteli", "Jose R", ""], ["Dey", "Sourav", ""], ["Henze", "Gregor", ""], ["Nagy", "Zoltan", ""]]}, {"id": "2012.10506", "submitter": "Karol Suchan", "authors": "Hern\\'an Lespay and Karol Suchan", "title": "Territory Design for Dynamic Multi-Period Vehicle Routing Problem with\n  Time Windows", "comments": "arXiv admin note: text overlap with arXiv:1912.05929", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This study introduces the Territory Design for Dynamic Multi-Period Vehicle\nRouting Problem with Time Windows (TD-DMPVRPTW), motivated by a real-world\napplication at a food company's distribution center. This problem deals with\nthe design of contiguous and compact territories for delivery of orders from a\ndepot to a set of customers, with time windows, over a multi-period planning\nhorizon. Customers and their demands vary dynamically over time. The problem is\nmodeled as a mixed-integer linear program (MILP) and solved by a proposed\nheuristic. The heuristic solutions are compared with the proposed MILP\nsolutions on a set of small artificial instances and the food company's\nsolutions on a set of real-world instances. Computational results show that the\nproposed algorithm can yield high-quality solutions within moderate running\ntimes.\n", "versions": [{"version": "v1", "created": "Fri, 18 Dec 2020 20:50:32 GMT"}], "update_date": "2020-12-22", "authors_parsed": [["Lespay", "Hern\u00e1n", ""], ["Suchan", "Karol", ""]]}, {"id": "2012.10531", "submitter": "Ding Ding", "authors": "Ding Ding and H. Howie Huang", "title": "A Graph Attention Based Approach for Trajectory Prediction in\n  Multi-agent Sports Games", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work investigates the problem of multi-agents trajectory prediction.\nPrior approaches lack of capability of capturing fine-grained dependencies\namong coordinated agents. In this paper, we propose a spatial-temporal\ntrajectory prediction approach that is able to learn the strategy of a team\nwith multiple coordinated agents. In particular, we use graph-based attention\nmodel to learn the dependency of the agents. In addition, instead of utilizing\nthe recurrent networks (e.g., VRNN, LSTM), our method uses a Temporal\nConvolutional Network (TCN) as the sequential model to support long effective\nhistory and provide important features such as parallelism and stable\ngradients. We demonstrate the validation and effectiveness of our approach on\ntwo different sports game datasets: basketball and soccer datasets. The result\nshows that compared to related approaches, our model that infers the dependency\nof players yields substantially improved performance. Code is available at\nhttps://github.com/iHeartGraph/predict\n", "versions": [{"version": "v1", "created": "Fri, 18 Dec 2020 21:51:43 GMT"}], "update_date": "2020-12-22", "authors_parsed": [["Ding", "Ding", ""], ["Huang", "H. Howie", ""]]}, {"id": "2012.10540", "submitter": "Islam Akef Ebeid", "authors": "Islam Akef Ebeid, Majdi Hassan, Tingyi Wanyan, Jack Roper, Abhik Seal,\n  Ying Ding", "title": "Biomedical Knowledge Graph Refinement and Completion using Graph\n  Representation Learning and Top-K Similarity Measure", "comments": "Accepted short paper submission to iConference 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Knowledge Graphs have been one of the fundamental methods for integrating\nheterogeneous data sources. Integrating heterogeneous data sources is crucial,\nespecially in the biomedical domain, where central data-driven tasks such as\ndrug discovery rely on incorporating information from different biomedical\ndatabases. These databases contain various biological entities and relations\nsuch as proteins (PDB), genes (Gene Ontology), drugs (DrugBank), diseases\n(DDB), and protein-protein interactions (BioGRID). The process of semantically\nintegrating heterogeneous biomedical databases is often riddled with\nimperfections. The quality of data-driven drug discovery relies on the accuracy\nof the mining methods used and the data's quality as well. Thus, having\ncomplete and refined biomedical knowledge graphs is central to achieving more\naccurate drug discovery outcomes. Here we propose using the latest graph\nrepresentation learning and embedding models to refine and complete biomedical\nknowledge graphs. This preliminary work demonstrates learning discrete\nrepresentations of the integrated biomedical knowledge graph Chem2Bio2RD [3].\nWe perform a knowledge graph completion and refinement task using a simple\ntop-K cosine similarity measure between the learned embedding vectors to\npredict missing links between drugs and targets present in the data. We show\nthat this simple procedure can be used alternatively to binary classifiers in\nlink prediction.\n", "versions": [{"version": "v1", "created": "Fri, 18 Dec 2020 22:19:57 GMT"}], "update_date": "2020-12-22", "authors_parsed": [["Ebeid", "Islam Akef", ""], ["Hassan", "Majdi", ""], ["Wanyan", "Tingyi", ""], ["Roper", "Jack", ""], ["Seal", "Abhik", ""], ["Ding", "Ying", ""]]}, {"id": "2012.10544", "submitter": "Micah Goldblum", "authors": "Micah Goldblum, Dimitris Tsipras, Chulin Xie, Xinyun Chen, Avi\n  Schwarzschild, Dawn Song, Aleksander Madry, Bo Li, Tom Goldstein", "title": "Dataset Security for Machine Learning: Data Poisoning, Backdoor Attacks,\n  and Defenses", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR cs.CV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  As machine learning systems grow in scale, so do their training data\nrequirements, forcing practitioners to automate and outsource the curation of\ntraining data in order to achieve state-of-the-art performance. The absence of\ntrustworthy human supervision over the data collection process exposes\norganizations to security vulnerabilities; training data can be manipulated to\ncontrol and degrade the downstream behaviors of learned models. The goal of\nthis work is to systematically categorize and discuss a wide range of dataset\nvulnerabilities and exploits, approaches for defending against these threats,\nand an array of open problems in this space. In addition to describing various\npoisoning and backdoor threat models and the relationships among them, we\ndevelop their unified taxonomy.\n", "versions": [{"version": "v1", "created": "Fri, 18 Dec 2020 22:38:47 GMT"}, {"version": "v2", "created": "Wed, 30 Dec 2020 03:03:30 GMT"}, {"version": "v3", "created": "Sun, 28 Mar 2021 19:01:07 GMT"}, {"version": "v4", "created": "Wed, 31 Mar 2021 22:21:34 GMT"}], "update_date": "2021-04-02", "authors_parsed": [["Goldblum", "Micah", ""], ["Tsipras", "Dimitris", ""], ["Xie", "Chulin", ""], ["Chen", "Xinyun", ""], ["Schwarzschild", "Avi", ""], ["Song", "Dawn", ""], ["Madry", "Aleksander", ""], ["Li", "Bo", ""], ["Goldstein", "Tom", ""]]}, {"id": "2012.10557", "submitter": "Romil Bhardwaj", "authors": "Romil Bhardwaj, Zhengxu Xia, Ganesh Ananthanarayanan, Junchen Jiang,\n  Nikolaos Karianakis, Yuanchao Shu, Kevin Hsieh, Victor Bahl, Ion Stoica", "title": "Ekya: Continuous Learning of Video Analytics Models on Edge Compute\n  Servers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.AI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Video analytics applications use edge compute servers for the analytics of\nthe videos (for bandwidth and privacy). Compressed models that are deployed on\nthe edge servers for inference suffer from data drift, where the live video\ndata diverges from the training data. Continuous learning handles data drift by\nperiodically retraining the models on new data. Our work addresses the\nchallenge of jointly supporting inference and retraining tasks on edge servers,\nwhich requires navigating the fundamental tradeoff between the retrained\nmodel's accuracy and the inference accuracy. Our solution Ekya balances this\ntradeoff across multiple models and uses a micro-profiler to identify the\nmodels that will benefit the most by retraining. Ekya's accuracy gain compared\nto a baseline scheduler is 29% higher, and the baseline requires 4x more GPU\nresources to achieve the same accuracy as Ekya.\n", "versions": [{"version": "v1", "created": "Sat, 19 Dec 2020 00:29:22 GMT"}], "update_date": "2020-12-22", "authors_parsed": [["Bhardwaj", "Romil", ""], ["Xia", "Zhengxu", ""], ["Ananthanarayanan", "Ganesh", ""], ["Jiang", "Junchen", ""], ["Karianakis", "Nikolaos", ""], ["Shu", "Yuanchao", ""], ["Hsieh", "Kevin", ""], ["Bahl", "Victor", ""], ["Stoica", "Ion", ""]]}, {"id": "2012.10564", "submitter": "Abhishek Dubey", "authors": "Abhishek K Dubey, Michael T Young, Christopher Stanley, Dalton Lunga,\n  Jacob Hinkle", "title": "Computer-aided abnormality detection in chest radiographs in a clinical\n  setting via domain-adaptation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Deep learning (DL) models are being deployed at medical centers to aid\nradiologists for diagnosis of lung conditions from chest radiographs. Such\nmodels are often trained on a large volume of publicly available labeled\nradiographs. These pre-trained DL models' ability to generalize in clinical\nsettings is poor because of the changes in data distributions between publicly\navailable and privately held radiographs. In chest radiographs, the\nheterogeneity in distributions arises from the diverse conditions in X-ray\nequipment and their configurations used for generating the images. In the\nmachine learning community, the challenges posed by the heterogeneity in the\ndata generation source is known as domain shift, which is a mode shift in the\ngenerative model. In this work, we introduce a domain-shift detection and\nremoval method to overcome this problem. Our experimental results show the\nproposed method's effectiveness in deploying a pre-trained DL model for\nabnormality detection in chest radiographs in a clinical setting.\n", "versions": [{"version": "v1", "created": "Sat, 19 Dec 2020 01:01:48 GMT"}], "update_date": "2020-12-22", "authors_parsed": [["Dubey", "Abhishek K", ""], ["Young", "Michael T", ""], ["Stanley", "Christopher", ""], ["Lunga", "Dalton", ""], ["Hinkle", "Jacob", ""]]}, {"id": "2012.10582", "submitter": "Yining Hong", "authors": "Yining Hong, Qing Li, Daniel Ciao, Siyuan Haung, Song-Chun Zhu", "title": "Learning by Fixing: Solving Math Word Problems with Weak Supervision", "comments": null, "journal-ref": "AAAI2021", "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Previous neural solvers of math word problems (MWPs) are learned with full\nsupervision and fail to generate diverse solutions. In this paper, we address\nthis issue by introducing a \\textit{weakly-supervised} paradigm for learning\nMWPs. Our method only requires the annotations of the final answers and can\ngenerate various solutions for a single problem. To boost weakly-supervised\nlearning, we propose a novel \\textit{learning-by-fixing} (LBF) framework, which\ncorrects the misperceptions of the neural network via symbolic reasoning.\nSpecifically, for an incorrect solution tree generated by the neural network,\nthe \\textit{fixing} mechanism propagates the error from the root node to the\nleaf nodes and infers the most probable fix that can be executed to get the\ndesired answer. To generate more diverse solutions, \\textit{tree\nregularization} is applied to guide the efficient shrinkage and exploration of\nthe solution space, and a \\textit{memory buffer} is designed to track and save\nthe discovered various fixes for each problem. Experimental results on the\nMath23K dataset show the proposed LBF framework significantly outperforms\nreinforcement learning baselines in weakly-supervised learning. Furthermore, it\nachieves comparable top-1 and much better top-3/5 answer accuracies than\nfully-supervised methods, demonstrating its strength in producing diverse\nsolutions.\n", "versions": [{"version": "v1", "created": "Sat, 19 Dec 2020 03:10:21 GMT"}], "update_date": "2020-12-29", "authors_parsed": [["Hong", "Yining", ""], ["Li", "Qing", ""], ["Ciao", "Daniel", ""], ["Haung", "Siyuan", ""], ["Zhu", "Song-Chun", ""]]}, {"id": "2012.10586", "submitter": "Jianze Liang", "authors": "Jianze Liang, Chengqi Zhao, Mingxuan Wang, Xipeng Qiu, Lei Li", "title": "Finding Sparse Structures for Domain Specific Neural Machine Translation", "comments": "Accepted to AAAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural machine translation often adopts the fine-tuning approach to adapt to\nspecific domains. However, nonrestricted fine-tuning can easily degrade on the\ngeneral domain and over-fit to the target domain. To mitigate the issue, we\npropose Prune-Tune, a novel domain adaptation method via gradual pruning. It\nlearns tiny domain-specific sub-networks during fine-tuning on new domains.\nPrune-Tune alleviates the over-fitting and the degradation problem without\nmodel modification. Furthermore, Prune-Tune is able to sequentially learn a\nsingle network with multiple disjoint domain-specific sub-networks for multiple\ndomains. Empirical experiment results show that Prune-Tune outperforms several\nstrong competitors in the target domain test set without sacrificing the\nquality on the general domain in both single and multi-domain settings. The\nsource code and data are available at https://github.com/ohlionel/Prune-Tune.\n", "versions": [{"version": "v1", "created": "Sat, 19 Dec 2020 03:33:27 GMT"}, {"version": "v2", "created": "Fri, 26 Mar 2021 16:57:21 GMT"}], "update_date": "2021-03-29", "authors_parsed": [["Liang", "Jianze", ""], ["Zhao", "Chengqi", ""], ["Wang", "Mingxuan", ""], ["Qiu", "Xipeng", ""], ["Li", "Lei", ""]]}, {"id": "2012.10592", "submitter": "Lixing Tan", "authors": "Lixing Tan, Zhaohui Zhu, Jinjin Zhang", "title": "More on extension-based semantics of argumentation", "comments": "86 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  After a few decades of development, computational argumentation has become\none of the active realms in AI. This paper considers extension-based concrete\nand abstract semantics of argumentation. For concrete ones, based on Grossi and\nModgil's recent work, this paper considers some issues on graded\nextension-based semantics of abstract argumentation framework (AAF, for short).\nFirst, an alternative fundamental lemma is given, which generalizes the\ncorresponding result due to Grossi and Modgil by relaxing the constraint on\nparameters. This lemma provides a new sufficient condition for preserving\nconflict-freeness and brings a Galois adjunction between admissible sets and\ncomplete extensions, which is of vital importance in constructing some special\nextensions in terms of iterations of the defense function. Applying such a\nlemma, some flaws in Grossi and Modgil's work are corrected, and the structural\nproperty and universal definability of various extension-based semantics are\ngiven. Second, an operator so-called reduced meet modulo an ultrafilter is\npresented, which is a simple but powerful tool in exploring infinite AAFs. The\nneutrality function and the defense function, which play central roles in\nDung's abstract argumentation theory, are shown to be distributive over reduced\nmeets modulo any ultrafilter. A variety of fundamental semantics of AAFs,\nincluding conflict-free, admissible, complete and stable semantics, etc, are\nshown to be closed under this operator. Based on this fact, a number of\napplications of such operators are considered. In particular, we provide a\nsimple and uniform method to prove the universal definability of a family of\nrange related semantics. Since all graded concrete semantics considered in this\npaper are generalizations of corresponding non-graded ones, all results about\nthem obtained in this paper also hold in the traditional situation.\n", "versions": [{"version": "v1", "created": "Sat, 19 Dec 2020 04:32:19 GMT"}, {"version": "v2", "created": "Sun, 27 Dec 2020 01:41:18 GMT"}, {"version": "v3", "created": "Thu, 20 May 2021 04:58:41 GMT"}], "update_date": "2021-05-21", "authors_parsed": [["Tan", "Lixing", ""], ["Zhu", "Zhaohui", ""], ["Zhang", "Jinjin", ""]]}, {"id": "2012.10595", "submitter": "Jaehun Jung", "authors": "Jaehun Jung, Jinhong Jung, U Kang", "title": "T-GAP: Learning to Walk across Time for Temporal Knowledge Graph\n  Completion", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Temporal knowledge graphs (TKGs) inherently reflect the transient nature of\nreal-world knowledge, as opposed to static knowledge graphs. Naturally,\nautomatic TKG completion has drawn much research interests for a more realistic\nmodeling of relational reasoning. However, most of the existing mod-els for TKG\ncompletion extend static KG embeddings that donot fully exploit TKG structure,\nthus lacking in 1) account-ing for temporally relevant events already residing\nin the lo-cal neighborhood of a query, and 2) path-based inference that\nfacilitates multi-hop reasoning and better interpretability. In this paper, we\npropose T-GAP, a novel model for TKG completion that maximally utilizes both\ntemporal information and graph structure in its encoder and decoder. T-GAP\nencodes query-specific substructure of TKG by focusing on the temporal\ndisplacement between each event and the query times-tamp, and performs\npath-based inference by propagating attention through the graph. Our empirical\nexperiments demonstrate that T-GAP not only achieves superior performance\nagainst state-of-the-art baselines, but also competently generalizes to queries\nwith unseen timestamps. Through extensive qualitative analyses, we also show\nthat T-GAP enjoys from transparent interpretability, and follows human\nintuition in its reasoning process.\n", "versions": [{"version": "v1", "created": "Sat, 19 Dec 2020 04:45:32 GMT"}], "update_date": "2020-12-22", "authors_parsed": [["Jung", "Jaehun", ""], ["Jung", "Jinhong", ""], ["Kang", "U", ""]]}, {"id": "2012.10630", "submitter": "Krishnateja Killamsetty", "authors": "Krishnateja Killamsetty, Durga Sivasubramanian, Ganesh Ramakrishnan,\n  Rishabh Iyer", "title": "GLISTER: Generalization based Data Subset Selection for Efficient and\n  Robust Learning", "comments": null, "journal-ref": "Proceedings of the AAAI Conference on Artificial Intelligence 35.\n  9(2021): 8110-8118", "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Large scale machine learning and deep models are extremely data-hungry.\nUnfortunately, obtaining large amounts of labeled data is expensive, and\ntraining state-of-the-art models (with hyperparameter tuning) requires\nsignificant computing resources and time. Secondly, real-world data is noisy\nand imbalanced. As a result, several recent papers try to make the training\nprocess more efficient and robust. However, most existing work either focuses\non robustness or efficiency, but not both. In this work, we introduce Glister,\na GeneraLIzation based data Subset selecTion for Efficient and Robust learning\nframework. We formulate Glister as a mixed discrete-continuous bi-level\noptimization problem to select a subset of the training data, which maximizes\nthe log-likelihood on a held-out validation set. Next, we propose an iterative\nonline algorithm Glister-Online, which performs data selection iteratively\nalong with the parameter updates and can be applied to any loss-based learning\nalgorithm. We then show that for a rich class of loss functions including\ncross-entropy, hinge-loss, squared-loss, and logistic-loss, the inner discrete\ndata selection is an instance of (weakly) submodular optimization, and we\nanalyze conditions for which Glister-Online reduces the validation loss and\nconverges. Finally, we propose Glister-Active, an extension to batch active\nlearning, and we empirically demonstrate the performance of Glister on a wide\nrange of tasks including, (a) data selection to reduce training time, (b)\nrobust learning under label noise and imbalance settings, and (c) batch-active\nlearning with several deep and shallow models. We show that our framework\nimproves upon state of the art both in efficiency and accuracy (in cases (a)\nand (c)) and is more efficient compared to other state-of-the-art robust\nlearning algorithms in case (b).\n", "versions": [{"version": "v1", "created": "Sat, 19 Dec 2020 08:41:34 GMT"}, {"version": "v2", "created": "Tue, 22 Dec 2020 02:23:54 GMT"}, {"version": "v3", "created": "Fri, 15 Jan 2021 21:00:10 GMT"}, {"version": "v4", "created": "Fri, 11 Jun 2021 22:45:42 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Killamsetty", "Krishnateja", ""], ["Sivasubramanian", "Durga", ""], ["Ramakrishnan", "Ganesh", ""], ["Iyer", "Rishabh", ""]]}, {"id": "2012.10638", "submitter": "Liang Xin", "authors": "Liang Xin, Wen Song, Zhiguang Cao, Jie Zhang", "title": "Multi-Decoder Attention Model with Embedding Glimpse for Solving Vehicle\n  Routing Problems", "comments": "Accepted by AAAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present a novel deep reinforcement learning method to learn construction\nheuristics for vehicle routing problems. In specific, we propose a\nMulti-Decoder Attention Model (MDAM) to train multiple diverse policies, which\neffectively increases the chance of finding good solutions compared with\nexisting methods that train only one policy. A customized beam search strategy\nis designed to fully exploit the diversity of MDAM. In addition, we propose an\nEmbedding Glimpse layer in MDAM based on the recursive nature of construction,\nwhich can improve the quality of each policy by providing more informative\nembeddings. Extensive experiments on six different routing problems show that\nour method significantly outperforms the state-of-the-art deep learning based\nmodels.\n", "versions": [{"version": "v1", "created": "Sat, 19 Dec 2020 09:32:13 GMT"}], "update_date": "2020-12-22", "authors_parsed": [["Xin", "Liang", ""], ["Song", "Wen", ""], ["Cao", "Zhiguang", ""], ["Zhang", "Jie", ""]]}, {"id": "2012.10700", "submitter": "Quentin Cohen-Solal", "authors": "Quentin Cohen-Solal and Tristan Cazenave", "title": "Minimax Strikes Back", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Reinforcement Learning (DRL) reaches a superhuman level of play in many\ncomplete information games. The state of the art search algorithm used in\ncombination with DRL is Monte Carlo Tree Search (MCTS). We take another\napproach to DRL using a Minimax algorithm instead of MCTS and learning only the\nevaluation of states, not the policy. We show that for multiple games it is\ncompetitive with the state of the art DRL for the learning performances and for\nthe confrontations.\n", "versions": [{"version": "v1", "created": "Sat, 19 Dec 2020 14:42:41 GMT"}], "update_date": "2020-12-22", "authors_parsed": [["Cohen-Solal", "Quentin", ""], ["Cazenave", "Tristan", ""]]}, {"id": "2012.10713", "submitter": "Han Zhao", "authors": "Han Zhao, Chen Dan, Bryon Aragam, Tommi S. Jaakkola, Geoffrey J.\n  Gordon, Pradeep Ravikumar", "title": "Fundamental Limits and Tradeoffs in Invariant Representation Learning", "comments": "Updated results in the regression setting to fully characterize the\n  frontier. Additional numerical experiments", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many machine learning applications, e.g., privacy-preserving learning,\nalgorithmic fairness and domain adaptation/generalization, involve learning the\nso-called invariant representations that achieve two competing goals: To\nmaximize information or accuracy with respect to a target while simultaneously\nmaximizing invariance or independence with respect to a set of protected\nfeatures (e.g.\\ for fairness, privacy, etc). Despite its abundant applications\nin the aforementioned domains, theoretical understanding on the limits and\ntradeoffs of invariant representations is still severely lacking. In this\npaper, we provide an information theoretic analysis of this general and\nimportant problem under both classification and regression settings. In both\ncases, we analyze the inherent tradeoffs between accuracy and invariance by\nproviding a geometric characterization of the feasible region in the\ninformation plane, where we connect the geometric properties of this feasible\nregion to the fundamental limitations of the tradeoff problem. In the\nregression setting, we further give a complete and exact characterization of\nthe frontier between accuracy and invariance. Although our contributions are\nmainly theoretical, we also demonstrate the practical applications of our\nresults in certifying the suboptimality of certain representation learning\nalgorithms in both classification and regression tasks. Our results shed new\nlight on this fundamental problem by providing insights on the interplay\nbetween accuracy and invariance. These results deepen our understanding of this\nfundamental problem and may be useful in guiding the design of future\nrepresentation learning algorithms.\n", "versions": [{"version": "v1", "created": "Sat, 19 Dec 2020 15:24:04 GMT"}, {"version": "v2", "created": "Fri, 23 Jul 2021 17:27:12 GMT"}], "update_date": "2021-07-26", "authors_parsed": [["Zhao", "Han", ""], ["Dan", "Chen", ""], ["Aragam", "Bryon", ""], ["Jaakkola", "Tommi S.", ""], ["Gordon", "Geoffrey J.", ""], ["Ravikumar", "Pradeep", ""]]}, {"id": "2012.10716", "submitter": "Baiyu Peng", "authors": "Baiyu Peng, Yao Mu, Yang Guan, Shengbo Eben Li, Yuming Yin, Jianyu\n  Chen", "title": "Model-Based Actor-Critic with Chance Constraint for Stochastic System", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Safety is essential for reinforcement learning (RL) applied in real-world\nsituations. Chance constraints are suitable to represent the safety\nrequirements in stochastic systems. Previous chance-constrained RL methods\nusually have a low convergence rate, or only learn a conservative policy. In\nthis paper, we propose a model-based chance constrained actor-critic (CCAC)\nalgorithm which can efficiently learn a safe and non-conservative policy.\nDifferent from existing methods that optimize a conservative lower bound, CCAC\ndirectly solves the original chance constrained problems, where the objective\nfunction and safe probability is simultaneously optimized with adaptive\nweights. In order to improve the convergence rate, CCAC utilizes the gradient\nof dynamic model to accelerate policy optimization. The effectiveness of CCAC\nis demonstrated by a stochastic car-following task. Experiments indicate that\ncompared with previous RL methods, CCAC improves the performance while\nguaranteeing safety, with a five times faster convergence rate. It also has 100\ntimes higher online computation efficiency than traditional safety techniques\nsuch as stochastic model predictive control.\n", "versions": [{"version": "v1", "created": "Sat, 19 Dec 2020 15:46:50 GMT"}, {"version": "v2", "created": "Tue, 16 Mar 2021 04:34:04 GMT"}], "update_date": "2021-03-17", "authors_parsed": [["Peng", "Baiyu", ""], ["Mu", "Yao", ""], ["Guan", "Yang", ""], ["Li", "Shengbo Eben", ""], ["Yin", "Yuming", ""], ["Chen", "Jianyu", ""]]}, {"id": "2012.10773", "submitter": "Lingfeng Tao", "authors": "Lingfeng Tao, Michael Bowman, Jiucai Zhang, Xiaoli Zhang", "title": "Forming Human-Robot Cooperation for Tasks with General Goal using\n  Evolutionary Value Learning", "comments": "submitted to IROS 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In Human-Robot Cooperation (HRC), the robot cooperates with humans to\naccomplish the task together. Existing approaches assume the human has a\nspecific goal during the cooperation, and the robot infers and acts toward it.\nHowever, in real-world environments, a human usually only has a general goal\n(e.g., general direction or area in motion planning) at the beginning of the\ncooperation, which needs to be clarified to a specific goal (e.g., an exact\nposition) during cooperation. The specification process is interactive and\ndynamic, which depends on the environment and the partners' behavior. The robot\nthat does not consider the goal specification process may cause frustration to\nthe human partner, elongate the time to come to an agreement, and compromise or\nfail team performance. We present the Evolutionary Value Learning (EVL)\napproach, which uses a State-based Multivariate Bayesian Inference method to\nmodel the dynamics of the goal specification process in HRC. EVL can actively\nenhance the process of goal specification and cooperation formation. This\nenables the robot to simultaneously help the human specify the goal and learn a\ncooperative policy in a Deep Reinforcement Learning (DRL) manner. In a dynamic\nball balancing task with real human subjects, the robot equipped with EVL\noutperforms existing methods with faster goal specification processes and\nbetter team performance.\n", "versions": [{"version": "v1", "created": "Sat, 19 Dec 2020 20:27:09 GMT"}, {"version": "v2", "created": "Sat, 6 Feb 2021 18:51:04 GMT"}, {"version": "v3", "created": "Tue, 30 Mar 2021 16:47:28 GMT"}], "update_date": "2021-03-31", "authors_parsed": [["Tao", "Lingfeng", ""], ["Bowman", "Michael", ""], ["Zhang", "Jiucai", ""], ["Zhang", "Xiaoli", ""]]}, {"id": "2012.10776", "submitter": "Kevin Denamgana\\\"i", "authors": "Kevin Denamgana\\\"i and James Alfred Walker", "title": "On (Emergent) Systematic Generalisation and Compositionality in Visual\n  Referential Games with Straight-Through Gumbel-Softmax Estimator", "comments": "Accepted at 4th NeurIPS Workshop on Emergent Communication (EmeCom @\n  NeurIPS 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The drivers of compositionality in artificial languages that emerge when two\n(or more) agents play a non-visual referential game has been previously\ninvestigated using approaches based on the REINFORCE algorithm and the (Neural)\nIterated Learning Model. Following the more recent introduction of the\n\\textit{Straight-Through Gumbel-Softmax} (ST-GS) approach, this paper\ninvestigates to what extent the drivers of compositionality identified so far\nin the field apply in the ST-GS context and to what extent do they translate\ninto (emergent) systematic generalisation abilities, when playing a visual\nreferential game. Compositionality and the generalisation abilities of the\nemergent languages are assessed using topographic similarity and zero-shot\ncompositional tests. Firstly, we provide evidence that the test-train split\nstrategy significantly impacts the zero-shot compositional tests when dealing\nwith visual stimuli, whilst it does not when dealing with symbolic ones.\nSecondly, empirical evidence shows that using the ST-GS approach with small\nbatch sizes and an overcomplete communication channel improves compositionality\nin the emerging languages. Nevertheless, while shown robust with symbolic\nstimuli, the effect of the batch size is not so clear-cut when dealing with\nvisual stimuli. Our results also show that not all overcomplete communication\nchannels are created equal. Indeed, while increasing the maximum sentence\nlength is found to be beneficial to further both compositionality and\ngeneralisation abilities, increasing the vocabulary size is found detrimental.\nFinally, a lack of correlation between the language compositionality at\ntraining-time and the agents' generalisation abilities is observed in the\ncontext of discriminative referential games with visual stimuli. This is\nsimilar to previous observations in the field using the generative variant with\nsymbolic stimuli.\n", "versions": [{"version": "v1", "created": "Sat, 19 Dec 2020 20:40:09 GMT"}], "update_date": "2020-12-22", "authors_parsed": [["Denamgana\u00ef", "Kevin", ""], ["Walker", "James Alfred", ""]]}, {"id": "2012.10791", "submitter": "James Queeney", "authors": "James Queeney, Ioannis Ch. Paschalidis, Christos G. Cassandras", "title": "Uncertainty-Aware Policy Optimization: A Robust, Adaptive Trust Region\n  Approach", "comments": "To appear in Proceedings of the Thirty-Fifth AAAI Conference on\n  Artificial Intelligence (AAAI-21)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In order for reinforcement learning techniques to be useful in real-world\ndecision making processes, they must be able to produce robust performance from\nlimited data. Deep policy optimization methods have achieved impressive results\non complex tasks, but their real-world adoption remains limited because they\noften require significant amounts of data to succeed. When combined with small\nsample sizes, these methods can result in unstable learning due to their\nreliance on high-dimensional sample-based estimates. In this work, we develop\ntechniques to control the uncertainty introduced by these estimates. We\nleverage these techniques to propose a deep policy optimization approach\ndesigned to produce stable performance even when data is scarce. The resulting\nalgorithm, Uncertainty-Aware Trust Region Policy Optimization, generates robust\npolicy updates that adapt to the level of uncertainty present throughout the\nlearning process.\n", "versions": [{"version": "v1", "created": "Sat, 19 Dec 2020 21:51:23 GMT"}], "update_date": "2020-12-22", "authors_parsed": [["Queeney", "James", ""], ["Paschalidis", "Ioannis Ch.", ""], ["Cassandras", "Christos G.", ""]]}, {"id": "2012.10800", "submitter": "Oliver Richardson", "authors": "Oliver Richardson, Joseph Y Halpern", "title": "Probabilistic Dependency Graphs", "comments": "5 figures, 7 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.IT math.IT", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We introduce Probabilistic Dependency Graphs (PDGs), a new class of directed\ngraphical models. PDGs can capture inconsistent beliefs in a natural way and\nare more modular than Bayesian Networks (BNs), in that they make it easier to\nincorporate new information and restructure the representation. We show by\nexample how PDGs are an especially natural modeling tool. We provide three\nsemantics for PDGs, each of which can be derived from a scoring function (on\njoint distributions over the variables in the network) that can be viewed as\nrepresenting a distribution's incompatibility with the PDG. For the PDG\ncorresponding to a BN, this function is uniquely minimized by the distribution\nthe BN represents, showing that PDG semantics extend BN semantics. We show\nfurther that factor graphs and their exponential families can also be\nfaithfully represented as PDGs, while there are significant barriers to\nmodeling a PDG with a factor graph.\n", "versions": [{"version": "v1", "created": "Sat, 19 Dec 2020 22:29:49 GMT"}], "update_date": "2020-12-22", "authors_parsed": [["Richardson", "Oliver", ""], ["Halpern", "Joseph Y", ""]]}, {"id": "2012.10820", "submitter": "Kai Wang", "authors": "Kai Wang, Chunxu Shen, Wenye Ma", "title": "AdnFM: An Attentive DenseNet based Factorization Machine for CTR\n  Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.IR cs.SI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we consider the Click-Through-Rate (CTR) prediction problem.\nFactorization Machines and their variants consider pair-wise feature\ninteractions, but normally we won't do high-order feature interactions using FM\ndue to high time complexity. Given the success of deep neural networks (DNNs)\nin many fields, researchers have proposed several DNN-based models to learn\nhigh-order feature interactions. Multi-layer perceptrons (MLP) have been widely\nemployed to learn reliable mappings from feature embeddings to final logits. In\nthis paper, we aim to explore more about these high-order features\ninteractions. However, high-order feature interaction deserves more attention\nand further development. Inspired by the great achievements of Densely\nConnected Convolutional Networks (DenseNet) in computer vision, we propose a\nnovel model called Attentive DenseNet based Factorization Machines (AdnFM).\nAdnFM can extract more comprehensive deep features by using all the hidden\nlayers from a feed-forward neural network as implicit high-order features, then\nselects dominant features via an attention mechanism. Also, high-order\ninteractions in the implicit way using DNNs are more cost-efficient than in the\nexplicit way, for example in FM. Extensive experiments on two real-world\ndatasets show that the proposed model can effectively improve the performance\nof CTR prediction.\n", "versions": [{"version": "v1", "created": "Sun, 20 Dec 2020 01:00:39 GMT"}], "update_date": "2020-12-22", "authors_parsed": [["Wang", "Kai", ""], ["Shen", "Chunxu", ""], ["Ma", "Wenye", ""]]}, {"id": "2012.10840", "submitter": "Angela Wang", "authors": "Matthew T. Dearing, Xiaoyan Wang", "title": "Analyzing the Performance of Graph Neural Networks with Pipe Parallelism", "comments": "Proceedings of the conference MLSys'21 Workshop on Graph Neural\n  Networks and Systems (GNNSys'21), San Jose, CA, USA, 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.DC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Many interesting datasets ubiquitous in machine learning and deep learning\ncan be described via graphs. As the scale and complexity of graph-structured\ndatasets increase, such as in expansive social networks, protein folding,\nchemical interaction networks, and material phase transitions, improving the\nefficiency of the machine learning techniques applied to these is crucial. In\nthis study, we focus on Graph Neural Networks (GNN) that have found great\nsuccess in tasks such as node or edge classification and link prediction.\nHowever, standard GNN models have scaling limits due to necessary recursive\ncalculations performed through dense graph relationships that lead to memory\nand runtime bottlenecks. While new approaches for processing larger networks\nare needed to advance graph techniques, and several have been proposed, we\nstudy how GNNs could be parallelized using existing tools and frameworks that\nare known to be successful in the deep learning community. In particular, we\ninvestigate applying pipeline parallelism to GNN models with GPipe, introduced\nby Google in 2018.\n", "versions": [{"version": "v1", "created": "Sun, 20 Dec 2020 04:20:38 GMT"}, {"version": "v2", "created": "Mon, 5 Apr 2021 16:59:33 GMT"}], "update_date": "2021-04-06", "authors_parsed": [["Dearing", "Matthew T.", ""], ["Wang", "Xiaoyan", ""]]}, {"id": "2012.10853", "submitter": "Faisal Almutairi", "authors": "Faisal M. Almutairi, Yunlong Wang, Dong Wang, Emily Zhao, Nicholas D.\n  Sidiropoulos", "title": "eTREE: Learning Tree-structured Embeddings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Matrix factorization (MF) plays an important role in a wide range of machine\nlearning and data mining models. MF is commonly used to obtain item embeddings\nand feature representations due to its ability to capture correlations and\nhigher-order statistical dependencies across dimensions. In many applications,\nthe categories of items exhibit a hierarchical tree structure. For instance,\nhuman diseases can be divided into coarse categories, e.g., bacterial, and\nviral. These categories can be further divided into finer categories, e.g.,\nviral infections can be respiratory, gastrointestinal, and exanthematous viral\ndiseases. In e-commerce, products, movies, books, etc., are grouped into\nhierarchical categories, e.g., clothing items are divided by gender, then by\ntype (formal, casual, etc.). While the tree structure and the categories of the\ndifferent items may be known in some applications, they have to be learned\ntogether with the embeddings in many others. In this work, we propose eTREE, a\nmodel that incorporates the (usually ignored) tree structure to enhance the\nquality of the embeddings. We leverage the special uniqueness properties of\nNonnegative MF (NMF) to prove identifiability of eTREE. The proposed model not\nonly exploits the tree structure prior, but also learns the hierarchical\nclustering in an unsupervised data-driven fashion. We derive an efficient\nalgorithmic solution and a scalable implementation of eTREE that exploits\nparallel computing, computation caching, and warm start strategies. We showcase\nthe effectiveness of eTREE on real data from various application domains:\nhealthcare, recommender systems, and education. We also demonstrate the\nmeaningfulness of the tree obtained from eTREE by means of domain experts\ninterpretation.\n", "versions": [{"version": "v1", "created": "Sun, 20 Dec 2020 06:06:08 GMT"}], "update_date": "2020-12-22", "authors_parsed": [["Almutairi", "Faisal M.", ""], ["Wang", "Yunlong", ""], ["Wang", "Dong", ""], ["Zhao", "Emily", ""], ["Sidiropoulos", "Nicholas D.", ""]]}, {"id": "2012.10858", "submitter": "Yang Liu", "authors": "Yang Liu, Zhengxing Chen, Kittipat Virochsiri, Juan Wang, Jiahao Wu,\n  Feng Liang", "title": "Reinforcement Learning-based Product Delivery Frequency Control", "comments": "In 35th AAAI Conference on Artificial Intelligence, February 2-9,\n  2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Frequency control is an important problem in modern recommender systems. It\ndictates the delivery frequency of recommendations to maintain product quality\nand efficiency. For example, the frequency of delivering promotional\nnotifications impacts daily metrics as well as the infrastructure resource\nconsumption (e.g. CPU and memory usage). There remain open questions on what\nobjective we should optimize to represent business values in the long term\nbest, and how we should balance between daily metrics and resource consumption\nin a dynamically fluctuating environment. We propose a personalized methodology\nfor the frequency control problem, which combines long-term value optimization\nusing reinforcement learning (RL) with a robust volume control technique we\ntermed \"Effective Factor\". We demonstrate statistically significant improvement\nin daily metrics and resource efficiency by our method in several notification\napplications at a scale of billions of users. To our best knowledge, our study\nrepresents the first deep RL application on the frequency control problem at\nsuch an industrial scale.\n", "versions": [{"version": "v1", "created": "Sun, 20 Dec 2020 07:22:34 GMT"}], "update_date": "2020-12-22", "authors_parsed": [["Liu", "Yang", ""], ["Chen", "Zhengxing", ""], ["Virochsiri", "Kittipat", ""], ["Wang", "Juan", ""], ["Wu", "Jiahao", ""], ["Liang", "Feng", ""]]}, {"id": "2012.10861", "submitter": "Lei Liu", "authors": "Lei Liu, Shunqi Huang and Brian M. Kurkoski", "title": "Memory AMP", "comments": "30 pages, 9 figures, submitted to IEEE Trans. on Information Theory\n  for possible publication. [Memory AMP inherits the strengths of AMP and\n  OAMP/VAMP such as low complexity, Bayes optimality and applicability to\n  unitarily-inavariant matrices, while avoiding the weakness of AMP (e.g.\n  limited to IID matrices) and OAMP/VAMP (e.g. needs high-complexity LMMSE).]", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.AI cs.LG eess.SP math.IT math.ST stat.TH", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Approximate message passing (AMP) is a low-cost iterative\nparameter-estimation technique for certain high-dimensional linear systems with\nnon-Gaussian distributions. However, AMP only applies to independent\nidentically distributed (IID) transform matrices, but may become unreliable\n(e.g. perform poorly or even diverge) for other matrix ensembles, especially\nfor ill-conditioned ones. To handle this difficulty, orthogonal/vector AMP\n(OAMP/VAMP) was proposed for general right-unitarily-invariant matrices.\nHowever, the Bayes-optimal OAMP/VAMP requires high-complexity linear minimum\nmean square error (MMSE) estimator. This limits the application of OAMP/VAMP to\nlarge-scale systems.\n  To solve the disadvantages of AMP and OAMP/VAMP, this paper proposes a memory\nAMP (MAMP), in which a long-memory matched filter is proposed for interference\nsuppression. The complexity of MAMP is comparable to AMP. The asymptotic\nGaussianity of estimation errors in MAMP is guaranteed by the orthogonality\nprinciple. A state evolution is derived to asymptotically characterize the\nperformance of MAMP. Based on state evolution, the relaxation parameters and\ndamping vector in MAMP are optimized. For all right-unitarily-invariant\nmatrices, the optimized MAMP converges to the high-complexity OAMP/VAMP, and\nthus is Bayes-optimal if it has a unique fixed point. Finally, simulations are\nprovided to verify the validity and accuracy of the theoretical results.\n", "versions": [{"version": "v1", "created": "Sun, 20 Dec 2020 07:42:15 GMT"}, {"version": "v2", "created": "Wed, 10 Feb 2021 14:31:38 GMT"}, {"version": "v3", "created": "Thu, 3 Jun 2021 04:08:05 GMT"}], "update_date": "2021-06-04", "authors_parsed": [["Liu", "Lei", ""], ["Huang", "Shunqi", ""], ["Kurkoski", "Brian M.", ""]]}, {"id": "2012.10877", "submitter": "Nuo Chen", "authors": "Nuo Chen, Fenglin Liu, Chenyu You, Peilin Zhou, Yuexian Zou", "title": "Adaptive Bi-directional Attention: Exploring Multi-Granularity\n  Representations for Machine Reading Comprehension", "comments": "five paes, four figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recently, the attention-enhanced multi-layer encoder, such as Transformer,\nhas been extensively studied in Machine Reading Comprehension (MRC). To predict\nthe answer, it is common practice to employ a predictor to draw information\nonly from the final encoder layer which generates the \\textit{coarse-grained}\nrepresentations of the source sequences, i.e., passage and question. Previous\nstudies have shown that the representation of source sequence becomes more\n\\textit{coarse-grained} from \\textit{fine-grained} as the encoding layer\nincreases. It is generally believed that with the growing number of layers in\ndeep neural networks, the encoding process will gather relevant information for\neach location increasingly, resulting in more \\textit{coarse-grained}\nrepresentations, which adds the likelihood of similarity to other locations\n(referring to homogeneity). Such a phenomenon will mislead the model to make\nwrong judgments so as to degrade the performance. To this end, we propose a\nnovel approach called Adaptive Bidirectional Attention, which adaptively\nexploits the source representations of different levels to the predictor.\nExperimental results on the benchmark dataset, SQuAD 2.0 demonstrate the\neffectiveness of our approach, and the results are better than the previous\nstate-of-the-art model by 2.5$\\%$ EM and 2.3$\\%$ F1 scores.\n", "versions": [{"version": "v1", "created": "Sun, 20 Dec 2020 09:31:35 GMT"}, {"version": "v2", "created": "Tue, 2 Feb 2021 08:42:32 GMT"}], "update_date": "2021-02-03", "authors_parsed": [["Chen", "Nuo", ""], ["Liu", "Fenglin", ""], ["You", "Chenyu", ""], ["Zhou", "Peilin", ""], ["Zou", "Yuexian", ""]]}, {"id": "2012.10890", "submitter": "Guoqing Wang", "authors": "Chao Yang, Guoqing Wang, Dongsheng Li, Huawei Shen, Su Feng, Bin Jiang", "title": "PPGN: Phrase-Guided Proposal Generation Network For Referring Expression\n  Comprehension", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.MM", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Reference expression comprehension (REC) aims to find the location that the\nphrase refer to in a given image. Proposal generation and proposal\nrepresentation are two effective techniques in many two-stage REC methods.\nHowever, most of the existing works only focus on proposal representation and\nneglect the importance of proposal generation. As a result, the low-quality\nproposals generated by these methods become the performance bottleneck in REC\ntasks. In this paper, we reconsider the problem of proposal generation, and\npropose a novel phrase-guided proposal generation network (PPGN). The main\nimplementation principle of PPGN is refining visual features with text and\ngenerate proposals through regression. Experiments show that our method is\neffective and achieve SOTA performance in benchmark datasets.\n", "versions": [{"version": "v1", "created": "Sun, 20 Dec 2020 11:21:06 GMT"}], "update_date": "2020-12-22", "authors_parsed": [["Yang", "Chao", ""], ["Wang", "Guoqing", ""], ["Li", "Dongsheng", ""], ["Shen", "Huawei", ""], ["Feng", "Su", ""], ["Jiang", "Bin", ""]]}, {"id": "2012.10923", "submitter": "Christian Tomani", "authors": "Christian Tomani, Florian Buettner", "title": "Towards Trustworthy Predictions from Deep Neural Networks with Fast\n  Adversarial Calibration", "comments": "In Thirty-Fifth AAAI Conference on Artificial Intelligence\n  (AAAI-2021). Code available at https://github.com/tochris/falcon", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To facilitate a wide-spread acceptance of AI systems guiding decision making\nin real-world applications, trustworthiness of deployed models is key. That is,\nit is crucial for predictive models to be uncertainty-aware and yield\nwell-calibrated (and thus trustworthy) predictions for both in-domain samples\nas well as under domain shift. Recent efforts to account for predictive\nuncertainty include post-processing steps for trained neural networks, Bayesian\nneural networks as well as alternative non-Bayesian approaches such as ensemble\napproaches and evidential deep learning. Here, we propose an efficient yet\ngeneral modelling approach for obtaining well-calibrated, trustworthy\nprobabilities for samples obtained after a domain shift. We introduce a new\ntraining strategy combining an entropy-encouraging loss term with an\nadversarial calibration loss term and demonstrate that this results in\nwell-calibrated and technically trustworthy predictions for a wide range of\ndomain drifts. We comprehensively evaluate previously proposed approaches on\ndifferent data modalities, a large range of data sets including sequence data,\nnetwork architectures and perturbation strategies. We observe that our\nmodelling approach substantially outperforms existing state-of-the-art\napproaches, yielding well-calibrated predictions under domain drift.\n", "versions": [{"version": "v1", "created": "Sun, 20 Dec 2020 13:39:29 GMT"}, {"version": "v2", "created": "Tue, 2 Mar 2021 19:27:46 GMT"}], "update_date": "2021-03-04", "authors_parsed": [["Tomani", "Christian", ""], ["Buettner", "Florian", ""]]}, {"id": "2012.10928", "submitter": "Milad Moradi", "authors": "Milad Moradi, Matthias Samwald", "title": "Explaining Black-box Models for Biomedical Text Classification", "comments": null, "journal-ref": null, "doi": "10.1109/JBHI.2021.3056748", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a novel method named Biomedical Confident Itemsets\nExplanation (BioCIE), aiming at post-hoc explanation of black-box machine\nlearning models for biomedical text classification. Using sources of domain\nknowledge and a confident itemset mining method, BioCIE discretizes the\ndecision space of a black-box into smaller subspaces and extracts semantic\nrelationships between the input text and class labels in different subspaces.\nConfident itemsets discover how biomedical concepts are related to class labels\nin the black-box's decision space. BioCIE uses the itemsets to approximate the\nblack-box's behavior for individual predictions. Optimizing fidelity,\ninterpretability, and coverage measures, BioCIE produces class-wise\nexplanations that represent decision boundaries of the black-box. Results of\nevaluations on various biomedical text classification tasks and black-box\nmodels demonstrated that BioCIE can outperform perturbation-based and decision\nset methods in terms of producing concise, accurate, and interpretable\nexplanations. BioCIE improved the fidelity of instance-wise and class-wise\nexplanations by 11.6% and 7.5%, respectively. It also improved the\ninterpretability of explanations by 8%. BioCIE can be effectively used to\nexplain how a black-box biomedical text classification model semantically\nrelates input texts to class labels. The source code and supplementary material\nare available at https://github.com/mmoradi-iut/BioCIE.\n", "versions": [{"version": "v1", "created": "Sun, 20 Dec 2020 13:58:52 GMT"}], "update_date": "2021-02-08", "authors_parsed": [["Moradi", "Milad", ""], ["Samwald", "Matthias", ""]]}, {"id": "2012.10940", "submitter": "Angelos Charalambidis", "authors": "Angelos Charalambidis, Giorgos Papadimitriou, Panos Rondogiannis,\n  Antonis Troumpoukis", "title": "Lexicographic Logic: a Many-valued Logic for Preference Representation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Logical formalisms provide a natural and concise means for specifying and\nreasoning about preferences. In this paper, we propose lexicographic logic, an\nextension of classical propositional logic that can express a variety of\npreferences, most notably lexicographic ones. The proposed logic supports a\nsimple new connective whose semantics can be defined in terms of finite lists\nof truth values. We demonstrate that, despite the well-known theoretical\nlimitations that pose barriers to the quantitative representation of\nlexicographic preferences, there exists a subset of the rational numbers over\nwhich the proposed new connective can be naturally defined. Lexicographic logic\ncan be used to define in a simple way some well-known preferential operators,\nlike \"$A$ and if possible $B$\", and \"$A$ or failing that $B$\". Moreover, many\nother hierarchical preferential operators can be defined using a systematic\napproach. We argue that the new logic is an effective formalism for ranking\nquery results according to the satisfaction level of user preferences.\n", "versions": [{"version": "v1", "created": "Sun, 20 Dec 2020 14:42:04 GMT"}], "update_date": "2020-12-22", "authors_parsed": [["Charalambidis", "Angelos", ""], ["Papadimitriou", "Giorgos", ""], ["Rondogiannis", "Panos", ""], ["Troumpoukis", "Antonis", ""]]}, {"id": "2012.10941", "submitter": "Lucas Ventura", "authors": "Lucas Ventura, Amanda Duarte, Xavier Giro-i-Nieto", "title": "Can Everybody Sign Now? Exploring Sign Language Video Generation from 2D\n  Poses", "comments": "Video here: https://youtu.be/4ve1sGzWl2g", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recent work have addressed the generation of human poses represented by 2D/3D\ncoordinates of human joints for sign language. We use the state of the art in\nDeep Learning for motion transfer and evaluate them on How2Sign, an American\nSign Language dataset, to generate videos of signers performing sign language\ngiven a 2D pose skeleton. We evaluate the generated videos quantitatively and\nqualitatively showing that the current models are not enough to generated\nadequate videos for Sign Language due to lack of detail in hands.\n", "versions": [{"version": "v1", "created": "Sun, 20 Dec 2020 14:43:32 GMT"}, {"version": "v2", "created": "Mon, 4 Jan 2021 14:44:33 GMT"}], "update_date": "2021-01-05", "authors_parsed": [["Ventura", "Lucas", ""], ["Duarte", "Amanda", ""], ["Giro-i-Nieto", "Xavier", ""]]}, {"id": "2012.10986", "submitter": "Aditya Jain", "authors": "Aditya Jain, Manish Ravula, Joydeep Ghosh", "title": "Biased Models Have Biased Explanations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We study fairness in Machine Learning (FairML) through the lens of\nattribute-based explanations generated for machine learning models. Our\nhypothesis is: Biased Models have Biased Explanations. To establish that, we\nfirst translate existing statistical notions of group fairness and define these\nnotions in terms of explanations given by the model. Then, we propose a novel\nway of detecting (un)fairness for any black box model. We further look at\npost-processing techniques for fairness and reason how explanations can be used\nto make a bias mitigation technique more individually fair. We also introduce a\nnovel post-processing mitigation technique which increases individual fairness\nin recourse while maintaining group level fairness.\n", "versions": [{"version": "v1", "created": "Sun, 20 Dec 2020 18:09:45 GMT"}], "update_date": "2020-12-22", "authors_parsed": [["Jain", "Aditya", ""], ["Ravula", "Manish", ""], ["Ghosh", "Joydeep", ""]]}, {"id": "2012.10988", "submitter": "Christian Tomani", "authors": "Christian Tomani, Sebastian Gruber, Muhammed Ebrar Erdem, Daniel\n  Cremers, Florian Buettner", "title": "Post-hoc Uncertainty Calibration for Domain Drift Scenarios", "comments": "In Proceedings of the IEEE/CVF Conference on Computer Vision and\n  Pattern Recognition (CVPR), 2021. Code available at\n  https://github.com/tochris/calibration-domain-drift", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the problem of uncertainty calibration. While standard deep neural\nnetworks typically yield uncalibrated predictions, calibrated confidence scores\nthat are representative of the true likelihood of a prediction can be achieved\nusing post-hoc calibration methods. However, to date the focus of these\napproaches has been on in-domain calibration. Our contribution is two-fold.\nFirst, we show that existing post-hoc calibration methods yield highly\nover-confident predictions under domain shift. Second, we introduce a simple\nstrategy where perturbations are applied to samples in the validation set\nbefore performing the post-hoc calibration step. In extensive experiments, we\ndemonstrate that this perturbation step results in substantially better\ncalibration under domain shift on a wide range of architectures and modelling\ntasks.\n", "versions": [{"version": "v1", "created": "Sun, 20 Dec 2020 18:21:13 GMT"}, {"version": "v2", "created": "Wed, 23 Jun 2021 15:01:51 GMT"}], "update_date": "2021-06-24", "authors_parsed": [["Tomani", "Christian", ""], ["Gruber", "Sebastian", ""], ["Erdem", "Muhammed Ebrar", ""], ["Cremers", "Daniel", ""], ["Buettner", "Florian", ""]]}, {"id": "2012.11025", "submitter": "Abhishek Singh", "authors": "Abhishek Singh, Ayush Chopra, Vivek Sharma, Ethan Garza, Emily Zhang,\n  Praneeth Vepakomma, Ramesh Raskar", "title": "DISCO: Dynamic and Invariant Sensitive Channel Obfuscation for deep\n  neural networks", "comments": "Presented at CVPR 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent deep learning models have shown remarkable performance in image\nclassification. While these deep learning systems are getting closer to\npractical deployment, the common assumption made about data is that it does not\ncarry any sensitive information. This assumption may not hold for many\npractical cases, especially in the domain where an individual's personal\ninformation is involved, like healthcare and facial recognition systems. We\nposit that selectively removing features in this latent space can protect the\nsensitive information and provide a better privacy-utility trade-off.\nConsequently, we propose DISCO which learns a dynamic and data driven pruning\nfilter to selectively obfuscate sensitive information in the feature space. We\npropose diverse attack schemes for sensitive inputs \\& attributes and\ndemonstrate the effectiveness of DISCO against state-of-the-art methods through\nquantitative and qualitative evaluation. Finally, we also release an evaluation\nbenchmark dataset of 1 million sensitive representations to encourage rigorous\nexploration of novel attack schemes.\n", "versions": [{"version": "v1", "created": "Sun, 20 Dec 2020 21:15:13 GMT"}, {"version": "v2", "created": "Tue, 15 Jun 2021 07:39:03 GMT"}], "update_date": "2021-06-16", "authors_parsed": [["Singh", "Abhishek", ""], ["Chopra", "Ayush", ""], ["Sharma", "Vivek", ""], ["Garza", "Ethan", ""], ["Zhang", "Emily", ""], ["Vepakomma", "Praneeth", ""], ["Raskar", "Ramesh", ""]]}, {"id": "2012.11045", "submitter": "Johannes Czech", "authors": "Johannes Czech, Patrick Korus, Kristian Kersting", "title": "Monte-Carlo Graph Search for AlphaZero", "comments": "11 pages, 7 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The AlphaZero algorithm has been successfully applied in a range of discrete\ndomains, most notably board games. It utilizes a neural network, that learns a\nvalue and policy function to guide the exploration in a Monte-Carlo Tree\nSearch. Although many search improvements have been proposed for Monte-Carlo\nTree Search in the past, most of them refer to an older variant of the Upper\nConfidence bounds for Trees algorithm that does not use a policy for planning.\nWe introduce a new, improved search algorithm for AlphaZero which generalizes\nthe search tree to a directed acyclic graph. This enables information flow\nacross different subtrees and greatly reduces memory consumption. Along with\nMonte-Carlo Graph Search, we propose a number of further extensions, such as\nthe inclusion of Epsilon-greedy exploration, a revised terminal solver and the\nintegration of domain knowledge as constraints. In our evaluations, we use the\nCrazyAra engine on chess and crazyhouse as examples to show that these changes\nbring significant improvements to AlphaZero.\n", "versions": [{"version": "v1", "created": "Sun, 20 Dec 2020 22:51:38 GMT"}], "update_date": "2020-12-22", "authors_parsed": [["Czech", "Johannes", ""], ["Korus", "Patrick", ""], ["Kersting", "Kristian", ""]]}, {"id": "2012.11049", "submitter": "Alejandro Martin", "authors": "Javier Huertas-Tato, Alejandro Mart\\'in, Juli\\'an Fierrez, David\n  Camacho", "title": "Fusing CNNs and statistical indicators to improve image classification", "comments": "16 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional Networks have dominated the field of computer vision for the\nlast ten years, exhibiting extremely powerful feature extraction capabilities\nand outstanding classification performance. The main strategy to prolong this\ntrend relies on further upscaling networks in size. However, costs increase\nrapidly while performance improvements may be marginal. We hypothesise that\nadding heterogeneous sources of information may be more cost-effective to a CNN\nthan building a bigger network. In this paper, an ensemble method is proposed\nfor accurate image classification, fusing automatically detected features\nthrough Convolutional Neural Network architectures with a set of manually\ndefined statistical indicators. Through a combination of the predictions of a\nCNN and a secondary classifier trained on statistical features, better\nclassification performance can be cheaply achieved. We test multiple learning\nalgorithms and CNN architectures on a diverse number of datasets to validate\nour proposal, making public all our code and data via GitHub. According to our\nresults, the inclusion of additional indicators and an ensemble classification\napproach helps to increase the performance in 8 of 9 datasets, with a\nremarkable increase of more than 10% precision in two of them.\n", "versions": [{"version": "v1", "created": "Sun, 20 Dec 2020 23:24:31 GMT"}, {"version": "v2", "created": "Fri, 4 Jun 2021 11:16:48 GMT"}], "update_date": "2021-06-07", "authors_parsed": [["Huertas-Tato", "Javier", ""], ["Mart\u00edn", "Alejandro", ""], ["Fierrez", "Juli\u00e1n", ""], ["Camacho", "David", ""]]}, {"id": "2012.11067", "submitter": "Alexey Ignatiev", "authors": "Alexey Ignatiev, Nina Narodytska, Nicholas Asher, Joao Marques-Silva", "title": "On Relating 'Why?' and 'Why Not?' Explanations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Explanations of Machine Learning (ML) models often address a 'Why?' question.\nSuch explanations can be related with selecting feature-value pairs which are\nsufficient for the prediction. Recent work has investigated explanations that\naddress a 'Why Not?' question, i.e. finding a change of feature values that\nguarantee a change of prediction. Given their goals, these two forms of\nexplaining predictions of ML models appear to be mostly unrelated. However,\nthis paper demonstrates otherwise, and establishes a rigorous formal\nrelationship between 'Why?' and 'Why Not?' explanations. Concretely, the paper\nproves that, for any given instance, 'Why?' explanations are minimal hitting\nsets of 'Why Not?' explanations and vice-versa. Furthermore, the paper devises\nnovel algorithms for extracting and enumerating both forms of explanations.\n", "versions": [{"version": "v1", "created": "Mon, 21 Dec 2020 01:07:13 GMT"}], "update_date": "2020-12-22", "authors_parsed": [["Ignatiev", "Alexey", ""], ["Narodytska", "Nina", ""], ["Asher", "Nicholas", ""], ["Marques-Silva", "Joao", ""]]}, {"id": "2012.11078", "submitter": "Patrick Rodler", "authors": "Patrick Rodler", "title": "DynamicHS: Streamlining Reiter's Hitting-Set Tree for Sequential\n  Diagnosis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Given a system that does not work as expected, Sequential Diagnosis (SD) aims\nat suggesting a series of system measurements to isolate the true explanation\nfor the system's misbehavior from a potentially exponential set of possible\nexplanations. To reason about the best next measurement, SD methods usually\nrequire a sample of possible fault explanations at each step of the iterative\ndiagnostic process. The computation of this sample can be accomplished by\nvarious diagnostic search algorithms. Among those, Reiter's HS-Tree is one of\nthe most popular due its desirable properties and general applicability.\nUsually, HS-Tree is used in a stateless fashion throughout the SD process to\n(re)compute a sample of possible fault explanations in each iteration, each\ntime given the latest (updated) system knowledge including all so-far collected\nmeasurements. At this, the built search tree is discarded between two\niterations, although often large parts of the tree have to be rebuilt in the\nnext iteration, involving redundant operations and calls to costly reasoning\nservices.\n  As a remedy to this, we propose DynamicHS, a variant of HS-Tree that\nmaintains state throughout the diagnostic session and additionally embraces\nspecial strategies to minimize the number of expensive reasoner invocations. In\nthis vein, DynamicHS provides an answer to a longstanding question posed by\nRaymond Reiter in his seminal paper from 1987.\n  Extensive evaluations on real-world diagnosis problems prove the\nreasonability of the DynamicHS and testify its clear superiority to HS-Tree\nwrt. computation time. More specifically, DynamicHS outperformed HS-Tree in 96%\nof the executed sequential diagnosis sessions and, per run, the latter required\nup to 800% the time of the former. Remarkably, DynamicHS achieves these\nperformance improvements while preserving all desirable properties as well as\nthe general applicability of HS-Tree.\n", "versions": [{"version": "v1", "created": "Mon, 21 Dec 2020 01:59:19 GMT"}], "update_date": "2020-12-22", "authors_parsed": [["Rodler", "Patrick", ""]]}, {"id": "2012.11097", "submitter": "Yi Ding", "authors": "Yi Ding, Fuyuan Tan, Zhen Qin, Mingsheng Cao, Kim-Kwang Raymond Choo\n  and Zhiguang Qin", "title": "DeepKeyGen: A Deep Learning-based Stream Cipher Generator for Medical\n  Image Encryption and Decryption", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The need for medical image encryption is increasingly pronounced, for example\nto safeguard the privacy of the patients' medical imaging data. In this paper,\na novel deep learning-based key generation network (DeepKeyGen) is proposed as\na stream cipher generator to generate the private key, which can then be used\nfor encrypting and decrypting of medical images. In DeepKeyGen, the generative\nadversarial network (GAN) is adopted as the learning network to generate the\nprivate key. Furthermore, the transformation domain (that represents the\n\"style\" of the private key to be generated) is designed to guide the learning\nnetwork to realize the private key generation process. The goal of DeepKeyGen\nis to learn the mapping relationship of how to transfer the initial image to\nthe private key. We evaluate DeepKeyGen using three datasets, namely: the\nMontgomery County chest X-ray dataset, the Ultrasonic Brachial Plexus dataset,\nand the BraTS18 dataset. The evaluation findings and security analysis show\nthat the proposed key generation network can achieve a high-level security in\ngenerating the private key.\n", "versions": [{"version": "v1", "created": "Mon, 21 Dec 2020 03:21:59 GMT"}], "update_date": "2020-12-22", "authors_parsed": [["Ding", "Yi", ""], ["Tan", "Fuyuan", ""], ["Qin", "Zhen", ""], ["Cao", "Mingsheng", ""], ["Choo", "Kim-Kwang Raymond", ""], ["Qin", "Zhiguang", ""]]}, {"id": "2012.11099", "submitter": "Yongkang Liu", "authors": "Yongkang Liu, Shi Feng, Daling Wang, Kaisong Song, Feiliang Ren, Yifei\n  Zhang", "title": "A Graph Reasoning Network for Multi-turn Response Selection via\n  Customized Pre-training", "comments": "Accepted by AAAI 2021;10 pages,6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate response selection for multi-turn conversation in\nretrieval-based chatbots. Existing studies pay more attention to the matching\nbetween utterances and responses by calculating the matching score based on\nlearned features, leading to insufficient model reasoning ability. In this\npaper, we propose a graph-reasoning network (GRN) to address the problem. GRN\nfirst conducts pre-training based on ALBERT using next utterance prediction and\nutterance order prediction tasks specifically devised for response selection.\nThese two customized pre-training tasks can endow our model with the ability of\ncapturing semantical and chronological dependency between utterances. We then\nfine-tune the model on an integrated network with sequence reasoning and graph\nreasoning structures. The sequence reasoning module conducts inference based on\nthe highly summarized context vector of utterance-response pairs from the\nglobal perspective. The graph reasoning module conducts the reasoning on the\nutterance-level graph neural network from the local perspective. Experiments on\ntwo conversational reasoning datasets show that our model can dramatically\noutperform the strong baseline methods and can achieve performance which is\nclose to human-level.\n", "versions": [{"version": "v1", "created": "Mon, 21 Dec 2020 03:38:29 GMT"}, {"version": "v2", "created": "Fri, 15 Jan 2021 02:12:11 GMT"}], "update_date": "2021-01-18", "authors_parsed": [["Liu", "Yongkang", ""], ["Feng", "Shi", ""], ["Wang", "Daling", ""], ["Song", "Kaisong", ""], ["Ren", "Feiliang", ""], ["Zhang", "Yifei", ""]]}, {"id": "2012.11142", "submitter": "Ishani Mondal", "authors": "Ishani Mondal", "title": "Towards Incorporating Entity-specific Knowledge Graph Information in\n  Predicting Drug-Drug Interactions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Off-the-shelf biomedical embeddings obtained from the recently released\nvarious pre-trained language models (such as BERT, XLNET) have demonstrated\nstate-of-the-art results (in terms of accuracy) for the various natural\nlanguage understanding tasks (NLU) in the biomedical domain. Relation\nClassification (RC) falls into one of the most critical tasks. In this paper,\nwe explore how to incorporate domain knowledge of the biomedical entities (such\nas drug, disease, genes), obtained from Knowledge Graph (KG) Embeddings, for\npredicting Drug-Drug Interaction from textual corpus. We propose a new method,\nBERTKG-DDI, to combine drug embeddings obtained from its interaction with other\nbiomedical entities along with domain-specific BioBERT embedding-based RC\narchitecture. Experiments conducted on the DDIExtraction 2013 corpus clearly\nindicate that this strategy improves other baselines architectures by 4.1%\nmacro F1-score.\n", "versions": [{"version": "v1", "created": "Mon, 21 Dec 2020 06:44:32 GMT"}], "update_date": "2020-12-22", "authors_parsed": [["Mondal", "Ishani", ""]]}, {"id": "2012.11150", "submitter": "Sungwon Han", "authors": "Sungwon Park, Sungwon Han, Sundong Kim, Danu Kim, Sungkyu Park,\n  Seunghoon Hong and Meeyoung Cha", "title": "Improving Unsupervised Image Clustering With Robust Learning", "comments": "Accepted at CVPR2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unsupervised image clustering methods often introduce alternative objectives\nto indirectly train the model and are subject to faulty predictions and\noverconfident results. To overcome these challenges, the current research\nproposes an innovative model RUC that is inspired by robust learning. RUC's\nnovelty is at utilizing pseudo-labels of existing image clustering models as a\nnoisy dataset that may include misclassified samples. Its retraining process\ncan revise misaligned knowledge and alleviate the overconfidence problem in\npredictions. The model's flexible structure makes it possible to be used as an\nadd-on module to other clustering methods and helps them achieve better\nperformance on multiple datasets. Extensive experiments show that the proposed\nmodel can adjust the model confidence with better calibration and gain\nadditional robustness against adversarial noise.\n", "versions": [{"version": "v1", "created": "Mon, 21 Dec 2020 07:02:11 GMT"}, {"version": "v2", "created": "Mon, 29 Mar 2021 15:36:14 GMT"}], "update_date": "2021-03-30", "authors_parsed": [["Park", "Sungwon", ""], ["Han", "Sungwon", ""], ["Kim", "Sundong", ""], ["Kim", "Danu", ""], ["Park", "Sungkyu", ""], ["Hong", "Seunghoon", ""], ["Cha", "Meeyoung", ""]]}, {"id": "2012.11154", "submitter": "Isaac Godfried", "authors": "Isaac Godfried, Kriti Mahajan, Maggie Wang, Kevin Li, Pranjalya Tiwari", "title": "FlowDB a large scale precipitation, river, and flash flood dataset", "comments": "NeurIPS 2020 Workshop Tackling Climate Change with Machine Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Flooding results in 8 billion dollars of damage annually in the US and causes\nthe most deaths of any weather related event. Due to climate change scientists\nexpect more heavy precipitation events in the future. However, no current\ndatasets exist that contain both hourly precipitation and river flow data. We\nintroduce a novel hourly river flow and precipitation dataset and a second\nsubset of flash flood events with damage estimates and injury counts. Using\nthese datasets we create two challenges (1) general stream flow forecasting and\n(2) flash flood damage estimation. We have created several publicly available\nbenchmarks and an easy to use package. Additionally, in the future we aim to\naugment our dataset with snow pack data and soil index moisture data to improve\npredictions.\n", "versions": [{"version": "v1", "created": "Mon, 21 Dec 2020 07:08:41 GMT"}], "update_date": "2020-12-22", "authors_parsed": [["Godfried", "Isaac", ""], ["Mahajan", "Kriti", ""], ["Wang", "Maggie", ""], ["Li", "Kevin", ""], ["Tiwari", "Pranjalya", ""]]}, {"id": "2012.11157", "submitter": "Deng Cai", "authors": "Deng Cai and Yizhe Zhang and Yichen Huang and Wai Lam and Bill Dolan", "title": "Narrative Incoherence Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We propose the task of narrative incoherence detection as a new arena for\ninter-sentential semantic understanding: Given a multi-sentence narrative,\ndecide whether there exist any semantic discrepancies in the narrative flow.\nSpecifically, we focus on the missing sentence and discordant sentence\ndetection. Despite its simple setup, this task is challenging as the model\nneeds to understand and analyze a multi-sentence narrative, and predict\nincoherence at the sentence level. As an initial step towards this task, we\nimplement several baselines either directly analyzing the raw text\n(\\textit{token-level}) or analyzing learned sentence representations\n(\\textit{sentence-level}). We observe that while token-level modeling has\nbetter performance when the input contains fewer sentences, sentence-level\nmodeling performs better on longer narratives and possesses an advantage in\nefficiency and flexibility. Pre-training on large-scale data and auxiliary\nsentence prediction training objective further boost the detection performance\nof the sentence-level model.\n", "versions": [{"version": "v1", "created": "Mon, 21 Dec 2020 07:18:08 GMT"}, {"version": "v2", "created": "Thu, 15 Apr 2021 11:47:45 GMT"}], "update_date": "2021-04-16", "authors_parsed": [["Cai", "Deng", ""], ["Zhang", "Yizhe", ""], ["Huang", "Yichen", ""], ["Lam", "Wai", ""], ["Dolan", "Bill", ""]]}, {"id": "2012.11164", "submitter": "Ishani Mondal", "authors": "Ishani Mondal, Sukannya Purkayastha, Sudeshna Sarkar, Pawan Goyal,\n  Jitesh Pillai, Amitava Bhattacharyya, Mahanandeeshwar Gattu", "title": "Medical Entity Linking using Triplet Network", "comments": "ClinicalNLP@NAACL 2019", "journal-ref": null, "doi": "10.18653/v1/W19-1912", "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Entity linking (or Normalization) is an essential task in text mining that\nmaps the entity mentions in the medical text to standard entities in a given\nKnowledge Base (KB). This task is of great importance in the medical domain. It\ncan also be used for merging different medical and clinical ontologies. In this\npaper, we center around the problem of disease linking or normalization. This\ntask is executed in two phases: candidate generation and candidate scoring. In\nthis paper, we present an approach to rank the candidate Knowledge Base entries\nbased on their similarity with disease mention. We make use of the Triplet\nNetwork for candidate ranking. While the existing methods have used carefully\ngenerated sieves and external resources for candidate generation, we introduce\na robust and portable candidate generation scheme that does not make use of the\nhand-crafted rules. Experimental results on the standard benchmark NCBI disease\ndataset demonstrate that our system outperforms the prior methods by a\nsignificant margin.\n", "versions": [{"version": "v1", "created": "Mon, 21 Dec 2020 07:44:37 GMT"}], "update_date": "2020-12-22", "authors_parsed": [["Mondal", "Ishani", ""], ["Purkayastha", "Sukannya", ""], ["Sarkar", "Sudeshna", ""], ["Goyal", "Pawan", ""], ["Pillai", "Jitesh", ""], ["Bhattacharyya", "Amitava", ""], ["Gattu", "Mahanandeeshwar", ""]]}, {"id": "2012.11172", "submitter": "Amin Javari", "authors": "Amin Javari, Mehrab Norouzitallab, Mahdi Jalili", "title": "Who will accept my request? Predicting response of link initiation in\n  two-way relation networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.IR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Popularity of social networks has rapidly increased over the past few years,\nand daily lives interrupt without their proper functioning. Social networking\nplatform provide multiple interaction types between individuals, such as\ncreating and joining groups, sending and receiving messages, sharing interests\nand creating friendship relationships. This paper addresses an important\nproblem in social networks analysis and mining that is how to predict link\ninitiation feedback in two-way networks. Relationships between two individuals\nin a two-way network include a link invitation from one of the individuals,\nwhich will be an established link if it is accepted by the invitee. We consider\na sport gaming social networking platform and construct a multilayer social\nnetwork between a number of users. The network formed by the link initiation\nprocess is on one of the layers, while the other two layers include a messaging\nrelationships and interactions between the users. We propose a methodology to\nsolve the link initiation feedback prediction problem in this multilayer\nfashion. The proposed method is based on features extracted from meta-paths,\ni.e. paths defined between different individuals from multiples layers in\nmultilayer networks. We proposed a cluster-based approach to handle the\nsparsity issue in the dataset. Experimental results show that the proposed\nmethod can provide accurate prediction that outperforms state-of-the-art\nmethods.\n", "versions": [{"version": "v1", "created": "Mon, 21 Dec 2020 08:14:37 GMT"}], "update_date": "2020-12-22", "authors_parsed": [["Javari", "Amin", ""], ["Norouzitallab", "Mehrab", ""], ["Jalili", "Mahdi", ""]]}, {"id": "2012.11174", "submitter": "Xiong Cai", "authors": "Xiong Cai, Zhiyong Wu, Kuo Zhong, Bin Su, Dongyang Dai, Helen Meng", "title": "Unsupervised Cross-Lingual Speech Emotion Recognition Using\n  DomainAdversarial Neural Network", "comments": "This paper has been accepted by ISCSLP2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  By using deep learning approaches, Speech Emotion Recog-nition (SER) on a\nsingle domain has achieved many excellentresults. However, cross-domain SER is\nstill a challenging taskdue to the distribution shift between source and target\ndomains.In this work, we propose a Domain Adversarial Neural Net-work (DANN)\nbased approach to mitigate this distribution shiftproblem for cross-lingual\nSER. Specifically, we add a languageclassifier and gradient reversal layer\nafter the feature extractor toforce the learned representation both\nlanguage-independent andemotion-meaningful. Our method is unsupervised, i. e.,\nlabelson target language are not required, which makes it easier to ap-ply our\nmethod to other languages. Experimental results showthe proposed method\nprovides an average absolute improve-ment of 3.91% over the baseline system for\narousal and valenceclassification task. Furthermore, we find that batch\nnormaliza-tion is beneficial to the performance gain of DANN. Thereforewe also\nexplore the effect of different ways of data combinationfor batch\nnormalization.\n", "versions": [{"version": "v1", "created": "Mon, 21 Dec 2020 08:21:11 GMT"}], "update_date": "2020-12-22", "authors_parsed": [["Cai", "Xiong", ""], ["Wu", "Zhiyong", ""], ["Zhong", "Kuo", ""], ["Su", "Bin", ""], ["Dai", "Dongyang", ""], ["Meng", "Helen", ""]]}, {"id": "2012.11185", "submitter": "Shenqqi Geng", "authors": "Shengqi Geng", "title": "Infrared image pedestrian target detection based on Yolov3 and migration\n  learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  With the gradual application of infrared night vision vehicle assistance\nsystem in automatic driving, the accuracy of the collected infrared images of\npedestrians is gradually improved. In this paper, the migration learning method\nis used to apply YOLOv3 model to realize pedestrian target detection in\ninfrared images. The target detection model YOLOv3 is migrated to the CVC\ninfrared pedestrian data set, and Diou loss is used to replace the loss\nfunction of the original YOLO model to test different super parameters to\nobtain the best migration learning effect. The experimental results show that\nin the pedestrian detection task of CVC data set, the average accuracy (AP) of\nYolov3 model reaches 96.35%, and that of Diou-Yolov3 model is 72.14%, but the\nlatter has a faster convergence rate of loss curve. The effect of migration\nlearning can be obtained by comparing the two models.\n", "versions": [{"version": "v1", "created": "Mon, 21 Dec 2020 08:55:48 GMT"}], "update_date": "2020-12-22", "authors_parsed": [["Geng", "Shengqi", ""]]}, {"id": "2012.11220", "submitter": "Lucas Carvalho Cordeiro", "authors": "Luiz Sena, Erickson Alves, Iury Bessa, Eddie Filho, and Lucas Cordeiro", "title": "Incremental Verification of Fixed-Point Implementations of Neural\n  Networks", "comments": "arXiv admin note: text overlap with arXiv:1907.12933", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Implementations of artificial neural networks (ANNs) might lead to failures,\nwhich are hardly predicted in the design phase since ANNs are highly parallel\nand their parameters are barely interpretable. Here, we develop and evaluate a\nnovel symbolic verification framework using incremental bounded model checking\n(BMC), satisfiability modulo theories (SMT), and invariant inference, to obtain\nadversarial cases and validate coverage methods in a multi-layer perceptron\n(MLP). We exploit incremental BMC based on interval analysis to compute\nboundaries from a neuron's input. Then, the latter are propagated to\neffectively find a neuron's output since it is the input of the next one. This\npaper describes the first bit-precise symbolic verification framework to reason\nover actual implementations of ANNs in CUDA, based on invariant inference,\ntherefore providing further guarantees about finite-precision arithmetic and\nits rounding errors, which are routinely ignored in the existing literature. We\nhave implemented the proposed approach on top of the efficient SMT-based\nbounded model checker (ESBMC), and its experimental results show that it can\nsuccessfully verify safety properties, in actual implementations of ANNs, and\ngenerate real adversarial cases in MLPs. Our approach was able to verify and\nproduce adversarial examples for 85.8% of 21 test cases considering different\ninput images, and 100% of the properties related to covering methods. Although\nour verification time is higher than existing approaches, our methodology can\nconsider fixed-point implementation aspects that are disregarded by the\nstate-of-the-art verification methodologies.\n", "versions": [{"version": "v1", "created": "Mon, 21 Dec 2020 10:03:44 GMT"}], "update_date": "2020-12-22", "authors_parsed": [["Sena", "Luiz", ""], ["Alves", "Erickson", ""], ["Bessa", "Iury", ""], ["Filho", "Eddie", ""], ["Cordeiro", "Lucas", ""]]}, {"id": "2012.11243", "submitter": "Yaman K Singla", "authors": "Yaman Kumar, Swati Aggarwal, Debanjan Mahata, Rajiv Ratn Shah,\n  Ponnurangam Kumaraguru, Roger Zimmermann", "title": "Get It Scored Using AutoSAS -- An Automated System for Scoring Short\n  Answers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the era of MOOCs, online exams are taken by millions of candidates, where\nscoring short answers is an integral part. It becomes intractable to evaluate\nthem by human graders. Thus, a generic automated system capable of grading\nthese responses should be designed and deployed. In this paper, we present a\nfast, scalable, and accurate approach towards automated Short Answer Scoring\n(SAS). We propose and explain the design and development of a system for SAS,\nnamely AutoSAS. Given a question along with its graded samples, AutoSAS can\nlearn to grade that prompt successfully. This paper further lays down the\nfeatures such as lexical diversity, Word2Vec, prompt, and content overlap that\nplays a pivotal role in building our proposed model. We also present a\nmethodology for indicating the factors responsible for scoring an answer. The\ntrained model is evaluated on an extensively used public dataset, namely\nAutomated Student Assessment Prize Short Answer Scoring (ASAP-SAS). AutoSAS\nshows state-of-the-art performance and achieves better results by over 8% in\nsome of the question prompts as measured by Quadratic Weighted Kappa (QWK),\nshowing performance comparable to humans.\n", "versions": [{"version": "v1", "created": "Mon, 21 Dec 2020 10:47:30 GMT"}], "update_date": "2020-12-22", "authors_parsed": [["Kumar", "Yaman", ""], ["Aggarwal", "Swati", ""], ["Mahata", "Debanjan", ""], ["Shah", "Rajiv Ratn", ""], ["Kumaraguru", "Ponnurangam", ""], ["Zimmermann", "Roger", ""]]}, {"id": "2012.11293", "submitter": "Mario Krenn", "authors": "Luca A. Thiede, Mario Krenn, AkshatKumar Nigam, Alan Aspuru-Guzik", "title": "Curiosity in exploring chemical space: Intrinsic rewards for deep\n  molecular reinforcement learning", "comments": "9 pages, 2 figures; comments welcome", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI physics.chem-ph", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Computer-aided design of molecules has the potential to disrupt the field of\ndrug and material discovery. Machine learning, and deep learning, in\nparticular, have been topics where the field has been developing at a rapid\npace. Reinforcement learning is a particularly promising approach since it\nallows for molecular design without prior knowledge. However, the search space\nis vast and efficient exploration is desirable when using reinforcement\nlearning agents. In this study, we propose an algorithm to aid efficient\nexploration. The algorithm is inspired by a concept known in the literature as\ncuriosity. We show on three benchmarks that a curious agent finds better\nperforming molecules. This indicates an exciting new research direction for\nreinforcement learning agents that can explore the chemical space out of their\nown motivation. This has the potential to eventually lead to unexpected new\nmolecules that no human has thought about so far.\n", "versions": [{"version": "v1", "created": "Thu, 17 Dec 2020 17:21:59 GMT"}], "update_date": "2020-12-22", "authors_parsed": [["Thiede", "Luca A.", ""], ["Krenn", "Mario", ""], ["Nigam", "AkshatKumar", ""], ["Aspuru-Guzik", "Alan", ""]]}, {"id": "2012.11319", "submitter": "Sabah Al-Fedaghi Dr.", "authors": "Sabah Al-Fedaghi", "title": "Conceptual Software Engineering Applied to Movie Scripts and Stories", "comments": "13 pages, 16 figures", "journal-ref": "Journal of Computer Science 2020, 16 (12): 1718.1730", "doi": "10.3844/jcssp.2020.1718.1730", "report-no": null, "categories": "cs.AI cs.SE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This study introduces another application of software engineering tools,\nconceptual modeling, which can be applied to other fields of research. One way\nto strengthen the relationship between software engineering and other fields is\nto develop a good way to perform conceptual modeling that is capable of\naddressing the peculiarities of these fields of study. This study concentrates\non humanities and social sciences, which are usually considered softer and\nfurther away from abstractions and (abstract) machines. Specifically, we focus\non conceptual modeling as a software engineering tool (e.g., UML) in the area\nof stories and movie scripts. Researchers in the humanities and social sciences\nmight not use the same degree of formalization that engineers do, but they\nstill find conceptual modeling useful. Current modeling techniques (e.g., UML)\nfail in this task because they are geared toward the creation of software\nsystems. Similar Conceptual Modeling Language (e.g., ConML) has been proposed\nwith the humanities and social sciences in mind and, as claimed, can be used to\nmodel anything. This study is a venture in this direction, where a software\nmodeling technique, Thinging Machine (TM), is applied to movie scripts and\nstories. The paper presents a novel approach to developing diagrammatic\nstatic/dynamic models of movie scripts and stories. The TM model diagram serves\nas a neutral and independent representation for narrative discourse and can be\nused as a communication instrument among participants. The examples presented\ninclude examples from Propp s model of fairytales; the railway children and an\nactual movie script seem to point to the viability of the approach.\n", "versions": [{"version": "v1", "created": "Thu, 17 Dec 2020 15:24:12 GMT"}], "update_date": "2020-12-22", "authors_parsed": [["Al-Fedaghi", "Sabah", ""]]}, {"id": "2012.11329", "submitter": "Christopher Galias", "authors": "B{\\l}a\\.zej Osi\\'nski, Piotr Mi{\\l}o\\'s, Adam Jakubowski, Pawe{\\l}\n  Zi\\k{e}cina, Micha{\\l} Martyniak, Christopher Galias, Antonia Breuer, Silviu\n  Homoceanu, Henryk Michalewski", "title": "CARLA Real Traffic Scenarios -- novel training ground and benchmark for\n  autonomous driving", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work introduces interactive traffic scenarios in the CARLA simulator,\nwhich are based on real-world traffic. We concentrate on tactical tasks lasting\nseveral seconds, which are especially challenging for current control methods.\nThe CARLA Real Traffic Scenarios (CRTS) is intended to be a training and\ntesting ground for autonomous driving systems. To this end, we open-source the\ncode under a permissive license and present a set of baseline policies. CRTS\ncombines the realism of traffic scenarios and the flexibility of simulation. We\nuse it to train agents using a reinforcement learning algorithm. We show how to\nobtain competitive polices and evaluate experimentally how observation types\nand reward schemes affect the training process and the resulting agent's\nbehavior.\n", "versions": [{"version": "v1", "created": "Wed, 16 Dec 2020 13:20:39 GMT"}], "update_date": "2020-12-22", "authors_parsed": [["Osi\u0144ski", "B\u0142a\u017cej", ""], ["Mi\u0142o\u015b", "Piotr", ""], ["Jakubowski", "Adam", ""], ["Zi\u0119cina", "Pawe\u0142", ""], ["Martyniak", "Micha\u0142", ""], ["Galias", "Christopher", ""], ["Breuer", "Antonia", ""], ["Homoceanu", "Silviu", ""], ["Michalewski", "Henryk", ""]]}, {"id": "2012.11364", "submitter": "Jo\\~ao Lousada", "authors": "Jo\\~ao Lousada, Miguel Ribeiro", "title": "Reinforcement Learning for Test Case Prioritization", "comments": "9 pages, 4 figures and 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In modern software engineering, Continuous Integration (CI) has become an\nindispensable step towards systematically managing the life cycles of software\ndevelopment. Large companies struggle with keeping the pipeline updated and\noperational, in useful time, due to the large amount of changes and addition of\nfeatures, that build on top of each other and have several developers, working\non different platforms. Associated with such software changes, there is always\na strong component of Testing. As teams and projects grow, exhaustive testing\nquickly becomes inhibitive, becoming adamant to select the most relevant test\ncases earlier, without compromising software quality. This paper extends recent\nstudies on applying Reinforcement Learning to optimize testing strategies. We\ntest its ability to adapt to new environments, by testing it on novel data\nextracted from a financial institution, yielding a Normalized percentage of\nFault Detection (NAPFD) of over $0.6$ using the Network Approximator and Test\nCase Failure Reward. Additionally, we studied the impact of using Decision Tree\n(DT) Approximator as a model for memory representation, which failed to produce\nsignificant improvements relative to Artificial Neural Networks.\n", "versions": [{"version": "v1", "created": "Fri, 18 Dec 2020 11:08:20 GMT"}], "update_date": "2020-12-22", "authors_parsed": [["Lousada", "Jo\u00e3o", ""], ["Ribeiro", "Miguel", ""]]}, {"id": "2012.11390", "submitter": "Lo\\\"ic Omnes", "authors": "Lo\\\"ic Omnes, Antoine Marot, Benjamin Donnot", "title": "Adversarial Training for a Continuous Robustness Control Problem in\n  Power Systems", "comments": "6 pages, 5 figures, to be published in the PowerTech 2021 conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We propose a new adversarial training approach for injecting robustness when\ndesigning controllers for upcoming cyber-physical power systems. Previous\napproaches relying deeply on simulations are not able to cope with the rising\ncomplexity and are too costly when used online in terms of computation budget.\nIn comparison, our method proves to be computationally efficient online while\ndisplaying useful robustness properties. To do so we model an adversarial\nframework, propose the implementation of a fixed opponent policy and test it on\na L2RPN (Learning to Run a Power Network) environment. This environment is a\nsynthetic but realistic modeling of a cyber-physical system accounting for one\nthird of the IEEE 118 grid. Using adversarial testing, we analyze the results\nof submitted trained agents from the robustness track of the L2RPN competition.\nWe then further assess the performance of these agents in regards to the\ncontinuous N-1 problem through tailored evaluation metrics. We discover that\nsome agents trained in an adversarial way demonstrate interesting preventive\nbehaviors in that regard, which we discuss.\n", "versions": [{"version": "v1", "created": "Mon, 21 Dec 2020 14:42:51 GMT"}, {"version": "v2", "created": "Thu, 14 Jan 2021 17:25:17 GMT"}, {"version": "v3", "created": "Fri, 16 Apr 2021 12:05:28 GMT"}], "update_date": "2021-04-19", "authors_parsed": [["Omnes", "Lo\u00efc", ""], ["Marot", "Antoine", ""], ["Donnot", "Benjamin", ""]]}, {"id": "2012.11399", "submitter": "Behzad Javaheri", "authors": "Behzad Javaheri", "title": "The COVID-19 pandemic: socioeconomic and health disparities", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Disadvantaged groups around the world have suffered and endured higher\nmortality during the current COVID-19 pandemic. This contrast disparity\nsuggests that socioeconomic and health-related factors may drive inequality in\ndisease outcome. To identify these factors correlated with COVID-19 outcome,\ncountry aggregate data provided by the Lancet COVID-19 Commission subjected to\ncorrelation analysis. Socioeconomic and health-related variables were used to\npredict mortality in the top 5 most affected countries using ridge regression\nand extreme gradient boosting (XGBoost) models. Our data reveal that predictors\nrelated to demographics and social disadvantage correlate with COVID-19\nmortality per million and that XGBoost performed better than ridge regression.\nTaken together, our findings suggest that the health consequence of the current\npandemic is not just confined to indiscriminate impact of a viral infection but\nthat these preventable effects are amplified based on pre-existing health and\nsocioeconomic inequalities.\n", "versions": [{"version": "v1", "created": "Mon, 21 Dec 2020 15:01:17 GMT"}, {"version": "v2", "created": "Tue, 22 Dec 2020 14:54:27 GMT"}], "update_date": "2020-12-23", "authors_parsed": [["Javaheri", "Behzad", ""]]}, {"id": "2012.11401", "submitter": "Daniel Selsam", "authors": "Daniel Selsam, Jesse Michael Han, Leonardo de Moura, Patrice Godefroid", "title": "Universal Policies for Software-Defined MDPs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new programming paradigm called oracle-guided decision\nprogramming in which a program specifies a Markov Decision Process (MDP) and\nthe language provides a universal policy. We prototype a new programming\nlanguage, Dodona, that manifests this paradigm using a primitive 'choose'\nrepresenting nondeterministic choice. The Dodona interpreter returns either a\nvalue or a choicepoint that includes a lossless encoding of all information\nnecessary in principle to make an optimal decision. Meta-interpreters query\nDodona's (neural) oracle on these choicepoints to get policy and value\nestimates, which they can use to perform heuristic search on the underlying\nMDP. We demonstrate Dodona's potential for zero-shot heuristic guidance by\nmeta-learning over hundreds of synthetic tasks that simulate basic operations\nover lists, trees, Church datastructures, polynomials, first-order terms and\nhigher-order terms.\n", "versions": [{"version": "v1", "created": "Mon, 21 Dec 2020 15:04:06 GMT"}], "update_date": "2020-12-22", "authors_parsed": [["Selsam", "Daniel", ""], ["Han", "Jesse Michael", ""], ["de Moura", "Leonardo", ""], ["Godefroid", "Patrice", ""]]}, {"id": "2012.11424", "submitter": "Brian Coyle", "authors": "Brian Coyle, Mina Doosti, Elham Kashefi, Niraj Kumar", "title": "Variational Quantum Cloning: Improving Practicality for Quantum\n  Cryptanalysis", "comments": "16 pages main text, 25 pages supplementary material, 20 figures.\n  Comments welcome", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.AI cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cryptanalysis on standard quantum cryptographic systems generally involves\nfinding optimal adversarial attack strategies on the underlying protocols. The\ncore principle of modelling quantum attacks in many cases reduces to the\nadversary's ability to clone unknown quantum states which facilitates the\nextraction of some meaningful secret information. Explicit optimal attack\nstrategies typically require high computational resources due to large circuit\ndepths or, in many cases, are unknown. In this work, we propose variational\nquantum cloning (VQC), a quantum machine learning based cryptanalysis algorithm\nwhich allows an adversary to obtain optimal (approximate) cloning strategies\nwith short depth quantum circuits, trained using hybrid classical-quantum\ntechniques. The algorithm contains operationally meaningful cost functions with\ntheoretical guarantees, quantum circuit structure learning and gradient descent\nbased optimisation. Our approach enables the end-to-end discovery of hardware\nefficient quantum circuits to clone specific families of quantum states, which\nin turn leads to an improvement in cloning fidelites when implemented on\nquantum hardware: the Rigetti Aspen chip. Finally, we connect these results to\nquantum cryptographic primitives, in particular quantum coin flipping. We\nderive attacks on two protocols as examples, based on quantum cloning and\nfacilitated by VQC. As a result, our algorithm can improve near term attacks on\nthese protocols, using approximate quantum cloning as a resource.\n", "versions": [{"version": "v1", "created": "Mon, 21 Dec 2020 15:28:09 GMT"}], "update_date": "2020-12-22", "authors_parsed": [["Coyle", "Brian", ""], ["Doosti", "Mina", ""], ["Kashefi", "Elham", ""], ["Kumar", "Niraj", ""]]}, {"id": "2012.11444", "submitter": "David Mark Bossens", "authors": "David M. Bossens and Danesh Tarapore", "title": "Rapidly adapting robot swarms with Swarm Map-based Bayesian Optimisation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.MA cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Rapid performance recovery from unforeseen environmental perturbations\nremains a grand challenge in swarm robotics. To solve this challenge, we\ninvestigate a behaviour adaptation approach, where one searches an archive of\ncontrollers for potential recovery solutions. To apply behaviour adaptation in\nswarm robotic systems, we propose two algorithms: (i) Swarm Map-based\nOptimisation (SMBO), which selects and evaluates one controller at a time, for\na homogeneous swarm, in a centralised fashion; and (ii) Swarm Map-based\nOptimisation Decentralised (SMBO-Dec), which performs an asynchronous\nbatch-based Bayesian optimisation to simultaneously explore different\ncontrollers for groups of robots in the swarm. We set up foraging experiments\nwith a variety of disturbances: injected faults to proximity sensors, ground\nsensors, and the actuators of individual robots, with 100 unique combinations\nfor each type. We also investigate disturbances in the operating environment of\nthe swarm, where the swarm has to adapt to drastic changes in the number of\nresources available in the environment, and to one of the robots behaving\ndisruptively towards the rest of the swarm, with 30 unique conditions for each\nsuch perturbation. The viability of SMBO and SMBO-Dec is demonstrated,\ncomparing favourably to variants of random search and gradient descent, and\nvarious ablations, and improving performance up to 80% compared to the\nperformance at the time of fault injection within at most 30 evaluations.\n", "versions": [{"version": "v1", "created": "Mon, 21 Dec 2020 15:54:37 GMT"}], "update_date": "2020-12-22", "authors_parsed": [["Bossens", "David M.", ""], ["Tarapore", "Danesh", ""]]}, {"id": "2012.11448", "submitter": "Naman Goel", "authors": "Naman Goel, Alfonso Amayuelas, Amit Deshpande, Amit Sharma", "title": "The Importance of Modeling Data Missingness in Algorithmic Fairness: A\n  Causal Perspective", "comments": "To appear in the Proceedings of AAAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Training datasets for machine learning often have some form of missingness.\nFor example, to learn a model for deciding whom to give a loan, the available\ntraining data includes individuals who were given a loan in the past, but not\nthose who were not. This missingness, if ignored, nullifies any fairness\nguarantee of the training procedure when the model is deployed. Using causal\ngraphs, we characterize the missingness mechanisms in different real-world\nscenarios. We show conditions under which various distributions, used in\npopular fairness algorithms, can or can not be recovered from the training\ndata. Our theoretical results imply that many of these algorithms can not\nguarantee fairness in practice. Modeling missingness also helps to identify\ncorrect design principles for fair algorithms. For example, in multi-stage\nsettings where decisions are made in multiple screening rounds, we use our\nframework to derive the minimal distributions required to design a fair\nalgorithm. Our proposed algorithm decentralizes the decision-making process and\nstill achieves similar performance to the optimal algorithm that requires\ncentralization and non-recoverable distributions.\n", "versions": [{"version": "v1", "created": "Mon, 21 Dec 2020 16:10:00 GMT"}], "update_date": "2020-12-22", "authors_parsed": [["Goel", "Naman", ""], ["Amayuelas", "Alfonso", ""], ["Deshpande", "Amit", ""], ["Sharma", "Amit", ""]]}, {"id": "2012.11490", "submitter": "Filip Ilievski", "authors": "Filip Ilievski, Pedro Szekely, Bin Zhang", "title": "CSKG: The CommonSense Knowledge Graph", "comments": "arXiv admin note: substantial text overlap with arXiv:2006.06114", "journal-ref": "ESWC 2021 Resource Track", "doi": null, "report-no": null, "categories": "cs.AI cs.SI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Sources of commonsense knowledge support applications in natural language\nunderstanding, computer vision, and knowledge graphs. Given their\ncomplementarity, their integration is desired. Yet, their different foci,\nmodeling approaches, and sparse overlap make integration difficult. In this\npaper, we consolidate commonsense knowledge by following five principles, which\nwe apply to combine seven key sources into a first integrated CommonSense\nKnowledge Graph (CSKG). We analyze CSKG and its various text and graph\nembeddings, showing that CSKG is well-connected and that its embeddings provide\na useful entry point to the graph. We demonstrate how CSKG can provide evidence\nfor generalizable downstream reasoning and for pre-training of language models.\nCSKG and all its embeddings are made publicly available to support further\nresearch on commonsense knowledge integration and reasoning.\n", "versions": [{"version": "v1", "created": "Mon, 21 Dec 2020 17:03:19 GMT"}, {"version": "v2", "created": "Tue, 23 Mar 2021 00:42:26 GMT"}], "update_date": "2021-03-24", "authors_parsed": [["Ilievski", "Filip", ""], ["Szekely", "Pedro", ""], ["Zhang", "Bin", ""]]}, {"id": "2012.11517", "submitter": "Hamidreza Dehghani", "authors": "Hamidreza Dehghani and Andreas Zilian", "title": "A hybrid MGA-MSGD ANN training approach for approximate solution of\n  linear elliptic PDEs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.AI cs.NA", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We introduce a hybrid \"Modified Genetic Algorithm-Multilevel Stochastic\nGradient Descent\" (MGA-MSGD) training algorithm that considerably improves\naccuracy and efficiency of solving 3D mechanical problems described, in\nstrong-form, by PDEs via ANNs (Artificial Neural Networks). This presented\napproach allows the selection of a number of locations of interest at which the\nstate variables are expected to fulfil the governing equations associated with\na physical problem. Unlike classical PDE approximation methods such as finite\ndifferences or the finite element method, there is no need to establish and\nreconstruct the physical field quantity throughout the computational domain in\norder to predict the mechanical response at specific locations of interest. The\nbasic idea of MGA-MSGD is the manipulation of the learnable parameters'\ncomponents responsible for the error explosion so that we can train the network\nwith relatively larger learning rates which avoids trapping in local minima.\nThe proposed training approach is less sensitive to the learning rate value,\ntraining points density and distribution, and the random initial parameters.\nThe distance function to minimise is where we introduce the PDEs including any\nphysical laws and conditions (so-called, Physics Informed ANN). The Genetic\nalgorithm is modified to be suitable for this type of ANN in which a\nCoarse-level Stochastic Gradient Descent (CSGD) is exploited to make the\ndecision of the offspring qualification. Employing the presented approach, a\nconsiderable improvement in both accuracy and efficiency, compared with\nstandard training algorithms such as classical SGD and Adam optimiser, is\nobserved. The local displacement accuracy is studied and ensured by introducing\nthe results of Finite Element Method (FEM) at sufficiently fine mesh as the\nreference displacements. A slightly more complex problem is solved ensuring its\nfeasibility.\n", "versions": [{"version": "v1", "created": "Fri, 18 Dec 2020 10:59:07 GMT"}], "update_date": "2020-12-22", "authors_parsed": [["Dehghani", "Hamidreza", ""], ["Zilian", "Andreas", ""]]}, {"id": "2012.11527", "submitter": "Marion G\\\"odel", "authors": "Marion G\\\"odel and Luca Spataro and Gerta K\\\"oster", "title": "Can we learn where people come from? Retracing of origins in merging\n  situations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.MA", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  One crucial information for a pedestrian crowd simulation is the number of\nagents moving from an origin to a certain target. While this setup has a large\nimpact on the simulation, it is in most setups challenging to find the number\nof agents that should be spawned at a source in the simulation. Often, number\nare chosen based on surveys and experience of modelers and event organizers.\nThese approaches are important and useful but reach their limits when we want\nto perform real-time predictions. In this case, a static information about the\ninflow is not sufficient. Instead, we need a dynamic information that can be\nretrieved each time the prediction is started. Nowadays, sensor data such as\nvideo footage or GPS tracks of a crowd are often available. If we can estimate\nthe number of pedestrians who stem from a certain origin from this sensor data,\nwe can dynamically initialize the simulation. In this study, we use density\nheatmaps that can be derived from sensor data as input for a random forest\nregressor to predict the origin distributions. We study three different\ndatasets: A simulated dataset, experimental data, and a hybrid approach with\nboth experimental and simulated data. In the hybrid setup, the model is trained\nwith simulated data and then tested on experimental data. The results\ndemonstrate that the random forest model is able to predict the origin\ndistribution based on a single density heatmap for all three configurations.\nThis is especially promising for applying the approach on real data since there\nis often only a limited amount of data available.\n", "versions": [{"version": "v1", "created": "Mon, 21 Dec 2020 17:42:14 GMT"}], "update_date": "2020-12-22", "authors_parsed": [["G\u00f6del", "Marion", ""], ["Spataro", "Luca", ""], ["K\u00f6ster", "Gerta", ""]]}, {"id": "2012.11538", "submitter": "Danijar Hafner", "authors": "Brendon Matusch, Jimmy Ba, Danijar Hafner", "title": "Evaluating Agents without Rewards", "comments": "15 pages, 6 figures, 5 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning has enabled agents to solve challenging tasks in\nunknown environments. However, manually crafting reward functions can be time\nconsuming, expensive, and error prone to human error. Competing objectives have\nbeen proposed for agents to learn without external supervision, but it has been\nunclear how well they reflect task rewards or human behavior. To accelerate the\ndevelopment of intrinsic objectives, we retrospectively compute potential\nobjectives on pre-collected datasets of agent behavior, rather than optimizing\nthem online, and compare them by analyzing their correlations. We study input\nentropy, information gain, and empowerment across seven agents, three Atari\ngames, and the 3D game Minecraft. We find that all three intrinsic objectives\ncorrelate more strongly with a human behavior similarity metric than with task\nreward. Moreover, input entropy and information gain correlate more strongly\nwith human similarity than task reward does, suggesting the use of intrinsic\nobjectives for designing agents that behave similarly to human players.\n", "versions": [{"version": "v1", "created": "Mon, 21 Dec 2020 18:00:39 GMT"}, {"version": "v2", "created": "Tue, 9 Feb 2021 22:06:26 GMT"}], "update_date": "2021-02-11", "authors_parsed": [["Matusch", "Brendon", ""], ["Ba", "Jimmy", ""], ["Hafner", "Danijar", ""]]}, {"id": "2012.11543", "submitter": "Rylee Thompson", "authors": "Rylee Thompson, Elahe Ghalebi, Terrance DeVries, Graham W. Taylor", "title": "Building LEGO Using Deep Generative Models of Graphs", "comments": "NeurIPS 2020 ML4eng workshop paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative models are now used to create a variety of high-quality digital\nartifacts. Yet their use in designing physical objects has received far less\nattention. In this paper, we advocate for the construction toy, LEGO, as a\nplatform for developing generative models of sequential assembly. We develop a\ngenerative model based on graph-structured neural networks that can learn from\nhuman-built structures and produce visually compelling designs. Our code is\nreleased at: https://github.com/uoguelph-mlrg/GenerativeLEGO.\n", "versions": [{"version": "v1", "created": "Mon, 21 Dec 2020 18:24:40 GMT"}], "update_date": "2020-12-22", "authors_parsed": [["Thompson", "Rylee", ""], ["Ghalebi", "Elahe", ""], ["DeVries", "Terrance", ""], ["Taylor", "Graham W.", ""]]}, {"id": "2012.11547", "submitter": "Rafael Rafailov", "authors": "Rafael Rafailov, Tianhe Yu, Aravind Rajeswaran, Chelsea Finn", "title": "Offline Reinforcement Learning from Images with Latent Space Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Offline reinforcement learning (RL) refers to the problem of learning\npolicies from a static dataset of environment interactions. Offline RL enables\nextensive use and re-use of historical datasets, while also alleviating safety\nconcerns associated with online exploration, thereby expanding the real-world\napplicability of RL. Most prior work in offline RL has focused on tasks with\ncompact state representations. However, the ability to learn directly from rich\nobservation spaces like images is critical for real-world applications such as\nrobotics. In this work, we build on recent advances in model-based algorithms\nfor offline RL, and extend them to high-dimensional visual observation spaces.\nModel-based offline RL algorithms have achieved state of the art results in\nstate based tasks and have strong theoretical guarantees. However, they rely\ncrucially on the ability to quantify uncertainty in the model predictions,\nwhich is particularly challenging with image observations. To overcome this\nchallenge, we propose to learn a latent-state dynamics model, and represent the\nuncertainty in the latent space. Our approach is both tractable in practice and\ncorresponds to maximizing a lower bound of the ELBO in the unknown POMDP. In\nexperiments on a range of challenging image-based locomotion and manipulation\ntasks, we find that our algorithm significantly outperforms previous offline\nmodel-free RL methods as well as state-of-the-art online visual model-based RL\nmethods. Moreover, we also find that our approach excels on an image-based\ndrawer closing task on a real robot using a pre-existing dataset. All results\nincluding videos can be found online at https://sites.google.com/view/lompo/ .\n", "versions": [{"version": "v1", "created": "Mon, 21 Dec 2020 18:28:17 GMT"}], "update_date": "2020-12-22", "authors_parsed": [["Rafailov", "Rafael", ""], ["Yu", "Tianhe", ""], ["Rajeswaran", "Aravind", ""], ["Finn", "Chelsea", ""]]}, {"id": "2012.11587", "submitter": "Chuang Gan", "authors": "Jianwei Yang, Jiayuan Mao, Jiajun Wu, Devi Parikh, David D. Cox,\n  Joshua B. Tenenbaum, Chuang Gan", "title": "Object-Centric Diagnosis of Visual Reasoning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When answering questions about an image, it not only needs knowing what --\nunderstanding the fine-grained contents (e.g., objects, relationships) in the\nimage, but also telling why -- reasoning over grounding visual cues to derive\nthe answer for a question. Over the last few years, we have seen significant\nprogress on visual question answering. Though impressive as the accuracy grows,\nit still lags behind to get knowing whether these models are undertaking\ngrounding visual reasoning or just leveraging spurious correlations in the\ntraining data. Recently, a number of works have attempted to answer this\nquestion from perspectives such as grounding and robustness. However, most of\nthem are either focusing on the language side or coarsely studying the\npixel-level attention maps. In this paper, by leveraging the step-wise object\ngrounding annotations provided in the GQA dataset, we first present a\nsystematical object-centric diagnosis of visual reasoning on grounding and\nrobustness, particularly on the vision side. According to the extensive\ncomparisons across different models, we find that even models with high\naccuracy are not good at grounding objects precisely, nor robust to visual\ncontent perturbations. In contrast, symbolic and modular models have a\nrelatively better grounding and robustness, though at the cost of accuracy. To\nreconcile these different aspects, we further develop a diagnostic model,\nnamely Graph Reasoning Machine. Our model replaces purely symbolic visual\nrepresentation with probabilistic scene graph and then applies teacher-forcing\ntraining for the visual reasoning module. The designed model improves the\nperformance on all three metrics over the vanilla neural-symbolic model while\ninheriting the transparency. Further ablation studies suggest that this\nimprovement is mainly due to more accurate image understanding and proper\nintermediate reasoning supervisions.\n", "versions": [{"version": "v1", "created": "Mon, 21 Dec 2020 18:59:28 GMT"}], "update_date": "2020-12-22", "authors_parsed": [["Yang", "Jianwei", ""], ["Mao", "Jiayuan", ""], ["Wu", "Jiajun", ""], ["Parikh", "Devi", ""], ["Cox", "David D.", ""], ["Tenenbaum", "Joshua B.", ""], ["Gan", "Chuang", ""]]}, {"id": "2012.11599", "submitter": "Ishani Mondal", "authors": "Ishani Mondal", "title": "BERTChem-DDI : Improved Drug-Drug Interaction Prediction from text using\n  Chemical Structure Information", "comments": "arXiv admin note: substantial text overlap with arXiv:2012.11142", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Traditional biomedical version of embeddings obtained from pre-trained\nlanguage models have recently shown state-of-the-art results for relation\nextraction (RE) tasks in the medical domain. In this paper, we explore how to\nincorporate domain knowledge, available in the form of molecular structure of\ndrugs, for predicting Drug-Drug Interaction from textual corpus. We propose a\nmethod, BERTChem-DDI, to efficiently combine drug embeddings obtained from the\nrich chemical structure of drugs along with off-the-shelf domain-specific\nBioBERT embedding-based RE architecture. Experiments conducted on the\nDDIExtraction 2013 corpus clearly indicate that this strategy improves other\nstrong baselines architectures by 3.4\\% macro F1-score.\n", "versions": [{"version": "v1", "created": "Mon, 21 Dec 2020 07:13:52 GMT"}], "update_date": "2020-12-23", "authors_parsed": [["Mondal", "Ishani", ""]]}, {"id": "2012.11634", "submitter": "Henrique Santos", "authors": "Henrique Santos, Minor Gordon, Zhicheng Liang, Gretchen Forbush,\n  Deborah L. McGuinness", "title": "Exploring and Analyzing Machine Commonsense Benchmarks", "comments": "Commonsense Knowledge Graphs Workshop 2021 (CSKGs) @AAAI-21", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Commonsense question-answering (QA) tasks, in the form of benchmarks, are\nconstantly being introduced for challenging and comparing commonsense QA\nsystems. The benchmarks provide question sets that systems' developers can use\nto train and test new models before submitting their implementations to\nofficial leaderboards. Although these tasks are created to evaluate systems in\nidentified dimensions (e.g. topic, reasoning type), this metadata is limited\nand largely presented in an unstructured format or completely not present.\nBecause machine common sense is a fast-paced field, the problem of fully\nassessing current benchmarks and systems with regards to these evaluation\ndimensions is aggravated. We argue that the lack of a common vocabulary for\naligning these approaches' metadata limits researchers in their efforts to\nunderstand systems' deficiencies and in making effective choices for future\ntasks. In this paper, we first discuss this MCS ecosystem in terms of its\nelements and their metadata. Then, we present how we are supporting the\nassessment of approaches by initially focusing on commonsense benchmarks. We\ndescribe our initial MCS Benchmark Ontology, an extensible common vocabulary\nthat formalizes benchmark metadata, and showcase how it is supporting the\ndevelopment of a Benchmark tool that enables benchmark exploration and\nanalysis.\n", "versions": [{"version": "v1", "created": "Mon, 21 Dec 2020 19:01:55 GMT"}], "update_date": "2020-12-23", "authors_parsed": [["Santos", "Henrique", ""], ["Gordon", "Minor", ""], ["Liang", "Zhicheng", ""], ["Forbush", "Gretchen", ""], ["McGuinness", "Deborah L.", ""]]}, {"id": "2012.11635", "submitter": "Muhammad Khalifa", "authors": "Muhammad Khalifa, Hady Elsahar, Marc Dymetman", "title": "A Distributional Approach to Controlled Text Generation", "comments": "ICLR 2021 camera-ready version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We propose a Distributional Approach for addressing Controlled Text\nGeneration from pre-trained Language Models (LMs). This approach permits to\nspecify, in a single formal framework, both \"pointwise\" and \"distributional\"\nconstraints over the target LM -- to our knowledge, the first model with such\ngenerality -- while minimizing KL divergence from the initial LM distribution.\nThe optimal target distribution is then uniquely determined as an explicit EBM\n(Energy-Based Model) representation. From that optimal representation we then\ntrain a target controlled Autoregressive LM through an adaptive distributional\nvariant of Policy Gradient. We conduct a first set of experiments over\npointwise constraints showing the advantages of our approach over a set of\nbaselines, in terms of obtaining a controlled LM balancing constraint\nsatisfaction with divergence from the initial LM. We then perform experiments\nover distributional constraints, a unique feature of our approach,\ndemonstrating its potential as a remedy to the problem of Bias in Language\nModels. Through an ablation study, we show the effectiveness of our adaptive\ntechnique for obtaining faster convergence. (Code available at\nhttps://github.com/naver/gdc)\n", "versions": [{"version": "v1", "created": "Mon, 21 Dec 2020 19:02:41 GMT"}, {"version": "v2", "created": "Thu, 6 May 2021 10:18:59 GMT"}], "update_date": "2021-05-07", "authors_parsed": [["Khalifa", "Muhammad", ""], ["Elsahar", "Hady", ""], ["Dymetman", "Marc", ""]]}, {"id": "2012.11643", "submitter": "Gabriela Sejnova", "authors": "Michal Vavrecka, Nikita Sokovnin, Megi Mejdrechova, Gabriela Sejnova,\n  Marek Otahal", "title": "myGym: Modular Toolkit for Visuomotor Robotic Tasks", "comments": "6 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We introduce a novel virtual robotic toolkit myGym, developed for\nreinforcement learning (RL), intrinsic motivation and imitation learning tasks\ntrained in a 3D simulator. The trained tasks can then be easily transferred to\nreal-world robotic scenarios. The modular structure of the simulator enables\nusers to train and validate their algorithms on a large number of scenarios\nwith various robots, environments and tasks. Compared to existing toolkits\n(e.g. OpenAI Gym, Roboschool) which are suitable for classical RL, myGym is\nalso prepared for visuomotor (combining vision & movement) unsupervised tasks\nthat require intrinsic motivation, i.e. the robots are able to generate their\nown goals. There are also collaborative scenarios intended for human-robot\ninteraction. The toolkit provides pretrained visual modules for visuomotor\ntasks allowing rapid prototyping, and, moreover, users can customize the visual\nsubmodules and retrain with their own set of objects. In practice, the user\nselects the desired environment, robot, objects, task and type of reward as\nsimulation parameters, and the training, visualization and testing themselves\nare handled automatically. The user can thus fully focus on development of the\nneural network architecture while controlling the behaviour of the environment\nusing predefined parameters.\n", "versions": [{"version": "v1", "created": "Mon, 21 Dec 2020 19:15:05 GMT"}], "update_date": "2020-12-23", "authors_parsed": [["Vavrecka", "Michal", ""], ["Sokovnin", "Nikita", ""], ["Mejdrechova", "Megi", ""], ["Sejnova", "Gabriela", ""], ["Otahal", "Marek", ""]]}, {"id": "2012.11685", "submitter": "Bhaskar Mitra", "authors": "Bhaskar Mitra", "title": "Neural Methods for Effective, Efficient, and Exposure-Aware Information\n  Retrieval", "comments": "PhD thesis, Univ College London (2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks with deep architectures have demonstrated significant\nperformance improvements in computer vision, speech recognition, and natural\nlanguage processing. The challenges in information retrieval (IR), however, are\ndifferent from these other application areas. A common form of IR involves\nranking of documents--or short passages--in response to keyword-based queries.\nEffective IR systems must deal with query-document vocabulary mismatch problem,\nby modeling relationships between different query and document terms and how\nthey indicate relevance. Models should also consider lexical matches when the\nquery contains rare terms--such as a person's name or a product model\nnumber--not seen during training, and to avoid retrieving semantically related\nbut irrelevant results. In many real-life IR tasks, the retrieval involves\nextremely large collections--such as the document index of a commercial Web\nsearch engine--containing billions of documents. Efficient IR methods should\ntake advantage of specialized IR data structures, such as inverted index, to\nefficiently retrieve from large collections. Given an information need, the IR\nsystem also mediates how much exposure an information artifact receives by\ndeciding whether it should be displayed, and where it should be positioned,\namong other results. Exposure-aware IR systems may optimize for additional\nobjectives, besides relevance, such as parity of exposure for retrieved items\nand content publishers. In this thesis, we present novel neural architectures\nand methods motivated by the specific needs and challenges of IR tasks.\n", "versions": [{"version": "v1", "created": "Mon, 21 Dec 2020 21:20:16 GMT"}, {"version": "v2", "created": "Fri, 19 Mar 2021 21:47:04 GMT"}], "update_date": "2021-03-23", "authors_parsed": [["Mitra", "Bhaskar", ""]]}, {"id": "2012.11689", "submitter": "Kai Wei", "authors": "Jixuan Wang, Kai Wei, Martin Radfar, Weiwei Zhang, Clement Chung", "title": "Encoding Syntactic Knowledge in Transformer Encoder for Intent Detection\n  and Slot Filling", "comments": "This is a pre-print version of paper accepted by AAAI2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We propose a novel Transformer encoder-based architecture with syntactical\nknowledge encoded for intent detection and slot filling. Specifically, we\nencode syntactic knowledge into the Transformer encoder by jointly training it\nto predict syntactic parse ancestors and part-of-speech of each token via\nmulti-task learning. Our model is based on self-attention and feed-forward\nlayers and does not require external syntactic information to be available at\ninference time. Experiments show that on two benchmark datasets, our models\nwith only two Transformer encoder layers achieve state-of-the-art results.\nCompared to the previously best performed model without pre-training, our\nmodels achieve absolute F1 score and accuracy improvement of 1.59% and 0.85%\nfor slot filling and intent detection on the SNIPS dataset, respectively. Our\nmodels also achieve absolute F1 score and accuracy improvement of 0.1% and\n0.34% for slot filling and intent detection on the ATIS dataset, respectively,\nover the previously best performed model. Furthermore, the visualization of the\nself-attention weights illustrates the benefits of incorporating syntactic\ninformation during training.\n", "versions": [{"version": "v1", "created": "Mon, 21 Dec 2020 21:25:11 GMT"}], "update_date": "2020-12-23", "authors_parsed": [["Wang", "Jixuan", ""], ["Wei", "Kai", ""], ["Radfar", "Martin", ""], ["Zhang", "Weiwei", ""], ["Chung", "Clement", ""]]}, {"id": "2012.11705", "submitter": "John Hooker", "authors": "Tae Wan Kim, John Hooker, Thomas Donaldson", "title": "Taking Principles Seriously: A Hybrid Approach to Value Alignment", "comments": "arXiv admin note: substantial text overlap with arXiv:1907.05447", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CY", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  An important step in the development of value alignment (VA) systems in AI is\nunderstanding how VA can reflect valid ethical principles. We propose that\ndesigners of VA systems incorporate ethics by utilizing a hybrid approach in\nwhich both ethical reasoning and empirical observation play a role. This, we\nargue, avoids committing the \"naturalistic fallacy,\" which is an attempt to\nderive \"ought\" from \"is,\" and it provides a more adequate form of ethical\nreasoning when the fallacy is not committed. Using quantified model logic, we\nprecisely formulate principles derived from deontological ethics and show how\nthey imply particular \"test propositions\" for any given action plan in an AI\nrule base. The action plan is ethical only if the test proposition is\nempirically true, a judgment that is made on the basis of empirical VA. This\npermits empirical VA to integrate seamlessly with independently justified\nethical principles.\n", "versions": [{"version": "v1", "created": "Mon, 21 Dec 2020 22:05:07 GMT"}], "update_date": "2020-12-23", "authors_parsed": [["Kim", "Tae Wan", ""], ["Hooker", "John", ""], ["Donaldson", "Thomas", ""]]}, {"id": "2012.11715", "submitter": "Nymisha Bandi", "authors": "Nymisha Bandi and Theja Tulabandhula", "title": "Off-Policy Optimization of Portfolio Allocation Policies under\n  Constraints", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI q-fin.PM", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The dynamic portfolio optimization problem in finance frequently requires\nlearning policies that adhere to various constraints, driven by investor\npreferences and risk. We motivate this problem of finding an allocation policy\nwithin a sequential decision making framework and study the effects of: (a)\nusing data collected under previously employed policies, which may be\nsub-optimal and constraint-violating, and (b) imposing desired constraints\nwhile computing near-optimal policies with this data. Our framework relies on\nsolving a minimax objective, where one player evaluates policies via off-policy\nestimators, and the opponent uses an online learning strategy to control\nconstraint violations. We extensively investigate various choices for\noff-policy estimation and their corresponding optimization sub-routines, and\nquantify their impact on computing constraint-aware allocation policies. Our\nstudy shows promising results for constructing such policies when back-tested\non historical equities data, under various regimes of operation, dimensionality\nand constraints.\n", "versions": [{"version": "v1", "created": "Mon, 21 Dec 2020 22:22:04 GMT"}], "update_date": "2020-12-23", "authors_parsed": [["Bandi", "Nymisha", ""], ["Tulabandhula", "Theja", ""]]}, {"id": "2012.11717", "submitter": "Yuejiang Liu", "authors": "Yuejiang Liu, Qi Yan, Alexandre Alahi", "title": "Social NCE: Contrastive Learning of Socially-aware Motion\n  Representations", "comments": "Code is available at\n  https://github.com/vita-epfl/social-nce-crowdnav,\n  https://github.com/YuejiangLIU/social-nce-trajectron-plus-plus and\n  https://github.com/qiyan98/social-nce-stgcnn", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning socially-aware motion representations is at the core of recent\nadvances in human trajectory forecasting and robot navigation in crowded\nspaces. Despite promising progress, existing neural motion models often\nstruggle to generalize in closed-loop operations (e.g., output colliding\ntrajectories), when the training set lacks examples collected from dangerous\nscenarios. In this work, we propose to address this issue via contrastive\nlearning with negative data augmentation. Concretely, we introduce a social\ncontrastive loss that encourages the encoded motion representation to preserve\nsufficient information for distinguishing a positive future event from a set of\nnegative ones. We explicitly draw these negative samples based on our domain\nknowledge of unfavorable circumstances in the multi-agent context. Experimental\nresults show that the proposed method dramatically reduces the collision rates\nof recent trajectory forecasting, behavioral cloning and reinforcement learning\nalgorithms, outperforming current state-of-the-art models on several\nbenchmarks. Our method makes few assumptions about neural architecture designs,\nand hence can be used as a generic way to promote the robustness of neural\nmotion models.\n", "versions": [{"version": "v1", "created": "Mon, 21 Dec 2020 22:25:06 GMT"}, {"version": "v2", "created": "Thu, 15 Apr 2021 17:54:33 GMT"}], "update_date": "2021-04-16", "authors_parsed": [["Liu", "Yuejiang", ""], ["Yan", "Qi", ""], ["Alahi", "Alexandre", ""]]}, {"id": "2012.11727", "submitter": "Jeremiah Deng", "authors": "Jinyong Hou, Jeremiah D. Deng, Stephen Cranefield, Xuejie Ding", "title": "Cross-Domain Latent Modulation for Variational Transfer Learning", "comments": "10 pages, 7 figures, to appear in IEEE WACV'21", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We propose a cross-domain latent modulation mechanism within a variational\nautoencoders (VAE) framework to enable improved transfer learning. Our key idea\nis to procure deep representations from one data domain and use it as\nperturbation to the reparameterization of the latent variable in another\ndomain. Specifically, deep representations of the source and target domains are\nfirst extracted by a unified inference model and aligned by employing gradient\nreversal. Second, the learned deep representations are cross-modulated to the\nlatent encoding of the alternate domain. The consistency between the\nreconstruction from the modulated latent encoding and the generation using deep\nrepresentation samples is then enforced in order to produce inter-class\nalignment in the latent space. We apply the proposed model to a number of\ntransfer learning tasks including unsupervised domain adaptation and\nimage-toimage translation. Experimental results show that our model gives\ncompetitive performance.\n", "versions": [{"version": "v1", "created": "Mon, 21 Dec 2020 22:45:00 GMT"}], "update_date": "2020-12-23", "authors_parsed": [["Hou", "Jinyong", ""], ["Deng", "Jeremiah D.", ""], ["Cranefield", "Stephen", ""], ["Ding", "Xuejie", ""]]}, {"id": "2012.11731", "submitter": "Richard Olaniyan", "authors": "Richard Olaniyan and Muthucumaru Maheswaran", "title": "A Fast Edge-Based Synchronizer for Tasks in Real-Time Artificial\n  Intelligence Applications", "comments": "11 pages, 20 figures, journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Real-time artificial intelligence (AI) applications mapped onto edge\ncomputing need to perform data capture, process data, and device actuation\nwithin given bounds while using the available devices. Task synchronization\nacross the devices is an important problem that affects the timely progress of\nan AI application by determining the quality of the captured data, time to\nprocess the data, and the quality of actuation. In this paper, we develop a\nfast edge-based synchronization scheme that can time align the execution of\ninput-output tasks as well compute tasks. The primary idea of the fast\nsynchronizer is to cluster the devices into groups that are highly synchronized\nin their task executions and statically determine few synchronization points\nusing a game-theoretic solver. The cluster of devices use a late notification\nprotocol to select the best point among the pre-computed synchronization points\nto reach a time aligned task execution as quickly as possible. We evaluate the\nperformance of our synchronization scheme using trace-driven simulations and we\ncompare the performance with existing distributed synchronization schemes for\nreal-time AI application tasks. We implement our synchronization scheme and\ncompare its training accuracy and training time with other parameter server\nsynchronization frameworks.\n", "versions": [{"version": "v1", "created": "Mon, 21 Dec 2020 23:02:21 GMT"}], "update_date": "2020-12-23", "authors_parsed": [["Olaniyan", "Richard", ""], ["Maheswaran", "Muthucumaru", ""]]}, {"id": "2012.11769", "submitter": "Minhao Cheng", "authors": "Minhao Cheng, Pin-Yu Chen, Sijia Liu, Shiyu Chang, Cho-Jui Hsieh,\n  Payel Das", "title": "Self-Progressing Robust Training", "comments": "Accepted in AAAI2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Enhancing model robustness under new and even adversarial environments is a\ncrucial milestone toward building trustworthy machine learning systems. Current\nrobust training methods such as adversarial training explicitly uses an\n\"attack\" (e.g., $\\ell_{\\infty}$-norm bounded perturbation) to generate\nadversarial examples during model training for improving adversarial\nrobustness. In this paper, we take a different perspective and propose a new\nframework called SPROUT, self-progressing robust training. During model\ntraining, SPROUT progressively adjusts training label distribution via our\nproposed parametrized label smoothing technique, making training free of attack\ngeneration and more scalable. We also motivate SPROUT using a general\nformulation based on vicinity risk minimization, which includes many robust\ntraining methods as special cases. Compared with state-of-the-art adversarial\ntraining methods (PGD-l_inf and TRADES) under l_inf-norm bounded attacks and\nvarious invariance tests, SPROUT consistently attains superior performance and\nis more scalable to large neural networks. Our results shed new light on\nscalable, effective and attack-independent robust training methods.\n", "versions": [{"version": "v1", "created": "Tue, 22 Dec 2020 00:45:24 GMT"}], "update_date": "2020-12-23", "authors_parsed": [["Cheng", "Minhao", ""], ["Chen", "Pin-Yu", ""], ["Liu", "Sijia", ""], ["Chang", "Shiyu", ""], ["Hsieh", "Cho-Jui", ""], ["Das", "Payel", ""]]}, {"id": "2012.11774", "submitter": "Amirsina Torfi", "authors": "Amirsina Torfi and Edward A. Fox and Chandan K. Reddy", "title": "Differentially Private Synthetic Medical Data Generation using\n  Convolutional GANs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Deep learning models have demonstrated superior performance in several\napplication problems, such as image classification and speech processing.\nHowever, creating a deep learning model using health record data requires\naddressing certain privacy challenges that bring unique concerns to researchers\nworking in this domain. One effective way to handle such private data issues is\nto generate realistic synthetic data that can provide practically acceptable\ndata quality and correspondingly the model performance. To tackle this\nchallenge, we develop a differentially private framework for synthetic data\ngeneration using R\\'enyi differential privacy. Our approach builds on\nconvolutional autoencoders and convolutional generative adversarial networks to\npreserve some of the critical characteristics of the generated synthetic data.\nIn addition, our model can also capture the temporal information and feature\ncorrelations that might be present in the original data. We demonstrate that\nour model outperforms existing state-of-the-art models under the same privacy\nbudget using several publicly available benchmark medical datasets in both\nsupervised and unsupervised settings.\n", "versions": [{"version": "v1", "created": "Tue, 22 Dec 2020 01:03:49 GMT"}], "update_date": "2020-12-23", "authors_parsed": [["Torfi", "Amirsina", ""], ["Fox", "Edward A.", ""], ["Reddy", "Chandan K.", ""]]}, {"id": "2012.11783", "submitter": "Wei Cui", "authors": "Wei Cui and Wei Yu", "title": "Scalable Deep Reinforcement Learning for Routing and Spectrum Access in\n  Physical Layer", "comments": "13 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.AI cs.LG cs.MA cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a novel and scalable reinforcement learning approach for\nsimultaneous routing and spectrum access in wireless ad-hoc networks. In most\nprevious works on reinforcement learning for network optimization, routing and\nspectrum access are tackled as separate tasks; further, the wireless links in\nthe network are assumed to be fixed, and a different agent is trained for each\ntransmission node -- this limits scalability and generalizability. In this\npaper, we account for the inherent signal-to-interference-plus-noise ratio\n(SINR) in the physical layer and propose a more scalable approach in which a\nsingle agent is associated with each flow. Specifically, a single agent makes\nall routing and spectrum access decisions as it moves along the frontier nodes\nof each flow. The agent is trained according to the physical layer\ncharacteristics of the environment using the future bottleneck SINR as a novel\nreward definition. This allows a highly effective routing strategy based on the\ngeographic locations of the nodes in the wireless ad-hoc network. The proposed\ndeep reinforcement learning strategy is capable of accounting for the mutual\ninterference between the links. It learns to avoid interference by\nintelligently allocating spectrum slots and making routing decisions for the\nentire network in a scalable manner.\n", "versions": [{"version": "v1", "created": "Tue, 22 Dec 2020 01:47:20 GMT"}], "update_date": "2020-12-23", "authors_parsed": [["Cui", "Wei", ""], ["Yu", "Wei", ""]]}, {"id": "2012.11788", "submitter": "Kaivalya Rawal", "authors": "Kaivalya Rawal, Ece Kamar, Himabindu Lakkaraju", "title": "Algorithmic Recourse in the Wild: Understanding the Impact of Data and\n  Model Shifts", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  As predictive models are increasingly being deployed to make a variety of\nconsequential decisions, there is a growing emphasis on designing algorithms\nthat can provide recourse to affected individuals. Existing recourse algorithms\nfunction under the assumption that the underlying predictive model does not\nchange. However, models are regularly updated in practice for several reasons\nincluding data distribution shifts. In this work, we make the first attempt at\nunderstanding how model updates resulting from data distribution shifts impact\nthe algorithmic recourses generated by state-of-the-art algorithms. We carry\nout a rigorous theoretical and empirical analysis to address the above\nquestion. Our theoretical results establish a lower bound on the probability of\nrecourse invalidation due to model shifts, and show the existence of a tradeoff\nbetween this invalidation probability and typical notions of \"cost\" minimized\nby modern recourse generation algorithms. We experiment with multiple synthetic\nand real world datasets, capturing different kinds of distribution shifts\nincluding temporal shifts, geospatial shifts, and shifts due to data\ncorrection. These experiments demonstrate that model updation due to all the\naforementioned distribution shifts can potentially invalidate recourses\ngenerated by state-of-the-art algorithms. Our findings thus not only expose\npreviously unknown flaws in the current recourse generation paradigm, but also\npave the way for fundamentally rethinking the design and development of\nrecourse generation algorithms.\n", "versions": [{"version": "v1", "created": "Tue, 22 Dec 2020 02:06:08 GMT"}, {"version": "v2", "created": "Fri, 26 Feb 2021 17:55:17 GMT"}, {"version": "v3", "created": "Sat, 26 Jun 2021 01:58:37 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Rawal", "Kaivalya", ""], ["Kamar", "Ece", ""], ["Lakkaraju", "Himabindu", ""]]}, {"id": "2012.11792", "submitter": "Mehrdad Zakershahrak", "authors": "Mehrdad Zakershahrak and Samira Ghodratnama", "title": "Are We On The Same Page? Hierarchical Explanation Generation for\n  Planning Tasks in Human-Robot Teaming using Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Providing explanations is considered an imperative ability for an AI agent in\na human-robot teaming framework. The right explanation provides the rationale\nbehind an AI agent's decision-making. However, to maintain the human teammate's\ncognitive demand to comprehend the provided explanations, prior works have\nfocused on providing explanations in a specific order or intertwining the\nexplanation generation with plan execution. Moreover, these approaches do not\nconsider the degree of details required to share throughout the provided\nexplanations. In this work, we argue that the agent-generated explanations,\nespecially the complex ones, should be abstracted to be aligned with the level\nof details the human teammate desires to maintain the recipient's cognitive\nload. Therefore, learning a hierarchical explanations model is a challenging\ntask. Moreover, the agent needs to follow a consistent high-level policy to\ntransfer the learned teammate preferences to a new scenario while lower-level\ndetailed plans are different. Our evaluation confirmed the process of\nunderstanding an explanation, especially a complex and detailed explanation, is\nhierarchical. The human preference that reflected this aspect corresponded\nexactly to creating and employing abstraction for knowledge assimilation hidden\ndeeper in our cognitive process. We showed that hierarchical explanations\nachieved better task performance and behavior interpretability while reduced\ncognitive load. These results shed light on designing explainable agents\nutilizing reinforcement learning and planning across various domains.\n", "versions": [{"version": "v1", "created": "Tue, 22 Dec 2020 02:14:52 GMT"}, {"version": "v2", "created": "Fri, 26 Feb 2021 03:42:47 GMT"}], "update_date": "2021-03-01", "authors_parsed": [["Zakershahrak", "Mehrdad", ""], ["Ghodratnama", "Samira", ""]]}, {"id": "2012.11804", "submitter": "Liang Li", "authors": "Liang Li, Dian Shi, Ronghui Hou, Hui Li, Miao Pan, Zhu Han", "title": "To Talk or to Work: Flexible Communication Compression for Energy\n  Efficient Federated Learning over Heterogeneous Mobile Edge Devices", "comments": "Accepted for publication in INFOCOM'21", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recent advances in machine learning, wireless communication, and mobile\nhardware technologies promisingly enable federated learning (FL) over massive\nmobile edge devices, which opens new horizons for numerous intelligent mobile\napplications. Despite the potential benefits, FL imposes huge communication and\ncomputation burdens on participating devices due to periodical global\nsynchronization and continuous local training, raising great challenges to\nbattery constrained mobile devices. In this work, we target at improving the\nenergy efficiency of FL over mobile edge networks to accommodate heterogeneous\nparticipating devices without sacrificing the learning performance. To this\nend, we develop a convergence-guaranteed FL algorithm enabling flexible\ncommunication compression. Guided by the derived convergence bound, we design a\ncompression control scheme to balance the energy consumption of local computing\n(i.e., \"working\") and wireless communication (i.e., \"talking\") from the\nlong-term learning perspective. In particular, the compression parameters are\nelaborately chosen for FL participants adapting to their computing and\ncommunication environments. Extensive simulations are conducted using various\ndatasets to validate our theoretical analysis, and the results also demonstrate\nthe efficacy of the proposed scheme in energy saving.\n", "versions": [{"version": "v1", "created": "Tue, 22 Dec 2020 02:54:18 GMT"}], "update_date": "2020-12-23", "authors_parsed": [["Li", "Liang", ""], ["Shi", "Dian", ""], ["Hou", "Ronghui", ""], ["Li", "Hui", ""], ["Pan", "Miao", ""], ["Han", "Zhu", ""]]}, {"id": "2012.11810", "submitter": "Haoyu He", "authors": "Haoyu He, Jing Zhang, Bhavani Thuraisingham, Dacheng Tao", "title": "Progressive One-shot Human Parsing", "comments": "Accepted in AAAI 2021. 9 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Prior human parsing models are limited to parsing humans into classes\npre-defined in the training data, which is not flexible to generalize to unseen\nclasses, e.g., new clothing in fashion analysis. In this paper, we propose a\nnew problem named one-shot human parsing (OSHP) that requires to parse human\ninto an open set of reference classes defined by any single reference example.\nDuring training, only base classes defined in the training set are exposed,\nwhich can overlap with part of reference classes. In this paper, we devise a\nnovel Progressive One-shot Parsing network (POPNet) to address two critical\nchallenges , i.e., testing bias and small sizes. POPNet consists of two\ncollaborative metric learning modules named Attention Guidance Module and\nNearest Centroid Module, which can learn representative prototypes for base\nclasses and quickly transfer the ability to unseen classes during testing,\nthereby reducing testing bias. Moreover, POPNet adopts a progressive human\nparsing framework that can incorporate the learned knowledge of parent classes\nat the coarse granularity to help recognize the descendant classes at the fine\ngranularity, thereby handling the small sizes issue. Experiments on the ATR-OS\nbenchmark tailored for OSHP demonstrate POPNet outperforms other representative\none-shot segmentation models by large margins and establishes a strong\nbaseline. Source code can be found at\nhttps://github.com/Charleshhy/One-shot-Human-Parsing.\n", "versions": [{"version": "v1", "created": "Tue, 22 Dec 2020 03:06:11 GMT"}, {"version": "v2", "created": "Tue, 16 Mar 2021 04:50:06 GMT"}, {"version": "v3", "created": "Fri, 7 May 2021 11:51:23 GMT"}], "update_date": "2021-05-10", "authors_parsed": [["He", "Haoyu", ""], ["Zhang", "Jing", ""], ["Thuraisingham", "Bhavani", ""], ["Tao", "Dacheng", ""]]}, {"id": "2012.11812", "submitter": "Shuang Zhou", "authors": "Shuang Zhou, Lingchao Guo, Zhaoming Lu, Xiangming Wen, Wei Zheng,\n  Yiming Wang", "title": "Subject-independent Human Pose Image Construction with Commodity Wi-Fi", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, commodity Wi-Fi devices have been shown to be able to construct\nhuman pose images, i.e., human skeletons, as fine-grained as cameras. Existing\npapers achieve good results when constructing the images of subjects who are in\nthe prior training samples. However, the performance drops when it comes to new\nsubjects, i.e., the subjects who are not in the training samples. This paper\nfocuses on solving the subject-generalization problem in human pose image\nconstruction. To this end, we define the subject as the domain. Then we design\na Domain-Independent Neural Network (DINN) to extract subject-independent\nfeatures and convert them into fine-grained human pose images. We also propose\na novel training method to train the DINN and it has no re-training overhead\ncomparing with the domain-adversarial approach. We build a prototype system and\nexperimental results demonstrate that our system can construct fine-grained\nhuman pose images of new subjects with commodity Wi-Fi in both the visible and\nthrough-wall scenarios, which shows the effectiveness and the\nsubject-generalization ability of our model.\n", "versions": [{"version": "v1", "created": "Tue, 22 Dec 2020 03:15:56 GMT"}], "update_date": "2020-12-23", "authors_parsed": [["Zhou", "Shuang", ""], ["Guo", "Lingchao", ""], ["Lu", "Zhaoming", ""], ["Wen", "Xiangming", ""], ["Zheng", "Wei", ""], ["Wang", "Yiming", ""]]}, {"id": "2012.11821", "submitter": "Bijaya Adhikari", "authors": "Sorour E. Amiri, Bijaya Adhikari, John Wenskovitch, Alexander\n  Rodriguez, Michelle Dowling, Chris North, and B. Aditya Prakash", "title": "NetReAct: Interactive Learning for Network Summarization", "comments": "Presented at NeuRIPS 2020 HAMLETS", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Generating useful network summaries is a challenging and important problem\nwith several applications like sensemaking, visualization, and compression.\nHowever, most of the current work in this space do not take human feedback into\naccount while generating summaries. Consider an intelligence analysis scenario,\nwhere the analyst is exploring a similarity network between documents. The\nanalyst can express her agreement/disagreement with the visualization of the\nnetwork summary via iterative feedback, e.g. closing or moving documents\n(\"nodes\") together. How can we use this feedback to improve the network summary\nquality? In this paper, we present NetReAct, a novel interactive network\nsummarization algorithm which supports the visualization of networks induced by\ntext corpora to perform sensemaking. NetReAct incorporates human feedback with\nreinforcement learning to summarize and visualize document networks. Using\nscenarios from two datasets, we show how NetReAct is successful in generating\nhigh-quality summaries and visualizations that reveal hidden patterns better\nthan other non-trivial baselines.\n", "versions": [{"version": "v1", "created": "Tue, 22 Dec 2020 03:56:26 GMT"}], "update_date": "2020-12-23", "authors_parsed": [["Amiri", "Sorour E.", ""], ["Adhikari", "Bijaya", ""], ["Wenskovitch", "John", ""], ["Rodriguez", "Alexander", ""], ["Dowling", "Michelle", ""], ["North", "Chris", ""], ["Prakash", "B. Aditya", ""]]}, {"id": "2012.11835", "submitter": "Xuefei Ning", "authors": "Xuefei Ning, Junbo Zhao, Wenshuo Li, Tianchen Zhao, Yin Zheng,\n  Huazhong Yang, Yu Wang", "title": "Discovering Robust Convolutional Architecture at Targeted Capacity: A\n  Multi-Shot Approach", "comments": "9 pages, 9 pages appendices", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional neural networks (CNNs) are vulnerable to adversarial examples,\nand studies show that increasing the model capacity of an architecture topology\n(e.g., width expansion) can bring consistent robustness improvements. This\nreveals a clear robustness-efficiency trade-off that should be considered in\narchitecture design. In this paper, considering scenarios with capacity budget,\nwe aim to discover adversarially robust architecture at targeted capacities.\nRecent studies employed one-shot neural architecture search (NAS) to discover\nrobust architectures. However, since the capacities of different topologies\ncannot be aligned in the search process, one-shot NAS methods favor topologies\nwith larger capacities in the supernet. And the discovered topology might be\nsuboptimal when augmented to the targeted capacity. We propose a novel\nmulti-shot NAS method to address this issue and explicitly search for robust\narchitectures at targeted capacities. At the targeted FLOPs of 2000M, the\ndiscovered MSRobNet-2000 outperforms the recent NAS-discovered architecture\nRobNet-large under various criteria by a large margin of 4%-7%. And at the\ntargeted FLOPs of 1560M, MSRobNet-1560 surpasses another NAS-discovered\narchitecture RobNet-free by 2.3% and 1.3% in the clean and PGD-7 accuracies,\nrespectively. All codes are available at https://github.com/walkerning/aw\\_nas.\n", "versions": [{"version": "v1", "created": "Tue, 22 Dec 2020 05:21:25 GMT"}, {"version": "v2", "created": "Fri, 1 Jan 2021 09:44:52 GMT"}, {"version": "v3", "created": "Sat, 27 Mar 2021 03:36:02 GMT"}], "update_date": "2021-03-30", "authors_parsed": [["Ning", "Xuefei", ""], ["Zhao", "Junbo", ""], ["Li", "Wenshuo", ""], ["Zhao", "Tianchen", ""], ["Zheng", "Yin", ""], ["Yang", "Huazhong", ""], ["Wang", "Yu", ""]]}, {"id": "2012.11847", "submitter": "Xiaopeng Guo", "authors": "Liye Mei, Yalan Yu, Yueyun Weng, Xiaopeng Guo, Yan Liu, Du Wang, Sheng\n  Liu, Fuling Zhou, and Cheng Lei", "title": "Adversarial Multiscale Feature Learning for Overlapping Chromosome\n  Segmentation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Chromosome karyotype analysis is of great clinical importance in the\ndiagnosis and treatment of diseases, especially for genetic diseases. Since\nmanual analysis is highly time and effort consuming, computer-assisted\nautomatic chromosome karyotype analysis based on images is routinely used to\nimprove the efficiency and accuracy of the analysis. Due to the strip shape of\nthe chromosomes, they easily get overlapped with each other when imaged,\nsignificantly affecting the accuracy of the analysis afterward. Conventional\noverlapping chromosome segmentation methods are usually based on manually\ntagged features, hence, the performance of which is easily affected by the\nquality, such as resolution and brightness, of the images. To address the\nproblem, in this paper, we present an adversarial multiscale feature learning\nframework to improve the accuracy and adaptability of overlapping chromosome\nsegmentation. Specifically, we first adopt the nested U-shape network with\ndense skip connections as the generator to explore the optimal representation\nof the chromosome images by exploiting multiscale features. Then we use the\nconditional generative adversarial network (cGAN) to generate images similar to\nthe original ones, the training stability of which is enhanced by applying the\nleast-square GAN objective. Finally, we employ Lovasz-Softmax to help the model\nconverge in a continuous optimization setting. Comparing with the established\nalgorithms, the performance of our framework is proven superior by using public\ndatasets in eight evaluation criteria, showing its great potential in\noverlapping chromosome segmentation\n", "versions": [{"version": "v1", "created": "Tue, 22 Dec 2020 06:04:22 GMT"}, {"version": "v2", "created": "Fri, 26 Mar 2021 05:44:18 GMT"}], "update_date": "2021-03-29", "authors_parsed": [["Mei", "Liye", ""], ["Yu", "Yalan", ""], ["Weng", "Yueyun", ""], ["Guo", "Xiaopeng", ""], ["Liu", "Yan", ""], ["Wang", "Du", ""], ["Liu", "Sheng", ""], ["Zhou", "Fuling", ""], ["Lei", "Cheng", ""]]}, {"id": "2012.11854", "submitter": "Zhaowei Zhu", "authors": "Zhaowei Zhu, Tongliang Liu, Yang Liu", "title": "A Second-Order Approach to Learning with Instance-Dependent Label Noise", "comments": "Learning with label noise. Accepted as an oral paper by CVPR 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The presence of label noise often misleads the training of deep neural\nnetworks. Departing from the recent literature which largely assumes the label\nnoise rate is only determined by the true label class, the errors in\nhuman-annotated labels are more likely to be dependent on the difficulty levels\nof tasks, resulting in settings with instance-dependent label noise. We first\nprovide evidences that the heterogeneous instance-dependent label noise is\neffectively down-weighting the examples with higher noise rates in a\nnon-uniform way and thus causes imbalances, rendering the strategy of directly\napplying methods for class-dependent label noise questionable. Built on a\nrecent work peer loss [24], we then propose and study the potentials of a\nsecond-order approach that leverages the estimation of several covariance terms\ndefined between the instance-dependent noise rates and the Bayes optimal label.\nWe show that this set of second-order statistics successfully captures the\ninduced imbalances. We further proceed to show that with the help of the\nestimated second-order statistics, we identify a new loss function whose\nexpected risk of a classifier under instance-dependent label noise is\nequivalent to a new problem with only class-dependent label noise. This fact\nallows us to apply existing solutions to handle this better-studied setting. We\nprovide an efficient procedure to estimate these second-order statistics\nwithout accessing either ground truth labels or prior knowledge of the noise\nrates. Experiments on CIFAR10 and CIFAR100 with synthetic instance-dependent\nlabel noise and Clothing1M with real-world human label noise verify our\napproach. Our implementation is available at https://github.com/UCSC-REAL/CAL.\n", "versions": [{"version": "v1", "created": "Tue, 22 Dec 2020 06:36:58 GMT"}, {"version": "v2", "created": "Tue, 30 Mar 2021 16:17:12 GMT"}], "update_date": "2021-03-31", "authors_parsed": [["Zhu", "Zhaowei", ""], ["Liu", "Tongliang", ""], ["Liu", "Yang", ""]]}, {"id": "2012.11867", "submitter": "Inaam Ilahi", "authors": "Inaam Ilahi, Muhammad Usama, Muhammad Omer Farooq, Muhammad Umar\n  Janjua, and Junaid Qadir", "title": "Intelligent Resource Allocation in Dense LoRa Networks using Deep\n  Reinforcement Learning", "comments": "11 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The anticipated increase in the count of IoT devices in the coming years\nmotivates the development of efficient algorithms that can help in their\neffective management while keeping the power consumption low. In this paper, we\npropose LoRaDRL and provide a detailed performance evaluation. We propose a\nmulti-channel scheme for LoRaDRL. We perform extensive experiments, and our\nresults demonstrate that the proposed algorithm not only significantly improves\nlong-range wide area network (LoRaWAN)'s packet delivery ratio (PDR) but is\nalso able to support mobile end-devices (EDs) while ensuring lower power\nconsumption. Most previous works focus on proposing different MAC protocols for\nimproving the network capacity. We show that through the use of LoRaDRL, we can\nachieve the same efficiency with ALOHA while moving the complexity from EDs to\nthe gateway thus making the EDs simpler and cheaper. Furthermore, we test the\nperformance of LoRaDRL under large-scale frequency jamming attacks and show its\nadaptiveness to the changes in the environment. We show that LoRaDRL's output\nimproves the performance of state-of-the-art techniques resulting in some cases\nan improvement of more than 500% in terms of PDR compared to learning-based\ntechniques.\n", "versions": [{"version": "v1", "created": "Tue, 22 Dec 2020 07:41:47 GMT"}], "update_date": "2020-12-23", "authors_parsed": [["Ilahi", "Inaam", ""], ["Usama", "Muhammad", ""], ["Farooq", "Muhammad Omer", ""], ["Janjua", "Muhammad Umar", ""], ["Qadir", "Junaid", ""]]}, {"id": "2012.11881", "submitter": "Sharath Nittur Sridhar", "authors": "Sharath Nittur Sridhar, Anthony Sarah", "title": "Undivided Attention: Are Intermediate Layers Necessary for BERT?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent times, BERT-based models have been extremely successful in solving\na variety of natural language processing (NLP) tasks such as reading\ncomprehension, natural language inference, sentiment analysis, etc. All\nBERT-based architectures have a self-attention block followed by a block of\nintermediate layers as the basic building component. However, a strong\njustification for the inclusion of these intermediate layers remains missing in\nthe literature. In this work we investigate the importance of intermediate\nlayers on the overall network performance of downstream tasks. We show that\nreducing the number of intermediate layers and modifying the architecture for\nBERT-Base results in minimal loss in fine-tuning accuracy for downstream tasks\nwhile decreasing the number of parameters and training time of the model.\nAdditionally, we use the central kernel alignment (CKA) similarity metric and\nprobing classifiers to demonstrate that removing intermediate layers has little\nimpact on the learned self-attention representations.\n", "versions": [{"version": "v1", "created": "Tue, 22 Dec 2020 08:46:14 GMT"}], "update_date": "2020-12-23", "authors_parsed": [["Sridhar", "Sharath Nittur", ""], ["Sarah", "Anthony", ""]]}, {"id": "2012.11898", "submitter": "Jianwei Yu", "authors": "Jia Li, Tomas Yu, Da-Cheng Juan, Arjun Gopalan, Hong Cheng, Andrew\n  Tomkins", "title": "Graph Autoencoders with Deconvolutional Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent studies have indicated that Graph Convolutional Networks (GCNs) act as\na \\emph{low pass} filter in spectral domain and encode smoothed node\nrepresentations. In this paper, we consider their opposite, namely Graph\nDeconvolutional Networks (GDNs) that reconstruct graph signals from smoothed\nnode representations. We motivate the design of Graph Deconvolutional Networks\nvia a combination of inverse filters in spectral domain and de-noising layers\nin wavelet domain, as the inverse operation results in a \\emph{high pass}\nfilter and may amplify the noise. Based on the proposed GDN, we further propose\na graph autoencoder framework that first encodes smoothed graph representations\nwith GCN and then decodes accurate graph signals with GDN. We demonstrate the\neffectiveness of the proposed method on several tasks including unsupervised\ngraph-level representation , social recommendation and graph generation\n", "versions": [{"version": "v1", "created": "Tue, 22 Dec 2020 09:49:39 GMT"}], "update_date": "2020-12-23", "authors_parsed": [["Li", "Jia", ""], ["Yu", "Tomas", ""], ["Juan", "Da-Cheng", ""], ["Gopalan", "Arjun", ""], ["Cheng", "Hong", ""], ["Tomkins", "Andrew", ""]]}, {"id": "2012.11903", "submitter": "Rijk Mercuur", "authors": "Rijk Mercuur, Virginia Dignum, Catholijn M. Jonker", "title": "Modelling Human Routines: Conceptualising Social Practice Theory for\n  Agent-Based Simulation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Our routines play an important role in a wide range of social challenges such\nas climate change, disease outbreaks and coordinating staff and patients in a\nhospital. To use agent-based simulations (ABS) to understand the role of\nroutines in social challenges we need an agent framework that integrates\nroutines. This paper provides the domain-independent Social Practice Agent\n(SoPrA) framework that satisfies requirements from the literature to simulate\nour routines. By choosing the appropriate concepts from the literature on agent\ntheory, social psychology and social practice theory we ensure SoPrA correctly\ndepicts current evidence on routines. By creating a consistent, modular and\nparsimonious framework suitable for multiple domains we enhance the usability\nof SoPrA. SoPrA provides ABS researchers with a conceptual, formal and\ncomputational framework to simulate routines and gain new insights into social\nsystems.\n", "versions": [{"version": "v1", "created": "Tue, 22 Dec 2020 10:06:47 GMT"}], "update_date": "2020-12-23", "authors_parsed": [["Mercuur", "Rijk", ""], ["Dignum", "Virginia", ""], ["Jonker", "Catholijn M.", ""]]}, {"id": "2012.11905", "submitter": "Silvan Mertes", "authors": "Silvan Mertes, Tobias Huber, Katharina Weitz, Alexander Heimerl,\n  Elisabeth Andr\\'e", "title": "This is not the Texture you are looking for! Introducing Novel\n  Counterfactual Explanations for Non-Experts using Generative Adversarial\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.HC cs.NE", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  With the ongoing rise of machine learning, the need for methods for\nexplaining decisions made by artificial intelligence systems is becoming a more\nand more important topic. Especially for image classification tasks, many\nstate-of-the-art tools to explain such classifiers rely on visual highlighting\nof important areas of the input data. Contrary, counterfactual explanation\nsystems try to enable a counterfactual reasoning by modifying the input image\nin a way such that the classifier would have made a different prediction. By\ndoing so, the users of counterfactual explanation systems are equipped with a\ncompletely different kind of explanatory information. However, methods for\ngenerating realistic counterfactual explanations for image classifiers are\nstill rare. In this work, we present a novel approach to generate such\ncounterfactual image explanations based on adversarial image-to-image\ntranslation techniques. Additionally, we conduct a user study to evaluate our\napproach in a use case which was inspired by a healthcare scenario. Our results\nshow that our approach leads to significantly better results regarding mental\nmodels, explanation satisfaction, trust, emotions, and self-efficacy than two\nstate-of-the art systems that work with saliency maps, namely LIME and LRP.\n", "versions": [{"version": "v1", "created": "Tue, 22 Dec 2020 10:08:05 GMT"}], "update_date": "2020-12-23", "authors_parsed": [["Mertes", "Silvan", ""], ["Huber", "Tobias", ""], ["Weitz", "Katharina", ""], ["Heimerl", "Alexander", ""], ["Andr\u00e9", "Elisabeth", ""]]}, {"id": "2012.11933", "submitter": "Valentin Gabeff", "authors": "Valentin Gabeff, Tomas Teijeiro, Marina Zapater, Leila Cammoun,\n  Sylvain Rheims, Philippe Ryvlin, David Atienza", "title": "Interpreting Deep Learning Models for Epileptic Seizure Detection on EEG\n  signals", "comments": "28 pages, 11 figures, 12 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  While Deep Learning (DL) is often considered the state-of-the art for\nArtificial Intelligence-based medical decision support, it remains sparsely\nimplemented in clinical practice and poorly trusted by clinicians due to\ninsufficient interpretability of neural network models. We have tackled this\nissue by developing interpretable DL models in the context of online detection\nof epileptic seizure, based on EEG signal. This has conditioned the preparation\nof the input signals, the network architecture, and the post-processing of the\noutput in line with the domain knowledge. Specifically, we focused the\ndiscussion on three main aspects: 1) how to aggregate the classification\nresults on signal segments provided by the DL model into a larger time scale,\nat the seizure-level; 2) what are the relevant frequency patterns learned in\nthe first convolutional layer of different models, and their relation with the\ndelta, theta, alpha, beta and gamma frequency bands on which the visual\ninterpretation of EEG is based; and 3) the identification of the signal\nwaveforms with larger contribution towards the ictal class, according to the\nactivation differences highlighted using the DeepLIFT method. Results show that\nthe kernel size in the first layer determines the interpretability of the\nextracted features and the sensitivity of the trained models, even though the\nfinal performance is very similar after post-processing. Also, we found that\namplitude is the main feature leading to an ictal prediction, suggesting that a\nlarger patient population would be required to learn more complex frequency\npatterns. Still, our methodology was successfully able to generalize patient\ninter-variability for the majority of the studied population with a\nclassification F1-score of 0.873 and detecting 90% of the seizures.\n", "versions": [{"version": "v1", "created": "Tue, 22 Dec 2020 11:10:23 GMT"}], "update_date": "2020-12-23", "authors_parsed": [["Gabeff", "Valentin", ""], ["Teijeiro", "Tomas", ""], ["Zapater", "Marina", ""], ["Cammoun", "Leila", ""], ["Rheims", "Sylvain", ""], ["Ryvlin", "Philippe", ""], ["Atienza", "David", ""]]}, {"id": "2012.11936", "submitter": "Valentina Anita Carriero", "authors": "Nacira Abbas, Kholoud Alghamdi, Mortaza Alinam, Francesca Alloatti,\n  Glenda Amaral, Claudia d'Amato, Luigi Asprino, Martin Beno, Felix Bensmann,\n  Russa Biswas, Ling Cai, Riley Capshaw, Valentina Anita Carriero, Irene\n  Celino, Amine Dadoun, Stefano De Giorgis, Harm Delva, John Domingue, Michel\n  Dumontier, Vincent Emonet, Marieke van Erp, Paola Espinoza Arias, Omaima\n  Fallatah, Sebasti\\'an Ferrada, Marc Gallofr\\'e Oca\\~na, Michalis Georgiou,\n  Genet Asefa Gesese, Frances Gillis-Webber, Francesca Giovannetti, Mar\\`ia\n  Granados Buey, Ismail Harrando, Ivan Heibi, Vitor Horta, Laurine Huber,\n  Federico Igne, Mohamad Yaser Jaradeh, Neha Keshan, Aneta Koleva, Bilal\n  Koteich, Kabul Kurniawan, Mengya Liu, Chuangtao Ma, Lientje Maas, Martin\n  Mansfield, Fabio Mariani, Eleonora Marzi, Sepideh Mesbah, Maheshkumar Mistry,\n  Alba Catalina Morales Tirado, Anna Nguyen, Viet Bach Nguyen, Allard Oelen,\n  Valentina Pasqual, Heiko Paulheim, Axel Polleres, Margherita Porena, Jan\n  Portisch, Valentina Presutti, Kader Pustu-Iren, Ariam Rivas Mendez, Soheil\n  Roshankish, Sebastian Rudolph, Harald Sack, Ahmad Sakor, Jaime Salas, Thomas\n  Schleider, Meilin Shi, Gianmarco Spinaci, Chang Sun, Tabea Tietz, Molka\n  Tounsi Dhouib, Alessandro Umbrico, Wouter van den Berg, Weiqin Xu", "title": "Knowledge Graphs Evolution and Preservation -- A Technical Report from\n  ISWS 2019", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the grand challenges discussed during the Dagstuhl Seminar \"Knowledge\nGraphs: New Directions for Knowledge Representation on the Semantic Web\" and\ndescribed in its report is that of a: \"Public FAIR Knowledge Graph of\nEverything: We increasingly see the creation of knowledge graphs that capture\ninformation about the entirety of a class of entities. [...] This grand\nchallenge extends this further by asking if we can create a knowledge graph of\n\"everything\" ranging from common sense concepts to location based entities.\nThis knowledge graph should be \"open to the public\" in a FAIR manner\ndemocratizing this mass amount of knowledge.\" Although linked open data (LOD)\nis one knowledge graph, it is the closest realisation (and probably the only\none) to a public FAIR Knowledge Graph (KG) of everything. Surely, LOD provides\na unique testbed for experimenting and evaluating research hypotheses on open\nand FAIR KG. One of the most neglected FAIR issues about KGs is their ongoing\nevolution and long term preservation. We want to investigate this problem, that\nis to understand what preserving and supporting the evolution of KGs means and\nhow these problems can be addressed. Clearly, the problem can be approached\nfrom different perspectives and may require the development of different\napproaches, including new theories, ontologies, metrics, strategies,\nprocedures, etc. This document reports a collaborative effort performed by 9\nteams of students, each guided by a senior researcher as their mentor,\nattending the International Semantic Web Research School (ISWS 2019). Each team\nprovides a different perspective to the problem of knowledge graph evolution\nsubstantiated by a set of research questions as the main subject of their\ninvestigation. In addition, they provide their working definition for KG\npreservation and evolution.\n", "versions": [{"version": "v1", "created": "Tue, 22 Dec 2020 11:21:09 GMT"}], "update_date": "2020-12-23", "authors_parsed": [["Abbas", "Nacira", ""], ["Alghamdi", "Kholoud", ""], ["Alinam", "Mortaza", ""], ["Alloatti", "Francesca", ""], ["Amaral", "Glenda", ""], ["d'Amato", "Claudia", ""], ["Asprino", "Luigi", ""], ["Beno", "Martin", ""], ["Bensmann", "Felix", ""], ["Biswas", "Russa", ""], ["Cai", "Ling", ""], ["Capshaw", "Riley", ""], ["Carriero", "Valentina Anita", ""], ["Celino", "Irene", ""], ["Dadoun", "Amine", ""], ["De Giorgis", "Stefano", ""], ["Delva", "Harm", ""], ["Domingue", "John", ""], ["Dumontier", "Michel", ""], ["Emonet", "Vincent", ""], ["van Erp", "Marieke", ""], ["Arias", "Paola Espinoza", ""], ["Fallatah", "Omaima", ""], ["Ferrada", "Sebasti\u00e1n", ""], ["Oca\u00f1a", "Marc Gallofr\u00e9", ""], ["Georgiou", "Michalis", ""], ["Gesese", "Genet Asefa", ""], ["Gillis-Webber", "Frances", ""], ["Giovannetti", "Francesca", ""], ["Buey", "Mar\u00eca Granados", ""], ["Harrando", "Ismail", ""], ["Heibi", "Ivan", ""], ["Horta", "Vitor", ""], ["Huber", "Laurine", ""], ["Igne", "Federico", ""], ["Jaradeh", "Mohamad Yaser", ""], ["Keshan", "Neha", ""], ["Koleva", "Aneta", ""], ["Koteich", "Bilal", ""], ["Kurniawan", "Kabul", ""], ["Liu", "Mengya", ""], ["Ma", "Chuangtao", ""], ["Maas", "Lientje", ""], ["Mansfield", "Martin", ""], ["Mariani", "Fabio", ""], ["Marzi", "Eleonora", ""], ["Mesbah", "Sepideh", ""], ["Mistry", "Maheshkumar", ""], ["Tirado", "Alba Catalina Morales", ""], ["Nguyen", "Anna", ""], ["Nguyen", "Viet Bach", ""], ["Oelen", "Allard", ""], ["Pasqual", "Valentina", ""], ["Paulheim", "Heiko", ""], ["Polleres", "Axel", ""], ["Porena", "Margherita", ""], ["Portisch", "Jan", ""], ["Presutti", "Valentina", ""], ["Pustu-Iren", "Kader", ""], ["Mendez", "Ariam Rivas", ""], ["Roshankish", "Soheil", ""], ["Rudolph", "Sebastian", ""], ["Sack", "Harald", ""], ["Sakor", "Ahmad", ""], ["Salas", "Jaime", ""], ["Schleider", "Thomas", ""], ["Shi", "Meilin", ""], ["Spinaci", "Gianmarco", ""], ["Sun", "Chang", ""], ["Tietz", "Tabea", ""], ["Dhouib", "Molka Tounsi", ""], ["Umbrico", "Alessandro", ""], ["Berg", "Wouter van den", ""], ["Xu", "Weiqin", ""]]}, {"id": "2012.11937", "submitter": "Chao-Hong Tan", "authors": "Chao-Hong Tan, Xiaoyu Yang, Zi'ou Zheng, Tianda Li, Yufei Feng,\n  Jia-Chen Gu, Quan Liu, Dan Liu, Zhen-Hua Ling, Xiaodan Zhu", "title": "Learning to Retrieve Entity-Aware Knowledge and Generate Responses with\n  Copy Mechanism for Task-Oriented Dialogue Systems", "comments": "Accepted by AAAI 2021, Workshop on DSTC 9", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Task-oriented conversational modeling with unstructured knowledge access, as\ntrack 1 of the 9th Dialogue System Technology Challenges (DSTC 9), requests to\nbuild a system to generate response given dialogue history and knowledge\naccess. This challenge can be separated into three subtasks, (1)\nknowledge-seeking turn detection, (2) knowledge selection, and (3)\nknowledge-grounded response generation. We use pre-trained language models,\nELECTRA and RoBERTa, as our base encoder for different subtasks. For subtask 1\nand 2, the coarse-grained information like domain and entity are used to\nenhance knowledge usage. For subtask 3, we use a latent variable to encode\ndialog history and selected knowledge better and generate responses combined\nwith copy mechanism. Meanwhile, some useful post-processing strategies are\nperformed on the model's final output to make further knowledge usage in the\ngeneration task. As shown in released evaluation results, our proposed system\nranks second under objective metrics and ranks fourth under human metrics.\n", "versions": [{"version": "v1", "created": "Tue, 22 Dec 2020 11:36:37 GMT"}], "update_date": "2020-12-23", "authors_parsed": [["Tan", "Chao-Hong", ""], ["Yang", "Xiaoyu", ""], ["Zheng", "Zi'ou", ""], ["Li", "Tianda", ""], ["Feng", "Yufei", ""], ["Gu", "Jia-Chen", ""], ["Liu", "Quan", ""], ["Liu", "Dan", ""], ["Ling", "Zhen-Hua", ""], ["Zhu", "Xiaodan", ""]]}, {"id": "2012.11957", "submitter": "Yao Zhang", "authors": "Yao Zhang, Xu Zhang, Jun Wang, Hongru Liang, Wenqiang Lei, Zhe Sun,\n  Adam Jatowt, Zhenglu Yang", "title": "Generalized Relation Learning with Semantic Correlation Awareness for\n  Link Prediction", "comments": "Preprint of accepted AAAI2021 paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Developing link prediction models to automatically complete knowledge graphs\nhas recently been the focus of significant research interest. The current\nmethods for the link prediction taskhavetwonaturalproblems:1)the relation\ndistributions in KGs are usually unbalanced, and 2) there are many unseen\nrelations that occur in practical situations. These two problems limit the\ntraining effectiveness and practical applications of the existing link\nprediction models. We advocate a holistic understanding of KGs and we propose\nin this work a unified Generalized Relation Learning framework GRL to address\nthe above two problems, which can be plugged into existing link prediction\nmodels. GRL conducts a generalized relation learning, which is aware of\nsemantic correlations between relations that serve as a bridge to connect\nsemantically similar relations. After training with GRL, the closeness of\nsemantically similar relations in vector space and the discrimination of\ndissimilar relations are improved. We perform comprehensive experiments on six\nbenchmarks to demonstrate the superior capability of GRL in the link prediction\ntask. In particular, GRL is found to enhance the existing link prediction\nmodels making them insensitive to unbalanced relation distributions and capable\nof learning unseen relations.\n", "versions": [{"version": "v1", "created": "Tue, 22 Dec 2020 12:22:03 GMT"}, {"version": "v2", "created": "Sun, 18 Apr 2021 08:57:36 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Zhang", "Yao", ""], ["Zhang", "Xu", ""], ["Wang", "Jun", ""], ["Liang", "Hongru", ""], ["Lei", "Wenqiang", ""], ["Sun", "Zhe", ""], ["Jatowt", "Adam", ""], ["Yang", "Zhenglu", ""]]}, {"id": "2012.11988", "submitter": "Shuai Lin", "authors": "Shuai Lin, Pan Zhou, Xiaodan Liang, Jianheng Tang, Ruihui Zhao,\n  Ziliang Chen, Liang Lin", "title": "Graph-Evolving Meta-Learning for Low-Resource Medical Dialogue\n  Generation", "comments": "Accepted by AAAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Human doctors with well-structured medical knowledge can diagnose a disease\nmerely via a few conversations with patients about symptoms. In contrast,\nexisting knowledge-grounded dialogue systems often require a large number of\ndialogue instances to learn as they fail to capture the correlations between\ndifferent diseases and neglect the diagnostic experience shared among them. To\naddress this issue, we propose a more natural and practical paradigm, i.e.,\nlow-resource medical dialogue generation, which can transfer the diagnostic\nexperience from source diseases to target ones with a handful of data for\nadaptation. It is capitalized on a commonsense knowledge graph to characterize\nthe prior disease-symptom relations. Besides, we develop a Graph-Evolving\nMeta-Learning (GEML) framework that learns to evolve the commonsense graph for\nreasoning disease-symptom correlations in a new disease, which effectively\nalleviates the needs of a large number of dialogues. More importantly, by\ndynamically evolving disease-symptom graphs, GEML also well addresses the\nreal-world challenges that the disease-symptom correlations of each disease may\nvary or evolve along with more diagnostic cases. Extensive experiment results\non the CMDD dataset and our newly-collected Chunyu dataset testify the\nsuperiority of our approach over state-of-the-art approaches. Besides, our GEML\ncan generate an enriched dialogue-sensitive knowledge graph in an online\nmanner, which could benefit other tasks grounded on knowledge graph.\n", "versions": [{"version": "v1", "created": "Tue, 22 Dec 2020 13:20:23 GMT"}], "update_date": "2020-12-23", "authors_parsed": [["Lin", "Shuai", ""], ["Zhou", "Pan", ""], ["Liang", "Xiaodan", ""], ["Tang", "Jianheng", ""], ["Zhao", "Ruihui", ""], ["Chen", "Ziliang", ""], ["Lin", "Liang", ""]]}, {"id": "2012.12007", "submitter": "Yubo Xie", "authors": "Yubo Xie, Junze Li, Pearl Pu", "title": "Uncertainty and Surprisal Jointly Deliver the Punchline: Exploiting\n  Incongruity-Based Features for Humor Recognition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Humor recognition has been widely studied as a text classification problem\nusing data-driven approaches. However, most existing work does not examine the\nactual joke mechanism to understand humor. We break down any joke into two\ndistinct components: the set-up and the punchline, and further explore the\nspecial relationship between them. Inspired by the incongruity theory of humor,\nwe model the set-up as the part developing semantic uncertainty, and the\npunchline disrupting audience expectations. With increasingly powerful language\nmodels, we were able to feed the set-up along with the punchline into the GPT-2\nlanguage model, and calculate the uncertainty and surprisal values of the\njokes. By conducting experiments on the SemEval 2021 Task 7 dataset, we found\nthat these two features have better capabilities of telling jokes from\nnon-jokes, compared with existing baselines.\n", "versions": [{"version": "v1", "created": "Tue, 22 Dec 2020 13:48:09 GMT"}], "update_date": "2020-12-23", "authors_parsed": [["Xie", "Yubo", ""], ["Li", "Junze", ""], ["Pu", "Pearl", ""]]}, {"id": "2012.12014", "submitter": "Ron Ferens", "authors": "Yoli Shavit and Ron Ferens", "title": "Do We Really Need Scene-specific Pose Encoders?", "comments": "To be presented at ICPR2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Visual pose regression models estimate the camera pose from a query image\nwith a single forward pass. Current models learn pose encoding from an image\nusing deep convolutional networks which are trained per scene. The resulting\nencoding is typically passed to a multi-layer perceptron in order to regress\nthe pose. In this work, we propose that scene-specific pose encoders are not\nrequired for pose regression and that encodings trained for visual similarity\ncan be used instead. In order to test our hypothesis, we take a shallow\narchitecture of several fully connected layers and train it with pre-computed\nencodings from a generic image retrieval model. We find that these encodings\nare not only sufficient to regress the camera pose, but that, when provided to\na branching fully connected architecture, a trained model can achieve\ncompetitive results and even surpass current \\textit{state-of-the-art} pose\nregressors in some cases. Moreover, we show that for outdoor localization, the\nproposed architecture is the only pose regressor, to date, consistently\nlocalizing in under 2 meters and 5 degrees.\n", "versions": [{"version": "v1", "created": "Tue, 22 Dec 2020 13:59:52 GMT"}], "update_date": "2020-12-23", "authors_parsed": [["Shavit", "Yoli", ""], ["Ferens", "Ron", ""]]}, {"id": "2012.12060", "submitter": "Yusuke Kawamoto", "authors": "M\\'ario S. Alvim, Konstantinos Chatzikokolakis, Yusuke Kawamoto,\n  Catuscia Palamidessi", "title": "Information Leakage Games: Exploring Information as a Utility Function", "comments": "Journal version of GameSec'17 paper (arXiv:1705.05030)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.GT cs.IT math.IT", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  A common goal in the areas of secure information flow and privacy is to build\neffective defenses against unwanted leakage of information. To this end, one\nmust be able to reason about potential attacks and their interplay with\npossible defenses. In this paper, we propose a game-theoretic framework to\nformalize strategies of attacker and defender in the context of information\nleakage, and provide a basis for developing optimal defense methods. A novelty\nof our games is that their utility is given by information leakage, which in\nsome cases may behave in a non-linear way. This causes a significant deviation\nfrom classic game theory, in which utility functions are linear with respect to\nplayers' strategies. Hence, a key contribution of this paper is the\nestablishment of the foundations of information leakage games. We consider two\nkinds of games, depending on the notion of leakage considered. The first kind,\nthe QIF-games, is tailored for the theory of quantitative information flow\n(QIF). The second one, the DP-games, corresponds to differential privacy (DP).\n", "versions": [{"version": "v1", "created": "Tue, 22 Dec 2020 14:51:30 GMT"}, {"version": "v2", "created": "Sun, 18 Jul 2021 09:56:24 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Alvim", "M\u00e1rio S.", ""], ["Chatzikokolakis", "Konstantinos", ""], ["Kawamoto", "Yusuke", ""], ["Palamidessi", "Catuscia", ""]]}, {"id": "2012.12062", "submitter": "Pascal Leroy", "authors": "Pascal Leroy, Damien Ernst, Pierre Geurts, Gilles Louppe, Jonathan\n  Pisane, Matthia Sabatelli", "title": "QVMix and QVMix-Max: Extending the Deep Quality-Value Family of\n  Algorithms to Cooperative Multi-Agent Reinforcement Learning", "comments": "To be published in AAAI-21 Workshop on Reinforcement Learning in\n  Games", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper introduces four new algorithms that can be used for tackling\nmulti-agent reinforcement learning (MARL) problems occurring in cooperative\nsettings. All algorithms are based on the Deep Quality-Value (DQV) family of\nalgorithms, a set of techniques that have proven to be successful when dealing\nwith single-agent reinforcement learning problems (SARL). The key idea of DQV\nalgorithms is to jointly learn an approximation of the state-value function\n$V$, alongside an approximation of the state-action value function $Q$. We\nfollow this principle and generalise these algorithms by introducing two fully\ndecentralised MARL algorithms (IQV and IQV-Max) and two algorithms that are\nbased on the centralised training with decentralised execution training\nparadigm (QVMix and QVMix-Max). We compare our algorithms with state-of-the-art\nMARL techniques on the popular StarCraft Multi-Agent Challenge (SMAC)\nenvironment. We show competitive results when QVMix and QVMix-Max are compared\nto well-known MARL techniques such as QMIX and MAVEN and show that QVMix can\neven outperform them on some of the tested environments, being the algorithm\nwhich performs best overall. We hypothesise that this is due to the fact that\nQVMix suffers less from the overestimation bias of the $Q$ function.\n", "versions": [{"version": "v1", "created": "Tue, 22 Dec 2020 14:53:42 GMT"}], "update_date": "2020-12-23", "authors_parsed": [["Leroy", "Pascal", ""], ["Ernst", "Damien", ""], ["Geurts", "Pierre", ""], ["Louppe", "Gilles", ""], ["Pisane", "Jonathan", ""], ["Sabatelli", "Matthia", ""]]}, {"id": "2012.12104", "submitter": "Bing Liu", "authors": "Bing Liu (1), Yu Tang (2), Yuxiong Ji (1), Yu Shen (1), and Yuchuan Du\n  (1) ((1) Key Laboratory of Road and Traffic Engineering of the Ministry of\n  Education, Tongji University, Shanghai, China, (2) Tandon School of\n  Engineering, New York University, New York, USA)", "title": "A Deep Reinforcement Learning Approach for Ramp Metering Based on\n  Traffic Video Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ramp metering that uses traffic signals to regulate vehicle flows from the\non-ramps has been widely implemented to improve vehicle mobility of the\nfreeway. Previous studies generally update signal timings in real-time based on\npredefined traffic measures collected by point detectors, such as traffic\nvolumes and occupancies. Comparing with point detectors, traffic cameras-which\nhave been increasingly deployed on road networks-could cover larger areas and\nprovide more detailed traffic information. In this work, we propose a deep\nreinforcement learning (DRL) method to explore the potential of traffic video\ndata in improving the efficiency of ramp metering. The proposed method uses\ntraffic video frames as inputs and learns the optimal control strategies\ndirectly from the high-dimensional visual inputs. A real-world case study\ndemonstrates that, in comparison with a state-of-the-practice method, the\nproposed DRL method results in 1) lower travel times in the mainline, 2)\nshorter vehicle queues at the on-ramp, and 3) higher traffic flows downstream\nof the merging area. The results suggest that the proposed method is able to\nextract useful information from the video data for better ramp metering\ncontrols.\n", "versions": [{"version": "v1", "created": "Wed, 9 Dec 2020 05:08:41 GMT"}], "update_date": "2020-12-23", "authors_parsed": [["Liu", "Bing", ""], ["Tang", "Yu", ""], ["Ji", "Yuxiong", ""], ["Shen", "Yu", ""], ["Du", "Yuchuan", ""]]}, {"id": "2012.12106", "submitter": "Gianni De Fabritiis", "authors": "Stefan Doerr, Maciej Majewsk, Adri\\`a P\\'erez, Andreas Kr\\\"amer,\n  Cecilia Clementi, Frank Noe, Toni Giorgino and Gianni De Fabritiis", "title": "TorchMD: A deep learning framework for molecular simulations", "comments": null, "journal-ref": null, "doi": "10.1021/acs.jctc.0c01343", "report-no": null, "categories": "physics.chem-ph cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Molecular dynamics simulations provide a mechanistic description of molecules\nby relying on empirical potentials. The quality and transferability of such\npotentials can be improved leveraging data-driven models derived with machine\nlearning approaches. Here, we present TorchMD, a framework for molecular\nsimulations with mixed classical and machine learning potentials. All of force\ncomputations including bond, angle, dihedral, Lennard-Jones and Coulomb\ninteractions are expressed as PyTorch arrays and operations. Moreover, TorchMD\nenables learning and simulating neural network potentials. We validate it using\nstandard Amber all-atom simulations, learning an ab-initio potential,\nperforming an end-to-end training and finally learning and simulating a\ncoarse-grained model for protein folding. We believe that TorchMD provides a\nuseful tool-set to support molecular simulations of machine learning\npotentials. Code and data are freely available at \\url{github.com/torchmd}.\n", "versions": [{"version": "v1", "created": "Tue, 22 Dec 2020 15:43:27 GMT"}], "update_date": "2021-06-18", "authors_parsed": [["Doerr", "Stefan", ""], ["Majewsk", "Maciej", ""], ["P\u00e9rez", "Adri\u00e0", ""], ["Kr\u00e4mer", "Andreas", ""], ["Clementi", "Cecilia", ""], ["Noe", "Frank", ""], ["Giorgino", "Toni", ""], ["De Fabritiis", "Gianni", ""]]}, {"id": "2012.12111", "submitter": "Fabio Valerio Massoli", "authors": "Fabio Valerio Massoli, Fabrizio Falchi, Alperen Kantarci, \\c{S}eymanur\n  Akti, Hazim Kemal Ekenel, Giuseppe Amato", "title": "MOCCA: Multi-Layer One-Class ClassificAtion for Anomaly Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Anomalies are ubiquitous in all scientific fields and can express an\nunexpected event due to incomplete knowledge about the data distribution or an\nunknown process that suddenly comes into play and distorts the observations.\nDue to such events' rarity, it is common to train deep learning models on\n\"normal\", i.e. non-anomalous, datasets only, thus letting the neural network to\nmodel the distribution beneath the input data. In this context, we propose our\ndeep learning approach to the anomaly detection problem named\nMulti-LayerOne-Class Classification (MOCCA). We explicitly leverage the\npiece-wise nature of deep neural networks by exploiting information extracted\nat different depths to detect abnormal data instances. We show how combining\nthe representations extracted from multiple layers of a model leads to higher\ndiscrimination performance than typical approaches proposed in the literature\nthat are based neural networks' final output only. We propose to train the\nmodel by minimizing the $L_2$ distance between the input representation and a\nreference point, the anomaly-free training data centroid, at each considered\nlayer. We conduct extensive experiments on publicly available datasets for\nanomaly detection, namely CIFAR10, MVTec AD, and ShanghaiTech, considering both\nthe single-image and video-based scenarios. We show that our method reaches\nsuperior performances compared to the state-of-the-art approaches available in\nthe literature. Moreover, we provide a model analysis to give insight on how\nour approach works.\n", "versions": [{"version": "v1", "created": "Wed, 9 Dec 2020 08:32:56 GMT"}, {"version": "v2", "created": "Mon, 5 Apr 2021 09:40:17 GMT"}], "update_date": "2021-04-06", "authors_parsed": [["Massoli", "Fabio Valerio", ""], ["Falchi", "Fabrizio", ""], ["Kantarci", "Alperen", ""], ["Akti", "\u015eeymanur", ""], ["Ekenel", "Hazim Kemal", ""], ["Amato", "Giuseppe", ""]]}, {"id": "2012.12115", "submitter": "Joao Leite", "authors": "Manuel de Sousa Ribeiro, Ludwig Krippahl, Joao Leite", "title": "Explainable Abstract Trains Dataset", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Explainable Abstract Trains Dataset is an image dataset containing\nsimplified representations of trains. It aims to provide a platform for the\napplication and research of algorithms for justification and explanation\nextraction. The dataset is accompanied by an ontology that conceptualizes and\nclassifies the depicted trains based on their visual characteristics, allowing\nfor a precise understanding of how each train was labeled. Each image in the\ndataset is annotated with multiple attributes describing the trains' features\nand with bounding boxes for the train elements.\n", "versions": [{"version": "v1", "created": "Tue, 15 Dec 2020 13:18:42 GMT"}], "update_date": "2020-12-23", "authors_parsed": [["Ribeiro", "Manuel de Sousa", ""], ["Krippahl", "Ludwig", ""], ["Leite", "Joao", ""]]}, {"id": "2012.12130", "submitter": "Md Saiful Islam", "authors": "Md Saiful Islam, Md Sarowar Morshed, and Md. Noor-E-Alam", "title": "Algorithms for Solving Nonlinear Binary Optimization Problems in Robust\n  Causal Inference", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.AI cs.DM stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Identifying cause-effect relation among variables is a key step in the\ndecision-making process. While causal inference requires randomized\nexperiments, researchers and policymakers are increasingly using observational\nstudies to test causal hypotheses due to the wide availability of observational\ndata and the infeasibility of experiments. The matching method is the most used\ntechnique to make causal inference from observational data. However, the pair\nassignment process in one-to-one matching creates uncertainty in the inference\nbecause of different choices made by the experimenter. Recently, discrete\noptimization models are proposed to tackle such uncertainty. Although a robust\ninference is possible with discrete optimization models, they produce nonlinear\nproblems and lack scalability. In this work, we propose greedy algorithms to\nsolve the robust causal inference test instances from observational data with\ncontinuous outcomes. We propose a unique framework to reformulate the nonlinear\nbinary optimization problems as feasibility problems. By leveraging the\nstructure of the feasibility formulation, we develop greedy schemes that are\nefficient in solving robust test problems. In many cases, the proposed\nalgorithms achieve global optimal solution. We perform experiments on three\nreal-world datasets to demonstrate the effectiveness of the proposed algorithms\nand compare our result with the state-of-the-art solver. Our experiments show\nthat the proposed algorithms significantly outperform the exact method in terms\nof computation time while achieving the same conclusion for causal tests. Both\nnumerical experiments and complexity analysis demonstrate that the proposed\nalgorithms ensure the scalability required for harnessing the power of big data\nin the decision-making process.\n", "versions": [{"version": "v1", "created": "Tue, 22 Dec 2020 16:12:11 GMT"}], "update_date": "2020-12-23", "authors_parsed": [["Islam", "Md Saiful", ""], ["Morshed", "Md Sarowar", ""], ["Noor-E-Alam", "Md.", ""]]}, {"id": "2012.12169", "submitter": "Jingbo Zhou", "authors": "Congxi Xiao, Jingbo Zhou, Jizhou Huang, An Zhuo, Ji Liu, Haoyi Xiong,\n  Dejing Dou", "title": "C-Watcher: A Framework for Early Detection of High-Risk Neighborhoods\n  Ahead of COVID-19 Outbreak", "comments": "11 pages, accepted by AAAI 2021, appendix is included", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  The novel coronavirus disease (COVID-19) has crushed daily routines and is\nstill rampaging through the world. Existing solution for nonpharmaceutical\ninterventions usually needs to timely and precisely select a subset of\nresidential urban areas for containment or even quarantine, where the spatial\ndistribution of confirmed cases has been considered as a key criterion for the\nsubset selection. While such containment measure has successfully stopped or\nslowed down the spread of COVID-19 in some countries, it is criticized for\nbeing inefficient or ineffective, as the statistics of confirmed cases are\nusually time-delayed and coarse-grained. To tackle the issues, we propose\nC-Watcher, a novel data-driven framework that aims at screening every\nneighborhood in a target city and predicting infection risks, prior to the\nspread of COVID-19 from epicenters to the city. In terms of design, C-Watcher\ncollects large-scale long-term human mobility data from Baidu Maps, then\ncharacterizes every residential neighborhood in the city using a set of\nfeatures based on urban mobility patterns. Furthermore, to transfer the\nfirsthand knowledge (witted in epicenters) to the target city before local\noutbreaks, we adopt a novel adversarial encoder framework to learn\n\"city-invariant\" representations from the mobility-related features for precise\nearly detection of high-risk neighborhoods, even before any confirmed cases\nknown, in the target city. We carried out extensive experiments on C-Watcher\nusing the real-data records in the early stage of COVID-19 outbreaks, where the\nresults demonstrate the efficiency and effectiveness of C-Watcher for early\ndetection of high-risk neighborhoods from a large number of cities.\n", "versions": [{"version": "v1", "created": "Tue, 22 Dec 2020 17:02:54 GMT"}, {"version": "v2", "created": "Wed, 27 Jan 2021 17:05:47 GMT"}, {"version": "v3", "created": "Thu, 4 Mar 2021 19:02:31 GMT"}], "update_date": "2021-03-08", "authors_parsed": [["Xiao", "Congxi", ""], ["Zhou", "Jingbo", ""], ["Huang", "Jizhou", ""], ["Zhuo", "An", ""], ["Liu", "Ji", ""], ["Xiong", "Haoyi", ""], ["Dou", "Dejing", ""]]}, {"id": "2012.12177", "submitter": "Samuel Yen-Chi Chen", "authors": "Samuel Yen-Chi Chen, Tzu-Chieh Wei, Chao Zhang, Haiwang Yu, Shinjae\n  Yoo", "title": "Quantum Convolutional Neural Networks for High Energy Physics Data\n  Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI hep-ex physics.data-an quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work presents a quantum convolutional neural network (QCNN) for the\nclassification of high energy physics events. The proposed model is tested\nusing a simulated dataset from the Deep Underground Neutrino Experiment. The\nproposed architecture demonstrates the quantum advantage of learning faster\nthan the classical convolutional neural networks (CNNs) under a similar number\nof parameters. In addition to faster convergence, the QCNN achieves greater\ntest accuracy compared to CNNs. Based on experimental results, it is a\npromising direction to study the application of QCNN and other quantum machine\nlearning models in high energy physics and additional scientific fields.\n", "versions": [{"version": "v1", "created": "Tue, 22 Dec 2020 17:14:47 GMT"}], "update_date": "2020-12-23", "authors_parsed": [["Chen", "Samuel Yen-Chi", ""], ["Wei", "Tzu-Chieh", ""], ["Zhang", "Chao", ""], ["Yu", "Haiwang", ""], ["Yoo", "Shinjae", ""]]}, {"id": "2012.12186", "submitter": "Rinu Boney", "authors": "Rinu Boney, Alexander Ilin, Juho Kannala, Jarno Sepp\\\"anen", "title": "Learning to Play Imperfect-Information Games by Imitating an Oracle\n  Planner", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider learning to play multiplayer imperfect-information games with\nsimultaneous moves and large state-action spaces. Previous attempts to tackle\nsuch challenging games have largely focused on model-free learning methods,\noften requiring hundreds of years of experience to produce competitive agents.\nOur approach is based on model-based planning. We tackle the problem of partial\nobservability by first building an (oracle) planner that has access to the full\nstate of the environment and then distilling the knowledge of the oracle to a\n(follower) agent which is trained to play the imperfect-information game by\nimitating the oracle's choices. We experimentally show that planning with naive\nMonte Carlo tree search does not perform very well in large combinatorial\naction spaces. We therefore propose planning with a fixed-depth tree search and\ndecoupled Thompson sampling for action selection. We show that the planner is\nable to discover efficient playing strategies in the games of Clash Royale and\nPommerman and the follower policy successfully learns to implement them by\ntraining on a few hundred battles.\n", "versions": [{"version": "v1", "created": "Tue, 22 Dec 2020 17:29:57 GMT"}], "update_date": "2020-12-23", "authors_parsed": [["Boney", "Rinu", ""], ["Ilin", "Alexander", ""], ["Kannala", "Juho", ""], ["Sepp\u00e4nen", "Jarno", ""]]}, {"id": "2012.12192", "submitter": "Liang Ma", "authors": "Liang Ma", "title": "Query Answering via Decentralized Search", "comments": "Updated author list", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Expert networks are formed by a group of expert-professionals with different\nspecialties to collaboratively resolve specific queries posted to the network.\nIn such networks, when a query reaches an expert who does not have sufficient\nexpertise, this query needs to be routed to other experts for further\nprocessing until it is completely solved; therefore, query answering efficiency\nis sensitive to the underlying query routing mechanism being used. Among all\npossible query routing mechanisms, decentralized search, operating purely on\neach expert's local information without any knowledge of network global\nstructure, represents the most basic and scalable routing mechanism, which is\napplicable to any network scenarios even in dynamic networks. However, there is\nstill a lack of fundamental understanding of the efficiency of decentralized\nsearch in expert networks. In this regard, we investigate decentralized search\nby quantifying its performance under a variety of network settings. Our key\nfindings reveal the existence of network conditions, under which decentralized\nsearch can achieve significantly short query routing paths (i.e., between\n$O(\\log n)$ and $O(\\log^2 n)$ hops, $n$: total number of experts in the\nnetwork). Based on such theoretical foundation, we further study how the unique\nproperties of decentralized search in expert networks is related to the\nanecdotal small-world phenomenon. In addition, we demonstrate that\ndecentralized search is robust against estimation errors introduced by\nmisinterpreting the required expertise levels. To the best of our knowledge,\nthis is the first work studying fundamental behaviors of decentralized search\nin expert networks. The developed performance bounds, confirmed by real\ndatasets, are able to assist in predicting network performance and designing\ncomplex expert networks.\n", "versions": [{"version": "v1", "created": "Fri, 18 Dec 2020 14:46:49 GMT"}, {"version": "v2", "created": "Sat, 26 Dec 2020 22:26:13 GMT"}], "update_date": "2020-12-29", "authors_parsed": [["Ma", "Liang", ""]]}, {"id": "2012.12209", "submitter": "Xinlei Pan", "authors": "Xinlei Pan, Animesh Garg, Animashree Anandkumar, Yuke Zhu", "title": "Emergent Hand Morphology and Control from Optimizing Robust Grasps of\n  Diverse Objects", "comments": "8 pages, 5 figures, Project website:\n  https://xinleipan.github.io/emergent_morphology/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Evolution in nature illustrates that the creatures' biological structure and\ntheir sensorimotor skills adapt to the environmental changes for survival.\nLikewise, the ability to morph and acquire new skills can facilitate an\nembodied agent to solve tasks of varying complexities. In this work, we\nintroduce a data-driven approach where effective hand designs naturally emerge\nfor the purpose of grasping diverse objects. Jointly optimizing morphology and\ncontrol imposes computational challenges since it requires constant evaluation\nof a black-box function that measures the performance of a combination of\nembodiment and behavior. We develop a novel Bayesian Optimization algorithm\nthat efficiently co-designs the morphology and grasping skills jointly through\nlearned latent-space representations. We design the grasping tasks based on a\ntaxonomy of three human grasp types: power grasp, pinch grasp, and lateral\ngrasp. Through experimentation and comparative study, we demonstrate the\neffectiveness of our approach in discovering robust and cost-efficient hand\nmorphologies for grasping novel objects.\n", "versions": [{"version": "v1", "created": "Tue, 22 Dec 2020 17:52:29 GMT"}], "update_date": "2020-12-23", "authors_parsed": [["Pan", "Xinlei", ""], ["Garg", "Animesh", ""], ["Anandkumar", "Animashree", ""], ["Zhu", "Yuke", ""]]}, {"id": "2012.12218", "submitter": "Sein Minn", "authors": "Sein Minn", "title": "BKT-LSTM: Efficient Student Modeling for knowledge tracing and student\n  performance prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, we have seen a rapid rise in usage of online educational platforms.\nThe personalized education became crucially important in future learning\nenvironments. Knowledge tracing (KT) refers to the detection of students'\nknowledge states and predict future performance given their past outcomes for\nproviding adaptive solution to Intelligent Tutoring Systems (ITS). Bayesian\nKnowledge Tracing (BKT) is a model to capture mastery level of each skill with\npsychologically meaningful parameters and widely used in successful tutoring\nsystems. However, it is unable to detect learning transfer across skills\nbecause each skill model is learned independently and shows lower efficiency in\nstudent performance prediction. While recent KT models based on deep neural\nnetworks shows impressive predictive power but it came with a price. Ten of\nthousands of parameters in neural networks are unable to provide\npsychologically meaningful interpretation that reflect to cognitive theory. In\nthis paper, we proposed an efficient student model called BKT-LSTM. It contains\nthree meaningful components: individual \\textit{skill mastery} assessed by BKT,\n\\textit{ability profile} (learning transfer across skills) detected by k-means\nclustering and \\textit{problem difficulty}. All these components are taken into\naccount in student's future performance prediction by leveraging predictive\npower of LSTM. BKT-LSTM outperforms state-of-the-art student models in\nstudent's performance prediction by considering these meaningful features\ninstead of using binary values of student's past interaction in DKT. We also\nconduct ablation studies on each of BKT-LSTM model components to examine their\nvalue and each component shows significant contribution in student's\nperformance prediction. Thus, it has potential for providing adaptive and\npersonalized instruction in real-world educational systems.\n", "versions": [{"version": "v1", "created": "Tue, 22 Dec 2020 18:05:36 GMT"}, {"version": "v2", "created": "Wed, 6 Jan 2021 03:46:09 GMT"}, {"version": "v3", "created": "Tue, 8 Jun 2021 16:03:53 GMT"}], "update_date": "2021-06-09", "authors_parsed": [["Minn", "Sein", ""]]}, {"id": "2012.12259", "submitter": "Haotian Liu", "authors": "Haotian Liu, Rafael A. Rivera Soto, Fanyi Xiao, Yong Jae Lee", "title": "YolactEdge: Real-time Instance Segmentation on the Edge", "comments": "\\c{opyright} 2021 IEEE. Personal use of this material is permitted.\n  Permission from IEEE must be obtained for all other uses, in any current or\n  future media, including reprinting/republishing this material for advertising\n  or promotional purposes, creating new collective works, for resale or\n  redistribution to servers or lists, or reuse of any copyrighted component of\n  this work in other works", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose YolactEdge, the first competitive instance segmentation approach\nthat runs on small edge devices at real-time speeds. Specifically, YolactEdge\nruns at up to 30.8 FPS on a Jetson AGX Xavier (and 172.7 FPS on an RTX 2080 Ti)\nwith a ResNet-101 backbone on 550x550 resolution images. To achieve this, we\nmake two improvements to the state-of-the-art image-based real-time method\nYOLACT: (1) applying TensorRT optimization while carefully trading off speed\nand accuracy, and (2) a novel feature warping module to exploit temporal\nredundancy in videos. Experiments on the YouTube VIS and MS COCO datasets\ndemonstrate that YolactEdge produces a 3-5x speed up over existing real-time\nmethods while producing competitive mask and box detection accuracy. We also\nconduct ablation studies to dissect our design choices and modules. Code and\nmodels are available at https://github.com/haotian-liu/yolact_edge.\n", "versions": [{"version": "v1", "created": "Tue, 22 Dec 2020 18:58:18 GMT"}, {"version": "v2", "created": "Thu, 1 Apr 2021 17:55:10 GMT"}], "update_date": "2021-04-02", "authors_parsed": [["Liu", "Haotian", ""], ["Soto", "Rafael A. Rivera", ""], ["Xiao", "Fanyi", ""], ["Lee", "Yong Jae", ""]]}, {"id": "2012.12262", "submitter": "Mohammad Reza Davahli", "authors": "Mohammad Reza Davahli", "title": "The Last State of Artificial Intelligence in Project Management", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Artificial intelligence (AI) has been used to advance different fields, such\nas education, healthcare, and finance. However, the application of AI in the\nfield of project management (PM) has not progressed equally. This paper reports\non a systematic review of the published studies used to investigate the\napplication of AI in PM. This systematic review identified relevant papers\nusing Web of Science, Science Direct, and Google Scholar databases. Of the 652\narticles found, 58 met the predefined criteria and were included in the review.\nIncluded papers were classified per the following dimensions: PM knowledge\nareas, PM processes, and AI techniques. The results indicated that the\napplication of AI in PM was in its early stages and AI models have not applied\nfor multiple PM processes especially in processes groups of project stakeholder\nmanagement, project procurements management, and project communication\nmanagement. However, the most popular PM processes among included papers were\nproject effort prediction and cost estimation, and the most popular AI\ntechniques were support vector machines, neural networks, and genetic\nalgorithms.\n", "versions": [{"version": "v1", "created": "Wed, 16 Dec 2020 05:10:08 GMT"}], "update_date": "2020-12-23", "authors_parsed": [["Davahli", "Mohammad Reza", ""]]}, {"id": "2012.12305", "submitter": "Svetlana Kiritchenko", "authors": "Svetlana Kiritchenko, Isar Nejadgholi, Kathleen C. Fraser", "title": "Confronting Abusive Language Online: A Survey from the Ethical and Human\n  Rights Perspective", "comments": "published in Journal of Artificial Intelligence Research, 71:\n  431-478, July 2021", "journal-ref": null, "doi": "10.1613/jair.1.12590", "report-no": null, "categories": "cs.CL cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The pervasiveness of abusive content on the internet can lead to severe\npsychological and physical harm. Significant effort in Natural Language\nProcessing (NLP) research has been devoted to addressing this problem through\nabusive content detection and related sub-areas, such as the detection of hate\nspeech, toxicity, cyberbullying, etc. Although current technologies achieve\nhigh classification performance in research studies, it has been observed that\nthe real-life application of this technology can cause unintended harms, such\nas the silencing of under-represented groups. We review a large body of NLP\nresearch on automatic abuse detection with a new focus on ethical challenges,\norganized around eight established ethical principles: privacy, accountability,\nsafety and security, transparency and explainability, fairness and\nnon-discrimination, human control of technology, professional responsibility,\nand promotion of human values. In many cases, these principles relate not only\nto situational ethical codes, which may be context-dependent, but are in fact\nconnected to universal human rights, such as the right to privacy, freedom from\ndiscrimination, and freedom of expression. We highlight the need to examine the\nbroad social impacts of this technology, and to bring ethical and human rights\nconsiderations to every stage of the application life-cycle, from task\nformulation and dataset design, to model training and evaluation, to\napplication deployment. Guided by these principles, we identify several\nopportunities for rights-respecting, socio-technical solutions to detect and\nconfront online abuse, including `nudging', `quarantining', value sensitive\ndesign, counter-narratives, style transfer, and AI-driven public education\napplications.\n", "versions": [{"version": "v1", "created": "Tue, 22 Dec 2020 19:27:11 GMT"}, {"version": "v2", "created": "Thu, 22 Jul 2021 16:53:43 GMT"}], "update_date": "2021-07-23", "authors_parsed": [["Kiritchenko", "Svetlana", ""], ["Nejadgholi", "Isar", ""], ["Fraser", "Kathleen C.", ""]]}, {"id": "2012.12309", "submitter": "Liang Ma", "authors": "Liang Ma", "title": "Influence Maximization Under Generic Threshold-based Non-submodular\n  Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As a widely observable social effect, influence diffusion refers to a process\nwhere innovations, trends, awareness, etc. spread across the network via the\nsocial impact among individuals. Motivated by such social effect, the concept\nof influence maximization is coined, where the goal is to select a bounded\nnumber of the most influential nodes (seed nodes) from a social network so that\nthey can jointly trigger the maximal influence diffusion. A rich body of\nresearch in this area is performed under statistical diffusion models with\nprovable submodularity, which essentially simplifies the problem as the optimal\nresult can be approximated by the simple greedy search. When the diffusion\nmodels are non-submodular, however, the research community mostly focuses on\nhow to bound/approximate them by tractable submodular functions so as to\nestimate the optimal result. In other words, there is still a lack of efficient\nmethods that can directly resolve non-submodular influence maximization\nproblems. In this regard, we fill the gap by proposing seed selection\nstrategies using network graphical properties in a generalized threshold-based\nmodel, called influence barricade model, which is non-submodular. Specifically,\nunder this model, we first establish theories to reveal graphical conditions\nthat ensure the network generated by node removals has the same optimal seed\nset as that in the original network. We then exploit these theoretical\nconditions to develop efficient algorithms by strategically removing\nless-important nodes and selecting seeds only in the remaining network. To the\nbest of our knowledge, this is the first graph-based approach that directly\ntackles non-submodular influence maximization.\n", "versions": [{"version": "v1", "created": "Fri, 18 Dec 2020 16:14:49 GMT"}], "update_date": "2020-12-24", "authors_parsed": [["Ma", "Liang", ""]]}, {"id": "2012.12335", "submitter": "Carlos N\\'u\\~nez Molina", "authors": "Carlos N\\'u\\~nez-Molina, Vladislav Nikolov, Ignacio Vellido, Juan\n  Fern\\'andez-Olivares", "title": "Goal Reasoning by Selecting Subgoals with Deep Q-Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we propose a goal reasoning method which learns to select\nsubgoals with Deep Q-Learning in order to decrease the load of a planner when\nfaced with scenarios with tight time restrictions, such as online execution\nsystems. We have designed a CNN-based goal selection module and trained it on a\nstandard video game environment, testing it on different games (planning\ndomains) and levels (planning problems) to measure its generalization\nabilities. When comparing its performance with a satisfying planner, the\nresults obtained show both approaches are able to find plans of good quality,\nbut our method greatly decreases planning time. We conclude our approach can be\nsuccessfully applied to different types of domains (games), and shows good\ngeneralization properties when evaluated on new levels (problems) of the same\ngame (domain).\n", "versions": [{"version": "v1", "created": "Tue, 22 Dec 2020 20:12:29 GMT"}], "update_date": "2020-12-24", "authors_parsed": [["N\u00fa\u00f1ez-Molina", "Carlos", ""], ["Nikolov", "Vladislav", ""], ["Vellido", "Ignacio", ""], ["Fern\u00e1ndez-Olivares", "Juan", ""]]}, {"id": "2012.12350", "submitter": "Zecheng He", "authors": "Zecheng He, Srinivas Sunkara, Xiaoxue Zang, Ying Xu, Lijuan Liu, Nevan\n  Wichers, Gabriel Schubiner, Ruby Lee, Jindong Chen and Blaise Ag\\\"uera y\n  Arcas", "title": "ActionBert: Leveraging User Actions for Semantic Understanding of User\n  Interfaces", "comments": "Accepted to AAAI Conference on Artificial Intelligence (AAAI-21)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As mobile devices are becoming ubiquitous, regularly interacting with a\nvariety of user interfaces (UIs) is a common aspect of daily life for many\npeople. To improve the accessibility of these devices and to enable their usage\nin a variety of settings, building models that can assist users and accomplish\ntasks through the UI is vitally important. However, there are several\nchallenges to achieve this. First, UI components of similar appearance can have\ndifferent functionalities, making understanding their function more important\nthan just analyzing their appearance. Second, domain-specific features like\nDocument Object Model (DOM) in web pages and View Hierarchy (VH) in mobile\napplications provide important signals about the semantics of UI elements, but\nthese features are not in a natural language format. Third, owing to a large\ndiversity in UIs and absence of standard DOM or VH representations, building a\nUI understanding model with high coverage requires large amounts of training\ndata.\n  Inspired by the success of pre-training based approaches in NLP for tackling\na variety of problems in a data-efficient way, we introduce a new pre-trained\nUI representation model called ActionBert. Our methodology is designed to\nleverage visual, linguistic and domain-specific features in user interaction\ntraces to pre-train generic feature representations of UIs and their\ncomponents. Our key intuition is that user actions, e.g., a sequence of clicks\non different UI components, reveals important information about their\nfunctionality. We evaluate the proposed model on a wide variety of downstream\ntasks, ranging from icon classification to UI component retrieval based on its\nnatural language description. Experiments show that the proposed ActionBert\nmodel outperforms multi-modal baselines across all downstream tasks by up to\n15.5%.\n", "versions": [{"version": "v1", "created": "Tue, 22 Dec 2020 20:49:52 GMT"}, {"version": "v2", "created": "Mon, 25 Jan 2021 20:37:39 GMT"}], "update_date": "2021-01-27", "authors_parsed": [["He", "Zecheng", ""], ["Sunkara", "Srinivas", ""], ["Zang", "Xiaoxue", ""], ["Xu", "Ying", ""], ["Liu", "Lijuan", ""], ["Wichers", "Nevan", ""], ["Schubiner", "Gabriel", ""], ["Lee", "Ruby", ""], ["Chen", "Jindong", ""], ["Arcas", "Blaise Ag\u00fcera y", ""]]}, {"id": "2012.12383", "submitter": "Hang Wang", "authors": "Hang Wang, Sen Lin, Hamid Jafarkhani, Junshan Zhang", "title": "Distributed Q-Learning with State Tracking for Multi-agent Networked\n  Control", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies distributed Q-learning for Linear Quadratic Regulator\n(LQR) in a multi-agent network. The existing results often assume that agents\ncan observe the global system state, which may be infeasible in large-scale\nsystems due to privacy concerns or communication constraints. In this work, we\nconsider a setting with unknown system models and no centralized coordinator.\nWe devise a state tracking (ST) based Q-learning algorithm to design optimal\ncontrollers for agents. Specifically, we assume that agents maintain local\nestimates of the global state based on their local information and\ncommunications with neighbors. At each step, every agent updates its local\nglobal state estimation, based on which it solves an approximate Q-factor\nlocally through policy iteration. Assuming decaying injected excitation noise\nduring the policy evaluation, we prove that the local estimation converges to\nthe true global state, and establish the convergence of the proposed\ndistributed ST-based Q-learning algorithm. The experimental studies corroborate\nour theoretical results by showing that our proposed method achieves comparable\nperformance with the centralized case.\n", "versions": [{"version": "v1", "created": "Tue, 22 Dec 2020 22:03:49 GMT"}], "update_date": "2020-12-24", "authors_parsed": [["Wang", "Hang", ""], ["Lin", "Sen", ""], ["Jafarkhani", "Hamid", ""], ["Zhang", "Junshan", ""]]}, {"id": "2012.12401", "submitter": "Naman Kohli", "authors": "Sonal Doomra, Naman Kohli, Shounak Athavale", "title": "Turn Signal Prediction: A Federated Learning Case Study", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CV", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Driving etiquette takes a different flavor for each locality as drivers not\nonly comply with rules/laws but also abide by local unspoken convention. When\nto have the turn signal (indicator) on/off is one such etiquette which does not\nhave a definitive right or wrong answer. Learning this behavior from the\nabundance of data generated from various sensor modalities integrated in the\nvehicle is a suitable candidate for deep learning. But what makes it a prime\ncandidate for Federated Learning are privacy concerns and bandwidth limitations\nfor any data aggregation. This paper presents a long short-term memory (LSTM)\nbased Turn Signal Prediction (on or off) model using vehicle control area\nnetwork (CAN) signal data. The model is trained using two approaches, one by\ncentrally aggregating the data and the other in a federated manner. Centrally\ntrained models and federated models are compared under similar hyperparameter\nsettings. This research demonstrates the efficacy of federated learning, paving\nthe way for in-vehicle learning of driving etiquette.\n", "versions": [{"version": "v1", "created": "Tue, 22 Dec 2020 22:58:22 GMT"}], "update_date": "2020-12-24", "authors_parsed": [["Doomra", "Sonal", ""], ["Kohli", "Naman", ""], ["Athavale", "Shounak", ""]]}, {"id": "2012.12447", "submitter": "Jie Li", "authors": "Jie Li, Binglin Li, Min Gao", "title": "Skeleton-based Approaches based on Machine Vision: A Survey", "comments": "10 pages, 1 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, skeleton-based approaches have achieved rapid progress on the basis\nof great success in skeleton representation. Plenty of researches focus on\nsolving specific problems according to skeleton features. Some skeleton-based\napproaches have been mentioned in several overviews on object detection as a\nnon-essential part. Nevertheless, there has not been any thorough analysis of\nskeleton-based approaches attentively. Instead of describing these techniques\nin terms of theoretical constructs, we devote to summarizing skeleton-based\napproaches with regard to application fields and given tasks as comprehensively\nas possible. This paper is conducive to further understanding of skeleton-based\napplication and dealing with particular issues.\n", "versions": [{"version": "v1", "created": "Wed, 23 Dec 2020 02:03:37 GMT"}], "update_date": "2020-12-24", "authors_parsed": [["Li", "Jie", ""], ["Li", "Binglin", ""], ["Gao", "Min", ""]]}, {"id": "2012.12465", "submitter": "Shaolei Zhang", "authors": "Shaolei Zhang, Yang Feng, Liangyou Li", "title": "Future-Guided Incremental Transformer for Simultaneous Translation", "comments": "Accepted by AAAI 2021. 9 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Simultaneous translation (ST) starts translations synchronously while reading\nsource sentences, and is used in many online scenarios. The previous wait-k\npolicy is concise and achieved good results in ST. However, wait-k policy faces\ntwo weaknesses: low training speed caused by the recalculation of hidden states\nand lack of future source information to guide training. For the low training\nspeed, we propose an incremental Transformer with an average embedding layer\n(AEL) to accelerate the speed of calculation of the hidden states during\ntraining. For future-guided training, we propose a conventional Transformer as\nthe teacher of the incremental Transformer, and try to invisibly embed some\nfuture information in the model through knowledge distillation. We conducted\nexperiments on Chinese-English and German-English simultaneous translation\ntasks and compared with the wait-k policy to evaluate the proposed method. Our\nmethod can effectively increase the training speed by about 28 times on average\nat different k and implicitly embed some predictive abilities in the model,\nachieving better translation quality than wait-k baseline.\n", "versions": [{"version": "v1", "created": "Wed, 23 Dec 2020 03:04:49 GMT"}], "update_date": "2020-12-24", "authors_parsed": [["Zhang", "Shaolei", ""], ["Feng", "Yang", ""], ["Li", "Liangyou", ""]]}, {"id": "2012.12469", "submitter": "Jiajun Wu", "authors": "Zelin Zhao, Chuang Gan, Jiajun Wu, Xiaoxiao Guo, Joshua B. Tenenbaum", "title": "Augmenting Policy Learning with Routines Discovered from a Single\n  Demonstration", "comments": "AAAI 2021. Code is available at\n  https://github.com/sjtuytc/AAAI21-RoutineAugmentedPolicyLearning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.SC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Humans can abstract prior knowledge from very little data and use it to boost\nskill learning. In this paper, we propose routine-augmented policy learning\n(RAPL), which discovers routines composed of primitive actions from a single\ndemonstration and uses discovered routines to augment policy learning. To\ndiscover routines from the demonstration, we first abstract routine candidates\nby identifying grammar over the demonstrated action trajectory. Then, the best\nroutines measured by length and frequency are selected to form a routine\nlibrary. We propose to learn policy simultaneously at primitive-level and\nroutine-level with discovered routines, leveraging the temporal structure of\nroutines. Our approach enables imitating expert behavior at multiple temporal\nscales for imitation learning and promotes reinforcement learning exploration.\nExtensive experiments on Atari games demonstrate that RAPL improves the\nstate-of-the-art imitation learning method SQIL and reinforcement learning\nmethod A2C. Further, we show that discovered routines can generalize to unseen\nlevels and difficulties on the CoinRun benchmark.\n", "versions": [{"version": "v1", "created": "Wed, 23 Dec 2020 03:15:21 GMT"}, {"version": "v2", "created": "Thu, 24 Dec 2020 02:46:57 GMT"}, {"version": "v3", "created": "Fri, 9 Apr 2021 10:11:00 GMT"}, {"version": "v4", "created": "Sun, 2 May 2021 06:55:54 GMT"}], "update_date": "2021-05-04", "authors_parsed": [["Zhao", "Zelin", ""], ["Gan", "Chuang", ""], ["Wu", "Jiajun", ""], ["Guo", "Xiaoxiao", ""], ["Tenenbaum", "Joshua B.", ""]]}, {"id": "2012.12477", "submitter": "Mohamed Abdelsalam", "authors": "Mohamed Abdelsalam, Mojtaba Faramarzi, Shagun Sodhani, Sarath Chandar", "title": "IIRC: Incremental Implicitly-Refined Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  We introduce the \"Incremental Implicitly-Refined Classi-fication (IIRC)\"\nsetup, an extension to the class incremental learning setup where the incoming\nbatches of classes have two granularity levels. i.e., each sample could have a\nhigh-level (coarse) label like \"bear\" and a low-level (fine) label like \"polar\nbear\". Only one label is provided at a time, and the model has to figure out\nthe other label if it has already learnfed it. This setup is more aligned with\nreal-life scenarios, where a learner usually interacts with the same family of\nentities multiple times, discovers more granularity about them, while still\ntrying not to forget previous knowledge. Moreover, this setup enables\nevaluating models for some important lifelong learning challenges that cannot\nbe easily addressed under the existing setups. These challenges can be\nmotivated by the example \"if a model was trained on the class bear in one task\nand on polar bear in another task, will it forget the concept of bear, will it\nrightfully infer that a polar bear is still a bear? and will it wrongfully\nassociate the label of polar bear to other breeds of bear?\". We develop a\nstandardized benchmark that enables evaluating models on the IIRC setup. We\nevaluate several state-of-the-art lifelong learning algorithms and highlight\ntheir strengths and limitations. For example, distillation-based methods\nperform relatively well but are prone to incorrectly predicting too many labels\nper image. We hope that the proposed setup, along with the benchmark, would\nprovide a meaningful problem setting to the practitioners\n", "versions": [{"version": "v1", "created": "Wed, 23 Dec 2020 04:21:01 GMT"}, {"version": "v2", "created": "Mon, 11 Jan 2021 21:58:52 GMT"}], "update_date": "2021-01-13", "authors_parsed": [["Abdelsalam", "Mohamed", ""], ["Faramarzi", "Mojtaba", ""], ["Sodhani", "Shagun", ""], ["Chandar", "Sarath", ""]]}, {"id": "2012.12502", "submitter": "Pengtao Xie", "authors": "Xuefeng Du, Pengtao Xie", "title": "Small-Group Learning, with Application to Neural Architecture Search", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In human learning, an effective learning methodology is small-group learning:\na small group of students work together towards the same learning objective,\nwhere they express their understanding of a topic to their peers, compare their\nideas, and help each other to trouble-shoot problems. In this paper, we aim to\ninvestigate whether this human learning method can be borrowed to train better\nmachine learning models, by developing a novel ML framework -- small-group\nlearning (SGL). In our framework, a group of learners (ML models) with\ndifferent model architectures collaboratively help each other to learn by\nleveraging their complementary advantages. Specifically, each learner uses its\nintermediately trained model to generate a pseudo-labeled dataset and re-trains\nits model using pseudo-labeled datasets generated by other learners. SGL is\nformulated as a multi-level optimization framework consisting of three learning\nstages: each learner trains a model independently and uses this model to\nperform pseudo-labeling; each learner trains another model using datasets\npseudo-labeled by other learners; learners improve their architectures by\nminimizing validation losses. An efficient algorithm is developed to solve the\nmulti-level optimization problem. We apply SGL for neural architecture search.\nResults on CIFAR-100, CIFAR-10, and ImageNet demonstrate the effectiveness of\nour method.\n", "versions": [{"version": "v1", "created": "Wed, 23 Dec 2020 05:56:47 GMT"}, {"version": "v2", "created": "Thu, 11 Mar 2021 03:38:50 GMT"}], "update_date": "2021-03-12", "authors_parsed": [["Du", "Xuefeng", ""], ["Xie", "Pengtao", ""]]}, {"id": "2012.12517", "submitter": "Xiaohe Li", "authors": "Xiaohe Li, Lijie Wen, Chen Qian, Jianmin Wang", "title": "GAHNE: Graph-Aggregated Heterogeneous Network Embedding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The real-world networks often compose of different types of nodes and edges\nwith rich semantics, widely known as heterogeneous information network (HIN).\nHeterogeneous network embedding aims to embed nodes into low-dimensional\nvectors which capture rich intrinsic information of heterogeneous networks.\nHowever, existing models either depend on manually designing meta-paths, ignore\nmutual effects between different semantics, or omit some aspects of information\nfrom global networks. To address these limitations, we propose a novel\nGraph-Aggregated Heterogeneous Network Embedding (GAHNE), which is designed to\nextract the semantics of HINs as comprehensively as possible to improve the\nresults of downstream tasks based on graph convolutional neural networks. In\nGAHNE model, we develop several mechanisms that can aggregate semantic\nrepresentations from different single-type sub-networks as well as fuse the\nglobal information into final embeddings. Extensive experiments on three\nreal-world HIN datasets show that our proposed model consistently outperforms\nthe existing state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Wed, 23 Dec 2020 07:11:30 GMT"}], "update_date": "2020-12-24", "authors_parsed": [["Li", "Xiaohe", ""], ["Wen", "Lijie", ""], ["Qian", "Chen", ""], ["Wang", "Jianmin", ""]]}, {"id": "2012.12540", "submitter": "Nilotpal Sinha", "authors": "Nilotpal Sinha, Kuan-Wen Chen", "title": "Evolving Neural Architecture Using One Shot Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Neural Architecture Search (NAS) is emerging as a new research direction\nwhich has the potential to replace the hand-crafted neural architectures\ndesigned for specific tasks. Previous evolution based architecture search\nrequires high computational resources resulting in high search time. In this\nwork, we propose a novel way of applying a simple genetic algorithm to the NAS\nproblem called EvNAS (Evolving Neural Architecture using One Shot Model) which\nreduces the search time significantly while still achieving better result than\nprevious evolution based methods. The architectures are represented by using\nthe architecture parameter of the one shot model which results in the weight\nsharing among the architectures for a given population of architectures and\nalso weight inheritance from one generation to the next generation of\narchitectures. We propose a decoding technique for the architecture parameter\nwhich is used to divert majority of the gradient information towards the given\narchitecture and is also used for improving the performance prediction of the\ngiven architecture from the one shot model during the search process.\nFurthermore, we use the accuracy of the partially trained architecture on the\nvalidation data as a prediction of its fitness in order to reduce the search\ntime. EvNAS searches for the architecture on the proxy dataset i.e. CIFAR-10\nfor 4.4 GPU day on a single GPU and achieves top-1 test error of 2.47% with\n3.63M parameters which is then transferred to CIFAR-100 and ImageNet achieving\ntop-1 error of 16.37% and top-5 error of 7.4% respectively. All of these\nresults show the potential of evolutionary methods in solving the architecture\nsearch problem.\n", "versions": [{"version": "v1", "created": "Wed, 23 Dec 2020 08:40:53 GMT"}], "update_date": "2020-12-24", "authors_parsed": [["Sinha", "Nilotpal", ""], ["Chen", "Kuan-Wen", ""]]}, {"id": "2012.12544", "submitter": "Letian Zhao", "authors": "Letian Zhao, Rui Xu, Tianqi Wang, Teng Tian, Xiaotian Wang, Wei Wu,\n  Chio-in Ieong, Xi Jin", "title": "BaPipe: Exploration of Balanced Pipeline Parallelism for DNN Training", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The size of deep neural networks (DNNs) grows rapidly as the complexity of\nthe machine learning algorithm increases. To satisfy the requirement of\ncomputation and memory of DNN training, distributed deep learning based on\nmodel parallelism has been widely recognized. We propose a new pipeline\nparallelism training framework, BaPipe, which can automatically explore\npipeline parallelism training methods and balanced partition strategies for DNN\ndistributed training. In BaPipe, each accelerator calculates the forward\npropagation and backward propagation of different parts of networks to\nimplement the intra-batch pipeline parallelism strategy. BaPipe uses a new load\nbalancing automatic exploration strategy that considers the parameters of DNN\nmodels and the computation, memory, and communication resources of accelerator\nclusters. We have trained different DNNs such as VGG-16, ResNet-50, and GNMT on\nGPU clusters and simulated the performance of different FPGA clusters. Compared\nwith state-of-the-art data parallelism and pipeline parallelism frameworks,\nBaPipe provides up to 3.2x speedup and 4x memory reduction in various\nplatforms.\n", "versions": [{"version": "v1", "created": "Wed, 23 Dec 2020 08:57:39 GMT"}, {"version": "v2", "created": "Thu, 14 Jan 2021 05:58:54 GMT"}], "update_date": "2021-01-15", "authors_parsed": [["Zhao", "Letian", ""], ["Xu", "Rui", ""], ["Wang", "Tianqi", ""], ["Tian", "Teng", ""], ["Wang", "Xiaotian", ""], ["Wu", "Wei", ""], ["Ieong", "Chio-in", ""], ["Jin", "Xi", ""]]}, {"id": "2012.12556", "submitter": "Kai Han", "authors": "Kai Han, Yunhe Wang, Hanting Chen, Xinghao Chen, Jianyuan Guo, Zhenhua\n  Liu, Yehui Tang, An Xiao, Chunjing Xu, Yixing Xu, Zhaohui Yang, Yiman Zhang,\n  Dacheng Tao", "title": "A Survey on Visual Transformer", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transformer, first applied to the field of natural language processing, is a\ntype of deep neural network mainly based on the self-attention mechanism.\nThanks to its strong representation capabilities, researchers are looking at\nways to apply transformer to computer vision tasks. In a variety of visual\nbenchmarks, transformer-based models perform similar to or better than other\ntypes of networks such as convolutional and recurrent networks. Given its high\nperformance and no need for human-defined inductive bias, transformer is\nreceiving more and more attention from the computer vision community. In this\npaper, we review these visual transformer models by categorizing them in\ndifferent tasks and analyzing their advantages and disadvantages. The main\ncategories we explore include the backbone network, high/mid-level vision,\nlow-level vision, and video processing. We also take a brief look at the\nself-attention mechanism in computer vision, as it is the base component in\ntransformer. Furthermore, we include efficient transformer methods for pushing\ntransformer into real device-based applications. Toward the end of this paper,\nwe discuss the challenges and provide several further research directions for\nvisual transformers.\n", "versions": [{"version": "v1", "created": "Wed, 23 Dec 2020 09:37:54 GMT"}, {"version": "v2", "created": "Fri, 15 Jan 2021 07:09:36 GMT"}, {"version": "v3", "created": "Sat, 30 Jan 2021 09:33:55 GMT"}], "update_date": "2021-02-02", "authors_parsed": [["Han", "Kai", ""], ["Wang", "Yunhe", ""], ["Chen", "Hanting", ""], ["Chen", "Xinghao", ""], ["Guo", "Jianyuan", ""], ["Liu", "Zhenhua", ""], ["Tang", "Yehui", ""], ["Xiao", "An", ""], ["Xu", "Chunjing", ""], ["Xu", "Yixing", ""], ["Yang", "Zhaohui", ""], ["Zhang", "Yiman", ""], ["Tao", "Dacheng", ""]]}, {"id": "2012.12570", "submitter": "Guodong Zeng", "authors": "Guodong Zeng, Till D. Lerch, Florian Schmaranzer, Guoyan Zheng,\n  Juergen Burger, Kate Gerber, Moritz Tannast, Klaus Siebenrock, Nicolas Gerber", "title": "ICMSC: Intra- and Cross-modality Semantic Consistency for Unsupervised\n  Domain Adaptation on Hip Joint Bone Segmentation", "comments": "12 pages, 3 figures, submitted to IPMI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Unsupervised domain adaptation (UDA) for cross-modality medical image\nsegmentation has shown great progress by domain-invariant feature learning or\nimage appearance translation. Adapted feature learning usually cannot detect\ndomain shifts at the pixel level and is not able to achieve good results in\ndense semantic segmentation tasks. Image appearance translation, e.g. CycleGAN,\ntranslates images into different styles with good appearance, despite its\npopulation, its semantic consistency is hardly to maintain and results in poor\ncross-modality segmentation. In this paper, we propose intra- and\ncross-modality semantic consistency (ICMSC) for UDA and our key insight is that\nthe segmentation of synthesised images in different styles should be\nconsistent. Specifically, our model consists of an image translation module and\na domain-specific segmentation module. The image translation module is a\nstandard CycleGAN, while the segmentation module contains two domain-specific\nsegmentation networks. The intra-modality semantic consistency (IMSC) forces\nthe reconstructed image after a cycle to be segmented in the same way as the\noriginal input image, while the cross-modality semantic consistency (CMSC)\nencourages the synthesized images after translation to be segmented exactly the\nsame as before translation. Comprehensive experimental results on\ncross-modality hip joint bone segmentation show the effectiveness of our\nproposed method, which achieves an average DICE of 81.61% on the acetabulum and\n88.16% on the proximal femur, outperforming other state-of-the-art methods. It\nis worth to note that without UDA, a model trained on CT for hip joint bone\nsegmentation is non-transferable to MRI and has almost zero-DICE segmentation.\n", "versions": [{"version": "v1", "created": "Wed, 23 Dec 2020 09:58:38 GMT"}], "update_date": "2020-12-24", "authors_parsed": [["Zeng", "Guodong", ""], ["Lerch", "Till D.", ""], ["Schmaranzer", "Florian", ""], ["Zheng", "Guoyan", ""], ["Burger", "Juergen", ""], ["Gerber", "Kate", ""], ["Tannast", "Moritz", ""], ["Siebenrock", "Klaus", ""], ["Gerber", "Nicolas", ""]]}, {"id": "2012.12586", "submitter": "Oscar Guerrero-Rosado", "authors": "Oscar Guerrero-Rosado and Paul Verschure", "title": "Distributed Adaptive Control: An ideal Cognitive Architecture candidate\n  for managing a robotic recycling plant", "comments": "12 pages, 2 figures, Living Machines conference 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI cs.NE cs.RO cs.SY eess.SY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In the past decade, society has experienced notable growth in a variety of\ntechnological areas. However, the Fourth Industrial Revolution has not been\nembraced yet. Industry 4.0 imposes several challenges which include the\nnecessity of new architectural models to tackle the uncertainty that open\nenvironments represent to cyber-physical systems (CPS). Waste Electrical and\nElectronic Equipment (WEEE) recycling plants stand for one of such open\nenvironments. Here, CPSs must work harmoniously in a changing environment,\ninteracting with similar and not so similar CPSs, and adaptively collaborating\nwith human workers. In this paper, we support the Distributed Adaptive Control\n(DAC) theory as a suitable Cognitive Architecture for managing a recycling\nplant. Specifically, a recursive implementation of DAC (between both\nsingle-agent and large-scale levels) is proposed to meet the expected demands\nof the European Project HR-Recycler. Additionally, with the aim of having a\nrealistic benchmark for future implementations of the recursive DAC, a\nmicro-recycling plant prototype is presented.\n", "versions": [{"version": "v1", "created": "Wed, 23 Dec 2020 10:33:22 GMT"}], "update_date": "2020-12-24", "authors_parsed": [["Guerrero-Rosado", "Oscar", ""], ["Verschure", "Paul", ""]]}, {"id": "2012.12588", "submitter": "Jean-Guy Mailly", "authors": "Jean-Guy Mailly and Julien Rossit", "title": "Stability in Abstract Argumentation", "comments": "7 pages, 7 figures, accepted to the 18th International Workshop on\n  Non-Monotonic Reasoning (NMR 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The notion of stability in a structured argumentation setup characterizes\nsituations where the acceptance status associated with a given literal will not\nbe impacted by any future evolution of this setup. In this paper, we abstract\naway from the logical structure of arguments, and we transpose this notion of\nstability to the context of Dungean argumentation frameworks. In particular, we\nshow how this problem can be translated into reasoning with Argument-Incomplete\nAFs. Then we provide preliminary complexity results for stability under four\nprominent semantics, in the case of both credulous and skeptical reasoning.\nFinally, we illustrate to what extent this notion can be useful with an\napplication to argument-based negotiation.\n", "versions": [{"version": "v1", "created": "Wed, 23 Dec 2020 10:34:38 GMT"}], "update_date": "2020-12-24", "authors_parsed": [["Mailly", "Jean-Guy", ""], ["Rossit", "Julien", ""]]}, {"id": "2012.12600", "submitter": "David Kedziora", "authors": "David Jacob Kedziora and Katarzyna Musial and Bogdan Gabrys", "title": "AutonoML: Towards an Integrated Framework for Autonomous Machine\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Over the last decade, the long-running endeavour to automate high-level\nprocesses in machine learning (ML) has risen to mainstream prominence,\nstimulated by advances in optimisation techniques and their impact on selecting\nML models/algorithms. Central to this drive is the appeal of engineering a\ncomputational system that both discovers and deploys high-performance solutions\nto arbitrary ML problems with minimal human interaction. Beyond this, an even\nloftier goal is the pursuit of autonomy, which describes the capability of the\nsystem to independently adjust an ML solution over a lifetime of changing\ncontexts. However, these ambitions are unlikely to be achieved in a robust\nmanner without the broader synthesis of various mechanisms and theoretical\nframeworks, which, at the present time, remain scattered across numerous\nresearch threads. Accordingly, this review seeks to motivate a more expansive\nperspective on what constitutes an automated/autonomous ML system, alongside\nconsideration of how best to consolidate those elements. In doing so, we survey\ndevelopments in the following research areas: hyperparameter optimisation,\nmulti-component models, neural architecture search, automated feature\nengineering, meta-learning, multi-level ensembling, dynamic adaptation,\nmulti-objective evaluation, resource constraints, flexible user involvement,\nand the principles of generalisation. We also develop a conceptual framework\nthroughout the review, augmented by each topic, to illustrate one possible way\nof fusing high-level mechanisms into an autonomous ML system. Ultimately, we\nconclude that the notion of architectural integration deserves more discussion,\nwithout which the field of automated ML risks stifling both its technical\nadvantages and general uptake.\n", "versions": [{"version": "v1", "created": "Wed, 23 Dec 2020 11:01:10 GMT"}], "update_date": "2020-12-24", "authors_parsed": [["Kedziora", "David Jacob", ""], ["Musial", "Katarzyna", ""], ["Gabrys", "Bogdan", ""]]}, {"id": "2012.12620", "submitter": "Rundong Wang", "authors": "Rundong Wang, Hongxin Wei, Bo An, Zhouyan Feng, Jun Yao", "title": "Deep Stock Trading: A Hierarchical Reinforcement Learning Framework for\n  Portfolio Optimization and Order Execution", "comments": "This paper was accepted by AAAI 2021 with the original title:\n  Commission Fee is not Enough: A Hierarchical Reinforced Framework for\n  Portfolio Management", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Portfolio management via reinforcement learning is at the forefront of\nfintech research, which explores how to optimally reallocate a fund into\ndifferent financial assets over the long term by trial-and-error. Existing\nmethods are impractical since they usually assume each reallocation can be\nfinished immediately and thus ignoring the price slippage as part of the\ntrading cost. To address these issues, we propose a hierarchical reinforced\nstock trading system for portfolio management (HRPM). Concretely, we decompose\nthe trading process into a hierarchy of portfolio management over trade\nexecution and train the corresponding policies. The high-level policy gives\nportfolio weights at a lower frequency to maximize the long term profit and\ninvokes the low-level policy to sell or buy the corresponding shares within a\nshort time window at a higher frequency to minimize the trading cost. We train\ntwo levels of policies via pre-training scheme and iterative training scheme\nfor data efficiency. Extensive experimental results in the U.S. market and the\nChina market demonstrate that HRPM achieves significant improvement against\nmany state-of-the-art approaches.\n", "versions": [{"version": "v1", "created": "Wed, 23 Dec 2020 12:09:26 GMT"}, {"version": "v2", "created": "Sun, 7 Feb 2021 12:37:07 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["Wang", "Rundong", ""], ["Wei", "Hongxin", ""], ["An", "Bo", ""], ["Feng", "Zhouyan", ""], ["Yao", "Jun", ""]]}, {"id": "2012.12627", "submitter": "Xi Victoria Lin", "authors": "Xi Victoria Lin and Richard Socher and Caiming Xiong", "title": "Bridging Textual and Tabular Data for Cross-Domain Text-to-SQL Semantic\n  Parsing", "comments": "EMNLP Findings 2020 long paper extended; 23 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.DB cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present BRIDGE, a powerful sequential architecture for modeling\ndependencies between natural language questions and relational databases in\ncross-DB semantic parsing. BRIDGE represents the question and DB schema in a\ntagged sequence where a subset of the fields are augmented with cell values\nmentioned in the question. The hybrid sequence is encoded by BERT with minimal\nsubsequent layers and the text-DB contextualization is realized via the\nfine-tuned deep attention in BERT. Combined with a pointer-generator decoder\nwith schema-consistency driven search space pruning, BRIDGE attained\nstate-of-the-art performance on popular cross-DB text-to-SQL benchmarks, Spider\n(71.1\\% dev, 67.5\\% test with ensemble model) and WikiSQL (92.6\\% dev, 91.9\\%\ntest). Our analysis shows that BRIDGE effectively captures the desired\ncross-modal dependencies and has the potential to generalize to more text-DB\nrelated tasks. Our implementation is available at\n\\url{https://github.com/salesforce/TabularSemanticParsing}.\n", "versions": [{"version": "v1", "created": "Wed, 23 Dec 2020 12:33:52 GMT"}, {"version": "v2", "created": "Thu, 31 Dec 2020 01:02:40 GMT"}], "update_date": "2021-01-01", "authors_parsed": [["Lin", "Xi Victoria", ""], ["Socher", "Richard", ""], ["Xiong", "Caiming", ""]]}, {"id": "2012.12634", "submitter": "Simin Liu", "authors": "Simin Liu", "title": "Overview of FPGA deep learning acceleration based on convolutional\n  neural network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In recent years, deep learning has become more and more mature, and as a\ncommonly used algorithm in deep learning, convolutional neural networks have\nbeen widely used in various visual tasks. In the past, research based on deep\nlearning algorithms mainly relied on hardware such as GPUs and CPUs. However,\nwith the increasing development of FPGAs, both field programmable logic gate\narrays, it has become the main implementation hardware platform that combines\nvarious neural network deep learning algorithms This article is a review\narticle, which mainly introduces the related theories and algorithms of\nconvolution. It summarizes the application scenarios of several existing FPGA\ntechnologies based on convolutional neural networks, and mainly introduces the\napplication of accelerators. At the same time, it summarizes some accelerators'\nunder-utilization of logic resources or under-utilization of memory bandwidth,\nso that they can't get the best performance.\n", "versions": [{"version": "v1", "created": "Wed, 23 Dec 2020 12:44:24 GMT"}], "update_date": "2020-12-24", "authors_parsed": [["Liu", "Simin", ""]]}, {"id": "2012.12689", "submitter": "Guido Fioretti", "authors": "Guido Fioretti, Andrea Policarpi", "title": "The Less Intelligent the Elements, the More Intelligent the Whole. Or,\n  Possibly Not?", "comments": "22 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.AI cs.SY nlin.AO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We dare to make use of a possible analogy between neurons in a brain and\npeople in society, asking ourselves whether individual intelligence is\nnecessary in order to collective wisdom to emerge and, most importantly, what\nsort of individual intelligence is conducive of greater collective wisdom. We\nreview insights and findings from connectionism, agent-based modeling, group\npsychology, economics and physics, casting them in terms of changing structure\nof the system's Lyapunov function. Finally, we apply these insights to the sort\nand degrees of intelligence of preys and predators in the Lotka-Volterra model,\nexplaining why certain individual understandings lead to co-existence of the\ntwo species whereas other usages of their individual intelligence cause global\nextinction.\n", "versions": [{"version": "v1", "created": "Wed, 23 Dec 2020 14:19:49 GMT"}], "update_date": "2020-12-24", "authors_parsed": [["Fioretti", "Guido", ""], ["Policarpi", "Andrea", ""]]}, {"id": "2012.12718", "submitter": "Rajaa El Hamdani", "authors": "David Restrepo Amariles, Aurore Cl\\'ement Troussel, Rajaa El Hamdani", "title": "Compliance Generation for Privacy Documents under GDPR: A Roadmap for\n  Implementing Automation and Machine Learning", "comments": "14 pages, The paper was presented at GDPR Compliance Theories,\n  Techniques, Tools a Workshop of JURIX 2019. Universidad Polit\\'ecnica de\n  Madrid, Madrid, Spain, 11 December 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most prominent research today addresses compliance with data protection laws\nthrough consumer-centric and public-regulatory approaches. We shift this\nperspective with the Privatech project to focus on corporations and law firms\nas agents of compliance. To comply with data protection laws, data processors\nmust implement accountability measures to assess and document compliance in\nrelation to both privacy documents and privacy practices. In this paper, we\nsurvey, on the one hand, current research on GDPR automation, and on the other\nhand, the operational challenges corporations face to comply with GDPR, and\nthat may benefit from new forms of automation. We attempt to bridge the gap. We\nprovide a roadmap for compliance assessment and generation by identifying\ncompliance issues, breaking them down into tasks that can be addressed through\nmachine learning and automation, and providing notes about related developments\nin the Privatech project.\n", "versions": [{"version": "v1", "created": "Wed, 23 Dec 2020 14:46:51 GMT"}], "update_date": "2020-12-24", "authors_parsed": [["Amariles", "David Restrepo", ""], ["Troussel", "Aurore Cl\u00e9ment", ""], ["Hamdani", "Rajaa El", ""]]}, {"id": "2012.12732", "submitter": "Giulio Mazzi", "authors": "Giulio Mazzi, Alberto Castellini, Alessandro Farinelli", "title": "Identification of Unexpected Decisions in Partially Observable\n  Monte-Carlo Planning: a Rule-Based Approach", "comments": "AAMAS 2021, 3-7 May 2021, London-UK (Virtual)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Partially Observable Monte-Carlo Planning (POMCP) is a powerful online\nalgorithm able to generate approximate policies for large Partially Observable\nMarkov Decision Processes. The online nature of this method supports\nscalability by avoiding complete policy representation. The lack of an explicit\nrepresentation however hinders interpretability. In this work, we propose a\nmethodology based on Satisfiability Modulo Theory (SMT) for analyzing POMCP\npolicies by inspecting their traces, namely sequences of\nbelief-action-observation triplets generated by the algorithm. The proposed\nmethod explores local properties of policy behavior to identify unexpected\ndecisions. We propose an iterative process of trace analysis consisting of\nthree main steps, i) the definition of a question by means of a parametric\nlogical formula describing (probabilistic) relationships between beliefs and\nactions, ii) the generation of an answer by computing the parameters of the\nlogical formula that maximize the number of satisfied clauses (solving a\nMAX-SMT problem), iii) the analysis of the generated logical formula and the\nrelated decision boundaries for identifying unexpected decisions made by POMCP\nwith respect to the original question. We evaluate our approach on Tiger, a\nstandard benchmark for POMDPs, and a real-world problem related to mobile robot\nnavigation. Results show that the approach can exploit human knowledge on the\ndomain, outperforming state-of-the-art anomaly detection methods in identifying\nunexpected decisions. An improvement of the Area Under Curve up to 47\\% has\nbeen achieved in our tests.\n", "versions": [{"version": "v1", "created": "Wed, 23 Dec 2020 15:09:28 GMT"}, {"version": "v2", "created": "Wed, 28 Apr 2021 14:16:54 GMT"}], "update_date": "2021-04-29", "authors_parsed": [["Mazzi", "Giulio", ""], ["Castellini", "Alberto", ""], ["Farinelli", "Alessandro", ""]]}, {"id": "2012.12741", "submitter": "Wenwei Zhang", "authors": "Wenwei Zhang, Zhe Wang, Chen Change Loy", "title": "Exploring Data Augmentation for Multi-Modality 3D Object Detection", "comments": "Technical Report", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  It is counter-intuitive that multi-modality methods based on point cloud and\nimages perform only marginally better or sometimes worse than approaches that\nsolely use point cloud. This paper investigates the reason behind this\nphenomenon. Due to the fact that multi-modality data augmentation must maintain\nconsistency between point cloud and images, recent methods in this field\ntypically use relatively insufficient data augmentation. This shortage makes\ntheir performance under expectation. Therefore, we contribute a pipeline, named\ntransformation flow, to bridge the gap between single and multi-modality data\naugmentation with transformation reversing and replaying. In addition,\nconsidering occlusions, a point in different modalities may be occupied by\ndifferent objects, making augmentations such as cut and paste non-trivial for\nmulti-modality detection. We further present Multi-mOdality Cut and pAste\n(MoCa), which simultaneously considers occlusion and physical plausibility to\nmaintain the multi-modality consistency. Without using ensemble of detectors,\nour multi-modality detector achieves new state-of-the-art performance on\nnuScenes dataset and competitive performance on KITTI 3D benchmark. Our method\nalso wins the best PKL award in the 3rd nuScenes detection challenge. Code and\nmodels will be released at https://github.com/open-mmlab/mmdetection3d.\n", "versions": [{"version": "v1", "created": "Wed, 23 Dec 2020 15:23:16 GMT"}, {"version": "v2", "created": "Wed, 21 Apr 2021 16:23:20 GMT"}], "update_date": "2021-04-22", "authors_parsed": [["Zhang", "Wenwei", ""], ["Wang", "Zhe", ""], ["Loy", "Chen Change", ""]]}, {"id": "2012.12756", "submitter": "Soumitra Ghosh", "authors": "Soumitra Ghosh, Arkaprava Roy, Asif Ekbal and Pushpak Bhattacharyya", "title": "EmotionGIF-IITP-AINLPML: Ensemble-based Automated Deep Neural System for\n  predicting category(ies) of a GIF response", "comments": "EmotionGIF 2020, the shared task of SocialNLP 2020 (in conjunction\n  with ACL 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we describe the systems submitted by our IITP-AINLPML team in\nthe shared task of SocialNLP 2020, EmotionGIF 2020, on predicting the\ncategory(ies) of a GIF response for a given unlabelled tweet. For the round 1\nphase of the task, we propose an attention-based Bi-directional GRU network\ntrained on both the tweet (text) and their replies (text wherever available)\nand the given category(ies) for its GIF response. In the round 2 phase, we\nbuild several deep neural-based classifiers for the task and report the final\npredictions through a majority voting based ensemble technique. Our proposed\nmodels attain the best Mean Recall (MR) scores of 52.92% and 53.80% in round 1\nand round 2, respectively.\n", "versions": [{"version": "v1", "created": "Wed, 23 Dec 2020 15:52:27 GMT"}], "update_date": "2020-12-24", "authors_parsed": [["Ghosh", "Soumitra", ""], ["Roy", "Arkaprava", ""], ["Ekbal", "Asif", ""], ["Bhattacharyya", "Pushpak", ""]]}, {"id": "2012.12764", "submitter": "Jan Martijn Van Der Werf", "authors": "Jan Martijn E. M. van der Werf, Artem Polyvyanyy, Bart R. van\n  Wensveen, Matthieu Brinkhuis and Hajo A. Reijers", "title": "All That Glitters Is Not Gold: Towards Process Discovery Techniques with\n  Guarantees", "comments": "13 pages, 4 figures. Submitted to the International Conference on\n  Advanced Information Systems Engineering, 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The aim of a process discovery algorithm is to construct from event data a\nprocess model that describes the underlying, real-world process well.\nIntuitively, the better the quality of the event data, the better the quality\nof the model that is discovered. However, existing process discovery algorithms\ndo not guarantee this relationship. We demonstrate this by using a range of\nquality measures for both event data and discovered process models. This paper\nis a call to the community of IS engineers to complement their process\ndiscovery algorithms with properties that relate qualities of their inputs to\nthose of their outputs. To this end, we distinguish four incremental stages for\nthe development of such algorithms, along with concrete guidelines for the\nformulation of relevant properties and experimental validation. We will also\nuse these stages to reflect on the state of the art, which shows the need to\nmove forward in our thinking about algorithmic process discovery.\n", "versions": [{"version": "v1", "created": "Wed, 23 Dec 2020 16:08:47 GMT"}], "update_date": "2020-12-24", "authors_parsed": [["van der Werf", "Jan Martijn E. M.", ""], ["Polyvyanyy", "Artem", ""], ["van Wensveen", "Bart R.", ""], ["Brinkhuis", "Matthieu", ""], ["Reijers", "Hajo A.", ""]]}, {"id": "2012.12809", "submitter": "Christopher Grimm", "authors": "Christopher Grimm, Tai Fei, Ernst Warsitz, Ridha Farhoud, Tobias\n  Breddermann, Reinhold Haeb-Umbach", "title": "Warping of Radar Data into Camera Image for Cross-Modal Supervision in\n  Automotive Applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI eess.SP", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  In this paper, we present a novel framework to project automotive radar\nrange-Doppler (RD) spectrum into camera image. The utilized warping operation\nis designed to be fully differentiable, which allows error backpropagation\nthrough the operation. This enables the training of neural networks (NN)\noperating exclusively on RD spectrum by utilizing labels provided from camera\nvision models. As the warping operation relies on accurate scene flow,\nadditionally, we present a novel scene flow estimation algorithm fed from\ncamera, lidar and radar, enabling us to improve the accuracy of the warping\noperation. We demonstrate the framework in multiple applications like\ndirection-of-arrival (DoA) estimation, target detection, semantic segmentation\nand estimation of radar power from camera data. Extensive evaluations have been\ncarried out for the DoA application and suggest superior quality for NN based\nestimators compared to classical estimators. The novel scene flow estimation\napproach is benchmarked against state-of-the-art scene flow algorithms and\noutperforms them by roughly a third.\n", "versions": [{"version": "v1", "created": "Wed, 23 Dec 2020 17:12:59 GMT"}], "update_date": "2020-12-24", "authors_parsed": [["Grimm", "Christopher", ""], ["Fei", "Tai", ""], ["Warsitz", "Ernst", ""], ["Farhoud", "Ridha", ""], ["Breddermann", "Tobias", ""], ["Haeb-Umbach", "Reinhold", ""]]}, {"id": "2012.12871", "submitter": "Nithin Holla", "authors": "Phillip Lippe, Nithin Holla, Shantanu Chandra, Santhosh Rajamanickam,\n  Georgios Antoniou, Ekaterina Shutova, Helen Yannakoudakis", "title": "A Multimodal Framework for the Detection of Hateful Memes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An increasingly common expression of online hate speech is multimodal in\nnature and comes in the form of memes. Designing systems to automatically\ndetect hateful content is of paramount importance if we are to mitigate its\nundesirable effects on the society at large. The detection of multimodal hate\nspeech is an intrinsically difficult and open problem: memes convey a message\nusing both images and text and, hence, require multimodal reasoning and joint\nvisual and language understanding. In this work, we seek to advance this line\nof research and develop a multimodal framework for the detection of hateful\nmemes. We improve the performance of existing multimodal approaches beyond\nsimple fine-tuning and, among others, show the effectiveness of upsampling of\ncontrastive examples to encourage multimodality and ensemble learning based on\ncross-validation to improve robustness. We furthermore analyze model\nmisclassifications and discuss a number of hypothesis-driven augmentations and\ntheir effects on performance, presenting important implications for future\nresearch in the field. Our best approach comprises an ensemble of UNITER-based\nmodels and achieves an AUROC score of 80.53, placing us 4th on phase 2 of the\n2020 Hateful Memes Challenge organized by Facebook.\n", "versions": [{"version": "v1", "created": "Wed, 23 Dec 2020 18:37:11 GMT"}, {"version": "v2", "created": "Thu, 24 Dec 2020 14:28:17 GMT"}], "update_date": "2020-12-25", "authors_parsed": [["Lippe", "Phillip", ""], ["Holla", "Nithin", ""], ["Chandra", "Shantanu", ""], ["Rajamanickam", "Santhosh", ""], ["Antoniou", "Georgios", ""], ["Shutova", "Ekaterina", ""], ["Yannakoudakis", "Helen", ""]]}, {"id": "2012.12899", "submitter": "Pengtao Xie", "authors": "Ramtin Hosseini, Pengtao Xie", "title": "Learning by Self-Explanation, with Application to Neural Architecture\n  Search", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Learning by self-explanation is an effective learning technique in human\nlearning, where students explain a learned topic to themselves for deepening\ntheir understanding of this topic. It is interesting to investigate whether\nthis explanation-driven learning methodology broadly used by humans is helpful\nfor improving machine learning as well. Based on this inspiration, we propose a\nnovel machine learning method called learning by self-explanation (LeaSE). In\nour approach, an explainer model improves its learning ability by trying to\nclearly explain to an audience model regarding how a prediction outcome is\nmade. LeaSE is formulated as a four-level optimization problem involving a\nsequence of four learning stages which are conducted end-to-end in a unified\nframework: 1) explainer learns; 2) explainer explains; 3) audience learns; 4)\nexplainer re-learns based on the performance of the audience. We develop an\nefficient algorithm to solve the LeaSE problem. We apply LeaSE for neural\narchitecture search on CIFAR-100, CIFAR-10, and ImageNet. Experimental results\nstrongly demonstrate the effectiveness of our method.\n", "versions": [{"version": "v1", "created": "Wed, 23 Dec 2020 07:39:54 GMT"}, {"version": "v2", "created": "Thu, 11 Mar 2021 01:05:48 GMT"}], "update_date": "2021-03-12", "authors_parsed": [["Hosseini", "Ramtin", ""], ["Xie", "Pengtao", ""]]}, {"id": "2012.12964", "submitter": "Maxwell Nye", "authors": "Maxwell Nye, Yewen Pu, Matthew Bowers, Jacob Andreas, Joshua B.\n  Tenenbaum, Armando Solar-Lezama", "title": "Representing Partial Programs with Blended Abstract Semantics", "comments": "ICLR 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Synthesizing programs from examples requires searching over a vast,\ncombinatorial space of possible programs. In this search process, a key\nchallenge is representing the behavior of a partially written program before it\ncan be executed, to judge if it is on the right track and predict where to\nsearch next. We introduce a general technique for representing partially\nwritten programs in a program synthesis engine. We take inspiration from the\ntechnique of abstract interpretation, in which an approximate execution model\nis used to determine if an unfinished program will eventually satisfy a goal\nspecification. Here we learn an approximate execution model implemented as a\nmodular neural network. By constructing compositional program representations\nthat implicitly encode the interpretation semantics of the underlying\nprogramming language, we can represent partial programs using a flexible\ncombination of concrete execution state and learned neural representations,\nusing the learned approximate semantics when concrete semantics are not known\n(in unfinished parts of the program). We show that these hybrid neuro-symbolic\nrepresentations enable execution-guided synthesizers to use more powerful\nlanguage constructs, such as loops and higher-order functions, and can be used\nto synthesize programs more accurately for a given search budget than pure\nneural approaches in several domains.\n", "versions": [{"version": "v1", "created": "Wed, 23 Dec 2020 20:40:18 GMT"}, {"version": "v2", "created": "Mon, 19 Apr 2021 18:44:59 GMT"}], "update_date": "2021-04-21", "authors_parsed": [["Nye", "Maxwell", ""], ["Pu", "Yewen", ""], ["Bowers", "Matthew", ""], ["Andreas", "Jacob", ""], ["Tenenbaum", "Joshua B.", ""], ["Solar-Lezama", "Armando", ""]]}, {"id": "2012.12975", "submitter": "Riza Velioglu", "authors": "Riza Velioglu, Jewgeni Rose", "title": "Detecting Hate Speech in Memes Using Multimodal Deep Learning\n  Approaches: Prize-winning solution to Hateful Memes Challenge", "comments": "Presented at NeurIPS (2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Memes on the Internet are often harmless and sometimes amusing. However, by\nusing certain types of images, text, or combinations of both, the seemingly\nharmless meme becomes a multimodal type of hate speech -- a hateful meme. The\nHateful Memes Challenge is a first-of-its-kind competition which focuses on\ndetecting hate speech in multimodal memes and it proposes a new data set\ncontaining 10,000+ new examples of multimodal content. We utilize VisualBERT --\nwhich meant to be the BERT of vision and language -- that was trained\nmultimodally on images and captions and apply Ensemble Learning. Our approach\nachieves 0.811 AUROC with an accuracy of 0.765 on the challenge test set and\nplaced third out of 3,173 participants in the Hateful Memes Challenge.\n", "versions": [{"version": "v1", "created": "Wed, 23 Dec 2020 21:09:52 GMT"}], "update_date": "2020-12-25", "authors_parsed": [["Velioglu", "Riza", ""], ["Rose", "Jewgeni", ""]]}, {"id": "2012.12982", "submitter": "Gaia Belardinelli", "authors": "Gaia Belardinelli, Rasmus K. Rendsvig", "title": "Awareness Logic: A Kripke-based Rendition of the Heifetz-Meier-Schipper\n  Model", "comments": "18 pages, 2 figures, proceedings of DaLi conference 2020", "journal-ref": "Martins M.A., Sedl\\'ar I. (eds) Dynamic Logic. New Trends and\n  Applications. DaLi 2020. Lecture Notes in Computer Science, vol 12569, pp\n  33-50. Springer, Cham", "doi": "10.1007/978-3-030-65840-3_3", "report-no": null, "categories": "cs.AI cs.LO cs.MA econ.TH math.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Heifetz, Meier and Schipper (HMS) present a lattice model of awareness. The\nHMS model is syntax-free, which precludes the simple option to rely on formal\nlanguage to induce lattices, and represents uncertainty and unawareness with\none entangled construct, making it difficult to assess the properties of\neither. Here, we present a model based on a lattice of Kripke models, induced\nby atom subset inclusion, in which uncertainty and unawareness are separate. We\nshow the models to be equivalent by defining transformations between them which\npreserve formula satisfaction, and obtain completeness through our and HMS'\nresults.\n", "versions": [{"version": "v1", "created": "Wed, 23 Dec 2020 21:24:06 GMT"}], "update_date": "2020-12-25", "authors_parsed": [["Belardinelli", "Gaia", ""], ["Rendsvig", "Rasmus K.", ""]]}, {"id": "2012.13016", "submitter": "Lance Eliot", "authors": "Lance Eliot", "title": "Antitrust and Artificial Intelligence (AAI): Antitrust Vigilance\n  Lifecycle and AI Legal Reasoning Autonomy", "comments": "29 pages, 12 figures. arXiv admin note: text overlap with\n  arXiv:2010.02726, arXiv:2009.14620", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is an increasing interest in the entwining of the field of antitrust\nwith the field of Artificial Intelligence (AI), frequently referred to jointly\nas Antitrust and AI (AAI) in the research literature. This study focuses on the\nsynergies entangling antitrust and AI, doing so to extend the literature by\nproffering the primary ways that these two fields intersect, consisting of: (1)\nthe application of antitrust to AI, and (2) the application of AI to antitrust.\nTo date, most of the existing research on this intermixing has concentrated on\nthe former, namely the application of antitrust to AI, entailing how the\nmarketplace will be altered by the advent of AI and the potential for adverse\nantitrust behaviors arising accordingly. Opting to explore more deeply the\nother side of this coin, this research closely examines the application of AI\nto antitrust and establishes an antitrust vigilance lifecycle to which AI is\npredicted to be substantively infused for purposes of enabling and bolstering\nantitrust detection, enforcement, and post-enforcement monitoring. Furthermore,\na gradual and incremental injection of AI into antitrust vigilance is\nanticipated to occur as significant advances emerge amidst the Levels of\nAutonomy (LoA) for AI Legal Reasoning (AILR).\n", "versions": [{"version": "v1", "created": "Wed, 23 Dec 2020 22:58:51 GMT"}], "update_date": "2020-12-25", "authors_parsed": [["Eliot", "Lance", ""]]}, {"id": "2012.13026", "submitter": "Siqi Wang", "authors": "Xiren Zhou and Siqi Wang and Ruisheng Diao and Desong Bian and Jiahui\n  Duan and Di Shi", "title": "Rethink AI-based Power Grid Control: Diving Into Algorithm Design", "comments": "Accepted by 34th NeurIPS Ml4eng Workshop, 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Recently, deep reinforcement learning (DRL)-based approach has shown\npromisein solving complex decision and control problems in power engineering\ndomain.In this paper, we present an in-depth analysis of DRL-based voltage\ncontrol fromaspects of algorithm selection, state space representation, and\nreward engineering.To resolve observed issues, we propose a novel imitation\nlearning-based approachto directly map power grid operating points to effective\nactions without any interimreinforcement learning process. The performance\nresults demonstrate that theproposed approach has strong generalization ability\nwith much less training time.The agent trained by imitation learning is\neffective and robust to solve voltagecontrol problem and outperforms the former\nRL agents.\n", "versions": [{"version": "v1", "created": "Wed, 23 Dec 2020 23:38:41 GMT"}], "update_date": "2020-12-25", "authors_parsed": [["Zhou", "Xiren", ""], ["Wang", "Siqi", ""], ["Diao", "Ruisheng", ""], ["Bian", "Desong", ""], ["Duan", "Jiahui", ""], ["Shi", "Di", ""]]}, {"id": "2012.13037", "submitter": "Daniel Kasenberg", "authors": "Vasanth Sarathy, Daniel Kasenberg, Shivam Goel, Jivko Sinapov,\n  Matthias Scheutz", "title": "SPOTTER: Extending Symbolic Planning Operators through Targeted\n  Reinforcement Learning", "comments": "Accepted to AAMAS 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Symbolic planning models allow decision-making agents to sequence actions in\narbitrary ways to achieve a variety of goals in dynamic domains. However, they\nare typically handcrafted and tend to require precise formulations that are not\nrobust to human error. Reinforcement learning (RL) approaches do not require\nsuch models, and instead learn domain dynamics by exploring the environment and\ncollecting rewards. However, RL approaches tend to require millions of episodes\nof experience and often learn policies that are not easily transferable to\nother tasks. In this paper, we address one aspect of the open problem of\nintegrating these approaches: how can decision-making agents resolve\ndiscrepancies in their symbolic planning models while attempting to accomplish\ngoals? We propose an integrated framework named SPOTTER that uses RL to augment\nand support (\"spot\") a planning agent by discovering new operators needed by\nthe agent to accomplish goals that are initially unreachable for the agent.\nSPOTTER outperforms pure-RL approaches while also discovering transferable\nsymbolic knowledge and does not require supervision, successful plan traces or\nany a priori knowledge about the missing planning operator.\n", "versions": [{"version": "v1", "created": "Thu, 24 Dec 2020 00:31:02 GMT"}], "update_date": "2020-12-25", "authors_parsed": [["Sarathy", "Vasanth", ""], ["Kasenberg", "Daniel", ""], ["Goel", "Shivam", ""], ["Sinapov", "Jivko", ""], ["Scheutz", "Matthias", ""]]}, {"id": "2012.13042", "submitter": "Soroush Vosoughi Dr", "authors": "Xiaobo Guo, Soroush Vosoughi", "title": "Multi-modal Identification of State-Sponsored Propaganda on Social Media", "comments": "Proceedings of the 25th International Conference on Pattern\n  Recognition (ICPR 2020)", "journal-ref": null, "doi": "10.1109/ICPR48806.2021.9412672", "report-no": null, "categories": "cs.CL cs.AI cs.SI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  The prevalence of state-sponsored propaganda on the Internet has become a\ncause for concern in the recent years. While much effort has been made to\nidentify state-sponsored Internet propaganda, the problem remains far from\nbeing solved because the ambiguous definition of propaganda leads to unreliable\ndata labelling, and the huge amount of potential predictive features causes the\nmodels to be inexplicable. This paper is the first attempt to build a balanced\ndataset for this task. The dataset is comprised of propaganda by three\ndifferent organizations across two time periods. A multi-model framework for\ndetecting propaganda messages solely based on the visual and textual content is\nproposed which achieves a promising performance on detecting propaganda by the\nthree organizations both for the same time period (training and testing on data\nfrom the same time period) (F1=0.869) and for different time periods (training\non past, testing on future) (F1=0.697). To reduce the influence of false\npositive predictions, we change the threshold to test the relationship between\nthe false positive and true positive rates and provide explanations for the\npredictions made by our models with visualization tools to enhance the\ninterpretability of our framework. Our new dataset and general framework\nprovide a strong benchmark for the task of identifying state-sponsored Internet\npropaganda and point out a potential path for future work on this task.\n", "versions": [{"version": "v1", "created": "Thu, 24 Dec 2020 00:43:09 GMT"}], "update_date": "2021-05-13", "authors_parsed": [["Guo", "Xiaobo", ""], ["Vosoughi", "Soroush", ""]]}, {"id": "2012.13045", "submitter": "Aldo Pacchiano", "authors": "Aldo Pacchiano, Christoph Dann, Claudio Gentile, Peter Bartlett", "title": "Regret Bound Balancing and Elimination for Model Selection in Bandits\n  and RL", "comments": "57 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML stat.OT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a simple model selection approach for algorithms in stochastic\nbandit and reinforcement learning problems. As opposed to prior work that\n(implicitly) assumes knowledge of the optimal regret, we only require that each\nbase algorithm comes with a candidate regret bound that may or may not hold\nduring all rounds. In each round, our approach plays a base algorithm to keep\nthe candidate regret bounds of all remaining base algorithms balanced, and\neliminates algorithms that violate their candidate bound. We prove that the\ntotal regret of this approach is bounded by the best valid candidate regret\nbound times a multiplicative factor. This factor is reasonably small in several\napplications, including linear bandits and MDPs with nested function classes,\nlinear bandits with unknown misspecification, and LinUCB applied to linear\nbandits with different confidence parameters. We further show that, under a\nsuitable gap-assumption, this factor only scales with the number of base\nalgorithms and not their complexity when the number of rounds is large enough.\nFinally, unlike recent efforts in model selection for linear stochastic\nbandits, our approach is versatile enough to also cover cases where the context\ninformation is generated by an adversarial environment, rather than a\nstochastic one.\n", "versions": [{"version": "v1", "created": "Thu, 24 Dec 2020 00:53:42 GMT"}], "update_date": "2020-12-25", "authors_parsed": [["Pacchiano", "Aldo", ""], ["Dann", "Christoph", ""], ["Gentile", "Claudio", ""], ["Bartlett", "Peter", ""]]}, {"id": "2012.13048", "submitter": "Peter Clark", "authors": "Oyvind Tafjord, Bhavana Dalvi Mishra, Peter Clark", "title": "ProofWriter: Generating Implications, Proofs, and Abductive Statements\n  over Natural Language", "comments": "Findings of ACL 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transformers have been shown to emulate logical deduction over natural\nlanguage theories (logical rules expressed in natural language), reliably\nassigning true/false labels to candidate implications. However, their ability\nto generate implications of a theory has not yet been demonstrated, and methods\nfor reconstructing proofs of answers are imperfect. In this work we show that a\ngenerative model, called ProofWriter, can reliably generate both implications\nof a theory and the natural language proof(s) that support them. In particular,\niterating a 1-step implication generator results in proofs that are highly\nreliable, and represent actual model decisions (rather than post-hoc\nrationalizations). On the RuleTaker dataset, the accuracy of ProofWriter's\nproofs exceed previous methods by +9% absolute, and in a way that generalizes\nto proof depths unseen in training and on out-of-domain problems. We also show\nthat generative techniques can perform a type of abduction with high precision:\nGiven a theory and an unprovable conclusion, identify a missing fact that\nallows the conclusion to be proved, along with a proof. These results\nsignificantly improve the viability of neural methods for systematically\nreasoning over natural language.\n", "versions": [{"version": "v1", "created": "Thu, 24 Dec 2020 00:55:46 GMT"}, {"version": "v2", "created": "Thu, 3 Jun 2021 19:15:08 GMT"}], "update_date": "2021-06-07", "authors_parsed": [["Tafjord", "Oyvind", ""], ["Mishra", "Bhavana Dalvi", ""], ["Clark", "Peter", ""]]}, {"id": "2012.13057", "submitter": "Panagiotis Tsiotras", "authors": "Jaein Lim and Panagiotis Tsiotras", "title": "A Generalized A* Algorithm for Finding Globally Optimal Paths in\n  Weighted Colored Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Both geometric and semantic information of the search space is imperative for\na good plan. We encode those properties in a weighted colored graph (geometric\ninformation in terms of edge weight and semantic information in terms of edge\nand vertex color), and propose a generalized A* to find the shortest path among\nthe set of paths with minimal inclusion of low-ranked color edges. We prove the\ncompleteness and optimality of this Class-Ordered A* (COA*) algorithm with\nrespect to the hereto defined notion of optimality. The utility of COA* is\nnumerically validated in a ternary graph with feasible, infeasible, and unknown\nvertices and edges for the cases of a 2D mobile robot, a 3D robotic arm, and a\n5D robotic arm with limited sensing capabilities. We compare the results of\nCOA* to that of the regular A* algorithm, the latter of which finds the\nshortest path regardless of uncertainty, and we show that the COA* dominates\nthe A* solution in terms of finding less uncertain paths.\n", "versions": [{"version": "v1", "created": "Thu, 24 Dec 2020 01:27:31 GMT"}], "update_date": "2020-12-25", "authors_parsed": [["Lim", "Jaein", ""], ["Tsiotras", "Panagiotis", ""]]}, {"id": "2012.13083", "submitter": "Md Abul Hayat", "authors": "Md Abul Hayat, George Stein, Peter Harrington, Zarija Luki\\'c, Mustafa\n  Mustafa", "title": "Self-Supervised Representation Learning for Astronomical Images", "comments": "The codes, trained models, and data can be found at\n  https://portal.nersc.gov/project/dasrepo/self-supervised-learning-sdss", "journal-ref": null, "doi": null, "report-no": null, "categories": "astro-ph.IM cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sky surveys are the largest data generators in astronomy, making automated\ntools for extracting meaningful scientific information an absolute necessity.\nWe show that, without the need for labels, self-supervised learning recovers\nrepresentations of sky survey images that are semantically useful for a variety\nof scientific tasks. These representations can be directly used as features, or\nfine-tuned, to outperform supervised methods trained only on labeled data. We\napply a contrastive learning framework on multi-band galaxy photometry from the\nSloan Digital Sky Survey (SDSS) to learn image representations. We then use\nthem for galaxy morphology classification, and fine-tune them for photometric\nredshift estimation, using labels from the Galaxy Zoo 2 dataset and SDSS\nspectroscopy. In both downstream tasks, using the same learned representations,\nwe outperform the supervised state-of-the-art results, and we show that our\napproach can achieve the accuracy of supervised models while using 2-4 times\nfewer labels for training.\n", "versions": [{"version": "v1", "created": "Thu, 24 Dec 2020 03:25:36 GMT"}, {"version": "v2", "created": "Thu, 8 Apr 2021 16:06:13 GMT"}], "update_date": "2021-04-09", "authors_parsed": [["Hayat", "Md Abul", ""], ["Stein", "George", ""], ["Harrington", "Peter", ""], ["Luki\u0107", "Zarija", ""], ["Mustafa", "Mustafa", ""]]}, {"id": "2012.13099", "submitter": "Xinran Wei", "authors": "Wenlei Shi, Xinran Wei, Jia Zhang, Xiaoyuan Ni, Arthur Jiang, Jiang\n  Bian, Tie-Yan Liu", "title": "Cooperative Policy Learning with Pre-trained Heterogeneous Observation\n  Representations", "comments": "accepted as an oral paper in AAMAS 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Multi-agent reinforcement learning (MARL) has been increasingly explored to\nlearn the cooperative policy towards maximizing a certain global reward. Many\nexisting studies take advantage of graph neural networks (GNN) in MARL to\npropagate critical collaborative information over the interaction graph, built\nupon inter-connected agents. Nevertheless, the vanilla GNN approach yields\nsubstantial defects in dealing with complex real-world scenarios since the\ngeneric message passing mechanism is ineffective between heterogeneous vertices\nand, moreover, simple message aggregation functions are incapable of accurately\nmodeling the combinational interactions from multiple neighbors. While adopting\ncomplex GNN models with more informative message passing and aggregation\nmechanisms can obviously benefit heterogeneous vertex representations and\ncooperative policy learning, it could, on the other hand, increase the training\ndifficulty of MARL and demand more intense and direct reward signals compared\nto the original global reward. To address these challenges, we propose a new\ncooperative learning framework with pre-trained heterogeneous observation\nrepresentations. Particularly, we employ an encoder-decoder based graph\nattention to learn the intricate interactions and heterogeneous representations\nthat can be more easily leveraged by MARL. Moreover, we design a pre-training\nwith local actor-critic algorithm to ease the difficulty in cooperative policy\nlearning. Extensive experiments over real-world scenarios demonstrate that our\nnew approach can significantly outperform existing MARL baselines as well as\noperational research solutions that are widely-used in industry.\n", "versions": [{"version": "v1", "created": "Thu, 24 Dec 2020 04:52:29 GMT"}], "update_date": "2020-12-25", "authors_parsed": [["Shi", "Wenlei", ""], ["Wei", "Xinran", ""], ["Zhang", "Jia", ""], ["Ni", "Xiaoyuan", ""], ["Jiang", "Arthur", ""], ["Bian", "Jiang", ""], ["Liu", "Tie-Yan", ""]]}, {"id": "2012.13102", "submitter": "Yunqiu Shao", "authors": "Yunqiu Shao, Bulou Liu, Jiaxin Mao, Yiqun Liu, Min Zhang, Shaoping Ma", "title": "THUIR@COLIEE-2020: Leveraging Semantic Understanding and Exact Matching\n  for Legal Case Retrieval and Entailment", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present our methodologies for tackling the challenges of\nlegal case retrieval and entailment in the Competition on Legal Information\nExtraction / Entailment 2020 (COLIEE-2020). We participated in the two case law\ntasks, i.e., the legal case retrieval task and the legal case entailment task.\nTask 1 (the retrieval task) aims to automatically identify supporting cases\nfrom the case law corpus given a new case, and Task 2 (the entailment task) to\nidentify specific paragraphs that entail the decision of a new case in a\nrelevant case. In both tasks, we employed the neural models for semantic\nunderstanding and the traditional retrieval models for exact matching. As a\nresult, our team (TLIR) ranked 2nd among all of the teams in Task 1 and 3rd\namong teams in Task 2. Experimental results suggest that combing models of\nsemantic understanding and exact matching benefits the legal case retrieval\ntask while the legal case entailment task relies more on semantic\nunderstanding.\n", "versions": [{"version": "v1", "created": "Thu, 24 Dec 2020 04:59:45 GMT"}], "update_date": "2020-12-25", "authors_parsed": [["Shao", "Yunqiu", ""], ["Liu", "Bulou", ""], ["Mao", "Jiaxin", ""], ["Liu", "Yiqun", ""], ["Zhang", "Min", ""], ["Ma", "Shaoping", ""]]}, {"id": "2012.13122", "submitter": "Naeha Sharif", "authors": "Naeha Sharif, Mohammed Bennamoun, Wei Liu, Syed Afaq Ali Shah", "title": "SubICap: Towards Subword-informed Image Captioning", "comments": "8 pages", "journal-ref": "Workshop on Applications of Computer Vision (WACV), 2021", "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing Image Captioning (IC) systems model words as atomic units in\ncaptions and are unable to exploit the structural information in the words.\nThis makes representation of rare words very difficult and out-of-vocabulary\nwords impossible. Moreover, to avoid computational complexity, existing IC\nmodels operate over a modest sized vocabulary of frequent words, such that the\nidentity of rare words is lost. In this work we address this common limitation\nof IC systems in dealing with rare words in the corpora. We decompose words\ninto smaller constituent units 'subwords' and represent captions as a sequence\nof subwords instead of words. This helps represent all words in the corpora\nusing a significantly lower subword vocabulary, leading to better parameter\nlearning. Using subword language modeling, our captioning system improves\nvarious metric scores, with a training vocabulary size approximately 90% less\nthan the baseline and various state-of-the-art word-level models. Our\nquantitative and qualitative results and analysis signify the efficacy of our\nproposed approach.\n", "versions": [{"version": "v1", "created": "Thu, 24 Dec 2020 06:10:36 GMT"}], "update_date": "2020-12-25", "authors_parsed": [["Sharif", "Naeha", ""], ["Bennamoun", "Mohammed", ""], ["Liu", "Wei", ""], ["Shah", "Syed Afaq Ali", ""]]}, {"id": "2012.13136", "submitter": "Naeha Sharif", "authors": "Naeha Sharif and Lyndon White and Mohammed Bennamoun and Wei Liu and\n  Syed Afaq Ali Shah", "title": "LCEval: Learned Composite Metric for Caption Evaluation", "comments": "18 pages", "journal-ref": "International Journal of Computer Vision (October 2019)", "doi": "10.1007/s11263-019-01206-z", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic evaluation metrics hold a fundamental importance in the development\nand fine-grained analysis of captioning systems. While current evaluation\nmetrics tend to achieve an acceptable correlation with human judgements at the\nsystem level, they fail to do so at the caption level. In this work, we propose\na neural network-based learned metric to improve the caption-level caption\nevaluation. To get a deeper insight into the parameters which impact a learned\nmetrics performance, this paper investigates the relationship between different\nlinguistic features and the caption-level correlation of the learned metrics.\nWe also compare metrics trained with different training examples to measure the\nvariations in their evaluation. Moreover, we perform a robustness analysis,\nwhich highlights the sensitivity of learned and handcrafted metrics to various\nsentence perturbations. Our empirical analysis shows that our proposed metric\nnot only outperforms the existing metrics in terms of caption-level correlation\nbut it also shows a strong system-level correlation against human assessments.\n", "versions": [{"version": "v1", "created": "Thu, 24 Dec 2020 06:38:24 GMT"}], "update_date": "2020-12-25", "authors_parsed": [["Sharif", "Naeha", ""], ["White", "Lyndon", ""], ["Bennamoun", "Mohammed", ""], ["Liu", "Wei", ""], ["Shah", "Syed Afaq Ali", ""]]}, {"id": "2012.13137", "submitter": "Naeha Sharif", "authors": "Naeha Sharif, Lyndon White, Mohammed Bennamoun, Wei Liu, Syed Afaq Ali\n  Shah", "title": "WEmbSim: A Simple yet Effective Metric for Image Captioning", "comments": "7 pages", "journal-ref": "International Conference on Digital Image Computing: Techniques\n  and Applications (DICTA), 2020", "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The area of automatic image caption evaluation is still undergoing intensive\nresearch to address the needs of generating captions which can meet adequacy\nand fluency requirements. Based on our past attempts at developing highly\nsophisticated learning-based metrics, we have discovered that a simple cosine\nsimilarity measure using the Mean of Word Embeddings(MOWE) of captions can\nactually achieve a surprisingly high performance on unsupervised caption\nevaluation. This inspires our proposed work on an effective metric WEmbSim,\nwhich beats complex measures such as SPICE, CIDEr and WMD at system-level\ncorrelation with human judgments. Moreover, it also achieves the best accuracy\nat matching human consensus scores for caption pairs, against commonly used\nunsupervised methods. Therefore, we believe that WEmbSim sets a new baseline\nfor any complex metric to be justified.\n", "versions": [{"version": "v1", "created": "Thu, 24 Dec 2020 06:39:43 GMT"}], "update_date": "2020-12-25", "authors_parsed": [["Sharif", "Naeha", ""], ["White", "Lyndon", ""], ["Bennamoun", "Mohammed", ""], ["Liu", "Wei", ""], ["Shah", "Syed Afaq Ali", ""]]}, {"id": "2012.13185", "submitter": "Yinya Huang", "authors": "Yinya Huang, Meng Fang, Xunlin Zhan, Qingxing Cao, Xiaodan Liang,\n  Liang Lin", "title": "REM-Net: Recursive Erasure Memory Network for Commonsense Evidence\n  Refinement", "comments": "Accepted by AAAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When answering a question, people often draw upon their rich world knowledge\nin addition to the particular context. While recent works retrieve supporting\nfacts/evidence from commonsense knowledge bases to supply additional\ninformation to each question, there is still ample opportunity to advance it on\nthe quality of the evidence. It is crucial since the quality of the evidence is\nthe key to answering commonsense questions, and even determines the upper bound\non the QA systems performance. In this paper, we propose a recursive erasure\nmemory network (REM-Net) to cope with the quality improvement of evidence. To\naddress this, REM-Net is equipped with a module to refine the evidence by\nrecursively erasing the low-quality evidence that does not explain the question\nanswering. Besides, instead of retrieving evidence from existing knowledge\nbases, REM-Net leverages a pre-trained generative model to generate candidate\nevidence customized for the question. We conduct experiments on two commonsense\nquestion answering datasets, WIQA and CosmosQA. The results demonstrate the\nperformance of REM-Net and show that the refined evidence is explainable.\n", "versions": [{"version": "v1", "created": "Thu, 24 Dec 2020 10:07:32 GMT"}, {"version": "v2", "created": "Sun, 3 Jan 2021 10:48:56 GMT"}, {"version": "v3", "created": "Thu, 25 Mar 2021 12:53:00 GMT"}], "update_date": "2021-03-26", "authors_parsed": [["Huang", "Yinya", ""], ["Fang", "Meng", ""], ["Zhan", "Xunlin", ""], ["Cao", "Qingxing", ""], ["Liang", "Xiaodan", ""], ["Lin", "Liang", ""]]}, {"id": "2012.13204", "submitter": "Nassim Dehouche", "authors": "Nassim Dehouche", "title": "Predicting Seminal Quality with the Dominance-Based Rough Sets Approach", "comments": null, "journal-ref": "ICIC Express Letters Volume 14, Number 7, July 2020", "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The paper relies on the clinical data of a previously published study. We\nidentify two very questionable assumptions of said work, namely confusing\nevidence of absence and absence of evidence, and neglecting the ordinal nature\nof attributes' domains. We then show that using an adequate ordinal methodology\nsuch as the dominance-based rough sets approach (DRSA) can significantly\nimprove the predictive accuracy of the expert system, resulting in almost\ncomplete accuracy for a dataset of 100 instances. Beyond the performance of\nDRSA in solving the diagnosis problem at hand, these results suggest the\ninadequacy and triviality of the underlying dataset. We provide links to open\ndata from the UCI machine learning repository to allow for an easy\nverification/refutation of the claims made in this paper.\n", "versions": [{"version": "v1", "created": "Thu, 24 Dec 2020 11:45:32 GMT"}], "update_date": "2020-12-25", "authors_parsed": [["Dehouche", "Nassim", ""]]}, {"id": "2012.13219", "submitter": "Mustafa Hashmi", "authors": "Ho-Pun Lam and Mustafa Hashmi and Akhil Kumar", "title": "Towards a Formal Framework for Partial Compliance of Business Processes", "comments": "15 page, 4 figures, 2 tables; Under consideration at AICOL 2020,\n  co-located with Jurix", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Binary \"YES-NO\" notions of process compliance are not very helpful to\nmanagers for assessing the operational performance of their company because a\nlarge number of cases fall in the grey area of partial compliance. Hence, it is\nnecessary to have ways to quantify partial compliance in terms of metrics and\nbe able to classify actual cases by assigning a numeric value of compliance to\nthem. In this paper, we formulate an evaluation framework to quantify the level\nof compliance of business processes across different levels of abstraction\n(such as task,trace and process level) and across multiple dimensions of each\ntask (such as temporal, monetary, role-, data-, and quality-related) to provide\nmanagers more useful information about their operations and to help them\nimprove their decision making processes. Our approach can also add social value\nby making social services provided by local, state and federal governments more\nflexible and improving the lives of citizens.\n", "versions": [{"version": "v1", "created": "Thu, 24 Dec 2020 12:38:40 GMT"}], "update_date": "2020-12-25", "authors_parsed": [["Lam", "Ho-Pun", ""], ["Hashmi", "Mustafa", ""], ["Kumar", "Akhil", ""]]}, {"id": "2012.13231", "submitter": "Raul Fernandez Rojas", "authors": "Raul Fernandez Rojas, Julio Romero, Jehu Lopez-Aparicio, Keng-Liang Ou", "title": "Pain Assessment based on fNIRS using Bidirectional LSTMs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Assessing pain in patients unable to speak (also called non-verbal patients)\nis extremely complicated and often is done by clinical judgement. However, this\nmethod is not reliable since patients vital signs can fluctuate significantly\ndue to other underlying medical conditions. No objective diagnosis test exists\nto date that can assist medical practitioners in the diagnosis of pain. In this\nstudy we propose the use of functional near-infrared spectroscopy (fNIRS) and\ndeep learning for the assessment of human pain. The aim of this study is to\nexplore the use deep learning to automatically learn features from fNIRS raw\ndata to reduce the level of subjectivity and domain knowledge required in the\ndesign of hand-crafted features. Four deep learning models were evaluated,\nmultilayer perceptron (MLP), forward and backward long short-term memory\nnet-works (LSTM), and bidirectional LSTM. The results showed that the Bi-LSTM\nmodel achieved the highest accuracy (90.6%)and faster than the other three\nmodels. These results advance knowledge in pain assessment using neuroimaging\nas a method of diagnosis and represent a step closer to developing a\nphysiologically based diagnosis of human pain that will benefit vulnerable\npopulations who cannot self-report pain.\n", "versions": [{"version": "v1", "created": "Thu, 24 Dec 2020 12:55:39 GMT"}, {"version": "v2", "created": "Sun, 27 Dec 2020 13:15:19 GMT"}], "update_date": "2020-12-29", "authors_parsed": [["Rojas", "Raul Fernandez", ""], ["Romero", "Julio", ""], ["Lopez-Aparicio", "Jehu", ""], ["Ou", "Keng-Liang", ""]]}, {"id": "2012.13253", "submitter": "Tal Daniel", "authors": "Tal Daniel and Aviv Tamar", "title": "Soft-IntroVAE: Analyzing and Improving the Introspective Variational\n  Autoencoder", "comments": "CVPR 2021, Extended version. Code and additional information is\n  available on the project website -\n  https://taldatech.github.io/soft-intro-vae-web", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recently introduced introspective variational autoencoder (IntroVAE)\nexhibits outstanding image generations, and allows for amortized inference\nusing an image encoder. The main idea in IntroVAE is to train a VAE\nadversarially, using the VAE encoder to discriminate between generated and real\ndata samples. However, the original IntroVAE loss function relied on a\nparticular hinge-loss formulation that is very hard to stabilize in practice,\nand its theoretical convergence analysis ignored important terms in the loss.\nIn this work, we take a step towards better understanding of the IntroVAE\nmodel, its practical implementation, and its applications. We propose the\nSoft-IntroVAE, a modified IntroVAE that replaces the hinge-loss terms with a\nsmooth exponential loss on generated samples. This change significantly\nimproves training stability, and also enables theoretical analysis of the\ncomplete algorithm. Interestingly, we show that the IntroVAE converges to a\ndistribution that minimizes a sum of KL distance from the data distribution and\nan entropy term. We discuss the implications of this result, and demonstrate\nthat it induces competitive image generation and reconstruction. Finally, we\ndescribe two applications of Soft-IntroVAE to unsupervised image translation\nand out-of-distribution detection, and demonstrate compelling results. Code and\nadditional information is available on the project website --\nhttps://taldatech.github.io/soft-intro-vae-web\n", "versions": [{"version": "v1", "created": "Thu, 24 Dec 2020 13:53:29 GMT"}, {"version": "v2", "created": "Thu, 25 Mar 2021 07:12:51 GMT"}], "update_date": "2021-03-26", "authors_parsed": [["Daniel", "Tal", ""], ["Tamar", "Aviv", ""]]}, {"id": "2012.13293", "submitter": "Margarita Osadchy", "authors": "Danny Keller, Margarita Osadchy, and Orr Dunkelman", "title": "Fuzzy Commitments Offer Insufficient Protection to Biometric Templates\n  Produced by Deep Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this work, we study the protection that fuzzy commitments offer when they\nare applied to facial images, processed by the state of the art deep learning\nfacial recognition systems. We show that while these systems are capable of\nproducing great accuracy, they produce templates of too little entropy. As a\nresult, we present a reconstruction attack that takes a protected template, and\nreconstructs a facial image. The reconstructed facial images greatly resemble\nthe original ones. In the simplest attack scenario, more than 78% of these\nreconstructed templates succeed in unlocking an account (when the system is\nconfigured to 0.1% FAR). Even in the \"hardest\" settings (in which we take a\nreconstructed image from one system and use it in a different system, with\ndifferent feature extraction process) the reconstructed image offers 50 to 120\ntimes higher success rates than the system's FAR.\n", "versions": [{"version": "v1", "created": "Thu, 24 Dec 2020 15:28:33 GMT"}], "update_date": "2020-12-25", "authors_parsed": [["Keller", "Danny", ""], ["Osadchy", "Margarita", ""], ["Dunkelman", "Orr", ""]]}, {"id": "2012.13300", "submitter": "Abhishek Dubey", "authors": "Geoffrey Pettet and Ayan Mukhopadhyay and Mykel Kochenderfer and\n  Abhishek Dubey", "title": "Hierarchical Planning for Resource Allocation in Emergency Response\n  Systems", "comments": "Accepted for publication in the proceedings of the 12th ACM/IEEE\n  International Conference on Cyber-Physical Systems (ICCPS-2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  A classical problem in city-scale cyber-physical systems (CPS) is resource\nallocation under uncertainty. Typically, such problems are modeled as Markov\n(or semi-Markov) decision processes. While online, offline, and decentralized\napproaches have been applied to such problems, they have difficulty scaling to\nlarge decision problems. We present a general approach to hierarchical planning\nthat leverages structure in city-level CPS problems for resource allocation\nunder uncertainty. We use the emergency response as a case study and show how a\nlarge resource allocation problem can be split into smaller problems. We then\ncreate a principled framework for solving the smaller problems and tackling the\ninteraction between them. Finally, we use real-world data from Nashville,\nTennessee, a major metropolitan area in the United States, to validate our\napproach. Our experiments show that the proposed approach outperforms\nstate-of-the-art approaches used in the field of emergency response.\n", "versions": [{"version": "v1", "created": "Thu, 24 Dec 2020 15:55:23 GMT"}, {"version": "v2", "created": "Thu, 4 Mar 2021 03:17:15 GMT"}], "update_date": "2021-03-05", "authors_parsed": [["Pettet", "Geoffrey", ""], ["Mukhopadhyay", "Ayan", ""], ["Kochenderfer", "Mykel", ""], ["Dubey", "Abhishek", ""]]}, {"id": "2012.13315", "submitter": "Ellen Vitercik", "authors": "Maria-Florina Balcan, Tuomas Sandholm, and Ellen Vitercik", "title": "Generalization in portfolio-based algorithm selection", "comments": "AAAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Portfolio-based algorithm selection has seen tremendous practical success\nover the past two decades. This algorithm configuration procedure works by\nfirst selecting a portfolio of diverse algorithm parameter settings, and then,\non a given problem instance, using an algorithm selector to choose a parameter\nsetting from the portfolio with strong predicted performance. Oftentimes, both\nthe portfolio and the algorithm selector are chosen using a training set of\ntypical problem instances from the application domain at hand. In this paper,\nwe provide the first provable guarantees for portfolio-based algorithm\nselection. We analyze how large the training set should be to ensure that the\nresulting algorithm selector's average performance over the training set is\nclose to its future (expected) performance. This involves analyzing three key\nreasons why these two quantities may diverge: 1) the learning-theoretic\ncomplexity of the algorithm selector, 2) the size of the portfolio, and 3) the\nlearning-theoretic complexity of the algorithm's performance as a function of\nits parameters. We introduce an end-to-end learning-theoretic analysis of the\nportfolio construction and algorithm selection together. We prove that if the\nportfolio is large, overfitting is inevitable, even with an extremely simple\nalgorithm selector. With experiments, we illustrate a tradeoff exposed by our\ntheoretical analysis: as we increase the portfolio size, we can hope to include\na well-suited parameter setting for every possible problem instance, but it\nbecomes impossible to avoid overfitting.\n", "versions": [{"version": "v1", "created": "Thu, 24 Dec 2020 16:33:17 GMT"}], "update_date": "2020-12-25", "authors_parsed": [["Balcan", "Maria-Florina", ""], ["Sandholm", "Tuomas", ""], ["Vitercik", "Ellen", ""]]}, {"id": "2012.13321", "submitter": "Hrithwik Shalu", "authors": "Joseph Stember, Hrithwik Shalu", "title": "Unsupervised deep clustering and reinforcement learning can accurately\n  segment MRI brain tumors with very small training sets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Purpose: Lesion segmentation in medical imaging is key to evaluating\ntreatment response. We have recently shown that reinforcement learning can be\napplied to radiological images for lesion localization. Furthermore, we\ndemonstrated that reinforcement learning addresses important limitations of\nsupervised deep learning; namely, it can eliminate the requirement for large\namounts of annotated training data and can provide valuable intuition lacking\nin supervised approaches. However, we did not address the fundamental task of\nlesion/structure-of-interest segmentation. Here we introduce a method combining\nunsupervised deep learning clustering with reinforcement learning to segment\nbrain lesions on MRI.\n  Materials and Methods: We initially clustered images using unsupervised deep\nlearning clustering to generate candidate lesion masks for each MRI image. The\nuser then selected the best mask for each of 10 training images. We then\ntrained a reinforcement learning algorithm to select the masks. We tested the\ncorresponding trained deep Q network on a separate testing set of 10 images.\nFor comparison, we also trained and tested a U-net supervised deep learning\nnetwork on the same set of training/testing images.\n  Results: Whereas the supervised approach quickly overfit the training data\nand predictably performed poorly on the testing set (16% average Dice score),\nthe unsupervised deep clustering and reinforcement learning achieved an average\nDice score of 83%.\n  Conclusion: We have demonstrated a proof-of-principle application of\nunsupervised deep clustering and reinforcement learning to segment brain\ntumors. The approach represents human-allied AI that requires minimal input\nfrom the radiologist without the need for hand-traced annotation.\n", "versions": [{"version": "v1", "created": "Thu, 24 Dec 2020 16:46:45 GMT"}, {"version": "v2", "created": "Fri, 19 Mar 2021 05:32:15 GMT"}], "update_date": "2021-03-22", "authors_parsed": [["Stember", "Joseph", ""], ["Shalu", "Hrithwik", ""]]}, {"id": "2012.13326", "submitter": "Qinghua Liu", "authors": "Qinghua Liu, Zhou Lu", "title": "A Tight Lower Bound for Uniformly Stable Algorithms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Leveraging algorithmic stability to derive sharp generalization bounds is a\nclassic and powerful approach in learning theory. Since Vapnik and Chervonenkis\n[1974] first formalized the idea for analyzing SVMs, it has been utilized to\nstudy many fundamental learning algorithms (e.g., $k$-nearest neighbors [Rogers\nand Wagner, 1978], stochastic gradient method [Hardt et al., 2016], linear\nregression [Maurer, 2017], etc). In a recent line of great works by Feldman and\nVondrak [2018, 2019] as well as Bousquet et al. [2020b], they prove a high\nprobability generalization upper bound of order $\\tilde{\\mathcal{O}}(\\gamma\n+\\frac{L}{\\sqrt{n}})$ for any uniformly $\\gamma$-stable algorithm and\n$L$-bounded loss function. Although much progress was achieved in proving\ngeneralization upper bounds for stable algorithms, our knowledge of lower\nbounds is rather limited. In fact, there is no nontrivial lower bound known\never since the study of uniform stability [Bousquet and Elisseeff, 2002], to\nthe best of our knowledge. In this paper we fill the gap by proving a tight\ngeneralization lower bound of order $\\Omega(\\gamma+\\frac{L}{\\sqrt{n}})$, which\nmatches the best known upper bound up to logarithmic factors\n", "versions": [{"version": "v1", "created": "Thu, 24 Dec 2020 17:01:18 GMT"}, {"version": "v2", "created": "Sun, 24 Jan 2021 22:46:24 GMT"}], "update_date": "2021-01-26", "authors_parsed": [["Liu", "Qinghua", ""], ["Lu", "Zhou", ""]]}, {"id": "2012.13329", "submitter": "Arda Sahiner", "authors": "Arda Sahiner, Tolga Ergen, John Pauly and Mert Pilanci", "title": "Vector-output ReLU Neural Network Problems are Copositive Programs:\n  Convex Analysis of Two Layer Networks and Polynomial-time Algorithms", "comments": "24 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CC stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We describe the convex semi-infinite dual of the two-layer vector-output ReLU\nneural network training problem. This semi-infinite dual admits a finite\ndimensional representation, but its support is over a convex set which is\ndifficult to characterize. In particular, we demonstrate that the non-convex\nneural network training problem is equivalent to a finite-dimensional convex\ncopositive program. Our work is the first to identify this strong connection\nbetween the global optima of neural networks and those of copositive programs.\nWe thus demonstrate how neural networks implicitly attempt to solve copositive\nprograms via semi-nonnegative matrix factorization, and draw key insights from\nthis formulation. We describe the first algorithms for provably finding the\nglobal minimum of the vector output neural network training problem, which are\npolynomial in the number of samples for a fixed data rank, yet exponential in\nthe dimension. However, in the case of convolutional architectures, the\ncomputational complexity is exponential in only the filter size and polynomial\nin all other parameters. We describe the circumstances in which we can find the\nglobal optimum of this neural network training problem exactly with\nsoft-thresholded SVD, and provide a copositive relaxation which is guaranteed\nto be exact for certain classes of problems, and which corresponds with the\nsolution of Stochastic Gradient Descent in practice.\n", "versions": [{"version": "v1", "created": "Thu, 24 Dec 2020 17:03:30 GMT"}], "update_date": "2020-12-25", "authors_parsed": [["Sahiner", "Arda", ""], ["Ergen", "Tolga", ""], ["Pauly", "John", ""], ["Pilanci", "Mert", ""]]}, {"id": "2012.13349", "submitter": "Nicolas Sonnerat", "authors": "Vinod Nair, Sergey Bartunov, Felix Gimeno, Ingrid von Glehn, Pawel\n  Lichocki, Ivan Lobov, Brendan O'Donoghue, Nicolas Sonnerat, Christian\n  Tjandraatmadja, Pengming Wang, Ravichandra Addanki, Tharindi Hapuarachchi,\n  Thomas Keck, James Keeling, Pushmeet Kohli, Ira Ktena, Yujia Li, Oriol\n  Vinyals, Yori Zwols", "title": "Solving Mixed Integer Programs Using Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.AI cs.DM cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mixed Integer Programming (MIP) solvers rely on an array of sophisticated\nheuristics developed with decades of research to solve large-scale MIP\ninstances encountered in practice. Machine learning offers to automatically\nconstruct better heuristics from data by exploiting shared structure among\ninstances in the data. This paper applies learning to the two key sub-tasks of\na MIP solver, generating a high-quality joint variable assignment, and bounding\nthe gap in objective value between that assignment and an optimal one. Our\napproach constructs two corresponding neural network-based components, Neural\nDiving and Neural Branching, to use in a base MIP solver such as SCIP. Neural\nDiving learns a deep neural network to generate multiple partial assignments\nfor its integer variables, and the resulting smaller MIPs for un-assigned\nvariables are solved with SCIP to construct high quality joint assignments.\nNeural Branching learns a deep neural network to make variable selection\ndecisions in branch-and-bound to bound the objective value gap with a small\ntree. This is done by imitating a new variant of Full Strong Branching we\npropose that scales to large instances using GPUs. We evaluate our approach on\nsix diverse real-world datasets, including two Google production datasets and\nMIPLIB, by training separate neural networks on each. Most instances in all the\ndatasets combined have $10^3-10^6$ variables and constraints after presolve,\nwhich is significantly larger than previous learning approaches. Comparing\nsolvers with respect to primal-dual gap averaged over a held-out set of\ninstances, the learning-augmented SCIP is 2x to 10x better on all datasets\nexcept one on which it is $10^5$x better, at large time limits. To the best of\nour knowledge, ours is the first learning approach to demonstrate such large\nimprovements over SCIP on both large-scale real-world application datasets and\nMIPLIB.\n", "versions": [{"version": "v1", "created": "Wed, 23 Dec 2020 09:33:11 GMT"}, {"version": "v2", "created": "Fri, 23 Jul 2021 16:49:39 GMT"}, {"version": "v3", "created": "Thu, 29 Jul 2021 13:41:25 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["Nair", "Vinod", ""], ["Bartunov", "Sergey", ""], ["Gimeno", "Felix", ""], ["von Glehn", "Ingrid", ""], ["Lichocki", "Pawel", ""], ["Lobov", "Ivan", ""], ["O'Donoghue", "Brendan", ""], ["Sonnerat", "Nicolas", ""], ["Tjandraatmadja", "Christian", ""], ["Wang", "Pengming", ""], ["Addanki", "Ravichandra", ""], ["Hapuarachchi", "Tharindi", ""], ["Keck", "Thomas", ""], ["Keeling", "James", ""], ["Kohli", "Pushmeet", ""], ["Ktena", "Ira", ""], ["Li", "Yujia", ""], ["Vinyals", "Oriol", ""], ["Zwols", "Yori", ""]]}, {"id": "2012.13380", "submitter": "Ambedkar Dukkipati", "authors": "Shaarad A. R and Ambedkar Dukkipati", "title": "A Regret bound for Non-stationary Multi-Armed Bandits with Fairness\n  Constraints", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The multi-armed bandits' framework is the most common platform to study\nstrategies for sequential decision-making problems. Recently, the notion of\nfairness has attracted a lot of attention in the machine learning community.\nOne can impose the fairness condition that at any given point of time, even\nduring the learning phase, a poorly performing candidate should not be\npreferred over a better candidate. This fairness constraint is known to be one\nof the most stringent and has been studied in the stochastic multi-armed\nbandits' framework in a stationary setting for which regret bounds have been\nestablished. The main aim of this paper is to study this problem in a\nnon-stationary setting. We present a new algorithm called Fair Upper Confidence\nBound with Exploration Fair-UCBe algorithm for solving a slowly varying\nstochastic $k$-armed bandit problem. With this we present two results: (i)\nFair-UCBe indeed satisfies the above mentioned fairness condition, and (ii) it\nachieves a regret bound of $O\\left(k^{\\frac{3}{2}} T^{1 - \\frac{\\alpha}{2}}\n\\sqrt{\\log T}\\right)$, for some suitable $\\alpha \\in (0, 1)$, where $T$ is the\ntime horizon. This is the first fair algorithm with a sublinear regret bound\napplicable to non-stationary bandits to the best of our knowledge. We show that\nthe performance of our algorithm in the non-stationary case approaches that of\nits stationary counterpart as the variation in the environment tends to zero.\n", "versions": [{"version": "v1", "created": "Thu, 24 Dec 2020 18:12:01 GMT"}], "update_date": "2020-12-25", "authors_parsed": [["R", "Shaarad A.", ""], ["Dukkipati", "Ambedkar", ""]]}, {"id": "2012.13387", "submitter": "Samira Ghodratnama", "authors": "Samira Ghodratnama and Mehrdad Zakershahrak and Fariborz Sobhanmanesh", "title": "Adaptive Summaries: A Personalized Concept-based Summarization Approach\n  by Learning from Users' Feedback", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Exploring the tremendous amount of data efficiently to make a decision,\nsimilar to answering a complicated question, is challenging with many\nreal-world application scenarios. In this context, automatic summarization has\nsubstantial importance as it will provide the foundation for big data analytic.\nTraditional summarization approaches optimize the system to produce a short\nstatic summary that fits all users that do not consider the subjectivity aspect\nof summarization, i.e., what is deemed valuable for different users, making\nthese approaches impractical in real-world use cases. This paper proposes an\ninteractive concept-based summarization model, called Adaptive Summaries, that\nhelps users make their desired summary instead of producing a single inflexible\nsummary. The system learns from users' provided information gradually while\ninteracting with the system by giving feedback in an iterative loop. Users can\nchoose either reject or accept action for selecting a concept being included in\nthe summary with the importance of that concept from users' perspectives and\nconfidence level of their feedback. The proposed approach can guarantee\ninteractive speed to keep the user engaged in the process. Furthermore, it\neliminates the need for reference summaries, which is a challenging issue for\nsummarization tasks. Evaluations show that Adaptive Summaries helps users make\nhigh-quality summaries based on their preferences by maximizing the\nuser-desired content in the generated summaries.\n", "versions": [{"version": "v1", "created": "Thu, 24 Dec 2020 18:27:50 GMT"}], "update_date": "2020-12-25", "authors_parsed": [["Ghodratnama", "Samira", ""], ["Zakershahrak", "Mehrdad", ""], ["Sobhanmanesh", "Fariborz", ""]]}, {"id": "2012.13391", "submitter": "Yixin Nie", "authors": "Yixin Nie, Mary Williamson, Mohit Bansal, Douwe Kiela, Jason Weston", "title": "I like fish, especially dolphins: Addressing Contradictions in Dialogue\n  Modeling", "comments": "15 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To quantify how well natural language understanding models can capture\nconsistency in a general conversation, we introduce the DialoguE COntradiction\nDEtection task (DECODE) and a new conversational dataset containing both\nhuman-human and human-bot contradictory dialogues. We then compare a structured\nutterance-based approach of using pre-trained Transformer models for\ncontradiction detection with the typical unstructured approach. Results reveal\nthat: (i) our newly collected dataset is notably more effective at providing\nsupervision for the dialogue contradiction detection task than existing NLI\ndata including those aimed to cover the dialogue domain; (ii) the structured\nutterance-based approach is more robust and transferable on both analysis and\nout-of-distribution dialogues than its unstructured counterpart. We also show\nthat our best contradiction detection model correlates well with human\njudgments and further provide evidence for its usage in both automatically\nevaluating and improving the consistency of state-of-the-art generative\nchatbots.\n", "versions": [{"version": "v1", "created": "Thu, 24 Dec 2020 18:47:49 GMT"}, {"version": "v2", "created": "Mon, 28 Dec 2020 18:32:21 GMT"}], "update_date": "2020-12-29", "authors_parsed": [["Nie", "Yixin", ""], ["Williamson", "Mary", ""], ["Bansal", "Mohit", ""], ["Kiela", "Douwe", ""], ["Weston", "Jason", ""]]}, {"id": "2012.13400", "submitter": "Athirai A. Irissappane", "authors": "Athirai A. Irissappane, Hanfei Yu, Yankun Shen, Anubha Agrawal, Gray\n  Stanton", "title": "Leveraging GPT-2 for Classifying Spam Reviews with Limited Labeled Data\n  via Adversarial Training", "comments": "arXiv admin note: text overlap with arXiv:1903.08289", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Online reviews are a vital source of information when purchasing a service or\na product. Opinion spammers manipulate these reviews, deliberately altering the\noverall perception of the service. Though there exists a corpus of online\nreviews, only a few have been labeled as spam or non-spam, making it difficult\nto train spam detection models. We propose an adversarial training mechanism\nleveraging the capabilities of Generative Pre-Training 2 (GPT-2) for\nclassifying opinion spam with limited labeled data and a large set of unlabeled\ndata. Experiments on TripAdvisor and YelpZip datasets show that the proposed\nmodel outperforms state-of-the-art techniques by at least 7% in terms of\naccuracy when labeled data is limited. The proposed model can also generate\nsynthetic spam/non-spam reviews with reasonable perplexity, thereby, providing\nadditional labeled data during training.\n", "versions": [{"version": "v1", "created": "Thu, 24 Dec 2020 18:59:51 GMT"}], "update_date": "2020-12-25", "authors_parsed": [["Irissappane", "Athirai A.", ""], ["Yu", "Hanfei", ""], ["Shen", "Yankun", ""], ["Agrawal", "Anubha", ""], ["Stanton", "Gray", ""]]}, {"id": "2012.13421", "submitter": "Laura Giordano", "authors": "Laura Giordano and Daniele Theseider Dupr\\'e", "title": "Weighted defeasible knowledge bases and a multipreference semantics for\n  a deep neural network model", "comments": "23 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we investigate the relationships between a multipreferential\nsemantics for defeasible reasoning in knowledge representation and a deep\nneural network model. Weighted knowledge bases for description logics are\nconsidered under a \"concept-wise\" multipreference semantics. The semantics is\nfurther extended to fuzzy interpretations and exploited to provide a\npreferential interpretation of Multilayer Perceptrons.\n", "versions": [{"version": "v1", "created": "Thu, 24 Dec 2020 19:04:51 GMT"}, {"version": "v2", "created": "Mon, 25 Jan 2021 18:11:00 GMT"}], "update_date": "2021-01-26", "authors_parsed": [["Giordano", "Laura", ""], ["Dupr\u00e9", "Daniele Theseider", ""]]}, {"id": "2012.13431", "submitter": "Aditya Golatkar", "authors": "Aditya Golatkar, Alessandro Achille, Avinash Ravichandran, Marzia\n  Polito, Stefano Soatto", "title": "Mixed-Privacy Forgetting in Deep Networks", "comments": "CVPR 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We show that the influence of a subset of the training samples can be removed\n-- or \"forgotten\" -- from the weights of a network trained on large-scale image\nclassification tasks, and we provide strong computable bounds on the amount of\nremaining information after forgetting. Inspired by real-world applications of\nforgetting techniques, we introduce a novel notion of forgetting in\nmixed-privacy setting, where we know that a \"core\" subset of the training\nsamples does not need to be forgotten. While this variation of the problem is\nconceptually simple, we show that working in this setting significantly\nimproves the accuracy and guarantees of forgetting methods applied to vision\nclassification tasks. Moreover, our method allows efficient removal of all\ninformation contained in non-core data by simply setting to zero a subset of\nthe weights with minimal loss in performance. We achieve these results by\nreplacing a standard deep network with a suitable linear approximation. With\nopportune changes to the network architecture and training procedure, we show\nthat such linear approximation achieves comparable performance to the original\nnetwork and that the forgetting problem becomes quadratic and can be solved\nefficiently even for large models. Unlike previous forgetting methods on deep\nnetworks, ours can achieve close to the state-of-the-art accuracy on large\nscale vision tasks. In particular, we show that our method allows forgetting\nwithout having to trade off the model accuracy.\n", "versions": [{"version": "v1", "created": "Thu, 24 Dec 2020 19:34:56 GMT"}, {"version": "v2", "created": "Sun, 20 Jun 2021 14:59:25 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Golatkar", "Aditya", ""], ["Achille", "Alessandro", ""], ["Ravichandran", "Avinash", ""], ["Polito", "Marzia", ""], ["Soatto", "Stefano", ""]]}, {"id": "2012.13483", "submitter": "Yingfei Wang", "authors": "Yingfei Wang, Inbal Yahav, Balaji Padmanabhan", "title": "Whom to Test? Active Sampling Strategies for Managing COVID-19", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper presents methods to choose individuals to test for infection\nduring a pandemic such as COVID-19, characterized by high contagion and\npresence of asymptomatic carriers. The smart-testing ideas presented here are\nmotivated by active learning and multi-armed bandit techniques in machine\nlearning. Our active sampling method works in conjunction with quarantine\npolicies, can handle different objectives, is dynamic and adaptive in the sense\nthat it continually adapts to changes in real-time data. The bandit algorithm\nuses contact tracing, location-based sampling and random sampling in order to\nselect specific individuals to test. Using a data-driven agent-based model\nsimulating New York City we show that the algorithm samples individuals to test\nin a manner that rapidly traces infected individuals. Experiments also suggest\nthat smart-testing can significantly reduce the death rates as compared to\ncurrent methods such as testing symptomatic individuals with or without contact\ntracing.\n", "versions": [{"version": "v1", "created": "Fri, 25 Dec 2020 02:04:50 GMT"}], "update_date": "2020-12-29", "authors_parsed": [["Wang", "Yingfei", ""], ["Yahav", "Inbal", ""], ["Padmanabhan", "Balaji", ""]]}, {"id": "2012.13490", "submitter": "Khimya Khetarpal", "authors": "Khimya Khetarpal, Matthew Riemer, Irina Rish, Doina Precup", "title": "Towards Continual Reinforcement Learning: A Review and Perspectives", "comments": "Preprint, 52 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this article, we aim to provide a literature review of different\nformulations and approaches to continual reinforcement learning (RL), also\nknown as lifelong or non-stationary RL. We begin by discussing our perspective\non why RL is a natural fit for studying continual learning. We then provide a\ntaxonomy of different continual RL formulations and mathematically characterize\nthe non-stationary dynamics of each setting. We go on to discuss evaluation of\ncontinual RL agents, providing an overview of benchmarks used in the literature\nand important metrics for understanding agent performance. Finally, we\nhighlight open problems and challenges in bridging the gap between the current\nstate of continual RL and findings in neuroscience. While still in its early\ndays, the study of continual RL has the promise to develop better incremental\nreinforcement learners that can function in increasingly realistic applications\nwhere non-stationarity plays a vital role. These include applications such as\nthose in the fields of healthcare, education, logistics, and robotics.\n", "versions": [{"version": "v1", "created": "Fri, 25 Dec 2020 02:35:27 GMT"}], "update_date": "2020-12-29", "authors_parsed": [["Khetarpal", "Khimya", ""], ["Riemer", "Matthew", ""], ["Rish", "Irina", ""], ["Precup", "Doina", ""]]}, {"id": "2012.13493", "submitter": "Chunyuan Li", "authors": "Chunyuan Li, Xiujun Li, Lei Zhang, Baolin Peng, Mingyuan Zhou,\n  Jianfeng Gao", "title": "Self-supervised Pre-training with Hard Examples Improves Visual\n  Representations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Self-supervised pre-training (SSP) employs random image transformations to\ngenerate training data for visual representation learning. In this paper, we\nfirst present a modeling framework that unifies existing SSP methods as\nlearning to predict pseudo-labels. Then, we propose new data augmentation\nmethods of generating training examples whose pseudo-labels are harder to\npredict than those generated via random image transformations. Specifically, we\nuse adversarial training and CutMix to create hard examples (HEXA) to be used\nas augmented views for MoCo-v2 and DeepCluster-v2, leading to two variants\nHEXA_{MoCo} and HEXA_{DCluster}, respectively. In our experiments, we pre-train\nmodels on ImageNet and evaluate them on multiple public benchmarks. Our\nevaluation shows that the two new algorithm variants outperform their original\ncounterparts, and achieve new state-of-the-art on a wide range of tasks where\nlimited task supervision is available for fine-tuning. These results verify\nthat hard examples are instrumental in improving the generalization of the\npre-trained models.\n", "versions": [{"version": "v1", "created": "Fri, 25 Dec 2020 02:44:22 GMT"}, {"version": "v2", "created": "Mon, 4 Jan 2021 01:21:04 GMT"}], "update_date": "2021-01-05", "authors_parsed": [["Li", "Chunyuan", ""], ["Li", "Xiujun", ""], ["Zhang", "Lei", ""], ["Peng", "Baolin", ""], ["Zhou", "Mingyuan", ""], ["Gao", "Jianfeng", ""]]}, {"id": "2012.13529", "submitter": "Xuejiao Zhao", "authors": "Xuejiao Zhao, Huanhuan Chen, Zhenchang Xing, Chunyan Miao", "title": "Brain-inspired Search Engine Assistant based on Knowledge Graph", "comments": "12 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Search engines can quickly response a hyperlink list according to query\nkeywords. However, when a query is complex, developers need to repeatedly\nrefine the search keywords and open a large number of web pages to find and\nsummarize answers. Many research works of question and answering (Q and A)\nsystem attempt to assist search engines by providing simple, accurate and\nunderstandable answers. However, without original semantic contexts, these\nanswers lack explainability, making them difficult for users to trust and\nadopt. In this paper, a brain-inspired search engine assistant named\nDeveloperBot based on knowledge graph is proposed, which aligns to the\ncognitive process of human and has the capacity to answer complex queries with\nexplainability. Specifically, DeveloperBot firstly constructs a multi-layer\nquery graph by splitting a complex multi-constraint query into several ordered\nconstraints. Then it models the constraint reasoning process as subgraph search\nprocess inspired by the spreading activation model of cognitive science. In the\nend, novel features of the subgraph will be extracted for decision-making. The\ncorresponding reasoning subgraph and answer confidence will be derived as\nexplanations. The results of the decision-making demonstrate that DeveloperBot\ncan estimate the answers and answer confidences with high accuracy. We\nimplement a prototype and conduct a user study to evaluate whether and how the\ndirect answers and the explanations provided by DeveloperBot can assist\ndevelopers' information needs.\n", "versions": [{"version": "v1", "created": "Fri, 25 Dec 2020 06:36:11 GMT"}], "update_date": "2020-12-29", "authors_parsed": [["Zhao", "Xuejiao", ""], ["Chen", "Huanhuan", ""], ["Xing", "Zhenchang", ""], ["Miao", "Chunyan", ""]]}, {"id": "2012.13533", "submitter": "Shuai Wang", "authors": "Shanfeng Huang, Shuai Wang, Rui Wang, Miaowen Wen, and Kaibin Huang", "title": "Reconfigurable Intelligent Surface Assisted Mobile Edge Computing with\n  Heterogeneous Learning Tasks", "comments": "30 pages, 8 figures, submitted to IEEE Transactions on Cognitive\n  Communications and Networking", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.AI cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ever-growing popularity and rapid improving of artificial intelligence\n(AI) have raised rethinking on the evolution of wireless networks. Mobile edge\ncomputing (MEC) provides a natural platform for AI applications since it is\nwith rich computation resources to train machine learning (ML) models, as well\nas low-latency access to the data generated by mobile and internet of things\n(IoT) devices. In this paper, we present an infrastructure to perform ML tasks\nat an MEC server with the assistance of a reconfigurable intelligent surface\n(RIS). In contrast to conventional communication systems where the principal\ncriterions are to maximize the throughput, we aim at maximizing the learning\nperformance. Specifically, we minimize the maximum learning error of all\nparticipating users by jointly optimizing transmit power of mobile users,\nbeamforming vectors of the base station (BS), and the phase-shift matrix of the\nRIS. An alternating optimization (AO)-based framework is proposed to optimize\nthe three terms iteratively, where a successive convex approximation\n(SCA)-based algorithm is developed to solve the power allocation problem,\nclosed-form expressions of the beamforming vectors are derived, and an\nalternating direction method of multipliers (ADMM)-based algorithm is designed\ntogether with an error level searching (ELS) framework to effectively solve the\nchallenging nonconvex optimization problem of the phase-shift matrix.\nSimulation results demonstrate significant gains of deploying an RIS and\nvalidate the advantages of our proposed algorithms over various benchmarks.\nLastly, a unified communication-training-inference platform is developed based\non the CARLA platform and the SECOND network, and a use case (3D object\ndetection in autonomous driving) for the proposed scheme is demonstrated on the\ndeveloped platform.\n", "versions": [{"version": "v1", "created": "Fri, 25 Dec 2020 07:08:50 GMT"}], "update_date": "2020-12-29", "authors_parsed": [["Huang", "Shanfeng", ""], ["Wang", "Shuai", ""], ["Wang", "Rui", ""], ["Wen", "Miaowen", ""], ["Huang", "Kaibin", ""]]}, {"id": "2012.13560", "submitter": "Xuli Tang", "authors": "Xuli Tang, Xin Li, Ying Ding, Feicheng Ma", "title": "Understanding Team Collaboration in Artificial Intelligence from the\n  perspective of Geographic Distance", "comments": "Accepted short paper submission to iConference 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper analyzes team collaboration in the field of Artificial\nIntelligence (AI) from the perspective of geographic distance. We obtained\n1,584,175 AI related publications during 1950-2019 from the Microsoft Academic\nGraph. Three latitude-and-longitude-based indicators were employed to quantify\nthe geographic distance of collaborations in AI over time at domestic and\ninternational levels. The results show team collaborations in AI has been more\npopular in the field over time with around 42,000 (38.4%) multiple-affiliation\nAI publications in 2019. The changes in geographic distances of team\ncollaborations indicate the increase of breadth and density for both domestic\nand international collaborations in AI over time. In addition, the United\nStates produced the largest number of single-country and internationally\ncollaborated AI publications, and China has played an important role in\ninternational collaborations in AI after 2010.\n", "versions": [{"version": "v1", "created": "Fri, 25 Dec 2020 11:06:38 GMT"}], "update_date": "2020-12-29", "authors_parsed": [["Tang", "Xuli", ""], ["Li", "Xin", ""], ["Ding", "Ying", ""], ["Ma", "Feicheng", ""]]}, {"id": "2012.13567", "submitter": "Hafez Ghaemi", "authors": "Mahbod Nouri, Faraz Moradi, Hafez Ghaemi, Ali Motie Nasrabadi", "title": "Towards Real-World BCI: CCSPNet, A Compact Subject-Independent Motor\n  Imagery Framework", "comments": "15 pages, 6 figures, 6 tables, 1 algorithm", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE eess.SP", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  A conventional subject-dependent (SD) brain-computer interface (BCI) requires\na complete data-gathering, training, and calibration phase for each user before\nit can be used. In recent years, a number of subject-independent (SI) BCIs have\nbeen developed. However, there are many problems preventing them from being\nused in real-world BCI applications. A weaker performance compared to the\nsubject-dependent (SD) approach, and a relatively large model requiring high\ncomputational power are the most important ones. Therefore, a potential\nreal-world BCI would greatly benefit from a compact low-power\nsubject-independent BCI framework, ready to be used immediately after the user\nputs it on. To move towards this goal, we propose a novel subject-independent\nBCI framework named CCSPNet (Convolutional Common Spatial Pattern Network)\ntrained on the motor imagery (MI) paradigm of a large-scale\nelectroencephalography (EEG) signals database consisting of 21600 trials for 54\nsubjects performing two-class hand-movement MI tasks. The proposed framework\napplies a wavelet kernel convolutional neural network (WKCNN) and a temporal\nconvolutional neural network (TCNN) in order to represent and extract the\ndiverse spectral features of EEG signals. The outputs of the convolutional\nlayers go through a common spatial pattern (CSP) algorithm for spatial feature\nextraction. The number of CSP features is reduced by a dense neural network,\nand the final class label is determined by a linear discriminative analysis\n(LDA) classifier. The CCSPNet framework evaluation results show that it is\npossible to have a low-power compact BCI that achieves both SD and SI\nperformance comparable to complex and computationally expensive.\n", "versions": [{"version": "v1", "created": "Fri, 25 Dec 2020 12:00:47 GMT"}, {"version": "v2", "created": "Sat, 2 Jan 2021 11:07:29 GMT"}, {"version": "v3", "created": "Sat, 10 Apr 2021 19:10:36 GMT"}, {"version": "v4", "created": "Fri, 2 Jul 2021 08:12:12 GMT"}], "update_date": "2021-07-05", "authors_parsed": [["Nouri", "Mahbod", ""], ["Moradi", "Faraz", ""], ["Ghaemi", "Hafez", ""], ["Nasrabadi", "Ali Motie", ""]]}, {"id": "2012.13568", "submitter": "Gang Chen", "authors": "Gang Chen, Maosong Sun, and Yang Liu", "title": "Towards a Universal Continuous Knowledge Base", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In artificial intelligence (AI), knowledge is the information required by an\nintelligent system to accomplish tasks. While traditional knowledge bases use\ndiscrete, symbolic representations, detecting knowledge encoded in the\ncontinuous representations learned from data has received increasing attention\nrecently. In this work, we propose a method for building a continuous knowledge\nbase (CKB) that can store knowledge imported from multiple, diverse neural\nnetworks. The key idea of our approach is to define an interface for each\nneural network and cast knowledge transferring as a function simulation\nproblem. Experiments on text classification show promising results: the CKB\nimports knowledge from a single model and then exports the knowledge to a new\nmodel, achieving comparable performance with the original model. More\ninteresting, we import the knowledge from multiple models to the knowledge\nbase, from which the fused knowledge is exported back to a single model,\nachieving a higher accuracy than the original model. With the CKB, it is also\neasy to achieve knowledge distillation and transfer learning. Our work opens\nthe door to building a universal continuous knowledge base to collect, store,\nand organize all continuous knowledge encoded in various neural networks\ntrained for different AI tasks.\n", "versions": [{"version": "v1", "created": "Fri, 25 Dec 2020 12:27:44 GMT"}, {"version": "v2", "created": "Sat, 17 Apr 2021 14:10:33 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Chen", "Gang", ""], ["Sun", "Maosong", ""], ["Liu", "Yang", ""]]}, {"id": "2012.13569", "submitter": "Yan Gao", "authors": "Yan Gao, Jiafeng Guo, Yanyan Lan, Huaming Liao", "title": "Dynamic-K Recommendation with Personalized Decision Boundary", "comments": "12 pages", "journal-ref": "CCIR 2017", "doi": null, "report-no": null, "categories": "cs.IR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we investigate the recommendation task in the most common\nscenario with implicit feedback (e.g., clicks, purchases). State-of-the-art\nmethods in this direction usually cast the problem as to learn a personalized\nranking on a set of items (e.g., webpages, products). The top-N results are\nthen provided to users as recommendations, where the N is usually a fixed\nnumber pre-defined by the system according to some heuristic criteria (e.g.,\npage size, screen size). There is one major assumption underlying this\nfixed-number recommendation scheme, i.e., there are always sufficient relevant\nitems to users' preferences. Unfortunately, this assumption may not always hold\nin real-world scenarios. In some applications, there might be very limited\ncandidate items to recommend, and some users may have very high relevance\nrequirement in recommendation. In this way, even the top-1 ranked item may not\nbe relevant to a user's preference. Therefore, we argue that it is critical to\nprovide a dynamic-K recommendation, where the K should be different with\nrespect to the candidate item set and the target user. We formulate this\ndynamic-K recommendation task as a joint learning problem with both ranking and\nclassification objectives. The ranking objective is the same as existing\nmethods, i.e., to create a ranking list of items according to users' interests.\nThe classification objective is unique in this work, which aims to learn a\npersonalized decision boundary to differentiate the relevant items from\nirrelevant items. Based on these ideas, we extend two state-of-the-art\nranking-based recommendation methods, i.e., BPRMF and HRM, to the corresponding\ndynamic-K versions, namely DK-BPRMF and DK-HRM. Our experimental results on two\ndatasets show that the dynamic-K models are more effective than the original\nfixed-N recommendation methods.\n", "versions": [{"version": "v1", "created": "Fri, 25 Dec 2020 13:02:57 GMT"}], "update_date": "2020-12-29", "authors_parsed": [["Gao", "Yan", ""], ["Guo", "Jiafeng", ""], ["Lan", "Yanyan", ""], ["Liao", "Huaming", ""]]}, {"id": "2012.13573", "submitter": "Fengxiang He", "authors": "Fengxiang He, Shaopeng Fu, Bohan Wang, Dacheng Tao", "title": "Robustness, Privacy, and Generalization of Adversarial Training", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial training can considerably robustify deep neural networks to\nresist adversarial attacks. However, some works suggested that adversarial\ntraining might comprise the privacy-preserving and generalization abilities.\nThis paper establishes and quantifies the privacy-robustness trade-off and\ngeneralization-robustness trade-off in adversarial training from both\ntheoretical and empirical aspects. We first define a notion, {\\it robustified\nintensity} to measure the robustness of an adversarial training algorithm. This\nmeasure can be approximate empirically by an asymptotically consistent\nempirical estimator, {\\it empirical robustified intensity}. Based on the\nrobustified intensity, we prove that (1) adversarial training is $(\\varepsilon,\n\\delta)$-differentially private, where the magnitude of the differential\nprivacy has a positive correlation with the robustified intensity; and (2) the\ngeneralization error of adversarial training can be upper bounded by an\n$\\mathcal O(\\sqrt{\\log N}/N)$ on-average bound and an $\\mathcal O(1/\\sqrt{N})$\nhigh-probability bound, both of which have positive correlations with the\nrobustified intensity. Additionally, our generalization bounds do not\nexplicitly rely on the parameter size which would be prohibitively large in\ndeep learning. Systematic experiments on standard datasets, CIFAR-10 and\nCIFAR-100, are in full agreement with our theories. The source code package is\navailable at \\url{https://github.com/fshp971/RPG}.\n", "versions": [{"version": "v1", "created": "Fri, 25 Dec 2020 13:35:02 GMT"}], "update_date": "2020-12-29", "authors_parsed": [["He", "Fengxiang", ""], ["Fu", "Shaopeng", ""], ["Wang", "Bohan", ""], ["Tao", "Dacheng", ""]]}, {"id": "2012.13574", "submitter": "Margarita Rebolledo", "authors": "Margarita Rebolledo, Sowmya Chandrasekaran, and Thomas\n  Bartz-Beielstein", "title": "Technical Report: Flushing Strategies in Drinking Water Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.NE", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Drinking water supply and distribution systems are critical infrastructure\nthat has to be well maintained for the safety of the public. One important tool\nin the maintenance of water distribution systems (WDS) is flushing. Flushing is\na process carried out in a periodic fashion to clean sediments and other\ncontaminants in the water pipes. Given the different topographies, water\ncomposition and supply demand between WDS no single flushing strategy is\nsuitable for all of them. In this report a non-exhaustive overview of\noptimization methods for flushing in WDS is given. Implementation of\noptimization methods for the flushing procedure and the flushing planing are\npresented. Suggestions are given as a possible option to optimise existing\nflushing planing frameworks.\n", "versions": [{"version": "v1", "created": "Fri, 25 Dec 2020 13:37:06 GMT"}], "update_date": "2020-12-29", "authors_parsed": [["Rebolledo", "Margarita", ""], ["Chandrasekaran", "Sowmya", ""], ["Bartz-Beielstein", "Thomas", ""]]}, {"id": "2012.13577", "submitter": "Jiangjie Chen", "authors": "Jiangjie Chen, Qiaoben Bao, Jiaze Chen, Changzhi Sun, Hao Zhou,\n  Yanghua Xiao, Lei Li", "title": "LOREN: Logic Enhanced Neural Reasoning for Fact Verification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a natural language statement, how to verify whether it is supported,\nrefuted, or unknown according to a large-scale knowledge source like Wikipedia?\nExisting neural-network-based methods often regard a sentence as a whole. While\nwe argue that it is beneficial to decompose a statement into multiple\nverifiable logical points. In this paper, we propose LOREN, a novel approach\nfor fact verification that integrates both Logic guided Reasoning and Neural\ninference. The key insight of LOREN is that it decomposes a statement into\nmultiple reasoning units around the central phrases. Instead of directly\nvalidating a single reasoning unit, LOREN turns it into a question-answering\ntask and calculates the confidence of every single hypothesis using neural\nnetworks in the embedding space. They are aggregated to make a final prediction\nusing a neural joint reasoner guided by a set of three-valued logic rules.\nLOREN enjoys the additional merit of interpretability -- it is easy to explain\nhow it reaches certain results with intermediate results and why it makes\nmistakes. We evaluate LOREN on FEVER, a public benchmark for fact verification.\nExperiments show that our proposed LOREN outperforms other previously published\nmethods and achieves 73.43% of the FEVER score.\n", "versions": [{"version": "v1", "created": "Fri, 25 Dec 2020 13:57:04 GMT"}], "update_date": "2020-12-29", "authors_parsed": [["Chen", "Jiangjie", ""], ["Bao", "Qiaoben", ""], ["Chen", "Jiaze", ""], ["Sun", "Changzhi", ""], ["Zhou", "Hao", ""], ["Xiao", "Yanghua", ""], ["Li", "Lei", ""]]}, {"id": "2012.13628", "submitter": "Ahmadreza Jeddi", "authors": "Ahmadreza Jeddi, Mohammad Javad Shafiee, Alexander Wong", "title": "A Simple Fine-tuning Is All You Need: Towards Robust Deep Learning Via\n  Adversarial Fine-tuning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.NE", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Adversarial Training (AT) with Projected Gradient Descent (PGD) is an\neffective approach for improving the robustness of the deep neural networks.\nHowever, PGD AT has been shown to suffer from two main limitations: i) high\ncomputational cost, and ii) extreme overfitting during training that leads to\nreduction in model generalization. While the effect of factors such as model\ncapacity and scale of training data on adversarial robustness have been\nextensively studied, little attention has been paid to the effect of a very\nimportant parameter in every network optimization on adversarial robustness:\nthe learning rate. In particular, we hypothesize that effective learning rate\nscheduling during adversarial training can significantly reduce the overfitting\nissue, to a degree where one does not even need to adversarially train a model\nfrom scratch but can instead simply adversarially fine-tune a pre-trained\nmodel. Motivated by this hypothesis, we propose a simple yet very effective\nadversarial fine-tuning approach based on a $\\textit{slow start, fast decay}$\nlearning rate scheduling strategy which not only significantly decreases\ncomputational cost required, but also greatly improves the accuracy and\nrobustness of a deep neural network. Experimental results show that the\nproposed adversarial fine-tuning approach outperforms the state-of-the-art\nmethods on CIFAR-10, CIFAR-100 and ImageNet datasets in both test accuracy and\nthe robustness, while reducing the computational cost by 8-10$\\times$.\nFurthermore, a very important benefit of the proposed adversarial fine-tuning\napproach is that it enables the ability to improve the robustness of any\npre-trained deep neural network without needing to train the model from\nscratch, which to the best of the authors' knowledge has not been previously\ndemonstrated in research literature.\n", "versions": [{"version": "v1", "created": "Fri, 25 Dec 2020 20:50:15 GMT"}], "update_date": "2020-12-29", "authors_parsed": [["Jeddi", "Ahmadreza", ""], ["Shafiee", "Mohammad Javad", ""], ["Wong", "Alexander", ""]]}, {"id": "2012.13635", "submitter": "Samy Badreddine", "authors": "Samy Badreddine and Artur d'Avila Garcez and Luciano Serafini and\n  Michael Spranger", "title": "Logic Tensor Networks", "comments": "68 pages, 28 figures, 6 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Artificial Intelligence agents are required to learn from their surroundings\nand to reason about the knowledge that has been learned in order to make\ndecisions. While state-of-the-art learning from data typically uses\nsub-symbolic distributed representations, reasoning is normally useful at a\nhigher level of abstraction with the use of a first-order logic language for\nknowledge representation. As a result, attempts at combining symbolic AI and\nneural computation into neural-symbolic systems have been on the increase. In\nthis paper, we present Logic Tensor Networks (LTN), a neurosymbolic formalism\nand computational model that supports learning and reasoning through the\nintroduction of a many-valued, end-to-end differentiable first-order logic\ncalled Real Logic as a representation language for deep learning. We show that\nLTN provides a uniform language for the specification and the computation of\nseveral AI tasks such as data clustering, multi-label classification,\nrelational learning, query answering, semi-supervised learning, regression and\nembedding learning. We implement and illustrate each of the above tasks with a\nnumber of simple explanatory examples using TensorFlow 2. Keywords:\nNeurosymbolic AI, Deep Learning and Reasoning, Many-valued Logic.\n", "versions": [{"version": "v1", "created": "Fri, 25 Dec 2020 22:30:18 GMT"}, {"version": "v2", "created": "Thu, 14 Jan 2021 07:37:47 GMT"}, {"version": "v3", "created": "Sun, 17 Jan 2021 01:28:44 GMT"}], "update_date": "2021-01-19", "authors_parsed": [["Badreddine", "Samy", ""], ["Garcez", "Artur d'Avila", ""], ["Serafini", "Luciano", ""], ["Spranger", "Michael", ""]]}, {"id": "2012.13637", "submitter": "Yue Hu", "authors": "Yue Hu, Ao Qu, Dan Work", "title": "Graph Convolutional Networks for traffic anomaly", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Event detection has been an important task in transportation, whose task is\nto detect points in time when large events disrupts a large portion of the\nurban traffic network. Travel information {Origin-Destination} (OD) matrix data\nby map service vendors has large potential to give us insights to discover\nhistoric patterns and distinguish anomalies. However, to fully capture the\nspatial and temporal traffic patterns remains a challenge, yet serves a crucial\nrole for effective anomaly detection. Meanwhile, existing anomaly detection\nmethods have not well-addressed the extreme data sparsity and high-dimension\nchallenges, which are common in OD matrix datasets. To tackle these challenges,\nwe formulate the problem in a novel way, as detecting anomalies in a set of\ndirected weighted graphs representing the traffic conditions at each time\ninterval. We further propose \\textit{Context augmented Graph Autoencoder}\n(\\textbf{Con-GAE }), that leverages graph embedding and context embedding\ntechniques to capture the spatial traffic network patterns while working around\nthe data sparsity and high-dimensionality issue. Con-GAE adopts an autoencoder\nframework and detect anomalies via semi-supervised learning. Extensive\nexperiments show that our method can achieve up can achieve a 0.1-0.4\nimprovements of the area under the curve (AUC) score over state-of-art anomaly\ndetection baselines, when applied on several real-world large scale OD matrix\ndatasets.\n", "versions": [{"version": "v1", "created": "Fri, 25 Dec 2020 22:36:22 GMT"}], "update_date": "2020-12-29", "authors_parsed": [["Hu", "Yue", ""], ["Qu", "Ao", ""], ["Work", "Dan", ""]]}, {"id": "2012.13664", "submitter": "Bram Van Berlo", "authors": "Bram van Berlo, Amany Elkelany, Tanir Ozcelebi, Nirvana Meratnia", "title": "Millimeter Wave Sensing: A Review of Application Pipelines and Building\n  Blocks", "comments": "36 pages, submitted to IEEE Sensors Journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The increasing bandwidth requirement of new wireless applications has lead to\nstandardization of the millimeter wave spectrum for high-speed wireless\ncommunication. The millimeter wave spectrum is part of 5G and covers\nfrequencies between 30 and 300 GHz corresponding to wavelengths ranging from 10\nto 1 mm. Although millimeter wave is often considered as a communication\nmedium, it has also proved to be an excellent 'sensor', thanks to its narrow\nbeams, operation across a wide bandwidth, and interaction with atmospheric\nconstituents. In this paper, which is to the best of our knowledge the first\nreview that completely covers millimeter wave sensing application pipelines, we\nprovide a comprehensive overview and analysis of different basic application\npipeline building blocks, including hardware, algorithms, analytical models,\nand model evaluation techniques. The review also provides a taxonomy that\nhighlights different millimeter wave sensing application domains. By performing\na thorough analysis, complying with the systematic literature review\nmethodology and reviewing 165 papers, we not only extend previous\ninvestigations focused only on communication aspects of the millimeter wave\ntechnology and using millimeter wave technology for active imaging, but also\nhighlight scientific and technological challenges and trends, and provide a\nfuture perspective for applications of millimeter wave as a sensing technology.\n", "versions": [{"version": "v1", "created": "Sat, 26 Dec 2020 02:41:33 GMT"}], "update_date": "2020-12-29", "authors_parsed": [["van Berlo", "Bram", ""], ["Elkelany", "Amany", ""], ["Ozcelebi", "Tanir", ""], ["Meratnia", "Nirvana", ""]]}, {"id": "2012.13666", "submitter": "Arman Haghanifar", "authors": "Arman Haghanifar, Mahdiyar Molahasani Majdabadi, Seok-Bum Ko", "title": "PaXNet: Dental Caries Detection in Panoramic X-ray using Ensemble\n  Transfer Learning and Capsule Classifier", "comments": "14 pages, 10 figures, 7 tables, 46 references", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Dental caries is one of the most chronic diseases involving the majority of\nthe population during their lifetime. Caries lesions are typically diagnosed by\nradiologists relying only on their visual inspection to detect via dental\nx-rays. In many cases, dental caries is hard to identify using x-rays and can\nbe misinterpreted as shadows due to different reasons such as low image\nquality. Hence, developing a decision support system for caries detection has\nbeen a topic of interest in recent years. Here, we propose an automatic\ndiagnosis system to detect dental caries in Panoramic images for the first\ntime, to the best of authors' knowledge. The proposed model benefits from\nvarious pretrained deep learning models through transfer learning to extract\nrelevant features from x-rays and uses a capsule network to draw prediction\nresults. On a dataset of 470 Panoramic images used for features extraction,\nincluding 240 labeled images for classification, our model achieved an accuracy\nscore of 86.05\\% on the test set. The obtained score demonstrates acceptable\ndetection performance and an increase in caries detection speed, as long as the\nchallenges of using Panoramic x-rays of real patients are taken into account.\nAmong images with caries lesions in the test set, our model acquired recall\nscores of 69.44\\% and 90.52\\% for mild and severe ones, confirming the fact\nthat severe caries spots are more straightforward to detect and efficient mild\ncaries detection needs a more robust and larger dataset. Considering the\nnovelty of current research study as using Panoramic images, this work is a\nstep towards developing a fully automated efficient decision support system to\nassist domain experts.\n", "versions": [{"version": "v1", "created": "Sat, 26 Dec 2020 03:00:35 GMT"}], "update_date": "2020-12-29", "authors_parsed": [["Haghanifar", "Arman", ""], ["Majdabadi", "Mahdiyar Molahasani", ""], ["Ko", "Seok-Bum", ""]]}, {"id": "2012.13675", "submitter": "Soroush Vosoughi Dr", "authors": "Neeti Pokhriyal, Abenezer Dara, Benjamin Valentino, Soroush Vosoughi", "title": "Social media data reveals signal for public consumer perceptions", "comments": "In Proceedings of the ACM International Conference on AI in Finance\n  (ICAIF '20)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.AI cs.CL", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Researchers have used social media data to estimate various macroeconomic\nindicators about public behaviors, mostly as a way to reduce surveying costs.\nOne of the most widely cited economic indicator is consumer confidence index\n(CCI). Numerous studies in the past have focused on using social media,\nespecially Twitter data, to predict CCI. However, the strong correlations\ndisappeared when those models were tested with newer data according to a recent\ncomprehensive survey. In this work, we revisit this problem of assessing the\ntrue potential of using social media data to measure CCI, by proposing a robust\nnon-parametric Bayesian modeling framework grounded in Gaussian Process\nRegression (which provides both an estimate and an uncertainty associated with\nit). Integral to our framework is a principled experimentation methodology that\ndemonstrates how digital data can be employed to reduce the frequency of\nsurveys, and thus periodic polling would be needed only to calibrate our model.\nVia extensive experimentation we show how the choice of different\nmicro-decisions, such as the smoothing interval, various types of lags etc.\nhave an important bearing on the results. By using decadal data (2008-2019)\nfrom Reddit, we show that both monthly and daily estimates of CCI can, indeed,\nbe reliably estimated at least several months in advance, and that our model\nestimates are far superior to those generated by the existing methods.\n", "versions": [{"version": "v1", "created": "Sat, 26 Dec 2020 03:58:20 GMT"}], "update_date": "2020-12-29", "authors_parsed": [["Pokhriyal", "Neeti", ""], ["Dara", "Abenezer", ""], ["Valentino", "Benjamin", ""], ["Vosoughi", "Soroush", ""]]}, {"id": "2012.13676", "submitter": "Yibo Hu", "authors": "Yibo Hu, Yuzhe Ou, Xujiang Zhao, Jin-Hee Cho, Feng Chen", "title": "Multidimensional Uncertainty-Aware Evidential Neural Networks", "comments": "AAAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditional deep neural networks (NNs) have significantly contributed to the\nstate-of-the-art performance in the task of classification under various\napplication domains. However, NNs have not considered inherent uncertainty in\ndata associated with the class probabilities where misclassification under\nuncertainty may easily introduce high risk in decision making in real-world\ncontexts (e.g., misclassification of objects in roads leads to serious\naccidents). Unlike Bayesian NN that indirectly infer uncertainty through weight\nuncertainties, evidential NNs (ENNs) have been recently proposed to explicitly\nmodel the uncertainty of class probabilities and use them for classification\ntasks. An ENN offers the formulation of the predictions of NNs as subjective\nopinions and learns the function by collecting an amount of evidence that can\nform the subjective opinions by a deterministic NN from data. However, the ENN\nis trained as a black box without explicitly considering inherent uncertainty\nin data with their different root causes, such as vacuity (i.e., uncertainty\ndue to a lack of evidence) or dissonance (i.e., uncertainty due to conflicting\nevidence). By considering the multidimensional uncertainty, we proposed a novel\nuncertainty-aware evidential NN called WGAN-ENN (WENN) for solving an\nout-of-distribution (OOD) detection problem. We took a hybrid approach that\ncombines Wasserstein Generative Adversarial Network (WGAN) with ENNs to jointly\ntrain a model with prior knowledge of a certain class, which has high vacuity\nfor OOD samples. Via extensive empirical experiments based on both synthetic\nand real-world datasets, we demonstrated that the estimation of uncertainty by\nWENN can significantly help distinguish OOD samples from boundary samples. WENN\noutperformed in OOD detection when compared with other competitive\ncounterparts.\n", "versions": [{"version": "v1", "created": "Sat, 26 Dec 2020 04:28:56 GMT"}, {"version": "v2", "created": "Mon, 3 May 2021 21:05:22 GMT"}], "update_date": "2021-05-05", "authors_parsed": [["Hu", "Yibo", ""], ["Ou", "Yuzhe", ""], ["Zhao", "Xujiang", ""], ["Cho", "Jin-Hee", ""], ["Chen", "Feng", ""]]}, {"id": "2012.13677", "submitter": "Song-Kyoo Amang Kim Ph.D.", "authors": "Song-Kyoo (Amang) Kim", "title": "Toward Compact Data from Big Data", "comments": "This paper has been accepted in the 2020 IEEE-ICITIS Conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.AI cs.LG stat.AP", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Bigdata is a dataset of which size is beyond the ability of handling a\nvaluable raw material that can be refined and distilled into valuable specific\ninsights. Compact data is a method that optimizes the big dataset that gives\nbest assets without handling complex bigdata. The compact dataset contains the\nmaximum knowledge patterns at fine grained level for effective and personalized\nutilization of bigdata systems without bigdata. The compact data method is a\ntailor-made design which depends on problem situations. Various compact data\ntechniques have been demonstrated into various data-driven research area in the\npaper.\n", "versions": [{"version": "v1", "created": "Sat, 26 Dec 2020 04:45:40 GMT"}], "update_date": "2020-12-29", "authors_parsed": [["Song-Kyoo", "", "", "Amang"], ["Kim", "", ""]]}, {"id": "2012.13682", "submitter": "Qiang He", "authors": "Qiang He, Xinwen Hou", "title": "POPO: Pessimistic Offline Policy Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Offline reinforcement learning (RL), also known as batch RL, aims to optimize\npolicy from a large pre-recorded dataset without interaction with the\nenvironment. This setting offers the promise of utilizing diverse,\npre-collected datasets to obtain policies without costly, risky, active\nexploration. However, commonly used off-policy algorithms based on Q-learning\nor actor-critic perform poorly when learning from a static dataset. In this\nwork, we study why off-policy RL methods fail to learn in offline setting from\nthe value function view, and we propose a novel offline RL algorithm that we\ncall Pessimistic Offline Policy Optimization (POPO), which learns a pessimistic\nvalue function to get a strong policy. We find that POPO performs surprisingly\nwell and scales to tasks with high-dimensional state and action space,\ncomparing or outperforming several state-of-the-art offline RL algorithms on\nbenchmark tasks.\n", "versions": [{"version": "v1", "created": "Sat, 26 Dec 2020 06:24:34 GMT"}, {"version": "v2", "created": "Mon, 4 Jan 2021 03:43:14 GMT"}], "update_date": "2021-01-05", "authors_parsed": [["He", "Qiang", ""], ["Hou", "Xinwen", ""]]}, {"id": "2012.13744", "submitter": "Ryoichi Takase", "authors": "Ryoichi Takase, Nobuyuki Yoshikawa, Toshisada Mariyama, and Takeshi\n  Tsuchiya", "title": "Stability-Certified Reinforcement Learning via Spectral Normalization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this article, two types of methods from different perspectives based on\nspectral normalization are described for ensuring the stability of the system\ncontrolled by a neural network. The first one is that the L2 gain of the\nfeedback system is bounded less than 1 to satisfy the stability condition\nderived from the small-gain theorem. While explicitly including the stability\ncondition, the first method may provide an insufficient performance on the\nneural network controller due to its strict stability condition. To overcome\nthis difficulty, the second one is proposed, which improves the performance\nwhile ensuring the local stability with a larger region of attraction. In the\nsecond method, the stability is ensured by solving linear matrix inequalities\nafter training the neural network controller. The spectral normalization\nproposed in this article improves the feasibility of the a-posteriori stability\ntest by constructing tighter local sectors. The numerical experiments show that\nthe second method provides enough performance compared with the first one while\nensuring enough stability compared with the existing reinforcement learning\nalgorithms.\n", "versions": [{"version": "v1", "created": "Sat, 26 Dec 2020 14:26:24 GMT"}], "update_date": "2020-12-29", "authors_parsed": [["Takase", "Ryoichi", ""], ["Yoshikawa", "Nobuyuki", ""], ["Mariyama", "Toshisada", ""], ["Tsuchiya", "Takeshi", ""]]}, {"id": "2012.13760", "submitter": "Wenjie Li", "authors": "Wenjie Li, Zhanyu Wang, Yichen Zhang, Guang Cheng", "title": "Variance Reduction on Adaptive Stochastic Mirror Descent", "comments": "NeurIPS 2020 OPT workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we study the idea of variance reduction applied to adaptive\nstochastic mirror descent algorithms in the nonsmooth nonconvex finite-sum\noptimization problems. We propose a simple yet generalized adaptive mirror\ndescent algorithm with variance reduction named SVRAMD and provide its\nconvergence analysis in different settings. We prove that variance reduction\nreduces the SFO complexity of most adaptive mirror descent algorithms and\naccelerates their convergence. In particular, our general theory implies that\nvariance reduction can be applied to algorithms using time-varying step sizes\nand self-adaptive algorithms such as AdaGrad and RMSProp. Moreover, the\nconvergence rates of SVRAMD recover the best existing rates of non-adaptive\nvariance reduced mirror descent algorithms. We check the validity of our claims\nusing experiments in deep learning.\n", "versions": [{"version": "v1", "created": "Sat, 26 Dec 2020 15:15:51 GMT"}, {"version": "v2", "created": "Mon, 19 Apr 2021 17:19:41 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Li", "Wenjie", ""], ["Wang", "Zhanyu", ""], ["Zhang", "Yichen", ""], ["Cheng", "Guang", ""]]}, {"id": "2012.13779", "submitter": "Ismael Tito Freire Gonz\\'alez", "authors": "Ismael T. Freire, Adri\\'an F. Amil, Vasiliki Vouloutsi, Paul F.M.J.\n  Verschure", "title": "Towards sample-efficient episodic control with DAC-ML", "comments": "8 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI q-bio.NC stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The sample-inefficiency problem in Artificial Intelligence refers to the\ninability of current Deep Reinforcement Learning models to optimize action\npolicies within a small number of episodes. Recent studies have tried to\novercome this limitation by adding memory systems and architectural biases to\nimprove learning speed, such as in Episodic Reinforcement Learning. However,\ndespite achieving incremental improvements, their performance is still not\ncomparable to how humans learn behavioral policies. In this paper, we\ncapitalize on the design principles of the Distributed Adaptive Control (DAC)\ntheory of mind and brain to build a novel cognitive architecture (DAC-ML) that,\nby incorporating a hippocampus-inspired sequential memory system, can rapidly\nconverge to effective action policies that maximize reward acquisition in a\nchallenging foraging task.\n", "versions": [{"version": "v1", "created": "Sat, 26 Dec 2020 16:38:08 GMT"}], "update_date": "2020-12-29", "authors_parsed": [["Freire", "Ismael T.", ""], ["Amil", "Adri\u00e1n F.", ""], ["Vouloutsi", "Vasiliki", ""], ["Verschure", "Paul F. M. J.", ""]]}, {"id": "2012.13798", "submitter": "Manuele Leonelli", "authors": "Federico Carli, Manuele Leonelli, Gherardo Varando", "title": "A new class of generative classifiers based on staged tree models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Generative models for classification use the joint probability distribution\nof the class variable and the features to construct a decision rule. Among\ngenerative models, Bayesian networks and naive Bayes classifiers are the most\ncommonly used and provide a clear graphical representation of the relationship\namong all variables. However, these have the disadvantage of highly restricting\nthe type of relationships that could exist, by not allowing for\ncontext-specific independences. Here we introduce a new class of generative\nclassifiers, called staged tree classifiers, which formally account for\ncontext-specific independence. They are constructed by a partitioning of the\nvertices of an event tree from which conditional independence can be formally\nread. The naive staged tree classifier is also defined, which extends the\nclassic naive Bayes classifier whilst retaining the same complexity. An\nextensive simulation study shows that the classification accuracy of staged\ntree classifiers is competitive with those of state-of-the-art classifiers. An\napplied analysis to predict the fate of the passengers of the Titanic\nhighlights the insights that the new class of generative classifiers can give.\n", "versions": [{"version": "v1", "created": "Sat, 26 Dec 2020 19:30:35 GMT"}], "update_date": "2020-12-29", "authors_parsed": [["Carli", "Federico", ""], ["Leonelli", "Manuele", ""], ["Varando", "Gherardo", ""]]}, {"id": "2012.13801", "submitter": "Pu Zhao", "authors": "Pu Zhao, Wei Niu, Geng Yuan, Yuxuan Cai, Hsin-Hsuan Sung, Sijia Liu,\n  Xipeng Shen, Bin Ren, Yanzhi Wang, Xue Lin", "title": "Achieving Real-Time LiDAR 3D Object Detection on a Mobile Device", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  3D object detection is an important task, especially in the autonomous\ndriving application domain. However, it is challenging to support the real-time\nperformance with the limited computation and memory resources on edge-computing\ndevices in self-driving cars. To achieve this, we propose a compiler-aware\nunified framework incorporating network enhancement and pruning search with the\nreinforcement learning techniques, to enable real-time inference of 3D object\ndetection on the resource-limited edge-computing devices. Specifically, a\ngenerator Recurrent Neural Network (RNN) is employed to provide the unified\nscheme for both network enhancement and pruning search automatically, without\nhuman expertise and assistance. And the evaluated performance of the unified\nschemes can be fed back to train the generator RNN. The experimental results\ndemonstrate that the proposed framework firstly achieves real-time 3D object\ndetection on mobile devices (Samsung Galaxy S20 phone) with competitive\ndetection performance.\n", "versions": [{"version": "v1", "created": "Sat, 26 Dec 2020 19:41:15 GMT"}, {"version": "v2", "created": "Sun, 7 Mar 2021 00:52:04 GMT"}], "update_date": "2021-03-09", "authors_parsed": [["Zhao", "Pu", ""], ["Niu", "Wei", ""], ["Yuan", "Geng", ""], ["Cai", "Yuxuan", ""], ["Sung", "Hsin-Hsuan", ""], ["Liu", "Sijia", ""], ["Shen", "Xipeng", ""], ["Ren", "Bin", ""], ["Wang", "Yanzhi", ""], ["Lin", "Xue", ""]]}, {"id": "2012.13817", "submitter": "Jianhua He", "authors": "Xiaosha Chen, Supeng Leng, Jianhua He, and Longyu Zhou", "title": "Deep Learning Based Intelligent Inter-Vehicle Distance Control for 6G\n  Enabled Cooperative Autonomous Driving", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Research on the sixth generation cellular networks (6G) is gaining huge\nmomentum to achieve ubiquitous wireless connectivity. Connected autonomous\ndriving (CAV) is a critical vertical envisioned for 6G, holding great\npotentials of improving road safety, road and energy efficiency. However the\nstringent service requirements of CAV applications on reliability, latency and\nhigh speed communications will present big challenges to 6G networks. New\nchannel access algorithms and intelligent control schemes for connected\nvehicles are needed for 6G supported CAV. In this paper, we investigated 6G\nsupported cooperative driving, which is an advanced driving mode through\ninformation sharing and driving coordination. Firstly we quantify the delay\nupper bounds of 6G vehicle to vehicle (V2V) communications with hybrid\ncommunication and channel access technologies. A deep learning neural network\nis developed and trained for fast computation of the delay bounds in real time\noperations. Then, an intelligent strategy is designed to control the\ninter-vehicle distance for cooperative autonomous driving. Furthermore, we\npropose a Markov Chain based algorithm to predict the parameters of the system\nstates, and also a safe distance mapping method to enable smooth vehicular\nspeed changes. The proposed algorithms are implemented in the AirSim autonomous\ndriving platform. Simulation results show that the proposed algorithms are\neffective and robust with safe and stable cooperative autonomous driving, which\ngreatly improve the road safety, capacity and efficiency.\n", "versions": [{"version": "v1", "created": "Sat, 26 Dec 2020 21:38:16 GMT"}], "update_date": "2020-12-29", "authors_parsed": [["Chen", "Xiaosha", ""], ["Leng", "Supeng", ""], ["He", "Jianhua", ""], ["Zhou", "Longyu", ""]]}, {"id": "2012.13823", "submitter": "Raphael Memmesheimer", "authors": "Raphael Memmesheimer, Simon H\\\"aring, Nick Theisen, Dietrich Paulus", "title": "Skeleton-DML: Deep Metric Learning for Skeleton-Based One-Shot Action\n  Recognition", "comments": "8 pages, 8 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.RO", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  One-shot action recognition allows the recognition of human-performed actions\nwith only a single training example. This can influence human-robot-interaction\npositively by enabling the robot to react to previously unseen behaviour. We\nformulate the one-shot action recognition problem as a deep metric learning\nproblem and propose a novel image-based skeleton representation that performs\nwell in a metric learning setting. Therefore, we train a model that projects\nthe image representations into an embedding space. In embedding space the\nsimilar actions have a low euclidean distance while dissimilar actions have a\nhigher distance. The one-shot action recognition problem becomes a\nnearest-neighbor search in a set of activity reference samples. We evaluate the\nperformance of our proposed representation against a variety of other\nskeleton-based image representations. In addition, we present an ablation study\nthat shows the influence of different embedding vector sizes, losses and\naugmentation. Our approach lifts the state-of-the-art by 3.3% for the one-shot\naction recognition protocol on the NTU RGB+D 120 dataset under a comparable\ntraining setup. With additional augmentation our result improved over 7.7%.\n", "versions": [{"version": "v1", "created": "Sat, 26 Dec 2020 22:31:11 GMT"}, {"version": "v2", "created": "Mon, 8 Mar 2021 14:33:17 GMT"}], "update_date": "2021-03-09", "authors_parsed": [["Memmesheimer", "Raphael", ""], ["H\u00e4ring", "Simon", ""], ["Theisen", "Nick", ""], ["Paulus", "Dietrich", ""]]}, {"id": "2012.13872", "submitter": "Yaman Kumar Singla", "authors": "Swapnil Parekh, Yaman Kumar Singla, Changyou Chen, Junyi Jessy Li,\n  Rajiv Ratn Shah", "title": "My Teacher Thinks The World Is Flat! Interpreting Automatic Essay\n  Scoring Mechanism", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Significant progress has been made in deep-learning based Automatic Essay\nScoring (AES) systems in the past two decades. However, little research has\nbeen put to understand and interpret the black-box nature of these\ndeep-learning based scoring models. Recent work shows that automated scoring\nsystems are prone to even common-sense adversarial samples. Their lack of\nnatural language understanding capability raises questions on the models being\nactively used by millions of candidates for life-changing decisions. With\nscoring being a highly multi-modal task, it becomes imperative for scoring\nmodels to be validated and tested on all these modalities. We utilize recent\nadvances in interpretability to find the extent to which features such as\ncoherence, content and relevance are important for automated scoring mechanisms\nand why they are susceptible to adversarial samples. We find that the systems\ntested consider essays not as a piece of prose having the characteristics of\nnatural flow of speech and grammatical structure, but as `word-soups' where a\nfew words are much more important than the other words. Removing the context\nsurrounding those few important words causes the prose to lose the flow of\nspeech and grammar, however has little impact on the predicted score. We also\nfind that since the models are not semantically grounded with world-knowledge\nand common sense, adding false facts such as ``the world is flat'' actually\nincreases the score instead of decreasing it.\n", "versions": [{"version": "v1", "created": "Sun, 27 Dec 2020 06:19:20 GMT"}], "update_date": "2020-12-29", "authors_parsed": [["Parekh", "Swapnil", ""], ["Singla", "Yaman Kumar", ""], ["Chen", "Changyou", ""], ["Li", "Junyi Jessy", ""], ["Shah", "Rajiv Ratn", ""]]}, {"id": "2012.13915", "submitter": "Zhuosheng Zhang", "authors": "Zhuosheng Zhang, Yuwei Wu, Junru Zhou, Sufeng Duan, Hai Zhao, Rui Wang", "title": "SG-Net: Syntax Guided Transformer for Language Representation", "comments": "The early version accepted by IEEE Transactions on Pattern Analysis\n  and Machine Intelligence (TPAMI). Journal extension of arXiv:1908.05147 (AAAI\n  2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding human language is one of the key themes of artificial\nintelligence. For language representation, the capacity of effectively modeling\nthe linguistic knowledge from the detail-riddled and lengthy texts and getting\nrid of the noises is essential to improve its performance. Traditional\nattentive models attend to all words without explicit constraint, which results\nin inaccurate concentration on some dispensable words. In this work, we propose\nusing syntax to guide the text modeling by incorporating explicit syntactic\nconstraints into attention mechanisms for better linguistically motivated word\nrepresentations. In detail, for self-attention network (SAN) sponsored\nTransformer-based encoder, we introduce syntactic dependency of interest (SDOI)\ndesign into the SAN to form an SDOI-SAN with syntax-guided self-attention.\nSyntax-guided network (SG-Net) is then composed of this extra SDOI-SAN and the\nSAN from the original Transformer encoder through a dual contextual\narchitecture for better linguistics inspired representation. The proposed\nSG-Net is applied to typical Transformer encoders. Extensive experiments on\npopular benchmark tasks, including machine reading comprehension, natural\nlanguage inference, and neural machine translation show the effectiveness of\nthe proposed SG-Net design.\n", "versions": [{"version": "v1", "created": "Sun, 27 Dec 2020 11:09:35 GMT"}, {"version": "v2", "created": "Thu, 7 Jan 2021 05:48:45 GMT"}], "update_date": "2021-01-08", "authors_parsed": [["Zhang", "Zhuosheng", ""], ["Wu", "Yuwei", ""], ["Zhou", "Junru", ""], ["Duan", "Sufeng", ""], ["Zhao", "Hai", ""], ["Wang", "Rui", ""]]}, {"id": "2012.13978", "submitter": "Zhi Wen", "authors": "Zhi Wen, Xing Han Lu, Siva Reddy", "title": "MeDAL: Medical Abbreviation Disambiguation Dataset for Natural Language\n  Understanding Pretraining", "comments": "EMNLP 2020 Clinical NLP", "journal-ref": "In Proceedings of the 3rd Clinical Natural Language Processing\n  Workshop, pp. 130-135. 2020", "doi": "10.18653/v1/2020.clinicalnlp-1.15", "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  One of the biggest challenges that prohibit the use of many current NLP\nmethods in clinical settings is the availability of public datasets. In this\nwork, we present MeDAL, a large medical text dataset curated for abbreviation\ndisambiguation, designed for natural language understanding pre-training in the\nmedical domain. We pre-trained several models of common architectures on this\ndataset and empirically showed that such pre-training leads to improved\nperformance and convergence speed when fine-tuning on downstream medical tasks.\n", "versions": [{"version": "v1", "created": "Sun, 27 Dec 2020 17:17:39 GMT"}], "update_date": "2020-12-29", "authors_parsed": [["Wen", "Zhi", ""], ["Lu", "Xing Han", ""], ["Reddy", "Siva", ""]]}, {"id": "2012.13982", "submitter": "Tong Zhang", "authors": "Cong Fang and Hanze Dong and Tong Zhang", "title": "Mathematical Models of Overparameterized Neural Networks", "comments": null, "journal-ref": "Proceedings of the IEEE, 2021", "doi": "10.1109/JPROC.2020.3048020", "report-no": null, "categories": "cs.LG cs.AI math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning has received considerable empirical successes in recent years.\nHowever, while many ad hoc tricks have been discovered by practitioners, until\nrecently, there has been a lack of theoretical understanding for tricks\ninvented in the deep learning literature. Known by practitioners that\noverparameterized neural networks are easy to learn, in the past few years\nthere have been important theoretical developments in the analysis of\noverparameterized neural networks. In particular, it was shown that such\nsystems behave like convex systems under various restricted settings, such as\nfor two-layer NNs, and when learning is restricted locally in the so-called\nneural tangent kernel space around specialized initializations. This paper\ndiscusses some of these recent progresses leading to significant better\nunderstanding of neural networks. We will focus on the analysis of two-layer\nneural networks, and explain the key mathematical models, with their\nalgorithmic implications. We will then discuss challenges in understanding deep\nneural networks and some current research directions.\n", "versions": [{"version": "v1", "created": "Sun, 27 Dec 2020 17:48:31 GMT"}], "update_date": "2020-12-29", "authors_parsed": [["Fang", "Cong", ""], ["Dong", "Hanze", ""], ["Zhang", "Tong", ""]]}, {"id": "2012.13985", "submitter": "Alexis Ross", "authors": "Alexis Ross, Ana Marasovi\\'c, Matthew E. Peters", "title": "Explaining NLP Models via Minimal Contrastive Editing (MiCE)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Humans have been shown to give contrastive explanations, which explain why an\nobserved event happened rather than some other counterfactual event (the\ncontrast case). Despite the influential role that contrastivity plays in how\nhumans explain, this property is largely missing from current methods for\nexplaining NLP models. We present Minimal Contrastive Editing (MiCE), a method\nfor producing contrastive explanations of model predictions in the form of\nedits to inputs that change model outputs to the contrast case. Our experiments\nacross three tasks--binary sentiment classification, topic classification, and\nmultiple-choice question answering--show that MiCE is able to produce edits\nthat are not only contrastive, but also minimal and fluent, consistent with\nhuman contrastive edits. We demonstrate how MiCE edits can be used for two use\ncases in NLP system development--debugging incorrect model outputs and\nuncovering dataset artifacts--and thereby illustrate that producing contrastive\nexplanations is a promising research direction for model interpretability.\n", "versions": [{"version": "v1", "created": "Sun, 27 Dec 2020 18:06:26 GMT"}, {"version": "v2", "created": "Wed, 23 Jun 2021 21:53:54 GMT"}], "update_date": "2021-06-25", "authors_parsed": [["Ross", "Alexis", ""], ["Marasovi\u0107", "Ana", ""], ["Peters", "Matthew E.", ""]]}, {"id": "2012.13995", "submitter": "Xiaoyu Cao", "authors": "Xiaoyu Cao, Minghong Fang, Jia Liu, Neil Zhenqiang Gong", "title": "FLTrust: Byzantine-robust Federated Learning via Trust Bootstrapping", "comments": "To appear in NDSS 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Byzantine-robust federated learning aims to enable a service provider to\nlearn an accurate global model when a bounded number of clients are malicious.\nThe key idea of existing Byzantine-robust federated learning methods is that\nthe service provider performs statistical analysis among the clients' local\nmodel updates and removes suspicious ones, before aggregating them to update\nthe global model. However, malicious clients can still corrupt the global\nmodels in these methods via sending carefully crafted local model updates to\nthe service provider. The fundamental reason is that there is no root of trust\nin existing federated learning methods.\n  In this work, we bridge the gap via proposing FLTrust, a new federated\nlearning method in which the service provider itself bootstraps trust. In\nparticular, the service provider itself collects a clean small training dataset\n(called root dataset) for the learning task and the service provider maintains\na model (called server model) based on it to bootstrap trust. In each\niteration, the service provider first assigns a trust score to each local model\nupdate from the clients, where a local model update has a lower trust score if\nits direction deviates more from the direction of the server model update.\nThen, the service provider normalizes the magnitudes of the local model updates\nsuch that they lie in the same hyper-sphere as the server model update in the\nvector space. Our normalization limits the impact of malicious local model\nupdates with large magnitudes. Finally, the service provider computes the\naverage of the normalized local model updates weighted by their trust scores as\na global model update, which is used to update the global model. Our extensive\nevaluations on six datasets from different domains show that our FLTrust is\nsecure against both existing attacks and strong adaptive attacks.\n", "versions": [{"version": "v1", "created": "Sun, 27 Dec 2020 18:43:39 GMT"}], "update_date": "2020-12-29", "authors_parsed": [["Cao", "Xiaoyu", ""], ["Fang", "Minghong", ""], ["Liu", "Jia", ""], ["Gong", "Neil Zhenqiang", ""]]}, {"id": "2012.14005", "submitter": "Cheng Tang", "authors": "Cheng Tang, Andrew Arnold", "title": "Neural document expansion for ad-hoc information retrieval", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recently, Nogueira et al. [2019] proposed a new approach to document\nexpansion based on a neural Seq2Seq model, showing significant improvement on\nshort text retrieval task. However, this approach needs a large amount of\nin-domain training data. In this paper, we show that this neural document\nexpansion approach can be effectively adapted to standard IR tasks, where\nlabels are scarce and many long documents are present.\n", "versions": [{"version": "v1", "created": "Sun, 27 Dec 2020 20:00:08 GMT"}], "update_date": "2020-12-29", "authors_parsed": [["Tang", "Cheng", ""], ["Arnold", "Andrew", ""]]}, {"id": "2012.14007", "submitter": "Michele Piana", "authors": "Emma Perracchione, Paolo Massa, Anna Maria Massone, Michele Piana", "title": "Visibility Interpolation in Solar Hard X-ray Imaging: Application to\n  RHESSI and STIX", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "astro-ph.IM cs.AI cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Space telescopes for solar hard X-ray imaging provide observations made of\nsampled Fourier components of the incoming photon flux. The aim of this study\nis to design an image reconstruction method relying on enhanced visibility\ninterpolation in the Fourier domain. % methods heading (mandatory) The\ninterpolation-based method is applied on synthetic visibilities generated by\nmeans of the simulation software implemented within the framework of the\nSpectrometer/Telescope for Imaging X-rays (STIX) mission on board Solar\nOrbiter. An application to experimental visibilities observed by the Reuven\nRamaty High Energy Solar Spectroscopic Imager (RHESSI) is also considered. In\norder to interpolate these visibility data we have utilized an approach based\non Variably Scaled Kernels (VSKs), which are able to realize feature\naugmentation by exploiting prior information on the flaring source and which\nare used here, for the first time, for image reconstruction purposes.} %\nresults heading (mandatory) When compared to an interpolation-based\nreconstruction algorithm previously introduced for RHESSI, VSKs offer\nsignificantly better performances, particularly in the case of STIX imaging,\nwhich is characterized by a notably sparse sampling of the Fourier domain. In\nthe case of RHESSI data, this novel approach is particularly reliable when\neither the flaring sources are characterized by narrow, ribbon-like shapes or\nhigh-resolution detectors are utilized for observations. % conclusions heading\n(optional), leave it empty if necessary The use of VSKs for interpolating hard\nX-ray visibilities allows a notable image reconstruction accuracy when the\ninformation on the flaring source is encoded by a small set of scattered\nFourier data and when the visibility surface is affected by significant\noscillations in the frequency domain.\n", "versions": [{"version": "v1", "created": "Sun, 27 Dec 2020 20:39:44 GMT"}], "update_date": "2020-12-29", "authors_parsed": [["Perracchione", "Emma", ""], ["Massa", "Paolo", ""], ["Massone", "Anna Maria", ""], ["Piana", "Michele", ""]]}, {"id": "2012.14011", "submitter": "Yining Hong", "authors": "Yining Hong, Qing Li, Ran Gong, Daniel Ciao, Siyuan Huang, Song-Chun\n  Zhu", "title": "SMART: A Situation Model for Algebra Story Problems via Attributed\n  Grammar", "comments": null, "journal-ref": "AAAI2021", "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Solving algebra story problems remains a challenging task in artificial\nintelligence, which requires a detailed understanding of real-world situations\nand a strong mathematical reasoning capability. Previous neural solvers of math\nword problems directly translate problem texts into equations, lacking an\nexplicit interpretation of the situations, and often fail to handle more\nsophisticated situations. To address such limits of neural solvers, we\nintroduce the concept of a \\emph{situation model}, which originates from\npsychology studies to represent the mental states of humans in problem-solving,\nand propose \\emph{SMART}, which adopts attributed grammar as the representation\nof situation models for algebra story problems. Specifically, we first train an\ninformation extraction module to extract nodes, attributes, and relations from\nproblem texts and then generate a parse graph based on a pre-defined attributed\ngrammar. An iterative learning strategy is also proposed to improve the\nperformance of SMART further. To rigorously study this task, we carefully\ncurate a new dataset named \\emph{ASP6.6k}. Experimental results on ASP6.6k show\nthat the proposed model outperforms all previous neural solvers by a large\nmargin while preserving much better interpretability. To test these models'\ngeneralization capability, we also design an out-of-distribution (OOD)\nevaluation, in which problems are more complex than those in the training set.\nOur model exceeds state-of-the-art models by 17\\% in the OOD evaluation,\ndemonstrating its superior generalization ability.\n", "versions": [{"version": "v1", "created": "Sun, 27 Dec 2020 21:03:40 GMT"}], "update_date": "2020-12-29", "authors_parsed": [["Hong", "Yining", ""], ["Li", "Qing", ""], ["Gong", "Ran", ""], ["Ciao", "Daniel", ""], ["Huang", "Siyuan", ""], ["Zhu", "Song-Chun", ""]]}, {"id": "2012.14036", "submitter": "Alireza Shamsoshoara", "authors": "Alireza Shamsoshoara, Fatemeh Afghah, Abolfazl Razi, Liming Zheng,\n  Peter Z Ful\\'e, Erik Blasch", "title": "Aerial Imagery Pile burn detection using Deep Learning: the FLAME\n  dataset", "comments": "27 Pages, 7 Figures, 4 Tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Wildfires are one of the costliest and deadliest natural disasters in the US,\ncausing damage to millions of hectares of forest resources and threatening the\nlives of people and animals. Of particular importance are risks to firefighters\nand operational forces, which highlights the need for leveraging technology to\nminimize danger to people and property. FLAME (Fire Luminosity Airborne-based\nMachine learning Evaluation) offers a dataset of aerial images of fires along\nwith methods for fire detection and segmentation which can help firefighters\nand researchers to develop optimal fire management strategies. This paper\nprovides a fire image dataset collected by drones during a prescribed burning\npiled detritus in an Arizona pine forest. The dataset includes video recordings\nand thermal heatmaps captured by infrared cameras. The captured videos and\nimages are annotated and labeled frame-wise to help researchers easily apply\ntheir fire detection and modeling algorithms. The paper also highlights\nsolutions to two machine learning problems: (1) Binary classification of video\nframes based on the presence [and absence] of fire flames. An Artificial Neural\nNetwork (ANN) method is developed that achieved a 76% classification accuracy.\n(2) Fire detection using segmentation methods to precisely determine fire\nborders. A deep learning method is designed based on the U-Net up-sampling and\ndown-sampling approach to extract a fire mask from the video frames. Our FLAME\nmethod approached a precision of 92% and a recall of 84%. Future research will\nexpand the technique for free burning broadcast fire using thermal images.\n", "versions": [{"version": "v1", "created": "Mon, 28 Dec 2020 00:00:41 GMT"}], "update_date": "2020-12-29", "authors_parsed": [["Shamsoshoara", "Alireza", ""], ["Afghah", "Fatemeh", ""], ["Razi", "Abolfazl", ""], ["Zheng", "Liming", ""], ["Ful\u00e9", "Peter Z", ""], ["Blasch", "Erik", ""]]}, {"id": "2012.14072", "submitter": "Yangyang Zhao", "authors": "Yangyang Zhao, Zhenyu Wang and Zhenhua Huang", "title": "Automatic Curriculum Learning With Over-repetition Penalty for Dialogue\n  Policy Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dialogue policy learning based on reinforcement learning is difficult to be\napplied to real users to train dialogue agents from scratch because of the high\ncost. User simulators, which choose random user goals for the dialogue agent to\ntrain on, have been considered as an affordable substitute for real users.\nHowever, this random sampling method ignores the law of human learning, making\nthe learned dialogue policy inefficient and unstable. We propose a novel\nframework, Automatic Curriculum Learning-based Deep Q-Network (ACL-DQN), which\nreplaces the traditional random sampling method with a teacher policy model to\nrealize the dialogue policy for automatic curriculum learning. The teacher\nmodel arranges a meaningful ordered curriculum and automatically adjusts it by\nmonitoring the learning progress of the dialogue agent and the over-repetition\npenalty without any requirement of prior knowledge. The learning progress of\nthe dialogue agent reflects the relationship between the dialogue agent's\nability and the sampled goals' difficulty for sample efficiency. The\nover-repetition penalty guarantees the sampled diversity. Experiments show that\nthe ACL-DQN significantly improves the effectiveness and stability of dialogue\ntasks with a statistically significant margin. Furthermore, the framework can\nbe further improved by equipping with different curriculum schedules, which\ndemonstrates that the framework has strong generalizability.\n", "versions": [{"version": "v1", "created": "Mon, 28 Dec 2020 02:44:49 GMT"}], "update_date": "2020-12-29", "authors_parsed": [["Zhao", "Yangyang", ""], ["Wang", "Zhenyu", ""], ["Huang", "Zhenhua", ""]]}, {"id": "2012.14124", "submitter": "Keisuke Shirai", "authors": "Keisuke Shirai, Kazuma Hashimoto, Akiko Eriguchi, Takashi Ninomiya,\n  Shinsuke Mori", "title": "Neural Text Generation with Artificial Negative Examples", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural text generation models conditioning on given input (e.g. machine\ntranslation and image captioning) are usually trained by maximum likelihood\nestimation of target text. However, the trained models suffer from various\ntypes of errors at inference time. In this paper, we propose to suppress an\narbitrary type of errors by training the text generation model in a\nreinforcement learning framework, where we use a trainable reward function that\nis capable of discriminating between references and sentences containing the\ntargeted type of errors. We create such negative examples by artificially\ninjecting the targeted errors to the references. In experiments, we focus on\ntwo error types, repeated and dropped tokens in model-generated text. The\nexperimental results show that our method can suppress the generation errors\nand achieve significant improvements on two machine translation and two image\ncaptioning tasks.\n", "versions": [{"version": "v1", "created": "Mon, 28 Dec 2020 07:25:10 GMT"}], "update_date": "2020-12-29", "authors_parsed": [["Shirai", "Keisuke", ""], ["Hashimoto", "Kazuma", ""], ["Eriguchi", "Akiko", ""], ["Ninomiya", "Takashi", ""], ["Mori", "Shinsuke", ""]]}, {"id": "2012.14137", "submitter": "Zheqi Zhu", "authors": "Zheqi Zhu, Shuo Wan, Pingyi Fan, Khaled B. Letaief", "title": "Federated Multi-Agent Actor-Critic Learning for Age Sensitive Mobile\n  Edge Computing", "comments": null, "journal-ref": null, "doi": "10.1109/JIOT.2021.3078514", "report-no": null, "categories": "cs.MA cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As an emerging technique, mobile edge computing (MEC) introduces a new\nprocessing scheme for various distributed communication-computing systems such\nas industrial Internet of Things (IoT), vehicular communication, smart city,\netc. In this work, we mainly focus on the timeliness of the MEC systems where\nthe freshness of the data and computation tasks is significant. Firstly, we\nformulate a kind of age-sensitive MEC models and define the average age of\ninformation (AoI) minimization problems of interests. Then, a novel policy\nbased multi-agent deep reinforcement learning (RL) framework, called\nheterogeneous multi-agent actor critic (H-MAAC), is proposed as a paradigm for\njoint collaboration in the investigated MEC systems, where edge devices and\ncenter controller learn the interactive strategies through their own\nobservations. To improves the system performance, we develop the corresponding\nonline algorithm by introducing an edge federated learning mode into the\nmulti-agent cooperation whose advantages on learning convergence can be\nguaranteed theoretically. To the best of our knowledge, it's the first joint\nMEC collaboration algorithm that combines the edge federated mode with the\nmulti-agent actor-critic reinforcement learning. Furthermore, we evaluate the\nproposed approach and compare it with classical RL based methods. As a result,\nthe proposed framework not only outperforms the baseline on average system age,\nbut also promotes the stability of training process. Besides, the simulation\nresults provide some innovative perspectives for the system design under the\nedge federated collaboration.\n", "versions": [{"version": "v1", "created": "Mon, 28 Dec 2020 08:19:26 GMT"}, {"version": "v2", "created": "Wed, 6 Jan 2021 13:43:32 GMT"}, {"version": "v3", "created": "Tue, 11 May 2021 10:02:12 GMT"}], "update_date": "2021-05-12", "authors_parsed": [["Zhu", "Zheqi", ""], ["Wan", "Shuo", ""], ["Fan", "Pingyi", ""], ["Letaief", "Khaled B.", ""]]}, {"id": "2012.14164", "submitter": "Martin Andrews", "authors": "Yew Ken Chia and Sam Witteveen and Martin Andrews", "title": "Red Dragon AI at TextGraphs 2020 Shared Task: LIT : LSTM-Interleaved\n  Transformer for Multi-Hop Explanation Ranking", "comments": "Accepted paper for TextGraphs-14 workshop at COLING 2020. (6 pages\n  including references)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Explainable question answering for science questions is a challenging task\nthat requires multi-hop inference over a large set of fact sentences. To\ncounter the limitations of methods that view each query-document pair in\nisolation, we propose the LSTM-Interleaved Transformer which incorporates\ncross-document interactions for improved multi-hop ranking. The LIT\narchitecture can leverage prior ranking positions in the re-ranking setting.\nOur model is competitive on the current leaderboard for the TextGraphs 2020\nshared task, achieving a test-set MAP of 0.5607, and would have gained third\nplace had we submitted before the competition deadline. Our code implementation\nis made available at\nhttps://github.com/mdda/worldtree_corpus/tree/textgraphs_2020\n", "versions": [{"version": "v1", "created": "Mon, 28 Dec 2020 09:54:00 GMT"}], "update_date": "2020-12-29", "authors_parsed": [["Chia", "Yew Ken", ""], ["Witteveen", "Sam", ""], ["Andrews", "Martin", ""]]}, {"id": "2012.14171", "submitter": "Yue Li", "authors": "Yue Li, Benedetta Tondi and Mauro Barni", "title": "Spread-Transform Dither Modulation Watermarking of Deep Neural Network", "comments": "Submitted to Journal of Information Security and Applications", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  DNN watermarking is receiving an increasing attention as a suitable mean to\nprotect the Intellectual Property Rights associated to DNN models. Several\nmethods proposed so far are inspired to the popular Spread Spectrum (SS)\nparadigm according to which the watermark bits are embedded into the projection\nof the weights of the DNN model onto a pseudorandom sequence. In this paper, we\npropose a new DNN watermarking algorithm that leverages on the watermarking\nwith side information paradigm to decrease the obtrusiveness of the watermark\nand increase its payload. In particular, the new scheme exploits the main ideas\nof ST-DM (Spread Transform Dither Modulation) watermarking to improve the\nperformance of a recently proposed algorithm based on conventional SS. The\nexperiments we carried out by applying the proposed scheme to watermark\ndifferent models, demonstrate its capability to provide a higher payload with a\nlower impact on network accuracy than a baseline method based on conventional\nSS, while retaining a satisfactory level of robustness.\n", "versions": [{"version": "v1", "created": "Mon, 28 Dec 2020 10:23:17 GMT"}], "update_date": "2020-12-29", "authors_parsed": [["Li", "Yue", ""], ["Tondi", "Benedetta", ""], ["Barni", "Mauro", ""]]}, {"id": "2012.14173", "submitter": "David Morales", "authors": "David Morales, Estefania Talavera, Beatriz Remeseiro", "title": "Playing to distraction: towards a robust training of CNN classifiers\n  through visual explanation techniques", "comments": "20 pages,3 figures, 4 tables", "journal-ref": "Neural Comput & Applic (2021)", "doi": "10.1007/s00521-021-06282-2", "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The field of deep learning is evolving in different directions, with still\nthe need for more efficient training strategies. In this work, we present a\nnovel and robust training scheme that integrates visual explanation techniques\nin the learning process. Unlike the attention mechanisms that focus on the\nrelevant parts of images, we aim to improve the robustness of the model by\nmaking it pay attention to other regions as well. Broadly speaking, the idea is\nto distract the classifier in the learning process to force it to focus not\nonly on relevant regions but also on those that, a priori, are not so\ninformative for the discrimination of the class. We tested the proposed\napproach by embedding it into the learning process of a convolutional neural\nnetwork for the analysis and classification of two well-known datasets, namely\nStanford cars and FGVC-Aircraft. Furthermore, we evaluated our model on a\nreal-case scenario for the classification of egocentric images, allowing us to\nobtain relevant information about peoples' lifestyles. In particular, we work\non the challenging EgoFoodPlaces dataset, achieving state-of-the-art results\nwith a lower level of complexity. The obtained results indicate the suitability\nof our proposed training scheme for image classification, improving the\nrobustness of the final model.\n", "versions": [{"version": "v1", "created": "Mon, 28 Dec 2020 10:24:32 GMT"}, {"version": "v2", "created": "Wed, 28 Jul 2021 15:28:14 GMT"}, {"version": "v3", "created": "Thu, 29 Jul 2021 08:49:37 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["Morales", "David", ""], ["Talavera", "Estefania", ""], ["Remeseiro", "Beatriz", ""]]}, {"id": "2012.14228", "submitter": "Minne Li", "authors": "Minne Li, Mengyue Yang, Furui Liu, Xu Chen, Zhitang Chen, Jun Wang", "title": "Causal World Models by Unsupervised Deconfounding of Physical Dynamics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The capability of imagining internally with a mental model of the world is\nvitally important for human cognition. If a machine intelligent agent can learn\na world model to create a \"dream\" environment, it can then internally ask\nwhat-if questions -- simulate the alternative futures that haven't been\nexperienced in the past yet -- and make optimal decisions accordingly. Existing\nworld models are established typically by learning spatio-temporal regularities\nembedded from the past sensory signal without taking into account confounding\nfactors that influence state transition dynamics. As such, they fail to answer\nthe critical counterfactual questions about \"what would have happened\" if a\ncertain action policy was taken. In this paper, we propose Causal World Models\n(CWMs) that allow unsupervised modeling of relationships between the intervened\nobservations and the alternative futures by learning an estimator of the latent\nconfounding factors. We empirically evaluate our method and demonstrate its\neffectiveness in a variety of physical reasoning environments. Specifically, we\nshow reductions in sample complexity for reinforcement learning tasks and\nimprovements in counterfactual physical reasoning.\n", "versions": [{"version": "v1", "created": "Mon, 28 Dec 2020 13:44:36 GMT"}], "update_date": "2020-12-29", "authors_parsed": [["Li", "Minne", ""], ["Yang", "Mengyue", ""], ["Liu", "Furui", ""], ["Chen", "Xu", ""], ["Chen", "Zhitang", ""], ["Wang", "Jun", ""]]}, {"id": "2012.14230", "submitter": "Bo Li", "authors": "Bo Li, Wiro J. Niessen, Stefan Klein, Marius de Groot, M. Arfan Ikram,\n  Meike W. Vernooij, Esther E. Bron", "title": "Longitudinal diffusion MRI analysis using Segis-Net: a single-step\n  deep-learning framework for simultaneous segmentation and registration", "comments": "To appear in NeuroImage", "journal-ref": null, "doi": "10.1016/j.neuroimage.2021.118004", "report-no": null, "categories": "cs.CV cs.AI eess.IV", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  This work presents a single-step deep-learning framework for longitudinal\nimage analysis, coined Segis-Net. To optimally exploit information available in\nlongitudinal data, this method concurrently learns a multi-class segmentation\nand nonlinear registration. Segmentation and registration are modeled using a\nconvolutional neural network and optimized simultaneously for their mutual\nbenefit. An objective function that optimizes spatial correspondence for the\nsegmented structures across time-points is proposed. We applied Segis-Net to\nthe analysis of white matter tracts from N=8045 longitudinal brain MRI datasets\nof 3249 elderly individuals. Segis-Net approach showed a significant increase\nin registration accuracy, spatio-temporal segmentation consistency, and\nreproducibility comparing with two multistage pipelines. This also led to a\nsignificant reduction in the sample-size that would be required to achieve the\nsame statistical power in analyzing tract-specific measures. Thus, we expect\nthat Segis-Net can serve as a new reliable tool to support longitudinal imaging\nstudies to investigate macro- and microstructural brain changes over time.\n", "versions": [{"version": "v1", "created": "Mon, 28 Dec 2020 13:48:21 GMT"}, {"version": "v2", "created": "Fri, 23 Apr 2021 11:06:25 GMT"}], "update_date": "2021-04-26", "authors_parsed": [["Li", "Bo", ""], ["Niessen", "Wiro J.", ""], ["Klein", "Stefan", ""], ["de Groot", "Marius", ""], ["Ikram", "M. Arfan", ""], ["Vernooij", "Meike W.", ""], ["Bron", "Esther E.", ""]]}, {"id": "2012.14235", "submitter": "Margarida Ferreira", "authors": "Margarida Ferreira and Miguel Terra-Neves and Miguel Ventura and\n  In\\^es Lynce and Ruben Martins", "title": "FOREST: An Interactive Multi-tree Synthesizer for Regular Expressions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.FL cs.AI", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Form validators based on regular expressions are often used on digital forms\nto prevent users from inserting data in the wrong format. However, writing\nthese validators can pose a challenge to some users. We present FOREST, a\nregular expression synthesizer for digital form validations. FOREST produces a\nregular expression that matches the desired pattern for the input values and a\nset of conditions over capturing groups that ensure the validity of integer\nvalues in the input. Our synthesis procedure is based on enumerative search and\nuses a Satisfiability Modulo Theories (SMT) solver to explore and prune the\nsearch space. We propose a novel representation for regular expressions\nsynthesis, multi-tree, which induces patterns in the examples and uses them to\nsplit the problem through a divide-and-conquer approach. We also present a new\nSMT encoding to synthesize capture conditions for a given regular expression.\nTo increase confidence in the synthesized regular expression, we implement user\ninteraction based on distinguishing inputs. We evaluated FOREST on real-world\nform-validation instances using regular expressions. Experimental results show\nthat FOREST successfully returns the desired regular expression in 72% of the\ninstances and outperforms REGEL, a state-of-the-art regular expression\nsynthesizer.\n", "versions": [{"version": "v1", "created": "Mon, 28 Dec 2020 14:06:01 GMT"}], "update_date": "2020-12-29", "authors_parsed": [["Ferreira", "Margarida", ""], ["Terra-Neves", "Miguel", ""], ["Ventura", "Miguel", ""], ["Lynce", "In\u00eas", ""], ["Martins", "Ruben", ""]]}, {"id": "2012.14259", "submitter": "Sorina Georgiana Smeureanu", "authors": "Cristina Palmero, Javier Selva, Sorina Smeureanu, Julio C. S. Jacques\n  Junior, Albert Clap\\'es, Alexa Mosegu\\'i, Zejian Zhang, David Gallardo,\n  Georgina Guilera, David Leiva, Sergio Escalera", "title": "Context-Aware Personality Inference in Dyadic Scenarios: Introducing the\n  UDIVA Dataset", "comments": "Accepted to the 11th International Workshop on Human Behavior\n  Understanding workshop at Winter Conference on Applications of Computer\n  Vision 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper introduces UDIVA, a new non-acted dataset of face-to-face dyadic\ninteractions, where interlocutors perform competitive and collaborative tasks\nwith different behavior elicitation and cognitive workload. The dataset\nconsists of 90.5 hours of dyadic interactions among 147 participants\ndistributed in 188 sessions, recorded using multiple audiovisual and\nphysiological sensors. Currently, it includes sociodemographic, self- and\npeer-reported personality, internal state, and relationship profiling from\nparticipants. As an initial analysis on UDIVA, we propose a transformer-based\nmethod for self-reported personality inference in dyadic scenarios, which uses\naudiovisual data and different sources of context from both interlocutors to\nregress a target person's personality traits. Preliminary results from an\nincremental study show consistent improvements when using all available context\ninformation.\n", "versions": [{"version": "v1", "created": "Mon, 28 Dec 2020 15:08:02 GMT"}], "update_date": "2020-12-29", "authors_parsed": [["Palmero", "Cristina", ""], ["Selva", "Javier", ""], ["Smeureanu", "Sorina", ""], ["Junior", "Julio C. S. Jacques", ""], ["Clap\u00e9s", "Albert", ""], ["Mosegu\u00ed", "Alexa", ""], ["Zhang", "Zejian", ""], ["Gallardo", "David", ""], ["Guilera", "Georgina", ""], ["Leiva", "David", ""], ["Escalera", "Sergio", ""]]}, {"id": "2012.14261", "submitter": "Yu Zhang", "authors": "Yu Zhang, Peter Ti\\v{n}o, Ale\\v{s} Leonardis, Ke Tang", "title": "A Survey on Neural Network Interpretability", "comments": "This work has been accepted by IEEE-TETCI", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Along with the great success of deep neural networks, there is also growing\nconcern about their black-box nature. The interpretability issue affects\npeople's trust on deep learning systems. It is also related to many ethical\nproblems, e.g., algorithmic discrimination. Moreover, interpretability is a\ndesired property for deep networks to become powerful tools in other research\nfields, e.g., drug discovery and genomics. In this survey, we conduct a\ncomprehensive review of the neural network interpretability research. We first\nclarify the definition of interpretability as it has been used in many\ndifferent contexts. Then we elaborate on the importance of interpretability and\npropose a novel taxonomy organized along three dimensions: type of engagement\n(passive vs. active interpretation approaches), the type of explanation, and\nthe focus (from local to global interpretability). This taxonomy provides a\nmeaningful 3D view of distribution of papers from the relevant literature as\ntwo of the dimensions are not simply categorical but allow ordinal\nsubcategories. Finally, we summarize the existing interpretability evaluation\nmethods and suggest possible research directions inspired by our new taxonomy.\n", "versions": [{"version": "v1", "created": "Mon, 28 Dec 2020 15:09:50 GMT"}, {"version": "v2", "created": "Wed, 3 Mar 2021 09:00:09 GMT"}, {"version": "v3", "created": "Thu, 15 Jul 2021 13:01:20 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Zhang", "Yu", ""], ["Ti\u0148o", "Peter", ""], ["Leonardis", "Ale\u0161", ""], ["Tang", "Ke", ""]]}, {"id": "2012.14283", "submitter": "Sarah Schwettmann", "authors": "Sarah Schwettmann, Hendrik Strobelt, Mauro Martino", "title": "Latent Compass: Creation by Navigation", "comments": "3 pages, 2 figures, accepted at the 4th Workshop on Machine Learning\n  for Creativity and Design at NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CV", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In Marius von Senden's Space and Sight, a newly sighted blind patient\ndescribes the experience of a corner as lemon-like, because corners \"prick\"\nsight like lemons prick the tongue. Prickliness, here, is a dimension in the\nfeature space of sensory experience, an effect of the perceived on the\nperceiver that arises where the two interact. In the account of the newly\nsighted, an effect familiar from one interaction translates to a novel context.\nPerception serves as the vehicle for generalization, in that an effect shared\nacross different experiences produces a concrete abstraction grounded in those\nexperiences. Cezanne and the post-impressionists, fluent in the language of\nexperience translation, realized that the way to paint a concrete form that\nbest reflected reality was to paint not what they saw, but what it was like to\nsee. We envision a future of creation using AI where what it is like to see is\nreplicable, transferrable, manipulable - part of the artist's palette that is\nboth grounded in a particular context, and generalizable beyond it.\n  An active line of research maps human-interpretable features onto directions\nin GAN latent space. Supervised and self-supervised approaches that search for\nanticipated directions or use off-the-shelf classifiers to drive image\nmanipulation in embedding space are limited in the variety of features they can\nuncover. Unsupervised approaches that discover useful new directions show that\nthe space of perceptually meaningful directions is nowhere close to being fully\nmapped. As this space is broad and full of creative potential, we want tools\nfor direction discovery that capture the richness and generalizability of human\nperception. Our approach puts creators in the discovery loop during real-time\ntool use, in order to identify directions that are perceptually meaningful to\nthem, and generate interpretable image translations along those directions.\n", "versions": [{"version": "v1", "created": "Sun, 20 Dec 2020 04:18:23 GMT"}], "update_date": "2020-12-29", "authors_parsed": [["Schwettmann", "Sarah", ""], ["Strobelt", "Hendrik", ""], ["Martino", "Mauro", ""]]}, {"id": "2012.14288", "submitter": "Pengtao Xie", "authors": "Xingchen Zhao, Xuehai He, Pengtao Xie", "title": "Learning by Ignoring, with Application to Domain Adaptation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Learning by ignoring, which identifies less important things and excludes\nthem from the learning process, is broadly practiced in human learning and has\nshown ubiquitous effectiveness. There has been psychological studies showing\nthat learning to ignore certain things is a powerful tool for helping people\nfocus. In this paper, we explore whether this useful human learning methodology\ncan be borrowed to improve machine learning. We propose a novel machine\nlearning framework referred to as learning by ignoring (LBI). Our framework\nautomatically identifies pretraining data examples that have large domain shift\nfrom the target distribution by learning an ignoring variable for each example\nand excludes them from the pretraining process. We formulate LBI as a\nthree-level optimization framework where three learning stages are involved:\npretraining by minimizing the losses weighed by ignoring variables; finetuning;\nupdating the ignoring variables by minimizing the validation loss. A\ngradient-based algorithm is developed to efficiently solve the three-level\noptimization problem in LBI. Experiments on various datasets demonstrate the\neffectiveness of our framework.\n", "versions": [{"version": "v1", "created": "Mon, 28 Dec 2020 15:33:41 GMT"}, {"version": "v2", "created": "Thu, 11 Mar 2021 04:56:23 GMT"}], "update_date": "2021-03-12", "authors_parsed": [["Zhao", "Xingchen", ""], ["He", "Xuehai", ""], ["Xie", "Pengtao", ""]]}, {"id": "2012.14314", "submitter": "Nian Xue", "authors": "Zhen Li, Sunzeng Cai, Xiaoyi Wang, Zhe Liu and Nian Xue", "title": "GAKP: GRU Association and Kalman Prediction for Multiple Object Tracking", "comments": "8 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multiple Object Tracking (MOT) has been a useful yet challenging task in many\nreal-world applications such as video surveillance, intelligent retail, and\nsmart city. The challenge is how to model long-term temporal dependencies in an\nefficient manner. Some recent works employ Recurrent Neural Networks (RNN) to\nobtain good performance, which, however, requires a large amount of training\ndata. In this paper, we proposed a novel tracking method that integrates the\nauto-tuning Kalman method for prediction and the Gated Recurrent Unit (GRU) and\nachieves a near-optimum with a small amount of training data. Experimental\nresults show that our new algorithm can achieve competitive performance on the\nchallenging MOT benchmark, and faster and more robust than the state-of-the-art\nRNN-based online MOT algorithms.\n", "versions": [{"version": "v1", "created": "Mon, 28 Dec 2020 15:52:24 GMT"}], "update_date": "2020-12-29", "authors_parsed": [["Li", "Zhen", ""], ["Cai", "Sunzeng", ""], ["Wang", "Xiaoyi", ""], ["Liu", "Zhe", ""], ["Xue", "Nian", ""]]}, {"id": "2012.14325", "submitter": "Ljupco Kocarev", "authors": "Ljupco Kocarev and Jasna Koteska", "title": "Digital me ontology and ethics", "comments": "17 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper addresses ontology and ethics of an AI agent called digital me. We\ndefine digital me as autonomous, decision-making, and learning agent,\nrepresenting an individual and having practically immortal own life. It is\nassumed that digital me is equipped with the big-five personality model,\nensuring that it provides a model of some aspects of a strong AI:\nconsciousness, free will, and intentionality. As computer-based personality\njudgments are more accurate than those made by humans, digital me can judge the\npersonality of the individual represented by the digital me, other individuals'\npersonalities, and other digital me-s. We describe seven ontological qualities\nof digital me: a) double-layer status of Digital Being versus digital me, b)\ndigital me versus real me, c) mind-digital me and body-digital me, d) digital\nme versus doppelganger (shadow digital me), e) non-human time concept, f)\nsocial quality, g) practical immortality. We argue that with the advancement of\nAI's sciences and technologies, there exist two digital me thresholds. The\nfirst threshold defines digital me having some (rudimentarily) form of\nconsciousness, free will, and intentionality. The second threshold assumes that\ndigital me is equipped with moral learning capabilities, implying that, in\nprinciple, digital me could develop their own ethics which significantly\ndiffers from human's understanding of ethics. Finally we discuss the\nimplications of digital me metaethics, normative and applied ethics, the\nimplementation of the Golden Rule in digital me-s, and we suggest two sets of\nnormative principles for digital me: consequentialist and duty based digital me\nprinciples.\n", "versions": [{"version": "v1", "created": "Tue, 22 Dec 2020 09:54:04 GMT"}], "update_date": "2020-12-29", "authors_parsed": [["Kocarev", "Ljupco", ""], ["Koteska", "Jasna", ""]]}, {"id": "2012.14332", "submitter": "Mario Michael Krell", "authors": "Sourabh Kulkarni and Mario Michael Krell and Seth Nabarro and Csaba\n  Andras Moritz", "title": "Hardware-accelerated Simulation-based Inference of Stochastic\n  Epidemiology Models for COVID-19", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.AI cs.AR", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Epidemiology models are central in understanding and controlling large scale\npandemics. Several epidemiology models require simulation-based inference such\nas Approximate Bayesian Computation (ABC) to fit their parameters to\nobservations. ABC inference is highly amenable to efficient hardware\nacceleration. In this work, we develop parallel ABC inference of a stochastic\nepidemiology model for COVID-19. The statistical inference framework is\nimplemented and compared on Intel Xeon CPU, NVIDIA Tesla V100 GPU and the\nGraphcore Mk1 IPU, and the results are discussed in the context of their\ncomputational architectures. Results show that GPUs are 4x and IPUs are 30x\nfaster than Xeon CPUs. Extensive performance analysis indicates that the\ndifference between IPU and GPU can be attributed to higher communication\nbandwidth, closeness of memory to compute, and higher compute power in the IPU.\nThe proposed framework scales across 16 IPUs, with scaling overhead not\nexceeding 8% for the experiments performed. We present an example of our\nframework in practice, performing inference on the epidemiology model across\nthree countries, and giving a brief overview of the results.\n", "versions": [{"version": "v1", "created": "Wed, 23 Dec 2020 03:01:59 GMT"}], "update_date": "2020-12-29", "authors_parsed": [["Kulkarni", "Sourabh", ""], ["Krell", "Mario Michael", ""], ["Nabarro", "Seth", ""], ["Moritz", "Csaba Andras", ""]]}, {"id": "2012.14359", "submitter": "Mehul Bhatt", "authors": "Jakob Suchan and Mehul Bhatt and Srikrishna Varadarajan", "title": "Commonsense Visual Sensemaking for Autonomous Driving: On Generalised\n  Neurosymbolic Online Abduction Integrating Vision and Semantics", "comments": "This is a preprint / review version of an accepted contribution to be\n  published as part of the Artificial Intelligence Journal (AIJ).? The article\n  is an extended version of an IJCAI 2019 publication [74, arXiv:1906.00107]", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CV cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We demonstrate the need and potential of systematically integrated vision and\nsemantics solutions for visual sensemaking in the backdrop of autonomous\ndriving. A general neurosymbolic method for online visual sensemaking using\nanswer set programming (ASP) is systematically formalised and fully\nimplemented. The method integrates state of the art in visual computing, and is\ndeveloped as a modular framework that is generally usable within hybrid\narchitectures for realtime perception and control. We evaluate and demonstrate\nwith community established benchmarks KITTIMOD, MOT-2017, and MOT-2020. As\nuse-case, we focus on the significance of human-centred visual sensemaking --\ne.g., involving semantic representation and explainability, question-answering,\ncommonsense interpolation -- in safety-critical autonomous driving situations.\nThe developed neurosymbolic framework is domain-independent, with the case of\nautonomous driving designed to serve as an exemplar for online visual\nsensemaking in diverse cognitive interaction settings in the backdrop of select\nhuman-centred AI technology design considerations.\n  Keywords: Cognitive Vision, Deep Semantics, Declarative Spatial Reasoning,\nKnowledge Representation and Reasoning, Commonsense Reasoning, Visual\nAbduction, Answer Set Programming, Autonomous Driving, Human-Centred Computing\nand Design, Standardisation in Driving Technology, Spatial Cognition and AI.\n", "versions": [{"version": "v1", "created": "Mon, 28 Dec 2020 16:55:19 GMT"}], "update_date": "2020-12-29", "authors_parsed": [["Suchan", "Jakob", ""], ["Bhatt", "Mehul", ""], ["Varadarajan", "Srikrishna", ""]]}, {"id": "2012.14366", "submitter": "Jian Zhang", "authors": "Jian Zhang, Cunjing Ge, Feifei Ma", "title": "Counting the Number of Solutions to Constraints", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Compared with constraint satisfaction problems, counting problems have\nreceived less attention. In this paper, we survey research works on the\nproblems of counting the number of solutions to constraints. The constraints\nmay take various forms, including, formulas in the propositional logic, linear\ninequalities over the reals or integers, Boolean combination of linear\nconstraints. We describe some techniques and tools for solving the counting\nproblems, as well as some applications (e.g., applications to automated\nreasoning, program analysis, formal verification and information security).\n", "versions": [{"version": "v1", "created": "Mon, 28 Dec 2020 17:11:57 GMT"}], "update_date": "2020-12-29", "authors_parsed": [["Zhang", "Jian", ""], ["Ge", "Cunjing", ""], ["Ma", "Feifei", ""]]}, {"id": "2012.14395", "submitter": "Anirban Sarkar", "authors": "Anindya Sarkar, Anirban Sarkar, Vineeth N Balasubramanian", "title": "Enhanced Regularizers for Attributional Robustness", "comments": "15 pages, 18 figures, Accepted at AAAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks are the default choice of learning models for computer\nvision tasks. Extensive work has been carried out in recent years on explaining\ndeep models for vision tasks such as classification. However, recent work has\nshown that it is possible for these models to produce substantially different\nattribution maps even when two very similar images are given to the network,\nraising serious questions about trustworthiness. To address this issue, we\npropose a robust attribution training strategy to improve attributional\nrobustness of deep neural networks. Our method carefully analyzes the\nrequirements for attributional robustness and introduces two new regularizers\nthat preserve a model's attribution map during attacks. Our method surpasses\nstate-of-the-art attributional robustness methods by a margin of approximately\n3% to 9% in terms of attribution robustness measures on several datasets\nincluding MNIST, FMNIST, Flower and GTSRB.\n", "versions": [{"version": "v1", "created": "Mon, 28 Dec 2020 18:18:39 GMT"}], "update_date": "2020-12-29", "authors_parsed": [["Sarkar", "Anindya", ""], ["Sarkar", "Anirban", ""], ["Balasubramanian", "Vineeth N", ""]]}, {"id": "2012.14430", "submitter": "Ismail Mustapha", "authors": "Ismail B. Mustapha, Shafaatunnur Hasan, Sunday O. Olatunji, Siti\n  Mariyam Shamsuddin, Afolabi Kazeem", "title": "Effective Email Spam Detection System using Extreme Gradient Boosting", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The popularity, cost-effectiveness and ease of information exchange that\nelectronic mails offer to electronic device users has been plagued with the\nrising number of unsolicited or spam emails. Driven by the need to protect\nemail users from this growing menace, research in spam email\nfiltering/detection systems has being increasingly active in the last decade.\nHowever, the adaptive nature of spam emails has often rendered most of these\nsystems ineffective. While several spam detection models have been reported in\nliterature, the reported performance on an out of sample test data shows the\nroom for more improvement. Presented in this research is an improved spam\ndetection model based on Extreme Gradient Boosting (XGBoost) which to the best\nof our knowledge has received little attention spam email detection problems.\nExperimental results show that the proposed model outperforms earlier\napproaches across a wide range of evaluation metrics. A thorough analysis of\nthe model results in comparison to the results of earlier works is also\npresented.\n", "versions": [{"version": "v1", "created": "Sun, 27 Dec 2020 15:23:58 GMT"}], "update_date": "2021-01-01", "authors_parsed": [["Mustapha", "Ismail B.", ""], ["Hasan", "Shafaatunnur", ""], ["Olatunji", "Sunday O.", ""], ["Shamsuddin", "Siti Mariyam", ""], ["Kazeem", "Afolabi", ""]]}, {"id": "2012.14456", "submitter": "Shiv Ram Dubey", "authors": "Jayendra Kantipudi, Shiv Ram Dubey, Soumendu Chakraborty", "title": "Color Channel Perturbation Attacks for Fooling Convolutional Neural\n  Networks and A Defense Against Such Attacks", "comments": "Accepted in IEEE Transactions on Artificial Intelligence", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Convolutional Neural Networks (CNNs) have emerged as a very powerful data\ndependent hierarchical feature extraction method. It is widely used in several\ncomputer vision problems. The CNNs learn the important visual features from\ntraining samples automatically. It is observed that the network overfits the\ntraining samples very easily. Several regularization methods have been proposed\nto avoid the overfitting. In spite of this, the network is sensitive to the\ncolor distribution within the images which is ignored by the existing\napproaches. In this paper, we discover the color robustness problem of CNN by\nproposing a Color Channel Perturbation (CCP) attack to fool the CNNs. In CCP\nattack new images are generated with new channels created by combining the\noriginal channels with the stochastic weights. Experiments were carried out\nover widely used CIFAR10, Caltech256 and TinyImageNet datasets in the image\nclassification framework. The VGG, ResNet and DenseNet models are used to test\nthe impact of the proposed attack. It is observed that the performance of the\nCNNs degrades drastically under the proposed CCP attack. Result show the effect\nof the proposed simple CCP attack over the robustness of the CNN trained model.\nThe results are also compared with existing CNN fooling approaches to evaluate\nthe accuracy drop. We also propose a primary defense mechanism to this problem\nby augmenting the training dataset with the proposed CCP attack. The\nstate-of-the-art performance using the proposed solution in terms of the CNN\nrobustness under CCP attack is observed in the experiments. The code is made\npublicly available at\n\\url{https://github.com/jayendrakantipudi/Color-Channel-Perturbation-Attack}.\n", "versions": [{"version": "v1", "created": "Sun, 20 Dec 2020 11:35:29 GMT"}], "update_date": "2021-01-01", "authors_parsed": [["Kantipudi", "Jayendra", ""], ["Dubey", "Shiv Ram", ""], ["Chakraborty", "Soumendu", ""]]}, {"id": "2012.14464", "submitter": "Alberto Camacho", "authors": "Alberto Camacho, Jacob Varley, Deepali Jain, Atil Iscen and Dmitry\n  Kalashnikov", "title": "Disentangled Planning and Control in Vision Based Robotics via Reward\n  Machines", "comments": "Accepted to the Deep Reinforcement Learning Workshop at Neural\n  Information Processing Systems (2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we augment a Deep Q-Learning agent with a Reward Machine (DQRM)\nto increase speed of learning vision-based policies for robot tasks, and\novercome some of the limitations of DQN that prevent it from converging to\ngood-quality policies. A reward machine (RM) is a finite state machine that\ndecomposes a task into a discrete planning graph and equips the agent with a\nreward function to guide it toward task completion. The reward machine can be\nused for both reward shaping, and informing the policy what abstract state it\nis currently at. An abstract state is a high level simplification of the\ncurrent state, defined in terms of task relevant features. These two\nsupervisory signals of reward shaping and knowledge of current abstract state\ncoming from the reward machine complement each other and can both be used to\nimprove policy performance as demonstrated on several vision based robotic pick\nand place tasks. Particularly for vision based robotics applications, it is\noften easier to build a reward machine than to try and get a policy to learn\nthe task without this structure.\n", "versions": [{"version": "v1", "created": "Mon, 28 Dec 2020 19:54:40 GMT"}], "update_date": "2021-01-01", "authors_parsed": [["Camacho", "Alberto", ""], ["Varley", "Jacob", ""], ["Jain", "Deepali", ""], ["Iscen", "Atil", ""], ["Kalashnikov", "Dmitry", ""]]}, {"id": "2012.14474", "submitter": "Benjamin Goertzel", "authors": "Ben Goertzel", "title": "Paraconsistent Foundations for Probabilistic Reasoning, Programming and\n  Concept Formation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is argued that 4-valued paraconsistent truth values (called here \"p-bits\")\ncan serve as a conceptual, mathematical and practical foundation for highly\nAI-relevant forms of probabilistic logic and probabilistic programming and\nconcept formation.\n  First it is shown that appropriate averaging-across-situations and\nrenormalization of 4-valued p-bits operating in accordance with Constructible\nDuality (CD) logic yields PLN (Probabilistic Logic Networks)\nstrength-and-confidence truth values. Then variations on the Curry-Howard\ncorrespondence are used to map these paraconsistent and probabilistic logics\ninto probabilistic types suitable for use within dependent type based\nprogramming languages.\n  Zach Weber's paraconsistent analysis of the sorites paradox is extended to\nform a paraconsistent / probabilistic / fuzzy analysis of concept boundaries;\nand a paraconsistent version of concept formation via Formal Concept Analysis\nis presented, building on a definition of fuzzy property-value degrees in terms\nof relative entropy on paraconsistent probability distributions.\n  These general points are fleshed out via reference to the realization of\nprobabilistic reasoning and programming and concept formation in the OpenCog\nAGI framework which is centered on collaborative multi-algorithm updating of a\ncommon knowledge metagraph.\n", "versions": [{"version": "v1", "created": "Mon, 28 Dec 2020 20:14:49 GMT"}, {"version": "v2", "created": "Thu, 14 Jan 2021 17:51:17 GMT"}], "update_date": "2021-01-15", "authors_parsed": [["Goertzel", "Ben", ""]]}, {"id": "2012.14516", "submitter": "Khoa Nguyen Van", "authors": "Van-Khoa Nguyen, Santiago Agudelo", "title": "Synergy between Observation Systems Oceanic in Turbulent Regions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.ao-ph cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ocean dynamics constitute a source of incertitude in determining the ocean's\nrole in complex climatic phenomena. Current observation systems have\nlimitations in achieving sufficiently statistical precision for\nthree-dimensional oceanic data. It is crucial knowledge to describe the\nbehavior of internal ocean structures. We present the data-driven approaches\nwhich explore latent class regressions and deep regression neural networks in\nmodeling ocean dynamics in the extensions of Gulf Stream and Kuroshio currents.\nThe obtained results show a promising data-driven direction for understanding\nthe ocean's characteristics, including salinity and temperature, in both\nspatial and temporal dimensions in the turbulent regions. Our source codes are\npublicly available at https://github.com/v18nguye/gulfstream-lrm and at\nhttps://github.com/sagudelor/Kuroshio.\n", "versions": [{"version": "v1", "created": "Mon, 28 Dec 2020 22:52:57 GMT"}, {"version": "v2", "created": "Wed, 27 Jan 2021 16:21:31 GMT"}], "update_date": "2021-01-28", "authors_parsed": [["Nguyen", "Van-Khoa", ""], ["Agudelo", "Santiago", ""]]}, {"id": "2012.14536", "submitter": "Arnaud Fickinger", "authors": "Arnaud Fickinger, Simon Zhuang, Andrew Critch, Dylan Hadfield-Menell,\n  Stuart Russell", "title": "Multi-Principal Assistance Games: Definition and Collegial Mechanisms", "comments": "arXiv admin note: text overlap with arXiv:2007.09540", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce the concept of a multi-principal assistance game (MPAG), and\ncircumvent an obstacle in social choice theory, Gibbard's theorem, by using a\nsufficiently collegial preference inference mechanism. In an MPAG, a single\nagent assists N human principals who may have widely different preferences.\nMPAGs generalize assistance games, also known as cooperative inverse\nreinforcement learning games. We analyze in particular a generalization of\napprenticeship learning in which the humans first perform some work to obtain\nutility and demonstrate their preferences, and then the robot acts to further\nmaximize the sum of human payoffs. We show in this setting that if the game is\nsufficiently collegial, i.e. if the humans are responsible for obtaining a\nsufficient fraction of the rewards through their own actions, then their\npreferences are straightforwardly revealed through their work. This revelation\nmechanism is non-dictatorial, does not limit the possible outcomes to two\nalternatives, and is dominant-strategy incentive-compatible.\n", "versions": [{"version": "v1", "created": "Tue, 29 Dec 2020 00:06:47 GMT"}], "update_date": "2021-01-01", "authors_parsed": [["Fickinger", "Arnaud", ""], ["Zhuang", "Simon", ""], ["Critch", "Andrew", ""], ["Hadfield-Menell", "Dylan", ""], ["Russell", "Stuart", ""]]}, {"id": "2012.14569", "submitter": "Shuchang Lyu", "authors": "Qi Zhao, Shuchang Lyu, Yuewen Li, Yujing Ma, Lijiang Chen", "title": "MGML: Multi-Granularity Multi-Level Feature Ensemble Network for Remote\n  Sensing Scene Classification", "comments": "14 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Remote sensing (RS) scene classification is a challenging task to predict\nscene categories of RS images. RS images have two main characters: large\nintra-class variance caused by large resolution variance and confusing\ninformation from large geographic covering area. To ease the negative influence\nfrom the above two characters. We propose a Multi-granularity Multi-Level\nFeature Ensemble Network (MGML-FENet) to efficiently tackle RS scene\nclassification task in this paper. Specifically, we propose Multi-granularity\nMulti-Level Feature Fusion Branch (MGML-FFB) to extract multi-granularity\nfeatures in different levels of network by channel-separate feature generator\n(CS-FG). To avoid the interference from confusing information, we propose\nMulti-granularity Multi-Level Feature Ensemble Module (MGML-FEM) which can\nprovide diverse predictions by full-channel feature generator (FC-FG). Compared\nto previous methods, our proposed networks have ability to use structure\ninformation and abundant fine-grained features. Furthermore, through ensemble\nlearning method, our proposed MGML-FENets can obtain more convincing final\npredictions. Extensive classification experiments on multiple RS datasets (AID,\nNWPU-RESISC45, UC-Merced and VGoogle) demonstrate that our proposed networks\nachieve better performance than previous state-of-the-art (SOTA) networks. The\nvisualization analysis also shows the good interpretability of MGML-FENet.\n", "versions": [{"version": "v1", "created": "Tue, 29 Dec 2020 02:18:11 GMT"}], "update_date": "2021-01-01", "authors_parsed": [["Zhao", "Qi", ""], ["Lyu", "Shuchang", ""], ["Li", "Yuewen", ""], ["Ma", "Yujing", ""], ["Chen", "Lijiang", ""]]}, {"id": "2012.14581", "submitter": "Mehdi Mashayekhi", "authors": "Mehdi Mashayekhi and Nirav Ajmeri and George F. List and Munindar P.\n  Singh", "title": "Prosocial Norm Emergence in Multiagent Systems", "comments": "17 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multiagent systems provide a basis of developing systems of autonomous\nentities and thus find application in a variety of domains. We consider a\nsetting where not only the member agents are adaptive but also the multiagent\nsystem itself is adaptive. Specifically, the social structure of a multiagent\nsystem can be reflected in the social norms among its members. It is well\nrecognized that the norms that arise in society are not always beneficial to\nits members. We focus on prosocial norms, which help achieve positive outcomes\nfor society and often provide guidance to agents to act in a manner that takes\ninto account the welfare of others.\n  Specifically, we propose Cha, a framework for the emergence of prosocial\nnorms. Unlike previous norm emergence approaches, Cha supports continual change\nto a system (agents may enter and leave), and dynamism (norms may change when\nthe environment changes). Importantly, Cha agents incorporate prosocial\ndecision making based on inequity aversion theory, reflecting an intuition of\nguilt from being antisocial. In this manner, Cha brings together two important\nthemes in prosociality: decision making by individuals and fairness of\nsystem-level outcomes. We demonstrate via simulation that Cha can improve\naggregate societal gains and fairness of outcomes.\n", "versions": [{"version": "v1", "created": "Tue, 29 Dec 2020 02:59:55 GMT"}], "update_date": "2021-01-01", "authors_parsed": [["Mashayekhi", "Mehdi", ""], ["Ajmeri", "Nirav", ""], ["List", "George F.", ""], ["Singh", "Munindar P.", ""]]}, {"id": "2012.14601", "submitter": "Taylor Webb", "authors": "Taylor W. Webb, Ishan Sinha, Jonathan D. Cohen", "title": "Emergent Symbols through Binding in External Memory", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A key aspect of human intelligence is the ability to infer abstract rules\ndirectly from high-dimensional sensory data, and to do so given only a limited\namount of training experience. Deep neural network algorithms have proven to be\na powerful tool for learning directly from high-dimensional data, but currently\nlack this capacity for data-efficient induction of abstract rules, leading some\nto argue that symbol-processing mechanisms will be necessary to account for\nthis capacity. In this work, we take a step toward bridging this gap by\nintroducing the Emergent Symbol Binding Network (ESBN), a recurrent network\naugmented with an external memory that enables a form of variable-binding and\nindirection. This binding mechanism allows symbol-like representations to\nemerge through the learning process without the need to explicitly incorporate\nsymbol-processing machinery, enabling the ESBN to learn rules in a manner that\nis abstracted away from the particular entities to which those rules apply.\nAcross a series of tasks, we show that this architecture displays nearly\nperfect generalization of learned rules to novel entities given only a limited\nnumber of training examples, and outperforms a number of other competitive\nneural network architectures.\n", "versions": [{"version": "v1", "created": "Tue, 29 Dec 2020 04:28:32 GMT"}, {"version": "v2", "created": "Wed, 10 Mar 2021 01:13:38 GMT"}], "update_date": "2021-03-11", "authors_parsed": [["Webb", "Taylor W.", ""], ["Sinha", "Ishan", ""], ["Cohen", "Jonathan D.", ""]]}, {"id": "2012.14617", "submitter": "Mingyu Fan", "authors": "Yuchen Sun and Dongchun Ren and Shiqi Lian and Mingyu Fan and Xiangyi\n  Teng", "title": "An Efficient Generation Method based on Dynamic Curvature of the\n  Reference Curve for Robust Trajectory Planning", "comments": "no comments", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Trajectory planning is a fundamental task on various autonomous driving\nplatforms, such as social robotics and self-driving cars. Many trajectory\nplanning algorithms use a reference curve based Frenet frame with time to\nreduce the planning dimension. However, there is a common implicit assumption\nin classic trajectory planning approaches, which is that the generated\ntrajectory should follow the reference curve continuously. This assumption is\nnot always true in real applications and it might cause some undesired issues\nin planning. One issue is that the projection of the planned trajectory onto\nthe reference curve maybe discontinuous. Then, some segments on the reference\ncurve are not the image of any part of the planned path. Another issue is that\nthe planned path might self-intersect when following a simple reference curve\ncontinuously. The generated trajectories are unnatural and suboptimal ones when\nthese issues happen. In this paper, we firstly demonstrate these issues and\nthen introduce an efficient trajectory generation method which uses a new\ntransformation from the Cartesian frame to Frenet frames. Experimental results\non a simulated street scenario demonstrated the effectiveness of the proposed\nmethod.\n", "versions": [{"version": "v1", "created": "Tue, 29 Dec 2020 05:49:37 GMT"}], "update_date": "2021-01-01", "authors_parsed": [["Sun", "Yuchen", ""], ["Ren", "Dongchun", ""], ["Lian", "Shiqi", ""], ["Fan", "Mingyu", ""], ["Teng", "Xiangyi", ""]]}, {"id": "2012.14619", "submitter": "Mo Zhang", "authors": "Mo Zhang, Quanzheng Li", "title": "MS-GWNN:multi-scale graph wavelet neural network for breast cancer\n  diagnosis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Breast cancer is one of the most common cancers in women worldwide, and early\ndetection can significantly reduce the mortality rate of breast cancer. It is\ncrucial to take multi-scale information of tissue structure into account in the\ndetection of breast cancer. And thus, it is the key to design an accurate\ncomputer-aided detection (CAD) system to capture multi-scale contextual\nfeatures in a cancerous tissue. In this work, we present a novel graph\nconvolutional neural network for histopathological image classification of\nbreast cancer. The new method, named multi-scale graph wavelet neural network\n(MS-GWNN), leverages the localization property of spectral graph wavelet to\nperform multi-scale analysis. By aggregating features at different scales,\nMS-GWNN can encode the multi-scale contextual interactions in the whole\npathological slide. Experimental results on two public datasets demonstrate the\nsuperiority of the proposed method. Moreover, through ablation studies, we find\nthat multi-scale analysis has a significant impact on the accuracy of cancer\ndiagnosis.\n", "versions": [{"version": "v1", "created": "Tue, 29 Dec 2020 06:04:27 GMT"}], "update_date": "2021-01-01", "authors_parsed": [["Zhang", "Mo", ""], ["Li", "Quanzheng", ""]]}, {"id": "2012.14654", "submitter": "Dong Eui Chang", "authors": "Xiaowei Xing, Dong Eui Chang", "title": "The Adaptive Dynamic Programming Toolbox", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.AI cs.LG cs.RO cs.SY eess.SY", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  The paper develops the Adaptive Dynamic Programming Toolbox (ADPT), which\nsolves optimal control problems for continuous-time nonlinear systems. Based on\nthe adaptive dynamic programming technique, the ADPT computes optimal feedback\ncontrols from the system dynamics in the model-based working mode, or from\nmeasurements of trajectories of the system in the model-free working mode\nwithout the requirement of knowledge of the system model. Multiple options are\nprovided such that the ADPT can accommodate various customized circumstances.\nCompared to other popular software toolboxes for optimal control, the ADPT\nenjoys its computational precision and speed, which is illustrated with its\napplications to a satellite attitude control problem.\n", "versions": [{"version": "v1", "created": "Tue, 29 Dec 2020 08:28:31 GMT"}], "update_date": "2021-01-01", "authors_parsed": [["Xing", "Xiaowei", ""], ["Chang", "Dong Eui", ""]]}, {"id": "2012.14666", "submitter": "Baolin Peng", "authors": "Baolin Peng, Chunyuan Li, Zhu Zhang, Chenguang Zhu, Jinchao Li,\n  Jianfeng Gao", "title": "RADDLE: An Evaluation Benchmark and Analysis Platform for Robust\n  Task-oriented Dialog Systems", "comments": "12 pages; Project website at aka.ms/raddle", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  For task-oriented dialog systems to be maximally useful, it must be able to\nprocess conversations in a way that is (1) generalizable with a small number of\ntraining examples for new task domains, and (2) robust to user input in various\nstyles, modalities or domains. In pursuit of these goals, we introduce the\nRADDLE benchmark, a collection of corpora and tools for evaluating the\nperformance of models across a diverse set of domains. By including tasks with\nlimited training data, RADDLE is designed to favor and encourage models with a\nstrong generalization ability. RADDLE also includes a diagnostic checklist that\nfacilitates detailed robustness analysis in aspects such as language\nvariations, speech errors, unseen entities, and out-of-domain utterances. We\nevaluate recent state-of-the-art systems based on pre-training and fine-tuning,\nand find that grounded pre-training on heterogeneous dialog corpora performs\nbetter than training a separate model per domain. Overall, existing models are\nless than satisfactory in robustness evaluation, which suggests opportunities\nfor future improvement.\n", "versions": [{"version": "v1", "created": "Tue, 29 Dec 2020 08:58:49 GMT"}], "update_date": "2021-01-01", "authors_parsed": [["Peng", "Baolin", ""], ["Li", "Chunyuan", ""], ["Zhang", "Zhu", ""], ["Zhu", "Chenguang", ""], ["Li", "Jinchao", ""], ["Gao", "Jianfeng", ""]]}, {"id": "2012.14670", "submitter": "Gersende Fort", "authors": "Gersende Fort (IMT), P. Gach (IMT), E. Moulines (CMAP, XPOP)", "title": "Fast Incremental Expectation Maximization for finite-sum optimization:\n  nonasymptotic convergence", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fast Incremental Expectation Maximization (FIEM) is a version of the EM\nframework for large datasets. In this paper, we first recast FIEM and other\nincremental EM type algorithms in the {\\em Stochastic Approximation within EM}\nframework. Then, we provide nonasymptotic bounds for the convergence in\nexpectation as a function of the number of examples $n$ and of the maximal\nnumber of iterations $\\kmax$. We propose two strategies for achieving an\n$\\epsilon$-approximate stationary point, respectively with $\\kmax =\nO(n^{2/3}/\\epsilon)$ and $\\kmax = O(\\sqrt{n}/\\epsilon^{3/2})$, both strategies\nrelying on a random termination rule before $\\kmax$ and on a constant step size\nin the Stochastic Approximation step. Our bounds provide some improvements on\nthe literature. First, they allow $\\kmax$ to scale as $\\sqrt{n}$ which is\nbetter than $n^{2/3}$ which was the best rate obtained so far; it is at the\ncost of a larger dependence upon the tolerance $\\epsilon$, thus making this\ncontrol relevant for small to medium accuracy with respect to the number of\nexamples $n$. Second, for the $n^{2/3}$-rate, the numerical illustrations show\nthat thanks to an optimized choice of the step size and of the bounds in terms\nof quantities characterizing the optimization problem at hand, our results\ndesig a less conservative choice of the step size and provide a better control\nof the convergence in expectation.\n", "versions": [{"version": "v1", "created": "Tue, 29 Dec 2020 09:11:42 GMT"}], "update_date": "2021-01-01", "authors_parsed": [["Fort", "Gersende", "", "IMT"], ["Gach", "P.", "", "IMT"], ["Moulines", "E.", "", "CMAP, XPOP"]]}, {"id": "2012.14681", "submitter": "Sathish Indurthi", "authors": "Hyojung Han, Sathish Indurthi, Mohd Abbas Zaidi, Nikhil Kumar\n  Lakumarapu, Beomseok Lee, Sangha Kim, Chanwoo Kim, Inchul Hwang", "title": "Faster Re-translation Using Non-Autoregressive Model For Simultaneous\n  Neural Machine Translation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recently, simultaneous translation has gathered a lot of attention since it\nenables compelling applications such as subtitle translation for a live event\nor real-time video-call translation. Some of these translation applications\nallow editing of partial translation giving rise to re-translation approaches.\nThe current re-translation approaches are based on autoregressive sequence\ngeneration models (ReTA), which generate tar-get tokens in the (partial)\ntranslation sequentially. The multiple re-translations with sequential\ngeneration inReTAmodelslead to an increased inference time gap between the\nincoming source input and the corresponding target output as the source input\ngrows. Besides, due to the large number of inference operations involved, the\nReTA models are not favorable for resource-constrained devices. In this work,\nwe propose a faster re-translation system based on a non-autoregressive\nsequence generation model (FReTNA) to overcome the aforementioned limitations.\nWe evaluate the proposed model on multiple translation tasks and our model\nreduces the inference times by several orders and achieves a competitive\nBLEUscore compared to the ReTA and streaming (Wait-k) models.The proposed model\nreduces the average computation time by a factor of 20 when compared to the\nReTA model by incurring a small drop in the translation quality. It also\noutperforms the streaming-based Wait-k model both in terms of computation time\n(1.5 times lower) and translation quality.\n", "versions": [{"version": "v1", "created": "Tue, 29 Dec 2020 09:43:27 GMT"}, {"version": "v2", "created": "Wed, 2 Jun 2021 03:45:18 GMT"}], "update_date": "2021-06-03", "authors_parsed": [["Han", "Hyojung", ""], ["Indurthi", "Sathish", ""], ["Zaidi", "Mohd Abbas", ""], ["Lakumarapu", "Nikhil Kumar", ""], ["Lee", "Beomseok", ""], ["Kim", "Sangha", ""], ["Kim", "Chanwoo", ""], ["Hwang", "Inchul", ""]]}, {"id": "2012.14716", "submitter": "Qianqian Pan", "authors": "Qianqian Pan, Jun Wu, Xi Zheng, Jianhua Li, Shenghong Li, Athanasios\n  V. Vasilakos", "title": "Leveraging AI and Intelligent Reflecting Surface for Energy-Efficient\n  Communication in 6G IoT", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.AI cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ever-increasing data traffic, various delay-sensitive services, and the\nmassive deployment of energy-limited Internet of Things (IoT) devices have\nbrought huge challenges to the current communication networks, motivating\nacademia and industry to move to the sixth-generation (6G) network. With the\npowerful capability of data transmission and processing, 6G is considered as an\nenabler for IoT communication with low latency and energy cost. In this paper,\nwe propose an artificial intelligence (AI) and intelligent reflecting surface\n(IRS) empowered energy-efficiency communication system for 6G IoT. First, we\ndesign a smart and efficient communication architecture including the IRS-aided\ndata transmission and the AI-driven network resource management mechanisms.\nSecond, an energy efficiency-maximizing model under given transmission latency\nfor 6G IoT system is formulated, which jointly optimizes the settings of all\ncommunication participants, i.e. IoT transmission power, IRS-reflection phase\nshift, and BS detection matrix. Third, a deep reinforcement learning (DRL)\nempowered network resource control and allocation scheme is proposed to solve\nthe formulated optimization model. Based on the network and channel status, the\nDRL-enabled scheme facilities the energy-efficiency and low-latency\ncommunication. Finally, experimental results verified the effectiveness of our\nproposed communication system for 6G IoT.\n", "versions": [{"version": "v1", "created": "Tue, 29 Dec 2020 11:56:28 GMT"}], "update_date": "2021-01-01", "authors_parsed": [["Pan", "Qianqian", ""], ["Wu", "Jun", ""], ["Zheng", "Xi", ""], ["Li", "Jianhua", ""], ["Li", "Shenghong", ""], ["Vasilakos", "Athanasios V.", ""]]}, {"id": "2012.14736", "submitter": "Petr Golovach", "authors": "Fedor V. Fomin, Pierre Fraigniaud, and Petr A. Golovach", "title": "Present-Biased Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.AI cs.MA", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper explores the behavior of present-biased agents, that is, agents\nwho erroneously anticipate the costs of future actions compared to their real\ncosts. Specifically, the paper extends the original framework proposed by\nAkerlof (1991) for studying various aspects of human behavior related to\ntime-inconsistent planning, including procrastination, and abandonment, as well\nas the elegant graph-theoretic model encapsulating this framework recently\nproposed by Kleinberg and Oren (2014). The benefit of this extension is\ntwofold. First, it enables to perform fine grained analysis of the behavior of\npresent-biased agents depending on the optimisation task they have to perform.\nIn particular, we study covering tasks vs. hitting tasks, and show that the\nratio between the cost of the solutions computed by present-biased agents and\nthe cost of the optimal solutions may differ significantly depending on the\nproblem constraints. Second, our extension enables to study not only\nunderestimation of future costs, coupled with minimization problems, but also\nall combinations of minimization/maximization, and\nunderestimation/overestimation. We study the four scenarios, and we establish\nupper bounds on the cost ratio for three of them (the cost ratio for the\noriginal scenario was known to be unbounded), providing a complete global\npicture of the behavior of present-biased agents, as far as optimisation tasks\nare concerned.\n", "versions": [{"version": "v1", "created": "Tue, 29 Dec 2020 12:40:59 GMT"}], "update_date": "2021-01-01", "authors_parsed": [["Fomin", "Fedor V.", ""], ["Fraigniaud", "Pierre", ""], ["Golovach", "Petr A.", ""]]}, {"id": "2012.14758", "submitter": "Veeru Talreja", "authors": "Veeru Talreja, Matthew Valenti, Nasser Nasrabadi", "title": "Deep Hashing for Secure Multimodal Biometrics", "comments": null, "journal-ref": "IEEE Transactions on Information Forensics and\n  Security,vol.16,pp.1306-1321,2021", "doi": "10.1109/TIFS.2020.3033189", "report-no": null, "categories": "cs.CV cs.AI cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When compared to unimodal systems, multimodal biometric systems have several\nadvantages, including lower error rate, higher accuracy, and larger population\ncoverage. However, multimodal systems have an increased demand for integrity\nand privacy because they must store multiple biometric traits associated with\neach user. In this paper, we present a deep learning framework for\nfeature-level fusion that generates a secure multimodal template from each\nuser's face and iris biometrics. We integrate a deep hashing (binarization)\ntechnique into the fusion architecture to generate a robust binary multimodal\nshared latent representation. Further, we employ a hybrid secure architecture\nby combining cancelable biometrics with secure sketch techniques and integrate\nit with a deep hashing framework, which makes it computationally prohibitive to\nforge a combination of multiple biometrics that pass the authentication. The\nefficacy of the proposed approach is shown using a multimodal database of face\nand iris and it is observed that the matching performance is improved due to\nthe fusion of multiple biometrics. Furthermore, the proposed approach also\nprovides cancelability and unlinkability of the templates along with improved\nprivacy of the biometric data. Additionally, we also test the proposed hashing\nfunction for an image retrieval application using a benchmark dataset. The main\ngoal of this paper is to develop a method for integrating multimodal fusion,\ndeep hashing, and biometric security, with an emphasis on structural data from\nmodalities like face and iris. The proposed approach is in no way a general\nbiometric security framework that can be applied to all biometric modalities,\nas further research is needed to extend the proposed framework to other\nunconstrained biometric modalities.\n", "versions": [{"version": "v1", "created": "Tue, 29 Dec 2020 14:15:05 GMT"}], "update_date": "2021-01-01", "authors_parsed": [["Talreja", "Veeru", ""], ["Valenti", "Matthew", ""], ["Nasrabadi", "Nasser", ""]]}, {"id": "2012.14762", "submitter": "Davide Mario Longo", "authors": "Georg Gottlob, Matthias Lanzinger, Davide Mario Longo, Cem Okulmus and\n  Reinhard Pichler", "title": "The HyperTrac Project: Recent Progress and Future Research Directions on\n  Hypergraph Decompositions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Constraint Satisfaction Problems (CSPs) play a central role in many\napplications in Artificial Intelligence and Operations Research. In general,\nsolving CSPs is NP-complete. The structure of CSPs is best described by\nhypergraphs. Therefore, various forms of hypergraph decompositions have been\nproposed in the literature to identify tractable fragments of CSPs. However,\nalso the computation of a concrete hypergraph decomposition is a challenging\ntask in itself. In this paper, we report on recent progress in the study of\nhypergraph decompositions and we outline several directions for future\nresearch.\n", "versions": [{"version": "v1", "created": "Tue, 29 Dec 2020 14:21:54 GMT"}], "update_date": "2021-01-01", "authors_parsed": [["Gottlob", "Georg", ""], ["Lanzinger", "Matthias", ""], ["Longo", "Davide Mario", ""], ["Okulmus", "Cem", ""], ["Pichler", "Reinhard", ""]]}, {"id": "2012.14791", "submitter": "Amir Abolfazli", "authors": "Amir Abolfazli and Eirini Ntoutsi", "title": "Drift-Aware Multi-Memory Model for Imbalanced Data Streams", "comments": null, "journal-ref": null, "doi": "10.1109/BigData50022.2020.9378101", "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Online class imbalance learning deals with data streams that are affected by\nboth concept drift and class imbalance. Online learning tries to find a\ntrade-off between exploiting previously learned information and incorporating\nnew information into the model. This requires both the incremental update of\nthe model and the ability to unlearn outdated information. The improper use of\nunlearning, however, can lead to the retroactive interference problem, a\nphenomenon that occurs when newly learned information interferes with the old\ninformation and impedes the recall of previously learned information. The\nproblem becomes more severe when the classes are not equally represented,\nresulting in the removal of minority information from the model. In this work,\nwe propose the Drift-Aware Multi-Memory Model (DAM3), which addresses the class\nimbalance problem in online learning for memory-based models. DAM3 mitigates\nclass imbalance by incorporating an imbalance-sensitive drift detector,\npreserving a balanced representation of classes in the model, and resolving\nretroactive interference using a working memory that prevents the forgetting of\nold information. We show through experiments on real-world and synthetic\ndatasets that the proposed method mitigates class imbalance and outperforms the\nstate-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Tue, 29 Dec 2020 15:06:30 GMT"}], "update_date": "2021-03-29", "authors_parsed": [["Abolfazli", "Amir", ""], ["Ntoutsi", "Eirini", ""]]}, {"id": "2012.14794", "submitter": "Kim Phuc Tran", "authors": "Zhenglei He (GEMTEX), Kim Phuc Tran (GEMTEX), Sebastien Thomassey\n  (GEMTEX), Xianyi Zeng (GEMTEX), Jie Xu, Chang Haiyi", "title": "A Deep Reinforcement Learning Based Multi-Criteria Decision Support\n  System for Textile Manufacturing Process Optimization", "comments": "arXiv admin note: text overlap with arXiv:2012.01101", "journal-ref": "Computers in Industry, Elsevier, 2020", "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Textile manufacturing is a typical traditional industry involving high\ncomplexity in interconnected processes with limited capacity on the application\nof modern technologies. Decision-making in this domain generally takes multiple\ncriteria into consideration, which usually arouses more complexity. To address\nthis issue, the present paper proposes a decision support system that combines\nthe intelligent data-based random forest (RF) models and a human knowledge\nbased analytical hierarchical process (AHP) multi-criteria structure in\naccordance to the objective and the subjective factors of the textile\nmanufacturing process. More importantly, the textile manufacturing process is\ndescribed as the Markov decision process (MDP) paradigm, and a deep\nreinforcement learning scheme, the Deep Q-networks (DQN), is employed to\noptimize it. The effectiveness of this system has been validated in a case\nstudy of optimizing a textile ozonation process, showing that it can better\nmaster the challenging decision-making tasks in textile manufacturing\nprocesses.\n", "versions": [{"version": "v1", "created": "Tue, 29 Dec 2020 15:09:48 GMT"}], "update_date": "2021-01-01", "authors_parsed": [["He", "Zhenglei", "", "GEMTEX"], ["Tran", "Kim Phuc", "", "GEMTEX"], ["Thomassey", "Sebastien", "", "GEMTEX"], ["Zeng", "Xianyi", "", "GEMTEX"], ["Xu", "Jie", ""], ["Haiyi", "Chang", ""]]}, {"id": "2012.14827", "submitter": "Siru Ouyang", "authors": "Siru Ouyang, Zhuosheng Zhang, Hai Zhao", "title": "Dialogue Graph Modeling for Conversational Machine Reading", "comments": "Findings of ACL: ACL 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conversational Machine Reading (CMR) aims at answering questions in a\ncomplicated manner. Machine needs to answer questions through interactions with\nusers based on given rule document, user scenario and dialogue history, and ask\nquestions to clarify if necessary. In this paper, we propose a dialogue graph\nmodeling framework to improve the understanding and reasoning ability of\nmachine on CMR task. There are three types of graph in total. Specifically,\nDiscourse Graph is designed to learn explicitly and extract the discourse\nrelation among rule texts as well as the extra knowledge of scenario;\nDecoupling Graph is used for understanding local and contextualized connection\nwithin rule texts. And finally a global graph for fusing the information\ntogether and reply to the user with our final decision being either\n\"Yes/No/Irrelevant\" or to ask a follow-up question to clarify.\n", "versions": [{"version": "v1", "created": "Tue, 29 Dec 2020 16:08:36 GMT"}, {"version": "v2", "created": "Sat, 22 May 2021 09:49:27 GMT"}, {"version": "v3", "created": "Sat, 29 May 2021 11:15:08 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Ouyang", "Siru", ""], ["Zhang", "Zhuosheng", ""], ["Zhao", "Hai", ""]]}, {"id": "2012.14840", "submitter": "Vinayak Elangovan", "authors": "Pengchang Chen and Vinayak Elangovan", "title": "Object sorting using faster R-CNN", "comments": "10 pages, 10 figures, 5 tables", "journal-ref": "International Journal of Artificial Intelligence & Applications\n  (IJAIA), Vol.11, No.5/6,November 2020", "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  In a factory production line, different industry parts need to be quickly\ndifferentiated and sorted for further process. Parts can be of different colors\nand shapes. It is tedious for humans to differentiate and sort these objects in\nappropriate categories. Automating this process would save more time and cost.\nIn the automation process, choosing an appropriate model to detect and classify\ndifferent objects based on specific features is more challenging. In this\npaper, three different neural network models are compared to the object sorting\nsystem. They are namely CNN, Fast R-CNN, and Faster R-CNN. These models are\ntested, and their performance is analyzed. Moreover, for the object sorting\nsystem, an Arduino-controlled 5 DoF (degree of freedom) robot arm is programmed\nto grab and drop symmetrical objects to the targeted zone. Objects are\ncategorized into classes based on color, defective and non-defective objects.\n", "versions": [{"version": "v1", "created": "Tue, 29 Dec 2020 16:41:56 GMT"}], "update_date": "2021-01-01", "authors_parsed": [["Chen", "Pengchang", ""], ["Elangovan", "Vinayak", ""]]}, {"id": "2012.14842", "submitter": "Md Ashaduzzaman Rubel Mondol", "authors": "Md Ashaduzzaman Rubel Mondol, Aishwarya Pothula, Deokgun Park", "title": "Modeling Social Interaction for Baby in Simulated Environment for\n  Developmental Robotics", "comments": "5 pages ( Including 1 page reference), 3 figures, Presented at\n  BabyMind workshop, NIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Task-specific AI agents are showing remarkable performance across different\ndomains. But modeling generalized AI agents like human intelligence will\nrequire more than current datasets or only reward-based environments that don't\ninclude experiences that an infant gathers throughout its initial stages. In\nthis paper, we present Simulated Environment for Developmental Robotics\n(SEDRo). It simulates the environments for a baby agent that a human baby\nexperiences throughout the pre-born fetus stage to post-birth 12 months. SEDRo\nalso includes a mother character to provide social interaction with the agent.\nTo evaluate different developmental milestones of the agent, SEDRo incorporates\nsome experiments from developmental psychology.\n", "versions": [{"version": "v1", "created": "Tue, 29 Dec 2020 16:42:50 GMT"}], "update_date": "2021-01-01", "authors_parsed": [["Mondol", "Md Ashaduzzaman Rubel", ""], ["Pothula", "Aishwarya", ""], ["Park", "Deokgun", ""]]}, {"id": "2012.14868", "submitter": "Aolin Xu", "authors": "Aolin Xu, Maxim Raginsky", "title": "Minimum Excess Risk in Bayesian Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.IT math.IT math.ST stat.ML stat.TH", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We analyze the best achievable performance of Bayesian learning under\ngenerative models by defining and upper-bounding the minimum excess risk (MER):\nthe gap between the minimum expected loss attainable by learning from data and\nthe minimum expected loss that could be achieved if the model realization were\nknown. The definition of MER provides a principled way to define different\nnotions of uncertainties in Bayesian learning, including the aleatoric\nuncertainty and the minimum epistemic uncertainty. Two methods for deriving\nupper bounds for the MER are presented. The first method, generally suitable\nfor Bayesian learning with a parametric generative model, upper-bounds the MER\nby the conditional mutual information between the model parameters and the\nquantity being predicted given the observed data. It allows us to quantify the\nrate at which the MER decays to zero as more data becomes available. The second\nmethod, particularly suitable for Bayesian learning with a parametric\npredictive model, relates the MER to the deviation of the posterior predictive\ndistribution from the true predictive model, and further to the minimum\nestimation error of the model parameters from data. It explicitly shows how the\nuncertainty in model parameter estimation translates to the MER and to the\nfinal prediction uncertainty. We also extend the definition and analysis of MER\nto the setting with multiple parametric model families and the setting with\nnonparametric models. Along the discussions we draw some comparisons between\nthe MER in Bayesian learning and the excess risk in frequentist learning.\n", "versions": [{"version": "v1", "created": "Tue, 29 Dec 2020 17:41:30 GMT"}], "update_date": "2021-01-01", "authors_parsed": [["Xu", "Aolin", ""], ["Raginsky", "Maxim", ""]]}, {"id": "2012.14905", "submitter": "Louis Kirsch", "authors": "Louis Kirsch and J\\\"urgen Schmidhuber", "title": "Meta Learning Backpropagation And Improving It", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many concepts have been proposed for meta learning with neural networks\n(NNs), e.g., NNs that learn to control fast weights, hyper networks, learned\nlearning rules, and meta recurrent NNs. Our Variable Shared Meta Learning\n(VS-ML) unifies the above and demonstrates that simple weight-sharing and\nsparsity in an NN is sufficient to express powerful learning algorithms (LAs)\nin a reusable fashion. A simple implementation of VS-ML called VS-ML RNN allows\nfor implementing the backpropagation LA solely by running an RNN in\nforward-mode. It can even meta-learn new LAs that improve upon backpropagation\nand generalize to datasets outside of the meta training distribution without\nexplicit gradient calculation. Introspection reveals that our meta-learned LAs\nlearn qualitatively different from gradient descent through fast association.\n", "versions": [{"version": "v1", "created": "Tue, 29 Dec 2020 18:56:10 GMT"}, {"version": "v2", "created": "Tue, 16 Feb 2021 17:28:31 GMT"}], "update_date": "2021-02-17", "authors_parsed": [["Kirsch", "Louis", ""], ["Schmidhuber", "J\u00fcrgen", ""]]}, {"id": "2012.14942", "submitter": "Daniel Graves PhD", "authors": "Daniel Graves, Jun Jin, Jun Luo", "title": "LISPR: An Options Framework for Policy Reuse with Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a framework for transferring any existing policy from a\npotentially unknown source MDP to a target MDP. This framework (1) enables\nreuse in the target domain of any form of source policy, including classical\ncontrollers, heuristic policies, or deep neural network-based policies, (2)\nattains optimality under suitable theoretical conditions, and (3) guarantees\nimprovement over the source policy in the target MDP. These are achieved by\npackaging the source policy as a black-box option in the target MDP and\nproviding a theoretically grounded way to learn the option's initiation set\nthrough general value functions. Our approach facilitates the learning of new\npolicies by (1) maximizing the target MDP reward with the help of the black-box\noption, and (2) returning the agent to states in the learned initiation set of\nthe black-box option where it is already optimal. We show that these two\nvariants are equivalent in performance under some conditions. Through a series\nof experiments in simulated environments, we demonstrate that our framework\nperforms excellently in sparse reward problems given (sub-)optimal source\npolicies and improves upon prior art in transfer methods such as continual\nlearning and progressive networks, which lack our framework's desirable\ntheoretical properties.\n", "versions": [{"version": "v1", "created": "Tue, 29 Dec 2020 21:05:32 GMT"}], "update_date": "2021-01-01", "authors_parsed": [["Graves", "Daniel", ""], ["Jin", "Jun", ""], ["Luo", "Jun", ""]]}, {"id": "2012.14961", "submitter": "Hongjing Zhang", "authors": "Hongjing Zhang, Ian Davidson", "title": "Towards Fair Deep Anomaly Detection", "comments": "Accepted for publication at the ACM Conference on Fairness,\n  Accountability, and Transparency 2021 (ACM FAccT'21)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Anomaly detection aims to find instances that are considered unusual and is a\nfundamental problem of data science. Recently, deep anomaly detection methods\nwere shown to achieve superior results particularly in complex data such as\nimages. Our work focuses on deep one-class classification for anomaly detection\nwhich learns a mapping only from the normal samples. However, the non-linear\ntransformation performed by deep learning can potentially find patterns\nassociated with social bias. The challenge with adding fairness to deep anomaly\ndetection is to ensure both making fair and correct anomaly predictions\nsimultaneously. In this paper, we propose a new architecture for the fair\nanomaly detection approach (Deep Fair SVDD) and train it using an adversarial\nnetwork to de-correlate the relationships between the sensitive attributes and\nthe learned representations. This differs from how fairness is typically added\nnamely as a regularizer or a constraint. Further, we propose two effective\nfairness measures and empirically demonstrate that existing deep anomaly\ndetection methods are unfair. We show that our proposed approach can remove the\nunfairness largely with minimal loss on the anomaly detection performance.\nLastly, we conduct an in-depth analysis to show the strength and limitations of\nour proposed model, including parameter analysis, feature visualization, and\nrun-time analysis.\n", "versions": [{"version": "v1", "created": "Tue, 29 Dec 2020 22:34:45 GMT"}], "update_date": "2021-01-01", "authors_parsed": [["Zhang", "Hongjing", ""], ["Davidson", "Ian", ""]]}, {"id": "2012.14983", "submitter": "Sabrina Mielke", "authors": "Sabrina J. Mielke, Arthur Szlam, Y-Lan Boureau, Emily Dinan", "title": "Linguistic calibration through metacognition: aligning dialogue agent\n  responses with expected correctness", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Open-domain dialogue agents have vastly improved, but still confidently\nhallucinate knowledge or express doubt when asked straightforward questions. In\nthis work, we analyze whether state-of-the-art chit-chat models can express\nmetacognition capabilities through their responses: does a verbalized\nexpression of doubt (or confidence) match the likelihood that the model's\nanswer is incorrect (or correct)? We find that these models are poorly\ncalibrated in this sense, yet we show that the representations within the\nmodels can be used to accurately predict likelihood of correctness. By\nincorporating these correctness predictions into the training of a controllable\ngeneration model, we obtain a dialogue agent with greatly improved linguistic\ncalibration.\n", "versions": [{"version": "v1", "created": "Wed, 30 Dec 2020 00:12:36 GMT"}], "update_date": "2021-01-01", "authors_parsed": [["Mielke", "Sabrina J.", ""], ["Szlam", "Arthur", ""], ["Boureau", "Y-Lan", ""], ["Dinan", "Emily", ""]]}, {"id": "2012.15010", "submitter": "Wei Xiong", "authors": "Haishan Ye, Wei Xiong, and Tong Zhang", "title": "PMGT-VR: A decentralized proximal-gradient algorithmic framework with\n  variance reduction", "comments": "16 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper considers the decentralized composite optimization problem. We\npropose a novel decentralized variance-reduction proximal-gradient algorithmic\nframework, called PMGT-VR, which is based on a combination of several\ntechniques including multi-consensus, gradient tracking, and variance\nreduction. The proposed framework relies on an imitation of centralized\nalgorithms and we demonstrate that algorithms under this framework achieve\nconvergence rates similar to that of their centralized counterparts. We also\ndescribe and analyze two representative algorithms, PMGT-SAGA and PMGT-LSVRG,\nand compare them to existing state-of-the-art proximal algorithms. To the best\nof our knowledge, PMGT-VR is the first linearly convergent decentralized\nstochastic algorithm that can solve decentralized composite optimization\nproblems. Numerical experiments are provided to demonstrate the effectiveness\nof the proposed algorithms.\n", "versions": [{"version": "v1", "created": "Wed, 30 Dec 2020 02:49:37 GMT"}, {"version": "v2", "created": "Sat, 5 Jun 2021 07:00:53 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Ye", "Haishan", ""], ["Xiong", "Wei", ""], ["Zhang", "Tong", ""]]}, {"id": "2012.15022", "submitter": "Yujia Qin", "authors": "Yujia Qin, Yankai Lin, Ryuichi Takanobu, Zhiyuan Liu, Peng Li, Heng\n  Ji, Minlie Huang, Maosong Sun, Jie Zhou", "title": "ERICA: Improving Entity and Relation Understanding for Pre-trained\n  Language Models via Contrastive Learning", "comments": "Accepted by ACL-IJCNLP 2021 main conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pre-trained Language Models (PLMs) have shown superior performance on various\ndownstream Natural Language Processing (NLP) tasks. However, conventional\npre-training objectives do not explicitly model relational facts in text, which\nare crucial for textual understanding. To address this issue, we propose a\nnovel contrastive learning framework ERICA to obtain a deep understanding of\nthe entities and their relations in text. Specifically, we define two novel\npre-training tasks to better understand entities and relations: (1) the entity\ndiscrimination task to distinguish which tail entity can be inferred by the\ngiven head entity and relation; (2) the relation discrimination task to\ndistinguish whether two relations are close or not semantically, which involves\ncomplex relational reasoning. Experimental results demonstrate that ERICA can\nimprove typical PLMs (BERT and RoBERTa) on several language understanding\ntasks, including relation extraction, entity typing and question answering,\nespecially under low-resource settings.\n", "versions": [{"version": "v1", "created": "Wed, 30 Dec 2020 03:35:22 GMT"}, {"version": "v2", "created": "Wed, 26 May 2021 05:08:18 GMT"}], "update_date": "2021-05-27", "authors_parsed": [["Qin", "Yujia", ""], ["Lin", "Yankai", ""], ["Takanobu", "Ryuichi", ""], ["Liu", "Zhiyuan", ""], ["Li", "Peng", ""], ["Ji", "Heng", ""], ["Huang", "Minlie", ""], ["Sun", "Maosong", ""], ["Zhou", "Jie", ""]]}, {"id": "2012.15024", "submitter": "Chuxiong Sun", "authors": "Chuxiong Sun, Guoshi Wu", "title": "Adaptive Graph Diffusion Networks with Hop-wise Attention", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph Neural Networks (GNNs) have received much attention recent years and\nhave achieved state-of-the-art performances in many fields. The deeper GNNs can\ntheoretically capture deeper neighborhood information. However, they often\nsuffer from problems of over-fitting and over-smoothing. In order to\nincorporate deeper information while preserving considerable complexity and\ngeneralization ability, we propose Adaptive Graph Diffusion Networks with\nHop-wise Attention (AGDNs-HA). We stack multi-hop neighborhood aggregations of\ndifferent orders into single layer. Then we integrate them with the help of\nhop-wise attention, which is learnable and adaptive for each node. Experimental\nresults on the standard dataset with semi-supervised node classification task\nshow that our proposed methods achieve significant improvements.\n", "versions": [{"version": "v1", "created": "Wed, 30 Dec 2020 03:43:04 GMT"}], "update_date": "2021-01-01", "authors_parsed": [["Sun", "Chuxiong", ""], ["Wu", "Guoshi", ""]]}, {"id": "2012.15037", "submitter": "Jindong Han", "authors": "Jindong Han, Hao Liu, Hengshu Zhu, Hui Xiong, Dejing Dou", "title": "Joint Air Quality and Weather Prediction Based on Multi-Adversarial\n  Spatiotemporal Networks", "comments": "9 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Accurate and timely air quality and weather predictions are of great\nimportance to urban governance and human livelihood. Though many efforts have\nbeen made for air quality or weather prediction, most of them simply employ one\nanother as feature input, which ignores the inner-connection between two\npredictive tasks. On the one hand, the accurate prediction of one task can help\nimprove another task's performance. On the other hand, geospatially distributed\nair quality and weather monitoring stations provide additional hints for\ncity-wide spatiotemporal dependency modeling. Inspired by the above two\ninsights, in this paper, we propose the Multi-adversarial spatiotemporal\nrecurrent Graph Neural Networks (MasterGNN) for joint air quality and weather\npredictions. Specifically, we first propose a heterogeneous recurrent graph\nneural network to model the spatiotemporal autocorrelation among air quality\nand weather monitoring stations. Then, we develop a multi-adversarial graph\nlearning framework to against observation noise propagation introduced by\nspatiotemporal modeling. Moreover, we present an adaptive training strategy by\nformulating multi-adversarial learning as a multi-task learning problem.\nFinally, extensive experiments on two real-world datasets show that MasterGNN\nachieves the best performance compared with seven baselines on both air quality\nand weather prediction tasks.\n", "versions": [{"version": "v1", "created": "Wed, 30 Dec 2020 04:42:03 GMT"}, {"version": "v2", "created": "Tue, 5 Jan 2021 04:51:56 GMT"}], "update_date": "2021-01-06", "authors_parsed": [["Han", "Jindong", ""], ["Liu", "Hao", ""], ["Zhu", "Hengshu", ""], ["Xiong", "Hui", ""], ["Dou", "Dejing", ""]]}, {"id": "2012.15081", "submitter": "Mingqi Yuan", "authors": "Mingqi Yuan, Qi Cao, Man-on Pun, Yi Chen", "title": "Fairness-Oriented User Scheduling for Bursty Downlink Transmission Using\n  Multi-Agent Reinforcement Learning", "comments": "14 pages, 15 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.OS cs.AI cs.LG cs.NI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this work, we develop practical user scheduling algorithms for downlink\nbursty traffic with emphasis on user fairness. In contrast to the conventional\nscheduling algorithms that either equally divides the transmission time slots\namong users or maximizing some ratios without physcial meanings, we propose to\nuse the 5%-tile user data rate (5TUDR) as the metric to evaluate user fairness.\nSince it is difficult to directly optimize 5TUDR, we first cast the problem\ninto the stochastic game framework and subsequently propose a Multi-Agent\nReinforcement Learning (MARL)-based algorithm to perform distributed\noptimization on the resource block group (RBG) allocation. Furthermore, each\nMARL agent is designed to take information measured by network counters from\nmultiple network layers (e.g. Channel Quality Indicator, Buffer size) as the\ninput states while the RBG allocation as action with a proposed reward function\ndesigned to maximize 5TUDR. Extensive simulation is performed to show that the\nproposed MARL-based scheduler can achieve fair scheduling while maintaining\ngood average network throughput as compared to conventional schedulers.\n", "versions": [{"version": "v1", "created": "Wed, 30 Dec 2020 08:41:51 GMT"}, {"version": "v10", "created": "Fri, 30 Apr 2021 08:09:39 GMT"}, {"version": "v11", "created": "Tue, 11 May 2021 13:51:29 GMT"}, {"version": "v2", "created": "Tue, 26 Jan 2021 02:55:02 GMT"}, {"version": "v3", "created": "Thu, 4 Feb 2021 03:14:17 GMT"}, {"version": "v4", "created": "Thu, 11 Feb 2021 16:00:14 GMT"}, {"version": "v5", "created": "Mon, 15 Feb 2021 16:53:45 GMT"}, {"version": "v6", "created": "Tue, 16 Feb 2021 06:06:10 GMT"}, {"version": "v7", "created": "Thu, 18 Feb 2021 02:30:27 GMT"}, {"version": "v8", "created": "Sun, 7 Mar 2021 12:20:34 GMT"}, {"version": "v9", "created": "Mon, 19 Apr 2021 07:08:08 GMT"}], "update_date": "2021-05-12", "authors_parsed": [["Yuan", "Mingqi", ""], ["Cao", "Qi", ""], ["Pun", "Man-on", ""], ["Chen", "Yi", ""]]}, {"id": "2012.15085", "submitter": "Ying Jin", "authors": "Ying Jin, Zhuoran Yang, Zhaoran Wang", "title": "Is Pessimism Provably Efficient for Offline RL?", "comments": "60 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI math.OC math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study offline reinforcement learning (RL), which aims to learn an optimal\npolicy based on a dataset collected a priori. Due to the lack of further\ninteractions with the environment, offline RL suffers from the insufficient\ncoverage of the dataset, which eludes most existing theoretical analysis. In\nthis paper, we propose a pessimistic variant of the value iteration algorithm\n(PEVI), which incorporates an uncertainty quantifier as the penalty function.\nSuch a penalty function simply flips the sign of the bonus function for\npromoting exploration in online RL, which makes it easily implementable and\ncompatible with general function approximators.\n  Without assuming the sufficient coverage of the dataset, we establish a\ndata-dependent upper bound on the suboptimality of PEVI for general Markov\ndecision processes (MDPs). When specialized to linear MDPs, it matches the\ninformation-theoretic lower bound up to multiplicative factors of the dimension\nand horizon. In other words, pessimism is not only provably efficient but also\nminimax optimal. In particular, given the dataset, the learned policy serves as\nthe \"best effort\" among all policies, as no other policies can do better. Our\ntheoretical analysis identifies the critical role of pessimism in eliminating a\nnotion of spurious correlation, which emerges from the \"irrelevant\"\ntrajectories that are less covered by the dataset and not informative for the\noptimal policy.\n", "versions": [{"version": "v1", "created": "Wed, 30 Dec 2020 09:06:57 GMT"}, {"version": "v2", "created": "Wed, 12 May 2021 15:05:39 GMT"}], "update_date": "2021-05-13", "authors_parsed": [["Jin", "Ying", ""], ["Yang", "Zhuoran", ""], ["Wang", "Zhaoran", ""]]}, {"id": "2012.15086", "submitter": "Zhuosheng Zhang", "authors": "Zhuosheng Zhang, Haojie Yu, Hai Zhao, Rui Wang, Masao Utiyama", "title": "Accurate Word Representations with Universal Visual Guidance", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Word representation is a fundamental component in neural language\nunderstanding models. Recently, pre-trained language models (PrLMs) offer a new\nperformant method of contextualized word representations by leveraging the\nsequence-level context for modeling. Although the PrLMs generally give more\naccurate contextualized word representations than non-contextualized models do,\nthey are still subject to a sequence of text contexts without diverse hints for\nword representation from multimodality. This paper thus proposes a visual\nrepresentation method to explicitly enhance conventional word embedding with\nmultiple-aspect senses from visual guidance. In detail, we build a small-scale\nword-image dictionary from a multimodal seed dataset where each word\ncorresponds to diverse related images. The texts and paired images are encoded\nin parallel, followed by an attention layer to integrate the multimodal\nrepresentations. We show that the method substantially improves the accuracy of\ndisambiguation. Experiments on 12 natural language understanding and machine\ntranslation tasks further verify the effectiveness and the generalization\ncapability of the proposed approach.\n", "versions": [{"version": "v1", "created": "Wed, 30 Dec 2020 09:11:50 GMT"}], "update_date": "2021-01-01", "authors_parsed": [["Zhang", "Zhuosheng", ""], ["Yu", "Haojie", ""], ["Zhao", "Hai", ""], ["Wang", "Rui", ""], ["Utiyama", "Masao", ""]]}, {"id": "2012.15180", "submitter": "Thang M. Pham", "authors": "Thang M. Pham, Trung Bui, Long Mai, Anh Nguyen", "title": "Out of Order: How Important Is The Sequential Order of Words in a\n  Sentence in Natural Language Understanding Tasks?", "comments": "9+7 pages, 4+4 figures. Findings of ACL 2021 (long paper)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Do state-of-the-art natural language understanding models care about word\norder - one of the most important characteristics of a sequence? Not always! We\nfound 75% to 90% of the correct predictions of BERT-based classifiers, trained\non many GLUE tasks, remain constant after input words are randomly shuffled.\nDespite BERT embeddings are famously contextual, the contribution of each\nindividual word to downstream tasks is almost unchanged even after the word's\ncontext is shuffled. BERT-based models are able to exploit superficial cues\n(e.g. the sentiment of keywords in sentiment analysis; or the word-wise\nsimilarity between sequence-pair inputs in natural language inference) to make\ncorrect decisions when tokens are arranged in random orders. Encouraging\nclassifiers to capture word order information improves the performance on most\nGLUE tasks, SQuAD 2.0 and out-of-samples. Our work suggests that many GLUE\ntasks are not challenging machines to understand the meaning of a sentence.\n", "versions": [{"version": "v1", "created": "Wed, 30 Dec 2020 14:56:12 GMT"}, {"version": "v2", "created": "Mon, 26 Jul 2021 17:55:13 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Pham", "Thang M.", ""], ["Bui", "Trung", ""], ["Mai", "Long", ""], ["Nguyen", "Anh", ""]]}, {"id": "2012.15197", "submitter": "Leilei Gan", "authors": "Leilei Gan, Zhiyang Teng, Yue Zhang, Linchao Zhu, Fei Wu, Yi Yang", "title": "SemGloVe: Semantic Co-occurrences for GloVe from BERT", "comments": "10 pages, 3 figures, 5 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  GloVe learns word embeddings by leveraging statistical information from word\nco-occurrence matrices. However, word pairs in the matrices are extracted from\na predefined local context window, which might lead to limited word pairs and\npotentially semantic irrelevant word pairs. In this paper, we propose SemGloVe,\nwhich distills semantic co-occurrences from BERT into static GloVe word\nembeddings. Particularly, we propose two models to extract co-occurrence\nstatistics based on either the masked language model or the multi-head\nattention weights of BERT. Our methods can extract word pairs without limiting\nby the local window assumption and can define the co-occurrence weights by\ndirectly considering the semantic distance between word pairs. Experiments on\nseveral word similarity datasets and four external tasks show that SemGloVe can\noutperform GloVe.\n", "versions": [{"version": "v1", "created": "Wed, 30 Dec 2020 15:38:26 GMT"}], "update_date": "2021-01-01", "authors_parsed": [["Gan", "Leilei", ""], ["Teng", "Zhiyang", ""], ["Zhang", "Yue", ""], ["Zhu", "Linchao", ""], ["Wu", "Fei", ""], ["Yang", "Yi", ""]]}, {"id": "2012.15203", "submitter": "Manjesh Kumar Hanawal", "authors": "Debamita Ghosh and Manjesh K. Hanawal and Nikola Zlatanov", "title": "Learning to Optimize Energy Efficiency in Energy Harvesting Wireless\n  Sensor Networks", "comments": "5 pages, 4 figures. Under review at IEEE Wireless Communications\n  Letters", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.AI cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We study wireless power transmission by an energy source to multiple energy\nharvesting nodes with the aim to maximize the energy efficiency. The source\ntransmits energy to the nodes using one of the available power levels in each\ntime slot and the nodes transmit information back to the energy source using\nthe harvested energy. The source does not have any channel state information\nand it only knows whether a received codeword from a given node was\nsuccessfully decoded or not. With this limited information, the source has to\nlearn the optimal power level that maximizes the energy efficiency of the\nnetwork. We model the problem as a stochastic Multi-Armed Bandits problem and\ndevelop an Upper Confidence Bound based algorithm, which learns the optimal\ntransmit power of the energy source that maximizes the energy efficiency.\nNumerical results validate the performance guarantees of the proposed algorithm\nand show significant gains compared to the benchmark schemes.\n", "versions": [{"version": "v1", "created": "Wed, 30 Dec 2020 15:51:39 GMT"}], "update_date": "2021-01-01", "authors_parsed": [["Ghosh", "Debamita", ""], ["Hanawal", "Manjesh K.", ""], ["Zlatanov", "Nikola", ""]]}, {"id": "2012.15234", "submitter": "Theodor Cimpeanu", "authors": "Theodor Cimpeanu, Francisco C. Santos, Luis Moniz Pereira, Tom\n  Lenaerts and The Anh Han", "title": "AI Development Race Can Be Mediated on Heterogeneous Networks", "comments": "35 pages, 11 figures, preprint", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.GT", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The field of Artificial Intelligence (AI) has been introducing a certain\nlevel of anxiety in research, business and also policy. Tensions are further\nheightened by an AI race narrative which makes many stakeholders fear that they\nmight be missing out. Whether real or not, a belief in this narrative may be\ndetrimental as some stakeholders will feel obliged to cut corners on safety\nprecautions or ignore societal consequences. Starting from a game-theoretical\nmodel describing an idealised technology race in a well-mixed world, here we\ninvestigate how different interaction structures among race participants can\nalter collective choices and requirements for regulatory actions. Our findings\nindicate that, when participants portray a strong diversity in terms of\nconnections and peer-influence (e.g., when scale-free networks shape\ninteractions among parties), the conflicts that exist in homogeneous settings\nare significantly reduced, thereby lessening the need for regulatory actions.\nFurthermore, our results suggest that technology governance and regulation may\nprofit from the world's patent heterogeneity and inequality among firms and\nnations to design and implement meticulous interventions on a minority of\nparticipants capable of influencing an entire population towards an ethical and\nsustainable use of AI.\n", "versions": [{"version": "v1", "created": "Wed, 30 Dec 2020 17:23:18 GMT"}], "update_date": "2021-01-01", "authors_parsed": [["Cimpeanu", "Theodor", ""], ["Santos", "Francisco C.", ""], ["Pereira", "Luis Moniz", ""], ["Lenaerts", "Tom", ""], ["Han", "The Anh", ""]]}, {"id": "2012.15259", "submitter": "Joshua Lee", "authors": "Joshua Lee, Yuheng Bu, Prasanna Sattigeri, Rameswar Panda, Gregory\n  Wornell, Leonid Karlinsky, Rogerio Feris", "title": "A Maximal Correlation Approach to Imposing Fairness in Machine Learning", "comments": "9 Pages 4 Figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.IT math.IT stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  As machine learning algorithms grow in popularity and diversify to many\nindustries, ethical and legal concerns regarding their fairness have become\nincreasingly relevant. We explore the problem of algorithmic fairness, taking\nan information-theoretic view. The maximal correlation framework is introduced\nfor expressing fairness constraints and shown to be capable of being used to\nderive regularizers that enforce independence and separation-based fairness\ncriteria, which admit optimization algorithms for both discrete and continuous\nvariables which are more computationally efficient than existing algorithms. We\nshow that these algorithms provide smooth performance-fairness tradeoff curves\nand perform competitively with state-of-the-art methods on both discrete\ndatasets (COMPAS, Adult) and continuous datasets (Communities and Crimes).\n", "versions": [{"version": "v1", "created": "Wed, 30 Dec 2020 18:15:05 GMT"}], "update_date": "2021-01-01", "authors_parsed": [["Lee", "Joshua", ""], ["Bu", "Yuheng", ""], ["Sattigeri", "Prasanna", ""], ["Panda", "Rameswar", ""], ["Wornell", "Gregory", ""], ["Karlinsky", "Leonid", ""], ["Feris", "Rogerio", ""]]}, {"id": "2012.15262", "submitter": "Ryuichi Takanobu", "authors": "Jiexi Liu, Ryuichi Takanobu, Jiaxin Wen, Dazhen Wan, Hongguang Li,\n  Weiran Nie, Cheng Li, Wei Peng, Minlie Huang", "title": "Robustness Testing of Language Understanding in Task-Oriented Dialog", "comments": "ACL 2021 long paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most language understanding models in task-oriented dialog systems are\ntrained on a small amount of annotated training data, and evaluated in a small\nset from the same distribution. However, these models can lead to system\nfailure or undesirable output when being exposed to natural language\nperturbation or variation in practice. In this paper, we conduct comprehensive\nevaluation and analysis with respect to the robustness of natural language\nunderstanding models, and introduce three important aspects related to language\nunderstanding in real-world dialog systems, namely, language variety, speech\ncharacteristics, and noise perturbation. We propose a model-agnostic toolkit\nLAUG to approximate natural language perturbations for testing the robustness\nissues in task-oriented dialog. Four data augmentation approaches covering the\nthree aspects are assembled in LAUG, which reveals critical robustness issues\nin state-of-the-art models. The augmented dataset through LAUG can be used to\nfacilitate future research on the robustness testing of language understanding\nin task-oriented dialog.\n", "versions": [{"version": "v1", "created": "Wed, 30 Dec 2020 18:18:47 GMT"}, {"version": "v2", "created": "Sat, 22 May 2021 17:30:54 GMT"}, {"version": "v3", "created": "Fri, 4 Jun 2021 17:21:23 GMT"}], "update_date": "2021-06-07", "authors_parsed": [["Liu", "Jiexi", ""], ["Takanobu", "Ryuichi", ""], ["Wen", "Jiaxin", ""], ["Wan", "Dazhen", ""], ["Li", "Hongguang", ""], ["Nie", "Weiran", ""], ["Li", "Cheng", ""], ["Peng", "Wei", ""], ["Huang", "Minlie", ""]]}, {"id": "2012.15329", "submitter": "Raphael Schumann", "authors": "Raphael Schumann and Stefan Riezler", "title": "Generating Landmark Navigation Instructions from Maps as a Graph-to-Text\n  Problem", "comments": "Accepted at ACL 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Car-focused navigation services are based on turns and distances of named\nstreets, whereas navigation instructions naturally used by humans are centered\naround physical objects called landmarks. We present a neural model that takes\nOpenStreetMap representations as input and learns to generate navigation\ninstructions that contain visible and salient landmarks from human natural\nlanguage instructions. Routes on the map are encoded in a location- and\nrotation-invariant graph representation that is decoded into natural language\ninstructions. Our work is based on a novel dataset of 7,672 crowd-sourced\ninstances that have been verified by human navigation in Street View. Our\nevaluation shows that the navigation instructions generated by our system have\nsimilar properties as human-generated instructions, and lead to successful\nhuman navigation in Street View.\n", "versions": [{"version": "v1", "created": "Wed, 30 Dec 2020 21:22:04 GMT"}, {"version": "v2", "created": "Fri, 7 May 2021 16:13:40 GMT"}, {"version": "v3", "created": "Wed, 26 May 2021 16:07:16 GMT"}], "update_date": "2021-05-27", "authors_parsed": [["Schumann", "Raphael", ""], ["Riezler", "Stefan", ""]]}, {"id": "2012.15358", "submitter": "Ashkan Yousefi Zadeh", "authors": "Ashkan Yousefi Zadeh, Meysam Shahbazy", "title": "A Review into Data Science and Its Approaches in Mechanical Engineering", "comments": "For associated information, see https://civilica.com/doc/1128400/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.RO cs.SY eess.SY", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Nowadays it is inevitable to use intelligent systems to improve the\nperformance and optimization of different components of devices or factories.\nFurthermore, it's so essential to have appropriate predictions to make better\ndecisions in businesses, medical studies, and engineering studies, etc. One of\nthe newest and most widely used of these methods is a field called Data Science\nthat all of the scientists, engineers, and factories need to learn and use in\ntheir careers. This article briefly introduced data science and reviewed its\nmethods, especially it's usages in mechanical engineering and challenges and\nways of developing data science in mechanical engineering. In the introduction,\ndifferent definitions of data science and its background in technology\nreviewed. In the following, data science methodology which is the process that\na data scientist needs to do in its works been discussed. Further, some\nresearches in the mechanical engineering area that used data science methods in\ntheir studies, are reviewed. Eventually, it has been discussed according to the\nsubjects that have been reviewed in the article, why it is necessary to use\ndata science in mechanical engineering researches and projects.\n", "versions": [{"version": "v1", "created": "Wed, 30 Dec 2020 23:05:29 GMT"}], "update_date": "2021-01-01", "authors_parsed": [["Zadeh", "Ashkan Yousefi", ""], ["Shahbazy", "Meysam", ""]]}, {"id": "2012.15373", "submitter": "Stephen Tian", "authors": "Stephen Tian, Suraj Nair, Frederik Ebert, Sudeep Dasari, Benjamin\n  Eysenbach, Chelsea Finn, Sergey Levine", "title": "Model-Based Visual Planning with Self-Supervised Functional Distances", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.RO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  A generalist robot must be able to complete a variety of tasks in its\nenvironment. One appealing way to specify each task is in terms of a goal\nobservation. However, learning goal-reaching policies with reinforcement\nlearning remains a challenging problem, particularly when hand-engineered\nreward functions are not available. Learned dynamics models are a promising\napproach for learning about the environment without rewards or task-directed\ndata, but planning to reach goals with such a model requires a notion of\nfunctional similarity between observations and goal states. We present a\nself-supervised method for model-based visual goal reaching, which uses both a\nvisual dynamics model as well as a dynamical distance function learned using\nmodel-free reinforcement learning. Our approach learns entirely using offline,\nunlabeled data, making it practical to scale to large and diverse datasets. In\nour experiments, we find that our method can successfully learn models that\nperform a variety of tasks at test-time, moving objects amid distractors with a\nsimulated robotic arm and even learning to open and close a drawer using a\nreal-world robot. In comparisons, we find that this approach substantially\noutperforms both model-free and model-based prior methods. Videos and\nvisualizations are available here: http://sites.google.com/berkeley.edu/mbold.\n", "versions": [{"version": "v1", "created": "Wed, 30 Dec 2020 23:59:09 GMT"}], "update_date": "2021-01-01", "authors_parsed": [["Tian", "Stephen", ""], ["Nair", "Suraj", ""], ["Ebert", "Frederik", ""], ["Dasari", "Sudeep", ""], ["Eysenbach", "Benjamin", ""], ["Finn", "Chelsea", ""], ["Levine", "Sergey", ""]]}, {"id": "2012.15375", "submitter": "Weiyan Shi", "authors": "Weiyan Shi, Yu Li, Saurav Sahay, Zhou Yu", "title": "Refine and Imitate: Reducing Repetition and Inconsistency in Persuasion\n  Dialogues via Reinforcement Learning and Human Demonstration", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the recent success of large-scale language models on various\ndownstream NLP tasks, the repetition and inconsistency problems still persist\nin dialogue response generation. Previous approaches have attempted to avoid\nrepetition by penalizing the language model's undesirable behaviors in the loss\nfunction. However, these methods focus on token-level information and can lead\nto incoherent responses and uninterpretable behaviors. To alleviate these\nissues, we propose to apply reinforcement learning to refine an MLE-based\nlanguage model without user simulators, and distill sentence-level information\nabout repetition, inconsistency and task relevance through rewards. In\naddition, to better accomplish the dialogue task, the model learns from human\ndemonstration to imitate intellectual activities such as persuasion, and\nselects the most persuasive responses. Experiments show that our model\noutperforms previous state-of-the-art dialogue models on both automatic metrics\nand human evaluation results on a donation persuasion task, and generates more\ndiverse, consistent and persuasive conversations according to the user\nfeedback.\n", "versions": [{"version": "v1", "created": "Thu, 31 Dec 2020 00:02:51 GMT"}], "update_date": "2021-01-01", "authors_parsed": [["Shi", "Weiyan", ""], ["Li", "Yu", ""], ["Sahay", "Saurav", ""], ["Yu", "Zhou", ""]]}, {"id": "2012.15377", "submitter": "Vaneet Aggarwal", "authors": "Arnob Ghosh and Vaneet Aggarwal", "title": "Model Free Reinforcement Learning Algorithm for Stationary Mean field\n  Equilibrium for Multiple Types of Agents", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI cs.GT cs.LG cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a multi-agent Markov strategic interaction over an infinite\nhorizon where agents can be of multiple types. We model the strategic\ninteraction as a mean-field game in the asymptotic limit when the number of\nagents of each type becomes infinite. Each agent has a private state; the state\nevolves depending on the distribution of the state of the agents of different\ntypes and the action of the agent. Each agent wants to maximize the discounted\nsum of rewards over the infinite horizon which depends on the state of the\nagent and the distribution of the state of the leaders and followers. We seek\nto characterize and compute a stationary multi-type Mean field equilibrium\n(MMFE) in the above game. We characterize the conditions under which a\nstationary MMFE exists. Finally, we propose Reinforcement learning (RL) based\nalgorithm using policy gradient approach to find the stationary MMFE when the\nagents are unaware of the dynamics. We, numerically, evaluate how such kind of\ninteraction can model the cyber attacks among defenders and adversaries, and\nshow how RL based algorithm can converge to an equilibrium.\n", "versions": [{"version": "v1", "created": "Thu, 31 Dec 2020 00:12:46 GMT"}], "update_date": "2021-01-01", "authors_parsed": [["Ghosh", "Arnob", ""], ["Aggarwal", "Vaneet", ""]]}, {"id": "2012.15378", "submitter": "Emad Barsoum", "authors": "Emad Barsoum, John Kender, Zicheng Liu", "title": "3D Human motion anticipation and classification", "comments": "arXiv admin note: substantial text overlap with arXiv:1711.09561", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.HC cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Human motion prediction and understanding is a challenging problem. Due to\nthe complex dynamic of human motion and the non-deterministic aspect of future\nprediction. We propose a novel sequence-to-sequence model for human motion\nprediction and feature learning, trained with a modified version of generative\nadversarial network, with a custom loss function that takes inspiration from\nhuman motion animation and can control the variation between multiple predicted\nmotion from the same input poses.\n  Our model learns to predict multiple future sequences of human poses from the\nsame input sequence. We show that the discriminator learns general presentation\nof human motion by using the learned feature in action recognition task.\nFurthermore, to quantify the quality of the non-deterministic predictions, we\nsimultaneously train a motion-quality-assessment network that learns the\nprobability that a given sequence of poses is a real human motion or not.\n  We test our model on two of the largest human pose datasets: NTURGB-D and\nHuman3.6M. We train on both single and multiple action types. Its predictive\npower for motion estimation is demonstrated by generating multiple plausible\nfutures from the same input and show the effect of each of the loss functions.\nFurthermore, we show that it takes less than half the number of epochs to train\nan activity recognition network by using the feature learned from the\ndiscriminator.\n", "versions": [{"version": "v1", "created": "Thu, 31 Dec 2020 00:19:39 GMT"}], "update_date": "2021-01-01", "authors_parsed": [["Barsoum", "Emad", ""], ["Kender", "John", ""], ["Liu", "Zicheng", ""]]}, {"id": "2012.15416", "submitter": "Damian Pascual", "authors": "Damian Pascual, Beni Egressy, Florian Bolli, Roger Wattenhofer", "title": "Directed Beam Search: Plug-and-Play Lexically Constrained Language\n  Generation", "comments": "Preprint. Work in progress", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large pre-trained language models are capable of generating realistic text.\nHowever, controlling these models so that the generated text satisfies lexical\nconstraints, i.e., contains specific words, is a challenging problem. Given\nthat state-of-the-art language models are too large to be trained from scratch\nin a manageable time, it is desirable to control these models without\nre-training them. Methods capable of doing this are called plug-and-play.\nRecent plug-and-play methods have been successful in constraining small\nbidirectional language models as well as forward models in tasks with a\nrestricted search space, e.g., machine translation. However, controlling large\ntransformer-based models to meet lexical constraints without re-training them\nremains a challenge. In this work, we propose Directed Beam Search (DBS), a\nplug-and-play method for lexically constrained language generation. Our method\ncan be applied to any language model, is easy to implement and can be used for\ngeneral language generation. In our experiments we use DBS to control GPT-2. We\ndemonstrate its performance on keyword-to-phrase generation and we obtain\ncomparable results as a state-of-the-art non-plug-and-play model for lexically\nconstrained story generation.\n", "versions": [{"version": "v1", "created": "Thu, 31 Dec 2020 03:05:44 GMT"}], "update_date": "2021-01-01", "authors_parsed": [["Pascual", "Damian", ""], ["Egressy", "Beni", ""], ["Bolli", "Florian", ""], ["Wattenhofer", "Roger", ""]]}, {"id": "2012.15436", "submitter": "Tara Boroushaki", "authors": "Tara Boroushaki, Junshan Leng, Ian Clester, Alberto Rodriguez, Fadel\n  Adib", "title": "Robotic Grasping of Fully-Occluded Objects using RF Perception", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We present the design, implementation, and evaluation of RF-Grasp, a robotic\nsystem that can grasp fully-occluded objects in unknown and unstructured\nenvironments. Unlike prior systems that are constrained by the line-of-sight\nperception of vision and infrared sensors, RF-Grasp employs RF (Radio\nFrequency) perception to identify and locate target objects through occlusions,\nand perform efficient exploration and complex manipulation tasks in\nnon-line-of-sight settings.\n  RF-Grasp relies on an eye-in-hand camera and batteryless RFID tags attached\nto objects of interest. It introduces two main innovations: (1) an RF-visual\nservoing controller that uses the RFID's location to selectively explore the\nenvironment and plan an efficient trajectory toward an occluded target, and (2)\nan RF-visual deep reinforcement learning network that can learn and execute\nefficient, complex policies for decluttering and grasping.\n  We implemented and evaluated an end-to-end physical prototype of RF-Grasp. We\ndemonstrate it improves success rate and efficiency by up to 40-50% over a\nstate-of-the-art baseline. We also demonstrate RF-Grasp in novel tasks such\nmechanical search of fully-occluded objects behind obstacles, opening up new\npossibilities for robotic manipulation. Qualitative results (videos) available\nat rfgrasp.media.mit.edu\n", "versions": [{"version": "v1", "created": "Thu, 31 Dec 2020 04:01:45 GMT"}, {"version": "v2", "created": "Sun, 2 May 2021 04:37:15 GMT"}], "update_date": "2021-05-04", "authors_parsed": [["Boroushaki", "Tara", ""], ["Leng", "Junshan", ""], ["Clester", "Ian", ""], ["Rodriguez", "Alberto", ""], ["Adib", "Fadel", ""]]}, {"id": "2012.15445", "submitter": "Hao Yuan", "authors": "Hao Yuan, Haiyang Yu, Shurui Gui, and Shuiwang Ji", "title": "Explainability in Graph Neural Networks: A Taxonomic Survey", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning methods are achieving ever-increasing performance on many\nartificial intelligence tasks. A major limitation of deep models is that they\nare not amenable to interpretability. This limitation can be circumvented by\ndeveloping post hoc techniques to explain the predictions, giving rise to the\narea of explainability. Recently, explainability of deep models on images and\ntexts has achieved significant progress. In the area of graph data, graph\nneural networks (GNNs) and their explainability are experiencing rapid\ndevelopments. However, there is neither a unified treatment of GNN\nexplainability methods, nor a standard benchmark and testbed for evaluations.\nIn this survey, we provide a unified and taxonomic view of current GNN\nexplainability methods. Our unified and taxonomic treatments of this subject\nshed lights on the commonalities and differences of existing methods and set\nthe stage for further methodological developments. To facilitate evaluations,\nwe generate a set of benchmark graph datasets specifically for GNN\nexplainability. We summarize current datasets and metrics for evaluating GNN\nexplainability. Altogether, this work provides a unified methodological\ntreatment of GNN explainability and a standardized testbed for evaluations.\n", "versions": [{"version": "v1", "created": "Thu, 31 Dec 2020 04:34:27 GMT"}, {"version": "v2", "created": "Thu, 25 Mar 2021 17:30:12 GMT"}], "update_date": "2021-03-26", "authors_parsed": [["Yuan", "Hao", ""], ["Yu", "Haiyang", ""], ["Gui", "Shurui", ""], ["Ji", "Shuiwang", ""]]}, {"id": "2012.15454", "submitter": "Wei-Ning Hsu", "authors": "Wei-Ning Hsu, David Harwath, Christopher Song, James Glass", "title": "Text-Free Image-to-Speech Synthesis Using Learned Segmental Units", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.CV cs.LG eess.AS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper we present the first model for directly synthesizing fluent,\nnatural-sounding spoken audio captions for images that does not require natural\nlanguage text as an intermediate representation or source of supervision.\nInstead, we connect the image captioning module and the speech synthesis module\nwith a set of discrete, sub-word speech units that are discovered with a\nself-supervised visual grounding task. We conduct experiments on the Flickr8k\nspoken caption dataset in addition to a novel corpus of spoken audio captions\ncollected for the popular MSCOCO dataset, demonstrating that our generated\ncaptions also capture diverse visual semantics of the images they describe. We\ninvestigate several different intermediate speech representations, and\nempirically find that the representation must satisfy several important\nproperties to serve as drop-in replacements for text.\n", "versions": [{"version": "v1", "created": "Thu, 31 Dec 2020 05:28:38 GMT"}], "update_date": "2021-01-01", "authors_parsed": [["Hsu", "Wei-Ning", ""], ["Harwath", "David", ""], ["Song", "Christopher", ""], ["Glass", "James", ""]]}, {"id": "2012.15465", "submitter": "Hiroki Matsutani", "authors": "Hirohisa Watanabe, Hiroki Matsutani", "title": "Accelerating ODE-Based Neural Networks on Low-Cost FPGAs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  ODENet is a deep neural network architecture in which a stacking structure of\nResNet is implemented with an ordinary differential equation (ODE) solver. It\ncan reduce the number of parameters and strike a balance between accuracy and\nperformance by selecting a proper solver. It is also possible to improve the\naccuracy while keeping the same number of parameters on resource-limited edge\ndevices. In this paper, using Euler method as an ODE solver, a part of ODENet\nis implemented as a dedicated logic on a low-cost FPGA (Field-Programmable Gate\nArray) board, such as PYNQ-Z2 board. As ODENet variants, reduced ODENets\n(rODENets) each of which heavily uses a part of ODENet layers and\nreduces/eliminates some layers differently are proposed and analyzed for\nlow-cost FPGA implementation. They are evaluated in terms of parameter size,\naccuracy, execution time, and resource utilization on the FPGA. The results\nshow that an overall execution time of an rODENet variant is improved by up to\n2.66 times compared to a pure software execution while keeping a comparable\naccuracy to the original ODENet.\n", "versions": [{"version": "v1", "created": "Thu, 31 Dec 2020 06:39:22 GMT"}, {"version": "v2", "created": "Sun, 3 Jan 2021 06:45:25 GMT"}, {"version": "v3", "created": "Mon, 29 Mar 2021 16:42:41 GMT"}], "update_date": "2021-03-30", "authors_parsed": [["Watanabe", "Hirohisa", ""], ["Matsutani", "Hiroki", ""]]}, {"id": "2012.15472", "submitter": "Yoav Alon", "authors": "Yoav Alon and Huiyu Zhou", "title": "Multi-Agent Reinforcement Learning for Unmanned Aerial Vehicle\n  Coordination by Multi-Critic Policy Gradient Optimization", "comments": "This work has been submitted to the IEEE for possible publication.\n  Copyright may be transferred without notice, after which this version may no\n  longer be accessible", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent technological progress in the development of Unmanned Aerial Vehicles\n(UAVs) together with decreasing acquisition costs make the application of drone\nfleets attractive for a wide variety of tasks. In agriculture, disaster\nmanagement, search and rescue operations, commercial and military applications,\nthe advantage of applying a fleet of drones originates from their ability to\ncooperate autonomously. Multi-Agent Reinforcement Learning approaches that aim\nto optimize a neural network based control policy, such as the best performing\nactor-critic policy gradient algorithms, struggle to effectively back-propagate\nerrors of distinct rewards signal sources and tend to favor lucrative signals\nwhile neglecting coordination and exploitation of previously learned\nsimilarities. We propose a Multi-Critic Policy Optimization architecture with\nmultiple value estimating networks and a novel advantage function that\noptimizes a stochastic actor policy network to achieve optimal coordination of\nagents. Consequently, we apply the algorithm to several tasks that require the\ncollaboration of multiple drones in a physics-based reinforcement learning\nenvironment. Our approach achieves a stable policy network update and\nsimilarity in reward signal development for an increasing number of agents. The\nresulting policy achieves optimal coordination and compliance with constraints\nsuch as collision avoidance.\n", "versions": [{"version": "v1", "created": "Thu, 31 Dec 2020 07:00:44 GMT"}], "update_date": "2021-01-01", "authors_parsed": [["Alon", "Yoav", ""], ["Zhou", "Huiyu", ""]]}, {"id": "2012.15485", "submitter": "Mahsa Ghasemi", "authors": "Mahsa Ghasemi, Evan Scope Crafts, Bo Zhao, Ufuk Topcu", "title": "Multiple Plans are Better than One: Diverse Stochastic Planning", "comments": "Mahsa Ghasemi and Evan Scope Crafts have contributed equally to the\n  manuscript", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In planning problems, it is often challenging to fully model the desired\nspecifications. In particular, in human-robot interaction, such difficulty may\narise due to human's preferences that are either private or complex to model.\nConsequently, the resulting objective function can only partially capture the\nspecifications and optimizing that may lead to poor performance with respect to\nthe true specifications. Motivated by this challenge, we formulate a problem,\ncalled diverse stochastic planning, that aims to generate a set of\nrepresentative -- small and diverse -- behaviors that are near-optimal with\nrespect to the known objective. In particular, the problem aims to compute a\nset of diverse and near-optimal policies for systems modeled by a Markov\ndecision process. We cast the problem as a constrained nonlinear optimization\nfor which we propose a solution relying on the Frank-Wolfe method. We then\nprove that the proposed solution converges to a stationary point and\ndemonstrate its efficacy in several planning problems.\n", "versions": [{"version": "v1", "created": "Thu, 31 Dec 2020 07:29:11 GMT"}], "update_date": "2021-01-01", "authors_parsed": [["Ghasemi", "Mahsa", ""], ["Crafts", "Evan Scope", ""], ["Zhao", "Bo", ""], ["Topcu", "Ufuk", ""]]}, {"id": "2012.15504", "submitter": "Andrea Madotto Mr", "authors": "Andrea Madotto, Zhaojiang Lin, Zhenpeng Zhou, Seungwhan Moon, Paul\n  Crook, Bing Liu, Zhou Yu, Eunjoon Cho, Zhiguang Wang", "title": "Continual Learning in Task-Oriented Dialogue Systems", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Continual learning in task-oriented dialogue systems can allow us to add new\ndomains and functionalities through time without incurring the high cost of a\nwhole system retraining. In this paper, we propose a continual learning\nbenchmark for task-oriented dialogue systems with 37 domains to be learned\ncontinuously in four settings, such as intent recognition, state tracking,\nnatural language generation, and end-to-end. Moreover, we implement and compare\nmultiple existing continual learning baselines, and we propose a simple yet\neffective architectural method based on residual adapters. Our experiments\ndemonstrate that the proposed architectural method and a simple replay-based\nstrategy perform comparably well but they both achieve inferior performance to\nthe multi-task learning baseline, in where all the data are shown at once,\nshowing that continual learning in task-oriented dialogue systems is a\nchallenging task. Furthermore, we reveal several trade-offs between different\ncontinual learning methods in term of parameter usage and memory size, which\nare important in the design of a task-oriented dialogue system. The proposed\nbenchmark is released together with several baselines to promote more research\nin this direction.\n", "versions": [{"version": "v1", "created": "Thu, 31 Dec 2020 08:44:25 GMT"}], "update_date": "2021-01-01", "authors_parsed": [["Madotto", "Andrea", ""], ["Lin", "Zhaojiang", ""], ["Zhou", "Zhenpeng", ""], ["Moon", "Seungwhan", ""], ["Crook", "Paul", ""], ["Liu", "Bing", ""], ["Yu", "Zhou", ""], ["Cho", "Eunjoon", ""], ["Wang", "Zhiguang", ""]]}, {"id": "2012.15537", "submitter": "Zhen Han", "authors": "Zhen Han, Peng Chen, Yunpu Ma, Volker Tresp", "title": "xERTE: Explainable Reasoning on Temporal Knowledge Graphs for\n  Forecasting Future Links", "comments": "24 pages, 8 figures, accepted to ICLR 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modeling time-evolving knowledge graphs (KGs) has recently gained increasing\ninterest. Here, graph representation learning has become the dominant paradigm\nfor link prediction on temporal KGs. However, the embedding-based approaches\nlargely operate in a black-box fashion, lacking the ability to interpret their\npredictions. This paper provides a link forecasting framework that reasons over\nquery-relevant subgraphs of temporal KGs and jointly models the structural\ndependencies and the temporal dynamics. Especially, we propose a temporal\nrelational attention mechanism and a novel reverse representation update scheme\nto guide the extraction of an enclosing subgraph around the query. The subgraph\nis expanded by an iterative sampling of temporal neighbors and by attention\npropagation. Our approach provides human-understandable evidence explaining the\nforecast. We evaluate our model on four benchmark temporal knowledge graphs for\nthe link forecasting task. While being more explainable, our model obtains a\nrelative improvement of up to 20% on Hits@1 compared to the previous best KG\nforecasting method. We also conduct a survey with 53 respondents, and the\nresults show that the evidence extracted by the model for link forecasting is\naligned with human understanding.\n", "versions": [{"version": "v1", "created": "Thu, 31 Dec 2020 10:41:01 GMT"}, {"version": "v2", "created": "Mon, 18 Jan 2021 10:27:22 GMT"}, {"version": "v3", "created": "Fri, 19 Mar 2021 18:11:59 GMT"}, {"version": "v4", "created": "Sat, 27 Mar 2021 11:28:05 GMT"}, {"version": "v5", "created": "Thu, 1 Apr 2021 13:17:47 GMT"}], "update_date": "2021-04-02", "authors_parsed": [["Han", "Zhen", ""], ["Chen", "Peng", ""], ["Ma", "Yunpu", ""], ["Tresp", "Volker", ""]]}, {"id": "2012.15543", "submitter": "Zheng-Yu Niu", "authors": "Jun Xu, Zeyang Lei, Haifeng Wang, Zheng-Yu Niu, Hua Wu, Wanxiang Che,\n  Ting Liu", "title": "Discovering Dialog Structure Graph for Open-Domain Dialog Generation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning interpretable dialog structure from human-human dialogs yields basic\ninsights into the structure of conversation, and also provides background\nknowledge to facilitate dialog generation. In this paper, we conduct\nunsupervised discovery of dialog structure from chitchat corpora, and then\nleverage it to facilitate dialog generation in downstream systems. To this end,\nwe present a Discrete Variational Auto-Encoder with Graph Neural Network\n(DVAE-GNN), to discover a unified human-readable dialog structure. The\nstructure is a two-layer directed graph that contains session-level semantics\nin the upper-layer vertices, utterance-level semantics in the lower-layer\nvertices, and edges among these semantic vertices. In particular, we integrate\nGNN into DVAE to fine-tune utterance-level semantics for more effective\nrecognition of session-level semantic vertex. Furthermore, to alleviate the\ndifficulty of discovering a large number of utterance-level semantics, we\ndesign a coupling mechanism that binds each utterance-level semantic vertex\nwith a distinct phrase to provide prior semantics. Experimental results on two\nbenchmark corpora confirm that DVAE-GNN can discover meaningful dialog\nstructure, and the use of dialog structure graph as background knowledge can\nfacilitate a graph grounded conversational system to conduct coherent\nmulti-turn dialog generation.\n", "versions": [{"version": "v1", "created": "Thu, 31 Dec 2020 10:58:37 GMT"}], "update_date": "2021-01-01", "authors_parsed": [["Xu", "Jun", ""], ["Lei", "Zeyang", ""], ["Wang", "Haifeng", ""], ["Niu", "Zheng-Yu", ""], ["Wu", "Hua", ""], ["Che", "Wanxiang", ""], ["Liu", "Ting", ""]]}, {"id": "2012.15544", "submitter": "Faezeh Faez", "authors": "Faezeh Faez, Yassaman Ommi, Mahdieh Soleymani Baghshah, Hamid R.\n  Rabiee", "title": "Deep Graph Generators: A Survey", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep generative models have achieved great success in areas such as image,\nspeech, and natural language processing in the past few years. Thanks to the\nadvances in graph-based deep learning, and in particular graph representation\nlearning, deep graph generation methods have recently emerged with new\napplications ranging from discovering novel molecular structures to modeling\nsocial networks. This paper conducts a comprehensive survey on deep\nlearning-based graph generation approaches and classifies them into five broad\ncategories, namely, autoregressive, autoencoder-based, RL-based, adversarial,\nand flow-based graph generators, providing the readers a detailed description\nof the methods in each class. We also present publicly available source codes,\ncommonly used datasets, and the most widely utilized evaluation metrics.\nFinally, we highlight the existing challenges and discuss future research\ndirections.\n", "versions": [{"version": "v1", "created": "Thu, 31 Dec 2020 11:01:33 GMT"}], "update_date": "2021-01-01", "authors_parsed": [["Faez", "Faezeh", ""], ["Ommi", "Yassaman", ""], ["Baghshah", "Mahdieh Soleymani", ""], ["Rabiee", "Hamid R.", ""]]}, {"id": "2012.15616", "submitter": "Xiao-Hui Li", "authors": "Xiao-Hui Li, Yuhan Shi, Haoyang Li, Wei Bai, Yuanwei Song, Caleb Chen\n  Cao, Lei Chen", "title": "Quantitative Evaluations on Saliency Methods: An Experimental Study", "comments": "14 pages, 16 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It has been long debated that eXplainable AI (XAI) is an important topic, but\nit lacks rigorous definition and fair metrics. In this paper, we briefly\nsummarize the status quo of the metrics, along with an exhaustive experimental\nstudy based on them, including faithfulness, localization, false-positives,\nsensitivity check, and stability. With the experimental results, we conclude\nthat among all the methods we compare, no single explanation method dominates\nothers in all metrics. Nonetheless, Gradient-weighted Class Activation Mapping\n(Grad-CAM) and Randomly Input Sampling for Explanation (RISE) perform fairly\nwell in most of the metrics. Utilizing a set of filtered metrics, we further\npresent a case study to diagnose the classification bases for models. While\nproviding a comprehensive experimental study of metrics, we also examine\nmeasuring factors that are missed in current metrics and hope this valuable\nwork could serve as a guide for future research.\n", "versions": [{"version": "v1", "created": "Thu, 31 Dec 2020 14:13:30 GMT"}], "update_date": "2021-01-01", "authors_parsed": [["Li", "Xiao-Hui", ""], ["Shi", "Yuhan", ""], ["Li", "Haoyang", ""], ["Bai", "Wei", ""], ["Song", "Yuanwei", ""], ["Cao", "Caleb Chen", ""], ["Chen", "Lei", ""]]}, {"id": "2012.15635", "submitter": "Alan Smeaton", "authors": "Lorin Sweeney, Graham Healy, Alan F. Smeaton", "title": "Leveraging Audio Gestalt to Predict Media Memorability", "comments": "3 pages, 1 Figure, 2 Tables", "journal-ref": "MediaEval Multimedia Benchmark Workshop Working Notes, 14-15\n  December 2020", "doi": null, "report-no": null, "categories": "cs.MM cs.AI cs.CV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Memorability determines what evanesces into emptiness, and what worms its way\ninto the deepest furrows of our minds. It is the key to curating more\nmeaningful media content as we wade through daily digital torrents. The\nPredicting Media Memorability task in MediaEval 2020 aims to address the\nquestion of media memorability by setting the task of automatically predicting\nvideo memorability. Our approach is a multimodal deep learning-based late\nfusion that combines visual, semantic, and auditory features. We used audio\ngestalt to estimate the influence of the audio modality on overall video\nmemorability, and accordingly inform which combination of features would best\npredict a given video's memorability scores.\n", "versions": [{"version": "v1", "created": "Thu, 31 Dec 2020 14:50:42 GMT"}], "update_date": "2021-01-01", "authors_parsed": [["Sweeney", "Lorin", ""], ["Healy", "Graham", ""], ["Smeaton", "Alan F.", ""]]}, {"id": "2012.15638", "submitter": "Yiming Zeng", "authors": "Yiming Zeng, Yue Qian, Zhiyu Zhu, Junhui Hou, Hui Yuan, Ying He", "title": "CorrNet3D: Unsupervised End-to-end Learning of Dense Correspondence for\n  3D Point Clouds", "comments": "This paper was accepted by CVPR 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by the intuition that one can transform two aligned point clouds to\neach other more easily and meaningfully than a misaligned pair, we propose\nCorrNet3D -- the first unsupervised and end-to-end deep learning-based\nframework -- to drive the learning of dense correspondence between 3D shapes by\nmeans of deformation-like reconstruction to overcome the need for annotated\ndata. Specifically, CorrNet3D consists of a deep feature embedding module and\ntwo novel modules called correspondence indicator and symmetric deformer.\nFeeding a pair of raw point clouds, our model first learns the pointwise\nfeatures and passes them into the indicator to generate a learnable\ncorrespondence matrix used to permute the input pair. The symmetric deformer,\nwith an additional regularized loss, transforms the two permuted point clouds\nto each other to drive the unsupervised learning of the correspondence. The\nextensive experiments on both synthetic and real-world datasets of rigid and\nnon-rigid 3D shapes show our CorrNet3D outperforms state-of-the-art methods to\na large extent, including those taking meshes as input. CorrNet3D is a flexible\nframework in that it can be easily adapted to supervised learning if annotated\ndata are available. The source code and pre-trained model will be available at\nhttps://github.com/ZENGYIMING-EAMON/CorrNet3D.git.\n", "versions": [{"version": "v1", "created": "Thu, 31 Dec 2020 14:55:51 GMT"}, {"version": "v2", "created": "Mon, 3 May 2021 07:50:28 GMT"}], "update_date": "2021-05-04", "authors_parsed": [["Zeng", "Yiming", ""], ["Qian", "Yue", ""], ["Zhu", "Zhiyu", ""], ["Hou", "Junhui", ""], ["Yuan", "Hui", ""], ["He", "Ying", ""]]}, {"id": "2012.15641", "submitter": "Alan Smeaton", "authors": "Phuc H. Le-Khac and Ayush K. Rai and Graham Healy and Alan F. Smeaton\n  and Noel E. O'Connor", "title": "Investigating Memorability of Dynamic Media", "comments": "3 pages, 1 figure. 1 table", "journal-ref": "MediaEval Multimedia Benchmark Workshop Working Notes, 14-15\n  December 2020", "doi": null, "report-no": null, "categories": "cs.MM cs.AI cs.CV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The Predicting Media Memorability task in MediaEval'20 has some challenging\naspects compared to previous years. In this paper we identify the high-dynamic\ncontent in videos and dataset of limited size as the core challenges for the\ntask, we propose directions to overcome some of these challenges and we present\nour initial result in these directions.\n", "versions": [{"version": "v1", "created": "Thu, 31 Dec 2020 15:01:44 GMT"}], "update_date": "2021-01-01", "authors_parsed": [["Le-Khac", "Phuc H.", ""], ["Rai", "Ayush K.", ""], ["Healy", "Graham", ""], ["Smeaton", "Alan F.", ""], ["O'Connor", "Noel E.", ""]]}, {"id": "2012.15650", "submitter": "Alan Smeaton", "authors": "Alba Garc\\'ia Seco De Herrera and Rukiye Savran Kiziltepe and Jon\n  Chamberlain and Mihai Gabriel Constantin and Claire-H\\'el\\`ene Demarty and\n  Faiyaz Doctor and Bogdan Ionescu and Alan F. Smeaton", "title": "Overview of MediaEval 2020 Predicting Media Memorability Task: What\n  Makes a Video Memorable?", "comments": "3 pages, 1 Figure", "journal-ref": "MediaEval Multimedia Benchmark Workshop Working Notes, 14-15\n  December 2020", "doi": null, "report-no": null, "categories": "cs.MM cs.AI cs.CV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper describes the MediaEval 2020 \\textit{Predicting Media\nMemorability} task. After first being proposed at MediaEval 2018, the\nPredicting Media Memorability task is in its 3rd edition this year, as the\nprediction of short-term and long-term video memorability (VM) remains a\nchallenging task. In 2020, the format remained the same as in previous\neditions. This year the videos are a subset of the TRECVid 2019 Video-to-Text\ndataset, containing more action rich video content as compared with the 2019\ntask. In this paper a description of some aspects of this task is provided,\nincluding its main characteristics, a description of the collection, the ground\ntruth dataset, evaluation metrics and the requirements for participants' run\nsubmissions.\n", "versions": [{"version": "v1", "created": "Thu, 31 Dec 2020 15:12:52 GMT"}], "update_date": "2021-01-01", "authors_parsed": [["De Herrera", "Alba Garc\u00eda Seco", ""], ["Kiziltepe", "Rukiye Savran", ""], ["Chamberlain", "Jon", ""], ["Constantin", "Mihai Gabriel", ""], ["Demarty", "Claire-H\u00e9l\u00e8ne", ""], ["Doctor", "Faiyaz", ""], ["Ionescu", "Bogdan", ""], ["Smeaton", "Alan F.", ""]]}, {"id": "2012.15700", "submitter": "Victoria Manfredi", "authors": "Victoria Manfredi, Alicia Wolfe, Bing Wang, Xiaolan Zhang", "title": "Relational Deep Reinforcement Learning for Routing in Wireless Networks", "comments": "11 pages, 26 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While routing in wireless networks has been studied extensively, existing\nprotocols are typically designed for a specific set of network conditions and\nso cannot accommodate any drastic changes in those conditions. For instance,\nprotocols designed for connected networks cannot be easily applied to\ndisconnected networks. In this paper, we develop a distributed routing strategy\nbased on deep reinforcement learning that generalizes to diverse traffic\npatterns, congestion levels, network connectivity, and link dynamics. We make\nthe following key innovations in our design: (i) the use of relational features\nas inputs to the deep neural network approximating the decision space, which\nenables our algorithm to generalize to diverse network conditions, (ii) the use\nof packet-centric decisions to transform the routing problem into an episodic\ntask by viewing packets, rather than wireless devices, as reinforcement\nlearning agents, which provides a natural way to propagate and model rewards\naccurately during learning, and (iii) the use of extended-time actions to model\nthe time spent by a packet waiting in a queue, which reduces the amount of\ntraining data needed and allows the learning algorithm to converge more\nquickly. We evaluate our routing algorithm using a packet-level simulator and\nshow that the policy our algorithm learns during training is able to generalize\nto larger and more congested networks, different topologies, and diverse link\ndynamics. Our algorithm outperforms shortest path and backpressure routing with\nrespect to packets delivered and delay per packet.\n", "versions": [{"version": "v1", "created": "Thu, 31 Dec 2020 16:28:21 GMT"}], "update_date": "2021-01-01", "authors_parsed": [["Manfredi", "Victoria", ""], ["Wolfe", "Alicia", ""], ["Wang", "Bing", ""], ["Zhang", "Xiaolan", ""]]}, {"id": "2012.15715", "submitter": "Mikel Artetxe", "authors": "Aitor Ormazabal, Mikel Artetxe, Aitor Soroa, Gorka Labaka, Eneko\n  Agirre", "title": "Beyond Offline Mapping: Learning Cross Lingual Word Embeddings through\n  Context Anchoring", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent research on cross-lingual word embeddings has been dominated by\nunsupervised mapping approaches that align monolingual embeddings. Such methods\ncritically rely on those embeddings having a similar structure, but it was\nrecently shown that the separate training in different languages causes\ndepartures from this assumption. In this paper, we propose an alternative\napproach that does not have this limitation, while requiring a weak seed\ndictionary (e.g., a list of identical words) as the only form of supervision.\nRather than aligning two fixed embedding spaces, our method works by fixing the\ntarget language embeddings, and learning a new set of embeddings for the source\nlanguage that are aligned with them. To that end, we use an extension of\nskip-gram that leverages translated context words as anchor points, and\nincorporates self-learning and iterative restarts to reduce the dependency on\nthe initial dictionary. Our approach outperforms conventional mapping methods\non bilingual lexicon induction, and obtains competitive results in the\ndownstream XNLI task.\n", "versions": [{"version": "v1", "created": "Thu, 31 Dec 2020 17:10:14 GMT"}], "update_date": "2021-01-01", "authors_parsed": [["Ormazabal", "Aitor", ""], ["Artetxe", "Mikel", ""], ["Soroa", "Aitor", ""], ["Labaka", "Gorka", ""], ["Agirre", "Eneko", ""]]}, {"id": "2012.15721", "submitter": "Nasser Aldaghri", "authors": "Nasser Aldaghri, Hessam Mahdavifar, Ahmad Beirami", "title": "Coded Machine Unlearning", "comments": "Accepted for publication in IEEE Access", "journal-ref": null, "doi": "10.1109/ACCESS.2021.3090019", "report-no": null, "categories": "cs.LG cs.AI cs.CR cs.IT math.IT", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  There are applications that may require removing the trace of a sample from\nthe system, e.g., a user requests their data to be deleted, or corrupted data\nis discovered. Simply removing a sample from storage units does not necessarily\nremove its entire trace since downstream machine learning models may store some\ninformation about the samples used to train them. A sample can be perfectly\nunlearned if we retrain all models that used it from scratch with that sample\nremoved from their training dataset. When multiple such unlearning requests are\nexpected to be served, unlearning by retraining becomes prohibitively\nexpensive. Ensemble learning enables the training data to be split into smaller\ndisjoint shards that are assigned to non-communicating weak learners. Each\nshard is used to produce a weak model. These models are then aggregated to\nproduce the final central model. This setup introduces an inherent trade-off\nbetween performance and unlearning cost, as reducing the shard size reduces the\nunlearning cost but may cause degradation in performance. In this paper, we\npropose a coded learning protocol where we utilize linear encoders to encode\nthe training data into shards prior to the learning phase. We also present the\ncorresponding unlearning protocol and show that it satisfies the perfect\nunlearning criterion. Our experimental results show that the proposed coded\nmachine unlearning provides a better performance versus unlearning cost\ntrade-off compared to the uncoded baseline.\n", "versions": [{"version": "v1", "created": "Thu, 31 Dec 2020 17:20:34 GMT"}, {"version": "v2", "created": "Tue, 15 Jun 2021 16:35:51 GMT"}], "update_date": "2021-06-17", "authors_parsed": [["Aldaghri", "Nasser", ""], ["Mahdavifar", "Hessam", ""], ["Beirami", "Ahmad", ""]]}, {"id": "2012.15738", "submitter": "Denis Emelin", "authors": "Denis Emelin, Ronan Le Bras, Jena D. Hwang, Maxwell Forbes, Yejin Choi", "title": "Moral Stories: Situated Reasoning about Norms, Intents, Actions, and\n  their Consequences", "comments": "For the 'Moral Stories' dataset, see\n  https://github.com/demelin/moral_stories", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In social settings, much of human behavior is governed by unspoken rules of\nconduct. For artificial systems to be fully integrated into social\nenvironments, adherence to such norms is a central prerequisite. We investigate\nwhether contemporary NLG models can function as behavioral priors for systems\ndeployed in social settings by generating action hypotheses that achieve\npredefined goals under moral constraints. Moreover, we examine if models can\nanticipate likely consequences of (im)moral actions, or explain why certain\nactions are preferable by generating relevant norms. For this purpose, we\nintroduce 'Moral Stories', a crowd-sourced dataset of structured, branching\nnarratives for the study of grounded, goal-oriented social reasoning. Finally,\nwe propose decoding strategies that effectively combine multiple expert models\nto significantly improve the quality of generated actions, consequences, and\nnorms compared to strong baselines, e.g. though abductive reasoning.\n", "versions": [{"version": "v1", "created": "Thu, 31 Dec 2020 17:28:01 GMT"}], "update_date": "2021-01-01", "authors_parsed": [["Emelin", "Denis", ""], ["Bras", "Ronan Le", ""], ["Hwang", "Jena D.", ""], ["Forbes", "Maxwell", ""], ["Choi", "Yejin", ""]]}, {"id": "2012.15741", "submitter": "Zhangyang Gao", "authors": "Zhangyang Gao, Haitao Lin, Stan. Z Li", "title": "LookHops: light multi-order convolution and pooling for graph\n  classification", "comments": "9 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolution and pooling are the key operations to learn hierarchical\nrepresentation for graph classification, where more expressive $k$-order($k>1$)\nmethod requires more computation cost, limiting the further applications. In\nthis paper, we investigate the strategy of selecting $k$ via neighborhood\ninformation gain and propose light $k$-order convolution and pooling requiring\nfewer parameters while improving the performance. Comprehensive and fair\nexperiments through six graph classification benchmarks show: 1) the\nperformance improvement is consistent to the $k$-order information gain. 2) the\nproposed convolution requires fewer parameters while providing competitive\nresults. 3) the proposed pooling outperforms SOTA algorithms in terms of\nefficiency and performance.\n", "versions": [{"version": "v1", "created": "Mon, 28 Dec 2020 11:47:03 GMT"}], "update_date": "2021-01-01", "authors_parsed": [["Gao", "Zhangyang", ""], ["Lin", "Haitao", ""], ["Li", "Stan. Z", ""]]}, {"id": "2012.15749", "submitter": "Erdem B{\\i}y{\\i}k", "authors": "Mark Beliaev, Erdem B{\\i}y{\\i}k, Daniel A. Lazar, Woodrow Z. Wang,\n  Dorsa Sadigh, Ramtin Pedarsani", "title": "Incentivizing Routing Choices for Safe and Efficient Transportation in\n  the Face of the COVID-19 Pandemic", "comments": "ICCPS 2021. 11 pages, 4 figures", "journal-ref": null, "doi": "10.1145/3450267.3450546", "report-no": null, "categories": "cs.SI cs.AI cs.LG cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The COVID-19 pandemic has severely affected many aspects of people's daily\nlives. While many countries are in a re-opening stage, some effects of the\npandemic on people's behaviors are expected to last much longer, including how\nthey choose between different transport options. Experts predict considerably\ndelayed recovery of the public transport options, as people try to avoid\ncrowded places. In turn, significant increases in traffic congestion are\nexpected, since people are likely to prefer using their own vehicles or taxis\nas opposed to riskier and more crowded options such as the railway. In this\npaper, we propose to use financial incentives to set the tradeoff between risk\nof infection and congestion to achieve safe and efficient transportation\nnetworks. To this end, we formulate a network optimization problem to optimize\ntaxi fares. For our framework to be useful in various cities and times of the\nday without much designer effort, we also propose a data-driven approach to\nlearn human preferences about transport options, which is then used in our taxi\nfare optimization. Our user studies and simulation experiments show our\nframework is able to minimize congestion and risk of infection.\n", "versions": [{"version": "v1", "created": "Mon, 28 Dec 2020 13:52:06 GMT"}, {"version": "v2", "created": "Thu, 18 Feb 2021 02:16:35 GMT"}], "update_date": "2021-02-19", "authors_parsed": [["Beliaev", "Mark", ""], ["B\u0131y\u0131k", "Erdem", ""], ["Lazar", "Daniel A.", ""], ["Wang", "Woodrow Z.", ""], ["Sadigh", "Dorsa", ""], ["Pedarsani", "Ramtin", ""]]}, {"id": "2012.15754", "submitter": "Stefanos Tsimenidis", "authors": "Stefanos Tsimenidis", "title": "Limitations of Deep Neural Networks: a discussion of G. Marcus' critical\n  appraisal of deep learning", "comments": "16 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CY cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Deep neural networks have triggered a revolution in artificial intelligence,\nhaving been applied with great results in medical imaging, semi-autonomous\nvehicles, ecommerce, genetics research, speech recognition, particle physics,\nexperimental art, economic forecasting, environmental science, industrial\nmanufacturing, and a wide variety of applications in nearly every field. This\nsudden success, though, may have intoxicated the research community and blinded\nthem to the potential pitfalls of assigning deep learning a higher status than\nwarranted. Also, research directed at alleviating the weaknesses of deep\nlearning may seem less attractive to scientists and engineers, who focus on the\nlow-hanging fruit of finding more and more applications for deep learning\nmodels, thus letting short-term benefits hamper long-term scientific progress.\nGary Marcus wrote a paper entitled Deep Learning: A Critical Appraisal, and\nhere we discuss Marcus' core ideas, as well as attempt a general assessment of\nthe subject. This study examines some of the limitations of deep neural\nnetworks, with the intention of pointing towards potential paths for future\nresearch, and of clearing up some metaphysical misconceptions, held by numerous\nresearchers, that may misdirect them.\n", "versions": [{"version": "v1", "created": "Tue, 22 Dec 2020 12:11:19 GMT"}], "update_date": "2021-01-01", "authors_parsed": [["Tsimenidis", "Stefanos", ""]]}, {"id": "2012.15755", "submitter": "Samira Ghodratnama", "authors": "Samira Ghodratnama and Mehrdad Zakershahrak and Fariborz Sobhanmanesh", "title": "Am I Rare? An Intelligent Summarization Approach for Identifying Hidden\n  Anomalies", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Monitoring network traffic data to detect any hidden patterns of anomalies is\na challenging and time-consuming task that requires high computing resources.\nTo this end, an appropriate summarization technique is of great importance,\nwhere it can be a substitute for the original data. However, the summarized\ndata is under the threat of removing anomalies. Therefore, it is vital to\ncreate a summary that can reflect the same pattern as the original data.\nTherefore, in this paper, we propose an INtelligent Summarization approach for\nIDENTifying hidden anomalies, called INSIDENT. The proposed approach guarantees\nto keep the original data distribution in summarized data. Our approach is a\nclustering-based algorithm that dynamically maps original feature space to a\nnew feature space by locally weighting features in each cluster. Therefore, in\nnew feature space, similar samples are closer, and consequently, outliers are\nmore detectable. Besides, selecting representatives based on cluster size keeps\nthe same distribution as the original data in summarized data. INSIDENT can be\nused both as the preprocess approach before performing anomaly detection\nalgorithms and anomaly detection algorithm. The experimental results on\nbenchmark datasets prove a summary of the data can be a substitute for original\ndata in the anomaly detection task.\n", "versions": [{"version": "v1", "created": "Thu, 24 Dec 2020 23:22:57 GMT"}], "update_date": "2021-01-01", "authors_parsed": [["Ghodratnama", "Samira", ""], ["Zakershahrak", "Mehrdad", ""], ["Sobhanmanesh", "Fariborz", ""]]}, {"id": "2012.15764", "submitter": "Joshua Peeples", "authors": "Joshua Peeples, Sarah Walker, Connor McCurley, Alina Zare, James\n  Keller", "title": "Divergence Regulated Encoder Network for Joint Dimensionality Reduction\n  and Classification", "comments": "5 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we investigate performing joint dimensionality reduction and\nclassification using a novel histogram neural network. Motivated by a popular\ndimensionality reduction approach, t-Distributed Stochastic Neighbor Embedding\n(t-SNE), our proposed method incorporates a classification loss computed on\nsamples in a low-dimensional embedding space. We compare the learned sample\nembeddings against coordinates found by t-SNE in terms of classification\naccuracy and qualitative assessment. We also explore use of various divergence\nmeasures in the t-SNE objective. The proposed method has several advantages\nsuch as readily embedding out-of-sample points and reducing feature\ndimensionality while retaining class discriminability. Our results show that\nthe proposed approach maintains and/or improves classification performance and\nreveals characteristics of features produced by neural networks that may be\nhelpful for other applications.\n", "versions": [{"version": "v1", "created": "Thu, 31 Dec 2020 17:39:02 GMT"}, {"version": "v2", "created": "Thu, 21 Jan 2021 15:55:52 GMT"}, {"version": "v3", "created": "Tue, 16 Mar 2021 20:03:12 GMT"}, {"version": "v4", "created": "Fri, 11 Jun 2021 17:53:35 GMT"}], "update_date": "2021-06-14", "authors_parsed": [["Peeples", "Joshua", ""], ["Walker", "Sarah", ""], ["McCurley", "Connor", ""], ["Zare", "Alina", ""], ["Keller", "James", ""]]}, {"id": "2012.15781", "submitter": "Han Guo", "authors": "Han Guo, Nazneen Fatema Rajani, Peter Hase, Mohit Bansal, Caiming\n  Xiong", "title": "FastIF: Scalable Influence Functions for Efficient Model Interpretation\n  and Debugging", "comments": "18 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Influence functions approximate the 'influences' of training data-points for\ntest predictions and have a wide variety of applications. Despite the\npopularity, their computational cost does not scale well with model and\ntraining data size. We present FastIF, a set of simple modifications to\ninfluence functions that significantly improves their run-time. We use\nk-Nearest Neighbors (kNN) to narrow the search space down to a subset of good\ncandidate data points, identify the configurations that best balance the\nspeed-quality trade-off in estimating the inverse Hessian-vector product, and\nintroduce a fast parallel variant. Our proposed method achieves about 80x\nspeedup while being highly correlated with the original influence values. With\nthe availability of the fast influence functions, we demonstrate their\nusefulness in four applications. First, we examine whether influential\ndata-points can 'explain' test time behavior using the framework of\nsimulatability. Second, we visualize the influence interactions between\ntraining and test data-points. Third, we show that we can correct model errors\nby additional fine-tuning on certain influential data-points, improving the\naccuracy of a trained MNLI model by 2.6% on the HANS challenge set using a\nsmall number of gradient updates. Finally, we experiment with a\ndata-augmentation setup where we use influence functions to search for new\ndata-points unseen during training to improve model performance. Overall, our\nfast influence functions can be efficiently applied to large models and\ndatasets, and our experiments demonstrate the potential of influence functions\nin model interpretation and correcting model errors. Code is available at\nhttps://github.com/salesforce/fast-influence-functions\n", "versions": [{"version": "v1", "created": "Thu, 31 Dec 2020 18:02:34 GMT"}], "update_date": "2021-01-01", "authors_parsed": [["Guo", "Han", ""], ["Rajani", "Nazneen Fatema", ""], ["Hase", "Peter", ""], ["Bansal", "Mohit", ""], ["Xiong", "Caiming", ""]]}, {"id": "2012.15788", "submitter": "James Thorne", "authors": "James Thorne, Andreas Vlachos", "title": "Evidence-based Factual Error Correction", "comments": "Accepted at ACL2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces the task of factual error correction: performing edits\nto a claim so that the generated rewrite is better supported by evidence. This\nextends the well-studied task of fact verification by providing a mechanism to\ncorrect written texts that are refuted or only partially supported by evidence.\nWe demonstrate that it is feasible to train factual error correction systems\nfrom existing fact checking datasets which only contain labeled claims\naccompanied by evidence, but not the correction. We achieve this by employing a\ntwo-stage distant supervision approach that incorporates evidence into masked\nclaims when generating corrections. Our approach, based on the T5 transformer\nand using retrieved evidence, achieved better results than existing work which\nused a pointer copy network and gold evidence, producing accurate factual error\ncorrections for 5x more instances in human evaluation and a .125 increase in\nSARI score. The evaluation is conducted on a dataset of 65,000 instances based\non a recent fact verification shared task and we release it to enable further\nwork on the task.\n", "versions": [{"version": "v1", "created": "Thu, 31 Dec 2020 18:11:26 GMT"}, {"version": "v2", "created": "Fri, 11 Jun 2021 16:23:26 GMT"}], "update_date": "2021-06-17", "authors_parsed": [["Thorne", "James", ""], ["Vlachos", "Andreas", ""]]}, {"id": "2012.15823", "submitter": "Mehdi Bahri", "authors": "Mehdi Bahri, Ga\\'etan Bahl, Stefanos Zafeiriou", "title": "Binary Graph Neural Networks", "comments": "CVPR 2021 Camera-Ready Version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Graph Neural Networks (GNNs) have emerged as a powerful and flexible\nframework for representation learning on irregular data. As they generalize the\noperations of classical CNNs on grids to arbitrary topologies, GNNs also bring\nmuch of the implementation challenges of their Euclidean counterparts. Model\nsize, memory footprint, and energy consumption are common concerns for many\nreal-world applications. Network binarization allocates a single bit to\nparameters and activations, thus dramatically reducing the memory requirements\n(up to 32x compared to single-precision floating-point numbers) and maximizing\nthe benefits of fast SIMD instructions on modern hardware for measurable\nspeedups. However, in spite of the large body of work on binarization for\nclassical CNNs, this area remains largely unexplored in geometric deep\nlearning. In this paper, we present and evaluate different strategies for the\nbinarization of graph neural networks. We show that through careful design of\nthe models, and control of the training process, binary graph neural networks\ncan be trained at only a moderate cost in accuracy on challenging benchmarks.\nIn particular, we present the first dynamic graph neural network in Hamming\nspace, able to leverage efficient k-NN search on binary vectors to speed-up the\nconstruction of the dynamic graph. We further verify that the binary models\noffer significant savings on embedded devices. Our code is publicly available\non Github.\n", "versions": [{"version": "v1", "created": "Thu, 31 Dec 2020 18:48:58 GMT"}, {"version": "v2", "created": "Mon, 29 Mar 2021 23:48:56 GMT"}], "update_date": "2021-03-31", "authors_parsed": [["Bahri", "Mehdi", ""], ["Bahl", "Ga\u00e9tan", ""], ["Zafeiriou", "Stefanos", ""]]}, {"id": "2012.15826", "submitter": "Shang-Wen Li", "authors": "Shang-Wen Li", "title": "Educational Content Linking for Enhancing Learning Need Remediation in\n  MOOCs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Since its introduction in 2011, there have been over 4000 MOOCs on various\nsubjects on the Web, serving over 35 million learners. MOOCs have shown the\nability to democratize knowledge dissemination and bring the best education in\nthe world to every learner. However, the disparate distances between\nparticipants, the size of the learner population, and the heterogeneity of the\nlearners' backgrounds make it extremely difficult for instructors to interact\nwith the learners in a timely manner, which adversely affects learning\nexperience. To address the challenges, in this thesis, we propose a framework:\neducational content linking. By linking and organizing pieces of learning\ncontent scattered in various course materials into an easily accessible\nstructure, we hypothesize that this framework can provide learners guidance and\nimprove content navigation. Since most instruction and knowledge acquisition in\nMOOCs takes place when learners are surveying course materials, better content\nnavigation may help learners find supporting information to resolve their\nconfusion and thus improve learning outcome and experience. To support our\nconjecture, we present end-to-end studies to investigate our framework around\ntwo research questions: 1) can manually generated linking improve learning? 2)\ncan learning content be generated with machine learning methods? For studying\nthe first question, we built an interface that present learning materials and\nvisualize the linking among them simultaneously. We found the interface enables\nusers to search for desired course materials more efficiently, and retain more\nconcepts more readily. For the second question, we propose an automatic content\nlinking algorithm based on conditional random fields. We demonstrate that\nautomatically generated linking can still lead to better learning, although the\nmagnitude of the improvement over the unlinked interface is smaller.\n", "versions": [{"version": "v1", "created": "Thu, 31 Dec 2020 18:51:15 GMT"}, {"version": "v2", "created": "Tue, 12 Jan 2021 15:33:50 GMT"}], "update_date": "2021-01-13", "authors_parsed": [["Li", "Shang-Wen", ""]]}, {"id": "2012.15834", "submitter": "Serguei Barannikov", "authors": "Serguei Barannikov, Grigorii Sotnikov, Ilya Trofimov, Alexander\n  Korotin, Evgeny Burnaev", "title": "Topological obstructions in neural networks learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.IT math.DS math.IT", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  We apply methods of topological data analysis to loss functions to gain\ninsights on learning of deep neural networks and their generalization\nproperties. We study global properties of the loss function gradient flow. We\nuse topological data analysis of the loss function and its Morse complex to\nrelate local behavior along gradient trajectories with global properties of the\nloss surface. We define neural network Topological Obstructions score,\nTO-score, with help of robust topological invariants, barcodes of loss\nfunction, that quantify the badness of local minima for gradient-based\noptimization. We have made several experiments for computing these invariants,\nfor small neural networks, and for fully connected, convolutional and\nResNet-like neural networks on different datasets: MNIST, Fashion MNIST,\nCIFAR10, SVHN. Our two principal observations are as follows. Firstly, the\nneural network barcode and TO-score decrease with the increase of the neural\nnetwork depth and width. Secondly, there is an intriguing connection between\nthe length of minima segments in the barcode and the minima generalization\nerror.\n", "versions": [{"version": "v1", "created": "Thu, 31 Dec 2020 18:53:25 GMT"}], "update_date": "2021-06-24", "authors_parsed": [["Barannikov", "Serguei", ""], ["Sotnikov", "Grigorii", ""], ["Trofimov", "Ilya", ""], ["Korotin", "Alexander", ""], ["Burnaev", "Evgeny", ""]]}, {"id": "2012.15835", "submitter": "Robert B. Allen", "authors": "Robert B. Allen", "title": "Semantic Modeling with SUMO", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  We explore using the Suggested Upper Merged Ontology (SUMO) to develop a\nsemantic simulation. We provide two proof-of-concept demonstrations modeling\ntransitions in a simulated gasoline engine using a general-purpose programming\nlanguage. Rather than focusing on computationally highly intensive techniques,\nwe explore a less computationally intensive approach related to familiar\nsoftware engineering testing procedures. In addition, we propose structured\nrepresentations of terms based on linguistic approaches to lexicography.\n", "versions": [{"version": "v1", "created": "Thu, 31 Dec 2020 18:53:59 GMT"}, {"version": "v2", "created": "Tue, 5 Jan 2021 14:53:38 GMT"}, {"version": "v3", "created": "Tue, 12 Jan 2021 18:13:42 GMT"}], "update_date": "2021-01-13", "authors_parsed": [["Allen", "Robert B.", ""]]}, {"id": "2012.15843", "submitter": "Shabnam Daghaghi", "authors": "Shabnam Daghaghi, Tharun Medini, Nicholas Meisburger, Beidi Chen,\n  Mengnan Zhao, Anshumali Shrivastava", "title": "A Tale of Two Efficient and Informative Negative Sampling Distributions", "comments": "Published at ICML 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.DS cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Softmax classifiers with a very large number of classes naturally occur in\nmany applications such as natural language processing and information\nretrieval. The calculation of full softmax is costly from the computational and\nenergy perspective. There have been various sampling approaches to overcome\nthis challenge, popularly known as negative sampling (NS). Ideally, NS should\nsample negative classes from a distribution that is dependent on the input\ndata, the current parameters, and the correct positive class. Unfortunately,\ndue to the dynamically updated parameters and data samples, there is no\nsampling scheme that is provably adaptive and samples the negative classes\nefficiently. Therefore, alternative heuristics like random sampling, static\nfrequency-based sampling, or learning-based biased sampling, which primarily\ntrade either the sampling cost or the adaptivity of samples per iteration are\nadopted. In this paper, we show two classes of distributions where the sampling\nscheme is truly adaptive and provably generates negative samples in\nnear-constant time. Our implementation in C++ on CPU is significantly superior,\nboth in terms of wall-clock time and accuracy, compared to the most optimized\nTensorFlow implementations of other popular negative sampling approaches on\npowerful NVIDIA V100 GPU.\n", "versions": [{"version": "v1", "created": "Thu, 31 Dec 2020 18:56:41 GMT"}, {"version": "v2", "created": "Thu, 29 Jul 2021 03:02:26 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["Daghaghi", "Shabnam", ""], ["Medini", "Tharun", ""], ["Meisburger", "Nicholas", ""], ["Chen", "Beidi", ""], ["Zhao", "Mengnan", ""], ["Shrivastava", "Anshumali", ""]]}, {"id": "2012.15856", "submitter": "Qinyuan Ye", "authors": "Qinyuan Ye, Belinda Z. Li, Sinong Wang, Benjamin Bolte, Hao Ma,\n  Wen-tau Yih, Xiang Ren, Madian Khabsa", "title": "Studying Strategically: Learning to Mask for Closed-book QA", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Closed-book question-answering (QA) is a challenging task that requires a\nmodel to directly answer questions without access to external knowledge. It has\nbeen shown that directly fine-tuning pre-trained language models with\n(question, answer) examples yields surprisingly competitive performance, which\nis further improved upon through adding an intermediate pre-training stage\nbetween general pre-training and fine-tuning. Prior work used a heuristic\nduring this intermediate stage, whereby named entities and dates are masked,\nand the model is trained to recover these tokens. In this paper, we aim to\nlearn the optimal masking strategy for the intermediate pre-training stage. We\nfirst train our masking policy to extract spans that are likely to be tested,\nusing supervision from the downstream task itself, then deploy the learned\npolicy during intermediate pre-training. Thus, our policy packs task-relevant\nknowledge into the parameters of a language model. Our approach is particularly\neffective on TriviaQA, outperforming strong heuristics when used to pre-train\nBART.\n", "versions": [{"version": "v1", "created": "Thu, 31 Dec 2020 18:59:08 GMT"}, {"version": "v2", "created": "Fri, 1 Jan 2021 18:50:48 GMT"}], "update_date": "2021-01-05", "authors_parsed": [["Ye", "Qinyuan", ""], ["Li", "Belinda Z.", ""], ["Wang", "Sinong", ""], ["Bolte", "Benjamin", ""], ["Ma", "Hao", ""], ["Yih", "Wen-tau", ""], ["Ren", "Xiang", ""], ["Khabsa", "Madian", ""]]}]