[{"id": "1704.00023", "submitter": "Tegjyot Singh Sethi", "authors": "Tegjyot Singh Sethi, Mehmed Kantardzic", "title": "On the Reliable Detection of Concept Drift from Streaming Unlabeled Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Classifiers deployed in the real world operate in a dynamic environment,\nwhere the data distribution can change over time. These changes, referred to as\nconcept drift, can cause the predictive performance of the classifier to drop\nover time, thereby making it obsolete. To be of any real use, these classifiers\nneed to detect drifts and be able to adapt to them, over time. Detecting drifts\nhas traditionally been approached as a supervised task, with labeled data\nconstantly being used for validating the learned model. Although effective in\ndetecting drifts, these techniques are impractical, as labeling is a difficult,\ncostly and time consuming activity. On the other hand, unsupervised change\ndetection techniques are unreliable, as they produce a large number of false\nalarms. The inefficacy of the unsupervised techniques stems from the exclusion\nof the characteristics of the learned classifier, from the detection process.\nIn this paper, we propose the Margin Density Drift Detection (MD3) algorithm,\nwhich tracks the number of samples in the uncertainty region of a classifier,\nas a metric to detect drift. The MD3 algorithm is a distribution independent,\napplication independent, model independent, unsupervised and incremental\nalgorithm for reliably detecting drifts from data streams. Experimental\nevaluation on 6 drift induced datasets and 4 additional datasets from the\ncybersecurity domain demonstrates that the MD3 approach can reliably detect\ndrifts, with significantly fewer false alarms compared to unsupervised feature\nbased drift detectors. The reduced false alarms enables the signaling of drifts\nonly when they are most likely to affect classification performance. As such,\nthe MD3 approach leads to a detection scheme which is credible, label efficient\nand general in its applicability.\n", "versions": [{"version": "v1", "created": "Fri, 31 Mar 2017 18:55:48 GMT"}], "update_date": "2017-04-04", "authors_parsed": [["Sethi", "Tegjyot Singh", ""], ["Kantardzic", "Mehmed", ""]]}, {"id": "1704.00045", "submitter": "Amir Ahooye Atashin", "authors": "Majid Mohammadi, Amir Ahooye Atashin, Wout Hofman, Yao-Hua Tan", "title": "Comparison of ontology alignment systems across single matching task via\n  the McNemar's test", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ontology alignment is widely-used to find the correspondences between\ndifferent ontologies in diverse fields.After discovering the alignments,several\nperformance scores are available to evaluate them.The scores typically require\nthe identified alignment and a reference containing the underlying actual\ncorrespondences of the given ontologies.The current trend in the alignment\nevaluation is to put forward a new score(e.g., precision, weighted precision,\netc.)and to compare various alignments by juxtaposing the obtained scores.\nHowever,it is substantially provocative to select one measure among others for\ncomparison.On top of that, claiming if one system has a better performance than\none another cannot be substantiated solely by comparing two scalars.In this\npaper,we propose the statistical procedures which enable us to theoretically\nfavor one system over one another.The McNemar's test is the statistical means\nby which the comparison of two ontology alignment systems over one matching\ntask is drawn.The test applies to a 2x2 contingency table which can be\nconstructed in two different ways based on the alignments,each of which has\ntheir own merits/pitfalls.The ways of the contingency table construction and\nvarious apposite statistics from the McNemar's test are elaborated in minute\ndetail.In the case of having more than two alignment systems for comparison,\nthe family-wise error rate is expected to happen. Thus, the ways of preventing\nsuch an error are also discussed.A directed graph visualizes the outcome of the\nMcNemar's test in the presence of multiple alignment systems.From this graph,\nit is readily understood if one system is better than one another or if their\ndifferences are imperceptible.The proposed statistical methodologies are\napplied to the systems participated in the OAEI 2016 anatomy track, and also\ncompares several well-known similarity metrics for the same matching problem.\n", "versions": [{"version": "v1", "created": "Wed, 29 Mar 2017 15:20:01 GMT"}, {"version": "v2", "created": "Fri, 20 Apr 2018 12:58:37 GMT"}], "update_date": "2018-04-23", "authors_parsed": [["Mohammadi", "Majid", ""], ["Atashin", "Amir Ahooye", ""], ["Hofman", "Wout", ""], ["Tan", "Yao-Hua", ""]]}, {"id": "1704.00115", "submitter": "Mostafa Milani", "authors": "Leopoldo Bertossi, Mostafa Milani", "title": "Ontological Multidimensional Data Models and Contextual Data Qality", "comments": "Journal submission (revised version addressing reviewers'\n  observations) Extended version of RuleML'15 paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data quality assessment and data cleaning are context-dependent activities.\nMotivated by this observation, we propose the Ontological Multidimensional Data\nModel (OMD model), which can be used to model and represent contexts as\nlogic-based ontologies. The data under assessment is mapped into the context,\nfor additional analysis, processing, and quality data extraction. The resulting\ncontexts allow for the representation of dimensions, and multidimensional data\nquality assessment becomes possible. At the core of a multidimensional context\nwe include a generalized multidimensional data model and a Datalog+/- ontology\nwith provably good properties in terms of query answering. These main\ncomponents are used to represent dimension hierarchies, dimensional\nconstraints, dimensional rules, and define predicates for quality data\nspecification. Query answering relies upon and triggers navigation through\ndimension hierarchies, and becomes the basic tool for the extraction of quality\ndata. The OMD model is interesting per se, beyond applications to data quality.\nIt allows for a logic-based, and computationally tractable representation of\nmultidimensional data, extending previous multidimensional data models with\nadditional expressive power and functionalities.\n", "versions": [{"version": "v1", "created": "Sat, 1 Apr 2017 03:50:53 GMT"}, {"version": "v2", "created": "Sun, 13 Aug 2017 21:11:37 GMT"}], "update_date": "2017-08-15", "authors_parsed": [["Bertossi", "Leopoldo", ""], ["Milani", "Mostafa", ""]]}, {"id": "1704.00217", "submitter": "Zhiting Hu", "authors": "Lianhui Qin, Zhisong Zhang, Hai Zhao, Zhiting Hu, Eric P. Xing", "title": "Adversarial Connective-exploiting Networks for Implicit Discourse\n  Relation Classification", "comments": "To appear in ACL2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Implicit discourse relation classification is of great challenge due to the\nlack of connectives as strong linguistic cues, which motivates the use of\nannotated implicit connectives to improve the recognition. We propose a feature\nimitation framework in which an implicit relation network is driven to learn\nfrom another neural network with access to connectives, and thus encouraged to\nextract similarly salient features for accurate classification. We develop an\nadversarial model to enable an adaptive imitation scheme through competition\nbetween the implicit network and a rival feature discriminator. Our method\neffectively transfers discriminability of connectives to the implicit features,\nand achieves state-of-the-art performance on the PDTB benchmark.\n", "versions": [{"version": "v1", "created": "Sat, 1 Apr 2017 19:29:21 GMT"}], "update_date": "2017-04-04", "authors_parsed": [["Qin", "Lianhui", ""], ["Zhang", "Zhisong", ""], ["Zhao", "Hai", ""], ["Hu", "Zhiting", ""], ["Xing", "Eric P.", ""]]}, {"id": "1704.00260", "submitter": "Tanmay Gupta", "authors": "Tanmay Gupta, Kevin Shih, Saurabh Singh, and Derek Hoiem", "title": "Aligned Image-Word Representations Improve Inductive Transfer Across\n  Vision-Language Tasks", "comments": "Accepted in ICCV 2017. The arxiv version has an extra analysis on\n  correlation with human attention", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An important goal of computer vision is to build systems that learn visual\nrepresentations over time that can be applied to many tasks. In this paper, we\ninvestigate a vision-language embedding as a core representation and show that\nit leads to better cross-task transfer than standard multi-task learning. In\nparticular, the task of visual recognition is aligned to the task of visual\nquestion answering by forcing each to use the same word-region embeddings. We\nshow this leads to greater inductive transfer from recognition to VQA than\nstandard multitask learning. Visual recognition also improves, especially for\ncategories that have relatively few recognition training labels but appear\noften in the VQA setting. Thus, our paper takes a small step towards creating\nmore general vision systems by showing the benefit of interpretable, flexible,\nand trainable core representations.\n", "versions": [{"version": "v1", "created": "Sun, 2 Apr 2017 08:01:30 GMT"}, {"version": "v2", "created": "Mon, 16 Oct 2017 05:34:24 GMT"}], "update_date": "2017-10-17", "authors_parsed": [["Gupta", "Tanmay", ""], ["Shih", "Kevin", ""], ["Singh", "Saurabh", ""], ["Hoiem", "Derek", ""]]}, {"id": "1704.00264", "submitter": "Ahmed Qureshi", "authors": "Ahmed Hussain Qureshi and Yasar Ayaz", "title": "Potential Functions based Sampling Heuristic For Optimal Path Planning", "comments": "This paper introduces a novel algorithm called P-RRT*. The work has\n  been published in Springer Autonomous Robots Journal", "journal-ref": "Autonomous Robots 40, no. 6 (2016): 1079-1093", "doi": "10.1007/s10514-015-9518-0", "report-no": null, "categories": "cs.RO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Rapidly-exploring Random Tree Star(RRT*) is a recently proposed extension of\nRapidly-exploring Random Tree (RRT) algorithm that provides a collision-free,\nasymptotically optimal path regardless of obstacle's geometry in a given\nenvironment. However, one of the limitations in the RRT* algorithm is slow\nconvergence to optimal path solution. As a result, it consumes high memory as\nwell as time due to a large number of iterations utilised in achieving optimal\npath solution. To overcome these limitations, we propose the Potential Function\nBased-RRT* (P-RRT*) that incorporates the Artificial Potential Field Algorithm\nin RRT*. The proposed algorithm allows a considerable decrease in the number of\niterations and thus leads to more efficient memory utilization and an\naccelerated convergence rate. In order to illustrate the usefulness of the\nproposed algorithm in terms of space execution and convergence rate, this paper\npresents rigorous simulation based comparisons between the proposed techniques\nand RRT* under different environmental conditions. Moreover, both algorithms\nare also tested and compared under non-holonomic differential constraints.\n", "versions": [{"version": "v1", "created": "Sun, 2 Apr 2017 08:21:30 GMT"}], "update_date": "2017-04-04", "authors_parsed": [["Qureshi", "Ahmed Hussain", ""], ["Ayaz", "Yasar", ""]]}, {"id": "1704.00325", "submitter": "Sayyed Ali Mirsoleimani", "authors": "S. Ali Mirsoleimani, Aske Plaat, Jaap van den Herik and Jos Vermaseren", "title": "Structured Parallel Programming for Monte Carlo Tree Search", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present a new algorithm for parallel Monte Carlo tree\nsearch (MCTS). It is based on the pipeline pattern and allows flexible\nmanagement of the control flow of the operations in parallel MCTS. The pipeline\npattern provides for the first structured parallel programming approach to\nMCTS. Moreover, we propose a new lock-free tree data structure for parallel\nMCTS which removes synchronization overhead. The Pipeline Pattern for Parallel\nMCTS algorithm (called 3PMCTS), scales very well to higher numbers of cores\nwhen compared to the existing methods.\n", "versions": [{"version": "v1", "created": "Sun, 2 Apr 2017 16:22:31 GMT"}], "update_date": "2017-04-04", "authors_parsed": [["Mirsoleimani", "S. Ali", ""], ["Plaat", "Aske", ""], ["Herik", "Jaap van den", ""], ["Vermaseren", "Jos", ""]]}, {"id": "1704.00514", "submitter": "Isabelle Augenstein", "authors": "Isabelle Augenstein, Anders S{\\o}gaard", "title": "Multi-Task Learning of Keyphrase Boundary Classification", "comments": "ACL 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Keyphrase boundary classification (KBC) is the task of detecting keyphrases\nin scientific articles and labelling them with respect to predefined types.\nAlthough important in practice, this task is so far underexplored, partly due\nto the lack of labelled data. To overcome this, we explore several auxiliary\ntasks, including semantic super-sense tagging and identification of multi-word\nexpressions, and cast the task as a multi-task learning problem with deep\nrecurrent neural networks. Our multi-task models perform significantly better\nthan previous state of the art approaches on two scientific KBC datasets,\nparticularly for long keyphrases.\n", "versions": [{"version": "v1", "created": "Mon, 3 Apr 2017 10:25:22 GMT"}, {"version": "v2", "created": "Wed, 26 Apr 2017 16:48:49 GMT"}], "update_date": "2017-04-27", "authors_parsed": [["Augenstein", "Isabelle", ""], ["S\u00f8gaard", "Anders", ""]]}, {"id": "1704.00616", "submitter": "Mohammadreza Zolfaghari", "authors": "Mohammadreza Zolfaghari, Gabriel L. Oliveira, Nima Sedaghat, and\n  Thomas Brox", "title": "Chained Multi-stream Networks Exploiting Pose, Motion, and Appearance\n  for Action Classification and Detection", "comments": "10 pages, 7 figures, ICCV 2017 submission", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.HC cs.MM cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  General human action recognition requires understanding of various visual\ncues. In this paper, we propose a network architecture that computes and\nintegrates the most important visual cues for action recognition: pose, motion,\nand the raw images. For the integration, we introduce a Markov chain model\nwhich adds cues successively. The resulting approach is efficient and\napplicable to action classification as well as to spatial and temporal action\nlocalization. The two contributions clearly improve the performance over\nrespective baselines. The overall approach achieves state-of-the-art action\nclassification performance on HMDB51, J-HMDB and NTU RGB+D datasets. Moreover,\nit yields state-of-the-art spatio-temporal action localization results on\nUCF101 and J-HMDB.\n", "versions": [{"version": "v1", "created": "Mon, 3 Apr 2017 14:29:40 GMT"}, {"version": "v2", "created": "Fri, 26 May 2017 18:40:14 GMT"}], "update_date": "2017-05-30", "authors_parsed": [["Zolfaghari", "Mohammadreza", ""], ["Oliveira", "Gabriel L.", ""], ["Sedaghat", "Nima", ""], ["Brox", "Thomas", ""]]}, {"id": "1704.00637", "submitter": "Lars Maal{\\o}e", "authors": "Lars Maal{\\o}e and Marco Fraccaro and Ole Winther", "title": "Semi-Supervised Generation with Cluster-aware Generative Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep generative models trained with large amounts of unlabelled data have\nproven to be powerful within the domain of unsupervised learning. Many real\nlife data sets contain a small amount of labelled data points, that are\ntypically disregarded when training generative models. We propose the\nCluster-aware Generative Model, that uses unlabelled information to infer a\nlatent representation that models the natural clustering of the data, and\nadditional labelled data points to refine this clustering. The generative\nperformances of the model significantly improve when labelled information is\nexploited, obtaining a log-likelihood of -79.38 nats on permutation invariant\nMNIST, while also achieving competitive semi-supervised classification\naccuracies. The model can also be trained fully unsupervised, and still improve\nthe log-likelihood performance with respect to related methods.\n", "versions": [{"version": "v1", "created": "Mon, 3 Apr 2017 15:25:47 GMT"}], "update_date": "2017-04-04", "authors_parsed": [["Maal\u00f8e", "Lars", ""], ["Fraccaro", "Marco", ""], ["Winther", "Ole", ""]]}, {"id": "1704.00717", "submitter": "Viraj Prabhu", "authors": "Arjun Chandrasekaran, Deshraj Yadav, Prithvijit Chattopadhyay, Viraj\n  Prabhu, Devi Parikh", "title": "It Takes Two to Tango: Towards Theory of AI's Mind", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Theory of Mind is the ability to attribute mental states (beliefs, intents,\nknowledge, perspectives, etc.) to others and recognize that these mental states\nmay differ from one's own. Theory of Mind is critical to effective\ncommunication and to teams demonstrating higher collective performance. To\neffectively leverage the progress in Artificial Intelligence (AI) to make our\nlives more productive, it is important for humans and AI to work well together\nin a team. Traditionally, there has been much emphasis on research to make AI\nmore accurate, and (to a lesser extent) on having it better understand human\nintentions, tendencies, beliefs, and contexts. The latter involves making AI\nmore human-like and having it develop a theory of our minds. In this work, we\nargue that for human-AI teams to be effective, humans must also develop a\ntheory of AI's mind (ToAIM) - get to know its strengths, weaknesses, beliefs,\nand quirks. We instantiate these ideas within the domain of Visual Question\nAnswering (VQA). We find that using just a few examples (50), lay people can be\ntrained to better predict responses and oncoming failures of a complex VQA\nmodel. We further evaluate the role existing explanation (or interpretability)\nmodalities play in helping humans build ToAIM. Explainable AI has received\nconsiderable scientific and popular attention in recent times. Surprisingly, we\nfind that having access to the model's internal states - its confidence in its\ntop-k predictions, explicit or implicit attention maps which highlight regions\nin the image (and words in the question) the model is looking at (and listening\nto) while answering a question about an image - do not help people better\npredict its behavior.\n", "versions": [{"version": "v1", "created": "Mon, 3 Apr 2017 17:58:07 GMT"}, {"version": "v2", "created": "Mon, 2 Oct 2017 17:55:50 GMT"}], "update_date": "2017-10-03", "authors_parsed": [["Chandrasekaran", "Arjun", ""], ["Yadav", "Deshraj", ""], ["Chattopadhyay", "Prithvijit", ""], ["Prabhu", "Viraj", ""], ["Parikh", "Devi", ""]]}, {"id": "1704.00725", "submitter": "Hector Zenil", "authors": "Hector Zenil", "title": "Reprogramming Matter, Life, and Purpose", "comments": "Invited contribution to 'Computing in the year 2065', A. Adamatzky\n  (Ed.), Springer Verlag and published in the International Journal of\n  Unconventional Computing, 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reprogramming matter may sound far-fetched, but we have been doing it with\nincreasing power and staggering efficiency for at least 60 years, and for\ncenturies we have been paving the way toward the ultimate reprogrammed fate of\nthe universe, the vessel of all programs. How will we be doing it in 60 years'\ntime and how will it impact life and the purpose both of machines and of\nhumans?\n", "versions": [{"version": "v1", "created": "Sun, 2 Apr 2017 10:45:29 GMT"}, {"version": "v2", "created": "Mon, 8 May 2017 23:30:18 GMT"}, {"version": "v3", "created": "Thu, 11 May 2017 18:22:23 GMT"}, {"version": "v4", "created": "Sun, 13 Aug 2017 17:15:49 GMT"}], "update_date": "2017-08-15", "authors_parsed": [["Zenil", "Hector", ""]]}, {"id": "1704.00756", "submitter": "Romain Laroche", "authors": "Romain Laroche and Mehdi Fatemi and Joshua Romoff and Harm van Seijen", "title": "Multi-Advisor Reinforcement Learning", "comments": "Submitted at ICLR2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider tackling a single-agent RL problem by distributing it to $n$\nlearners. These learners, called advisors, endeavour to solve the problem from\na different focus. Their advice, taking the form of action values, is then\ncommunicated to an aggregator, which is in control of the system. We show that\nthe local planning method for the advisors is critical and that none of the\nones found in the literature is flawless: the egocentric planning overestimates\nvalues of states where the other advisors disagree, and the agnostic planning\nis inefficient around danger zones. We introduce a novel approach called\nempathic and discuss its theoretical aspects. We empirically examine and\nvalidate our theoretical findings on a fruit collection task.\n", "versions": [{"version": "v1", "created": "Mon, 3 Apr 2017 18:37:12 GMT"}, {"version": "v2", "created": "Tue, 14 Nov 2017 20:35:27 GMT"}], "update_date": "2017-11-16", "authors_parsed": [["Laroche", "Romain", ""], ["Fatemi", "Mehdi", ""], ["Romoff", "Joshua", ""], ["van Seijen", "Harm", ""]]}, {"id": "1704.00783", "submitter": "Gopal P. Sarma", "authors": "Gopal P. Sarma", "title": "Brief Notes on Hard Takeoff, Value Alignment, and Coherent Extrapolated\n  Volition", "comments": "3 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CY cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  I make some basic observations about hard takeoff, value alignment, and\ncoherent extrapolated volition, concepts which have been central in analyses of\nsuperintelligent AI systems.\n", "versions": [{"version": "v1", "created": "Mon, 3 Apr 2017 19:45:04 GMT"}, {"version": "v2", "created": "Sat, 21 Apr 2018 20:32:30 GMT"}], "update_date": "2018-04-24", "authors_parsed": [["Sarma", "Gopal P.", ""]]}, {"id": "1704.00795", "submitter": "Utku Kose", "authors": "Utku Kose", "title": "Design and development of a software system for swarm intelligence based\n  research studies", "comments": "6 pages, 2 figures, 1 table", "journal-ref": "Broad Research in Artificial Intelligence and Neuroscience, 3(3),\n  2012, 12-17", "doi": null, "report-no": null, "categories": "cs.AI cs.SE", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  This paper introduce a software system including widely-used Swarm\nIntelligence algorithms or approaches to be used for the related scientific\nresearch studies associated with the subject area. The programmatic\ninfrastructure of the system allows working on a fast, easy-to-use, interactive\nplatform to perform Swarm Intelligence based studies in a more effective,\nefficient and accurate way. In this sense, the system employs all of the\nnecessary controls for the algorithms and it ensures an interactive platform on\nwhich computer users can perform studies on a wide spectrum of solution\napproaches associated with simple and also more advanced problems.\n", "versions": [{"version": "v1", "created": "Mon, 3 Apr 2017 20:17:32 GMT"}], "update_date": "2017-04-05", "authors_parsed": [["Kose", "Utku", ""]]}, {"id": "1704.00797", "submitter": "Utku Kose", "authors": "Utku Kose, Ahmet Arslan", "title": "On the idea of a new artificial intelligence based optimization\n  algorithm inspired from the nature of vortex", "comments": "7 pages, 1 figure, 2 tables", "journal-ref": "Broad Research in Artificial Intelligence and Neuroscience,\n  5(1-4), 2014, 60-66", "doi": null, "report-no": null, "categories": "cs.AI math.OC", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  In this paper, the idea of a new artificial intelligence based optimization\nalgorithm, which is inspired from the nature of vortex, has been provided\nbriefly. As also a bio-inspired computation algorithm, the idea is generally\nfocused on a typical vortex flow / behavior in nature and inspires from some\ndynamics that are occurred in the sense of vortex nature. Briefly, the\nalgorithm is also a swarm-oriented evolutional problem solution approach;\nbecause it includes many methods related to elimination of weak swarm members\nand trying to improve the solution process by supporting the solution space via\nnew swarm members. In order have better idea about success of the algorithm; it\nhas been tested via some benchmark functions. At this point, the obtained\nresults show that the algorithm can be an alternative to the literature in\nterms of single-objective optimization solution ways. Vortex Optimization\nAlgorithm (VOA) is the name suggestion by the authors; for this new idea of\nintelligent optimization approach.\n", "versions": [{"version": "v1", "created": "Mon, 3 Apr 2017 20:22:52 GMT"}], "update_date": "2017-04-05", "authors_parsed": [["Kose", "Utku", ""], ["Arslan", "Ahmet", ""]]}, {"id": "1704.00853", "submitter": "Fred Glover", "authors": "Kenneth Sorensen, Marc Sevaux and Fred Glover", "title": "A History of Metaheuristics", "comments": "27 pages, to appear in: R. Marti, P. Pardalos, and M. Resende, eds.,\n  Handbook of Heuristics, Springer", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This chapter describes the history of metaheuristics in five distinct\nperiods, starting long before the first use of the term and ending a long time\nin the future.\n", "versions": [{"version": "v1", "created": "Tue, 4 Apr 2017 02:28:59 GMT"}], "update_date": "2017-04-05", "authors_parsed": [["Sorensen", "Kenneth", ""], ["Sevaux", "Marc", ""], ["Glover", "Fred", ""]]}, {"id": "1704.00917", "submitter": "J\\\"urgen Koslowski", "authors": "Sooraj Bhat and Johannes Borgstr\\\"om and Andrew D. Gordon and Claudio\n  Russo", "title": "Deriving Probability Density Functions from Probabilistic Functional\n  Programs", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 13, Issue 2 (July 3,\n  2017) lmcs:3758", "doi": "10.23638/LMCS-13(2:16)2017", "report-no": null, "categories": "cs.PL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The probability density function of a probability distribution is a\nfundamental concept in probability theory and a key ingredient in various\nwidely used machine learning methods. However, the necessary framework for\ncompiling probabilistic functional programs to density functions has only\nrecently been developed. In this work, we present a density compiler for a\nprobabilistic language with failure and both discrete and continuous\ndistributions, and provide a proof of its soundness. The compiler greatly\nreduces the development effort of domain experts, which we demonstrate by\nsolving inference problems from various scientific applications, such as\nmodelling the global carbon cycle, using a standard Markov chain Monte Carlo\nframework.\n", "versions": [{"version": "v1", "created": "Tue, 4 Apr 2017 08:27:21 GMT"}, {"version": "v2", "created": "Thu, 29 Jun 2017 19:47:20 GMT"}], "update_date": "2019-03-14", "authors_parsed": [["Bhat", "Sooraj", ""], ["Borgstr\u00f6m", "Johannes", ""], ["Gordon", "Andrew D.", ""], ["Russo", "Claudio", ""]]}, {"id": "1704.00961", "submitter": "Ruck Thawonmas", "authors": "Pujana Paliyawan, Takahiro Kusano, Yuto Nakagawa, Tomohiro Harada,\n  Ruck Thawonmas", "title": "Adaptive Motion Gaming AI for Health Promotion", "comments": "A revised version of our paper for 2017 AAAI Spring Symposium Series\n  (Well-Being AI: From Machine Learning to Subjective Oriented Computing), San\n  Francisco,USA, Mar. 27-29, 2017. Revised contents, due to our correction of\n  (8), are highlighted in red. Many apologies, but the effectiveness of the\n  proposed method/approach in the paper still holds", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CY cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a design of a non-player character (AI) for promoting\nbalancedness in use of body segments when engaging in full-body motion gaming.\nIn our experiment, we settle a battle between the proposed AI and a player by\nusing FightingICE, a fighting game platform for AI development. A middleware\ncalled UKI is used to allow the player to control the game by using body motion\ninstead of the keyboard and mouse. During gameplay, the proposed AI analyze\nhealth states of the player; it determines its next action by predicting how\neach candidate action, recommended by a Monte-Carlo tree search algorithm, will\ninduce the player to move, and how the player's health tends to be affected.\nOur result demonstrates successful improvement in balancedness in use of body\nsegments on 4 out of 5 subjects.\n", "versions": [{"version": "v1", "created": "Tue, 4 Apr 2017 11:29:02 GMT"}], "update_date": "2017-04-05", "authors_parsed": [["Paliyawan", "Pujana", ""], ["Kusano", "Takahiro", ""], ["Nakagawa", "Yuto", ""], ["Harada", "Tomohiro", ""], ["Thawonmas", "Ruck", ""]]}, {"id": "1704.01006", "submitter": "Gerrit Bagschik", "authors": "Gerrit Bagschik, Till Menzel, Markus Maurer", "title": "Ontology based Scene Creation for the Development of Automated Vehicles", "comments": "Accepted at the 2018 IEEE Intelligent Vehicles Symposium, 8 pages, 10\n  figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The introduction of automated vehicles without permanent human supervision\ndemands a functional system description, including functional system boundaries\nand a comprehensive safety analysis. These inputs to the technical development\ncan be identified and analyzed by a scenario-based approach. Furthermore, to\nestablish an economical test and release process, a large number of scenarios\nmust be identified to obtain meaningful test results. Experts are doing well to\nidentify scenarios that are difficult to handle or unlikely to happen. However,\nexperts are unlikely to identify all scenarios possible based on the knowledge\nthey have on hand. Expert knowledge modeled for computer aided processing may\nhelp for the purpose of providing a wide range of scenarios. This contribution\nreviews ontologies as knowledge-based systems in the field of automated\nvehicles, and proposes a generation of traffic scenes in natural language as a\nbasis for a scenario creation.\n", "versions": [{"version": "v1", "created": "Wed, 29 Mar 2017 20:02:39 GMT"}, {"version": "v2", "created": "Thu, 15 Jun 2017 07:22:17 GMT"}, {"version": "v3", "created": "Thu, 4 Jan 2018 11:56:14 GMT"}, {"version": "v4", "created": "Fri, 19 Jan 2018 08:50:19 GMT"}, {"version": "v5", "created": "Mon, 23 Apr 2018 20:25:41 GMT"}], "update_date": "2018-04-25", "authors_parsed": [["Bagschik", "Gerrit", ""], ["Menzel", "Till", ""], ["Maurer", "Markus", ""]]}, {"id": "1704.01014", "submitter": "Robert Rovetto", "authors": "Robert J. Rovetto", "title": "An Ontological Architecture for Orbital Debris Data", "comments": null, "journal-ref": "Earth Science Informatics (Aug 2015) 9:67, pp.67-82, Springer", "doi": "10.1007/s12145-015-0233-3", "report-no": null, "categories": "cs.AI cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The orbital debris problem presents an opportunity for inter-agency and\ninternational cooperation toward the mutually beneficial goals of debris\nprevention, mitigation, remediation, and improved space situational awareness\n(SSA). Achieving these goals requires sharing orbital debris and other SSA\ndata. Toward this, I present an ontological architecture for the orbital debris\ndomain, taking steps in the creation of an orbital debris ontology (ODO). The\npurpose of this ontological system is to (I) represent general orbital debris\nand SSA domain knowledge, (II) structure, and standardize where needed, orbital\ndata and terminology, and (III) foster semantic interoperability and\ndata-sharing. In doing so I hope to (IV) contribute to solving the orbital\ndebris problem, improving peaceful global SSA, and ensuring safe space travel\nfor future generations.\n", "versions": [{"version": "v1", "created": "Sat, 1 Apr 2017 21:26:37 GMT"}, {"version": "v2", "created": "Thu, 28 Dec 2017 06:25:39 GMT"}], "update_date": "2017-12-29", "authors_parsed": [["Rovetto", "Robert J.", ""]]}, {"id": "1704.01049", "submitter": "Carina Geldhauser", "authors": "Alexander Eckrot and Carina Geldhauser and Jan Jurczyk", "title": "A simulated annealing approach to optimal storing in a multi-level\n  warehouse", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a simulated annealing algorithm specifically tailored to optimise\ntotal retrieval times in a multi-level warehouse under complex pre-batched\npicking constraints. Experiments on real data from a picker-to-parts order\npicking process in the warehouse of a European manufacturer show that optimal\nstorage assignments do not necessarily display features presumed in heuristics,\nsuch as clustering of positively correlated items or ordering of items by\npicking frequency.\n  In an experiment run on more than 4000 batched orders with 1 to 150 items per\nbatch, the storage assignment suggested by the algorithm produces a 21\\%\nreduction in the total retrieval time with respect to a frequency-based storage\nassignment.\n", "versions": [{"version": "v1", "created": "Sat, 25 Mar 2017 14:15:35 GMT"}], "update_date": "2017-04-05", "authors_parsed": [["Eckrot", "Alexander", ""], ["Geldhauser", "Carina", ""], ["Jurczyk", "Jan", ""]]}, {"id": "1704.01074", "submitter": "Hao Zhou", "authors": "Hao Zhou, Minlie Huang, Tianyang Zhang, Xiaoyan Zhu, Bing Liu", "title": "Emotional Chatting Machine: Emotional Conversation Generation with\n  Internal and External Memory", "comments": "Accepted in AAAI 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Perception and expression of emotion are key factors to the success of\ndialogue systems or conversational agents. However, this problem has not been\nstudied in large-scale conversation generation so far. In this paper, we\npropose Emotional Chatting Machine (ECM) that can generate appropriate\nresponses not only in content (relevant and grammatical) but also in emotion\n(emotionally consistent). To the best of our knowledge, this is the first work\nthat addresses the emotion factor in large-scale conversation generation. ECM\naddresses the factor using three new mechanisms that respectively (1) models\nthe high-level abstraction of emotion expressions by embedding emotion\ncategories, (2) captures the change of implicit internal emotion states, and\n(3) uses explicit emotion expressions with an external emotion vocabulary.\nExperiments show that the proposed model can generate responses appropriate not\nonly in content but also in emotion.\n", "versions": [{"version": "v1", "created": "Tue, 4 Apr 2017 15:44:48 GMT"}, {"version": "v2", "created": "Wed, 19 Apr 2017 10:17:53 GMT"}, {"version": "v3", "created": "Thu, 14 Sep 2017 10:29:06 GMT"}, {"version": "v4", "created": "Fri, 1 Jun 2018 03:38:59 GMT"}], "update_date": "2018-06-04", "authors_parsed": [["Zhou", "Hao", ""], ["Huang", "Minlie", ""], ["Zhang", "Tianyang", ""], ["Zhu", "Xiaoyan", ""], ["Liu", "Bing", ""]]}, {"id": "1704.01087", "submitter": "Feras Saad", "authors": "Feras Saad, Leonardo Casarsa, Vikash Mansinghka", "title": "Probabilistic Search for Structured Data via Probabilistic Programming\n  and Nonparametric Bayes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.DB cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Databases are widespread, yet extracting relevant data can be difficult.\nWithout substantial domain knowledge, multivariate search queries often return\nsparse or uninformative results. This paper introduces an approach for\nsearching structured data based on probabilistic programming and nonparametric\nBayes. Users specify queries in a probabilistic language that combines standard\nSQL database search operators with an information theoretic ranking function\ncalled predictive relevance. Predictive relevance can be calculated by a fast\nsparse matrix algorithm based on posterior samples from CrossCat, a\nnonparametric Bayesian model for high-dimensional, heterogeneously-typed data\ntables. The result is a flexible search technique that applies to a broad class\nof information retrieval problems, which we integrate into BayesDB, a\nprobabilistic programming platform for probabilistic data analysis. This paper\ndemonstrates applications to databases of US colleges, global macroeconomic\nindicators of public health, and classic cars. We found that human evaluators\noften prefer the results from probabilistic search to results from a standard\nbaseline.\n", "versions": [{"version": "v1", "created": "Tue, 4 Apr 2017 16:18:07 GMT"}], "update_date": "2017-04-05", "authors_parsed": [["Saad", "Feras", ""], ["Casarsa", "Leonardo", ""], ["Mansinghka", "Vikash", ""]]}, {"id": "1704.01161", "submitter": "Gal Dalal", "authors": "Gal Dalal, Bal\\'azs Sz\\\"or\\'enyi, Gugan Thoppe, Shie Mannor", "title": "Finite Sample Analyses for TD(0) with Function Approximation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  TD(0) is one of the most commonly used algorithms in reinforcement learning.\nDespite this, there is no existing finite sample analysis for TD(0) with\nfunction approximation, even for the linear case. Our work is the first to\nprovide such results. Existing convergence rates for Temporal Difference (TD)\nmethods apply only to somewhat modified versions, e.g., projected variants or\nones where stepsizes depend on unknown problem parameters. Our analyses obviate\nthese artificial alterations by exploiting strong properties of TD(0). We\nprovide convergence rates both in expectation and with high-probability. The\ntwo are obtained via different approaches that use relatively unknown, recently\ndeveloped stochastic approximation techniques.\n", "versions": [{"version": "v1", "created": "Tue, 4 Apr 2017 19:47:52 GMT"}, {"version": "v2", "created": "Sun, 2 Jul 2017 10:28:28 GMT"}, {"version": "v3", "created": "Thu, 30 Nov 2017 18:24:15 GMT"}, {"version": "v4", "created": "Mon, 11 Dec 2017 08:21:21 GMT"}], "update_date": "2017-12-12", "authors_parsed": [["Dalal", "Gal", ""], ["Sz\u00f6r\u00e9nyi", "Bal\u00e1zs", ""], ["Thoppe", "Gugan", ""], ["Mannor", "Shie", ""]]}, {"id": "1704.01279", "submitter": "Jesse Engel", "authors": "Jesse Engel, Cinjon Resnick, Adam Roberts, Sander Dieleman, Douglas\n  Eck, Karen Simonyan, Mohammad Norouzi", "title": "Neural Audio Synthesis of Musical Notes with WaveNet Autoencoders", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative models in vision have seen rapid progress due to algorithmic\nimprovements and the availability of high-quality image datasets. In this\npaper, we offer contributions in both these areas to enable similar progress in\naudio modeling. First, we detail a powerful new WaveNet-style autoencoder model\nthat conditions an autoregressive decoder on temporal codes learned from the\nraw audio waveform. Second, we introduce NSynth, a large-scale and high-quality\ndataset of musical notes that is an order of magnitude larger than comparable\npublic datasets. Using NSynth, we demonstrate improved qualitative and\nquantitative performance of the WaveNet autoencoder over a well-tuned spectral\nautoencoder baseline. Finally, we show that the model learns a manifold of\nembeddings that allows for morphing between instruments, meaningfully\ninterpolating in timbre to create new types of sounds that are realistic and\nexpressive.\n", "versions": [{"version": "v1", "created": "Wed, 5 Apr 2017 06:34:22 GMT"}], "update_date": "2017-04-06", "authors_parsed": [["Engel", "Jesse", ""], ["Resnick", "Cinjon", ""], ["Roberts", "Adam", ""], ["Dieleman", "Sander", ""], ["Eck", "Douglas", ""], ["Simonyan", "Karen", ""], ["Norouzi", "Mohammad", ""]]}, {"id": "1704.01383", "submitter": "Michel Fliess", "authors": "Philip Polack, Brigitte d'Andr\\'ea-Novel, Michel Fliess, Arnaud de la\n  Fortelle, Lghani Menhour", "title": "Finite-Time Stabilization of Longitudinal Control for Autonomous\n  Vehicles via a Model-Free Approach", "comments": "IFAC 2017 World Congress, Toulouse", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SY cs.AI math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This communication presents a longitudinal model-free control approach for\ncomputing the wheel torque command to be applied on a vehicle. This setting\nenables us to overcome the problem of unknown vehicle parameters for generating\na suitable control law. An important parameter in this control setting is made\ntime-varying for ensuring finite-time stability. Several convincing computer\nsimulations are displayed and discussed. Overshoots become therefore smaller.\nThe driving comfort is increased and the robustness to time-delays is improved.\n", "versions": [{"version": "v1", "created": "Wed, 5 Apr 2017 12:35:20 GMT"}], "update_date": "2017-04-06", "authors_parsed": [["Polack", "Philip", ""], ["d'Andr\u00e9a-Novel", "Brigitte", ""], ["Fliess", "Michel", ""], ["de la Fortelle", "Arnaud", ""], ["Menhour", "Lghani", ""]]}, {"id": "1704.01399", "submitter": "Victor Dantas Mr.", "authors": "Victor Dantas, Henrique Santos, Carlos Caminha, Vasco Furtado", "title": "Geracao Automatica de Paineis de Controle para Analise de Mobilidade\n  Urbana Utilizando Redes Complexas", "comments": "12 pages, in Portuguese, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we describe an automatic generator to support the data\nscientist to construct, in a user-friendly way, dashboards from data\nrepresented as networks. The generator called SBINet (Semantic for Business\nIntelligence from Networks) has a semantic layer that, through ontologies,\ndescribes the data that represents a network as well as the possible metrics to\nbe calculated in the network. Thus, with SBINet, the stages of the dashboard\nconstructing process that uses complex network metrics are facilitated and can\nbe done by users who do not necessarily know about complex networks.\n", "versions": [{"version": "v1", "created": "Tue, 4 Apr 2017 12:04:03 GMT"}], "update_date": "2017-04-06", "authors_parsed": [["Dantas", "Victor", ""], ["Santos", "Henrique", ""], ["Caminha", "Carlos", ""], ["Furtado", "Vasco", ""]]}, {"id": "1704.01407", "submitter": "Cl\\'ement Moulin-Frier", "authors": "Cl\\'ement Moulin-Frier, Jordi-Ysard Puigb\\`o, Xerxes D. Arsiwalla,\n  Mart\\`i Sanchez-Fibla, Paul F. M. J. Verschure", "title": "Embodied Artificial Intelligence through Distributed Adaptive Control:\n  An Integrated Framework", "comments": "Updated version of the paper accepted to the ICDL-Epirob 2017\n  conference (Lisbon, Portugal)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we argue that the future of Artificial Intelligence research\nresides in two keywords: integration and embodiment. We support this claim by\nanalyzing the recent advances of the field. Regarding integration, we note that\nthe most impactful recent contributions have been made possible through the\nintegration of recent Machine Learning methods (based in particular on Deep\nLearning and Recurrent Neural Networks) with more traditional ones (e.g.\nMonte-Carlo tree search, goal babbling exploration or addressable memory\nsystems). Regarding embodiment, we note that the traditional benchmark tasks\n(e.g. visual classification or board games) are becoming obsolete as\nstate-of-the-art learning algorithms approach or even surpass human performance\nin most of them, having recently encouraged the development of first-person 3D\ngame platforms embedding realistic physics. Building upon this analysis, we\nfirst propose an embodied cognitive architecture integrating heterogenous\nsub-fields of Artificial Intelligence into a unified framework. We demonstrate\nthe utility of our approach by showing how major contributions of the field can\nbe expressed within the proposed framework. We then claim that benchmarking\nenvironments need to reproduce ecologically-valid conditions for bootstrapping\nthe acquisition of increasingly complex cognitive skills through the concept of\na cognitive arms race between embodied agents.\n", "versions": [{"version": "v1", "created": "Wed, 5 Apr 2017 13:26:50 GMT"}, {"version": "v2", "created": "Thu, 15 Jun 2017 08:40:20 GMT"}, {"version": "v3", "created": "Mon, 18 Sep 2017 16:27:46 GMT"}], "update_date": "2017-09-19", "authors_parsed": [["Moulin-Frier", "Cl\u00e9ment", ""], ["Puigb\u00f2", "Jordi-Ysard", ""], ["Arsiwalla", "Xerxes D.", ""], ["Sanchez-Fibla", "Mart\u00ec", ""], ["Verschure", "Paul F. M. J.", ""]]}, {"id": "1704.01415", "submitter": "Zhi-Hua Zhou", "authors": "Yue Zhu and James T. Kwok and Zhi-Hua Zhou", "title": "Multi-Label Learning with Global and Local Label Correlation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is well-known that exploiting label correlations is important to\nmulti-label learning. Existing approaches either assume that the label\ncorrelations are global and shared by all instances; or that the label\ncorrelations are local and shared only by a data subset. In fact, in the\nreal-world applications, both cases may occur that some label correlations are\nglobally applicable and some are shared only in a local group of instances.\nMoreover, it is also a usual case that only partial labels are observed, which\nmakes the exploitation of the label correlations much more difficult. That is,\nit is hard to estimate the label correlations when many labels are absent. In\nthis paper, we propose a new multi-label approach GLOCAL dealing with both the\nfull-label and the missing-label cases, exploiting global and local label\ncorrelations simultaneously, through learning a latent label representation and\noptimizing label manifolds. The extensive experimental studies validate the\neffectiveness of our approach on both full-label and missing-label data.\n", "versions": [{"version": "v1", "created": "Tue, 4 Apr 2017 12:50:25 GMT"}], "update_date": "2017-04-06", "authors_parsed": [["Zhu", "Yue", ""], ["Kwok", "James T.", ""], ["Zhou", "Zhi-Hua", ""]]}, {"id": "1704.01523", "submitter": "Franck Dernoncourt", "authors": "Ji Young Lee, Franck Dernoncourt, Peter Szolovits", "title": "MIT at SemEval-2017 Task 10: Relation Extraction with Convolutional\n  Neural Networks", "comments": "Accepted at SemEval 2017. The first two authors contributed equally\n  to this work", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Over 50 million scholarly articles have been published: they constitute a\nunique repository of knowledge. In particular, one may infer from them\nrelations between scientific concepts, such as synonyms and hyponyms.\nArtificial neural networks have been recently explored for relation extraction.\nIn this work, we continue this line of work and present a system based on a\nconvolutional neural network to extract relations. Our model ranked first in\nthe SemEval-2017 task 10 (ScienceIE) for relation extraction in scientific\narticles (subtask C).\n", "versions": [{"version": "v1", "created": "Wed, 5 Apr 2017 16:54:20 GMT"}], "update_date": "2017-04-06", "authors_parsed": [["Lee", "Ji Young", ""], ["Dernoncourt", "Franck", ""], ["Szolovits", "Peter", ""]]}, {"id": "1704.01568", "submitter": "Leslie Smith", "authors": "Leslie N. Smith", "title": "Best Practices for Applying Deep Learning to Novel Applications", "comments": null, "journal-ref": null, "doi": null, "report-no": "NRL Technical Note 5510-052", "categories": "cs.SE cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This report is targeted to groups who are subject matter experts in their\napplication but deep learning novices. It contains practical advice for those\ninterested in testing the use of deep neural networks on applications that are\nnovel for deep learning. We suggest making your project more manageable by\ndividing it into phases. For each phase this report contains numerous\nrecommendations and insights to assist novice practitioners.\n", "versions": [{"version": "v1", "created": "Wed, 5 Apr 2017 17:59:07 GMT"}], "update_date": "2017-04-06", "authors_parsed": [["Smith", "Leslie N.", ""]]}, {"id": "1704.01631", "submitter": "Shubham Toshniwal", "authors": "Shubham Toshniwal, Hao Tang, Liang Lu, Karen Livescu", "title": "Multitask Learning with Low-Level Auxiliary Tasks for Encoder-Decoder\n  Based Speech Recognition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  End-to-end training of deep learning-based models allows for implicit\nlearning of intermediate representations based on the final task loss. However,\nthe end-to-end approach ignores the useful domain knowledge encoded in explicit\nintermediate-level supervision. We hypothesize that using intermediate\nrepresentations as auxiliary supervision at lower levels of deep networks may\nbe a good way of combining the advantages of end-to-end training and more\ntraditional pipeline approaches. We present experiments on conversational\nspeech recognition where we use lower-level tasks, such as phoneme recognition,\nin a multitask training approach with an encoder-decoder model for direct\ncharacter transcription. We compare multiple types of lower-level tasks and\nanalyze the effects of the auxiliary tasks. Our results on the Switchboard\ncorpus show that this approach improves recognition accuracy over a standard\nencoder-decoder model on the Eval2000 test set.\n", "versions": [{"version": "v1", "created": "Wed, 5 Apr 2017 19:44:23 GMT"}, {"version": "v2", "created": "Wed, 19 Apr 2017 16:01:53 GMT"}], "update_date": "2017-04-20", "authors_parsed": [["Toshniwal", "Shubham", ""], ["Tang", "Hao", ""], ["Lu", "Liang", ""], ["Livescu", "Karen", ""]]}, {"id": "1704.01742", "submitter": "Mieczys{\\l}aw K{\\l}opotek", "authors": "Mieczys{\\l}aw K{\\l}opotek", "title": "Transferrable Plausibility Model - A Probabilistic Interpretation of\n  Mathematical Theory of Evidence", "comments": "Pre-publication version of: M.A. K{\\l}opotek: Transferable\n  Plausibility Model - A Probabilistic Interpretation of Mathematical Theory of\n  Evidence O.Hryniewicz, J. Kacprzyk, J.Koronacki, S.Wierzcho\\'{n}: Issues in\n  Intelligent Systems Paradigms Akademicka Oficyna Wydawnicza EXIT, Warszawa\n  2005 ISBN 83-87674-90-7, pp.107--118", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper suggests a new interpretation of the Dempster-Shafer theory in\nterms of probabilistic interpretation of plausibility. A new rule of\ncombination of independent evidence is shown and its preservation of\ninterpretation is demonstrated.\n", "versions": [{"version": "v1", "created": "Thu, 6 Apr 2017 08:08:38 GMT"}], "update_date": "2017-04-07", "authors_parsed": [["K\u0142opotek", "Mieczys\u0142aw", ""]]}, {"id": "1704.01759", "submitter": "Annamalai Narayanan", "authors": "Annamalai Narayanan, Mahinthan Chandramohan, Lihui Chen, Yang Liu", "title": "A Multi-view Context-aware Approach to Android Malware Detection and\n  Malicious Code Localization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing Android malware detection approaches use a variety of features such\nas security sensitive APIs, system calls, control-flow structures and\ninformation flows in conjunction with Machine Learning classifiers to achieve\naccurate detection. Each of these feature sets provides a unique semantic\nperspective (or view) of apps' behaviours with inherent strengths and\nlimitations. Meaning, some views are more amenable to detect certain attacks\nbut may not be suitable to characterise several other attacks. Most of the\nexisting malware detection approaches use only one (or a selected few) of the\naforementioned feature sets which prevent them from detecting a vast majority\nof attacks. Addressing this limitation, we propose MKLDroid, a unified\nframework that systematically integrates multiple views of apps for performing\ncomprehensive malware detection and malicious code localisation. The rationale\nis that, while a malware app can disguise itself in some views, disguising in\nevery view while maintaining malicious intent will be much harder.\n  MKLDroid uses a graph kernel to capture structural and contextual information\nfrom apps' dependency graphs and identify malice code patterns in each view.\nSubsequently, it employs Multiple Kernel Learning (MKL) to find a weighted\ncombination of the views which yields the best detection accuracy. Besides\nmulti-view learning, MKLDroid's unique and salient trait is its ability to\nlocate fine-grained malice code portions in dependency graphs (e.g.,\nmethods/classes). Through our large-scale experiments on several datasets\n(incl. wild apps), we demonstrate that MKLDroid outperforms three\nstate-of-the-art techniques consistently, in terms of accuracy while\nmaintaining comparable efficiency. In our malicious code localisation\nexperiments on a dataset of repackaged malware, MKLDroid was able to identify\nall the malice classes with 94% average recall.\n", "versions": [{"version": "v1", "created": "Thu, 6 Apr 2017 09:44:08 GMT"}, {"version": "v2", "created": "Sat, 8 Apr 2017 13:10:50 GMT"}], "update_date": "2017-04-11", "authors_parsed": [["Narayanan", "Annamalai", ""], ["Chandramohan", "Mahinthan", ""], ["Chen", "Lihui", ""], ["Liu", "Yang", ""]]}, {"id": "1704.01785", "submitter": "Johannes Rauh", "authors": "Guido Montufar and Johannes Rauh", "title": "Geometry of Policy Improvement", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the geometry of optimal memoryless time independent decision\nmaking in relation to the amount of information that the acting agent has about\nthe state of the system. We show that the expected long term reward, discounted\nor per time step, is maximized by policies that randomize among at most $k$\nactions whenever at most $k$ world states are consistent with the agent's\nobservation. Moreover, we show that the expected reward per time step can be\nstudied in terms of the expected discounted reward. Our main tool is a\ngeometric version of the policy improvement lemma, which identifies a\npolyhedral cone of policy changes in which the state value function increases\nfor all states.\n", "versions": [{"version": "v1", "created": "Thu, 6 Apr 2017 11:17:54 GMT"}], "update_date": "2017-04-07", "authors_parsed": [["Montufar", "Guido", ""], ["Rauh", "Johannes", ""]]}, {"id": "1704.01802", "submitter": "Henrique Oliveira Santos", "authors": "Henrique Santos, Vasco Furtado, Paulo Pinheiro, Deborah L. McGuinness", "title": "Contextual Data Collection for Smart Cities", "comments": "In Proceedings of the 6th Workshop on Semantics for Smarter Cities\n  (S4SC 2015), Bethlehem, PA, USA, October 11-12, 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As part of Smart Cities initiatives, national, regional and local governments\nall over the globe are under the mandate of being more open regarding how they\nshare their data. Under this mandate, many of these governments are publishing\ndata under the umbrella of open government data, which includes measurement\ndata from city-wide sensor networks. Furthermore, many of these data are\npublished in so-called data portals as documents that may be spreadsheets,\ncomma-separated value (CSV) data files, or plain documents in PDF or Word\ndocuments. The sharing of these documents may be a convenient way for the data\nprovider to convey and publish data but it is not the ideal way for data\nconsumers to reuse the data. For example, the problems of reusing the data may\nrange from difficulty opening a document that is provided in any format that is\nnot plain text, to the actual problem of understanding the meaning of each\npiece of knowledge inside of the document. Our proposal tackles those\nchallenges by identifying metadata that has been regarded to be relevant for\nmeasurement data and providing a schema for this metadata. We further leverage\nthe Human-Aware Sensor Network Ontology (HASNetO) to build an architecture for\ndata collected in urban environments. We discuss the use of HASNetO and the\nsupporting infrastructure to manage both data and metadata in support of the\nCity of Fortaleza, a large metropolitan area in Brazil.\n", "versions": [{"version": "v1", "created": "Thu, 6 Apr 2017 12:21:57 GMT"}], "update_date": "2017-04-07", "authors_parsed": [["Santos", "Henrique", ""], ["Furtado", "Vasco", ""], ["Pinheiro", "Paulo", ""], ["McGuinness", "Deborah L.", ""]]}, {"id": "1704.01806", "submitter": "Henrique Oliveira Santos", "authors": "Paulo Pinheiro, Deborah L. McGuinness, Henrique Santos", "title": "Human-Aware Sensor Network Ontology: Semantic Support for Empirical Data\n  Collection", "comments": "In Proceedings of the 5th Workshop on Linked Science 2015 - Best\n  Practices and the Road Ahead (LISC 2015)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Significant efforts have been made to understand and document knowledge\nrelated to scientific measurements. Many of those efforts resulted in one or\nmore high-quality ontologies that describe some aspects of scientific\nmeasurements, but not in a comprehensive and coherently integrated manner. For\ninstance, we note that many of these high-quality ontologies are not properly\naligned, and more challenging, that they have different and often conflicting\nconcepts and approaches for encoding knowledge about empirical measurements. As\na result of this lack of an integrated view, it is often challenging for\nscientists to determine whether any two scientific measurements were taken in\nsemantically compatible manners, thus making it difficult to decide whether\nmeasurements should be analyzed in combination or not. In this paper, we\npresent the Human-Aware Sensor Network Ontology that is a comprehensive\nalignment and integration of a sensing infrastructure ontology and a provenance\nontology. HASNetO has been under development for more than one year, and has\nbeen reviewed, shared and used by multiple scientific communities. The ontology\nhas been in use to support the data management of a number of large-scale\necological monitoring activities (observations) and empirical experiments.\n", "versions": [{"version": "v1", "created": "Thu, 6 Apr 2017 12:36:45 GMT"}], "update_date": "2017-04-07", "authors_parsed": [["Pinheiro", "Paulo", ""], ["McGuinness", "Deborah L.", ""], ["Santos", "Henrique", ""]]}, {"id": "1704.01855", "submitter": "Henrique Oliveira Santos", "authors": "Henrique Santos, Vasco Furtado", "title": "A Service-Oriented Architecture for Assisting the Authoring of Semantic\n  Crowd Maps", "comments": "In Advances in Artificial Intelligence - SBIA 2012", "journal-ref": null, "doi": "10.1007/978-3-642-34459-6_4", "report-no": null, "categories": "cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although there are increasingly more initiatives for the generation of\nsemantic knowledge based on user participation, there is still a shortage of\nplatforms for regular users to create applications on which semantic data can\nbe exploited and generated automatically. We propose an architecture, called\nSemantic Maps (SeMaps), for assisting the authoring and hosting of applications\nin which the maps combine the aggregation of a Geographic Information System\nand crowd-generated content (called here crowd maps). In these systems, the\ndigital map works as a blackboard for accommodating stories told by people\nabout events they want to share with others typically participating in their\nsocial networks. SeMaps offers an environment for the creation and maintenance\nof sites based on crowd maps with the possibility for the user to characterize\nsemantically that which s/he intends to mark on the map. The designer of a\ncrowd map, by informing a linguistic expression that designates what has to be\nmarked on the maps, is guided in a process that aims to associate a concept\nfrom a common-sense base to this linguistic expression. Thus, the crowd maps\nstart to have dominion over common-sense inferential relations that define the\nmeaning of the marker, and are able to make inferences about the network of\nlinked data. This makes it possible to generate maps that have the power to\nperform inferences and access external sources (such as DBpedia) that\nconstitute information that is useful and appropriate to the context of the\nmap. In this paper we describe the architecture of SeMaps and how it was\napplied in a crowd map authoring tool.\n", "versions": [{"version": "v1", "created": "Thu, 6 Apr 2017 14:22:56 GMT"}], "update_date": "2017-04-07", "authors_parsed": [["Santos", "Henrique", ""], ["Furtado", "Vasco", ""]]}, {"id": "1704.01859", "submitter": "Raluca Necula", "authors": "Raluca Necula (1), Mihaela Breaban (1) and Madalina Raschip (1) ((1)\n  Faculty of Computer Science, Alexandru Ioan Cuza University, Iasi, Romania)", "title": "Tackling Dynamic Vehicle Routing Problem with Time Windows by means of\n  Ant Colony System", "comments": "10 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Dynamic Vehicle Routing Problem with Time Windows (DVRPTW) is an\nextension of the well-known Vehicle Routing Problem (VRP), which takes into\naccount the dynamic nature of the problem. This aspect requires the vehicle\nroutes to be updated in an ongoing manner as new customer requests arrive in\nthe system and must be incorporated into an evolving schedule during the\nworking day. Besides the vehicle capacity constraint involved in the classical\nVRP, DVRPTW considers in addition time windows, which are able to better\ncapture real-world situations. Despite this, so far, few studies have focused\non tackling this problem of greater practical importance. To this end, this\nstudy devises for the resolution of DVRPTW, an ant colony optimization based\nalgorithm, which resorts to a joint solution construction mechanism, able to\nconstruct in parallel the vehicle routes. This method is coupled with a local\nsearch procedure, aimed to further improve the solutions built by ants, and\nwith an insertion heuristics, which tries to reduce the number of vehicles used\nto service the available customers. The experiments indicate that the proposed\nalgorithm is competitive and effective, and on DVRPTW instances with a higher\ndynamicity level, it is able to yield better results compared to existing\nant-based approaches.\n", "versions": [{"version": "v1", "created": "Thu, 6 Apr 2017 14:29:14 GMT"}], "update_date": "2017-04-07", "authors_parsed": [["Necula", "Raluca", ""], ["Breaban", "Mihaela", ""], ["Raschip", "Madalina", ""]]}, {"id": "1704.01864", "submitter": "Ioan Gabriel Bucur", "authors": "Ioan Gabriel Bucur, Tom Claassen, Tom Heskes", "title": "Robust Causal Estimation in the Large-Sample Limit without Strict\n  Faithfulness", "comments": "10 pages, 12 figures, Proceedings of the 20th International\n  Conference on Artificial Intelligence and Statistics (AISTATS) 2017", "journal-ref": "PMLR 54:1523-1531, 2017", "doi": null, "report-no": null, "categories": "stat.ML cs.AI stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Causal effect estimation from observational data is an important and much\nstudied research topic. The instrumental variable (IV) and local causal\ndiscovery (LCD) patterns are canonical examples of settings where a closed-form\nexpression exists for the causal effect of one variable on another, given the\npresence of a third variable. Both rely on faithfulness to infer that the\nlatter only influences the target effect via the cause variable. In reality, it\nis likely that this assumption only holds approximately and that there will be\nat least some form of weak interaction. This brings about the paradoxical\nsituation that, in the large-sample limit, no predictions are made, as\ndetecting the weak edge invalidates the setting. We introduce an alternative\napproach by replacing strict faithfulness with a prior that reflects the\nexistence of many 'weak' (irrelevant) and 'strong' interactions. We obtain a\nposterior distribution over the target causal effect estimator which shows\nthat, in many cases, we can still make good estimates. We demonstrate the\napproach in an application on a simple linear-Gaussian setting, using the\nMultiNest sampling algorithm, and compare it with established techniques to\nshow our method is robust even when strict faithfulness is violated.\n", "versions": [{"version": "v1", "created": "Thu, 6 Apr 2017 14:39:54 GMT"}], "update_date": "2018-09-19", "authors_parsed": [["Bucur", "Ioan Gabriel", ""], ["Claassen", "Tom", ""], ["Heskes", "Tom", ""]]}, {"id": "1704.01886", "submitter": "Brian Paden", "authors": "Brian Paden, Yannik Nager, Emilio Frazzoli", "title": "Landmark Guided Probabilistic Roadmap Queries", "comments": "7 Pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A landmark based heuristic is investigated for reducing query phase run-time\nof the probabilistic roadmap (\\PRM) motion planning method. The heuristic is\ngenerated by storing minimum spanning trees from a small number of vertices\nwithin the \\PRM graph and using these trees to approximate the cost of a\nshortest path between any two vertices of the graph. The intermediate step of\npreprocessing the graph increases the time and memory requirements of the\nclassical motion planning technique in exchange for speeding up individual\nqueries making the method advantageous in multi-query applications. This paper\ninvestigates these trade-offs on \\PRM graphs constructed in randomized\nenvironments as well as a practical manipulator simulation.We conclude that the\nmethod is preferable to Dijkstra's algorithm or the ${\\rm A}^*$ algorithm with\nconventional heuristics in multi-query applications.\n", "versions": [{"version": "v1", "created": "Thu, 6 Apr 2017 15:16:03 GMT"}], "update_date": "2017-04-07", "authors_parsed": [["Paden", "Brian", ""], ["Nager", "Yannik", ""], ["Frazzoli", "Emilio", ""]]}, {"id": "1704.01889", "submitter": "Farhan Khawar", "authors": "Farhan Khawar, Nevin L. Zhang", "title": "Conformative Filtering for Implicit Feedback Data", "comments": null, "journal-ref": null, "doi": "10.1007/978-3-030-15712-8_11", "report-no": null, "categories": "cs.IR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Implicit feedback is the simplest form of user feedback that can be used for\nitem recommendation. It is easy to collect and is domain independent. However,\nthere is a lack of negative examples. Previous work tackles this problem by\nassuming that users are not interested or not as much interested in the\nunconsumed items. Those assumptions are often severely violated since\nnon-consumption can be due to factors like unawareness or lack of resources.\nTherefore, non-consumption by a user does not always mean disinterest or\nirrelevance. In this paper, we propose a novel method called Conformative\nFiltering (CoF) to address the issue. The motivating observation is that if\nthere is a large group of users who share the same taste and none of them have\nconsumed an item before, then it is likely that the item is not of interest to\nthe group. We perform multidimensional clustering on implicit feedback data\nusing hierarchical latent tree analysis (HLTA) to identify user `tastes' groups\nand make recommendations for a user based on her memberships in the groups and\non the past behavior of the groups. Experiments on two real-world datasets from\ndifferent domains show that CoF has superior performance compared to several\ncommon baselines.\n", "versions": [{"version": "v1", "created": "Thu, 6 Apr 2017 15:31:48 GMT"}, {"version": "v2", "created": "Wed, 17 Apr 2019 18:17:56 GMT"}], "update_date": "2019-04-19", "authors_parsed": [["Khawar", "Farhan", ""], ["Zhang", "Nevin L.", ""]]}, {"id": "1704.01920", "submitter": "Rahaf Aljundi", "authors": "Amal Rannen Triki, Rahaf Aljundi, Mathew B. Blaschko and Tinne\n  Tuytelaars", "title": "Encoder Based Lifelong Learning", "comments": null, "journal-ref": null, "doi": "10.1109/ICCV.2017.148", "report-no": null, "categories": "cs.CV cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces a new lifelong learning solution where a single model\nis trained for a sequence of tasks. The main challenge that vision systems face\nin this context is catastrophic forgetting: as they tend to adapt to the most\nrecently seen task, they lose performance on the tasks that were learned\npreviously. Our method aims at preserving the knowledge of the previous tasks\nwhile learning a new one by using autoencoders. For each task, an\nunder-complete autoencoder is learned, capturing the features that are crucial\nfor its achievement. When a new task is presented to the system, we prevent the\nreconstructions of the features with these autoencoders from changing, which\nhas the effect of preserving the information on which the previous tasks are\nmainly relying. At the same time, the features are given space to adjust to the\nmost recent environment as only their projection into a low dimension\nsubmanifold is controlled. The proposed system is evaluated on image\nclassification tasks and shows a reduction of forgetting over the\nstate-of-the-art\n", "versions": [{"version": "v1", "created": "Thu, 6 Apr 2017 16:37:15 GMT"}], "update_date": "2018-07-19", "authors_parsed": [["Triki", "Amal Rannen", ""], ["Aljundi", "Rahaf", ""], ["Blaschko", "Mathew B.", ""], ["Tuytelaars", "Tinne", ""]]}, {"id": "1704.01944", "submitter": "Paul Thaddeus Kazibudzki", "authors": "Paul Thaddeus Kazibudzki", "title": "The quality of priority ratios estimation in relation to a selected\n  prioritization procedure and consistency measure for a Pairwise Comparison\n  Matrix", "comments": "30 pages, 11 tables, 3 figures", "journal-ref": "https://www.hindawi.com/journals/aor/2019/3574263/", "doi": "10.1155/2019/3574263", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An overview of current debates and contemporary research devoted to the\nmodeling of decision making processes and their facilitation directs attention\nto the Analytic Hierarchy Process (AHP). At the core of the AHP are various\nprioritization procedures (PPs) and consistency measures (CMs) for a Pairwise\nComparison Matrix (PCM) which, in a sense, reflects preferences of decision\nmakers. Certainly, when judgments about these preferences are perfectly\nconsistent (cardinally transitive), all PPs coincide and the quality of the\npriority ratios (PRs) estimation is exemplary. However, human judgments are\nvery rarely consistent, thus the quality of PRs estimation may significantly\nvary. The scale of these variations depends on the applied PP and utilized CM\nfor a PCM. This is why it is important to find out which PPs and which CMs for\na PCM lead directly to an improvement of the PRs estimation accuracy. The main\ngoal of this research is realized through the properly designed, coded and\nexecuted seminal and sophisticated simulation algorithms in Wolfram Mathematica\n8.0. These research results convince that the embedded in the AHP and commonly\napplied, both genuine PP and CM for PCM may significantly deteriorate the\nquality of PRs estimation; however, solutions proposed in this paper can\nsignificantly improve the methodology.\n", "versions": [{"version": "v1", "created": "Thu, 6 Apr 2017 17:25:39 GMT"}, {"version": "v2", "created": "Mon, 19 Jun 2017 23:18:34 GMT"}], "update_date": "2020-06-05", "authors_parsed": [["Kazibudzki", "Paul Thaddeus", ""]]}, {"id": "1704.01946", "submitter": "Henrique Oliveira Santos", "authors": "Henrique Santos, Victor Dantas, Vasco Furtado, Paulo Pinheiro, Deborah\n  L. McGuinness", "title": "From Data to City Indicators: A Knowledge Graph for Supporting Automatic\n  Generation of Dashboards", "comments": "Accepted at the 14th Extended Semantic Web Conference (ESWC 2017)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the context of Smart Cities, indicator definitions have been used to\ncalculate values that enable the comparison among different cities. The\ncalculation of an indicator values has challenges as the calculation may need\nto combine some aspects of quality while addressing different levels of\nabstraction. Knowledge graphs (KGs) have been used successfully to support\nflexible representation, which can support improved understanding and data\nanalysis in similar settings. This paper presents an operational description\nfor a city KG, an indicator ontology that support indicator discovery and data\nvisualization and an application capable of performing metadata analysis to\nautomatically build and display dashboards according to discovered indicators.\nWe describe our implementation in an urban mobility setting.\n", "versions": [{"version": "v1", "created": "Thu, 6 Apr 2017 17:29:16 GMT"}], "update_date": "2017-04-07", "authors_parsed": [["Santos", "Henrique", ""], ["Dantas", "Victor", ""], ["Furtado", "Vasco", ""], ["Pinheiro", "Paulo", ""], ["McGuinness", "Deborah L.", ""]]}, {"id": "1704.01975", "submitter": "Daniela Moctezuma", "authors": "Eric S. Tellez, Daniela Moctezuma, Sabino Miranda-J\\'imenez, Mario\n  Graff", "title": "An Automated Text Categorization Framework based on Hyperparameter\n  Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A great variety of text tasks such as topic or spam identification, user\nprofiling, and sentiment analysis can be posed as a supervised learning problem\nand tackle using a text classifier. A text classifier consists of several\nsubprocesses, some of them are general enough to be applied to any supervised\nlearning problem, whereas others are specifically designed to tackle a\nparticular task, using complex and computational expensive processes such as\nlemmatization, syntactic analysis, etc. Contrary to traditional approaches, we\npropose a minimalistic and wide system able to tackle text classification tasks\nindependent of domain and language, namely microTC. It is composed by some easy\nto implement text transformations, text representations, and a supervised\nlearning algorithm. These pieces produce a competitive classifier even in the\ndomain of informally written text. We provide a detailed description of microTC\nalong with an extensive experimental comparison with relevant state-of-the-art\nmethods. mircoTC was compared on 30 different datasets. Regarding accuracy,\nmicroTC obtained the best performance in 20 datasets while achieves competitive\nresults in the remaining 10. The compared datasets include several problems\nlike topic and polarity classification, spam detection, user profiling and\nauthorship attribution. Furthermore, it is important to state that our approach\nallows the usage of the technology even without knowledge of machine learning\nand natural language processing.\n", "versions": [{"version": "v1", "created": "Thu, 6 Apr 2017 18:01:22 GMT"}, {"version": "v2", "created": "Thu, 14 Sep 2017 22:30:13 GMT"}], "update_date": "2017-09-18", "authors_parsed": [["Tellez", "Eric S.", ""], ["Moctezuma", "Daniela", ""], ["Miranda-J\u00edmenez", "Sabino", ""], ["Graff", "Mario", ""]]}, {"id": "1704.02038", "submitter": "Hossein Soleimani", "authors": "Hossein Soleimani, Adarsh Subbaswamy, Suchi Saria", "title": "Treatment-Response Models for Counterfactual Reasoning with\n  Continuous-time, Continuous-valued Interventions", "comments": "In Proceedings of the Thirty-Third Conference on Uncertainty in\n  Artificial Intelligence (UAI-2017), Sydney, Australia, August 2017. The first\n  two authors contributed equally to this work", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Treatment effects can be estimated from observational data as the difference\nin potential outcomes. In this paper, we address the challenge of estimating\nthe potential outcome when treatment-dose levels can vary continuously over\ntime. Further, the outcome variable may not be measured at a regular frequency.\nOur proposed solution represents the treatment response curves using linear\ntime-invariant dynamical systems---this provides a flexible means for modeling\nresponse over time to highly variable dose curves. Moreover, for multivariate\ndata, the proposed method: uncovers shared structure in treatment response and\nthe baseline across multiple markers; and, flexibly models challenging\ncorrelation structure both across and within signals over time. For this, we\nbuild upon the framework of multiple-output Gaussian Processes. On simulated\nand a challenging clinical dataset, we show significant gains in accuracy over\nstate-of-the-art models.\n", "versions": [{"version": "v1", "created": "Thu, 6 Apr 2017 22:42:13 GMT"}, {"version": "v2", "created": "Sun, 5 Nov 2017 02:16:25 GMT"}], "update_date": "2017-11-07", "authors_parsed": [["Soleimani", "Hossein", ""], ["Subbaswamy", "Adarsh", ""], ["Saria", "Suchi", ""]]}, {"id": "1704.02081", "submitter": "Alexander Wong", "authors": "Mohammad Javad Shafiee, Elnaz Barshan, and Alexander Wong", "title": "Evolution in Groups: A deeper look at synaptic cluster driven evolution\n  of deep neural networks", "comments": "8 pages. arXiv admin note: substantial text overlap with\n  arXiv:1609.01360", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A promising paradigm for achieving highly efficient deep neural networks is\nthe idea of evolutionary deep intelligence, which mimics biological evolution\nprocesses to progressively synthesize more efficient networks. A crucial design\nfactor in evolutionary deep intelligence is the genetic encoding scheme used to\nsimulate heredity and determine the architectures of offspring networks. In\nthis study, we take a deeper look at the notion of synaptic cluster-driven\nevolution of deep neural networks which guides the evolution process towards\nthe formation of a highly sparse set of synaptic clusters in offspring\nnetworks. Utilizing a synaptic cluster-driven genetic encoding, the\nprobabilistic encoding of synaptic traits considers not only individual\nsynaptic properties but also inter-synaptic relationships within a deep neural\nnetwork. This process results in highly sparse offspring networks which are\nparticularly tailored for parallel computational devices such as GPUs and deep\nneural network accelerator chips. Comprehensive experimental results using four\nwell-known deep neural network architectures (LeNet-5, AlexNet, ResNet-56, and\nDetectNet) on two different tasks (object categorization and object detection)\ndemonstrate the efficiency of the proposed method. Cluster-driven genetic\nencoding scheme synthesizes networks that can achieve state-of-the-art\nperformance with significantly smaller number of synapses than that of the\noriginal ancestor network. ($\\sim$125-fold decrease in synapses for MNIST).\nFurthermore, the improved cluster efficiency in the generated offspring\nnetworks ($\\sim$9.71-fold decrease in clusters for MNIST and a $\\sim$8.16-fold\ndecrease in clusters for KITTI) is particularly useful for accelerated\nperformance on parallel computing hardware architectures such as those in GPUs\nand deep neural network accelerator chips.\n", "versions": [{"version": "v1", "created": "Fri, 7 Apr 2017 03:28:02 GMT"}], "update_date": "2017-04-10", "authors_parsed": [["Shafiee", "Mohammad Javad", ""], ["Barshan", "Elnaz", ""], ["Wong", "Alexander", ""]]}, {"id": "1704.02114", "submitter": "Utku Kose", "authors": "Utku Kose, Selcuk Sert", "title": "Improving content marketing processes with the approaches by artificial\n  intelligence", "comments": "8 pages, 6 figures", "journal-ref": "Ecoforum Journal, 6, 1 (10), 2017", "doi": null, "report-no": null, "categories": "cs.AI cs.SI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Content marketing is todays one of the most remarkable approaches in the\ncontext of marketing processes of companies. Value of this kind of marketing\nhas improved in time, thanks to the latest developments regarding to computer\nand communication technologies. Nowadays, especially social media based\nplatforms have a great importance on enabling companies to design multimedia\noriented, interactive content. But on the other hand, there is still something\nmore to do for improved content marketing approaches. In this context,\nobjective of this study is to focus on intelligent content marketing, which can\nbe done by using artificial intelligence. Artificial Intelligence is todays one\nof the most remarkable research fields and it can be used easily as\nmultidisciplinary. So, this study has aimed to discuss about its potential on\nimproving content marketing. In detail, the study has enabled readers to\nimprove their awareness about the intersection point of content marketing and\nartificial intelligence. Furthermore, the authors have introduced some example\nmodels of intelligent content marketing, which can be achieved by using current\nWeb technologies and artificial intelligence techniques.\n", "versions": [{"version": "v1", "created": "Fri, 7 Apr 2017 07:31:39 GMT"}], "update_date": "2017-04-10", "authors_parsed": [["Kose", "Utku", ""], ["Sert", "Selcuk", ""]]}, {"id": "1704.02254", "submitter": "Silvia Chiappa", "authors": "Silvia Chiappa and S\\'ebastien Racaniere and Daan Wierstra and Shakir\n  Mohamed", "title": "Recurrent Environment Simulators", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Models that can simulate how environments change in response to actions can\nbe used by agents to plan and act efficiently. We improve on previous\nenvironment simulators from high-dimensional pixel observations by introducing\nrecurrent neural networks that are able to make temporally and spatially\ncoherent predictions for hundreds of time-steps into the future. We present an\nin-depth analysis of the factors affecting performance, providing the most\nextensive attempt to advance the understanding of the properties of these\nmodels. We address the issue of computationally inefficiency with a model that\ndoes not need to generate a high-dimensional image at each time-step. We show\nthat our approach can be used to improve exploration and is adaptable to many\ndiverse environments, namely 10 Atari games, a 3D car racing environment, and\ncomplex 3D mazes.\n", "versions": [{"version": "v1", "created": "Fri, 7 Apr 2017 14:53:54 GMT"}, {"version": "v2", "created": "Wed, 19 Apr 2017 15:43:32 GMT"}], "update_date": "2017-04-20", "authors_parsed": [["Chiappa", "Silvia", ""], ["Racaniere", "S\u00e9bastien", ""], ["Wierstra", "Daan", ""], ["Mohamed", "Shakir", ""]]}, {"id": "1704.02312", "submitter": "Yaoyuan Zhang", "authors": "Yaoyuan Zhang, Zhenxu Ye, Yansong Feng, Dongyan Zhao, Rui Yan", "title": "A Constrained Sequence-to-Sequence Neural Model for Sentence\n  Simplification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sentence simplification reduces semantic complexity to benefit people with\nlanguage impairments. Previous simplification studies on the sentence level and\nword level have achieved promising results but also meet great challenges. For\nsentence-level studies, sentences after simplification are fluent but sometimes\nare not really simplified. For word-level studies, words are simplified but\nalso have potential grammar errors due to different usages of words before and\nafter simplification. In this paper, we propose a two-step simplification\nframework by combining both the word-level and the sentence-level\nsimplifications, making use of their corresponding advantages. Based on the\ntwo-step framework, we implement a novel constrained neural generation model to\nsimplify sentences given simplified words. The final results on Wikipedia and\nSimple Wikipedia aligned datasets indicate that our method yields better\nperformance than various baselines.\n", "versions": [{"version": "v1", "created": "Fri, 7 Apr 2017 17:53:24 GMT"}], "update_date": "2017-04-10", "authors_parsed": [["Zhang", "Yaoyuan", ""], ["Ye", "Zhenxu", ""], ["Feng", "Yansong", ""], ["Zhao", "Dongyan", ""], ["Yan", "Rui", ""]]}, {"id": "1704.02375", "submitter": "Yanhong Annie Liu", "authors": "David S. Warren and Yanhong A. Liu", "title": "AppLP: A Dialogue on Applications of Logic Programming", "comments": "David S. Warren and Yanhong A. Liu (Editors). 33 pages. Including\n  summaries by Christopher Kane and abstracts or position papers by M. Aref, J.\n  Rosenwald, I. Cervesato, E.S.L. Lam, M. Balduccini, J. Lobo, A. Russo, E.\n  Lupu, N. Leone, F. Ricca, G. Gupta, K. Marple, E. Salazar, Z. Chen, A. Sobhi,\n  S. Srirangapalli, C.R. Ramakrishnan, N. Bj{\\o}rner, N.P. Lopes, A.\n  Rybalchenko, and P. Tarau", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.AI cs.LO cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This document describes the contributions of the 2016 Applications of Logic\nProgramming Workshop (AppLP), which was held on October 17 and associated with\nthe International Conference on Logic Programming (ICLP) in Flushing, New York\nCity.\n", "versions": [{"version": "v1", "created": "Fri, 7 Apr 2017 21:10:00 GMT"}], "update_date": "2017-04-11", "authors_parsed": [["Warren", "David S.", ""], ["Liu", "Yanhong A.", ""]]}, {"id": "1704.02468", "submitter": "Mieczys{\\l}aw K{\\l}opotek", "authors": "Mieczys{\\l}aw A. K{\\l}opotek, S{\\l}awomir T. Wierzcho\\'n", "title": "Basic Formal Properties of A Relational Model of The Mathematical Theory\n  of Evidence", "comments": "23 pages", "journal-ref": "This is the preliminary version of the paper published in\n  Demonstratio Mathematica. Vol XXXI No 3,1998, pp. 669-688", "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper presents a novel view of the Dempster-Shafer belief function as a\nmeasure of diversity in relational data bases. It is demonstrated that under\nthe interpretation The Dempster rule of evidence combination corresponds to the\njoin operator of the relational database theory. This rough-set based\ninterpretation is qualitative in nature and can represent a number of belief\nfunction operators.\n  The interpretation has the property that Given a definition of the belief\nmeasure of objects in the interpretation domain we can perform operations in\nthis domain and the measure of the resulting object is derivable from measures\nof component objects via belief operator. We demonstrated this property for\nDempster rule of combination, marginalization, Shafer's conditioning,\nindependent variables, Shenoy's notion of conditional independence of\nvariables.\n  The interpretation is based on rough sets (in connection with decision\ntables), but differs from previous interpretations of this type in that it\ncounts the diversity rather than frequencies in a decision table.\n", "versions": [{"version": "v1", "created": "Sat, 8 Apr 2017 10:07:04 GMT"}], "update_date": "2017-04-11", "authors_parsed": [["K\u0142opotek", "Mieczys\u0142aw A.", ""], ["Wierzcho\u0144", "S\u0142awomir T.", ""]]}, {"id": "1704.02621", "submitter": "Panayiotis Benos", "authors": "Andrew J Sedgewick, Joseph D. Ramsey, Peter Spirtes, Clark Glymour,\n  Panayiotis V. Benos", "title": "Mixed Graphical Models for Causal Analysis of Multi-modal Variables", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graphical causal models are an important tool for knowledge discovery because\nthey can represent both the causal relations between variables and the\nmultivariate probability distributions over the data. Once learned, causal\ngraphs can be used for classification, feature selection and hypothesis\ngeneration, while revealing the underlying causal network structure and thus\nallowing for arbitrary likelihood queries over the data. However, current\nalgorithms for learning sparse directed graphs are generally designed to handle\nonly one type of data (continuous-only or discrete-only), which limits their\napplicability to a large class of multi-modal biological datasets that include\nmixed type variables. To address this issue, we developed new methods that\nmodify and combine existing methods for finding undirected graphs with methods\nfor finding directed graphs. These hybrid methods are not only faster, but also\nperform better than the directed graph estimation methods alone for a variety\nof parameter settings and data set sizes. Here, we describe a new conditional\nindependence test for learning directed graphs over mixed data types and we\ncompare performances of different graph learning strategies on synthetic data.\n", "versions": [{"version": "v1", "created": "Sun, 9 Apr 2017 15:58:35 GMT"}], "update_date": "2017-04-11", "authors_parsed": [["Sedgewick", "Andrew J", ""], ["Ramsey", "Joseph D.", ""], ["Spirtes", "Peter", ""], ["Glymour", "Clark", ""], ["Benos", "Panayiotis V.", ""]]}, {"id": "1704.02712", "submitter": "Zheng Xu", "authors": "Zheng Xu, Mario A. T. Figueiredo, Xiaoming Yuan, Christoph Studer, and\n  Tom Goldstein", "title": "Adaptive Relaxed ADMM: Convergence Theory and Practical Implementation", "comments": "CVPR 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many modern computer vision and machine learning applications rely on solving\ndifficult optimization problems that involve non-differentiable objective\nfunctions and constraints. The alternating direction method of multipliers\n(ADMM) is a widely used approach to solve such problems. Relaxed ADMM is a\ngeneralization of ADMM that often achieves better performance, but its\nefficiency depends strongly on algorithm parameters that must be chosen by an\nexpert user. We propose an adaptive method that automatically tunes the key\nalgorithm parameters to achieve optimal performance without user oversight.\nInspired by recent work on adaptivity, the proposed adaptive relaxed ADMM\n(ARADMM) is derived by assuming a Barzilai-Borwein style linear gradient. A\ndetailed convergence analysis of ARADMM is provided, and numerical results on\nseveral applications demonstrate fast practical convergence.\n", "versions": [{"version": "v1", "created": "Mon, 10 Apr 2017 05:07:38 GMT"}], "update_date": "2017-04-11", "authors_parsed": [["Xu", "Zheng", ""], ["Figueiredo", "Mario A. T.", ""], ["Yuan", "Xiaoming", ""], ["Studer", "Christoph", ""], ["Goldstein", "Tom", ""]]}, {"id": "1704.02716", "submitter": "Martin  Biehl", "authors": "Martin Biehl", "title": "Formal approaches to a definition of agents", "comments": "PhD thesis, 198 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.IT cs.MA math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This thesis contributes to the formalisation of the notion of an agent within\nthe class of finite multivariate Markov chains. Agents are seen as entities\nthat act, perceive, and are goal-directed.\n  We present a new measure that can be used to identify entities (called\n$\\iota$-entities), some general requirements for entities in multivariate\nMarkov chains, as well as formal definitions of actions and perceptions\nsuitable for such entities.\n  The intuition behind $\\iota$-entities is that entities are spatiotemporal\npatterns for which every part makes every other part more probable. The\nmeasure, complete local integration (CLI), is formally investigated in general\nBayesian networks. It is based on the specific local integration (SLI) which is\nmeasured with respect to a partition. CLI is the minimum value of SLI over all\npartitions. We prove that $\\iota$-entities are blocks in specific partitions of\nthe global trajectory. These partitions are the finest partitions that achieve\na given SLI value. We also establish the transformation behaviour of SLI under\npermutations of nodes in the network.\n  We go on to present three conditions on general definitions of entities.\nThese are not fulfilled by sets of random variables i.e.\\ the perception-action\nloop, which is often used to model agents, is too restrictive. We propose that\nany general entity definition should in effect specify a subset (called an an\nentity-set) of the set of all spatiotemporal patterns of a given multivariate\nMarkov chain. The set of $\\iota$-entities is such a set. Importantly the\nperception-action loop also induces an entity-set.\n  We then propose formal definitions of actions and perceptions for arbitrary\nentity-sets. These specialise to standard notions in case of the\nperception-action loop entity-set.\n  Finally we look at some very simple examples.\n", "versions": [{"version": "v1", "created": "Mon, 10 Apr 2017 05:45:23 GMT"}], "update_date": "2017-04-11", "authors_parsed": [["Biehl", "Martin", ""]]}, {"id": "1704.02853", "submitter": "Isabelle Augenstein", "authors": "Isabelle Augenstein, Mrinal Das, Sebastian Riedel, Lakshmi Vikraman,\n  Andrew McCallum", "title": "SemEval 2017 Task 10: ScienceIE - Extracting Keyphrases and Relations\n  from Scientific Publications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe the SemEval task of extracting keyphrases and relations between\nthem from scientific documents, which is crucial for understanding which\npublications describe which processes, tasks and materials. Although this was a\nnew task, we had a total of 26 submissions across 3 evaluation scenarios. We\nexpect the task and the findings reported in this paper to be relevant for\nresearchers working on understanding scientific content, as well as the broader\nknowledge base population and information extraction communities.\n", "versions": [{"version": "v1", "created": "Mon, 10 Apr 2017 13:43:40 GMT"}, {"version": "v2", "created": "Thu, 20 Apr 2017 10:41:31 GMT"}, {"version": "v3", "created": "Tue, 2 May 2017 15:32:41 GMT"}], "update_date": "2017-05-03", "authors_parsed": [["Augenstein", "Isabelle", ""], ["Das", "Mrinal", ""], ["Riedel", "Sebastian", ""], ["Vikraman", "Lakshmi", ""], ["McCallum", "Andrew", ""]]}, {"id": "1704.02882", "submitter": "Hadrien Hendrikx", "authors": "El Mahdi El Mhamdi, Rachid Guerraoui, Hadrien Hendrikx, Alexandre\n  Maurer", "title": "Dynamic Safe Interruptibility for Decentralized Multi-Agent\n  Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In reinforcement learning, agents learn by performing actions and observing\ntheir outcomes. Sometimes, it is desirable for a human operator to\n\\textit{interrupt} an agent in order to prevent dangerous situations from\nhappening. Yet, as part of their learning process, agents may link these\ninterruptions, that impact their reward, to specific states and deliberately\navoid them. The situation is particularly challenging in a multi-agent context\nbecause agents might not only learn from their own past interruptions, but also\nfrom those of other agents. Orseau and Armstrong defined \\emph{safe\ninterruptibility} for one learner, but their work does not naturally extend to\nmulti-agent systems. This paper introduces \\textit{dynamic safe\ninterruptibility}, an alternative definition more suited to decentralized\nlearning problems, and studies this notion in two learning frameworks:\n\\textit{joint action learners} and \\textit{independent learners}. We give\nrealistic sufficient conditions on the learning algorithm to enable dynamic\nsafe interruptibility in the case of joint action learners, yet show that these\nconditions are not sufficient for independent learners. We show however that if\nagents can detect interruptions, it is possible to prune the observations to\nensure dynamic safe interruptibility even for independent learners.\n", "versions": [{"version": "v1", "created": "Mon, 10 Apr 2017 14:38:37 GMT"}, {"version": "v2", "created": "Mon, 22 May 2017 11:01:28 GMT"}], "update_date": "2017-05-23", "authors_parsed": [["Mhamdi", "El Mahdi El", ""], ["Guerraoui", "Rachid", ""], ["Hendrikx", "Hadrien", ""], ["Maurer", "Alexandre", ""]]}, {"id": "1704.02906", "submitter": "Viveka Kulharia", "authors": "Arnab Ghosh and Viveka Kulharia and Vinay Namboodiri and Philip H. S.\n  Torr and Puneet K. Dokania", "title": "Multi-Agent Diverse Generative Adversarial Networks", "comments": "This is an updated version of our CVPR'18 paper with the same title.\n  In this version, we also introduce MAD-GAN-Sim in Appendix B", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.GR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose MAD-GAN, an intuitive generalization to the Generative Adversarial\nNetworks (GANs) and its conditional variants to address the well known problem\nof mode collapse. First, MAD-GAN is a multi-agent GAN architecture\nincorporating multiple generators and one discriminator. Second, to enforce\nthat different generators capture diverse high probability modes, the\ndiscriminator of MAD-GAN is designed such that along with finding the real and\nfake samples, it is also required to identify the generator that generated the\ngiven fake sample. Intuitively, to succeed in this task, the discriminator must\nlearn to push different generators towards different identifiable modes. We\nperform extensive experiments on synthetic and real datasets and compare\nMAD-GAN with different variants of GAN. We show high quality diverse sample\ngenerations for challenging tasks such as image-to-image translation and face\ngeneration. In addition, we also show that MAD-GAN is able to disentangle\ndifferent modalities when trained using highly challenging diverse-class\ndataset (e.g. dataset with images of forests, icebergs, and bedrooms). In the\nend, we show its efficacy on the unsupervised feature representation task. In\nAppendix, we introduce a similarity based competing objective (MAD-GAN-Sim)\nwhich encourages different generators to generate diverse samples based on a\nuser defined similarity metric. We show its performance on the image-to-image\ntranslation, and also show its effectiveness on the unsupervised feature\nrepresentation task.\n", "versions": [{"version": "v1", "created": "Mon, 10 Apr 2017 15:26:23 GMT"}, {"version": "v2", "created": "Fri, 9 Mar 2018 23:29:16 GMT"}, {"version": "v3", "created": "Mon, 16 Jul 2018 16:21:52 GMT"}], "update_date": "2018-07-17", "authors_parsed": [["Ghosh", "Arnab", ""], ["Kulharia", "Viveka", ""], ["Namboodiri", "Vinay", ""], ["Torr", "Philip H. S.", ""], ["Dokania", "Puneet K.", ""]]}, {"id": "1704.02923", "submitter": "Sandro Pezzelle", "authors": "Ionut Sorodoc, Sandro Pezzelle, Aur\\'elie Herbelot, Mariella\n  Dimiccoli, Raffaella Bernardi", "title": "Pay Attention to Those Sets! Learning Quantification from Images", "comments": "Submitted to Journal Paper, 28 pages, 12 figures, 5 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Major advances have recently been made in merging language and vision\nrepresentations. But most tasks considered so far have confined themselves to\nthe processing of objects and lexicalised relations amongst objects (content\nwords). We know, however, that humans (even pre-school children) can abstract\nover raw data to perform certain types of higher-level reasoning, expressed in\nnatural language by function words. A case in point is given by their ability\nto learn quantifiers, i.e. expressions like 'few', 'some' and 'all'. From\nformal semantics and cognitive linguistics, we know that quantifiers are\nrelations over sets which, as a simplification, we can see as proportions. For\ninstance, in 'most fish are red', most encodes the proportion of fish which are\nred fish. In this paper, we study how well current language and vision\nstrategies model such relations. We show that state-of-the-art attention\nmechanisms coupled with a traditional linguistic formalisation of quantifiers\ngives best performance on the task. Additionally, we provide insights on the\nrole of 'gist' representations in quantification. A 'logical' strategy to\ntackle the task would be to first obtain a numerosity estimation for the two\ninvolved sets and then compare their cardinalities. We however argue that\nprecisely identifying the composition of the sets is not only beyond current\nstate-of-the-art models but perhaps even detrimental to a task that is most\nefficiently performed by refining the approximate numerosity estimator of the\nsystem.\n", "versions": [{"version": "v1", "created": "Mon, 10 Apr 2017 16:03:31 GMT"}], "update_date": "2017-04-11", "authors_parsed": [["Sorodoc", "Ionut", ""], ["Pezzelle", "Sandro", ""], ["Herbelot", "Aur\u00e9lie", ""], ["Dimiccoli", "Mariella", ""], ["Bernardi", "Raffaella", ""]]}, {"id": "1704.02963", "submitter": "Thales Felipe Costa Bertaglia", "authors": "Thales Felipe Costa Bertaglia and Maria das Gra\\c{c}as Volpe Nunes", "title": "Exploring Word Embeddings for Unsupervised Textual User-Generated\n  Content Normalization", "comments": "Published in Proceedings of the 2nd Workshop on Noisy User-generated\n  Text, 9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Text normalization techniques based on rules, lexicons or supervised training\nrequiring large corpora are not scalable nor domain interchangeable, and this\nmakes them unsuitable for normalizing user-generated content (UGC). Current\ntools available for Brazilian Portuguese make use of such techniques. In this\nwork we propose a technique based on distributed representation of words (or\nword embeddings). It generates continuous numeric vectors of\nhigh-dimensionality to represent words. The vectors explicitly encode many\nlinguistic regularities and patterns, as well as syntactic and semantic word\nrelationships. Words that share semantic similarity are represented by similar\nvectors. Based on these features, we present a totally unsupervised, expandable\nand language and domain independent method for learning normalization lexicons\nfrom word embeddings. Our approach obtains high correction rate of orthographic\nerrors and internet slang in product reviews, outperforming the current\navailable tools for Brazilian Portuguese.\n", "versions": [{"version": "v1", "created": "Mon, 10 Apr 2017 17:37:22 GMT"}], "update_date": "2017-04-11", "authors_parsed": [["Bertaglia", "Thales Felipe Costa", ""], ["Nunes", "Maria das Gra\u00e7as Volpe", ""]]}, {"id": "1704.03012", "submitter": "Carlos Florensa Campo", "authors": "Carlos Florensa, Yan Duan, Pieter Abbeel", "title": "Stochastic Neural Networks for Hierarchical Reinforcement Learning", "comments": "Published as a conference paper at ICLR 2017", "journal-ref": "International Conference on Learning Representations 2017", "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.NE cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep reinforcement learning has achieved many impressive results in recent\nyears. However, tasks with sparse rewards or long horizons continue to pose\nsignificant challenges. To tackle these important problems, we propose a\ngeneral framework that first learns useful skills in a pre-training\nenvironment, and then leverages the acquired skills for learning faster in\ndownstream tasks. Our approach brings together some of the strengths of\nintrinsic motivation and hierarchical methods: the learning of useful skill is\nguided by a single proxy reward, the design of which requires very minimal\ndomain knowledge about the downstream tasks. Then a high-level policy is\ntrained on top of these skills, providing a significant improvement of the\nexploration and allowing to tackle sparse rewards in the downstream tasks. To\nefficiently pre-train a large span of skills, we use Stochastic Neural Networks\ncombined with an information-theoretic regularizer. Our experiments show that\nthis combination is effective in learning a wide span of interpretable skills\nin a sample-efficient way, and can significantly boost the learning performance\nuniformly across a wide range of downstream tasks.\n", "versions": [{"version": "v1", "created": "Mon, 10 Apr 2017 18:41:28 GMT"}], "update_date": "2017-04-12", "authors_parsed": [["Florensa", "Carlos", ""], ["Duan", "Yan", ""], ["Abbeel", "Pieter", ""]]}, {"id": "1704.03039", "submitter": "Pedro Morgado", "authors": "Pedro Morgado, Nuno Vasconcelos", "title": "Semantically Consistent Regularization for Zero-Shot Recognition", "comments": "Accepted to CVPR 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The role of semantics in zero-shot learning is considered. The effectiveness\nof previous approaches is analyzed according to the form of supervision\nprovided. While some learn semantics independently, others only supervise the\nsemantic subspace explained by training classes. Thus, the former is able to\nconstrain the whole space but lacks the ability to model semantic correlations.\nThe latter addresses this issue but leaves part of the semantic space\nunsupervised. This complementarity is exploited in a new convolutional neural\nnetwork (CNN) framework, which proposes the use of semantics as constraints for\nrecognition.Although a CNN trained for classification has no transfer ability,\nthis can be encouraged by learning an hidden semantic layer together with a\nsemantic code for classification. Two forms of semantic constraints are then\nintroduced. The first is a loss-based regularizer that introduces a\ngeneralization constraint on each semantic predictor. The second is a codeword\nregularizer that favors semantic-to-class mappings consistent with prior\nsemantic knowledge while allowing these to be learned from data. Significant\nimprovements over the state-of-the-art are achieved on several datasets.\n", "versions": [{"version": "v1", "created": "Mon, 10 Apr 2017 19:59:33 GMT"}], "update_date": "2017-04-12", "authors_parsed": [["Morgado", "Pedro", ""], ["Vasconcelos", "Nuno", ""]]}, {"id": "1704.03048", "submitter": "Luigi Troiano", "authors": "Luigi Troiano and Irene D\\'iaz and Ciro Gaglione", "title": "Matching Media Contents with User Profiles by means of the\n  Dempster-Shafer Theory", "comments": "FUZZ-IEEE 2017. 6 pages, 3 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The media industry is increasingly personalizing the offering of contents in\nattempt to better target the audience. This requires to analyze the\nrelationships that goes established between users and content they enjoy,\nlooking at one side to the content characteristics and on the other to the user\nprofile, in order to find the best match between the two. In this paper we\nsuggest to build that relationship using the Dempster-Shafer's Theory of\nEvidence, proposing a reference model and illustrating its properties by means\nof a toy example. Finally we suggest possible applications of the model for\ntasks that are common in the modern media industry.\n", "versions": [{"version": "v1", "created": "Mon, 10 Apr 2017 20:34:37 GMT"}], "update_date": "2017-04-12", "authors_parsed": [["Troiano", "Luigi", ""], ["D\u00edaz", "Irene", ""], ["Gaglione", "Ciro", ""]]}, {"id": "1704.03079", "submitter": "Asit Mishra", "authors": "Asit Mishra, Jeffrey J Cook, Eriko Nurvitadhi and Debbie Marr", "title": "WRPN: Training and Inference using Wide Reduced-Precision Networks", "comments": "Under submission to CVPR Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For computer vision applications, prior works have shown the efficacy of\nreducing the numeric precision of model parameters (network weights) in deep\nneural networks but also that reducing the precision of activations hurts model\naccuracy much more than reducing the precision of model parameters. We study\nschemes to train networks from scratch using reduced-precision activations\nwithout hurting the model accuracy. We reduce the precision of activation maps\n(along with model parameters) using a novel quantization scheme and increase\nthe number of filter maps in a layer, and find that this scheme compensates or\nsurpasses the accuracy of the baseline full-precision network. As a result, one\ncan significantly reduce the dynamic memory footprint, memory bandwidth,\ncomputational energy and speed up the training and inference process with\nappropriate hardware support. We call our scheme WRPN - wide reduced-precision\nnetworks. We report results using our proposed schemes and show that our\nresults are better than previously reported accuracies on ILSVRC-12 dataset\nwhile being computationally less expensive compared to previously reported\nreduced-precision networks.\n", "versions": [{"version": "v1", "created": "Mon, 10 Apr 2017 22:54:38 GMT"}], "update_date": "2017-04-12", "authors_parsed": [["Mishra", "Asit", ""], ["Cook", "Jeffrey J", ""], ["Nurvitadhi", "Eriko", ""], ["Marr", "Debbie", ""]]}, {"id": "1704.03084", "submitter": "Xiujun Li", "authors": "Baolin Peng and Xiujun Li and Lihong Li and Jianfeng Gao and Asli\n  Celikyilmaz and Sungjin Lee and Kam-Fai Wong", "title": "Composite Task-Completion Dialogue Policy Learning via Hierarchical Deep\n  Reinforcement Learning", "comments": "12 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Building a dialogue agent to fulfill complex tasks, such as travel planning,\nis challenging because the agent has to learn to collectively complete multiple\nsubtasks. For example, the agent needs to reserve a hotel and book a flight so\nthat there leaves enough time for commute between arrival and hotel check-in.\nThis paper addresses this challenge by formulating the task in the mathematical\nframework of options over Markov Decision Processes (MDPs), and proposing a\nhierarchical deep reinforcement learning approach to learning a dialogue\nmanager that operates at different temporal scales. The dialogue manager\nconsists of: (1) a top-level dialogue policy that selects among subtasks or\noptions, (2) a low-level dialogue policy that selects primitive actions to\ncomplete the subtask given by the top-level policy, and (3) a global state\ntracker that helps ensure all cross-subtask constraints be satisfied.\nExperiments on a travel planning task with simulated and real users show that\nour approach leads to significant improvements over three baselines, two based\non handcrafted rules and the other based on flat deep reinforcement learning.\n", "versions": [{"version": "v1", "created": "Mon, 10 Apr 2017 23:24:46 GMT"}, {"version": "v2", "created": "Mon, 17 Apr 2017 19:36:30 GMT"}, {"version": "v3", "created": "Sat, 22 Jul 2017 22:23:53 GMT"}], "update_date": "2017-07-25", "authors_parsed": [["Peng", "Baolin", ""], ["Li", "Xiujun", ""], ["Li", "Lihong", ""], ["Gao", "Jianfeng", ""], ["Celikyilmaz", "Asli", ""], ["Lee", "Sungjin", ""], ["Wong", "Kam-Fai", ""]]}, {"id": "1704.03103", "submitter": "EPTCS", "authors": "Benoit Desrochers (DGA-TN), Luc Jaulin (Ensta Bretagne, Lab-Sticc)", "title": "Minkowski Operations of Sets with Application to Robot Localization", "comments": "In Proceedings SNR 2017, arXiv:1704.02421", "journal-ref": "EPTCS 247, 2017, pp. 34-45", "doi": "10.4204/EPTCS.247.3", "report-no": null, "categories": "cs.RO cs.AI cs.CG cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This papers shows that using separators, which is a pair of two complementary\ncontractors, we can easily and efficiently solve the localization problem of a\nrobot with sonar measurements in an unstructured environment. We introduce\nseparators associated with the Minkowski sum and the Minkowski difference in\norder to facilitate the resolution. A test-case is given in order to illustrate\nthe principle of the approach.\n", "versions": [{"version": "v1", "created": "Tue, 11 Apr 2017 00:56:51 GMT"}], "update_date": "2017-04-12", "authors_parsed": [["Desrochers", "Benoit", "", "DGA-TN"], ["Jaulin", "Luc", "", "Ensta Bretagne, Lab-Sticc"]]}, {"id": "1704.03275", "submitter": "Bruno Woltzenlogel Paleo", "authors": "Daniyar Itegulov, John Slaney, Bruno Woltzenlogel Paleo", "title": "Scavenger 0.1: A Theorem Prover Based on Conflict Resolution", "comments": "Published at CADE 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI cs.FL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  This paper introduces Scavenger, the first theorem prover for pure\nfirst-order logic without equality based on the new conflict resolution\ncalculus. Conflict resolution has a restricted resolution inference rule that\nresembles (a first-order generalization of) unit propagation as well as a rule\nfor assuming decision literals and a rule for deriving new clauses by (a\nfirst-order generalization of) conflict-driven clause learning.\n", "versions": [{"version": "v1", "created": "Tue, 11 Apr 2017 13:11:57 GMT"}, {"version": "v2", "created": "Tue, 31 Oct 2017 09:09:33 GMT"}], "update_date": "2017-11-01", "authors_parsed": [["Itegulov", "Daniyar", ""], ["Slaney", "John", ""], ["Paleo", "Bruno Woltzenlogel", ""]]}, {"id": "1704.03296", "submitter": "Ruth Fong", "authors": "Ruth Fong and Andrea Vedaldi", "title": "Interpretable Explanations of Black Boxes by Meaningful Perturbation", "comments": "Final camera-ready paper published at ICCV 2017 (Supplementary\n  materials:\n  http://openaccess.thecvf.com/content_ICCV_2017/supplemental/Fong_Interpretable_Explanations_of_ICCV_2017_supplemental.pdf)", "journal-ref": "Proceedings of the 2017 IEEE International Conference on Computer\n  Vision (ICCV)", "doi": "10.1109/ICCV.2017.371", "report-no": null, "categories": "cs.CV cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As machine learning algorithms are increasingly applied to high impact yet\nhigh risk tasks, such as medical diagnosis or autonomous driving, it is\ncritical that researchers can explain how such algorithms arrived at their\npredictions. In recent years, a number of image saliency methods have been\ndeveloped to summarize where highly complex neural networks \"look\" in an image\nfor evidence for their predictions. However, these techniques are limited by\ntheir heuristic nature and architectural constraints. In this paper, we make\ntwo main contributions: First, we propose a general framework for learning\ndifferent kinds of explanations for any black box algorithm. Second, we\nspecialise the framework to find the part of an image most responsible for a\nclassifier decision. Unlike previous works, our method is model-agnostic and\ntestable because it is grounded in explicit and interpretable image\nperturbations.\n", "versions": [{"version": "v1", "created": "Tue, 11 Apr 2017 14:15:20 GMT"}, {"version": "v2", "created": "Tue, 9 Jan 2018 13:53:21 GMT"}, {"version": "v3", "created": "Wed, 10 Jan 2018 16:03:33 GMT"}], "update_date": "2018-01-11", "authors_parsed": [["Fong", "Ruth", ""], ["Vedaldi", "Andrea", ""]]}, {"id": "1704.03342", "submitter": "Mieczys{\\l}aw K{\\l}opotek", "authors": "Mieczys{\\l}aw A. K{\\l}opotek", "title": "Beliefs and Probability in Bacchus' l.p. Logic: A~3-Valued Logic\n  Solution to Apparent Counter-intuition", "comments": "Draft for the conference M.A. K{\\l}opotek: Beliefs and Probability in\n  Bacchus' l.p. Logic: A 3-Valued Logic Solution to Apparent Counter-intuition.\n  [in:] R. Trappl Ed,: Cybernetics and Systems Research. Proc. 11 European\n  Meeting on Cybernetics and System Research EMCSR'92, Wien, Osterreich, 20.\n  April 1992. World Scientific Singapore, New Jersey, London, HongKong Vol. 1,\n  pp. 519-526", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fundamental discrepancy between first order logic and statistical inference\n(global versus local properties of universe) is shown to be the obstacle for\nintegration of logic and probability in L.p. logic of Bacchus. To overcome the\ncounterintuitiveness of L.p. behaviour, a 3-valued logic is proposed.\n", "versions": [{"version": "v1", "created": "Tue, 11 Apr 2017 15:04:45 GMT"}], "update_date": "2017-04-12", "authors_parsed": [["K\u0142opotek", "Mieczys\u0142aw A.", ""]]}, {"id": "1704.03373", "submitter": "Yu Liu", "authors": "Yu Liu, Junjie Yan, Wanli Ouyang", "title": "Quality Aware Network for Set to Set Recognition", "comments": "Accepted at CVPR 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper targets on the problem of set to set recognition, which learns the\nmetric between two image sets. Images in each set belong to the same identity.\nSince images in a set can be complementary, they hopefully lead to higher\naccuracy in practical applications. However, the quality of each sample cannot\nbe guaranteed, and samples with poor quality will hurt the metric. In this\npaper, the quality aware network (QAN) is proposed to confront this problem,\nwhere the quality of each sample can be automatically learned although such\ninformation is not explicitly provided in the training stage. The network has\ntwo branches, where the first branch extracts appearance feature embedding for\neach sample and the other branch predicts quality score for each sample.\nFeatures and quality scores of all samples in a set are then aggregated to\ngenerate the final feature embedding. We show that the two branches can be\ntrained in an end-to-end manner given only the set-level identity annotation.\nAnalysis on gradient spread of this mechanism indicates that the quality\nlearned by the network is beneficial to set-to-set recognition and simplifies\nthe distribution that the network needs to fit. Experiments on both face\nverification and person re-identification show advantages of the proposed QAN.\nThe source code and network structure can be downloaded at\nhttps://github.com/sciencefans/Quality-Aware-Network.\n", "versions": [{"version": "v1", "created": "Tue, 11 Apr 2017 15:47:41 GMT"}], "update_date": "2017-04-12", "authors_parsed": [["Liu", "Yu", ""], ["Yan", "Junjie", ""], ["Ouyang", "Wanli", ""]]}, {"id": "1704.03396", "submitter": "Shahab Ebrahimi", "authors": "Shahab Ebrahimi", "title": "Source-Sensitive Belief Change", "comments": "13 pages", "journal-ref": "International Journal of Artificial Intelligence and Applications\n  (IJAIA), Vol.8, No.2, March 2017", "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The AGM model is the most remarkable framework for modeling belief revision.\nHowever, it is not perfect in all aspects. Paraconsistent belief revision,\nmulti-agent belief revision and non-prioritized belief revision are three\ndifferent extensions to AGM to address three important criticisms applied to\nit. In this article, we propose a framework based on AGM that takes a position\nin each of these categories. Also, we discuss some features of our framework\nand study the satisfiability of AGM postulates in this new context.\n", "versions": [{"version": "v1", "created": "Tue, 11 Apr 2017 16:20:39 GMT"}, {"version": "v2", "created": "Fri, 5 May 2017 08:44:14 GMT"}], "update_date": "2017-05-08", "authors_parsed": [["Ebrahimi", "Shahab", ""]]}, {"id": "1704.03402", "submitter": "Sael Lee", "authors": "Quoc Duy Vo, Jaya Thomas, Shinyoung Cho, Pradipta De, Bong Jun Choi,\n  Lee Sael", "title": "Next Generation Business Intelligence and Analytics: A Survey", "comments": "11 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Business Intelligence and Analytics (BI&A) is the process of extracting and\npredicting business-critical insights from data. Traditional BI focused on data\ncollection, extraction, and organization to enable efficient query processing\nfor deriving insights from historical data. With the rise of big data and cloud\ncomputing, there are many challenges and opportunities for the BI. Especially\nwith the growing number of data sources, traditional BI\\&A are evolving to\nprovide intelligence at different scales and perspectives - operational BI,\nsituational BI, self-service BI. In this survey, we review the evolution of\nbusiness intelligence systems in full scale from back-end architecture to and\nfront-end applications. We focus on the changes in the back-end architecture\nthat deals with the collection and organization of the data. We also review the\nchanges in the front-end applications, where analytic services and\nvisualization are the core components. Using a uses case from BI in Healthcare,\nwhich is one of the most complex enterprises, we show how BI\\&A will play an\nimportant role beyond the traditional usage. The survey provides a holistic\nview of Business Intelligence and Analytics for anyone interested in getting a\ncomplete picture of the different pieces in the emerging next generation BI\\&A\nsolutions.\n", "versions": [{"version": "v1", "created": "Tue, 11 Apr 2017 16:31:51 GMT"}], "update_date": "2017-04-12", "authors_parsed": [["Vo", "Quoc Duy", ""], ["Thomas", "Jaya", ""], ["Cho", "Shinyoung", ""], ["De", "Pradipta", ""], ["Choi", "Bong Jun", ""], ["Sael", "Lee", ""]]}, {"id": "1704.03520", "submitter": "Niek Tax", "authors": "Felix Mannhardt and Niek Tax", "title": "Unsupervised Event Abstraction using Pattern Abstraction and Local\n  Process Models", "comments": "Accepted at Enabling Business Transformation by Business Process\n  Modeling, Development, and Support Working Conference 2017 (BPMDS)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Process mining analyzes business processes based on events stored in event\nlogs. However, some recorded events may correspond to activities on a very low\nlevel of abstraction. When events are recorded on a too low level of\ngranularity, process discovery methods tend to generate overgeneralizing\nprocess models. Grouping low-level events to higher level activities, i.e.,\nevent abstraction, can be used to discover better process models. Existing\nevent abstraction methods are mainly based on common sub-sequences and\nclustering techniques. In this paper, we propose to first discover local\nprocess models and then use those models to lift the event log to a higher\nlevel of abstraction. Our conjecture is that process models discovered on the\nobtained high-level event log return process models of higher quality: their\nfitness and precision scores are more balanced. We show this with preliminary\nresults on several real-life event logs.\n", "versions": [{"version": "v1", "created": "Tue, 11 Apr 2017 20:08:14 GMT"}, {"version": "v2", "created": "Tue, 16 May 2017 16:48:18 GMT"}], "update_date": "2017-05-17", "authors_parsed": [["Mannhardt", "Felix", ""], ["Tax", "Niek", ""]]}, {"id": "1704.03574", "submitter": "Marcello Balduccini", "authors": "Marcello Balduccini, Daniele Magazzeni, Marco Maratea, Emily LeBlanc", "title": "CASP Solutions for Planning in Hybrid Domains", "comments": "Under consideration in Theory and Practice of Logic Programming\n  (TPLP)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  CASP is an extension of ASP that allows for numerical constraints to be added\nin the rules. PDDL+ is an extension of the PDDL standard language of automated\nplanning for modeling mixed discrete-continuous dynamics.\n  In this paper, we present CASP solutions for dealing with PDDL+ problems,\ni.e., encoding from PDDL+ to CASP, and extensions to the algorithm of the EZCSP\nCASP solver in order to solve CASP programs arising from PDDL+ domains. An\nexperimental analysis, performed on well-known linear and non-linear variants\nof PDDL+ domains, involving various configurations of the EZCSP solver, other\nCASP solvers, and PDDL+ planners, shows the viability of our solution.\n", "versions": [{"version": "v1", "created": "Wed, 12 Apr 2017 00:10:27 GMT"}, {"version": "v2", "created": "Mon, 25 Jun 2018 13:46:34 GMT"}], "update_date": "2018-06-26", "authors_parsed": [["Balduccini", "Marcello", ""], ["Magazzeni", "Daniele", ""], ["Maratea", "Marco", ""], ["LeBlanc", "Emily", ""]]}, {"id": "1704.03612", "submitter": "Yang Wang", "authors": "Yang Wang, Lin Wu", "title": "Finding Modes by Probabilistic Hypergraphs Shifting", "comments": "Fixing some minor issues in PAKDD 2014", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we develop a novel paradigm, namely hypergraph shift, to find\nrobust graph modes by probabilistic voting strategy, which are semantically\nsound besides the self-cohesiveness requirement in forming graph modes. Unlike\nthe existing techniques to seek graph modes by shifting vertices based on\npair-wise edges (i.e, an edge with $2$ ends), our paradigm is based on shifting\nhigh-order edges (hyperedges) to deliver graph modes. Specifically, we convert\nthe problem of seeking graph modes as the problem of seeking maximizers of a\nnovel objective function with the aim to generate good graph modes based on\nsifting edges in hypergraphs. As a result, the generated graph modes based on\ndense subhypergraphs may more accurately capture the object semantics besides\nthe self-cohesiveness requirement. We also formally prove that our technique is\nalways convergent. Extensive empirical studies on synthetic and real world data\nsets are conducted on clustering and graph matching. They demonstrate that our\ntechniques significantly outperform the existing techniques.\n", "versions": [{"version": "v1", "created": "Wed, 12 Apr 2017 04:02:04 GMT"}], "update_date": "2017-04-13", "authors_parsed": [["Wang", "Yang", ""], ["Wu", "Lin", ""]]}, {"id": "1704.03627", "submitter": "Ting-Hao Huang", "authors": "Ting-Hao 'Kenneth' Huang, Yun-Nung Chen, Jeffrey P. Bigham", "title": "Real-time On-Demand Crowd-powered Entity Extraction", "comments": "Accepted by the 5th Edition Of The Collective Intelligence Conference\n  (CI 2017) as an oral presentation. Interface code and data are available at:\n  https://github.com/windx0303/dialogue-esp-game", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Output-agreement mechanisms such as ESP Game have been widely used in human\ncomputation to obtain reliable human-generated labels. In this paper, we argue\nthat a \"time-limited\" output-agreement mechanism can be used to create a fast\nand robust crowd-powered component in interactive systems, particularly\ndialogue systems, to extract key information from user utterances on the fly.\nOur experiments on Amazon Mechanical Turk using the Airline Travel Information\nSystem (ATIS) dataset showed that the proposed approach achieves high-quality\nresults with an average response time shorter than 9 seconds.\n", "versions": [{"version": "v1", "created": "Wed, 12 Apr 2017 05:48:18 GMT"}, {"version": "v2", "created": "Wed, 6 Dec 2017 17:12:12 GMT"}], "update_date": "2017-12-07", "authors_parsed": [["Huang", "Ting-Hao 'Kenneth'", ""], ["Chen", "Yun-Nung", ""], ["Bigham", "Jeffrey P.", ""]]}, {"id": "1704.03667", "submitter": "Antonio Luca Alfeo", "authors": "Antonio L. Alfeo, Mario G. C. A. Cimino, Sara Egidi, Bruno Lepri, Alex\n  Pentland, Gigliola Vaglini", "title": "Stigmergy-based modeling to discover urban activity patterns from\n  positioning data", "comments": null, "journal-ref": "in Proc. of the International Conference SBP-BRiMS 2017,\n  Washington, DC, USA, 5-8 July, 2017, LNCS 10354, pp. 292-301", "doi": "10.1007/978-3-319-60240-0_35", "report-no": null, "categories": "cs.AI cs.SI physics.soc-ph", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Positioning data offer a remarkable source of information to analyze crowds\nurban dynamics. However, discovering urban activity patterns from the emergent\nbehavior of crowds involves complex system modeling. An alternative approach is\nto adopt computational techniques belonging to the emergent paradigm, which\nenables self-organization of data and allows adaptive analysis. Specifically,\nour approach is based on stigmergy. By using stigmergy each sample position is\nassociated with a digital pheromone deposit, which progressively evaporates and\naggregates with other deposits according to their spatiotemporal proximity.\nBased on this principle, we exploit positioning data to identify high density\nareas (hotspots) and characterize their activity over time. This\ncharacterization allows the comparison of dynamics occurring in different days,\nproviding a similarity measure exploitable by clustering techniques. Thus, we\ncluster days according to their activity behavior, discovering unexpected urban\nactivity patterns. As a case study, we analyze taxi traces in New York City\nduring 2015.\n", "versions": [{"version": "v1", "created": "Wed, 12 Apr 2017 09:24:37 GMT"}, {"version": "v2", "created": "Mon, 21 Jan 2019 10:13:57 GMT"}], "update_date": "2019-01-23", "authors_parsed": [["Alfeo", "Antonio L.", ""], ["Cimino", "Mario G. C. A.", ""], ["Egidi", "Sara", ""], ["Lepri", "Bruno", ""], ["Pentland", "Alex", ""], ["Vaglini", "Gigliola", ""]]}, {"id": "1704.03723", "submitter": "Mieczys{\\l}aw K{\\l}opotek", "authors": "Mieczys{\\l}aw A. K{\\l}opotek", "title": "Beliefs in Markov Trees - From Local Computations to Local Valuation", "comments": "Preliminary versioin of conference paper: M.A. K{\\l}opotek: Beliefs\n  in Markov Trees - From Local Computations to Local Valuation. [in:] R.\n  Trappl, Ed.: Cybernetics and Systems Research , Proc. 12th European Meeting\n  on Cybernetics and System Research, Vienna 5-8 April 1994, World Scientific\n  Publishers, Vol.1. pp. 351-358", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper is devoted to expressiveness of hypergraphs for which uncertainty\npropagation by local computations via Shenoy/Shafer method applies. It is\ndemonstrated that for this propagation method for a given joint belief\ndistribution no valuation of hyperedges of a hypergraph may provide with\nsimpler hypergraph structure than valuation of hyperedges by conditional\ndistributions. This has vital implication that methods recovering belief\nnetworks from data have no better alternative for finding the simplest\nhypergraph structure for belief propagation. A method for recovery\ntree-structured belief networks has been developed and specialized for\nDempster-Shafer belief functions\n", "versions": [{"version": "v1", "created": "Wed, 12 Apr 2017 12:30:17 GMT"}], "update_date": "2017-04-13", "authors_parsed": [["K\u0142opotek", "Mieczys\u0142aw A.", ""]]}, {"id": "1704.03732", "submitter": "Todd Hester", "authors": "Todd Hester, Matej Vecerik, Olivier Pietquin, Marc Lanctot, Tom\n  Schaul, Bilal Piot, Dan Horgan, John Quan, Andrew Sendonaris, Gabriel\n  Dulac-Arnold, Ian Osband, John Agapiou, Joel Z. Leibo, Audrunas Gruslys", "title": "Deep Q-learning from Demonstrations", "comments": "Published at AAAI 2018. Previously on arxiv as \"Learning from\n  Demonstrations for Real World Reinforcement Learning\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep reinforcement learning (RL) has achieved several high profile successes\nin difficult decision-making problems. However, these algorithms typically\nrequire a huge amount of data before they reach reasonable performance. In\nfact, their performance during learning can be extremely poor. This may be\nacceptable for a simulator, but it severely limits the applicability of deep RL\nto many real-world tasks, where the agent must learn in the real environment.\nIn this paper we study a setting where the agent may access data from previous\ncontrol of the system. We present an algorithm, Deep Q-learning from\nDemonstrations (DQfD), that leverages small sets of demonstration data to\nmassively accelerate the learning process even from relatively small amounts of\ndemonstration data and is able to automatically assess the necessary ratio of\ndemonstration data while learning thanks to a prioritized replay mechanism.\nDQfD works by combining temporal difference updates with supervised\nclassification of the demonstrator's actions. We show that DQfD has better\ninitial performance than Prioritized Dueling Double Deep Q-Networks (PDD DQN)\nas it starts with better scores on the first million steps on 41 of 42 games\nand on average it takes PDD DQN 83 million steps to catch up to DQfD's\nperformance. DQfD learns to out-perform the best demonstration given in 14 of\n42 games. In addition, DQfD leverages human demonstrations to achieve\nstate-of-the-art results for 11 games. Finally, we show that DQfD performs\nbetter than three related algorithms for incorporating demonstration data into\nDQN.\n", "versions": [{"version": "v1", "created": "Wed, 12 Apr 2017 12:44:37 GMT"}, {"version": "v2", "created": "Tue, 18 Jul 2017 13:19:52 GMT"}, {"version": "v3", "created": "Fri, 21 Jul 2017 10:48:28 GMT"}, {"version": "v4", "created": "Wed, 22 Nov 2017 21:18:31 GMT"}], "update_date": "2017-11-27", "authors_parsed": [["Hester", "Todd", ""], ["Vecerik", "Matej", ""], ["Pietquin", "Olivier", ""], ["Lanctot", "Marc", ""], ["Schaul", "Tom", ""], ["Piot", "Bilal", ""], ["Horgan", "Dan", ""], ["Quan", "John", ""], ["Sendonaris", "Andrew", ""], ["Dulac-Arnold", "Gabriel", ""], ["Osband", "Ian", ""], ["Agapiou", "John", ""], ["Leibo", "Joel Z.", ""], ["Gruslys", "Audrunas", ""]]}, {"id": "1704.03738", "submitter": "Lucas Carvalho Cordeiro", "authors": "Rodrigo F. Araujo, Higo F. Albuquerque, Iury V. de Bessa, Lucas C.\n  Cordeiro, Joao Edgar C. Filho", "title": "Counterexample Guided Inductive Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes three variants of a counterexample guided inductive\noptimization (CEGIO) approach based on Satisfiability Modulo Theories (SMT)\nsolvers. In particular, CEGIO relies on iterative executions to constrain a\nverification procedure, in order to perform inductive generalization, based on\ncounterexamples extracted from SMT solvers. CEGIO is able to successfully\noptimize a wide range of functions, including non-linear and non-convex\noptimization problems based on SMT solvers, in which data provided by\ncounterexamples are employed to guide the verification engine, thus reducing\nthe optimization domain. The present algorithms are evaluated using a large set\nof benchmarks typically employed for evaluating optimization techniques.\nExperimental results show the efficiency and effectiveness of the proposed\nalgorithms, which find the optimal solution in all evaluated benchmarks, while\ntraditional techniques are usually trapped by local minima.\n", "versions": [{"version": "v1", "created": "Tue, 11 Apr 2017 15:33:50 GMT"}], "update_date": "2017-04-13", "authors_parsed": [["Araujo", "Rodrigo F.", ""], ["Albuquerque", "Higo F.", ""], ["de Bessa", "Iury V.", ""], ["Cordeiro", "Lucas C.", ""], ["Filho", "Joao Edgar C.", ""]]}, {"id": "1704.03767", "submitter": "Yongchao Liu", "authors": "Yongchao Liu, Tony Pan, Oded Green, Srinivas Aluru", "title": "Parallelized Kendall's Tau Coefficient Computation via SIMD Vectorized\n  Sorting On Many-Integrated-Core Processors", "comments": "29 pages, 6 figures, 5 tables, submitted to Journal of Parallel and\n  Distributed Computing", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pairwise association measure is an important operation in data analytics.\nKendall's tau coefficient is one widely used correlation coefficient\nidentifying non-linear relationships between ordinal variables. In this paper,\nwe investigated a parallel algorithm accelerating all-pairs Kendall's tau\ncoefficient computation via single instruction multiple data (SIMD) vectorized\nsorting on Intel Xeon Phis by taking advantage of many processing cores and\n512-bit SIMD vector instructions. To facilitate workload balancing and overcome\non-chip memory limitation, we proposed a generic framework for symmetric\nall-pairs computation by building provable bijective functions between job\nidentifier and coordinate space. Performance evaluation demonstrated that our\nalgorithm on one 5110P Phi achieves two orders-of-magnitude speedups over\n16-threaded MATLAB and three orders-of-magnitude speedups over sequential R,\nboth running on high-end CPUs. Besides, our algorithm exhibited rather good\ndistributed computing scalability with respect to number of Phis. Source code\nand datasets are publicly available at http://lightpcc.sourceforge.net.\n", "versions": [{"version": "v1", "created": "Wed, 12 Apr 2017 14:29:39 GMT"}], "update_date": "2017-04-13", "authors_parsed": [["Liu", "Yongchao", ""], ["Pan", "Tony", ""], ["Green", "Oded", ""], ["Aluru", "Srinivas", ""]]}, {"id": "1704.03899", "submitter": "Xiaoyu Wang", "authors": "Zhou Ren, Xiaoyu Wang, Ning Zhang, Xutao Lv, Li-Jia Li", "title": "Deep Reinforcement Learning-based Image Captioning with Embedding Reward", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Image captioning is a challenging problem owing to the complexity in\nunderstanding the image content and diverse ways of describing it in natural\nlanguage. Recent advances in deep neural networks have substantially improved\nthe performance of this task. Most state-of-the-art approaches follow an\nencoder-decoder framework, which generates captions using a sequential\nrecurrent prediction model. However, in this paper, we introduce a novel\ndecision-making framework for image captioning. We utilize a \"policy network\"\nand a \"value network\" to collaboratively generate captions. The policy network\nserves as a local guidance by providing the confidence of predicting the next\nword according to the current state. Additionally, the value network serves as\na global and lookahead guidance by evaluating all possible extensions of the\ncurrent state. In essence, it adjusts the goal of predicting the correct words\ntowards the goal of generating captions similar to the ground truth captions.\nWe train both networks using an actor-critic reinforcement learning model, with\na novel reward defined by visual-semantic embedding. Extensive experiments and\nanalyses on the Microsoft COCO dataset show that the proposed framework\noutperforms state-of-the-art approaches across different evaluation metrics.\n", "versions": [{"version": "v1", "created": "Wed, 12 Apr 2017 18:55:03 GMT"}], "update_date": "2017-04-14", "authors_parsed": [["Ren", "Zhou", ""], ["Wang", "Xiaoyu", ""], ["Zhang", "Ning", ""], ["Lv", "Xutao", ""], ["Li", "Li-Jia", ""]]}, {"id": "1704.03926", "submitter": "Bence Cserna", "authors": "Bence Cserna, Marek Petrik, Reazul Hasan Russel, Wheeler Ruml", "title": "Value Directed Exploration in Multi-Armed Bandits with Structured Priors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-armed bandits are a quintessential machine learning problem requiring\nthe balancing of exploration and exploitation. While there has been progress in\ndeveloping algorithms with strong theoretical guarantees, there has been less\nfocus on practical near-optimal finite-time performance. In this paper, we\npropose an algorithm for Bayesian multi-armed bandits that utilizes\nvalue-function-driven online planning techniques. Building on previous work on\nUCB and Gittins index, we introduce linearly-separable value functions that\ntake both the expected return and the benefit of exploration into consideration\nto perform n-step lookahead. The algorithm enjoys a sub-linear performance\nguarantee and we present simulation results that confirm its strength in\nproblems with structured priors. The simplicity and generality of our approach\nmakes it a strong candidate for analyzing more complex multi-armed bandit\nproblems.\n", "versions": [{"version": "v1", "created": "Wed, 12 Apr 2017 20:46:50 GMT"}, {"version": "v2", "created": "Wed, 17 May 2017 14:02:27 GMT"}], "update_date": "2017-05-18", "authors_parsed": [["Cserna", "Bence", ""], ["Petrik", "Marek", ""], ["Russel", "Reazul Hasan", ""], ["Ruml", "Wheeler", ""]]}, {"id": "1704.03952", "submitter": "Xinlei Pan", "authors": "Xinlei Pan, Yurong You, Ziyan Wang, Cewu Lu", "title": "Virtual to Real Reinforcement Learning for Autonomous Driving", "comments": null, "journal-ref": "Proceedings of the British Machine Vision Conference (BMVC) 2017\n  (Spotlight)", "doi": null, "report-no": null, "categories": "cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning is considered as a promising direction for driving\npolicy learning. However, training autonomous driving vehicle with\nreinforcement learning in real environment involves non-affordable\ntrial-and-error. It is more desirable to first train in a virtual environment\nand then transfer to the real environment. In this paper, we propose a novel\nrealistic translation network to make model trained in virtual environment be\nworkable in real world. The proposed network can convert non-realistic virtual\nimage input into a realistic one with similar scene structure. Given realistic\nframes as input, driving policy trained by reinforcement learning can nicely\nadapt to real world driving. Experiments show that our proposed virtual to real\n(VR) reinforcement learning (RL) works pretty well. To our knowledge, this is\nthe first successful case of driving policy trained by reinforcement learning\nthat can adapt to real world driving data.\n", "versions": [{"version": "v1", "created": "Thu, 13 Apr 2017 00:03:40 GMT"}, {"version": "v2", "created": "Tue, 9 May 2017 08:09:40 GMT"}, {"version": "v3", "created": "Thu, 11 May 2017 16:56:54 GMT"}, {"version": "v4", "created": "Tue, 26 Sep 2017 17:22:04 GMT"}], "update_date": "2017-09-27", "authors_parsed": [["Pan", "Xinlei", ""], ["You", "Yurong", ""], ["Wang", "Ziyan", ""], ["Lu", "Cewu", ""]]}, {"id": "1704.03992", "submitter": "Ying Zhang", "authors": "Ying Zhang", "title": "Fully Distributed and Asynchronized Stochastic Gradient Descent for\n  Networked Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper considers a general data-fitting problem over a networked system,\nin which many computing nodes are connected by an undirected graph. This kind\nof problem can find many real-world applications and has been studied\nextensively in the literature. However, existing solutions either need a\ncentral controller for information sharing or requires slot synchronization\namong different nodes, which increases the difficulty of practical\nimplementations, especially for a very large and heterogeneous system.\n  As a contrast, in this paper, we treat the data-fitting problem over the\nnetwork as a stochastic programming problem with many constraints. By adapting\nthe results in a recent paper, we design a fully distributed and asynchronized\nstochastic gradient descent (SGD) algorithm. We show that our algorithm can\nachieve global optimality and consensus asymptotically by only local\ncomputations and communications. Additionally, we provide a sharp lower bound\nfor the convergence speed in the regular graph case. This result fits the\nintuition and provides guidance to design a `good' network topology to speed up\nthe convergence. Also, the merit of our design is validated by experiments on\nboth synthetic and real-world datasets.\n", "versions": [{"version": "v1", "created": "Thu, 13 Apr 2017 04:58:54 GMT"}], "update_date": "2017-04-14", "authors_parsed": [["Zhang", "Ying", ""]]}, {"id": "1704.04000", "submitter": "Mieczys{\\l}aw K{\\l}opotek", "authors": "Mieczys{\\l}aw K{\\l}opotek", "title": "Dempster-Shafer Belief Function - A New Interpretation", "comments": "70 pages, an internat intermediate research report, dating back to\n  1993", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop our interpretation of the joint belief distribution and of\nevidential updating that matches the following basic requirements:\n  * there must exist an efficient method for reasoning within this framework\n  * there must exist a clear correspondence between the contents of the\nknowledge base and the real world\n  * there must be a clear correspondence between the reasoning method and some\nreal world process\n  * there must exist a clear correspondence between the results of the\nreasoning process and the results of the real world process corresponding to\nthe reasoning process.\n", "versions": [{"version": "v1", "created": "Thu, 13 Apr 2017 06:00:00 GMT"}], "update_date": "2017-04-14", "authors_parsed": [["K\u0142opotek", "Mieczys\u0142aw", ""]]}, {"id": "1704.04058", "submitter": "Jonas Adler", "authors": "Jonas Adler and Ozan \\\"Oktem", "title": "Solving ill-posed inverse problems using iterative deep neural networks", "comments": null, "journal-ref": "Inverse Problems 2017", "doi": "10.1088/1361-6420/aa9581", "report-no": null, "categories": "math.OC cs.AI math.FA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a partially learned approach for the solution of ill posed inverse\nproblems with not necessarily linear forward operators. The method builds on\nideas from classical regularization theory and recent advances in deep learning\nto perform learning while making use of prior information about the inverse\nproblem encoded in the forward operator, noise model and a regularizing\nfunctional. The method results in a gradient-like iterative scheme, where the\n\"gradient\" component is learned using a convolutional network that includes the\ngradients of the data discrepancy and regularizer as input in each iteration.\nWe present results of such a partially learned gradient scheme on a non-linear\ntomographic inversion problem with simulated data from both the Sheep-Logan\nphantom as well as a head CT. The outcome is compared against FBP and TV\nreconstruction and the proposed method provides a 5.4 dB PSNR improvement over\nthe TV reconstruction while being significantly faster, giving reconstructions\nof 512 x 512 volumes in about 0.4 seconds using a single GPU.\n", "versions": [{"version": "v1", "created": "Thu, 13 Apr 2017 10:10:15 GMT"}, {"version": "v2", "created": "Mon, 22 May 2017 15:06:45 GMT"}], "update_date": "2017-11-27", "authors_parsed": [["Adler", "Jonas", ""], ["\u00d6ktem", "Ozan", ""]]}, {"id": "1704.04110", "submitter": "David Salinas", "authors": "David Salinas, Valentin Flunkert, Jan Gasthaus", "title": "DeepAR: Probabilistic Forecasting with Autoregressive Recurrent Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Probabilistic forecasting, i.e. estimating the probability distribution of a\ntime series' future given its past, is a key enabler for optimizing business\nprocesses. In retail businesses, for example, forecasting demand is crucial for\nhaving the right inventory available at the right time at the right place. In\nthis paper we propose DeepAR, a methodology for producing accurate\nprobabilistic forecasts, based on training an auto regressive recurrent network\nmodel on a large number of related time series. We demonstrate how by applying\ndeep learning techniques to forecasting, one can overcome many of the\nchallenges faced by widely-used classical approaches to the problem. We show\nthrough extensive empirical evaluation on several real-world forecasting data\nsets accuracy improvements of around 15% compared to state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Thu, 13 Apr 2017 13:11:53 GMT"}, {"version": "v2", "created": "Wed, 5 Jul 2017 07:39:14 GMT"}, {"version": "v3", "created": "Fri, 22 Feb 2019 13:43:50 GMT"}], "update_date": "2019-02-25", "authors_parsed": [["Salinas", "David", ""], ["Flunkert", "Valentin", ""], ["Gasthaus", "Jan", ""]]}, {"id": "1704.04133", "submitter": "Devinder Kumar", "authors": "Devinder Kumar, Alexander Wong, Graham W. Taylor", "title": "Explaining the Unexplained: A CLass-Enhanced Attentive Response (CLEAR)\n  Approach to Understanding Deep Neural Networks", "comments": "Accepted at Computer Vision and Patter Recognition Workshop (CVPR-W)\n  on Explainable Computer Vision, 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we propose CLass-Enhanced Attentive Response (CLEAR): an\napproach to visualize and understand the decisions made by deep neural networks\n(DNNs) given a specific input. CLEAR facilitates the visualization of attentive\nregions and levels of interest of DNNs during the decision-making process. It\nalso enables the visualization of the most dominant classes associated with\nthese attentive regions of interest. As such, CLEAR can mitigate some of the\nshortcomings of heatmap-based methods associated with decision ambiguity, and\nallows for better insights into the decision-making process of DNNs.\nQuantitative and qualitative experiments across three different datasets\ndemonstrate the efficacy of CLEAR for gaining a better understanding of the\ninner workings of DNNs during the decision-making process.\n", "versions": [{"version": "v1", "created": "Thu, 13 Apr 2017 13:44:33 GMT"}, {"version": "v2", "created": "Thu, 18 May 2017 18:38:06 GMT"}], "update_date": "2017-05-22", "authors_parsed": [["Kumar", "Devinder", ""], ["Wong", "Alexander", ""], ["Taylor", "Graham W.", ""]]}, {"id": "1704.04313", "submitter": "Lukas Cavigelli", "authors": "Lukas Cavigelli, Philippe Degen, Luca Benini", "title": "CBinfer: Change-Based Inference for Convolutional Neural Networks on\n  Video Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.PF eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Extracting per-frame features using convolutional neural networks for\nreal-time processing of video data is currently mainly performed on powerful\nGPU-accelerated workstations and compute clusters. However, there are many\napplications such as smart surveillance cameras that require or would benefit\nfrom on-site processing. To this end, we propose and evaluate a novel algorithm\nfor change-based evaluation of CNNs for video data recorded with a static\ncamera setting, exploiting the spatio-temporal sparsity of pixel changes. We\nachieve an average speed-up of 8.6x over a cuDNN baseline on a realistic\nbenchmark with a negligible accuracy loss of less than 0.1% and no retraining\nof the network. The resulting energy efficiency is 10x higher than that of\nper-frame evaluation and reaches an equivalent of 328 GOp/s/W on the Tegra X1\nplatform.\n", "versions": [{"version": "v1", "created": "Fri, 14 Apr 2017 00:36:55 GMT"}, {"version": "v2", "created": "Wed, 21 Jun 2017 09:27:14 GMT"}], "update_date": "2017-11-10", "authors_parsed": [["Cavigelli", "Lukas", ""], ["Degen", "Philippe", ""], ["Benini", "Luca", ""]]}, {"id": "1704.04327", "submitter": "Surya Bhupatiraju", "authors": "Surya Bhupatiraju, Rishabh Singh, Abdel-rahman Mohamed, Pushmeet Kohli", "title": "Deep API Programmer: Learning to Program with APIs", "comments": "8 pages + 4 pages of supplementary material. Submitted to IJCAI 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present DAPIP, a Programming-By-Example system that learns to program with\nAPIs to perform data transformation tasks. We design a domain-specific language\n(DSL) that allows for arbitrary concatenations of API outputs and constant\nstrings. The DSL consists of three family of APIs: regular expression-based\nAPIs, lookup APIs, and transformation APIs. We then present a novel neural\nsynthesis algorithm to search for programs in the DSL that are consistent with\na given set of examples. The search algorithm uses recently introduced neural\narchitectures to encode input-output examples and to model the program search\nin the DSL. We show that synthesis algorithm outperforms baseline methods for\nsynthesizing programs on both synthetic and real-world benchmarks.\n", "versions": [{"version": "v1", "created": "Fri, 14 Apr 2017 02:04:06 GMT"}], "update_date": "2017-04-17", "authors_parsed": [["Bhupatiraju", "Surya", ""], ["Singh", "Rishabh", ""], ["Mohamed", "Abdel-rahman", ""], ["Kohli", "Pushmeet", ""]]}, {"id": "1704.04341", "submitter": "Michael Littman", "authors": "Michael L. Littman and Ufuk Topcu and Jie Fu and Charles Isbell and\n  Min Wen and James MacGlashan", "title": "Environment-Independent Task Specifications via GLTL", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new task-specification language for Markov decision processes\nthat is designed to be an improvement over reward functions by being\nenvironment independent. The language is a variant of Linear Temporal Logic\n(LTL) that is extended to probabilistic specifications in a way that permits\napproximations to be learned in finite time. We provide several small\nenvironments that demonstrate the advantages of our geometric LTL (GLTL)\nlanguage and illustrate how it can be used to specify standard\nreinforcement-learning tasks straightforwardly.\n", "versions": [{"version": "v1", "created": "Fri, 14 Apr 2017 03:41:59 GMT"}], "update_date": "2017-04-17", "authors_parsed": [["Littman", "Michael L.", ""], ["Topcu", "Ufuk", ""], ["Fu", "Jie", ""], ["Isbell", "Charles", ""], ["Wen", "Min", ""], ["MacGlashan", "James", ""]]}, {"id": "1704.04379", "submitter": "Makoto Naruse", "authors": "Makoto Naruse, Yuta Terashima, Atsushi Uchida and Song-Ju Kim", "title": "Ultrafast photonic reinforcement learning based on laser chaos", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.optics cs.AI cs.ET", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning involves decision making in dynamic and uncertain\nenvironments, and constitutes one important element of artificial intelligence\n(AI). In this paper, we experimentally demonstrate that the ultrafast chaotic\noscillatory dynamics of lasers efficiently solve the multi-armed bandit problem\n(MAB), which requires decision making concerning a class of difficult\ntrade-offs called the exploration-exploitation dilemma. To solve the MAB, a\ncertain degree of randomness is required for exploration purposes. However,\npseudo-random numbers generated using conventional electronic circuitry\nencounter severe limitations in terms of their data rate and the quality of\nrandomness due to their algorithmic foundations. We generate laser chaos\nsignals using a semiconductor laser sampled at a maximum rate of 100 GSample/s,\nand combine it with a simple decision-making principle called tug-of-war with a\nvariable threshold, to ensure ultrafast, adaptive and accurate decision making\nat a maximum adaptation speed of 1 GHz. We found that decision-making\nperformance was maximized with an optimal sampling interval, and we highlight\nthe exact coincidence between the negative autocorrelation inherent in laser\nchaos and decision-making performance. This study paves the way for a new realm\nof ultrafast photonics in the age of AI, where the ultrahigh bandwidth of\nphotons can provide new value.\n", "versions": [{"version": "v1", "created": "Fri, 14 Apr 2017 10:05:52 GMT"}], "update_date": "2017-04-17", "authors_parsed": [["Naruse", "Makoto", ""], ["Terashima", "Yuta", ""], ["Uchida", "Atsushi", ""], ["Kim", "Song-Ju", ""]]}, {"id": "1704.04408", "submitter": "Mina Alibeigi", "authors": "Mina Alibeigi, Majid Nili Ahmadabadi and Babak Nadjar Araabi", "title": "Incremental learning of high-level concepts by imitation", "comments": "6 pages, 5 figures, 2 tables, supplementary material, conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nowadays, robots become a companion in everyday life. To be well-accepted by\nhumans, robots should efficiently understand meanings of their partners'\nmotions and body language, and respond accordingly. Learning concepts by\nimitation brings them this ability in a user-friendly way.\n  This paper presents a fast and robust model for Incremental Learning of\nConcepts by Imitation (ILoCI). In ILoCI, observed multimodal spatio-temporal\ndemonstrations are incrementally abstracted and generalized based on both their\nperceptual and functional similarities during the imitation. In this method,\nperceptually similar demonstrations are abstracted by a dynamic model of mirror\nneuron system. An incremental method is proposed to learn their functional\nsimilarities through a limited number of interactions with the teacher.\nLearning all concepts together by the proposed memory rehearsal enables robot\nto utilize the common structural relations among concepts which not only\nexpedites the learning process especially at the initial stages, but also\nimproves the generalization ability and the robustness against discrepancies\nbetween observed demonstrations.\n  Performance of ILoCI is assessed using standard LASA handwriting benchmark\ndata set. The results show efficiency of ILoCI in concept acquisition,\nrecognition and generation in addition to its robustness against variability in\ndemonstrations.\n", "versions": [{"version": "v1", "created": "Fri, 14 Apr 2017 12:28:19 GMT"}], "update_date": "2017-07-25", "authors_parsed": [["Alibeigi", "Mina", ""], ["Ahmadabadi", "Majid Nili", ""], ["Araabi", "Babak Nadjar", ""]]}, {"id": "1704.04451", "submitter": "Phong Le", "authors": "Phong Le and Ivan Titov", "title": "Optimizing Differentiable Relaxations of Coreference Evaluation Metrics", "comments": "10 pages. CoNLL", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Coreference evaluation metrics are hard to optimize directly as they are\nnon-differentiable functions, not easily decomposable into elementary\ndecisions. Consequently, most approaches optimize objectives only indirectly\nrelated to the end goal, resulting in suboptimal performance. Instead, we\npropose a differentiable relaxation that lends itself to gradient-based\noptimisation, thus bypassing the need for reinforcement learning or heuristic\nmodification of cross-entropy. We show that by modifying the training objective\nof a competitive neural coreference system, we obtain a substantial gain in\nperformance. This suggests that our approach can be regarded as a viable\nalternative to using reinforcement learning or more computationally expensive\nimitation learning.\n", "versions": [{"version": "v1", "created": "Fri, 14 Apr 2017 15:22:51 GMT"}, {"version": "v2", "created": "Mon, 17 Apr 2017 08:30:32 GMT"}, {"version": "v3", "created": "Thu, 22 Jun 2017 07:55:47 GMT"}], "update_date": "2017-06-23", "authors_parsed": [["Le", "Phong", ""], ["Titov", "Ivan", ""]]}, {"id": "1704.04478", "submitter": "Neil Hallonquist", "authors": "Neil Hallonquist", "title": "Graphical Models: An Extension to Random Graphs, Trees, and Other\n  Objects", "comments": "111 pages, with extended discussion", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we consider an extension of graphical models to random graphs,\ntrees, and other objects. To do this, many fundamental concepts for\nmultivariate random variables (e.g., marginal variables, Gibbs distribution,\nMarkov properties) must be extended to other mathematical objects; it turns out\nthat this extension is possible, as we will discuss, if we have a consistent,\ncomplete system of projections on a given object. Each projection defines a\nmarginal random variable, allowing one to specify independence assumptions\nbetween them. Furthermore, these independencies can be specified in terms of a\nsmall subset of these marginal variables (which we call the atomic variables),\nallowing the compact representation of independencies by a directed graph.\nProjections also define factors, functions on the projected object space, and\nhence a projection family defines a set of possible factorizations for a\ndistribution; these can be compactly represented by an undirected graph.\n  The invariances used in graphical models are essential for learning\ndistributions, not just on multivariate random variables, but also on other\nobjects. When they are applied to random graphs and random trees, the result is\na general class of models that is applicable to a broad range of problems,\nincluding those in which the graphs and trees have complicated edge structures.\nThese models need not be conditioned on a fixed number of vertices, as is often\nthe case in the literature for random graphs, and can be used for problems in\nwhich attributes are associated with vertices and edges. For graphs,\napplications include the modeling of molecules, neural networks, and relational\nreal-world scenes; for trees, applications include the modeling of infectious\ndiseases, cell fusion, the structure of language, and the structure of objects\nin visual scenes. Many classic models are particular instances of this\nframework.\n", "versions": [{"version": "v1", "created": "Fri, 14 Apr 2017 16:38:45 GMT"}, {"version": "v2", "created": "Fri, 5 May 2017 14:13:18 GMT"}], "update_date": "2017-05-08", "authors_parsed": [["Hallonquist", "Neil", ""]]}, {"id": "1704.04517", "submitter": "Alexander Kuhnle", "authors": "Alexander Kuhnle and Ann Copestake", "title": "ShapeWorld - A new test methodology for multimodal language\n  understanding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a novel framework for evaluating multimodal deep learning models\nwith respect to their language understanding and generalization abilities. In\nthis approach, artificial data is automatically generated according to the\nexperimenter's specifications. The content of the data, both during training\nand evaluation, can be controlled in detail, which enables tasks to be created\nthat require true generalization abilities, in particular the combination of\npreviously introduced concepts in novel ways. We demonstrate the potential of\nour methodology by evaluating various visual question answering models on four\ndifferent tasks, and show how our framework gives us detailed insights into\ntheir capabilities and limitations. By open-sourcing our framework, we hope to\nstimulate progress in the field of multimodal language understanding.\n", "versions": [{"version": "v1", "created": "Fri, 14 Apr 2017 19:01:51 GMT"}], "update_date": "2017-04-18", "authors_parsed": [["Kuhnle", "Alexander", ""], ["Copestake", "Ann", ""]]}, {"id": "1704.04576", "submitter": "Chenliang Li", "authors": "Zhiqian Zhang, Chenliang Li, Zhiyong Wu, Aixin Sun, Dengpan Ye,\n  Xiangyang Luo", "title": "NEXT: A Neural Network Framework for Next POI Recommendation", "comments": null, "journal-ref": "Frontiers of Computer Science, 2019", "doi": "10.1007/s11704-018-8011-2", "report-no": null, "categories": "cs.IR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The task of next POI recommendation has been studied extensively in recent\nyears. However, developing an unified recommendation framework to incorporate\nmultiple factors associated with both POIs and users remains challenging,\nbecause of the heterogeneity nature of these information. Further, effective\nmechanisms to handle cold-start and endow the system with interpretability are\nalso difficult topics. Inspired by the recent success of neural networks in\nmany areas, in this paper, we present a simple but effective neural network\nframework for next POI recommendation, named NEXT. NEXT is an unified framework\nto learn the hidden intent regarding user's next move, by incorporating\ndifferent factors in an unified manner. Specifically, in NEXT, we incorporate\nmeta-data information and two kinds of temporal contexts (i.e., time interval\nand visit time). To leverage sequential relations and geographical influence,\nwe propose to adopt DeepWalk, a network representation learning technique, to\nencode such knowledge. We evaluate the effectiveness of NEXT against\nstate-of-the-art alternatives and neural networks based solutions. Experimental\nresults over three publicly available datasets demonstrate that NEXT\nsignificantly outperforms baselines in real-time next POI recommendation.\nFurther experiments demonstrate the superiority of NEXT in handling cold-start.\nMore importantly, we show that NEXT provides meaningful explanation of the\ndimensions in hidden intent space.\n", "versions": [{"version": "v1", "created": "Sat, 15 Apr 2017 04:00:53 GMT"}], "update_date": "2019-04-22", "authors_parsed": [["Zhang", "Zhiqian", ""], ["Li", "Chenliang", ""], ["Wu", "Zhiyong", ""], ["Sun", "Aixin", ""], ["Ye", "Dengpan", ""], ["Luo", "Xiangyang", ""]]}, {"id": "1704.04651", "submitter": "Audrunas Gruslys", "authors": "Audrunas Gruslys, Will Dabney, Mohammad Gheshlaghi Azar, Bilal Piot,\n  Marc Bellemare, Remi Munos", "title": "The Reactor: A fast and sample-efficient Actor-Critic agent for\n  Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we present a new agent architecture, called Reactor, which\ncombines multiple algorithmic and architectural contributions to produce an\nagent with higher sample-efficiency than Prioritized Dueling DQN (Wang et al.,\n2016) and Categorical DQN (Bellemare et al., 2017), while giving better\nrun-time performance than A3C (Mnih et al., 2016). Our first contribution is a\nnew policy evaluation algorithm called Distributional Retrace, which brings\nmulti-step off-policy updates to the distributional reinforcement learning\nsetting. The same approach can be used to convert several classes of multi-step\npolicy evaluation algorithms designed for expected value evaluation into\ndistributional ones. Next, we introduce the \\b{eta}-leave-one-out policy\ngradient algorithm which improves the trade-off between variance and bias by\nusing action values as a baseline. Our final algorithmic contribution is a new\nprioritized replay algorithm for sequences, which exploits the temporal\nlocality of neighboring observations for more efficient replay prioritization.\nUsing the Atari 2600 benchmarks, we show that each of these innovations\ncontribute to both the sample efficiency and final agent performance. Finally,\nwe demonstrate that Reactor reaches state-of-the-art performance after 200\nmillion frames and less than a day of training.\n", "versions": [{"version": "v1", "created": "Sat, 15 Apr 2017 15:38:23 GMT"}, {"version": "v2", "created": "Tue, 19 Jun 2018 15:32:15 GMT"}], "update_date": "2018-06-20", "authors_parsed": [["Gruslys", "Audrunas", ""], ["Dabney", "Will", ""], ["Azar", "Mohammad Gheshlaghi", ""], ["Piot", "Bilal", ""], ["Bellemare", "Marc", ""], ["Munos", "Remi", ""]]}, {"id": "1704.04664", "submitter": "Akira Taniguchi", "authors": "Akira Taniguchi, Yoshinobu Hagiwara, Tadahiro Taniguchi, Tetsunari\n  Inamura", "title": "Online Spatial Concept and Lexical Acquisition with Simultaneous\n  Localization and Mapping", "comments": "This paper was accepted in the 2017 IEEE/RSJ International Conference\n  on Intelligent Robots and Systems (IROS 2017)", "journal-ref": null, "doi": "10.1109/IROS.2017.8202243", "report-no": null, "categories": "cs.AI cs.CL cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose an online learning algorithm based on a\nRao-Blackwellized particle filter for spatial concept acquisition and mapping.\nWe have proposed a nonparametric Bayesian spatial concept acquisition model\n(SpCoA). We propose a novel method (SpCoSLAM) integrating SpCoA and FastSLAM in\nthe theoretical framework of the Bayesian generative model. The proposed method\ncan simultaneously learn place categories and lexicons while incrementally\ngenerating an environmental map. Furthermore, the proposed method has scene\nimage features and a language model added to SpCoA. In the experiments, we\ntested online learning of spatial concepts and environmental maps in a novel\nenvironment of which the robot did not have a map. Then, we evaluated the\nresults of online learning of spatial concepts and lexical acquisition. The\nexperimental results demonstrated that the robot was able to more accurately\nlearn the relationships between words and the place in the environmental map\nincrementally by using the proposed method.\n", "versions": [{"version": "v1", "created": "Sat, 15 Apr 2017 17:18:11 GMT"}, {"version": "v2", "created": "Fri, 9 Mar 2018 12:20:51 GMT"}], "update_date": "2018-03-12", "authors_parsed": [["Taniguchi", "Akira", ""], ["Hagiwara", "Yoshinobu", ""], ["Taniguchi", "Tadahiro", ""], ["Inamura", "Tetsunari", ""]]}, {"id": "1704.04683", "submitter": "Guokun Lai", "authors": "Guokun Lai, Qizhe Xie, Hanxiao Liu, Yiming Yang, Eduard Hovy", "title": "RACE: Large-scale ReAding Comprehension Dataset From Examinations", "comments": "EMNLP 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present RACE, a new dataset for benchmark evaluation of methods in the\nreading comprehension task. Collected from the English exams for middle and\nhigh school Chinese students in the age range between 12 to 18, RACE consists\nof near 28,000 passages and near 100,000 questions generated by human experts\n(English instructors), and covers a variety of topics which are carefully\ndesigned for evaluating the students' ability in understanding and reasoning.\nIn particular, the proportion of questions that requires reasoning is much\nlarger in RACE than that in other benchmark datasets for reading comprehension,\nand there is a significant gap between the performance of the state-of-the-art\nmodels (43%) and the ceiling human performance (95%). We hope this new dataset\ncan serve as a valuable resource for research and evaluation in machine\ncomprehension. The dataset is freely available at\nhttp://www.cs.cmu.edu/~glai1/data/race/ and the code is available at\nhttps://github.com/qizhex/RACE_AR_baselines.\n", "versions": [{"version": "v1", "created": "Sat, 15 Apr 2017 19:31:41 GMT"}, {"version": "v2", "created": "Sun, 30 Apr 2017 15:47:40 GMT"}, {"version": "v3", "created": "Sat, 10 Jun 2017 03:21:55 GMT"}, {"version": "v4", "created": "Sat, 15 Jul 2017 18:48:57 GMT"}, {"version": "v5", "created": "Tue, 5 Dec 2017 19:36:03 GMT"}], "update_date": "2017-12-07", "authors_parsed": [["Lai", "Guokun", ""], ["Xie", "Qizhe", ""], ["Liu", "Hanxiao", ""], ["Yang", "Yiming", ""], ["Hovy", "Eduard", ""]]}, {"id": "1704.04684", "submitter": "Luis Argerich", "authors": "Luis Argerich, Natalia Golmar", "title": "Generic LSH Families for the Angular Distance Based on\n  Johnson-Lindenstrauss Projections and Feature Hashing LSH", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.AI cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we propose the creation of generic LSH families for the angular\ndistance based on Johnson-Lindenstrauss projections. We show that feature\nhashing is a valid J-L projection and propose two new LSH families based on\nfeature hashing. These new LSH families are tested on both synthetic and real\ndatasets with very good results and a considerable performance improvement over\nother LSH families. While the theoretical analysis is done for the angular\ndistance, these families can also be used in practice for the euclidean\ndistance with excellent results [2]. Our tests using real datasets show that\nthe proposed LSH functions work well for the euclidean distance.\n", "versions": [{"version": "v1", "created": "Sat, 15 Apr 2017 19:32:51 GMT"}], "update_date": "2017-05-03", "authors_parsed": [["Argerich", "Luis", ""], ["Golmar", "Natalia", ""]]}, {"id": "1704.04712", "submitter": "Shaoshan Liu", "authors": "Shaoshan Liu, Bolin Ding, Jie Tang, Dawei Sun, Zhe Zhang, Grace Tsai,\n  and Jean-Luc Gaudiot", "title": "Learn-Memorize-Recall-Reduce A Robotic Cloud Computing Paradigm", "comments": "6 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The rise of robotic applications has led to the generation of a huge volume\nof unstructured data, whereas the current cloud infrastructure was designed to\nprocess limited amounts of structured data. To address this problem, we propose\na learn-memorize-recall-reduce paradigm for robotic cloud computing. The\nlearning stage converts incoming unstructured data into structured data; the\nmemorization stage provides effective storage for the massive amount of data;\nthe recall stage provides efficient means to retrieve the raw data; while the\nreduction stage provides means to make sense of this massive amount of\nunstructured data with limited computing resources.\n", "versions": [{"version": "v1", "created": "Sun, 16 Apr 2017 02:55:07 GMT"}, {"version": "v2", "created": "Tue, 18 Apr 2017 00:20:51 GMT"}], "update_date": "2017-04-19", "authors_parsed": [["Liu", "Shaoshan", ""], ["Ding", "Bolin", ""], ["Tang", "Jie", ""], ["Sun", "Dawei", ""], ["Zhang", "Zhe", ""], ["Tsai", "Grace", ""], ["Gaudiot", "Jean-Luc", ""]]}, {"id": "1704.04719", "submitter": "Chang-Shing Lee", "authors": "Chang-Shing Lee, Mei-Hui Wang, Chia-Hsiu Kao, Sheng-Chi Yang, Yusuke\n  Nojima, Ryosuke Saga, Nan Shuo, and Naoyuki Kubota", "title": "FML-based Prediction Agent and Its Application to Game of Go", "comments": "6 pages, 12 figures, Joint 17th World Congress of International Fuzzy\n  Systems Association and 9th International Conference on Soft Computing and\n  Intelligent Systems (IFSA-SCIS 2017), Otsu, Japan, Jun. 27-30, 2017", "journal-ref": null, "doi": "10.1109/IFSA-SCIS.2017.8023311", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present a robotic prediction agent including a darkforest\nGo engine, a fuzzy markup language (FML) assessment engine, an FML-based\ndecision support engine, and a robot engine for game of Go application. The\nknowledge base and rule base of FML assessment engine are constructed by\nreferring the information from the darkforest Go engine located in NUTN and\nOPU, for example, the number of MCTS simulations and winning rate prediction.\nThe proposed robotic prediction agent first retrieves the database of Go\ncompetition website, and then the FML assessment engine infers the winning\npossibility based on the information generated by darkforest Go engine. The\nFML-based decision support engine computes the winning possibility based on the\npartial game situation inferred by FML assessment engine. Finally, the robot\nengine combines with the human-friendly robot partner PALRO, produced by\nFujisoft incorporated, to report the game situation to human Go players.\nExperimental results show that the FML-based prediction agent can work\neffectively.\n", "versions": [{"version": "v1", "created": "Sun, 16 Apr 2017 04:19:36 GMT"}], "update_date": "2019-04-15", "authors_parsed": [["Lee", "Chang-Shing", ""], ["Wang", "Mei-Hui", ""], ["Kao", "Chia-Hsiu", ""], ["Yang", "Sheng-Chi", ""], ["Nojima", "Yusuke", ""], ["Saga", "Ryosuke", ""], ["Shuo", "Nan", ""], ["Kubota", "Naoyuki", ""]]}, {"id": "1704.04775", "submitter": "He Jiang", "authors": "He Jiang, Jifeng Xuan, Yan Hu", "title": "Approximating the Backbone in the Weighted Maximum Satisfiability\n  Problem", "comments": "14 pages, 1 figure, Proceedings of Advances in Knowledge Discovery\n  and Data Mining 2008 (PAKDD 2008), 2008", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The weighted Maximum Satisfiability problem (weighted MAX-SAT) is a NP-hard\nproblem with numerous applications arising in artificial intelligence. As an\nefficient tool for heuristic design, the backbone has been applied to\nheuristics design for many NP-hard problems. In this paper, we investigated the\ncomputational complexity for retrieving the backbone in weighted MAX-SAT and\ndeveloped a new algorithm for solving this problem. We showed that it is\nintractable to retrieve the full backbone under the assumption that . Moreover,\nit is intractable to retrieve a fixed fraction of the backbone as well. And\nthen we presented a backbone guided local search (BGLS) with Walksat operator\nfor weighted MAX-SAT. BGLS consists of two phases: the first phase samples the\nbackbone information from local optima and the backbone phase conducts local\nsearch under the guideline of backbone. Extensive experimental results on the\nbenchmark showed that BGLS outperforms the existing heuristics in both solution\nquality and runtime.\n", "versions": [{"version": "v1", "created": "Sun, 16 Apr 2017 13:23:14 GMT"}], "update_date": "2017-04-18", "authors_parsed": [["Jiang", "He", ""], ["Xuan", "Jifeng", ""], ["Hu", "Yan", ""]]}, {"id": "1704.04782", "submitter": "Andres Gomez Ramirez", "authors": "A. Gomez Ramirez, M. Martinez Pedreira, C. Grigoras, L. Betev, C. Lara\n  and U. Kebschull (for the ALICE Collaboration)", "title": "A Security Monitoring Framework For Virtualization Based HEP\n  Infrastructures", "comments": "Proceedings of the 22nd International Conference on Computing in High\n  Energy and Nuclear Physics, CHEP 2016, 10-14 October 2016, San Francisco.\n  Submitted to Journal of Physics: Conference Series (JPCS)", "journal-ref": null, "doi": "10.1088/1742-6596/898/10/102004", "report-no": null, "categories": "cs.DC cs.AI cs.CR hep-ex", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  High Energy Physics (HEP) distributed computing infrastructures require\nautomatic tools to monitor, analyze and react to potential security incidents.\nThese tools should collect and inspect data such as resource consumption, logs\nand sequence of system calls for detecting anomalies that indicate the presence\nof a malicious agent. They should also be able to perform automated reactions\nto attacks without administrator intervention. We describe a novel framework\nthat accomplishes these requirements, with a proof of concept implementation\nfor the ALICE experiment at CERN. We show how we achieve a fully virtualized\nenvironment that improves the security by isolating services and Jobs without a\nsignificant performance impact. We also describe a collected dataset for\nMachine Learning based Intrusion Prevention and Detection Systems on Grid\ncomputing. This dataset is composed of resource consumption measurements (such\nas CPU, RAM and network traffic), logfiles from operating system services, and\nsystem call data collected from production Jobs running in an ALICE Grid test\nsite and a big set of malware. This malware was collected from security\nresearch sites. Based on this dataset, we will proceed to develop Machine\nLearning algorithms able to detect malicious Jobs.\n", "versions": [{"version": "v1", "created": "Sun, 16 Apr 2017 14:59:21 GMT"}], "update_date": "2019-08-14", "authors_parsed": [["Ramirez", "A. Gomez", "", "for the ALICE Collaboration"], ["Pedreira", "M. Martinez", "", "for the ALICE Collaboration"], ["Grigoras", "C.", "", "for the ALICE Collaboration"], ["Betev", "L.", "", "for the ALICE Collaboration"], ["Lara", "C.", "", "for the ALICE Collaboration"], ["Kebschull", "U.", "", "for the ALICE Collaboration"]]}, {"id": "1704.04810", "submitter": "Nariman Farsad Dr.", "authors": "Nariman Farsad, David Pan, Andrea Goldsmith", "title": "A Novel Experimental Platform for In-Vessel Multi-Chemical Molecular\n  Communications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.ET cs.AI cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work presents a new multi-chemical experimental platform for molecular\ncommunication where the transmitter can release different chemicals. This\nplatform is designed to be inexpensive and accessible, and it can be expanded\nto simulate different environments including the cardiovascular system and\ncomplex network of pipes in industrial complexes and city infrastructures. To\ndemonstrate the capabilities of the platform, we implement a time-slotted\nbinary communication system where a bit-0 is represented by an acid pulse, a\nbit-1 by a base pulse, and information is carried via pH signals. The channel\nmodel for this system, which is nonlinear and has long memories, is unknown.\nTherefore, we devise novel detection algorithms that use techniques from\nmachine learning and deep learning to train a maximum-likelihood detector.\nUsing these algorithms the bit error rate improves by an order of magnitude\nrelative to the approach used in previous works. Moreover, our system achieves\na data rate that is an order of magnitude higher than any of the previous\nmolecular communication platforms.\n", "versions": [{"version": "v1", "created": "Sun, 16 Apr 2017 19:24:30 GMT"}], "update_date": "2017-04-18", "authors_parsed": [["Farsad", "Nariman", ""], ["Pan", "David", ""], ["Goldsmith", "Andrea", ""]]}, {"id": "1704.04866", "submitter": "Feiyun Zhu", "authors": "Feiyun Zhu and Peng Liao", "title": "Effective Warm Start for the Online Actor-Critic Reinforcement Learning\n  based mHealth Intervention", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Online reinforcement learning (RL) is increasingly popular for the\npersonalized mobile health (mHealth) intervention. It is able to personalize\nthe type and dose of interventions according to user's ongoing statuses and\nchanging needs. However, at the beginning of online learning, there are usually\ntoo few samples to support the RL updating, which leads to poor performances. A\ndelay in good performance of the online learning algorithms can be especially\ndetrimental in the mHealth, where users tend to quickly disengage with the\nmHealth app. To address this problem, we propose a new online RL methodology\nthat focuses on an effective warm start. The main idea is to make full use of\nthe data accumulated and the decision rule achieved in a former study. As a\nresult, we can greatly enrich the data size at the beginning of online learning\nin our method. Such case accelerates the online learning process for new users\nto achieve good performances not only at the beginning of online learning but\nalso through the whole online learning process. Besides, we use the decision\nrules achieved in a previous study to initialize the parameter in our online RL\nmodel for new users. It provides a good initialization for the proposed online\nRL algorithm. Experiment results show that promising improvements have been\nachieved by our method compared with the state-of-the-art method.\n", "versions": [{"version": "v1", "created": "Mon, 17 Apr 2017 04:43:05 GMT"}, {"version": "v2", "created": "Mon, 1 May 2017 04:51:43 GMT"}, {"version": "v3", "created": "Sun, 21 May 2017 21:00:12 GMT"}], "update_date": "2017-05-23", "authors_parsed": [["Zhu", "Feiyun", ""], ["Liao", "Peng", ""]]}, {"id": "1704.04912", "submitter": "Manuel Mazzara", "authors": "Marochko Vladimir, Leonard Johard, Manuel Mazzara", "title": "Pseudorehearsal in actor-critic agents", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Catastrophic forgetting has a serious impact in reinforcement learning, as\nthe data distribution is generally sparse and non-stationary over time. The\npurpose of this study is to investigate whether pseudorehearsal can increase\nperformance of an actor-critic agent with neural-network based policy selection\nand function approximation in a pole balancing task and compare different\npseudorehearsal approaches. We expect that pseudorehearsal assists learning\neven in such very simple problems, given proper initialization of the rehearsal\nparameters.\n", "versions": [{"version": "v1", "created": "Mon, 17 Apr 2017 09:27:52 GMT"}], "update_date": "2017-04-18", "authors_parsed": [["Vladimir", "Marochko", ""], ["Johard", "Leonard", ""], ["Mazzara", "Manuel", ""]]}, {"id": "1704.04966", "submitter": "Fanhua Shang", "authors": "Fanhua Shang", "title": "Larger is Better: The Effect of Learning Rates Enjoyed by Stochastic\n  Optimization with Progressive Variance Reduction", "comments": "36 pages, 10 figures. The simple variant of SVRG is much better than\n  the best-known stochastic method, Katyusha", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a simple variant of the original stochastic\nvariance reduction gradient (SVRG), where hereafter we refer to as the variance\nreduced stochastic gradient descent (VR-SGD). Different from the choices of the\nsnapshot point and starting point in SVRG and its proximal variant, Prox-SVRG,\nthe two vectors of each epoch in VR-SGD are set to the average and last iterate\nof the previous epoch, respectively. This setting allows us to use much larger\nlearning rates or step sizes than SVRG, e.g., 3/(7L) for VR-SGD vs 1/(10L) for\nSVRG, and also makes our convergence analysis more challenging. In fact, a\nlarger learning rate enjoyed by VR-SGD means that the variance of its\nstochastic gradient estimator asymptotically approaches zero more rapidly.\nUnlike common stochastic methods such as SVRG and proximal stochastic methods\nsuch as Prox-SVRG, we design two different update rules for smooth and\nnon-smooth objective functions, respectively. In other words, VR-SGD can tackle\nnon-smooth and/or non-strongly convex problems directly without using any\nreduction techniques such as quadratic regularizers. Moreover, we analyze the\nconvergence properties of VR-SGD for strongly convex problems, which show that\nVR-SGD attains a linear convergence rate. We also provide the convergence\nguarantees of VR-SGD for non-strongly convex problems. Experimental results\nshow that the performance of VR-SGD is significantly better than its\ncounterparts, SVRG and Prox-SVRG, and it is also much better than the best\nknown stochastic method, Katyusha.\n", "versions": [{"version": "v1", "created": "Mon, 17 Apr 2017 13:50:43 GMT"}], "update_date": "2017-04-18", "authors_parsed": [["Shang", "Fanhua", ""]]}, {"id": "1704.04977", "submitter": "Marco Cusumano-Towner", "authors": "Marco F. Cusumano-Towner, Alexey Radul, David Wingate, Vikash K.\n  Mansinghka", "title": "Probabilistic programs for inferring the goals of autonomous agents", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Intelligent systems sometimes need to infer the probable goals of people,\ncars, and robots, based on partial observations of their motion. This paper\nintroduces a class of probabilistic programs for formulating and solving these\nproblems. The formulation uses randomized path planning algorithms as the basis\nfor probabilistic models of the process by which autonomous agents plan to\nachieve their goals. Because these path planning algorithms do not have\ntractable likelihood functions, new inference algorithms are needed. This paper\nproposes two Monte Carlo techniques for these \"likelihood-free\" models, one of\nwhich can use likelihood estimates from neural networks to accelerate\ninference. The paper demonstrates efficacy on three simple examples, each using\nunder 50 lines of probabilistic code.\n", "versions": [{"version": "v1", "created": "Mon, 17 Apr 2017 14:34:02 GMT"}, {"version": "v2", "created": "Tue, 18 Apr 2017 14:40:03 GMT"}], "update_date": "2017-04-19", "authors_parsed": [["Cusumano-Towner", "Marco F.", ""], ["Radul", "Alexey", ""], ["Wingate", "David", ""], ["Mansinghka", "Vikash K.", ""]]}, {"id": "1704.05017", "submitter": "Mathieu Galtier", "authors": "Mathieu Galtier and Camille Marini", "title": "Morpheo: Traceable Machine Learning on Hidden data", "comments": "whitepaper, 9 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CR cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Morpheo is a transparent and secure machine learning platform collecting and\nanalysing large datasets. It aims at building state-of-the art prediction\nmodels in various fields where data are sensitive. Indeed, it offers strong\nprivacy of data and algorithm, by preventing anyone to read the data, apart\nfrom the owner and the chosen algorithms. Computations in Morpheo are\norchestrated by a blockchain infrastructure, thus offering total traceability\nof operations. Morpheo aims at building an attractive economic ecosystem around\ndata prediction by channelling crypto-money from prediction requests to useful\ndata and algorithms providers. Morpheo is designed to handle multiple data\nsources in a transfer learning approach in order to mutualize knowledge\nacquired from large datasets for applications with smaller but similar\ndatasets.\n", "versions": [{"version": "v1", "created": "Mon, 17 Apr 2017 16:24:29 GMT"}], "update_date": "2017-04-18", "authors_parsed": [["Galtier", "Mathieu", ""], ["Marini", "Camille", ""]]}, {"id": "1704.05136", "submitter": "Leopoldo Bertossi", "authors": "Leopoldo Bertossi", "title": "The Causality/Repair Connection in Databases: Causality-Programs", "comments": "To appear in Proc. SUM'17 as short paper, 7-pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, answer-set programs that specify repairs of databases are used\nas a basis for solving computational and reasoning problems about causes for\nquery answers from databases.\n", "versions": [{"version": "v1", "created": "Mon, 17 Apr 2017 21:58:45 GMT"}, {"version": "v2", "created": "Mon, 26 Jun 2017 17:05:39 GMT"}], "update_date": "2017-06-27", "authors_parsed": [["Bertossi", "Leopoldo", ""]]}, {"id": "1704.05295", "submitter": "S\\'ebastien Harispe", "authors": "S\\'ebastien Harispe, Sylvie Ranwez, Stefan Janaqi, Jacky Montmain", "title": "Semantic Similarity from Natural Language and Ontology Analysis", "comments": "preprint version of the book Semantic Similarity from Natural\n  Language and Ontology Analysis (Synthesis Lectures on Human Language\n  Technologies - Morgan & Claypool publishers)", "journal-ref": null, "doi": "10.2200/S00639ED1V01Y201504HLT027", "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Artificial Intelligence federates numerous scientific fields in the aim of\ndeveloping machines able to assist human operators performing complex\ntreatments -- most of which demand high cognitive skills (e.g. learning or\ndecision processes). Central to this quest is to give machines the ability to\nestimate the likeness or similarity between things in the way human beings\nestimate the similarity between stimuli.\n  In this context, this book focuses on semantic measures: approaches designed\nfor comparing semantic entities such as units of language, e.g. words,\nsentences, or concepts and instances defined into knowledge bases. The aim of\nthese measures is to assess the similarity or relatedness of such semantic\nentities by taking into account their semantics, i.e. their meaning --\nintuitively, the words tea and coffee, which both refer to stimulating\nbeverage, will be estimated to be more semantically similar than the words\ntoffee (confection) and coffee, despite that the last pair has a higher\nsyntactic similarity. The two state-of-the-art approaches for estimating and\nquantifying semantic similarities/relatedness of semantic entities are\npresented in detail: the first one relies on corpora analysis and is based on\nNatural Language Processing techniques and semantic models while the second is\nbased on more or less formal, computer-readable and workable forms of knowledge\nsuch as semantic networks, thesaurus or ontologies. (...) Beyond a simple\ninventory and categorization of existing measures, the aim of this monograph is\nto convey novices as well as researchers of these domains towards a better\nunderstanding of semantic similarity estimation and more generally semantic\nmeasures.\n", "versions": [{"version": "v1", "created": "Tue, 18 Apr 2017 12:24:26 GMT"}], "update_date": "2017-04-19", "authors_parsed": [["Harispe", "S\u00e9bastien", ""], ["Ranwez", "Sylvie", ""], ["Janaqi", "Stefan", ""], ["Montmain", "Jacky", ""]]}, {"id": "1704.05325", "submitter": "Pierre Parrend", "authors": "Fabio Guigou (ICube), Pierre Collet (ICube, UNISTRA), Pierre Parrend\n  (ICube)", "title": "Anomaly detection and motif discovery in symbolic representations of\n  time series", "comments": null, "journal-ref": null, "doi": "10.13140/RG.2.2.20158.69447", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The advent of the Big Data hype and the consistent recollection of event logs\nand real-time data from sensors, monitoring software and machine configuration\nhas generated a huge amount of time-varying data in about every sector of the\nindustry. Rule-based processing of such data has ceased to be relevant in many\nscenarios where anomaly detection and pattern mining have to be entirely\naccomplished by the machine. Since the early 2000s, the de-facto standard for\nrepresenting time series has been the Symbolic Aggregate approXimation (SAX).In\nthis document, we present a few algorithms using this representation for\nanomaly detection and motif discovery, also known as pattern mining, in such\ndata. We propose a benchmark of anomaly detection algorithms using data from\nCloud monitoring software.\n", "versions": [{"version": "v1", "created": "Tue, 18 Apr 2017 13:19:50 GMT"}], "update_date": "2017-04-19", "authors_parsed": [["Guigou", "Fabio", "", "ICube"], ["Collet", "Pierre", "", "ICube, UNISTRA"], ["Parrend", "Pierre", "", "ICube"]]}, {"id": "1704.05356", "submitter": "Nicolas Pr\\'ollochs", "authors": "Nicolas Pr\\\"ollochs, Stefan Feuerriegel, Dirk Neumann", "title": "Understanding Negations in Information Processing: Learning from\n  Replicating Human Behavior", "comments": "39 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Information systems experience an ever-growing volume of unstructured data,\nparticularly in the form of textual materials. This represents a rich source of\ninformation from which one can create value for people, organizations and\nbusinesses. For instance, recommender systems can benefit from automatically\nunderstanding preferences based on user reviews or social media. However, it is\ndifficult for computer programs to correctly infer meaning from narrative\ncontent. One major challenge is negations that invert the interpretation of\nwords and sentences. As a remedy, this paper proposes a novel learning strategy\nto detect negations: we apply reinforcement learning to find a policy that\nreplicates the human perception of negations based on an exogenous response,\nsuch as a user rating for reviews. Our method yields several benefits, as it\neliminates the former need for expensive and subjective manual labeling in an\nintermediate stage. Moreover, the inferred policy can be used to derive\nstatistical inferences and implications regarding how humans process and act on\nnegations.\n", "versions": [{"version": "v1", "created": "Tue, 18 Apr 2017 14:27:46 GMT"}], "update_date": "2017-04-19", "authors_parsed": [["Pr\u00f6llochs", "Nicolas", ""], ["Feuerriegel", "Stefan", ""], ["Neumann", "Dirk", ""]]}, {"id": "1704.05392", "submitter": "Dmitry Demidov", "authors": "Galina Rybina, Alexey Mozgachev, Dmitry Demidov", "title": "Synergy of all-purpose static solver and temporal reasoning tools in\n  dynamic integrated expert systems", "comments": "8 pages, 3 figures", "journal-ref": "\"Informatsionno-izmeritelnye i upravlyayushchie sistemy\"\n  (Information-measuring and Control Systems) no.8, vol.12, 2014. pp 27-33.\n  ISSN 2070-0814", "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper discusses scientific and technological problems of dynamic\nintegrated expert systems development. Extensions of problem-oriented\nmethodology for dynamic integrated expert systems development are considered.\nAttention is paid to the temporal knowledge representation and processing.\n", "versions": [{"version": "v1", "created": "Sun, 16 Apr 2017 21:50:23 GMT"}], "update_date": "2017-04-19", "authors_parsed": [["Rybina", "Galina", ""], ["Mozgachev", "Alexey", ""], ["Demidov", "Dmitry", ""]]}, {"id": "1704.05443", "submitter": "A. Mani", "authors": "A. Mani", "title": "Approximations from Anywhere and General Rough Sets", "comments": "20 Pages. Scheduled to appear in IJCRS'2017 LNCS Proceedings,\n  Springer", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.LO cs.AI cs.DM cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Not all approximations arise from information systems. The problem of fitting\napproximations, subjected to some rules (and related data), to information\nsystems in a rough scheme of things is known as the \\emph{inverse problem}. The\ninverse problem is more general than the duality (or abstract representation)\nproblems and was introduced by the present author in her earlier papers. From\nthe practical perspective, a few (as opposed to one) theoretical frameworks may\nbe suitable for formulating the problem itself. \\emph{Granular operator spaces}\nhave been recently introduced and investigated by the present author in her\nrecent work in the context of antichain based and dialectical semantics for\ngeneral rough sets. The nature of the inverse problem is examined from\nnumber-theoretic and combinatorial perspectives in a higher order variant of\ngranular operator spaces and some necessary conditions are proved. The results\nand the novel approach would be useful in a number of unsupervised and semi\nsupervised learning contexts and algorithms.\n", "versions": [{"version": "v1", "created": "Tue, 18 Apr 2017 17:46:58 GMT"}], "update_date": "2017-04-19", "authors_parsed": [["Mani", "A.", ""]]}, {"id": "1704.05477", "submitter": "Mani A", "authors": "A Mani", "title": "Generalized Ideals and Co-Granular Rough Sets", "comments": "20pages. Scheduled to appear in IJCRS'2017 Proceedings, LNCS,\n  Springer", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.LO cs.AI cs.IT cs.LO math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Lattice-theoretic ideals have been used to define and generate non granular\nrough approximations over general approximation spaces over the last few years\nby few authors. The goal of these studies, in relation based rough sets, have\nbeen to obtain nice properties comparable to those of classical rough\napproximations. In this research paper, these ideas are generalized in a severe\nway by the present author and associated semantic features are investigated by\nher. Granules are used in the construction of approximations in implicit ways\nand so a concept of co-granularity is introduced. Knowledge interpretation\nassociable with the approaches is also investigated. This research will be of\nrelevance for a number of logico-algebraic approaches to rough sets that\nproceed from point-wise definitions of approximations and also for using\nalternative approximations in spatial mereological contexts involving actual\ncontact relations. The antichain based semantics invented in earlier papers by\nthe present author also applies to the contexts considered.\n", "versions": [{"version": "v1", "created": "Tue, 18 Apr 2017 18:02:47 GMT"}], "update_date": "2017-04-20", "authors_parsed": [["Mani", "A", ""]]}, {"id": "1704.05495", "submitter": "Jean Harb", "authors": "Jean Harb and Doina Precup", "title": "Investigating Recurrence and Eligibility Traces in Deep Q-Networks", "comments": "8 pages, 3 figures, NIPS 2016 Deep Reinforcement Learning Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Eligibility traces in reinforcement learning are used as a bias-variance\ntrade-off and can often speed up training time by propagating knowledge back\nover time-steps in a single update. We investigate the use of eligibility\ntraces in combination with recurrent networks in the Atari domain. We\nillustrate the benefits of both recurrent nets and eligibility traces in some\nAtari games, and highlight also the importance of the optimization used in the\ntraining.\n", "versions": [{"version": "v1", "created": "Tue, 18 Apr 2017 18:46:12 GMT"}], "update_date": "2017-04-20", "authors_parsed": [["Harb", "Jean", ""], ["Precup", "Doina", ""]]}, {"id": "1704.05513", "submitter": "Pierre-Hadrien Arnoux", "authors": "Pierre-Hadrien Arnoux, Anbang Xu, Neil Boyette, Jalal Mahmud, Rama\n  Akkiraju, Vibha Sinha", "title": "25 Tweets to Know You: A New Model to Predict Personality with Social\n  Media", "comments": "Accepted as a short paper at ICWSM 2017. Please cite the ICWSM\n  version and not the ArXiv version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.AI cs.CL cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Predicting personality is essential for social applications supporting\nhuman-centered activities, yet prior modeling methods with users written text\nrequire too much input data to be realistically used in the context of social\nmedia. In this work, we aim to drastically reduce the data requirement for\npersonality modeling and develop a model that is applicable to most users on\nTwitter. Our model integrates Word Embedding features with Gaussian Processes\nregression. Based on the evaluation of over 1.3K users on Twitter, we find that\nour model achieves comparable or better accuracy than state of the art\ntechniques with 8 times fewer data.\n", "versions": [{"version": "v1", "created": "Tue, 18 Apr 2017 20:16:31 GMT"}], "update_date": "2017-04-20", "authors_parsed": [["Arnoux", "Pierre-Hadrien", ""], ["Xu", "Anbang", ""], ["Boyette", "Neil", ""], ["Mahmud", "Jalal", ""], ["Akkiraju", "Rama", ""], ["Sinha", "Vibha", ""]]}, {"id": "1704.05539", "submitter": "Russell Kaplan", "authors": "Russell Kaplan, Christopher Sauer, Alexander Sosa", "title": "Beating Atari with Natural Language Guided Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce the first deep reinforcement learning agent that learns to beat\nAtari games with the aid of natural language instructions. The agent uses a\nmultimodal embedding between environment observations and natural language to\nself-monitor progress through a list of English instructions, granting itself\nreward for completing instructions in addition to increasing the game score.\nOur agent significantly outperforms Deep Q-Networks (DQNs), Asynchronous\nAdvantage Actor-Critic (A3C) agents, and the best agents posted to OpenAI Gym\non what is often considered the hardest Atari 2600 environment: Montezuma's\nRevenge.\n", "versions": [{"version": "v1", "created": "Tue, 18 Apr 2017 21:31:29 GMT"}], "update_date": "2017-04-20", "authors_parsed": [["Kaplan", "Russell", ""], ["Sauer", "Christopher", ""], ["Sosa", "Alexander", ""]]}, {"id": "1704.05543", "submitter": "Sreecharan Sankaranarayanan", "authors": "Gaurav Singh Tomar, Sreecharan Sankaranarayanan, Xu Wang and Carolyn\n  Penstein Ros\\'e", "title": "Coordinating Collaborative Chat in Massive Open Online Courses", "comments": "8 pages", "journal-ref": "Proceedings of the International Conference of the Learning\n  Sciences 2016, Volume 1, pp 607-614", "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.CL cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An earlier study of a collaborative chat intervention in a Massive Open\nOnline Course (MOOC) identified negative effects on attrition stemming from a\nrequirement for students to be matched with exactly one partner prior to\nbeginning the activity. That study raised questions about how to orchestrate a\ncollaborative chat intervention in a MOOC context in order to provide the\nbenefit of synchronous social engagement without the coordination difficulties.\nIn this paper we present a careful analysis of an intervention designed to\novercome coordination difficulties by welcoming students into the chat on a\nrolling basis as they arrive rather than requiring them to be matched with a\npartner before beginning. The results suggest the most positive impact when\nexperiencing a chat with exactly one partner rather than more or less. A\nqualitative analysis of the chat data reveals differential experiences between\nthese configurations that suggests a potential explanation for the effect and\nraises questions for future research.\n", "versions": [{"version": "v1", "created": "Tue, 18 Apr 2017 21:57:10 GMT"}], "update_date": "2021-07-02", "authors_parsed": [["Tomar", "Gaurav Singh", ""], ["Sankaranarayanan", "Sreecharan", ""], ["Wang", "Xu", ""], ["Ros\u00e9", "Carolyn Penstein", ""]]}, {"id": "1704.05566", "submitter": "Jeremy Morton", "authors": "Jeremy Morton and Mykel J. Kochenderfer", "title": "Simultaneous Policy Learning and Latent State Inference for Imitating\n  Driver Behavior", "comments": "7 pages, 6 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we propose a method for learning driver models that account for\nvariables that cannot be observed directly. When trained on a synthetic\ndataset, our models are able to learn encodings for vehicle trajectories that\ndistinguish between four distinct classes of driver behavior. Such encodings\nare learned without any knowledge of the number of driver classes or any\nobjective that directly requires the models to learn encodings for each class.\nWe show that driving policies trained with knowledge of latent variables are\nmore effective than baseline methods at imitating the driver behavior that they\nare trained to replicate. Furthermore, we demonstrate that the actions chosen\nby our policy are heavily influenced by the latent variable settings that are\nprovided to them.\n", "versions": [{"version": "v1", "created": "Wed, 19 Apr 2017 00:23:59 GMT"}], "update_date": "2017-04-20", "authors_parsed": [["Morton", "Jeremy", ""], ["Kochenderfer", "Mykel J.", ""]]}, {"id": "1704.05569", "submitter": "Mayank Kejriwal", "authors": "Rahul Kapoor, Mayank Kejriwal and Pedro Szekely", "title": "Using Contexts and Constraints for Improved Geotagging of Human\n  Trafficking Webpages", "comments": "6 pages, GeoRich 2017 workshop at ACM SIGMOD conference", "journal-ref": null, "doi": "10.1145/3080546.3080547", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Extracting geographical tags from webpages is a well-motivated application in\nmany domains. In illicit domains with unusual language models, like human\ntrafficking, extracting geotags with both high precision and recall is a\nchallenging problem. In this paper, we describe a geotag extraction framework\nin which context, constraints and the openly available Geonames knowledge base\nwork in tandem in an Integer Linear Programming (ILP) model to achieve good\nperformance. In preliminary empirical investigations, the framework improves\nprecision by 28.57% and F-measure by 36.9% on a difficult human trafficking\ngeotagging task compared to a machine learning-based baseline. The method is\nalready being integrated into an existing knowledge base construction system\nwidely used by US law enforcement agencies to combat human trafficking.\n", "versions": [{"version": "v1", "created": "Wed, 19 Apr 2017 00:52:02 GMT"}], "update_date": "2017-04-20", "authors_parsed": [["Kapoor", "Rahul", ""], ["Kejriwal", "Mayank", ""], ["Szekely", "Pedro", ""]]}, {"id": "1704.05572", "submitter": "Tushar Khot", "authors": "Tushar Khot and Ashish Sabharwal and Peter Clark", "title": "Answering Complex Questions Using Open Information Extraction", "comments": "Accepted as short paper at ACL 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While there has been substantial progress in factoid question-answering (QA),\nanswering complex questions remains challenging, typically requiring both a\nlarge body of knowledge and inference techniques. Open Information Extraction\n(Open IE) provides a way to generate semi-structured knowledge for QA, but to\ndate such knowledge has only been used to answer simple questions with\nretrieval-based methods. We overcome this limitation by presenting a method for\nreasoning with Open IE knowledge, allowing more complex questions to be\nhandled. Using a recently proposed support graph optimization framework for QA,\nwe develop a new inference model for Open IE, in particular one that can work\neffectively with multiple short facts, noise, and the relational structure of\ntuples. Our model significantly outperforms a state-of-the-art structured\nsolver on complex questions of varying difficulty, while also removing the\nreliance on manually curated knowledge.\n", "versions": [{"version": "v1", "created": "Wed, 19 Apr 2017 01:07:56 GMT"}], "update_date": "2017-04-20", "authors_parsed": [["Khot", "Tushar", ""], ["Sabharwal", "Ashish", ""], ["Clark", "Peter", ""]]}, {"id": "1704.05579", "submitter": "Mikhail Khodak", "authors": "Mikhail Khodak, Nikunj Saunshi and Kiran Vodrahalli", "title": "A Large Self-Annotated Corpus for Sarcasm", "comments": "6 pages, 4 Figures. To Appear in LREC 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce the Self-Annotated Reddit Corpus (SARC), a large corpus for\nsarcasm research and for training and evaluating systems for sarcasm detection.\nThe corpus has 1.3 million sarcastic statements -- 10 times more than any\nprevious dataset -- and many times more instances of non-sarcastic statements,\nallowing for learning in both balanced and unbalanced label regimes. Each\nstatement is furthermore self-annotated -- sarcasm is labeled by the author,\nnot an independent annotator -- and provided with user, topic, and conversation\ncontext. We evaluate the corpus for accuracy, construct benchmarks for sarcasm\ndetection, and evaluate baseline methods.\n", "versions": [{"version": "v1", "created": "Wed, 19 Apr 2017 02:01:39 GMT"}, {"version": "v2", "created": "Fri, 21 Apr 2017 01:25:08 GMT"}, {"version": "v3", "created": "Fri, 6 Oct 2017 03:09:01 GMT"}, {"version": "v4", "created": "Thu, 22 Mar 2018 22:23:10 GMT"}], "update_date": "2018-03-26", "authors_parsed": [["Khodak", "Mikhail", ""], ["Saunshi", "Nikunj", ""], ["Vodrahalli", "Kiran", ""]]}, {"id": "1704.05591", "submitter": "Hamed Sadeghi", "authors": "Hamed Sadeghi, Shahrokh Valaee and Shahram Shirani", "title": "OCRAPOSE II: An OCR-based indoor positioning system using mobile phone\n  images", "comments": "14 pages, 22 Figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose an OCR (optical character recognition)-based\nlocalization system called OCRAPOSE II, which is applicable in a number of\nindoor scenarios including office buildings, parkings, airports, grocery\nstores, etc. In these scenarios, characters (i.e. texts or numbers) can be used\nas suitable distinctive landmarks for localization. The proposed system takes\nadvantage of OCR to read these characters in the query still images and\nprovides a rough location estimate using a floor plan. Then, it finds depth and\nangle-of-view of the query using the information provided by the OCR engine in\norder to refine the location estimate. We derive novel formulas for the query\nangle-of-view and depth estimation using image line segments and the OCR box\ninformation. We demonstrate the applicability and effectiveness of the proposed\nsystem through experiments in indoor scenarios. It is shown that our system\ndemonstrates better performance compared to the state-of-the-art benchmarks in\nterms of location recognition rate and average localization error specially\nunder sparse database condition.\n", "versions": [{"version": "v1", "created": "Wed, 19 Apr 2017 02:43:23 GMT"}], "update_date": "2017-04-20", "authors_parsed": [["Sadeghi", "Hamed", ""], ["Valaee", "Shahrokh", ""], ["Shirani", "Shahram", ""]]}, {"id": "1704.05692", "submitter": "Thierry Van Der Spek", "authors": "Thierry van der Spek", "title": "A multi-method simulation of a high-frequency bus line using AnyLogic", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work a mixed agent-based and discrete event simulation model is\ndeveloped for a high frequency bus route in the Netherlands. With this model,\ndifferent passenger growth scenarios can be easily evaluated. This simulation\nmodel helps policy makers to predict changes that have to be made to bus routes\nand planned travel times before problems occur. The model is validated using\nseveral performance indicators, showing that under some model assumptions, it\ncan realistically simulate real-life situations. The simulation's workings are\nillustrated by two use cases.\n", "versions": [{"version": "v1", "created": "Wed, 19 Apr 2017 11:17:30 GMT"}], "update_date": "2017-04-20", "authors_parsed": [["van der Spek", "Thierry", ""]]}, {"id": "1704.05712", "submitter": "Jan Hendrik Metzen", "authors": "Jan Hendrik Metzen, Mummadi Chaithanya Kumar, Thomas Brox, Volker\n  Fischer", "title": "Universal Adversarial Perturbations Against Semantic Image Segmentation", "comments": "Final version for ICCV including supplementary material", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While deep learning is remarkably successful on perceptual tasks, it was also\nshown to be vulnerable to adversarial perturbations of the input. These\nperturbations denote noise added to the input that was generated specifically\nto fool the system while being quasi-imperceptible for humans. More severely,\nthere even exist universal perturbations that are input-agnostic but fool the\nnetwork on the majority of inputs. While recent work has focused on image\nclassification, this work proposes attacks against semantic image segmentation:\nwe present an approach for generating (universal) adversarial perturbations\nthat make the network yield a desired target segmentation as output. We show\nempirically that there exist barely perceptible universal noise patterns which\nresult in nearly the same predicted segmentation for arbitrary inputs.\nFurthermore, we also show the existence of universal noise which removes a\ntarget class (e.g., all pedestrians) from the segmentation while leaving the\nsegmentation mostly unchanged otherwise.\n", "versions": [{"version": "v1", "created": "Wed, 19 Apr 2017 12:48:52 GMT"}, {"version": "v2", "created": "Fri, 28 Jul 2017 08:35:25 GMT"}, {"version": "v3", "created": "Mon, 31 Jul 2017 18:55:54 GMT"}], "update_date": "2017-08-02", "authors_parsed": [["Metzen", "Jan Hendrik", ""], ["Kumar", "Mummadi Chaithanya", ""], ["Brox", "Thomas", ""], ["Fischer", "Volker", ""]]}, {"id": "1704.05796", "submitter": "David Bau", "authors": "David Bau, Bolei Zhou, Aditya Khosla, Aude Oliva, and Antonio Torralba", "title": "Network Dissection: Quantifying Interpretability of Deep Visual\n  Representations", "comments": "First two authors contributed equally. Oral presentation at CVPR 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a general framework called Network Dissection for quantifying the\ninterpretability of latent representations of CNNs by evaluating the alignment\nbetween individual hidden units and a set of semantic concepts. Given any CNN\nmodel, the proposed method draws on a broad data set of visual concepts to\nscore the semantics of hidden units at each intermediate convolutional layer.\nThe units with semantics are given labels across a range of objects, parts,\nscenes, textures, materials, and colors. We use the proposed method to test the\nhypothesis that interpretability of units is equivalent to random linear\ncombinations of units, then we apply our method to compare the latent\nrepresentations of various networks when trained to solve different supervised\nand self-supervised training tasks. We further analyze the effect of training\niterations, compare networks trained with different initializations, examine\nthe impact of network depth and width, and measure the effect of dropout and\nbatch normalization on the interpretability of deep visual representations. We\ndemonstrate that the proposed method can shed light on characteristics of CNN\nmodels and training methods that go beyond measurements of their discriminative\npower.\n", "versions": [{"version": "v1", "created": "Wed, 19 Apr 2017 16:10:38 GMT"}], "update_date": "2017-04-20", "authors_parsed": [["Bau", "David", ""], ["Zhou", "Bolei", ""], ["Khosla", "Aditya", ""], ["Oliva", "Aude", ""], ["Torralba", "Antonio", ""]]}, {"id": "1704.05904", "submitter": "Utku Kose", "authors": "Utku Kose, Ahmet Arslan", "title": "Realizing an optimization approach inspired from Piagets theory on\n  cognitive development", "comments": "8 pages, 1 figure, 2 tables", "journal-ref": "Broad Research in Artificial Intelligence and Neuroscience,\n  6(1-4), 2015, 15-22", "doi": null, "report-no": null, "categories": "cs.AI math.OC", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  The objective of this paper is to introduce an artificial intelligence based\noptimization approach, which is inspired from Piagets theory on cognitive\ndevelopment. The approach has been designed according to essential processes\nthat an individual may experience while learning something new or improving his\n/ her knowledge. These processes are associated with the Piagets ideas on an\nindividuals cognitive development. The approach expressed in this paper is a\nsimple algorithm employing swarm intelligence oriented tasks in order to\novercome single-objective optimization problems. For evaluating effectiveness\nof this early version of the algorithm, test operations have been done via some\nbenchmark functions. The obtained results show that the approach / algorithm\ncan be an alternative to the literature in terms of single-objective\noptimization. The authors have suggested the name: Cognitive Development\nOptimization Algorithm (CoDOA) for the related intelligent optimization\napproach.\n", "versions": [{"version": "v1", "created": "Mon, 3 Apr 2017 20:28:05 GMT"}], "update_date": "2017-04-21", "authors_parsed": [["Kose", "Utku", ""], ["Arslan", "Ahmet", ""]]}, {"id": "1704.05908", "submitter": "Qizhe Xie", "authors": "Qizhe Xie, Xuezhe Ma, Zihang Dai, Eduard Hovy", "title": "An Interpretable Knowledge Transfer Model for Knowledge Base Completion", "comments": "Accepted by ACL 2017. Minor update", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge bases are important resources for a variety of natural language\nprocessing tasks but suffer from incompleteness. We propose a novel embedding\nmodel, \\emph{ITransF}, to perform knowledge base completion. Equipped with a\nsparse attention mechanism, ITransF discovers hidden concepts of relations and\ntransfer statistical strength through the sharing of concepts. Moreover, the\nlearned associations between relations and concepts, which are represented by\nsparse attention vectors, can be interpreted easily. We evaluate ITransF on two\nbenchmark datasets---WN18 and FB15k for knowledge base completion and obtains\nimprovements on both the mean rank and Hits@10 metrics, over all baselines that\ndo not use additional information.\n", "versions": [{"version": "v1", "created": "Wed, 19 Apr 2017 19:35:54 GMT"}, {"version": "v2", "created": "Wed, 3 May 2017 05:20:09 GMT"}], "update_date": "2017-05-04", "authors_parsed": [["Xie", "Qizhe", ""], ["Ma", "Xuezhe", ""], ["Dai", "Zihang", ""], ["Hovy", "Eduard", ""]]}, {"id": "1704.05915", "submitter": "Yuri G. Gordienko", "authors": "S. Stirenko, Yu. Gordienko, T. Shemsedinov, O. Alienin, Yu. Kochura,\n  N. Gordienko, A. Rojbi, J.R. L\\'opez Benito, E. Artetxe Gonz\\'alez", "title": "User-driven Intelligent Interface on the Basis of Multimodal Augmented\n  Reality and Brain-Computer Interaction for People with Functional\n  Disabilities", "comments": "10 pages, 11 figures, 1 table, submitted to Future of Information and\n  Communication Conference (FICC) 2018, 5-6 April 2018, Singapore", "journal-ref": "In: Arai K., Kapoor S., Bhatia R. (eds) Advances in Information\n  and Communication Networks. FICC 2018. Advances in Intelligent Systems and\n  Computing, vol 886, pp.612-631. Springer, Cham", "doi": "10.1007/978-3-030-03402-3_43", "report-no": null, "categories": "cs.HC cs.AI cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The analysis of the current integration attempts of some modes and use cases\nof user-machine interaction is presented. The new concept of the user-driven\nintelligent interface is proposed on the basis of multimodal augmented reality\nand brain-computer interaction for various applications: in disabilities\nstudies, education, home care, health care, etc. The several use cases of\nmultimodal augmentation are presented. The perspectives of the better human\ncomprehension by the immediate feedback through neurophysical channels by means\nof brain-computer interaction are outlined. It is shown that brain-computer\ninterface (BCI) technology provides new strategies to overcome limits of the\ncurrently available user interfaces, especially for people with functional\ndisabilities. The results of the previous studies of the low end consumer and\nopen-source BCI-devices allow us to conclude that combination of machine\nlearning (ML), multimodal interactions (visual, sound, tactile) with BCI will\nprofit from the immediate feedback from the actual neurophysical reactions\nclassified by ML methods. In general, BCI in combination with other modes of AR\ninteraction can deliver much more information than these types of interaction\nthemselves. Even in the current state the combined AR-BCI interfaces could\nprovide the highly adaptable and personal services, especially for people with\nfunctional disabilities.\n", "versions": [{"version": "v1", "created": "Wed, 12 Apr 2017 21:03:52 GMT"}, {"version": "v2", "created": "Tue, 15 Aug 2017 22:51:53 GMT"}], "update_date": "2018-12-11", "authors_parsed": [["Stirenko", "S.", ""], ["Gordienko", "Yu.", ""], ["Shemsedinov", "T.", ""], ["Alienin", "O.", ""], ["Kochura", "Yu.", ""], ["Gordienko", "N.", ""], ["Rojbi", "A.", ""], ["Benito", "J. R. L\u00f3pez", ""], ["Gonz\u00e1lez", "E. Artetxe", ""]]}, {"id": "1704.05963", "submitter": "Daniel R. Jiang", "authors": "Daniel R. Jiang, Lina Al-Kanj, Warren B. Powell", "title": "Monte Carlo Tree Search with Sampled Information Relaxation Dual Bounds", "comments": "33 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Monte Carlo Tree Search (MCTS), most famously used in game-play artificial\nintelligence (e.g., the game of Go), is a well-known strategy for constructing\napproximate solutions to sequential decision problems. Its primary innovation\nis the use of a heuristic, known as a default policy, to obtain Monte Carlo\nestimates of downstream values for states in a decision tree. This information\nis used to iteratively expand the tree towards regions of states and actions\nthat an optimal policy might visit. However, to guarantee convergence to the\noptimal action, MCTS requires the entire tree to be expanded asymptotically. In\nthis paper, we propose a new technique called Primal-Dual MCTS that utilizes\nsampled information relaxation upper bounds on potential actions, creating the\npossibility of \"ignoring\" parts of the tree that stem from highly suboptimal\nchoices. This allows us to prove that despite converging to a partial decision\ntree in the limit, the recommended action from Primal-Dual MCTS is optimal. The\nnew approach shows significant promise when used to optimize the behavior of a\nsingle driver navigating a graph while operating on a ride-sharing platform.\nNumerical experiments on a real dataset of 7,000 trips in New Jersey suggest\nthat Primal-Dual MCTS improves upon standard MCTS by producing deeper decision\ntrees and exhibits a reduced sensitivity to the size of the action space.\n", "versions": [{"version": "v1", "created": "Thu, 20 Apr 2017 00:16:01 GMT"}], "update_date": "2017-04-21", "authors_parsed": [["Jiang", "Daniel R.", ""], ["Al-Kanj", "Lina", ""], ["Powell", "Warren B.", ""]]}, {"id": "1704.05972", "submitter": "Leon Derczynski", "authors": "Leon Derczynski and Kalina Bontcheva and Maria Liakata and Rob Procter\n  and Geraldine Wong Sak Hoi and Arkaitz Zubiaga", "title": "SemEval-2017 Task 8: RumourEval: Determining rumour veracity and support\n  for rumours", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Media is full of false claims. Even Oxford Dictionaries named \"post-truth\" as\nthe word of 2016. This makes it more important than ever to build systems that\ncan identify the veracity of a story, and the kind of discourse there is around\nit. RumourEval is a SemEval shared task that aims to identify and handle\nrumours and reactions to them, in text. We present an annotation scheme, a\nlarge dataset covering multiple topics - each having their own families of\nclaims and replies - and use these to pose two concrete challenges as well as\nthe results achieved by participants on these challenges.\n", "versions": [{"version": "v1", "created": "Thu, 20 Apr 2017 01:21:20 GMT"}], "update_date": "2017-04-21", "authors_parsed": [["Derczynski", "Leon", ""], ["Bontcheva", "Kalina", ""], ["Liakata", "Maria", ""], ["Procter", "Rob", ""], ["Hoi", "Geraldine Wong Sak", ""], ["Zubiaga", "Arkaitz", ""]]}, {"id": "1704.06033", "submitter": "Hongyoon Choi Dr", "authors": "Hongyoon Choi, Kyong Hwan Jin", "title": "Predicting Cognitive Decline with Deep Learning of Brain Metabolism and\n  Amyloid Imaging", "comments": "24 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For effective treatment of Alzheimer disease (AD), it is important to\nidentify subjects who are most likely to exhibit rapid cognitive decline.\nHerein, we developed a novel framework based on a deep convolutional neural\nnetwork which can predict future cognitive decline in mild cognitive impairment\n(MCI) patients using flurodeoxyglucose and florbetapir positron emission\ntomography (PET). The architecture of the network only relies on baseline PET\nstudies of AD and normal subjects as the training dataset. Feature extraction\nand complicated image preprocessing including nonlinear warping are unnecessary\nfor our approach. Accuracy of prediction (84.2%) for conversion to AD in MCI\npatients outperformed conventional feature-based quantification approaches. ROC\nanalyses revealed that performance of CNN-based approach was significantly\nhigher than that of the conventional quantification methods (p < 0.05). Output\nscores of the network were strongly correlated with the longitudinal change in\ncognitive measurements. These results show the feasibility of deep learning as\na tool for predicting disease outcome using brain images.\n", "versions": [{"version": "v1", "created": "Thu, 20 Apr 2017 07:33:18 GMT"}], "update_date": "2017-04-21", "authors_parsed": [["Choi", "Hongyoon", ""], ["Jin", "Kyong Hwan", ""]]}, {"id": "1704.06084", "submitter": "Steffen Thoma", "authors": "Steffen Thoma, Achim Rettinger, Fabian Both", "title": "Knowledge Fusion via Embeddings from Text, Knowledge Graphs, and Images", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a baseline approach for cross-modal knowledge fusion. Different\nbasic fusion methods are evaluated on existing embedding approaches to show the\npotential of joining knowledge about certain concepts across modalities in a\nfused concept representation.\n", "versions": [{"version": "v1", "created": "Thu, 20 Apr 2017 10:49:51 GMT"}], "update_date": "2017-04-21", "authors_parsed": [["Thoma", "Steffen", ""], ["Rettinger", "Achim", ""], ["Both", "Fabian", ""]]}, {"id": "1704.06096", "submitter": "Amos Korman", "authors": "Amos Korman (GANG, IRIF), Yoav Rodeh", "title": "The Dependent Doors Problem: An Investigation into Sequential Decisions\n  without Feedback", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce the dependent doors problem as an abstraction for situations in\nwhich one must perform a sequence of possibly dependent decisions, without\nreceiving feedback information on the effectiveness of previously made actions.\nInformally, the problem considers a set of $d$ doors that are initially closed,\nand the aim is to open all of them as fast as possible. To open a door, the\nalgorithm knocks on it and it might open or not according to some probability\ndistribution. This distribution may depend on which other doors are currently\nopen, as well as on which other doors were open during each of the previous\nknocks on that door. The algorithm aims to minimize the expected time until all\ndoors open. Crucially, it must act at any time without knowing whether or which\nother doors have already opened. In this work, we focus on scenarios where\ndependencies between doors are both positively correlated and acyclic.The\nfundamental distribution of a door describes the probability it opens in the\nbest of conditions (with respect to other doors being open or closed). We show\nthat if in two configurations of $d$ doors corresponding doors share the same\nfundamental distribution, then these configurations have the same optimal\nrunning time up to a universal constant, no matter what are the dependencies\nbetween doors and what are the distributions. We also identify algorithms that\nare optimal up to a universal constant factor. For the case in which all doors\nshare the same fundamental distribution we additionally provide a simpler\nalgorithm, and a formula to calculate its running time. We furthermore analyse\nthe price of lacking feedback for several configurations governed by standard\nfundamental distributions. In particular, we show that the price is logarithmic\nin $d$ for memoryless doors, but can potentially grow to be linear in $d$ for\nother distributions.We then turn our attention to investigate precise bounds.\nEven for the case of two doors, identifying the optimal sequence is an\nintriguing combinatorial question. Here, we study the case of two cascading\nmemoryless doors. That is, the first door opens on each knock independently\nwith probability $p\\_1$. The second door can only open if the first door is\nopen, in which case it will open on each knock independently with probability\n$p\\_2$. We solve this problem almost completely by identifying algorithms that\nare optimal up to an additive term of 1.\n", "versions": [{"version": "v1", "created": "Thu, 20 Apr 2017 11:35:44 GMT"}], "update_date": "2017-04-21", "authors_parsed": [["Korman", "Amos", "", "GANG, IRIF"], ["Rodeh", "Yoav", ""]]}, {"id": "1704.06131", "submitter": "Yewen Pu", "authors": "Yewen Pu, Leslie P Kaelbling, Armando Solar-Lezama", "title": "Learning to Acquire Information", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of diagnosis where a set of simple observations are\nused to infer a potentially complex hidden hypothesis. Finding the optimal\nsubset of observations is intractable in general, thus we focus on the problem\nof active diagnosis, where the agent selects the next most-informative\nobservation based on the results of previous observations. We show that under\nthe assumption of uniform observation entropy, one can build an implication\nmodel which directly predicts the outcome of the potential next observation\nconditioned on the results of past observations, and selects the observation\nwith the maximum entropy. This approach enjoys reduced computation complexity\nby bypassing the complicated hypothesis space, and can be trained on\nobservation data alone, learning how to query without knowledge of the hidden\nhypothesis.\n", "versions": [{"version": "v1", "created": "Thu, 20 Apr 2017 13:28:02 GMT"}, {"version": "v2", "created": "Tue, 11 Jul 2017 12:58:45 GMT"}], "update_date": "2017-07-12", "authors_parsed": [["Pu", "Yewen", ""], ["Kaelbling", "Leslie P", ""], ["Solar-Lezama", "Armando", ""]]}, {"id": "1704.06193", "submitter": "Andres Gomez Ramirez", "authors": "Andres Gomez, Camilo Lara, Udo Kebschull (for the ALICE Collaboration)", "title": "Intrusion Prevention and Detection in Grid Computing - The ALICE Case", "comments": "Journal of Physics: Conference Series, Volume 664", "journal-ref": "J. Phys.: Conf. Ser. 664 062017 (2015)", "doi": "10.1088/1742-6596/664/6/062017", "report-no": null, "categories": "cs.DC cs.AI cs.CR hep-ex", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Grids allow users flexible on-demand usage of computing resources through\nremote communication networks. A remarkable example of a Grid in High Energy\nPhysics (HEP) research is used in the ALICE experiment at European Organization\nfor Nuclear Research CERN. Physicists can submit jobs used to process the huge\namount of particle collision data produced by the Large Hadron Collider (LHC).\nGrids face complex security challenges. They are interesting targets for\nattackers seeking for huge computational resources. Since users can execute\narbitrary code in the worker nodes on the Grid sites, special care should be\nput in this environment. Automatic tools to harden and monitor this scenario\nare required. Currently, there is no integrated solution for such requirement.\nThis paper describes a new security framework to allow execution of job\npayloads in a sandboxed context. It also allows process behavior monitoring to\ndetect intrusions, even when new attack methods or zero day vulnerabilities are\nexploited, by a Machine Learning approach. We plan to implement the proposed\nframework as a software prototype that will be tested as a component of the\nALICE Grid middleware.\n", "versions": [{"version": "v1", "created": "Thu, 20 Apr 2017 15:47:44 GMT"}], "update_date": "2017-04-21", "authors_parsed": [["Gomez", "Andres", "", "for the ALICE Collaboration"], ["Lara", "Camilo", "", "for the ALICE Collaboration"], ["Kebschull", "Udo", "", "for the ALICE Collaboration"]]}, {"id": "1704.06194", "submitter": "Mo Yu", "authors": "Mo Yu, Wenpeng Yin, Kazi Saidul Hasan, Cicero dos Santos, Bing Xiang,\n  Bowen Zhou", "title": "Improved Neural Relation Detection for Knowledge Base Question Answering", "comments": "Accepted by ACL 2017 (updated for camera-ready)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Relation detection is a core component for many NLP applications including\nKnowledge Base Question Answering (KBQA). In this paper, we propose a\nhierarchical recurrent neural network enhanced by residual learning that\ndetects KB relations given an input question. Our method uses deep residual\nbidirectional LSTMs to compare questions and relation names via different\nhierarchies of abstraction. Additionally, we propose a simple KBQA system that\nintegrates entity linking and our proposed relation detector to enable one\nenhance another. Experimental results evidence that our approach achieves not\nonly outstanding relation detection performance, but more importantly, it helps\nour KBQA system to achieve state-of-the-art accuracy for both single-relation\n(SimpleQuestions) and multi-relation (WebQSP) QA benchmarks.\n", "versions": [{"version": "v1", "created": "Thu, 20 Apr 2017 15:48:05 GMT"}, {"version": "v2", "created": "Sat, 27 May 2017 17:45:35 GMT"}], "update_date": "2017-05-30", "authors_parsed": [["Yu", "Mo", ""], ["Yin", "Wenpeng", ""], ["Hasan", "Kazi Saidul", ""], ["Santos", "Cicero dos", ""], ["Xiang", "Bing", ""], ["Zhou", "Bowen", ""]]}, {"id": "1704.06215", "submitter": "Stanislav Zivny", "authors": "Clement Carbonnel and David A. Cohen and Martin C. Cooper and\n  Stanislav Zivny", "title": "On Singleton Arc Consistency for CSPs Defined by Monotone Patterns", "comments": "v4: Full version of a STACS'18 paper; improved presentation", "journal-ref": "Algorithmica 81(4) 1699-1727 (2019)", "doi": "10.1007/s00453-018-0498-2", "report-no": null, "categories": "cs.CC cs.AI cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Singleton arc consistency is an important type of local consistency which has\nbeen recently shown to solve all constraint satisfaction problems (CSPs) over\nconstraint languages of bounded width. We aim to characterise all classes of\nCSPs defined by a forbidden pattern that are solved by singleton arc\nconsistency and closed under removing constraints. We identify five new\npatterns whose absence ensures solvability by singleton arc consistency, four\nof which are provably maximal and three of which generalise 2-SAT. Combined\nwith simple counter-examples for other patterns, we make significant progress\ntowards a complete classification.\n", "versions": [{"version": "v1", "created": "Thu, 20 Apr 2017 16:29:21 GMT"}, {"version": "v2", "created": "Fri, 21 Apr 2017 20:10:25 GMT"}, {"version": "v3", "created": "Fri, 22 Dec 2017 18:00:57 GMT"}, {"version": "v4", "created": "Fri, 10 Aug 2018 08:31:10 GMT"}], "update_date": "2019-06-28", "authors_parsed": [["Carbonnel", "Clement", ""], ["Cohen", "David A.", ""], ["Cooper", "Martin C.", ""], ["Zivny", "Stanislav", ""]]}, {"id": "1704.06259", "submitter": "Ping Chen Dr.", "authors": "Ping Chen, Fei Wu, Tong Wang, Wei Ding", "title": "A Semantic QA-Based Approach for Text Summarization Evaluation", "comments": null, "journal-ref": "AAAI 2018", "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many Natural Language Processing and Computational Linguistics applications\ninvolves the generation of new texts based on some existing texts, such as\nsummarization, text simplification and machine translation. However, there has\nbeen a serious problem haunting these applications for decades, that is, how to\nautomatically and accurately assess quality of these applications. In this\npaper, we will present some preliminary results on one especially useful and\nchallenging problem in NLP system evaluation: how to pinpoint content\ndifferences of two text passages (especially for large pas-sages such as\narticles and books). Our idea is intuitive and very different from existing\napproaches. We treat one text passage as a small knowledge base, and ask it a\nlarge number of questions to exhaustively identify all content points in it. By\ncomparing the correctly answered questions from two text passages, we will be\nable to compare their content precisely. The experiment using 2007 DUC\nsummarization corpus clearly shows promising results.\n", "versions": [{"version": "v1", "created": "Fri, 21 Apr 2017 15:32:01 GMT"}, {"version": "v2", "created": "Wed, 11 Apr 2018 00:34:01 GMT"}], "update_date": "2018-04-12", "authors_parsed": [["Chen", "Ping", ""], ["Wu", "Fei", ""], ["Wang", "Tong", ""], ["Ding", "Wei", ""]]}, {"id": "1704.06300", "submitter": "Niranjani Prasad", "authors": "Niranjani Prasad, Li-Fang Cheng, Corey Chivers, Michael Draugelis,\n  Barbara E Engelhardt", "title": "A Reinforcement Learning Approach to Weaning of Mechanical Ventilation\n  in Intensive Care Units", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The management of invasive mechanical ventilation, and the regulation of\nsedation and analgesia during ventilation, constitutes a major part of the care\nof patients admitted to intensive care units. Both prolonged dependence on\nmechanical ventilation and premature extubation are associated with increased\nrisk of complications and higher hospital costs, but clinical opinion on the\nbest protocol for weaning patients off of a ventilator varies. This work aims\nto develop a decision support tool that uses available patient information to\npredict time-to-extubation readiness and to recommend a personalized regime of\nsedation dosage and ventilator support. To this end, we use off-policy\nreinforcement learning algorithms to determine the best action at a given\npatient state from sub-optimal historical ICU data. We compare treatment\npolicies from fitted Q-iteration with extremely randomized trees and with\nfeedforward neural networks, and demonstrate that the policies learnt show\npromise in recommending weaning protocols with improved outcomes, in terms of\nminimizing rates of reintubation and regulating physiological stability.\n", "versions": [{"version": "v1", "created": "Thu, 20 Apr 2017 18:53:51 GMT"}], "update_date": "2017-04-24", "authors_parsed": [["Prasad", "Niranjani", ""], ["Cheng", "Li-Fang", ""], ["Chivers", "Corey", ""], ["Draugelis", "Michael", ""], ["Engelhardt", "Barbara E", ""]]}, {"id": "1704.06498", "submitter": "Benjamin Paassen", "authors": "Benjamin Paa{\\ss}en and Christina G\\\"opfert and Barbara Hammer", "title": "Time Series Prediction for Graphs in Kernel and Dissimilarity Spaces", "comments": "preprint of a submission to 'Neural Processing Letters' (Special\n  issue 'Off the mainstream')", "journal-ref": "Neural Processing Letters 48 (2018) 669-689", "doi": "10.1007/s11063-017-9684-5", "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph models are relevant in many fields, such as distributed computing,\nintelligent tutoring systems or social network analysis. In many cases, such\nmodels need to take changes in the graph structure into account, i.e. a varying\nnumber of nodes or edges. Predicting such changes within graphs can be expected\nto yield important insight with respect to the underlying dynamics, e.g. with\nrespect to user behaviour. However, predictive techniques in the past have\nalmost exclusively focused on single edges or nodes. In this contribution, we\nattempt to predict the future state of a graph as a whole. We propose to phrase\ntime series prediction as a regression problem and apply dissimilarity- or\nkernel-based regression techniques, such as 1-nearest neighbor, kernel\nregression and Gaussian process regression, which can be applied to graphs via\ngraph kernels. The output of the regression is a point embedded in a\npseudo-Euclidean space, which can be analyzed using subsequent dissimilarity-\nor kernel-based processing methods. We discuss strategies to speed up Gaussian\nProcesses regression from cubic to linear time and evaluate our approach on two\nwell-established theoretical models of graph evolution as well as two real data\nsets from the domain of intelligent tutoring systems. We find that simple\nregression methods, such as kernel regression, are sufficient to capture the\ndynamics in the theoretical models, but that Gaussian process regression\nsignificantly improves the prediction error for real-world data.\n", "versions": [{"version": "v1", "created": "Fri, 21 Apr 2017 12:08:30 GMT"}, {"version": "v2", "created": "Tue, 6 Jun 2017 10:21:36 GMT"}, {"version": "v3", "created": "Fri, 11 Aug 2017 11:47:42 GMT"}], "update_date": "2018-10-09", "authors_parsed": [["Paa\u00dfen", "Benjamin", ""], ["G\u00f6pfert", "Christina", ""], ["Hammer", "Barbara", ""]]}, {"id": "1704.06616", "submitter": "Siddharth Karamcheti", "authors": "Dilip Arumugam, Siddharth Karamcheti, Nakul Gopalan, Lawson L.S. Wong,\n  and Stefanie Tellex", "title": "Accurately and Efficiently Interpreting Human-Robot Instructions of\n  Varying Granularities", "comments": "Updated with final version - Published as Conference Paper in\n  Robotics: Science and Systems 2017", "journal-ref": null, "doi": "10.15607/RSS.2017.XIII.056", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Humans can ground natural language commands to tasks at both abstract and\nfine-grained levels of specificity. For instance, a human forklift operator can\nbe instructed to perform a high-level action, like \"grab a pallet\" or a\nlow-level action like \"tilt back a little bit.\" While robots are also capable\nof grounding language commands to tasks, previous methods implicitly assume\nthat all commands and tasks reside at a single, fixed level of abstraction.\nAdditionally, methods that do not use multiple levels of abstraction encounter\ninefficient planning and execution times as they solve tasks at a single level\nof abstraction with large, intractable state-action spaces closely resembling\nreal world complexity. In this work, by grounding commands to all the tasks or\nsubtasks available in a hierarchical planning framework, we arrive at a model\ncapable of interpreting language at multiple levels of specificity ranging from\ncoarse to more granular. We show that the accuracy of the grounding procedure\nis improved when simultaneously inferring the degree of abstraction in language\nused to communicate the task. Leveraging hierarchy also improves efficiency:\nour proposed approach enables a robot to respond to a command within one second\non 90% of our tasks, while baselines take over twenty seconds on half the\ntasks. Finally, we demonstrate that a real, physical robot can ground commands\nat multiple levels of abstraction allowing it to efficiently plan different\nsubtasks within the same planning hierarchy.\n", "versions": [{"version": "v1", "created": "Fri, 21 Apr 2017 16:15:19 GMT"}, {"version": "v2", "created": "Tue, 19 Jun 2018 17:19:29 GMT"}], "update_date": "2018-06-20", "authors_parsed": [["Arumugam", "Dilip", ""], ["Karamcheti", "Siddharth", ""], ["Gopalan", "Nakul", ""], ["Wong", "Lawson L. S.", ""], ["Tellex", "Stefanie", ""]]}, {"id": "1704.06621", "submitter": "Nasser Ghadiri", "authors": "Amir Hossein Goudarzi, Nasser Ghadiri", "title": "A hybrid spatial data mining approach based on fuzzy topological\n  relations and MOSES evolutionary algorithm", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Making high-quality decisions in strategic spatial planning is heavily\ndependent on extracting knowledge from vast amounts of data. Although many\ndecision-making problems like developing urban areas require such perception\nand reasoning, existing methods in this field usually neglect the deep\nknowledge mined from geographic databases and are based on pure statistical\nmethods. Due to the large volume of data gathered in spatial databases, and the\nuncertainty of spatial objects, mining association rules for high-level\nknowledge representation is a challenging task. Few algorithms manage\ngeographical and non-geographical data using topological relations. In this\npaper, a novel approach for spatial data mining based on the MOSES evolutionary\nframework is presented which improves the classic genetic programming approach.\nA hybrid architecture called GGeo is proposed to apply the MOSES mining rules\nconsidering fuzzy topological relations from spatial data. The uncertainty and\nfuzziness aspects are addressed using an enriched model of topological\nrelations by fuzzy region connection calculus. Moreover, to overcome the\nproblem of time-consuming fuzzy topological relationships calculations, this a\nnovel data pre-processing method is offered. GGeo analyses and learns from\ngeographical and non-geographical data and uses topological and distance\nparameters, and returns a series of arithmetic-spatial formulas as\nclassification rules. The proposed approach is resistant to noisy data, and all\nits stages run in parallel to increase speed. This approach may be used in\ndifferent spatial data classification problems as well as representing an\nappropriate method of data analysis and economic policy making.\n", "versions": [{"version": "v1", "created": "Fri, 21 Apr 2017 16:30:10 GMT"}], "update_date": "2017-04-24", "authors_parsed": [["Goudarzi", "Amir Hossein", ""], ["Ghadiri", "Nasser", ""]]}, {"id": "1704.06654", "submitter": "Thomas C King", "authors": "Thomas C. King", "title": "Governing Governance: A Formal Framework for Analysing Institutional\n  Design and Enactment Governance", "comments": null, "journal-ref": "SIKS Dissertation Series No. 2016-41", "doi": "10.4233/uuid:82438672-3e8b-477a-a39e-0ce189639e88", "report-no": null, "categories": "cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This dissertation is motivated by the need, in today's globalist world, for a\nprecise way to enable governments, organisations and other regulatory bodies to\nevaluate the constraints they place on themselves and others. An organisation's\nmodus operandi is enacting and fulfilling contracts between itself and its\nparticipants. Yet, organisational contracts should respect external laws, such\nas those setting out data privacy rights and liberties. Contracts can only be\nenacted by following contract law processes, which often require bilateral\nagreement and consideration. Governments need to legislate whilst understanding\ntoday's context of national and international governance hierarchy where law\nmakers shun isolationism and seek to influence one another. Governments should\navoid punishment by respecting constraints from international treaties and\nhuman rights charters. Governments can only enact legislation by following\ntheir own, pre-existing, law making procedures. In other words, institutions,\nsuch as laws and contracts are designed and enacted under constraints.\n", "versions": [{"version": "v1", "created": "Fri, 21 Apr 2017 14:39:51 GMT"}], "update_date": "2017-04-25", "authors_parsed": [["King", "Thomas C.", ""]]}, {"id": "1704.06676", "submitter": "Tomasz Tajmajer", "authors": "Tomasz Tajmajer", "title": "Modular Multi-Objective Deep Reinforcement Learning with Decision Values", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we present a method for using Deep Q-Networks (DQNs) in\nmulti-objective environments. Deep Q-Networks provide remarkable performance in\nsingle objective problems learning from high-level visual state\nrepresentations. However, in many scenarios (e.g in robotics, games), the agent\nneeds to pursue multiple objectives simultaneously. We propose an architecture\nin which separate DQNs are used to control the agent's behaviour with respect\nto particular objectives. In this architecture we introduce decision values to\nimprove the scalarization of multiple DQNs into a single action. Our\narchitecture enables the decomposition of the agent's behaviour into\ncontrollable and replaceable sub-behaviours learned by distinct modules.\nMoreover, it allows to change the priorities of particular objectives\npost-learning, while preserving the overall performance of the agent. To\nevaluate our solution we used a game-like simulator in which an agent -\nprovided with high-level visual input - pursues multiple objectives in a 2D\nworld.\n", "versions": [{"version": "v1", "created": "Fri, 21 Apr 2017 18:42:02 GMT"}, {"version": "v2", "created": "Thu, 22 Feb 2018 19:13:06 GMT"}], "update_date": "2018-02-26", "authors_parsed": [["Tajmajer", "Tomasz", ""]]}, {"id": "1704.06857", "submitter": "Alberto Garcia-Garcia", "authors": "Alberto Garcia-Garcia, Sergio Orts-Escolano, Sergiu Oprea, Victor\n  Villena-Martinez, Jose Garcia-Rodriguez", "title": "A Review on Deep Learning Techniques Applied to Semantic Segmentation", "comments": "Submitted to TPAMI on Apr. 22, 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Image semantic segmentation is more and more being of interest for computer\nvision and machine learning researchers. Many applications on the rise need\naccurate and efficient segmentation mechanisms: autonomous driving, indoor\nnavigation, and even virtual or augmented reality systems to name a few. This\ndemand coincides with the rise of deep learning approaches in almost every\nfield or application target related to computer vision, including semantic\nsegmentation or scene understanding. This paper provides a review on deep\nlearning methods for semantic segmentation applied to various application\nareas. Firstly, we describe the terminology of this field as well as mandatory\nbackground concepts. Next, the main datasets and challenges are exposed to help\nresearchers decide which are the ones that best suit their needs and their\ntargets. Then, existing methods are reviewed, highlighting their contributions\nand their significance in the field. Finally, quantitative results are given\nfor the described methods and the datasets in which they were evaluated,\nfollowing up with a discussion of the results. At last, we point out a set of\npromising future works and draw our own conclusions about the state of the art\nof semantic segmentation using deep learning techniques.\n", "versions": [{"version": "v1", "created": "Sat, 22 Apr 2017 23:37:43 GMT"}], "update_date": "2017-04-25", "authors_parsed": [["Garcia-Garcia", "Alberto", ""], ["Orts-Escolano", "Sergio", ""], ["Oprea", "Sergiu", ""], ["Villena-Martinez", "Victor", ""], ["Garcia-Rodriguez", "Jose", ""]]}, {"id": "1704.06885", "submitter": "Hong Zhao", "authors": "Hong Zhao", "title": "A General Theory for Training Learning Machine", "comments": "55 pages, 18 figures. arXiv admin note: substantial text overlap with\n  arXiv:1602.03950", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Though the deep learning is pushing the machine learning to a new stage,\nbasic theories of machine learning are still limited. The principle of\nlearning, the role of the a prior knowledge, the role of neuron bias, and the\nbasis for choosing neural transfer function and cost function, etc., are still\nfar from clear. In this paper, we present a general theoretical framework for\nmachine learning. We classify the prior knowledge into common and\nproblem-dependent parts, and consider that the aim of learning is to maximally\nincorporate them. The principle we suggested for maximizing the former is the\ndesign risk minimization principle, while the neural transfer function, the\ncost function, as well as pretreatment of samples, are endowed with the role\nfor maximizing the latter. The role of the neuron bias is explained from a\ndifferent angle. We develop a Monte Carlo algorithm to establish the\ninput-output responses, and we control the input-output sensitivity of a\nlearning machine by controlling that of individual neurons. Applications of\nfunction approaching and smoothing, pattern recognition and classification, are\nprovided to illustrate how to train general learning machines based on our\ntheory and algorithm. Our method may in addition induce new applications, such\nas the transductive inference.\n", "versions": [{"version": "v1", "created": "Sun, 23 Apr 2017 05:48:18 GMT"}], "update_date": "2017-04-25", "authors_parsed": [["Zhao", "Hong", ""]]}, {"id": "1704.06942", "submitter": "Diego Perez Liebana Dr.", "authors": "Rauca D. Gaina and Simon M. Lucas and Diego Perez-Liebana", "title": "Population Seeding Techniques for Rolling Horizon Evolution in General\n  Video Game Playing", "comments": "Proceedings of the IEEE Conference on Evolutionary Computation 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While Monte Carlo Tree Search and closely related methods have dominated\nGeneral Video Game Playing, recent research has demonstrated the promise of\nRolling Horizon Evolutionary Algorithms as an interesting alternative. However,\nthere is little attention paid to population initialization techniques in the\nsetting of general real-time video games. Therefore, this paper proposes the\nuse of population seeding to improve the performance of Rolling Horizon\nEvolution and presents the results of two methods, One Step Look Ahead and\nMonte Carlo Tree Search, tested on 20 games of the General Video Game AI corpus\nwith multiple evolution parameter values (population size and individual\nlength). An in-depth analysis is carried out between the results of the seeding\nmethods and the vanilla Rolling Horizon Evolution. In addition, the paper\npresents a comparison to a Monte Carlo Tree Search algorithm. The results are\npromising, with seeding able to boost performance significantly over baseline\nevolution and even match the high level of play obtained by the Monte Carlo\nTree Search.\n", "versions": [{"version": "v1", "created": "Sun, 23 Apr 2017 15:53:29 GMT"}], "update_date": "2017-04-25", "authors_parsed": [["Gaina", "Rauca D.", ""], ["Lucas", "Simon M.", ""], ["Perez-Liebana", "Diego", ""]]}, {"id": "1704.06945", "submitter": "Diego Perez Liebana Dr.", "authors": "Kamolwan Kunanusont and Simon M. Lucas and Diego Perez-Liebana", "title": "General Video Game AI: Learning from Screen Capture", "comments": "Proceedings of the IEEE Conference on Evolutionary Computation 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  General Video Game Artificial Intelligence is a general game playing\nframework for Artificial General Intelligence research in the video-games\ndomain. In this paper, we propose for the first time a screen capture learning\nagent for General Video Game AI framework. A Deep Q-Network algorithm was\napplied and improved to develop an agent capable of learning to play different\ngames in the framework. After testing this algorithm using various games of\ndifferent categories and difficulty levels, the results suggest that our\nproposed screen capture learning agent has the potential to learn many\ndifferent games using only a single learning algorithm.\n", "versions": [{"version": "v1", "created": "Sun, 23 Apr 2017 16:08:06 GMT"}], "update_date": "2017-04-25", "authors_parsed": [["Kunanusont", "Kamolwan", ""], ["Lucas", "Simon M.", ""], ["Perez-Liebana", "Diego", ""]]}, {"id": "1704.06956", "submitter": "Sida Wang", "authors": "Sida I. Wang and Samuel Ginn and Percy Liang and Christoper D. Manning", "title": "Naturalizing a Programming Language via Interactive Learning", "comments": "10 pages, ACL2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Our goal is to create a convenient natural language interface for performing\nwell-specified but complex actions such as analyzing data, manipulating text,\nand querying databases. However, existing natural language interfaces for such\ntasks are quite primitive compared to the power one wields with a programming\nlanguage. To bridge this gap, we start with a core programming language and\nallow users to \"naturalize\" the core language incrementally by defining\nalternative, more natural syntax and increasingly complex concepts in terms of\ncompositions of simpler ones. In a voxel world, we show that a community of\nusers can simultaneously teach a common system a diverse language and use it to\nbuild hundreds of complex voxel structures. Over the course of three days,\nthese users went from using only the core language to using the naturalized\nlanguage in 85.9\\% of the last 10K utterances.\n", "versions": [{"version": "v1", "created": "Sun, 23 Apr 2017 18:13:10 GMT"}], "update_date": "2017-04-25", "authors_parsed": [["Wang", "Sida I.", ""], ["Ginn", "Samuel", ""], ["Liang", "Percy", ""], ["Manning", "Christoper D.", ""]]}, {"id": "1704.07069", "submitter": "Diego Perez Liebana Dr.", "authors": "Joseph Walton-Rivers and Piers R. Williams and Richard Bartle and\n  Diego Perez-Liebana and Simon M. Lucas", "title": "Evaluating and Modelling Hanabi-Playing Agents", "comments": "Proceedings of the IEEE Conference on Evolutionary Computation (2017)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Agent modelling involves considering how other agents will behave, in order\nto influence your own actions. In this paper, we explore the use of agent\nmodelling in the hidden-information, collaborative card game Hanabi. We\nimplement a number of rule-based agents, both from the literature and of our\nown devising, in addition to an Information Set Monte Carlo Tree Search\n(IS-MCTS) agent. We observe poor results from IS-MCTS, so construct a new,\npredictor version that uses a model of the agents with which it is paired. We\nobserve a significant improvement in game-playing strength from this agent in\ncomparison to IS-MCTS, resulting from its consideration of what the other\nagents in a game would do. In addition, we create a flawed rule-based agent to\nhighlight the predictor's capabilities with such an agent.\n", "versions": [{"version": "v1", "created": "Mon, 24 Apr 2017 07:44:10 GMT"}], "update_date": "2017-04-25", "authors_parsed": [["Walton-Rivers", "Joseph", ""], ["Williams", "Piers R.", ""], ["Bartle", "Richard", ""], ["Perez-Liebana", "Diego", ""], ["Lucas", "Simon M.", ""]]}, {"id": "1704.07075", "submitter": "Diego Perez Liebana Dr.", "authors": "Raluca D. Gaina and Jialin Liu and Simon M. Lucas and Diego\n  Perez-Liebana", "title": "Analysis of Vanilla Rolling Horizon Evolution Parameters in General\n  Video Game Playing", "comments": null, "journal-ref": "Applications of Evolutionary Computation, EvoApplications, Lecture\n  Notes in Computer Science, vol. 10199, Springer, Cham., p. 418-434, 2017", "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Monte Carlo Tree Search techniques have generally dominated General Video\nGame Playing, but recent research has started looking at Evolutionary\nAlgorithms and their potential at matching Tree Search level of play or even\noutperforming these methods. Online or Rolling Horizon Evolution is one of the\noptions available to evolve sequences of actions for planning in General Video\nGame Playing, but no research has been done up to date that explores the\ncapabilities of the vanilla version of this algorithm in multiple games. This\nstudy aims to critically analyse the different configurations regarding\npopulation size and individual length in a set of 20 games from the General\nVideo Game AI corpus. Distinctions are made between deterministic and\nstochastic games, and the implications of using superior time budgets are\nstudied. Results show that there is scope for the use of these techniques,\nwhich in some configurations outperform Monte Carlo Tree Search, and also\nsuggest that further research in these methods could boost their performance.\n", "versions": [{"version": "v1", "created": "Mon, 24 Apr 2017 08:01:39 GMT"}], "update_date": "2017-04-25", "authors_parsed": [["Gaina", "Raluca D.", ""], ["Liu", "Jialin", ""], ["Lucas", "Simon M.", ""], ["Perez-Liebana", "Diego", ""]]}, {"id": "1704.07121", "submitter": "Hexiang Hu", "authors": "Wei-Lun Chao, Hexiang Hu, Fei Sha", "title": "Being Negative but Constructively: Lessons Learnt from Creating Better\n  Visual Question Answering Datasets", "comments": "Accepted for Oral Presentation at NAACL-HLT 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Visual question answering (Visual QA) has attracted a lot of attention\nlately, seen essentially as a form of (visual) Turing test that artificial\nintelligence should strive to achieve. In this paper, we study a crucial\ncomponent of this task: how can we design good datasets for the task? We focus\non the design of multiple-choice based datasets where the learner has to select\nthe right answer from a set of candidate ones including the target (\\ie the\ncorrect one) and the decoys (\\ie the incorrect ones). Through careful analysis\nof the results attained by state-of-the-art learning models and human\nannotators on existing datasets, we show that the design of the decoy answers\nhas a significant impact on how and what the learning models learn from the\ndatasets. In particular, the resulting learner can ignore the visual\ninformation, the question, or both while still doing well on the task. Inspired\nby this, we propose automatic procedures to remedy such design deficiencies. We\napply the procedures to re-construct decoy answers for two popular Visual QA\ndatasets as well as to create a new Visual QA dataset from the Visual Genome\nproject, resulting in the largest dataset for this task. Extensive empirical\nstudies show that the design deficiencies have been alleviated in the remedied\ndatasets and the performance on them is likely a more faithful indicator of the\ndifference among learning models. The datasets are released and publicly\navailable via http://www.teds.usc.edu/website_vqa/.\n", "versions": [{"version": "v1", "created": "Mon, 24 Apr 2017 10:05:19 GMT"}, {"version": "v2", "created": "Sun, 10 Jun 2018 20:34:21 GMT"}], "update_date": "2018-06-12", "authors_parsed": [["Chao", "Wei-Lun", ""], ["Hu", "Hexiang", ""], ["Sha", "Fei", ""]]}, {"id": "1704.07183", "submitter": "Steven Prestwich D", "authors": "Steven Prestwich and Roberto Rossi and Armagan Tarim", "title": "Stochastic Constraint Programming as Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stochastic Constraint Programming (SCP) is an extension of Constraint\nProgramming (CP) used for modelling and solving problems involving constraints\nand uncertainty. SCP inherits excellent modelling abilities and filtering\nalgorithms from CP, but so far it has not been applied to large problems.\nReinforcement Learning (RL) extends Dynamic Programming to large stochastic\nproblems, but is problem-specific and has no generic solvers. We propose a\nhybrid combining the scalability of RL with the modelling and constraint\nfiltering methods of CP. We implement a prototype in a CP system and\ndemonstrate its usefulness on SCP problems.\n", "versions": [{"version": "v1", "created": "Mon, 24 Apr 2017 12:44:38 GMT"}], "update_date": "2017-04-25", "authors_parsed": [["Prestwich", "Steven", ""], ["Rossi", "Roberto", ""], ["Tarim", "Armagan", ""]]}, {"id": "1704.07221", "submitter": "Elena Kochkina", "authors": "Elena Kochkina, Maria Liakata, Isabelle Augenstein", "title": "Turing at SemEval-2017 Task 8: Sequential Approach to Rumour Stance\n  Classification with Branch-LSTM", "comments": "SemEval 2017 RumourEval: Determining rumour veracity and support for\n  rumours (SemEval 2017 Task 8, Subtask A)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes team Turing's submission to SemEval 2017 RumourEval:\nDetermining rumour veracity and support for rumours (SemEval 2017 Task 8,\nSubtask A). Subtask A addresses the challenge of rumour stance classification,\nwhich involves identifying the attitude of Twitter users towards the\ntruthfulness of the rumour they are discussing. Stance classification is\nconsidered to be an important step towards rumour verification, therefore\nperforming well in this task is expected to be useful in debunking false\nrumours. In this work we classify a set of Twitter posts discussing rumours\ninto either supporting, denying, questioning or commenting on the underlying\nrumours. We propose a LSTM-based sequential model that, through modelling the\nconversational structure of tweets, which achieves an accuracy of 0.784 on the\nRumourEval test set outperforming all other systems in Subtask A.\n", "versions": [{"version": "v1", "created": "Mon, 24 Apr 2017 13:41:25 GMT"}], "update_date": "2017-04-25", "authors_parsed": [["Kochkina", "Elena", ""], ["Liakata", "Maria", ""], ["Augenstein", "Isabelle", ""]]}, {"id": "1704.07402", "submitter": "Hamed R. Tavakoli", "authors": "Hamed R. Tavakoli, Jorma Laaksonen", "title": "Towards Instance Segmentation with Object Priority: Prominent Object\n  Detection and Recognition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This manuscript introduces the problem of prominent object detection and\nrecognition inspired by the fact that human seems to priorities perception of\nscene elements. The problem deals with finding the most important region of\ninterest, segmenting the relevant item/object in that area, and assigning it an\nobject class label. In other words, we are solving the three problems of\nsaliency modeling, saliency detection, and object recognition under one\numbrella. The motivation behind such a problem formulation is (1) the benefits\nto the knowledge representation-based vision pipelines, and (2) the potential\nimprovements in emulating bio-inspired vision systems by solving these three\nproblems together. We are foreseeing extending this problem formulation to\nfully semantically segmented scenes with instance object priority for\nhigh-level inferences in various applications including assistive vision. Along\nwith a new problem definition, we also propose a method to achieve such a task.\nThe proposed model predicts the most important area in the image, segments the\nassociated objects, and labels them. The proposed problem and method are\nevaluated against human fixations, annotated segmentation masks, and object\nclass categories. We define a chance level for each of the evaluation criterion\nto compare the proposed algorithm with. Despite the good performance of the\nproposed baseline, the overall evaluations indicate that the problem of\nprominent object detection and recognition is a challenging task that is still\nworth investigating further.\n", "versions": [{"version": "v1", "created": "Mon, 24 Apr 2017 18:12:12 GMT"}, {"version": "v2", "created": "Fri, 4 Aug 2017 12:15:34 GMT"}], "update_date": "2017-08-07", "authors_parsed": [["Tavakoli", "Hamed R.", ""], ["Laaksonen", "Jorma", ""]]}, {"id": "1704.07434", "submitter": "Hamed R. Tavakoli", "authors": "Hamed R. Tavakoli, Rakshith Shetty, Ali Borji, Jorma Laaksonen", "title": "Paying Attention to Descriptions Generated by Image Captioning Models", "comments": "To appear in ICCV 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To bridge the gap between humans and machines in image understanding and\ndescribing, we need further insight into how people describe a perceived scene.\nIn this paper, we study the agreement between bottom-up saliency-based visual\nattention and object referrals in scene description constructs. We investigate\nthe properties of human-written descriptions and machine-generated ones. We\nthen propose a saliency-boosted image captioning model in order to investigate\nbenefits from low-level cues in language models. We learn that (1) humans\nmention more salient objects earlier than less salient ones in their\ndescriptions, (2) the better a captioning model performs, the better attention\nagreement it has with human descriptions, (3) the proposed saliency-boosted\nmodel, compared to its baseline form, does not improve significantly on the MS\nCOCO database, indicating explicit bottom-up boosting does not help when the\ntask is well learnt and tuned on a data, (4) a better generalization is,\nhowever, observed for the saliency-boosted model on unseen data.\n", "versions": [{"version": "v1", "created": "Mon, 24 Apr 2017 19:51:16 GMT"}, {"version": "v2", "created": "Wed, 28 Jun 2017 10:13:45 GMT"}, {"version": "v3", "created": "Fri, 4 Aug 2017 11:24:45 GMT"}], "update_date": "2017-08-07", "authors_parsed": [["Tavakoli", "Hamed R.", ""], ["Shetty", "Rakshith", ""], ["Borji", "Ali", ""], ["Laaksonen", "Jorma", ""]]}, {"id": "1704.07466", "submitter": "Freddy Lecue", "authors": "Freddy Lecue, Jiaoyan Chen, Jeff Pan, Huajun Chen", "title": "Learning from Ontology Streams with Semantic Concept Drift", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data stream learning has been largely studied for extracting knowledge\nstructures from continuous and rapid data records. In the semantic Web, data is\ninterpreted in ontologies and its ordered sequence is represented as an\nontology stream. Our work exploits the semantics of such streams to tackle the\nproblem of concept drift i.e., unexpected changes in data distribution, causing\nmost of models to be less accurate as time passes. To this end we revisited (i)\nsemantic inference in the context of supervised stream learning, and (ii)\nmodels with semantic embeddings. The experiments show accurate prediction with\ndata from Dublin and Beijing.\n", "versions": [{"version": "v1", "created": "Mon, 24 Apr 2017 21:12:13 GMT"}], "update_date": "2017-04-26", "authors_parsed": [["Lecue", "Freddy", ""], ["Chen", "Jiaoyan", ""], ["Pan", "Jeff", ""], ["Chen", "Huajun", ""]]}, {"id": "1704.07468", "submitter": "Yanjun  Qi Dr.", "authors": "Ritambhara Singh, Arshdeep Sekhon, Kamran Kowsari, Jack Lanchantin,\n  Beilun Wang and Yanjun Qi", "title": "GaKCo: a Fast GApped k-mer string Kernel using COunting", "comments": "@ECML 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CC cs.CL cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  String Kernel (SK) techniques, especially those using gapped $k$-mers as\nfeatures (gk), have obtained great success in classifying sequences like DNA,\nprotein, and text. However, the state-of-the-art gk-SK runs extremely slow when\nwe increase the dictionary size ($\\Sigma$) or allow more mismatches ($M$). This\nis because current gk-SK uses a trie-based algorithm to calculate co-occurrence\nof mismatched substrings resulting in a time cost proportional to\n$O(\\Sigma^{M})$. We propose a \\textbf{fast} algorithm for calculating\n\\underline{Ga}pped $k$-mer \\underline{K}ernel using \\underline{Co}unting\n(GaKCo). GaKCo uses associative arrays to calculate the co-occurrence of\nsubstrings using cumulative counting. This algorithm is fast, scalable to\nlarger $\\Sigma$ and $M$, and naturally parallelizable. We provide a rigorous\nasymptotic analysis that compares GaKCo with the state-of-the-art gk-SK.\nTheoretically, the time cost of GaKCo is independent of the $\\Sigma^{M}$ term\nthat slows down the trie-based approach. Experimentally, we observe that GaKCo\nachieves the same accuracy as the state-of-the-art and outperforms its speed by\nfactors of 2, 100, and 4, on classifying sequences of DNA (5 datasets), protein\n(12 datasets), and character-based English text (2 datasets), respectively.\n  GaKCo is shared as an open source tool at\n\\url{https://github.com/QData/GaKCo-SVM}\n", "versions": [{"version": "v1", "created": "Mon, 24 Apr 2017 21:43:21 GMT"}, {"version": "v2", "created": "Sun, 30 Apr 2017 20:12:01 GMT"}, {"version": "v3", "created": "Mon, 18 Sep 2017 17:25:17 GMT"}], "update_date": "2017-09-19", "authors_parsed": [["Singh", "Ritambhara", ""], ["Sekhon", "Arshdeep", ""], ["Kowsari", "Kamran", ""], ["Lanchantin", "Jack", ""], ["Wang", "Beilun", ""], ["Qi", "Yanjun", ""]]}, {"id": "1704.07489", "submitter": "Ramakanth Pasunuru", "authors": "Ramakanth Pasunuru, Mohit Bansal", "title": "Multi-Task Video Captioning with Video and Entailment Generation", "comments": "ACL 2017 (14 pages w/ supplementary)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Video captioning, the task of describing the content of a video, has seen\nsome promising improvements in recent years with sequence-to-sequence models,\nbut accurately learning the temporal and logical dynamics involved in the task\nstill remains a challenge, especially given the lack of sufficient annotated\ndata. We improve video captioning by sharing knowledge with two related\ndirected-generation tasks: a temporally-directed unsupervised video prediction\ntask to learn richer context-aware video encoder representations, and a\nlogically-directed language entailment generation task to learn better\nvideo-entailed caption decoder representations. For this, we present a\nmany-to-many multi-task learning model that shares parameters across the\nencoders and decoders of the three tasks. We achieve significant improvements\nand the new state-of-the-art on several standard video captioning datasets\nusing diverse automatic and human evaluations. We also show mutual multi-task\nimprovements on the entailment generation task.\n", "versions": [{"version": "v1", "created": "Mon, 24 Apr 2017 23:07:32 GMT"}, {"version": "v2", "created": "Tue, 8 Aug 2017 17:08:58 GMT"}], "update_date": "2017-08-09", "authors_parsed": [["Pasunuru", "Ramakanth", ""], ["Bansal", "Mohit", ""]]}, {"id": "1704.07498", "submitter": "Samir Abdelrahman", "authors": "Mohammad Amin Morid, Olivia R. Liu Sheng, Samir Abdelrahman", "title": "Leveraging Patient Similarity and Time Series Data in Healthcare\n  Predictive Models", "comments": "To appear:Twenty-third Americas Conference on Information Systems,\n  Boston, 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Patient time series classification faces challenges in high degrees of\ndimensionality and missingness. In light of patient similarity theory, this\nstudy explores effective temporal feature engineering and reduction, missing\nvalue imputation, and change point detection methods that can afford\nsimilarity-based classification models with desirable accuracy enhancement. We\nselect a piecewise aggregation approximation method to extract fine-grain\ntemporal features and propose a minimalist method to impute missing values in\ntemporal features. For dimensionality reduction, we adopt a gradient descent\nsearch method for feature weight assignment. We propose new patient status and\ndirectional change definitions based on medical knowledge or clinical\nguidelines about the value ranges for different patient status levels, and\ndevelop a method to detect change points indicating positive or negative\npatient status changes. We evaluate the effectiveness of the proposed methods\nin the context of early Intensive Care Unit mortality prediction. The\nevaluation results show that the k-Nearest Neighbor algorithm that incorporates\nmethods we select and propose significantly outperform the relevant benchmarks\nfor early ICU mortality prediction. This study makes contributions to time\nseries classification and early ICU mortality prediction via identifying and\nenhancing temporal feature engineering and reduction methods for\nsimilarity-based time series classification.\n", "versions": [{"version": "v1", "created": "Tue, 25 Apr 2017 00:25:06 GMT"}, {"version": "v2", "created": "Wed, 26 Apr 2017 00:27:53 GMT"}, {"version": "v3", "created": "Sun, 30 Apr 2017 15:33:25 GMT"}], "update_date": "2017-05-02", "authors_parsed": [["Morid", "Mohammad Amin", ""], ["Sheng", "Olivia R. Liu", ""], ["Abdelrahman", "Samir", ""]]}, {"id": "1704.07499", "submitter": "Samir Abdelrahman", "authors": "Mohammad Amin Morid, Olivia R. Liu Sheng, Samir Abdelrahman", "title": "PPMF: A Patient-based Predictive Modeling Framework for Early ICU\n  Mortality Prediction", "comments": "10 pages, Healthcare Analytics and Medical Decision Making, INFORMS\n  Workshop. Nashville, Tennessee, 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To date, developing a good model for early intensive care unit (ICU)\nmortality prediction is still challenging. This paper presents a patient based\npredictive modeling framework (PPMF) to improve the performance of ICU\nmortality prediction using data collected during the first 48 hours of ICU\nadmission. PPMF consists of three main components verifying three related\nresearch hypotheses. The first component captures dynamic changes of patients\nstatus in the ICU using their time series data (e.g., vital signs and\nlaboratory tests). The second component is a local approximation algorithm that\nclassifies patients based on their similarities. The third component is a\nGradient Decent wrapper that updates feature weights according to the\nclassification feedback. Experiments using data from MIMICIII show that PPMF\nsignificantly outperforms: (1) the severity score systems, namely SASP III,\nAPACHE IV, and MPM0III, (2) the aggregation based classifiers that utilize\nsummarized time series, and (3) baseline feature selection methods.\n", "versions": [{"version": "v1", "created": "Tue, 25 Apr 2017 00:27:00 GMT"}], "update_date": "2017-05-02", "authors_parsed": [["Morid", "Mohammad Amin", ""], ["Sheng", "Olivia R. Liu", ""], ["Abdelrahman", "Samir", ""]]}, {"id": "1704.07503", "submitter": "Cheng-Hao Cai", "authors": "Cheng-Hao Cai, Dengfeng Ke, Yanyan Xu, Kaile Su", "title": "Learning of Human-like Algebraic Reasoning Using Deep Feedforward Neural\n  Networks", "comments": "8 pages, 7 figures", "journal-ref": null, "doi": "10.1016/j.bica.2018.07.004", "report-no": null, "categories": "cs.AI cs.LG cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is a wide gap between symbolic reasoning and deep learning. In this\nresearch, we explore the possibility of using deep learning to improve symbolic\nreasoning. Briefly, in a reasoning system, a deep feedforward neural network is\nused to guide rewriting processes after learning from algebraic reasoning\nexamples produced by humans. To enable the neural network to recognise patterns\nof algebraic expressions with non-deterministic sizes, reduced partial trees\nare used to represent the expressions. Also, to represent both top-down and\nbottom-up information of the expressions, a centralisation technique is used to\nimprove the reduced partial trees. Besides, symbolic association vectors and\nrule application records are used to improve the rewriting processes.\nExperimental results reveal that the algebraic reasoning examples can be\naccurately learnt only if the feedforward neural network has enough hidden\nlayers. Also, the centralisation technique, the symbolic association vectors\nand the rule application records can reduce error rates of reasoning. In\nparticular, the above approaches have led to 4.6% error rate of reasoning on a\ndataset of linear equations, differentials and integrals.\n", "versions": [{"version": "v1", "created": "Tue, 25 Apr 2017 01:10:09 GMT"}], "update_date": "2018-09-13", "authors_parsed": [["Cai", "Cheng-Hao", ""], ["Ke", "Dengfeng", ""], ["Xu", "Yanyan", ""], ["Su", "Kaile", ""]]}, {"id": "1704.07535", "submitter": "Maxim Rabinovich", "authors": "Maxim Rabinovich, Mitchell Stern, Dan Klein", "title": "Abstract Syntax Networks for Code Generation and Semantic Parsing", "comments": "ACL 2017. MR and MS contributed equally", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tasks like code generation and semantic parsing require mapping unstructured\n(or partially structured) inputs to well-formed, executable outputs. We\nintroduce abstract syntax networks, a modeling framework for these problems.\nThe outputs are represented as abstract syntax trees (ASTs) and constructed by\na decoder with a dynamically-determined modular structure paralleling the\nstructure of the output tree. On the benchmark Hearthstone dataset for code\ngeneration, our model obtains 79.2 BLEU and 22.7% exact match accuracy,\ncompared to previous state-of-the-art values of 67.1 and 6.1%. Furthermore, we\nperform competitively on the Atis, Jobs, and Geo semantic parsing datasets with\nno task-specific engineering.\n", "versions": [{"version": "v1", "created": "Tue, 25 Apr 2017 04:37:35 GMT"}], "update_date": "2017-04-26", "authors_parsed": [["Rabinovich", "Maxim", ""], ["Stern", "Mitchell", ""], ["Klein", "Dan", ""]]}, {"id": "1704.07538", "submitter": "Hang Ma", "authors": "Wolfgang H\\\"onig, T. K. Satish Kumar, Liron Cohen, Hang Ma, Sven\n  Koenig, Nora Ayanian", "title": "Path Planning with Kinematic Constraints for Robot Groups", "comments": "Published in Southern California Robotics Symposium 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Path planning for multiple robots is well studied in the AI and robotics\ncommunities. For a given discretized environment, robots need to find\ncollision-free paths to a set of specified goal locations. Robots can be fully\nanonymous, non-anonymous, or organized in groups. Although powerful solvers for\nthis abstract problem exist, they make simplifying assumptions by ignoring\nkinematic constraints, making it difficult to use the resulting plans on actual\nrobots. In this paper, we present a solution which takes kinematic constraints,\nsuch as maximum velocities, into account, while guaranteeing a user-specified\nminimum safety distance between robots. We demonstrate our approach in\nsimulation and on real robots in 2D and 3D environments.\n", "versions": [{"version": "v1", "created": "Tue, 25 Apr 2017 04:52:09 GMT"}], "update_date": "2017-04-26", "authors_parsed": [["H\u00f6nig", "Wolfgang", ""], ["Kumar", "T. K. Satish", ""], ["Cohen", "Liron", ""], ["Ma", "Hang", ""], ["Koenig", "Sven", ""], ["Ayanian", "Nora", ""]]}, {"id": "1704.07548", "submitter": "Huiguang He", "authors": "Changde Du, Changying Du, Jinpeng Li, Wei-long Zheng, Bao-liang Lu,\n  Huiguang He", "title": "Semi-supervised Bayesian Deep Multi-modal Emotion Recognition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In emotion recognition, it is difficult to recognize human's emotional states\nusing just a single modality. Besides, the annotation of physiological\nemotional data is particularly expensive. These two aspects make the building\nof effective emotion recognition model challenging. In this paper, we first\nbuild a multi-view deep generative model to simulate the generative process of\nmulti-modality emotional data. By imposing a mixture of Gaussians assumption on\nthe posterior approximation of the latent variables, our model can learn the\nshared deep representation from multiple modalities. To solve the\nlabeled-data-scarcity problem, we further extend our multi-view model to\nsemi-supervised learning scenario by casting the semi-supervised classification\nproblem as a specialized missing data imputation task. Our semi-supervised\nmulti-view deep generative framework can leverage both labeled and unlabeled\ndata from multiple modalities, where the weight factor for each modality can be\nlearned automatically. Compared with previous emotion recognition methods, our\nmethod is more robust and flexible. The experiments conducted on two real\nmulti-modal emotion datasets have demonstrated the superiority of our framework\nover a number of competitors.\n", "versions": [{"version": "v1", "created": "Tue, 25 Apr 2017 06:29:59 GMT"}], "update_date": "2017-04-26", "authors_parsed": [["Du", "Changde", ""], ["Du", "Changying", ""], ["Li", "Jinpeng", ""], ["Zheng", "Wei-long", ""], ["Lu", "Bao-liang", ""], ["He", "Huiguang", ""]]}, {"id": "1704.07555", "submitter": "Marcus Olivecrona", "authors": "Marcus Olivecrona, Thomas Blaschke, Ola Engkvist, and Hongming Chen", "title": "Molecular De Novo Design through Deep Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work introduces a method to tune a sequence-based generative model for\nmolecular de novo design that through augmented episodic likelihood can learn\nto generate structures with certain specified desirable properties. We\ndemonstrate how this model can execute a range of tasks such as generating\nanalogues to a query structure and generating compounds predicted to be active\nagainst a biological target. As a proof of principle, the model is first\ntrained to generate molecules that do not contain sulphur. As a second example,\nthe model is trained to generate analogues to the drug Celecoxib, a technique\nthat could be used for scaffold hopping or library expansion starting from a\nsingle molecule. Finally, when tuning the model towards generating compounds\npredicted to be active against the dopamine receptor type 2, the model\ngenerates structures of which more than 95% are predicted to be active,\nincluding experimentally confirmed actives that have not been included in\neither the generative model nor the activity prediction model.\n", "versions": [{"version": "v1", "created": "Tue, 25 Apr 2017 06:41:21 GMT"}, {"version": "v2", "created": "Tue, 29 Aug 2017 12:31:19 GMT"}], "update_date": "2017-08-30", "authors_parsed": [["Olivecrona", "Marcus", ""], ["Blaschke", "Thomas", ""], ["Engkvist", "Ola", ""], ["Chen", "Hongming", ""]]}, {"id": "1704.07575", "submitter": "Huiguang He", "authors": "Changde Du, Changying Du, Huiguang He", "title": "Sharing deep generative representation for perceived image\n  reconstruction from human brain activity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CV q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Decoding human brain activities via functional magnetic resonance imaging\n(fMRI) has gained increasing attention in recent years. While encouraging\nresults have been reported in brain states classification tasks, reconstructing\nthe details of human visual experience still remains difficult. Two main\nchallenges that hinder the development of effective models are the perplexing\nfMRI measurement noise and the high dimensionality of limited data instances.\nExisting methods generally suffer from one or both of these issues and yield\ndissatisfactory results. In this paper, we tackle this problem by casting the\nreconstruction of visual stimulus as the Bayesian inference of missing view in\na multiview latent variable model. Sharing a common latent representation, our\njoint generative model of external stimulus and brain response is not only\n\"deep\" in extracting nonlinear features from visual images, but also powerful\nin capturing correlations among voxel activities of fMRI recordings. The\nnonlinearity and deep structure endow our model with strong representation\nability, while the correlations of voxel activities are critical for\nsuppressing noise and improving prediction. We devise an efficient variational\nBayesian method to infer the latent variables and the model parameters. To\nfurther improve the reconstruction accuracy, the latent representations of\ntesting instances are enforced to be close to that of their neighbours from the\ntraining set via posterior regularization. Experiments on three fMRI recording\ndatasets demonstrate that our approach can more accurately reconstruct visual\nstimuli.\n", "versions": [{"version": "v1", "created": "Tue, 25 Apr 2017 08:20:42 GMT"}, {"version": "v2", "created": "Wed, 17 May 2017 05:16:14 GMT"}, {"version": "v3", "created": "Tue, 11 Jul 2017 01:50:34 GMT"}], "update_date": "2017-07-12", "authors_parsed": [["Du", "Changde", ""], ["Du", "Changying", ""], ["He", "Huiguang", ""]]}, {"id": "1704.07624", "submitter": "Amit Gupta", "authors": "Amit Gupta and R\\'emi Lebret and Hamza Harkous and Karl Aberer", "title": "280 Birds with One Stone: Inducing Multilingual Taxonomies from\n  Wikipedia using Character-level Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a simple, yet effective, approach towards inducing multilingual\ntaxonomies from Wikipedia. Given an English taxonomy, our approach leverages\nthe interlanguage links of Wikipedia followed by character-level classifiers to\ninduce high-precision, high-coverage taxonomies in other languages. Through\nexperiments, we demonstrate that our approach significantly outperforms the\nstate-of-the-art, heuristics-heavy approaches for six languages. As a\nconsequence of our work, we release presumably the largest and the most\naccurate multilingual taxonomic resource spanning over 280 languages.\n", "versions": [{"version": "v1", "created": "Tue, 25 Apr 2017 10:45:43 GMT"}, {"version": "v2", "created": "Tue, 12 Sep 2017 09:23:40 GMT"}], "update_date": "2017-09-13", "authors_parsed": [["Gupta", "Amit", ""], ["Lebret", "R\u00e9mi", ""], ["Harkous", "Hamza", ""], ["Aberer", "Karl", ""]]}, {"id": "1704.07626", "submitter": "Amit Gupta", "authors": "Amit Gupta, R\\'emi Lebret, Hamza Harkous and Karl Aberer", "title": "Taxonomy Induction using Hypernym Subsequences", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel, semi-supervised approach towards domain taxonomy\ninduction from an input vocabulary of seed terms. Unlike all previous\napproaches, which typically extract direct hypernym edges for terms, our\napproach utilizes a novel probabilistic framework to extract hypernym\nsubsequences. Taxonomy induction from extracted subsequences is cast as an\ninstance of the minimumcost flow problem on a carefully designed directed\ngraph. Through experiments, we demonstrate that our approach outperforms\nstateof- the-art taxonomy induction approaches across four languages.\nImportantly, we also show that our approach is robust to the presence of noise\nin the input vocabulary. To the best of our knowledge, no previous approaches\nhave been empirically proven to manifest noise-robustness in the input\nvocabulary.\n", "versions": [{"version": "v1", "created": "Tue, 25 Apr 2017 10:49:53 GMT"}, {"version": "v2", "created": "Fri, 5 May 2017 17:03:17 GMT"}, {"version": "v3", "created": "Fri, 26 May 2017 14:42:59 GMT"}, {"version": "v4", "created": "Thu, 14 Sep 2017 20:34:26 GMT"}], "update_date": "2017-09-18", "authors_parsed": [["Gupta", "Amit", ""], ["Lebret", "R\u00e9mi", ""], ["Harkous", "Hamza", ""], ["Aberer", "Karl", ""]]}, {"id": "1704.07751", "submitter": "Maxim Rabinovich", "authors": "Maxim Rabinovich, Dan Klein", "title": "Fine-Grained Entity Typing with High-Multiplicity Assignments", "comments": "ACL 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As entity type systems become richer and more fine-grained, we expect the\nnumber of types assigned to a given entity to increase. However, most\nfine-grained typing work has focused on datasets that exhibit a low degree of\ntype multiplicity. In this paper, we consider the high-multiplicity regime\ninherent in data sources such as Wikipedia that have semi-open type systems. We\nintroduce a set-prediction approach to this problem and show that our model\noutperforms unstructured baselines on a new Wikipedia-based fine-grained typing\ncorpus.\n", "versions": [{"version": "v1", "created": "Tue, 25 Apr 2017 15:52:52 GMT"}], "update_date": "2017-04-26", "authors_parsed": [["Rabinovich", "Maxim", ""], ["Klein", "Dan", ""]]}, {"id": "1704.07899", "submitter": "James Brusey", "authors": "James Brusey, Diana Hintea, Elena Gaura, Neil Beloe", "title": "Reinforcement Learning-based Thermal Comfort Control for Vehicle Cabins", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Vehicle climate control systems aim to keep passengers thermally comfortable.\nHowever, current systems control temperature rather than thermal comfort and\ntend to be energy hungry, which is of particular concern when considering\nelectric vehicles. This paper poses energy-efficient vehicle comfort control as\na Markov Decision Process, which is then solved numerically using\nSarsa({\\lambda}) and an empirically validated, single-zone, 1D thermal model of\nthe cabin. The resulting controller was tested in simulation using 200 randomly\nselected scenarios and found to exceed the performance of bang-bang,\nproportional, simple fuzzy logic, and commercial controllers with 23%, 43%,\n40%, 56% increase, respectively. Compared to the next best performing\ncontroller, energy consumption is reduced by 13% while the proportion of time\nspent thermally comfortable is increased by 23%. These results indicate that\nthis is a viable approach that promises to translate into substantial comfort\nand energy improvements in the car.\n", "versions": [{"version": "v1", "created": "Tue, 25 Apr 2017 20:24:17 GMT"}, {"version": "v2", "created": "Tue, 5 Sep 2017 11:02:03 GMT"}], "update_date": "2017-09-06", "authors_parsed": [["Brusey", "James", ""], ["Hintea", "Diana", ""], ["Gaura", "Elena", ""], ["Beloe", "Neil", ""]]}, {"id": "1704.07926", "submitter": "Kelvin Guu", "authors": "Kelvin Guu, Panupong Pasupat, Evan Zheran Liu, Percy Liang", "title": "From Language to Programs: Bridging Reinforcement Learning and Maximum\n  Marginal Likelihood", "comments": "Proceedings of the 55th Annual Meeting of the Association for\n  Computational Linguistics (2017)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Our goal is to learn a semantic parser that maps natural language utterances\ninto executable programs when only indirect supervision is available: examples\nare labeled with the correct execution result, but not the program itself.\nConsequently, we must search the space of programs for those that output the\ncorrect result, while not being misled by spurious programs: incorrect programs\nthat coincidentally output the correct result. We connect two common learning\nparadigms, reinforcement learning (RL) and maximum marginal likelihood (MML),\nand then present a new learning algorithm that combines the strengths of both.\nThe new algorithm guards against spurious programs by combining the systematic\nsearch traditionally employed in MML with the randomized exploration of RL, and\nby updating parameters such that probability is spread more evenly across\nconsistent programs. We apply our learning algorithm to a new neural semantic\nparser and show significant gains over existing state-of-the-art results on a\nrecent context-dependent semantic parsing task.\n", "versions": [{"version": "v1", "created": "Tue, 25 Apr 2017 22:51:12 GMT"}], "update_date": "2017-04-27", "authors_parsed": [["Guu", "Kelvin", ""], ["Pasupat", "Panupong", ""], ["Liu", "Evan Zheran", ""], ["Liang", "Percy", ""]]}, {"id": "1704.07950", "submitter": "Yi Zhou Dr.", "authors": "Yi Zhou", "title": "Structured Production System (extended abstract)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this extended abstract, we propose Structured Production Systems (SPS),\nwhich extend traditional production systems with well-formed syntactic\nstructures. Due to the richness of structures, structured production systems\nsignificantly enhance the expressive power as well as the flexibility of\nproduction systems, for instance, to handle uncertainty. We show that different\nrule application strategies can be reduced into the basic one by utilizing\nstructures. Also, many fundamental approaches in computer science, including\nautomata, grammar and logic, can be captured by structured production systems.\n", "versions": [{"version": "v1", "created": "Wed, 26 Apr 2017 02:39:07 GMT"}], "update_date": "2017-04-27", "authors_parsed": [["Zhou", "Yi", ""]]}, {"id": "1704.08045", "submitter": "Quynh Nguyen", "authors": "Quynh Nguyen and Matthias Hein", "title": "The loss surface of deep and wide neural networks", "comments": "ICML 2017. Main results now hold for larger classes of loss functions", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While the optimization problem behind deep neural networks is highly\nnon-convex, it is frequently observed in practice that training deep networks\nseems possible without getting stuck in suboptimal points. It has been argued\nthat this is the case as all local minima are close to being globally optimal.\nWe show that this is (almost) true, in fact almost all local minima are\nglobally optimal, for a fully connected network with squared loss and analytic\nactivation function given that the number of hidden units of one layer of the\nnetwork is larger than the number of training points and the network structure\nfrom this layer on is pyramidal.\n", "versions": [{"version": "v1", "created": "Wed, 26 Apr 2017 10:24:54 GMT"}, {"version": "v2", "created": "Mon, 12 Jun 2017 19:43:39 GMT"}], "update_date": "2017-06-14", "authors_parsed": [["Nguyen", "Quynh", ""], ["Hein", "Matthias", ""]]}, {"id": "1704.08092", "submitter": "Samuel R\\\"onnqvist", "authors": "Samuel R\\\"onnqvist, Niko Schenk, Christian Chiarcos", "title": "A Recurrent Neural Model with Attention for the Recognition of Chinese\n  Implicit Discourse Relations", "comments": "To appear at ACL2017, code available at\n  https://github.com/sronnqvist/discourse-ablstm", "journal-ref": null, "doi": "10.18653/v1/P17-2040", "report-no": "Proceedings of the 55th Annual Meeting of the Association for\n  Computational Linguistics (ACL'17)", "categories": "cs.CL cs.AI cs.LG cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We introduce an attention-based Bi-LSTM for Chinese implicit discourse\nrelations and demonstrate that modeling argument pairs as a joint sequence can\noutperform word order-agnostic approaches. Our model benefits from a partial\nsampling scheme and is conceptually simple, yet achieves state-of-the-art\nperformance on the Chinese Discourse Treebank. We also visualize its attention\nactivity to illustrate the model's ability to selectively focus on the relevant\nparts of an input sequence.\n", "versions": [{"version": "v1", "created": "Wed, 26 Apr 2017 13:10:12 GMT"}], "update_date": "2018-02-01", "authors_parsed": [["R\u00f6nnqvist", "Samuel", ""], ["Schenk", "Niko", ""], ["Chiarcos", "Christian", ""]]}, {"id": "1704.08101", "submitter": "Sebastiaan J. van Zelst", "authors": "Sebastiaan J. van Zelst, Boudewijn F. van Dongen, Wil M.P. van der\n  Aalst", "title": "Event Stream-Based Process Discovery using Abstract Representations", "comments": "Accepted for publication in \"Knowledge and Information Systems; \"\n  (Springer: http://link.springer.com/journal/10115)", "journal-ref": null, "doi": "10.1007/s10115-017-1060-2", "report-no": null, "categories": "cs.DB cs.AI cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The aim of process discovery, originating from the area of process mining, is\nto discover a process model based on business process execution data. A\nmajority of process discovery techniques relies on an event log as an input. An\nevent log is a static source of historical data capturing the execution of a\nbusiness process. In this paper we focus on process discovery relying on online\nstreams of business process execution events. Learning process models from\nevent streams poses both challenges and opportunities, i.e. we need to handle\nunlimited amounts of data using finite memory and, preferably, constant time.\nWe propose a generic architecture that allows for adopting several classes of\nexisting process discovery techniques in context of event streams. Moreover, we\nprovide several instantiations of the architecture, accompanied by\nimplementations in the process mining tool-kit ProM (http://promtools.org).\nUsing these instantiations, we evaluate several dimensions of stream-based\nprocess discovery. The evaluation shows that the proposed architecture allows\nus to lift process discovery to the streaming domain.\n", "versions": [{"version": "v1", "created": "Tue, 25 Apr 2017 12:10:35 GMT"}], "update_date": "2017-05-17", "authors_parsed": [["van Zelst", "Sebastiaan J.", ""], ["van Dongen", "Boudewijn F.", ""], ["van der Aalst", "Wil M. P.", ""]]}, {"id": "1704.08111", "submitter": "Steven Meyer", "authors": "Steven Meyer", "title": "A Popperian Falsification of Artificial Intelligence -- Lighthill\n  Defended", "comments": "12 pages. Version improves discussion of chess and adds sections on\n  when combinatorial explosion may not apply", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The area of computation called artificial intelligence (AI) is falsified by\ndescribing a previous 1972 falsification of AI by British mathematical\nphysicist James Lighthill. How Lighthill's arguments continue to apply to\ncurrent AI is explained. It is argued that AI should use the Popperian\nscientific method in which it is the duty of scientists to attempt to falsify\ntheories and if theories are falsified to replace or modify them. The paper\ndescribes the Popperian method and discusses Paul Nurse's application of the\nmethod to cell biology that also involves questions of mechanism and behavior.\nIt is shown how Lighthill's falsifying arguments especially combinatorial\nexplosion continue to apply to modern AI. Various skeptical arguments against\nthe assumptions of AI mostly by physicists especially against Hilbert's\nphilosophical programme that defined knowledge and truth as provable formal\nsentences. John von Neumann's arguments from natural complexity against neural\nnetworks and evolutionary algorithms are discussed. Next the game of chess is\ndiscussed to show how modern chess experts have reacted to computer chess\nprograms. It is shown that currently chess masters can defeat any chess program\nusing Kasperov's arguments from his 1997 Deep Blue match and aftermath. The\ngame of 'go' and climate models are discussed to show computer applications\nwhere combinatorial explosion may not apply. The paper concludes by advocating\nstudying computation as Peter Naur's Dataology.\n", "versions": [{"version": "v1", "created": "Sun, 23 Apr 2017 21:16:40 GMT"}, {"version": "v2", "created": "Wed, 18 Apr 2018 17:56:05 GMT"}, {"version": "v3", "created": "Thu, 30 Apr 2020 23:58:09 GMT"}], "update_date": "2020-05-04", "authors_parsed": [["Meyer", "Steven", ""]]}, {"id": "1704.08119", "submitter": "Salvatore Corrente", "authors": "Francesca Abastante, Salvatore Corrente, Salvatore Greco, Alessio\n  Ishizaka, Isabella Lami", "title": "Using a new parsimonious AHP methodology combined with the Choquet\n  integral: An application for evaluating social housing initiatives", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a development of the Analytic Hierarchy Process (AHP) permitting\nto use the methodology also in cases of decision problems with a very large\nnumber of alternatives evaluated with respect to several criteria. While the\napplication of the original AHP method involves many pairwise comparisons\nbetween alternatives and criteria, our proposal is composed of three steps: (i)\ndirect evaluation of the alternatives at hand on the considered criteria, (ii)\nselection of some reference evaluations; (iii) application of the original AHP\nmethod to reference evaluations; (iv) revision of the direct evaluation on the\nbasis of the prioritization supplied by AHP on reference evaluations. The new\nproposal has been tested and validated in an experiment conducted on a sample\nof university students. The new methodology has been therefore applied to a\nreal world problem involving the evaluation of 21 Social Housing initiatives\nsited in the Piedmont region (Italy). To take into account interaction between\ncriteria, the Choquet integral preference model has been considered within a\nNon Additive Robust Ordinal Regression approach.\n", "versions": [{"version": "v1", "created": "Mon, 24 Apr 2017 12:38:22 GMT"}], "update_date": "2017-04-27", "authors_parsed": [["Abastante", "Francesca", ""], ["Corrente", "Salvatore", ""], ["Greco", "Salvatore", ""], ["Ishizaka", "Alessio", ""], ["Lami", "Isabella", ""]]}, {"id": "1704.08165", "submitter": "Yotam Hechtlinger", "authors": "Yotam Hechtlinger, Purvasha Chakravarti and Jining Qin", "title": "A Generalization of Convolutional Neural Networks to Graph-Structured\n  Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces a generalization of Convolutional Neural Networks\n(CNNs) from low-dimensional grid data, such as images, to graph-structured\ndata. We propose a novel spatial convolution utilizing a random walk to uncover\nthe relations within the input, analogous to the way the standard convolution\nuses the spatial neighborhood of a pixel on the grid. The convolution has an\nintuitive interpretation, is efficient and scalable and can also be used on\ndata with varying graph structure. Furthermore, this generalization can be\napplied to many standard regression or classification problems, by learning the\nthe underlying graph. We empirically demonstrate the performance of the\nproposed CNN on MNIST, and challenge the state-of-the-art on Merck molecular\nactivity data set.\n", "versions": [{"version": "v1", "created": "Wed, 26 Apr 2017 15:37:50 GMT"}], "update_date": "2017-04-27", "authors_parsed": [["Hechtlinger", "Yotam", ""], ["Chakravarti", "Purvasha", ""], ["Qin", "Jining", ""]]}, {"id": "1704.08224", "submitter": "Arjun Chandrasekaran", "authors": "Arjun Chandrasekaran and Devi Parikh and Mohit Bansal", "title": "Punny Captions: Witty Wordplay in Image Descriptions", "comments": "NAACL 2018 (11 pages)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Wit is a form of rich interaction that is often grounded in a specific\nsituation (e.g., a comment in response to an event). In this work, we attempt\nto build computational models that can produce witty descriptions for a given\nimage. Inspired by a cognitive account of humor appreciation, we employ\nlinguistic wordplay, specifically puns, in image descriptions. We develop two\napproaches which involve retrieving witty descriptions for a given image from a\nlarge corpus of sentences, or generating them via an encoder-decoder neural\nnetwork architecture. We compare our approach against meaningful baseline\napproaches via human studies and show substantial improvements. We find that\nwhen a human is subject to similar constraints as the model regarding word\nusage and style, people vote the image descriptions generated by our model to\nbe slightly wittier than human-written witty descriptions. Unsurprisingly,\nhumans are almost always wittier than the model when they are free to choose\nthe vocabulary, style, etc.\n", "versions": [{"version": "v1", "created": "Wed, 26 Apr 2017 17:22:53 GMT"}, {"version": "v2", "created": "Thu, 31 May 2018 17:45:50 GMT"}], "update_date": "2018-06-01", "authors_parsed": [["Chandrasekaran", "Arjun", ""], ["Parikh", "Devi", ""], ["Bansal", "Mohit", ""]]}, {"id": "1704.08243", "submitter": "Aishwarya Agrawal", "authors": "Aishwarya Agrawal, Aniruddha Kembhavi, Dhruv Batra, Devi Parikh", "title": "C-VQA: A Compositional Split of the Visual Question Answering (VQA) v1.0\n  Dataset", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Visual Question Answering (VQA) has received a lot of attention over the past\ncouple of years. A number of deep learning models have been proposed for this\ntask. However, it has been shown that these models are heavily driven by\nsuperficial correlations in the training data and lack compositionality -- the\nability to answer questions about unseen compositions of seen concepts. This\ncompositionality is desirable and central to intelligence. In this paper, we\npropose a new setting for Visual Question Answering where the test\nquestion-answer pairs are compositionally novel compared to training\nquestion-answer pairs. To facilitate developing models under this setting, we\npresent a new compositional split of the VQA v1.0 dataset, which we call\nCompositional VQA (C-VQA). We analyze the distribution of questions and answers\nin the C-VQA splits. Finally, we evaluate several existing VQA models under\nthis new setting and show that the performances of these models degrade by a\nsignificant amount compared to the original VQA setting.\n", "versions": [{"version": "v1", "created": "Wed, 26 Apr 2017 17:57:59 GMT"}], "update_date": "2017-04-27", "authors_parsed": [["Agrawal", "Aishwarya", ""], ["Kembhavi", "Aniruddha", ""], ["Batra", "Dhruv", ""], ["Parikh", "Devi", ""]]}, {"id": "1704.08350", "submitter": "Vasanth Sarathy", "authors": "Vasanth Sarathy and Matthias Scheutz", "title": "The MacGyver Test - A Framework for Evaluating Machine Resourcefulness\n  and Creative Problem Solving", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current measures of machine intelligence are either difficult to evaluate or\nlack the ability to test a robot's problem-solving capacity in open worlds. We\npropose a novel evaluation framework based on the formal notion of MacGyver\nTest which provides a practical way for assessing the resilience and\nresourcefulness of artificial agents.\n", "versions": [{"version": "v1", "created": "Wed, 26 Apr 2017 21:05:27 GMT"}], "update_date": "2017-04-28", "authors_parsed": [["Sarathy", "Vasanth", ""], ["Scheutz", "Matthias", ""]]}, {"id": "1704.08389", "submitter": "Lydia Manikonda", "authors": "Lydia Manikonda, Cameron Dudley, Subbarao Kambhampati", "title": "Tweeting AI: Perceptions of AI-Tweeters (AIT) vs Expert AI-Tweeters\n  (EAIT)", "comments": "New results at arXiv:1709.09534", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CY cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the recent advancements in Artificial Intelligence (AI), various\norganizations and individuals started debating about the progress of AI as a\nblessing or a curse for the future of the society. This paper conducts an\ninvestigation on how the public perceives the progress of AI by utilizing the\ndata shared on Twitter. Specifically, this paper performs a comparative\nanalysis on the understanding of users from two categories -- general\nAI-Tweeters (AIT) and the expert AI-Tweeters (EAIT) who share posts about AI on\nTwitter. Our analysis revealed that users from both the categories express\ndistinct emotions and interests towards AI. Users from both the categories\nregard AI as positive and are optimistic about the progress of AI but the\nexperts are more negative than the general AI-Tweeters. Characterization of\nusers manifested that `London' is the popular location of users from where they\ntweet about AI. Tweets posted by AIT are highly retweeted than posts made by\nEAIT that reveals greater diffusion of information from AIT.\n", "versions": [{"version": "v1", "created": "Thu, 27 Apr 2017 00:37:05 GMT"}, {"version": "v2", "created": "Thu, 28 Sep 2017 02:06:08 GMT"}], "update_date": "2017-09-29", "authors_parsed": [["Manikonda", "Lydia", ""], ["Dudley", "Cameron", ""], ["Kambhampati", "Subbarao", ""]]}, {"id": "1704.08424", "submitter": "Ben Athiwaratkun", "authors": "Ben Athiwaratkun, Andrew Gordon Wilson", "title": "Multimodal Word Distributions", "comments": "This paper also appears at ACL 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Word embeddings provide point representations of words containing useful\nsemantic information. We introduce multimodal word distributions formed from\nGaussian mixtures, for multiple word meanings, entailment, and rich uncertainty\ninformation. To learn these distributions, we propose an energy-based\nmax-margin objective. We show that the resulting approach captures uniquely\nexpressive semantic information, and outperforms alternatives, such as word2vec\nskip-grams, and Gaussian embeddings, on benchmark datasets such as word\nsimilarity and entailment.\n", "versions": [{"version": "v1", "created": "Thu, 27 Apr 2017 03:59:54 GMT"}, {"version": "v2", "created": "Mon, 9 Sep 2019 17:56:33 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["Athiwaratkun", "Ben", ""], ["Wilson", "Andrew Gordon", ""]]}, {"id": "1704.08464", "submitter": "Zhiwei Lin", "authors": "Zhiwei Lin, Yi Li, and Xiaolian Guo", "title": "Consensus measure of rankings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A ranking is an ordered sequence of items, in which an item with higher\nranking score is more preferred than the items with lower ranking scores. In\nmany information systems, rankings are widely used to represent the preferences\nover a set of items or candidates. The consensus measure of rankings is the\nproblem of how to evaluate the degree to which the rankings agree. The\nconsensus measure can be used to evaluate rankings in many information systems,\nas quite often there is not ground truth available for evaluation.\n  This paper introduces a novel approach for consensus measure of rankings by\nusing graph representation, in which the vertices or nodes are the items and\nthe edges are the relationship of items in the rankings. Such representation\nleads to various algorithms for consensus measure in terms of different aspects\nof rankings, including the number of common patterns, the number of common\npatterns with fixed length and the length of the longest common patterns. The\nproposed measure can be adopted for various types of rankings, such as full\nrankings, partial rankings and rankings with ties. This paper demonstrates how\nthe proposed approaches can be used to evaluate the quality of rank aggregation\nand the quality of top-$k$ rankings from Google and Bing search engines.\n", "versions": [{"version": "v1", "created": "Thu, 27 Apr 2017 07:58:47 GMT"}, {"version": "v2", "created": "Thu, 21 Sep 2017 17:09:37 GMT"}], "update_date": "2017-09-22", "authors_parsed": [["Lin", "Zhiwei", ""], ["Li", "Yi", ""], ["Guo", "Xiaolian", ""]]}, {"id": "1704.08483", "submitter": "Zolt\\'an Kov\\'acs", "authors": "Zolt\\'an Kov\\'acs", "title": "No, This is not a Circle", "comments": "12 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.HO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A popular curve shown in introductory maths textbooks, seems like a circle.\nBut it is actually a different curve. This paper discusses some elementary\napproaches to identify the geometric object, including novel technological\nmeans by using GeoGebra. We demonstrate two ways to refute the false\nimpression, two suggestions to find a correct conjecture, and four ways to\nconfirm the result by proving it rigorously.\n  All of the discussed approaches can be introduced in classrooms at various\nlevels from middle school to high school.\n", "versions": [{"version": "v1", "created": "Thu, 27 Apr 2017 09:04:10 GMT"}, {"version": "v2", "created": "Sun, 30 Apr 2017 14:53:07 GMT"}, {"version": "v3", "created": "Sat, 13 May 2017 16:43:02 GMT"}], "update_date": "2017-05-16", "authors_parsed": [["Kov\u00e1cs", "Zolt\u00e1n", ""]]}, {"id": "1704.08509", "submitter": "Bo-Cheng Tsai", "authors": "Yi-Hsin Chen, Wei-Yu Chen, Yu-Ting Chen, Bo-Cheng Tsai, Yu-Chiang\n  Frank Wang, Min Sun", "title": "No More Discrimination: Cross City Adaptation of Road Scene Segmenters", "comments": "13 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the recent success of deep-learning based semantic segmentation,\ndeploying a pre-trained road scene segmenter to a city whose images are not\npresented in the training set would not achieve satisfactory performance due to\ndataset biases. Instead of collecting a large number of annotated images of\neach city of interest to train or refine the segmenter, we propose an\nunsupervised learning approach to adapt road scene segmenters across different\ncities. By utilizing Google Street View and its time-machine feature, we can\ncollect unannotated images for each road scene at different times, so that the\nassociated static-object priors can be extracted accordingly. By advancing a\njoint global and class-specific domain adversarial learning framework,\nadaptation of pre-trained segmenters to that city can be achieved without the\nneed of any user annotation or interaction. We show that our method improves\nthe performance of semantic segmentation in multiple cities across continents,\nwhile it performs favorably against state-of-the-art approaches requiring\nannotated training data.\n", "versions": [{"version": "v1", "created": "Thu, 27 Apr 2017 11:14:21 GMT"}], "update_date": "2017-04-28", "authors_parsed": [["Chen", "Yi-Hsin", ""], ["Chen", "Wei-Yu", ""], ["Chen", "Yu-Ting", ""], ["Tsai", "Bo-Cheng", ""], ["Wang", "Yu-Chiang Frank", ""], ["Sun", "Min", ""]]}, {"id": "1704.08544", "submitter": "Borislav Hristov", "authors": "Borislav H. Hristov and Mona Singh", "title": "Network-based coverage of mutational profiles reveals cancer genes", "comments": "RECOMB 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.GN cs.AI q-bio.MN", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A central goal in cancer genomics is to identify the somatic alterations that\nunderpin tumor initiation and progression. This task is challenging as the\nmutational profiles of cancer genomes exhibit vast heterogeneity, with many\nalterations observed within each individual, few shared somatically mutated\ngenes across individuals, and important roles in cancer for both frequently and\ninfrequently mutated genes. While commonly mutated cancer genes are readily\nidentifiable, those that are rarely mutated across samples are difficult to\ndistinguish from the large numbers of other infrequently mutated genes. Here,\nwe introduce a method that considers per-individual mutational profiles within\nthe context of protein-protein interaction networks in order to identify small\nconnected subnetworks of genes that, while not individually frequently mutated,\ncomprise pathways that are perturbed across (i.e., \"cover\") a large fraction of\nthe individuals. We devise a simple yet intuitive objective function that\nbalances identifying a small subset of genes with covering a large fraction of\nindividuals. We show how to solve this problem optimally using integer linear\nprogramming and also give a fast heuristic algorithm that works well in\npractice. We perform a large-scale evaluation of our resulting method, nCOP, on\n6,038 TCGA tumor samples across 24 different cancer types. We demonstrate that\nour approach nCOP is more effective in identifying cancer genes than both\nmethods that do not utilize any network information as well as state-of-the-art\nnetwork-based methods that aggregate mutational information across individuals.\nOverall, our work demonstrates the power of combining per-individual mutational\ninformation with interaction networks in order to uncover genes functionally\nrelevant in cancers, and in particular those genes that are less frequently\nmutated.\n", "versions": [{"version": "v1", "created": "Wed, 26 Apr 2017 15:47:57 GMT"}], "update_date": "2017-04-28", "authors_parsed": [["Hristov", "Borislav H.", ""], ["Singh", "Mona", ""]]}, {"id": "1704.08588", "submitter": "Sabah Al-Fedaghi Dr.", "authors": "Sabah Al-Fedaghi", "title": "Modeling Events as Machines", "comments": null, "journal-ref": "International Journal of Computer Science and Information\n  Security, Volume 15 No. 4, April 2017", "doi": null, "report-no": null, "categories": "cs.AI cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The notion of events has occupied a central role in modeling and has an\ninfluence in computer science and philosophy. Recent developments in\ndiagrammatic modeling have made it possible to examine conceptual\nrepresentation of events. This paper explores some aspects of the notion of\nevents that are produced by applying a new diagrammatic methodology with a\nfocus on the interaction of events with such concepts as time and space,\nobjects. The proposed description applies to abstract machines where events\nform the dynamic phases of a system. The results of this nontechnical research\ncan be utilized in many fields where the notion of an event is typically used\nin interdisciplinary application.\n", "versions": [{"version": "v1", "created": "Wed, 26 Apr 2017 12:50:51 GMT"}], "update_date": "2017-04-28", "authors_parsed": [["Al-Fedaghi", "Sabah", ""]]}, {"id": "1704.08676", "submitter": "Daniele Ramazzotti", "authors": "Stefano Beretta and Mauro Castelli and Ivo Goncalves and Roberto\n  Henriques and Daniele Ramazzotti", "title": "Learning the structure of Bayesian Networks: A quantitative assessment\n  of the effect of different algorithmic schemes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the most challenging tasks when adopting Bayesian Networks (BNs) is\nthe one of learning their structure from data. This task is complicated by the\nhuge search space of possible solutions, and by the fact that the problem is\nNP-hard. Hence, full enumeration of all the possible solutions is not always\nfeasible and approximations are often required. However, to the best of our\nknowledge, a quantitative analysis of the performance and characteristics of\nthe different heuristics to solve this problem has never been done before.\n  For this reason, in this work, we provide a detailed comparison of many\ndifferent state-of-the-arts methods for structural learning on simulated data\nconsidering both BNs with discrete and continuous variables, and with different\nrates of noise in the data. In particular, we investigate the performance of\ndifferent widespread scores and algorithmic approaches proposed for the\ninference and the statistical pitfalls within them.\n", "versions": [{"version": "v1", "created": "Thu, 27 Apr 2017 17:40:22 GMT"}, {"version": "v2", "created": "Fri, 3 Aug 2018 20:16:37 GMT"}], "update_date": "2018-08-07", "authors_parsed": [["Beretta", "Stefano", ""], ["Castelli", "Mauro", ""], ["Goncalves", "Ivo", ""], ["Henriques", "Roberto", ""], ["Ramazzotti", "Daniele", ""]]}, {"id": "1704.08716", "submitter": "Brian Ruttenberg", "authors": "Avi Pfeffer, Brian Ruttenberg, Lee Kellogg, Michael Howard, Catherine\n  Call, Alison O'Connor, Glenn Takata, Scott Neal Reilly, Terry Patten, Jason\n  Taylor, Robert Hall, Arun Lakhotia, Craig Miles, Dan Scofield, Jared Frank", "title": "Artificial Intelligence Based Malware Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Artificial intelligence methods have often been applied to perform specific\nfunctions or tasks in the cyber-defense realm. However, as adversary methods\nbecome more complex and difficult to divine, piecemeal efforts to understand\ncyber-attacks, and malware-based attacks in particular, are not providing\nsufficient means for malware analysts to understand the past, present and\nfuture characteristics of malware.\n  In this paper, we present the Malware Analysis and Attributed using Genetic\nInformation (MAAGI) system. The underlying idea behind the MAAGI system is that\nthere are strong similarities between malware behavior and biological organism\nbehavior, and applying biologically inspired methods to corpora of malware can\nhelp analysts better understand the ecosystem of malware attacks. Due to the\nsophistication of the malware and the analysis, the MAAGI system relies heavily\non artificial intelligence techniques to provide this capability. It has\nalready yielded promising results over its development life, and will hopefully\ninspire more integration between the artificial intelligence and cyber--defense\ncommunities.\n", "versions": [{"version": "v1", "created": "Thu, 27 Apr 2017 18:53:37 GMT"}], "update_date": "2017-05-01", "authors_parsed": [["Pfeffer", "Avi", ""], ["Ruttenberg", "Brian", ""], ["Kellogg", "Lee", ""], ["Howard", "Michael", ""], ["Call", "Catherine", ""], ["O'Connor", "Alison", ""], ["Takata", "Glenn", ""], ["Reilly", "Scott Neal", ""], ["Patten", "Terry", ""], ["Taylor", "Jason", ""], ["Hall", "Robert", ""], ["Lakhotia", "Arun", ""], ["Miles", "Craig", ""], ["Scofield", "Dan", ""], ["Frank", "Jared", ""]]}, {"id": "1704.08772", "submitter": "Grigorios Chrysos", "authors": "Grigorios G. Chrysos, Stefanos Zafeiriou", "title": "Deep Face Deblurring", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Blind deblurring consists a long studied task, however the outcomes of\ngeneric methods are not effective in real world blurred images. Domain-specific\nmethods for deblurring targeted object categories, e.g. text or faces,\nfrequently outperform their generic counterparts, hence they are attracting an\nincreasing amount of attention. In this work, we develop such a domain-specific\nmethod to tackle deblurring of human faces, henceforth referred to as face\ndeblurring. Studying faces is of tremendous significance in computer vision,\nhowever face deblurring has yet to demonstrate some convincing results. This\ncan be partly attributed to the combination of i) poor texture and ii) highly\nstructure shape that yield the contour/gradient priors (that are typically\nused) sub-optimal. In our work instead of making assumptions over the prior, we\nadopt a learning approach by inserting weak supervision that exploits the\nwell-documented structure of the face. Namely, we utilise a deep network to\nperform the deblurring and employ a face alignment technique to pre-process\neach face. We additionally surpass the requirement of the deep network for\nthousands training samples, by introducing an efficient framework that allows\nthe generation of a large dataset. We utilised this framework to create 2MF2, a\ndataset of over two million frames. We conducted experiments with real world\nblurred facial images and report that our method returns a result close to the\nsharp natural latent image.\n", "versions": [{"version": "v1", "created": "Thu, 27 Apr 2017 23:01:45 GMT"}, {"version": "v2", "created": "Thu, 25 May 2017 07:45:36 GMT"}], "update_date": "2017-05-26", "authors_parsed": [["Chrysos", "Grigorios G.", ""], ["Zafeiriou", "Stefanos", ""]]}, {"id": "1704.08847", "submitter": "Moustapha Cisse", "authors": "Moustapha Cisse, Piotr Bojanowski, Edouard Grave, Yann Dauphin,\n  Nicolas Usunier", "title": "Parseval Networks: Improving Robustness to Adversarial Examples", "comments": "submitted", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce Parseval networks, a form of deep neural networks in which the\nLipschitz constant of linear, convolutional and aggregation layers is\nconstrained to be smaller than 1. Parseval networks are empirically and\ntheoretically motivated by an analysis of the robustness of the predictions\nmade by deep neural networks when their input is subject to an adversarial\nperturbation. The most important feature of Parseval networks is to maintain\nweight matrices of linear and convolutional layers to be (approximately)\nParseval tight frames, which are extensions of orthogonal matrices to\nnon-square matrices. We describe how these constraints can be maintained\nefficiently during SGD. We show that Parseval networks match the\nstate-of-the-art in terms of accuracy on CIFAR-10/100 and Street View House\nNumbers (SVHN) while being more robust than their vanilla counterpart against\nadversarial examples. Incidentally, Parseval networks also tend to train faster\nand make a better usage of the full capacity of the networks.\n", "versions": [{"version": "v1", "created": "Fri, 28 Apr 2017 08:43:55 GMT"}, {"version": "v2", "created": "Tue, 2 May 2017 01:11:21 GMT"}], "update_date": "2017-08-08", "authors_parsed": [["Cisse", "Moustapha", ""], ["Bojanowski", "Piotr", ""], ["Grave", "Edouard", ""], ["Dauphin", "Yann", ""], ["Usunier", "Nicolas", ""]]}, {"id": "1704.08914", "submitter": "Ehsaneddin Asgari", "authors": "Ehsaneddin Asgari and Hinrich Sch\\\"utze", "title": "Past, Present, Future: A Computational Investigation of the Typology of\n  Tense in 1000 Languages", "comments": null, "journal-ref": "Extended version of EMNLP 2017", "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present SuperPivot, an analysis method for low-resource languages that\noccur in a superparallel corpus, i.e., in a corpus that contains an order of\nmagnitude more languages than parallel corpora currently in use. We show that\nSuperPivot performs well for the crosslingual analysis of the linguistic\nphenomenon of tense. We produce analysis results for more than 1000 languages,\nconducting - to the best of our knowledge - the largest crosslingual\ncomputational study performed to date. We extend existing methodology for\nleveraging parallel corpora for typological analysis by overcoming a limiting\nassumption of earlier work: We only require that a linguistic feature is\novertly marked in a few of thousands of languages as opposed to requiring that\nit be marked in all languages under investigation.\n", "versions": [{"version": "v1", "created": "Fri, 28 Apr 2017 13:11:09 GMT"}, {"version": "v2", "created": "Thu, 14 Sep 2017 17:20:41 GMT"}], "update_date": "2017-09-15", "authors_parsed": [["Asgari", "Ehsaneddin", ""], ["Sch\u00fctze", "Hinrich", ""]]}, {"id": "1704.08950", "submitter": "Amit Kumar", "authors": "Amit Kumar, Rahul Dutta, Harbhajan Rai", "title": "Intelligent Personal Assistant with Knowledge Navigation", "comments": "Converted O(N3) solution to viable O(N) solution", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An Intelligent Personal Agent (IPA) is an agent that has the purpose of\nhelping the user to gain information through reliable resources with the help\nof knowledge navigation techniques and saving time to search the best content.\nThe agent is also responsible for responding to the chat-based queries with the\nhelp of Conversation Corpus. We will be testing different methods for optimal\nquery generation. To felicitate the ease of usage of the application, the agent\nwill be able to accept the input through Text (Keyboard), Voice (Speech\nRecognition) and Server (Facebook) and output responses using the same method.\nExisting chat bots reply by making changes in the input, but we will give\nresponses based on multiple SRT files. The model will learn using the human\ndialogs dataset and will be able respond human-like. Responses to queries about\nfamous things (places, people, and words) can be provided using web scraping\nwhich will enable the bot to have knowledge navigation features. The agent will\neven learn from its past experiences supporting semi-supervised learning.\n", "versions": [{"version": "v1", "created": "Fri, 28 Apr 2017 14:26:12 GMT"}], "update_date": "2017-05-01", "authors_parsed": [["Kumar", "Amit", ""], ["Dutta", "Rahul", ""], ["Rai", "Harbhajan", ""]]}, {"id": "1704.08966", "submitter": "Pierre Lison", "authors": "Pierre Lison, Serge Bibauw", "title": "Not All Dialogues are Created Equal: Instance Weighting for Neural\n  Conversational Models", "comments": "Accepted to SIGDIAL 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural conversational models require substantial amounts of dialogue data for\ntheir parameter estimation and are therefore usually learned on large corpora\nsuch as chat forums or movie subtitles. These corpora are, however, often\nchallenging to work with, notably due to their frequent lack of turn\nsegmentation and the presence of multiple references external to the dialogue\nitself. This paper shows that these challenges can be mitigated by adding a\nweighting model into the architecture. The weighting model, which is itself\nestimated from dialogue data, associates each training example to a numerical\nweight that reflects its intrinsic quality for dialogue modelling. At training\ntime, these sample weights are included into the empirical loss to be\nminimised. Evaluation results on retrieval-based models trained on movie and TV\nsubtitles demonstrate that the inclusion of such a weighting model improves the\nmodel performance on unsupervised metrics.\n", "versions": [{"version": "v1", "created": "Fri, 28 Apr 2017 14:57:29 GMT"}, {"version": "v2", "created": "Sat, 15 Jul 2017 17:27:13 GMT"}], "update_date": "2017-07-18", "authors_parsed": [["Lison", "Pierre", ""], ["Bibauw", "Serge", ""]]}]