[{"id": "1906.00025", "submitter": "Heinrich Jiang", "authors": "Heinrich Jiang, Maya Gupta", "title": "Minimum-Margin Active Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new active sampling method we call min-margin which trains\nmultiple learners on bootstrap samples and then chooses the examples to label\nbased on the candidates' minimum margin amongst the bootstrapped models. This\nextends standard margin sampling in a way that increases its diversity in a\nsupervised manner as it arises from the model uncertainty. We focus on the\none-shot batch active learning setting, and show theoretically and through\nextensive experiments on a broad set of problems that min-margin outperforms\nother methods, particularly as batch size grows.\n", "versions": [{"version": "v1", "created": "Fri, 31 May 2019 18:32:18 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Jiang", "Heinrich", ""], ["Gupta", "Maya", ""]]}, {"id": "1906.00078", "submitter": "Dali Wang", "authors": "Dali Wang, Zheng Lu, Zhirong Bao", "title": "Augmenting C. elegans Microscopic Dataset for Accelerated Pattern\n  Recognition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The detection of cell shape changes in 3D time-lapse images of complex\ntissues is an important task. However, it is a challenging and tedious task to\nestablish a comprehensive dataset to improve the performance of deep learning\nmodels. In the paper, we present a deep learning approach to augment 3D live\nimages of the Caenorhabditis elegans embryo, so that we can further speed up\nthe specific structural pattern recognition. We use an unsupervised training\nover unlabeled images to generate supplementary datasets for further pattern\nrecognition. Technically, we used Alex-style neural networks in a generative\nadversarial network framework to generate new datasets that have common\nfeatures of the C. elegans membrane structure. We also made the dataset\navailable for a broad scientific community.\n", "versions": [{"version": "v1", "created": "Fri, 31 May 2019 20:58:52 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Wang", "Dali", ""], ["Lu", "Zheng", ""], ["Bao", "Zhirong", ""]]}, {"id": "1906.00098", "submitter": "Hao Wang", "authors": "Hao Wang, Linlin Zong, Bing Liu, Yan Yang and Wei Zhou", "title": "Spectral Perturbation Meets Incomplete Multi-view Data", "comments": "to appear in IJCAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Beyond existing multi-view clustering, this paper studies a more realistic\nclustering scenario, referred to as incomplete multi-view clustering, where a\nnumber of data instances are missing in certain views. To tackle this problem,\nwe explore spectral perturbation theory. In this work, we show a strong link\nbetween perturbation risk bounds and incomplete multi-view clustering. That is,\nas the similarity matrix fed into spectral clustering is a quantity bounded in\nmagnitude O(1), we transfer the missing problem from data to similarity and\ntailor a matrix completion method for incomplete similarity matrix. Moreover,\nwe show that the minimization of perturbation risk bounds among different views\nmaximizes the final fusion result across all views. This provides a solid\nfusion criteria for multi-view data. We motivate and propose a\nPerturbation-oriented Incomplete multi-view Clustering (PIC) method.\nExperimental results demonstrate the effectiveness of the proposed method.\n", "versions": [{"version": "v1", "created": "Fri, 31 May 2019 22:05:39 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Wang", "Hao", ""], ["Zong", "Linlin", ""], ["Liu", "Bing", ""], ["Yang", "Yan", ""], ["Zhou", "Wei", ""]]}, {"id": "1906.00107", "submitter": "Mehul Bhatt", "authors": "Jakob Suchan, Mehul Bhatt, and Srikrishna Varadarajan", "title": "Out of Sight But Not Out of Mind: An Answer Set Programming Based Online\n  Abduction Framework for Visual Sensemaking in Autonomous Driving", "comments": "IJCAI 2019: the 28th International Joint Conference on Artificial\n  Intelligence (IJCAI) 2019, August 10 - 16, Macao. (Preprint / to appear)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CV cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We demonstrate the need and potential of systematically integrated vision and\nsemantics} solutions for visual sensemaking (in the backdrop of autonomous\ndriving). A general method for online visual sensemaking using answer set\nprogramming is systematically formalised and fully implemented. The method\nintegrates state of the art in (deep learning based) visual computing, and is\ndeveloped as a modular framework usable within hybrid architectures for\nperception & control. We evaluate and demo with community established\nbenchmarks KITTIMOD and MOT. As use-case, we focus on the significance of\nhuman-centred visual sensemaking ---e.g., semantic representation and\nexplainability, question-answering, commonsense interpolation--- in\nsafety-critical autonomous driving situations.\n", "versions": [{"version": "v1", "created": "Fri, 31 May 2019 22:23:15 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Suchan", "Jakob", ""], ["Bhatt", "Mehul", ""], ["Varadarajan", "Srikrishna", ""]]}, {"id": "1906.00128", "submitter": "Boli Fang", "authors": "Boli Fang, Miao Jiang, Jerry Shen", "title": "Achieving Fairness in Determining Medicaid Eligibility through Fairgroup\n  Construction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Effective complements to human judgment, artificial intelligence techniques\nhave started to aid human decisions in complicated social problems across the\nworld. In the context of United States for instance, automated ML/DL\nclassification models offer complements to human decisions in determining\nMedicaid eligibility. However, given the limitations in ML/DL model design,\nthese algorithms may fail to leverage various factors for decision making,\nresulting in improper decisions that allocate resources to individuals who may\nnot be in the most need. In view of such an issue, we propose in this paper the\nmethod of \\textit{fairgroup construction}, based on the legal doctrine of\n\\textit{disparate impact}, to improve the fairness of regressive classifiers.\nExperiments on American Community Survey dataset demonstrate that our method\ncould be easily adapted to a variety of regressive classification models to\nboost their fairness in deciding Medicaid Eligibility, while maintaining high\nlevels of classification accuracy.\n", "versions": [{"version": "v1", "created": "Sat, 1 Jun 2019 01:54:19 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Fang", "Boli", ""], ["Jiang", "Miao", ""], ["Shen", "Jerry", ""]]}, {"id": "1906.00131", "submitter": "Arsh Javed Rehman", "authors": "Arsh Javed Rehman, Pradeep Tomar", "title": "Decision-Making in Reinforcement Learning", "comments": "4 pages, 1 figure", "journal-ref": null, "doi": "10.13140/RG.2.2.12367.33443", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this research work, probabilistic decision-making approaches are studied,\ne.g. Bayesian and Boltzmann strategies, along with various deterministic\nexploration strategies, e.g. greedy, epsilon-Greedy and random approaches. In\nthis research work, a comparative study has been done between probabilistic and\ndeterministic decision-making approaches, the experiments are performed in\nOpenAI gym environment, solving Cart Pole problem. This research work discusses\nabout the Bayesian approach to decision-making in deep reinforcement learning,\nand about dropout, how it can reduce the computational cost. All the\nexploration approaches are compared. It also discusses about the importance of\nexploration in deep reinforcement learning, and how improving exploration\nstrategies may help in science and technology. This research work shows how\nprobabilistic decision-making approaches are better in the long run as compared\nto the deterministic approaches. When there is uncertainty, Bayesian dropout\napproach proved to be better than all other approaches in this research work.\n", "versions": [{"version": "v1", "created": "Sat, 1 Jun 2019 02:36:42 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Rehman", "Arsh Javed", ""], ["Tomar", "Pradeep", ""]]}, {"id": "1906.00137", "submitter": "Bahare Fatemi", "authors": "Bahare Fatemi, Perouz Taslakian, David Vazquez, and David Poole", "title": "Knowledge Hypergraphs: Prediction Beyond Binary Relations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge graphs store facts using relations between two entities. In this\nwork, we address the question of link prediction in knowledge hypergraphs where\nrelations are defined on any number of entities. While techniques exist (such\nas reification) that convert non-binary relations into binary ones, we show\nthat current embedding-based methods for knowledge graph completion do not work\nwell out of the box for knowledge graphs obtained through these techniques. To\novercome this, we introduce HSimplE and HypE, two embedding-based methods that\nwork directly with knowledge hypergraphs. In both models, the prediction is a\nfunction of the relation embedding, the entity embeddings and their\ncorresponding positions in the relation. We also develop public datasets,\nbenchmarks and baselines for hypergraph prediction and show experimentally that\nthe proposed models are more effective than the baselines.\n", "versions": [{"version": "v1", "created": "Sat, 1 Jun 2019 03:03:15 GMT"}, {"version": "v2", "created": "Thu, 26 Sep 2019 20:33:33 GMT"}, {"version": "v3", "created": "Wed, 15 Jul 2020 13:39:31 GMT"}], "update_date": "2020-07-16", "authors_parsed": [["Fatemi", "Bahare", ""], ["Taslakian", "Perouz", ""], ["Vazquez", "David", ""], ["Poole", "David", ""]]}, {"id": "1906.00140", "submitter": "Xin Huang", "authors": "Soroush Ebadian, Xin Huang", "title": "Fast Algorithm for K-Truss Discovery on Public-Private Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.AI cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In public-private graphs, users share one public graph and have their own\nprivate graphs. A private graph consists of personal private contacts that only\ncan be visible to its owner, e.g., hidden friend lists on Facebook and secret\nfollowing on Sina Weibo. However, existing public-private analytic algorithms\nhave not yet investigated the dense subgraph discovery of k-truss, where each\nedge is contained in at least k-2 triangles. This paper aims at finding k-truss\nefficiently in public-private graphs. The core of our solution is a novel\nalgorithm to update k-truss with node insertions. We develop a\nclassification-based hybrid strategy of node insertions and edge insertions to\nincrementally compute k-truss in public-private graphs. Extensive experiments\nvalidate the superiority of our proposed algorithms against state-of-the-art\nmethods on real-world datasets.\n", "versions": [{"version": "v1", "created": "Sat, 1 Jun 2019 03:31:06 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Ebadian", "Soroush", ""], ["Huang", "Xin", ""]]}, {"id": "1906.00163", "submitter": "Mukund Raghothaman", "authors": "Xujie Si, Mukund Raghothaman, Kihong Heo, Mayur Naik", "title": "Synthesizing Datalog Programs Using Numerical Relaxation", "comments": "Per editor's instructions, this is only an early preprint of the\n  paper which will be presented at IJCAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of learning logical rules from examples arises in diverse fields,\nincluding program synthesis, logic programming, and machine learning. Existing\napproaches either involve solving computationally difficult combinatorial\nproblems, or performing parameter estimation in complex statistical models.\n  In this paper, we present Difflog, a technique to extend the logic\nprogramming language Datalog to the continuous setting. By attaching\nreal-valued weights to individual rules of a Datalog program, we naturally\nassociate numerical values with individual conclusions of the program.\nAnalogous to the strategy of numerical relaxation in optimization problems, we\ncan now first determine the rule weights which cause the best agreement between\nthe training labels and the induced values of output tuples, and subsequently\nrecover the classical discrete-valued target program from the continuous\noptimum.\n  We evaluate Difflog on a suite of 34 benchmark problems from recent\nliterature in knowledge discovery, formal verification, and database\nquery-by-example, and demonstrate significant improvements in learning complex\nprograms with recursive rules, invented predicates, and relations of arbitrary\narity.\n", "versions": [{"version": "v1", "created": "Sat, 1 Jun 2019 06:42:05 GMT"}, {"version": "v2", "created": "Tue, 25 Jun 2019 08:34:46 GMT"}], "update_date": "2019-06-26", "authors_parsed": [["Si", "Xujie", ""], ["Raghothaman", "Mukund", ""], ["Heo", "Kihong", ""], ["Naik", "Mayur", ""]]}, {"id": "1906.00179", "submitter": "Diego Calvanese", "authors": "Diego Calvanese, Davide Lanti, Ana Ozaki, Rafael Penaloza, Guohui Xiao", "title": "Enriching Ontology-based Data Access with Provenance (Extended Version)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ontology-based data access (OBDA) is a popular paradigm for querying\nheterogeneous data sources by connecting them through mappings to an ontology.\nIn OBDA, it is often difficult to reconstruct why a tuple occurs in the answer\nof a query. We address this challenge by enriching OBDA with provenance\nsemirings, taking inspiration from database theory. In particular, we\ninvestigate the problems of (i) deciding whether a provenance annotated OBDA\ninstance entails a provenance annotated conjunctive query, and (ii) computing a\npolynomial representing the provenance of a query entailed by a provenance\nannotated OBDA instance. Differently from pure databases, in our case these\npolynomials may be infinite. To regain finiteness, we consider idempotent\nsemirings, and study the complexity in the case of DL-Lite ontologies. We\nimplement Task (ii) in a state-of-the-art OBDA system and show the practical\nfeasibility of the approach through an extensive evaluation against two popular\nbenchmarks.\n", "versions": [{"version": "v1", "created": "Sat, 1 Jun 2019 08:15:48 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Calvanese", "Diego", ""], ["Lanti", "Davide", ""], ["Ozaki", "Ana", ""], ["Penaloza", "Rafael", ""], ["Xiao", "Guohui", ""]]}, {"id": "1906.00180", "submitter": "Mathijs Mul", "authors": "Mathijs Mul, Willem Zuidema", "title": "Siamese recurrent networks learn first-order logic reasoning and exhibit\n  zero-shot compositional generalization", "comments": "12 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Can neural nets learn logic? We approach this classic question with current\nmethods, and demonstrate that recurrent neural networks can learn to recognize\nfirst order logical entailment relations between expressions. We define an\nartificial language in first-order predicate logic, generate a large dataset of\nsample 'sentences', and use an automatic theorem prover to infer the relation\nbetween random pairs of such sentences. We describe a Siamese neural\narchitecture trained to predict the logical relation, and experiment with\nrecurrent and recursive networks. Siamese Recurrent Networks are surprisingly\nsuccessful at the entailment recognition task, reaching near perfect\nperformance on novel sentences (consisting of known words), and even\noutperforming recursive networks. We report a series of experiments to test the\nability of the models to perform compositional generalization. In particular,\nwe study how they deal with sentences of unseen length, and sentences\ncontaining unseen words. We show that set-ups using LSTMs and GRUs obtain high\nscores on these tests, demonstrating a form of compositionality.\n", "versions": [{"version": "v1", "created": "Sat, 1 Jun 2019 08:17:42 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Mul", "Mathijs", ""], ["Zuidema", "Willem", ""]]}, {"id": "1906.00182", "submitter": "Jie Zhang", "authors": "Yansong Gao and Jie Zhang", "title": "Average-case Analysis of the Assignment Problem with Independent\n  Preferences", "comments": "To appear in IJCAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The fundamental assignment problem is in search of welfare maximization\nmechanisms to allocate items to agents when the private preferences over\nindivisible items are provided by self-interested agents. The mainstream\nmechanism \\textit{Random Priority} is asymptotically the best mechanism for\nthis purpose, when comparing its welfare to the optimal social welfare using\nthe canonical \\textit{worst-case approximation ratio}. Despite its popularity,\nthe efficiency loss indicated by the worst-case ratio does not have a constant\nbound. Recently, [Deng, Gao, Zhang 2017] show that when the agents' preferences\nare drawn from a uniform distribution, its \\textit{average-case approximation\nratio} is upper bounded by 3.718. They left it as an open question of whether a\nconstant ratio holds for general scenarios. In this paper, we offer an\naffirmative answer to this question by showing that the ratio is bounded by\n$1/\\mu$ when the preference values are independent and identically distributed\nrandom variables, where $\\mu$ is the expectation of the value distribution.\nThis upper bound also improves the upper bound of 3.718 in [Deng, Gao, Zhang\n2017] for the Uniform distribution. Moreover, under mild conditions, the ratio\nhas a \\textit{constant} bound for any independent random values. En route to\nthese results, we develop powerful tools to show the insights that in most\ninstances the efficiency loss is small.\n", "versions": [{"version": "v1", "created": "Sat, 1 Jun 2019 08:29:24 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Gao", "Yansong", ""], ["Zhang", "Jie", ""]]}, {"id": "1906.00190", "submitter": "Shayegan Omidshafiei", "authors": "Daniel Hennes, Dustin Morrill, Shayegan Omidshafiei, Remi Munos,\n  Julien Perolat, Marc Lanctot, Audrunas Gruslys, Jean-Baptiste Lespiau, Paavo\n  Parmas, Edgar Duenez-Guzman, Karl Tuyls", "title": "Neural Replicator Dynamics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Policy gradient and actor-critic algorithms form the basis of many commonly\nused training techniques in deep reinforcement learning. Using these algorithms\nin multiagent environments poses problems such as nonstationarity and\ninstability. In this paper, we first demonstrate that standard softmax-based\npolicy gradient can be prone to poor performance in the presence of even the\nmost benign nonstationarity. By contrast, it is known that the replicator\ndynamics, a well-studied model from evolutionary game theory, eliminates\ndominated strategies and exhibits convergence of the time-averaged trajectories\nto interior Nash equilibria in zero-sum games. Thus, using the replicator\ndynamics as a foundation, we derive an elegant one-line change to policy\ngradient methods that simply bypasses the gradient step through the softmax,\nyielding a new algorithm titled Neural Replicator Dynamics (NeuRD). NeuRD\nreduces to the exponential weights/Hedge algorithm in the single-state\nall-actions case. Additionally, NeuRD has formal equivalence to softmax\ncounterfactual regret minimization, which guarantees convergence in the\nsequential tabular case. Importantly, our algorithm provides a straightforward\nway of extending the replicator dynamics to the function approximation setting.\nEmpirical results show that NeuRD quickly adapts to nonstationarities,\noutperforming policy gradient significantly in both tabular and function\napproximation settings, when evaluated on the standard imperfect information\nbenchmarks of Kuhn Poker, Leduc Poker, and Goofspiel.\n", "versions": [{"version": "v1", "created": "Sat, 1 Jun 2019 09:18:48 GMT"}, {"version": "v2", "created": "Tue, 18 Jun 2019 13:20:48 GMT"}, {"version": "v3", "created": "Mon, 25 Nov 2019 18:15:16 GMT"}, {"version": "v4", "created": "Thu, 28 Nov 2019 16:51:11 GMT"}, {"version": "v5", "created": "Wed, 26 Feb 2020 13:26:41 GMT"}], "update_date": "2020-03-02", "authors_parsed": [["Hennes", "Daniel", ""], ["Morrill", "Dustin", ""], ["Omidshafiei", "Shayegan", ""], ["Munos", "Remi", ""], ["Perolat", "Julien", ""], ["Lanctot", "Marc", ""], ["Gruslys", "Audrunas", ""], ["Lespiau", "Jean-Baptiste", ""], ["Parmas", "Paavo", ""], ["Duenez-Guzman", "Edgar", ""], ["Tuyls", "Karl", ""]]}, {"id": "1906.00208", "submitter": "Senthil Yogamani", "authors": "Khaled El Madawy, Hazem Rashed, Ahmad El Sallab, Omar Nasr, Hanan\n  Kamel and Senthil Yogamani", "title": "RGB and LiDAR fusion based 3D Semantic Segmentation for Autonomous\n  Driving", "comments": "Accepted for Oral Presentation at IEEE Intelligent Transportation\n  Systems Conference (ITSC) 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  LiDAR has become a standard sensor for autonomous driving applications as\nthey provide highly precise 3D point clouds. LiDAR is also robust for low-light\nscenarios at night-time or due to shadows where the performance of cameras is\ndegraded. LiDAR perception is gradually becoming mature for algorithms\nincluding object detection and SLAM. However, semantic segmentation algorithm\nremains to be relatively less explored. Motivated by the fact that semantic\nsegmentation is a mature algorithm on image data, we explore sensor fusion\nbased 3D segmentation. Our main contribution is to convert the RGB image to a\npolar-grid mapping representation used for LiDAR and design early and mid-level\nfusion architectures. Additionally, we design a hybrid fusion architecture that\ncombines both fusion algorithms. We evaluate our algorithm on KITTI dataset\nwhich provides segmentation annotation for cars, pedestrians and cyclists. We\nevaluate two state-of-the-art architectures namely SqueezeSeg and PointSeg and\nimprove the mIoU score by 10 % in both cases relative to the LiDAR only\nbaseline.\n", "versions": [{"version": "v1", "created": "Sat, 1 Jun 2019 11:57:38 GMT"}, {"version": "v2", "created": "Wed, 17 Jul 2019 16:28:00 GMT"}], "update_date": "2019-07-18", "authors_parsed": [["Madawy", "Khaled El", ""], ["Rashed", "Hazem", ""], ["Sallab", "Ahmad El", ""], ["Nasr", "Omar", ""], ["Kamel", "Hanan", ""], ["Yogamani", "Senthil", ""]]}, {"id": "1906.00290", "submitter": "Mahdi Jafari Siavoshani", "authors": "Saeed Masoudian, Ali Arabzadeh, Mahdi Jafari Siavoshani, Milad Jalal,\n  Alireza Amouzad", "title": "Adaptive Online Learning for Gradient-Based Optimizers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As application demands for online convex optimization accelerate, the need\nfor designing new methods that simultaneously cover a large class of convex\nfunctions and impose the lowest possible regret is highly rising. Known online\noptimization methods usually perform well only in specific settings, and their\nperformance depends highly on the geometry of the decision space and cost\nfunctions. However, in practice, lack of such geometric information leads to\nconfusion in using the appropriate algorithm. To address this issue, some\nadaptive methods have been proposed that focus on adaptively learning\nparameters such as step size, Lipschitz constant, and strong convexity\ncoefficient, or on specific parametric families such as quadratic regularizers.\nIn this work, we generalize these methods and propose a framework that competes\nwith the best algorithm in a family of expert algorithms. Our framework\nincludes many of the well-known adaptive methods including MetaGrad,\nMetaGrad+C, and Ader. We also introduce a second algorithm that computationally\noutperforms our first algorithm with at most a constant factor increase in\nregret. Finally, as a representative application of our proposed algorithm, we\nstudy the problem of learning the best regularizer from a family of\nregularizers for Online Mirror Descent. Empirically, we support our theoretical\nfindings in the problem of learning the best regularizer on the simplex and\n$l_2$-ball in a multiclass learning problem.\n", "versions": [{"version": "v1", "created": "Sat, 1 Jun 2019 21:04:31 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Masoudian", "Saeed", ""], ["Arabzadeh", "Ali", ""], ["Siavoshani", "Mahdi Jafari", ""], ["Jalal", "Milad", ""], ["Amouzad", "Alireza", ""]]}, {"id": "1906.00311", "submitter": "Andy Shih", "authors": "Andy Shih, Guy Van den Broeck, Paul Beame, Antoine Amarilli", "title": "Smoothing Structured Decomposable Circuits", "comments": null, "journal-ref": "33rd Conference on Neural Information Processing Systems (NeurIPS\n  2019), Vancouver, Canada", "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the task of smoothing a circuit, i.e., ensuring that all children of\na plus-gate mention the same variables. Circuits serve as the building blocks\nof state-of-the-art inference algorithms on discrete probabilistic graphical\nmodels and probabilistic programs. They are also important for discrete density\nestimation algorithms. Many of these tasks require the input circuit to be\nsmooth. However, smoothing has not been studied in its own right yet, and only\na trivial quadratic algorithm is known. This paper studies efficient smoothing\nfor structured decomposable circuits. We propose a near-linear time algorithm\nfor this task and explore lower bounds for smoothing decomposable circuits,\nusing existing results on range-sum queries. Further, for the important case of\nAll-Marginals, we show a more efficient linear-time algorithm. We validate\nexperimentally the performance of our methods.\n", "versions": [{"version": "v1", "created": "Sat, 1 Jun 2019 23:25:38 GMT"}, {"version": "v2", "created": "Mon, 28 Oct 2019 04:41:20 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Shih", "Andy", ""], ["Broeck", "Guy Van den", ""], ["Beame", "Paul", ""], ["Amarilli", "Antoine", ""]]}, {"id": "1906.00317", "submitter": "Elif Surer", "authors": "Sinan Ariyurek, Aysu Betin-Can, Elif Surer", "title": "Automated Video Game Testing Using Synthetic and Human-Like Agents", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present a new methodology that employs tester agents to\nautomate video game testing. We introduce two types of agents -synthetic and\nhuman-like- and two distinct approaches to create them. Our agents are derived\nfrom Reinforcement Learning (RL) and Monte Carlo Tree Search (MCTS) agents, but\nfocus on finding defects. The synthetic agent uses test goals generated from\ngame scenarios, and these goals are further modified to examine the effects of\nunintended game transitions. The human-like agent uses test goals extracted by\nour proposed multiple greedy-policy inverse reinforcement learning (MGP-IRL)\nalgorithm from tester trajectories. MGPIRL captures multiple policies executed\nby human testers. These testers' aims are finding defects while interacting\nwith the game to break it, which is considerably different from game playing.\nWe present interaction states to model such interactions. We use our agents to\nproduce test sequences, run the game with these sequences, and check the game\nfor each run with an automated test oracle. We analyze the proposed method in\ntwo parts: we compare the success of human-like and synthetic agents in bug\nfinding, and we evaluate the similarity between humanlike agents and human\ntesters. We collected 427 trajectories from human testers using the General\nVideo Game Artificial Intelligence (GVG-AI) framework and created three games\nwith 12 levels that contain 45 bugs. Our experiments reveal that human-like and\nsynthetic agents compete with human testers' bug finding performances.\nMoreover, we show that MGP-IRL increases the human-likeness of agents while\nimproving the bug finding performance.\n", "versions": [{"version": "v1", "created": "Sun, 2 Jun 2019 00:19:00 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Ariyurek", "Sinan", ""], ["Betin-Can", "Aysu", ""], ["Surer", "Elif", ""]]}, {"id": "1906.00336", "submitter": "Xingyou Song", "authors": "Alex Irpan, Xingyou Song", "title": "The Principle of Unchanged Optimality in Reinforcement Learning\n  Generalization", "comments": "Published at ICML 2019 Workshop \"Understanding and Improving\n  Generalization in Deep Learning\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Several recent papers have examined generalization in reinforcement learning\n(RL), by proposing new environments or ways to add noise to existing\nenvironments, then benchmarking algorithms and model architectures on those\nenvironments. We discuss subtle conceptual properties of RL benchmarks that are\nnot required in supervised learning (SL), and also properties that an RL\nbenchmark should possess. Chief among them is one we call the principle of\nunchanged optimality: there should exist a single $\\pi$ that is optimal across\nall train and test tasks. In this work, we argue why this principle is\nimportant, and ways it can be broken or satisfied due to subtle choices in\nstate representation or model architecture. We conclude by discussing\nchallenges and future lines of research in theoretically analyzing\ngeneralization benchmarks.\n", "versions": [{"version": "v1", "created": "Sun, 2 Jun 2019 03:52:28 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Irpan", "Alex", ""], ["Song", "Xingyou", ""]]}, {"id": "1906.00346", "submitter": "Junyuan Shang", "authors": "Junyuan Shang, Tengfei Ma, Cao Xiao, Jimeng Sun", "title": "Pre-training of Graph Augmented Transformers for Medication\n  Recommendation", "comments": "IJCAI2019; fix some undefined problems; provide more intuitive\n  figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Medication recommendation is an important healthcare application. It is\ncommonly formulated as a temporal prediction task. Hence, most existing works\nonly utilize longitudinal electronic health records (EHRs) from a small number\nof patients with multiple visits ignoring a large number of patients with a\nsingle visit (selection bias). Moreover, important hierarchical knowledge such\nas diagnosis hierarchy is not leveraged in the representation learning process.\nTo address these challenges, we propose G-BERT, a new model to combine the\npower of Graph Neural Networks (GNNs) and BERT (Bidirectional Encoder\nRepresentations from Transformers) for medical code representation and\nmedication recommendation. We use GNNs to represent the internal hierarchical\nstructures of medical codes. Then we integrate the GNN representation into a\ntransformer-based visit encoder and pre-train it on EHR data from patients only\nwith a single visit. The pre-trained visit encoder and representation are then\nfine-tuned for downstream predictive tasks on longitudinal EHRs from patients\nwith multiple visits. G-BERT is the first to bring the language model\npre-training schema into the healthcare domain and it achieved state-of-the-art\nperformance on the medication recommendation task.\n", "versions": [{"version": "v1", "created": "Sun, 2 Jun 2019 05:11:38 GMT"}, {"version": "v2", "created": "Wed, 27 Nov 2019 02:36:05 GMT"}], "update_date": "2019-11-28", "authors_parsed": [["Shang", "Junyuan", ""], ["Ma", "Tengfei", ""], ["Xiao", "Cao", ""], ["Sun", "Jimeng", ""]]}, {"id": "1906.00363", "submitter": "Cunxiang Wang", "authors": "Cunxiang Wang, Shuailong Liang, Yue Zhang, Xiaonan Li and Tian Gao", "title": "Does It Make Sense? And Why? A Pilot Study for Sense Making and\n  Explanation", "comments": "This paper has been accepted by ACL2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Introducing common sense to natural language understanding systems has\nreceived increasing research attention. It remains a fundamental question on\nhow to evaluate whether a system has a sense making capability. Existing\nbenchmarks measures commonsense knowledge indirectly and without explanation.\nIn this paper, we release a benchmark to directly test whether a system can\ndifferentiate natural language statements that make sense from those that do\nnot make sense. In addition, a system is asked to identify the most crucial\nreason why a statement does not make sense. We evaluate models trained over\nlarge-scale language modeling tasks as well as human performance, showing that\nthere are different challenges for system sense making.\n", "versions": [{"version": "v1", "created": "Sun, 2 Jun 2019 08:03:21 GMT"}, {"version": "v2", "created": "Fri, 24 Apr 2020 06:55:11 GMT"}], "update_date": "2020-04-27", "authors_parsed": [["Wang", "Cunxiang", ""], ["Liang", "Shuailong", ""], ["Zhang", "Yue", ""], ["Li", "Xiaonan", ""], ["Gao", "Tian", ""]]}, {"id": "1906.00414", "submitter": "Shikib Mehri", "authors": "Shikib Mehri, Evgeniia Razumovskaia, Tiancheng Zhao and Maxine\n  Eskenazi", "title": "Pretraining Methods for Dialog Context Representation Learning", "comments": "Accepted to ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper examines various unsupervised pretraining objectives for learning\ndialog context representations. Two novel methods of pretraining dialog context\nencoders are proposed, and a total of four methods are examined. Each\npretraining objective is fine-tuned and evaluated on a set of downstream dialog\ntasks using the MultiWoz dataset and strong performance improvement is\nobserved. Further evaluation shows that our pretraining objectives result in\nnot only better performance, but also better convergence, models that are less\ndata hungry and have better domain generalizability.\n", "versions": [{"version": "v1", "created": "Sun, 2 Jun 2019 14:57:25 GMT"}, {"version": "v2", "created": "Tue, 4 Jun 2019 02:09:30 GMT"}], "update_date": "2019-06-05", "authors_parsed": [["Mehri", "Shikib", ""], ["Razumovskaia", "Evgeniia", ""], ["Zhao", "Tiancheng", ""], ["Eskenazi", "Maxine", ""]]}, {"id": "1906.00429", "submitter": "Sebastian Tschiatschek", "authors": "Sebastian Tschiatschek, Ahana Ghosh, Luis Haug, Rati Devidze, Adish\n  Singla", "title": "Learner-aware Teaching: Inverse Reinforcement Learning with Preferences\n  and Constraints", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inverse reinforcement learning (IRL) enables an agent to learn complex\nbehavior by observing demonstrations from a (near-)optimal policy. The typical\nassumption is that the learner's goal is to match the teacher's demonstrated\nbehavior. In this paper, we consider the setting where the learner has its own\npreferences that it additionally takes into consideration. These preferences\ncan for example capture behavioral biases, mismatched worldviews, or physical\nconstraints. We study two teaching approaches: learner-agnostic teaching, where\nthe teacher provides demonstrations from an optimal policy ignoring the\nlearner's preferences, and learner-aware teaching, where the teacher accounts\nfor the learner's preferences. We design learner-aware teaching algorithms and\nshow that significant performance improvements can be achieved over\nlearner-agnostic teaching.\n", "versions": [{"version": "v1", "created": "Sun, 2 Jun 2019 15:51:35 GMT"}, {"version": "v2", "created": "Tue, 29 Oct 2019 15:10:09 GMT"}], "update_date": "2019-10-30", "authors_parsed": [["Tschiatschek", "Sebastian", ""], ["Ghosh", "Ahana", ""], ["Haug", "Luis", ""], ["Devidze", "Rati", ""], ["Singla", "Adish", ""]]}, {"id": "1906.00431", "submitter": "Xingyou Song", "authors": "Xingyou Song, Yilun Du, Jacob Jackson", "title": "An Empirical Study on Hyperparameters and their Interdependence for RL\n  Generalization", "comments": "Published in ICML 2019 Workshop \"Understanding and Improving\n  Generalization in Deep Learning\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent results in Reinforcement Learning (RL) have shown that agents with\nlimited training environments are susceptible to a large amount of overfitting\nacross many domains. A key challenge for RL generalization is to quantitatively\nexplain the effects of changing parameters on testing performance. Such\nparameters include architecture, regularization, and RL-dependent variables\nsuch as discount factor and action stochasticity. We provide empirical results\nthat show complex and interdependent relationships between hyperparameters and\ngeneralization. We further show that several empirical metrics such as gradient\ncosine similarity and trajectory-dependent metrics serve to provide intuition\ntowards these results.\n", "versions": [{"version": "v1", "created": "Sun, 2 Jun 2019 16:01:17 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Song", "Xingyou", ""], ["Du", "Yilun", ""], ["Jackson", "Jacob", ""]]}, {"id": "1906.00499", "submitter": "Xiujun Li", "authors": "Zhirui Zhang and Xiujun Li and Jianfeng Gao and Enhong Chen", "title": "Budgeted Policy Learning for Task-Oriented Dialogue Systems", "comments": "10 pages, 7 figures, ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a new approach that extends Deep Dyna-Q (DDQ) by\nincorporating a Budget-Conscious Scheduling (BCS) to best utilize a fixed,\nsmall amount of user interactions (budget) for learning task-oriented dialogue\nagents. BCS consists of (1) a Poisson-based global scheduler to allocate budget\nover different stages of training; (2) a controller to decide at each training\nstep whether the agent is trained using real or simulated experiences; (3) a\nuser goal sampling module to generate the experiences that are most effective\nfor policy learning. Experiments on a movie-ticket booking task with simulated\nand real users show that our approach leads to significant improvements in\nsuccess rate over the state-of-the-art baselines given the fixed budget.\n", "versions": [{"version": "v1", "created": "Sun, 2 Jun 2019 22:53:33 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Zhang", "Zhirui", ""], ["Li", "Xiujun", ""], ["Gao", "Jianfeng", ""], ["Chen", "Enhong", ""]]}, {"id": "1906.00535", "submitter": "Igor Borovikov", "authors": "Igor Borovikov, Jesse Harder, Michael Sadovsky, Ahmad Beirami", "title": "Towards Interactive Training of Non-Player Characters in Video Games", "comments": "presented at 2019 ICML Workshop on Human in the Loop Learning (HILL\n  2019), Long Beach, USA", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is a high demand for high-quality Non-Player Characters (NPCs) in video\ngames. Hand-crafting their behavior is a labor intensive and error prone\nengineering process with limited controls exposed to the game designers. We\npropose to create such NPC behaviors interactively by training an agent in the\ntarget environment using imitation learning with a human in the loop. While\ntraditional behavior cloning may fall short of achieving the desired\nperformance, we show that interactivity can substantially improve it with a\nmodest amount of human efforts. The model we train is a multi-resolution\nensemble of Markov models, which can be used as is or can be further\n\"compressed\" into a more compact model for inference on consumer devices. We\nillustrate our approach on an example in OpenAI Gym, where a human can help to\nquickly train an agent with only a handful of interactive demonstrations. We\nalso outline our experiments with NPC training for a first-person shooter game\ncurrently in development.\n", "versions": [{"version": "v1", "created": "Mon, 3 Jun 2019 02:38:05 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Borovikov", "Igor", ""], ["Harder", "Jesse", ""], ["Sadovsky", "Michael", ""], ["Beirami", "Ahmad", ""]]}, {"id": "1906.00580", "submitter": "Hongyu Zang", "authors": "Hongyu Zang and Xiaojun Wan", "title": "Massive Styles Transfer with Limited Labeled Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Language style transfer has attracted more and more attention in the past few\nyears. Recent researches focus on improving neural models targeting at\ntransferring from one style to the other with labeled data. However,\ntransferring across multiple styles is often very useful in real-life\napplications. Previous researches of language style transfer have two main\ndeficiencies: dependency on massive labeled data and neglect of mutual\ninfluence among different style transfer tasks. In this paper, we propose a\nmulti-agent style transfer system (MAST) for addressing multiple style transfer\ntasks with limited labeled data, by leveraging abundant unlabeled data and the\nmutual benefit among the multiple styles. A style transfer agent in our system\nnot only learns from unlabeled data by using techniques like denoising\nauto-encoder and back-translation, but also learns to cooperate with other\nstyle transfer agents in a self-organization manner. We conduct our experiments\nby simulating a set of real-world style transfer tasks with multiple versions\nof the Bible. Our model significantly outperforms the other competitive\nmethods. Extensive results and analysis further verify the efficacy of our\nproposed system.\n", "versions": [{"version": "v1", "created": "Mon, 3 Jun 2019 05:27:05 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Zang", "Hongyu", ""], ["Wan", "Xiaojun", ""]]}, {"id": "1906.00582", "submitter": "Chaobing Song", "authors": "Chaobing Song, Yong Jiang and Yi Ma", "title": "Unified Acceleration of High-Order Algorithms under H\\\"{o}lder\n  Continuity and Uniform Convexity", "comments": "39 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, through a very intuitive vanilla proximal method perspective,\nwe derive accelerated high-order optimization algorithms for minimizing a\nconvex function that has H\\\"{o}lder continuous derivatives. In this general\nconvex setting, we propose a concise unified acceleration framework (UAF),\nwhich reconciles the two different high-order acceleration approaches, one by\nNesterov and Baes [29, 3, 33] and one by Monteiro and Svaiter [25]. As result,\nthe UAF unifies the high-order acceleration instances [29, 3, 33, 15, 16, 25,\n19, 6, 14] of the two approaches by only two problem-related parameters and two\nadditional parameters for framework design. Furthermore, the UAF (and its\nanalysis) is the first approach to make high-order methods applicable for\nhigh-order smoothness conditions with respect to non-Euclidean norms. If the\nfunction is further uniformly convex, we propose a general restart scheme for\nthe UAF. The iteration complexities of instances of both the UAF and the\nrestarted UAF match existing lower bounds in most important cases [2, 16]. For\npractical implementation, we introduce a new and effective heuristic that\nsignificantly simplifies the binary search procedure required by the framework.\nWe use experiments to verify the effectiveness of the heuristic and demonstrate\nclear and consistent advantages of high-order acceleration methods over\nfirst-order ones, in terms of run-time complexity. Finally, the UAF is proposed\ndirectly in the general composite convex setting, thus show that the existing\nhigh-order algorithms [29, 3, 33, 16, 6, 14] can be naturally extended to the\ngeneral composite convex setting.\n", "versions": [{"version": "v1", "created": "Mon, 3 Jun 2019 05:27:59 GMT"}, {"version": "v2", "created": "Sun, 29 Sep 2019 19:19:52 GMT"}], "update_date": "2019-10-01", "authors_parsed": [["Song", "Chaobing", ""], ["Jiang", "Yong", ""], ["Ma", "Yi", ""]]}, {"id": "1906.00592", "submitter": "Baosong Yang", "authors": "Baosong Yang, Longyue Wang, Derek F. Wong, Lidia S. Chao, Zhaopeng Tu", "title": "Assessing the Ability of Self-Attention Networks to Learn Word Order", "comments": "ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Self-attention networks (SAN) have attracted a lot of interests due to their\nhigh parallelization and strong performance on a variety of NLP tasks, e.g.\nmachine translation. Due to the lack of recurrence structure such as recurrent\nneural networks (RNN), SAN is ascribed to be weak at learning positional\ninformation of words for sequence modeling. However, neither this speculation\nhas been empirically confirmed, nor explanations for their strong performances\non machine translation tasks when \"lacking positional information\" have been\nexplored. To this end, we propose a novel word reordering detection task to\nquantify how well the word order information learned by SAN and RNN.\nSpecifically, we randomly move one word to another position, and examine\nwhether a trained model can detect both the original and inserted positions.\nExperimental results reveal that: 1) SAN trained on word reordering detection\nindeed has difficulty learning the positional information even with the\nposition embedding; and 2) SAN trained on machine translation learns better\npositional information than its RNN counterpart, in which position embedding\nplays a critical role. Although recurrence structure make the model more\nuniversally-effective on learning word order, learning objectives matter more\nin the downstream tasks such as machine translation.\n", "versions": [{"version": "v1", "created": "Mon, 3 Jun 2019 06:32:29 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Yang", "Baosong", ""], ["Wang", "Longyue", ""], ["Wong", "Derek F.", ""], ["Chao", "Lidia S.", ""], ["Tu", "Zhaopeng", ""]]}, {"id": "1906.00606", "submitter": "Manish Joshi", "authors": "Manish Joshi, Sangeeta Jadhav", "title": "An Extensive Review of Computational Dance Automation Techniques and\n  Applications", "comments": "15 pages, 6 figures,", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dance is an art and when technology meets this kind of art, it's a novel\nattempt in itself. Several researchers have attempted to automate several\naspects of dance, right from dance notation to choreography. Furthermore, we\nhave encountered several applications of dance automation like e-learning,\nheritage preservation, etc. Despite several attempts by researchers for more\nthan two decades in various styles of dance all round the world, we found a\nreview paper that portrays the research status in this area dating to 1990\n\\cite{politis1990computers}. Hence, we decide to come up with a comprehensive\nreview article that showcases several aspects of dance automation.\n  This paper is an attempt to review research work reported in the literature,\ncategorize and group all research work completed so far in the field of\nautomating dance. We have explicitly identified six major categories\ncorresponding to the use of computers in dance automation namely dance\nrepresentation, dance capturing, dance semantics, dance generation, dance\nprocessing approaches and applications of dance automation systems. We\nclassified several research papers under these categories according to their\nresearch approach and functionality. With the help of proposed categories and\nsubcategories one can easily determine the state of research and the new\navenues left for exploration in the field of dance automation.\n", "versions": [{"version": "v1", "created": "Mon, 3 Jun 2019 07:17:35 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Joshi", "Manish", ""], ["Jadhav", "Sangeeta", ""]]}, {"id": "1906.00624", "submitter": "Louis Jachiet", "authors": "Michael Benedikt, Pierre Bourhis (CRIStAL, CNRS, SPIRALS), Louis\n  Jachiet (CRIStAL, CNRS, SPIRALS), Micha\\\"el Thomazo (DI-ENS, ENS Paris, CNRS,\n  PSL, VALDA )", "title": "Reasoning about disclosure in data integration in the presence of source\n  constraints", "comments": null, "journal-ref": "28th International Joint Conference on Artificial Intelligence\n  (IJCAI-19), Aug 2019, Macau, China", "doi": "10.24963/ijcai.2019/215", "report-no": null, "categories": "cs.LO cs.AI cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data integration systems allow users to access data sitting in multiple\nsources by means of queries over a global schema, related to the sources via\nmappings. Data sources often contain sensitive information, and thus an\nanalysis is needed to verify that a schema satisfies a privacy policy, given as\na set of queries whose answers should not be accessible to users. Such an\nanalysis should take into account not only knowledge that an attacker may have\nabout the mappings, but also what they may know about the semantics of the\nsources. In this paper, we show that source constraints can have a dramatic\nimpact on disclosure analysis. We study the problem of determining whether a\ngiven data integration system discloses a source query to an attacker in the\npresence of constraints, providing both lower and upper bounds on source-aware\ndisclosure analysis.\n", "versions": [{"version": "v1", "created": "Mon, 3 Jun 2019 08:18:12 GMT"}, {"version": "v2", "created": "Mon, 14 Dec 2020 12:50:52 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["Benedikt", "Michael", "", "CRIStAL, CNRS, SPIRALS"], ["Bourhis", "Pierre", "", "CRIStAL, CNRS, SPIRALS"], ["Jachiet", "Louis", "", "CRIStAL, CNRS, SPIRALS"], ["Thomazo", "Micha\u00ebl", "", "DI-ENS, ENS Paris, CNRS,\n  PSL, VALDA"]]}, {"id": "1906.00634", "submitter": "Alejandro Cartas", "authors": "Alejandro Cartas, Jordi Luque, Petia Radeva, Carlos Segura, Mariella\n  Dimiccoli", "title": "How Much Does Audio Matter to Recognize Egocentric Object Interactions?", "comments": "Accepted for presentation at EPIC@CVPR2019 workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Sounds are an important source of information on our daily interactions with\nobjects. For instance, a significant amount of people can discern the\ntemperature of water that it is being poured just by using the sense of\nhearing. However, only a few works have explored the use of audio for the\nclassification of object interactions in conjunction with vision or as single\nmodality. In this preliminary work, we propose an audio model for egocentric\naction recognition and explore its usefulness on the parts of the problem\n(noun, verb, and action classification). Our model achieves a competitive\nresult in terms of verb classification (34.26% accuracy) on a standard\nbenchmark with respect to vision-based state of the art systems, using a\ncomparatively lighter architecture.\n", "versions": [{"version": "v1", "created": "Mon, 3 Jun 2019 08:40:49 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Cartas", "Alejandro", ""], ["Luque", "Jordi", ""], ["Radeva", "Petia", ""], ["Segura", "Carlos", ""], ["Dimiccoli", "Mariella", ""]]}, {"id": "1906.00657", "submitter": "Andreas Holzinger", "authors": "Heimo Mueller and Andreas Holzinger", "title": "Kandinsky Patterns", "comments": "13 pages, 13 Figures", "journal-ref": "Artificial Intelligence, 2021", "doi": "10.1016/j.artint.2021.103546", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Kandinsky Figures and Kandinsky Patterns are mathematically describable,\nsimple self-contained hence controllable test data sets for the development,\nvalidation and training of explainability in artificial intelligence. Whilst\nKandinsky Patterns have these computationally manageable properties, they are\nat the same time easily distinguishable from human observers. Consequently,\ncontrolled patterns can be described by both humans and computers. We define a\nKandinsky Pattern as a set of Kandinsky Figures, where for each figure an\n\"infallible authority\" defines that the figure belongs to the Kandinsky\nPattern. With this simple principle we build training and validation data sets\nfor automatic interpretability and context learning. In this paper we describe\nthe basic idea and some underlying principles of Kandinsky Patterns and provide\na Github repository to invite the international machine learning research\ncommunity to a challenge to experiment with our Kandinsky Patterns to expand\nand thus make progress in the field of explainable AI and to contribute to the\nupcoming field of explainability and causability.\n", "versions": [{"version": "v1", "created": "Mon, 3 Jun 2019 09:22:33 GMT"}], "update_date": "2021-06-11", "authors_parsed": [["Mueller", "Heimo", ""], ["Holzinger", "Andreas", ""]]}, {"id": "1906.00687", "submitter": "Canran Xu", "authors": "Canran Xu, Ruijiang Li", "title": "Relation Embedding with Dihedral Group in Knowledge Graph", "comments": "ACL 2019", "journal-ref": null, "doi": "10.18653/v1/P19-1026", "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Link prediction is critical for the application of incomplete knowledge graph\n(KG) in the downstream tasks. As a family of effective approaches for link\npredictions, embedding methods try to learn low-rank representations for both\nentities and relations such that the bilinear form defined therein is a\nwell-behaved scoring function. Despite of their successful performances,\nexisting bilinear forms overlook the modeling of relation compositions,\nresulting in lacks of interpretability for reasoning on KG. To fulfill this\ngap, we propose a new model called DihEdral, named after dihedral symmetry\ngroup. This new model learns knowledge graph embeddings that can capture\nrelation compositions by nature. Furthermore, our approach models the relation\nembeddings parametrized by discrete values, thereby decrease the solution space\ndrastically. Our experiments show that DihEdral is able to capture all desired\nproperties such as (skew-) symmetry, inversion and (non-) Abelian composition,\nand outperforms existing bilinear form based approach and is comparable to or\nbetter than deep learning models such as ConvE.\n", "versions": [{"version": "v1", "created": "Mon, 3 Jun 2019 10:13:32 GMT"}], "update_date": "2019-11-22", "authors_parsed": [["Xu", "Canran", ""], ["Li", "Ruijiang", ""]]}, {"id": "1906.00695", "submitter": "Christian Henning", "authors": "Johannes von Oswald and Christian Henning and Jo\\~ao Sacramento and\n  Benjamin F. Grewe", "title": "Continual learning with hypernetworks", "comments": "Published at ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Artificial neural networks suffer from catastrophic forgetting when they are\nsequentially trained on multiple tasks. To overcome this problem, we present a\nnovel approach based on task-conditioned hypernetworks, i.e., networks that\ngenerate the weights of a target model based on task identity. Continual\nlearning (CL) is less difficult for this class of models thanks to a simple key\nfeature: instead of recalling the input-output relations of all previously seen\ndata, task-conditioned hypernetworks only require rehearsing task-specific\nweight realizations, which can be maintained in memory using a simple\nregularizer. Besides achieving state-of-the-art performance on standard CL\nbenchmarks, additional experiments on long task sequences reveal that\ntask-conditioned hypernetworks display a very large capacity to retain previous\nmemories. Notably, such long memory lifetimes are achieved in a compressive\nregime, when the number of trainable hypernetwork weights is comparable or\nsmaller than target network size. We provide insight into the structure of\nlow-dimensional task embedding spaces (the input space of the hypernetwork) and\nshow that task-conditioned hypernetworks demonstrate transfer learning.\nFinally, forward information transfer is further supported by empirical results\non a challenging CL benchmark based on the CIFAR-10/100 image datasets.\n", "versions": [{"version": "v1", "created": "Mon, 3 Jun 2019 10:45:08 GMT"}, {"version": "v2", "created": "Thu, 10 Oct 2019 12:11:32 GMT"}, {"version": "v3", "created": "Wed, 12 Feb 2020 14:56:57 GMT"}], "update_date": "2020-02-13", "authors_parsed": [["von Oswald", "Johannes", ""], ["Henning", "Christian", ""], ["Sacramento", "Jo\u00e3o", ""], ["Grewe", "Benjamin F.", ""]]}, {"id": "1906.00744", "submitter": "Denis Yarats", "authors": "Hengyuan Hu, Denis Yarats, Qucheng Gong, Yuandong Tian, Mike Lewis", "title": "Hierarchical Decision Making by Generating and Following Natural\n  Language Instructions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We explore using latent natural language instructions as an expressive and\ncompositional representation of complex actions for hierarchical decision\nmaking. Rather than directly selecting micro-actions, our agent first generates\na latent plan in natural language, which is then executed by a separate model.\nWe introduce a challenging real-time strategy game environment in which the\nactions of a large number of units must be coordinated across long time scales.\nWe gather a dataset of 76 thousand pairs of instructions and executions from\nhuman play, and train instructor and executor models. Experiments show that\nmodels using natural language as a latent variable significantly outperform\nmodels that directly imitate human actions. The compositional structure of\nlanguage proves crucial to its effectiveness for action representation. We also\nrelease our code, models and data.\n", "versions": [{"version": "v1", "created": "Mon, 3 Jun 2019 12:28:50 GMT"}, {"version": "v2", "created": "Wed, 12 Jun 2019 08:46:09 GMT"}, {"version": "v3", "created": "Tue, 20 Aug 2019 20:53:30 GMT"}, {"version": "v4", "created": "Tue, 27 Aug 2019 19:24:48 GMT"}, {"version": "v5", "created": "Wed, 2 Oct 2019 16:10:21 GMT"}], "update_date": "2019-10-03", "authors_parsed": [["Hu", "Hengyuan", ""], ["Yarats", "Denis", ""], ["Gong", "Qucheng", ""], ["Tian", "Yuandong", ""], ["Lewis", "Mike", ""]]}, {"id": "1906.00772", "submitter": "Oscar J. Romero", "authors": "Oscar J. Romero", "title": "Dynamic Service Composition Orchestrated by Cognitive Agents in Mobile &\n  Pervasive Computing", "comments": "This paper will appear on SCC'19 (IEEE International Conference on\n  Services Computing) on July 13. arXiv admin note: substantial text overlap\n  with arXiv:1905.12630", "journal-ref": "2019 IEEE World Congress on Services (SERVICES)", "doi": "10.1109/SERVICES.2019.00118", "report-no": null, "categories": "cs.SE cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic service composition in mobile and pervasive computing faces many\nchallenges due to the complex nature of the environment. Common approaches\naddress service composition from optimization perspectives which are not\nfeasible in practice due to the intractability of the problem, limited\ncomputational resources of smart devices, service host's mobility, and time\nconstraints. Our main contribution is the development of a cognitively-inspired\nagent-based service composition model focused on bounded rationality rather\nthan optimality, which allows the system to compensate for limited resources by\nselectively filtering out continuous streams of data. The evaluation of our\napproach shows promising results when compared against state-of-the-art service\ncomposition models.\n", "versions": [{"version": "v1", "created": "Fri, 31 May 2019 13:45:18 GMT"}], "update_date": "2019-08-07", "authors_parsed": [["Romero", "Oscar J.", ""]]}, {"id": "1906.00805", "submitter": "Xueying Qin", "authors": "Jichao Zhang, Meng Sun, Jingjing Chen, Hao Tang, Yan Yan, Xueying Qin,\n  Nicu Sebe", "title": "GazeCorrection:Self-Guided Eye Manipulation in the wild using\n  Self-Supervised Generative Adversarial Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gaze correction aims to redirect the person's gaze into the camera by\nmanipulating the eye region, and it can be considered as a specific image\nresynthesis problem. Gaze correction has a wide range of applications in real\nlife, such as taking a picture with staring at the camera. In this paper, we\npropose a novel method that is based on the inpainting model to learn from the\nface image to fill in the missing eye regions with new contents representing\ncorrected eye gaze. Moreover, our model does not require the training dataset\nlabeled with the specific head pose and eye angle information, thus, the\ntraining data is easy to collect. To retain the identity information of the eye\nregion in the original input, we propose a self-guided pretrained model to\nlearn the angle-invariance feature. Experiments show our model achieves very\ncompelling gaze-corrected results in the wild dataset which is collected from\nthe website and will be introduced in details. Code is available at\nhttps://github.com/zhangqianhui/GazeCorrection.\n", "versions": [{"version": "v1", "created": "Mon, 3 Jun 2019 13:43:01 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Zhang", "Jichao", ""], ["Sun", "Meng", ""], ["Chen", "Jingjing", ""], ["Tang", "Hao", ""], ["Yan", "Yan", ""], ["Qin", "Xueying", ""], ["Sebe", "Nicu", ""]]}, {"id": "1906.00855", "submitter": "Di Chen", "authors": "Di Chen, Yiwei Bai, Wenting Zhao, Sebastian Ament, John M. Gregoire,\n  Carla P. Gomes", "title": "Deep Reasoning Networks: Thinking Fast and Slow", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce Deep Reasoning Networks (DRNets), an end-to-end framework that\ncombines deep learning with reasoning for solving complex tasks, typically in\nan unsupervised or weakly-supervised setting. DRNets exploit problem structure\nand prior knowledge by tightly combining logic and constraint reasoning with\nstochastic-gradient-based neural network optimization. We illustrate the power\nof DRNets on de-mixing overlapping hand-written Sudokus (Multi-MNIST-Sudoku)\nand on a substantially more complex task in scientific discovery that concerns\ninferring crystal structures of materials from X-ray diffraction data under\nthermodynamic rules (Crystal-Structure-Phase-Mapping). At a high level, DRNets\nencode a structured latent space of the input data, which is constrained to\nadhere to prior knowledge by a reasoning module. The structured latent encoding\nis used by a generative decoder to generate the targeted output. Finally, an\noverall objective combines responses from the generative decoder (thinking\nfast) and the reasoning module (thinking slow), which is optimized using\nconstraint-aware stochastic gradient descent. We show how to encode different\ntasks as DRNets and demonstrate DRNets' effectiveness with detailed\nexperiments: DRNets significantly outperform the state of the art and experts'\ncapabilities on Crystal-Structure-Phase-Mapping, recovering more precise and\nphysically meaningful crystal structures. On Multi-MNIST-Sudoku, DRNets\nperfectly recovered the mixed Sudokus' digits, with 100% digit accuracy,\noutperforming the supervised state-of-the-art MNIST de-mixing models. Finally,\nas a proof of concept, we also show how DRNets can solve standard combinatorial\nproblems -- 9-by-9 Sudoku puzzles and Boolean satisfiability problems (SAT),\noutperforming other specialized deep learning models. DRNets are general and\ncan be adapted and expanded to tackle other tasks.\n", "versions": [{"version": "v1", "created": "Mon, 3 Jun 2019 15:09:57 GMT"}, {"version": "v2", "created": "Tue, 4 Jun 2019 15:41:03 GMT"}], "update_date": "2019-06-05", "authors_parsed": [["Chen", "Di", ""], ["Bai", "Yiwei", ""], ["Zhao", "Wenting", ""], ["Ament", "Sebastian", ""], ["Gregoire", "John M.", ""], ["Gomes", "Carla P.", ""]]}, {"id": "1906.00872", "submitter": "Shizhe Chen", "authors": "Shizhe Chen, Qin Jin and Jianlong Fu", "title": "From Words to Sentences: A Progressive Learning Approach for\n  Zero-resource Machine Translation with Visual Pivots", "comments": "Accepted by IJCAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The neural machine translation model has suffered from the lack of\nlarge-scale parallel corpora. In contrast, we humans can learn multi-lingual\ntranslations even without parallel texts by referring our languages to the\nexternal world. To mimic such human learning behavior, we employ images as\npivots to enable zero-resource translation learning. However, a picture tells a\nthousand words, which makes multi-lingual sentences pivoted by the same image\nnoisy as mutual translations and thus hinders the translation model learning.\nIn this work, we propose a progressive learning approach for image-pivoted\nzero-resource machine translation. Since words are less diverse when grounded\nin the image, we first learn word-level translation with image pivots, and then\nprogress to learn the sentence-level translation by utilizing the learned word\ntranslation to suppress noises in image-pivoted multi-lingual sentences.\nExperimental results on two widely used image-pivot translation datasets,\nIAPR-TC12 and Multi30k, show that the proposed approach significantly\noutperforms other state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Mon, 3 Jun 2019 15:28:48 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Chen", "Shizhe", ""], ["Jin", "Qin", ""], ["Fu", "Jianlong", ""]]}, {"id": "1906.00908", "submitter": "Cristiano Chesi", "authors": "Cristiano Chesi", "title": "Phase-based Minimalist Parsing and complexity in non-local dependencies", "comments": null, "journal-ref": "Proceedings of CLiC-it 2017. CEUR WORKSHOP PROCEEDINGS, ROMA:CEUR\n  Workshop Proceedings, ISBN: 9788899982768, ISSN: 1613-0073, Rome, 11-13\n  December 2017", "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.CC", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  A cognitively plausible parsing algorithm should perform like the human\nparser in critical contexts. Here I propose an adaptation of Earley's parsing\nalgorithm, suitable for Phase-based Minimalist Grammars (PMG, Chesi 2012), that\nis able to predict complexity effects in performance. Focusing on self-paced\nreading experiments of object clefts sentences (Warren & Gibson 2005) I will\nassociate to parsing a complexity metric based on cued features to be retrieved\nat the verb segment (Feature Retrieval & Encoding Cost, FREC). FREC is\ncrucially based on the usage of memory predicted by the discussed parsing\nalgorithm and it correctly fits with the reading time revealed.\n", "versions": [{"version": "v1", "created": "Mon, 3 Jun 2019 16:20:04 GMT"}, {"version": "v2", "created": "Sat, 17 Jul 2021 14:03:08 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Chesi", "Cristiano", ""]]}, {"id": "1906.00917", "submitter": "Yichang Wang", "authors": "Yichang Wang, R\\'emi Emonet, Elisa Fromont, Simon Malinowski, Etienne\n  Menager, Lo\\\"ic Mosser, Romain Tavenard", "title": "Learning Interpretable Shapelets for Time Series Classification through\n  Adversarial Regularization", "comments": "submitted to CIKM2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Times series classification can be successfully tackled by jointly learning a\nshapelet-based representation of the series in the dataset and classifying the\nseries according to this representation. However, although the learned\nshapelets are discriminative, they are not always similar to pieces of a real\nseries in the dataset. This makes it difficult to interpret the decision, i.e.\ndifficult to analyze if there are particular behaviors in a series that\ntriggered the decision. In this paper, we make use of a simple convolutional\nnetwork to tackle the time series classification task and we introduce an\nadversarial regularization to constrain the model to learn more interpretable\nshapelets. Our classification results on all the usual time series benchmarks\nare comparable with the results obtained by similar state-of-the-art algorithms\nbut our adversarially regularized method learns shapelets that are, by design,\ninterpretable.\n", "versions": [{"version": "v1", "created": "Mon, 3 Jun 2019 16:38:20 GMT"}, {"version": "v2", "created": "Wed, 12 Jun 2019 13:44:17 GMT"}], "update_date": "2019-06-13", "authors_parsed": [["Wang", "Yichang", ""], ["Emonet", "R\u00e9mi", ""], ["Fromont", "Elisa", ""], ["Malinowski", "Simon", ""], ["Menager", "Etienne", ""], ["Mosser", "Lo\u00efc", ""], ["Tavenard", "Romain", ""]]}, {"id": "1906.01035", "submitter": "Sjoerd van Steenkiste", "authors": "Sjoerd van Steenkiste, Klaus Greff, J\\\"urgen Schmidhuber", "title": "A Perspective on Objects and Systematic Generalization in Model-Based RL", "comments": "Accepted to the ICML 2019 workshop on Workshop on Generative Modeling\n  and Model-Based Reasoning for Robotics and AI", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In order to meet the diverse challenges in solving many real-world problems,\nan intelligent agent has to be able to dynamically construct a model of its\nenvironment. Objects facilitate the modular reuse of prior knowledge and the\ncombinatorial construction of such models. In this work, we argue that\ndynamically bound features (objects) do not simply emerge in connectionist\nmodels of the world. We identify several requirements that need to be fulfilled\nin overcoming this limitation and highlight corresponding inductive biases.\n", "versions": [{"version": "v1", "created": "Mon, 3 Jun 2019 19:29:12 GMT"}], "update_date": "2019-06-05", "authors_parsed": [["van Steenkiste", "Sjoerd", ""], ["Greff", "Klaus", ""], ["Schmidhuber", "J\u00fcrgen", ""]]}, {"id": "1906.01039", "submitter": "Guruprasad Raghavan", "authors": "Guruprasad Raghavan, Matt Thomson", "title": "Neural networks grown and self-organized by noise", "comments": "21 pages (including 11 pages of appendix)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI nlin.AO q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Living neural networks emerge through a process of growth and\nself-organization that begins with a single cell and results in a brain, an\norganized and functional computational device. Artificial neural networks,\nhowever, rely on human-designed, hand-programmed architectures for their\nremarkable performance. Can we develop artificial computational devices that\ncan grow and self-organize without human intervention? In this paper, we\npropose a biologically inspired developmental algorithm that can 'grow' a\nfunctional, layered neural network from a single initial cell. The algorithm\norganizes inter-layer connections to construct a convolutional pooling layer, a\nkey constituent of convolutional neural networks (CNN's). Our approach is\ninspired by the mechanisms employed by the early visual system to wire the\nretina to the lateral geniculate nucleus (LGN), days before animals open their\neyes. The key ingredients for robust self-organization are an emergent\nspontaneous spatiotemporal activity wave in the first layer and a local\nlearning rule in the second layer that 'learns' the underlying activity pattern\nin the first layer. The algorithm is adaptable to a wide-range of input-layer\ngeometries, robust to malfunctioning units in the first layer, and so can be\nused to successfully grow and self-organize pooling architectures of different\npool-sizes and shapes. The algorithm provides a primitive procedure for\nconstructing layered neural networks through growth and self-organization.\nBroadly, our work shows that biologically inspired developmental algorithms can\nbe applied to autonomously grow functional 'brains' in-silico.\n", "versions": [{"version": "v1", "created": "Mon, 3 Jun 2019 19:33:39 GMT"}], "update_date": "2019-06-05", "authors_parsed": [["Raghavan", "Guruprasad", ""], ["Thomson", "Matt", ""]]}, {"id": "1906.01105", "submitter": "Georgiana Dinu", "authors": "Georgiana Dinu, Prashant Mathur, Marcello Federico, Yaser Al-Onaizan", "title": "Training Neural Machine Translation To Apply Terminology Constraints", "comments": "Accepted as a short paper at ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a novel method to inject custom terminology into neural\nmachine translation at run time. Previous works have mainly proposed\nmodifications to the decoding algorithm in order to constrain the output to\ninclude run-time-provided target terms. While being effective, these\nconstrained decoding methods add, however, significant computational overhead\nto the inference step, and, as we show in this paper, can be brittle when\ntested in realistic conditions. In this paper we approach the problem by\ntraining a neural MT system to learn how to use custom terminology when\nprovided with the input. Comparative experiments show that our method is not\nonly more effective than a state-of-the-art implementation of constrained\ndecoding, but is also as fast as constraint-free decoding.\n", "versions": [{"version": "v1", "created": "Mon, 3 Jun 2019 22:33:22 GMT"}, {"version": "v2", "created": "Mon, 24 Jun 2019 19:41:06 GMT"}], "update_date": "2019-06-26", "authors_parsed": [["Dinu", "Georgiana", ""], ["Mathur", "Prashant", ""], ["Federico", "Marcello", ""], ["Al-Onaizan", "Yaser", ""]]}, {"id": "1906.01110", "submitter": "Vahid Behzadan", "authors": "Vahid Behzadan and William Hsu", "title": "RL-Based Method for Benchmarking the Adversarial Resilience and\n  Robustness of Deep Reinforcement Learning Policies", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR cs.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper investigates the resilience and robustness of Deep Reinforcement\nLearning (DRL) policies to adversarial perturbations in the state space. We\nfirst present an approach for the disentanglement of vulnerabilities caused by\nrepresentation learning of DRL agents from those that stem from the sensitivity\nof the DRL policies to distributional shifts in state transitions. Building on\nthis approach, we propose two RL-based techniques for quantitative benchmarking\nof adversarial resilience and robustness in DRL policies against perturbations\nof state transitions. We demonstrate the feasibility of our proposals through\nexperimental evaluation of resilience and robustness in DQN, A2C, and PPO2\npolicies trained in the Cartpole environment.\n", "versions": [{"version": "v1", "created": "Mon, 3 Jun 2019 22:43:54 GMT"}], "update_date": "2019-06-05", "authors_parsed": [["Behzadan", "Vahid", ""], ["Hsu", "William", ""]]}, {"id": "1906.01119", "submitter": "Vahid Behzadan", "authors": "Vahid Behzadan and William Hsu", "title": "Analysis and Improvement of Adversarial Training in DQN Agents With\n  Adversarially-Guided Exploration (AGE)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper investigates the effectiveness of adversarial training in\nenhancing the robustness of Deep Q-Network (DQN) policies to state-space\nperturbations. We first present a formal analysis of adversarial training in\nDQN agents and its performance with respect to the proportion of adversarial\nperturbations to nominal observations used for training. Next, we consider the\nsample-inefficiency of current adversarial training techniques, and propose a\nnovel Adversarially-Guided Exploration (AGE) mechanism based on a modified\nhybrid of the $\\epsilon$-greedy algorithm and Boltzmann exploration. We verify\nthe feasibility of this exploration mechanism through experimental evaluation\nof its performance in comparison with the traditional decaying\n$\\epsilon$-greedy and parameter-space noise exploration algorithms.\n", "versions": [{"version": "v1", "created": "Mon, 3 Jun 2019 23:31:25 GMT"}], "update_date": "2019-06-05", "authors_parsed": [["Behzadan", "Vahid", ""], ["Hsu", "William", ""]]}, {"id": "1906.01121", "submitter": "Vahid Behzadan", "authors": "Vahid Behzadan and William Hsu", "title": "Adversarial Exploitation of Policy Imitation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper investigates a class of attacks targeting the confidentiality\naspect of security in Deep Reinforcement Learning (DRL) policies. Recent\nresearch have established the vulnerability of supervised machine learning\nmodels (e.g., classifiers) to model extraction attacks. Such attacks leverage\nthe loosely-restricted ability of the attacker to iteratively query the model\nfor labels, thereby allowing for the forging of a labeled dataset which can be\nused to train a replica of the original model. In this work, we demonstrate the\nfeasibility of exploiting imitation learning techniques in launching model\nextraction attacks on DRL agents. Furthermore, we develop proof-of-concept\nattacks that leverage such techniques for black-box attacks against the\nintegrity of DRL policies. We also present a discussion on potential solution\nconcepts for mitigation techniques.\n", "versions": [{"version": "v1", "created": "Mon, 3 Jun 2019 23:38:33 GMT"}], "update_date": "2019-06-05", "authors_parsed": [["Behzadan", "Vahid", ""], ["Hsu", "William", ""]]}, {"id": "1906.01126", "submitter": "Vahid Behzadan", "authors": "Vahid Behzadan and William Hsu", "title": "Sequential Triggers for Watermarking of Deep Reinforcement Learning\n  Policies", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a novel scheme for the watermarking of Deep Reinforcement\nLearning (DRL) policies. This scheme provides a mechanism for the integration\nof a unique identifier within the policy in the form of its response to a\ndesignated sequence of state transitions, while incurring minimal impact on the\nnominal performance of the policy. The applications of this watermarking scheme\ninclude detection of unauthorized replications of proprietary policies, as well\nas enabling the graceful interruption or termination of DRL activities by\nauthorized entities. We demonstrate the feasibility of our proposal via\nexperimental evaluation of watermarking a DQN policy trained in the Cartpole\nenvironment.\n", "versions": [{"version": "v1", "created": "Mon, 3 Jun 2019 23:42:44 GMT"}], "update_date": "2019-06-05", "authors_parsed": [["Behzadan", "Vahid", ""], ["Hsu", "William", ""]]}, {"id": "1906.01140", "submitter": "Bo Yang", "authors": "Bo Yang, Jianan Wang, Ronald Clark, Qingyong Hu, Sen Wang, Andrew\n  Markham, Niki Trigoni", "title": "Learning Object Bounding Boxes for 3D Instance Segmentation on Point\n  Clouds", "comments": "NeurIPS 2019 Spotlight. Code and data are available at\n  https://github.com/Yang7879/3D-BoNet", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel, conceptually simple and general framework for instance\nsegmentation on 3D point clouds. Our method, called 3D-BoNet, follows the\nsimple design philosophy of per-point multilayer perceptrons (MLPs). The\nframework directly regresses 3D bounding boxes for all instances in a point\ncloud, while simultaneously predicting a point-level mask for each instance. It\nconsists of a backbone network followed by two parallel network branches for 1)\nbounding box regression and 2) point mask prediction. 3D-BoNet is single-stage,\nanchor-free and end-to-end trainable. Moreover, it is remarkably\ncomputationally efficient as, unlike existing approaches, it does not require\nany post-processing steps such as non-maximum suppression, feature sampling,\nclustering or voting. Extensive experiments show that our approach surpasses\nexisting work on both ScanNet and S3DIS datasets while being approximately 10x\nmore computationally efficient. Comprehensive ablation studies demonstrate the\neffectiveness of our design.\n", "versions": [{"version": "v1", "created": "Tue, 4 Jun 2019 00:33:56 GMT"}, {"version": "v2", "created": "Thu, 5 Sep 2019 06:47:05 GMT"}], "update_date": "2019-09-06", "authors_parsed": [["Yang", "Bo", ""], ["Wang", "Jianan", ""], ["Clark", "Ronald", ""], ["Hu", "Qingyong", ""], ["Wang", "Sen", ""], ["Markham", "Andrew", ""], ["Trigoni", "Niki", ""]]}, {"id": "1906.01167", "submitter": "Lingjuan Lyu", "authors": "Lingjuan Lyu, Jiangshan Yu, Karthik Nandakumar, Yitong Li, Xingjun Ma,\n  Jiong Jin, Han Yu, and Kee Siong Ng", "title": "Towards Fair and Privacy-Preserving Federated Deep Models", "comments": "Accepted for publication in TPDS", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The current standalone deep learning framework tends to result in overfitting\nand low utility. This problem can be addressed by either a centralized\nframework that deploys a central server to train a global model on the joint\ndata from all parties, or a distributed framework that leverages a parameter\nserver to aggregate local model updates. Server-based solutions are prone to\nthe problem of a single-point-of-failure. In this respect, collaborative\nlearning frameworks, such as federated learning (FL), are more robust. Existing\nfederated learning frameworks overlook an important aspect of participation:\nfairness. All parties are given the same final model without regard to their\ncontributions. To address these issues, we propose a decentralized Fair and\nPrivacy-Preserving Deep Learning (FPPDL) framework to incorporate fairness into\nfederated deep learning models. In particular, we design a local credibility\nmutual evaluation mechanism to guarantee fairness, and a three-layer\nonion-style encryption scheme to guarantee both accuracy and privacy. Different\nfrom existing FL paradigm, under FPPDL, each participant receives a different\nversion of the FL model with performance commensurate with his contributions.\nExperiments on benchmark datasets demonstrate that FPPDL balances fairness,\nprivacy and accuracy. It enables federated learning ecosystems to detect and\nisolate low-contribution parties, thereby promoting responsible participation.\n", "versions": [{"version": "v1", "created": "Tue, 4 Jun 2019 02:43:42 GMT"}, {"version": "v2", "created": "Wed, 23 Oct 2019 01:09:35 GMT"}, {"version": "v3", "created": "Tue, 19 May 2020 10:43:55 GMT"}], "update_date": "2020-05-20", "authors_parsed": [["Lyu", "Lingjuan", ""], ["Yu", "Jiangshan", ""], ["Nandakumar", "Karthik", ""], ["Li", "Yitong", ""], ["Ma", "Xingjun", ""], ["Jin", "Jiong", ""], ["Yu", "Han", ""], ["Ng", "Kee Siong", ""]]}, {"id": "1906.01178", "submitter": "Fangyuan Zhao", "authors": "Fangyuan Zhao, Xuebin Ren, Shusen Yang and Xinyu Yang", "title": "On Privacy Protection of Latent Dirichlet Allocation Model Training", "comments": "8 pages,5 figures,and is published in International Joint Conferences\n  on Artificial Intelligence", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Latent Dirichlet Allocation (LDA) is a popular topic modeling technique for\ndiscovery of hidden semantic architecture of text datasets, and plays a\nfundamental role in many machine learning applications. However, like many\nother machine learning algorithms, the process of training a LDA model may leak\nthe sensitive information of the training datasets and bring significant\nprivacy risks. To mitigate the privacy issues in LDA, we focus on studying\nprivacy-preserving algorithms of LDA model training in this paper. In\nparticular, we first develop a privacy monitoring algorithm to investigate the\nprivacy guarantee obtained from the inherent randomness of the Collapsed Gibbs\nSampling (CGS) process in a typical LDA training algorithm on centralized\ncurated datasets. Then, we further propose a locally private LDA training\nalgorithm on crowdsourced data to provide local differential privacy for\nindividual data contributors. The experimental results on real-world datasets\ndemonstrate the effectiveness of our proposed algorithms.\n", "versions": [{"version": "v1", "created": "Tue, 4 Jun 2019 03:25:17 GMT"}, {"version": "v2", "created": "Mon, 1 Jul 2019 12:56:11 GMT"}], "update_date": "2019-07-02", "authors_parsed": [["Zhao", "Fangyuan", ""], ["Ren", "Xuebin", ""], ["Yang", "Shusen", ""], ["Yang", "Xinyu", ""]]}, {"id": "1906.01210", "submitter": "Qimai Li", "authors": "Xiaotong Zhang, Han Liu, Qimai Li, and Xiao-Ming Wu", "title": "Attributed Graph Clustering via Adaptive Graph Convolution", "comments": "IJCAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Attributed graph clustering is challenging as it requires joint modelling of\ngraph structures and node attributes. Recent progress on graph convolutional\nnetworks has proved that graph convolution is effective in combining structural\nand content information, and several recent methods based on it have achieved\npromising clustering performance on some real attributed networks. However,\nthere is limited understanding of how graph convolution affects clustering\nperformance and how to properly use it to optimize performance for different\ngraphs. Existing methods essentially use graph convolution of a fixed and low\norder that only takes into account neighbours within a few hops of each node,\nwhich underutilizes node relations and ignores the diversity of graphs. In this\npaper, we propose an adaptive graph convolution method for attributed graph\nclustering that exploits high-order graph convolution to capture global cluster\nstructure and adaptively selects the appropriate order for different graphs. We\nestablish the validity of our method by theoretical analysis and extensive\nexperiments on benchmark datasets. Empirical results show that our method\ncompares favourably with state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Tue, 4 Jun 2019 06:01:10 GMT"}], "update_date": "2019-06-05", "authors_parsed": [["Zhang", "Xiaotong", ""], ["Liu", "Han", ""], ["Li", "Qimai", ""], ["Wu", "Xiao-Ming", ""]]}, {"id": "1906.01231", "submitter": "Wei Li", "authors": "Wei Li, Jingjing Xu, Yancheng He, Shengli Yan, Yunfang Wu, Xu sun", "title": "Coherent Comment Generation for Chinese Articles with a\n  Graph-to-Sequence Model", "comments": "Accepted by ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic article commenting is helpful in encouraging user engagement and\ninteraction on online news platforms. However, the news documents are usually\ntoo long for traditional encoder-decoder based models, which often results in\ngeneral and irrelevant comments. In this paper, we propose to generate comments\nwith a graph-to-sequence model that models the input news as a topic\ninteraction graph. By organizing the article into graph structure, our model\ncan better understand the internal structure of the article and the connection\nbetween topics, which makes it better able to understand the story. We collect\nand release a large scale news-comment corpus from a popular Chinese online\nnews platform Tencent Kuaibao. Extensive experiment results show that our model\ncan generate much more coherent and informative comments compared with several\nstrong baseline models.\n", "versions": [{"version": "v1", "created": "Tue, 4 Jun 2019 07:03:04 GMT"}], "update_date": "2019-06-05", "authors_parsed": [["Li", "Wei", ""], ["Xu", "Jingjing", ""], ["He", "Yancheng", ""], ["Yan", "Shengli", ""], ["Wu", "Yunfang", ""], ["sun", "Xu", ""]]}, {"id": "1906.01234", "submitter": "Dieuwke Hupkes", "authors": "Kris Korrel, Dieuwke Hupkes, Verna Dankers and Elia Bruni", "title": "Transcoding compositionally: using attention to find more generalizable\n  solutions", "comments": "to appear at BlackboxNLP 2019, ACL", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While sequence-to-sequence models have shown remarkable generalization power\nacross several natural language tasks, their construct of solutions are argued\nto be less compositional than human-like generalization. In this paper, we\npresent seq2attn, a new architecture that is specifically designed to exploit\nattention to find compositional patterns in the input. In seq2attn, the two\nstandard components of an encoder-decoder model are connected via a transcoder,\nthat modulates the information flow between them. We show that seq2attn can\nsuccessfully generalize, without requiring any additional supervision, on two\ntasks which are specifically constructed to challenge the compositional skills\nof neural networks. The solutions found by the model are highly interpretable,\nallowing easy analysis of both the types of solutions that are found and\npotential causes for mistakes. We exploit this opportunity to introduce a new\nparadigm to test compositionality that studies the extent to which a model\novergeneralizes when confronted with exceptions. We show that seq2attn exhibits\nsuch overgeneralization to a larger degree than a standard sequence-to-sequence\nmodel.\n", "versions": [{"version": "v1", "created": "Tue, 4 Jun 2019 07:07:56 GMT"}, {"version": "v2", "created": "Thu, 6 Jun 2019 08:34:09 GMT"}], "update_date": "2019-06-07", "authors_parsed": [["Korrel", "Kris", ""], ["Hupkes", "Dieuwke", ""], ["Dankers", "Verna", ""], ["Bruni", "Elia", ""]]}, {"id": "1906.01246", "submitter": "Paolo Casari", "authors": "Rafael Garcia Leiva, Antonio Fernandez Anta, Vincenzo Mancuso, Paolo\n  Casari", "title": "A Novel Hyperparameter-free Approach to Decision Tree Construction that\n  Avoids Overfitting by Design", "comments": "Submitted to IEEE Access", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Decision trees are an extremely popular machine learning technique.\nUnfortunately, overfitting in decision trees still remains an open issue that\nsometimes prevents achieving good performance. In this work, we present a novel\napproach for the construction of decision trees that avoids the overfitting by\ndesign, without losing accuracy. A distinctive feature of our algorithm is that\nit requires neither the optimization of any hyperparameters, nor the use of\nregularization techniques, thus significantly reducing the decision tree\ntraining time. Moreover, our algorithm produces much smaller and shallower\ntrees than traditional algorithms, facilitating the interpretability of the\nresulting models.\n", "versions": [{"version": "v1", "created": "Tue, 4 Jun 2019 07:30:32 GMT"}], "update_date": "2019-06-05", "authors_parsed": [["Leiva", "Rafael Garcia", ""], ["Anta", "Antonio Fernandez", ""], ["Mancuso", "Vincenzo", ""], ["Casari", "Paolo", ""]]}, {"id": "1906.01250", "submitter": "Phong Le", "authors": "Phong Le and Ivan Titov", "title": "Boosting Entity Linking Performance by Leveraging Unlabeled Documents", "comments": "ACL2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern entity linking systems rely on large collections of documents\nspecifically annotated for the task (e.g., AIDA CoNLL). In contrast, we propose\nan approach which exploits only naturally occurring information: unlabeled\ndocuments and Wikipedia. Our approach consists of two stages. First, we\nconstruct a high recall list of candidate entities for each mention in an\nunlabeled document. Second, we use the candidate lists as weak supervision to\nconstrain our document-level entity linking model. The model treats entities as\nlatent variables and, when estimated on a collection of unlabelled texts,\nlearns to choose entities relying both on local context of each mention and on\ncoherence with other entities in the document. The resulting approach rivals\nfully-supervised state-of-the-art systems on standard test sets. It also\napproaches their performance in the very challenging setting: when tested on a\ntest set sampled from the data used to estimate the supervised systems. By\ncomparing to Wikipedia-only training of our model, we demonstrate that modeling\nunlabeled documents is beneficial.\n", "versions": [{"version": "v1", "created": "Tue, 4 Jun 2019 07:49:46 GMT"}], "update_date": "2019-06-05", "authors_parsed": [["Le", "Phong", ""], ["Titov", "Ivan", ""]]}, {"id": "1906.01350", "submitter": "Andreas Orthey", "authors": "Andreas Orthey and Marc Toussaint", "title": "Rapidly-Exploring Quotient-Space Trees: Motion Planning using Sequential\n  Simplifications", "comments": "The International Symposium on Robotics Research (ISRR) 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motion planning problems can be simplified by admissible projections of the\nconfiguration space to sequences of lower-dimensional quotient-spaces, called\nsequential simplifications. To exploit sequential simplifications, we present\nthe Quotient-space Rapidly-exploring Random Trees (QRRT) algorithm. QRRT takes\nas input a start and a goal configuration, and a sequence of quotient-spaces.\nThe algorithm grows trees on the quotient-spaces both sequentially and\nsimultaneously to guarantee a dense coverage. QRRT is shown to be (1)\nprobabilistically complete, and (2) can reduce the runtime by at least one\norder of magnitude. However, we show in experiments that the runtime varies\nsubstantially between different quotient-space sequences. To find out why, we\nperform an additional experiment, showing that the more narrow an environment,\nthe more a quotient-space sequence can reduce runtime.\n", "versions": [{"version": "v1", "created": "Tue, 4 Jun 2019 11:23:38 GMT"}, {"version": "v2", "created": "Sat, 24 Aug 2019 16:40:10 GMT"}], "update_date": "2019-08-27", "authors_parsed": [["Orthey", "Andreas", ""], ["Toussaint", "Marc", ""]]}, {"id": "1906.01374", "submitter": "Vieri Giuliano Santucci", "authors": "Vieri Giuliano Santucci and Gianluca Baldassarre and Emilio Cartoni", "title": "Autonomous Reinforcement Learning of Multiple Interrelated Tasks", "comments": "Accepted to \"The 9th Joint IEEE International Conference on\n  Development and Learning and on Epigenetic Robotics\" (ICDL-EpiRob2019). arXiv\n  admin note: substantial text overlap with arXiv:1905.02690", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Autonomous multiple tasks learning is a fundamental capability to develop\nversatile artificial agents that can act in complex environments. In real-world\nscenarios, tasks may be interrelated (or \"hierarchical\") so that a robot has to\nfirst learn to achieve some of them to set the preconditions for learning other\nones. Even though different strategies have been used in robotics to tackle the\nacquisition of interrelated tasks, in particular within the developmental\nrobotics framework, autonomous learning in this kind of scenarios is still an\nopen question. Building on previous research in the framework of intrinsically\nmotivated open-ended learning, in this work we describe how this question can\nbe addressed working on the level of task selection, in particular considering\nthe multiple interrelated tasks scenario as an MDP where the system is trying\nto maximise its competence over all the tasks.\n", "versions": [{"version": "v1", "created": "Tue, 4 Jun 2019 12:30:04 GMT"}], "update_date": "2019-06-05", "authors_parsed": [["Santucci", "Vieri Giuliano", ""], ["Baldassarre", "Gianluca", ""], ["Cartoni", "Emilio", ""]]}, {"id": "1906.01393", "submitter": "Martin Schmitt", "authors": "Martin Schmitt and Hinrich Sch\\\"utze", "title": "SherLIiC: A Typed Event-Focused Lexical Inference Benchmark for\n  Evaluating Natural Language Inference", "comments": "Accepted as a long paper to ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present SherLIiC, a testbed for lexical inference in context (LIiC),\nconsisting of 3985 manually annotated inference rule candidates (InfCands),\naccompanied by (i) ~960k unlabeled InfCands, and (ii) ~190k typed textual\nrelations between Freebase entities extracted from the large entity-linked\ncorpus ClueWeb09. Each InfCand consists of one of these relations, expressed as\na lemmatized dependency path, and two argument placeholders, each linked to one\nor more Freebase types. Due to our candidate selection process based on strong\ndistributional evidence, SherLIiC is much harder than existing testbeds because\ndistributional evidence is of little utility in the classification of InfCands.\nWe also show that, due to its construction, many of SherLIiC's correct InfCands\nare novel and missing from existing rule bases. We evaluate a number of strong\nbaselines on SherLIiC, ranging from semantic vector space models to state of\nthe art neural models of natural language inference (NLI). We show that\nSherLIiC poses a tough challenge to existing NLI systems.\n", "versions": [{"version": "v1", "created": "Tue, 4 Jun 2019 13:07:35 GMT"}], "update_date": "2019-06-05", "authors_parsed": [["Schmitt", "Martin", ""], ["Sch\u00fctze", "Hinrich", ""]]}, {"id": "1906.01401", "submitter": "Alban Laflaqui\\`ere Dr", "authors": "Alban Laflaqui\\`ere, Michael Garcia Ortiz", "title": "Unsupervised Emergence of Egocentric Spatial Structure from Sensorimotor\n  Prediction", "comments": "27 pages, 16 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite its omnipresence in robotics application, the nature of spatial\nknowledge and the mechanisms that underlie its emergence in autonomous agents\nare still poorly understood. Recent theoretical works suggest that the\nEuclidean structure of space induces invariants in an agent's raw sensorimotor\nexperience. We hypothesize that capturing these invariants is beneficial for\nsensorimotor prediction and that, under certain exploratory conditions, a motor\nrepresentation capturing the structure of the external space should emerge as a\nbyproduct of learning to predict future sensory experiences. We propose a\nsimple sensorimotor predictive scheme, apply it to different agents and types\nof exploration, and evaluate the pertinence of these hypotheses. We show that a\nnaive agent can capture the topology and metric regularity of its sensor's\nposition in an egocentric spatial frame without any a priori knowledge, nor\nextraneous supervision.\n", "versions": [{"version": "v1", "created": "Tue, 4 Jun 2019 13:13:31 GMT"}, {"version": "v2", "created": "Mon, 16 Sep 2019 10:17:17 GMT"}, {"version": "v3", "created": "Tue, 17 Sep 2019 10:50:45 GMT"}], "update_date": "2019-09-18", "authors_parsed": [["Laflaqui\u00e8re", "Alban", ""], ["Ortiz", "Michael Garcia", ""]]}, {"id": "1906.01407", "submitter": "Hao Lu", "authors": "Hao Lu, Mengdi Wang", "title": "RL4health: Crowdsourcing Reinforcement Learning for Knee Replacement\n  Pathway Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Joint replacement is the most common inpatient surgical treatment in the US.\nWe investigate the clinical pathway optimization for knee replacement, which is\na sequential decision process from onset to recovery. Based on episodic claims\nfrom previous cases, we view the pathway optimization as an intelligence\ncrowdsourcing problem and learn the optimal decision policy from data by\nimitating the best expert at every intermediate state. We develop a\nreinforcement learning-based pipeline that uses value iteration, state\ncompression and aggregation learning, kernel representation and cross\nvalidation to predict the best treatment policy. It also provides forecast of\nthe clinical pathway under the optimized policy. Empirical validation shows\nthat the optimized policy reduces the overall cost by 7 percent and reduces the\nexcessive cost premium by 33 percent.\n", "versions": [{"version": "v1", "created": "Fri, 24 May 2019 22:12:02 GMT"}], "update_date": "2019-06-05", "authors_parsed": [["Lu", "Hao", ""], ["Wang", "Mengdi", ""]]}, {"id": "1906.01408", "submitter": "Caleb Chuck", "authors": "Caleb Chuck, Supawit Chockchowwat, Scott Niekum", "title": "Hypothesis-Driven Skill Discovery for Hierarchical Deep Reinforcement\n  Learning", "comments": "Submitted to IROS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep reinforcement learning (DRL) is capable of learning high-performing\npolicies on a variety of complex high-dimensional tasks, ranging from video\ngames to robotic manipulation. However, standard DRL methods often suffer from\npoor sample efficiency, partially because they aim to be entirely\nproblem-agnostic. In this work, we introduce a novel approach to exploration\nand hierarchical skill learning that derives its sample efficiency from\nintuitive assumptions it makes about the behavior of objects both in the\nphysical world and simulations which mimic physics. Specifically, we propose\nthe Hypothesis Proposal and Evaluation (HyPE) algorithm, which discovers\nobjects from raw pixel data, generates hypotheses about the controllability of\nobserved changes in object state, and learns a hierarchy of skills to test\nthese hypotheses. We demonstrate that HyPE can dramatically improve the sample\nefficiency of policy learning in two different domains: a simulated robotic\nblock-pushing domain, and a popular benchmark task: Breakout. In these domains,\nHyPE learns high-scoring policies an order of magnitude faster than several\nstate-of-the-art reinforcement learning methods.\n", "versions": [{"version": "v1", "created": "Mon, 27 May 2019 13:17:35 GMT"}, {"version": "v2", "created": "Mon, 8 Jul 2019 22:33:11 GMT"}, {"version": "v3", "created": "Tue, 3 Mar 2020 17:59:13 GMT"}], "update_date": "2020-03-04", "authors_parsed": [["Chuck", "Caleb", ""], ["Chockchowwat", "Supawit", ""], ["Niekum", "Scott", ""]]}, {"id": "1906.01432", "submitter": "Mayukh Das", "authors": "Mayukh Das, Devendra Singh Dhami, Yang Yu, Gautam Kunapuli, Sriraam\n  Natarajan", "title": "Knowledge-augmented Column Networks: Guiding Deep Learning with Advice", "comments": "Presented at 2019 ICML Workshop on Human in the Loop Learning (HILL\n  2019), Long Beach, USA. arXiv admin note: substantial text overlap with\n  arXiv:1904.06950", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, deep models have had considerable success in several tasks,\nespecially with low-level representations. However, effective learning from\nsparse noisy samples is a major challenge in most deep models, especially in\ndomains with structured representations. Inspired by the proven success of\nhuman guided machine learning, we propose Knowledge-augmented Column Networks,\na relational deep learning framework that leverages human advice/knowledge to\nlearn better models in presence of sparsity and systematic noise.\n", "versions": [{"version": "v1", "created": "Fri, 31 May 2019 21:09:21 GMT"}], "update_date": "2019-06-05", "authors_parsed": [["Das", "Mayukh", ""], ["Dhami", "Devendra Singh", ""], ["Yu", "Yang", ""], ["Kunapuli", "Gautam", ""], ["Natarajan", "Sriraam", ""]]}, {"id": "1906.01440", "submitter": "Rocco Tripodi", "authors": "Rocco Tripodi, Massimo Warglien, Simon Levis Sullam and Deborah Paci", "title": "Tracing Antisemitic Language Through Diachronic Embedding Projections:\n  France 1789-1914", "comments": "Accepted to the 1st International Workshop on Computational\n  Approaches to Historical Language Change 2019 (ACL 2019). 11 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.DL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We investigate some aspects of the history of antisemitism in France, one of\nthe cradles of modern antisemitism, using diachronic word embeddings. We\nconstructed a large corpus of French books and periodicals issues that contain\na keyword related to Jews and performed a diachronic word embedding over the\n1789-1914 period. We studied the changes over time in the semantic spaces of 4\ntarget words and performed embedding projections over 6 streams of antisemitic\ndiscourse. This allowed us to track the evolution of antisemitic bias in the\nreligious, economic, socio-politic, racial, ethic and conspiratorial domains.\nProjections show a trend of growing antisemitism, especially in the years\nstarting in the mid-80s and culminating in the Dreyfus affair. Our analysis\nalso allows us to highlight the peculiar adverse bias towards Judaism in the\nbroader context of other religions.\n", "versions": [{"version": "v1", "created": "Tue, 4 Jun 2019 13:54:47 GMT"}], "update_date": "2019-06-05", "authors_parsed": [["Tripodi", "Rocco", ""], ["Warglien", "Massimo", ""], ["Sullam", "Simon Levis", ""], ["Paci", "Deborah", ""]]}, {"id": "1906.01470", "submitter": "Alexander Vezhnevets", "authors": "Alexander Sasha Vezhnevets, Yuhuai Wu, Remi Leblond, Joel Z. Leibo", "title": "Options as responses: Grounding behavioural hierarchies in multi-agent\n  RL", "comments": "First two authors contributed equally", "journal-ref": "International Conference on Machine Learning 2020", "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper investigates generalisation in multi-agent games, where the\ngenerality of the agent can be evaluated by playing against opponents it hasn't\nseen during training. We propose two new games with concealed information and\ncomplex, non-transitive reward structure (think rock/paper/scissors). It turns\nout that most current deep reinforcement learning methods fail to efficiently\nexplore the strategy space, thus learning policies that generalise poorly to\nunseen opponents. We then propose a novel hierarchical agent architecture,\nwhere the hierarchy is grounded in the game-theoretic structure of the game --\nthe top level chooses strategic responses to opponents, while the low level\nimplements them into policy over primitive actions. This grounding facilitates\ncredit assignment across the levels of hierarchy. Our experiments show that the\nproposed hierarchical agent is capable of generalisation to unseen opponents,\nwhile conventional baselines fail to generalise whatsoever.\n", "versions": [{"version": "v1", "created": "Tue, 4 Jun 2019 14:18:47 GMT"}, {"version": "v2", "created": "Thu, 6 Jun 2019 15:10:59 GMT"}, {"version": "v3", "created": "Fri, 10 Jul 2020 13:31:16 GMT"}], "update_date": "2020-07-13", "authors_parsed": [["Vezhnevets", "Alexander Sasha", ""], ["Wu", "Yuhuai", ""], ["Leblond", "Remi", ""], ["Leibo", "Joel Z.", ""]]}, {"id": "1906.01502", "submitter": "Telmo Pires", "authors": "Telmo Pires, Eva Schlinger and Dan Garrette", "title": "How multilingual is Multilingual BERT?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we show that Multilingual BERT (M-BERT), released by Devlin et\nal. (2018) as a single language model pre-trained from monolingual corpora in\n104 languages, is surprisingly good at zero-shot cross-lingual model transfer,\nin which task-specific annotations in one language are used to fine-tune the\nmodel for evaluation in another language. To understand why, we present a large\nnumber of probing experiments, showing that transfer is possible even to\nlanguages in different scripts, that transfer works best between typologically\nsimilar languages, that monolingual corpora can train models for\ncode-switching, and that the model can find translation pairs. From these\nresults, we can conclude that M-BERT does create multilingual representations,\nbut that these representations exhibit systematic deficiencies affecting\ncertain language pairs.\n", "versions": [{"version": "v1", "created": "Tue, 4 Jun 2019 15:12:47 GMT"}], "update_date": "2019-06-05", "authors_parsed": [["Pires", "Telmo", ""], ["Schlinger", "Eva", ""], ["Garrette", "Dan", ""]]}, {"id": "1906.01504", "submitter": "Matteo Fischetti", "authors": "Matteo Fischetti and Matteo Stringher", "title": "Embedded hyper-parameter tuning by Simulated Annealing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.DM math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new metaheuristic training scheme that combines Stochastic\nGradient Descent (SGD) and Discrete Optimization in an unconventional way. Our\nidea is to define a discrete neighborhood of the current SGD point containing a\nnumber of \"potentially good moves\" that exploit gradient information, and to\nsearch this neighborhood by using a classical metaheuristic scheme borrowed\nfrom Discrete Optimization.\n  In the present paper we investigate the use of a simple Simulated Annealing\n(SA) metaheuristic that accepts/rejects a candidate new solution in the\nneighborhood with a probability that depends both on the new solution quality\nand on a parameter (the temperature) which is modified over time to lower the\nprobability of accepting worsening moves. We use this scheme as an automatic\nway to perform hyper-parameter tuning, hence the title of the paper. A\ndistinctive feature of our scheme is that hyper-parameters are modified within\na single SGD execution (and not in an external loop, as customary) and\nevaluated on the fly on the current minibatch, i.e., their tuning is fully\nembedded within the SGD algorithm.\n  The use of SA for training is not new, but previous proposals were mainly\nintended for non-differentiable objective functions for which SGD is not\napplied due to the lack of gradients. On the contrary, our SA method requires\ndifferentiability of (a proxy of) the loss function, and leverages on the\navailability of a gradient direction to define local moves that have a large\nprobability to improve the current solution.\n  Computational results on image classification (CIFAR-10) are reported,\nshowing that the proposed approach leads to an improvement of the final\nvalidation accuracy for modern Deep Neural Networks such as ResNet34 and VGG16.\n", "versions": [{"version": "v1", "created": "Tue, 4 Jun 2019 15:14:36 GMT"}], "update_date": "2019-06-05", "authors_parsed": [["Fischetti", "Matteo", ""], ["Stringher", "Matteo", ""]]}, {"id": "1906.01528", "submitter": "Zhe Feng", "authors": "Zhe Feng, David C. Parkes, Haifeng Xu", "title": "The Intrinsic Robustness of Stochastic Bandits to Strategic Manipulation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.GT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by economic applications such as recommender systems, we study the\nbehavior of stochastic bandits algorithms under \\emph{strategic behavior}\nconducted by rational actors, i.e., the arms. Each arm is a\n\\emph{self-interested} strategic player who can modify its own reward whenever\npulled, subject to a cross-period budget constraint, in order to maximize its\nown expected number of times of being pulled. We analyze the robustness of\nthree popular bandit algorithms: UCB, $\\varepsilon$-Greedy, and Thompson\nSampling. We prove that all three algorithms achieve a regret upper bound\n$\\mathcal{O}(\\max \\{ B, K\\ln T\\})$ where $B$ is the total budget across arms,\n$K$ is the total number of arms and $T$ is length of the time horizon. This\nregret guarantee holds under \\emph{arbitrary adaptive} manipulation strategy of\narms. Our second set of main results shows that this regret bound is\n\\emph{tight} -- in fact for UCB it is tight even when we restrict the arms'\nmanipulation strategies to form a \\emph{Nash equilibrium}. The lower bound\nmakes use of a simple manipulation strategy, the same for all three algorithms,\nyielding a bound of $\\Omega(\\max \\{ B, K\\ln T\\})$. Our results illustrate the\nrobustness of classic bandits algorithms against strategic manipulations as\nlong as $B=o(T)$.\n", "versions": [{"version": "v1", "created": "Tue, 4 Jun 2019 15:40:49 GMT"}, {"version": "v2", "created": "Thu, 12 Nov 2020 21:56:33 GMT"}], "update_date": "2020-11-16", "authors_parsed": [["Feng", "Zhe", ""], ["Parkes", "David C.", ""], ["Xu", "Haifeng", ""]]}, {"id": "1906.01530", "submitter": "Janosch Haber", "authors": "Janosch Haber, Tim Baumg\\\"artner, Ece Takmaz, Lieke Gelderloos, Elia\n  Bruni and Raquel Fern\\'andez", "title": "The PhotoBook Dataset: Building Common Ground through Visually-Grounded\n  Dialogue", "comments": "Updates 26-06-2019: Changed caption sizes to comply with the ACL\n  style guidelines and corrected some references", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces the PhotoBook dataset, a large-scale collection of\nvisually-grounded, task-oriented dialogues in English designed to investigate\nshared dialogue history accumulating during conversation. Taking inspiration\nfrom seminal work on dialogue analysis, we propose a data-collection task\nformulated as a collaborative game prompting two online participants to refer\nto images utilising both their visual context as well as previously established\nreferring expressions. We provide a detailed description of the task setup and\na thorough analysis of the 2,500 dialogues collected. To further illustrate the\nnovel features of the dataset, we propose a baseline model for reference\nresolution which uses a simple method to take into account shared information\naccumulated in a reference chain. Our results show that this information is\nparticularly important to resolve later descriptions and underline the need to\ndevelop more sophisticated models of common ground in dialogue interaction.\n", "versions": [{"version": "v1", "created": "Tue, 4 Jun 2019 15:41:32 GMT"}, {"version": "v2", "created": "Wed, 26 Jun 2019 17:36:47 GMT"}], "update_date": "2019-06-27", "authors_parsed": [["Haber", "Janosch", ""], ["Baumg\u00e4rtner", "Tim", ""], ["Takmaz", "Ece", ""], ["Gelderloos", "Lieke", ""], ["Bruni", "Elia", ""], ["Fern\u00e1ndez", "Raquel", ""]]}, {"id": "1906.01539", "submitter": "Samira Abnar", "authors": "Samira Abnar, Lisa Beinborn, Rochelle Choenni, Willem Zuidema", "title": "Blackbox meets blackbox: Representational Similarity and Stability\n  Analysis of Neural Language Models and Brains", "comments": null, "journal-ref": "2nd BlackBoxNLP workshop @ACL2019", "doi": null, "report-no": null, "categories": "cs.AI cs.CL q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we define and apply representational stability analysis\n(ReStA), an intuitive way of analyzing neural language models. ReStA is a\nvariant of the popular representational similarity analysis (RSA) in cognitive\nneuroscience. While RSA can be used to compare representations in models, model\ncomponents, and human brains, ReStA compares instances of the same model, while\nsystematically varying single model parameter. Using ReStA, we study four\nrecent and successful neural language models, and evaluate how sensitive their\ninternal representations are to the amount of prior context. Using RSA, we\nperform a systematic study of how similar the representational spaces in the\nfirst and second (or higher) layers of these models are to each other and to\npatterns of activation in the human brain. Our results reveal surprisingly\nstrong differences between language models, and give insights into where the\ndeep linguistic processing, that integrates information over multiple\nsentences, is happening in these models. The combination of ReStA and RSA on\nmodels and brains allows us to start addressing the important question of what\nkind of linguistic processes we can hope to observe in fMRI brain imaging data.\nIn particular, our results suggest that the data on story reading from Wehbe et\nal. (2014) contains a signal of shallow linguistic processing, but show no\nevidence on the more interesting deep linguistic processing.\n", "versions": [{"version": "v1", "created": "Tue, 4 Jun 2019 15:52:46 GMT"}, {"version": "v2", "created": "Wed, 5 Jun 2019 09:58:34 GMT"}], "update_date": "2019-06-06", "authors_parsed": [["Abnar", "Samira", ""], ["Beinborn", "Lisa", ""], ["Choenni", "Rochelle", ""], ["Zuidema", "Willem", ""]]}, {"id": "1906.01548", "submitter": "Abu Sebastian", "authors": "Geethan Karunaratne, Manuel Le Gallo, Giovanni Cherubini, Luca Benini,\n  Abbas Rahimi, Abu Sebastian", "title": "In-memory hyperdimensional computing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.ET cs.AI physics.app-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hyperdimensional computing (HDC) is an emerging computational framework that\ntakes inspiration from attributes of neuronal circuits such as\nhyperdimensionality, fully distributed holographic representation, and\n(pseudo)randomness. When employed for machine learning tasks such as learning\nand classification, HDC involves manipulation and comparison of large patterns\nwithin memory. Moreover, a key attribute of HDC is its robustness to the\nimperfections associated with the computational substrates on which it is\nimplemented. It is therefore particularly amenable to emerging non-von Neumann\nparadigms such as in-memory computing, where the physical attributes of\nnanoscale memristive devices are exploited to perform computation in place.\nHere, we present a complete in-memory HDC system that achieves a near optimum\ntrade-off between design complexity and classification accuracy based on three\nprototypical HDC related learning tasks, namely, language classification, news\nclassification, and hand gesture recognition from electromyography signals.\nComparable accuracies to software implementations are demonstrated,\nexperimentally, using 760,000 phase-change memory devices performing analog\nin-memory computing.\n", "versions": [{"version": "v1", "created": "Tue, 4 Jun 2019 16:06:51 GMT"}, {"version": "v2", "created": "Thu, 9 Apr 2020 11:04:05 GMT"}], "update_date": "2020-04-10", "authors_parsed": [["Karunaratne", "Geethan", ""], ["Gallo", "Manuel Le", ""], ["Cherubini", "Giovanni", ""], ["Benini", "Luca", ""], ["Rahimi", "Abbas", ""], ["Sebastian", "Abu", ""]]}, {"id": "1906.01558", "submitter": "Drew Linsley", "authors": "Junkyung Kim, Drew Linsley, Kalpit Thakkar, Thomas Serre", "title": "Disentangling neural mechanisms for perceptual grouping", "comments": "Published in ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Forming perceptual groups and individuating objects in visual scenes is an\nessential step towards visual intelligence. This ability is thought to arise in\nthe brain from computations implemented by bottom-up, horizontal, and top-down\nconnections between neurons. However, the relative contributions of these\nconnections to perceptual grouping are poorly understood. We address this\nquestion by systematically evaluating neural network architectures featuring\ncombinations bottom-up, horizontal, and top-down connections on two synthetic\nvisual tasks, which stress low-level \"Gestalt\" vs. high-level object cues for\nperceptual grouping. We show that increasing the difficulty of either task\nstrains learning for networks that rely solely on bottom-up connections.\nHorizontal connections resolve straining on tasks with Gestalt cues by\nsupporting incremental grouping, whereas top-down connections rescue learning\non tasks with high-level object cues by modifying coarse predictions about the\nposition of the target object. Our findings dissociate the computational roles\nof bottom-up, horizontal and top-down connectivity, and demonstrate how a model\nfeaturing all of these interactions can more flexibly learn to form perceptual\ngroups.\n", "versions": [{"version": "v1", "created": "Tue, 4 Jun 2019 16:21:46 GMT"}, {"version": "v2", "created": "Wed, 28 Oct 2020 15:53:55 GMT"}], "update_date": "2020-10-29", "authors_parsed": [["Kim", "Junkyung", ""], ["Linsley", "Drew", ""], ["Thakkar", "Kalpit", ""], ["Serre", "Thomas", ""]]}, {"id": "1906.01562", "submitter": "Teng Wang", "authors": "Teng Wang, Jun Zhao, Han Yu, Jinyan Liu, Xinyu Yang, Xuebin Ren, and\n  Shuyu Shi", "title": "Privacy-preserving Crowd-guided AI Decision-making in Ethical Dilemmas", "comments": "This paper has been published as a full paper in ACM International\n  Conference on Information and Knowledge Management (CIKM) 2019, held in\n  November 3-7, 2019, Beijing, China", "journal-ref": null, "doi": "10.1145/3357384.3357954", "report-no": null, "categories": "cs.CR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the rapid development of artificial intelligence (AI), ethical issues\nsurrounding AI have attracted increasing attention. In particular, autonomous\nvehicles may face moral dilemmas in accident scenarios, such as staying the\ncourse resulting in hurting pedestrians or swerving leading to hurting\npassengers. To investigate such ethical dilemmas, recent studies have adopted\npreference aggregation, in which each voter expresses her/his preferences over\ndecisions for the possible ethical dilemma scenarios, and a centralized system\naggregates these preferences to obtain the winning decision. Although a useful\nmethodology for building ethical AI systems, such an approach can potentially\nviolate the privacy of voters since moral preferences are sensitive information\nand their disclosure can be exploited by malicious parties. In this paper, we\nreport a first-of-its-kind privacy-preserving crowd-guided AI decision-making\napproach in ethical dilemmas. We adopt the notion of differential privacy to\nquantify privacy and consider four granularities of privacy protection by\ntaking voter-/record-level privacy protection and centralized/distributed\nperturbation into account, resulting in four approaches VLCP, RLCP, VLDP, and\nRLDP. Moreover, we propose different algorithms to achieve these privacy\nprotection granularities, while retaining the accuracy of the learned moral\npreference model. Specifically, VLCP and RLCP are implemented with the data\naggregator setting a universal privacy parameter and perturbing the averaged\nmoral preference to protect the privacy of voters' data. VLDP and RLDP are\nimplemented in such a way that each voter perturbs her/his local moral\npreference with a personalized privacy parameter. Extensive experiments on both\nsynthetic and real data demonstrate that the proposed approach can achieve high\naccuracy of preference aggregation while protecting individual voter's privacy.\n", "versions": [{"version": "v1", "created": "Tue, 4 Jun 2019 16:27:47 GMT"}, {"version": "v2", "created": "Fri, 27 Sep 2019 13:22:08 GMT"}], "update_date": "2019-09-30", "authors_parsed": [["Wang", "Teng", ""], ["Zhao", "Jun", ""], ["Yu", "Han", ""], ["Liu", "Jinyan", ""], ["Yang", "Xinyu", ""], ["Ren", "Xuebin", ""], ["Shi", "Shuyu", ""]]}, {"id": "1906.01603", "submitter": "Chinnadhurai Sankar", "authors": "Chinnadhurai Sankar, Sandeep Subramanian, Christopher Pal, Sarath\n  Chandar, Yoshua Bengio", "title": "Do Neural Dialog Systems Use the Conversation History Effectively? An\n  Empirical Study", "comments": "To appear at ACL 2019(oral; nominated for best paper)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural generative models have been become increasingly popular when building\nconversational agents. They offer flexibility, can be easily adapted to new\ndomains, and require minimal domain engineering. A common criticism of these\nsystems is that they seldom understand or use the available dialog history\neffectively. In this paper, we take an empirical approach to understanding how\nthese models use the available dialog history by studying the sensitivity of\nthe models to artificially introduced unnatural changes or perturbations to\ntheir context at test time. We experiment with 10 different types of\nperturbations on 4 multi-turn dialog datasets and find that commonly used\nneural dialog architectures like recurrent and transformer-based seq2seq models\nare rarely sensitive to most perturbations such as missing or reordering\nutterances, shuffling words, etc. Also, by open-sourcing our code, we believe\nthat it will serve as a useful diagnostic tool for evaluating dialog systems in\nthe future.\n", "versions": [{"version": "v1", "created": "Tue, 4 Jun 2019 17:32:35 GMT"}, {"version": "v2", "created": "Thu, 25 Jul 2019 20:27:46 GMT"}], "update_date": "2019-07-29", "authors_parsed": [["Sankar", "Chinnadhurai", ""], ["Subramanian", "Sandeep", ""], ["Pal", "Christopher", ""], ["Chandar", "Sarath", ""], ["Bengio", "Yoshua", ""]]}, {"id": "1906.01605", "submitter": "Chinnadhurai Sankar", "authors": "Chinnadhurai Sankar, Sujith Ravi, Zornitsa Kozareva", "title": "Transferable Neural Projection Representations", "comments": null, "journal-ref": "Proc. of NAACL 2019", "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural word representations are at the core of many state-of-the-art natural\nlanguage processing models. A widely used approach is to pre-train, store and\nlook up word or character embedding matrices. While useful, such\nrepresentations occupy huge memory making it hard to deploy on-device and often\ndo not generalize to unknown words due to vocabulary pruning.\n  In this paper, we propose a skip-gram based architecture coupled with\nLocality-Sensitive Hashing (LSH) projections to learn efficient dynamically\ncomputable representations. Our model does not need to store lookup tables as\nrepresentations are computed on-the-fly and require low memory footprint. The\nrepresentations can be trained in an unsupervised fashion and can be easily\ntransferred to other NLP tasks. For qualitative evaluation, we analyze the\nnearest neighbors of the word representations and discover semantically similar\nwords even with misspellings. For quantitative evaluation, we plug our\ntransferable projections into a simple LSTM and run it on multiple NLP tasks\nand show how our transferable projections achieve better performance compared\nto prior work.\n", "versions": [{"version": "v1", "created": "Tue, 4 Jun 2019 17:39:52 GMT"}], "update_date": "2019-06-05", "authors_parsed": [["Sankar", "Chinnadhurai", ""], ["Ravi", "Sujith", ""], ["Kozareva", "Zornitsa", ""]]}, {"id": "1906.01618", "submitter": "Vincent Sitzmann", "authors": "Vincent Sitzmann, Michael Zollh\\\"ofer, Gordon Wetzstein", "title": "Scene Representation Networks: Continuous 3D-Structure-Aware Neural\n  Scene Representations", "comments": "Video: https://youtu.be/6vMEBWD8O20 Project page:\n  https://vsitzmann.github.io/srns/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unsupervised learning with generative models has the potential of discovering\nrich representations of 3D scenes. While geometric deep learning has explored\n3D-structure-aware representations of scene geometry, these models typically\nrequire explicit 3D supervision. Emerging neural scene representations can be\ntrained only with posed 2D images, but existing methods ignore the\nthree-dimensional structure of scenes. We propose Scene Representation Networks\n(SRNs), a continuous, 3D-structure-aware scene representation that encodes both\ngeometry and appearance. SRNs represent scenes as continuous functions that map\nworld coordinates to a feature representation of local scene properties. By\nformulating the image formation as a differentiable ray-marching algorithm,\nSRNs can be trained end-to-end from only 2D images and their camera poses,\nwithout access to depth or shape. This formulation naturally generalizes across\nscenes, learning powerful geometry and appearance priors in the process. We\ndemonstrate the potential of SRNs by evaluating them for novel view synthesis,\nfew-shot reconstruction, joint shape and appearance interpolation, and\nunsupervised discovery of a non-rigid face model.\n", "versions": [{"version": "v1", "created": "Tue, 4 Jun 2019 17:53:11 GMT"}, {"version": "v2", "created": "Tue, 28 Jan 2020 23:06:36 GMT"}], "update_date": "2020-01-30", "authors_parsed": [["Sitzmann", "Vincent", ""], ["Zollh\u00f6fer", "Michael", ""], ["Wetzstein", "Gordon", ""]]}, {"id": "1906.01622", "submitter": "Mozhi Zhang", "authors": "Mozhi Zhang, Keyulu Xu, Ken-ichi Kawarabayashi, Stefanie Jegelka,\n  Jordan Boyd-Graber", "title": "Are Girls Neko or Sh\\=ojo? Cross-Lingual Alignment of Non-Isomorphic\n  Embeddings with Iterative Normalization", "comments": "ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cross-lingual word embeddings (CLWE) underlie many multilingual natural\nlanguage processing systems, often through orthogonal transformations of\npre-trained monolingual embeddings. However, orthogonal mapping only works on\nlanguage pairs whose embeddings are naturally isomorphic. For non-isomorphic\npairs, our method (Iterative Normalization) transforms monolingual embeddings\nto make orthogonal alignment easier by simultaneously enforcing that (1)\nindividual word vectors are unit length, and (2) each language's average vector\nis zero. Iterative Normalization consistently improves word translation\naccuracy of three CLWE methods, with the largest improvement observed on\nEnglish-Japanese (from 2% to 44% test accuracy).\n", "versions": [{"version": "v1", "created": "Tue, 4 Jun 2019 17:56:22 GMT"}, {"version": "v2", "created": "Wed, 5 Jun 2019 01:34:19 GMT"}, {"version": "v3", "created": "Mon, 11 Nov 2019 07:36:47 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["Zhang", "Mozhi", ""], ["Xu", "Keyulu", ""], ["Kawarabayashi", "Ken-ichi", ""], ["Jegelka", "Stefanie", ""], ["Boyd-Graber", "Jordan", ""]]}, {"id": "1906.01624", "submitter": "Alexander Irpan", "authors": "Alex Irpan, Kanishka Rao, Konstantinos Bousmalis, Chris Harris, Julian\n  Ibarz, Sergey Levine", "title": "Off-Policy Evaluation via Off-Policy Classification", "comments": "Accepted to NeurIPS 2019. Camera ready version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we consider the problem of model selection for deep\nreinforcement learning (RL) in real-world environments. Typically, the\nperformance of deep RL algorithms is evaluated via on-policy interactions with\nthe target environment. However, comparing models in a real-world environment\nfor the purposes of early stopping or hyperparameter tuning is costly and often\npractically infeasible. This leads us to examine off-policy policy evaluation\n(OPE) in such settings. We focus on OPE for value-based methods, which are of\nparticular interest in deep RL, with applications like robotics, where\noff-policy algorithms based on Q-function estimation can often attain better\nsample complexity than direct policy optimization. Existing OPE metrics either\nrely on a model of the environment, or the use of importance sampling (IS) to\ncorrect for the data being off-policy. However, for high-dimensional\nobservations, such as images, models of the environment can be difficult to fit\nand value-based methods can make IS hard to use or even ill-conditioned,\nespecially when dealing with continuous action spaces. In this paper, we focus\non the specific case of MDPs with continuous action spaces and sparse binary\nrewards, which is representative of many important real-world applications. We\npropose an alternative metric that relies on neither models nor IS, by framing\nOPE as a positive-unlabeled (PU) classification problem with the Q-function as\nthe decision function. We experimentally show that this metric outperforms\nbaselines on a number of tasks. Most importantly, it can reliably predict the\nrelative performance of different policies in a number of generalization\nscenarios, including the transfer to the real-world of policies trained in\nsimulation for an image-based robotic manipulation task.\n", "versions": [{"version": "v1", "created": "Tue, 4 Jun 2019 17:57:06 GMT"}, {"version": "v2", "created": "Thu, 20 Jun 2019 19:05:40 GMT"}, {"version": "v3", "created": "Sat, 23 Nov 2019 01:19:09 GMT"}], "update_date": "2019-11-26", "authors_parsed": [["Irpan", "Alex", ""], ["Rao", "Kanishka", ""], ["Bousmalis", "Konstantinos", ""], ["Harris", "Chris", ""], ["Ibarz", "Julian", ""], ["Levine", "Sergey", ""]]}, {"id": "1906.01634", "submitter": "Dieuwke Hupkes", "authors": "Joris Baan, Jana Leible, Mitja Nikolaus, David Rau, Dennis Ulmer, Tim\n  Baumg\\\"artner, Dieuwke Hupkes and Elia Bruni", "title": "On the Realization of Compositionality in Neural Networks", "comments": "To appear at BlackboxNLP 2019, ACL", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a detailed comparison of two types of sequence to sequence models\ntrained to conduct a compositional task. The models are architecturally\nidentical at inference time, but differ in the way that they are trained: our\nbaseline model is trained with a task-success signal only, while the other\nmodel receives additional supervision on its attention mechanism (Attentive\nGuidance), which has shown to be an effective method for encouraging more\ncompositional solutions (Hupkes et al.,2019). We first confirm that the models\nwith attentive guidance indeed infer more compositional solutions than the\nbaseline, by training them on the lookup table task presented by Li\\v{s}ka et\nal. (2019). We then do an in-depth analysis of the structural differences\nbetween the two model types, focusing in particular on the organisation of the\nparameter space and the hidden layer activations and find noticeable\ndifferences in both these aspects. Guided networks focus more on the components\nof the input rather than the sequence as a whole and develop small functional\ngroups of neurons with specific purposes that use their gates more selectively.\nResults from parameter heat maps, component swapping and graph analysis also\nindicate that guided networks exhibit a more modular structure with a small\nnumber of specialized, strongly connected neurons.\n", "versions": [{"version": "v1", "created": "Tue, 4 Jun 2019 07:30:48 GMT"}, {"version": "v2", "created": "Thu, 6 Jun 2019 08:42:25 GMT"}], "update_date": "2019-06-07", "authors_parsed": [["Baan", "Joris", ""], ["Leible", "Jana", ""], ["Nikolaus", "Mitja", ""], ["Rau", "David", ""], ["Ulmer", "Dennis", ""], ["Baumg\u00e4rtner", "Tim", ""], ["Hupkes", "Dieuwke", ""], ["Bruni", "Elia", ""]]}, {"id": "1906.01747", "submitter": "Julia Stoyanovich", "authors": "Ke Yang and Vasilis Gkatzelis and Julia Stoyanovich", "title": "Balanced Ranking with Diversity Constraints", "comments": "to appear in IJCAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many set selection and ranking algorithms have recently been enhanced with\ndiversity constraints that aim to explicitly increase representation of\nhistorically disadvantaged populations, or to improve the overall\nrepresentativeness of the selected set. An unintended consequence of these\nconstraints, however, is reduced in-group fairness: the selected candidates\nfrom a given group may not be the best ones, and this unfairness may not be\nwell-balanced across groups.\n  In this paper we study this phenomenon using datasets that comprise multiple\nsensitive attributes. We then introduce additional constraints, aimed at\nbalancing the \\in-group fairness across groups, and formalize the induced\noptimization problems as integer linear programs. Using these programs, we\nconduct an experimental evaluation with real datasets, and quantify the\nfeasible trade-offs between balance and overall performance in the presence of\ndiversity constraints.\n", "versions": [{"version": "v1", "created": "Tue, 4 Jun 2019 22:53:11 GMT"}], "update_date": "2019-06-06", "authors_parsed": [["Yang", "Ke", ""], ["Gkatzelis", "Vasilis", ""], ["Stoyanovich", "Julia", ""]]}, {"id": "1906.01764", "submitter": "Ting-Yao Hsu", "authors": "Ting-Yao Hsu, Chieh-Yang Huang, Yen-Chia Hsu, Ting-Hao 'Kenneth' Huang", "title": "Visual Story Post-Editing", "comments": "Accepted by ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce the first dataset for human edits of machine-generated visual\nstories and explore how these collected edits may be used for the visual story\npost-editing task. The dataset, VIST-Edit, includes 14,905 human edited\nversions of 2,981 machine-generated visual stories. The stories were generated\nby two state-of-the-art visual storytelling models, each aligned to 5\nhuman-edited versions. We establish baselines for the task, showing how a\nrelatively small set of human edits can be leveraged to boost the performance\nof large visual storytelling models. We also discuss the weak correlation\nbetween automatic evaluation scores and human ratings, motivating the need for\nnew automatic metrics.\n", "versions": [{"version": "v1", "created": "Wed, 5 Jun 2019 00:33:47 GMT"}], "update_date": "2019-06-06", "authors_parsed": [["Hsu", "Ting-Yao", ""], ["Huang", "Chieh-Yang", ""], ["Hsu", "Yen-Chia", ""], ["Huang", "Ting-Hao 'Kenneth'", ""]]}, {"id": "1906.01796", "submitter": "Changxing Ding", "authors": "Chenhong Zhou, Changxing Ding, Xinchao Wang, Zhentai Lu, Dacheng Tao", "title": "One-pass Multi-task Networks with Cross-task Guided Attention for Brain\n  Tumor Segmentation", "comments": "14 pages, 7 figures, To appear in IEEE Transactions on Image\n  Processing", "journal-ref": null, "doi": "10.1109/TIP.2020.2973510", "report-no": null, "categories": "cs.CV cs.AI cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Class imbalance has emerged as one of the major challenges for medical image\nsegmentation. The model cascade (MC) strategy significantly alleviates the\nclass imbalance issue via running a set of individual deep models for\ncoarse-to-fine segmentation. Despite its outstanding performance, however, this\nmethod leads to undesired system complexity and also ignores the correlation\namong the models. To handle these flaws, we propose a light-weight deep model,\ni.e., the One-pass Multi-task Network (OM-Net) to solve class imbalance better\nthan MC does, while requiring only one-pass computation. First, OM-Net\nintegrates the separate segmentation tasks into one deep model, which consists\nof shared parameters to learn joint features, as well as task-specific\nparameters to learn discriminative features. Second, to more effectively\noptimize OM-Net, we take advantage of the correlation among tasks to design\nboth an online training data transfer strategy and a curriculum learning-based\ntraining strategy. Third, we further propose sharing prediction results between\ntasks and design a cross-task guided attention (CGA) module which can\nadaptively recalibrate channel-wise feature responses based on the\ncategory-specific statistics. Finally, a simple yet effective post-processing\nmethod is introduced to refine the segmentation results. Extensive experiments\nare conducted to demonstrate the effectiveness of the proposed techniques. Most\nimpressively, we achieve state-of-the-art performance on the BraTS 2015 testing\nset and BraTS 2017 online validation set. Using these proposed approaches, we\nalso won joint third place in the BraTS 2018 challenge among 64 participating\nteams. The code is publicly available at\nhttps://github.com/chenhong-zhou/OM-Net.\n", "versions": [{"version": "v1", "created": "Wed, 5 Jun 2019 02:50:08 GMT"}, {"version": "v2", "created": "Sat, 8 Feb 2020 03:34:20 GMT"}], "update_date": "2020-04-22", "authors_parsed": [["Zhou", "Chenhong", ""], ["Ding", "Changxing", ""], ["Wang", "Xinchao", ""], ["Lu", "Zhentai", ""], ["Tao", "Dacheng", ""]]}, {"id": "1906.01811", "submitter": "Ali Malik", "authors": "Chris Piech, Ali Malik, Laura M Scott, Robert T Chang, Charles Lin", "title": "The Stanford Acuity Test: A Precise Vision Test Using Bayesian\n  Techniques and a Discovery in Human Visual Response", "comments": "Proceedings of the 34th AAAI Conference on Artificial Intelligence,\n  New York, USA. 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Chart-based visual acuity measurements are used by billions of people to\ndiagnose and guide treatment of vision impairment. However, the ubiquitous eye\nexam has no mechanism for reasoning about uncertainty and as such, suffers from\na well-documented reproducibility problem. In this paper we make two core\ncontributions. First, we uncover a new parametric probabilistic model of visual\nacuity response based on detailed measurements of patients with eye disease.\nThen, we present an adaptive, digital eye exam using modern artificial\nintelligence techniques which substantially reduces acuity exam error over\nexisting approaches, while also introducing the novel ability to model its own\nuncertainty and incorporate prior beliefs. Using standard evaluation metrics,\nwe estimate a 74% reduction in prediction error compared to the ubiquitous\nchart-based eye exam and up to 67% reduction compared to the previous best\ndigital exam. For patients with eye disease, the novel ability to finely\nmeasure acuity from home could be a crucial part in early diagnosis. We provide\na web implementation of our algorithm for anyone in the world to use. The\ninsights in this paper also provide interesting implications for the field of\npsychometric Item Response Theory.\n", "versions": [{"version": "v1", "created": "Wed, 5 Jun 2019 03:37:32 GMT"}, {"version": "v2", "created": "Fri, 22 Nov 2019 01:02:03 GMT"}], "update_date": "2019-11-25", "authors_parsed": [["Piech", "Chris", ""], ["Malik", "Ali", ""], ["Scott", "Laura M", ""], ["Chang", "Robert T", ""], ["Lin", "Charles", ""]]}, {"id": "1906.01820", "submitter": "Evan Hubinger", "authors": "Evan Hubinger, Chris van Merwijk, Vladimir Mikulik, Joar Skalse, Scott\n  Garrabrant", "title": "Risks from Learned Optimization in Advanced Machine Learning Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We analyze the type of learned optimization that occurs when a learned model\n(such as a neural network) is itself an optimizer - a situation we refer to as\nmesa-optimization, a neologism we introduce in this paper. We believe that the\npossibility of mesa-optimization raises two important questions for the safety\nand transparency of advanced machine learning systems. First, under what\ncircumstances will learned models be optimizers, including when they should not\nbe? Second, when a learned model is an optimizer, what will its objective be -\nhow will it differ from the loss function it was trained under - and how can it\nbe aligned? In this paper, we provide an in-depth analysis of these two primary\nquestions and provide an overview of topics for future research.\n", "versions": [{"version": "v1", "created": "Wed, 5 Jun 2019 04:43:25 GMT"}, {"version": "v2", "created": "Tue, 11 Jun 2019 21:44:27 GMT"}], "update_date": "2019-06-13", "authors_parsed": [["Hubinger", "Evan", ""], ["van Merwijk", "Chris", ""], ["Mikulik", "Vladimir", ""], ["Skalse", "Joar", ""], ["Garrabrant", "Scott", ""]]}, {"id": "1906.01827", "submitter": "Baharan Mirzasoleiman", "authors": "Baharan Mirzasoleiman, Jeff Bilmes, Jure Leskovec", "title": "Coresets for Data-efficient Training of Machine Learning Models", "comments": null, "journal-ref": "International Conference on Machine Learning 2020", "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Incremental gradient (IG) methods, such as stochastic gradient descent and\nits variants are commonly used for large scale optimization in machine\nlearning. Despite the sustained effort to make IG methods more data-efficient,\nit remains an open question how to select a training data subset that can\ntheoretically and practically perform on par with the full dataset. Here we\ndevelop CRAIG, a method to select a weighted subset (or coreset) of training\ndata that closely estimates the full gradient by maximizing a submodular\nfunction. We prove that applying IG to this subset is guaranteed to converge to\nthe (near)optimal solution with the same convergence rate as that of IG for\nconvex optimization. As a result, CRAIG achieves a speedup that is inversely\nproportional to the size of the subset. To our knowledge, this is the first\nrigorous method for data-efficient training of general machine learning models.\nOur extensive set of experiments show that CRAIG, while achieving practically\nthe same solution, speeds up various IG methods by up to 6x for logistic\nregression and 3x for training deep neural networks.\n", "versions": [{"version": "v1", "created": "Wed, 5 Jun 2019 05:10:37 GMT"}, {"version": "v2", "created": "Mon, 24 Feb 2020 17:04:20 GMT"}, {"version": "v3", "created": "Mon, 16 Nov 2020 20:58:39 GMT"}], "update_date": "2020-11-18", "authors_parsed": [["Mirzasoleiman", "Baharan", ""], ["Bilmes", "Jeff", ""], ["Leskovec", "Jure", ""]]}, {"id": "1906.01833", "submitter": "Chen Wu", "authors": "Chen Wu, Xuancheng Ren, Fuli Luo, Xu Sun", "title": "A Hierarchical Reinforced Sequence Operation Method for Unsupervised\n  Text Style Transfer", "comments": "Accepted to ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unsupervised text style transfer aims to alter text styles while preserving\nthe content, without aligned data for supervision. Existing seq2seq methods\nface three challenges: 1) the transfer is weakly interpretable, 2) generated\noutputs struggle in content preservation, and 3) the trade-off between content\nand style is intractable. To address these challenges, we propose a\nhierarchical reinforced sequence operation method, named Point-Then-Operate\n(PTO), which consists of a high-level agent that proposes operation positions\nand a low-level agent that alters the sentence. We provide comprehensive\ntraining objectives to control the fluency, style, and content of the outputs\nand a mask-based inference algorithm that allows for multi-step revision based\non the single-step trained agents. Experimental results on two text style\ntransfer datasets show that our method significantly outperforms recent methods\nand effectively addresses the aforementioned challenges.\n", "versions": [{"version": "v1", "created": "Wed, 5 Jun 2019 05:27:31 GMT"}], "update_date": "2019-06-06", "authors_parsed": [["Wu", "Chen", ""], ["Ren", "Xuancheng", ""], ["Luo", "Fuli", ""], ["Sun", "Xu", ""]]}, {"id": "1906.01843", "submitter": "Amir Ziai", "authors": "Amir Ziai", "title": "Detecting Kissing Scenes in a Database of Hollywood Films", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Detecting scene types in a movie can be very useful for application such as\nvideo editing, ratings assignment, and personalization. We propose a system for\ndetecting kissing scenes in a movie. This system consists of two components.\nThe first component is a binary classifier that predicts a binary label (i.e.\nkissing or not) given a features exctracted from both the still frames and\naudio waves of a one-second segment. The second component aggregates the binary\nlabels for contiguous non-overlapping segments into a set of kissing scenes. We\nexperimented with a variety of 2D and 3D convolutional architectures such as\nResNet, DesnseNet, and VGGish and developed a highly accurate kissing detector\nthat achieves a validation F1 score of 0.95 on a diverse database of Hollywood\nfilms ranging many genres and spanning multiple decades. The code for this\nproject is available at http://github.com/amirziai/kissing-detector.\n", "versions": [{"version": "v1", "created": "Wed, 5 Jun 2019 06:31:26 GMT"}], "update_date": "2019-06-06", "authors_parsed": [["Ziai", "Amir", ""]]}, {"id": "1906.01864", "submitter": "Xingzhou Zhang", "authors": "Xingzhou Zhang, Yifan Wang, Sidi Lu, Liangkai Liu, Lanyu Xu, Weisong\n  Shi", "title": "OpenEI: An Open Framework for Edge Intelligence", "comments": "12 pages, 6 figures, ICDCS 2019 conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.DC eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the last five years, edge computing has attracted tremendous attention\nfrom industry and academia due to its promise to reduce latency, save\nbandwidth, improve availability, and protect data privacy to keep data secure.\nAt the same time, we have witnessed the proliferation of AI algorithms and\nmodels which accelerate the successful deployment of intelligence mainly in\ncloud services. These two trends, combined together, have created a new\nhorizon: Edge Intelligence (EI). The development of EI requires much attention\nfrom both the computer systems research community and the AI community to meet\nthese demands. However, existing computing techniques used in the cloud are not\napplicable to edge computing directly due to the diversity of computing sources\nand the distribution of data sources. We envision that there missing a\nframework that can be rapidly deployed on edge and enable edge AI capabilities.\nTo address this challenge, in this paper we first present the definition and a\nsystematic review of EI. Then, we introduce an Open Framework for Edge\nIntelligence (OpenEI), which is a lightweight software platform to equip edges\nwith intelligent processing and data sharing capability. We analyze four\nfundamental EI techniques which are used to build OpenEI and identify several\nopen problems based on potential research directions. Finally, four typical\napplication scenarios enabled by OpenEI are presented.\n", "versions": [{"version": "v1", "created": "Wed, 5 Jun 2019 07:41:39 GMT"}], "update_date": "2019-06-06", "authors_parsed": [["Zhang", "Xingzhou", ""], ["Wang", "Yifan", ""], ["Lu", "Sidi", ""], ["Liu", "Liangkai", ""], ["Xu", "Lanyu", ""], ["Shi", "Weisong", ""]]}, {"id": "1906.01873", "submitter": "Luka Nenadovic", "authors": "Luka Nenadovi\\'c, Vladimir Prelovac", "title": "Towards conceptual generalization in the embedding space", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Humans are able to conceive physical reality by jointly learning different\nfacets thereof. To every pair of notions related to a perceived reality may\ncorrespond a mutual relation, which is a notion on its own, but one-level\nhigher. Thus, we may have a description of perceived reality on at least two\nlevels and the translation map between them is in general, due to their\ndifferent content corpus, one-to-many. Following success of the unsupervised\nneural machine translation models, which are essentially one-to-one mappings\ntrained separately on monolingual corpora, we examine further capabilities of\nthe unsupervised deep learning methods used there and apply some of these\nmethods to sets of notions of different level and measure. Using the graph and\nword embedding-like techniques, we build one-to-many map without parallel data\nin order to establish a unified vector representation of the outer world by\ncombining notions of different kind into a unique conceptual framework. Due to\ntheir latent similarity, by aligning the two embedding spaces in purely\nunsupervised way, one obtains a geometric relation between objects of cognition\non the two levels, making it possible to express a natural knowledge using one\ndescription in the context of the other.\n", "versions": [{"version": "v1", "created": "Wed, 5 Jun 2019 08:11:12 GMT"}, {"version": "v2", "created": "Thu, 15 Aug 2019 12:58:36 GMT"}, {"version": "v3", "created": "Fri, 16 Aug 2019 14:24:58 GMT"}], "update_date": "2019-08-19", "authors_parsed": [["Nenadovi\u0107", "Luka", ""], ["Prelovac", "Vladimir", ""]]}, {"id": "1906.01930", "submitter": "Alexander Immer", "authors": "Mohammad Emtiyaz Khan, Alexander Immer, Ehsan Abedi, Maciej Korzepa", "title": "Approximate Inference Turns Deep Networks into Gaussian Processes", "comments": "published at NeurIPS 2019:\n  https://papers.nips.cc/paper/8573-approximate-inference-turns-deep-networks-into-gaussian-processes.pdf", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (DNN) and Gaussian processes (GP) are two powerful\nmodels with several theoretical connections relating them, but the relationship\nbetween their training methods is not well understood. In this paper, we show\nthat certain Gaussian posterior approximations for Bayesian DNNs are equivalent\nto GP posteriors. This enables us to relate solutions and iterations of a\ndeep-learning algorithm to GP inference. As a result, we can obtain a GP kernel\nand a nonlinear feature map while training a DNN. Surprisingly, the resulting\nkernel is the neural tangent kernel. We show kernels obtained on real datasets\nand demonstrate the use of the GP marginal likelihood to tune hyperparameters\nof DNNs. Our work aims to facilitate further research on combining DNNs and GPs\nin practical settings.\n", "versions": [{"version": "v1", "created": "Wed, 5 Jun 2019 10:43:20 GMT"}, {"version": "v2", "created": "Wed, 4 Dec 2019 03:21:09 GMT"}, {"version": "v3", "created": "Sun, 19 Jul 2020 21:28:11 GMT"}], "update_date": "2020-07-21", "authors_parsed": [["Khan", "Mohammad Emtiyaz", ""], ["Immer", "Alexander", ""], ["Abedi", "Ehsan", ""], ["Korzepa", "Maciej", ""]]}, {"id": "1906.01946", "submitter": "Joseph Bullock", "authors": "Joseph Bullock, Miguel Luengo-Oroz", "title": "Automated Speech Generation from UN General Assembly Statements: Mapping\n  Risks in AI Generated Texts", "comments": "5 pages", "journal-ref": "International Conference on Machine Learning AI for Social Good\n  Workshop, Long Beach, United States, 2019", "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automated text generation has been applied broadly in many domains such as\nmarketing and robotics, and used to create chatbots, product reviews and write\npoetry. The ability to synthesize text, however, presents many potential risks,\nwhile access to the technology required to build generative models is becoming\nincreasingly easy. This work is aligned with the efforts of the United Nations\nand other civil society organisations to highlight potential political and\nsocietal risks arising through the malicious use of text generation software,\nand their potential impact on human rights. As a case study, we present the\nfindings of an experiment to generate remarks in the style of political leaders\nby fine-tuning a pretrained AWD- LSTM model on a dataset of speeches made at\nthe UN General Assembly. This work highlights the ease with which this can be\naccomplished, as well as the threats of combining these techniques with other\ntechnologies.\n", "versions": [{"version": "v1", "created": "Wed, 5 Jun 2019 11:23:14 GMT"}], "update_date": "2019-06-06", "authors_parsed": [["Bullock", "Joseph", ""], ["Luengo-Oroz", "Miguel", ""]]}, {"id": "1906.01965", "submitter": "Yaoming Zhu", "authors": "Yaoming Zhu, Juncheng Wan, Zhiming Zhou, Liheng Chen, Lin Qiu, Weinan\n  Zhang, Xin Jiang, Yong Yu", "title": "Triple-to-Text: Converting RDF Triples into High-Quality Natural\n  Languages via Optimizing an Inverse KL Divergence", "comments": null, "journal-ref": null, "doi": "10.1145/3331184.3331232", "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge base is one of the main forms to represent information in a\nstructured way. A knowledge base typically consists of Resource Description\nFrameworks (RDF) triples which describe the entities and their relations.\nGenerating natural language description of the knowledge base is an important\ntask in NLP, which has been formulated as a conditional language generation\ntask and tackled using the sequence-to-sequence framework. Current works mostly\ntrain the language models by maximum likelihood estimation, which tends to\ngenerate lousy sentences. In this paper, we argue that such a problem of\nmaximum likelihood estimation is intrinsic, which is generally irrevocable via\nchanging network structures. Accordingly, we propose a novel Triple-to-Text\n(T2T) framework, which approximately optimizes the inverse Kullback-Leibler\n(KL) divergence between the distributions of the real and generated sentences.\nDue to the nature that inverse KL imposes large penalty on fake-looking\nsamples, the proposed method can significantly reduce the probability of\ngenerating low-quality sentences. Our experiments on three real-world datasets\ndemonstrate that T2T can generate higher-quality sentences and outperform\nbaseline models in several evaluation metrics.\n", "versions": [{"version": "v1", "created": "Sat, 25 May 2019 03:05:15 GMT"}], "update_date": "2019-06-06", "authors_parsed": [["Zhu", "Yaoming", ""], ["Wan", "Juncheng", ""], ["Zhou", "Zhiming", ""], ["Chen", "Liheng", ""], ["Qiu", "Lin", ""], ["Zhang", "Weinan", ""], ["Jiang", "Xin", ""], ["Yu", "Yong", ""]]}, {"id": "1906.01983", "submitter": "Mark Ho", "authors": "Mark K. Ho and Joanna Korman and Thomas L. Griffiths", "title": "The Computational Structure of Unintentional Meaning", "comments": "7 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG cs.MA stat.AP", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Speech-acts can have literal meaning as well as pragmatic meaning, but these\nboth involve consequences typically intended by a speaker. Speech-acts can also\nhave unintentional meaning, in which what is conveyed goes above and beyond\nwhat was intended. Here, we present a Bayesian analysis of how, to a listener,\nthe meaning of an utterance can significantly differ from a speaker's intended\nmeaning. Our model emphasizes how comprehending the intentional and\nunintentional meaning of speech-acts requires listeners to engage in\nsophisticated model-based perspective-taking and reasoning about the history of\nthe state of the world, each other's actions, and each other's observations. To\ntest our model, we have human participants make judgments about vignettes where\nspeakers make utterances that could be interpreted as intentional insults or\nunintentional faux pas. In elucidating the mechanics of speech-acts with\nunintentional meanings, our account provides insight into how communication\nboth functions and malfunctions.\n", "versions": [{"version": "v1", "created": "Mon, 3 Jun 2019 17:26:36 GMT"}], "update_date": "2019-06-06", "authors_parsed": [["Ho", "Mark K.", ""], ["Korman", "Joanna", ""], ["Griffiths", "Thomas L.", ""]]}, {"id": "1906.02010", "submitter": "Sujit Khanna", "authors": "Sujit Pramod Khanna and Alexander Ororbia II", "title": "A Hybrid Algorithm for Metaheuristic Optimization", "comments": "10 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.LG cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel, flexible algorithm for combining together\nmetaheuristicoptimizers for non-convex optimization problems. Our approach\ntreatsthe constituent optimizers as a team of complex agents that\ncommunicateinformation amongst each other at various intervals during the\nsimulationprocess. The information produced by each individual agent can be\ncombinedin various ways via higher-level operators. In our experiments on\nkeybenchmark functions, we investigate how the performance of our\nalgorithmvaries with respect to several of its key modifiable properties.\nFinally,we apply our proposed algorithm to classification problems involving\ntheoptimization of support-vector machine classifiers.\n", "versions": [{"version": "v1", "created": "Sun, 26 May 2019 10:45:58 GMT"}], "update_date": "2019-06-06", "authors_parsed": [["Khanna", "Sujit Pramod", ""], ["Ororbia", "Alexander", "II"]]}, {"id": "1906.02068", "submitter": "Oscar J. Romero", "authors": "Oscar J. Romero", "title": "Architectural Middleware that Supports Building High-performance,\n  Scalable, Ubiquitous, Intelligent Personal Assistants", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.AI cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Intelligent Personal Assistants (IPAs) are software agents that can perform\ntasks on behalf of individuals and assist them on many of their daily\nactivities. IPAs capabilities are expanding rapidly due to the recent advances\non areas such as natural language processing, machine learning, artificial\ncognition, and ubiquitous computing, which equip the agents with competences to\nunderstand what users say, collect information from everyday ubiquitous devices\n(e.g., smartphones, wearables, tablets, laptops, cars, household appliances,\netc.), learn user preferences, deliver data-driven search results, and make\ndecisions based on user's context. Apart from the inherent complexity of\nbuilding such IPAs, developers and researchers have to address many critical\narchitectural challenges (e.g., low-latency, scalability, concurrency,\nubiquity, code mobility, interoperability, support to cognitive services and\nreasoning, to name a few.), thereby diverting them from their main goal:\nbuilding IPAs. Thus, our contribution in this paper is twofold: 1) we propose\nan architecture for a platform-agnostic, high-performance, ubiquitous, and\ndistributed middleware that alleviates the burdensome task of dealing with\nlow-level implementation details when building IPAs by adding multiple\nabstraction layers that hide the underlying complexity; and 2) we present an\nimplementation of the middleware that concretizes the aforementioned\narchitecture and allows the development of high-level capabilities while\nscaling the system up to hundreds of thousands of IPAs with no extra effort. We\ndemonstrate the powerfulness of our middleware by analyzing software metrics\nfor complexity, effort, performance, cohesion and coupling when developing a\nconversational IPA.\n", "versions": [{"version": "v1", "created": "Wed, 5 Jun 2019 15:15:36 GMT"}], "update_date": "2019-06-06", "authors_parsed": [["Romero", "Oscar J.", ""]]}, {"id": "1906.02074", "submitter": "Yeting Li", "authors": "Yeting Li, Haiming Chen, Xiaolan Zhang, Lingqi Zhang", "title": "An Effective Algorithm for Learning Single Occurrence Regular\n  Expressions with Interleaving", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The advantages offered by the presence of a schema are numerous. However,\nmany XML documents in practice are not accompanied by a (valid) schema, making\nschema inference an attractive research problem. The fundamental task in XML\nschema learning is inferring restricted subclasses of regular expressions. Most\nprevious work either lacks support for interleaving or only has limited support\nfor interleaving. In this paper, we first propose a new subclass Single\nOccurrence Regular Expressions with Interleaving (SOIRE), which has\nunrestricted support for interleaving. Then, based on single occurrence\nautomaton and maximum independent set, we propose an algorithm iSOIRE to infer\nSOIREs. Finally, we further conduct a series of experiments on real datasets to\nevaluate the effectiveness of our work, comparing with both ongoing learning\nalgorithms in academia and industrial tools in real-world. The results reveal\nthe practicability of SOIRE and the effectiveness of iSOIRE, showing the high\npreciseness and conciseness of our work.\n", "versions": [{"version": "v1", "created": "Wed, 5 Jun 2019 15:32:22 GMT"}], "update_date": "2019-06-06", "authors_parsed": [["Li", "Yeting", ""], ["Chen", "Haiming", ""], ["Zhang", "Xiaolan", ""], ["Zhang", "Lingqi", ""]]}, {"id": "1906.02090", "submitter": "Sergio Consoli", "authors": "Michael van Hartskamp, Sergio Consoli, Wim Verhaegh, Milan Petkovi\\'c,\n  Anja van de Stolpe", "title": "Artificial Intelligence in Clinical Health Care Applications: Viewpoint", "comments": null, "journal-ref": "Journal of Medical Internet Research (2019), 21(4):e12100", "doi": "10.2196/12100", "report-no": null, "categories": "cs.CY cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The idea of Artificial Intelligence (AI) has a long history. It turned out,\nhowever, that reaching intelligence at human levels is more complicated than\noriginally anticipated. Currently we are experiencing a renewed interest in AI,\nfueled by an enormous increase in computing power and an even larger increase\nin data, in combination with improved AI technologies like deep learning.\nHealthcare is considered the next domain to be revolutionized by Artificial\nIntelligence. While AI approaches are excellently suited to develop certain\nalgorithms, for biomedical applications there are specific challenges. We\npropose recommendations to improve AI projects in the biomedical space and\nespecially clinical healthcare.\n", "versions": [{"version": "v1", "created": "Wed, 5 Jun 2019 15:57:20 GMT"}, {"version": "v2", "created": "Wed, 26 Jun 2019 08:37:53 GMT"}], "update_date": "2019-06-27", "authors_parsed": [["van Hartskamp", "Michael", ""], ["Consoli", "Sergio", ""], ["Verhaegh", "Wim", ""], ["Petkovi\u0107", "Milan", ""], ["van de Stolpe", "Anja", ""]]}, {"id": "1906.02121", "submitter": "Jo\\~ao Paulo Aires", "authors": "Jo\\~ao Paulo Aires, Roger Granada, Juarez Monteiro, Rodrigo C. Barros,\n  Felipe Meneguzzi", "title": "Classifying Norm Conflicts using Learned Semantic Representations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While most social norms are informal, they are often formalized by companies\nin contracts to regulate trades of goods and services. When poorly written,\ncontracts may contain normative conflicts resulting from opposing deontic\nmeanings or contradict specifications. As contracts tend to be long and contain\nmany norms, manually identifying such conflicts requires human-effort, which is\ntime-consuming and error-prone. Automating such task benefits contract makers\nincreasing productivity and making conflict identification more reliable. To\naddress this problem, we introduce an approach to detect and classify norm\nconflicts in contracts by converting them into latent representations that\npreserve both syntactic and semantic information and training a model to\nclassify norm conflicts in four conflict types. Our results reach the new state\nof the art when compared to a previous approach.\n", "versions": [{"version": "v1", "created": "Mon, 13 May 2019 19:43:54 GMT"}], "update_date": "2019-06-06", "authors_parsed": [["Aires", "Jo\u00e3o Paulo", ""], ["Granada", "Roger", ""], ["Monteiro", "Juarez", ""], ["Barros", "Rodrigo C.", ""], ["Meneguzzi", "Felipe", ""]]}, {"id": "1906.02123", "submitter": "Hongming Zhang", "authors": "Hongming Zhang, Hantian Ding, Yangqiu Song", "title": "SP-10K: A Large-scale Evaluation Set for Selectional Preference\n  Acquisition", "comments": "Accepted by ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Selectional Preference (SP) is a commonly observed language phenomenon and\nproved to be useful in many natural language processing tasks. To provide a\nbetter evaluation method for SP models, we introduce SP-10K, a large-scale\nevaluation set that provides human ratings for the plausibility of 10,000 SP\npairs over five SP relations, covering 2,500 most frequent verbs, nouns, and\nadjectives in American English. Three representative SP acquisition methods\nbased on pseudo-disambiguation are evaluated with SP-10K. To demonstrate the\nimportance of our dataset, we investigate the relationship between SP-10K and\nthe commonsense knowledge in ConceptNet5 and show the potential of using SP to\nrepresent the commonsense knowledge. We also use the Winograd Schema Challenge\nto prove that the proposed new SP relations are essential for the hard pronoun\ncoreference resolution problem.\n", "versions": [{"version": "v1", "created": "Tue, 14 May 2019 08:32:39 GMT"}], "update_date": "2019-06-06", "authors_parsed": [["Zhang", "Hongming", ""], ["Ding", "Hantian", ""], ["Song", "Yangqiu", ""]]}, {"id": "1906.02125", "submitter": "Paul Pu Liang", "authors": "Paul Pu Liang, Yao Chong Lim, Yao-Hung Hubert Tsai, Ruslan\n  Salakhutdinov, Louis-Philippe Morency", "title": "Strong and Simple Baselines for Multimodal Utterance Embeddings", "comments": "NAACL 2019 oral presentation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG cs.SD eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Human language is a rich multimodal signal consisting of spoken words, facial\nexpressions, body gestures, and vocal intonations. Learning representations for\nthese spoken utterances is a complex research problem due to the presence of\nmultiple heterogeneous sources of information. Recent advances in multimodal\nlearning have followed the general trend of building more complex models that\nutilize various attention, memory and recurrent components. In this paper, we\npropose two simple but strong baselines to learn embeddings of multimodal\nutterances. The first baseline assumes a conditional factorization of the\nutterance into unimodal factors. Each unimodal factor is modeled using the\nsimple form of a likelihood function obtained via a linear transformation of\nthe embedding. We show that the optimal embedding can be derived in closed form\nby taking a weighted average of the unimodal features. In order to capture\nricher representations, our second baseline extends the first by factorizing\ninto unimodal, bimodal, and trimodal factors, while retaining simplicity and\nefficiency during learning and inference. From a set of experiments across two\ntasks, we show strong performance on both supervised and semi-supervised\nmultimodal prediction, as well as significant (10 times) speedups over neural\nmodels during inference. Overall, we believe that our strong baseline models\noffer new benchmarking options for future research in multimodal learning.\n", "versions": [{"version": "v1", "created": "Tue, 14 May 2019 13:44:37 GMT"}, {"version": "v2", "created": "Fri, 28 Feb 2020 07:01:32 GMT"}], "update_date": "2020-03-02", "authors_parsed": [["Liang", "Paul Pu", ""], ["Lim", "Yao Chong", ""], ["Tsai", "Yao-Hung Hubert", ""], ["Salakhutdinov", "Ruslan", ""], ["Morency", "Louis-Philippe", ""]]}, {"id": "1906.02126", "submitter": "Ryohto Sawada", "authors": "Ryohto Sawada", "title": "Extractive Summarization via Weighted Dissimilarity and Importance\n  Aligned Key Iterative Algorithm", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present importance aligned key iterative algorithm for extractive\nsummarization that is faster than conventional algorithms keeping its accuracy.\nThe computational complexity of our algorithm is O($SNlogN$) to summarize\noriginal $N$ sentences into final $S$ sentences. Our algorithm maximizes the\nweighted dissimilarity defined by the product of importance and cosine\ndissimilarity so that the summary represents the document and at the same time\nthe sentences of the summary are not similar to each other. The weighted\ndissimilarity is heuristically maximized by iterative greedy search and binary\nsearch to the sentences ordered by importance. We finally show a benchmark\nscore based on summarization of customer reviews of products, which highlights\nthe quality of our algorithm comparable to human and existing algorithms. We\nprovide the source code of our algorithm on github\nhttps://github.com/qhapaq-49/imakita .\n", "versions": [{"version": "v1", "created": "Wed, 15 May 2019 12:42:42 GMT"}], "update_date": "2019-06-06", "authors_parsed": [["Sawada", "Ryohto", ""]]}, {"id": "1906.02127", "submitter": "Chen Qian", "authors": "Chen Qian, Lijie Wen, Akhil Kumar, Leilei Lin, Li Lin, Zan Zong,\n  Shuang Li, Jianmin Wang", "title": "An Approach for Process Model Extraction By Multi-Grained Text\n  Classification", "comments": "Accepted to CAiSE-2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Process model extraction (PME) is a recently emerged interdiscipline between\nnatural language processing (NLP) and business process management (BPM), which\naims to extract process models from textual descriptions. Previous process\nextractors heavily depend on manual features and ignore the potential relations\nbetween clues of different text granularities. In this paper, we formalize the\nPME task into the multi-grained text classification problem, and propose a\nhierarchical neural network to effectively model and extract multi-grained\ninformation without manually-defined procedural features. Under this structure,\nwe accordingly propose the coarse-to-fine (grained) learning mechanism,\ntraining multi-grained tasks in coarse-to-fine grained order to share the\nhigh-level knowledge for the low-level tasks. To evaluate our approach, we\nconstruct two multi-grained datasets from two different domains and conduct\nextensive experiments from different dimensions. The experimental results\ndemonstrate that our approach outperforms the state-of-the-art methods with\nstatistical significance and further investigations demonstrate its\neffectiveness.\n", "versions": [{"version": "v1", "created": "Thu, 16 May 2019 16:04:49 GMT"}, {"version": "v2", "created": "Tue, 20 Aug 2019 13:06:30 GMT"}, {"version": "v3", "created": "Fri, 20 Mar 2020 00:39:22 GMT"}], "update_date": "2020-03-23", "authors_parsed": [["Qian", "Chen", ""], ["Wen", "Lijie", ""], ["Kumar", "Akhil", ""], ["Lin", "Leilei", ""], ["Lin", "Li", ""], ["Zong", "Zan", ""], ["Li", "Shuang", ""], ["Wang", "Jianmin", ""]]}, {"id": "1906.02132", "submitter": "Tunazzina Islam", "authors": "Tunazzina Islam", "title": "Ex-Twit: Explainable Twitter Mining on Health Data", "comments": "In SocialNLP 2019 @ IJCAI-2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Since most machine learning models provide no explanations for the\npredictions, their predictions are obscure for the human. The ability to\nexplain a model's prediction has become a necessity in many applications\nincluding Twitter mining. In this work, we propose a method called Explainable\nTwitter Mining (Ex-Twit) combining Topic Modeling and Local Interpretable\nModel-agnostic Explanation (LIME) to predict the topic and explain the model\npredictions. We demonstrate the effectiveness of Ex-Twit on Twitter\nhealth-related data.\n", "versions": [{"version": "v1", "created": "Fri, 24 May 2019 15:26:18 GMT"}, {"version": "v2", "created": "Sat, 22 Jun 2019 21:42:59 GMT"}], "update_date": "2020-12-21", "authors_parsed": [["Islam", "Tunazzina", ""]]}, {"id": "1906.02138", "submitter": "Wendelin B\\\"ohmer", "authors": "Wendelin B\\\"ohmer, Tabish Rashid, Shimon Whiteson", "title": "Exploration with Unreliable Intrinsic Reward in Multi-Agent\n  Reinforcement Learning", "comments": "Accepted to the 2nd Exploration in Reinforcement Learning Workshop at\n  the International Conference on Machine Learning 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper investigates the use of intrinsic reward to guide exploration in\nmulti-agent reinforcement learning. We discuss the challenges in applying\nintrinsic reward to multiple collaborative agents and demonstrate how\nunreliable reward can prevent decentralized agents from learning the optimal\npolicy. We address this problem with a novel framework, Independent\nCentrally-assisted Q-learning (ICQL), in which decentralized agents share\ncontrol and an experience replay buffer with a centralized agent. Only the\ncentralized agent is intrinsically rewarded, but the decentralized agents still\nbenefit from improved exploration, without the distraction of unreliable\nincentives.\n", "versions": [{"version": "v1", "created": "Wed, 5 Jun 2019 16:56:54 GMT"}], "update_date": "2019-06-06", "authors_parsed": [["B\u00f6hmer", "Wendelin", ""], ["Rashid", "Tabish", ""], ["Whiteson", "Shimon", ""]]}, {"id": "1906.02146", "submitter": "Shiqi Gao", "authors": "Shiqi Gao, Fuminori Okuya, Yoshihiro Kawahara, Yoshimasa Tsuruoka", "title": "Building a Computer Mahjong Player via Deep Convolutional Neural\n  Networks", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The evaluation function for imperfect information games is always hard to\ndefine but owns a significant impact on the playing strength of a program. Deep\nlearning has made great achievements these years, and already exceeded the top\nhuman players' level even in the game of Go. In this paper, we introduce a new\ndata model to represent the available imperfect information on the game table,\nand construct a well-designed convolutional neural network for game record\ntraining. We choose the accuracy of tile discarding which is also called as the\nagreement rate as the benchmark for this study. Our accuracy on test data\nreaches 70.44%, while the state-of-art baseline is 62.1% reported by Mizukami\nand Tsuruoka (2015), and is significantly higher than previous trials using\ndeep learning, which shows the promising potential of our new model. For the AI\nprogram building, besides the tile discarding strategy, we adopt similar\npredicting strategies for other actions such as stealing (pon, chi, and kan)\nand riichi. With the simple combination of these several predicting networks\nand without any knowledge about the concrete rules of the game, a strength\nevaluation is made for the resulting program on the largest Japanese Mahjong\nsite `Tenhou'. The program has achieved a rating of around 1850, which is\nsignificantly higher than that of an average human player and of programs among\npast studies.\n", "versions": [{"version": "v1", "created": "Wed, 5 Jun 2019 17:07:08 GMT"}, {"version": "v2", "created": "Fri, 7 Jun 2019 12:12:57 GMT"}], "update_date": "2019-06-10", "authors_parsed": [["Gao", "Shiqi", ""], ["Okuya", "Fuminori", ""], ["Kawahara", "Yoshihiro", ""], ["Tsuruoka", "Yoshimasa", ""]]}, {"id": "1906.02155", "submitter": "Alessandro Saffiotti", "authors": "Oscar Th\\\"orn, Peter F\\\"ogel, Peter Knudsen, Luis de Miranda and\n  Alessandro Saffiotti", "title": "Anticipation in collaborative music performance using fuzzy systems: a\n  case study", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In order to collaborate and co-create with humans, an AI system must be\ncapable of both reactive and anticipatory behavior. We present a case study of\nsuch a system in the domain of musical improvisation. We consider a duo\nconsisting of a human pianist accompained by an off-the-shelf virtual drummer,\nand we design an AI system to control the perfomance parameters of the drummer\n(e.g., patterns, intensity, or complexity) as a function of what the human\npianist is playing. The AI system utilizes a model elicited from the musicians\nand encoded through fuzzy logic. This paper outlines the methodology, design,\nand development process of this system. An evaluation in public concerts is\nupcoming. This case study is seen as a step in the broader investigation of\nanticipation and creative processes in mixed human-robot, or \"anthrobotic\"\nsystems.\n", "versions": [{"version": "v1", "created": "Wed, 5 Jun 2019 17:26:50 GMT"}], "update_date": "2019-06-06", "authors_parsed": [["Th\u00f6rn", "Oscar", ""], ["F\u00f6gel", "Peter", ""], ["Knudsen", "Peter", ""], ["de Miranda", "Luis", ""], ["Saffiotti", "Alessandro", ""]]}, {"id": "1906.02164", "submitter": "Vijay Keswani", "authors": "L. Elisa Celis, Vijay Keswani, Nisheeth K. Vishnoi", "title": "Data preprocessing to mitigate bias: A maximum entropy based approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CY cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data containing human or social attributes may over- or under-represent\ngroups with respect to salient social attributes such as gender or race, which\ncan lead to biases in downstream applications. This paper presents an\nalgorithmic framework that can be used as a data preprocessing method towards\nmitigating such bias. Unlike prior work, it can efficiently learn distributions\nover large domains, controllably adjust the representation rates of protected\ngroups and achieve target fairness metrics such as statistical parity, yet\nremains close to the empirical distribution induced by the given dataset. Our\napproach leverages the principle of maximum entropy - amongst all distributions\nsatisfying a given set of constraints, we should choose the one closest in\nKL-divergence to a given prior. While maximum entropy distributions can\nsuccinctly encode distributions over large domains, they can be difficult to\ncompute. Our main contribution is an instantiation of this framework for our\nset of constraints and priors, which encode our bias mitigation goals, and that\nruns in time polynomial in the dimension of the data. Empirically, we observe\nthat samples from the learned distribution have desired representation rates\nand statistical rates, and when used for training a classifier incurs only a\nslight loss in accuracy while maintaining fairness properties.\n", "versions": [{"version": "v1", "created": "Wed, 5 Jun 2019 17:54:00 GMT"}, {"version": "v2", "created": "Tue, 30 Jun 2020 13:07:15 GMT"}], "update_date": "2020-07-01", "authors_parsed": [["Celis", "L. Elisa", ""], ["Keswani", "Vijay", ""], ["Vishnoi", "Nisheeth K.", ""]]}, {"id": "1906.02174", "submitter": "Mingde Zhao", "authors": "Sitao Luan and Mingde Zhao and Xiao-Wen Chang and Doina Precup", "title": "Break the Ceiling: Stronger Multi-scale Deep Graph Convolutional\n  Networks", "comments": "Accepted and to be published by NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, neural network based approaches have achieved significant\nimprovement for solving large, complex, graph-structured problems. However,\ntheir bottlenecks still need to be addressed, and the advantages of multi-scale\ninformation and deep architectures have not been sufficiently exploited. In\nthis paper, we theoretically analyze how existing Graph Convolutional Networks\n(GCNs) have limited expressive power due to the constraint of the activation\nfunctions and their architectures. We generalize spectral graph convolution and\ndeep GCN in block Krylov subspace forms and devise two architectures, both with\nthe potential to be scaled deeper but each making use of the multi-scale\ninformation in different ways. We further show that the equivalence of these\ntwo architectures can be established under certain conditions. On several node\nclassification tasks, with or without the help of validation, the two new\narchitectures achieve better performance compared to many state-of-the-art\nmethods.\n", "versions": [{"version": "v1", "created": "Wed, 5 Jun 2019 17:59:39 GMT"}, {"version": "v2", "created": "Fri, 21 Jun 2019 01:52:27 GMT"}, {"version": "v3", "created": "Sun, 8 Sep 2019 16:22:01 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["Luan", "Sitao", ""], ["Zhao", "Mingde", ""], ["Chang", "Xiao-Wen", ""], ["Precup", "Doina", ""]]}, {"id": "1906.02179", "submitter": "Cuong Nguyen", "authors": "Cuong V. Nguyen, Lam Si Tung Ho, Huan Xu, Vu Dinh, Binh Nguyen", "title": "Bayesian Active Learning With Abstention Feedbacks", "comments": "Poster presented at 2019 ICML Workshop on Human in the Loop Learning\n  2019 (non-archival). arXiv admin note: substantial text overlap with\n  arXiv:1705.08481", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study pool-based active learning with abstention feedbacks where a labeler\ncan abstain from labeling a queried example with some unknown abstention rate.\nThis is an important problem with many useful applications. We take a Bayesian\napproach to the problem and develop two new greedy algorithms that learn both\nthe classification problem and the unknown abstention rate at the same time.\nThese are achieved by simply incorporating the estimated average abstention\nrate into the greedy criteria. We prove that both algorithms have\nnear-optimality guarantees: they respectively achieve a ${(1-\\frac{1}{e})}$\nconstant factor approximation of the optimal expected or worst-case value of a\nuseful utility function. Our experiments show the algorithms perform well in\nvarious practical scenarios.\n", "versions": [{"version": "v1", "created": "Tue, 4 Jun 2019 18:18:17 GMT"}, {"version": "v2", "created": "Wed, 30 Dec 2020 20:35:43 GMT"}], "update_date": "2021-01-01", "authors_parsed": [["Nguyen", "Cuong V.", ""], ["Ho", "Lam Si Tung", ""], ["Xu", "Huan", ""], ["Dinh", "Vu", ""], ["Nguyen", "Binh", ""]]}, {"id": "1906.02285", "submitter": "Tao Yu", "authors": "Tao Yu, Rui Zhang, Michihiro Yasunaga, Yi Chern Tan, Xi Victoria Lin,\n  Suyi Li, Heyang Er, Irene Li, Bo Pang, Tao Chen, Emily Ji, Shreya Dixit,\n  David Proctor, Sungrok Shim, Jonathan Kraft, Vincent Zhang, Caiming Xiong,\n  Richard Socher and Dragomir Radev", "title": "SParC: Cross-Domain Semantic Parsing in Context", "comments": "Accepted to ACL 2019, long paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present SParC, a dataset for cross-domainSemanticParsing inContext that\nconsists of 4,298 coherent question sequences (12k+ individual questions\nannotated with SQL queries). It is obtained from controlled user interactions\nwith 200 complex databases over 138 domains. We provide an in-depth analysis of\nSParC and show that it introduces new challenges compared to existing datasets.\nSParC demonstrates complex contextual dependencies, (2) has greater semantic\ndiversity, and (3) requires generalization to unseen domains due to its\ncross-domain nature and the unseen databases at test time. We experiment with\ntwo state-of-the-art text-to-SQL models adapted to the context-dependent,\ncross-domain setup. The best model obtains an exact match accuracy of 20.2%\nover all questions and less than10% over all interaction sequences, indicating\nthat the cross-domain setting and the con-textual phenomena of the dataset\npresent significant challenges for future research. The dataset, baselines, and\nleaderboard are released at https://yale-lily.github.io/sparc.\n", "versions": [{"version": "v1", "created": "Wed, 5 Jun 2019 20:05:18 GMT"}], "update_date": "2019-06-07", "authors_parsed": [["Yu", "Tao", ""], ["Zhang", "Rui", ""], ["Yasunaga", "Michihiro", ""], ["Tan", "Yi Chern", ""], ["Lin", "Xi Victoria", ""], ["Li", "Suyi", ""], ["Er", "Heyang", ""], ["Li", "Irene", ""], ["Pang", "Bo", ""], ["Chen", "Tao", ""], ["Ji", "Emily", ""], ["Dixit", "Shreya", ""], ["Proctor", "David", ""], ["Shim", "Sungrok", ""], ["Kraft", "Jonathan", ""], ["Zhang", "Vincent", ""], ["Xiong", "Caiming", ""], ["Socher", "Richard", ""], ["Radev", "Dragomir", ""]]}, {"id": "1906.02299", "submitter": "Michael Hind", "authors": "Noel C. F. Codella, Michael Hind, Karthikeyan Natesan Ramamurthy,\n  Murray Campbell, Amit Dhurandhar, Kush R. Varshney, Dennis Wei, Aleksandra\n  Mojsilovi\\'c", "title": "Teaching AI to Explain its Decisions Using Embeddings and Multi-Task\n  Learning", "comments": "presented at 2019 ICML Workshop on Human in the Loop Learning (HILL\n  2019), Long Beach, USA. arXiv admin note: substantial text overlap with\n  arXiv:1805.11648", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Using machine learning in high-stakes applications often requires predictions\nto be accompanied by explanations comprehensible to the domain user, who has\nultimate responsibility for decisions and outcomes. Recently, a new framework\nfor providing explanations, called TED, has been proposed to provide meaningful\nexplanations for predictions. This framework augments training data to include\nexplanations elicited from domain users, in addition to features and labels.\nThis approach ensures that explanations for predictions are tailored to the\ncomplexity expectations and domain knowledge of the consumer. In this paper, we\nbuild on this foundational work, by exploring more sophisticated instantiations\nof the TED framework and empirically evaluate their effectiveness in two\ndiverse domains, chemical odor and skin cancer prediction. Results demonstrate\nthat meaningful explanations can be reliably taught to machine learning\nalgorithms, and in some cases, improving modeling accuracy.\n", "versions": [{"version": "v1", "created": "Wed, 5 Jun 2019 20:42:14 GMT"}], "update_date": "2019-06-07", "authors_parsed": [["Codella", "Noel C. F.", ""], ["Hind", "Michael", ""], ["Ramamurthy", "Karthikeyan Natesan", ""], ["Campbell", "Murray", ""], ["Dhurandhar", "Amit", ""], ["Varshney", "Kush R.", ""], ["Wei", "Dennis", ""], ["Mojsilovi\u0107", "Aleksandra", ""]]}, {"id": "1906.02355", "submitter": "Xuanqing Liu", "authors": "Xuanqing Liu, Tesi Xiao, Si Si, Qin Cao, Sanjiv Kumar, Cho-Jui Hsieh", "title": "Neural SDE: Stabilizing Neural ODE Networks with Stochastic Noise", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural Ordinary Differential Equation (Neural ODE) has been proposed as a\ncontinuous approximation to the ResNet architecture. Some commonly used\nregularization mechanisms in discrete neural networks (e.g. dropout, Gaussian\nnoise) are missing in current Neural ODE networks. In this paper, we propose a\nnew continuous neural network framework called Neural Stochastic Differential\nEquation (Neural SDE) network, which naturally incorporates various commonly\nused regularization mechanisms based on random noise injection. Our framework\ncan model various types of noise injection frequently used in discrete networks\nfor regularization purpose, such as dropout and additive/multiplicative noise\nin each block. We provide theoretical analysis explaining the improved\nrobustness of Neural SDE models against input perturbations/adversarial\nattacks. Furthermore, we demonstrate that the Neural SDE network can achieve\nbetter generalization than the Neural ODE and is more resistant to adversarial\nand non-adversarial input perturbations.\n", "versions": [{"version": "v1", "created": "Wed, 5 Jun 2019 23:19:50 GMT"}], "update_date": "2019-06-07", "authors_parsed": [["Liu", "Xuanqing", ""], ["Xiao", "Tesi", ""], ["Si", "Si", ""], ["Cao", "Qin", ""], ["Kumar", "Sanjiv", ""], ["Hsieh", "Cho-Jui", ""]]}, {"id": "1906.02390", "submitter": "Wei Hu", "authors": "Qingheng Zhang and Zequn Sun and Wei Hu and Muhao Chen and Lingbing\n  Guo and Yuzhong Qu", "title": "Multi-view Knowledge Graph Embedding for Entity Alignment", "comments": "Accepted by the 28th International Joint Conference on Artificial\n  Intelligence (IJCAI 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of embedding-based entity alignment between knowledge\ngraphs (KGs). Previous works mainly focus on the relational structure of\nentities. Some further incorporate another type of features, such as\nattributes, for refinement. However, a vast of entity features are still\nunexplored or not equally treated together, which impairs the accuracy and\nrobustness of embedding-based entity alignment. In this paper, we propose a\nnovel framework that unifies multiple views of entities to learn embeddings for\nentity alignment. Specifically, we embed entities based on the views of entity\nnames, relations and attributes, with several combination strategies.\nFurthermore, we design some cross-KG inference methods to enhance the alignment\nbetween two KGs. Our experiments on real-world datasets show that the proposed\nframework significantly outperforms the state-of-the-art embedding-based entity\nalignment methods. The selected views, cross-KG inference and combination\nstrategies all contribute to the performance improvement.\n", "versions": [{"version": "v1", "created": "Thu, 6 Jun 2019 02:52:12 GMT"}], "update_date": "2019-06-07", "authors_parsed": [["Zhang", "Qingheng", ""], ["Sun", "Zequn", ""], ["Hu", "Wei", ""], ["Chen", "Muhao", ""], ["Guo", "Lingbing", ""], ["Qu", "Yuzhong", ""]]}, {"id": "1906.02403", "submitter": "Fushan Li", "authors": "Fushan Li, Michael Bowling", "title": "Ease-of-Teaching and Language Structure from Emergent Communication", "comments": "Accepted at Neural Information Processing Systems (NeurIPS) 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.LG cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Artificial agents have been shown to learn to communicate when needed to\ncomplete a cooperative task. Some level of language structure (e.g.,\ncompositionality) has been found in the learned communication protocols. This\nobserved structure is often the result of specific environmental pressures\nduring training. By introducing new agents periodically to replace old ones,\nsequentially and within a population, we explore such a new pressure -- ease of\nteaching -- and show its impact on the structure of the resulting language.\n", "versions": [{"version": "v1", "created": "Thu, 6 Jun 2019 03:59:37 GMT"}, {"version": "v2", "created": "Mon, 28 Oct 2019 22:51:26 GMT"}], "update_date": "2019-10-30", "authors_parsed": [["Li", "Fushan", ""], ["Bowling", "Michael", ""]]}, {"id": "1906.02425", "submitter": "Sayna Ebrahimi", "authors": "Sayna Ebrahimi, Mohamed Elhoseiny, Trevor Darrell, Marcus Rohrbach", "title": "Uncertainty-guided Continual Learning with Bayesian Neural Networks", "comments": "Accepted at ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Continual learning aims to learn new tasks without forgetting previously\nlearned ones. This is especially challenging when one cannot access data from\nprevious tasks and when the model has a fixed capacity. Current\nregularization-based continual learning algorithms need an external\nrepresentation and extra computation to measure the parameters'\n\\textit{importance}. In contrast, we propose Uncertainty-guided Continual\nBayesian Neural Networks (UCB), where the learning rate adapts according to the\nuncertainty defined in the probability distribution of the weights in networks.\nUncertainty is a natural way to identify \\textit{what to remember} and\n\\textit{what to change} as we continually learn, and thus mitigate catastrophic\nforgetting. We also show a variant of our model, which uses uncertainty for\nweight pruning and retains task performance after pruning by saving binary\nmasks per tasks. We evaluate our UCB approach extensively on diverse object\nclassification datasets with short and long sequences of tasks and report\nsuperior or on-par performance compared to existing approaches. Additionally,\nwe show that our model does not necessarily need task information at test time,\ni.e. it does not presume knowledge of which task a sample belongs to.\n", "versions": [{"version": "v1", "created": "Thu, 6 Jun 2019 05:40:25 GMT"}, {"version": "v2", "created": "Thu, 20 Feb 2020 01:08:22 GMT"}], "update_date": "2020-02-21", "authors_parsed": [["Ebrahimi", "Sayna", ""], ["Elhoseiny", "Mohamed", ""], ["Darrell", "Trevor", ""], ["Rohrbach", "Marcus", ""]]}, {"id": "1906.02427", "submitter": "Vishal Sunder", "authors": "Vishal Sunder, Ashwin Srinivasan, Lovekesh Vig, Gautam Shroff, Rohit\n  Rahul", "title": "One-shot Information Extraction from Document Images using\n  Neuro-Deductive Program Synthesis", "comments": "11 pages, appears in the 13th International Workshop on\n  Neural-Symbolic Learning and Reasoning at IJCAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Our interest in this paper is in meeting a rapidly growing industrial demand\nfor information extraction from images of documents such as invoices, bills,\nreceipts etc. In practice users are able to provide a very small number of\nexample images labeled with the information that needs to be extracted. We\nadopt a novel two-level neuro-deductive, approach where (a) we use pre-trained\ndeep neural networks to populate a relational database with facts about each\ndocument-image; and (b) we use a form of deductive reasoning, related to\nmeta-interpretive learning of transition systems to learn extraction programs:\nGiven task-specific transitions defined using the entities and relations\nidentified by the neural detectors and a small number of instances (usually 1,\nsometimes 2) of images and the desired outputs, a resource-bounded\nmeta-interpreter constructs proofs for the instance(s) via logical deduction; a\nset of logic programs that extract each desired entity is easily synthesized\nfrom such proofs. In most cases a single training example together with a\nnoisy-clone of itself suffices to learn a program-set that generalizes well on\ntest documents, at which time the value of each entity is determined by a\nmajority vote across its program-set. We demonstrate our two-level\nneuro-deductive approach on publicly available datasets (\"Patent\" and \"Doctor's\nBills\") and also describe its use in a real-life industrial problem.\n", "versions": [{"version": "v1", "created": "Thu, 6 Jun 2019 05:48:21 GMT"}], "update_date": "2019-06-07", "authors_parsed": [["Sunder", "Vishal", ""], ["Srinivasan", "Ashwin", ""], ["Vig", "Lovekesh", ""], ["Shroff", "Gautam", ""], ["Rahul", "Rohit", ""]]}, {"id": "1906.02457", "submitter": "Xiao Ma", "authors": "Xiao Ma, Shen-Yi Zhao and Wu-Jun Li", "title": "Clustered Reinforcement Learning", "comments": "16pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Exploration strategy design is one of the challenging problems in\nreinforcement learning~(RL), especially when the environment contains a large\nstate space or sparse rewards. During exploration, the agent tries to discover\nnovel areas or high reward~(quality) areas. In most existing methods, the\nnovelty and quality in the neighboring area of the current state are not well\nutilized to guide the exploration of the agent. To tackle this problem, we\npropose a novel RL framework, called \\underline{c}lustered\n\\underline{r}einforcement \\underline{l}earning~(CRL), for efficient exploration\nin RL. CRL adopts clustering to divide the collected states into several\nclusters, based on which a bonus reward reflecting both novelty and quality in\nthe neighboring area~(cluster) of the current state is given to the agent.\nExperiments on a continuous control task and several \\emph{Atari 2600} games\nshow that CRL can outperform other state-of-the-art methods to achieve the best\nperformance in most cases.\n", "versions": [{"version": "v1", "created": "Thu, 6 Jun 2019 07:35:02 GMT"}], "update_date": "2019-06-07", "authors_parsed": [["Ma", "Xiao", ""], ["Zhao", "Shen-Yi", ""], ["Li", "Wu-Jun", ""]]}, {"id": "1906.02461", "submitter": "Yichong Leng", "authors": "Yichong Leng, Xu Tan, Tao Qin, Xiang-Yang Li and Tie-Yan Liu", "title": "Unsupervised Pivot Translation for Distant Languages", "comments": "Accepted by ACL-2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unsupervised neural machine translation (NMT) has attracted a lot of\nattention recently. While state-of-the-art methods for unsupervised translation\nusually perform well between similar languages (e.g., English-German\ntranslation), they perform poorly between distant languages, because\nunsupervised alignment does not work well for distant languages. In this work,\nwe introduce unsupervised pivot translation for distant languages, which\ntranslates a language to a distant language through multiple hops, and the\nunsupervised translation on each hop is relatively easier than the original\ndirect translation. We propose a learning to route (LTR) method to choose the\ntranslation path between the source and target languages. LTR is trained on\nlanguage pairs whose best translation path is available and is applied on the\nunseen language pairs for path selection. Experiments on 20 languages and 294\ndistant language pairs demonstrate the advantages of the unsupervised pivot\ntranslation for distant languages, as well as the effectiveness of the proposed\nLTR for path selection. Specifically, in the best case, LTR achieves an\nimprovement of 5.58 BLEU points over the conventional direct unsupervised\nmethod.\n", "versions": [{"version": "v1", "created": "Thu, 6 Jun 2019 07:48:36 GMT"}, {"version": "v2", "created": "Wed, 12 Jun 2019 05:07:08 GMT"}, {"version": "v3", "created": "Tue, 25 Jun 2019 02:58:06 GMT"}], "update_date": "2019-06-26", "authors_parsed": [["Leng", "Yichong", ""], ["Tan", "Xu", ""], ["Qin", "Tao", ""], ["Li", "Xiang-Yang", ""], ["Liu", "Tie-Yan", ""]]}, {"id": "1906.02485", "submitter": "Jonathan Grizou", "authors": "Jonathan Grizou", "title": "The Open Vault Challenge -- Learning how to build calibration-free\n  interactive systems by cracking the code of a vault", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This demo takes the form of a challenge to the IJCAI community. A physical\nvault, secured by a 4-digit code, will be placed in the demo area. The author\nwill publicly open the vault by entering the code on a touch-based interface,\nand as many times as requested. The challenge to the IJCAI participants will be\nto crack the code, open the vault, and collect its content. The interface is\nbased on previous work on calibration-free interactive systems that enables a\nuser to start instructing a machine without the machine knowing how to\ninterpret the user's actions beforehand. The intent and the behavior of the\nhuman are simultaneously learned by the machine. An online demo and videos are\navailable for readers to participate in the challenge. An additional interface\nusing vocal commands will be revealed on the demo day, demonstrating the\nscalability of our approach to continuous input signals.\n", "versions": [{"version": "v1", "created": "Thu, 6 Jun 2019 09:02:16 GMT"}], "update_date": "2019-06-07", "authors_parsed": [["Grizou", "Jonathan", ""]]}, {"id": "1906.02534", "submitter": "Nicolas Pugeault Dr", "authors": "Faisal Alamri and Nicolas Pugeault", "title": "Contextual Relabelling of Detected Objects", "comments": "Presented at the IEEE ICDL-Epirob'2019 conference, Oslo, Norway", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Contextual information, such as the co-occurrence of objects and the spatial\nand relative size among objects provides deep and complex information about\nscenes. It also can play an important role in improving object detection. In\nthis work, we present two contextual models (rescoring and re-labeling models)\nthat leverage contextual information (16 contextual relationships are applied\nin this paper) to enhance the state-of-the-art RCNN-based object detection\n(Faster RCNN). We experimentally demonstrate that our models lead to\nenhancement in detection performance using the most common dataset used in this\nfield (MSCOCO).\n", "versions": [{"version": "v1", "created": "Thu, 6 Jun 2019 11:48:36 GMT"}], "update_date": "2019-06-07", "authors_parsed": [["Alamri", "Faisal", ""], ["Pugeault", "Nicolas", ""]]}, {"id": "1906.02564", "submitter": "Claudia Schulz", "authors": "Claudia Schulz, Christian M. Meyer, Jan Kiesewetter, Michael Sailer,\n  Elisabeth Bauer, Martin R. Fischer, Frank Fischer, Iryna Gurevych", "title": "Analysis of Automatic Annotation Suggestions for Hard Discourse-Level\n  Tasks in Expert Domains", "comments": "To appear in Proceedings of the 57th Annual Meeting of the\n  Association for Computational Linguistics (ACL 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many complex discourse-level tasks can aid domain experts in their work but\nrequire costly expert annotations for data creation. To speed up and ease\nannotations, we investigate the viability of automatically generated annotation\nsuggestions for such tasks. As an example, we choose a task that is\nparticularly hard for both humans and machines: the segmentation and\nclassification of epistemic activities in diagnostic reasoning texts. We create\nand publish a new dataset covering two domains and carefully analyse the\nsuggested annotations. We find that suggestions have positive effects on\nannotation speed and performance, while not introducing noteworthy biases.\nEnvisioning suggestion models that improve with newly annotated texts, we\ncontrast methods for continuous model adjustment and suggest the most effective\nsetup for suggestions in future expert tasks.\n", "versions": [{"version": "v1", "created": "Thu, 6 Jun 2019 13:13:46 GMT"}], "update_date": "2019-06-07", "authors_parsed": [["Schulz", "Claudia", ""], ["Meyer", "Christian M.", ""], ["Kiesewetter", "Jan", ""], ["Sailer", "Michael", ""], ["Bauer", "Elisabeth", ""], ["Fischer", "Martin R.", ""], ["Fischer", "Frank", ""], ["Gurevych", "Iryna", ""]]}, {"id": "1906.02568", "submitter": "Felix Wiewel", "authors": "Felix Wiewel and Bin Yang", "title": "Localizing Catastrophic Forgetting in Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Artificial neural networks (ANNs) suffer from catastrophic forgetting when\ntrained on a sequence of tasks. While this phenomenon was studied in the past,\nthere is only very limited recent research on this phenomenon. We propose a\nmethod for determining the contribution of individual parameters in an ANN to\ncatastrophic forgetting. The method is used to analyze an ANNs response to\nthree different continual learning scenarios.\n", "versions": [{"version": "v1", "created": "Thu, 6 Jun 2019 13:18:03 GMT"}], "update_date": "2019-06-07", "authors_parsed": [["Wiewel", "Felix", ""], ["Yang", "Bin", ""]]}, {"id": "1906.02578", "submitter": "Peilin Chen", "authors": "Peilin Chen, Hai Wan, Shaowei Cai, Weilin Luo, Jia Li", "title": "Combining Reinforcement Learning and Configuration Checking for Maximum\n  k-plex Problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Maximum k-plex Problem is an important combinatorial optimization problem\nwith increasingly wide applications. Due to its exponential time complexity,\nmany heuristic methods have been proposed which can return a good-quality\nsolution in a reasonable time. However, most of the heuristic algorithms are\nmemoryless and unable to utilize the experience during the search. Inspired by\nthe multi-armed bandit (MAB) problem in reinforcement learning (RL), we propose\na novel perturbation mechanism named BLP, which can learn online to select a\ngood vertex for perturbation when getting stuck in local optima. To our best of\nknowledge, this is the first attempt to combine local search with RL for the\nmaximum $ k $-plex problem.\n  Besides, we also propose a novel strategy, named Dynamic-threshold\nConfiguration Checking (DTCC), which extends the original Configuration\nChecking (CC) strategy from two aspects.\n  Based on the BLP and DTCC, we develop a local search algorithm named BDCC and\nimprove it by a hyperheuristic strategy. The experimental result shows that our\nalgorithms dominate on the standard DIMACS and BHOSLIB benchmarks and achieve\nstate-of-the-art performance on massive graphs.\n", "versions": [{"version": "v1", "created": "Thu, 6 Jun 2019 13:35:49 GMT"}], "update_date": "2019-06-07", "authors_parsed": [["Chen", "Peilin", ""], ["Wan", "Hai", ""], ["Cai", "Shaowei", ""], ["Luo", "Weilin", ""], ["Li", "Jia", ""]]}, {"id": "1906.02589", "submitter": "Elliot Creager", "authors": "Elliot Creager, David Madras, J\\\"orn-Henrik Jacobsen, Marissa A. Weis,\n  Kevin Swersky, Toniann Pitassi, Richard Zemel", "title": "Flexibly Fair Representation Learning by Disentanglement", "comments": null, "journal-ref": "Proceedings of the International Conference on Machine Learning\n  (ICML), 2019", "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of learning representations that achieve group and\nsubgroup fairness with respect to multiple sensitive attributes. Taking\ninspiration from the disentangled representation learning literature, we\npropose an algorithm for learning compact representations of datasets that are\nuseful for reconstruction and prediction, but are also \\emph{flexibly fair},\nmeaning they can be easily modified at test time to achieve subgroup\ndemographic parity with respect to multiple sensitive attributes and their\nconjunctions. We show empirically that the resulting encoder---which does not\nrequire the sensitive attributes for inference---enables the adaptation of a\nsingle representation to a variety of fair classification tasks with new target\nlabels and subgroup definitions.\n", "versions": [{"version": "v1", "created": "Thu, 6 Jun 2019 13:56:24 GMT"}], "update_date": "2019-06-07", "authors_parsed": [["Creager", "Elliot", ""], ["Madras", "David", ""], ["Jacobsen", "J\u00f6rn-Henrik", ""], ["Weis", "Marissa A.", ""], ["Swersky", "Kevin", ""], ["Pitassi", "Toniann", ""], ["Zemel", "Richard", ""]]}, {"id": "1906.02634", "submitter": "Oscar T\\\"ackstr\\\"om", "authors": "Dirk Weissenborn, Oscar T\\\"ackstr\\\"om, Jakob Uszkoreit", "title": "Scaling Autoregressive Video Models", "comments": "International Conference on Learning Representations (ICLR) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to the statistical complexity of video, the high degree of inherent\nstochasticity, and the sheer amount of data, generating natural video remains a\nchallenging task. State-of-the-art video generation models often attempt to\naddress these issues by combining sometimes complex, usually video-specific\nneural network architectures, latent variable models, adversarial training and\na range of other methods. Despite their often high complexity, these approaches\nstill fall short of generating high quality video continuations outside of\nnarrow domains and often struggle with fidelity. In contrast, we show that\nconceptually simple autoregressive video generation models based on a\nthree-dimensional self-attention mechanism achieve competitive results across\nmultiple metrics on popular benchmark datasets, for which they produce\ncontinuations of high fidelity and realism. We also present results from\ntraining our models on Kinetics, a large scale action recognition dataset\ncomprised of YouTube videos exhibiting phenomena such as camera movement,\ncomplex object interactions and diverse human movement. While modeling these\nphenomena consistently remains elusive, we hope that our results, which include\noccasional realistic continuations encourage further research on comparatively\ncomplex, large scale datasets such as Kinetics.\n", "versions": [{"version": "v1", "created": "Thu, 6 Jun 2019 15:06:21 GMT"}, {"version": "v2", "created": "Tue, 4 Feb 2020 17:43:56 GMT"}, {"version": "v3", "created": "Mon, 10 Feb 2020 19:29:56 GMT"}], "update_date": "2020-02-12", "authors_parsed": [["Weissenborn", "Dirk", ""], ["T\u00e4ckstr\u00f6m", "Oscar", ""], ["Uszkoreit", "Jakob", ""]]}, {"id": "1906.02717", "submitter": "Mikhail Khodak", "authors": "Mikhail Khodak, Maria-Florina Balcan, Ameet Talwalkar", "title": "Adaptive Gradient-Based Meta-Learning Methods", "comments": "NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We build a theoretical framework for designing and understanding practical\nmeta-learning methods that integrates sophisticated formalizations of\ntask-similarity with the extensive literature on online convex optimization and\nsequential prediction algorithms. Our approach enables the task-similarity to\nbe learned adaptively, provides sharper transfer-risk bounds in the setting of\nstatistical learning-to-learn, and leads to straightforward derivations of\naverage-case regret bounds for efficient algorithms in settings where the\ntask-environment changes dynamically or the tasks share a certain geometric\nstructure. We use our theory to modify several popular meta-learning algorithms\nand improve their meta-test-time performance on standard problems in few-shot\nlearning and federated learning.\n", "versions": [{"version": "v1", "created": "Thu, 6 Jun 2019 17:36:34 GMT"}, {"version": "v2", "created": "Mon, 17 Jun 2019 14:38:19 GMT"}, {"version": "v3", "created": "Sat, 7 Dec 2019 03:50:47 GMT"}], "update_date": "2019-12-10", "authors_parsed": [["Khodak", "Mikhail", ""], ["Balcan", "Maria-Florina", ""], ["Talwalkar", "Ameet", ""]]}, {"id": "1906.02738", "submitter": "Lianhui Qin", "authors": "Lianhui Qin, Michel Galley, Chris Brockett, Xiaodong Liu, Xiang Gao,\n  Bill Dolan, Yejin Choi and Jianfeng Gao", "title": "Conversing by Reading: Contentful Neural Conversation with On-demand\n  Machine Reading", "comments": "ACL 2019 long paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although neural conversation models are effective in learning how to produce\nfluent responses, their primary challenge lies in knowing what to say to make\nthe conversation contentful and non-vacuous. We present a new end-to-end\napproach to contentful neural conversation that jointly models response\ngeneration and on-demand machine reading. The key idea is to provide the\nconversation model with relevant long-form text on the fly as a source of\nexternal knowledge. The model performs QA-style reading comprehension on this\ntext in response to each conversational turn, thereby allowing for more focused\nintegration of external knowledge than has been possible in prior approaches.\nTo support further research on knowledge-grounded conversation, we introduce a\nnew large-scale conversation dataset grounded in external web pages (2.8M\nturns, 7.4M sentences of grounding). Both human evaluation and automated\nmetrics show that our approach results in more contentful responses compared to\na variety of previous methods, improving both the informativeness and diversity\nof generated output.\n", "versions": [{"version": "v1", "created": "Thu, 6 Jun 2019 17:55:37 GMT"}, {"version": "v2", "created": "Fri, 7 Jun 2019 03:10:20 GMT"}], "update_date": "2019-06-10", "authors_parsed": [["Qin", "Lianhui", ""], ["Galley", "Michel", ""], ["Brockett", "Chris", ""], ["Liu", "Xiaodong", ""], ["Gao", "Xiang", ""], ["Dolan", "Bill", ""], ["Choi", "Yejin", ""], ["Gao", "Jianfeng", ""]]}, {"id": "1906.02768", "submitter": "Ari Morcos", "authors": "Haonan Yu, Sergey Edunov, Yuandong Tian, and Ari S. Morcos", "title": "Playing the lottery with rewards and multiple languages: lottery tickets\n  in RL and NLP", "comments": "ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The lottery ticket hypothesis proposes that over-parameterization of deep\nneural networks (DNNs) aids training by increasing the probability of a \"lucky\"\nsub-network initialization being present rather than by helping the\noptimization process (Frankle & Carbin, 2019). Intriguingly, this phenomenon\nsuggests that initialization strategies for DNNs can be improved substantially,\nbut the lottery ticket hypothesis has only previously been tested in the\ncontext of supervised learning for natural image tasks. Here, we evaluate\nwhether \"winning ticket\" initializations exist in two different domains:\nnatural language processing (NLP) and reinforcement learning (RL).For NLP, we\nexamined both recurrent LSTM models and large-scale Transformer models (Vaswani\net al., 2017). For RL, we analyzed a number of discrete-action space tasks,\nincluding both classic control and pixel control. Consistent with workin\nsupervised image classification, we confirm that winning ticket initializations\ngenerally outperform parameter-matched random initializations, even at extreme\npruning rates for both NLP and RL. Notably, we are able to find winning ticket\ninitializations for Transformers which enable models one-third the size to\nachieve nearly equivalent performance. Together, these results suggest that the\nlottery ticket hypothesis is not restricted to supervised learning of natural\nimages, but rather represents a broader phenomenon in DNNs.\n", "versions": [{"version": "v1", "created": "Thu, 6 Jun 2019 18:38:38 GMT"}, {"version": "v2", "created": "Mon, 25 Nov 2019 17:33:34 GMT"}, {"version": "v3", "created": "Tue, 25 Feb 2020 21:50:07 GMT"}], "update_date": "2020-02-27", "authors_parsed": [["Yu", "Haonan", ""], ["Edunov", "Sergey", ""], ["Tian", "Yuandong", ""], ["Morcos", "Ari S.", ""]]}, {"id": "1906.02771", "submitter": "Ariella Smofsky", "authors": "Patrick Nadeem Ward and Ariella Smofsky and Avishek Joey Bose", "title": "Improving Exploration in Soft-Actor-Critic with Normalizing Flows\n  Policies", "comments": "INNF workshop, International Conference on Machine Learning 2019,\n  Long Beach CA, USA", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Deep Reinforcement Learning (DRL) algorithms for continuous action spaces are\nknown to be brittle toward hyperparameters as well as \\cut{being}sample\ninefficient. Soft Actor Critic (SAC) proposes an off-policy deep actor critic\nalgorithm within the maximum entropy RL framework which offers greater\nstability and empirical gains. The choice of policy distribution, a factored\nGaussian, is motivated by \\cut{chosen due}its easy re-parametrization rather\nthan its modeling power. We introduce Normalizing Flow policies within the SAC\nframework that learn more expressive classes of policies than simple factored\nGaussians. \\cut{We also present a series of stabilization tricks that enable\neffective training of these policies in the RL setting.}We show empirically on\ncontinuous grid world tasks that our approach increases stability and is better\nsuited to difficult exploration in sparse reward settings.\n", "versions": [{"version": "v1", "created": "Thu, 6 Jun 2019 18:43:19 GMT"}], "update_date": "2019-06-10", "authors_parsed": [["Ward", "Patrick Nadeem", ""], ["Smofsky", "Ariella", ""], ["Bose", "Avishek Joey", ""]]}, {"id": "1906.02775", "submitter": "Alexander Peysakhovich", "authors": "Alexander Peysakhovich, Christian Kroer", "title": "Fair Division Without Disparate Impact", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of dividing items between individuals in a way that\nis fair both in the sense of distributional fairness and in the sense of not\nhaving disparate impact across protected classes. An important existing\nmechanism for distributionally fair division is competitive equilibrium from\nequal incomes (CEEI). Unfortunately, CEEI will not, in general, respect\ndisparate impact constraints. We consider two types of disparate impact\nmeasures: requiring that allocations be similar across protected classes and\nrequiring that average utility levels be similar across protected classes. We\nmodify the standard CEEI algorithm in two ways: equitable equilibrium from\nequal incomes, which removes disparate impact in allocations, and competitive\nequilibrium from equitable incomes which removes disparate impact in attained\nutility levels. We show analytically that removing disparate impact in outcomes\nbreaks several of CEEI's desirable properties such as envy, regret, Pareto\noptimality, and incentive compatibility. By contrast, we can remove disparate\nimpact in attained utility levels without affecting these properties. Finally,\nwe experimentally evaluate the tradeoffs between efficiency, equity, and\ndisparate impact in a recommender-system based market.\n", "versions": [{"version": "v1", "created": "Thu, 6 Jun 2019 18:56:17 GMT"}], "update_date": "2019-06-10", "authors_parsed": [["Peysakhovich", "Alexander", ""], ["Kroer", "Christian", ""]]}, {"id": "1906.02789", "submitter": "Zlatan Ajanovic", "authors": "Zlatan Ajanovic, Halil Beglerovic, Bakir Lacevic", "title": "A novel approach to model exploration for value function learning", "comments": "Presented at RSS 2019 workshop CLeaR", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Planning and Learning are complementary approaches. Planning relies on\ndeliberative reasoning about the current state and sequence of future reachable\nstates to solve the problem. Learning, on the other hand, is focused on\nimproving system performance based on experience or available data. Learning to\nimprove the performance of planning based on experience in similar, previously\nsolved problems, is ongoing research. One approach is to learn Value function\n(cost-to-go) which can be used as heuristics for speeding up search-based\nplanning. Existing approaches in this direction use the results of the previous\nsearch for learning the heuristics. In this work, we present a search-inspired\napproach of systematic model exploration for the learning of the value function\nwhich does not stop when a plan is available but rather prolongs search such\nthat not only resulting optimal path is used but also extended region around\nthe optimal path. This, in turn, improves both the efficiency and robustness of\nsuccessive planning. Additionally, the effect of losing admissibility by using\nML heuristic is managed by bounding ML with other admissible heuristics.\n", "versions": [{"version": "v1", "created": "Thu, 6 Jun 2019 19:46:33 GMT"}, {"version": "v2", "created": "Tue, 10 Sep 2019 10:39:45 GMT"}], "update_date": "2019-09-11", "authors_parsed": [["Ajanovic", "Zlatan", ""], ["Beglerovic", "Halil", ""], ["Lacevic", "Bakir", ""]]}, {"id": "1906.02795", "submitter": "Yan Zhang", "authors": "Yan Zhang and Jonathon Hare and Adam Pr\\\"ugel-Bennett", "title": "FSPool: Learning Set Representations with Featurewise Sort Pooling", "comments": "Published at International Conference on Learning Representations\n  (ICLR) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Traditional set prediction models can struggle with simple datasets due to an\nissue we call the responsibility problem. We introduce a pooling method for\nsets of feature vectors based on sorting features across elements of the set.\nThis can be used to construct a permutation-equivariant auto-encoder that\navoids this responsibility problem. On a toy dataset of polygons and a set\nversion of MNIST, we show that such an auto-encoder produces considerably\nbetter reconstructions and representations. Replacing the pooling function in\nexisting set encoders with FSPool improves accuracy and convergence speed on a\nvariety of datasets.\n", "versions": [{"version": "v1", "created": "Thu, 6 Jun 2019 20:16:40 GMT"}, {"version": "v2", "created": "Sat, 28 Sep 2019 22:43:55 GMT"}, {"version": "v3", "created": "Thu, 26 Dec 2019 12:02:15 GMT"}, {"version": "v4", "created": "Fri, 1 May 2020 09:40:45 GMT"}], "update_date": "2020-05-04", "authors_parsed": [["Zhang", "Yan", ""], ["Hare", "Jonathon", ""], ["Pr\u00fcgel-Bennett", "Adam", ""]]}, {"id": "1906.02858", "submitter": "Iacopo Masi", "authors": "Joe Mathai, Iacopo Masi, Wael AbdAlmageed", "title": "Does Generative Face Completion Help Face Recognition?", "comments": "In Proceedings Of IAPR International Conference On Biometrics 2019\n  (ICB'19)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Face occlusions, covering either the majority or discriminative parts of the\nface, can break facial perception and produce a drastic loss of information.\nBiometric systems such as recent deep face recognition models are not immune to\nobstructions or other objects covering parts of the face. While most of the\ncurrent face recognition methods are not optimized to handle occlusions, there\nhave been a few attempts to improve robustness directly in the training stage.\nUnlike those, we propose to study the effect of generative face completion on\nthe recognition. We offer a face completion encoder-decoder, based on a\nconvolutional operator with a gating mechanism, trained with an ample set of\nface occlusions. To systematically evaluate the impact of realistic occlusions\non recognition, we propose to play the occlusion game: we render 3D objects\nonto different face parts, providing precious knowledge of what the impact is\nof effectively removing those occlusions. Extensive experiments on the Labeled\nFaces in the Wild (LFW), and its more difficult variant LFW-BLUFR, testify that\nface completion is able to partially restore face perception in machine vision\nsystems for improved recognition.\n", "versions": [{"version": "v1", "created": "Fri, 7 Jun 2019 01:48:28 GMT"}], "update_date": "2019-06-10", "authors_parsed": [["Mathai", "Joe", ""], ["Masi", "Iacopo", ""], ["AbdAlmageed", "Wael", ""]]}, {"id": "1906.02859", "submitter": "Ekim Yurtsever", "authors": "Ekim Yurtsever, Yongkang Liu, Jacob Lambert, Chiyomi Miyajima, Eijiro\n  Takeuchi, Kazuya Takeda, John H. L. Hansen", "title": "Risky Action Recognition in Lane Change Video Clips using Deep\n  Spatiotemporal Networks with Segmentation Mask Transfer", "comments": "8 pages, 3 figures, 1 table. The code is open-source", "journal-ref": "2019 IEEE Intelligent Transportation Systems Conference (ITSC),\n  Auckland, New Zealand, 2019, pp. 3100-3107", "doi": "10.1109/ITSC.2019.8917362", "report-no": null, "categories": "cs.CV cs.AI cs.LG eess.IV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Advanced driver assistance and automated driving systems rely on risk\nestimation modules to predict and avoid dangerous situations. Current methods\nuse expensive sensor setups and complex processing pipeline, limiting their\navailability and robustness. To address these issues, we introduce a novel deep\nlearning based action recognition framework for classifying dangerous lane\nchange behavior in short video clips captured by a monocular camera. We\ndesigned a deep spatiotemporal classification network that uses pre-trained\nstate-of-the-art instance segmentation network Mask R-CNN as its spatial\nfeature extractor for this task. The Long-Short Term Memory (LSTM) and\nshallower final classification layers of the proposed method were trained on a\nsemi-naturalistic lane change dataset with annotated risk labels. A\ncomprehensive comparison of state-of-the-art feature extractors was carried out\nto find the best network layout and training strategy. The best result, with a\n0.937 AUC score, was obtained with the proposed network. Our code and trained\nmodels are available open-source.\n", "versions": [{"version": "v1", "created": "Fri, 7 Jun 2019 01:53:23 GMT"}, {"version": "v2", "created": "Sun, 2 Feb 2020 16:01:54 GMT"}], "update_date": "2020-02-04", "authors_parsed": [["Yurtsever", "Ekim", ""], ["Liu", "Yongkang", ""], ["Lambert", "Jacob", ""], ["Miyajima", "Chiyomi", ""], ["Takeuchi", "Eijiro", ""], ["Takeda", "Kazuya", ""], ["Hansen", "John H. L.", ""]]}, {"id": "1906.02870", "submitter": "Daniel Russo", "authors": "Daniel Russo", "title": "Worst-Case Regret Bounds for Exploration via Randomized Value Functions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies a recent proposal to use randomized value functions to\ndrive exploration in reinforcement learning. These randomized value functions\nare generated by injecting random noise into the training data, making the\napproach compatible with many popular methods for estimating parameterized\nvalue functions. By providing a worst-case regret bound for tabular\nfinite-horizon Markov decision processes, we show that planning with respect to\nthese randomized value functions can induce provably efficient exploration.\n", "versions": [{"version": "v1", "created": "Fri, 7 Jun 2019 02:36:00 GMT"}, {"version": "v2", "created": "Sat, 22 Jun 2019 09:40:10 GMT"}, {"version": "v3", "created": "Fri, 16 Aug 2019 22:43:53 GMT"}], "update_date": "2019-08-20", "authors_parsed": [["Russo", "Daniel", ""]]}, {"id": "1906.02900", "submitter": "Sewon Min", "authors": "Sewon Min, Eric Wallace, Sameer Singh, Matt Gardner, Hannaneh\n  Hajishirzi, Luke Zettlemoyer", "title": "Compositional Questions Do Not Necessitate Multi-hop Reasoning", "comments": "Published as a conference paper at ACL 2019 (short). Code available\n  at https://github.com/shmsw25/single-hop-rc", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-hop reading comprehension (RC) questions are challenging because they\nrequire reading and reasoning over multiple paragraphs. We argue that it can be\ndifficult to construct large multi-hop RC datasets. For example, even highly\ncompositional questions can be answered with a single hop if they target\nspecific entity types, or the facts needed to answer them are redundant. Our\nanalysis is centered on HotpotQA, where we show that single-hop reasoning can\nsolve much more of the dataset than previously thought. We introduce a\nsingle-hop BERT-based RC model that achieves 67 F1---comparable to\nstate-of-the-art multi-hop models. We also design an evaluation setting where\nhumans are not shown all of the necessary paragraphs for the intended multi-hop\nreasoning but can still answer over 80% of questions. Together with detailed\nerror analysis, these results suggest there should be an increasing focus on\nthe role of evidence in multi-hop reasoning and possibly even a shift towards\ninformation retrieval style evaluations with large and diverse evidence\ncollections.\n", "versions": [{"version": "v1", "created": "Fri, 7 Jun 2019 05:10:15 GMT"}], "update_date": "2019-06-10", "authors_parsed": [["Min", "Sewon", ""], ["Wallace", "Eric", ""], ["Singh", "Sameer", ""], ["Gardner", "Matt", ""], ["Hajishirzi", "Hannaneh", ""], ["Zettlemoyer", "Luke", ""]]}, {"id": "1906.02912", "submitter": "Nathan Sturtevant", "authors": "Nathan Sturtevant and Malte Helmert", "title": "Exponential-Binary State-Space Search", "comments": "This paper and another independent IJCAI 2019 submission have been\n  merged into a single paper that subsumes both of them (Helmert et. al.,\n  2019). This paper is placed here only for historical context. Please only\n  cite the subsuming paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Iterative deepening search is used in applications where the best cost bound\nfor state-space search is unknown. The iterative deepening process is used to\navoid overshooting the appropriate cost bound and doing too much work as a\nresult. However, iterative deepening search also does too much work if the cost\nbound grows too slowly. This paper proposes a new framework for iterative\ndeepening search called exponential-binary state-space search. The approach\ninterleaves exponential and binary searches to find the desired cost bound,\nreducing the worst-case overhead from polynomial to logarithmic.\nExponential-binary search can be used with bounded depth-first search to\nimprove the worst-case performance of IDA* and with breadth-first heuristic\nsearch to improve the worst-case performance of search with inconsistent\nheuristics.\n", "versions": [{"version": "v1", "created": "Fri, 7 Jun 2019 06:11:06 GMT"}], "update_date": "2019-06-10", "authors_parsed": [["Sturtevant", "Nathan", ""], ["Helmert", "Malte", ""]]}, {"id": "1906.02916", "submitter": "Sewon Min", "authors": "Sewon Min, Victor Zhong, Luke Zettlemoyer, Hannaneh Hajishirzi", "title": "Multi-hop Reading Comprehension through Question Decomposition and\n  Rescoring", "comments": "Published as a conference paper at ACL 2019 (long). Code available at\n  https://github.com/shmsw25/DecompRC", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-hop Reading Comprehension (RC) requires reasoning and aggregation\nacross several paragraphs. We propose a system for multi-hop RC that decomposes\na compositional question into simpler sub-questions that can be answered by\noff-the-shelf single-hop RC models. Since annotations for such decomposition\nare expensive, we recast sub-question generation as a span prediction problem\nand show that our method, trained using only 400 labeled examples, generates\nsub-questions that are as effective as human-authored sub-questions. We also\nintroduce a new global rescoring approach that considers each decomposition\n(i.e. the sub-questions and their answers) to select the best final answer,\ngreatly improving overall performance. Our experiments on HotpotQA show that\nthis approach achieves the state-of-the-art results, while providing\nexplainable evidence for its decision making in the form of sub-questions.\n", "versions": [{"version": "v1", "created": "Fri, 7 Jun 2019 06:22:17 GMT"}, {"version": "v2", "created": "Sun, 30 Jun 2019 22:30:19 GMT"}], "update_date": "2019-07-02", "authors_parsed": [["Min", "Sewon", ""], ["Zhong", "Victor", ""], ["Zettlemoyer", "Luke", ""], ["Hajishirzi", "Hannaneh", ""]]}, {"id": "1906.02991", "submitter": "Gabriel Turinici", "authors": "Gabriel Turinici (CEREMADE, IUF)", "title": "Stochastic learning control of inhomogeneous quantum ensembles", "comments": null, "journal-ref": "Phys. Rev. A 100, 053403 (2019)", "doi": "10.1103/PhysRevA.100.053403", "report-no": null, "categories": "math.NA cs.AI cs.NA quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In quantum control, the robustness with respect to uncertainties in the\nsystem's parameters or driving field characteristics is of paramount importance\nand has been studied theoretically, numerically and experimentally. We test in\nthis paper stochastic search procedures (Stochastic gradient descent and the\nAdam algorithm) that sample, at each iteration, from the distribution of the\nparameter uncertainty, as opposed to previous approaches that use a fixed grid.\nWe show that both algorithms behave well with respect to benchmarks and discuss\ntheir relative merits. In addition the methodology allows to address high\ndimensional parameter uncertainty; we implement numerically, with good results,\na 3D and a 6D case.\n", "versions": [{"version": "v1", "created": "Fri, 7 Jun 2019 09:54:29 GMT"}, {"version": "v2", "created": "Thu, 12 Sep 2019 13:25:02 GMT"}, {"version": "v3", "created": "Fri, 29 Nov 2019 10:24:15 GMT"}], "update_date": "2019-12-04", "authors_parsed": [["Turinici", "Gabriel", "", "CEREMADE, IUF"]]}, {"id": "1906.03022", "submitter": "Pablo Lanillos", "authors": "Guillermo Oliver, Pablo Lanillos, Gordon Cheng", "title": "Active inference body perception and action for humanoid robots", "comments": "Under review", "journal-ref": null, "doi": "10.1109/TCDS.2021.3049907", "report-no": null, "categories": "cs.RO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Providing artificial agents with the same computational models of biological\nsystems is a way to understand how intelligent behaviours may emerge. We\npresent an active inference body perception and action model working for the\nfirst time in a humanoid robot. The model relies on the free energy principle\nproposed for the brain, where both perception and action goal is to minimise\nthe prediction error through gradient descent on the variational free energy\nbound. The body state (latent variable) is inferred by minimising the\ndifference between the observed (visual and proprioceptive) sensor values and\nthe predicted ones. Simultaneously, the action makes sensory data sampling to\nbetter correspond to the prediction made by the inner model. We formalised and\nimplemented the algorithm on the iCub robot and tested in 2D and 3D visual\nspaces for online adaptation to visual changes, sensory noise and discrepancies\nbetween the model and the real robot. We also compared our approach with\nclassical inverse kinematics in a reaching task, analysing the suitability of\nsuch a neuroscience-inspired approach for real-world interaction. The algorithm\ngave the robot adaptive body perception and upper body reaching with head\nobject tracking (toddler-like), and was able to incorporate visual features\nonline (in a closed-loop manner) without increasing the computational\ncomplexity. Moreover, our model predicted involuntary actions in the presence\nof sensorimotor conflicts showing the path for a potential proof of active\ninference in humans.\n", "versions": [{"version": "v1", "created": "Fri, 7 Jun 2019 11:33:53 GMT"}, {"version": "v2", "created": "Thu, 8 Aug 2019 16:03:43 GMT"}, {"version": "v3", "created": "Wed, 29 Jan 2020 14:09:20 GMT"}], "update_date": "2021-02-08", "authors_parsed": [["Oliver", "Guillermo", ""], ["Lanillos", "Pablo", ""], ["Cheng", "Gordon", ""]]}, {"id": "1906.03037", "submitter": "Vidyasagar Sadhu", "authors": "Vidyasagar Sadhu, Gabriel Salles-Loustau, Dario Pompili, Saman Zonouz,\n  Vincent Sritapan", "title": "Argus: Smartphone-enabled Human Cooperation via Multi-Agent\n  Reinforcement Learning for Disaster Situational Awareness", "comments": null, "journal-ref": "2016 IEEE International Conference on Autonomic Computing (ICAC),\n  Wurzburg, 2016, pp. 251-256", "doi": "10.1109/ICAC.2016.43", "report-no": null, "categories": "cs.CY cs.AI cs.LG cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Argus exploits a Multi-Agent Reinforcement Learning (MARL) framework to\ncreate a 3D mapping of the disaster scene using agents present around the\nincident zone to facilitate the rescue operations. The agents can be both human\nbystanders at the disaster scene as well as drones or robots that can assist\nthe humans. The agents are involved in capturing the images of the scene using\ntheir smartphones (or on-board cameras in case of drones) as directed by the\nMARL algorithm. These images are used to build real time a 3D map of the\ndisaster scene. Via both simulations and real experiments, an evaluation of the\nframework in terms of effectiveness in tracking random dynamicity of the\nenvironment is presented.\n", "versions": [{"version": "v1", "created": "Mon, 29 Apr 2019 02:16:32 GMT"}], "update_date": "2019-06-10", "authors_parsed": [["Sadhu", "Vidyasagar", ""], ["Salles-Loustau", "Gabriel", ""], ["Pompili", "Dario", ""], ["Zonouz", "Saman", ""], ["Sritapan", "Vincent", ""]]}, {"id": "1906.03051", "submitter": "Feihong Liu", "authors": "Feihong Liu and Jun Feng and Geng Chen and Ye Wu and Yoonmi Hong and\n  Pew-Thian Yap and Dinggang Shen", "title": "DeepBundle: Fiber Bundle Parcellation with Graph Convolution Neural\n  Networks", "comments": "8 pages", "journal-ref": null, "doi": "10.1007/978-3-030-35817-4_11", "report-no": null, "categories": "eess.IV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Parcellation of whole-brain tractography streamlines is an important step for\ntract-based analysis of brain white matter microstructure. Existing fiber\nparcellation approaches rely on accurate registration between an atlas and the\ntractograms of an individual, however, due to large individual differences,\naccurate registration is hard to guarantee in practice. To resolve this issue,\nwe propose a novel deep learning method, called DeepBundle, for\nregistration-free fiber parcellation. Our method utilizes graph convolution\nneural networks (GCNNs) to predict the parcellation label of each fiber tract.\nGCNNs are capable of extracting the geometric features of each fiber tract and\nharnessing the resulting features for accurate fiber parcellation and\nultimately avoiding the use of atlases and any registration method. We evaluate\nDeepBundle using data from the Human Connectome Project. Experimental results\ndemonstrate the advantages of DeepBundle and suggest that the geometric\nfeatures extracted from each fiber tract can be used to effectively parcellate\nthe fiber tracts.\n", "versions": [{"version": "v1", "created": "Fri, 7 Jun 2019 12:37:08 GMT"}, {"version": "v2", "created": "Mon, 23 Dec 2019 09:58:01 GMT"}], "update_date": "2019-12-24", "authors_parsed": [["Liu", "Feihong", ""], ["Feng", "Jun", ""], ["Chen", "Geng", ""], ["Wu", "Ye", ""], ["Hong", "Yoonmi", ""], ["Yap", "Pew-Thian", ""], ["Shen", "Dinggang", ""]]}, {"id": "1906.03074", "submitter": "Feng Tian Ph.D Eng.", "authors": "Feng Tian, Jia Yue, Kuo-ming Chao, Buyue Qian, Nazaraf Shah,\n  Longzhuang Li, Haiping Zhu, Yan Chen, Bin Zeng and Qinghua Zheng", "title": "Modeling e-Learners' Cognitive and Metacognitive Strategy in Comparative\n  Question Solving", "comments": "12 pages, 15 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cognitive and metacognitive strategy had demonstrated a significant role in\nself-regulated learning (SRL), and an appropriate use of strategies is\nbeneficial to effective learning or question-solving tasks during a\nhuman-computer interaction process. This paper proposes a novel method\ncombining Knowledge Map (KM) based data mining technique with Thinking Map (TM)\nto detect learner's cognitive and metacognitive strategy in the\nquestion-solving scenario. In particular, a graph-based mining algorithm is\ndesigned to facilitate our proposed method, which can automatically map\ncognitive strategy to metacognitive strategy with raising abstraction level,\nand make the cognitive and metacognitive process viewable, which acts like a\nreverse engineering engine to explain how a learner thinks when solving a\nquestion. Additionally, we develop an online learning environment system for\nparticipants to learn and record their behaviors. To corroborate the\neffectiveness of our approach and algorithm, we conduct experiments recruiting\n173 postgraduate and undergraduate students, and they were asked to complete a\nquestion-solving task, such as \"What are similarities and differences between\narray and pointer?\" from \"The C Programming Language\" course and \"What are\nsimilarities and differences between packet switching and circuit switching?\"\nfrom \"Computer Network Principle\" course. The mined strategies patterns results\nare encouraging and supported well our proposed method.\n", "versions": [{"version": "v1", "created": "Tue, 4 Jun 2019 14:51:09 GMT"}], "update_date": "2019-06-10", "authors_parsed": [["Tian", "Feng", ""], ["Yue", "Jia", ""], ["Chao", "Kuo-ming", ""], ["Qian", "Buyue", ""], ["Shah", "Nazaraf", ""], ["Li", "Longzhuang", ""], ["Zhu", "Haiping", ""], ["Chen", "Yan", ""], ["Zeng", "Bin", ""], ["Zheng", "Qinghua", ""]]}, {"id": "1906.03085", "submitter": "Weilin Luo", "authors": "Weilin Luo and Hai Wan and Hongzhen Zhong and Ou Wei", "title": "CoAPI: An Efficient Two-Phase Algorithm Using Core-Guided\n  Over-Approximate Cover for Prime Compilation of Non-Clausal Formulae", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Prime compilation, i.e., the generation of all prime implicates or implicants\n(primes for short) of formulae, is a prominent fundamental issue for AI.\nRecently, the prime compilation for non-clausal formulae has received great\nattention. The state-of-the-art approaches generate all primes along with a\nprime cover constructed by prime implicates using dual rail encoding. However,\nthe dual rail encoding potentially expands search space. In addition,\nconstructing a prime cover, which is necessary for their methods, is\ntime-consuming. To address these issues, we propose a novel two-phase method --\nCoAPI. The two phases are the key to construct a cover without using dual rail\nencoding. Specifically, given a non-clausal formula, we first propose a\ncore-guided method to rewrite the non-clausal formula into a cover constructed\nby over-approximate implicates in the first phase. Then, we generate all the\nprimes based on the cover in the second phase. In order to reduce the size of\nthe cover, we provide a multi-order based shrinking method, with a good\ntradeoff between the small size and efficiency, to compress the size of cover\nconsiderably. The experimental results show that CoAPI outperforms\nstate-of-the-art approaches. Particularly, for generating all prime implicates,\nCoAPI consumes about one order of magnitude less time.\n", "versions": [{"version": "v1", "created": "Fri, 7 Jun 2019 13:26:39 GMT"}], "update_date": "2019-06-10", "authors_parsed": [["Luo", "Weilin", ""], ["Wan", "Hai", ""], ["Zhong", "Hongzhen", ""], ["Wei", "Ou", ""]]}, {"id": "1906.03098", "submitter": "Oggi Rudovic", "authors": "Ognjen Rudovic, Meiru Zhang, Bjorn Schuller and Rosalind W. Picard", "title": "Multi-modal Active Learning From Human Data: A Deep Reinforcement\n  Learning Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.HC cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Human behavior expression and experience are inherently multi-modal, and\ncharacterized by vast individual and contextual heterogeneity. To achieve\nmeaningful human-computer and human-robot interactions, multi-modal models of\nthe users states (e.g., engagement) are therefore needed. Most of the existing\nworks that try to build classifiers for the users states assume that the data\nto train the models are fully labeled. Nevertheless, data labeling is costly\nand tedious, and also prone to subjective interpretations by the human coders.\nThis is even more pronounced when the data are multi-modal (e.g., some users\nare more expressive with their facial expressions, some with their voice).\nThus, building models that can accurately estimate the users states during an\ninteraction is challenging. To tackle this, we propose a novel multi-modal\nactive learning (AL) approach that uses the notion of deep reinforcement\nlearning (RL) to find an optimal policy for active selection of the users data,\nneeded to train the target (modality-specific) models. We investigate different\nstrategies for multi-modal data fusion, and show that the proposed model-level\nfusion coupled with RL outperforms the feature-level and modality-specific\nmodels, and the naive AL strategies such as random sampling, and the standard\nheuristics such as uncertainty sampling. We show the benefits of this approach\non the task of engagement estimation from real-world child-robot interactions\nduring an autism therapy. Importantly, we show that the proposed multi-modal AL\napproach can be used to efficiently personalize the engagement classifiers to\nthe target user using a small amount of actively selected users data.\n", "versions": [{"version": "v1", "created": "Fri, 7 Jun 2019 13:46:15 GMT"}], "update_date": "2019-06-10", "authors_parsed": [["Rudovic", "Ognjen", ""], ["Zhang", "Meiru", ""], ["Schuller", "Bjorn", ""], ["Picard", "Rosalind W.", ""]]}, {"id": "1906.03100", "submitter": "Xuebo Liu", "authors": "Xuebo Liu, Derek F. Wong, Yang Liu, Lidia S. Chao, Tong Xiao, Jingbo\n  Zhu", "title": "Shared-Private Bilingual Word Embeddings for Neural Machine Translation", "comments": "Accepted to ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Word embedding is central to neural machine translation (NMT), which has\nattracted intensive research interest in recent years. In NMT, the source\nembedding plays the role of the entrance while the target embedding acts as the\nterminal. These layers occupy most of the model parameters for representation\nlearning. Furthermore, they indirectly interface via a soft-attention\nmechanism, which makes them comparatively isolated. In this paper, we propose\nshared-private bilingual word embeddings, which give a closer relationship\nbetween the source and target embeddings, and which also reduce the number of\nmodel parameters. For similar source and target words, their embeddings tend to\nshare a part of the features and they cooperatively learn these common\nrepresentation units. Experiments on 5 language pairs belonging to 6 different\nlanguage families and written in 5 different alphabets demonstrate that the\nproposed model provides a significant performance boost over the strong\nbaselines with dramatically fewer model parameters.\n", "versions": [{"version": "v1", "created": "Fri, 7 Jun 2019 13:48:46 GMT"}], "update_date": "2019-06-10", "authors_parsed": [["Liu", "Xuebo", ""], ["Wong", "Derek F.", ""], ["Liu", "Yang", ""], ["Chao", "Lidia S.", ""], ["Xiao", "Tong", ""], ["Zhu", "Jingbo", ""]]}, {"id": "1906.03129", "submitter": "Shahram Khadivi", "authors": "Shen Yan, Leonard Dahlmann, Pavel Petrushkov, Sanjika Hewavitharana,\n  Shahram Khadivi", "title": "Word-based Domain Adaptation for Neural Machine Translation", "comments": "Published on the proceedings of the International Workshop on Spoken\n  Language Translation (IWSLT), 2018", "journal-ref": "Proceedings of the 15th International Workshop on Spoken Language\n  Translation, Bruges, Belgium, October 29-30, 2018", "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we empirically investigate applying word-level weights to\nadapt neural machine translation to e-commerce domains, where small e-commerce\ndatasets and large out-of-domain datasets are available. In order to mine\nin-domain like words in the out-of-domain datasets, we compute word weights by\nusing a domain-specific and a non-domain-specific language model followed by\nsmoothing and binary quantization. The baseline model is trained on mixed\nin-domain and out-of-domain datasets. Experimental results on English to\nChinese e-commerce domain translation show that compared to continuing training\nwithout word weights, it improves MT quality by up to 2.11% BLEU absolute and\n1.59% TER. We have also trained models using fine-tuning on the in-domain data.\nPre-training a model with word weights improves fine-tuning up to 1.24% BLEU\nabsolute and 1.64% TER, respectively.\n", "versions": [{"version": "v1", "created": "Fri, 7 Jun 2019 14:32:17 GMT"}], "update_date": "2019-06-10", "authors_parsed": [["Yan", "Shen", ""], ["Dahlmann", "Leonard", ""], ["Petrushkov", "Pavel", ""], ["Hewavitharana", "Sanjika", ""], ["Khadivi", "Shahram", ""]]}, {"id": "1906.03158", "submitter": "Livio Baldini Soares", "authors": "Livio Baldini Soares, Nicholas FitzGerald, Jeffrey Ling, Tom\n  Kwiatkowski", "title": "Matching the Blanks: Distributional Similarity for Relation Learning", "comments": "To appear at ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  General purpose relation extractors, which can model arbitrary relations, are\na core aspiration in information extraction. Efforts have been made to build\ngeneral purpose extractors that represent relations with their surface forms,\nor which jointly embed surface forms with relations from an existing knowledge\ngraph. However, both of these approaches are limited in their ability to\ngeneralize. In this paper, we build on extensions of Harris' distributional\nhypothesis to relations, as well as recent advances in learning text\nrepresentations (specifically, BERT), to build task agnostic relation\nrepresentations solely from entity-linked text. We show that these\nrepresentations significantly outperform previous work on exemplar based\nrelation extraction (FewRel) even without using any of that task's training\ndata. We also show that models initialized with our task agnostic\nrepresentations, and then tuned on supervised relation extraction datasets,\nsignificantly outperform the previous methods on SemEval 2010 Task 8, KBP37,\nand TACRED.\n", "versions": [{"version": "v1", "created": "Fri, 7 Jun 2019 15:26:50 GMT"}], "update_date": "2019-06-10", "authors_parsed": [["Soares", "Livio Baldini", ""], ["FitzGerald", "Nicholas", ""], ["Ling", "Jeffrey", ""], ["Kwiatkowski", "Tom", ""]]}, {"id": "1906.03173", "submitter": "Ye Yuan", "authors": "Ye Yuan, Kris Kitani", "title": "Ego-Pose Estimation and Forecasting as Real-Time PD Control", "comments": "ICCV 2019; Webpage: https://www.ye-yuan.com/ego-pose; Video:\n  https://youtu.be/968IIDZeWE0", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose the use of a proportional-derivative (PD) control based policy\nlearned via reinforcement learning (RL) to estimate and forecast 3D human pose\nfrom egocentric videos. The method learns directly from unsegmented egocentric\nvideos and motion capture data consisting of various complex human motions\n(e.g., crouching, hopping, bending, and motion transitions). We propose a\nvideo-conditioned recurrent control technique to forecast physically-valid and\nstable future motions of arbitrary length. We also introduce a value function\nbased fail-safe mechanism which enables our method to run as a single pass\nalgorithm over the video data. Experiments with both controlled and in-the-wild\ndata show that our approach outperforms previous art in both quantitative\nmetrics and visual quality of the motions, and is also robust enough to\ntransfer directly to real-world scenarios. Additionally, our time analysis\nshows that the combined use of our pose estimation and forecasting can run at\n30 FPS, making it suitable for real-time applications.\n", "versions": [{"version": "v1", "created": "Fri, 7 Jun 2019 15:39:21 GMT"}, {"version": "v2", "created": "Sun, 4 Aug 2019 21:21:33 GMT"}], "update_date": "2019-08-06", "authors_parsed": [["Yuan", "Ye", ""], ["Kitani", "Kris", ""]]}, {"id": "1906.03223", "submitter": "Jialong Shi", "authors": "Jialong Shi, Jianyong Sun, Qingfu Zhang, Kai Ye", "title": "Homotopic Convex Transformation: A New Landscape Smoothing Method for\n  the Traveling Salesman Problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a novel landscape smoothing method for the symmetric\nTraveling Salesman Problem (TSP). We first define the Homotopic Convex (HC)\ntransformation of a TSP as a convex combination of a well-constructed simple\nTSP and the original TSP. The simple TSP, called the convex-hull TSP, is\nconstructed by transforming a known local or global optimum. We observe that\ncontrolled by the coefficient of the convex combination, with local or global\noptimum, (i) the landscape of the HC transformed TSP is smoothed in terms that\nits number of local optima is reduced compared to the original TSP; (ii) the\nfitness distance correlation of the HC transformed TSP is increased. Further,\nwe observe that the smoothing effect of the HC transformation depends highly on\nthe quality of the used optimum. A high-quality optimum leads to a better\nsmoothing effect than a low-quality optimum. We then propose an iterative\nalgorithmic framework in which the proposed HC transformation is combined\nwithin a heuristic TSP solver. It works as an escaping scheme from local optima\naiming to improve the global search ability of the combined heuristic. Case\nstudies using the 3-Opt and the Lin-Kernighan local search as the heuristic\nsolver show that the resultant algorithms significantly outperform their\ncounterparts and two other smoothing-based TSP heuristic solvers on most of the\ntest instances with up to 20,000 cities.\n", "versions": [{"version": "v1", "created": "Tue, 14 May 2019 12:48:21 GMT"}, {"version": "v2", "created": "Tue, 12 Nov 2019 03:14:24 GMT"}, {"version": "v3", "created": "Sat, 14 Mar 2020 10:08:49 GMT"}], "update_date": "2020-03-17", "authors_parsed": [["Shi", "Jialong", ""], ["Sun", "Jianyong", ""], ["Zhang", "Qingfu", ""], ["Ye", "Kai", ""]]}, {"id": "1906.03242", "submitter": "Laurent Orseau", "authors": "Laurent Orseau, Levi H. S. Lelis, Tor Lattimore", "title": "Zooming Cautiously: Linear-Memory Heuristic Search With Node Expansion\n  Guarantees", "comments": "This paper and another independent IJCAI 2019 submission have been\n  merged into a single paper that subsumes both of them (Helmert et. al.,\n  2019). This paper is placed here only for historical context. Please only\n  cite the subsuming paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce and analyze two parameter-free linear-memory tree search\nalgorithms. Under mild assumptions we prove our algorithms are guaranteed to\nperform only a logarithmic factor more node expansions than A* when the search\nspace is a tree. Previously, the best guarantee for a linear-memory algorithm\nunder similar assumptions was achieved by IDA*, which in the worst case expands\nquadratically more nodes than in its last iteration. Empirical results support\nthe theory and demonstrate the practicality and robustness of our algorithms.\nFurthermore, they are fast and easy to implement.\n", "versions": [{"version": "v1", "created": "Fri, 7 Jun 2019 17:04:16 GMT"}], "update_date": "2019-06-10", "authors_parsed": [["Orseau", "Laurent", ""], ["Lelis", "Levi H. S.", ""], ["Lattimore", "Tor", ""]]}, {"id": "1906.03253", "submitter": "Victor Hansen", "authors": "Victor E Hansen", "title": "Representing and Using Knowledge with the Contextual Evaluation Model", "comments": null, "journal-ref": null, "doi": "10.13140/RG.2.2.34892.05762", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces the Contextual Evaluation Model (CEM), a novel method\nfor knowledge representation and manipulation. The CEM differs from existing\nmodels in that it integrates facts, patterns and sequences into a single\ncontextual framework. V5, an implementation of the model is presented and\ndemonstrated with multiple annotated examples. The paper includes simulations\ndemonstrating how the model reacts to pleasure/pain stimuli. The 'thought' is\ndefined within the model and examples are given converting thoughts to\nlanguage, converting language to thoughts and how 'meaning' arises from\nthoughts. A pattern learning algorithm is described. The algorithm is applied\nto multiple problems ranging from recognizing a voice to the autonomous\nlearning of a simplified natural language.\n", "versions": [{"version": "v1", "created": "Fri, 31 May 2019 19:26:54 GMT"}], "update_date": "2019-06-10", "authors_parsed": [["Hansen", "Victor E", ""]]}, {"id": "1906.03337", "submitter": "Min Shu", "authors": "Min Shu, Wei Zhu", "title": "Extension of Rough Set Based on Positive Transitive Relation", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The application of rough set theory in incomplete information systems is a\nkey problem in practice since missing values almost always occur in knowledge\nacquisition due to the error of data measuring, the limitation of data\ncollection, or the limitation of data comprehension, etc. An incomplete\ninformation system is mainly processed by compressing the indiscernibility\nrelation. The existing rough set extension models based on tolerance or\nsymmetric similarity relations typically discard one relation among the\nreflexive, symmetric and transitive relations, especially the transitive\nrelation. In order to overcome the limitations of the current rough set\nextension models, we define a new relation called the positive transitive\nrelation and then propose a novel rough set extension model built upon which.\nThe new model holds the merit of the existing rough set extension models while\navoids their limitations of discarding transitivity or symmetry. In comparison\nto the existing extension models, the proposed model has a better performance\nin processing the incomplete information systems while substantially reducing\nthe computational complexity, taking into account the relation of tolerance and\nsimilarity of positive transitivity, and supplementing the related theories in\naccordance to the intuitive classification of incomplete information. In\nsummary, the positive transitive relation can improve current theoretical\nanalysis of incomplete information systems and the newly proposed extension\nmodel is more suitable for processing incomplete information systems and has a\nbroad application prospect.\n", "versions": [{"version": "v1", "created": "Fri, 7 Jun 2019 21:28:53 GMT"}, {"version": "v2", "created": "Thu, 13 Jun 2019 05:23:29 GMT"}], "update_date": "2019-06-14", "authors_parsed": [["Shu", "Min", ""], ["Zhu", "Wei", ""]]}, {"id": "1906.03348", "submitter": "Denis Newman-Griffis", "authors": "Denis Newman-Griffis, Ayah Zirikly, Guy Divita, Bart Desmet", "title": "Classifying the reported ability in clinical mobility descriptions", "comments": "Appearing in BioNLP 2019. 10 pages; 6 tables, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Assessing how individuals perform different activities is key information for\nmodeling health states of individuals and populations. Descriptions of activity\nperformance in clinical free text are complex, including syntactic negation and\nsimilarities to textual entailment tasks. We explore a variety of methods for\nthe novel task of classifying four types of assertions about activity\nperformance: Able, Unable, Unclear, and None (no information). We find that\nensembling an SVM trained with lexical features and a CNN achieves 77.9% macro\nF1 score on our task, and yields nearly 80% recall on the rare Unclear and\nUnable samples. Finally, we highlight several challenges in classifying\nperformance assertions, including capturing information about sources of\nassistance, incorporating syntactic structure and negation scope, and handling\nnew modalities at test time. Our findings establish a strong baseline for this\nnovel task, and identify intriguing areas for further research.\n", "versions": [{"version": "v1", "created": "Fri, 7 Jun 2019 22:26:29 GMT"}], "update_date": "2019-06-11", "authors_parsed": [["Newman-Griffis", "Denis", ""], ["Zirikly", "Ayah", ""], ["Divita", "Guy", ""], ["Desmet", "Bart", ""]]}, {"id": "1906.03352", "submitter": "Allan Zhou", "authors": "Allan Zhou, Eric Jang, Daniel Kappler, Alex Herzog, Mohi Khansari,\n  Paul Wohlhart, Yunfei Bai, Mrinal Kalakrishnan, Sergey Levine, Chelsea Finn", "title": "Watch, Try, Learn: Meta-Learning from Demonstrations and Reward", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Imitation learning allows agents to learn complex behaviors from\ndemonstrations. However, learning a complex vision-based task may require an\nimpractical number of demonstrations. Meta-imitation learning is a promising\napproach towards enabling agents to learn a new task from one or a few\ndemonstrations by leveraging experience from learning similar tasks. In the\npresence of task ambiguity or unobserved dynamics, demonstrations alone may not\nprovide enough information; an agent must also try the task to successfully\ninfer a policy. In this work, we propose a method that can learn to learn from\nboth demonstrations and trial-and-error experience with sparse reward feedback.\nIn comparison to meta-imitation, this approach enables the agent to effectively\nand efficiently improve itself autonomously beyond the demonstration data. In\ncomparison to meta-reinforcement learning, we can scale to substantially\nbroader distributions of tasks, as the demonstration reduces the burden of\nexploration. Our experiments show that our method significantly outperforms\nprior approaches on a set of challenging, vision-based control tasks.\n", "versions": [{"version": "v1", "created": "Fri, 7 Jun 2019 22:46:35 GMT"}, {"version": "v2", "created": "Mon, 5 Aug 2019 16:21:21 GMT"}, {"version": "v3", "created": "Tue, 28 Jan 2020 03:06:23 GMT"}, {"version": "v4", "created": "Thu, 30 Jan 2020 23:13:01 GMT"}], "update_date": "2020-02-03", "authors_parsed": [["Zhou", "Allan", ""], ["Jang", "Eric", ""], ["Kappler", "Daniel", ""], ["Herzog", "Alex", ""], ["Khansari", "Mohi", ""], ["Wohlhart", "Paul", ""], ["Bai", "Yunfei", ""], ["Kalakrishnan", "Mrinal", ""], ["Levine", "Sergey", ""], ["Finn", "Chelsea", ""]]}, {"id": "1906.03365", "submitter": "Omar Vidal Pino", "authors": "Omar Vidal Pino, Erickson Rangel Nascimento and Mario Fernando\n  Montenegro Campos", "title": "Global Semantic Description of Objects based on Prototype Theory", "comments": "Content: 24 pages (22 + 2 reference) with 15 Figures and 3 Tables. In\n  the future, a new version will be updated with other experiments and results\n  (and a journal reference if applicable)", "journal-ref": null, "doi": "10.1016/j.imavis.2021.104249", "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we introduce a novel semantic description approach inspired on\nPrototype Theory foundations. We propose a Computational Prototype Model (CPM)\nthat encodes and stores the central semantic meaning of objects category: the\nsemantic prototype. Also, we introduce a Prototype-based Description Model that\nencodes the semantic meaning of an object while describing its features using\nour CPM model. Our description method uses semantic prototypes computed by\nCNN-classifications models to create discriminative signatures that describe an\nobject highlighting its most distinctive features within the category. Our\nexperiments show that: i) our CPM model (semantic prototype + distance metric)\nis able to describe the internal semantic structure of objects categories; ii)\nour semantic distance metric can be understood as the object visual typicality\nscore within a category; iii) our descriptor encoding is semantically\ninterpretable and significantly outperforms other image global encodings in\nclustering and classification tasks.\n", "versions": [{"version": "v1", "created": "Sat, 8 Jun 2019 01:02:02 GMT"}, {"version": "v2", "created": "Sat, 29 Feb 2020 03:23:20 GMT"}, {"version": "v3", "created": "Sun, 2 Aug 2020 20:32:38 GMT"}, {"version": "v4", "created": "Sun, 20 Jun 2021 01:22:02 GMT"}], "update_date": "2021-07-08", "authors_parsed": [["Pino", "Omar Vidal", ""], ["Nascimento", "Erickson Rangel", ""], ["Campos", "Mario Fernando Montenegro", ""]]}, {"id": "1906.03393", "submitter": "Tengyang Xie", "authors": "Tengyang Xie, Yifei Ma, Yu-Xiang Wang", "title": "Towards Optimal Off-Policy Evaluation for Reinforcement Learning with\n  Marginalized Importance Sampling", "comments": "Published at the Neural Information Processing Systems (NeurIPS) 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by the many real-world applications of reinforcement learning (RL)\nthat require safe-policy iterations, we consider the problem of off-policy\nevaluation (OPE) -- the problem of evaluating a new policy using the historical\ndata obtained by different behavior policies -- under the model of\nnonstationary episodic Markov Decision Processes (MDP) with a long horizon and\na large action space. Existing importance sampling (IS) methods often suffer\nfrom large variance that depends exponentially on the RL horizon $H$. To solve\nthis problem, we consider a marginalized importance sampling (MIS) estimator\nthat recursively estimates the state marginal distribution for the target\npolicy at every step. MIS achieves a mean-squared error of $$ \\frac{1}{n}\n\\sum\\nolimits_{t=1}^H\\mathbb{E}_{\\mu}\\left[\\frac{d_t^\\pi(s_t)^2}{d_t^\\mu(s_t)^2}\n\\mathrm{Var}_{\\mu}\\left[\\frac{\\pi_t(a_t|s_t)}{\\mu_t(a_t|s_t)}\\big(\nV_{t+1}^\\pi(s_{t+1}) + r_t\\big) \\middle| s_t\\right]\\right] +\n\\tilde{O}(n^{-1.5}) $$ where $\\mu$ and $\\pi$ are the logging and target\npolicies, $d_t^{\\mu}(s_t)$ and $d_t^{\\pi}(s_t)$ are the marginal distribution\nof the state at $t$th step, $H$ is the horizon, $n$ is the sample size and\n$V_{t+1}^\\pi$ is the value function of the MDP under $\\pi$. The result matches\nthe Cramer-Rao lower bound in \\citet{jiang2016doubly} up to a multiplicative\nfactor of $H$. To the best of our knowledge, this is the first OPE estimation\nerror bound with a polynomial dependence on $H$. Besides theory, we show\nempirical superiority of our method in time-varying, partially observable, and\nlong-horizon RL environments.\n", "versions": [{"version": "v1", "created": "Sat, 8 Jun 2019 05:15:34 GMT"}, {"version": "v2", "created": "Sun, 3 Nov 2019 01:35:04 GMT"}, {"version": "v3", "created": "Tue, 31 Mar 2020 03:31:06 GMT"}, {"version": "v4", "created": "Wed, 1 Apr 2020 02:16:55 GMT"}], "update_date": "2020-04-02", "authors_parsed": [["Xie", "Tengyang", ""], ["Ma", "Yifei", ""], ["Wang", "Yu-Xiang", ""]]}, {"id": "1906.03394", "submitter": "Jiyao Li", "authors": "Jiyao Li, Vicki H. Allan", "title": "A Ride-Matching Strategy For Large Scale Dynamic Ridesharing Services\n  Based on Polar Coordinates", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study a challenging problem of how to pool multiple\nride-share trip requests in real time under an uncertain environment. The goals\nare better performance metrics of efficiency and acceptable satisfaction of\nriders. To solve the problem effectively, an objective function that\ncompromises the benefits and losses of dynamic ridesharing service is proposed.\nThe Polar Coordinates based Ride-Matching strategy (PCRM) that can adapt to the\nsatisfaction of riders on board is also addressed. In the experiment, large\nscale data sets from New York City (NYC) are applied. We do a case study to\nidentify the best set of parameters of the dynamic ridesharing service with a\ntraining set of 135,252 trip requests. In addition, we also use a testing set\ncontaining 427,799 trip requests and two state-of-the-art approaches as\nbaselines to estimate the effectiveness of our method. The experimental results\nshow that on average 38% of traveling distance can be saved, nearly 100% of\npassengers can be served and each rider only spends an additional 3.8 minutes\nin ridesharing trips compared to single rider service.\n", "versions": [{"version": "v1", "created": "Sat, 8 Jun 2019 05:50:25 GMT"}], "update_date": "2019-06-11", "authors_parsed": [["Li", "Jiyao", ""], ["Allan", "Vicki H.", ""]]}, {"id": "1906.03466", "submitter": "Rajagopal A", "authors": "Rajagopal. A, Nirmala. V", "title": "Strategies to architect AI Safety: Defense to guard AI from Adversaries", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CR cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The impact of designing for security of AI is critical for humanity in the AI\nera. With humans increasingly becoming dependent upon AI, there is a need for\nneural networks that work reliably, inspite of Adversarial attacks. The vision\nfor Safe and secure AI for popular use is achievable. To achieve safety of AI,\nthis paper explores strategies and a novel deep learning architecture. To guard\nAI from adversaries, paper explores combination of 3 strategies:\n  1. Introduce randomness at inference time to hide the representation learning\nfrom adversaries.\n  2. Detect presence of adversaries by analyzing the sequence of inferences.\n  3. Exploit visual similarity.\n  To realize these strategies, this paper designs a novel architecture, Dynamic\nNeural Defense, DND. This defense has 3 deep learning architectural features:\n  1. By hiding the way a neural network learns from exploratory attacks using a\nrandom computation graph, DND evades attack.\n  2. By analyzing input sequence to cloud AI inference engine with LSTM, DND\ndetects attack sequence.\n  3. By inferring with visual similar inputs generated by VAE, any AI defended\nby DND approach does not succumb to hackers.\n  Thus, a roadmap to develop reliable, safe and secure AI is presented.\n", "versions": [{"version": "v1", "created": "Sat, 8 Jun 2019 14:34:47 GMT"}], "update_date": "2019-06-11", "authors_parsed": [["A", "Rajagopal.", ""], ["V", "Nirmala.", ""]]}, {"id": "1906.03506", "submitter": "Hao Wang", "authors": "Hao Wang, Bing Liu, Shuai Wang, Nianzu Ma, Yan Yang", "title": "Forward and Backward Knowledge Transfer for Sentiment Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies the problem of learning a sequence of sentiment\nclassification tasks. The learned knowledge from each task is retained and used\nto help future or subsequent task learning. This learning paradigm is called\nLifelong Learning (LL). However, existing LL methods either only transfer\nknowledge forward to help future learning and do not go back to improve the\nmodel of a previous task or require the training data of the previous task to\nretrain its model to exploit backward/reverse knowledge transfer. This paper\nstudies reverse knowledge transfer of LL in the context of naive Bayesian (NB)\nclassification. It aims to improve the model of a previous task by leveraging\nfuture knowledge without retraining using its training data. This is done by\nexploiting a key characteristic of the generative model of NB. That is, it is\npossible to improve the NB classifier for a task by improving its model\nparameters directly by using the retained knowledge from other tasks.\nExperimental results show that the proposed method markedly outperforms\nexisting LL baselines.\n", "versions": [{"version": "v1", "created": "Sat, 8 Jun 2019 19:18:18 GMT"}], "update_date": "2019-06-11", "authors_parsed": [["Wang", "Hao", ""], ["Liu", "Bing", ""], ["Wang", "Shuai", ""], ["Ma", "Nianzu", ""], ["Yang", "Yan", ""]]}, {"id": "1906.03523", "submitter": "Ali Payani", "authors": "Ali Payani and Faramarz Fekri", "title": "Inductive Logic Programming via Differentiable Deep Neural Logic\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  We propose a novel paradigm for solving Inductive Logic Programming (ILP)\nproblems via deep recurrent neural networks. This proposed ILP solver is\ndesigned based on differentiable implementation of the deduction via forward\nchaining. In contrast to the majority of past methods, instead of searching\nthrough the space of possible first-order logic rules by using some restrictive\nrule templates, we directly learn the symbolic logical predicate rules by\nintroducing a novel differentiable Neural Logic (dNL) network. The proposed dNL\nnetwork is able to learn and represent Boolean functions efficiently and in an\nexplicit manner. We show that the proposed dNL-ILP solver supports desirable\nfeatures such as recursion and predicate invention. Further, we investigate the\nperformance of the proposed ILP solver in classification tasks involving\nbenchmark relational datasets. In particular, we show that our proposed method\noutperforms the state of the art ILP solvers in classification tasks for\nMutagenesis, Cora and IMDB datasets.\n", "versions": [{"version": "v1", "created": "Sat, 8 Jun 2019 21:23:21 GMT"}], "update_date": "2019-06-11", "authors_parsed": [["Payani", "Ali", ""], ["Fekri", "Faramarz", ""]]}, {"id": "1906.03533", "submitter": "Patrick Hall", "authors": "Patrick Hall and Navdeep Gill and Nicholas Schmidt", "title": "Proposed Guidelines for the Responsible Use of Explainable Machine\n  Learning", "comments": "Errata and updates available here:\n  https://github.com/jphall663/responsible_xai", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Explainable machine learning (ML) enables human learning from ML, human\nappeal of automated model decisions, regulatory compliance, and security audits\nof ML models. Explainable ML (i.e. explainable artificial intelligence or XAI)\nhas been implemented in numerous open source and commercial packages and\nexplainable ML is also an important, mandatory, or embedded aspect of\ncommercial predictive modeling in industries like financial services. However,\nlike many technologies, explainable ML can be misused, particularly as a faulty\nsafeguard for harmful black-boxes, e.g. fairwashing or scaffolding, and for\nother malevolent purposes like stealing models and sensitive training data. To\npromote best-practice discussions for this already in-flight technology, this\nshort text presents internal definitions and a few examples before covering the\nproposed guidelines. This text concludes with a seemingly natural argument for\nthe use of interpretable models and explanatory, debugging, and disparate\nimpact testing methods in life- or mission-critical ML systems.\n", "versions": [{"version": "v1", "created": "Sat, 8 Jun 2019 22:12:11 GMT"}, {"version": "v2", "created": "Thu, 31 Oct 2019 19:11:26 GMT"}, {"version": "v3", "created": "Fri, 29 Nov 2019 22:30:16 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Hall", "Patrick", ""], ["Gill", "Navdeep", ""], ["Schmidt", "Nicholas", ""]]}, {"id": "1906.03574", "submitter": "Disha Shrivastava", "authors": "Disha Shrivastava, Eeshan Gunesh Dhekane, Riashat Islam", "title": "Transfer Learning by Modeling a Distribution over Policies", "comments": "Accepted at the ICML 2019 workshop on Multi-Task and Lifelong\n  Reinforcement Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Exploration and adaptation to new tasks in a transfer learning setup is a\ncentral challenge in reinforcement learning. In this work, we build on the idea\nof modeling a distribution over policies in a Bayesian deep reinforcement\nlearning setup to propose a transfer strategy. Recent works have shown to\ninduce diversity in the learned policies by maximizing the entropy of a\ndistribution of policies (Bachman et al., 2018; Garnelo et al., 2018) and thus,\nwe postulate that our proposed approach leads to faster exploration resulting\nin improved transfer learning. We support our hypothesis by demonstrating\nfavorable experimental results on a variety of settings on fully-observable\nGridWorld and partially observable MiniGrid (Chevalier-Boisvert et al., 2018)\nenvironments.\n", "versions": [{"version": "v1", "created": "Sun, 9 Jun 2019 06:00:50 GMT"}], "update_date": "2019-06-11", "authors_parsed": [["Shrivastava", "Disha", ""], ["Dhekane", "Eeshan Gunesh", ""], ["Islam", "Riashat", ""]]}, {"id": "1906.03593", "submitter": "Xin Yang", "authors": "Zhao Song, Xin Yang", "title": "Quadratic Suffices for Over-parametrization via Matrix Chernoff Bound", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We improve the over-parametrization size over two beautiful results [Li and\nLiang' 2018] and [Du, Zhai, Poczos and Singh' 2019] in deep learning theory.\n", "versions": [{"version": "v1", "created": "Sun, 9 Jun 2019 08:36:35 GMT"}, {"version": "v2", "created": "Tue, 18 Feb 2020 11:17:58 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Song", "Zhao", ""], ["Yang", "Xin", ""]]}, {"id": "1906.03595", "submitter": "Rajagopal A", "authors": "Rajagopal. A, Nirmala. V", "title": "Federated AI lets a team imagine together: Federated Learning of GANs", "comments": "Keywords. Artificial Intelligence, Distributed Machine Learning,\n  Generative Deep Learning, Generative Adversarial Networks, Federated\n  learning, Creative AI, AI based Collaboration, AI planning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.DC cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Envisioning a new imaginative idea together is a popular human need.\nImagining together as a team can often lead to breakthrough ideas, but the\ncollaboration effort can also be challenging, especially when the team members\nare separated by time and space. What if there is a AI that can assist the team\nto collaboratively envision new ideas?. Is it possible to develop a working\nmodel of such an AI? This paper aims to design such an intelligence. This paper\nproposes a approach to design a creative and collaborative intelligence by\nemploying a form of distributed machine learning approach called Federated\nLearning along with fusion on Generative Adversarial Networks, GAN. This\ncollaborative creative AI presents a new paradigm in AI, one that lets a team\nof two or more to come together to imagine and envision ideas that synergies\nwell with interests of all members of the team. In short, this paper explores\nthe design of a novel type of AI paradigm, called Federated AI Imagination, one\nthat lets geographically distributed teams to collaboratively imagine.\n", "versions": [{"version": "v1", "created": "Sun, 9 Jun 2019 08:44:23 GMT"}], "update_date": "2019-06-11", "authors_parsed": [["A", "Rajagopal.", ""], ["V", "Nirmala.", ""]]}, {"id": "1906.03609", "submitter": "Tao Wang", "authors": "Tao Wang and Li Yuan and Xiaopeng Zhang and Jiashi Feng", "title": "Distilling Object Detectors with Fine-grained Feature Imitation", "comments": "accepted at CVPR2019\n  code:https://github.com/twangnh/Distilling-Object-Detectors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  State-of-the-art CNN based recognition models are often computationally\nprohibitive to deploy on low-end devices. A promising high level approach\ntackling this limitation is knowledge distillation, which let small student\nmodel mimic cumbersome teacher model's output to get improved generalization.\nHowever, related methods mainly focus on simple task of classification while do\nnot consider complex tasks like object detection. We show applying the vanilla\nknowledge distillation to detection model gets minor gain. To address the\nchallenge of distilling knowledge in detection model, we propose a fine-grained\nfeature imitation method exploiting the cross-location discrepancy of feature\nresponse. Our intuition is that detectors care more about local near object\nregions. Thus the discrepancy of feature response on the near object anchor\nlocations reveals important information of how teacher model tends to\ngeneralize. We design a novel mechanism to estimate those locations and let\nstudent model imitate the teacher on them to get enhanced performance. We first\nvalidate the idea on a developed lightweight toy detector which carries\nsimplest notion of current state-of-the-art anchor based detection models on\nchallenging KITTI dataset, our method generates up to 15% boost of mAP for the\nstudent model compared to the non-imitated counterpart. We then extensively\nevaluate the method with Faster R-CNN model under various scenarios with common\nobject detection benchmark of Pascal VOC and COCO, imitation alleviates up to\n74% performance drop of student model compared to teacher. Codes released at\nhttps://github.com/twangnh/Distilling-Object-Detectors\n", "versions": [{"version": "v1", "created": "Sun, 9 Jun 2019 09:57:26 GMT"}], "update_date": "2019-10-31", "authors_parsed": [["Wang", "Tao", ""], ["Yuan", "Li", ""], ["Zhang", "Xiaopeng", ""], ["Feng", "Jiashi", ""]]}, {"id": "1906.03672", "submitter": "Daniel Khashabi Mr.", "authors": "Daniel Khashabi, Tushar Khot, Ashish Sabharwal, Dan Roth", "title": "Question Answering as Global Reasoning over Semantic Abstractions", "comments": "Appeared in AAAI'18", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel method for exploiting the semantic structure of text to\nanswer multiple-choice questions. The approach is especially suitable for\ndomains that require reasoning over a diverse set of linguistic constructs but\nhave limited training data. To address these challenges, we present the first\nsystem, to the best of our knowledge, that reasons over a wide range of\nsemantic abstractions of the text, which are derived using off-the-shelf,\ngeneral-purpose, pre-trained natural language modules such as semantic role\nlabelers, coreference resolvers, and dependency parsers. Representing multiple\nabstractions as a family of graphs, we translate question answering (QA) into a\nsearch for an optimal subgraph that satisfies certain global and local\nproperties. This formulation generalizes several prior structured QA systems.\nOur system, SEMANTICILP, demonstrates strong performance on two domains\nsimultaneously. In particular, on a collection of challenging science QA\ndatasets, it outperforms various state-of-the-art approaches, including neural\nmodels, broad coverage information retrieval, and specialized techniques using\nstructured knowledge bases, by 2%-6%.\n", "versions": [{"version": "v1", "created": "Sun, 9 Jun 2019 16:56:31 GMT"}], "update_date": "2019-06-11", "authors_parsed": [["Khashabi", "Daniel", ""], ["Khot", "Tushar", ""], ["Sabharwal", "Ashish", ""], ["Roth", "Dan", ""]]}, {"id": "1906.03697", "submitter": "Keunwoo Choi Mr", "authors": "Keunwoo Choi and Kyunghyun Cho", "title": "Deep Unsupervised Drum Transcription", "comments": "ISMIR 2019 camera-ready", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.AI eess.AS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We introduce DrummerNet, a drum transcription system that is trained in an\nunsupervised manner. DrummerNet does not require any ground-truth transcription\nand, with the data-scalability of deep neural networks, learns from a large\nunlabeled dataset. In DrummerNet, the target drum signal is first passed to a\n(trainable) transcriber, then reconstructed in a (fixed) synthesizer according\nto the transcription estimate. By training the system to minimize the distance\nbetween the input and the output audio signals, the transcriber learns to\ntranscribe without ground truth transcription. Our experiment shows that\nDrummerNet performs favorably compared to many other recent drum transcription\nsystems, both supervised and unsupervised.\n", "versions": [{"version": "v1", "created": "Sun, 9 Jun 2019 19:35:55 GMT"}, {"version": "v2", "created": "Fri, 28 Jun 2019 22:59:34 GMT"}], "update_date": "2020-10-26", "authors_parsed": [["Choi", "Keunwoo", ""], ["Cho", "Kyunghyun", ""]]}, {"id": "1906.03710", "submitter": "John Lanier B", "authors": "John B. Lanier, Stephen McAleer, Pierre Baldi", "title": "Curiosity-Driven Multi-Criteria Hindsight Experience Replay", "comments": "14 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Dealing with sparse rewards is a longstanding challenge in reinforcement\nlearning. The recent use of hindsight methods have achieved success on a\nvariety of sparse-reward tasks, but they fail on complex tasks such as stacking\nmultiple blocks with a robot arm in simulation. Curiosity-driven exploration\nusing the prediction error of a learned dynamics model as an intrinsic reward\nhas been shown to be effective for exploring a number of sparse-reward\nenvironments. We present a method that combines hindsight with curiosity-driven\nexploration and curriculum learning in order to solve the challenging\nsparse-reward block stacking task. We are the first to stack more than two\nblocks using only sparse reward without human demonstrations.\n", "versions": [{"version": "v1", "created": "Sun, 9 Jun 2019 21:11:08 GMT"}], "update_date": "2019-06-11", "authors_parsed": [["Lanier", "John B.", ""], ["McAleer", "Stephen", ""], ["Baldi", "Pierre", ""]]}, {"id": "1906.03744", "submitter": "Mohammad Rostami", "authors": "Mohammad Rostami, Soheil Kolouri, James McClelland, Praveen Pilly", "title": "Generative Continual Concept Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  After learning a concept, humans are also able to continually generalize\ntheir learned concepts to new domains by observing only a few labeled instances\nwithout any interference with the past learned knowledge. In contrast, learning\nconcepts efficiently in a continual learning setting remains an open challenge\nfor current Artificial Intelligence algorithms as persistent model retraining\nis necessary. Inspired by the Parallel Distributed Processing learning and the\nComplementary Learning Systems theories, we develop a computational model that\nis able to expand its previously learned concepts efficiently to new domains\nusing a few labeled samples. We couple the new form of a concept to its past\nlearned forms in an embedding space for effective continual learning. Doing so,\na generative distribution is learned such that it is shared across the tasks in\nthe embedding space and models the abstract concepts. This procedure enables\nthe model to generate pseudo-data points to replay the past experience to\ntackle catastrophic forgetting.\n", "versions": [{"version": "v1", "created": "Mon, 10 Jun 2019 00:30:06 GMT"}, {"version": "v2", "created": "Sat, 7 Sep 2019 05:06:43 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["Rostami", "Mohammad", ""], ["Kolouri", "Soheil", ""], ["McClelland", "James", ""], ["Pilly", "Praveen", ""]]}, {"id": "1906.03843", "submitter": "YooJung Choi", "authors": "YooJung Choi, Golnoosh Farnadi, Behrouz Babaki, Guy Van den Broeck", "title": "Learning Fair Naive Bayes Classifiers by Discovering and Eliminating\n  Discrimination Patterns", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As machine learning is increasingly used to make real-world decisions, recent\nresearch efforts aim to define and ensure fairness in algorithmic decision\nmaking. Existing methods often assume a fixed set of observable features to\ndefine individuals, but lack a discussion of certain features not being\nobserved at test time. In this paper, we study fairness of naive Bayes\nclassifiers, which allow partial observations. In particular, we introduce the\nnotion of a discrimination pattern, which refers to an individual receiving\ndifferent classifications depending on whether some sensitive attributes were\nobserved. Then a model is considered fair if it has no such pattern. We propose\nan algorithm to discover and mine for discrimination patterns in a naive Bayes\nclassifier, and show how to learn maximum likelihood parameters subject to\nthese fairness constraints. Our approach iteratively discovers and eliminates\ndiscrimination patterns until a fair model is learned. An empirical evaluation\non three real-world datasets demonstrates that we can remove exponentially many\ndiscrimination patterns by only adding a small fraction of them as constraints.\n", "versions": [{"version": "v1", "created": "Mon, 10 Jun 2019 08:48:19 GMT"}, {"version": "v2", "created": "Thu, 7 May 2020 22:46:36 GMT"}], "update_date": "2020-05-11", "authors_parsed": [["Choi", "YooJung", ""], ["Farnadi", "Golnoosh", ""], ["Babaki", "Behrouz", ""], ["Broeck", "Guy Van den", ""]]}, {"id": "1906.03853", "submitter": "Jiajun Wu", "authors": "Zhenjia Xu, Jiajun Wu, Andy Zeng, Joshua B. Tenenbaum, and Shuran Song", "title": "DensePhysNet: Learning Dense Physical Object Representations via\n  Multi-step Dynamic Interactions", "comments": "RSS 2019. Project page: http://zhenjiaxu.com/DensePhysNet", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of learning physical object representations for robot\nmanipulation. Understanding object physics is critical for successful object\nmanipulation, but also challenging because physical object properties can\nrarely be inferred from the object's static appearance. In this paper, we\npropose DensePhysNet, a system that actively executes a sequence of dynamic\ninteractions (e.g., sliding and colliding), and uses a deep predictive model\nover its visual observations to learn dense, pixel-wise representations that\nreflect the physical properties of observed objects. Our experiments in both\nsimulation and real settings demonstrate that the learned representations carry\nrich physical information, and can directly be used to decode physical object\nproperties such as friction and mass. The use of dense representation enables\nDensePhysNet to generalize well to novel scenes with more objects than in\ntraining. With knowledge of object physics, the learned representation also\nleads to more accurate and efficient manipulation in downstream tasks than the\nstate-of-the-art.\n", "versions": [{"version": "v1", "created": "Mon, 10 Jun 2019 09:13:02 GMT"}, {"version": "v2", "created": "Tue, 11 Jun 2019 18:10:45 GMT"}], "update_date": "2019-06-13", "authors_parsed": [["Xu", "Zhenjia", ""], ["Wu", "Jiajun", ""], ["Zeng", "Andy", ""], ["Tenenbaum", "Joshua B.", ""], ["Song", "Shuran", ""]]}, {"id": "1906.03897", "submitter": "Leshem Choshen", "authors": "Yoav Kantor and Yoav Katz and Leshem Choshen and Edo Cohen-Karlik and\n  Naftali Liberman and Assaf Toledo and Amir Menczel and Noam Slonim", "title": "Learning to combine Grammatical Error Corrections", "comments": "BEA 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The field of Grammatical Error Correction (GEC) has produced various systems\nto deal with focused phenomena or general text editing. We propose an automatic\nway to combine black-box systems. Our method automatically detects the strength\nof a system or the combination of several systems per error type, improving\nprecision and recall while optimizing $F$ score directly. We show consistent\nimprovement over the best standalone system in all the configurations tested.\nThis approach also outperforms average ensembling of different RNN models with\nrandom initializations.\n  In addition, we analyze the use of BERT for GEC - reporting promising results\non this end. We also present a spellchecker created for this task which\noutperforms standard spellcheckers tested on the task of spellchecking.\n  This paper describes a system submission to Building Educational Applications\n2019 Shared Task: Grammatical Error Correction.\n  Combining the output of top BEA 2019 shared task systems using our approach,\ncurrently holds the highest reported score in the open phase of the BEA 2019\nshared task, improving F0.5 by 3.7 points over the best result reported.\n", "versions": [{"version": "v1", "created": "Mon, 10 Jun 2019 10:57:47 GMT"}], "update_date": "2019-06-11", "authors_parsed": [["Kantor", "Yoav", ""], ["Katz", "Yoav", ""], ["Choshen", "Leshem", ""], ["Cohen-Karlik", "Edo", ""], ["Liberman", "Naftali", ""], ["Toledo", "Assaf", ""], ["Menczel", "Amir", ""], ["Slonim", "Noam", ""]]}, {"id": "1906.03926", "submitter": "Nantas Nardelli", "authors": "Jelena Luketina, Nantas Nardelli, Gregory Farquhar, Jakob Foerster,\n  Jacob Andreas, Edward Grefenstette, Shimon Whiteson, Tim Rockt\\\"aschel", "title": "A Survey of Reinforcement Learning Informed by Natural Language", "comments": "Published at IJCAI'19", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To be successful in real-world tasks, Reinforcement Learning (RL) needs to\nexploit the compositional, relational, and hierarchical structure of the world,\nand learn to transfer it to the task at hand. Recent advances in representation\nlearning for language make it possible to build models that acquire world\nknowledge from text corpora and integrate this knowledge into downstream\ndecision making problems. We thus argue that the time is right to investigate a\ntight integration of natural language understanding into RL in particular. We\nsurvey the state of the field, including work on instruction following, text\ngames, and learning from textual domain knowledge. Finally, we call for the\ndevelopment of new environments as well as further investigation into the\npotential uses of recent Natural Language Processing (NLP) techniques for such\ntasks.\n", "versions": [{"version": "v1", "created": "Mon, 10 Jun 2019 12:17:45 GMT"}], "update_date": "2019-06-11", "authors_parsed": [["Luketina", "Jelena", ""], ["Nardelli", "Nantas", ""], ["Farquhar", "Gregory", ""], ["Foerster", "Jakob", ""], ["Andreas", "Jacob", ""], ["Grefenstette", "Edward", ""], ["Whiteson", "Shimon", ""], ["Rockt\u00e4schel", "Tim", ""]]}, {"id": "1906.03950", "submitter": "Seonguk Seo", "authors": "Woong-Gi Chang, Tackgeun You, Seonguk Seo, Suha Kwak, Bohyung Han", "title": "Domain-Specific Batch Normalization for Unsupervised Domain Adaptation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel unsupervised domain adaptation framework based on\ndomain-specific batch normalization in deep neural networks. We aim to adapt to\nboth domains by specializing batch normalization layers in convolutional neural\nnetworks while allowing them to share all other model parameters, which is\nrealized by a two-stage algorithm. In the first stage, we estimate\npseudo-labels for the examples in the target domain using an external\nunsupervised domain adaptation algorithm---for example, MSTN or\nCPUA---integrating the proposed domain-specific batch normalization. The second\nstage learns the final models using a multi-task classification loss for the\nsource and target domains. Note that the two domains have separate batch\nnormalization layers in both stages. Our framework can be easily incorporated\ninto the domain adaptation techniques based on deep neural networks with batch\nnormalization layers. We also present that our approach can be extended to the\nproblem with multiple source domains. The proposed algorithm is evaluated on\nmultiple benchmark datasets and achieves the state-of-the-art accuracy in the\nstandard setting and the multi-source domain adaption scenario.\n", "versions": [{"version": "v1", "created": "Mon, 27 May 2019 10:46:50 GMT"}], "update_date": "2019-06-11", "authors_parsed": [["Chang", "Woong-Gi", ""], ["You", "Tackgeun", ""], ["Seo", "Seonguk", ""], ["Kwak", "Suha", ""], ["Han", "Bohyung", ""]]}, {"id": "1906.03955", "submitter": "Nir Lipovetzky", "authors": "Alfonso E. Gerevini, Nir Lipovetzky, Francesco Percassi, Alessandro\n  Saetti, Ivan Serina", "title": "Best-First Width Search for Multi Agent Privacy-preserving Planning", "comments": "Accepted in ICAPS-19", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In multi-agent planning, preserving the agents' privacy has become an\nincreasingly popular research topic. For preserving the agents' privacy, agents\njointly compute a plan that achieves mutual goals by keeping certain\ninformation private to the individual agents. Unfortunately, this can severely\nrestrict the accuracy of the heuristic functions used while searching for\nsolutions. It has been recently shown that, for centralized planning, the\nperformance of goal oriented search can be improved by combining goal oriented\nsearch and width-based search. The combination of these techniques has been\ncalled best-first width search. In this paper, we investigate the usage of\nbest-first width search in the context of (decentralised) multi-agent\nprivacy-preserving planning, addressing the challenges related to the agents'\nprivacy and performance. In particular, we show that best-first width search is\na very effective approach over several benchmark domains, even when the search\nis driven by heuristics that roughly estimate the distance from goal states,\ncomputed without using the private information of other agents. An experimental\nstudy analyses the effectiveness of our techniques and compares them with the\nstate-of-the-art.\n", "versions": [{"version": "v1", "created": "Mon, 10 Jun 2019 13:01:07 GMT"}], "update_date": "2019-06-11", "authors_parsed": [["Gerevini", "Alfonso E.", ""], ["Lipovetzky", "Nir", ""], ["Percassi", "Francesco", ""], ["Saetti", "Alessandro", ""], ["Serina", "Ivan", ""]]}, {"id": "1906.03963", "submitter": "Moin Hussain Moti", "authors": "Moin Hussain Moti, Dimitris Chatzopoulos, Pan Hui, Sujit Gujar", "title": "FaRM: Fair Reward Mechanism for Information Aggregation in Spontaneous\n  Localized Settings (Extended Version)", "comments": "13 pages, IJCAI Main Track Extended version of \"FaRM: Fair Reward\n  Mechanism for Information Aggregation in Spontaneous Localized Settings\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although peer prediction markets are widely used in crowdsourcing to\naggregate information from agents, they often fail to reward the participating\nagents equitably. Honest agents can be wrongly penalized if randomly paired\nwith dishonest ones. In this work, we introduce \\emph{selective} and\n\\emph{cumulative} fairness. We characterize a mechanism as fair if it satisfies\nboth notions and present FaRM, a representative mechanism we designed. FaRM is\na Nash incentive mechanism that focuses on information aggregation for\nspontaneous local activities which are accessible to a limited number of agents\nwithout assuming any prior knowledge of the event. All the agents in the\nvicinity observe the same information. FaRM uses \\textit{(i)} a \\emph{report\nstrength score} to remove the risk of random pairing with dishonest reporters,\n\\textit{(ii)} a \\emph{consistency score} to measure an agent's history of\naccurate reports and distinguish valuable reports, \\textit{(iii)} a\n\\emph{reliability score} to estimate the probability of an agent to collude\nwith nearby agents and prevents agents from getting swayed, and \\textit{(iv)} a\n\\emph{location robustness score} to filter agents who try to participate\nwithout being present in the considered setting. Together, report strength,\nconsistency, and reliability represent a fair reward given to agents based on\ntheir reports.\n", "versions": [{"version": "v1", "created": "Mon, 10 Jun 2019 13:21:10 GMT"}], "update_date": "2019-06-11", "authors_parsed": [["Moti", "Moin Hussain", ""], ["Chatzopoulos", "Dimitris", ""], ["Hui", "Pan", ""], ["Gujar", "Sujit", ""]]}, {"id": "1906.03967", "submitter": "Adrien Laversanne-Finot", "authors": "Adrien Laversanne-Finot and Alexandre P\\'er\\'e and Pierre-Yves Oudeyer", "title": "Autonomous Goal Exploration using Learned Goal Spaces for Visuomotor\n  Skill Acquisition in Robots", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The automatic and efficient discovery of skills, without supervision, for\nlong-living autonomous agents, remains a challenge of Artificial Intelligence.\nIntrinsically Motivated Goal Exploration Processes give learning agents a\nhuman-inspired mechanism to sequentially select goals to achieve. This approach\ngives a new perspective on the lifelong learning problem, with promising\nresults on both simulated and real-world experiments. Until recently, those\nalgorithms were restricted to domains with experimenter-knowledge, since the\nGoal Space used by the agents was built on engineered feature extractors. The\nrecent advances of deep representation learning, enables new ways of designing\nthose feature extractors, using directly the agent experience. Recent work has\nshown the potential of those methods on simple yet challenging simulated\ndomains. In this paper, we present recent results showing the applicability of\nthose principles on a real-world robotic setup, where a 6-joint robotic arm\nlearns to manipulate a ball inside an arena, by choosing goals in a space\nlearned from its past experience.\n", "versions": [{"version": "v1", "created": "Mon, 10 Jun 2019 13:31:12 GMT"}], "update_date": "2019-06-11", "authors_parsed": [["Laversanne-Finot", "Adrien", ""], ["P\u00e9r\u00e9", "Alexandre", ""], ["Oudeyer", "Pierre-Yves", ""]]}, {"id": "1906.03992", "submitter": "Devon Sigurdson", "authors": "Devon Sigurdson, Vadim Bulitko, Sven Koenig, Carlos Hernandez, William\n  Yeoh", "title": "Automatic Algorithm Selection In Multi-agent Pathfinding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In a multi-agent pathfinding (MAPF) problem, agents need to navigate from\ntheir start to their goal locations without colliding into each other. There\nare various MAPF algorithms, including Windowed Hierarchical Cooperative A*,\nFlow Annotated Replanning, and Bounded Multi-Agent A*. It is often the case\nthat there is no a single algorithm that dominates all MAPF instances.\nTherefore, in this paper, we investigate the use of deep learning to\nautomatically select the best MAPF algorithm from a portfolio of algorithms for\na given MAPF problem instance. Empirical results show that our automatic\nalgorithm selection approach, which uses an off-the-shelf convolutional neural\nnetwork, is able to outperform any individual MAPF algorithm in our portfolio.\n", "versions": [{"version": "v1", "created": "Mon, 10 Jun 2019 14:10:49 GMT"}, {"version": "v2", "created": "Sat, 15 Jun 2019 13:55:12 GMT"}], "update_date": "2019-06-18", "authors_parsed": [["Sigurdson", "Devon", ""], ["Bulitko", "Vadim", ""], ["Koenig", "Sven", ""], ["Hernandez", "Carlos", ""], ["Yeoh", "William", ""]]}, {"id": "1906.03997", "submitter": "Christoph Salge", "authors": "Daniel Ashlock and Christoph Salge", "title": "The Riddle of Togelby", "comments": "8 pages, in proceedings of 2019 IEEE Conference on Games, COG 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  At the 2017 Artificial and Computational Intelligence in Games meeting at\nDagstuhl, Julian Togelius asked how to make spaces where every way of filling\nin the details yielded a good game. This study examines the possibility of\nenriching search spaces so that they contain very high rates of interesting\nobjects, specifically game elements. While we do not answer the full challenge\nof finding good games throughout the space, this study highlights a number of\npotential avenues. These include naturally rich spaces, a simple technique for\nmodifying a representation to search only rich parts of a larger search space,\nand representations that are highly expressive and so exhibit highly restricted\nand consequently enriched search spaces.\n", "versions": [{"version": "v1", "created": "Mon, 10 Jun 2019 14:16:02 GMT"}], "update_date": "2019-06-11", "authors_parsed": [["Ashlock", "Daniel", ""], ["Salge", "Christoph", ""]]}, {"id": "1906.04009", "submitter": "Che Wang", "authors": "Che Wang, Keith Ross", "title": "Boosting Soft Actor-Critic: Emphasizing Recent Experience without\n  Forgetting the Past", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Soft Actor-Critic (SAC) is an off-policy actor-critic deep reinforcement\nlearning (DRL) algorithm based on maximum entropy reinforcement learning. By\ncombining off-policy updates with an actor-critic formulation, SAC achieves\nstate-of-the-art performance on a range of continuous-action benchmark tasks,\noutperforming prior on-policy and off-policy methods. The off-policy method\nemployed by SAC samples data uniformly from past experience when performing\nparameter updates. We propose Emphasizing Recent Experience (ERE), a simple but\npowerful off-policy sampling technique, which emphasizes recently observed data\nwhile not forgetting the past. The ERE algorithm samples more aggressively from\nrecent experience, and also orders the updates to ensure that updates from old\ndata do not overwrite updates from new data. We compare vanilla SAC and\nSAC+ERE, and show that ERE is more sample efficient than vanilla SAC for\ncontinuous-action Mujoco tasks. We also consider combining SAC with Priority\nExperience Replay (PER), a scheme originally proposed for deep Q-learning which\nprioritizes the data based on temporal-difference (TD) error. We show that\nSAC+PER can marginally improve the sample efficiency performance of SAC, but\nmuch less so than SAC+ERE. Finally, we propose an algorithm which integrates\nERE and PER and show that this hybrid algorithm can give the best results for\nsome of the Mujoco tasks.\n", "versions": [{"version": "v1", "created": "Mon, 10 Jun 2019 14:27:13 GMT"}], "update_date": "2019-06-11", "authors_parsed": [["Wang", "Che", ""], ["Ross", "Keith", ""]]}, {"id": "1906.04023", "submitter": "Raluca Gaina", "authors": "Raluca D. Gaina, Simon M. Lucas, Diego Perez-Liebana", "title": "Project Thyia: A Forever Gameplayer", "comments": "8 pages, 1 figure, accepted at IEEE COG 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The space of Artificial Intelligence entities is dominated by conversational\nbots. Some of them fit in our pockets and we take them everywhere we go, or\nallow them to be a part of human homes. Siri, Alexa, they are recognised as\npresent in our world. But a lot of games research is restricted to existing in\nthe separate realm of software. We enter different worlds when playing games,\nbut those worlds cease to exist once we quit. Similarly, AI game-players are\nrun once on a game (or maybe for longer periods of time, in the case of\nlearning algorithms which need some, still limited, period for training), and\nthey cease to exist once the game ends. But what if they didn't? What if there\nexisted artificial game-players that continuously played games, learned from\ntheir experiences and kept getting better? What if they interacted with the\nreal world and us, humans: live-streaming games, chatting with viewers,\naccepting suggestions for strategies or games to play, forming opinions on\npopular game titles? In this paper, we introduce the vision behind a new\nproject called Thyia, which focuses around creating a present, continuous,\n`always-on', interactive game-player.\n", "versions": [{"version": "v1", "created": "Mon, 10 Jun 2019 14:35:07 GMT"}], "update_date": "2019-06-11", "authors_parsed": [["Gaina", "Raluca D.", ""], ["Lucas", "Simon M.", ""], ["Perez-Liebana", "Diego", ""]]}, {"id": "1906.04027", "submitter": "Raluca Gaina", "authors": "Raluca D. Gaina, Matthew Stephenson", "title": "\"Did You Hear That?\" Learning to Play Video Games from Audio Cues", "comments": "4 pages, 2 figures, accepted at IEEE COG 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.SD eess.AS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Game-playing AI research has focused for a long time on learning to play\nvideo games from visual input or symbolic information. However, humans benefit\nfrom a wider array of sensors which we utilise in order to navigate the world\naround us. In particular, sounds and music are key to how many of us perceive\nthe world and influence the decisions we make. In this paper, we present\ninitial experiments on game-playing agents learning to play video games solely\nfrom audio cues. We expand the Video Game Description Language to allow for\naudio specification, and the General Video Game AI framework to provide new\naudio games and an API for learning agents to make use of audio observations.\nWe analyse the games and the audio game design process, include initial results\nwith simple Q~Learning agents, and encourage further research in this area.\n", "versions": [{"version": "v1", "created": "Mon, 10 Jun 2019 14:38:17 GMT"}, {"version": "v2", "created": "Tue, 11 Jun 2019 14:59:50 GMT"}], "update_date": "2019-06-12", "authors_parsed": [["Gaina", "Raluca D.", ""], ["Stephenson", "Matthew", ""]]}, {"id": "1906.04043", "submitter": "Sebastian Gehrmann", "authors": "Sebastian Gehrmann and Hendrik Strobelt and Alexander M. Rush", "title": "GLTR: Statistical Detection and Visualization of Generated Text", "comments": "ACL 2019 Demo Track", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The rapid improvement of language models has raised the specter of abuse of\ntext generation systems. This progress motivates the development of simple\nmethods for detecting generated text that can be used by and explained to\nnon-experts. We develop GLTR, a tool to support humans in detecting whether a\ntext was generated by a model. GLTR applies a suite of baseline statistical\nmethods that can detect generation artifacts across common sampling schemes. In\na human-subjects study, we show that the annotation scheme provided by GLTR\nimproves the human detection-rate of fake text from 54% to 72% without any\nprior training. GLTR is open-source and publicly deployed, and has already been\nwidely used to detect generated outputs\n", "versions": [{"version": "v1", "created": "Mon, 10 Jun 2019 14:52:41 GMT"}], "update_date": "2019-06-11", "authors_parsed": [["Gehrmann", "Sebastian", ""], ["Strobelt", "Hendrik", ""], ["Rush", "Alexander M.", ""]]}, {"id": "1906.04102", "submitter": "Lilian Wanzare", "authors": "Lilian D.A. Wanzare and Michael Roth and Manfred Pinkal", "title": "Detecting Everyday Scenarios in Narrative Texts", "comments": "Storytelling workshop 2019@ACL", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Script knowledge consists of detailed information on everyday activities.\nSuch information is often taken for granted in text and needs to be inferred by\nreaders. Therefore, script knowledge is a central component to language\ncomprehension. Previous work on representing scripts is mostly based on\nextensive manual work or limited to scenarios that can be found with sufficient\nredundancy in large corpora. We introduce the task of scenario detection, in\nwhich we identify references to scripts. In this task, we address a wide range\nof different scripts (200 scenarios) and we attempt to identify all references\nto them in a collection of narrative texts. We present a first benchmark data\nset and a baseline model that tackles scenario detection using techniques from\ntopic segmentation and text classification.\n", "versions": [{"version": "v1", "created": "Mon, 10 Jun 2019 16:23:07 GMT"}], "update_date": "2019-06-11", "authors_parsed": [["Wanzare", "Lilian D. A.", ""], ["Roth", "Michael", ""], ["Pinkal", "Manfred", ""]]}, {"id": "1906.04158", "submitter": "Hanbyul Joo", "authors": "Hanbyul Joo, Tomas Simon, Mina Cikara, Yaser Sheikh", "title": "Towards Social Artificial Intelligence: Nonverbal Social Signal\n  Prediction in A Triadic Interaction", "comments": "CVPR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new research task and a dataset to understand human social\ninteractions via computational methods, to ultimately endow machines with the\nability to encode and decode a broad channel of social signals humans use. This\nresearch direction is essential to make a machine that genuinely communicates\nwith humans, which we call Social Artificial Intelligence. We first formulate\nthe \"social signal prediction\" problem as a way to model the dynamics of social\nsignals exchanged among interacting individuals in a data-driven way. We then\npresent a new 3D motion capture dataset to explore this problem, where the\nbroad spectrum of social signals (3D body, face, and hand motions) are captured\nin a triadic social interaction scenario. Baseline approaches to predict\nspeaking status, social formation, and body gestures of interacting individuals\nare presented in the defined social prediction framework.\n", "versions": [{"version": "v1", "created": "Mon, 10 Jun 2019 17:56:03 GMT"}], "update_date": "2019-06-11", "authors_parsed": [["Joo", "Hanbyul", ""], ["Simon", "Tomas", ""], ["Cikara", "Mina", ""], ["Sheikh", "Yaser", ""]]}, {"id": "1906.04161", "submitter": "Deepak Pathak", "authors": "Deepak Pathak, Dhiraj Gandhi, Abhinav Gupta", "title": "Self-Supervised Exploration via Disagreement", "comments": "Accepted at ICML 2019. Website at\n  https://pathak22.github.io/exploration-by-disagreement/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Efficient exploration is a long-standing problem in sensorimotor learning.\nMajor advances have been demonstrated in noise-free, non-stochastic domains\nsuch as video games and simulation. However, most of these formulations either\nget stuck in environments with stochastic dynamics or are too inefficient to be\nscalable to real robotics setups. In this paper, we propose a formulation for\nexploration inspired by the work in active learning literature. Specifically,\nwe train an ensemble of dynamics models and incentivize the agent to explore\nsuch that the disagreement of those ensembles is maximized. This allows the\nagent to learn skills by exploring in a self-supervised manner without any\nexternal reward. Notably, we further leverage the disagreement objective to\noptimize the agent's policy in a differentiable manner, without using\nreinforcement learning, which results in a sample-efficient exploration. We\ndemonstrate the efficacy of this formulation across a variety of benchmark\nenvironments including stochastic-Atari, Mujoco and Unity. Finally, we\nimplement our differentiable exploration on a real robot which learns to\ninteract with objects completely from scratch. Project videos and code are at\nhttps://pathak22.github.io/exploration-by-disagreement/\n", "versions": [{"version": "v1", "created": "Mon, 10 Jun 2019 17:58:32 GMT"}], "update_date": "2019-06-11", "authors_parsed": [["Pathak", "Deepak", ""], ["Gandhi", "Dhiraj", ""], ["Gupta", "Abhinav", ""]]}, {"id": "1906.04238", "submitter": "Alexander Dockhorn", "authors": "Alexander Dockhorn and Sanaz Mostaghim", "title": "Introducing the Hearthstone-AI Competition", "comments": "Competition Webpage:\n  http://www.ci.ovgu.de/Research/HearthstoneAI.html", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The Hearthstone AI framework and competition motivates the development of\nartificial intelligence agents that can play collectible card games. A special\nfeature of those games is the high variety of cards, which can be chosen by the\nplayers to create their own decks. In contrast to simpler card games, the value\nof many cards is determined by their possible synergies. The vast amount of\npossible decks, the randomness of the game, as well as the restricted\ninformation during the player's turn offer quite a hard challenge for the\ndevelopment of game-playing agents. This short paper introduces the competition\nframework and goes into more detail on the problems and challenges that need to\nbe faced during the development process.\n", "versions": [{"version": "v1", "created": "Mon, 6 May 2019 12:53:36 GMT"}], "update_date": "2019-06-12", "authors_parsed": [["Dockhorn", "Alexander", ""], ["Mostaghim", "Sanaz", ""]]}, {"id": "1906.04239", "submitter": "Shih-Yuan Yu", "authors": "Shih Yuan Yu, Sujit Rokka Chhetri, Arquimedes Canedo, Palash Goyal,\n  Mohammad Abdullah Al Faruque", "title": "Pykg2vec: A Python Library for Knowledge Graph Embedding", "comments": "5 pages, 5 figures, few code snippets", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pykg2vec is an open-source Python library for learning the representations of\nthe entities and relations in knowledge graphs. Pykg2vec's flexible and modular\nsoftware architecture currently implements 16 state-of-the-art knowledge graph\nembedding algorithms, and is designed to easily incorporate new algorithms. The\ngoal of pykg2vec is to provide a practical and educational platform to\naccelerate research in knowledge graph representation learning. Pykg2vec is\nbuilt on top of TensorFlow and Python's multiprocessing framework and provides\nmodules for batch generation, Bayesian hyperparameter optimization, mean rank\nevaluation, embedding, and result visualization. Pykg2vec is released under the\nMIT License and is also available in the Python Package Index (PyPI). The\nsource code of pykg2vec is available at https://github.com/Sujit-O/pykg2vec.\n", "versions": [{"version": "v1", "created": "Tue, 4 Jun 2019 04:22:32 GMT"}], "update_date": "2019-06-12", "authors_parsed": [["Yu", "Shih Yuan", ""], ["Chhetri", "Sujit Rokka", ""], ["Canedo", "Arquimedes", ""], ["Goyal", "Palash", ""], ["Faruque", "Mohammad Abdullah Al", ""]]}, {"id": "1906.04240", "submitter": "Yingbing Hua", "authors": "Yingbing Hua, Bj\\\"orn Hein", "title": "Interpreting OWL Complex Classes in AutomationML based on Bidirectional\n  Translation", "comments": "As accepted to IEEE 24th International Conference on Emerging\n  Technologies and Factory Automation (ETFA 2019)", "journal-ref": null, "doi": "10.1109/ETFA.2019.8869456", "report-no": null, "categories": "cs.AI cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The World Wide Web Consortium (W3C) has published several recommendations for\nbuilding and storing ontologies, including the most recent OWL 2 Web Ontology\nLanguage (OWL). These initiatives have been followed by practical\nimplementations that popularize OWL in various domains. For example, OWL has\nbeen used for conceptual modeling in industrial engineering, and its reasoning\nfacilities are used to provide a wealth of services, e.g. model diagnosis,\nautomated code generation, and semantic integration. More specifically, recent\nstudies have shown that OWL is well suited for harmonizing information of\nengineering tools stored as AutomationML (AML) files. However, OWL and its\ntools can be cumbersome for direct use by engineers such that an ontology\nexpert is often required in practice. Although much attention has been paid in\nthe literature to overcome this issue by transforming OWL ontologies from/to\nAML models automatically, dealing with OWL complex classes remains an open\nresearch question. In this paper, we introduce the AML concept models for\nrepresenting OWL complex classes in AutomationML, and present algorithms for\nthe bidirectional translation between OWL complex classes and their\ncorresponding AML concept models. We show that this approach provides an\nefficient and intuitive interface for nonexperts to visualize, modify, and\ncreate OWL complex classes.\n", "versions": [{"version": "v1", "created": "Tue, 4 Jun 2019 09:04:48 GMT"}], "update_date": "2019-10-24", "authors_parsed": [["Hua", "Yingbing", ""], ["Hein", "Bj\u00f6rn", ""]]}, {"id": "1906.04328", "submitter": "Matthew Schlegel", "authors": "Matthew Schlegel, Wesley Chung, Daniel Graves, Jian Qian, Martha White", "title": "Importance Resampling for Off-policy Prediction", "comments": "Recently published in NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Importance sampling (IS) is a common reweighting strategy for off-policy\nprediction in reinforcement learning. While it is consistent and unbiased, it\ncan result in high variance updates to the weights for the value function. In\nthis work, we explore a resampling strategy as an alternative to reweighting.\nWe propose Importance Resampling (IR) for off-policy prediction, which\nresamples experience from a replay buffer and applies standard on-policy\nupdates. The approach avoids using importance sampling ratios in the update,\ninstead correcting the distribution before the update. We characterize the bias\nand consistency of IR, particularly compared to Weighted IS (WIS). We\ndemonstrate in several microworlds that IR has improved sample efficiency and\nlower variance updates, as compared to IS and several variance-reduced IS\nstrategies, including variants of WIS and V-trace which clips IS ratios. We\nalso provide a demonstration showing IR improves over IS for learning a value\nfunction from images in a racing car simulator.\n", "versions": [{"version": "v1", "created": "Tue, 11 Jun 2019 00:30:17 GMT"}, {"version": "v2", "created": "Wed, 13 Nov 2019 19:47:24 GMT"}], "update_date": "2019-11-15", "authors_parsed": [["Schlegel", "Matthew", ""], ["Chung", "Wesley", ""], ["Graves", "Daniel", ""], ["Qian", "Jian", ""], ["White", "Martha", ""]]}, {"id": "1906.04355", "submitter": "Shagun Sodhani", "authors": "Shagun Sodhani, Anirudh Goyal, Tristan Deleu, Yoshua Bengio, Sergey\n  Levine, Jian Tang", "title": "Learning Powerful Policies by Using Consistent Dynamics Model", "comments": "Accpted at RLDM 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Model-based Reinforcement Learning approaches have the promise of being\nsample efficient. Much of the progress in learning dynamics models in RL has\nbeen made by learning models via supervised learning. But traditional\nmodel-based approaches lead to `compounding errors' when the model is unrolled\nstep by step. Essentially, the state transitions that the learner predicts (by\nunrolling the model for multiple steps) and the state transitions that the\nlearner experiences (by acting in the environment) may not be consistent. There\nis enough evidence that humans build a model of the environment, not only by\nobserving the environment but also by interacting with the environment.\nInteraction with the environment allows humans to carry out experiments: taking\nactions that help uncover true causal relationships which can be used for\nbuilding better dynamics models. Analogously, we would expect such interactions\nto be helpful for a learning agent while learning to model the environment\ndynamics. In this paper, we build upon this intuition by using an auxiliary\ncost function to ensure consistency between what the agent observes (by acting\nin the real world) and what it imagines (by acting in the `learned' world). We\nconsider several tasks - Mujoco based control tasks and Atari games - and show\nthat the proposed approach helps to train powerful policies and better dynamics\nmodels.\n", "versions": [{"version": "v1", "created": "Tue, 11 Jun 2019 02:31:38 GMT"}], "update_date": "2019-06-12", "authors_parsed": [["Sodhani", "Shagun", ""], ["Goyal", "Anirudh", ""], ["Deleu", "Tristan", ""], ["Bengio", "Yoshua", ""], ["Levine", "Sergey", ""], ["Tang", "Jian", ""]]}, {"id": "1906.04439", "submitter": "Michele Alberti", "authors": "Joel Niklaus, Michele Alberti, Vinaychandran Pondenkandath, Rolf\n  Ingold, Marcus Liwicki", "title": "Survey of Artificial Intelligence for Card Games and Its Application to\n  the Swiss Game Jass", "comments": null, "journal-ref": "6th Swiss Conference on Data Science (SDS), Bern, Switzerland,\n  2019", "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the last decades we have witnessed the success of applications of\nArtificial Intelligence to playing games. In this work we address the\nchallenging field of games with hidden information and card games in\nparticular. Jass is a very popular card game in Switzerland and is closely\nconnected with Swiss culture. To the best of our knowledge, performances of\nArtificial Intelligence agents in the game of Jass do not outperform top\nplayers yet. Our contribution to the community is two-fold. First, we provide\nan overview of the current state-of-the-art of Artificial Intelligence methods\nfor card games in general. Second, we discuss their application to the use-case\nof the Swiss card game Jass. This paper aims to be an entry point for both\nseasoned researchers and new practitioners who want to join in the Jass\nchallenge.\n", "versions": [{"version": "v1", "created": "Tue, 11 Jun 2019 08:31:21 GMT"}], "update_date": "2019-06-12", "authors_parsed": [["Niklaus", "Joel", ""], ["Alberti", "Michele", ""], ["Pondenkandath", "Vinaychandran", ""], ["Ingold", "Rolf", ""], ["Liwicki", "Marcus", ""]]}, {"id": "1906.04447", "submitter": "Peter beim Graben", "authors": "Peter beim Graben, Ronald R\\\"omer, Werner Meyer, Markus Huber, and\n  Matthias Wolff", "title": "Reinforcement Learning of Minimalist Numeral Grammars", "comments": "13 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Speech-controlled user interfaces facilitate the operation of devices and\nhousehold functions to laymen. State-of-the-art language technology scans the\nacoustically analyzed speech signal for relevant keywords that are subsequently\ninserted into semantic slots to interpret the user's intent. In order to\ndevelop proper cognitive information and communication technologies, simple\nslot-filling should be replaced by utterance meaning transducers (UMT) that are\nbased on semantic parsers and a \\emph{mental lexicon}, comprising syntactic,\nphonetic and semantic features of the language under consideration. This\nlexicon must be acquired by a cognitive agent during interaction with its\nusers. We outline a reinforcement learning algorithm for the acquisition of the\nsyntactic morphology and arithmetic semantics of English numerals, based on\nminimalist grammar (MG), a recent computational implementation of generative\nlinguistics. Number words are presented to the agent by a teacher in form of\nutterance meaning pairs (UMP) where the meanings are encoded as arithmetic\nterms from a suitable term algebra. Since MG encodes universal linguistic\ncompetence through inference rules, thereby separating innate linguistic\nknowledge from the contingently acquired lexicon, our approach unifies\ngenerative grammar and reinforcement learning, hence potentially resolving the\nstill pending Chomsky-Skinner controversy.\n", "versions": [{"version": "v1", "created": "Tue, 11 Jun 2019 08:54:23 GMT"}], "update_date": "2019-06-12", "authors_parsed": [["Graben", "Peter beim", ""], ["R\u00f6mer", "Ronald", ""], ["Meyer", "Werner", ""], ["Huber", "Markus", ""], ["Wolff", "Matthias", ""]]}, {"id": "1906.04448", "submitter": "Fabrizio Carpi", "authors": "Fabrizio Carpi, Christian H\\\"ager, Marco Martal\\`o, Riccardo Raheli,\n  Henry D. Pfister", "title": "Reinforcement Learning for Channel Coding: Learned Bit-Flipping Decoding", "comments": null, "journal-ref": null, "doi": "10.1109/ALLERTON.2019.8919799", "report-no": null, "categories": "cs.IT cs.AI cs.LG math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we use reinforcement learning to find effective decoding\nstrategies for binary linear codes. We start by reviewing several iterative\ndecoding algorithms that involve a decision-making process at each step,\nincluding bit-flipping (BF) decoding, residual belief propagation, and anchor\ndecoding. We then illustrate how such algorithms can be mapped to Markov\ndecision processes allowing for data-driven learning of optimal decision\nstrategies, rather than basing decisions on heuristics or intuition. As a case\nstudy, we consider BF decoding for both the binary symmetric and additive white\nGaussian noise channel. Our results show that learned BF decoders can offer a\nrange of performance-complexity trade-offs for the considered Reed-Muller and\nBCH codes, and achieve near-optimal performance in some cases. We also\ndemonstrate learning convergence speed-ups when biasing the learning process\ntowards correct decoding decisions, as opposed to relying only on random\nexplorations and past knowledge.\n", "versions": [{"version": "v1", "created": "Tue, 11 Jun 2019 08:58:11 GMT"}, {"version": "v2", "created": "Wed, 21 Aug 2019 12:48:03 GMT"}], "update_date": "2019-12-10", "authors_parsed": [["Carpi", "Fabrizio", ""], ["H\u00e4ger", "Christian", ""], ["Martal\u00f2", "Marco", ""], ["Raheli", "Riccardo", ""], ["Pfister", "Henry D.", ""]]}, {"id": "1906.04536", "submitter": "Armand Boschin", "authors": "Armand Boschin, Thomas Bonald", "title": "WikiDataSets: Standardized sub-graphs from Wikidata", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Developing new ideas and algorithms in the fields of graph processing and\nrelational learning requires public datasets. While Wikidata is the largest\nopen source knowledge graph, involving more than fifty million entities, it is\nlarger than needed in many cases and even too large to be processed easily.\nStill, it is a goldmine of relevant facts and relations. Using this knowledge\ngraph is time consuming and prone to task specific tuning which can affect\nreproducibility of results. Providing a unified framework to extract\ntopic-specific subgraphs solves this problem and allows researchers to evaluate\nalgorithms on common datasets. This paper presents various topic-specific\nsubgraphs of Wikidata along with the generic Python code used to extract them.\nThese datasets can help develop new methods of knowledge graph processing and\nrelational learning.\n", "versions": [{"version": "v1", "created": "Tue, 11 Jun 2019 12:47:59 GMT"}, {"version": "v2", "created": "Tue, 2 Jul 2019 18:08:38 GMT"}, {"version": "v3", "created": "Fri, 4 Oct 2019 13:27:17 GMT"}], "update_date": "2019-10-07", "authors_parsed": [["Boschin", "Armand", ""], ["Bonald", "Thomas", ""]]}, {"id": "1906.04569", "submitter": "Hien Nguyen", "authors": "Aryan Mobiny, Hien V. Nguyen, Supratik Moulik, Naveen Garg, Carol C.\n  Wu", "title": "DropConnect Is Effective in Modeling Uncertainty of Bayesian Deep\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (DNNs) have achieved state-of-the-art performances in\nmany important domains, including medical diagnosis, security, and autonomous\ndriving. In these domains where safety is highly critical, an erroneous\ndecision can result in serious consequences. While a perfect prediction\naccuracy is not always achievable, recent work on Bayesian deep networks shows\nthat it is possible to know when DNNs are more likely to make mistakes. Knowing\nwhat DNNs do not know is desirable to increase the safety of deep learning\ntechnology in sensitive applications. Bayesian neural networks attempt to\naddress this challenge. However, traditional approaches are computationally\nintractable and do not scale well to large, complex neural network\narchitectures. In this paper, we develop a theoretical framework to approximate\nBayesian inference for DNNs by imposing a Bernoulli distribution on the model\nweights. This method, called MC-DropConnect, gives us a tool to represent the\nmodel uncertainty with little change in the overall model structure or\ncomputational cost. We extensively validate the proposed algorithm on multiple\nnetwork architectures and datasets for classification and semantic segmentation\ntasks. We also propose new metrics to quantify the uncertainty estimates. This\nenables an objective comparison between MC-DropConnect and prior approaches.\nOur empirical results demonstrate that the proposed framework yields\nsignificant improvement in both prediction accuracy and uncertainty estimation\nquality compared to the state of the art.\n", "versions": [{"version": "v1", "created": "Fri, 7 Jun 2019 20:51:52 GMT"}], "update_date": "2019-06-12", "authors_parsed": [["Mobiny", "Aryan", ""], ["Nguyen", "Hien V.", ""], ["Moulik", "Supratik", ""], ["Garg", "Naveen", ""], ["Wu", "Carol C.", ""]]}, {"id": "1906.04585", "submitter": "Mahmoud Assran", "authors": "Mahmoud Assran, Joshua Romoff, Nicolas Ballas, Joelle Pineau, Michael\n  Rabbat", "title": "Gossip-based Actor-Learner Architectures for Deep Reinforcement Learning", "comments": null, "journal-ref": "Advances in Neural Information Processing Systems (2019)\n  13299-13309", "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-simulator training has contributed to the recent success of Deep\nReinforcement Learning by stabilizing learning and allowing for higher training\nthroughputs. We propose Gossip-based Actor-Learner Architectures (GALA) where\nseveral actor-learners (such as A2C agents) are organized in a peer-to-peer\ncommunication topology, and exchange information through asynchronous gossip in\norder to take advantage of a large number of distributed simulators. We prove\nthat GALA agents remain within an epsilon-ball of one-another during training\nwhen using loosely coupled asynchronous communication. By reducing the amount\nof synchronization between agents, GALA is more computationally efficient and\nscalable compared to A2C, its fully-synchronous counterpart. GALA also\noutperforms A2C, being more robust and sample efficient. We show that we can\nrun several loosely coupled GALA agents in parallel on a single GPU and achieve\nsignificantly higher hardware utilization and frame-rates than vanilla A2C at\ncomparable power draws.\n", "versions": [{"version": "v1", "created": "Sun, 9 Jun 2019 16:15:43 GMT"}, {"version": "v2", "created": "Tue, 21 Apr 2020 23:56:00 GMT"}], "update_date": "2020-04-23", "authors_parsed": [["Assran", "Mahmoud", ""], ["Romoff", "Joshua", ""], ["Ballas", "Nicolas", ""], ["Pineau", "Joelle", ""], ["Rabbat", "Michael", ""]]}, {"id": "1906.04595", "submitter": "Chaopeng Shen", "authors": "Kuai Fang, Chaopeng Shen, Daniel Kifer", "title": "Evaluating aleatoric and epistemic uncertainties of time series deep\n  learning models for soil moisture predictions", "comments": null, "journal-ref": "Water Resources Research (2020)", "doi": "10.1029/2020WR028095", "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Soil moisture is an important variable that determines floods, vegetation\nhealth, agriculture productivity, and land surface feedbacks to the atmosphere,\netc. Accurately modeling soil moisture has important implications in both\nweather and climate models. The recently available satellite-based observations\ngive us a unique opportunity to build data-driven models to predict soil\nmoisture instead of using land surface models, but previously there was no\nuncertainty estimate. We tested Monte Carlo dropout (MCD) with an aleatoric\nterm for our long short-term memory models for this problem, and asked if the\nuncertainty terms behave as they were argued to. We show that the method\nsuccessfully captures the predictive error after tuning a hyperparameter on a\nrepresentative training dataset. We show the MCD uncertainty estimate, as\npreviously argued, does detect dissimilarity.\n", "versions": [{"version": "v1", "created": "Mon, 10 Jun 2019 01:18:35 GMT"}], "update_date": "2020-11-30", "authors_parsed": [["Fang", "Kuai", ""], ["Shen", "Chaopeng", ""], ["Kifer", "Daniel", ""]]}, {"id": "1906.04604", "submitter": "Maxwell Nye", "authors": "Kevin Ellis, Maxwell Nye, Yewen Pu, Felix Sosa, Josh Tenenbaum,\n  Armando Solar-Lezama", "title": "Write, Execute, Assess: Program Synthesis with a REPL", "comments": "The first four authors contributed equally to this work", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.AI cs.LG cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a neural program synthesis approach integrating components which\nwrite, execute, and assess code to navigate the search space of possible\nprograms. We equip the search process with an interpreter or a\nread-eval-print-loop (REPL), which immediately executes partially written\nprograms, exposing their semantics. The REPL addresses a basic challenge of\nprogram synthesis: tiny changes in syntax can lead to huge changes in\nsemantics. We train a pair of models, a policy that proposes the new piece of\ncode to write, and a value function that assesses the prospects of the code\nwritten so-far. At test time we can combine these models with a Sequential\nMonte Carlo algorithm. We apply our approach to two domains: synthesizing text\nediting programs and inferring 2D and 3D graphics programs.\n", "versions": [{"version": "v1", "created": "Sun, 9 Jun 2019 23:12:40 GMT"}], "update_date": "2019-06-12", "authors_parsed": [["Ellis", "Kevin", ""], ["Nye", "Maxwell", ""], ["Pu", "Yewen", ""], ["Sosa", "Felix", ""], ["Tenenbaum", "Josh", ""], ["Solar-Lezama", "Armando", ""]]}, {"id": "1906.04660", "submitter": "Michael Green", "authors": "Michael Cerny Green, Ahmed Khalifa, Athoug Alsoughayer, Divyesh\n  Surana, Antonios Liapis and Julian Togelius", "title": "Two-step Constructive Approaches for Dungeon Generation", "comments": "7 pages, 4 figures, published at PCG workshop at the Foundations of\n  Digital Games Conference 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a two-step generative approach for creating dungeons in\nthe rogue-like puzzle game MiniDungeons 2. Generation is split into two steps,\ninitially producing the architectural layout of the level as its walls and\nfloor tiles, and then furnishing it with game objects representing the player's\nstart and goal position, challenges and rewards. Three layout creators and\nthree furnishers are introduced in this paper, which can be combined in\ndifferent ways in the two-step generative process for producing diverse\ndungeons levels. Layout creators generate the floors and walls of a level,\nwhile furnishers populate it with monsters, traps, and treasures. We test the\ngenerated levels on several expressivity measures, and in simulations with\nprocedural persona agents.\n", "versions": [{"version": "v1", "created": "Tue, 11 Jun 2019 15:39:33 GMT"}], "update_date": "2019-06-12", "authors_parsed": [["Green", "Michael Cerny", ""], ["Khalifa", "Ahmed", ""], ["Alsoughayer", "Athoug", ""], ["Surana", "Divyesh", ""], ["Liapis", "Antonios", ""], ["Togelius", "Julian", ""]]}, {"id": "1906.04706", "submitter": "Amita Misra", "authors": "Amita Misra, Mansurul Bhuiyan, Jalal Mahmud, and Saurabh Tripathy", "title": "Using Structured Representation and Data: A Hybrid Model for Negation\n  and Sentiment in Customer Service Conversations", "comments": null, "journal-ref": "Proceedings of the 10th Workshop on Computational Approaches to\n  Subjectivity, Sentiment and Social Media Analysis, 2019", "doi": null, "report-no": "https://www.aclweb.org/anthology/W19-1306", "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Twitter customer service interactions have recently emerged as an effective\nplatform to respond and engage with customers. In this work, we explore the\nrole of negation in customer service interactions, particularly applied to\nsentiment analysis. We define rules to identify true negation cues and scope\nmore suited to conversational data than existing general review data. Using\nsemantic knowledge and syntactic structure from constituency parse trees, we\npropose an algorithm for scope detection that performs comparable to state of\nthe art BiLSTM. We further investigate the results of negation scope detection\nfor the sentiment prediction task on customer service conversation data using\nboth a traditional SVM and a Neural Network. We propose an antonym dictionary\nbased method for negation applied to a CNN-LSTM combination model for sentiment\nanalysis. Experimental results show that the antonym-based method outperforms\nthe previous lexicon-based and neural network methods.\n", "versions": [{"version": "v1", "created": "Tue, 11 Jun 2019 17:15:32 GMT"}], "update_date": "2019-06-12", "authors_parsed": [["Misra", "Amita", ""], ["Bhuiyan", "Mansurul", ""], ["Mahmud", "Jalal", ""], ["Tripathy", "Saurabh", ""]]}, {"id": "1906.04733", "submitter": "Ofir Nachum", "authors": "Ofir Nachum, Yinlam Chow, Bo Dai, Lihong Li", "title": "DualDICE: Behavior-Agnostic Estimation of Discounted Stationary\n  Distribution Corrections", "comments": "Appearing in NeurIPS 2019 Vancouver, Canada", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many real-world reinforcement learning applications, access to the\nenvironment is limited to a fixed dataset, instead of direct (online)\ninteraction with the environment. When using this data for either evaluation or\ntraining of a new policy, accurate estimates of discounted stationary\ndistribution ratios -- correction terms which quantify the likelihood that the\nnew policy will experience a certain state-action pair normalized by the\nprobability with which the state-action pair appears in the dataset -- can\nimprove accuracy and performance. In this work, we propose an algorithm,\nDualDICE, for estimating these quantities. In contrast to previous approaches,\nour algorithm is agnostic to knowledge of the behavior policy (or policies)\nused to generate the dataset. Furthermore, it eschews any direct use of\nimportance weights, thus avoiding potential optimization instabilities endemic\nof previous methods. In addition to providing theoretical guarantees, we\npresent an empirical study of our algorithm applied to off-policy policy\nevaluation and find that our algorithm significantly improves accuracy compared\nto existing techniques.\n", "versions": [{"version": "v1", "created": "Mon, 10 Jun 2019 19:33:00 GMT"}, {"version": "v2", "created": "Mon, 4 Nov 2019 22:01:49 GMT"}], "update_date": "2019-11-06", "authors_parsed": [["Nachum", "Ofir", ""], ["Chow", "Yinlam", ""], ["Dai", "Bo", ""], ["Li", "Lihong", ""]]}, {"id": "1906.04737", "submitter": "Georgios Papoudakis", "authors": "Georgios Papoudakis, Filippos Christianos, Arrasy Rahman, Stefano V.\n  Albrecht", "title": "Dealing with Non-Stationarity in Multi-Agent Deep Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent developments in deep reinforcement learning are concerned with\ncreating decision-making agents which can perform well in various complex\ndomains. A particular approach which has received increasing attention is\nmulti-agent reinforcement learning, in which multiple agents learn concurrently\nto coordinate their actions. In such multi-agent environments, additional\nlearning problems arise due to the continually changing decision-making\npolicies of agents. This paper surveys recent works that address the\nnon-stationarity problem in multi-agent deep reinforcement learning. The\nsurveyed methods range from modifications in the training procedure, such as\ncentralized training, to learning representations of the opponent's policy,\nmeta-learning, communication, and decentralized learning. The survey concludes\nwith a list of open problems and possible lines of future research.\n", "versions": [{"version": "v1", "created": "Tue, 11 Jun 2019 09:42:00 GMT"}], "update_date": "2019-06-13", "authors_parsed": [["Papoudakis", "Georgios", ""], ["Christianos", "Filippos", ""], ["Rahman", "Arrasy", ""], ["Albrecht", "Stefano V.", ""]]}, {"id": "1906.04739", "submitter": "Adriana-Simona Mihaita Dr.", "authors": "Sajjad Shafiei, Adriana-Simona Mihaita, Chen Cai", "title": "Trip Table Estimation and Prediction for Dynamic Traffic Assignment\n  Applications", "comments": "6 pages, 6 figures, preprint at the 26th ITS World Congress 21-25 Oct\n  2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The study focuses on estimating and predicting time-varying origin to\ndestination (OD) trip tables for a dynamic traffic assignment (DTA) model. A\nbi-level optimisation problem is formulated and solved to estimate OD flows\nfrom pre-existent demand matrix and historical traffic flow counts. The\nestimated demand is then considered as an input for a time series OD demand\nprediction model to support the DTA model for short-term traffic condition\nforecasting. Results show a high capability of the proposed OD demand\nestimation method to reduce the DTA model error through an iterative solution\nalgorithm. Moreover, the applicability of the OD demand prediction approach is\ninvestigated for an incident analysis application for a major corridor in\nSydney, Australia.\n", "versions": [{"version": "v1", "created": "Tue, 11 Jun 2019 13:42:12 GMT"}], "update_date": "2019-06-13", "authors_parsed": [["Shafiei", "Sajjad", ""], ["Mihaita", "Adriana-Simona", ""], ["Cai", "Chen", ""]]}, {"id": "1906.04774", "submitter": "Thibault Laugel", "authors": "Thibault Laugel and Marie-Jeanne Lesot and Christophe Marsala and\n  Marcin Detyniecki", "title": "Issues with post-hoc counterfactual explanations: a discussion", "comments": "presented at 2019 ICML Workshop on Human in the Loop Learning (HILL\n  2019), Long Beach, USA", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Counterfactual post-hoc interpretability approaches have been proven to be\nuseful tools to generate explanations for the predictions of a trained blackbox\nclassifier. However, the assumptions they make about the data and the\nclassifier make them unreliable in many contexts. In this paper, we discuss\nthree desirable properties and approaches to quantify them: proximity,\nconnectedness and stability. In addition, we illustrate that there is a risk\nfor post-hoc counterfactual approaches to not satisfy these properties.\n", "versions": [{"version": "v1", "created": "Tue, 11 Jun 2019 19:04:54 GMT"}], "update_date": "2019-06-13", "authors_parsed": [["Laugel", "Thibault", ""], ["Lesot", "Marie-Jeanne", ""], ["Marsala", "Christophe", ""], ["Detyniecki", "Marcin", ""]]}, {"id": "1906.04825", "submitter": "Sabri Pllana", "authors": "Sabri Pllana, Suejb Memeti, Joanna Kolodziej", "title": "Customizing Pareto Simulated Annealing for Multi-objective Optimization\n  of Control Cabinet Layout", "comments": "Preprint, CSCS22, (C) 2019 IEEE", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.OH cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Determining the optimal location of control cabinet components requires the\nexploration of a large configuration space. For real-world control cabinets it\nis impractical to evaluate all possible cabinet configurations. Therefore, we\nneed to apply methods for intelligent exploration of cabinet configuration\nspace that enable to find a near-optimal configuration without evaluation of\nall possible configurations. In this paper, we describe an approach for\nmulti-objective optimization of control cabinet layout that is based on Pareto\nSimulated Annealing. Optimization aims at minimizing the total wire length used\nfor interconnection of components and the heat convection within the cabinet.\nWe simulate heat convection to study the warm air flow within the control\ncabinet and determine the optimal position of components that generate heat\nduring the operation. We evaluate and demonstrate the effectiveness of our\napproach empirically for various control cabinet sizes and usage scenarios.\n", "versions": [{"version": "v1", "created": "Tue, 4 Jun 2019 10:05:00 GMT"}], "update_date": "2019-06-13", "authors_parsed": [["Pllana", "Sabri", ""], ["Memeti", "Suejb", ""], ["Kolodziej", "Joanna", ""]]}, {"id": "1906.04837", "submitter": "Kit Kuksenok", "authors": "Kit Kuksenok", "title": "Toward Best Practices for Explainable B2B Machine Learning", "comments": "4 pages, 1 figure; position paper for INTERACT 2019 workshop on\n  Humans in the Loop: Bridging AI and HCI", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To design tools and data pipelines for explainable B2B machine learning (ML)\nsystems, we need to recognize not only the immediate audience of such tools and\ndata, but also (1) their organizational context and (2) secondary audiences.\nOur learnings are based on building custom ML-based chatbots for recruitment.\nWe believe that in the B2B context, \"explainable\" ML means not only a system\nthat can \"explain itself\" through tools and data pipelines, but also enables\nits domain-expert users to explain it to other stakeholders.\n", "versions": [{"version": "v1", "created": "Tue, 11 Jun 2019 21:46:24 GMT"}], "update_date": "2019-06-13", "authors_parsed": [["Kuksenok", "Kit", ""]]}, {"id": "1906.04893", "submitter": "Mahyar Fazlyab", "authors": "Mahyar Fazlyab, Alexander Robey, Hamed Hassani, Manfred Morari, George\n  J. Pappas", "title": "Efficient and Accurate Estimation of Lipschitz Constants for Deep Neural\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tight estimation of the Lipschitz constant for deep neural networks (DNNs) is\nuseful in many applications ranging from robustness certification of\nclassifiers to stability analysis of closed-loop systems with reinforcement\nlearning controllers. Existing methods in the literature for estimating the\nLipschitz constant suffer from either lack of accuracy or poor scalability. In\nthis paper, we present a convex optimization framework to compute guaranteed\nupper bounds on the Lipschitz constant of DNNs both accurately and efficiently.\nOur main idea is to interpret activation functions as gradients of convex\npotential functions. Hence, they satisfy certain properties that can be\ndescribed by quadratic constraints. This particular description allows us to\npose the Lipschitz constant estimation problem as a semidefinite program (SDP).\nThe resulting SDP can be adapted to increase either the estimation accuracy (by\ncapturing the interaction between activation functions of different layers) or\nscalability (by decomposition and parallel implementation). We illustrate the\nutility of our approach with a variety of experiments on randomly generated\nnetworks and on classifiers trained on the MNIST and Iris datasets. In\nparticular, we experimentally demonstrate that our Lipschitz bounds are the\nmost accurate compared to those in the literature. We also study the impact of\nadversarial training methods on the Lipschitz bounds of the resulting\nclassifiers and show that our bounds can be used to efficiently provide\nrobustness guarantees.\n", "versions": [{"version": "v1", "created": "Wed, 12 Jun 2019 02:18:19 GMT"}], "update_date": "2019-06-14", "authors_parsed": [["Fazlyab", "Mahyar", ""], ["Robey", "Alexander", ""], ["Hassani", "Hamed", ""], ["Morari", "Manfred", ""], ["Pappas", "George J.", ""]]}, {"id": "1906.04941", "submitter": "Qiang Ning", "authors": "Qiang Ning, Zhili Feng, Hao Wu, Dan Roth", "title": "Joint Reasoning for Temporal and Causal Relations", "comments": "Long paper appeared in ACL'18. 11 pages and 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding temporal and causal relations between events is a fundamental\nnatural language understanding task. Because a cause must be before its effect\nin time, temporal and causal relations are closely related and one relation\neven dictates the other one in many cases. However, limited attention has been\npaid to studying these two relations jointly. This paper presents a joint\ninference framework for them using constrained conditional models (CCMs).\nSpecifically, we formulate the joint problem as an integer linear programming\n(ILP) problem, enforcing constraints inherently in the nature of time and\ncausality. We show that the joint inference framework results in statistically\nsignificant improvement in the extraction of both temporal and causal relations\nfrom text.\n", "versions": [{"version": "v1", "created": "Wed, 12 Jun 2019 04:58:51 GMT"}], "update_date": "2019-06-13", "authors_parsed": [["Ning", "Qiang", ""], ["Feng", "Zhili", ""], ["Wu", "Hao", ""], ["Roth", "Dan", ""]]}, {"id": "1906.04980", "submitter": "Patrick Lewis", "authors": "Patrick Lewis, Ludovic Denoyer, Sebastian Riedel", "title": "Unsupervised Question Answering by Cloze Translation", "comments": "To appear in ACL 2019", "journal-ref": "Proceedings of the 57th Annual Meeting of the Association for\n  Computational Linguistics, 2019", "doi": "10.18653/v1/P19-1484", "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Obtaining training data for Question Answering (QA) is time-consuming and\nresource-intensive, and existing QA datasets are only available for limited\ndomains and languages. In this work, we explore to what extent high quality\ntraining data is actually required for Extractive QA, and investigate the\npossibility of unsupervised Extractive QA. We approach this problem by first\nlearning to generate context, question and answer triples in an unsupervised\nmanner, which we then use to synthesize Extractive QA training data\nautomatically. To generate such triples, we first sample random context\nparagraphs from a large corpus of documents and then random noun phrases or\nnamed entity mentions from these paragraphs as answers. Next we convert answers\nin context to \"fill-in-the-blank\" cloze questions and finally translate them\ninto natural questions. We propose and compare various unsupervised ways to\nperform cloze-to-natural question translation, including training an\nunsupervised NMT model using non-aligned corpora of natural questions and cloze\nquestions as well as a rule-based approach. We find that modern QA models can\nlearn to answer human questions surprisingly well using only synthetic training\ndata. We demonstrate that, without using the SQuAD training data at all, our\napproach achieves 56.4 F1 on SQuAD v1 (64.5 F1 when the answer is a Named\nentity mention), outperforming early supervised models.\n", "versions": [{"version": "v1", "created": "Wed, 12 Jun 2019 07:30:32 GMT"}, {"version": "v2", "created": "Thu, 27 Jun 2019 09:43:46 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Lewis", "Patrick", ""], ["Denoyer", "Ludovic", ""], ["Riedel", "Sebastian", ""]]}, {"id": "1906.04985", "submitter": "Alexander Cowen-Rivers MSc", "authors": "Alexander I. Cowen-Rivers, Pasquale Minervini, Tim Rocktaschel, Matko\n  Bosnjak, Sebastian Riedel, Jun Wang", "title": "Neural Variational Inference For Estimating Uncertainty in Knowledge\n  Graph Embeddings", "comments": "Accepted at IJCAI 19 Neural-Symbolic Learning and Reasoning Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.SC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in Neural Variational Inference allowed for a renaissance in\nlatent variable models in a variety of domains involving high-dimensional data.\nWhile traditional variational methods derive an analytical approximation for\nthe intractable distribution over the latent variables, here we construct an\ninference network conditioned on the symbolic representation of entities and\nrelation types in the Knowledge Graph, to provide the variational\ndistributions. The new framework results in a highly-scalable method. Under a\nBernoulli sampling framework, we provide an alternative justification for\ncommonly used techniques in large-scale stochastic variational inference, which\ndrastically reduce training time at a cost of an additional approximation to\nthe variational lower bound. We introduce two models from this highly scalable\nprobabilistic framework, namely the Latent Information and Latent Fact models,\nfor reasoning over knowledge graph-based representations. Our Latent\nInformation and Latent Fact models improve upon baseline performance under\ncertain conditions. We use the learnt embedding variance to estimate predictive\nuncertainty during link prediction, and discuss the quality of these learnt\nuncertainty estimates. Our source code and datasets are publicly available\nonline at\nhttps://github.com/alexanderimanicowenrivers/Neural-Variational-Knowledge-Graphs.\n", "versions": [{"version": "v1", "created": "Wed, 12 Jun 2019 07:52:02 GMT"}, {"version": "v2", "created": "Mon, 19 Aug 2019 03:01:30 GMT"}], "update_date": "2019-08-20", "authors_parsed": [["Cowen-Rivers", "Alexander I.", ""], ["Minervini", "Pasquale", ""], ["Rocktaschel", "Tim", ""], ["Bosnjak", "Matko", ""], ["Riedel", "Sebastian", ""], ["Wang", "Jun", ""]]}, {"id": "1906.05015", "submitter": "Ming Zhu", "authors": "Ming Zhu, Xiao-Yang Liu, and Xiaodong Wang", "title": "Deep Reinforcement Learning for Unmanned Aerial Vehicle-Assisted\n  Vehicular Networks", "comments": "14 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unmanned aerial vehicles (UAVs) are envisioned to complement the 5G\ncommunication infrastructure in future smart cities. Hot spots easily appear in\nroad intersections, where effective communication among vehicles is\nchallenging. UAVs may serve as relays with the advantages of low price, easy\ndeployment, line-of-sight links, and flexible mobility. In this paper, we study\na UAV-assisted vehicular network where the UAV jointly adjusts its transmission\ncontrol (power and channel) and 3D flight to maximize the total throughput.\nFirst, we formulate a Markov decision process (MDP) problem by modeling the\nmobility of the UAV/vehicles and the state transitions. Secondly, we solve the\ntarget problem using a deep reinforcement learning method under unknown or\nunmeasurable environment variables especially in 5G, namely, the deep\ndeterministic policy gradient (DDPG), and propose three solutions with\ndifferent control objectives. Environment variables are unknown and\nunmeasurable, therefore, we use a deep reinforcement learning method. Moreover,\nconsidering the energy consumption of 3D flight, we extend the proposed\nsolutions to maximize the total throughput per energy unit by encouraging or\ndiscouraging the UAV's mobility. To achieve this goal, the DDPG framework is\nmodified. Thirdly, in a simplified model with small state space and action\nspace, we verify the optimality of proposed algorithms. Comparing with two\nbaseline schemes, we demonstrate the effectiveness of proposed algorithms in a\nrealistic model.\n", "versions": [{"version": "v1", "created": "Wed, 12 Jun 2019 09:12:50 GMT"}, {"version": "v10", "created": "Wed, 4 Mar 2020 02:18:20 GMT"}, {"version": "v2", "created": "Sun, 23 Jun 2019 08:58:02 GMT"}, {"version": "v3", "created": "Mon, 1 Jul 2019 12:25:15 GMT"}, {"version": "v4", "created": "Mon, 8 Jul 2019 16:00:25 GMT"}, {"version": "v5", "created": "Tue, 9 Jul 2019 01:47:49 GMT"}, {"version": "v6", "created": "Fri, 12 Jul 2019 13:49:35 GMT"}, {"version": "v7", "created": "Sat, 27 Jul 2019 03:50:11 GMT"}, {"version": "v8", "created": "Mon, 12 Aug 2019 10:50:40 GMT"}, {"version": "v9", "created": "Tue, 3 Sep 2019 14:29:54 GMT"}], "update_date": "2020-03-05", "authors_parsed": [["Zhu", "Ming", ""], ["Liu", "Xiao-Yang", ""], ["Wang", "Xiaodong", ""]]}, {"id": "1906.05030", "submitter": "Steven Hansen", "authors": "Steven Hansen, Will Dabney, Andre Barreto, Tom Van de Wiele, David\n  Warde-Farley, Volodymyr Mnih", "title": "Fast Task Inference with Variational Intrinsic Successor Features", "comments": "Accepted for publication at ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It has been established that diverse behaviors spanning the controllable\nsubspace of an Markov decision process can be trained by rewarding a policy for\nbeing distinguishable from other policies \\citep{gregor2016variational,\neysenbach2018diversity, warde2018unsupervised}. However, one limitation of this\nformulation is generalizing behaviors beyond the finite set being explicitly\nlearned, as is needed for use on subsequent tasks. Successor features\n\\citep{dayan93improving, barreto2017successor} provide an appealing solution to\nthis generalization problem, but require defining the reward function as linear\nin some grounded feature space. In this paper, we show that these two\ntechniques can be combined, and that each method solves the other's primary\nlimitation. To do so we introduce Variational Intrinsic Successor FeatuRes\n(VISR), a novel algorithm which learns controllable features that can be\nleveraged to provide enhanced generalization and fast task inference through\nthe successor feature framework. We empirically validate VISR on the full Atari\nsuite, in a novel setup wherein the rewards are only exposed briefly after a\nlong unsupervised phase. Achieving human-level performance on 14 games and\nbeating all baselines, we believe VISR represents a step towards agents that\nrapidly learn from limited feedback.\n", "versions": [{"version": "v1", "created": "Wed, 12 Jun 2019 09:39:05 GMT"}, {"version": "v2", "created": "Mon, 27 Jan 2020 18:14:54 GMT"}], "update_date": "2020-01-28", "authors_parsed": [["Hansen", "Steven", ""], ["Dabney", "Will", ""], ["Barreto", "Andre", ""], ["Van de Wiele", "Tom", ""], ["Warde-Farley", "David", ""], ["Mnih", "Volodymyr", ""]]}, {"id": "1906.05066", "submitter": "Nico Potyka", "authors": "Nico Potyka and Sylwia Polberg and Anthony Hunter", "title": "Polynomial-time Updates of Epistemic States in a Fragment of\n  Probabilistic Epistemic Argumentation (Technical Report)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Probabilistic epistemic argumentation allows for reasoning about\nargumentation problems in a way that is well founded by probability theory.\nEpistemic states are represented by probability functions over possible worlds\nand can be adjusted to new beliefs using update operators. While the use of\nprobability functions puts this approach on a solid foundational basis, it also\ncauses computational challenges as the amount of data to process depends\nexponentially on the number of arguments. This leads to bottlenecks in\napplications such as modelling opponent's beliefs for persuasion dialogues. We\nshow how update operators over probability functions can be related to update\noperators over much more compact representations that allow polynomial-time\nupdates. We discuss the cognitive and probabilistic-logical plausibility of\nthis approach and demonstrate its applicability in computational persuasion.\n", "versions": [{"version": "v1", "created": "Wed, 12 Jun 2019 11:39:42 GMT"}], "update_date": "2019-06-13", "authors_parsed": [["Potyka", "Nico", ""], ["Polberg", "Sylwia", ""], ["Hunter", "Anthony", ""]]}, {"id": "1906.05130", "submitter": "Yunlong Liu", "authors": "Yunlong Liu and Jianyang Zheng", "title": "Online Learning and Planning in Partially Observable Domains without\n  Prior Knowledge", "comments": "arXiv admin note: text overlap with arXiv:1904.03008", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  How an agent can act optimally in stochastic, partially observable domains is\na challenge problem, the standard approach to address this issue is to learn\nthe domain model firstly and then based on the learned model to find the (near)\noptimal policy. However, offline learning the model often needs to store the\nentire training data and cannot utilize the data generated in the planning\nphase. Furthermore, current research usually assumes the learned model is\naccurate or presupposes knowledge of the nature of the unobservable part of the\nworld. In this paper, for systems with discrete settings, with the benefits of\nPredictive State Representations~(PSRs), a model-based planning approach is\nproposed where the learning and planning phases can both be executed online and\nno prior knowledge of the underlying system is required. Experimental results\nshow compared to the state-of-the-art approaches, our algorithm achieved a high\nlevel of performance with no prior knowledge provided, along with theoretical\nadvantages of PSRs. Source code is available at\nhttps://github.com/DMU-XMU/PSR-MCTS-Online.\n", "versions": [{"version": "v1", "created": "Tue, 11 Jun 2019 07:06:06 GMT"}], "update_date": "2019-06-13", "authors_parsed": [["Liu", "Yunlong", ""], ["Zheng", "Jianyang", ""]]}, {"id": "1906.05156", "submitter": "Ahmad Kalhor", "authors": "Ahmad Kalhor, Mohsen Saffar, Melika Kheirieh, Somayyeh Hoseinipoor and\n  Babak N. Araabi (University of Tehran, College of Engineering, School of\n  Electrical and Computer Engineering, Tehran, Iran)", "title": "Evaluation of Dataflow through layers of Deep Neural Networks in\n  Classification and Regression Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces two straightforward, effective indices to evaluate the\ninput data and the data flowing through layers of a feedforward deep neural\nnetwork. For classification problems, the separation rate of target labels in\nthe space of dataflow is explained as a key factor indicating the performance\nof designed layers in improving the generalization of the network. According to\nthe explained concept, a shapeless distance-based evaluation index is proposed.\nSimilarly, for regression problems, the smoothness rate of target outputs in\nthe space of dataflow is explained as a key factor indicating the performance\nof designed layers in improving the generalization of the network. According to\nthe explained smoothness concept, a shapeless distance-based smoothness index\nis proposed for regression problems. To consider more strictly concepts of\nseparation and smoothness, their extended versions are introduced, and by\ninterpreting a regression problem as a classification problem, it is shown that\nthe separation and smoothness indices are related together. Through four case\nstudies, the profits of using the introduced indices are shown. In the first\ncase study, for classification and regression problems , the challenging of\nsome known input datasets are compared respectively by the proposed separation\nand smoothness indices. In the second case study, the quality of dataflow is\nevaluated through layers of two pre-trained VGG 16 networks in classification\nof Cifar10 and Cifar100. In the third case study, it is shown that the correct\nclassification rate and the separation index are almost equivalent through\nlayers particularly while the serration index is increased. In the last case\nstudy, two multi-layer neural networks, which are designed for the prediction\nof Boston Housing price, are compared layer by layer by using the proposed\nsmoothness index.\n", "versions": [{"version": "v1", "created": "Wed, 12 Jun 2019 14:16:10 GMT"}], "update_date": "2019-06-14", "authors_parsed": [["Kalhor", "Ahmad", "", "University of Tehran, College of Engineering, School of\n  Electrical and Computer Engineering, Tehran, Iran"], ["Saffar", "Mohsen", "", "University of Tehran, College of Engineering, School of\n  Electrical and Computer Engineering, Tehran, Iran"], ["Kheirieh", "Melika", "", "University of Tehran, College of Engineering, School of\n  Electrical and Computer Engineering, Tehran, Iran"], ["Hoseinipoor", "Somayyeh", "", "University of Tehran, College of Engineering, School of\n  Electrical and Computer Engineering, Tehran, Iran"], ["Araabi", "Babak N.", "", "University of Tehran, College of Engineering, School of\n  Electrical and Computer Engineering, Tehran, Iran"]]}, {"id": "1906.05160", "submitter": "Michael Green", "authors": "Ahmed Khalifa, Michael Cerny Green, Diego Perez-Liebana and Julian\n  Togelius", "title": "General Video Game Rule Generation", "comments": "8 pages, 9 listings, 1 table, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce the General Video Game Rule Generation problem, and the\neponymous software framework which will be used in a new track of the General\nVideo Game AI (GVGAI) competition. The problem is, given a game level as input,\nto generate the rules of a game that fits that level. This can be seen as the\ninverse of the General Video Game Level Generation problem. Conceptualizing\nthese two problems as separate helps breaking the very hard problem of\ngenerating complete games into smaller, more manageable subproblems. The\nproposed framework builds on the GVGAI software and thus asks the rule\ngenerator for rules defined in the Video Game Description Language. We describe\nthe API, and three different rule generators: a random, a constructive and a\nsearch-based generator. Early results indicate that the constructive generator\ngenerates playable and somewhat interesting game rules but has a limited\nexpressive range, whereas the search-based generator generates remarkably\ndiverse rulesets, but with an uneven quality.\n", "versions": [{"version": "v1", "created": "Wed, 12 Jun 2019 14:17:50 GMT"}], "update_date": "2019-06-13", "authors_parsed": [["Khalifa", "Ahmed", ""], ["Green", "Michael Cerny", ""], ["Perez-Liebana", "Diego", ""], ["Togelius", "Julian", ""]]}, {"id": "1906.05175", "submitter": "Alberto Alvarez", "authors": "Alberto Alvarez, Steve Dahlskog, Jose Font, Julian Togelius", "title": "Empowering Quality Diversity in Dungeon Design with Interactive\n  Constrained MAP-Elites", "comments": "8 pages, Accepted and to appear in proceedings of 2019 IEEE\n  Conference on Games, COG 2019", "journal-ref": null, "doi": "10.1109/CIG.2019.8848022", "report-no": null, "categories": "cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose the use of quality-diversity algorithms for mixed-initiative game\ncontent generation. This idea is implemented as a new feature of the\nEvolutionary Dungeon Designer, a system for mixed-initiative design of the type\nof levels you typically find in computer role playing games. The feature uses\nthe MAP-Elites algorithm, an illumination algorithm which divides the\npopulation into a number of cells depending on their values along several\nbehavioral dimensions. Users can flexibly and dynamically choose relevant\ndimensions of variation, and incorporate suggestions produced by the algorithm\nin their map designs. At the same time, any modifications performed by the\nhuman feed back into MAP-Elites, and are used to generate further suggestions.\n", "versions": [{"version": "v1", "created": "Wed, 12 Jun 2019 14:39:07 GMT"}], "update_date": "2020-03-06", "authors_parsed": [["Alvarez", "Alberto", ""], ["Dahlskog", "Steve", ""], ["Font", "Jose", ""], ["Togelius", "Julian", ""]]}, {"id": "1906.05210", "submitter": "Yichen Jiang", "authors": "Yichen Jiang, Nitish Joshi, Yen-Chun Chen, Mohit Bansal", "title": "Explore, Propose, and Assemble: An Interpretable Model for Multi-Hop\n  Reading Comprehension", "comments": "ACL 2019 (12 pages)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-hop reading comprehension requires the model to explore and connect\nrelevant information from multiple sentences/documents in order to answer the\nquestion about the context. To achieve this, we propose an interpretable\n3-module system called Explore-Propose-Assemble reader (EPAr). First, the\nDocument Explorer iteratively selects relevant documents and represents\ndivergent reasoning chains in a tree structure so as to allow assimilating\ninformation from all chains. The Answer Proposer then proposes an answer from\nevery root-to-leaf path in the reasoning tree. Finally, the Evidence Assembler\nextracts a key sentence containing the proposed answer from every path and\ncombines them to predict the final answer. Intuitively, EPAr approximates the\ncoarse-to-fine-grained comprehension behavior of human readers when facing\nmultiple long documents. We jointly optimize our 3 modules by minimizing the\nsum of losses from each stage conditioned on the previous stage's output. On\ntwo multi-hop reading comprehension datasets WikiHop and MedHop, our EPAr model\nachieves significant improvements over the baseline and competitive results\ncompared to the state-of-the-art model. We also present multiple\nreasoning-chain-recovery tests and ablation studies to demonstrate our system's\nability to perform interpretable and accurate reasoning.\n", "versions": [{"version": "v1", "created": "Wed, 12 Jun 2019 15:26:59 GMT"}], "update_date": "2019-06-13", "authors_parsed": [["Jiang", "Yichen", ""], ["Joshi", "Nitish", ""], ["Chen", "Yen-Chun", ""], ["Bansal", "Mohit", ""]]}, {"id": "1906.05243", "submitter": "Hado van Hasselt", "authors": "Hado van Hasselt, Matteo Hessel, John Aslanides", "title": "When to use parametric models in reinforcement learning?", "comments": null, "journal-ref": "NeurIPS 2019", "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We examine the question of when and how parametric models are most useful in\nreinforcement learning. In particular, we look at commonalities and differences\nbetween parametric models and experience replay. Replay-based learning\nalgorithms share important traits with model-based approaches, including the\nability to plan: to use more computation without additional data to improve\npredictions and behaviour. We discuss when to expect benefits from either\napproach, and interpret prior work in this context. We hypothesise that, under\nsuitable conditions, replay-based algorithms should be competitive to or better\nthan model-based algorithms if the model is used only to generate fictional\ntransitions from observed states for an update rule that is otherwise\nmodel-free. We validated this hypothesis on Atari 2600 video games. The\nreplay-based algorithm attained state-of-the-art data efficiency, improving\nover prior results with parametric models.\n", "versions": [{"version": "v1", "created": "Wed, 12 Jun 2019 16:57:00 GMT"}], "update_date": "2019-09-18", "authors_parsed": [["van Hasselt", "Hado", ""], ["Hessel", "Matteo", ""], ["Aslanides", "John", ""]]}, {"id": "1906.05253", "submitter": "Benjamin Eysenbach", "authors": "Benjamin Eysenbach, Ruslan Salakhutdinov, Sergey Levine", "title": "Search on the Replay Buffer: Bridging Planning and Reinforcement\n  Learning", "comments": "Run our algorithm in your browser: http://bit.ly/rl_search", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The history of learning for control has been an exciting back and forth\nbetween two broad classes of algorithms: planning and reinforcement learning.\nPlanning algorithms effectively reason over long horizons, but assume access to\na local policy and distance metric over collision-free paths. Reinforcement\nlearning excels at learning policies and the relative values of states, but\nfails to plan over long horizons. Despite the successes of each method in\nvarious domains, tasks that require reasoning over long horizons with limited\nfeedback and high-dimensional observations remain exceedingly challenging for\nboth planning and reinforcement learning algorithms. Frustratingly, these sorts\nof tasks are potentially the most useful, as they are simple to design (a human\nonly need to provide an example goal state) and avoid reward shaping, which can\nbias the agent towards finding a sub-optimal solution. We introduce a general\ncontrol algorithm that combines the strengths of planning and reinforcement\nlearning to effectively solve these tasks. Our aim is to decompose the task of\nreaching a distant goal state into a sequence of easier tasks, each of which\ncorresponds to reaching a subgoal. Planning algorithms can automatically find\nthese waypoints, but only if provided with suitable abstractions of the\nenvironment -- namely, a graph consisting of nodes and edges. Our main insight\nis that this graph can be constructed via reinforcement learning, where a\ngoal-conditioned value function provides edge weights, and nodes are taken to\nbe previously seen observations in a replay buffer. Using graph search over our\nreplay buffer, we can automatically generate this sequence of subgoals, even in\nimage-based environments. Our algorithm, search on the replay buffer (SoRB),\nenables agents to solve sparse reward tasks over one hundred steps, and\ngeneralizes substantially better than standard RL algorithms.\n", "versions": [{"version": "v1", "created": "Wed, 12 Jun 2019 17:24:03 GMT"}], "update_date": "2019-06-13", "authors_parsed": [["Eysenbach", "Benjamin", ""], ["Salakhutdinov", "Ruslan", ""], ["Levine", "Sergey", ""]]}, {"id": "1906.05274", "submitter": "Benjamin Eysenbach", "authors": "Lisa Lee, Benjamin Eysenbach, Emilio Parisotto, Eric Xing, Sergey\n  Levine, Ruslan Salakhutdinov", "title": "Efficient Exploration via State Marginal Matching", "comments": "Videos and code:\n  https://sites.google.com/view/state-marginal-matching", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Exploration is critical to a reinforcement learning agent's performance in\nits given environment. Prior exploration methods are often based on using\nheuristic auxiliary predictions to guide policy behavior, lacking a\nmathematically-grounded objective with clear properties. In contrast, we recast\nexploration as a problem of State Marginal Matching (SMM), where we aim to\nlearn a policy for which the state marginal distribution matches a given target\nstate distribution. The target distribution is a uniform distribution in most\ncases, but can incorporate prior knowledge if available. In effect, SMM\namortizes the cost of learning to explore in a given environment. The SMM\nobjective can be viewed as a two-player, zero-sum game between a state density\nmodel and a parametric policy, an idea that we use to build an algorithm for\noptimizing the SMM objective. Using this formalism, we further demonstrate that\nprior work approximately maximizes the SMM objective, offering an explanation\nfor the success of these methods. On both simulated and real-world tasks, we\ndemonstrate that agents that directly optimize the SMM objective explore faster\nand adapt more quickly to new tasks as compared to prior exploration methods.\n", "versions": [{"version": "v1", "created": "Wed, 12 Jun 2019 17:57:02 GMT"}, {"version": "v2", "created": "Fri, 4 Oct 2019 13:17:24 GMT"}, {"version": "v3", "created": "Fri, 28 Feb 2020 16:02:59 GMT"}], "update_date": "2020-03-02", "authors_parsed": [["Lee", "Lisa", ""], ["Eysenbach", "Benjamin", ""], ["Parisotto", "Emilio", ""], ["Xing", "Eric", ""], ["Levine", "Sergey", ""], ["Salakhutdinov", "Ruslan", ""]]}, {"id": "1906.05317", "submitter": "Antoine Bosselut", "authors": "Antoine Bosselut, Hannah Rashkin, Maarten Sap, Chaitanya Malaviya,\n  Asli Celikyilmaz, Yejin Choi", "title": "COMET: Commonsense Transformers for Automatic Knowledge Graph\n  Construction", "comments": "Accepted to ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present the first comprehensive study on automatic knowledge base\nconstruction for two prevalent commonsense knowledge graphs: ATOMIC (Sap et\nal., 2019) and ConceptNet (Speer et al., 2017). Contrary to many conventional\nKBs that store knowledge with canonical templates, commonsense KBs only store\nloosely structured open-text descriptions of knowledge. We posit that an\nimportant step toward automatic commonsense completion is the development of\ngenerative models of commonsense knowledge, and propose COMmonsEnse\nTransformers (COMET) that learn to generate rich and diverse commonsense\ndescriptions in natural language. Despite the challenges of commonsense\nmodeling, our investigation reveals promising results when implicit knowledge\nfrom deep pre-trained language models is transferred to generate explicit\nknowledge in commonsense knowledge graphs. Empirical results demonstrate that\nCOMET is able to generate novel knowledge that humans rate as high quality,\nwith up to 77.5% (ATOMIC) and 91.7% (ConceptNet) precision at top 1, which\napproaches human performance for these resources. Our findings suggest that\nusing generative commonsense models for automatic commonsense KB completion\ncould soon be a plausible alternative to extractive methods.\n", "versions": [{"version": "v1", "created": "Wed, 12 Jun 2019 18:11:20 GMT"}, {"version": "v2", "created": "Fri, 14 Jun 2019 20:13:16 GMT"}], "update_date": "2019-06-18", "authors_parsed": [["Bosselut", "Antoine", ""], ["Rashkin", "Hannah", ""], ["Sap", "Maarten", ""], ["Malaviya", "Chaitanya", ""], ["Celikyilmaz", "Asli", ""], ["Choi", "Yejin", ""]]}, {"id": "1906.05329", "submitter": "Tom Jurgenson", "authors": "Tom Jurgenson, Edward Groshev, Aviv Tamar", "title": "Sub-Goal Trees -- a Framework for Goal-Directed Trajectory Prediction\n  and Optimization", "comments": "15 pages (8 main), 2 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many AI problems, in robotics and other domains, are goal-directed,\nessentially seeking a trajectory leading to some goal state. In such problems,\nthe way we choose to represent a trajectory underlies algorithms for trajectory\nprediction and optimization. Interestingly, most all prior work in imitation\nand reinforcement learning builds on a sequential trajectory representation --\ncalculating the next state in the trajectory given its predecessors. We propose\na different perspective: a goal-conditioned trajectory can be represented by\nfirst selecting an intermediate state between start and goal, partitioning the\ntrajectory into two. Then, recursively, predicting intermediate points on each\nsub-segment, until a complete trajectory is obtained. We call this\nrepresentation a sub-goal tree, and building on it, we develop new methods for\ntrajectory prediction, learning, and optimization. We show that in a supervised\nlearning setting, sub-goal trees better account for trajectory variability, and\ncan predict trajectories exponentially faster at test time by leveraging a\nconcurrent computation. Then, for optimization, we derive a new dynamic\nprogramming equation for sub-goal trees, and use it to develop new planning and\nreinforcement learning algorithms. These algorithms, which are not based on the\nstandard Bellman equation, naturally account for hierarchical sub-goal\nstructure in a task. Empirical results on motion planning domains show that the\nsub-goal tree framework significantly improves both accuracy and prediction\ntime.\n", "versions": [{"version": "v1", "created": "Wed, 12 Jun 2019 19:06:51 GMT"}], "update_date": "2019-06-14", "authors_parsed": [["Jurgenson", "Tom", ""], ["Groshev", "Edward", ""], ["Tamar", "Aviv", ""]]}, {"id": "1906.05373", "submitter": "Victor Zhong", "authors": "Victor Zhong and Luke Zettlemoyer", "title": "E3: Entailment-driven Extracting and Editing for Conversational Machine\n  Reading", "comments": "Published at the Annual Meeting of the Association for Computational\n  Linguistics (ACL) 2019. Source code: https://github.com/vzhong/e3. 10 pages,\n  5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conversational machine reading systems help users answer high-level questions\n(e.g. determine if they qualify for particular government benefits) when they\ndo not know the exact rules by which the determination is made(e.g. whether\nthey need certain income levels or veteran status). The key challenge is that\nthese rules are only provided in the form of a procedural text (e.g. guidelines\nfrom government website) which the system must read to figure out what to ask\nthe user. We present a new conversational machine reading model that jointly\nextracts a set of decision rules from the procedural text while reasoning about\nwhich are entailed by the conversational history and which still need to be\nedited to create questions for the user. On the recently introduced ShARC\nconversational machine reading dataset, our Entailment-driven Extract and Edit\nnetwork (E3) achieves a new state-of-the-art, outperforming existing systems as\nwell as a new BERT-based baseline. In addition, by explicitly highlighting\nwhich information still needs to be gathered, E3 provides a more explainable\nalternative to prior work. We release source code for our models and\nexperiments at https://github.com/vzhong/e3.\n", "versions": [{"version": "v1", "created": "Wed, 12 Jun 2019 20:49:48 GMT"}, {"version": "v2", "created": "Thu, 13 Feb 2020 06:20:11 GMT"}], "update_date": "2020-02-14", "authors_parsed": [["Zhong", "Victor", ""], ["Zettlemoyer", "Luke", ""]]}, {"id": "1906.05374", "submitter": "Sarah Bechtle", "authors": "Sarah Bechtle, Artem Molchanov, Yevgen Chebotar, Edward Grefenstette,\n  Ludovic Righetti, Gaurav Sukhatme, Franziska Meier", "title": "Meta-Learning via Learned Loss", "comments": "Project website with code and video at\n  https://sites.google.com/view/mlthree", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Typically, loss functions, regularization mechanisms and other important\naspects of training parametric models are chosen heuristically from a limited\nset of options. In this paper, we take the first step towards automating this\nprocess, with the view of producing models which train faster and more\nrobustly. Concretely, we present a meta-learning method for learning parametric\nloss functions that can generalize across different tasks and model\narchitectures. We develop a pipeline for meta-training such loss functions,\ntargeted at maximizing the performance of the model trained under them. The\nloss landscape produced by our learned losses significantly improves upon the\noriginal task-specific losses in both supervised and reinforcement learning\ntasks. Furthermore, we show that our meta-learning framework is flexible enough\nto incorporate additional information at meta-train time. This information\nshapes the learned loss function such that the environment does not need to\nprovide this information during meta-test time. We make our code available at\nhttps://sites.google.com/view/mlthree.\n", "versions": [{"version": "v1", "created": "Wed, 12 Jun 2019 20:55:18 GMT"}, {"version": "v2", "created": "Tue, 1 Oct 2019 01:44:23 GMT"}, {"version": "v3", "created": "Tue, 18 Feb 2020 22:48:48 GMT"}, {"version": "v4", "created": "Tue, 19 Jan 2021 17:00:54 GMT"}], "update_date": "2021-01-20", "authors_parsed": [["Bechtle", "Sarah", ""], ["Molchanov", "Artem", ""], ["Chebotar", "Yevgen", ""], ["Grefenstette", "Edward", ""], ["Righetti", "Ludovic", ""], ["Sukhatme", "Gaurav", ""], ["Meier", "Franziska", ""]]}, {"id": "1906.05381", "submitter": "Brenden Lake", "authors": "Brenden M. Lake", "title": "Compositional generalization through meta sequence-to-sequence learning", "comments": "This paper appears in the 33rd Conference on Neural Information\n  Processing Systems (NeurIPS 2019), Vancouver, Canada", "journal-ref": "Advances in Neural Information Processing Systems 33 (2019)", "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  People can learn a new concept and use it compositionally, understanding how\nto \"blicket twice\" after learning how to \"blicket.\" In contrast, powerful\nsequence-to-sequence (seq2seq) neural networks fail such tests of\ncompositionality, especially when composing new concepts together with existing\nconcepts. In this paper, I show how memory-augmented neural networks can be\ntrained to generalize compositionally through meta seq2seq learning. In this\napproach, models train on a series of seq2seq problems to acquire the\ncompositional skills needed to solve new seq2seq problems. Meta se2seq learning\nsolves several of the SCAN tests for compositional learning and can learn to\napply implicit rules to variables.\n", "versions": [{"version": "v1", "created": "Wed, 12 Jun 2019 21:25:09 GMT"}, {"version": "v2", "created": "Tue, 8 Oct 2019 22:03:19 GMT"}], "update_date": "2019-10-10", "authors_parsed": [["Lake", "Brenden M.", ""]]}, {"id": "1906.05433", "submitter": "David Rolnick", "authors": "David Rolnick, Priya L. Donti, Lynn H. Kaack, Kelly Kochanski,\n  Alexandre Lacoste, Kris Sankaran, Andrew Slavin Ross, Nikola\n  Milojevic-Dupont, Natasha Jaques, Anna Waldman-Brown, Alexandra Luccioni,\n  Tegan Maharaj, Evan D. Sherwin, S. Karthik Mukkavilli, Konrad P. Kording,\n  Carla Gomes, Andrew Y. Ng, Demis Hassabis, John C. Platt, Felix Creutzig,\n  Jennifer Chayes, Yoshua Bengio", "title": "Tackling Climate Change with Machine Learning", "comments": "For additional resources, please visit the website that accompanies\n  this paper: https://www.climatechange.ai/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Climate change is one of the greatest challenges facing humanity, and we, as\nmachine learning experts, may wonder how we can help. Here we describe how\nmachine learning can be a powerful tool in reducing greenhouse gas emissions\nand helping society adapt to a changing climate. From smart grids to disaster\nmanagement, we identify high impact problems where existing gaps can be filled\nby machine learning, in collaboration with other fields. Our recommendations\nencompass exciting research questions as well as promising business\nopportunities. We call on the machine learning community to join the global\neffort against climate change.\n", "versions": [{"version": "v1", "created": "Mon, 10 Jun 2019 17:51:47 GMT"}, {"version": "v2", "created": "Tue, 5 Nov 2019 17:37:20 GMT"}], "update_date": "2019-11-06", "authors_parsed": [["Rolnick", "David", ""], ["Donti", "Priya L.", ""], ["Kaack", "Lynn H.", ""], ["Kochanski", "Kelly", ""], ["Lacoste", "Alexandre", ""], ["Sankaran", "Kris", ""], ["Ross", "Andrew Slavin", ""], ["Milojevic-Dupont", "Nikola", ""], ["Jaques", "Natasha", ""], ["Waldman-Brown", "Anna", ""], ["Luccioni", "Alexandra", ""], ["Maharaj", "Tegan", ""], ["Sherwin", "Evan D.", ""], ["Mukkavilli", "S. Karthik", ""], ["Kording", "Konrad P.", ""], ["Gomes", "Carla", ""], ["Ng", "Andrew Y.", ""], ["Hassabis", "Demis", ""], ["Platt", "John C.", ""], ["Creutzig", "Felix", ""], ["Chayes", "Jennifer", ""], ["Bengio", "Yoshua", ""]]}, {"id": "1906.05516", "submitter": "Mojtaba Moattari", "authors": "Mojtaba Moattari, Emad Roshandel, Shima Kamyab, Zohreh Azimifar", "title": "A New Approach for Optimizing Highly Nonlinear Problems Based on the\n  Observer Effect Concept", "comments": "29 pages, 10 figures, 9 pages, 11 formulas", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A lot of real-world engineering problems represent dynamicity with nests of\nnonlinearities due to highly complex network of exponential functions or large\nnumber of differential equations interacting together. Such search spaces are\nprovided with multiple convex regions peaked with diverse nonlinear slopes and\nin non-homogenous ways. To find global optima, a new meta-heuristic algorithm\nis proposed based on Observer Effect concepts for controlling memory usage per\nlocalities without pursuing Tabu-like cut-off approaches. Observer effect in\nphysics (or psychology) regards bias in measurement (or perception) due to the\ninterference of instrument (or knowledge). Performance analysis of the proposed\nalgorithms is sought in two real-world engineering applications, i.e.,\nElectroencephalogram feature learning and Distributed Generator parameter\ntuning, each of which having nonlinearity and complex multi-modal peaks\ndistributions as their characteristics. In addition, the effect of version\nimprovement has been assessed. The performance comparison with other optimizers\nin the same context suggests that proposed algorithm is useful both solely and\nin hybrid Gradient Descent settings where problem's search space is\nnonhomogeneous in terms of local peaks density.\n", "versions": [{"version": "v1", "created": "Thu, 13 Jun 2019 07:29:22 GMT"}, {"version": "v2", "created": "Wed, 6 May 2020 17:00:26 GMT"}], "update_date": "2020-05-07", "authors_parsed": [["Moattari", "Mojtaba", ""], ["Roshandel", "Emad", ""], ["Kamyab", "Shima", ""], ["Azimifar", "Zohreh", ""]]}, {"id": "1906.05651", "submitter": "Pushpendre Rastogi", "authors": "Pushpendre Rastogi", "title": "Representation Learning for Words and Entities", "comments": "phd thesis, Machine Learning, Natural Language Processing,\n  Representation Learning, Knowledge Graphs, Entities, Word Embeddings, Entity\n  Embeddings", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This thesis presents new methods for unsupervised learning of distributed\nrepresentations of words and entities from text and knowledge bases. The first\nalgorithm presented in the thesis is a multi-view algorithm for learning\nrepresentations of words called Multiview Latent Semantic Analysis (MVLSA). By\nincorporating up to 46 different types of co-occurrence statistics for the same\nvocabulary of english words, I show that MVLSA outperforms other\nstate-of-the-art word embedding models. Next, I focus on learning entity\nrepresentations for search and recommendation and present the second method of\nthis thesis, Neural Variational Set Expansion (NVSE). NVSE is also an\nunsupervised learning method, but it is based on the Variational Autoencoder\nframework. Evaluations with human annotators show that NVSE can facilitate\nbetter search and recommendation of information gathered from noisy, automatic\nannotation of unstructured natural language corpora. Finally, I move from\nunstructured data and focus on structured knowledge graphs. I present novel\napproaches for learning embeddings of vertices and edges in a knowledge graph\nthat obey logical constraints.\n", "versions": [{"version": "v1", "created": "Wed, 12 Jun 2019 17:29:22 GMT"}], "update_date": "2019-06-14", "authors_parsed": [["Rastogi", "Pushpendre", ""]]}, {"id": "1906.05670", "submitter": "Sheng Lin", "authors": "Sheng Lin, Luye Zheng, Bo Chen, Siliang Tang, Yueting Zhuang, Fei Wu,\n  Zhigang Chen, Guoping Hu, Xiang Ren", "title": "KCAT: A Knowledge-Constraint Typing Annotation Tool", "comments": "6 pages, acl2019 demo paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fine-grained Entity Typing is a tough task which suffers from noise samples\nextracted from distant supervision. Thousands of manually annotated samples can\nachieve greater performance than millions of samples generated by the previous\ndistant supervision method. Whereas, it's hard for human beings to\ndifferentiate and memorize thousands of types, thus making large-scale human\nlabeling hardly possible. In this paper, we introduce a Knowledge-Constraint\nTyping Annotation Tool (KCAT), which is efficient for fine-grained entity\ntyping annotation. KCAT reduces the size of candidate types to an acceptable\nrange for human beings through entity linking and provides a Multi-step Typing\nscheme to revise the entity linking result. Moreover, KCAT provides an\nefficient Annotator Client to accelerate the annotation process and a\ncomprehensive Manager Module to analyse crowdsourcing annotations. Experiment\nshows that KCAT can significantly improve annotation efficiency, the time\nconsumption increases slowly as the size of type set expands.\n", "versions": [{"version": "v1", "created": "Thu, 13 Jun 2019 13:33:22 GMT"}], "update_date": "2019-06-14", "authors_parsed": [["Lin", "Sheng", ""], ["Zheng", "Luye", ""], ["Chen", "Bo", ""], ["Tang", "Siliang", ""], ["Zhuang", "Yueting", ""], ["Wu", "Fei", ""], ["Chen", "Zhigang", ""], ["Hu", "Guoping", ""], ["Ren", "Xiang", ""]]}, {"id": "1906.05676", "submitter": "Guoyang Chen", "authors": "Xinli Cai, Peng Zhou, Shuhan Ding, Guoyang Chen, Weifeng Zhang", "title": "Sionnx: Automatic Unit Test Generator for ONNX Conformance", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Open Neural Network Exchange (ONNX) is an open format to represent AI models\nand is supported by many machine learning frameworks. While ONNX defines\nunified and portable computation operators across various frameworks, the\nconformance tests for those operators are insufficient, which makes it\ndifficult to verify if an operator's behavior in an ONNX backend implementation\ncomplies with the ONNX standard. In this paper, we present the first automatic\nunit test generator named Sionnx for verifying the compliance of ONNX\nimplementation. First, we propose a compact yet complete set of rules to\ndescribe the operator's attributes and the properties of its operands. Second,\nwe design an Operator Specification Language (OSL) to provide a high-level\ndescription for the operator's syntax. Finally, through this easy-to-use\nspecification language, we are able to build a full testing specification which\nleverages LLVM TableGen to automatically generate unit tests for ONNX operators\nwith much large coverage. Sionnx is lightweight and flexible to support\ncross-framework verification. The Sionnx framework is open-sourced in the\ngithub repository (https://github.com/alibaba/Sionnx).\n", "versions": [{"version": "v1", "created": "Wed, 12 Jun 2019 02:59:16 GMT"}], "update_date": "2019-06-14", "authors_parsed": [["Cai", "Xinli", ""], ["Zhou", "Peng", ""], ["Ding", "Shuhan", ""], ["Chen", "Guoyang", ""], ["Zhang", "Weifeng", ""]]}, {"id": "1906.05684", "submitter": "David Leslie", "authors": "David Leslie", "title": "Understanding artificial intelligence ethics and safety", "comments": null, "journal-ref": "The Alan Turing Institute (June, 2019)", "doi": "10.5281/zenodo.3240529", "report-no": null, "categories": "cs.CY cs.AI cs.LG stat.AP", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  A remarkable time of human promise has been ushered in by the convergence of\nthe ever-expanding availability of big data, the soaring speed and stretch of\ncloud computing platforms, and the advancement of increasingly sophisticated\nmachine learning algorithms. Innovations in AI are already leaving a mark on\ngovernment by improving the provision of essential social goods and services\nfrom healthcare, education, and transportation to food supply, energy, and\nenvironmental management. These bounties are likely just the start. The\nprospect that progress in AI will help government to confront some of its most\nurgent challenges is exciting, but legitimate worries abound. As with any new\nand rapidly evolving technology, a steep learning curve means that mistakes and\nmiscalculations will be made and that both unanticipated and harmful impacts\nwill occur.\n  This guide, written for department and delivery leads in the UK public sector\nand adopted by the British Government in its publication, 'Using AI in the\nPublic Sector,' identifies the potential harms caused by AI systems and\nproposes concrete, operationalisable measures to counteract them. It stresses\nthat public sector organisations can anticipate and prevent these potential\nharms by stewarding a culture of responsible innovation and by putting in place\ngovernance processes that support the design and implementation of ethical,\nfair, and safe AI systems. It also highlights the need for algorithmically\nsupported outcomes to be interpretable by their users and made understandable\nto decision subjects in clear, non-technical, and accessible ways. Finally, it\nbuilds out a vision of human-centred and context-sensitive implementation that\ngives a central role to communication, evidence-based reasoning, situational\nawareness, and moral justifiability.\n", "versions": [{"version": "v1", "created": "Tue, 11 Jun 2019 22:14:07 GMT"}], "update_date": "2019-06-14", "authors_parsed": [["Leslie", "David", ""]]}, {"id": "1906.05691", "submitter": "Masaru Isonuma", "authors": "Masaru Isonuma, Junichiro Mori, Ichiro Sakata", "title": "Unsupervised Neural Single-Document Summarization of Reviews via\n  Learning Latent Discourse Structure and its Ranking", "comments": "13 pages, ACL 2019 (long paper)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper focuses on the end-to-end abstractive summarization of a single\nproduct review without supervision. We assume that a review can be described as\na discourse tree, in which the summary is the root, and the child sentences\nexplain their parent in detail. By recursively estimating a parent from its\nchildren, our model learns the latent discourse tree without an external parser\nand generates a concise summary. We also introduce an architecture that ranks\nthe importance of each sentence on the tree to support summary generation\nfocusing on the main review point. The experimental results demonstrate that\nour model is competitive with or outperforms other unsupervised approaches. In\nparticular, for relatively long reviews, it achieves a competitive or better\nperformance than supervised models. The induced tree shows that the child\nsentences provide additional information about their parent, and the generated\nsummary abstracts the entire review.\n", "versions": [{"version": "v1", "created": "Thu, 13 Jun 2019 13:53:10 GMT"}], "update_date": "2019-06-14", "authors_parsed": [["Isonuma", "Masaru", ""], ["Mori", "Junichiro", ""], ["Sakata", "Ichiro", ""]]}, {"id": "1906.05799", "submitter": "Thanh Thi Nguyen", "authors": "Thanh Thi Nguyen and Vijay Janapa Reddi", "title": "Deep Reinforcement Learning for Cyber Security", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The scale of Internet-connected systems has increased considerably, and these\nsystems are being exposed to cyber attacks more than ever. The complexity and\ndynamics of cyber attacks require protecting mechanisms to be responsive,\nadaptive, and scalable. Machine learning, or more specifically deep\nreinforcement learning (DRL), methods have been proposed widely to address\nthese issues. By incorporating deep learning into traditional RL, DRL is highly\ncapable of solving complex, dynamic, and especially high-dimensional cyber\ndefense problems. This paper presents a survey of DRL approaches developed for\ncyber security. We touch on different vital aspects, including DRL-based\nsecurity methods for cyber-physical systems, autonomous intrusion detection\ntechniques, and multi-agent DRL-based game theory simulations for defense\nstrategies against cyber attacks. Extensive discussions and future research\ndirections on DRL-based cyber security are also given. We expect that this\ncomprehensive review provides the foundations for and facilitates future\nstudies on exploring the potential of emerging DRL to cope with increasingly\ncomplex cyber security problems.\n", "versions": [{"version": "v1", "created": "Thu, 13 Jun 2019 16:34:12 GMT"}, {"version": "v2", "created": "Thu, 20 Jun 2019 17:55:14 GMT"}, {"version": "v3", "created": "Tue, 21 Jul 2020 10:06:00 GMT"}], "update_date": "2020-07-22", "authors_parsed": [["Nguyen", "Thanh Thi", ""], ["Reddi", "Vijay Janapa", ""]]}, {"id": "1906.05833", "submitter": "Barry Smith", "authors": "J. Landgrebe and B. Smith", "title": "There is no Artificial General Intelligence", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The goal of creating Artificial General Intelligence (AGI) -- or in other\nwords of creating Turing machines (modern computers) that can behave in a way\nthat mimics human intelligence -- has occupied AI researchers ever since the\nidea of AI was first proposed. One common theme in these discussions is the\nthesis that the ability of a machine to conduct convincing dialogues with human\nbeings can serve as at least a sufficient criterion of AGI. We argue that this\nvery ability should be accepted also as a necessary condition of AGI, and we\nprovide a description of the nature of human dialogue in particular and of\nhuman language in general against this background. We then argue that it is for\nmathematical reasons impossible to program a machine in such a way that it\ncould master human dialogue behaviour in its full generality. This is (1)\nbecause there are no traditional explicitly designed mathematical models that\ncould be used as a starting point for creating such programs; and (2) because\neven the sorts of automated models generated by using machine learning, which\nhave been used successfully in areas such as machine translation, cannot be\nextended to cope with human dialogue. If this is so, then we can conclude that\na Turing machine also cannot possess AGI, because it fails to fulfil a\nnecessary condition thereof. At the same time, however, we acknowledge the\npotential of Turing machines to master dialogue behaviour in highly restricted\ncontexts, where what is called ``narrow'' AI can still be of considerable\nutility.\n", "versions": [{"version": "v1", "created": "Sun, 9 Jun 2019 12:42:23 GMT"}, {"version": "v2", "created": "Thu, 28 Nov 2019 20:26:52 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Landgrebe", "J.", ""], ["Smith", "B.", ""]]}, {"id": "1906.05838", "submitter": "Carlos Florensa", "authors": "Yiming Ding, Carlos Florensa, Mariano Phielipp, Pieter Abbeel", "title": "Goal-conditioned Imitation Learning", "comments": "Published at NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Designing rewards for Reinforcement Learning (RL) is challenging because it\nneeds to convey the desired task, be efficient to optimize, and be easy to\ncompute. The latter is particularly problematic when applying RL to robotics,\nwhere detecting whether the desired configuration is reached might require\nconsiderable supervision and instrumentation. Furthermore, we are often\ninterested in being able to reach a wide range of configurations, hence setting\nup a different reward every time might be unpractical. Methods like Hindsight\nExperience Replay (HER) have recently shown promise to learn policies able to\nreach many goals, without the need of a reward. Unfortunately, without tricks\nlike resetting to points along the trajectory, HER might require many samples\nto discover how to reach certain areas of the state-space. In this work we\ninvestigate different approaches to incorporate demonstrations to drastically\nspeed up the convergence to a policy able to reach any goal, also surpassing\nthe performance of an agent trained with other Imitation Learning algorithms.\nFurthermore, we show our method can also be used when the available expert\ntrajectories do not contain the actions, which can leverage kinesthetic or\nthird person demonstration. The code is available at\nhttps://sites.google.com/view/goalconditioned-il/.\n", "versions": [{"version": "v1", "created": "Thu, 13 Jun 2019 17:39:52 GMT"}, {"version": "v2", "created": "Fri, 23 Aug 2019 18:37:00 GMT"}, {"version": "v3", "created": "Wed, 27 May 2020 06:47:07 GMT"}], "update_date": "2020-05-28", "authors_parsed": [["Ding", "Yiming", ""], ["Florensa", "Carlos", ""], ["Phielipp", "Mariano", ""], ["Abbeel", "Pieter", ""]]}, {"id": "1906.05862", "submitter": "Alexander Li", "authors": "Alexander C. Li, Carlos Florensa, Ignasi Clavera, Pieter Abbeel", "title": "Sub-policy Adaptation for Hierarchical Reinforcement Learning", "comments": "ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hierarchical reinforcement learning is a promising approach to tackle\nlong-horizon decision-making problems with sparse rewards. Unfortunately, most\nmethods still decouple the lower-level skill acquisition process and the\ntraining of a higher level that controls the skills in a new task. Leaving the\nskills fixed can lead to significant sub-optimality in the transfer setting. In\nthis work, we propose a novel algorithm to discover a set of skills, and\ncontinuously adapt them along with the higher level even when training on a new\ntask. Our main contributions are two-fold. First, we derive a new hierarchical\npolicy gradient with an unbiased latent-dependent baseline, and we introduce\nHierarchical Proximal Policy Optimization (HiPPO), an on-policy method to\nefficiently train all levels of the hierarchy jointly. Second, we propose a\nmethod for training time-abstractions that improves the robustness of the\nobtained skills to environment changes. Code and results are available at\nsites.google.com/view/hippo-rl\n", "versions": [{"version": "v1", "created": "Thu, 13 Jun 2019 16:59:48 GMT"}, {"version": "v2", "created": "Fri, 15 Nov 2019 23:18:29 GMT"}, {"version": "v3", "created": "Tue, 19 Nov 2019 17:59:41 GMT"}, {"version": "v4", "created": "Wed, 13 May 2020 23:32:41 GMT"}], "update_date": "2020-05-15", "authors_parsed": [["Li", "Alexander C.", ""], ["Florensa", "Carlos", ""], ["Clavera", "Ignasi", ""], ["Abbeel", "Pieter", ""]]}, {"id": "1906.05939", "submitter": "Sotiris Kotitsas", "authors": "Sotiris Kotitsas, Dimitris Pappas, Ion Androutsopoulos, Ryan McDonald\n  and Marianna Apidianaki", "title": "Embedding Biomedical Ontologies by Jointly Encoding Network Structure\n  and Textual Node Descriptors", "comments": "Proceedings of the 18th Workshop on Biomedical Natural Language\n  Processing (BioNLP 2019) of the 57th Annual Meeting of the Association for\n  Computational Linguistics (ACL 2019), Florence, Italy, 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Network Embedding (NE) methods, which map network nodes to low-dimensional\nfeature vectors, have wide applications in network analysis and bioinformatics.\nMany existing NE methods rely only on network structure, overlooking other\ninformation associated with the nodes, e.g., text describing the nodes. Recent\nattempts to combine the two sources of information only consider local network\nstructure. We extend NODE2VEC, a well-known NE method that considers broader\nnetwork structure, to also consider textual node descriptors using recurrent\nneural encoders. Our method is evaluated on link prediction in two networks\nderived from UMLS. Experimental results demonstrate the effectiveness of the\nproposed approach compared to previous work.\n", "versions": [{"version": "v1", "created": "Thu, 13 Jun 2019 21:40:15 GMT"}, {"version": "v2", "created": "Thu, 20 Jun 2019 08:15:57 GMT"}], "update_date": "2019-06-21", "authors_parsed": [["Kotitsas", "Sotiris", ""], ["Pappas", "Dimitris", ""], ["Androutsopoulos", "Ion", ""], ["McDonald", "Ryan", ""], ["Apidianaki", "Marianna", ""]]}, {"id": "1906.05959", "submitter": "Boris Rabinovich", "authors": "Yoni Schamroth, Liron Gat Kahlon, Boris Rabinovich, David Steinberg", "title": "Early Detection of Long Term Evaluation Criteria in Online Controlled\n  Experiments", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A common dilemma encountered by many upon implementing an optimization method\nor experiment, whether it be a reinforcement learning algorithm, or A/B\ntesting, is deciding on what metric to optimize for. Very often short-term\nmetrics, which are easier to measure are chosen over long term metrics which\nhave undesirable time considerations and often a more complex calculation. In\nthis paper, we argue the importance of choosing a metrics that focuses on long\nterm effects. With this comes the necessity in the ability to measure\nsignificant differences between groups relatively early. We present here an\nefficient methodology for early detection of lifetime differences between\ngroups based on bootstrap hypothesis testing of the lifetime forecast of the\nresponse. We present an application of this method in the domain of online\nadvertising and we argue that approach not only allows one to focus on the\nultimate metric of importance but also provides a means of accelerating the\ntesting period.\n", "versions": [{"version": "v1", "created": "Thu, 13 Jun 2019 23:16:18 GMT"}], "update_date": "2019-06-17", "authors_parsed": [["Schamroth", "Yoni", ""], ["Kahlon", "Liron Gat", ""], ["Rabinovich", "Boris", ""], ["Steinberg", "David", ""]]}, {"id": "1906.06047", "submitter": "Rasmus Kr{\\ae}mmer Rendsvig", "authors": "Andr\\'es Occhipinti Liberman, Andreas Achen, Rasmus Kr{\\ae}mmer\n  Rendsvig", "title": "Dynamic Term-Modal Logics for First-Order Epistemic Planning", "comments": null, "journal-ref": null, "doi": "10.1016/j.artint.2020.103305", "report-no": null, "categories": "cs.LO cs.AI cs.MA math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many classical planning frameworks are built on first-order languages. The\nfirst-order expressive power is desirable for compactly representing actions\nvia schemas, and for specifying quantified conditions such as $\\neg\\exists\nx\\mathsf{blocks\\_door}(x)$. In contrast, several recent epistemic planning\nframeworks are built on propositional epistemic logic. The epistemic language\nis useful to describe planning problems involving higher-order reasoning or\nepistemic goals such as $K_{a}\\neg\\mathsf{problem}$.\n  This paper develops a first-order version of Dynamic Epistemic Logic (DEL).\nIn this framework, for example, $\\exists xK_{x}\\exists\ny\\mathsf{blocks\\_door}(y)$ is a formula. The formalism combines the strengths\nof DEL (higher-order reasoning) with those of first-order logic (lifted\nrepresentation) to model multi-agent epistemic planning. The paper introduces\nan epistemic language with a possible-worlds semantics, followed by novel\ndynamics given by first-order action models and their execution via product\nupdates. Taking advantage of the first-order machinery, epistemic action\nschemas are defined to provide compact, problem-independent domain\ndescriptions, in the spirit of PDDL.\n  Concerning metatheory, the paper defines axiomatic normal term-modal logics,\nshows a Canonical Model Theorem-like result which allows establishing\ncompleteness through frame characterization formulas, shows decidability for\nthe finite agent case, and shows a general completeness result for the dynamic\nextension by reduction axioms.\n", "versions": [{"version": "v1", "created": "Fri, 14 Jun 2019 06:51:25 GMT"}, {"version": "v2", "created": "Tue, 2 Jun 2020 22:56:16 GMT"}], "update_date": "2020-06-04", "authors_parsed": [["Liberman", "Andr\u00e9s Occhipinti", ""], ["Achen", "Andreas", ""], ["Rendsvig", "Rasmus Kr\u00e6mmer", ""]]}, {"id": "1906.06062", "submitter": "Guy Lorberbom", "authors": "Guy Lorberbom, Chris J. Maddison, Nicolas Heess, Tamir Hazan, Daniel\n  Tarlow", "title": "Direct Policy Gradients: Direct Optimization of Policies in Discrete\n  Action Spaces", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Direct optimization is an appealing framework that replaces integration with\noptimization of a random objective for approximating gradients in models with\ndiscrete random variables. A$^\\star$ sampling is a framework for optimizing\nsuch random objectives over large spaces. We show how to combine these\ntechniques to yield a reinforcement learning algorithm that approximates a\npolicy gradient by finding trajectories that optimize a random objective. We\ncall the resulting algorithms \"direct policy gradient\" (DirPG) algorithms. A\nmain benefit of DirPG algorithms is that they allow the insertion of domain\nknowledge in the form of upper bounds on return-to-go at training time, like is\nused in heuristic search, while still directly computing a policy gradient. We\nfurther analyze their properties, showing there are cases where DirPG has an\nexponentially larger probability of sampling informative gradients compared to\nREINFORCE. We also show that there is a built-in variance reduction technique\nand that a parameter that was previously viewed as a numerical approximation\ncan be interpreted as controlling risk sensitivity. Empirically, we evaluate\nthe effect of key degrees of freedom and show that the algorithm performs well\nin illustrative domains compared to baselines.\n", "versions": [{"version": "v1", "created": "Fri, 14 Jun 2019 07:50:36 GMT"}, {"version": "v2", "created": "Fri, 23 Oct 2020 08:52:59 GMT"}], "update_date": "2020-10-26", "authors_parsed": [["Lorberbom", "Guy", ""], ["Maddison", "Chris J.", ""], ["Heess", "Nicolas", ""], ["Hazan", "Tamir", ""], ["Tarlow", "Daniel", ""]]}, {"id": "1906.06178", "submitter": "Francesco Foglino", "authors": "Francesco Foglino, Christiano Coletto Christakou, Ricardo Luna\n  Gutierrez, Matteo Leonetti", "title": "Curriculum Learning for Cumulative Return Maximization", "comments": "Proceedings of the 28th International Joint Conference on Artificial\n  Intelligence (IJCAI-19). arXiv admin note: text overlap with arXiv:1901.11478", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Curriculum learning has been successfully used in reinforcement learning to\naccelerate the learning process, through knowledge transfer between tasks of\nincreasing complexity. Critical tasks, in which suboptimal exploratory actions\nmust be minimized, can benefit from curriculum learning, and its ability to\nshape exploration through transfer. We propose a task sequencing algorithm\nmaximizing the cumulative return, that is, the return obtained by the agent\nacross all the learning episodes. By maximizing the cumulative return, the\nagent not only aims at achieving high rewards as fast as possible, but also at\ndoing so while limiting suboptimal actions. We experimentally compare our task\nsequencing algorithm to several popular metaheuristic algorithms for\ncombinatorial optimization, and show that it achieves significantly better\nperformance on the problem of cumulative return maximization. Furthermore, we\nvalidate our algorithm on a critical task, optimizing a home controller for a\nmicro energy grid.\n", "versions": [{"version": "v1", "created": "Thu, 13 Jun 2019 14:38:56 GMT"}], "update_date": "2019-06-17", "authors_parsed": [["Foglino", "Francesco", ""], ["Christakou", "Christiano Coletto", ""], ["Gutierrez", "Ricardo Luna", ""], ["Leonetti", "Matteo", ""]]}, {"id": "1906.06251", "submitter": "Curtis Bright", "authors": "Curtis Bright, J\\\"urgen Gerhard, Ilias Kotsireas, Vijay Ganesh", "title": "Effective problem solving using SAT solvers", "comments": "To appear in Proceedings of the Maple Conference 2019", "journal-ref": null, "doi": "10.1007/978-3-030-41258-6_15", "report-no": null, "categories": "cs.AI cs.LO cs.SC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this article we demonstrate how to solve a variety of problems and puzzles\nusing the built-in SAT solver of the computer algebra system Maple. Once the\nproblems have been encoded into Boolean logic, solutions can be found (or shown\nto not exist) automatically, without the need to implement any search\nalgorithm. In particular, we describe how to solve the $n$-queens problem, how\nto generate and solve Sudoku puzzles, how to solve logic puzzles like the\nEinstein riddle, how to solve the 15-puzzle, how to solve the maximum clique\nproblem, and finding Graeco-Latin squares.\n", "versions": [{"version": "v1", "created": "Fri, 14 Jun 2019 15:32:17 GMT"}, {"version": "v2", "created": "Mon, 16 Sep 2019 17:20:51 GMT"}], "update_date": "2020-03-17", "authors_parsed": [["Bright", "Curtis", ""], ["Gerhard", "J\u00fcrgen", ""], ["Kotsireas", "Ilias", ""], ["Ganesh", "Vijay", ""]]}, {"id": "1906.06273", "submitter": "Hannes Eriksson", "authors": "Hannes Eriksson, Christos Dimitrakakis", "title": "Epistemic Risk-Sensitive Reinforcement Learning", "comments": "8 pages, 2 figures", "journal-ref": "Proceedings of the 28th European Symposium on Artificial Neural\n  Networks, Computational Intelligence and Machine Learning (ESANN 2020)\n  339-344", "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a framework for interacting with uncertain environments in\nreinforcement learning (RL) by leveraging preferences in the form of utility\nfunctions. We claim that there is value in considering different risk measures\nduring learning. In this framework, the preference for risk can be tuned by\nvariation of the parameter $\\beta$ and the resulting behavior can be\nrisk-averse, risk-neutral or risk-taking depending on the parameter choice. We\nevaluate our framework for learning problems with model uncertainty. We measure\nand control for \\emph{epistemic} risk using dynamic programming (DP) and policy\ngradient-based algorithms. The risk-averse behavior is then compared with the\nbehavior of the optimal risk-neutral policy in environments with epistemic\nrisk.\n", "versions": [{"version": "v1", "created": "Fri, 14 Jun 2019 16:25:20 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Eriksson", "Hannes", ""], ["Dimitrakakis", "Christos", ""]]}, {"id": "1906.06275", "submitter": "Mihai Codescu", "authors": "Mihai Codescu and Bernd Krieg-Br\\\"uckner and Till Mossakowski", "title": "Extensions of Generic DOL for Generic Ontology Design Patterns", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generic ontologies were introduced as an extension (Generic DOL) of the\nDistributed Ontology, Modeling and Specification Language, DOL, with the aim to\nprovide a language for Generic Ontology Design Patterns. In this paper we\npresent a number of new language constructs that increase the expressivity and\nthe generality of Generic DOL, among them sequential and optional parameters,\nlist parameters with recursion, and local sub-patterns. These are illustrated\nwith non-trivial patterns: generic value sets and (nested) qualitatively graded\nrelations, demonstrated as definitional building blocks in an application\ndomain.\n", "versions": [{"version": "v1", "created": "Fri, 14 Jun 2019 16:25:43 GMT"}], "update_date": "2019-06-17", "authors_parsed": [["Codescu", "Mihai", ""], ["Krieg-Br\u00fcckner", "Bernd", ""], ["Mossakowski", "Till", ""]]}, {"id": "1906.06321", "submitter": "Simon Du", "authors": "Simon S. Du, Yuping Luo, Ruosong Wang, Hanrui Zhang", "title": "Provably Efficient $Q$-learning with Function Approximation via\n  Distribution Shift Error Checking Oracle", "comments": "In NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  $Q$-learning with function approximation is one of the most popular methods\nin reinforcement learning. Though the idea of using function approximation was\nproposed at least 60 years ago, even in the simplest setup, i.e, approximating\n$Q$-functions with linear functions, it is still an open problem on how to\ndesign a provably efficient algorithm that learns a near-optimal policy. The\nkey challenges are how to efficiently explore the state space and how to decide\nwhen to stop exploring in conjunction with the function approximation scheme.\n  The current paper presents a provably efficient algorithm for $Q$-learning\nwith linear function approximation. Under certain regularity assumptions, our\nalgorithm, Difference Maximization $Q$-learning (DMQ), combined with linear\nfunction approximation, returns a near-optimal policy using a polynomial number\nof trajectories. Our algorithm introduces a new notion, the Distribution Shift\nError Checking (DSEC) oracle. This oracle tests whether there exists a function\nin the function class that predicts well on a distribution $\\mathcal{D}_1$, but\npredicts poorly on another distribution $\\mathcal{D}_2$, where $\\mathcal{D}_1$\nand $\\mathcal{D}_2$ are distributions over states induced by two different\nexploration policies. For the linear function class, this oracle is equivalent\nto solving a top eigenvalue problem. We believe our algorithmic insights,\nespecially the DSEC oracle, are also useful in designing and analyzing\nreinforcement learning algorithms with general function approximation.\n", "versions": [{"version": "v1", "created": "Fri, 14 Jun 2019 17:55:05 GMT"}, {"version": "v2", "created": "Mon, 4 Nov 2019 16:11:13 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Du", "Simon S.", ""], ["Luo", "Yuping", ""], ["Wang", "Ruosong", ""], ["Zhang", "Hanrui", ""]]}, {"id": "1906.06332", "submitter": "Tanik Saikh Mr", "authors": "Dibyanayan Bandyopadhyay, Baban Gain, Tanik Saikh, Asif Ekbal", "title": "IITP at MEDIQA 2019: Systems Report for Natural Language Inference,\n  Question Entailment and Question Answering", "comments": null, "journal-ref": null, "doi": "10.18653/v1/W19-5056", "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents the experiments accomplished as a part of our\nparticipation in the MEDIQA challenge, an (Abacha et al., 2019) shared task. We\nparticipated in all the three tasks defined in this particular shared task. The\ntasks are viz. i. Natural Language Inference (NLI) ii. Recognizing Question\nEntailment(RQE) and their application in medical Question Answering (QA). We\nsubmitted runs using multiple deep learning based systems (runs) for each of\nthese three tasks. We submitted five system results in each of the NLI and RQE\ntasks, and four system results for the QA task. The systems yield encouraging\nresults in all three tasks. The highest performance obtained in NLI, RQE and QA\ntasks are 81.8%, 53.2%, and 71.7%, respectively.\n", "versions": [{"version": "v1", "created": "Fri, 14 Jun 2019 06:38:33 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Bandyopadhyay", "Dibyanayan", ""], ["Gain", "Baban", ""], ["Saikh", "Tanik", ""], ["Ekbal", "Asif", ""]]}, {"id": "1906.06375", "submitter": "Camila P.S. Tautenhain", "authors": "Camila P. S. Tautenhain, Ana Paula Barbosa-Povoa, Bruna Mota, Mari\\'a\n  C. V. Nascimento", "title": "An efficient Lagrangian-based heuristic to solve a multi-objective\n  sustainable supply chain problem", "comments": "45 pages. Paper accepted to European Journal of Operational Research", "journal-ref": null, "doi": "10.1016/j.ejor.2021.01.008", "report-no": null, "categories": "math.OC cs.AI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Sustainable Supply Chain (SSC) management aims at integrating economic,\nenvironmental and social goals to assist in the long-term planning of a company\nand its supply chains. There is no consensus in the literature as to whether\nsocial and environmental responsibilities are profit-compatible. However, the\nconflicting nature of these goals is explicit when considering specific\nassessment measures and, in this scenario, multi-objective optimization is a\nway to represent problems that simultaneously optimize the goals. This paper\nproposes a Lagrangian matheuristic method, called $AugMathLagr$, to solve a\nhard and relevant multi-objective problem found in the literature.\n$AugMathLagr$ was extensively tested using artificial instances defined by a\ngenerator presented in this paper. The results show a competitive performance\nof $AugMathLagr$ when compared with an exact multi-objective method limited by\ntime and a matheuristic recently proposed in the literature and adapted here to\naddress the studied problem. In addition, computational results on a case study\nare presented and analyzed, and demonstrate the outstanding performance of\n$AugMathLagr$.\n", "versions": [{"version": "v1", "created": "Fri, 14 Jun 2019 19:29:03 GMT"}, {"version": "v2", "created": "Thu, 7 Jan 2021 22:38:54 GMT"}], "update_date": "2021-01-11", "authors_parsed": [["Tautenhain", "Camila P. S.", ""], ["Barbosa-Povoa", "Ana Paula", ""], ["Mota", "Bruna", ""], ["Nascimento", "Mari\u00e1 C. V.", ""]]}, {"id": "1906.06397", "submitter": "Rohan Paleja", "authors": "Rohan Paleja, Andrew Silva, Letian Chen, Matthew Gombolay", "title": "Interpretable and Personalized Apprenticeship Scheduling: Learning\n  Interpretable Scheduling Policies from Heterogeneous User Demonstrations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Resource scheduling and coordination is an NP-hard optimization requiring an\nefficient allocation of agents to a set of tasks with upper- and lower bound\ntemporal and resource constraints. Due to the large-scale and dynamic nature of\nresource coordination in hospitals and factories, human domain experts manually\nplan and adjust schedules on the fly. To perform this job, domain experts\nleverage heterogeneous strategies and rules-of-thumb honed over years of\napprenticeship. What is critically needed is the ability to extract this domain\nknowledge in a heterogeneous and interpretable apprenticeship learning\nframework to scale beyond the power of a single human expert, a necessity in\nsafety-critical domains. We propose a personalized and interpretable\napprenticeship scheduling algorithm that infers an interpretable representation\nof all human task demonstrators by extracting decision-making criteria via an\ninferred, personalized embedding non-parametric in the number of demonstrator\ntypes. We achieve near-perfect LfD accuracy in synthetic domains and 88.22\\%\naccuracy on a planning domain with real-world, outperforming baselines.\nFinally, our user study showed our methodology produces more interpretable and\neasier-to-use models than neural networks ($p < 0.05$).\n", "versions": [{"version": "v1", "created": "Fri, 14 Jun 2019 20:51:01 GMT"}, {"version": "v2", "created": "Mon, 27 Jan 2020 02:37:36 GMT"}, {"version": "v3", "created": "Wed, 21 Oct 2020 17:44:43 GMT"}, {"version": "v4", "created": "Thu, 5 Nov 2020 03:10:53 GMT"}], "update_date": "2020-11-06", "authors_parsed": [["Paleja", "Rohan", ""], ["Silva", "Andrew", ""], ["Chen", "Letian", ""], ["Gombolay", "Matthew", ""]]}, {"id": "1906.06412", "submitter": "Vojtech Kovarik", "authors": "Vojt\\v{e}ch Kova\\v{r}\\'ik, Dominik Seitz, Viliam Lis\\'y, Jan Rudolf,\n  Shuo Sun, Karel Ha", "title": "Value Functions for Depth-Limited Solving in Imperfect-Information Games", "comments": "The first two authors contributed equally", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide a formal definition of depth-limited games together with an\naccessible and rigorous explanation of the underlying concepts, both of which\nwere previously missing in imperfect-information games. The definition works\nfor an arbitrary extensive-form game and is not tied to any specific\ngame-solving algorithm. Moreover, this framework unifies and significantly\nextends three approaches to depth-limited solving that previously existed in\nextensive-form games and multiagent reinforcement learning but were not known\nto be compatible. A key ingredient of these depth-limited games are value\nfunctions. Focusing on two-player zero-sum imperfect-information games, we show\nhow to obtain optimal value functions and prove that public information\nprovides both necessary and sufficient context for computing them. We provide a\ndomain-independent encoding of the domain which allows for approximating value\nfunctions even by simple feed-forward neural networks. We use the resulting\nvalue network to implement a depth-limited version of counterfactual regret\nminimization. In three distinct domains, we show that the algorithm produces a\nlow-exploitability strategy if and only if it is paired with a near-optimal\nvalue network. We show that the value network is capable of generalizing to\nunseen game situations and that the resulting algorithm performs on par with\nCFR-D despite being trained on randomly-generated game situations.\n", "versions": [{"version": "v1", "created": "Fri, 31 May 2019 15:40:26 GMT"}, {"version": "v2", "created": "Wed, 2 Oct 2019 14:30:54 GMT"}, {"version": "v3", "created": "Mon, 19 Oct 2020 09:49:00 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["Kova\u0159\u00edk", "Vojt\u011bch", ""], ["Seitz", "Dominik", ""], ["Lis\u00fd", "Viliam", ""], ["Rudolf", "Jan", ""], ["Sun", "Shuo", ""], ["Ha", "Karel", ""]]}, {"id": "1906.06425", "submitter": "Shrimai Prabhumoye", "authors": "Shrimai Prabhumoye, Elijah Mayfield, Alan W Black", "title": "Principled Frameworks for Evaluating Ethics in NLP Systems", "comments": null, "journal-ref": "Widening NLP Workshop at ACL 2019", "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We critique recent work on ethics in natural language processing. Those\ndiscussions have focused on data collection, experimental design, and\ninterventions in modeling. But we argue that we ought to first understand the\nframeworks of ethics that are being used to evaluate the fairness and justice\nof algorithmic systems. Here, we begin that discussion by outlining\ndeontological ethics, and envision a research agenda prioritized by it.\n", "versions": [{"version": "v1", "created": "Fri, 14 Jun 2019 22:52:21 GMT"}], "update_date": "2019-06-18", "authors_parsed": [["Prabhumoye", "Shrimai", ""], ["Mayfield", "Elijah", ""], ["Black", "Alan W", ""]]}, {"id": "1906.06436", "submitter": "Maayan Shvo", "authors": "Maayan Shvo, Sheila A. McIlraith", "title": "Towards Empathetic Planning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Critical to successful human interaction is a capacity for empathy - the\nability to understand and share the thoughts and feelings of another. As\nArtificial Intelligence (AI) systems are increasingly required to interact with\nhumans in a myriad of settings, it is important to enable AI to wield empathy\nas a tool to benefit those it interacts with. In this paper, we work towards\nthis goal by bringing together a number of important concepts: empathy, AI\nplanning, and reasoning in the presence of knowledge and belief. We formalize\nthe notion of Empathetic Planning which is informed by the beliefs and\naffective state of the empathizee. We appeal to an epistemic logic framework to\nrepresent the beliefs of the empathizee and propose AI planning-based\ncomputational approaches to compute empathetic solutions. We illustrate the\npotential benefits of our approach by conducting a study where we evaluate\nparticipants' perceptions of the agent's empathetic abilities and assistive\ncapabilities.\n", "versions": [{"version": "v1", "created": "Fri, 14 Jun 2019 23:36:53 GMT"}], "update_date": "2019-06-18", "authors_parsed": [["Shvo", "Maayan", ""], ["McIlraith", "Sheila A.", ""]]}, {"id": "1906.06455", "submitter": "Edjard De Souza Mota Mota", "authors": "Edjard Mota, Jacob M. Howe, Ana Schramm and Artur d'Avila Garcez", "title": "Efficient predicate invention using shared \"NeMuS\"", "comments": "7 pages, 5 figures, Proceedings of the 2019 International Workshop on\n  Neural-Symbolic Learning and Reasoning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Amao is a cognitive agent framework that tackles the invention of predicates\nwith a different strategy as compared to recent advances in Inductive Logic\nProgramming (ILP) approaches like Meta-Intepretive Learning (MIL) technique. It\nuses a Neural Multi-Space (NeMuS) graph structure to anti-unify atoms from the\nHerbrand base, which passes in the inductive momentum check. Inductive Clause\nLearning (ICL), as it is called, is extended here by using the weights of\nlogical components, already present in NeMuS, to support inductive learning by\nexpanding clause candidates with anti-unified atoms. An efficient invention\nmechanism is achieved, including the learning of recursive hypotheses, while\nrestricting the shape of the hypothesis by adding bias definitions or\nidiosyncrasies of the language.\n", "versions": [{"version": "v1", "created": "Sat, 15 Jun 2019 02:45:00 GMT"}], "update_date": "2019-06-18", "authors_parsed": [["Mota", "Edjard", ""], ["Howe", "Jacob M.", ""], ["Schramm", "Ana", ""], ["Garcez", "Artur d'Avila", ""]]}, {"id": "1906.06475", "submitter": "Jonathan Pan", "authors": "Jonathan Pan", "title": "Physical Integrity Attack Detection of Surveillance Camera with Deep\n  Learning Based Video Frame Interpolation", "comments": "7 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Surveillance cameras, which is a form of Cyber Physical System, are deployed\nextensively to provide visual surveillance monitoring of activities of interest\nor anomalies. However, these cameras are at risks of physical security attacks\nagainst their physical attributes or configuration like tampering of their\nrecording coverage, camera positions or recording configurations like focus and\nzoom factors. Such adversarial alteration of physical configuration could also\nbe invoked through cyber security attacks against the camera's software\nvulnerabilities to administratively change the camera's physical configuration\nsettings. When such Cyber Physical attacks occur, they affect the integrity of\nthe targeted cameras that would in turn render these cameras ineffective in\nfulfilling the intended security functions. There is a significant measure of\nresearch work in detection mechanisms of cyber-attacks against these Cyber\nPhysical devices, however it is understudied area with such mechanisms against\nintegrity attacks on physical configuration. This research proposes the use of\nthe novel use of deep learning algorithms to detect such physical attacks\noriginating from cyber or physical spaces. Additionally, we proposed the novel\nuse of deep learning-based video frame interpolation for such detection that\nhas comparatively better performance to other anomaly detectors in\nspatiotemporal environments.\n", "versions": [{"version": "v1", "created": "Sat, 15 Jun 2019 05:48:29 GMT"}], "update_date": "2019-06-18", "authors_parsed": [["Pan", "Jonathan", ""]]}, {"id": "1906.06582", "submitter": "Christoph Benzm\\\"uller", "authors": "David Fuenmayor and Christoph Benzm\\\"uller", "title": "A Computational-Hermeneutic Approach for Conceptual Explicitation", "comments": "29 pages, 9 figures, to appear in A. Nepomuceno, L. Magnani, F.\n  Salguero, C. Bar\\'es, M. Fontaine (eds.), Model-Based Reasoning in Science\n  and Technology. Inferential Models for Logic, Language, Cognition and\n  Computation, Series \"Sapere\", Springer", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a computer-supported approach for the logical analysis and\nconceptual explicitation of argumentative discourse. Computational hermeneutics\nharnesses recent progresses in automated reasoning for higher-order logics and\naims at formalizing natural-language argumentative discourse using flexible\ncombinations of expressive non-classical logics. In doing so, it allows us to\nrender explicit the tacit conceptualizations implicit in argumentative\ndiscursive practices. Our approach operates on networks of structured arguments\nand is iterative and two-layered. At one layer we search for logically correct\nformalizations for each of the individual arguments. At the next layer we\nselect among those correct formalizations the ones which honor the argument's\ndialectic role, i.e. attacking or supporting other arguments as intended. We\noperate at these two layers in parallel and continuously rate sentences'\nformalizations by using, primarily, inferential adequacy criteria. An\ninterpretive, logical theory will thus gradually evolve. This theory is\ncomposed of meaning postulates serving as explications for concepts playing a\nrole in the analyzed arguments. Such a recursive, iterative approach to\ninterpretation does justice to the inherent circularity of understanding: the\nwhole is understood compositionally on the basis of its parts, while each part\nis understood only in the context of the whole (hermeneutic circle). We\nsummarily discuss previous work on exemplary applications of human-in-the-loop\ncomputational hermeneutics in metaphysical discourse. We also discuss some of\nthe main challenges involved in fully-automating our approach. By sketching\nsome design ideas and reviewing relevant technologies, we argue for the\ntechnological feasibility of a highly-automated computational hermeneutics.\n", "versions": [{"version": "v1", "created": "Sat, 15 Jun 2019 15:57:57 GMT"}, {"version": "v2", "created": "Fri, 19 Jul 2019 09:49:19 GMT"}], "update_date": "2019-07-22", "authors_parsed": [["Fuenmayor", "David", ""], ["Benzm\u00fcller", "Christoph", ""]]}, {"id": "1906.06668", "submitter": "Brent Mittelstadt", "authors": "Brent Mittelstadt", "title": "Principles alone cannot guarantee ethical AI", "comments": "A previous, pre-print version of this paper was entitled 'AI Ethics -\n  Too Principled to Fail?'", "journal-ref": "Nat Mach Intell 1, 501-507, 2019", "doi": "10.1038/s42256-019-0114-4", "report-no": null, "categories": "cs.CY cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  AI Ethics is now a global topic of discussion in academic and policy circles.\nAt least 84 public-private initiatives have produced statements describing\nhigh-level principles, values, and other tenets to guide the ethical\ndevelopment, deployment, and governance of AI. According to recent\nmeta-analyses, AI Ethics has seemingly converged on a set of principles that\nclosely resemble the four classic principles of medical ethics. Despite the\ninitial credibility granted to a principled approach to AI Ethics by the\nconnection to principles in medical ethics, there are reasons to be concerned\nabout its future impact on AI development and governance. Significant\ndifferences exist between medicine and AI development that suggest a principled\napproach in the latter may not enjoy success comparable to the former. Compared\nto medicine, AI development lacks (1) common aims and fiduciary duties, (2)\nprofessional history and norms, (3) proven methods to translate principles into\npractice, and (4) robust legal and professional accountability mechanisms.\nThese differences suggest we should not yet celebrate consensus around\nhigh-level principles that hide deep political and normative disagreement.\n", "versions": [{"version": "v1", "created": "Sun, 16 Jun 2019 12:40:08 GMT"}, {"version": "v2", "created": "Tue, 18 Feb 2020 19:58:35 GMT"}], "update_date": "2020-02-20", "authors_parsed": [["Mittelstadt", "Brent", ""]]}, {"id": "1906.06685", "submitter": "Yangjun Zhang", "authors": "Yangjun Zhang, Pengjie Ren, Maarten de Rijke", "title": "Improving Background Based Conversation with Context-aware Knowledge\n  Pre-selection", "comments": "SCAI 2019 workshop paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Background Based Conversations (BBCs) have been developed to make dialogue\nsystems generate more informative and natural responses by leveraging\nbackground knowledge. Existing methods for BBCs can be grouped into two\ncategories: extraction-based methods and generation-based methods. The former\nextract spans frombackground material as responses that are not necessarily\nnatural. The latter generate responses thatare natural but not necessarily\neffective in leveraging background knowledge. In this paper, we focus on\ngeneration-based methods and propose a model, namely Context-aware Knowledge\nPre-selection (CaKe), which introduces a pre-selection process that uses\ndynamic bi-directional attention to improve knowledge selection by using the\nutterance history context as prior information to select the most relevant\nbackground material. Experimental results show that our model is superior to\ncurrent state-of-the-art baselines, indicating that it benefits from the\npre-selection process, thus improving in-formativeness and fluency.\n", "versions": [{"version": "v1", "created": "Sun, 16 Jun 2019 13:33:55 GMT"}], "update_date": "2019-06-18", "authors_parsed": [["Zhang", "Yangjun", ""], ["Ren", "Pengjie", ""], ["de Rijke", "Maarten", ""]]}, {"id": "1906.06717", "submitter": "Marko Vasic", "authors": "Marko Vasic, Andrija Petrovic, Kaiyuan Wang, Mladen Nikolic, Rishabh\n  Singh, Sarfraz Khurshid", "title": "MoET: Mixture of Expert Trees and its Application to Verifiable\n  Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Rapid advancements in deep learning have led to many recent breakthroughs.\nWhile deep learning models achieve superior performance, often statistically\nbetter than humans, their adaption into safety-critical settings, such as\nhealthcare or self-driving cars is hindered by their inability to provide\nsafety guarantees or to analyze the inner workings of the model. We present\nMoET, a novel model based on Mixture of Experts, consisting of decision tree\nexperts and a generalized linear model gating function. While decision\nboundaries of decision trees (used in an existing verifiable approach), are\naxis-perpendicular hyperplanes, MoET supports hyperplanes of arbitrary\norientation as the boundaries. To support non-differentiable decision trees as\nexperts we formulate a novel training procedure. In addition, we introduce a\nhard thresholding version, MoET_h, in which predictions are made solely by a\nsingle expert chosen via the gating function. Thanks to that property, MoET_h\nallows each prediction to be easily decomposed into a set of logical rules.\nSuch rules can be translated into a manageable SMT formula providing rich means\nfor verification. While MoET is a general use model, we illustrate its power in\nthe reinforcement learning setting. By training MoET models using an imitation\nlearning procedure on deep RL agents we outperform the previous\nstate-of-the-art technique based on decision trees while preserving the\nverifiability of the models.\n", "versions": [{"version": "v1", "created": "Sun, 16 Jun 2019 15:28:35 GMT"}, {"version": "v2", "created": "Tue, 17 Sep 2019 02:51:48 GMT"}, {"version": "v3", "created": "Tue, 1 Jun 2021 09:24:03 GMT"}], "update_date": "2021-06-02", "authors_parsed": [["Vasic", "Marko", ""], ["Petrovic", "Andrija", ""], ["Wang", "Kaiyuan", ""], ["Nikolic", "Mladen", ""], ["Singh", "Rishabh", ""], ["Khurshid", "Sarfraz", ""]]}, {"id": "1906.06725", "submitter": "Weiyan Shi", "authors": "Xuewei Wang, Weiyan Shi, Richard Kim, Yoojung Oh, Sijia Yang, Jingwen\n  Zhang and Zhou Yu", "title": "Persuasion for Good: Towards a Personalized Persuasive Dialogue System\n  for Social Good", "comments": "Accepted by ACL 2019 as a long paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Developing intelligent persuasive conversational agents to change people's\nopinions and actions for social good is the frontier in advancing the ethical\ndevelopment of automated dialogue systems. To do so, the first step is to\nunderstand the intricate organization of strategic disclosures and appeals\nemployed in human persuasion conversations. We designed an online persuasion\ntask where one participant was asked to persuade the other to donate to a\nspecific charity. We collected a large dataset with 1,017 dialogues and\nannotated emerging persuasion strategies from a subset. Based on the\nannotation, we built a baseline classifier with context information and\nsentence-level features to predict the 10 persuasion strategies used in the\ncorpus. Furthermore, to develop an understanding of personalized persuasion\nprocesses, we analyzed the relationships between individuals' demographic and\npsychological backgrounds including personality, morality, value systems, and\ntheir willingness for donation. Then, we analyzed which types of persuasion\nstrategies led to a greater amount of donation depending on the individuals'\npersonal backgrounds. This work lays the ground for developing a personalized\npersuasive dialogue system.\n", "versions": [{"version": "v1", "created": "Sun, 16 Jun 2019 16:43:02 GMT"}, {"version": "v2", "created": "Mon, 13 Jan 2020 04:17:44 GMT"}], "update_date": "2020-01-14", "authors_parsed": [["Wang", "Xuewei", ""], ["Shi", "Weiyan", ""], ["Kim", "Richard", ""], ["Oh", "Yoojung", ""], ["Yang", "Sijia", ""], ["Zhang", "Jingwen", ""], ["Yu", "Zhou", ""]]}, {"id": "1906.06750", "submitter": "Thibaut Vidal", "authors": "Thibaut Vidal, Gilbert Laporte, Piotr Matl", "title": "A concise guide to existing and emerging vehicle routing problem\n  variants", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DM cs.AI cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Vehicle routing problems have been the focus of extensive research over the\npast sixty years, driven by their economic importance and their theoretical\ninterest. The diversity of applications has motivated the study of a myriad of\nproblem variants with different attributes. In this article, we provide a\nconcise overview of existing and emerging problem variants. Models are\ntypically refined along three lines: considering more relevant objectives and\nperformance metrics, integrating vehicle routing evaluations with other\ntactical decisions, and capturing fine-grained yet essential aspects of modern\nsupply chains. We organize the main problem attributes within this structured\nframework. We discuss recent research directions and pinpoint current\nshortcomings, recent successes, and emerging challenges.\n", "versions": [{"version": "v1", "created": "Sun, 16 Jun 2019 18:50:18 GMT"}, {"version": "v2", "created": "Sun, 5 Apr 2020 13:08:07 GMT"}], "update_date": "2020-04-07", "authors_parsed": [["Vidal", "Thibaut", ""], ["Laporte", "Gilbert", ""], ["Matl", "Piotr", ""]]}, {"id": "1906.06761", "submitter": "Edjard de Souza Mota", "authors": "Leonardo Barreto and Edjard Mota", "title": "Self-organized inductive reasoning with NeMuS", "comments": "6 pages, 5 figures,", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural Multi-Space (NeMuS) is a weighted multi-space representation for a\nportion of first-order logic designed for use with machine learning and neural\nnetwork methods. It was demonstrated that it can be used to perform reasoning\nbased on regions forming patterns of refutation and also in the process of\ninductive learning in ILP-like style. Initial experiments were carried out to\ninvestigate whether a self-organizing the approach is suitable to generate\nsimilar concept regions according to the attributes that form such concepts. We\npresent the results and make an analysis of the suitability of the method in\nthe process of inductive learning with NeMuS.\n", "versions": [{"version": "v1", "created": "Sun, 16 Jun 2019 20:16:53 GMT"}], "update_date": "2019-06-18", "authors_parsed": [["Barreto", "Leonardo", ""], ["Mota", "Edjard", ""]]}, {"id": "1906.06788", "submitter": "Jiahuan Pei", "authors": "Jiahuan Pei, Arent Stienstra, Julia Kiseleva, Maarten de Rijke", "title": "SEntNet: Source-aware Recurrent Entity Network for Dialogue Response\n  Selection", "comments": "Proceedings of the 2019 IJCAI Workshop SCAI: The 4th International\n  Workshop on Search-Oriented Conversational AI", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dialogue response selection is an important part of Task-oriented Dialogue\nSystems (TDSs); it aims to predict an appropriate response given a dialogue\ncontext. Obtaining key information from a complex, long dialogue context is\nchallenging, especially when different sources of information are available,\ne.g., the user's utterances, the system's responses, and results retrieved from\na knowledge base (KB). Previous work ignores the type of information source and\nmerges sources for response selection. However, accounting for the source type\nmay lead to remarkable differences in the quality of response selection. We\npropose the Source-aware Recurrent Entity Network (SEntNet), which is aware of\ndifferent information sources for the response selection process. SEntNet\nachieves this by employing source-specific memories to exploit differences in\nthe usage of words and syntactic structure from different information sources\n(user, system, and KB). Experimental results show that SEntNet obtains 91.0%\naccuracy on the Dialog bAbI dataset, outperforming prior work by 4.7%. On the\nDSTC2 dataset, SEntNet obtains an accuracy of 41.2%, beating source unaware\nrecurrent entity networks by 2.4%.\n", "versions": [{"version": "v1", "created": "Sun, 16 Jun 2019 22:36:33 GMT"}, {"version": "v2", "created": "Wed, 19 Jun 2019 17:24:59 GMT"}, {"version": "v3", "created": "Thu, 20 Jun 2019 00:38:00 GMT"}, {"version": "v4", "created": "Mon, 16 Sep 2019 09:29:48 GMT"}], "update_date": "2019-09-17", "authors_parsed": [["Pei", "Jiahuan", ""], ["Stienstra", "Arent", ""], ["Kiseleva", "Julia", ""], ["de Rijke", "Maarten", ""]]}, {"id": "1906.06812", "submitter": "Ruggiero Seccia Mr", "authors": "Francesco Foglino, Matteo Leonetti, Simone Sagratella, Ruggiero Seccia", "title": "A gray-box approach for curriculum learning", "comments": "10 pages, 1 figure", "journal-ref": "Optimization of Complex Systems: Theory, Models, Algorithms and\n  Applications, 2020, pp 720-729", "doi": "10.1007/978-3-030-21803-4_72", "report-no": null, "categories": "cs.LG cs.AI math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Curriculum learning is often employed in deep reinforcement learning to let\nthe agent progress more quickly towards better behaviors. Numerical methods for\ncurriculum learning in the literature provides only initial heuristic\nsolutions, with little to no guarantee on their quality. We define a new\ngray-box function that, including a suitable scheduling problem, can be\neffectively used to reformulate the curriculum learning problem. We propose\ndifferent efficient numerical methods to address this gray-box reformulation.\nPreliminary numerical results on a benchmark task in the curriculum learning\nliterature show the viability of the proposed approach.\n", "versions": [{"version": "v1", "created": "Mon, 17 Jun 2019 01:27:49 GMT"}], "update_date": "2019-06-18", "authors_parsed": [["Foglino", "Francesco", ""], ["Leonetti", "Matteo", ""], ["Sagratella", "Simone", ""], ["Seccia", "Ruggiero", ""]]}, {"id": "1906.06816", "submitter": "Wenli Ouyang", "authors": "Wenli Ouyang", "title": "A new approach to forecast service parts demand by integrating user\n  preferences into multi-objective optimization", "comments": "16 pages, 2 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Service supply chain management is to prepare spare parts for failed products\nunder warranty. Their goal is to reach agreed service level at the minimum\ncost. We convert this business problem into a preference based multi-objective\noptimization problem, where two quality criteria must be simultaneously\noptimized. One criterion is accuracy of demand forecast and the other is\nservice level. Here we propose a general framework supporting solving\npreference-based multi-objective optimization problems (MOPs) by multi-gradient\ndescent algorithm (MGDA), which is well suited for training deep neural\nnetwork. The proposed framework treats agreed service level as a constrained\ncriterion that must be met and generate a Pareto-optimal solution with highest\nforecasting accuracy. The neural networks used here are two Encoder-Decoder\nLSTM modes: one is used for pre-training phase to learn distributed\nrepresentation of former generations' service parts consumption data, and the\nother is used for supervised learning phase to generate forecast quantities of\ncurrent generations' service parts. Evaluated under the service parts\nconsumption data in Lenovo Group Ltd, the proposed method clearly outperform\nbaseline methods.\n", "versions": [{"version": "v1", "created": "Mon, 17 Jun 2019 02:00:09 GMT"}, {"version": "v2", "created": "Wed, 19 Jun 2019 08:14:13 GMT"}], "update_date": "2019-06-20", "authors_parsed": [["Ouyang", "Wenli", ""]]}, {"id": "1906.06836", "submitter": "Haibin Wang", "authors": "Haibin Wang, Sujoy Sikdar, Xiaoxi Guo, Lirong Xia, Yongzhi Cao, Hanpin\n  Wang", "title": "Multi-type Resource Allocation with Partial Preferences", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  We propose multi-type probabilistic serial (MPS) and multi-type random\npriority (MRP) as extensions of the well known PS and RP mechanisms to the\nmulti-type resource allocation problem (MTRA) with partial preferences. In our\nsetting, there are multiple types of divisible items, and a group of agents who\nhave partial order preferences over bundles consisting of one item of each\ntype. We show that for the unrestricted domain of partial order preferences, no\nmechanism satisfies both sd-efficiency and sd-envy-freeness. Notwithstanding\nthis impossibility result, our main message is positive: When agents'\npreferences are represented by acyclic CP-nets, MPS satisfies sd-efficiency,\nsd-envy-freeness, ordinal fairness, and upper invariance, while MRP satisfies\nex-post-efficiency, sd-strategy-proofness, and upper invariance, recovering the\nproperties of PS and RP.\n", "versions": [{"version": "v1", "created": "Thu, 13 Jun 2019 08:49:21 GMT"}, {"version": "v2", "created": "Tue, 19 Nov 2019 07:04:52 GMT"}, {"version": "v3", "created": "Thu, 29 Oct 2020 07:15:16 GMT"}], "update_date": "2020-10-30", "authors_parsed": [["Wang", "Haibin", ""], ["Sikdar", "Sujoy", ""], ["Guo", "Xiaoxi", ""], ["Xia", "Lirong", ""], ["Cao", "Yongzhi", ""], ["Wang", "Hanpin", ""]]}, {"id": "1906.06841", "submitter": "Biao Jia", "authors": "Biao Jia, Jonathan Brandt, Radomir Mech, Byungmoon Kim, Dinesh Manocha", "title": "LPaintB: Learning to Paint from Self-Supervision", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel reinforcement learning-based natural media painting\nalgorithm. Our goal is to reproduce a reference image using brush strokes and\nwe encode the objective through observations. Our formulation takes into\naccount that the distribution of the reward in the action space is sparse and\ntraining a reinforcement learning algorithm from scratch can be difficult. We\npresent an approach that combines self-supervised learning and reinforcement\nlearning to effectively transfer negative samples into positive ones and change\nthe reward distribution. We demonstrate the benefits of our painting agent to\nreproduce reference images with brush strokes. The training phase takes about\none hour and the runtime algorithm takes about 30 seconds on a GTX1080 GPU\nreproducing a 1000x800 image with 20,000 strokes.\n", "versions": [{"version": "v1", "created": "Mon, 17 Jun 2019 04:52:15 GMT"}, {"version": "v2", "created": "Sat, 21 Sep 2019 15:14:21 GMT"}], "update_date": "2019-09-24", "authors_parsed": [["Jia", "Biao", ""], ["Brandt", "Jonathan", ""], ["Mech", "Radomir", ""], ["Kim", "Byungmoon", ""], ["Manocha", "Dinesh", ""]]}, {"id": "1906.06931", "submitter": "Thorsten Wissmann", "authors": "Jan K\\v{r}et\\'insk\\'y and Tobias Meggendorfer", "title": "Of Cores: A Partial-Exploration Framework for Markov Decision Processes", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 16, Issue 4 (October\n  9, 2020) lmcs:6833", "doi": "10.23638/LMCS-16(4:3)2020", "report-no": null, "categories": "eess.SY cs.AI cs.LO cs.SY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We introduce a framework for approximate analysis of Markov decision\nprocesses (MDP) with bounded-, unbounded-, and infinite-horizon properties. The\nmain idea is to identify a \"core\" of an MDP, i.e., a subsystem where we\nprovably remain with high probability, and to avoid computation on the less\nrelevant rest of the state space. Although we identify the core using\nsimulations and statistical techniques, it allows for rigorous error bounds in\nthe analysis. Consequently, we obtain efficient analysis algorithms based on\npartial exploration for various settings, including the challenging case of\nstrongly connected systems.\n", "versions": [{"version": "v1", "created": "Mon, 17 Jun 2019 10:07:31 GMT"}, {"version": "v2", "created": "Mon, 16 Dec 2019 14:02:46 GMT"}, {"version": "v3", "created": "Tue, 26 May 2020 07:45:18 GMT"}, {"version": "v4", "created": "Wed, 12 Aug 2020 09:40:11 GMT"}, {"version": "v5", "created": "Thu, 17 Sep 2020 13:07:38 GMT"}, {"version": "v6", "created": "Thu, 8 Oct 2020 13:49:41 GMT"}], "update_date": "2021-02-10", "authors_parsed": [["K\u0159et\u00ednsk\u00fd", "Jan", ""], ["Meggendorfer", "Tobias", ""]]}, {"id": "1906.06977", "submitter": "Yvan Lucas", "authors": "Yvan Lucas, Pierre-Edouard Portier, L\\'ea Laporte, Sylvie Calabretto,\n  Liyun He-Guelton, Frederic Obl\\'e, Michael Granitzer", "title": "Dataset shift quantification for credit card fraud detection", "comments": "Presented at IEEE Artificial Intelligence and Knowledge Engineering\n  (AIKE 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning and data mining techniques have been used extensively in\norder to detect credit card frauds. However purchase behaviour and fraudster\nstrategies may change over time. This phenomenon is named dataset shift or\nconcept drift in the domain of fraud detection. In this paper, we present a\nmethod to quantify day-by-day the dataset shift in our face-to-face credit card\ntransactions dataset (card holder located in the shop) . In practice, we\nclassify the days against each other and measure the efficiency of the\nclassification. The more efficient the classification, the more different the\nbuying behaviour between two days, and vice versa. Therefore, we obtain a\ndistance matrix characterizing the dataset shift. After an agglomerative\nclustering of the distance matrix, we observe that the dataset shift pattern\nmatches the calendar events for this time period (holidays, week-ends, etc). We\nthen incorporate this dataset shift knowledge in the credit card fraud\ndetection task as a new feature. This leads to a small improvement of the\ndetection.\n", "versions": [{"version": "v1", "created": "Mon, 17 Jun 2019 12:03:42 GMT"}], "update_date": "2019-06-18", "authors_parsed": [["Lucas", "Yvan", ""], ["Portier", "Pierre-Edouard", ""], ["Laporte", "L\u00e9a", ""], ["Calabretto", "Sylvie", ""], ["He-Guelton", "Liyun", ""], ["Obl\u00e9", "Frederic", ""], ["Granitzer", "Michael", ""]]}, {"id": "1906.06994", "submitter": "Verner Vla\\v{c}i\\'c", "authors": "Verner Vla\\v{c}i\\'c and Helmut B\\\"olcskei", "title": "Neural network identifiability for a family of sigmoidal nonlinearities", "comments": "43 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CO cs.AI cs.IT math.CV math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper addresses the following question of neural network\nidentifiability: Does the input-output map realized by a feed-forward neural\nnetwork with respect to a given nonlinearity uniquely specify the network\narchitecture, weights, and biases? Existing literature on the subject Sussman\n1992, Albertini, Sontag et al. 1993, Fefferman 1994 suggests that the answer\nshould be yes, up to certain symmetries induced by the nonlinearity, and\nprovided the networks under consideration satisfy certain \"genericity\nconditions\". The results in Sussman 1992 and Albertini, Sontag et al. 1993\napply to networks with a single hidden layer and in Fefferman 1994 the networks\nneed to be fully connected. In an effort to answer the identifiability question\nin greater generality, we derive necessary genericity conditions for the\nidentifiability of neural networks of arbitrary depth and connectivity with an\narbitrary nonlinearity. Moreover, we construct a family of nonlinearities for\nwhich these genericity conditions are minimal, i.e., both necessary and\nsufficient. This family is large enough to approximate many commonly\nencountered nonlinearities to within arbitrary precision in the uniform norm.\n", "versions": [{"version": "v1", "created": "Tue, 11 Jun 2019 14:48:11 GMT"}, {"version": "v2", "created": "Tue, 25 Jun 2019 13:13:26 GMT"}, {"version": "v3", "created": "Wed, 2 Sep 2020 08:15:05 GMT"}], "update_date": "2020-09-03", "authors_parsed": [["Vla\u010di\u0107", "Verner", ""], ["B\u00f6lcskei", "Helmut", ""]]}, {"id": "1906.06997", "submitter": "Charles Telles Roberto", "authors": "Charles Roberto Telles", "title": "Productivity equation and the m distributions of information processing\n  in workflows", "comments": "6 pages, 0 figures", "journal-ref": null, "doi": "10.3390/asi2030024", "report-no": null, "categories": "math.OC cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This research investigates an equation of productivity for workflows\nregarding its robustness towards the definition of workflows as probabilistic\ndistributions. The equation was formulated across its derivations through a\ntheoretical framework about information theory, probabilities and complex\nadaptive systems. By defining the productivity equation for organism-object\ninteractions, workflows mathematical derivations can be predicted and monitored\nwithout strict empirical methods and allows workflow flexibility for\norganism-object environments.\n", "versions": [{"version": "v1", "created": "Mon, 17 Jun 2019 13:10:22 GMT"}], "update_date": "2019-07-25", "authors_parsed": [["Telles", "Charles Roberto", ""]]}, {"id": "1906.07004", "submitter": "Hui Su", "authors": "Hui Su, Xiaoyu Shen, Rongzhi Zhang, Fei Sun, Pengwei Hu, Cheng Niu,\n  Jie Zhou", "title": "Improving Multi-turn Dialogue Modelling with Utterance ReWriter", "comments": "Accepted to ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent research has made impressive progress in single-turn dialogue\nmodelling. In the multi-turn setting, however, current models are still far\nfrom satisfactory. One major challenge is the frequently occurred coreference\nand information omission in our daily conversation, making it hard for machines\nto understand the real intention. In this paper, we propose rewriting the human\nutterance as a pre-process to help multi-turn dialgoue modelling. Each\nutterance is first rewritten to recover all coreferred and omitted information.\nThe next processing steps are then performed based on the rewritten utterance.\nTo properly train the utterance rewriter, we collect a new dataset with human\nannotations and introduce a Transformer-based utterance rewriting architecture\nusing the pointer network. We show the proposed architecture achieves\nremarkably good performance on the utterance rewriting task. The trained\nutterance rewriter can be easily integrated into online chatbots and brings\ngeneral improvement over different domains.\n", "versions": [{"version": "v1", "created": "Fri, 14 Jun 2019 06:45:08 GMT"}], "update_date": "2019-06-18", "authors_parsed": [["Su", "Hui", ""], ["Shen", "Xiaoyu", ""], ["Zhang", "Rongzhi", ""], ["Sun", "Fei", ""], ["Hu", "Pengwei", ""], ["Niu", "Cheng", ""], ["Zhou", "Jie", ""]]}, {"id": "1906.07122", "submitter": "Ari Azarafrooz", "authors": "Ari Azarafrooz and John Brock", "title": "Hierarchical Soft Actor-Critic: Adversarial Exploration via Mutual\n  Information Optimization", "comments": "Presented at the ICML 2019 workshop on Imitation, Intent, and\n  Interaction, Long Beach, CA, USA", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe a novel extension of soft actor-critics for hierarchical Deep\nQ-Networks (HDQN) architectures using mutual information metric. The proposed\nextension provides a suitable framework for encouraging explorations in such\nhierarchical networks. A natural utilization of this framework is an\nadversarial setting, where meta-controller and controller play minimax over the\nmutual information objective but cooperate on maximizing expected rewards.\n", "versions": [{"version": "v1", "created": "Mon, 17 Jun 2019 16:43:09 GMT"}], "update_date": "2019-06-18", "authors_parsed": [["Azarafrooz", "Ari", ""], ["Brock", "John", ""]]}, {"id": "1906.07132", "submitter": "Yichen Jiang", "authors": "Yichen Jiang, Mohit Bansal", "title": "Avoiding Reasoning Shortcuts: Adversarial Evaluation, Training, and\n  Model Development for Multi-Hop QA", "comments": "ACL 2019 (11 pages)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-hop question answering requires a model to connect multiple pieces of\nevidence scattered in a long context to answer the question. In this paper, we\nshow that in the multi-hop HotpotQA (Yang et al., 2018) dataset, the examples\noften contain reasoning shortcuts through which models can directly locate the\nanswer by word-matching the question with a sentence in the context. We\ndemonstrate this issue by constructing adversarial documents that create\ncontradicting answers to the shortcut but do not affect the validity of the\noriginal answer. The performance of strong baseline models drops significantly\non our adversarial evaluation, indicating that they are indeed exploiting the\nshortcuts rather than performing multi-hop reasoning. After adversarial\ntraining, the baseline's performance improves but is still limited on the\nadversarial evaluation. Hence, we use a control unit that dynamically attends\nto the question at different reasoning hops to guide the model's multi-hop\nreasoning. We show that this 2-hop model trained on the regular data is more\nrobust to the adversaries than the baseline model. After adversarial training,\nthis 2-hop model not only achieves improvements over its counterpart trained on\nregular data, but also outperforms the adversarially-trained 1-hop baseline. We\nhope that these insights and initial improvements will motivate the development\nof new models that combine explicit compositional reasoning with adversarial\ntraining.\n", "versions": [{"version": "v1", "created": "Mon, 17 Jun 2019 17:03:57 GMT"}], "update_date": "2019-06-18", "authors_parsed": [["Jiang", "Yichen", ""], ["Bansal", "Mohit", ""]]}, {"id": "1906.07181", "submitter": "Zhan Shi", "authors": "Zhan Shi, Kevin Swersky, Daniel Tarlow, Parthasarathy Ranganathan,\n  Milad Hashemi", "title": "Learning Execution through Neural Code Fusion", "comments": "14 pages,7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.PL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As the performance of computer systems stagnates due to the end of Moore's\nLaw, there is a need for new models that can understand and optimize the\nexecution of general purpose code. While there is a growing body of work on\nusing Graph Neural Networks (GNNs) to learn representations of source code,\nthese representations do not understand how code dynamically executes. In this\nwork, we propose a new approach to use GNNs to learn fused representations of\ngeneral source code and its execution. Our approach defines a multi-task GNN\nover low-level representations of source code and program state (i.e., assembly\ncode and dynamic memory states), converting complex source code constructs and\ncomplex data structures into a simpler, more uniform format. We show that this\nleads to improved performance over similar methods that do not use execution\nand it opens the door to applying GNN models to new tasks that would not be\nfeasible from static code alone. As an illustration of this, we apply the new\nmodel to challenging dynamic tasks (branch prediction and prefetching) from the\nSPEC CPU benchmark suite, outperforming the state-of-the-art by 26% and 45%\nrespectively. Moreover, we use the learned fused graph embeddings to\ndemonstrate transfer learning with high performance on an indirectly related\ntask (algorithm classification).\n", "versions": [{"version": "v1", "created": "Mon, 17 Jun 2019 20:05:48 GMT"}, {"version": "v2", "created": "Wed, 11 Mar 2020 03:11:50 GMT"}], "update_date": "2020-03-12", "authors_parsed": [["Shi", "Zhan", ""], ["Swersky", "Kevin", ""], ["Tarlow", "Daniel", ""], ["Ranganathan", "Parthasarathy", ""], ["Hashemi", "Milad", ""]]}, {"id": "1906.07220", "submitter": "Anusha Balakrishnan", "authors": "Anusha Balakrishnan, Jinfeng Rao, Kartikeya Upasani, Michael White,\n  Rajen Subba", "title": "Constrained Decoding for Neural NLG from Compositional Representations\n  in Task-Oriented Dialogue", "comments": "To appear in the Proceedings of the 57th Annual Meeting of the\n  Association for Computational Linguistics (2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generating fluent natural language responses from structured semantic\nrepresentations is a critical step in task-oriented conversational systems.\nAvenues like the E2E NLG Challenge have encouraged the development of neural\napproaches, particularly sequence-to-sequence (Seq2Seq) models for this\nproblem. The semantic representations used, however, are often underspecified,\nwhich places a higher burden on the generation model for sentence planning, and\nalso limits the extent to which generated responses can be controlled in a live\nsystem. In this paper, we (1) propose using tree-structured semantic\nrepresentations, like those used in traditional rule-based NLG systems, for\nbetter discourse-level structuring and sentence-level planning; (2) introduce a\nchallenging dataset using this representation for the weather domain; (3)\nintroduce a constrained decoding approach for Seq2Seq models that leverages\nthis representation to improve semantic correctness; and (4) demonstrate\npromising results on our dataset and the E2E dataset.\n", "versions": [{"version": "v1", "created": "Mon, 17 Jun 2019 18:54:51 GMT"}], "update_date": "2019-06-19", "authors_parsed": [["Balakrishnan", "Anusha", ""], ["Rao", "Jinfeng", ""], ["Upasani", "Kartikeya", ""], ["White", "Michael", ""], ["Subba", "Rajen", ""]]}, {"id": "1906.07268", "submitter": "Daoming Lyu", "authors": "Daoming Lyu, Fangkai Yang, Bo Liu, Steven Gustafson", "title": "A Joint Planning and Learning Framework for Human-Aided Decision-Making", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conventional reinforcement learning (RL) allows an agent to learn policies\nvia environmental rewards only, with a long and slow learning curve, especially\nat the beginning stage. On the contrary, human learning is usually much faster\nbecause prior and general knowledge and multiple information resources are\nutilized. In this paper, we propose a\n\\textbf{P}lanner-\\textbf{A}ctor-\\textbf{C}ritic architecture for\nhu\\textbf{MAN}-centered planning and learning (\\textbf{PACMAN}), where an agent\nuses prior, high-level, deterministic symbolic knowledge to plan for\ngoal-directed actions. PACMAN integrates Actor-Critic algorithm of RL to\nfine-tune its behavior towards both environmental rewards and human feedback.\nTo the best our knowledge, This is the first unified framework where\nknowledge-based planning, RL, and human teaching jointly contribute to the\npolicy learning of an agent. Our experiments demonstrate that PACMAN leads to a\nsignificant jump-start at the early stage of learning, converges rapidly and\nwith small variance, and is robust to inconsistent, infrequent, and misleading\nfeedback.\n", "versions": [{"version": "v1", "created": "Mon, 17 Jun 2019 20:56:31 GMT"}, {"version": "v2", "created": "Thu, 1 Aug 2019 02:02:04 GMT"}, {"version": "v3", "created": "Tue, 24 Dec 2019 17:14:02 GMT"}], "update_date": "2019-12-25", "authors_parsed": [["Lyu", "Daoming", ""], ["Yang", "Fangkai", ""], ["Liu", "Bo", ""], ["Gustafson", "Steven", ""]]}, {"id": "1906.07304", "submitter": "Jiayuan Mao", "authors": "Sidi Lu and Jiayuan Mao and Joshua B. Tenenbaum and Jiajun Wu", "title": "Neurally-Guided Structure Inference", "comments": "Proceedings of the 36th International Conference on Machine Learning\n  (ICML 2019). First two authors contributed equally. Project page:\n  http://ngsi.csail.mit.edu", "journal-ref": "PMLR(2019)97: 4144--4153", "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.SC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most structure inference methods either rely on exhaustive search or are\npurely data-driven. Exhaustive search robustly infers the structure of\narbitrarily complex data, but it is slow. Data-driven methods allow efficient\ninference, but do not generalize when test data have more complex structures\nthan training data. In this paper, we propose a hybrid inference algorithm, the\nNeurally-Guided Structure Inference (NG-SI), keeping the advantages of both\nsearch-based and data-driven methods. The key idea of NG-SI is to use a neural\nnetwork to guide the hierarchical, layer-wise search over the compositional\nspace of structures. We evaluate our algorithm on two representative structure\ninference tasks: probabilistic matrix decomposition and symbolic program\nparsing. It outperforms data-driven and search-based alternatives on both\ntasks.\n", "versions": [{"version": "v1", "created": "Mon, 17 Jun 2019 23:22:28 GMT"}, {"version": "v2", "created": "Thu, 15 Aug 2019 08:38:29 GMT"}], "update_date": "2019-08-16", "authors_parsed": [["Lu", "Sidi", ""], ["Mao", "Jiayuan", ""], ["Tenenbaum", "Joshua B.", ""], ["Wu", "Jiajun", ""]]}, {"id": "1906.07315", "submitter": "Somdeb Majumdar", "authors": "Shauharda Khadka and Somdeb Majumdar and Santiago Miret and Stephen\n  McAleer and Kagan Tumer", "title": "Evolutionary Reinforcement Learning for Sample-Efficient Multiagent\n  Coordination", "comments": "Proceedings of the 37th International Conference on Machine Learning,\n  Vienna, Austria, PMLR 108, 2020", "journal-ref": "Proceedings of the 37th International Conference on Machine\n  Learning, Vienna, Austria, PMLR 119, 2020", "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many cooperative multiagent reinforcement learning environments provide\nagents with a sparse team-based reward, as well as a dense agent-specific\nreward that incentivizes learning basic skills. Training policies solely on the\nteam-based reward is often difficult due to its sparsity. Furthermore, relying\nsolely on the agent-specific reward is sub-optimal because it usually does not\ncapture the team coordination objective. A common approach is to use reward\nshaping to construct a proxy reward by combining the individual rewards.\nHowever, this requires manual tuning for each environment. We introduce\nMultiagent Evolutionary Reinforcement Learning (MERL), a split-level training\nplatform that handles the two objectives separately through two optimization\nprocesses. An evolutionary algorithm maximizes the sparse team-based objective\nthrough neuroevolution on a population of teams. Concurrently, a gradient-based\noptimizer trains policies to only maximize the dense agent-specific rewards.\nThe gradient-based policies are periodically added to the evolutionary\npopulation as a way of information transfer between the two optimization\nprocesses. This enables the evolutionary algorithm to use skills learned via\nthe agent-specific rewards toward optimizing the global objective. Results\ndemonstrate that MERL significantly outperforms state-of-the-art methods, such\nas MADDPG, on a number of difficult coordination benchmarks.\n", "versions": [{"version": "v1", "created": "Tue, 18 Jun 2019 00:25:27 GMT"}, {"version": "v2", "created": "Tue, 29 Oct 2019 18:24:50 GMT"}, {"version": "v3", "created": "Thu, 11 Jun 2020 17:03:43 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Khadka", "Shauharda", ""], ["Majumdar", "Somdeb", ""], ["Miret", "Santiago", ""], ["McAleer", "Stephen", ""], ["Tumer", "Kagan", ""]]}, {"id": "1906.07328", "submitter": "Alex Cummaudo Mr", "authors": "Alex Cummaudo, Rajesh Vasa, John Grundy, Mohamed Abdelrazek, Andrew\n  Cain", "title": "Losing Confidence in Quality: Unspoken Evolution of Computer Vision\n  Services", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in artificial intelligence (AI) and machine learning (ML),\nsuch as computer vision, are now available as intelligent services and their\naccessibility and simplicity is compelling. Multiple vendors now offer this\ntechnology as cloud services and developers want to leverage these advances to\nprovide value to end-users. However, there is no firm investigation into the\nmaintenance and evolution risks arising from use of these intelligent services;\nin particular, their behavioural consistency and transparency of their\nfunctionality. We evaluated the responses of three different intelligent\nservices (specifically computer vision) over 11 months using 3 different data\nsets, verifying responses against the respective documentation and assessing\nevolution risk. We found that there are: (1) inconsistencies in how these\nservices behave; (2) evolution risk in the responses; and (3) a lack of clear\ncommunication that documents these risks and inconsistencies. We propose a set\nof recommendations to both developers and intelligent service providers to\ninform risk and assist maintainability.\n", "versions": [{"version": "v1", "created": "Tue, 18 Jun 2019 01:11:43 GMT"}, {"version": "v2", "created": "Tue, 30 Jul 2019 23:51:03 GMT"}], "update_date": "2019-08-01", "authors_parsed": [["Cummaudo", "Alex", ""], ["Vasa", "Rajesh", ""], ["Grundy", "John", ""], ["Abdelrazek", "Mohamed", ""], ["Cain", "Andrew", ""]]}, {"id": "1906.07343", "submitter": "YiDing Jiang", "authors": "Yiding Jiang, Shixiang Gu, Kevin Murphy, Chelsea Finn", "title": "Language as an Abstraction for Hierarchical Deep Reinforcement Learning", "comments": "Published in Neural Information Processing Systems (NeurIPS) 2019;\n  Supplementary materials: https://sites.google.com/view/hal-demo", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Solving complex, temporally-extended tasks is a long-standing problem in\nreinforcement learning (RL). We hypothesize that one critical element of\nsolving such problems is the notion of compositionality. With the ability to\nlearn concepts and sub-skills that can be composed to solve longer tasks, i.e.\nhierarchical RL, we can acquire temporally-extended behaviors. However,\nacquiring effective yet general abstractions for hierarchical RL is remarkably\nchallenging. In this paper, we propose to use language as the abstraction, as\nit provides unique compositional structure, enabling fast learning and\ncombinatorial generalization, while retaining tremendous flexibility, making it\nsuitable for a variety of problems. Our approach learns an\ninstruction-following low-level policy and a high-level policy that can reuse\nabstractions across tasks, in essence, permitting agents to reason using\nstructured language. To study compositional task learning, we introduce an\nopen-source object interaction environment built using the MuJoCo physics\nengine and the CLEVR engine. We find that, using our approach, agents can learn\nto solve to diverse, temporally-extended tasks such as object sorting and\nmulti-object rearrangement, including from raw pixel observations. Our analysis\nreveals that the compositional nature of language is critical for learning\ndiverse sub-skills and systematically generalizing to new sub-skills in\ncomparison to non-compositional abstractions that use the same supervision.\n", "versions": [{"version": "v1", "created": "Tue, 18 Jun 2019 02:27:45 GMT"}, {"version": "v2", "created": "Mon, 18 Nov 2019 21:51:49 GMT"}], "update_date": "2019-11-21", "authors_parsed": [["Jiang", "Yiding", ""], ["Gu", "Shixiang", ""], ["Murphy", "Kevin", ""], ["Finn", "Chelsea", ""]]}, {"id": "1906.07371", "submitter": "Philippe Morere", "authors": "Philippe Morere, Lionel Ott, Fabio Ramos", "title": "Learning to Plan Hierarchically from Curriculum", "comments": null, "journal-ref": "IEEE Robotics and Automation Letters (2019)", "doi": "10.1109/LRA.2019.2920285", "report-no": null, "categories": "cs.AI cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a framework for learning to plan hierarchically in domains with\nunknown dynamics. We enhance planning performance by exploiting problem\nstructure in several ways: (i) We simplify the search over plans by leveraging\nknowledge of skill objectives, (ii) Shorter plans are generated by enforcing\naggressively hierarchical planning, (iii) We learn transition dynamics with\nsparse local models for better generalisation. Our framework decomposes\ntransition dynamics into skill effects and success conditions, which allows\nfast planning by reasoning on effects, while learning conditions from\ninteractions with the world. We propose a simple method for learning new\nabstract skills, using successful trajectories stemming from completing the\ngoals of a curriculum. Learned skills are then refined to leverage other\nabstract skills and enhance subsequent planning. We show that both conditions\nand abstract skills can be learned simultaneously while planning, even in\nstochastic domains. Our method is validated in experiments of increasing\ncomplexity, with up to 2^100 states, showing superior planning to classic\nnon-hierarchical planners or reinforcement learning methods. Applicability to\nreal-world problems is demonstrated in a simulation-to-real transfer experiment\non a robotic manipulator.\n", "versions": [{"version": "v1", "created": "Tue, 18 Jun 2019 04:31:25 GMT"}], "update_date": "2019-06-19", "authors_parsed": [["Morere", "Philippe", ""], ["Ott", "Lionel", ""], ["Ramos", "Fabio", ""]]}, {"id": "1906.07389", "submitter": "Isabelle Augenstein", "authors": "Johannes Bjerva, Yova Kementchedjhieva, Ryan Cotterell, Isabelle\n  Augenstein", "title": "Uncovering Probabilistic Implications in Typological Knowledge Bases", "comments": "To appear in Proceedings of ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The study of linguistic typology is rooted in the implications we find\nbetween linguistic features, such as the fact that languages with object-verb\nword ordering tend to have post-positions. Uncovering such implications\ntypically amounts to time-consuming manual processing by trained and\nexperienced linguists, which potentially leaves key linguistic universals\nunexplored. In this paper, we present a computational model which successfully\nidentifies known universals, including Greenberg universals, but also uncovers\nnew ones, worthy of further linguistic investigation. Our approach outperforms\nbaselines previously used for this problem, as well as a strong baseline from\nknowledge base population.\n", "versions": [{"version": "v1", "created": "Tue, 18 Jun 2019 05:51:13 GMT"}], "update_date": "2019-06-19", "authors_parsed": [["Bjerva", "Johannes", ""], ["Kementchedjhieva", "Yova", ""], ["Cotterell", "Ryan", ""], ["Augenstein", "Isabelle", ""]]}, {"id": "1906.07508", "submitter": "Olivier Bailleux", "authors": "Olivier Bailleux", "title": "Subsumption-driven clause learning with DPLL+restarts", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose to use a DPLL+restart to solve SAT instances by successive\nsimplifications based on the production of clauses that subsume the initial\nclauses. We show that this approach allows the refutation of pebbling formulae\nin polynomial time and linear space, as effectively as with a CDCL solver.\n", "versions": [{"version": "v1", "created": "Tue, 18 Jun 2019 11:53:52 GMT"}], "update_date": "2019-06-19", "authors_parsed": [["Bailleux", "Olivier", ""]]}, {"id": "1906.07516", "submitter": "Daniel J. Mankowitz", "authors": "Daniel J. Mankowitz and Nir Levine and Rae Jeong and Yuanyuan Shi and\n  Jackie Kay and Abbas Abdolmaleki and Jost Tobias Springenberg and Timothy\n  Mann and Todd Hester and Martin Riedmiller", "title": "Robust Reinforcement Learning for Continuous Control with Model\n  Misspecification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide a framework for incorporating robustness -- to perturbations in\nthe transition dynamics which we refer to as model misspecification -- into\ncontinuous control Reinforcement Learning (RL) algorithms. We specifically\nfocus on incorporating robustness into a state-of-the-art continuous control RL\nalgorithm called Maximum a-posteriori Policy Optimization (MPO). We achieve\nthis by learning a policy that optimizes for a worst case expected return\nobjective and derive a corresponding robust entropy-regularized Bellman\ncontraction operator. In addition, we introduce a less conservative,\nsoft-robust, entropy-regularized objective with a corresponding Bellman\noperator. We show that both, robust and soft-robust policies, outperform their\nnon-robust counterparts in nine Mujoco domains with environment perturbations.\nIn addition, we show improved robust performance on a high-dimensional,\nsimulated, dexterous robotic hand. Finally, we present multiple investigative\nexperiments that provide a deeper insight into the robustness framework. This\nincludes an adaptation to another continuous control RL algorithm as well as\nlearning the uncertainty set from offline data. Performance videos can be found\nonline at https://sites.google.com/view/robust-rl.\n", "versions": [{"version": "v1", "created": "Tue, 18 Jun 2019 12:08:42 GMT"}, {"version": "v2", "created": "Tue, 11 Feb 2020 10:23:02 GMT"}], "update_date": "2020-02-12", "authors_parsed": [["Mankowitz", "Daniel J.", ""], ["Levine", "Nir", ""], ["Jeong", "Rae", ""], ["Shi", "Yuanyuan", ""], ["Kay", "Jackie", ""], ["Abdolmaleki", "Abbas", ""], ["Springenberg", "Jost Tobias", ""], ["Mann", "Timothy", ""], ["Hester", "Todd", ""], ["Riedmiller", "Martin", ""]]}, {"id": "1906.07622", "submitter": "Pranava Madhyastha", "authors": "Rishabh Jain and Pranava Madhyastha", "title": "Model Explanations under Calibration", "comments": "Accepted for publication in SIGIR 2019 Workshop on ExplainAble\n  Recommendation and Search (EARS 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Explaining and interpreting the decisions of recommender systems are becoming\nextremely relevant both, for improving predictive performance, and providing\nvalid explanations to users. While most of the recent interest has focused on\nproviding local explanations, there has been a much lower emphasis on studying\nthe effects of model dynamics and its impact on explanation. In this paper, we\nperform a focused study on the impact of model interpretability in the context\nof calibration. Specifically, we address the challenges of both over-confident\nand under-confident predictions with interpretability using attention\ndistribution. Our results indicate that the means of using attention\ndistributions for interpretability are highly unstable for un-calibrated\nmodels. Our empirical analysis on the stability of attention distribution\nraises questions on the utility of attention for explainability.\n", "versions": [{"version": "v1", "created": "Tue, 18 Jun 2019 14:50:36 GMT"}], "update_date": "2019-06-19", "authors_parsed": [["Jain", "Rishabh", ""], ["Madhyastha", "Pranava", ""]]}, {"id": "1906.07644", "submitter": "Andr\\'e Biedenkapp", "authors": "Andr\\'e Biedenkapp, H. Furkan Bozkurt, Frank Hutter, Marius Lindauer", "title": "Towards White-box Benchmarks for Algorithm Control", "comments": "8 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The performance of many algorithms in the fields of hard combinatorial\nproblem solving, machine learning or AI in general depends on tuned\nhyperparameter configurations. Automated methods have been proposed to\nalleviate users from the tedious and error-prone task of manually searching for\nperformance-optimized configurations across a set of problem instances. However\nthere is still a lot of untapped potential through adjusting an algorithm's\nhyperparameters online since different hyperparameters are potentially optimal\nat different stages of the algorithm. We formulate the problem of adjusting an\nalgorithm's hyperparameters for a given instance on the fly as a contextual\nMDP, making reinforcement learning (RL) the prime candidate to solve the\nresulting algorithm control problem in a data-driven way. Furthermore, inspired\nby applications of algorithm configuration, we introduce new white-box\nbenchmarks suitable to study algorithm control. We show that on short\nsequences, algorithm configuration is a valid choice, but that with increasing\nsequence length a black-box view on the problem quickly becomes infeasible and\nRL performs better.\n", "versions": [{"version": "v1", "created": "Tue, 18 Jun 2019 15:40:43 GMT"}, {"version": "v2", "created": "Thu, 22 Aug 2019 13:43:34 GMT"}], "update_date": "2019-08-23", "authors_parsed": [["Biedenkapp", "Andr\u00e9", ""], ["Bozkurt", "H. Furkan", ""], ["Hutter", "Frank", ""], ["Lindauer", "Marius", ""]]}, {"id": "1906.07663", "submitter": "Tamas Madarasz", "authors": "Tamas J. Madarasz", "title": "Better transfer learning with inferred successor maps", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Humans and animals show remarkable flexibility in adjusting their behaviour\nwhen their goals, or rewards in the environment change. While such flexibility\nis a hallmark of intelligent behaviour, these multi-task scenarios remain an\nimportant challenge for machine learning algorithms and neurobiological models\nalike. We investigated two approaches that could enable this flexibility:\nfactorized representations, which abstract away general aspects of a task from\nthose prone to change, and nonparametric, memory-based approaches, which can\nprovide a principled way of using similarity to past experiences to guide\ncurrent behaviour. In particular, we combine the successor representation (SR)\nthat factors the value of actions into expected outcomes and corresponding\nrewards with evaluating task similarity through clustering the space of reward\nfunctions. The proposed algorithm inverts a generative model over tasks, and\ndynamically samples from a flexible number of distinct SR maps while\naccumulating evidence about the current task context through amortized\ninference. It improves SR's transfer capabilities and outperforms competing\nalgorithms and baselines in settings with both known and unsignalled rewards\nchanges. Further, as a neurobiological model of spatial coding in the\nhippocampus, it explains important signatures of this representation, such as\nthe \"flickering\" behaviour of hippocampal maps, and trajectory-dependent place\ncells (so-called splitter cells) and their dynamics. We thus provide a novel\nalgorithmic approach for multi-task learning, as well as a common normative\nframework that links together these different characteristics of the brain's\nspatial representation.\n", "versions": [{"version": "v1", "created": "Tue, 18 Jun 2019 16:03:25 GMT"}, {"version": "v2", "created": "Tue, 2 Jul 2019 17:11:46 GMT"}, {"version": "v3", "created": "Thu, 31 Oct 2019 15:45:21 GMT"}, {"version": "v4", "created": "Fri, 6 Dec 2019 16:31:08 GMT"}, {"version": "v5", "created": "Fri, 10 Jan 2020 15:27:22 GMT"}], "update_date": "2020-01-13", "authors_parsed": [["Madarasz", "Tamas J.", ""]]}, {"id": "1906.07668", "submitter": "Tunazzina Islam", "authors": "Tunazzina Islam", "title": "Yoga-Veganism: Correlation Mining of Twitter Health Data", "comments": "In Proceedings of 8th KDD Workshop on Issues of Sentiment Discovery\n  and Opinion Mining (WISDOM) @KDD 2019. arXiv admin note: substantial text\n  overlap with arXiv:1906.02132", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nowadays social media is a huge platform of data. People usually share their\ninterest, thoughts via discussions, tweets, status. It is not possible to go\nthrough all the data manually. We need to mine the data to explore hidden\npatterns or unknown correlations, find out the dominant topic in data and\nunderstand people's interest through the discussions. In this work, we explore\nTwitter data related to health. We extract the popular topics under different\ncategories (e.g. diet, exercise) discussed in Twitter via topic modeling,\nobserve model behavior on new tweets, discover interesting correlation (i.e.\nYoga-Veganism). We evaluate accuracy by comparing with ground truth using\nmanual annotation both for train and test data.\n", "versions": [{"version": "v1", "created": "Sat, 15 Jun 2019 20:56:48 GMT"}], "update_date": "2020-12-21", "authors_parsed": [["Islam", "Tunazzina", ""]]}, {"id": "1906.07749", "submitter": "Volker Haarslev", "authors": "Zixi Quan and Volker Haarslev", "title": "A Framework for Parallelizing OWL Classification in Description Logic\n  Reasoners", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we report on a black-box approach to parallelize existing\ndescription logic (DL) reasoners for the Web Ontology Language (OWL). We focus\non OWL ontology classification, which is an important inference service and\nsupported by every major OWL/DL reasoner. We propose a flexible parallel\nframework which can be applied to existing OWL reasoners in order to speed up\ntheir classification process. In order to test its performance, we evaluated\nour framework by parallelizing major OWL reasoners for concept classification.\nIn comparison to the selected black-box reasoner our results demonstrate that\nthe wall clock time of ontology classification can be improved by one order of\nmagnitude for most real-world ontologies.\n", "versions": [{"version": "v1", "created": "Tue, 18 Jun 2019 18:16:17 GMT"}], "update_date": "2019-06-20", "authors_parsed": [["Quan", "Zixi", ""], ["Haarslev", "Volker", ""]]}, {"id": "1906.07754", "submitter": "Patrick O'Hara", "authors": "Patrick O'Hara, M.S. Ramanujan, Theodoros Damoulas", "title": "On the Constrained Least-cost Tour Problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce the Constrained Least-cost Tour (CLT) problem: given an\nundirected graph with weight and cost functions on the edges, minimise the\ntotal cost of a tour rooted at a start vertex such that the total weight lies\nwithin a given range. CLT is related to the family of Travelling Salesman\nProblems with Profits, but differs by defining the weight function on edges\ninstead of vertices, and by requiring the total weight to be within a range\ninstead of being at least some quota. We prove CLT is $\\mathcal{NP}$-hard, even\nin the simple case when the input graph is a path. We derive an informative\nlower bound by relaxing the integrality of edges and propose a heuristic\nmotivated by this relaxation. For the case that requires the tour to be a\nsimple cycle, we develop two heuristics which exploit Suurballe's algorithm to\nfind low-cost, weight-feasible cycles. We demonstrate our algorithms by\naddressing a real-world problem that affects urban populations: finding routes\nthat minimise air pollution exposure for walking, running and cycling in the\ncity of London.\n", "versions": [{"version": "v1", "created": "Tue, 18 Jun 2019 18:28:17 GMT"}], "update_date": "2019-06-20", "authors_parsed": [["O'Hara", "Patrick", ""], ["Ramanujan", "M. S.", ""], ["Damoulas", "Theodoros", ""]]}, {"id": "1906.07791", "submitter": "Yangchen Pan", "authors": "Yangchen Pan, Hengshuai Yao, Amir-massoud Farahmand, Martha White", "title": "Hill Climbing on Value Estimates for Search-control in Dyna", "comments": "IJCAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dyna is an architecture for model-based reinforcement learning (RL), where\nsimulated experience from a model is used to update policies or value\nfunctions. A key component of Dyna is search-control, the mechanism to generate\nthe state and action from which the agent queries the model, which remains\nlargely unexplored. In this work, we propose to generate such states by using\nthe trajectory obtained from Hill Climbing (HC) the current estimate of the\nvalue function. This has the effect of propagating value from high-value\nregions and of preemptively updating value estimates of the regions that the\nagent is likely to visit next. We derive a noisy projected natural gradient\nalgorithm for hill climbing, and highlight a connection to Langevin dynamics.\nWe provide an empirical demonstration on four classical domains that our\nalgorithm, HC-Dyna, can obtain significant sample efficiency improvements. We\nstudy the properties of different sampling distributions for search-control,\nand find that there appears to be a benefit specifically from using the samples\ngenerated by climbing on current value estimates from low-value to high-value\nregion.\n", "versions": [{"version": "v1", "created": "Tue, 18 Jun 2019 20:24:45 GMT"}, {"version": "v2", "created": "Sun, 23 Jun 2019 04:03:47 GMT"}, {"version": "v3", "created": "Thu, 4 Jul 2019 08:26:53 GMT"}], "update_date": "2019-07-05", "authors_parsed": [["Pan", "Yangchen", ""], ["Yao", "Hengshuai", ""], ["Farahmand", "Amir-massoud", ""], ["White", "Martha", ""]]}, {"id": "1906.07805", "submitter": "Zhaohan Guo", "authors": "Zhaohan Daniel Guo, Emma Brunskill", "title": "Directed Exploration for Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Efficient exploration is necessary to achieve good sample efficiency for\nreinforcement learning in general. From small, tabular settings such as\ngridworlds to large, continuous and sparse reward settings such as robotic\nobject manipulation tasks, exploration through adding an uncertainty bonus to\nthe reward function has been shown to be effective when the uncertainty is able\nto accurately drive exploration towards promising states. However reward\nbonuses can still be inefficient since they are non-stationary, which means\nthat we must wait for function approximators to catch up and converge again\nwhen uncertainties change. We propose the idea of directed exploration, that is\nlearning a goal-conditioned policy where goals are simply other states, and\nusing that to directly try to reach states with large uncertainty. The\ngoal-conditioned policy is independent of uncertainty and is thus stationary.\nWe show in our experiments how directed exploration is more efficient at\nexploration and more robust to how the uncertainty is computed than adding\nbonuses to rewards.\n", "versions": [{"version": "v1", "created": "Tue, 18 Jun 2019 20:44:07 GMT"}], "update_date": "2019-06-20", "authors_parsed": [["Guo", "Zhaohan Daniel", ""], ["Brunskill", "Emma", ""]]}, {"id": "1906.07809", "submitter": "Parisa Kordjamshidi", "authors": "Parisa Kordjamshidi, Dan Roth, Kristian Kersting", "title": "Declarative Learning-Based Programming as an Interface to AI Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data-driven approaches are becoming more common as problem-solving techniques\nin many areas of research and industry. In most cases, machine learning models\nare the key component of these solutions, but a solution involves multiple such\nmodels, along with significant levels of reasoning with the models' output and\ninput. Current technologies do not make such techniques easy to use for\napplication experts who are not fluent in machine learning nor for machine\nlearning experts who aim at testing ideas and models on real-world data in the\ncontext of the overall AI system. We review key efforts made by various AI\ncommunities to provide languages for high-level abstractions over learning and\nreasoning techniques needed for designing complex AI systems. We classify the\nexisting frameworks based on the type of techniques and the data and knowledge\nrepresentations they use, provide a comparative study of the way they address\nthe challenges of programming real-world applications, and highlight some\nshortcomings and future directions.\n", "versions": [{"version": "v1", "created": "Tue, 18 Jun 2019 20:57:51 GMT"}], "update_date": "2019-06-20", "authors_parsed": [["Kordjamshidi", "Parisa", ""], ["Roth", "Dan", ""], ["Kersting", "Kristian", ""]]}, {"id": "1906.07838", "submitter": "Paul Budnarain", "authors": "Paul Budnarain, Renato Ferreira Pinto Junior, Ilan Kogan", "title": "RadGrad: Active learning with loss gradients", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Solving sequential decision prediction problems, including those in imitation\nlearning settings, requires mitigating the problem of covariate shift. The\nstandard approach, DAgger, relies on capturing expert behaviour in all states\nthat the agent reaches. In real-world settings, querying an expert is costly.\nWe propose a new active learning algorithm that selectively queries the expert,\nbased on both a prediction of agent error and a proxy for agent risk, that\nmaintains the performance of unrestrained expert querying systems while\nsubstantially reducing the number of expert queries made. We show that our\napproach, RadGrad, has the potential to improve upon existing safety-aware\nalgorithms, and matches or exceeds the performance of DAgger and variants\n(i.e., SafeDAgger) in one simulated environment. However, we also find that a\nmore complex environment poses challenges not only to our proposed method, but\nalso to existing safety-aware algorithms, which do not match the performance of\nDAgger in our experiments.\n", "versions": [{"version": "v1", "created": "Tue, 18 Jun 2019 23:02:48 GMT"}], "update_date": "2019-06-20", "authors_parsed": [["Budnarain", "Paul", ""], ["Junior", "Renato Ferreira Pinto", ""], ["Kogan", "Ilan", ""]]}, {"id": "1906.07865", "submitter": "Cameron Linke", "authors": "Cam Linke, Nadia M. Ady, Martha White, Thomas Degris, Adam White", "title": "Adapting Behaviour via Intrinsic Reward: A Survey and Empirical Study", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning about many things can provide numerous benefits to a reinforcement\nlearning system. For example, learning many auxiliary value functions, in\naddition to optimizing the environmental reward, appears to improve both\nexploration and representation learning. The question we tackle in this paper\nis how to sculpt the stream of experience---how to adapt the learning system's\nbehavior---to optimize the learning of a collection of value functions. A\nsimple answer is to compute an intrinsic reward based on the statistics of each\nauxiliary learner, and use reinforcement learning to maximize that intrinsic\nreward. Unfortunately, implementing this simple idea has proven difficult, and\nthus has been the focus of decades of study. It remains unclear which of the\nmany possible measures of learning would work well in a parallel learning\nsetting where environmental reward is extremely sparse or absent. In this\npaper, we investigate and compare different intrinsic reward mechanisms in a\nnew bandit-like parallel-learning testbed. We discuss the interaction between\nreward and prediction learners and highlight the importance of introspective\nprediction learners: those that increase their rate of learning when progress\nis possible, and decrease when it is not. We provide a comprehensive empirical\ncomparison of 14 different rewards, including well-known ideas from\nreinforcement learning and active learning. Our results highlight a simple but\nseemingly powerful principle: intrinsic rewards based on the amount of learning\ncan generate useful behavior, if each individual learner is introspective.\n", "versions": [{"version": "v1", "created": "Wed, 19 Jun 2019 01:07:12 GMT"}, {"version": "v2", "created": "Sat, 25 Apr 2020 23:39:27 GMT"}, {"version": "v3", "created": "Fri, 15 May 2020 15:59:09 GMT"}, {"version": "v4", "created": "Sat, 22 Aug 2020 03:33:39 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Linke", "Cam", ""], ["Ady", "Nadia M.", ""], ["White", "Martha", ""], ["Degris", "Thomas", ""], ["White", "Adam", ""]]}, {"id": "1906.07900", "submitter": "Chen Wang", "authors": "Chen Wang, Hui Ma, Gang Chen, and Sven Hartmann", "title": "Memetic EDA-Based Approaches to Comprehensive Quality-Aware Automated\n  Semantic Web Service Composition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Comprehensive quality-aware automated semantic web service composition is an\nNP-hard problem, where service composition workflows are unknown, and\ncomprehensive quality, i.e., Quality of services (QoS) and Quality of semantic\nmatchmaking (QoSM) are simultaneously optimized. The objective of this problem\nis to find a solution with optimized or near-optimized overall QoS and QoSM\nwithin polynomial time over a service request. In this paper, we proposed novel\nmemetic EDA-based approaches to tackle this problem. The proposed method\ninvestigates the effectiveness of several neighborhood structures of composite\nservices by proposing domain-dependent local search operators. Apart from that,\na joint strategy of the local search procedure is proposed to integrate with a\nmodified EDA to reduce the overall computation time of our memetic approach. To\nbetter demonstrate the effectiveness and scalability of our approach, we create\na more challenging, augmented version of the service composition benchmark\nbased on WSC-08 \\cite{bansal2008wsc} and WSC-09 \\cite{kona2009wsc}.\nExperimental results on this benchmark show that one of our proposed memetic\nEDA-based approach (i.e., MEEDA-LOP) significantly outperforms existing\nstate-of-the-art algorithms.\n", "versions": [{"version": "v1", "created": "Wed, 19 Jun 2019 03:45:37 GMT"}], "update_date": "2019-06-20", "authors_parsed": [["Wang", "Chen", ""], ["Ma", "Hui", ""], ["Chen", "Gang", ""], ["Hartmann", "Sven", ""]]}, {"id": "1906.07987", "submitter": "Hugo Penedones", "authors": "Hugo Penedones, Carlos Riquelme, Damien Vincent, Hartmut Maennel,\n  Timothy Mann, Andre Barreto, Sylvain Gelly, Gergely Neu", "title": "Adaptive Temporal-Difference Learning for Policy Evaluation with\n  Per-State Uncertainty Estimates", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the core reinforcement-learning problem of on-policy value\nfunction approximation from a batch of trajectory data, and focus on various\nissues of Temporal Difference (TD) learning and Monte Carlo (MC) policy\nevaluation. The two methods are known to achieve complementary bias-variance\ntrade-off properties, with TD tending to achieve lower variance but potentially\nhigher bias. In this paper, we argue that the larger bias of TD can be a result\nof the amplification of local approximation errors. We address this by\nproposing an algorithm that adaptively switches between TD and MC in each\nstate, thus mitigating the propagation of errors. Our method is based on\nlearned confidence intervals that detect biases of TD estimates. We demonstrate\nin a variety of policy evaluation tasks that this simple adaptive algorithm\nperforms competitively with the best approach in hindsight, suggesting that\nlearned confidence intervals are a powerful technique for adapting policy\nevaluation to use TD or MC returns in a data-driven way.\n", "versions": [{"version": "v1", "created": "Wed, 19 Jun 2019 09:22:22 GMT"}], "update_date": "2019-06-20", "authors_parsed": [["Penedones", "Hugo", ""], ["Riquelme", "Carlos", ""], ["Vincent", "Damien", ""], ["Maennel", "Hartmut", ""], ["Mann", "Timothy", ""], ["Barreto", "Andre", ""], ["Gelly", "Sylvain", ""], ["Neu", "Gergely", ""]]}, {"id": "1906.08061", "submitter": "Nir Lipovetzky", "authors": "Alfonso E. Gerevini, Nir Lipovetzky, Nico Peli, Francesco Percassi,\n  Alessandro Saetti, Ivan Serina", "title": "Novelty Messages Filtering for Multi Agent Privacy-preserving Planning", "comments": "Accepted in SOCS-19. arXiv admin note: text overlap with\n  arXiv:1706.06927 by other authors and arXiv:1906.03955", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In multi-agent planning, agents jointly compute a plan that achieves mutual\ngoals, keeping certain information private to the individual agents. Agents'\ncoordination is achieved through the transmission of messages. These messages\ncan be a source of privacy leakage as they can permit a malicious agent to\ncollect information about other agents' actions and search states. In this\npaper, we investigate the usage of novelty techniques in the context of\n(decentralised) multi-agent privacy-preserving planning, addressing the\nchallenges related to the agents' privacy and performance. In particular, we\nshow that the use of novelty based techniques can significantly reduce the\nnumber of messages transmitted among agents, better preserving their privacy\nand improving their performance. An experimental study analyses the\neffectiveness of our techniques and compares them with the state-of-the-art.\nFinally, we evaluate the robustness of our approach, considering different\ndelays in the transmission of messages as they would occur in overloaded\nnetworks, due for example to massive attacks or critical situations.\n", "versions": [{"version": "v1", "created": "Tue, 18 Jun 2019 06:49:13 GMT"}], "update_date": "2019-06-20", "authors_parsed": [["Gerevini", "Alfonso E.", ""], ["Lipovetzky", "Nir", ""], ["Peli", "Nico", ""], ["Percassi", "Francesco", ""], ["Saetti", "Alessandro", ""], ["Serina", "Ivan", ""]]}, {"id": "1906.08097", "submitter": "Luigi Asprino", "authors": "Luigi Asprino, Wouter Beek, Paolo Ciancarini, Frank van Harmelen and\n  Valentina Presutti", "title": "Observing LOD using Equivalent Set Graphs: it is mostly flat and\n  sparsely linked", "comments": "18 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  This paper presents an empirical study aiming at understanding the modeling\nstyle and the overall semantic structure of Linked Open Data. We observe how\nclasses, properties and individuals are used in practice. We also investigate\nhow hierarchies of concepts are structured, and how much they are linked. In\naddition to discussing the results, this paper contributes (i) a conceptual\nframework, including a set of metrics, which generalises over the observable\nconstructs; (ii) an open source implementation that facilitates its application\nto other Linked Data knowledge graphs.\n", "versions": [{"version": "v1", "created": "Wed, 19 Jun 2019 13:48:08 GMT"}, {"version": "v2", "created": "Mon, 8 Jul 2019 16:49:46 GMT"}, {"version": "v3", "created": "Thu, 18 Jul 2019 16:48:47 GMT"}], "update_date": "2019-07-19", "authors_parsed": [["Asprino", "Luigi", ""], ["Beek", "Wouter", ""], ["Ciancarini", "Paolo", ""], ["van Harmelen", "Frank", ""], ["Presutti", "Valentina", ""]]}, {"id": "1906.08157", "submitter": "Daniel Furelos-Blanco", "authors": "Daniel Furelos-Blanco and Anders Jonsson", "title": "Solving Multiagent Planning Problems with Concurrent Conditional Effects", "comments": "Preprint accepted for publication to the 33rd AAAI Conference on\n  Artificial Intelligence (AAAI-19)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we present a novel approach to solving concurrent multiagent\nplanning problems in which several agents act in parallel. Our approach relies\non a compilation from concurrent multiagent planning to classical planning,\nallowing us to use an off-the-shelf classical planner to solve the original\nmultiagent problem. The solution can be directly interpreted as a concurrent\nplan that satisfies a given set of concurrency constraints, while avoiding the\nexponential blowup associated with concurrent actions. Our planner is the first\nto handle action effects that are conditional on what other agents are doing.\nTheoretically, we show that the compilation is sound and complete. Empirically,\nwe show that our compilation can solve challenging multiagent planning problems\nthat require concurrent actions.\n", "versions": [{"version": "v1", "created": "Wed, 19 Jun 2019 15:34:37 GMT"}], "update_date": "2019-06-20", "authors_parsed": [["Furelos-Blanco", "Daniel", ""], ["Jonsson", "Anders", ""]]}, {"id": "1906.08160", "submitter": "Nikhil Garg", "authors": "Nikhil Garg, Lodewijk Gelauff, Sukolsak Sakshuwong, Ashish Goel", "title": "Who is in Your Top Three? Optimizing Learning in Elections with Many\n  Candidates", "comments": "To appear in HCOMP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Elections and opinion polls often have many candidates, with the aim to\neither rank the candidates or identify a small set of winners according to\nvoters' preferences. In practice, voters do not provide a full ranking;\ninstead, each voter provides their favorite K candidates, potentially in ranked\norder. The election organizer must choose K and an aggregation rule.\n  We provide a theoretical framework to make these choices. Each K-Approval or\nK-partial ranking mechanism (with a corresponding positional scoring rule)\ninduces a learning rate for the speed at which the election correctly recovers\nthe asymptotic outcome. Given the voter choice distribution, the election\nplanner can thus identify the rate optimal mechanism. Earlier work in this area\nprovides coarse order-of-magnitude guaranties which are not sufficient to make\nsuch choices. Our framework further resolves questions of when randomizing\nbetween multiple mechanisms may improve learning, for arbitrary voter noise\nmodels.\n  Finally, we use data from 5 large participatory budgeting elections that we\norganized across several US cities, along with other ranking data, to\ndemonstrate the utility of our methods. In particular, we find that\nhistorically such elections have set K too low and that picking the right\nmechanism can be the difference between identifying the ultimate winner with\nonly a 80% probability or a 99.9% probability after 400 voters.\n", "versions": [{"version": "v1", "created": "Wed, 19 Jun 2019 15:36:24 GMT"}, {"version": "v2", "created": "Thu, 15 Aug 2019 00:06:10 GMT"}], "update_date": "2019-08-16", "authors_parsed": [["Garg", "Nikhil", ""], ["Gelauff", "Lodewijk", ""], ["Sakshuwong", "Sukolsak", ""], ["Goel", "Ashish", ""]]}, {"id": "1906.08190", "submitter": "Sebastian Blaes", "authors": "Sebastian Blaes, Marin Vlastelica Pogan\\v{c}i\\'c, Jia-Jie Zhu, Georg\n  Martius", "title": "Control What You Can: Intrinsically Motivated Task-Planning Agent", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel intrinsically motivated agent that learns how to control\nthe environment in the fastest possible manner by optimizing learning progress.\nIt learns what can be controlled, how to allocate time and attention, and the\nrelations between objects using surprise based motivation. The effectiveness of\nour method is demonstrated in a synthetic as well as a robotic manipulation\nenvironment yielding considerably improved performance and smaller sample\ncomplexity. In a nutshell, our work combines several task-level planning agent\nstructures (backtracking search on task graph, probabilistic road-maps,\nallocation of search efforts) with intrinsic motivation to achieve learning\nfrom scratch.\n", "versions": [{"version": "v1", "created": "Wed, 19 Jun 2019 16:08:23 GMT"}, {"version": "v2", "created": "Thu, 9 Jan 2020 08:43:50 GMT"}], "update_date": "2020-01-10", "authors_parsed": [["Blaes", "Sebastian", ""], ["Pogan\u010di\u0107", "Marin Vlastelica", ""], ["Zhu", "Jia-Jie", ""], ["Martius", "Georg", ""]]}, {"id": "1906.08222", "submitter": "Khaled Nagaty Prof.", "authors": "Khaled Ahmed Nagaty", "title": "Deep Fuzzy Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.OH cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An investigation of deep fuzzy systems is presented in this paper. A deep\nfuzzy system is represented by recursive fuzzy systems from an input terminal\nto output terminal. Recursive fuzzy systems are sequences of fuzzy grade\nmemberships obtained using fuzzy transmition functions and recursive calls to\nfuzzy systems. A recursive fuzzy system which calls a fuzzy system n times\nincludes fuzzy chains to evaluate the final grade membership of this recursive\nsystem. A connection matrix which includes recursive calls are used to\nrepresent recursive fuzzy systems.\n", "versions": [{"version": "v1", "created": "Thu, 23 May 2019 08:48:37 GMT"}], "update_date": "2019-06-20", "authors_parsed": [["Nagaty", "Khaled Ahmed", ""]]}, {"id": "1906.08236", "submitter": "Lerrel Pinto Mr", "authors": "Adithyavairavan Murali, Tao Chen, Kalyan Vasudev Alwala, Dhiraj\n  Gandhi, Lerrel Pinto, Saurabh Gupta, Abhinav Gupta", "title": "PyRobot: An Open-source Robotics Framework for Research and Benchmarking", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces PyRobot, an open-source robotics framework for research\nand benchmarking. PyRobot is a light-weight, high-level interface on top of ROS\nthat provides a consistent set of hardware independent mid-level APIs to\ncontrol different robots. PyRobot abstracts away details about low-level\ncontrollers and inter-process communication, and allows non-robotics\nresearchers (ML, CV researchers) to focus on building high-level AI\napplications. PyRobot aims to provide a research ecosystem with convenient\naccess to robotics datasets, algorithm implementations and models that can be\nused to quickly create a state-of-the-art baseline. We believe PyRobot, when\npaired up with low-cost robot platforms such as LoCoBot, will reduce the entry\nbarrier into robotics, and democratize robotics. PyRobot is open-source, and\ncan be accessed via https://pyrobot.org.\n", "versions": [{"version": "v1", "created": "Wed, 19 Jun 2019 17:35:43 GMT"}], "update_date": "2019-06-20", "authors_parsed": [["Murali", "Adithyavairavan", ""], ["Chen", "Tao", ""], ["Alwala", "Kalyan Vasudev", ""], ["Gandhi", "Dhiraj", ""], ["Pinto", "Lerrel", ""], ["Gupta", "Saurabh", ""], ["Gupta", "Abhinav", ""]]}, {"id": "1906.08253", "submitter": "Michael Janner", "authors": "Michael Janner, Justin Fu, Marvin Zhang, Sergey Levine", "title": "When to Trust Your Model: Model-Based Policy Optimization", "comments": "NeurIPS 2019. Code at https://github.com/JannerM/mbpo, project page\n  at: https://people.eecs.berkeley.edu/~janner/mbpo/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Designing effective model-based reinforcement learning algorithms is\ndifficult because the ease of data generation must be weighed against the bias\nof model-generated data. In this paper, we study the role of model usage in\npolicy optimization both theoretically and empirically. We first formulate and\nanalyze a model-based reinforcement learning algorithm with a guarantee of\nmonotonic improvement at each step. In practice, this analysis is overly\npessimistic and suggests that real off-policy data is always preferable to\nmodel-generated on-policy data, but we show that an empirical estimate of model\ngeneralization can be incorporated into such analysis to justify model usage.\nMotivated by this analysis, we then demonstrate that a simple procedure of\nusing short model-generated rollouts branched from real data has the benefits\nof more complicated model-based algorithms without the usual pitfalls. In\nparticular, this approach surpasses the sample efficiency of prior model-based\nmethods, matches the asymptotic performance of the best model-free algorithms,\nand scales to horizons that cause other model-based methods to fail entirely.\n", "versions": [{"version": "v1", "created": "Wed, 19 Jun 2019 17:54:53 GMT"}, {"version": "v2", "created": "Tue, 5 Nov 2019 01:22:47 GMT"}], "update_date": "2019-11-06", "authors_parsed": [["Janner", "Michael", ""], ["Fu", "Justin", ""], ["Zhang", "Marvin", ""], ["Levine", "Sergey", ""]]}, {"id": "1906.08291", "submitter": "Hang Ma", "authors": "Roni Stern and Nathan Sturtevant and Ariel Felner and Sven Koenig and\n  Hang Ma and Thayne Walker and Jiaoyang Li and Dor Atzmon and Liron Cohen and\n  T. K. Satish Kumar and Eli Boyarski and Roman Bartak", "title": "Multi-Agent Pathfinding: Definitions, Variants, and Benchmarks", "comments": "Accepted to SoCS 2019: The 12th Annual Symposium on Combinatorial\n  Search", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.MA cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The MAPF problem is the fundamental problem of planning paths for multiple\nagents, where the key constraint is that the agents will be able to follow\nthese paths concurrently without colliding with each other. Applications of\nMAPF include automated warehouses and autonomous vehicles. Research on MAPF has\nbeen flourishing in the past couple of years. Different MAPF research papers\nmake different assumptions, e.g., whether agents can traverse the same road at\nthe same time, and have different objective functions, e.g., minimize makespan\nor sum of agents' actions costs. These assumptions and objectives are sometimes\nimplicitly assumed or described informally. This makes it difficult to\nestablish appropriate baselines for comparison in research papers, as well as\nmaking it difficult for practitioners to find the papers relevant to their\nconcrete application. This paper aims to fill this gap and support researchers\nand practitioners by providing a unifying terminology for describing common\nMAPF assumptions and objectives. In addition, we also provide pointers to two\nMAPF benchmarks. In particular, we introduce a new grid-based benchmark for\nMAPF, and demonstrate experimentally that it poses a challenge to contemporary\nMAPF algorithms.\n", "versions": [{"version": "v1", "created": "Wed, 19 Jun 2019 18:17:14 GMT"}], "update_date": "2019-06-21", "authors_parsed": [["Stern", "Roni", ""], ["Sturtevant", "Nathan", ""], ["Felner", "Ariel", ""], ["Koenig", "Sven", ""], ["Ma", "Hang", ""], ["Walker", "Thayne", ""], ["Li", "Jiaoyang", ""], ["Atzmon", "Dor", ""], ["Cohen", "Liron", ""], ["Kumar", "T. K. Satish", ""], ["Boyarski", "Eli", ""], ["Bartak", "Roman", ""]]}, {"id": "1906.08305", "submitter": "Hsin-Pai Cheng", "authors": "Hsin-Pai Cheng, Tunhou Zhang, Yukun Yang, Feng Yan, Shiyu Li, Harris\n  Teague, Hai Li, and Yiran Chen", "title": "SwiftNet: Using Graph Propagation as Meta-knowledge to Search Highly\n  Representative Neural Architectures", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Designing neural architectures for edge devices is subject to constraints of\naccuracy, inference latency, and computational cost. Traditionally, researchers\nmanually craft deep neural networks to meet the needs of mobile devices. Neural\nArchitecture Search (NAS) was proposed to automate the neural architecture\ndesign without requiring extensive domain expertise and significant manual\nefforts. Recent works utilized NAS to design mobile models by taking into\naccount hardware constraints and achieved state-of-the-art accuracy with fewer\nparameters and less computational cost measured in Multiply-accumulates (MACs).\nTo find highly compact neural architectures, existing works relies on\npredefined cells and directly applying width multiplier, which may potentially\nlimit the model flexibility, reduce the useful feature map information, and\ncause accuracy drop. To conquer this issue, we propose GRAM(GRAph propagation\nas Meta-knowledge) that adopts fine-grained (node-wise) search method and\naccumulates the knowledge learned in updates into a meta-graph. As a result,\nGRAM can enable more flexible search space and achieve higher search\nefficiency. Without the constraints of predefined cell or blocks, we propose a\nnew structure-level pruning method to remove redundant operations in neural\narchitectures. SwiftNet, which is a set of models discovered by GRAM,\noutperforms MobileNet-V2 by 2.15x higher accuracy density and 2.42x faster with\nsimilar accuracy. Compared with FBNet, SwiftNet reduces the search cost by 26x\nand achieves 2.35x higher accuracy density and 1.47x speedup while preserving\nsimilar accuracy. SwiftNetcan obtain 63.28% top-1 accuracy on ImageNet-1K with\nonly 53M MACs and 2.07M parameters. The corresponding inference latency is only\n19.09 ms on Google Pixel 1.\n", "versions": [{"version": "v1", "created": "Wed, 19 Jun 2019 19:00:12 GMT"}, {"version": "v2", "created": "Tue, 25 Jun 2019 23:33:24 GMT"}], "update_date": "2019-06-27", "authors_parsed": [["Cheng", "Hsin-Pai", ""], ["Zhang", "Tunhou", ""], ["Yang", "Yukun", ""], ["Yan", "Feng", ""], ["Li", "Shiyu", ""], ["Teague", "Harris", ""], ["Li", "Hai", ""], ["Chen", "Yiran", ""]]}, {"id": "1906.08362", "submitter": "Roberto Confalonieri", "authors": "Roberto Confalonieri, Tillman Weyde, Tarek R. Besold, Ferm\\'in Moscoso\n  del Prado Mart\\'in", "title": "Trepan Reloaded: A Knowledge-driven Approach to Explaining Artificial\n  Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Explainability in Artificial Intelligence has been revived as a topic of\nactive research by the need of conveying safety and trust to users in the `how'\nand `why' of automated decision-making. Whilst a plethora of approaches have\nbeen developed for post-hoc explainability, only a few focus on how to use\ndomain knowledge, and how this influences the understandability of global\nexplanations from the users' perspective. In this paper, we show how ontologies\nhelp the understandability of global post-hoc explanations, presented in the\nform of symbolic models. In particular, we build on Trepan, an algorithm that\nexplains artificial neural networks by means of decision trees, and we extend\nit to include ontologies modeling domain knowledge in the process of generating\nexplanations. We present the results of a user study that measures the\nunderstandability of decision trees using a syntactic complexity measure, and\nthrough time and accuracy of responses as well as reported user confidence and\nunderstandability. The user study considers domains where explanations are\ncritical, namely, in finance and medicine. The results show that decision trees\ngenerated with our algorithm, taking into account domain knowledge, are more\nunderstandable than those generated by standard Trepan without the use of\nontologies.\n", "versions": [{"version": "v1", "created": "Wed, 19 Jun 2019 21:22:34 GMT"}, {"version": "v2", "created": "Thu, 21 Nov 2019 11:59:21 GMT"}], "update_date": "2019-11-22", "authors_parsed": [["Confalonieri", "Roberto", ""], ["Weyde", "Tillman", ""], ["Besold", "Tarek R.", ""], ["Mart\u00edn", "Ferm\u00edn Moscoso del Prado", ""]]}, {"id": "1906.08382", "submitter": "Haseeb Shah", "authors": "Haseeb Shah, Johannes Villmow, Adrian Ulges, Ulrich Schwanecke and\n  Faisal Shafait", "title": "An Open-World Extension to Knowledge Graph Completion Models", "comments": "8 pages, accepted to AAAI-2019", "journal-ref": "AAAI-19 Vol 33 (2019) 3044-3051", "doi": "10.1609/aaai.v33i01.33013044", "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel extension to embedding-based knowledge graph completion\nmodels which enables them to perform open-world link prediction, i.e. to\npredict facts for entities unseen in training based on their textual\ndescription. Our model combines a regular link prediction model learned from a\nknowledge graph with word embeddings learned from a textual corpus. After\ntraining both independently, we learn a transformation to map the embeddings of\nan entity's name and description to the graph-based embedding space. In\nexperiments on several datasets including FB20k, DBPedia50k and our new dataset\nFB15k-237-OWE, we demonstrate competitive results. Particularly, our approach\nexploits the full knowledge graph structure even when textual descriptions are\nscarce, does not require a joint training on graph and text, and can be applied\nto any embedding-based link prediction model, such as TransE, ComplEx and\nDistMult.\n", "versions": [{"version": "v1", "created": "Wed, 19 Jun 2019 22:23:20 GMT"}], "update_date": "2020-01-10", "authors_parsed": [["Shah", "Haseeb", ""], ["Villmow", "Johannes", ""], ["Ulges", "Adrian", ""], ["Schwanecke", "Ulrich", ""], ["Shafait", "Faisal", ""]]}, {"id": "1906.08386", "submitter": "Han Zhao", "authors": "Han Zhao, Geoffrey J. Gordon", "title": "Inherent Tradeoffs in Learning Fair Representations", "comments": "Appeared in NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the prevalence of machine learning in high-stakes applications,\nespecially the ones regulated by anti-discrimination laws or societal norms, it\nis crucial to ensure that the predictive models do not propagate any existing\nbias or discrimination. Due to the ability of deep neural nets to learn rich\nrepresentations, recent advances in algorithmic fairness have focused on\nlearning fair representations with adversarial techniques to reduce bias in\ndata while preserving utility simultaneously. In this paper, through the lens\nof information theory, we provide the first result that quantitatively\ncharacterizes the tradeoff between demographic parity and the joint utility\nacross different population groups. Specifically, when the base rates differ\nbetween groups, we show that any method aiming to learn fair representations\nadmits an information-theoretic lower bound on the joint error across these\ngroups. To complement our negative results, we also prove that if the optimal\ndecision functions across different groups are close, then learning fair\nrepresentations leads to an alternative notion of fairness, known as the\naccuracy parity, which states that the error rates are close between groups.\nFinally, our theoretical findings are also confirmed empirically on real-world\ndatasets.\n", "versions": [{"version": "v1", "created": "Wed, 19 Jun 2019 22:44:14 GMT"}, {"version": "v2", "created": "Thu, 17 Oct 2019 18:49:45 GMT"}, {"version": "v3", "created": "Sun, 7 Jun 2020 18:54:23 GMT"}, {"version": "v4", "created": "Fri, 16 Oct 2020 07:28:58 GMT"}], "update_date": "2020-10-19", "authors_parsed": [["Zhao", "Han", ""], ["Gordon", "Geoffrey J.", ""]]}, {"id": "1906.08464", "submitter": "Majid Moghadam", "authors": "Majid Moghadam, Gabriel Hugh Elkaim", "title": "A Hierarchical Architecture for Sequential Decision-Making in Autonomous\n  Driving using Deep Reinforcement Learning", "comments": "Appears in ICML 2019 workshop on Real-world Sequential Decision\n  Making: Reinforcement Learning and Beyond. Source code available in:\n  https://github.com/MajidMoghadam2006", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tactical decision making is a critical feature for advanced driving systems,\nthat incorporates several challenges such as complexity of the uncertain\nenvironment and reliability of the autonomous system. In this work, we develop\na multi-modal architecture that includes the environmental modeling of ego\nsurrounding and train a deep reinforcement learning (DRL) agent that yields\nconsistent performance in stochastic highway driving scenarios. To this end, we\nfeed the occupancy grid of the ego surrounding into the DRL agent and obtain\nthe high-level sequential commands (i.e. lane change) to send them to\nlower-level controllers. We will show that dividing the autonomous driving\nproblem into a multi-layer control architecture enables us to leverage the AI\npower to solve each layer separately and achieve an admissible reliability\nscore. Comparing with end-to-end approaches, this architecture enables us to\nend up with a more reliable system which can be implemented in actual\nself-driving cars.\n", "versions": [{"version": "v1", "created": "Thu, 20 Jun 2019 07:05:20 GMT"}], "update_date": "2019-06-21", "authors_parsed": [["Moghadam", "Majid", ""], ["Elkaim", "Gabriel Hugh", ""]]}, {"id": "1906.08487", "submitter": "Jamin Shin", "authors": "Jamin Shin, Peng Xu, Andrea Madotto, Pascale Fung", "title": "HappyBot: Generating Empathetic Dialogue Responses by Improving User\n  Experience Look-ahead", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent neural conversation models that attempted to incorporate emotion and\ngenerate empathetic responses either focused on conditioning the output to a\ngiven emotion, or incorporating the current user emotional state. While these\napproaches have been successful to some extent in generating more diverse and\nseemingly engaging utterances, they do not factor in how the user would feel\ntowards the generated dialogue response. Hence, in this paper, we advocate such\nlook-ahead of user emotion as the key to modeling and generating empathetic\ndialogue responses. We thus train a Sentiment Predictor to estimate the user\nsentiment look-ahead towards the generated system responses, which is then used\nas the reward function for generating more empathetic responses. Human\nevaluation results show that our model outperforms other baselines in empathy,\nrelevance, and fluency.\n", "versions": [{"version": "v1", "created": "Thu, 20 Jun 2019 08:03:58 GMT"}], "update_date": "2019-06-21", "authors_parsed": [["Shin", "Jamin", ""], ["Xu", "Peng", ""], ["Madotto", "Andrea", ""], ["Fung", "Pascale", ""]]}, {"id": "1906.08494", "submitter": "Abdul Rahman Dabbour", "authors": "Abdul Rahman Dabbour, Esra Erdem, and Volkan Patoglu", "title": "Object Placement on Cluttered Surfaces: A Nested Local Search Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For planning rearrangements of objects in a clutter, it is required to know\nthe goal configuration of the objects. However, in real life scenarios, this\ninformation is not available most of the time. We introduce a novel method that\ncomputes a collision-free placement of objects on a cluttered surface, while\nminimizing the total number and amount of displacements of the existing\nmoveable objects. Our method applies nested local searches that perform\nmulti-objective optimizations guided by heuristics. Experimental evaluations\ndemonstrate high computational efficiency and success rate of our method, as\nwell as good quality of solutions.\n", "versions": [{"version": "v1", "created": "Thu, 20 Jun 2019 08:21:07 GMT"}], "update_date": "2019-06-21", "authors_parsed": [["Dabbour", "Abdul Rahman", ""], ["Erdem", "Esra", ""], ["Patoglu", "Volkan", ""]]}, {"id": "1906.08495", "submitter": "Meng Qu", "authors": "Meng Qu, Jian Tang", "title": "Probabilistic Logic Neural Networks for Reasoning", "comments": "NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge graph reasoning, which aims at predicting the missing facts through\nreasoning with the observed facts, is critical to many applications. Such a\nproblem has been widely explored by traditional logic rule-based approaches and\nrecent knowledge graph embedding methods. A principled logic rule-based\napproach is the Markov Logic Network (MLN), which is able to leverage domain\nknowledge with first-order logic and meanwhile handle their uncertainty.\nHowever, the inference of MLNs is usually very difficult due to the complicated\ngraph structures. Different from MLNs, knowledge graph embedding methods (e.g.\nTransE, DistMult) learn effective entity and relation embeddings for reasoning,\nwhich are much more effective and efficient. However, they are unable to\nleverage domain knowledge. In this paper, we propose the probabilistic Logic\nNeural Network (pLogicNet), which combines the advantages of both methods. A\npLogicNet defines the joint distribution of all possible triplets by using a\nMarkov logic network with first-order logic, which can be efficiently optimized\nwith the variational EM algorithm. In the E-step, a knowledge graph embedding\nmodel is used for inferring the missing triplets, while in the M-step, the\nweights of logic rules are updated based on both the observed and predicted\ntriplets. Experiments on multiple knowledge graphs prove the effectiveness of\npLogicNet over many competitive baselines.\n", "versions": [{"version": "v1", "created": "Thu, 20 Jun 2019 08:22:26 GMT"}, {"version": "v2", "created": "Tue, 29 Oct 2019 17:07:14 GMT"}], "update_date": "2019-10-30", "authors_parsed": [["Qu", "Meng", ""], ["Tang", "Jian", ""]]}, {"id": "1906.08549", "submitter": "Yutaka Nagashima", "authors": "Yutaka Nagashima", "title": "Designing Game of Theorems", "comments": "Presented at the third Conference on Artificial Intelligence and\n  Theorem Proving (AITP 2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  \"Theorem proving is similar to the game of Go. So, we can probably improve\nour provers using deep learning, like DeepMind built the super-human computer\nGo program, AlphaGo.\" Such optimism has been observed among participants of\nAITP2017. But is theorem proving really similar to Go? In this paper, we first\nidentify the similarities and differences between them and then propose a\nsystem in which various provers keep competing against each other and changing\nthemselves until they prove conjectures provided by users.\n", "versions": [{"version": "v1", "created": "Thu, 20 Jun 2019 10:50:15 GMT"}], "update_date": "2019-06-21", "authors_parsed": [["Nagashima", "Yutaka", ""]]}, {"id": "1906.08562", "submitter": "Elad Yom-Tov", "authors": "Gilie Gefen, Omer Ben-Porat, Moshe Tennenholtz, Elad Yom-Tov", "title": "Privacy, Altruism, and Experience: Estimating the Perceived Value of\n  Internet Data for Medical Uses", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.AI cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  People increasingly turn to the Internet when they have a medical condition.\nThe data they create during this process is a valuable source for medical\nresearch and for future health services. However, utilizing these data could\ncome at a cost to user privacy. Thus, it is important to balance the perceived\nvalue that users assign to these data with the value of the services derived\nfrom them. Here we describe experiments where methods from Mechanism Design\nwere used to elicit a truthful valuation from users for their Internet data and\nfor services to screen people for medical conditions. In these experiments, 880\npeople from around the world were asked to participate in an auction to provide\ntheir data for uses differing in their contribution to the participant, to\nsociety, and in the disease they addressed. Some users were offered monetary\ncompensation for their participation, while others were asked to pay to\nparticipate. Our findings show that 99\\% of people were willing to contribute\ntheir data in exchange for monetary compensation and an analysis of their data,\nwhile 53\\% were willing to pay to have their data analyzed. The average\nperceived value users assigned to their data was estimated at US\\$49. Their\nvalue to screen them for a specific cancer was US\\$22 while the value of this\nservice offered to the general public was US\\$22. Participants requested higher\ncompensation when notified that their data would be used to analyze a more\nsevere condition. They were willing to pay more to have their data analyzed\nwhen the condition was more severe, when they had higher education or if they\nhad recently experienced a serious medical condition.\n", "versions": [{"version": "v1", "created": "Thu, 20 Jun 2019 11:20:40 GMT"}, {"version": "v2", "created": "Sun, 3 Nov 2019 20:09:48 GMT"}, {"version": "v3", "created": "Sun, 22 Mar 2020 07:18:46 GMT"}], "update_date": "2020-03-24", "authors_parsed": [["Gefen", "Gilie", ""], ["Ben-Porat", "Omer", ""], ["Tennenholtz", "Moshe", ""], ["Yom-Tov", "Elad", ""]]}, {"id": "1906.08619", "submitter": "David Ruhe", "authors": "David Ruhe, Giovanni Cin\\`a, Michele Tonutti, Daan de Bruin, Paul\n  Elbers", "title": "Bayesian Modelling in Practice: Using Uncertainty to Improve\n  Trustworthiness in Medical Applications", "comments": "Presented at AISG @ ICML2019:\n  https://aiforsocialgood.github.io/icml2019/index.htm", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Intensive Care Unit (ICU) is a hospital department where machine learning\nhas the potential to provide valuable assistance in clinical decision making.\nClassical machine learning models usually only provide point-estimates and no\nuncertainty of predictions. In practice, uncertain predictions should be\npresented to doctors with extra care in order to prevent potentially\ncatastrophic treatment decisions. In this work we show how Bayesian modelling\nand the predictive uncertainty that it provides can be used to mitigate risk of\nmisguided prediction and to detect out-of-domain examples in a medical setting.\nWe derive analytically a bound on the prediction loss with respect to\npredictive uncertainty. The bound shows that uncertainty can mitigate loss.\nFurthermore, we apply a Bayesian Neural Network to the MIMIC-III dataset,\npredicting risk of mortality of ICU patients. Our empirical results show that\nuncertainty can indeed prevent potential errors and reliably identifies\nout-of-domain patients. These results suggest that Bayesian predictive\nuncertainty can greatly improve trustworthiness of machine learning models in\nhigh-risk settings such as the ICU.\n", "versions": [{"version": "v1", "created": "Thu, 20 Jun 2019 13:51:07 GMT"}], "update_date": "2019-06-21", "authors_parsed": [["Ruhe", "David", ""], ["Cin\u00e0", "Giovanni", ""], ["Tonutti", "Michele", ""], ["de Bruin", "Daan", ""], ["Elbers", "Paul", ""]]}, {"id": "1906.08649", "submitter": "Tingwu Wang", "authors": "Tingwu Wang, Jimmy Ba", "title": "Exploring Model-based Planning with Policy Networks", "comments": "8 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Model-based reinforcement learning (MBRL) with model-predictive control or\nonline planning has shown great potential for locomotion control tasks in terms\nof both sample efficiency and asymptotic performance. Despite their initial\nsuccesses, the existing planning methods search from candidate sequences\nrandomly generated in the action space, which is inefficient in complex\nhigh-dimensional environments. In this paper, we propose a novel MBRL\nalgorithm, model-based policy planning (POPLIN), that combines policy networks\nwith online planning. More specifically, we formulate action planning at each\ntime-step as an optimization problem using neural networks. We experiment with\nboth optimization w.r.t. the action sequences initialized from the policy\nnetwork, and also online optimization directly w.r.t. the parameters of the\npolicy network. We show that POPLIN obtains state-of-the-art performance in the\nMuJoCo benchmarking environments, being about 3x more sample efficient than the\nstate-of-the-art algorithms, such as PETS, TD3 and SAC. To explain the\neffectiveness of our algorithm, we show that the optimization surface in\nparameter space is smoother than in action space. Further more, we found the\ndistilled policy network can be effectively applied without the expansive model\npredictive control during test time for some environments such as Cheetah. Code\nis released in https://github.com/WilsonWangTHU/POPLIN.\n", "versions": [{"version": "v1", "created": "Thu, 20 Jun 2019 14:13:12 GMT"}], "update_date": "2019-06-21", "authors_parsed": [["Wang", "Tingwu", ""], ["Ba", "Jimmy", ""]]}, {"id": "1906.08662", "submitter": "Guan Wang", "authors": "Guan Wang, Jianming Hu, Zhiheng Li, Li Li", "title": "Cooperative Lane Changing via Deep Reinforcement Learning", "comments": "7 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.AI cs.LG cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study how to learn an appropriate lane changing strategy\nfor autonomous vehicles by using deep reinforcement learning. We show that the\nreward of the system should consider the overall traffic efficiency instead of\nthe travel efficiency of an individual vehicle. In summary, cooperation leads\nto a more harmonic and efficient traffic system rather than competition\n", "versions": [{"version": "v1", "created": "Thu, 20 Jun 2019 14:31:48 GMT"}], "update_date": "2019-06-21", "authors_parsed": [["Wang", "Guan", ""], ["Hu", "Jianming", ""], ["Li", "Zhiheng", ""], ["Li", "Li", ""]]}, {"id": "1906.08663", "submitter": "Victoria Krakovna", "authors": "Tom Everitt, Ramana Kumar, Victoria Krakovna, Shane Legg", "title": "Modeling AGI Safety Frameworks with Causal Influence Diagrams", "comments": "IJCAI 2019 AI Safety Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Proposals for safe AGI systems are typically made at the level of frameworks,\nspecifying how the components of the proposed system should be trained and\ninteract with each other. In this paper, we model and compare the most\npromising AGI safety frameworks using causal influence diagrams. The diagrams\nshow the optimization objective and causal assumptions of the framework. The\nunified representation permits easy comparison of frameworks and their\nassumptions. We hope that the diagrams will serve as an accessible and visual\nintroduction to the main AGI safety frameworks.\n", "versions": [{"version": "v1", "created": "Thu, 20 Jun 2019 14:35:03 GMT"}], "update_date": "2019-06-21", "authors_parsed": [["Everitt", "Tom", ""], ["Kumar", "Ramana", ""], ["Krakovna", "Victoria", ""], ["Legg", "Shane", ""]]}, {"id": "1906.08724", "submitter": "Fabian Neuhaus", "authors": "Bernd Krieg-Br\\\"uckner and Till Mossakowski and Fabian Neuhaus", "title": "Generic Ontology Design Patterns at Work", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generic Ontology Design Patterns, GODPs, are defined in Generic DOL, an\nextension of DOL, the Distributed Ontology, Model and Specification Language,\nand implemented using Heterogeneous Tool Set.\n  Parameters such as classes, properties, individuals, or whole ontologies may\nbe instantiated with arguments in a host ontology. The potential of Generic DOL\nis illustrated with GODPs for an example from the literature, namely the Role\ndesign pattern. We also discuss how larger GODPs may be composed by\ninstantiating smaller GODPs.\n", "versions": [{"version": "v1", "created": "Thu, 20 Jun 2019 16:12:12 GMT"}], "update_date": "2019-06-21", "authors_parsed": [["Krieg-Br\u00fcckner", "Bernd", ""], ["Mossakowski", "Till", ""], ["Neuhaus", "Fabian", ""]]}, {"id": "1906.08733", "submitter": "Rui Aguiar", "authors": "Rui Aguiar, Kevin Liao", "title": "Autonomous Haiku Generation", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Artificial Intelligence is an excellent tool to improve efficiency and lower\ncost in many quantitative real world applications, but what if the task is not\neasily defined? What if the task is generating creativity? Poetry is a creative\nendeavor that is highly difficult to both grasp and achieve with any level of\ncompetence. As Rita Dove, a famous American poet and author states, \"Poetry is\nlanguage at its most distilled and most powerful.\" Taking Doves quote as an\ninspiration, our task was to generate high quality haikus using artificial\nintelligence and deep learning.\n", "versions": [{"version": "v1", "created": "Thu, 20 Jun 2019 16:25:47 GMT"}], "update_date": "2019-06-21", "authors_parsed": [["Aguiar", "Rui", ""], ["Liao", "Kevin", ""]]}, {"id": "1906.08805", "submitter": "Liang Tong", "authors": "Liang Tong, Aron Laszka, Chao Yan, Ning Zhang and Yevgeniy Vorobeychik", "title": "Finding Needles in a Moving Haystack: Prioritizing Alerts with\n  Adversarial Reinforcement Learning", "comments": "v1.0", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Detection of malicious behavior is a fundamental problem in security. One of\nthe major challenges in using detection systems in practice is in dealing with\nan overwhelming number of alerts that are triggered by normal behavior (the\nso-called false positives), obscuring alerts resulting from actual malicious\nactivity. While numerous methods for reducing the scope of this issue have been\nproposed, ultimately one must still decide how to prioritize which alerts to\ninvestigate, and most existing prioritization methods are heuristic, for\nexample, based on suspiciousness or priority scores. We introduce a novel\napproach for computing a policy for prioritizing alerts using adversarial\nreinforcement learning. Our approach assumes that the attackers know the full\nstate of the detection system and dynamically choose an optimal attack as a\nfunction of this state, as well as of the alert prioritization policy. The\nfirst step of our approach is to capture the interaction between the defender\nand attacker in a game theoretic model. To tackle the computational complexity\nof solving this game to obtain a dynamic stochastic alert prioritization\npolicy, we propose an adversarial reinforcement learning framework. In this\nframework, we use neural reinforcement learning to compute best response\npolicies for both the defender and the adversary to an arbitrary stochastic\npolicy of the other. We then use these in a double-oracle framework to obtain\nan approximate equilibrium of the game, which in turn yields a robust\nstochastic policy for the defender. Extensive experiments using case studies in\nfraud and intrusion detection demonstrate that our approach is effective in\ncreating robust alert prioritization policies.\n", "versions": [{"version": "v1", "created": "Thu, 20 Jun 2019 18:47:06 GMT"}], "update_date": "2019-06-24", "authors_parsed": [["Tong", "Liang", ""], ["Laszka", "Aron", ""], ["Yan", "Chao", ""], ["Zhang", "Ning", ""], ["Vorobeychik", "Yevgeniy", ""]]}, {"id": "1906.08809", "submitter": "Wentai Zhang", "authors": "Haiguang Liao, Wentai Zhang, Xuliang Dong, Barnabas Poczos, Kenji\n  Shimada, Levent Burak Kara", "title": "A Deep Reinforcement Learning Approach for Global Routing", "comments": "Preprint submitted to ASME JMD", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Global routing has been a historically challenging problem in electronic\ncircuit design, where the challenge is to connect a large and arbitrary number\nof circuit components with wires without violating the design rules for the\nprinted circuit boards or integrated circuits. Similar routing problems also\nexist in the design of complex hydraulic systems, pipe systems and logistic\nnetworks. Existing solutions typically consist of greedy algorithms and\nhard-coded heuristics. As such, existing approaches suffer from a lack of model\nflexibility and non-optimum solutions. As an alternative approach, this work\npresents a deep reinforcement learning method for solving the global routing\nproblem in a simulated environment. At the heart of the proposed method is deep\nreinforcement learning that enables an agent to produce an optimal policy for\nrouting based on the variety of problems it is presented with leveraging the\nconjoint optimization mechanism of deep reinforcement learning. Conjoint\noptimization mechanism is explained and demonstrated in details; the best\nnetwork structure and the parameters of the learned model are explored. Based\non the fine-tuned model, routing solutions and rewards are presented and\nanalyzed. The results indicate that the approach can outperform the benchmark\nmethod of a sequential A* method, suggesting a promising potential for deep\nreinforcement learning for global routing and other routing or path planning\nproblems in general. Another major contribution of this work is the development\nof a global routing problem sets generator with the ability to generate\nparameterized global routing problem sets with different size and constraints,\nenabling evaluation of different routing algorithms and the generation of\ntraining datasets for future data-driven routing approaches.\n", "versions": [{"version": "v1", "created": "Thu, 20 Jun 2019 19:07:01 GMT"}], "update_date": "2019-06-24", "authors_parsed": [["Liao", "Haiguang", ""], ["Zhang", "Wentai", ""], ["Dong", "Xuliang", ""], ["Poczos", "Barnabas", ""], ["Shimada", "Kenji", ""], ["Kara", "Levent Burak", ""]]}, {"id": "1906.08857", "submitter": "Sebastian Risi", "authors": "Sebastian Risi, Kenneth O. Stanley", "title": "Deep Neuroevolution of Recurrent and Discrete World Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural architectures inspired by our own human cognitive system, such as the\nrecently introduced world models, have been shown to outperform traditional\ndeep reinforcement learning (RL) methods in a variety of different domains.\nInstead of the relatively simple architectures employed in most RL experiments,\nworld models rely on multiple different neural components that are responsible\nfor visual information processing, memory, and decision-making. However, so far\nthe components of these models have to be trained separately and through a\nvariety of specialized training methods. This paper demonstrates the surprising\nfinding that models with the same precise parts can be instead efficiently\ntrained end-to-end through a genetic algorithm (GA), reaching a comparable\nperformance to the original world model by solving a challenging car racing\ntask. An analysis of the evolved visual and memory system indicates that they\ninclude a similar effective representation to the system trained through\ngradient descent. Additionally, in contrast to gradient descent methods that\nstruggle with discrete variables, GAs also work directly with such\nrepresentations, opening up opportunities for classical planning in latent\nspace. This paper adds additional evidence on the effectiveness of deep\nneuroevolution for tasks that require the intricate orchestration of multiple\ncomponents in complex heterogeneous architectures.\n", "versions": [{"version": "v1", "created": "Sun, 28 Apr 2019 10:00:59 GMT"}], "update_date": "2019-06-24", "authors_parsed": [["Risi", "Sebastian", ""], ["Stanley", "Kenneth O.", ""]]}, {"id": "1906.08865", "submitter": "Nam Le", "authors": "Nam Le", "title": "Evolving Self-supervised Neural Networks: Autonomous Intelligence from\n  Evolved Self-teaching", "comments": "11. arXiv admin note: text overlap with arXiv:1906.08854", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a technique called evolving self-supervised neural\nnetworks - neural networks that can teach themselves, intrinsically motivated,\nwithout external supervision or reward. The proposed method presents some\nsort-of paradigm shift, and differs greatly from both traditional\ngradient-based learning and evolutionary algorithms in that it combines the\nmetaphor of evolution and learning, more specifically self-learning, together,\nrather than treating these phenomena alternatively. I simulate a multi-agent\nsystem in which neural networks are used to control autonomous foraging agents\nwith little domain knowledge. Experimental results show that only evolved\nself-supervised agents can demonstrate some sort of intelligent behaviour, but\nnot evolution or self-learning alone. Indications for future work on evolving\nintelligence are also presented.\n", "versions": [{"version": "v1", "created": "Mon, 27 May 2019 20:18:41 GMT"}], "update_date": "2019-06-24", "authors_parsed": [["Le", "Nam", ""]]}, {"id": "1906.08874", "submitter": "Sotiris Moschoyiannis Dr", "authors": "Matthew R Karlsen and Sotiris K. Moschoyiannis", "title": "Customer Segmentation of Wireless Trajectory Data", "comments": "Technical Report, University of Surrey, UK, 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Wireless trajectory data consists of a number of (time, point) entries where\neach point is associated with a particular wireless device (WAP or BLE beacon)\ntied to a location identifier, such as a place name. A trajectory relates to a\nparticular mobile device. Such data can be clustered `semantically' to identify\nsimilar trajectories, where similarity relates to non-geographic\ncharacteristics such as the type of location visited. Here we present a new\napproach to semantic trajectory clustering for such data. The approach is\napplicable to interpreting data that does not contain geographical coordinates,\nand thus contributes to the current literature on semantic trajectory\nclustering. The literature does not appear to provide such an approach, instead\nfocusing on trajectory data where latitude and longitude data is available.\n  We apply the techniques developed above in the context of the Onward Journey\nPlanner Application, with the motivation of providing on-line recommendations\nfor onward journey options in a context-specific manner. The trajectories\nanalysed indicate commute patterns on the London Underground. Points are only\nrecorded for communication with WAP and BLE beacons within the rail network.\nThis context presents additional challenge since the trajectories are\n`truncated', with no true origin and destination details.\n  In the above context we find that there are a range of travel patterns in the\ndata, without the existence of distinct clusters. Suggestions are made\nconcerning how to approach the problem of provision of on-line recommendations\nwith such a data set. Thoughts concerning the related problem of prediction of\njourney route and destination are also provided.\n", "versions": [{"version": "v1", "created": "Thu, 20 Jun 2019 21:32:33 GMT"}], "update_date": "2019-06-24", "authors_parsed": [["Karlsen", "Matthew R", ""], ["Moschoyiannis", "Sotiris K.", ""]]}, {"id": "1906.08880", "submitter": "Roberto Mart\\'in-Mart\\'in", "authors": "Roberto Mart\\'in-Mart\\'in, Michelle A. Lee, Rachel Gardner, Silvio\n  Savarese, Jeannette Bohg, Animesh Garg", "title": "Variable Impedance Control in End-Effector Space: An Action Space for\n  Reinforcement Learning in Contact-Rich Tasks", "comments": "IROS19", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement Learning (RL) of contact-rich manipulation tasks has yielded\nimpressive results in recent years. While many studies in RL focus on varying\nthe observation space or reward model, few efforts focused on the choice of\naction space (e.g. joint or end-effector space, position, velocity, etc.).\nHowever, studies in robot motion control indicate that choosing an action space\nthat conforms to the characteristics of the task can simplify exploration and\nimprove robustness to disturbances. This paper studies the effect of different\naction spaces in deep RL and advocates for Variable Impedance Control in\nEnd-effector Space (VICES) as an advantageous action space for constrained and\ncontact-rich tasks. We evaluate multiple action spaces on three prototypical\nmanipulation tasks: Path Following (task with no contact), Door Opening (task\nwith kinematic constraints), and Surface Wiping (task with continuous contact).\nWe show that VICES improves sample efficiency, maintains low energy\nconsumption, and ensures safety across all three experimental setups. Further,\nRL policies learned with VICES can transfer across different robot models in\nsimulation, and from simulation to real for the same robot. Further information\nis available at https://stanfordvl.github.io/vices.\n", "versions": [{"version": "v1", "created": "Thu, 20 Jun 2019 22:21:30 GMT"}, {"version": "v2", "created": "Fri, 2 Aug 2019 20:42:48 GMT"}], "update_date": "2019-08-06", "authors_parsed": [["Mart\u00edn-Mart\u00edn", "Roberto", ""], ["Lee", "Michelle A.", ""], ["Gardner", "Rachel", ""], ["Savarese", "Silvio", ""], ["Bohg", "Jeannette", ""], ["Garg", "Animesh", ""]]}, {"id": "1906.08928", "submitter": "Malayandi Palaniappan", "authors": "Malayandi Palan, Nicholas C. Landolfi, Gleb Shevchuk, Dorsa Sadigh", "title": "Learning Reward Functions by Integrating Human Demonstrations and\n  Preferences", "comments": "Presented at RSS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Our goal is to accurately and efficiently learn reward functions for\nautonomous robots. Current approaches to this problem include inverse\nreinforcement learning (IRL), which uses expert demonstrations, and\npreference-based learning, which iteratively queries the user for her\npreferences between trajectories. In robotics however, IRL often struggles\nbecause it is difficult to get high-quality demonstrations; conversely,\npreference-based learning is very inefficient since it attempts to learn a\ncontinuous, high-dimensional function from binary feedback. We propose a new\nframework for reward learning, DemPref, that uses both demonstrations and\npreference queries to learn a reward function. Specifically, we (1) use the\ndemonstrations to learn a coarse prior over the space of reward functions, to\nreduce the effective size of the space from which queries are generated; and\n(2) use the demonstrations to ground the (active) query generation process, to\nimprove the quality of the generated queries. Our method alleviates the\nefficiency issues faced by standard preference-based learning methods and does\nnot exclusively depend on (possibly low-quality) demonstrations. In numerical\nexperiments, we find that DemPref is significantly more efficient than a\nstandard active preference-based learning method. In a user study, we compare\nour method to a standard IRL method; we find that users rated the robot trained\nwith DemPref as being more successful at learning their desired behavior, and\npreferred to use the DemPref system (over IRL) to train the robot.\n", "versions": [{"version": "v1", "created": "Fri, 21 Jun 2019 03:00:36 GMT"}], "update_date": "2019-06-24", "authors_parsed": [["Palan", "Malayandi", ""], ["Landolfi", "Nicholas C.", ""], ["Shevchuk", "Gleb", ""], ["Sadigh", "Dorsa", ""]]}, {"id": "1906.08939", "submitter": "Muhao Chen", "authors": "Weijia Shi, Muhao Chen, Yingtao Tian, Kai-Wei Chang", "title": "Learning Bilingual Word Embeddings Using Lexical Definitions", "comments": "ACL 2019 RepL4NLP", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bilingual word embeddings, which representlexicons of different languages in\na shared em-bedding space, are essential for supporting se-mantic and knowledge\ntransfers in a variety ofcross-lingual NLP tasks. Existing approachesto\ntraining bilingual word embeddings requireoften require pre-defined seed\nlexicons that areexpensive to obtain, or parallel sentences thatcomprise coarse\nand noisy alignment. In con-trast, we propose BilLex that leverages pub-licly\navailable lexical definitions for bilingualword embedding learning. Without the\nneedof predefined seed lexicons, BilLex comprisesa novel word pairing strategy\nto automati-cally identify and propagate the precise fine-grained word\nalignment from lexical defini-tions. We evaluate BilLex in word-level\nandsentence-level translation tasks, which seek tofind the cross-lingual\ncounterparts of wordsand sentences respectively.BilLex signifi-cantly\noutperforms previous embedding meth-ods on both tasks.\n", "versions": [{"version": "v1", "created": "Fri, 21 Jun 2019 04:14:07 GMT"}], "update_date": "2020-01-07", "authors_parsed": [["Shi", "Weijia", ""], ["Chen", "Muhao", ""], ["Tian", "Yingtao", ""], ["Chang", "Kai-Wei", ""]]}, {"id": "1906.09094", "submitter": "Shushman Choudhury", "authors": "Shushman Choudhury and Mykel J. Kochenderfer", "title": "Hybrid Planning for Dynamic Multimodal Stochastic Shortest Paths", "comments": "20 pages, 5 figures, 5 tables; Under Review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sequential decision problems in applications such as manipulation in\nwarehouses, multi-step meal preparation, and routing in autonomous vehicle\nnetworks often involve reasoning about uncertainty, planning over discrete\nmodes as well as continuous states, and reacting to dynamic updates. To\nformalize such problems generally, we introduce a class of Markov Decision\nProcesses (MDPs) called Dynamic Multimodal Stochastic Shortest Paths (DMSSPs).\nMuch of the work in these domains solves deterministic variants, which can\nyield poor results when the uncertainty has downstream effects. We develop a\nHybrid Stochastic Planning (HSP) algorithm, which uses domain-agnostic\nabstractions to efficiently unify heuristic search for planning over discrete\nmodes, approximate dynamic programming for stochastic planning over continuous\nstates, and hierarchical interleaved planning and execution. In the domain of\nautonomous multimodal routing, HSP obtains significantly higher quality\nsolutions than a state-of-the-art Upper Confidence Trees algorithm and a\ntwo-level Receding Horizon Control algorithm.\n", "versions": [{"version": "v1", "created": "Fri, 21 Jun 2019 12:41:19 GMT"}], "update_date": "2019-06-24", "authors_parsed": [["Choudhury", "Shushman", ""], ["Kochenderfer", "Mykel J.", ""]]}, {"id": "1906.09114", "submitter": "Aristide Charles Yedia Tossou", "authors": "Aristide Tossou, Christos Dimitrakakis, Debabrota Basu", "title": "Near-optimal Bayesian Solution For Unknown Discrete Markov Decision\n  Process", "comments": "Improved the text and added detailed proofs of claims Change title to\n  better express the solution proposed", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.GT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We tackle the problem of acting in an unknown finite and discrete Markov\nDecision Process (MDP) for which the expected shortest path from any state to\nany other state is bounded by a finite number $D$. An MDP consists of $S$\nstates and $A$ possible actions per state. Upon choosing an action $a_t$ at\nstate $s_t$, one receives a real value reward $r_t$, then one transits to a\nnext state $s_{t+1}$. The reward $r_t$ is generated from a fixed reward\ndistribution depending only on $(s_t, a_t)$ and similarly, the next state\n$s_{t+1}$ is generated from a fixed transition distribution depending only on\n$(s_t, a_t)$. The objective is to maximize the accumulated rewards after $T$\ninteractions. In this paper, we consider the case where the reward\ndistributions, the transitions, $T$ and $D$ are all unknown. We derive the\nfirst polynomial time Bayesian algorithm, BUCRL{} that achieves up to logarithm\nfactors, a regret (i.e the difference between the accumulated rewards of the\noptimal policy and our algorithm) of the optimal order\n$\\tilde{\\mathcal{O}}(\\sqrt{DSAT})$. Importantly, our result holds with high\nprobability for the worst-case (frequentist) regret and not the weaker notion\nof Bayesian regret. We perform experiments in a variety of environments that\ndemonstrate the superiority of our algorithm over previous techniques.\n  Our work also illustrates several results that will be of independent\ninterest. In particular, we derive a sharper upper bound for the KL-divergence\nof Bernoulli random variables. We also derive sharper upper and lower bounds\nfor Beta and Binomial quantiles. All the bound are very simple and only use\nelementary functions.\n", "versions": [{"version": "v1", "created": "Thu, 20 Jun 2019 06:32:36 GMT"}, {"version": "v2", "created": "Tue, 9 Jul 2019 21:47:50 GMT"}], "update_date": "2019-07-11", "authors_parsed": [["Tossou", "Aristide", ""], ["Dimitrakakis", "Christos", ""], ["Basu", "Debabrota", ""]]}, {"id": "1906.09136", "submitter": "Sayan Sarkar", "authors": "Arushi Majha, Sayan Sarkar and Davide Zagami", "title": "Categorizing Wireheading in Partially Embedded Agents", "comments": "Accepted at the AI Safety Workshop in IJCAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  $\\textit{Embedded agents}$ are not explicitly separated from their\nenvironment, lacking clear I/O channels. Such agents can reason about and\nmodify their internal parts, which they are incentivized to shortcut or\n$\\textit{wirehead}$ in order to achieve the maximal reward. In this paper, we\nprovide a taxonomy of ways by which wireheading can occur, followed by a\ndefinition of wirehead-vulnerable agents. Starting from the fully dualistic\nuniversal agent AIXI, we introduce a spectrum of partially embedded agents and\nidentify wireheading opportunities that such agents can exploit, experimentally\ndemonstrating the results with the GRL simulation platform AIXIjs. We\ncontextualize wireheading in the broader class of all misalignment problems -\nwhere the goals of the agent conflict with the goals of the human designer -\nand conjecture that the only other possible type of misalignment is\nspecification gaming. Motivated by this taxonomy, we define wirehead-vulnerable\nagents as embedded agents that choose to behave differently from fully\ndualistic agents lacking access to their internal parts.\n", "versions": [{"version": "v1", "created": "Fri, 21 Jun 2019 13:38:35 GMT"}], "update_date": "2019-06-24", "authors_parsed": [["Majha", "Arushi", ""], ["Sarkar", "Sayan", ""], ["Zagami", "Davide", ""]]}, {"id": "1906.09198", "submitter": "Paolo Papotti", "authors": "Naser Ahmadi, Joohyung Lee, Paolo Papotti, Mohammed Saeed", "title": "Explainable Fact Checking with Probabilistic Answer Set Programming", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One challenge in fact checking is the ability to improve the transparency of\nthe decision. We present a fact checking method that uses reference information\nin knowledge graphs (KGs) to assess claims and explain its decisions. KGs\ncontain a formal representation of knowledge with semantic descriptions of\nentities and their relationships. We exploit such rich semantics to produce\ninterpretable explanations for the fact checking output. As information in a KG\nis inevitably incomplete, we rely on logical rule discovery and on Web text\nmining to gather the evidence to assess a given claim. Uncertain rules and\nfacts are turned into logical programs and the checking task is modeled as an\ninference problem in a probabilistic extension of answer set programs.\nExperiments show that the probabilistic inference enables the efficient\nlabeling of claims with interpretable explanations, and the quality of the\nresults is higher than state of the art baselines.\n", "versions": [{"version": "v1", "created": "Fri, 21 Jun 2019 15:35:03 GMT"}], "update_date": "2019-06-24", "authors_parsed": [["Ahmadi", "Naser", ""], ["Lee", "Joohyung", ""], ["Papotti", "Paolo", ""], ["Saeed", "Mohammed", ""]]}, {"id": "1906.09205", "submitter": "Fengda Zhu", "authors": "Fengda Zhu, Xiaojun Chang, Runhao Zeng, Mingkui Tan", "title": "Continual Reinforcement Learning with Diversity Exploration and\n  Adversarial Self-Correction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep reinforcement learning has made significant progress in the field of\ncontinuous control, such as physical control and autonomous driving. However,\nit is challenging for a reinforcement model to learn a policy for each task\nsequentially due to catastrophic forgetting. Specifically, the model would\nforget knowledge it learned in the past when trained on a new task. We consider\nthis challenge from two perspectives: i) acquiring task-specific skills is\ndifficult since task information and rewards are not highly related; ii)\nlearning knowledge from previous experience is difficult in continuous control\ndomains. In this paper, we introduce an end-to-end framework namely Continual\nDiversity Adversarial Network (CDAN). We first develop an unsupervised\ndiversity exploration method to learn task-specific skills using an\nunsupervised objective. Then, we propose an adversarial self-correction\nmechanism to learn knowledge by exploiting past experience. The two learning\nprocedures are presumably reciprocal. To evaluate the proposed method, we\npropose a new continuous reinforcement learning environment named Continual Ant\nMaze (CAM) and a new metric termed Normalized Shorten Distance (NSD). The\nexperimental results confirm the effectiveness of diversity exploration and\nself-correction. It is worthwhile noting that our final result outperforms\nbaseline by 18.35% in terms of NSD, and 0.61 according to the average reward.\n", "versions": [{"version": "v1", "created": "Fri, 21 Jun 2019 15:44:41 GMT"}], "update_date": "2019-06-24", "authors_parsed": [["Zhu", "Fengda", ""], ["Chang", "Xiaojun", ""], ["Zeng", "Runhao", ""], ["Tan", "Mingkui", ""]]}, {"id": "1906.09208", "submitter": "Manish Raghavan", "authors": "Manish Raghavan, Solon Barocas, Jon Kleinberg, Karen Levy", "title": "Mitigating Bias in Algorithmic Hiring: Evaluating Claims and Practices", "comments": null, "journal-ref": null, "doi": "10.1145/3351095.3372828", "report-no": null, "categories": "cs.CY cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There has been rapidly growing interest in the use of algorithms in hiring,\nespecially as a means to address or mitigate bias. Yet, to date, little is\nknown about how these methods are used in practice. How are algorithmic\nassessments built, validated, and examined for bias? In this work, we document\nand analyze the claims and practices of companies offering algorithms for\nemployment assessment. In particular, we identify vendors of algorithmic\npre-employment assessments (i.e., algorithms to screen candidates), document\nwhat they have disclosed about their development and validation procedures, and\nevaluate their practices, focusing particularly on efforts to detect and\nmitigate bias. Our analysis considers both technical and legal perspectives.\nTechnically, we consider the various choices vendors make regarding data\ncollection and prediction targets, and explore the risks and trade-offs that\nthese choices pose. We also discuss how algorithmic de-biasing techniques\ninterface with, and create challenges for, antidiscrimination law.\n", "versions": [{"version": "v1", "created": "Fri, 21 Jun 2019 15:49:45 GMT"}, {"version": "v2", "created": "Fri, 13 Sep 2019 22:41:01 GMT"}, {"version": "v3", "created": "Fri, 6 Dec 2019 19:27:21 GMT"}], "update_date": "2019-12-10", "authors_parsed": [["Raghavan", "Manish", ""], ["Barocas", "Solon", ""], ["Kleinberg", "Jon", ""], ["Levy", "Karen", ""]]}, {"id": "1906.09223", "submitter": "Janith C. Petangoda", "authors": "Janith C. Petangoda, Sergio Pascual-Diaz, Vincent Adam, Peter Vrancx,\n  Jordi Grau-Moya", "title": "Disentangled Skill Embeddings for Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel framework for multi-task reinforcement learning (MTRL).\nUsing a variational inference formulation, we learn policies that generalize\nacross both changing dynamics and goals. The resulting policies are\nparametrized by shared parameters that allow for transfer between different\ndynamics and goal conditions, and by task-specific latent-space embeddings that\nallow for specialization to particular tasks. We show how the latent-spaces\nenable generalization to unseen dynamics and goals conditions. Additionally,\npolicies equipped with such embeddings serve as a space of skills (or options)\nfor hierarchical reinforcement learning. Since we can change task dynamics and\ngoals independently, we name our framework Disentangled Skill Embeddings (DSE).\n", "versions": [{"version": "v1", "created": "Fri, 21 Jun 2019 16:12:15 GMT"}], "update_date": "2019-06-24", "authors_parsed": [["Petangoda", "Janith C.", ""], ["Pascual-Diaz", "Sergio", ""], ["Adam", "Vincent", ""], ["Vrancx", "Peter", ""], ["Grau-Moya", "Jordi", ""]]}, {"id": "1906.09237", "submitter": "Danilo Jimenez Rezende", "authors": "Karol Gregor and Danilo Jimenez Rezende and Frederic Besse and Yan Wu\n  and Hamza Merzic and Aaron van den Oord", "title": "Shaping Belief States with Generative Environment Models for RL", "comments": "pre-print", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When agents interact with a complex environment, they must form and maintain\nbeliefs about the relevant aspects of that environment. We propose a way to\nefficiently train expressive generative models in complex environments. We show\nthat a predictive algorithm with an expressive generative model can form stable\nbelief-states in visually rich and dynamic 3D environments. More precisely, we\nshow that the learned representation captures the layout of the environment as\nwell as the position and orientation of the agent. Our experiments show that\nthe model substantially improves data-efficiency on a number of reinforcement\nlearning (RL) tasks compared with strong model-free baseline agents. We find\nthat predicting multiple steps into the future (overshooting), in combination\nwith an expressive generative model, is critical for stable representations to\nemerge. In practice, using expressive generative models in RL is\ncomputationally expensive and we propose a scheme to reduce this computational\nburden, allowing us to build agents that are competitive with model-free\nbaselines.\n", "versions": [{"version": "v1", "created": "Fri, 21 Jun 2019 16:54:42 GMT"}, {"version": "v2", "created": "Mon, 24 Jun 2019 15:36:55 GMT"}], "update_date": "2019-06-25", "authors_parsed": [["Gregor", "Karol", ""], ["Rezende", "Danilo Jimenez", ""], ["Besse", "Frederic", ""], ["Wu", "Yan", ""], ["Merzic", "Hamza", ""], ["Oord", "Aaron van den", ""]]}, {"id": "1906.09264", "submitter": "Baihan Lin", "authors": "Baihan Lin, Marieke Mur, Tim Kietzmann, Nikolaus Kriegeskorte", "title": "Visualizing Representational Dynamics with Multidimensional Scaling\n  Alignment", "comments": "CCN 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.AI cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Representational similarity analysis (RSA) has been shown to be an effective\nframework to characterize brain-activity profiles and deep neural network\nactivations as representational geometry by computing the pairwise distances of\nthe response patterns as a representational dissimilarity matrix (RDM).\nHowever, how to properly analyze and visualize the representational geometry as\ndynamics over the time course from stimulus onset to offset is not well\nunderstood. In this work, we formulated the pipeline to understand\nrepresentational dynamics with RDM movies and Procrustes-aligned\nMultidimensional Scaling (pMDS), and applied it to neural recording of monkey\nIT cortex. Our results suggest that the the multidimensional scaling alignment\ncan genuinely capture the dynamics of the category-specific representation\nspaces with multiple visualization possibilities, and that object\ncategorization may be hierarchical, multi-staged, and oscillatory (or\nrecurrent).\n", "versions": [{"version": "v1", "created": "Fri, 21 Jun 2019 03:46:18 GMT"}, {"version": "v2", "created": "Sun, 28 Jul 2019 12:07:06 GMT"}], "update_date": "2019-07-30", "authors_parsed": [["Lin", "Baihan", ""], ["Mur", "Marieke", ""], ["Kietzmann", "Tim", ""], ["Kriegeskorte", "Nikolaus", ""]]}, {"id": "1906.09293", "submitter": "Shubham Rathi", "authors": "Shubham Rathi", "title": "Generating Counterfactual and Contrastive Explanations using SHAP", "comments": "This work was presented at 2nd Workshop on Humanizing AI (HAI) at\n  IJCAI'19 in Macao, China", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the advent of GDPR, the domain of explainable AI and model\ninterpretability has gained added impetus. Methods to extract and communicate\nvisibility into decision-making models have become legal requirement. Two\nspecific types of explanations, contrastive and counterfactual have been\nidentified as suitable for human understanding. In this paper, we propose a\nmodel agnostic method and its systemic implementation to generate these\nexplanations using shapely additive explanations (SHAP). We discuss a\ngenerative pipeline to create contrastive explanations and use it to further to\ngenerate counterfactual datapoints. This pipeline is tested and discussed on\nthe IRIS, Wine Quality & Mobile Features dataset. Analysis of the results\nobtained follows.\n", "versions": [{"version": "v1", "created": "Fri, 21 Jun 2019 19:13:31 GMT"}], "update_date": "2019-06-25", "authors_parsed": [["Rathi", "Shubham", ""]]}, {"id": "1906.09308", "submitter": "Asma Ghandeharioun", "authors": "Asma Ghandeharioun, Judy Hanwen Shen, Natasha Jaques, Craig Ferguson,\n  Noah Jones, Agata Lapedriza, Rosalind Picard", "title": "Approximating Interactive Human Evaluation with Self-Play for\n  Open-Domain Dialog Systems", "comments": "33rd Conference on Neural Information Processing Systems (NeurIPS\n  2019), Vancouver, Canada", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Building an open-domain conversational agent is a challenging problem.\nCurrent evaluation methods, mostly post-hoc judgments of static conversation,\ndo not capture conversation quality in a realistic interactive context. In this\npaper, we investigate interactive human evaluation and provide evidence for its\nnecessity; we then introduce a novel, model-agnostic, and dataset-agnostic\nmethod to approximate it. In particular, we propose a self-play scenario where\nthe dialog system talks to itself and we calculate a combination of proxies\nsuch as sentiment and semantic coherence on the conversation trajectory. We\nshow that this metric is capable of capturing the human-rated quality of a\ndialog model better than any automated metric known to-date, achieving a\nsignificant Pearson correlation (r>.7, p<.05). To investigate the strengths of\nthis novel metric and interactive evaluation in comparison to state-of-the-art\nmetrics and human evaluation of static conversations, we perform extended\nexperiments with a set of models, including several that make novel\nimprovements to recent hierarchical dialog generation architectures through\nsentiment and semantic knowledge distillation on the utterance level. Finally,\nwe open-source the interactive evaluation platform we built and the dataset we\ncollected to allow researchers to efficiently deploy and evaluate dialog\nmodels.\n", "versions": [{"version": "v1", "created": "Fri, 21 Jun 2019 20:08:18 GMT"}, {"version": "v2", "created": "Mon, 4 Nov 2019 01:47:34 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Ghandeharioun", "Asma", ""], ["Shen", "Judy Hanwen", ""], ["Jaques", "Natasha", ""], ["Ferguson", "Craig", ""], ["Jones", "Noah", ""], ["Lapedriza", "Agata", ""], ["Picard", "Rosalind", ""]]}, {"id": "1906.09310", "submitter": "Layla El Asri", "authors": "Layla El Asri and Adam Trischler", "title": "A Study of State Aliasing in Structured Prediction with RNNs", "comments": "Deep Reinforcement Learning Meets Structured Prediction workshop at\n  ICLR 2019 and Representation Learning for NLP workshop at ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  End-to-end reinforcement learning agents learn a state representation and a\npolicy at the same time. Recurrent neural networks (RNNs) have been trained\nsuccessfully as reinforcement learning agents in settings like dialogue that\nrequire structured prediction. In this paper, we investigate the\nrepresentations learned by RNN-based agents when trained with both policy\ngradient and value-based methods. We show through extensive experiments and\nanalysis that, when trained with policy gradient, recurrent neural networks\noften fail to learn a state representation that leads to an optimal policy in\nsettings where the same action should be taken at different states. To explain\nthis failure, we highlight the problem of state aliasing, which entails\nconflating two or more distinct states in the representation space. We\ndemonstrate that state aliasing occurs when several states share the same\noptimal action and the agent is trained via policy gradient. We characterize\nthis phenomenon through experiments on a simple maze setting and a more complex\ntext-based game, and make recommendations for training RNNs with reinforcement\nlearning.\n", "versions": [{"version": "v1", "created": "Fri, 21 Jun 2019 20:16:52 GMT"}], "update_date": "2019-06-25", "authors_parsed": [["Asri", "Layla El", ""], ["Trischler", "Adam", ""]]}, {"id": "1906.09317", "submitter": "Yufang Hou", "authors": "Yufang Hou, Charles Jochim, Martin Gleize, Francesca Bonin and Debasis\n  Ganguly", "title": "Identification of Tasks, Datasets, Evaluation Metrics, and Numeric\n  Scores for Scientific Leaderboards Construction", "comments": "ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While the fast-paced inception of novel tasks and new datasets helps foster\nactive research in a community towards interesting directions, keeping track of\nthe abundance of research activity in different areas on different datasets is\nlikely to become increasingly difficult. The community could greatly benefit\nfrom an automatic system able to summarize scientific results, e.g., in the\nform of a leaderboard. In this paper we build two datasets and develop a\nframework (TDMS-IE) aimed at automatically extracting task, dataset, metric and\nscore from NLP papers, towards the automatic construction of leaderboards.\nExperiments show that our model outperforms several baselines by a large\nmargin. Our model is a first step towards automatic leaderboard construction,\ne.g., in the NLP domain.\n", "versions": [{"version": "v1", "created": "Fri, 21 Jun 2019 20:55:57 GMT"}], "update_date": "2019-06-25", "authors_parsed": [["Hou", "Yufang", ""], ["Jochim", "Charles", ""], ["Gleize", "Martin", ""], ["Bonin", "Francesca", ""], ["Ganguly", "Debasis", ""]]}, {"id": "1906.09322", "submitter": "Jie Wang", "authors": "Xu Lu, Jie Wang, Bojin Zhuang, Shaojun Wang and Jing Xiao", "title": "A Syllable-Structured, Contextually-Based Conditionally Generation of\n  Chinese Lyrics", "comments": "accepted by The 16th Pacific Rim International Conference on AI", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a novel, syllable-structured Chinese lyrics generation\nmodel given a piece of original melody. Most previously reported lyrics\ngeneration models fail to include the relationship between lyrics and melody.\nIn this work, we propose to interpret lyrics-melody alignments as syllable\nstructural information and use a multi-channel sequence-to-sequence model with\nconsidering both phrasal structures and semantics. Two different RNN encoders\nare applied, one of which is for encoding syllable structures while the other\nfor semantic encoding with contextual sentences or input keywords. Moreover, a\nlarge Chinese lyrics corpus for model training is leveraged. With automatic and\nhuman evaluations, results demonstrate the effectiveness of our proposed lyrics\ngeneration model. To the best of our knowledge, there is few previous reports\non lyrics generation considering both music and linguistic perspectives.\n", "versions": [{"version": "v1", "created": "Sat, 15 Jun 2019 09:09:12 GMT"}], "update_date": "2019-06-25", "authors_parsed": [["Lu", "Xu", ""], ["Wang", "Jie", ""], ["Zhuang", "Bojin", ""], ["Wang", "Shaojun", ""], ["Xiao", "Jing", ""]]}, {"id": "1906.09323", "submitter": "Sobhan Miryoosefi", "authors": "Sobhan Miryoosefi, Kiant\\'e Brantley, Hal Daum\\'e III, Miroslav Dudik,\n  Robert Schapire", "title": "Reinforcement Learning with Convex Constraints", "comments": null, "journal-ref": "Advances in Neural Information Processing Systems 32 (2019),\n  14093-14102", "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.GT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In standard reinforcement learning (RL), a learning agent seeks to optimize\nthe overall reward. However, many key aspects of a desired behavior are more\nnaturally expressed as constraints. For instance, the designer may want to\nlimit the use of unsafe actions, increase the diversity of trajectories to\nenable exploration, or approximate expert trajectories when rewards are sparse.\nIn this paper, we propose an algorithmic scheme that can handle a wide class of\nconstraints in RL tasks: specifically, any constraints that require expected\nvalues of some vector measurements (such as the use of an action) to lie in a\nconvex set. This captures previously studied constraints (such as safety and\nproximity to an expert), but also enables new classes of constraints (such as\ndiversity). Our approach comes with rigorous theoretical guarantees and only\nrelies on the ability to approximately solve standard RL tasks. As a result, it\ncan be easily adapted to work with any model-free or model-based RL. In our\nexperiments, we show that it matches previous algorithms that enforce safety\nvia constraints, but can also enforce new properties that these algorithms do\nnot incorporate, such as diversity.\n", "versions": [{"version": "v1", "created": "Fri, 21 Jun 2019 21:04:27 GMT"}, {"version": "v2", "created": "Mon, 11 Nov 2019 20:00:43 GMT"}], "update_date": "2021-01-29", "authors_parsed": [["Miryoosefi", "Sobhan", ""], ["Brantley", "Kiant\u00e9", ""], ["Daum\u00e9", "Hal", "III"], ["Dudik", "Miroslav", ""], ["Schapire", "Robert", ""]]}, {"id": "1906.09324", "submitter": "Jie Wang", "authors": "Ziwen Wang, Jie Wang, Haiqian Gu, Fei Su and Bojin Zhuang", "title": "Automatic Conditional Generation of Personalized Social Media Short\n  Texts", "comments": "published in PRICAI 2018", "journal-ref": "In: Geng X., Kang BH. (eds) PRICAI 2018: Trends in Artificial\n  Intelligence", "doi": "10.1007/978-3-319-97310-4_7", "report-no": null, "categories": "cs.CL cs.AI cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic text generation has received much attention owing to rapid\ndevelopment of deep neural networks. In general, text generation systems based\non statistical language model will not consider anthropomorphic\ncharacteristics, which results in machine-like generated texts. To fill the\ngap, we propose a conditional language generation model with Big Five\nPersonality (BFP) feature vectors as input context, which writes human-like\nshort texts. The short text generator consists of a layer of long short memory\nnetwork (LSTM), where a BFP feature vector is concatenated as one part of input\nfor each cell. To enable supervised training generation model, a text\nclassification model based convolution neural network (CNN) has been used to\nprepare BFP-tagged Chinese micro-blog corpora. Validated by a BFP linguistic\ncomputational model, our generated Chinese short texts exhibit discriminative\npersonality styles, which are also syntactically correct and semantically\nsmooth with appropriate emoticons. With combination of natural language\ngeneration with psychological linguistics, our proposed BFP-dependent text\ngeneration model can be widely used for individualization in machine\ntranslation, image caption, dialogue generation and so on.\n", "versions": [{"version": "v1", "created": "Sat, 15 Jun 2019 09:20:41 GMT"}], "update_date": "2019-06-25", "authors_parsed": [["Wang", "Ziwen", ""], ["Wang", "Jie", ""], ["Gu", "Haiqian", ""], ["Su", "Fei", ""], ["Zhuang", "Bojin", ""]]}, {"id": "1906.09333", "submitter": "Marek Smieja", "authors": "Marek \\'Smieja, Maciej Wo{\\l}czyk, Jacek Tabor and Bernhard C. Geiger", "title": "SeGMA: Semi-Supervised Gaussian Mixture Auto-Encoder", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a semi-supervised generative model, SeGMA, which learns a joint\nprobability distribution of data and their classes and which is implemented in\na typical Wasserstein auto-encoder framework. We choose a mixture of Gaussians\nas a target distribution in latent space, which provides a natural splitting of\ndata into clusters. To connect Gaussian components with correct classes, we use\na small amount of labeled data and a Gaussian classifier induced by the target\ndistribution. SeGMA is optimized efficiently due to the use of Cramer-Wold\ndistance as a maximum mean discrepancy penalty, which yields a closed-form\nexpression for a mixture of spherical Gaussian components and thus obviates the\nneed of sampling. While SeGMA preserves all properties of its semi-supervised\npredecessors and achieves at least as good generative performance on standard\nbenchmark data sets, it presents additional features: (a) interpolation between\nany pair of points in the latent space produces realistically-looking samples;\n(b) combining the interpolation property with disentangled class and style\nvariables, SeGMA is able to perform a continuous style transfer from one class\nto another; (c) it is possible to change the intensity of class characteristics\nin a data point by moving the latent representation of the data point away from\nspecific Gaussian components.\n", "versions": [{"version": "v1", "created": "Fri, 21 Jun 2019 21:23:12 GMT"}, {"version": "v2", "created": "Thu, 27 Aug 2020 08:49:02 GMT"}], "update_date": "2020-08-28", "authors_parsed": [["\u015amieja", "Marek", ""], ["Wo\u0142czyk", "Maciej", ""], ["Tabor", "Jacek", ""], ["Geiger", "Bernhard C.", ""]]}, {"id": "1906.09340", "submitter": "Nikki Lijing Kuang", "authors": "Nikki Lijing Kuang and Clement H. C. Leung", "title": "Leveraging Reinforcement Learning Techniques for Effective Policy\n  Adoption and Validation", "comments": "12 pages; ICCSA 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Rewards and punishments in different forms are pervasive and present in a\nwide variety of decision-making scenarios. By observing the outcome of a\nsufficient number of repeated trials, one would gradually learn the value and\nusefulness of a particular policy or strategy. However, in a given environment,\nthe outcomes resulting from different trials are subject to chance influence\nand variations. In learning about the usefulness of a given policy, significant\ncosts are involved in systematically undertaking the sequential trials;\ntherefore, in most learning episodes, one would wish to keep the cost within\nbounds by adopting learning stopping rules. In this paper, we examine the\ndeployment of different stopping strategies in given learning environments\nwhich vary from highly stringent for mission critical operations to highly\ntolerant for non-mission critical operations, and emphasis is placed on the\nformer with particular application to aviation safety. In policy evaluation,\ntwo sequential phases of learning are identified, and we describe the outcomes\nvariations using a probabilistic model, with closedform expressions obtained\nfor the key measures of performance. Decision rules that map the trial\nobservations to policy choices are also formulated. In addition, simulation\nexperiments are performed, which corroborate the validity of the theoretical\nresults.\n", "versions": [{"version": "v1", "created": "Fri, 21 Jun 2019 21:45:58 GMT"}], "update_date": "2019-06-25", "authors_parsed": [["Kuang", "Nikki Lijing", ""], ["Leung", "Clement H. C.", ""]]}, {"id": "1906.09372", "submitter": "Tongwen Wu", "authors": "Tongwen Wu, Zizhen Zhang, Yanzhi Li, Jiahai Wang", "title": "Collective Mobile Sequential Recommendation: A Recommender System for\n  Multiple Taxicabs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mobile sequential recommendation was originally designed to find a promising\nroute for a single taxicab. Directly applying it for multiple taxicabs may\ncause an excessive overlap of recommended routes. The multi-taxicab\nrecommendation problem is challenging and has been less studied. In this paper,\nwe first formalize a collective mobile sequential recommendation problem based\non a classic mathematical model, which characterizes time-varying influence\namong competing taxicabs. Next, we propose a new evaluation metric for a\ncollection of taxicab routes aimed to minimize the sum of potential travel\ntime. We then develop an efficient algorithm to calculate the metric and design\na greedy recommendation method to approximate the solution. Finally, numerical\nexperiments show the superiority of our methods. In trace-driven simulation,\nthe set of routes recommended by our method significantly outperforms those\nobtained by conventional methods.\n", "versions": [{"version": "v1", "created": "Sat, 22 Jun 2019 02:51:50 GMT"}], "update_date": "2019-06-25", "authors_parsed": [["Wu", "Tongwen", ""], ["Zhang", "Zizhen", ""], ["Li", "Yanzhi", ""], ["Wang", "Jiahai", ""]]}, {"id": "1906.09384", "submitter": "Mayank Agarwal", "authors": "Sohini Upadhyay, Mayank Agarwal, Djallel Bounneffouf, Yasaman Khazaeni", "title": "A Bandit Approach to Posterior Dialog Orchestration Under a Budget", "comments": "2nd Conversational AI Workshop, NeurIPS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Building multi-domain AI agents is a challenging task and an open problem in\nthe area of AI. Within the domain of dialog, the ability to orchestrate\nmultiple independently trained dialog agents, or skills, to create a unified\nsystem is of particular significance. In this work, we study the task of online\nposterior dialog orchestration, where we define posterior orchestration as the\ntask of selecting a subset of skills which most appropriately answer a user\ninput using features extracted from both the user input and the individual\nskills. To account for the various costs associated with extracting skill\nfeatures, we consider online posterior orchestration under a skill execution\nbudget. We formalize this setting as Context Attentive Bandit with Observations\n(CABO), a variant of context attentive bandits, and evaluate it on simulated\nnon-conversational and proprietary conversational datasets.\n", "versions": [{"version": "v1", "created": "Sat, 22 Jun 2019 04:02:26 GMT"}], "update_date": "2019-06-25", "authors_parsed": [["Upadhyay", "Sohini", ""], ["Agarwal", "Mayank", ""], ["Bounneffouf", "Djallel", ""], ["Khazaeni", "Yasaman", ""]]}, {"id": "1906.09443", "submitter": "Amir M. Mir", "authors": "A. Mir, Jalal A. Nasiri", "title": "An enhanced KNN-based twin support vector machine with stable learning\n  rules", "comments": "This paper was written in the summer of 2018. It is a part of Mir's\n  MSc thesis", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Among the extensions of twin support vector machine (TSVM), some scholars\nhave utilized K-nearest neighbor (KNN) graph to enhance TSVM's classification\naccuracy. However, these KNN-based TSVM classifiers have two major issues such\nas high computational cost and overfitting. In order to address these issues,\nthis paper presents an enhanced regularized K-nearest neighbor based twin\nsupport vector machine (RKNN-TSVM). It has three additional advantages: (1)\nWeight is given to each sample by considering the distance from its nearest\nneighbors. This further reduces the effect of noise and outliers on the output\nmodel. (2) An extra stabilizer term was added to each objective function. As a\nresult, the learning rules of the proposed method are stable. (3) To reduce the\ncomputational cost of finding KNNs for all the samples, location difference of\nmultiple distances based k-nearest neighbors algorithm (LDMDBA) was embedded\ninto the learning process of the proposed method. The extensive experimental\nresults on several synthetic and benchmark datasets show the effectiveness of\nour proposed RKNN-TSVM in both classification accuracy and computational time.\nMoreover, the largest speedup in the proposed method reaches to 14 times.\n", "versions": [{"version": "v1", "created": "Sat, 22 Jun 2019 13:03:01 GMT"}], "update_date": "2019-06-25", "authors_parsed": [["Mir", "A.", ""], ["Nasiri", "Jalal A.", ""]]}, {"id": "1906.09444", "submitter": "Chenze Shao", "authors": "Chenze Shao, Yang Feng, Jinchao Zhang, Fandong Meng, Xilin Chen and\n  Jie Zhou", "title": "Retrieving Sequential Information for Non-Autoregressive Neural Machine\n  Translation", "comments": "12 pages, 4 figures, ACL 2019 long paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Non-Autoregressive Transformer (NAT) aims to accelerate the Transformer model\nthrough discarding the autoregressive mechanism and generating target words\nindependently, which fails to exploit the target sequential information.\nOver-translation and under-translation errors often occur for the above reason,\nespecially in the long sentence translation scenario. In this paper, we propose\ntwo approaches to retrieve the target sequential information for NAT to enhance\nits translation ability while preserving the fast-decoding property. Firstly,\nwe propose a sequence-level training method based on a novel reinforcement\nalgorithm for NAT (Reinforce-NAT) to reduce the variance and stabilize the\ntraining procedure. Secondly, we propose an innovative Transformer decoder\nnamed FS-decoder to fuse the target sequential information into the top layer\nof the decoder. Experimental results on three translation tasks show that the\nReinforce-NAT surpasses the baseline NAT system by a significant margin on BLEU\nwithout decelerating the decoding speed and the FS-decoder achieves comparable\ntranslation performance to the autoregressive Transformer with considerable\nspeedup.\n", "versions": [{"version": "v1", "created": "Sat, 22 Jun 2019 13:20:57 GMT"}], "update_date": "2019-06-25", "authors_parsed": [["Shao", "Chenze", ""], ["Feng", "Yang", ""], ["Zhang", "Jinchao", ""], ["Meng", "Fandong", ""], ["Chen", "Xilin", ""], ["Zhou", "Jie", ""]]}, {"id": "1906.09445", "submitter": "Hadrien Van Lierde", "authors": "Hadrien Van Lierde and Tommy W. S. Chow", "title": "Learning with fuzzy hypergraphs: a topical approach to query-oriented\n  text summarization", "comments": "8 figures", "journal-ref": "Information Sciences, 496 (2019), 212-224", "doi": "10.1016/j.ins.2019.05.020", "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing graph-based methods for extractive document summarization represent\nsentences of a corpus as the nodes of a graph or a hypergraph in which edges\ndepict relationships of lexical similarity between sentences. Such approaches\nfail to capture semantic similarities between sentences when they express a\nsimilar information but have few words in common and are thus lexically\ndissimilar. To overcome this issue, we propose to extract semantic similarities\nbased on topical representations of sentences. Inspired by the Hierarchical\nDirichlet Process, we propose a probabilistic topic model in order to infer\ntopic distributions of sentences. As each topic defines a semantic connection\namong a group of sentences with a certain degree of membership for each\nsentence, we propose a fuzzy hypergraph model in which nodes are sentences and\nfuzzy hyperedges are topics. To produce an informative summary, we extract a\nset of sentences from the corpus by simultaneously maximizing their relevance\nto a user-defined query, their centrality in the fuzzy hypergraph and their\ncoverage of topics present in the corpus. We formulate a polynomial time\nalgorithm building on the theory of submodular functions to solve the\nassociated optimization problem. A thorough comparative analysis with other\ngraph-based summarization systems is included in the paper. Our obtained\nresults show the superiority of our method in terms of content coverage of the\nsummaries.\n", "versions": [{"version": "v1", "created": "Sat, 22 Jun 2019 13:28:32 GMT"}], "update_date": "2019-06-25", "authors_parsed": [["Van Lierde", "Hadrien", ""], ["Chow", "Tommy W. S.", ""]]}, {"id": "1906.09449", "submitter": "Dawid Rymarczyk", "authors": "Bartosz Zieli\\'nski, Agnieszka Sroka-Oleksiak, Dawid Rymarczyk, Adam\n  Piekarczyk, Monika Brzychczy-W{\\l}och", "title": "Deep learning approach to description and classification of fungi\n  microscopic images", "comments": null, "journal-ref": null, "doi": "10.1371/journal.pone.0234806", "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Diagnosis of fungal infections can rely on microscopic examination, however,\nin many cases, it does not allow unambiguous identification of the species due\nto their visual similarity. Therefore, it is usually necessary to use\nadditional biochemical tests. That involves additional costs and extends the\nidentification process up to 10 days. Such a delay in the implementation of\ntargeted treatment is grave in consequences as the mortality rate for\nimmunosuppressed patients is high. In this paper, we apply machine learning\napproach based on deep learning and bag-of-words to classify microscopic images\nof various fungi species. Our approach makes the last stage of biochemical\nidentification redundant, shortening the identification process by 2-3 days and\nreducing the cost of the diagnostic examination.\n", "versions": [{"version": "v1", "created": "Sat, 22 Jun 2019 14:00:51 GMT"}, {"version": "v2", "created": "Fri, 2 Aug 2019 11:24:49 GMT"}, {"version": "v3", "created": "Tue, 28 Jan 2020 14:30:00 GMT"}], "update_date": "2020-10-14", "authors_parsed": [["Zieli\u0144ski", "Bartosz", ""], ["Sroka-Oleksiak", "Agnieszka", ""], ["Rymarczyk", "Dawid", ""], ["Piekarczyk", "Adam", ""], ["Brzychczy-W\u0142och", "Monika", ""]]}, {"id": "1906.09506", "submitter": "Weiping Song", "authors": "Weiping Song, Zhijian Duan, Ziqing Yang, Hao Zhu, Ming Zhang, Jian\n  Tang", "title": "Explainable Knowledge Graph-based Recommendation via Deep Reinforcement\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies recommender systems with knowledge graphs, which can\neffectively address the problems of data sparsity and cold start. Recently, a\nvariety of methods have been developed for this problem, which generally try to\nlearn effective representations of users and items and then match items to\nusers according to their representations. Though these methods have been shown\nquite effective, they lack good explanations, which are critical to recommender\nsystems. In this paper, we take a different path and propose generating\nrecommendations by finding meaningful paths from users to items. Specifically,\nwe formulate the problem as a sequential decision process, where the target\nuser is defined as the initial state, and the walks on the graphs are defined\nas actions. We shape the rewards according to existing state-of-the-art methods\nand then train a policy function with policy gradient methods. Experimental\nresults on three real-world datasets show that our proposed method not only\nprovides effective recommendations but also offers good explanations.\n", "versions": [{"version": "v1", "created": "Sat, 22 Jun 2019 21:02:57 GMT"}], "update_date": "2019-06-25", "authors_parsed": [["Song", "Weiping", ""], ["Duan", "Zhijian", ""], ["Yang", "Ziqing", ""], ["Zhu", "Hao", ""], ["Zhang", "Ming", ""], ["Tang", "Jian", ""]]}, {"id": "1906.09525", "submitter": "Chawin Sitawarin", "authors": "Chawin Sitawarin, David Wagner", "title": "Defending Against Adversarial Examples with K-Nearest Neighbor", "comments": "Inadequate experimental evaluation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Robustness is an increasingly important property of machine learning models\nas they become more and more prevalent. We propose a defense against\nadversarial examples based on a k-nearest neighbor (kNN) on the intermediate\nactivation of neural networks. Our scheme surpasses state-of-the-art defenses\non MNIST and CIFAR-10 against l2-perturbation by a significant margin. With our\nmodels, the mean perturbation norm required to fool our MNIST model is 3.07 and\n2.30 on CIFAR-10. Additionally, we propose a simple certifiable lower bound on\nthe l2-norm of the adversarial perturbation using a more specific version of\nour scheme, a 1-NN on representations learned by a Lipschitz network. Our model\nprovides a nontrivial average lower bound of the perturbation norm, comparable\nto other schemes on MNIST with similar clean accuracy.\n", "versions": [{"version": "v1", "created": "Sun, 23 Jun 2019 00:38:07 GMT"}, {"version": "v2", "created": "Wed, 18 Mar 2020 20:14:50 GMT"}], "update_date": "2020-03-20", "authors_parsed": [["Sitawarin", "Chawin", ""], ["Wagner", "David", ""]]}, {"id": "1906.09550", "submitter": "Behzad Khamidehi", "authors": "Behzad Khamidehi and Elvino S. Sousa", "title": "Reinforcement Learning-Based Trajectory Design for the Aerial Base\n  Stations", "comments": "6 pages, 3 figures, to be presented in IEEE PIMRC 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.AI cs.LG cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, the trajectory optimization problem for a multi-aerial base\nstation (ABS) communication network is investigated. The objective is to find\nthe trajectory of the ABSs so that the sum-rate of the users served by each ABS\nis maximized. To reach this goal, along with the optimal trajectory design,\noptimal power and sub-channel allocation is also of great importance to support\nthe users with the highest possible data rates. To solve this complicated\nproblem, we divide it into two sub-problems: ABS trajectory optimization\nsub-problem, and joint power and sub-channel assignment sub-problem. Then,\nbased on the Q-learning method, we develop a distributed algorithm which solves\nthese sub-problems efficiently, and does not need significant amount of\ninformation exchange between the ABSs and the core network. Simulation results\nshow that although Q-learning is a model-free reinforcement learning technique,\nit has a remarkable capability to train the ABSs to optimize their trajectories\nbased on the received reward signals, which carry decent information from the\ntopology of the network.\n", "versions": [{"version": "v1", "created": "Sun, 23 Jun 2019 04:08:33 GMT"}, {"version": "v2", "created": "Sat, 29 Jun 2019 05:28:34 GMT"}], "update_date": "2019-07-02", "authors_parsed": [["Khamidehi", "Behzad", ""], ["Sousa", "Elvino S.", ""]]}, {"id": "1906.09575", "submitter": "Jian-Ya Ding", "authors": "Jian-Ya Ding, Chao Zhang, Lei Shen, Shengyin Li, Bing Wang, Yinghui\n  Xu, Le Song", "title": "Accelerating Primal Solution Findings for Mixed Integer Programs Based\n  on Solution Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mixed Integer Programming (MIP) is one of the most widely used modeling\ntechniques for combinatorial optimization problems. In many applications, a\nsimilar MIP model is solved on a regular basis, maintaining remarkable\nsimilarities in model structures and solution appearances but differing in\nformulation coefficients. This offers the opportunity for machine learning\nmethods to explore the correlations between model structures and the resulting\nsolution values. To address this issue, we propose to represent an MIP instance\nusing a tripartite graph, based on which a Graph Convolutional Network (GCN) is\nconstructed to predict solution values for binary variables. The predicted\nsolutions are used to generate a local branching type cut which can be either\ntreated as a global (invalid) inequality in the formulation resulting in a\nheuristic approach to solve the MIP, or as a root branching rule resulting in\nan exact approach. Computational evaluations on 8 distinct types of MIP\nproblems show that the proposed framework improves the primal solution finding\nperformance significantly on a state-of-the-art open-source MIP solver.\n", "versions": [{"version": "v1", "created": "Sun, 23 Jun 2019 10:07:47 GMT"}, {"version": "v2", "created": "Mon, 9 Sep 2019 06:21:09 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["Ding", "Jian-Ya", ""], ["Zhang", "Chao", ""], ["Shen", "Lei", ""], ["Li", "Shengyin", ""], ["Wang", "Bing", ""], ["Xu", "Yinghui", ""], ["Song", "Le", ""]]}, {"id": "1906.09586", "submitter": "Jakub Mare\\v{c}ek", "authors": "Wann-Jiun Ma and Jakub Marecek and Martin Mevissen", "title": "A Fine-Grained Variant of the Hierarchy of Lasserre", "comments": null, "journal-ref": "57th Annual Allerton Conference on Communication, Control, and\n  Computing (2019)", "doi": null, "report-no": null, "categories": "math.OC cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There has been much recent interest in hierarchies of progressively stronger\nconvexifications of polynomial optimisation problems (POP). These often\nconverge to the global optimum of the POP, asymptotically, but prove\nchallenging to solve beyond the first level in the hierarchy for modest\ninstances. We present a finer-grained variant of the Lasserre hierarchy,\ntogether with first-order methods for solving the convexifications, which allow\nfor efficient warm-starting with solutions from lower levels in the hierarchy.\n", "versions": [{"version": "v1", "created": "Sun, 23 Jun 2019 11:50:23 GMT"}], "update_date": "2019-09-24", "authors_parsed": [["Ma", "Wann-Jiun", ""], ["Marecek", "Jakub", ""], ["Mevissen", "Martin", ""]]}, {"id": "1906.09587", "submitter": "Nagender Aneja", "authors": "Amit Kumar Jaiswal and Ivan Panshin and Dimitrij Shulkin and Nagender\n  Aneja and Samuel Abramov", "title": "Semi-Supervised Learning for Cancer Detection of Lymph Node Metastases", "comments": "Accepted in CVPR 2019 Workshop Towards Causal, Explainable and\n  Universal Medical Visual Diagnosis", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pathologists find tedious to examine the status of the sentinel lymph node on\na large number of pathological scans. The examination process of such lymph\nnode which encompasses metastasized cancer cells is histopathologically\norganized. However, the task of finding metastatic tissues is gradual which is\noften challenging. In this work, we present our deep convolutional neural\nnetwork based model validated on PatchCamelyon (PCam) benchmark dataset for\nfundamental machine learning research in histopathology diagnosis. We find that\nour proposed model trained with a semi-supervised learning approach by using\npseudo labels on PCam-level significantly leads to better performances to\nstrong CNN baseline on the AUC metric.\n", "versions": [{"version": "v1", "created": "Sun, 23 Jun 2019 11:54:53 GMT"}], "update_date": "2019-06-25", "authors_parsed": [["Jaiswal", "Amit Kumar", ""], ["Panshin", "Ivan", ""], ["Shulkin", "Dimitrij", ""], ["Aneja", "Nagender", ""], ["Abramov", "Samuel", ""]]}, {"id": "1906.09591", "submitter": "Luigi Freda", "authors": "Luigi Freda, Mario Gianni, Fiora Pirri, Abel Gawel, Renaud Dube,\n  Roland Siegwart, Cesar Cadena", "title": "3D Multi-Robot Patrolling with a Two-Level Coordination Strategy", "comments": null, "journal-ref": null, "doi": "10.1007/s10514-018-09822-3", "report-no": null, "categories": "cs.RO cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Teams of UGVs patrolling harsh and complex 3D environments can experience\ninterference and spatial conflicts with one another. Neglecting the occurrence\nof these events crucially hinders both soundness and reliability of a\npatrolling process. This work presents a distributed multi-robot patrolling\ntechnique, which uses a two-level coordination strategy to minimize and\nexplicitly manage the occurrence of conflicts and interference. The first level\nguides the agents to single out exclusive target nodes on a topological map.\nThis target selection relies on a shared idleness representation and a\ncoordination mechanism preventing topological conflicts. The second level hosts\ncoordination strategies based on a metric representation of space and is\nsupported by a 3D SLAM system. Here, each robot path planner negotiates spatial\nconflicts by applying a multi-robot traversability function. Continuous\ninteractions between these two levels ensure coordination and conflicts\nresolution. Both simulations and real-world experiments are presented to\nvalidate the performances of the proposed patrolling strategy in 3D\nenvironments. Results show this is a promising solution for managing spatial\nconflicts and preventing deadlocks.\n", "versions": [{"version": "v1", "created": "Sun, 23 Jun 2019 12:51:05 GMT"}], "update_date": "2019-06-25", "authors_parsed": [["Freda", "Luigi", ""], ["Gianni", "Mario", ""], ["Pirri", "Fiora", ""], ["Gawel", "Abel", ""], ["Dube", "Renaud", ""], ["Siegwart", "Roland", ""], ["Cadena", "Cesar", ""]]}, {"id": "1906.09601", "submitter": "Long Zhou", "authors": "Long Zhou, Jiajun Zhang, Chengqing Zong, Heng Yu", "title": "Sequence Generation: From Both Sides to the Middle", "comments": "Accepted by IJCAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The encoder-decoder framework has achieved promising process for many\nsequence generation tasks, such as neural machine translation and text\nsummarization. Such a framework usually generates a sequence token by token\nfrom left to right, hence (1) this autoregressive decoding procedure is\ntime-consuming when the output sentence becomes longer, and (2) it lacks the\nguidance of future context which is crucial to avoid under translation. To\nalleviate these issues, we propose a synchronous bidirectional sequence\ngeneration (SBSG) model which predicts its outputs from both sides to the\nmiddle simultaneously. In the SBSG model, we enable the left-to-right (L2R) and\nright-to-left (R2L) generation to help and interact with each other by\nleveraging interactive bidirectional attention network. Experiments on neural\nmachine translation (En-De, Ch-En, and En-Ro) and text summarization tasks show\nthat the proposed model significantly speeds up decoding while improving the\ngeneration quality compared to the autoregressive Transformer.\n", "versions": [{"version": "v1", "created": "Sun, 23 Jun 2019 16:13:45 GMT"}], "update_date": "2019-06-25", "authors_parsed": [["Zhou", "Long", ""], ["Zhang", "Jiajun", ""], ["Zong", "Chengqing", ""], ["Yu", "Heng", ""]]}, {"id": "1906.09621", "submitter": "Candice Schumann", "authors": "Candice Schumann, Zhi Lang, Jeffrey S. Foster, John P. Dickerson", "title": "Making the Cut: A Bandit-based Approach to Tiered Interviewing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a huge set of applicants, how should a firm allocate sequential resume\nscreenings, phone interviews, and in-person site visits? In a tiered interview\nprocess, later stages (e.g., in-person visits) are more informative, but also\nmore expensive than earlier stages (e.g., resume screenings). Using accepted\nhiring models and the concept of structured interviews, a best practice in\nhuman resources, we cast tiered hiring as a combinatorial pure exploration\n(CPE) problem in the stochastic multi-armed bandit setting. The goal is to\nselect a subset of arms (in our case, applicants) with some combinatorial\nstructure. We present new algorithms in both the probably approximately correct\n(PAC) and fixed-budget settings that select a near-optimal cohort with provable\nguarantees. We show via simulations on real data from one of the largest\nUS-based computer science graduate programs that our algorithms make better\nhiring decisions or use less budget than the status quo.\n", "versions": [{"version": "v1", "created": "Sun, 23 Jun 2019 18:02:10 GMT"}, {"version": "v2", "created": "Thu, 14 Nov 2019 22:27:28 GMT"}], "update_date": "2019-11-18", "authors_parsed": [["Schumann", "Candice", ""], ["Lang", "Zhi", ""], ["Foster", "Jeffrey S.", ""], ["Dickerson", "John P.", ""]]}, {"id": "1906.09624", "submitter": "Rohin Shah", "authors": "Rohin Shah, Noah Gundotra, Pieter Abbeel, Anca D. Dragan", "title": "On the Feasibility of Learning, Rather than Assuming, Human Biases for\n  Reward Inference", "comments": "Published at ICML 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Our goal is for agents to optimize the right reward function, despite how\ndifficult it is for us to specify what that is. Inverse Reinforcement Learning\n(IRL) enables us to infer reward functions from demonstrations, but it usually\nassumes that the expert is noisily optimal. Real people, on the other hand,\noften have systematic biases: risk-aversion, myopia, etc. One option is to try\nto characterize these biases and account for them explicitly during learning.\nBut in the era of deep learning, a natural suggestion researchers make is to\navoid mathematical models of human behavior that are fraught with specific\nassumptions, and instead use a purely data-driven approach. We decided to put\nthis to the test -- rather than relying on assumptions about which specific\nbias the demonstrator has when planning, we instead learn the demonstrator's\nplanning algorithm that they use to generate demonstrations, as a\ndifferentiable planner. Our exploration yielded mixed findings: on the one\nhand, learning the planner can lead to better reward inference than relying on\nthe wrong assumption; on the other hand, this benefit is dwarfed by the loss we\nincur by going from an exact to a differentiable planner. This suggest that at\nleast for the foreseeable future, agents need a middle ground between the\nflexibility of data-driven methods and the useful bias of known human biases.\nCode is available at https://tinyurl.com/learningbiases.\n", "versions": [{"version": "v1", "created": "Sun, 23 Jun 2019 18:41:31 GMT"}], "update_date": "2019-06-25", "authors_parsed": [["Shah", "Rohin", ""], ["Gundotra", "Noah", ""], ["Abbeel", "Pieter", ""], ["Dragan", "Anca D.", ""]]}, {"id": "1906.09627", "submitter": "Andrew Cropper", "authors": "Andrew Cropper and Richard Evans and Mark Law", "title": "Inductive general game playing", "comments": "Accepted for the Machine Learning journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  General game playing (GGP) is a framework for evaluating an agent's general\nintelligence across a wide range of tasks. In the GGP competition, an agent is\ngiven the rules of a game (described as a logic program) that it has never seen\nbefore. The task is for the agent to play the game, thus generating game\ntraces. The winner of the GGP competition is the agent that gets the best total\nscore over all the games. In this paper, we invert this task: a learner is\ngiven game traces and the task is to learn the rules that could produce the\ntraces. This problem is central to inductive general game playing (IGGP). We\nintroduce a technique that automatically generates IGGP tasks from GGP games.\nWe introduce an IGGP dataset which contains traces from 50 diverse games, such\nas Sudoku, Sokoban, and Checkers. We claim that IGGP is difficult for existing\ninductive logic programming (ILP) approaches. To support this claim, we\nevaluate existing ILP systems on our dataset. Our empirical results show that\nmost of the games cannot be correctly learned by existing systems. The best\nperforming system solves only 40% of the tasks perfectly. Our results suggest\nthat IGGP poses many challenges to existing approaches. Furthermore, because we\ncan automatically generate IGGP tasks from GGP games, our dataset will continue\nto grow with the GGP competition, as new games are added every year. We\ntherefore think that the IGGP problem and dataset will be valuable for\nmotivating and evaluating future research.\n", "versions": [{"version": "v1", "created": "Sun, 23 Jun 2019 19:06:09 GMT"}], "update_date": "2019-06-25", "authors_parsed": [["Cropper", "Andrew", ""], ["Evans", "Richard", ""], ["Law", "Mark", ""]]}, {"id": "1906.09674", "submitter": "Kaixiang Lin", "authors": "Kaixiang Lin and Jiayu Zhou", "title": "Ranking Policy Gradient", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sample inefficiency is a long-lasting problem in reinforcement learning (RL).\nThe state-of-the-art estimates the optimal action values while it usually\ninvolves an extensive search over the state-action space and unstable\noptimization. Towards the sample-efficient RL, we propose ranking policy\ngradient (RPG), a policy gradient method that learns the optimal rank of a set\nof discrete actions. To accelerate the learning of policy gradient methods, we\nestablish the equivalence between maximizing the lower bound of return and\nimitating a near-optimal policy without accessing any oracles. These results\nlead to a general off-policy learning framework, which preserves the\noptimality, reduces variance, and improves the sample-efficiency. Furthermore,\nthe sample complexity of RPG does not depend on the dimension of state space,\nwhich enables RPG for large-scale problems. We conduct extensive experiments\nshowing that when consolidating with the off-policy learning framework, RPG\nsubstantially reduces the sample complexity, comparing to the state-of-the-art.\n", "versions": [{"version": "v1", "created": "Mon, 24 Jun 2019 00:13:42 GMT"}, {"version": "v2", "created": "Sat, 12 Oct 2019 17:49:21 GMT"}, {"version": "v3", "created": "Tue, 26 Nov 2019 16:00:15 GMT"}], "update_date": "2019-11-27", "authors_parsed": [["Lin", "Kaixiang", ""], ["Zhou", "Jiayu", ""]]}, {"id": "1906.09676", "submitter": "Arnold Wiliem", "authors": "Sam Maksoud, Arnold Wiliem, Kun Zhao, Teng Zhang, Lin Wu and Brian C.\n  Lovell", "title": "CORAL8: Concurrent Object Regression for Area Localization in Medical\n  Image Panels", "comments": "Accepted for MICCAI 2019", "journal-ref": null, "doi": "10.1007/978-3-030-32239-7_48", "report-no": null, "categories": "cs.CV cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work tackles the problem of generating a medical report for multi-image\npanels. We apply our solution to the Renal Direct Immunofluorescence (RDIF)\nassay which requires a pathologist to generate a report based on observations\nacross the eight different WSI in concert with existing clinical features. To\nthis end, we propose a novel attention-based multi-modal generative recurrent\nneural network (RNN) architecture capable of dynamically sampling image data\nconcurrently across the RDIF panel. The proposed methodology incorporates text\nfrom the clinical notes of the requesting physician to regulate the output of\nthe network to align with the overall clinical context. In addition, we found\nthe importance of regularizing the attention weights for word generation\nprocesses. This is because the system can ignore the attention mechanism by\nassigning equal weights for all members. Thus, we propose two regularizations\nwhich force the system to utilize the attention mechanism. Experiments on our\nnovel collection of RDIF WSIs provided by a large clinical laboratory\ndemonstrate that our framework offers significant improvements over existing\nmethods.\n", "versions": [{"version": "v1", "created": "Mon, 24 Jun 2019 00:30:32 GMT"}], "update_date": "2020-07-03", "authors_parsed": [["Maksoud", "Sam", ""], ["Wiliem", "Arnold", ""], ["Zhao", "Kun", ""], ["Zhang", "Teng", ""], ["Wu", "Lin", ""], ["Lovell", "Brian C.", ""]]}, {"id": "1906.09681", "submitter": "Meng Li", "authors": "Meng Li, Lin Wu, Arnold Wiliem, Kun Zhao, Teng Zhang and Brian C.\n  Lovell", "title": "Deep Instance-Level Hard Negative Mining Model for Histopathology Images", "comments": "Accepted by MICCAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Histopathology image analysis can be considered as a Multiple instance\nlearning (MIL) problem, where the whole slide histopathology image (WSI) is\nregarded as a bag of instances (i.e, patches) and the task is to predict a\nsingle class label to the WSI. However, in many real-life applications such as\ncomputational pathology, discovering the key instances that trigger the bag\nlabel is of great interest because it provides reasons for the decision made by\nthe system. In this paper, we propose a deep convolutional neural network (CNN)\nmodel that addresses the primary task of a bag classification on a WSI and also\nlearns to identify the response of each instance to provide interpretable\nresults to the final prediction. We incorporate the attention mechanism into\nthe proposed model to operate the transformation of instances and learn\nattention weights to allow us to find key patches. To perform a balanced\ntraining, we introduce adaptive weighing in each training bag to explicitly\nadjust the weight distribution in order to concentrate more on the contribution\nof hard samples. Based on the learned attention weights, we further develop a\nsolution to boost the classification performance by generating the bags with\nhard negative instances. We conduct extensive experiments on colon and breast\ncancer histopathology data and show that our framework achieves\nstate-of-the-art performance.\n", "versions": [{"version": "v1", "created": "Mon, 24 Jun 2019 01:00:05 GMT"}, {"version": "v2", "created": "Wed, 26 Jun 2019 00:35:51 GMT"}, {"version": "v3", "created": "Thu, 27 Jun 2019 02:00:32 GMT"}], "update_date": "2019-06-28", "authors_parsed": [["Li", "Meng", ""], ["Wu", "Lin", ""], ["Wiliem", "Arnold", ""], ["Zhao", "Kun", ""], ["Zhang", "Teng", ""], ["Lovell", "Brian C.", ""]]}, {"id": "1906.09689", "submitter": "Johan F. Hoorn", "authors": "Johan F. Hoorn and Denice J. Tuinhof", "title": "A robot's sense-making of fallacies and rhetorical tropes. Creating\n  ontologies of what humans try to say", "comments": "Hoorn, J. F., & Tuinhof, D. J. (2019). A robot's sense-making of\n  fallacies and rhetorical tropes. Creating ontologies of what humans try to\n  say. arXiv:cs", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.HC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In the design of user-friendly robots, human communication should be\nunderstood by the system beyond mere logics and literal meaning. Robot\ncommunication-design has long ignored the importance of communication and\npoliteness rules that are 'forgiving' and 'suspending disbelief' and cannot\nhandle the basically metaphorical way humans design their utterances. Through\nanalysis of the psychological causes of illogical and non-literal statements,\nsignal detection, fundamental attribution errors, and anthropomorphism, we\ndeveloped a fail-safe protocol for fallacies and tropes that makes use of\nFrege's distinction between reference and sense, Beth's tableau analytics,\nGrice's maxim of quality, and epistemic considerations to have the robot\npolitely make sense of a user's sometimes unintelligible demands. Keywords:\nsocial robots, logical fallacies, metaphors, reference, sense, maxim of\nquality, tableau reasoning, epistemics of the virtual\n", "versions": [{"version": "v1", "created": "Mon, 24 Jun 2019 02:04:15 GMT"}], "update_date": "2019-06-25", "authors_parsed": [["Hoorn", "Johan F.", ""], ["Tuinhof", "Denice J.", ""]]}, {"id": "1906.09722", "submitter": "Sibylle Hess", "authors": "Sibylle Hess, Katharina Morik, Nico Piatkowski", "title": "The PRIMPing Routine -- Tiling through Proximal Alternating Linearized\n  Minimization", "comments": null, "journal-ref": "Data Mining and Knowledge Discovery 31(4): 1090-1131 (2017)", "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mining and exploring databases should provide users with knowledge and new\ninsights. Tiles of data strive to unveil true underlying structure and\ndistinguish valuable information from various kinds of noise. We propose a\nnovel Boolean matrix factorization algorithm to solve the tiling problem, based\non recent results from optimization theory. In contrast to existing work, the\nnew algorithm minimizes the description length of the resulting factorization.\nThis approach is well known for model selection and data compression, but not\nfor finding suitable factorizations via numerical optimization. We demonstrate\nthe superior robustness of the new approach in the presence of several kinds of\nnoise and types of underlying structure. Moreover, our general framework can\nwork with any cost measure having a suitable real-valued relaxation. Thereby,\nno convexity assumptions have to be met. The experimental results on synthetic\ndata and image data show that the new method identifies interpretable patterns\nwhich explain the data almost always better than the competing algorithms.\n", "versions": [{"version": "v1", "created": "Mon, 17 Jun 2019 21:56:36 GMT"}], "update_date": "2019-06-25", "authors_parsed": [["Hess", "Sibylle", ""], ["Morik", "Katharina", ""], ["Piatkowski", "Nico", ""]]}, {"id": "1906.09744", "submitter": "Ye Zhu PhD", "authors": "Ye Zhu, Kai Ming Ting", "title": "Improving the Effectiveness and Efficiency of Stochastic Neighbour\n  Embedding with Isolation Kernel", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a new insight into improving the performance of\nStochastic Neighbour Embedding (t-SNE) by using Isolation kernel instead of\nGaussian kernel. Isolation kernel outperforms Gaussian kernel in two aspects.\nFirst, the use of Isolation kernel in t-SNE overcomes the drawback of\nmisrepresenting some structures in the data, which often occurs when Gaussian\nkernel is applied in t-SNE. This is because Gaussian kernel determines each\nlocal bandwidth based on one local point only, while Isolation kernel is\nderived directly from the data based on space partitioning. Second, the use of\nIsolation kernel yields a more efficient similarity computation because\ndata-dependent Isolation kernel has only one parameter that needs to be tuned.\nIn contrast, the use of data-independent Gaussian kernel increases the\ncomputational cost by determining n bandwidths for a dataset of n points. As\nthe root cause of these deficiencies in t-SNE is Gaussian kernel, we show that\nsimply replacing Gaussian kernel with Isolation kernel in t-SNE significantly\nimproves the quality of the final visualisation output (without creating\nmisrepresented structures) and removes one key obstacle that prevents t-SNE\nfrom processing large datasets. Moreover, Isolation kernel enables t-SNE to\ndeal with large-scale datasets in less runtime without trading off accuracy,\nunlike existing methods in speeding up t-SNE.\n", "versions": [{"version": "v1", "created": "Mon, 24 Jun 2019 06:49:04 GMT"}, {"version": "v2", "created": "Tue, 25 Jun 2019 03:34:10 GMT"}, {"version": "v3", "created": "Thu, 8 Jul 2021 04:20:20 GMT"}], "update_date": "2021-07-09", "authors_parsed": [["Zhu", "Ye", ""], ["Ting", "Kai Ming", ""]]}, {"id": "1906.09745", "submitter": "Wenhao Jiang", "authors": "Wenhao Jiang, Zhiyu Liu, Kit-Hang Lee, Shihui Chen, Yui-Lun Ng, Qi\n  Dou, Hing-Chiu Chang, and Ka-Wai Kwok", "title": "Respiratory Motion Correction in Abdominal MRI using a Densely Connected\n  U-Net with GAN-guided Training", "comments": "8 pages, 4 figures, submitted to the 22nd International Conference on\n  Medical Image Computing and Computer Assisted Intervention", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Abdominal magnetic resonance imaging (MRI) provides a straightforward way of\ncharacterizing tissue and locating lesions of patients as in standard\ndiagnosis. However, abdominal MRI often suffers from respiratory motion\nartifacts, which leads to blurring and ghosting that significantly deteriorate\nthe imaging quality. Conventional methods to reduce or eliminate these motion\nartifacts include breath holding, patient sedation, respiratory gating, and\nimage post-processing, but these strategies inevitably involve extra scanning\ntime and patient discomfort. In this paper, we propose a novel\ndeep-learning-based model to recover MR images from respiratory motion\nartifacts. The proposed model comprises a densely connected U-net with\ngenerative adversarial network (GAN)-guided training and a perceptual loss\nfunction. We validate the model using a diverse collection of MRI data that are\nadversely affected by both synthetic and authentic respiration artifacts.\nEffective outcomes of motion removal are demonstrated. Our experimental results\nshow the great potential of utilizing deep-learning-based methods in\nrespiratory motion correction for abdominal MRI.\n", "versions": [{"version": "v1", "created": "Mon, 24 Jun 2019 06:54:35 GMT"}], "update_date": "2019-06-25", "authors_parsed": [["Jiang", "Wenhao", ""], ["Liu", "Zhiyu", ""], ["Lee", "Kit-Hang", ""], ["Chen", "Shihui", ""], ["Ng", "Yui-Lun", ""], ["Dou", "Qi", ""], ["Chang", "Hing-Chiu", ""], ["Kwok", "Ka-Wai", ""]]}, {"id": "1906.09769", "submitter": "Nimisha Ghosh", "authors": "Nimisha Ghosh, Rourab Paul, Satyabrata Maity, Krishanu Maity and\n  Sayantan Saha", "title": "Fault Matters: Sensor Data Fusion for Detection of Faults using\n  Dempster-Shafer Theory of Evidence in IoT-Based Applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fault detection in sensor nodes is a pertinent issue that has been an\nimportant area of research for a very long time. But it is not explored much as\nyet in the context of Internet of Things. Internet of Things work with a\nmassive amount of data so the responsibility for guaranteeing the accuracy of\nthe data also lies with it. Moreover, a lot of important and critical decisions\nare made based on these data, so ensuring its correctness and accuracy is also\nvery important. Also, the detection needs to be as precise as possible to avoid\nnegative alerts. For this purpose, this work has adopted Dempster-Shafer Theory\nof Evidence which is a popular learning method to collate the information from\nsensors to come up with a decision regarding the faulty status of a sensor\nnode. To verify the validity of the proposed method, simulations have been\nperformed on a benchmark data set and data collected through a test bed in a\nlaboratory set-up. For the different types of faults, the proposed method shows\nvery competent accuracy for both the benchmark (99.8%) and laboratory data sets\n(99.9%) when compared to the other state-of-the-art machine learning\ntechniques.\n", "versions": [{"version": "v1", "created": "Mon, 24 Jun 2019 07:58:59 GMT"}], "update_date": "2019-06-25", "authors_parsed": [["Ghosh", "Nimisha", ""], ["Paul", "Rourab", ""], ["Maity", "Satyabrata", ""], ["Maity", "Krishanu", ""], ["Saha", "Sayantan", ""]]}, {"id": "1906.09785", "submitter": "Wenchao Ding", "authors": "Wenchao Ding and Wenliang Gao and Kaixuan Wang and Shaojie Shen", "title": "An Efficient B-spline-Based Kinodynamic Replanning Framework for\n  Quadrotors", "comments": "IEEE Transactions on Robotics", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Trajectory replanning for quadrotors is essential to enable fully autonomous\nflight in unknown environments. Hierarchical motion planning frameworks, which\ncombine path planning with path parameterization, are popular due to their time\nefficiency. However, the path planning cannot properly deal with non-static\ninitial states of the quadrotor, which may result in non-smooth or even\ndynamically infeasible trajectories. In this paper, we present an efficient\nkinodynamic replanning framework by exploiting the advantageous properties of\nthe B-spline, which facilitates dealing with the non-static state and\nguarantees safety and dynamical feasibility. Our framework starts with an\nefficient B-spline-based kinodynamic (EBK) search algorithm which finds a\nfeasible trajectory with minimum control effort and time. To compensate for the\ndiscretization induced by the EBK search, an elastic optimization (EO) approach\nis proposed to refine the control point placement to the optimal location.\nSystematic comparisons against the state-of-the-art are conducted to validate\nthe performance. Comprehensive onboard experiments using two different\nvision-based quadrotors are carried out showing the general applicability of\nthe framework.\n", "versions": [{"version": "v1", "created": "Mon, 24 Jun 2019 08:44:56 GMT"}], "update_date": "2019-06-25", "authors_parsed": [["Ding", "Wenchao", ""], ["Gao", "Wenliang", ""], ["Wang", "Kaixuan", ""], ["Shen", "Shaojie", ""]]}, {"id": "1906.09788", "submitter": "Wenchao Ding", "authors": "Wenchao Ding and Lu Zhang and Jing Chen and Shaojie Shen", "title": "Safe Trajectory Generation for Complex Urban Environments Using\n  Spatio-temporal Semantic Corridor", "comments": "Accepted by IEEE Robotics and Automation Letters (IEEE RA-L)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Planning safe trajectories for autonomous vehicles in complex urban\nenvironments is challenging since there are numerous semantic elements (such as\ndynamic agents, traffic lights and speed limits) to consider. These semantic\nelements may have different mathematical descriptions such as obstacle,\nconstraint and cost. It is non-trivial to tune the effects from different\ncombinations of semantic elements for a stable and generalizable behavior. In\nthis paper, we propose a novel unified spatio-temporal semantic corridor (SSC)\nstructure, which provides a level of abstraction for different types of\nsemantic elements. The SSC consists of a series of mutually connected\ncollision-free cubes with dynamical constraints posed by the semantic elements\nin the spatio-temporal domain. The trajectory generation problem then boils\ndown to a general quadratic programming (QP) formulation. Thanks to the unified\nSSC representation, our framework can generalize to any combination of semantic\nelements. Moreover, our formulation provides a theoretical guarantee that the\nentire trajectory is safe and constraint-satisfied, by using the convex hull\nand hodograph properties of piecewise Bezier curve parameterization. We also\nrelease the code of our method to accommodate benchmarking.\n", "versions": [{"version": "v1", "created": "Mon, 24 Jun 2019 08:49:17 GMT"}], "update_date": "2019-06-25", "authors_parsed": [["Ding", "Wenchao", ""], ["Zhang", "Lu", ""], ["Chen", "Jing", ""], ["Shen", "Shaojie", ""]]}, {"id": "1906.09831", "submitter": "Alexis Jacq", "authors": "Alexis Jacq and Julien Perolat and Matthieu Geist and Olivier Pietquin", "title": "Foolproof Cooperative Learning", "comments": null, "journal-ref": "Proceedings of The 12th Asian Conference on Machine Learning, PMLR\n  129:401-416, 2020", "doi": null, "report-no": null, "categories": "cs.GT cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  This paper extends the notion of learning equilibrium in game theory from\nmatrix games to stochastic games. We introduce Foolproof Cooperative Learning\n(FCL), an algorithm that converges to a Tit-for-Tat behavior. It allows\ncooperative strategies when played against itself while being not exploitable\nby selfish players. We prove that in repeated symmetric games, this algorithm\nis a learning equilibrium. We illustrate the behavior of FCL on symmetric\nmatrix and grid games, and its robustness to selfish learners.\n", "versions": [{"version": "v1", "created": "Mon, 24 Jun 2019 10:13:23 GMT"}, {"version": "v2", "created": "Wed, 4 Sep 2019 13:15:51 GMT"}, {"version": "v3", "created": "Thu, 15 Oct 2020 09:23:43 GMT"}], "update_date": "2020-10-16", "authors_parsed": [["Jacq", "Alexis", ""], ["Perolat", "Julien", ""], ["Geist", "Matthieu", ""], ["Pietquin", "Olivier", ""]]}, {"id": "1906.09833", "submitter": "Yvette Graham", "authors": "Yvette Graham and Barry Haddow and Philipp Koehn", "title": "Translationese in Machine Translation Evaluation", "comments": "17 pages, 8 figures, 9 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The term translationese has been used to describe the presence of unusual\nfeatures of translated text. In this paper, we provide a detailed analysis of\nthe adverse effects of translationese on machine translation evaluation\nresults. Our analysis shows evidence to support differences in text originally\nwritten in a given language relative to translated text and this can\npotentially negatively impact the accuracy of machine translation evaluations.\nFor this reason we recommend that reverse-created test data be omitted from\nfuture machine translation test sets. In addition, we provide a re-evaluation\nof a past high-profile machine translation evaluation claiming human-parity of\nMT, as well as analysis of the since re-evaluations of it. We find potential\nways of improving the reliability of all three past evaluations. One important\nissue not previously considered is the statistical power of significance tests\napplied in past evaluations that aim to investigate human-parity of MT. Since\nthe very aim of such evaluations is to reveal legitimate ties between human and\nMT systems, power analysis is of particular importance, where low power could\nresult in claims of human parity that in fact simply correspond to Type II\nerror. We therefore provide a detailed power analysis of tests used in such\nevaluations to provide an indication of a suitable minimum sample size of\ntranslations for such studies. Subsequently, since no past evaluation that\naimed to investigate claims of human parity ticks all boxes in terms of\naccuracy and reliability, we rerun the evaluation of the systems claiming human\nparity. Finally, we provide a comprehensive check-list for future machine\ntranslation evaluation.\n", "versions": [{"version": "v1", "created": "Mon, 24 Jun 2019 10:14:42 GMT"}], "update_date": "2019-06-25", "authors_parsed": [["Graham", "Yvette", ""], ["Haddow", "Barry", ""], ["Koehn", "Philipp", ""]]}, {"id": "1906.09874", "submitter": "William Long", "authors": "William Long", "title": "Escaping the State of Nature: A Hobbesian Approach to Cooperation in\n  Multi-agent Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cooperation is a phenomenon that has been widely studied across many\ndifferent disciplines. In the field of computer science, the modularity and\nrobustness of multi-agent systems offer significant practical advantages over\nindividual machines. At the same time, agents using standard reinforcement\nlearning algorithms often fail to achieve long-term, cooperative strategies in\nunstable environments when there are short-term incentives to defect. Political\nphilosophy, on the other hand, studies the evolution of cooperation in humans\nwho face similar incentives to act individualistically, but nevertheless\nsucceed in forming societies. Thomas Hobbes in Leviathan provides the classic\nanalysis of the transition from a pre-social State of Nature, where consistent\ndefection results in a constant state of war, to stable political community\nthrough the institution of an absolute Sovereign. This thesis argues that\nHobbes's natural and moral philosophy are strikingly applicable to artificially\nintelligent agents and aims to show that his political solutions are\nexperimentally successful in producing cooperation among modified Q-Learning\nagents. Cooperative play is achieved in a novel Sequential Social Dilemma\ncalled the Civilization Game, which models the State of Nature by introducing\nthe Hobbesian mechanisms of opponent learning awareness and majoritarian\nvoting, leading to the establishment of a Sovereign.\n", "versions": [{"version": "v1", "created": "Wed, 5 Jun 2019 17:44:36 GMT"}], "update_date": "2019-06-25", "authors_parsed": [["Long", "William", ""]]}, {"id": "1906.09895", "submitter": "Sam Ganzfried", "authors": "Sam Ganzfried and Max Chiswick", "title": "Most Important Fundamental Rule of Poker Strategy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG econ.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Poker is a large complex game of imperfect information, which has been\nsingled out as a major AI challenge problem. Recently there has been a series\nof breakthroughs culminating in agents that have successfully defeated the\nstrongest human players in two-player no-limit Texas hold 'em. The strongest\nagents are based on algorithms for approximating Nash equilibrium strategies,\nwhich are stored in massive binary files and unintelligible to humans. A recent\nline of research has explored approaches for extrapolating knowledge from\nstrong game-theoretic strategies that can be understood by humans. This would\nbe useful when humans are the ultimate decision maker and allow humans to make\nbetter decisions from massive algorithmically-generated strategies. Using\ntechniques from machine learning we have uncovered a new simple, fundamental\nrule of poker strategy that leads to a significant improvement in performance\nover the best prior rule and can also easily be applied by human players.\n", "versions": [{"version": "v1", "created": "Sat, 8 Jun 2019 22:42:24 GMT"}, {"version": "v2", "created": "Fri, 28 Jun 2019 20:58:21 GMT"}, {"version": "v3", "created": "Fri, 21 Feb 2020 04:24:33 GMT"}], "update_date": "2020-02-24", "authors_parsed": [["Ganzfried", "Sam", ""], ["Chiswick", "Max", ""]]}, {"id": "1906.09909", "submitter": "Bo Zhang", "authors": "Bo Zhang, Mingming He, Jing Liao, Pedro V. Sander, Lu Yuan, Amine\n  Bermak, Dong Chen", "title": "Deep Exemplar-based Video Colorization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents the first end-to-end network for exemplar-based video\ncolorization. The main challenge is to achieve temporal consistency while\nremaining faithful to the reference style. To address this issue, we introduce\na recurrent framework that unifies the semantic correspondence and color\npropagation steps. Both steps allow a provided reference image to guide the\ncolorization of every frame, thus reducing accumulated propagation errors.\nVideo frames are colorized in sequence based on the colorization history, and\nits coherency is further enforced by the temporal consistency loss. All of\nthese components, learned end-to-end, help produce realistic videos with good\ntemporal stability. Experiments show our result is superior to the\nstate-of-the-art methods both quantitatively and qualitatively.\n", "versions": [{"version": "v1", "created": "Mon, 24 Jun 2019 12:56:36 GMT"}], "update_date": "2019-06-25", "authors_parsed": [["Zhang", "Bo", ""], ["He", "Mingming", ""], ["Liao", "Jing", ""], ["Sander", "Pedro V.", ""], ["Yuan", "Lu", ""], ["Bermak", "Amine", ""], ["Chen", "Dong", ""]]}, {"id": "1906.09926", "submitter": "Prathamesh Deshpande", "authors": "Prathamesh Deshpande, Sunita Sarawagi", "title": "Streaming Adaptation of Deep Forecasting Models using Adaptive Recurrent\n  Units", "comments": "9 pages, 4 figures", "journal-ref": null, "doi": "10.1145/3292500.3330996", "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present ARU, an Adaptive Recurrent Unit for streaming adaptation of deep\nglobally trained time-series forecasting models. The ARU combines the\nadvantages of learning complex data transformations across multiple time series\nfrom deep global models, with per-series localization offered by closed-form\nlinear models. Unlike existing methods of adaptation that are either\nmemory-intensive or non-responsive after training, ARUs require only fixed\nsized state and adapt to streaming data via an easy RNN-like update operation.\nThe core principle driving ARU is simple --- maintain sufficient statistics of\nconditional Gaussian distributions and use them to compute local parameters in\nclosed form. Our contribution is in embedding such local linear models in\nglobally trained deep models while allowing end-to-end training on the one\nhand, and easy RNN-like updates on the other. Across several datasets we show\nthat ARU is more effective than recently proposed local adaptation methods that\ntax the global network to compute local parameters.\n", "versions": [{"version": "v1", "created": "Mon, 24 Jun 2019 13:15:02 GMT"}, {"version": "v2", "created": "Thu, 4 Jul 2019 12:08:21 GMT"}], "update_date": "2019-07-05", "authors_parsed": [["Deshpande", "Prathamesh", ""], ["Sarawagi", "Sunita", ""]]}, {"id": "1906.09954", "submitter": "Somak Aditya", "authors": "Somak Aditya, Yezhou Yang and Chitta Baral", "title": "Integrating Knowledge and Reasoning in Image Understanding", "comments": "8 pages, 2 figures", "journal-ref": "IJCAI 2019", "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning based data-driven approaches have been successfully applied in\nvarious image understanding applications ranging from object recognition,\nsemantic segmentation to visual question answering. However, the lack of\nknowledge integration as well as higher-level reasoning capabilities with the\nmethods still pose a hindrance. In this work, we present a brief survey of a\nfew representative reasoning mechanisms, knowledge integration methods and\ntheir corresponding image understanding applications developed by various\ngroups of researchers, approaching the problem from a variety of angles.\nFurthermore, we discuss upon key efforts on integrating external knowledge with\nneural networks. Taking cues from these efforts, we conclude by discussing\npotential pathways to improve reasoning capabilities.\n", "versions": [{"version": "v1", "created": "Mon, 24 Jun 2019 13:44:34 GMT"}], "update_date": "2019-06-25", "authors_parsed": [["Aditya", "Somak", ""], ["Yang", "Yezhou", ""], ["Baral", "Chitta", ""]]}, {"id": "1906.10002", "submitter": "Daniel Loureiro", "authors": "Daniel Loureiro and Alipio Jorge", "title": "LIAAD at SemDeep-5 Challenge: Word-in-Context (WiC)", "comments": "Accepted at the SemDeep-5 Workshop in IJCAI 2019. Code and data:\n  https://github.com/danlou/LMMS", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes the LIAAD system that was ranked second place in the\nWord-in-Context challenge (WiC) featured in SemDeep-5. Our solution is based on\na novel system for Word Sense Disambiguation (WSD) using contextual embeddings\nand full-inventory sense embeddings. We adapt this WSD system, in a\nstraightforward manner, for the present task of detecting whether the same\nsense occurs in a pair of sentences. Additionally, we show that our solution is\nable to achieve competitive performance even without using the provided\ntraining or development sets, mitigating potential concerns related to task\noverfitting\n", "versions": [{"version": "v1", "created": "Mon, 24 Jun 2019 14:49:05 GMT"}], "update_date": "2019-06-25", "authors_parsed": [["Loureiro", "Daniel", ""], ["Jorge", "Alipio", ""]]}, {"id": "1906.10015", "submitter": "Pablo Lanillos", "authors": "Pablo Lanillos, Daniel Oliva, Anja Philippsen, Yuichi Yamashita, Yukie\n  Nagai, Gordon Cheng", "title": "A Review on Neural Network Models of Schizophrenia and Autism Spectrum\n  Disorder", "comments": "Preprint submitted to Neural Networks. Research not referenced in the\n  manuscript within the field of NN models of SZ and ASD are encouraged to\n  contact the corresponding authors", "journal-ref": "Neural Networks 122 (2020) 338-363", "doi": "10.1016/j.neunet.2019.10.014", "report-no": null, "categories": "q-bio.NC cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This survey presents the most relevant neural network models of autism\nspectrum disorder and schizophrenia, from the first connectionist models to\nrecent deep network architectures. We analyzed and compared the most\nrepresentative symptoms with its neural model counterpart, detailing the\nalteration introduced in the network that generates each of the symptoms, and\nidentifying their strengths and weaknesses. We additionally cross-compared\nBayesian and free-energy approaches, as they are widely applied to modeling\npsychiatric disorders and share basic mechanisms with neural networks. Models\nof schizophrenia mainly focused on hallucinations and delusional thoughts using\nneural dysconnections or inhibitory imbalance as the predominating alteration.\nModels of autism rather focused on perceptual difficulties, mainly excessive\nattention to environment details, implemented as excessive inhibitory\nconnections or increased sensory precision. We found an excessive tight view of\nthe psychopathologies around one specific and simplified effect, usually\nconstrained to the technical idiosyncrasy of the used network architecture.\nRecent theories and evidence on sensorimotor integration and body perception\ncombined with modern neural network architectures could offer a broader and\nnovel spectrum to approach these psychopathologies. This review emphasizes the\npower of artificial neural networks for modeling some symptoms of neurological\ndisorders but also calls for further developing these techniques in the field\nof computational psychiatry.\n", "versions": [{"version": "v1", "created": "Mon, 24 Jun 2019 15:10:44 GMT"}, {"version": "v2", "created": "Wed, 23 Oct 2019 09:25:59 GMT"}], "update_date": "2019-11-22", "authors_parsed": [["Lanillos", "Pablo", ""], ["Oliva", "Daniel", ""], ["Philippsen", "Anja", ""], ["Yamashita", "Yuichi", ""], ["Nagai", "Yukie", ""], ["Cheng", "Gordon", ""]]}, {"id": "1906.10025", "submitter": "Sergey Ivanov", "authors": "Sergey Ivanov, Alexander D'yakonov", "title": "Modern Deep Reinforcement Learning Algorithms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Recent advances in Reinforcement Learning, grounded on combining classical\ntheoretical results with Deep Learning paradigm, led to breakthroughs in many\nartificial intelligence tasks and gave birth to Deep Reinforcement Learning\n(DRL) as a field of research. In this work latest DRL algorithms are reviewed\nwith a focus on their theoretical justification, practical limitations and\nobserved empirical properties.\n", "versions": [{"version": "v1", "created": "Mon, 24 Jun 2019 15:27:51 GMT"}, {"version": "v2", "created": "Sat, 6 Jul 2019 18:30:45 GMT"}], "update_date": "2019-07-09", "authors_parsed": [["Ivanov", "Sergey", ""], ["D'yakonov", "Alexander", ""]]}, {"id": "1906.10064", "submitter": "Yuchen Li", "authors": "Yuchen Li, Frank Rudzicz, Jekaterina Novikova", "title": "Variations on the Chebyshev-Lagrange Activation Function", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We seek to improve the data efficiency of neural networks and present novel\nimplementations of parameterized piece-wise polynomial activation functions.\nThe parameters are the y-coordinates of n+1 Chebyshev nodes per hidden unit and\nLagrangian interpolation between the nodes produces the polynomial on [-1, 1].\nWe show results for different methods of handling inputs outside [-1, 1] on\nsynthetic datasets, finding significant improvements in capacity of expression\nand accuracy of interpolation in models that compute some form of linear\nextrapolation from either ends. We demonstrate competitive or state-of-the-art\nperformance on the classification of images (MNIST and CIFAR-10) and\nminimally-correlated vectors (DementiaBank) when we replace ReLU or tanh with\nlinearly extrapolated Chebyshev-Lagrange activations in deep residual\narchitectures.\n", "versions": [{"version": "v1", "created": "Mon, 24 Jun 2019 16:38:22 GMT"}], "update_date": "2019-06-25", "authors_parsed": [["Li", "Yuchen", ""], ["Rudzicz", "Frank", ""], ["Novikova", "Jekaterina", ""]]}, {"id": "1906.10101", "submitter": "Dong Wang", "authors": "Dong Wang, Yitong Li, Wei Cao, Liqun Chen, Qi Wei, Lawrence Carin", "title": "LMVP: Video Predictor with Leaked Motion Information", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a Leaked Motion Video Predictor (LMVP) to predict future frames by\ncapturing the spatial and temporal dependencies from given inputs. The motion\nis modeled by a newly proposed component, motion guider, which plays the role\nof both learner and teacher. Specifically, it {\\em learns} the temporal\nfeatures from real data and {\\em guides} the generator to predict future\nframes. The spatial consistency in video is modeled by an adaptive filtering\nnetwork. To further ensure the spatio-temporal consistency of the prediction, a\ndiscriminator is also adopted to distinguish the real and generated frames.\nFurther, the discriminator leaks information to the motion guider and the\ngenerator to help the learning of motion. The proposed LMVP can effectively\nlearn the static and temporal features in videos without the need for human\nlabeling. Experiments on synthetic and real data demonstrate that LMVP can\nyield state-of-the-art results.\n", "versions": [{"version": "v1", "created": "Mon, 24 Jun 2019 17:36:27 GMT"}], "update_date": "2019-06-25", "authors_parsed": [["Wang", "Dong", ""], ["Li", "Yitong", ""], ["Cao", "Wei", ""], ["Chen", "Liqun", ""], ["Wei", "Qi", ""], ["Carin", "Lawrence", ""]]}, {"id": "1906.10106", "submitter": "Brendan Juba", "authors": "Vaishak Belle and Brendan Juba", "title": "Implicitly Learning to Reason in First-Order Logic", "comments": "In Fourth International Workshop on Declarative Learning Based\n  Programming (DeLBP 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of answering queries about formulas of first-order\nlogic based on background knowledge partially represented explicitly as other\nformulas, and partially represented as examples independently drawn from a\nfixed probability distribution. PAC semantics, introduced by Valiant, is one\nrigorous, general proposal for learning to reason in formal languages: although\nweaker than classical entailment, it allows for a powerful model theoretic\nframework for answering queries while requiring minimal assumptions about the\nform of the distribution in question. To date, however, the most significant\nlimitation of that approach, and more generally most machine learning\napproaches with robustness guarantees, is that the logical language is\nultimately essentially propositional, with finitely many atoms. Indeed, the\ntheoretical findings on the learning of relational theories in such generality\nhave been resoundingly negative. This is despite the fact that first-order\nlogic is widely argued to be most appropriate for representing human knowledge.\nIn this work, we present a new theoretical approach to robustly learning to\nreason in first-order logic, and consider universally quantified clauses over a\ncountably infinite domain. Our results exploit symmetries exhibited by\nconstants in the language, and generalize the notion of implicit learnability\nto show how queries can be computed against (implicitly) learned first-order\nbackground knowledge.\n", "versions": [{"version": "v1", "created": "Mon, 24 Jun 2019 17:48:27 GMT"}], "update_date": "2019-06-25", "authors_parsed": [["Belle", "Vaishak", ""], ["Juba", "Brendan", ""]]}, {"id": "1906.10118", "submitter": "Brendan Juba", "authors": "Brendan Juba", "title": "Query-driven PAC-Learning for Reasoning", "comments": "In Fourth International Workshop on Declarative Learning Based\n  Programming (DeLBP 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of learning rules from a data set that support a\nproof of a given query, under Valiant's PAC-Semantics. We show how any backward\nproof search algorithm that is sufficiently oblivious to the contents of its\nknowledge base can be modified to learn such rules while it searches for a\nproof using those rules. We note that this gives such algorithms for standard\nlogics such as chaining and resolution.\n", "versions": [{"version": "v1", "created": "Mon, 24 Jun 2019 17:59:19 GMT"}], "update_date": "2019-06-25", "authors_parsed": [["Juba", "Brendan", ""]]}, {"id": "1906.10120", "submitter": "Humberto Jos\\'e Longo", "authors": "Carlos Alexandre X. Silva and Les Foulds and Humberto J. Longo", "title": "Assembly line balancing with task division", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In a commonly-used version of the Simple Assembly Line Balancing Problem\n(SALBP-1) tasks are assigned to stations along an assembly line with a fixed\ncycle time in order to minimize the required number of stations. It has\ntraditionally been assumed that the total work needed for each product unit has\nbeen partitioned into economically indivisible tasks. However, in practice, it\nis sometimes possible to divide particular tasks in limited ways at additional\ntime penalty cost. Despite the penalties, task division where possible, now and\nthen leads to a reduction in the minimum number of stations. Deciding which\nallowable tasks to divide creates a new assembly line balancing problem, TDALBP\n(Task Division Assembly Line Balancing Problem). We propose a mathematical\nmodel of the TDALBP, an exact solution procedure for it and present promising\ncomputational results for the adaptation of some classical SALBP instances from\nthe research literature. The results demonstrate that the TDALBP sometimes has\nthe potential to significantly improve assembly line performance.\n", "versions": [{"version": "v1", "created": "Sat, 22 Jun 2019 14:02:05 GMT"}], "update_date": "2019-06-26", "authors_parsed": [["Silva", "Carlos Alexandre X.", ""], ["Foulds", "Les", ""], ["Longo", "Humberto J.", ""]]}, {"id": "1906.10124", "submitter": "Ahmad Beirami", "authors": "Yunqi Zhao and Igor Borovikov and Jason Rupert and Caedmon Somers and\n  Ahmad Beirami", "title": "On Multi-Agent Learning in Team Sports Games", "comments": "Presented at ICML 2019 Workshop on Imitation, Intent, and Interaction\n  (I3). arXiv admin note: substantial text overlap with arXiv:1903.10545", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, reinforcement learning has been successful in solving video\ngames from Atari to Star Craft II. However, the end-to-end model-free\nreinforcement learning (RL) is not sample efficient and requires a significant\namount of computational resources to achieve superhuman level performance.\nModel-free RL is also unlikely to produce human-like agents for playtesting and\ngameplaying AI in the development cycle of complex video games. In this paper,\nwe present a hierarchical approach to training agents with the goal of\nachieving human-like style and high skill level in team sports games. While\nthis is still work in progress, our preliminary results show that the presented\napproach holds promise for solving the posed multi-agent learning problem.\n", "versions": [{"version": "v1", "created": "Tue, 25 Jun 2019 15:18:10 GMT"}], "update_date": "2019-06-26", "authors_parsed": [["Zhao", "Yunqi", ""], ["Borovikov", "Igor", ""], ["Rupert", "Jason", ""], ["Somers", "Caedmon", ""], ["Beirami", "Ahmad", ""]]}, {"id": "1906.10165", "submitter": "Mark Woodward", "authors": "Mark Woodward and Chelsea Finn and Karol Hausman", "title": "Training an Interactive Helper", "comments": "The paper \"Learning to Interactively Learn and Assist\" (LILA), at\n  arXiv:1906.10187, supersedes this paper. This preliminary workshop paper\n  appeared in the Emergent Communication Workshop and Workshop on Learning by\n  Instruction at NeurIPS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Developing agents that can quickly adapt their behavior to new tasks remains\na challenge. Meta-learning has been applied to this problem, but previous\nmethods require either specifying a reward function which can be tedious or\nproviding demonstrations which can be inefficient. In this paper, we\ninvestigate if, and how, a \"helper\" agent can be trained to interactively adapt\ntheir behavior to maximize the reward of another agent, whom we call the\n\"prime\" agent, without observing their reward or receiving explicit\ndemonstrations. To this end, we propose to meta-learn a helper agent along with\na prime agent, who, during training, observes the reward function and serves as\na surrogate for a human prime. We introduce a distribution of multi-agent\ncooperative foraging tasks, in which only the prime agent knows the objects\nthat should be collected. We demonstrate that, from the emerged physical\ncommunication, the trained helper rapidly infers and collects the correct\nobjects.\n", "versions": [{"version": "v1", "created": "Mon, 24 Jun 2019 18:37:33 GMT"}, {"version": "v2", "created": "Tue, 2 Jul 2019 02:49:14 GMT"}], "update_date": "2019-07-03", "authors_parsed": [["Woodward", "Mark", ""], ["Finn", "Chelsea", ""], ["Hausman", "Karol", ""]]}, {"id": "1906.10177", "submitter": "Andrew Knight", "authors": "Andrew Knight", "title": "Refuting Strong AI: Why Consciousness Cannot Be Algorithmic", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.hist-ph cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While physicalism requires only that a conscious state depends entirely on an\nunderlying physical state, it is often assumed that consciousness is\nalgorithmic and that conscious states can be copied, such as by copying or\ndigitizing the human brain. In an effort to further elucidate the physical\nnature of consciousness, I challenge these assumptions and attempt to prove the\nSingle Stream of Consciousness Theorem (SSCT): that a conscious entity cannot\nexperience more than one stream of consciousness from a given conscious state.\nAssuming only that consciousness is a purely physical phenomenon, it is shown\nthat both Special Relativity and Multiverse theory independently imply SSCT and\nthat the Many Worlds Interpretation of quantum mechanics is inadequate to\ncounter it. Then, SSCT is shown to be incompatible with Strong Artificial\nIntelligence, implying that consciousness cannot be created or simulated by a\ncomputer. Finally, SSCT is shown to imply that a conscious state cannot be\nphysically reset to an earlier conscious state nor can it be duplicated by any\nphysical means. The profound but counterintuitive implications of these\nconclusions are briefly discussed.\n", "versions": [{"version": "v1", "created": "Tue, 11 Jun 2019 16:16:25 GMT"}], "update_date": "2019-06-26", "authors_parsed": [["Knight", "Andrew", ""]]}, {"id": "1906.10187", "submitter": "Mark Woodward", "authors": "Mark Woodward and Chelsea Finn and Karol Hausman", "title": "Learning to Interactively Learn and Assist", "comments": "AAAI 2020. Video overview at https://youtu.be/8yBvDBuAPrw, paper\n  website with videos and interactive game at\n  http://interactive-learning.github.io/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When deploying autonomous agents in the real world, we need effective ways of\ncommunicating objectives to them. Traditional skill learning has revolved\naround reinforcement and imitation learning, each with rigid constraints on the\nformat of information exchanged between the human and the agent. While scalar\nrewards carry little information, demonstrations require significant effort to\nprovide and may carry more information than is necessary. Furthermore, rewards\nand demonstrations are often defined and collected before training begins, when\nthe human is most uncertain about what information would help the agent. In\ncontrast, when humans communicate objectives with each other, they make use of\na large vocabulary of informative behaviors, including non-verbal\ncommunication, and often communicate throughout learning, responding to\nobserved behavior. In this way, humans communicate intent with minimal effort.\nIn this paper, we propose such interactive learning as an alternative to reward\nor demonstration-driven learning. To accomplish this, we introduce a\nmulti-agent training framework that enables an agent to learn from another\nagent who knows the current task. Through a series of experiments, we\ndemonstrate the emergence of a variety of interactive learning behaviors,\nincluding information-sharing, information-seeking, and question-answering.\nMost importantly, we find that our approach produces an agent that is capable\nof learning interactively from a human user, without a set of explicit\ndemonstrations or a reward function, and achieving significantly better\nperformance cooperatively with a human than a human performing the task alone.\n", "versions": [{"version": "v1", "created": "Mon, 24 Jun 2019 19:23:27 GMT"}, {"version": "v2", "created": "Mon, 1 Jul 2019 23:07:37 GMT"}, {"version": "v3", "created": "Tue, 19 Nov 2019 21:04:13 GMT"}], "update_date": "2019-11-21", "authors_parsed": [["Woodward", "Mark", ""], ["Finn", "Chelsea", ""], ["Hausman", "Karol", ""]]}, {"id": "1906.10189", "submitter": "Joel Lehman", "authors": "Joel Lehman", "title": "Evolutionary Computation and AI Safety: Research Problems Impeding\n  Routine and Safe Real-world Application of Evolution", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent developments in artificial intelligence and machine learning have\nspurred interest in the growing field of AI safety, which studies how to\nprevent human-harming accidents when deploying AI systems. This paper thus\nexplores the intersection of AI safety with evolutionary computation, to show\nhow safety issues arise in evolutionary computation and how understanding from\nevolutionary computational and biological evolution can inform the broader\nstudy of AI safety.\n", "versions": [{"version": "v1", "created": "Mon, 24 Jun 2019 19:26:10 GMT"}, {"version": "v2", "created": "Fri, 4 Oct 2019 17:49:07 GMT"}], "update_date": "2019-10-07", "authors_parsed": [["Lehman", "Joel", ""]]}, {"id": "1906.10228", "submitter": "Jad Rahme", "authors": "Jad Rahme and Ryan P. Adams", "title": "A Theoretical Connection Between Statistical Physics and Reinforcement\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cond-mat.stat-mech cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sequential decision making in the presence of uncertainty and stochastic\ndynamics gives rise to distributions over state/action trajectories in\nreinforcement learning (RL) and optimal control problems. This observation has\nled to a variety of connections between RL and inference in probabilistic\ngraphical models (PGMs). Here we explore a different dimension to this\nrelationship, examining reinforcement learning using the tools and abstractions\nof statistical physics. The central object in the statistical physics\nabstraction is the idea of a partition function $\\mathcal{Z}$, and here we\nconstruct a partition function from the ensemble of possible trajectories that\nan agent might take in a Markov decision process. Although value functions and\n$Q$-functions can be derived from this partition function and interpreted via\naverage energies, the $\\mathcal{Z}$-function provides an object with its own\nBellman equation that can form the basis of alternative dynamic programming\napproaches. Moreover, when the MDP dynamics are deterministic, the Bellman\nequation for $\\mathcal{Z}$ is linear, allowing direct solutions that are\nunavailable for the nonlinear equations associated with traditional value\nfunctions. The policies learned via these $\\mathcal{Z}$-based Bellman updates\nare tightly linked to Boltzmann-like policy parameterizations. In addition to\nsampling actions proportionally to the exponential of the expected cumulative\nreward as Boltzmann policies would, these policies take entropy into account\nfavoring states from which many outcomes are possible.\n", "versions": [{"version": "v1", "created": "Mon, 24 Jun 2019 20:47:42 GMT"}], "update_date": "2019-06-26", "authors_parsed": [["Rahme", "Jad", ""], ["Adams", "Ryan P.", ""]]}, {"id": "1906.10250", "submitter": "Nicolas Maudet", "authors": "Aur\\'elie Beynier, Nicolas Maudet, Simon Rey, and Parham Shams", "title": "Swap Dynamics in Single-Peaked Housing Markets", "comments": "Replaces our previous submission: \"House Markets and Single-Peaked\n  Preferences: From Centralized to Decentralized Allocation Procedures\".\n  Following reviewers' comments, leaves out our contribution on a variant of\n  the Crawler procedure (goes in a separate submission) to concentrate on swap\n  dynamics (new results added)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper focuses on the problem of fairly and efficiently allocating\nresources to agents. We consider a specific setting, usually referred to as a\nhousing market, where each agent must receive exactly one resource (and\ninitially owns one). In this framework, in the domain of linear preferences,\nthe Top Trading Cycle (TTC) algorithm is the only procedure satisfying\nPareto-optimality, individual rationality and strategy-proofness. Under the\nrestriction of single-peaked preferences, Crawler enjoys the same properties.\nThese two centralized procedures might however involve long trading cycles. In\nthis paper we focus instead on procedures involving the shortest cycles:\nbilateral swap-deals. In such swap dynamics, the agents perform pairwise\nmutually improving deals until reaching a swap-stable allocation (no improving\nswap-deal is possible). We prove that in the single-peaked domain every\nswap-stable allocation is Pareto-optimal, showing the efficiency of the swap\ndynamics. In fact, this domain turns out to be maximal when it comes to\nguaranteeing this property. Besides, both the outcome of TTC and Crawler can\nalways be reached by sequences of swaps. However, some Pareto-optimal\nallocations are not reachable through improving swap-deals. We further analyze\nthe outcome of swap dynamics through social welfare notions, in our context the\naverage or minimum rank of the resources obtained by agents in the final\nallocation. We start by providing a worst-case analysis of these procedures.\nFinally, we present an extensive experimental study in which different versions\nof swap dynamics are compared to other existing allocation procedures. We show\nthat they exhibit good results on average in this domain, under different\ncultures for generating synthetic data.\n", "versions": [{"version": "v1", "created": "Mon, 24 Jun 2019 22:12:01 GMT"}, {"version": "v2", "created": "Thu, 13 Feb 2020 12:38:34 GMT"}, {"version": "v3", "created": "Mon, 19 Apr 2021 13:55:21 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Beynier", "Aur\u00e9lie", ""], ["Maudet", "Nicolas", ""], ["Rey", "Simon", ""], ["Shams", "Parham", ""]]}, {"id": "1906.10263", "submitter": "Muhammad Rehman Zafar", "authors": "Muhammad Rehman Zafar, Naimul Mefraz Khan", "title": "DLIME: A Deterministic Local Interpretable Model-Agnostic Explanations\n  Approach for Computer-Aided Diagnosis Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Local Interpretable Model-Agnostic Explanations (LIME) is a popular technique\nused to increase the interpretability and explainability of black box Machine\nLearning (ML) algorithms. LIME typically generates an explanation for a single\nprediction by any ML model by learning a simpler interpretable model (e.g.\nlinear classifier) around the prediction through generating simulated data\naround the instance by random perturbation, and obtaining feature importance\nthrough applying some form of feature selection. While LIME and similar local\nalgorithms have gained popularity due to their simplicity, the random\nperturbation and feature selection methods result in \"instability\" in the\ngenerated explanations, where for the same prediction, different explanations\ncan be generated. This is a critical issue that can prevent deployment of LIME\nin a Computer-Aided Diagnosis (CAD) system, where stability is of utmost\nimportance to earn the trust of medical professionals. In this paper, we\npropose a deterministic version of LIME. Instead of random perturbation, we\nutilize agglomerative Hierarchical Clustering (HC) to group the training data\ntogether and K-Nearest Neighbour (KNN) to select the relevant cluster of the\nnew instance that is being explained. After finding the relevant cluster, a\nlinear model is trained over the selected cluster to generate the explanations.\nExperimental results on three different medical datasets show the superiority\nfor Deterministic Local Interpretable Model-Agnostic Explanations (DLIME),\nwhere we quantitatively determine the stability of DLIME compared to LIME\nutilizing the Jaccard similarity among multiple generated explanations.\n", "versions": [{"version": "v1", "created": "Mon, 24 Jun 2019 23:08:03 GMT"}], "update_date": "2019-06-26", "authors_parsed": [["Zafar", "Muhammad Rehman", ""], ["Khan", "Naimul Mefraz", ""]]}, {"id": "1906.10395", "submitter": "Teodora Baluta", "authors": "Teodora Baluta and Shiqi Shen and Shweta Shinde and Kuldeep S. Meel\n  and Prateek Saxena", "title": "Quantitative Verification of Neural Networks And its Security\n  Applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.LG cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks are increasingly employed in safety-critical domains. This\nhas prompted interest in verifying or certifying logically encoded properties\nof neural networks. Prior work has largely focused on checking existential\nproperties, wherein the goal is to check whether there exists any input that\nviolates a given property of interest. However, neural network training is a\nstochastic process, and many questions arising in their analysis require\nprobabilistic and quantitative reasoning, i.e., estimating how many inputs\nsatisfy a given property. To this end, our paper proposes a novel and\nprincipled framework to quantitative verification of logical properties\nspecified over neural networks. Our framework is the first to provide PAC-style\nsoundness guarantees, in that its quantitative estimates are within a\ncontrollable and bounded error from the true count. We instantiate our\nalgorithmic framework by building a prototype tool called NPAQ that enables\nchecking rich properties over binarized neural networks. We show how emerging\nsecurity analyses can utilize our framework in 3 concrete point applications:\nquantifying robustness to adversarial inputs, efficacy of trojan attacks, and\nfairness/bias of given neural networks.\n", "versions": [{"version": "v1", "created": "Tue, 25 Jun 2019 09:08:03 GMT"}], "update_date": "2019-06-26", "authors_parsed": [["Baluta", "Teodora", ""], ["Shen", "Shiqi", ""], ["Shinde", "Shweta", ""], ["Meel", "Kuldeep S.", ""], ["Saxena", "Prateek", ""]]}, {"id": "1906.10450", "submitter": "Anat Goldstein", "authors": "Anat Goldstein, Lior Fink and Gilad Ravid", "title": "A Framework for Evaluating Agricultural Ontologies", "comments": "18 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An ontology is a formal representation of domain knowledge, which can be\ninterpreted by machines. In recent years, ontologies have become a major tool\nfor domain knowledge representation and a core component of many knowledge\nmanagement systems, decision support systems and other intelligent systems,\ninter alia, in the context of agriculture. A review of the existing literature\non agricultural ontologies, however, reveals that most of the studies, which\npropose agricultural ontologies, are lacking an explicit evaluation procedure.\nThis is undesired because without well-structured evaluation processes, it is\ndifficult to consider the value of ontologies to research and practice.\nMoreover, it is difficult to rely on such ontologies and share them on the\nSemantic Web or between semantic aware applications. With the growing number of\nontology-based agricultural systems and the increasing popularity of the\nSemantic Web, it becomes essential that such development and evaluation methods\nare put forward to guide future efforts of ontology development. Our work\ncontributes to the literature on agricultural ontologies, by presenting a\nmethod for evaluating agricultural ontologies, which seems to be missing from\nmost existing studies on agricultural ontologies. The framework supports the\nmatching of appropriate evaluation methods for a given ontology based on the\nontology's purpose.\n", "versions": [{"version": "v1", "created": "Tue, 25 Jun 2019 10:59:38 GMT"}, {"version": "v2", "created": "Wed, 26 Jun 2019 02:48:20 GMT"}], "update_date": "2019-06-27", "authors_parsed": [["Goldstein", "Anat", ""], ["Fink", "Lior", ""], ["Ravid", "Gilad", ""]]}, {"id": "1906.10528", "submitter": "Shixian Wen", "authors": "Shixian Wen and Laurent Itti", "title": "Beneficial perturbation network for continual learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sequential learning of multiple tasks in artificial neural networks using\ngradient descent leads to catastrophic forgetting, whereby previously learned\nknowledge is erased during learning of new, disjoint knowledge. Here, we\npropose a fundamentally new type of method - Beneficial Perturbation Network\n(BPN). We add task-dependent memory (biasing) units to allow the network to\noperate in different regimes for different tasks. We compute the most\nbeneficial directions to train these units, in a manner inspired by recent work\non adversarial examples. At test time, beneficial perturbations for a given\ntask bias the network toward that task to overcome catastrophic forgetting. BPN\nis not only more parameter-efficient than network expansion methods, but also\ndoes not need to store any data from previous tasks, in contrast with episodic\nmemory methods. Experiments on variants of the MNIST, CIFAR-10, CIFAR-100\ndatasets demonstrate strong performance of BPN when compared to the\nstate-of-the-art.\n", "versions": [{"version": "v1", "created": "Sat, 22 Jun 2019 04:46:19 GMT"}], "update_date": "2019-06-26", "authors_parsed": [["Wen", "Shixian", ""], ["Itti", "Laurent", ""]]}, {"id": "1906.10536", "submitter": "Roman Yampolskiy", "authors": "James D. Miller and Roman Yampolskiy", "title": "An AGI with Time-Inconsistent Preferences", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper reveals a trap for artificial general intelligence (AGI) theorists\nwho use economists' standard method of discounting. This trap is implicitly and\nfalsely assuming that a rational AGI would have time-consistent preferences. An\nagent with time-inconsistent preferences knows that its future self will\ndisagree with its current self concerning intertemporal decision making. Such\nan agent cannot automatically trust its future self to carry out plans that its\ncurrent self considers optimal.\n", "versions": [{"version": "v1", "created": "Sun, 23 Jun 2019 21:22:19 GMT"}], "update_date": "2019-06-26", "authors_parsed": [["Miller", "James D.", ""], ["Yampolskiy", "Roman", ""]]}, {"id": "1906.10545", "submitter": "Xiao Dong", "authors": "X. Dong and L. Zhou", "title": "Gauge theory and twins paradox of disentangled representations", "comments": "5 pages, 2 figures, draft version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Achieving disentangled representations of information is one of the key goals\nof deep network based machine learning system. Recently there are more\ndiscussions on this issue. In this paper, by comparing the geometric structure\nof disentangled representation and the geometry of the evolution of mixed\nstates in quantum mechanics, we give a fibre bundle based geometric picture of\ndisentangled representation which can be regarded as a kind of gauge theory.\nFrom this perspective we can build a connection between the disentangled\nrepresentations and the twins paradox in relativity. This can help to clarify\nsome problems about disentangled representation.\n", "versions": [{"version": "v1", "created": "Mon, 24 Jun 2019 12:25:56 GMT"}], "update_date": "2019-06-26", "authors_parsed": [["Dong", "X.", ""], ["Zhou", "L.", ""]]}, {"id": "1906.10562", "submitter": "Wennan Zhu", "authors": "Ben Abramowitz, Elliot Anshelevich, Wennan Zhu", "title": "Awareness of Voter Passion Greatly Improves the Distortion of Metric\n  Social Choice", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop new voting mechanisms for the case when voters and candidates are\nlocated in an arbitrary unknown metric space, and the goal is to choose a\ncandidate minimizing social cost: the total distance from the voters to this\ncandidate. Previous work has often assumed that only ordinal preferences of the\nvoters are known (instead of their true costs), and focused on minimizing\ndistortion: the quality of the chosen candidate as compared with the best\npossible candidate. In this paper, we instead assume that a (very small) amount\nof information is known about the voter preference strengths, not just about\ntheir ordinal preferences. We provide mechanisms with much better distortion\nwhen this extra information is known as compared to mechanisms which use only\nordinal information. We quantify tradeoffs between the amount of information\nknown about preference strengths and the achievable distortion. We further\nprovide advice about which type of information about preference strengths seems\nto be the most useful. Finally, we conclude by quantifying the ideal candidate\ndistortion, which compares the quality of the chosen outcome with the best\npossible candidate that could ever exist, instead of only the best candidate\nthat is actually in the running.\n", "versions": [{"version": "v1", "created": "Tue, 25 Jun 2019 14:25:12 GMT"}], "update_date": "2019-06-26", "authors_parsed": [["Abramowitz", "Ben", ""], ["Anshelevich", "Elliot", ""], ["Zhu", "Wennan", ""]]}, {"id": "1906.10571", "submitter": "Yunhan Huang", "authors": "Yunhan Huang and Quanyan Zhu", "title": "Deceptive Reinforcement Learning Under Adversarial Manipulations on Cost\n  Signals", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies reinforcement learning (RL) under malicious falsification\non cost signals and introduces a quantitative framework of attack models to\nunderstand the vulnerabilities of RL. Focusing on $Q$-learning, we show that\n$Q$-learning algorithms converge under stealthy attacks and bounded\nfalsifications on cost signals. We characterize the relation between the\nfalsified cost and the $Q$-factors as well as the policy learned by the\nlearning agent which provides fundamental limits for feasible offensive and\ndefensive moves. We propose a robust region in terms of the cost within which\nthe adversary can never achieve the targeted policy. We provide conditions on\nthe falsified cost which can mislead the agent to learn an adversary's favored\npolicy. A numerical case study of water reservoir control is provided to show\nthe potential hazards of RL in learning-based control systems and corroborate\nthe results.\n", "versions": [{"version": "v1", "created": "Mon, 24 Jun 2019 15:48:54 GMT"}, {"version": "v2", "created": "Tue, 13 Aug 2019 14:55:39 GMT"}, {"version": "v3", "created": "Fri, 16 Aug 2019 18:32:49 GMT"}], "update_date": "2019-08-20", "authors_parsed": [["Huang", "Yunhan", ""], ["Zhu", "Quanyan", ""]]}, {"id": "1906.10667", "submitter": "Shagun Sodhani", "authors": "Anirudh Goyal, Shagun Sodhani, Jonathan Binas, Xue Bin Peng, Sergey\n  Levine, Yoshua Bengio", "title": "Reinforcement Learning with Competitive Ensembles of\n  Information-Constrained Primitives", "comments": "Preprint, Under Review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning agents that operate in diverse and complex\nenvironments can benefit from the structured decomposition of their behavior.\nOften, this is addressed in the context of hierarchical reinforcement learning,\nwhere the aim is to decompose a policy into lower-level primitives or options,\nand a higher-level meta-policy that triggers the appropriate behaviors for a\ngiven situation. However, the meta-policy must still produce appropriate\ndecisions in all states. In this work, we propose a policy design that\ndecomposes into primitives, similarly to hierarchical reinforcement learning,\nbut without a high-level meta-policy. Instead, each primitive can decide for\nthemselves whether they wish to act in the current state. We use an\ninformation-theoretic mechanism for enabling this decentralized decision: each\nprimitive chooses how much information it needs about the current state to make\na decision and the primitive that requests the most information about the\ncurrent state acts in the world. The primitives are regularized to use as\nlittle information as possible, which leads to natural competition and\nspecialization. We experimentally demonstrate that this policy architecture\nimproves over both flat and hierarchical policies in terms of generalization.\n", "versions": [{"version": "v1", "created": "Tue, 25 Jun 2019 17:04:48 GMT"}], "update_date": "2019-06-26", "authors_parsed": [["Goyal", "Anirudh", ""], ["Sodhani", "Shagun", ""], ["Binas", "Jonathan", ""], ["Peng", "Xue Bin", ""], ["Levine", "Sergey", ""], ["Bengio", "Yoshua", ""]]}, {"id": "1906.10689", "submitter": "Jamal Toutouh", "authors": "Jamal Toutouh, Diego Rossit, and Sergio Nesmachnow", "title": "Soft computing methods for multiobjective location of garbage\n  accumulation points in smart cities", "comments": null, "journal-ref": "Annals of Mathematics and Artificial Intelligence, 2019", "doi": "10.1007/s10472-019-09647-5", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article describes the application of soft computing methods for solving\nthe problem of locating garbage accumulation points in urban scenarios. This is\na relevant problem in modern smart cities, in order to reduce negative\nenvironmental and social impacts in the waste management process, and also to\noptimize the available budget from the city administration to install waste\nbins. A specific problem model is presented, which accounts for reducing the\ninvestment costs, enhance the number of citizens served by the installed bins,\nand the accessibility to the system. A family of single- and multi-objective\nheuristics based on the PageRank method and two mutiobjective evolutionary\nalgorithms are proposed. Experimental evaluation performed on real scenarios on\nthe cities of Montevideo (Uruguay) and Bahia Blanca (Argentina) demonstrates\nthe effectiveness of the proposed approaches. The methods allow computing\nplannings with different trade-off between the problem objectives. The computed\nresults improve over the current planning in Montevideo and provide a\nreasonable budget cost and quality of service for Bahia Blanca.\n", "versions": [{"version": "v1", "created": "Tue, 25 Jun 2019 16:21:16 GMT"}], "update_date": "2019-06-27", "authors_parsed": [["Toutouh", "Jamal", ""], ["Rossit", "Diego", ""], ["Nesmachnow", "Sergio", ""]]}, {"id": "1906.10740", "submitter": "Dimiter Dobrev", "authors": "Dimiter Dobrev", "title": "Event-Driven Models", "comments": null, "journal-ref": "International Journal \"Information Models and Analyses\", Volume 8,\n  Number 1, 2019, pp. 23-58", "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In Reinforcement Learning we look for meaning in the flow of input/output\ninformation. If we do not find meaning, the information flow is not more than\nnoise to us. Before we are able to find meaning, we should first learn how to\ndiscover and identify objects. What is an object? In this article we will\ndemonstrate that an object is an event-driven model. These models are a\ngeneralization of action-driven models. In Markov Decision Process we have an\naction-driven model which changes its state at each step. The advantage of\nevent-driven models is their greater sustainability as they change their states\nonly upon the occurrence of particular events. These events may occur very\nrarely, therefore the state of the event-driven model is much more predictable.\n", "versions": [{"version": "v1", "created": "Mon, 24 Jun 2019 09:59:40 GMT"}], "update_date": "2019-06-27", "authors_parsed": [["Dobrev", "Dimiter", ""]]}, {"id": "1906.10742", "submitter": "Jie Zhang", "authors": "Jie M. Zhang (1), Mark Harman (1 and 2), Lei Ma (3), Yang Liu (4) ((1)\n  University College London, (2) Facebook London, (3) Kyushu University, (4)\n  Nanyang Technological University)", "title": "Machine Learning Testing: Survey, Landscapes and Horizons", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.SE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper provides a comprehensive survey of Machine Learning Testing (ML\ntesting) research. It covers 144 papers on testing properties (e.g.,\ncorrectness, robustness, and fairness), testing components (e.g., the data,\nlearning program, and framework), testing workflow (e.g., test generation and\ntest evaluation), and application scenarios (e.g., autonomous driving, machine\ntranslation). The paper also analyses trends concerning datasets, research\ntrends, and research focus, concluding with research challenges and promising\nresearch directions in ML testing.\n", "versions": [{"version": "v1", "created": "Wed, 19 Jun 2019 22:39:19 GMT"}, {"version": "v2", "created": "Sat, 21 Dec 2019 23:12:23 GMT"}], "update_date": "2019-12-24", "authors_parsed": [["Zhang", "Jie M.", "", "1 and 2"], ["Harman", "Mark", "", "1 and 2"], ["Ma", "Lei", ""], ["Liu", "Yang", ""]]}, {"id": "1906.10816", "submitter": "Oleksandr Polozov", "authors": "Richard Shin, Miltiadis Allamanis, Marc Brockschmidt, Oleksandr\n  Polozov", "title": "Program Synthesis and Semantic Parsing with Learned Code Idioms", "comments": "33rd Conference on Neural Information Processing Systems (NeurIPS)\n  2019. 13 pages total, 9 pages of main text", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL cs.PL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Program synthesis of general-purpose source code from natural language\nspecifications is challenging due to the need to reason about high-level\npatterns in the target program and low-level implementation details at the same\ntime. In this work, we present PATOIS, a system that allows a neural program\nsynthesizer to explicitly interleave high-level and low-level reasoning at\nevery generation step. It accomplishes this by automatically mining common code\nidioms from a given corpus, incorporating them into the underlying language for\nneural synthesis, and training a tree-based neural synthesizer to use these\nidioms during code generation. We evaluate PATOIS on two complex semantic\nparsing datasets and show that using learned code idioms improves the\nsynthesizer's accuracy.\n", "versions": [{"version": "v1", "created": "Wed, 26 Jun 2019 02:28:10 GMT"}, {"version": "v2", "created": "Tue, 23 Jul 2019 21:58:59 GMT"}, {"version": "v3", "created": "Thu, 5 Sep 2019 01:28:05 GMT"}, {"version": "v4", "created": "Tue, 5 Nov 2019 02:44:38 GMT"}], "update_date": "2019-11-06", "authors_parsed": [["Shin", "Richard", ""], ["Allamanis", "Miltiadis", ""], ["Brockschmidt", "Marc", ""], ["Polozov", "Oleksandr", ""]]}, {"id": "1906.10918", "submitter": "Bart Bussmann", "authors": "Bart Bussmann, Jacqueline Heinerman, Joel Lehman", "title": "Towards Empathic Deep Q-Learning", "comments": "To be presented as a poster at the IJCAI-19 AI Safety Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As reinforcement learning (RL) scales to solve increasingly complex tasks,\ninterest continues to grow in the fields of AI safety and machine ethics. As a\ncontribution to these fields, this paper introduces an extension to Deep\nQ-Networks (DQNs), called Empathic DQN, that is loosely inspired both by\nempathy and the golden rule (\"Do unto others as you would have them do unto\nyou\"). Empathic DQN aims to help mitigate negative side effects to other agents\nresulting from myopic goal-directed behavior. We assume a setting where a\nlearning agent coexists with other independent agents (who receive unknown\nrewards), where some types of reward (e.g. negative rewards from physical harm)\nmay generalize across agents. Empathic DQN combines the typical (self-centered)\nvalue with the estimated value of other agents, by imagining (by its own\nstandards) the value of it being in the other's situation (by considering\nconstructed states where both agents are swapped). Proof-of-concept results in\ntwo gridworld environments highlight the approach's potential to decrease\ncollateral harms. While extending Empathic DQN to complex environments is\nnon-trivial, we believe that this first step highlights the potential of\nbridge-work between machine ethics and RL to contribute useful priors for\nnorm-abiding RL agents.\n", "versions": [{"version": "v1", "created": "Wed, 26 Jun 2019 08:59:02 GMT"}], "update_date": "2019-06-27", "authors_parsed": [["Bussmann", "Bart", ""], ["Heinerman", "Jacqueline", ""], ["Lehman", "Joel", ""]]}, {"id": "1906.10924", "submitter": "Benjamin Roth", "authors": "Alona Sydorova, Nina Poerner, Benjamin Roth", "title": "Interpretable Question Answering on Knowledge Bases and Text", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Interpretability of machine learning (ML) models becomes more relevant with\ntheir increasing adoption. In this work, we address the interpretability of ML\nbased question answering (QA) models on a combination of knowledge bases (KB)\nand text documents. We adapt post hoc explanation methods such as LIME and\ninput perturbation (IP) and compare them with the self-explanatory attention\nmechanism of the model. For this purpose, we propose an automatic evaluation\nparadigm for explanation methods in the context of QA. We also conduct a study\nwith human annotators to evaluate whether explanations help them identify\nbetter QA models. Our results suggest that IP provides better explanations than\nLIME or attention, according to both automatic and human evaluation. We obtain\nthe same ranking of methods in both experiments, which supports the validity of\nour automatic evaluation paradigm.\n", "versions": [{"version": "v1", "created": "Wed, 26 Jun 2019 09:10:33 GMT"}], "update_date": "2019-06-27", "authors_parsed": [["Sydorova", "Alona", ""], ["Poerner", "Nina", ""], ["Roth", "Benjamin", ""]]}, {"id": "1906.10991", "submitter": "Yaniv Saar", "authors": "Gil Einziger, Maayan Goldstein, Yaniv Sa'ar, Itai Segall", "title": "Verifying Robustness of Gradient Boosted Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gradient boosted models are a fundamental machine learning technique.\nRobustness to small perturbations of the input is an important quality measure\nfor machine learning models, but the literature lacks a method to prove the\nrobustness of gradient boosted models. This work introduces VeriGB, a tool for\nquantifying the robustness of gradient boosted models. VeriGB encodes the model\nand the robustness property as an SMT formula, which enables state of the art\nverification tools to prove the model's robustness. We extensively evaluate\nVeriGB on publicly available datasets and demonstrate a capability for\nverifying large models. Finally, we show that some model configurations tend to\nbe inherently more robust than others.\n", "versions": [{"version": "v1", "created": "Wed, 26 Jun 2019 11:48:58 GMT"}], "update_date": "2019-06-27", "authors_parsed": [["Einziger", "Gil", ""], ["Goldstein", "Maayan", ""], ["Sa'ar", "Yaniv", ""], ["Segall", "Itai", ""]]}, {"id": "1906.11021", "submitter": "Maxime Bouton", "authors": "Maxime Bouton, Alireza Nakhaei, Kikuo Fujimura, and Mykel J.\n  Kochenderfer", "title": "Cooperation-Aware Reinforcement Learning for Merging in Dense Traffic", "comments": "7 pages, 5 figures", "journal-ref": "IEEE Conference on Intelligent Transportation Systems (ITSC), 2019", "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Decision making in dense traffic can be challenging for autonomous vehicles.\nAn autonomous system only relying on predefined road priorities and considering\nother drivers as moving objects will cause the vehicle to freeze and fail the\nmaneuver. Human drivers leverage the cooperation of other drivers to avoid such\ndeadlock situations and convince others to change their behavior. Decision\nmaking algorithms must reason about the interaction with other drivers and\nanticipate a broad range of driver behaviors. In this work, we present a\nreinforcement learning approach to learn how to interact with drivers with\ndifferent cooperation levels. We enhanced the performance of traditional\nreinforcement learning algorithms by maintaining a belief over the level of\ncooperation of other drivers. We show that our agent successfully learns how to\nnavigate a dense merging scenario with less deadlocks than with online planning\nmethods.\n", "versions": [{"version": "v1", "created": "Wed, 26 Jun 2019 12:22:13 GMT"}], "update_date": "2019-06-27", "authors_parsed": [["Bouton", "Maxime", ""], ["Nakhaei", "Alireza", ""], ["Fujimura", "Kikuo", ""], ["Kochenderfer", "Mykel J.", ""]]}, {"id": "1906.11032", "submitter": "Aladdin Ayesh", "authors": "Aladdin Ayesh", "title": "Cognitive Systems Approach to Smart Cities", "comments": "Draft: work in progress", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In our connected world, services are expected to be delivered at speed\nthrough multiple means with seamless communication. To put it in day to day\nconversational terms, 'there is an app for it' attitude prevails. Several\ntechnologies are needed to meet this growing demand and indeed these\ntechnologies are being developed. The first noteworthy is Internet of Things\n(IoT), which is in itself coupled technologies to deliver seamless\ncommunication with 'anywhere, anytime' as an underlying objective. The\n'anywhere, anytime' service delivery paradigm requires a new type of smart\nsystems in developing these services with better capabilities to interact with\nthe human user, such as personalisation, affect state recognition, etc. Here\nenter cognitive systems, where AI meets cognitive sciences (e.g. cognitive\npsychology, linguistics, social cognition, etc.). In this paper we will examine\nthe requirements imposed by smart cities development, e.g. intelligent\nlogistics, sensor networks and domestic appliances connectivity, data streams\nand media delivery, to mention but few. Then we will explore how cognitive\nsystems can meet the challenges these requirements present to the development\nof new systems. Throughout our discussion here, examples from our recent and\ncurrent projects will be given supplemented by examples from the literature.\n", "versions": [{"version": "v1", "created": "Wed, 26 Jun 2019 12:36:43 GMT"}], "update_date": "2019-06-27", "authors_parsed": [["Ayesh", "Aladdin", ""]]}, {"id": "1906.11058", "submitter": "Long Yang", "authors": "Long Yang, Yu Zhang, Jun Wen, Qian Zheng, Pengfei Li, Gang Pan", "title": "Expected Sarsa($\\lambda$) with Control Variate for Variance Reduction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Off-policy learning is powerful for reinforcement learning. However, the high\nvariance of off-policy evaluation is a critical challenge, which causes\noff-policy learning falls into an uncontrolled instability. In this paper, for\nreducing the variance, we introduce control variate technique to\n$\\mathtt{Expected}$ $\\mathtt{Sarsa}$($\\lambda$) and propose a tabular\n$\\mathtt{ES}$($\\lambda$)-$\\mathtt{CV}$ algorithm. We prove that if a proper\nestimator of value function reaches, the proposed\n$\\mathtt{ES}$($\\lambda$)-$\\mathtt{CV}$ enjoys a lower variance than\n$\\mathtt{Expected}$ $\\mathtt{Sarsa}$($\\lambda$). Furthermore, to extend\n$\\mathtt{ES}$($\\lambda$)-$\\mathtt{CV}$ to be a convergent algorithm with linear\nfunction approximation, we propose the $\\mathtt{GES}$($\\lambda$) algorithm\nunder the convex-concave saddle-point formulation. We prove that the\nconvergence rate of $\\mathtt{GES}$($\\lambda$) achieves $\\mathcal{O}(1/T)$,\nwhich matches or outperforms lots of state-of-art gradient-based algorithms,\nbut we use a more relaxed condition. Numerical experiments show that the\nproposed algorithm performs better with lower variance than several\nstate-of-art gradient-based TD learning algorithms: $\\mathtt{GQ}$($\\lambda$),\n$\\mathtt{GTB}$($\\lambda$) and $\\mathtt{ABQ}$($\\zeta$).\n", "versions": [{"version": "v1", "created": "Tue, 25 Jun 2019 11:35:44 GMT"}, {"version": "v2", "created": "Fri, 6 Sep 2019 12:38:02 GMT"}], "update_date": "2019-09-09", "authors_parsed": [["Yang", "Long", ""], ["Zhang", "Yu", ""], ["Wen", "Jun", ""], ["Zheng", "Qian", ""], ["Li", "Pengfei", ""], ["Pan", "Gang", ""]]}, {"id": "1906.11068", "submitter": "Aladdin Ayesh", "authors": "Aladdin Ayesh", "title": "Turing Test Revisited: A Framework for an Alternative", "comments": "early complete draft", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper aims to question the suitability of the Turing Test, for testing\nmachine intelligence, in the light of advances made in the last 60 years in\nscience, medicine, and philosophy of mind. While the main concept of the test\nmay seem sound and valid, a detailed analysis of what is required to pass the\ntest highlights a significant flow. Once the analysis of the test is presented,\na systematic approach is followed in analysing what is needed to devise a test\nor tests for intelligent machines. The paper presents a plausible generic\nframework based on categories of factors implied by subjective perception of\nintelligence. An evaluative discussion concludes the paper highlighting some of\nthe unaddressed issues within this generic framework.\n", "versions": [{"version": "v1", "created": "Wed, 26 Jun 2019 13:06:33 GMT"}], "update_date": "2019-06-27", "authors_parsed": [["Ayesh", "Aladdin", ""]]}, {"id": "1906.11075", "submitter": "Takahisa Imagawa", "authors": "Takahisa Imagawa, Takuya Hiraoka and Yoshimasa Tsuruoka", "title": "Optimistic Proximal Policy Optimization", "comments": "Exploration in RL (workshop @ ICML2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement Learning, a machine learning framework for training an\nautonomous agent based on rewards, has shown outstanding results in various\ndomains. However, it is known that learning a good policy is difficult in a\ndomain where rewards are rare. We propose a method, optimistic proximal policy\noptimization (OPPO) to alleviate this difficulty. OPPO considers the\nuncertainty of the estimated total return and optimistically evaluates the\npolicy based on that amount. We show that OPPO outperforms the existing methods\nin a tabular task.\n", "versions": [{"version": "v1", "created": "Tue, 25 Jun 2019 10:21:02 GMT"}], "update_date": "2019-06-27", "authors_parsed": [["Imagawa", "Takahisa", ""], ["Hiraoka", "Takuya", ""], ["Tsuruoka", "Yoshimasa", ""]]}, {"id": "1906.11080", "submitter": "Jun Huan", "authors": "Hanchao Wang and Jun Huan", "title": "AGAN: Towards Automated Design of Generative Adversarial Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent progress in Generative Adversarial Networks (GANs) has shown promising\nsigns of improving GAN training via architectural change. Despite some early\nsuccess, at present the design of GAN architectures requires human expertise,\nlaborious trial-and-error testings, and often draws inspiration from its image\nclassification counterpart. In the current paper, we present the first neural\narchitecture search algorithm, automated neural architecture search for deep\ngenerative models, or AGAN for abbreviation, that is specifically suited for\nGAN training. For unsupervised image generation tasks on CIFAR-10, our\nalgorithm finds architecture that outperforms state-of-the-art models under\nsame regularization techniques. For supervised tasks, the automatically\nsearched architectures also achieve highly competitive performance,\noutperforming best human-invented architectures at resolution $32\\times32$.\nMoreover, we empirically demonstrate that the modules learned by AGAN are\ntransferable to other image generation tasks such as STL-10.\n", "versions": [{"version": "v1", "created": "Tue, 25 Jun 2019 10:12:32 GMT"}], "update_date": "2019-06-27", "authors_parsed": [["Wang", "Hanchao", ""], ["Huan", "Jun", ""]]}, {"id": "1906.11110", "submitter": "Vojtech Kovarik", "authors": "Vojt\\v{e}ch Kova\\v{r}\\'ik, Martin Schmid, Neil Burch, Michael Bowling,\n  Viliam Lis\\'y", "title": "Rethinking Formal Models of Partially Observable Multiagent Decision\n  Making", "comments": "A 2020 update of the original 2019 version of the paper. (Rewrote the\n  main text and clarified the relationship between FOSGs/POSGs and EFGs. Some\n  of the technical results are now presented in the appendix.)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multiagent decision-making in partially observable environments is usually\nmodelled as either an extensive-form game (EFG) in game theory or a partially\nobservable stochastic game (POSG) in multiagent reinforcement learning (MARL).\nOne issue with the current situation is that while most practical problems can\nbe modelled in both formalisms, the relationship of the two models is unclear,\nwhich hinders the transfer of ideas between the two communities. A second issue\nis that while EFGs have recently seen significant algorithmic progress, their\nclassical formalization is unsuitable for efficient presentation of the\nunderlying ideas, such as those around decomposition.\n  To solve the first issue, we introduce factored-observation stochastic games\n(FOSGs), a minor modification of the POSG formalism which distinguishes between\nprivate and public observation and thereby greatly simplifies decomposition. To\nremedy the second issue, we show that FOSGs and POSGs are naturally connected\nto EFGs: by \"unrolling\" a FOSG into its tree form, we obtain an EFG.\nConversely, any perfect-recall timeable EFG corresponds to some underlying FOSG\nin this manner. Moreover, this relationship justifies several minor\nmodifications to the classical EFG formalization that recently appeared as an\nimplicit response to the model's issues with decomposition. Finally, we\nillustrate the transfer of ideas between EFGs and MARL by presenting three key\nEFG techniques -- counterfactual regret minimization, sequence form, and\ndecomposition -- in the FOSG framework.\n", "versions": [{"version": "v1", "created": "Wed, 26 Jun 2019 14:01:34 GMT"}, {"version": "v2", "created": "Wed, 30 Sep 2020 10:50:22 GMT"}, {"version": "v3", "created": "Mon, 26 Oct 2020 12:20:13 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Kova\u0159\u00edk", "Vojt\u011bch", ""], ["Schmid", "Martin", ""], ["Burch", "Neil", ""], ["Bowling", "Michael", ""], ["Lis\u00fd", "Viliam", ""]]}, {"id": "1906.11114", "submitter": "Christian A. Mueller", "authors": "Madhura Thosar, Christian A. Mueller, Georg Jaeger, Johannes Schleiss,\n  Narender Pulugu, Ravi Mallikarjun Chennaboina, Sai Vivek Jeevangekar, Andreas\n  Birk, Max Pfingsthorn, Sebastian Zug", "title": "From Multi-modal Property Dataset to Robot-centric Conceptual Knowledge\n  About Household Objects", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tool-use applications in robotics require conceptual knowledge about objects\nfor informed decision making and object interactions. State-of-the-art methods\nemploy hand-crafted symbolic knowledge which is defined from a human\nperspective and grounded into sensory data afterwards. However, due to\ndifferent sensing and acting capabilities of robots, their conceptual\nunderstanding of objects must be generated from a robot's perspective entirely,\nwhich asks for robot-centric conceptual knowledge about objects. With this goal\nin mind, this article motivates that such knowledge should be based on physical\nand functional properties of objects. Consequently, a selection of ten\nproperties is defined and corresponding extraction methods are proposed. This\nmulti-modal property extraction forms the basis on which our second\ncontribution, a robot-centric knowledge generation is build on. It employs\nunsupervised clustering methods to transform numerical property data into\nsymbols, and Bivariate Joint Frequency Distributions and Sample Proportion to\ngenerate conceptual knowledge about objects using the robot-centric symbols. A\npreliminary implementation of the proposed framework is employed to acquire a\ndataset comprising physical and functional property data of 110 houshold\nobjects. This Robot-Centric dataSet (RoCS) is used to evaluate the framework\nregarding the property extraction methods, the semantics of the considered\nproperties within the dataset and its usefulness in real-world applications\nsuch as tool substitution.\n", "versions": [{"version": "v1", "created": "Wed, 26 Jun 2019 14:11:41 GMT"}], "update_date": "2019-06-27", "authors_parsed": [["Thosar", "Madhura", ""], ["Mueller", "Christian A.", ""], ["Jaeger", "Georg", ""], ["Schleiss", "Johannes", ""], ["Pulugu", "Narender", ""], ["Chennaboina", "Ravi Mallikarjun", ""], ["Jeevangekar", "Sai Vivek", ""], ["Birk", "Andreas", ""], ["Pfingsthorn", "Max", ""], ["Zug", "Sebastian", ""]]}, {"id": "1906.11133", "submitter": "Gary Saavedra", "authors": "Gary J Saavedra, Kathryn N Rodhouse, Daniel M Dunlavy, Philip W\n  Kegelmeyer", "title": "A Review of Machine Learning Applications in Fuzzing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fuzzing has played an important role in improving software development and\ntesting over the course of several decades. Recent research in fuzzing has\nfocused on applications of machine learning (ML), offering useful tools to\novercome challenges in the fuzzing process. This review surveys the current\nresearch in applying ML to fuzzing. Specifically, this review discusses\nsuccessful applications of ML to fuzzing, briefly explores challenges\nencountered, and motivates future research to address fuzzing bottlenecks.\n", "versions": [{"version": "v1", "created": "Thu, 13 Jun 2019 20:02:49 GMT"}, {"version": "v2", "created": "Wed, 9 Oct 2019 20:19:14 GMT"}], "update_date": "2019-10-11", "authors_parsed": [["Saavedra", "Gary J", ""], ["Rodhouse", "Kathryn N", ""], ["Dunlavy", "Daniel M", ""], ["Kegelmeyer", "Philip W", ""]]}, {"id": "1906.11180", "submitter": "Jiaoyan Chen", "authors": "Jiaoyan Chen and Ernesto Jimenez-Ruiz and Ian Horrocks", "title": "Canonicalizing Knowledge Base Literals", "comments": null, "journal-ref": "International Semantic Web Conference (ISWC) 2019", "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ontology-based knowledge bases (KBs) like DBpedia are very valuable\nresources, but their usefulness and usability is limited by various quality\nissues. One such issue is the use of string literals instead of semantically\ntyped entities. In this paper we study the automated canonicalization of such\nliterals, i.e., replacing the literal with an existing entity from the KB or\nwith a new entity that is typed using classes from the KB. We propose a\nframework that combines both reasoning and machine learning in order to predict\nthe relevant entities and types, and we evaluate this framework against\nstate-of-the-art baselines for both semantic typing and entity matching.\n", "versions": [{"version": "v1", "created": "Wed, 26 Jun 2019 15:53:59 GMT"}], "update_date": "2019-06-27", "authors_parsed": [["Chen", "Jiaoyan", ""], ["Jimenez-Ruiz", "Ernesto", ""], ["Horrocks", "Ian", ""]]}, {"id": "1906.11199", "submitter": "David Tolpin", "authors": "David Tolpin", "title": "Deployable probabilistic programming", "comments": "15 pages, to appear in SLPASH Onward! 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose design guidelines for a probabilistic programming facility\nsuitable for deployment as a part of a production software system. As a\nreference implementation, we introduce Infergo, a probabilistic programming\nfacility for Go, a modern programming language of choice for server-side\nsoftware development. We argue that a similar probabilistic programming\nfacility can be added to most modern general-purpose programming languages.\n  Probabilistic programming enables automatic tuning of program parameters and\nalgorithmic decision making through probabilistic inference based on the data.\nTo facilitate addition of probabilistic programming capabilities to other\nprogramming languages, we share implementation choices and techniques employed\nin development of Infergo. We illustrate applicability of Infergo to various\nuse cases on case studies, and evaluate Infergo's performance on several\nbenchmarks, comparing Infergo to dedicated inference-centric probabilistic\nprogramming frameworks.\n", "versions": [{"version": "v1", "created": "Thu, 20 Jun 2019 15:17:02 GMT"}], "update_date": "2019-06-27", "authors_parsed": [["Tolpin", "David", ""]]}, {"id": "1906.11228", "submitter": "Markus Wulfmeier", "authors": "Markus Wulfmeier, Abbas Abdolmaleki, Roland Hafner, Jost Tobias\n  Springenberg, Michael Neunert, Tim Hertweck, Thomas Lampe, Noah Siegel,\n  Nicolas Heess, Martin Riedmiller", "title": "Compositional Transfer in Hierarchical Reinforcement Learning", "comments": "Robotics Science and Systems 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The successful application of general reinforcement learning algorithms to\nreal-world robotics applications is often limited by their high data\nrequirements. We introduce Regularized Hierarchical Policy Optimization (RHPO)\nto improve data-efficiency for domains with multiple dominant tasks and\nultimately reduce required platform time. To this end, we employ compositional\ninductive biases on multiple levels and corresponding mechanisms for sharing\noff-policy transition data across low-level controllers and tasks as well as\nscheduling of tasks. The presented algorithm enables stable and fast learning\nfor complex, real-world domains in the parallel multitask and sequential\ntransfer case. We show that the investigated types of hierarchy enable positive\ntransfer while partially mitigating negative interference and evaluate the\nbenefits of additional incentives for efficient, compositional task solutions\nin single task domains. Finally, we demonstrate substantial data-efficiency and\nfinal performance gains over competitive baselines in a week-long, physical\nrobot stacking experiment.\n", "versions": [{"version": "v1", "created": "Wed, 26 Jun 2019 17:42:07 GMT"}, {"version": "v2", "created": "Thu, 27 Jun 2019 09:44:16 GMT"}, {"version": "v3", "created": "Tue, 19 May 2020 17:29:06 GMT"}], "update_date": "2020-05-20", "authors_parsed": [["Wulfmeier", "Markus", ""], ["Abdolmaleki", "Abbas", ""], ["Hafner", "Roland", ""], ["Springenberg", "Jost Tobias", ""], ["Neunert", "Michael", ""], ["Hertweck", "Tim", ""], ["Lampe", "Thomas", ""], ["Siegel", "Noah", ""], ["Heess", "Nicolas", ""], ["Riedmiller", "Martin", ""]]}, {"id": "1906.11245", "submitter": "Phanideep Gampa", "authors": "Phanideep Gampa, Sairam Satwik Kondamudi, Lakshmanan Kailasam", "title": "A Tractable Algorithm For Finite-Horizon Continuous Reinforcement\n  Learning", "comments": "InProceedings of International Conference on Intelligent Autonomous\n  System, ICOIAS 2019", "journal-ref": null, "doi": "10.1109/ICoIAS.2019.00018", "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the finite horizon continuous reinforcement learning problem. Our\ncontribution is three-fold. First,we give a tractable algorithm based on\noptimistic value iteration for the problem. Next,we give a lower bound on\nregret of order $\\Omega(T^{2/3})$ for any algorithm discretizes the state\nspace, improving the previous regret bound of $\\Omega(T^{1/2})$ of Ortner and\nRyabko \\cite{contrl} for the same problem. Next,under the assumption that the\nrewards and transitions are H\\\"{o}lder Continuous we show that the upper bound\non the discretization error is $const.Ln^{-\\alpha}T$. Finally,we give some\nsimple experiments to validate our propositions.\n", "versions": [{"version": "v1", "created": "Wed, 26 Jun 2019 09:11:14 GMT"}], "update_date": "2019-08-05", "authors_parsed": [["Gampa", "Phanideep", ""], ["Kondamudi", "Sairam Satwik", ""], ["Kailasam", "Lakshmanan", ""]]}, {"id": "1906.11247", "submitter": "Osonde Osoba Ph.D.", "authors": "Osonde Osoba, Bart Kosko", "title": "Beyond DAGs: Modeling Causal Feedback with Fuzzy Cognitive Maps", "comments": "51 pages, 10 figures. Full details, theorems, & knowledge engineering\n  for \"Causal Modeling with Feedback Fuzzy Cognitive Maps\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fuzzy cognitive maps (FCMs) model feedback causal relations in interwoven\nwebs of causality and policy variables. FCMs are fuzzy signed directed graphs\nthat allow degrees of causal influence and event occurrence. Such causal models\ncan simulate a wide range of policy scenarios and decision processes. Their\ndirected loops or cycles directly model causal feedback. Their nonlinear\ndynamics permit forward-chaining inference from input causes and policy options\nto output effects. Users can add detailed dynamics and feedback links directly\nto the causal model or infer them with statistical learning laws. Users can\nfuse or combine FCMs from multiple experts by weighting and adding the\nunderlying fuzzy edge matrices and do so recursively if needed. The combined\nFCM tends to better represent domain knowledge as the expert sample size\nincreases if the expert sample approximates a random sample. Many causal models\nuse more restrictive directed acyclic graphs (DAGs) and Bayesian probabilities.\nDAGs do not model causal feedback because they do not contain closed loops.\nCombining DAGs also tends to produce cycles and thus tends not to produce a new\nDAG. Combining DAGs tends to produce a FCM. FCM causal influence is also\ntransitive whereas probabilistic causal influence is not transitive in general.\nOverall: FCMs trade the numerical precision of probabilistic DAGs for pattern\nprediction, faster and scalable computation, ease of combination, and richer\nfeedback representation. We show how FCMs can apply to problems of public\nsupport for insurgency and terrorism and to US-China conflict relations in\nGraham Allison's Thucydides-trap framework. The appendix gives the textual\njustification of the Thucydides-trap FCM. It also extends our earlier theorem\n[Osoba-Kosko2017] to a more general result that shows the transitive and total\ncausal influence that upstream concept nodes exert on downstream nodes.\n", "versions": [{"version": "v1", "created": "Wed, 26 Jun 2019 16:27:01 GMT"}, {"version": "v2", "created": "Tue, 2 Jul 2019 04:18:14 GMT"}], "update_date": "2019-07-03", "authors_parsed": [["Osoba", "Osonde", ""], ["Kosko", "Bart", ""]]}, {"id": "1906.11259", "submitter": "Jacob Biamonte", "authors": "V. Akshay, H. Philathong, M.E.S. Morales, J. Biamonte", "title": "Reachability Deficits in Quantum Approximate Optimization", "comments": "feedback welcome; 8 pages; 4 composite figures; RevTeX", "journal-ref": "Phys. Rev. Lett. 124, 090504 (2020)", "doi": "10.1103/PhysRevLett.124.090504", "report-no": null, "categories": "quant-ph cond-mat.dis-nn cond-mat.stat-mech cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The quantum approximate optimization algorithm (QAOA) has rapidly become a\ncornerstone of contemporary quantum algorithm development. Despite a growing\nrange of applications, only a few results have been developed towards\nunderstanding the algorithms ultimate limitations. Here we report that QAOA\nexhibits a strong dependence on a problem instances constraint to variable\nratio$-$this problem density places a limiting restriction on the algorithms\ncapacity to minimize a corresponding objective function (and hence solve\noptimization problem instances). Such $reachability~deficits$ persist even in\nthe absence of barren plateaus [McClean et al., 2018] and are outside of the\nrecently reported level-1 QAOA limitations [Hastings 2019]. These findings are\namong the first to determine strong limitations on variational quantum\napproximate optimization.\n", "versions": [{"version": "v1", "created": "Wed, 26 Jun 2019 18:00:03 GMT"}, {"version": "v2", "created": "Thu, 24 Oct 2019 12:12:27 GMT"}], "update_date": "2020-03-11", "authors_parsed": [["Akshay", "V.", ""], ["Philathong", "H.", ""], ["Morales", "M. E. S.", ""], ["Biamonte", "J.", ""]]}, {"id": "1906.11286", "submitter": "Baihan Lin", "authors": "Baihan Lin, Guillermo Cecchi, Djallel Bouneffouf, Jenna Reinen, Irina\n  Rish", "title": "A Story of Two Streams: Reinforcement Learning Models from Human\n  Behavior and Neuropsychiatry", "comments": "Published in AAMAS 2020 as a full paper. This article supersedes our\n  work arXiv:1706.02897 into RL setting and extends extensively into RL games,\n  cognitive modeling, and gambling tasks in lifelong learning setting", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Drawing an inspiration from behavioral studies of human decision making, we\npropose here a more general and flexible parametric framework for reinforcement\nlearning that extends standard Q-learning to a two-stream model for processing\npositive and negative rewards, and allows to incorporate a wide range of\nreward-processing biases -- an important component of human decision making\nwhich can help us better understand a wide spectrum of multi-agent interactions\nin complex real-world socioeconomic systems, as well as various\nneuropsychiatric conditions associated with disruptions in normal reward\nprocessing. From the computational perspective, we observe that the proposed\nSplit-QL model and its clinically inspired variants consistently outperform\nstandard Q-Learning and SARSA methods, as well as recently proposed Double\nQ-Learning approaches, on simulated tasks with particular reward distributions,\na real-world dataset capturing human decision-making in gambling tasks, and the\nPac-Man game in a lifelong learning setting across different reward\nstationarities.\n", "versions": [{"version": "v1", "created": "Fri, 21 Jun 2019 03:31:37 GMT"}, {"version": "v2", "created": "Fri, 28 Jun 2019 06:14:11 GMT"}, {"version": "v3", "created": "Mon, 18 Nov 2019 04:34:06 GMT"}, {"version": "v4", "created": "Mon, 24 Feb 2020 19:21:21 GMT"}, {"version": "v5", "created": "Wed, 26 Feb 2020 18:56:09 GMT"}, {"version": "v6", "created": "Tue, 10 Mar 2020 20:52:24 GMT"}, {"version": "v7", "created": "Tue, 14 Apr 2020 17:26:49 GMT"}], "update_date": "2020-04-15", "authors_parsed": [["Lin", "Baihan", ""], ["Cecchi", "Guillermo", ""], ["Bouneffouf", "Djallel", ""], ["Reinen", "Jenna", ""], ["Rish", "Irina", ""]]}, {"id": "1906.11301", "submitter": "Esin Durmus", "authors": "Esin Durmus and Claire Cardie", "title": "Exploring the Role of Prior Beliefs for Argument Persuasion", "comments": "11 pages", "journal-ref": null, "doi": "10.18653/v1/N18-1094", "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Public debate forums provide a common platform for exchanging opinions on a\ntopic of interest. While recent studies in natural language processing (NLP)\nhave provided empirical evidence that the language of the debaters and their\npatterns of interaction play a key role in changing the mind of a reader,\nresearch in psychology has shown that prior beliefs can affect our\ninterpretation of an argument and could therefore constitute a competing\nalternative explanation for resistance to changing one's stance. To study the\nactual effect of language use vs. prior beliefs on persuasion, we provide a new\ndataset and propose a controlled setting that takes into consideration two\nreader level factors: political and religious ideology. We find that prior\nbeliefs affected by these reader level factors play a more important role than\nlanguage use effects and argue that it is important to account for them in NLP\nstudies of persuasion.\n", "versions": [{"version": "v1", "created": "Wed, 26 Jun 2019 19:15:41 GMT"}], "update_date": "2019-09-26", "authors_parsed": [["Durmus", "Esin", ""], ["Cardie", "Claire", ""]]}, {"id": "1906.11310", "submitter": "Esin Durmus", "authors": "Esin Durmus and Claire Cardie", "title": "A Corpus for Modeling User and Language Effects in Argumentation on\n  Online Debating", "comments": null, "journal-ref": null, "doi": "10.18653/v1/P19-1057", "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Existing argumentation datasets have succeeded in allowing researchers to\ndevelop computational methods for analyzing the content, structure and\nlinguistic features of argumentative text. They have been much less successful\nin fostering studies of the effect of \"user\" traits -- characteristics and\nbeliefs of the participants -- on the debate/argument outcome as this type of\nuser information is generally not available. This paper presents a dataset of\n78, 376 debates generated over a 10-year period along with surprisingly\ncomprehensive participant profiles. We also complete an example study using the\ndataset to analyze the effect of selected user traits on the debate outcome in\ncomparison to the linguistic features typically employed in studies of this\nkind.\n", "versions": [{"version": "v1", "created": "Wed, 26 Jun 2019 19:38:02 GMT"}], "update_date": "2019-09-26", "authors_parsed": [["Durmus", "Esin", ""], ["Cardie", "Claire", ""]]}, {"id": "1906.11313", "submitter": "Esin Durmus", "authors": "Esin Durmus, Faisal Ladhak and Claire Cardie", "title": "Determining Relative Argument Specificity and Stance for Complex\n  Argumentative Structures", "comments": null, "journal-ref": null, "doi": "10.18653/v1/P19-1456", "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Systems for automatic argument generation and debate require the ability to\n(1) determine the stance of any claims employed in the argument and (2) assess\nthe specificity of each claim relative to the argument context. Existing work\non understanding claim specificity and stance, however, has been limited to the\nstudy of argumentative structures that are relatively shallow, most often\nconsisting of a single claim that directly supports or opposes the argument\nthesis. In this paper, we tackle these tasks in the context of complex\narguments on a diverse set of topics. In particular, our dataset consists of\nmanually curated argument trees for 741 controversial topics covering 95,312\nunique claims; lines of argument are generally of depth 2 to 6. We find that as\nthe distance between a pair of claims increases along the argument path,\ndetermining the relative specificity of a pair of claims becomes easier and\ndetermining their relative stance becomes harder.\n", "versions": [{"version": "v1", "created": "Wed, 26 Jun 2019 19:45:42 GMT"}], "update_date": "2019-09-26", "authors_parsed": [["Durmus", "Esin", ""], ["Ladhak", "Faisal", ""], ["Cardie", "Claire", ""]]}, {"id": "1906.11315", "submitter": "Varun Kumar Vijay", "authors": "Varun Kumar Vijay, Abhinav Ganesh, Hanlin Tang, Arjun Bansal", "title": "Generalization to Novel Objects using Prior Relational Knowledge", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To solve tasks in new environments involving objects unseen during training,\nagents must reason over prior information about those objects and their\nrelations. We introduce the Prior Knowledge Graph network, an architecture for\ncombining prior information, structured as a knowledge graph, with a symbolic\nparsing of the visual scene, and demonstrate that this approach is able to\napply learned relations to novel objects whereas the baseline algorithms fail.\nAblation experiments show that the agents ground the knowledge graph relations\nto semantically-relevant behaviors. In both a Sokoban game and the more complex\nPacman environment, our network is also more sample efficient than the\nbaselines, reaching the same performance in 5-10x fewer episodes. Once the\nagents are trained with our approach, we can manipulate agent behavior by\nmodifying the knowledge graph in semantically meaningful ways. These results\nsuggest that our network provides a framework for agents to reason over\nstructured knowledge graphs while still leveraging gradient based learning\napproaches.\n", "versions": [{"version": "v1", "created": "Wed, 26 Jun 2019 19:48:25 GMT"}, {"version": "v2", "created": "Fri, 20 Sep 2019 13:44:38 GMT"}], "update_date": "2019-09-23", "authors_parsed": [["Vijay", "Varun Kumar", ""], ["Ganesh", "Abhinav", ""], ["Tang", "Hanlin", ""], ["Bansal", "Arjun", ""]]}, {"id": "1906.11333", "submitter": "Daniel Gilbert", "authors": "Benjamin R. Baer, Daniel E. Gilbert and Martin T. Wells", "title": "Fairness criteria through the lens of directed acyclic graphical models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A substantial portion of the literature on fairness in algorithms proposes,\nanalyzes, and operationalizes simple formulaic criteria for assessing fairness.\nTwo of these criteria, Equalized Odds and Calibration by Group, have gained\nsignificant attention for their simplicity and intuitive appeal, but also for\ntheir incompatibility. This chapter provides a perspective on the meaning and\nconsequences of these and other fairness criteria using graphical models which\nreveals Equalized Odds and related criteria to be ultimately misleading. An\nassessment of various graphical models suggests that fairness criteria should\nultimately be case-specific and sensitive to the nature of the information the\nalgorithm processes.\n", "versions": [{"version": "v1", "created": "Wed, 26 Jun 2019 20:21:39 GMT"}], "update_date": "2019-06-28", "authors_parsed": [["Baer", "Benjamin R.", ""], ["Gilbert", "Daniel E.", ""], ["Wells", "Martin T.", ""]]}, {"id": "1906.11385", "submitter": "Ray Li", "authors": "Ray Li, Percy Liang, Stephen Mussmann", "title": "A Tight Analysis of Greedy Yields Subexponential Time Approximation for\n  Uniform Decision Tree", "comments": "40 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.AI cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Decision Tree is a classic formulation of active learning: given $n$\nhypotheses with nonnegative weights summing to 1 and a set of tests that each\npartition the hypotheses, output a decision tree using the provided tests that\nuniquely identifies each hypothesis and has minimum (weighted) average depth.\nPrevious works showed that the greedy algorithm achieves a $O(\\log n)$\napproximation ratio for this problem and it is NP-hard beat a $O(\\log n)$\napproximation, settling the complexity of the problem.\n  However, for Uniform Decision Tree, i.e. Decision Tree with uniform weights,\nthe story is more subtle. The greedy algorithm's $O(\\log n)$ approximation\nratio was the best known, but the largest approximation ratio known to be\nNP-hard is $4-\\varepsilon$. We prove that the greedy algorithm gives a\n$O(\\frac{\\log n}{\\log C_{OPT}})$ approximation for Uniform Decision Tree, where\n$C_{OPT}$ is the cost of the optimal tree and show this is best possible for\nthe greedy algorithm. As a corollary, we resolve a conjecture of Kosaraju,\nPrzytycka, and Borgstrom. Leveraging this result, for all $\\alpha\\in(0,1)$, we\nexhibit a $\\frac{9.01}{\\alpha}$ approximation algorithm to Uniform Decision\nTree running in subexponential time $2^{\\tilde O(n^\\alpha)}$. As a corollary,\nachieving any super-constant approximation ratio on Uniform Decision Tree is\nnot NP-hard, assuming the Exponential Time Hypothesis. This work therefore adds\napproximating Uniform Decision Tree to a small list of natural problems that\nhave subexponential time algorithms but no known polynomial time algorithms.\nAll our results hold for Decision Tree with weights not too far from uniform. A\nkey technical contribution of our work is showing a connection between greedy\nalgorithms for Uniform Decision Tree and for Min Sum Set Cover.\n", "versions": [{"version": "v1", "created": "Wed, 26 Jun 2019 23:34:46 GMT"}, {"version": "v2", "created": "Mon, 21 Oct 2019 20:56:43 GMT"}], "update_date": "2019-10-23", "authors_parsed": [["Li", "Ray", ""], ["Liang", "Percy", ""], ["Mussmann", "Stephen", ""]]}, {"id": "1906.11409", "submitter": "Fuyuan Xiao", "authors": "Fuyuan Xiao", "title": "Generalization of Dempster-Shafer theory: A complex belief function", "comments": "9 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dempster-Shafer evidence theory has been widely used in various fields of\napplications, because of the flexibility and effectiveness in modeling\nuncertainties without prior information. However, the existing evidence theory\nis insufficient to consider the situations where it has no capability to\nexpress the fluctuations of data at a given phase of time during their\nexecution, and the uncertainty and imprecision which are inevitably involved in\nthe data occur concurrently with changes to the phase or periodicity of the\ndata. In this paper, therefore, a generalized Dempster-Shafer evidence theory\nis proposed. To be specific, a mass function in the generalized Dempster-Shafer\nevidence theory is modeled by a complex number, called as a complex basic\nbelief assignment, which has more powerful ability to express uncertain\ninformation. Based on that, a generalized Dempster's combination rule is\nexploited. In contrast to the classical Dempster's combination rule, the\ncondition in terms of the conflict coefficient between the evidences K<1 is\nreleased in the generalized Dempster's combination rule. Hence, it is more\ngeneral and applicable than the classical Dempster's combination rule. When the\ncomplex mass function is degenerated from complex numbers to real numbers, the\ngeneralized Dempster's combination rule degenerates to the classical evidence\ntheory under the condition that the conflict coefficient between the evidences\nK is less than 1. In a word, this generalized Dempster-Shafer evidence theory\nprovides a promising way to model and handle more uncertain information.\n", "versions": [{"version": "v1", "created": "Thu, 27 Jun 2019 01:52:04 GMT"}], "update_date": "2019-06-28", "authors_parsed": [["Xiao", "Fuyuan", ""]]}, {"id": "1906.11463", "submitter": "Hemin Ali Qadir", "authors": "Younghak Shin, Hemin Ali Qadir, Lars Aabakken, Jacob Bergsland, and\n  Ilangko Balasingham", "title": "Automatic Colon Polyp Detection using Region based Deep CNN and Post\n  Learning Approaches", "comments": "9 pages", "journal-ref": "IEEE Access 6 (2018): 40950-40962", "doi": "10.1109/ACCESS.2018.2856402", "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic detection of colonic polyps is still an unsolved problem due to the\nlarge variation of polyps in terms of shape, texture, size, and color, and the\nexistence of various polyp-like mimics during colonoscopy. In this study, we\napply a recent region based convolutional neural network (CNN) approach for the\nautomatic detection of polyps in images and videos obtained from colonoscopy\nexaminations. We use a deep-CNN model (Inception Resnet) as a transfer learning\nscheme in the detection system. To overcome the polyp detection obstacles and\nthe small number of polyp images, we examine image augmentation strategies for\ntraining deep networks. We further propose two efficient post-learning methods\nsuch as, automatic false positive learning and off-line learning, both of which\ncan be incorporated with the region based detection system for reliable polyp\ndetection. Using the large size of colonoscopy databases, experimental results\ndemonstrate that the suggested detection systems show better performance\ncompared to other systems in the literature. Furthermore, we show improved\ndetection performance using the proposed post-learning schemes for colonoscopy\nvideos.\n", "versions": [{"version": "v1", "created": "Thu, 27 Jun 2019 07:18:44 GMT"}], "update_date": "2019-06-28", "authors_parsed": [["Shin", "Younghak", ""], ["Qadir", "Hemin Ali", ""], ["Aabakken", "Lars", ""], ["Bergsland", "Jacob", ""], ["Balasingham", "Ilangko", ""]]}, {"id": "1906.11537", "submitter": "Andrew Y. K. Foong", "authors": "Andrew Y. K. Foong, Yingzhen Li, Jos\\'e Miguel Hern\\'andez-Lobato,\n  Richard E. Turner", "title": "'In-Between' Uncertainty in Bayesian Neural Networks", "comments": "Presented at the ICML 2019 Workshop on Uncertainty and Robustness in\n  Deep Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe a limitation in the expressiveness of the predictive uncertainty\nestimate given by mean-field variational inference (MFVI), a popular\napproximate inference method for Bayesian neural networks. In particular, MFVI\nfails to give calibrated uncertainty estimates in between separated regions of\nobservations. This can lead to catastrophically overconfident predictions when\ntesting on out-of-distribution data. Avoiding such overconfidence is critical\nfor active learning, Bayesian optimisation and out-of-distribution robustness.\nWe instead find that a classical technique, the linearised Laplace\napproximation, can handle 'in-between' uncertainty much better for small\nnetwork architectures.\n", "versions": [{"version": "v1", "created": "Thu, 27 Jun 2019 10:25:14 GMT"}], "update_date": "2019-06-28", "authors_parsed": [["Foong", "Andrew Y. K.", ""], ["Li", "Yingzhen", ""], ["Hern\u00e1ndez-Lobato", "Jos\u00e9 Miguel", ""], ["Turner", "Richard E.", ""]]}, {"id": "1906.11567", "submitter": "Morgane Goibert", "authors": "Morgane Goibert and Elvis Dohmatob", "title": "Adversarial Robustness via Label-Smoothing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study Label-Smoothing as a means for improving adversarial robustness of\nsupervised deep-learning models. After establishing a thorough and unified\nframework, we propose several variations to this general method: adversarial,\nBoltzmann and second-best Label-Smoothing methods, and we explain how to\nconstruct your own one. On various datasets (MNIST, CIFAR10, SVHN) and models\n(linear models, MLPs, LeNet, ResNet), we show that Label-Smoothing in general\nimproves adversarial robustness against a variety of attacks (FGSM, BIM,\nDeepFool, Carlini-Wagner) by better taking account of the dataset geometry. The\nproposed Label-Smoothing methods have two main advantages: they can be\nimplemented as a modified cross-entropy loss, thus do not require any\nmodifications of the network architecture nor do they lead to increased\ntraining times, and they improve both standard and adversarial accuracy.\n", "versions": [{"version": "v1", "created": "Thu, 27 Jun 2019 11:47:55 GMT"}, {"version": "v2", "created": "Tue, 15 Oct 2019 16:40:10 GMT"}], "update_date": "2019-10-16", "authors_parsed": [["Goibert", "Morgane", ""], ["Dohmatob", "Elvis", ""]]}, {"id": "1906.11578", "submitter": "Anne-Ruth Meijer", "authors": "Anne-Ruth Jos\\'e Meijer and Arnoud Visser", "title": "A shallow residual neural network to predict the visual cortex response", "comments": "3 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding how the visual cortex of the human brain really works is still\nan open problem for science today. A better understanding of natural\nintelligence could also benefit object-recognition algorithms based on\nconvolutional neural networks. In this paper we demonstrate the asset of using\na shallow residual neural network for this task. The benefit of this approach\nis that earlier stages of the network can be accurately trained, which allows\nus to add more layers at the earlier stage. With this additional layer the\nprediction of the visual brain activity improves from $10.4\\%$ (block 1) to\n$15.53\\%$ (last fully connected layer). By training the network for more than\n10 epochs this improvement can become even larger.\n", "versions": [{"version": "v1", "created": "Thu, 27 Jun 2019 12:06:55 GMT"}], "update_date": "2019-06-28", "authors_parsed": [["Meijer", "Anne-Ruth Jos\u00e9", ""], ["Visser", "Arnoud", ""]]}, {"id": "1906.11583", "submitter": "Sander Beckers", "authors": "Sander Beckers, Frederick Eberhardt, Joseph Y. Halpern", "title": "Approximate Causal Abstraction", "comments": "Appears in UAI-2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Scientific models describe natural phenomena at different levels of\nabstraction. Abstract descriptions can provide the basis for interventions on\nthe system and explanation of observed phenomena at a level of granularity that\nis coarser than the most fundamental account of the system. Beckers and Halpern\n(2019), building on work of Rubenstein et al. (2017), developed an account of\nabstraction for causal models that is exact. Here we extend this account to the\nmore realistic case where an abstract causal model offers only an approximation\nof the underlying system. We show how the resulting account handles the\ndiscrepancy that can arise between low- and high-level causal models of the\nsame system, and in the process provide an account of how one causal model\napproximates another, a topic of independent interest. Finally, we extend the\naccount of approximate abstractions to probabilistic causal models, indicating\nhow and where uncertainty can enter into an approximate abstraction.\n", "versions": [{"version": "v1", "created": "Thu, 27 Jun 2019 12:14:57 GMT"}, {"version": "v2", "created": "Sat, 29 Jun 2019 13:28:50 GMT"}], "update_date": "2019-07-02", "authors_parsed": [["Beckers", "Sander", ""], ["Eberhardt", "Frederick", ""], ["Halpern", "Joseph Y.", ""]]}, {"id": "1906.11667", "submitter": "Shashank Kotyan", "authors": "Shashank Kotyan and Danilo Vasconcellos Vargas", "title": "Evolving Robust Neural Architectures to Defend from Adversarial Attacks", "comments": "Pre-print of the published article in Proceedings of the Workshop on\n  Artificial Intelligence Safety 2020, co-located with the 29th International\n  Joint Conference on Artificial Intelligence and the 17th Pacific Rim\n  International Conference on Artificial Intelligence (IJCAI-PRICAI 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.CR cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Neural networks are prone to misclassify slightly modified input images.\nRecently, many defences have been proposed, but none have improved the\nrobustness of neural networks consistently. Here, we propose to use adversarial\nattacks as a function evaluation to search for neural architectures that can\nresist such attacks automatically. Experiments on neural architecture search\nalgorithms from the literature show that although accurate, they are not able\nto find robust architectures. A significant reason for this lies in their\nlimited search space. By creating a novel neural architecture search with\noptions for dense layers to connect with convolution layers and vice-versa as\nwell as the addition of concatenation layers in the search, we were able to\nevolve an architecture that is inherently accurate on adversarial samples.\nInterestingly, this inherent robustness of the evolved architecture rivals\nstate-of-the-art defences such as adversarial training while being trained only\non the non-adversarial samples. Moreover, the evolved architecture makes use of\nsome peculiar traits which might be useful for developing even more robust\nones. Thus, the results here confirm that more robust architectures exist as\nwell as opens up a new realm of feasibilities for the development and\nexploration of neural networks.\n  Code available at http://bit.ly/RobustArchitectureSearch.\n", "versions": [{"version": "v1", "created": "Thu, 27 Jun 2019 14:12:52 GMT"}, {"version": "v2", "created": "Tue, 18 Feb 2020 20:46:26 GMT"}, {"version": "v3", "created": "Thu, 16 Jul 2020 13:34:50 GMT"}], "update_date": "2021-06-11", "authors_parsed": [["Kotyan", "Shashank", ""], ["Vargas", "Danilo Vasconcellos", ""]]}, {"id": "1906.11668", "submitter": "Anna Jobin", "authors": "Anna Jobin, Marcello Ienca, Effy Vayena", "title": "Artificial Intelligence: the global landscape of ethics guidelines", "comments": "42 pages (incl. figures and supplementary information)", "journal-ref": "Nat. Mach. Intell. (2019)", "doi": "10.1038/s42256-019-0088-2", "report-no": null, "categories": "cs.CY cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the last five years, private companies, research institutions as well as\npublic sector organisations have issued principles and guidelines for ethical\nAI, yet there is debate about both what constitutes \"ethical AI\" and which\nethical requirements, technical standards and best practices are needed for its\nrealization. To investigate whether a global agreement on these questions is\nemerging, we mapped and analyzed the current corpus of principles and\nguidelines on ethical AI. Our results reveal a global convergence emerging\naround five ethical principles (transparency, justice and fairness,\nnon-maleficence, responsibility and privacy), with substantive divergence in\nrelation to how these principles are interpreted; why they are deemed\nimportant; what issue, domain or actors they pertain to; and how they should be\nimplemented. Our findings highlight the importance of integrating\nguideline-development efforts with substantive ethical analysis and adequate\nimplementation strategies.\n", "versions": [{"version": "v1", "created": "Mon, 24 Jun 2019 17:59:19 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Jobin", "Anna", ""], ["Ienca", "Marcello", ""], ["Vayena", "Effy", ""]]}, {"id": "1906.11732", "submitter": "Yue Bai", "authors": "Yue Bai, Leo L. Duan", "title": "Tuning-Free Disentanglement via Projection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In representation learning and non-linear dimension reduction, there is a\nhuge interest to learn the 'disentangled' latent variables, where each\nsub-coordinate almost uniquely controls a facet of the observed data. While\nmany regularization approaches have been proposed on variational autoencoders,\nheuristic tuning is required to balance between disentanglement and loss in\nreconstruction accuracy -- due to the unsupervised nature, there is no\nprincipled way to find an optimal weight for regularization. Motivated to\ncompletely bypass regularization, we consider a projection strategy: modifying\nthe canonical Gaussian encoder, we add a layer of scaling and rotation to the\nGaussian mean, such that the marginal correlations among latent sub-coordinates\nbecome exactly zero. This achieves a theoretically maximal disentanglement, as\nguaranteed by zero cross-correlation between one latent sub-coordinate and the\nobserved varying with the rest. Unlike regularizations, the extra projection\nlayer does not impact the flexibility of the previous encoder layers, leading\nto almost no loss in expressiveness. This approach is simple to implement in\npractice. Our numerical experiments demonstrate very good performance, with no\ntuning required.\n", "versions": [{"version": "v1", "created": "Thu, 27 Jun 2019 15:29:52 GMT"}, {"version": "v2", "created": "Fri, 6 Sep 2019 03:47:00 GMT"}], "update_date": "2019-09-09", "authors_parsed": [["Bai", "Yue", ""], ["Duan", "Leo L.", ""]]}, {"id": "1906.11826", "submitter": "Hananel Hazan", "authors": "Hananel Hazan, Daniel J. Saunders, Darpan T. Sanghavi, Hava\n  Siegelmann, and Robert Kozma", "title": "Lattice Map Spiking Neural Networks (LM-SNNs) for Clustering and\n  Classifying Image Data", "comments": "Original Manuscript Submitted: October 30, 2018. Revised: May 28,\n  2019. Special Issue: \"Cognition and Neurocomputation\" of Annals of\n  Mathematics and Artificial Intelligence. arXiv admin note: text overlap with\n  arXiv:1807.09374", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Spiking neural networks (SNNs) with a lattice architecture are introduced in\nthis work, combining several desirable properties of SNNs and self-organized\nmaps (SOMs). Networks are trained with biologically motivated, unsupervised\nlearning rules to obtain a self-organized grid of filters via cooperative and\ncompetitive excitatory-inhibitory interactions. Several inhibition strategies\nare developed and tested, such as (i) incrementally increasing inhibition level\nover the course of network training, and (ii) switching the inhibition level\nfrom low to high (two-level) after an initial training segment. During the\nlabeling phase, the spiking activity generated by data with known labels is\nused to assign neurons to categories of data, which are then used to evaluate\nthe network's classification ability on a held-out set of test data. Several\nbiologically plausible evaluation rules are proposed and compared, including a\npopulation-level confidence rating, and an $n$-gram inspired method. The\neffectiveness of the proposed self-organized learning mechanism is tested using\nthe MNIST benchmark dataset, as well as using images produced by playing the\nAtari Breakout game.\n", "versions": [{"version": "v1", "created": "Tue, 4 Jun 2019 18:44:22 GMT"}], "update_date": "2019-06-28", "authors_parsed": [["Hazan", "Hananel", ""], ["Saunders", "Daniel J.", ""], ["Sanghavi", "Darpan T.", ""], ["Siegelmann", "Hava", ""], ["Kozma", "Robert", ""]]}, {"id": "1906.11877", "submitter": "Matthew Guzdial", "authors": "Zijin Luo, Matthew Guzdial, and Mark Riedl", "title": "Making CNNs for Video Parsing Accessible", "comments": "11 pages, 6 figures, Foundations of Digital Games 2018", "journal-ref": null, "doi": "10.1145/3337722.3337755", "report-no": null, "categories": "cs.CV cs.AI cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ability to extract sequences of game events for high-resolution e-sport\ngames has traditionally required access to the game's engine. This serves as a\nbarrier to groups who don't possess this access. It is possible to apply deep\nlearning to derive these logs from gameplay video, but it requires\ncomputational power that serves as an additional barrier. These groups would\nbenefit from access to these logs, such as small e-sport tournament organizers\nwho could better visualize gameplay to inform both audience and commentators.\nIn this paper we present a combined solution to reduce the required\ncomputational resources and time to apply a convolutional neural network (CNN)\nto extract events from e-sport gameplay videos. This solution consists of\ntechniques to train a CNN faster and methods to execute predictions more\nquickly. This expands the types of machines capable of training and running\nthese models, which in turn extends access to extracting game logs with this\napproach. We evaluate the approaches in the domain of DOTA2, one of the most\npopular e-sports. Our results demonstrate our approach outperforms standard\nbackpropagation baselines.\n", "versions": [{"version": "v1", "created": "Mon, 10 Jun 2019 16:00:40 GMT"}], "update_date": "2019-07-01", "authors_parsed": [["Luo", "Zijin", ""], ["Guzdial", "Matthew", ""], ["Riedl", "Mark", ""]]}, {"id": "1906.11941", "submitter": "Oliver Richter", "authors": "Oliver Richter and Roger Wattenhofer", "title": "Learning Policies through Quantile Regression", "comments": "Preprint", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Policy gradient based reinforcement learning algorithms coupled with neural\nnetworks have shown success in learning complex policies in the model free\ncontinuous action space control setting. However, explicitly parameterized\npolicies are limited by the scope of the chosen parametric probability\ndistribution. We show that alternatively to the likelihood based policy\ngradient, a related objective can be optimized through advantage weighted\nquantile regression. Our approach models the policy implicitly in the network,\nwhich gives the agent the freedom to approximate any distribution in each\naction dimension, not limiting its capabilities to the commonly used unimodal\nGaussian parameterization. This broader spectrum of policies makes our\nalgorithm suitable for problems where Gaussian policies cannot fit the optimal\npolicy. Moreover, our results on the MuJoCo physics simulator benchmarks are\ncomparable or superior to state-of-the-art on-policy methods.\n", "versions": [{"version": "v1", "created": "Thu, 27 Jun 2019 20:15:45 GMT"}, {"version": "v2", "created": "Fri, 27 Sep 2019 09:55:21 GMT"}], "update_date": "2019-09-30", "authors_parsed": [["Richter", "Oliver", ""], ["Wattenhofer", "Roger", ""]]}, {"id": "1906.11994", "submitter": "Chaoyang He", "authors": "Chaoyang He, Tian Xie, Yu Rong, Wenbing Huang, Junzhou Huang, Xiang\n  Ren, Cyrus Shahabi", "title": "Cascade-BGNN: Toward Efficient Self-supervised Representation Learning\n  on Large-scale Bipartite Graphs", "comments": "KDD 2020 Submission. Our code is open-sourced at\n  https://github.com/chaoyanghe/bipartite-graph-learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.AI cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Bipartite graphs have been used to represent data relationships in many\ndata-mining applications such as in E-commerce recommendation systems. Since\nlearning in graph space is more complicated than in Euclidian space, recent\nstudies have extensively utilized neural nets to effectively and efficiently\nembed a graph's nodes into a multidimensional space. However, this embedding\nmethod has not yet been applied to large-scale bipartite graphs. Existing\ntechniques either cannot be scaled to large-scale bipartite graphs that have\nlimited labels or cannot exploit the unique structure of bipartite graphs,\nwhich have distinct node features in two domains. Thus, we propose Cascade\nBipartite Graph Neural Networks, Cascade-BGNN, a novel node representation\nlearning for bipartite graphs that is domain-consistent, self-supervised, and\nefficient. To efficiently aggregate information both across and within the two\npartitions of a bipartite graph, BGNN utilizes a customized Inter-domain\nMessage Passing (IDMP) and Intra-domain Alignment (IDA), which is our\nadaptation of adversarial learning, for message aggregation across and within\npartitions, respectively. BGNN is trained in a self-supervised manner.\nMoreover, we formulate a multi-layer BGNN in a cascaded training manner to\nenable multi-hop relationship modeling while improving training efficiency.\nExtensive experiments on several datasets of varying scales verify the\neffectiveness and efficiency of BGNN over baselines. Our design is further\naffirmed through theoretical analysis for domain alignment. The scalability of\nBGNN is additionally verified through its demonstrated rapid training speed and\nlow memory cost over a large-scale real-world bipartite graph.\n", "versions": [{"version": "v1", "created": "Thu, 27 Jun 2019 23:34:45 GMT"}, {"version": "v2", "created": "Sat, 28 Sep 2019 20:25:05 GMT"}, {"version": "v3", "created": "Tue, 27 Oct 2020 06:35:53 GMT"}], "update_date": "2020-10-28", "authors_parsed": [["He", "Chaoyang", ""], ["Xie", "Tian", ""], ["Rong", "Yu", ""], ["Huang", "Wenbing", ""], ["Huang", "Junzhou", ""], ["Ren", "Xiang", ""], ["Shahabi", "Cyrus", ""]]}, {"id": "1906.12035", "submitter": "Xipeng Qiu", "authors": "Xipeng Qiu, Hengzhi Pei, Hang Yan, Xuanjing Huang", "title": "A Concise Model for Multi-Criteria Chinese Word Segmentation with\n  Transformer Encoder", "comments": "Findings of EMNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-criteria Chinese word segmentation (MCCWS) aims to exploit the\nrelations among the multiple heterogeneous segmentation criteria and further\nimprove the performance of each single criterion. Previous work usually regards\nMCCWS as different tasks, which are learned together under the multi-task\nlearning framework. In this paper, we propose a concise but effective unified\nmodel for MCCWS, which is fully-shared for all the criteria. By leveraging the\npowerful ability of the Transformer encoder, the proposed unified model can\nsegment Chinese text according to a unique criterion-token indicating the\noutput criterion. Besides, the proposed unified model can segment both\nsimplified and traditional Chinese and has an excellent transfer capability.\nExperiments on eight datasets with different criteria show that our model\noutperforms our single-criterion baseline model and other multi-criteria\nmodels. Source codes of this paper are available on Github\nhttps://github.com/acphile/MCCWS.\n", "versions": [{"version": "v1", "created": "Fri, 28 Jun 2019 04:08:15 GMT"}, {"version": "v2", "created": "Mon, 5 Oct 2020 11:02:37 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Qiu", "Xipeng", ""], ["Pei", "Hengzhi", ""], ["Yan", "Hang", ""], ["Huang", "Xuanjing", ""]]}, {"id": "1906.12089", "submitter": "Nicolas Heist", "authors": "Nicolas Heist and Heiko Paulheim", "title": "Uncovering the Semantics of Wikipedia Categories", "comments": "Preprint of a research track paper at the International Semantic Web\n  Conference (ISWC) 2019, Auckland, NZ", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Wikipedia category graph serves as the taxonomic backbone for large-scale\nknowledge graphs like YAGO or Probase, and has been used extensively for tasks\nlike entity disambiguation or semantic similarity estimation. Wikipedia's\ncategories are a rich source of taxonomic as well as non-taxonomic information.\nThe category 'German science fiction writers', for example, encodes the type of\nits resources (Writer), as well as their nationality (German) and genre\n(Science Fiction). Several approaches in the literature make use of fractions\nof this encoded information without exploiting its full potential. In this\npaper, we introduce an approach for the discovery of category axioms that uses\ninformation from the category network, category instances, and their\nlexicalisations. With DBpedia as background knowledge, we discover 703k axioms\ncovering 502k of Wikipedia's categories and populate the DBpedia knowledge\ngraph with additional 4.4M relation assertions and 3.3M type assertions at more\nthan 87% and 90% precision, respectively.\n", "versions": [{"version": "v1", "created": "Fri, 28 Jun 2019 08:32:46 GMT"}], "update_date": "2019-07-01", "authors_parsed": [["Heist", "Nicolas", ""], ["Paulheim", "Heiko", ""]]}, {"id": "1906.12174", "submitter": "Dongfang Yang", "authors": "Yongfei Li, Dongfang Yang, Shicheng Wang, Hao He", "title": "Road-network-based Rapid Geolocalization", "comments": "19pages, 10 figures, 3 tables. in IEEE Transactions on Geoscience and\n  Remote Sensing", "journal-ref": null, "doi": "10.1109/TGRS.2020.3011034", "report-no": null, "categories": "cs.CV cs.AI eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It has always been a research hotspot to use geographic information to assist\nthe navigation of unmanned aerial vehicles. In this paper, a road-network-based\nlocalization method is proposed. We match roads in the measurement images to\nthe reference road vector map, and realize successful localization on areas as\nlarge as a whole city. The road network matching problem is treated as a point\ncloud registration problem under two-dimensional projective transformation, and\nsolved under a hypothesise-and-test framework. To deal with the projective\npoint cloud registration problem, a global projective invariant feature is\nproposed, which consists of two road intersections augmented with the\ninformation of their tangents. We call it two road intersections tuple. We\ndeduce the closed-form solution for determining the alignment transformation\nfrom a pair of matching two road intersections tuples. In addition, we propose\nthe necessary conditions for the tuples to match. This can reduce the candidate\nmatching tuples, thus accelerating the search to a great extent. We test all\nthe candidate matching tuples under a hypothesise-and-test framework to search\nfor the best match. The experiments show that our method can localize the\ntarget area over an area of 400 within 1 second on a single cpu.\n", "versions": [{"version": "v1", "created": "Tue, 25 Jun 2019 01:54:21 GMT"}], "update_date": "2020-10-12", "authors_parsed": [["Li", "Yongfei", ""], ["Yang", "Dongfang", ""], ["Wang", "Shicheng", ""], ["He", "Hao", ""]]}, {"id": "1906.12182", "submitter": "Linan Huang", "authors": "Linan Huang, Quanyan Zhu", "title": "Adaptive Honeypot Engagement through Reinforcement Learning of\n  Semi-Markov Decision Processes", "comments": "The presentation can be found at https://youtu.be/GPKT3uJtXqk. arXiv\n  admin note: text overlap with arXiv:1907.01396", "journal-ref": null, "doi": "10.1007/978-3-030-32430-8_13", "report-no": null, "categories": "cs.CR cs.AI cs.GT cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A honeynet is a promising active cyber defense mechanism. It reveals the\nfundamental Indicators of Compromise (IoCs) by luring attackers to conduct\nadversarial behaviors in a controlled and monitored environment. The active\ninteraction at the honeynet brings a high reward but also introduces high\nimplementation costs and risks of adversarial honeynet exploitation. In this\nwork, we apply infinite-horizon Semi-Markov Decision Process (SMDP) to\ncharacterize a stochastic transition and sojourn time of attackers in the\nhoneynet and quantify the reward-risk trade-off. In particular, we design\nadaptive long-term engagement policies shown to be risk-averse, cost-effective,\nand time-efficient. Numerical results have demonstrated that our adaptive\nengagement policies can quickly attract attackers to the target honeypot and\nengage them for a sufficiently long period to obtain worthy threat information.\nMeanwhile, the penetration probability is kept at a low level. The results show\nthat the expected utility is robust against attackers of a large range of\npersistence and intelligence. Finally, we apply reinforcement learning to the\nSMDP to solve the curse of modeling. Under a prudent choice of the learning\nrate and exploration policy, we achieve a quick and robust convergence of the\noptimal policy and value.\n", "versions": [{"version": "v1", "created": "Thu, 27 Jun 2019 02:23:11 GMT"}, {"version": "v2", "created": "Thu, 7 Nov 2019 02:10:44 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["Huang", "Linan", ""], ["Zhu", "Quanyan", ""]]}, {"id": "1906.12188", "submitter": "Ahmad Asadi", "authors": "Ahmad Asadi and Reza Safabakhsh", "title": "A Deep Decoder Structure Based on WordEmbedding Regression for An\n  Encoder-Decoder Based Model for Image Captioning", "comments": "19 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generating textual descriptions for images has been an attractive problem for\nthe computer vision and natural language processing researchers in recent\nyears. Dozens of models based on deep learning have been proposed to solve this\nproblem. The existing approaches are based on neural encoder-decoder structures\nequipped with the attention mechanism. These methods strive to train decoders\nto minimize the log likelihood of the next word in a sentence given the\nprevious ones, which results in the sparsity of the output space. In this work,\nwe propose a new approach to train decoders to regress the word embedding of\nthe next word with respect to the previous ones instead of minimizing the log\nlikelihood. The proposed method is able to learn and extract long-term\ninformation and can generate longer fine-grained captions without introducing\nany external memory cell. Furthermore, decoders trained by the proposed\ntechnique can take the importance of the generated words into consideration\nwhile generating captions. In addition, a novel semantic attention mechanism is\nproposed that guides attention points through the image, taking the meaning of\nthe previously generated word into account. We evaluate the proposed approach\nwith the MS-COCO dataset. The proposed model outperformed the state of the art\nmodels especially in generating longer captions. It achieved a CIDEr score\nequal to 125.0 and a BLEU-4 score equal to 50.5, while the best scores of the\nstate of the art models are 117.1 and 48.0, respectively.\n", "versions": [{"version": "v1", "created": "Wed, 26 Jun 2019 13:51:59 GMT"}], "update_date": "2019-07-01", "authors_parsed": [["Asadi", "Ahmad", ""], ["Safabakhsh", "Reza", ""]]}, {"id": "1906.12189", "submitter": "Torsten Koller", "authors": "Torsten Koller, Felix Berkenkamp, Matteo Turchetta, Joschka Boedecker,\n  Andreas Krause", "title": "Learning-based Model Predictive Control for Safe Exploration and\n  Reinforcement Learning", "comments": "14 pages, 7 figures. arXiv admin note: substantial text overlap with\n  arXiv:1803.08287", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.AI cs.LG cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning has been successfully used to solve difficult tasks in\ncomplex unknown environments. However, these methods typically do not provide\nany safety guarantees during the learning process. This is particularly\nproblematic, since reinforcement learning agent actively explore their\nenvironment. This prevents their use in safety-critical, real-world\napplications. In this paper, we present a learning-based model predictive\ncontrol scheme that provides high-probability safety guarantees throughout the\nlearning process. Based on a reliable statistical model, we construct provably\naccurate confidence intervals on predicted trajectories. Unlike previous\napproaches, we allow for input-dependent uncertainties. Based on these reliable\npredictions, we guarantee that trajectories satisfy safety constraints.\nMoreover, we use a terminal set constraint to recursively guarantee the\nexistence of safe control actions at every iteration. We evaluate the resulting\nalgorithm to safely explore the dynamics of an inverted pendulum and to solve a\nreinforcement learning task on a cart-pole system with safety constraints.\n", "versions": [{"version": "v1", "created": "Thu, 27 Jun 2019 11:37:49 GMT"}], "update_date": "2019-07-02", "authors_parsed": [["Koller", "Torsten", ""], ["Berkenkamp", "Felix", ""], ["Turchetta", "Matteo", ""], ["Boedecker", "Joschka", ""], ["Krause", "Andreas", ""]]}, {"id": "1906.12213", "submitter": "Norbert B\\'atfai Ph.D.", "authors": "Norbert B\\'atfai and D\\'avid Papp and Gerg\\H{o} Bogacsovics and\n  M\\'at\\'e Szab\\'o and Viktor Szil\\'ard Simk\\'o and M\\'ari\\'o Bersenszki and\n  Gergely Szab\\'o and Lajos Kov\\'acs and Ferencz Kov\\'acs and Erik Szilveszter\n  Varga", "title": "On the notion of number in humans and machines", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we performed two types of software experiments to study the\nnumerosity classification (subitizing) in humans and machines. Experiments\nfocus on a particular kind of task is referred to as Semantic MNIST or simply\nSMNIST where the numerosity of objects placed in an image must be determined.\nThe experiments called SMNIST for Humans are intended to measure the capacity\nof the Object File System in humans. In this type of experiment the measurement\nresult is in well agreement with the value known from the cognitive psychology\nliterature. The experiments called SMNIST for Machines serve similar purposes\nbut they investigate existing, well known (but originally developed for other\npurpose) and under development deep learning computer programs. These\nmeasurement results can be interpreted similar to the results from SMNIST for\nHumans. The main thesis of this paper can be formulated as follows: in machines\nthe image classification artificial neural networks can learn to distinguish\nnumerosities with better accuracy when these numerosities are smaller than the\ncapacity of OFS in humans. Finally, we outline a conceptual framework to\ninvestigate the notion of number in humans and machines.\n", "versions": [{"version": "v1", "created": "Thu, 27 Jun 2019 09:26:22 GMT"}], "update_date": "2019-07-01", "authors_parsed": [["B\u00e1tfai", "Norbert", ""], ["Papp", "D\u00e1vid", ""], ["Bogacsovics", "Gerg\u0151", ""], ["Szab\u00f3", "M\u00e1t\u00e9", ""], ["Simk\u00f3", "Viktor Szil\u00e1rd", ""], ["Bersenszki", "M\u00e1ri\u00f3", ""], ["Szab\u00f3", "Gergely", ""], ["Kov\u00e1cs", "Lajos", ""], ["Kov\u00e1cs", "Ferencz", ""], ["Varga", "Erik Szilveszter", ""]]}, {"id": "1906.12222", "submitter": "Alexander Gorban", "authors": "Alexander N. Gorban, Valeri A. Makarov, Ivan Y. Tyukin", "title": "Symphony of high-dimensional brain", "comments": null, "journal-ref": "Physics of Life Reviews, 2019", "doi": "10.1016/j.plrev.2019.06.003", "report-no": null, "categories": "q-bio.NC cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper is the final part of the scientific discussion organised by the\nJournal \"Physics of Life Rviews\" about the simplicity revolution in\nneuroscience and AI. This discussion was initiated by the review paper \"The\nunreasonable effectiveness of small neural ensembles in high-dimensional\nbrain\". Phys Life Rev 2019, doi 10.1016/j.plrev.2018.09.005, arXiv:1809.07656.\nThe topics of the discussion varied from the necessity to take into account the\ndifference between the theoretical random distributions and \"extremely\nnon-random\" real distributions and revise the common machine learning theory,\nto different forms of the curse of dimensionality and high-dimensional pitfalls\nin neuroscience. V. K{\\r{u}}rkov{\\'a}, A. Tozzi and J.F. Peters, R. Quian\nQuiroga, P. Varona, R. Barrio, G. Kreiman, L. Fortuna, C. van Leeuwen, R. Quian\nQuiroga, and V. Kreinovich, A.N. Gorban, V.A. Makarov, and I.Y. Tyukin\nparticipated in the discussion. In this paper we analyse the symphony of\nopinions and the possible outcomes of the simplicity revolution for machine\nlearning and neuroscience.\n", "versions": [{"version": "v1", "created": "Thu, 27 Jun 2019 17:46:24 GMT"}], "update_date": "2019-07-01", "authors_parsed": [["Gorban", "Alexander N.", ""], ["Makarov", "Valeri A.", ""], ["Tyukin", "Ivan Y.", ""]]}, {"id": "1906.12249", "submitter": "Adam Amos-Binks", "authors": "Adam Amos-Binks and Dustin Dannenhauer", "title": "Anticipatory Thinking: A Metacognitive Capability", "comments": "Submitted to 2019 Goal Reasoning Workshop at Advances in Cognitive\n  Systems", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Anticipatory thinking is a complex cognitive process for assessing and\nmanaging risk in many contexts. Humans use anticipatory thinking to identify\npotential future issues and proactively take actions to manage their risks. In\nthis paper we define a cognitive systems approach to anticipatory thinking as a\nmetacognitive goal reasoning mechanism. The contributions of this paper include\n(1) defining anticipatory thinking in the MIDCA cognitive architecture, (2)\noperationalizing anticipatory thinking as a three step process for managing\nrisk in plans, and (3) a numeric risk assessment calculating an expected\ncost-benefit ratio for modifying a plan with anticipatory actions.\n", "versions": [{"version": "v1", "created": "Fri, 28 Jun 2019 14:45:41 GMT"}], "update_date": "2019-07-01", "authors_parsed": [["Amos-Binks", "Adam", ""], ["Dannenhauer", "Dustin", ""]]}, {"id": "1906.12264", "submitter": "Yongqiang Huang", "authors": "Yongqiang Huang and Yu Sun", "title": "Accurate Robotic Pouring for Serving Drinks", "comments": null, "journal-ref": "IJCAI 2019 Workshop on AIxFood", "doi": null, "report-no": null, "categories": "cs.RO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pouring is the second most frequently executed motion in cooking scenarios.\nIn this work, we present our system of accurate pouring that generates the\nangular velocities of the source container using recurrent neural networks. We\ncollected demonstrations of human pouring water. We made a physical system on\nwhich the velocities of the source container were generated at each time step\nand executed by a motor. We tested our system on pouring water from containers\nthat are not used for training and achieved an error of as low as 4\nmilliliters. We also used the system to pour oil and syrup. The accuracy\nachieved with oil is slightly lower than but comparable with that of water.\n", "versions": [{"version": "v1", "created": "Fri, 21 Jun 2019 21:56:38 GMT"}], "update_date": "2019-07-01", "authors_parsed": [["Huang", "Yongqiang", ""], ["Sun", "Yu", ""]]}, {"id": "1906.12266", "submitter": "Gregory Farquhar", "authors": "Gregory Farquhar, Laura Gustafson, Zeming Lin, Shimon Whiteson,\n  Nicolas Usunier, Gabriel Synnaeve", "title": "Growing Action Spaces", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In complex tasks, such as those with large combinatorial action spaces,\nrandom exploration may be too inefficient to achieve meaningful learning\nprogress. In this work, we use a curriculum of progressively growing action\nspaces to accelerate learning. We assume the environment is out of our control,\nbut that the agent may set an internal curriculum by initially restricting its\naction space. Our approach uses off-policy reinforcement learning to estimate\noptimal value functions for multiple action spaces simultaneously and\nefficiently transfers data, value estimates, and state representations from\nrestricted action spaces to the full task. We show the efficacy of our approach\nin proof-of-concept control tasks and on challenging large-scale StarCraft\nmicromanagement tasks with large, multi-agent action spaces.\n", "versions": [{"version": "v1", "created": "Fri, 28 Jun 2019 15:35:11 GMT"}], "update_date": "2019-07-01", "authors_parsed": [["Farquhar", "Gregory", ""], ["Gustafson", "Laura", ""], ["Lin", "Zeming", ""], ["Whiteson", "Shimon", ""], ["Usunier", "Nicolas", ""], ["Synnaeve", "Gabriel", ""]]}, {"id": "1906.12314", "submitter": "Ian Gent", "authors": "Charlie Blake and Ian P. Gent", "title": "The Winnability of Klondike Solitaire and Many Other Patience Games", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Our ignorance of the winnability percentage of the game in the Windows\nSolitaire program, more properly called 'Klondike', has been described as \"one\nof the embarrassments of applied mathematics\". Klondike is just one of many\nsingle-player card games, generically called 'patience' or 'solitaire' games,\nfor which players have long wanted to know how likely a particular game is to\nbe winnable. A number of different games have been studied empirically in the\nacademic literature and by non-academic enthusiasts. Here we show that a single\ngeneral purpose Artificial Intelligence program, called \"Solvitaire\", can be\nused to determine the winnability percentage of 45 different single-player card\ngames with a 95% confidence interval of +/- 0.1% or better. For example, we\nreport the winnability of Klondike as 81.956% +/- 0.096% (in the 'thoughtful'\nvariant where the player knows the location of all cards), a 30-fold reduction\nin confidence interval over the best previous result. Almost all our results\nare either entirely new or represent significant improvements on previous\nknowledge.\n", "versions": [{"version": "v1", "created": "Fri, 28 Jun 2019 17:19:36 GMT"}, {"version": "v2", "created": "Mon, 23 Sep 2019 15:42:30 GMT"}, {"version": "v3", "created": "Wed, 6 Nov 2019 15:21:49 GMT"}], "update_date": "2019-11-07", "authors_parsed": [["Blake", "Charlie", ""], ["Gent", "Ian P.", ""]]}, {"id": "1906.12350", "submitter": "Baihan Lin", "authors": "Baihan Lin, Djallel Bouneffouf, Guillermo Cecchi", "title": "Split Q Learning: Reinforcement Learning with Two-Stream Rewards", "comments": "IJCAI 2019. This article supersedes our work arXiv:1706.02897 into RL\n  setting, with a different focus by applying Inverse Reinforcement Learning to\n  model human clinical behavioral bias. It also precedes our work\n  arXiv:1906.11286 which introduces extensive emphases in RL games", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Drawing an inspiration from behavioral studies of human decision making, we\npropose here a general parametric framework for a reinforcement learning\nproblem, which extends the standard Q-learning approach to incorporate a\ntwo-stream framework of reward processing with biases biologically associated\nwith several neurological and psychiatric conditions, including Parkinson's and\nAlzheimer's diseases, attention-deficit/hyperactivity disorder (ADHD),\naddiction, and chronic pain. For AI community, the development of agents that\nreact differently to different types of rewards can enable us to understand a\nwide spectrum of multi-agent interactions in complex real-world socioeconomic\nsystems. Moreover, from the behavioral modeling perspective, our parametric\nframework can be viewed as a first step towards a unifying computational model\ncapturing reward processing abnormalities across multiple mental conditions and\nuser preferences in long-term recommendation systems.\n", "versions": [{"version": "v1", "created": "Fri, 21 Jun 2019 01:59:52 GMT"}, {"version": "v2", "created": "Tue, 12 Nov 2019 19:10:05 GMT"}], "update_date": "2019-11-14", "authors_parsed": [["Lin", "Baihan", ""], ["Bouneffouf", "Djallel", ""], ["Cecchi", "Guillermo", ""]]}]