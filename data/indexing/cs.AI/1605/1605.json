[{"id": "1605.00064", "submitter": "Rohollah Soltani", "authors": "Rohollah Soltani and Hui Jiang", "title": "Higher Order Recurrent Neural Networks", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study novel neural network structures to better model long\nterm dependency in sequential data. We propose to use more memory units to keep\ntrack of more preceding states in recurrent neural networks (RNNs), which are\nall recurrently fed to the hidden layers as feedback through different weighted\npaths. By extending the popular recurrent structure in RNNs, we provide the\nmodels with better short-term memory mechanism to learn long term dependency in\nsequences. Analogous to digital filters in signal processing, we call these\nstructures as higher order RNNs (HORNNs). Similar to RNNs, HORNNs can also be\nlearned using the back-propagation through time method. HORNNs are generally\napplicable to a variety of sequence modelling tasks. In this work, we have\nexamined HORNNs for the language modeling task using two popular data sets,\nnamely the Penn Treebank (PTB) and English text8 data sets. Experimental\nresults have shown that the proposed HORNNs yield the state-of-the-art\nperformance on both data sets, significantly outperforming the regular RNNs as\nwell as the popular LSTMs.\n", "versions": [{"version": "v1", "created": "Sat, 30 Apr 2016 05:04:08 GMT"}], "update_date": "2016-05-03", "authors_parsed": [["Soltani", "Rohollah", ""], ["Jiang", "Hui", ""]]}, {"id": "1605.00122", "submitter": "Xinyu Fu", "authors": "Xinyu Fu, Eugene Ch'ng, Uwe Aickelin, Lanyun Zhang", "title": "An Improved System for Sentence-level Novelty Detection in Textual\n  Streams", "comments": null, "journal-ref": null, "doi": "10.1049/cp.2015.0250", "report-no": null, "categories": "cs.IR cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Novelty detection in news events has long been a difficult problem. A number\nof models performed well on specific data streams but certain issues are far\nfrom being solved, particularly in large data streams from the WWW where\nunpredictability of new terms requires adaptation in the vector space model. We\npresent a novel event detection system based on the Incremental Term\nFrequency-Inverse Document Frequency (TF-IDF) weighting incorporated with\nLocality Sensitive Hashing (LSH). Our system could efficiently and effectively\nadapt to the changes within the data streams of any new terms with continual\nupdates to the vector space model. Regarding miss probability, our proposed\nnovelty detection framework outperforms a recognised baseline system by\napproximately 16% when evaluating a benchmark dataset from Google News.\n", "versions": [{"version": "v1", "created": "Sat, 30 Apr 2016 15:04:19 GMT"}], "update_date": "2017-06-06", "authors_parsed": [["Fu", "Xinyu", ""], ["Ch'ng", "Eugene", ""], ["Aickelin", "Uwe", ""], ["Zhang", "Lanyun", ""]]}, {"id": "1605.00164", "submitter": "Dinesh Jayaraman", "authors": "Dinesh Jayaraman and Kristen Grauman", "title": "Look-ahead before you leap: end-to-end active recognition by forecasting\n  the effect of motion", "comments": "A preliminary version of the material in this document was filed as\n  University of Texas technical report no. UT AI15-06, December, 2015, at:\n  http://apps.cs.utexas.edu/tech_reports/reports/ai/AI-2214.pdf, ECCV 2016", "journal-ref": null, "doi": null, "report-no": "University of Texas Technical Report UT AI 15-06 (December 2015)", "categories": "cs.CV cs.AI cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Visual recognition systems mounted on autonomous moving agents face the\nchallenge of unconstrained data, but simultaneously have the opportunity to\nimprove their performance by moving to acquire new views of test data. In this\nwork, we first show how a recurrent neural network-based system may be trained\nto perform end-to-end learning of motion policies suited for this \"active\nrecognition\" setting. Further, we hypothesize that active vision requires an\nagent to have the capacity to reason about the effects of its motions on its\nview of the world. To verify this hypothesis, we attempt to induce this\ncapacity in our active recognition pipeline, by simultaneously learning to\nforecast the effects of the agent's motions on its internal representation of\nthe environment conditional on all past views. Results across two challenging\ndatasets confirm both that our end-to-end system successfully learns meaningful\npolicies for active category recognition, and that \"learning to look ahead\"\nfurther boosts recognition performance.\n", "versions": [{"version": "v1", "created": "Sat, 30 Apr 2016 20:39:16 GMT"}, {"version": "v2", "created": "Fri, 5 Aug 2016 22:15:48 GMT"}], "update_date": "2016-08-09", "authors_parsed": [["Jayaraman", "Dinesh", ""], ["Grauman", "Kristen", ""]]}, {"id": "1605.00241", "submitter": "Basem Elbarashy", "authors": "Basem G. El-Barashy", "title": "Common-Description Learning: A Framework for Learning Algorithms and\n  Generating Subproblems from Few Examples", "comments": "32 pages, 13 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current learning algorithms face many difficulties in learning simple\npatterns and using them to learn more complex ones. They also require more\nexamples than humans do to learn the same pattern, assuming no prior knowledge.\nIn this paper, a new learning framework is introduced that is called\ncommon-description learning (CDL). This framework has been tested on 32 small\nmulti-task datasets, and the results show that it was able to learn complex\nalgorithms from a few number of examples. The final model is perfectly\ninterpretable and its depth depends on the question. What is meant by depth\nhere is that whenever needed, the model learns to break down the problem into\nsimpler subproblems and solves them using previously learned models. Finally,\nwe explain the capabilities of our framework in discovering complex relations\nin data and how it can help in improving language understanding in machines.\n", "versions": [{"version": "v1", "created": "Sun, 1 May 2016 11:56:01 GMT"}], "update_date": "2016-05-03", "authors_parsed": [["El-Barashy", "Basem G.", ""]]}, {"id": "1605.00303", "submitter": "Tommaso Mansi", "authors": "Dominik Neumann, Tommaso Mansi, Lucian Itu, Bogdan Georgescu, Elham\n  Kayvanpour, Farbod Sedaghat-Hamedani, Ali Amr, Jan Haas, Hugo Katus, Benjamin\n  Meder, Stefan Steidl, Joachim Hornegger, Dorin Comaniciu", "title": "A Self-Taught Artificial Agent for Multi-Physics Computational Model\n  Personalization", "comments": "Submitted to Medical Image Analysis, Elsevier", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Personalization is the process of fitting a model to patient data, a critical\nstep towards application of multi-physics computational models in clinical\npractice. Designing robust personalization algorithms is often a tedious,\ntime-consuming, model- and data-specific process. We propose to use artificial\nintelligence concepts to learn this task, inspired by how human experts\nmanually perform it. The problem is reformulated in terms of reinforcement\nlearning. In an off-line phase, Vito, our self-taught artificial agent, learns\na representative decision process model through exploration of the\ncomputational model: it learns how the model behaves under change of\nparameters. The agent then automatically learns an optimal strategy for on-line\npersonalization. The algorithm is model-independent; applying it to a new model\nrequires only adjusting few hyper-parameters of the agent and defining the\nobservations to match. The full knowledge of the model itself is not required.\nVito was tested in a synthetic scenario, showing that it could learn how to\noptimize cost functions generically. Then Vito was applied to the inverse\nproblem of cardiac electrophysiology and the personalization of a whole-body\ncirculation model. The obtained results suggested that Vito could achieve\nequivalent, if not better goodness of fit than standard methods, while being\nmore robust (up to 11% higher success rates) and with faster (up to seven\ntimes) convergence rate. Our artificial intelligence approach could thus make\npersonalization algorithms generalizable and self-adaptable to any patient and\nany model.\n", "versions": [{"version": "v1", "created": "Sun, 1 May 2016 20:19:25 GMT"}], "update_date": "2016-05-03", "authors_parsed": [["Neumann", "Dominik", ""], ["Mansi", "Tommaso", ""], ["Itu", "Lucian", ""], ["Georgescu", "Bogdan", ""], ["Kayvanpour", "Elham", ""], ["Sedaghat-Hamedani", "Farbod", ""], ["Amr", "Ali", ""], ["Haas", "Jan", ""], ["Katus", "Hugo", ""], ["Meder", "Benjamin", ""], ["Steidl", "Stefan", ""], ["Hornegger", "Joachim", ""], ["Comaniciu", "Dorin", ""]]}, {"id": "1605.00495", "submitter": "Ryuta Arisaka", "authors": "Ryuta Arisaka and Ken Satoh", "title": "Coalition Formability Semantics with Conflict-Eliminable Sets of\n  Arguments", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider abstract-argumentation-theoretic coalition formability in this\nwork. Taking a model from political alliance among political parties, we will\ncontemplate profitability, and then formability, of a coalition. As is commonly\nunderstood, a group forms a coalition with another group for a greater good,\nthe goodness measured against some criteria. As is also commonly understood,\nhowever, a coalition may deliver benefits to a group X at the sacrifice of\nsomething that X was able to do before coalition formation, which X may be no\nlonger able to do under the coalition. Use of the typical conflict-free sets of\narguments is not very fitting for accommodating this aspect of coalition, which\nprompts us to turn to a weaker notion, conflict-eliminability, as a property\nthat a set of arguments should primarily satisfy. We require numerical\nquantification of attack strengths as well as of argument strengths for its\ncharacterisation. We will first analyse semantics of profitability of a given\nconflict-eliminable set forming a coalition with another conflict-eliminable\nset, and will then provide four coalition formability semantics, each of which\nformalises certain utility postulate(s) taking the coalition profitability into\naccount.\n", "versions": [{"version": "v1", "created": "Mon, 2 May 2016 14:08:23 GMT"}, {"version": "v2", "created": "Sun, 21 May 2017 23:46:45 GMT"}], "update_date": "2017-05-23", "authors_parsed": [["Arisaka", "Ryuta", ""], ["Satoh", "Ken", ""]]}, {"id": "1605.00596", "submitter": "Shuai Li", "authors": "Shuai Li and Claudio Gentile and Alexandros Karatzoglou", "title": "Graph Clustering Bandits for Recommendation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate an efficient context-dependent clustering technique for\nrecommender systems based on exploration-exploitation strategies through\nmulti-armed bandits over multiple users. Our algorithm dynamically groups users\nbased on their observed behavioral similarity during a sequence of logged\nactivities. In doing so, the algorithm reacts to the currently served user by\nshaping clusters around him/her but, at the same time, it explores the\ngeneration of clusters over users which are not currently engaged. We motivate\nthe effectiveness of this clustering policy, and provide an extensive empirical\nanalysis on real-world datasets, showing scalability and improved prediction\nperformance over state-of-the-art methods for sequential clustering of users in\nmulti-armed bandit scenarios.\n", "versions": [{"version": "v1", "created": "Mon, 2 May 2016 18:13:04 GMT"}], "update_date": "2016-05-03", "authors_parsed": [["Li", "Shuai", ""], ["Gentile", "Claudio", ""], ["Karatzoglou", "Alexandros", ""]]}, {"id": "1605.00686", "submitter": "Mayank Kejriwal", "authors": "Mayank Kejriwal", "title": "Adaptive Candidate Generation for Scalable Edge-discovery Tasks on Data\n  Graphs", "comments": "8 pages,published at MLG workshop at KDD'17", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Several `edge-discovery' applications over graph-based data models are known\nto have worst-case quadratic time complexity in the nodes, even if the\ndiscovered edges are sparse. One example is the generic link discovery problem\nbetween two graphs, which has invited research interest in several communities.\nSpecific versions of this problem include link prediction in social networks,\nontology alignment between metadata-rich RDF data, approximate joins, and\nentity resolution between instance-rich data. As large datasets continue to\nproliferate, reducing quadratic complexity to make the task practical is an\nimportant research problem. Within the entity resolution community, the problem\nis commonly referred to as blocking. A particular class of learnable blocking\nschemes is known as Disjunctive Normal Form (DNF) blocking schemes, and has\nemerged as state-of-the art for homogeneous (i.e. same-schema) tabular data.\nDespite the promise of these schemes, a formalism or learning framework has not\nbeen developed for them when input data instances are generic, attributed\ngraphs possessing both node and edge heterogeneity. With such a development,\nthe complexity-reducing scope of DNF schemes becomes applicable to a variety of\nproblems, including entity resolution and type alignment between heterogeneous\ngraphs, and link prediction in networks represented as attributed graphs. This\npaper presents a graph-theoretic formalism for DNF schemes, and investigates\ntheir learnability in an optimization framework. We also briefly describe an\nempirical case study encapsulating some of the principles in this paper.\n", "versions": [{"version": "v1", "created": "Mon, 2 May 2016 20:51:43 GMT"}, {"version": "v2", "created": "Sat, 1 Jul 2017 00:47:21 GMT"}], "update_date": "2017-07-04", "authors_parsed": [["Kejriwal", "Mayank", ""]]}, {"id": "1605.00702", "submitter": "F\\'abio Cruz", "authors": "F\\'abio Cruz, Anand Subramanian, Bruno P. Bruck, Manuel Iori", "title": "A heuristic algorithm for a single vehicle static bike sharing\n  rebalancing problem", "comments": "Technical report Universidade Federal da Para\\'iba-UFPB, Brazil", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The static bike rebalancing problem (SBRP) concerns the task of repositioning\nbikes among stations in self-service bike-sharing systems. This problem can be\nseen as a variant of the one-commodity pickup and delivery vehicle routing\nproblem, where multiple visits are allowed to be performed at each station,\ni.e., the demand of a station is allowed to be split. Moreover, a vehicle may\ntemporarily drop its load at a station, leaving it in excess or, alternatively,\ncollect more bikes from a station (even all of them), thus leaving it in\ndefault. Both cases require further visits in order to meet the actual demands\nof such station. This paper deals with a particular case of the SBRP, in which\nonly a single vehicle is available and the objective is to find a least-cost\nroute that meets the demand of all stations and does not violate the minimum\n(zero) and maximum (vehicle capacity) load limits along the tour. Therefore,\nthe number of bikes to be collected or delivered at each station should be\nappropriately determined in order to respect such constraints. We propose an\niterated local search (ILS) based heuristic to solve the problem. The ILS\nalgorithm was tested on 980 benchmark instances from the literature and the\nresults obtained are quite competitive when compared to other existing methods.\nMoreover, our heuristic was capable of finding most of the known optimal\nsolutions and also of improving the results on a number of open instances.\n", "versions": [{"version": "v1", "created": "Mon, 2 May 2016 22:44:54 GMT"}, {"version": "v2", "created": "Wed, 4 May 2016 00:26:14 GMT"}], "update_date": "2016-05-05", "authors_parsed": [["Cruz", "F\u00e1bio", ""], ["Subramanian", "Anand", ""], ["Bruck", "Bruno P.", ""], ["Iori", "Manuel", ""]]}, {"id": "1605.00787", "submitter": "Shadrack Kipchirchir Kimutai", "authors": "Shadrack Kimutai", "title": "Obstacle evasion using fuzzy logic in a sliding blades problem\n  environment", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.RO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper discusses obstacle avoidance using fuzzy logic and shortest path\nalgorithm. This paper also introduces the sliding blades problem and\nillustrates how a drone can navigate itself through the swinging blade\nobstacles while tracing a semi-optimal path and also maintaining constant\nvelocity\n", "versions": [{"version": "v1", "created": "Tue, 3 May 2016 08:34:45 GMT"}], "update_date": "2016-05-04", "authors_parsed": [["Kimutai", "Shadrack", ""]]}, {"id": "1605.00788", "submitter": "Guy Uziel", "authors": "Guy Uziel and Ran El-Yaniv", "title": "Online Learning of Commission Avoidant Portfolio Ensembles", "comments": "arXiv admin note: text overlap with arXiv:1604.03266", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel online ensemble learning strategy for portfolio selection.\nThe new strategy controls and exploits any set of commission-oblivious\nportfolio selection algorithms. The strategy handles transaction costs using a\nnovel commission avoidance mechanism. We prove a logarithmic regret bound for\nour strategy with respect to optimal mixtures of the base algorithms. Numerical\nexamples validate the viability of our method and show significant improvement\nover the state-of-the-art.\n", "versions": [{"version": "v1", "created": "Tue, 3 May 2016 08:38:34 GMT"}, {"version": "v2", "created": "Sun, 29 May 2016 14:20:01 GMT"}], "update_date": "2016-05-31", "authors_parsed": [["Uziel", "Guy", ""], ["El-Yaniv", "Ran", ""]]}, {"id": "1605.00854", "submitter": "Qixia Yuan", "authors": "Andrzej Mizera and Jun Pang and Qixia Yuan", "title": "Fast Simulation of Probabilistic Boolean Networks (Technical Report)", "comments": "15 pages, 3 figures, for CMSB 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE cs.AI q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Probabilistic Boolean networks (PBNs) is an important mathematical framework\nwidely used for modelling and analysing biological systems. PBNs are suited for\nmodelling large biological systems, which more and more often arise in systems\nbiology. However, the large system size poses a~significant challenge to the\nanalysis of PBNs, in particular, to the crucial analysis of their steady-state\nbehaviour. Numerical methods for performing steady-state analyses suffer from\nthe state-space explosion problem, which makes the utilisation of statistical\nmethods the only viable approach. However, such methods require long\nsimulations of PBNs, rendering the simulation speed a crucial efficiency\nfactor. For large PBNs and high estimation precision requirements, a slow\nsimulation speed becomes an obstacle. In this paper, we propose a\nstructure-based method for fast simulation of PBNs. This method first performs\na network reduction operation and then divides nodes into groups for parallel\nsimulation. Experimental results show that our method can lead to an\napproximately 10 times speedup for computing steady-state probabilities of a\nreal-life biological network.\n", "versions": [{"version": "v1", "created": "Thu, 28 Apr 2016 16:29:39 GMT"}], "update_date": "2016-05-04", "authors_parsed": [["Mizera", "Andrzej", ""], ["Pang", "Jun", ""], ["Yuan", "Qixia", ""]]}, {"id": "1605.01018", "submitter": "Lantao Liu", "authors": "Lantao Liu, Gaurav S. Sukhatme", "title": "A Solution to Time-Varying Markov Decision Processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a decision-making problem where the environment varies both in\nspace and time. Such problems arise naturally when considering e.g., the\nnavigation of an underwater robot amidst ocean currents or the navigation of an\naerial vehicle in wind. To model such spatiotemporal variation, we extend the\nstandard Markov Decision Process (MDP) to a new framework called the\nTime-Varying Markov Decision Process (TVMDP). The TVMDP has a time-varying\nstate transition model and transforms the standard MDP that considers only\nimmediate and static uncertainty descriptions of state transitions, to a\nframework that is able to adapt to future time-varying transition dynamics over\nsome horizon. We show how to solve a TVMDP via a redesign of the MDP value\npropagation mechanisms by incorporating the introduced dynamics along the\ntemporal dimension. We validate our framework in a marine robotics navigation\nsetting using spatiotemporal ocean data and show that it outperforms prior\nefforts.\n", "versions": [{"version": "v1", "created": "Tue, 3 May 2016 18:43:58 GMT"}, {"version": "v2", "created": "Tue, 31 Jan 2017 23:56:57 GMT"}, {"version": "v3", "created": "Thu, 25 Jan 2018 23:05:57 GMT"}], "update_date": "2019-01-10", "authors_parsed": [["Liu", "Lantao", ""], ["Sukhatme", "Gaurav S.", ""]]}, {"id": "1605.01138", "submitter": "Jiajun Wu", "authors": "Renqiao Zhang, Jiajun Wu, Chengkai Zhang, William T. Freeman, Joshua\n  B. Tenenbaum", "title": "A Comparative Evaluation of Approximate Probabilistic Simulation and\n  Deep Neural Networks as Accounts of Human Physical Scene Understanding", "comments": "Accepted to CogSci 2016 as an oral presentation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CV q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Humans demonstrate remarkable abilities to predict physical events in complex\nscenes. Two classes of models for physical scene understanding have recently\nbeen proposed: \"Intuitive Physics Engines\", or IPEs, which posit that people\nmake predictions by running approximate probabilistic simulations in causal\nmental models similar in nature to video-game physics engines, and memory-based\nmodels, which make judgments based on analogies to stored experiences of\npreviously encountered scenes and physical outcomes. Versions of the latter\nhave recently been instantiated in convolutional neural network (CNN)\narchitectures. Here we report four experiments that, to our knowledge, are the\nfirst rigorous comparisons of simulation-based and CNN-based models, where both\napproaches are concretely instantiated in algorithms that can run on raw image\ninputs and produce as outputs physical judgments such as whether a stack of\nblocks will fall. Both approaches can achieve super-human accuracy levels and\ncan quantitatively predict human judgments to a similar degree, but only the\nsimulation-based models generalize to novel situations in ways that people do,\nand are qualitatively consistent with systematic perceptual illusions and\njudgment asymmetries that people show.\n", "versions": [{"version": "v1", "created": "Wed, 4 May 2016 04:26:06 GMT"}, {"version": "v2", "created": "Tue, 4 Oct 2016 01:01:47 GMT"}], "update_date": "2016-10-05", "authors_parsed": [["Zhang", "Renqiao", ""], ["Wu", "Jiajun", ""], ["Zhang", "Chengkai", ""], ["Freeman", "William T.", ""], ["Tenenbaum", "Joshua B.", ""]]}, {"id": "1605.01180", "submitter": "Alexey Potapov", "authors": "Alexey Potapov", "title": "A Step from Probabilistic Programming to Cognitive Architectures", "comments": "4 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Probabilistic programming is considered as a framework, in which basic\ncomponents of cognitive architectures can be represented in unified and elegant\nfashion. At the same time, necessity of adopting some component of cognitive\narchitectures for extending capabilities of probabilistic programming languages\nis pointed out. In particular, implicit specification of generative models via\ndeclaration of concepts and links between them is proposed, and usefulness of\ndeclarative knowledge for achieving efficient inference is briefly discussed.\n", "versions": [{"version": "v1", "created": "Wed, 4 May 2016 08:34:17 GMT"}], "update_date": "2016-05-05", "authors_parsed": [["Potapov", "Alexey", ""]]}, {"id": "1605.01207", "submitter": "Stanislav Kikot", "authors": "Meghyn Bienvenu, Stanislav Kikot, Roman Kontchakov, Vladimir Podolskii\n  and Michael Zakharyaschev", "title": "Ontology-Mediated Queries: Combined Complexity and Succinctness of\n  Rewritings via Circuit Complexity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.AI cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give solutions to two fundamental computational problems in ontology-based\ndata access with the W3C standard ontology language OWL 2 QL: the succinctness\nproblem for first-order rewritings of ontology-mediated queries (OMQs), and the\ncomplexity problem for OMQ answering. We classify OMQs according to the shape\nof their conjunctive queries (treewidth, the number of leaves) and the\nexistential depth of their ontologies. For each of these classes, we determine\nthe combined complexity of OMQ answering, and whether all OMQs in the class\nhave polynomial-size first-order, positive existential, and nonrecursive\ndatalog rewritings. We obtain the succinctness results using hypergraph\nprograms, a new computational model for Boolean functions, which makes it\npossible to connect the size of OMQ rewritings and circuit complexity.\n", "versions": [{"version": "v1", "created": "Wed, 4 May 2016 10:10:37 GMT"}], "update_date": "2016-05-05", "authors_parsed": [["Bienvenu", "Meghyn", ""], ["Kikot", "Stanislav", ""], ["Kontchakov", "Roman", ""], ["Podolskii", "Vladimir", ""], ["Zakharyaschev", "Michael", ""]]}, {"id": "1605.01335", "submitter": "Jakub Sygnowski", "authors": "Jakub Sygnowski and Henryk Michalewski", "title": "Learning from the memory of Atari 2600", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We train a number of neural networks to play games Bowling, Breakout and\nSeaquest using information stored in the memory of a video game console Atari\n2600. We consider four models of neural networks which differ in size and\narchitecture: two networks which use only information contained in the RAM and\ntwo mixed networks which use both information in the RAM and information from\nthe screen. As the benchmark we used the convolutional model proposed in NIPS\nand received comparable results in all considered games. Quite surprisingly, in\nthe case of Seaquest we were able to train RAM-only agents which behave better\nthan the benchmark screen-only agent. Mixing screen and RAM did not lead to an\nimproved performance comparing to screen-only and RAM-only agents.\n", "versions": [{"version": "v1", "created": "Wed, 4 May 2016 16:23:34 GMT"}], "update_date": "2016-05-05", "authors_parsed": [["Sygnowski", "Jakub", ""], ["Michalewski", "Henryk", ""]]}, {"id": "1605.01459", "submitter": "Laurel Riek", "authors": "Tariq Iqbal, Samantha Rack, and Laurel D. Riek", "title": "Movement Coordination in Human-Robot Teams: A Dynamical Systems Approach", "comments": "11 pages, 7 figures, IEEE Transactions on Robotics 2016 preprint", "journal-ref": null, "doi": "10.1109/TRO.2016.2570240", "report-no": null, "categories": "cs.RO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In order to be effective teammates, robots need to be able to understand\nhigh-level human behavior to recognize, anticipate, and adapt to human motion.\nWe have designed a new approach to enable robots to perceive human group motion\nin real-time, anticipate future actions, and synthesize their own motion\naccordingly. We explore this within the context of joint action, where humans\nand robots move together synchronously. In this paper, we present an\nanticipation method which takes high-level group behavior into account. We\nvalidate the method within a human-robot interaction scenario, where an\nautonomous mobile robot observes a team of human dancers, and then successfully\nand contingently coordinates its movements to \"join the dance\". We compared the\nresults of our anticipation method to move the robot with another method which\ndid not rely on high-level group behavior, and found our method performed\nbetter both in terms of more closely synchronizing the robot's motion to the\nteam, and also exhibiting more contingent and fluent motion. These findings\nsuggest that the robot performs better when it has an understanding of\nhigh-level group behavior than when it does not. This work will help enable\nothers in the robotics community to build more fluent and adaptable robots in\nthe future.\n", "versions": [{"version": "v1", "created": "Wed, 4 May 2016 23:48:16 GMT"}], "update_date": "2016-11-15", "authors_parsed": [["Iqbal", "Tariq", ""], ["Rack", "Samantha", ""], ["Riek", "Laurel D.", ""]]}, {"id": "1605.01534", "submitter": "Mohit Yadav", "authors": "Mohit Yadav, Pankaj Malhotra, Lovekesh Vig, K Sriram, and Gautam\n  Shroff", "title": "ODE - Augmented Training Improves Anomaly Detection in Sensor Data from\n  Machines", "comments": "Published at NIPS Time-series Workshop - 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machines of all kinds from vehicles to industrial equipment are increasingly\ninstrumented with hundreds of sensors. Using such data to detect anomalous\nbehaviour is critical for safety and efficient maintenance. However, anomalies\noccur rarely and with great variety in such systems, so there is often\ninsufficient anomalous data to build reliable detectors. A standard approach to\nmitigate this problem is to use one class methods relying only on data from\nnormal behaviour. Unfortunately, even these approaches are more likely to fail\nin the scenario of a dynamical system with manual control input(s). Normal\nbehaviour in response to novel control input(s) might look very different to\nthe learned detector which may be incorrectly detected as anomalous. In this\npaper, we address this issue by modelling time-series via Ordinary Differential\nEquations (ODE) and utilising such an ODE model to simulate the behaviour of\ndynamical systems under varying control inputs. The available data is then\naugmented with data generated from the ODE, and the anomaly detector is\nretrained on this augmented dataset. Experiments demonstrate that ODE-augmented\ntraining data allows better coverage of possible control input(s) and results\nin learning more accurate distinctions between normal and anomalous behaviour\nin time-series.\n", "versions": [{"version": "v1", "created": "Thu, 5 May 2016 09:15:55 GMT"}], "update_date": "2016-05-06", "authors_parsed": [["Yadav", "Mohit", ""], ["Malhotra", "Pankaj", ""], ["Vig", "Lovekesh", ""], ["Sriram", "K", ""], ["Shroff", "Gautam", ""]]}, {"id": "1605.01596", "submitter": "Gianluca Caterina", "authors": "Vittorio Cafagna, Gianluca Caterina", "title": "Notes on a model for fuzzy computing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In these notes we propose a setting for fuzzy computing in a framework\nsimilar to that of well-established theories of computation: boolean, and\nquantum computing. Our efforts have been directed towards stressing the formal\nsimilarities: there is a common pattern underlying these three theories. We\ntried to conform our approach, as much as possible, to this pattern. This work\nwas part of a project jointly with Professor Vittorio Cafagna. Professor\nCafagna passed away unexpectedly in 2007. His intellectual breadth and\ninspiring passion for mathematics is still very well alive.\n", "versions": [{"version": "v1", "created": "Wed, 4 May 2016 16:16:10 GMT"}], "update_date": "2016-05-06", "authors_parsed": [["Cafagna", "Vittorio", ""], ["Caterina", "Gianluca", ""]]}, {"id": "1605.01622", "submitter": "Jingchao Chen", "authors": "Jingchao Chen", "title": "Improving abcdSAT by At-Least-One Recently Used Clause Management\n  Strategy", "comments": "2 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We improve further the 2015 version of abcdSAT by various heuristics such as\nat-least-one recently used strategy, learnt clause database approximation\nreduction etc. Based on the requirement of different tracks at the SAT\nCompetition 2016, we develop three versions of abcdSAT: drup, inc and lim,\nwhich participate in the competition of main (agile), incremental library and\nno-limit track, respectively.\n", "versions": [{"version": "v1", "created": "Thu, 5 May 2016 15:20:33 GMT"}], "update_date": "2016-05-06", "authors_parsed": [["Chen", "Jingchao", ""]]}, {"id": "1605.01652", "submitter": "Phong Le", "authors": "Phong Le, Marc Dymetman, Jean-Michel Renders", "title": "LSTM-based Mixture-of-Experts for Knowledge-Aware Dialogues", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce an LSTM-based method for dynamically integrating several\nword-prediction experts to obtain a conditional language model which can be\ngood simultaneously at several subtasks. We illustrate this general approach\nwith an application to dialogue where we integrate a neural chat model, good at\nconversational aspects, with a neural question-answering model, good at\nretrieving precise information from a knowledge-base, and show how the\nintegration combines the strengths of the independent components. We hope that\nthis focused contribution will attract attention on the benefits of using such\nmixtures of experts in NLP.\n", "versions": [{"version": "v1", "created": "Thu, 5 May 2016 17:00:44 GMT"}], "update_date": "2016-05-06", "authors_parsed": [["Le", "Phong", ""], ["Dymetman", "Marc", ""], ["Renders", "Jean-Michel", ""]]}, {"id": "1605.01681", "submitter": "Mahboobeh Parsapoor", "authors": "Mahboobeh Parsapoor", "title": "Brain Emotional Learning-Based Prediction Model (For Long-Term Chaotic\n  Prediction Applications)", "comments": "14 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This study suggests a new prediction model for chaotic time series inspired\nby the brain emotional learning of mammals. We describe the structure and\nfunction of this model, which is referred to as BELPM (Brain Emotional\nLearning-Based Prediction Model). Structurally, the model mimics the connection\nbetween the regions of the limbic system, and functionally it uses weighted k\nnearest neighbors to imitate the roles of those regions. The learning algorithm\nof BELPM is defined using steepest descent (SD) and the least square estimator\n(LSE). Two benchmark chaotic time series, Lorenz and Henon, have been used to\nevaluate the performance of BELPM. The obtained results have been compared with\nthose of other prediction methods. The results show that BELPM has the\ncapability to achieve a reasonable accuracy for long-term prediction of chaotic\ntime series, using a limited amount of training data and a reasonably low\ncomputational time.\n", "versions": [{"version": "v1", "created": "Thu, 5 May 2016 18:29:56 GMT"}], "update_date": "2020-05-27", "authors_parsed": [["Parsapoor", "Mahboobeh", ""]]}, {"id": "1605.01703", "submitter": "Indre Zliobaite", "authors": "Indre Zliobaite and Nikolaj Tatti", "title": "A note on adjusting $R^2$ for using with cross-validation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show how to adjust the coefficient of determination ($R^2$) when used for\nmeasuring predictive accuracy via leave-one-out cross-validation.\n", "versions": [{"version": "v1", "created": "Thu, 5 May 2016 19:34:08 GMT"}], "update_date": "2016-05-06", "authors_parsed": [["Zliobaite", "Indre", ""], ["Tatti", "Nikolaj", ""]]}, {"id": "1605.01778", "submitter": "Mani A", "authors": "A. Mani", "title": "Combinatorial Aspects of the Distribution of Rough Objects", "comments": "17 Pages, 5 Figures, Preprint This version has since been\n  substantially revised. Please wait for new version to appear", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.IT math.CO math.IT math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The inverse problem of general rough sets, considered by the present author\nin some of her earlier papers, in one of its manifestations is essentially the\nquestion of when an agent's view about crisp and non crisp objects over a set\nof objects has a rough evolution. In this research the nature of the problem is\nexamined from number-theoretic and combinatorial perspectives under very few\nassumptions about the nature of data and some necessary conditions are proved.\n", "versions": [{"version": "v1", "created": "Thu, 5 May 2016 22:20:00 GMT"}, {"version": "v2", "created": "Tue, 31 Jan 2017 17:29:41 GMT"}], "update_date": "2017-02-01", "authors_parsed": [["Mani", "A.", ""]]}, {"id": "1605.01846", "submitter": "Pieter Van Hertum", "authors": "Pieter Van Hertum, Ingmar Dasseville, Gerda Janssens, Marc Denecker", "title": "The KB paradigm and its application to interactive configuration", "comments": "To appear in Theory and Practice of Logic Programming (TPLP)", "journal-ref": null, "doi": "10.1017/S1471068416000156", "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The knowledge base paradigm aims to express domain knowledge in a rich formal\nlanguage, and to use this domain knowledge as a knowledge base to solve various\nproblems and tasks that arise in the domain by applying multiple forms of\ninference. As such, the paradigm applies a strict separation of concerns\nbetween information and problem solving. In this paper, we analyze the\nprinciples and feasibility of the knowledge base paradigm in the context of an\nimportant class of applications: interactive configuration problems. In\ninteractive configuration problems, a configuration of interrelated objects\nunder constraints is searched, where the system assists the user in reaching an\nintended configuration. It is widely recognized in industry that good software\nsolutions for these problems are very difficult to develop. We investigate such\nproblems from the perspective of the KB paradigm. We show that multiple\nfunctionalities in this domain can be achieved by applying different forms of\nlogical inferences on a formal specification of the configuration domain. We\nreport on a proof of concept of this approach in a real-life application with a\nbanking company. To appear in Theory and Practice of Logic Programming (TPLP).\n", "versions": [{"version": "v1", "created": "Fri, 6 May 2016 07:39:19 GMT"}], "update_date": "2016-07-06", "authors_parsed": [["Van Hertum", "Pieter", ""], ["Dasseville", "Ingmar", ""], ["Janssens", "Gerda", ""], ["Denecker", "Marc", ""]]}, {"id": "1605.01939", "submitter": "Elena Mocanu", "authors": "Elena Mocanu, Phuong H. Nguyen, Madeleine Gibescu", "title": "Energy Disaggregation for Real-Time Building Flexibility Detection", "comments": "To appear in IEEE PES General Meeting, 2016, Boston, USA", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Energy is a limited resource which has to be managed wisely, taking into\naccount both supply-demand matching and capacity constraints in the\ndistribution grid. One aspect of the smart energy management at the building\nlevel is given by the problem of real-time detection of flexible demand\navailable. In this paper we propose the use of energy disaggregation techniques\nto perform this task. Firstly, we investigate the use of existing\nclassification methods to perform energy disaggregation. A comparison is\nperformed between four classifiers, namely Naive Bayes, k-Nearest Neighbors,\nSupport Vector Machine and AdaBoost. Secondly, we propose the use of Restricted\nBoltzmann Machine to automatically perform feature extraction. The extracted\nfeatures are then used as inputs to the four classifiers and consequently shown\nto improve their accuracy. The efficiency of our approach is demonstrated on a\nreal database consisting of detailed appliance-level measurements with high\ntemporal resolution, which has been used for energy disaggregation in previous\nstudies, namely the REDD. The results show robustness and good generalization\ncapabilities to newly presented buildings with at least 96% accuracy.\n", "versions": [{"version": "v1", "created": "Fri, 6 May 2016 13:52:45 GMT"}], "update_date": "2016-05-09", "authors_parsed": [["Mocanu", "Elena", ""], ["Nguyen", "Phuong H.", ""], ["Gibescu", "Madeleine", ""]]}, {"id": "1605.01995", "submitter": "Yanjing Wang", "authors": "Yanjing Wang", "title": "Beyond knowing that: a new generation of epistemic logics", "comments": "36 pages, to appear in Jaakko Hintikka on knowledge and game\n  theoretical semantics, Springer's Outstanding Contributions to Logic Series\n  (some references are updated in this version)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Epistemic logic has become a major field of philosophical logic ever since\nthe groundbreaking work by Hintikka (1962). Despite its various successful\napplications in theoretical computer science, AI, and game theory, the\ntechnical development of the field has been mainly focusing on the\npropositional part, i.e., the propositional modal logics of \"knowing that\".\nHowever, knowledge is expressed in everyday life by using various other\nlocutions such as \"knowing whether\", \"knowing what\", \"knowing how\" and so on\n(knowing-wh hereafter). Such knowledge expressions are better captured in\nquantified epistemic logic, as was already discussed by Hintikka (1962) and his\nsequel works at length. This paper aims to draw the attention back again to\nsuch a fascinating but largely neglected topic. We first survey what Hintikka\nand others did in the literature of quantified epistemic logic, and then\nadvocate a new quantifier-free approach to study the epistemic logics of\nknowing-wh, which we believe can balance expressivity and complexity, and\ncapture the essential reasoning patterns about knowing-wh. We survey our recent\nline of work on the epistemic logics of \"knowing whether\", \"knowing what\" and\n\"knowing how\" to demonstrate the use of this new approach.\n", "versions": [{"version": "v1", "created": "Fri, 6 May 2016 16:24:03 GMT"}, {"version": "v2", "created": "Fri, 17 Jun 2016 02:23:48 GMT"}, {"version": "v3", "created": "Wed, 23 Nov 2016 08:54:01 GMT"}], "update_date": "2016-11-24", "authors_parsed": [["Wang", "Yanjing", ""]]}, {"id": "1605.02038", "submitter": "Daniel Karapetyan Dr", "authors": "Daniel Karapetyan and Abraham P. Punnen and Andrew J. Parkes", "title": "Markov Chain methods for the bipartite Boolean quadratic programming\n  problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the Bipartite Boolean Quadratic Programming Problem (BBQP) which is\nan extension of the well known Boolean Quadratic Programming Problem (BQP).\nApplications of the BBQP include mining discrete patterns from binary data,\napproximating matrices by rank-one binary matrices, computing the cut-norm of a\nmatrix, and solving optimisation problems such as maximum weight biclique,\nbipartite maximum weight cut, maximum weight induced sub-graph of a bipartite\ngraph, etc. For the BBQP, we first present several algorithmic components,\nspecifically, hill climbers and mutations, and then show how to combine them in\na high-performance metaheuristic. Instead of hand-tuning a standard\nmetaheuristic to test the efficiency of the hybrid of the components, we chose\nto use an automated generation of a multi-component metaheuristic to save human\ntime, and also improve objectivity in the analysis and comparisons of\ncomponents. For this we designed a new metaheuristic schema which we call\nConditional Markov Chain Search (CMCS). We show that CMCS is flexible enough to\nmodel several standard metaheuristics; this flexibility is controlled by\nmultiple numeric parameters, and so is convenient for automated generation. We\nstudy the configurations revealed by our approach and show that the best of\nthem outperforms the previous state-of-the-art BBQP algorithm by several orders\nof magnitude. In our experiments we use benchmark instances introduced in the\npreliminary version of this paper and described here, which have already become\nthe de facto standard in the BBQP literature.\n", "versions": [{"version": "v1", "created": "Fri, 6 May 2016 19:06:56 GMT"}, {"version": "v2", "created": "Mon, 24 Oct 2016 18:44:11 GMT"}], "update_date": "2016-10-25", "authors_parsed": [["Karapetyan", "Daniel", ""], ["Punnen", "Abraham P.", ""], ["Parkes", "Andrew J.", ""]]}, {"id": "1605.02046", "submitter": "Mahdi Jafari Siavoshani", "authors": "Farzin Haddadpour, Mahdi Jafari Siavoshani, Morteza Noshad", "title": "Low-Complexity Stochastic Generalized Belief Propagation", "comments": "18 pages, 11 figures, a shorter version of this paper was accepted in\n  ISIT'16", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The generalized belief propagation (GBP), introduced by Yedidia et al., is an\nextension of the belief propagation (BP) algorithm, which is widely used in\ndifferent problems involved in calculating exact or approximate marginals of\nprobability distributions. In many problems, it has been observed that the\naccuracy of GBP considerably outperforms that of BP. However, because in\ngeneral the computational complexity of GBP is higher than BP, its application\nis limited in practice.\n  In this paper, we introduce a stochastic version of GBP called stochastic\ngeneralized belief propagation (SGBP) that can be considered as an extension to\nthe stochastic BP (SBP) algorithm introduced by Noorshams et al. They have\nshown that SBP reduces the complexity per iteration of BP by an order of\nmagnitude in alphabet size. In contrast to SBP, SGBP can reduce the computation\ncomplexity if certain topological conditions are met by the region graph\nassociated to a graphical model. However, this reduction can be larger than\nonly one order of magnitude in alphabet size. In this paper, we characterize\nthese conditions and the amount of computation gain that we can obtain by using\nSGBP. Finally, using similar proof techniques employed by Noorshams et al., for\ngeneral graphical models satisfy contraction conditions, we prove the\nasymptotic convergence of SGBP to the unique GBP fixed point, as well as\nproviding non-asymptotic upper bounds on the mean square error and on the high\nprobability error.\n", "versions": [{"version": "v1", "created": "Fri, 6 May 2016 19:17:33 GMT"}], "update_date": "2016-05-09", "authors_parsed": [["Haddadpour", "Farzin", ""], ["Siavoshani", "Mahdi Jafari", ""], ["Noshad", "Morteza", ""]]}, {"id": "1605.02097", "submitter": "Wojciech Ja\\'skowski", "authors": "Micha{\\l} Kempka, Marek Wydmuch, Grzegorz Runc, Jakub Toczek and\n  Wojciech Ja\\'skowski", "title": "ViZDoom: A Doom-based AI Research Platform for Visual Reinforcement\n  Learning", "comments": null, "journal-ref": "Proceedings of IEEE Conference of Computational Intelligence in\n  Games 2016", "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recent advances in deep neural networks have led to effective\nvision-based reinforcement learning methods that have been employed to obtain\nhuman-level controllers in Atari 2600 games from pixel data. Atari 2600 games,\nhowever, do not resemble real-world tasks since they involve non-realistic 2D\nenvironments and the third-person perspective. Here, we propose a novel\ntest-bed platform for reinforcement learning research from raw visual\ninformation which employs the first-person perspective in a semi-realistic 3D\nworld. The software, called ViZDoom, is based on the classical first-person\nshooter video game, Doom. It allows developing bots that play the game using\nthe screen buffer. ViZDoom is lightweight, fast, and highly customizable via a\nconvenient mechanism of user scenarios. In the experimental part, we test the\nenvironment by trying to learn bots for two scenarios: a basic move-and-shoot\ntask and a more complex maze-navigation problem. Using convolutional deep\nneural networks with Q-learning and experience replay, for both scenarios, we\nwere able to train competent bots, which exhibit human-like behaviors. The\nresults confirm the utility of ViZDoom as an AI research platform and imply\nthat visual reinforcement learning in 3D realistic first-person perspective\nenvironments is feasible.\n", "versions": [{"version": "v1", "created": "Fri, 6 May 2016 20:46:34 GMT"}, {"version": "v2", "created": "Tue, 20 Sep 2016 19:12:49 GMT"}], "update_date": "2016-09-21", "authors_parsed": [["Kempka", "Micha\u0142", ""], ["Wydmuch", "Marek", ""], ["Runc", "Grzegorz", ""], ["Toczek", "Jakub", ""], ["Ja\u015bkowski", "Wojciech", ""]]}, {"id": "1605.02129", "submitter": "Franck Dernoncourt", "authors": "Franck Dernoncourt, Ji Young Lee, Trung H. Bui, and Hung H. Bui", "title": "Adobe-MIT submission to the DSTC 4 Spoken Language Understanding pilot\n  task", "comments": "Paper accepted at IWSDS 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Dialog State Tracking Challenge 4 (DSTC 4) proposes several pilot tasks.\nIn this paper, we focus on the spoken language understanding pilot task, which\nconsists of tagging a given utterance with speech acts and semantic slots. We\ncompare different classifiers: the best system obtains 0.52 and 0.67 F1-scores\non the test set for speech act recognition for the tourist and the guide\nrespectively, and 0.52 F1-score for semantic tagging for both the guide and the\ntourist.\n", "versions": [{"version": "v1", "created": "Sat, 7 May 2016 01:55:51 GMT"}], "update_date": "2016-05-10", "authors_parsed": [["Dernoncourt", "Franck", ""], ["Lee", "Ji Young", ""], ["Bui", "Trung H.", ""], ["Bui", "Hung H.", ""]]}, {"id": "1605.02130", "submitter": "Franck Dernoncourt", "authors": "Franck Dernoncourt, Ji Young Lee, Trung H. Bui, Hung H. Bui", "title": "Robust Dialog State Tracking for Large Ontologies", "comments": "Paper accepted at IWSDS 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Dialog State Tracking Challenge 4 (DSTC 4) differentiates itself from the\nprevious three editions as follows: the number of slot-value pairs present in\nthe ontology is much larger, no spoken language understanding output is given,\nand utterances are labeled at the subdialog level. This paper describes a novel\ndialog state tracking method designed to work robustly under these conditions,\nusing elaborate string matching, coreference resolution tailored for dialogs\nand a few other improvements. The method can correctly identify many values\nthat are not explicitly present in the utterance. On the final evaluation, our\nmethod came in first among 7 competing teams and 24 entries. The F1-score\nachieved by our method was 9 and 7 percentage points higher than that of the\nrunner-up for the utterance-level evaluation and for the subdialog-level\nevaluation, respectively.\n", "versions": [{"version": "v1", "created": "Sat, 7 May 2016 02:00:30 GMT"}], "update_date": "2016-05-10", "authors_parsed": [["Dernoncourt", "Franck", ""], ["Lee", "Ji Young", ""], ["Bui", "Trung H.", ""], ["Bui", "Hung H.", ""]]}, {"id": "1605.02160", "submitter": "Paolo Liberatore", "authors": "Paolo Liberatore", "title": "Belief Merging by Source Reliability Assessment", "comments": null, "journal-ref": null, "doi": "10.1613/jair.1.11238", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Merging beliefs requires the plausibility of the sources of the information\nto be merged. They are typically assumed equally reliable in lack of hints\nindicating otherwise; yet, a recent line of research spun from the idea of\nderiving this information from the revision process itself. In particular, the\nhistory of previous revisions and previous merging examples provide information\nfor performing subsequent mergings.\n  Yet, no examples or previous revisions may be available. In spite of the\napparent lack of information, something can still be inferred by a\ntry-and-check approach: a relative reliability ordering is assumed, the merging\nprocess is performed based on it, and the result is compared with the original\ninformation. The outcome of this check may be incoherent with the initial\nassumption, like when a completely reliable source is rejected some of the\ninformation it provided. In such cases, the reliability ordering assumed in the\nfirst place can be excluded from consideration. The first theorem of this\narticle proves that such a scenario is indeed possible. Other results are\nobtained under various definition of reliability and merging.\n", "versions": [{"version": "v1", "created": "Sat, 7 May 2016 09:09:08 GMT"}], "update_date": "2021-03-23", "authors_parsed": [["Liberatore", "Paolo", ""]]}, {"id": "1605.02321", "submitter": "Yun-Ching Liu", "authors": "Yun-Ching Liu and Yoshimasa Tsuruoka", "title": "Asymmetric Move Selection Strategies in Monte-Carlo Tree Search:\n  Minimizing the Simple Regret at Max Nodes", "comments": "submitted to the 2016 IEEE Computational Intelligence and Games\n  Conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The combination of multi-armed bandit (MAB) algorithms with Monte-Carlo tree\nsearch (MCTS) has made a significant impact in various research fields. The UCT\nalgorithm, which combines the UCB bandit algorithm with MCTS, is a good example\nof the success of this combination. The recent breakthrough made by AlphaGo,\nwhich incorporates convolutional neural networks with bandit algorithms in\nMCTS, also highlights the necessity of bandit algorithms in MCTS. However,\ndespite the various investigations carried out on MCTS, nearly all of them\nstill follow the paradigm of treating every node as an independent instance of\nthe MAB problem, and applying the same bandit algorithm and heuristics on every\nnode. As a result, this paradigm may leave some properties of the game tree\nunexploited. In this work, we propose that max nodes and min nodes have\ndifferent concerns regarding their value estimation, and different bandit\nalgorithms should be applied accordingly. We develop the Asymmetric-MCTS\nalgorithm, which is an MCTS variant that applies a simple regret algorithm on\nmax nodes, and the UCB algorithm on min nodes. We will demonstrate the\nperformance of the Asymmetric-MCTS algorithm on the game of $9\\times 9$ Go,\n$9\\times 9$ NoGo, and Othello.\n", "versions": [{"version": "v1", "created": "Sun, 8 May 2016 13:52:41 GMT"}], "update_date": "2016-05-10", "authors_parsed": [["Liu", "Yun-Ching", ""], ["Tsuruoka", "Yoshimasa", ""]]}, {"id": "1605.02401", "submitter": "Anurag Kumar", "authors": "Anurag Kumar, Bhiksha Raj", "title": "Audio Event Detection using Weakly Labeled Data", "comments": "ACM Multimedia 2016", "journal-ref": null, "doi": "10.1145/2964284.2964310", "report-no": null, "categories": "cs.SD cs.AI cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Acoustic event detection is essential for content analysis and description of\nmultimedia recordings. The majority of current literature on the topic learns\nthe detectors through fully-supervised techniques employing strongly labeled\ndata. However, the labels available for majority of multimedia data are\ngenerally weak and do not provide sufficient detail for such methods to be\nemployed. In this paper we propose a framework for learning acoustic event\ndetectors using only weakly labeled data. We first show that audio event\ndetection using weak labels can be formulated as an Multiple Instance Learning\nproblem. We then suggest two frameworks for solving multiple-instance learning,\none based on support vector machines, and the other on neural networks. The\nproposed methods can help in removing the time consuming and expensive process\nof manually annotating data to facilitate fully supervised learning. Moreover,\nit can not only detect events in a recording but can also provide temporal\nlocations of events in the recording. This helps in obtaining a complete\ndescription of the recording and is notable since temporal information was\nnever known in the first place in weakly labeled data.\n", "versions": [{"version": "v1", "created": "Mon, 9 May 2016 02:17:12 GMT"}, {"version": "v2", "created": "Thu, 9 Jun 2016 03:33:13 GMT"}, {"version": "v3", "created": "Wed, 6 Jul 2016 05:46:56 GMT"}], "update_date": "2016-07-07", "authors_parsed": [["Kumar", "Anurag", ""], ["Raj", "Bhiksha", ""]]}, {"id": "1605.02442", "submitter": "Himani Mittal", "authors": "M. Syamala Devi and Himani Mittal", "title": "Machine Learning Techniques with Ontology for Subjective Answer\n  Evaluation", "comments": "11 pages, 5 figures, journal,\n  http://airccse.org/journal/ijnlc/current.html 2016", "journal-ref": null, "doi": "10.5121/ijnlc.2016.5201", "report-no": null, "categories": "cs.AI cs.CL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computerized Evaluation of English Essays is performed using Machine learning\ntechniques like Latent Semantic Analysis (LSA), Generalized LSA, Bilingual\nEvaluation Understudy and Maximum Entropy. Ontology, a concept map of domain\nknowledge, can enhance the performance of these techniques. Use of Ontology\nmakes the evaluation process holistic as presence of keywords, synonyms, the\nright word combination and coverage of concepts can be checked. In this paper,\nthe above mentioned techniques are implemented both with and without Ontology\nand tested on common input data consisting of technical answers of Computer\nScience. Domain Ontology of Computer Graphics is designed and developed. The\nsoftware used for implementation includes Java Programming Language and tools\nsuch as MATLAB, Prot\\'eg\\'e, etc. Ten questions from Computer Graphics with\nsixty answers for each question are used for testing. The results are analyzed\nand it is concluded that the results are more accurate with use of Ontology.\n", "versions": [{"version": "v1", "created": "Mon, 9 May 2016 07:14:52 GMT"}], "update_date": "2016-05-10", "authors_parsed": [["Devi", "M. Syamala", ""], ["Mittal", "Himani", ""]]}, {"id": "1605.02669", "submitter": "Rafa{\\l} Skinderowicz", "authors": "Rafa{\\l} Skinderowicz", "title": "The GPU-based Parallel Ant Colony System", "comments": null, "journal-ref": null, "doi": "10.1016/j.jpdc.2016.04.014", "report-no": null, "categories": "cs.DC cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Ant Colony System (ACS) is, next to Ant Colony Optimization (ACO) and the\nMAX-MIN Ant System (MMAS), one of the most efficient metaheuristic algorithms\ninspired by the behavior of ants. In this article we present three novel\nparallel versions of the ACS for the graphics processing units (GPUs). To the\nbest of our knowledge, this is the first such work on the ACS which shares many\nkey elements of the ACO and the MMAS, but differences in the process of\nbuilding solutions and updating the pheromone trails make obtaining an\nefficient parallel version for the GPUs a difficult task. The proposed parallel\nversions of the ACS differ mainly in their implementations of the pheromone\nmemory. The first two use the standard pheromone matrix, and the third uses a\nnovel selective pheromone memory. Computational experiments conducted on\nseveral Travelling Salesman Problem (TSP) instances of sizes ranging from 198\nto 2392 cities showed that the parallel ACS on Nvidia Kepler GK104 GPU (1536\nCUDA cores) is able to obtain a speedup up to 24.29x vs the sequential ACS\nrunning on a single core of Intel Xeon E5-2670 CPU. The parallel ACS with the\nselective pheromone memory achieved speedups up to 16.85x, but in most cases\nthe obtained solutions were of significantly better quality than for the\nsequential ACS.\n", "versions": [{"version": "v1", "created": "Mon, 9 May 2016 17:41:37 GMT"}, {"version": "v2", "created": "Fri, 5 May 2017 10:43:58 GMT"}], "update_date": "2017-05-08", "authors_parsed": [["Skinderowicz", "Rafa\u0142", ""]]}, {"id": "1605.02677", "submitter": "Quanzeng You", "authors": "Quanzeng You, Jiebo Luo, Hailin Jin, Jianchao Yang", "title": "Building a Large Scale Dataset for Image Emotion Recognition: The Fine\n  Print and The Benchmark", "comments": "7 pages, 7 figures, AAAI 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Psychological research results have confirmed that people can have different\nemotional reactions to different visual stimuli. Several papers have been\npublished on the problem of visual emotion analysis. In particular, attempts\nhave been made to analyze and predict people's emotional reaction towards\nimages. To this end, different kinds of hand-tuned features are proposed. The\nresults reported on several carefully selected and labeled small image data\nsets have confirmed the promise of such features. While the recent successes of\nmany computer vision related tasks are due to the adoption of Convolutional\nNeural Networks (CNNs), visual emotion analysis has not achieved the same level\nof success. This may be primarily due to the unavailability of confidently\nlabeled and relatively large image data sets for visual emotion analysis. In\nthis work, we introduce a new data set, which started from 3+ million weakly\nlabeled images of different emotions and ended up 30 times as large as the\ncurrent largest publicly available visual emotion data set. We hope that this\ndata set encourages further research on visual emotion analysis. We also\nperform extensive benchmarking analyses on this large data set using the state\nof the art methods including CNNs.\n", "versions": [{"version": "v1", "created": "Mon, 9 May 2016 18:14:52 GMT"}], "update_date": "2016-05-10", "authors_parsed": [["You", "Quanzeng", ""], ["Luo", "Jiebo", ""], ["Jin", "Hailin", ""], ["Yang", "Jianchao", ""]]}, {"id": "1605.02697", "submitter": "Mateusz Malinowski", "authors": "Mateusz Malinowski and Marcus Rohrbach and Mario Fritz", "title": "Ask Your Neurons: A Deep Learning Approach to Visual Question Answering", "comments": "Improved version, it also has a final table from the VQA challenge,\n  and more baselines on DAQUAR", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address a question answering task on real-world images that is set up as a\nVisual Turing Test. By combining latest advances in image representation and\nnatural language processing, we propose Ask Your Neurons, a scalable, jointly\ntrained, end-to-end formulation to this problem.\n  In contrast to previous efforts, we are facing a multi-modal problem where\nthe language output (answer) is conditioned on visual and natural language\ninputs (image and question). We provide additional insights into the problem by\nanalyzing how much information is contained only in the language part for which\nwe provide a new human baseline. To study human consensus, which is related to\nthe ambiguities inherent in this challenging task, we propose two novel metrics\nand collect additional answers which extend the original DAQUAR dataset to\nDAQUAR-Consensus.\n  Moreover, we also extend our analysis to VQA, a large-scale question\nanswering about images dataset, where we investigate some particular design\nchoices and show the importance of stronger visual models. At the same time, we\nachieve strong performance of our model that still uses a global image\nrepresentation. Finally, based on such analysis, we refine our Ask Your Neurons\non DAQUAR, which also leads to a better performance on this challenging task.\n", "versions": [{"version": "v1", "created": "Mon, 9 May 2016 19:04:23 GMT"}, {"version": "v2", "created": "Thu, 24 Nov 2016 10:30:18 GMT"}], "update_date": "2016-11-28", "authors_parsed": [["Malinowski", "Mateusz", ""], ["Rohrbach", "Marcus", ""], ["Fritz", "Mario", ""]]}, {"id": "1605.02817", "submitter": "Roman Yampolskiy", "authors": "Federico Pistono, Roman V. Yampolskiy", "title": "Unethical Research: How to Create a Malevolent Artificial Intelligence", "comments": null, "journal-ref": "In proceedings of Ethics for Artificial Intelligence Workshop\n  (AI-Ethics-2016). Pages 1-7. New York, NY. July 9 -- 15, 2016", "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cybersecurity research involves publishing papers about malicious exploits as\nmuch as publishing information on how to design tools to protect\ncyber-infrastructure. It is this information exchange between ethical hackers\nand security experts, which results in a well-balanced cyber-ecosystem. In the\nblooming domain of AI Safety Engineering, hundreds of papers have been\npublished on different proposals geared at the creation of a safe machine, yet\nnothing, to our knowledge, has been published on how to design a malevolent\nmachine. Availability of such information would be of great value particularly\nto computer scientists, mathematicians, and others who have an interest in AI\nsafety, and who are attempting to avoid the spontaneous emergence or the\ndeliberate creation of a dangerous AI, which can negatively affect human\nactivities and in the worst case cause the complete obliteration of the human\nspecies. This paper provides some general guidelines for the creation of a\nMalevolent Artificial Intelligence (MAI).\n", "versions": [{"version": "v1", "created": "Tue, 10 May 2016 01:39:38 GMT"}, {"version": "v2", "created": "Thu, 1 Sep 2016 18:29:13 GMT"}], "update_date": "2017-06-06", "authors_parsed": [["Pistono", "Federico", ""], ["Yampolskiy", "Roman V.", ""]]}, {"id": "1605.02929", "submitter": "Francesc Serratosa", "authors": "Francesc Serratosa", "title": "Function-Described Graphs for Structural Pattern Recognition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present in this article the model Function-described graph (FDG), which is\na type of compact representation of a set of attributed graphs (AGs) that\nborrow from Random Graphs the capability of probabilistic modelling of\nstructural and attribute information. We define the FDGs, their features and\ntwo distance measures between AGs (unclassified patterns) and FDGs (models or\nclasses) and we also explain an efficient matching algorithm. Two applications\nof FDGs are presented: in the former, FDGs are used for modelling and matching\n3D-objects described by multiple views, whereas in the latter, they are used\nfor representing and recognising human faces, described also by several views.\n", "versions": [{"version": "v1", "created": "Tue, 10 May 2016 10:30:06 GMT"}], "update_date": "2016-05-11", "authors_parsed": [["Serratosa", "Francesc", ""]]}, {"id": "1605.03009", "submitter": "Ray Van De Walker Ray Van De Walker", "authors": "Ray Van De Walker", "title": "Consciousness is Pattern Recognition", "comments": "8 pages; Now describes the utility of the proof. Lemma A3 is\n  improved. The root lemma is clarified. Included and excused some basic\n  objections. Reordered the speculations, objections and excuses to be more\n  coherent. Added paragraphs and references to aid some AI paradigms. Added my\n  orcid and revised the abstract", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This is a proof of the strong AI hypothesis, i.e. that machines can be\nconscious. It is a phenomenological proof that pattern-recognition and\nsubjective consciousness are the same activity in different terms. Therefore,\nit proves that essential subjective processes of consciousness are computable,\nand identifies significant traits and requirements of a conscious system. Since\nHusserl, many philosophers have accepted that consciousness consists of\nmemories of logical connections between an ego and external objects. These\nconnections are called \"intentions.\" Pattern recognition systems are achievable\ntechnical artifacts. The proof links this respected introspective philosophical\ntheory of consciousness with technical art. The proof therefore endorses the\nstrong AI hypothesis and may therefore also enable a theoretically-grounded\nform of artificial intelligence called a \"synthetic intentionality,\" able to\nsynthesize, generalize, select and repeat intentions. If the pattern\nrecognition is reflexive, able to operate on the set of intentions, and\nflexible, with several methods of synthesizing intentions, an SI may be a\nparticularly strong form of AI. Similarities and possible applications to\nseveral AI paradigms are discussed. The article then addresses some problems:\nThe proof's limitations, reflexive cognition, Searles' Chinese room, and how an\nSI could \"understand\" \"meanings\" and \"be creative.\"\n", "versions": [{"version": "v1", "created": "Wed, 4 May 2016 20:19:05 GMT"}, {"version": "v2", "created": "Tue, 28 Jun 2016 20:44:09 GMT"}], "update_date": "2016-06-30", "authors_parsed": [["Van De Walker", "Ray", ""]]}, {"id": "1605.03035", "submitter": "Tayeb Lemlouma", "authors": "Haider Mshali, Tayeb Lemlouma, Damien Magoni", "title": "Context-Aware Adaptive Framework for e-Health Monitoring", "comments": "8 pages, Proceedings of the 11th IEEE Global Communications\n  Conference (merged with the IEEE DSDIS2015), Sydney, Australi,11-13 December,\n  2015", "journal-ref": "IEEE International Conference on Data Science and Data Intensive\n  Systems (2015) 276-283", "doi": "10.1109/DSDIS.2015.13", "report-no": null, "categories": "cs.CY cs.AI cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For improving e-health services, we propose a context-aware framework to\nmonitor the activities of daily living of dependent persons. We define a\nstrategy for generating long-term realistic scenarios and a framework\ncontaining an adaptive monitoring algorithm based on three approaches for\noptimizing resource usage. The used approaches provide a deep knowledge about\nthe person's context by considering: the person's profile, the activities and\nthe relationships between activities. We evaluate the performances of our\nframework and show its adaptability and significant reduction in network,\nenergy and processing usage over a traditional monitoring implementation.\n", "versions": [{"version": "v1", "created": "Tue, 10 May 2016 14:37:16 GMT"}], "update_date": "2018-06-13", "authors_parsed": [["Mshali", "Haider", ""], ["Lemlouma", "Tayeb", ""], ["Magoni", "Damien", ""]]}, {"id": "1605.03142", "submitter": "Tom Everitt", "authors": "Tom Everitt, Daniel Filan, Mayank Daswani, Marcus Hutter", "title": "Self-Modification of Policy and Utility Function in Rational Agents", "comments": "Artificial General Intelligence (AGI) 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Any agent that is part of the environment it interacts with and has versatile\nactuators (such as arms and fingers), will in principle have the ability to\nself-modify -- for example by changing its own source code. As we continue to\ncreate more and more intelligent agents, chances increase that they will learn\nabout this ability. The question is: will they want to use it? For example,\nhighly intelligent systems may find ways to change their goals to something\nmore easily achievable, thereby `escaping' the control of their designers. In\nan important paper, Omohundro (2008) argued that goal preservation is a\nfundamental drive of any intelligent system, since a goal is more likely to be\nachieved if future versions of the agent strive towards the same goal. In this\npaper, we formalise this argument in general reinforcement learning, and\nexplore situations where it fails. Our conclusion is that the self-modification\npossibility is harmless if and only if the value function of the agent\nanticipates the consequences of self-modifications and use the current utility\nfunction when evaluating the future.\n", "versions": [{"version": "v1", "created": "Tue, 10 May 2016 18:25:49 GMT"}], "update_date": "2016-05-11", "authors_parsed": [["Everitt", "Tom", ""], ["Filan", "Daniel", ""], ["Daswani", "Mayank", ""], ["Hutter", "Marcus", ""]]}, {"id": "1605.03143", "submitter": "Tom Everitt", "authors": "Tom Everitt, Marcus Hutter", "title": "Avoiding Wireheading with Value Reinforcement Learning", "comments": "Artificial General Intelligence (AGI) 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  How can we design good goals for arbitrarily intelligent agents?\nReinforcement learning (RL) is a natural approach. Unfortunately, RL does not\nwork well for generally intelligent agents, as RL agents are incentivised to\nshortcut the reward sensor for maximum reward -- the so-called wireheading\nproblem. In this paper we suggest an alternative to RL called value\nreinforcement learning (VRL). In VRL, agents use the reward signal to learn a\nutility function. The VRL setup allows us to remove the incentive to wirehead\nby placing a constraint on the agent's actions. The constraint is defined in\nterms of the agent's belief distributions, and does not require an explicit\nspecification of which actions constitute wireheading.\n", "versions": [{"version": "v1", "created": "Tue, 10 May 2016 18:28:57 GMT"}], "update_date": "2016-05-11", "authors_parsed": [["Everitt", "Tom", ""], ["Hutter", "Marcus", ""]]}, {"id": "1605.03269", "submitter": "Junpei Zhong", "authors": "Junpei Zhong and Rony Novianto and Mingjun Dai and Xinzheng Zhang and\n  Angelo Cangelosi", "title": "A Hierarchical Emotion Regulated Sensorimotor Model: Case Studies", "comments": "Accepted at The 5th International Conference on Data-Driven Control\n  and Learning Systems. 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inspired by the hierarchical cognitive architecture and the perception-action\nmodel (PAM), we propose that the internal status acts as a kind of\ncommon-coding representation which affects, mediates and even regulates the\nsensorimotor behaviours. These regulation can be depicted in the Bayesian\nframework, that is why cognitive agents are able to generate behaviours with\nsubtle differences according to their emotion or recognize the emotion by\nperception. A novel recurrent neural network called recurrent neural network\nwith parametric bias units (RNNPB) runs in three modes, constructing a\ntwo-level emotion regulated learning model, was further applied to testify this\ntheory in two different cases.\n", "versions": [{"version": "v1", "created": "Wed, 11 May 2016 03:22:13 GMT"}], "update_date": "2016-05-12", "authors_parsed": [["Zhong", "Junpei", ""], ["Novianto", "Rony", ""], ["Dai", "Mingjun", ""], ["Zhang", "Xinzheng", ""], ["Cangelosi", "Angelo", ""]]}, {"id": "1605.03392", "submitter": "Mauro Scanagatta", "authors": "Mauro Scanagatta, Giorgio Corani, Cassio P. de Campos, Marco Zaffalon", "title": "Learning Bounded Treewidth Bayesian Networks with Thousands of Variables", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a method for learning treewidth-bounded Bayesian networks from\ndata sets containing thousands of variables. Bounding the treewidth of a\nBayesian greatly reduces the complexity of inferences. Yet, being a global\nproperty of the graph, it considerably increases the difficulty of the learning\nprocess. We propose a novel algorithm for this task, able to scale to large\ndomains and large treewidths. Our novel approach consistently outperforms the\nstate of the art on data sets with up to ten thousand variables.\n", "versions": [{"version": "v1", "created": "Wed, 11 May 2016 11:54:26 GMT"}], "update_date": "2016-05-12", "authors_parsed": [["Scanagatta", "Mauro", ""], ["Corani", "Giorgio", ""], ["de Campos", "Cassio P.", ""], ["Zaffalon", "Marco", ""]]}, {"id": "1605.03416", "submitter": "Barco You Mr.", "authors": "Jie You, Xin Yang, Matthias Hub", "title": "Concept based Attention", "comments": "7 pages, 2 figures", "journal-ref": "NeuroSci.Proc.Suppl. 89 (2007) 4-11", "doi": null, "report-no": "CS-5230-481", "categories": "cs.AI q-bio.NC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Attention endows animals an ability to concentrate on the most relevant\ninformation among a deluge of distractors at any given time, either through\nvolitionally 'top-down' biasing, or driven by automatically 'bottom-up'\nsaliency of stimuli, in favour of advantageous competition in neural\nmodulations for information processing. Nevertheless, instead of being limited\nto perceive simple features, human and other advanced animals adaptively learn\nthe world into categories and abstract concepts from experiences, imparting the\nworld meanings. This thesis suggests that the high-level cognitive ability of\nhuman is more likely driven by attention basing on abstract perceptions, which\nis defined as concept based attention (CbA).\n", "versions": [{"version": "v1", "created": "Wed, 11 May 2016 12:51:19 GMT"}], "update_date": "2016-05-13", "authors_parsed": [["You", "Jie", ""], ["Yang", "Xin", ""], ["Hub", "Matthias", ""]]}, {"id": "1605.03468", "submitter": "Yanjun  Qi Dr.", "authors": "Beilun Wang, Ritambhara Singh and Yanjun Qi", "title": "A constrained L1 minimization approach for estimating multiple Sparse\n  Gaussian or Nonparanormal Graphical Models", "comments": "Extended Journal Version / Previously @ ICML 2016 comp. bio workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Identifying context-specific entity networks from aggregated data is an\nimportant task, arising often in bioinformatics and neuroimaging.\nComputationally, this task can be formulated as jointly estimating multiple\ndifferent, but related, sparse Undirected Graphical Models (UGM) from\naggregated samples across several contexts. Previous joint-UGM studies have\nmostly focused on sparse Gaussian Graphical Models (sGGMs) and can't identify\ncontext-specific edge patterns directly. We, therefore, propose a novel\napproach, SIMULE (detecting Shared and Individual parts of MULtiple graphs\nExplicitly) to learn multi-UGM via a constrained L1 minimization. SIMULE\nautomatically infers both specific edge patterns that are unique to each\ncontext and shared interactions preserved among all the contexts. Through the\nL1 constrained formulation, this problem is cast as multiple independent\nsubtasks of linear programming that can be solved efficiently in parallel. In\naddition to Gaussian data, SIMULE can also handle multivariate Nonparanormal\ndata that greatly relaxes the normality assumption that many real-world\napplications do not follow. We provide a novel theoretical proof showing that\nSIMULE achieves a consistent result at the rate O(log(Kp)/n_{tot}). On multiple\nsynthetic datasets and two biomedical datasets, SIMULE shows significant\nimprovement over state-of-the-art multi-sGGM and single-UGM baselines.\n", "versions": [{"version": "v1", "created": "Wed, 11 May 2016 14:54:44 GMT"}, {"version": "v2", "created": "Sun, 22 May 2016 11:05:24 GMT"}, {"version": "v3", "created": "Thu, 2 Jun 2016 21:40:33 GMT"}, {"version": "v4", "created": "Tue, 18 Oct 2016 18:11:38 GMT"}, {"version": "v5", "created": "Wed, 8 Mar 2017 20:34:04 GMT"}, {"version": "v6", "created": "Mon, 18 Sep 2017 11:29:14 GMT"}], "update_date": "2017-09-19", "authors_parsed": [["Wang", "Beilun", ""], ["Singh", "Ritambhara", ""], ["Qi", "Yanjun", ""]]}, {"id": "1605.03498", "submitter": "Micael Carvalho", "authors": "Micael Carvalho, Matthieu Cord, Sandra Avila, Nicolas Thome, Eduardo\n  Valle", "title": "Deep Neural Networks Under Stress", "comments": "This article corresponds to the accepted version at IEEE ICIP 2016.\n  We will link the DOI as soon as it is available", "journal-ref": null, "doi": "10.1109/ICIP.2016.7533200", "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, deep architectures have been used for transfer learning with\nstate-of-the-art performance in many datasets. The properties of their features\nremain, however, largely unstudied under the transfer perspective. In this\nwork, we present an extensive analysis of the resiliency of feature vectors\nextracted from deep models, with special focus on the trade-off between\nperformance and compression rate. By introducing perturbations to image\ndescriptions extracted from a deep convolutional neural network, we change\ntheir precision and number of dimensions, measuring how it affects the final\nscore. We show that deep features are more robust to these disturbances when\ncompared to classical approaches, achieving a compression rate of 98.4%, while\nlosing only 0.88% of their original score for Pascal VOC 2007.\n", "versions": [{"version": "v1", "created": "Wed, 11 May 2016 16:22:23 GMT"}, {"version": "v2", "created": "Mon, 23 May 2016 08:34:50 GMT"}], "update_date": "2016-11-17", "authors_parsed": [["Carvalho", "Micael", ""], ["Cord", "Matthieu", ""], ["Avila", "Sandra", ""], ["Thome", "Nicolas", ""], ["Valle", "Eduardo", ""]]}, {"id": "1605.03506", "submitter": "Felix Diaz Hermida", "authors": "F. Diaz-Hermida and M. Pereira-Fari\\~na and Juan C. Vidal and A.\n  Ramos-Soto", "title": "Characterizing Quantifier Fuzzification Mechanisms: a behavioral guide\n  for practical applications", "comments": "28 pages", "journal-ref": "2017, Elsevier. Fuzzy Sets and Systems", "doi": "10.1016/j.fss.2017.07.017", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Important advances have been made in the fuzzy quantification field.\nNevertheless, some problems remain when we face the decision of selecting the\nmost convenient model for a specific application. In the literature, several\ndesirable adequacy properties have been proposed, but theoretical limits impede\nquantification models from simultaneously fulfilling every adequacy property\nthat has been defined. Besides, the complexity of model definitions and\nadequacy properties makes very difficult for real users to understand the\nparticularities of the different models that have been presented. In this work\nwe will present several criteria conceived to help in the process of selecting\nthe most adequate Quantifier Fuzzification Mechanisms for specific practical\napplications. In addition, some of the best known well-behaved models will be\ncompared against this list of criteria. Based on this analysis, some guidance\nto choose fuzzy quantification models for practical applications will be\nprovided.\n", "versions": [{"version": "v1", "created": "Wed, 11 May 2016 16:42:37 GMT"}], "update_date": "2019-02-19", "authors_parsed": [["Diaz-Hermida", "F.", ""], ["Pereira-Fari\u00f1a", "M.", ""], ["Vidal", "Juan C.", ""], ["Ramos-Soto", "A.", ""]]}, {"id": "1605.03661", "submitter": "Fredrik D. Johansson", "authors": "Fredrik D. Johansson, Uri Shalit and David Sontag", "title": "Learning Representations for Counterfactual Inference", "comments": "Appeared in ICML 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Observational studies are rising in importance due to the widespread\naccumulation of data in fields such as healthcare, education, employment and\necology. We consider the task of answering counterfactual questions such as,\n\"Would this patient have lower blood sugar had she received a different\nmedication?\". We propose a new algorithmic framework for counterfactual\ninference which brings together ideas from domain adaptation and representation\nlearning. In addition to a theoretical justification, we perform an empirical\ncomparison with previous approaches to causal inference from observational\ndata. Our deep learning algorithm significantly outperforms the previous\nstate-of-the-art.\n", "versions": [{"version": "v1", "created": "Thu, 12 May 2016 02:59:40 GMT"}, {"version": "v2", "created": "Wed, 8 Jun 2016 17:04:07 GMT"}, {"version": "v3", "created": "Wed, 6 Jun 2018 13:00:53 GMT"}], "update_date": "2018-06-07", "authors_parsed": [["Johansson", "Fredrik D.", ""], ["Shalit", "Uri", ""], ["Sontag", "David", ""]]}, {"id": "1605.03915", "submitter": "Hang Ren", "authors": "Hang Ren, Weiqun Xu and Yonghong Yan", "title": "Optimizing human-interpretable dialog management policy using Genetic\n  Algorithm", "comments": "This technical report is an updated version of the conference paper:\n  \"H. Ren, W. Xu, and Y. Yan, Optimizing human-interpretable dialog management\n  policy using genetic algorithm, in 2015 IEEE Workshop on Automatic Speech\n  Recognition and Understanding (ASRU), 2015, 791-797\". Experiments on policy\n  training via user simulator have been enriched and the reward function is\n  updated", "journal-ref": null, "doi": "10.1109/ASRU.2015.7404869", "report-no": null, "categories": "cs.HC cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic optimization of spoken dialog management policies that are robust\nto environmental noise has long been the goal for both academia and industry.\nApproaches based on reinforcement learning have been proved to be effective.\nHowever, the numerical representation of dialog policy is\nhuman-incomprehensible and difficult for dialog system designers to verify or\nmodify, which limits its practical application. In this paper we propose a\nnovel framework for optimizing dialog policies specified in domain language\nusing genetic algorithm. The human-interpretable representation of policy makes\nthe method suitable for practical employment. We present learning algorithms\nusing user simulation and real human-machine dialogs respectively.Empirical\nexperimental results are given to show the effectiveness of the proposed\napproach.\n", "versions": [{"version": "v1", "created": "Thu, 12 May 2016 18:03:38 GMT"}, {"version": "v2", "created": "Fri, 13 May 2016 01:28:52 GMT"}], "update_date": "2016-11-18", "authors_parsed": [["Ren", "Hang", ""], ["Xu", "Weiqun", ""], ["Yan", "Yonghong", ""]]}, {"id": "1605.04039", "submitter": "Guangrun Wang", "authors": "Liang Lin, Guangrun Wang, Wangmeng Zuo, Xiangchu Feng, and Lei Zhang", "title": "Cross-Domain Visual Matching via Generalized Similarity Measure and\n  Feature Learning", "comments": "To appear in IEEE Transactions on Pattern Analysis and Machine\n  Intelligence (T-PAMI), 2016", "journal-ref": null, "doi": "10.1109/TPAMI.2016.2567386", "report-no": null, "categories": "cs.CV cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cross-domain visual data matching is one of the fundamental problems in many\nreal-world vision tasks, e.g., matching persons across ID photos and\nsurveillance videos. Conventional approaches to this problem usually involves\ntwo steps: i) projecting samples from different domains into a common space,\nand ii) computing (dis-)similarity in this space based on a certain distance.\nIn this paper, we present a novel pairwise similarity measure that advances\nexisting models by i) expanding traditional linear projections into affine\ntransformations and ii) fusing affine Mahalanobis distance and Cosine\nsimilarity by a data-driven combination. Moreover, we unify our similarity\nmeasure with feature representation learning via deep convolutional neural\nnetworks. Specifically, we incorporate the similarity measure matrix into the\ndeep architecture, enabling an end-to-end way of model optimization. We\nextensively evaluate our generalized similarity model in several challenging\ncross-domain matching tasks: person re-identification under different views and\nface verification over different modalities (i.e., faces from still images and\nvideos, older and younger faces, and sketch and photo portraits). The\nexperimental results demonstrate superior performance of our model over other\nstate-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Fri, 13 May 2016 03:35:14 GMT"}], "update_date": "2016-11-17", "authors_parsed": [["Lin", "Liang", ""], ["Wang", "Guangrun", ""], ["Zuo", "Wangmeng", ""], ["Feng", "Xiangchu", ""], ["Zhang", "Lei", ""]]}, {"id": "1605.04056", "submitter": "Rumi Ghosh", "authors": "Katerina Marazopoulou, Rumi Ghosh, Prasanth Lade, David Jensen", "title": "Causal Discovery for Manufacturing Domains", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Yield and quality improvement is of paramount importance to any manufacturing\ncompany. One of the ways of improving yield is through discovery of the root\ncausal factors affecting yield. We propose the use of data-driven interpretable\ncausal models to identify key factors affecting yield. We focus on factors that\nare measured in different stages of production and testing in the manufacturing\ncycle of a product. We apply causal structure learning techniques on real data\ncollected from this line. Specifically, the goal of this work is to learn\ninterpretable causal models from observational data produced by manufacturing\nlines.\n  Emphasis has been given to the interpretability of the models to make them\nactionable in the field of manufacturing. We highlight the challenges presented\nby assembly line data and propose ways to alleviate them.We also identify\nunique characteristics of data originating from assembly lines and how to\nleverage them in order to improve causal discovery. Standard evaluation\ntechniques for causal structure learning shows that the learned causal models\nseem to closely represent the underlying latent causal relationship between\ndifferent factors in the production process. These results were also validated\nby manufacturing domain experts who found them promising. This work\ndemonstrates how data mining and knowledge discovery can be used for root cause\nanalysis in the domain of manufacturing and connected industry.\n", "versions": [{"version": "v1", "created": "Fri, 13 May 2016 06:17:54 GMT"}, {"version": "v2", "created": "Mon, 13 Jun 2016 22:51:23 GMT"}], "update_date": "2016-06-15", "authors_parsed": [["Marazopoulou", "Katerina", ""], ["Ghosh", "Rumi", ""], ["Lade", "Prasanth", ""], ["Jensen", "David", ""]]}, {"id": "1605.04071", "submitter": "James Cussens", "authors": "James Cussens, Matti J\\\"arvisalo, Janne H. Korhonen and Mark Bartlett", "title": "Bayesian Network Structure Learning with Integer Programming: Polytopes,\n  Facets, and Complexity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The challenging task of learning structures of probabilistic graphical models\nis an important problem within modern AI research. Recent years have witnessed\nseveral major algorithmic advances in structure learning for Bayesian\nnetworks---arguably the most central class of graphical models---especially in\nwhat is known as the score-based setting. A successful generic approach to\noptimal Bayesian network structure learning (BNSL), based on integer\nprogramming (IP), is implemented in the GOBNILP system. Despite the recent\nalgorithmic advances, current understanding of foundational aspects underlying\nthe IP based approach to BNSL is still somewhat lacking. Understanding\nfundamental aspects of cutting planes and the related separation problem( is\nimportant not only from a purely theoretical perspective, but also since it\nholds out the promise of further improving the efficiency of state-of-the-art\napproaches to solving BNSL exactly. In this paper, we make several theoretical\ncontributions towards these goals: (i) we study the computational complexity of\nthe separation problem, proving that the problem is NP-hard; (ii) we formalise\nand analyse the relationship between three key polytopes underlying the\nIP-based approach to BNSL; (iii) we study the facets of the three polytopes\nboth from the theoretical and practical perspective, providing, via exhaustive\ncomputation, a complete enumeration of facets for low-dimensional\nfamily-variable polytopes; and, furthermore, (iv) we establish a tight\nconnection of the BNSL problem to the acyclic subgraph problem.\n", "versions": [{"version": "v1", "created": "Fri, 13 May 2016 07:27:03 GMT"}, {"version": "v2", "created": "Sun, 18 Dec 2016 17:28:15 GMT"}], "update_date": "2016-12-20", "authors_parsed": [["Cussens", "James", ""], ["J\u00e4rvisalo", "Matti", ""], ["Korhonen", "Janne H.", ""], ["Bartlett", "Mark", ""]]}, {"id": "1605.04072", "submitter": "Pascale Fung Prof.", "authors": "Pascale Fung, Dario Bertero, Yan Wan, Anik Dey, Ricky Ho Yin Chan,\n  Farhad Bin Siddique, Yang Yang, Chien-Sheng Wu, Ruixi Lin", "title": "Towards Empathetic Human-Robot Interactions", "comments": "23 pages. Keynote at 17th International Conference on Intelligent\n  Text Processing and Computational Linguistics. To appear in Lecture Notes in\n  Computer Science", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.HC cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Since the late 1990s when speech companies began providing their\ncustomer-service software in the market, people have gotten used to speaking to\nmachines. As people interact more often with voice and gesture controlled\nmachines, they expect the machines to recognize different emotions, and\nunderstand other high level communication features such as humor, sarcasm and\nintention. In order to make such communication possible, the machines need an\nempathy module in them which can extract emotions from human speech and\nbehavior and can decide the correct response of the robot. Although research on\nempathetic robots is still in the early stage, we described our approach using\nsignal processing techniques, sentiment analysis and machine learning\nalgorithms to make robots that can \"understand\" human emotion. We propose Zara\nthe Supergirl as a prototype system of empathetic robots. It is a software\nbased virtual android, with an animated cartoon character to present itself on\nthe screen. She will get \"smarter\" and more empathetic through its deep\nlearning algorithms, and by gathering more data and learning from it. In this\npaper, we present our work so far in the areas of deep learning of emotion and\nsentiment recognition, as well as humor recognition. We hope to explore the\nfuture direction of android development and how it can help improve people's\nlives.\n", "versions": [{"version": "v1", "created": "Fri, 13 May 2016 07:31:50 GMT"}], "update_date": "2016-05-16", "authors_parsed": [["Fung", "Pascale", ""], ["Bertero", "Dario", ""], ["Wan", "Yan", ""], ["Dey", "Anik", ""], ["Chan", "Ricky Ho Yin", ""], ["Siddique", "Farhad Bin", ""], ["Yang", "Yang", ""], ["Wu", "Chien-Sheng", ""], ["Lin", "Ruixi", ""]]}, {"id": "1605.04074", "submitter": "Muhammad Yousefnezhad", "authors": "Hosein Alizadeh, Muhammad Yousefnezhad and Behrouz Minaei Bidgoli", "title": "Wisdom of Crowds cluster ensemble", "comments": "Intelligent Data Analysis (IDA), IOS Press", "journal-ref": null, "doi": "10.3233/IDA-150728", "report-no": null, "categories": "stat.ML cs.AI cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Wisdom of Crowds is a phenomenon described in social science that\nsuggests four criteria applicable to groups of people. It is claimed that, if\nthese criteria are satisfied, then the aggregate decisions made by a group will\noften be better than those of its individual members. Inspired by this concept,\nwe present a novel feedback framework for the cluster ensemble problem, which\nwe call Wisdom of Crowds Cluster Ensemble (WOCCE). Although many conventional\ncluster ensemble methods focusing on diversity have recently been proposed,\nWOCCE analyzes the conditions necessary for a crowd to exhibit this collective\nwisdom. These include decentralization criteria for generating primary results,\nindependence criteria for the base algorithms, and diversity criteria for the\nensemble members. We suggest appropriate procedures for evaluating these\nmeasures, and propose a new measure to assess the diversity. We evaluate the\nperformance of WOCCE against some other traditional base algorithms as well as\nstate-of-the-art ensemble methods. The results demonstrate the efficiency of\nWOCCE's aggregate decision-making compared to other algorithms.\n", "versions": [{"version": "v1", "created": "Fri, 13 May 2016 07:50:50 GMT"}], "update_date": "2016-05-16", "authors_parsed": [["Alizadeh", "Hosein", ""], ["Yousefnezhad", "Muhammad", ""], ["Bidgoli", "Behrouz Minaei", ""]]}, {"id": "1605.04122", "submitter": "Richard Moot", "authors": "Richard Moot (LaBRI), Christian Retor\\'e (TEXTE)", "title": "Natural Language Semantics and Computability", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper is a reflexion on the computability of natural language semantics.\nIt does not contain a new model or new results in the formal semantics of\nnatural language: it is rather a computational analysis of the logical models\nand algorithms currently used in natural language semantics, defined as the\nmapping of a statement to logical formulas - formulas, because a statement can\nbe ambiguous. We argue that as long as possible world semantics is left out,\none can compute the semantic representation(s) of a given statement, including\naspects of lexical meaning. We also discuss the algorithmic complexity of this\nprocess.\n", "versions": [{"version": "v1", "created": "Fri, 13 May 2016 10:46:22 GMT"}], "update_date": "2016-05-16", "authors_parsed": [["Moot", "Richard", "", "LaBRI"], ["Retor\u00e9", "Christian", "", "TEXTE"]]}, {"id": "1605.04135", "submitter": "Purushottam Kar", "authors": "Purushottam Kar and Shuai Li and Harikrishna Narasimhan and Sanjay\n  Chawla and Fabrizio Sebastiani", "title": "Online Optimization Methods for the Quantification Problem", "comments": "26 pages, 6 figures. A short version of this manuscript will appear\n  in the proceedings of the 22nd ACM SIGKDD Conference on Knowledge Discovery\n  and Data Mining, KDD 2016", "journal-ref": null, "doi": "10.1145/2939672.2939832", "report-no": null, "categories": "stat.ML cs.AI cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The estimation of class prevalence, i.e., the fraction of a population that\nbelongs to a certain class, is a very useful tool in data analytics and\nlearning, and finds applications in many domains such as sentiment analysis,\nepidemiology, etc. For example, in sentiment analysis, the objective is often\nnot to estimate whether a specific text conveys a positive or a negative\nsentiment, but rather estimate the overall distribution of positive and\nnegative sentiments during an event window. A popular way of performing the\nabove task, often dubbed quantification, is to use supervised learning to train\na prevalence estimator from labeled data.\n  Contemporary literature cites several performance measures used to measure\nthe success of such prevalence estimators. In this paper we propose the first\nonline stochastic algorithms for directly optimizing these\nquantification-specific performance measures. We also provide algorithms that\noptimize hybrid performance measures that seek to balance quantification and\nclassification performance. Our algorithms present a significant advancement in\nthe theory of multivariate optimization and we show, by a rigorous theoretical\nanalysis, that they exhibit optimal convergence. We also report extensive\nexperiments on benchmark and real data sets which demonstrate that our methods\nsignificantly outperform existing optimization techniques used for these\nperformance measures.\n", "versions": [{"version": "v1", "created": "Fri, 13 May 2016 11:14:58 GMT"}, {"version": "v2", "created": "Mon, 16 May 2016 04:29:47 GMT"}, {"version": "v3", "created": "Mon, 13 Jun 2016 18:11:54 GMT"}], "update_date": "2018-09-11", "authors_parsed": [["Kar", "Purushottam", ""], ["Li", "Shuai", ""], ["Narasimhan", "Harikrishna", ""], ["Chawla", "Sanjay", ""], ["Sebastiani", "Fabrizio", ""]]}, {"id": "1605.04218", "submitter": "Abhishek Dasgupta", "authors": "Abhishek Dasgupta and Samson Abramsky", "title": "Anytime Inference in Valuation Algebras", "comments": "9 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Anytime inference is inference performed incrementally, with the accuracy of\nthe inference being controlled by a tunable parameter, usually time. Such\nanytime inference algorithms are also usually interruptible, gradually\nconverging to the exact inference value until terminated. While anytime\ninference algorithms for specific domains like probability potentials exist in\nthe literature, our objective in this article is to obtain an anytime inference\nalgorithm which is sufficiently generic to cover a wide range of domains. For\nthis we utilise the theory of generic inference as a basis for constructing an\nanytime inference algorithm, and in particular, extending work done on ordered\nvaluation algebras. The novel contribution of this work is the construction of\nanytime algorithms in a generic framework, which automatically gives us\ninstantiations in various useful domains. We also show how to apply this\ngeneric framework for anytime inference in semiring induced valuation algebras,\nan important subclass of valuation algebras, which includes instances like\nprobability potentials, disjunctive normal forms and distributive lattices.\n  Keywords: Approximation; Anytime algorithms; Resource-bounded computation;\nGeneric inference; Valuation algebras; Local computation; Binary join trees.\n", "versions": [{"version": "v1", "created": "Fri, 13 May 2016 15:40:10 GMT"}], "update_date": "2016-05-16", "authors_parsed": [["Dasgupta", "Abhishek", ""], ["Abramsky", "Samson", ""]]}, {"id": "1605.04232", "submitter": "Vladimir Shakirov", "authors": "Vladimir Shakirov", "title": "Review of state-of-the-arts in artificial intelligence with application\n  to AI safety problem", "comments": "version 2 includes grant information", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Here, I review current state-of-the-arts in many areas of AI to estimate when\nit's reasonable to expect human level AI development. Predictions of prominent\nAI researchers vary broadly from very pessimistic predictions of Andrew Ng to\nmuch more moderate predictions of Geoffrey Hinton and optimistic predictions of\nShane Legg, DeepMind cofounder. Given huge rate of progress in recent years and\nthis broad range of predictions of AI experts, AI safety questions are also\ndiscussed.\n", "versions": [{"version": "v1", "created": "Wed, 11 May 2016 17:49:24 GMT"}, {"version": "v2", "created": "Tue, 6 Dec 2016 09:29:12 GMT"}], "update_date": "2016-12-07", "authors_parsed": [["Shakirov", "Vladimir", ""]]}, {"id": "1605.04263", "submitter": "Guohui Xiao", "authors": "Dag Hovland and Davide Lanti and Martin Rezk and Guohui Xiao", "title": "OBDA Constraints for Effective Query Answering (Extended Version)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In Ontology Based Data Access (OBDA) users pose SPARQL queries over an\nontology that lies on top of relational datasources. These queries are\ntranslated on-the-fly into SQL queries by OBDA systems. Standard SPARQL-to-SQL\ntranslation techniques in OBDA often produce SQL queries containing redundant\njoins and unions, even after a number of semantic and structural optimizations.\nThese redundancies are detrimental to the performance of query answering,\nespecially in complex industrial OBDA scenarios with large enterprise\ndatabases. To address this issue, we introduce two novel notions of OBDA\nconstraints and show how to exploit them for efficient query answering. We\nconduct an extensive set of experiments on large datasets using real world data\nand queries, showing that these techniques strongly improve the performance of\nquery answering up to orders of magnitude.\n", "versions": [{"version": "v1", "created": "Fri, 13 May 2016 17:29:28 GMT"}, {"version": "v2", "created": "Mon, 16 May 2016 09:21:26 GMT"}], "update_date": "2016-05-17", "authors_parsed": [["Hovland", "Dag", ""], ["Lanti", "Davide", ""], ["Rezk", "Martin", ""], ["Xiao", "Guohui", ""]]}, {"id": "1605.04465", "submitter": "Avradeep Bhowmik", "authors": "Avradeep Bhowmik, Joydeep Ghosh", "title": "Monotone Retargeting for Unsupervised Rank Aggregation with Object\n  Features", "comments": "15 pages, 2 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning the true ordering between objects by aggregating a set of expert\nopinion rank order lists is an important and ubiquitous problem in many\napplications ranging from social choice theory to natural language processing\nand search aggregation. We study the problem of unsupervised rank aggregation\nwhere no ground truth ordering information in available, neither about the true\npreference ordering between any set of objects nor about the quality of\nindividual rank lists. Aggregating the often inconsistent and poor quality rank\nlists in such an unsupervised manner is a highly challenging problem, and\nstandard consensus-based methods are often ill-defined, and difficult to solve.\nIn this manuscript we propose a novel framework to bypass these issues by using\nobject attributes to augment the standard rank aggregation framework. We design\nalgorithms that learn joint models on both rank lists and object features to\nobtain an aggregated rank ordering that is more accurate and robust, and also\nhelps weed out rank lists of dubious validity. We validate our techniques on\nsynthetic datasets where our algorithm is able to estimate the true rank\nordering even when the rank lists are corrupted. Experiments on three real\ndatasets, MQ2008, MQ2008 and OHSUMED, show that using object features can\nresult in significant improvement in performance over existing rank aggregation\nmethods that do not use object information. Furthermore, when at least some of\nthe rank lists are of high quality, our methods are able to effectively exploit\ntheir high expertise to output an aggregated rank ordering of great accuracy.\n", "versions": [{"version": "v1", "created": "Sat, 14 May 2016 20:35:20 GMT"}], "update_date": "2016-05-17", "authors_parsed": [["Bhowmik", "Avradeep", ""], ["Ghosh", "Joydeep", ""]]}, {"id": "1605.04466", "submitter": "Avradeep Bhowmik", "authors": "Avradeep Bhowmik, Joydeep Ghosh, Oluwasanmi Koyejo", "title": "Generalized Linear Models for Aggregated Data", "comments": "AISTATS 2015, 9 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Databases in domains such as healthcare are routinely released to the public\nin aggregated form. Unfortunately, naive modeling with aggregated data may\nsignificantly diminish the accuracy of inferences at the individual level. This\npaper addresses the scenario where features are provided at the individual\nlevel, but the target variables are only available as histogram aggregates or\norder statistics. We consider a limiting case of generalized linear modeling\nwhen the target variables are only known up to permutation, and explore how\nthis relates to permutation testing; a standard technique for assessing\nstatistical dependency. Based on this relationship, we propose a simple\nalgorithm to estimate the model parameters and individual level inferences via\nalternating imputation and standard generalized linear model fitting. Our\nresults suggest the effectiveness of the proposed approach when, in the\noriginal data, permutation testing accurately ascertains the veracity of the\nlinear relationship. The framework is extended to general histogram data with\nlarger bins - with order statistics such as the median as a limiting case. Our\nexperimental results on simulated data and aggregated healthcare data suggest a\ndiminishing returns property with respect to the granularity of the histogram -\nwhen a linear relationship holds in the original data, the targets can be\npredicted accurately given relatively coarse histograms.\n", "versions": [{"version": "v1", "created": "Sat, 14 May 2016 21:09:10 GMT"}], "update_date": "2016-05-17", "authors_parsed": [["Bhowmik", "Avradeep", ""], ["Ghosh", "Joydeep", ""], ["Koyejo", "Oluwasanmi", ""]]}, {"id": "1605.04672", "submitter": "Pushpendre Rastogi", "authors": "Pushpendre Rastogi, Benjamin Van Durme", "title": "A Critical Examination of RESCAL for Completion of Knowledge Bases with\n  Transitive Relations", "comments": "Four and a half page", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.DB cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Link prediction in large knowledge graphs has received a lot of attention\nrecently because of its importance for inferring missing relations and for\ncompleting and improving noisily extracted knowledge graphs. Over the years a\nnumber of machine learning researchers have presented various models for\npredicting the presence of missing relations in a knowledge base. Although all\nthe previous methods are presented with empirical results that show high\nperformance on select datasets, there is almost no previous work on\nunderstanding the connection between properties of a knowledge base and the\nperformance of a model. In this paper we analyze the RESCAL method and prove\nthat it can not encode asymmetric transitive relations in knowledge bases.\n", "versions": [{"version": "v1", "created": "Mon, 16 May 2016 07:43:28 GMT"}], "update_date": "2016-05-17", "authors_parsed": [["Rastogi", "Pushpendre", ""], ["Van Durme", "Benjamin", ""]]}, {"id": "1605.04682", "submitter": "Gerhard Rauchecker", "authors": "Gerhard Rauchecker and Guido Schryen", "title": "High-Performance Computing for Scheduling Decision Support: A Parallel\n  Depth-First Search Heuristic", "comments": "ISBN# 978-0-646-95337-3 Presented at the Australasian Conference on\n  Information Systems 2015 (arXiv:1605.01032)", "journal-ref": null, "doi": null, "report-no": "ACIS/2015/7", "categories": "cs.DC cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Many academic disciplines - including information systems, computer science,\nand operations management - face scheduling problems as important decision\nmaking tasks. Since many scheduling problems are NP-hard in the strong sense,\nthere is a need for developing solution heuristics. For scheduling problems\nwith setup times on unrelated parallel machines, there is limited research on\nsolution methods and to the best of our knowledge, parallel computer\narchitectures have not yet been taken advantage of. We address this gap by\nproposing and implementing a new solution heuristic and by testing different\nparallelization strategies. In our computational experiments, we show that our\nheuristic calculates near-optimal solutions even for large instances and that\ncomputing time can be reduced substantially by our parallelization approach.\n", "versions": [{"version": "v1", "created": "Mon, 16 May 2016 09:11:08 GMT"}], "update_date": "2016-05-26", "authors_parsed": [["Rauchecker", "Gerhard", ""], ["Schryen", "Guido", ""]]}, {"id": "1605.04691", "submitter": "Tom Ameloot", "authors": "Tom J. Ameloot", "title": "On Avoidance Learning with Partial Observability", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study a framework where agents have to avoid aversive signals. The agents\nare given only partial information, in the form of features that are\nprojections of task states. Additionally, the agents have to cope with\nnon-determinism, defined as unpredictability on the way that actions are\nexecuted. The goal of each agent is to define its behavior based on\nfeature-action pairs that reliably avoid aversive signals. We study a learning\nalgorithm, called A-learning, that exhibits fixpoint convergence, where the\nbelief of the allowed feature-action pairs eventually becomes fixed. A-learning\nis parameter-free and easy to implement.\n", "versions": [{"version": "v1", "created": "Mon, 16 May 2016 09:26:53 GMT"}], "update_date": "2016-05-17", "authors_parsed": [["Ameloot", "Tom J.", ""]]}, {"id": "1605.04715", "submitter": "Abdallah Saffidine", "authors": "\\'Edouard Bonnet, Florian Jamain, Abdallah Saffidine", "title": "On the Complexity of Connection Games", "comments": "Subsumes and extends https://arxiv.org/abs/1403.6518 significantly", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study three connection games among the most widely played:\nHavannah, Twixt, and Slither. We show that determining the outcome of an\narbitrary input position is PSPACE-complete in all three cases. Our reductions\nare based on the popular graph problem Generalized Geography and on Hex itself.\nWe also consider the complexity of generalizations of Hex parameterized by the\nlength of the solution and establish that while Short Generalized Hex is\nW[1]-hard, Short Hex is FPT. Finally, we prove that the ultra-weak solution to\nthe empty starting position in hex cannot be fully adapted to any of these\nthree games.\n", "versions": [{"version": "v1", "created": "Mon, 16 May 2016 10:26:38 GMT"}], "update_date": "2016-05-17", "authors_parsed": [["Bonnet", "\u00c9douard", ""], ["Jamain", "Florian", ""], ["Saffidine", "Abdallah", ""]]}, {"id": "1605.04812", "submitter": "Adith Swaminathan", "authors": "Adith Swaminathan, Akshay Krishnamurthy, Alekh Agarwal, Miroslav\n  Dud\\'ik, John Langford, Damien Jose, Imed Zitouni", "title": "Off-policy evaluation for slate recommendation", "comments": "31 pages (9 main paper, 20 supplementary), 12 figures (2 main paper,\n  10 supplementary)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies the evaluation of policies that recommend an ordered set\nof items (e.g., a ranking) based on some context---a common scenario in web\nsearch, ads, and recommendation. We build on techniques from combinatorial\nbandits to introduce a new practical estimator that uses logged data to\nestimate a policy's performance. A thorough empirical evaluation on real-world\ndata reveals that our estimator is accurate in a variety of settings, including\nas a subroutine in a learning-to-rank task, where it achieves competitive\nperformance. We derive conditions under which our estimator is unbiased---these\nconditions are weaker than prior heuristics for slate evaluation---and\nexperimentally demonstrate a smaller bias than parametric approaches, even when\nthese conditions are violated. Finally, our theory and experiments also show\nexponential savings in the amount of required data compared with general\nunbiased estimators.\n", "versions": [{"version": "v1", "created": "Mon, 16 May 2016 15:47:21 GMT"}, {"version": "v2", "created": "Tue, 24 May 2016 10:34:21 GMT"}, {"version": "v3", "created": "Mon, 6 Nov 2017 22:55:48 GMT"}], "update_date": "2017-11-08", "authors_parsed": [["Swaminathan", "Adith", ""], ["Krishnamurthy", "Akshay", ""], ["Agarwal", "Alekh", ""], ["Dud\u00edk", "Miroslav", ""], ["Langford", "John", ""], ["Jose", "Damien", ""], ["Zitouni", "Imed", ""]]}, {"id": "1605.04874", "submitter": "Amir Hosein Zamanian", "authors": "Amir Hosein Zamanian, Abdolreza Ohadi", "title": "Gearbox Fault Detection through PSO Exact Wavelet Analysis and SVM\n  Classifier", "comments": null, "journal-ref": null, "doi": "10.13140/RG.2.1.4983.3442", "report-no": "ISME2010-3820", "categories": "cs.LG cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Time-frequency methods for vibration-based gearbox faults detection have been\nconsidered the most efficient method. Among these methods, continuous wavelet\ntransform (CWT) as one of the best time-frequency method has been used for both\nstationary and transitory signals. Some deficiencies of CWT are problem of\noverlapping and distortion ofsignals. In this condition, a large amount of\nredundant information exists so that it may cause false alarm or\nmisinterpretation of the operator. In this paper a modified method called Exact\nWavelet Analysis is used to minimize the effects of overlapping and distortion\nin case of gearbox faults. To implement exact wavelet analysis, Particle Swarm\nOptimization (PSO) algorithm has been used for this purpose. This method have\nbeen implemented for the acceleration signals from 2D acceleration sensor\nacquired by Advantech PCI-1710 card from a gearbox test setup in Amirkabir\nUniversity of Technology. Gearbox has been considered in both healthy and\nchipped tooth gears conditions. Kernelized Support Vector Machine (SVM) with\nradial basis functions has used the extracted features from exact wavelet\nanalysis for classification. The efficiency of this classifier is then\nevaluated with the other signals acquired from the setup test. The results show\nthat in comparison of CWT, PSO Exact Wavelet Transform has better ability in\nfeature extraction in price of more computational effort. In addition, PSO\nexact wavelet has better speed comparing to Genetic Algorithm (GA) exact\nwavelet in condition of equal population because of factoring mutation and\ncrossover in PSO algorithm. SVM classifier with the extracted features in\ngearbox shows very good results and its ability has been proved.\n", "versions": [{"version": "v1", "created": "Thu, 12 May 2016 23:29:29 GMT"}], "update_date": "2016-06-23", "authors_parsed": [["Zamanian", "Amir Hosein", ""], ["Ohadi", "Abdolreza", ""]]}, {"id": "1605.04934", "submitter": "Fei Han", "authors": "Fei Han, Christopher Reardon, Lynne E. Parker, Hao Zhang", "title": "Self-Reflective Risk-Aware Artificial Cognitive Modeling for Robot\n  Response to Human Behaviors", "comments": "40 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In order for cooperative robots (\"co-robots\") to respond to human behaviors\naccurately and efficiently in human-robot collaboration, interpretation of\nhuman actions, awareness of new situations, and appropriate decision making are\nall crucial abilities for co-robots. For this purpose, the human behaviors\nshould be interpreted by co-robots in the same manner as human peers. To\naddress this issue, a novel interpretability indicator is introduced so that\nrobot actions are appropriate to the current human behaviors. In addition, the\ncomplete consideration of all potential situations of a robot's environment is\nnearly impossible in real-world applications, making it difficult for the\nco-robot to act appropriately and safely in new scenarios. This is true even\nwhen the pretrained model is highly accurate in a known situation. For\neffective and safe teaming with humans, we introduce a new generalizability\nindicator that allows a co-robot to self-reflect and reason about when an\nobservation falls outside the co-robot's learned model. Based on topic modeling\nand two novel indicators, we propose a new Self-reflective Risk-aware\nArtificial Cognitive (SRAC) model. The co-robots are able to consider action\nrisks and identify new situations so that better decisions can be made.\nExperiments both using real-world datasets and on physical robots suggest that\nour SRAC model significantly outperforms the traditional methodology and\nenables better decision making in response to human activities.\n", "versions": [{"version": "v1", "created": "Mon, 16 May 2016 20:22:30 GMT"}], "update_date": "2016-05-18", "authors_parsed": [["Han", "Fei", ""], ["Reardon", "Christopher", ""], ["Parker", "Lynne E.", ""], ["Zhang", "Hao", ""]]}, {"id": "1605.05166", "submitter": "Soroush Vosoughi Dr", "authors": "Soroush Vosoughi, Helen Zhou, Deb Roy", "title": "Digital Stylometry: Linking Profiles Across Social Networks", "comments": "SocInfo'15, Beijing, China. In proceedings of the 7th International\n  Conference on Social Informatics (SocInfo 2015). Beijing, China", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.AI cs.CL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is an ever growing number of users with accounts on multiple social\nmedia and networking sites. Consequently, there is increasing interest in\nmatching user accounts and profiles across different social networks in order\nto create aggregate profiles of users. In this paper, we present models for\nDigital Stylometry, which is a method for matching users through stylometry\ninspired techniques. We experimented with linguistic, temporal, and combined\ntemporal-linguistic models for matching user accounts, using standard and novel\ntechniques. Using publicly available data, our best model, a combined\ntemporal-linguistic one, was able to correctly match the accounts of 31% of\n5,612 distinct users across Twitter and Facebook.\n", "versions": [{"version": "v1", "created": "Tue, 17 May 2016 13:47:24 GMT"}], "update_date": "2016-06-21", "authors_parsed": [["Vosoughi", "Soroush", ""], ["Zhou", "Helen", ""], ["Roy", "Deb", ""]]}, {"id": "1605.05195", "submitter": "Soroush Vosoughi Dr", "authors": "Soroush Vosoughi, Helen Zhou, Deb Roy", "title": "Enhanced Twitter Sentiment Classification Using Contextual Information", "comments": "In proceedings of the 6th workshop on Computational Approaches to\n  Subjectivity, Sentiment & Social Media Analysis (WASSA) at EMNLP 2015", "journal-ref": null, "doi": "10.18653/v1/W15-2904", "report-no": null, "categories": "cs.SI cs.AI cs.CL cs.IR", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  The rise in popularity and ubiquity of Twitter has made sentiment analysis of\ntweets an important and well-covered area of research. However, the 140\ncharacter limit imposed on tweets makes it hard to use standard linguistic\nmethods for sentiment classification. On the other hand, what tweets lack in\nstructure they make up with sheer volume and rich metadata. This metadata\nincludes geolocation, temporal and author information. We hypothesize that\nsentiment is dependent on all these contextual factors. Different locations,\ntimes and authors have different emotional valences. In this paper, we explored\nthis hypothesis by utilizing distant supervision to collect millions of\nlabelled tweets from different locations, times and authors. We used this data\nto analyse the variation of tweet sentiments across different authors, times\nand locations. Once we explored and understood the relationship between these\nvariables and sentiment, we used a Bayesian approach to combine these variables\nwith more standard linguistic features such as n-grams to create a Twitter\nsentiment classifier. This combined classifier outperforms the purely\nlinguistic classifier, showing that integrating the rich contextual information\navailable on Twitter into sentiment classification is a promising direction of\nresearch.\n", "versions": [{"version": "v1", "created": "Tue, 17 May 2016 14:51:54 GMT"}, {"version": "v2", "created": "Sat, 2 Jan 2021 03:59:19 GMT"}], "update_date": "2021-01-05", "authors_parsed": [["Vosoughi", "Soroush", ""], ["Zhou", "Helen", ""], ["Roy", "Deb", ""]]}, {"id": "1605.05247", "submitter": "Yuan Wang", "authors": "Yuan Wang, Guy Carrault, Alain Beuchee, Nathalie Costet, Huazhong Shu,\n  Lotfi Senhadji", "title": "Heart Rate Variability and Respiration Signal as Diagnostic Tools for\n  Late Onset Sepsis in Neonatal Intensive Care Units", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Apnea-bradycardia is one of the major clinical early indicators of late-onset\nsepsis occurring in approximately 7% to 10% of all neonates and in more than\n25% of very low birth weight infants in NICU. The objective of this paper was\nto determine if HRV, respiration and their relationships help to diagnose\ninfection in premature infants via non-invasive ways in NICU. Therefore, we\nimplement Mono-Channel (MC) and Bi-Channel (BC) Analysis in two groups: sepsis\n(S) vs. non-sepsis (NS). Firstly, we studied RR series not only by linear\nmethods: time domain and frequency domain, but also by non-linear methods:\nchaos theory and information theory. The results show that alpha Slow, alpha\nFast and Sample Entropy are significant parameters to distinguish S from NS.\nSecondly, the question about the functional coupling of HRV and nasal\nrespiration is addressed. Local linear correlation coefficient r2t,f has been\nexplored, while non-linear regression coefficient h2 was calculated in two\ndirections. It is obvious that r2t,f within the third frequency band (0.2<f<0.4\nHz) and h2 in two directions were complementary approaches to diagnose sepsis.\nThirdly, feasibility study is carried out on the candidate parameters selected\nfrom MC and BC respectively. We discovered that the proposed test based on\noptimal fusion of 6 features shows good performance with the largest AUC and a\nreduced probability of false alarm (PFA).\n", "versions": [{"version": "v1", "created": "Thu, 12 May 2016 23:56:31 GMT"}], "update_date": "2016-05-18", "authors_parsed": [["Wang", "Yuan", ""], ["Carrault", "Guy", ""], ["Beuchee", "Alain", ""], ["Costet", "Nathalie", ""], ["Shu", "Huazhong", ""], ["Senhadji", "Lotfi", ""]]}, {"id": "1605.05273", "submitter": "Mathias Niepert", "authors": "Mathias Niepert and Mohamed Ahmed and Konstantin Kutzkov", "title": "Learning Convolutional Neural Networks for Graphs", "comments": "To be presented at ICML 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Numerous important problems can be framed as learning from graph data. We\npropose a framework for learning convolutional neural networks for arbitrary\ngraphs. These graphs may be undirected, directed, and with both discrete and\ncontinuous node and edge attributes. Analogous to image-based convolutional\nnetworks that operate on locally connected regions of the input, we present a\ngeneral approach to extracting locally connected regions from graphs. Using\nestablished benchmark data sets, we demonstrate that the learned feature\nrepresentations are competitive with state of the art graph kernels and that\ntheir computation is highly efficient.\n", "versions": [{"version": "v1", "created": "Tue, 17 May 2016 18:13:13 GMT"}, {"version": "v2", "created": "Wed, 18 May 2016 15:38:30 GMT"}, {"version": "v3", "created": "Mon, 6 Jun 2016 13:33:38 GMT"}, {"version": "v4", "created": "Wed, 8 Jun 2016 11:40:13 GMT"}], "update_date": "2016-06-09", "authors_parsed": [["Niepert", "Mathias", ""], ["Ahmed", "Mohamed", ""], ["Kutzkov", "Konstantin", ""]]}, {"id": "1605.05303", "submitter": "Alejandro Ramos Soto", "authors": "A. Ramos-Soto, A. Bugar\\'in, S. Barro", "title": "Fuzzy Sets Across the Natural Language Generation Pipeline", "comments": "Paper features: 16 pages, 2 tables, 13 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We explore the implications of using fuzzy techniques (mainly those commonly\nused in the linguistic description/summarization of data discipline) from a\nnatural language generation perspective. For this, we provide an extensive\ndiscussion of some general convergence points and an exploration of the\nrelationship between the different tasks involved in the standard NLG system\npipeline architecture and the most common fuzzy approaches used in linguistic\nsummarization/description of data, such as fuzzy quantified statements,\nevaluation criteria or aggregation operators. Each individual discussion is\nillustrated with a related use case. Recent work made in the context of\ncross-fertilization of both research fields is also referenced. This paper\nencompasses general ideas that emerged as part of the PhD thesis \"Application\nof fuzzy sets in data-to-text systems\". It does not present a specific\napplication or a formal approach, but rather discusses current high-level\nissues and potential usages of fuzzy sets (focused on linguistic summarization\nof data) in natural language generation.\n", "versions": [{"version": "v1", "created": "Tue, 17 May 2016 19:45:49 GMT"}], "update_date": "2016-05-18", "authors_parsed": [["Ramos-Soto", "A.", ""], ["Bugar\u00edn", "A.", ""], ["Barro", "S.", ""]]}, {"id": "1605.05305", "submitter": "Alberto Uriarte", "authors": "Alberto Uriarte and Santiago Onta\\~n\\'on", "title": "Combat Models for RTS Games", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Game tree search algorithms, such as Monte Carlo Tree Search (MCTS), require\naccess to a forward model (or \"simulator\") of the game at hand. However, in\nsome games such forward model is not readily available. This paper presents\nthree forward models for two-player attrition games, which we call \"combat\nmodels\", and show how they can be used to simulate combat in RTS games. We also\nshow how these combat models can be learned from replay data. We use StarCraft\nas our application domain. We report experiments comparing our combat models\npredicting a combat output and their impact when used for tactical decisions\nduring a real game.\n", "versions": [{"version": "v1", "created": "Tue, 17 May 2016 19:47:13 GMT"}], "update_date": "2016-05-18", "authors_parsed": [["Uriarte", "Alberto", ""], ["Onta\u00f1\u00f3n", "Santiago", ""]]}, {"id": "1605.05359", "submitter": "Aravind Srinivas", "authors": "Aravind Srinivas, Ramnandan Krishnamurthy, Peeyush Kumar and Balaraman\n  Ravindran", "title": "Option Discovery in Hierarchical Reinforcement Learning using\n  Spatio-Temporal Clustering", "comments": "Revised version of ICML 16 Abstraction in Reinforcement Learning\n  workshop paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces an automated skill acquisition framework in\nreinforcement learning which involves identifying a hierarchical description of\nthe given task in terms of abstract states and extended actions between\nabstract states. Identifying such structures present in the task provides ways\nto simplify and speed up reinforcement learning algorithms. These structures\nalso help to generalize such algorithms over multiple tasks without relearning\npolicies from scratch. We use ideas from dynamical systems to find metastable\nregions in the state space and associate them with abstract states. The\nspectral clustering algorithm PCCA+ is used to identify suitable abstractions\naligned to the underlying structure. Skills are defined in terms of the\nsequence of actions that lead to transitions between such abstract states. The\nconnectivity information from PCCA+ is used to generate these skills or\noptions. These skills are independent of the learning task and can be\nefficiently reused across a variety of tasks defined over the same model. This\napproach works well even without the exact model of the environment by using\nsample trajectories to construct an approximate estimate. We also present our\napproach to scaling the skill acquisition framework to complex tasks with large\nstate spaces for which we perform state aggregation using the representation\nlearned from an action conditional video prediction network and use the skill\nacquisition framework on the aggregated state space.\n", "versions": [{"version": "v1", "created": "Tue, 17 May 2016 20:44:19 GMT"}, {"version": "v2", "created": "Tue, 20 Sep 2016 19:14:20 GMT"}, {"version": "v3", "created": "Mon, 21 Sep 2020 22:18:31 GMT"}], "update_date": "2020-09-23", "authors_parsed": [["Srinivas", "Aravind", ""], ["Krishnamurthy", "Ramnandan", ""], ["Kumar", "Peeyush", ""], ["Ravindran", "Balaraman", ""]]}, {"id": "1605.05365", "submitter": "Aravind Srinivas", "authors": "Aravind Srinivas, Sahil Sharma and Balaraman Ravindran", "title": "Dynamic Frame skip Deep Q Network", "comments": "IJCAI 2016 Workshop on Deep Reinforcement Learning: Frontiers and\n  Challenges; 6 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Reinforcement Learning methods have achieved state of the art\nperformance in learning control policies for the games in the Atari 2600\ndomain. One of the important parameters in the Arcade Learning Environment\n(ALE) is the frame skip rate. It decides the granularity at which agents can\ncontrol game play. A frame skip value of $k$ allows the agent to repeat a\nselected action $k$ number of times. The current state of the art architectures\nlike Deep Q-Network (DQN) and Dueling Network Architectures (DuDQN) consist of\na framework with a static frame skip rate, where the action output from the\nnetwork is repeated for a fixed number of frames regardless of the current\nstate. In this paper, we propose a new architecture, Dynamic Frame skip Deep\nQ-Network (DFDQN) which makes the frame skip rate a dynamic learnable\nparameter. This allows us to choose the number of times an action is to be\nrepeated based on the current state. We show empirically that such a setting\nimproves the performance on relatively harder games like Seaquest.\n", "versions": [{"version": "v1", "created": "Tue, 17 May 2016 20:58:41 GMT"}, {"version": "v2", "created": "Sat, 11 Jun 2016 01:04:13 GMT"}, {"version": "v3", "created": "Mon, 21 Sep 2020 22:20:49 GMT"}], "update_date": "2020-09-23", "authors_parsed": [["Srinivas", "Aravind", ""], ["Sharma", "Sahil", ""], ["Ravindran", "Balaraman", ""]]}, {"id": "1605.05433", "submitter": "Stephen Roller", "authors": "Stephen Roller, Katrin Erk", "title": "Relations such as Hypernymy: Identifying and Exploiting Hearst Patterns\n  in Distributional Vectors for Lexical Entailment", "comments": "EMNLP 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the task of predicting lexical entailment using distributional\nvectors. We perform a novel qualitative analysis of one existing model which\nwas previously shown to only measure the prototypicality of word pairs. We find\nthat the model strongly learns to identify hypernyms using Hearst patterns,\nwhich are well known to be predictive of lexical relations. We present a novel\nmodel which exploits this behavior as a method of feature extraction in an\niterative procedure similar to Principal Component Analysis. Our model combines\nthe extracted features with the strengths of other proposed models in the\nliterature, and matches or outperforms prior work on multiple data sets.\n", "versions": [{"version": "v1", "created": "Wed, 18 May 2016 04:10:41 GMT"}, {"version": "v2", "created": "Fri, 23 Sep 2016 20:31:51 GMT"}], "update_date": "2016-09-27", "authors_parsed": [["Roller", "Stephen", ""], ["Erk", "Katrin", ""]]}, {"id": "1605.05448", "submitter": "Aish Fenton", "authors": "Aish Fenton", "title": "The Bees Algorithm for the Vehicle Routing Problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this thesis we present a new algorithm for the Vehicle Routing Problem\ncalled the Enhanced Bees Algorithm. It is adapted from a fairly recent\nalgorithm, the Bees Algorithm, which was developed for continuous optimisation\nproblems. We show that the results obtained by the Enhanced Bees Algorithm are\ncompetitive with the best meta-heuristics available for the Vehicle Routing\nProblem (within 0.5% of the optimal solution for common benchmark problems). We\nshow that the algorithm has good runtime performance, producing results within\n2% of the optimal solution within 60 seconds, making it suitable for use within\nreal world dispatch scenarios.\n", "versions": [{"version": "v1", "created": "Wed, 18 May 2016 05:53:44 GMT"}], "update_date": "2016-05-19", "authors_parsed": [["Fenton", "Aish", ""]]}, {"id": "1605.05676", "submitter": "Martin  Biehl", "authors": "Martin Biehl, Takashi Ikegami, Daniel Polani", "title": "Towards information based spatiotemporal patterns as a foundation for\n  agent representation in dynamical systems", "comments": "8 pages, 3 figures", "journal-ref": "Proceedings of the Artificial Life Conference 2016", "doi": "10.7551/978-0-262-33936-0-ch115", "report-no": null, "categories": "cs.AI cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present some arguments why existing methods for representing agents fall\nshort in applications crucial to artificial life. Using a thought experiment\ninvolving a fictitious dynamical systems model of the biosphere we argue that\nthe metabolism, motility, and the concept of counterfactual variation should be\ncompatible with any agent representation in dynamical systems. We then propose\nan information-theoretic notion of \\emph{integrated spatiotemporal patterns}\nwhich we believe can serve as the basic building block of an agent definition.\nWe argue that these patterns are capable of solving the problems mentioned\nbefore. We also test this in some preliminary experiments.\n", "versions": [{"version": "v1", "created": "Wed, 18 May 2016 18:18:38 GMT"}], "update_date": "2017-04-11", "authors_parsed": [["Biehl", "Martin", ""], ["Ikegami", "Takashi", ""], ["Polani", "Daniel", ""]]}, {"id": "1605.05711", "submitter": "Lina Al-Kanj Dr.", "authors": "Lina Al-Kanj, Warren B. Powell and Belgacem Bouzaiene-Ayari", "title": "The Information-Collecting Vehicle Routing Problem: Stochastic\n  Optimization for Emergency Storm Response", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.AI cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Utilities face the challenge of responding to power outages due to storms and\nice damage, but most power grids are not equipped with sensors to pinpoint the\nprecise location of the faults causing the outage. Instead, utilities have to\ndepend primarily on phone calls (trouble calls) from customers who have lost\npower to guide the dispatching of utility trucks. In this paper, we develop a\npolicy that routes a utility truck to restore outages in the power grid as\nquickly as possible, using phone calls to create beliefs about outages, but\nalso using utility trucks as a mechanism for collecting additional information.\nThis means that routing decisions change not only the physical state of the\ntruck (as it moves from one location to another) and the grid (as the truck\nperforms repairs), but also our belief about the network, creating the first\nstochastic vehicle routing problem that explicitly models information\ncollection and belief modeling. We address the problem of managing a single\nutility truck, which we start by formulating as a sequential stochastic\noptimization model which captures our belief about the state of the grid. We\npropose a stochastic lookahead policy, and use Monte Carlo tree search (MCTS)\nto produce a practical policy that is asymptotically optimal. Simulation\nresults show that the developed policy restores the power grid much faster\ncompared to standard industry heuristics.\n", "versions": [{"version": "v1", "created": "Wed, 18 May 2016 19:23:43 GMT"}], "update_date": "2016-05-20", "authors_parsed": [["Al-Kanj", "Lina", ""], ["Powell", "Warren B.", ""], ["Bouzaiene-Ayari", "Belgacem", ""]]}, {"id": "1605.05807", "submitter": "Miquel Ramirez", "authors": "Miquel Ramirez and Hector Geffner", "title": "Heuristics for Planning, Plan Recognition and Parsing", "comments": "Written: June 2009, Published: May 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a recent paper, we have shown that Plan Recognition over STRIPS can be\nformulated and solved using Classical Planning heuristics and algorithms. In\nthis work, we show that this formulation subsumes the standard formulation of\nPlan Recognition over libraries through a compilation of libraries into STRIPS\ntheories. The libraries correspond to AND/OR graphs that may be cyclic and\nwhere children of AND nodes may be partially ordered. These libraries include\nContext-Free Grammars as a special case, where the Plan Recognition problem\nbecomes a parsing with missing tokens problem. Plan Recognition over the\nstandard libraries become Planning problems that can be easily solved by any\nmodern planner, while recognition over more complex libraries, including\nContext-Free Grammars (CFGs), illustrate limitations of current Planning\nheuristics and suggest improvements that may be relevant in other Planning\nproblems too.\n", "versions": [{"version": "v1", "created": "Thu, 19 May 2016 04:22:35 GMT"}, {"version": "v2", "created": "Sun, 22 May 2016 23:02:35 GMT"}], "update_date": "2016-05-24", "authors_parsed": [["Ramirez", "Miquel", ""], ["Geffner", "Hector", ""]]}, {"id": "1605.05950", "submitter": "Patrick Rodler", "authors": "Patrick Rodler", "title": "Interactive Debugging of Knowledge Bases", "comments": "Ph.D. Thesis, Alpen-Adria Universit\\\"at Klagenfurt", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many AI applications rely on knowledge about a relevant real-world domain\nthat is encoded by means of some logical knowledge base (KB). The most\nessential benefit of logical KBs is the opportunity to perform automatic\nreasoning to derive implicit knowledge or to answer complex queries about the\nmodeled domain. The feasibility of meaningful reasoning requires KBs to meet\nsome minimal quality criteria such as logical consistency. Without adequate\ntool assistance, the task of resolving violated quality criteria in KBs can be\nextremely tough even for domain experts, especially when the problematic KB\nincludes a large number of logical formulas or comprises complicated logical\nformalisms.\n  Published non-interactive debugging systems often cannot localize all\npossible faults (incompleteness), suggest the deletion or modification of\nunnecessarily large parts of the KB (non-minimality), return incorrect\nsolutions which lead to a repaired KB not satisfying the imposed quality\nrequirements (unsoundness) or suffer from poor scalability due to the inherent\ncomplexity of the KB debugging problem. Even if a system is complete and sound\nand considers only minimal solutions, there are generally exponentially many\nsolution candidates to select one from. However, any two repaired KBs obtained\nfrom these candidates differ in their semantics in terms of entailments and\nnon-entailments. Selection of just any of these repaired KBs might result in\nunexpected entailments, the loss of desired entailments or unwanted changes to\nthe KB.\n  This work proposes complete, sound and optimal methods for the interactive\ndebugging of KBs that suggest the one (minimally invasive) error correction of\nthe faulty KB that yields a repaired KB with exactly the intended semantics.\nUsers, e.g. domain experts, are involved in the debugging process by answering\nautomatically generated queries about the intended domain.\n", "versions": [{"version": "v1", "created": "Thu, 19 May 2016 13:40:01 GMT"}], "update_date": "2016-05-20", "authors_parsed": [["Rodler", "Patrick", ""]]}, {"id": "1605.05966", "submitter": "Khadija Tijani", "authors": "Khadija Tijani (CSTB, LIG Laboratoire d'Informatique de Grenoble,\n  G-SCOP), Stephane Ploix (G-SCOP), Benjamin Haas (CSTB), Julie Dugdale (LIG\n  Laboratoire d'Informatique de Grenoble), Quoc Dung Ngo", "title": "Dynamic Bayesian Networks to simulate occupant behaviours in office\n  buildings related to indoor air quality", "comments": "IBPSA India 2015, Dec 2015, Hyderabad, India. arXiv admin note:\n  substantial text overlap with arXiv:1510.01970", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a new general approach based on Bayesian networks to\nmodel the human behaviour. This approach represents human behaviour with\nprobabilistic cause-effect relations based on knowledge, but also with\nconditional probabilities coming either from knowledge or deduced from\nobservations. This approach has been applied to the co-simulation of the CO2\nconcentration in an office coupled with human behaviour.\n", "versions": [{"version": "v1", "created": "Thu, 19 May 2016 14:16:39 GMT"}], "update_date": "2016-05-20", "authors_parsed": [["Tijani", "Khadija", "", "CSTB, LIG Laboratoire d'Informatique de Grenoble,\n  G-SCOP"], ["Ploix", "Stephane", "", "G-SCOP"], ["Haas", "Benjamin", "", "CSTB"], ["Dugdale", "Julie", "", "LIG\n  Laboratoire d'Informatique de Grenoble"], ["Ngo", "Quoc Dung", ""]]}, {"id": "1605.06047", "submitter": "Gerasimos Spanakis", "authors": "Gerasimos Spanakis, Gerhard Weiss", "title": "AMSOM: Adaptive Moving Self-organizing Map for Clustering and\n  Visualization", "comments": "ICAART 2016 accepted full paper", "journal-ref": null, "doi": "10.5220/0005704801290140", "report-no": null, "categories": "cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Self-Organizing Map (SOM) is a neural network model which is used to obtain a\ntopology-preserving mapping from the (usually high dimensional) input/feature\nspace to an output/map space of fewer dimensions (usually two or three in order\nto facilitate visualization). Neurons in the output space are connected with\neach other but this structure remains fixed throughout training and learning is\nachieved through the updating of neuron reference vectors in feature space.\nDespite the fact that growing variants of SOM overcome the fixed structure\nlimitation they increase computational cost and also do not allow the removal\nof a neuron after its introduction. In this paper, a variant of SOM is proposed\ncalled AMSOM (Adaptive Moving Self-Organizing Map) that on the one hand creates\na more flexible structure where neuron positions are dynamically altered during\ntraining and on the other hand tackles the drawback of having a predefined grid\nby allowing neuron addition and/or removal during training. Experiments using\nmultiple literature datasets show that the proposed method improves training\nperformance of SOM, leads to a better visualization of the input dataset and\nprovides a framework for determining the optimal number and structure of\nneurons.\n", "versions": [{"version": "v1", "created": "Thu, 19 May 2016 16:41:00 GMT"}], "update_date": "2016-05-20", "authors_parsed": [["Spanakis", "Gerasimos", ""], ["Weiss", "Gerhard", ""]]}, {"id": "1605.06048", "submitter": "Vincent Conitzer", "authors": "Vincent Conitzer", "title": "Philosophy in the Face of Artificial Intelligence", "comments": "Prospect, May 4, 2016.\n  http://www.prospectmagazine.co.uk/science-and-technology/artificial-intelligence-wheres-the-philosophical-scrutiny", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this article, I discuss how the AI community views concerns about the\nemergence of superintelligent AI and related philosophical issues.\n", "versions": [{"version": "v1", "created": "Thu, 19 May 2016 16:45:12 GMT"}], "update_date": "2016-05-20", "authors_parsed": [["Conitzer", "Vincent", ""]]}, {"id": "1605.06069", "submitter": "Iulian Vlad Serban", "authors": "Iulian Vlad Serban, Alessandro Sordoni, Ryan Lowe, Laurent Charlin,\n  Joelle Pineau, Aaron Courville, Yoshua Bengio", "title": "A Hierarchical Latent Variable Encoder-Decoder Model for Generating\n  Dialogues", "comments": "15 pages, 5 tables, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sequential data often possesses a hierarchical structure with complex\ndependencies between subsequences, such as found between the utterances in a\ndialogue. In an effort to model this kind of generative process, we propose a\nneural network-based generative architecture, with latent stochastic variables\nthat span a variable number of time steps. We apply the proposed model to the\ntask of dialogue response generation and compare it with recent neural network\narchitectures. We evaluate the model performance through automatic evaluation\nmetrics and by carrying out a human evaluation. The experiments demonstrate\nthat our model improves upon recently proposed models and that the latent\nvariables facilitate the generation of long outputs and maintain the context.\n", "versions": [{"version": "v1", "created": "Thu, 19 May 2016 17:59:02 GMT"}, {"version": "v2", "created": "Fri, 20 May 2016 16:02:30 GMT"}, {"version": "v3", "created": "Tue, 14 Jun 2016 02:21:04 GMT"}], "update_date": "2016-06-15", "authors_parsed": [["Serban", "Iulian Vlad", ""], ["Sordoni", "Alessandro", ""], ["Lowe", "Ryan", ""], ["Charlin", "Laurent", ""], ["Pineau", "Joelle", ""], ["Courville", "Aaron", ""], ["Bengio", "Yoshua", ""]]}, {"id": "1605.06181", "submitter": "Yusheng Xie", "authors": "Yusheng Xie, Nan Du, Wei Fan, Jing Zhai, Weicheng Zhu", "title": "Variational hybridization and transformation for large inaccurate\n  noisy-or networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Variational inference provides approximations to the computationally\nintractable posterior distribution in Bayesian networks. A prominent medical\napplication of noisy-or Bayesian network is to infer potential diseases given\nobserved symptoms. Previous studies focus on approximating a handful of\ncomplicated pathological cases using variational transformation. Our goal is to\nuse variational transformation as part of a novel hybridized inference for\nserving reliable and real time diagnosis at web scale. We propose a hybridized\ninference that allows variational parameters to be estimated without disease\nposteriors or priors, making the inference faster and much of its computation\nrecyclable. In addition, we propose a transformation ranking algorithm that is\nvery stable to large variances in network prior probabilities, a common issue\nthat arises in medical applications of Bayesian networks. In experiments, we\nperform comparative study on a large real life medical network and scalability\nstudy on a much larger (36,000x) synthesized network.\n", "versions": [{"version": "v1", "created": "Fri, 20 May 2016 00:31:07 GMT"}], "update_date": "2016-05-23", "authors_parsed": [["Xie", "Yusheng", ""], ["Du", "Nan", ""], ["Fan", "Wei", ""], ["Zhai", "Jing", ""], ["Zhu", "Weicheng", ""]]}, {"id": "1605.06201", "submitter": "Daniel Khashabi Mr.", "authors": "Daniel Khashabi, Kent Quanrud, Amirhossein Taghvaei", "title": "Adversarial Delays in Online Strongly-Convex Optimization", "comments": "We discovered mistakes in the proof of proof of Theorem 3.1. The\n  overall is no longer correct, although the claim is still true", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of strongly-convex online optimization in presence of\nadversarial delays; in a T-iteration online game, the feedback of the player's\nquery at time t is arbitrarily delayed by an adversary for d_t rounds and\ndelivered before the game ends, at iteration t+d_t-1. Specifically for\n\\algo{online-gradient-descent} algorithm we show it has a simple regret bound\nof \\Oh{\\sum_{t=1}^T \\log (1+ \\frac{d_t}{t})}. This gives a clear and simple\nbound without resorting any distributional and limiting assumptions on the\ndelays. We further show how this result encompasses and generalizes several of\nthe existing known results in the literature. Specifically it matches the\ncelebrated logarithmic regret \\Oh{\\log T} when there are no delays (i.e. d_t =\n1) and regret bound of \\Oh{\\tau \\log T} for constant delays d_t = \\tau.\n", "versions": [{"version": "v1", "created": "Fri, 20 May 2016 02:55:59 GMT"}, {"version": "v2", "created": "Wed, 22 Feb 2017 18:41:57 GMT"}, {"version": "v3", "created": "Mon, 9 Sep 2019 18:34:56 GMT"}, {"version": "v4", "created": "Wed, 11 Sep 2019 04:53:49 GMT"}], "update_date": "2019-09-12", "authors_parsed": [["Khashabi", "Daniel", ""], ["Quanrud", "Kent", ""], ["Taghvaei", "Amirhossein", ""]]}, {"id": "1605.06319", "submitter": "Nikola Milo\\v{s}evi\\'c MSc", "authors": "Nikola Milosevic and Goran Nenadic", "title": "As Cool as a Cucumber: Towards a Corpus of Contemporary Similes in\n  Serbian", "comments": "Phrase modelling, simile extraction, language resource building,\n  crowdsourcing", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Similes are natural language expressions used to compare unlikely things,\nwhere the comparison is not taken literally. They are often used in everyday\ncommunication and are an important part of cultural heritage. Having an\nup-to-date corpus of similes is challenging, as they are constantly coined\nand/or adapted to the contemporary times. In this paper we present a\nmethodology for semi-automated collection of similes from the world wide web\nusing text mining techniques. We expanded an existing corpus of traditional\nsimiles (containing 333 similes) by collecting 446 additional expressions. We,\nalso, explore how crowdsourcing can be used to extract and curate new similes.\n", "versions": [{"version": "v1", "created": "Fri, 20 May 2016 12:20:27 GMT"}], "update_date": "2016-05-23", "authors_parsed": [["Milosevic", "Nikola", ""], ["Nenadic", "Goran", ""]]}, {"id": "1605.06377", "submitter": "Christian Gruhl", "authors": "Dominik Fisch, Christian Gruhl, Edgar Kalkowski, Bernhard Sick, Seppo\n  J. Ovaska", "title": "Towards Automation of Knowledge Understanding: An Approach for\n  Probabilistic Generative Classifiers", "comments": "29 pages with 9 figures and 4 tables. Currently under review for\n  Information Sciences", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  After data selection, pre-processing, transformation, and feature extraction,\nknowledge extraction is not the final step in a data mining process. It is then\nnecessary to understand this knowledge in order to apply it efficiently and\neffectively. Up to now, there is a lack of appropriate techniques that support\nthis significant step. This is partly due to the fact that the assessment of\nknowledge is often highly subjective, e.g., regarding aspects such as novelty\nor usefulness. These aspects depend on the specific knowledge and requirements\nof the data miner. There are, however, a number of aspects that are objective\nand for which it is possible to provide appropriate measures. In this article\nwe focus on classification problems and use probabilistic generative\nclassifiers based on mixture density models that are quite common in data\nmining applications. We define objective measures to assess the\ninformativeness, uniqueness, importance, discrimination, representativity,\nuncertainty, and distinguishability of rules contained in these classifiers\nnumerically. These measures not only support a data miner in evaluating results\nof a data mining process based on such classifiers. As we will see in\nillustrative case studies, they may also be used to improve the data mining\nprocess itself or to support the later application of the extracted knowledge.\n", "versions": [{"version": "v1", "created": "Fri, 20 May 2016 14:34:49 GMT"}], "update_date": "2016-05-23", "authors_parsed": [["Fisch", "Dominik", ""], ["Gruhl", "Christian", ""], ["Kalkowski", "Edgar", ""], ["Sick", "Bernhard", ""], ["Ovaska", "Seppo J.", ""]]}, {"id": "1605.06431", "submitter": "Andreas Veit", "authors": "Andreas Veit, Michael Wilber, Serge Belongie", "title": "Residual Networks Behave Like Ensembles of Relatively Shallow Networks", "comments": "NIPS 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we propose a novel interpretation of residual networks showing\nthat they can be seen as a collection of many paths of differing length.\nMoreover, residual networks seem to enable very deep networks by leveraging\nonly the short paths during training. To support this observation, we rewrite\nresidual networks as an explicit collection of paths. Unlike traditional\nmodels, paths through residual networks vary in length. Further, a lesion study\nreveals that these paths show ensemble-like behavior in the sense that they do\nnot strongly depend on each other. Finally, and most surprising, most paths are\nshorter than one might expect, and only the short paths are needed during\ntraining, as longer paths do not contribute any gradient. For example, most of\nthe gradient in a residual network with 110 layers comes from paths that are\nonly 10-34 layers deep. Our results reveal one of the key characteristics that\nseem to enable the training of very deep networks: Residual networks avoid the\nvanishing gradient problem by introducing short paths which can carry gradient\nthroughout the extent of very deep networks.\n", "versions": [{"version": "v1", "created": "Fri, 20 May 2016 16:44:03 GMT"}, {"version": "v2", "created": "Thu, 27 Oct 2016 00:43:58 GMT"}], "update_date": "2016-10-28", "authors_parsed": [["Veit", "Andreas", ""], ["Wilber", "Michael", ""], ["Belongie", "Serge", ""]]}, {"id": "1605.06450", "submitter": "Jiakai Zhang", "authors": "Jiakai Zhang, Kyunghyun Cho", "title": "Query-Efficient Imitation Learning for End-to-End Autonomous Driving", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One way to approach end-to-end autonomous driving is to learn a policy\nfunction that maps from a sensory input, such as an image frame from a\nfront-facing camera, to a driving action, by imitating an expert driver, or a\nreference policy. This can be done by supervised learning, where a policy\nfunction is tuned to minimize the difference between the predicted and\nground-truth actions. A policy function trained in this way however is known to\nsuffer from unexpected behaviours due to the mismatch between the states\nreachable by the reference policy and trained policy functions. More advanced\nalgorithms for imitation learning, such as DAgger, addresses this issue by\niteratively collecting training examples from both reference and trained\npolicies. These algorithms often requires a large number of queries to a\nreference policy, which is undesirable as the reference policy is often\nexpensive. In this paper, we propose an extension of the DAgger, called\nSafeDAgger, that is query-efficient and more suitable for end-to-end autonomous\ndriving. We evaluate the proposed SafeDAgger in a car racing simulator and show\nthat it indeed requires less queries to a reference policy. We observe a\nsignificant speed up in convergence, which we conjecture to be due to the\neffect of automated curriculum learning.\n", "versions": [{"version": "v1", "created": "Fri, 20 May 2016 17:40:16 GMT"}], "update_date": "2016-05-23", "authors_parsed": [["Zhang", "Jiakai", ""], ["Cho", "Kyunghyun", ""]]}, {"id": "1605.06466", "submitter": "Mohammad Abdollahi Azgomi Dr.", "authors": "Reyhaneh Ghassem Esfahani, Mohammad Abadollahi Azgomi and Reza Fathi", "title": "Anomaly Detection in XML-Structured SOAP Messages Using Tree-Based\n  Association Rule Mining", "comments": "Trustworthy Computing Laboratory, School of Computer Engineering,\n  Iran University of Science and Technology", "journal-ref": null, "doi": null, "report-no": "Technical Report No. TWcL-TR-1501, Trustworthy Computing Laboratory,\n  School of Computer Engineering, Iran University of Science and Technology,\n  Tehran, Iran, 2015", "categories": "cs.CR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Web services are software systems designed for supporting interoperable\ndynamic cross-enterprise interactions. The result of attacks to Web services\ncan be catastrophic and causing the disclosure of enterprises' confidential\ndata. As new approaches of attacking arise every day, anomaly detection systems\nseem to be invaluable tools in this context. The aim of this work has been to\ntarget the attacks that reside in the Web service layer and the extensible\nmarkup language (XML)-structured simple object access protocol (SOAP) messages.\nAfter studying the shortcomings of the existing solutions, a new approach for\ndetecting anomalies in Web services is outlined. More specifically, the\nproposed technique illustrates how to identify anomalies by employing mining\nmethods on XML-structured SOAP messages. This technique also takes the\nadvantages of tree-based association rule mining to extract knowledge in the\ntraining phase, which is used in the test phase to detect anomalies. In\naddition, this novel composition of techniques brings nearly low false alarm\nrate while maintaining the detection rate reasonably high, which is shown by a\ncase study.\n", "versions": [{"version": "v1", "created": "Fri, 20 May 2016 18:43:44 GMT"}], "update_date": "2016-05-23", "authors_parsed": [["Esfahani", "Reyhaneh Ghassem", ""], ["Azgomi", "Mohammad Abadollahi", ""], ["Fathi", "Reza", ""]]}, {"id": "1605.06523", "submitter": "William Cohen", "authors": "William W. Cohen", "title": "TensorLog: A Differentiable Deductive Database", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.DB cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large knowledge bases (KBs) are useful in many tasks, but it is unclear how\nto integrate this sort of knowledge into \"deep\" gradient-based learning\nsystems. To address this problem, we describe a probabilistic deductive\ndatabase, called TensorLog, in which reasoning uses a differentiable process.\nIn TensorLog, each clause in a logical theory is first converted into certain\ntype of factor graph. Then, for each type of query to the factor graph, the\nmessage-passing steps required to perform belief propagation (BP) are\n\"unrolled\" into a function, which is differentiable. We show that these\nfunctions can be composed recursively to perform inference in non-trivial\nlogical theories containing multiple interrelated clauses and predicates. Both\ncompilation and inference in TensorLog are efficient: compilation is linear in\ntheory size and proof depth, and inference is linear in database size and the\nnumber of message-passing steps used in BP. We also present experimental\nresults with TensorLog and discuss its relationship to other first-order\nprobabilistic logics.\n", "versions": [{"version": "v1", "created": "Fri, 20 May 2016 20:10:46 GMT"}, {"version": "v2", "created": "Tue, 19 Jul 2016 21:03:55 GMT"}], "update_date": "2016-07-21", "authors_parsed": [["Cohen", "William W.", ""]]}, {"id": "1605.06588", "submitter": "Sam Ganzfried", "authors": "Sam Ganzfried and Farzana Yusuf", "title": "Optimal Number of Choices in Rating Contexts", "comments": null, "journal-ref": "Big Data Cogn. Comput. 2019, 3, 48", "doi": "10.3390/bdcc3030048", "report-no": null, "categories": "cs.AI cs.IT cs.SI eess.SP math.IT math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many settings people must give numerical scores to entities from a small\ndiscrete set. For instance, rating physical attractiveness from 1--5 on dating\nsites, or papers from 1--10 for conference reviewing. We study the problem of\nunderstanding when using a different number of options is optimal. We consider\nthe case when scores are uniform random and Gaussian. We study computationally\nwhen using 2, 3, 4, 5, and 10 options out of a total of 100 is optimal in these\nmodels (though our theoretical analysis is for a more general setting with $k$\nchoices from $n$ total options as well as a continuous underlying space). One\nmay expect that using more options would always improve performance in this\nmodel, but we show that this is not necessarily the case, and that using fewer\nchoices---even just two---can surprisingly be optimal in certain situations.\nWhile in theory for this setting it would be optimal to use all 100 options, in\npractice this is prohibitive, and it is preferable to utilize a smaller number\nof options due to humans' limited computational resources. Our results could\nhave many potential applications, as settings requiring entities to be ranked\nby humans are ubiquitous. There could also be applications to other fields such\nas signal or image processing where input values from a large set must be\nmapped to output values in a smaller set.\n", "versions": [{"version": "v1", "created": "Sat, 21 May 2016 05:09:11 GMT"}, {"version": "v2", "created": "Mon, 30 May 2016 20:38:30 GMT"}, {"version": "v3", "created": "Sat, 17 Sep 2016 20:23:12 GMT"}, {"version": "v4", "created": "Fri, 18 Nov 2016 06:32:09 GMT"}, {"version": "v5", "created": "Wed, 15 Feb 2017 06:48:28 GMT"}, {"version": "v6", "created": "Tue, 30 Jan 2018 07:49:07 GMT"}, {"version": "v7", "created": "Wed, 12 Sep 2018 07:41:06 GMT"}, {"version": "v8", "created": "Tue, 6 Nov 2018 10:09:24 GMT"}, {"version": "v9", "created": "Wed, 7 Nov 2018 01:49:14 GMT"}], "update_date": "2019-08-28", "authors_parsed": [["Ganzfried", "Sam", ""], ["Yusuf", "Farzana", ""]]}, {"id": "1605.06593", "submitter": "Zheng Wen", "authors": "Zheng Wen, Branislav Kveton, Michal Valko, Sharan Vaswani", "title": "Online Influence Maximization under Independent Cascade Model with\n  Semi-Bandit Feedback", "comments": "Compared with the previous version, this version has fixed a mistake.\n  This version is also consistent with the NIPS camera-ready version", "journal-ref": "Z. Wen, B. Kveton, M. Valko, and S. Vaswani, \"Online Influence\n  Maximization under Independent Cascade Model with Semi-Bandit Feedback\",\n  Advances in Neural Information Processing Systems 30 Proceedings, 2017", "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.SI math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the online influence maximization problem in social networks under\nthe independent cascade model. Specifically, we aim to learn the set of \"best\ninfluencers\" in a social network online while repeatedly interacting with it.\nWe address the challenges of (i) combinatorial action space, since the number\nof feasible influencer sets grows exponentially with the maximum number of\ninfluencers, and (ii) limited feedback, since only the influenced portion of\nthe network is observed. Under a stochastic semi-bandit feedback, we propose\nand analyze IMLinUCB, a computationally efficient UCB-based algorithm. Our\nbounds on the cumulative regret are polynomial in all quantities of interest,\nachieve near-optimal dependence on the number of interactions and reflect the\ntopology of the network and the activation probabilities of its edges, thereby\ngiving insights on the problem complexity. To the best of our knowledge, these\nare the first such results. Our experiments show that in several representative\ngraph topologies, the regret of IMLinUCB scales as suggested by our upper\nbounds. IMLinUCB permits linear generalization and thus is both statistically\nand computationally suitable for large-scale problems. Our experiments also\nshow that IMLinUCB with linear generalization can lead to low regret in\nreal-world online influence maximization.\n", "versions": [{"version": "v1", "created": "Sat, 21 May 2016 06:07:53 GMT"}, {"version": "v2", "created": "Mon, 22 May 2017 23:36:42 GMT"}, {"version": "v3", "created": "Tue, 19 Jun 2018 05:51:52 GMT"}], "update_date": "2018-06-20", "authors_parsed": [["Wen", "Zheng", ""], ["Kveton", "Branislav", ""], ["Valko", "Michal", ""], ["Vaswani", "Sharan", ""]]}, {"id": "1605.06640", "submitter": "Matko Bo\\v{s}njak", "authors": "Matko Bo\\v{s}njak, Tim Rockt\\\"aschel, Jason Naradowsky, Sebastian\n  Riedel", "title": "Programming with a Differentiable Forth Interpreter", "comments": "34th International Conference on Machine Learning (ICML 2017)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given that in practice training data is scarce for all but a small set of\nproblems, a core question is how to incorporate prior knowledge into a model.\nIn this paper, we consider the case of prior procedural knowledge for neural\nnetworks, such as knowing how a program should traverse a sequence, but not\nwhat local actions should be performed at each step. To this end, we present an\nend-to-end differentiable interpreter for the programming language Forth which\nenables programmers to write program sketches with slots that can be filled\nwith behaviour trained from program input-output data. We can optimise this\nbehaviour directly through gradient descent techniques on user-specified\nobjectives, and also integrate the program into any larger neural computation\ngraph. We show empirically that our interpreter is able to effectively leverage\ndifferent levels of prior program structure and learn complex behaviours such\nas sequence sorting and addition. When connected to outputs of an LSTM and\ntrained jointly, our interpreter achieves state-of-the-art accuracy for\nend-to-end reasoning about quantities expressed in natural language stories.\n", "versions": [{"version": "v1", "created": "Sat, 21 May 2016 13:24:14 GMT"}, {"version": "v2", "created": "Sat, 5 Nov 2016 19:15:44 GMT"}, {"version": "v3", "created": "Sun, 23 Jul 2017 09:20:48 GMT"}], "update_date": "2017-07-25", "authors_parsed": [["Bo\u0161njak", "Matko", ""], ["Rockt\u00e4schel", "Tim", ""], ["Naradowsky", "Jason", ""], ["Riedel", "Sebastian", ""]]}, {"id": "1605.06676", "submitter": "Jakob Foerster", "authors": "Jakob N. Foerster, Yannis M. Assael, Nando de Freitas, Shimon Whiteson", "title": "Learning to Communicate with Deep Multi-Agent Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of multiple agents sensing and acting in environments\nwith the goal of maximising their shared utility. In these environments, agents\nmust learn communication protocols in order to share information that is needed\nto solve the tasks. By embracing deep neural networks, we are able to\ndemonstrate end-to-end learning of protocols in complex environments inspired\nby communication riddles and multi-agent computer vision problems with partial\nobservability. We propose two approaches for learning in these domains:\nReinforced Inter-Agent Learning (RIAL) and Differentiable Inter-Agent Learning\n(DIAL). The former uses deep Q-learning, while the latter exploits the fact\nthat, during learning, agents can backpropagate error derivatives through\n(noisy) communication channels. Hence, this approach uses centralised learning\nbut decentralised execution. Our experiments introduce new environments for\nstudying the learning of communication protocols and present a set of\nengineering innovations that are essential for success in these domains.\n", "versions": [{"version": "v1", "created": "Sat, 21 May 2016 17:20:04 GMT"}, {"version": "v2", "created": "Tue, 24 May 2016 18:16:56 GMT"}], "update_date": "2016-05-25", "authors_parsed": [["Foerster", "Jakob N.", ""], ["Assael", "Yannis M.", ""], ["de Freitas", "Nando", ""], ["Whiteson", "Shimon", ""]]}, {"id": "1605.06838", "submitter": "Ridho Rahmadi", "authors": "Ridho Rahmadi, Perry Groot, Marieke HC van Rijn, Jan AJG van den\n  Brand, Marianne Heins, Hans Knoop, Tom Heskes (the Alzheimer's Disease\n  Neuroimaging Initiatives, the MASTERPLAN Study Group, the OPTIMISTIC\n  Consortium)", "title": "Causality on Longitudinal Data: Stable Specification Search in\n  Constrained Structural Equation Modeling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A typical problem in causal modeling is the instability of model structure\nlearning, i.e., small changes in finite data can result in completely different\noptimal models. The present work introduces a novel causal modeling algorithm\nfor longitudinal data, that is robust for finite samples based on recent\nadvances in stability selection using subsampling and selection algorithms. Our\napproach uses exploratory search but allows incorporation of prior knowledge,\ne.g., the absence of a particular causal relationship between two specific\nvariables. We represent causal relationships using structural equation models.\nModels are scored along two objectives: the model fit and the model complexity.\nSince both objectives are often conflicting we apply a multi-objective\nevolutionary algorithm to search for Pareto optimal models. To handle the\ninstability of small finite data samples, we repeatedly subsample the data and\nselect those substructures (from the optimal models) that are both stable and\nparsimonious. These substructures can be visualized through a causal graph. Our\nmore exploratory approach achieves at least comparable performance as, but\noften a significant improvement over state-of-the-art alternative approaches on\na simulated data set with a known ground truth. We also present the results of\nour method on three real-world longitudinal data sets on chronic fatigue\nsyndrome, Alzheimer disease, and chronic kidney disease. The findings obtained\nwith our approach are generally in line with results from more\nhypothesis-driven analyses in earlier studies and suggest some novel\nrelationships that deserve further research.\n", "versions": [{"version": "v1", "created": "Sun, 22 May 2016 19:28:25 GMT"}, {"version": "v2", "created": "Tue, 29 Nov 2016 14:32:02 GMT"}, {"version": "v3", "created": "Tue, 4 Apr 2017 12:46:28 GMT"}], "update_date": "2017-04-05", "authors_parsed": [["Rahmadi", "Ridho", "", "the Alzheimer's Disease\n  Neuroimaging Initiatives, the MASTERPLAN Study Group, the OPTIMISTIC\n  Consortium"], ["Groot", "Perry", "", "the Alzheimer's Disease\n  Neuroimaging Initiatives, the MASTERPLAN Study Group, the OPTIMISTIC\n  Consortium"], ["van Rijn", "Marieke HC", "", "the Alzheimer's Disease\n  Neuroimaging Initiatives, the MASTERPLAN Study Group, the OPTIMISTIC\n  Consortium"], ["Brand", "Jan AJG van den", "", "the Alzheimer's Disease\n  Neuroimaging Initiatives, the MASTERPLAN Study Group, the OPTIMISTIC\n  Consortium"], ["Heins", "Marianne", "", "the Alzheimer's Disease\n  Neuroimaging Initiatives, the MASTERPLAN Study Group, the OPTIMISTIC\n  Consortium"], ["Knoop", "Hans", "", "the Alzheimer's Disease\n  Neuroimaging Initiatives, the MASTERPLAN Study Group, the OPTIMISTIC\n  Consortium"], ["Heskes", "Tom", "", "the Alzheimer's Disease\n  Neuroimaging Initiatives, the MASTERPLAN Study Group, the OPTIMISTIC\n  Consortium"]]}, {"id": "1605.06886", "submitter": "Xuhui Fan", "authors": "Xuhui Fan, Bin Li, Yi Wang, Yang Wang, Fang Chen", "title": "Stochastic Patching Process", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stochastic partition models tailor a product space into a number of\nrectangular regions such that the data within each region exhibit certain types\nof homogeneity. Due to constraints of partition strategy, existing models may\ncause unnecessary dissections in sparse regions when fitting data in dense\nregions. To alleviate this limitation, we propose a parsimonious partition\nmodel, named Stochastic Patching Process (SPP), to deal with multi-dimensional\narrays. SPP adopts an \"enclosing\" strategy to attach rectangular patches to\ndense regions. SPP is self-consistent such that it can be extended to infinite\narrays. We apply SPP to relational modeling and the experimental results\nvalidate its merit compared to the state-of-the-arts.\n", "versions": [{"version": "v1", "created": "Mon, 23 May 2016 03:43:01 GMT"}, {"version": "v2", "created": "Mon, 27 Feb 2017 03:26:56 GMT"}], "update_date": "2017-02-28", "authors_parsed": [["Fan", "Xuhui", ""], ["Li", "Bin", ""], ["Wang", "Yi", ""], ["Wang", "Yang", ""], ["Chen", "Fang", ""]]}, {"id": "1605.06921", "submitter": "Luka Crnkovic-Friis", "authors": "Luka Crnkovic-Friis, Louise Crnkovic-Friis", "title": "Generative Choreography using Deep Learning", "comments": "This article will be presented at the 7th International Conference on\n  Computational Creativity, ICCC2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.MM cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in deep learning have enabled the extraction of high-level\nfeatures from raw sensor data which has opened up new possibilities in many\ndifferent fields, including computer generated choreography. In this paper we\npresent a system chor-rnn for generating novel choreographic material in the\nnuanced choreographic language and style of an individual choreographer. It\nalso shows promising results in producing a higher level compositional\ncohesion, rather than just generating sequences of movement. At the core of\nchor-rnn is a deep recurrent neural network trained on raw motion capture data\nand that can generate new dance sequences for a solo dancer. Chor-rnn can be\nused for collaborative human-machine choreography or as a creative catalyst,\nserving as inspiration for a choreographer.\n", "versions": [{"version": "v1", "created": "Mon, 23 May 2016 07:36:49 GMT"}], "update_date": "2016-05-24", "authors_parsed": [["Crnkovic-Friis", "Luka", ""], ["Crnkovic-Friis", "Louise", ""]]}, {"id": "1605.06940", "submitter": "Barry Hurley", "authors": "Barry Hurley, Deepak Mehta, Barry O'Sullivan", "title": "Elastic Solver: Balancing Solution Time and Energy Consumption", "comments": "Keywords: Combinatorial Optimisation, Energy Minimisation, Parallel\n  Solving", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Combinatorial decision problems arise in many different domains such as\nscheduling, routing, packing, bioinformatics, and many more. Despite recent\nadvances in developing scalable solvers, there are still many problems which\nare often very hard to solve. Typically the most advanced solvers include\nelements which are stochastic in nature. If a same instance is solved many\ntimes using different seeds then depending on the inherent characteristics of a\nproblem instance and the solver, one can observe a highly-variant distribution\nof times spanning multiple orders of magnitude. Therefore, to solve a problem\ninstance efficiently it is often useful to solve the same instance in parallel\nwith different seeds. With the proliferation of cloud computing, it is natural\nto think about an elastic solver which can scale up by launching searches in\nparallel on thousands of machines (or cores). However, this could result in\nconsuming a lot of energy. Moreover, not every instance would require thousands\nof machines. The challenge is to resolve the tradeoff between solution time and\nenergy consumption optimally for a given problem instance. We analyse the\nimpact of the number of machines (or cores) on not only solution time but also\non energy consumption. We highlight that although solution time always drops as\nthe number of machines increases, the relation between the number of machines\nand energy consumption is more complicated. In many cases, the optimal energy\nconsumption may be achieved by a middle ground, we analyse this relationship in\ndetail. The tradeoff between solution time and energy consumption is studied\nfurther, showing that the energy consumption of a solver can be reduced\ndrastically if we increase the solution time marginally. We also develop a\nprediction model, demonstrating that such insights can be exploited to achieve\nfaster solutions times in a more energy efficient manor.\n", "versions": [{"version": "v1", "created": "Mon, 23 May 2016 08:54:27 GMT"}], "update_date": "2016-05-24", "authors_parsed": [["Hurley", "Barry", ""], ["Mehta", "Deepak", ""], ["O'Sullivan", "Barry", ""]]}, {"id": "1605.06995", "submitter": "Mijung Park", "authors": "Mijung Park, Jimmy Foulds, Kamalika Chaudhuri, Max Welling", "title": "DP-EM: Differentially Private Expectation Maximization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The iterative nature of the expectation maximization (EM) algorithm presents\na challenge for privacy-preserving estimation, as each iteration increases the\namount of noise needed. We propose a practical private EM algorithm that\novercomes this challenge using two innovations: (1) a novel moment perturbation\nformulation for differentially private EM (DP-EM), and (2) the use of two\nrecently developed composition methods to bound the privacy \"cost\" of multiple\nEM iterations: the moments accountant (MA) and zero-mean concentrated\ndifferential privacy (zCDP). Both MA and zCDP bound the moment generating\nfunction of the privacy loss random variable and achieve a refined tail bound,\nwhich effectively decrease the amount of additive noise. We present empirical\nresults showing the benefits of our approach, as well as similar performance\nbetween these two composition methods in the DP-EM setting for Gaussian mixture\nmodels. Our approach can be readily extended to many iterative learning\nalgorithms, opening up various exciting future directions.\n", "versions": [{"version": "v1", "created": "Mon, 23 May 2016 12:36:55 GMT"}, {"version": "v2", "created": "Mon, 31 Oct 2016 17:17:01 GMT"}], "update_date": "2016-11-01", "authors_parsed": [["Park", "Mijung", ""], ["Foulds", "Jimmy", ""], ["Chaudhuri", "Kamalika", ""], ["Welling", "Max", ""]]}, {"id": "1605.06996", "submitter": "Josef Urban", "authors": "Chad Brown and Josef Urban", "title": "Extracting Higher-Order Goals from the Mizar Mathematical Library", "comments": "Accepted to CICM 2016. The final publication will be available at\n  Springer", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Certain constructs allowed in Mizar articles cannot be represented in\nfirst-order logic but can be represented in higher-order logic. We describe a\nway to obtain higher-order theorem proving problems from Mizar articles that\nmake use of these constructs. In particular, higher-order logic is used to\nrepresent schemes, a global choice construct and set level binders. The\nhigher-order automated theorem provers Satallax and LEO-II have been run on\ncollections of these problems and the results are discussed.\n", "versions": [{"version": "v1", "created": "Mon, 23 May 2016 12:37:54 GMT"}], "update_date": "2016-05-24", "authors_parsed": [["Brown", "Chad", ""], ["Urban", "Josef", ""]]}, {"id": "1605.07026", "submitter": "Bappaditya Mandal", "authors": "Bappaditya Mandal and Nizar Ouarti", "title": "Spontaneous vs. Posed smiles - can we tell the difference?", "comments": "10 pages, 5 figures, 6 tables, International Conference on Computer\n  Vision and Image Processing (CVIP 2016)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Smile is an irrefutable expression that shows the physical state of the mind\nin both true and deceptive ways. Generally, it shows happy state of the mind,\nhowever, `smiles' can be deceptive, for example people can give a smile when\nthey feel happy and sometimes they might also give a smile (in a different way)\nwhen they feel pity for others. This work aims to distinguish spontaneous\n(felt) smile expressions from posed (deliberate) smiles by extracting and\nanalyzing both global (macro) motion of the face and subtle (micro) changes in\nthe facial expression features through both tracking a series of facial\nfiducial markers as well as using dense optical flow. Specifically the eyes and\nlips features are captured and used for analysis. It aims to automatically\nclassify all smiles into either `spontaneous' or `posed' categories, by using\nsupport vector machines (SVM). Experimental results on large database show\npromising results as compared to other relevant methods.\n", "versions": [{"version": "v1", "created": "Mon, 23 May 2016 14:21:30 GMT"}], "update_date": "2016-05-24", "authors_parsed": [["Mandal", "Bappaditya", ""], ["Ouarti", "Nizar", ""]]}, {"id": "1605.07079", "submitter": "Aaron Klein", "authors": "Aaron Klein, Stefan Falkner, Simon Bartels, Philipp Hennig, Frank\n  Hutter", "title": "Fast Bayesian Optimization of Machine Learning Hyperparameters on Large\n  Datasets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian optimization has become a successful tool for hyperparameter\noptimization of machine learning algorithms, such as support vector machines or\ndeep neural networks. Despite its success, for large datasets, training and\nvalidating a single configuration often takes hours, days, or even weeks, which\nlimits the achievable performance. To accelerate hyperparameter optimization,\nwe propose a generative model for the validation error as a function of\ntraining set size, which is learned during the optimization process and allows\nexploration of preliminary configurations on small subsets, by extrapolating to\nthe full dataset. We construct a Bayesian optimization procedure, dubbed\nFabolas, which models loss and training time as a function of dataset size and\nautomatically trades off high information gain about the global optimum against\ncomputational cost. Experiments optimizing support vector machines and deep\nneural networks show that Fabolas often finds high-quality solutions 10 to 100\ntimes faster than other state-of-the-art Bayesian optimization methods or the\nrecently proposed bandit strategy Hyperband.\n", "versions": [{"version": "v1", "created": "Mon, 23 May 2016 16:29:51 GMT"}, {"version": "v2", "created": "Tue, 7 Mar 2017 14:48:54 GMT"}], "update_date": "2017-03-08", "authors_parsed": [["Klein", "Aaron", ""], ["Falkner", "Stefan", ""], ["Bartels", "Simon", ""], ["Hennig", "Philipp", ""], ["Hutter", "Frank", ""]]}, {"id": "1605.07148", "submitter": "Tuomas Haarnoja", "authors": "Tuomas Haarnoja, Anurag Ajay, Sergey Levine, Pieter Abbeel", "title": "Backprop KF: Learning Discriminative Deterministic State Estimators", "comments": "NIPS 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative state estimators based on probabilistic filters and smoothers are\none of the most popular classes of state estimators for robots and autonomous\nvehicles. However, generative models have limited capacity to handle rich\nsensory observations, such as camera images, since they must model the entire\ndistribution over sensor readings. Discriminative models do not suffer from\nthis limitation, but are typically more complex to train as latent variable\nmodels for state estimation. We present an alternative approach where the\nparameters of the latent state distribution are directly optimized as a\ndeterministic computation graph, resulting in a simple and effective gradient\ndescent algorithm for training discriminative state estimators. We show that\nthis procedure can be used to train state estimators that use complex input,\nsuch as raw camera images, which must be processed using expressive nonlinear\nfunction approximators such as convolutional neural networks. Our model can be\nviewed as a type of recurrent neural network, and the connection to\nprobabilistic filtering allows us to design a network architecture that is\nparticularly well suited for state estimation. We evaluate our approach on\nsynthetic tracking task with raw image inputs and on the visual odometry task\nin the KITTI dataset. The results show significant improvement over both\nstandard generative approaches and regular recurrent neural networks.\n", "versions": [{"version": "v1", "created": "Mon, 23 May 2016 19:28:21 GMT"}, {"version": "v2", "created": "Sun, 17 Jul 2016 01:43:34 GMT"}, {"version": "v3", "created": "Sun, 30 Oct 2016 05:15:47 GMT"}, {"version": "v4", "created": "Sun, 1 Oct 2017 00:57:20 GMT"}], "update_date": "2017-10-03", "authors_parsed": [["Haarnoja", "Tuomas", ""], ["Ajay", "Anurag", ""], ["Levine", "Sergey", ""], ["Abbeel", "Pieter", ""]]}, {"id": "1605.07156", "submitter": "Sasha Targ", "authors": "Laura Deming, Sasha Targ, Nate Sauder, Diogo Almeida, Chun Jimmie Ye", "title": "Genetic Architect: Discovering Genomic Structure with Learned Neural\n  Architectures", "comments": "10 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Each human genome is a 3 billion base pair set of encoding instructions.\nDecoding the genome using deep learning fundamentally differs from most tasks,\nas we do not know the full structure of the data and therefore cannot design\narchitectures to suit it. As such, architectures that fit the structure of\ngenomics should be learned not prescribed. Here, we develop a novel search\nalgorithm, applicable across domains, that discovers an optimal architecture\nwhich simultaneously learns general genomic patterns and identifies the most\nimportant sequence motifs in predicting functional genomic outcomes. The\narchitectures we find using this algorithm succeed at using only RNA expression\ndata to predict gene regulatory structure, learn human-interpretable\nvisualizations of key sequence motifs, and surpass state-of-the-art results on\nbenchmark genomics challenges.\n", "versions": [{"version": "v1", "created": "Mon, 23 May 2016 19:43:08 GMT"}], "update_date": "2016-05-24", "authors_parsed": [["Deming", "Laura", ""], ["Targ", "Sasha", ""], ["Sauder", "Nate", ""], ["Almeida", "Diogo", ""], ["Ye", "Chun Jimmie", ""]]}, {"id": "1605.07157", "submitter": "Chelsea Finn", "authors": "Chelsea Finn, Ian Goodfellow, Sergey Levine", "title": "Unsupervised Learning for Physical Interaction through Video Prediction", "comments": "To appear in NIPS '16; Video results, code, and data available at:\n  http://www.sites.google.com/site/robotprediction", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A core challenge for an agent learning to interact with the world is to\npredict how its actions affect objects in its environment. Many existing\nmethods for learning the dynamics of physical interactions require labeled\nobject information. However, to scale real-world interaction learning to a\nvariety of scenes and objects, acquiring labeled data becomes increasingly\nimpractical. To learn about physical object motion without labels, we develop\nan action-conditioned video prediction model that explicitly models pixel\nmotion, by predicting a distribution over pixel motion from previous frames.\nBecause our model explicitly predicts motion, it is partially invariant to\nobject appearance, enabling it to generalize to previously unseen objects. To\nexplore video prediction for real-world interactive agents, we also introduce a\ndataset of 59,000 robot interactions involving pushing motions, including a\ntest set with novel objects. In this dataset, accurate prediction of videos\nconditioned on the robot's future actions amounts to learning a \"visual\nimagination\" of different futures based on different courses of action. Our\nexperiments show that our proposed method produces more accurate video\npredictions both quantitatively and qualitatively, when compared to prior\nmethods.\n", "versions": [{"version": "v1", "created": "Mon, 23 May 2016 19:45:55 GMT"}, {"version": "v2", "created": "Tue, 24 May 2016 19:33:23 GMT"}, {"version": "v3", "created": "Thu, 9 Jun 2016 00:29:37 GMT"}, {"version": "v4", "created": "Mon, 17 Oct 2016 20:09:56 GMT"}], "update_date": "2016-10-19", "authors_parsed": [["Finn", "Chelsea", ""], ["Goodfellow", "Ian", ""], ["Levine", "Sergey", ""]]}, {"id": "1605.07246", "submitter": "Zheng Xu", "authors": "Zheng Xu, Mario A. T. Figueiredo, Tom Goldstein", "title": "Adaptive ADMM with Spectral Penalty Parameter Selection", "comments": "AISTATS 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The alternating direction method of multipliers (ADMM) is a versatile tool\nfor solving a wide range of constrained optimization problems, with\ndifferentiable or non-differentiable objective functions. Unfortunately, its\nperformance is highly sensitive to a penalty parameter, which makes ADMM often\nunreliable and hard to automate for a non-expert user. We tackle this weakness\nof ADMM by proposing a method to adaptively tune the penalty parameters to\nachieve fast convergence. The resulting adaptive ADMM (AADMM) algorithm,\ninspired by the successful Barzilai-Borwein spectral method for gradient\ndescent, yields fast convergence and relative insensitivity to the initial\nstepsize and problem scaling.\n", "versions": [{"version": "v1", "created": "Tue, 24 May 2016 00:48:28 GMT"}, {"version": "v2", "created": "Fri, 10 Jun 2016 19:21:26 GMT"}, {"version": "v3", "created": "Fri, 9 Sep 2016 19:51:17 GMT"}, {"version": "v4", "created": "Wed, 25 Jan 2017 18:49:04 GMT"}, {"version": "v5", "created": "Wed, 19 Jul 2017 16:23:11 GMT"}], "update_date": "2017-07-20", "authors_parsed": [["Xu", "Zheng", ""], ["Figueiredo", "Mario A. T.", ""], ["Goldstein", "Tom", ""]]}, {"id": "1605.07260", "submitter": "Matthieu Vernier", "authors": "Matthieu Vernier, Luis Carcamo, Eliana Scheihing", "title": "Diagnosing editorial strategies of Chilean media on Twitter using an\n  automatic news classifier", "comments": "in Spanish", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In Chile, does not exist an independent entity that publishes quantitative or\nqualitative surveys to understand the traditional media environment and its\nadaptation on the Social Web. Nowadays, Chilean newsreaders are increasingly\nusing social web platforms as their primary source of information, among which\nTwitter plays a central role. Historical media and pure players are developing\ndifferent strategies to increase their audience and influence on this platform.\nIn this article, we propose a methodology based on data mining techniques to\nprovide a first level of analysis of the new Chilean media environment. We use\na crawling technique to mine news streams of 37 different Chilean media\nactively presents on Twitter and propose several indicators to compare them. We\nanalyze their volumes of production, their potential audience, and using NLP\ntechniques, we explore the content of their production: their editorial line\nand their geographic coverage.\n", "versions": [{"version": "v1", "created": "Tue, 24 May 2016 02:05:09 GMT"}], "update_date": "2016-05-25", "authors_parsed": [["Vernier", "Matthieu", ""], ["Carcamo", "Luis", ""], ["Scheihing", "Eliana", ""]]}, {"id": "1605.07334", "submitter": "Yuxin Chen", "authors": "Yuxin Chen, S. Hamed Hassani, Andreas Krause", "title": "Near-optimal Bayesian Active Learning with Correlated and Noisy Tests", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the Bayesian active learning and experimental design problem,\nwhere the goal is to learn the value of some unknown target variable through a\nsequence of informative, noisy tests. In contrast to prior work, we focus on\nthe challenging, yet practically relevant setting where test outcomes can be\nconditionally dependent given the hidden target variable. Under such\nassumptions, common heuristics, such as greedily performing tests that maximize\nthe reduction in uncertainty of the target, often perform poorly. In this\npaper, we propose ECED, a novel, computationally efficient active learning\nalgorithm, and prove strong theoretical guarantees that hold with correlated,\nnoisy tests. Rather than directly optimizing the prediction error, at each\nstep, ECED picks the test that maximizes the gain in a surrogate objective,\nwhich takes into account the dependencies between tests. Our analysis relies on\nan information-theoretic auxiliary function to track the progress of ECED, and\nutilizes adaptive submodularity to attain the near-optimal bound. We\ndemonstrate strong empirical performance of ECED on two problem instances,\nincluding a Bayesian experimental design task intended to distinguish among\neconomic theories of how people make risky decisions, and an active preference\nlearning task via pairwise comparisons.\n", "versions": [{"version": "v1", "created": "Tue, 24 May 2016 08:25:27 GMT"}, {"version": "v2", "created": "Mon, 11 Jul 2016 06:47:19 GMT"}], "update_date": "2016-07-12", "authors_parsed": [["Chen", "Yuxin", ""], ["Hassani", "S. Hamed", ""], ["Krause", "Andreas", ""]]}, {"id": "1605.07335", "submitter": "Aleksander Lodwich", "authors": "Aleksander Lodwich", "title": "Differences between Industrial Models of Autonomy and Systemic Models of\n  Autonomy", "comments": "11 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper discusses the idea of levels of autonomy of systems - be this\ntechnical or organic - and compares the insights with models employed by\nindustries used to describe maturity and capability of their products.\n", "versions": [{"version": "v1", "created": "Tue, 24 May 2016 08:49:36 GMT"}, {"version": "v2", "created": "Wed, 25 May 2016 17:43:42 GMT"}, {"version": "v3", "created": "Fri, 3 Jun 2016 21:31:44 GMT"}], "update_date": "2016-06-07", "authors_parsed": [["Lodwich", "Aleksander", ""]]}, {"id": "1605.07364", "submitter": "Timothy Ganesan PhD", "authors": "Timothy Ganesan, Pandian Vasant and Irraivan Elamvazuthi", "title": "Non-Gaussian Random Generators in Bacteria Foraging Algorithm for\n  Multiobjective Optimization", "comments": "8 pages; 5 Figures; 6 Tables. Industrial Engineering & Management,\n  2015", "journal-ref": null, "doi": "10.4172/2169-0316.1000182", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Random generators or stochastic engines are a key component in the structure\nof metaheuristic algorithms. This work investigates the effects of non-Gaussian\nstochastic engines on the performance of metaheuristics when solving a\nreal-world optimization problem. In this work, the bacteria foraging algorithm\n(BFA) was employed in tandem with four random generators (stochastic engines).\nThe stochastic engines operate using the Weibull distribution, Gamma\ndistribution, Gaussian distribution and a chaotic mechanism. The two\nnon-Gaussian distributions are the Weibull and Gamma distributions. In this\nwork, the approaches developed were implemented on the real-world\nmulti-objective resin bonded sand mould problem. The Pareto frontiers obtained\nwere benchmarked using two metrics; the hyper volume indicator (HVI) and the\nproposed Average Explorative Rate (AER) metric. Detail discussions from various\nperspectives on the effects of non-Gaussian random generators in metaheuristics\nare provided.\n", "versions": [{"version": "v1", "created": "Tue, 24 May 2016 10:27:17 GMT"}], "update_date": "2016-05-25", "authors_parsed": [["Ganesan", "Timothy", ""], ["Vasant", "Pandian", ""], ["Elamvazuthi", "Irraivan", ""]]}, {"id": "1605.07496", "submitter": "Supratik Paul", "authors": "Supratik Paul, Konstantinos Chatzilygeroudis, Kamil Ciosek,\n  Jean-Baptiste Mouret, Michael A. Osborne, Shimon Whiteson", "title": "Alternating Optimisation and Quadrature for Robust Control", "comments": "To appear in AAAI 2018. Video of policy learnt in simulation deployed\n  on a real hexapod see https://youtu.be/ME90xtIPsKk", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian optimisation has been successfully applied to a variety of\nreinforcement learning problems. However, the traditional approach for learning\noptimal policies in simulators does not utilise the opportunity to improve\nlearning by adjusting certain environment variables: state features that are\nunobservable and randomly determined by the environment in a physical setting\nbut are controllable in a simulator. This paper considers the problem of\nfinding a robust policy while taking into account the impact of environment\nvariables. We present Alternating Optimisation and Quadrature (ALOQ), which\nuses Bayesian optimisation and Bayesian quadrature to address such settings.\nALOQ is robust to the presence of significant rare events, which may not be\nobservable under random sampling, but play a substantial role in determining\nthe optimal policy. Experimental results across different domains show that\nALOQ can learn more efficiently and robustly than existing methods.\n", "versions": [{"version": "v1", "created": "Tue, 24 May 2016 15:15:57 GMT"}, {"version": "v2", "created": "Tue, 20 Sep 2016 12:39:46 GMT"}, {"version": "v3", "created": "Mon, 18 Dec 2017 10:12:32 GMT"}], "update_date": "2017-12-19", "authors_parsed": [["Paul", "Supratik", ""], ["Chatzilygeroudis", "Konstantinos", ""], ["Ciosek", "Kamil", ""], ["Mouret", "Jean-Baptiste", ""], ["Osborne", "Michael A.", ""], ["Whiteson", "Shimon", ""]]}, {"id": "1605.07511", "submitter": "Mijung Park", "authors": "Mijung Park, Max Welling", "title": "A note on privacy preserving iteratively reweighted least squares", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Iteratively reweighted least squares (IRLS) is a widely-used method in\nmachine learning to estimate the parameters in the generalised linear models.\nIn particular, IRLS for L1 minimisation under the linear model provides a\nclosed-form solution in each step, which is a simple multiplication between the\ninverse of the weighted second moment matrix and the weighted first moment\nvector. When dealing with privacy sensitive data, however, developing a privacy\npreserving IRLS algorithm faces two challenges. First, due to the inversion of\nthe second moment matrix, the usual sensitivity analysis in differential\nprivacy incorporating a single datapoint perturbation gets complicated and\noften requires unrealistic assumptions. Second, due to its iterative nature, a\nsignificant cumulative privacy loss occurs. However, adding a high level of\nnoise to compensate for the privacy loss hinders from getting accurate\nestimates. Here, we develop a practical algorithm that overcomes these\nchallenges and outputs privatised and accurate IRLS solutions. In our method,\nwe analyse the sensitivity of each moments separately and treat the matrix\ninversion and multiplication as a post-processing step, which simplifies the\nsensitivity analysis. Furthermore, we apply the {\\it{concentrated differential\nprivacy}} formalism, a more relaxed version of differential privacy, which\nrequires adding a significantly less amount of noise for the same level of\nprivacy guarantee, compared to the conventional and advanced compositions of\ndifferentially private mechanisms.\n", "versions": [{"version": "v1", "created": "Tue, 24 May 2016 15:50:26 GMT"}], "update_date": "2016-05-25", "authors_parsed": [["Park", "Mijung", ""], ["Welling", "Max", ""]]}, {"id": "1605.07574", "submitter": "Mark Levin", "authors": "Mark Sh. Levin", "title": "Towards Bin Packing (preliminary problem survey, models with multiset\n  estimates)", "comments": "39 pages, 18 figures, 14 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper described a generalized integrated glance to bin packing problems\nincluding a brief literature survey and some new problem formulations for the\ncases of multiset estimates of items. A new systemic viewpoint to bin packing\nproblems is suggested: (a) basic element sets (item set, bin set, item subset\nassigned to bin), (b) binary relation over the sets: relation over item set as\ncompatibility, precedence, dominance; relation over items and bins (i.e.,\ncorrespondence of items to bins). A special attention is targeted to the\nfollowing versions of bin packing problems: (a) problem with multiset estimates\nof items, (b) problem with colored items (and some close problems). Applied\nexamples of bin packing problems are considered: (i) planning in paper industry\n(framework of combinatorial problems), (ii) selection of information messages,\n(iii) packing of messages/information packages in WiMAX communication system\n(brief description).\n", "versions": [{"version": "v1", "created": "Tue, 24 May 2016 18:28:54 GMT"}], "update_date": "2016-05-25", "authors_parsed": [["Levin", "Mark Sh.", ""]]}, {"id": "1605.07604", "submitter": "Alp Kucukelbir", "authors": "Alp Kucukelbir, David M. Blei", "title": "Posterior Dispersion Indices", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Probabilistic modeling is cyclical: we specify a model, infer its posterior,\nand evaluate its performance. Evaluation drives the cycle, as we revise our\nmodel based on how it performs. This requires a metric. Traditionally,\npredictive accuracy prevails. Yet, predictive accuracy does not tell the whole\nstory. We propose to evaluate a model through posterior dispersion. The idea is\nto analyze how each datapoint fares in relation to posterior uncertainty around\nthe hidden structure. We propose a family of posterior dispersion indices (PDI)\nthat capture this idea. A PDI identifies rich patterns of model mismatch in\nthree real data examples: voting preferences, supermarket shopping, and\npopulation genetics.\n", "versions": [{"version": "v1", "created": "Tue, 24 May 2016 19:58:02 GMT"}], "update_date": "2016-05-25", "authors_parsed": [["Kucukelbir", "Alp", ""], ["Blei", "David M.", ""]]}, {"id": "1605.07700", "submitter": "Marlos C. Machado", "authors": "Marlos C. Machado and Michael Bowling", "title": "Learning Purposeful Behaviour in the Absence of Rewards", "comments": "Extended version of the paper presented at the workshop entitled\n  Abstraction in Reinforcement Learning, at the 33rd International Conference\n  on Machine Learning, New York, NY, USA, 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Artificial intelligence is commonly defined as the ability to achieve goals\nin the world. In the reinforcement learning framework, goals are encoded as\nreward functions that guide agent behaviour, and the sum of observed rewards\nprovide a notion of progress. However, some domains have no such reward signal,\nor have a reward signal so sparse as to appear absent. Without reward feedback,\nagent behaviour is typically random, often dithering aimlessly and lacking\nintentionality. In this paper we present an algorithm capable of learning\npurposeful behaviour in the absence of rewards. The algorithm proceeds by\nconstructing temporally extended actions (options), through the identification\nof purposes that are \"just out of reach\" of the agent's current behaviour.\nThese purposes establish intrinsic goals for the agent to learn, ultimately\nresulting in a suite of behaviours that encourage the agent to visit different\nparts of the state space. Moreover, the approach is particularly suited for\nsettings where rewards are very sparse, and such behaviours can help in the\nexploration of the environment until reward is observed.\n", "versions": [{"version": "v1", "created": "Wed, 25 May 2016 01:33:34 GMT"}], "update_date": "2016-05-26", "authors_parsed": [["Machado", "Marlos C.", ""], ["Bowling", "Michael", ""]]}, {"id": "1605.07722", "submitter": "Longqi Yang", "authors": "Longqi Yang, Cheng-Kang Hsieh, Hongjian Yang, Nicola Dell, Serge\n  Belongie, Curtis Cole, Deborah Estrin", "title": "Yum-me: A Personalized Nutrient-based Meal Recommender System", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI cs.CV cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nutrient-based meal recommendations have the potential to help individuals\nprevent or manage conditions such as diabetes and obesity. However, learning\npeople's food preferences and making recommendations that simultaneously appeal\nto their palate and satisfy nutritional expectations are challenging. Existing\napproaches either only learn high-level preferences or require a prolonged\nlearning period. We propose Yum-me, a personalized nutrient-based meal\nrecommender system designed to meet individuals' nutritional expectations,\ndietary restrictions, and fine-grained food preferences. Yum-me enables a\nsimple and accurate food preference profiling procedure via a visual quiz-based\nuser interface, and projects the learned profile into the domain of\nnutritionally appropriate food options to find ones that will appeal to the\nuser. We present the design and implementation of Yum-me, and further describe\nand evaluate two innovative contributions. The first contriution is an open\nsource state-of-the-art food image analysis model, named FoodDist. We\ndemonstrate FoodDist's superior performance through careful benchmarking and\ndiscuss its applicability across a wide array of dietary applications. The\nsecond contribution is a novel online learning framework that learns food\npreference from item-wise and pairwise image comparisons. We evaluate the\nframework in a field study of 227 anonymous users and demonstrate that it\noutperforms other baselines by a significant margin. We further conducted an\nend-to-end validation of the feasibility and effectiveness of Yum-me through a\n60-person user study, in which Yum-me improves the recommendation acceptance\nrate by 42.63%.\n", "versions": [{"version": "v1", "created": "Wed, 25 May 2016 04:13:49 GMT"}, {"version": "v2", "created": "Wed, 21 Dec 2016 14:48:18 GMT"}, {"version": "v3", "created": "Sun, 30 Apr 2017 17:43:02 GMT"}], "update_date": "2017-05-02", "authors_parsed": [["Yang", "Longqi", ""], ["Hsieh", "Cheng-Kang", ""], ["Yang", "Hongjian", ""], ["Dell", "Nicola", ""], ["Belongie", "Serge", ""], ["Cole", "Curtis", ""], ["Estrin", "Deborah", ""]]}, {"id": "1605.07723", "submitter": "Alexander Ratner", "authors": "Alexander Ratner, Christopher De Sa, Sen Wu, Daniel Selsam,\n  Christopher R\\'e", "title": "Data Programming: Creating Large Training Sets, Quickly", "comments": null, "journal-ref": "Advances in Neural Information Processing Systems 29, 2016,\n  3567--3575", "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large labeled training sets are the critical building blocks of supervised\nlearning methods and are key enablers of deep learning techniques. For some\napplications, creating labeled training sets is the most time-consuming and\nexpensive part of applying machine learning. We therefore propose a paradigm\nfor the programmatic creation of training sets called data programming in which\nusers express weak supervision strategies or domain heuristics as labeling\nfunctions, which are programs that label subsets of the data, but that are\nnoisy and may conflict. We show that by explicitly representing this training\nset labeling process as a generative model, we can \"denoise\" the generated\ntraining set, and establish theoretically that we can recover the parameters of\nthese generative models in a handful of settings. We then show how to modify a\ndiscriminative loss function to make it noise-aware, and demonstrate our method\nover a range of discriminative models including logistic regression and LSTMs.\nExperimentally, on the 2014 TAC-KBP Slot Filling challenge, we show that data\nprogramming would have led to a new winning score, and also show that applying\ndata programming to an LSTM model leads to a TAC-KBP score almost 6 F1 points\nover a state-of-the-art LSTM baseline (and into second place in the\ncompetition). Additionally, in initial user studies we observed that data\nprogramming may be an easier way for non-experts to create machine learning\nmodels when training data is limited or unavailable.\n", "versions": [{"version": "v1", "created": "Wed, 25 May 2016 04:14:59 GMT"}, {"version": "v2", "created": "Sat, 3 Dec 2016 20:03:26 GMT"}, {"version": "v3", "created": "Sun, 8 Jan 2017 19:48:53 GMT"}], "update_date": "2018-12-10", "authors_parsed": [["Ratner", "Alexander", ""], ["De Sa", "Christopher", ""], ["Wu", "Sen", ""], ["Selsam", "Daniel", ""], ["R\u00e9", "Christopher", ""]]}, {"id": "1605.07728", "submitter": "John Dickerson", "authors": "John P. Dickerson, Aleksandr M. Kazachkov, Ariel D. Procaccia, Tuomas\n  Sandholm", "title": "Small Representations of Big Kidney Exchange Graphs", "comments": "Preliminary version appeared at the 31st AAAI Conference on\n  Artificial Intelligence (AAAI 2017)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Kidney exchanges are organized markets where patients swap willing but\nincompatible donors. In the last decade, kidney exchanges grew from small and\nregional to large and national---and soon, international. This growth results\nin more lives saved, but exacerbates the empirical hardness of the\n$\\mathcal{NP}$-complete problem of optimally matching patients to donors.\nState-of-the-art matching engines use integer programming techniques to clear\nfielded kidney exchanges, but these methods must be tailored to specific models\nand objective functions, and may fail to scale to larger exchanges. In this\npaper, we observe that if the kidney exchange compatibility graph can be\nencoded by a constant number of patient and donor attributes, the clearing\nproblem is solvable in polynomial time. We give necessary and sufficient\nconditions for losslessly shrinking the representation of an arbitrary\ncompatibility graph. Then, using real compatibility graphs from the UNOS\nnationwide kidney exchange, we show how many attributes are needed to encode\nreal compatibility graphs. The experiments show that, indeed, small numbers of\nattributes suffice.\n", "versions": [{"version": "v1", "created": "Wed, 25 May 2016 04:33:41 GMT"}, {"version": "v2", "created": "Fri, 16 Dec 2016 19:31:20 GMT"}], "update_date": "2016-12-19", "authors_parsed": [["Dickerson", "John P.", ""], ["Kazachkov", "Aleksandr M.", ""], ["Procaccia", "Ariel D.", ""], ["Sandholm", "Tuomas", ""]]}, {"id": "1605.07736", "submitter": "Sainbayar Sukhbaatar", "authors": "Sainbayar Sukhbaatar, Arthur Szlam, Rob Fergus", "title": "Learning Multiagent Communication with Backpropagation", "comments": "Accepted to NIPS 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many tasks in AI require the collaboration of multiple agents. Typically, the\ncommunication protocol between agents is manually specified and not altered\nduring training. In this paper we explore a simple neural model, called\nCommNet, that uses continuous communication for fully cooperative tasks. The\nmodel consists of multiple agents and the communication between them is learned\nalongside their policy. We apply this model to a diverse set of tasks,\ndemonstrating the ability of the agents to learn to communicate amongst\nthemselves, yielding improved performance over non-communicative agents and\nbaselines. In some cases, it is possible to interpret the language devised by\nthe agents, revealing simple but effective strategies for solving the task at\nhand.\n", "versions": [{"version": "v1", "created": "Wed, 25 May 2016 05:33:21 GMT"}, {"version": "v2", "created": "Mon, 31 Oct 2016 17:29:58 GMT"}], "update_date": "2016-11-01", "authors_parsed": [["Sukhbaatar", "Sainbayar", ""], ["Szlam", "Arthur", ""], ["Fergus", "Rob", ""]]}, {"id": "1605.07844", "submitter": "Javid Dadashkarimi", "authors": "Javid Dadashkarimi, Mahsa S. Shahshahani, Amirhossein Tebbifakhr,\n  Heshaam Faili, and Azadeh Shakery", "title": "Dimension Projection among Languages based on Pseudo-relevant Documents\n  for Query Translation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Using top-ranked documents in response to a query has been shown to be an\neffective approach to improve the quality of query translation in\ndictionary-based cross-language information retrieval. In this paper, we\npropose a new method for dictionary-based query translation based on dimension\nprojection of embedded vectors from the pseudo-relevant documents in the source\nlanguage to their equivalents in the target language. To this end, first we\nlearn low-dimensional vectors of the words in the pseudo-relevant collections\nseparately and then aim to find a query-dependent transformation matrix between\nthe vectors of translation pairs appeared in the collections. At the next step,\nrepresentation of each query term is projected to the target language and then,\nafter using a softmax function, a query-dependent translation model is built.\nFinally, the model is used for query translation. Our experiments on four CLEF\ncollections in French, Spanish, German, and Italian demonstrate that the\nproposed method outperforms a word embedding baseline based on bilingual\nshuffling and a further number of competitive baselines. The proposed method\nreaches up to 87% performance of machine translation (MT) in short queries and\nconsiderable improvements in verbose queries.\n", "versions": [{"version": "v1", "created": "Wed, 25 May 2016 12:04:43 GMT"}, {"version": "v2", "created": "Sat, 8 Oct 2016 11:19:10 GMT"}], "update_date": "2016-10-11", "authors_parsed": [["Dadashkarimi", "Javid", ""], ["Shahshahani", "Mahsa S.", ""], ["Tebbifakhr", "Amirhossein", ""], ["Faili", "Heshaam", ""], ["Shakery", "Azadeh", ""]]}, {"id": "1605.07895", "submitter": "Nabiha Asghar", "authors": "Nabiha Asghar", "title": "Automatic Extraction of Causal Relations from Natural Language Texts: A\n  Comprehensive Survey", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic extraction of cause-effect relationships from natural language\ntexts is a challenging open problem in Artificial Intelligence. Most of the\nearly attempts at its solution used manually constructed linguistic and\nsyntactic rules on small and domain-specific data sets. However, with the\nadvent of big data, the availability of affordable computing power and the\nrecent popularization of machine learning, the paradigm to tackle this problem\nhas slowly shifted. Machines are now expected to learn generic causal\nextraction rules from labelled data with minimal supervision, in a domain\nindependent-manner. In this paper, we provide a comprehensive survey of causal\nrelation extraction techniques from both paradigms, and analyse their relative\nstrengths and weaknesses, with recommendations for future work.\n", "versions": [{"version": "v1", "created": "Wed, 25 May 2016 14:23:21 GMT"}], "update_date": "2016-05-26", "authors_parsed": [["Asghar", "Nabiha", ""]]}, {"id": "1605.07918", "submitter": "Byungsoo Kim", "authors": "Byungsoo Kim, Hwanjo Yu, Gary Geunbae Lee", "title": "Automatic Open Knowledge Acquisition via Long Short-Term Memory Networks\n  with Feedback Negative Sampling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Previous studies in Open Information Extraction (Open IE) are mainly based on\nextraction patterns. They manually define patterns or automatically learn them\nfrom a large corpus. However, these approaches are limited when grasping the\ncontext of a sentence, and they fail to capture implicit relations. In this\npaper, we address this problem with the following methods. First, we exploit\nlong short-term memory (LSTM) networks to extract higher-level features along\nthe shortest dependency paths, connecting headwords of relations and arguments.\nThe path-level features from LSTM networks provide useful clues regarding\ncontextual information and the validity of arguments. Second, we constructed\nsamples to train LSTM networks without the need for manual labeling. In\nparticular, feedback negative sampling picks highly negative samples among\nnon-positive samples through a model trained with positive samples. The\nexperimental results show that our approach produces more precise and abundant\nextractions than state-of-the-art open IE systems. To the best of our\nknowledge, this is the first work to apply deep learning to Open IE.\n", "versions": [{"version": "v1", "created": "Wed, 25 May 2016 14:59:46 GMT"}], "update_date": "2016-05-26", "authors_parsed": [["Kim", "Byungsoo", ""], ["Yu", "Hwanjo", ""], ["Lee", "Gary Geunbae", ""]]}, {"id": "1605.07969", "submitter": "Rudy Bunel", "authors": "Rudy Bunel, Alban Desmaison, Pushmeet Kohli, Philip H.S. Torr and M.\n  Pawan Kumar", "title": "Adaptive Neural Compilation", "comments": "Submitted to NIPS 2016, code and supplementary materials will be\n  available on author's page", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes an adaptive neural-compilation framework to address the\nproblem of efficient program learning. Traditional code optimisation strategies\nused in compilers are based on applying pre-specified set of transformations\nthat make the code faster to execute without changing its semantics. In\ncontrast, our work involves adapting programs to make them more efficient while\nconsidering correctness only on a target input distribution. Our approach is\ninspired by the recent works on differentiable representations of programs. We\nshow that it is possible to compile programs written in a low-level language to\na differentiable representation. We also show how programs in this\nrepresentation can be optimised to make them efficient on a target distribution\nof inputs. Experimental results demonstrate that our approach enables learning\nspecifically-tuned algorithms for given data distributions with a high success\nrate.\n", "versions": [{"version": "v1", "created": "Wed, 25 May 2016 17:17:21 GMT"}, {"version": "v2", "created": "Thu, 26 May 2016 15:49:33 GMT"}], "update_date": "2016-05-27", "authors_parsed": [["Bunel", "Rudy", ""], ["Desmaison", "Alban", ""], ["Kohli", "Pushmeet", ""], ["Torr", "Philip H. S.", ""], ["Kumar", "M. Pawan", ""]]}, {"id": "1605.07989", "submitter": "Sailik Sengupta", "authors": "Tathagata Chakraborti, Sarath Sreedharan, Sailik Sengupta, T. K.\n  Satish Kumar, and Subbarao Kambhampati", "title": "Compliant Conditions for Polynomial Time Approximation of Operator\n  Counts", "comments": "Published at the International Symposium on Combinatorial Search\n  (SoCS), 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we develop a computationally simpler version of the operator\ncount heuristic for a particular class of domains. The contribution of this\nabstract is threefold, we (1) propose an efficient closed form approximation to\nthe operator count heuristic using the Lagrangian dual; (2) leverage compressed\nsensing techniques to obtain an integer approximation for operator counts in\npolynomial time; and (3) discuss the relationship of the proposed formulation\nto existing heuristics and investigate properties of domains where such\napproaches appear to be useful.\n", "versions": [{"version": "v1", "created": "Wed, 25 May 2016 18:10:48 GMT"}, {"version": "v2", "created": "Tue, 5 Jul 2016 02:10:11 GMT"}], "update_date": "2016-07-06", "authors_parsed": [["Chakraborti", "Tathagata", ""], ["Sreedharan", "Sarath", ""], ["Sengupta", "Sailik", ""], ["Kumar", "T. K. Satish", ""], ["Kambhampati", "Subbarao", ""]]}, {"id": "1605.07999", "submitter": "Baxter Eaves Jr", "authors": "Baxter S. Eaves Jr and Patrick Shafto", "title": "Toward a general, scaleable framework for Bayesian teaching with\n  applications to topic models", "comments": "7 Pages, 5 Figures, submitted to IJCAI 2016 workshop on Interactive\n  Machine Learning: Connecting Humans and Machines", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machines, not humans, are the world's dominant knowledge accumulators but\nhumans remain the dominant decision makers. Interpreting and disseminating the\nknowledge accumulated by machines requires expertise, time, and is prone to\nfailure. The problem of how best to convey accumulated knowledge from computers\nto humans is a critical bottleneck in the broader application of machine\nlearning. We propose an approach based on human teaching where the problem is\nformalized as selecting a small subset of the data that will, with high\nprobability, lead the human user to the correct inference. This approach,\nthough successful for modeling human learning in simple laboratory experiments,\nhas failed to achieve broader relevance due to challenges in formulating\ngeneral and scalable algorithms. We propose general-purpose teaching via\npseudo-marginal sampling and demonstrate the algorithm by teaching topic\nmodels. Simulation results show our sampling-based approach: effectively\napproximates the probability where ground-truth is possible via enumeration,\nresults in data that are markedly different from those expected by random\nsampling, and speeds learning especially for small amounts of data. Application\nto movie synopsis data illustrates differences between teaching and random\nsampling for teaching distributions and specific topics, and demonstrates gains\nin scalability and applicability to real-world problems.\n", "versions": [{"version": "v1", "created": "Wed, 25 May 2016 18:33:10 GMT"}], "update_date": "2016-06-09", "authors_parsed": [["Eaves", "Baxter S.", "Jr"], ["Shafto", "Patrick", ""]]}, {"id": "1605.08062", "submitter": "Zhaohan Guo", "authors": "Zhaohan Daniel Guo, Shayan Doroudi, Emma Brunskill", "title": "A PAC RL Algorithm for Episodic POMDPs", "comments": null, "journal-ref": "Proceedings of the 19th International Conference on Artificial\n  Intelligence and Statistics, pp. 510-518, 2016", "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many interesting real world domains involve reinforcement learning (RL) in\npartially observable environments. Efficient learning in such domains is\nimportant, but existing sample complexity bounds for partially observable RL\nare at least exponential in the episode length. We give, to our knowledge, the\nfirst partially observable RL algorithm with a polynomial bound on the number\nof episodes on which the algorithm may not achieve near-optimal performance.\nOur algorithm is suitable for an important class of episodic POMDPs. Our\napproach builds on recent advances in method of moments for latent variable\nmodel estimation.\n", "versions": [{"version": "v1", "created": "Wed, 25 May 2016 20:15:38 GMT"}, {"version": "v2", "created": "Wed, 1 Jun 2016 18:23:04 GMT"}], "update_date": "2016-06-02", "authors_parsed": [["Guo", "Zhaohan Daniel", ""], ["Doroudi", "Shayan", ""], ["Brunskill", "Emma", ""]]}, {"id": "1605.08104", "submitter": "William Lotter", "authors": "William Lotter, Gabriel Kreiman, David Cox", "title": "Deep Predictive Coding Networks for Video Prediction and Unsupervised\n  Learning", "comments": "Code and example video clips can be found here:\n  https://coxlab.github.io/prednet/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.NE q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While great strides have been made in using deep learning algorithms to solve\nsupervised learning tasks, the problem of unsupervised learning - leveraging\nunlabeled examples to learn about the structure of a domain - remains a\ndifficult unsolved challenge. Here, we explore prediction of future frames in a\nvideo sequence as an unsupervised learning rule for learning about the\nstructure of the visual world. We describe a predictive neural network\n(\"PredNet\") architecture that is inspired by the concept of \"predictive coding\"\nfrom the neuroscience literature. These networks learn to predict future frames\nin a video sequence, with each layer in the network making local predictions\nand only forwarding deviations from those predictions to subsequent network\nlayers. We show that these networks are able to robustly learn to predict the\nmovement of synthetic (rendered) objects, and that in doing so, the networks\nlearn internal representations that are useful for decoding latent object\nparameters (e.g. pose) that support object recognition with fewer training\nviews. We also show that these networks can scale to complex natural image\nstreams (car-mounted camera videos), capturing key aspects of both egocentric\nmovement and the movement of objects in the visual scene, and the\nrepresentation learned in this setting is useful for estimating the steering\nangle. Altogether, these results suggest that prediction represents a powerful\nframework for unsupervised learning, allowing for implicit learning of object\nand scene structure.\n", "versions": [{"version": "v1", "created": "Wed, 25 May 2016 23:58:55 GMT"}, {"version": "v2", "created": "Tue, 14 Jun 2016 14:36:09 GMT"}, {"version": "v3", "created": "Tue, 30 Aug 2016 00:08:34 GMT"}, {"version": "v4", "created": "Wed, 31 Aug 2016 16:06:03 GMT"}, {"version": "v5", "created": "Wed, 1 Mar 2017 01:00:54 GMT"}], "update_date": "2017-03-02", "authors_parsed": [["Lotter", "William", ""], ["Kreiman", "Gabriel", ""], ["Cox", "David", ""]]}, {"id": "1605.08150", "submitter": "Saman Sarraf", "authors": "Krishanth Krishnan, Taralyn Schwering and Saman Sarraf", "title": "Cognitive Dynamic Systems: A Technical Review of Cognitive Radar", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We start with the history of cognitive radar, where origins of the PAC,\nFuster research on cognition and principals of cognition are provided. Fuster\ndescribes five cognitive functions: perception, memory, attention, language,\nand intelligence. We describe the Perception-Action Cyclec as it applies to\ncognitive radar, and then discuss long-term memory, memory storage, memory\nretrieval and working memory. A comparison between memory in human cognition\nand cognitive radar is given as well. Attention is another function described\nby Fuster, and we have given the comparison of attention in human cognition and\ncognitive radar. We talk about the four functional blocks from the PAC:\nBayesian filter, feedback information, dynamic programming and state-space\nmodel for the radar environment. Then, to show that the PAC improves the\ntracking accuracy of Cognitive Radar over Traditional Active Radar, we have\nprovided simulation results. In the simulation, three nonlinear filters:\nCubature Kalman Filter, Unscented Kalman Filter and Extended Kalman Filter are\ncompared. Based on the results, radars implemented with CKF perform better than\nthe radars implemented with UKF or radars implemented with EKF. Further, radar\nwith EKF has the worst accuracy and has the biggest computation load because of\nderivation and evaluation of Jacobian matrices. We suggest using the concept of\nrisk management to better control parameters and improve performance in\ncognitive radar. We believe, spectrum sensing can be seen as a potential\ninterest to be used in cognitive radar and we propose a new approach\nProbabilistic ICA which will presumably reduce noise based on estimation error\nin cognitive radar. Parallel computing is a concept based on divide and\nconquers mechanism, and we suggest using the parallel computing approach in\ncognitive radar by doing complicated calculations or tasks to reduce processing\ntime.\n", "versions": [{"version": "v1", "created": "Thu, 26 May 2016 05:49:25 GMT"}], "update_date": "2016-05-27", "authors_parsed": [["Krishnan", "Krishanth", ""], ["Schwering", "Taralyn", ""], ["Sarraf", "Saman", ""]]}, {"id": "1605.08187", "submitter": "Martin Mladenov", "authors": "Martin Mladenov and Vaishak Belle and Kristian Kersting", "title": "The Symbolic Interior Point Method", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO cs.SC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A recent trend in probabilistic inference emphasizes the codification of\nmodels in a formal syntax, with suitable high-level features such as\nindividuals, relations, and connectives, enabling descriptive clarity,\nsuccinctness and circumventing the need for the modeler to engineer a custom\nsolver. Unfortunately, bringing these linguistic and pragmatic benefits to\nnumerical optimization has proven surprisingly challenging. In this paper, we\nturn to these challenges: we introduce a rich modeling language, for which an\ninterior-point method computes approximate solutions in a generic way. While\nlogical features easily complicates the underlying model, often yielding\nintricate dependencies, we exploit and cache local structure using algebraic\ndecision diagrams (ADDs). Indeed, standard matrix-vector algebra is efficiently\nrealizable in ADDs, but we argue and show that well-known optimization methods\nare not ideal for ADDs. Our engine, therefore, invokes a sophisticated\nmatrix-free approach. We demonstrate the flexibility of the resulting\nsymbolic-numeric optimizer on decision making and compressed sensing tasks with\nmillions of non-zero entries.\n", "versions": [{"version": "v1", "created": "Thu, 26 May 2016 08:26:34 GMT"}, {"version": "v2", "created": "Sat, 28 May 2016 17:11:30 GMT"}, {"version": "v3", "created": "Tue, 14 Jun 2016 18:29:14 GMT"}], "update_date": "2016-06-15", "authors_parsed": [["Mladenov", "Martin", ""], ["Belle", "Vaishak", ""], ["Kersting", "Kristian", ""]]}, {"id": "1605.08367", "submitter": "Rodrigo De Salvo Braz", "authors": "Rodrigo de Salvo Braz, Ciaran O'Reilly, Vibhav Gogate, Rina Dechter", "title": "Probabilistic Inference Modulo Theories", "comments": "Submitted to StarAI-16 workshop as closely revised version of\n  IJCAI-16 paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present SGDPLL(T), an algorithm that solves (among many other problems)\nprobabilistic inference modulo theories, that is, inference problems over\nprobabilistic models defined via a logic theory provided as a parameter\n(currently, propositional, equalities on discrete sorts, and inequalities, more\nspecifically difference arithmetic, on bounded integers). While many solutions\nto probabilistic inference over logic representations have been proposed,\nSGDPLL(T) is simultaneously (1) lifted, (2) exact and (3) modulo theories, that\nis, parameterized by a background logic theory. This offers a foundation for\nextending it to rich logic languages such as data structures and relational\ndata. By lifted, we mean algorithms with constant complexity in the domain size\n(the number of values that variables can take). We also detail a solver for\nsummations with difference arithmetic and show experimental results from a\nscenario in which SGDPLL(T) is much faster than a state-of-the-art\nprobabilistic solver.\n", "versions": [{"version": "v1", "created": "Thu, 26 May 2016 17:10:10 GMT"}, {"version": "v2", "created": "Fri, 27 May 2016 02:29:20 GMT"}], "update_date": "2016-05-30", "authors_parsed": [["Braz", "Rodrigo de Salvo", ""], ["O'Reilly", "Ciaran", ""], ["Gogate", "Vibhav", ""], ["Dechter", "Rina", ""]]}, {"id": "1605.08374", "submitter": "Zelda Mariet", "authors": "Zelda Mariet and Suvrit Sra", "title": "Kronecker Determinantal Point Processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Determinantal Point Processes (DPPs) are probabilistic models over all\nsubsets a ground set of $N$ items. They have recently gained prominence in\nseveral applications that rely on \"diverse\" subsets. However, their\napplicability to large problems is still limited due to the $\\mathcal O(N^3)$\ncomplexity of core tasks such as sampling and learning. We enable efficient\nsampling and learning for DPPs by introducing KronDPP, a DPP model whose kernel\nmatrix decomposes as a tensor product of multiple smaller kernel matrices. This\ndecomposition immediately enables fast exact sampling. But contrary to what one\nmay expect, leveraging the Kronecker product structure for speeding up DPP\nlearning turns out to be more difficult. We overcome this challenge, and derive\nbatch and stochastic optimization algorithms for efficiently learning the\nparameters of a KronDPP.\n", "versions": [{"version": "v1", "created": "Thu, 26 May 2016 17:33:31 GMT"}], "update_date": "2016-05-27", "authors_parsed": [["Mariet", "Zelda", ""], ["Sra", "Suvrit", ""]]}, {"id": "1605.08390", "submitter": "Juanjuan Zhao", "authors": "Juanjuan Zhao, Fan Zhang, Lai Tu, Chengzhong Xu, Dayong Shen, Chen\n  Tian, Xiang-Yang Li, Zhengxi Li", "title": "Estimation of Passenger Route Choice Pattern Using Smart Card Data for\n  Complex Metro Systems", "comments": "12 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Nowadays, metro systems play an important role in meeting the urban\ntransportation demand in large cities. The understanding of passenger route\nchoice is critical for public transit management. The wide deployment of\nAutomated Fare Collection(AFC) systems opens up a new opportunity. However,\nonly each trip's tap-in and tap-out timestamp and stations can be directly\nobtained from AFC system records; the train and route chosen by a passenger are\nunknown, which are necessary to solve our problem. While existing methods work\nwell in some specific situations, they don't work for complicated situations.\nIn this paper, we propose a solution that needs no additional equipment or\nhuman involvement than the AFC systems. We develop a probabilistic model that\ncan estimate from empirical analysis how the passenger flows are dispatched to\ndifferent routes and trains. We validate our approach using a large scale data\nset collected from the Shenzhen metro system. The measured results provide us\nwith useful inputs when building the passenger path choice model.\n", "versions": [{"version": "v1", "created": "Tue, 19 Apr 2016 07:52:30 GMT"}], "update_date": "2016-05-27", "authors_parsed": [["Zhao", "Juanjuan", ""], ["Zhang", "Fan", ""], ["Tu", "Lai", ""], ["Xu", "Chengzhong", ""], ["Shen", "Dayong", ""], ["Tian", "Chen", ""], ["Li", "Xiang-Yang", ""], ["Li", "Zhengxi", ""]]}, {"id": "1605.08412", "submitter": "Tobias Strau{\\ss}", "authors": "Gundram Leifert and Tobias Strau{\\ss} and Tobias Gr\\\"uning and Roger\n  Labahn", "title": "CITlab ARGUS for historical handwritten documents", "comments": "Description of CITlab's System for the HTRtS 2015 Task : Handwritten\n  Text Recognition on the tranScriptorium Dataset", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe CITlab's recognition system for the HTRtS competition attached to\nthe 13. International Conference on Document Analysis and Recognition, ICDAR\n2015. The task comprises the recognition of historical handwritten documents.\nThe core algorithms of our system are based on multi-dimensional recurrent\nneural networks (MDRNN) and connectionist temporal classification (CTC). The\nsoftware modules behind that as well as the basic utility technologies are\nessentially powered by PLANET's ARGUS framework for intelligent text\nrecognition and image processing.\n", "versions": [{"version": "v1", "created": "Thu, 26 May 2016 19:19:43 GMT"}], "update_date": "2016-05-27", "authors_parsed": [["Leifert", "Gundram", ""], ["Strau\u00df", "Tobias", ""], ["Gr\u00fcning", "Tobias", ""], ["Labahn", "Roger", ""]]}, {"id": "1605.08464", "submitter": "Vivek Sharma", "authors": "Vivek Sharma and Sule Yildirim-Yayilgan and Luc Van Gool", "title": "Low-Cost Scene Modeling using a Density Function Improves Segmentation\n  Performance", "comments": "accepted for publication at 25th IEEE International Symposium on\n  Robot and Human Interactive Communication (RO-MAN), 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.HC cs.RO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We propose a low cost and effective way to combine a free simulation software\nand free CAD models for modeling human-object interaction in order to improve\nhuman & object segmentation. It is intended for research scenarios related to\nsafe human-robot collaboration (SHRC) and interaction (SHRI) in the industrial\ndomain. The task of human and object modeling has been used for detecting\nactivity, and for inferring and predicting actions, different from those works,\nwe do human and object modeling in order to learn interactions in RGB-D data\nfor improving segmentation. For this purpose, we define a novel density\nfunction to model a three dimensional (3D) scene in a virtual environment\n(VREP). This density function takes into account various possible\nconfigurations of human-object and object-object relationships and interactions\ngoverned by their affordances. Using this function, we synthesize a large,\nrealistic and highly varied synthetic RGB-D dataset that we use for training.\nWe train a random forest classifier, and the pixelwise predictions obtained is\nintegrated as a unary term in a pairwise conditional random fields (CRF). Our\nevaluation shows that modeling these interactions improves segmentation\nperformance by ~7\\% in mean average precision and recall over state-of-the-art\nmethods that ignore these interactions in real-world data. Our approach is\ncomputationally efficient, robust and can run real-time on consumer hardware.\n", "versions": [{"version": "v1", "created": "Thu, 26 May 2016 22:34:37 GMT"}], "update_date": "2016-05-30", "authors_parsed": [["Sharma", "Vivek", ""], ["Yildirim-Yayilgan", "Sule", ""], ["Van Gool", "Luc", ""]]}, {"id": "1605.08478", "submitter": "Jonathan Ho", "authors": "Jonathan Ho, Jayesh K. Gupta, Stefano Ermon", "title": "Model-Free Imitation Learning with Policy Optimization", "comments": "In Proceedings of the 33rd International Conference on Machine\n  Learning, 2016", "journal-ref": "JMLR W&CP 48 (2016) 2760-2769", "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  In imitation learning, an agent learns how to behave in an environment with\nan unknown cost function by mimicking expert demonstrations. Existing imitation\nlearning algorithms typically involve solving a sequence of planning or\nreinforcement learning problems. Such algorithms are therefore not directly\napplicable to large, high-dimensional environments, and their performance can\nsignificantly degrade if the planning problems are not solved to optimality.\nUnder the apprenticeship learning formalism, we develop alternative model-free\nalgorithms for finding a parameterized stochastic policy that performs at least\nas well as an expert policy on an unknown cost function, based on sample\ntrajectories from the expert. Our approach, based on policy gradients, scales\nto large continuous environments with guaranteed convergence to local minima.\n", "versions": [{"version": "v1", "created": "Thu, 26 May 2016 23:43:32 GMT"}], "update_date": "2016-06-17", "authors_parsed": [["Ho", "Jonathan", ""], ["Gupta", "Jayesh K.", ""], ["Ermon", "Stefano", ""]]}, {"id": "1605.08695", "submitter": "Derek Murray", "authors": "Mart\\'in Abadi, Paul Barham, Jianmin Chen, Zhifeng Chen, Andy Davis,\n  Jeffrey Dean, Matthieu Devin, Sanjay Ghemawat, Geoffrey Irving, Michael\n  Isard, Manjunath Kudlur, Josh Levenberg, Rajat Monga, Sherry Moore, Derek G.\n  Murray, Benoit Steiner, Paul Tucker, Vijay Vasudevan, Pete Warden, Martin\n  Wicke, Yuan Yu and Xiaoqiang Zheng", "title": "TensorFlow: A system for large-scale machine learning", "comments": "18 pages, 9 figures; v2 has a spelling correction in the metadata", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  TensorFlow is a machine learning system that operates at large scale and in\nheterogeneous environments. TensorFlow uses dataflow graphs to represent\ncomputation, shared state, and the operations that mutate that state. It maps\nthe nodes of a dataflow graph across many machines in a cluster, and within a\nmachine across multiple computational devices, including multicore CPUs,\ngeneral-purpose GPUs, and custom designed ASICs known as Tensor Processing\nUnits (TPUs). This architecture gives flexibility to the application developer:\nwhereas in previous \"parameter server\" designs the management of shared state\nis built into the system, TensorFlow enables developers to experiment with\nnovel optimizations and training algorithms. TensorFlow supports a variety of\napplications, with particularly strong support for training and inference on\ndeep neural networks. Several Google services use TensorFlow in production, we\nhave released it as an open-source project, and it has become widely used for\nmachine learning research. In this paper, we describe the TensorFlow dataflow\nmodel in contrast to existing systems, and demonstrate the compelling\nperformance that TensorFlow achieves for several real-world applications.\n", "versions": [{"version": "v1", "created": "Fri, 27 May 2016 15:49:50 GMT"}, {"version": "v2", "created": "Tue, 31 May 2016 19:46:10 GMT"}], "update_date": "2016-06-01", "authors_parsed": [["Abadi", "Mart\u00edn", ""], ["Barham", "Paul", ""], ["Chen", "Jianmin", ""], ["Chen", "Zhifeng", ""], ["Davis", "Andy", ""], ["Dean", "Jeffrey", ""], ["Devin", "Matthieu", ""], ["Ghemawat", "Sanjay", ""], ["Irving", "Geoffrey", ""], ["Isard", "Michael", ""], ["Kudlur", "Manjunath", ""], ["Levenberg", "Josh", ""], ["Monga", "Rajat", ""], ["Moore", "Sherry", ""], ["Murray", "Derek G.", ""], ["Steiner", "Benoit", ""], ["Tucker", "Paul", ""], ["Vasudevan", "Vijay", ""], ["Warden", "Pete", ""], ["Wicke", "Martin", ""], ["Yu", "Yuan", ""], ["Zheng", "Xiaoqiang", ""]]}, {"id": "1605.08803", "submitter": "Laurent Dinh", "authors": "Laurent Dinh, Jascha Sohl-Dickstein, Samy Bengio", "title": "Density estimation using Real NVP", "comments": "10 pages of main content, 3 pages of bibliography, 18 pages of\n  appendix. Accepted at ICLR 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unsupervised learning of probabilistic models is a central yet challenging\nproblem in machine learning. Specifically, designing models with tractable\nlearning, sampling, inference and evaluation is crucial in solving this task.\nWe extend the space of such models using real-valued non-volume preserving\n(real NVP) transformations, a set of powerful invertible and learnable\ntransformations, resulting in an unsupervised learning algorithm with exact\nlog-likelihood computation, exact sampling, exact inference of latent\nvariables, and an interpretable latent space. We demonstrate its ability to\nmodel natural images on four datasets through sampling, log-likelihood\nevaluation and latent variable manipulations.\n", "versions": [{"version": "v1", "created": "Fri, 27 May 2016 21:24:32 GMT"}, {"version": "v2", "created": "Mon, 14 Nov 2016 21:37:10 GMT"}, {"version": "v3", "created": "Mon, 27 Feb 2017 23:21:10 GMT"}], "update_date": "2017-03-01", "authors_parsed": [["Dinh", "Laurent", ""], ["Sohl-Dickstein", "Jascha", ""], ["Bengio", "Samy", ""]]}, {"id": "1605.08878", "submitter": "Kennedy Ehimwenma", "authors": "Kennedy E. Ehimwenma, Martin Beer and Paul Crowther", "title": "Computational Estimate Visualisation and Evaluation of Agent Classified\n  Rules Learning System", "comments": "10 pages, 15 figures, International Journal of Emerging Technologies\n  in Learning iJET, 11(1), 2016, PhD research work", "journal-ref": "International Journal of Emerging Technologies in Learning (iJET),\n  11(01), 38-47 (2016)", "doi": null, "report-no": null, "categories": "cs.CY cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Student modelling and agent classified rules learning as applied in the\ndevelopment of the intelligent Preassessment System has been presented in\n[10],[11]. In this paper, we now demystify the theory behind the development of\nthe pre-assessment system followed by some computational experimentation and\ngraph visualisation of the agent classified rules learning algorithm in the\nestimation and prediction of classified rules. In addition, we present some\npreliminary results of the pre-assessment system evaluation. From the results,\nit is gathered that the system has performed according to its design\nspecification.\n", "versions": [{"version": "v1", "created": "Sat, 28 May 2016 11:29:09 GMT"}], "update_date": "2016-05-31", "authors_parsed": [["Ehimwenma", "Kennedy E.", ""], ["Beer", "Martin", ""], ["Crowther", "Paul", ""]]}, {"id": "1605.09042", "submitter": "Sungsoo Ahn", "authors": "Sungsoo Ahn, Michael Chertkov, Jinwoo Shin", "title": "MCMC assisted by Belief Propagation", "comments": "Fixed minor typos", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Markov Chain Monte Carlo (MCMC) and Belief Propagation (BP) are the most\npopular algorithms for computational inference in Graphical Models (GM). In\nprinciple, MCMC is an exact probabilistic method which, however, often suffers\nfrom exponentially slow mixing. In contrast, BP is a deterministic method,\nwhich is typically fast, empirically very successful, however in general\nlacking control of accuracy over loopy graphs. In this paper, we introduce MCMC\nalgorithms correcting the approximation error of BP, i.e., we provide a way to\ncompensate for BP errors via a consecutive BP-aware MCMC. Our framework is\nbased on the Loop Calculus (LC) approach which allows expressing the BP error\nas a sum of weighted generalized loops. Although the full series is\ncomputationally intractable, it is known that a truncated series, summing up\nall 2-regular loops, is computable in polynomial-time for planar pair-wise\nbinary GMs and it also provides a highly accurate approximation empirically.\nMotivated by this, we first propose a polynomial-time approximation MCMC scheme\nfor the truncated series of general (non-planar) pair-wise binary models. Our\nmain idea here is to use the Worm algorithm, known to provide fast mixing in\nother (related) problems, and then design an appropriate rejection scheme to\nsample 2-regular loops. Furthermore, we also design an efficient rejection-free\nMCMC scheme for approximating the full series. The main novelty underlying our\ndesign is in utilizing the concept of cycle basis, which provides an efficient\ndecomposition of the generalized loops. In essence, the proposed MCMC schemes\nrun on transformed GM built upon the non-trivial BP solution, and our\nexperiments show that this synthesis of BP and MCMC outperforms both direct\nMCMC and bare BP schemes.\n", "versions": [{"version": "v1", "created": "Sun, 29 May 2016 18:24:45 GMT"}, {"version": "v2", "created": "Fri, 2 Sep 2016 05:48:45 GMT"}, {"version": "v3", "created": "Mon, 24 Oct 2016 02:58:38 GMT"}, {"version": "v4", "created": "Wed, 9 Nov 2016 14:55:22 GMT"}, {"version": "v5", "created": "Mon, 21 Nov 2016 01:32:03 GMT"}, {"version": "v6", "created": "Mon, 11 May 2020 03:20:05 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["Ahn", "Sungsoo", ""], ["Chertkov", "Michael", ""], ["Shin", "Jinwoo", ""]]}, {"id": "1605.09128", "submitter": "Junhyuk Oh", "authors": "Junhyuk Oh, Valliappa Chockalingam, Satinder Singh, Honglak Lee", "title": "Control of Memory, Active Perception, and Action in Minecraft", "comments": "ICML 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we introduce a new set of reinforcement learning (RL) tasks in\nMinecraft (a flexible 3D world). We then use these tasks to systematically\ncompare and contrast existing deep reinforcement learning (DRL) architectures\nwith our new memory-based DRL architectures. These tasks are designed to\nemphasize, in a controllable manner, issues that pose challenges for RL methods\nincluding partial observability (due to first-person visual observations),\ndelayed rewards, high-dimensional visual observations, and the need to use\nactive perception in a correct manner so as to perform well in the tasks. While\nthese tasks are conceptually simple to describe, by virtue of having all of\nthese challenges simultaneously they are difficult for current DRL\narchitectures. Additionally, we evaluate the generalization performance of the\narchitectures on environments not used during training. The experimental\nresults show that our new architectures generalize to unseen environments\nbetter than existing DRL architectures.\n", "versions": [{"version": "v1", "created": "Mon, 30 May 2016 07:40:13 GMT"}], "update_date": "2016-05-31", "authors_parsed": [["Oh", "Junhyuk", ""], ["Chockalingam", "Valliappa", ""], ["Singh", "Satinder", ""], ["Lee", "Honglak", ""]]}, {"id": "1605.09293", "submitter": "Michael F\\\"arber", "authors": "Michael F\\\"arber and Chad Brown", "title": "Internal Guidance for Satallax", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We propose a new internal guidance method for automated theorem provers based\non the given-clause algorithm. Our method influences the choice of unprocessed\nclauses using positive and negative examples from previous proofs. To this end,\nwe present an efficient scheme for Naive Bayesian classification by\ngeneralising label occurrences to types with monoid structure. This makes it\npossible to extend existing fast classifiers, which consider only positive\nexamples, with negative ones. We implement the method in the higher-order logic\nprover Satallax, where we modify the delay with which propositions are\nprocessed. We evaluated our method on a simply-typed higher-order logic version\nof the Flyspeck project, where it solves 26% more problems than Satallax\nwithout internal guidance.\n", "versions": [{"version": "v1", "created": "Mon, 30 May 2016 16:01:51 GMT"}], "update_date": "2016-05-31", "authors_parsed": [["F\u00e4rber", "Michael", ""], ["Brown", "Chad", ""]]}, {"id": "1605.09304", "submitter": "Anh Nguyen", "authors": "Anh Nguyen, Alexey Dosovitskiy, Jason Yosinski, Thomas Brox, Jeff\n  Clune", "title": "Synthesizing the preferred inputs for neurons in neural networks via\n  deep generator networks", "comments": "29 pages, 35 figures, NIPS camera-ready", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (DNNs) have demonstrated state-of-the-art results on\nmany pattern recognition tasks, especially vision classification problems.\nUnderstanding the inner workings of such computational brains is both\nfascinating basic science that is interesting in its own right - similar to why\nwe study the human brain - and will enable researchers to further improve DNNs.\nOne path to understanding how a neural network functions internally is to study\nwhat each of its neurons has learned to detect. One such method is called\nactivation maximization (AM), which synthesizes an input (e.g. an image) that\nhighly activates a neuron. Here we dramatically improve the qualitative state\nof the art of activation maximization by harnessing a powerful, learned prior:\na deep generator network (DGN). The algorithm (1) generates qualitatively\nstate-of-the-art synthetic images that look almost real, (2) reveals the\nfeatures learned by each neuron in an interpretable way, (3) generalizes well\nto new datasets and somewhat well to different network architectures without\nrequiring the prior to be relearned, and (4) can be considered as a\nhigh-quality generative method (in this case, by generating novel, creative,\ninteresting, recognizable images).\n", "versions": [{"version": "v1", "created": "Mon, 30 May 2016 16:22:54 GMT"}, {"version": "v2", "created": "Fri, 3 Jun 2016 15:52:04 GMT"}, {"version": "v3", "created": "Mon, 6 Jun 2016 17:34:59 GMT"}, {"version": "v4", "created": "Thu, 27 Oct 2016 22:16:07 GMT"}, {"version": "v5", "created": "Wed, 23 Nov 2016 18:41:12 GMT"}], "update_date": "2016-11-24", "authors_parsed": [["Nguyen", "Anh", ""], ["Dosovitskiy", "Alexey", ""], ["Yosinski", "Jason", ""], ["Brox", "Thomas", ""], ["Clune", "Jeff", ""]]}, {"id": "1605.09370", "submitter": "Krzysztof Chalupka", "authors": "Krzysztof Chalupka, Tobias Bischoff, Pietro Perona, Frederick\n  Eberhardt", "title": "Unsupervised Discovery of El Nino Using Causal Feature Learning on\n  Microlevel Climate Data", "comments": "Accepted for plenary presentation at UAI 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG physics.ao-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that the climate phenomena of El Nino and La Nina arise naturally as\nstates of macro-variables when our recent causal feature learning framework\n(Chalupka 2015, Chalupka 2016) is applied to micro-level measures of zonal wind\n(ZW) and sea surface temperatures (SST) taken over the equatorial band of the\nPacific Ocean. The method identifies these unusual climate states on the basis\nof the relation between ZW and SST patterns without any input about past\noccurrences of El Nino or La Nina. The simpler alternatives of (i) clustering\nthe SST fields while disregarding their relationship with ZW patterns, or (ii)\nclustering the joint ZW-SST patterns, do not discover El Nino. We discuss the\ndegree to which our method supports a causal interpretation and use a\nlow-dimensional toy example to explain its success over other clustering\napproaches. Finally, we propose a new robust and scalable alternative to our\noriginal algorithm (Chalupka 2016), which circumvents the need for\nhigh-dimensional density learning.\n", "versions": [{"version": "v1", "created": "Mon, 30 May 2016 19:57:56 GMT"}], "update_date": "2016-05-31", "authors_parsed": [["Chalupka", "Krzysztof", ""], ["Bischoff", "Tobias", ""], ["Perona", "Pietro", ""], ["Eberhardt", "Frederick", ""]]}, {"id": "1605.09497", "submitter": "Nicholas Mattei", "authors": "Andres Abeliuk, Haris Aziz, Gerardo Berbeglia, Serge Gaspers, Petr\n  Kalina, Nicholas Mattei, Dominik Peters, Paul Stursberg, Pascal Van\n  Hentenryck, Toby Walsh", "title": "Interdependent Scheduling Games", "comments": "Accepted to IJCAI 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.AI cs.MA cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a model of interdependent scheduling games in which each player\ncontrols a set of services that they schedule independently. A player is free\nto schedule his own services at any time; however, each of these services only\nbegins to accrue reward for the player when all predecessor services, which may\nor may not be controlled by the same player, have been activated. This model,\nwhere players have interdependent services, is motivated by the problems faced\nin planning and coordinating large-scale infrastructures, e.g., restoring\nelectricity and gas to residents after a natural disaster or providing medical\ncare in a crisis when different agencies are responsible for the delivery of\nstaff, equipment, and medicine. We undertake a game-theoretic analysis of this\nsetting and in particular consider the issues of welfare maximization,\ncomputing best responses, Nash dynamics, and existence and computation of Nash\nequilibria.\n", "versions": [{"version": "v1", "created": "Tue, 31 May 2016 04:54:46 GMT"}], "update_date": "2016-06-01", "authors_parsed": [["Abeliuk", "Andres", ""], ["Aziz", "Haris", ""], ["Berbeglia", "Gerardo", ""], ["Gaspers", "Serge", ""], ["Kalina", "Petr", ""], ["Mattei", "Nicholas", ""], ["Peters", "Dominik", ""], ["Stursberg", "Paul", ""], ["Van Hentenryck", "Pascal", ""], ["Walsh", "Toby", ""]]}, {"id": "1605.09505", "submitter": "Sarit Kraus", "authors": "Moshe Bitan, Galit Nahari, Zvi Nisin, Ariel Roth, Sarit Kraus", "title": "Psychologically based Virtual-Suspect for Interrogative Interview\n  Training", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present a Virtual-Suspect system which can be used to train\ninexperienced law enforcement personnel in interrogation strategies. The system\nsupports different scenario configurations based on historical data. The\nresponses presented by the Virtual-Suspect are selected based on the\npsychological state of the suspect, which can be configured as well.\nFurthermore, each interrogator's statement affects the Virtual-Suspect's\ncurrent psychological state, which may lead the interrogation in different\ndirections. In addition, the model takes into account the context in which the\nstatements are made. Experiments with 24 subjects demonstrate that the\nVirtual-Suspect's behavior is similar to that of a human who plays the role of\nthe suspect.\n", "versions": [{"version": "v1", "created": "Tue, 31 May 2016 06:43:51 GMT"}], "update_date": "2016-06-01", "authors_parsed": [["Bitan", "Moshe", ""], ["Nahari", "Galit", ""], ["Nisin", "Zvi", ""], ["Roth", "Ariel", ""], ["Kraus", "Sarit", ""]]}, {"id": "1605.09564", "submitter": "Gregory Grefenstette", "authors": "Gregory Grefenstette (TAO), Lawrence Muchemi (TAO)", "title": "Determining the Characteristic Vocabulary for a Specialized Dictionary\n  using Word2vec and a Directed Crawler", "comments": null, "journal-ref": "GLOBALEX 2016: Lexicographic Resources for Human Language\n  Technology, May 2016, Portoroz, Slovenia. 2016", "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Specialized dictionaries are used to understand concepts in specific domains,\nespecially where those concepts are not part of the general vocabulary, or\nhaving meanings that differ from ordinary languages. The first step in creating\na specialized dictionary involves detecting the characteristic vocabulary of\nthe domain in question. Classical methods for detecting this vocabulary involve\ngathering a domain corpus, calculating statistics on the terms found there, and\nthen comparing these statistics to a background or general language corpus.\nTerms which are found significantly more often in the specialized corpus than\nin the background corpus are candidates for the characteristic vocabulary of\nthe domain. Here we present two tools, a directed crawler, and a distributional\nsemantics package, that can be used together, circumventing the need of a\nbackground corpus. Both tools are available on the web.\n", "versions": [{"version": "v1", "created": "Tue, 31 May 2016 10:31:16 GMT"}], "update_date": "2016-06-01", "authors_parsed": [["Grefenstette", "Gregory", "", "TAO"], ["Muchemi", "Lawrence", "", "TAO"]]}, {"id": "1605.09593", "submitter": "Yasutoshi Ida", "authors": "Yasutoshi Ida, Yasuhiro Fujiwara, Sotetsu Iwamura", "title": "Adaptive Learning Rate via Covariance Matrix Based Preconditioning for\n  Deep Neural Networks", "comments": "Accepted at IJCAI 2017", "journal-ref": null, "doi": "10.24963/ijcai.2017/267", "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adaptive learning rate algorithms such as RMSProp are widely used for\ntraining deep neural networks. RMSProp offers efficient training since it uses\nfirst order gradients to approximate Hessian-based preconditioning. However,\nsince the first order gradients include noise caused by stochastic\noptimization, the approximation may be inaccurate. In this paper, we propose a\nnovel adaptive learning rate algorithm called SDProp. Its key idea is effective\nhandling of the noise by preconditioning based on covariance matrix. For\nvarious neural networks, our approach is more efficient and effective than\nRMSProp and its variant.\n", "versions": [{"version": "v1", "created": "Tue, 31 May 2016 12:11:51 GMT"}, {"version": "v2", "created": "Thu, 28 Sep 2017 10:24:50 GMT"}], "update_date": "2017-09-29", "authors_parsed": [["Ida", "Yasutoshi", ""], ["Fujiwara", "Yasuhiro", ""], ["Iwamura", "Sotetsu", ""]]}, {"id": "1605.09674", "submitter": "Rein Houthooft", "authors": "Rein Houthooft, Xi Chen, Yan Duan, John Schulman, Filip De Turck,\n  Pieter Abbeel", "title": "VIME: Variational Information Maximizing Exploration", "comments": "Published in Advances in Neural Information Processing Systems 29\n  (NIPS), pages 1109-1117", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Scalable and effective exploration remains a key challenge in reinforcement\nlearning (RL). While there are methods with optimality guarantees in the\nsetting of discrete state and action spaces, these methods cannot be applied in\nhigh-dimensional deep RL scenarios. As such, most contemporary RL relies on\nsimple heuristics such as epsilon-greedy exploration or adding Gaussian noise\nto the controls. This paper introduces Variational Information Maximizing\nExploration (VIME), an exploration strategy based on maximization of\ninformation gain about the agent's belief of environment dynamics. We propose a\npractical implementation, using variational inference in Bayesian neural\nnetworks which efficiently handles continuous state and action spaces. VIME\nmodifies the MDP reward function, and can be applied with several different\nunderlying RL algorithms. We demonstrate that VIME achieves significantly\nbetter performance compared to heuristic exploration methods across a variety\nof continuous control tasks and algorithms, including tasks with very sparse\nrewards.\n", "versions": [{"version": "v1", "created": "Tue, 31 May 2016 15:34:36 GMT"}, {"version": "v2", "created": "Wed, 17 Aug 2016 18:25:42 GMT"}, {"version": "v3", "created": "Wed, 23 Nov 2016 12:58:44 GMT"}, {"version": "v4", "created": "Fri, 27 Jan 2017 09:26:28 GMT"}], "update_date": "2017-01-30", "authors_parsed": [["Houthooft", "Rein", ""], ["Chen", "Xi", ""], ["Duan", "Yan", ""], ["Schulman", "John", ""], ["De Turck", "Filip", ""], ["Abbeel", "Pieter", ""]]}, {"id": "1605.09735", "submitter": "Guido F.  Montufar", "authors": "Guido Montufar, Keyan Ghazi-Zahedi, Nihat Ay", "title": "Information Theoretically Aided Reinforcement Learning for Embodied\n  Agents", "comments": "10 pages, 4 figures, 8 pages appendix", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.RO math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning for embodied agents is a challenging problem. The\naccumulated reward to be optimized is often a very rugged function, and\ngradient methods are impaired by many local optimizers. We demonstrate, in an\nexperimental setting, that incorporating an intrinsic reward can smoothen the\noptimization landscape while preserving the global optimizers of interest. We\nshow that policy gradient optimization for locomotion in a complex morphology\nis significantly improved when supplementing the extrinsic reward by an\nintrinsic reward defined in terms of the mutual information of time consecutive\nsensor readings.\n", "versions": [{"version": "v1", "created": "Tue, 31 May 2016 17:30:54 GMT"}], "update_date": "2016-06-01", "authors_parsed": [["Montufar", "Guido", ""], ["Ghazi-Zahedi", "Keyan", ""], ["Ay", "Nihat", ""]]}, {"id": "1605.09757", "submitter": "Francois Scharffe", "authors": "Sanchit Arora, Chuck Cho, Paul Fitzpatrick, Francois Scharffe", "title": "Towards ontology driven learning of visual concept detectors", "comments": "unpublished", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.CV", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The maturity of deep learning techniques has led in recent years to a\nbreakthrough in object recognition in visual media. While for some specific\nbenchmarks, neural techniques seem to match if not outperform human judgement,\nchallenges are still open for detecting arbitrary concepts in arbitrary videos.\nIn this paper, we propose a system that combines neural techniques, a large\nscale visual concepts ontology, and an active learning loop, to provide on the\nfly model learning of arbitrary concepts. We give an overview of the system as\na whole, and focus on the central role of the ontology for guiding and\nbootstrapping the learning of new concepts, improving the recall of concept\ndetection, and, on the user end, providing semantic search on a library of\nannotated videos.\n", "versions": [{"version": "v1", "created": "Tue, 31 May 2016 18:35:44 GMT"}], "update_date": "2016-06-01", "authors_parsed": [["Arora", "Sanchit", ""], ["Cho", "Chuck", ""], ["Fitzpatrick", "Paul", ""], ["Scharffe", "Francois", ""]]}, {"id": "1605.09772", "submitter": "Daniel Ciolek", "authors": "Daniel Ciolek, Victor Braberman, Nicol\\'as D'Ippolito and Sebasti\\'an\n  Uchitel", "title": "Technical Report: Directed Controller Synthesis of Discrete Event\n  Systems", "comments": "8 pages, submitted to the 55th IEEE Conference on Decision and\n  Control", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SY cs.AI cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a Directed Controller Synthesis (DCS) technique for\ndiscrete event systems. The DCS method explores the solution space for reactive\ncontrollers guided by a domain-independent heuristic. The heuristic is derived\nfrom an efficient abstraction of the environment based on the componentized way\nin which complex environments are described. Then by building the composition\nof the components on-the-fly DCS obtains a solution by exploring a reduced\nportion of the state space. This work focuses on untimed discrete event systems\nwith safety and co-safety (i.e. reachability) goals. An evaluation for the\ntechnique is presented comparing it to other well-known approaches to\ncontroller synthesis (based on symbolic representation and compositional\nanalyses).\n", "versions": [{"version": "v1", "created": "Tue, 31 May 2016 19:12:41 GMT"}], "update_date": "2016-06-01", "authors_parsed": [["Ciolek", "Daniel", ""], ["Braberman", "Victor", ""], ["D'Ippolito", "Nicol\u00e1s", ""], ["Uchitel", "Sebasti\u00e1n", ""]]}, {"id": "1605.09782", "submitter": "Jeff Donahue", "authors": "Jeff Donahue, Philipp Kr\\\"ahenb\\\"uhl, Trevor Darrell", "title": "Adversarial Feature Learning", "comments": "Published as a conference paper at ICLR 2017. Changelog: (v7) Table 2\n  results improved 1-2% due to averaging predictions over 10 crops at test\n  time, as done in Noroozi & Favaro; Table 3 VOC classification results\n  slightly improved due to minor bugfix. (See v6 changelog for previous\n  versions.)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ability of the Generative Adversarial Networks (GANs) framework to learn\ngenerative models mapping from simple latent distributions to arbitrarily\ncomplex data distributions has been demonstrated empirically, with compelling\nresults showing that the latent space of such generators captures semantic\nvariation in the data distribution. Intuitively, models trained to predict\nthese semantic latent representations given data may serve as useful feature\nrepresentations for auxiliary problems where semantics are relevant. However,\nin their existing form, GANs have no means of learning the inverse mapping --\nprojecting data back into the latent space. We propose Bidirectional Generative\nAdversarial Networks (BiGANs) as a means of learning this inverse mapping, and\ndemonstrate that the resulting learned feature representation is useful for\nauxiliary supervised discrimination tasks, competitive with contemporary\napproaches to unsupervised and self-supervised feature learning.\n", "versions": [{"version": "v1", "created": "Tue, 31 May 2016 19:37:29 GMT"}, {"version": "v2", "created": "Fri, 15 Jul 2016 19:52:42 GMT"}, {"version": "v3", "created": "Mon, 18 Jul 2016 03:25:03 GMT"}, {"version": "v4", "created": "Fri, 4 Nov 2016 18:40:47 GMT"}, {"version": "v5", "created": "Fri, 6 Jan 2017 02:49:57 GMT"}, {"version": "v6", "created": "Mon, 9 Jan 2017 05:38:18 GMT"}, {"version": "v7", "created": "Mon, 3 Apr 2017 20:34:36 GMT"}], "update_date": "2017-04-05", "authors_parsed": [["Donahue", "Jeff", ""], ["Kr\u00e4henb\u00fchl", "Philipp", ""], ["Darrell", "Trevor", ""]]}]