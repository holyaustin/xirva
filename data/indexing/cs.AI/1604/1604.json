[{"id": "1604.00066", "submitter": "Wenbin Li", "authors": "Wenbin Li, Seyedmajid Azimi, Ale\\v{s} Leonardis, Mario Fritz", "title": "To Fall Or Not To Fall: A Visual Approach to Physical Stability\n  Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding physical phenomena is a key competence that enables humans and\nanimals to act and interact under uncertain perception in previously unseen\nenvironments containing novel object and their configurations. Developmental\npsychology has shown that such skills are acquired by infants from observations\nat a very early stage.\n  In this paper, we contrast a more traditional approach of taking a\nmodel-based route with explicit 3D representations and physical simulation by\nan end-to-end approach that directly predicts stability and related quantities\nfrom appearance. We ask the question if and to what extent and quality such a\nskill can directly be acquired in a data-driven way bypassing the need for an\nexplicit simulation.\n  We present a learning-based approach based on simulated data that predicts\nstability of towers comprised of wooden blocks under different conditions and\nquantities related to the potential fall of the towers. The evaluation is\ncarried out on synthetic data and compared to human judgments on the same\nstimuli.\n", "versions": [{"version": "v1", "created": "Thu, 31 Mar 2016 21:53:32 GMT"}], "update_date": "2016-04-04", "authors_parsed": [["Li", "Wenbin", ""], ["Azimi", "Seyedmajid", ""], ["Leonardis", "Ale\u0161", ""], ["Fritz", "Mario", ""]]}, {"id": "1604.00162", "submitter": "Christian Stra{\\ss}er", "authors": "Jesse Heyninck and Christian Stra{\\ss}er", "title": "Relations between assumption-based approaches in nonmonotonic logic and\n  formal argumentation", "comments": "Contribution to the 16th International Workshop on Non-Monotonic\n  Reasoning (NMR'16), Cape Town", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we make a contribution to the unification of formal models of\ndefeasible reasoning. We present several translations between formal\nargumentation frameworks and nonmonotonic logics for reasoning with plausible\nassumptions. More specifically, we translate adaptive logics into\nassumption-based argumentation and ASPIC+, ASPIC+ into assumption-based\nargumentation and a fragment of assumption-based argumentation into adaptive\nlogics. Adaptive logics are closely related to Makinson's default assumptions\nand to a significant class of systems within the tradition of preferential\nsemantics in the vein of KLM and Shoham. Thus, our results also provide close\nlinks between formal argumentation and the latter approaches.\n", "versions": [{"version": "v1", "created": "Fri, 1 Apr 2016 08:14:30 GMT"}], "update_date": "2016-04-04", "authors_parsed": [["Heyninck", "Jesse", ""], ["Stra\u00dfer", "Christian", ""]]}, {"id": "1604.00266", "submitter": "Elnaser Abdelwahab", "authors": "Elnaserledinellah Mahmood Abdelwahab, Karim Daghbouche, Nadra Ahmad\n  Shannan", "title": "The Algorithm of Islamic Jurisprudence (Fiqh) with Validation of an\n  Entscheidungsproblem", "comments": "36 pages, 6 Figures. J.Acad.(N.Y.)4,2:52-87, published May 16 2014", "journal-ref": "J.Acad.(N.Y.)4,2:52-87 May 16 2014", "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The historic background of algorithmic processing with regard to etymology\nand methodology is translated into terms of mathematical logic and Computer\nScience. A formal logic structure is introduced by exemplaryquestions posed to\nFiqh-chapters to define alogic query language. As a foundation, ageneric\nalgorithm for deciding Fiqh-rulings is designed to enable and further leverage\nrule of law (vs. rule by law) with full transparency and complete algorithmic\ncoverage of Islamic law eventually providing legal security, legal equality,\nand full legal accountability.This is implemented by disentangling and\nreinstating classic Fiqh-methodology (usul al-Fiqh) with the expressive power\nof subsets of First Order Logic (FOL)sustainably substituting ad hoc reasoning\nwith falsifiable rational argumentation. The results are discussed in formal\nterms of completeness, decidability and complexity of formal Fiqh-systems.\nAnEntscheidungsproblem for formal Fiqh-Systems is formulated and validated.\n", "versions": [{"version": "v1", "created": "Thu, 10 Mar 2016 20:56:15 GMT"}], "update_date": "2016-07-05", "authors_parsed": [["Abdelwahab", "Elnaserledinellah Mahmood", ""], ["Daghbouche", "Karim", ""], ["Shannan", "Nadra Ahmad", ""]]}, {"id": "1604.00289", "submitter": "Brenden Lake", "authors": "Brenden M. Lake, Tomer D. Ullman, Joshua B. Tenenbaum, Samuel J.\n  Gershman", "title": "Building Machines That Learn and Think Like People", "comments": "In press at Behavioral and Brain Sciences. Open call for commentary\n  proposals (until Nov. 22, 2016).\n  https://www.cambridge.org/core/journals/behavioral-and-brain-sciences/information/calls-for-commentary/open-calls-for-commentary", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CV cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent progress in artificial intelligence (AI) has renewed interest in\nbuilding systems that learn and think like people. Many advances have come from\nusing deep neural networks trained end-to-end in tasks such as object\nrecognition, video games, and board games, achieving performance that equals or\neven beats humans in some respects. Despite their biological inspiration and\nperformance achievements, these systems differ from human intelligence in\ncrucial ways. We review progress in cognitive science suggesting that truly\nhuman-like learning and thinking machines will have to reach beyond current\nengineering trends in both what they learn, and how they learn it.\nSpecifically, we argue that these machines should (a) build causal models of\nthe world that support explanation and understanding, rather than merely\nsolving pattern recognition problems; (b) ground learning in intuitive theories\nof physics and psychology, to support and enrich the knowledge that is learned;\nand (c) harness compositionality and learning-to-learn to rapidly acquire and\ngeneralize knowledge to new tasks and situations. We suggest concrete\nchallenges and promising routes towards these goals that can combine the\nstrengths of recent neural network advances with more structured cognitive\nmodels.\n", "versions": [{"version": "v1", "created": "Fri, 1 Apr 2016 15:37:57 GMT"}, {"version": "v2", "created": "Sat, 7 May 2016 18:03:53 GMT"}, {"version": "v3", "created": "Wed, 2 Nov 2016 17:26:50 GMT"}], "update_date": "2016-11-03", "authors_parsed": [["Lake", "Brenden M.", ""], ["Ullman", "Tomer D.", ""], ["Tenenbaum", "Joshua B.", ""], ["Gershman", "Samuel J.", ""]]}, {"id": "1604.00300", "submitter": "Benjamin Negrevergne", "authors": "R\\'emi Coletta and Benjamin Negrevergne", "title": "A SAT model to mine flexible sequences in transactional datasets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditional pattern mining algorithms generally suffer from a lack of\nflexibility. In this paper, we propose a SAT formulation of the problem to\nsuccessfully mine frequent flexible sequences occurring in transactional\ndatasets. Our SAT-based approach can easily be extended with extra constraints\nto address a broad range of pattern mining applications. To demonstrate this\nclaim, we formulate and add several constraints, such as gap and span\nconstraints, to our model in order to extract more specific patterns. We also\nuse interactive solving to perform important derived tasks, such as closed\npattern mining or maximal pattern mining. Finally, we prove the practical\nfeasibility of our SAT model by running experiments on two real datasets.\n", "versions": [{"version": "v1", "created": "Fri, 1 Apr 2016 15:49:51 GMT"}], "update_date": "2016-04-04", "authors_parsed": [["Coletta", "R\u00e9mi", ""], ["Negrevergne", "Benjamin", ""]]}, {"id": "1604.00301", "submitter": "Valentina Gliozzi", "authors": "Valentina Gliozzi", "title": "A strengthening of rational closure in DLs: reasoning about multiple\n  aspects", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a logical analysis of the concept of typicality, central in human\ncognition (Rosch,1978). We start from a previously proposed extension of the\nbasic Description Logic ALC (a computationally tractable fragment of First\nOrder Logic, used to represent concept inclusions and ontologies) with a\ntypicality operator T that allows to consistently represent the attribution to\nclasses of individuals of properties with exceptions (as in the classic example\n(i) typical birds fly, (ii) penguins are birds but (iii) typical penguins don't\nfly). We then strengthen this extension in order to separately reason about the\ntypicality with respect to different aspects (e.g., flying, having nice\nfeather: in the previous example, penguins may not inherit the property of\nflying, for which they are exceptional, but can nonetheless inherit other\nproperties, such as having nice feather).\n", "versions": [{"version": "v1", "created": "Fri, 1 Apr 2016 15:50:24 GMT"}], "update_date": "2016-04-04", "authors_parsed": [["Gliozzi", "Valentina", ""]]}, {"id": "1604.00359", "submitter": "Dimo Brockhoff", "authors": "Dimo Brockhoff (RANDOPT), Tea Tusar, Anne Auger (RANDOPT), Nikolaus\n  Hansen (RANDOPT)", "title": "Using Well-Understood Single-Objective Functions in Multiobjective\n  Black-Box Optimization Test Suites", "comments": "ArXiv e-prints, arXiv:1604.00359", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.NA cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Several test function suites are being used for numerical benchmarking of\nmultiobjective optimization algorithms. While they have some desirable\nproperties, like well-understood Pareto sets and Pareto fronts of various\nshapes, most of the currently used functions possess characteristics that are\narguably under-represented in real-world problems. They mainly stem from the\neasier construction of such functions and result in improbable properties such\nas separability, optima located exactly at the boundary constraints, and the\nexistence of variables that solely control the distance between a solution and\nthe Pareto front. Here, we propose an alternative way to constructing\nmultiobjective problems-by combining existing single-objective problems from\nthe literature. We describe in particular the bbob-biobj test suite with 55\nbi-objective functions in continuous domain, and its extended version with 92\nbi-objective functions (bbob-biobj-ext). Both test suites have been implemented\nin the COCO platform for black-box optimization benchmarking. Finally, we\nrecommend a general procedure for creating test suites for an arbitrary number\nof objectives. Besides providing the formal function definitions and presenting\ntheir (known) properties, this paper also aims at giving the rationale behind\nour approach in terms of groups of functions with similar properties, objective\nspace normalization, and problem instances. The latter allows us to easily\ncompare the performance of deterministic and stochastic solvers, which is an\noften overlooked issue in benchmarking.\n", "versions": [{"version": "v1", "created": "Fri, 1 Apr 2016 18:55:05 GMT"}, {"version": "v2", "created": "Wed, 25 May 2016 06:49:31 GMT"}, {"version": "v3", "created": "Fri, 4 Jan 2019 09:47:43 GMT"}], "update_date": "2019-01-07", "authors_parsed": [["Brockhoff", "Dimo", "", "RANDOPT"], ["Tusar", "Tea", "", "RANDOPT"], ["Auger", "Anne", "", "RANDOPT"], ["Hansen", "Nikolaus", "", "RANDOPT"]]}, {"id": "1604.00377", "submitter": "Jin-Kao Hao", "authors": "Yangming Zhou, Jin-Kao Hao, B\\'eatrice Duval", "title": "Reinforcement learning based local search for grouping problems: A case\n  study on graph coloring", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Grouping problems aim to partition a set of items into multiple mutually\ndisjoint subsets according to some specific criterion and constraints. Grouping\nproblems cover a large class of important combinatorial optimization problems\nthat are generally computationally difficult. In this paper, we propose a\ngeneral solution approach for grouping problems, i.e., reinforcement learning\nbased local search (RLS), which combines reinforcement learning techniques with\ndescent-based local search. The viability of the proposed approach is verified\non a well-known representative grouping problem (graph coloring) where a very\nsimple descent-based coloring algorithm is applied. Experimental studies on\npopular DIMACS and COLOR02 benchmark graphs indicate that RLS achieves\ncompetitive performances compared to a number of well-known coloring\nalgorithms.\n", "versions": [{"version": "v1", "created": "Fri, 1 Apr 2016 19:38:35 GMT"}], "update_date": "2016-04-04", "authors_parsed": [["Zhou", "Yangming", ""], ["Hao", "Jin-Kao", ""], ["Duval", "B\u00e9atrice", ""]]}, {"id": "1604.00449", "submitter": "Christopher B. Choy", "authors": "Christopher B. Choy, Danfei Xu, JunYoung Gwak, Kevin Chen, Silvio\n  Savarese", "title": "3D-R2N2: A Unified Approach for Single and Multi-view 3D Object\n  Reconstruction", "comments": "Appendix can be found at\n  http://cvgl.stanford.edu/papers/choy_16_appendix.pdf", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inspired by the recent success of methods that employ shape priors to achieve\nrobust 3D reconstructions, we propose a novel recurrent neural network\narchitecture that we call the 3D Recurrent Reconstruction Neural Network\n(3D-R2N2). The network learns a mapping from images of objects to their\nunderlying 3D shapes from a large collection of synthetic data. Our network\ntakes in one or more images of an object instance from arbitrary viewpoints and\noutputs a reconstruction of the object in the form of a 3D occupancy grid.\nUnlike most of the previous works, our network does not require any image\nannotations or object class labels for training or testing. Our extensive\nexperimental analysis shows that our reconstruction framework i) outperforms\nthe state-of-the-art methods for single view reconstruction, and ii) enables\nthe 3D reconstruction of objects in situations when traditional SFM/SLAM\nmethods fail (because of lack of texture and/or wide baseline).\n", "versions": [{"version": "v1", "created": "Sat, 2 Apr 2016 01:28:27 GMT"}], "update_date": "2016-04-05", "authors_parsed": [["Choy", "Christopher B.", ""], ["Xu", "Danfei", ""], ["Gwak", "JunYoung", ""], ["Chen", "Kevin", ""], ["Savarese", "Silvio", ""]]}, {"id": "1604.00461", "submitter": "Mo Yu", "authors": "Mo Yu, Mark Dredze, Raman Arora, Matthew Gormley", "title": "Embedding Lexical Features via Low-Rank Tensors", "comments": "Accepted by NAACL 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern NLP models rely heavily on engineered features, which often combine\nword and contextual information into complex lexical features. Such combination\nresults in large numbers of features, which can lead to over-fitting. We\npresent a new model that represents complex lexical features---comprised of\nparts for words, contextual information and labels---in a tensor that captures\nconjunction information among these parts. We apply low-rank tensor\napproximations to the corresponding parameter tensors to reduce the parameter\nspace and improve prediction speed. Furthermore, we investigate two methods for\nhandling features that include $n$-grams of mixed lengths. Our model achieves\nstate-of-the-art results on tasks in relation extraction, PP-attachment, and\npreposition disambiguation.\n", "versions": [{"version": "v1", "created": "Sat, 2 Apr 2016 04:59:21 GMT"}], "update_date": "2016-04-05", "authors_parsed": [["Yu", "Mo", ""], ["Dredze", "Mark", ""], ["Arora", "Raman", ""], ["Gormley", "Matthew", ""]]}, {"id": "1604.00536", "submitter": "Jingchao Chen", "authors": "Jingchao Chen", "title": "Improving SAT Solvers via Blocked Clause Decomposition", "comments": "9 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The decision variable selection policy used by the most competitive CDCL\n(Conflict-Driven Clause Learning) SAT solvers is either VSIDS (Variable State\nIndependent Decaying Sum) or its variants such as exponential version EVSIDS.\nThe common characteristic of VSIDS and its variants is to make use of\nstatistical information in the solving process, but ignore structure\ninformation of the problem. For this reason, this paper modifies the decision\nvariable selection policy, and presents a SAT solving technique based on BCD\n(Blocked Clause Decomposition). Its basic idea is that a part of decision\nvariables are selected by VSIDS heuristic, while another part of decision\nvariables are selected by blocked sets that are obtained by BCD. Compared with\nthe existing BCD-based technique, our technique is simple, and need not to\nreencode CNF formulas. SAT solvers for certified UNSAT track can apply also our\nBCD-based technique. Our experiments on application benchmarks demonstrate that\nthe new variables selection policy based on BCD can increase the performance of\nSAT solvers such as abcdSAT. The solver with BCD solved an instance from the\nSAT Race 2015 that was not solved by any solver so far. This shows that in some\ncases, the heuristic based on structure information is more efficient than that\nbased on statistical information.\n", "versions": [{"version": "v1", "created": "Sat, 2 Apr 2016 17:50:32 GMT"}], "update_date": "2016-04-05", "authors_parsed": [["Chen", "Jingchao", ""]]}, {"id": "1604.00545", "submitter": "Janos Kramar", "authors": "James Babcock, Janos Kramar, Roman Yampolskiy", "title": "The AGI Containment Problem", "comments": null, "journal-ref": "Lecture Notes in Artificial Intelligence 9782 (AGI 2016,\n  Proceedings) 53-63", "doi": "10.1007/978-3-319-41649-6", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is considerable uncertainty about what properties, capabilities and\nmotivations future AGIs will have. In some plausible scenarios, AGIs may pose\nsecurity risks arising from accidents and defects. In order to mitigate these\nrisks, prudent early AGI research teams will perform significant testing on\ntheir creations before use. Unfortunately, if an AGI has human-level or greater\nintelligence, testing itself may not be safe; some natural AGI goal systems\ncreate emergent incentives for AGIs to tamper with their test environments,\nmake copies of themselves on the internet, or convince developers and operators\nto do dangerous things. In this paper, we survey the AGI containment problem -\nthe question of how to build a container in which tests can be conducted safely\nand reliably, even on AGIs with unknown motivations and capabilities that could\nbe dangerous. We identify requirements for AGI containers, available\nmechanisms, and weaknesses that need to be addressed.\n", "versions": [{"version": "v1", "created": "Sat, 2 Apr 2016 19:26:05 GMT"}, {"version": "v2", "created": "Thu, 12 May 2016 15:37:38 GMT"}, {"version": "v3", "created": "Wed, 13 Jul 2016 14:54:16 GMT"}], "update_date": "2016-07-14", "authors_parsed": [["Babcock", "James", ""], ["Kramar", "Janos", ""], ["Yampolskiy", "Roman", ""]]}, {"id": "1604.00644", "submitter": "Fabricio de Franca Olivetti", "authors": "Karine da Silva Miras de Ara\\'ujo, Fabr\\'icio Olivetti de Fran\\c{c}a", "title": "An electronic-game framework for evaluating coevolutionary algorithms", "comments": "This paper is a translation of \\cite{karine2015}, published in\n  Portuguese at Brazilian Congress on Computational Intelligence, 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the common artificial intelligence applications in electronic games\nconsists of making an artificial agent learn how to execute some determined\ntask successfully in a game environment. One way to perform this task is\nthrough machine learning algorithms capable of learning the sequence of actions\nrequired to win in a given game environment. There are several supervised\nlearning techniques able to learn the correct answer for a problem through\nexamples. However, when learning how to play electronic games, the correct\nanswer might only be known by the end of the game, after all the actions were\nalready taken. Thus, not being possible to measure the accuracy of each\nindividual action to be taken at each time step. A way for dealing with this\nproblem is through Neuroevolution, a method which trains Artificial Neural\nNetworks using evolutionary algorithms. In this article, we introduce a\nframework for testing optimization algorithms with artificial agent controllers\nin electronic games, called EvoMan, which is inspired in the action-platformer\ngame Mega Man II. The environment can be configured to run in different\nexperiment modes, as single evolution, coevolution and others. To demonstrate\nsome challenges regarding the proposed platform, as initial experiments we\napplied Neuroevolution using Genetic Algorithms and the NEAT algorithm, in the\ncontext of competitively coevolving two distinct agents in this game.\n", "versions": [{"version": "v1", "created": "Sun, 3 Apr 2016 14:57:24 GMT"}, {"version": "v2", "created": "Mon, 11 Apr 2016 18:35:29 GMT"}], "update_date": "2016-04-12", "authors_parsed": [["de Ara\u00fajo", "Karine da Silva Miras", ""], ["de Fran\u00e7a", "Fabr\u00edcio Olivetti", ""]]}, {"id": "1604.00647", "submitter": "Ernesto Diaz-Aviles", "authors": "Lucas Drumond, Ernesto Diaz-Aviles, and Lars Schmidt-Thieme", "title": "Multi-Relational Learning at Scale with ADMM", "comments": "Keywords: Multi-Relational Learning, Distributed Learning,\n  Factorization Models, ADMM", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning from multiple-relational data which contains noise, ambiguities, or\nduplicate entities is essential to a wide range of applications such as\nstatistical inference based on Web Linked Data, recommender systems,\ncomputational biology, and natural language processing. These tasks usually\nrequire working with very large and complex datasets - e.g., the Web graph -\nhowever, current approaches to multi-relational learning are not practical for\nsuch scenarios due to their high computational complexity and poor scalability\non large data.\n  In this paper, we propose a novel and scalable approach for multi-relational\nfactorization based on consensus optimization. Our model, called ConsMRF, is\nbased on the Alternating Direction Method of Multipliers (ADMM) framework,\nwhich enables us to optimize each target relation using a smaller set of\nparameters than the state-of-the-art competitors in this task.\n  Due to ADMM's nature, ConsMRF can be easily parallelized which makes it\nsuitable for large multi-relational data. Experiments on large Web datasets -\nderived from DBpedia, Wikipedia and YAGO - show the efficiency and performance\nimprovement of ConsMRF over strong competitors. In addition, ConsMRF\nnear-linear scalability indicates great potential to tackle Web-scale problem\nsizes.\n", "versions": [{"version": "v1", "created": "Sun, 3 Apr 2016 15:42:36 GMT"}], "update_date": "2016-04-05", "authors_parsed": [["Drumond", "Lucas", ""], ["Diaz-Aviles", "Ernesto", ""], ["Schmidt-Thieme", "Lars", ""]]}, {"id": "1604.00664", "submitter": "Jiawei Zhang", "authors": "Jiawei Zhang and Xiao Pan and Moyin Li and Philip S. Yu", "title": "Bicycle-Sharing System Analysis and Trip Prediction", "comments": "11 pages, 11 figures, accepted by 2016 IEEE MDM Conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bicycle-sharing systems, which can provide shared bike usage services for the\npublic, have been launched in many big cities. In bicycle-sharing systems,\npeople can borrow and return bikes at any stations in the service region very\nconveniently. Therefore, bicycle-sharing systems are normally used as a\nshort-distance trip supplement for private vehicles as well as regular public\ntransportation. Meanwhile, for stations located at different places in the\nservice region, the bike usages can be quite skewed and imbalanced. Some\nstations have too many incoming bikes and get jammed without enough docks for\nupcoming bikes, while some other stations get empty quickly and lack enough\nbikes for people to check out. Therefore, inferring the potential destinations\nand arriving time of each individual trip beforehand can effectively help the\nservice providers schedule manual bike re-dispatch in advance. In this paper,\nwe will study the individual trip prediction problem for bicycle-sharing\nsystems. To address the problem, we study a real-world bicycle-sharing system\nand analyze individuals' bike usage behaviors first. Based on the analysis\nresults, a new trip destination prediction and trip duration inference model\nwill be introduced. Experiments conducted on a real-world bicycle-sharing\nsystem demonstrate the effectiveness of the proposed model.\n", "versions": [{"version": "v1", "created": "Sun, 3 Apr 2016 18:06:36 GMT"}], "update_date": "2016-04-05", "authors_parsed": [["Zhang", "Jiawei", ""], ["Pan", "Xiao", ""], ["Li", "Moyin", ""], ["Yu", "Philip S.", ""]]}, {"id": "1604.00681", "submitter": "Edmond Awad", "authors": "Edmond Awad, Jean-Fran\\c{c}ois Bonnefon, Martin Caminada, Thomas\n  Malone and Iyad Rahwan", "title": "Experimental Assessment of Aggregation Principles in\n  Argumentation-enabled Collective Intelligence", "comments": null, "journal-ref": "ACM Transactions on Internet Technology (TOIT), 17(3), 29 (2017)", "doi": "10.1145/3053371", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  On the Web, there is always a need to aggregate opinions from the crowd (as\nin posts, social networks, forums, etc.). Different mechanisms have been\nimplemented to capture these opinions such as \"Like\" in Facebook, \"Favorite\" in\nTwitter, thumbs-up/down, flagging, and so on. However, in more contested\ndomains (e.g. Wikipedia, political discussion, and climate change discussion)\nthese mechanisms are not sufficient since they only deal with each issue\nindependently without considering the relationships between different claims.\nWe can view a set of conflicting arguments as a graph in which the nodes\nrepresent arguments and the arcs between these nodes represent the defeat\nrelation. A group of people can then collectively evaluate such graphs. To do\nthis, the group must use a rule to aggregate their individual opinions about\nthe entire argument graph. Here, we present the first experimental evaluation\nof different principles commonly employed by aggregation rules presented in the\nliterature. We use randomized controlled experiments to investigate which\nprinciples people consider better at aggregating opinions under different\nconditions. Our analysis reveals a number of factors, not captured by\ntraditional formal models, that play an important role in determining the\nefficacy of aggregation. These results help bring formal models of\nargumentation closer to real-world application.\n", "versions": [{"version": "v1", "created": "Sun, 3 Apr 2016 19:58:18 GMT"}, {"version": "v2", "created": "Sun, 12 Feb 2017 18:38:35 GMT"}], "update_date": "2017-06-20", "authors_parsed": [["Awad", "Edmond", ""], ["Bonnefon", "Jean-Fran\u00e7ois", ""], ["Caminada", "Martin", ""], ["Malone", "Thomas", ""], ["Rahwan", "Iyad", ""]]}, {"id": "1604.00693", "submitter": "Edmond Awad", "authors": "Edmond Awad, Martin Caminada, Gabriella Pigozzi, Miko{\\l}aj\n  Podlaszewski and Iyad Rahwan", "title": "Pareto Optimality and Strategy Proofness in Group Argument Evaluation\n  (Extended Version)", "comments": null, "journal-ref": null, "doi": "10.1093/logcom/exx017", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An inconsistent knowledge base can be abstracted as a set of arguments and a\ndefeat relation among them. There can be more than one consistent way to\nevaluate such an argumentation graph. Collective argument evaluation is the\nproblem of aggregating the opinions of multiple agents on how a given set of\narguments should be evaluated. It is crucial not only to ensure that the\noutcome is logically consistent, but also satisfies measures of social\noptimality and immunity to strategic manipulation. This is because agents have\ntheir individual preferences about what the outcome ought to be. In the current\npaper, we analyze three previously introduced argument-based aggregation\noperators with respect to Pareto optimality and strategy proofness under\ndifferent general classes of agent preferences. We highlight fundamental\ntrade-offs between strategic manipulability and social optimality on one hand,\nand classical logical criteria on the other. Our results motivate further\ninvestigation into the relationship between social choice and argumentation\ntheory. The results are also relevant for choosing an appropriate aggregation\noperator given the criteria that are considered more important, as well as the\nnature of agents' preferences.\n", "versions": [{"version": "v1", "created": "Sun, 3 Apr 2016 21:48:37 GMT"}, {"version": "v2", "created": "Fri, 7 Apr 2017 20:02:55 GMT"}], "update_date": "2017-06-20", "authors_parsed": [["Awad", "Edmond", ""], ["Caminada", "Martin", ""], ["Pigozzi", "Gabriella", ""], ["Podlaszewski", "Miko\u0142aj", ""], ["Rahwan", "Iyad", ""]]}, {"id": "1604.00697", "submitter": "Wei Wen", "authors": "Wei Wen, Chunpeng Wu, Yandan Wang, Kent Nixon, Qing Wu, Mark Barnell,\n  Hai Li, Yiran Chen", "title": "A New Learning Method for Inference Accuracy, Core Occupation, and\n  Performance Co-optimization on TrueNorth Chip", "comments": "6 pages; 9 figures; DAC 2016", "journal-ref": null, "doi": "10.1145/2897937.2897968", "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  IBM TrueNorth chip uses digital spikes to perform neuromorphic computing and\nachieves ultrahigh execution parallelism and power efficiency. However, in\nTrueNorth chip, low quantization resolution of the synaptic weights and spikes\nsignificantly limits the inference (e.g., classification) accuracy of the\ndeployed neural network model. Existing workaround, i.e., averaging the results\nover multiple copies instantiated in spatial and temporal domains, rapidly\nexhausts the hardware resources and slows down the computation. In this work,\nwe propose a novel learning method on TrueNorth platform that constrains the\nrandom variance of each computation copy and reduces the number of needed\ncopies. Compared to the existing learning method, our method can achieve up to\n68.8% reduction of the required neuro-synaptic cores or 6.5X speedup, with even\nslightly improved inference accuracy.\n", "versions": [{"version": "v1", "created": "Sun, 3 Apr 2016 22:44:00 GMT"}, {"version": "v2", "created": "Tue, 12 Jul 2016 03:49:21 GMT"}, {"version": "v3", "created": "Sat, 16 Jul 2016 05:09:04 GMT"}], "update_date": "2016-07-19", "authors_parsed": [["Wen", "Wei", ""], ["Wu", "Chunpeng", ""], ["Wang", "Yandan", ""], ["Nixon", "Kent", ""], ["Wu", "Qing", ""], ["Barnell", "Mark", ""], ["Li", "Hai", ""], ["Chen", "Yiran", ""]]}, {"id": "1604.00727", "submitter": "David Golub", "authors": "David Golub, Xiaodong He", "title": "Character-Level Question Answering with Attention", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that a character-level encoder-decoder framework can be successfully\napplied to question answering with a structured knowledge base. We use our\nmodel for single-relation question answering and demonstrate the effectiveness\nof our approach on the SimpleQuestions dataset (Bordes et al., 2015), where we\nimprove state-of-the-art accuracy from 63.9% to 70.9%, without use of\nensembles. Importantly, our character-level model has 16x fewer parameters than\nan equivalent word-level model, can be learned with significantly less data\ncompared to previous work, which relies on data augmentation, and is robust to\nnew entities in testing.\n", "versions": [{"version": "v1", "created": "Mon, 4 Apr 2016 02:43:23 GMT"}, {"version": "v2", "created": "Tue, 5 Apr 2016 23:09:31 GMT"}, {"version": "v3", "created": "Fri, 8 Apr 2016 21:12:47 GMT"}, {"version": "v4", "created": "Sun, 5 Jun 2016 02:02:10 GMT"}], "update_date": "2016-06-07", "authors_parsed": [["Golub", "David", ""], ["He", "Xiaodong", ""]]}, {"id": "1604.00799", "submitter": "Alessandro Artale", "authors": "Alessandro Artale and Enrico Franconi", "title": "Extending DLR with Labelled Tuples, Projections, Functional Dependencies\n  and Objectification (full version)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce an extension of the n-ary description logic DLR to deal with\nattribute-labelled tuples (generalising the positional notation), with\narbitrary projections of relations (inclusion dependencies), generic functional\ndependencies and with global and local objectification (reifying relations or\ntheir projections). We show how a simple syntactic condition on the appearance\nof projections and functional dependencies in a knowledge base makes the\nlanguage decidable without increasing the computational complexity of the basic\nDLR language.\n", "versions": [{"version": "v1", "created": "Mon, 4 Apr 2016 10:11:52 GMT"}], "update_date": "2016-04-05", "authors_parsed": [["Artale", "Alessandro", ""], ["Franconi", "Enrico", ""]]}, {"id": "1604.00869", "submitter": "Sundong Kim", "authors": "Sundong Kim", "title": "Automatic Knowledge Base Evolution by Learning Instances", "comments": "11 pages, submitted to International Semantic Web Conference 2014\n  (Rejected), Revising(2016-04-04~)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge base is the way to store structured and unstructured data\nthroughout the web. Since the size of the web is increasing rapidly, there are\nhuge needs to structure the knowledge in a fully automated way. However\nfully-automated knowledge-base evolution on the Semantic Web is a major\nchallenges, although there are many ontology evolution techniques available.\nTherefore learning ontology automatically can contribute to the semantic web\nsociety significantly. In this paper, we propose full-automated ontology\nlearning algorithm to generate refined knowledge base from incomplete knowledge\nbase and rdf-triples. Our algorithm is data-driven approach which is based on\nthe property of each instance. Ontology class is being elaborated by\ngeneralizing frequent property of its instances. By using that developed class\ninformation, each instance can find its most relatively matching class. By\nrepeating these two steps, we achieve fully-automated ontology evolution from\nincomplete basic knowledge base.\n", "versions": [{"version": "v1", "created": "Mon, 4 Apr 2016 14:23:25 GMT"}], "update_date": "2016-04-05", "authors_parsed": [["Kim", "Sundong", ""]]}, {"id": "1604.00921", "submitter": "Hussein Abbass A", "authors": "Hussein A. Abbass, George Leu, Kathryn Merrick", "title": "A Review of Theoretical and Practical Challenges of Trusted Autonomy in\n  Big Data", "comments": null, "journal-ref": null, "doi": "10.1109/ACCESS.2016.2571058", "report-no": null, "categories": "cs.CY cs.AI cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the advances made in artificial intelligence, software agents, and\nrobotics, there is little we see today that we can truly call a fully\nautonomous system. We conjecture that the main inhibitor for advancing autonomy\nis lack of trust. Trusted autonomy is the scientific and engineering field to\nestablish the foundations and ground work for developing trusted autonomous\nsystems (robotics and software agents) that can be used in our daily life, and\ncan be integrated with humans seamlessly, naturally and efficiently.\n  In this paper, we review this literature to reveal opportunities for\nresearchers and practitioners to work on topics that can create a leap forward\nin advancing the field of trusted autonomy. We focus the paper on the `trust'\ncomponent as the uniting technology between humans and machines. Our inquiry\ninto this topic revolves around three sub-topics: (1) reviewing and positioning\nthe trust modelling literature for the purpose of trusted autonomy; (2)\nreviewing a critical subset of sensor technologies that allow a machine to\nsense human states; and (3) distilling some critical questions for advancing\nthe field of trusted autonomy. The inquiry is augmented with conceptual models\nthat we propose along the way by recompiling and reshaping the literature into\nforms that enables trusted autonomous systems to become a reality. The paper\noffers a vision for a Trusted Cyborg Swarm, an extension of our previous\nCognitive Cyber Symbiosis concept, whereby humans and machines meld together in\na harmonious, seamless, and coordinated manner.\n", "versions": [{"version": "v1", "created": "Wed, 16 Mar 2016 11:00:23 GMT"}], "update_date": "2017-12-21", "authors_parsed": [["Abbass", "Hussein A.", ""], ["Leu", "George", ""], ["Merrick", "Kathryn", ""]]}, {"id": "1604.00923", "submitter": "Philip Thomas", "authors": "Philip S. Thomas and Emma Brunskill", "title": "Data-Efficient Off-Policy Policy Evaluation for Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we present a new way of predicting the performance of a\nreinforcement learning policy given historical data that may have been\ngenerated by a different policy. The ability to evaluate a policy from\nhistorical data is important for applications where the deployment of a bad\npolicy can be dangerous or costly. We show empirically that our algorithm\nproduces estimates that often have orders of magnitude lower mean squared error\nthan existing methods---it makes more efficient use of the available data. Our\nnew estimator is based on two advances: an extension of the doubly robust\nestimator (Jiang and Li, 2015), and a new way to mix between model based\nestimates and importance sampling based estimates.\n", "versions": [{"version": "v1", "created": "Mon, 4 Apr 2016 15:56:52 GMT"}], "update_date": "2016-04-05", "authors_parsed": [["Thomas", "Philip S.", ""], ["Brunskill", "Emma", ""]]}, {"id": "1604.00932", "submitter": "Hubie Chen", "authors": "Hubie Chen, Benoit Larose", "title": "Asking the metaquestions in constraint tractability", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The constraint satisfaction problem (CSP) involves deciding, given a set of\nvariables and a set of constraints on the variables, whether or not there is an\nassignment to the variables satisfying all of the constraints. One formulation\nof the CSP is as the problem of deciding, given a pair (G,H) of relational\nstructures, whether or not there is a homomorphism from the first structure to\nthe second structure. The CSP is in general NP-hard; a common way to restrict\nthis problem is to fix the second structure H, so that each structure H gives\nrise to a problem CSP(H). The problem family CSP(H) has been studied using an\nalgebraic approach, which links the algorithmic and complexity properties of\neach problem CSP(H) to a set of operations, the so-called polymorphisms of H.\nCertain types of polymorphisms are known to imply the polynomial-time\ntractability of $CSP(H)$, and others are conjectured to do so. This article\nsystematically studies---for various classes of polymorphisms---the\ncomputational complexity of deciding whether or not a given structure H admits\na polymorphism from the class. Among other results, we prove the\nNP-completeness of deciding a condition conjectured to characterize the\ntractable problems CSP(H), as well as the NP-completeness of deciding if CSP(H)\nhas bounded width.\n", "versions": [{"version": "v1", "created": "Mon, 4 Apr 2016 16:18:16 GMT"}, {"version": "v2", "created": "Fri, 6 Jan 2017 02:55:16 GMT"}], "update_date": "2017-01-09", "authors_parsed": [["Chen", "Hubie", ""], ["Larose", "Benoit", ""]]}, {"id": "1604.00980", "submitter": "Mohd Anuar Mat Isa Dr.", "authors": "Mohd Anuar Mat Isa, Ramlan Mahmod, Nur Izura Udzir, Jamalul-lail Ab\n  Manan, Ali Dehghan Tanha", "title": "A Mathematical Trust Algebra for International Nation Relations\n  Computation and Evaluation", "comments": "Keywords Trust Algebra, International Relations, Trust Computation,\n  Foreign Policy, Politics, Dempster-Shafer, Subjective Logic, Common Criteria,\n  Defense, National Security, Terrorism, Counter Terrorism, Trust Perception,\n  Foreign Ministry, Intelligent", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a trust computation for international relations and its\ncalculus, which related to Bayesian inference, Dempster Shafer theory and\nsubjective logic. We proposed a method that allows a trust computation which is\npreviously subjective and incomputable. An example of case study for the trust\ncomputation is the United States of America Great Britain relations. The method\nsupports decision makers in a government such as foreign ministry, defense\nministry, presidential or prime minister office. The Department of Defense\n(DoD) may use our method to determine a nation that can be known as a friendly,\nneutral or hostile nation.\n", "versions": [{"version": "v1", "created": "Sat, 13 Feb 2016 05:26:08 GMT"}], "update_date": "2016-04-05", "authors_parsed": [["Isa", "Mohd Anuar Mat", ""], ["Mahmod", "Ramlan", ""], ["Udzir", "Nur Izura", ""], ["Manan", "Jamalul-lail Ab", ""], ["Tanha", "Ali Dehghan", ""]]}, {"id": "1604.01166", "submitter": "Pierre Schaus", "authors": "John O.R. Aoga and Tias Guns and Pierre Schaus", "title": "An Efficient Algorithm for Mining Frequent Sequence with Constraint\n  Programming", "comments": "frequent sequence mining, constraint programming", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The main advantage of Constraint Programming (CP) approaches for sequential\npattern mining (SPM) is their modularity, which includes the ability to add new\nconstraints (regular expressions, length restrictions, etc). The current best\nCP approach for SPM uses a global constraint (module) that computes the\nprojected database and enforces the minimum frequency; it does this with a\nfiltering algorithm similar to the PrefixSpan method. However, the resulting\nsystem is not as scalable as some of the most advanced mining systems like\nZaki's cSPADE. We show how, using techniques from both data mining and CP, one\ncan use a generic constraint solver and yet outperform existing specialized\nsystems. This is mainly due to two improvements in the module that computes the\nprojected frequencies: first, computing the projected database can be sped up\nby pre-computing the positions at which an symbol can become unsupported by a\nsequence, thereby avoiding to scan the full sequence each time; and second by\ntaking inspiration from the trailing used in CP solvers to devise a\nbacktracking-aware data structure that allows fast incremental storing and\nrestoring of the projected database. Detailed experiments show how this\napproach outperforms existing CP as well as specialized systems for SPM, and\nthat the gain in efficiency translates directly into increased efficiency for\nother settings such as mining with regular expressions.\n", "versions": [{"version": "v1", "created": "Tue, 5 Apr 2016 08:15:24 GMT"}], "update_date": "2016-04-06", "authors_parsed": [["Aoga", "John O. R.", ""], ["Guns", "Tias", ""], ["Schaus", "Pierre", ""]]}, {"id": "1604.01219", "submitter": "Yuting Qaing", "authors": "Yuting Qiang, Yanwei Fu, Yanwen Guo, Zhi-Hua Zhou and Leonid Sigal", "title": "Learning to Generate Posters of Scientific Papers", "comments": "in Proceedings of the 30th AAAI Conference on Artificial Intelligence\n  (AAAI'16), Phoenix, AZ, 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.HC cs.MM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Researchers often summarize their work in the form of posters. Posters\nprovide a coherent and efficient way to convey core ideas from scientific\npapers. Generating a good scientific poster, however, is a complex and time\nconsuming cognitive task, since such posters need to be readable, informative,\nand visually aesthetic. In this paper, for the first time, we study the\nchallenging problem of learning to generate posters from scientific papers. To\nthis end, a data-driven framework, that utilizes graphical models, is proposed.\nSpecifically, given content to display, the key elements of a good poster,\nincluding panel layout and attributes of each panel, are learned and inferred\nfrom data. Then, given inferred layout and attributes, composition of graphical\nelements within each panel is synthesized. To learn and validate our model, we\ncollect and make public a Poster-Paper dataset, which consists of scientific\npapers and corresponding posters with exhaustively labelled panels and\nattributes. Qualitative and quantitative results indicate the effectiveness of\nour approach.\n", "versions": [{"version": "v1", "created": "Tue, 5 Apr 2016 11:18:04 GMT"}], "update_date": "2016-04-15", "authors_parsed": [["Qiang", "Yuting", ""], ["Fu", "Yanwei", ""], ["Guo", "Yanwen", ""], ["Zhou", "Zhi-Hua", ""], ["Sigal", "Leonid", ""]]}, {"id": "1604.01272", "submitter": "Despoina Christou", "authors": "Despoina Christou", "title": "Feature extraction using Latent Dirichlet Allocation and Neural\n  Networks: A case study on movie synopses", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Feature extraction has gained increasing attention in the field of machine\nlearning, as in order to detect patterns, extract information, or predict\nfuture observations from big data, the urge of informative features is crucial.\nThe process of extracting features is highly linked to dimensionality reduction\nas it implies the transformation of the data from a sparse high-dimensional\nspace, to higher level meaningful abstractions. This dissertation employs\nNeural Networks for distributed paragraph representations, and Latent Dirichlet\nAllocation to capture higher level features of paragraph vectors. Although\nNeural Networks for distributed paragraph representations are considered the\nstate of the art for extracting paragraph vectors, we show that a quick topic\nanalysis model such as Latent Dirichlet Allocation can provide meaningful\nfeatures too. We evaluate the two methods on the CMU Movie Summary Corpus, a\ncollection of 25,203 movie plot summaries extracted from Wikipedia. Finally,\nfor both approaches, we use K-Nearest Neighbors to discover similar movies, and\nplot the projected representations using T-Distributed Stochastic Neighbor\nEmbedding to depict the context similarities. These similarities, expressed as\nmovie distances, can be used for movies recommendation. The recommended movies\nof this approach are compared with the recommended movies from IMDB, which use\na collaborative filtering recommendation approach, to show that our two models\ncould constitute either an alternative or a supplementary recommendation\napproach.\n", "versions": [{"version": "v1", "created": "Tue, 5 Apr 2016 14:32:48 GMT"}], "update_date": "2016-04-06", "authors_parsed": [["Christou", "Despoina", ""]]}, {"id": "1604.01277", "submitter": "Ramon Fraga Pereira", "authors": "Ramon Fraga Pereira and Felipe Meneguzzi", "title": "Landmark-Based Plan Recognition", "comments": "Accepted as short paper in the 22nd European Conference on Artificial\n  Intelligence, ECAI 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recognition of goals and plans using incomplete evidence from action\nexecution can be done efficiently by using planning techniques. In many\napplications it is important to recognize goals and plans not only accurately,\nbut also quickly. In this paper, we develop a heuristic approach for\nrecognizing plans based on planning techniques that rely on ordering\nconstraints to filter candidate goals from observations. These ordering\nconstraints are called landmarks in the planning literature, which are facts or\nactions that cannot be avoided to achieve a goal. We show the applicability of\nplanning landmarks in two settings: first, we use it directly to develop a\nheuristic-based plan recognition approach; second, we refine an existing\nplanning-based plan recognition approach by pre-filtering its candidate goals.\nOur empirical evaluation shows that our approach is not only substantially more\naccurate than the state-of-the-art in all available datasets, it is also an\norder of magnitude faster.\n", "versions": [{"version": "v1", "created": "Tue, 5 Apr 2016 14:44:03 GMT"}, {"version": "v2", "created": "Tue, 28 Jun 2016 17:56:47 GMT"}, {"version": "v3", "created": "Tue, 7 Feb 2017 01:15:59 GMT"}], "update_date": "2017-02-08", "authors_parsed": [["Pereira", "Ramon Fraga", ""], ["Meneguzzi", "Felipe", ""]]}, {"id": "1604.01335", "submitter": "Brendan Jou", "authors": "Brendan Jou and Shih-Fu Chang", "title": "Deep Cross Residual Learning for Multitask Visual Recognition", "comments": "10 pages, 6 figures, To appear in ACM Multimedia", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Residual learning has recently surfaced as an effective means of constructing\nvery deep neural networks for object recognition. However, current incarnations\nof residual networks do not allow for the modeling and integration of complex\nrelations between closely coupled recognition tasks or across domains. Such\nproblems are often encountered in multimedia applications involving large-scale\ncontent recognition. We propose a novel extension of residual learning for deep\nnetworks that enables intuitive learning across multiple related tasks using\ncross-connections called cross-residuals. These cross-residuals connections can\nbe viewed as a form of in-network regularization and enables greater network\ngeneralization. We show how cross-residual learning (CRL) can be integrated in\nmultitask networks to jointly train and detect visual concepts across several\ntasks. We present a single multitask cross-residual network with >40% less\nparameters that is able to achieve competitive, or even better, detection\nperformance on a visual sentiment concept detection problem normally requiring\nmultiple specialized single-task networks. The resulting multitask\ncross-residual network also achieves better detection performance by about\n10.4% over a standard multitask residual network without cross-residuals with\neven a small amount of cross-task weighting.\n", "versions": [{"version": "v1", "created": "Tue, 5 Apr 2016 17:08:14 GMT"}, {"version": "v2", "created": "Wed, 20 Jul 2016 01:55:12 GMT"}], "update_date": "2016-07-21", "authors_parsed": [["Jou", "Brendan", ""], ["Chang", "Shih-Fu", ""]]}, {"id": "1604.01350", "submitter": "Kenji Kawaguchi", "authors": "Kenji Kawaguchi", "title": "Bounded Optimal Exploration in MDP", "comments": "In Proceedings of the 30th AAAI Conference on Artificial Intelligence\n  (AAAI), 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Within the framework of probably approximately correct Markov decision\nprocesses (PAC-MDP), much theoretical work has focused on methods to attain\nnear optimality after a relatively long period of learning and exploration.\nHowever, practical concerns require the attainment of satisfactory behavior\nwithin a short period of time. In this paper, we relax the PAC-MDP conditions\nto reconcile theoretically driven exploration methods and practical needs. We\npropose simple algorithms for discrete and continuous state spaces, and\nillustrate the benefits of our proposed relaxation via theoretical analyses and\nnumerical examples. Our algorithms also maintain anytime error bounds and\naverage loss bounds. Our approach accommodates both Bayesian and non-Bayesian\nmethods.\n", "versions": [{"version": "v1", "created": "Tue, 5 Apr 2016 18:00:02 GMT"}], "update_date": "2016-04-06", "authors_parsed": [["Kawaguchi", "Kenji", ""]]}, {"id": "1604.01360", "submitter": "Lerrel Pinto Mr", "authors": "Lerrel Pinto, Dhiraj Gandhi, Yuanfeng Han, Yong-Lae Park, Abhinav\n  Gupta", "title": "The Curious Robot: Learning Visual Representations via Physical\n  Interactions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  What is the right supervisory signal to train visual representations? Current\napproaches in computer vision use category labels from datasets such as\nImageNet to train ConvNets. However, in case of biological agents, visual\nrepresentation learning does not require millions of semantic labels. We argue\nthat biological agents use physical interactions with the world to learn visual\nrepresentations unlike current vision systems which just use passive\nobservations (images and videos downloaded from web). For example, babies push\nobjects, poke them, put them in their mouth and throw them to learn\nrepresentations. Towards this goal, we build one of the first systems on a\nBaxter platform that pushes, pokes, grasps and observes objects in a tabletop\nenvironment. It uses four different types of physical interactions to collect\nmore than 130K datapoints, with each datapoint providing supervision to a\nshared ConvNet architecture allowing us to learn visual representations. We\nshow the quality of learned representations by observing neuron activations and\nperforming nearest neighbor retrieval on this learned representation.\nQuantitatively, we evaluate our learned ConvNet on image classification tasks\nand show improvements compared to learning without external data. Finally, on\nthe task of instance retrieval, our network outperforms the ImageNet network on\nrecall@1 by 3%\n", "versions": [{"version": "v1", "created": "Tue, 5 Apr 2016 18:47:15 GMT"}, {"version": "v2", "created": "Tue, 26 Jul 2016 03:30:44 GMT"}], "update_date": "2016-07-27", "authors_parsed": [["Pinto", "Lerrel", ""], ["Gandhi", "Dhiraj", ""], ["Han", "Yuanfeng", ""], ["Park", "Yong-Lae", ""], ["Gupta", "Abhinav", ""]]}, {"id": "1604.01662", "submitter": "Hao Wang", "authors": "Hao Wang and Dit-Yan Yeung", "title": "A Survey on Bayesian Deep Learning", "comments": "Published in ACM Computing Surveys (CSUR) 2020. Constantly updating\n  project page at https://github.com/js05212/BayesianDeepLearning-Survey", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A comprehensive artificial intelligence system needs to not only perceive the\nenvironment with different `senses' (e.g., seeing and hearing) but also infer\nthe world's conditional (or even causal) relations and corresponding\nuncertainty. The past decade has seen major advances in many perception tasks\nsuch as visual object recognition and speech recognition using deep learning\nmodels. For higher-level inference, however, probabilistic graphical models\nwith their Bayesian nature are still more powerful and flexible. In recent\nyears, Bayesian deep learning has emerged as a unified probabilistic framework\nto tightly integrate deep learning and Bayesian models. In this general\nframework, the perception of text or images using deep learning can boost the\nperformance of higher-level inference and in turn, the feedback from the\ninference process is able to enhance the perception of text or images. This\nsurvey provides a comprehensive introduction to Bayesian deep learning and\nreviews its recent applications on recommender systems, topic models, control,\netc. Besides, we also discuss the relationship and differences between Bayesian\ndeep learning and other related topics such as Bayesian treatment of neural\nnetworks. For a constantly updating project page, please refer to\nhttps://github.com/js05212/BayesianDeepLearning-Survey.\n", "versions": [{"version": "v1", "created": "Wed, 6 Apr 2016 15:35:08 GMT"}, {"version": "v2", "created": "Thu, 7 Apr 2016 06:17:44 GMT"}, {"version": "v3", "created": "Thu, 2 Jul 2020 03:52:57 GMT"}, {"version": "v4", "created": "Wed, 6 Jan 2021 03:14:13 GMT"}], "update_date": "2021-01-07", "authors_parsed": [["Wang", "Hao", ""], ["Yeung", "Dit-Yan", ""]]}, {"id": "1604.01673", "submitter": "Antti Kuusisto", "authors": "Antti Kuusisto", "title": "On the uniform one-dimensional fragment", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The uniform one-dimensional fragment of first-order logic, U1, is a recently\nintroduced formalism that extends two-variable logic in a natural way to\ncontexts with relations of all arities. We survey properties of U1 and\ninvestigate its relationship to description logics designed to accommodate\nhigher arity relations, with particular attention given to DLR_reg. We also\ndefine a description logic version of a variant of U1 and prove a range of new\nresults concerning the expressivity of U1 and related logics.\n", "versions": [{"version": "v1", "created": "Wed, 6 Apr 2016 16:03:42 GMT"}, {"version": "v2", "created": "Thu, 7 Apr 2016 15:09:02 GMT"}], "update_date": "2016-04-08", "authors_parsed": [["Kuusisto", "Antti", ""]]}, {"id": "1604.01696", "submitter": "Nasrin Mostafazadeh", "authors": "Nasrin Mostafazadeh, Nathanael Chambers, Xiaodong He, Devi Parikh,\n  Dhruv Batra, Lucy Vanderwende, Pushmeet Kohli and James Allen", "title": "A Corpus and Evaluation Framework for Deeper Understanding of\n  Commonsense Stories", "comments": "In Proceedings of the 2016 North American Chapter of the ACL (NAACL\n  HLT), 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Representation and learning of commonsense knowledge is one of the\nfoundational problems in the quest to enable deep language understanding. This\nissue is particularly challenging for understanding casual and correlational\nrelationships between events. While this topic has received a lot of interest\nin the NLP community, research has been hindered by the lack of a proper\nevaluation framework. This paper attempts to address this problem with a new\nframework for evaluating story understanding and script learning: the 'Story\nCloze Test'. This test requires a system to choose the correct ending to a\nfour-sentence story. We created a new corpus of ~50k five-sentence commonsense\nstories, ROCStories, to enable this evaluation. This corpus is unique in two\nways: (1) it captures a rich set of causal and temporal commonsense relations\nbetween daily events, and (2) it is a high quality collection of everyday life\nstories that can also be used for story generation. Experimental evaluation\nshows that a host of baselines and state-of-the-art models based on shallow\nlanguage understanding struggle to achieve a high score on the Story Cloze\nTest. We discuss these implications for script and story learning, and offer\nsuggestions for deeper language understanding.\n", "versions": [{"version": "v1", "created": "Wed, 6 Apr 2016 17:15:10 GMT"}], "update_date": "2016-04-07", "authors_parsed": [["Mostafazadeh", "Nasrin", ""], ["Chambers", "Nathanael", ""], ["He", "Xiaodong", ""], ["Parikh", "Devi", ""], ["Batra", "Dhruv", ""], ["Vanderwende", "Lucy", ""], ["Kohli", "Pushmeet", ""], ["Allen", "James", ""]]}, {"id": "1604.01734", "submitter": "Michel Lemaitre", "authors": "Sylvain Bouveret, Michel Lema\\^itre (Toulouse)", "title": "Efficiency and Sequenceability in Fair Division of Indivisible Goods\n  with Additive Preferences", "comments": "COMSOC-2016, Jun 2016, Toulouse, France", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In fair division of indivisible goods, using sequences of sincere choices (or\npicking sequences) is a natural way to allocate the objects. The idea is the\nfollowing: at each stage, a designated agent picks one object among those that\nremain. This paper, restricted to the case where the agents have numerical\nadditive preferences over objects, revisits to some extent the seminal paper by\nBrams and King [9] which was specific to ordinal and linear order preferences\nover items. We point out similarities and differences with this latter context.\nIn particular, we show that any Pareto-optimal allocation (under additive\npreferences) is sequenceable, but that the converse is not true anymore. This\nasymmetry leads naturally to the definition of a \"scale of efficiency\" having\nthree steps: Pareto-optimality, sequenceability without Pareto-optimality, and\nnon-sequenceability. Finally, we investigate the links between these efficiency\nproperties and the \"scale of fairness\" we have described in an earlier work\n[7]: we first show that an allocation can be envy-free and non-sequenceable,\nbut that every competitive equilibrium with equal incomes is sequenceable. Then\nwe experimentally explore the links between the scales of efficiency and\nfairness.\n", "versions": [{"version": "v1", "created": "Wed, 6 Apr 2016 19:08:34 GMT"}], "update_date": "2016-04-07", "authors_parsed": [["Bouveret", "Sylvain", "", "Toulouse"], ["Lema\u00eetre", "Michel", "", "Toulouse"]]}, {"id": "1604.01785", "submitter": "Peter Gr\\\"unwald", "authors": "Peter Gr\\\"unwald", "title": "Safe Probability", "comments": "Submitted to a journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.AI cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We formalize the idea of probability distributions that lead to reliable\npredictions about some, but not all aspects of a domain. The resulting notion\nof `safety' provides a fresh perspective on foundational issues in statistics,\nproviding a middle ground between imprecise probability and multiple-prior\nmodels on the one hand and strictly Bayesian approaches on the other. It also\nallows us to formalize fiducial distributions in terms of the set of random\nvariables that they can safely predict, thus taking some of the sting out of\nthe fiducial idea. By restricting probabilistic inference to safe uses, one\nalso automatically avoids paradoxes such as the Monty Hall problem. Safety\ncomes in a variety of degrees, such as \"validity\" (the strongest notion),\n\"calibration\", \"confidence safety\" and \"unbiasedness\" (almost the weakest\nnotion).\n", "versions": [{"version": "v1", "created": "Wed, 6 Apr 2016 20:01:28 GMT"}], "update_date": "2016-04-08", "authors_parsed": [["Gr\u00fcnwald", "Peter", ""]]}, {"id": "1604.01802", "submitter": "David Held", "authors": "David Held, Sebastian Thrun, Silvio Savarese", "title": "Learning to Track at 100 FPS with Deep Regression Networks", "comments": "To appear in European Conference on Computer Vision (ECCV) 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning techniques are often used in computer vision due to their\nability to leverage large amounts of training data to improve performance.\nUnfortunately, most generic object trackers are still trained from scratch\nonline and do not benefit from the large number of videos that are readily\navailable for offline training. We propose a method for offline training of\nneural networks that can track novel objects at test-time at 100 fps. Our\ntracker is significantly faster than previous methods that use neural networks\nfor tracking, which are typically very slow to run and not practical for\nreal-time applications. Our tracker uses a simple feed-forward network with no\nonline training required. The tracker learns a generic relationship between\nobject motion and appearance and can be used to track novel objects that do not\nappear in the training set. We test our network on a standard tracking\nbenchmark to demonstrate our tracker's state-of-the-art performance. Further,\nour performance improves as we add more videos to our offline training set. To\nthe best of our knowledge, our tracker is the first neural-network tracker that\nlearns to track generic objects at 100 fps.\n", "versions": [{"version": "v1", "created": "Wed, 6 Apr 2016 20:39:34 GMT"}, {"version": "v2", "created": "Tue, 16 Aug 2016 02:34:48 GMT"}], "update_date": "2016-08-17", "authors_parsed": [["Held", "David", ""], ["Thrun", "Sebastian", ""], ["Savarese", "Silvio", ""]]}, {"id": "1604.02006", "submitter": "Ann Drobnis", "authors": "Vasant G. Honavar, Mark D. Hill, and Katherine Yelick", "title": "Accelerating Science: A Computing Research Agenda", "comments": "Computing Community Consortium (CCC) white paper, 17 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.DC cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The emergence of \"big data\" offers unprecedented opportunities for not only\naccelerating scientific advances but also enabling new modes of discovery.\nScientific progress in many disciplines is increasingly enabled by our ability\nto examine natural phenomena through the computational lens, i.e., using\nalgorithmic or information processing abstractions of the underlying processes;\nand our ability to acquire, share, integrate and analyze disparate types of\ndata. However, there is a huge gap between our ability to acquire, store, and\nprocess data and our ability to make effective use of the data to advance\ndiscovery. Despite successful automation of routine aspects of data management\nand analytics, most elements of the scientific process currently require\nconsiderable human expertise and effort. Accelerating science to keep pace with\nthe rate of data acquisition and data processing calls for the development of\nalgorithmic or information processing abstractions, coupled with formal methods\nand tools for modeling and simulation of natural processes as well as major\ninnovations in cognitive tools for scientists, i.e., computational tools that\nleverage and extend the reach of human intellect, and partner with humans on a\nbroad range of tasks in scientific discovery (e.g., identifying, prioritizing\nformulating questions, designing, prioritizing and executing experiments\ndesigned to answer a chosen question, drawing inferences and evaluating the\nresults, and formulating new questions, in a closed-loop fashion). This calls\nfor concerted research agenda aimed at: Development, analysis, integration,\nsharing, and simulation of algorithmic or information processing abstractions\nof natural processes, coupled with formal methods and tools for their analyses\nand simulation; Innovations in cognitive tools that augment and extend human\nintellect and partner with humans in all aspects of science.\n", "versions": [{"version": "v1", "created": "Wed, 6 Apr 2016 18:43:00 GMT"}], "update_date": "2017-07-03", "authors_parsed": [["Honavar", "Vasant G.", ""], ["Hill", "Mark D.", ""], ["Yelick", "Katherine", ""]]}, {"id": "1604.02080", "submitter": "Jordi Grau-Moya", "authors": "Jordi Grau-Moya, Felix Leibfried, Tim Genewein, Daniel A. Braun", "title": "Planning with Information-Processing Constraints and Model Uncertainty\n  in Markov Decision Processes", "comments": "16 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Information-theoretic principles for learning and acting have been proposed\nto solve particular classes of Markov Decision Problems. Mathematically, such\napproaches are governed by a variational free energy principle and allow\nsolving MDP planning problems with information-processing constraints expressed\nin terms of a Kullback-Leibler divergence with respect to a reference\ndistribution. Here we consider a generalization of such MDP planners by taking\nmodel uncertainty into account. As model uncertainty can also be formalized as\nan information-processing constraint, we can derive a unified solution from a\nsingle generalized variational principle. We provide a generalized value\niteration scheme together with a convergence proof. As limit cases, this\ngeneralized scheme includes standard value iteration with a known model,\nBayesian MDP planning, and robust planning. We demonstrate the benefits of this\napproach in a grid world simulation.\n", "versions": [{"version": "v1", "created": "Thu, 7 Apr 2016 17:12:07 GMT"}], "update_date": "2016-04-08", "authors_parsed": [["Grau-Moya", "Jordi", ""], ["Leibfried", "Felix", ""], ["Genewein", "Tim", ""], ["Braun", "Daniel A.", ""]]}, {"id": "1604.02126", "submitter": "Gavin Rens", "authors": "Gavin Rens", "title": "On Stochastic Belief Revision and Update and their Combination", "comments": "Presented at the Sixteenth International Workshop on Non-Monotonic\n  Reasoning, 22-24 April 2016, Cape Town, South Africa. 10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  I propose a framework for an agent to change its probabilistic beliefs when a\nnew piece of propositional information $\\alpha$ is observed. Traditionally,\nbelief change occurs by either a revision process or by an update process,\ndepending on whether the agent is informed with $\\alpha$ in a static world or,\nrespectively, whether $\\alpha$ is a 'signal' from the environment due to an\nevent occurring. Boutilier suggested a unified model of qualitative belief\nchange, which \"combines aspects of revision and update, providing a more\nrealistic characterization of belief change.\" In this paper, I propose a\nunified model of quantitative belief change, where an agent's beliefs are\nrepresented as a probability distribution over possible worlds. As does\nBoutilier, I take a dynamical systems perspective. The proposed approach is\nevaluated against several rationality postulated, and some properties of the\napproach are worked out.\n", "versions": [{"version": "v1", "created": "Thu, 7 Apr 2016 19:28:00 GMT"}], "update_date": "2016-04-08", "authors_parsed": [["Rens", "Gavin", ""]]}, {"id": "1604.02133", "submitter": "Gavin Rens", "authors": "Gavin Rens, Thomas Meyer, Giovanni Casini", "title": "Revising Incompletely Specified Convex Probabilistic Belief Bases", "comments": "Presented at the Sixteenth International Workshop on Non-Monotonic\n  Reasoning, 22-24 April 2016, Cape Town, South Africa. 9.25 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a method for an agent to revise its incomplete probabilistic\nbeliefs when a new piece of propositional information is observed. In this\nwork, an agent's beliefs are represented by a set of probabilistic formulae --\na belief base. The method involves determining a representative set of\n'boundary' probability distributions consistent with the current belief base,\nrevising each of these probability distributions and then translating the\nrevised information into a new belief base. We use a version of Lewis Imaging\nas the revision operation. The correctness of the approach is proved. The\nexpressivity of the belief bases under consideration are rather restricted, but\nhas some applications. We also discuss methods of belief base revision\nemploying the notion of optimum entropy, and point out some of the benefits and\ndifficulties in those methods. Both the boundary distribution method and the\noptimum entropy method are reasonable, yet yield different results.\n", "versions": [{"version": "v1", "created": "Thu, 7 Apr 2016 19:41:35 GMT"}], "update_date": "2016-04-08", "authors_parsed": [["Rens", "Gavin", ""], ["Meyer", "Thomas", ""], ["Casini", "Giovanni", ""]]}, {"id": "1604.02323", "submitter": "Kennedy Ehimwenma", "authors": "Kennedy E. Ehimwenma, Paul Crowther and Martin Beer", "title": "A system of serial computation for classified rules prediction in\n  non-regular ontology trees", "comments": "13 pages, 15 figures, International Journal article, PhD research\n  work", "journal-ref": "International Journal of Artificial Intelligence and Applications\n  (IJAIA) March 2016, Vol 7(2), pp. 21-33", "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Objects or structures that are regular take uniform dimensions. Based on the\nconcepts of regular models, our previous research work has developed a system\nof a regular ontology that models learning structures in a multiagent system\nfor uniform pre-assessments in a learning environment. This regular ontology\nhas led to the modelling of a classified rules learning algorithm that predicts\nthe actual number of rules needed for inductive learning processes and decision\nmaking in a multiagent system. But not all processes or models are regular.\nThus this paper presents a system of polynomial equation that can estimate and\npredict the required number of rules of a non-regular ontology model given some\ndefined parameters.\n", "versions": [{"version": "v1", "created": "Fri, 8 Apr 2016 12:12:17 GMT"}], "update_date": "2016-04-11", "authors_parsed": [["Ehimwenma", "Kennedy E.", ""], ["Crowther", "Paul", ""], ["Beer", "Martin", ""]]}, {"id": "1604.02336", "submitter": "Kevin Wilson", "authors": "Kevin H. Wilson, Yan Karklin, Bojian Han, and Chaitanya Ekanadham", "title": "Back to the Basics: Bayesian extensions of IRT outperform neural\n  networks for proficiency estimation", "comments": "6 pages, 2 figures, Educational Data Mining 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Estimating student proficiency is an important task for computer based\nlearning systems. We compare a family of IRT-based proficiency estimation\nmethods to Deep Knowledge Tracing (DKT), a recently proposed recurrent neural\nnetwork model with promising initial results. We evaluate how well each model\npredicts a student's future response given previous responses using two\npublicly available and one proprietary data set. We find that IRT-based methods\nconsistently matched or outperformed DKT across all data sets at the finest\nlevel of content granularity that was tractable for them to be trained on. A\nhierarchical extension of IRT that captured item grouping structure performed\nbest overall. When data sets included non-trivial autocorrelations in student\nresponse patterns, a temporal extension of IRT improved performance over\nstandard IRT while the RNN-based method did not. We conclude that IRT-based\nmodels provide a simpler, better-performing alternative to existing RNN-based\nmodels of student interaction data while also affording more interpretability\nand guarantees due to their formulation as Bayesian probabilistic models.\n", "versions": [{"version": "v1", "created": "Fri, 8 Apr 2016 12:54:18 GMT"}, {"version": "v2", "created": "Sat, 21 May 2016 18:26:21 GMT"}], "update_date": "2016-05-24", "authors_parsed": [["Wilson", "Kevin H.", ""], ["Karklin", "Yan", ""], ["Han", "Bojian", ""], ["Ekanadham", "Chaitanya", ""]]}, {"id": "1604.02416", "submitter": "Michael Mozer", "authors": "Mohammad Khajah and Robert V. Lindsey and Michael C. Mozer", "title": "How deep is knowledge tracing?", "comments": "8 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In theoretical cognitive science, there is a tension between highly\nstructured models whose parameters have a direct psychological interpretation\nand highly complex, general-purpose models whose parameters and representations\nare difficult to interpret. The former typically provide more insight into\ncognition but the latter often perform better. This tension has recently\nsurfaced in the realm of educational data mining, where a deep learning\napproach to predicting students' performance as they work through a series of\nexercises---termed deep knowledge tracing or DKT---has demonstrated a stunning\nperformance advantage over the mainstay of the field, Bayesian knowledge\ntracing or BKT. In this article, we attempt to understand the basis for DKT's\nadvantage by considering the sources of statistical regularity in the data that\nDKT can leverage but which BKT cannot. We hypothesize four forms of regularity\nthat BKT fails to exploit: recency effects, the contextualized trial sequence,\ninter-skill similarity, and individual variation in ability. We demonstrate\nthat when BKT is extended to allow it more flexibility in modeling statistical\nregularities---using extensions previously proposed in the literature---BKT\nachieves a level of performance indistinguishable from that of DKT. We argue\nthat while DKT is a powerful, useful, general-purpose framework for modeling\nstudent learning, its gains do not come from the discovery of novel\nrepresentations---the fundamental advantage of deep learning. To answer the\nquestion posed in our title, knowledge tracing may be a domain that does not\nrequire `depth'; shallow models like BKT can perform just as well and offer us\ngreater interpretability and explanatory power.\n", "versions": [{"version": "v1", "created": "Mon, 14 Mar 2016 04:20:55 GMT"}, {"version": "v2", "created": "Tue, 21 Jun 2016 04:51:22 GMT"}], "update_date": "2016-06-22", "authors_parsed": [["Khajah", "Mohammad", ""], ["Lindsey", "Robert V.", ""], ["Mozer", "Michael C.", ""]]}, {"id": "1604.02509", "submitter": "Shiwali Mohan", "authors": "Shiwali Mohan, Aaron Mininger, John Laird", "title": "Towards an Indexical Model of Situated Language Comprehension for\n  Cognitive Agents in Physical Worlds", "comments": "Advances in Cognitive Systems 3 (2014)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a computational model of situated language comprehension based on\nthe Indexical Hypothesis that generates meaning representations by translating\namodal linguistic symbols to modal representations of beliefs, knowledge, and\nexperience external to the linguistic system. This Indexical Model incorporates\nmultiple information sources, including perceptions, domain knowledge, and\nshort-term and long-term experiences during comprehension. We show that\nexploiting diverse information sources can alleviate ambiguities that arise\nfrom contextual use of underspecific referring expressions and unexpressed\nargument alternations of verbs. The model is being used to support linguistic\ninteractions in Rosie, an agent implemented in Soar that learns from\ninstruction.\n", "versions": [{"version": "v1", "created": "Sat, 9 Apr 2016 01:57:13 GMT"}], "update_date": "2016-04-12", "authors_parsed": [["Mohan", "Shiwali", ""], ["Mininger", "Aaron", ""], ["Laird", "John", ""]]}, {"id": "1604.02523", "submitter": "Somaiyeh Mahmoud Zadeh", "authors": "S. Mahmoud Zadeh, D. M.W. Powers, A. Yazdani, K. Sammut, A Atyabi", "title": "Differential Evolution for Efficient AUV Path Planning in Time Variant\n  Uncertain Underwater Environment", "comments": "9 Pages,6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The AUV three-dimension path planning in complex turbulent underwater\nenvironment is investigated in this research, in which static current map data\nand uncertain static-moving time variant obstacles are taken into account.\nRobustness of AUVs path planning to this strong variability is known as a\ncomplex NP-hard problem and is considered a critical issue to ensure vehicles\nsafe deployment. Efficient evolutionary techniques have substantial potential\nof handling NP hard complexity of path planning problem as more powerful and\nfast algorithms among other approaches for mentioned problem. For the purpose\nof this research Differential Evolution (DE) technique is conducted to solve\nthe AUV path planning problem in a realistic underwater environment. The path\nplanners designed in this paper are capable of extracting feasible areas of a\nreal map to determine the allowed spaces for deployment, where coastal area,\nislands, static/dynamic obstacles and ocean current is taken into account and\nprovides the efficient path with a small computation time. The results obtained\nfrom analyze of experimental demonstrate the inherent robustness and drastic\nefficiency of the proposed scheme in enhancement of the vehicles path planning\ncapability in coping undesired current, using useful current flow, and avoid\ncolliding collision boundaries in a real-time manner. The proposed approach is\nalso flexible and strictly respects to vehicle's kinematic constraints\nresisting current instabilities.\n", "versions": [{"version": "v1", "created": "Sat, 9 Apr 2016 05:04:29 GMT"}, {"version": "v2", "created": "Tue, 26 Apr 2016 07:24:06 GMT"}, {"version": "v3", "created": "Wed, 15 Jun 2016 23:01:23 GMT"}, {"version": "v4", "created": "Sun, 4 Dec 2016 12:17:53 GMT"}], "update_date": "2016-12-06", "authors_parsed": [["Zadeh", "S. Mahmoud", ""], ["Powers", "D. M. W.", ""], ["Yazdani", "A.", ""], ["Sammut", "K.", ""], ["Atyabi", "A", ""]]}, {"id": "1604.02737", "submitter": "Luis Ortiz", "authors": "Luis E. Ortiz and Boshen Wang and Ze Gong", "title": "Correlated Equilibria for Approximate Variational Inference in MRFs", "comments": "54 pages, 8 figures, 20 plots, Extension of Section 4 of a manuscript\n  by the first author first drafted on August 25, 2009 (see\n  http://www-personal.umd.umich.edu/~leortiz/papers/infeq.pdf). Changes:\n  experiments with multiplicative-weight learning algorithms on larger (12x12)\n  synthetic Ising models and 28x28 Ising models learned from MNIST dataset; and\n  misc. edits to improve presentation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.GT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Almost all of the work in graphical models for game theory has mirrored\nprevious work in probabilistic graphical models. Our work considers the\nopposite direction: Taking advantage of recent advances in equilibrium\ncomputation for probabilistic inference. We present formulations of inference\nproblems in Markov random fields (MRFs) as computation of equilibria in a\ncertain class of game-theoretic graphical models. We concretely establishes the\nprecise connection between variational probabilistic inference in MRFs and\ncorrelated equilibria. No previous work exploits recent theoretical and\nempirical results from the literature on algorithmic and computational game\ntheory on the tractable, polynomial-time computation of exact or approximate\ncorrelated equilibria in graphical games with arbitrary, loopy graph structure.\nWe discuss how to design new algorithms with equally tractable guarantees for\nthe computation of approximate variational inference in MRFs. Also, inspired by\na previously stated game-theoretic view of state-of-the-art tree-reweighed\n(TRW) message-passing techniques for belief inference as zero-sum game, we\npropose a different, general-sum potential game to design approximate\nfictitious-play techniques. We perform synthetic experiments evaluating our\nproposed approximation algorithms with standard methods and TRW on several\nclasses of classical Ising models (i.e., with binary random variables). We also\nevaluate the algorithms using Ising models learned from the MNIST dataset. Our\nexperiments show that our global approach is competitive, particularly shinning\nin a class of Ising models with constant, \"highly attractive\" edge-weights, in\nwhich it is often better than all other alternatives we evaluated. With a\nnotable exception, our more local approach was not as effective. Yet, in\nfairness, almost all of the alternatives are often no better than a simple\nbaseline: estimate 0.5.\n", "versions": [{"version": "v1", "created": "Sun, 10 Apr 2016 21:21:00 GMT"}, {"version": "v2", "created": "Sat, 7 Oct 2017 13:18:40 GMT"}], "update_date": "2017-10-10", "authors_parsed": [["Ortiz", "Luis E.", ""], ["Wang", "Boshen", ""], ["Gong", "Ze", ""]]}, {"id": "1604.02774", "submitter": "Carlos Leandro", "authors": "Carlos Leandro", "title": "Reverse Engineering and Symbolic Knowledge Extraction on {\\L}ukasiewicz\n  Fuzzy Logics using Linear Neural Networks", "comments": "24 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work describes a methodology to combine logic-based systems and\nconnectionist systems. Our approach uses finite truth valued {\\L}ukasiewicz\nlogic, where we take advantage of fact what in this type of logics every\nconnective can be define by a neuron in an artificial network having by\nactivation function the identity truncated to zero and one. This allowed the\ninjection of first-order formulas in a network architecture, and also\nsimplified symbolic rule extraction.\n  Our method trains a neural network using Levenderg-Marquardt algorithm, where\nwe restrict the knowledge dissemination in the network structure. We show how\nthis reduces neural networks plasticity without damage drastically the learning\nperformance. Making the descriptive power of produced neural networks similar\nto the descriptive power of {\\L}ukasiewicz logic language, simplifying the\ntranslation between symbolic and connectionist structures.\n  This method is used in the reverse engineering problem of finding the formula\nused on generation of a truth table for a multi-valued {\\L}ukasiewicz logic.\nFor real data sets the method is particularly useful for attribute selection,\non binary classification problems defined using nominal attribute. After\nattribute selection and possible data set completion in the resulting\nconnectionist model: neurons are directly representable using a disjunctive or\nconjunctive formulas, in the {\\L}ukasiewicz logic, or neurons are\ninterpretations which can be approximated by symbolic rules. This fact is\nexemplified, extracting symbolic knowledge from connectionist models generated\nfor the data set Mushroom from UCI Machine Learning Repository.\n", "versions": [{"version": "v1", "created": "Mon, 11 Apr 2016 02:05:21 GMT"}], "update_date": "2016-04-12", "authors_parsed": [["Leandro", "Carlos", ""]]}, {"id": "1604.02780", "submitter": "Carlos Leandro", "authors": "Carlos Leandro", "title": "Knowledge Extraction and Knowledge Integration governed by\n  {\\L}ukasiewicz Logics", "comments": "38 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The development of machine learning in particular and artificial intelligent\nin general has been strongly conditioned by the lack of an appropriate\ninterface layer between deduction, abduction and induction. In this work we\nextend traditional algebraic specification methods in this direction. Here we\nassume that such interface for AI emerges from an adequate Neural-Symbolic\nintegration. This integration is made for universe of discourse described on a\nTopos governed by a many-valued {\\L}ukasiewicz logic. Sentences are integrated\nin a symbolic knowledge base describing the problem domain, codified using a\ngraphic-based language, wherein every logic connective is defined by a neuron\nin an artificial network. This allows the integration of first-order formulas\ninto a network architecture as background knowledge, and simplifies symbolic\nrule extraction from trained networks. For the train of such neural networks we\nchanged the Levenderg-Marquardt algorithm, restricting the knowledge\ndissemination in the network structure using soft crystallization. This\nprocedure reduces neural network plasticity without drastically damaging the\nlearning performance, allowing the emergence of symbolic patterns. This makes\nthe descriptive power of produced neural networks similar to the descriptive\npower of {\\L}ukasiewicz logic language, reducing the information lost on\ntranslation between symbolic and connectionist structures. We tested this\nmethod on the extraction of knowledge from specified structures. For it, we\npresent the notion of fuzzy state automata, and we use automata behaviour to\ninfer its structure. We use this type of automata on the generation of models\nfor relations specified as symbolic background knowledge.\n", "versions": [{"version": "v1", "created": "Mon, 11 Apr 2016 03:23:21 GMT"}], "update_date": "2016-04-12", "authors_parsed": [["Leandro", "Carlos", ""]]}, {"id": "1604.03099", "submitter": "Carlos Leandro", "authors": "Carlos Leandro", "title": "Symbolic Knowledge Extraction using {\\L}ukasiewicz Logics", "comments": "15 pages. arXiv admin note: substantial text overlap with\n  arXiv:1604.02780, arXiv:1604.02774", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work describes a methodology that combines logic-based systems and\nconnectionist systems. Our approach uses finite truth-valued {\\L}ukasiewicz\nlogic, wherein every connective can be defined by a neuron in an artificial\nnetwork. This allowed the injection of first-order formulas into a network\narchitecture, and also simplified symbolic rule extraction. For that we trained\na neural networks using the Levenderg-Marquardt algorithm, where we restricted\nthe knowledge dissemination in the network structure. This procedure reduces\nneural network plasticity without drastically damaging the learning\nperformance, thus making the descriptive power of produced neural networks\nsimilar to the descriptive power of {\\L}ukasiewicz logic language and\nsimplifying the translation between symbolic and connectionist structures. We\nused this method for reverse engineering truth table and in extraction of\nformulas from real data sets.\n", "versions": [{"version": "v1", "created": "Mon, 11 Apr 2016 05:17:09 GMT"}], "update_date": "2016-04-13", "authors_parsed": [["Leandro", "Carlos", ""]]}, {"id": "1604.03114", "submitter": "Justine Zhang", "authors": "Justine Zhang, Ravi Kumar, Sujith Ravi, Cristian\n  Danescu-Niculescu-Mizil", "title": "Conversational flow in Oxford-style debates", "comments": "To appear at NAACL 2016. 5 pp, 1 fig. Data and other info available\n  at http://www.cs.cornell.edu/~cristian/debates", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.SI physics.soc-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Public debates are a common platform for presenting and juxtaposing diverging\nviews on important issues. In this work we propose a methodology for tracking\nhow ideas flow between participants throughout a debate. We use this approach\nin a case study of Oxford-style debates---a competitive format where the winner\nis determined by audience votes---and show how the outcome of a debate depends\non aspects of conversational flow. In particular, we find that winners tend to\nmake better use of a debate's interactive component than losers, by actively\npursuing their opponents' points rather than promoting their own ideas over the\ncourse of the conversation.\n", "versions": [{"version": "v1", "created": "Mon, 11 Apr 2016 20:00:04 GMT"}], "update_date": "2016-04-13", "authors_parsed": [["Zhang", "Justine", ""], ["Kumar", "Ravi", ""], ["Ravi", "Sujith", ""], ["Danescu-Niculescu-Mizil", "Cristian", ""]]}, {"id": "1604.03200", "submitter": "Ilias Flaounas", "authors": "Ricardo \\~Nanculef, Ilias Flaounas, Nello Cristianini", "title": "Efficient Classification of Multi-Labelled Text Streams by Clashing", "comments": null, "journal-ref": null, "doi": "10.1016/j.eswa.2014.02.017", "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a method for the classification of multi-labelled text documents\nexplicitly designed for data stream applications that require to process a\nvirtually infinite sequence of data using constant memory and constant\nprocessing time. Our method is composed of an online procedure used to\nefficiently map text into a low-dimensional feature space and a partition of\nthis space into a set of regions for which the system extracts and keeps\nstatistics used to predict multi-label text annotations. Documents are fed into\nthe system as a sequence of words, mapped to a region of the partition, and\nannotated using the statistics computed from the labelled instances colliding\nin the same region. This approach is referred to as clashing. We illustrate the\nmethod in real-world text data, comparing the results with those obtained using\nother text classifiers. In addition, we provide an analysis about the effect of\nthe representation space dimensionality on the predictive performance of the\nsystem. Our results show that the online embedding indeed approximates the\ngeometry of the full corpus-wise TF and TF-IDF space. The model obtains\ncompetitive F measures with respect to the most accurate methods, using\nsignificantly fewer computational resources. In addition, the method achieves a\nhigher macro-averaged F measure than methods with similar running time.\nFurthermore, the system is able to learn faster than the other methods from\npartially labelled streams.\n", "versions": [{"version": "v1", "created": "Tue, 12 Apr 2016 01:52:38 GMT"}], "update_date": "2016-04-13", "authors_parsed": [["\u00d1anculef", "Ricardo", ""], ["Flaounas", "Ilias", ""], ["Cristianini", "Nello", ""]]}, {"id": "1604.03210", "submitter": "Son-Il Kwak", "authors": "Kwak Son Il", "title": "An Analysis of General Fuzzy Logic and Fuzzy Reasoning Method", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this article, we describe the fuzzy logic, fuzzy language and algorithms\nas the basis of fuzzy reasoning, one of the intelligent information processing\nmethod, and then describe the general fuzzy reasoning method.\n", "versions": [{"version": "v1", "created": "Thu, 7 Apr 2016 13:05:10 GMT"}], "update_date": "2016-04-13", "authors_parsed": [["Il", "Kwak Son", ""]]}, {"id": "1604.03243", "submitter": "Luke Mathieson", "authors": "Giuseppe Lancia, Luke Mathieson, Pablo Moscato", "title": "Separating Sets of Strings by Finding Matching Patterns is Almost Always\n  Hard", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.AI cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the complexity of the problem of searching for a set of patterns\nthat separate two given sets of strings. This problem has applications in a\nwide variety of areas, most notably in data mining, computational biology, and\nin understanding the complexity of genetic algorithms. We show that the basic\nproblem of finding a small set of patterns that match one set of strings but do\nnot match any string in a second set is difficult (NP-complete, W[2]-hard when\nparameterized by the size of the pattern set, and APX-hard). We then perform a\ndetailed parameterized analysis of the problem, separating tractable and\nintractable variants. In particular we show that parameterizing by the size of\npattern set and the number of strings, and the size of the alphabet and the\nnumber of strings give FPT results, amongst others.\n", "versions": [{"version": "v1", "created": "Tue, 12 Apr 2016 04:37:35 GMT"}, {"version": "v2", "created": "Tue, 1 Nov 2016 03:31:41 GMT"}, {"version": "v3", "created": "Mon, 19 Dec 2016 00:50:32 GMT"}], "update_date": "2016-12-20", "authors_parsed": [["Lancia", "Giuseppe", ""], ["Mathieson", "Luke", ""], ["Moscato", "Pablo", ""]]}, {"id": "1604.03265", "submitter": "Hao Su", "authors": "Charles R. Qi, Hao Su, Matthias Niessner, Angela Dai, Mengyuan Yan,\n  Leonidas J. Guibas", "title": "Volumetric and Multi-View CNNs for Object Classification on 3D Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  3D shape models are becoming widely available and easier to capture, making\navailable 3D information crucial for progress in object classification. Current\nstate-of-the-art methods rely on CNNs to address this problem. Recently, we\nwitness two types of CNNs being developed: CNNs based upon volumetric\nrepresentations versus CNNs based upon multi-view representations. Empirical\nresults from these two types of CNNs exhibit a large gap, indicating that\nexisting volumetric CNN architectures and approaches are unable to fully\nexploit the power of 3D representations. In this paper, we aim to improve both\nvolumetric CNNs and multi-view CNNs according to extensive analysis of existing\napproaches. To this end, we introduce two distinct network architectures of\nvolumetric CNNs. In addition, we examine multi-view CNNs, where we introduce\nmulti-resolution filtering in 3D. Overall, we are able to outperform current\nstate-of-the-art methods for both volumetric CNNs and multi-view CNNs. We\nprovide extensive experiments designed to evaluate underlying design choices,\nthus providing a better understanding of the space of methods available for\nobject classification on 3D data.\n", "versions": [{"version": "v1", "created": "Tue, 12 Apr 2016 07:10:43 GMT"}, {"version": "v2", "created": "Fri, 29 Apr 2016 06:21:09 GMT"}], "update_date": "2016-05-02", "authors_parsed": [["Qi", "Charles R.", ""], ["Su", "Hao", ""], ["Niessner", "Matthias", ""], ["Dai", "Angela", ""], ["Yan", "Mengyuan", ""], ["Guibas", "Leonidas J.", ""]]}, {"id": "1604.03303", "submitter": "Somaiyeh Mahmoudzadeh", "authors": "S. Mahmoud Zadeh, D. Powers, K. Sammut, A. Lammas, A.M. Yazdani", "title": "Optimal Route Planning with Prioritized Task Scheduling for AUV Missions", "comments": null, "journal-ref": "IEEE International Symposium on Robotics and Intelligent Sensors,\n  pp 7-15, 2015", "doi": null, "report-no": null, "categories": "cs.RO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a solution to Autonomous Underwater Vehicles (AUVs) large\nscale route planning and task assignment joint problem. Given a set of\nconstraints (e.g., time) and a set of task priority values, the goal is to find\nthe optimal route for underwater mission that maximizes the sum of the\npriorities and minimizes the total risk percentage while meeting the given\nconstraints. Making use of the heuristic nature of genetic and swarm\nintelligence algorithms in solving NP-hard graph problems, Particle Swarm\nOptimization (PSO) and Genetic Algorithm (GA) are employed to find the optimum\nsolution, where each individual in the population is a candidate solution\n(route). To evaluate the robustness of the proposed methods, the performance of\nthe all PS and GA algorithms are examined and compared for a number of Monte\nCarlo runs. Simulation results suggest that the routes generated by both\nalgorithms are feasible and reliable enough, and applicable for underwater\nmotion planning. However, the GA-based route planner produces superior results\ncomparing to the results obtained from the PSO based route planner.\n", "versions": [{"version": "v1", "created": "Tue, 12 Apr 2016 08:45:51 GMT"}], "update_date": "2016-12-06", "authors_parsed": [["Zadeh", "S. Mahmoud", ""], ["Powers", "D.", ""], ["Sammut", "K.", ""], ["Lammas", "A.", ""], ["Yazdani", "A. M.", ""]]}, {"id": "1604.03318", "submitter": "Sazid Zaman Khan", "authors": "A.B.M. Shamsuzzaman Sadi, Towfique Anam, Mohamed Abdirazak, Abdillahi\n  Hasan Adnan, Sazid Zaman Khan, Mohamed Mahmudur Rahman, Ghassan Samara", "title": "Applying Ontological Modeling on Quranic Nature Domain", "comments": "2016 7th International Conference on Information and Communication\n  Systems (ICICS)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The holy Quran is the holy book of the Muslims. It contains information about\nmany domains. Often people search for particular concepts of holy Quran based\non the relations among concepts. An ontological modeling of holy Quran can be\nuseful in such a scenario. In this paper, we have modeled nature related\nconcepts of holy Quran using OWL (Web Ontology Language) / RDF (Resource\nDescription Framework). Our methodology involves identifying nature related\nconcepts mentioned in holy Quran and identifying relations among those\nconcepts. These concepts and relations are represented as classes/instances and\nproperties of an OWL ontology. Later, in the result section it is shown that,\nusing the Ontological model, SPARQL queries can retrieve verses and concepts of\ninterest. Thus, this modeling helps semantic search and query on the holy\nQuran. In this work, we have used English translation of the holy Quran by\nSahih International, Protege OWL Editor and for querying we have used SPARQL.\n", "versions": [{"version": "v1", "created": "Tue, 12 Apr 2016 09:27:00 GMT"}], "update_date": "2016-04-13", "authors_parsed": [["Sadi", "A. B. M. Shamsuzzaman", ""], ["Anam", "Towfique", ""], ["Abdirazak", "Mohamed", ""], ["Adnan", "Abdillahi Hasan", ""], ["Khan", "Sazid Zaman", ""], ["Rahman", "Mohamed Mahmudur", ""], ["Samara", "Ghassan", ""]]}, {"id": "1604.03458", "submitter": "Jakub Mare\\v{c}ek", "authors": "Jonathan Epperlein and Jakub Marecek", "title": "Resource Allocation with Population Dynamics", "comments": null, "journal-ref": null, "doi": "10.1109/ALLERTON.2017.8262886", "report-no": null, "categories": "math.OC cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many analyses of resource-allocation problems employ simplistic models of the\npopulation. Using the example of a resource-allocation problem of Marecek et\nal. [arXiv:1406.7639], we introduce rather a general behavioural model, where\nthe evolution of a heterogeneous population of agents is governed by a Markov\nchain. Still, we are able to show that the distribution of agents across\nresources converges in distribution, for suitable means of information\nprovision, under certain assumptions. The model and proof techniques may have\nwider applicability.\n", "versions": [{"version": "v1", "created": "Tue, 12 Apr 2016 15:53:25 GMT"}], "update_date": "2018-02-20", "authors_parsed": [["Epperlein", "Jonathan", ""], ["Marecek", "Jakub", ""]]}, {"id": "1604.03468", "submitter": "Caelan Garrett", "authors": "Caelan Reed Garrett, Tomas Lozano-Perez, and Leslie Pack Kaelbling", "title": "Backward-Forward Search for Manipulation Planning", "comments": "8 pages in IEEE/RSJ International Conference on Intelligent Robots\n  and Systems (IROS), 2015", "journal-ref": null, "doi": "10.1109/IROS.2015.7354287", "report-no": null, "categories": "cs.RO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we address planning problems in high-dimensional hybrid\nconfiguration spaces, with a particular focus on manipulation planning problems\ninvolving many objects. We present the hybrid backward-forward (HBF) planning\nalgorithm that uses a backward identification of constraints to direct the\nsampling of the infinite action space in a forward search from the initial\nstate towards a goal configuration. The resulting planner is probabilistically\ncomplete and can effectively construct long manipulation plans requiring both\nprehensile and nonprehensile actions in cluttered environments.\n", "versions": [{"version": "v1", "created": "Tue, 12 Apr 2016 16:22:29 GMT"}], "update_date": "2016-11-18", "authors_parsed": [["Garrett", "Caelan Reed", ""], ["Lozano-Perez", "Tomas", ""], ["Kaelbling", "Leslie Pack", ""]]}, {"id": "1604.03526", "submitter": "Suren Kumar", "authors": "Suren Kumar, Vikas Dhiman, Madan Ravi Ganesh, Jason J. Corso", "title": "Spatiotemporal Articulated Models for Dynamic SLAM", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an online spatiotemporal articulation model estimation framework\nthat estimates both articulated structure as well as a temporal prediction\nmodel solely using passive observations. The resulting model can predict future\nmo- tions of an articulated object with high confidence because of the spatial\nand temporal structure. We demonstrate the effectiveness of the predictive\nmodel by incorporating it within a standard simultaneous localization and\nmapping (SLAM) pipeline for mapping and robot localization in previously\nunexplored dynamic environments. Our method is able to localize the robot and\nmap a dynamic scene by explaining the observed motion in the world. We\ndemonstrate the effectiveness of the proposed framework for both simulated and\nreal-world dynamic environments.\n", "versions": [{"version": "v1", "created": "Tue, 12 Apr 2016 19:00:48 GMT"}], "update_date": "2016-04-13", "authors_parsed": [["Kumar", "Suren", ""], ["Dhiman", "Vikas", ""], ["Ganesh", "Madan Ravi", ""], ["Corso", "Jason J.", ""]]}, {"id": "1604.03632", "submitter": "Nicholas Mattei", "authors": "Haris Aziz, Omer Lev, Nicholas Mattei, Jeffrey S. Rosenschein, and\n  Toby Walsh", "title": "Strategyproof Peer Selection using Randomization, Partitioning, and\n  Apportionment", "comments": "1 Figure, Source Code available at\n  https://github.com/nmattei/peerselection", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Peer reviews, evaluations, and selections are a fundamental aspect of modern\nscience. Funding bodies the world over employ experts to review and select the\nbest proposals from those submitted for funding. The problem of peer selection,\nhowever, is much more general: a professional society may want to give a subset\nof its members awards based on the opinions of all members; an instructor for a\nMassive Open Online Course (MOOC) or an online course may want to crowdsource\ngrading; or a marketing company may select ideas from group brainstorming\nsessions based on peer evaluation.\n  We make three fundamental contributions to the study of peer selection, a\nspecific type of group decision-making problem, studied in computer science,\neconomics, and political science. First, we propose a novel mechanism that is\nstrategyproof, i.e., agents cannot benefit by reporting insincere valuations.\nSecond, we demonstrate the effectiveness of our mechanism by a comprehensive\nsimulation-based comparison with a suite of mechanisms found in the literature.\nFinally, our mechanism employs a randomized rounding technique that is of\nindependent interest, as it solves the apportionment problem that arises in\nvarious settings where discrete resources such as parliamentary representation\nslots need to be divided proportionally.\n", "versions": [{"version": "v1", "created": "Wed, 13 Apr 2016 02:28:15 GMT"}, {"version": "v2", "created": "Fri, 29 Sep 2017 13:44:12 GMT"}, {"version": "v3", "created": "Thu, 25 Apr 2019 20:14:19 GMT"}, {"version": "v4", "created": "Tue, 30 Apr 2019 17:53:38 GMT"}], "update_date": "2019-05-01", "authors_parsed": [["Aziz", "Haris", ""], ["Lev", "Omer", ""], ["Mattei", "Nicholas", ""], ["Rosenschein", "Jeffrey S.", ""], ["Walsh", "Toby", ""]]}, {"id": "1604.03655", "submitter": "Haris Aziz", "authors": "Haris Aziz and Simon Mackenzie", "title": "A Discrete and Bounded Envy-Free Cake Cutting Protocol for Any Number of\n  Agents", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.AI cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the well-studied cake cutting problem in which the goal is to\nfind an envy-free allocation based on queries from $n$ agents. The problem has\nreceived attention in computer science, mathematics, and economics. It has been\na major open problem whether there exists a discrete and bounded envy-free\nprotocol. We resolve the problem by proposing a discrete and bounded envy-free\nprotocol for any number of agents. The maximum number of queries required by\nthe protocol is $n^{n^{n^{n^{n^n}}}}$. We additionally show that even if we do\nnot run our protocol to completion, it can find in at most $n^3{(n^2)}^n$\nqueries a partial allocation of the cake that achieves proportionality (each\nagent gets at least $1/n$ of the value of the whole cake) and envy-freeness.\nFinally we show that an envy-free partial allocation can be computed in at most\n$n^3{(n^2)}^n$ queries such that each agent gets a connected piece that gives\nthe agent at least $1/(3n)$ of the value of the whole cake.\n", "versions": [{"version": "v1", "created": "Wed, 13 Apr 2016 05:06:29 GMT"}, {"version": "v10", "created": "Wed, 5 Oct 2016 22:30:52 GMT"}, {"version": "v11", "created": "Tue, 27 Dec 2016 23:00:21 GMT"}, {"version": "v12", "created": "Sun, 27 Aug 2017 08:35:26 GMT"}, {"version": "v2", "created": "Thu, 14 Apr 2016 02:50:59 GMT"}, {"version": "v3", "created": "Wed, 27 Apr 2016 21:45:28 GMT"}, {"version": "v4", "created": "Sat, 7 May 2016 13:57:27 GMT"}, {"version": "v5", "created": "Tue, 7 Jun 2016 11:44:24 GMT"}, {"version": "v6", "created": "Mon, 25 Jul 2016 12:36:58 GMT"}, {"version": "v7", "created": "Fri, 29 Jul 2016 22:15:32 GMT"}, {"version": "v8", "created": "Sun, 28 Aug 2016 23:25:26 GMT"}, {"version": "v9", "created": "Thu, 15 Sep 2016 11:07:30 GMT"}], "update_date": "2017-08-29", "authors_parsed": [["Aziz", "Haris", ""], ["Mackenzie", "Simon", ""]]}, {"id": "1604.03692", "submitter": "Tianmin Shu", "authors": "Tianmin Shu, M. S. Ryoo and Song-Chun Zhu", "title": "Learning Social Affordance for Human-Robot Interaction", "comments": "International Joint Conference on Artificial Intelligence (IJCAI),\n  2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present an approach for robot learning of social affordance\nfrom human activity videos. We consider the problem in the context of\nhuman-robot interaction: Our approach learns structural representations of\nhuman-human (and human-object-human) interactions, describing how body-parts of\neach agent move with respect to each other and what spatial relations they\nshould maintain to complete each sub-event (i.e., sub-goal). This enables the\nrobot to infer its own movement in reaction to the human body motion, allowing\nit to naturally replicate such interactions.\n  We introduce the representation of social affordance and propose a generative\nmodel for its weakly supervised learning from human demonstration videos. Our\napproach discovers critical steps (i.e., latent sub-events) in an interaction\nand the typical motion associated with them, learning what body-parts should be\ninvolved and how. The experimental results demonstrate that our Markov Chain\nMonte Carlo (MCMC) based learning algorithm automatically discovers\nsemantically meaningful interactive affordance from RGB-D videos, which allows\nus to generate appropriate full body motion for an agent.\n", "versions": [{"version": "v1", "created": "Wed, 13 Apr 2016 08:40:06 GMT"}, {"version": "v2", "created": "Wed, 20 Apr 2016 21:02:02 GMT"}], "update_date": "2016-04-22", "authors_parsed": [["Shu", "Tianmin", ""], ["Ryoo", "M. S.", ""], ["Zhu", "Song-Chun", ""]]}, {"id": "1604.03793", "submitter": "Florian Lonsing", "authors": "Tomas Balyo and Florian Lonsing", "title": "HordeQBF: A Modular and Massively Parallel QBF Solver", "comments": "camera-ready version, 6-page tool paper, to appear in the proceedings\n  of SAT 2016, LNCS, Springer", "journal-ref": null, "doi": "10.1007/978-3-319-40970-2_33", "report-no": null, "categories": "cs.LO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recently developed massively parallel satisfiability (SAT) solver\nHordeSAT was designed in a modular way to allow the integration of any\nsequential CDCL-based SAT solver in its core. We integrated the QCDCL-based\nquantified Boolean formula (QBF) solver DepQBF in HordeSAT to obtain a\nmassively parallel QBF solver---HordeQBF. In this paper we describe the details\nof this integration and report on results of the experimental evaluation of\nHordeQBF's performance. HordeQBF achieves superlinear average and median\nspeedup on the hard application instances of the 2014 QBF Gallery.\n", "versions": [{"version": "v1", "created": "Wed, 13 Apr 2016 14:21:34 GMT"}], "update_date": "2016-06-15", "authors_parsed": [["Balyo", "Tomas", ""], ["Lonsing", "Florian", ""]]}, {"id": "1604.03853", "submitter": "Mehmet Basbug", "authors": "Mehmet E. Basbug, Barbara E. Engelhardt", "title": "Hierarchical Compound Poisson Factorization", "comments": "Will appear on Proceedings of the 33 rd International Conference on\n  Machine Learning, New York, NY, USA, 2016. JMLR: W&CP volume 48", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Non-negative matrix factorization models based on a hierarchical\nGamma-Poisson structure capture user and item behavior effectively in extremely\nsparse data sets, making them the ideal choice for collaborative filtering\napplications. Hierarchical Poisson factorization (HPF) in particular has proved\nsuccessful for scalable recommendation systems with extreme sparsity. HPF,\nhowever, suffers from a tight coupling of sparsity model (absence of a rating)\nand response model (the value of the rating), which limits the expressiveness\nof the latter. Here, we introduce hierarchical compound Poisson factorization\n(HCPF) that has the favorable Gamma-Poisson structure and scalability of HPF to\nhigh-dimensional extremely sparse matrices. More importantly, HCPF decouples\nthe sparsity model from the response model, allowing us to choose the most\nsuitable distribution for the response. HCPF can capture binary, non-negative\ndiscrete, non-negative continuous, and zero-inflated continuous responses. We\ncompare HCPF with HPF on nine discrete and three continuous data sets and\nconclude that HCPF captures the relationship between sparsity and response\nbetter than HPF.\n", "versions": [{"version": "v1", "created": "Wed, 13 Apr 2016 16:12:01 GMT"}, {"version": "v2", "created": "Thu, 26 May 2016 11:09:19 GMT"}], "update_date": "2016-05-27", "authors_parsed": [["Basbug", "Mehmet E.", ""], ["Engelhardt", "Barbara E.", ""]]}, {"id": "1604.03901", "submitter": "Weifeng Chen", "authors": "Weifeng Chen, Zhao Fu, Dawei Yang, Jia Deng", "title": "Single-Image Depth Perception in the Wild", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies single-image depth perception in the wild, i.e.,\nrecovering depth from a single image taken in unconstrained settings. We\nintroduce a new dataset \"Depth in the Wild\" consisting of images in the wild\nannotated with relative depth between pairs of random points. We also propose a\nnew algorithm that learns to estimate metric depth using annotations of\nrelative depth. Compared to the state of the art, our algorithm is simpler and\nperforms better. Experiments show that our algorithm, combined with existing\nRGB-D data and our new relative depth annotations, significantly improves\nsingle-image depth perception in the wild.\n", "versions": [{"version": "v1", "created": "Wed, 13 Apr 2016 18:19:35 GMT"}, {"version": "v2", "created": "Fri, 6 Jan 2017 16:05:35 GMT"}], "update_date": "2017-01-09", "authors_parsed": [["Chen", "Weifeng", ""], ["Fu", "Zhao", ""], ["Yang", "Dawei", ""], ["Deng", "Jia", ""]]}, {"id": "1604.03912", "submitter": "Michael Herman", "authors": "Michael Herman, Tobias Gindele, J\\\"org Wagner, Felix Schmitt, Wolfram\n  Burgard", "title": "Inverse Reinforcement Learning with Simultaneous Estimation of Rewards\n  and Dynamics", "comments": "accepted to appear in AISTATS 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inverse Reinforcement Learning (IRL) describes the problem of learning an\nunknown reward function of a Markov Decision Process (MDP) from observed\nbehavior of an agent. Since the agent's behavior originates in its policy and\nMDP policies depend on both the stochastic system dynamics as well as the\nreward function, the solution of the inverse problem is significantly\ninfluenced by both. Current IRL approaches assume that if the transition model\nis unknown, additional samples from the system's dynamics are accessible, or\nthe observed behavior provides enough samples of the system's dynamics to solve\nthe inverse problem accurately. These assumptions are often not satisfied. To\novercome this, we present a gradient-based IRL approach that simultaneously\nestimates the system's dynamics. By solving the combined optimization problem,\nour approach takes into account the bias of the demonstrations, which stems\nfrom the generating policy. The evaluation on a synthetic MDP and a transfer\nlearning task shows improvements regarding the sample efficiency as well as the\naccuracy of the estimated reward functions and transition models.\n", "versions": [{"version": "v1", "created": "Wed, 13 Apr 2016 19:06:41 GMT"}], "update_date": "2016-04-14", "authors_parsed": [["Herman", "Michael", ""], ["Gindele", "Tobias", ""], ["Wagner", "J\u00f6rg", ""], ["Schmitt", "Felix", ""], ["Burgard", "Wolfram", ""]]}, {"id": "1604.03968", "submitter": "Francis Ferraro", "authors": "Ting-Hao (Kenneth) Huang, Francis Ferraro, Nasrin Mostafazadeh, Ishan\n  Misra, Aishwarya Agrawal, Jacob Devlin, Ross Girshick, Xiaodong He, Pushmeet\n  Kohli, Dhruv Batra, C. Lawrence Zitnick, Devi Parikh, Lucy Vanderwende,\n  Michel Galley, Margaret Mitchell", "title": "Visual Storytelling", "comments": "to appear in NAACL 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce the first dataset for sequential vision-to-language, and explore\nhow this data may be used for the task of visual storytelling. The first\nrelease of this dataset, SIND v.1, includes 81,743 unique photos in 20,211\nsequences, aligned to both descriptive (caption) and story language. We\nestablish several strong baselines for the storytelling task, and motivate an\nautomatic metric to benchmark progress. Modelling concrete description as well\nas figurative and social language, as provided in this dataset and the\nstorytelling task, has the potential to move artificial intelligence from basic\nunderstandings of typical visual scenes towards more and more human-like\nunderstanding of grounded event structure and subjective expression.\n", "versions": [{"version": "v1", "created": "Wed, 13 Apr 2016 20:27:43 GMT"}], "update_date": "2016-04-15", "authors_parsed": [["Ting-Hao", "", "", "Kenneth"], ["Huang", "", ""], ["Ferraro", "Francis", ""], ["Mostafazadeh", "Nasrin", ""], ["Misra", "Ishan", ""], ["Agrawal", "Aishwarya", ""], ["Devlin", "Jacob", ""], ["Girshick", "Ross", ""], ["He", "Xiaodong", ""], ["Kohli", "Pushmeet", ""], ["Batra", "Dhruv", ""], ["Zitnick", "C. Lawrence", ""], ["Parikh", "Devi", ""], ["Vanderwende", "Lucy", ""], ["Galley", "Michel", ""], ["Mitchell", "Margaret", ""]]}, {"id": "1604.04096", "submitter": "Mauro Vallati", "authors": "Valerio Velardo and Mauro Vallati", "title": "A General Framework for Describing Creative Agents", "comments": "14 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computational creativity is a subfield of AI focused on developing and\nstudying creative systems. Few academic studies analysing the behaviour of\ncreative agents from a theoretical viewpoint have been proposed. The proposed\nframeworks are vague and hard to exploit; moreover, such works are focused on a\nnotion of creativity tailored for humans.\n  In this paper we introduce General Creativity, which extends that traditional\nnotion. General Creativity provides the basis for a formalised theoretical\nframework, that allows one to univocally describe any creative agent, and their\nbehaviour within societies of creative systems. Given the growing number of AI\ncreative systems developed over recent years, it is of fundamental importance\nto understand how they could influence each other as well as how to gauge their\nimpact on human society. In particular, in this paper we exploit the proposed\nframework for (i) identifying different forms of creativity; (ii) describing\nsome typical creative agents behaviour, and (iii) analysing the dynamics of\nsocieties in which both human and non-human creative systems coexist.\n", "versions": [{"version": "v1", "created": "Thu, 14 Apr 2016 10:13:43 GMT"}], "update_date": "2016-04-15", "authors_parsed": [["Velardo", "Valerio", ""], ["Vallati", "Mauro", ""]]}, {"id": "1604.04138", "submitter": "Xin-She Yang", "authors": "Eneko Osaba, Xin-She Yang, Fernando Diaz, Pedro Lopez-Garcia, Roberto\n  Carballedo", "title": "An Improved Discrete Bat Algorithm for Symmetric and Asymmetric\n  Traveling Salesman Problems", "comments": "1 figure, 8 tables", "journal-ref": "Engineering Applications of Artificial Intelligence, 48 (1), 59-71\n  (2016)", "doi": "10.1016/j.engappai.2015.10.006", "report-no": null, "categories": "cs.NE cs.AI math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bat algorithm is a population metaheuristic proposed in 2010 which is based\non the echolocation or bio-sonar characteristics of microbats. Since its first\nimplementation, the bat algorithm has been used in a wide range of fields. In\nthis paper, we present a discrete version of the bat algorithm to solve the\nwell-known symmetric and asymmetric traveling salesman problems. In addition,\nwe propose an improvement in the basic structure of the classic bat algorithm.\nTo prove that our proposal is a promising approximation method, we have\ncompared its performance in 37 instances with the results obtained by five\ndifferent techniques: evolutionary simulated annealing, genetic algorithm, an\nisland based distributed genetic algorithm, a discrete firefly algorithm and an\nimperialist competitive algorithm. In order to obtain fair and rigorous\ncomparisons, we have conducted three different statistical tests along the\npaper: the Student's $t$-test, the Holm's test, and the Friedman test. We have\nalso compared the convergence behaviour shown by our proposal with the ones\nshown by the evolutionary simulated annealing, and the discrete firefly\nalgorithm. The experimentation carried out in this study has shown that the\npresented improved bat algorithm outperforms significantly all the other\nalternatives in most of the cases.\n", "versions": [{"version": "v1", "created": "Thu, 14 Apr 2016 12:52:20 GMT"}], "update_date": "2016-04-15", "authors_parsed": [["Osaba", "Eneko", ""], ["Yang", "Xin-She", ""], ["Diaz", "Fernando", ""], ["Lopez-Garcia", "Pedro", ""], ["Carballedo", "Roberto", ""]]}, {"id": "1604.04146", "submitter": "Xin-She Yang", "authors": "E. Osaba, Xin-She Yang, F. Diaz, E. Onieva, A. D. Masegosa, A.\n  Perallos", "title": "A Discrete Firefly Algorithm to Solve a Rich Vehicle Routing Problem\n  Modelling a Newspaper Distribution System with Recycling Policy", "comments": "7 tables and 4 figures", "journal-ref": null, "doi": "10.1007/s00500-016-2114-1", "report-no": null, "categories": "cs.NE cs.AI math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A real-world newspaper distribution problem with recycling policy is tackled\nin this work. In order to meet all the complex restrictions contained in such a\nproblem, it has been modeled as a rich vehicle routing problem, which can be\nmore specifically considered as an asymmetric and clustered vehicle routing\nproblem with simultaneous pickup and deliveries, variable costs and forbidden\npaths (AC-VRP-SPDVCFP). This is the first study of such a problem in the\nliterature. For this reason, a benchmark composed by 15 instances has been also\nproposed. In the design of this benchmark, real geographical positions have\nbeen used, located in the province of Bizkaia, Spain. For the proper treatment\nof this AC-VRP-SPDVCFP, a discrete firefly algorithm (DFA) has been developed.\nThis application is the first application of the firefly algorithm to any rich\nvehicle routing problem. To prove that the proposed DFA is a promising\ntechnique, its performance has been compared with two other well-known\ntechniques: an evolutionary algorithm and an evolutionary simulated annealing.\nOur results have shown that the DFA has outperformed these two classic\nmeta-heuristics.\n", "versions": [{"version": "v1", "created": "Thu, 14 Apr 2016 13:25:42 GMT"}], "update_date": "2016-04-15", "authors_parsed": [["Osaba", "E.", ""], ["Yang", "Xin-She", ""], ["Diaz", "F.", ""], ["Onieva", "E.", ""], ["Masegosa", "A. D.", ""], ["Perallos", "A.", ""]]}, {"id": "1604.04169", "submitter": "Mayank Baranwal", "authors": "Mayank Baranwal, Brian Roehl and Srinivasa M. Salapaka", "title": "A Deterministic Annealing Approach to the Multiple Traveling Salesmen\n  and Related Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a novel and efficient heuristic framework for\napproximating the solutions to the multiple traveling salesmen problem (m-TSP)\nand other variants on the TSP. The approach adopted in this paper is an\nextension of the Maximum-Entropy-Principle (MEP) and the Deterministic\nAnnealing (DA) algorithm. The framework is presented as a general tool that can\nbe suitably adapted to a number of variants on the basic TSP. Additionally,\nunlike most other heuristics for the TSP, the framework presented in this paper\nis independent of the edges defined between any two pairs of nodes. This makes\nthe algorithm particularly suited for variants such as the close-enough\ntraveling salesman problem (CETSP) which are challenging due to added\ncomputational complexity. The examples presented in this paper illustrate the\neffectiveness of this new framework for use in TSP and many variants thereof.\n", "versions": [{"version": "v1", "created": "Thu, 14 Apr 2016 14:39:56 GMT"}], "update_date": "2016-04-15", "authors_parsed": [["Baranwal", "Mayank", ""], ["Roehl", "Brian", ""], ["Salapaka", "Srinivasa M.", ""]]}, {"id": "1604.04315", "submitter": "Carissa Schoenick", "authors": "Carissa Schoenick, Peter Clark, Oyvind Tafjord, Peter Turney, Oren\n  Etzioni", "title": "Moving Beyond the Turing Test with the Allen AI Science Challenge", "comments": "7 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given recent successes in AI (e.g., AlphaGo's victory against Lee Sedol in\nthe game of GO), it's become increasingly important to assess: how close are AI\nsystems to human-level intelligence? This paper describes the Allen AI Science\nChallenge---an approach towards that goal which led to a unique Kaggle\nCompetition, its results, the lessons learned, and our next steps.\n", "versions": [{"version": "v1", "created": "Thu, 14 Apr 2016 22:43:30 GMT"}, {"version": "v2", "created": "Tue, 17 May 2016 18:47:00 GMT"}, {"version": "v3", "created": "Wed, 22 Feb 2017 20:02:46 GMT"}], "update_date": "2017-02-24", "authors_parsed": [["Schoenick", "Carissa", ""], ["Clark", "Peter", ""], ["Tafjord", "Oyvind", ""], ["Turney", "Peter", ""], ["Etzioni", "Oren", ""]]}, {"id": "1604.04358", "submitter": "Lili Mou", "authors": "Xiang Li, Lili Mou, Rui Yan, Ming Zhang", "title": "StalemateBreaker: A Proactive Content-Introducing Approach to Automatic\n  Human-Computer Conversation", "comments": "Accepted by IJCAI-16", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing open-domain human-computer conversation systems are typically\npassive: they either synthesize or retrieve a reply provided a human-issued\nutterance. It is generally presumed that humans should take the role to lead\nthe conversation and introduce new content when a stalemate occurs, and that\nthe computer only needs to \"respond.\" In this paper, we propose\nStalemateBreaker, a conversation system that can proactively introduce new\ncontent when appropriate. We design a pipeline to determine when, what, and how\nto introduce new content during human-computer conversation. We further propose\na novel reranking algorithm Bi-PageRank-HITS to enable rich interaction between\nconversation context and candidate replies. Experiments show that both the\ncontent-introducing approach and the reranking algorithm are effective. Our\nfull StalemateBreaker model outperforms a state-of-the-practice conversation\nsystem by +14.4% p@1 when a stalemate occurs.\n", "versions": [{"version": "v1", "created": "Fri, 15 Apr 2016 05:51:29 GMT"}], "update_date": "2016-04-18", "authors_parsed": [["Li", "Xiang", ""], ["Mou", "Lili", ""], ["Yan", "Rui", ""], ["Zhang", "Ming", ""]]}, {"id": "1604.04359", "submitter": "Palash Dey", "authors": "Palash Dey, Neeldhara Misra, Y. Narahari", "title": "Complexity of Manipulation with Partial Information in Voting", "comments": "Appeared in IJCAI 2016. Fixed some typos", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI cs.CC cs.CY cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Coalitional Manipulation problem has been studied extensively in the\nliterature for many voting rules. However, most studies have focused on the\ncomplete information setting, wherein the manipulators know the votes of the\nnon-manipulators. While this assumption is reasonable for purposes of showing\nintractability, it is unrealistic for algorithmic considerations. In most\nreal-world scenarios, it is impractical for the manipulators to have accurate\nknowledge of all the other votes. In this paper, we investigate manipulation\nwith incomplete information. In our framework, the manipulators know a partial\norder for each voter that is consistent with the true preference of that voter.\nIn this setting, we formulate three natural computational notions of\nmanipulation, namely weak, opportunistic, and strong manipulation. We say that\nan extension of a partial order is if there exists a manipulative vote for that\nextension.\n  1. Weak Manipulation (WM): the manipulators seek to vote in a way that makes\ntheir preferred candidate win in at least one extension of the partial votes of\nthe non-manipulators.\n  2. Opportunistic Manipulation (OM): the manipulators seek to vote in a way\nthat makes their preferred candidate win in every viable extension of the\npartial votes of the non-manipulators.\n  3. Strong Manipulation (SM): the manipulators seek to vote in a way that\nmakes their preferred candidate win in every extension of the partial votes of\nthe non-manipulators.\n  We consider several scenarios for which the traditional manipulation problems\nare easy (for instance, Borda with a single manipulator). For many of them, the\ncorresponding manipulative questions that we propose turn out to be\ncomputationally intractable. Our hardness results often hold even when very\nlittle information is missing, or in other words, even when the instances are\nquite close to the complete information setting.\n", "versions": [{"version": "v1", "created": "Fri, 15 Apr 2016 05:55:07 GMT"}, {"version": "v2", "created": "Thu, 13 Jul 2017 03:30:09 GMT"}], "update_date": "2017-07-14", "authors_parsed": [["Dey", "Palash", ""], ["Misra", "Neeldhara", ""], ["Narahari", "Y.", ""]]}, {"id": "1604.04378", "submitter": "Shengxian Wan", "authors": "Shengxian Wan, Yanyan Lan, Jun Xu, Jiafeng Guo, Liang Pang, Xueqi\n  Cheng", "title": "Match-SRNN: Modeling the Recursive Matching Structure with Spatial RNN", "comments": "Accepted by IJCAI-2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Semantic matching, which aims to determine the matching degree between two\ntexts, is a fundamental problem for many NLP applications. Recently, deep\nlearning approach has been applied to this problem and significant improvements\nhave been achieved. In this paper, we propose to view the generation of the\nglobal interaction between two texts as a recursive process: i.e. the\ninteraction of two texts at each position is a composition of the interactions\nbetween their prefixes as well as the word level interaction at the current\nposition. Based on this idea, we propose a novel deep architecture, namely\nMatch-SRNN, to model the recursive matching structure. Firstly, a tensor is\nconstructed to capture the word level interactions. Then a spatial RNN is\napplied to integrate the local interactions recursively, with importance\ndetermined by four types of gates. Finally, the matching score is calculated\nbased on the global interaction. We show that, after degenerated to the exact\nmatching scenario, Match-SRNN can approximate the dynamic programming process\nof longest common subsequence. Thus, there exists a clear interpretation for\nMatch-SRNN. Our experiments on two semantic matching tasks showed the\neffectiveness of Match-SRNN, and its ability of visualizing the learned\nmatching structure.\n", "versions": [{"version": "v1", "created": "Fri, 15 Apr 2016 07:23:53 GMT"}], "update_date": "2016-04-20", "authors_parsed": [["Wan", "Shengxian", ""], ["Lan", "Yanyan", ""], ["Xu", "Jun", ""], ["Guo", "Jiafeng", ""], ["Pang", "Liang", ""], ["Cheng", "Xueqi", ""]]}, {"id": "1604.04403", "submitter": "Palash Dey", "authors": "Palash Dey and Neeldhara Misra", "title": "Elicitation for Preferences Single Peaked on Trees", "comments": "To appear in IJCAI 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.AI cs.CC cs.DS cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In multiagent systems, we often have a set of agents each of which have a\npreference ordering over a set of items and one would like to know these\npreference orderings for various tasks, for example, data analysis, preference\naggregation, voting etc. However, we often have a large number of items which\nmakes it impractical to ask the agents for their complete preference ordering.\nIn such scenarios, we usually elicit these agents' preferences by asking (a\nhopefully small number of) comparison queries --- asking an agent to compare\ntwo items. Prior works on preference elicitation focus on unrestricted domain\nand the domain of single peaked preferences and show that the preferences in\nsingle peaked domain can be elicited by much less number of queries compared to\nunrestricted domain. We extend this line of research and study preference\nelicitation for single peaked preferences on trees which is a strict superset\nof the domain of single peaked preferences. We show that the query complexity\ncrucially depends on the number of leaves, the path cover number, and the\ndistance from path of the underlying single peaked tree, whereas the other\nnatural parameters like maximum degree, diameter, pathwidth do not play any\ndirect role in determining query complexity. We then investigate the query\ncomplexity for finding a weak Condorcet winner for preferences single peaked on\na tree and show that this task has much less query complexity than preference\nelicitation. Here again we observe that the number of leaves in the underlying\nsingle peaked tree and the path cover number of the tree influence the query\ncomplexity of the problem.\n", "versions": [{"version": "v1", "created": "Fri, 15 Apr 2016 08:40:39 GMT"}], "update_date": "2016-04-18", "authors_parsed": [["Dey", "Palash", ""], ["Misra", "Neeldhara", ""]]}, {"id": "1604.04506", "submitter": "Paolo Pareti Mr.", "authors": "Paolo Pareti, Benoit Testu, Ryutaro Ichise, Ewan Klein, Adam Barker", "title": "Integrating Know-How into the Linked Data Cloud", "comments": "The 19th International Conference on Knowledge Engineering and\n  Knowledge Management (EKAW 2014), 24-28 November 2014, Link\\\"oping, Sweden", "journal-ref": "Knowledge Engineering and Knowledge Management, volume 8876 of\n  Lecture Notes in Computer Science, pages 385-396. Springer International\n  Publishing (2014)", "doi": "10.1007/978-3-319-13704-9_30", "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper presents the first framework for integrating procedural knowledge,\nor \"know-how\", into the Linked Data Cloud. Know-how available on the Web, such\nas step-by-step instructions, is largely unstructured and isolated from other\nsources of online knowledge. To overcome these limitations, we propose\nextending to procedural knowledge the benefits that Linked Data has already\nbrought to representing, retrieving and reusing declarative knowledge. We\ndescribe a framework for representing generic know-how as Linked Data and for\nautomatically acquiring this representation from existing resources on the Web.\nThis system also allows the automatic generation of links between different\nknow-how resources, and between those resources and other online knowledge\nbases, such as DBpedia. We discuss the results of applying this framework to a\nreal-world scenario and we show how it outperforms existing manual\ncommunity-driven integration efforts.\n", "versions": [{"version": "v1", "created": "Fri, 15 Apr 2016 13:52:12 GMT"}], "update_date": "2016-04-18", "authors_parsed": [["Pareti", "Paolo", ""], ["Testu", "Benoit", ""], ["Ichise", "Ryutaro", ""], ["Klein", "Ewan", ""], ["Barker", "Adam", ""]]}, {"id": "1604.04558", "submitter": "Jyothi Korra", "authors": "Jinju Joby and Jyothi Korra", "title": "Accessing accurate documents by mining auxiliary document information", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Earlier techniques of text mining included algorithms like k-means, Naive\nBayes, SVM which classify and cluster the text document for mining relevant\ninformation about the documents. The need for improving the mining techniques\nhas us searching for techniques using the available algorithms. This paper\nproposes one technique which uses the auxiliary information that is present\ninside the text documents to improve the mining. This auxiliary information can\nbe a description to the content. This information can be either useful or\ncompletely useless for mining. The user should assess the worth of the\nauxiliary information before considering this technique for text mining. In\nthis paper, a combination of classical clustering algorithms is used to mine\nthe datasets. The algorithm runs in two stages which carry out mining at\ndifferent levels of abstraction. The clustered documents would then be\nclassified based on the necessary groups. The proposed technique is aimed at\nimproved results of document clustering.\n", "versions": [{"version": "v1", "created": "Fri, 15 Apr 2016 16:27:38 GMT"}], "update_date": "2016-05-10", "authors_parsed": [["Joby", "Jinju", ""], ["Korra", "Jyothi", ""]]}, {"id": "1604.04562", "submitter": "Tsung-Hsien Wen", "authors": "Tsung-Hsien Wen, David Vandyke, Nikola Mrksic, Milica Gasic, Lina M.\n  Rojas-Barahona, Pei-Hao Su, Stefan Ultes, Steve Young", "title": "A Network-based End-to-End Trainable Task-oriented Dialogue System", "comments": "published at EACL 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Teaching machines to accomplish tasks by conversing naturally with humans is\nchallenging. Currently, developing task-oriented dialogue systems requires\ncreating multiple components and typically this involves either a large amount\nof handcrafting, or acquiring costly labelled datasets to solve a statistical\nlearning problem for each component. In this work we introduce a neural\nnetwork-based text-in, text-out end-to-end trainable goal-oriented dialogue\nsystem along with a new way of collecting dialogue data based on a novel\npipe-lined Wizard-of-Oz framework. This approach allows us to develop dialogue\nsystems easily and without making too many assumptions about the task at hand.\nThe results show that the model can converse with human subjects naturally\nwhilst helping them to accomplish tasks in a restaurant search domain.\n", "versions": [{"version": "v1", "created": "Fri, 15 Apr 2016 16:40:49 GMT"}, {"version": "v2", "created": "Fri, 20 May 2016 14:03:58 GMT"}, {"version": "v3", "created": "Mon, 24 Apr 2017 10:55:12 GMT"}], "update_date": "2017-04-25", "authors_parsed": [["Wen", "Tsung-Hsien", ""], ["Vandyke", "David", ""], ["Mrksic", "Nikola", ""], ["Gasic", "Milica", ""], ["Rojas-Barahona", "Lina M.", ""], ["Su", "Pei-Hao", ""], ["Ultes", "Stefan", ""], ["Young", "Steve", ""]]}, {"id": "1604.04660", "submitter": "Jordi Bieger", "authors": "Kristinn R. Th\\'orisson and Jordi Bieger and Thr\\\"ostur Thorarensen\n  and J\\'ona S. Sigur{\\dh}ard\\'ottir, and Bas R. Steunebrink", "title": "Why Artificial Intelligence Needs a Task Theory --- And What It Might\n  Look Like", "comments": "accepted to the Ninth Conference on Artificial General Intelligence\n  (AGI-16)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The concept of \"task\" is at the core of artificial intelligence (AI): Tasks\nare used for training and evaluating AI systems, which are built in order to\nperform and automatize tasks we deem useful. In other fields of engineering\ntheoretical foundations allow thorough evaluation of designs by methodical\nmanipulation of well understood parameters with a known role and importance;\nthis allows an aeronautics engineer, for instance, to systematically assess the\neffects of wind speed on an airplane's performance and stability. No framework\nexists in AI that allows this kind of methodical manipulation: Performance\nresults on the few tasks in current use (cf. board games, question-answering)\ncannot be easily compared, however similar or different. The issue is even more\nacute with respect to artificial *general* intelligence systems, which must\nhandle unanticipated tasks whose specifics cannot be known beforehand. A *task\ntheory* would enable addressing tasks at the *class* level, bypassing their\nspecifics, providing the appropriate formalization and classification of tasks,\nenvironments, and their parameters, resulting in more rigorous ways of\nmeasuring, comparing, and evaluating intelligent behavior. Even modest\nimprovements in this direction would surpass the current ad-hoc nature of\nmachine learning and AI evaluation. Here we discuss the main elements of the\nargument for a task theory and present an outline of what it might look like\nfor physical tasks.\n", "versions": [{"version": "v1", "created": "Fri, 15 Apr 2016 23:36:44 GMT"}, {"version": "v2", "created": "Thu, 12 May 2016 17:16:25 GMT"}], "update_date": "2016-05-13", "authors_parsed": [["Th\u00f3risson", "Kristinn R.", ""], ["Bieger", "Jordi", ""], ["Thorarensen", "Thr\u00f6stur", ""], ["Sigur\u00f0ard\u00f3ttir", "J\u00f3na S.", ""], ["Steunebrink", "Bas R.", ""]]}, {"id": "1604.04721", "submitter": "Victor Sanchez-Anguix Dr.", "authors": "Juan M. Alberola, Elena Del Val, Victor Sanchez-Anguix, Alberto\n  Palomares and Maria Dolores Teruel", "title": "An artificial intelligence tool for heterogeneous team formation in the\n  classroom", "comments": null, "journal-ref": "Knowledge-Based Systems, 2016", "doi": "10.1016/j.knosys.2016.02.010", "report-no": null, "categories": "cs.AI cs.CY cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nowadays, there is increasing interest in the development of teamwork skills\nin the educational context. This growing interest is motivated by its\npedagogical effectiveness and the fact that, in labour contexts, enterprises\norganize their employees in teams to carry out complex projects. Despite its\ncrucial importance in the classroom and industry, there is a lack of support\nfor the team formation process. Not only do many factors influence team\nperformance, but the problem becomes exponentially costly if teams are to be\noptimized. In this article, we propose a tool whose aim it is to cover such a\ngap. It combines artificial intelligence techniques such as coalition structure\ngeneration, Bayesian learning, and Belbin's role theory to facilitate the\ngeneration of working groups in an educational context. This tool improves\ncurrent state of the art proposals in three ways: i) it takes into account the\nfeedback of other teammates in order to establish the most predominant role of\na student instead of self-perception questionnaires; ii) it handles uncertainty\nwith regard to each student's predominant team role; iii) it is iterative since\nit considers information from several interactions in order to improve the\nestimation of role assignments. We tested the performance of the proposed tool\nin an experiment involving students that took part in three different team\nactivities. The experiments suggest that the proposed tool is able to improve\ndifferent teamwork aspects such as team dynamics and student satisfaction.\n", "versions": [{"version": "v1", "created": "Sat, 16 Apr 2016 10:50:02 GMT"}], "update_date": "2016-04-19", "authors_parsed": [["Alberola", "Juan M.", ""], ["Del Val", "Elena", ""], ["Sanchez-Anguix", "Victor", ""], ["Palomares", "Alberto", ""], ["Teruel", "Maria Dolores", ""]]}, {"id": "1604.04725", "submitter": "Victor Sanchez-Anguix Dr.", "authors": "Victor Sanchez-Anguix, Reyhan Aydogan, Vicente Julian and Catholijn\n  Jonker", "title": "Unanimously acceptable agreements for negotiation teams in unpredictable\n  domains", "comments": "Electronic Commerce Research and Applications, 2014", "journal-ref": null, "doi": "10.1016/j.elerap.2014.05.002", "report-no": null, "categories": "cs.MA cs.AI cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A negotiation team is a set of agents with common and possibly also\nconflicting preferences that forms one of the parties of a negotiation. A\nnegotiation team is involved in two decision making processes simultaneously, a\nnegotiation with the opponents, and an intra-team process to decide on the\nmoves to make in the negotiation. This article focuses on negotiation team\ndecision making for circumstances that require unanimity of team decisions.\nExisting agent-based approaches only guarantee unanimity in teams negotiating\nin domains exclusively composed of predictable and compatible issues. This\narticle presents a model for negotiation teams that guarantees unanimous team\ndecisions in domains consisting of predictable and compatible, and also\nunpredictable issues. Moreover, the article explores the influence of using\nopponent, and team member models in the proposing strategies that team members\nuse. Experimental results show that the team benefits if team members employ\nBayesian learning to model their teammates' preferences.\n", "versions": [{"version": "v1", "created": "Sat, 16 Apr 2016 11:01:44 GMT"}], "update_date": "2016-04-19", "authors_parsed": [["Sanchez-Anguix", "Victor", ""], ["Aydogan", "Reyhan", ""], ["Julian", "Vicente", ""], ["Jonker", "Catholijn", ""]]}, {"id": "1604.04727", "submitter": "Victor Sanchez-Anguix Dr.", "authors": "Victor Sanchez-Anguix, Vicente Julian, Vicente Botti and Ana\n  Garcia-Fornes", "title": "Tasks for agent-based negotiation teams: Analysis, review, and\n  challenges", "comments": "Engineering Applications of Artificial Intelligence, 2013", "journal-ref": null, "doi": "10.1016/j.engappai.2013.07.006", "report-no": null, "categories": "cs.MA cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An agent-based negotiation team is a group of interdependent agents that join\ntogether as a single negotiation party due to their shared interests in the\nnegotiation at hand. The reasons to employ an agent-based negotiation team may\nvary: (i) more computation and parallelization capabilities, (ii) unite agents\nwith different expertise and skills whose joint work makes it possible to\ntackle complex negotiation domains, (iii) the necessity to represent different\nstakeholders or different preferences in the same party (e.g., organizations,\ncountries, and married couple). The topic of agent-based negotiation teams has\nbeen recently introduced in multi-agent research. Therefore, it is necessary to\nidentify good practices, challenges, and related research that may help in\nadvancing the state-of-the-art in agent-based negotiation teams. For that\nreason, in this article we review the tasks to be carried out by agent-based\nnegotiation teams. Each task is analyzed and related with current advances in\ndifferent research areas. The analysis aims to identify special challenges that\nmay arise due to the particularities of agent-based negotiation teams.\n", "versions": [{"version": "v1", "created": "Sat, 16 Apr 2016 11:37:50 GMT"}], "update_date": "2016-04-19", "authors_parsed": [["Sanchez-Anguix", "Victor", ""], ["Julian", "Vicente", ""], ["Botti", "Vicente", ""], ["Garcia-Fornes", "Ana", ""]]}, {"id": "1604.04728", "submitter": "Victor Sanchez-Anguix Dr.", "authors": "Victor Sanchez-Anguix, Vicente Julian, Vicente Botti and Ana\n  Garcia-Fornes", "title": "Reaching Unanimous Agreements Within Agent-Based Negotiation Teams With\n  Linear and Monotonic Utility Functions", "comments": "IEEE Transactions on Systems, Man, and Cybernetics, Part B\n  (Cybernetics), 2012", "journal-ref": null, "doi": "10.1109/TSMCB.2011.2177658", "report-no": null, "categories": "cs.MA cs.AI cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this article, an agent-based negotiation model for negotiation teams that\nnegotiate a deal with an opponent is presented. Agent-based negotiation teams\nare groups of agents that join together as a single negotiation party because\nthey share an interest that is related to the negotiation process. The model\nrelies on a trusted mediator that coordinates and helps team members in the\ndecisions that they have to take during the negotiation process: which offer is\nsent to the opponent, and whether the offers received from the opponent are\naccepted. The main strength of the proposed negotiation model is the fact that\nit guarantees unanimity within team decisions since decisions report a utility\nto team members that is greater than or equal to their aspiration levels at\neach negotiation round. This work analyzes how unanimous decisions are taken\nwithin the team and the robustness of the model against different types of\nmanipulations. An empirical evaluation is also performed to study the impact of\nthe different parameters of the model.\n", "versions": [{"version": "v1", "created": "Sat, 16 Apr 2016 11:42:38 GMT"}], "update_date": "2016-04-19", "authors_parsed": [["Sanchez-Anguix", "Victor", ""], ["Julian", "Vicente", ""], ["Botti", "Vicente", ""], ["Garcia-Fornes", "Ana", ""]]}, {"id": "1604.04730", "submitter": "Victor Sanchez-Anguix Dr.", "authors": "Victor Sanchez-Anguix, Soledad Valero, Vicente Julian, Vicente Botti\n  and Ana Garcia-Fornes", "title": "Evolutionary-aided negotiation model for bilateral bargaining in Ambient\n  Intelligence domains with complex utility functions", "comments": "Information Sciences, 2013", "journal-ref": null, "doi": "10.1016/j.ins.2010.11.018", "report-no": null, "categories": "cs.MA cs.AI cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ambient Intelligence aims to offer personalized services and easier ways of\ninteraction between people and systems. Since several users and systems may\ncoexist in these environments, it is quite possible that entities with opposing\npreferences need to cooperate to reach their respective goals. Automated\nnegotiation is pointed as one of the mechanisms that may provide a solution to\nthis kind of problems. In this article, a multi-issue bilateral bargaining\nmodel for Ambient Intelligence domains is presented where it is assumed that\nagents have computational bounded resources and do not know their opponents'\npreferences. The main goal of this work is to provide negotiation models that\nobtain efficient agreements while maintaining the computational cost low. A\nniching genetic algorithm is used before the negotiation process to sample\none's own utility function (self-sampling). During the negotiation process,\ngenetic operators are applied over the opponent's and one's own offers in order\nto sample new offers that are interesting for both parties. Results show that\nthe proposed model is capable of outperforming similarity heuristics which only\nsample before the negotiation process and of obtaining similar results to\nsimilarity heuristics which have access to all of the possible offers.\n", "versions": [{"version": "v1", "created": "Sat, 16 Apr 2016 11:53:46 GMT"}], "update_date": "2016-04-19", "authors_parsed": [["Sanchez-Anguix", "Victor", ""], ["Valero", "Soledad", ""], ["Julian", "Vicente", ""], ["Botti", "Vicente", ""], ["Garcia-Fornes", "Ana", ""]]}, {"id": "1604.04736", "submitter": "Victor Sanchez-Anguix Dr.", "authors": "Victor Sanchez-Anguix, Reyhan Aydogan, Vicente Julian and Catholijn\n  Jonker", "title": "Intra-Team Strategies for Teams Negotiating Against Competitor,\n  Matchers, and Conceders", "comments": "Novel Insights in Agent-based Complex Automated Negotiation, 2014", "journal-ref": null, "doi": "10.1007/978-4-431-54758-7_1", "report-no": null, "categories": "cs.MA cs.AI cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Under some circumstances, a group of individuals may need to negotiate\ntogether as a negotiation team against another party. Unlike bilateral\nnegotiation between two individuals, this type of negotiations entails to adopt\nan intra-team strategy for negotiation teams in order to make team decisions\nand accordingly negotiate with the opponent. It is crucial to be able to\nnegotiate successfully with heterogeneous opponents since opponents'\nnegotiation strategy and behavior may vary in an open environment. While one\nopponent might collaborate and concede over time, another may not be inclined\nto concede. This paper analyzes the performance of recently proposed intra-team\nstrategies for negotiation teams against different categories of opponents:\ncompetitors, matchers, and conceders. Furthermore, it provides an extension of\nthe negotiation tool Genius for negotiation teams in bilateral settings.\nConsequently, this work facilitates research in negotiation teams.\n", "versions": [{"version": "v1", "created": "Sat, 16 Apr 2016 12:11:02 GMT"}], "update_date": "2016-04-19", "authors_parsed": [["Sanchez-Anguix", "Victor", ""], ["Aydogan", "Reyhan", ""], ["Julian", "Vicente", ""], ["Jonker", "Catholijn", ""]]}, {"id": "1604.04737", "submitter": "Victor Sanchez-Anguix Dr.", "authors": "Victor Sanchez-Anguix, Vicente Julian, Vicente Botti and Ana\n  Garcia-Fornes", "title": "Studying the impact of negotiation environments on negotiation teams'\n  performance", "comments": "Information Sciences, 2013", "journal-ref": null, "doi": "10.1016/j.ins.2012.07.017", "report-no": null, "categories": "cs.MA cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this article we study the impact of the negotiation environment on the\nperformance of several intra-team strategies (team dynamics) for agent-based\nnegotiation teams that negotiate with an opponent. An agent-based negotiation\nteam is a group of agents that joins together as a party because they share\ncommon interests in the negotiation at hand. It is experimentally shown how\nnegotiation environment conditions like the deadline of both parties, the\nconcession speed of the opponent, similarity among team members, and team size\naffect performance metrics like the minimum utility of team members, the\naverage utility of team members, and the number of negotiation rounds. Our goal\nis identifying which intra-team strategies work better in different\nenvironmental conditions in order to provide useful knowledge for team members\nto select appropriate intra-team strategies according to environmental\nconditions.\n", "versions": [{"version": "v1", "created": "Sat, 16 Apr 2016 12:13:02 GMT"}], "update_date": "2016-04-19", "authors_parsed": [["Sanchez-Anguix", "Victor", ""], ["Julian", "Vicente", ""], ["Botti", "Vicente", ""], ["Garcia-Fornes", "Ana", ""]]}, {"id": "1604.04789", "submitter": "Enrico De Santis", "authors": "Enrico De Santis, Antonello Rizzi, Alireza Sadeghian", "title": "A Hierarchical Genetic Optimization of a Fuzzy Logic System for Flow\n  Control in Micro Grids", "comments": null, "journal-ref": null, "doi": "10.1016/j.asoc.2017.05.059", "report-no": null, "categories": "cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bio-inspired algorithms like Genetic Algorithms and Fuzzy Inference Systems\n(FIS) are nowadays widely adopted as hybrid techniques in commercial and\nindustrial environment. In this paper we present an interesting application of\nthe fuzzy-GA paradigm to Smart Grids. The main aim consists in performing\ndecision making for power flow management tasks in the proposed microgrid model\nequipped by renewable sources and an energy storage system, taking into account\nthe economical profit in energy trading with the main-grid. In particular, this\nstudy focuses on the application of a Hierarchical Genetic Algorithm (HGA) for\ntuning the Rule Base (RB) of a Fuzzy Inference System (FIS), trying to discover\na minimal fuzzy rules set in a Fuzzy Logic Controller (FLC) adopted to perform\ndecision making in the microgrid. The HGA rationale focuses on a particular\nencoding scheme, based on control genes and parametric genes applied to the\noptimization of the FIS parameters, allowing to perform a reduction in the\nstructural complexity of the RB. This approach will be referred in the\nfollowing as fuzzy-HGA. Results are compared with a simpler approach based on a\nclassic fuzzy-GA scheme, where both FIS parameters and rule weights are tuned,\nwhile the number of fuzzy rules is fixed in advance. Experiments shows how the\nfuzzy-HGA approach adopted for the synthesis of the proposed controller\noutperforms the classic fuzzy-GA scheme, increasing the accounting profit by\n67\\% in the considered energy trading problem yielding at the same time a\nsimpler RB.\n", "versions": [{"version": "v1", "created": "Sat, 16 Apr 2016 19:38:21 GMT"}, {"version": "v2", "created": "Tue, 24 Jan 2017 12:17:24 GMT"}, {"version": "v3", "created": "Wed, 1 Mar 2017 04:57:14 GMT"}], "update_date": "2017-06-15", "authors_parsed": [["De Santis", "Enrico", ""], ["Rizzi", "Antonello", ""], ["Sadeghian", "Alireza", ""]]}, {"id": "1604.04795", "submitter": "Jacopo Urbani", "authors": "Jacopo Urbani, Sourav Dutta, Sairam Gurajada, Gerhard Weikum", "title": "KOGNAC: Efficient Encoding of Large Knowledge Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many Web applications require efficient querying of large Knowledge Graphs\n(KGs). We propose KOGNAC, a dictionary-encoding algorithm designed to improve\nSPARQL querying with a judicious combination of statistical and semantic\ntechniques. In KOGNAC, frequent terms are detected with a frequency\napproximation algorithm and encoded to maximise compression. Infrequent terms\nare semantically grouped into ontological classes and encoded to increase data\nlocality. We evaluated KOGNAC in combination with state-of-the-art RDF engines,\nand observed that it significantly improves SPARQL querying on KGs with up to\n1B edges.\n", "versions": [{"version": "v1", "created": "Sat, 16 Apr 2016 20:54:12 GMT"}, {"version": "v2", "created": "Sun, 10 Jul 2016 16:24:37 GMT"}], "update_date": "2016-07-12", "authors_parsed": [["Urbani", "Jacopo", ""], ["Dutta", "Sourav", ""], ["Gurajada", "Sairam", ""], ["Weikum", "Gerhard", ""]]}, {"id": "1604.04854", "submitter": "Somaiyeh Mahmoud Zadeh", "authors": "Somaiyeh Mahmoud Zadeh, David MW Powers, Karl Sammut, Amirmehdi\n  Yazdani", "title": "Toward Efficient Task Assignment and Motion Planning for Large Scale\n  Underwater Mission", "comments": "arXiv admin note: substantial text overlap with arXiv:1604.03308", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An Autonomous Underwater Vehicle (AUV) needs to acquire a certain degree of\nautonomy for any particular underwater mission to fulfill the mission\nobjectives successfully and ensure its safety in all stages of the mission in a\nlarge scale operating filed. In this paper, a novel combinatorial\nconflict-free-task assignment strategy consisting an interactive engagement of\na local path planner and an adaptive global route planner, is introduced. The\nmethod is established upon the heuristic search potency of the Particle Swarm\nOptimisation (PSO) algorithm to address the discrete nature of routing-task\nassignment approach and the complexity of NP-hard path planning problem. The\nproposed hybrid method is highly efficient for having a reactive guidance\nframework that guarantees successful completion of missions specifically in\ncluttered environments. To examine the performance of the method in a context\nof mission productivity, mission time management and vehicle safety, a series\nof simulation studies are undertaken. The results of simulations declare that\nthe proposed method is reliable and robust, particularly in dealing with\nuncertainties, and it can significantly enhance the level of vehicle's autonomy\nby relying on its reactive nature and capability of providing fast feasible\nsolutions.\n", "versions": [{"version": "v1", "created": "Sun, 17 Apr 2016 09:39:26 GMT"}, {"version": "v2", "created": "Tue, 26 Apr 2016 03:10:39 GMT"}, {"version": "v3", "created": "Wed, 15 Jun 2016 23:05:16 GMT"}], "update_date": "2016-12-06", "authors_parsed": [["Zadeh", "Somaiyeh Mahmoud", ""], ["Powers", "David MW", ""], ["Sammut", "Karl", ""], ["Yazdani", "Amirmehdi", ""]]}, {"id": "1604.04894", "submitter": "Yahia Lebbah", "authors": "Mehdi Maamar, Nadjib Lazaar, Samir Loudni, Yahia Lebbah", "title": "A global constraint for closed itemset mining", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Discovering the set of closed frequent patterns is one of the fundamental\nproblems in Data Mining. Recent Constraint Programming (CP) approaches for\ndeclarative itemset mining have proven their usefulness and flexibility. But\nthe wide use of reified constraints in current CP approaches raises many\ndifficulties to cope with high dimensional datasets. This paper proposes CLOSED\nPATTERN global constraint which does not require any reified constraints nor\nany extra variables to encode efficiently the Closed Frequent Pattern Mining\n(CFPM) constraint. CLOSED-PATTERN captures the particular semantics of the CFPM\nproblem in order to ensure a polynomial pruning algorithm ensuring domain\nconsistency. The computational properties of our constraint are analyzed and\ntheir practical effectiveness is experimentally evaluated.\n", "versions": [{"version": "v1", "created": "Sun, 17 Apr 2016 16:32:27 GMT"}], "update_date": "2016-04-19", "authors_parsed": [["Maamar", "Mehdi", ""], ["Lazaar", "Nadjib", ""], ["Loudni", "Samir", ""], ["Lebbah", "Yahia", ""]]}, {"id": "1604.04928", "submitter": "Yang Liu", "authors": "Yang Liu and Yiling Chen", "title": "Learning to Incentivize: Eliciting Effort via Output Agreement", "comments": "23 pages; short version is accepted to IJCAI 16", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.AI cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In crowdsourcing when there is a lack of verification for contributed\nanswers, output agreement mechanisms are often used to incentivize participants\nto provide truthful answers when the correct answer is hold by the majority. In\nthis paper, we focus on using output agreement mechanisms to elicit effort, in\naddition to eliciting truthful answers, from a population of workers. We\nconsider a setting where workers have heterogeneous cost of effort exertion and\nexamine the data requester's problem of deciding the reward level in output\nagreement for optimal elicitation. In particular, when the requester knows the\ncost distribution, we derive the optimal reward level for output agreement\nmechanisms. This is achieved by first characterizing Bayesian Nash equilibria\nof output agreement mechanisms for a given reward level. When the requester\ndoes not know the cost distribution, we develop sequential mechanisms that\ncombine learning the cost distribution with incentivizing effort exertion to\napproximately determine the optimal reward level.\n", "versions": [{"version": "v1", "created": "Sun, 17 Apr 2016 21:07:02 GMT"}], "update_date": "2016-04-19", "authors_parsed": [["Liu", "Yang", ""], ["Chen", "Yiling", ""]]}, {"id": "1604.05006", "submitter": "Heng Zhang", "authors": "Heng Zhang, Yan Zhang, Jia-Huai You", "title": "Expressive Completeness of Existential Rule Languages for Ontology-based\n  Query Answering", "comments": "10 pages; the full version of a paper to appear in IJCAI 2016.\n  Changes (regarding to v1): a new reference has been added, and some typos\n  have been corrected", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.DB cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existential rules, also known as data dependencies in Databases, have been\nrecently rediscovered as a promising family of languages for Ontology-based\nQuery Answering. In this paper, we prove that disjunctive embedded dependencies\nexactly capture the class of recursively enumerable ontologies in\nOntology-based Conjunctive Query Answering (OCQA). Our expressive completeness\nresult does not rely on any built-in linear order on the database. To establish\nthe expressive completeness, we introduce a novel semantic definition for OCQA\nontologies. We also show that neither the class of disjunctive tuple-generating\ndependencies nor the class of embedded dependencies is expressively complete\nfor recursively enumerable OCQA ontologies.\n", "versions": [{"version": "v1", "created": "Mon, 18 Apr 2016 06:16:49 GMT"}, {"version": "v2", "created": "Wed, 27 Apr 2016 13:22:52 GMT"}], "update_date": "2016-04-28", "authors_parsed": [["Zhang", "Heng", ""], ["Zhang", "Yan", ""], ["You", "Jia-Huai", ""]]}, {"id": "1604.05024", "submitter": "Ziqiang Shi", "authors": "Ziqiang Shi and Rujie Liu", "title": "Empirical study of PROXTONE and PROXTONE$^+$ for Fast Learning of Large\n  Scale Sparse Models", "comments": "arXiv admin note: text overlap with arXiv:1311.2115 by other authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  PROXTONE is a novel and fast method for optimization of large scale\nnon-smooth convex problem \\cite{shi2015large}. In this work, we try to use\nPROXTONE method in solving large scale \\emph{non-smooth non-convex} problems,\nfor example training of sparse deep neural network (sparse DNN) or sparse\nconvolutional neural network (sparse CNN) for embedded or mobile device.\nPROXTONE converges much faster than first order methods, while first order\nmethod is easy in deriving and controlling the sparseness of the solutions.\nThus in some applications, in order to train sparse models fast, we propose to\ncombine the merits of both methods, that is we use PROXTONE in the first\nseveral epochs to reach the neighborhood of an optimal solution, and then use\nthe first order method to explore the possibility of sparsity in the following\ntraining. We call such method PROXTONE plus (PROXTONE$^+$). Both PROXTONE and\nPROXTONE$^+$ are tested in our experiments, and which demonstrate both methods\nimproved convergence speed twice as fast at least on diverse sparse model\nlearning problems, and at the same time reduce the size to 0.5\\% for DNN\nmodels. The source of all the algorithms is available upon request.\n", "versions": [{"version": "v1", "created": "Mon, 18 Apr 2016 08:01:02 GMT"}], "update_date": "2016-04-19", "authors_parsed": [["Shi", "Ziqiang", ""], ["Liu", "Rujie", ""]]}, {"id": "1604.05085", "submitter": "Wojciech Ja\\'skowski", "authors": "Wojciech Ja\\'skowski", "title": "Mastering 2048 with Delayed Temporal Coherence Learning, Multi-Stage\n  Weight Promotion, Redundant Encoding and Carousel Shaping", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  2048 is an engaging single-player, nondeterministic video puzzle game, which,\nthanks to the simple rules and hard-to-master gameplay, has gained massive\npopularity in recent years. As 2048 can be conveniently embedded into the\ndiscrete-state Markov decision processes framework, we treat it as a testbed\nfor evaluating existing and new methods in reinforcement learning. With the aim\nto develop a strong 2048 playing program, we employ temporal difference\nlearning with systematic n-tuple networks. We show that this basic method can\nbe significantly improved with temporal coherence learning, multi-stage\nfunction approximator with weight promotion, carousel shaping, and redundant\nencoding. In addition, we demonstrate how to take advantage of the\ncharacteristics of the n-tuple network, to improve the algorithmic\neffectiveness of the learning process by i) delaying the (decayed) update and\napplying lock-free optimistic parallelism to effortlessly make advantage of\nmultiple CPU cores. This way, we were able to develop the best known 2048\nplaying program to date, which confirms the effectiveness of the introduced\nmethods for discrete-state Markov decision problems.\n", "versions": [{"version": "v1", "created": "Mon, 18 Apr 2016 11:06:32 GMT"}, {"version": "v2", "created": "Sun, 6 Nov 2016 13:18:39 GMT"}, {"version": "v3", "created": "Mon, 12 Dec 2016 12:54:36 GMT"}], "update_date": "2016-12-13", "authors_parsed": [["Ja\u015bkowski", "Wojciech", ""]]}, {"id": "1604.05086", "submitter": "Ji Ruan", "authors": "Xiaowei Huang, Ji Ruan, Qingliang Chen and Kaile Su", "title": "Normative Multiagent Systems: A Dynamic Generalization", "comments": "26 pages. A conference version of this work is accepted by the 25th\n  International Joint Conference on Artificial Intelligence (IJCAI-16)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CC cs.LO cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Social norms are powerful formalism in coordinating autonomous agents'\nbehaviour to achieve certain objectives. In this paper, we propose a dynamic\nnormative system to enable the reasoning of the changes of norms under\ndifferent circumstances, which cannot be done in the existing static normative\nsystems. We study two important problems (norm synthesis and norm recognition)\nrelated to the autonomy of the entire system and the agents, and characterise\nthe computational complexities of solving these problems.\n", "versions": [{"version": "v1", "created": "Mon, 18 Apr 2016 11:07:02 GMT"}], "update_date": "2016-04-19", "authors_parsed": [["Huang", "Xiaowei", ""], ["Ruan", "Ji", ""], ["Chen", "Qingliang", ""], ["Su", "Kaile", ""]]}, {"id": "1604.05091", "submitter": "Peter Ondruska", "authors": "Peter Ondruska, Julie Dequaire, Dominic Zeng Wang, Ingmar Posner", "title": "End-to-End Tracking and Semantic Segmentation Using Recurrent Neural\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.NE cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we present a novel end-to-end framework for tracking and\nclassifying a robot's surroundings in complex, dynamic and only partially\nobservable real-world environments. The approach deploys a recurrent neural\nnetwork to filter an input stream of raw laser measurements in order to\ndirectly infer object locations, along with their identity in both visible and\noccluded areas. To achieve this we first train the network using unsupervised\nDeep Tracking, a recently proposed theoretical framework for end-to-end space\noccupancy prediction. We show that by learning to track on a large amount of\nunsupervised data, the network creates a rich internal representation of its\nenvironment which we in turn exploit through the principle of inductive\ntransfer of knowledge to perform the task of it's semantic classification. As a\nresult, we show that only a small amount of labelled data suffices to steer the\nnetwork towards mastering this additional task. Furthermore we propose a novel\nrecurrent neural network architecture specifically tailored to tracking and\nsemantic classification in real-world robotics applications. We demonstrate the\ntracking and classification performance of the method on real-world data\ncollected at a busy road junction. Our evaluation shows that the proposed\nend-to-end framework compares favourably to a state-of-the-art, model-free\ntracking solution and that it outperforms a conventional one-shot training\nscheme for semantic classification.\n", "versions": [{"version": "v1", "created": "Mon, 18 Apr 2016 11:15:56 GMT"}, {"version": "v2", "created": "Tue, 19 Apr 2016 14:09:26 GMT"}], "update_date": "2016-04-20", "authors_parsed": [["Ondruska", "Peter", ""], ["Dequaire", "Julie", ""], ["Wang", "Dominic Zeng", ""], ["Posner", "Ingmar", ""]]}, {"id": "1604.05129", "submitter": "Pedro Alejandro Ortega", "authors": "Pedro A. Ortega and Naftali Tishby", "title": "Memory shapes time perception and intertemporal choices", "comments": "24 pages, 4 figures, 2 tables. Submitted", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is a consensus that human and non-human subjects experience temporal\ndistortions in many stages of their perceptual and decision-making systems.\nSimilarly, intertemporal choice research has shown that decision-makers\nundervalue future outcomes relative to immediate ones. Here we combine\ntechniques from information theory and artificial intelligence to show how both\ntemporal distortions and intertemporal choice preferences can be explained as a\nconsequence of the coding efficiency of sensorimotor representation. In\nparticular, the model implies that interactions that constrain future behavior\nare perceived as being both longer in duration and more valuable. Furthermore,\nusing simulations of artificial agents, we investigate how memory constraints\nenforce a renormalization of the perceived timescales. Our results show that\nqualitatively different discount functions, such as exponential and hyperbolic\ndiscounting, arise as a consequence of an agent's probabilistic model of the\nworld.\n", "versions": [{"version": "v1", "created": "Mon, 18 Apr 2016 13:17:55 GMT"}, {"version": "v2", "created": "Sun, 29 May 2016 18:39:52 GMT"}], "update_date": "2016-05-31", "authors_parsed": [["Ortega", "Pedro A.", ""], ["Tishby", "Naftali", ""]]}, {"id": "1604.05170", "submitter": "Kieran Greer Dr", "authors": "Kieran Greer", "title": "A Repeated Signal Difference for Recognising Patterns", "comments": null, "journal-ref": "BRAIN, Broad Research in Artificial Intelligence and Neuroscience,\n  Vol. 7, No. 3, pp. 139 - 147, 2016", "doi": null, "report-no": null, "categories": "cs.NE cs.AI q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes a new mechanism that might help with defining pattern\nsequences, by the fact that it can produce an upper bound on the ensemble value\nthat can persistently oscillate with the actual values produced from each\npattern. With every firing event, a node also receives an on/off feedback\nswitch. If the node fires, then it sends a feedback result depending on the\ninput signal strength. If the input signal is positive or larger, it can store\nan 'on' switch feedback for the next iteration. If the signal is negative or\nsmaller, it can store an 'off' switch feedback for the next iteration. If the\nnode does not fire, then it does not affect the current feedback situation and\nreceives the switch command produced by the last active pattern event for the\nsame neuron. The upper bound therefore also represents the largest or most\nenclosing pattern set and the lower value is for the actual set of firing\npatterns. If the pattern sequence repeats, it will oscillate between the two\nvalues, allowing them to be recognised and measured more easily, over time.\nTests show that changing the sequence ordering produces different value sets,\nwhich can also be measured.\n", "versions": [{"version": "v1", "created": "Mon, 18 Apr 2016 14:13:52 GMT"}, {"version": "v2", "created": "Sat, 30 Apr 2016 12:08:14 GMT"}, {"version": "v3", "created": "Wed, 7 Sep 2016 17:17:54 GMT"}], "update_date": "2019-01-04", "authors_parsed": [["Greer", "Kieran", ""]]}, {"id": "1604.05194", "submitter": "Palash Dey", "authors": "Palash Dey and Neeldhara Misra", "title": "Preference Elicitation For Single Crossing Domain", "comments": "To appear in IJCAI 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.AI cs.DS cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Eliciting the preferences of a set of agents over a set of alternatives is a\nproblem of fundamental importance in social choice theory. Prior work on this\nproblem has studied the query complexity of preference elicitation for the\nunrestricted domain and for the domain of single peaked preferences. In this\npaper, we consider the domain of single crossing preference profiles and study\nthe query complexity of preference elicitation under various settings. We\nconsider two distinct situations: when an ordering of the voters with respect\nto which the profile is single crossing is known versus when it is unknown. We\nalso consider different access models: when the votes can be accessed at\nrandom, as opposed to when they are coming in a pre-defined sequence. In the\nsequential access model, we distinguish two cases when the ordering is known:\nthe first is that sequence in which the votes appear is also a single-crossing\norder, versus when it is not.\n  The main contribution of our work is to provide polynomial time algorithms\nwith low query complexity for preference elicitation in all the above six\ncases. Further, we show that the query complexities of our algorithms are\noptimal up to constant factors for all but one of the above six cases. We then\npresent preference elicitation algorithms for profiles which are close to being\nsingle crossing under various notions of closeness, for example, single\ncrossing width, minimum number of candidates | voters whose deletion makes a\nprofile single crossing.\n", "versions": [{"version": "v1", "created": "Fri, 15 Apr 2016 08:47:18 GMT"}], "update_date": "2016-04-19", "authors_parsed": [["Dey", "Palash", ""], ["Misra", "Neeldhara", ""]]}, {"id": "1604.05225", "submitter": "Jiren Jin", "authors": "Jiren Jin, Hideki Nakayama", "title": "Annotation Order Matters: Recurrent Image Annotator for Arbitrary Length\n  Image Tagging", "comments": "International Conference on Pattern Recognition (ICPR) 2016, Cancun,\n  Mexico (oral presentation)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic image annotation has been an important research topic in\nfacilitating large scale image management and retrieval. Existing methods focus\non learning image-tag correlation or correlation between tags to improve\nannotation accuracy. However, most of these methods evaluate their performance\nusing top-k retrieval performance, where k is fixed. Although such setting\ngives convenience for comparing different methods, it is not the natural way\nthat humans annotate images. The number of annotated tags should depend on\nimage contents. Inspired by the recent progress in machine translation and\nimage captioning, we propose a novel Recurrent Image Annotator (RIA) model that\nforms image annotation task as a sequence generation problem so that RIA can\nnatively predict the proper length of tags according to image contents. We\nevaluate the proposed model on various image annotation datasets. In addition\nto comparing our model with existing methods using the conventional top-k\nevaluation measures, we also provide our model as a high quality baseline for\nthe arbitrary length image tagging task. Moreover, the results of our\nexperiments show that the order of tags in training phase has a great impact on\nthe final annotation performance.\n", "versions": [{"version": "v1", "created": "Mon, 18 Apr 2016 16:09:04 GMT"}, {"version": "v2", "created": "Sat, 23 Apr 2016 08:30:48 GMT"}, {"version": "v3", "created": "Wed, 7 Dec 2016 19:57:02 GMT"}], "update_date": "2018-01-01", "authors_parsed": [["Jin", "Jiren", ""], ["Nakayama", "Hideki", ""]]}, {"id": "1604.05273", "submitter": "Ondrej Kuzelka", "authors": "Ondrej Kuzelka, Jesse Davis, Steven Schockaert", "title": "Learning Possibilistic Logic Theories from Default Rules", "comments": "Long version of a paper accepted at IJCAI 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a setting for learning possibilistic logic theories from\ndefaults of the form \"if alpha then typically beta\". We first analyse this\nproblem from the point of view of machine learning theory, determining the VC\ndimension of possibilistic stratifications as well as the complexity of the\nassociated learning problems, after which we present a heuristic learning\nalgorithm that can easily scale to thousands of defaults. An important property\nof our approach is that it is inherently able to handle noisy and conflicting\nsets of defaults. Among others, this allows us to learn possibilistic logic\ntheories from crowdsourced data and to approximate propositional Markov logic\nnetworks using heuristic MAP solvers. We present experimental results that\ndemonstrate the effectiveness of this approach.\n", "versions": [{"version": "v1", "created": "Mon, 18 Apr 2016 18:35:38 GMT"}], "update_date": "2016-04-19", "authors_parsed": [["Kuzelka", "Ondrej", ""], ["Davis", "Jesse", ""], ["Schockaert", "Steven", ""]]}, {"id": "1604.05280", "submitter": "Scott Garrabrant", "authors": "Scott Garrabrant, Nate Soares, Jessica Taylor", "title": "Asymptotic Convergence in Online Learning with Unbounded Delays", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of predicting the results of computations that are too\nexpensive to run, via the observation of the results of smaller computations.\nWe model this as an online learning problem with delayed feedback, where the\nlength of the delay is unbounded, which we study mainly in a stochastic\nsetting. We show that in this setting, consistency is not possible in general,\nand that optimal forecasters might not have average regret going to zero.\nHowever, it is still possible to give algorithms that converge asymptotically\nto Bayes-optimal predictions, by evaluating forecasters on specific sparse\nindependent subsequences of their predictions. We give an algorithm that does\nthis, which converges asymptotically on good behavior, and give very weak\nbounds on how long it takes to converge. We then relate our results back to the\nproblem of predicting large computations in a deterministic setting.\n", "versions": [{"version": "v1", "created": "Mon, 18 Apr 2016 19:04:59 GMT"}, {"version": "v2", "created": "Fri, 15 Jul 2016 02:10:26 GMT"}, {"version": "v3", "created": "Fri, 2 Sep 2016 02:21:21 GMT"}, {"version": "v4", "created": "Wed, 7 Sep 2016 18:43:24 GMT"}], "update_date": "2016-09-08", "authors_parsed": [["Garrabrant", "Scott", ""], ["Soares", "Nate", ""], ["Taylor", "Jessica", ""]]}, {"id": "1604.05288", "submitter": "Scott Garrabrant", "authors": "Scott Garrabrant, Benya Fallenstein, Abram Demski, Nate Soares", "title": "Inductive Coherence", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While probability theory is normally applied to external environments, there\nhas been some recent interest in probabilistic modeling of the outputs of\ncomputations that are too expensive to run. Since mathematical logic is a\npowerful tool for reasoning about computer programs, we consider this problem\nfrom the perspective of integrating probability and logic. Recent work on\nassigning probabilities to mathematical statements has used the concept of\ncoherent distributions, which satisfy logical constraints such as the\nprobability of a sentence and its negation summing to one. Although there are\nalgorithms which converge to a coherent probability distribution in the limit,\nthis yields only weak guarantees about finite approximations of these\ndistributions. In our setting, this is a significant limitation: Coherent\ndistributions assign probability one to all statements provable in a specific\nlogical theory, such as Peano Arithmetic, which can prove what the output of\nany terminating computation is; thus, a coherent distribution must assign\nprobability one to the output of any terminating computation. To model\nuncertainty about computations, we propose to work with approximations to\ncoherent distributions. We introduce inductive coherence, a strengthening of\ncoherence that provides appropriate constraints on finite approximations, and\npropose an algorithm which satisfies this criterion.\n", "versions": [{"version": "v1", "created": "Mon, 18 Apr 2016 19:37:46 GMT"}, {"version": "v2", "created": "Fri, 15 Jul 2016 00:14:04 GMT"}, {"version": "v3", "created": "Fri, 7 Oct 2016 17:00:38 GMT"}], "update_date": "2016-10-10", "authors_parsed": [["Garrabrant", "Scott", ""], ["Fallenstein", "Benya", ""], ["Demski", "Abram", ""], ["Soares", "Nate", ""]]}, {"id": "1604.05358", "submitter": "Keunwoo Choi Mr", "authors": "Keunwoo Choi, George Fazekas, Mark Sandler", "title": "Text-based LSTM networks for Automatic Music Composition", "comments": "Accepted in the 1st Conference on Computer Simulation of Musical\n  Creativity, 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.MM", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we introduce new methods and discuss results of text-based\nLSTM (Long Short-Term Memory) networks for automatic music composition. The\nproposed network is designed to learn relationships within text documents that\nrepresent chord progressions and drum tracks in two case studies. In the\nexperiments, word-RNNs (Recurrent Neural Networks) show good results for both\ncases, while character-based RNNs (char-RNNs) only succeed to learn chord\nprogressions. The proposed system can be used for fully automatic composition\nor as semi-automatic systems that help humans to compose music by controlling a\ndiversity parameter of the model.\n", "versions": [{"version": "v1", "created": "Mon, 18 Apr 2016 21:43:44 GMT"}], "update_date": "2016-04-20", "authors_parsed": [["Choi", "Keunwoo", ""], ["Fazekas", "George", ""], ["Sandler", "Mark", ""]]}, {"id": "1604.05419", "submitter": "Jake Chandler", "authors": "Jake Chandler and Richard Booth", "title": "Extending the Harper Identity to Iterated Belief Change", "comments": "Extended version of a paper accepted to IJCAI16. 23 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The field of iterated belief change has focused mainly on revision, with the\nother main operator of AGM belief change theory, i.e. contraction, receiving\nrelatively little attention. In this paper we extend the Harper Identity from\nsingle-step change to define iterated contraction in terms of iterated\nrevision. Specifically, just as the Harper Identity provides a recipe for\ndefining the belief set resulting from contracting A in terms of (i) the\ninitial belief set and (ii) the belief set resulting from revision by not-A, we\nlook at ways to define the plausibility ordering over worlds resulting from\ncontracting A in terms of (iii) the initial plausibility ordering, and (iv) the\nplausibility ordering resulting from revision by not-A. After noting that the\nmost straightforward such extension leads to a trivialisation of the space of\npermissible orderings, we provide a family of operators for combining\nplausibility orderings that avoid such a result. These operators are\ncharacterised in our domain of interest by a pair of intuitively compelling\nproperties, which turn out to enable the derivation of a number of iterated\ncontraction postulates from postulates for iterated revision. We finish by\nobserving that a salient member of this family allows for the derivation of\ncounterparts for contraction of some well known iterated revision operators, as\nwell as for defining new iterated contraction operators.\n", "versions": [{"version": "v1", "created": "Tue, 19 Apr 2016 03:36:20 GMT"}], "update_date": "2016-04-20", "authors_parsed": [["Chandler", "Jake", ""], ["Booth", "Richard", ""]]}, {"id": "1604.05468", "submitter": "Rahul Kamath", "authors": "Rahul Kamath, Masanao Ochi, Yutaka Matsuo", "title": "Understanding Rating Behaviour and Predicting Ratings by Identifying\n  Representative Users", "comments": "The 29th Pacific Asia Conference on Language, Information and\n  Computation (PACLIC-29)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Online user reviews describing various products and services are now abundant\non the web. While the information conveyed through review texts and ratings is\neasily comprehensible, there is a wealth of hidden information in them that is\nnot immediately obvious. In this study, we unlock this hidden value behind user\nreviews to understand the various dimensions along which users rate products.\nWe learn a set of users that represent each of these dimensions and use their\nratings to predict product ratings. Specifically, we work with restaurant\nreviews to identify users whose ratings are influenced by dimensions like\n'Service', 'Atmosphere' etc. in order to predict restaurant ratings and\nunderstand the variation in rating behaviour across different cuisines. While\nprevious approaches to obtaining product ratings require either a large number\nof user ratings or a few review texts, we show that it is possible to predict\nratings with few user ratings and no review text. Our experiments show that our\napproach outperforms other conventional methods by 16-27% in terms of RMSE.\n", "versions": [{"version": "v1", "created": "Tue, 19 Apr 2016 08:31:23 GMT"}], "update_date": "2016-04-20", "authors_parsed": [["Kamath", "Rahul", ""], ["Ochi", "Masanao", ""], ["Matsuo", "Yutaka", ""]]}, {"id": "1604.05471", "submitter": "Ragavendran Gopalakrishnan", "authors": "Arpita Biswas, Ragavendran Gopalakrishnan, Partha Dutta", "title": "Managing Overstaying Electric Vehicles in Park-and-Charge Facilities", "comments": "Published in Proceedings of the 25th International Joint Conference\n  on Artificial Intelligence IJCAI 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the increase in adoption of Electric Vehicles (EVs), proper utilization\nof the charging infrastructure is an emerging challenge for service providers.\nOverstaying of an EV after a charging event is a key contributor to low\nutilization. Since overstaying is easily detectable by monitoring the power\ndrawn from the charger, managing this problem primarily involves designing an\nappropriate \"penalty\" during the overstaying period. Higher penalties do\ndiscourage overstaying; however, due to uncertainty in parking duration, less\npeople would find such penalties acceptable, leading to decreased utilization\n(and revenue). To analyze this central trade-off, we develop a novel framework\nthat integrates models for realistic user behavior into queueing dynamics to\nlocate the optimal penalty from the points of view of utilization and revenue,\nfor different values of the external charging demand. Next, when the model\nparameters are unknown, we show how an online learning algorithm, such as UCB,\ncan be adapted to learn the optimal penalty. Our experimental validation, based\non charging data from London, shows that an appropriate penalty can increase\nboth utilization and revenue while significantly reducing overstaying.\n", "versions": [{"version": "v1", "created": "Tue, 19 Apr 2016 08:42:14 GMT"}, {"version": "v2", "created": "Thu, 14 Jul 2016 15:20:26 GMT"}], "update_date": "2016-07-15", "authors_parsed": [["Biswas", "Arpita", ""], ["Gopalakrishnan", "Ragavendran", ""], ["Dutta", "Partha", ""]]}, {"id": "1604.05472", "submitter": "Arpita Biswas", "authors": "Ragavendran Gopalakrishnan, Arpita Biswas, Alefiya Lightwala, Skanda\n  Vasudevan, Partha Dutta, Abhishek Tripathi", "title": "Demand Prediction and Placement Optimization for Electric Vehicle\n  Charging Stations", "comments": "Published in the proceedings of the 25th International Joint\n  Conference on Artificial Intelligence IJCAI 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Effective placement of charging stations plays a key role in Electric Vehicle\n(EV) adoption. In the placement problem, given a set of candidate sites, an\noptimal subset needs to be selected with respect to the concerns of both (a)\nthe charging station service provider, such as the demand at the candidate\nsites and the budget for deployment, and (b) the EV user, such as charging\nstation reachability and short waiting times at the station. This work\naddresses these concerns, making the following three novel contributions: (i) a\nsupervised multi-view learning framework using Canonical Correlation Analysis\n(CCA) for demand prediction at candidate sites, using multiple datasets such as\npoints of interest information, traffic density, and the historical usage at\nexisting charging stations; (ii) a mixed-packing-and- covering optimization\nframework that models competing concerns of the service provider and EV users;\n(iii) an iterative heuristic to solve these problems by alternately invoking\nknapsack and set cover algorithms. The performance of the demand prediction\nmodel and the placement optimization heuristic are evaluated using real world\ndata.\n", "versions": [{"version": "v1", "created": "Tue, 19 Apr 2016 08:51:03 GMT"}, {"version": "v2", "created": "Wed, 13 Jul 2016 14:30:23 GMT"}], "update_date": "2016-07-14", "authors_parsed": [["Gopalakrishnan", "Ragavendran", ""], ["Biswas", "Arpita", ""], ["Lightwala", "Alefiya", ""], ["Vasudevan", "Skanda", ""], ["Dutta", "Partha", ""], ["Tripathi", "Abhishek", ""]]}, {"id": "1604.05535", "submitter": "J. G. Wolff", "authors": "J Gerard Wolff", "title": "The SP theory of intelligence and the representation and processing of\n  knowledge in the brain", "comments": null, "journal-ref": "Frontiers in Psychology, 7, 1584, 2016", "doi": "10.3389/fpsyg.2016.01584", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The \"SP theory of intelligence\", with its realisation in the \"SP computer\nmodel\", aims to simplify and integrate observations and concepts across\nAI-related fields, with information compression as a unifying theme. This paper\ndescribes how abstract structures and processes in the theory may be realised\nin terms of neurons, their interconnections, and the transmission of signals\nbetween neurons. This part of the SP theory -- \"SP-neural\" -- is a tentative\nand partial model for the representation and processing of knowledge in the\nbrain. In the SP theory (apart from SP-neural), all kinds of knowledge are\nrepresented with \"patterns\", where a pattern is an array of atomic symbols in\none or two dimensions. In SP-neural, the concept of a \"pattern\" is realised as\nan array of neurons called a \"pattern assembly\", similar to Hebb's concept of a\n\"cell assembly\" but with important differences. Central to the processing of\ninformation in the SP system is the powerful concept of \"multiple alignment\",\nborrowed and adapted from bioinformatics. Processes such as pattern\nrecognition, reasoning and problem solving are achieved via the building of\nmultiple alignments, while unsupervised learning -- significantly different\nfrom the \"Hebbian\" kinds of learning -- is achieved by creating patterns from\nsensory information and also by creating patterns from multiple alignments in\nwhich there is a partial match between one pattern and another. Short-lived\nneural structures equivalent to multiple alignments will be created via an\ninter-play of excitatory and inhibitory neural signals. The paper discusses\nseveral associated issues, with relevant empirical evidence.\n", "versions": [{"version": "v1", "created": "Tue, 19 Apr 2016 12:04:14 GMT"}, {"version": "v2", "created": "Thu, 12 May 2016 11:29:50 GMT"}], "update_date": "2016-12-12", "authors_parsed": [["Wolff", "J Gerard", ""]]}, {"id": "1604.05557", "submitter": "Pascal Faudemay", "authors": "Pascal Faudemay", "title": "AGI and Reflexivity", "comments": "submitted to ECAI-2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We define a property of intelligent systems, which we call Reflexivity. In\nhuman beings, it is one aspect of consciousness, and an element of\ndeliberation. We propose a conjecture, that this property is conditioned by a\ntopological property of the processes which implement this reflexivity. These\nprocesses may be symbolic, or non symbolic e.g. connexionnist. An architecture\nwhich implements reflexivity may be based on the interaction of one or several\nmodules of deep learning, which may be specialized or not, and interconnected\nin a relevant way. A necessary condition of reflexivity is the existence of\nrecurrence in its processes, we will examine in which cases this condition may\nbe sufficient. We will then examine how this topology and this property make\npossible the expression of a second property, the deliberation. In a final\nparagraph, we propose an evaluation of intelligent systems, based on the\nfulfillment of all or some of these properties.\n", "versions": [{"version": "v1", "created": "Fri, 15 Apr 2016 19:39:54 GMT"}, {"version": "v2", "created": "Wed, 20 Apr 2016 18:48:02 GMT"}, {"version": "v3", "created": "Thu, 28 Apr 2016 18:49:12 GMT"}], "update_date": "2016-04-29", "authors_parsed": [["Faudemay", "Pascal", ""]]}, {"id": "1604.05577", "submitter": "Nadeem Akhtar", "authors": "Nadeem Akhtar, Malik M. Saad Missen", "title": "Contribution to the Formal Specification and Verification of a\n  Multi-Agent Robotic System", "comments": "arXiv admin note: text overlap with arXiv:1501.05120", "journal-ref": "European Journal of Scientific Research, ISSN 1450-216X /\n  1450-202X Vol.117 No.1 January, 2014, pp. 35-55", "doi": null, "report-no": null, "categories": "cs.SE cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is important to have multi-agent robotic system specifications that ensure\ncorrectness properties of safety and liveness. As these systems have\nconcurrency, and often have dynamic environment, the formal specification and\nverification of these systems along with step-wise refinement from abstract to\nconcrete concepts play a major role in system correctness. Formal verification\nis used for exhaustive investigation of the system space thus ensuring that\nundetected failures in the behavior are excluded. We construct the system\nincrementally from subcomponents, based on software architecture. The challenge\nis to develop a safe multi-agent robotic system, more specifically to ensure\nthe correctness properties of safety and liveness. Formal specifications based\non model-checking are flexible, have a concrete syntax, and play vital role in\ncorrectness of a multi-agent robotic system. To formally verify safety and\nliveness of such systems is important because they have high concurrency and in\nmost of the cases have dynamic environment. We have considered a case-study of\na multi-agent robotic system for the transport of stock between storehouses to\nexemplify our formal approach. Our proposed development approach allows for\nformal verification during specification definition. The development process\nhas been classified in to four major phases of requirement specifications,\nverification specifications, architecture specifications and implementation.\n", "versions": [{"version": "v1", "created": "Fri, 2 Oct 2015 13:53:35 GMT"}], "update_date": "2016-04-20", "authors_parsed": [["Akhtar", "Nadeem", ""], ["Missen", "Malik M. Saad", ""]]}, {"id": "1604.05636", "submitter": "Daniel Karapetyan Dr", "authors": "Daniel Karapetyan, Andrew J. Parkes, Gregory Gutin, Andrei Gagarin", "title": "Pattern-Based Approach to the Workflow Satisfiability Problem with\n  User-Independent Constraints", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The fixed parameter tractable (FPT) approach is a powerful tool in tackling\ncomputationally hard problems. In this paper, we link FPT results to classic\nartificial intelligence (AI) techniques to show how they complement each other.\nSpecifically, we consider the workflow satisfiability problem (WSP) which asks\nwhether there exists an assignment of authorised users to the steps in a\nworkflow specification, subject to certain constraints on the assignment. It\nwas shown by Cohen et al. (JAIR 2014) that WSP restricted to the class of\nuser-independent constraints (UI), covering many practical cases, admits FPT\nalgorithms, i.e. can be solved in time exponential only in the number of steps\n$k$ and polynomial in the number of users $n$. Since usually $k << n$ in WSP,\nsuch FPT algorithms are of great practical interest. We present a new\ninterpretation of the FPT nature of the WSP with UI constraints giving a\ndecomposition of the problem into two levels. Exploiting this two-level split,\nwe develop a new FPT algorithm that is by many orders of magnitude faster than\nthe previous state-of-the-art WSP algorithm and also has only polynomial-space\ncomplexity. We also introduce new pseudo-Boolean (PB) and Constraint\nSatisfaction (CSP) formulations of the WSP with UI constraints which\nefficiently exploit this new decomposition of the problem and raise the novel\nissue of how to use general-purpose solvers to tackle FPT problems in a fashion\nthat meets FPT efficiency expectations. In our computational study, we\ninvestigate, for the first time, the phase transition (PT) properties of the\nWSP, under a model for generation of random instances. We show how PT studies\ncan be extended, in a novel fashion, to support empirical evaluation of scaling\nof FPT algorithms.\n", "versions": [{"version": "v1", "created": "Tue, 19 Apr 2016 16:08:33 GMT"}, {"version": "v2", "created": "Thu, 22 Feb 2018 16:13:37 GMT"}, {"version": "v3", "created": "Fri, 1 Feb 2019 15:33:12 GMT"}, {"version": "v4", "created": "Tue, 23 Jul 2019 15:44:25 GMT"}], "update_date": "2019-07-24", "authors_parsed": [["Karapetyan", "Daniel", ""], ["Parkes", "Andrew J.", ""], ["Gutin", "Gregory", ""], ["Gagarin", "Andrei", ""]]}, {"id": "1604.05692", "submitter": "Florian Brandl", "authors": "Florian Brandl, Felix Brandt, Manuel Eberl and Christian Geist", "title": "Proving the Incompatibility of Efficiency and Strategyproofness via SMT\n  Solving", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Two important requirements when aggregating the preferences of multiple\nagents are that the outcome should be economically efficient and the\naggregation mechanism should not be manipulable. In this paper, we provide a\ncomputer-aided proof of a sweeping impossibility using these two conditions for\nrandomized aggregation mechanisms. More precisely, we show that every efficient\naggregation mechanism can be manipulated for all expected utility\nrepresentations of the agents' preferences. This settles an open problem and\nstrengthens a number of existing theorems, including statements that were shown\nwithin the special domain of assignment. Our proof is obtained by formulating\nthe claim as a satisfiability problem over predicates from real-valued\narithmetic, which is then checked using an SMT (satisfiability modulo theories)\nsolver. In order to verify the correctness of the result, a minimal\nunsatisfiable set of constraints returned by the SMT solver was translated back\ninto a proof in higher-order logic, which was automatically verified by an\ninteractive theorem prover. To the best of our knowledge, this is the first\napplication of SMT solvers in computational social choice.\n", "versions": [{"version": "v1", "created": "Tue, 19 Apr 2016 19:01:55 GMT"}, {"version": "v2", "created": "Sat, 23 Apr 2016 10:21:50 GMT"}, {"version": "v3", "created": "Thu, 16 Jun 2016 12:19:30 GMT"}, {"version": "v4", "created": "Wed, 6 Sep 2017 16:03:25 GMT"}], "update_date": "2017-09-07", "authors_parsed": [["Brandl", "Florian", ""], ["Brandt", "Felix", ""], ["Eberl", "Manuel", ""], ["Geist", "Christian", ""]]}, {"id": "1604.05753", "submitter": "Kunal Talwar", "authors": "Amit Daniely and Nevena Lazic and Yoram Singer and Kunal Talwar", "title": "Sketching and Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  High-dimensional sparse data present computational and statistical challenges\nfor supervised learning. We propose compact linear sketches for reducing the\ndimensionality of the input, followed by a single layer neural network. We show\nthat any sparse polynomial function can be computed, on nearly all sparse\nbinary vectors, by a single layer neural network that takes a compact sketch of\nthe vector as input. Consequently, when a set of sparse binary vectors is\napproximately separable using a sparse polynomial, there exists a single-layer\nneural network that takes a short sketch as input and correctly classifies\nnearly all the points. Previous work has proposed using sketches to reduce\ndimensionality while preserving the hypothesis class. However, the sketch size\nhas an exponential dependence on the degree in the case of polynomial\nclassifiers. In stark contrast, our approach of using improper learning, using\na larger hypothesis class allows the sketch size to have a logarithmic\ndependence on the degree. Even in the linear case, our approach allows us to\nimprove on the pesky $O({1}/{{\\gamma}^2})$ dependence of random projections, on\nthe margin $\\gamma$. We empirically show that our approach leads to more\ncompact neural networks than related methods such as feature hashing at equal\nor better performance.\n", "versions": [{"version": "v1", "created": "Tue, 19 Apr 2016 21:22:29 GMT"}], "update_date": "2016-04-21", "authors_parsed": [["Daniely", "Amit", ""], ["Lazic", "Nevena", ""], ["Singer", "Yoram", ""], ["Talwar", "Kunal", ""]]}, {"id": "1604.05791", "submitter": "Andrew Connor", "authors": "Jan Kruse, Ricardo Sosa and Andy M. Connor", "title": "Procedural urban environments for FPS games", "comments": null, "journal-ref": null, "doi": "10.1145/2843043.2843479", "report-no": null, "categories": "cs.AI cs.HC cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a novel approach to procedural generation of urban maps\nfor First Person Shooter (FPS) games. A multi-agent evolutionary system is\nemployed to place streets, buildings and other items inside the Unity3D game\nengine, resulting in playable video game levels. A computational agent is\ntrained using machine learning techniques to capture the intent of the game\ndesigner as part of the multi-agent system, and to enable a semi-automated\naesthetic selection for the underlying genetic algorithm.\n", "versions": [{"version": "v1", "created": "Wed, 20 Apr 2016 02:39:04 GMT"}], "update_date": "2016-04-21", "authors_parsed": [["Kruse", "Jan", ""], ["Sosa", "Ricardo", ""], ["Connor", "Andy M.", ""]]}, {"id": "1604.05865", "submitter": "Decebal Constantin Mocanu", "authors": "Decebal Constantin Mocanu, Haitham Bou Ammar, Luis Puig, Eric Eaton\n  and Antonio Liotta", "title": "Estimating 3D Trajectories from 2D Projections via Disjunctive Factored\n  Four-Way Conditional Restricted Boltzmann Machines", "comments": "Pattern Recognition, ISSN 0031-3203, Elsevier, 2017", "journal-ref": null, "doi": "10.1016/j.patcog.2017.04.017", "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Estimation, recognition, and near-future prediction of 3D trajectories based\non their two dimensional projections available from one camera source is an\nexceptionally difficult problem due to uncertainty in the trajectories and\nenvironment, high dimensionality of the specific trajectory states, lack of\nenough labeled data and so on. In this article, we propose a solution to solve\nthis problem based on a novel deep learning model dubbed Disjunctive Factored\nFour-Way Conditional Restricted Boltzmann Machine (DFFW-CRBM). Our method\nimproves state-of-the-art deep learning techniques for high dimensional\ntime-series modeling by introducing a novel tensor factorization capable of\ndriving forth order Boltzmann machines to considerably lower energy levels, at\nno computational costs. DFFW-CRBMs are capable of accurately estimating,\nrecognizing, and performing near-future prediction of three-dimensional\ntrajectories from their 2D projections while requiring limited amount of\nlabeled data. We evaluate our method on both simulated and real-world data,\nshowing its effectiveness in predicting and classifying complex ball\ntrajectories and human activities.\n", "versions": [{"version": "v1", "created": "Wed, 20 Apr 2016 09:08:50 GMT"}, {"version": "v2", "created": "Sat, 29 Apr 2017 06:11:10 GMT"}], "update_date": "2017-05-02", "authors_parsed": [["Mocanu", "Decebal Constantin", ""], ["Ammar", "Haitham Bou", ""], ["Puig", "Luis", ""], ["Eaton", "Eric", ""], ["Liotta", "Antonio", ""]]}, {"id": "1604.05878", "submitter": "Johannes Welbl", "authors": "Johannes Welbl, Guillaume Bouchard, Sebastian Riedel", "title": "A Factorization Machine Framework for Testing Bigram Embeddings in\n  Knowledgebase Completion", "comments": "accepted for AKBC 2016 workshop, 6pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Embedding-based Knowledge Base Completion models have so far mostly combined\ndistributed representations of individual entities or relations to compute\ntruth scores of missing links. Facts can however also be represented using\npairwise embeddings, i.e. embeddings for pairs of entities and relations. In\nthis paper we explore such bigram embeddings with a flexible Factorization\nMachine model and several ablations from it. We investigate the relevance of\nvarious bigram types on the fb15k237 dataset and find relative improvements\ncompared to a compositional model.\n", "versions": [{"version": "v1", "created": "Wed, 20 Apr 2016 09:58:56 GMT"}], "update_date": "2016-04-21", "authors_parsed": [["Welbl", "Johannes", ""], ["Bouchard", "Guillaume", ""], ["Riedel", "Sebastian", ""]]}, {"id": "1604.05942", "submitter": "Arash Tavakoli", "authors": "Arash Tavakoli, Haig Nalbandian, Nora Ayanian", "title": "Multiplayer Games for Learning Multirobot Coordination Algorithms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.HC cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Humans have an impressive ability to solve complex coordination problems in a\nfully distributed manner. This ability, if learned as a set of distributed\nmultirobot coordination strategies, can enable programming large groups of\nrobots to collaborate towards complex coordination objectives in a way similar\nto humans. Such strategies would offer robustness, adaptability,\nfault-tolerance, and, importantly, distributed decision-making. To that end, we\nhave designed a networked gaming platform to investigate human group behavior,\nspecifically in solving complex collaborative coordinated tasks. Through this\nplatform, we are able to limit the communication, sensing, and actuation\ncapabilities provided to the players. With the aim of learning coordination\nalgorithms for robots in mind, we define these capabilities to mimic those of a\nsimple ground robot.\n", "versions": [{"version": "v1", "created": "Wed, 20 Apr 2016 13:12:45 GMT"}], "update_date": "2016-04-21", "authors_parsed": [["Tavakoli", "Arash", ""], ["Nalbandian", "Haig", ""], ["Ayanian", "Nora", ""]]}, {"id": "1604.05978", "submitter": "Decebal Constantin Mocanu", "authors": "Decebal Constantin Mocanu, Elena Mocanu, Phuong H. Nguyen, Madeleine\n  Gibescu and Antonio Liotta", "title": "A topological insight into restricted Boltzmann machines", "comments": "http://link.springer.com/article/10.1007/s10994-016-5570-z, Machine\n  Learning, issn=1573-0565, 2016", "journal-ref": null, "doi": "10.1007/s10994-016-5570-z", "report-no": null, "categories": "cs.NE cs.AI cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Restricted Boltzmann Machines (RBMs) and models derived from them have been\nsuccessfully used as basic building blocks in deep artificial neural networks\nfor automatic features extraction, unsupervised weights initialization, but\nalso as density estimators. Thus, their generative and discriminative\ncapabilities, but also their computational time are instrumental to a wide\nrange of applications. Our main contribution is to look at RBMs from a\ntopological perspective, bringing insights from network science. Firstly, here\nwe show that RBMs and Gaussian RBMs (GRBMs) are bipartite graphs which\nnaturally have a small-world topology. Secondly, we demonstrate both on\nsynthetic and real-world datasets that by constraining RBMs and GRBMs to a\nscale-free topology (while still considering local neighborhoods and data\ndistribution), we reduce the number of weights that need to be computed by a\nfew orders of magnitude, at virtually no loss in generative performance.\nThirdly, we show that, for a fixed number of weights, our proposed sparse\nmodels (which by design have a higher number of hidden neurons) achieve better\ngenerative capabilities than standard fully connected RBMs and GRBMs (which by\ndesign have a smaller number of hidden neurons), at no additional computational\ncosts.\n", "versions": [{"version": "v1", "created": "Wed, 20 Apr 2016 14:35:12 GMT"}, {"version": "v2", "created": "Mon, 18 Jul 2016 20:14:41 GMT"}], "update_date": "2016-07-20", "authors_parsed": [["Mocanu", "Decebal Constantin", ""], ["Mocanu", "Elena", ""], ["Nguyen", "Phuong H.", ""], ["Gibescu", "Madeleine", ""], ["Liotta", "Antonio", ""]]}, {"id": "1604.06020", "submitter": "Stefano Teso", "authors": "Stefano Teso, Andrea Passerini, Paolo Viappiani", "title": "Constructive Preference Elicitation by Setwise Max-margin Learning", "comments": "7 pages. A conference version of this work is accepted by the 25th\n  International Joint Conference on Artificial Intelligence (IJCAI-16)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we propose an approach to preference elicitation that is\nsuitable to large configuration spaces beyond the reach of existing\nstate-of-the-art approaches. Our setwise max-margin method can be viewed as a\ngeneralization of max-margin learning to sets, and can produce a set of\n\"diverse\" items that can be used to ask informative queries to the user.\nMoreover, the approach can encourage sparsity in the parameter space, in order\nto favor the assessment of utility towards combinations of weights that\nconcentrate on just few features. We present a mixed integer linear programming\nformulation and show how our approach compares favourably with Bayesian\npreference elicitation alternatives and easily scales to realistic datasets.\n", "versions": [{"version": "v1", "created": "Wed, 20 Apr 2016 16:22:01 GMT"}], "update_date": "2016-04-21", "authors_parsed": [["Teso", "Stefano", ""], ["Passerini", "Andrea", ""], ["Viappiani", "Paolo", ""]]}, {"id": "1604.06057", "submitter": "Karthik Narasimhan", "authors": "Tejas D. Kulkarni, Karthik R. Narasimhan, Ardavan Saeedi, Joshua B.\n  Tenenbaum", "title": "Hierarchical Deep Reinforcement Learning: Integrating Temporal\n  Abstraction and Intrinsic Motivation", "comments": "14 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning goal-directed behavior in environments with sparse feedback is a\nmajor challenge for reinforcement learning algorithms. The primary difficulty\narises due to insufficient exploration, resulting in an agent being unable to\nlearn robust value functions. Intrinsically motivated agents can explore new\nbehavior for its own sake rather than to directly solve problems. Such\nintrinsic behaviors could eventually help the agent solve tasks posed by the\nenvironment. We present hierarchical-DQN (h-DQN), a framework to integrate\nhierarchical value functions, operating at different temporal scales, with\nintrinsically motivated deep reinforcement learning. A top-level value function\nlearns a policy over intrinsic goals, and a lower-level function learns a\npolicy over atomic actions to satisfy the given goals. h-DQN allows for\nflexible goal specifications, such as functions over entities and relations.\nThis provides an efficient space for exploration in complicated environments.\nWe demonstrate the strength of our approach on two problems with very sparse,\ndelayed feedback: (1) a complex discrete stochastic decision process, and (2)\nthe classic ATARI game `Montezuma's Revenge'.\n", "versions": [{"version": "v1", "created": "Wed, 20 Apr 2016 18:47:48 GMT"}, {"version": "v2", "created": "Tue, 31 May 2016 14:45:58 GMT"}], "update_date": "2016-06-01", "authors_parsed": [["Kulkarni", "Tejas D.", ""], ["Narasimhan", "Karthik R.", ""], ["Saeedi", "Ardavan", ""], ["Tenenbaum", "Joshua B.", ""]]}, {"id": "1604.06076", "submitter": "Daniel Khashabi Mr.", "authors": "Daniel Khashabi, Tushar Khot, Ashish Sabharwal, Peter Clark, Oren\n  Etzioni and Dan Roth", "title": "Question Answering via Integer Programming over Semi-Structured\n  Knowledge", "comments": "Extended version of the paper accepted to IJCAI'16", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Answering science questions posed in natural language is an important AI\nchallenge. Answering such questions often requires non-trivial inference and\nknowledge that goes beyond factoid retrieval. Yet, most systems for this task\nare based on relatively shallow Information Retrieval (IR) and statistical\ncorrelation techniques operating on large unstructured corpora. We propose a\nstructured inference system for this task, formulated as an Integer Linear\nProgram (ILP), that answers natural language questions using a semi-structured\nknowledge base derived from text, including questions requiring multi-step\ninference and a combination of multiple facts. On a dataset of real, unseen\nscience questions, our system significantly outperforms (+14%) the best\nprevious attempt at structured reasoning for this task, which used Markov Logic\nNetworks (MLNs). It also improves upon a previous ILP formulation by 17.7%.\nWhen combined with unstructured inference methods, the ILP system significantly\nboosts overall performance (+10%). Finally, we show our approach is\nsubstantially more robust to a simple answer perturbation compared to\nstatistical correlation methods.\n", "versions": [{"version": "v1", "created": "Wed, 20 Apr 2016 19:48:07 GMT"}], "update_date": "2016-04-21", "authors_parsed": [["Khashabi", "Daniel", ""], ["Khot", "Tushar", ""], ["Sabharwal", "Ashish", ""], ["Clark", "Peter", ""], ["Etzioni", "Oren", ""], ["Roth", "Dan", ""]]}, {"id": "1604.06223", "submitter": "Yohanes Khosiawan", "authors": "Yohanes Khosiawan, Young Soo Park, Ilkyeong Moon, Janardhanan Mukund\n  Nilakantan, Izabela Nielsen", "title": "Task scheduling system for UAV operations in indoor environment", "comments": null, "journal-ref": null, "doi": "10.1007/s00521-018-3373-9", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Application of UAV in indoor environment is emerging nowadays due to the\nadvancements in technology. UAV brings more space-flexibility in an occupied or\nhardly-accessible indoor environment, e.g., shop floor of manufacturing\nindustry, greenhouse, nuclear powerplant. UAV helps in creating an autonomous\nmanufacturing system by executing tasks with less human intervention in\ntime-efficient manner. Consequently, a scheduler is one essential component to\nbe focused on; yet the number of reported studies on UAV scheduling has been\nminimal. This work proposes a methodology with a heuristic (based on Earliest\nAvailable Time algorithm) which assigns tasks to UAVs with an objective of\nminimizing the makespan. In addition, a quick response towards uncertain events\nand a quick creation of new high-quality feasible schedule are needed. Hence,\nthe proposed heuristic is incorporated with Particle Swarm Optimization (PSO)\nalgorithm to find a quick near optimal schedule. This proposed methodology is\nimplemented into a scheduler and tested on a few scales of datasets generated\nbased on a real flight demonstration. Performance evaluation of scheduler is\ndiscussed in detail and the best solution obtained from a selected set of\nparameters is reported.\n", "versions": [{"version": "v1", "created": "Thu, 21 Apr 2016 09:21:21 GMT"}], "update_date": "2018-03-06", "authors_parsed": [["Khosiawan", "Yohanes", ""], ["Park", "Young Soo", ""], ["Moon", "Ilkyeong", ""], ["Nilakantan", "Janardhanan Mukund", ""], ["Nielsen", "Izabela", ""]]}, {"id": "1604.06356", "submitter": "Marija Slavkovik", "authors": "Marija Slavkovik and Wojciech Jamroga", "title": "Iterative Judgment Aggregation", "comments": null, "journal-ref": null, "doi": "10.3233/978-1-61499-672-9-1528", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Judgment aggregation problems form a class of collective decision-making\nproblems represented in an abstract way, subsuming some well known problems\nsuch as voting. A collective decision can be reached in many ways, but a direct\none-step aggregation of individual decisions is arguably most studied. Another\nway to reach collective decisions is by iterative consensus building --\nallowing each decision-maker to change their individual decision in response to\nthe choices of the other agents until a consensus is reached. Iterative\nconsensus building has so far only been studied for voting problems. Here we\npropose an iterative judgment aggregation algorithm, based on movements in an\nundirected graph, and we study for which instances it terminates with a\nconsensus. We also compare the computational complexity of our iterative\nprocedure with that of related judgment aggregation operators.\n", "versions": [{"version": "v1", "created": "Thu, 21 Apr 2016 15:26:02 GMT"}, {"version": "v2", "created": "Fri, 22 Apr 2016 14:08:06 GMT"}, {"version": "v3", "created": "Tue, 12 Jul 2016 12:36:46 GMT"}], "update_date": "2016-08-30", "authors_parsed": [["Slavkovik", "Marija", ""], ["Jamroga", "Wojciech", ""]]}, {"id": "1604.06484", "submitter": "Jean-Charles Regin", "authors": "Anthony Palmieri and Jean-Charles R\\'egin and Pierre Schaus", "title": "Parallel Strategies Selection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of selecting the best variable-value strategy for\nsolving a given problem in constraint programming. We show that the recent\nEmbarrassingly Parallel Search method (EPS) can be used for this purpose. EPS\nproposes to solve a problem by decomposing it in a lot of subproblems and to\ngive them on-demand to workers which run in parallel. Our method uses a part of\nthese subproblems as a simple sample as defined in statistics for comparing\nsome strategies in order to select the most promising one that will be used for\nsolving the remaining subproblems. For each subproblem of the sample, the\nparallelism helps us to control the running time of the strategies because it\ngives us the possibility to introduce timeouts by stopping a strategy when it\nrequires more than twice the time of the best one. Thus, we can deal with the\ngreat disparity in solving times for the strategies. The selections we made are\nbased on the Wilcoxon signed rank tests because no assumption has to be made on\nthe distribution of the solving times and because these tests can deal with the\ncensored data that we obtain after introducing timeouts. The experiments we\nperformed on a set of classical benchmarks for satisfaction and optimization\nproblems show that our method obtain good performance by selecting almost all\nthe time the best variable-value strategy and by almost never choosing a\nvariable-value strategy which is dramatically slower than the best one. Our\nmethod also outperforms the portfolio approach consisting in running some\nstrategies in parallel and is competitive with the multi armed bandit\nframework.\n", "versions": [{"version": "v1", "created": "Thu, 21 Apr 2016 20:40:35 GMT"}], "update_date": "2016-04-25", "authors_parsed": [["Palmieri", "Anthony", ""], ["R\u00e9gin", "Jean-Charles", ""], ["Schaus", "Pierre", ""]]}, {"id": "1604.06614", "submitter": "Marija Slavkovik", "authors": "J\\'er\\^ome Lang and Marija Slavkovik and Srdjan Vesic", "title": "Agenda Separability in Judgment Aggregation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the better studied properties for operators in judgment aggregation is\nindependence, which essentially dictates that the collective judgment on one\nissue should not depend on the individual judgments given on some other\nissue(s) in the same agenda. Independence, although considered a desirable\nproperty, is too strong, because together with mild additional conditions it\nimplies dictatorship. We propose here a weakening of independence, named agenda\nseparability: a judgment aggregation rule satisfies it if, whenever the agenda\nis composed of several independent sub-agendas, the resulting collective\njudgment sets can be computed separately for each sub-agenda and then put\ntogether. We show that this property is discriminant, in the sense that among\njudgment aggregation rules so far studied in the literature, some satisfy it\nand some do not. We briefly discuss the implications of agenda separability on\nthe computation of judgment aggregation rules.\n", "versions": [{"version": "v1", "created": "Fri, 22 Apr 2016 11:53:37 GMT"}], "update_date": "2016-04-25", "authors_parsed": [["Lang", "J\u00e9r\u00f4me", ""], ["Slavkovik", "Marija", ""], ["Vesic", "Srdjan", ""]]}, {"id": "1604.06635", "submitter": "Xipeng Qiu", "authors": "Peng Qian, Xipeng Qiu, Xuanjing Huang", "title": "Bridging LSTM Architecture and the Neural Dynamics during Reading", "comments": "25th International Joint Conference on Artificial Intelligence\n  IJCAI-16", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, the long short-term memory neural network (LSTM) has attracted wide\ninterest due to its success in many tasks. LSTM architecture consists of a\nmemory cell and three gates, which looks similar to the neuronal networks in\nthe brain. However, there still lacks the evidence of the cognitive\nplausibility of LSTM architecture as well as its working mechanism. In this\npaper, we study the cognitive plausibility of LSTM by aligning its internal\narchitecture with the brain activity observed via fMRI when the subjects read a\nstory. Experiment results show that the artificial memory vector in LSTM can\naccurately predict the observed sequential brain activities, indicating the\ncorrelation between LSTM architecture and the cognitive process of story\nreading.\n", "versions": [{"version": "v1", "created": "Fri, 22 Apr 2016 12:51:11 GMT"}], "update_date": "2016-04-25", "authors_parsed": [["Qian", "Peng", ""], ["Qiu", "Xipeng", ""], ["Huang", "Xuanjing", ""]]}, {"id": "1604.06641", "submitter": "Pierre Schaus", "authors": "Jordan Demeulenaere, Renaud Hartert, Christophe Lecoutre, Guillaume\n  Perez, Laurent Perron, Jean-Charles R\\'egin, Pierre Schaus", "title": "Compact-Table: Efficiently Filtering Table Constraints with Reversible\n  Sparse Bit-Sets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we describe Compact-Table (CT), a bitwise algorithm to enforce\nGeneralized Arc Consistency (GAC) on table con- straints. Although this\nalgorithm is the default propagator for table constraints in or-tools and\nOscaR, two publicly available CP solvers, it has never been described so far.\nImportantly, CT has been recently improved further with the introduction of\nresidues, resetting operations and a data-structure called reversible sparse\nbit-set, used to maintain tables of supports (following the idea of tabular\nreduction): tuples are invalidated incrementally on value removals by means of\nbit-set operations. The experimentation that we have conducted with OscaR shows\nthat CT outperforms state-of-the-art algorithms STR2, STR3, GAC4R, MDD4R and\nAC5-TC on standard benchmarks.\n", "versions": [{"version": "v1", "created": "Fri, 22 Apr 2016 13:12:38 GMT"}], "update_date": "2016-04-25", "authors_parsed": [["Demeulenaere", "Jordan", ""], ["Hartert", "Renaud", ""], ["Lecoutre", "Christophe", ""], ["Perez", "Guillaume", ""], ["Perron", "Laurent", ""], ["R\u00e9gin", "Jean-Charles", ""], ["Schaus", "Pierre", ""]]}, {"id": "1604.06710", "submitter": "Mason Wright", "authors": "Mason Wright", "title": "Using Reinforcement Learning to Validate Empirical Game-Theoretic\n  Analysis: A Continuous Double Auction Study", "comments": "technical report, 37 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Empirical game-theoretic analysis (EGTA) has recently been applied\nsuccessfully to analyze the behavior of large numbers of competing traders in a\ncontinuous double auction market. Multiagent simulation methods like EGTA are\nuseful for studying complex strategic environments like a stock market, where\nit is not feasible to solve analytically for the rational behavior of each\nagent. A weakness of simulation-based methods in strategic settings, however,\nis that it is typically impossible to prove that the strategy profile assigned\nto the simulated agents is stable, as in a Nash equilibrium. I propose using\nreinforcement learning to analyze the regret of supposed Nash-equilibrium\nstrategy profiles found by EGTA. I have developed a new library of\nreinforcement learning tools, which I have integrated into an extended version\nof the market simulator from our prior work. I provide evidence for the\neffectiveness of our library methods, both on a suite of benchmark problems\nfrom the literature, and on non-equilibrium strategy profiles in our market\nenvironment. Finally, I use our new reinforcement learning tools to provide\nevidence that the equilibria found by EGTA in our recent continuous double\nauction study are likely to have only negligible regret, even with respect to\nan extended strategy space.\n", "versions": [{"version": "v1", "created": "Fri, 22 Apr 2016 15:23:27 GMT"}], "update_date": "2016-04-25", "authors_parsed": [["Wright", "Mason", ""]]}, {"id": "1604.06715", "submitter": "Stefan Mengel", "authors": "Stefan Mengel", "title": "Parameterized Compilation Lower Bounds for Restricted CNF-formulas", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show unconditional parameterized lower bounds in the area of knowledge\ncompilation, more specifically on the size of circuits in decomposable negation\nnormal form (DNNF) that encode CNF-formulas restricted by several graph width\nmeasures. In particular, we show that\n  - there are CNF formulas of size $n$ and modular incidence treewidth $k$\nwhose smallest DNNF-encoding has size $n^{\\Omega(k)}$, and\n  - there are CNF formulas of size $n$ and incidence neighborhood diversity $k$\nwhose smallest DNNF-encoding has size $n^{\\Omega(\\sqrt{k})}$.\n  These results complement recent upper bounds for compiling CNF into DNNF and\nstrengthen---quantitatively and qualitatively---known conditional low\\-er\nbounds for cliquewidth. Moreover, they show that, unlike for many graph\nproblems, the parameters considered here behave significantly differently from\ntreewidth.\n", "versions": [{"version": "v1", "created": "Fri, 22 Apr 2016 15:37:14 GMT"}], "update_date": "2016-04-25", "authors_parsed": [["Mengel", "Stefan", ""]]}, {"id": "1604.06721", "submitter": "Manfred Eppe", "authors": "Manfred Eppe, Sean Trott, Jerome Feldman", "title": "Exploiting Deep Semantics and Compositionality of Natural Language for\n  Human-Robot-Interaction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a natural language interface for human robot interaction that\nimplements reasoning about deep semantics in natural language. To realize the\nrequired deep analysis, we employ methods from cognitive linguistics, namely\nthe modular and compositional framework of Embodied Construction Grammar (ECG)\n[Feldman, 2009]. Using ECG, robots are able to solve fine-grained reference\nresolution problems and other issues related to deep semantics and\ncompositionality of natural language. This also includes verbal interaction\nwith humans to clarify commands and queries that are too ambiguous to be\nexecuted safely. We implement our NLU framework as a ROS package and present\nproof-of-concept scenarios with different robots, as well as a survey on the\nstate of the art.\n", "versions": [{"version": "v1", "created": "Fri, 22 Apr 2016 15:58:18 GMT"}], "update_date": "2016-04-25", "authors_parsed": [["Eppe", "Manfred", ""], ["Trott", "Sean", ""], ["Feldman", "Jerome", ""]]}, {"id": "1604.06743", "submitter": "Li Zhou", "authors": "Li Zhou and Emma Brunskill", "title": "Latent Contextual Bandits and their Application to Personalized\n  Recommendations for New Users", "comments": "25th International Joint Conference on Artificial Intelligence (IJCAI\n  2016)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Personalized recommendations for new users, also known as the cold-start\nproblem, can be formulated as a contextual bandit problem. Existing contextual\nbandit algorithms generally rely on features alone to capture user variability.\nSuch methods are inefficient in learning new users' interests. In this paper we\npropose Latent Contextual Bandits. We consider both the benefit of leveraging a\nset of learned latent user classes for new users, and how we can learn such\nlatent classes from prior users. We show that our approach achieves a better\nregret bound than existing algorithms. We also demonstrate the benefit of our\napproach using a large real world dataset and a preliminary user study.\n", "versions": [{"version": "v1", "created": "Fri, 22 Apr 2016 16:47:04 GMT"}], "update_date": "2016-04-25", "authors_parsed": [["Zhou", "Li", ""], ["Brunskill", "Emma", ""]]}, {"id": "1604.06770", "submitter": "Mostafa Milani", "authors": "Mostafa Milani, Andrea Cali, Leopoldo Bertossi", "title": "A Hybrid Approach to Query Answering under Expressive Datalog+/-", "comments": "Extended version of RR'16 paper, to appear", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Datalog+/- is a family of ontology languages that combine good computational\nproperties with high expressive power. Datalog+/- languages are provably able\nto capture the most relevant Semantic Web languages. In this paper we consider\nthe class of weakly-sticky (WS) Datalog+/- programs, which allow for certain\nuseful forms of joins in rule bodies as well as extending the well-known class\nof weakly-acyclic TGDs. So far, only non-deterministic algorithms were known\nfor answering queries on WS Datalog+/- programs. We present novel deterministic\nquery answering algorithms under WS Datalog+/-. In particular, we propose: (1)\na bottom-up grounding algorithm based on a query-driven chase, and (2) a hybrid\napproach based on transforming a WS program into a so-called sticky one, for\nwhich query rewriting techniques are known. We discuss how our algorithms can\nbe optimized and effectively applied for query answering in real-world\nscenarios.\n", "versions": [{"version": "v1", "created": "Fri, 22 Apr 2016 18:46:10 GMT"}, {"version": "v2", "created": "Mon, 25 Jul 2016 18:22:01 GMT"}], "update_date": "2016-07-26", "authors_parsed": [["Milani", "Mostafa", ""], ["Cali", "Andrea", ""], ["Bertossi", "Leopoldo", ""]]}, {"id": "1604.06778", "submitter": "Yan Duan", "authors": "Yan Duan, Xi Chen, Rein Houthooft, John Schulman, Pieter Abbeel", "title": "Benchmarking Deep Reinforcement Learning for Continuous Control", "comments": "14 pages, ICML 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, researchers have made significant progress combining the advances\nin deep learning for learning feature representations with reinforcement\nlearning. Some notable examples include training agents to play Atari games\nbased on raw pixel data and to acquire advanced manipulation skills using raw\nsensory inputs. However, it has been difficult to quantify progress in the\ndomain of continuous control due to the lack of a commonly adopted benchmark.\nIn this work, we present a benchmark suite of continuous control tasks,\nincluding classic tasks like cart-pole swing-up, tasks with very high state and\naction dimensionality such as 3D humanoid locomotion, tasks with partial\nobservations, and tasks with hierarchical structure. We report novel findings\nbased on the systematic evaluation of a range of implemented reinforcement\nlearning algorithms. Both the benchmark and reference implementations are\nreleased at https://github.com/rllab/rllab in order to facilitate experimental\nreproducibility and to encourage adoption by other researchers.\n", "versions": [{"version": "v1", "created": "Fri, 22 Apr 2016 18:57:24 GMT"}, {"version": "v2", "created": "Mon, 25 Apr 2016 06:16:06 GMT"}, {"version": "v3", "created": "Fri, 27 May 2016 19:25:59 GMT"}], "update_date": "2016-05-30", "authors_parsed": [["Duan", "Yan", ""], ["Chen", "Xi", ""], ["Houthooft", "Rein", ""], ["Schulman", "John", ""], ["Abbeel", "Pieter", ""]]}, {"id": "1604.06787", "submitter": "Julien Savaux", "authors": "Julien Savaux, Julien Vion, Sylvain Piechowiak, Ren\\'e Mandiau,\n  Toshihiro Matsui, Katsutoshi Hirayama, Makoto Yokoo, Shakre Elmane, Marius\n  Silaghi", "title": "Utilitarian Distributed Constraint Optimization Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Privacy has been a major motivation for distributed problem optimization.\nHowever, even though several methods have been proposed to evaluate it, none of\nthem is widely used. The Distributed Constraint Optimization Problem (DCOP) is\na fundamental model used to approach various families of distributed problems.\nAs privacy loss does not occur when a solution is accepted, but when it is\nproposed, privacy requirements cannot be interpreted as a criteria of the\nobjective function of the DCOP. Here we approach the problem by letting both\nthe optimized costs found in DCOPs and the privacy requirements guide the\nagents' exploration of the search space. We introduce Utilitarian Distributed\nConstraint Optimization Problem (UDCOP) where the costs and the privacy\nrequirements are used as parameters to a heuristic modifying the search\nprocess. Common stochastic algorithms for decentralized constraint optimization\nproblems are evaluated here according to how well they preserve privacy.\nFurther, we propose some extensions where these solvers modify their search\nprocess to take into account their privacy requirements, succeeding in\nsignificantly reducing their privacy loss without significant degradation of\nthe solution quality.\n", "versions": [{"version": "v1", "created": "Fri, 22 Apr 2016 19:26:30 GMT"}], "update_date": "2016-04-25", "authors_parsed": [["Savaux", "Julien", ""], ["Vion", "Julien", ""], ["Piechowiak", "Sylvain", ""], ["Mandiau", "Ren\u00e9", ""], ["Matsui", "Toshihiro", ""], ["Hirayama", "Katsutoshi", ""], ["Yokoo", "Makoto", ""], ["Elmane", "Shakre", ""], ["Silaghi", "Marius", ""]]}, {"id": "1604.06790", "submitter": "Julien Savaux", "authors": "Julien Savaux, Julien Vion, Sylvain Piechowiak, Ren\\'e Mandiau,\n  Toshihiro Matsui, Katsutoshi Hirayama, Makoto Yokoo, Shakre Elmane, Marius\n  Silaghi", "title": "DisCSPs with Privacy Recast as Planning Problems for Utility-based\n  Agents", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Privacy has traditionally been a major motivation for decentralized problem\nsolving. However, even though several metrics have been proposed to quantify\nit, none of them is easily integrated with common solvers. Constraint\nprogramming is a fundamental paradigm used to approach various families of\nproblems. We introduce Utilitarian Distributed Constraint Satisfaction Problems\n(UDisCSP) where the utility of each state is estimated as the difference\nbetween the the expected rewards for agreements on assignments for shared\nvariables, and the expected cost of privacy loss. Therefore, a traditional\nDisCSP with privacy requirements is viewed as a planning problem. The actions\navailable to agents are: communication and local inference. Common\ndecentralized solvers are evaluated here from the point of view of their\ninterpretation as greedy planners. Further, we investigate some simple\nextensions where these solvers start taking into account the utility function.\nIn these extensions we assume that the planning problem is further restricting\nthe set of communication actions to only the communication primitives present\nin the corresponding solver protocols. The solvers obtained for the new type of\nproblems propose the action (communication/inference) to be performed in each\nsituation, defining thereby the policy.\n", "versions": [{"version": "v1", "created": "Fri, 22 Apr 2016 19:35:49 GMT"}], "update_date": "2016-04-25", "authors_parsed": [["Savaux", "Julien", ""], ["Vion", "Julien", ""], ["Piechowiak", "Sylvain", ""], ["Mandiau", "Ren\u00e9", ""], ["Matsui", "Toshihiro", ""], ["Hirayama", "Katsutoshi", ""], ["Yokoo", "Makoto", ""], ["Elmane", "Shakre", ""], ["Silaghi", "Marius", ""]]}, {"id": "1604.06849", "submitter": "Shiwali Mohan", "authors": "Shiwali Mohan, James Kirk, John Laird", "title": "A Computational Model for Situated Task Learning with Interactive\n  Instruction", "comments": "International Conference on Cognitive Modeling, 2013", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning novel tasks is a complex cognitive activity requiring the learner to\nacquire diverse declarative and procedural knowledge. Prior ACT-R models of\nacquiring task knowledge from instruction focused on learning procedural\nknowledge from declarative instructions encoded in semantic memory. In this\npaper, we identify the requirements for designing compu- tational models that\nlearn task knowledge from situated task- oriented interactions with an expert\nand then describe and evaluate a model of learning from situated interactive\ninstruc- tion that is implemented in the Soar cognitive architecture.\n", "versions": [{"version": "v1", "created": "Sat, 23 Apr 2016 02:23:14 GMT"}], "update_date": "2016-04-26", "authors_parsed": [["Mohan", "Shiwali", ""], ["Kirk", "James", ""], ["Laird", "John", ""]]}, {"id": "1604.06954", "submitter": "Santiago Ontanon", "authors": "Santiago Onta\\~n\\'on", "title": "RHOG: A Refinement-Operator Library for Directed Labeled Graphs", "comments": "Report of the theory behind the RHOG library developed under NSF\n  EAGER grant IIS-1551338", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This document provides the foundations behind the functionality provided by\nthe $\\rho$G library (https://github.com/santiontanon/RHOG), focusing on the\nbasic operations the library provides: subsumption, refinement of directed\nlabeled graphs, and distance/similarity assessment between directed labeled\ngraphs. $\\rho$G development was initially supported by the National Science\nFoundation, by the EAGER grant IIS-1551338.\n", "versions": [{"version": "v1", "created": "Sat, 23 Apr 2016 21:03:45 GMT"}, {"version": "v2", "created": "Sat, 18 Apr 2020 23:39:45 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Onta\u00f1\u00f3n", "Santiago", ""]]}, {"id": "1604.06963", "submitter": "David Jilk", "authors": "David J. Jilk", "title": "Limits to Verification and Validation of Agentic Behavior", "comments": "13 pages, 0 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Verification and validation of agentic behavior have been suggested as\nimportant research priorities in efforts to reduce risks associated with the\ncreation of general artificial intelligence (Russell et al 2015). In this paper\nwe question the appropriateness of using language of certainty with respect to\nefforts to manage that risk. We begin by establishing a very general formalism\nto characterize agentic behavior and to describe standards of acceptable\nbehavior. We show that determination of whether an agent meets any particular\nstandard is not computable. We discuss the extent of the burden associated with\nverification by manual proof and by automated behavioral governance. We show\nthat to ensure decidability of the behavioral standard itself, one must further\nlimit the capabilities of the agent. We then demonstrate that if our concerns\nrelate to outcomes in the physical world, attempts at validation are futile.\nFinally, we show that layered architectures aimed at making these challenges\ntractable mistakenly equate intentions with actions or outcomes, thereby\nfailing to provide any guarantees. We conclude with a discussion of why\nlanguage of certainty should be eradicated from the conversation about the\nsafety of general artificial intelligence.\n", "versions": [{"version": "v1", "created": "Sat, 23 Apr 2016 23:01:29 GMT"}, {"version": "v2", "created": "Mon, 10 Oct 2016 22:21:25 GMT"}], "update_date": "2016-10-12", "authors_parsed": [["Jilk", "David J.", ""]]}, {"id": "1604.06970", "submitter": "Clayton Morrison", "authors": "Ernesto Brau, Colin Dawson, Alfredo Carrillo, David Sidi and Clayton\n  T. Morrison", "title": "Bayesian Inference of Recursive Sequences of Group Activities from\n  Tracks", "comments": "10 pages, 6 figures, in Proceedings of the 30th AAAI Conference on\n  Artificial Intelligence (AAAI'16), Phoenix, AZ, 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a probabilistic generative model for inferring a description of\ncoordinated, recursively structured group activities at multiple levels of\ntemporal granularity based on observations of individuals' trajectories. The\nmodel accommodates: (1) hierarchically structured groups, (2) activities that\nare temporally and compositionally recursive, (3) component roles assigning\ndifferent subactivity dynamics to subgroups of participants, and (4) a\nnonparametric Gaussian Process model of trajectories. We present an MCMC\nsampling framework for performing joint inference over recursive activity\ndescriptions and assignment of trajectories to groups, integrating out\ncontinuous parameters. We demonstrate the model's expressive power in several\nsimulated and complex real-world scenarios from the VIRAT and UCLA Aerial Event\nvideo data sets.\n", "versions": [{"version": "v1", "created": "Sun, 24 Apr 2016 00:55:27 GMT"}], "update_date": "2016-04-26", "authors_parsed": [["Brau", "Ernesto", ""], ["Dawson", "Colin", ""], ["Carrillo", "Alfredo", ""], ["Sidi", "David", ""], ["Morrison", "Clayton T.", ""]]}, {"id": "1604.06976", "submitter": "Mahyuddin K. M.  Nasution", "authors": "Mahyuddin K. M. Nasution", "title": "Extracted Social Network Mining", "comments": "6 pages. Proceeding of International Conference on Information\n  Technology and Engineering Application (5-th ICIBA), 86-91, February 19-20,\n  2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.AI", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  In this paper we study the relationship between the resources of social\nnetworks by exploring the Web as big data based on a simple search engine. We\nhave used set theory by utilizing the occurrence and co-occurrence for defining\nthe singleton or doubleton spaces of event in a search engine model, and then\nprovided them as representation of social actors and their relationship in\nclusters. Thus, there are behaviors of social actors and their relation based\non Web.\n", "versions": [{"version": "v1", "created": "Sun, 24 Apr 2016 02:39:16 GMT"}], "update_date": "2016-04-26", "authors_parsed": [["Nasution", "Mahyuddin K. M.", ""]]}, {"id": "1604.07063", "submitter": "Clement Carbonnel", "authors": "Cl\\'ement Carbonnel", "title": "The Dichotomy for Conservative Constraint Satisfaction is Polynomially\n  Decidable", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a fixed constraint language $\\Gamma$, the conservative CSP over\n$\\Gamma$ (denoted by c-CSP($\\Gamma$)) is a variant of CSP($\\Gamma$) where the\ndomain of each variable can be restricted arbitrarily. A dichotomy is known for\nconservative CSP: for every fixed language $\\Gamma$, c-CSP($\\Gamma$) is either\nin P or NP-complete. However, the characterization of conservatively tractable\nlanguages is of algebraic nature and the naive recognition algorithm is\nsuper-exponential in the domain size. The main contribution of this paper is a\npolynomial-time algorithm that, given a constraint language $\\Gamma$ as input,\ndecides if c-CSP($\\Gamma$) is tractable. In addition, if $\\Gamma$ is proven\ntractable the algorithm also outputs its coloured graph, which contains\nvaluable information on the structure of $\\Gamma$.\n", "versions": [{"version": "v1", "created": "Sun, 24 Apr 2016 17:56:44 GMT"}, {"version": "v2", "created": "Mon, 20 Jun 2016 13:43:50 GMT"}], "update_date": "2016-06-21", "authors_parsed": [["Carbonnel", "Cl\u00e9ment", ""]]}, {"id": "1604.07093", "submitter": "Yanwei  Fu", "authors": "Yanwei Fu, Leonid Sigal", "title": "Semi-supervised Vocabulary-informed Learning", "comments": "10 pages, Accepted by CVPR 2016 as an oral presentation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite significant progress in object categorization, in recent years, a\nnumber of important challenges remain, mainly, ability to learn from limited\nlabeled data and ability to recognize object classes within large, potentially\nopen, set of labels. Zero-shot learning is one way of addressing these\nchallenges, but it has only been shown to work with limited sized class\nvocabularies and typically requires separation between supervised and\nunsupervised classes, allowing former to inform the latter but not vice versa.\nWe propose the notion of semi-supervised vocabulary-informed learning to\nalleviate the above mentioned challenges and address problems of supervised,\nzero-shot and open set recognition using a unified framework. Specifically, we\npropose a maximum margin framework for semantic manifold-based recognition that\nincorporates distance constraints from (both supervised and unsupervised)\nvocabulary atoms, ensuring that labeled samples are projected closest to their\ncorrect prototypes, in the embedding space, than to others. We show that\nresulting model shows improvements in supervised, zero-shot, and large open set\nrecognition, with up to 310K class vocabulary on AwA and ImageNet datasets.\n", "versions": [{"version": "v1", "created": "Sun, 24 Apr 2016 23:36:36 GMT"}], "update_date": "2016-04-26", "authors_parsed": [["Fu", "Yanwei", ""], ["Sigal", "Leonid", ""]]}, {"id": "1604.07095", "submitter": "Xiaoxiao Guo", "authors": "Xiaoxiao Guo, Satinder Singh, Richard Lewis and Honglak Lee", "title": "Deep Learning for Reward Design to Improve Monte Carlo Tree Search in\n  ATARI Games", "comments": "In 25th International Joint Conference on Artificial Intelligence\n  (IJCAI), 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Monte Carlo Tree Search (MCTS) methods have proven powerful in planning for\nsequential decision-making problems such as Go and video games, but their\nperformance can be poor when the planning depth and sampling trajectories are\nlimited or when the rewards are sparse. We present an adaptation of PGRD\n(policy-gradient for reward-design) for learning a reward-bonus function to\nimprove UCT (a MCTS algorithm). Unlike previous applications of PGRD in which\nthe space of reward-bonus functions was limited to linear functions of\nhand-coded state-action-features, we use PGRD with a multi-layer convolutional\nneural network to automatically learn features from raw perception as well as\nto adapt the non-linear reward-bonus function parameters. We also adopt a\nvariance-reducing gradient method to improve PGRD's performance. The new method\nimproves UCT's performance on multiple ATARI games compared to UCT without the\nreward bonus. Combining PGRD and Deep Learning in this way should make adapting\nrewards for MCTS algorithms far more widely and practically applicable than\nbefore.\n", "versions": [{"version": "v1", "created": "Sun, 24 Apr 2016 23:51:18 GMT"}], "update_date": "2016-04-26", "authors_parsed": [["Guo", "Xiaoxiao", ""], ["Singh", "Satinder", ""], ["Lewis", "Richard", ""], ["Lee", "Honglak", ""]]}, {"id": "1604.07097", "submitter": "Kenneth Young", "authors": "Kenny Young, Ryan Hayward, Gautham Vasan", "title": "Neurohex: A Deep Q-learning Hex Agent", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  DeepMind's recent spectacular success in using deep convolutional neural nets\nand machine learning to build superhuman level agents --- e.g. for Atari games\nvia deep Q-learning and for the game of Go via Reinforcement Learning ---\nraises many questions, including to what extent these methods will succeed in\nother domains. In this paper we consider DQL for the game of Hex: after\nsupervised initialization, we use selfplay to train NeuroHex, an 11-layer CNN\nthat plays Hex on the 13x13 board. Hex is the classic two-player alternate-turn\nstone placement game played on a rhombus of hexagonal cells in which the winner\nis whomever connects their two opposing sides. Despite the large action and\nstate space, our system trains a Q-network capable of strong play with no\nsearch. After two weeks of Q-learning, NeuroHex achieves win-rates of 20.4% as\nfirst player and 2.1% as second player against a 1-second/move version of\nMoHex, the current ICGA Olympiad Hex champion. Our data suggests further\nimprovement might be possible with more training time.\n", "versions": [{"version": "v1", "created": "Sun, 24 Apr 2016 23:56:37 GMT"}, {"version": "v2", "created": "Tue, 26 Apr 2016 02:26:14 GMT"}], "update_date": "2016-04-27", "authors_parsed": [["Young", "Kenny", ""], ["Hayward", "Ryan", ""], ["Vasan", "Gautham", ""]]}, {"id": "1604.07102", "submitter": "Wei Wang", "authors": "Si Liu, Xinyu Ou, Ruihe Qian, Wei Wang, Xiaochun Cao", "title": "Makeup like a superstar: Deep Localized Makeup Transfer Network", "comments": "7pages, 11 figures, to appear in IJCAI 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a novel Deep Localized Makeup Transfer Network to\nautomatically recommend the most suitable makeup for a female and synthesis the\nmakeup on her face. Given a before-makeup face, her most suitable makeup is\ndetermined automatically. Then, both the beforemakeup and the reference faces\nare fed into the proposed Deep Transfer Network to generate the after-makeup\nface. Our end-to-end makeup transfer network have several nice properties\nincluding: (1) with complete functions: including foundation, lip gloss, and\neye shadow transfer; (2) cosmetic specific: different cosmetics are transferred\nin different manners; (3) localized: different cosmetics are applied on\ndifferent facial regions; (4) producing naturally looking results without\nobvious artifacts; (5) controllable makeup lightness: various results from\nlight makeup to heavy makeup can be generated. Qualitative and quantitative\nexperiments show that our network performs much better than the methods of [Guo\nand Sim, 2009] and two variants of NerualStyle [Gatys et al., 2015a].\n", "versions": [{"version": "v1", "created": "Mon, 25 Apr 2016 01:01:51 GMT"}], "update_date": "2016-04-26", "authors_parsed": [["Liu", "Si", ""], ["Ou", "Xinyu", ""], ["Qian", "Ruihe", ""], ["Wang", "Wei", ""], ["Cao", "Xiaochun", ""]]}, {"id": "1604.07176", "submitter": "Zhen Li", "authors": "Zhen Li and Yizhou Yu", "title": "Protein Secondary Structure Prediction Using Cascaded Convolutional and\n  Recurrent Neural Networks", "comments": "8 pages, 3 figures, Accepted by International Joint Conferences on\n  Artificial Intelligence (IJCAI)", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.BM cs.AI cs.LG cs.NE q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Protein secondary structure prediction is an important problem in\nbioinformatics. Inspired by the recent successes of deep neural networks, in\nthis paper, we propose an end-to-end deep network that predicts protein\nsecondary structures from integrated local and global contextual features. Our\ndeep architecture leverages convolutional neural networks with different kernel\nsizes to extract multiscale local contextual features. In addition, considering\nlong-range dependencies existing in amino acid sequences, we set up a\nbidirectional neural network consisting of gated recurrent unit to capture\nglobal contextual features. Furthermore, multi-task learning is utilized to\npredict secondary structure labels and amino-acid solvent accessibility\nsimultaneously. Our proposed deep network demonstrates its effectiveness by\nachieving state-of-the-art performance, i.e., 69.7% Q8 accuracy on the public\nbenchmark CB513, 76.9% Q8 accuracy on CASP10 and 73.1% Q8 accuracy on CASP11.\nOur model and results are publicly available.\n", "versions": [{"version": "v1", "created": "Mon, 25 Apr 2016 09:17:18 GMT"}], "update_date": "2016-04-27", "authors_parsed": [["Li", "Zhen", ""], ["Yu", "Yizhou", ""]]}, {"id": "1604.07178", "submitter": "Muhammad Yousefnezhad", "authors": "Muhammad Yousefnezhad, Daoqiang Zhang", "title": "Weighted Spectral Cluster Ensemble", "comments": "IEEE International Conference on Data Mining (ICDM), 2015", "journal-ref": null, "doi": "10.1109/ICDM.2015.145", "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Clustering explores meaningful patterns in the non-labeled data sets. Cluster\nEnsemble Selection (CES) is a new approach, which can combine individual\nclustering results for increasing the performance of the final results.\nAlthough CES can achieve better final results in comparison with individual\nclustering algorithms and cluster ensemble methods, its performance can be\ndramatically affected by its consensus diversity metric and thresholding\nprocedure. There are two problems in CES: 1) most of the diversity metrics is\nbased on heuristic Shannon's entropy and 2) estimating threshold values are\nreally hard in practice. The main goal of this paper is proposing a robust\napproach for solving the above mentioned problems. Accordingly, this paper\ndevelops a novel framework for clustering problems, which is called Weighted\nSpectral Cluster Ensemble (WSCE), by exploiting some concepts from community\ndetection arena and graph based clustering. Under this framework, a new version\nof spectral clustering, which is called Two Kernels Spectral Clustering, is\nused for generating graphs based individual clustering results. Further, by\nusing modularity, which is a famous metric in the community detection, on the\ntransformed graph representation of individual clustering results, our approach\nprovides an effective diversity estimation for individual clustering results.\nMoreover, this paper introduces a new approach for combining the evaluated\nindividual clustering results without the procedure of thresholding.\nExperimental study on varied data sets demonstrates that the prosed approach\nachieves superior performance to state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Mon, 25 Apr 2016 09:29:21 GMT"}], "update_date": "2016-04-26", "authors_parsed": [["Yousefnezhad", "Muhammad", ""], ["Zhang", "Daoqiang", ""]]}, {"id": "1604.07183", "submitter": "Marc van Zee", "authors": "Marc van Zee and Dragan Doder", "title": "AGM-Style Revision of Beliefs and Intentions from a Database Perspective\n  (Preliminary Version)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a logic for temporal beliefs and intentions based on Shoham's\ndatabase perspective. We separate strong beliefs from weak beliefs. Strong\nbeliefs are independent from intentions, while weak beliefs are obtained by\nadding intentions to strong beliefs and everything that follows from that. We\nformalize coherence conditions on strong beliefs and intentions. We provide\nAGM-style postulates for the revision of strong beliefs and intentions. We show\nin a representation theorem that a revision operator satisfying our postulates\ncan be represented by a pre-order on interpretations of the beliefs, together\nwith a selection function for the intentions.\n", "versions": [{"version": "v1", "created": "Mon, 25 Apr 2016 09:44:02 GMT"}, {"version": "v2", "created": "Tue, 26 Apr 2016 16:10:38 GMT"}], "update_date": "2016-04-27", "authors_parsed": [["van Zee", "Marc", ""], ["Doder", "Dragan", ""]]}, {"id": "1604.07255", "submitter": "Tom Zahavy", "authors": "Chen Tessler, Shahar Givony, Tom Zahavy, Daniel J. Mankowitz, Shie\n  Mannor", "title": "A Deep Hierarchical Approach to Lifelong Learning in Minecraft", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a lifelong learning system that has the ability to reuse and\ntransfer knowledge from one task to another while efficiently retaining the\npreviously learned knowledge-base. Knowledge is transferred by learning\nreusable skills to solve tasks in Minecraft, a popular video game which is an\nunsolved and high-dimensional lifelong learning problem. These reusable skills,\nwhich we refer to as Deep Skill Networks, are then incorporated into our novel\nHierarchical Deep Reinforcement Learning Network (H-DRLN) architecture using\ntwo techniques: (1) a deep skill array and (2) skill distillation, our novel\nvariation of policy distillation (Rusu et. al. 2015) for learning skills. Skill\ndistillation enables the HDRLN to efficiently retain knowledge and therefore\nscale in lifelong learning, by accumulating knowledge and encapsulating\nmultiple reusable skills into a single distilled network. The H-DRLN exhibits\nsuperior performance and lower learning sample complexity compared to the\nregular Deep Q Network (Mnih et. al. 2015) in sub-domains of Minecraft.\n", "versions": [{"version": "v1", "created": "Mon, 25 Apr 2016 13:45:50 GMT"}, {"version": "v2", "created": "Thu, 27 Oct 2016 13:18:20 GMT"}, {"version": "v3", "created": "Wed, 30 Nov 2016 17:35:27 GMT"}], "update_date": "2016-12-01", "authors_parsed": [["Tessler", "Chen", ""], ["Givony", "Shahar", ""], ["Zahavy", "Tom", ""], ["Mankowitz", "Daniel J.", ""], ["Mannor", "Shie", ""]]}, {"id": "1604.07312", "submitter": "Jan N. van Rijn", "authors": "Jan N. van Rijn, Jonathan K. Vis", "title": "Endgame Analysis of Dou Shou Qi", "comments": "5 pages, ICGA Journal, Vol. 37, pp. 120-124, 2014", "journal-ref": "ICGA Journal, Vol. 37, pp. 120-124, 2014", "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dou Shou Qi is a game in which two players control a number of pieces, each\nof them aiming to move one of their pieces onto a given square. We implemented\nan engine for analyzing the game. Moreover, we created a series of endgame\ntablebases containing all configurations with up to four pieces. These\ntablebases are the first steps towards theoretically solving the game. Finally,\nwe constructed decision trees based on the endgame tablebases. In this note we\nreport on some interesting patterns.\n", "versions": [{"version": "v1", "created": "Mon, 25 Apr 2016 15:35:38 GMT"}], "update_date": "2016-04-26", "authors_parsed": [["van Rijn", "Jan N.", ""], ["Vis", "Jonathan K.", ""]]}, {"id": "1604.07322", "submitter": "Maria Torres Vega", "authors": "Maria Torres Vega, Decebal Constantin Mocanu and Antonio Liotta", "title": "Predictive No-Reference Assessment of Video Quality", "comments": "13 pages, 8 figures, IEEE Selected Topics on Signal Processing", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MM cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Among the various means to evaluate the quality of video streams,\nNo-Reference (NR) methods have low computation and may be executed on thin\nclients. Thus, NR algorithms would be perfect candidates in cases of real-time\nquality assessment, automated quality control and, particularly, in adaptive\nmobile streaming. Yet, existing NR approaches are often inaccurate, in\ncomparison to Full-Reference (FR) algorithms, especially under lossy network\nconditions. In this work, we present an NR method that combines machine\nlearning with simple NR metrics to achieve a quality index comparably as\naccurate as the Video Quality Metric (VQM) Full-Reference algorithm. Our method\nis tested in an extensive dataset (960 videos), under lossy network conditions\nand considering nine different machine learning algorithms. Overall, we achieve\nan over 97% correlation with VQM, while allowing real-time assessment of video\nquality of experience in realistic streaming scenarios.\n", "versions": [{"version": "v1", "created": "Mon, 25 Apr 2016 16:34:17 GMT"}, {"version": "v2", "created": "Wed, 27 Apr 2016 06:16:40 GMT"}], "update_date": "2016-04-28", "authors_parsed": [["Vega", "Maria Torres", ""], ["Mocanu", "Decebal Constantin", ""], ["Liotta", "Antonio", ""]]}, {"id": "1604.07379", "submitter": "Deepak Pathak", "authors": "Deepak Pathak, Philipp Krahenbuhl, Jeff Donahue, Trevor Darrell,\n  Alexei A. Efros", "title": "Context Encoders: Feature Learning by Inpainting", "comments": "New results on ImageNet Generation", "journal-ref": "CVPR 2016", "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.GR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an unsupervised visual feature learning algorithm driven by\ncontext-based pixel prediction. By analogy with auto-encoders, we propose\nContext Encoders -- a convolutional neural network trained to generate the\ncontents of an arbitrary image region conditioned on its surroundings. In order\nto succeed at this task, context encoders need to both understand the content\nof the entire image, as well as produce a plausible hypothesis for the missing\npart(s). When training context encoders, we have experimented with both a\nstandard pixel-wise reconstruction loss, as well as a reconstruction plus an\nadversarial loss. The latter produces much sharper results because it can\nbetter handle multiple modes in the output. We found that a context encoder\nlearns a representation that captures not just appearance but also the\nsemantics of visual structures. We quantitatively demonstrate the effectiveness\nof our learned features for CNN pre-training on classification, detection, and\nsegmentation tasks. Furthermore, context encoders can be used for semantic\ninpainting tasks, either stand-alone or as initialization for non-parametric\nmethods.\n", "versions": [{"version": "v1", "created": "Mon, 25 Apr 2016 19:42:46 GMT"}, {"version": "v2", "created": "Mon, 21 Nov 2016 20:56:42 GMT"}], "update_date": "2016-11-22", "authors_parsed": [["Pathak", "Deepak", ""], ["Krahenbuhl", "Philipp", ""], ["Donahue", "Jeff", ""], ["Darrell", "Trevor", ""], ["Efros", "Alexei A.", ""]]}, {"id": "1604.07407", "submitter": "Vlad Niculae", "authors": "Vlad Niculae and Cristian Danescu-Niculescu-Mizil", "title": "Conversational Markers of Constructive Discussions", "comments": "To appear at NAACL-HLT 2016. 11pp, 5 fig. Data and other info\n  available at http://vene.ro/constructive/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.SI physics.soc-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Group discussions are essential for organizing every aspect of modern life,\nfrom faculty meetings to senate debates, from grant review panels to papal\nconclaves. While costly in terms of time and organization effort, group\ndiscussions are commonly seen as a way of reaching better decisions compared to\nsolutions that do not require coordination between the individuals (e.g.\nvoting)---through discussion, the sum becomes greater than the parts. However,\nthis assumption is not irrefutable: anecdotal evidence of wasteful discussions\nabounds, and in our own experiments we find that over 30% of discussions are\nunproductive.\n  We propose a framework for analyzing conversational dynamics in order to\ndetermine whether a given task-oriented discussion is worth having or not. We\nexploit conversational patterns reflecting the flow of ideas and the balance\nbetween the participants, as well as their linguistic choices. We apply this\nframework to conversations naturally occurring in an online collaborative world\nexploration game developed and deployed to support this research. Using this\nsetting, we show that linguistic cues and conversational patterns extracted\nfrom the first 20 seconds of a team discussion are predictive of whether it\nwill be a wasteful or a productive one.\n", "versions": [{"version": "v1", "created": "Mon, 25 Apr 2016 20:00:02 GMT"}], "update_date": "2016-04-27", "authors_parsed": [["Niculae", "Vlad", ""], ["Danescu-Niculescu-Mizil", "Cristian", ""]]}, {"id": "1604.07429", "submitter": "Yale Song", "authors": "Yale Song, Randall Davis, Kaichen Ma, Dana L. Penny", "title": "Balancing Appearance and Context in Sketch Interpretation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe a sketch interpretation system that detects and classifies clock\nnumerals created by subjects taking the Clock Drawing Test, a clinical tool\nwidely used to screen for cognitive impairments (e.g., dementia). We describe\nhow it balances appearance and context, and document its performance on some\n2,000 drawings (about 24K clock numerals) produced by a wide spectrum of\npatients. We calibrate the utility of different forms of context, describing\nexperiments with Conditional Random Fields trained and tested using a variety\nof features. We identify context that contributes to interpreting otherwise\nambiguous or incomprehensible strokes. We describe ST-slices, a novel\nrepresentation that enables \"unpeeling\" the layers of ink that result when\npeople overwrite, which often produces ink impossible to analyze if only the\nfinal drawing is examined. We characterize when ST-slices work, calibrate their\nimpact on performance, and consider their breadth of applicability.\n", "versions": [{"version": "v1", "created": "Mon, 25 Apr 2016 20:14:35 GMT"}], "update_date": "2016-04-27", "authors_parsed": [["Song", "Yale", ""], ["Davis", "Randall", ""], ["Ma", "Kaichen", ""], ["Penny", "Dana L.", ""]]}, {"id": "1604.07513", "submitter": "Hirokatsu Kataoka", "authors": "Teppei Suzuki, Soma Shirakabe, Yudai Miyashita, Akio Nakamura, Yutaka\n  Satoh, Hirokatsu Kataoka", "title": "Semantic Change Detection with Hypermaps", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Change detection is the study of detecting changes between two different\nimages of a scene taken at different times. By the detected change areas,\nhowever, a human cannot understand how different the two images. Therefore, a\nsemantic understanding is required in the change detection research such as\ndisaster investigation. The paper proposes the concept of semantic change\ndetection, which involves intuitively inserting semantic meaning into detected\nchange areas. We mainly focus on the novel semantic segmentation in addition to\na conventional change detection approach. In order to solve this problem and\nobtain a high-level of performance, we propose an improvement to the\nhypercolumns representation, hereafter known as hypermaps, which effectively\nuses convolutional maps obtained from convolutional neural networks (CNNs). We\nalso employ multi-scale feature representation captured by different image\npatches. We applied our method to the TSUNAMI Panoramic Change Detection\ndataset, and re-annotated the changed areas of the dataset via semantic\nclasses. The results show that our multi-scale hypermaps provided outstanding\nperformance on the re-annotated TSUNAMI dataset.\n", "versions": [{"version": "v1", "created": "Tue, 26 Apr 2016 04:31:31 GMT"}, {"version": "v2", "created": "Thu, 16 Mar 2017 01:46:37 GMT"}], "update_date": "2017-03-17", "authors_parsed": [["Suzuki", "Teppei", ""], ["Shirakabe", "Soma", ""], ["Miyashita", "Yudai", ""], ["Nakamura", "Akio", ""], ["Satoh", "Yutaka", ""], ["Kataoka", "Hirokatsu", ""]]}, {"id": "1604.07625", "submitter": "Olegs Verhodubs", "authors": "Olegs Verhodubs", "title": "Mutual Transformation of Information and Knowledge", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Information and knowledge are transformable into each other. Information\ntransformation into knowledge by the example of rule generation from OWL (Web\nOntology Language) ontology has been shown during the development of the SWES\n(Semantic Web Expert System). The SWES is expected as an expert system for\nsearching OWL ontologies from the Web, generating rules from the found\nontologies and supplementing the SWES knowledge base with these rules. The\npurpose of this paper is to show knowledge transformation into information by\nthe example of ontology generation from rules.\n", "versions": [{"version": "v1", "created": "Tue, 26 Apr 2016 11:31:02 GMT"}], "update_date": "2016-04-27", "authors_parsed": [["Verhodubs", "Olegs", ""]]}, {"id": "1604.07704", "submitter": "Zhaoxiang Zang", "authors": "Zhaoxiang Zang, Zhao Li, Junying Wang, Zhiping Dan", "title": "Tournament selection in zeroth-level classifier systems based on average\n  reward reinforcement learning", "comments": "14 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As a genetics-based machine learning technique, zeroth-level classifier\nsystem (ZCS) is based on a discounted reward reinforcement learning algorithm,\nbucket-brigade algorithm, which optimizes the discounted total reward received\nby an agent but is not suitable for all multi-step problems, especially\nlarge-size ones. There are some undiscounted reinforcement learning methods\navailable, such as R-learning, which optimize the average reward per time step.\nIn this paper, R-learning is used as the reinforcement learning employed by\nZCS, to replace its discounted reward reinforcement learning approach, and\ntournament selection is used to replace roulette wheel selection in ZCS. The\nmodification results in classifier systems that can support long action chains,\nand thus is able to solve large multi-step problems.\n", "versions": [{"version": "v1", "created": "Tue, 26 Apr 2016 14:57:56 GMT"}], "update_date": "2016-04-27", "authors_parsed": [["Zang", "Zhaoxiang", ""], ["Li", "Zhao", ""], ["Wang", "Junying", ""], ["Dan", "Zhiping", ""]]}, {"id": "1604.07706", "submitter": "Shuai Li", "authors": "Nathan Korda and Balazs Szorenyi and Shuai Li", "title": "Distributed Clustering of Linear Bandits in Peer to Peer Networks", "comments": "The 33rd ICML, 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide two distributed confidence ball algorithms for solving linear\nbandit problems in peer to peer networks with limited communication\ncapabilities. For the first, we assume that all the peers are solving the same\nlinear bandit problem, and prove that our algorithm achieves the optimal\nasymptotic regret rate of any centralised algorithm that can instantly\ncommunicate information between the peers. For the second, we assume that there\nare clusters of peers solving the same bandit problem within each cluster, and\nwe prove that our algorithm discovers these clusters, while achieving the\noptimal asymptotic regret rate within each one. Through experiments on several\nreal-world datasets, we demonstrate the performance of proposed algorithms\ncompared to the state-of-the-art.\n", "versions": [{"version": "v1", "created": "Tue, 26 Apr 2016 14:59:43 GMT"}, {"version": "v2", "created": "Wed, 25 May 2016 06:12:46 GMT"}, {"version": "v3", "created": "Tue, 7 Jun 2016 08:06:23 GMT"}], "update_date": "2016-06-08", "authors_parsed": [["Korda", "Nathan", ""], ["Szorenyi", "Balazs", ""], ["Li", "Shuai", ""]]}, {"id": "1604.07806", "submitter": "Jacob Schrum", "authors": "Jacob Schrum, Joel Lehman, Sebastian Risi", "title": "Using Indirect Encoding of Multiple Brains to Produce Multimodal\n  Behavior", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An important challenge in neuroevolution is to evolve complex neural networks\nwith multiple modes of behavior. Indirect encodings can potentially answer this\nchallenge. Yet in practice, indirect encodings do not yield effective\nmultimodal controllers. Thus, this paper introduces novel multimodal extensions\nto HyperNEAT, a popular indirect encoding. A previous multimodal HyperNEAT\napproach called situational policy geometry assumes that multiple brains\nbenefit from being embedded within an explicit geometric space. However,\nexperiments here illustrate that this assumption unnecessarily constrains\nevolution, resulting in lower performance. Specifically, this paper introduces\nHyperNEAT extensions for evolving many brains without assuming geometric\nrelationships between them. The resulting Multi-Brain HyperNEAT can exploit\nhuman-specified task divisions to decide when each brain controls the agent, or\ncan automatically discover when brains should be used, by means of preference\nneurons. A further extension called module mutation allows evolution to\ndiscover the number of brains, enabling multimodal behavior with even less\nexpert knowledge. Experiments in several multimodal domains highlight that\nmulti-brain approaches are more effective than HyperNEAT without multimodal\nextensions, and show that brains without a geometric relation to each other\noutperform situational policy geometry. The conclusion is that Multi-Brain\nHyperNEAT provides several promising techniques for evolving complex multimodal\nbehavior.\n", "versions": [{"version": "v1", "created": "Tue, 26 Apr 2016 19:24:52 GMT"}], "update_date": "2016-04-27", "authors_parsed": [["Schrum", "Jacob", ""], ["Lehman", "Joel", ""], ["Risi", "Sebastian", ""]]}, {"id": "1604.07906", "submitter": "Ruck Thawonmas", "authors": "YuXuan Jiang, Misaki Kaidan, Chun Yin Chu, Tomohiro Harada, and Ruck\n  Thawonmas", "title": "Procedural Generation of Angry Birds Levels using Building Constructive\n  Grammar with Chinese-Style and/or Japanese-Style Models", "comments": null, "journal-ref": "Proc. of ASIAGRAPH 2016, Toyama, Japan, pp. 53-54, Mar. 5-6, 2016", "doi": null, "report-no": null, "categories": "cs.AI cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a procedural generation method that creates visually\nattractive levels for the Angry Birds game. Besides being an immensely popular\nmobile game, Angry Birds has recently become a test bed for various artificial\nintelligence technologies. We propose a new approach for procedurally\ngenerating Angry Birds levels using Chinese style and Japanese style building\nstructures. A conducted experiment confirms the effectiveness of our approach\nwith statistical significance.\n", "versions": [{"version": "v1", "created": "Wed, 27 Apr 2016 02:21:28 GMT"}], "update_date": "2016-04-28", "authors_parsed": [["Jiang", "YuXuan", ""], ["Kaidan", "Misaki", ""], ["Chu", "Chun Yin", ""], ["Harada", "Tomohiro", ""], ["Thawonmas", "Ruck", ""]]}, {"id": "1604.07928", "submitter": "Shandian Zhe", "authors": "Shandian Zhe, Kai Zhang, Pengyuan Wang, Kuang-chih Lee, Zenglin Xu,\n  Yuan Qi, Zoubin Ghahramani", "title": "Distributed Flexible Nonlinear Tensor Factorization", "comments": "Gaussian process, tensor factorization, multidimensional arrays,\n  large scale, spark, map-reduce", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tensor factorization is a powerful tool to analyse multi-way data. Compared\nwith traditional multi-linear methods, nonlinear tensor factorization models\nare capable of capturing more complex relationships in the data. However, they\nare computationally expensive and may suffer severe learning bias in case of\nextreme data sparsity. To overcome these limitations, in this paper we propose\na distributed, flexible nonlinear tensor factorization model. Our model can\neffectively avoid the expensive computations and structural restrictions of the\nKronecker-product in existing TGP formulations, allowing an arbitrary subset of\ntensorial entries to be selected to contribute to the training. At the same\ntime, we derive a tractable and tight variational evidence lower bound (ELBO)\nthat enables highly decoupled, parallel computations and high-quality\ninference. Based on the new bound, we develop a distributed inference algorithm\nin the MapReduce framework, which is key-value-free and can fully exploit the\nmemory cache mechanism in fast MapReduce systems such as SPARK. Experimental\nresults fully demonstrate the advantages of our method over several\nstate-of-the-art approaches, in terms of both predictive performance and\ncomputational efficiency. Moreover, our approach shows a promising potential in\nthe application of Click-Through-Rate (CTR) prediction for online advertising.\n", "versions": [{"version": "v1", "created": "Wed, 27 Apr 2016 04:18:32 GMT"}, {"version": "v2", "created": "Sun, 22 May 2016 00:00:23 GMT"}], "update_date": "2016-05-24", "authors_parsed": [["Zhe", "Shandian", ""], ["Zhang", "Kai", ""], ["Wang", "Pengyuan", ""], ["Lee", "Kuang-chih", ""], ["Xu", "Zenglin", ""], ["Qi", "Yuan", ""], ["Ghahramani", "Zoubin", ""]]}, {"id": "1604.07981", "submitter": "Ale\\v{s} Bizjak", "authors": "Martin C. Cooper and Stanislav \\v{Z}ivn\\'y", "title": "The Power of Arc Consistency for CSPs Defined by Partially-Ordered\n  Forbidden Patterns", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 13, Issue 4 (December\n  27, 2017) lmcs:4168", "doi": "10.23638/LMCS-13(4:26)2017", "report-no": null, "categories": "cs.CC cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Characterising tractable fragments of the constraint satisfaction problem\n(CSP) is an important challenge in theoretical computer science and artificial\nintelligence. Forbidding patterns (generic sub-instances) provides a means of\ndefining CSP fragments which are neither exclusively language-based nor\nexclusively structure-based. It is known that the class of binary CSP instances\nin which the broken-triangle pattern (BTP) does not occur, a class which\nincludes all tree-structured instances, are decided by arc consistency (AC), a\nubiquitous reduction operation in constraint solvers. We provide a\ncharacterisation of simple partially-ordered forbidden patterns which have this\nAC-solvability property. It turns out that BTP is just one of five such\nAC-solvable patterns. The four other patterns allow us to exhibit new tractable\nclasses.\n", "versions": [{"version": "v1", "created": "Wed, 27 Apr 2016 09:00:17 GMT"}, {"version": "v2", "created": "Sun, 29 May 2016 12:53:08 GMT"}, {"version": "v3", "created": "Fri, 15 Dec 2017 13:10:14 GMT"}, {"version": "v4", "created": "Mon, 25 Dec 2017 09:28:41 GMT"}], "update_date": "2019-03-14", "authors_parsed": [["Cooper", "Martin C.", ""], ["\u017divn\u00fd", "Stanislav", ""]]}, {"id": "1604.07990", "submitter": "Andres Masegosa R", "authors": "Andres R. Masegosa, Ana M. Martinez, Hanen Borchani", "title": "Probabilistic Graphical Models on Multi-Core CPUs using Java 8", "comments": "Pre-print version of the paper presented in the special issue on\n  Computational Intelligence Software at IEEE Computational Intelligence\n  Magazine journal", "journal-ref": "IEEE Computational Intelligence Magazine, 11(2), 41-54. 2016", "doi": "10.1109/MCI.2016.2532267", "report-no": null, "categories": "cs.AI cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we discuss software design issues related to the development\nof parallel computational intelligence algorithms on multi-core CPUs, using the\nnew Java 8 functional programming features. In particular, we focus on\nprobabilistic graphical models (PGMs) and present the parallelisation of a\ncollection of algorithms that deal with inference and learning of PGMs from\ndata. Namely, maximum likelihood estimation, importance sampling, and greedy\nsearch for solving combinatorial optimisation problems. Through these concrete\nexamples, we tackle the problem of defining efficient data structures for PGMs\nand parallel processing of same-size batches of data sets using Java 8\nfeatures. We also provide straightforward techniques to code parallel\nalgorithms that seamlessly exploit multi-core processors. The experimental\nanalysis, carried out using our open source AMIDST (Analysis of MassIve Data\nSTreams) Java toolbox, shows the merits of the proposed solutions.\n", "versions": [{"version": "v1", "created": "Wed, 27 Apr 2016 09:28:27 GMT"}], "update_date": "2017-07-10", "authors_parsed": [["Masegosa", "Andres R.", ""], ["Martinez", "Ana M.", ""], ["Borchani", "Hanen", ""]]}, {"id": "1604.08055", "submitter": "Martin Suda", "authors": "Giles Reger, Martin Suda, Andrei Voronkov, Krystof Hoder", "title": "Selecting the Selection", "comments": "IJCAR 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern saturation-based Automated Theorem Provers typically implement the\nsuperposition calculus for reasoning about first-order logic with or without\nequality. Practical implementations of this calculus use a variety of literal\nselections and term orderings to tame the growth of the search space and help\nsteer proof search. This paper introduces the notion of lookahead selection\nthat estimates (looks ahead) the effect on the search space of selecting a\nliteral. There is also a case made for the use of incomplete selection\nfunctions that attempt to restrict the search space instead of satisfying some\ncompleteness criteria. Experimental evaluation in the \\Vampire\\ theorem prover\nshows that both lookahead selection and incomplete selection significantly\ncontribute to solving hard problems unsolvable by other methods.\n", "versions": [{"version": "v1", "created": "Wed, 27 Apr 2016 13:14:44 GMT"}], "update_date": "2016-04-28", "authors_parsed": [["Reger", "Giles", ""], ["Suda", "Martin", ""], ["Voronkov", "Andrei", ""], ["Hoder", "Krystof", ""]]}, {"id": "1604.08148", "submitter": "Changqing Liu", "authors": "Changqing Liu", "title": "Defining Concepts of Emotion: From Philosophy to Science", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper is motivated by a series of (related) questions as to whether a\ncomputer can have pleasure and pain, what pleasure (and intensity of pleasure)\nis, and, ultimately, what concepts of emotion are.\n  To determine what an emotion is, is a matter of conceptualization, namely,\nunderstanding and explicitly encoding the concept of emotion as people use it\nin everyday life. This is a notoriously difficult problem (Frijda, 1986, Fehr\n\\& Russell, 1984). This paper firstly shows why this is a difficult problem by\naligning it with the conceptualization of a few other so called semantic\nprimitives such as \"EXIST\", \"FORCE\", \"BIG\" (plus \"LIMIT\"). The definitions of\nthese thought-to-be-indefinable concepts, given in this paper, show what formal\ndefinitions of concepts look like and how concepts are constructed. As a\nby-product, owing to the explicit account of the meaning of \"exist\", the famous\ndispute between Einstein and Bohr is naturally resolved from linguistic point\nof view. Secondly, defending Frijda's view that emotion is action tendency (or\nRyle's behavioral disposition (propensity)), we give a list of emotions defined\nin terms of action tendency. In particular, the definitions of pleasure and the\nfeeling of beauty are presented.\n  Further, we give a formal definition of \"action tendency\", from which the\nconcept of \"intensity\" of emotions (including pleasure) is naturally derived in\na formal fashion. The meanings of \"wish\", \"wait\", \"good\", \"hot\" are analyzed.\n", "versions": [{"version": "v1", "created": "Thu, 11 Feb 2016 22:51:06 GMT"}], "update_date": "2016-04-28", "authors_parsed": [["Liu", "Changqing", ""]]}, {"id": "1604.08153", "submitter": "Kai Arulkumaran", "authors": "Kai Arulkumaran, Nat Dilokthanakul, Murray Shanahan, Anil Anthony\n  Bharath", "title": "Classifying Options for Deep Reinforcement Learning", "comments": "IJCAI 2016 Workshop on Deep Reinforcement Learning: Frontiers and\n  Challenges", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we combine one method for hierarchical reinforcement learning -\nthe options framework - with deep Q-networks (DQNs) through the use of\ndifferent \"option heads\" on the policy network, and a supervisory network for\nchoosing between the different options. We utilise our setup to investigate the\neffects of architectural constraints in subtasks with positive and negative\ntransfer, across a range of network capacities. We empirically show that our\naugmented DQN has lower sample complexity when simultaneously learning subtasks\nwith negative transfer, without degrading performance when learning subtasks\nwith positive transfer.\n", "versions": [{"version": "v1", "created": "Wed, 27 Apr 2016 17:48:39 GMT"}, {"version": "v2", "created": "Wed, 8 Jun 2016 16:05:31 GMT"}, {"version": "v3", "created": "Mon, 19 Jun 2017 15:34:58 GMT"}], "update_date": "2017-06-20", "authors_parsed": [["Arulkumaran", "Kai", ""], ["Dilokthanakul", "Nat", ""], ["Shanahan", "Murray", ""], ["Bharath", "Anil Anthony", ""]]}, {"id": "1604.08229", "submitter": "Alexey Ignatiev", "authors": "Alexey Ignatiev, Antonio Morgado and Joao Marques-Silva", "title": "Propositional Abduction with Implicit Hitting Sets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Logic-based abduction finds important applications in artificial intelligence\nand related areas. One application example is in finding explanations for\nobserved phenomena. Propositional abduction is a restriction of abduction to\nthe propositional domain, and complexity-wise is in the second level of the\npolynomial hierarchy. Recent work has shown that exploiting implicit hitting\nsets and propositional satisfiability (SAT) solvers provides an efficient\napproach for propositional abduction. This paper investigates this earlier work\nand proposes a number of algorithmic improvements. These improvements are shown\nto yield exponential reductions in the number of SAT solver calls. More\nimportantly, the experimental results show significant performance improvements\ncompared to the the best approaches for propositional abduction.\n", "versions": [{"version": "v1", "created": "Wed, 27 Apr 2016 20:29:01 GMT"}], "update_date": "2016-04-29", "authors_parsed": [["Ignatiev", "Alexey", ""], ["Morgado", "Antonio", ""], ["Marques-Silva", "Joao", ""]]}, {"id": "1604.08268", "submitter": "Diederik Aerts", "authors": "Diederik Aerts, Lyneth Beltran, Massimiliano Sassoli de Bianchi,\n  Sandro Sozzo and Tomas Veloz", "title": "Quantum Cognition Beyond Hilbert Space I: Fundamentals", "comments": "10 pages, 2 figures", "journal-ref": "In de Barros J., Coecke B., Pothos E. (Eds), Quantum Interaction.\n  QI 2016 (pp. 81-98). Lecture Notes in Computer Science, vol 10106. Springer,\n  Cham (2017)", "doi": "10.1007/978-3-319-52289-0_7", "report-no": null, "categories": "cs.AI quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The formalism of quantum theory in Hilbert space has been applied with\nsuccess to the modeling and explanation of several cognitive phenomena, whereas\ntraditional cognitive approaches were problematical. However, this 'quantum\ncognition paradigm' was recently challenged by its proven impossibility to\nsimultaneously model 'question order effects' and 'response replicability'. In\nPart I of this paper we describe sequential dichotomic measurements within an\noperational and realistic framework for human cognition elaborated by\nourselves, and represent them in a quantum-like 'extended Bloch representation'\nwhere the Born rule of quantum probability does not necessarily hold. In Part\nII we apply this mathematical framework to successfully model question order\neffects, response replicability and unpacking effects, thus opening the way\ntoward quantum cognition beyond Hilbert space.\n", "versions": [{"version": "v1", "created": "Wed, 27 Apr 2016 23:30:29 GMT"}], "update_date": "2019-02-12", "authors_parsed": [["Aerts", "Diederik", ""], ["Beltran", "Lyneth", ""], ["de Bianchi", "Massimiliano Sassoli", ""], ["Sozzo", "Sandro", ""], ["Veloz", "Tomas", ""]]}, {"id": "1604.08270", "submitter": "Diederik Aerts", "authors": "Diederik Aerts, Lyneth Beltran, Massimiliano Sassoli de Bianchi,\n  Sandro Sozzo and Tomas Veloz", "title": "Quantum cognition beyond Hilbert space II: Applications", "comments": "10 pages, 2 figures", "journal-ref": "In de Barros J., Coecke B., Pothos E. (Eds) Quantum Interaction.\n  QI 2016 (pp. 81-98). Lecture Notes in Computer Science, vol 10106. Springer,\n  Cham (2017)", "doi": "10.1007/978-3-319-52289-0_7", "report-no": null, "categories": "cs.AI quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The research on human cognition has recently benefited from the use of the\nmathematical formalism of quantum theory in Hilbert space. However, cognitive\nsituations exist which indicate that the Hilbert space structure, and the\nassociated Born rule, would be insufficient to provide a satisfactory modeling\nof the collected data, so that one needs to go beyond Hilbert space. In Part I\nof this paper we follow this direction and present a general tension-reduction\n(GTR) model, in the ambit of an operational and realistic framework for human\ncognition. In this Part II we apply this non-Hilbertian quantum-like model to\nfaithfully reproduce the probabilities of the 'Clinton/Gore' and 'Rose/Jackson'\nexperiments on question order effects. We also explain why the GTR-model is\nneeded if one wants to deal, in a fully consistent way, with response\nreplicability and unpacking effects.\n", "versions": [{"version": "v1", "created": "Wed, 27 Apr 2016 23:40:11 GMT"}], "update_date": "2019-02-12", "authors_parsed": [["Aerts", "Diederik", ""], ["Beltran", "Lyneth", ""], ["de Bianchi", "Massimiliano Sassoli", ""], ["Sozzo", "Sandro", ""], ["Veloz", "Tomas", ""]]}, {"id": "1604.08340", "submitter": "Altti Ilari Maarala", "authors": "Altti Ilari Maarala, Xiang Su, and Jukka Riekki", "title": "Semantic Reasoning for Context-aware Internet of Things Applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Advances in ICT are bringing into reality the vision of a large number of\nuniquely identifiable, interconnected objects and things that gather\ninformation from diverse physical environments and deliver the information to a\nvariety of innovative applications and services. These sensing objects and\nthings form the Internet of Things (IoT) that can improve energy and cost\nefficiency and automation in many different industry fields such as\ntransportation and logistics, health care and manufacturing, and facilitate our\neveryday lives as well. IoT applications rely on real-time context data and\nallow sending information for driving the behaviors of users in intelligent\nenvironments.\n", "versions": [{"version": "v1", "created": "Thu, 28 Apr 2016 08:17:56 GMT"}], "update_date": "2016-04-29", "authors_parsed": [["Maarala", "Altti Ilari", ""], ["Su", "Xiang", ""], ["Riekki", "Jukka", ""]]}, {"id": "1604.08448", "submitter": "Shunji Umetani", "authors": "Shunji Umetani", "title": "Exploiting variable associations to configure efficient local search\n  algorithms in large-scale binary integer programs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.AI math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a data mining approach for reducing the search space of local\nsearch algorithms in a class of binary integer programs including the set\ncovering and partitioning problems. The quality of locally optimal solutions\ntypically improves if a larger neighborhood is used, while the computation time\nof searching the neighborhood increases exponentially. To overcome this, we\nextract variable associations from the instance to be solved in order to\nidentify promising pairs of flipping variables in the neighborhood search.\nBased on this, we develop a 4-flip neighborhood local search algorithm that\nincorporates an efficient incremental evaluation of solutions and an adaptive\ncontrol of penalty weights. Computational results show that the proposed method\nimproves the performance of the local search algorithm for large-scale set\ncovering and partitioning problems.\n", "versions": [{"version": "v1", "created": "Thu, 28 Apr 2016 15:04:08 GMT"}, {"version": "v2", "created": "Fri, 12 May 2017 15:34:54 GMT"}], "update_date": "2017-05-15", "authors_parsed": [["Umetani", "Shunji", ""]]}, {"id": "1604.08612", "submitter": "Jerome Feldman", "authors": "Jerome Feldman", "title": "Mysteries of Visual Experience", "comments": "This 7/22,2021 revision retains all the original text but adds new\n  comments (in italics) There are several new references, connecting with\n  current research.. This version also includes a pointer to the related Fall\n  2017 UC Berkeley class Science and Subjectivity and a link to a related arXiv\n  article on evolution", "journal-ref": null, "doi": "10.1007/s41470-019-00041-4", "report-no": null, "categories": "q-bio.NC cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Science is a crowning glory of the human spirit and its applications remain\nour best hope for social progress. But there are limitations to current science\nand perhaps to any science. The general mind-body problem is known to be\nintractable and currently mysterious. This is one of many deep problems that\nare universally agreed to be beyond the current purview of Science, including\nquantum phenomena, etc. But all of these famous unsolved problems are either\nremote from everyday experience (entanglement, dark matter) or are hard to even\ndefine sharply (phenomenology, consciousness, etc.).\n  In this note, we will consider some obvious computational problems in vision\nthat arise every time that we open our eyes and yet are demonstrably\nincompatible with current theories of neural computation. The focus will be on\ntwo related phenomena, known as the neural binding problem and the illusion of\na detailed stable visual world.\n", "versions": [{"version": "v1", "created": "Thu, 28 Apr 2016 20:41:25 GMT"}, {"version": "v2", "created": "Wed, 28 Sep 2016 17:33:49 GMT"}, {"version": "v3", "created": "Tue, 10 Jan 2017 18:46:42 GMT"}, {"version": "v4", "created": "Tue, 20 Mar 2018 16:07:22 GMT"}, {"version": "v5", "created": "Fri, 23 Jul 2021 16:13:55 GMT"}], "update_date": "2021-07-26", "authors_parsed": [["Feldman", "Jerome", ""]]}, {"id": "1604.08642", "submitter": "Yongyi Mao Dr", "authors": "Jianfeng Wen, Jianxin Li, Yongyi Mao, Shini Chen, Richong Zhang", "title": "On the representation and embedding of knowledge bases beyond binary\n  relations", "comments": "8 pages, to appear in IJCAI 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The models developed to date for knowledge base embedding are all based on\nthe assumption that the relations contained in knowledge bases are binary. For\nthe training and testing of these embedding models, multi-fold (or n-ary)\nrelational data are converted to triples (e.g., in FB15K dataset) and\ninterpreted as instances of binary relations. This paper presents a canonical\nrepresentation of knowledge bases containing multi-fold relations. We show that\nthe existing embedding models on the popular FB15K datasets correspond to a\nsub-optimal modelling framework, resulting in a loss of structural information.\nWe advocate a novel modelling framework, which models multi-fold relations\ndirectly using this canonical representation. Using this framework, the\nexisting TransH model is generalized to a new model, m-TransH. We demonstrate\nexperimentally that m-TransH outperforms TransH by a large margin, thereby\nestablishing a new state of the art.\n", "versions": [{"version": "v1", "created": "Thu, 28 Apr 2016 22:42:38 GMT"}], "update_date": "2016-05-02", "authors_parsed": [["Wen", "Jianfeng", ""], ["Li", "Jianxin", ""], ["Mao", "Yongyi", ""], ["Chen", "Shini", ""], ["Zhang", "Richong", ""]]}, {"id": "1604.08709", "submitter": "Yanjing Wang", "authors": "Tao Gu and Yanjing Wang", "title": "\"Knowing value\" logic as a normal modal logic", "comments": "21 pages, in Advances in Modal Logic Vol 11: 362-381 College\n  Publications. This is a draft with a more detailed proof of Prop. 3.5", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent years witness a growing interest in nonstandard epistemic logics of\n\"knowing whether\", \"knowing what\", \"knowing how\", and so on. These logics are\nusually not normal, i.e., the standard axioms and reasoning rules for modal\nlogic may be invalid. In this paper, we show that the conditional \"knowing\nvalue\" logic proposed by Wang and Fan \\cite{WF13} can be viewed as a disguised\nnormal modal logic by treating the negation of the Kv operator as a special\ndiamond. Under this perspective, it turns out that the original first-order\nKripke semantics can be greatly simplified by introducing a ternary relation\n$R_i^c$ in standard Kripke models, which associates one world with two\n$i$-accessible worlds that do not agree on the value of constant $c$. Under\nintuitive constraints, the modal logic based on such Kripke models is exactly\nthe one studied by Wang and Fan (2013,2014}. Moreover, there is a very natural\nbinary generalization of the \"knowing value\" diamond, which, surprisingly, does\nnot increase the expressive power of the logic. The resulting logic with the\nbinary diamond has a transparent normal modal system, which sharpens our\nunderstanding of the \"knowing value\" logic and simplifies some previously hard\nproblems.\n", "versions": [{"version": "v1", "created": "Fri, 29 Apr 2016 07:22:27 GMT"}, {"version": "v2", "created": "Sun, 12 Jun 2016 16:48:41 GMT"}, {"version": "v3", "created": "Mon, 21 Nov 2016 05:34:15 GMT"}], "update_date": "2016-11-22", "authors_parsed": [["Gu", "Tao", ""], ["Wang", "Yanjing", ""]]}, {"id": "1604.08768", "submitter": "Nitin Yadav", "authors": "Paolo Felli, Nitin Yadav, Sebastian Sardina", "title": "Supervisory Control for Behavior Composition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We relate behavior composition, a synthesis task studied in AI, to\nsupervisory control theory from the discrete event systems field. In\nparticular, we show that realizing (i.e., implementing) a target behavior\nmodule (e.g., a house surveillance system) by suitably coordinating a\ncollection of available behaviors (e.g., automatic blinds, doors, lights,\ncameras, etc.) amounts to imposing a supervisor onto a special discrete event\nsystem. Such a link allows us to leverage on the solid foundations and\nextensive work on discrete event systems, including borrowing tools and ideas\nfrom that field. As evidence of that we show how simple it is to introduce\npreferences in the mapped framework.\n", "versions": [{"version": "v1", "created": "Fri, 29 Apr 2016 10:38:04 GMT"}], "update_date": "2016-05-02", "authors_parsed": [["Felli", "Paolo", ""], ["Yadav", "Nitin", ""], ["Sardina", "Sebastian", ""]]}, {"id": "1604.08781", "submitter": "Joseph Corneli", "authors": "Joseph Corneli and Miriam Corneli", "title": "Teaching natural language to computers", "comments": "6 pages, including 1 figure and 3 tables; accepted for presentation\n  at IJCAI2016 Workshop on Language Sense on Computers", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  \"Natural Language,\" whether spoken and attended to by humans, or processed\nand generated by computers, requires networked structures that reflect creative\nprocesses in semantic, syntactic, phonetic, linguistic, social, emotional, and\ncultural modules. Being able to produce novel and useful behavior following\nrepeated practice gets to the root of both artificial intelligence and human\nlanguage. This paper investigates the modalities involved in language-like\napplications that computers -- and programmers -- engage with, and aims to fine\ntune the questions we ask to better account for context, self-awareness, and\nembodiment.\n", "versions": [{"version": "v1", "created": "Fri, 29 Apr 2016 11:36:25 GMT"}, {"version": "v2", "created": "Tue, 28 Jun 2016 05:29:24 GMT"}], "update_date": "2016-06-29", "authors_parsed": [["Corneli", "Joseph", ""], ["Corneli", "Miriam", ""]]}, {"id": "1604.08859", "submitter": "Alexandre de Br\\'ebisson", "authors": "Alexandre de Br\\'ebisson, Pascal Vincent", "title": "The Z-loss: a shift and scale invariant classification loss belonging to\n  the Spherical Family", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite being the standard loss function to train multi-class neural\nnetworks, the log-softmax has two potential limitations. First, it involves\ncomputations that scale linearly with the number of output classes, which can\nrestrict the size of problems we are able to tackle with current hardware.\nSecond, it remains unclear how close it matches the task loss such as the top-k\nerror rate or other non-differentiable evaluation metrics which we aim to\noptimize ultimately. In this paper, we introduce an alternative classification\nloss function, the Z-loss, which is designed to address these two issues.\nUnlike the log-softmax, it has the desirable property of belonging to the\nspherical loss family (Vincent et al., 2015), a class of loss functions for\nwhich training can be performed very efficiently with a complexity independent\nof the number of output classes. We show experimentally that it significantly\noutperforms the other spherical loss functions previously investigated.\nFurthermore, we show on a word language modeling task that it also outperforms\nthe log-softmax with respect to certain ranking scores, such as top-k scores,\nsuggesting that the Z-loss has the flexibility to better match the task loss.\nThese qualities thus makes the Z-loss an appealing candidate to train very\nefficiently large output networks such as word-language models or other extreme\nclassification problems. On the One Billion Word (Chelba et al., 2014) dataset,\nwe are able to train a model with the Z-loss 40 times faster than the\nlog-softmax and more than 4 times faster than the hierarchical softmax.\n", "versions": [{"version": "v1", "created": "Fri, 29 Apr 2016 14:53:00 GMT"}, {"version": "v2", "created": "Fri, 27 May 2016 15:17:34 GMT"}], "update_date": "2016-05-30", "authors_parsed": [["de Br\u00e9bisson", "Alexandre", ""], ["Vincent", "Pascal", ""]]}, {"id": "1604.08880", "submitter": "Shane Halloran", "authors": "Nils Y. Hammerla, Shane Halloran and Thomas Ploetz", "title": "Deep, Convolutional, and Recurrent Models for Human Activity Recognition\n  using Wearables", "comments": "Extended version has been accepted for publication at International\n  Joint Conference on Artificial Intelligence (IJCAI)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.HC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Human activity recognition (HAR) in ubiquitous computing is beginning to\nadopt deep learning to substitute for well-established analysis techniques that\nrely on hand-crafted feature extraction and classification techniques. From\nthese isolated applications of custom deep architectures it is, however,\ndifficult to gain an overview of their suitability for problems ranging from\nthe recognition of manipulative gestures to the segmentation and identification\nof physical activities like running or ascending stairs. In this paper we\nrigorously explore deep, convolutional, and recurrent approaches across three\nrepresentative datasets that contain movement data captured with wearable\nsensors. We describe how to train recurrent approaches in this setting,\nintroduce a novel regularisation approach, and illustrate how they outperform\nthe state-of-the-art on a large benchmark dataset. Across thousands of\nrecognition experiments with randomly sampled model configurations we\ninvestigate the suitability of each model for different tasks in HAR, explore\nthe impact of hyperparameters using the fANOVA framework, and provide\nguidelines for the practitioner who wants to apply deep learning in their\nproblem setting.\n", "versions": [{"version": "v1", "created": "Fri, 29 Apr 2016 15:38:44 GMT"}], "update_date": "2016-05-02", "authors_parsed": [["Hammerla", "Nils Y.", ""], ["Halloran", "Shane", ""], ["Ploetz", "Thomas", ""]]}, {"id": "1604.08934", "submitter": "Sebastijan Dumancic", "authors": "Sebastijan Dumancic and Hendrik Blockeel", "title": "An expressive dissimilarity measure for relational clustering using\n  neighbourhood trees", "comments": "9 pages, 3 figures, 4 tables, submitted to ECMLPKDD 2017", "journal-ref": null, "doi": "10.1007/s10994-017-5644-6", "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Clustering is an underspecified task: there are no universal criteria for\nwhat makes a good clustering. This is especially true for relational data,\nwhere similarity can be based on the features of individuals, the relationships\nbetween them, or a mix of both. Existing methods for relational clustering have\nstrong and often implicit biases in this respect. In this paper, we introduce a\nnovel similarity measure for relational data. It is the first measure to\nincorporate a wide variety of types of similarity, including similarity of\nattributes, similarity of relational context, and proximity in a hypergraph. We\nexperimentally evaluate how using this similarity affects the quality of\nclustering on very different types of datasets. The experiments demonstrate\nthat (a) using this similarity in standard clustering methods consistently\ngives good results, whereas other measures work well only on datasets that\nmatch their bias; and (b) on most datasets, the novel similarity outperforms\neven the best among the existing ones.\n", "versions": [{"version": "v1", "created": "Fri, 29 Apr 2016 18:48:53 GMT"}, {"version": "v2", "created": "Tue, 7 Mar 2017 08:45:19 GMT"}], "update_date": "2017-09-29", "authors_parsed": [["Dumancic", "Sebastijan", ""], ["Blockeel", "Hendrik", ""]]}]