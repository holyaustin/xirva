[{"id": "0712.0171", "submitter": "Elchanan Mossel", "authors": "Amin Coja-Oghlan and Elchanan Mossel and Dan Vilenchik", "title": "A Spectral Approach to Analyzing Belief Propagation for 3-Coloring", "comments": null, "journal-ref": "Combinatorics, Probability and Computing 18 (2009) 881 - 912", "doi": "10.1017/S096354830900981X", "report-no": null, "categories": "cs.CC cs.AI cs.DM", "license": null, "abstract": "  Contributing to the rigorous understanding of BP, in this paper we relate the\nconvergence of BP to spectral properties of the graph. This encompasses a\nresult for random graphs with a ``planted'' solution; thus, we obtain the first\nrigorous result on BP for graph coloring in the case of a complex graphical\nstructure (as opposed to trees). In particular, the analysis shows how Belief\nPropagation breaks the symmetry between the $3!$ possible permutations of the\ncolor classes.\n", "versions": [{"version": "v1", "created": "Sun, 2 Dec 2007 19:34:59 GMT"}], "update_date": "2017-11-17", "authors_parsed": [["Coja-Oghlan", "Amin", ""], ["Mossel", "Elchanan", ""], ["Vilenchik", "Dan", ""]]}, {"id": "0712.0451", "submitter": "Alejandro Chinea Manrique De Lara", "authors": "Alejandro Chinea Manrique De Lara", "title": "A Reactive Tabu Search Algorithm for Stimuli Generation in\n  Psycholinguistics", "comments": "Artificial Intelligence in Science and Technology AISAT 2004\n  Conference. 8 pages, 5 figures, 3 tables", "journal-ref": "Artificial Intelligence in Science and Technology AISAT 2004\n  Conference", "doi": null, "report-no": null, "categories": "cs.AI cs.CC cs.DM cs.LG", "license": null, "abstract": "  The generation of meaningless \"words\" matching certain statistical and/or\nlinguistic criteria is frequently needed for experimental purposes in\nPsycholinguistics. Such stimuli receive the name of pseudowords or nonwords in\nthe Cognitive Neuroscience literatue. The process for building nonwords\nsometimes has to be based on linguistic units such as syllables or morphemes,\nresulting in a numerical explosion of combinations when the size of the\nnonwords is increased. In this paper, a reactive tabu search scheme is proposed\nto generate nonwords of variables size. The approach builds pseudowords by\nusing a modified Metaheuristic algorithm based on a local search procedure\nenhanced by a feedback-based scheme. Experimental results show that the new\nalgorithm is a practical and effective tool for nonword generation.\n", "versions": [{"version": "v1", "created": "Tue, 4 Dec 2007 08:52:46 GMT"}], "update_date": "2007-12-05", "authors_parsed": [["De Lara", "Alejandro Chinea Manrique", ""]]}, {"id": "0712.0744", "submitter": "Vitorino Ramos Dr.", "authors": "Vitorino Ramos, C. M. Fernandes, A. C. Rosa, A. Abraham", "title": "Computational Chemotaxis in Ants and Bacteria over Dynamic Environments", "comments": "8 pages, 6 figures, in CEC 07 - IEEE Congress on Evolutionary\n  Computation, ISBN 1-4244-1340-0, pp. 1009-1017, Sep. 2007", "journal-ref": null, "doi": "10.1109/CEC.2007.4424594", "report-no": null, "categories": "cs.MA cs.AI q-bio.PE q-bio.QM", "license": null, "abstract": "  Chemotaxis can be defined as an innate behavioural response by an organism to\na directional stimulus, in which bacteria, and other single-cell or\nmulticellular organisms direct their movements according to certain chemicals\nin their environment. This is important for bacteria to find food (e.g.,\nglucose) by swimming towards the highest concentration of food molecules, or to\nflee from poisons. Based on self-organized computational approaches and similar\nstigmergic concepts we derive a novel swarm intelligent algorithm. What strikes\nfrom these observations is that both eusocial insects as ant colonies and\nbacteria have similar natural mechanisms based on stigmergy in order to emerge\ncoherent and sophisticated patterns of global collective behaviour. Keeping in\nmind the above characteristics we will present a simple model to tackle the\ncollective adaptation of a social swarm based on real ant colony behaviors (SSA\nalgorithm) for tracking extrema in dynamic environments and highly multimodal\ncomplex functions described in the well-know De Jong test suite. Later, for the\npurpose of comparison, a recent model of artificial bacterial foraging (BFOA\nalgorithm) based on similar stigmergic features is described and analyzed.\nFinal results indicate that the SSA collective intelligence is able to cope and\nquickly adapt to unforeseen situations even when over the same cooperative\nforaging period, the community is requested to deal with two different and\ncontradictory purposes, while outperforming BFOA in adaptive speed. Results\nindicate that the present approach deals well in severe Dynamic Optimization\nproblems.\n", "versions": [{"version": "v1", "created": "Wed, 5 Dec 2007 15:02:19 GMT"}], "update_date": "2016-11-18", "authors_parsed": [["Ramos", "Vitorino", ""], ["Fernandes", "C. M.", ""], ["Rosa", "A. C.", ""], ["Abraham", "A.", ""]]}, {"id": "0712.0836", "submitter": "Andrew Adamatzky", "authors": "Andrew Adamatzky, Larry Bull, Pierre Collet, Emmanuel Sapin", "title": "Evolving localizations in reaction-diffusion cellular automata", "comments": "Accepted for publication in Int. J. Modern Physics C", "journal-ref": "International Journal of Modern Physics C (IJMPC) Volume: 19,\n  Issue: 4 (April 2008) pp. 557-567", "doi": "10.1142/S0129183108012376", "report-no": null, "categories": "cs.AI", "license": null, "abstract": "  We consider hexagonal cellular automata with immediate cell neighbourhood and\nthree cell-states. Every cell calculates its next state depending on the\nintegral representation of states in its neighbourhood, i.e. how many\nneighbours are in each one state. We employ evolutionary algorithms to breed\nlocal transition functions that support mobile localizations (gliders), and\ncharacterize sets of the functions selected in terms of quasi-chemical systems.\nAnalysis of the set of functions evolved allows to speculate that mobile\nlocalizations are likely to emerge in the quasi-chemical systems with limited\ndiffusion of one reagent, a small number of molecules is required for\namplification of travelling localizations, and reactions leading to stationary\nlocalizations involve relatively equal amount of quasi-chemical species.\nTechniques developed can be applied in cascading signals in nature-inspired\nspatially extended computing devices, and phenomenological studies and\nclassification of non-linear discrete systems.\n", "versions": [{"version": "v1", "created": "Wed, 5 Dec 2007 22:07:04 GMT"}], "update_date": "2010-11-23", "authors_parsed": [["Adamatzky", "Andrew", ""], ["Bull", "Larry", ""], ["Collet", "Pierre", ""], ["Sapin", "Emmanuel", ""]]}, {"id": "0712.0932", "submitter": "Kumar Eswaran Dr.", "authors": "Dasika Ratna Deepthi, Sujeet Kuchibhotla and K.Eswaran", "title": "Dimensionality Reduction and Reconstruction using Mirroring Neural\n  Networks and Object Recognition based on Reduced Dimension Characteristic\n  Vector", "comments": "Presented in IEEE International Conference on Advances in Computer\n  Vision and Information Technology (ACVIT-07), Nov. 28-30 2007", "journal-ref": "IEEE International Conference On Advances in Computer Vision and\n  Information Tech. (IEEE, ACVIT-07), pp. 348 - 353 (2007)", "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.NE", "license": null, "abstract": "  In this paper, we present a Mirroring Neural Network architecture to perform\nnon-linear dimensionality reduction and Object Recognition using a reduced\nlowdimensional characteristic vector. In addition to dimensionality reduction,\nthe network also reconstructs (mirrors) the original high-dimensional input\nvector from the reduced low-dimensional data. The Mirroring Neural Network\narchitecture has more number of processing elements (adalines) in the outer\nlayers and the least number of elements in the central layer to form a\nconverging-diverging shape in its configuration. Since this network is able to\nreconstruct the original image from the output of the innermost layer (which\ncontains all the information about the input pattern), these outputs can be\nused as object signature to classify patterns. The network is trained to\nminimize the discrepancy between actual output and the input by back\npropagating the mean squared error from the output layer to the input layer.\nAfter successfully training the network, it can reduce the dimension of input\nvectors and mirror the patterns fed to it. The Mirroring Neural Network\narchitecture gave very good results on various test patterns.\n", "versions": [{"version": "v1", "created": "Thu, 6 Dec 2007 14:11:07 GMT"}], "update_date": "2008-12-13", "authors_parsed": [["Deepthi", "Dasika Ratna", ""], ["Kuchibhotla", "Sujeet", ""], ["Eswaran", "K.", ""]]}, {"id": "0712.0938", "submitter": "Kumar Eswaran Dr.", "authors": "Dasika Ratna Deepthi, G.R.Aditya Krishna and K. Eswaran", "title": "Automatic Pattern Classification by Unsupervised Learning Using\n  Dimensionality Reduction of Data with Mirroring Neural Networks", "comments": "Presented in IEEE International Conference on Advances in Computer\n  Vision and Information Technology (ACVIT-07), Nov. 28-30 2007", "journal-ref": "IEEE International Conference on Advances in Computer Vision and\n  Information Tech. (IEEE, ACVIT-07), pp. 354 - 360 (2007)", "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE", "license": null, "abstract": "  This paper proposes an unsupervised learning technique by using Multi-layer\nMirroring Neural Network and Forgy's clustering algorithm. Multi-layer\nMirroring Neural Network is a neural network that can be trained with\ngeneralized data inputs (different categories of image patterns) to perform\nnon-linear dimensionality reduction and the resultant low-dimensional code is\nused for unsupervised pattern classification using Forgy's algorithm. By\nadapting the non-linear activation function (modified sigmoidal function) and\ninitializing the weights and bias terms to small random values, mirroring of\nthe input pattern is initiated. In training, the weights and bias terms are\nchanged in such a way that the input presented is reproduced at the output by\nback propagating the error. The mirroring neural network is capable of reducing\nthe input vector to a great degree (approximately 1/30th the original size) and\nalso able to reconstruct the input pattern at the output layer from this\nreduced code units. The feature set (output of central hidden layer) extracted\nfrom this network is fed to Forgy's algorithm, which classify input data\npatterns into distinguishable classes. In the implementation of Forgy's\nalgorithm, initial seed points are selected in such a way that they are distant\nenough to be perfectly grouped into different categories. Thus a new method of\nunsupervised learning is formulated and demonstrated in this paper. This method\ngave impressive results when applied to classification of different image\npatterns.\n", "versions": [{"version": "v1", "created": "Thu, 6 Dec 2007 13:52:04 GMT"}], "update_date": "2008-12-15", "authors_parsed": [["Deepthi", "Dasika Ratna", ""], ["Krishna", "G. R. Aditya", ""], ["Eswaran", "K.", ""]]}, {"id": "0712.0948", "submitter": "Stefan Woltran", "authors": "Stefan Woltran", "title": "A Common View on Strong, Uniform, and Other Notions of Equivalence in\n  Answer-Set Programming", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": null, "abstract": "  Logic programming under the answer-set semantics nowadays deals with numerous\ndifferent notions of program equivalence. This is due to the fact that\nequivalence for substitution (known as strong equivalence) and ordinary\nequivalence are different concepts. The former holds, given programs P and Q,\niff P can be faithfully replaced by Q within any context R, while the latter\nholds iff P and Q provide the same output, that is, they have the same answer\nsets. Notions in between strong and ordinary equivalence have been introduced\nas theoretical tools to compare incomplete programs and are defined by either\nrestricting the syntactic structure of the considered context programs R or by\nbounding the set A of atoms allowed to occur in R (relativized equivalence).For\nthe latter approach, different A yield properly different equivalence notions,\nin general. For the former approach, however, it turned out that any\n``reasonable'' syntactic restriction to R coincides with either ordinary,\nstrong, or uniform equivalence. In this paper, we propose a parameterization\nfor equivalence notions which takes care of both such kinds of restrictions\nsimultaneously by bounding, on the one hand, the atoms which are allowed to\noccur in the rule heads of the context and, on the other hand, the atoms which\nare allowed to occur in the rule bodies of the context. We introduce a general\nsemantical characterization which includes known ones as SE-models (for strong\nequivalence) or UE-models (for uniform equivalence) as special cases.\nMoreover,we provide complexity bounds for the problem in question and sketch a\npossible implementation method.\n  To appear in Theory and Practice of Logic Programming (TPLP).\n", "versions": [{"version": "v1", "created": "Thu, 6 Dec 2007 14:26:42 GMT"}], "update_date": "2007-12-07", "authors_parsed": [["Woltran", "Stefan", ""]]}, {"id": "0712.1097", "submitter": "Joao Marques-Silva", "authors": "Joao Marques-Silva, Jordi Planes", "title": "On Using Unsatisfiability for Solving Maximum Satisfiability", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.DS", "license": null, "abstract": "  Maximum Satisfiability (MaxSAT) is a well-known optimization pro- blem, with\nseveral practical applications. The most widely known MAXS AT algorithms are\nineffective at solving hard problems instances from practical application\ndomains. Recent work proposed using efficient Boolean Satisfiability (SAT)\nsolvers for solving the MaxSAT problem, based on identifying and eliminating\nunsatisfiable subformulas. However, these algorithms do not scale in practice.\nThis paper analyzes existing MaxSAT algorithms based on unsatisfiable\nsubformula identification. Moreover, the paper proposes a number of key\noptimizations to these MaxSAT algorithms and a new alternative algorithm. The\nproposed optimizations and the new algorithm provide significant performance\nimprovements on MaxSAT instances from practical applications. Moreover, the\nefficiency of the new generation of unsatisfiability-based MaxSAT solvers\nbecomes effectively indexed to the ability of modern SAT solvers to proving\nunsatisfiability and identifying unsatisfiable subformulas.\n", "versions": [{"version": "v1", "created": "Fri, 7 Dec 2007 09:21:58 GMT"}], "update_date": "2007-12-10", "authors_parsed": [["Marques-Silva", "Joao", ""], ["Planes", "Jordi", ""]]}, {"id": "0712.1182", "submitter": "Audun Josang", "authors": "Audun Josang", "title": "Cumulative and Averaging Fission of Beliefs", "comments": "7 pages, 4 figures, working paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": null, "abstract": "  Belief fusion is the principle of combining separate beliefs or bodies of\nevidence originating from different sources. Depending on the situation to be\nmodelled, different belief fusion methods can be applied. Cumulative and\naveraging belief fusion is defined for fusing opinions in subjective logic, and\nfor fusing belief functions in general. The principle of fission is the\nopposite of fusion, namely to eliminate the contribution of a specific belief\nfrom an already fused belief, with the purpose of deriving the remaining\nbelief. This paper describes fission of cumulative belief as well as fission of\naveraging belief in subjective logic. These operators can for example be\napplied to belief revision in Bayesian belief networks, where the belief\ncontribution of a given evidence source can be determined as a function of a\ngiven fused belief and its other contributing beliefs.\n", "versions": [{"version": "v1", "created": "Fri, 7 Dec 2007 16:42:07 GMT"}], "update_date": "2007-12-10", "authors_parsed": [["Josang", "Audun", ""]]}, {"id": "0712.1310", "submitter": "Lev Cherbanski Dr.", "authors": "Lev Cherbanski", "title": "About Algorithm for Transformation of Logic Functions (ATLF)", "comments": "25 pages, in English, German and Russian", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI", "license": null, "abstract": "  In this article the algorithm for transformation of logic functions which are\ngiven by truth tables is considered. The suggested algorithm allows the\ntransformation of many-valued logic functions with the required number of\nvariables and can be looked in this sense as universal.\n", "versions": [{"version": "v1", "created": "Sat, 8 Dec 2007 22:36:44 GMT"}], "update_date": "2007-12-11", "authors_parsed": [["Cherbanski", "Lev", ""]]}, {"id": "0712.1345", "submitter": "Giorgi Japaridze", "authors": "Giorgi Japaridze", "title": "Sequential operators in computability logic", "comments": "To appear in \"Information and Computation\"", "journal-ref": "Information and Computation 206 (2008), pp. 1443-1475", "doi": "10.1016/j.ic.2008.10.001", "report-no": null, "categories": "cs.LO cs.AI math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computability logic (CL) (see http://www.cis.upenn.edu/~giorgi/cl.html) is a\nsemantical platform and research program for redeveloping logic as a formal\ntheory of computability, as opposed to the formal theory of truth which it has\nmore traditionally been. Formulas in CL stand for (interactive) computational\nproblems, understood as games between a machine and its environment; logical\noperators represent operations on such entities; and \"truth\" is understood as\nexistence of an effective solution, i.e., of an algorithmic winning strategy.\n  The formalism of CL is open-ended, and may undergo series of extensions as\nthe study of the subject advances. The main groups of operators on which CL has\nbeen focused so far are the parallel, choice, branching, and blind operators.\nThe present paper introduces a new important group of operators, called\nsequential. The latter come in the form of sequential conjunction and\ndisjunction, sequential quantifiers, and sequential recurrences. As the name\nmay suggest, the algorithmic intuitions associated with this group are those of\nsequential computations, as opposed to the intuitions of parallel computations\nassociated with the parallel group of operations: playing a sequential\ncombination of games means playing its components in a sequential fashion, one\nafter one.\n  The main technical result of the present paper is a sound and complete\naxiomatization of the propositional fragment of computability logic whose\nvocabulary, together with negation, includes all three -- parallel, choice and\nsequential -- sorts of conjunction and disjunction. An extension of this result\nto the first-order level is also outlined.\n", "versions": [{"version": "v1", "created": "Sun, 9 Dec 2007 16:59:35 GMT"}, {"version": "v2", "created": "Wed, 15 Oct 2008 07:44:55 GMT"}], "update_date": "2011-04-15", "authors_parsed": [["Japaridze", "Giorgi", ""]]}, {"id": "0712.1365", "submitter": "Alexei Vazquez", "authors": "Alexei Vazquez", "title": "Population stratification using a statistical model on hypergraphs", "comments": "7 pages, 6 figures", "journal-ref": "Phys. Rev. E 77, 066106 (2008)", "doi": "10.1103/PhysRevE.77.066106", "report-no": null, "categories": "q-bio.PE cs.AI physics.data-an", "license": null, "abstract": "  Population stratification is a problem encountered in several areas of\nbiology and public health. We tackle this problem by mapping a population and\nits elements attributes into a hypergraph, a natural extension of the concept\nof graph or network to encode associations among any number of elements. On\nthis hypergraph, we construct a statistical model reflecting our intuition\nabout how the elements attributes can emerge from a postulated population\nstructure. Finally, we introduce the concept of stratification\nrepresentativeness as a mean to identify the simplest stratification already\ncontaining most of the information about the population structure. We\ndemonstrate the power of this framework stratifying an animal and a human\npopulation based on phenotypic and genotypic properties, respectively.\n", "versions": [{"version": "v1", "created": "Sun, 9 Dec 2007 20:53:45 GMT"}], "update_date": "2009-11-13", "authors_parsed": [["Vazquez", "Alexei", ""]]}, {"id": "0712.1529", "submitter": "W Saba", "authors": "Walid S. Saba", "title": "Ontology and Formal Semantics - Integration Overdue", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": null, "abstract": "  In this note we suggest that difficulties encountered in natural language\nsemantics are, for the most part, due to the use of mere symbol manipulation\nsystems that are devoid of any content. In such systems, where there is hardly\nany link with our common-sense view of the world, and it is quite difficult to\nenvision how one can formally account for the considerable amount of content\nthat is often implicit, but almost never explicitly stated in our everyday\ndiscourse. The solution, in our opinion, is a compositional semantics grounded\nin an ontology that reflects our commonsense view of the world and the way we\ntalk about it in ordinary language. In the compositional logic we envision\nthere are ontological (or first-intension) concepts, and logical (or\nsecond-intension) concepts, and where the ontological concepts include not only\nDavidsonian events, but other abstract objects as well (e.g., states,\nprocesses, properties, activities, attributes, etc.) It will be demonstrated\nhere that in such a framework, a number of challenges in the semantics of\nnatural language (e.g., metonymy, intensionality, metaphor, etc.) can be\nproperly and uniformly addressed.\n", "versions": [{"version": "v1", "created": "Sat, 1 Dec 2007 14:27:12 GMT"}, {"version": "v2", "created": "Thu, 13 Dec 2007 20:25:26 GMT"}], "update_date": "2007-12-13", "authors_parsed": [["Saba", "Walid S.", ""]]}, {"id": "0712.2141", "submitter": "Sebastien Destercke", "authors": "Eric Chojnacki (IRSN), Jean Baccou (IRSN), S\\'ebastien Destercke\n  (IRSN, IRIT)", "title": "Numerical Sensitivity and Efficiency in the Treatment of Epistemic and\n  Aleatory Uncertainty", "comments": null, "journal-ref": "Fifth International Conference on Sensitivity Analysis of Model\n  Output, Budapest : Hongrie (2007)", "doi": null, "report-no": null, "categories": "cs.AI math.PR", "license": null, "abstract": "  The treatment of both aleatory and epistemic uncertainty by recent methods\noften requires an high computational effort. In this abstract, we propose a\nnumerical sampling method allowing to lighten the computational burden of\ntreating the information by means of so-called fuzzy random variables.\n", "versions": [{"version": "v1", "created": "Thu, 13 Dec 2007 12:49:30 GMT"}], "update_date": "2007-12-14", "authors_parsed": [["Chojnacki", "Eric", "", "IRSN"], ["Baccou", "Jean", "", "IRSN"], ["Destercke", "S\u00e9bastien", "", "IRSN, IRIT"]]}, {"id": "0712.2389", "submitter": "Guido Tack", "authors": "Martin Mann and Guido Tack and Sebastian Will", "title": "Decomposition During Search for Propagation-Based Constraint Solvers", "comments": "20 pages, 9 figures, 2 tables; longer, more detailed version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe decomposition during search (DDS), an integration of And/Or tree\nsearch into propagation-based constraint solvers. The presented search\nalgorithm dynamically decomposes sub-problems of a constraint satisfaction\nproblem into independent partial problems, avoiding redundant work.\n  The paper discusses how DDS interacts with key features that make\npropagation-based solvers successful: constraint propagation, especially for\nglobal constraints, and dynamic search heuristics.\n  We have implemented DDS for the Gecode constraint programming library. Two\napplications, solution counting in graph coloring and protein structure\nprediction, exemplify the benefits of DDS in practice.\n", "versions": [{"version": "v1", "created": "Fri, 14 Dec 2007 18:08:26 GMT"}, {"version": "v2", "created": "Wed, 11 Jun 2008 13:00:11 GMT"}], "update_date": "2008-06-11", "authors_parsed": [["Mann", "Martin", ""], ["Tack", "Guido", ""], ["Will", "Sebastian", ""]]}, {"id": "0712.3147", "submitter": "Pierre Lescanne", "authors": "Pierre Lescanne (LIP)", "title": "Common knowledge logic in a higher order proof assistant?", "comments": "11 p", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": null, "abstract": "  This paper presents experiments on common knowledge logic, conducted with the\nhelp of the proof assistant Coq. The main feature of common knowledge logic is\nthe eponymous modality that says that a group of agents shares a knowledge\nabout a certain proposition in a inductive way. This modality is specified by\nusing a fixpoint approach. Furthermore, from these experiments, we discuss and\ncompare the structure of theorems that can be proved in specific theories that\nuse common knowledge logic. Those structures manifests the interplay between\nthe theory (as implemented in the proof assistant Coq) and the metatheory.\n", "versions": [{"version": "v1", "created": "Wed, 19 Dec 2007 10:25:34 GMT"}, {"version": "v2", "created": "Tue, 15 Jan 2008 16:12:50 GMT"}], "update_date": "2008-01-16", "authors_parsed": [["Lescanne", "Pierre", "", "LIP"]]}, {"id": "0712.3329", "submitter": "Marcus Hutter", "authors": "Shane Legg and Marcus Hutter", "title": "Universal Intelligence: A Definition of Machine Intelligence", "comments": "50 gentle pages", "journal-ref": "Minds & Machines, 17:4 (2007) pages 391-444", "doi": null, "report-no": "IDSIA-10-07", "categories": "cs.AI", "license": null, "abstract": "  A fundamental problem in artificial intelligence is that nobody really knows\nwhat intelligence is. The problem is especially acute when we need to consider\nartificial systems which are significantly different to humans. In this paper\nwe approach this problem in the following way: We take a number of well known\ninformal definitions of human intelligence that have been given by experts, and\nextract their essential features. These are then mathematically formalised to\nproduce a general measure of intelligence for arbitrary machines. We believe\nthat this equation formally captures the concept of machine intelligence in the\nbroadest reasonable sense. We then show how this formal definition is related\nto the theory of universal optimal learning agents. Finally, we survey the many\nother tests and definitions of intelligence that have been proposed for\nmachines.\n", "versions": [{"version": "v1", "created": "Thu, 20 Dec 2007 05:50:54 GMT"}], "update_date": "2008-06-26", "authors_parsed": [["Legg", "Shane", ""], ["Hutter", "Marcus", ""]]}, {"id": "0712.3654", "submitter": "Alejandro Chinea Manrique De Lara", "authors": "Alejandro Chinea Manrique De Lara, Juan Manuel Moreno, Arostegui Jordi\n  Madrenas, Joan Cabestany", "title": "Improving the Performance of PieceWise Linear Separation Incremental\n  Algorithms for Practical Hardware Implementations", "comments": "10 pages, 1 figure, 3 tables", "journal-ref": "Biological and Artificial Computation: From Neuroscience to\n  Technology, J.Mira, R.Moreno-Diaz, J.Cabestany (eds.), pp. 607-616,\n  Springer-Verlag, 1997", "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.LG", "license": null, "abstract": "  In this paper we shall review the common problems associated with Piecewise\nLinear Separation incremental algorithms. This kind of neural models yield poor\nperformances when dealing with some classification problems, due to the\nevolving schemes used to construct the resulting networks. So as to avoid this\nundesirable behavior we shall propose a modification criterion. It is based\nupon the definition of a function which will provide information about the\nquality of the network growth process during the learning phase. This function\nis evaluated periodically as the network structure evolves, and will permit, as\nwe shall show through exhaustive benchmarks, to considerably improve the\nperformance(measured in terms of network complexity and generalization\ncapabilities) offered by the networks generated by these incremental models.\n", "versions": [{"version": "v1", "created": "Fri, 21 Dec 2007 10:05:52 GMT"}], "update_date": "2007-12-24", "authors_parsed": [["De Lara", "Alejandro Chinea Manrique", ""], ["Moreno", "Juan Manuel", ""], ["Madrenas", "Arostegui Jordi", ""], ["Cabestany", "Joan", ""]]}, {"id": "0712.3825", "submitter": "Marcus Hutter", "authors": "Shane Legg and Marcus Hutter", "title": "Tests of Machine Intelligence", "comments": "12 pages; 1 table. Turing test and derivatives; Compression tests;\n  Linguistic complexity; Multiple cognitive abilities; Competitive games;\n  Psychometric tests; Smith's test; C-test; Universal intelligence", "journal-ref": "50 Years of Artificial Intelligence (2007) pages 232-242", "doi": null, "report-no": "IDSIA-11-07", "categories": "cs.AI", "license": null, "abstract": "  Although the definition and measurement of intelligence is clearly of\nfundamental importance to the field of artificial intelligence, no general\nsurvey of definitions and tests of machine intelligence exists. Indeed few\nresearchers are even aware of alternatives to the Turing test and its many\nderivatives. In this paper we fill this gap by providing a short survey of the\nmany tests of machine intelligence that have been proposed.\n", "versions": [{"version": "v1", "created": "Sat, 22 Dec 2007 01:17:24 GMT"}], "update_date": "2008-06-26", "authors_parsed": [["Legg", "Shane", ""], ["Hutter", "Marcus", ""]]}, {"id": "0712.4126", "submitter": "Chandan Reddy", "authors": "Chandan K. Reddy", "title": "TRUST-TECH based Methods for Optimization and Learning", "comments": "PHD Thesis", "journal-ref": "Chandan K. Reddy, TRUST-TECH based Methods for Optimization and\n  Learning, PHD Thesis, Cornell University, February 2007", "doi": null, "report-no": null, "categories": "cs.AI cs.CE cs.MS cs.NA cs.NE", "license": null, "abstract": "  Many problems that arise in machine learning domain deal with nonlinearity\nand quite often demand users to obtain global optimal solutions rather than\nlocal optimal ones. Optimization problems are inherent in machine learning\nalgorithms and hence many methods in machine learning were inherited from the\noptimization literature. Popularly known as the initialization problem, the\nideal set of parameters required will significantly depend on the given\ninitialization values. The recently developed TRUST-TECH (TRansformation Under\nSTability-reTaining Equilibria CHaracterization) methodology systematically\nexplores the subspace of the parameters to obtain a complete set of local\noptimal solutions. In this thesis work, we propose TRUST-TECH based methods for\nsolving several optimization and machine learning problems. Two stages namely,\nthe local stage and the neighborhood-search stage, are repeated alternatively\nin the solution space to achieve improvements in the quality of the solutions.\nOur methods were tested on both synthetic and real datasets and the advantages\nof using this novel framework are clearly manifested. This framework not only\nreduces the sensitivity to initialization, but also allows the flexibility for\nthe practitioners to use various global and local methods that work well for a\nparticular problem of interest. Other hierarchical stochastic algorithms like\nevolutionary algorithms and smoothing algorithms are also studied and\nframeworks for combining these methods with TRUST-TECH have been proposed and\nevaluated on several test systems.\n", "versions": [{"version": "v1", "created": "Tue, 25 Dec 2007 03:14:32 GMT"}], "update_date": "2007-12-27", "authors_parsed": [["Reddy", "Chandan K.", ""]]}, {"id": "0712.4318", "submitter": "Peter de Blanc", "authors": "Peter de Blanc", "title": "Convergence of Expected Utilities with Algorithmic Probability\n  Distributions", "comments": "2 pages + title page, references", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": null, "abstract": "  We consider an agent interacting with an unknown environment. The environment\nis a function which maps natural numbers to natural numbers; the agent's set of\nhypotheses about the environment contains all such functions which are\ncomputable and compatible with a finite set of known input-output pairs, and\nthe agent assigns a positive probability to each such hypothesis. We do not\nrequire that this probability distribution be computable, but it must be\nbounded below by a positive computable function. The agent has a utility\nfunction on outputs from the environment. We show that if this utility function\nis bounded below in absolute value by an unbounded computable function, then\nthe expected utility of any input is undefined. This implies that a computable\nutility function will have convergent expected utilities iff that function is\nbounded.\n", "versions": [{"version": "v1", "created": "Fri, 28 Dec 2007 07:50:00 GMT"}], "update_date": "2007-12-31", "authors_parsed": [["de Blanc", "Peter", ""]]}, {"id": "0712.4402", "submitter": "Ruadhan O'Flanagan", "authors": "Ruadhan O'Flanagan", "title": "Judgment", "comments": "20 pages; minor changes; references added; submitted", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR cs.AI math.LO", "license": null, "abstract": "  The concept of a judgment as a logical action which introduces new\ninformation into a deductive system is examined. This leads to a way of\nmathematically representing implication which is distinct from the familiar\nmaterial implication, according to which \"If A then B\" is considered to be\nequivalent to \"B or not-A\". This leads, in turn, to a resolution of the paradox\nof the raven.\n", "versions": [{"version": "v1", "created": "Fri, 28 Dec 2007 21:00:01 GMT"}, {"version": "v2", "created": "Sat, 29 Dec 2007 03:57:26 GMT"}, {"version": "v3", "created": "Fri, 18 Jan 2008 21:30:57 GMT"}], "update_date": "2011-11-10", "authors_parsed": [["O'Flanagan", "Ruadhan", ""]]}]