[{"id": "2007.00049", "submitter": "Sunipa Dev", "authors": "Sunipa Dev, Tao Li, Jeff M Phillips, Vivek Srikumar", "title": "OSCaR: Orthogonal Subspace Correction and Rectification of Biases in\n  Word Embeddings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Language representations are known to carry stereotypical biases and, as a\nresult, lead to biased predictions in downstream tasks. While existing methods\nare effective at mitigating biases by linear projection, such methods are too\naggressive: they not only remove bias, but also erase valuable information from\nword embeddings. We develop new measures for evaluating specific information\nretention that demonstrate the tradeoff between bias removal and information\nretention. To address this challenge, we propose OSCaR (Orthogonal Subspace\nCorrection and Rectification), a bias-mitigating method that focuses on\ndisentangling biased associations between concepts instead of removing concepts\nwholesale. Our experiments on gender biases show that OSCaR is a well-balanced\napproach that ensures that semantic information is retained in the embeddings\nand bias is also effectively mitigated.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jun 2020 18:18:13 GMT"}], "update_date": "2020-07-02", "authors_parsed": [["Dev", "Sunipa", ""], ["Li", "Tao", ""], ["Phillips", "Jeff M", ""], ["Srikumar", "Vivek", ""]]}, {"id": "2007.00059", "submitter": "Asaf Shabtai", "authors": "Noam Moscovich, Ron Bitton, Yakov Mallah, Masaki Inokuchi, Tomohiko\n  Yagyu, Meir Kalech, Yuval Elovici, Asaf Shabtai", "title": "Autosploit: A Fully Automated Framework for Evaluating the\n  Exploitability of Security Vulnerabilities", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The existence of a security vulnerability in a system does not necessarily\nmean that it can be exploited. In this research, we introduce Autosploit -- an\nautomated framework for evaluating the exploitability of vulnerabilities. Given\na vulnerable environment and relevant exploits, Autosploit will automatically\ntest the exploits on different configurations of the environment in order to\nidentify the specific properties necessary for successful exploitation of the\nexisting vulnerabilities. Since testing all possible system configurations is\ninfeasible, we introduce an efficient approach for testing and searching\nthrough all possible configurations of the environment. The efficient testing\nprocess implemented by Autosploit is based on two algorithms: generalized\nbinary splitting and Barinel, which are used for noiseless and noisy\nenvironments respectively. We implemented the proposed framework and evaluated\nit using real vulnerabilities. The results show that Autosploit is able to\nautomatically identify the system properties that affect the ability to exploit\na vulnerability in both noiseless and noisy environments. These important\nresults can be utilized for more accurate and effective risk assessment.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jun 2020 18:49:18 GMT"}], "update_date": "2020-07-02", "authors_parsed": [["Moscovich", "Noam", ""], ["Bitton", "Ron", ""], ["Mallah", "Yakov", ""], ["Inokuchi", "Masaki", ""], ["Yagyu", "Tomohiko", ""], ["Kalech", "Meir", ""], ["Elovici", "Yuval", ""], ["Shabtai", "Asaf", ""]]}, {"id": "2007.00077", "submitter": "Cody Coleman", "authors": "Cody Coleman, Edward Chou, Julian Katz-Samuels, Sean Culatana, Peter\n  Bailis, Alexander C. Berg, Robert Nowak, Roshan Sumbaly, Matei Zaharia, I.\n  Zeki Yalniz", "title": "Similarity Search for Efficient Active Learning and Search of Rare\n  Concepts", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many active learning and search approaches are intractable for large-scale\nindustrial settings with billions of unlabeled examples. Existing approaches\nsearch globally for the optimal examples to label, scaling linearly or even\nquadratically with the unlabeled data. In this paper, we improve the\ncomputational efficiency of active learning and search methods by restricting\nthe candidate pool for labeling to the nearest neighbors of the currently\nlabeled set instead of scanning over all of the unlabeled data. We evaluate\nseveral selection strategies in this setting on three large-scale computer\nvision datasets: ImageNet, OpenImages, and a de-identified and aggregated\ndataset of 10 billion images provided by a large internet company. Our approach\nachieved similar mean average precision and recall as the traditional global\napproach while reducing the computational cost of selection by up to three\norders of magnitude, thus enabling web-scale active learning.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jun 2020 19:46:10 GMT"}, {"version": "v2", "created": "Thu, 22 Jul 2021 16:54:12 GMT"}], "update_date": "2021-07-23", "authors_parsed": [["Coleman", "Cody", ""], ["Chou", "Edward", ""], ["Katz-Samuels", "Julian", ""], ["Culatana", "Sean", ""], ["Bailis", "Peter", ""], ["Berg", "Alexander C.", ""], ["Nowak", "Robert", ""], ["Sumbaly", "Roshan", ""], ["Zaharia", "Matei", ""], ["Yalniz", "I. Zeki", ""]]}, {"id": "2007.00085", "submitter": "Nils Jansen", "authors": "Sebastian Junges, Nils Jansen, Sanjit A. Seshia", "title": "Enforcing Almost-Sure Reachability in POMDPs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.RO cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Partially-Observable Markov Decision Processes (POMDPs) are a well-known\nstochastic model for sequential decision making under limited information. We\nconsider the EXPTIME-hard problem of synthesising policies that almost-surely\nreach some goal state without ever visiting a bad state. In particular, we are\ninterested in computing the winning region, that is, the set of system\nconfigurations from which a policy exists that satisfies the reachability\nspecification. A direct application of such a winning region is the safe\nexploration of POMDPs by, for instance, restricting the behavior of a\nreinforcement learning agent to the region. We present two algorithms: A novel\nSAT-based iterative approach and a decision-diagram based alternative. The\nempirical evaluation demonstrates the feasibility and efficacy of the\napproaches.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jun 2020 19:59:46 GMT"}, {"version": "v2", "created": "Tue, 29 Sep 2020 07:51:28 GMT"}, {"version": "v3", "created": "Thu, 18 Mar 2021 23:07:15 GMT"}], "update_date": "2021-03-22", "authors_parsed": [["Junges", "Sebastian", ""], ["Jansen", "Nils", ""], ["Seshia", "Sanjit A.", ""]]}, {"id": "2007.00102", "submitter": "Sebastian Junges", "authors": "Alexander Bork, Sebastian Junges, Joost-Pieter Katoen, Tim Quatmann", "title": "Verification of indefinite-horizon POMDPs", "comments": "Technical report for ATVA 2020 paper with the same title", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The verification problem in MDPs asks whether, for any policy resolving the\nnondeterminism, the probability that something bad happens is bounded by some\ngiven threshold. This verification problem is often overly pessimistic, as the\npolicies it considers may depend on the complete system state. This paper\nconsiders the verification problem for partially observable MDPs, in which the\npolicies make their decisions based on (the history of) the observations\nemitted by the system. We present an abstraction-refinement framework extending\nprevious instantiations of the Lovejoy-approach. Our experiments show that this\nframework significantly improves the scalability of the approach.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jun 2020 21:01:52 GMT"}], "update_date": "2020-07-02", "authors_parsed": [["Bork", "Alexander", ""], ["Junges", "Sebastian", ""], ["Katoen", "Joost-Pieter", ""], ["Quatmann", "Tim", ""]]}, {"id": "2007.00125", "submitter": "David A. Plaisted", "authors": "David A. Plaisted", "title": "Situation Calculus by Term Rewriting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A version of the situation calculus in which situations are represented as\nfirst-order terms is presented. Fluents can be computed from the term\nstructure, and actions on the situations correspond to rewrite rules on the\nterms. Actions that only depend on or influence a subset of the fluents can be\ndescribed as rewrite rules that operate on subterms of the terms in some cases.\nIf actions are bidirectional then efficient completion methods can be used to\nsolve planning problems. This representation for situations and actions is most\nsimilar to the fluent calculus of Thielscher \\cite{Thielscher98}, except that\nthis representation is more flexible and more use is made of the subterm\nstructure. Some examples are given, and a few general methods for constructing\nsuch sets of rewrite rules are presented. This paper was submitted to FSCD 2020\non December 23, 2019.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jun 2020 21:47:47 GMT"}], "update_date": "2020-07-02", "authors_parsed": [["Plaisted", "David A.", ""]]}, {"id": "2007.00161", "submitter": "Ransalu Senanayake", "authors": "Ransalu Senanayake, Maneekwan Toyungyernsub, Mingyu Wang, Mykel J.\n  Kochenderfer, and Mac Schwager", "title": "Directional Primitives for Uncertainty-Aware Motion Estimation in Urban\n  Environments", "comments": "The 23rd IEEE International Conference on Intelligent Transportation\n  Systems. September, 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We can use driving data collected over a long period of time to extract rich\ninformation about how vehicles behave in different areas of the roads. In this\npaper, we introduce the concept of directional primitives, which is a\nrepresentation of prior information of road networks. Specifically, we\nrepresent the uncertainty of directions using a mixture of von Mises\ndistributions and associated speeds using gamma distributions. These\nlocation-dependent primitives can be combined with motion information of\nsurrounding vehicles to predict their future behavior in the form of\nprobability distributions. Experiments conducted on highways, intersections,\nand roundabouts in the Carla simulator, as well as real-world urban driving\ndatasets, indicate that primitives lead to better uncertainty-aware motion\nestimation.\n", "versions": [{"version": "v1", "created": "Wed, 1 Jul 2020 00:22:31 GMT"}], "update_date": "2020-07-02", "authors_parsed": [["Senanayake", "Ransalu", ""], ["Toyungyernsub", "Maneekwan", ""], ["Wang", "Mingyu", ""], ["Kochenderfer", "Mykel J.", ""], ["Schwager", "Mac", ""]]}, {"id": "2007.00162", "submitter": "Wonjun Ko", "authors": "Wonjun Ko, Eunjin Jeon, and Heung-Il Suk", "title": "A Novel RL-assisted Deep Learning Framework for Task-informative Signals\n  Selection and Classification for Spontaneous BCIs", "comments": "8 pages, 6 figures, 2 tables, and under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we formulate the problem of estimating and selecting\ntask-relevant temporal signal segments from a single EEG trial in the form of a\nMarkov decision process and propose a novel reinforcement-learning mechanism\nthat can be combined with the existing deep-learning based BCI methods. To be\nspecific, we devise an actor-critic network such that an agent can determine\nwhich timepoints need to be used (informative) or discarded (uninformative) in\ncomposing the intention-related features in a given trial, and thus enhancing\nthe intention identification performance. To validate the effectiveness of our\nproposed method, we conducted experiments with a publicly available big MI\ndataset and applied our novel mechanism to various recent deep-learning\narchitectures designed for MI classification. Based on the exhaustive\nexperiments, we observed that our proposed method helped achieve statistically\nsignificant improvements in performance.\n", "versions": [{"version": "v1", "created": "Wed, 1 Jul 2020 00:35:41 GMT"}], "update_date": "2020-07-02", "authors_parsed": [["Ko", "Wonjun", ""], ["Jeon", "Eunjin", ""], ["Suk", "Heung-Il", ""]]}, {"id": "2007.00178", "submitter": "Erdem B{\\i}y{\\i}k", "authors": "Zhangjie Cao, Erdem B{\\i}y{\\i}k, Woodrow Z. Wang, Allan Raventos,\n  Adrien Gaidon, Guy Rosman, Dorsa Sadigh", "title": "Reinforcement Learning based Control of Imitative Policies for\n  Near-Accident Driving", "comments": "10 pages, 7 figures. Published at Robotics: Science and Systems (RSS)\n  2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Autonomous driving has achieved significant progress in recent years, but\nautonomous cars are still unable to tackle high-risk situations where a\npotential accident is likely. In such near-accident scenarios, even a minor\nchange in the vehicle's actions may result in drastically different\nconsequences. To avoid unsafe actions in near-accident scenarios, we need to\nfully explore the environment. However, reinforcement learning (RL) and\nimitation learning (IL), two widely-used policy learning methods, cannot model\nrapid phase transitions and are not scalable to fully cover all the states. To\naddress driving in near-accident scenarios, we propose a hierarchical\nreinforcement and imitation learning (H-ReIL) approach that consists of\nlow-level policies learned by IL for discrete driving modes, and a high-level\npolicy learned by RL that switches between different driving modes. Our\napproach exploits the advantages of both IL and RL by integrating them into a\nunified learning framework. Experimental results and user studies suggest our\napproach can achieve higher efficiency and safety compared to other methods.\nAnalyses of the policies demonstrate our high-level policy appropriately\nswitches between different low-level policies in near-accident driving\nsituations.\n", "versions": [{"version": "v1", "created": "Wed, 1 Jul 2020 01:41:45 GMT"}], "update_date": "2020-07-02", "authors_parsed": [["Cao", "Zhangjie", ""], ["B\u0131y\u0131k", "Erdem", ""], ["Wang", "Woodrow Z.", ""], ["Raventos", "Allan", ""], ["Gaidon", "Adrien", ""], ["Rosman", "Guy", ""], ["Sadigh", "Dorsa", ""]]}, {"id": "2007.00229", "submitter": "Xin Eric Wang", "authors": "Wanrong Zhu, Xin Eric Wang, Tsu-Jui Fu, An Yan, Pradyumna Narayana,\n  Kazoo Sone, Sugato Basu, William Yang Wang", "title": "Multimodal Text Style Transfer for Outdoor Vision-and-Language\n  Navigation", "comments": "EACL 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the most challenging topics in Natural Language Processing (NLP) is\nvisually-grounded language understanding and reasoning. Outdoor\nvision-and-language navigation (VLN) is such a task where an agent follows\nnatural language instructions and navigates a real-life urban environment. Due\nto the lack of human-annotated instructions that illustrate intricate urban\nscenes, outdoor VLN remains a challenging task to solve. This paper introduces\na Multimodal Text Style Transfer (MTST) learning approach and leverages\nexternal multimodal resources to mitigate data scarcity in outdoor navigation\ntasks. We first enrich the navigation data by transferring the style of the\ninstructions generated by Google Maps API, then pre-train the navigator with\nthe augmented external outdoor navigation dataset. Experimental results show\nthat our MTST learning approach is model-agnostic, and our MTST approach\nsignificantly outperforms the baseline models on the outdoor VLN task,\nimproving task completion rate by 8.7% relatively on the test set.\n", "versions": [{"version": "v1", "created": "Wed, 1 Jul 2020 04:29:07 GMT"}, {"version": "v2", "created": "Tue, 26 Jan 2021 09:43:58 GMT"}, {"version": "v3", "created": "Thu, 4 Feb 2021 04:48:23 GMT"}], "update_date": "2021-02-05", "authors_parsed": [["Zhu", "Wanrong", ""], ["Wang", "Xin Eric", ""], ["Fu", "Tsu-Jui", ""], ["Yan", "An", ""], ["Narayana", "Pradyumna", ""], ["Sone", "Kazoo", ""], ["Basu", "Sugato", ""], ["Wang", "William Yang", ""]]}, {"id": "2007.00236", "submitter": "Cunxiang Wang", "authors": "Cunxiang Wang, Shuailong Liang, Yili Jin, Yilong Wang, Xiaodan Zhu and\n  Yue Zhang", "title": "SemEval-2020 Task 4: Commonsense Validation and Explanation", "comments": "Task description paper of SemEval-2020 Task 4: Commonsense Validation\n  and Explanation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present SemEval-2020 Task 4, Commonsense Validation and\nExplanation (ComVE), which includes three subtasks, aiming to evaluate whether\na system can distinguish a natural language statement that makes sense to\nhumans from one that does not, and provide the reasons. Specifically, in our\nfirst subtask, the participating systems are required to choose from two\nnatural language statements of similar wording the one that makes sense and the\none does not. The second subtask additionally asks a system to select the key\nreason from three options why a given statement does not make sense. In the\nthird subtask, a participating system needs to generate the reason. We finally\nattracted 39 teams participating at least one of the three subtasks. For\nSubtask A and Subtask B, the performances of top-ranked systems are close to\nthat of humans. However, for Subtask C, there is still a relatively large gap\nbetween systems and human performance. The dataset used in our task can be\nfound at https://github.com/wangcunxiang/SemEval2020-\nTask4-Commonsense-Validation-and-Explanation; The leaderboard can be found at\nhttps://competitions.codalab.org/competitions/21080#results.\n", "versions": [{"version": "v1", "created": "Wed, 1 Jul 2020 04:41:05 GMT"}, {"version": "v2", "created": "Mon, 3 Aug 2020 15:13:40 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Wang", "Cunxiang", ""], ["Liang", "Shuailong", ""], ["Jin", "Yili", ""], ["Wang", "Yilong", ""], ["Zhu", "Xiaodan", ""], ["Zhang", "Yue", ""]]}, {"id": "2007.00251", "submitter": "Vedant Nanda", "authors": "Vedant Nanda, Till Speicher, John P. Dickerson, Krishna P. Gummadi,\n  Muhammad Bilal Zafar", "title": "Unifying Model Explainability and Robustness via Machine-Checkable\n  Concepts", "comments": "22 pages, 12 figures, 11 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As deep neural networks (DNNs) get adopted in an ever-increasing number of\napplications, explainability has emerged as a crucial desideratum for these\nmodels. In many real-world tasks, one of the principal reasons for requiring\nexplainability is to in turn assess prediction robustness, where predictions\n(i.e., class labels) that do not conform to their respective explanations\n(e.g., presence or absence of a concept in the input) are deemed to be\nunreliable. However, most, if not all, prior methods for checking\nexplanation-conformity (e.g., LIME, TCAV, saliency maps) require significant\nmanual intervention, which hinders their large-scale deployability. In this\npaper, we propose a robustness-assessment framework, at the core of which is\nthe idea of using machine-checkable concepts. Our framework defines a large\nnumber of concepts that the DNN explanations could be based on and performs the\nexplanation-conformity check at test time to assess prediction robustness. Both\nsteps are executed in an automated manner without requiring any human\nintervention and are easily scaled to datasets with a very large number of\nclasses. Experiments on real-world datasets and human surveys show that our\nframework is able to enhance prediction robustness significantly: the\npredictions marked to be robust by our framework have significantly higher\naccuracy and are more robust to adversarial perturbations.\n", "versions": [{"version": "v1", "created": "Wed, 1 Jul 2020 05:21:16 GMT"}, {"version": "v2", "created": "Thu, 2 Jul 2020 07:33:15 GMT"}], "update_date": "2020-07-03", "authors_parsed": [["Nanda", "Vedant", ""], ["Speicher", "Till", ""], ["Dickerson", "John P.", ""], ["Gummadi", "Krishna P.", ""], ["Zafar", "Muhammad Bilal", ""]]}, {"id": "2007.00266", "submitter": "Ben Bogin", "authors": "Ben Bogin, Sanjay Subramanian, Matt Gardner, Jonathan Berant", "title": "Latent Compositional Representations Improve Systematic Generalization\n  in Grounded Question Answering", "comments": "Accepted for publication in Transactions of the Association for\n  Computational Linguistics (TACL), 2020. Author's final version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Answering questions that involve multi-step reasoning requires decomposing\nthem and using the answers of intermediate steps to reach the final answer.\nHowever, state-of-the-art models in grounded question answering often do not\nexplicitly perform decomposition, leading to difficulties in generalization to\nout-of-distribution examples. In this work, we propose a model that computes a\nrepresentation and denotation for all question spans in a bottom-up,\ncompositional manner using a CKY-style parser. Our model induces latent trees,\ndriven by end-to-end (the answer) supervision only. We show that this inductive\nbias towards tree structures dramatically improves systematic generalization to\nout-of-distribution examples, compared to strong baselines on an arithmetic\nexpressions benchmark as well as on CLOSURE, a dataset that focuses on\nsystematic generalization for grounded question answering. On this challenging\ndataset, our model reaches an accuracy of 96.1%, significantly higher than\nprior models that almost perfectly solve the task on a random, in-distribution\nsplit.\n", "versions": [{"version": "v1", "created": "Wed, 1 Jul 2020 06:22:51 GMT"}, {"version": "v2", "created": "Mon, 9 Nov 2020 14:35:21 GMT"}, {"version": "v3", "created": "Tue, 10 Nov 2020 06:22:21 GMT"}], "update_date": "2020-11-11", "authors_parsed": [["Bogin", "Ben", ""], ["Subramanian", "Sanjay", ""], ["Gardner", "Matt", ""], ["Berant", "Jonathan", ""]]}, {"id": "2007.00337", "submitter": "Kishor Datta Gupta", "authors": "Kishor Datta Gupta, Zahid Akhtar, Dipankar Dasgupta", "title": "Determining Sequence of Image Processing Technique (IPT) to Detect\n  Adversarial Attacks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Developing secure machine learning models from adversarial examples is\nchallenging as various methods are continually being developed to generate\nadversarial attacks. In this work, we propose an evolutionary approach to\nautomatically determine Image Processing Techniques Sequence (IPTS) for\ndetecting malicious inputs. Accordingly, we first used a diverse set of attack\nmethods including adaptive attack methods (on our defense) to generate\nadversarial samples from the clean dataset. A detection framework based on a\ngenetic algorithm (GA) is developed to find the optimal IPTS, where the\noptimality is estimated by different fitness measures such as Euclidean\ndistance, entropy loss, average histogram, local binary pattern and loss\nfunctions. The \"image difference\" between the original and processed images is\nused to extract the features, which are then fed to a classification scheme in\norder to determine whether the input sample is adversarial or clean. This paper\ndescribed our methodology and performed experiments using multiple data-sets\ntested with several adversarial attacks. For each attack-type and dataset, it\ngenerates unique IPTS. A set of IPTS selected dynamically in testing time which\nworks as a filter for the adversarial attack. Our empirical experiments\nexhibited promising results indicating the approach can efficiently be used as\nprocessing for any AI model.\n", "versions": [{"version": "v1", "created": "Wed, 1 Jul 2020 08:59:14 GMT"}, {"version": "v2", "created": "Tue, 7 Jul 2020 09:26:57 GMT"}], "update_date": "2021-07-21", "authors_parsed": [["Gupta", "Kishor Datta", ""], ["Akhtar", "Zahid", ""], ["Dasgupta", "Dipankar", ""]]}, {"id": "2007.00364", "submitter": "Evangelia Kyrimi", "authors": "Evangelia Kyrimi, Mariana Raniere Neves, Scott McLachlan, Martin Neil,\n  William Marsh, Norman Fenton", "title": "Medical idioms for clinical Bayesian network development", "comments": null, "journal-ref": null, "doi": "10.1016/j.jbi.2020.103495", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian Networks (BNs) are graphical probabilistic models that have proven\npopular in medical applications. While numerous medical BNs have been\npublished, most are presented fait accompli without explanation of how the\nnetwork structure was developed or justification of why it represents the\ncorrect structure for the given medical application. This means that the\nprocess of building medical BNs from experts is typically ad hoc and offers\nlittle opportunity for methodological improvement. This paper proposes\ngenerally applicable and reusable medical reasoning patterns to aid those\ndeveloping medical BNs. The proposed method complements and extends the\nidiom-based approach introduced by Neil, Fenton, and Nielsen in 2000. We\npropose instances of their generic idioms that are specific to medical BNs. We\nrefer to the proposed medical reasoning patterns as medical idioms. In\naddition, we extend the use of idioms to represent interventional and\ncounterfactual reasoning. We believe that the proposed medical idioms are\nlogical reasoning patterns that can be combined, reused and applied generically\nto help develop medical BNs. All proposed medical idioms have been illustrated\nusing medical examples on coronary artery disease. The method has also been\napplied to other ongoing BNs being developed with medical experts. Finally, we\nshow that applying the proposed medical idioms to published BN models results\nin models with a clearer structure.\n", "versions": [{"version": "v1", "created": "Wed, 1 Jul 2020 10:10:52 GMT"}, {"version": "v2", "created": "Thu, 2 Jul 2020 08:03:45 GMT"}], "update_date": "2020-07-03", "authors_parsed": [["Kyrimi", "Evangelia", ""], ["Neves", "Mariana Raniere", ""], ["McLachlan", "Scott", ""], ["Neil", "Martin", ""], ["Marsh", "William", ""], ["Fenton", "Norman", ""]]}, {"id": "2007.00391", "submitter": "Tuan Dam", "authors": "Tuan Dam, Carlo D'Eramo, Jan Peters, Joni Pajarinen", "title": "Convex Regularization in Monte-Carlo Tree Search", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Monte-Carlo planning and Reinforcement Learning (RL) are essential to\nsequential decision making. The recent AlphaGo and AlphaZero algorithms have\nshown how to successfully combine these two paradigms in order to solve large\nscale sequential decision problems. These methodologies exploit a variant of\nthe well-known UCT algorithm to trade off exploitation of good actions and\nexploration of unvisited states, but their empirical success comes at the cost\nof poor sample-efficiency and high computation time. In this paper, we overcome\nthese limitations by considering convex regularization in Monte-Carlo Tree\nSearch (MCTS), which has been successfully used in RL to efficiently drive\nexploration. First, we introduce a unifying theory on the use of generic convex\nregularizers in MCTS, deriving the regret analysis and providing guarantees of\nexponential convergence rate. Second, we exploit our theoretical framework to\nintroduce novel regularized backup operators for MCTS, based on the relative\nentropy of the policy update, and on the Tsallis entropy of the policy.\nFinally, we empirically evaluate the proposed operators in AlphaGo and\nAlphaZero on problems of increasing dimensionality and branching factor, from a\ntoy problem to several Atari games, showing their superiority w.r.t.\nrepresentative baselines.\n", "versions": [{"version": "v1", "created": "Wed, 1 Jul 2020 11:29:08 GMT"}, {"version": "v2", "created": "Fri, 5 Feb 2021 19:00:18 GMT"}, {"version": "v3", "created": "Tue, 16 Feb 2021 15:14:47 GMT"}], "update_date": "2021-02-17", "authors_parsed": [["Dam", "Tuan", ""], ["D'Eramo", "Carlo", ""], ["Peters", "Jan", ""], ["Pajarinen", "Joni", ""]]}, {"id": "2007.00463", "submitter": "Richa Verma", "authors": "Richa Verma, Aniruddha Singhal, Harshad Khadilkar, Ansuma Basumatary,\n  Siddharth Nayak, Harsh Vardhan Singh, Swagat Kumar, Rajesh Sinha", "title": "A Generalized Reinforcement Learning Algorithm for Online 3D Bin-Packing", "comments": "9 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a Deep Reinforcement Learning (Deep RL) algorithm for solving the\nonline 3D bin packing problem for an arbitrary number of bins and any bin size.\nThe focus is on producing decisions that can be physically implemented by a\nrobotic loading arm, a laboratory prototype used for testing the concept. The\nproblem considered in this paper is novel in two ways. First, unlike the\ntraditional 3D bin packing problem, we assume that the entire set of objects to\nbe packed is not known a priori. Instead, a fixed number of upcoming objects is\nvisible to the loading system, and they must be loaded in the order of arrival.\nSecond, the goal is not to move objects from one point to another via a\nfeasible path, but to find a location and orientation for each object that\nmaximises the overall packing efficiency of the bin(s). Finally, the learnt\nmodel is designed to work with problem instances of arbitrary size without\nretraining. Simulation results show that the RL-based method outperforms\nstate-of-the-art online bin packing heuristics in terms of empirical\ncompetitive ratio and volume efficiency.\n", "versions": [{"version": "v1", "created": "Wed, 1 Jul 2020 13:02:04 GMT"}], "update_date": "2020-07-02", "authors_parsed": [["Verma", "Richa", ""], ["Singhal", "Aniruddha", ""], ["Khadilkar", "Harshad", ""], ["Basumatary", "Ansuma", ""], ["Nayak", "Siddharth", ""], ["Singh", "Harsh Vardhan", ""], ["Kumar", "Swagat", ""], ["Sinha", "Rajesh", ""]]}, {"id": "2007.00487", "submitter": "Timoth\\'ee Lesort", "authors": "Timoth\\'ee Lesort", "title": "Continual Learning: Tackling Catastrophic Forgetting in Deep Neural\n  Networks with Replay Processes", "comments": "Doctoral Thesis Manuscript, Institut Polytechnique de Paris (2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Humans learn all their life long. They accumulate knowledge from a sequence\nof learning experiences and remember the essential concepts without forgetting\nwhat they have learned previously. Artificial neural networks struggle to learn\nsimilarly. They often rely on data rigorously preprocessed to learn solutions\nto specific problems such as classification or regression. In particular, they\nforget their past learning experiences if trained on new ones. Therefore,\nartificial neural networks are often inept to deal with real-life settings such\nas an autonomous-robot that has to learn on-line to adapt to new situations and\novercome new problems without forgetting its past learning-experiences.\nContinual learning (CL) is a branch of machine learning addressing this type of\nproblem. Continual algorithms are designed to accumulate and improve knowledge\nin a curriculum of learning-experiences without forgetting. In this thesis, we\npropose to explore continual algorithms with replay processes. Replay processes\ngather together rehearsal methods and generative replay methods. Generative\nReplay consists of regenerating past learning experiences with a generative\nmodel to remember them. Rehearsal consists of saving a core-set of samples from\npast learning experiences to rehearse them later. The replay processes make\npossible a compromise between optimizing the current learning objective and the\npast ones enabling learning without forgetting in sequences of tasks settings.\nWe show that they are very promising methods for continual learning. Notably,\nthey enable the re-evaluation of past data with new knowledge and the\nconfrontation of data from different learning-experiences. We demonstrate their\nability to learn continually through unsupervised learning, supervised learning\nand reinforcement learning tasks.\n", "versions": [{"version": "v1", "created": "Wed, 1 Jul 2020 13:44:33 GMT"}, {"version": "v2", "created": "Fri, 3 Jul 2020 13:07:32 GMT"}, {"version": "v3", "created": "Tue, 8 Dec 2020 17:08:29 GMT"}], "update_date": "2020-12-09", "authors_parsed": [["Lesort", "Timoth\u00e9e", ""]]}, {"id": "2007.00523", "submitter": "Jose Jimenez-Luna", "authors": "Jos\\'e Jim\\'enez-Luna, Francesca Grisoni, Gisbert Schneider", "title": "Drug discovery with explainable artificial intelligence", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Deep learning bears promise for drug discovery, including advanced image\nanalysis, prediction of molecular structure and function, and automated\ngeneration of innovative chemical entities with bespoke properties. Despite the\ngrowing number of successful prospective applications, the underlying\nmathematical models often remain elusive to interpretation by the human mind.\nThere is a demand for 'explainable' deep learning methods to address the need\nfor a new narrative of the machine language of the molecular sciences. This\nreview summarizes the most prominent algorithmic concepts of explainable\nartificial intelligence, and dares a forecast of the future opportunities,\npotential applications, and remaining challenges.\n", "versions": [{"version": "v1", "created": "Wed, 1 Jul 2020 14:36:23 GMT"}, {"version": "v2", "created": "Thu, 2 Jul 2020 09:47:01 GMT"}], "update_date": "2020-07-03", "authors_parsed": [["Jim\u00e9nez-Luna", "Jos\u00e9", ""], ["Grisoni", "Francesca", ""], ["Schneider", "Gisbert", ""]]}, {"id": "2007.00571", "submitter": "Erman Acar", "authors": "Erman Acar and Rafael Pe\\~naloza", "title": "Reasoning with Contextual Knowledge and Influence Diagrams", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Influence diagrams (IDs) are well-known formalisms extending Bayesian\nnetworks to model decision situations under uncertainty. Although they are\nconvenient as a decision theoretic tool, their knowledge representation ability\nis limited in capturing other crucial notions such as logical consistency. We\ncomplement IDs with the light-weight description logic (DL) EL to overcome such\nlimitations. We consider a setup where DL axioms hold in some contexts, yet the\nactual context is uncertain. The framework benefits from the convenience of\nusing DL as a domain knowledge representation language and the modelling\nstrength of IDs to deal with decisions over contexts in the presence of\ncontextual uncertainty. We define related reasoning problems and study their\ncomputational complexity.\n", "versions": [{"version": "v1", "created": "Wed, 1 Jul 2020 15:57:48 GMT"}], "update_date": "2020-07-02", "authors_parsed": [["Acar", "Erman", ""], ["Pe\u00f1aloza", "Rafael", ""]]}, {"id": "2007.00576", "submitter": "Qingyun Wang", "authors": "Qingyun Wang, Manling Li, Xuan Wang, Nikolaus Parulian, Guangxing Han,\n  Jiawei Ma, Jingxuan Tu, Ying Lin, Haoran Zhang, Weili Liu, Aabhas Chauhan,\n  Yingjun Guan, Bangzheng Li, Ruisong Li, Xiangchen Song, Yi R. Fung, Heng Ji,\n  Jiawei Han, Shih-Fu Chang, James Pustejovsky, Jasmine Rah, David Liem, Ahmed\n  Elsayed, Martha Palmer, Clare Voss, Cynthia Schneider, Boyan Onyshkevych", "title": "COVID-19 Literature Knowledge Graph Construction and Drug Repurposing\n  Report Generation", "comments": "12 pages, Accepted by Proceedings of 2021 Annual Conference of the\n  North American Chapter of the Association for Computational Linguistics\n  System Demonstrations, for resources see\n  http://blender.cs.illinois.edu/covid19/, for video see\n  http://159.89.180.81/demo/covid/Covid-KG_DemoVideo.mp4, for slides see\n  https://eaglew.github.io/files/Covid-KG_DemoVideo_with_ethics.pdf", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To combat COVID-19, both clinicians and scientists need to digest vast\namounts of relevant biomedical knowledge in scientific literature to understand\nthe disease mechanism and related biological functions. We have developed a\nnovel and comprehensive knowledge discovery framework, COVID-KG to extract\nfine-grained multimedia knowledge elements (entities and their visual chemical\nstructures, relations, and events) from scientific literature. We then exploit\nthe constructed multimedia knowledge graphs (KGs) for question answering and\nreport generation, using drug repurposing as a case study. Our framework also\nprovides detailed contextual sentences, subfigures, and knowledge subgraphs as\nevidence.\n", "versions": [{"version": "v1", "created": "Wed, 1 Jul 2020 16:03:20 GMT"}, {"version": "v2", "created": "Mon, 6 Jul 2020 22:50:14 GMT"}, {"version": "v3", "created": "Mon, 20 Jul 2020 23:53:39 GMT"}, {"version": "v4", "created": "Thu, 18 Mar 2021 20:38:41 GMT"}, {"version": "v5", "created": "Thu, 22 Apr 2021 02:47:58 GMT"}, {"version": "v6", "created": "Wed, 12 May 2021 03:30:44 GMT"}], "update_date": "2021-05-13", "authors_parsed": [["Wang", "Qingyun", ""], ["Li", "Manling", ""], ["Wang", "Xuan", ""], ["Parulian", "Nikolaus", ""], ["Han", "Guangxing", ""], ["Ma", "Jiawei", ""], ["Tu", "Jingxuan", ""], ["Lin", "Ying", ""], ["Zhang", "Haoran", ""], ["Liu", "Weili", ""], ["Chauhan", "Aabhas", ""], ["Guan", "Yingjun", ""], ["Li", "Bangzheng", ""], ["Li", "Ruisong", ""], ["Song", "Xiangchen", ""], ["Fung", "Yi R.", ""], ["Ji", "Heng", ""], ["Han", "Jiawei", ""], ["Chang", "Shih-Fu", ""], ["Pustejovsky", "James", ""], ["Rah", "Jasmine", ""], ["Liem", "David", ""], ["Elsayed", "Ahmed", ""], ["Palmer", "Martha", ""], ["Voss", "Clare", ""], ["Schneider", "Cynthia", ""], ["Onyshkevych", "Boyan", ""]]}, {"id": "2007.00611", "submitter": "Sina Ghiassian", "authors": "Sina Ghiassian, Andrew Patterson, Shivam Garg, Dhawal Gupta, Adam\n  White, Martha White", "title": "Gradient Temporal-Difference Learning with Regularized Corrections", "comments": "Appeared in Proceedings of the 37th International Conference on\n  Machine Learning (ICML2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is still common to use Q-learning and temporal difference (TD)\nlearning-even though they have divergence issues and sound Gradient TD\nalternatives exist-because divergence seems rare and they typically perform\nwell. However, recent work with large neural network learning systems reveals\nthat instability is more common than previously thought. Practitioners face a\ndifficult dilemma: choose an easy to use and performant TD method, or a more\ncomplex algorithm that is more sound but harder to tune and all but unexplored\nwith non-linear function approximation or control. In this paper, we introduce\na new method called TD with Regularized Corrections (TDRC), that attempts to\nbalance ease of use, soundness, and performance. It behaves as well as TD, when\nTD performs well, but is sound in cases where TD diverges. We empirically\ninvestigate TDRC across a range of problems, for both prediction and control,\nand for both linear and non-linear function approximation, and show,\npotentially for the first time, that gradient TD methods could be a better\nalternative to TD and Q-learning.\n", "versions": [{"version": "v1", "created": "Wed, 1 Jul 2020 16:56:56 GMT"}, {"version": "v2", "created": "Sun, 5 Jul 2020 17:53:35 GMT"}, {"version": "v3", "created": "Tue, 7 Jul 2020 16:59:45 GMT"}, {"version": "v4", "created": "Thu, 17 Sep 2020 21:17:00 GMT"}], "update_date": "2020-09-21", "authors_parsed": [["Ghiassian", "Sina", ""], ["Patterson", "Andrew", ""], ["Garg", "Shivam", ""], ["Gupta", "Dhawal", ""], ["White", "Adam", ""], ["White", "Martha", ""]]}, {"id": "2007.00708", "submitter": "Linnan Wang", "authors": "Linnan Wang, Rodrigo Fonseca, Yuandong Tian", "title": "Learning Search Space Partition for Black-box Optimization using Monte\n  Carlo Tree Search", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  High dimensional black-box optimization has broad applications but remains a\nchallenging problem to solve. Given a set of samples $\\{\\vx_i, y_i\\}$, building\na global model (like Bayesian Optimization (BO)) suffers from the curse of\ndimensionality in the high-dimensional search space, while a greedy search may\nlead to sub-optimality. By recursively splitting the search space into regions\nwith high/low function values, recent works like LaNAS shows good performance\nin Neural Architecture Search (NAS), reducing the sample complexity\nempirically. In this paper, we coin LA-MCTS that extends LaNAS to other\ndomains. Unlike previous approaches, LA-MCTS learns the partition of the search\nspace using a few samples and their function values in an online fashion. While\nLaNAS uses linear partition and performs uniform sampling in each region, our\nLA-MCTS adopts a nonlinear decision boundary and learns a local model to pick\ngood candidates. If the nonlinear partition function and the local model fits\nwell with ground-truth black-box function, then good partitions and candidates\ncan be reached with much fewer samples. LA-MCTS serves as a\n\\emph{meta-algorithm} by using existing black-box optimizers (e.g., BO, TuRBO)\nas its local models, achieving strong performance in general black-box\noptimization and reinforcement learning benchmarks, in particular for\nhigh-dimensional problems.\n", "versions": [{"version": "v1", "created": "Wed, 1 Jul 2020 19:17:47 GMT"}], "update_date": "2020-07-03", "authors_parsed": [["Wang", "Linnan", ""], ["Fonseca", "Rodrigo", ""], ["Tian", "Yuandong", ""]]}, {"id": "2007.00714", "submitter": "Dominik Janzing", "authors": "Dominik Janzing, Patrick Bl\\\"obaum, Lenon Minorics, Philipp Faller", "title": "Quantifying causal contributions via structure preserving interventions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a concept to quantify the 'intrinsic' causal contribution of\neach variable in a causal directed acyclic graph to the uncertainty or\ninformation of some target variable. By recursively writing each node as\nfunction of the noise terms, we separate the information added by each node\nfrom the one obtained from its ancestors. To interpret this information as a\ncausal contribution, we consider 'structure-preserving interventions' that\nrandomize each node in a way that mimics the usual dependence on the parents\nand don't perturb the observed joint distribution. Using Shapley values, the\ncontribution becomes independent of the ordering of nodes. We describe our\ncontribution analysis for variance and entropy as two important examples, but\ncontributions for other target metrics can be defined analogously.\n", "versions": [{"version": "v1", "created": "Wed, 1 Jul 2020 19:34:08 GMT"}, {"version": "v2", "created": "Thu, 4 Mar 2021 15:42:40 GMT"}], "update_date": "2021-03-05", "authors_parsed": [["Janzing", "Dominik", ""], ["Bl\u00f6baum", "Patrick", ""], ["Minorics", "Lenon", ""], ["Faller", "Philipp", ""]]}, {"id": "2007.00720", "submitter": "Avishek Bose", "authors": "Avishek Joey Bose, Gauthier Gidel, Hugo Berard, Andre Cianflone,\n  Pascal Vincent, Simon Lacoste-Julien and William L. Hamilton", "title": "Adversarial Example Games", "comments": "Appears in: Advances in Neural Information Processing Systems 33\n  (NeurIPS 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The existence of adversarial examples capable of fooling trained neural\nnetwork classifiers calls for a much better understanding of possible attacks\nto guide the development of safeguards against them. This includes attack\nmethods in the challenging non-interactive blackbox setting, where adversarial\nattacks are generated without any access, including queries, to the target\nmodel. Prior attacks in this setting have relied mainly on algorithmic\ninnovations derived from empirical observations (e.g., that momentum helps),\nlacking principled transferability guarantees. In this work, we provide a\ntheoretical foundation for crafting transferable adversarial examples to entire\nhypothesis classes. We introduce Adversarial Example Games (AEG), a framework\nthat models the crafting of adversarial examples as a min-max game between a\ngenerator of attacks and a classifier. AEG provides a new way to design\nadversarial examples by adversarially training a generator and a classifier\nfrom a given hypothesis class (e.g., architecture). We prove that this game has\nan equilibrium, and that the optimal generator is able to craft adversarial\nexamples that can attack any classifier from the corresponding hypothesis\nclass. We demonstrate the efficacy of AEG on the MNIST and CIFAR-10 datasets,\noutperforming prior state-of-the-art approaches with an average relative\nimprovement of $29.9\\%$ and $47.2\\%$ against undefended and robust models\n(Table 2 & 3) respectively.\n", "versions": [{"version": "v1", "created": "Wed, 1 Jul 2020 19:47:23 GMT"}, {"version": "v2", "created": "Wed, 21 Oct 2020 05:56:03 GMT"}, {"version": "v3", "created": "Thu, 22 Oct 2020 02:47:01 GMT"}, {"version": "v4", "created": "Sat, 24 Oct 2020 02:15:06 GMT"}, {"version": "v5", "created": "Fri, 20 Nov 2020 05:07:25 GMT"}, {"version": "v6", "created": "Sat, 9 Jan 2021 01:44:02 GMT"}], "update_date": "2021-01-12", "authors_parsed": [["Bose", "Avishek Joey", ""], ["Gidel", "Gauthier", ""], ["Berard", "Hugo", ""], ["Cianflone", "Andre", ""], ["Vincent", "Pascal", ""], ["Lacoste-Julien", "Simon", ""], ["Hamilton", "William L.", ""]]}, {"id": "2007.00730", "submitter": "Songyang Zhang", "authors": "Songyang Zhang, Han Zhang, Shuguang Cui, Zhi Ding", "title": "From Spectrum Wavelet to Vertex Propagation: Graph Convolutional\n  Networks Based on Taylor Approximation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph convolutional networks (GCN) have been recently utilized to extract the\nunderlying structures of datasets with some labeled data and high-dimensional\nfeatures. Existing GCNs mostly rely on a first-order Chebyshev approximation of\ngraph wavelet-kernels. Such a generic propagation model does not always suit\nthe various datasets and their features. This work revisits the fundamentals of\ngraph wavelet and explores the utility of signal propagation in the vertex\ndomain to approximate the spectral wavelet-kernels. We first derive the\nconditions for representing the graph wavelet-kernels via vertex propagation.\nWe next propose alternative propagation models for GCN layers based on Taylor\nexpansions. We further analyze the choices of detailed graph representations\nfor TGCNs. Experiments on citation networks, multimedia datasets and synthetic\ngraphs demonstrate the advantage of Taylor-based GCN (TGCN) in the node\nclassification problems over the traditional GCN methods.\n", "versions": [{"version": "v1", "created": "Wed, 1 Jul 2020 20:07:13 GMT"}, {"version": "v2", "created": "Sun, 29 Nov 2020 04:29:18 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Zhang", "Songyang", ""], ["Zhang", "Han", ""], ["Cui", "Shuguang", ""], ["Ding", "Zhi", ""]]}, {"id": "2007.00747", "submitter": "Yusuf Sermet", "authors": "Yusuf Sermet and Ibrahim Demir", "title": "A Semantic Web Framework for Automated Smart Assistants: COVID-19 Case\n  Study", "comments": "19 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.HC cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  COVID-19 pandemic elucidated that knowledge systems will be instrumental in\ncases where accurate information needs to be communicated to a substantial\ngroup of people with different backgrounds and technological resources.\nHowever, several challenges and obstacles hold back the wide adoption of\nvirtual assistants by public health departments and organizations. This paper\npresents the Instant Expert, an open-source semantic web framework to build and\nintegrate voice-enabled smart assistants (i.e. chatbots) for any web platform\nregardless of the underlying domain and technology. The component allows\nnon-technical domain experts to effortlessly incorporate an operational\nassistant with voice recognition capability into their websites. Instant Expert\nis capable of automatically parsing, processing, and modeling Frequently Asked\nQuestions pages as an information resource as well as communicating with an\nexternal knowledge engine for ontology-powered inference and dynamic data\nutilization. The presented framework utilizes advanced web technologies to\nensure reusability and reliability, and an inference engine for natural\nlanguage understanding powered by deep learning and heuristic algorithms. A use\ncase for creating an informatory assistant for COVID-19 based on the Centers\nfor Disease Control and Prevention (CDC) data is presented to demonstrate the\nframework's usage and benefits.\n", "versions": [{"version": "v1", "created": "Wed, 1 Jul 2020 20:47:44 GMT"}, {"version": "v2", "created": "Thu, 17 Sep 2020 17:28:08 GMT"}], "update_date": "2020-09-18", "authors_parsed": [["Sermet", "Yusuf", ""], ["Demir", "Ibrahim", ""]]}, {"id": "2007.00753", "submitter": "Samuel Henrique Silva", "authors": "Samuel Henrique Silva and Peyman Najafirad", "title": "Opportunities and Challenges in Deep Learning Adversarial Robustness: A\n  Survey", "comments": "20 pages, 9 figures, submited to IEEE Transactions on Knowledge and\n  Data Engineering", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As we seek to deploy machine learning models beyond virtual and controlled\ndomains, it is critical to analyze not only the accuracy or the fact that it\nworks most of the time, but if such a model is truly robust and reliable. This\npaper studies strategies to implement adversary robustly trained algorithms\ntowards guaranteeing safety in machine learning algorithms. We provide a\ntaxonomy to classify adversarial attacks and defenses, formulate the Robust\nOptimization problem in a min-max setting and divide it into 3 subcategories,\nnamely: Adversarial (re)Training, Regularization Approach, and Certified\nDefenses. We survey the most recent and important results in adversarial\nexample generation, defense mechanisms with adversarial (re)Training as their\nmain defense against perturbations. We also survey mothods that add\nregularization terms that change the behavior of the gradient, making it harder\nfor attackers to achieve their objective. Alternatively, we've surveyed methods\nwhich formally derive certificates of robustness by exactly solving the\noptimization problem or by approximations using upper or lower bounds. In\naddition, we discuss the challenges faced by most of the recent algorithms\npresenting future research perspectives.\n", "versions": [{"version": "v1", "created": "Wed, 1 Jul 2020 21:00:32 GMT"}, {"version": "v2", "created": "Fri, 3 Jul 2020 20:10:20 GMT"}], "update_date": "2020-07-07", "authors_parsed": [["Silva", "Samuel Henrique", ""], ["Najafirad", "Peyman", ""]]}, {"id": "2007.00757", "submitter": "Renate Schmidt", "authors": "Patrick Koopmann, Warren Del-Pinto, Sophie Tourret and Renate A.\n  Schmidt", "title": "Signature-Based Abduction for Expressive Description Logics -- Technical\n  Report", "comments": "13 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Signature-based abduction aims at building hypotheses over a specified set of\nnames, the signature, that explain an observation relative to some background\nknowledge. This type of abduction is useful for tasks such as diagnosis, where\nthe vocabulary used for observed symptoms differs from the vocabulary expected\nto explain those symptoms. We present the first complete method solving\nsignature-based abduction for observations expressed in the expressive\ndescription logic ALC, which can include TBox and ABox axioms, thereby solving\nthe knowledge base abduction problem. The method is guaranteed to compute a\nfinite and complete set of hypotheses, and is evaluated on a set of realistic\nknowledge bases.\n", "versions": [{"version": "v1", "created": "Wed, 1 Jul 2020 21:06:24 GMT"}, {"version": "v2", "created": "Wed, 8 Jul 2020 12:32:36 GMT"}], "update_date": "2020-07-09", "authors_parsed": [["Koopmann", "Patrick", ""], ["Del-Pinto", "Warren", ""], ["Tourret", "Sophie", ""], ["Schmidt", "Renate A.", ""]]}, {"id": "2007.00777", "submitter": "Yu Zhang", "authors": "Zakk Giacometti and Yu Zhang", "title": "Allocation of Multi-Robot Tasks with Task Variants", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Task allocation has been a well studied problem. In most prior problem\nformulations, it is assumed that each task is associated with a unique set of\nresource requirements. In the scope of multi-robot task allocation problem,\nthese requirements can be satisfied by a coalition of robots. In this paper, we\nintroduce a more general formulation of multi-robot task allocation problem\nthat allows more than one option for specifying the set of task\nrequirements--satisfying any one of the options will satisfy the task. We\nreferred to this new problem as the multi-robot task allocation problem with\ntask variants. First, we theoretically show that this extension fortunately\ndoes not impact the complexity class, which is still NP-complete. For solution\nmethods, we adapt two previous greedy methods for the task allocation problem\nwithout task variants to solve this new problem and analyze their\neffectiveness. In particular, we \"flatten\" the new problem to the problem\nwithout task variants, modify the previous methods to solve the flattened\nproblem, and prove that the bounds still hold. Finally, we thoroughly evaluate\nthese two methods along with a random baseline to demonstrate their efficacy\nfor the new problem.\n", "versions": [{"version": "v1", "created": "Wed, 1 Jul 2020 21:45:06 GMT"}], "update_date": "2020-07-03", "authors_parsed": [["Giacometti", "Zakk", ""], ["Zhang", "Yu", ""]]}, {"id": "2007.00795", "submitter": "Ching-An Cheng", "authors": "Ching-An Cheng, Andrey Kolobov, Alekh Agarwal", "title": "Policy Improvement via Imitation of Multiple Oracles", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite its promise, reinforcement learning's real-world adoption has been\nhampered by the need for costly exploration to learn a good policy. Imitation\nlearning (IL) mitigates this shortcoming by using an oracle policy during\ntraining as a bootstrap to accelerate the learning process. However, in many\npractical situations, the learner has access to multiple suboptimal oracles,\nwhich may provide conflicting advice in a state. The existing IL literature\nprovides a limited treatment of such scenarios. Whereas in the single-oracle\ncase, the return of the oracle's policy provides an obvious benchmark for the\nlearner to compete against, neither such a benchmark nor principled ways of\noutperforming it are known for the multi-oracle setting. In this paper, we\npropose the state-wise maximum of the oracle policies' values as a natural\nbaseline to resolve conflicting advice from multiple oracles. Using a reduction\nof policy optimization to online learning, we introduce a novel IL algorithm\nMAMBA, which can provably learn a policy competitive with this benchmark. In\nparticular, MAMBA optimizes policies by using a gradient estimator in the style\nof generalized advantage estimation (GAE). Our theoretical analysis shows that\nthis design makes MAMBA robust and enables it to outperform the oracle policies\nby a larger margin than the IL state of the art, even in the single-oracle\ncase. In an evaluation against standard policy gradient with GAE and\nAggreVaTe(D), we showcase MAMBA's ability to leverage demonstrations both from\na single and from multiple weak oracles, and significantly speed up policy\noptimization.\n", "versions": [{"version": "v1", "created": "Wed, 1 Jul 2020 22:33:28 GMT"}, {"version": "v2", "created": "Sun, 6 Dec 2020 04:02:56 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Cheng", "Ching-An", ""], ["Kolobov", "Andrey", ""], ["Agarwal", "Alekh", ""]]}, {"id": "2007.00820", "submitter": "Anagha Kulkarni", "authors": "Anagha Kulkarni, Sarath Sreedharan, Sarah Keren, Tathagata\n  Chakraborti, David Smith and Subbarao Kambhampati", "title": "Designing Environments Conducive to Interpretable Robot Behavior", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Designing robots capable of generating interpretable behavior is a\nprerequisite for achieving effective human-robot collaboration. This means that\nthe robots need to be capable of generating behavior that aligns with human\nexpectations and, when required, provide explanations to the humans in the\nloop. However, exhibiting such behavior in arbitrary environments could be\nquite expensive for robots, and in some cases, the robot may not even be able\nto exhibit the expected behavior. Given structured environments (like\nwarehouses and restaurants), it may be possible to design the environment so as\nto boost the interpretability of the robot's behavior or to shape the human's\nexpectations of the robot's behavior. In this paper, we investigate the\nopportunities and limitations of environment design as a tool to promote a type\nof interpretable behavior -- known in the literature as explicable behavior. We\nformulate a novel environment design framework that considers design over\nmultiple tasks and over a time horizon. In addition, we explore the\nlongitudinal aspect of explicable behavior and the trade-off that arises\nbetween the cost of design and the cost of generating explicable behavior over\na time horizon.\n", "versions": [{"version": "v1", "created": "Thu, 2 Jul 2020 00:50:10 GMT"}, {"version": "v2", "created": "Sun, 2 Aug 2020 16:34:05 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Kulkarni", "Anagha", ""], ["Sreedharan", "Sarath", ""], ["Keren", "Sarah", ""], ["Chakraborti", "Tathagata", ""], ["Smith", "David", ""], ["Kambhampati", "Subbarao", ""]]}, {"id": "2007.00849", "submitter": "Haitian Sun", "authors": "Pat Verga, Haitian Sun, Livio Baldini Soares, William W. Cohen", "title": "Facts as Experts: Adaptable and Interpretable Neural Memory over\n  Symbolic Knowledge", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Massive language models are the core of modern NLP modeling and have been\nshown to encode impressive amounts of commonsense and factual information.\nHowever, that knowledge exists only within the latent parameters of the model,\ninaccessible to inspection and interpretation, and even worse, factual\ninformation memorized from the training corpora is likely to become stale as\nthe world changes. Knowledge stored as parameters will also inevitably exhibit\nall of the biases inherent in the source materials. To address these problems,\nwe develop a neural language model that includes an explicit interface between\nsymbolically interpretable factual information and subsymbolic neural\nknowledge. We show that this model dramatically improves performance on two\nknowledge-intensive question-answering tasks. More interestingly, the model can\nbe updated without re-training by manipulating its symbolic representations. In\nparticular this model allows us to add new facts and overwrite existing ones in\nways that are not possible for earlier models.\n", "versions": [{"version": "v1", "created": "Thu, 2 Jul 2020 03:05:41 GMT"}], "update_date": "2020-07-03", "authors_parsed": [["Verga", "Pat", ""], ["Sun", "Haitian", ""], ["Soares", "Livio Baldini", ""], ["Cohen", "William W.", ""]]}, {"id": "2007.00875", "submitter": "Nikka Mofid", "authors": "Chetanya Rastogi, Nikka Mofid, Fang-I Hsiao", "title": "Can We Achieve More with Less? Exploring Data Augmentation for Toxic\n  Comment Classification", "comments": "11 pages, 15 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper tackles one of the greatest limitations in Machine Learning: Data\nScarcity. Specifically, we explore whether high accuracy classifiers can be\nbuilt from small datasets, utilizing a combination of data augmentation\ntechniques and machine learning algorithms. In this paper, we experiment with\nEasy Data Augmentation (EDA) and Backtranslation, as well as with three popular\nlearning algorithms, Logistic Regression, Support Vector Machine (SVM), and\nBidirectional Long Short-Term Memory Network (Bi-LSTM). For our\nexperimentation, we utilize the Wikipedia Toxic Comments dataset so that in the\nprocess of exploring the benefits of data augmentation, we can develop a model\nto detect and classify toxic speech in comments to help fight back against\ncyberbullying and online harassment. Ultimately, we found that data\naugmentation techniques can be used to significantly boost the performance of\nclassifiers and are an excellent strategy to combat lack of data in NLP\nproblems.\n", "versions": [{"version": "v1", "created": "Thu, 2 Jul 2020 04:43:31 GMT"}], "update_date": "2020-07-03", "authors_parsed": [["Rastogi", "Chetanya", ""], ["Mofid", "Nikka", ""], ["Hsiao", "Fang-I", ""]]}, {"id": "2007.00900", "submitter": "Kamran Alipour", "authors": "Kamran Alipour, Arijit Ray, Xiao Lin, Jurgen P. Schulze, Yi Yao,\n  Giedrius T. Burachas", "title": "The Impact of Explanations on AI Competency Prediction in VQA", "comments": "Submitted to HCCAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Explainability is one of the key elements for building trust in AI systems.\nAmong numerous attempts to make AI explainable, quantifying the effect of\nexplanations remains a challenge in conducting human-AI collaborative tasks.\nAside from the ability to predict the overall behavior of AI, in many\napplications, users need to understand an AI agent's competency in different\naspects of the task domain. In this paper, we evaluate the impact of\nexplanations on the user's mental model of AI agent competency within the task\nof visual question answering (VQA). We quantify users' understanding of\ncompetency, based on the correlation between the actual system performance and\nuser rankings. We introduce an explainable VQA system that uses spatial and\nobject features and is powered by the BERT language model. Each group of users\nsees only one kind of explanation to rank the competencies of the VQA model.\nThe proposed model is evaluated through between-subject experiments to probe\nexplanations' impact on the user's perception of competency. The comparison\nbetween two VQA models shows BERT based explanations and the use of object\nfeatures improve the user's prediction of the model's competencies.\n", "versions": [{"version": "v1", "created": "Thu, 2 Jul 2020 06:11:28 GMT"}], "update_date": "2020-07-03", "authors_parsed": [["Alipour", "Kamran", ""], ["Ray", "Arijit", ""], ["Lin", "Xiao", ""], ["Schulze", "Jurgen P.", ""], ["Yao", "Yi", ""], ["Burachas", "Giedrius T.", ""]]}, {"id": "2007.00914", "submitter": "Eugenio Mart\\'inez-C\\'amara", "authors": "Nuria Rodr\\'iguez-Barroso, Goran Stipcich, Daniel Jim\\'enez-L\\'opez,\n  Jos\\'e Antonio Ruiz-Mill\\'an, Eugenio Mart\\'inez-C\\'amara, Gerardo\n  Gonz\\'alez-Seco, M. Victoria Luz\\'on, Miguel \\'Angel Veganzones, Francisco\n  Herrera", "title": "Federated Learning and Differential Privacy: Software tools analysis,\n  the Sherpa.ai FL framework and methodological guidelines for preserving data\n  privacy", "comments": "46 pages, 5 figures", "journal-ref": "Information Fusion 64 (2020) 270-292", "doi": "10.1016/j.inffus.2020.07.009", "report-no": null, "categories": "cs.LG cs.AI cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The high demand of artificial intelligence services at the edges that also\npreserve data privacy has pushed the research on novel machine learning\nparadigms that fit those requirements. Federated learning has the ambition to\nprotect data privacy through distributed learning methods that keep the data in\ntheir data silos. Likewise, differential privacy attains to improve the\nprotection of data privacy by measuring the privacy loss in the communication\namong the elements of federated learning. The prospective matching of federated\nlearning and differential privacy to the challenges of data privacy protection\nhas caused the release of several software tools that support their\nfunctionalities, but they lack of the needed unified vision for those\ntechniques, and a methodological workflow that support their use. Hence, we\npresent the Sherpa.ai Federated Learning framework that is built upon an\nholistic view of federated learning and differential privacy. It results from\nthe study of how to adapt the machine learning paradigm to federated learning,\nand the definition of methodological guidelines for developing artificial\nintelligence services based on federated learning and differential privacy. We\nshow how to follow the methodological guidelines with the Sherpa.ai Federated\nLearning framework by means of a classification and a regression use cases.\n", "versions": [{"version": "v1", "created": "Thu, 2 Jul 2020 06:47:35 GMT"}, {"version": "v2", "created": "Tue, 6 Oct 2020 07:39:39 GMT"}], "update_date": "2020-10-07", "authors_parsed": [["Rodr\u00edguez-Barroso", "Nuria", ""], ["Stipcich", "Goran", ""], ["Jim\u00e9nez-L\u00f3pez", "Daniel", ""], ["Ruiz-Mill\u00e1n", "Jos\u00e9 Antonio", ""], ["Mart\u00ednez-C\u00e1mara", "Eugenio", ""], ["Gonz\u00e1lez-Seco", "Gerardo", ""], ["Luz\u00f3n", "M. Victoria", ""], ["Veganzones", "Miguel \u00c1ngel", ""], ["Herrera", "Francisco", ""]]}, {"id": "2007.00977", "submitter": "Dorien Herremans", "authors": "Kanish Garg, Ajeet kumar Singh, Dorien Herremans, Brejesh Lall", "title": "PerceptionGAN: Real-world Image Construction from Provided Text through\n  Perceptual Understanding", "comments": "Proceedings of IEEE International Conference on Imaging, Vision &\n  Pattern Recognition, (IVPR 2020, Japan)", "journal-ref": "Proceedings of IEEE International Conference on Imaging, Vision &\n  Pattern Recognition, (IVPR 2020, Japan)", "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.GR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generating an image from a provided descriptive text is quite a challenging\ntask because of the difficulty in incorporating perceptual information (object\nshapes, colors, and their interactions) along with providing high relevancy\nrelated to the provided text. Current methods first generate an initial\nlow-resolution image, which typically has irregular object shapes, colors, and\ninteraction between objects. This initial image is then improved by\nconditioning on the text. However, these methods mainly address the problem of\nusing text representation efficiently in the refinement of the initially\ngenerated image, while the success of this refinement process depends heavily\non the quality of the initially generated image, as pointed out in the DM-GAN\npaper. Hence, we propose a method to provide good initialized images by\nincorporating perceptual understanding in the discriminator module. We improve\nthe perceptual information at the first stage itself, which results in\nsignificant improvement in the final generated image. In this paper, we have\napplied our approach to the novel StackGAN architecture. We then show that the\nperceptual information included in the initial image is improved while modeling\nimage distribution at multiple stages. Finally, we generated realistic\nmulti-colored images conditioned by text. These images have good quality along\nwith containing improved basic perceptual information. More importantly, the\nproposed method can be integrated into the pipeline of other state-of-the-art\ntext-based-image-generation models to generate initial low-resolution images.\nWe also worked on improving the refinement process in StackGAN by augmenting\nthe third stage of the generator-discriminator pair in the StackGAN\narchitecture. Our experimental analysis and comparison with the\nstate-of-the-art on a large but sparse dataset MS COCO further validate the\nusefulness of our proposed approach.\n", "versions": [{"version": "v1", "created": "Thu, 2 Jul 2020 09:23:08 GMT"}], "update_date": "2020-07-03", "authors_parsed": [["Garg", "Kanish", ""], ["Singh", "Ajeet kumar", ""], ["Herremans", "Dorien", ""], ["Lall", "Brejesh", ""]]}, {"id": "2007.01009", "submitter": "Ali Ghadirzadeh", "authors": "Ali Ghadirzadeh, Xi Chen, Wenjie Yin, Zhengrong Yi, M{\\aa}rten\n  Bj\\\"orkman and Danica Kragic", "title": "Human-centered collaborative robots with deep reinforcement learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a reinforcement learning based framework for human-centered\ncollaborative systems. The framework is proactive and balances the benefits of\ntimely actions with the risk of taking improper actions by minimizing the total\ntime spent to complete the task. The framework is learned end-to-end in an\nunsupervised fashion addressing the perception uncertainties and decision\nmaking in an integrated manner. The framework is shown to provide more fluent\ncoordination between human and robot partners on an example task of packaging\ncompared to alternatives for which perception and decision-making systems are\nlearned independently, using supervised learning. The foremost benefit of the\nproposed approach is that it allows for fast adaptation to new human partners\nand tasks since tedious annotation of motion data is avoided and the learning\nis performed on-line.\n", "versions": [{"version": "v1", "created": "Thu, 2 Jul 2020 10:45:34 GMT"}], "update_date": "2020-07-03", "authors_parsed": [["Ghadirzadeh", "Ali", ""], ["Chen", "Xi", ""], ["Yin", "Wenjie", ""], ["Yi", "Zhengrong", ""], ["Bj\u00f6rkman", "M\u00e5rten", ""], ["Kragic", "Danica", ""]]}, {"id": "2007.01019", "submitter": "Christoph Benzm\\\"uller", "authors": "David Fuenmayor and Christoph Benzm\\\"uller", "title": "Higher-order Logic as Lingua Franca -- Integrating Argumentative\n  Discourse and Deep Logical Analysis", "comments": "35 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an approach towards the deep, pluralistic logical analysis of\nargumentative discourse that benefits from the application of state-of-the-art\nautomated reasoning technology for classical higher-order logic. Thanks to its\nexpressivity this logic can adopt the status of a uniform \\textit{lingua\nfranca} allowing the encoding of both formalized arguments (their deep logical\nstructure) and dialectical interactions (their attack and support relations).\nWe illustrate this by analyzing an excerpt from an argumentative debate on\nclimate engineering.\n  Another, novel contribution concerns the definition of abstract,\nlanguage-theoretical foundations for the characterization and assessment of\nshallow semantical embeddings (SSEs) of non-classical logics in classical\nhigher-order logic, which constitute a pillar stone of our approach.\n  The novel perspective we draw enables more concise and more elegant\ncharacterizations of semantical embeddings of logics and logic combinations,\nwhich is demonstrated with several examples.\n", "versions": [{"version": "v1", "created": "Thu, 2 Jul 2020 11:07:53 GMT"}], "update_date": "2020-07-03", "authors_parsed": [["Fuenmayor", "David", ""], ["Benzm\u00fcller", "Christoph", ""]]}, {"id": "2007.01097", "submitter": "Daniel Reiss Harris", "authors": "Daniel Reiss Harris", "title": "PrototypeML: A Neural Network Integrated Design and Development\n  Environment", "comments": "10 pages, 6 figures. Submitted to NeurIPS 2020. More details\n  available at https://PrototypeML.com", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.SE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural network architectures are most often conceptually designed and\ndescribed in visual terms, but are implemented by writing error-prone code.\nPrototypeML is a machine learning development environment that bridges the\ndichotomy between the design and development processes: it provides a highly\nintuitive visual neural network design interface that supports (yet abstracts)\nthe full capabilities of the PyTorch deep learning framework, reduces model\ndesign and development time, makes debugging easier, and automates many\nframework and code writing idiosyncrasies. In this paper, we detail the deep\nlearning development deficiencies that drove the implementation of PrototypeML,\nand propose a hybrid approach to resolve these issues without limiting network\nexpressiveness or reducing code quality. We demonstrate the real-world benefits\nof a visual approach to neural network design for research, industry and\nteaching. Available at https://PrototypeML.com\n", "versions": [{"version": "v1", "created": "Wed, 1 Jul 2020 08:47:46 GMT"}], "update_date": "2020-07-03", "authors_parsed": [["Harris", "Daniel Reiss", ""]]}, {"id": "2007.01187", "submitter": "Tom Bewley", "authors": "Tom Bewley", "title": "Am I Building a White Box Agent or Interpreting a Black Box Agent?", "comments": "6 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The rule extraction literature contains the notion of a fidelity-accuracy\ndilemma: when building an interpretable model of a black box function,\noptimising for fidelity is likely to reduce performance on the underlying task,\nand vice versa. I reassert the relevance of this dilemma for the modern field\nof explainable artificial intelligence, and highlight how it is compounded when\nthe black box is an agent interacting with a dynamic environment. I then\ndiscuss two independent research directions - building white box agents and\ninterpreting black box agents - which are both coherent and worthy of\nattention, but must not be conflated by researchers embarking on projects in\nthe domain of agent interpretability.\n", "versions": [{"version": "v1", "created": "Thu, 2 Jul 2020 15:20:43 GMT"}, {"version": "v2", "created": "Fri, 3 Jul 2020 12:35:41 GMT"}, {"version": "v3", "created": "Wed, 8 Jul 2020 15:06:14 GMT"}], "update_date": "2020-07-09", "authors_parsed": [["Bewley", "Tom", ""]]}, {"id": "2007.01195", "submitter": "Mayalen Etcheverry", "authors": "Mayalen Etcheverry, Clement Moulin-Frier, Pierre-Yves Oudeyer", "title": "Hierarchically Organized Latent Modules for Exploratory Search in\n  Morphogenetic Systems", "comments": null, "journal-ref": "Advances in Neural Information Processing Systems 33 (NeurIPS 2020\n  - oral)", "doi": null, "report-no": null, "categories": "cs.LG cs.AI nlin.CG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Self-organization of complex morphological patterns from local interactions\nis a fascinating phenomenon in many natural and artificial systems. In the\nartificial world, typical examples of such morphogenetic systems are cellular\nautomata. Yet, their mechanisms are often very hard to grasp and so far\nscientific discoveries of novel patterns have primarily been relying on manual\ntuning and ad hoc exploratory search. The problem of automated diversity-driven\ndiscovery in these systems was recently introduced [26, 62], highlighting that\ntwo key ingredients are autonomous exploration and unsupervised representation\nlearning to describe \"relevant\" degrees of variations in the patterns. In this\npaper, we motivate the need for what we call Meta-diversity search, arguing\nthat there is not a unique ground truth interesting diversity as it strongly\ndepends on the final observer and its motives. Using a continuous game-of-life\nsystem for experiments, we provide empirical evidences that relying on\nmonolithic architectures for the behavioral embedding design tends to bias the\nfinal discoveries (both for hand-defined and unsupervisedly-learned features)\nwhich are unlikely to be aligned with the interest of a final end-user. To\naddress these issues, we introduce a novel dynamic and modular architecture\nthat enables unsupervised learning of a hierarchy of diverse representations.\nCombined with intrinsically motivated goal exploration algorithms, we show that\nthis system forms a discovery assistant that can efficiently adapt its\ndiversity search towards preferences of a user using only a very small amount\nof user feedback.\n", "versions": [{"version": "v1", "created": "Thu, 2 Jul 2020 15:28:27 GMT"}, {"version": "v2", "created": "Wed, 21 Oct 2020 14:47:31 GMT"}], "update_date": "2021-02-26", "authors_parsed": [["Etcheverry", "Mayalen", ""], ["Moulin-Frier", "Clement", ""], ["Oudeyer", "Pierre-Yves", ""]]}, {"id": "2007.01223", "submitter": "Nathan Fulton", "authors": "Nathan Hunt, Nathan Fulton, Sara Magliacane, Nghia Hoang, Subhro Das,\n  Armando Solar-Lezama", "title": "Verifiably Safe Exploration for End-to-End Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deploying deep reinforcement learning in safety-critical settings requires\ndeveloping algorithms that obey hard constraints during exploration. This paper\ncontributes a first approach toward enforcing formal safety constraints on\nend-to-end policies with visual inputs. Our approach draws on recent advances\nin object detection and automated reasoning for hybrid dynamical systems. The\napproach is evaluated on a novel benchmark that emphasizes the challenge of\nsafely exploring in the presence of hard constraints. Our benchmark draws from\nseveral proposed problem sets for safe learning and includes problems that\nemphasize challenges such as reward signals that are not aligned with safety\nconstraints. On each of these benchmark problems, our algorithm completely\navoids unsafe behavior while remaining competitive at optimizing for as much\nreward as is safe. We also prove that our method of enforcing the safety\nconstraints preserves all safe policies from the original environment.\n", "versions": [{"version": "v1", "created": "Thu, 2 Jul 2020 16:12:20 GMT"}], "update_date": "2020-07-03", "authors_parsed": [["Hunt", "Nathan", ""], ["Fulton", "Nathan", ""], ["Magliacane", "Sara", ""], ["Hoang", "Nghia", ""], ["Das", "Subhro", ""], ["Solar-Lezama", "Armando", ""]]}, {"id": "2007.01334", "submitter": "Muhammad Aneeq Uz Zaman", "authors": "Muhammad Aneeq uz Zaman and Aamer Iqbal Bhatti", "title": "Multi-agent Planning for thermalling gliders using multi level\n  graph-search", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.AI cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper solves a path planning problem for a group of gliders. The gliders\nare tasked with visiting a set of interest points. The gliders have limited\nrange but are able to increase their range by visiting special points called\nthermals. The problem addressed in this paper is of path planning for the\ngliders such that, the total number of interest points visited by the gliders\nis maximized. This is referred to as the multi-agent problem. The problem is\nsolved by first decomposing it into several single-agent problems. In a\nsingle-agent problem a set of interest points are allocated to a single glider.\nThis problem is solved by planning a path which maximizes the number of visited\ninterest points from the allocated set. This is achieved through a uniform cost\ngraph search, as shown in our earlier work. The multi-agent problem now\nconsists of determining the best allocation (of interest points) for each\nglider. Two ways are presented of solving this problem, a brute force search\napproach as shown in earlier work and a Branch\\&Bound type graph search. The\nBranch&Bound approach is the main contribution of the paper. This approach is\nproven to be optimal and shown to be faster than the brute force search using\nsimulations.\n", "versions": [{"version": "v1", "created": "Thu, 2 Jul 2020 18:30:15 GMT"}], "update_date": "2020-07-06", "authors_parsed": [["Zaman", "Muhammad Aneeq uz", ""], ["Bhatti", "Aamer Iqbal", ""]]}, {"id": "2007.01380", "submitter": "Charalampos Andriotis", "authors": "C.P. Andriotis, K.G. Papakonstantinou", "title": "Deep reinforcement learning driven inspection and maintenance planning\n  under incomplete information and constraints", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Determination of inspection and maintenance policies for minimizing long-term\nrisks and costs in deteriorating engineering environments constitutes a complex\noptimization problem. Major computational challenges include the (i) curse of\ndimensionality, due to exponential scaling of state/action set cardinalities\nwith the number of components; (ii) curse of history, related to exponentially\ngrowing decision-trees with the number of decision-steps; (iii) presence of\nstate uncertainties, induced by inherent environment stochasticity and\nvariability of inspection/monitoring measurements; (iv) presence of\nconstraints, pertaining to stochastic long-term limitations, due to resource\nscarcity and other infeasible/undesirable system responses. In this work, these\nchallenges are addressed within a joint framework of constrained Partially\nObservable Markov Decision Processes (POMDP) and multi-agent Deep Reinforcement\nLearning (DRL). POMDPs optimally tackle (ii)-(iii), combining stochastic\ndynamic programming with Bayesian inference principles. Multi-agent DRL\naddresses (i), through deep function parametrizations and decentralized control\nassumptions. Challenge (iv) is herein handled through proper state augmentation\nand Lagrangian relaxation, with emphasis on life-cycle risk-based constraints\nand budget limitations. The underlying algorithmic steps are provided, and the\nproposed framework is found to outperform well-established policy baselines and\nfacilitate adept prescription of inspection and intervention actions, in cases\nwhere decisions must be made in the most resource- and risk-aware manner.\n", "versions": [{"version": "v1", "created": "Thu, 2 Jul 2020 20:44:07 GMT"}], "update_date": "2020-07-06", "authors_parsed": [["Andriotis", "C. P.", ""], ["Papakonstantinou", "K. G.", ""]]}, {"id": "2007.01413", "submitter": "Ridwan Alam", "authors": "Ridwan Alam, David B. Peden, and John C. Lach", "title": "Wearable Respiration Monitoring: Interpretable Inference with Context\n  and Sensor Biomarkers", "comments": "10 pages, 10 figures", "journal-ref": null, "doi": "10.1109/JBHI.2020.3035776", "report-no": null, "categories": "eess.SP cs.AI cs.CY cs.HC cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Breathing rate (BR), minute ventilation (VE), and other respiratory\nparameters are essential for real-time patient monitoring in many acute health\nconditions, such as asthma. The clinical standard for measuring respiration,\nnamely Spirometry, is hardly suitable for continuous use. Wearables can track\nmany physiological signals, like ECG and motion, yet not respiration. Deriving\nrespiration from other modalities has become an area of active research. In\nthis work, we infer respiratory parameters from wearable ECG and wrist motion\nsignals. We propose a modular and generalizable classification-regression\npipeline to utilize available context information, such as physical activity,\nin learning context-conditioned inference models. Morphological and power\ndomain novel features from the wearable ECG are extracted to use with these\nmodels. Exploratory feature selection methods are incorporated in this pipeline\nto discover application-specific interpretable biomarkers. Using data from 15\nsubjects, we evaluate two implementations of the proposed pipeline: for\ninferring BR and VE. Each implementation compares generalized linear model,\nrandom forest, support vector machine, Gaussian process regression, and\nneighborhood component analysis as contextual regression models. Permutation,\nregularization, and relevance determination methods are used to rank the ECG\nfeatures to identify robust ECG biomarkers across models and activities. This\nwork demonstrates the potential of wearable sensors not only in continuous\nmonitoring, but also in designing biomarker-driven preventive measures.\n", "versions": [{"version": "v1", "created": "Thu, 2 Jul 2020 22:12:49 GMT"}], "update_date": "2020-11-26", "authors_parsed": [["Alam", "Ridwan", ""], ["Peden", "David B.", ""], ["Lach", "John C.", ""]]}, {"id": "2007.01493", "submitter": "Arthur Choi", "authors": "Arthur Choi and Andy Shih and Anchal Goyanka and Adnan Darwiche", "title": "On Symbolically Encoding the Behavior of Random Forests", "comments": "Presented at the 3rd Workshop on Formal Methods for ML-Enabled\n  Autonomous Systems (FoMLAS), 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work has shown that the input-output behavior of some machine learning\nsystems can be captured symbolically using Boolean expressions or tractable\nBoolean circuits, which facilitates reasoning about the behavior of these\nsystems. While most of the focus has been on systems with Boolean inputs and\noutputs, we address systems with discrete inputs and outputs, including ones\nwith discretized continuous variables as in systems based on decision trees. We\nalso focus on the suitability of encodings for computing prime implicants,\nwhich have recently played a central role in explaining the decisions of\nmachine learning systems. We show some key distinctions with encodings for\nsatisfiability, and propose an encoding that is sound and complete for the\ngiven task.\n", "versions": [{"version": "v1", "created": "Fri, 3 Jul 2020 04:21:47 GMT"}], "update_date": "2020-07-06", "authors_parsed": [["Choi", "Arthur", ""], ["Shih", "Andy", ""], ["Goyanka", "Anchal", ""], ["Darwiche", "Adnan", ""]]}, {"id": "2007.01498", "submitter": "Yuqian Jiang", "authors": "Yuqian Jiang, Sudarshanan Bharadwaj, Bo Wu, Rishi Shah, Ufuk Topcu,\n  Peter Stone", "title": "Temporal-Logic-Based Reward Shaping for Continuing Learning Tasks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In continuing tasks, average-reward reinforcement learning may be a more\nappropriate problem formulation than the more common discounted reward\nformulation. As usual, learning an optimal policy in this setting typically\nrequires a large amount of training experiences. Reward shaping is a common\napproach for incorporating domain knowledge into reinforcement learning in\norder to speed up convergence to an optimal policy. However, to the best of our\nknowledge, the theoretical properties of reward shaping have thus far only been\nestablished in the discounted setting. This paper presents the first reward\nshaping framework for average-reward learning and proves that, under standard\nassumptions, the optimal policy under the original reward function can be\nrecovered. In order to avoid the need for manual construction of the shaping\nfunction, we introduce a method for utilizing domain knowledge expressed as a\ntemporal logic formula. The formula is automatically translated to a shaping\nfunction that provides additional reward throughout the learning process. We\nevaluate the proposed method on three continuing tasks. In all cases, shaping\nspeeds up the average-reward learning rate without any reduction in the\nperformance of the learned policy compared to relevant baselines.\n", "versions": [{"version": "v1", "created": "Fri, 3 Jul 2020 05:06:57 GMT"}], "update_date": "2020-07-06", "authors_parsed": [["Jiang", "Yuqian", ""], ["Bharadwaj", "Sudarshanan", ""], ["Wu", "Bo", ""], ["Shah", "Rishi", ""], ["Topcu", "Ufuk", ""], ["Stone", "Peter", ""]]}, {"id": "2007.01542", "submitter": "Jeppe Theiss Kristensen", "authors": "Jeppe Theiss Kristensen, Paolo Burelli", "title": "Strategies for Using Proximal Policy Optimization in Mobile Puzzle Games", "comments": "10 pages, 8 figures, to be published in 2020 Foundations of Digital\n  Games conference", "journal-ref": null, "doi": "10.1145/3402942.3402944", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While traditionally a labour intensive task, the testing of game content is\nprogressively becoming more automated. Among the many directions in which this\nautomation is taking shape, automatic play-testing is one of the most promising\nthanks also to advancements of many supervised and reinforcement learning (RL)\nalgorithms. However these type of algorithms, while extremely powerful, often\nsuffer in production environments due to issues with reliability and\ntransparency in their training and usage.\n  In this research work we are investigating and evaluating strategies to apply\nthe popular RL method Proximal Policy Optimization (PPO) in a casual mobile\npuzzle game with a specific focus on improving its reliability in training and\ngeneralization during game playing.\n  We have implemented and tested a number of different strategies against a\nreal-world mobile puzzle game (Lily's Garden from Tactile Games). We isolated\nthe conditions that lead to a failure in either training or generalization\nduring testing and we identified a few strategies to ensure a more stable\nbehaviour of the algorithm in this game genre.\n", "versions": [{"version": "v1", "created": "Fri, 3 Jul 2020 08:03:45 GMT"}], "update_date": "2021-07-09", "authors_parsed": [["Kristensen", "Jeppe Theiss", ""], ["Burelli", "Paolo", ""]]}, {"id": "2007.01544", "submitter": "Francisco Cruz", "authors": "Adam Bignold, Francisco Cruz, Matthew E. Taylor, Tim Brys, Richard\n  Dazeley, Peter Vamplew, Cameron Foale", "title": "A Conceptual Framework for Externally-influenced Agents: An Assisted\n  Reinforcement Learning Review", "comments": "33 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A long-term goal of reinforcement learning agents is to be able to perform\ntasks in complex real-world scenarios. The use of external information is one\nway of scaling agents to more complex problems. However, there is a general\nlack of collaboration or interoperability between different approaches using\nexternal information. In this work, we propose a conceptual framework and\ntaxonomy for assisted reinforcement learning, aimed at fostering such\ncollaboration by classifying and comparing various methods that use external\ninformation in the learning process. The proposed taxonomy details the\nrelationship between the external information source and the learner agent,\nhighlighting the process of information decomposition, structure, retention,\nand how it can be used to influence agent learning. As well as reviewing\nstate-of-the-art methods, we identify current streams of reinforcement learning\nthat use external information in order to improve the agent's performance and\nits decision-making process. These include heuristic reinforcement learning,\ninteractive reinforcement learning, learning from demonstration, transfer\nlearning, and learning from multiple sources, among others. These streams of\nreinforcement learning operate with the shared objective of scaffolding the\nlearner agent. Lastly, we discuss further possibilities for future work in the\nfield of assisted reinforcement learning systems.\n", "versions": [{"version": "v1", "created": "Fri, 3 Jul 2020 08:07:31 GMT"}], "update_date": "2020-07-06", "authors_parsed": [["Bignold", "Adam", ""], ["Cruz", "Francisco", ""], ["Taylor", "Matthew E.", ""], ["Brys", "Tim", ""], ["Dazeley", "Richard", ""], ["Vamplew", "Peter", ""], ["Foale", "Cameron", ""]]}, {"id": "2007.01599", "submitter": "Joris Mollinga", "authors": "Joris Mollinga, Herke van Hoof", "title": "An Autonomous Free Airspace En-route Controller using Deep Reinforcement\n  Learning Techniques", "comments": "Published at ICRAT2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Air traffic control is becoming a more and more complex task due to the\nincreasing number of aircraft. Current air traffic control methods are not\nsuitable for managing this increased traffic. Autonomous air traffic control is\ndeemed a promising alternative. In this paper an air traffic control model is\npresented that guides an arbitrary number of aircraft across a\nthree-dimensional, unstructured airspace while avoiding conflicts and\ncollisions. This is done utilizing the power of graph based deep learning\napproaches. These approaches offer significant advantages over current\napproaches to this task, such as invariance to the input ordering of aircraft\nand the ability to easily cope with a varying number of aircraft. Results\nacquired using these approaches show that the air traffic control model\nperforms well on realistic traffic densities; it is capable of managing the\nairspace by avoiding 100% of potential collisions and preventing 89.8% of\npotential conflicts.\n", "versions": [{"version": "v1", "created": "Fri, 3 Jul 2020 10:37:25 GMT"}], "update_date": "2020-07-06", "authors_parsed": [["Mollinga", "Joris", ""], ["van Hoof", "Herke", ""]]}, {"id": "2007.01610", "submitter": "Jean Christoph Jung", "authors": "Jean Christoph Jung, Carsten Lutz, Hadrien Pulcini, Frank Wolter", "title": "Logical Separability of Incomplete Data under Ontologies", "comments": "Full Version of KR'20 paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Finding a logical formula that separates positive and negative examples given\nin the form of labeled data items is fundamental in applications such as\nconcept learning, reverse engineering of database queries, and generating\nreferring expressions. In this paper, we investigate the existence of a\nseparating formula for incomplete data in the presence of an ontology. Both for\nthe ontology language and the separation language, we concentrate on\nfirst-order logic and three important fragments thereof: the description logic\n$\\mathcal{ALCI}$, the guarded fragment, and the two-variable fragment. We\nconsider several forms of separability that differ in the treatment of negative\nexamples and in whether or not they admit the use of additional helper symbols\nto achieve separation. We characterize separability in a model-theoretic way,\ncompare the separating power of the different languages, and determine the\ncomputational complexity of separability as a decision problem.\n", "versions": [{"version": "v1", "created": "Fri, 3 Jul 2020 11:00:47 GMT"}], "update_date": "2020-07-06", "authors_parsed": [["Jung", "Jean Christoph", ""], ["Lutz", "Carsten", ""], ["Pulcini", "Hadrien", ""], ["Wolter", "Frank", ""]]}, {"id": "2007.01627", "submitter": "Thomas Moreau", "authors": "Marine Le Morvan (PARIETAL, IJCLab), Julie Josse (CMAP, XPOP), Thomas\n  Moreau (PARIETAL), Erwan Scornet (CMAP), Ga\\\"el Varoquaux (PARIETAL, MILA)", "title": "NeuMiss networks: differentiable programming for supervised learning\n  with missing values", "comments": null, "journal-ref": "Advances in Neural Information Processing Systems 33, Dec 2020,\n  Vancouver, Canada", "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The presence of missing values makes supervised learning much more\nchallenging. Indeed, previous work has shown that even when the response is a\nlinear function of the complete data, the optimal predictor is a complex\nfunction of the observed entries and the missingness indicator. As a result,\nthe computational or sample complexities of consistent approaches depend on the\nnumber of missing patterns, which can be exponential in the number of\ndimensions. In this work, we derive the analytical form of the optimal\npredictor under a linearity assumption and various missing data mechanisms\nincluding Missing at Random (MAR) and self-masking (Missing Not At Random).\nBased on a Neumann-series approximation of the optimal predictor, we propose a\nnew principled architecture, named NeuMiss networks. Their originality and\nstrength come from the use of a new type of non-linearity: the multiplication\nby the missingness indicator. We provide an upper bound on the Bayes risk of\nNeuMiss networks, and show that they have good predictive accuracy with both a\nnumber of parameters and a computational complexity independent of the number\nof missing data patterns. As a result they scale well to problems with many\nfeatures, and remain statistically efficient for medium-sized samples.\nMoreover, we show that, contrary to procedures using EM or imputation, they are\nrobust to the missing data mechanism, including difficult MNAR settings such as\nself-masking.\n", "versions": [{"version": "v1", "created": "Fri, 3 Jul 2020 11:42:25 GMT"}, {"version": "v2", "created": "Mon, 12 Oct 2020 12:29:36 GMT"}, {"version": "v3", "created": "Tue, 13 Oct 2020 14:47:18 GMT"}, {"version": "v4", "created": "Wed, 4 Nov 2020 15:39:04 GMT"}], "update_date": "2020-11-05", "authors_parsed": [["Morvan", "Marine Le", "", "PARIETAL, IJCLab"], ["Josse", "Julie", "", "CMAP, XPOP"], ["Moreau", "Thomas", "", "PARIETAL"], ["Scornet", "Erwan", "", "CMAP"], ["Varoquaux", "Ga\u00ebl", "", "PARIETAL, MILA"]]}, {"id": "2007.01647", "submitter": "Martin Stetter Ph.D.", "authors": "Martin Stetter and Elmar W. Lang", "title": "Learning intuitive physics and one-shot imitation using\n  state-action-prediction self-organizing maps", "comments": "27 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Human learning and intelligence work differently from the supervised pattern\nrecognition approach adopted in most deep learning architectures. Humans seem\nto learn rich representations by exploration and imitation, build causal models\nof the world, and use both to flexibly solve new tasks. We suggest a simple but\neffective unsupervised model which develops such characteristics. The agent\nlearns to represent the dynamical physical properties of its environment by\nintrinsically motivated exploration, and performs inference on this\nrepresentation to reach goals. For this, a set of self-organizing maps which\nrepresent state-action pairs is combined with a causal model for sequence\nprediction. The proposed system is evaluated in the cartpole environment. After\nan initial phase of playful exploration, the agent can execute kinematic\nsimulations of the environment's future, and use those for action planning. We\ndemonstrate its performance on a set of several related, but different one-shot\nimitation tasks, which the agent flexibly solves in an active inference style.\n", "versions": [{"version": "v1", "created": "Fri, 3 Jul 2020 12:29:11 GMT"}, {"version": "v2", "created": "Fri, 8 Jan 2021 10:10:53 GMT"}], "update_date": "2021-01-11", "authors_parsed": [["Stetter", "Martin", ""], ["Lang", "Elmar W.", ""]]}, {"id": "2007.01719", "submitter": "Halcyon Carvalho", "authors": "Halcyon D. P. Carvalho, Mar\\'ilia N. C. A. Lima, Wylliams B. Santos\n  and Roberta A. de A.Fagunde", "title": "Ensemble Regression Models for Software Development Effort Estimation: A\n  Comparative Study", "comments": null, "journal-ref": "International Journal of Software Engineering & Applications\n  (IJSEA), Vol.11, No.3, May 2020", "doi": "10.5121/ijsea.2020.11305", "report-no": null, "categories": "cs.SE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As demand for computer software continually increases, software scope and\ncomplexity become higher than ever. The software industry is in real need of\naccurate estimates of the project under development. Software development\neffort estimation is one of the main processes in software project management.\nHowever, overestimation and underestimation may cause the software industry\nloses. This study determines which technique has better effort prediction\naccuracy and propose combined techniques that could provide better estimates.\nEight different ensemble models to estimate effort with Ensemble Models were\ncompared with each other base on the predictive accuracy on the Mean Absolute\nResidual (MAR) criterion and statistical tests. The results have indicated that\nthe proposed ensemble models, besides delivering high efficiency in contrast to\nits counterparts, and produces the best responses for software project effort\nestimation. Therefore, the proposed ensemble models in this study will help the\nproject managers working with development quality software.\n", "versions": [{"version": "v1", "created": "Fri, 3 Jul 2020 14:40:41 GMT"}], "update_date": "2020-07-06", "authors_parsed": [["Carvalho", "Halcyon D. P.", ""], ["Lima", "Mar\u00edlia N. C. A.", ""], ["Santos", "Wylliams B.", ""], ["Fagunde", "Roberta A. de A.", ""]]}, {"id": "2007.01780", "submitter": "Amelia Pollard", "authors": "Amelia Elizabeth Pollard and Jonathan L. Shapiro", "title": "Visual Question Answering as a Multi-Task Problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Visual Question Answering(VQA) is a highly complex problem set, relying on\nmany sub-problems to produce reasonable answers. In this paper, we present the\nhypothesis that Visual Question Answering should be viewed as a multi-task\nproblem, and provide evidence to support this hypothesis. We demonstrate this\nby reformatting two commonly used Visual Question Answering datasets, COCO-QA\nand DAQUAR, into a multi-task format and train these reformatted datasets on\ntwo baseline networks, with one designed specifically to eliminate other\npossible causes for performance changes as a result of the reformatting. Though\nthe networks demonstrated in this paper do not achieve strongly competitive\nresults, we find that the multi-task approach to Visual Question Answering\nresults in increases in performance of 5-9% against the single-task formatting,\nand that the networks reach convergence much faster than in the single-task\ncase. Finally we discuss possible reasons for the observed difference in\nperformance, and perform additional experiments which rule out causes not\nassociated with the learning of the dataset as a multi-task problem.\n", "versions": [{"version": "v1", "created": "Fri, 3 Jul 2020 16:07:13 GMT"}], "update_date": "2020-07-06", "authors_parsed": [["Pollard", "Amelia Elizabeth", ""], ["Shapiro", "Jonathan L.", ""]]}, {"id": "2007.01833", "submitter": "Prakash Rajan", "authors": "Prakash Rajan, Krishna P. Miyapuram", "title": "PsychFM: Predicting your next gamble", "comments": "To be published in International Joint Conference on Neural Networks\n  (IJCNN) 2020 conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is a sudden surge to model human behavior due to its vast and diverse\napplications which includes modeling public policies, economic behavior and\nconsumer behavior. Most of the human behavior itself can be modeled into a\nchoice prediction problem. Prospect theory is a theoretical model that tries to\nexplain the anomalies in choice prediction. These theories perform well in\nterms of explaining the anomalies but they lack precision. Since the behavior\nis person dependent, there is a need to build a model that predicts choices on\na per-person basis. Looking on at the average persons choice may not\nnecessarily throw light on a particular person's choice. Modeling the gambling\nproblem on a per person basis will help in recommendation systems and related\nareas. A novel hybrid model namely psychological factorisation machine (\nPsychFM ) has been proposed that involves concepts from machine learning as\nwell as psychological theories. It outperforms the popular existing models\nnamely random forest and factorisation machines for the benchmark dataset\nCPC-18. Finally,the efficacy of the proposed hybrid model has been verified by\ncomparing with the existing models.\n", "versions": [{"version": "v1", "created": "Fri, 3 Jul 2020 17:41:14 GMT"}], "update_date": "2020-07-06", "authors_parsed": [["Rajan", "Prakash", ""], ["Miyapuram", "Krishna P.", ""]]}, {"id": "2007.01839", "submitter": "Hado van Hasselt", "authors": "Hado van Hasselt, Sephora Madjiheurem, Matteo Hessel, David Silver,\n  Andr\\'e Barreto, Diana Borsa", "title": "Expected Eligibility Traces", "comments": "AAAI, distinguished paper award", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The question of how to determine which states and actions are responsible for\na certain outcome is known as the credit assignment problem and remains a\ncentral research question in reinforcement learning and artificial\nintelligence. Eligibility traces enable efficient credit assignment to the\nrecent sequence of states and actions experienced by the agent, but not to\ncounterfactual sequences that could also have led to the current state. In this\nwork, we introduce expected eligibility traces. Expected traces allow, with a\nsingle update, to update states and actions that could have preceded the\ncurrent state, even if they did not do so on this occasion. We discuss when\nexpected traces provide benefits over classic (instantaneous) traces in\ntemporal-difference learning, and show that sometimes substantial improvements\ncan be attained. We provide a way to smoothly interpolate between instantaneous\nand expected traces by a mechanism similar to bootstrapping, which ensures that\nthe resulting algorithm is a strict generalisation of TD($\\lambda$). Finally,\nwe discuss possible extensions and connections to related ideas, such as\nsuccessor features.\n", "versions": [{"version": "v1", "created": "Fri, 3 Jul 2020 17:46:16 GMT"}, {"version": "v2", "created": "Mon, 8 Feb 2021 13:02:30 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["van Hasselt", "Hado", ""], ["Madjiheurem", "Sephora", ""], ["Hessel", "Matteo", ""], ["Silver", "David", ""], ["Barreto", "Andr\u00e9", ""], ["Borsa", "Diana", ""]]}, {"id": "2007.01921", "submitter": "Matthew Gombolay", "authors": "Ruisen Liu, Manisha Natarajan, and Matthew Gombolay", "title": "Human-Robot Team Coordination with Dynamic and Latent Human Task\n  Proficiencies: Scheduling with Learning Curves", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.HC cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As robots become ubiquitous in the workforce, it is essential that\nhuman-robot collaboration be both intuitive and adaptive. A robot's quality\nimproves based on its ability to explicitly reason about the time-varying (i.e.\nlearning curves) and stochastic capabilities of its human counterparts, and\nadjust the joint workload to improve efficiency while factoring human\npreferences. We introduce a novel resource coordination algorithm that enables\nrobots to explore the relative strengths and learning abilities of their human\nteammates, by constructing schedules that are robust to stochastic and\ntime-varying human task performance. We first validate our algorithmic approach\nusing data we collected from a user study (n = 20), showing we can quickly\ngenerate and evaluate a robust schedule while discovering the latest individual\nworker proficiency. Second, we conduct a between-subjects experiment (n = 90)\nto validate the efficacy of our coordinating algorithm. Results from the\nhuman-subjects experiment indicate that scheduling strategies favoring\nexploration tend to be beneficial for human-robot collaboration as it improves\nteam fluency (p = 0.0438), while also maximizing team efficiency (p < 0.001).\n", "versions": [{"version": "v1", "created": "Fri, 3 Jul 2020 19:44:22 GMT"}, {"version": "v2", "created": "Thu, 9 Jul 2020 02:40:57 GMT"}], "update_date": "2020-07-10", "authors_parsed": [["Liu", "Ruisen", ""], ["Natarajan", "Manisha", ""], ["Gombolay", "Matthew", ""]]}, {"id": "2007.01962", "submitter": "Cyrus Neary", "authors": "Cyrus Neary, Zhe Xu, Bo Wu, and Ufuk Topcu", "title": "Reward Machines for Cooperative Multi-Agent Reinforcement Learning", "comments": "Accepted at AAMAS 2021. Changes since last version: The paper's\n  running example has been modified to simplify presentation (experimental\n  section changed accordingly). Several proofs and definitions surrounding\n  reward machines have been moved from the supplementary material into the body\n  of the paper", "journal-ref": null, "doi": "10.5555/3463952.3464063", "report-no": null, "categories": "cs.MA cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In cooperative multi-agent reinforcement learning, a collection of agents\nlearns to interact in a shared environment to achieve a common goal. We propose\nthe use of reward machines (RM) -- Mealy machines used as structured\nrepresentations of reward functions -- to encode the team's task. The proposed\nnovel interpretation of RMs in the multi-agent setting explicitly encodes\nrequired teammate interdependencies, allowing the team-level task to be\ndecomposed into sub-tasks for individual agents. We define such a notion of RM\ndecomposition and present algorithmically verifiable conditions guaranteeing\nthat distributed completion of the sub-tasks leads to team behavior\naccomplishing the original task. This framework for task decomposition provides\na natural approach to decentralized learning: agents may learn to accomplish\ntheir sub-tasks while observing only their local state and abstracted\nrepresentations of their teammates. We accordingly propose a decentralized\nq-learning algorithm. Furthermore, in the case of undiscounted rewards, we use\nlocal value functions to derive lower and upper bounds for the global value\nfunction corresponding to the team task. Experimental results in three discrete\nsettings exemplify the effectiveness of the proposed RM decomposition approach,\nwhich converges to a successful team policy an order of magnitude faster than a\ncentralized learner and significantly outperforms hierarchical and independent\nq-learning approaches.\n", "versions": [{"version": "v1", "created": "Fri, 3 Jul 2020 23:08:14 GMT"}, {"version": "v2", "created": "Tue, 9 Feb 2021 00:28:11 GMT"}], "update_date": "2021-06-16", "authors_parsed": [["Neary", "Cyrus", ""], ["Xu", "Zhe", ""], ["Wu", "Bo", ""], ["Topcu", "Ufuk", ""]]}, {"id": "2007.01977", "submitter": "Martin Hirzel", "authors": "Guillaume Baudart, Martin Hirzel, Kiran Kate, Parikshit Ram, Avraham\n  Shinnar", "title": "Lale: Consistent Automated Machine Learning", "comments": "KDD Workshop on Automation in Machine Learning (AutoML@KDD), August\n  2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automated machine learning makes it easier for data scientists to develop\npipelines by searching over possible choices for hyperparameters, algorithms,\nand even pipeline topologies. Unfortunately, the syntax for automated machine\nlearning tools is inconsistent with manual machine learning, with each other,\nand with error checks. Furthermore, few tools support advanced features such as\ntopology search or higher-order operators. This paper introduces Lale, a\nlibrary of high-level Python interfaces that simplifies and unifies automated\nmachine learning in a consistent way.\n", "versions": [{"version": "v1", "created": "Sat, 4 Jul 2020 00:55:41 GMT"}], "update_date": "2020-07-07", "authors_parsed": [["Baudart", "Guillaume", ""], ["Hirzel", "Martin", ""], ["Kate", "Kiran", ""], ["Ram", "Parikshit", ""], ["Shinnar", "Avraham", ""]]}, {"id": "2007.01995", "submitter": "Hang Lai", "authors": "Hang Lai, Jian Shen, Weinan Zhang, Yong Yu", "title": "Bidirectional Model-based Policy Optimization", "comments": "Accepted at ICML2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Model-based reinforcement learning approaches leverage a forward dynamics\nmodel to support planning and decision making, which, however, may fail\ncatastrophically if the model is inaccurate. Although there are several\nexisting methods dedicated to combating the model error, the potential of the\nsingle forward model is still limited. In this paper, we propose to\nadditionally construct a backward dynamics model to reduce the reliance on\naccuracy in forward model predictions. We develop a novel method, called\nBidirectional Model-based Policy Optimization (BMPO) to utilize both the\nforward model and backward model to generate short branched rollouts for policy\noptimization. Furthermore, we theoretically derive a tighter bound of return\ndiscrepancy, which shows the superiority of BMPO against the one using merely\nthe forward model. Extensive experiments demonstrate that BMPO outperforms\nstate-of-the-art model-based methods in terms of sample efficiency and\nasymptotic performance.\n", "versions": [{"version": "v1", "created": "Sat, 4 Jul 2020 03:34:09 GMT"}, {"version": "v2", "created": "Tue, 29 Sep 2020 13:58:33 GMT"}], "update_date": "2020-09-30", "authors_parsed": [["Lai", "Hang", ""], ["Shen", "Jian", ""], ["Zhang", "Weinan", ""], ["Yu", "Yong", ""]]}, {"id": "2007.02040", "submitter": "Ron Amit", "authors": "Ron Amit, Ron Meir, Kamil Ciosek", "title": "Discount Factor as a Regularizer in Reinforcement Learning", "comments": "Published in ICML 2020", "journal-ref": "Published in Proceedings of the 37th International Conference on\n  Machine Learning, Vienna, Austria, PMLR 119, 2020", "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Specifying a Reinforcement Learning (RL) task involves choosing a suitable\nplanning horizon, which is typically modeled by a discount factor. It is known\nthat applying RL algorithms with a lower discount factor can act as a\nregularizer, improving performance in the limited data regime. Yet the exact\nnature of this regularizer has not been investigated. In this work, we fill in\nthis gap. For several Temporal-Difference (TD) learning methods, we show an\nexplicit equivalence between using a reduced discount factor and adding an\nexplicit regularization term to the algorithm's loss. Motivated by the\nequivalence, we empirically study this technique compared to standard $L_2$\nregularization by extensive experiments in discrete and continuous domains,\nusing tabular and functional representations. Our experiments suggest the\nregularization effectiveness is strongly related to properties of the available\ndata, such as size, distribution, and mixing rate.\n", "versions": [{"version": "v1", "created": "Sat, 4 Jul 2020 08:10:09 GMT"}], "update_date": "2020-07-07", "authors_parsed": [["Amit", "Ron", ""], ["Meir", "Ron", ""], ["Ciosek", "Kamil", ""]]}, {"id": "2007.02092", "submitter": "Deepak Edakkattil Gopinath", "authors": "Deepak Gopinath, Mahdieh Nejati Javaremi and Brenna D. Argall", "title": "Customized Handling of Unintended Interface Operation in Assistive\n  Robots", "comments": "10 pages, 7 figures, preprint", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an assistance system that reasons about a human's intended actions\nduring robot teleoperation in order to provide appropriate corrections for\nunintended behavior. We model the human's physical interaction with a control\ninterface during robot teleoperation and distinguish between intended and\nmeasured physical actions explicitly. By reasoning over the unobserved\nintentions using model-based inference techniques, our assistive system\nprovides customized corrections on a user's issued commands. We validate our\nalgorithm with a 10-person human subject study in which we evaluate the\nperformance of the proposed assistance paradigms. Our results show that the\nassistance paradigms helped to significantly reduce task completion time,\nnumber of mode switches, cognitive workload, and user frustration and improve\noverall user satisfaction.\n", "versions": [{"version": "v1", "created": "Sat, 4 Jul 2020 13:23:22 GMT"}, {"version": "v2", "created": "Thu, 5 Nov 2020 20:03:43 GMT"}], "update_date": "2020-11-09", "authors_parsed": [["Gopinath", "Deepak", ""], ["Javaremi", "Mahdieh Nejati", ""], ["Argall", "Brenna D.", ""]]}, {"id": "2007.02100", "submitter": "Alberto Cetoli", "authors": "Alberto Cetoli", "title": "Pynsett: A programmable relation extractor", "comments": "Accepted for publication in SEMAPRO2020", "journal-ref": "The Fourteenth International Conference on Advances in Semantic\n  Processing (2020), Pages 45-48", "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a programmable relation extraction method for the English\nlanguage by parsing texts into semantic graphs. A person can define rules in\nplain English that act as matching patterns onto the graph representation.\nThese rules are designed to capture the semantic content of the documents,\nallowing for flexibility and ad-hoc entities. Relation extraction is a complex\ntask that typically requires sizable training corpora. The method proposed here\nis ideal for extracting specialized ontologies in a limited collection of\ndocuments.\n", "versions": [{"version": "v1", "created": "Sat, 4 Jul 2020 14:03:48 GMT"}, {"version": "v2", "created": "Sun, 4 Oct 2020 22:52:29 GMT"}], "update_date": "2020-11-06", "authors_parsed": [["Cetoli", "Alberto", ""]]}, {"id": "2007.02114", "submitter": "Kuruge Darshana Abeyrathna", "authors": "K. Darshana Abeyrathna, Ole-Christoffer Granmo, Rishad Shafik, Alex\n  Yakovlev, Adrian Wheeldon, Jie Lei, Morten Goodwin", "title": "A Novel Multi-Step Finite-State Automaton for Arbitrarily Deterministic\n  Tsetlin Machine Learning", "comments": "10 pages, 8 figures, 7 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to the high energy consumption and scalability challenges of deep\nlearning, there is a critical need to shift research focus towards dealing with\nenergy consumption constraints. Tsetlin Machines (TMs) are a recent approach to\nmachine learning that has demonstrated significantly reduced energy usage\ncompared to neural networks alike, while performing competitively accuracy-wise\non several benchmarks. However, TMs rely heavily on energy-costly random number\ngeneration to stochastically guide a team of Tsetlin Automata to a Nash\nEquilibrium of the TM game. In this paper, we propose a novel finite-state\nlearning automaton that can replace the Tsetlin Automata in TM learning, for\nincreased determinism. The new automaton uses multi-step deterministic state\njumps to reinforce sub-patterns. Simultaneously, flipping a coin to skip every\n$d$'th state update ensures diversification by randomization. The $d$-parameter\nthus allows the degree of randomization to be finely controlled. E.g., $d=1$\nmakes every update random and $d=\\infty$ makes the automaton completely\ndeterministic. Our empirical results show that, overall, only substantial\ndegrees of determinism reduces accuracy. Energy-wise, random number generation\nconstitutes switching energy consumption of the TM, saving up to 11 mW power\nfor larger datasets with high $d$ values. We can thus use the new $d$-parameter\nto trade off accuracy against energy consumption, to facilitate low-energy\nmachine learning.\n", "versions": [{"version": "v1", "created": "Sat, 4 Jul 2020 14:56:05 GMT"}], "update_date": "2020-07-07", "authors_parsed": [["Abeyrathna", "K. Darshana", ""], ["Granmo", "Ole-Christoffer", ""], ["Shafik", "Rishad", ""], ["Yakovlev", "Alex", ""], ["Wheeldon", "Adrian", ""], ["Lei", "Jie", ""], ["Goodwin", "Morten", ""]]}, {"id": "2007.02130", "submitter": "Arman Maesumi", "authors": "Arman Maesumi", "title": "Playing Chess with Limited Look Ahead", "comments": "11 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We have seen numerous machine learning methods tackle the game of chess over\nthe years. However, one common element in these works is the necessity of a\nfinely optimized look ahead algorithm. The particular interest of this research\nlies with creating a chess engine that is highly capable, but restricted in its\nlook ahead depth. We train a deep neural network to serve as a static\nevaluation function, which is accompanied by a relatively simple look ahead\nalgorithm. We show that our static evaluation function has encoded some\nsemblance of look ahead knowledge, and is comparable to classical evaluation\nfunctions. The strength of our chess engine is assessed by comparing its\nproposed moves against those proposed by Stockfish. We show that, despite\nstrict restrictions on look ahead depth, our engine recommends moves of equal\nstrength in roughly $83\\%$ of our sample positions.\n", "versions": [{"version": "v1", "created": "Sat, 4 Jul 2020 16:02:43 GMT"}], "update_date": "2020-07-07", "authors_parsed": [["Maesumi", "Arman", ""]]}, {"id": "2007.02149", "submitter": "Piyush Yadav", "authors": "Piyush Yadav, Dipto Sarkar, Shailesh Deshpande, Edward Curry", "title": "Human Assisted Artificial Intelligence Based Technique to Create Natural\n  Features for OpenStreetMap", "comments": "3 pages, 2 Figures, Submitted to FOSS4G Europe 2020 Academic Track\n  (Postponed to 2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we propose an AI-based technique using freely available\nsatellite images like Landsat and Sentinel to create natural features over OSM\nin congruence with human editors acting as initiators and validators. The\nmethod is based on Interactive Machine Learning technique where human inputs\nare coupled with the machine to solve complex problems efficiently as compare\nto pure autonomous process. We use a bottom-up approach where a machine\nlearning (ML) pipeline in loop with editors is used to extract classes using\nspectral signatures of images and later convert them to editable features to\ncreate natural features.\n", "versions": [{"version": "v1", "created": "Sat, 4 Jul 2020 17:26:46 GMT"}, {"version": "v2", "created": "Wed, 8 Jul 2020 18:33:35 GMT"}], "update_date": "2020-07-10", "authors_parsed": [["Yadav", "Piyush", ""], ["Sarkar", "Dipto", ""], ["Deshpande", "Shailesh", ""], ["Curry", "Edward", ""]]}, {"id": "2007.02171", "submitter": "Gunjan Aggarwal", "authors": "Gunjan Aggarwal, Devi Parikh", "title": "Neuro-Symbolic Generative Art: A Preliminary Study", "comments": "Accepted as a short paper at ICCC 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There are two classes of generative art approaches: neural, where a deep\nmodel is trained to generate samples from a data distribution, and symbolic or\nalgorithmic, where an artist designs the primary parameters and an autonomous\nsystem generates samples within these constraints. In this work, we propose a\nnew hybrid genre: neuro-symbolic generative art. As a preliminary study, we\ntrain a generative deep neural network on samples from the symbolic approach.\nWe demonstrate through human studies that subjects find the final artifacts and\nthe creation process using our neuro-symbolic approach to be more creative than\nthe symbolic approach 61% and 82% of the time respectively.\n", "versions": [{"version": "v1", "created": "Sat, 4 Jul 2020 19:40:00 GMT"}], "update_date": "2020-07-07", "authors_parsed": [["Aggarwal", "Gunjan", ""], ["Parikh", "Devi", ""]]}, {"id": "2007.02244", "submitter": "A.B. Siddique", "authors": "A. B. Siddique, Samet Oymak, Vagelis Hristidis", "title": "Unsupervised Paraphrasing via Deep Reinforcement Learning", "comments": null, "journal-ref": null, "doi": "10.1145/3394486.3403231", "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Paraphrasing is expressing the meaning of an input sentence in different\nwording while maintaining fluency (i.e., grammatical and syntactical\ncorrectness). Most existing work on paraphrasing use supervised models that are\nlimited to specific domains (e.g., image captions). Such models can neither be\nstraightforwardly transferred to other domains nor generalize well, and\ncreating labeled training data for new domains is expensive and laborious. The\nneed for paraphrasing across different domains and the scarcity of labeled\ntraining data in many such domains call for exploring unsupervised paraphrase\ngeneration methods. We propose Progressive Unsupervised Paraphrasing (PUP): a\nnovel unsupervised paraphrase generation method based on deep reinforcement\nlearning (DRL). PUP uses a variational autoencoder (trained using a\nnon-parallel corpus) to generate a seed paraphrase that warm-starts the DRL\nmodel. Then, PUP progressively tunes the seed paraphrase guided by our novel\nreward function which combines semantic adequacy, language fluency, and\nexpression diversity measures to quantify the quality of the generated\nparaphrases in each iteration without needing parallel sentences. Our extensive\nexperimental evaluation shows that PUP outperforms unsupervised\nstate-of-the-art paraphrasing techniques in terms of both automatic metrics and\nuser studies on four real datasets. We also show that PUP outperforms\ndomain-adapted supervised algorithms on several datasets. Our evaluation also\nshows that PUP achieves a great trade-off between semantic similarity and\ndiversity of expression.\n", "versions": [{"version": "v1", "created": "Sun, 5 Jul 2020 05:54:02 GMT"}], "update_date": "2020-07-08", "authors_parsed": [["Siddique", "A. B.", ""], ["Oymak", "Samet", ""], ["Hristidis", "Vagelis", ""]]}, {"id": "2007.02352", "submitter": "Xinrui Liu", "authors": "Xinrui Liu", "title": "Mission schedule of agile satellites based on Proximal Policy\n  Optimization Algorithm", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mission schedule of satellites is an important part of space operation\nnowadays, since the number and types of satellites in orbit are increasing\ntremendously and their corresponding tasks are also becoming more and more\ncomplicated. In this paper, a mission schedule model combined with Proximal\nPolicy Optimization Algorithm(PPO) is proposed. Different from the traditional\nheuristic planning method, this paper incorporate reinforcement learning\nalgorithms into it and find a new way to describe the problem. Several\nconstraints including data download are considered in this paper.\n", "versions": [{"version": "v1", "created": "Sun, 5 Jul 2020 14:28:44 GMT"}], "update_date": "2020-07-07", "authors_parsed": [["Liu", "Xinrui", ""]]}, {"id": "2007.02416", "submitter": "Han Van Der Aa", "authors": "Han van der Aa, Henrik Leopold, Matthias Weidlich", "title": "Partial Order Resolution of Event Logs for Process Conformance Checking", "comments": "Accepted for publication in Decision Support Systems", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While supporting the execution of business processes, information systems\nrecord event logs. Conformance checking relies on these logs to analyze whether\nthe recorded behavior of a process conforms to the behavior of a normative\nspecification. A key assumption of existing conformance checking techniques,\nhowever, is that all events are associated with timestamps that allow to infer\na total order of events per process instance. Unfortunately, this assumption is\noften violated in practice. Due to synchronization issues, manual event\nrecordings, or data corruption, events are only partially ordered. In this\npaper, we put forward the problem of partial order resolution of event logs to\nclose this gap. It refers to the construction of a probability distribution\nover all possible total orders of events of an instance. To cope with the order\nuncertainty in real-world data, we present several estimators for this task,\nincorporating different notions of behavioral abstraction. Moreover, to reduce\nthe runtime of conformance checking based on partial order resolution, we\nintroduce an approximation method that comes with a bounded error in terms of\naccuracy. Our experiments with real-world and synthetic data reveal that our\napproach improves accuracy over the state-of-the-art considerably.\n", "versions": [{"version": "v1", "created": "Sun, 5 Jul 2020 18:43:57 GMT"}], "update_date": "2020-07-07", "authors_parsed": [["van der Aa", "Han", ""], ["Leopold", "Henrik", ""], ["Weidlich", "Matthias", ""]]}, {"id": "2007.02418", "submitter": "Zaheer Abbas", "authors": "Zaheer Abbas, Samuel Sokota, Erin J. Talvitie, Martha White", "title": "Selective Dyna-style Planning Under Limited Model Capacity", "comments": "Accepted at ICML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In model-based reinforcement learning, planning with an imperfect model of\nthe environment has the potential to harm learning progress. But even when a\nmodel is imperfect, it may still contain information that is useful for\nplanning. In this paper, we investigate the idea of using an imperfect model\nselectively. The agent should plan in parts of the state space where the model\nwould be helpful but refrain from using the model where it would be harmful. An\neffective selective planning mechanism requires estimating predictive\nuncertainty, which arises out of aleatoric uncertainty, parameter uncertainty,\nand model inadequacy, among other sources. Prior work has focused on parameter\nuncertainty for selective planning. In this work, we emphasize the importance\nof model inadequacy. We show that heteroscedastic regression can signal\npredictive uncertainty arising from model inadequacy that is complementary to\nthat which is detected by methods designed for parameter uncertainty,\nindicating that considering both parameter uncertainty and model inadequacy may\nbe a more promising direction for effective selective planning than either in\nisolation.\n", "versions": [{"version": "v1", "created": "Sun, 5 Jul 2020 18:51:50 GMT"}, {"version": "v2", "created": "Wed, 29 Jul 2020 22:32:28 GMT"}, {"version": "v3", "created": "Sun, 7 Mar 2021 21:52:28 GMT"}], "update_date": "2021-03-09", "authors_parsed": [["Abbas", "Zaheer", ""], ["Sokota", "Samuel", ""], ["Talvitie", "Erin J.", ""], ["White", "Martha", ""]]}, {"id": "2007.02472", "submitter": "Fang Liu", "authors": "Fang Liu, Wei-Guo Zhang", "title": "A modified axiomatic foundation of the analytic hierarchy process", "comments": "28 pages; 3 figures; submitted to a journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.AI math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper reports a modified axiomatic foundation of the analytic hierarchy\nprocess (AHP), where the reciprocal property of paired comparisons is broken.\nThe novel concept of reciprocal symmetry breaking is proposed to characterize\nthe considered situation without reciprocal property. It is found that the\nuncertainty experienced by the decision maker can be naturally incorporated\ninto the modified axioms. Some results are derived from the new axioms\ninvolving the new concept of approximate consistency and the method of\neliciting priorities. The phenomenon of ranking reversal is revisited from a\ntheoretical viewpoint under the modified axiomatic foundation. The situations\nwithout ranking reversal are addressed and called ranking equilibrium. The\nlikelihood of ranking reversal is captured by introducing a possibility degree\nindex based on the Kendall's coefficient of concordance. The modified axioms\nand the derived facts form a novel operational basis of the AHP choice model\nunder some uncertainty. The observations reveal that a more flexible expression\nof decision information could be accepted as compared to the judgments with\nreciprocal property.\n", "versions": [{"version": "v1", "created": "Mon, 6 Jul 2020 00:03:44 GMT"}], "update_date": "2020-07-07", "authors_parsed": [["Liu", "Fang", ""], ["Zhang", "Wei-Guo", ""]]}, {"id": "2007.02484", "submitter": "Florian Richter", "authors": "Florian Richter", "title": "Logic, Language, and Calculus", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The difference between object-language and metalanguage is crucial for\nlogical analysis, but has yet not been examined for the field of computer\nscience. In this paper the difference is examined with regard to inferential\nrelations. It is argued that inferential relations in a metalanguage (like a\ncalculus for propositional logic) cannot represent conceptual relations of\nnatural language. Inferential relations govern our concept use and\nunderstanding. Several approaches in the field of Natural Language\nUnderstanding (NLU) and Natural Language Inference (NLI) take this insight in\naccount, but do not consider, how an inference can be assessed as a good\ninference. I present a logical analysis that can assesss the normative\ndimension of inferences, which is a crucial part of logical understanding and\ngoes beyond formal understanding of metalanguages.\n", "versions": [{"version": "v1", "created": "Mon, 6 Jul 2020 00:52:54 GMT"}], "update_date": "2020-07-07", "authors_parsed": [["Richter", "Florian", ""]]}, {"id": "2007.02487", "submitter": "Florian Richter", "authors": "Florian Richter", "title": "Inferences and Modal Vocabulary", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deduction is the one of the major forms of inferences and commonly used in\nformal logic. This kind of inference has the feature of monotonicity, which can\nbe problematic. There are different types of inferences that are not monotonic,\ne.g. abductive inferences. The debate between advocates and critics of\nabduction as a useful instrument can be reconstructed along the issue, how an\nabductive inference warrants to pick out one hypothesis as the best one. But\nhow can the goodness of an inference be assessed? Material inferences express\ngood inferences based on the principle of material incompatibility. Material\ninferences are based on modal vocabulary, which enriches the logical\nexpressivity of the inferential relations. This leads also to certain limits in\nthe application of labeling in machine learning. I propose a modal\ninterpretation of implications to express conceptual relations.\n", "versions": [{"version": "v1", "created": "Mon, 6 Jul 2020 01:04:06 GMT"}], "update_date": "2020-07-07", "authors_parsed": [["Richter", "Florian", ""]]}, {"id": "2007.02489", "submitter": "Florian Richter", "authors": "Florian Richter", "title": "Space of Reasons and Mathematical Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inferential relations govern our concept use. In order to understand a\nconcept it has to be located in a space of implications. There are different\nkinds of conditions for statements, i.e. that the conditions represent\ndifferent kinds of explanations, e.g. causal or conceptual explanations. The\ncrucial questions is: How can the conditionality of language use be\nrepresented. The conceptual background of representation in models is discussed\nand in the end I propose how implications of propositional logic and conceptual\ndeterminations can be represented in a model of a neural network.\n", "versions": [{"version": "v1", "created": "Mon, 6 Jul 2020 01:13:43 GMT"}], "update_date": "2020-07-07", "authors_parsed": [["Richter", "Florian", ""]]}, {"id": "2007.02515", "submitter": "Tao Yang", "authors": "Tao Yang, Zhixiong Nan, He Zhang, Shitao Chen and Nanning Zheng", "title": "Traffic Agent Trajectory Prediction Using Social Convolution and\n  Attention Mechanism", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The trajectory prediction is significant for the decision-making of\nautonomous driving vehicles. In this paper, we propose a model to predict the\ntrajectories of target agents around an autonomous vehicle. The main idea of\nour method is considering the history trajectories of the target agent and the\ninfluence of surrounding agents on the target agent. To this end, we encode the\ntarget agent history trajectories as an attention mask and construct a social\nmap to encode the interactive relationship between the target agent and its\nsurrounding agents. Given a trajectory sequence, the LSTM networks are firstly\nutilized to extract the features for all agents, based on which the attention\nmask and social map are formed. Then, the attention mask and social map are\nfused to get the fusion feature map, which is processed by the social\nconvolution to obtain a fusion feature representation. Finally, this fusion\nfeature is taken as the input of a variable-length LSTM to predict the\ntrajectory of the target agent. We note that the variable-length LSTM enables\nour model to handle the case that the number of agents in the sensing scope is\nhighly dynamic in traffic scenes. To verify the effectiveness of our method, we\nwidely compare with several methods on a public dataset, achieving a 20% error\ndecrease. In addition, the model satisfies the real-time requirement with the\n32 fps.\n", "versions": [{"version": "v1", "created": "Mon, 6 Jul 2020 03:48:08 GMT"}], "update_date": "2020-07-08", "authors_parsed": [["Yang", "Tao", ""], ["Nan", "Zhixiong", ""], ["Zhang", "He", ""], ["Chen", "Shitao", ""], ["Zheng", "Nanning", ""]]}, {"id": "2007.02527", "submitter": "Thomas Ringstrom", "authors": "Thomas J. Ringstrom, Mohammadhosein Hasanbeig, Alessandro Abate", "title": "Jump Operator Planning: Goal-Conditioned Policy Ensembles and Zero-Shot\n  Transfer", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In Hierarchical Control, compositionality, abstraction, and task-transfer are\ncrucial for designing versatile algorithms which can solve a variety of\nproblems with maximal representational reuse. We propose a novel hierarchical\nand compositional framework called Jump-Operator Dynamic Programming for\nquickly computing solutions within a super-exponential space of sequential\nsub-goal tasks with ordering constraints, while also providing a fast\nlinearly-solvable algorithm as an implementation. This approach involves\ncontrolling over an ensemble of reusable goal-conditioned polices functioning\nas temporally extended actions, and utilizes transition operators called\nfeasibility functions, which are used to summarize initial-to-final state\ndynamics of the polices. Consequently, the added complexity of grounding a\nhigh-level task space onto a larger ambient state-space can be mitigated by\noptimizing in a lower-dimensional subspace defined by the grounding,\nsubstantially improving the scalability of the algorithm while effecting\ntransferable solutions. We then identify classes of objective functions on this\nsubspace whose solutions are invariant to the grounding, resulting in optimal\nzero-shot transfer.\n", "versions": [{"version": "v1", "created": "Mon, 6 Jul 2020 05:13:20 GMT"}], "update_date": "2020-07-07", "authors_parsed": [["Ringstrom", "Thomas J.", ""], ["Hasanbeig", "Mohammadhosein", ""], ["Abate", "Alessandro", ""]]}, {"id": "2007.02540", "submitter": "Shilei Liu", "authors": "Shilei Liu, Yu Guo, Bochao Li and Feiliang Ren", "title": "LMVE at SemEval-2020 Task 4: Commonsense Validation and Explanation\n  using Pretraining Language Model", "comments": "Accepted in SemEval2020. 7 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper describes our submission to subtask a and b of SemEval-2020 Task\n4. For subtask a, we use a ALBERT based model with improved input form to pick\nout the common sense statement from two statement candidates. For subtask b, we\nuse a multiple choice model enhanced by hint sentence mechanism to select the\nreason from given options about why a statement is against common sense.\nBesides, we propose a novel transfer learning strategy between subtasks which\nhelp improve the performance. The accuracy scores of our system are 95.6 / 94.9\non official test set and rank 7$^{th}$ / 2$^{nd}$ on Post-Evaluation\nleaderboard.\n", "versions": [{"version": "v1", "created": "Mon, 6 Jul 2020 05:51:10 GMT"}], "update_date": "2020-07-07", "authors_parsed": [["Liu", "Shilei", ""], ["Guo", "Yu", ""], ["Li", "Bochao", ""], ["Ren", "Feiliang", ""]]}, {"id": "2007.02559", "submitter": "Jesse Han", "authors": "Jesse Michael Han", "title": "Enhancing SAT solvers with glue variable predictions", "comments": "8 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern SAT solvers routinely operate at scales that make it impractical to\nquery a neural network for every branching decision. NeuroCore, proposed by\nSelsam and Bjorner, offered a proof-of-concept that neural networks can still\naccelerate SAT solvers by only periodically refocusing a score-based branching\nheuristic. However, that work suffered from several limitations: their modified\nsolvers require GPU acceleration, further ablations showed that they were no\nbetter than a random baseline on the SATCOMP 2018 benchmark, and their training\ntarget of unsat cores required an expensive data pipeline which only labels\nrelatively easy unsatisfiable problems. We address all these limitations, using\na simpler network architecture allowing CPU inference for even large industrial\nproblems with millions of clauses, and training instead to predict {\\em glue\nvariables}---a target for which it is easier to generate labelled data, and\nwhich can also be formulated as a reinforcement learning task. We demonstrate\nthe effectiveness of our approach by modifying the state-of-the-art SAT solver\nCaDiCaL, improving its performance on SATCOMP 2018 and SATRACE 2019 with\nsupervised learning and its performance on a dataset of SHA-1 preimage attacks\nwith reinforcement learning.\n", "versions": [{"version": "v1", "created": "Mon, 6 Jul 2020 07:16:49 GMT"}], "update_date": "2020-07-07", "authors_parsed": [["Han", "Jesse Michael", ""]]}, {"id": "2007.02622", "submitter": "Albert Bou", "authors": "Albert Bou and Gianni De Fabritiis", "title": "PyTorchRL: Modular and Distributed Reinforcement Learning in PyTorch", "comments": "8 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep reinforcement learning (RL) has proved successful at solving challenging\nenvironments but often requires scaling to large sampling and computing\nresources. Furthermore, advancing RL requires tools that are flexible enough to\neasily prototype new methods, yet avoiding impractically slow experimental\nturnaround times. To this end, we present PyTorchRL, a PyTorch-based library\nfor RL with a modular design that allows composing agents from a set of\nreusable and easily extendable modules. Additionally, PyTorchRL permits the\ndefinition of distributed training architectures with flexibility and\nindependence of the Agent components. In combination, these two features can\naccelerate the pace at which ideas are implemented and tested, simplifying\nresearch and enabling to tackle more challenging RL problems. We present\nseveral interesting use-cases of PyTorchRL and showcase the library by\nobtaining the highest to-date test performance on the Obstacle Tower Unity3D\nchallenge environment.\n", "versions": [{"version": "v1", "created": "Mon, 6 Jul 2020 10:22:07 GMT"}, {"version": "v2", "created": "Wed, 10 Feb 2021 16:39:37 GMT"}], "update_date": "2021-02-11", "authors_parsed": [["Bou", "Albert", ""], ["De Fabritiis", "Gianni", ""]]}, {"id": "2007.02629", "submitter": "Chao-Wei Huang", "authors": "Chao-Wei Huang and Yun-Nung Chen", "title": "Learning Spoken Language Representations with Neural Lattice Language\n  Modeling", "comments": "Published in ACL 2020 as a short paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Pre-trained language models have achieved huge improvement on many NLP tasks.\nHowever, these methods are usually designed for written text, so they do not\nconsider the properties of spoken language. Therefore, this paper aims at\ngeneralizing the idea of language model pre-training to lattices generated by\nrecognition systems. We propose a framework that trains neural lattice language\nmodels to provide contextualized representations for spoken language\nunderstanding tasks. The proposed two-stage pre-training approach reduces the\ndemands of speech data and has better efficiency. Experiments on intent\ndetection and dialogue act recognition datasets demonstrate that our proposed\nmethod consistently outperforms strong baselines when evaluated on spoken\ninputs. The code is available at https://github.com/MiuLab/Lattice-ELMo.\n", "versions": [{"version": "v1", "created": "Mon, 6 Jul 2020 10:38:03 GMT"}, {"version": "v2", "created": "Mon, 2 Nov 2020 06:53:56 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Huang", "Chao-Wei", ""], ["Chen", "Yun-Nung", ""]]}, {"id": "2007.02641", "submitter": "Javier Fumanal-Idocin Mr.", "authors": "J. Fumanal-Idocin, A. Alonso-Betanzos, O. Cord\\'on, H. Bustince,\n  M.Min\\'arov\\'a", "title": "Community detection and Social Network analysis based on the Italian\n  wars of the 15th century", "comments": "Corrections in: Revamped affinity section, conclusions and minor\n  changes in the introduction. Also, the dynamic delta section is expanded a\n  bit", "journal-ref": null, "doi": "10.1016/j.future.2020.06.030", "report-no": null, "categories": "cs.SI cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this contribution we study social network modelling by using human\ninteraction as a basis. To do so, we propose a new set of functions,\naffinities, designed to capture the nature of the local interactions among each\npair of actors in a network. By using these functions, we develop a new\ncommunity detection algorithm, the Borgia Clustering, where communities\nnaturally arise from the multi-agent interaction in the network. We also\ndiscuss the effects of size and scale for communities regarding this case, as\nwell as how we cope with the additional complexity present when big communities\narise. Finally, we compare our community detection solution with other\nrepresentative algorithms, finding favourable results.\n", "versions": [{"version": "v1", "created": "Mon, 6 Jul 2020 11:05:07 GMT"}, {"version": "v2", "created": "Tue, 7 Jul 2020 10:46:18 GMT"}], "update_date": "2020-07-08", "authors_parsed": [["Fumanal-Idocin", "J.", ""], ["Alonso-Betanzos", "A.", ""], ["Cord\u00f3n", "O.", ""], ["Bustince", "H.", ""], ["Min\u00e1rov\u00e1", "M.", ""]]}, {"id": "2007.02642", "submitter": "Sang-Woo Lee", "authors": "Sang-Woo Lee, Hyunhoon Jung, SukHyun Ko, Sunyoung Kim, Hyewon Kim,\n  Kyoungtae Doh, Hyunjung Park, Joseph Yeo, Sang-Houn Ok, Joonhaeng Lee,\n  Sungsoon Lim, Minyoung Jeong, Seongjae Choi, SeungTae Hwang, Eun-Young Park,\n  Gwang-Ja Ma, Seok-Joo Han, Kwang-Seung Cha, Nako Sung, Jung-Woo Ha", "title": "CareCall: a Call-Based Active Monitoring Dialog Agent for Managing\n  COVID-19 Pandemic", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tracking suspected cases of COVID-19 is crucial to suppressing the spread of\nCOVID-19 pandemic. Active monitoring and proactive inspection are indispensable\nto mitigate COVID-19 spread, though these require considerable social and\neconomic expense. To address this issue, we introduce CareCall, a call-based\ndialog agent which is deployed for active monitoring in Korea and Japan. We\ndescribe our system with a case study with statistics to show how the system\nworks. Finally, we discuss a simple idea which uses CareCall to support\nproactive inspection.\n", "versions": [{"version": "v1", "created": "Mon, 6 Jul 2020 11:05:22 GMT"}, {"version": "v2", "created": "Tue, 25 Aug 2020 09:21:08 GMT"}], "update_date": "2020-08-26", "authors_parsed": [["Lee", "Sang-Woo", ""], ["Jung", "Hyunhoon", ""], ["Ko", "SukHyun", ""], ["Kim", "Sunyoung", ""], ["Kim", "Hyewon", ""], ["Doh", "Kyoungtae", ""], ["Park", "Hyunjung", ""], ["Yeo", "Joseph", ""], ["Ok", "Sang-Houn", ""], ["Lee", "Joonhaeng", ""], ["Lim", "Sungsoon", ""], ["Jeong", "Minyoung", ""], ["Choi", "Seongjae", ""], ["Hwang", "SeungTae", ""], ["Park", "Eun-Young", ""], ["Ma", "Gwang-Ja", ""], ["Han", "Seok-Joo", ""], ["Cha", "Kwang-Seung", ""], ["Sung", "Nako", ""], ["Ha", "Jung-Woo", ""]]}, {"id": "2007.02669", "submitter": "Jean Christoph Jung", "authors": "Jean Christoph Jung, Carsten Lutz, Hadrien Pulcini, Frank Wolter", "title": "Separating Positive and Negative Data Examples by Concepts and Formulas:\n  The Case of Restricted Signatures", "comments": "35 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the separation of positive and negative data examples in terms of\ndescription logic (DL) concepts and formulas of decidable FO fragments, in the\npresence of an ontology. In contrast to previous work, we add a signature that\nspecifies a subset of the symbols from the data and ontology that can be used\nfor separation. We consider weak and strong versions of the resulting problem\nthat differ in how the negative examples are treated. Our main results are that\n(a projective form of) the weak version is decidable in $\\mathcal{ALCI}$ while\nit is undecidable in the guarded fragment GF, the guarded negation fragment\nGNF, and the DL $\\mathcal{ALCFIO}$, and that strong separability is decidable\nin $\\mathcal{ALCI}$, GF, and GNF. We also provide (mostly tight) complexity\nbounds.\n", "versions": [{"version": "v1", "created": "Mon, 6 Jul 2020 11:58:02 GMT"}], "update_date": "2020-07-07", "authors_parsed": [["Jung", "Jean Christoph", ""], ["Lutz", "Carsten", ""], ["Pulcini", "Hadrien", ""], ["Wolter", "Frank", ""]]}, {"id": "2007.02701", "submitter": "Artemij Amiranashvili", "authors": "Artemij Amiranashvili, Nicolai Dorka, Wolfram Burgard, Vladlen Koltun,\n  Thomas Brox", "title": "Scaling Imitation Learning in Minecraft", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Imitation learning is a powerful family of techniques for learning\nsensorimotor coordination in immersive environments. We apply imitation\nlearning to attain state-of-the-art performance on hard exploration problems in\nthe Minecraft environment. We report experiments that highlight the influence\nof network architecture, loss function, and data augmentation. An early version\nof our approach reached second place in the MineRL competition at NeurIPS 2019.\nHere we report stronger results that can be used as a starting point for future\ncompetition entries and related research. Our code is available at\nhttps://github.com/amiranas/minerl_imitation_learning.\n", "versions": [{"version": "v1", "created": "Mon, 6 Jul 2020 12:47:01 GMT"}], "update_date": "2020-07-07", "authors_parsed": [["Amiranashvili", "Artemij", ""], ["Dorka", "Nicolai", ""], ["Burgard", "Wolfram", ""], ["Koltun", "Vladlen", ""], ["Brox", "Thomas", ""]]}, {"id": "2007.02728", "submitter": "HMN Dilum Bandara", "authors": "Sandareka Wickramanayake, H.M.N Dilum Bandara, Nishal A. Samarasekara", "title": "Real-Time Monitoring and Driver Feedback to Promote Fuel Efficient\n  Driving", "comments": "17 pages, 9 figures, and 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Improving the fuel efficiency of vehicles is imperative to reduce costs and\nprotect the environment. While the efficient engine and vehicle designs, as\nwell as intelligent route planning, are well-known solutions to enhance the\nfuel efficiency, research has also demonstrated that the adoption of\nfuel-efficient driving behaviors could lead to further savings. In this work,\nwe propose a novel framework to promote fuel-efficient driving behaviors\nthrough real-time automatic monitoring and driver feedback. In this framework,\na random-forest based classification model developed using historical data to\nidentifies fuel-inefficient driving behaviors. The classifier considers\ndriver-dependent parameters such as speed and acceleration/deceleration\npattern, as well as environmental parameters such as traffic, road topography,\nand weather to evaluate the fuel efficiency of one-minute driving events. When\nan inefficient driving action is detected, a fuzzy logic inference system is\nused to determine what the driver should do to maintain fuel-efficient driving\nbehavior. The decided action is then conveyed to the driver via a smartphone in\na non-intrusive manner. Using a dataset from a long-distance bus, we\ndemonstrate that the proposed classification model yields an accuracy of 85.2%\nwhile increasing the fuel efficiency up to 16.4%.\n", "versions": [{"version": "v1", "created": "Fri, 3 Jul 2020 09:23:53 GMT"}], "update_date": "2020-07-07", "authors_parsed": [["Wickramanayake", "Sandareka", ""], ["Bandara", "H. M. N Dilum", ""], ["Samarasekara", "Nishal A.", ""]]}, {"id": "2007.02742", "submitter": "Vanessa Volz", "authors": "Vanessa Volz and Boris Naujoks", "title": "Towards Game-Playing AI Benchmarks via Performance Reporting Standards", "comments": "IEEE Conference on Games 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While games have been used extensively as milestones to evaluate game-playing\nAI, there exists no standardised framework for reporting the obtained\nobservations. As a result, it remains difficult to draw general conclusions\nabout the strengths and weaknesses of different game-playing AI algorithms. In\nthis paper, we propose reporting guidelines for AI game-playing performance\nthat, if followed, provide information suitable for unbiased comparisons\nbetween different AI approaches. The vision we describe is to build benchmarks\nand competitions based on such guidelines in order to be able to draw more\ngeneral conclusions about the behaviour of different AI algorithms, as well as\nthe types of challenges different games pose.\n", "versions": [{"version": "v1", "created": "Mon, 6 Jul 2020 13:27:00 GMT"}], "update_date": "2020-07-07", "authors_parsed": [["Volz", "Vanessa", ""], ["Naujoks", "Boris", ""]]}, {"id": "2007.02753", "submitter": "Matteo Lucchi", "authors": "Matteo Lucchi, Friedemann Zindler, Stephan M\\\"uhlbacher-Karrer, Horst\n  Pichler", "title": "robo-gym -- An Open Source Toolkit for Distributed Deep Reinforcement\n  Learning on Real and Simulated Robots", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.DC cs.LG cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Applying Deep Reinforcement Learning (DRL) to complex tasks in the field of\nrobotics has proven to be very successful in the recent years. However, most of\nthe publications focus either on applying it to a task in simulation or to a\ntask in a real world setup. Although there are great examples of combining the\ntwo worlds with the help of transfer learning, it often requires a lot of\nadditional work and fine-tuning to make the setup work effectively. In order to\nincrease the use of DRL with real robots and reduce the gap between simulation\nand real world robotics, we propose an open source toolkit: robo-gym. We\ndemonstrate a unified setup for simulation and real environments which enables\na seamless transfer from training in simulation to application on the robot. We\nshowcase the capabilities and the effectiveness of the framework with two real\nworld applications featuring industrial robots: a mobile robot and a robot arm.\nThe distributed capabilities of the framework enable several advantages like\nusing distributed algorithms, separating the workload of simulation and\ntraining on different physical machines as well as enabling the future\nopportunity to train in simulation and real world at the same time. Finally we\noffer an overview and comparison of robo-gym with other frequently used\nstate-of-the-art DRL frameworks.\n", "versions": [{"version": "v1", "created": "Mon, 6 Jul 2020 13:51:33 GMT"}, {"version": "v2", "created": "Mon, 16 Nov 2020 17:00:34 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Lucchi", "Matteo", ""], ["Zindler", "Friedemann", ""], ["M\u00fchlbacher-Karrer", "Stephan", ""], ["Pichler", "Horst", ""]]}, {"id": "2007.02787", "submitter": "Vincenzo Riccio", "authors": "Vincenzo Riccio and Paolo Tonella", "title": "Model-based Exploration of the Frontier of Behaviours for Deep Learning\n  System Testing", "comments": "To be published in the Proceedings of the ACM Joint European Software\n  Engineering Conference and Symposium on the Foundations of Software\n  Engineering (ESEC/FSE 2020); 13 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  With the increasing adoption of Deep Learning (DL) for critical tasks, such\nas autonomous driving, the evaluation of the quality of systems that rely on DL\nhas become crucial. Once trained, DL systems produce an output for any\narbitrary numeric vector provided as input, regardless of whether it is within\nor outside the validity domain of the system under test. Hence, the quality of\nsuch systems is determined by the intersection between their validity domain\nand the regions where their outputs exhibit a misbehaviour. In this paper, we\nintroduce the notion of frontier of behaviours, i.e., the inputs at which the\nDL system starts to misbehave. If the frontier of misbehaviours is outside the\nvalidity domain of the system, the quality check is passed. Otherwise, the\ninputs at the intersection represent quality deficiencies of the system. We\ndeveloped DeepJanus, a search-based tool that generates frontier inputs for DL\nsystems. The experimental results obtained for the lane keeping component of a\nself-driving car show that the frontier of a well trained system contains\nalmost exclusively unrealistic roads that violate the best practices of civil\nengineering, while the frontier of a poorly trained one includes many valid\ninputs that point to serious deficiencies of the system.\n", "versions": [{"version": "v1", "created": "Mon, 6 Jul 2020 14:42:11 GMT"}], "update_date": "2020-07-07", "authors_parsed": [["Riccio", "Vincenzo", ""], ["Tonella", "Paolo", ""]]}, {"id": "2007.02823", "submitter": "Evan Piermont", "authors": "Joseph Y. Halpern and Evan Piermont", "title": "Dynamic Awareness", "comments": "To appear in the 17th International Conference on Principles of\n  Knowledge Representation and Reasoning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO econ.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate how to model the beliefs of an agent who becomes more aware.\nWe use the framework of Halpern and Rego (2013) by adding probability, and\ndefine a notion of a model transition that describes constraints on how, if an\nagent becomes aware of a new formula $\\phi$ in state $s$ of a model $M$, she\ntransitions to state $s^*$ in a model $M^*$. We then discuss how such a model\ncan be applied to information disclosure.\n", "versions": [{"version": "v1", "created": "Mon, 6 Jul 2020 15:28:22 GMT"}], "update_date": "2020-07-07", "authors_parsed": [["Halpern", "Joseph Y.", ""], ["Piermont", "Evan", ""]]}, {"id": "2007.02829", "submitter": "Ronald Seoh", "authors": "Ronald Seoh", "title": "Solving Bayesian Network Structure Learning Problem with Integer Linear\n  Programming", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  This dissertation investigates integer linear programming (ILP) formulation\nof Bayesian Network structure learning problem. We review the definition and\nkey properties of Bayesian network and explain score metrics used to measure\nhow well certain Bayesian network structure fits the dataset. We outline the\ninteger linear programming formulation based on the decomposability of score\nmetrics. In order to ensure acyclicity of the structure, we add ``cluster\nconstraints'' developed specifically for Bayesian network, in addition to cycle\nconstraints applicable to directed acyclic graphs in general. Since there would\nbe exponential number of these constraints if we specify them fully, we explain\nthe methods to add them as cutting planes without declaring them all in the\ninitial model. Also, we develop a heuristic algorithm that finds a feasible\nsolution based on the idea of sink node on directed acyclic graphs. We\nimplemented the ILP formulation and cutting planes as a \\textsf{Python}\npackage, and present the results of experiments with different settings on\nreference datasets.\n", "versions": [{"version": "v1", "created": "Mon, 6 Jul 2020 15:34:03 GMT"}], "update_date": "2020-07-07", "authors_parsed": [["Seoh", "Ronald", ""]]}, {"id": "2007.02832", "submitter": "Silviu Pitis", "authors": "Silviu Pitis, Harris Chan, Stephen Zhao, Bradly Stadie, Jimmy Ba", "title": "Maximum Entropy Gain Exploration for Long Horizon Multi-goal\n  Reinforcement Learning", "comments": "12 pages (+12 appendix). Published as a conference paper at ICML\n  2020. Code available at https://github.com/spitis/mrl", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  What goals should a multi-goal reinforcement learning agent pursue during\ntraining in long-horizon tasks? When the desired (test time) goal distribution\nis too distant to offer a useful learning signal, we argue that the agent\nshould not pursue unobtainable goals. Instead, it should set its own intrinsic\ngoals that maximize the entropy of the historical achieved goal distribution.\nWe propose to optimize this objective by having the agent pursue past achieved\ngoals in sparsely explored areas of the goal space, which focuses exploration\non the frontier of the achievable goal set. We show that our strategy achieves\nan order of magnitude better sample efficiency than the prior state of the art\non long-horizon multi-goal tasks including maze navigation and block stacking.\n", "versions": [{"version": "v1", "created": "Mon, 6 Jul 2020 15:36:05 GMT"}], "update_date": "2020-07-07", "authors_parsed": [["Pitis", "Silviu", ""], ["Chan", "Harris", ""], ["Zhao", "Stephen", ""], ["Stadie", "Bradly", ""], ["Ba", "Jimmy", ""]]}, {"id": "2007.02854", "submitter": "Noor Akhmad Setiawan PhD", "authors": "Noor Akhmad Setiawan, Paruvachi Ammasai Venkatachalam, Ahmad Fadzil M\n  Hani", "title": "Diagnosis of Coronary Artery Disease Using Artificial Intelligence Based\n  Decision Support System", "comments": null, "journal-ref": "Proceedings of the International Conference on Man Machine Systems\n  Batu Ferringhi Penang October 2009", "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This research is about the development a fuzzy decision support system for\nthe diagnosis of coronary artery disease based on evidence. The coronary artery\ndisease data sets taken from University California Irvine (UCI) are used. The\nknowledge base of fuzzy decision support system is taken by using rules\nextraction method based on Rough Set Theory. The rules then are selected and\nfuzzified based on information from discretization of numerical attributes.\nFuzzy rules weight is proposed using the information from support of extracted\nrules. UCI heart disease data sets collected from U.S., Switzerland and\nHungary, data from Ipoh Specialist Hospital Malaysia are used to verify the\nproposed system. The results show that the system is able to give the\npercentage of coronary artery blocking better than cardiologists and\nangiography. The results of the proposed system were verified and validated by\nthree expert cardiologists and are considered to be more efficient and useful.\n", "versions": [{"version": "v1", "created": "Mon, 6 Jul 2020 16:10:13 GMT"}], "update_date": "2020-07-07", "authors_parsed": [["Setiawan", "Noor Akhmad", ""], ["Venkatachalam", "Paruvachi Ammasai", ""], ["Hani", "Ahmad Fadzil M", ""]]}, {"id": "2007.02863", "submitter": "Silviu Pitis", "authors": "Silviu Pitis, Elliot Creager, Animesh Garg", "title": "Counterfactual Data Augmentation using Locally Factored Dynamics", "comments": "In Proceedings of NeurIPS 2020. 10 pages (+5 references, +12\n  appendix). Code available at \\url{https://github.com/spitis/mrl}", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many dynamic processes, including common scenarios in robotic control and\nreinforcement learning (RL), involve a set of interacting subprocesses. Though\nthe subprocesses are not independent, their interactions are often sparse, and\nthe dynamics at any given time step can often be decomposed into locally\nindependent causal mechanisms. Such local causal structures can be leveraged to\nimprove the sample efficiency of sequence prediction and off-policy\nreinforcement learning. We formalize this by introducing local causal models\n(LCMs), which are induced from a global causal model by conditioning on a\nsubset of the state space. We propose an approach to inferring these structures\ngiven an object-oriented state representation, as well as a novel algorithm for\nCounterfactual Data Augmentation (CoDA). CoDA uses local structures and an\nexperience replay to generate counterfactual experiences that are causally\nvalid in the global model. We find that CoDA significantly improves the\nperformance of RL agents in locally factored tasks, including the\nbatch-constrained and goal-conditioned settings.\n", "versions": [{"version": "v1", "created": "Mon, 6 Jul 2020 16:29:00 GMT"}, {"version": "v2", "created": "Thu, 3 Dec 2020 23:50:13 GMT"}], "update_date": "2020-12-07", "authors_parsed": [["Pitis", "Silviu", ""], ["Creager", "Elliot", ""], ["Garg", "Animesh", ""]]}, {"id": "2007.02874", "submitter": "Matthew Deardorff", "authors": "Derek Anderson, Matthew Deardorff, Timothy Havens, Siva Kakula,\n  Timothy Wilkin, Muhammad Islam, Anthony Pinar, and Andrew Buck", "title": "Fuzzy Integral = Contextual Linear Order Statistic", "comments": "11 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The fuzzy integral is a powerful parametric nonlin-ear function with utility\nin a wide range of applications, from information fusion to classification,\nregression, decision making,interpolation, metrics, morphology, and beyond.\nWhile the fuzzy integral is in general a nonlinear operator, herein we show\nthat it can be represented by a set of contextual linear order statistics(LOS).\nThese operators can be obtained via sampling the fuzzy measure and clustering\nis used to produce a partitioning of the underlying space of linear convex\nsums. Benefits of our approach include scalability, improved integral/measure\nacquisition, generalizability, and explainable/interpretable models. Our\nmethods are both demonstrated on controlled synthetic experiments, and also\nanalyzed and validated with real-world benchmark data sets.\n", "versions": [{"version": "v1", "created": "Mon, 6 Jul 2020 16:37:36 GMT"}, {"version": "v2", "created": "Tue, 20 Oct 2020 18:45:49 GMT"}], "update_date": "2020-10-22", "authors_parsed": [["Anderson", "Derek", ""], ["Deardorff", "Matthew", ""], ["Havens", "Timothy", ""], ["Kakula", "Siva", ""], ["Wilkin", "Timothy", ""], ["Islam", "Muhammad", ""], ["Pinar", "Anthony", ""], ["Buck", "Andrew", ""]]}, {"id": "2007.02879", "submitter": "Roberta Raileanu", "authors": "Roberta Raileanu, Max Goldstein, Arthur Szlam, Rob Fergus", "title": "Fast Adaptation via Policy-Dynamics Value Functions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Standard RL algorithms assume fixed environment dynamics and require a\nsignificant amount of interaction to adapt to new environments. We introduce\nPolicy-Dynamics Value Functions (PD-VF), a novel approach for rapidly adapting\nto dynamics different from those previously seen in training. PD-VF explicitly\nestimates the cumulative reward in a space of policies and environments. An\nensemble of conventional RL policies is used to gather experience on training\nenvironments, from which embeddings of both policies and environments can be\nlearned. Then, a value function conditioned on both embeddings is trained. At\ntest time, a few actions are sufficient to infer the environment embedding,\nenabling a policy to be selected by maximizing the learned value function\n(which requires no additional environment interaction). We show that our method\ncan rapidly adapt to new dynamics on a set of MuJoCo domains. Code available at\nhttps://github.com/rraileanu/policy-dynamics-value-functions.\n", "versions": [{"version": "v1", "created": "Mon, 6 Jul 2020 16:47:56 GMT"}], "update_date": "2020-07-07", "authors_parsed": [["Raileanu", "Roberta", ""], ["Goldstein", "Max", ""], ["Szlam", "Arthur", ""], ["Fergus", "Rob", ""]]}, {"id": "2007.02890", "submitter": "Robert Long", "authors": "Robert Long", "title": "Fairness in machine learning: against false positive rate equality as a\n  measure of fairness", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As machine learning informs increasingly consequential decisions, different\nmetrics have been proposed for measuring algorithmic bias or unfairness. Two\npopular fairness measures are calibration and equality of false positive rate.\nEach measure seems intuitively important, but notably, it is usually impossible\nto satisfy both measures. For this reason, a large literature in machine\nlearning speaks of a fairness tradeoff between these two measures. This framing\nassumes that both measures are, in fact, capturing something important. To\ndate, philosophers have not examined this crucial assumption, and examined to\nwhat extent each measure actually tracks a normatively important property. This\nmakes this inevitable statistical conflict, between calibration and false\npositive rate equality, an important topic for ethics. In this paper, I give an\nethical framework for thinking about these measures and argue that, contrary to\ninitial appearances, false positive rate equality does not track anything about\nfairness, and thus sets an incoherent standard for evaluating the fairness of\nalgorithms.\n", "versions": [{"version": "v1", "created": "Mon, 6 Jul 2020 17:03:58 GMT"}], "update_date": "2020-07-07", "authors_parsed": [["Long", "Robert", ""]]}, {"id": "2007.02924", "submitter": "Albert Qiaochu Jiang", "authors": "Yuhuai Wu, Albert Qiaochu Jiang, Jimmy Ba, Roger Grosse", "title": "INT: An Inequality Benchmark for Evaluating Generalization in Theorem\n  Proving", "comments": "Published as a conference paper at ICLR 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.LO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In learning-assisted theorem proving, one of the most critical challenges is\nto generalize to theorems unlike those seen at training time. In this paper, we\nintroduce INT, an INequality Theorem proving benchmark, specifically designed\nto test agents' generalization ability. INT is based on a procedure for\ngenerating theorems and proofs; this procedure's knobs allow us to measure 6\ndifferent types of generalization, each reflecting a distinct challenge\ncharacteristic to automated theorem proving. In addition, unlike prior\nbenchmarks for learning-assisted theorem proving, INT provides a lightweight\nand user-friendly theorem proving environment with fast simulations, conducive\nto performing learning-based and search-based research. We introduce\nlearning-based baselines and evaluate them across 6 dimensions of\ngeneralization with the benchmark. We then evaluate the same agents augmented\nwith Monte Carlo Tree Search (MCTS) at test time, and show that MCTS can help\nto prove new theorems.\n", "versions": [{"version": "v1", "created": "Mon, 6 Jul 2020 17:55:33 GMT"}, {"version": "v2", "created": "Sat, 3 Apr 2021 16:21:59 GMT"}], "update_date": "2021-04-06", "authors_parsed": [["Wu", "Yuhuai", ""], ["Jiang", "Albert Qiaochu", ""], ["Ba", "Jimmy", ""], ["Grosse", "Roger", ""]]}, {"id": "2007.03102", "submitter": "Ankur Deka", "authors": "Ankur Deka and Katia Sycara", "title": "Natural Emergence of Heterogeneous Strategies in Artificially\n  Intelligent Competitive Teams", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi agent strategies in mixed cooperative-competitive environments can be\nhard to craft by hand because each agent needs to coordinate with its teammates\nwhile competing with its opponents. Learning based algorithms are appealing but\nmany scenarios require heterogeneous agent behavior for the team's success and\nthis increases the complexity of the learning algorithm. In this work, we\ndevelop a competitive multi agent environment called FortAttack in which two\nteams compete against each other. We corroborate that modeling agents with\nGraph Neural Networks and training them with Reinforcement Learning leads to\nthe evolution of increasingly complex strategies for each team. We observe a\nnatural emergence of heterogeneous behavior amongst homogeneous agents when\nsuch behavior can lead to the team's success. Such heterogeneous behavior from\nhomogeneous agents is appealing because any agent can replace the role of\nanother agent at test time. Finally, we propose ensemble training, in which we\nutilize the evolved opponent strategies to train a single policy for friendly\nagents.\n", "versions": [{"version": "v1", "created": "Mon, 6 Jul 2020 22:35:56 GMT"}], "update_date": "2020-07-08", "authors_parsed": [["Deka", "Ankur", ""], ["Sycara", "Katia", ""]]}, {"id": "2007.03132", "submitter": "Tuan Anh Le", "authors": "Luke B. Hewitt and Tuan Anh Le and Joshua B. Tenenbaum", "title": "Learning to learn generative programs with Memoised Wake-Sleep", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study a class of neuro-symbolic generative models in which neural networks\nare used both for inference and as priors over symbolic, data-generating\nprograms. As generative models, these programs capture compositional structures\nin a naturally explainable form. To tackle the challenge of performing program\ninduction as an 'inner-loop' to learning, we propose the Memoised Wake-Sleep\n(MWS) algorithm, which extends Wake Sleep by explicitly storing and reusing the\nbest programs discovered by the inference network throughout training. We use\nMWS to learn accurate, explainable models in three challenging domains:\nstroke-based character modelling, cellular automata, and few-shot learning in a\nnovel dataset of real-world string concepts.\n", "versions": [{"version": "v1", "created": "Mon, 6 Jul 2020 23:51:03 GMT"}, {"version": "v2", "created": "Wed, 22 Jul 2020 22:36:04 GMT"}], "update_date": "2020-07-24", "authors_parsed": [["Hewitt", "Luke B.", ""], ["Le", "Tuan Anh", ""], ["Tenenbaum", "Joshua B.", ""]]}, {"id": "2007.03158", "submitter": "Harm van Seijen", "authors": "Harm van Seijen and Hadi Nekoei and Evan Racah and Sarath Chandar", "title": "The LoCA Regret: A Consistent Metric to Evaluate Model-Based Behavior in\n  Reinforcement Learning", "comments": "NeurIPS 2020, code: https://github.com/chandar-lab/LoCA", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep model-based Reinforcement Learning (RL) has the potential to\nsubstantially improve the sample-efficiency of deep RL. While various\nchallenges have long held it back, a number of papers have recently come out\nreporting success with deep model-based methods. This is a great development,\nbut the lack of a consistent metric to evaluate such methods makes it difficult\nto compare various approaches. For example, the common single-task\nsample-efficiency metric conflates improvements due to model-based learning\nwith various other aspects, such as representation learning, making it\ndifficult to assess true progress on model-based RL. To address this, we\nintroduce an experimental setup to evaluate model-based behavior of RL methods,\ninspired by work from neuroscience on detecting model-based behavior in humans\nand animals. Our metric based on this setup, the Local Change Adaptation (LoCA)\nregret, measures how quickly an RL method adapts to a local change in the\nenvironment. Our metric can identify model-based behavior, even if the method\nuses a poor representation and provides insight in how close a method's\nbehavior is from optimal model-based behavior. We use our setup to evaluate the\nmodel-based behavior of MuZero on a variation of the classic Mountain Car task.\n", "versions": [{"version": "v1", "created": "Tue, 7 Jul 2020 01:34:55 GMT"}, {"version": "v2", "created": "Thu, 3 Dec 2020 12:18:07 GMT"}], "update_date": "2020-12-04", "authors_parsed": [["van Seijen", "Harm", ""], ["Nekoei", "Hadi", ""], ["Racah", "Evan", ""], ["Chandar", "Sarath", ""]]}, {"id": "2007.03184", "submitter": "Yang Fang", "authors": "Yang Fang, Xiang Zhao, Yifan Chen, Weidong Xiao, Maarten de Rijke", "title": "Pre-Trained Models for Heterogeneous Information Networks", "comments": "Submitted to TKDE", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In network representation learning we learn how to represent heterogeneous\ninformation networks in a low-dimensional space so as to facilitate effective\nsearch, classification, and prediction solutions. Previous network\nrepresentation learning methods typically require sufficient task-specific\nlabeled data to address domain-specific problems. The trained model usually\ncannot be transferred to out-of-domain datasets. We propose a self-supervised\npre-training and fine-tuning framework, PF-HIN, to capture the features of a\nheterogeneous information network. Unlike traditional network representation\nlearning models that have to train the entire model all over again for every\ndownstream task and dataset, PF-HIN only needs to fine-tune the model and a\nsmall number of extra task-specific parameters, thus improving model efficiency\nand effectiveness. During pre-training, we first transform the neighborhood of\na given node into a sequence. PF-HIN is pre-trained based on two\nself-supervised tasks, masked node modeling and adjacent node prediction. We\nadopt deep bi-directional transformer encoders to train the model, and leverage\nfactorized embedding parameterization and cross-layer parameter sharing to\nreduce the parameters. In the fine-tuning stage, we choose four benchmark\ndownstream tasks, i.e., link prediction, similarity search, node\nclassification, and node clustering. PF-HIN consistently and significantly\noutperforms state-of-the-art alternatives on each of these tasks, on four\ndatasets.\n", "versions": [{"version": "v1", "created": "Tue, 7 Jul 2020 03:36:28 GMT"}, {"version": "v2", "created": "Tue, 18 May 2021 09:53:57 GMT"}], "update_date": "2021-05-19", "authors_parsed": [["Fang", "Yang", ""], ["Zhao", "Xiang", ""], ["Chen", "Yifan", ""], ["Xiao", "Weidong", ""], ["de Rijke", "Maarten", ""]]}, {"id": "2007.03191", "submitter": "Ke Ren", "authors": "Hoda Bidkhori, John P Dickerson, Duncan C McElfresh, Ke Ren", "title": "Kidney Exchange with Inhomogeneous Edge Existence Uncertainty", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by kidney exchange, we study a stochastic cycle and chain packing\nproblem, where we aim to identify structures in a directed graph to maximize\nthe expectation of matched edge weights. All edges are subject to failure, and\nthe failures can have nonidentical probabilities. To the best of our knowledge,\nthe state-of-the-art approaches are only tractable when failure probabilities\nare identical. We formulate a relevant non-convex optimization problem and\npropose a tractable mixed-integer linear programming reformulation to solve it.\nIn addition, we propose a model that integrates both risks and the expected\nutilities of the matching by incorporating conditional value at risk (CVaR)\ninto the objective function, providing a robust formulation for this problem.\nSubsequently, we propose a sample-average-approximation (SAA) based approach to\nsolve this problem. We test our approaches on data from the United Network for\nOrgan Sharing (UNOS) and compare against state-of-the-art approaches. Our model\nprovides better performance with the same running time as a leading\ndeterministic approach (PICEF). Our CVaR extensions with an SAA-based method\nimproves the $\\alpha \\times 100\\%$ ($0<\\alpha\\leqslant 1$) worst-case\nperformance substantially compared to existing models.\n", "versions": [{"version": "v1", "created": "Tue, 7 Jul 2020 04:08:39 GMT"}], "update_date": "2020-07-08", "authors_parsed": [["Bidkhori", "Hoda", ""], ["Dickerson", "John P", ""], ["McElfresh", "Duncan C", ""], ["Ren", "Ke", ""]]}, {"id": "2007.03203", "submitter": "Yuwen Yang", "authors": "Yuwen Yang, Jayant Rajgopal", "title": "Learning Combined Set Covering and Traveling Salesman Problem", "comments": "38 pages, 1 figure, 5 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Traveling Salesman Problem is one of the most intensively studied\ncombinatorial optimization problems due both to its range of real-world\napplications and its computational complexity. When combined with the Set\nCovering Problem, it raises even more issues related to tractability and\nscalability. We study a combined Set Covering and Traveling Salesman problem\nand provide a mixed integer programming formulation to solve the problem.\nMotivated by applications where the optimal policy needs to be updated on a\nregular basis and repetitively solving this via MIP can be computationally\nexpensive, we propose a machine learning approach to effectively deal with this\nproblem by providing an opportunity to learn from historical optimal solutions\nthat are derived from the MIP formulation. We also present a case study using\nthe vaccine distribution chain of the World Health Organization, and provide\nnumerical results with data derived from four countries in sub-Saharan Africa.\n", "versions": [{"version": "v1", "created": "Tue, 7 Jul 2020 05:11:28 GMT"}], "update_date": "2020-07-08", "authors_parsed": [["Yang", "Yuwen", ""], ["Rajgopal", "Jayant", ""]]}, {"id": "2007.03204", "submitter": "Pashootan Vaezipoor", "authors": "Pashootan Vaezipoor, Gil Lederman, Yuhuai Wu, Chris J. Maddison, Roger\n  Grosse, Edward Lee, Sanjit A. Seshia, Fahiem Bacchus", "title": "Learning Branching Heuristics for Propositional Model Counting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.LO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Propositional model counting or #SAT is the problem of computing the number\nof satisfying assignments of a Boolean formula and many discrete probabilistic\ninference problems can be translated into a model counting problem to be solved\nby #SAT solvers. Generic ``exact'' #SAT solvers, however, are often not\nscalable to industrial-level instances. In this paper, we present Neuro#, an\napproach for learning branching heuristics for exact #SAT solvers via evolution\nstrategies (ES) to reduce the number of branching steps the solver takes to\nsolve an instance. We experimentally show that our approach not only reduces\nthe step count on similarly distributed held-out instances but it also\ngeneralizes to much larger instances from the same problem family. The gap\nbetween the learned and the vanilla solver on larger instances is sometimes so\nwide that the learned solver can even overcome the run time overhead of\nquerying the model and beat the vanilla in wall-clock time by orders of\nmagnitude.\n", "versions": [{"version": "v1", "created": "Tue, 7 Jul 2020 05:20:29 GMT"}], "update_date": "2020-07-09", "authors_parsed": [["Vaezipoor", "Pashootan", ""], ["Lederman", "Gil", ""], ["Wu", "Yuhuai", ""], ["Maddison", "Chris J.", ""], ["Grosse", "Roger", ""], ["Lee", "Edward", ""], ["Seshia", "Sanjit A.", ""], ["Bacchus", "Fahiem", ""]]}, {"id": "2007.03248", "submitter": "Alessandro Bregoli", "authors": "Alessandro Bregoli, Marco Scutari, Fabio Stella", "title": "A Constraint-Based Algorithm for the Structural Learning of\n  Continuous-Time Bayesian Networks", "comments": null, "journal-ref": "Proceedings of Machine Learning Research (138, PGM 2020), 41-52", "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dynamic Bayesian networks have been well explored in the literature as\ndiscrete-time models: however, their continuous-time extensions have seen\ncomparatively little attention. In this paper, we propose the first\nconstraint-based algorithm for learning the structure of continuous-time\nBayesian networks. We discuss the different statistical tests and the\nunderlying hypotheses used by our proposal to establish conditional\nindependence. Furthermore, we analyze and discuss the computational complexity\nof the best and worst cases for the proposed algorithm. Finally, we validate\nits performance using synthetic data, and we discuss its strengths and\nlimitations comparing it with the score-based structure learning algorithm from\nNodelman et al. (2003). We find the latter to be more accurate in learning\nnetworks with binary variables, while our constraint-based approach is more\naccurate with variables assuming more than two values. Numerical experiments\nconfirm that score-based and constraint-based algorithms are comparable in\nterms of computation time.\n", "versions": [{"version": "v1", "created": "Tue, 7 Jul 2020 07:34:09 GMT"}, {"version": "v2", "created": "Mon, 8 Feb 2021 08:40:00 GMT"}, {"version": "v3", "created": "Wed, 2 Jun 2021 19:27:44 GMT"}], "update_date": "2021-06-04", "authors_parsed": [["Bregoli", "Alessandro", ""], ["Scutari", "Marco", ""], ["Stella", "Fabio", ""]]}, {"id": "2007.03286", "submitter": "Kieran Greer Dr", "authors": "Kieran Greer", "title": "An Entropy Equation for Energy", "comments": "Incorrectly edited on journal web site, read arXiv version", "journal-ref": "IOSR Journal of Engineering (IOSRJEN), Vol. 10, No. 7, pp. 16-19,\n  2020", "doi": null, "report-no": null, "categories": "cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes an entropy equation, but one that should be used for\nmeasuring energy and not information. In relation to the human brain therefore,\nboth of these quantities can be used to represent the stored information. The\nhuman brain makes use of energy efficiency to form its structures, which is\nlikely to be linked to the neuron wiring. This energy efficiency can also be\nused as the basis for a clustering algorithm, which is described in a different\npaper. This paper is more of a discussion about global properties, where the\nrules used for the clustering algorithm can also create the entropy equation E\n= (mean * variance). This states that work is done through the energy released\nby the 'change' in entropy. The equation is so simplistic and generic that it\ncan offer arguments for completely different domains, where the journey ends\nwith a discussion about global energy properties in physics and beyond. A\ncomparison with Einstein's relativity equation is made and also the audacious\nsuggestion that a black hole has zero-energy inside.\n", "versions": [{"version": "v1", "created": "Tue, 7 Jul 2020 09:01:00 GMT"}, {"version": "v2", "created": "Thu, 30 Jul 2020 07:22:57 GMT"}, {"version": "v3", "created": "Tue, 11 Aug 2020 09:33:58 GMT"}], "update_date": "2020-08-12", "authors_parsed": [["Greer", "Kieran", ""]]}, {"id": "2007.03313", "submitter": "Kevin Ong", "authors": "Kevin Shen Hoong Ong, Dusit Niyato, Chau Yuen", "title": "Predictive Maintenance for Edge-Based Sensor Networks: A Deep\n  Reinforcement Learning Approach", "comments": "6 pages, 5 figures, accepted in IEEE WF-IoT 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Failure of mission-critical equipment interrupts production and results in\nmonetary loss. The risk of unplanned equipment downtime can be minimized\nthrough Predictive Maintenance of revenue generating assets to ensure optimal\nperformance and safe operation of equipment. However, the increased\nsensorization of the equipment generates a data deluge, and existing\nmachine-learning based predictive model alone becomes inadequate for timely\nequipment condition predictions. In this paper, a model-free Deep Reinforcement\nLearning algorithm is proposed for predictive equipment maintenance from an\nequipment-based sensor network context. Within each equipment, a sensor device\naggregates raw sensor data, and the equipment health status is analyzed for\nanomalous events. Unlike traditional black-box regression models, the proposed\nalgorithm self-learns an optimal maintenance policy and provides actionable\nrecommendation for each equipment. Our experimental results demonstrate the\npotential for broader range of equipment maintenance applications as an\nautomatic learning framework.\n", "versions": [{"version": "v1", "created": "Tue, 7 Jul 2020 10:00:32 GMT"}], "update_date": "2020-07-08", "authors_parsed": [["Ong", "Kevin Shen Hoong", ""], ["Niyato", "Dusit", ""], ["Yuen", "Chau", ""]]}, {"id": "2007.03328", "submitter": "Gianni De Fabritiis", "authors": "Gabriele Libardi and Gianni De Fabritiis", "title": "Guided Exploration with Proximal Policy Optimization using a Single\n  Demonstration", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Solving sparse reward tasks through exploration is one of the major\nchallenges in deep reinforcement learning, especially in three-dimensional,\npartially-observable environments. Critically, the algorithm proposed in this\narticle uses a single human demonstration to solve hard-exploration problems.\nWe train an agent on a combination of demonstrations and own experience to\nsolve problems with variable initial conditions. We adapt this idea and\nintegrate it with the proximal policy optimization (PPO). The agent is able to\nincrease its performance and to tackle harder problems by replaying its own\npast trajectories prioritizing them based on the obtained reward and the\nmaximum value of the trajectory. We compare different variations of this\nalgorithm to behavioral cloning on a set of hard-exploration tasks in the\nAnimal-AI Olympics environment. To the best of our knowledge, learning a task\nin a three-dimensional environment with comparable difficulty has never been\nconsidered before using only one human demonstration.\n", "versions": [{"version": "v1", "created": "Tue, 7 Jul 2020 10:30:32 GMT"}, {"version": "v2", "created": "Wed, 16 Jun 2021 21:38:35 GMT"}], "update_date": "2021-06-18", "authors_parsed": [["Libardi", "Gabriele", ""], ["De Fabritiis", "Gianni", ""]]}, {"id": "2007.03363", "submitter": "Francisco Cruz", "authors": "Ithan Moreira, Javier Rivas, Francisco Cruz, Richard Dazeley, Angel\n  Ayala, Bruno Fernandes", "title": "Deep Reinforcement Learning with Interactive Feedback in a Human-Robot\n  Environment", "comments": "In press journal Applied Sciences", "journal-ref": null, "doi": "10.3390/app10165574", "report-no": null, "categories": "cs.AI cs.MA cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Robots are extending their presence in domestic environments every day, being\nmore common to see them carrying out tasks in home scenarios. In the future,\nrobots are expected to increasingly perform more complex tasks and, therefore,\nbe able to acquire experience from different sources as quickly as possible. A\nplausible approach to address this issue is interactive feedback, where a\ntrainer advises a learner on which actions should be taken from specific states\nto speed up the learning process. Moreover, deep reinforcement learning has\nbeen recently widely utilized in robotics to learn the environment and acquire\nnew skills autonomously. However, an open issue when using deep reinforcement\nlearning is the excessive time needed to learn a task from raw input images. In\nthis work, we propose a deep reinforcement learning approach with interactive\nfeedback to learn a domestic task in a human-robot scenario. We compare three\ndifferent learning methods using a simulated robotic arm for the task of\norganizing different objects; the proposed methods are (i) deep reinforcement\nlearning (DeepRL); (ii) interactive deep reinforcement learning using a\npreviously trained artificial agent as an advisor (agent-IDeepRL); and (iii)\ninteractive deep reinforcement learning using a human advisor (human-IDeepRL).\nWe demonstrate that interactive approaches provide advantages for the learning\nprocess. The obtained results show that a learner agent, using either\nagent-IDeepRL or human-IDeepRL, completes the given task earlier and has fewer\nmistakes compared to the autonomous DeepRL approach.\n", "versions": [{"version": "v1", "created": "Tue, 7 Jul 2020 11:55:27 GMT"}, {"version": "v2", "created": "Tue, 11 Aug 2020 11:04:58 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Moreira", "Ithan", ""], ["Rivas", "Javier", ""], ["Cruz", "Francisco", ""], ["Dazeley", "Richard", ""], ["Ayala", "Angel", ""], ["Fernandes", "Bruno", ""]]}, {"id": "2007.03425", "submitter": "Jordi Pereira", "authors": "Igor Averbakh and Jordi Pereira", "title": "Tree Optimization Based Heuristics and Metaheuristics in Network\n  Construction Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a recently introduced class of network construction problems\nwhere edges of a transportation network need to be constructed by a server\n(construction crew). The server has a constant construction speed which is much\nlower than its travel speed, so relocation times are negligible with respect to\nconstruction times. It is required to find a construction schedule that\nminimizes a non-decreasing function of the times when various connections of\ninterest become operational. Most problems of this class are strongly NP-hard\non general networks, but are often tree-efficient, that is, polynomially\nsolvable on trees. We develop a generic local search heuristic approach and two\nmetaheuristics (Iterated Local Search and Tabu Search) for solving\ntree-efficient network construction problems on general networks, and explore\nthem computationally. Results of computational experiments indicate that the\nmethods have excellent performance.\n", "versions": [{"version": "v1", "created": "Fri, 3 Jul 2020 18:40:45 GMT"}], "update_date": "2020-07-08", "authors_parsed": [["Averbakh", "Igor", ""], ["Pereira", "Jordi", ""]]}, {"id": "2007.03433", "submitter": "Jin Guo", "authors": "Jin Guo", "title": "Decentralized Deep Reinforcement Learning for Network Level Traffic\n  Signal Control", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this thesis, I propose a family of fully decentralized deep multi-agent\nreinforcement learning (MARL) algorithms to achieve high, real-time performance\nin network-level traffic signal control. In this approach, each intersection is\nmodeled as an agent that plays a Markovian Game against the other intersection\nnodes in a traffic signal network modeled as an undirected graph, to approach\nthe optimal reduction in delay. Following Partially Observable Markov Decision\nProcesses (POMDPs), there are 3 levels of communication schemes between\nadjacent learning agents: independent deep Q-leaning (IDQL), shared states\nreinforcement learning (S2RL) and a shared states & rewards version of\nS2RL--S2R2L. In these 3 variants of decentralized MARL schemes, individual\nagent trains its local deep Q network (DQN) separately, enhanced by\nconvergence-guaranteed techniques like double DQN, prioritized experience\nreplay, multi-step bootstrapping, etc. To test the performance of the proposed\nthree MARL algorithms, a SUMO-based simulation platform is developed to mimic\nthe traffic evolution of the real world. Fed with random traffic demand between\npermitted OD pairs, a 4x4 Manhattan-style grid network is set up as the\ntestbed, two different vehicle arrival rates are generated for model training\nand testing. The experiment results show that S2R2L has a quicker convergence\nrate and better convergent performance than IDQL and S2RL in the training\nprocess. Moreover, three MARL schemes all reveal exceptional generalization\nabilities. Their testing results surpass the benchmark Max Pressure (MP)\nalgorithm, under the criteria of average vehicle delay, network-level queue\nlength and fuel consumption rate. Notably, S2R2L has the best testing\nperformance of reducing 34.55% traffic delay and dissipating 10.91% queue\nlength compared with MP.\n", "versions": [{"version": "v1", "created": "Thu, 2 Jul 2020 06:58:27 GMT"}, {"version": "v2", "created": "Fri, 17 Jul 2020 23:15:45 GMT"}], "update_date": "2020-07-21", "authors_parsed": [["Guo", "Jin", ""]]}, {"id": "2007.03437", "submitter": "Arnab Kumar Mondal", "authors": "Arnab Kumar Mondal, Pratheeksha Nair, Kaleem Siddiqi", "title": "Group Equivariant Deep Reinforcement Learning", "comments": "Presented at the ICML 2020 Workshop on Inductive Biases, Invariances\n  and Generalization in RL", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In Reinforcement Learning (RL), Convolutional Neural Networks(CNNs) have been\nsuccessfully applied as function approximators in Deep Q-Learning algorithms,\nwhich seek to learn action-value functions and policies in various\nenvironments. However, to date, there has been little work on the learning of\nsymmetry-transformation equivariant representations of the input environment\nstate. In this paper, we propose the use of Equivariant CNNs to train RL agents\nand study their inductive bias for transformation equivariant Q-value\napproximation. We demonstrate that equivariant architectures can dramatically\nenhance the performance and sample efficiency of RL agents in a highly\nsymmetric environment while requiring fewer parameters. Additionally, we show\nthat they are robust to changes in the environment caused by affine\ntransformations.\n", "versions": [{"version": "v1", "created": "Wed, 1 Jul 2020 02:38:48 GMT"}], "update_date": "2020-07-08", "authors_parsed": [["Mondal", "Arnab Kumar", ""], ["Nair", "Pratheeksha", ""], ["Siddiqi", "Kaleem", ""]]}, {"id": "2007.03458", "submitter": "Sarah Perrin", "authors": "Sarah Perrin, Julien Perolat, Mathieu Lauri\\`ere, Matthieu Geist,\n  Romuald Elie, Olivier Pietquin", "title": "Fictitious Play for Mean Field Games: Continuous Time Analysis and\n  Applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we deepen the analysis of continuous time Fictitious Play\nlearning algorithm to the consideration of various finite state Mean Field Game\nsettings (finite horizon, $\\gamma$-discounted), allowing in particular for the\nintroduction of an additional common noise.\n  We first present a theoretical convergence analysis of the continuous time\nFictitious Play process and prove that the induced exploitability decreases at\na rate $O(\\frac{1}{t})$. Such analysis emphasizes the use of exploitability as\na relevant metric for evaluating the convergence towards a Nash equilibrium in\nthe context of Mean Field Games. These theoretical contributions are supported\nby numerical experiments provided in either model-based or model-free settings.\nWe provide hereby for the first time converging learning dynamics for Mean\nField Games in the presence of common noise.\n", "versions": [{"version": "v1", "created": "Sun, 5 Jul 2020 23:31:47 GMT"}, {"version": "v2", "created": "Mon, 26 Oct 2020 11:18:44 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Perrin", "Sarah", ""], ["Perolat", "Julien", ""], ["Lauri\u00e8re", "Mathieu", ""], ["Geist", "Matthieu", ""], ["Elie", "Romuald", ""], ["Pietquin", "Olivier", ""]]}, {"id": "2007.03574", "submitter": "Melrose Roderick", "authors": "Melrose Roderick, Vaishnavh Nagarajan, J. Zico Kolter", "title": "Provably Safe PAC-MDP Exploration Using Analogies", "comments": "10 pages, 3 figures, In proceedings of the 24th International\n  Conference on Artificial Intelligence and Statistics (AISTATS) 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A key challenge in applying reinforcement learning to safety-critical domains\nis understanding how to balance exploration (needed to attain good performance\non the task) with safety (needed to avoid catastrophic failure). Although a\ngrowing line of work in reinforcement learning has investigated this area of\n\"safe exploration,\" most existing techniques either 1) do not guarantee safety\nduring the actual exploration process; and/or 2) limit the problem to a priori\nknown and/or deterministic transition dynamics with strong smoothness\nassumptions. Addressing this gap, we propose Analogous Safe-state Exploration\n(ASE), an algorithm for provably safe exploration in MDPs with unknown,\nstochastic dynamics. Our method exploits analogies between state-action pairs\nto safely learn a near-optimal policy in a PAC-MDP sense. Additionally, ASE\nalso guides exploration towards the most task-relevant states, which\nempirically results in significant improvements in terms of sample efficiency,\nwhen compared to existing methods.\n", "versions": [{"version": "v1", "created": "Tue, 7 Jul 2020 15:50:50 GMT"}, {"version": "v2", "created": "Mon, 22 Mar 2021 14:28:54 GMT"}], "update_date": "2021-03-23", "authors_parsed": [["Roderick", "Melrose", ""], ["Nagarajan", "Vaishnavh", ""], ["Kolter", "J. Zico", ""]]}, {"id": "2007.03575", "submitter": "Lun Yang", "authors": "Lun Yang", "title": "Resolving Head-On Conflicts for Multi-Agent Path Finding with\n  Conflict-Based Search", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conflict-Based Search (CBS) is a popular framework for solving the\nMulti-Agent Path Finding problem. Some of the conflicts incur a foreseeable\nconflict in one or both of the children nodes when splitting on them. This\npaper introduces a new technique, namely the head-on technique that finds out\nsuch conflicts, so they can be processed more efficiently by resolving the\nconflict with the potential conflict all together in one split. The proposed\ntechnique applies to all CBS-based solvers. Experimental results show that the\nhead-on technique improves the state-of-the-art MAPF solver CBSH.\n", "versions": [{"version": "v1", "created": "Tue, 7 Jul 2020 15:52:45 GMT"}], "update_date": "2020-07-08", "authors_parsed": [["Yang", "Lun", ""]]}, {"id": "2007.03580", "submitter": "Lukas Malburg", "authors": "Lukas Malburg and Patrick Klein and Ralph Bergmann", "title": "Using Semantic Web Services for AI-Based Research in Industry 4.0", "comments": "Submitted to ISWC 2020", "journal-ref": "Proceedings of the International Conference on Innovative\n  Intelligent Industrial Production and Logistics - Volume 1: IN4PL (2020)", "doi": "10.5220/0010135900320043", "report-no": null, "categories": "cs.AI cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The transition to Industry 4.0 requires smart manufacturing systems that are\neasily configurable and provide a high level of flexibility during\nmanufacturing in order to achieve mass customization or to support cloud\nmanufacturing. To realize this, Cyber-Physical Systems (CPSs) combined with\nArtificial Intelligence (AI) methods find their way into manufacturing shop\nfloors. For using AI methods in the context of Industry 4.0, semantic web\nservices are indispensable to provide a reasonable abstraction of the\nunderlying manufacturing capabilities. In this paper, we present semantic web\nservices for AI-based research in Industry 4.0. Therefore, we developed more\nthan 300 semantic web services for a physical simulation factory based on Web\nOntology Language for Web Services (OWL-S) and Web Service Modeling Ontology\n(WSMO) and linked them to an already existing domain ontology for intelligent\nmanufacturing control. Suitable for the requirements of CPS environments, our\npre- and postconditions are verified in near real-time by invoking other\nsemantic web services in contrast to complex reasoning within the knowledge\nbase. Finally, we evaluate our implementation by executing a cyber-physical\nworkflow composed of semantic web services using a workflow management system.\n", "versions": [{"version": "v1", "created": "Tue, 7 Jul 2020 15:58:10 GMT"}], "update_date": "2021-02-18", "authors_parsed": [["Malburg", "Lukas", ""], ["Klein", "Patrick", ""], ["Bergmann", "Ralph", ""]]}, {"id": "2007.03581", "submitter": "Wolfgang Dvo\\v{r}\\'ak", "authors": "Wolfgang Dvo\\v{r}\\'ak and Atefeh Keshavarzi Zafarghandi and Stefan\n  Woltran", "title": "Expressiveness of SETAFs and Support-Free ADFs under 3-valued Semantics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generalizing the attack structure in argumentation frameworks (AFs) has been\nstudied in different ways. Most prominently, the binary attack relation of Dung\nframeworks has been extended to the notion of collective attacks. The resulting\nformalism is often termed SETAFs. Another approach is provided via abstract\ndialectical frameworks (ADFs), where acceptance conditions specify the relation\nbetween arguments; restricting these conditions naturally allows for so-called\nsupport-free ADFs. The aim of the paper is to shed light on the relation\nbetween these two different approaches. To this end, we investigate and compare\nthe expressiveness of SETAFs and support-free ADFs under the lens of 3-valued\nsemantics. Our results show that it is only the presence of unsatisfiable\nacceptance conditions in support-free ADFs that discriminate the two\napproaches.\n", "versions": [{"version": "v1", "created": "Tue, 7 Jul 2020 16:03:23 GMT"}], "update_date": "2020-07-08", "authors_parsed": [["Dvo\u0159\u00e1k", "Wolfgang", ""], ["Zafarghandi", "Atefeh Keshavarzi", ""], ["Woltran", "Stefan", ""]]}, {"id": "2007.03592", "submitter": "Shaojie Tang", "authors": "Shaojie Tang and Jing Yuan", "title": "Adaptive Cascade Submodular Maximization", "comments": "Accepted at AAMAS 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose and study the cascade submodular maximization\nproblem under the adaptive setting. The input of our problem is a set of items,\neach item is in a particular state (i.e., the marginal contribution of an item)\nwhich is drawn from a known probability distribution. However, we can not know\nits actual state before selecting it. As compared with existing studies on\nstochastic submodular maximization, one unique setting of our problem is that\neach item is associated with a continuation probability which represents the\nprobability that one is allowed to continue to select the next item after\nselecting the current one. Intuitively, this term captures the externality of\nselecting one item to all its subsequent items in terms of the opportunity of\nbeing selected. Therefore, the actual set of items that can be selected by a\npolicy depends on the specific ordering it adopts to select items, this makes\nour problem fundamentally different from classical submodular set optimization\nproblems. Our objective is to identify the best sequence of selecting items so\nas to maximize the expected utility of the selected items. We propose a class\nof stochastic utility functions, \\emph{adaptive cascade submodular functions},\nand show that the objective functions in many practical application domains\nsatisfy adaptive cascade submodularity. Then we develop a $0.12$ approximation\nalgorithm to the adaptive cascade submodular maximization problem.\n", "versions": [{"version": "v1", "created": "Tue, 7 Jul 2020 16:21:56 GMT"}, {"version": "v2", "created": "Fri, 12 Feb 2021 21:57:43 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Tang", "Shaojie", ""], ["Yuan", "Jing", ""]]}, {"id": "2007.03616", "submitter": "Michael Falk", "authors": "Michael Falk", "title": "Artificial Stupidity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Public debate about AI is dominated by Frankenstein Syndrome, the fear that\nAI will become superhuman and escape human control. Although superintelligence\nis certainly a possibility, the interest it excites can distract the public\nfrom a more imminent concern: the rise of Artificial Stupidity (AS). This\narticle discusses the roots of Frankenstein Syndrome in Mary Shelley's famous\nnovel of 1818. It then provides a philosophical framework for analysing the\nstupidity of artificial agents, demonstrating that modern intelligent systems\ncan be seen to suffer from 'stupidity of judgement'. Finally it identifies an\nalternative literary tradition that exposes the perils and benefits of AS. In\nthe writings of Edmund Spenser, Jonathan Swift and E.T.A. Hoffmann, ASs\nreplace, oppress or seduce their human users. More optimistically, Joseph\nFurphy and Laurence Sterne imagine ASs that can serve human intellect as maps\nor as pipes. These writers provide a strong counternarrative to the myths that\ncurrently drive the AI debate. They identify ways in which even stupid\nartificial agents can evade human control, for instance by appealing to\nstereotypes or distancing us from reality. And they underscore the continuing\nimportance of the literary imagination in an increasingly automated society.\n", "versions": [{"version": "v1", "created": "Thu, 2 Jul 2020 00:37:23 GMT"}], "update_date": "2020-07-08", "authors_parsed": [["Falk", "Michael", ""]]}, {"id": "2007.03629", "submitter": "Yujia Li", "authors": "Yujia Li, Felix Gimeno, Pushmeet Kohli, Oriol Vinyals", "title": "Strong Generalization and Efficiency in Neural Programs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of learning efficient algorithms that strongly\ngeneralize in the framework of neural program induction. By carefully designing\nthe input / output interfaces of the neural model and through imitation, we are\nable to learn models that produce correct results for arbitrary input sizes,\nachieving strong generalization. Moreover, by using reinforcement learning, we\noptimize for program efficiency metrics, and discover new algorithms that\nsurpass the teacher used in imitation. With this, our approach can learn to\noutperform custom-written solutions for a variety of problems, as we tested it\non sorting, searching in ordered lists and the NP-complete 0/1 knapsack\nproblem, which sets a notable milestone in the field of Neural Program\nInduction. As highlights, our learned model can perform sorting perfectly on\nany input data size we tested on, with $O(n log n)$ complexity, whilst\noutperforming hand-coded algorithms, including quick sort, in number of\noperations even for list sizes far beyond those seen during training.\n", "versions": [{"version": "v1", "created": "Tue, 7 Jul 2020 17:03:02 GMT"}, {"version": "v2", "created": "Wed, 8 Jul 2020 09:19:58 GMT"}], "update_date": "2020-07-09", "authors_parsed": [["Li", "Yujia", ""], ["Gimeno", "Felix", ""], ["Kohli", "Pushmeet", ""], ["Vinyals", "Oriol", ""]]}, {"id": "2007.03669", "submitter": "Victoria Dean", "authors": "Victoria Dean, Shubham Tulsiani, Abhinav Gupta", "title": "See, Hear, Explore: Curiosity via Audio-Visual Association", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Exploration is one of the core challenges in reinforcement learning. A common\nformulation of curiosity-driven exploration uses the difference between the\nreal future and the future predicted by a learned model. However, predicting\nthe future is an inherently difficult task which can be ill-posed in the face\nof stochasticity. In this paper, we introduce an alternative form of curiosity\nthat rewards novel associations between different senses. Our approach exploits\nmultiple modalities to provide a stronger signal for more efficient\nexploration. Our method is inspired by the fact that, for humans, both sight\nand sound play a critical role in exploration. We present results on several\nAtari environments and Habitat (a photorealistic navigation simulator), showing\nthe benefits of using an audio-visual association model for intrinsically\nguiding learning agents in the absence of external rewards. For videos and\ncode, see https://vdean.github.io/audio-curiosity.html.\n", "versions": [{"version": "v1", "created": "Tue, 7 Jul 2020 17:56:35 GMT"}, {"version": "v2", "created": "Mon, 18 Jan 2021 16:26:54 GMT"}], "update_date": "2021-01-19", "authors_parsed": [["Dean", "Victoria", ""], ["Tulsiani", "Shubham", ""], ["Gupta", "Abhinav", ""]]}, {"id": "2007.03727", "submitter": "Maria In\\^es Silva", "authors": "Maria In\\^es Silva, Roberto Henriques", "title": "TripMD: Driving patterns investigation via Motif Analysis", "comments": "14 pages, 11 figures, to be published in Expert Systems with\n  Applications", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Processing driving data and investigating driving behavior has been receiving\nan increasing interest in the last decades, with applications ranging from car\ninsurance pricing to policy making. A common strategy to analyze driving\nbehavior is to study the maneuvers being performance by the driver. In this\npaper, we propose TripMD, a system that extracts the most relevant driving\npatterns from sensor recordings (such as acceleration) and provides a\nvisualization that allows for an easy investigation. Additionally, we test our\nsystem using the UAH-DriveSet dataset, a publicly available naturalistic\ndriving dataset. We show that (1) our system can extract a rich number of\ndriving patterns from a single driver that are meaningful to understand driving\nbehaviors and (2) our system can be used to identify the driving behavior of an\nunknown driver from a set of drivers whose behavior we know.\n", "versions": [{"version": "v1", "created": "Tue, 7 Jul 2020 18:34:31 GMT"}, {"version": "v2", "created": "Fri, 4 Dec 2020 10:32:54 GMT"}, {"version": "v3", "created": "Sun, 25 Apr 2021 12:03:59 GMT"}, {"version": "v4", "created": "Mon, 5 Jul 2021 16:49:18 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Silva", "Maria In\u00eas", ""], ["Henriques", "Roberto", ""]]}, {"id": "2007.03750", "submitter": "Jane Wang", "authors": "Matthew Botvinick, Jane X. Wang, Will Dabney, Kevin J. Miller, Zeb\n  Kurth-Nelson", "title": "Deep Reinforcement Learning and its Neuroscientific Implications", "comments": "22 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG q-bio.NC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The emergence of powerful artificial intelligence is defining new research\ndirections in neuroscience. To date, this research has focused largely on deep\nneural networks trained using supervised learning, in tasks such as image\nclassification. However, there is another area of recent AI work which has so\nfar received less attention from neuroscientists, but which may have profound\nneuroscientific implications: deep reinforcement learning. Deep RL offers a\ncomprehensive framework for studying the interplay among learning,\nrepresentation and decision-making, offering to the brain sciences a new set of\nresearch tools and a wide range of novel hypotheses. In the present review, we\nprovide a high-level introduction to deep RL, discuss some of its initial\napplications to neuroscience, and survey its wider implications for research on\nbrain and behavior, concluding with a list of opportunities for next-stage\nresearch.\n", "versions": [{"version": "v1", "created": "Tue, 7 Jul 2020 19:27:54 GMT"}], "update_date": "2020-07-09", "authors_parsed": [["Botvinick", "Matthew", ""], ["Wang", "Jane X.", ""], ["Dabney", "Will", ""], ["Miller", "Kevin J.", ""], ["Kurth-Nelson", "Zeb", ""]]}, {"id": "2007.03760", "submitter": "Ming Yin", "authors": "Ming Yin, Yu Bai and Yu-Xiang Wang", "title": "Near-Optimal Provable Uniform Convergence in Offline Policy Evaluation\n  for Reinforcement Learning", "comments": "Short version presented at Offline RL workshop at Neurips, 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of Offline Policy Evaluation (OPE) in Reinforcement Learning (RL)\nis a critical step towards applying RL in real-life applications. Existing work\non OPE mostly focus on evaluating a fixed target policy $\\pi$, which does not\nprovide useful bounds for offline policy learning as $\\pi$ will then be\ndata-dependent. We address this problem by simultaneously evaluating all\npolicies in a policy class $\\Pi$ -- uniform convergence in OPE -- and obtain\nnearly optimal error bounds for a number of global / local policy classes. Our\nresults imply that the model-based planning achieves an optimal episode\ncomplexity of $\\widetilde{O}(H^3/d_m\\epsilon^2)$ in identifying an\n$\\epsilon$-optimal policy under the time-inhomogeneous episodic MDP model ($H$\nis the planning horizon, $d_m$ is a quantity that reflects the exploration of\nthe logging policy $\\mu$). To the best of our knowledge, this is the first time\nthe optimal rate is shown to be possible for the offline RL setting and the\npaper is the first that systematically investigates the uniform convergence in\nOPE.\n", "versions": [{"version": "v1", "created": "Tue, 7 Jul 2020 19:44:14 GMT"}, {"version": "v2", "created": "Tue, 1 Dec 2020 09:14:25 GMT"}], "update_date": "2020-12-02", "authors_parsed": [["Yin", "Ming", ""], ["Bai", "Yu", ""], ["Wang", "Yu-Xiang", ""]]}, {"id": "2007.03805", "submitter": "Tuan Manh Lai", "authors": "Tuan Manh Lai, Trung Bui, Nedim Lipka", "title": "ISA: An Intelligent Shopping Assistant", "comments": "Accepted by AACL 2020 (Demo)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the growth of e-commerce, brick-and-mortar stores are still the\npreferred destinations for many people. In this paper, we present ISA, a\nmobile-based intelligent shopping assistant that is designed to improve\nshopping experience in physical stores. ISA assists users by leveraging\nadvanced techniques in computer vision, speech processing, and natural language\nprocessing. An in-store user only needs to take a picture or scan the barcode\nof the product of interest, and then the user can talk to the assistant about\nthe product. The assistant can also guide the user through the purchase process\nor recommend other similar products to the user. We take a data-driven approach\nin building the engines of ISA's natural language processing component, and the\nengines achieve good performance.\n", "versions": [{"version": "v1", "created": "Tue, 7 Jul 2020 21:57:34 GMT"}, {"version": "v2", "created": "Wed, 23 Sep 2020 05:42:24 GMT"}], "update_date": "2020-09-24", "authors_parsed": [["Lai", "Tuan Manh", ""], ["Bui", "Trung", ""], ["Lipka", "Nedim", ""]]}, {"id": "2007.03807", "submitter": "Vincent Liu", "authors": "Vincent Liu, Adam White, Hengshuai Yao, Martha White", "title": "Towards a practical measure of interference for reinforcement learning", "comments": "18 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Catastrophic interference is common in many network-based learning systems,\nand many proposals exist for mitigating it. But, before we overcome\ninterference we must understand it better. In this work, we provide a\ndefinition of interference for control in reinforcement learning. We\nsystematically evaluate our new measures, by assessing correlation with several\nmeasures of learning performance, including stability, sample efficiency, and\nonline and offline control performance across a variety of learning\narchitectures. Our new interference measure allows us to ask novel scientific\nquestions about commonly used deep learning architectures. In particular we\nshow that target network frequency is a dominating factor for interference, and\nthat updates on the last layer result in significantly higher interference than\nupdates internal to the network. This new measure can be expensive to compute;\nwe conclude with motivation for an efficient proxy measure and empirically\ndemonstrate it is correlated with our definition of interference.\n", "versions": [{"version": "v1", "created": "Tue, 7 Jul 2020 22:02:00 GMT"}], "update_date": "2020-07-09", "authors_parsed": [["Liu", "Vincent", ""], ["White", "Adam", ""], ["Yao", "Hengshuai", ""], ["White", "Martha", ""]]}, {"id": "2007.03926", "submitter": "Ulysse Marteau-Ferey", "authors": "Ulysse Marteau-Ferey (PSL, DI-ENS, SIERRA), Francis Bach (PSL, DI-ENS,\n  SIERRA), Alessandro Rudi (PSL, DI-ENS, SIERRA)", "title": "Non-parametric Models for Non-negative Functions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Linear models have shown great effectiveness and flexibility in many fields\nsuch as machine learning, signal processing and statistics. They can represent\nrich spaces of functions while preserving the convexity of the optimization\nproblems where they are used, and are simple to evaluate, differentiate and\nintegrate. However, for modeling non-negative functions, which are crucial for\nunsupervised learning, density estimation, or non-parametric Bayesian methods,\nlinear models are not applicable directly. Moreover, current state-of-the-art\nmodels like generalized linear models either lead to non-convex optimization\nproblems, or cannot be easily integrated. In this paper we provide the first\nmodel for non-negative functions which benefits from the same good properties\nof linear models. In particular, we prove that it admits a representer theorem\nand provide an efficient dual formulation for convex problems. We study its\nrepresentation power, showing that the resulting space of functions is strictly\nricher than that of generalized linear models. Finally we extend the model and\nthe theoretical results to functions with outputs in convex cones. The paper is\ncomplemented by an experimental evaluation of the model showing its\neffectiveness in terms of formulation, algorithmic derivation and practical\nresults on the problems of density estimation, regression with heteroscedastic\nerrors, and multiple quantile regression.\n", "versions": [{"version": "v1", "created": "Wed, 8 Jul 2020 07:17:28 GMT"}], "update_date": "2020-07-09", "authors_parsed": [["Marteau-Ferey", "Ulysse", "", "PSL, DI-ENS, SIERRA"], ["Bach", "Francis", "", "PSL, DI-ENS,\n  SIERRA"], ["Rudi", "Alessandro", "", "PSL, DI-ENS, SIERRA"]]}, {"id": "2007.03940", "submitter": "Pirmin Lemberger", "authors": "Pirmin Lemberger and Denis Oblin", "title": "Reconciling Causality and Statistics", "comments": "22 pages, 14 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Statisticians have warned us since the early days of their discipline that\nexperimental correlation between two observations by no means implies the\nexistence of a causal relation. The question about what clues exist in\nobservational data that could informs us about the existence of such causal\nrelations is nevertheless more that legitimate. It lies actually at the root of\nany scientific endeavor. For decades however the only accepted method among\nstatisticians to elucidate causal relationships was the so called Randomized\nControlled Trial. Besides this notorious exception causality questions remained\nlargely taboo for many. One reason for this state of affairs was the lack of an\nappropriate mathematical framework to formulate such questions in an\nunambiguous way. Fortunately thinks have changed these last years with the\nadvent of the so called Causality Revolution initiated by Judea Pearl and\ncoworkers. The aim of this pedagogical paper is to present their ideas and\nmethods in a compact and self-contained fashion with concrete business examples\nas illustrations.\n", "versions": [{"version": "v1", "created": "Wed, 8 Jul 2020 07:52:13 GMT"}, {"version": "v2", "created": "Thu, 24 Sep 2020 07:27:20 GMT"}], "update_date": "2020-09-25", "authors_parsed": [["Lemberger", "Pirmin", ""], ["Oblin", "Denis", ""]]}, {"id": "2007.03964", "submitter": "Adam Stooke", "authors": "Adam Stooke, Joshua Achiam, and Pieter Abbeel", "title": "Responsive Safety in Reinforcement Learning by PID Lagrangian Methods", "comments": "ICML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Lagrangian methods are widely used algorithms for constrained optimization\nproblems, but their learning dynamics exhibit oscillations and overshoot which,\nwhen applied to safe reinforcement learning, leads to constraint-violating\nbehavior during agent training. We address this shortcoming by proposing a\nnovel Lagrange multiplier update method that utilizes derivatives of the\nconstraint function. We take a controls perspective, wherein the traditional\nLagrange multiplier update behaves as \\emph{integral} control; our terms\nintroduce \\emph{proportional} and \\emph{derivative} control, achieving\nfavorable learning dynamics through damping and predictive measures. We apply\nour PID Lagrangian methods in deep RL, setting a new state of the art in Safety\nGym, a safe RL benchmark. Lastly, we introduce a new method to ease controller\ntuning by providing invariance to the relative numerical scales of reward and\ncost. Our extensive experiments demonstrate improved performance and\nhyperparameter robustness, while our algorithms remain nearly as simple to\nderive and implement as the traditional Lagrangian approach.\n", "versions": [{"version": "v1", "created": "Wed, 8 Jul 2020 08:43:14 GMT"}], "update_date": "2020-07-09", "authors_parsed": [["Stooke", "Adam", ""], ["Achiam", "Joshua", ""], ["Abbeel", "Pieter", ""]]}, {"id": "2007.04032", "submitter": "Yuanhang Zhou", "authors": "Kun Zhou, Wayne Xin Zhao, Shuqing Bian, Yuanhang Zhou, Ji-Rong Wen,\n  Jingsong Yu", "title": "Improving Conversational Recommender Systems via Knowledge Graph based\n  Semantic Fusion", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conversational recommender systems (CRS) aim to recommend high-quality items\nto users through interactive conversations. Although several efforts have been\nmade for CRS, two major issues still remain to be solved. First, the\nconversation data itself lacks of sufficient contextual information for\naccurately understanding users' preference. Second, there is a semantic gap\nbetween natural language expression and item-level user preference. To address\nthese issues, we incorporate both word-oriented and entity-oriented knowledge\ngraphs (KG) to enhance the data representations in CRSs, and adopt Mutual\nInformation Maximization to align the word-level and entity-level semantic\nspaces. Based on the aligned semantic representations, we further develop a\nKG-enhanced recommender component for making accurate recommendations, and a\nKG-enhanced dialog component that can generate informative keywords or entities\nin the response text. Extensive experiments have demonstrated the effectiveness\nof our approach in yielding better performance on both recommendation and\nconversation tasks.\n", "versions": [{"version": "v1", "created": "Wed, 8 Jul 2020 11:14:23 GMT"}], "update_date": "2020-07-09", "authors_parsed": [["Zhou", "Kun", ""], ["Zhao", "Wayne Xin", ""], ["Bian", "Shuqing", ""], ["Zhou", "Yuanhang", ""], ["Wen", "Ji-Rong", ""], ["Yu", "Jingsong", ""]]}, {"id": "2007.04068", "submitter": "Shakir Mohamed", "authors": "Shakir Mohamed, Marie-Therese Png, William Isaac", "title": "Decolonial AI: Decolonial Theory as Sociotechnical Foresight in\n  Artificial Intelligence", "comments": "28 Pages. Accepted, to appear in: Philosophy and Technology (405),\n  Springer. Submitted 16 January, Accepted 26 May 2020", "journal-ref": null, "doi": "10.1007/s13347-020-00405-8", "report-no": null, "categories": "cs.CY cs.AI cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper explores the important role of critical science, and in particular\nof post-colonial and decolonial theories, in understanding and shaping the\nongoing advances in artificial intelligence. Artificial Intelligence (AI) is\nviewed as amongst the technological advances that will reshape modern societies\nand their relations. Whilst the design and deployment of systems that\ncontinually adapt holds the promise of far-reaching positive change, they\nsimultaneously pose significant risks, especially to already vulnerable\npeoples. Values and power are central to this discussion. Decolonial theories\nuse historical hindsight to explain patterns of power that shape our\nintellectual, political, economic, and social world. By embedding a decolonial\ncritical approach within its technical practice, AI communities can develop\nforesight and tactics that can better align research and technology development\nwith established ethical principles, centring vulnerable peoples who continue\nto bear the brunt of negative impacts of innovation and scientific progress. We\nhighlight problematic applications that are instances of coloniality, and using\na decolonial lens, submit three tactics that can form a decolonial field of\nartificial intelligence: creating a critical technical practice of AI, seeking\nreverse tutelage and reverse pedagogies, and the renewal of affective and\npolitical communities. The years ahead will usher in a wave of new scientific\nbreakthroughs and technologies driven by AI research, making it incumbent upon\nAI communities to strengthen the social contract through ethical foresight and\nthe multiplicity of intellectual perspectives available to us; ultimately\nsupporting future technologies that enable greater well-being, with the goal of\nbeneficence and justice for all.\n", "versions": [{"version": "v1", "created": "Wed, 8 Jul 2020 12:36:21 GMT"}], "update_date": "2020-07-09", "authors_parsed": [["Mohamed", "Shakir", ""], ["Png", "Marie-Therese", ""], ["Isaac", "William", ""]]}, {"id": "2007.04069", "submitter": "Shiqing Fan", "authors": "Siyu Wang, Yi Rong, Shiqing Fan, Zhen Zheng, LanSong Diao, Guoping\n  Long, Jun Yang, Xiaoyong Liu, Wei Lin", "title": "Auto-MAP: A DQN Framework for Exploring Distributed Execution Plans for\n  DNN Workloads", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The last decade has witnessed growth in the computational requirements for\ntraining deep neural networks. Current approaches (e.g., data/model\nparallelism, pipeline parallelism) parallelize training tasks onto multiple\ndevices. However, these approaches always rely on specific deep learning\nframeworks and requires elaborate manual design, which make it difficult to\nmaintain and share between different type of models. In this paper, we propose\nAuto-MAP, a framework for exploring distributed execution plans for DNN\nworkloads, which can automatically discovering fast parallelization strategies\nthrough reinforcement learning on IR level of deep learning models. Efficient\nexploration remains a major challenge for reinforcement learning. We leverage\nDQN with task-specific pruning strategies to help efficiently explore the\nsearch space including optimized strategies. Our evaluation shows that Auto-MAP\ncan find the optimal solution in two hours, while achieving better throughput\non several NLP and convolution models.\n", "versions": [{"version": "v1", "created": "Wed, 8 Jul 2020 12:38:03 GMT"}], "update_date": "2020-07-09", "authors_parsed": [["Wang", "Siyu", ""], ["Rong", "Yi", ""], ["Fan", "Shiqing", ""], ["Zheng", "Zhen", ""], ["Diao", "LanSong", ""], ["Long", "Guoping", ""], ["Yang", "Jun", ""], ["Liu", "Xiaoyong", ""], ["Lin", "Wei", ""]]}, {"id": "2007.04169", "submitter": "Jay Budzik", "authors": "Geoff Ward, Sean Kamkar, Jay Budzik", "title": "An exploration of the influence of path choice in game-theoretic\n  attribution algorithms", "comments": "21 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We compare machine learning explainability methods based on the theory of\natomic (Shapley, 1953) and infinitesimal (Aumann and Shapley, 1974) games, in a\ntheoretical and experimental investigation into how the model and choice of\nintegration path can influence the resulting feature attributions. To gain\ninsight into differences in attributions resulting from interventional Shapley\nvalues (Sundararajan and Najmi, 2019; Janzing et al., 2019; Chen et al., 2019)\nand Generalized Integrated Gradients (GIG) (Merrill et al., 2019) we note\ninterventional Shapley is equivalent to a multi-path integration along $n!$\npaths where $n$ is the number of model input features. Applying Stoke's theorem\nwe show that the path symmetry of these two methods results in the same\nattributions when the model is composed of a sum of separable functions of\nindividual features and a sum of two-feature products. We then perform a series\nof experiments with varying degrees of data missingness to demonstrate how\ninterventional Shapley's multi-path approach can yield less consistent\nattributions than the single straight-line path of Aumann-Shapley. We argue\nthis is because the multiple paths employed by interventional Shapley extend\naway from the training data manifold and are therefore more likely to pass\nthrough regions where the model has little support. In the absence of a more\nmeaningful path choice, we therefore advocate the straight-line path since it\nwill almost always pass closer to the data manifold. Among straight-line path\nattribution algorithms, GIG is uniquely robust since it will still yield\nShapley values for atomic games modeled by decision trees.\n", "versions": [{"version": "v1", "created": "Wed, 8 Jul 2020 14:57:28 GMT"}, {"version": "v2", "created": "Fri, 26 Feb 2021 19:33:47 GMT"}], "update_date": "2021-03-02", "authors_parsed": [["Ward", "Geoff", ""], ["Kamkar", "Sean", ""], ["Budzik", "Jay", ""]]}, {"id": "2007.04203", "submitter": "Thomas Spooner", "authors": "Thomas Spooner and Rahul Savani", "title": "A Natural Actor-Critic Algorithm with Downside Risk Constraints", "comments": "14 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI q-fin.CP q-fin.PM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing work on risk-sensitive reinforcement learning - both for symmetric\nand downside risk measures - has typically used direct Monte-Carlo estimation\nof policy gradients. While this approach yields unbiased gradient estimates, it\nalso suffers from high variance and decreased sample efficiency compared to\ntemporal-difference methods. In this paper, we study prediction and control\nwith aversion to downside risk which we gauge by the lower partial moment of\nthe return. We introduce a new Bellman equation that upper bounds the lower\npartial moment, circumventing its non-linearity. We prove that this proxy for\nthe lower partial moment is a contraction, and provide intuition into the\nstability of the algorithm by variance decomposition. This allows\nsample-efficient, on-line estimation of partial moments. For risk-sensitive\ncontrol, we instantiate Reward Constrained Policy Optimization, a recent\nactor-critic method for finding constrained policies, with our proxy for the\nlower partial moment. We extend the method to use natural policy gradients and\ndemonstrate the effectiveness of our approach on three benchmark problems for\nrisk-sensitive reinforcement learning.\n", "versions": [{"version": "v1", "created": "Wed, 8 Jul 2020 15:44:33 GMT"}], "update_date": "2020-07-09", "authors_parsed": [["Spooner", "Thomas", ""], ["Savani", "Rahul", ""]]}, {"id": "2007.04212", "submitter": "Yuhuai(Tony) Wu", "authors": "Yuhuai Wu, Honghua Dong, Roger Grosse, Jimmy Ba", "title": "The Scattering Compositional Learner: Discovering Objects, Attributes,\n  Relationships in Analogical Reasoning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.LO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we focus on an analogical reasoning task that contains rich\ncompositional structures, Raven's Progressive Matrices (RPM). To discover\ncompositional structures of the data, we propose the Scattering Compositional\nLearner (SCL), an architecture that composes neural networks in a sequence. Our\nSCL achieves state-of-the-art performance on two RPM datasets, with a 48.7%\nrelative improvement on Balanced-RAVEN and 26.4% on PGM over the previous\nstate-of-the-art. We additionally show that our model discovers compositional\nrepresentations of objects' attributes (e.g., shape color, size), and their\nrelationships (e.g., progression, union). We also find that the compositional\nrepresentation makes the SCL significantly more robust to test-time domain\nshifts and greatly improves zero-shot generalization to previously unseen\nanalogies.\n", "versions": [{"version": "v1", "created": "Wed, 8 Jul 2020 15:53:06 GMT"}], "update_date": "2020-07-09", "authors_parsed": [["Wu", "Yuhuai", ""], ["Dong", "Honghua", ""], ["Grosse", "Roger", ""], ["Ba", "Jimmy", ""]]}, {"id": "2007.04221", "submitter": "Srdjan Vesic", "authors": "Leila Amgoud, Srdjan Vesic", "title": "Dung's semantics satisfy attack removal monotonicity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that preferred, stable, complete, and grounded semantics satisfy\nattack removal monotonicity. This means that if an attack from b to a is\nremoved, the status of a cannot worsen, e.g. if a was skeptically accepted, it\ncannot become rejected.\n", "versions": [{"version": "v1", "created": "Wed, 8 Jul 2020 15:59:14 GMT"}], "update_date": "2020-07-09", "authors_parsed": [["Amgoud", "Leila", ""], ["Vesic", "Srdjan", ""]]}, {"id": "2007.04223", "submitter": "Nuno Louren\\c{c}o", "authors": "Pedro Carvalho, Nuno Louren\\c{c}o, Filipe Assun\\c{c}\\~ao, Penousal\n  Machado", "title": "AutoLR: An Evolutionary Approach to Learning Rate Policies", "comments": null, "journal-ref": null, "doi": "10.1145/3377930.3390158", "report-no": null, "categories": "cs.NE cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The choice of a proper learning rate is paramount for good Artificial Neural\nNetwork training and performance. In the past, one had to rely on experience\nand trial-and-error to find an adequate learning rate. Presently, a plethora of\nstate of the art automatic methods exist that make the search for a good\nlearning rate easier. While these techniques are effective and have yielded\ngood results over the years, they are general solutions. This means the\noptimization of learning rate for specific network topologies remains largely\nunexplored. This work presents AutoLR, a framework that evolves Learning Rate\nSchedulers for a specific Neural Network Architecture using Structured\nGrammatical Evolution. The system was used to evolve learning rate policies\nthat were compared with a commonly used baseline value for learning rate.\nResults show that training performed using certain evolved policies is more\nefficient than the established baseline and suggest that this approach is a\nviable means of improving a neural network's performance.\n", "versions": [{"version": "v1", "created": "Wed, 8 Jul 2020 16:03:44 GMT"}], "update_date": "2020-07-09", "authors_parsed": [["Carvalho", "Pedro", ""], ["Louren\u00e7o", "Nuno", ""], ["Assun\u00e7\u00e3o", "Filipe", ""], ["Machado", "Penousal", ""]]}, {"id": "2007.04248", "submitter": "Nazakat Ali", "authors": "Nazakat Ali", "title": "Chatbot: A Conversational Agent employed with Named Entity Recognition\n  Model using Artificial Neural Network", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Chatbot is a technology that is used to mimic human behavior using natural\nlanguage. There are different types of Chatbot that can be used as\nconversational agent in various business domains in order to increase the\ncustomer service and satisfaction. For any business domain, it requires a\nknowledge base to be built for that domain and design an information retrieval\nbased system that can respond the user with a piece of documentation or\ngenerated sentences. The core component of a Chatbot is Natural Language\nUnderstanding (NLU) which has been impressively improved by deep learning\nmethods. But we often lack such properly built NLU modules and requires more\ntime to build it from scratch for high quality conversations. This may\nencourage fresh learners to build a Chatbot from scratch with simple\narchitecture and using small dataset, although it may have reduced\nfunctionality, rather than building high quality data driven methods. This\nresearch focuses on Named Entity Recognition (NER) and Intent Classification\nmodels which can be integrated into NLU service of a Chatbot. Named entities\nwill be inserted manually in the knowledge base and automatically detected in a\ngiven sentence. The NER model in the proposed architecture is based on\nartificial neural network which is trained on manually created entities and\nevaluated using CoNLL-2003 dataset.\n", "versions": [{"version": "v1", "created": "Fri, 19 Jun 2020 14:47:21 GMT"}], "update_date": "2020-07-09", "authors_parsed": [["Ali", "Nazakat", ""]]}, {"id": "2007.04304", "submitter": "Oliver Roesler", "authors": "Oliver Roesler", "title": "Unsupervised Online Grounding of Natural Language during Human-Robot\n  Interactions", "comments": "11 pages, 6 figures, 3 tables; Published in Proceedings of the Second\n  Grand Challenge and Workshop on Multimodal Language (Challenge-HML) in the\n  58th Annual Meeting of the Association for Computational Linguistics (ACL\n  2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Allowing humans to communicate through natural language with robots requires\nconnections between words and percepts. The process of creating these\nconnections is called symbol grounding and has been studied for nearly three\ndecades. Although many studies have been conducted, not many considered\ngrounding of synonyms and the employed algorithms either work only offline or\nin a supervised manner. In this paper, a cross-situational learning based\ngrounding framework is proposed that allows grounding of words and phrases\nthrough corresponding percepts without human supervision and online, i.e. it\ndoes not require any explicit training phase, but instead updates the obtained\nmappings for every new encountered situation. The proposed framework is\nevaluated through an interaction experiment between a human tutor and a robot,\nand compared to an existing unsupervised grounding framework. The results show\nthat the proposed framework is able to ground words through their corresponding\npercepts online and in an unsupervised manner, while outperforming the baseline\nframework.\n", "versions": [{"version": "v1", "created": "Sun, 5 Jul 2020 17:48:26 GMT"}], "update_date": "2020-07-09", "authors_parsed": [["Roesler", "Oliver", ""]]}, {"id": "2007.04364", "submitter": "Anamaria Radoi", "authors": "Andreea Birhala, Catalin Nicolae Ristea, Anamaria Radoi, Liviu\n  Cristian Dutu", "title": "Temporal aggregation of audio-visual modalities for emotion recognition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Emotion recognition has a pivotal role in affective computing and in\nhuman-computer interaction. The current technological developments lead to\nincreased possibilities of collecting data about the emotional state of a\nperson. In general, human perception regarding the emotion transmitted by a\nsubject is based on vocal and visual information collected in the first seconds\nof interaction with the subject. As a consequence, the integration of verbal\n(i.e., speech) and non-verbal (i.e., image) information seems to be the\npreferred choice in most of the current approaches towards emotion recognition.\nIn this paper, we propose a multimodal fusion technique for emotion recognition\nbased on combining audio-visual modalities from a temporal window with\ndifferent temporal offsets for each modality. We show that our proposed method\noutperforms other methods from the literature and human accuracy rating. The\nexperiments are conducted over the open-access multimodal dataset CREMA-D.\n", "versions": [{"version": "v1", "created": "Wed, 8 Jul 2020 18:44:15 GMT"}], "update_date": "2020-07-10", "authors_parsed": [["Birhala", "Andreea", ""], ["Ristea", "Catalin Nicolae", ""], ["Radoi", "Anamaria", ""], ["Dutu", "Liviu Cristian", ""]]}, {"id": "2007.04395", "submitter": "Xiang Ling", "authors": "Xiang Ling, Lingfei Wu, Saizhuo Wang, Tengfei Ma, Fangli Xu, Alex X.\n  Liu, Chunming Wu, Shouling Ji", "title": "Multi-Level Graph Matching Networks for Deep Graph Similarity Learning", "comments": "14 pages, rename names & fix typos, under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While the celebrated graph neural networks yield effective representations\nfor individual nodes of a graph, there has been relatively less success in\nextending to the task of graph similarity learning. Recent work on graph\nsimilarity learning has considered either global-level graph-graph interactions\nor low-level node-node interactions, ignoring the rich cross-level interactions\n(e.g., between nodes of a graph and the other whole graph). In this paper, we\npropose a Multi-Level Graph Matching Network (MGMN) framework for computing the\ngraph similarity between any pair of graph-structured objects in an end-to-end\nfashion. The proposed model MGMN consists of a node-graph matching network for\neffectively learning cross-level interactions between nodes of a graph and the\nother whole graph, and a siamese graph neural network to learn global-level\ninteractions between two input graphs. Furthermore, to bridge the gap of the\nlack of standard graph similarity learning benchmarks, we have created and\ncollected a set of datasets for both the graph-graph classification and\ngraph-graph regression tasks with different sizes in order to evaluate the\neffectiveness and robustness of our models. Comprehensive experiments\ndemonstrate that the proposed model MGMN consistently outperforms\nstate-of-the-art baseline models one both the graph-graph classification and\ngraph-graph regression tasks. Compared with previous work, MGMN also exhibits\nstronger robustness as the sizes of the two input graphs increase.\n", "versions": [{"version": "v1", "created": "Wed, 8 Jul 2020 19:48:19 GMT"}, {"version": "v2", "created": "Fri, 19 Mar 2021 06:46:11 GMT"}], "update_date": "2021-03-22", "authors_parsed": [["Ling", "Xiang", ""], ["Wu", "Lingfei", ""], ["Wang", "Saizhuo", ""], ["Ma", "Tengfei", ""], ["Xu", "Fangli", ""], ["Liu", "Alex X.", ""], ["Wu", "Chunming", ""], ["Ji", "Shouling", ""]]}, {"id": "2007.04432", "submitter": "Aditya Mate", "authors": "Aditya Mate, Jackson A. Killian, Haifeng Xu, Andrew Perrault, Milind\n  Tambe", "title": "Collapsing Bandits and Their Application to Public Health Interventions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose and study Collpasing Bandits, a new restless multi-armed bandit\n(RMAB) setting in which each arm follows a binary-state Markovian process with\na special structure: when an arm is played, the state is fully observed, thus\n\"collapsing\" any uncertainty, but when an arm is passive, no observation is\nmade, thus allowing uncertainty to evolve. The goal is to keep as many arms in\nthe \"good\" state as possible by planning a limited budget of actions per round.\nSuch Collapsing Bandits are natural models for many healthcare domains in which\nworkers must simultaneously monitor patients and deliver interventions in a way\nthat maximizes the health of their patient cohort. Our main contributions are\nas follows: (i) Building on the Whittle index technique for RMABs, we derive\nconditions under which the Collapsing Bandits problem is indexable. Our\nderivation hinges on novel conditions that characterize when the optimal\npolicies may take the form of either \"forward\" or \"reverse\" threshold policies.\n(ii) We exploit the optimality of threshold policies to build fast algorithms\nfor computing the Whittle index, including a closed-form. (iii) We evaluate our\nalgorithm on several data distributions including data from a real-world\nhealthcare task in which a worker must monitor and deliver interventions to\nmaximize their patients' adherence to tuberculosis medication. Our algorithm\nachieves a 3-order-of-magnitude speedup compared to state-of-the-art RMAB\ntechniques while achieving similar performance.\n", "versions": [{"version": "v1", "created": "Sun, 5 Jul 2020 00:33:30 GMT"}], "update_date": "2020-07-10", "authors_parsed": [["Mate", "Aditya", ""], ["Killian", "Jackson A.", ""], ["Xu", "Haifeng", ""], ["Perrault", "Andrew", ""], ["Tambe", "Milind", ""]]}, {"id": "2007.04452", "submitter": "Hsin-Pai Cheng", "authors": "Hsin-Pai Cheng, Tunhou Zhang, Yixing Zhang, Shiyu Li, Feng Liang, Feng\n  Yan, Meng Li, Vikas Chandra, Hai Li, Yiran Chen", "title": "NASGEM: Neural Architecture Search via Graph Embedding Method", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural Architecture Search (NAS) automates and prospers the design of neural\nnetworks. Estimator-based NAS has been proposed recently to model the\nrelationship between architectures and their performance to enable scalable and\nflexible search. However, existing estimator-based methods encode the\narchitecture into a latent space without considering graph similarity. Ignoring\ngraph similarity in node-based search space may induce a large inconsistency\nbetween similar graphs and their distance in the continuous encoding space,\nleading to inaccurate encoding representation and/or reduced representation\ncapacity that can yield sub-optimal search results. To preserve graph\ncorrelation information in encoding, we propose NASGEM which stands for Neural\nArchitecture Search via Graph Embedding Method. NASGEM is driven by a novel\ngraph embedding method equipped with similarity measures to capture the graph\ntopology information. By precisely estimating the graph distance and using an\nauxiliary Weisfeiler-Lehman kernel to guide the encoding, NASGEM can utilize\nadditional structural information to get more accurate graph representation to\nimprove the search efficiency. GEMNet, a set of networks discovered by NASGEM,\nconsistently outperforms networks crafted by existing search methods in\nclassification tasks, i.e., with 0.4%-3.6% higher accuracy while having 11%-\n21% fewer Multiply-Accumulates. We further transfer GEMNet for COCO object\ndetection. In both one-stage and twostage detectors, our GEMNet surpasses its\nmanually-crafted and automatically-searched counterparts.\n", "versions": [{"version": "v1", "created": "Wed, 8 Jul 2020 21:58:37 GMT"}, {"version": "v2", "created": "Mon, 28 Sep 2020 04:34:42 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Cheng", "Hsin-Pai", ""], ["Zhang", "Tunhou", ""], ["Zhang", "Yixing", ""], ["Li", "Shiyu", ""], ["Liang", "Feng", ""], ["Yan", "Feng", ""], ["Li", "Meng", ""], ["Chandra", "Vikas", ""], ["Li", "Hai", ""], ["Chen", "Yiran", ""]]}, {"id": "2007.04456", "submitter": "Faisal Hussain", "authors": "Ivan Miguel Pires, Faisal Hussain, Nuno M. Garcia, Eftim Zdravevski", "title": "An Efficient Data Imputation Technique for Human Activity Recognition", "comments": "8 Pages, 8 Figures, 1 Table. Accepted in 14th Multi Conference on\n  Computer Science and Information Systems 2020 (MCCSIS 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.AI cs.CY cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The tremendous applications of human activity recognition are surging its\nspan from health monitoring systems to virtual reality applications. Thus, the\nautomatic recognition of daily life activities has become significant for\nnumerous applications. In recent years, many datasets have been proposed to\ntrain the machine learning models for efficient monitoring and recognition of\nhuman daily living activities. However, the performance of machine learning\nmodels in activity recognition is crucially affected when there are incomplete\nactivities in a dataset, i.e., having missing samples in dataset captures.\nTherefore, in this work, we propose a methodology for extrapolating the missing\nsamples of a dataset to better recognize the human daily living activities. The\nproposed method efficiently pre-processes the data captures and utilizes the\nk-Nearest Neighbors (KNN) imputation technique to extrapolate the missing\nsamples in dataset captures. The proposed methodology elegantly extrapolated a\nsimilar pattern of activities as they were in the real dataset.\n", "versions": [{"version": "v1", "created": "Wed, 8 Jul 2020 22:05:38 GMT"}], "update_date": "2020-07-10", "authors_parsed": [["Pires", "Ivan Miguel", ""], ["Hussain", "Faisal", ""], ["Garcia", "Nuno M.", ""], ["Zdravevski", "Eftim", ""]]}, {"id": "2007.04477", "submitter": "Nicholas Kluge Corr\\^ea", "authors": "Nicholas Kluge Corr\\^ea and Nythamar de Oliveira", "title": "Good AI for the Present of Humanity Democratizing AI Governance", "comments": null, "journal-ref": "The AI Ethics Journal (2021)", "doi": "10.47289/AIEJ20210716-2", "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  What do Cyberpunk and AI Ethics have to do with each other? Cyberpunk is a\nsub-genre of science fiction that explores the post-human relationships between\nhuman experience and technology. One similarity between AI Ethics and Cyberpunk\nliterature is that both seek to explore future social and ethical problems that\nour technological advances may bring upon society. In recent years, an\nincreasing number of ethical matters involving AI have been pointed and\ndebated, and several ethical principles and guides have been suggested as\ngovernance policies for the tech industry. However, would this be the role of\nAI Ethics? To serve as a soft and ambiguous version of the law? We would like\nto advocate in this article for a more Cyberpunk way of doing AI Ethics, with a\nmore democratic way of governance. In this study, we will seek to expose some\nof the deficits of the underlying power structures of the AI industry, and\nsuggest that AI governance be subject to public opinion, so that good AI can\nbecome good AI for all.\n", "versions": [{"version": "v1", "created": "Wed, 8 Jul 2020 23:50:28 GMT"}, {"version": "v10", "created": "Sat, 26 Dec 2020 21:26:07 GMT"}, {"version": "v11", "created": "Tue, 1 Jun 2021 18:31:11 GMT"}, {"version": "v12", "created": "Sat, 17 Jul 2021 17:21:15 GMT"}, {"version": "v2", "created": "Sun, 12 Jul 2020 22:52:10 GMT"}, {"version": "v3", "created": "Thu, 23 Jul 2020 22:40:36 GMT"}, {"version": "v4", "created": "Fri, 7 Aug 2020 23:48:38 GMT"}, {"version": "v5", "created": "Thu, 27 Aug 2020 17:26:32 GMT"}, {"version": "v6", "created": "Sat, 5 Sep 2020 18:55:27 GMT"}, {"version": "v7", "created": "Sun, 18 Oct 2020 04:11:19 GMT"}, {"version": "v8", "created": "Sun, 25 Oct 2020 03:53:29 GMT"}, {"version": "v9", "created": "Tue, 27 Oct 2020 02:42:33 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Corr\u00eaa", "Nicholas Kluge", ""], ["de Oliveira", "Nythamar", ""]]}, {"id": "2007.04571", "submitter": "Mohammad Reza Feizi Derakhshi", "authors": "Majid Ramezani, Mohammad-Reza Feizi-Derakhshi, Mohammad-Ali Balafar,\n  Meysam Asgari-Chenaghlu, Ali-Reza Feizi-Derakhshi, Narjes Nikzad-Khasmakhi,\n  Mehrdad Ranjbar-Khadivi, Zoleikha Jahanbakhsh-Nagadeh, Elnaz\n  Zafarani-Moattar, Taymaz Rahkar-Farshi", "title": "Automatic Personality Prediction; an Enhanced Method Using Ensemble\n  Modeling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Human personality is significantly represented by those words which he/she\nuses in his/her speech or writing. As a consequence of spreading the\ninformation infrastructures (specifically the Internet and social media), human\ncommunications have reformed notably from face to face communication.\nGenerally, Automatic Personality Prediction (or Perception) (APP) is the\nautomated forecasting of the personality on different types of human\ngenerated/exchanged contents (like text, speech, image, video, etc.). The major\nobjective of this study is to enhance the accuracy of APP from the text. To\nthis end, we suggest five new APP methods including term frequency\nvector-based, ontology-based, enriched ontology-based, latent semantic analysis\n(LSA)-based, and deep learning-based (BiLSTM) methods. These methods as the\nbase ones, contribute to each other to enhance the APP accuracy through\nensemble modeling (stacking) based on a hierarchical attention network (HAN) as\nthe meta-model. The results show that ensemble modeling enhances the accuracy\nof APP.\n", "versions": [{"version": "v1", "created": "Thu, 9 Jul 2020 06:05:10 GMT"}, {"version": "v2", "created": "Sun, 21 Feb 2021 07:37:07 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Ramezani", "Majid", ""], ["Feizi-Derakhshi", "Mohammad-Reza", ""], ["Balafar", "Mohammad-Ali", ""], ["Asgari-Chenaghlu", "Meysam", ""], ["Feizi-Derakhshi", "Ali-Reza", ""], ["Nikzad-Khasmakhi", "Narjes", ""], ["Ranjbar-Khadivi", "Mehrdad", ""], ["Jahanbakhsh-Nagadeh", "Zoleikha", ""], ["Zafarani-Moattar", "Elnaz", ""], ["Rahkar-Farshi", "Taymaz", ""]]}, {"id": "2007.04578", "submitter": "Dongjae Kim", "authors": "Dongjae Kim and Jee Hang Lee, Jae Hoon Shin, Minsu Abel Yang, Sang Wan\n  Lee", "title": "On the Reliability and Generalizability of Brain-inspired Reinforcement\n  Learning Algorithms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although deep RL models have shown a great potential for solving various\ntypes of tasks with minimal supervision, several key challenges remain in terms\nof learning from limited experience, adapting to environmental changes, and\ngeneralizing learning from a single task. Recent evidence in decision\nneuroscience has shown that the human brain has an innate capacity to resolve\nthese issues, leading to optimism regarding the development of\nneuroscience-inspired solutions toward sample-efficient, and generalizable RL\nalgorithms. We show that the computational model combining model-based and\nmodel-free control, which we term the prefrontal RL, reliably encodes the\ninformation of high-level policy that humans learned, and this model can\ngeneralize the learned policy to a wide range of tasks. First, we trained the\nprefrontal RL, and deep RL algorithms on 82 subjects' data, collected while\nhuman participants were performing two-stage Markov decision tasks, in which we\nmanipulated the goal, state-transition uncertainty and state-space complexity.\nIn the reliability test, which includes the latent behavior profile and the\nparameter recoverability test, we showed that the prefrontal RL reliably\nlearned the latent policies of the humans, while all the other models failed.\nSecond, to test the ability to generalize what these models learned from the\noriginal task, we situated them in the context of environmental volatility.\nSpecifically, we ran large-scale simulations with 10 Markov decision tasks, in\nwhich latent context variables change over time. Our information-theoretic\nanalysis showed that the prefrontal RL showed the highest level of adaptability\nand episodic encoding efficacy. This is the first attempt to formally test the\npossibility that computational models mimicking the way the brain solves\ngeneral problems can lead to practical solutions to key challenges in machine\nlearning.\n", "versions": [{"version": "v1", "created": "Thu, 9 Jul 2020 06:32:42 GMT"}], "update_date": "2020-07-10", "authors_parsed": [["Kim", "Dongjae", ""], ["Lee", "Jee Hang", ""], ["Shin", "Jae Hoon", ""], ["Yang", "Minsu Abel", ""], ["Lee", "Sang Wan", ""]]}, {"id": "2007.04614", "submitter": "Wei Li", "authors": "Lei Zhang, Wei Bai, Shize Guo, Shiming Xia, Hongmei Li and Zhisong Pan", "title": "Weakness Analysis of Cyberspace Configuration Based on Reinforcement\n  Learning", "comments": "10 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we present a learning-based approach to analysis cyberspace\nconfiguration. Unlike prior methods, our approach has the ability to learn from\npast experience and improve over time. In particular, as we train over a\ngreater number of agents as attackers, our method becomes better at rapidly\nfinding attack paths for previously hidden paths, especially in multiple domain\ncyberspace. To achieve these results, we pose finding attack paths as a\nReinforcement Learning (RL) problem and train an agent to find multiple domain\nattack paths. To enable our RL policy to find more hidden attack paths, we\nground representation introduction an multiple domain action select module in\nRL. By designing a simulated cyberspace experimental environment to verify our\nmethod. Our objective is to find more hidden attack paths, to analysis the\nweakness of cyberspace configuration. The experimental results show that our\nmethod can find more hidden multiple domain attack paths than existing\nbaselines methods.\n", "versions": [{"version": "v1", "created": "Thu, 9 Jul 2020 07:53:35 GMT"}], "update_date": "2020-07-10", "authors_parsed": [["Zhang", "Lei", ""], ["Bai", "Wei", ""], ["Guo", "Shize", ""], ["Xia", "Shiming", ""], ["Li", "Hongmei", ""], ["Pan", "Zhisong", ""]]}, {"id": "2007.04620", "submitter": "Markus Hecher", "authors": "Markus Hecher, Jorge Fandinno", "title": "Treewidth-Aware Complexity in ASP: Not all Positive Cycles are Equally\n  Hard", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is well-know that deciding consistency for normal answer set programs\n(ASP) is NP-complete, thus, as hard as the satisfaction problem for classical\npropositional logic (SAT). The best algorithms to solve these problems take\nexponential time in the worst case. The exponential time hypothesis (ETH)\nimplies that this result is tight for SAT, that is, SAT cannot be solved in\nsubexponential time. This immediately establishes that the result is also tight\nfor the consistency problem for ASP. However, accounting for the treewidth of\nthe problem, the consistency problem for ASP is slightly harder than SAT: while\nSAT can be solved by an algorithm that runs in exponential time in the\ntreewidth k, it was recently shown that ASP requires exponential time in k\n\\cdot log(k). This extra cost is due checking that there are no self-supported\ntrue atoms due to positive cycles in the program. In this paper, we refine the\nabove result and show that the consistency problem for ASP can be solved in\nexponential time in k \\cdot log({\\lambda}) where {\\lambda} is the minimum\nbetween the treewidth and the size of the largest strongly-connected component\nin the positive dependency graph of the program. We provide a dynamic\nprogramming algorithm that solves the problem and a treewidth-aware reduction\nfrom ASP to SAT that adhere to the above limit.\n", "versions": [{"version": "v1", "created": "Thu, 9 Jul 2020 08:09:41 GMT"}], "update_date": "2020-07-10", "authors_parsed": [["Hecher", "Markus", ""], ["Fandinno", "Jorge", ""]]}, {"id": "2007.04663", "submitter": "Rushikesh Joshi", "authors": "Charu Agarwal, Rushikesh K. Joshi", "title": "Automation Strategies for Unconstrained Crossword Puzzle Generation", "comments": "28 pages, 28 figures, category: cs, preprint", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An unconstrained crossword puzzle is a generalization of the constrained\ncrossword problem. In this problem, only the word vocabulary, and optionally\nthe grid dimensions are known. Hence, it not only requires the algorithm to\ndetermine the word locations, but it also needs to come up with the grid\ngeometry. This paper discusses algorithmic strategies for automatic crossword\npuzzle generation in such an unconstrained setting. The strategies proposed\ncover the tasks of selection of words from a given vocabulary, selection of\ngrid sizes, grid resizing and adjustments, metrics for word fitting,\nback-tracking techniques, and also clue generation. The strategies have been\nformulated based on a study of the effect of word sequence permutation order on\ngrid fitting. An end-to-end algorithm that combines these strategies is\npresented, and its performance is analyzed. The techniques have been found to\nbe successful in quickly producing well-packed puzzles of even large sizes.\nFinally, a few example puzzles generated by our algorithm are also provided.\n", "versions": [{"version": "v1", "created": "Thu, 9 Jul 2020 09:45:03 GMT"}], "update_date": "2020-07-10", "authors_parsed": [["Agarwal", "Charu", ""], ["Joshi", "Rushikesh K.", ""]]}, {"id": "2007.04670", "submitter": "Xiangru Tang", "authors": "Xiangru Tang, Haoyuan Wang, Xiang Pan, Jiyang Qi", "title": "Multi-Granularity Modularized Network for Abstract Visual Reasoning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Abstract visual reasoning connects mental abilities to the physical world,\nwhich is a crucial factor in cognitive development. Most toddlers display\nsensitivity to this skill, but it is not easy for machines. Aimed at it, we\nfocus on the Raven Progressive Matrices Test, designed to measure cognitive\nreasoning. Recent work designed some black-boxes to solve it in an end-to-end\nfashion, but they are incredibly complicated and difficult to explain. Inspired\nby cognitive studies, we propose a Multi-Granularity Modularized Network (MMoN)\nto bridge the gap between the processing of raw sensory information and\nsymbolic reasoning. Specifically, it learns modularized reasoning functions to\nmodel the semantic rule from the visual grounding in a neuro-symbolic and\nsemi-supervision way. To comprehensively evaluate MMoN, our experiments are\nconducted on the dataset of both seen and unseen reasoning rules. The result\nshows that MMoN is well suited for abstract visual reasoning and also\nexplainable on the generalization test.\n", "versions": [{"version": "v1", "created": "Thu, 9 Jul 2020 09:54:05 GMT"}, {"version": "v2", "created": "Fri, 10 Jul 2020 02:32:25 GMT"}], "update_date": "2020-07-13", "authors_parsed": [["Tang", "Xiangru", ""], ["Wang", "Haoyuan", ""], ["Pan", "Xiang", ""], ["Qi", "Jiyang", ""]]}, {"id": "2007.04705", "submitter": "Ijaz Ahmad Dr.", "authors": "Ijaz Ahmad, Shahriar Shahabuddin, Tanesh Kumar, Erkki Harjula, Marcus\n  Meisel, Markku Juntti, Thilo Sauter, Mika Ylianttila", "title": "Challenges of AI in Wireless Networks for IoT", "comments": null, "journal-ref": null, "doi": "10.1109/MIE.2020.2979272", "report-no": null, "categories": "cs.NI cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Internet of Things (IoT), hailed as the enabler of the next industrial\nrevolution, will require ubiquitous connectivity, context-aware and dynamic\nservice mobility, and extreme security through the wireless network\ninfrastructure. Artificial Intelligence (AI), thus, will play a major role in\nthe underlying network infrastructure. However, a number of challenges will\nsurface while using the concepts, tools and algorithms of AI in wireless\nnetworks used by IoT. In this article, the main challenges in using AI in the\nwireless network infrastructure that facilitate end-to-end IoT communication\nare highlighted with potential generalized solution and future research\ndirections.\n", "versions": [{"version": "v1", "created": "Thu, 9 Jul 2020 11:00:56 GMT"}], "update_date": "2021-01-15", "authors_parsed": [["Ahmad", "Ijaz", ""], ["Shahabuddin", "Shahriar", ""], ["Kumar", "Tanesh", ""], ["Harjula", "Erkki", ""], ["Meisel", "Marcus", ""], ["Juntti", "Markku", ""], ["Sauter", "Thilo", ""], ["Ylianttila", "Mika", ""]]}, {"id": "2007.04725", "submitter": "Ahmed Hallawa Mr.", "authors": "Ahmed Hallawa, Thorsten Born, Anke Schmeink, Guido Dartmann, Arne\n  Peine, Lukas Martin, Giovanni Iacca, A. E. Eiben, Gerd Ascheid", "title": "EVO-RL: Evolutionary-Driven Reinforcement Learning", "comments": "9 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we propose a novel approach for reinforcement learning driven\nby evolutionary computation. Our algorithm, dubbed as Evolutionary-Driven\nReinforcement Learning (evo-RL), embeds the reinforcement learning algorithm in\nan evolutionary cycle, where we distinctly differentiate between purely\nevolvable (instinctive) behaviour versus purely learnable behaviour.\nFurthermore, we propose that this distinction is decided by the evolutionary\nprocess, thus allowing evo-RL to be adaptive to different environments. In\naddition, evo-RL facilitates learning on environments with rewardless states,\nwhich makes it more suited for real-world problems with incomplete information.\nTo show that evo-RL leads to state-of-the-art performance, we present the\nperformance of different state-of-the-art reinforcement learning algorithms\nwhen operating within evo-RL and compare it with the case when these same\nalgorithms are executed independently. Results show that reinforcement learning\nalgorithms embedded within our evo-RL approach significantly outperform the\nstand-alone versions of the same RL algorithms on OpenAI Gym control problems\nwith rewardless states constrained by the same computational budget.\n", "versions": [{"version": "v1", "created": "Thu, 9 Jul 2020 11:52:19 GMT"}, {"version": "v2", "created": "Fri, 10 Jul 2020 16:14:58 GMT"}], "update_date": "2020-07-13", "authors_parsed": [["Hallawa", "Ahmed", ""], ["Born", "Thorsten", ""], ["Schmeink", "Anke", ""], ["Dartmann", "Guido", ""], ["Peine", "Arne", ""], ["Martin", "Lukas", ""], ["Iacca", "Giovanni", ""], ["Eiben", "A. E.", ""], ["Ascheid", "Gerd", ""]]}, {"id": "2007.04756", "submitter": "Manas Gupta", "authors": "Manas Gupta, Siddharth Aravindan, Aleksandra Kalisz, Vijay\n  Chandrasekhar, Lin Jie", "title": "Learning to Prune Deep Neural Networks via Reinforcement Learning", "comments": "Accepted at the ICML 2020 Workshop on Automated Machine Learning\n  (AutoML 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes PuRL - a deep reinforcement learning (RL) based algorithm\nfor pruning neural networks. Unlike current RL based model compression\napproaches where feedback is given only at the end of each episode to the\nagent, PuRL provides rewards at every pruning step. This enables PuRL to\nachieve sparsity and accuracy comparable to current state-of-the-art methods,\nwhile having a much shorter training cycle. PuRL achieves more than 80%\nsparsity on the ResNet-50 model while retaining a Top-1 accuracy of 75.37% on\nthe ImageNet dataset. Through our experiments we show that PuRL is also able to\nsparsify already efficient architectures like MobileNet-V2. In addition to\nperformance characterisation experiments, we also provide a discussion and\nanalysis of the various RL design choices that went into the tuning of the\nMarkov Decision Process underlying PuRL. Lastly, we point out that PuRL is\nsimple to use and can be easily adapted for various architectures.\n", "versions": [{"version": "v1", "created": "Thu, 9 Jul 2020 13:06:07 GMT"}], "update_date": "2020-07-22", "authors_parsed": [["Gupta", "Manas", ""], ["Aravindan", "Siddharth", ""], ["Kalisz", "Aleksandra", ""], ["Chandrasekhar", "Vijay", ""], ["Jie", "Lin", ""]]}, {"id": "2007.04766", "submitter": "Adrien Luxey", "authors": "Daniel Bosk (KTH), Y\\'erom-David Bromberg (WIDE, IRISA), Sonja\n  Buchegger (KTH), Adrien Luxey (WIDE, IRISA), Fran\\c{c}ois Ta\\\"iani (WIDE,\n  IRISA)", "title": "Spores: Stateless Predictive Onion Routing for E-Squads", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.AI cs.NI cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mass surveillance of the population by state agencies and corporate parties\nis now a well-known fact. Journalists and whistle-blowers still lack means to\ncircumvent global spying for the sake of their investigations. With Spores, we\npropose a way for journalists and their sources to plan a posteriori file\nexchanges when they physically meet. We leverage on the multiplication of\npersonal devices per capita to provide a lightweight, robust and fully\nanonymous decentralised file transfer protocol between users. Spores hinges on\nour novel concept of e-squads: one's personal devices, rendered intelligent by\ngossip communication protocols, can provide private and dependable services to\ntheir user. People's e-squads are federated into a novel onion routing network,\nable to withstand the inherent unreliability of personal appliances while\nproviding reliable routing. Spores' performances are competitive, and its\nprivacy properties of the communication outperform state of the art onion\nrouting strategies.\n", "versions": [{"version": "v1", "created": "Thu, 2 Jul 2020 06:24:15 GMT"}], "update_date": "2020-07-10", "authors_parsed": [["Bosk", "Daniel", "", "KTH"], ["Bromberg", "Y\u00e9rom-David", "", "WIDE, IRISA"], ["Buchegger", "Sonja", "", "KTH"], ["Luxey", "Adrien", "", "WIDE, IRISA"], ["Ta\u00efani", "Fran\u00e7ois", "", "WIDE,\n  IRISA"]]}, {"id": "2007.04769", "submitter": "Han Zhang", "authors": "Han Zhang, Jialin Liu, and Xin Yao", "title": "A Hybrid Evolutionary Algorithm for Reliable Facility Location Problem", "comments": "Accepted at PPSN2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The reliable facility location problem (RFLP) is an important research topic\nof operational research and plays a vital role in the decision-making and\nmanagement of modern supply chain and logistics. Through solving RFLP, the\ndecision-maker can obtain reliable location decisions under the risk of\nfacilities' disruptions or failures. In this paper, we propose a novel model\nfor the RFLP. Instead of assuming allocating a fixed number of facilities to\neach customer as in the existing works, we set the number of allocated\nfacilities as an independent variable in our proposed model, which makes our\nmodel closer to the scenarios in real life but more difficult to be solved by\ntraditional methods. To handle it, we propose EAMLS, a hybrid evolutionary\nalgorithm, which combines a memorable local search (MLS) method and an\nevolutionary algorithm (EA). Additionally, a novel metric called l3-value is\nproposed to assist the analysis of the algorithm's convergence speed and exam\nthe process of evolution. The experimental results show the effectiveness and\nsuperior performance of our EAMLS, compared to a CPLEX solver and a Genetic\nAlgorithm (GA), on large-scale problems.\n", "versions": [{"version": "v1", "created": "Sat, 27 Jun 2020 11:31:55 GMT"}], "update_date": "2020-07-10", "authors_parsed": [["Zhang", "Han", ""], ["Liu", "Jialin", ""], ["Yao", "Xin", ""]]}, {"id": "2007.04785", "submitter": "Renqian Luo", "authors": "Renqian Luo, Xu Tan, Rui Wang, Tao Qin, Enhong Chen, Tie-Yan Liu", "title": "Accuracy Prediction with Non-neural Model for Neural Architecture Search", "comments": "Code is available at https://github.com/renqianluo/GBDT-NAS", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural architecture search (NAS) with an accuracy predictor that predicts the\naccuracy of candidate architectures has drawn increasing attention due to its\nsimplicity and effectiveness. Previous works usually employ neural\nnetwork-based predictors which require more delicate design and are easy to\noverfit. Considering that most architectures are represented as sequences of\ndiscrete symbols which are more like tabular data and preferred by non-neural\npredictors, in this paper, we study an alternative approach which uses\nnon-neural model for accuracy prediction. Specifically, as decision tree based\nmodels can better handle tabular data, we leverage gradient boosting decision\ntree (GBDT) as the predictor for NAS. We demonstrate that the GBDT predictor\ncan achieve comparable (if not better) prediction accuracy than neural network\nbased predictors. Moreover, considering that a compact search space can ease\nthe search process, we propose to prune the search space gradually according to\nimportant features derived from GBDT. In this way, NAS can be performed by\nfirst pruning the search space and then searching a neural architecture, which\nis more efficient and effective. Experiments on NASBench-101 and ImageNet\ndemonstrate the effectiveness of using GBDT as predictor for NAS: (1) On\nNASBench-101, it is 22x, 8x, and 6x more sample efficient than random search,\nregularized evolution, and Monte Carlo Tree Search (MCTS) in finding the global\noptimum; (2) It achieves 24.2% top-1 error rate on ImageNet, and further\nachieves 23.4% top-1 error rate on ImageNet when enhanced with search space\npruning. Code is provided at https://github.com/renqianluo/GBDT-NAS.\n", "versions": [{"version": "v1", "created": "Thu, 9 Jul 2020 13:28:49 GMT"}, {"version": "v2", "created": "Fri, 16 Jul 2021 11:43:02 GMT"}, {"version": "v3", "created": "Mon, 19 Jul 2021 07:31:57 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Luo", "Renqian", ""], ["Tan", "Xu", ""], ["Wang", "Rui", ""], ["Qin", "Tao", ""], ["Chen", "Enhong", ""], ["Liu", "Tie-Yan", ""]]}, {"id": "2007.04824", "submitter": "Fabrice Muhlenbach", "authors": "Fabrice Muhlenbach, Long Nguyen Phuoc and Isabelle Sayn", "title": "Predicting Court Decisions for Alimony: Avoiding Extra-legal Factors in\n  Decision made by Judges and Not Understandable AI Models", "comments": "Extended version of the poster accepted at the first ICML Workshop on\n  \"Law and Machine Learning\".\n  https://sites.google.com/view/icml-law-and-ml-2020/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The advent of machine learning techniques has made it possible to obtain\npredictive systems that have overturned traditional legal practices. However,\nrather than leading to systems seeking to replace humans, the search for the\ndeterminants in a court decision makes it possible to give a better\nunderstanding of the decision mechanisms carried out by the judge. By using a\nlarge amount of court decisions in matters of divorce produced by French\njurisdictions and by looking at the variables that allow to allocate an alimony\nor not, and to define its amount, we seek to identify if there may be\nextra-legal factors in the decisions taken by the judges. From this\nperspective, we present an explainable AI model designed in this purpose by\ncombining a classification with random forest and a regression model, as a\ncomplementary tool to existing decision-making scales or guidelines created by\npractitioners.\n", "versions": [{"version": "v1", "created": "Thu, 9 Jul 2020 14:14:20 GMT"}], "update_date": "2020-07-10", "authors_parsed": [["Muhlenbach", "Fabrice", ""], ["Phuoc", "Long Nguyen", ""], ["Sayn", "Isabelle", ""]]}, {"id": "2007.04848", "submitter": "Angus Main Mr", "authors": "Angus Main, Mick Grierson", "title": "Guru, Partner, or Pencil Sharpener? Understanding Designers' Attitudes\n  Towards Intelligent Creativity Support Tools", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Creativity Support Tools (CST) aim to enhance human creativity, but the\ndeeply personal and subjective nature of creativity makes the design of\nuniversal support tools challenging. Individuals develop personal approaches to\ncreativity, particularly in the context of commercial design where signature\nstyles and techniques are valuable commodities. Artificial Intelligence (AI)\nand Machine Learning (ML) techniques could provide a means of creating\n'intelligent' CST which learn and adapt to personal styles of creativity.\nIdentifying what kind of role such tools could play in the design process\nrequires a better understanding of designers' attitudes towards working with\nAI, and their willingness to include it in their personal creative process.\nThis paper details the results of a survey of professional designers which\nindicates a positive and pragmatic attitude towards collaborating with AI\ntools, and a particular opportunity for incorporating them in the research\nstages of a design project.\n", "versions": [{"version": "v1", "created": "Thu, 9 Jul 2020 14:52:52 GMT"}], "update_date": "2020-07-10", "authors_parsed": [["Main", "Angus", ""], ["Grierson", "Mick", ""]]}, {"id": "2007.04862", "submitter": "Lennart Bramlage", "authors": "Lennart Bramlage and Aurelio Cortese", "title": "Attention or memory? Neurointerpretable agents in space and time", "comments": "8 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In neuroscience, attention has been shown to bidirectionally interact with\nreinforcement learning (RL) processes. This interaction is thought to support\ndimensionality reduction of task representations, restricting computations to\nrelevant features. However, it remains unclear whether these properties can\ntranslate into real algorithmic advantages for artificial agents, especially in\ndynamic environments. We design a model incorporating a self-attention\nmechanism that implements task-state representations in semantic feature-space,\nand test it on a battery of Atari games. To evaluate the agent's selective\nproperties, we add a large volume of task-irrelevant features to observations.\nIn line with neuroscience predictions, self-attention leads to increased\nrobustness to noise compared to benchmark models. Strikingly, this\nself-attention mechanism is general enough, such that it can be naturally\nextended to implement a transient working-memory, able to solve a partially\nobservable maze task. Lastly, we highlight the predictive quality of attended\nstimuli. Because we use semantic observations, we can uncover not only which\nfeatures the agent elects to base decisions on, but also how it chooses to\ncompile more complex, relational features from simpler ones. These results\nformally illustrate the benefits of attention in deep RL and provide evidence\nfor the interpretability of self-attention mechanisms.\n", "versions": [{"version": "v1", "created": "Thu, 9 Jul 2020 15:04:26 GMT"}, {"version": "v2", "created": "Sun, 12 Jul 2020 15:32:16 GMT"}], "update_date": "2020-07-14", "authors_parsed": [["Bramlage", "Lennart", ""], ["Cortese", "Aurelio", ""]]}, {"id": "2007.04908", "submitter": "Rustam Rustam", "authors": "Rustam and Koredianto Usman and Mudyawati Kamaruddin and Dina Chamidah\n  and Nopendri and Khaerudin Saleh and Yulinda Eliskar and Ismail Marzuki", "title": "Modified Possibilistic Fuzzy C-Means Algorithm for Clustering Incomplete\n  Data Sets", "comments": "13 pages, 13 figures, submitted to Acta Polytechnica as scientific\n  journal published by the Czech Technical University in Prague", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Possibilistic fuzzy c-means (PFCM) algorithm is a reliable algorithm has been\nproposed to deal the weakness of two popular algorithms for clustering, fuzzy\nc-means (FCM) and possibilistic c-means (PCM). PFCM algorithm deals with the\nweaknesses of FCM in handling noise sensitivity and the weaknesses of PCM in\nthe case of coincidence clusters. However, the PFCM algorithm can be only\napplied to cluster complete data sets. Therefore, in this study, we propose a\nmodification of the PFCM algorithm that can be applied to incomplete data sets\nclustering. We modified the PFCM algorithm to OCSPFCM and NPSPFCM algorithms\nand measured performance on three things: 1) accuracy percentage, 2) a number\nof iterations to termination, and 3) centroid errors. Based on the results that\nboth algorithms have the potential for clustering incomplete data sets.\nHowever, the performance of the NPSPFCM algorithm is better than the OCSPFCM\nalgorithm for clustering incomplete data sets.\n", "versions": [{"version": "v1", "created": "Thu, 9 Jul 2020 16:12:11 GMT"}, {"version": "v2", "created": "Wed, 15 Jul 2020 23:37:09 GMT"}], "update_date": "2020-07-17", "authors_parsed": [["Rustam", "", ""], ["Usman", "Koredianto", ""], ["Kamaruddin", "Mudyawati", ""], ["Chamidah", "Dina", ""], ["Nopendri", "", ""], ["Saleh", "Khaerudin", ""], ["Eliskar", "Yulinda", ""], ["Marzuki", "Ismail", ""]]}, {"id": "2007.04916", "submitter": "Salom\\'on Wollenstein-Betech", "authors": "Salom\\'on Wollenstein-Betech, Christian Muise, Christos G. Cassandras,\n  Ioannis Ch. Paschalidis, Yasaman Khazaeni", "title": "Explainability of Intelligent Transportation Systems using Knowledge\n  Compilation: a Traffic Light Controller Case", "comments": "Proc. IEEE Int. Conf. on Intelligent Transportation Systems, Rhodes,\n  Greece, 2020. (In Press)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.HC cs.LO cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Usage of automated controllers which make decisions on an environment are\nwidespread and are often based on black-box models. We use Knowledge\nCompilation theory to bring explainability to the controller's decision given\nthe state of the system. For this, we use simulated historical state-action\ndata as input and build a compact and structured representation which relates\nstates with actions. We implement this method in a Traffic Light Control\nscenario where the controller selects the light cycle by observing the presence\n(or absence) of vehicles in different regions of the incoming roads.\n", "versions": [{"version": "v1", "created": "Thu, 9 Jul 2020 16:27:47 GMT"}], "update_date": "2020-07-10", "authors_parsed": [["Wollenstein-Betech", "Salom\u00f3n", ""], ["Muise", "Christian", ""], ["Cassandras", "Christos G.", ""], ["Paschalidis", "Ioannis Ch.", ""], ["Khazaeni", "Yasaman", ""]]}, {"id": "2007.04933", "submitter": "Luigi Asprino", "authors": "Luigi Asprino, Paolo Ciancarini, Andrea Giovanni Nuzzolese, Valentina\n  Presutti, Alessandro Russo", "title": "A Reference Software Architecture for Social Robots", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.RO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Social Robotics poses tough challenges to software designers who are required\nto take care of difficult architectural drivers like acceptability, trust of\nrobots as well as to guarantee that robots establish a personalised interaction\nwith their users. Moreover, in this context recurrent software design issues\nsuch as ensuring interoperability, improving reusability and customizability of\nsoftware components also arise.\n  Designing and implementing social robotic software architectures is a\ntime-intensive activity requiring multi-disciplinary expertise: this makes\ndifficult to rapidly develop, customise, and personalise robotic solutions.\n  These challenges may be mitigated at design time by choosing certain\narchitectural styles, implementing specific architectural patterns and using\nparticular technologies.\n  Leveraging on our experience in the MARIO project, in this paper we propose a\nseries of principles that social robots may benefit from. These principles lay\nalso the foundations for the design of a reference software architecture for\nSocial Robots. The ultimate goal of this work is to establish a common ground\nbased on a reference software architecture to allow to easily reuse robotic\nsoftware components in order to rapidly develop, implement, and personalise\nSocial Robots.\n", "versions": [{"version": "v1", "created": "Thu, 9 Jul 2020 17:03:21 GMT"}], "update_date": "2020-07-10", "authors_parsed": [["Asprino", "Luigi", ""], ["Ciancarini", "Paolo", ""], ["Nuzzolese", "Andrea Giovanni", ""], ["Presutti", "Valentina", ""], ["Russo", "Alessandro", ""]]}, {"id": "2007.04938", "submitter": "Kimin Lee", "authors": "Kimin Lee, Michael Laskin, Aravind Srinivas, Pieter Abbeel", "title": "SUNRISE: A Simple Unified Framework for Ensemble Learning in Deep\n  Reinforcement Learning", "comments": "ICML 2021 camera ready", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Off-policy deep reinforcement learning (RL) has been successful in a range of\nchallenging domains. However, standard off-policy RL algorithms can suffer from\nseveral issues, such as instability in Q-learning and balancing exploration and\nexploitation. To mitigate these issues, we present SUNRISE, a simple unified\nensemble method, which is compatible with various off-policy RL algorithms.\nSUNRISE integrates two key ingredients: (a) ensemble-based weighted Bellman\nbackups, which re-weight target Q-values based on uncertainty estimates from a\nQ-ensemble, and (b) an inference method that selects actions using the highest\nupper-confidence bounds for efficient exploration. By enforcing the diversity\nbetween agents using Bootstrap with random initialization, we show that these\ndifferent ideas are largely orthogonal and can be fruitfully integrated,\ntogether further improving the performance of existing off-policy RL\nalgorithms, such as Soft Actor-Critic and Rainbow DQN, for both continuous and\ndiscrete control tasks on both low-dimensional and high-dimensional\nenvironments. Our training code is available at\nhttps://github.com/pokaxpoka/sunrise.\n", "versions": [{"version": "v1", "created": "Thu, 9 Jul 2020 17:08:44 GMT"}, {"version": "v2", "created": "Tue, 21 Jul 2020 20:10:34 GMT"}, {"version": "v3", "created": "Wed, 9 Jun 2021 22:27:09 GMT"}, {"version": "v4", "created": "Fri, 11 Jun 2021 21:00:13 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Lee", "Kimin", ""], ["Laskin", "Michael", ""], ["Srinivas", "Aravind", ""], ["Abbeel", "Pieter", ""]]}, {"id": "2007.04949", "submitter": "Amal Nammouchi", "authors": "Amal Nammouchi, Hakim Ghazzai, and Yehia Massoud", "title": "A Generative Graph Method to Solve the Travelling Salesman Problem", "comments": "5 pages, 2 figures, 2 tables, conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Travelling Salesman Problem (TSP) is a challenging graph task in\ncombinatorial optimization that requires reasoning about both local node\nneighborhoods and global graph structure. In this paper, we propose to use the\nnovel Graph Learning Network (GLN), a generative approach, to approximately\nsolve the TSP. GLN model learns directly the pattern of TSP instances as\ntraining dataset, encodes the graph properties, and merge the different node\nembeddings to output node-to-node an optimal tour directly or via graph search\ntechnique that validates the final tour. The preliminary results of the\nproposed novel approach proves its applicability to this challenging problem\nproviding a low optimally gap with significant computation saving compared to\nthe optimal solution.\n", "versions": [{"version": "v1", "created": "Thu, 9 Jul 2020 17:23:55 GMT"}], "update_date": "2020-07-10", "authors_parsed": [["Nammouchi", "Amal", ""], ["Ghazzai", "Hakim", ""], ["Massoud", "Yehia", ""]]}, {"id": "2007.04950", "submitter": "Nitish Bhardwaj", "authors": "Alpana Dubey, Nitish Bhardwaj, Kumar Abhinav, Suma Mani Kuriakose,\n  Sakshi Jain and Veenu Arora", "title": "AI Assisted Apparel Design", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fashion is a fast-changing industry where designs are refreshed at large\nscale every season. Moreover, it faces huge challenge of unsold inventory as\nnot all designs appeal to customers. This puts designers under significant\npressure. Firstly, they need to create innumerous fresh designs. Secondly, they\nneed to create designs that appeal to customers. Although we see advancements\nin approaches to help designers analyzing consumers, often such insights are\ntoo many. Creating all possible designs with those insights is time consuming.\nIn this paper, we propose a system of AI assistants that assists designers in\ntheir design journey. The proposed system assists designers in analyzing\ndifferent selling/trending attributes of apparels. We propose two design\ngeneration assistants namely Apparel-Style-Merge and Apparel-Style-Transfer.\nApparel-Style-Merge generates new designs by combining high level components of\napparels whereas Apparel-Style-Transfer generates multiple customization of\napparels by applying different styles, colors and patterns. We compose a new\ndataset, named DeepAttributeStyle, with fine-grained annotation of landmarks of\ndifferent apparel components such as neck, sleeve etc. The proposed system is\nevaluated on a user group consisting of people with and without design\nbackground. Our evaluation result demonstrates that our approach generates high\nquality designs that can be easily used in fabrication. Moreover, the suggested\ndesigns aid to the designers creativity.\n", "versions": [{"version": "v1", "created": "Thu, 9 Jul 2020 17:24:40 GMT"}, {"version": "v2", "created": "Fri, 10 Jul 2020 17:14:17 GMT"}], "update_date": "2020-07-13", "authors_parsed": [["Dubey", "Alpana", ""], ["Bhardwaj", "Nitish", ""], ["Abhinav", "Kumar", ""], ["Kuriakose", "Suma Mani", ""], ["Jain", "Sakshi", ""], ["Arora", "Veenu", ""]]}, {"id": "2007.04973", "submitter": "Paras Jain", "authors": "Paras Jain, Ajay Jain, Tianjun Zhang, Pieter Abbeel, Joseph E.\n  Gonzalez, Ion Stoica", "title": "Contrastive Code Representation Learning", "comments": "Code available at https://github.com/parasj/contracode", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.PL cs.SE stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Recent work learns contextual representations of source code by\nreconstructing tokens from their context. For downstream semantic understanding\ntasks like summarizing code in English, these representations should ideally\ncapture program functionality. However, we show that the popular\nreconstruction-based BERT model is sensitive to source code edits, even when\nthe edits preserve semantics. We propose ContraCode: a contrastive pre-training\ntask that learns code functionality, not form. ContraCode pre-trains a neural\nnetwork to identify functionally similar variants of a program among many\nnon-equivalent distractors. We scalably generate these variants using an\nautomated source-to-source compiler as a form of data augmentation. Contrastive\npre-training improves JavaScript summarization and TypeScript type inference\naccuracy by 2% to 13%. We also propose a new zero-shot JavaScript code clone\ndetection dataset, showing that ContraCode is both more robust and semantically\nmeaningful. On it, we outperform RoBERTa by 39% AUROC in an adversarial setting\nand up to 5% on natural code.\n", "versions": [{"version": "v1", "created": "Thu, 9 Jul 2020 17:59:06 GMT"}, {"version": "v2", "created": "Fri, 9 Oct 2020 05:30:35 GMT"}, {"version": "v3", "created": "Thu, 15 Apr 2021 17:58:44 GMT"}], "update_date": "2021-04-16", "authors_parsed": [["Jain", "Paras", ""], ["Jain", "Ajay", ""], ["Zhang", "Tianjun", ""], ["Abbeel", "Pieter", ""], ["Gonzalez", "Joseph E.", ""], ["Stoica", "Ion", ""]]}, {"id": "2007.04979", "submitter": "Unnat Jain", "authors": "Unnat Jain, Luca Weihs, Eric Kolve, Ali Farhadi, Svetlana Lazebnik,\n  Aniruddha Kembhavi, Alexander Schwing", "title": "A Cordial Sync: Going Beyond Marginal Policies for Multi-Agent Embodied\n  Tasks", "comments": "Accepted to ECCV 2020 (spotlight); Project page:\n  https://unnat.github.io/cordial-sync", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Autonomous agents must learn to collaborate. It is not scalable to develop a\nnew centralized agent every time a task's difficulty outpaces a single agent's\nabilities. While multi-agent collaboration research has flourished in\ngridworld-like environments, relatively little work has considered visually\nrich domains. Addressing this, we introduce the novel task FurnMove in which\nagents work together to move a piece of furniture through a living room to a\ngoal. Unlike existing tasks, FurnMove requires agents to coordinate at every\ntimestep. We identify two challenges when training agents to complete FurnMove:\nexisting decentralized action sampling procedures do not permit expressive\njoint action policies and, in tasks requiring close coordination, the number of\nfailed actions dominates successful actions. To confront these challenges we\nintroduce SYNC-policies (synchronize your actions coherently) and CORDIAL\n(coordination loss). Using SYNC-policies and CORDIAL, our agents achieve a 58%\ncompletion rate on FurnMove, an impressive absolute gain of 25 percentage\npoints over competitive decentralized baselines. Our dataset, code, and\npretrained models are available at https://unnat.github.io/cordial-sync .\n", "versions": [{"version": "v1", "created": "Thu, 9 Jul 2020 17:59:57 GMT"}], "update_date": "2020-07-10", "authors_parsed": [["Jain", "Unnat", ""], ["Weihs", "Luca", ""], ["Kolve", "Eric", ""], ["Farhadi", "Ali", ""], ["Lazebnik", "Svetlana", ""], ["Kembhavi", "Aniruddha", ""], ["Schwing", "Alexander", ""]]}, {"id": "2007.05060", "submitter": "Yewen Pu", "authors": "Yewen Pu, Kevin Ellis, Marta Kryven, Josh Tenenbaum, Armando\n  Solar-Lezama", "title": "Program Synthesis with Pragmatic Communication", "comments": "The second author and the third author contributed equally to this\n  work", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Program synthesis techniques construct or infer programs from user-provided\nspecifications, such as input-output examples. Yet most specifications,\nespecially those given by end-users, leave the synthesis problem radically\nill-posed, because many programs may simultaneously satisfy the specification.\nPrior work resolves this ambiguity by using various inductive biases, such as a\npreference for simpler programs. This work introduces a new inductive bias\nderived by modeling the program synthesis task as rational communication,\ndrawing insights from recursive reasoning models of pragmatics. Given a\nspecification, we score a candidate program both on its consistency with the\nspecification, and also whether a rational speaker would chose this particular\nspecification to communicate that program. We develop efficient algorithms for\nsuch an approach when learning from input-output examples, and build a\npragmatic program synthesizer over a simple grid-like layout domain. A user\nstudy finds that end-user participants communicate more effectively with the\npragmatic program synthesizer over a non-pragmatic one.\n", "versions": [{"version": "v1", "created": "Thu, 9 Jul 2020 20:55:44 GMT"}, {"version": "v2", "created": "Tue, 20 Oct 2020 06:50:08 GMT"}, {"version": "v3", "created": "Wed, 21 Oct 2020 03:02:39 GMT"}], "update_date": "2020-10-22", "authors_parsed": [["Pu", "Yewen", ""], ["Ellis", "Kevin", ""], ["Kryven", "Marta", ""], ["Tenenbaum", "Josh", ""], ["Solar-Lezama", "Armando", ""]]}, {"id": "2007.05081", "submitter": "Girish Sathyanarayana", "authors": "Girish Sathyanarayana and Arun Patro", "title": "Intelligent Warehouse Allocator for Optimal Regional Utilization", "comments": "7 pages, 1 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we describe a novel solution to compute optimal warehouse\nallocations for fashion inventory. Procured inventory must be optimally\nallocated to warehouses in proportion to the regional demand around the\nwarehouse. This will ensure that demand is fulfilled by the nearest warehouse\nthereby minimizing the delivery logistics cost and delivery times. These are\nkey metrics to drive profitability and customer experience respectively.\nWarehouses have capacity constraints and allocations must minimize inter\nwarehouse redistribution cost of the inventory. This leads to maximum Regional\nUtilization (RU). We use machine learning and optimization methods to build an\nefficient solution to this warehouse allocation problem. We use machine\nlearning models to estimate the geographical split of the demand for every\nproduct. We use Integer Programming methods to compute the optimal feasible\nwarehouse allocations considering the capacity constraints. We conduct a\nback-testing by using this solution and validate the efficiency of this model\nby demonstrating a significant uptick in two key metrics Regional Utilization\n(RU) and Percentage Two-day-delivery (2DD). We use this process to\nintelligently create purchase orders with warehouse assignments for Myntra, a\nleading online fashion retailer.\n", "versions": [{"version": "v1", "created": "Thu, 9 Jul 2020 21:46:15 GMT"}], "update_date": "2020-07-13", "authors_parsed": [["Sathyanarayana", "Girish", ""], ["Patro", "Arun", ""]]}, {"id": "2007.05096", "submitter": "Quinlan Sykora", "authors": "Quinlan Sykora, Mengye Ren, Raquel Urtasun", "title": "Multi-Agent Routing Value Iteration Network", "comments": "Published at ICML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.MA cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we tackle the problem of routing multiple agents in a\ncoordinated manner. This is a complex problem that has a wide range of\napplications in fleet management to achieve a common goal, such as mapping from\na swarm of robots and ride sharing. Traditional methods are typically not\ndesigned for realistic environments hich contain sparsely connected graphs and\nunknown traffic, and are often too slow in runtime to be practical. In\ncontrast, we propose a graph neural network based model that is able to perform\nmulti-agent routing based on learned value iteration in a sparsely connected\ngraph with dynamically changing traffic conditions. Moreover, our learned\ncommunication module enables the agents to coordinate online and adapt to\nchanges more effectively. We created a simulated environment to mimic realistic\nmapping performed by autonomous vehicles with unknown minimum edge coverage and\ntraffic conditions; our approach significantly outperforms traditional solvers\nboth in terms of total cost and runtime. We also show that our model trained\nwith only two agents on graphs with a maximum of 25 nodes can easily generalize\nto situations with more agents and/or nodes.\n", "versions": [{"version": "v1", "created": "Thu, 9 Jul 2020 22:16:45 GMT"}, {"version": "v2", "created": "Fri, 14 Aug 2020 18:08:25 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Sykora", "Quinlan", ""], ["Ren", "Mengye", ""], ["Urtasun", "Raquel", ""]]}, {"id": "2007.05156", "submitter": "Rongye Shi", "authors": "Xuan Di and Rongye Shi", "title": "A Survey on Autonomous Vehicle Control in the Era of Mixed-Autonomy:\n  From Physics-Based to AI-Guided Driving Policy Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper serves as an introduction and overview of the potentially useful\nmodels and methodologies from artificial intelligence (AI) into the field of\ntransportation engineering for autonomous vehicle (AV) control in the era of\nmixed autonomy. We will discuss state-of-the-art applications of AI-guided\nmethods, identify opportunities and obstacles, raise open questions, and help\nsuggest the building blocks and areas where AI could play a role in mixed\nautonomy. We divide the stage of autonomous vehicle (AV) deployment into four\nphases: the pure HVs, the HV-dominated, the AVdominated, and the pure AVs. This\npaper is primarily focused on the latter three phases. It is the\nfirst-of-its-kind survey paper to comprehensively review literature in both\ntransportation engineering and AI for mixed traffic modeling. Models used for\neach phase are summarized, encompassing game theory, deep (reinforcement)\nlearning, and imitation learning. While reviewing the methodologies, we\nprimarily focus on the following research questions: (1) What scalable driving\npolicies are to control a large number of AVs in mixed traffic comprised of\nhuman drivers and uncontrollable AVs? (2) How do we estimate human driver\nbehaviors? (3) How should the driving behavior of uncontrollable AVs be modeled\nin the environment? (4) How are the interactions between human drivers and\nautonomous vehicles characterized? Hopefully this paper will not only inspire\nour transportation community to rethink the conventional models that are\ndeveloped in the data-shortage era, but also reach out to other disciplines, in\nparticular robotics and machine learning, to join forces towards creating a\nsafe and efficient mixed traffic ecosystem.\n", "versions": [{"version": "v1", "created": "Fri, 10 Jul 2020 04:27:39 GMT"}], "update_date": "2020-07-13", "authors_parsed": [["Di", "Xuan", ""], ["Shi", "Rongye", ""]]}, {"id": "2007.05179", "submitter": "Somaiyeh MahmoudZadeh", "authors": "Adham Atyabi, Somaiyeh MahmoudZadeh, Samia Nefti-Meziani", "title": "Current Advancements on Autonomous Mission Planning and Management\n  Systems: an AUV and UAV perspective", "comments": null, "journal-ref": "Journal of Annual Reviews in Control, Volume, 46, P.196-215, 2018", "doi": "10.1016/j.arcontrol.2018.07.002", "report-no": null, "categories": "cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Advances in hardware technology have enabled more integration of\nsophisticated software, triggering progress in the development and employment\nof Unmanned Vehicles (UVs), and mitigating restraints for onboard intelligence.\nAs a result, UVs can now take part in more complex mission where continuous\ntransformation in environmental condition calls for a higher level of\nsituational responsiveness. This paper serves as an introduction to UVs mission\nplanning and management systems aiming to highlight some of the recent\ndevelopments in the field of autonomous underwater and aerial vehicles in\naddition to stressing some possible future directions and discussing the\nlearned lessons. A comprehensive survey over autonomy assessment of UVs, and\ndifferent aspects of autonomy such as situation awareness, cognition, and\ndecision-making has been provided in this study. The paper separately explains\nthe humanoid and autonomous system's performance and highlights the role and\nimpact of a human in UVs operations.\n", "versions": [{"version": "v1", "created": "Fri, 10 Jul 2020 05:56:34 GMT"}], "update_date": "2020-07-13", "authors_parsed": [["Atyabi", "Adham", ""], ["MahmoudZadeh", "Somaiyeh", ""], ["Nefti-Meziani", "Samia", ""]]}, {"id": "2007.05196", "submitter": "Matthias Hutsebaut-Buysse", "authors": "Matthias Hutsebaut-Buysse, Kevin Mets, Steven Latr\\'e", "title": "Pre-trained Word Embeddings for Goal-conditional Transfer Learning in\n  Reinforcement Learning", "comments": "Paper accepted to the ICML 2020 Language in Reinforcement Learning\n  (LaReL) Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning (RL) algorithms typically start tabula rasa, without\nany prior knowledge of the environment, and without any prior skills. This\nhowever often leads to low sample efficiency, requiring a large amount of\ninteraction with the environment. This is especially true in a lifelong\nlearning setting, in which the agent needs to continually extend its\ncapabilities. In this paper, we examine how a pre-trained task-independent\nlanguage model can make a goal-conditional RL agent more sample efficient. We\ndo this by facilitating transfer learning between different related tasks. We\nexperimentally demonstrate our approach on a set of object navigation tasks.\n", "versions": [{"version": "v1", "created": "Fri, 10 Jul 2020 06:42:00 GMT"}], "update_date": "2020-07-13", "authors_parsed": [["Hutsebaut-Buysse", "Matthias", ""], ["Mets", "Kevin", ""], ["Latr\u00e9", "Steven", ""]]}, {"id": "2007.05234", "submitter": "Alexander Fraser", "authors": "Anita Ramm, Ekaterina Lapshinova-Koltunski, Alexander Fraser", "title": "Pragmatic information in translation: a corpus-based study of tense and\n  mood in English and German", "comments": "Technical Report of CIS, LMU Munich. September 19th, 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Grammatical tense and mood are important linguistic phenomena to consider in\nnatural language processing (NLP) research. We consider the correspondence\nbetween English and German tense and mood in translation. Human translators do\nnot find this correspondence easy, and as we will show through careful\nanalysis, there are no simplistic ways to map tense and mood from one language\nto another. Our observations about the challenges of human translation of tense\nand mood have important implications for multilingual NLP. Of particular\nimportance is the challenge of modeling tense and mood in rule-based,\nphrase-based statistical and neural machine translation.\n", "versions": [{"version": "v1", "created": "Fri, 10 Jul 2020 08:15:59 GMT"}], "update_date": "2020-07-13", "authors_parsed": [["Ramm", "Anita", ""], ["Lapshinova-Koltunski", "Ekaterina", ""], ["Fraser", "Alexander", ""]]}, {"id": "2007.05254", "submitter": "Wu Qinghua", "authors": "Yongliang Lu, Jin-Kao Hao, Qinghua Wu", "title": "Solving the Clustered Traveling Salesman Problem via TSP methods", "comments": "23 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Clustered Traveling Salesman Problem (CTSP) is a variant of the popular\nTraveling Salesman Problem (TSP) arising from a number of real-life\napplications. In this work, we explore an uncharted solution approach that\nsolves the CTSP by transforming it to the well-studied TSP. For this purpose,\nwe first investigate a technique to convert a CTSP instance to a TSP and then\napply popular TSP solvers (including exact and heuristic solvers) to solve the\nresulting TSP instance. We want to answer the following questions: How do\nstate-of-the-art TSP solvers perform on clustered instances converted from the\nCTSP? Do state-of-the-art TSP solvers compete well with the best performing\nmethods specifically designed for the CTSP? For this purpose, we present\nintensive computational experiments on various benchmark instances to draw\nconclusions.\n", "versions": [{"version": "v1", "created": "Fri, 10 Jul 2020 08:56:06 GMT"}, {"version": "v2", "created": "Tue, 15 Dec 2020 08:35:00 GMT"}], "update_date": "2020-12-16", "authors_parsed": [["Lu", "Yongliang", ""], ["Hao", "Jin-Kao", ""], ["Wu", "Qinghua", ""]]}, {"id": "2007.05270", "submitter": "Edward Beeching", "authors": "Edward Beeching and Jilles Dibangoye and Olivier Simonin and Christian\n  Wolf", "title": "Learning to plan with uncertain topological maps", "comments": "ECCV 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We train an agent to navigate in 3D environments using a hierarchical\nstrategy including a high-level graph based planner and a local policy. Our\nmain contribution is a data driven learning based approach for planning under\nuncertainty in topological maps, requiring an estimate of shortest paths in\nvalued graphs with a probabilistic structure. Whereas classical symbolic\nalgorithms achieve optimal results on noise-less topologies, or optimal results\nin a probabilistic sense on graphs with probabilistic structure, we aim to show\nthat machine learning can overcome missing information in the graph by taking\ninto account rich high-dimensional node features, for instance visual\ninformation available at each location of the map. Compared to purely learned\nneural white box algorithms, we structure our neural model with an inductive\nbias for dynamic programming based shortest path algorithms, and we show that a\nparticular parameterization of our neural model corresponds to the Bellman-Ford\nalgorithm. By performing an empirical analysis of our method in simulated\nphoto-realistic 3D environments, we demonstrate that the inclusion of visual\nfeatures in the learned neural planner outperforms classical symbolic solutions\nfor graph based planning.\n", "versions": [{"version": "v1", "created": "Fri, 10 Jul 2020 09:28:30 GMT"}], "update_date": "2020-07-13", "authors_parsed": [["Beeching", "Edward", ""], ["Dibangoye", "Jilles", ""], ["Simonin", "Olivier", ""], ["Wolf", "Christian", ""]]}, {"id": "2007.05271", "submitter": "Pier Giuseppe Sessa", "authors": "Pier Giuseppe Sessa, Ilija Bogunovic, Maryam Kamgarpour, Andreas\n  Krause", "title": "Learning to Play Sequential Games versus Unknown Opponents", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a repeated sequential game between a learner, who plays first,\nand an opponent who responds to the chosen action. We seek to design strategies\nfor the learner to successfully interact with the opponent. While most previous\napproaches consider known opponent models, we focus on the setting in which the\nopponent's model is unknown. To this end, we use kernel-based regularity\nassumptions to capture and exploit the structure in the opponent's response. We\npropose a novel algorithm for the learner when playing against an adversarial\nsequence of opponents. The algorithm combines ideas from bilevel optimization\nand online learning to effectively balance between exploration (learning about\nthe opponent's model) and exploitation (selecting highly rewarding actions for\nthe learner). Our results include algorithm's regret guarantees that depend on\nthe regularity of the opponent's response and scale sublinearly with the number\nof game rounds. Moreover, we specialize our approach to repeated Stackelberg\ngames, and empirically demonstrate its effectiveness in a traffic routing and\nwildlife conservation task\n", "versions": [{"version": "v1", "created": "Fri, 10 Jul 2020 09:33:05 GMT"}], "update_date": "2020-07-13", "authors_parsed": [["Sessa", "Pier Giuseppe", ""], ["Bogunovic", "Ilija", ""], ["Kamgarpour", "Maryam", ""], ["Krause", "Andreas", ""]]}, {"id": "2007.05284", "submitter": "Guilherme Paulino-Passos", "authors": "Guilherme Paulino-Passos, Francesca Toni", "title": "Cautious Monotonicity in Case-Based Reasoning with Abstract\n  Argumentation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, abstract argumentation-based models of case-based reasoning\n($AA{\\text -}CBR$ in short) have been proposed, originally inspired by the\nlegal domain, but also applicable as classifiers in different scenarios,\nincluding image classification, sentiment analysis of text, and in predicting\nthe passage of bills in the UK Parliament. However, the formal properties of\n$AA{\\text -}CBR$ as a reasoning system remain largely unexplored. In this\npaper, we focus on analysing the non-monotonicity properties of a regular\nversion of $AA{\\text -}CBR$ (that we call $AA{\\text -}CBR_{\\succeq}$).\nSpecifically, we prove that $AA{\\text -}CBR_{\\succeq}$ is not cautiously\nmonotonic, a property frequently considered desirable in the literature of\nnon-monotonic reasoning. We then define a variation of $AA{\\text\n-}CBR_{\\succeq}$ which is cautiously monotonic, and provide an algorithm for\nobtaining it. Further, we prove that such variation is equivalent to using\n$AA{\\text -}CBR_{\\succeq}$ with a restricted casebase consisting of all\n\"surprising\" cases in the original casebase.\n", "versions": [{"version": "v1", "created": "Fri, 10 Jul 2020 10:08:30 GMT"}, {"version": "v2", "created": "Mon, 13 Jul 2020 07:42:11 GMT"}], "update_date": "2020-07-14", "authors_parsed": [["Paulino-Passos", "Guilherme", ""], ["Toni", "Francesca", ""]]}, {"id": "2007.05292", "submitter": "Yushan Liu", "authors": "Yushan Liu, Marcel Hildebrandt, Mitchell Joblin, Martin Ringsquandl,\n  Volker Tresp", "title": "Integrating Logical Rules Into Neural Multi-Hop Reasoning for Drug\n  Repurposing", "comments": "Accepted at the ICML 2020 Workshop Graph Representation Learning and\n  Beyond (GRL+)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The graph structure of biomedical data differs from those in typical\nknowledge graph benchmark tasks. A particular property of biomedical data is\nthe presence of long-range dependencies, which can be captured by patterns\ndescribed as logical rules. We propose a novel method that combines these rules\nwith a neural multi-hop reasoning approach that uses reinforcement learning. We\nconduct an empirical study based on the real-world task of drug repurposing by\nformulating this task as a link prediction problem. We apply our method to the\nbiomedical knowledge graph Hetionet and show that our approach outperforms\nseveral baseline methods.\n", "versions": [{"version": "v1", "created": "Fri, 10 Jul 2020 10:32:08 GMT"}], "update_date": "2020-07-13", "authors_parsed": [["Liu", "Yushan", ""], ["Hildebrandt", "Marcel", ""], ["Joblin", "Mitchell", ""], ["Ringsquandl", "Martin", ""], ["Tresp", "Volker", ""]]}, {"id": "2007.05367", "submitter": "Richard Evans", "authors": "Richard Evans, Jose Hernandez-Orallo, Johannes Welbl, Pushmeet Kohli,\n  Marek Sergot", "title": "Evaluating the Apperception Engine", "comments": "arXiv admin note: substantial text overlap with arXiv:1910.02227", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Apperception Engine is an unsupervised learning system. Given a sequence\nof sensory inputs, it constructs a symbolic causal theory that both explains\nthe sensory sequence and also satisfies a set of unity conditions. The unity\nconditions insist that the constituents of the theory - objects, properties,\nand laws - must be integrated into a coherent whole. Once a theory has been\nconstructed, it can be applied to predict future sensor readings, retrodict\nearlier readings, or impute missing readings.\n  In this paper, we evaluate the Apperception Engine in a diverse variety of\ndomains, including cellular automata, rhythms and simple nursery tunes,\nmulti-modal binding problems, occlusion tasks, and sequence induction\nintelligence tests. In each domain, we test our engine's ability to predict\nfuture sensor values, retrodict earlier sensor values, and impute missing\nsensory data. The engine performs well in all these domains, significantly\noutperforming neural net baselines and state of the art inductive logic\nprogramming systems. These results are significant because neural nets\ntypically struggle to solve the binding problem (where information from\ndifferent modalities must somehow be combined together into different aspects\nof one unified object) and fail to solve occlusion tasks (in which objects are\nsometimes visible and sometimes obscured from view). We note in particular that\nin the sequence induction intelligence tests, our system achieved human-level\nperformance. This is notable because our system is not a bespoke system\ndesigned specifically to solve intelligence tests, but a general-purpose system\nthat was designed to make sense of any sensory sequence.\n", "versions": [{"version": "v1", "created": "Thu, 9 Jul 2020 11:54:05 GMT"}], "update_date": "2020-07-13", "authors_parsed": [["Evans", "Richard", ""], ["Hernandez-Orallo", "Jose", ""], ["Welbl", "Johannes", ""], ["Kohli", "Pushmeet", ""], ["Sergot", "Marek", ""]]}, {"id": "2007.05402", "submitter": "Sean Yi", "authors": "Jinho Lee, Raehyun Kim, Seok-Won Yi, Jaewoo Kang", "title": "MAPS: Multi-agent Reinforcement Learning-based Portfolio Management\n  System", "comments": "7 pages, 5 figures, IJCAI-PRICAI 2020", "journal-ref": null, "doi": "10.24963/ijcai.2020/623", "report-no": null, "categories": "cs.AI cs.CE cs.LG cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generating an investment strategy using advanced deep learning methods in\nstock markets has recently been a topic of interest. Most existing deep\nlearning methods focus on proposing an optimal model or network architecture by\nmaximizing return. However, these models often fail to consider and adapt to\nthe continuously changing market conditions. In this paper, we propose the\nMulti-Agent reinforcement learning-based Portfolio management System (MAPS).\nMAPS is a cooperative system in which each agent is an independent \"investor\"\ncreating its own portfolio. In the training procedure, each agent is guided to\nact as diversely as possible while maximizing its own return with a carefully\ndesigned loss function. As a result, MAPS as a system ends up with a\ndiversified portfolio. Experiment results with 12 years of US market data show\nthat MAPS outperforms most of the baselines in terms of Sharpe ratio.\nFurthermore, our results show that adding more agents to our system would allow\nus to get a higher Sharpe ratio by lowering risk with a more diversified\nportfolio.\n", "versions": [{"version": "v1", "created": "Fri, 10 Jul 2020 14:08:12 GMT"}], "update_date": "2020-07-13", "authors_parsed": [["Lee", "Jinho", ""], ["Kim", "Raehyun", ""], ["Yi", "Seok-Won", ""], ["Kang", "Jaewoo", ""]]}, {"id": "2007.05408", "submitter": "Umang Bhatt", "authors": "Umang Bhatt, McKane Andrus, Adrian Weller, Alice Xiang", "title": "Machine Learning Explainability for External Stakeholders", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As machine learning is increasingly deployed in high-stakes contexts\naffecting people's livelihoods, there have been growing calls to open the black\nbox and to make machine learning algorithms more explainable. Providing useful\nexplanations requires careful consideration of the needs of stakeholders,\nincluding end-users, regulators, and domain experts. Despite this need, little\nwork has been done to facilitate inter-stakeholder conversation around\nexplainable machine learning. To help address this gap, we conducted a\nclosed-door, day-long workshop between academics, industry experts, legal\nscholars, and policymakers to develop a shared language around explainability\nand to understand the current shortcomings of and potential solutions for\ndeploying explainable machine learning in service of transparency goals. We\nalso asked participants to share case studies in deploying explainable machine\nlearning at scale. In this paper, we provide a short summary of various case\nstudies of explainable machine learning, lessons from those studies, and\ndiscuss open challenges.\n", "versions": [{"version": "v1", "created": "Fri, 10 Jul 2020 14:27:06 GMT"}], "update_date": "2020-07-13", "authors_parsed": [["Bhatt", "Umang", ""], ["Andrus", "McKane", ""], ["Weller", "Adrian", ""], ["Xiang", "Alice", ""]]}, {"id": "2007.05411", "submitter": "Koen Holtman", "authors": "Koen Holtman", "title": "AGI Agent Safety by Iteratively Improving the Utility Function", "comments": "Part 1 of this work is a preprint of a conference paper to appear in:\n  Proceedings of the 13th International Conference on Artificial General\n  Intelligence (AGI-20), Springer LNAI 12177 (2020). Part 2 has additional, new\n  research results that go beyond those in the conference paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While it is still unclear if agents with Artificial General Intelligence\n(AGI) could ever be built, we can already use mathematical models to\ninvestigate potential safety systems for these agents. We present an AGI safety\nlayer that creates a special dedicated input terminal to support the iterative\nimprovement of an AGI agent's utility function. The humans who switched on the\nagent can use this terminal to close any loopholes that are discovered in the\nutility function's encoding of agent goals and constraints, to direct the agent\ntowards new goals, or to force the agent to switch itself off. An AGI agent may\ndevelop the emergent incentive to manipulate the above utility function\nimprovement process, for example by deceiving, restraining, or even attacking\nthe humans involved. The safety layer will partially, and sometimes fully,\nsuppress this dangerous incentive. The first part of this paper generalizes\nearlier work on AGI emergency stop buttons. We aim to make the mathematical\nmethods used to construct the layer more accessible, by applying them to an MDP\nmodel. We discuss two provable properties of the safety layer, and show ongoing\nwork in mapping it to a Causal Influence Diagram (CID). In the second part, we\ndevelop full mathematical proofs, and show that the safety layer creates a type\nof bureaucratic blindness. We then present the design of a learning agent, a\ndesign that wraps the safety layer around either a known machine learning\nsystem, or a potential future AGI-level learning system. The resulting agent\nwill satisfy the provable safety properties from the moment it is first\nswitched on. Finally, we show how this agent can be mapped from its model to a\nreal-life implementation. We review the methodological issues involved in this\nstep, and discuss how these are typically resolved.\n", "versions": [{"version": "v1", "created": "Fri, 10 Jul 2020 14:30:56 GMT"}], "update_date": "2020-07-13", "authors_parsed": [["Holtman", "Koen", ""]]}, {"id": "2007.05423", "submitter": "Mikael Zayenz Lagerkvist", "authors": "Mikael Zayenz Lagerkvist and Magnus Rattfeldt", "title": "Half-checking propagators", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Propagators are central to the success of constraint programming, that is\ncontracting functions removing values proven not to be in any solution of a\ngiven constraint. The literature contains numerous propagation algorithms, for\nmany different constraints, and common to all these propagation algorithms is\nthe notion of correctness: only values that appear in no solution to the\nrespective constraint may be removed. In this paper half-checking propagators\nare introduced, for which the only requirements are that identified solutions\n(by the propagators) are actual solutions (to the corresponding constraints),\nand that the propagators are contracting. In particular, a half-checking\npropagator may remove solutions resulting in an incomplete solving process, but\nwith the upside that (good) solutions may be found faster. Overall completeness\ncan be obtained by running half-checking propagators as one component in a\nportfolio solving process. Half-checking propagators opens up a wider variety\nof techniques to be used when designing propagation algorithms, compared to\nwhat is currently available.\n  A formal model for half-checking propagators is introduced, together with a\ndetailed description of how to support such propagators in a constraint\nprogramming system. Three general directions for creating half-checking\npropagation algorithms are introduced, and used for designing new half-checking\npropagators for the cost-circuit constraint as examples. The new propagators\nare implemented in the Gecode system.\n", "versions": [{"version": "v1", "created": "Fri, 10 Jul 2020 14:54:57 GMT"}], "update_date": "2020-07-13", "authors_parsed": [["Lagerkvist", "Mikael Zayenz", ""], ["Rattfeldt", "Magnus", ""]]}, {"id": "2007.05443", "submitter": "Hansol Lee", "authors": "Ren\\'e F. Kizilcec and Hansol Lee", "title": "Algorithmic Fairness in Education", "comments": "Forthcoming in W. Holmes & K. Porayska-Pomsta (Eds.), Ethics in\n  Artificial Intelligence in Education, Taylor & Francis", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data-driven predictive models are increasingly used in education to support\nstudents, instructors, and administrators. However, there are concerns about\nthe fairness of the predictions and uses of these algorithmic systems. In this\nintroduction to algorithmic fairness in education, we draw parallels to prior\nliterature on educational access, bias, and discrimination, and we examine core\ncomponents of algorithmic systems (measurement, model learning, and action) to\nidentify sources of bias and discrimination in the process of developing and\ndeploying these systems. Statistical, similarity-based, and causal notions of\nfairness are reviewed and contrasted in the way they apply in educational\ncontexts. Recommendations for policy makers and developers of educational\ntechnology offer guidance for how to promote algorithmic fairness in education.\n", "versions": [{"version": "v1", "created": "Fri, 10 Jul 2020 15:35:10 GMT"}, {"version": "v2", "created": "Fri, 18 Sep 2020 01:25:59 GMT"}, {"version": "v3", "created": "Sun, 11 Apr 2021 15:22:14 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Kizilcec", "Ren\u00e9 F.", ""], ["Lee", "Hansol", ""]]}, {"id": "2007.05460", "submitter": "Ranwa Al Mallah", "authors": "Ranwa Al Mallah, Bilal Farooq, Alejandro Quintero", "title": "Prediction of Traffic Flow via Connected Vehicles", "comments": null, "journal-ref": null, "doi": "10.1109/TMC.2020.3006713", "report-no": null, "categories": "cs.NI cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a Short-term Traffic flow Prediction (STP) framework so that\ntransportation authorities take early actions to control flow and prevent\ncongestion. We anticipate flow at future time frames on a target road segment\nbased on historical flow data and innovative features such as real time feeds\nand trajectory data provided by Connected Vehicles (CV) technology. To cope\nwith the fact that existing approaches do not adapt to variation in traffic, we\nshow how this novel approach allows advanced modelling by integrating into the\nforecasting of flow, the impact of the various events that CV realistically\nencountered on segments along their trajectory. We solve the STP problem with a\nDeep Neural Networks (DNN) in a multitask learning setting augmented by input\nfrom CV. Results show that our approach, namely MTL-CV, with an average\nRoot-Mean-Square Error (RMSE) of 0.052, outperforms state-of-the-art ARIMA time\nseries (RMSE of 0.255) and baseline classifiers (RMSE of 0.122). Compared to\nsingle task learning with Artificial Neural Network (ANN), ANN had a lower\nperformance, 0.113 for RMSE, than MTL-CV. MTL-CV learned historical\nsimilarities between segments, in contrast to using direct historical trends in\nthe measure, because trends may not exist in the measure but do in the\nsimilarities.\n", "versions": [{"version": "v1", "created": "Fri, 10 Jul 2020 16:00:44 GMT"}, {"version": "v2", "created": "Fri, 4 Dec 2020 17:06:56 GMT"}], "update_date": "2020-12-07", "authors_parsed": [["Mallah", "Ranwa Al", ""], ["Farooq", "Bilal", ""], ["Quintero", "Alejandro", ""]]}, {"id": "2007.05479", "submitter": "Adrien Bibal", "authors": "Adrien Bibal, Michael Lognoul, Alexandre de Streel and Beno\\^it\n  Fr\\'enay", "title": "Impact of Legal Requirements on Explainability in Machine Learning", "comments": "ICML Workshop on Law and Machine Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The requirements on explainability imposed by European laws and their\nimplications for machine learning (ML) models are not always clear. In that\nperspective, our research analyzes explanation obligations imposed for private\nand public decision-making, and how they can be implemented by machine learning\ntechniques.\n", "versions": [{"version": "v1", "created": "Fri, 10 Jul 2020 16:57:18 GMT"}], "update_date": "2020-07-13", "authors_parsed": [["Bibal", "Adrien", ""], ["Lognoul", "Michael", ""], ["de Streel", "Alexandre", ""], ["Fr\u00e9nay", "Beno\u00eet", ""]]}, {"id": "2007.05505", "submitter": "Chetan Bansal", "authors": "Manish Shetty, Chetan Bansal, Sumit Kumar, Nikitha Rao, Nachiappan\n  Nagappan, Thomas Zimmermann", "title": "Neural Knowledge Extraction From Cloud Service Incidents", "comments": "To be published in the proceedings of ICSE 2021 - Software\n  Engineering in Practice Track", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.AI cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the last decade, two paradigm shifts have reshaped the software industry -\nthe move from boxed products to services and the widespread adoption of cloud\ncomputing. This has had a huge impact on the software development life cycle\nand the DevOps processes. Particularly, incident management has become critical\nfor developing and operating large-scale services. Incidents are created to\nensure timely communication of service issues and, also, their resolution.\nPrior work on incident management has been heavily focused on the challenges\nwith incident triaging and de-duplication. In this work, we address the\nfundamental problem of structured knowledge extraction from service incidents.\nWe have built SoftNER, a framework for unsupervised knowledge extraction from\nservice incidents. We frame the knowledge extraction problem as a Named-entity\nRecognition task for extracting factual information. SoftNER leverages\nstructural patterns like key,value pairs and tables for bootstrapping the\ntraining data. Further, we build a novel multi-task learning based BiLSTM-CRF\nmodel which leverages not just the semantic context but also the data-types for\nnamed-entity extraction. We have deployed SoftNER at Microsoft, a major cloud\nservice provider and have evaluated it on more than 2 months of cloud\nincidents. We show that the unsupervised machine learning based approach has a\nhigh precision of 0.96. Our multi-task learning based deep learning model also\noutperforms the state of the art NER models. Lastly, using the knowledge\nextracted by SoftNER we are able to build significantly more accurate models\nfor important downstream tasks like incident triaging.\n", "versions": [{"version": "v1", "created": "Fri, 10 Jul 2020 17:33:07 GMT"}, {"version": "v2", "created": "Tue, 14 Jul 2020 06:47:23 GMT"}, {"version": "v3", "created": "Wed, 15 Jul 2020 07:07:03 GMT"}, {"version": "v4", "created": "Fri, 15 Jan 2021 21:56:16 GMT"}], "update_date": "2021-01-19", "authors_parsed": [["Shetty", "Manish", ""], ["Bansal", "Chetan", ""], ["Kumar", "Sumit", ""], ["Rao", "Nikitha", ""], ["Nagappan", "Nachiappan", ""], ["Zimmermann", "Thomas", ""]]}, {"id": "2007.05516", "submitter": "Pavan Ravishankar", "authors": "Pavan Ravishankar, Pranshu Malviya, Balaraman Ravindran", "title": "A Causal Linear Model to Quantify Edge Flow and Edge Unfairness for\n  UnfairEdge Prioritization and Discrimination Removal", "comments": "Accepted in the Workshop on Law and Machine Learning, ICML 2020;\n  First two authors contributed equally", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Law enforcement must prioritize sources of unfairness before mitigating their\nunderlying unfairness, considering that they have limited resources. Unlike\nprevious works that only make cautionary claims of discrimination and de-biases\ndata after its generation, this paper attempts to prioritize unfair sources\nbefore mitigating their unfairness in the real-world. We assume that a causal\nbayesian network, representative of the data generation procedure, along with\nthe sensitive nodes, that result in unfairness, are given. We quantify Edge\nFlow, which is the belief flowing along an edge by attenuating the indirect\npath influences, and use it to quantify Edge Unfairness. We prove that\ncumulative unfairness is non-existent in any decision, like judicial bail,\ntowards any sensitive groups, like race, when the edge unfairness is absent,\ngiven an error-free linear model of conditional probability. We then measure\nthe potential to mitigate the cumulative unfairness when edge unfairness is\ndecreased. Based on these measures, we propose an unfair edge prioritization\nalgorithm that prioritizes the unfair edges and a discrimination removal\nprocedure that de-biases the generated data distribution. The experimental\nsection validates the specifications used for quantifying the above measures.\n", "versions": [{"version": "v1", "created": "Fri, 10 Jul 2020 17:50:41 GMT"}, {"version": "v2", "created": "Thu, 16 Jul 2020 17:02:58 GMT"}, {"version": "v3", "created": "Thu, 10 Sep 2020 17:50:23 GMT"}, {"version": "v4", "created": "Thu, 11 Mar 2021 05:35:15 GMT"}], "update_date": "2021-03-12", "authors_parsed": [["Ravishankar", "Pavan", ""], ["Malviya", "Pranshu", ""], ["Ravindran", "Balaraman", ""]]}, {"id": "2007.05520", "submitter": "Dibya Ghosh", "authors": "Dibya Ghosh, Marc G. Bellemare", "title": "Representations for Stable Off-Policy Reinforcement Learning", "comments": "ICML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning with function approximation can be unstable and even\ndivergent, especially when combined with off-policy learning and Bellman\nupdates. In deep reinforcement learning, these issues have been dealt with\nempirically by adapting and regularizing the representation, in particular with\nauxiliary tasks. This suggests that representation learning may provide a means\nto guarantee stability. In this paper, we formally show that there are indeed\nnontrivial state representations under which the canonical TD algorithm is\nstable, even when learning off-policy. We analyze representation learning\nschemes that are based on the transition matrix of a policy, such as\nproto-value functions, along three axes: approximation error, stability, and\nease of estimation. In the most general case, we show that a Schur basis\nprovides convergence guarantees, but is difficult to estimate from samples. For\na fixed reward function, we find that an orthogonal basis of the corresponding\nKrylov subspace is an even better choice. We conclude by empirically\ndemonstrating that these stable representations can be learned using stochastic\ngradient descent, opening the door to improved techniques for representation\nlearning with deep networks.\n", "versions": [{"version": "v1", "created": "Fri, 10 Jul 2020 17:55:54 GMT"}, {"version": "v2", "created": "Fri, 2 Oct 2020 20:58:51 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Ghosh", "Dibya", ""], ["Bellemare", "Marc G.", ""]]}, {"id": "2007.05577", "submitter": "Shubhankar Deshpande", "authors": "Shuby Deshpande, Jeff Schneider", "title": "Vizarel: A System to Help Better Understand RL Agents", "comments": "Accepted to ICML 2020 Workshop on Human Interpretability in Machine\n  Learning (Spotlight)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Visualization tools for supervised learning have allowed users to interpret,\nintrospect, and gain intuition for the successes and failures of their models.\nWhile reinforcement learning practitioners ask many of the same questions,\nexisting tools are not applicable to the RL setting. In this work, we describe\nour initial attempt at constructing a prototype of these ideas, through\nidentifying possible features that such a system should encapsulate. Our design\nis motivated by envisioning the system to be a platform on which to experiment\nwith interpretable reinforcement learning.\n", "versions": [{"version": "v1", "created": "Fri, 10 Jul 2020 19:19:22 GMT"}], "update_date": "2020-07-14", "authors_parsed": [["Deshpande", "Shuby", ""], ["Schneider", "Jeff", ""]]}, {"id": "2007.05606", "submitter": "Philippe Reiter", "authors": "Philippe Reiter, Geet Rose Jose, Spyridon Bizmpikis, Ionela-Ancu\\c{t}a\n  C\\^irjil\\u{a}", "title": "Neuromorphic Processing and Sensing: Evolutionary Progression of AI to\n  Spiking", "comments": "15 pages, 13 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The increasing rise in machine learning and deep learning applications is\nrequiring ever more computational resources to successfully meet the growing\ndemands of an always-connected, automated world. Neuromorphic technologies\nbased on Spiking Neural Network algorithms hold the promise to implement\nadvanced artificial intelligence using a fraction of the computations and power\nrequirements by modeling the functioning, and spiking, of the human brain. With\nthe proliferation of tools and platforms aiding data scientists and machine\nlearning engineers to develop the latest innovations in artificial and deep\nneural networks, a transition to a new paradigm will require building from the\ncurrent well-established foundations. This paper explains the theoretical\nworkings of neuromorphic technologies based on spikes, and overviews the\nstate-of-art in hardware processors, software platforms and neuromorphic\nsensing devices. A progression path is paved for current machine learning\nspecialists to update their skillset, as well as classification or predictive\nmodels from the current generation of deep neural networks to SNNs. This can be\nachieved by leveraging existing, specialized hardware in the form of SpiNNaker\nand the Nengo migration toolkit. First-hand, experimental results of converting\na VGG-16 neural network to an SNN are shared. A forward gaze into industrial,\nmedical and commercial applications that can readily benefit from SNNs wraps up\nthis investigation into the neuromorphic computing future.\n", "versions": [{"version": "v1", "created": "Fri, 10 Jul 2020 20:54:42 GMT"}], "update_date": "2020-07-14", "authors_parsed": [["Reiter", "Philippe", ""], ["Jose", "Geet Rose", ""], ["Bizmpikis", "Spyridon", ""], ["C\u00eerjil\u0103", "Ionela-Ancu\u0163a", ""]]}, {"id": "2007.05611", "submitter": "Rohan Kodialam", "authors": "Rohan S. Kodialam, Rebecca Boiarsky, Justin Lim, Neil Dixit, Aditya\n  Sai, David Sontag", "title": "Deep Contextual Clinical Prediction with Reverse Distillation", "comments": "To appear in AAAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Healthcare providers are increasingly using machine learning to predict\npatient outcomes to make meaningful interventions. However, despite innovations\nin this area, deep learning models often struggle to match performance of\nshallow linear models in predicting these outcomes, making it difficult to\nleverage such techniques in practice. In this work, motivated by the task of\nclinical prediction from insurance claims, we present a new technique called\nReverse Distillation which pretrains deep models by using high-performing\nlinear models for initialization. We make use of the longitudinal structure of\ninsurance claims datasets to develop Self Attention with Reverse Distillation,\nor SARD, an architecture that utilizes a combination of contextual embedding,\ntemporal embedding and self-attention mechanisms and most critically is trained\nvia reverse distillation. SARD outperforms state-of-the-art methods on multiple\nclinical prediction outcomes, with ablation studies revealing that reverse\ndistillation is a primary driver of these improvements. Code is available at\nhttps://github.com/clinicalml/omop-learn.\n", "versions": [{"version": "v1", "created": "Fri, 10 Jul 2020 21:10:34 GMT"}, {"version": "v2", "created": "Thu, 17 Dec 2020 01:56:08 GMT"}], "update_date": "2020-12-18", "authors_parsed": [["Kodialam", "Rohan S.", ""], ["Boiarsky", "Rebecca", ""], ["Lim", "Justin", ""], ["Dixit", "Neil", ""], ["Sai", "Aditya", ""], ["Sontag", "David", ""]]}, {"id": "2007.05619", "submitter": "Ondrej Kuzelka", "authors": "Ondrej Kuzelka", "title": "Weighted First-Order Model Counting in the Two-Variable Fragment With\n  Counting Quantifiers", "comments": "This version: Fixed typos in the statement of Proposition 4 (missing\n  dependency on bit-complexity of w and \\overline{w} in the statement of the\n  proposition) and in Eq. 19 (missing negation)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is known due to the work of Van den Broeck et al [KR, 2014] that weighted\nfirst-order model counting (WFOMC) in the two-variable fragment of first-order\nlogic can be solved in time polynomial in the number of domain elements. In\nthis paper we extend this result to the two-variable fragment with counting\nquantifiers.\n", "versions": [{"version": "v1", "created": "Fri, 10 Jul 2020 21:38:42 GMT"}, {"version": "v2", "created": "Fri, 17 Jul 2020 20:32:52 GMT"}, {"version": "v3", "created": "Fri, 14 Aug 2020 08:56:25 GMT"}], "update_date": "2020-08-17", "authors_parsed": [["Kuzelka", "Ondrej", ""]]}, {"id": "2007.05655", "submitter": "Zhiwei Deng", "authors": "Zhiwei Deng, Karthik Narasimhan, Olga Russakovsky", "title": "Evolving Graphical Planner: Contextual Global Planning for\n  Vision-and-Language Navigation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ability to perform effective planning is crucial for building an\ninstruction-following agent. When navigating through a new environment, an\nagent is challenged with (1) connecting the natural language instructions with\nits progressively growing knowledge of the world; and (2) performing long-range\nplanning and decision making in the form of effective exploration and error\ncorrection. Current methods are still limited on both fronts despite extensive\nefforts. In this paper, we introduce the Evolving Graphical Planner (EGP), a\nmodel that performs global planning for navigation based on raw sensory input.\nThe model dynamically constructs a graphical representation, generalizes the\naction space to allow for more flexible decision making, and performs efficient\nplanning on a proxy graph representation. We evaluate our model on a\nchallenging Vision-and-Language Navigation (VLN) task with photorealistic\nimages and achieve superior performance compared to previous navigation\narchitectures. For instance, we achieve a 53% success rate on the test split of\nthe Room-to-Room navigation task through pure imitation learning, outperforming\nprevious navigation architectures by up to 5%.\n", "versions": [{"version": "v1", "created": "Sat, 11 Jul 2020 00:21:05 GMT"}], "update_date": "2020-07-14", "authors_parsed": [["Deng", "Zhiwei", ""], ["Narasimhan", "Karthik", ""], ["Russakovsky", "Olga", ""]]}, {"id": "2007.05674", "submitter": "Matthew Fontaine", "authors": "Matthew C. Fontaine, Ruilin Liu, Ahmed Khalifa, Jignesh Modi, Julian\n  Togelius, Amy K. Hoover, Stefanos Nikolaidis", "title": "Illuminating Mario Scenes in the Latent Space of a Generative\n  Adversarial Network", "comments": "Accepted to AAAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative adversarial networks (GANs) are quickly becoming a ubiquitous\napproach to procedurally generating video game levels. While GAN generated\nlevels are stylistically similar to human-authored examples, human designers\noften want to explore the generative design space of GANs to extract\ninteresting levels. However, human designers find latent vectors opaque and\nwould rather explore along dimensions the designer specifies, such as number of\nenemies or obstacles. We propose using state-of-the-art quality diversity\nalgorithms designed to optimize continuous spaces, i.e. MAP-Elites with a\ndirectional variation operator and Covariance Matrix Adaptation MAP-Elites, to\nefficiently explore the latent space of a GAN to extract levels that vary\nacross a set of specified gameplay measures. In the benchmark domain of Super\nMario Bros, we demonstrate how designers may specify gameplay measures to our\nsystem and extract high-quality (playable) levels with a diverse range of level\nmechanics, while still maintaining stylistic similarity to human authored\nexamples. An online user study shows how the different mechanics of the\nautomatically generated levels affect subjective ratings of their perceived\ndifficulty and appearance.\n", "versions": [{"version": "v1", "created": "Sat, 11 Jul 2020 03:38:06 GMT"}, {"version": "v2", "created": "Wed, 29 Jul 2020 16:56:38 GMT"}, {"version": "v3", "created": "Tue, 15 Dec 2020 23:55:41 GMT"}, {"version": "v4", "created": "Mon, 21 Jun 2021 04:14:08 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Fontaine", "Matthew C.", ""], ["Liu", "Ruilin", ""], ["Khalifa", "Ahmed", ""], ["Modi", "Jignesh", ""], ["Togelius", "Julian", ""], ["Hoover", "Amy K.", ""], ["Nikolaidis", "Stefanos", ""]]}, {"id": "2007.05683", "submitter": "Zheda Mai", "authors": "Zheda Mai, Hyunwoo Kim, Jihwan Jeong, Scott Sanner", "title": "Batch-level Experience Replay with Review for Continual Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Continual learning is a branch of deep learning that seeks to strike a\nbalance between learning stability and plasticity. The CVPR 2020 CLVision\nContinual Learning for Computer Vision challenge is dedicated to evaluating and\nadvancing the current state-of-the-art continual learning methods using the\nCORe50 dataset with three different continual learning scenarios. This paper\npresents our approach, called Batch-level Experience Replay with Review, to\nthis challenge. Our team achieved the 1'st place in all three scenarios out of\n79 participated teams. The codebase of our implementation is publicly available\nat https://github.com/RaptorMai/CVPR20_CLVision_challenge\n", "versions": [{"version": "v1", "created": "Sat, 11 Jul 2020 05:20:09 GMT"}], "update_date": "2020-07-15", "authors_parsed": [["Mai", "Zheda", ""], ["Kim", "Hyunwoo", ""], ["Jeong", "Jihwan", ""], ["Sanner", "Scott", ""]]}, {"id": "2007.05694", "submitter": "Ugurkan Ates", "authors": "Ugurkan Ates", "title": "Long-Term Planning with Deep Reinforcement Learning on Autonomous Drones", "comments": "Submitted to Association for the Advancement of Artificial\n  Intelligence(AAAI) 2020 Fall Symposium Series", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.IT math.IT stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we study a long-term planning scenario that is based on drone\nracing competitions held in real life. We conducted this experiment on a\nframework created for \"Game of Drones: Drone Racing Competition\" at NeurIPS\n2019. The racing environment was created using Microsoft's AirSim Drone Racing\nLab. A reinforcement learning agent, a simulated quadrotor in our case, has\ntrained with the Policy Proximal Optimization(PPO) algorithm was able to\nsuccessfully compete against another simulated quadrotor that was running a\nclassical path planning algorithm. Agent observations consist of data from IMU\nsensors, GPS coordinates of drone obtained through simulation and opponent\ndrone GPS information. Using opponent drone GPS information during training\nhelps dealing with complex state spaces, serving as expert guidance allows for\nefficient and stable training process. All experiments performed in this paper\ncan be found and reproduced with code at our GitHub repository\n", "versions": [{"version": "v1", "created": "Sat, 11 Jul 2020 06:16:50 GMT"}], "update_date": "2020-07-14", "authors_parsed": [["Ates", "Ugurkan", ""]]}, {"id": "2007.05781", "submitter": "Romit Beed Mr", "authors": "Romit S Beed, Sunita Sarkar, Arindam Roy, Suvranil D Biswas and Suhana\n  Biswas", "title": "A Hybrid Multi-Objective Carpool Route Optimization Technique using\n  Genetic Algorithm and A* Algorithm", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Carpooling has gained considerable importance in developed as well as in\ndeveloping countries as an effective solution for controlling vehicular\npollution, both sound and air. As carpooling decreases the number of vehicles\nused by commuters, it results in multiple benefits like mitigation of traffic\nand congestion on the roads, reduced demand for parking facilities, lesser\nenergy or fuel consumption and most importantly, reduction in carbon emission,\nthus improving the quality of life in cities. This work presents a hybrid GA-A*\nalgorithm to obtain optimal routes for the carpooling problem in the domain of\nmulti-objective optimization having multiple conflicting objectives. Though\nGenetic algorithm provides optimal solutions, A* algorithm because of its\nefficiency in providing the shortest route between any two points based on\nheuristics, enhances the optimal routes obtained using Genetic algorithm. The\nrefined routes, obtained using the GA-A* algorithm, are further subjected to\ndominance test to obtain non-dominating solutions based on Pareto-Optimality.\nThe routes obtained maximize the profit of the service provider by minimizing\nthe travel and detour distance as well as pick-up/drop costs while maximizing\nthe utilization of the car. The proposed algorithm has been implemented over\nthe Salt Lake area of Kolkata. Route distance and detour distance for the\noptimal routes obtained using the proposed algorithm are consistently lesser\nfor the same number of passengers when compared with the corresponding data\nobtained using the existing algorithm. Various statistical analyses like\nboxplots have also confirmed that the proposed algorithm regularly performed\nbetter than the existing algorithm using only Genetic Algorithm.\n", "versions": [{"version": "v1", "created": "Sat, 11 Jul 2020 14:13:20 GMT"}], "update_date": "2020-07-15", "authors_parsed": [["Beed", "Romit S", ""], ["Sarkar", "Sunita", ""], ["Roy", "Arindam", ""], ["Biswas", "Suvranil D", ""], ["Biswas", "Suhana", ""]]}, {"id": "2007.05798", "submitter": "Sascha Rosbach", "authors": "Sascha Rosbach, Xing Li, Simon Gro{\\ss}johann, Silviu Homoceanu and\n  Stefan Roth", "title": "Planning on the fast lane: Learning to interact using attention\n  mechanisms in path integral inverse reinforcement learning", "comments": "To appear in Proceedings of the IEEE/RSJ International Conference on\n  Intelligent Robots and Systems (IROS), Las Vegas, NV, USA, October 2020", "journal-ref": "2020 IEEE/RSJ Int. Conf. on Intelligent Robots and Syst. (IROS),\n  Las Vegas, USA, 2020, pp. 5187-5193", "doi": "10.1109/IROS45743.2020.9340636", "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  General-purpose trajectory planning algorithms for automated driving utilize\ncomplex reward functions to perform a combined optimization of strategic,\nbehavioral, and kinematic features. The specification and tuning of a single\nreward function is a tedious task and does not generalize over a large set of\ntraffic situations. Deep learning approaches based on path integral inverse\nreinforcement learning have been successfully applied to predict local\nsituation-dependent reward functions using features of a set of sampled driving\npolicies. Sample-based trajectory planning algorithms are able to approximate a\nspatio-temporal subspace of feasible driving policies that can be used to\nencode the context of a situation. However, the interaction with dynamic\nobjects requires an extended planning horizon, which depends on sequential\ncontext modeling. In this work, we are concerned with the sequential reward\nprediction over an extended time horizon. We present a neural network\narchitecture that uses a policy attention mechanism to generate a\nlow-dimensional context vector by concentrating on trajectories with a\nhuman-like driving style. Apart from this, we propose a temporal attention\nmechanism to identify context switches and allow for stable adaptation of\nrewards. We evaluate our results on complex simulated driving situations,\nincluding other moving vehicles. Our evaluation shows that our policy attention\nmechanism learns to focus on collision-free policies in the configuration\nspace. Furthermore, the temporal attention mechanism learns persistent\ninteraction with other vehicles over an extended planning horizon.\n", "versions": [{"version": "v1", "created": "Sat, 11 Jul 2020 15:25:44 GMT"}, {"version": "v2", "created": "Sat, 12 Sep 2020 08:33:02 GMT"}], "update_date": "2021-05-04", "authors_parsed": [["Rosbach", "Sascha", ""], ["Li", "Xing", ""], ["Gro\u00dfjohann", "Simon", ""], ["Homoceanu", "Silviu", ""], ["Roth", "Stefan", ""]]}, {"id": "2007.05838", "submitter": "Alexander Tschantz", "authors": "Alexander Tschantz, Beren Millidge, Anil K. Seth, Christopher L.\n  Buckley", "title": "Control as Hybrid Inference", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The field of reinforcement learning can be split into model-based and\nmodel-free methods. Here, we unify these approaches by casting model-free\npolicy optimisation as amortised variational inference, and model-based\nplanning as iterative variational inference, within a `control as hybrid\ninference' (CHI) framework. We present an implementation of CHI which naturally\nmediates the balance between iterative and amortised inference. Using a\ndidactic experiment, we demonstrate that the proposed algorithm operates in a\nmodel-based manner at the onset of learning, before converging to a model-free\nalgorithm once sufficient data have been collected. We verify the scalability\nof our algorithm on a continuous control benchmark, demonstrating that it\noutperforms strong model-free and model-based baselines. CHI thus provides a\nprincipled framework for harnessing the sample efficiency of model-based\nplanning while retaining the asymptotic performance of model-free policy\noptimisation.\n", "versions": [{"version": "v1", "created": "Sat, 11 Jul 2020 19:44:09 GMT"}], "update_date": "2020-07-14", "authors_parsed": [["Tschantz", "Alexander", ""], ["Millidge", "Beren", ""], ["Seth", "Anil K.", ""], ["Buckley", "Christopher L.", ""]]}, {"id": "2007.05881", "submitter": "Marko Smilevski", "authors": "Marko Smilevski", "title": "Applying recent advances in Visual Question Answering to Record Linkage", "comments": "48 pages, 15 figures, 6 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.DB stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Multi-modal Record Linkage is the process of matching multi-modal records\nfrom multiple sources that represent the same entity. This field has not been\nexplored in research and we propose two solutions based on Deep Learning\narchitectures that are inspired by recent work in Visual Question Answering.\nThe neural networks we propose use two different fusion modules, the Recurrent\nNeural Network + Convolutional Neural Network fusion module and the Stacked\nAttention Network fusion module, that jointly combine the visual and the\ntextual data of the records. The output of these fusion models is the input of\na Siamese Neural Network that computes the similarity of the records. Using\ndata from the Avito Duplicate Advertisements Detection dataset, we train these\nsolutions and from the experiments, we concluded that the Recurrent Neural\nNetwork + Convolutional Neural Network fusion module outperforms a simple model\nthat uses hand-crafted features. We also find that the Recurrent Neural Network\n+ Convolutional Neural Network fusion module classifies dissimilar\nadvertisements as similar more frequently if their average description is\nbigger than 40 words. We conclude that the reason for this is that the longer\nadvertisements have a different distribution then the shorter advertisements\nwho are more prevalent in the dataset. In the end, we also conclude that\nfurther research needs to be done with the Stacked Attention Network, to\nfurther explore the effects of the visual data on the performance of the fusion\nmodules.\n", "versions": [{"version": "v1", "created": "Sun, 12 Jul 2020 01:24:47 GMT"}], "update_date": "2020-07-14", "authors_parsed": [["Smilevski", "Marko", ""]]}, {"id": "2007.05896", "submitter": "Evan Liu", "authors": "Evan Zheran Liu, Ramtin Keramati, Sudarshan Seshadri, Kelvin Guu,\n  Panupong Pasupat, Emma Brunskill, Percy Liang", "title": "Learning Abstract Models for Strategic Exploration and Fast Reward\n  Transfer", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Model-based reinforcement learning (RL) is appealing because (i) it enables\nplanning and thus more strategic exploration, and (ii) by decoupling dynamics\nfrom rewards, it enables fast transfer to new reward functions. However,\nlearning an accurate Markov Decision Process (MDP) over high-dimensional states\n(e.g., raw pixels) is extremely challenging because it requires function\napproximation, which leads to compounding errors. Instead, to avoid compounding\nerrors, we propose learning an abstract MDP over abstract states:\nlow-dimensional coarse representations of the state (e.g., capturing agent\nposition, ignoring other objects). We assume access to an abstraction function\nthat maps the concrete states to abstract states. In our approach, we construct\nan abstract MDP, which grows through strategic exploration via planning.\nSimilar to hierarchical RL approaches, the abstract actions of the abstract MDP\nare backed by learned subpolicies that navigate between abstract states. Our\napproach achieves strong results on three of the hardest Arcade Learning\nEnvironment games (Montezuma's Revenge, Pitfall!, and Private Eye), including\nsuperhuman performance on Pitfall! without demonstrations. After training on\none task, we can reuse the learned abstract MDP for new reward functions,\nachieving higher reward in 1000x fewer samples than model-free methods trained\nfrom scratch.\n", "versions": [{"version": "v1", "created": "Sun, 12 Jul 2020 03:33:50 GMT"}], "update_date": "2020-07-14", "authors_parsed": [["Liu", "Evan Zheran", ""], ["Keramati", "Ramtin", ""], ["Seshadri", "Sudarshan", ""], ["Guu", "Kelvin", ""], ["Pasupat", "Panupong", ""], ["Brunskill", "Emma", ""], ["Liang", "Percy", ""]]}, {"id": "2007.05902", "submitter": "Kartik Chugh", "authors": "Kartik Chugh, Andrea Y. Solis, Thomas D. LaToza", "title": "Editable AI: Mixed Human-AI Authoring of Code Patterns", "comments": null, "journal-ref": "2019 IEEE Symposium on Visual Languages and Human-Centric\n  Computing (VL/HCC), Memphis, TN, USA, 2019, pp. 35-43", "doi": "10.1109/VLHCC.2019.8818871", "report-no": null, "categories": "cs.HC cs.AI cs.LG cs.SE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Developers authoring HTML documents define elements following patterns which\nestablish and reflect the visual structure of a document, such as making all\nimages in a footer the same height by applying a class to each. To surface\nthese patterns to developers and support developers in authoring consistent\nwith these patterns, we propose a mixed human-AI technique for creating code\npatterns. Patterns are first learned from individual HTML documents through a\ndecision tree, generating a representation which developers may view and edit.\nCode patterns are used to offer developers autocomplete suggestions, list\nexamples, and flag violations. To evaluate our technique, we conducted a user\nstudy in which 24 participants wrote, edited, and corrected HTML documents. We\nfound that our technique enabled developers to edit and correct documents more\nquickly and create, edit, and correct documents more successfully.\n", "versions": [{"version": "v1", "created": "Sun, 12 Jul 2020 03:49:42 GMT"}], "update_date": "2020-07-14", "authors_parsed": [["Chugh", "Kartik", ""], ["Solis", "Andrea Y.", ""], ["LaToza", "Thomas D.", ""]]}, {"id": "2007.05961", "submitter": "Elif Surer", "authors": "Faruk Kucuksubasi and Elif Surer", "title": "Relational-Grid-World: A Novel Relational Reasoning Environment and An\n  Agent Model for Relational Information Extraction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning (RL) agents are often designed specifically for a\nparticular problem and they generally have uninterpretable working processes.\nStatistical methods-based agent algorithms can be improved in terms of\ngeneralizability and interpretability using symbolic Artificial Intelligence\n(AI) tools such as logic programming. In this study, we present a model-free RL\narchitecture that is supported with explicit relational representations of the\nenvironmental objects. For the first time, we use the PrediNet network\narchitecture in a dynamic decision-making problem rather than image-based\ntasks, and Multi-Head Dot-Product Attention Network (MHDPA) as a baseline for\nperformance comparisons. We tested two networks in two environments ---i.e.,\nthe baseline Box-World environment and our novel environment,\nRelational-Grid-World (RGW). With the procedurally generated RGW environment,\nwhich is complex in terms of visual perceptions and combinatorial selections,\nit is easy to measure the relational representation performance of the RL\nagents. The experiments were carried out using different configurations of the\nenvironment so that the presented module and the environment were compared with\nthe baselines. We reached similar policy optimization performance results with\nthe PrediNet architecture and MHDPA; additionally, we achieved to extract the\npropositional representation explicitly ---which makes the agent's statistical\npolicy logic more interpretable and tractable. This flexibility in the agent's\npolicy provides convenience for designing non-task-specific agent\narchitectures. The main contributions of this study are two-fold ---an RL agent\nthat can explicitly perform relational reasoning, and a new environment that\nmeasures the relational reasoning capabilities of RL agents.\n", "versions": [{"version": "v1", "created": "Sun, 12 Jul 2020 11:30:48 GMT"}], "update_date": "2020-07-14", "authors_parsed": [["Kucuksubasi", "Faruk", ""], ["Surer", "Elif", ""]]}, {"id": "2007.05971", "submitter": "Liwen Li", "authors": "Liwen Li, Zequn Wei, Jin-Kao Hao and Kun He", "title": "Probability Learning based Tabu Search for the Budgeted Maximum Coverage\n  Problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knapsack problems are classic models that can formulate a wide range of\napplications. In this work, we deal with the Budgeted Maximum Coverage Problem\n(BMCP), which is a generalized 0-1 knapsack problem. Given a set of items with\nnonnegative weights and a set of elements with nonnegative profits, where each\nitem is composed of a subset of elements, BMCP aims to pack a subset of items\nin a capacity-constrained knapsack such that the total weight of the selected\nitems does not exceed the knapsack capacity, and the total profit of the\nassociated elements is maximized. Note that each element is counted once even\nif it is covered multiple times. BMCP is closely related to the Set-Union\nKnapsack Problem (SUKP) that is well studied in recent years. As the\ncounterpart problem of SUKP, however, BMCP was introduced early in 1999 but\nsince then it has been rarely studied, especially there is no practical\nalgorithm proposed. By combining the reinforcement learning technique to the\nlocal search procedure, we propose a probability learning based tabu search\n(PLTS) algorithm for addressing this NP-hard problem. The proposed algorithm\niterates through two distinct phases, namely a tabu search phase and a\nprobability learning based perturbation phase. As there is no benchmark\ninstances proposed in the literature, we generate 30 benchmark instances with\nvaried properties. Experimental results demonstrate that our PLTS algorithm\nsignificantly outperforms the general CPLEX solver for solving the challenging\nBMCP in terms of the solution quality.\n", "versions": [{"version": "v1", "created": "Sun, 12 Jul 2020 12:11:59 GMT"}], "update_date": "2020-07-14", "authors_parsed": [["Li", "Liwen", ""], ["Wei", "Zequn", ""], ["Hao", "Jin-Kao", ""], ["He", "Kun", ""]]}, {"id": "2007.06024", "submitter": "Kailash Karthik Saravanakumar", "authors": "Kailash Karthik Saravanakumar", "title": "The Impossibility Theorem of Machine Fairness -- A Causal Perspective", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the increasing pervasive use of machine learning in social and economic\nsettings, there has been an interest in the notion of machine bias in the AI\ncommunity. Models trained on historic data reflect biases that exist in society\nand propagated them to the future through their decisions. There are three\nprominent metrics of machine fairness used in the community, and it has been\nshown statistically that it is impossible to satisfy them all at the same time.\nThis has led to an ambiguity with regards to the definition of fairness. In\nthis report, a causal perspective to the impossibility theorem of fairness is\npresented along with a causal goal for machine fairness.\n", "versions": [{"version": "v1", "created": "Sun, 12 Jul 2020 15:56:15 GMT"}, {"version": "v2", "created": "Fri, 29 Jan 2021 22:45:07 GMT"}], "update_date": "2021-02-02", "authors_parsed": [["Saravanakumar", "Kailash Karthik", ""]]}, {"id": "2007.06108", "submitter": "Matthew Guzdial", "authors": "Matthew Guzdial, Devi Acharya, Max Kreminski, Michael Cook, Mirjam\n  Eladhari, Antonios Liapis and Anne Sullivan", "title": "Tabletop Roleplaying Games as Procedural Content Generators", "comments": "9 pages, 2 figures, FDG Workshop on Procedural Content Generation\n  2020", "journal-ref": "FDG Workshop on Procedural Content Generation 2020", "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tabletop roleplaying games (TTRPGs) and procedural content generators can\nboth be understood as systems of rules for producing content. In this paper, we\nargue that TTRPG design can usefully be viewed as procedural content generator\ndesign. We present several case studies linking key concepts from PCG research\n-- including possibility spaces, expressive range analysis, and generative\npipelines -- to key concepts in TTRPG design. We then discuss the implications\nof these relationships and suggest directions for future work uniting research\nin TTRPGs and PCG.\n", "versions": [{"version": "v1", "created": "Sun, 12 Jul 2020 22:05:17 GMT"}, {"version": "v2", "created": "Wed, 15 Jul 2020 17:37:55 GMT"}], "update_date": "2020-07-16", "authors_parsed": [["Guzdial", "Matthew", ""], ["Acharya", "Devi", ""], ["Kreminski", "Max", ""], ["Cook", "Michael", ""], ["Eladhari", "Mirjam", ""], ["Liapis", "Antonios", ""], ["Sullivan", "Anne", ""]]}, {"id": "2007.06131", "submitter": "Randy Tan", "authors": "Randy Tan, Naimul Khan, and Ling Guan", "title": "Locality Guided Neural Networks for Explainable Artificial Intelligence", "comments": "8 pages, 3 figures, submitted to WCCI2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In current deep network architectures, deeper layers in networks tend to\ncontain hundreds of independent neurons which makes it hard for humans to\nunderstand how they interact with each other. By organizing the neurons by\ncorrelation, humans can observe how clusters of neighbouring neurons interact\nwith each other. In this paper, we propose a novel algorithm for back\npropagation, called Locality Guided Neural Network(LGNN) for training networks\nthat preserves locality between neighbouring neurons within each layer of a\ndeep network. Heavily motivated by Self-Organizing Map (SOM), the goal is to\nenforce a local topology on each layer of a deep network such that neighbouring\nneurons are highly correlated with each other. This method contributes to the\ndomain of Explainable Artificial Intelligence (XAI), which aims to alleviate\nthe black-box nature of current AI methods and make them understandable by\nhumans. Our method aims to achieve XAI in deep learning without changing the\nstructure of current models nor requiring any post processing. This paper\nfocuses on Convolutional Neural Networks (CNNs), but can theoretically be\napplied to any type of deep learning architecture. In our experiments, we train\nvarious VGG and Wide ResNet (WRN) networks for image classification on\nCIFAR100. In depth analyses presenting both qualitative and quantitative\nresults demonstrate that our method is capable of enforcing a topology on each\nlayer while achieving a small increase in classification accuracy\n", "versions": [{"version": "v1", "created": "Sun, 12 Jul 2020 23:45:51 GMT"}], "update_date": "2020-07-14", "authors_parsed": [["Tan", "Randy", ""], ["Khan", "Naimul", ""], ["Guan", "Ling", ""]]}, {"id": "2007.06172", "submitter": "Guohua Wu", "authors": "Baoju Liu, Min Deng, Guohua Wu, Xinyu Pei, Haifeng Li, Witold Pedrycz", "title": "Bottom-up mechanism and improved contract net protocol for the dynamic\n  task planning of heterogeneous Earth observation resources", "comments": "14 pages, 11 figures.This work has been submitted to the IEEE for\n  possible publication", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.AI cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Earth observation resources are becoming increasingly indispensable in\ndisaster relief, damage assessment and related domains. Many unpredicted\nfactors, such as the change of observation task requirements, to the occurring\nof bad weather and resource failures, may cause the scheduled observation\nscheme to become infeasible. Therefore, it is crucial to be able to promptly\nand maybe frequently develop high-quality replanned observation schemes that\nminimize the effects on the scheduled tasks. A bottom-up distributed\ncoordinated framework together with an improved contract net are proposed to\nfacilitate the dynamic task replanning for heterogeneous Earth observation\nresources. This hierarchical framework consists of three levels, namely,\nneighboring resource coordination, single planning center coordination, and\nmultiple planning center coordination. Observation tasks affected by\nunpredicted factors are assigned and treated along with a bottom-up route from\nresources to planning centers. This bottom-up distributed coordinated framework\ntransfers part of the computing load to various nodes of the observation\nsystems to allocate tasks more efficiently and robustly. To support the prompt\nassignment of large-scale tasks to proper Earth observation resources in\ndynamic environments, we propose a multiround combinatorial allocation (MCA)\nmethod. Moreover, a new float interval-based local search algorithm is proposed\nto obtain the promising planning scheme more quickly. The experiments\ndemonstrate that the MCA method can achieve a better task completion rate for\nlarge-scale tasks with satisfactory time efficiency. It also demonstrates that\nthis method can help to efficiently obtain replanning schemes based on original\nscheme in dynamic environments.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jul 2020 03:51:08 GMT"}, {"version": "v2", "created": "Wed, 9 Jun 2021 05:49:28 GMT"}], "update_date": "2021-06-10", "authors_parsed": [["Liu", "Baoju", ""], ["Deng", "Min", ""], ["Wu", "Guohua", ""], ["Pei", "Xinyu", ""], ["Li", "Haifeng", ""], ["Pedrycz", "Witold", ""]]}, {"id": "2007.06202", "submitter": "Youngsuk Park", "authors": "Youngsuk Park, Ryan A. Rossi, Zheng Wen, Gang Wu, Handong Zhao", "title": "Structured Policy Iteration for Linear Quadratic Regulator", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Linear quadratic regulator (LQR) is one of the most popular frameworks to\ntackle continuous Markov decision process tasks. With its fundamental theory\nand tractable optimal policy, LQR has been revisited and analyzed in recent\nyears, in terms of reinforcement learning scenarios such as the model-free or\nmodel-based setting. In this paper, we introduce the \\textit{Structured Policy\nIteration} (S-PI) for LQR, a method capable of deriving a structured linear\npolicy. Such a structured policy with (block) sparsity or low-rank can have\nsignificant advantages over the standard LQR policy: more interpretable,\nmemory-efficient, and well-suited for the distributed setting. In order to\nderive such a policy, we first cast a regularized LQR problem when the model is\nknown. Then, our Structured Policy Iteration (S-PI) algorithm, which takes a\npolicy evaluation step and a policy improvement step in an iterative manner,\ncan solve this regularized LQR efficiently. We further extend the S-PI\nalgorithm to the model-free setting where a smoothing procedure is adopted to\nestimate the gradient. In both the known-model and model-free setting, we prove\nconvergence analysis under the proper choice of parameters. Finally, the\nexperiments demonstrate the advantages of S-PI in terms of balancing the LQR\nperformance and level of structure by varying the weight parameter.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jul 2020 06:03:15 GMT"}], "update_date": "2020-07-14", "authors_parsed": [["Park", "Youngsuk", ""], ["Rossi", "Ryan A.", ""], ["Wen", "Zheng", ""], ["Wu", "Gang", ""], ["Zhao", "Handong", ""]]}, {"id": "2007.06207", "submitter": "Siwei Chen", "authors": "Siwei Chen, Xiao Ma, David Hsu", "title": "DinerDash Gym: A Benchmark for Policy Learning in High-Dimensional\n  Action Space", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It has been arduous to assess the progress of a policy learning algorithm in\nthe domain of hierarchical task with high dimensional action space due to the\nlack of a commonly accepted benchmark. In this work, we propose a new\nlight-weight benchmark task called Diner Dash for evaluating the performance in\na complicated task with high dimensional action space. In contrast to the\ntraditional Atari games that only have a flat structure of goals and very few\nactions, the proposed benchmark task has a hierarchical task structure and size\nof 57 for the action space and hence can facilitate the development of policy\nlearning in complicated tasks. On top of that, we introduce Decomposed Policy\nGraph Modelling (DPGM), an algorithm that combines both graph modelling and\ndeep learning to allow explicit domain knowledge embedding and achieves\nsignificant improvement comparing to the baseline. In the experiments, we have\nshown the effectiveness of the domain knowledge injection via a specially\ndesigned imitation algorithm as well as results of other popular algorithms.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jul 2020 06:22:55 GMT"}], "update_date": "2020-07-14", "authors_parsed": [["Chen", "Siwei", ""], ["Ma", "Xiao", ""], ["Hsu", "David", ""]]}, {"id": "2007.06258", "submitter": "Johannes Reich", "authors": "Johannes Reich", "title": "A theory of interaction semantics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The aim of this article is to delineate a theory of interaction semantics and\nthereby provide a proper understanding of the \"meaning\" of the exchanged\ncharacters within an interaction. The idea is to describe the interaction\n(between discrete systems) by a mechanism that depends on information exchange,\nthat is, on the identical naming of the \"exchanged\" characters -- by a\nprotocol. Complementing a nondeterministic protocol with decisions to a game in\nits interactive form (GIF) makes it interpretable in the sense of an execution.\nThe consistency of such a protocol depends on the particular choice of its sets\nof characters. Thus, assigning a protocol its sets of charaacters makes it\nconsistent or not, creating a fulfillment relation. The interpretation of the\ncharacters during GIF execution results in their meaning. The proposed theory\nof interaction semantics is consistent with the model of information transport\nand processing, it has a clear relation to models of formal semantics, it\naccounts for the fact that the meaning of a character is invariant against\nrenaming and locates the concept of meaning in the technical description of\ninteractions. It defines when two different characters have the same meaning\nand what an \"interpretation\" and what an \"interpretation context\" is as well as\nunder which conditions meaning is compositional.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jul 2020 09:22:59 GMT"}], "update_date": "2020-07-14", "authors_parsed": [["Reich", "Johannes", ""]]}, {"id": "2007.06267", "submitter": "Ralph Abboud", "authors": "Ralph Abboud, \\.Ismail \\.Ilkan Ceylan, Thomas Lukasiewicz, Tommaso\n  Salvatori", "title": "BoxE: A Box Embedding Model for Knowledge Base Completion", "comments": "Proceedings of the Thirty-Fourth Annual Conference on Advances in\n  Neural Information Processing Systems (NeurIPS 2020). Code and data available\n  at: http://www.github.com/ralphabb/BoxE", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge base completion (KBC) aims to automatically infer missing facts by\nexploiting information already present in a knowledge base (KB). A promising\napproach for KBC is to embed knowledge into latent spaces and make predictions\nfrom learned embeddings. However, existing embedding models are subject to at\nleast one of the following limitations: (1) theoretical inexpressivity, (2)\nlack of support for prominent inference patterns (e.g., hierarchies), (3) lack\nof support for KBC over higher-arity relations, and (4) lack of support for\nincorporating logical rules. Here, we propose a spatio-translational embedding\nmodel, called BoxE, that simultaneously addresses all these limitations. BoxE\nembeds entities as points, and relations as a set of hyper-rectangles (or\nboxes), which spatially characterize basic logical properties. This seemingly\nsimple abstraction yields a fully expressive model offering a natural encoding\nfor many desired logical properties. BoxE can both capture and inject rules\nfrom rich classes of rule languages, going well beyond individual inference\npatterns. By design, BoxE naturally applies to higher-arity KBs. We conduct a\ndetailed experimental analysis, and show that BoxE achieves state-of-the-art\nperformance, both on benchmark knowledge graphs and on more general KBs, and we\nempirically show the power of integrating logical rules.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jul 2020 09:40:49 GMT"}, {"version": "v2", "created": "Thu, 29 Oct 2020 09:48:19 GMT"}], "update_date": "2020-10-30", "authors_parsed": [["Abboud", "Ralph", ""], ["Ceylan", "\u0130smail \u0130lkan", ""], ["Lukasiewicz", "Thomas", ""], ["Salvatori", "Tommaso", ""]]}, {"id": "2007.06282", "submitter": "Martin Cooper", "authors": "Martin C. Cooper", "title": "Strengthening neighbourhood substitution", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Domain reduction is an essential tool for solving the constraint satisfaction\nproblem (CSP). In the binary CSP, neighbourhood substitution consists in\neliminating a value if there exists another value which can be substituted for\nit in each constraint. We show that the notion of neighbourhood substitution\ncan be strengthened in two distinct ways without increasing time complexity. We\nalso show the theoretical result that, unlike neighbourhood substitution,\nfinding an optimal sequence of these new operations is NP-hard.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jul 2020 10:06:20 GMT"}], "update_date": "2020-07-14", "authors_parsed": [["Cooper", "Martin C.", ""]]}, {"id": "2007.06286", "submitter": "Gustav Sourek", "authors": "Gustav Sourek, Filip Zelezny, Ondrej Kuzelka", "title": "Beyond Graph Neural Networks with Lifted Relational Neural Networks", "comments": "Submitted to MLJ's Special Track on Learning and Reasoning (May 15th\n  2020 cut-off) http://lr2020.iit.demokritos.gr/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.LO cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We demonstrate a declarative differentiable programming framework based on\nthe language of Lifted Relational Neural Networks, where small parameterized\nlogic programs are used to encode relational learning scenarios. When presented\nwith relational data, such as various forms of graphs, the program interpreter\ndynamically unfolds differentiable computational graphs to be used for the\nprogram parameter optimization by standard means. Following from the used\ndeclarative Datalog abstraction, this results into compact and elegant learning\nprograms, in contrast with the existing procedural approaches operating\ndirectly on the computational graph level. We illustrate how this idea can be\nused for an efficient encoding of a diverse range of existing advanced neural\narchitectures, with a particular focus on Graph Neural Networks (GNNs).\nAdditionally, we show how the contemporary GNN models can be easily extended\ntowards higher relational expressiveness. In the experiments, we demonstrate\ncorrectness and computation efficiency through comparison against specialized\nGNN deep learning frameworks, while shedding some light on the learning\nperformance of existing GNN models.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jul 2020 10:10:58 GMT"}], "update_date": "2020-07-15", "authors_parsed": [["Sourek", "Gustav", ""], ["Zelezny", "Filip", ""], ["Kuzelka", "Ondrej", ""]]}, {"id": "2007.06290", "submitter": "Ivan P Yamshchikov", "authors": "Yana Agafonova, Alexey Tikhonov, Ivan P. Yamshchikov", "title": "Paranoid Transformer: Reading Narrative of Madness as Computational\n  Approach to Creativity", "comments": null, "journal-ref": null, "doi": "10.3390/fi12110182", "report-no": null, "categories": "cs.CL cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This papers revisits the receptive theory in context of computational\ncreativity. It presents a case study of a Paranoid Transformer - a fully\nautonomous text generation engine with raw output that could be read as the\nnarrative of a mad digital persona without any additional human post-filtering.\nWe describe technical details of the generative system, provide examples of\noutput and discuss the impact of receptive theory, chance discovery and\nsimulation of fringe mental state on the understanding of computational\ncreativity.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jul 2020 10:18:24 GMT"}], "update_date": "2021-05-20", "authors_parsed": [["Agafonova", "Yana", ""], ["Tikhonov", "Alexey", ""], ["Yamshchikov", "Ivan P.", ""]]}, {"id": "2007.06292", "submitter": "Piyush Yadav", "authors": "Piyush Yadav, Dhaval Salwala, Edward Curry", "title": "Knowledge Graph Driven Approach to Represent Video Streams for\n  Spatiotemporal Event Pattern Matching in Complex Event Processing", "comments": "31 pages, 14 Figures, Publication accepted in International Journal\n  of Graph Computing", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.DB cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Complex Event Processing (CEP) is an event processing paradigm to perform\nreal-time analytics over streaming data and match high-level event patterns.\nPresently, CEP is limited to process structured data stream. Video streams are\ncomplicated due to their unstructured data model and limit CEP systems to\nperform matching over them. This work introduces a graph-based structure for\ncontinuous evolving video streams, which enables the CEP system to query\ncomplex video event patterns. We propose the Video Event Knowledge Graph\n(VEKG), a graph driven representation of video data. VEKG models video objects\nas nodes and their relationship interaction as edges over time and space. It\ncreates a semantic knowledge representation of video data derived from the\ndetection of high-level semantic concepts from the video using an ensemble of\ndeep learning models. A CEP-based state optimization - VEKG-Time Aggregated\nGraph (VEKG-TAG) is proposed over VEKG representation for faster event\ndetection. VEKG-TAG is a spatiotemporal graph aggregation method that provides\na summarized view of the VEKG graph over a given time length. We defined a set\nof nine event pattern rules for two domains (Activity Recognition and Traffic\nManagement), which act as a query and applied over VEKG graphs to discover\ncomplex event patterns. To show the efficacy of our approach, we performed\nextensive experiments over 801 video clips across 10 datasets. The proposed\nVEKG approach was compared with other state-of-the-art methods and was able to\ndetect complex event patterns over videos with F-Score ranging from 0.44 to\n0.90. In the given experiments, the optimized VEKG-TAG was able to reduce 99%\nand 93% of VEKG nodes and edges, respectively, with 5.19X faster search time,\nachieving sub-second median latency of 4-20 milliseconds.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jul 2020 10:20:58 GMT"}], "update_date": "2020-07-14", "authors_parsed": [["Yadav", "Piyush", ""], ["Salwala", "Dhaval", ""], ["Curry", "Edward", ""]]}, {"id": "2007.06300", "submitter": "Marta Arias", "authors": "Christian Lezcano, Marta Arias", "title": "Synthetic Dataset Generation with Itemset-Based Generative Models", "comments": "IEEE International Symposium on Software Reliability Engineering\n  Workshops (ISSREW@RDSA 2019), Oct 2019", "journal-ref": null, "doi": "10.1109/ISSREW.2019.00086", "report-no": null, "categories": "cs.DB cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes three different data generators, tailored to\ntransactional datasets, based on existing itemset-based generative models. All\nthese generators are intuitive and easy to implement and show satisfactory\nperformance. The quality of each generator is assessed by means of three\ndifferent methods that capture how well the original dataset structure is\npreserved.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jul 2020 10:37:21 GMT"}], "update_date": "2020-07-15", "authors_parsed": [["Lezcano", "Christian", ""], ["Arias", "Marta", ""]]}, {"id": "2007.06368", "submitter": "Djallel Bouneffouf", "authors": "Djallel Bouneffouf, Sohini Upadhyay and Yasaman Khazaeni", "title": "Contextual Bandit with Missing Rewards", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a novel variant of the contextual bandit problem (i.e., the\nmulti-armed bandit with side-information, or context, available to a\ndecision-maker) where the reward associated with each context-based decision\nmay not always be observed(\"missing rewards\"). This new problem is motivated by\ncertain online settings including clinical trial and ad recommendation\napplications. In order to address the missing rewards setting, we propose to\ncombine the standard contextual bandit approach with an unsupervised learning\nmechanism such as clustering. Unlike standard contextual bandit methods, by\nleveraging clustering to estimate missing reward, we are able to learn from\neach incoming event, even those with missing rewards. Promising empirical\nresults are obtained on several real-life datasets.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jul 2020 13:29:51 GMT"}, {"version": "v2", "created": "Sun, 19 Jul 2020 00:16:49 GMT"}], "update_date": "2020-07-21", "authors_parsed": [["Bouneffouf", "Djallel", ""], ["Upadhyay", "Sohini", ""], ["Khazaeni", "Yasaman", ""]]}, {"id": "2007.06374", "submitter": "Maria Ovchinnikova", "authors": "Arian Garshi and Malin Wist Jakobsen and J{\\o}rgen Nyborg-Christensen\n  and Daniel Ostnes and Maria Ovchinnikova", "title": "Smart technology in the classroom: a systematic review.Prospects for\n  algorithmic accountability", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Artificial intelligence (AI) algorithms have emerged in the educational\ndomain as a tool to make learning more efficient. Different applications for\nmastering particular skills, learning new languages, and tracking their\nprogress are used by children. What is the impact on children from using this\nsmart technology? We conducted a systematic review to understand the state of\nthe art. We explored the literature in several sub-disciplines: wearables,\nchild psychology, AI and education, school surveillance, and accountability.\nOur review identified the need for more research for each established topic. We\nmanaged to find both positive and negative effects of using wearables, but\ncannot conclude if smart technology use leads to lowering the young children's\nperformance. Based on our insights we propose a framework to effectively\nidentify accountability for smart technology in education.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jul 2020 13:34:49 GMT"}], "update_date": "2020-07-14", "authors_parsed": [["Garshi", "Arian", ""], ["Jakobsen", "Malin Wist", ""], ["Nyborg-Christensen", "J\u00f8rgen", ""], ["Ostnes", "Daniel", ""], ["Ovchinnikova", "Maria", ""]]}, {"id": "2007.06381", "submitter": "Laura Rieger", "authors": "Laura Rieger, Lars Kai Hansen", "title": "A simple defense against adversarial attacks on heatmap explanations", "comments": "Accepted at 2020 Workshop on Human Interpretability in Machine\n  Learning (WHI)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With machine learning models being used for more sensitive applications, we\nrely on interpretability methods to prove that no discriminating attributes\nwere used for classification. A potential concern is the so-called\n\"fair-washing\" - manipulating a model such that the features used in reality\nare hidden and more innocuous features are shown to be important instead.\n  In our work we present an effective defence against such adversarial attacks\non neural networks. By a simple aggregation of multiple explanation methods,\nthe network becomes robust against manipulation. This holds even when the\nattacker has exact knowledge of the model weights and the explanation methods\nused.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jul 2020 13:44:13 GMT"}], "update_date": "2020-07-14", "authors_parsed": [["Rieger", "Laura", ""], ["Hansen", "Lars Kai", ""]]}, {"id": "2007.06477", "submitter": "Pasquale Minervini", "authors": "Pasquale Minervini, Sebastian Riedel, Pontus Stenetorp, Edward\n  Grefenstette, Tim Rockt\\\"aschel", "title": "Learning Reasoning Strategies in End-to-End Differentiable Proving", "comments": "Proceedings of the 37th International Conference on Machine Learning\n  (ICML 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.LG cs.NE cs.SC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Attempts to render deep learning models interpretable, data-efficient, and\nrobust have seen some success through hybridisation with rule-based systems,\nfor example, in Neural Theorem Provers (NTPs). These neuro-symbolic models can\ninduce interpretable rules and learn representations from data via\nback-propagation, while providing logical explanations for their predictions.\nHowever, they are restricted by their computational complexity, as they need to\nconsider all possible proof paths for explaining a goal, thus rendering them\nunfit for large-scale applications. We present Conditional Theorem Provers\n(CTPs), an extension to NTPs that learns an optimal rule selection strategy via\ngradient-based optimisation. We show that CTPs are scalable and yield\nstate-of-the-art results on the CLUTRR dataset, which tests systematic\ngeneralisation of neural models by learning to reason over smaller graphs and\nevaluating on larger ones. Finally, CTPs show better link prediction results on\nstandard benchmarks in comparison with other neural-symbolic models, while\nbeing explainable. All source code and datasets are available online, at\nhttps://github.com/uclnlp/ctp.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jul 2020 16:22:14 GMT"}, {"version": "v2", "created": "Tue, 14 Jul 2020 08:40:14 GMT"}, {"version": "v3", "created": "Mon, 24 Aug 2020 16:17:34 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Minervini", "Pasquale", ""], ["Riedel", "Sebastian", ""], ["Stenetorp", "Pontus", ""], ["Grefenstette", "Edward", ""], ["Rockt\u00e4schel", "Tim", ""]]}, {"id": "2007.06567", "submitter": "Gustav Sourek", "authors": "Gustav Sourek, Filip Zelezny, Ondrej Kuzelka", "title": "Lossless Compression of Structured Convolutional Models via Lifting", "comments": "Accepted to ICLR 2021. TL;DR: Speeding up weight-sharing dynamic\n  neural computation graphs, such as GNNs, with lifted inference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Lifting is an efficient technique to scale up graphical models generalized to\nrelational domains by exploiting the underlying symmetries. Concurrently,\nneural models are continuously expanding from grid-like tensor data into\nstructured representations, such as various attributed graphs and relational\ndatabases. To address the irregular structure of the data, the models typically\nextrapolate on the idea of convolution, effectively introducing parameter\nsharing in their, dynamically unfolded, computation graphs. The computation\ngraphs themselves then reflect the symmetries of the underlying data, similarly\nto the lifted graphical models. Inspired by lifting, we introduce a simple and\nefficient technique to detect the symmetries and compress the neural models\nwithout loss of any information. We demonstrate through experiments that such\ncompression can lead to significant speedups of structured convolutional\nmodels, such as various Graph Neural Networks, across various tasks, such as\nmolecule classification and knowledge-base completion.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jul 2020 08:02:27 GMT"}, {"version": "v2", "created": "Mon, 18 Jan 2021 12:49:03 GMT"}], "update_date": "2021-01-19", "authors_parsed": [["Sourek", "Gustav", ""], ["Zelezny", "Filip", ""], ["Kuzelka", "Ondrej", ""]]}, {"id": "2007.06677", "submitter": "Elizabeth Polgreen", "authors": "Nicolas Chan, Elizabeth Polgreen and Sanjit A. Seshia", "title": "Gradient Descent over Metagrammars for Syntax-Guided Synthesis", "comments": "5 pages, SYNT 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.AI cs.LG cs.PL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The performance of a syntax-guided synthesis algorithm is highly dependent on\nthe provision of a good syntactic template, or grammar. Provision of such a\ntemplate is often left to the user to do manually, though in the absence of\nsuch a grammar, state-of-the-art solvers will provide their own default\ngrammar, which is dependent on the signature of the target program to be\nsythesized. In this work, we speculate this default grammar could be improved\nupon substantially. We build sets of rules, or metagrammars, for constructing\ngrammars, and perform a gradient descent over these metagrammars aiming to find\na metagrammar which solves more benchmarks and on average faster. We show the\nresulting metagrammar enables CVC4 to solve 26% more benchmarks than the\ndefault grammar within a 300s time-out, and that metagrammars learnt from tens\nof benchmarks generalize to performance on 100s of benchmarks.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jul 2020 20:37:35 GMT"}, {"version": "v2", "created": "Thu, 16 Jul 2020 18:31:10 GMT"}], "update_date": "2020-07-20", "authors_parsed": [["Chan", "Nicolas", ""], ["Polgreen", "Elizabeth", ""], ["Seshia", "Sanjit A.", ""]]}, {"id": "2007.06699", "submitter": "Nisarg Shah", "authors": "Safwan Hossain, Evi Micha, Nisarg Shah", "title": "Fair Algorithms for Multi-Agent Multi-Armed Bandits", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.AI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  We propose a multi-agent variant of the classical multi-armed bandit problem,\nin which there are $N$ agents and $K$ arms, and pulling an arm generates a\n(possibly different) stochastic reward for each agent. Unlike the classical\nmulti-armed bandit problem, the goal is not to learn the \"best arm\"; indeed,\neach agent may perceive a different arm to be the best for her personally.\nInstead, we seek to learn a fair distribution over the arms. Drawing on a long\nline of research in economics and computer science, we use the Nash social\nwelfare as our notion of fairness. We design multi-agent variants of three\nclassic multi-armed bandit algorithms and show that they achieve sublinear\nregret, which is now measured in terms of the lost Nash social welfare.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jul 2020 21:20:04 GMT"}, {"version": "v2", "created": "Wed, 24 Feb 2021 02:43:57 GMT"}], "update_date": "2021-02-25", "authors_parsed": [["Hossain", "Safwan", ""], ["Micha", "Evi", ""], ["Shah", "Nisarg", ""]]}, {"id": "2007.06702", "submitter": "Rushang Karia", "authors": "Rushang Karia, Siddharth Srivastava", "title": "Learning Generalized Relational Heuristic Networks for Model-Agnostic\n  Planning", "comments": "Submitted to AAAI-21", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computing goal-directed behavior is essential to designing efficient AI\nsystems. Due to the computational complexity of planning, current approaches\nrely primarily upon hand-coded symbolic action models and hand-coded\nheuristic-function generators for efficiency. Learned heuristics for such\nproblems have been of limited utility as they are difficult to apply to\nproblems with objects and object quantities that are significantly different\nfrom those in the training data. This paper develops a new approach for\nlearning generalized heuristics in the absence of symbolic action models using\ndeep neural networks that utilize an input predicate vocabulary but are\nagnostic to object names and quantities. It uses an abstract state\nrepresentation to facilitate data efficient, generalizable learning. Empirical\nevaluation on a range of benchmark domains show that in contrast to prior\napproaches, generalized heuristics computed by this method can be transferred\neasily to problems with different objects and with object quantities much\nlarger than those in the training data.\n", "versions": [{"version": "v1", "created": "Fri, 10 Jul 2020 06:08:28 GMT"}, {"version": "v2", "created": "Tue, 20 Oct 2020 03:04:41 GMT"}], "update_date": "2020-10-21", "authors_parsed": [["Karia", "Rushang", ""], ["Srivastava", "Siddharth", ""]]}, {"id": "2007.06703", "submitter": "Shangtong Zhang", "authors": "Shangtong Zhang, Vivek Veeriah, Shimon Whiteson", "title": "Learning Retrospective Knowledge with Reverse Reinforcement Learning", "comments": "NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a Reverse Reinforcement Learning (Reverse RL) approach for\nrepresenting retrospective knowledge. General Value Functions (GVFs) have\nenjoyed great success in representing predictive knowledge, i.e., answering\nquestions about possible future outcomes such as \"how much fuel will be\nconsumed in expectation if we drive from A to B?\". GVFs, however, cannot answer\nquestions like \"how much fuel do we expect a car to have given it is at B at\ntime $t$?\". To answer this question, we need to know when that car had a full\ntank and how that car came to B. Since such questions emphasize the influence\nof possible past events on the present, we refer to their answers as\nretrospective knowledge. In this paper, we show how to represent retrospective\nknowledge with Reverse GVFs, which are trained via Reverse RL. We demonstrate\nempirically the utility of Reverse GVFs in both representation learning and\nanomaly detection.\n", "versions": [{"version": "v1", "created": "Thu, 9 Jul 2020 20:56:22 GMT"}, {"version": "v2", "created": "Sun, 18 Oct 2020 16:41:12 GMT"}, {"version": "v3", "created": "Sun, 1 Nov 2020 18:12:00 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Zhang", "Shangtong", ""], ["Veeriah", "Vivek", ""], ["Whiteson", "Shimon", ""]]}, {"id": "2007.06720", "submitter": "Kourosh Darvish", "authors": "Prajval Kumar Murali, Kourosh Darvish, Fulvio Mastrogiovanni", "title": "Deployment and Evaluation of a Flexible Human-Robot Collaboration Model\n  Based on AND/OR Graphs in a Manufacturing Environment", "comments": null, "journal-ref": null, "doi": "10.1007/s11370-020-00332-9", "report-no": null, "categories": "cs.RO cs.AI cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Industry 4.0 paradigm promises shorter development times, increased\nergonomy, higher flexibility, and resource efficiency in manufacturing\nenvironments. Collaborative robots are an important tangible technology for\nimplementing such a paradigm. A major bottleneck to effectively deploy\ncollaborative robots to manufacturing industries is developing task planning\nalgorithms that enable them to recognize and naturally adapt to varying and\neven unpredictable human actions while simultaneously ensuring an overall\nefficiency in terms of production cycle time. In this context, an architecture\nencompassing task representation, task planning, sensing, and robot control has\nbeen designed, developed and evaluated in a real industrial environment. A\npick-and-place palletization task, which requires the collaboration between\nhumans and robots, is investigated. The architecture uses AND/OR graphs for\nrepresenting and reasoning upon human-robot collaboration models online.\nFurthermore, objective measures of the overall computational performance and\nsubjective measures of naturalness in human-robot collaboration have been\nevaluated by performing experiments with production-line operators. The results\nof this user study demonstrate how human-robot collaboration models like the\none we propose can leverage the flexibility and the comfort of operators in the\nworkplace. In this regard, an extensive comparison study among recent models\nhas been carried out.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jul 2020 22:05:34 GMT"}], "update_date": "2020-07-15", "authors_parsed": [["Murali", "Prajval Kumar", ""], ["Darvish", "Kourosh", ""], ["Mastrogiovanni", "Fulvio", ""]]}, {"id": "2007.06727", "submitter": "You Li", "authors": "You Li, Ruizhi Chen, Xiaoji Niu, Yuan Zhuang, Zhouzheng Gao, Xin Hu,\n  Naser El-Sheimy", "title": "Inertial Sensing Meets Artificial Intelligence: Opportunity or\n  Challenge?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The inertial navigation system (INS) has been widely used to provide\nself-contained and continuous motion estimation in intelligent transportation\nsystems. Recently, the emergence of chip-level inertial sensors has expanded\nthe relevant applications from positioning, navigation, and mobile mapping to\nlocation-based services, unmanned systems, and transportation big data.\nMeanwhile, benefit from the emergence of big data and the improvement of\nalgorithms and computing power, artificial intelligence (AI) has become a\nconsensus tool that has been successfully applied in various fields. This\narticle reviews the research on using AI technology to enhance inertial sensing\nfrom various aspects, including sensor design and selection, calibration and\nerror modeling, navigation and motion-sensing algorithms, multi-sensor\ninformation fusion, system evaluation, and practical application. Based on the\nover 30 representative articles selected from the nearly 300 related\npublications, this article summarizes the state of the art, advantages, and\nchallenges on each aspect. Finally, it summarizes nine advantages and nine\nchallenges of AI-enhanced inertial sensing and then points out future research\ndirections.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jul 2020 22:33:21 GMT"}], "update_date": "2020-07-15", "authors_parsed": [["Li", "You", ""], ["Chen", "Ruizhi", ""], ["Niu", "Xiaoji", ""], ["Zhuang", "Yuan", ""], ["Gao", "Zhouzheng", ""], ["Hu", "Xin", ""], ["El-Sheimy", "Naser", ""]]}, {"id": "2007.06776", "submitter": "Tristan Jean-Baptiste", "authors": "Jean-Baptiste Tristan, Joseph Tassarotti, Koundinya Vajjha, Michael L.\n  Wick, Anindya Banerjee", "title": "Verification of ML Systems via Reparameterization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As machine learning is increasingly used in essential systems, it is\nimportant to reduce or eliminate the incidence of serious bugs. A growing body\nof research has developed machine learning algorithms with formal guarantees\nabout performance, robustness, or fairness. Yet, the analysis of these\nalgorithms is often complex, and implementing such systems in practice\nintroduces room for error. Proof assistants can be used to formally verify\nmachine learning systems by constructing machine checked proofs of correctness\nthat rule out such bugs. However, reasoning about probabilistic claims inside\nof a proof assistant remains challenging. We show how a probabilistic program\ncan be automatically represented in a theorem prover using the concept of\n\\emph{reparameterization}, and how some of the tedious proofs of measurability\ncan be generated automatically from the probabilistic program. To demonstrate\nthat this approach is broad enough to handle rather different types of machine\nlearning systems, we verify both a classic result from statistical learning\ntheory (PAC-learnability of decision stumps) and prove that the null model used\nin a Bayesian hypothesis test satisfies a fairness criterion called demographic\nparity.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jul 2020 02:19:25 GMT"}], "update_date": "2020-07-15", "authors_parsed": [["Tristan", "Jean-Baptiste", ""], ["Tassarotti", "Joseph", ""], ["Vajjha", "Koundinya", ""], ["Wick", "Michael L.", ""], ["Banerjee", "Anindya", ""]]}, {"id": "2007.06796", "submitter": "Anubha Kabra Ms", "authors": "Yaman Kumar, Mehar Bhatia, Anubha Kabra, Jessy Junyi Li, Di Jin, Rajiv\n  Ratn Shah", "title": "Calling Out Bluff: Attacking the Robustness of Automatic Scoring Systems\n  with Simple Adversarial Testing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A significant progress has been made in deep-learning based Automatic Essay\nScoring (AES) systems in the past two decades. The performance commonly\nmeasured by the standard performance metrics like Quadratic Weighted Kappa\n(QWK), and accuracy points to the same. However, testing on common-sense\nadversarial examples of these AES systems reveal their lack of natural language\nunderstanding capability. Inspired by common student behaviour during\nexaminations, we propose a task agnostic adversarial evaluation scheme for AES\nsystems to test their natural language understanding capabilities and overall\nrobustness.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jul 2020 03:49:43 GMT"}, {"version": "v2", "created": "Tue, 10 Nov 2020 23:24:07 GMT"}, {"version": "v3", "created": "Sat, 2 Jan 2021 06:46:13 GMT"}], "update_date": "2021-01-05", "authors_parsed": [["Kumar", "Yaman", ""], ["Bhatia", "Mehar", ""], ["Kabra", "Anubha", ""], ["Li", "Jessy Junyi", ""], ["Jin", "Di", ""], ["Shah", "Rajiv Ratn", ""]]}, {"id": "2007.06835", "submitter": "Nagarajan Natarajan", "authors": "Nagarajan Natarajan, Ajaykrishna Karthikeyan, Prateek Jain, Ivan\n  Radicek, Sriram Rajamani, Sumit Gulwani, Johannes Gehrke", "title": "Programming by Rewards", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.PL cs.SE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We formalize and study ``programming by rewards'' (PBR), a new approach for\nspecifying and synthesizing subroutines for optimizing some quantitative metric\nsuch as performance, resource utilization, or correctness over a benchmark. A\nPBR specification consists of (1) input features $x$, and (2) a reward function\n$r$, modeled as a black-box component (which we can only run), that assigns a\nreward for each execution. The goal of the synthesizer is to synthesize a\n\"decision function\" $f$ which transforms the features to a decision value for\nthe black-box component so as to maximize the expected reward $E[r \\circ f\n(x)]$ for executing decisions $f(x)$ for various values of $x$. We consider a\nspace of decision functions in a DSL of loop-free if-then-else programs, which\ncan branch on linear functions of the input features in a tree-structure and\ncompute a linear function of the inputs in the leaves of the tree. We find that\nthis DSL captures decision functions that are manually written in practice by\nprogrammers. Our technical contribution is the use of continuous-optimization\ntechniques to perform synthesis of such decision functions as if-then-else\nprograms. We also show that the framework is theoretically-founded ---in cases\nwhen the rewards satisfy nice properties, the synthesized code is optimal in a\nprecise sense.\n  We have leveraged PBR to synthesize non-trivial decision functions related to\nsearch and ranking heuristics in the PROSE codebase (an industrial strength\nprogram synthesis framework) and achieve competitive results to manually\nwritten procedures over multiple man years of tuning. We present empirical\nevaluation against other baseline techniques over real-world case studies\n(including PROSE) as well on simple synthetic benchmarks.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jul 2020 05:49:14 GMT"}], "update_date": "2020-07-15", "authors_parsed": [["Natarajan", "Nagarajan", ""], ["Karthikeyan", "Ajaykrishna", ""], ["Jain", "Prateek", ""], ["Radicek", "Ivan", ""], ["Rajamani", "Sriram", ""], ["Gulwani", "Sumit", ""], ["Gehrke", "Johannes", ""]]}, {"id": "2007.06850", "submitter": "Natalia Criado", "authors": "Jordi Ganzer, Natalia Criado, Maite Lopez-Sanchez, Simon Parsons, Juan\n  A. Rodriguez-Aguilar", "title": "A model to support collective reasoning: Formalization, analysis and\n  computational assessment", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inspired by e-participation systems, in this paper we propose a new model to\nrepresent human debates and methods to obtain collective conclusions from them.\nThis model overcomes drawbacks of existing approaches by allowing users to\nintroduce new pieces of information into the discussion, to relate them to\nexisting pieces, and also to express their opinion on the pieces proposed by\nother users. In addition, our model does not assume that users' opinions are\nrational in order to extract information from it, an assumption that\nsignificantly limits current approaches. Instead, we define a weaker notion of\nrationality that characterises coherent opinions, and we consider different\nscenarios based on the coherence of individual opinions and the level of\nconsensus that users have on the debate structure. Considering these two\nfactors, we analyse the outcomes of different opinion aggregation functions\nthat compute a collective decision based on the individual opinions and the\ndebate structure. In particular, we demonstrate that aggregated opinions can be\ncoherent even if there is a lack of consensus and individual opinions are not\ncoherent. We conclude our analysis with a computational evaluation\ndemonstrating that collective opinions can be computed efficiently for\nreal-sized debates.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jul 2020 06:55:32 GMT"}], "update_date": "2020-07-15", "authors_parsed": [["Ganzer", "Jordi", ""], ["Criado", "Natalia", ""], ["Lopez-Sanchez", "Maite", ""], ["Parsons", "Simon", ""], ["Rodriguez-Aguilar", "Juan A.", ""]]}, {"id": "2007.06852", "submitter": "Walid Krichene", "authors": "Walid Krichene, Kenneth F. Caluya, Abhishek Halder", "title": "Global Convergence of Second-order Dynamics in Two-layer Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent results have shown that for two-layer fully connected neural networks,\ngradient flow converges to a global optimum in the infinite width limit, by\nmaking a connection between the mean field dynamics and the Wasserstein\ngradient flow. These results were derived for first-order gradient flow, and a\nnatural question is whether second-order dynamics, i.e., dynamics with\nmomentum, exhibit a similar guarantee. We show that the answer is positive for\nthe heavy ball method. In this case, the resulting integro-PDE is a nonlinear\nkinetic Fokker Planck equation, and unlike the first-order case, it has no\napparent connection with the Wasserstein gradient flow. Instead, we study the\nvariations of a Lyapunov functional along the solution trajectories to\ncharacterize the stationary points and to prove convergence. While our results\nare asymptotic in the mean field limit, numerical simulations indicate that\nglobal convergence may already occur for reasonably small networks.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jul 2020 07:01:57 GMT"}], "update_date": "2020-07-16", "authors_parsed": [["Krichene", "Walid", ""], ["Caluya", "Kenneth F.", ""], ["Halder", "Abhishek", ""]]}, {"id": "2007.06869", "submitter": "Karthik Abinav Sankararaman", "authors": "Karthik Abinav Sankararaman, Anand Louis, Navin Goyal", "title": "Robust Identifiability in Linear Structural Equation Models of Causal\n  Inference", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we consider the problem of robust parameter estimation from\nobservational data in the context of linear structural equation models (LSEMs).\nLSEMs are a popular and well-studied class of models for inferring causality in\nthe natural and social sciences. One of the main problems related to LSEMs is\nto recover the model parameters from the observational data. Under various\nconditions on LSEMs and the model parameters the prior work provides efficient\nalgorithms to recover the parameters. However, these results are often about\ngeneric identifiability. In practice, generic identifiability is not sufficient\nand we need robust identifiability: small changes in the observational data\nshould not affect the parameters by a huge amount. Robust identifiability has\nreceived far less attention and remains poorly understood. Sankararaman et al.\n(2019) recently provided a set of sufficient conditions on parameters under\nwhich robust identifiability is feasible. However, a limitation of their work\nis that their results only apply to a small sub-class of LSEMs, called\n``bow-free paths.'' In this work, we significantly extend their work along\nmultiple dimensions. First, for a large and well-studied class of LSEMs, namely\n``bow free'' models, we provide a sufficient condition on model parameters\nunder which robust identifiability holds, thereby removing the restriction of\npaths required by prior work. We then show that this sufficient condition holds\nwith high probability which implies that for a large set of parameters robust\nidentifiability holds and that for such parameters, existing algorithms already\nachieve robust identifiability. Finally, we validate our results on both\nsimulated and real-world datasets.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jul 2020 07:32:36 GMT"}], "update_date": "2020-07-15", "authors_parsed": [["Sankararaman", "Karthik Abinav", ""], ["Louis", "Anand", ""], ["Goyal", "Navin", ""]]}, {"id": "2007.06898", "submitter": "Swaroop Mishra", "authors": "Swaroop Mishra, Anjana Arunkumar, Chris Bryan and Chitta Baral", "title": "Our Evaluation Metric Needs an Update to Encourage Generalization", "comments": "Accepted to ICML UDL 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Models that surpass human performance on several popular benchmarks display\nsignificant degradation in performance on exposure to Out of Distribution (OOD)\ndata. Recent research has shown that models overfit to spurious biases and\n`hack' datasets, in lieu of learning generalizable features like humans. In\norder to stop the inflation in model performance -- and thus overestimation in\nAI systems' capabilities -- we propose a simple and novel evaluation metric,\nWOOD Score, that encourages generalization during evaluation.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jul 2020 08:15:19 GMT"}], "update_date": "2020-07-15", "authors_parsed": [["Mishra", "Swaroop", ""], ["Arunkumar", "Anjana", ""], ["Bryan", "Chris", ""], ["Baral", "Chitta", ""]]}, {"id": "2007.06918", "submitter": "Aswin Raghavan", "authors": "Aswin Raghavan, Jesse Hostetler, Indranil Sur, Abrar Rahman, Ajay\n  Divakaran", "title": "Lifelong Learning using Eigentasks: Task Separation, Skill Acquisition,\n  and Selective Transfer", "comments": "Accepted at the 4th Lifelong Machine Learning Workshop at the\n  Thirty-seventh International Conference on Machine Learning (ICML) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce the eigentask framework for lifelong learning. An eigentask is a\npairing of a skill that solves a set of related tasks, paired with a generative\nmodel that can sample from the skill's input space. The framework extends\ngenerative replay approaches, which have mainly been used to avoid catastrophic\nforgetting, to also address other lifelong learning goals such as forward\nknowledge transfer. We propose a wake-sleep cycle of alternating task learning\nand knowledge consolidation for learning in our framework, and instantiate it\nfor lifelong supervised learning and lifelong RL. We achieve improved\nperformance over the state-of-the-art in supervised continual learning, and\nshow evidence of forward knowledge transfer in a lifelong RL application in the\ngame Starcraft2.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jul 2020 09:06:13 GMT"}], "update_date": "2020-07-15", "authors_parsed": [["Raghavan", "Aswin", ""], ["Hostetler", "Jesse", ""], ["Sur", "Indranil", ""], ["Rahman", "Abrar", ""], ["Divakaran", "Ajay", ""]]}, {"id": "2007.07011", "submitter": "Jorge A Mendez", "authors": "Jorge A. Mendez and Boyu Wang and Eric Eaton", "title": "Lifelong Policy Gradient Learning of Factored Policies for Faster\n  Training Without Forgetting", "comments": "To appear in Advances in Neural Information Processing Systems 33\n  (NeurIPS-20)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Policy gradient methods have shown success in learning control policies for\nhigh-dimensional dynamical systems. Their biggest downside is the amount of\nexploration they require before yielding high-performing policies. In a\nlifelong learning setting, in which an agent is faced with multiple consecutive\ntasks over its lifetime, reusing information from previously seen tasks can\nsubstantially accelerate the learning of new tasks. We provide a novel method\nfor lifelong policy gradient learning that trains lifelong function\napproximators directly via policy gradients, allowing the agent to benefit from\naccumulated knowledge throughout the entire training process. We show\nempirically that our algorithm learns faster and converges to better policies\nthan single-task and lifelong learning baselines, and completely avoids\ncatastrophic forgetting on a variety of challenging domains.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jul 2020 13:05:42 GMT"}, {"version": "v2", "created": "Wed, 21 Oct 2020 20:36:14 GMT"}], "update_date": "2020-10-23", "authors_parsed": [["Mendez", "Jorge A.", ""], ["Wang", "Boyu", ""], ["Eaton", "Eric", ""]]}, {"id": "2007.07079", "submitter": "Tanner Fiez", "authors": "Tanner Fiez, Nihar B. Shah, Lillian Ratliff", "title": "A SUPER* Algorithm to Optimize Paper Bidding in Peer Review", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A number of applications involve sequential arrival of users, and require\nshowing each user an ordering of items. A prime example (which forms the focus\nof this paper) is the bidding process in conference peer review where reviewers\nenter the system sequentially, each reviewer needs to be shown the list of\nsubmitted papers, and the reviewer then \"bids\" to review some papers. The order\nof the papers shown has a significant impact on the bids due to primacy\neffects. In deciding on the ordering of papers to show, there are two competing\ngoals: (i) obtaining sufficiently many bids for each paper, and (ii) satisfying\nreviewers by showing them relevant items. In this paper, we begin by developing\na framework to study this problem in a principled manner. We present an\nalgorithm called SUPER*, inspired by the A* algorithm, for this goal.\nTheoretically, we show a local optimality guarantee of our algorithm and prove\nthat popular baselines are considerably suboptimal. Moreover, under a community\nmodel for the similarities, we prove that SUPER* is near-optimal whereas the\npopular baselines are considerably suboptimal. In experiments on real data from\nICLR 2018 and synthetic data, we find that SUPER* considerably outperforms\nbaselines deployed in existing systems, consistently reducing the number of\npapers with fewer than requisite bids by 50-75% or more, and is also robust to\nvarious real world complexities.\n", "versions": [{"version": "v1", "created": "Sat, 27 Jun 2020 06:44:49 GMT"}, {"version": "v2", "created": "Fri, 31 Jul 2020 17:47:45 GMT"}], "update_date": "2020-08-03", "authors_parsed": [["Fiez", "Tanner", ""], ["Shah", "Nihar B.", ""], ["Ratliff", "Lillian", ""]]}, {"id": "2007.07092", "submitter": "Xavier Ferrer Aran", "authors": "Natalia Criado, Xavier Ferrer, Jose M. Such", "title": "A Normative approach to Attest Digital Discrimination", "comments": "Author's copy of the manuscript accepted in the Advancing Towards the\n  SDGS Artificial Intelligence for a Fair, Just and Equitable World Workshop of\n  the 24th European Conference on Artificial Intelligence (ECAI'20)", "journal-ref": "Advancing Towards the SDGS Artificial Intelligence for a Fair,\n  Just and Equitable World Workshop of the 24th European Conference on\n  Artificial Intelligence 2020 (ECAI'20)", "doi": null, "report-no": null, "categories": "cs.AI cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Digital discrimination is a form of discrimination whereby users are\nautomatically treated unfairly, unethically or just differently based on their\npersonal data by a machine learning (ML) system. Examples of digital\ndiscrimination include low-income neighbourhood's targeted with high-interest\nloans or low credit scores, and women being undervalued by 21% in online\nmarketing. Recently, different techniques and tools have been proposed to\ndetect biases that may lead to digital discrimination. These tools often\nrequire technical expertise to be executed and for their results to be\ninterpreted. To allow non-technical users to benefit from ML, simpler notions\nand concepts to represent and reason about digital discrimination are needed.\nIn this paper, we use norms as an abstraction to represent different situations\nthat may lead to digital discrimination. In particular, we formalise\nnon-discrimination norms in the context of ML systems and propose an algorithm\nto check whether ML systems violate these norms.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jul 2020 15:14:52 GMT"}, {"version": "v2", "created": "Mon, 3 Aug 2020 11:39:18 GMT"}], "update_date": "2021-06-07", "authors_parsed": [["Criado", "Natalia", ""], ["Ferrer", "Xavier", ""], ["Such", "Jose M.", ""]]}, {"id": "2007.07151", "submitter": "Kundan Krishna", "authors": "Kundan Krishna, Amy Pavel, Benjamin Schloss, Jeffrey P. Bigham,\n  Zachary C. Lipton", "title": "Extracting Structured Data from Physician-Patient Conversations By\n  Predicting Noteworthy Utterances", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite diverse efforts to mine various modalities of medical data, the\nconversations between physicians and patients at the time of care remain an\nuntapped source of insights. In this paper, we leverage this data to extract\nstructured information that might assist physicians with post-visit\ndocumentation in electronic health records, potentially lightening the clerical\nburden. In this exploratory study, we describe a new dataset consisting of\nconversation transcripts, post-visit summaries, corresponding supporting\nevidence (in the transcript), and structured labels. We focus on the tasks of\nrecognizing relevant diagnoses and abnormalities in the review of organ systems\n(RoS). One methodological challenge is that the conversations are long (around\n1500 words), making it difficult for modern deep-learning models to use them as\ninput. To address this challenge, we extract noteworthy utterances---parts of\nthe conversation likely to be cited as evidence supporting some summary\nsentence. We find that by first filtering for (predicted) noteworthy\nutterances, we can significantly boost predictive performance for recognizing\nboth diagnoses and RoS abnormalities.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jul 2020 16:10:37 GMT"}], "update_date": "2020-07-15", "authors_parsed": [["Krishna", "Kundan", ""], ["Pavel", "Amy", ""], ["Schloss", "Benjamin", ""], ["Bigham", "Jeffrey P.", ""], ["Lipton", "Zachary C.", ""]]}, {"id": "2007.07170", "submitter": "Suraj Nair", "authors": "Suraj Nair, Silvio Savarese, Chelsea Finn", "title": "Goal-Aware Prediction: Learning to Model What Matters", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learned dynamics models combined with both planning and policy learning\nalgorithms have shown promise in enabling artificial agents to learn to perform\nmany diverse tasks with limited supervision. However, one of the fundamental\nchallenges in using a learned forward dynamics model is the mismatch between\nthe objective of the learned model (future state reconstruction), and that of\nthe downstream planner or policy (completing a specified task). This issue is\nexacerbated by vision-based control tasks in diverse real-world environments,\nwhere the complexity of the real world dwarfs model capacity. In this paper, we\npropose to direct prediction towards task relevant information, enabling the\nmodel to be aware of the current task and encouraging it to only model relevant\nquantities of the state space, resulting in a learning objective that more\nclosely matches the downstream task. Further, we do so in an entirely\nself-supervised manner, without the need for a reward function or image labels.\nWe find that our method more effectively models the relevant parts of the scene\nconditioned on the goal, and as a result outperforms standard task-agnostic\ndynamics models and model-free reinforcement learning.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jul 2020 16:42:59 GMT"}, {"version": "v2", "created": "Mon, 10 Aug 2020 23:15:15 GMT"}], "update_date": "2020-08-12", "authors_parsed": [["Nair", "Suraj", ""], ["Savarese", "Silvio", ""], ["Finn", "Chelsea", ""]]}, {"id": "2007.07183", "submitter": "Tineke Blom", "authors": "Tineke Blom and Mirthe M. van Diepen and Joris M. Mooij", "title": "Conditional independences and causal relations implied by sets of\n  equations", "comments": "60 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Real-world complex systems are often modelled by sets of equations with\nendogenous and exogenous variables. What can we say about the causal and\nprobabilistic aspects of variables that appear in these equations without\nexplicitly solving the equations? We make use of Simon's causal ordering\nalgorithm (Simon, 1953) to construct a causal ordering graph and prove that it\nexpresses the effects of soft and perfect interventions on the equations under\ncertain unique solvability assumptions. We further construct a Markov ordering\ngraph and prove that it encodes conditional independences in the distribution\nimplied by the equations with independent random exogenous variables, under a\nsimilar unique solvability assumption. We discuss how this approach reveals and\naddresses some of the limitations of existing causal modelling frameworks, such\nas causal Bayesian networks and structural causal models.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jul 2020 17:00:28 GMT"}, {"version": "v2", "created": "Sun, 31 Jan 2021 17:37:16 GMT"}], "update_date": "2021-02-02", "authors_parsed": [["Blom", "Tineke", ""], ["van Diepen", "Mirthe M.", ""], ["Mooij", "Joris M.", ""]]}, {"id": "2007.07195", "submitter": "Hao Liu", "authors": "Hao Liu, Ying Li, Yanjie Fu, Huaibo Mei, Jingbo Zhou, Xu Ma, Hui Xiong", "title": "Polestar: An Intelligent, Efficient and National-Wide Public\n  Transportation Routing Engine", "comments": null, "journal-ref": "KDD 2020 applied data science track", "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Public transportation plays a critical role in people's daily life. It has\nbeen proven that public transportation is more environmentally sustainable,\nefficient, and economical than any other forms of travel. However, due to the\nincreasing expansion of transportation networks and more complex travel\nsituations, people are having difficulties in efficiently finding the most\npreferred route from one place to another through public transportation\nsystems. To this end, in this paper, we present Polestar, a data-driven engine\nfor intelligent and efficient public transportation routing. Specifically, we\nfirst propose a novel Public Transportation Graph (PTG) to model public\ntransportation system in terms of various travel costs, such as time or\ndistance. Then, we introduce a general route search algorithm coupled with an\nefficient station binding method for efficient route candidate generation.\nAfter that, we propose a two-pass route candidate ranking module to capture\nuser preferences under dynamic travel situations. Finally, experiments on two\nreal-world data sets demonstrate the advantages of Polestar in terms of both\nefficiency and effectiveness. Indeed, in early 2019, Polestar has been deployed\non Baidu Maps, one of the world's largest map services. To date, Polestar is\nservicing over 330 cities, answers over a hundred millions of queries each day,\nand achieves substantial improvement of user click ratio.\n", "versions": [{"version": "v1", "created": "Sat, 11 Jul 2020 05:14:52 GMT"}], "update_date": "2020-07-15", "authors_parsed": [["Liu", "Hao", ""], ["Li", "Ying", ""], ["Fu", "Yanjie", ""], ["Mei", "Huaibo", ""], ["Zhou", "Jingbo", ""], ["Ma", "Xu", ""], ["Xiong", "Hui", ""]]}, {"id": "2007.07196", "submitter": "ChengHao Ho", "authors": "Hung-yi Lee, Cheng-Hao Ho, Chien-Fu Lin, Chiung-Chih Chang, Chih-Wei\n  Lee, Yau-Shian Wang, Tsung-Yuan Hsu and Kuan-Yu Chen", "title": "Investigation of Sentiment Controllable Chatbot", "comments": "arXiv admin note: text overlap with arXiv:1804.02504", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conventional seq2seq chatbot models attempt only to find sentences with the\nhighest probabilities conditioned on the input sequences, without considering\nthe sentiment of the output sentences. In this paper, we investigate four\nmodels to scale or adjust the sentiment of the chatbot response: a\npersona-based model, reinforcement learning, a plug and play model, and\nCycleGAN, all based on the seq2seq model. We also develop machine-evaluated\nmetrics to estimate whether the responses are reasonable given the input. These\nmetrics, together with human evaluation, are used to analyze the performance of\nthe four models in terms of different aspects; reinforcement learning and\nCycleGAN are shown to be very attractive.\n", "versions": [{"version": "v1", "created": "Sat, 11 Jul 2020 16:04:30 GMT"}], "update_date": "2020-07-15", "authors_parsed": [["Lee", "Hung-yi", ""], ["Ho", "Cheng-Hao", ""], ["Lin", "Chien-Fu", ""], ["Chang", "Chiung-Chih", ""], ["Lee", "Chih-Wei", ""], ["Wang", "Yau-Shian", ""], ["Hsu", "Tsung-Yuan", ""], ["Chen", "Kuan-Yu", ""]]}, {"id": "2007.07206", "submitter": "Amy Zhang", "authors": "Amy Zhang, Shagun Sodhani, Khimya Khetarpal, Joelle Pineau", "title": "Learning Robust State Abstractions for Hidden-Parameter Block MDPs", "comments": "Accepted at the 9th International Conference on Learning\n  Representations. 22 pages, 14 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many control tasks exhibit similar dynamics that can be modeled as having\ncommon latent structure. Hidden-Parameter Markov Decision Processes (HiP-MDPs)\nexplicitly model this structure to improve sample efficiency in multi-task\nsettings. However, this setting makes strong assumptions on the observability\nof the state that limit its application in real-world scenarios with rich\nobservation spaces. In this work, we leverage ideas of common structure from\nthe HiP-MDP setting, and extend it to enable robust state abstractions inspired\nby Block MDPs. We derive instantiations of this new framework for both\nmulti-task reinforcement learning (MTRL) and meta-reinforcement learning\n(Meta-RL) settings. Further, we provide transfer and generalization bounds\nbased on task and state similarity, along with sample complexity bounds that\ndepend on the aggregate number of samples across tasks, rather than the number\nof tasks, a significant improvement over prior work that use the same\nenvironment assumptions. To further demonstrate the efficacy of the proposed\nmethod, we empirically compare and show improvement over multi-task and\nmeta-reinforcement learning baselines.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jul 2020 17:25:27 GMT"}, {"version": "v2", "created": "Tue, 28 Jul 2020 14:37:00 GMT"}, {"version": "v3", "created": "Thu, 14 Jan 2021 18:08:05 GMT"}, {"version": "v4", "created": "Fri, 12 Feb 2021 04:40:14 GMT"}], "update_date": "2021-02-15", "authors_parsed": [["Zhang", "Amy", ""], ["Sodhani", "Shagun", ""], ["Khetarpal", "Khimya", ""], ["Pineau", "Joelle", ""]]}, {"id": "2007.07218", "submitter": "Dengxin Dai", "authors": "Simon Hecker, Dengxin Dai, Alexander Liniger, Luc Van Gool", "title": "Learning Accurate and Human-Like Driving using Semantic Maps and\n  Attention", "comments": "IROS 2020 final version. arXiv admin note: text overlap with\n  arXiv:1903.10995", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper investigates how end-to-end driving models can be improved to\ndrive more accurately and human-like. To tackle the first issue we exploit\nsemantic and visual maps from HERE Technologies and augment the existing\nDrive360 dataset with such. The maps are used in an attention mechanism that\npromotes segmentation confidence masks, thus focusing the network on semantic\nclasses in the image that are important for the current driving situation.\nHuman-like driving is achieved using adversarial learning, by not only\nminimizing the imitation loss with respect to the human driver but by further\ndefining a discriminator, that forces the driving model to produce action\nsequences that are human-like. Our models are trained and evaluated on the\nDrive360 + HERE dataset, which features 60 hours and 3000 km of real-world\ndriving data. Extensive experiments show that our driving models are more\naccurate and behave more human-like than previous methods.\n", "versions": [{"version": "v1", "created": "Fri, 10 Jul 2020 22:25:27 GMT"}], "update_date": "2020-07-15", "authors_parsed": [["Hecker", "Simon", ""], ["Dai", "Dengxin", ""], ["Liniger", "Alexander", ""], ["Van Gool", "Luc", ""]]}, {"id": "2007.07220", "submitter": "Nicolas A. Barriga", "authors": "Gabriel K. Sepulveda, Felipe Besoain, and Nicolas A. Barriga", "title": "Exploring Dynamic Difficulty Adjustment in Videogames", "comments": null, "journal-ref": null, "doi": "10.1109/CHILECON47746.2019.8988068", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Videogames are nowadays one of the biggest entertainment industries in the\nworld. Being part of this industry means competing against lots of other\ncompanies and developers, thus, making fanbases of vital importance. They are a\ngroup of clients that constantly support your company because your video games\nare fun. Videogames are most entertaining when the difficulty level is a good\nmatch for the player's skill, increasing the player engagement. However, not\nall players are equally proficient, so some kind of difficulty selection is\nrequired. In this paper, we will present Dynamic Difficulty Adjustment (DDA), a\nrecently arising research topic, which aims to develop an automated difficulty\nselection mechanism that keeps the player engaged and properly challenged,\nneither bored nor overwhelmed. We will present some recent research addressing\nthis issue, as well as an overview of how to implement it. Satisfactorily\nsolving the DDA problem directly affects the player's experience when playing\nthe game, making it of high interest to any game developer, from independent\nones, to 100 billion dollar businesses, because of the potential impacts in\nplayer retention and monetization.\n", "versions": [{"version": "v1", "created": "Mon, 6 Jul 2020 15:05:20 GMT"}], "update_date": "2020-07-15", "authors_parsed": [["Sepulveda", "Gabriel K.", ""], ["Besoain", "Felipe", ""], ["Barriga", "Nicolas A.", ""]]}, {"id": "2007.07250", "submitter": "Niloofar Shadab", "authors": "Niloofar Shadab, Alejandro Salado", "title": "Towards an Interface Description Template for AI-enabled Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reuse is a common system architecture approach that seeks to instantiate a\nsystem architecture with existing components. However, reusing components with\nAI capabilities might introduce new risks as there is currently no framework\nthat guides the selection of necessary information to assess their portability\nto operate in a system different than the one for which the component was\noriginally purposed. We know from SW-intensive systems that AI algorithms are\ngenerally fragile and behave unexpectedly to changes in context and boundary\nconditions. The question we address in this paper is, what type of information\nshould be captured in the Interface Control Document (ICD) of an AI-enabled\nsystem or component to assess its compatibility with a system for which it was\nnot designed originally. We present ongoing work on establishing an interface\ndescription template that captures the main information of an AI-enabled\ncomponent to facilitate its adequate reuse across different systems and\noperational contexts. Our work is inspired by Google's Model Card concept,\nwhich was developed with the same goal but focused on the reusability of AI\nalgorithms. We extend that concept to address system-level autonomy\ncapabilities of AI-enabled cyber-physical systems.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jul 2020 20:30:26 GMT"}], "update_date": "2020-07-16", "authors_parsed": [["Shadab", "Niloofar", ""], ["Salado", "Alejandro", ""]]}, {"id": "2007.07293", "submitter": "Yikun Ban", "authors": "Yikun Ban and Jingrui He", "title": "Generic Outlier Detection in Multi-Armed Bandit", "comments": "Published in SIGKDD 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study the problem of outlier arm detection in multi-armed\nbandit settings, which finds plenty of applications in many high-impact domains\nsuch as finance, healthcare, and online advertising. For this problem, a\nlearner aims to identify the arms whose expected rewards deviate significantly\nfrom most of the other arms. Different from existing work, we target the\ngeneric outlier arms or outlier arm groups whose expected rewards can be\nlarger, smaller, or even in between those of normal arms. To this end, we start\nby providing a comprehensive definition of such generic outlier arms and\noutlier arm groups. Then we propose a novel pulling algorithm named GOLD to\nidentify such generic outlier arms. It builds a real-time neighborhood graph\nbased on upper confidence bounds and catches the behavior pattern of outliers\nfrom normal arms. We also analyze its performance from various aspects. In the\nexperiments conducted on both synthetic and real-world data sets, the proposed\nalgorithm achieves 98 % accuracy while saving 83 % exploration cost on average\ncompared with state-of-the-art techniques.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jul 2020 18:42:44 GMT"}], "update_date": "2020-07-16", "authors_parsed": [["Ban", "Yikun", ""], ["He", "Jingrui", ""]]}, {"id": "2007.07298", "submitter": "Somdeb Majumdar", "authors": "Shauharda Khadka, Estelle Aflalo, Mattias Marder, Avrech Ben-David,\n  Santiago Miret, Shie Mannor, Tamir Hazan, Hanlin Tang, Somdeb Majumdar", "title": "Optimizing Memory Placement using Evolutionary Graph Reinforcement\n  Learning", "comments": "Updated manuscript", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For deep neural network accelerators, memory movement is both energetically\nexpensive and can bound computation. Therefore, optimal mapping of tensors to\nmemory hierarchies is critical to performance. The growing complexity of neural\nnetworks calls for automated memory mapping instead of manual heuristic\napproaches; yet the search space of neural network computational graphs have\npreviously been prohibitively large. We introduce Evolutionary Graph\nReinforcement Learning (EGRL), a method designed for large search spaces, that\ncombines graph neural networks, reinforcement learning, and evolutionary\nsearch. A set of fast, stateless policies guide the evolutionary search to\nimprove its sample-efficiency. We train and validate our approach directly on\nthe Intel NNP-I chip for inference. EGRL outperforms policy-gradient,\nevolutionary search and dynamic programming baselines on BERT, ResNet-101 and\nResNet-50. We additionally achieve 28-78\\% speed-up compared to the native\nNNP-I compiler on all three workloads.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jul 2020 18:50:12 GMT"}, {"version": "v2", "created": "Thu, 15 Oct 2020 20:59:06 GMT"}], "update_date": "2020-10-19", "authors_parsed": [["Khadka", "Shauharda", ""], ["Aflalo", "Estelle", ""], ["Marder", "Mattias", ""], ["Ben-David", "Avrech", ""], ["Miret", "Santiago", ""], ["Mannor", "Shie", ""], ["Hazan", "Tamir", ""], ["Tang", "Hanlin", ""], ["Majumdar", "Somdeb", ""]]}, {"id": "2007.07320", "submitter": "Tiansi Dong", "authors": "Tiansi Dong, Chengjiang Li, Christian Bauckhage, Juanzi Li, Stefan\n  Wrobel, Armin B. Cremers", "title": "Learning Syllogism with Euler Neural-Networks", "comments": "16 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditional neural networks represent everything as a vector, and are able to\napproximate a subset of logical reasoning to a certain degree. As basic logic\nrelations are better represented by topological relations between regions, we\npropose a novel neural network that represents everything as a ball and is able\nto learn topological configuration as an Euler diagram. So comes the name Euler\nNeural-Network (ENN). The central vector of a ball is a vector that can inherit\nrepresentation power of traditional neural network. ENN distinguishes four\nspatial statuses between balls, namely, being disconnected, being partially\noverlapped, being part of, being inverse part of. Within each status, ideal\nvalues are defined for efficient reasoning. A novel back-propagation algorithm\nwith six Rectified Spatial Units (ReSU) can optimize an Euler diagram\nrepresenting logical premises, from which logical conclusion can be deduced. In\ncontrast to traditional neural network, ENN can precisely represent all 24\ndifferent structures of Syllogism. Two large datasets are created: one\nextracted from WordNet-3.0 covers all types of Syllogism reasoning, the other\nextracted all family relations from DBpedia. Experiment results approve the\nsuperior power of ENN in logical representation and reasoning. Datasets and\nsource code are available upon request.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jul 2020 19:35:35 GMT"}, {"version": "v2", "created": "Mon, 20 Jul 2020 09:58:24 GMT"}], "update_date": "2020-07-21", "authors_parsed": [["Dong", "Tiansi", ""], ["Li", "Chengjiang", ""], ["Bauckhage", "Christian", ""], ["Li", "Juanzi", ""], ["Wrobel", "Stefan", ""], ["Cremers", "Armin B.", ""]]}, {"id": "2007.07352", "submitter": "Jobst Heitzig", "authors": "Jobst Heitzig and Sarah Hiller", "title": "Degrees of individual and groupwise backward and forward responsibility\n  in extensive-form games with ambiguity, and their application to social\n  choice problems", "comments": "38 pages, 6 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "econ.TH cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many real-world situations of ethical relevance, in particular those of\nlarge-scale social choice such as mitigating climate change, involve not only\nmany agents whose decisions interact in complicated ways, but also various\nforms of uncertainty, including quantifiable risk and unquantifiable ambiguity.\nIn such problems, an assessment of individual and groupwise moral\nresponsibility for ethically undesired outcomes or their responsibility to\navoid such is challenging and prone to the risk of under- or overdetermination\nof responsibility. In contrast to existing approaches based on strict causation\nor certain deontic logics that focus on a binary classification of\n`responsible' vs `not responsible', we here present several different\nquantitative responsibility metrics that assess responsibility degrees in units\nof probability. For this, we use a framework based on an adapted version of\nextensive-form game trees and an axiomatic approach that specifies a number of\npotentially desirable properties of such metrics, and then test the developed\ncandidate metrics by their application to a number of paradigmatic social\nchoice situations. We find that while most properties one might desire of such\nresponsibility metrics can be fulfilled by some variant, an optimal metric that\nclearly outperforms others has yet to be found.\n", "versions": [{"version": "v1", "created": "Thu, 9 Jul 2020 13:19:13 GMT"}], "update_date": "2020-07-16", "authors_parsed": [["Heitzig", "Jobst", ""], ["Hiller", "Sarah", ""]]}, {"id": "2007.07356", "submitter": "Ruihan Zhao", "authors": "Ruihan Zhao, Kevin Lu, Pieter Abbeel, Stas Tiomkin", "title": "Efficient Empowerment Estimation for Unsupervised Stabilization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Intrinsically motivated artificial agents learn advantageous behavior without\nexternally-provided rewards. Previously, it was shown that maximizing mutual\ninformation between agent actuators and future states, known as the empowerment\nprinciple, enables unsupervised stabilization of dynamical systems at upright\npositions, which is a prototypical intrinsically motivated behavior for upright\nstanding and walking. This follows from the coincidence between the objective\nof stabilization and the objective of empowerment. Unfortunately, sample-based\nestimation of this kind of mutual information is challenging. Recently, various\nvariational lower bounds (VLBs) on empowerment have been proposed as solutions;\nhowever, they are often biased, unstable in training, and have high sample\ncomplexity. In this work, we propose an alternative solution based on a\ntrainable representation of a dynamical system as a Gaussian channel, which\nallows us to efficiently calculate an unbiased estimator of empowerment by\nconvex optimization. We demonstrate our solution for sample-based unsupervised\nstabilization on different dynamical control systems and show the advantages of\nour method by comparing it to the existing VLB approaches. Specifically, we\nshow that our method has a lower sample complexity, is more stable in training,\npossesses the essential properties of the empowerment function, and allows\nestimation of empowerment from images. Consequently, our method opens a path to\nwider and easier adoption of empowerment for various applications.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jul 2020 21:10:16 GMT"}, {"version": "v2", "created": "Sun, 9 May 2021 06:16:25 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Zhao", "Ruihan", ""], ["Lu", "Kevin", ""], ["Abbeel", "Pieter", ""], ["Tiomkin", "Stas", ""]]}, {"id": "2007.07455", "submitter": "Yingjie Hu", "authors": "Jimin Wang, Yingjie Hu", "title": "Are We There Yet? Evaluating State-of-the-Art Neural Network based\n  Geoparsers Using EUPEG as a Benchmarking Platform", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Geoparsing is an important task in geographic information retrieval. A\ngeoparsing system, known as a geoparser, takes some texts as the input and\noutputs the recognized place mentions and their location coordinates. In June\n2019, a geoparsing competition, Toponym Resolution in Scientific Papers, was\nheld as one of the SemEval 2019 tasks. The winning teams developed neural\nnetwork based geoparsers that achieved outstanding performances (over 90%\nprecision, recall, and F1 score for toponym recognition). This exciting result\nbrings the question \"are we there yet?\", namely have we achieved high enough\nperformances to possibly consider the problem of geoparsing as solved? One\nlimitation of this competition is that the developed geoparsers were tested on\nonly one dataset which has 45 research articles collected from the particular\ndomain of Bio-medicine. It is known that the same geoparser can have very\ndifferent performances on different datasets. Thus, this work performs a\nsystematic evaluation of these state-of-the-art geoparsers using our recently\ndeveloped benchmarking platform EUPEG that has eight annotated datasets, nine\nbaseline geoparsers, and eight performance metrics. The evaluation result\nsuggests that these new geoparsers indeed improve the performances of\ngeoparsing on multiple datasets although some challenges remain.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jul 2020 03:13:15 GMT"}], "update_date": "2020-07-16", "authors_parsed": [["Wang", "Jimin", ""], ["Hu", "Yingjie", ""]]}, {"id": "2007.07477", "submitter": "Sercan Arik", "authors": "Yu-han Liu and Sercan O. Arik", "title": "Explaining Deep Neural Networks using Unsupervised Clustering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel method to explain trained deep neural networks (DNNs), by\ndistilling them into surrogate models using unsupervised clustering. Our method\ncan be applied flexibly to any subset of layers of a DNN architecture and can\nincorporate low-level and high-level information. On image datasets given\npre-trained DNNs, we demonstrate the strength of our method in finding similar\ntraining samples, and shedding light on the concepts the DNNs base their\ndecisions on. Via user studies, we show that our model can improve the user\ntrust in model's prediction.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jul 2020 04:49:43 GMT"}, {"version": "v2", "created": "Thu, 16 Jul 2020 00:50:15 GMT"}], "update_date": "2020-07-17", "authors_parsed": [["Liu", "Yu-han", ""], ["Arik", "Sercan O.", ""]]}, {"id": "2007.07549", "submitter": "Jens Brunk", "authors": "Jens Brunk, Matthias Stierle, Leon Papke, Kate Revoredo, Martin\n  Matzner, J\\\"org Becker", "title": "Cause vs. Effect in Context-Sensitive Prediction of Business Process\n  Instances", "comments": null, "journal-ref": null, "doi": "10.1016/j.is.2020.101635", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Predicting undesirable events during the execution of a business process\ninstance provides the process participants with an opportunity to intervene and\nkeep the process aligned with its goals. Few approaches for tackling this\nchallenge consider a multi-perspective view, where the flow perspective of the\nprocess is combined with its surrounding context. Given the many sources of\ndata in today's world, context can vary widely and have various meanings. This\npaper addresses the issue of context being cause or effect of the next event\nand its impact on next event prediction. We leverage previous work on\nprobabilistic models to develop a Dynamic Bayesian Network technique.\nProbabilistic models are considered comprehensible and they allow the end-user\nand his or her understanding of the domain to be involved in the prediction.\nOur technique models context attributes that have either a cause or effect\nrelationship towards the event. We evaluate our technique with two real-life\ndata sets and benchmark it with other techniques from the field of predictive\nprocess monitoring. The results show that our solution achieves superior\nprediction results if context information is correctly introduced into the\nmodel.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jul 2020 08:58:15 GMT"}, {"version": "v2", "created": "Mon, 21 Sep 2020 10:17:28 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Brunk", "Jens", ""], ["Stierle", "Matthias", ""], ["Papke", "Leon", ""], ["Revoredo", "Kate", ""], ["Matzner", "Martin", ""], ["Becker", "J\u00f6rg", ""]]}, {"id": "2007.07562", "submitter": "Vladimir Kokh", "authors": "Pavel Blinov, Manvel Avetisian, Vladimir Kokh, Dmitry Umerenkov,\n  Alexander Tuzhilin", "title": "Predicting Clinical Diagnosis from Patients Electronic Health Records\n  Using BERT-based Neural Networks", "comments": "To be published in the proceedings of 2020 International Conference\n  on Artificial Intelligence in Medicine, Minneapolis MN, USA", "journal-ref": null, "doi": "10.1007/978-3-030-59137-3_11", "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we study the problem of predicting clinical diagnoses from\ntextual Electronic Health Records (EHR) data. We show the importance of this\nproblem in medical community and present comprehensive historical review of the\nproblem and proposed methods. As the main scientific contributions we present a\nmodification of Bidirectional Encoder Representations from Transformers (BERT)\nmodel for sequence classification that implements a novel way of\nFully-Connected (FC) layer composition and a BERT model pretrained only on\ndomain data. To empirically validate our model, we use a large-scale Russian\nEHR dataset consisting of about 4 million unique patient visits. This is the\nlargest such study for the Russian language and one of the largest globally. We\nperformed a number of comparative experiments with other text representation\nmodels on the task of multiclass classification for 265 disease subset of\nICD-10. The experiments demonstrate improved performance of our models compared\nto other baselines, including a fine-tuned Russian BERT (RuBERT) variant. We\nalso show comparable performance of our model with a panel of experienced\nmedical experts. This allows us to hope that implementation of this system will\nreduce misdiagnosis.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jul 2020 09:22:55 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Blinov", "Pavel", ""], ["Avetisian", "Manvel", ""], ["Kokh", "Vladimir", ""], ["Umerenkov", "Dmitry", ""], ["Tuzhilin", "Alexander", ""]]}, {"id": "2007.07573", "submitter": "Giovanni Casini", "authors": "Giovanni Casini, Umberto Straccia", "title": "Defeasible RDFS via Rational Closure", "comments": "47 pages. Preprint version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the field of non-monotonic logics, the notion of Rational Closure (RC) is\nacknowledged as a prominent approach. In recent years, RC has gained even more\npopularity in the context of Description Logics (DLs), the logic underpinning\nthe semantic web standard ontology language OWL 2, whose main ingredients are\nclasses and roles. In this work, we show how to integrate RC within the triple\nlanguage RDFS, which together with OWL2 are the two major standard semantic web\nontology languages. To do so, we start from $\\rho df$, which is the logic\nbehind RDFS, and then extend it to $\\rho df_\\bot$, allowing to state that two\nentities are incompatible. Eventually, we propose defeasible $\\rho df_\\bot$ via\na typical RC construction. The main features of our approach are: (i) unlike\nmost other approaches that add an extra non-monotone rule layer on top of\nmonotone RDFS, defeasible $\\rho df_\\bot$ remains syntactically a triple\nlanguage and is a simple extension of $\\rho df_\\bot$ by introducing some new\npredicate symbols with specific semantics. In particular, any RDFS\nreasoner/store may handle them as ordinary terms if it does not want to take\naccount for the extra semantics of the new predicate symbols; (ii) the\ndefeasible $\\rho df_\\bot$ entailment decision procedure is build on top of the\n$\\rho df_\\bot$ entailment decision procedure, which in turn is an extension of\nthe one for $\\rho df$ via some additional inference rules favouring an\npotential implementation; and (iii) defeasible $\\rho df_\\bot$ entailment can be\ndecided in polynomial time.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jul 2020 09:45:50 GMT"}], "update_date": "2020-07-16", "authors_parsed": [["Casini", "Giovanni", ""], ["Straccia", "Umberto", ""]]}, {"id": "2007.07629", "submitter": "Dennis Craandijk", "authors": "Dennis Craandijk and Floris Bex", "title": "Deep Learning for Abstract Argumentation Semantics", "comments": "Accepted at the main track of IJCAI 2020. SOLE copyright holder is\n  IJCAI (international Joint Conferences on Artificial Intelligence)", "journal-ref": null, "doi": "10.24963/ijcai.2020/231", "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present a learning-based approach to determining acceptance\nof arguments under several abstract argumentation semantics. More specifically,\nwe propose an argumentation graph neural network (AGNN) that learns a\nmessage-passing algorithm to predict the likelihood of an argument being\naccepted. The experimental results demonstrate that the AGNN can almost\nperfectly predict the acceptability under different semantics and scales well\nfor larger argumentation frameworks. Furthermore, analysing the behaviour of\nthe message-passing algorithm shows that the AGNN learns to adhere to basic\nprinciples of argument semantics as identified in the literature, and can thus\nbe trained to predict extensions under the different semantics - we show how\nthe latter can be done for multi-extension semantics by using AGNNs to guide a\nbasic search. We publish our code at\nhttps://github.com/DennisCraandijk/DL-Abstract-Argumentation\n", "versions": [{"version": "v1", "created": "Wed, 15 Jul 2020 11:37:28 GMT"}, {"version": "v2", "created": "Thu, 16 Jul 2020 09:48:06 GMT"}], "update_date": "2020-07-17", "authors_parsed": [["Craandijk", "Dennis", ""], ["Bex", "Floris", ""]]}, {"id": "2007.07703", "submitter": "Evan Piermont", "authors": "Evan Piermont and Peio Zuazo-Garin", "title": "Failures of Contingent Thinking", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI econ.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we provide a theoretical framework to analyze an agent who\nmisinterprets or misperceives the true decision problem she faces. Within this\nframework, we show that a wide range of behavior observed in experimental\nsettings manifest as failures to perceive implications, in other words, to\nproperly account for the logical relationships between various payoff relevant\ncontingencies. We present behavioral characterizations corresponding to several\nbenchmarks of logical sophistication and show how it is possible to identify\nwhich implications the agent fails to perceive. Thus, our framework delivers\nboth a methodology for assessing an agent's level of contingent thinking and a\nstrategy for identifying her beliefs in the absence full rationality.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jul 2020 14:21:16 GMT"}], "update_date": "2020-07-16", "authors_parsed": [["Piermont", "Evan", ""], ["Zuazo-Garin", "Peio", ""]]}, {"id": "2007.07710", "submitter": "Roman Yampolskiy", "authors": "Roman V. Yampolskiy", "title": "Human $\\neq$ AGI", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Terms Artificial General Intelligence (AGI) and Human-Level Artificial\nIntelligence (HLAI) have been used interchangeably to refer to the Holy Grail\nof Artificial Intelligence (AI) research, creation of a machine capable of\nachieving goals in a wide range of environments. However, widespread implicit\nassumption of equivalence between capabilities of AGI and HLAI appears to be\nunjustified, as humans are not general intelligences. In this paper, we will\nprove this distinction.\n", "versions": [{"version": "v1", "created": "Sat, 11 Jul 2020 14:06:13 GMT"}], "update_date": "2020-07-16", "authors_parsed": [["Yampolskiy", "Roman V.", ""]]}, {"id": "2007.07711", "submitter": "Quentin Cohen-Solal", "authors": "Quentin Cohen-Solal", "title": "Tractable Fragments of Temporal Sequences of Topological Information", "comments": null, "journal-ref": null, "doi": "10.1007/978-3-030-58475-7_7", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we focus on qualitative temporal sequences of topological\ninformation. We firstly consider the context of topological temporal sequences\nof length greater than 3 describing the evolution of regions at consecutive\ntime points. We show that there is no Cartesian subclass containing all the\nbasic relations and the universal relation for which the algebraic closure\ndecides satisfiability. However, we identify some tractable subclasses, by\ngiving up the relations containing the non-tangential proper part relation and\nnot containing the tangential proper part relation. We then formalize an\nalternative semantics for temporal sequences. We place ourselves in the context\nof the topological temporal sequences describing the evolution of regions on a\npartition of time (i.e. an alternation of instants and intervals). In this\ncontext, we identify large tractable fragments.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jul 2020 14:33:17 GMT"}, {"version": "v2", "created": "Fri, 22 Jan 2021 14:42:01 GMT"}], "update_date": "2021-01-25", "authors_parsed": [["Cohen-Solal", "Quentin", ""]]}, {"id": "2007.07768", "submitter": "Helge Spieker", "authors": "Mohit Kumar Ahuja, Mohamed-Bachir Belaid, Pierre Bernab\\'e, Mathieu\n  Collet, Arnaud Gotlieb, Chhagan Lal, Dusica Marijan, Sagar Sen, Aizaz Sharif,\n  Helge Spieker", "title": "Opening the Software Engineering Toolbox for the Assessment of\n  Trustworthy AI", "comments": "1st International Workshop on New Foundations for Human-Centered AI @\n  ECAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Trustworthiness is a central requirement for the acceptance and success of\nhuman-centered artificial intelligence (AI). To deem an AI system as\ntrustworthy, it is crucial to assess its behaviour and characteristics against\na gold standard of Trustworthy AI, consisting of guidelines, requirements, or\nonly expectations. While AI systems are highly complex, their implementations\nare still based on software. The software engineering community has a\nlong-established toolbox for the assessment of software systems, especially in\nthe context of software testing. In this paper, we argue for the application of\nsoftware engineering and testing practices for the assessment of trustworthy\nAI. We make the connection between the seven key requirements as defined by the\nEuropean Commission's AI high-level expert group and established procedures\nfrom software engineering and raise questions for future work.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jul 2020 08:16:15 GMT"}, {"version": "v2", "created": "Sun, 30 Aug 2020 14:16:31 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Ahuja", "Mohit Kumar", ""], ["Belaid", "Mohamed-Bachir", ""], ["Bernab\u00e9", "Pierre", ""], ["Collet", "Mathieu", ""], ["Gotlieb", "Arnaud", ""], ["Lal", "Chhagan", ""], ["Marijan", "Dusica", ""], ["Sen", "Sagar", ""], ["Sharif", "Aizaz", ""], ["Spieker", "Helge", ""]]}, {"id": "2007.07793", "submitter": "Aditya M. Deshpande", "authors": "Aditya M. Deshpande and Rumit Kumar and Ali A. Minai and Manish Kumar", "title": "Developmental Reinforcement Learning of Control Policy of a Quadcopter\n  UAV with Thrust Vectoring Rotors", "comments": "10 pages, 8 figures, Accepted in Dynamic Systems and Control\n  Conference (https://event.asme.org/DSCC)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG cs.SY eess.SY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we present a novel developmental reinforcement learning-based\ncontroller for a quadcopter with thrust vectoring capabilities. This multirotor\nUAV design has tilt-enabled rotors. It utilizes the rotor force magnitude and\ndirection to achieve the desired state during flight. The control policy of\nthis robot is learned using the policy transfer from the learned controller of\nthe quadcopter (comparatively simple UAV design without thrust vectoring). This\napproach allows learning a control policy for systems with multiple inputs and\nmultiple outputs. The performance of the learned policy is evaluated by\nphysics-based simulations for the tasks of hovering and way-point navigation.\nThe flight simulations utilize a flight controller based on reinforcement\nlearning without any additional PID components. The results show faster\nlearning with the presented approach as opposed to learning the control policy\nfrom scratch for this new UAV design created by modifications in a conventional\nquadcopter, i.e., the addition of more degrees of freedom (4-actuators in\nconventional quadcopter to 8-actuators in tilt-rotor quadcopter). We\ndemonstrate the robustness of our learned policy by showing the recovery of the\ntilt-rotor platform in the simulation from various non-static initial\nconditions in order to reach a desired state. The developmental policy for the\ntilt-rotor UAV also showed superior fault tolerance when compared with the\npolicy learned from the scratch. The results show the ability of the presented\napproach to bootstrap the learned behavior from a simpler system\n(lower-dimensional action-space) to a more complex robot (comparatively\nhigher-dimensional action-space) and reach better performance faster.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jul 2020 16:17:29 GMT"}], "update_date": "2020-07-16", "authors_parsed": [["Deshpande", "Aditya M.", ""], ["Kumar", "Rumit", ""], ["Minai", "Ali A.", ""], ["Kumar", "Manish", ""]]}, {"id": "2007.07825", "submitter": "Alain-J\\'er\\^ome Foug\\`eres", "authors": "Alain-J\\'er\\^ome Foug\\`eres and Egon Ostrosi", "title": "Intelligent requirements engineering from natural language and their\n  chaining toward CAD models", "comments": "15 pages, conference TMCE2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper assumes that design language plays an important role in how\ndesigners design and on the creativity of designers. Designers use and develop\nmodels as an aid to thinking, a focus for discussion and decision-making and a\nmeans of evaluating the reliability of the proposals. This paper proposes an\nintelligent method for requirements engineering from natural language and their\nchaining toward CAD models. The transition from linguistic analysis to the\nrepresentation of engineering requirements consists of the translation of the\nsyntactic structure into semantic form represented by conceptual graphs. Based\non the isomorphism between conceptual graphs and predicate logic, a formal\nlanguage of the specification is proposed. The outcome of this language is\nchained and translated in Computer Aided Three-Dimensional Interactive\nApplication (CATIA) models. The tool (EGEON: Engineering desiGn sEmantics\nelabOration and applicatioN) is developed to represent the semantic network of\nengineering requirements. A case study on the design of a car door hinge is\npresented to illustrates the proposed method.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jul 2020 17:53:01 GMT"}], "update_date": "2020-07-16", "authors_parsed": [["Foug\u00e8res", "Alain-J\u00e9r\u00f4me", ""], ["Ostrosi", "Egon", ""]]}, {"id": "2007.07853", "submitter": "Kun Ho Kim", "authors": "Kuno Kim, Megumi Sano, Julian De Freitas, Nick Haber, Daniel Yamins", "title": "Active World Model Learning with Progress Curiosity", "comments": "ICML 2020. Video of results at https://bit.ly/31vg7v1", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  World models are self-supervised predictive models of how the world evolves.\nHumans learn world models by curiously exploring their environment, in the\nprocess acquiring compact abstractions of high bandwidth sensory inputs, the\nability to plan across long temporal horizons, and an understanding of the\nbehavioral patterns of other agents. In this work, we study how to design such\na curiosity-driven Active World Model Learning (AWML) system. To do so, we\nconstruct a curious agent building world models while visually exploring a 3D\nphysical environment rich with distillations of representative real-world\nagents. We propose an AWML system driven by $\\gamma$-Progress: a scalable and\neffective learning progress-based curiosity signal. We show that\n$\\gamma$-Progress naturally gives rise to an exploration policy that directs\nattention to complex but learnable dynamics in a balanced manner, thus\novercoming the \"white noise problem\". As a result, our $\\gamma$-Progress-driven\ncontroller achieves significantly higher AWML performance than baseline\ncontrollers equipped with state-of-the-art exploration strategies such as\nRandom Network Distillation and Model Disagreement.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jul 2020 17:19:17 GMT"}], "update_date": "2020-07-16", "authors_parsed": [["Kim", "Kuno", ""], ["Sano", "Megumi", ""], ["De Freitas", "Julian", ""], ["Haber", "Nick", ""], ["Yamins", "Daniel", ""]]}, {"id": "2007.08082", "submitter": "Yasuhiro Fujita", "authors": "Yasuhiro Fujita, Kota Uenishi, Avinash Ummadisingu, Prabhat Nagarajan,\n  Shimpei Masuda, and Mario Ynocente Castro", "title": "Distributed Reinforcement Learning of Targeted Grasping with Active\n  Vision for Mobile Manipulators", "comments": "Accepted at IROS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.DC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Developing personal robots that can perform a diverse range of manipulation\ntasks in unstructured environments necessitates solving several challenges for\nrobotic grasping systems. We take a step towards this broader goal by\npresenting the first RL-based system, to our knowledge, for a mobile\nmanipulator that can (a) achieve targeted grasping generalizing to unseen\ntarget objects, (b) learn complex grasping strategies for cluttered scenes with\noccluded objects, and (c) perform active vision through its movable wrist\ncamera to better locate objects. The system is informed of the desired target\nobject in the form of a single, arbitrary-pose RGB image of that object,\nenabling the system to generalize to unseen objects without retraining. To\nachieve such a system, we combine several advances in deep reinforcement\nlearning and present a large-scale distributed training system using\nsynchronous SGD that seamlessly scales to multi-node, multi-GPU infrastructure\nto make rapid prototyping easier. We train and evaluate our system in a\nsimulated environment, identify key components for improving performance,\nanalyze its behaviors, and transfer to a real-world setup.\n", "versions": [{"version": "v1", "created": "Thu, 16 Jul 2020 02:47:48 GMT"}, {"version": "v2", "created": "Wed, 14 Oct 2020 08:59:39 GMT"}], "update_date": "2020-10-15", "authors_parsed": [["Fujita", "Yasuhiro", ""], ["Uenishi", "Kota", ""], ["Ummadisingu", "Avinash", ""], ["Nagarajan", "Prabhat", ""], ["Masuda", "Shimpei", ""], ["Castro", "Mario Ynocente", ""]]}, {"id": "2007.08202", "submitter": "Yao Liu", "authors": "Yao Liu, Adith Swaminathan, Alekh Agarwal, Emma Brunskill", "title": "Provably Good Batch Reinforcement Learning Without Great Exploration", "comments": "36 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Batch reinforcement learning (RL) is important to apply RL algorithms to many\nhigh stakes tasks. Doing batch RL in a way that yields a reliable new policy in\nlarge domains is challenging: a new decision policy may visit states and\nactions outside the support of the batch data, and function approximation and\noptimization with limited samples can further increase the potential of\nlearning policies with overly optimistic estimates of their future performance.\nRecent algorithms have shown promise but can still be overly optimistic in\ntheir expected outcomes. Theoretical work that provides strong guarantees on\nthe performance of the output policy relies on a strong concentrability\nassumption, that makes it unsuitable for cases where the ratio between\nstate-action distributions of behavior policy and some candidate policies is\nlarge. This is because in the traditional analysis, the error bound scales up\nwith this ratio. We show that a small modification to Bellman optimality and\nevaluation back-up to take a more conservative update can have much stronger\nguarantees. In certain settings, they can find the approximately best policy\nwithin the state-action space explored by the batch data, without requiring a\npriori assumptions of concentrability. We highlight the necessity of our\nconservative update and the limitations of previous algorithms and analyses by\nillustrative MDP examples, and demonstrate an empirical comparison of our\nalgorithm and other state-of-the-art batch RL baselines in standard benchmarks.\n", "versions": [{"version": "v1", "created": "Thu, 16 Jul 2020 09:25:54 GMT"}, {"version": "v2", "created": "Wed, 22 Jul 2020 08:48:10 GMT"}], "update_date": "2020-07-23", "authors_parsed": [["Liu", "Yao", ""], ["Swaminathan", "Adith", ""], ["Agarwal", "Alekh", ""], ["Brunskill", "Emma", ""]]}, {"id": "2007.08220", "submitter": "Luke Harries Mr", "authors": "Luke Harries, Rebekah Storan Clarke, Timothy Chapman, Swamy V. P. L.\n  N. Nallamalli, Levent Ozgur, Shuktika Jain, Alex Leung, Steve Lim, Aaron\n  Dietrich, Jos\\'e Miguel Hern\\'andez-Lobato, Tom Ellis, Cheng Zhang, Kamil\n  Ciosek", "title": "DRIFT: Deep Reinforcement Learning for Functional Software Testing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Efficient software testing is essential for productive software development\nand reliable user experiences. As human testing is inefficient and expensive,\nautomated software testing is needed. In this work, we propose a Reinforcement\nLearning (RL) framework for functional software testing named DRIFT. DRIFT\noperates on the symbolic representation of the user interface. It uses\nQ-learning through Batch-RL and models the state-action value function with a\nGraph Neural Network. We apply DRIFT to testing the Windows 10 operating system\nand show that DRIFT can robustly trigger the desired software functionality in\na fully automated manner. Our experiments test the ability to perform single\nand combined tasks across different applications, demonstrating that our\nframework can efficiently test software with a large range of testing\nobjectives.\n", "versions": [{"version": "v1", "created": "Thu, 16 Jul 2020 09:46:59 GMT"}], "update_date": "2020-07-17", "authors_parsed": [["Harries", "Luke", ""], ["Clarke", "Rebekah Storan", ""], ["Chapman", "Timothy", ""], ["Nallamalli", "Swamy V. P. L. N.", ""], ["Ozgur", "Levent", ""], ["Jain", "Shuktika", ""], ["Leung", "Alex", ""], ["Lim", "Steve", ""], ["Dietrich", "Aaron", ""], ["Hern\u00e1ndez-Lobato", "Jos\u00e9 Miguel", ""], ["Ellis", "Tom", ""], ["Zhang", "Cheng", ""], ["Ciosek", "Kamil", ""]]}, {"id": "2007.08229", "submitter": "PoHan Chiang", "authors": "Po-Han Chiang, Hsuan-Kung Yang, Zhang-Wei Hong and Chun-Yi Lee", "title": "Mixture of Step Returns in Bootstrapped DQN", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The concept of utilizing multi-step returns for updating value functions has\nbeen adopted in deep reinforcement learning (DRL) for a number of years.\nUpdating value functions with different backup lengths provides advantages in\ndifferent aspects, including bias and variance of value estimates, convergence\nspeed, and exploration behavior of the agent. Conventional methods such as\nTD-lambda leverage these advantages by using a target value equivalent to an\nexponential average of different step returns. Nevertheless, integrating step\nreturns into a single target sacrifices the diversity of the advantages offered\nby different step return targets. To address this issue, we propose Mixture\nBootstrapped DQN (MB-DQN) built on top of bootstrapped DQN, and uses different\nbackup lengths for different bootstrapped heads. MB-DQN enables heterogeneity\nof the target values that is unavailable in approaches relying only on a single\ntarget value. As a result, it is able to maintain the advantages offered by\ndifferent backup lengths. In this paper, we first discuss the motivational\ninsights through a simple maze environment. In order to validate the\neffectiveness of MB-DQN, we perform experiments on the Atari 2600 benchmark\nenvironments, and demonstrate the performance improvement of MB-DQN over a\nnumber of baseline methods. We further provide a set of ablation studies to\nexamine the impacts of different design configurations of MB-DQN.\n", "versions": [{"version": "v1", "created": "Thu, 16 Jul 2020 10:00:16 GMT"}], "update_date": "2020-07-17", "authors_parsed": [["Chiang", "Po-Han", ""], ["Yang", "Hsuan-Kung", ""], ["Hong", "Zhang-Wei", ""], ["Lee", "Chun-Yi", ""]]}, {"id": "2007.08251", "submitter": "Alejandro Agostini", "authors": "Alejandro Agostini, Dongheui Lee", "title": "Efficient State Abstraction using Object-centered Predicates for\n  Manipulation Planning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The definition of symbolic descriptions that consistently represent relevant\ngeometrical aspects in manipulation tasks is a challenging problem that has\nreceived little attention in the robotic community. This definition is usually\ndone from an observer perspective of a finite set of object relations and\norientations that only satisfy geometrical constraints to execute experiments\nin laboratory conditions. This restricts the possible changes with manipulation\nactions in the object configuration space to those compatible with that\nparticular external reference definitions, which greatly limits the spectrum of\npossible manipulations. To tackle these limitations we propose an\nobject-centered representation that permits characterizing a much wider set of\npossible changes in configuration spaces than the traditional observer\nperspective counterpart. Based on this representation, we define universal\nplanning operators for picking and placing actions that permits generating\nplans with geometric and force consistency in manipulation tasks. This\nobject-centered description is directly obtained from the poses and bounding\nboxes of objects using a novel learning mechanisms that permits generating\nsignal-symbols relations without the need of handcrafting these relations for\neach particular scenario.\n", "versions": [{"version": "v1", "created": "Thu, 16 Jul 2020 10:52:53 GMT"}], "update_date": "2020-07-17", "authors_parsed": [["Agostini", "Alejandro", ""], ["Lee", "Dongheui", ""]]}, {"id": "2007.08343", "submitter": "Teng Liu", "authors": "Teng Liu, Xingyu Mu, Xiaolin Tang, Bing Huang, Hong Wang, Dongpu Cao", "title": "Dueling Deep Q Network for Highway Decision Making in Autonomous\n  Vehicles: A Case Study", "comments": "5 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work optimizes the highway decision making strategy of autonomous\nvehicles by using deep reinforcement learning (DRL). First, the highway driving\nenvironment is built, wherein the ego vehicle, surrounding vehicles, and road\nlanes are included. Then, the overtaking decision-making problem of the\nautomated vehicle is formulated as an optimal control problem. Then relevant\ncontrol actions, state variables, and optimization objectives are elaborated.\nFinally, the deep Q-network is applied to derive the intelligent driving\npolicies for the ego vehicle. Simulation results reveal that the ego vehicle\ncould safely and efficiently accomplish the driving task after learning and\ntraining.\n", "versions": [{"version": "v1", "created": "Thu, 16 Jul 2020 14:09:20 GMT"}], "update_date": "2020-07-17", "authors_parsed": [["Liu", "Teng", ""], ["Mu", "Xingyu", ""], ["Tang", "Xiaolin", ""], ["Huang", "Bing", ""], ["Wang", "Hong", ""], ["Cao", "Dongpu", ""]]}, {"id": "2007.08351", "submitter": "Nils Jansen", "authors": "Leonore Winterer, Ralf Wimmer, Nils Jansen, Bernd Becker", "title": "Strengthening Deterministic Policies for POMDPs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO cs.RO cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The synthesis problem for partially observable Markov decision processes\n(POMDPs) is to compute a policy that satisfies a given specification. Such\npolicies have to take the full execution history of a POMDP into account,\nrendering the problem undecidable in general. A common approach is to use a\nlimited amount of memory and randomize over potential choices. Yet, this\nproblem is still NP-hard and often computationally intractable in practice. A\nrestricted problem is to use neither history nor randomization, yielding\npolicies that are called stationary and deterministic. Previous approaches to\ncompute such policies employ mixed-integer linear programming (MILP). We\nprovide a novel MILP encoding that supports sophisticated specifications in the\nform of temporal logic constraints. It is able to handle an arbitrary number of\nsuch specifications. Yet, randomization and memory are often mandatory to\nachieve satisfactory policies. First, we extend our encoding to deliver a\nrestricted class of randomized policies. Second, based on the results of the\noriginal MILP, we employ a preprocessing of the POMDP to encompass memory-based\ndecisions. The advantages of our approach over state-of-the-art POMDP solvers\nlie (1) in the flexibility to strengthen simple deterministic policies without\nlosing computational tractability and (2) in the ability to enforce the\nprovable satisfaction of arbitrarily many specifications. The latter point\nallows taking trade-offs between performance and safety aspects of typical\nPOMDP examples into account. We show the effectiveness of our method on a broad\nrange of benchmarks.\n", "versions": [{"version": "v1", "created": "Thu, 16 Jul 2020 14:22:55 GMT"}], "update_date": "2020-07-20", "authors_parsed": [["Winterer", "Leonore", ""], ["Wimmer", "Ralf", ""], ["Jansen", "Nils", ""], ["Becker", "Bernd", ""]]}, {"id": "2007.08406", "submitter": "Norman Fenton Prof", "authors": "Norman Fenton, Martin Neil, Steven Frazier", "title": "The role of collider bias in understanding statistics on racially biased\n  policing", "comments": "7 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Contradictory conclusions have been made about whether unarmed blacks are\nmore likely to be shot by police than unarmed whites using the same data. The\nproblem is that, by relying only on data of 'police encounters', there is the\npossibility that genuine bias can be hidden. We provide a causal Bayesian\nnetwork model to explain this bias, which is called collider bias or Berkson's\nparadox, and show how the different conclusions arise from the same model and\ndata. We also show that causal Bayesian networks provide the ideal formalism\nfor considering alternative hypotheses and explanations of bias.\n", "versions": [{"version": "v1", "created": "Thu, 16 Jul 2020 15:26:23 GMT"}], "update_date": "2020-07-17", "authors_parsed": [["Fenton", "Norman", ""], ["Neil", "Martin", ""], ["Frazier", "Steven", ""]]}, {"id": "2007.08433", "submitter": "Zhongwen Xu", "authors": "Zhongwen Xu, Hado van Hasselt, Matteo Hessel, Junhyuk Oh, Satinder\n  Singh, David Silver", "title": "Meta-Gradient Reinforcement Learning with an Objective Discovered Online", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep reinforcement learning includes a broad family of algorithms that\nparameterise an internal representation, such as a value function or policy, by\na deep neural network. Each algorithm optimises its parameters with respect to\nan objective, such as Q-learning or policy gradient, that defines its\nsemantics. In this work, we propose an algorithm based on meta-gradient descent\nthat discovers its own objective, flexibly parameterised by a deep neural\nnetwork, solely from interactive experience with its environment. Over time,\nthis allows the agent to learn how to learn increasingly effectively.\nFurthermore, because the objective is discovered online, it can adapt to\nchanges over time. We demonstrate that the algorithm discovers how to address\nseveral important issues in RL, such as bootstrapping, non-stationarity, and\noff-policy learning. On the Atari Learning Environment, the meta-gradient\nalgorithm adapts over time to learn with greater efficiency, eventually\noutperforming the median score of a strong actor-critic baseline.\n", "versions": [{"version": "v1", "created": "Thu, 16 Jul 2020 16:17:09 GMT"}], "update_date": "2020-07-17", "authors_parsed": [["Xu", "Zhongwen", ""], ["van Hasselt", "Hado", ""], ["Hessel", "Matteo", ""], ["Oh", "Junhyuk", ""], ["Singh", "Satinder", ""], ["Silver", "David", ""]]}, {"id": "2007.08451", "submitter": "Zhiyu Liu", "authors": "Zhiyu Liu, Meng Jiang, Hai Lin", "title": "Specification mining and automated task planning for autonomous robots\n  based on a graph-based spatial temporal logic", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.RO cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We aim to enable an autonomous robot to learn new skills from demo videos and\nuse these newly learned skills to accomplish non-trivial high-level tasks. The\ngoal of developing such autonomous robot involves knowledge representation,\nspecification mining, and automated task planning. For knowledge\nrepresentation, we use a graph-based spatial temporal logic (GSTL) to capture\nspatial and temporal information of related skills demonstrated by demo videos.\nWe design a specification mining algorithm to generate a set of parametric GSTL\nformulas from demo videos by inductively constructing spatial terms and\ntemporal formulas. The resulting parametric GSTL formulas from specification\nmining serve as a domain theory, which is used in automated task planning for\nautonomous robots. We propose an automatic task planning based on GSTL where a\nproposer is used to generate ordered actions, and a verifier is used to\ngenerate executable task plans. A table setting example is used throughout the\npaper to illustrate the main ideas.\n", "versions": [{"version": "v1", "created": "Thu, 16 Jul 2020 16:40:12 GMT"}], "update_date": "2020-07-17", "authors_parsed": [["Liu", "Zhiyu", ""], ["Jiang", "Meng", ""], ["Lin", "Hai", ""]]}, {"id": "2007.08459", "submitter": "Wen Sun", "authors": "Alekh Agarwal, Mikael Henaff, Sham Kakade, Wen Sun", "title": "PC-PG: Policy Cover Directed Exploration for Provable Policy Gradient\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Direct policy gradient methods for reinforcement learning are a successful\napproach for a variety of reasons: they are model free, they directly optimize\nthe performance metric of interest, and they allow for richly parameterized\npolicies. Their primary drawback is that, by being local in nature, they fail\nto adequately explore the environment. In contrast, while model-based\napproaches and Q-learning directly handle exploration through the use of\noptimism, their ability to handle model misspecification and function\napproximation is far less evident. This work introduces the the Policy\nCover-Policy Gradient (PC-PG) algorithm, which provably balances the\nexploration vs. exploitation tradeoff using an ensemble of learned policies\n(the policy cover). PC-PG enjoys polynomial sample complexity and run time for\nboth tabular MDPs and, more generally, linear MDPs in an infinite dimensional\nRKHS. Furthermore, PC-PG also has strong guarantees under model\nmisspecification that go beyond the standard worst case $\\ell_{\\infty}$\nassumptions; this includes approximation guarantees for state aggregation under\nan average case error assumption, along with guarantees under a more general\nassumption where the approximation error under distribution shift is\ncontrolled. We complement the theory with empirical evaluation across a variety\nof domains in both reward-free and reward-driven settings.\n", "versions": [{"version": "v1", "created": "Thu, 16 Jul 2020 16:57:41 GMT"}, {"version": "v2", "created": "Thu, 13 Aug 2020 17:59:40 GMT"}], "update_date": "2020-08-14", "authors_parsed": [["Agarwal", "Alekh", ""], ["Henaff", "Mikael", ""], ["Kakade", "Sham", ""], ["Sun", "Wen", ""]]}, {"id": "2007.08557", "submitter": "Lili Mou", "authors": "Jingjing Li, Zichao Li, Lili Mou, Xin Jiang, Michael R. Lyu, Irwin\n  King", "title": "Unsupervised Text Generation by Learning from Search", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we present TGLS, a novel framework to unsupervised Text\nGeneration by Learning from Search. We start by applying a strong search\nalgorithm (in particular, simulated annealing) towards a heuristically defined\nobjective that (roughly) estimates the quality of sentences. Then, a\nconditional generative model learns from the search results, and meanwhile\nsmooth out the noise of search. The alternation between search and learning can\nbe repeated for performance bootstrapping. We demonstrate the effectiveness of\nTGLS on two real-world natural language generation tasks, paraphrase generation\nand text formalization. Our model significantly outperforms unsupervised\nbaseline methods in both tasks. Especially, it achieves comparable performance\nwith the state-of-the-art supervised methods in paraphrase generation.\n", "versions": [{"version": "v1", "created": "Thu, 9 Jul 2020 04:34:48 GMT"}], "update_date": "2020-07-20", "authors_parsed": [["Li", "Jingjing", ""], ["Li", "Zichao", ""], ["Mou", "Lili", ""], ["Jiang", "Xin", ""], ["Lyu", "Michael R.", ""], ["King", "Irwin", ""]]}, {"id": "2007.08616", "submitter": "Abhiram Iyer", "authors": "Abhiram Iyer, Aravind Mahadevan", "title": "Collision Avoidance Robotics Via Meta-Learning (CARML)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents an approach to exploring a multi-objective reinforcement\nlearning problem with Model-Agnostic Meta-Learning. The environment we used\nconsists of a 2D vehicle equipped with a LIDAR sensor. The goal of the\nenvironment is to reach some pre-determined target location but also\neffectively avoid any obstacles it may find along its path. We also compare\nthis approach against a baseline TD3 solution that attempts to solve the same\nproblem.\n", "versions": [{"version": "v1", "created": "Thu, 16 Jul 2020 20:31:34 GMT"}], "update_date": "2020-07-20", "authors_parsed": [["Iyer", "Abhiram", ""], ["Mahadevan", "Aravind", ""]]}, {"id": "2007.08620", "submitter": "Sylvain Le Corff", "authors": "Alice Martin (CMAP, IP Paris, CITI, TIPIC-SAMOVAR), Charles Ollion\n  (CMAP), Florian Strub, Sylvain Le Corff (IP Paris, CITI, TIPIC-SAMOVAR),\n  Olivier Pietquin", "title": "The Monte Carlo Transformer: a stochastic self-attention model for\n  sequence prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces the Sequential Monte Carlo Transformer, an original\napproach that naturally captures the observations distribution in a transformer\narchitecture. The keys, queries, values and attention vectors of the network\nare considered as the unobserved stochastic states of its hidden structure.\nThis generative model is such that at each time step the received observation\nis a random function of its past states in a given attention window. In this\ngeneral state-space setting, we use Sequential Monte Carlo methods to\napproximate the posterior distributions of the states given the observations,\nand to estimate the gradient of the log-likelihood. We hence propose a\ngenerative model giving a predictive distribution, instead of a single-point\nestimate.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jul 2020 10:01:48 GMT"}, {"version": "v2", "created": "Tue, 15 Dec 2020 14:27:22 GMT"}], "update_date": "2020-12-16", "authors_parsed": [["Martin", "Alice", "", "CMAP, IP Paris, CITI, TIPIC-SAMOVAR"], ["Ollion", "Charles", "", "CMAP"], ["Strub", "Florian", "", "IP Paris, CITI, TIPIC-SAMOVAR"], ["Corff", "Sylvain Le", "", "IP Paris, CITI, TIPIC-SAMOVAR"], ["Pietquin", "Olivier", ""]]}, {"id": "2007.08656", "submitter": "Sondre Engebr{\\aa}ten Msc", "authors": "Sondre A. Engebraaten, Jonas Moen, Oleg A. Yakimenko, Kyrre Glette", "title": "A Framework for Automatic Behavior Generation in Multi-Function Swarms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-function swarms are swarms that solve multiple tasks at once. For\nexample, a quadcopter swarm could be tasked with exploring an area of interest\nwhile simultaneously functioning as ad-hoc relays. With this type of\nmulti-function comes the challenge of handling potentially conflicting\nrequirements simultaneously. Using the Quality-Diversity algorithm MAP-elites\nin combination with a suitable controller structure, a framework for automatic\nbehavior generation in multi-function swarms is proposed. The framework is\ntested on a scenario with three simultaneous tasks: exploration, communication\nnetwork creation and geolocation of RF emitters. A repertoire is evolved,\nconsisting of a wide range of controllers, or behavior primitives, with\ndifferent characteristics and trade-offs in the different tasks. This\nrepertoire would enable the swarm to transition between behavior trade-offs\nonline, according to the situational requirements. Furthermore, the effect of\nnoise on the behavior characteristics in MAP-elites is investigated. A moderate\nnumber of re-evaluations is found to increase the robustness while keeping the\ncomputational requirements relatively low. A few selected controllers are\nexamined, and the dynamics of transitioning between these controllers are\nexplored. Finally, the study develops a methodology for analyzing the makeup of\nthe resulting controllers. This is done through a parameter variation study\nwhere the importance of individual inputs to the swarm controllers is assessed\nand analyzed.\n", "versions": [{"version": "v1", "created": "Sat, 11 Jul 2020 20:50:52 GMT"}], "update_date": "2020-07-20", "authors_parsed": [["Engebraaten", "Sondre A.", ""], ["Moen", "Jonas", ""], ["Yakimenko", "Oleg A.", ""], ["Glette", "Kyrre", ""]]}, {"id": "2007.08666", "submitter": "Mike Zajko", "authors": "Mike Zajko", "title": "Conservative AI and social inequality: Conceptualizing alternatives to\n  bias through social theory", "comments": "AI & Soc (2021)", "journal-ref": null, "doi": "10.1007/s00146-021-01153-9", "report-no": null, "categories": "cs.CY cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In response to calls for greater interdisciplinary involvement from the\nsocial sciences and humanities in the development, governance, and study of\nartificial intelligence systems, this paper presents one sociologist's view on\nthe problem of algorithmic bias and the reproduction of societal bias.\nDiscussions of bias in AI cover much of the same conceptual terrain that\nsociologists studying inequality have long understood using more specific terms\nand theories. Concerns over reproducing societal bias should be informed by an\nunderstanding of the ways that inequality is continually reproduced in society\n-- processes that AI systems are either complicit in, or can be designed to\ndisrupt and counter. The contrast presented here is between conservative and\nradical approaches to AI, with conservatism referring to dominant tendencies\nthat reproduce and strengthen the status quo, while radical approaches work to\ndisrupt systemic forms of inequality. The limitations of conservative\napproaches to class, gender, and racial bias are discussed as specific\nexamples, along with the social structures and processes that biases in these\nareas are linked to. Societal issues can no longer be out of scope for AI and\nmachine learning, given the impact of these systems on human lives. This\nrequires engagement with a growing body of critical AI scholarship that goes\nbeyond biased data to analyze structured ways of perpetuating inequality,\nopening up the possibility for radical alternatives.\n", "versions": [{"version": "v1", "created": "Thu, 16 Jul 2020 21:52:13 GMT"}], "update_date": "2021-02-10", "authors_parsed": [["Zajko", "Mike", ""]]}, {"id": "2007.08670", "submitter": "Tom Williams", "authors": "Ryan Blake Jackson and Tom Williams", "title": "Enabling Morally Sensitive Robotic Clarification Requests", "comments": "Accepted for nonarchival presentation at Advances in Cognitive\n  Systems (ACS) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.CY cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The design of current natural language oriented robot architectures enables\ncertain architectural components to circumvent moral reasoning capabilities.\nOne example of this is reflexive generation of clarification requests as soon\nas referential ambiguity is detected in a human utterance. As shown in previous\nresearch, this can lead robots to (1) miscommunicate their moral dispositions\nand (2) weaken human perception or application of moral norms within their\ncurrent context. We present a solution to these problems by performing moral\nreasoning on each potential disambiguation of an ambiguous human utterance and\nresponding accordingly, rather than immediately and naively requesting\nclarification. We implement our solution in the DIARC robot architecture,\nwhich, to our knowledge, is the only current robot architecture with both moral\nreasoning and clarification request generation capabilities. We then evaluate\nour method with a human subjects experiment, the results of which indicate that\nour approach successfully ameliorates the two identified concerns.\n", "versions": [{"version": "v1", "created": "Thu, 16 Jul 2020 22:12:35 GMT"}], "update_date": "2020-07-20", "authors_parsed": [["Jackson", "Ryan Blake", ""], ["Williams", "Tom", ""]]}, {"id": "2007.08672", "submitter": "Tom Williams", "authors": "Tom Williams and Torin Johnson and Will Culpepper and Kellyn Larson", "title": "Toward Forgetting-Sensitive Referring Expression Generationfor\n  Integrated Robot Architectures", "comments": "Accepted for (nonarchival) presentation at Advances in Cognitive\n  Systems (ACS) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To engage in human-like dialogue, robots require the ability to describe the\nobjects, locations, and people in their environment, a capability known as\n\"Referring Expression Generation.\" As speakers repeatedly refer to similar\nobjects, they tend to re-use properties from previous descriptions, in part to\nhelp the listener, and in part due to cognitive availability of those\nproperties in working memory (WM). Because different theories of working memory\n\"forgetting\" necessarily lead to differences in cognitive availability, we\nhypothesize that they will similarly result in generation of different\nreferring expressions. To design effective intelligent agents, it is thus\nnecessary to determine how different models of forgetting may be differentially\neffective at producing natural human-like referring expressions. In this work,\nwe computationalize two candidate models of working memory forgetting within a\nrobot cognitive architecture, and demonstrate how they lead to cognitive\navailability-based differences in generated referring expressions.\n", "versions": [{"version": "v1", "created": "Thu, 16 Jul 2020 22:20:15 GMT"}], "update_date": "2020-07-20", "authors_parsed": [["Williams", "Tom", ""], ["Johnson", "Torin", ""], ["Culpepper", "Will", ""], ["Larson", "Kellyn", ""]]}, {"id": "2007.08690", "submitter": "Teng Liu", "authors": "Xiaowei Guo, Teng Liu, Bangbei Tang, Xiaolin Tang, Jinwei Zhang,\n  Wenhao Tan, and Shufeng Jin", "title": "Transfer Deep Reinforcement Learning-enabled Energy Management Strategy\n  for Hybrid Tracked Vehicle", "comments": "11 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes an adaptive energy management strategy for hybrid\nelectric vehicles by combining deep reinforcement learning (DRL) and transfer\nlearning (TL). This work aims to address the defect of DRL in tedious training\ntime. First, an optimization control modeling of a hybrid tracked vehicle is\nbuilt, wherein the elaborate powertrain components are introduced. Then, a\nbi-level control framework is constructed to derive the energy management\nstrategies (EMSs). The upper-level is applying the particular deep\ndeterministic policy gradient (DDPG) algorithms for EMS training at different\nspeed intervals. The lower-level is employing the TL method to transform the\npre-trained neural networks for a novel driving cycle. Finally, a series of\nexperiments are executed to prove the effectiveness of the presented control\nframework. The optimality and adaptability of the formulated EMS are\nilluminated. The founded DRL and TL-enabled control policy is capable of\nenhancing energy efficiency and improving system performance.\n", "versions": [{"version": "v1", "created": "Thu, 16 Jul 2020 23:39:34 GMT"}], "update_date": "2020-07-20", "authors_parsed": [["Guo", "Xiaowei", ""], ["Liu", "Teng", ""], ["Tang", "Bangbei", ""], ["Tang", "Xiaolin", ""], ["Zhang", "Jinwei", ""], ["Tan", "Wenhao", ""], ["Jin", "Shufeng", ""]]}, {"id": "2007.08794", "submitter": "Junhyuk Oh", "authors": "Junhyuk Oh, Matteo Hessel, Wojciech M. Czarnecki, Zhongwen Xu, Hado\n  van Hasselt, Satinder Singh, David Silver", "title": "Discovering Reinforcement Learning Algorithms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning (RL) algorithms update an agent's parameters according\nto one of several possible rules, discovered manually through years of\nresearch. Automating the discovery of update rules from data could lead to more\nefficient algorithms, or algorithms that are better adapted to specific\nenvironments. Although there have been prior attempts at addressing this\nsignificant scientific challenge, it remains an open question whether it is\nfeasible to discover alternatives to fundamental concepts of RL such as value\nfunctions and temporal-difference learning. This paper introduces a new\nmeta-learning approach that discovers an entire update rule which includes both\n'what to predict' (e.g. value functions) and 'how to learn from it' (e.g.\nbootstrapping) by interacting with a set of environments. The output of this\nmethod is an RL algorithm that we call Learned Policy Gradient (LPG). Empirical\nresults show that our method discovers its own alternative to the concept of\nvalue functions. Furthermore it discovers a bootstrapping mechanism to maintain\nand use its predictions. Surprisingly, when trained solely on toy environments,\nLPG generalises effectively to complex Atari games and achieves non-trivial\nperformance. This shows the potential to discover general RL algorithms from\ndata.\n", "versions": [{"version": "v1", "created": "Fri, 17 Jul 2020 07:38:39 GMT"}, {"version": "v2", "created": "Mon, 23 Nov 2020 20:02:06 GMT"}, {"version": "v3", "created": "Tue, 5 Jan 2021 12:44:56 GMT"}], "update_date": "2021-01-06", "authors_parsed": [["Oh", "Junhyuk", ""], ["Hessel", "Matteo", ""], ["Czarnecki", "Wojciech M.", ""], ["Xu", "Zhongwen", ""], ["van Hasselt", "Hado", ""], ["Singh", "Satinder", ""], ["Silver", "David", ""]]}, {"id": "2007.08812", "submitter": "Nataliya Sokolovska", "authors": "Nataliya Sokolovska (SU), Pierre-Henri Wuillemin", "title": "Latent Instrumental Variables as Priors in Causal Inference based on\n  Independence of Cause and Mechanism", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Causal inference methods based on conditional independence construct Markov\nequivalent graphs, and cannot be applied to bivariate cases. The approaches\nbased on independence of cause and mechanism state, on the contrary, that\ncausal discovery can be inferred for two observations. In our contribution, we\nchallenge to reconcile these two research directions. We study the role of\nlatent variables such as latent instrumental variables and hidden common causes\nin the causal graphical structures. We show that the methods based on the\nindependence of cause and mechanism, indirectly contain traces of the existence\nof the hidden instrumental variables. We derive a novel algorithm to infer\ncausal relationships between two variables, and we validate the proposed method\non simulated data and on a benchmark of cause-effect pairs. We illustrate by\nour experiments that the proposed approach is simple and extremely competitive\nin terms of empirical accuracy compared to the state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Fri, 17 Jul 2020 08:18:19 GMT"}], "update_date": "2020-07-20", "authors_parsed": [["Sokolovska", "Nataliya", "", "SU"], ["Wuillemin", "Pierre-Henri", ""]]}, {"id": "2007.08821", "submitter": "Pierre Monnin", "authors": "Pierre Monnin and Emmanuel Bresso and Miguel Couceiro and Malika\n  Sma\\\"il-Tabbone and Amedeo Napoli and Adrien Coulet", "title": "Tackling scalability issues in mining path patterns from knowledge\n  graphs: a preliminary study", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Features mined from knowledge graphs are widely used within multiple\nknowledge discovery tasks such as classification or fact-checking. Here, we\nconsider a given set of vertices, called seed vertices, and focus on mining\ntheir associated neighboring vertices, paths, and, more generally, path\npatterns that involve classes of ontologies linked with knowledge graphs. Due\nto the combinatorial nature and the increasing size of real-world knowledge\ngraphs, the task of mining these patterns immediately entails scalability\nissues. In this paper, we address these issues by proposing a pattern mining\napproach that relies on a set of constraints (e.g., support or degree\nthresholds) and the monotonicity property. As our motivation comes from the\nmining of real-world knowledge graphs, we illustrate our approach with PGxLOD,\na biomedical knowledge graph.\n", "versions": [{"version": "v1", "created": "Fri, 17 Jul 2020 08:36:26 GMT"}, {"version": "v2", "created": "Fri, 7 Aug 2020 13:33:15 GMT"}], "update_date": "2020-08-10", "authors_parsed": [["Monnin", "Pierre", ""], ["Bresso", "Emmanuel", ""], ["Couceiro", "Miguel", ""], ["Sma\u00efl-Tabbone", "Malika", ""], ["Napoli", "Amedeo", ""], ["Coulet", "Adrien", ""]]}, {"id": "2007.08848", "submitter": "Xinyu Ma", "authors": "Liantao Ma, Xinyu Ma, Junyi Gao, Chaohe Zhang, Zhihao Yu, Xianfeng\n  Jiao, Wenjie Ruan, Yasha Wang, Wen Tang, Jiangtao Wang", "title": "CovidCare: Transferring Knowledge from Existing EMR to Emerging Epidemic\n  for Interpretable Prognosis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to the characteristics of COVID-19, the epidemic develops rapidly and\noverwhelms health service systems worldwide. Many patients suffer from systemic\nlife-threatening problems and need to be carefully monitored in ICUs. Thus the\nintelligent prognosis is in an urgent need to assist physicians to take an\nearly intervention, prevent the adverse outcome, and optimize the medical\nresource allocation. However, in the early stage of the epidemic outbreak, the\ndata available for analysis is limited due to the lack of effective diagnostic\nmechanisms, rarity of the cases, and privacy concerns. In this paper, we\npropose a deep-learning-based approach, CovidCare, which leverages the existing\nelectronic medical records to enhance the prognosis for inpatients with\nemerging infectious diseases. It learns to embed the COVID-19-related medical\nfeatures based on massive existing EMR data via transfer learning. The\ntransferred parameters are further trained to imitate the teacher model's\nrepresentation behavior based on knowledge distillation, which embeds the\nhealth status more comprehensively in the source dataset. We conduct the length\nof stay prediction experiments for patients on a real-world COVID-19 dataset.\nThe experiment results indicate that our proposed model consistently\noutperforms the comparative baseline methods. CovidCare also reveals that, 1)\nhs-cTnI, hs-CRP and Platelet Counts are the most fatal biomarkers, whose\nabnormal values usually indicate emergency adverse outcome. 2) Normal values of\ngamma-GT, AP and eGFR indicate the overall improvement of health. The medical\nfindings extracted by CovidCare are empirically confirmed by human experts and\nmedical literatures.\n", "versions": [{"version": "v1", "created": "Fri, 17 Jul 2020 09:20:56 GMT"}], "update_date": "2020-07-20", "authors_parsed": [["Ma", "Liantao", ""], ["Ma", "Xinyu", ""], ["Gao", "Junyi", ""], ["Zhang", "Chaohe", ""], ["Yu", "Zhihao", ""], ["Jiao", "Xianfeng", ""], ["Ruan", "Wenjie", ""], ["Wang", "Yasha", ""], ["Tang", "Wen", ""], ["Wang", "Jiangtao", ""]]}, {"id": "2007.08854", "submitter": "Sibo Zhang", "authors": "Miao Liao, Feixiang Lu, Dingfu Zhou, Sibo Zhang, Wei Li, Ruigang Yang", "title": "DVI: Depth Guided Video Inpainting for Autonomous Driving", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.RO eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To get clear street-view and photo-realistic simulation in autonomous\ndriving, we present an automatic video inpainting algorithm that can remove\ntraffic agents from videos and synthesize missing regions with the guidance of\ndepth/point cloud. By building a dense 3D map from stitched point clouds,\nframes within a video are geometrically correlated via this common 3D map. In\norder to fill a target inpainting area in a frame, it is straightforward to\ntransform pixels from other frames into the current one with correct occlusion.\nFurthermore, we are able to fuse multiple videos through 3D point cloud\nregistration, making it possible to inpaint a target video with multiple source\nvideos. The motivation is to solve the long-time occlusion problem where an\noccluded area has never been visible in the entire video. To our knowledge, we\nare the first to fuse multiple videos for video inpainting. To verify the\neffectiveness of our approach, we build a large inpainting dataset in the real\nurban road environment with synchronized images and Lidar data including many\nchallenge scenes, e.g., long time occlusion. The experimental results show that\nthe proposed approach outperforms the state-of-the-art approaches for all the\ncriteria, especially the RMSE (Root Mean Squared Error) has been reduced by\nabout 13%.\n", "versions": [{"version": "v1", "created": "Fri, 17 Jul 2020 09:29:53 GMT"}], "update_date": "2020-09-23", "authors_parsed": [["Liao", "Miao", ""], ["Lu", "Feixiang", ""], ["Zhou", "Dingfu", ""], ["Zhang", "Sibo", ""], ["Li", "Wei", ""], ["Yang", "Ruigang", ""]]}, {"id": "2007.08855", "submitter": "Wenjie Chen", "authors": "Wenjie Chen, Fengtong Du, Ye Wang, Lihong Cao", "title": "A Biologically Plausible Audio-Visual Integration Model for Continual\n  Learning", "comments": "Accepted by 2021 International Joint Conference on Neural Networks", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of catastrophic forgetting has a history of more than 30 years\nand has not been completely solved yet. Since the human brain has natural\nability to perform continual lifelong learning, learning from the brain may\nprovide solutions to this problem. In this paper, we propose a novel\nbiologically plausible audio-visual integration model (AVIM) based on the\nassumption that the integration of audio and visual perceptual information in\nthe medial temporal lobe during learning is crucial to form concepts and make\ncontinual learning possible. Specifically, we use multi-compartment\nHodgkin-Huxley neurons to build the model and adopt the calcium-based synaptic\ntagging and capture as the model's learning rule. Furthermore, we define a new\ncontinual learning paradigm to simulate the possible continual learning process\nin the human brain. We then test our model under this new paradigm. Our\nexperimental results show that the proposed AVIM can achieve state-of-the-art\ncontinual learning performance compared with other advanced methods such as\nOWM, iCaRL and GEM. Moreover, it can generate stable representations of objects\nduring learning. These results support our assumption that concept formation is\nessential for continuous lifelong learning and suggest the proposed AVIM is a\npossible concept formation mechanism.\n", "versions": [{"version": "v1", "created": "Fri, 17 Jul 2020 09:30:41 GMT"}, {"version": "v2", "created": "Tue, 20 Jul 2021 09:21:16 GMT"}], "update_date": "2021-07-21", "authors_parsed": [["Chen", "Wenjie", ""], ["Du", "Fengtong", ""], ["Wang", "Ye", ""], ["Cao", "Lihong", ""]]}, {"id": "2007.08911", "submitter": "Ehsan Toreini", "authors": "Ehsan Toreini, Mhairi Aitken, Kovila P. L. Coopamootoo, Karen Elliott,\n  Vladimiro Gonzalez Zelaya, Paolo Missier, Magdalene Ng, Aad van Moorsel", "title": "Technologies for Trustworthy Machine Learning: A Survey in a\n  Socio-Technical Context", "comments": "We are updating some sections to include more recent advances", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Concerns about the societal impact of AI-based services and systems has\nencouraged governments and other organisations around the world to propose AI\npolicy frameworks to address fairness, accountability, transparency and related\ntopics. To achieve the objectives of these frameworks, the data and software\nengineers who build machine-learning systems require knowledge about a variety\nof relevant supporting tools and techniques. In this paper we provide an\noverview of technologies that support building trustworthy machine learning\nsystems, i.e., systems whose properties justify that people place trust in\nthem. We argue that four categories of system properties are instrumental in\nachieving the policy objectives, namely fairness, explainability, auditability\nand safety & security (FEAS). We discuss how these properties need to be\nconsidered across all stages of the machine learning life cycle, from data\ncollection through run-time model inference. As a consequence, we survey in\nthis paper the main technologies with respect to all four of the FEAS\nproperties, for data-centric as well as model-centric stages of the machine\nlearning system life cycle. We conclude with an identification of open research\nproblems, with a particular focus on the connection between trustworthy machine\nlearning technologies and their implications for individuals and society.\n", "versions": [{"version": "v1", "created": "Fri, 17 Jul 2020 11:39:20 GMT"}, {"version": "v2", "created": "Mon, 7 Jun 2021 09:40:31 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Toreini", "Ehsan", ""], ["Aitken", "Mhairi", ""], ["Coopamootoo", "Kovila P. L.", ""], ["Elliott", "Karen", ""], ["Zelaya", "Vladimiro Gonzalez", ""], ["Missier", "Paolo", ""], ["Ng", "Magdalene", ""], ["van Moorsel", "Aad", ""]]}, {"id": "2007.08955", "submitter": "Rodothea Myrsini Tsoupidi", "authors": "Rodothea Myrsini Tsoupidi, Roberto Casta\\~neda Lozano and Benoit\n  Baudry", "title": "Constraint-Based Software Diversification for Efficient Mitigation of\n  Code-Reuse Attacks", "comments": "15 pages, 26th International Conference on Principles and Practice of\n  Constraint Programming", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Modern software deployment process produces software that is uniform, and\nhence vulnerable to large-scale code-reuse attacks. Compiler-based\ndiversification improves the resilience and security of software systems by\nautomatically generating different assembly code versions of a given program.\nExisting techniques are efficient but do not have a precise control over the\nquality of the generated code variants.\n  This paper introduces Diversity by Construction (DivCon), a constraint-based\ncompiler approach to software diversification. Unlike previous approaches,\nDivCon allows users to control and adjust the conflicting goals of diversity\nand code quality. A key enabler is the use of Large Neighborhood Search (LNS)\nto generate highly diverse assembly code efficiently.\n  Experiments using two popular compiler benchmark suites confirm that there is\na trade-off between quality of each assembly code version and diversity of the\nentire pool of versions. Our results show that DivCon allows users to trade\nbetween these two properties by generating diverse assembly code for a range of\nquality bounds. In particular, the experiments show that DivCon is able to\nmitigate code-reuse attacks effectively while delivering near-optimal code (<\n10% optimality gap).\n  For constraint programming researchers and practitioners, this paper\ndemonstrates that LNS is a valuable technique for finding diverse solutions.\nFor security researchers and software engineers, DivCon extends the scope of\ncompiler-based diversification to performance-critical and resource-constrained\napplications.\n", "versions": [{"version": "v1", "created": "Fri, 17 Jul 2020 13:01:44 GMT"}], "update_date": "2020-07-20", "authors_parsed": [["Tsoupidi", "Rodothea Myrsini", ""], ["Lozano", "Roberto Casta\u00f1eda", ""], ["Baudry", "Benoit", ""]]}, {"id": "2007.08973", "submitter": "Antonia Creswell", "authors": "Antonia Creswell, Kyriacos Nikiforou, Oriol Vinyals, Andre Saraiva,\n  Rishabh Kabra, Loic Matthey, Chris Burgess, Malcolm Reynolds, Richard\n  Tanburn, Marta Garnelo, Murray Shanahan", "title": "AlignNet: Unsupervised Entity Alignment", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently developed deep learning models are able to learn to segment scenes\ninto component objects without supervision. This opens many new and exciting\navenues of research, allowing agents to take objects (or entities) as inputs,\nrather that pixels. Unfortunately, while these models provide excellent\nsegmentation of a single frame, they do not keep track of how objects segmented\nat one time-step correspond (or align) to those at a later time-step. The\nalignment (or correspondence) problem has impeded progress towards using object\nrepresentations in downstream tasks. In this paper we take steps towards\nsolving the alignment problem, presenting the AlignNet, an unsupervised\nalignment module.\n", "versions": [{"version": "v1", "created": "Fri, 17 Jul 2020 13:38:29 GMT"}, {"version": "v2", "created": "Tue, 21 Jul 2020 13:12:07 GMT"}], "update_date": "2020-07-22", "authors_parsed": [["Creswell", "Antonia", ""], ["Nikiforou", "Kyriacos", ""], ["Vinyals", "Oriol", ""], ["Saraiva", "Andre", ""], ["Kabra", "Rishabh", ""], ["Matthey", "Loic", ""], ["Burgess", "Chris", ""], ["Reynolds", "Malcolm", ""], ["Tanburn", "Richard", ""], ["Garnelo", "Marta", ""], ["Shanahan", "Murray", ""]]}, {"id": "2007.09028", "submitter": "Arnold Yeung", "authors": "Arnold YS Yeung, Shalmali Joshi, Joseph Jay Williams, Frank Rudzicz", "title": "Sequential Explanations with Mental Model-Based Policies", "comments": "Accepted into ICML 2020 Workshop on Human Interpretability in Machine\n  Learning (Spotlight)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.HC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The act of explaining across two parties is a feedback loop, where one\nprovides information on what needs to be explained and the other provides an\nexplanation relevant to this information. We apply a reinforcement learning\nframework which emulates this format by providing explanations based on the\nexplainee's current mental model. We conduct novel online human experiments\nwhere explanations generated by various explanation methods are selected and\npresented to participants, using policies which observe participants' mental\nmodels, in order to optimize an interpretability proxy. Our results suggest\nthat mental model-based policies (anchored in our proposed state\nrepresentation) may increase interpretability over multiple sequential\nexplanations, when compared to a random selection baseline. This work provides\ninsight into how to select explanations which increase relevant information for\nusers, and into conducting human-grounded experimentation to understand\ninterpretability.\n", "versions": [{"version": "v1", "created": "Fri, 17 Jul 2020 14:43:46 GMT"}], "update_date": "2020-07-20", "authors_parsed": [["Yeung", "Arnold YS", ""], ["Joshi", "Shalmali", ""], ["Williams", "Joseph Jay", ""], ["Rudzicz", "Frank", ""]]}, {"id": "2007.09053", "submitter": "Nikhil Krishnaswamy", "authors": "Katherine Krajovic, Nikhil Krishnaswamy, Nathaniel J. Dimick, R. Pito\n  Salas, and James Pustejovsky", "title": "Situated Multimodal Control of a Mobile Robot: Navigation through a\n  Virtual Environment", "comments": "4 pages, 1 table, 4 figures, proceedings of RoboDIAL special session\n  a SigDIAL 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new interface for controlling a navigation robot in novel\nenvironments using coordinated gesture and language. We use a TurtleBot3 robot\nwith a LIDAR and a camera, an embodied simulation of what the robot has\nencountered while exploring, and a cross-platform bridge facilitating generic\ncommunication. A human partner can deliver instructions to the robot using\nspoken English and gestures relative to the simulated environment, to guide the\nrobot through navigation tasks.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jul 2020 16:37:01 GMT"}], "update_date": "2020-07-20", "authors_parsed": [["Krajovic", "Katherine", ""], ["Krishnaswamy", "Nikhil", ""], ["Dimick", "Nathaniel J.", ""], ["Salas", "R. Pito", ""], ["Pustejovsky", "James", ""]]}, {"id": "2007.09055", "submitter": "Tom Paine", "authors": "Tom Le Paine, Cosmin Paduraru, Andrea Michi, Caglar Gulcehre, Konrad\n  Zolna, Alexander Novikov, Ziyu Wang, Nando de Freitas", "title": "Hyperparameter Selection for Offline Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Offline reinforcement learning (RL purely from logged data) is an important\navenue for deploying RL techniques in real-world scenarios. However, existing\nhyperparameter selection methods for offline RL break the offline assumption by\nevaluating policies corresponding to each hyperparameter setting in the\nenvironment. This online execution is often infeasible and hence undermines the\nmain aim of offline RL. Therefore, in this work, we focus on \\textit{offline\nhyperparameter selection}, i.e. methods for choosing the best policy from a set\nof many policies trained using different hyperparameters, given only logged\ndata. Through large-scale empirical evaluation we show that: 1) offline RL\nalgorithms are not robust to hyperparameter choices, 2) factors such as the\noffline RL algorithm and method for estimating Q values can have a big impact\non hyperparameter selection, and 3) when we control those factors carefully, we\ncan reliably rank policies across hyperparameter choices, and therefore choose\npolicies which are close to the best policy in the set. Overall, our results\npresent an optimistic view that offline hyperparameter selection is within\nreach, even in challenging tasks with pixel observations, high dimensional\naction spaces, and long horizon.\n", "versions": [{"version": "v1", "created": "Fri, 17 Jul 2020 15:30:38 GMT"}], "update_date": "2020-07-20", "authors_parsed": [["Paine", "Tom Le", ""], ["Paduraru", "Cosmin", ""], ["Michi", "Andrea", ""], ["Gulcehre", "Caglar", ""], ["Zolna", "Konrad", ""], ["Novikov", "Alexander", ""], ["Wang", "Ziyu", ""], ["de Freitas", "Nando", ""]]}, {"id": "2007.09079", "submitter": "Vijay  Menon", "authors": "Hadi Hosseini, Vijay Menon, Nisarg Shah, Sujoy Sikdar", "title": "Necessarily Optimal One-Sided Matchings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the classical problem of matching $n$ agents to $n$ objects, where\nthe agents have ranked preferences over the objects. We focus on two popular\ndesiderata from the matching literature: Pareto optimality and rank-maximality.\nInstead of asking the agents to report their complete preferences, our goal is\nto learn a desirable matching from partial preferences, specifically a matching\nthat is necessarily Pareto optimal (NPO) or necessarily rank-maximal (NRM)\nunder any completion of the partial preferences. We focus on the top-$k$ model\nin which agents reveal a prefix of their preference rankings. We design\nefficient algorithms to check if a given matching is NPO or NRM, and to check\nwhether such a matching exists given top-$k$ partial preferences. We also study\nonline algorithms for eliciting partial preferences adaptively, and prove\nbounds on their competitive ratio.\n", "versions": [{"version": "v1", "created": "Fri, 17 Jul 2020 16:01:34 GMT"}, {"version": "v2", "created": "Fri, 26 Feb 2021 22:41:02 GMT"}, {"version": "v3", "created": "Tue, 13 Apr 2021 21:45:37 GMT"}], "update_date": "2021-04-15", "authors_parsed": [["Hosseini", "Hadi", ""], ["Menon", "Vijay", ""], ["Shah", "Nisarg", ""], ["Sikdar", "Sujoy", ""]]}, {"id": "2007.09101", "submitter": "Teng Liu", "authors": "Teng Liu, Xiaolin Tang, Jinwei Zhang, Wenbo Li, Zejian Deng, Yalian\n  Yang", "title": "Reinforcement Learning-Enabled Decision-Making Strategies for a\n  Vehicle-Cyber-Physical-System in Connected Environment", "comments": "5 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.AI cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As a typical vehicle-cyber-physical-system (V-CPS), connected automated\nvehicles attracted more and more attention in recent years. This paper focuses\non discussing the decision-making (DM) strategy for autonomous vehicles in a\nconnected environment. First, the highway DM problem is formulated, wherein the\nvehicles can exchange information via wireless networking. Then, two classical\nreinforcement learning (RL) algorithms, Q-learning and Dyna, are leveraged to\nderive the DM strategies in a predefined driving scenario. Finally, the control\nperformance of the derived DM policies in safety and efficiency is analyzed.\nFurthermore, the inherent differences of the RL algorithms are embodied and\ndiscussed in DM strategies.\n", "versions": [{"version": "v1", "created": "Thu, 16 Jul 2020 14:37:50 GMT"}], "update_date": "2020-07-20", "authors_parsed": [["Liu", "Teng", ""], ["Tang", "Xiaolin", ""], ["Zhang", "Jinwei", ""], ["Li", "Wenbo", ""], ["Deng", "Zejian", ""], ["Yang", "Yalian", ""]]}, {"id": "2007.09102", "submitter": "Hyunsuk Baek", "authors": "Shin Woong Sung, Hyunsuk Baek, Hyeonjun Sim, Eun Hie Kim, Hyunwoo\n  Hwangbo, and Young Jae Jang", "title": "Breaking Moravec's Paradox: Visual-Based Distribution in Smart Fashion\n  Retail", "comments": "10 pages, 19 figures, The fifth international workshop on fashion and\n  KDD, KDD 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.AI cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we report an industry-academia collaborative study on the\ndistribution method of fashion products using an artificial intelligence (AI)\ntechnique combined with an optimization method. To meet the current fashion\ntrend of short product lifetimes and an increasing variety of styles, the\ncompany produces limited volumes of a large variety of styles. However, due to\nthe limited volume of each style, some styles may not be distributed to some\noff-line stores. As a result, this high-variety, low-volume strategy presents\nanother challenge to distribution managers. We collaborated with KOLON F/C, one\nof the largest fashion business units in South Korea, to develop models and an\nalgorithm to optimally distribute the products to the stores based on the\nvisual images of the products. The team developed a deep learning model that\neffectively represents the styles of clothes based on their visual image.\nMoreover, the team created an optimization model that effectively determines\nthe product mix for each store based on the image representation of clothes. In\nthe past, computers were only considered to be useful for conducting logical\ncalculations, and visual perception and cognition were considered to be\ndifficult computational tasks. The proposed approach is significant in that it\nuses both AI (perception and cognition) and mathematical optimization (logical\ncalculation) to address a practical supply chain problem, which is why the\nstudy was called \"Breaking Moravec's Paradox.\"\n", "versions": [{"version": "v1", "created": "Fri, 10 Jul 2020 02:20:39 GMT"}], "update_date": "2020-07-20", "authors_parsed": [["Sung", "Shin Woong", ""], ["Baek", "Hyunsuk", ""], ["Sim", "Hyeonjun", ""], ["Kim", "Eun Hie", ""], ["Hwangbo", "Hyunwoo", ""], ["Jang", "Young Jae", ""]]}, {"id": "2007.09177", "submitter": "Jichen Zhu", "authors": "Jennifer Villareale, Ana Acosta-Ruiz, Samuel Arcaro, Thomas Fox, Evan\n  Freed, Robert Gray, Mathias L\\\"owe, Panote Nuchprayoon, Aleksanteri Sladek,\n  Rush Weigelt, Yifu Li, Sebastian Risi, Jichen Zhu", "title": "iNNk: A Multi-Player Game to Deceive a Neural Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents iNNK, a multiplayer drawing game where human players team\nup against an NN. The players need to successfully communicate a secret code\nword to each other through drawings, without being deciphered by the NN. With\nthis game, we aim to foster a playful environment where players can, in a small\nway, go from passive consumers of NN applications to creative thinkers and\ncritical challengers.\n", "versions": [{"version": "v1", "created": "Fri, 17 Jul 2020 18:25:10 GMT"}, {"version": "v2", "created": "Fri, 15 Jan 2021 17:31:00 GMT"}], "update_date": "2021-01-18", "authors_parsed": [["Villareale", "Jennifer", ""], ["Acosta-Ruiz", "Ana", ""], ["Arcaro", "Samuel", ""], ["Fox", "Thomas", ""], ["Freed", "Evan", ""], ["Gray", "Robert", ""], ["L\u00f6we", "Mathias", ""], ["Nuchprayoon", "Panote", ""], ["Sladek", "Aleksanteri", ""], ["Weigelt", "Rush", ""], ["Li", "Yifu", ""], ["Risi", "Sebastian", ""], ["Zhu", "Jichen", ""]]}, {"id": "2007.09185", "submitter": "Minqi Jiang", "authors": "Minqi Jiang, Jelena Luketina, Nantas Nardelli, Pasquale Minervini,\n  Philip H. S. Torr, Shimon Whiteson, Tim Rockt\\\"aschel", "title": "WordCraft: An Environment for Benchmarking Commonsense Agents", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ability to quickly solve a wide range of real-world tasks requires a\ncommonsense understanding of the world. Yet, how to best extract such knowledge\nfrom natural language corpora and integrate it with reinforcement learning (RL)\nagents remains an open challenge. This is partly due to the lack of lightweight\nsimulation environments that sufficiently reflect the semantics of the real\nworld and provide knowledge sources grounded with respect to observations in an\nRL environment. To better enable research on agents making use of commonsense\nknowledge, we propose WordCraft, an RL environment based on Little Alchemy 2.\nThis lightweight environment is fast to run and built upon entities and\nrelations inspired by real-world semantics. We evaluate several representation\nlearning methods on this new benchmark and propose a new method for integrating\nknowledge graphs with an RL agent.\n", "versions": [{"version": "v1", "created": "Fri, 17 Jul 2020 18:40:46 GMT"}], "update_date": "2020-07-21", "authors_parsed": [["Jiang", "Minqi", ""], ["Luketina", "Jelena", ""], ["Nardelli", "Nantas", ""], ["Minervini", "Pasquale", ""], ["Torr", "Philip H. S.", ""], ["Whiteson", "Shimon", ""], ["Rockt\u00e4schel", "Tim", ""]]}, {"id": "2007.09206", "submitter": "Daniel Garijo", "authors": "Daniel Garijo and Maximiliano Osorio", "title": "OBA: An Ontology-Based Framework for Creating REST APIs for Knowledge\n  Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In recent years, Semantic Web technologies have been increasingly adopted by\nresearchers, industry and public institutions to describe and link data on the\nWeb, create web annotations and consume large knowledge graphs like Wikidata\nand DBPedia. However, there is still a knowledge gap between ontology\nengineers, who design, populate and create knowledge graphs; and web\ndevelopers, who need to understand, access and query these knowledge graphs but\nare not familiar with ontologies, RDF or SPARQL. In this paper we describe the\nOntology-Based APIs framework (OBA), our approach to automatically create REST\nAPIs from ontologies while following RESTful API best practices. Given an\nontology (or ontology network) OBA uses standard technologies familiar to web\ndevelopers (OpenAPI Specification, JSON) and combines them with W3C standards\n(OWL, JSON-LD frames and SPARQL) to create maintainable APIs with\ndocumentation, units tests, automated validation of resources and clients (in\nPython, Javascript, etc.) for non Semantic Web experts to access the contents\nof a target knowledge graph. We showcase OBA with three examples that\nillustrate the capabilities of the framework for different ontologies.\n", "versions": [{"version": "v1", "created": "Fri, 17 Jul 2020 19:46:18 GMT"}], "update_date": "2020-07-21", "authors_parsed": [["Garijo", "Daniel", ""], ["Osorio", "Maximiliano", ""]]}, {"id": "2007.09227", "submitter": "Yuxiao Hu", "authors": "Sean Wang, Yuxiao Hu, Jason Wu", "title": "KubeEdge.AI: AI Platform for Edge Devices", "comments": "https://www.embedded-ai.org", "journal-ref": "Embedded AI Summit 2019, Shenzhen, china", "doi": null, "report-no": null, "categories": "cs.DC cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The demand for smartness in embedded systems has been mounting up drastically\nin the past few years. Embedded system today must address the fundamental\nchallenges introduced by cloud computing and artificial intelligence. KubeEdge\n[1] is an edge computing framework build on top of Kubernetes [2]. It provides\ncompute resource management, deployment, runtime and operation capabilities on\ngeo-located edge computing resources, from the cloud, which is a natural fit\nfor embedded systems. Here we propose KubeEdge.AI, an edge AI framework on top\nof KubeEdge. It provides a set of key modules and interfaces: a data handling\nand processing engine, a concise AI runtime, a decision engine, and a\ndistributed data query interface. KubeEdge.AI will help reduce the burdens for\ndeveloping specific edge/embedded AI systems and promote edge-cloud\ncoordination and synergy.\n", "versions": [{"version": "v1", "created": "Tue, 7 Jul 2020 23:36:23 GMT"}], "update_date": "2020-07-21", "authors_parsed": [["Wang", "Sean", ""], ["Hu", "Yuxiao", ""], ["Wu", "Jason", ""]]}, {"id": "2007.09288", "submitter": "Han Lei", "authors": "Zhiyong Yu, Lei Han, Chao Chen, Wenzhong Guo, Zhiwen Yu", "title": "Object Tracking by Least Spatiotemporal Searches", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tracking a car or a person in a city is crucial for urban safety management.\nHow can we complete the task with minimal number of spatiotemporal searches\nfrom massive camera records? This paper proposes a strategy named IHMs\n(Intermediate Searching at Heuristic Moments): each step we figure out which\nmoment is the best to search according to a heuristic indicator, then at that\nmoment search locations one by one in descending order of predicted appearing\nprobabilities, until a search hits; iterate this step until we get the object's\ncurrent location. Five searching strategies are compared in experiments, and\nIHMs is validated to be most efficient, which can save up to 1/3 total costs.\nThis result provides an evidence that \"searching at intermediate moments can\nsave cost\".\n", "versions": [{"version": "v1", "created": "Sat, 18 Jul 2020 00:17:55 GMT"}, {"version": "v2", "created": "Fri, 12 Mar 2021 07:25:27 GMT"}], "update_date": "2021-03-15", "authors_parsed": [["Yu", "Zhiyong", ""], ["Han", "Lei", ""], ["Chen", "Chao", ""], ["Guo", "Wenzhong", ""], ["Yu", "Zhiwen", ""]]}, {"id": "2007.09297", "submitter": "Alvaro Ovalle", "authors": "Alvaro Ovalle and Simon M. Lucas", "title": "Modulation of viability signals for self-regulatory control", "comments": "Accepted at the International Workshop on Active Inference 2020\n  (camera-ready version). Extended from 6 to 13 pages to include appendices and\n  a more comprehensive reference list", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We revisit the role of instrumental value as a driver of adaptive behavior.\nIn active inference, instrumental or extrinsic value is quantified by the\ninformation-theoretic surprisal of a set of observations measuring the extent\nto which those observations conform to prior beliefs or preferences. That is,\nan agent is expected to seek the type of evidence that is consistent with its\nown model of the world. For reinforcement learning tasks, the distribution of\npreferences replaces the notion of reward. We explore a scenario in which the\nagent learns this distribution in a self-supervised manner. In particular, we\nhighlight the distinction between observations induced by the environment and\nthose pertaining more directly to the continuity of an agent in time. We\nevaluate our methodology in a dynamic environment with discrete time and\nactions. First with a surprisal minimizing model-free agent (in the RL sense)\nand then expanding to the model-based case to minimize the expected free\nenergy.\n", "versions": [{"version": "v1", "created": "Sat, 18 Jul 2020 01:11:51 GMT"}, {"version": "v2", "created": "Tue, 13 Oct 2020 11:57:40 GMT"}], "update_date": "2020-10-14", "authors_parsed": [["Ovalle", "Alvaro", ""], ["Lucas", "Simon M.", ""]]}, {"id": "2007.09300", "submitter": "Deokgun Park", "authors": "SM Mazharul Islam, Md Ashaduzzaman Rubel Mondol, Aishwarya Pothula,\n  Deokgun Park", "title": "An Open-World Simulated Environment for Developmental Robotics", "comments": "Presented at Workshop on Learning in Artificial Open Worlds held with\n  ICML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As the current trend of artificial intelligence is shifting towards\nself-supervised learning, conventional norms such as highly curated\ndomain-specific data, application-specific learning models, extrinsic reward\nbased learning policies etc. might not provide with the suitable ground for\nsuch developments. In this paper, we introduce SEDRo, a Simulated Environment\nfor Developmental Robotics which allows a learning agent to have similar\nexperiences that a human infant goes through from the fetus stage up to 12\nmonths. A series of simulated tests based on developmental psychology will be\nused to evaluate the progress of a learning model.\n", "versions": [{"version": "v1", "created": "Sat, 18 Jul 2020 01:16:13 GMT"}], "update_date": "2020-07-21", "authors_parsed": [["Islam", "SM Mazharul", ""], ["Mondol", "Md Ashaduzzaman Rubel", ""], ["Pothula", "Aishwarya", ""], ["Park", "Deokgun", ""]]}, {"id": "2007.09310", "submitter": "Artem Polyvyanyy", "authors": "Artem Polyvyanyy, Alistair Moffat, Luciano Garc\\'ia-Ba\\~nuelos", "title": "An Entropic Relevance Measure for Stochastic Conformance Checking in\n  Process Mining", "comments": "8 pages. Postprint version of the ICPM 2020 paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given an event log as a collection of recorded real-world process traces,\nprocess mining aims to automatically construct a process model that is both\nsimple and provides a useful explanation of the traces. Conformance checking\ntechniques are then employed to characterize and quantify commonalities and\ndiscrepancies between the log's traces and the candidate models. Recent\napproaches to conformance checking acknowledge that the elements being compared\nare inherently stochastic - for example, some traces occur frequently and\nothers infrequently - and seek to incorporate this knowledge in their analyses.\n  Here we present an entropic relevance measure for stochastic conformance\nchecking, computed as the average number of bits required to compress each of\nthe log's traces, based on the structure and information about relative\nlikelihoods provided by the model. The measure penalizes traces from the event\nlog not captured by the model and traces described by the model but absent in\nthe event log, thus addressing both precision and recall quality criteria at\nthe same time. We further show that entropic relevance is computable in time\nlinear in the size of the log, and provide evaluation outcomes that demonstrate\nthe feasibility of using the new approach in industrial settings.\n", "versions": [{"version": "v1", "created": "Sat, 18 Jul 2020 02:25:33 GMT"}, {"version": "v2", "created": "Wed, 26 Aug 2020 15:57:16 GMT"}], "update_date": "2020-08-27", "authors_parsed": [["Polyvyanyy", "Artem", ""], ["Moffat", "Alistair", ""], ["Garc\u00eda-Ba\u00f1uelos", "Luciano", ""]]}, {"id": "2007.09331", "submitter": "Meihua Dang", "authors": "Meihua Dang, Antonio Vergari, Guy Van den Broeck", "title": "Strudel: Learning Structured-Decomposable Probabilistic Circuits", "comments": "12 pages, 3 figures, to be published on PGM2020 (The 10th\n  International Conference on Probabilistic Graphical Models)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Probabilistic circuits (PCs) represent a probability distribution as a\ncomputational graph. Enforcing structural properties on these graphs guarantees\nthat several inference scenarios become tractable. Among these properties,\nstructured decomposability is a particularly appealing one: it enables the\nefficient and exact computations of the probability of complex logical\nformulas, and can be used to reason about the expected output of certain\npredictive models under missing data. This paper proposes Strudel, a simple,\nfast and accurate learning algorithm for structured-decomposable PCs. Compared\nto prior work for learning structured-decomposable PCs, Strudel delivers more\naccurate single PC models in fewer iterations, and dramatically scales learning\nwhen building ensembles of PCs. It achieves this scalability by exploiting\nanother structural property of PCs, called determinism, and by sharing the same\ncomputational graph across mixture components. We show these advantages on\nstandard density estimation benchmarks and challenging inference scenarios.\n", "versions": [{"version": "v1", "created": "Sat, 18 Jul 2020 04:51:31 GMT"}, {"version": "v2", "created": "Wed, 2 Sep 2020 05:16:31 GMT"}], "update_date": "2020-09-03", "authors_parsed": [["Dang", "Meihua", ""], ["Vergari", "Antonio", ""], ["Broeck", "Guy Van den", ""]]}, {"id": "2007.09380", "submitter": "Xin Chen", "authors": "Xin Chen, Yawen Duan, Zewei Chen, Hang Xu, Zihao Chen, Xiaodan Liang,\n  Tong Zhang, Zhenguo Li", "title": "CATCH: Context-based Meta Reinforcement Learning for Transferrable\n  Architecture Search", "comments": "Published at ECCV2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural Architecture Search (NAS) achieved many breakthroughs in recent years.\nIn spite of its remarkable progress, many algorithms are restricted to\nparticular search spaces. They also lack efficient mechanisms to reuse\nknowledge when confronting multiple tasks. These challenges preclude their\napplicability, and motivate our proposal of CATCH, a novel Context-bAsed meTa\nreinforcement learning (RL) algorithm for transferrable arChitecture searcH.\nThe combination of meta-learning and RL allows CATCH to efficiently adapt to\nnew tasks while being agnostic to search spaces. CATCH utilizes a probabilistic\nencoder to encode task properties into latent context variables, which then\nguide CATCH's controller to quickly \"catch\" top-performing networks. The\ncontexts also assist a network evaluator in filtering inferior candidates and\nspeed up learning. Extensive experiments demonstrate CATCH's universality and\nsearch efficiency over many other widely-recognized algorithms. It is also\ncapable of handling cross-domain architecture search as competitive networks on\nImageNet, COCO, and Cityscapes are identified. This is the first work to our\nknowledge that proposes an efficient transferrable NAS solution while\nmaintaining robustness across various settings.\n", "versions": [{"version": "v1", "created": "Sat, 18 Jul 2020 09:35:53 GMT"}, {"version": "v2", "created": "Tue, 21 Jul 2020 01:12:31 GMT"}, {"version": "v3", "created": "Wed, 22 Jul 2020 05:39:31 GMT"}], "update_date": "2020-07-23", "authors_parsed": [["Chen", "Xin", ""], ["Duan", "Yawen", ""], ["Chen", "Zewei", ""], ["Xu", "Hang", ""], ["Chen", "Zihao", ""], ["Liang", "Xiaodan", ""], ["Zhang", "Tong", ""], ["Li", "Zhenguo", ""]]}, {"id": "2007.09445", "submitter": "Purva Pruthi", "authors": "Purva Pruthi, Javier Gonz\\'alez, Xiaoyu Lu, Madalina Fiterau", "title": "Structure Mapping for Transferability of Causal Models", "comments": "Presented at the Inductive Biases, Invariances and Generalization in\n  Reinforcement Learning Workshop, ICML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Human beings learn causal models and constantly use them to transfer\nknowledge between similar environments. We use this intuition to design a\ntransfer-learning framework using object-oriented representations to learn the\ncausal relationships between objects. A learned causal dynamics model can be\nused to transfer between variants of an environment with exchangeable\nperceptual features among objects but with the same underlying causal dynamics.\nWe adapt continuous optimization for structure learning techniques to\nexplicitly learn the cause and effects of the actions in an interactive\nenvironment and transfer to the target domain by categorization of the objects\nbased on causal knowledge. We demonstrate the advantages of our approach in a\ngridworld setting by combining causal model-based approach with model-free\napproach in reinforcement learning.\n", "versions": [{"version": "v1", "created": "Sat, 18 Jul 2020 14:59:54 GMT"}], "update_date": "2020-07-21", "authors_parsed": [["Pruthi", "Purva", ""], ["Gonz\u00e1lez", "Javier", ""], ["Lu", "Xiaoyu", ""], ["Fiterau", "Madalina", ""]]}, {"id": "2007.09448", "submitter": "Alberto Santamaria-Pang", "authors": "Alberto Santamaria-Pang, James Kubricht, Aritra Chowdhury, Chitresh\n  Bhushan, Peter Tu", "title": "Towards Emergent Language Symbolic Semantic Segmentation and Model\n  Interpretability", "comments": "Accepted to Medical Image Computing and Computer Assisted\n  Intervention (MICCAI) 2020, 9 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in methods focused on the grounding problem have resulted in\ntechniques that can be used to construct a symbolic language associated with a\nspecific domain. Inspired by how humans communicate complex ideas through\nlanguage, we developed a generalized Symbolic Semantic ($\\text{S}^2$) framework\nfor interpretable segmentation. Unlike adversarial models (e.g., GANs), we\nexplicitly model cooperation between two agents, a Sender and a Receiver, that\nmust cooperate to achieve a common goal. The Sender receives information from a\nhigh layer of a segmentation network and generates a symbolic sentence derived\nfrom a categorical distribution. The Receiver obtains the symbolic sentences\nand co-generates the segmentation mask. In order for the model to converge, the\nSender and Receiver must learn to communicate using a private language. We\napply our architecture to segment tumors in the TCGA dataset. A UNet-like\narchitecture is used to generate input to the Sender network which produces a\nsymbolic sentence, and a Receiver network co-generates the segmentation mask\nbased on the sentence. Our Segmentation framework achieved similar or better\nperformance compared with state-of-the-art segmentation methods. In addition,\nour results suggest direct interpretation of the symbolic sentences to\ndiscriminate between normal and tumor tissue, tumor morphology, and other image\ncharacteristics.\n", "versions": [{"version": "v1", "created": "Sat, 18 Jul 2020 15:06:12 GMT"}, {"version": "v2", "created": "Tue, 4 Aug 2020 19:12:20 GMT"}], "update_date": "2020-08-06", "authors_parsed": [["Santamaria-Pang", "Alberto", ""], ["Kubricht", "James", ""], ["Chowdhury", "Aritra", ""], ["Bhushan", "Chitresh", ""], ["Tu", "Peter", ""]]}, {"id": "2007.09450", "submitter": "Ezio Bartocci", "authors": "Ezio Bartocci and Laura Kov\\'acs and Miroslav Stankovi\\v{c}", "title": "Analysis of Bayesian Networks via Prob-Solvable Loops", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Prob-solvable loops are probabilistic programs with polynomial assignments\nover random variables and parametrised distributions, for which the full\nautomation of moment-based invariant generation is decidable. In this paper we\nextend Prob-solvable loops with new features essential for encoding Bayesian\nnetworks (BNs). We show that various BNs, such as discrete, Gaussian,\nconditional linear Gaussian and dynamic BNs, can be naturally encoded as\nProb-solvable loops. Thanks to these encodings, we can automatically solve\nseveral BN related problems, including exact inference, sensitivity analysis,\nfiltering and computing the expected number of rejecting samples in\nsampling-based procedures. We evaluate our work on a number of BN benchmarks,\nusing automated invariant generation within Prob-solvable loop analysis.\n", "versions": [{"version": "v1", "created": "Sat, 18 Jul 2020 15:16:13 GMT"}, {"version": "v2", "created": "Sun, 26 Jul 2020 08:03:08 GMT"}], "update_date": "2020-07-28", "authors_parsed": [["Bartocci", "Ezio", ""], ["Kov\u00e1cs", "Laura", ""], ["Stankovi\u010d", "Miroslav", ""]]}, {"id": "2007.09454", "submitter": "Xiaobin Hu", "authors": "Xiaobin Hu, Wenqi Ren, John LaMaster, Xiaochun Cao, Xiaoming Li,\n  Zechao Li, Bjoern Menze, and Wei Liu", "title": "Face Super-Resolution Guided by 3D Facial Priors", "comments": "Accepted as a spotlight paper, European Conference on Computer Vision\n  2020 (ECCV)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  State-of-the-art face super-resolution methods employ deep convolutional\nneural networks to learn a mapping between low- and high- resolution facial\npatterns by exploring local appearance knowledge. However, most of these\nmethods do not well exploit facial structures and identity information, and\nstruggle to deal with facial images that exhibit large pose variations. In this\npaper, we propose a novel face super-resolution method that explicitly\nincorporates 3D facial priors which grasp the sharp facial structures. Our work\nis the first to explore 3D morphable knowledge based on the fusion of\nparametric descriptions of face attributes (e.g., identity, facial expression,\ntexture, illumination, and face pose). Furthermore, the priors can easily be\nincorporated into any network and are extremely efficient in improving the\nperformance and accelerating the convergence speed. Firstly, a 3D face\nrendering branch is set up to obtain 3D priors of salient facial structures and\nidentity knowledge. Secondly, the Spatial Attention Module is used to better\nexploit this hierarchical information (i.e., intensity similarity, 3D facial\nstructure, and identity content) for the super-resolution problem. Extensive\nexperiments demonstrate that the proposed 3D priors achieve superior face\nsuper-resolution results over the state-of-the-arts.\n", "versions": [{"version": "v1", "created": "Sat, 18 Jul 2020 15:26:07 GMT"}], "update_date": "2020-07-21", "authors_parsed": [["Hu", "Xiaobin", ""], ["Ren", "Wenqi", ""], ["LaMaster", "John", ""], ["Cao", "Xiaochun", ""], ["Li", "Xiaoming", ""], ["Li", "Zechao", ""], ["Menze", "Bjoern", ""], ["Liu", "Wei", ""]]}, {"id": "2007.09469", "submitter": "Alberto Santamaria-Pang", "authors": "Aritra Chowdhury, James R. Kubricht, Anup Sood, Peter Tu, Alberto\n  Santamaria-Pang", "title": "ESCELL: Emergent Symbolic Cellular Language", "comments": "IEEE International Symposium on Biomedical Imaging (IEEE ISBI 2020)", "journal-ref": "2020 IEEE 17th International Symposium on Biomedical Imaging\n  (ISBI), Iowa City, IA, USA, 2020, pp. 1604-1607", "doi": "10.1109/ISBI45749.2020.9098343", "report-no": null, "categories": "cs.AI cs.CV cs.LG q-bio.CB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present ESCELL, a method for developing an emergent symbolic language of\ncommunication between multiple agents reasoning about cells. We show how agents\nare able to cooperate and communicate successfully in the form of symbols\nsimilar to human language to accomplish a task in the form of a referential\ngame (Lewis' signaling game). In one form of the game, a sender and a receiver\nobserve a set of cells from 5 different cell phenotypes. The sender is told one\ncell is a target and is allowed to send one symbol to the receiver from a fixed\narbitrary vocabulary size. The receiver relies on the information in the symbol\nto identify the target cell. We train the sender and receiver networks to\ndevelop an innate emergent language between themselves to accomplish this task.\nWe observe that the networks are able to successfully identify cells from 5\ndifferent phenotypes with an accuracy of 93.2%. We also introduce a new form of\nthe signaling game where the sender is shown one image instead of all the\nimages that the receiver sees. The networks successfully develop an emergent\nlanguage to get an identification accuracy of 77.8%.\n", "versions": [{"version": "v1", "created": "Sat, 18 Jul 2020 16:34:36 GMT"}], "update_date": "2020-07-21", "authors_parsed": [["Chowdhury", "Aritra", ""], ["Kubricht", "James R.", ""], ["Sood", "Anup", ""], ["Tu", "Peter", ""], ["Santamaria-Pang", "Alberto", ""]]}, {"id": "2007.09483", "submitter": "Emma Rocheteau", "authors": "Emma Rocheteau and Pietro Li\\`o and Stephanie Hyland", "title": "Temporal Pointwise Convolutional Networks for Length of Stay Prediction\n  in the Intensive Care Unit", "comments": "ACM CHIL 2021 Proceedings. arXiv admin note: substantial text overlap\n  with arXiv:2006.16109", "journal-ref": null, "doi": "10.1145/3450439.3451860", "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The pressure of ever-increasing patient demand and budget restrictions make\nhospital bed management a daily challenge for clinical staff. Most critical is\nthe efficient allocation of resource-heavy Intensive Care Unit (ICU) beds to\nthe patients who need life support. Central to solving this problem is knowing\nfor how long the current set of ICU patients are likely to stay in the unit. In\nthis work, we propose a new deep learning model based on the combination of\ntemporal convolution and pointwise (1x1) convolution, to solve the length of\nstay prediction task on the eICU and MIMIC-IV critical care datasets. The model\n- which we refer to as Temporal Pointwise Convolution (TPC) - is specifically\ndesigned to mitigate common challenges with Electronic Health Records, such as\nskewness, irregular sampling and missing data. In doing so, we have achieved\nsignificant performance benefits of 18-68% (metric and dataset dependent) over\nthe commonly used Long-Short Term Memory (LSTM) network, and the multi-head\nself-attention network known as the Transformer. By adding mortality prediction\nas a side-task, we can improve performance further still, resulting in a mean\nabsolute deviation of 1.55 days (eICU) and 2.28 days (MIMIC-IV) on predicting\nremaining length of stay.\n", "versions": [{"version": "v1", "created": "Sat, 18 Jul 2020 17:30:10 GMT"}, {"version": "v2", "created": "Thu, 29 Oct 2020 16:27:09 GMT"}, {"version": "v3", "created": "Fri, 30 Oct 2020 15:34:14 GMT"}, {"version": "v4", "created": "Wed, 24 Feb 2021 12:10:39 GMT"}], "update_date": "2021-02-25", "authors_parsed": [["Rocheteau", "Emma", ""], ["Li\u00f2", "Pietro", ""], ["Hyland", "Stephanie", ""]]}, {"id": "2007.09515", "submitter": "Bharathan Balaji", "authors": "Bo-Jhang Ho, Bharathan Balaji, Mehmet Koseoglu, Sandeep Sandha, Siyou\n  Pei, Mani Srivastava", "title": "Quick Question: Interrupting Users for Microtasks with Reinforcement\n  Learning", "comments": "Presented at the 2nd Workshop on Human in the Loop Learning in ICML\n  2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Human attention is a scarce resource in modern computing. A multitude of\nmicrotasks vie for user attention to crowdsource information, perform momentary\nassessments, personalize services, and execute actions with a single touch. A\nlot gets done when these tasks take up the invisible free moments of the day.\nHowever, an interruption at an inappropriate time degrades productivity and\ncauses annoyance. Prior works have exploited contextual cues and behavioral\ndata to identify interruptibility for microtasks with much success. With Quick\nQuestion, we explore use of reinforcement learning (RL) to schedule microtasks\nwhile minimizing user annoyance and compare its performance with supervised\nlearning. We model the problem as a Markov decision process and use Advantage\nActor Critic algorithm to identify interruptible moments based on context and\nhistory of user interactions. In our 5-week, 30-participant study, we compare\nthe proposed RL algorithm against supervised learning methods. While the mean\nnumber of responses between both methods is commensurate, RL is more effective\nat avoiding dismissal of notifications and improves user experience over time.\n", "versions": [{"version": "v1", "created": "Sat, 18 Jul 2020 20:26:53 GMT"}], "update_date": "2020-07-21", "authors_parsed": [["Ho", "Bo-Jhang", ""], ["Balaji", "Bharathan", ""], ["Koseoglu", "Mehmet", ""], ["Sandha", "Sandeep", ""], ["Pei", "Siyou", ""], ["Srivastava", "Mani", ""]]}, {"id": "2007.09540", "submitter": "Arnaud Fickinger", "authors": "Arnaud Fickinger, Simon Zhuang, Dylan Hadfield-Menell, Stuart Russell", "title": "Multi-Principal Assistance Games", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Assistance games (also known as cooperative inverse reinforcement learning\ngames) have been proposed as a model for beneficial AI, wherein a robotic agent\nmust act on behalf of a human principal but is initially uncertain about the\nhumans payoff function. This paper studies multi-principal assistance games,\nwhich cover the more general case in which the robot acts on behalf of N humans\nwho may have widely differing payoffs. Impossibility theorems in social choice\ntheory and voting theory can be applied to such games, suggesting that\nstrategic behavior by the human principals may complicate the robots task in\nlearning their payoffs. We analyze in particular a bandit apprentice game in\nwhich the humans act first to demonstrate their individual preferences for the\narms and then the robot acts to maximize the sum of human payoffs. We explore\nthe extent to which the cost of choosing suboptimal arms reduces the incentive\nto mislead, a form of natural mechanism design. In this context we propose a\nsocial choice method that uses shared control of a system to combine preference\ninference with social welfare optimization.\n", "versions": [{"version": "v1", "created": "Sun, 19 Jul 2020 00:23:25 GMT"}], "update_date": "2020-07-21", "authors_parsed": [["Fickinger", "Arnaud", ""], ["Zhuang", "Simon", ""], ["Hadfield-Menell", "Dylan", ""], ["Russell", "Stuart", ""]]}, {"id": "2007.09551", "submitter": "Soham Dan", "authors": "Soham Dan, Hangfeng He, Dan Roth", "title": "Understanding Spatial Relations through Multiple Modalities", "comments": null, "journal-ref": "LREC 2020", "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recognizing spatial relations and reasoning about them is essential in\nmultiple applications including navigation, direction giving and human-computer\ninteraction in general. Spatial relations between objects can either be\nexplicit -- expressed as spatial prepositions, or implicit -- expressed by\nspatial verbs such as moving, walking, shifting, etc. Both these, but implicit\nrelations in particular, require significant common sense understanding. In\nthis paper, we introduce the task of inferring implicit and explicit spatial\nrelations between two entities in an image. We design a model that uses both\ntextual and visual information to predict the spatial relations, making use of\nboth positional and size information of objects and image embeddings. We\ncontrast our spatial model with powerful language models and show how our\nmodeling complements the power of these, improving prediction accuracy and\ncoverage and facilitates dealing with unseen subjects, objects and relations.\n", "versions": [{"version": "v1", "created": "Sun, 19 Jul 2020 01:35:08 GMT"}], "update_date": "2020-07-21", "authors_parsed": [["Dan", "Soham", ""], ["He", "Hangfeng", ""], ["Roth", "Dan", ""]]}, {"id": "2007.09563", "submitter": "Somaiyeh MahmoudZadeh", "authors": "Somaiyeh MahmoudZadeh, David MW Powers, Reza Bairam Zadeh", "title": "Autonomy and Unmanned Vehicles Augmented Reactive Mission-Motion\n  Planning Architecture for Autonomous Vehicles", "comments": null, "journal-ref": "Book: Springer Nature (2019), Cognitive Science and Technology,\n  ISBN 978-981-13-2245-7, Series ISSN: 2195-3988. 2019", "doi": "10.1007/978-981-13-2245-7", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Advances in hardware technology have facilitated more integration of\nsophisticated software toward augmenting the development of Unmanned Vehicles\n(UVs) and mitigating constraints for onboard intelligence. As a result, UVs can\noperate in complex missions where continuous trans-formation in environmental\ncondition calls for a higher level of situational responsiveness and autonomous\ndecision making. This book is a research monograph that aims to provide a\ncomprehensive survey of UVs autonomy and its related properties in internal and\nexternal situation awareness to-ward robust mission planning in severe\nconditions. An advance level of intelligence is essential to minimize the\nreliance on the human supervisor, which is a main concept of autonomy. A\nself-controlled system needs a robust mission management strategy to push the\nboundaries towards autonomous structures, and the UV should be aware of its\ninternal state and capabilities to assess whether current mission goal is\nachievable or find an alternative solution. In this book, the AUVs will become\nthe major case study thread but other cases/types of vehicle will also be\nconsidered. In-deed the research monograph, the review chapters and the new\napproaches we have developed would be appropriate for use as a reference in\nupper years or postgraduate degrees for its coverage of literature and\nalgorithms relating to Robot/Vehicle planning, tasking, routing, and trust.\n", "versions": [{"version": "v1", "created": "Sun, 19 Jul 2020 02:34:48 GMT"}], "update_date": "2020-07-21", "authors_parsed": [["MahmoudZadeh", "Somaiyeh", ""], ["Powers", "David MW", ""], ["Zadeh", "Reza Bairam", ""]]}, {"id": "2007.09569", "submitter": "Yangchen Pan", "authors": "Jincheng Mei, Yangchen Pan, Amir-massoud Farahmand, Hengshuai Yao,\n  Martha White", "title": "Beyond Prioritized Replay: Sampling States in Model-Based Reinforcement\n  Learning via Simulated Priorities", "comments": "The paper is under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The prioritized Experience Replay (ER) method has attracted great attention;\nhowever, there is little theoretical understanding about why it can help and\nits limitations. In this work, we take a deep look at the prioritized ER. In a\nsupervised learning setting, we show the equivalence between the error-based\nprioritized sampling method for mean squared error and uniform sampling for\ncubic power loss. We then provide theoretical insight into why it improves\nconvergence rate upon uniform sampling during early learning. Based on the\ninsight, we further point out two limitations of the prioritized ER method: 1)\noutdated priorities and 2) insufficient coverage of the sample space. To\nmitigate the limitations, we propose our model-based stochastic gradient\nLangevin dynamics sampling method. We show that our method does provide states\ndistributed close to an ideal prioritized sampling distribution estimated by\nthe brute-force method, which does not suffer from the two limitations. We\nconduct experiments on both discrete and continuous control problems to show\nour approach's efficacy and examine the practical implication of our method in\nan autonomous driving application.\n", "versions": [{"version": "v1", "created": "Sun, 19 Jul 2020 03:10:02 GMT"}, {"version": "v2", "created": "Fri, 19 Feb 2021 04:42:40 GMT"}], "update_date": "2021-02-22", "authors_parsed": [["Mei", "Jincheng", ""], ["Pan", "Yangchen", ""], ["Farahmand", "Amir-massoud", ""], ["Yao", "Hengshuai", ""], ["White", "Martha", ""]]}, {"id": "2007.09645", "submitter": "Kennedy Ehimwenma PhD", "authors": "Kennedy E. Ehimwenma and Sujatha Krishnamoorthy", "title": "Design and Analysis of a Multi-Agent E-Learning System Using Prometheus\n  Design Tool", "comments": "17 figures, 3 tables", "journal-ref": "IAES International Journal of Artificial Intelligence (IJ-AI) Vol.\n  10, No. 1, March 2021, pp. 9~23", "doi": "10.11591/ijai.v10.i1.pp9-23", "report-no": null, "categories": "cs.MA cs.AI", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Agent unified modeling languages (AUML) are agent-oriented approaches that\nsupports the specification, design, visualization and documentation of an\nagent-based system. This paper presents the use of Prometheus AUML approach for\nthe modeling of a Pre-assessment System of five interactive agents. The\nPre-assessment System, as previously reported, is a multi-agent based\ne-learning system that is developed to support the assessment of prior learning\nskills in students so as to classify their skills and make recommendation for\ntheir learning. This paper discusses the detailed design approach of the system\nin a step-by-step manner; and domain knowledge abstraction and organization in\nthe system. In addition, the analysis of the data collated and models of\nprediction for future pre-assessment results are also presented.\n", "versions": [{"version": "v1", "created": "Sun, 19 Jul 2020 10:37:52 GMT"}, {"version": "v2", "created": "Thu, 18 Feb 2021 19:57:12 GMT"}, {"version": "v3", "created": "Thu, 25 Feb 2021 01:02:35 GMT"}], "update_date": "2021-02-26", "authors_parsed": [["Ehimwenma", "Kennedy E.", ""], ["Krishnamoorthy", "Sujatha", ""]]}, {"id": "2007.09815", "submitter": "Liang Zhao", "authors": "Liang Zhao", "title": "Event Prediction in the Big Data Era: A Systematic Survey", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Events are occurrences in specific locations, time, and semantics that\nnontrivially impact either our society or the nature, such as civil unrest,\nsystem failures, and epidemics. It is highly desirable to be able to anticipate\nthe occurrence of such events in advance in order to reduce the potential\nsocial upheaval and damage caused. Event prediction, which has traditionally\nbeen prohibitively challenging, is now becoming a viable option in the big data\nera and is thus experiencing rapid growth. There is a large amount of existing\nwork that focuses on addressing the challenges involved, including\nheterogeneous multi-faceted outputs, complex dependencies, and streaming data\nfeeds. Most existing event prediction methods were initially designed to deal\nwith specific application domains, though the techniques and evaluation\nprocedures utilized are usually generalizable across different domains.\nHowever, it is imperative yet difficult to cross-reference the techniques\nacross different domains, given the absence of a comprehensive literature\nsurvey for event prediction. This paper aims to provide a systematic and\ncomprehensive survey of the technologies, applications, and evaluations of\nevent prediction in the big data era. First, systematic categorization and\nsummary of existing techniques are presented, which facilitate domain experts'\nsearches for suitable techniques and help model developers consolidate their\nresearch at the frontiers. Then, comprehensive categorization and summary of\nmajor application domains are provided. Evaluation metrics and procedures are\nsummarized and standardized to unify the understanding of model performance\namong stakeholders, model developers, and domain experts in various application\ndomains. Finally, open problems and future directions for this promising and\nimportant domain are elucidated and discussed.\n", "versions": [{"version": "v1", "created": "Sun, 19 Jul 2020 23:24:52 GMT"}, {"version": "v2", "created": "Tue, 21 Jul 2020 01:39:17 GMT"}, {"version": "v3", "created": "Tue, 4 Aug 2020 23:59:11 GMT"}], "update_date": "2020-08-06", "authors_parsed": [["Zhao", "Liang", ""]]}, {"id": "2007.09820", "submitter": "Marina Dubova", "authors": "Marina Dubova, Arseny Moskvichev, Robert Goldstone", "title": "Reinforcement Communication Learning in Different Social Network\n  Structures", "comments": null, "journal-ref": "1st Workshop on Language in Reinforcement Learning, ICML 2020", "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.LG cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Social network structure is one of the key determinants of human language\nevolution. Previous work has shown that the network of social interactions\nshapes decentralized learning in human groups, leading to the emergence of\ndifferent kinds of communicative conventions. We examined the effects of social\nnetwork organization on the properties of communication systems emerging in\ndecentralized, multi-agent reinforcement learning communities. We found that\nthe global connectivity of a social network drives the convergence of\npopulations on shared and symmetric communication systems, preventing the\nagents from forming many local \"dialects\". Moreover, the agent's degree is\ninversely related to the consistency of its use of communicative conventions.\nThese results show the importance of the basic properties of social network\nstructure on reinforcement communication learning and suggest a new\ninterpretation of findings on human convergence on word conventions.\n", "versions": [{"version": "v1", "created": "Sun, 19 Jul 2020 23:57:30 GMT"}], "update_date": "2020-07-21", "authors_parsed": [["Dubova", "Marina", ""], ["Moskvichev", "Arseny", ""], ["Goldstone", "Robert", ""]]}, {"id": "2007.09964", "submitter": "Daniel Hein", "authors": "Daniel Hein, Steffen Limmer, Thomas A. Runkler", "title": "Interpretable Control by Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO cs.SC cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, three recently introduced reinforcement learning (RL) methods\nare used to generate human-interpretable policies for the cart-pole balancing\nbenchmark. The novel RL methods learn human-interpretable policies in the form\nof compact fuzzy controllers and simple algebraic equations. The\nrepresentations as well as the achieved control performances are compared with\ntwo classical controller design methods and three non-interpretable RL methods.\nAll eight methods utilize the same previously generated data batch and produce\ntheir controller offline - without interaction with the real benchmark\ndynamics. The experiments show that the novel RL methods are able to\nautomatically generate well-performing policies which are at the same time\nhuman-interpretable. Furthermore, one of the methods is applied to\nautomatically learn an equation-based policy for a hardware cart-pole\ndemonstrator by using only human-player-generated batch data. The solution\ngenerated in the first attempt already represents a successful balancing\npolicy, which demonstrates the methods applicability to real-world problems.\n", "versions": [{"version": "v1", "created": "Mon, 20 Jul 2020 09:35:04 GMT"}], "update_date": "2020-07-21", "authors_parsed": [["Hein", "Daniel", ""], ["Limmer", "Steffen", ""], ["Runkler", "Thomas A.", ""]]}, {"id": "2007.09998", "submitter": "Pranay Pasula", "authors": "Pranay Pasula", "title": "Lagrangian Duality in Reinforcement Learning", "comments": "8 pages, 0 figures; fixed typo in abstract", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although duality is used extensively in certain fields, such as supervised\nlearning in machine learning, it has been much less explored in others, such as\nreinforcement learning (RL). In this paper, we show how duality is involved in\na variety of RL work, from that which spearheaded the field, such as Richard\nBellman's value iteration, to that which was done within just the past few\nyears yet has already had significant impact, such as TRPO, A3C, and GAIL. We\nshow that duality is not uncommon in reinforcement learning, especially when\nvalue iteration, or dynamic programming, is used or when first or second order\napproximations are made to transform initially intractable problems into\ntractable convex programs.\n", "versions": [{"version": "v1", "created": "Mon, 20 Jul 2020 10:55:12 GMT"}, {"version": "v2", "created": "Tue, 21 Jul 2020 01:01:50 GMT"}, {"version": "v3", "created": "Sat, 25 Jul 2020 01:17:10 GMT"}], "update_date": "2020-07-28", "authors_parsed": [["Pasula", "Pranay", ""]]}, {"id": "2007.10018", "submitter": "Mohit Kumar", "authors": "Teodora Popordanoska, Mohit Kumar, and Stefano Teso", "title": "Toward Machine-Guided, Human-Initiated Explanatory Interactive Learning", "comments": "Accepted at TAILOR workshop at ECAI 2020, the 24th European\n  Conference on Artificial Intelligence", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work has demonstrated the promise of combining local explanations with\nactive learning for understanding and supervising black-box models. Here we\nshow that, under specific conditions, these algorithms may misrepresent the\nquality of the model being learned. The reason is that the machine illustrates\nits beliefs by predicting and explaining the labels of the query instances: if\nthe machine is unaware of its own mistakes, it may end up choosing queries on\nwhich it performs artificially well. This biases the \"narrative\" presented by\nthe machine to the user.We address this narrative bias by introducing\nexplanatory guided learning, a novel interactive learning strategy in which: i)\nthe supervisor is in charge of choosing the query instances, while ii) the\nmachine uses global explanations to illustrate its overall behavior and to\nguide the supervisor toward choosing challenging, informative instances. This\nstrategy retains the key advantages of explanatory interaction while avoiding\nnarrative bias and compares favorably to active learning in terms of sample\ncomplexity. An initial empirical evaluation with a clustering-based prototype\nhighlights the promise of our approach.\n", "versions": [{"version": "v1", "created": "Mon, 20 Jul 2020 11:51:31 GMT"}], "update_date": "2020-07-21", "authors_parsed": [["Popordanoska", "Teodora", ""], ["Kumar", "Mohit", ""], ["Teso", "Stefano", ""]]}, {"id": "2007.10040", "submitter": "Louis Mahon", "authors": "Louis Mahon, Eleonora Giunchiglia, Bowen Li, Thomas Lukasiewicz", "title": "Knowledge Graph Extraction from Videos", "comments": "10 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nearly all existing techniques for automated video annotation (or captioning)\ndescribe videos using natural language sentences. However, this has several\nshortcomings: (i) it is very hard to then further use the generated natural\nlanguage annotations in automated data processing, (ii) generating natural\nlanguage annotations requires to solve the hard subtask of generating\nsemantically precise and syntactically correct natural language sentences,\nwhich is actually unrelated to the task of video annotation, (iii) it is\ndifficult to quantitatively measure performance, as standard metrics (e.g.,\naccuracy and F1-score) are inapplicable, and (iv) annotations are\nlanguage-specific. In this paper, we propose the new task of knowledge graph\nextraction from videos, i.e., producing a description in the form of a\nknowledge graph of the contents of a given video. Since no datasets exist for\nthis task, we also include a method to automatically generate them, starting\nfrom datasets where videos are annotated with natural language. We then\ndescribe an initial deep-learning model for knowledge graph extraction from\nvideos, and report results on MSVD* and MSR-VTT*, two datasets obtained from\nMSVD and MSR-VTT using our method.\n", "versions": [{"version": "v1", "created": "Mon, 20 Jul 2020 12:23:39 GMT"}], "update_date": "2020-07-21", "authors_parsed": [["Mahon", "Louis", ""], ["Giunchiglia", "Eleonora", ""], ["Li", "Bowen", ""], ["Lukasiewicz", "Thomas", ""]]}, {"id": "2007.10058", "submitter": "Surabhi Nath", "authors": "Surabhi S. Nath, Vishaal Udandarao, Jainendra Shukla", "title": "It's LeVAsa not LevioSA! Latent Encodings for Valence-Arousal Structure\n  Alignment", "comments": "5 pages, 4 figures and 3 tables", "journal-ref": null, "doi": "10.1145/3430984.3431037", "report-no": null, "categories": "cs.AI cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, great strides have been made in the field of affective\ncomputing. Several models have been developed to represent and quantify\nemotions. Two popular ones include (i) categorical models which represent\nemotions as discrete labels, and (ii) dimensional models which represent\nemotions in a Valence-Arousal (VA) circumplex domain. However, there is no\nstandard for annotation mapping between the two labelling methods. We build a\nnovel algorithm for mapping categorical and dimensional model labels using\nannotation transfer across affective facial image datasets. Further, we utilize\nthe transferred annotations to learn rich and interpretable data\nrepresentations using a variational autoencoder (VAE). We present \"LeVAsa\", a\nVAE model that learns implicit structure by aligning the latent space with the\nVA space. We evaluate the efficacy of LeVAsa by comparing performance with the\nVanilla VAE using quantitative and qualitative analysis on two benchmark\naffective image datasets. Our results reveal that LeVAsa achieves high\nlatent-circumplex alignment which leads to improved downstream categorical\nemotion prediction. The work also demonstrates the trade-off between degree of\nalignment and quality of reconstructions.\n", "versions": [{"version": "v1", "created": "Mon, 20 Jul 2020 12:52:26 GMT"}, {"version": "v2", "created": "Tue, 27 Oct 2020 22:40:30 GMT"}, {"version": "v3", "created": "Mon, 30 Nov 2020 18:24:01 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Nath", "Surabhi S.", ""], ["Udandarao", "Vishaal", ""], ["Shukla", "Jainendra", ""]]}, {"id": "2007.10087", "submitter": "Bingqing Yu", "authors": "Jacopo Tagliabue and Bingqing Yu", "title": "Shopping in the Multiverse: A Counterfactual Approach to In-Session\n  Attribution", "comments": "accepted at 2020 SIGIR Workshop On eCommerce", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We tackle the challenge of in-session attribution for on-site search engines\nin eCommerce. We phrase the problem as a causal counterfactual inference, and\ncontrast the approach with rule-based systems from industry settings and\nprediction models from the multi-touch attribution literature. We approach\ncounterfactuals in analogy with treatments in formal semantics, explicitly\nmodeling possible outcomes through alternative shopper timelines; in\nparticular, we propose to learn a generative browsing model over a target shop,\nleveraging the latent space induced by prod2vec embeddings; we show how natural\nlanguage queries can be effectively represented in the same space and how\n\"search intervention\" can be performed to assess causal contribution. Finally,\nwe validate the methodology on a synthetic dataset, mimicking important\npatterns emerged in customer interviews and qualitative analysis, and we\npresent preliminary findings on an industry dataset from a partnering shop.\n", "versions": [{"version": "v1", "created": "Mon, 20 Jul 2020 13:32:02 GMT"}], "update_date": "2020-07-21", "authors_parsed": [["Tagliabue", "Jacopo", ""], ["Yu", "Bingqing", ""]]}, {"id": "2007.10090", "submitter": "Amirhoshang Hoseinpour Dehkordi", "authors": "Amirhoshang Hoseinpour Dehkordi, Majid Alizadeh, Ebrahim\n  Ardeshir-Larijani, Ali Movaghar", "title": "MASKS: A Multi-Classifier's verification approach", "comments": "17 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Classifiers are one of the most widely applied approaches in Artificial\nIntelligence (AI). However, the employment of classifiers in critical\napplications would render any errors in these systems more consequential;\nparticularly due to the lack of formal verification methods in these systems.\nThis study aims to develop a verification method that eliminates errors through\nthe integration of multiple classifiers. In order to do this, primarily, we\nhave defined a special property for the classifiers which extracts the\nknowledge of these classifiers. Secondly, we have designed a multi-agent\nsystem, comprised of multiple classifiers, in order to check the satisfaction\nof the aforementioned special property. Also, in order to help examine the\nreasoning concerning the aggregation of the distributed knowledge, itself\ngained through the combined effort of separate classifiers and acquired\nexternal information sources, a dynamic epistemic logic-based method has been\nproposed. Our proposed model is capable of verifying itself given specific\ninputs if the cumulative knowledge of the entire system proves their\ncorrectness, which results in self-awareness of this system. Finally, we\napplied this model to the MNIST dataset, and it successfully reduced the error\nrate to approximately one-tenth of the individual classifiers. In conclusion,\nwe have formulated and developed a Multi-Agent Systems' Knowledge-Sharing\nalgorithm (MASKS) and verified its utility compared to individual classifiers\nusing the MNIST dataset.\n", "versions": [{"version": "v1", "created": "Fri, 3 Jul 2020 10:47:40 GMT"}, {"version": "v2", "created": "Fri, 11 Dec 2020 11:48:44 GMT"}], "update_date": "2020-12-14", "authors_parsed": [["Dehkordi", "Amirhoshang Hoseinpour", ""], ["Alizadeh", "Majid", ""], ["Ardeshir-Larijani", "Ebrahim", ""], ["Movaghar", "Ali", ""]]}, {"id": "2007.10095", "submitter": "Simona Rombo", "authors": "Mario Randazzo, Simona E. Rombo", "title": "A Big Data Approach for Sequences Indexing on the Cloud via Burrows\n  Wheeler Transform", "comments": "Accepted at HELPLINE@ECAI2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.AI cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Indexing sequence data is important in the context of Precision Medicine,\nwhere large amounts of ``omics'' data have to be daily collected and analyzed\nin order to categorize patients and identify the most effective therapies. Here\nwe propose an algorithm for the computation of Burrows Wheeler transform\nrelying on Big Data technologies, i.e., Apache Spark and Hadoop. Our approach\nis the first that distributes the index computation and not only the input\ndataset, allowing to fully benefit of the available cloud resources.\n", "versions": [{"version": "v1", "created": "Mon, 20 Jul 2020 13:39:57 GMT"}], "update_date": "2020-07-21", "authors_parsed": [["Randazzo", "Mario", ""], ["Rombo", "Simona E.", ""]]}, {"id": "2007.10121", "submitter": "Shiva H C Prasad Prof", "authors": "Dilip U Shenoy, Vinay Sharma, Shiva HC Prasad", "title": "Strategic Evaluation in Optimizing the Internal Supply Chain Using\n  TOPSIS: Evidence In A Coil Winding Machine Manufacturer", "comments": "04 pages, 03 figure, 07 tables", "journal-ref": "Acta Mechanica Malaysia, 4(1) : 01-04 (2020)", "doi": null, "report-no": null, "categories": "cs.AI stat.OT", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Most of the manufacturing firm aims to optimize their Supply Chain in terms\nof improved profitability of its products through value Addition. This study\ntakes a critical look into the factors that affect the Performance of internal\nsupply chain with respect to specific criteria. Accordingly, ranking these\nfactors to get the critical dimensions of supply chain performance in the\nmanufacturing industry. A semi-structured interview with the pre-defined set of\nquestions used to collect the responses from decision makers of the firm. Multi\ncriteria decision-making tool called TOPSIS is used to evaluate the responses\nand rank the factors. The results of this indicate that supplier relationship\nand inventory planning were most principal factors positively influencing\non-time delivery of the product, production flexibility, cost savings,\nadditional costs. This study helps to identify and optimize the process\nparameters using objective and subjective evaluation approach. The combined\ninfluence of the thought process of the manager to optimize the internal supply\nchain is extracted in this work.\n", "versions": [{"version": "v1", "created": "Wed, 8 Jul 2020 12:46:42 GMT"}], "update_date": "2020-07-21", "authors_parsed": [["Shenoy", "Dilip U", ""], ["Sharma", "Vinay", ""], ["Prasad", "Shiva HC", ""]]}, {"id": "2007.10126", "submitter": "Teng Liu", "authors": "Teng Liu, Xiaolin Tang, Xiaosong Hu, Wenhao Tan, Jinwei Zhang", "title": "Human-like Energy Management Based on Deep Reinforcement Learning and\n  Historical Driving Experiences", "comments": "8 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.AI cs.LG cs.SY eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Development of hybrid electric vehicles depends on an advanced and efficient\nenergy management strategy (EMS). With online and real-time requirements in\nmind, this article presents a human-like energy management framework for hybrid\nelectric vehicles according to deep reinforcement learning methods and\ncollected historical driving data. The hybrid powertrain studied has a\nseries-parallel topology, and its control-oriented modeling is founded first.\nThen, the distinctive deep reinforcement learning (DRL) algorithm, named deep\ndeterministic policy gradient (DDPG), is introduced. To enhance the derived\npower split controls in the DRL framework, the global optimal control\ntrajectories obtained from dynamic programming (DP) are regarded as expert\nknowledge to train the DDPG model. This operation guarantees the optimality of\nthe proposed control architecture. Moreover, the collected historical driving\ndata based on experienced drivers are employed to replace the DP-based\ncontrols, and thus construct the human-like EMSs. Finally, different categories\nof experiments are executed to estimate the optimality and adaptability of the\nproposed human-like EMS. Improvements in fuel economy and convergence rate\nindicate the effectiveness of the constructed control structure.\n", "versions": [{"version": "v1", "created": "Thu, 16 Jul 2020 14:15:35 GMT"}], "update_date": "2020-07-21", "authors_parsed": [["Liu", "Teng", ""], ["Tang", "Xiaolin", ""], ["Hu", "Xiaosong", ""], ["Tan", "Wenhao", ""], ["Zhang", "Jinwei", ""]]}, {"id": "2007.10151", "submitter": "Sabah Al-Fedaghi Dr.", "authors": "Sabah Al-Fedaghi", "title": "Conceptual Modeling of Time for Computational Ontologies", "comments": "14 pages, 27 figures", "journal-ref": "IJCSNS International Journal of Computer Science and Network\n  Security, VOL.20 No.6, June 2020", "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To provide a foundation for conceptual modeling, ontologies have been\nintroduced to specify the entities, the existences of which are acknowledged in\nthe model. Ontologies are essential components as mechanisms to model a portion\nof reality in software engineering. In this context, a model refers to a\ndescription of objects and processes that populate a system. Developing such a\ndescription constrains and directs the design, development, and use of the\ncorresponding system, thus avoiding such difficulties as conflicts and lack of\na common understanding. In this cross-area research between modeling and\nontology, there has been a growing interest in the development and use of\ndomain ontologies (e.g., Resource Description Framework, Ontology Web\nLanguage). This paper contributes to the establishment of a broad ontological\nfoundation for conceptual modeling in a specific domain through proposing a\nworkable ontology (abbreviated as TM). A TM is a one-category ontology called a\nthimac (things/machines) that is used to elaborate the design and analysis of\nontological presumptions. The focus of the study is on such notions as change,\nevent, and time. Several current ontological difficulties are reviewed and\nremodeled in the TM. TM modeling is also contrasted with time representation in\nSysML. The results demonstrate that a TM is a useful tool for addressing these\nontological problems.\n", "versions": [{"version": "v1", "created": "Thu, 16 Jul 2020 20:11:18 GMT"}], "update_date": "2020-07-21", "authors_parsed": [["Al-Fedaghi", "Sabah", ""]]}, {"id": "2007.10256", "submitter": "Cedric Schockaert", "authors": "Cedric Schockaert, Vadim Macher, Alexander Schmitz", "title": "VAE-LIME: Deep Generative Model Based Approach for Local Data-Driven\n  Model Interpretability Applied to the Ironmaking Industry", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning applied to generate data-driven models are lacking of\ntransparency leading the process engineer to lose confidence in relying on the\nmodel predictions to optimize his industrial process. Bringing processes in the\nindustry to a certain level of autonomy using data-driven models is\nparticularly challenging as the first user of those models, is the expert in\nthe process with often decades of experience. It is necessary to expose to the\nprocess engineer, not solely the model predictions, but also their\ninterpretability. To that end, several approaches have been proposed in the\nliterature. The Local Interpretable Model-agnostic Explanations (LIME) method\nhas gained a lot of interest from the research community recently. The\nprinciple of this method is to train a linear model that is locally\napproximating the black-box model, by generating randomly artificial data\npoints locally. Model-agnostic local interpretability solutions based on LIME\nhave recently emerged to improve the original method. We present in this paper\na novel approach, VAE-LIME, for local interpretability of data-driven models\nforecasting the temperature of the hot metal produced by a blast furnace. Such\nironmaking process data is characterized by multivariate time series with high\ninter-correlation representing the underlying process in a blast furnace. Our\ncontribution is to use a Variational Autoencoder (VAE) to learn the complex\nblast furnace process characteristics from the data. The VAE is aiming at\ngenerating optimal artificial samples to train a local interpretable model\nbetter representing the black-box model in the neighborhood of the input sample\nprocessed by the black-box model to make a prediction. In comparison with LIME,\nVAE-LIME is showing a significantly improved local fidelity of the local\ninterpretable linear model with the black-box model resulting in robust model\ninterpretability.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jul 2020 07:07:07 GMT"}], "update_date": "2020-07-21", "authors_parsed": [["Schockaert", "Cedric", ""], ["Macher", "Vadim", ""], ["Schmitz", "Alexander", ""]]}, {"id": "2007.10257", "submitter": "Het Shah", "authors": "Ashwin Vaswani and Rijul Ganguly and Het Shah and Sharan Ranjit S and\n  Shrey Pandit and Samruddhi Bothara", "title": "An Autoencoder Based Approach to Simulate Sports Games", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sports data has become widely available in the recent past. With the\nimprovement of machine learning techniques, there have been attempts to use\nsports data to analyze not only the outcome of individual games but also to\nimprove insights and strategies. The outbreak of COVID-19 has interrupted\nsports leagues globally, giving rise to increasing questions and speculations\nabout the outcome of this season's leagues. What if the season was not\ninterrupted and concluded normally? Which teams would end up winning trophies?\nWhich players would perform the best? Which team would end their season on a\nhigh and which teams would fail to keep up with the pressure? We aim to tackle\nthis problem and develop a solution. In this paper, we proposeUCLData, which is\na dataset containing detailed information of UEFA Champions League games played\nover the past six years. We also propose a novel autoencoder based machine\nlearning pipeline that can come up with a story on how the rest of the season\nwill pan out.\n", "versions": [{"version": "v1", "created": "Thu, 16 Jul 2020 16:10:13 GMT"}], "update_date": "2020-07-21", "authors_parsed": [["Vaswani", "Ashwin", ""], ["Ganguly", "Rijul", ""], ["Shah", "Het", ""], ["S", "Sharan Ranjit", ""], ["Pandit", "Shrey", ""], ["Bothara", "Samruddhi", ""]]}, {"id": "2007.10281", "submitter": "Pranay Pasula", "authors": "Pranay Pasula", "title": "Complex Skill Acquisition Through Simple Skill Imitation Learning", "comments": "7 pages, 2 figures; Fixed typos", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Humans often think of complex tasks as combinations of simpler subtasks in\norder to learn those complex tasks more efficiently. For example, a backflip\ncould be considered a combination of four subskills: jumping, tucking knees,\nrolling backwards, and thrusting arms downwards. Motivated by this line of\nreasoning, we propose a new algorithm that trains neural network policies on\nsimple, easy-to-learn skills in order to cultivate latent spaces that\naccelerate imitation learning of complex, hard-to-learn skills. We focus on the\ncase in which the complex task comprises a concurrent (and possibly sequential)\ncombination of the simpler subtasks, and therefore our algorithm can be seen as\na novel approach to concurrent hierarchical imitation learning. We evaluate our\nalgorithm on difficult tasks in a high-dimensional environment and find that it\nconsistently outperforms a state-of-the-art baseline in training speed and\noverall performance.\n", "versions": [{"version": "v1", "created": "Mon, 20 Jul 2020 17:06:26 GMT"}, {"version": "v2", "created": "Sun, 13 Sep 2020 20:27:38 GMT"}, {"version": "v3", "created": "Wed, 14 Oct 2020 17:45:38 GMT"}, {"version": "v4", "created": "Mon, 19 Oct 2020 19:43:49 GMT"}], "update_date": "2020-10-21", "authors_parsed": [["Pasula", "Pranay", ""]]}, {"id": "2007.10287", "submitter": "Chongyan Chen", "authors": "Chongyan Chen, Islam Akef Ebeid, Yi Bu and Ying Ding", "title": "Coronavirus Knowledge Graph: A Case Study", "comments": "8 pages; Accepted by ACM KDD 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The emergence of the novel COVID-19 pandemic has had a significant impact on\nglobal healthcare and the economy over the past few months. The virus's rapid\nwidespread has led to a proliferation in biomedical research addressing the\npandemic and its related topics. One of the essential Knowledge Discovery tools\nthat could help the biomedical research community understand and eventually\nfind a cure for COVID-19 are Knowledge Graphs. The CORD-19 dataset is a\ncollection of publicly available full-text research articles that have been\nrecently published on COVID-19 and coronavirus topics. Here, we use several\nMachine Learning, Deep Learning, and Knowledge Graph construction and mining\ntechniques to formalize and extract insights from the PubMed dataset and the\nCORD-19 dataset to identify COVID-19 related experts and bio-entities. Besides,\nwe suggest possible techniques to predict related diseases, drug candidates,\ngene, gene mutations, and related compounds as part of a systematic effort to\napply Knowledge Discovery methods to help biomedical researchers tackle the\npandemic.\n", "versions": [{"version": "v1", "created": "Sat, 4 Jul 2020 03:55:31 GMT"}], "update_date": "2020-07-21", "authors_parsed": [["Chen", "Chongyan", ""], ["Ebeid", "Islam Akef", ""], ["Bu", "Yi", ""], ["Ding", "Ying", ""]]}, {"id": "2007.10328", "submitter": "Ashish Mani Dr.", "authors": "Arit Kumar Bishwas, Ashish Mani and Vasile Palade", "title": "Parts of Speech Tagging in NLP: Runtime Optimization with Quantum\n  Formulation and ZX Calculus", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes an optimized formulation of the parts of speech tagging\nin Natural Language Processing with a quantum computing approach and further\ndemonstrates the quantum gate-level runnable optimization with ZX-calculus,\nkeeping the implementation target in the context of Noisy Intermediate Scale\nQuantum Systems (NISQ). Our quantum formulation exhibits quadratic speed up\nover the classical counterpart and further demonstrates the implementable\noptimization with the help of ZX calculus postulates.\n", "versions": [{"version": "v1", "created": "Sun, 19 Jul 2020 23:55:35 GMT"}], "update_date": "2020-07-22", "authors_parsed": [["Bishwas", "Arit Kumar", ""], ["Mani", "Ashish", ""], ["Palade", "Vasile", ""]]}, {"id": "2007.10394", "submitter": "Tsuyoshi Okita", "authors": "Tsuyoshi Okita and Hirotaka Hachiya and Sozo Inoue and Naonori Ueda", "title": "Translation Between Waves, wave2wave", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The understanding of sensor data has been greatly improved by advanced deep\nlearning methods with big data. However, available sensor data in the real\nworld are still limited, which is called the opportunistic sensor problem. This\npaper proposes a new variant of neural machine translation seq2seq to deal with\ncontinuous signal waves by introducing the window-based (inverse-)\nrepresentation to adaptively represent partial shapes of waves and the\niterative back-translation model for high-dimensional data. Experimental\nresults are shown for two real-life data: earthquake and activity translation.\nThe performance improvements of one-dimensional data was about 46% in test loss\nand that of high-dimensional data was about 1625% in perplexity with regard to\nthe original seq2seq.\n", "versions": [{"version": "v1", "created": "Mon, 20 Jul 2020 18:29:09 GMT"}], "update_date": "2020-07-22", "authors_parsed": [["Okita", "Tsuyoshi", ""], ["Hachiya", "Hirotaka", ""], ["Inoue", "Sozo", ""], ["Ueda", "Naonori", ""]]}, {"id": "2007.10400", "submitter": "Kuldeep S. Meel", "authors": "Rahul Gupta, Subhajit Roy, Kuldeep S. Meel", "title": "Phase Transition Behavior in Knowledge Compilation", "comments": "This is full version of the conference paper published at\n  International Conference on Principles and Practice of Constraint Programming", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The study of phase transition behaviour in SAT has led to deeper\nunderstanding and algorithmic improvements of modern SAT solvers. Motivated by\nthese prior studies of phase transitions in SAT, we seek to study the behaviour\nof size and compile-time behaviour for random k-CNF formulas in the context of\nknowledge compilation.\n  We perform a rigorous empirical study and analysis of the size and runtime\nbehavior for different knowledge compilation forms (and their corresponding\ncompilation algorithms): d-DNNFs, SDDs and OBDDs across multiple tools and\ncompilation algorithms. We employ instances generated from the random k-CNF\nmodel with varying generation parameters to empirically reason about the\nexpected and median behavior of size and compilation-time for these languages.\nOur work is similar in spirit to the early work in CSP community on phase\ntransition behavior in SAT/CSP. In a similar spirit, we identify the\ninteresting behavior with respect to different parameters: clause density and\nsolution density, a novel control parameter that we identify for the study of\nphase transition behavior in the context of knowledge compilation. Furthermore,\nwe summarize our empirical study in terms of two concrete conjectures; a\nrigorous study of these conjectures will possibly require new theoretical\ntools.\n", "versions": [{"version": "v1", "created": "Mon, 20 Jul 2020 18:36:27 GMT"}], "update_date": "2020-07-22", "authors_parsed": [["Gupta", "Rahul", ""], ["Roy", "Subhajit", ""], ["Meel", "Kuldeep S.", ""]]}, {"id": "2007.10420", "submitter": "Kate Sanders", "authors": "Kate Sanders, Michael Danielczuk, Jeffrey Mahler, Ajay Tanwani, Ken\n  Goldberg", "title": "Non-Markov Policies to Reduce Sequential Failures in Robot Bin Picking", "comments": "2020 IEEE International Conference on Automation Science and\n  Engineering (CASE)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A new generation of automated bin picking systems using deep learning is\nevolving to support increasing demand for e-commerce. To accommodate a wide\nvariety of products, many automated systems include multiple gripper types\nand/or tool changers. However, for some objects, sequential grasp failures are\ncommon: when a computed grasp fails to lift and remove the object, the bin is\noften left unchanged; as the sensor input is consistent, the system retries the\nsame grasp over and over, resulting in a significant reduction in mean\nsuccessful picks per hour (MPPH). Based on an empirical study of sequential\nfailures, we characterize a class of \"sequential failure objects\" (SFOs) --\nobjects prone to sequential failures based on a novel taxonomy. We then propose\nthree non-Markov picking policies that incorporate memory of past failures to\nmodify subsequent actions. Simulation experiments on SFO models and the EGAD\ndataset suggest that the non-Markov policies significantly outperform the\nMarkov policy in terms of the sequential failure rate and MPPH. In physical\nexperiments on 50 heaps of 12 SFOs the most effective Non-Markov policy\nincreased MPPH over the Dex-Net Markov policy by 107%.\n", "versions": [{"version": "v1", "created": "Mon, 20 Jul 2020 19:20:40 GMT"}], "update_date": "2020-07-22", "authors_parsed": [["Sanders", "Kate", ""], ["Danielczuk", "Michael", ""], ["Mahler", "Jeffrey", ""], ["Tanwani", "Ajay", ""], ["Goldberg", "Ken", ""]]}, {"id": "2007.10442", "submitter": "Ryan Zarick", "authors": "Ryan Zarick, Bryan Pellegrino, Noam Brown, Caleb Banister", "title": "Unlocking the Potential of Deep Counterfactual Value Networks", "comments": "11 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep counterfactual value networks combined with continual resolving provide\na way to conduct depth-limited search in imperfect-information games. However,\nsince their introduction in the DeepStack poker AI, deep counterfactual value\nnetworks have not seen widespread adoption. In this paper we introduce several\nimprovements to deep counterfactual value networks, as well as counterfactual\nregret minimization, and analyze the effects of each change. We combined these\nimprovements to create the poker AI Supremus. We show that while a\nreimplementation of DeepStack loses head-to-head against the strong benchmark\nagent Slumbot, Supremus successfully beats Slumbot by an extremely large margin\nand also achieves a lower exploitability than DeepStack against a local best\nresponse. Together, these results show that with our key improvements, deep\ncounterfactual value networks can achieve state-of-the-art performance.\n", "versions": [{"version": "v1", "created": "Mon, 20 Jul 2020 20:10:32 GMT"}], "update_date": "2020-07-22", "authors_parsed": [["Zarick", "Ryan", ""], ["Pellegrino", "Bryan", ""], ["Brown", "Noam", ""], ["Banister", "Caleb", ""]]}, {"id": "2007.10457", "submitter": "Sailik Sengupta", "authors": "Sailik Sengupta, Subbarao Kambhampati", "title": "Multi-agent Reinforcement Learning in Bayesian Stackelberg Markov Games\n  for Adaptive Moving Target Defense", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.AI cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The field of cybersecurity has mostly been a cat-and-mouse game with the\ndiscovery of new attacks leading the way. To take away an attacker's advantage\nof reconnaissance, researchers have proposed proactive defense methods such as\nMoving Target Defense (MTD). To find good movement strategies, researchers have\nmodeled MTD as leader-follower games between the defender and a\ncyber-adversary. We argue that existing models are inadequate in sequential\nsettings when there is incomplete information about a rational adversary and\nyield sub-optimal movement strategies. Further, while there exists an array of\nwork on learning defense policies in sequential settings for cyber-security,\nthey are either unpopular due to scalability issues arising out of incomplete\ninformation or tend to ignore the strategic nature of the adversary simplifying\nthe scenario to use single-agent reinforcement learning techniques. To address\nthese concerns, we propose (1) a unifying game-theoretic model, called the\nBayesian Stackelberg Markov Games (BSMGs), that can model uncertainty over\nattacker types and the nuances of an MTD system and (2) a Bayesian Strong\nStackelberg Q-learning (BSS-Q) approach that can, via interaction, learn the\noptimal movement policy for BSMGs within a reasonable time. We situate BSMGs in\nthe landscape of incomplete-information Markov games and characterize the\nnotion of Strong Stackelberg Equilibrium (SSE) in them. We show that our\nlearning approach converges to an SSE of a BSMG and then highlight that the\nlearned movement policy (1) improves the state-of-the-art in MTD for\nweb-application security and (2) converges to an optimal policy in MTD domains\nwith incomplete information about adversaries even when prior information about\nrewards and transitions is absent.\n", "versions": [{"version": "v1", "created": "Mon, 20 Jul 2020 20:34:53 GMT"}], "update_date": "2020-07-22", "authors_parsed": [["Sengupta", "Sailik", ""], ["Kambhampati", "Subbarao", ""]]}, {"id": "2007.10504", "submitter": "Jonathan Chung", "authors": "Jonathan Chung, Anna Luo, Xavier Raffin, Scott Perry", "title": "Battlesnake Challenge: A Multi-agent Reinforcement Learning Playground\n  with Human-in-the-loop", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present the Battlesnake Challenge, a framework for multi-agent\nreinforcement learning with Human-In-the-Loop Learning (HILL). It is developed\nupon Battlesnake, a multiplayer extension of the traditional Snake game in\nwhich 2 or more snakes compete for the final survival. The Battlesnake\nChallenge consists of an offline module for model training and an online module\nfor live competitions. We develop a simulated game environment for the offline\nmulti-agent model training and identify a set of baseline heuristics that can\nbe instilled to improve learning. Our framework is agent-agnostic and\nheuristics-agnostic such that researchers can design their own algorithms,\ntrain their models, and demonstrate in the online Battlesnake competition. We\nvalidate the framework and baseline heuristics with our preliminary\nexperiments. Our results show that agents with the proposed HILL methods\nconsistently outperform agents without HILL. Besides, heuristics of reward\nmanipulation had the best performance in the online competition. We open source\nour framework at https://github.com/awslabs/sagemaker-battlesnake-ai.\n", "versions": [{"version": "v1", "created": "Mon, 20 Jul 2020 21:59:53 GMT"}], "update_date": "2020-07-22", "authors_parsed": [["Chung", "Jonathan", ""], ["Luo", "Anna", ""], ["Raffin", "Xavier", ""], ["Perry", "Scott", ""]]}, {"id": "2007.10527", "submitter": "Sebastian Musslick", "authors": "Sachin Ravi and Sebastian Musslick and Maia Hamin and Theodore L.\n  Willke and Jonathan D. Cohen", "title": "Navigating the Trade-Off between Multi-Task Learning and Learning to\n  Multitask in Deep Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The terms multi-task learning and multitasking are easily confused.\nMulti-task learning refers to a paradigm in machine learning in which a network\nis trained on various related tasks to facilitate the acquisition of tasks. In\ncontrast, multitasking is used to indicate, especially in the cognitive science\nliterature, the ability to execute multiple tasks simultaneously. While\nmulti-task learning exploits the discovery of common structure between tasks in\nthe form of shared representations, multitasking is promoted by separating\nrepresentations between tasks to avoid processing interference. Here, we build\non previous work involving shallow networks and simple task settings suggesting\nthat there is a trade-off between multi-task learning and multitasking,\nmediated by the use of shared versus separated representations. We show that\nthe same tension arises in deep networks and discuss a meta-learning algorithm\nfor an agent to manage this trade-off in an unfamiliar environment. We display\nthrough different experiments that the agent is able to successfully optimize\nits training strategy as a function of the environment.\n", "versions": [{"version": "v1", "created": "Mon, 20 Jul 2020 23:26:16 GMT"}, {"version": "v2", "created": "Tue, 5 Jan 2021 18:16:35 GMT"}], "update_date": "2021-01-06", "authors_parsed": [["Ravi", "Sachin", ""], ["Musslick", "Sebastian", ""], ["Hamin", "Maia", ""], ["Willke", "Theodore L.", ""], ["Cohen", "Jonathan D.", ""]]}, {"id": "2007.10546", "submitter": "Mayoore Jaiswal", "authors": "Shagun Sodhani, Mayoore S. Jaiswal, Lauren Baker, Koustuv Sinha, Carl\n  Shneider, Peter Henderson, Joel Lehman, Ryan Lowe", "title": "Ideas for Improving the Field of Machine Learning: Summarizing\n  Discussion from the NeurIPS 2019 Retrospectives Workshop", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This report documents ideas for improving the field of machine learning,\nwhich arose from discussions at the ML Retrospectives workshop at NeurIPS 2019.\nThe goal of the report is to disseminate these ideas more broadly, and in turn\nencourage continuing discussion about how the field could improve along these\naxes. We focus on topics that were most discussed at the workshop: incentives\nfor encouraging alternate forms of scholarship, re-structuring the review\nprocess, participation from academia and industry, and how we might better\ntrain computer scientists as scientists. Videos from the workshop can be\naccessed at\nhttps://slideslive.com/neurips/west-114-115-retrospectives-a-venue-for-selfreflection-in-ml-research\n", "versions": [{"version": "v1", "created": "Tue, 21 Jul 2020 01:17:29 GMT"}], "update_date": "2020-07-22", "authors_parsed": [["Sodhani", "Shagun", ""], ["Jaiswal", "Mayoore S.", ""], ["Baker", "Lauren", ""], ["Sinha", "Koustuv", ""], ["Shneider", "Carl", ""], ["Henderson", "Peter", ""], ["Lehman", "Joel", ""], ["Lowe", "Ryan", ""]]}, {"id": "2007.10668", "submitter": "Catarina Moreira", "authors": "Catarina Moreira and Yu-Liang Chou and Mythreyi Velmurugan and Chun\n  Ouyang and Renuka Sindhgatta and Peter Bruza", "title": "An Interpretable Probabilistic Approach for Demystifying Black-box\n  Predictive Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The use of sophisticated machine learning models for critical decision making\nis faced with a challenge that these models are often applied as a \"black-box\".\nThis has led to an increased interest in interpretable machine learning, where\npost hoc interpretation presents a useful mechanism for generating\ninterpretations of complex learning models. In this paper, we propose a novel\napproach underpinned by an extended framework of Bayesian networks for\ngenerating post hoc interpretations of a black-box predictive model. The\nframework supports extracting a Bayesian network as an approximation of the\nblack-box model for a specific prediction. Compared to the existing post hoc\ninterpretation methods, the contribution of our approach is three-fold.\nFirstly, the extracted Bayesian network, as a probabilistic graphical model,\ncan provide interpretations about not only what input features but also why\nthese features contributed to a prediction. Secondly, for complex decision\nproblems with many features, a Markov blanket can be generated from the\nextracted Bayesian network to provide interpretations with a focused view on\nthose input features that directly contributed to a prediction. Thirdly, the\nextracted Bayesian network enables the identification of four different rules\nwhich can inform the decision-maker about the confidence level in a prediction,\nthus helping the decision-maker assess the reliability of predictions learned\nby a black-box model. We implemented the proposed approach, applied it in the\ncontext of two well-known public datasets and analysed the results, which are\nmade available in an open-source repository.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jul 2020 09:04:04 GMT"}], "update_date": "2020-07-22", "authors_parsed": [["Moreira", "Catarina", ""], ["Chou", "Yu-Liang", ""], ["Velmurugan", "Mythreyi", ""], ["Ouyang", "Chun", ""], ["Sindhgatta", "Renuka", ""], ["Bruza", "Peter", ""]]}, {"id": "2007.10675", "submitter": "Jingyi Huang", "authors": "Jingyi Huang, Fabio Giardina and Andre Rosendo", "title": "Bayesian Reinforcement Learning: Real-world learning faster than\n  simulations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Reinforcement Learning (DRL) experiments are commonly performed in\nsimulated environments due to the tremendous training sample demands from deep\nneural networks. In contrast, model-based Bayesian learning allows a robot to\nlearn good policies within a few trials in the real world. Although methods\nsuch as Deep PILCO have been applied on many single-robot tasks, here we\npropose an application of Deep PILCO on finding optimal solutions to the\nproblem of winning a multi-robot combat game. We compare the deep Bayesian\nlearning algorithm with a model-free Deep RL algorithm, Deep Q-Learning, by\nanalyzing the results collected from simulations and real-world experiments. In\nthis game, the RL algorithms' inputs are noisy and unstable due to the filtered\nLiDAR sensory signal. Surprisingly, our experiments show that the\nsample-efficient Deep Bayesian RL performance is better than DRL even when\ncomparing the results of a real-world Deep Bayesian RL to those of a\nsimulation-based Deep Q-Learning. Our results point to the advantage of\nbypassing the reality gap when learning in the real-world with faster learning\nrates than simulations.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jul 2020 09:28:18 GMT"}, {"version": "v2", "created": "Mon, 3 May 2021 09:09:21 GMT"}], "update_date": "2021-05-04", "authors_parsed": [["Huang", "Jingyi", ""], ["Giardina", "Fabio", ""], ["Rosendo", "Andre", ""]]}, {"id": "2007.10735", "submitter": "Fangqi Li", "authors": "Fangqi Li", "title": "The Electromagnetic Balance Game: A Probabilistic Perspective", "comments": "13 pages, 5 figures,", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.AI math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Finding a counterfeit coin with the different weight from a set of visually\nidentical coin using a balance, usually a two-armed balance, known as the\nbalance question, is an intersting and inspiring question. Its variants involve\ndiversified toolkits including information theory, coding theory, optimization,\nprobabilistic theory, combinatorics and a lot of quick wits. In this paper some\nvariants of the balance game are dicussed, especially from a probabilistic\nperspective. Unlike the gravity field setting, we adopt an electromagnetic\nfield, where tighter bounds for some variants of the balance game can be found.\nWe focus on the predetermined setting, where the player has to arrange the\nstrategy without observing the outcome of the balancing. The sufficient\ncondition for the balance to win is obtained by adopting a coding scheme. Apart\nfrom designing a delicate encoding framework, we also propose and analyze the\nperformance of a completely randomized strategy. The optimal behavior of a\nrandomized player is derived. Then we rise the dishonest balance game, in which\nthe balance can adversely cheat the player. We present some elementary results\non the analysis of dishonest balance game using probabilistic method at length.\nIts relationship with Shannon' s coding theorem in a noisy channel is also\nrevealed.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jul 2020 11:49:00 GMT"}, {"version": "v2", "created": "Sun, 26 Jul 2020 14:24:33 GMT"}], "update_date": "2020-07-28", "authors_parsed": [["Li", "Fangqi", ""]]}, {"id": "2007.10781", "submitter": "Alaettin Zubaro\\u{g}lu", "authors": "Alaettin Zubaro\\u{g}lu and Volkan Atalay", "title": "Data Stream Clustering: A Review", "comments": "Has been accepted for publication in Artificial Intelligence Review", "journal-ref": null, "doi": "10.1007/s10462-020-09874-x", "report-no": null, "categories": "cs.LG cs.AI cs.DB stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Number of connected devices is steadily increasing and these devices\ncontinuously generate data streams. Real-time processing of data streams is\narousing interest despite many challenges. Clustering is one of the most\nsuitable methods for real-time data stream processing, because it can be\napplied with less prior information about the data and it does not need labeled\ninstances. However, data stream clustering differs from traditional clustering\nin many aspects and it has several challenging issues. Here, we provide\ninformation regarding the concepts and common characteristics of data streams,\nsuch as concept drift, data structures for data streams, time window models and\noutlier detection. We comprehensively review recent data stream clustering\nalgorithms and analyze them in terms of the base clustering technique,\ncomputational complexity and clustering accuracy. A comparison of these\nalgorithms is given along with still open problems. We indicate popular data\nstream repositories and datasets, stream processing tools and platforms. Open\nproblems about data stream clustering are also discussed.\n", "versions": [{"version": "v1", "created": "Thu, 16 Jul 2020 20:35:09 GMT"}], "update_date": "2020-07-22", "authors_parsed": [["Zubaro\u011flu", "Alaettin", ""], ["Atalay", "Volkan", ""]]}, {"id": "2007.10786", "submitter": "Teng Liu", "authors": "Teng Liu, Bin Tian, Yunfeng Ai, Long Chen, Fei Liu, Dongpu Cao", "title": "Comparison of Different Methods for Time Sequence Prediction in\n  Autonomous Vehicles", "comments": "6 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As a combination of various kinds of technologies, autonomous vehicles could\ncomplete a series of driving tasks by itself, such as perception,\ndecision-making, planning, and control. Since there is no human driver to\nhandle the emergency situation, future transportation information is\nsignificant for automated vehicles. This paper proposes different methods to\nforecast the time series for autonomous vehicles, which are the nearest\nneighborhood (NN), fuzzy coding (FC), and long short term memory (LSTM). First,\nthe formulation and operational process for these three approaches are\nintroduced. Then, the vehicle velocity is regarded as a case study and the\nreal-world dataset is utilized to predict future information via these\ntechniques. Finally, the performance, merits, and drawbacks of the presented\nmethods are analyzed and discussed.\n", "versions": [{"version": "v1", "created": "Thu, 16 Jul 2020 14:32:46 GMT"}], "update_date": "2020-07-22", "authors_parsed": [["Liu", "Teng", ""], ["Tian", "Bin", ""], ["Ai", "Yunfeng", ""], ["Chen", "Long", ""], ["Liu", "Fei", ""], ["Cao", "Dongpu", ""]]}, {"id": "2007.10799", "submitter": "Teng Liu", "authors": "Teng Liu, Xing Yang, Hong Wang, Xiaolin Tang, Long Chen, Huilong Yu,\n  Fei-Yue Wang", "title": "Digital Quadruplets for Cyber-Physical-Social Systems based Parallel\n  Driving: From Concept to Applications", "comments": "6 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Digital quadruplets aiming to improve road safety, traffic efficiency, and\ndriving cooperation for future connected automated vehicles are proposed with\nthe enlightenment of ACP based parallel driving. The ACP method denotes\nArtificial societies, Computational experiments, and Parallel execution modules\nfor cyber-physical-social systems. Four agents are designed in the framework of\ndigital quadruplets: descriptive vehicles, predictive vehicles, prescriptive\nvehicles, and real vehicles. The three virtual vehicles (descriptive,\npredictive, and prescriptive) dynamically interact with the real one in order\nto enhance the safety and performance of the real vehicle. The details of the\nthree virtual vehicles in the digital quadruplets are described. Then, the\ninteractions between the virtual and real vehicles are presented. The\nexperimental results of the digital quadruplets demonstrate the effectiveness\nof the proposed framework.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jul 2020 13:42:54 GMT"}], "update_date": "2020-07-22", "authors_parsed": [["Liu", "Teng", ""], ["Yang", "Xing", ""], ["Wang", "Hong", ""], ["Tang", "Xiaolin", ""], ["Chen", "Long", ""], ["Yu", "Huilong", ""], ["Wang", "Fei-Yue", ""]]}, {"id": "2007.10820", "submitter": "Sahil Dhull", "authors": "Vipul Singhal, Sahil Dhull, Rishabh Agarwal and Ashutosh Modi", "title": "IITK at SemEval-2020 Task 10: Transformers for Emphasis Selection", "comments": "6 pages, 3 figures, 3 tables. Accepted at Proceedings of 14th\n  International Workshop on Semantic Evaluation (SemEval-2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes the system proposed for addressing the research problem\nposed in Task 10 of SemEval-2020: Emphasis Selection For Written Text in Visual\nMedia. We propose an end-to-end model that takes as input the text and\ncorresponding to each word gives the probability of the word to be emphasized.\nOur results show that transformer-based models are particularly effective in\nthis task. We achieved the best Matchm score (described in section 2.2) of\n0.810 and were ranked third on the leaderboard.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jul 2020 14:05:56 GMT"}], "update_date": "2020-07-22", "authors_parsed": [["Singhal", "Vipul", ""], ["Dhull", "Sahil", ""], ["Agarwal", "Rishabh", ""], ["Modi", "Ashutosh", ""]]}, {"id": "2007.10866", "submitter": "Shashank Gupta", "authors": "Anirudh Anil Ojha, Rohin Garg, Shashank Gupta and Ashutosh Modi", "title": "IITK-RSA at SemEval-2020 Task 5: Detecting Counterfactuals", "comments": "10 pages, 1 figure, 4 tables. For associated code, see\n  https://github.com/gargrohin/Counterfactuals-NLP. Accepted at Proceedings of\n  14th International Workshop on Semantic Evaluation (SemEval-2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper describes our efforts in tackling Task 5 of SemEval-2020. The task\ninvolved detecting a class of textual expressions known as counterfactuals and\nseparating them into their constituent elements. Counterfactual statements\ndescribe events that have not or could not have occurred and the possible\nimplications of such events. While counterfactual reasoning is natural for\nhumans, understanding these expressions is difficult for artificial agents due\nto a variety of linguistic subtleties. Our final submitted approaches were an\nensemble of various fine-tuned transformer-based and CNN-based models for the\nfirst subtask and a transformer model with dependency tree information for the\nsecond subtask. We ranked 4-th and 9-th in the overall leaderboard. We also\nexplored various other approaches that involved the use of classical methods,\nother neural architectures and the incorporation of different linguistic\nfeatures.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jul 2020 14:45:53 GMT"}], "update_date": "2020-07-22", "authors_parsed": [["Ojha", "Anirudh Anil", ""], ["Garg", "Rohin", ""], ["Gupta", "Shashank", ""], ["Modi", "Ashutosh", ""]]}, {"id": "2007.11038", "submitter": "Yosvany Medina Carb\\'o", "authors": "Ing. Yosvany Medina Carb\\'o, MSc. Iracely Milagros Santana Ges, Lic.\n  Saily Leo Gonz\\'alez", "title": "Sistema experto para el diagn\\'ostico de enfermedades y plagas en los\n  cultivos del arroz, tabaco, tomate, pimiento, ma\\'iz, pepino y frijol", "comments": "in Spanish", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Agricultural production has become a complex business that requires the\naccumulation and integration of knowledge, in addition to information from many\ndifferent sources. To remain competitive, the modern farmer often relies on\nagricultural specialists and advisors who provide them with information for\ndecision making in their crops. But unfortunately, the help of the agricultural\nspecialist is not always available when the farmer needs it. To alleviate this\nproblem, expert systems have become a powerful instrument that has great\npotential within agriculture. This paper presents an Expert System for the\ndiagnosis of diseases and pests in rice, tobacco, tomato, pepper, corn,\ncucumber and bean crops. For the development of this Expert System, SWI-Prolog\nwas used to create the knowledge base, so it works with predicates and allows\nthe system to be based on production rules. This system allows a fast and\nreliable diagnosis of pests and diseases that affect these crops.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jul 2020 18:39:37 GMT"}], "update_date": "2020-07-23", "authors_parsed": [["Carb\u00f3", "Ing. Yosvany Medina", ""], ["Ges", "MSc. Iracely Milagros Santana", ""], ["Gonz\u00e1lez", "Lic. Saily Leo", ""]]}, {"id": "2007.11073", "submitter": "Muhammad Khalifa", "authors": "Muhammad Khalifa and Aminul Islam", "title": "Will Your Forthcoming Book be Successful? Predicting Book Success with\n  CNN and Readability Scores", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Predicting the potential success of a book in advance is vital in many\napplications. This could help both publishers and readers in their decision\nmaking process whether or not a book is worth publishing and reading,\nrespectively. This prediction could also help authors decide whether a book\ndraft is good enough to send to a publisher. We propose a model that leverages\nConvolutional Neural Networks along with readability indices. Unlike previous\nmethods, our method includes no count-based, lexical, or syntactic hand-crafted\nfeatures. Instead, we make use of a pre-trained sentence encoder to encode the\nbook sentences. We highlight the connection between this task and book genre\nidentification by showing that embeddings that are good at capturing the\nseparability of book genres are better for the book success prediction task. We\nalso show that only the first 1K sentences are good enough to predict the\nsuccessability of books. Our proposed model outperforms strong baselines on\nthis task by as large as 6.4% F1-score.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jul 2020 20:11:18 GMT"}], "update_date": "2020-07-23", "authors_parsed": [["Khalifa", "Muhammad", ""], ["Islam", "Aminul", ""]]}, {"id": "2007.11119", "submitter": "Ziv Epstein", "authors": "Ziv Epstein, Oc\\'eane Boulais, Skylar Gordon, and Matt Groh", "title": "Interpolating GANs to Scaffold Autotelic Creativity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI cs.LG cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The latent space modeled by generative adversarial networks (GANs) represents\na large possibility space. By interpolating categories generated by GANs, it is\npossible to create novel hybrid images. We present \"Meet the Ganimals,\" a\ncasual creator built on interpolations of BigGAN that can generate novel,\nhybrid animals called ganimals by efficiently searching this possibility space.\nLike traditional casual creators, the system supports a simple creative flow\nthat encourages rapid exploration of the possibility space. Users can discover\nnew ganimals, create their own, and share their reactions to aesthetic,\nemotional, and morphological characteristics of the ganimals. As users provide\ninput to the system, the system adapts and changes the distribution of\ncategories upon which ganimals are generated. As one of the first GAN-based\ncasual creators, Meet the Ganimals is an example how casual creators can\nleverage human curation and citizen science to discover novel artifacts within\na large possibility space.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jul 2020 22:29:07 GMT"}], "update_date": "2020-07-23", "authors_parsed": [["Epstein", "Ziv", ""], ["Boulais", "Oc\u00e9ane", ""], ["Gordon", "Skylar", ""], ["Groh", "Matt", ""]]}, {"id": "2007.11121", "submitter": "Ankit Goyal", "authors": "Ankit Goyal and Jia Deng", "title": "PackIt: A Virtual Environment for Geometric Planning", "comments": "Accepted to ICML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ability to jointly understand the geometry of objects and plan actions\nfor manipulating them is crucial for intelligent agents. We refer to this\nability as geometric planning. Recently, many interactive environments have\nbeen proposed to evaluate intelligent agents on various skills, however, none\nof them cater to the needs of geometric planning. We present PackIt, a virtual\nenvironment to evaluate and potentially learn the ability to do geometric\nplanning, where an agent needs to take a sequence of actions to pack a set of\nobjects into a box with limited space. We also construct a set of challenging\npacking tasks using an evolutionary algorithm. Further, we study various\nbaselines for the task that include model-free learning-based and\nheuristic-based methods, as well as search-based optimization methods that\nassume access to the model of the environment. Code and data are available at\nhttps://github.com/princeton-vl/PackIt.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jul 2020 22:51:17 GMT"}], "update_date": "2020-07-23", "authors_parsed": [["Goyal", "Ankit", ""], ["Deng", "Jia", ""]]}, {"id": "2007.11172", "submitter": "Le Cong Dinh", "authors": "Le Cong Dinh and Nick Bishop and Long Tran-Thanh", "title": "Exploiting No-Regret Algorithms in System Design", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate a repeated two-player zero-sum game setting where the column\nplayer is also a designer of the system, and has full control on the design of\nthe payoff matrix. In addition, the row player uses a no-regret algorithm to\nefficiently learn how to adapt their strategy to the column player's behaviour\nover time in order to achieve good total payoff. The goal of the column player\nis to guide her opponent to pick a mixed strategy which is favourable for the\nsystem designer. Therefore, she needs to: (i) design an appropriate payoff\nmatrix $A$ whose unique minimax solution contains the desired mixed strategy of\nthe row player; and (ii) strategically interact with the row player during a\nsequence of plays in order to guide her opponent to converge to that desired\nbehaviour. To design such a payoff matrix, we propose a novel solution that\nprovably has a unique minimax solution with the desired behaviour. We also\ninvestigate a relaxation of this problem where uniqueness is not required, but\nall the minimax solutions have the same mixed strategy for the row player.\nFinally, we propose a new game playing algorithm for the system designer and\nprove that it can guide the row player, who may play a \\emph{stable} no-regret\nalgorithm, to converge to a minimax solution.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jul 2020 02:48:28 GMT"}, {"version": "v2", "created": "Fri, 24 Jul 2020 10:05:25 GMT"}], "update_date": "2020-07-27", "authors_parsed": [["Dinh", "Le Cong", ""], ["Bishop", "Nick", ""], ["Tran-Thanh", "Long", ""]]}, {"id": "2007.11189", "submitter": "Madhura Jayaratne", "authors": "Madhura Jayaratne and Buddhi Jayatilleke", "title": "Predicting Job-Hopping Motive of Candidates Using Answers to Open-ended\n  Interview Questions", "comments": "JCSS version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A significant proportion of voluntary employee turnover includes people who\nfrequently move from job to job, known as job-hopping. Our work shows that\nlanguage used in responding to interview questions on past behaviour and\nsituational judgement is predictive of job-hopping motive as measured by the\nJob-Hopping Motives (JHM) Scale. The study is based on responses from over\n45,000 job applicants who completed an online chat interview and self-rated\nthemselves on JHM Scale. Five different methods of text representation were\nevaluated, namely four open-vocabulary approaches (TF-IDF, LDA, Glove word\nembeddings and Doc2Vec document embeddings) and one closed-vocabulary approach\n(LIWC). The Glove embeddings provided the best results with a correlation of r\n= 0.35 between sequences of words used and the JHM Scale. Further analysis also\nshowed a correlation of r = 0.25 between language-based job-hopping motive and\nthe personality trait Openness to experience and a correlation of r = -0.09\nwith the trait Agreeableness.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jul 2020 03:41:32 GMT"}, {"version": "v2", "created": "Wed, 12 May 2021 04:02:41 GMT"}], "update_date": "2021-05-13", "authors_parsed": [["Jayaratne", "Madhura", ""], ["Jayatilleke", "Buddhi", ""]]}, {"id": "2007.11218", "submitter": "Araz Taeihagh", "authors": "Mikolaj firlej, Araz Taeihagh", "title": "Regulating human control over autonomous systems", "comments": null, "journal-ref": "Regulation and Governance (2020)", "doi": "10.1111/rego.12344", "report-no": null, "categories": "cs.CY cs.AI cs.HC cs.RO cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, many sectors have experienced significant progress in\nautomation, associated with the growing advances in artificial intelligence and\nmachine learning. There are already automated robotic weapons, which are able\nto evaluate and engage with targets on their own, and there are already\nautonomous vehicles that do not need a human driver. It is argued that the use\nof increasingly autonomous systems (AS) should be guided by the policy of human\ncontrol, according to which humans should execute a certain significant level\nof judgment over AS. While in the military sector there is a fear that AS could\nmean that humans lose control over life and death decisions, in the\ntransportation domain, on the contrary, there is a strongly held view that\nautonomy could bring significant operational benefits by removing the need for\na human driver. This article explores the notion of human control in the United\nStates in the two domains of defense and transportation. The operationalization\nof emerging policies of human control results in the typology of direct and\nindirect human controls exercised over the use of AS. The typology helps to\nsteer the debate away from the linguistic complexities of the term autonomy. It\nidentifies instead where human factors are undergoing important changes and\nultimately informs about more detailed rules and standards formulation, which\ndiffer across domains, applications, and sectors.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jul 2020 06:05:41 GMT"}], "update_date": "2020-07-23", "authors_parsed": [["firlej", "Mikolaj", ""], ["Taeihagh", "Araz", ""]]}, {"id": "2007.11338", "submitter": "Simon T. Powers", "authors": "The Anh Han, Cedric Perret and Simon T. Powers", "title": "When to (or not to) trust intelligent machines: Insights from an\n  evolutionary game theory analysis of trust in repeated games", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The actions of intelligent agents, such as chatbots, recommender systems, and\nvirtual assistants are typically not fully transparent to the user.\nConsequently, using such an agent involves the user exposing themselves to the\nrisk that the agent may act in a way opposed to the user's goals. It is often\nargued that people use trust as a cognitive shortcut to reduce the complexity\nof such interactions. Here we formalise this by using the methods of\nevolutionary game theory to study the viability of trust-based strategies in\nrepeated games. These are reciprocal strategies that cooperate as long as the\nother player is observed to be cooperating. Unlike classic reciprocal\nstrategies, once mutual cooperation has been observed for a threshold number of\nrounds they stop checking their co-player's behaviour every round, and instead\nonly check with some probability. By doing so, they reduce the opportunity cost\nof verifying whether the action of their co-player was actually cooperative. We\ndemonstrate that these trust-based strategies can outcompete strategies that\nare always conditional, such as Tit-for-Tat, when the opportunity cost is\nnon-negligible. We argue that this cost is likely to be greater when the\ninteraction is between people and intelligent agents, because of the reduced\ntransparency of the agent. Consequently, we expect people to use trust-based\nstrategies more frequently in interactions with intelligent agents. Our results\nprovide new, important insights into the design of mechanisms for facilitating\ninteractions between humans and intelligent agents, where trust is an essential\nfactor.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jul 2020 10:53:49 GMT"}], "update_date": "2020-07-23", "authors_parsed": [["Han", "The Anh", ""], ["Perret", "Cedric", ""], ["Powers", "Simon T.", ""]]}, {"id": "2007.11461", "submitter": "Wendy Cho", "authors": "Wendy K. Tam Cho and Yan Y. Liu", "title": "A Parallel Evolutionary Multiple-Try Metropolis Markov Chain Monte Carlo\n  Algorithm for Sampling Spatial Partitions", "comments": null, "journal-ref": "Statistics and Computing 31, Article 10 (2021)", "doi": "10.1007/s11222-020-09977-z", "report-no": null, "categories": "stat.CO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop an Evolutionary Markov Chain Monte Carlo (EMCMC) algorithm for\nsampling spatial partitions that lie within a large and complex spatial state\nspace. Our algorithm combines the advantages of evolutionary algorithms (EAs)\nas optimization heuristics for state space traversal and the theoretical\nconvergence properties of Markov Chain Monte Carlo algorithms for sampling from\nunknown distributions. Local optimality information that is identified via a\ndirected search by our optimization heuristic is used to adaptively update a\nMarkov chain in a promising direction within the framework of a Multiple-Try\nMetropolis Markov Chain model that incorporates a generalized\nMetropolis-Hasting ratio. We further expand the reach of our EMCMC algorithm by\nharnessing the computational power afforded by massively parallel architecture\nthrough the integration of a parallel EA framework that guides Markov chains\nrunning in parallel.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jul 2020 14:28:44 GMT"}], "update_date": "2021-01-19", "authors_parsed": [["Cho", "Wendy K. Tam", ""], ["Liu", "Yan Y.", ""]]}, {"id": "2007.11621", "submitter": "Reihaneh Torkzadehmahani", "authors": "Reihaneh Torkzadehmahani, Reza Nasirigerdeh, David B. Blumenthal, Tim\n  Kacprowski, Markus List, Julian Matschinske, Julian Sp\\\"ath, Nina Kerstin\n  Wenke, B\\'ela Bihari, Tobias Frisch, Anne Hartebrodt, Anne-Christin\n  Hausschild, Dominik Heider, Andreas Holzinger, Walter H\\\"otzendorfer, Markus\n  Kastelitz, Rudolf Mayer, Cristian Nogales, Anastasia Pustozerova, Richard\n  R\\\"ottger, Harald H.H.W. Schmidt, Ameli Schwalber, Christof Tschohl, Andrea\n  Wohner, Jan Baumbach", "title": "Privacy-preserving Artificial Intelligence Techniques in Biomedicine", "comments": "17 pages, 3 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Artificial intelligence (AI) has been successfully applied in numerous\nscientific domains. In biomedicine, AI has already shown tremendous potential,\ne.g. in the interpretation of next-generation sequencing data and in the design\nof clinical decision support systems. However, training an AI model on\nsensitive data raises concerns about the privacy of individual participants.\nFor example, summary statistics of a genome-wide association study can be used\nto determine the presence or absence of an individual in a given dataset. This\nconsiderable privacy risk has led to restrictions in accessing genomic and\nother biomedical data, which is detrimental for collaborative research and\nimpedes scientific progress. Hence, there has been a substantial effort to\ndevelop AI methods that can learn from sensitive data while protecting\nindividuals' privacy. This paper provides a structured overview of recent\nadvances in privacy-preserving AI techniques in biomedicine. It places the most\nimportant state-of-the-art approaches within a unified taxonomy and discusses\ntheir strengths, limitations, and open problems. As the most promising\ndirection, we suggest combining federated machine learning as a more scalable\napproach with other additional privacy preserving techniques. This would allow\nto merge the advantages to provide privacy guarantees in a distributed way for\nbiomedical applications. Nonetheless, more research is necessary as hybrid\napproaches pose new challenges such as additional network or computation\noverhead.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jul 2020 18:35:55 GMT"}, {"version": "v2", "created": "Fri, 6 Nov 2020 15:32:38 GMT"}], "update_date": "2020-11-09", "authors_parsed": [["Torkzadehmahani", "Reihaneh", ""], ["Nasirigerdeh", "Reza", ""], ["Blumenthal", "David B.", ""], ["Kacprowski", "Tim", ""], ["List", "Markus", ""], ["Matschinske", "Julian", ""], ["Sp\u00e4th", "Julian", ""], ["Wenke", "Nina Kerstin", ""], ["Bihari", "B\u00e9la", ""], ["Frisch", "Tobias", ""], ["Hartebrodt", "Anne", ""], ["Hausschild", "Anne-Christin", ""], ["Heider", "Dominik", ""], ["Holzinger", "Andreas", ""], ["H\u00f6tzendorfer", "Walter", ""], ["Kastelitz", "Markus", ""], ["Mayer", "Rudolf", ""], ["Nogales", "Cristian", ""], ["Pustozerova", "Anastasia", ""], ["R\u00f6ttger", "Richard", ""], ["Schmidt", "Harald H. H. W.", ""], ["Schwalber", "Ameli", ""], ["Tschohl", "Christof", ""], ["Wohner", "Andrea", ""], ["Baumbach", "Jan", ""]]}, {"id": "2007.11627", "submitter": "Mengxi Li", "authors": "Mengxi Li, Dylan P. Losey, Jeannette Bohg, and Dorsa Sadigh", "title": "Learning User-Preferred Mappings for Intuitive Robot Control", "comments": "8 pages, 7 figures, Proceedings of the IEEE/RSJ International\n  Conference on Intelligent Robots and Systems (IROS), October 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When humans control drones, cars, and robots, we often have some preconceived\nnotion of how our inputs should make the system behave. Existing approaches to\nteleoperation typically assume a one-size-fits-all approach, where the\ndesigners pre-define a mapping between human inputs and robot actions, and\nevery user must adapt to this mapping over repeated interactions. Instead, we\npropose a personalized method for learning the human's preferred or\npreconceived mapping from a few robot queries. Given a robot controller, we\nidentify an alignment model that transforms the human's inputs so that the\ncontroller's output matches their expectations. We make this approach\ndata-efficient by recognizing that human mappings have strong priors: we expect\nthe input space to be proportional, reversable, and consistent. Incorporating\nthese priors ensures that the robot learns an intuitive mapping from few\nexamples. We test our learning approach in robot manipulation tasks inspired by\nassistive settings, where each user has different personal preferences and\nphysical capabilities for teleoperating the robot arm. Our simulated and\nexperimental results suggest that learning the mapping between inputs and robot\nactions improves objective and subjective performance when compared to manually\ndefined alignments or learned alignments without intuitive priors. The\nsupplementary video showing these user studies can be found at:\nhttps://youtu.be/rKHka0_48-Q.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jul 2020 18:54:35 GMT"}], "update_date": "2020-07-24", "authors_parsed": [["Li", "Mengxi", ""], ["Losey", "Dylan P.", ""], ["Bohg", "Jeannette", ""], ["Sadigh", "Dorsa", ""]]}, {"id": "2007.11668", "submitter": "Bo Wu", "authors": "Bo Wu, Haoyu Qin, Alireza Zareian, Carl Vondrick, Shih-Fu Chang", "title": "Analogical Reasoning for Visually Grounded Language Acquisition", "comments": "12 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.CV cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Children acquire language subconsciously by observing the surrounding world\nand listening to descriptions. They can discover the meaning of words even\nwithout explicit language knowledge, and generalize to novel compositions\neffortlessly. In this paper, we bring this ability to AI, by studying the task\nof Visually grounded Language Acquisition (VLA). We propose a multimodal\ntransformer model augmented with a novel mechanism for analogical reasoning,\nwhich approximates novel compositions by learning semantic mapping and\nreasoning operations from previously seen compositions. Our proposed method,\nAnalogical Reasoning Transformer Networks (ARTNet), is trained on raw\nmultimedia data (video frames and transcripts), and after observing a set of\ncompositions such as \"washing apple\" or \"cutting carrot\", it can generalize and\nrecognize new compositions in new video frames, such as \"washing carrot\" or\n\"cutting apple\". To this end, ARTNet refers to relevant instances in the\ntraining data and uses their visual features and captions to establish\nanalogies with the query image. Then it chooses the suitable verb and noun to\ncreate a new composition that describes the new image best. Extensive\nexperiments on an instructional video dataset demonstrate that the proposed\nmethod achieves significantly better generalization capability and recognition\naccuracy compared to state-of-the-art transformer models.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jul 2020 20:51:58 GMT"}], "update_date": "2020-07-24", "authors_parsed": [["Wu", "Bo", ""], ["Qin", "Haoyu", ""], ["Zareian", "Alireza", ""], ["Vondrick", "Carl", ""], ["Chang", "Shih-Fu", ""]]}, {"id": "2007.11735", "submitter": "Xiaochang Li", "authors": "Xiaochang Li, Bei Chen, Xuesong Lu", "title": "Discovering Traveling Companions using Autoencoders", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  With the wide adoption of mobile devices, today's location tracking systems\nsuch as satellites, cellular base stations and wireless access points are\ncontinuously producing tremendous amounts of location data of moving objects.\nThe ability to discover moving objects that travel together, i.e., traveling\ncompanions, from their trajectories is desired by many applications such as\nintelligent transportation systems and location-based services. Existing\nalgorithms are either based on pattern mining methods that define a particular\npattern of traveling companions or based on representation learning methods\nthat learn similar representations for similar trajectories. The former methods\nsuffer from the pairwise point-matching problem and the latter often ignore the\ntemporal proximity between trajectories. In this work, we propose a generic\ndeep representation learning model using autoencoders, namely, ATTN-MEAN, for\nthe discovery of traveling companions. ATTN-MEAN collectively injects spatial\nand temporal information into its input embeddings using skip-gram, positional\nencoding techniques, respectively. Besides, our model further encourages\ntrajectories to learn from their neighbours by leveraging the\nSort-Tile-Recursive algorithm, mean operation and global attention mechanism.\nAfter obtaining the representations from the encoders, we run DBSCAN to cluster\nthe representations to find travelling companion. The corresponding\ntrajectories in the same cluster are considered as traveling companions.\nExperimental results suggest that ATTN-MEAN performs better than the\nstate-of-the-art algorithms on finding traveling companions.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jul 2020 01:16:38 GMT"}], "update_date": "2020-07-24", "authors_parsed": [["Li", "Xiaochang", ""], ["Chen", "Bei", ""], ["Lu", "Xuesong", ""]]}, {"id": "2007.11740", "submitter": "EPTCS", "authors": "Connor Basich (University of Massachusetts Amherst), Justin Svegliato\n  (University of Massachusetts Amherst), Kyle Hollins Wray (Alliance Innovation\n  Lab Silicon Valley), Stefan J. Witwicki (Alliance Innovation Lab Silicon\n  Valley), Shlomo Zilberstein (University of Massachuetts Amherst)", "title": "Improving Competence for Reliable Autonomy", "comments": "In Proceedings AREA 2020, arXiv:2007.11260", "journal-ref": "EPTCS 319, 2020, pp. 37-53", "doi": "10.4204/EPTCS.319.4", "report-no": null, "categories": "cs.AI cs.HC cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given the complexity of real-world, unstructured domains, it is often\nimpossible or impractical to design models that include every feature needed to\nhandle all possible scenarios that an autonomous system may encounter. For an\nautonomous system to be reliable in such domains, it should have the ability to\nimprove its competence online. In this paper, we propose a method for improving\nthe competence of a system over the course of its deployment. We specifically\nfocus on a class of semi-autonomous systems known as competence-aware systems\nthat model their own competence -- the optimal extent of autonomy to use in any\ngiven situation -- and learn this competence over time from feedback received\nthrough interactions with a human authority. Our method exploits such feedback\nto identify important state features missing from the system's initial model,\nand incorporates them into its state representation. The result is an agent\nthat better predicts human involvement, leading to improvements in its\ncompetence and reliability, and as a result, its overall performance.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jul 2020 01:31:28 GMT"}], "update_date": "2020-07-24", "authors_parsed": [["Basich", "Connor", "", "University of Massachusetts Amherst"], ["Svegliato", "Justin", "", "University of Massachusetts Amherst"], ["Wray", "Kyle Hollins", "", "Alliance Innovation\n  Lab Silicon Valley"], ["Witwicki", "Stefan J.", "", "Alliance Innovation Lab Silicon\n  Valley"], ["Zilberstein", "Shlomo", "", "University of Massachuetts Amherst"]]}, {"id": "2007.11741", "submitter": "EPTCS", "authors": "Eleonora Iotti, Giuseppe Petrosino, Stefania Monica, Federico Bergenti", "title": "Exploratory Experiments on Programming Autonomous Robots in Jadescript", "comments": "In Proceedings AREA 2020, arXiv:2007.11260", "journal-ref": "EPTCS 319, 2020, pp. 55-67", "doi": "10.4204/EPTCS.319.5", "report-no": null, "categories": "cs.MA cs.AI cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes exploratory experiments to validate the possibility of\nprogramming autonomous robots using an agent-oriented programming language.\nProper perception of the environment, by means of various types of sensors, and\ntimely reaction to external events, by means of effective actuators, are\nessential to provide robots with a sufficient level of autonomy. The\nagent-oriented programming paradigm is relevant with this respect because it\noffers language-level abstractions to process events and to command actuators.\nA recent agent-oriented programming language called Jadescript is presented in\nthis paper together with its new features specifically designed to handle\nevents. Exploratory experiments on a simple case-study application are\npresented to show the validity of the proposed approach and to exemplify the\nuse of the language to program autonomous robots.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jul 2020 01:31:46 GMT"}], "update_date": "2020-07-24", "authors_parsed": [["Iotti", "Eleonora", ""], ["Petrosino", "Giuseppe", ""], ["Monica", "Stefania", ""], ["Bergenti", "Federico", ""]]}, {"id": "2007.11743", "submitter": "EPTCS", "authors": "Peter Stringer (University of Liverpool), Rafael C. Cardoso\n  (University of Liverpool), Xiaowei Huang (University of Liverpool), Louise A.\n  Dennis (University of Liverpool)", "title": "Adaptable and Verifiable BDI Reasoning", "comments": "In Proceedings AREA 2020, arXiv:2007.11260", "journal-ref": "EPTCS 319, 2020, pp. 117-125", "doi": "10.4204/EPTCS.319.9", "report-no": null, "categories": "cs.MA cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Long-term autonomy requires autonomous systems to adapt as their capabilities\nno longer perform as expected. To achieve this, a system must first be capable\nof detecting such changes. In this position paper, we describe a system\narchitecture for BDI autonomous agents capable of adapting to changes in a\ndynamic environment and outline the required research. Specifically, we\ndescribe an agent-maintained self-model with accompanying theories of durative\nactions and learning new action descriptions in BDI systems.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jul 2020 01:32:53 GMT"}], "update_date": "2020-07-24", "authors_parsed": [["Stringer", "Peter", "", "University of Liverpool"], ["Cardoso", "Rafael C.", "", "University of Liverpool"], ["Huang", "Xiaowei", "", "University of Liverpool"], ["Dennis", "Louise A.", "", "University of Liverpool"]]}, {"id": "2007.11838", "submitter": "Alexander Lew", "authors": "Alexander K. Lew, Monica Agrawal, David Sontag, Vikash K. Mansinghka", "title": "PClean: Bayesian Data Cleaning at Scale with Domain-Specific\n  Probabilistic Programming", "comments": "Correct formatting error", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.CO stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Data cleaning can be naturally framed as probabilistic inference in a\ngenerative model, combining a prior distribution over ground-truth databases\nwith a likelihood that models the noisy channel by which the data are filtered\nand corrupted to yield incomplete, dirty, and denormalized datasets. Based on\nthis view, we present PClean, a probabilistic programming language for\nleveraging dataset-specific knowledge to clean and normalize dirty data. PClean\nis powered by three modeling and inference contributions: (1) a non-parametric\nmodel of relational database instances, customizable via probabilistic\nprograms, (2) a sequential Monte Carlo inference algorithm that exploits the\nmodel's structure, and (3) near-optimal SMC proposals and blocked Gibbs\nrejuvenation moves constructed on a per-dataset basis. We show empirically that\nshort (< 50-line) PClean programs can be faster and more accurate than generic\nPPL inference on multiple data-cleaning benchmarks; perform comparably in terms\nof accuracy and runtime to state-of-the-art data-cleaning systems (unlike\ngeneric PPL inference given the same runtime); and scale to real-world datasets\nwith millions of records.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jul 2020 08:01:47 GMT"}, {"version": "v2", "created": "Fri, 7 Aug 2020 05:19:18 GMT"}, {"version": "v3", "created": "Sun, 25 Oct 2020 21:07:53 GMT"}, {"version": "v4", "created": "Tue, 27 Oct 2020 18:41:52 GMT"}], "update_date": "2020-10-29", "authors_parsed": [["Lew", "Alexander K.", ""], ["Agrawal", "Monica", ""], ["Sontag", "David", ""], ["Mansinghka", "Vikash K.", ""]]}, {"id": "2007.11845", "submitter": "Hamit Basgol", "authors": "Hamit Basgol, Inci Ayhan, Emre Ugur", "title": "Time Perception: A Review on Psychological, Computational and Robotic\n  Models", "comments": "15 pages, 9 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CY cs.NE cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Animals exploit time to survive in the world. Temporal information is\nrequired for higher-level cognitive abilities such as planning, decision\nmaking, communication, and effective cooperation. Since time is an inseparable\npart of cognition, there is a growing interest in the artificial intelligence\napproach to subjective time, which has a possibility of advancing the field.\nThe current survey study aims to provide researchers with an interdisciplinary\nperspective on time perception. Firstly, we introduce a brief background from\nthe psychology and neuroscience literature, covering the characteristics and\nmodels of time perception and related abilities. Secondly, we summarize the\nemergent computational and robotic models of time perception. A general\noverview to the literature reveals that a substantial amount of timing models\nare based on a dedicated time processing like the emergence of a clock-like\nmechanism from the neural network dynamics and reveal a relationship between\nthe embodiment and time perception. We also notice that most models of timing\nare developed for either sensory timing (i.e. ability to assess an interval) or\nmotor timing (i.e. ability to reproduce an interval). The number of timing\nmodels capable of retrospective timing, which is the ability to track time\nwithout paying attention, is insufficient. In this light, we discuss the\npossible research directions to promote interdisciplinary collaboration in the\nfield of time perception.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jul 2020 08:16:47 GMT"}, {"version": "v2", "created": "Sat, 1 Aug 2020 23:30:12 GMT"}, {"version": "v3", "created": "Fri, 25 Dec 2020 08:23:33 GMT"}], "update_date": "2020-12-29", "authors_parsed": [["Basgol", "Hamit", ""], ["Ayhan", "Inci", ""], ["Ugur", "Emre", ""]]}, {"id": "2007.11967", "submitter": "Djallel Bouneffouf", "authors": "Djallel Bouneffouf", "title": "Computing the Dirichlet-Multinomial Log-Likelihood Function", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dirichlet-multinomial (DMN) distribution is commonly used to model\nover-dispersion in count data. Precise and fast numerical computation of the\nDMN log-likelihood function is important for performing statistical inference\nusing this distribution, and remains a challenge. To address this, we use\nmathematical properties of the gamma function to derive a closed form\nexpression for the DMN log-likelihood function. Compared to existing methods,\ncalculation of the closed form has a lower computational complexity, hence is\nmuch faster without comprimising computational accuracy.\n", "versions": [{"version": "v1", "created": "Fri, 17 Jul 2020 20:31:01 GMT"}], "update_date": "2020-07-24", "authors_parsed": [["Bouneffouf", "Djallel", ""]]}, {"id": "2007.11973", "submitter": "Michele Loi Dr.", "authors": "Michele Loi, Eleonora Vigan\\`o, Lonneke van der Plas", "title": "The societal and ethical relevance of computational creativity", "comments": "4 pages, 1 figure, Eleventh International Conference on Computational\n  Creativity, ICCC'20", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI econ.GN q-fin.EC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we provide a philosophical account of the value of creative\nsystems for individuals and society. We characterize creativity in very broad\nphilosophical terms, encompassing natural, existential, and social creative\nprocesses, such as natural evolution and entrepreneurship, and explain why\ncreativity understood in this way is instrumental for advancing human\nwell-being in the long term. We then explain why current mainstream AI tends to\nbe anti-creative, which means that there are moral costs of employing this type\nof AI in human endeavors, although computational systems that involve\ncreativity are on the rise. In conclusion, there is an argument for ethics to\nbe more hospitable to creativity-enabling AI, which can also be in a trade-off\nwith other values promoted in AI ethics, such as its explainability and\naccuracy.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jul 2020 12:39:10 GMT"}], "update_date": "2020-07-24", "authors_parsed": [["Loi", "Michele", ""], ["Vigan\u00f2", "Eleonora", ""], ["van der Plas", "Lonneke", ""]]}, {"id": "2007.12020", "submitter": "Youngsung Kim", "authors": "Youngsung Kim, Jinwoo Shin, Eunho Yang, Sung Ju Hwang", "title": "Few-shot Visual Reasoning with Meta-analogical Contrastive Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While humans can solve a visual puzzle that requires logical reasoning by\nobserving only few samples, it would require training over large amount of data\nfor state-of-the-art deep reasoning models to obtain similar performance on the\nsame task. In this work, we propose to solve such a few-shot (or low-shot)\nvisual reasoning problem, by resorting to analogical reasoning, which is a\nunique human ability to identify structural or relational similarity between\ntwo sets. Specifically, given training and test sets that contain the same type\nof visual reasoning problems, we extract the structural relationships between\nelements in both domains, and enforce them to be as similar as possible with\nanalogical learning. We repeatedly apply this process with slightly modified\nqueries of the same problem under the assumption that it does not affect the\nrelationship between a training and a test sample. This allows to learn the\nrelational similarity between the two samples in an effective manner even with\na single pair of samples. We validate our method on RAVEN dataset, on which it\noutperforms state-of-the-art method, with larger gains when the training data\nis scarce. We further meta-learn our analogical contrastive learning model over\nthe same tasks with diverse attributes, and show that it generalizes to the\nsame visual reasoning problem with unseen attributes.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jul 2020 14:00:34 GMT"}], "update_date": "2020-07-24", "authors_parsed": [["Kim", "Youngsung", ""], ["Shin", "Jinwoo", ""], ["Yang", "Eunho", ""], ["Hwang", "Sung Ju", ""]]}, {"id": "2007.12101", "submitter": "Ameesh Shah", "authors": "Ameesh Shah, Eric Zhan, Jennifer J. Sun, Abhinav Verma, Yisong Yue,\n  Swarat Chaudhuri", "title": "Learning Differentiable Programs with Admissible Neural Heuristics", "comments": "9 pages, published in NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.PL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of learning differentiable functions expressed as\nprograms in a domain-specific language. Such programmatic models can offer\nbenefits such as composability and interpretability; however, learning them\nrequires optimizing over a combinatorial space of program \"architectures\". We\nframe this optimization problem as a search in a weighted graph whose paths\nencode top-down derivations of program syntax. Our key innovation is to view\nvarious classes of neural networks as continuous relaxations over the space of\nprograms, which can then be used to complete any partial program. This relaxed\nprogram is differentiable and can be trained end-to-end, and the resulting\ntraining loss is an approximately admissible heuristic that can guide the\ncombinatorial search. We instantiate our approach on top of the A-star\nalgorithm and an iteratively deepened branch-and-bound search, and use these\nalgorithms to learn programmatic classifiers in three sequence classification\ntasks. Our experiments show that the algorithms outperform state-of-the-art\nmethods for program learning, and that they discover programmatic classifiers\nthat yield natural interpretations and achieve competitive accuracy.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jul 2020 16:07:39 GMT"}, {"version": "v2", "created": "Sun, 26 Jul 2020 03:41:24 GMT"}, {"version": "v3", "created": "Sat, 26 Sep 2020 00:24:44 GMT"}, {"version": "v4", "created": "Tue, 1 Dec 2020 02:11:06 GMT"}, {"version": "v5", "created": "Sun, 28 Mar 2021 01:15:33 GMT"}], "update_date": "2021-03-30", "authors_parsed": [["Shah", "Ameesh", ""], ["Zhan", "Eric", ""], ["Sun", "Jennifer J.", ""], ["Verma", "Abhinav", ""], ["Yue", "Yisong", ""], ["Chaudhuri", "Swarat", ""]]}, {"id": "2007.12173", "submitter": "Unnat Jain", "authors": "Luca Weihs, Unnat Jain, Jordi Salvador, Svetlana Lazebnik, Aniruddha\n  Kembhavi, Alexander Schwing", "title": "Bridging the Imitation Gap by Adaptive Insubordination", "comments": "The first two authors contributed equally. Project page:\n  https://unnat.github.io/advisor/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When expert supervision is available, practitioners often use imitation\nlearning with varying degrees of success. We show that when an expert has\naccess to privileged information that is unavailable to the student, this\ninformation is marginalized in the student policy during imitation learning\nresulting in an \"imitation gap\" and, potentially, poor results. Prior work\nbridges this gap via a progression from imitation learning to reinforcement\nlearning. While often successful, gradual progression fails for tasks that\nrequire frequent switches between exploration and memorization skills. To\nbetter address these tasks and alleviate the imitation gap we propose 'Adaptive\nInsubordination' (ADVISOR), which dynamically weights imitation and\nreward-based reinforcement learning losses during training, enabling switching\nbetween imitation and exploration. On a suite of challenging didactic and\nMiniGrid tasks, we show that ADVISOR outperforms pure imitation, pure\nreinforcement learning, as well as their sequential and parallel combinations.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jul 2020 17:59:57 GMT"}, {"version": "v2", "created": "Fri, 23 Oct 2020 21:48:30 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Weihs", "Luca", ""], ["Jain", "Unnat", ""], ["Salvador", "Jordi", ""], ["Lazebnik", "Svetlana", ""], ["Kembhavi", "Aniruddha", ""], ["Schwing", "Alexander", ""]]}, {"id": "2007.12248", "submitter": "Eric Chu", "authors": "Eric Chu, Deb Roy, Jacob Andreas", "title": "Are Visual Explanations Useful? A Case Study in Model-in-the-Loop\n  Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.HC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a randomized controlled trial for a model-in-the-loop regression\ntask, with the goal of measuring the extent to which (1) good explanations of\nmodel predictions increase human accuracy, and (2) faulty explanations decrease\nhuman trust in the model. We study explanations based on visual saliency in an\nimage-based age prediction task for which humans and learned models are\nindividually capable but not highly proficient and frequently disagree. Our\nexperimental design separates model quality from explanation quality, and makes\nit possible to compare treatments involving a variety of explanations of\nvarying levels of quality. We find that presenting model predictions improves\nhuman accuracy. However, visual explanations of various kinds fail to\nsignificantly alter human accuracy or trust in the model - regardless of\nwhether explanations characterize an accurate model, an inaccurate one, or are\ngenerated randomly and independently of the input image. These findings suggest\nthe need for greater evaluation of explanations in downstream decision making\ntasks, better design-based tools for presenting explanations to users, and\nbetter approaches for generating explanations.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jul 2020 20:39:40 GMT"}], "update_date": "2020-07-27", "authors_parsed": [["Chu", "Eric", ""], ["Roy", "Deb", ""], ["Andreas", "Jacob", ""]]}, {"id": "2007.12306", "submitter": "Jianyu Su", "authors": "Jianyu Su, Stephen Adams, Peter A. Beling", "title": "Value-Decomposition Multi-Agent Actor-Critics", "comments": "Accepted by 35th AAAI Conference on Artificial Intelligence (AAAI\n  2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The exploitation of extra state information has been an active research area\nin multi-agent reinforcement learning (MARL). QMIX represents the joint\naction-value using a non-negative function approximator and achieves the best\nperformance, by far, on multi-agent benchmarks, StarCraft II micromanagement\ntasks. However, our experiments show that, in some cases, QMIX is incompatible\nwith A2C, a training paradigm that promotes algorithm training efficiency. To\nobtain a reasonable trade-off between training efficiency and algorithm\nperformance, we extend value-decomposition to actor-critics that are compatible\nwith A2C and propose a novel actor-critic framework, value-decomposition\nactor-critics (VDACs). We evaluate VDACs on the testbed of StarCraft II\nmicromanagement tasks and demonstrate that the proposed framework improves\nmedian performance over other actor-critic methods. Furthermore, we use a set\nof ablation experiments to identify the key factors that contribute to the\nperformance of VDACs.\n", "versions": [{"version": "v1", "created": "Fri, 24 Jul 2020 00:50:02 GMT"}, {"version": "v2", "created": "Sat, 1 Aug 2020 17:15:25 GMT"}, {"version": "v3", "created": "Tue, 8 Dec 2020 03:57:03 GMT"}, {"version": "v4", "created": "Fri, 18 Dec 2020 15:16:06 GMT"}], "update_date": "2020-12-21", "authors_parsed": [["Su", "Jianyu", ""], ["Adams", "Stephen", ""], ["Beling", "Peter A.", ""]]}, {"id": "2007.12312", "submitter": "Ashlesha Nesarikar", "authors": "Ashlesha Nesarikar (University of Texas at Dallas and Plano\n  Intelligence), Waqas Haque (UT Southwestern), Suchith Vuppala (UT\n  Southwestern), Abhijit Nesarikar (Plano Intelligence)", "title": "COVID-19 Remote Patient Monitoring: Social Impact of AI", "comments": "21 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A primary indicator of success in the fight against COVID-19 is avoiding\nstress on critical care infrastructure and services (CCIS). However, CCIS will\nlikely remain stressed until sustained herd immunity is built. There are also\nsecondary considerations for success: mitigating economic damage; curbing the\nspread of misinformation, improving morale, and preserving a sense of control;\nbuilding global trust for diplomacy, trade and travel; and restoring\nreliability and normalcy to day-to-day life, among others. We envision\ntechnology plays a pivotal role. Here, we focus on the effective use of readily\navailable technology to improve the primary and secondary success criteria for\nthe fight against SARS-CoV-2. In a multifaceted technology approach, we start\nwith effective technology use for remote patient monitoring (RPM) of COVID-19\nwith the following objectives:\n  1. Deploy readily available technology for continuous real-time remote\nmonitoring of patient vitals with the help of biosensors on a large scale.\n  2. Effective and safe remote large-scale communitywide care of low-severity\ncases as a buffer against surges in COVID-19 hospitalizations to reduce strain\non critical care services and emergency hospitals.\n  3. Improve the patient, their family, and their community's sense of control\nand morale.\n  4. Propose a clear technology and medical definition of remote patient\nmonitoring for COVID-19 to address an urgent technology need; address\nobfuscated, narrow, and erroneous information and provide examples; and urge\npublishers to be clear and complete in their disclosures.\n  5. Leverage the cloud-based distributed cognitive RPM platform for community\nleaders and decision makers to enable planning and resource management,\npandemic research, damage prevention and containment, and receiving feedback on\nstrategies and executions.\n", "versions": [{"version": "v1", "created": "Fri, 24 Jul 2020 01:09:56 GMT"}], "update_date": "2020-07-27", "authors_parsed": [["Nesarikar", "Ashlesha", "", "University of Texas at Dallas and Plano\n  Intelligence"], ["Haque", "Waqas", "", "UT Southwestern"], ["Vuppala", "Suchith", "", "UT\n  Southwestern"], ["Nesarikar", "Abhijit", "", "Plano Intelligence"]]}, {"id": "2007.12324", "submitter": "Aritra Ghosh", "authors": "Aritra Ghosh, Neil Heffernan and Andrew S. Lan", "title": "Context-Aware Attentive Knowledge Tracing", "comments": "Published in KDD 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Knowledge tracing (KT) refers to the problem of predicting future learner\nperformance given their past performance in educational applications. Recent\ndevelopments in KT using flexible deep neural network-based models excel at\nthis task. However, these models often offer limited interpretability, thus\nmaking them insufficient for personalized learning, which requires using\ninterpretable feedback and actionable recommendations to help learners achieve\nbetter learning outcomes. In this paper, we propose attentive knowledge tracing\n(AKT), which couples flexible attention-based neural network models with a\nseries of novel, interpretable model components inspired by cognitive and\npsychometric models. AKT uses a novel monotonic attention mechanism that\nrelates a learner's future responses to assessment questions to their past\nresponses; attention weights are computed using exponential decay and a\ncontext-aware relative distance measure, in addition to the similarity between\nquestions. Moreover, we use the Rasch model to regularize the concept and\nquestion embeddings; these embeddings are able to capture individual\ndifferences among questions on the same concept without using an excessive\nnumber of parameters. We conduct experiments on several real-world benchmark\ndatasets and show that AKT outperforms existing KT methods (by up to $6\\%$ in\nAUC in some cases) on predicting future learner responses. We also conduct\nseveral case studies and show that AKT exhibits excellent interpretability and\nthus has potential for automated feedback and personalization in real-world\neducational settings.\n", "versions": [{"version": "v1", "created": "Fri, 24 Jul 2020 02:45:43 GMT"}], "update_date": "2020-07-27", "authors_parsed": [["Ghosh", "Aritra", ""], ["Heffernan", "Neil", ""], ["Lan", "Andrew S.", ""]]}, {"id": "2007.12354", "submitter": "Thanh Nguyen Tang", "authors": "Thanh Tang Nguyen, Sunil Gupta, Svetha Venkatesh", "title": "Distributional Reinforcement Learning via Moment Matching", "comments": "To appear in AAAI'21; code available at\n  https://github.com/thanhnguyentang/mmdrl", "journal-ref": "AAAI 2021", "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of learning a set of probability distributions from\nthe empirical Bellman dynamics in distributional reinforcement learning (RL), a\nclass of state-of-the-art methods that estimate the distribution, as opposed to\nonly the expectation, of the total return. We formulate a method that learns a\nfinite set of statistics from each return distribution via neural networks, as\nin (Bellemare, Dabney, and Munos 2017; Dabney et al. 2018b). Existing\ndistributional RL methods however constrain the learned statistics to\n\\emph{predefined} functional forms of the return distribution which is both\nrestrictive in representation and difficult in maintaining the predefined\nstatistics. Instead, we learn \\emph{unrestricted} statistics, i.e.,\ndeterministic (pseudo-)samples, of the return distribution by leveraging a\ntechnique from hypothesis testing known as maximum mean discrepancy (MMD),\nwhich leads to a simpler objective amenable to backpropagation. Our method can\nbe interpreted as implicitly matching all orders of moments between a return\ndistribution and its Bellman target. We establish sufficient conditions for the\ncontraction of the distributional Bellman operator and provide finite-sample\nanalysis for the deterministic samples in distribution approximation.\nExperiments on the suite of Atari games show that our method outperforms the\nstandard distributional RL baselines and sets a new record in the Atari games\nfor non-distributed agents.\n", "versions": [{"version": "v1", "created": "Fri, 24 Jul 2020 05:18:17 GMT"}, {"version": "v2", "created": "Sat, 5 Dec 2020 06:43:28 GMT"}, {"version": "v3", "created": "Wed, 9 Dec 2020 00:38:36 GMT"}], "update_date": "2020-12-10", "authors_parsed": [["Nguyen", "Thanh Tang", ""], ["Gupta", "Sunil", ""], ["Venkatesh", "Svetha", ""]]}, {"id": "2007.12358", "submitter": "Sina Mohseni", "authors": "Sina Mohseni, Fan Yang, Shiva Pentyala, Mengnan Du, Yi Liu, Nic\n  Lupfer, Xia Hu, Shuiwang Ji, Eric Ragan", "title": "Machine Learning Explanations to Prevent Overtrust in Fake News\n  Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Combating fake news and misinformation propagation is a challenging task in\nthe post-truth era. News feed and search algorithms could potentially lead to\nunintentional large-scale propagation of false and fabricated information with\nusers being exposed to algorithmically selected false content. Our research\ninvestigates the effects of an Explainable AI assistant embedded in news review\nplatforms for combating the propagation of fake news. We design a news\nreviewing and sharing interface, create a dataset of news stories, and train\nfour interpretable fake news detection algorithms to study the effects of\nalgorithmic transparency on end-users. We present evaluation results and\nanalysis from multiple controlled crowdsourced studies. For a deeper\nunderstanding of Explainable AI systems, we discuss interactions between user\nengagement, mental model, trust, and performance measures in the process of\nexplaining. The study results indicate that explanations helped participants to\nbuild appropriate mental models of the intelligent assistants in different\nconditions and adjust their trust accordingly for model limitations.\n", "versions": [{"version": "v1", "created": "Fri, 24 Jul 2020 05:42:29 GMT"}, {"version": "v2", "created": "Mon, 27 Jul 2020 03:59:56 GMT"}], "update_date": "2020-07-28", "authors_parsed": [["Mohseni", "Sina", ""], ["Yang", "Fan", ""], ["Pentyala", "Shiva", ""], ["Du", "Mengnan", ""], ["Liu", "Yi", ""], ["Lupfer", "Nic", ""], ["Hu", "Xia", ""], ["Ji", "Shuiwang", ""], ["Ragan", "Eric", ""]]}, {"id": "2007.12374", "submitter": "Siddhant Arora", "authors": "Siddhant Arora", "title": "A Survey on Graph Neural Networks for Knowledge Graph Completion", "comments": "10 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge Graphs are increasingly becoming popular for a variety of\ndownstream tasks like Question Answering and Information Retrieval. However,\nthe Knowledge Graphs are often incomplete, thus leading to poor performance. As\na result, there has been a lot of interest in the task of Knowledge Base\nCompletion. More recently, Graph Neural Networks have been used to capture\nstructural information inherently stored in these Knowledge Graphs and have\nbeen shown to achieve SOTA performance across a variety of datasets. In this\nsurvey, we understand the various strengths and weaknesses of the proposed\nmethodology and try to find new exciting research problems in this area that\nrequire further investigation.\n", "versions": [{"version": "v1", "created": "Fri, 24 Jul 2020 06:46:46 GMT"}], "update_date": "2020-07-27", "authors_parsed": [["Arora", "Siddhant", ""]]}, {"id": "2007.12375", "submitter": "Mei Wang", "authors": "Mei Wang, Jianwen Su, Haiqin Lu", "title": "Impact of Medical Data Imprecision on Learning Results", "comments": "2020 KDD Workshop on Applied Data Science for Healthcare", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Test data measured by medical instruments often carry imprecise ranges that\ninclude the true values. The latter are not obtainable in virtually all cases.\nMost learning algorithms, however, carry out arithmetical calculations that are\nsubject to uncertain influence in both the learning process to obtain models\nand applications of the learned models in, e.g. prediction. In this paper, we\ninitiate a study on the impact of imprecision on prediction results in a\nhealthcare application where a pre-trained model is used to predict future\nstate of hyperthyroidism for patients. We formulate a model for data\nimprecisions. Using parameters to control the degree of imprecision, imprecise\nsamples for comparison experiments can be generated using this model. Further,\na group of measures are defined to evaluate the different impacts\nquantitatively. More specifically, the statistics to measure the inconsistent\nprediction for individual patients are defined. We perform experimental\nevaluations to compare prediction results based on the data from the original\ndataset and the corresponding ones generated from the proposed precision model\nusing the long-short-term memories (LSTM) network. The results against a real\nworld hyperthyroidism dataset provide insights into how small imprecisions can\ncause large ranges of predicted results, which could cause mis-labeling and\ninappropriate actions (treatments or no treatments) for individual patients.\n", "versions": [{"version": "v1", "created": "Fri, 24 Jul 2020 06:54:57 GMT"}], "update_date": "2020-07-27", "authors_parsed": [["Wang", "Mei", ""], ["Su", "Jianwen", ""], ["Lu", "Haiqin", ""]]}, {"id": "2007.12391", "submitter": "Nantheera Anantrasirichai", "authors": "Nantheera Anantrasirichai and David Bull", "title": "Artificial Intelligence in the Creative Industries: A Review", "comments": null, "journal-ref": "Artif Intell Rev (2021) 1-68", "doi": "10.1007/s10462-021-10039-7", "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  This paper reviews the current state of the art in Artificial Intelligence\n(AI) technologies and applications in the context of the creative industries. A\nbrief background of AI, and specifically Machine Learning (ML) algorithms, is\nprovided including Convolutional Neural Network (CNNs), Generative Adversarial\nNetworks (GANs), Recurrent Neural Networks (RNNs) and Deep Reinforcement\nLearning (DRL). We categorise creative applications into five groups related to\nhow AI technologies are used: i) content creation, ii) information analysis,\niii) content enhancement and post production workflows, iv) information\nextraction and enhancement, and v) data compression. We critically examine the\nsuccesses and limitations of this rapidly advancing technology in each of these\nareas. We further differentiate between the use of AI as a creative tool and\nits potential as a creator in its own right. We foresee that, in the near\nfuture, machine learning-based AI will be adopted widely as a tool or\ncollaborative assistant for creativity. In contrast, we observe that the\nsuccesses of machine learning in domains with fewer constraints, where AI is\nthe `creator', remain modest. The potential of AI (or its developers) to win\nawards for its original creations in competition with human creatives is also\nlimited, based on contemporary technologies. We therefore conclude that, in the\ncontext of creative industries, maximum benefit from AI will be derived where\nits focus is human centric -- where it is designed to augment, rather than\nreplace, human creativity.\n", "versions": [{"version": "v1", "created": "Fri, 24 Jul 2020 07:29:52 GMT"}, {"version": "v2", "created": "Fri, 31 Jul 2020 17:04:03 GMT"}, {"version": "v3", "created": "Fri, 18 Sep 2020 20:30:14 GMT"}, {"version": "v4", "created": "Tue, 2 Mar 2021 16:03:20 GMT"}, {"version": "v5", "created": "Sat, 19 Jun 2021 20:30:57 GMT"}, {"version": "v6", "created": "Fri, 2 Jul 2021 11:35:08 GMT"}], "update_date": "2021-07-05", "authors_parsed": [["Anantrasirichai", "Nantheera", ""], ["Bull", "David", ""]]}, {"id": "2007.12397", "submitter": "Takayuki Osa", "authors": "Takayuki Osa", "title": "Learning the Solution Manifold in Optimization and Its Application in\n  Motion Planning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Optimization is an essential component for solving problems in wide-ranging\nfields. Ideally, the objective function should be designed such that the\nsolution is unique and the optimization problem can be solved stably. However,\nthe objective function used in a practical application is usually non-convex,\nand sometimes it even has an infinite set of solutions. To address this issue,\nwe propose to learn the solution manifold in optimization. We train a model\nconditioned on the latent variable such that the model represents an infinite\nset of solutions. In our framework, we reduce this problem to density\nestimation by using importance sampling, and the latent representation of the\nsolutions is learned by maximizing the variational lower bound. We apply the\nproposed algorithm to motion-planning problems, which involve the optimization\nof high-dimensional parameters. The experimental results indicate that the\nsolution manifold can be learned with the proposed algorithm, and the trained\nmodel represents an infinite set of homotopic solutions for motion-planning\nproblems.\n", "versions": [{"version": "v1", "created": "Fri, 24 Jul 2020 08:05:36 GMT"}], "update_date": "2020-07-27", "authors_parsed": [["Osa", "Takayuki", ""]]}, {"id": "2007.12401", "submitter": "Kuang-Huei Lee", "authors": "Kuang-Huei Lee, Ian Fischer, Anthony Liu, Yijie Guo, Honglak Lee, John\n  Canny, Sergio Guadarrama", "title": "Predictive Information Accelerates Learning in RL", "comments": "To appear at NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.IT cs.RO math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Predictive Information is the mutual information between the past and the\nfuture, I(X_past; X_future). We hypothesize that capturing the predictive\ninformation is useful in RL, since the ability to model what will happen next\nis necessary for success on many tasks. To test our hypothesis, we train Soft\nActor-Critic (SAC) agents from pixels with an auxiliary task that learns a\ncompressed representation of the predictive information of the RL environment\ndynamics using a contrastive version of the Conditional Entropy Bottleneck\n(CEB) objective. We refer to these as Predictive Information SAC (PI-SAC)\nagents. We show that PI-SAC agents can substantially improve sample efficiency\nover challenging baselines on tasks from the DM Control suite of continuous\ncontrol environments. We evaluate PI-SAC agents by comparing against\nuncompressed PI-SAC agents, other compressed and uncompressed agents, and SAC\nagents directly trained from pixels. Our implementation is given on GitHub.\n", "versions": [{"version": "v1", "created": "Fri, 24 Jul 2020 08:14:41 GMT"}, {"version": "v2", "created": "Mon, 26 Oct 2020 00:27:00 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Lee", "Kuang-Huei", ""], ["Fischer", "Ian", ""], ["Liu", "Anthony", ""], ["Guo", "Yijie", ""], ["Lee", "Honglak", ""], ["Canny", "John", ""], ["Guadarrama", "Sergio", ""]]}, {"id": "2007.12412", "submitter": "Wojciech Jamroga", "authors": "Wojciech Jamroga, Yan Kim, Damian Kurpiewski, Peter Y. A. Ryan", "title": "Model Checkers Are Cool: How to Model Check Voting Protocols in Uppaal", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.LO cs.MA", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  The design and implementation of an e-voting system is a challenging task.\nFormal analysis can be of great help here. In particular, it can lead to a\nbetter understanding of how the voting system works, and what requirements on\nthe system are relevant. In this paper, we propose that the state-of-art model\nchecker Uppaal provides a good environment for modelling and preliminary\nverification of voting protocols. To illustrate this, we present an Uppaal\nmodel of Pr\\^et \\`a Voter, together with some natural extensions. We also show\nhow to verify a variant of receipt-freeness, despite the severe limitations of\nthe property specification language in the model checker.\n", "versions": [{"version": "v1", "created": "Fri, 24 Jul 2020 09:05:06 GMT"}, {"version": "v2", "created": "Sun, 24 Jan 2021 11:28:35 GMT"}], "update_date": "2021-01-26", "authors_parsed": [["Jamroga", "Wojciech", ""], ["Kim", "Yan", ""], ["Kurpiewski", "Damian", ""], ["Ryan", "Peter Y. A.", ""]]}, {"id": "2007.12447", "submitter": "Zolt\\'an Kov\\'acs", "authors": "Zolt\\'an Kov\\'acs and Jonathan H. Yu", "title": "Towards Automated Discovery of Geometrical Theorems in GeoGebra", "comments": "21 pages, 19 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI math.HO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe a prototype of a new experimental GeoGebra command and tool\nDiscover that analyzes geometric figures for salient patterns, properties, and\ntheorems. This tool is a basic implementation of automated discovery in\nelementary planar geometry. The paper focuses on the mathematical background of\nthe implementation, as well as methods to avoid combinatorial explosion when\nstoring the interesting properties of a geometric figure.\n", "versions": [{"version": "v1", "created": "Fri, 24 Jul 2020 10:59:39 GMT"}], "update_date": "2020-07-27", "authors_parsed": [["Kov\u00e1cs", "Zolt\u00e1n", ""], ["Yu", "Jonathan H.", ""]]}, {"id": "2007.12474", "submitter": "Ryuta Arisaka", "authors": "Ryuta Arisaka and Takayuki Ito", "title": "Abstract Interpretation in Formal Argumentation: with a Galois\n  Connection for Abstract Dialectical Frameworks and May-Must Argumentation\n  (First Report)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Labelling-based formal argumentation relies on labelling functions that\ntypically assign one of 3 labels to indicate either acceptance, rejection, or\nelse undecided-to-be-either, to each argument. While a classical\nlabelling-based approach applies globally uniform conditions as to how an\nargument is to be labelled, they can be determined more locally per argument.\nAbstract dialectical frameworks (ADF) is a well-known argumentation formalism\nthat belongs to this category, offering a greater labelling flexibility. As the\nsize of an argumentation increases in the numbers of arguments and\nargument-to-argument relations, however, it becomes increasingly more costly to\ncheck whether a labelling function satisfies those local conditions or even\nwhether the conditions are as per the intention of those who had specified\nthem. Some compromise is thus required for reasoning about a larger\nargumentation. In this context, there is a more recently proposed formalism of\nmay-must argumentation (MMA) that enforces still local but more abstract\nlabelling conditions. We identify how they link to each other in this work. We\nprove that there is a Galois connection between them, in which ADF is a\nconcretisation of MMA and MMA is an abstraction of ADF. We explore the\nconsequence of abstract interpretation at play in formal argumentation,\ndemonstrating a sound reasoning about the judgement of\nacceptability/rejectability in ADF from within MMA. As far as we are aware,\nthere is seldom any work that incorporates abstract interpretation into formal\nargumentation in the literature, and, in the stated context, this work is the\nfirst to demonstrate its use and relevance.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jul 2020 04:26:15 GMT"}], "update_date": "2020-07-27", "authors_parsed": [["Arisaka", "Ryuta", ""], ["Ito", "Takayuki", ""]]}, {"id": "2007.12488", "submitter": "Ioana Manolescu", "authors": "Oana Balalau (CEDAR), Catarina Concei\\c{c}{\\~a}o (INESC-ID, IST),\n  Helena Galhardas (INESC-ID, IST), Ioana Manolescu (CEDAR), Tayeb Merabti\n  (CEDAR), Jingmao You (CEDAR, IP Paris), Youssr Youssef (CEDAR, ENSAE, IP\n  Paris)", "title": "Graph integration of structured, semistructured and unstructured data\n  for data journalism", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nowadays, journalism is facilitated by the existence of large amounts of\ndigital data sources, including many Open Data ones. Such data sources are\nextremely heterogeneous, ranging from highly struc-tured (relational\ndatabases), semi-structured (JSON, XML, HTML), graphs (e.g., RDF), and text.\nJournalists (and other classes of users lacking advanced IT expertise, such as\nmost non-governmental-organizations, or small public administrations) need to\nbe able to make sense of such heterogeneous corpora, even if they lack the\nability to de ne and deploy custom extract-transform-load work ows. These are\ndi cult to set up not only for arbitrary heterogeneous inputs , but also given\nthat users may want to add (or remove) datasets to (from) the corpus. We\ndescribe a complete approach for integrating dynamic sets of heterogeneous data\nsources along the lines described above: the challenges we faced to make such\ngraphs useful, allow their integration to scale, and the solutions we proposed\nfor these problems. Our approach is implemented within the ConnectionLens\nsystem; we validate it through a set of experiments.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jul 2020 08:55:09 GMT"}, {"version": "v2", "created": "Fri, 30 Oct 2020 08:07:09 GMT"}], "update_date": "2020-11-02", "authors_parsed": [["Balalau", "Oana", "", "CEDAR"], ["Concei\u00e7{\u00e3}o", "Catarina", "", "INESC-ID, IST"], ["Galhardas", "Helena", "", "INESC-ID, IST"], ["Manolescu", "Ioana", "", "CEDAR"], ["Merabti", "Tayeb", "", "CEDAR"], ["You", "Jingmao", "", "CEDAR, IP Paris"], ["Youssef", "Youssr", "", "CEDAR, ENSAE, IP\n  Paris"]]}, {"id": "2007.12500", "submitter": "EPTCS", "authors": "Sim\\'on C. Smith (The University of Edinburgh), Subramanian\n  Ramamoorthy (The University of Edinburgh)", "title": "Semi-supervised Learning From Demonstration Through Program Synthesis:\n  An Inspection Robot Case Study", "comments": "In Proceedings AREA 2020, arXiv:2007.11260", "journal-ref": "EPTCS 319, 2020, pp. 81-101", "doi": "10.4204/EPTCS.319.7", "report-no": null, "categories": "cs.RO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Semi-supervised learning improves the performance of supervised machine\nlearning by leveraging methods from unsupervised learning to extract\ninformation not explicitly available in the labels. Through the design of a\nsystem that enables a robot to learn inspection strategies from a human\noperator, we present a hybrid semi-supervised system capable of learning\ninterpretable and verifiable models from demonstrations. The system induces a\ncontroller program by learning from immersive demonstrations using sequential\nimportance sampling. These visual servo controllers are parametrised by\nproportional gains and are visually verifiable through observation of the\nposition of the robot in the environment. Clustering and effective particle\nsize filtering allows the system to discover goals in the state space. These\ngoals are used to label the original demonstration for end-to-end learning of\nbehavioural models. The behavioural models are used for autonomous model\npredictive control and scrutinised for explanations. We implement causal\nsensitivity analysis to identify salient objects and generate counterfactual\nconditional explanations. These features enable decision making interpretation\nand post hoc discovery of the causes of a failure. The proposed system expands\non previous approaches to program synthesis by incorporating repellers in the\nattribution prior of the sampling process. We successfully learn the hybrid\nsystem from an inspection scenario where an unmanned ground vehicle has to\ninspect, in a specific order, different areas of the environment. The system\ninduces an interpretable computer program of the demonstration that can be\nsynthesised to produce novel inspection behaviours. Importantly, the robot\nsuccessfully runs the synthesised program on an unseen configuration of the\nenvironment while presenting explanations of its autonomous behaviour.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jul 2020 01:32:21 GMT"}], "update_date": "2020-07-27", "authors_parsed": [["Smith", "Sim\u00f3n C.", "", "The University of Edinburgh"], ["Ramamoorthy", "Subramanian", "", "The University of Edinburgh"]]}, {"id": "2007.12582", "submitter": "Wouter Verbeke", "authors": "Wouter Verbeke, Diego Olaya, Jeroen Berrevoets, Sam Verboven,\n  Sebasti\\'an Maldonado", "title": "The foundations of cost-sensitive causal classification", "comments": "New version: overall language edit - switch in notation (class 0:\n  negatives, class 1: positive) - typos corrected - proofs moved to appendix", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Classification is a well-studied machine learning task which concerns the\nassignment of instances to a set of outcomes. Classification models support the\noptimization of managerial decision-making across a variety of operational\nbusiness processes. For instance, customer churn prediction models are adopted\nto increase the efficiency of retention campaigns by optimizing the selection\nof customers that are to be targeted. Cost-sensitive and causal classification\nmethods have independently been proposed to improve the performance of\nclassification models. The former considers the benefits and costs of correct\nand incorrect classifications, such as the benefit of a retained customer,\nwhereas the latter estimates the causal effect of an action, such as a\nretention campaign, on the outcome of interest. This study integrates\ncost-sensitive and causal classification by elaborating a unifying evaluation\nframework. The framework encompasses a range of existing and novel performance\nmeasures for evaluating both causal and conventional classification models in a\ncost-sensitive as well as a cost-insensitive manner. We proof that conventional\nclassification is a specific case of causal classification in terms of a range\nof performance measures when the number of actions is equal to one. The\nframework is shown to instantiate to application-specific cost-sensitive\nperformance measures that have been recently proposed for evaluating customer\nretention and response uplift models, and allows to maximize profitability when\nadopting a causal classification model for optimizing decision-making. The\nproposed framework paves the way toward the development of cost-sensitive\ncausal learning methods and opens a range of opportunities for improving\ndata-driven business decision-making.\n", "versions": [{"version": "v1", "created": "Fri, 24 Jul 2020 15:33:48 GMT"}, {"version": "v2", "created": "Thu, 30 Jul 2020 10:47:01 GMT"}, {"version": "v3", "created": "Wed, 19 Aug 2020 10:01:09 GMT"}, {"version": "v4", "created": "Wed, 27 Jan 2021 09:16:56 GMT"}, {"version": "v5", "created": "Tue, 20 Apr 2021 06:50:43 GMT"}], "update_date": "2021-04-21", "authors_parsed": [["Verbeke", "Wouter", ""], ["Olaya", "Diego", ""], ["Berrevoets", "Jeroen", ""], ["Verboven", "Sam", ""], ["Maldonado", "Sebasti\u00e1n", ""]]}, {"id": "2007.12586", "submitter": "Nicolas A. Barriga", "authors": "Ignacio Gajardo, Felipe Besoain, and Nicolas A. Barriga", "title": "Introduction to Behavior Algorithms for Fighting Games", "comments": "in Spanish", "journal-ref": null, "doi": "10.1109/CHILECON47746.2019.8988008", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The quality of opponent Artificial Intelligence (AI) in fighting videogames\nis crucial. Some other game genres can rely on their story or visuals, but\nfighting games are all about the adversarial experience. In this paper, we will\nintroduce standard behavior algorithms in videogames, such as Finite-State\nMachines and Behavior Trees, as well as more recent developments, such as\nMonte-Carlo Tree Search. We will also discuss the existing and potential\ncombinations of these algorithms, and how they might be used in fighting games.\nSince we are at the financial peak of fighting games, both for casual players\nand in tournaments, it is important to build and expand on fighting game AI, as\nit is one of the pillars of this growing market.\n", "versions": [{"version": "v1", "created": "Mon, 6 Jul 2020 14:52:20 GMT"}], "update_date": "2020-07-27", "authors_parsed": [["Gajardo", "Ignacio", ""], ["Besoain", "Felipe", ""], ["Barriga", "Nicolas A.", ""]]}, {"id": "2007.12631", "submitter": "Michael Kane", "authors": "Michael J. Kane and Simon Urbanek", "title": "On the Programmatic Generation of Reproducible Documents", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL cs.AI stat.OT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reproducible document standards, like R Markdown, facilitate the programmatic\ncreation of documents whose content is itself programmatically generated. While\nthese documents are generally not complete in the sense that they will not\ninclude prose content, generated by an author to provide context, a narrative,\netc., programmatic generation can provide substantial efficiencies for\nstructuring and constructing documents. This paper explores the programmatic\ngeneration of reproducible by distinguishing components than can be created by\ncomputational means from those requiring human-generated prose, providing\nguidelines for the generation of these documents, and identifying a use case in\nclinical trial reporting. These concepts and use case are illustrated through\nthe listdown package for the R programming environment, which is is currently\navailable on the Comprehensive R Archive Network (CRAN).\n", "versions": [{"version": "v1", "created": "Tue, 23 Jun 2020 22:32:58 GMT"}], "update_date": "2020-07-27", "authors_parsed": [["Kane", "Michael J.", ""], ["Urbanek", "Simon", ""]]}, {"id": "2007.12652", "submitter": "Emir Demirovi\\'c", "authors": "Emir Demirovi\\'c, Anna Lukina, Emmanuel Hebrard, Jeffrey Chan, James\n  Bailey, Christopher Leckie, Kotagiri Ramamohanarao, Peter J. Stuckey", "title": "MurTree: Optimal Classification Trees via Dynamic Programming and Search", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Decision tree learning is a widely used approach in machine learning,\nfavoured in applications that require concise and interpretable models.\nHeuristic methods are traditionally used to quickly produce models with\nreasonably high accuracy. A commonly criticised point, however, is that the\nresulting trees may not necessarily be the best representation of the data in\nterms of accuracy and size. In recent years, this motivated the development of\noptimal classification tree algorithms that globally optimise the decision tree\nin contrast to heuristic methods that perform a sequence of locally optimal\ndecisions. We follow this line of work and provide a novel algorithm for\nlearning optimal classification trees based on dynamic programming and search.\nOur algorithm supports constraints on the depth of the tree and number of\nnodes. The success of our approach is attributed to a series of specialised\ntechniques that exploit properties unique to classification trees. Whereas\nalgorithms for optimal classification trees have traditionally been plagued by\nhigh runtimes and limited scalability, we show in a detailed experimental study\nthat our approach uses only a fraction of the time required by the\nstate-of-the-art and can handle datasets with tens of thousands of instances,\nproviding several orders of magnitude improvements and notably contributing\ntowards the practical realisation of optimal decision trees.\n", "versions": [{"version": "v1", "created": "Fri, 24 Jul 2020 17:06:55 GMT"}, {"version": "v2", "created": "Sun, 9 May 2021 16:46:36 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Demirovi\u0107", "Emir", ""], ["Lukina", "Anna", ""], ["Hebrard", "Emmanuel", ""], ["Chan", "Jeffrey", ""], ["Bailey", "James", ""], ["Leckie", "Christopher", ""], ["Ramamohanarao", "Kotagiri", ""], ["Stuckey", "Peter J.", ""]]}, {"id": "2007.12678", "submitter": "Shengpu Tang", "authors": "Shengpu Tang, Aditya Modi, Michael W. Sjoding, Jenna Wiens", "title": "Clinician-in-the-Loop Decision Making: Reinforcement Learning with\n  Near-Optimal Set-Valued Policies", "comments": "ICML 2020. Code available at\n  https://github.com/shengpu1126/RL-Set-Valued-Policy", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Standard reinforcement learning (RL) aims to find an optimal policy that\nidentifies the best action for each state. However, in healthcare settings,\nmany actions may be near-equivalent with respect to the reward (e.g.,\nsurvival). We consider an alternative objective -- learning set-valued policies\nto capture near-equivalent actions that lead to similar cumulative rewards. We\npropose a model-free algorithm based on temporal difference learning and a\nnear-greedy heuristic for action selection. We analyze the theoretical\nproperties of the proposed algorithm, providing optimality guarantees and\ndemonstrate our approach on simulated environments and a real clinical task.\nEmpirically, the proposed algorithm exhibits good convergence properties and\ndiscovers meaningful near-equivalent actions. Our work provides theoretical, as\nwell as practical, foundations for clinician/human-in-the-loop decision making,\nin which humans (e.g., clinicians, patients) can incorporate additional\nknowledge (e.g., side effects, patient preference) when selecting among\nnear-equivalent actions.\n", "versions": [{"version": "v1", "created": "Fri, 24 Jul 2020 17:50:58 GMT"}], "update_date": "2020-07-27", "authors_parsed": [["Tang", "Shengpu", ""], ["Modi", "Aditya", ""], ["Sjoding", "Michael W.", ""], ["Wiens", "Jenna", ""]]}, {"id": "2007.12681", "submitter": "Longbing Cao", "authors": "Longbing Cao, Qiang Yang and Philip S. Yu", "title": "Data science and AI in FinTech: An overview", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.GN cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Financial technology (FinTech) has been playing an increasingly critical role\nin driving modern economies, society, technology, and many other areas. Smart\nFinTech is the new-generation FinTech, largely inspired and empowered by data\nscience and new-generation AI and (DSAI) techniques. Smart FinTech synthesizes\nbroad DSAI and transforms finance and economies to drive intelligent,\nautomated, whole-of-business and personalized economic and financial\nbusinesses, services and systems. The research on data science and AI in\nFinTech involves many latest progress made in smart FinTech for BankingTech,\nTradeTech, LendTech, InsurTech, WealthTech, PayTech, RiskTech,\ncryptocurrencies, and blockchain, and the DSAI techniques including complex\nsystem methods, quantitative methods, intelligent interactions, recognition and\nresponses, data analytics, deep learning, federated learning,\nprivacy-preserving processing, augmentation, optimization, and system\nintelligence enhancement. Here, we present a highly dense research overview of\nsmart financial businesses and their challenges, the smart FinTech ecosystem,\nthe DSAI techniques to enable smart FinTech, and some research directions of\nsmart FinTech futures to the DSAI communities.\n", "versions": [{"version": "v1", "created": "Fri, 10 Jul 2020 01:10:37 GMT"}, {"version": "v2", "created": "Tue, 20 Jul 2021 08:28:58 GMT"}], "update_date": "2021-07-21", "authors_parsed": [["Cao", "Longbing", ""], ["Yang", "Qiang", ""], ["Yu", "Philip S.", ""]]}, {"id": "2007.12717", "submitter": "Ghassan Samara", "authors": "Ghassan Samara", "title": "Intelligent Reputation System for Safety Messages in VANET", "comments": "9 pages", "journal-ref": "IAES International Journal of Artificial Intelligence (IJ-AI) Vol.\n  9, No. 3, September 2020, pp. 439~447, ISSN: 2252-8938, DOI:\n  10.11591/ijai.v9.i3.pp439-447", "doi": "10.11591/ijai.v9.i3.pp439-447", "report-no": null, "categories": "cs.NI cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Nowadays, Vehicle Ad - hoc Nets (VANET) applications have become very\nimportant in our lives because VANET provides drivers with safety messages,\nwarnings, and instructions to ensure drivers have a safe and enjoyable journey.\nVANET Security is one of the hottest topics in computer networks research,\nFalsifying VANET system information violates VANET safety objectives and may\nlead to hazardous situations and loss of life. In this paper, an Intelligent\nReputation System (IRS) aims to identify attacking vehicles will be proposed;\nthe proposed system will rely on opinion generation, trust value collection,\ntraffic analysis, position based, data collection, and intelligent decision\nmaking by utilizing the multi-parameter Greedy Best First algorithm. The\nresults of this research will enhance VANET's safety level and will facilitate\nthe identification of misbehaving vehicles and their messages. The results of\nthe proposed system have also proven to be superior to other reputational\nsystems.\n", "versions": [{"version": "v1", "created": "Fri, 12 Jun 2020 10:11:44 GMT"}], "update_date": "2020-07-28", "authors_parsed": [["Samara", "Ghassan", ""]]}, {"id": "2007.12720", "submitter": "Xiaoxue Zang", "authors": "Xiaoxue Zang, Abhinav Rastogi, Srinivas Sunkara, Raghav Gupta, Jianguo\n  Zhang, Jindong Chen", "title": "MultiWOZ 2.2 : A Dialogue Dataset with Additional Annotation Corrections\n  and State Tracking Baselines", "comments": null, "journal-ref": "Proceedings of the 2nd Workshop on Natural Language Processing for\n  Conversational AI (2020) 109-117", "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  MultiWOZ is a well-known task-oriented dialogue dataset containing over\n10,000 annotated dialogues spanning 8 domains. It is extensively used as a\nbenchmark for dialogue state tracking. However, recent works have reported\npresence of substantial noise in the dialogue state annotations. MultiWOZ 2.1\nidentified and fixed many of these erroneous annotations and user utterances,\nresulting in an improved version of this dataset. This work introduces MultiWOZ\n2.2, which is a yet another improved version of this dataset. Firstly, we\nidentify and fix dialogue state annotation errors across 17.3% of the\nutterances on top of MultiWOZ 2.1. Secondly, we redefine the ontology by\ndisallowing vocabularies of slots with a large number of possible values (e.g.,\nrestaurant name, time of booking). In addition, we introduce slot span\nannotations for these slots to standardize them across recent models, which\npreviously used custom string matching heuristics to generate them. We also\nbenchmark a few state of the art dialogue state tracking models on the\ncorrected dataset to facilitate comparison for future work. In the end, we\ndiscuss best practices for dialogue data collection that can help avoid\nannotation errors.\n", "versions": [{"version": "v1", "created": "Fri, 10 Jul 2020 22:52:14 GMT"}], "update_date": "2020-07-28", "authors_parsed": [["Zang", "Xiaoxue", ""], ["Rastogi", "Abhinav", ""], ["Sunkara", "Srinivas", ""], ["Gupta", "Raghav", ""], ["Zhang", "Jianguo", ""], ["Chen", "Jindong", ""]]}, {"id": "2007.12731", "submitter": "Colby Wise", "authors": "Colby Wise, Vassilis N. Ioannidis, Miguel Romero Calvo, Xiang Song,\n  George Price, Ninad Kulkarni, Ryan Brand, Parminder Bhatia, George Karypis", "title": "COVID-19 Knowledge Graph: Accelerating Information Retrieval and\n  Discovery for Scientific Literature", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The coronavirus disease (COVID-19) has claimed the lives of over 350,000\npeople and infected more than 6 million people worldwide. Several search\nengines have surfaced to provide researchers with additional tools to find and\nretrieve information from the rapidly growing corpora on COVID-19. These\nengines lack extraction and visualization tools necessary to retrieve and\ninterpret complex relations inherent to scientific literature. Moreover,\nbecause these engines mainly rely upon semantic information, their ability to\ncapture complex global relationships across documents is limited, which reduces\nthe quality of similarity-based article recommendations for users. In this\nwork, we present the COVID-19 Knowledge Graph (CKG), a heterogeneous graph for\nextracting and visualizing complex relationships between COVID-19 scientific\narticles. The CKG combines semantic information with document topological\ninformation for the application of similar document retrieval. The CKG is\nconstructed using the latent schema of the data, and then enriched with\nbiomedical entity information extracted from the unstructured text of articles\nusing scalable AWS technologies to form relations in the graph. Finally, we\npropose a document similarity engine that leverages low-dimensional graph\nembeddings from the CKG with semantic embeddings for similar article retrieval.\nAnalysis demonstrates the quality of relationships in the CKG and shows that it\ncan be used to uncover meaningful information in COVID-19 scientific articles.\nThe CKG helps power www.cord19.aws and is publicly available.\n", "versions": [{"version": "v1", "created": "Fri, 24 Jul 2020 18:29:43 GMT"}], "update_date": "2020-07-28", "authors_parsed": [["Wise", "Colby", ""], ["Ioannidis", "Vassilis N.", ""], ["Calvo", "Miguel Romero", ""], ["Song", "Xiang", ""], ["Price", "George", ""], ["Kulkarni", "Ninad", ""], ["Brand", "Ryan", ""], ["Bhatia", "Parminder", ""], ["Karypis", "George", ""]]}, {"id": "2007.12750", "submitter": "Jiasen Lu", "authors": "Michael Cogswell, Jiasen Lu, Rishabh Jain, Stefan Lee, Devi Parikh,\n  Dhruv Batra", "title": "Dialog without Dialog Data: Learning Visual Dialog Agents from VQA Data", "comments": "19 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Can we develop visually grounded dialog agents that can efficiently adapt to\nnew tasks without forgetting how to talk to people? Such agents could leverage\na larger variety of existing data to generalize to new tasks, minimizing\nexpensive data collection and annotation. In this work, we study a setting we\ncall \"Dialog without Dialog\", which requires agents to develop visually\ngrounded dialog models that can adapt to new tasks without language level\nsupervision. By factorizing intention and language, our model minimizes\nlinguistic drift after fine-tuning for new tasks. We present qualitative\nresults, automated metrics, and human studies that all show our model can adapt\nto new tasks and maintain language quality. Baselines either fail to perform\nwell at new tasks or experience language drift, becoming unintelligible to\nhumans. Code has been made available at\nhttps://github.com/mcogswell/dialog_without_dialog\n", "versions": [{"version": "v1", "created": "Fri, 24 Jul 2020 19:35:57 GMT"}], "update_date": "2020-07-28", "authors_parsed": [["Cogswell", "Michael", ""], ["Lu", "Jiasen", ""], ["Jain", "Rishabh", ""], ["Lee", "Stefan", ""], ["Parikh", "Devi", ""], ["Batra", "Dhruv", ""]]}, {"id": "2007.12770", "submitter": "David Yu-Tung Hui", "authors": "David Yu-Tung Hui, Maxime Chevalier-Boisvert, Dzmitry Bahdanau, Yoshua\n  Bengio", "title": "BabyAI 1.1", "comments": "9 pages, 1 figure, technical report", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The BabyAI platform is designed to measure the sample efficiency of training\nan agent to follow grounded-language instructions. BabyAI 1.0 presents baseline\nresults of an agent trained by deep imitation or reinforcement learning. BabyAI\n1.1 improves the agent's architecture in three minor ways. This increases\nreinforcement learning sample efficiency by up to 3 times and improves\nimitation learning performance on the hardest level from 77 % to 90.4 %. We\nhope that these improvements increase the computational efficiency of BabyAI\nexperiments and help users design better agents.\n", "versions": [{"version": "v1", "created": "Fri, 24 Jul 2020 21:19:49 GMT"}], "update_date": "2020-07-28", "authors_parsed": [["Hui", "David Yu-Tung", ""], ["Chevalier-Boisvert", "Maxime", ""], ["Bahdanau", "Dzmitry", ""], ["Bengio", "Yoshua", ""]]}, {"id": "2007.12780", "submitter": "Prithwish Chakraborty", "authors": "Parthasarathy Suryanarayanan, Bhavani Iyer, Prithwish Chakraborty,\n  Bibo Hao, Italo Buleje, Piyush Madan, James Codella, Antonio Foncubierta,\n  Divya Pathak, Sarah Miller, Amol Rajmane, Shannon Harrer, Gigi Yuan-Reed,\n  Daby Sow", "title": "A Canonical Architecture For Predictive Analytics on Longitudinal\n  Patient Records", "comments": "Presented at DSHealth 2020 KDD Workshop on Applied Data Science for\n  Healthcare", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many institutions within the healthcare ecosystem are making significant\ninvestments in AI technologies to optimize their business operations at lower\ncost with improved patient outcomes. Despite the hype with AI, the full\nrealization of this potential is seriously hindered by several systemic\nproblems, including data privacy, security, bias, fairness, and explainability.\nIn this paper, we propose a novel canonical architecture for the development of\nAI models in healthcare that addresses these challenges. This system enables\nthe creation and management of AI predictive models throughout all the phases\nof their life cycle, including data ingestion, model building, and model\npromotion in production environments. This paper describes this architecture in\ndetail, along with a qualitative evaluation of our experience of using it on\nreal world problems.\n", "versions": [{"version": "v1", "created": "Fri, 24 Jul 2020 21:51:41 GMT"}, {"version": "v2", "created": "Tue, 5 Jan 2021 19:46:04 GMT"}], "update_date": "2021-01-07", "authors_parsed": [["Suryanarayanan", "Parthasarathy", ""], ["Iyer", "Bhavani", ""], ["Chakraborty", "Prithwish", ""], ["Hao", "Bibo", ""], ["Buleje", "Italo", ""], ["Madan", "Piyush", ""], ["Codella", "James", ""], ["Foncubierta", "Antonio", ""], ["Pathak", "Divya", ""], ["Miller", "Sarah", ""], ["Rajmane", "Amol", ""], ["Harrer", "Shannon", ""], ["Yuan-Reed", "Gigi", ""], ["Sow", "Daby", ""]]}, {"id": "2007.12799", "submitter": "Leopoldo Bertossi", "authors": "Leopoldo Bertossi", "title": "Score-Based Explanations in Data Management and Machine Learning", "comments": "Companion paper for a tutorial at the Scalable Uncertainty Management\n  Conference (SUM'20). To appear in Proc. SUM'20. Minor fixes made", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe some approaches to explanations for observed outcomes in data\nmanagement and machine learning. They are based on the assignment of numerical\nscores to predefined and potentially relevant inputs. More specifically, we\nconsider explanations for query answers in databases, and for results from\nclassification models. The described approaches are mostly of a causal and\ncounterfactual nature. We argue for the need to bring domain and semantic\nknowledge into score computations; and suggest some ways to do this.\n", "versions": [{"version": "v1", "created": "Fri, 24 Jul 2020 23:13:27 GMT"}, {"version": "v2", "created": "Wed, 19 Aug 2020 01:53:53 GMT"}], "update_date": "2020-08-20", "authors_parsed": [["Bertossi", "Leopoldo", ""]]}, {"id": "2007.12803", "submitter": "Xiaofeng Gao", "authors": "Xiaofeng Gao, Ran Gong, Yizhou Zhao, Shu Wang, Tianmin Shu, Song-Chun\n  Zhu", "title": "Joint Mind Modeling for Explanation Generation in Complex Human-Robot\n  Collaborative Tasks", "comments": "IEEE International Conference on Robot and Human Interactive\n  Communication (RO-MAN 2020), 8 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.HC cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Human collaborators can effectively communicate with their partners to finish\na common task by inferring each other's mental states (e.g., goals, beliefs,\nand desires). Such mind-aware communication minimizes the discrepancy among\ncollaborators' mental states, and is crucial to the success in human ad-hoc\nteaming. We believe that robots collaborating with human users should\ndemonstrate similar pedagogic behavior. Thus, in this paper, we propose a novel\nexplainable AI (XAI) framework for achieving human-like communication in\nhuman-robot collaborations, where the robot builds a hierarchical mind model of\nthe human user and generates explanations of its own mind as a form of\ncommunications based on its online Bayesian inference of the user's mental\nstate. To evaluate our framework, we conduct a user study on a real-time\nhuman-robot cooking task. Experimental results show that the generated\nexplanations of our approach significantly improves the collaboration\nperformance and user perception of the robot. Code and video demos are\navailable on our project website: https://xfgao.github.io/xCookingWeb/.\n", "versions": [{"version": "v1", "created": "Fri, 24 Jul 2020 23:35:03 GMT"}], "update_date": "2020-07-28", "authors_parsed": [["Gao", "Xiaofeng", ""], ["Gong", "Ran", ""], ["Zhao", "Yizhou", ""], ["Wang", "Shu", ""], ["Shu", "Tianmin", ""], ["Zhu", "Song-Chun", ""]]}, {"id": "2007.12824", "submitter": "Douglas Cardoso D.Sc.", "authors": "Igor Q. Lordeiro, Diego B. Haddad, Douglas O. Cardoso", "title": "Multi-Armed Bandits for Minesweeper: Profiting from\n  Exploration-Exploitation Synergy", "comments": "To be published in IEEE Transactions on Games (ISSN 2475-1510 /\n  2475-1502)", "journal-ref": null, "doi": "10.1109/TG.2021.3082909", "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A popular computer puzzle, the game of Minesweeper requires its human players\nto have a mix of both luck and strategy to succeed. Analyzing these aspects\nmore formally, in our research we assessed the feasibility of a novel\nmethodology based on Reinforcement Learning as an adequate approach to tackle\nthe problem presented by this game. For this purpose we employed Multi-Armed\nBandit algorithms which were carefully adapted in order to enable their use to\ndefine autonomous computational players, targeting to make the best use of some\ngame peculiarities. After experimental evaluation, results showed that this\napproach was indeed successful, especially in smaller game boards, such as the\nstandard beginner level. Despite this fact the main contribution of this work\nis a detailed examination of Minesweeper from a learning perspective, which led\nto various original insights which are thoroughly discussed.\n", "versions": [{"version": "v1", "created": "Sat, 25 Jul 2020 01:44:50 GMT"}, {"version": "v2", "created": "Thu, 17 Jun 2021 21:18:03 GMT"}], "update_date": "2021-06-21", "authors_parsed": [["Lordeiro", "Igor Q.", ""], ["Haddad", "Diego B.", ""], ["Cardoso", "Douglas O.", ""]]}, {"id": "2007.12870", "submitter": "Georgy Kopanitsa", "authors": "Sergey V. Kovalchuk, Georgy D. Kopanitsa, Ilia V. Derevitskii, Daria\n  A. Savitskaya", "title": "Three-stage intelligent support of clinical decision making for higher\n  trust, validity, and explainability", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper presents an approach for building consistent and applicable\nclinical decision support systems (CDSSs) using a data-driven predictive model\naimed at resolving the problem of low applicability and scalability of CDSSs in\nreal-world applications. The approach is based on a threestage application of\ndomain-specific and data-driven supportive procedures that are to be integrated\ninto clinical business processes with higher trust and explainability of the\nprediction results and recommendations. Within the considered three stages, the\nregulatory policy, data-driven modes, and interpretation procedures are\nintegrated to enable natural domain-specific interaction with decisionmakers\nwith sequential narrowing of the intelligent decision support focus. The\nproposed methodology enables a higher level of automation, scalability, and\nsemantic interpretability of CDSSs. The approach was implemented in software\nsolutions and tested within a case study in T2DM prediction, enabling us to\nimprove known clinical scales (such as FINDRISK) while keeping the\nproblem-specific reasoning interface similar to existing applications. Such\ninheritance, together with the three-staged approach, provide higher\ncompatibility of the solution and leads to trust, valid, and explainable\napplication of data-driven solutions in real-world cases.\n", "versions": [{"version": "v1", "created": "Sat, 25 Jul 2020 07:12:21 GMT"}, {"version": "v2", "created": "Sat, 6 Mar 2021 17:16:41 GMT"}], "update_date": "2021-03-09", "authors_parsed": [["Kovalchuk", "Sergey V.", ""], ["Kopanitsa", "Georgy D.", ""], ["Derevitskii", "Ilia V.", ""], ["Savitskaya", "Daria A.", ""]]}, {"id": "2007.12904", "submitter": "Zehong Cao Dr.", "authors": "Zehong Cao, KaiChiu Wong, Chin-Teng Lin", "title": "Weak Human Preference Supervision For Deep Reinforcement Learning", "comments": "Submitting to IEEE Transactions on Neural Networks and Learning\n  Systems", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The current reward learning from human preferences could be used to resolve\ncomplex reinforcement learning (RL) tasks without access to a reward function\nby defining a single fixed preference between pairs of trajectory segments.\nHowever, the judgement of preferences between trajectories is not dynamic and\nstill requires human input over thousands of iterations. In this study, we\nproposed a weak human preference supervision framework, for which we developed\na human preference scaling model that naturally reflects the human perception\nof the degree of weak choices between trajectories and established a\nhuman-demonstration estimator via supervised learning to generate the predicted\npreferences for reducing the number of human inputs. The proposed weak human\npreference supervision framework can effectively solve complex RL tasks and\nachieve higher cumulative rewards in simulated robot locomotion -- MuJoCo games\n-- relative to the single fixed human preferences. Furthermore, our established\nhuman-demonstration estimator requires human feedback only for less than 0.01\\%\nof the agent's interactions with the environment and significantly reduces the\ncost of human inputs by up to 30\\% compared with the existing approaches. To\npresent the flexibility of our approach, we released a video\n(https://youtu.be/jQPe1OILT0M) showing comparisons of the behaviours of agents\ntrained on different types of human input. We believe that our naturally\ninspired human preferences with weakly supervised learning are beneficial for\nprecise reward learning and can be applied to state-of-the-art RL systems, such\nas human-autonomy teaming systems.\n", "versions": [{"version": "v1", "created": "Sat, 25 Jul 2020 10:37:15 GMT"}, {"version": "v2", "created": "Sat, 26 Dec 2020 02:02:31 GMT"}], "update_date": "2020-12-29", "authors_parsed": [["Cao", "Zehong", ""], ["Wong", "KaiChiu", ""], ["Lin", "Chin-Teng", ""]]}, {"id": "2007.12929", "submitter": "Christian Meurisch", "authors": "Bekir Bayrak, Florian Giger, Christian Meurisch", "title": "Insightful Assistant: AI-compatible Operation Graph Representations for\n  Enhancing Industrial Conversational Agents", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Advances in voice-controlled assistants paved the way into the consumer\nmarket. For professional or industrial use, the capabilities of such assistants\nare too limited or too time-consuming to implement due to the higher complexity\nof data, possible AI-based operations, and requests. In the light of these\ndeficits, this paper presents Insightful Assistant---a pipeline concept based\non a novel operation graph representation resulting from the intents detected.\nUsing a predefined set of semantically annotated (executable) functions, each\nnode of the operation graph is assigned to a function for execution. Besides\nbasic operations, such functions can contain artificial intelligence (AI) based\noperations (e.g., anomaly detection). The result is then visualized to the user\naccording to type and extracted user preferences in an automated way. We\nfurther collected a unique crowd-sourced set of 869 requests, each with four\ndifferent variants expected visualization, for an industrial dataset. The\nevaluation of our proof-of-concept prototype on this dataset shows its\nfeasibility: it achieves an accuracy of up to 95.0% (74.5%) for simple\n(complex) request detection with different variants and a top3-accuracy up to\n95.4% for data-/user-adaptive visualization.\n", "versions": [{"version": "v1", "created": "Sat, 25 Jul 2020 13:46:58 GMT"}], "update_date": "2020-07-28", "authors_parsed": [["Bayrak", "Bekir", ""], ["Giger", "Florian", ""], ["Meurisch", "Christian", ""]]}, {"id": "2007.12989", "submitter": "Svetlana Yanushkevich", "authors": "Shawn C. Eastwood and Svetlana N. Yanushkevich", "title": "Information Fusion on Belief Networks", "comments": "25 pages, pages of Appendix, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper will focus on the process of 'fusing' several observations or\nmodels of uncertainty into a single resultant model. Many existing approaches\nto fusion use subjective quantities such as 'strengths of belief' and process\nthese quantities with heuristic algorithms. This paper argues in favor of\nquantities that can be objectively measured, as opposed to the subjective\n'strength of belief' values. This paper will focus on probability\ndistributions, and more importantly, structures that denote sets of probability\ndistributions known as 'credal sets'. The novel aspect of this paper will be a\ntaxonomy of models of fusion that use specific types of credal sets, namely\nprobability interval distributions and Dempster-Shafer models. An objective\nrequirement for information fusion algorithms is provided, and is satisfied by\nall models of fusion presented in this paper. Dempster's rule of combination is\nshown to not satisfy this requirement. This paper will also assess the\ncomputational challenges involved for the proposed fusion approaches.\n", "versions": [{"version": "v1", "created": "Sat, 25 Jul 2020 18:10:45 GMT"}], "update_date": "2020-07-28", "authors_parsed": [["Eastwood", "Shawn C.", ""], ["Yanushkevich", "Svetlana N.", ""]]}, {"id": "2007.13053", "submitter": "Yanhong Annie Liu", "authors": "Yanhong A. Liu and Scott D. Stoller", "title": "Recursive Rules with Aggregation: A Simple Unified Semantics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Complex reasoning problems are most clearly and easily specified using\nlogical rules, especially recursive rules with aggregation such as counts and\nsums for practical applications. Unfortunately, the meaning of such rules has\nbeen a significant challenge, leading to many different conflicting semantics.\n  This paper describes a unified semantics for recursive rules with\naggregation, extending the unified founded semantics and constraint semantics\nfor recursive rules with negation. The key idea is to support simple expression\nof the different assumptions underlying different semantics, and orthogonally\ninterpret aggregation operations straightforwardly using their simple usual\nmeaning.\n", "versions": [{"version": "v1", "created": "Sun, 26 Jul 2020 04:42:44 GMT"}], "update_date": "2020-07-28", "authors_parsed": [["Liu", "Yanhong A.", ""], ["Stoller", "Scott D.", ""]]}, {"id": "2007.13073", "submitter": "Kai Zhou", "authors": "Kai Zhou and Yevgeniy Vorobeychik", "title": "Robust Collective Classification against Structural Attacks", "comments": "UAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Collective learning methods exploit relations among data points to enhance\nclassification performance. However, such relations, represented as edges in\nthe underlying graphical model, expose an extra attack surface to the\nadversaries. We study adversarial robustness of an important class of such\ngraphical models, Associative Markov Networks (AMN), to structural attacks,\nwhere an attacker can modify the graph structure at test time. We formulate the\ntask of learning a robust AMN classifier as a bi-level program, where the inner\nproblem is a challenging non-linear integer program that computes optimal\nstructural changes to the AMN. To address this technical challenge, we first\nrelax the attacker problem, and then use duality to obtain a convex quadratic\nupper bound for the robust AMN problem. We then prove a bound on the quality of\nthe resulting approximately optimal solutions, and experimentally demonstrate\nthe efficacy of our approach. Finally, we apply our approach in a transductive\nlearning setting, and show that robust AMN is much more robust than\nstate-of-the-art deep learning methods, while sacrificing little in accuracy on\nnon-adversarial data.\n", "versions": [{"version": "v1", "created": "Sun, 26 Jul 2020 07:42:45 GMT"}], "update_date": "2020-07-28", "authors_parsed": [["Zhou", "Kai", ""], ["Vorobeychik", "Yevgeniy", ""]]}, {"id": "2007.13077", "submitter": "Hossein Yazdani", "authors": "Hossein Yazdani", "title": "Bounded Fuzzy Possibilistic Method of Critical Objects Processing in\n  Machine Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unsatisfying accuracy of learning methods is mostly caused by omitting the\ninfluence of important parameters such as membership assignments, type of data\nobjects, and distance or similarity functions. The proposed method, called\nBounded Fuzzy Possibilistic Method (BFPM) addresses different issues that\nprevious clustering or classification methods have not sufficiently considered\nin their membership assignments. In fuzzy methods, the object's memberships\nshould sum to 1. Hence, any data object may obtain full membership in at most\none cluster or class. Possibilistic methods relax this condition, but the\nmethod can be satisfied with the results even if just an arbitrary object\nobtains the membership from just one cluster, which prevents the objects'\nmovement analysis. Whereas, BFPM differs from previous fuzzy and possibilistic\napproaches by removing these restrictions. Furthermore, BFPM provides the\nflexible search space for objects' movement analysis. Data objects are also\nconsidered as fundamental keys in learning methods, and knowing the exact type\nof objects results in providing a suitable environment for learning algorithms.\nThe Thesis introduces a new type of object, called critical, as well as\ncategorizing data objects into two different categories: structural-based and\nbehavioural-based. Critical objects are considered as causes of\nmiss-classification and miss-assignment in learning procedures. The Thesis also\nproposes new methodologies to study the behaviour of critical objects with the\naim of evaluating objects' movements (mutation) from one cluster or class to\nanother. The Thesis also introduces a new type of feature, called dominant,\nthat is considered as one of the causes of miss-classification and\nmiss-assignments. Then the Thesis proposes new sets of similarity functions,\ncalled Weighted Feature Distance (WFD) and Prioritized Weighted Feature\nDistance (PWFD).\n", "versions": [{"version": "v1", "created": "Sun, 26 Jul 2020 08:12:33 GMT"}], "update_date": "2020-07-28", "authors_parsed": [["Yazdani", "Hossein", ""]]}, {"id": "2007.13197", "submitter": "Andrea Passerini", "authors": "Luca Di Liello, Pierfrancesco Ardino, Jacopo Gobbi, Paolo Morettin,\n  Stefano Teso, Andrea Passerini", "title": "Efficient Generation of Structured Objects with Constrained Adversarial\n  Networks", "comments": "34th Conference on Neural Information Processing Systems (NeurIPS\n  2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative Adversarial Networks (GANs) struggle to generate structured\nobjects like molecules and game maps. The issue is that structured objects must\nsatisfy hard requirements (e.g., molecules must be chemically valid) that are\ndifficult to acquire from examples alone. As a remedy, we propose Constrained\nAdversarial Networks (CANs), an extension of GANs in which the constraints are\nembedded into the model during training. This is achieved by penalizing the\ngenerator proportionally to the mass it allocates to invalid structures. In\ncontrast to other generative models, CANs support efficient inference of valid\nstructures (with high probability) and allows to turn on and off the learned\nconstraints at inference time. CANs handle arbitrary logical constraints and\nleverage knowledge compilation techniques to efficiently evaluate the\ndisagreement between the model and the constraints. Our setup is further\nextended to hybrid logical-neural constraints for capturing very complex\nconstraints, like graph reachability. An extensive empirical analysis shows\nthat CANs efficiently generate valid structures that are both high-quality and\nnovel.\n", "versions": [{"version": "v1", "created": "Sun, 26 Jul 2020 19:04:37 GMT"}, {"version": "v2", "created": "Sun, 29 Nov 2020 20:54:27 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Di Liello", "Luca", ""], ["Ardino", "Pierfrancesco", ""], ["Gobbi", "Jacopo", ""], ["Morettin", "Paolo", ""], ["Teso", "Stefano", ""], ["Passerini", "Andrea", ""]]}, {"id": "2007.13202", "submitter": "Rohan Chitnis", "authors": "Rohan Chitnis, Tom Silver, Beomjoon Kim, Leslie Pack Kaelbling, Tomas\n  Lozano-Perez", "title": "CAMPs: Learning Context-Specific Abstractions for Efficient Planning in\n  Factored MDPs", "comments": "CoRL 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Meta-planning, or learning to guide planning from experience, is a promising\napproach to improving the computational cost of planning. A general\nmeta-planning strategy is to learn to impose constraints on the states\nconsidered and actions taken by the agent. We observe that (1) imposing a\nconstraint can induce context-specific independences that render some aspects\nof the domain irrelevant, and (2) an agent can take advantage of this fact by\nimposing constraints on its own behavior. These observations lead us to propose\nthe context-specific abstract Markov decision process (CAMP), an abstraction of\na factored MDP that affords efficient planning. We then describe how to learn\nconstraints to impose so the CAMP optimizes a trade-off between rewards and\ncomputational cost. Our experiments consider five planners across four domains,\nincluding robotic navigation among movable obstacles (NAMO), robotic task and\nmotion planning for sequential manipulation, and classical planning. We find\nplanning with learned CAMPs to consistently outperform baselines, including\nStilman's NAMO-specific algorithm. Video: https://youtu.be/wTXt6djcAd4 Code:\nhttps://git.io/JTnf6\n", "versions": [{"version": "v1", "created": "Sun, 26 Jul 2020 19:35:28 GMT"}, {"version": "v2", "created": "Fri, 16 Oct 2020 22:14:52 GMT"}, {"version": "v3", "created": "Sun, 8 Nov 2020 00:10:55 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Chitnis", "Rohan", ""], ["Silver", "Tom", ""], ["Kim", "Beomjoon", ""], ["Kaelbling", "Leslie Pack", ""], ["Lozano-Perez", "Tomas", ""]]}, {"id": "2007.13233", "submitter": "Najla Al-Taleb", "authors": "Najla Al-Taleb, Nazar Abbas Saqib, Atta-ur-Rahman, Sujata Dash", "title": "Cyber Threat Intelligence for Secure Smart City", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Smart city improved the quality of life for the citizens by implementing\ninformation communication technology (ICT) such as the internet of things\n(IoT). Nevertheless, the smart city is a critical environment that needs to\nsecure it is network and data from intrusions and attacks. This work proposes a\nhybrid deep learning (DL) model for cyber threat intelligence (CTI) to improve\nthreats classification performance based on convolutional neural network (CNN)\nand quasi-recurrent neural network (QRNN). We use QRNN to provide a real-time\nthreat classification model. The evaluation results of the proposed model\ncompared to the state-of-the-art models show that the proposed model\noutperformed the other models. Therefore, it will help in classifying the smart\ncity threats in a reasonable time.\n", "versions": [{"version": "v1", "created": "Sun, 26 Jul 2020 22:39:33 GMT"}], "update_date": "2020-07-28", "authors_parsed": [["Al-Taleb", "Najla", ""], ["Saqib", "Nazar Abbas", ""], ["Atta-ur-Rahman", "", ""], ["Dash", "Sujata", ""]]}, {"id": "2007.13256", "submitter": "Yara Rizk", "authors": "Yara Rizk, Vatche Isahagian, Scott Boag, Yasaman Khazaeni, Merve\n  Unuvar, Vinod Muthusamy, Rania Khalaf", "title": "A Conversational Digital Assistant for Intelligent Process Automation", "comments": "International Conference on Business Process Management 2020 RPA\n  Forum", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Robotic process automation (RPA) has emerged as the leading approach to\nautomate tasks in business processes. Moving away from back-end automation, RPA\nautomated the mouse-click on user interfaces; this outside-in approach reduced\nthe overhead of updating legacy software. However, its many shortcomings,\nnamely its lack of accessibility to business users, have prevented its\nwidespread adoption in highly regulated industries. In this work, we explore\ninteractive automation in the form of a conversational digital assistant. It\nallows business users to interact with and customize their automation solutions\nthrough natural language. The framework, which creates such assistants, relies\non a multi-agent orchestration model and conversational wrappers for autonomous\nagents including RPAs. We demonstrate the effectiveness of our proposed\napproach on a loan approval business process and a travel preapproval business\nprocess.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jul 2020 00:38:13 GMT"}], "update_date": "2020-07-28", "authors_parsed": [["Rizk", "Yara", ""], ["Isahagian", "Vatche", ""], ["Boag", "Scott", ""], ["Khazaeni", "Yasaman", ""], ["Unuvar", "Merve", ""], ["Muthusamy", "Vinod", ""], ["Khalaf", "Rania", ""]]}, {"id": "2007.13257", "submitter": "Yara Rizk", "authors": "Tathagata Chakraborti, Vatche Isahagian, Rania Khalaf, Yasaman\n  Khazaeni, Vinod Muthusamy, Yara Rizk, Merve Unuvar", "title": "From Robotic Process Automation to Intelligent Process Automation:\n  Emerging Trends", "comments": "Internation Conference on Business Process Management 2020 RPA Forum", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this survey, we study how recent advances in machine intelligence are\ndisrupting the world of business processes. Over the last decade, there has\nbeen steady progress towards the automation of business processes under the\numbrella of ``robotic process automation'' (RPA). However, we are currently at\nan inflection point in this evolution, as a new paradigm called ``Intelligent\nProcess Automation'' (IPA) emerges, bringing machine learning (ML) and\nartificial intelligence (AI) technologies to bear in order to improve business\nprocess outcomes. The purpose of this paper is to provide a survey of this\nemerging theme and identify key open research challenges at the intersection of\nAI and business processes. We hope that this emerging theme will spark engaging\nconversations at the RPA Forum.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jul 2020 00:43:08 GMT"}], "update_date": "2020-07-28", "authors_parsed": [["Chakraborti", "Tathagata", ""], ["Isahagian", "Vatche", ""], ["Khalaf", "Rania", ""], ["Khazaeni", "Yasaman", ""], ["Muthusamy", "Vinod", ""], ["Rizk", "Yara", ""], ["Unuvar", "Merve", ""]]}, {"id": "2007.13262", "submitter": "Siwen Luo", "authors": "Siwen Luo, Soyeon Caren Han, Kaiyuan Sun and Josiah Poon", "title": "REXUP: I REason, I EXtract, I UPdate with Structured Compositional\n  Reasoning for Visual Question Answering", "comments": "Accepted by ICONIP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Visual question answering (VQA) is a challenging multi-modal task that\nrequires not only the semantic understanding of both images and questions, but\nalso the sound perception of a step-by-step reasoning process that would lead\nto the correct answer. So far, most successful attempts in VQA have been\nfocused on only one aspect, either the interaction of visual pixel features of\nimages and word features of questions, or the reasoning process of answering\nthe question in an image with simple objects. In this paper, we propose a deep\nreasoning VQA model with explicit visual structure-aware textual information,\nand it works well in capturing step-by-step reasoning process and detecting a\ncomplex object-relationship in photo-realistic images. REXUP network consists\nof two branches, image object-oriented and scene graph oriented, which jointly\nworks with super-diagonal fusion compositional attention network. We\nquantitatively and qualitatively evaluate REXUP on the GQA dataset and conduct\nextensive ablation studies to explore the reasons behind REXUP's effectiveness.\nOur best model significantly outperforms the precious state-of-the-art, which\ndelivers 92.7% on the validation set and 73.1% on the test-dev set.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jul 2020 00:54:50 GMT"}, {"version": "v2", "created": "Mon, 14 Sep 2020 09:18:20 GMT"}], "update_date": "2021-04-06", "authors_parsed": [["Luo", "Siwen", ""], ["Han", "Soyeon Caren", ""], ["Sun", "Kaiyuan", ""], ["Poon", "Josiah", ""]]}, {"id": "2007.13363", "submitter": "Nicolas Perrin-Gilbert", "authors": "Thomas Pierrot, Nicolas Perrin, Feryal Behbahani, Alexandre Laterre,\n  Olivier Sigaud, Karim Beguir, Nando de Freitas", "title": "Learning Compositional Neural Programs for Continuous Control", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel solution to challenging sparse-reward, continuous control\nproblems that require hierarchical planning at multiple levels of abstraction.\nOur solution, dubbed AlphaNPI-X, involves three separate stages of learning.\nFirst, we use off-policy reinforcement learning algorithms with experience\nreplay to learn a set of atomic goal-conditioned policies, which can be easily\nrepurposed for many tasks. Second, we learn self-models describing the effect\nof the atomic policies on the environment. Third, the self-models are harnessed\nto learn recursive compositional programs with multiple levels of abstraction.\nThe key insight is that the self-models enable planning by imagination,\nobviating the need for interaction with the world when learning higher-level\ncompositional programs. To accomplish the third stage of learning, we extend\nthe AlphaNPI algorithm, which applies AlphaZero to learn recursive neural\nprogrammer-interpreters. We empirically show that AlphaNPI-X can effectively\nlearn to tackle challenging sparse manipulation tasks, such as stacking\nmultiple blocks, where powerful model-free baselines fail.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jul 2020 08:27:14 GMT"}, {"version": "v2", "created": "Tue, 13 Apr 2021 12:08:39 GMT"}], "update_date": "2021-04-14", "authors_parsed": [["Pierrot", "Thomas", ""], ["Perrin", "Nicolas", ""], ["Behbahani", "Feryal", ""], ["Laterre", "Alexandre", ""], ["Sigaud", "Olivier", ""], ["Beguir", "Karim", ""], ["de Freitas", "Nando", ""]]}, {"id": "2007.13371", "submitter": "Lia Morra", "authors": "Lia Morra, Fabrizio Lamberti, F. Gabriele Prattic\\'o, Salvatore La\n  Rosa, Paolo Montuschi", "title": "Building Trust in Autonomous Vehicles: Role of Virtual Reality Driving\n  Simulators in HMI Design", "comments": null, "journal-ref": "IEEE Transactions on Vehicular Technology, 68(10), pp.9438-9450,\n  2019", "doi": "10.1109/TVT.2019.2933601", "report-no": null, "categories": "cs.HC cs.AI cs.GR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The investigation of factors contributing at making humans trust Autonomous\nVehicles (AVs) will play a fundamental role in the adoption of such technology.\nThe user's ability to form a mental model of the AV, which is crucial to\nestablish trust, depends on effective user-vehicle communication; thus, the\nimportance of Human-Machine Interaction (HMI) is poised to increase. In this\nwork, we propose a methodology to validate the user experience in AVs based on\ncontinuous, objective information gathered from physiological signals, while\nthe user is immersed in a Virtual Reality-based driving simulation. We applied\nthis methodology to the design of a head-up display interface delivering visual\ncues about the vehicle' sensory and planning systems. Through this approach, we\nobtained qualitative and quantitative evidence that a complete picture of the\nvehicle's surrounding, despite the higher cognitive load, is conducive to a\nless stressful experience. Moreover, after having been exposed to a more\ninformative interface, users involved in the study were also more willing to\ntest a real AV. The proposed methodology could be extended by adjusting the\nsimulation environment, the HMI and/or the vehicle's Artificial Intelligence\nmodules to dig into other aspects of the user experience.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jul 2020 08:42:07 GMT"}], "update_date": "2020-07-28", "authors_parsed": [["Morra", "Lia", ""], ["Lamberti", "Fabrizio", ""], ["Prattic\u00f3", "F. Gabriele", ""], ["La Rosa", "Salvatore", ""], ["Montuschi", "Paolo", ""]]}, {"id": "2007.13414", "submitter": "Nupur Aggarwal Ms", "authors": "Nupur Aggarwal, Abhishek Bansal, Kushagra Manglik, Kedar Kulkarni,\n  Vikas Raykar", "title": "Hyper-local sustainable assortment planning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Assortment planning, an important seasonal activity for any retailer,\ninvolves choosing the right subset of products to stock in each store.While\nexisting approaches only maximize the expected revenue, we propose including\nthe environmental impact too, through the Higg Material Sustainability Index.\nThe trade-off between revenue and environmental impact is balanced through a\nmulti-objective optimization approach, that yields a Pareto-front of optimal\nassortments for merchandisers to choose from. Using the proposed approach on a\nfew product categories of a leading fashion retailer shows that choosing\nassortments with lower environmental impact with a minimal impact on revenue is\npossible.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jul 2020 10:23:46 GMT"}], "update_date": "2020-07-28", "authors_parsed": [["Aggarwal", "Nupur", ""], ["Bansal", "Abhishek", ""], ["Manglik", "Kushagra", ""], ["Kulkarni", "Kedar", ""], ["Raykar", "Vikas", ""]]}, {"id": "2007.13475", "submitter": "Beatrice Bouchou Markhoff", "authors": "Mathieu Lirzin (BDTLN), B\\'eatrice Markhoff (BDTLN)", "title": "Towards an ontology of HTTP interactions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Enterprise information systems have adopted Web-based foundations for\nexchanges between heterogeneous programmes. These programs provide and consume\nvia Web APIs some resources identified by URIs, whose representations are\ntransmitted via HTTP. Furthermore HTTP remains at the heart of all Web\ndevelopments (Semantic Web, linked data, IoT...). Thus, situations where a\nprogram must be able to reason about HTTP interactions (request-response) are\nmultiplying. This requires an explicit formal specification of a shared\nconceptualization of those interactions. A proposal for an RDF vocabulary\nexists, developed with a view to carrying out web application conformity tests\nand record the tests outputs. This vocabulary has already been reused. In this\npaper we propose to adapt and extend it for making it more reusable.\n", "versions": [{"version": "v1", "created": "Mon, 20 Jul 2020 08:38:36 GMT"}], "update_date": "2020-07-28", "authors_parsed": [["Lirzin", "Mathieu", "", "BDTLN"], ["Markhoff", "B\u00e9atrice", "", "BDTLN"]]}, {"id": "2007.13483", "submitter": "Levent Sagun", "authors": "Levent Sagun, Caglar Gulcehre, Adriana Romero, Negar Rostamzadeh,\n  Stefano Sarao Mannelli", "title": "Post-Workshop Report on Science meets Engineering in Deep Learning,\n  NeurIPS 2019, Vancouver", "comments": "Report of NeurIPS 2019 workshop SEDL", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Science meets Engineering in Deep Learning took place in Vancouver as part of\nthe Workshop section of NeurIPS 2019. As organizers of the workshop, we created\nthe following report in an attempt to isolate emerging topics and recurring\nthemes that have been presented throughout the event. Deep learning can still\nbe a complex mix of art and engineering despite its tremendous success in\nrecent years. The workshop aimed at gathering people across the board to\naddress seemingly contrasting challenges in the problems they are working on.\nAs part of the call for the workshop, particular attention has been given to\nthe interdependence of architecture, data, and optimization that gives rise to\nan enormous landscape of design and performance intricacies that are not\nwell-understood. This year, our goal was to emphasize the following directions\nin our community: (i) identify obstacles in the way to better models and\nalgorithms; (ii) identify the general trends from which we would like to build\nscientific and potentially theoretical understanding; and (iii) the rigorous\ndesign of scientific experiments and experimental protocols whose purpose is to\nresolve and pinpoint the origin of mysteries while ensuring reproducibility and\nrobustness of conclusions. In the event, these topics emerged and were broadly\ndiscussed, matching our expectations and paving the way for new studies in\nthese directions. While we acknowledge that the text is naturally biased as it\ncomes through our lens, here we present an attempt to do a fair job of\nhighlighting the outcome of the workshop.\n", "versions": [{"version": "v1", "created": "Thu, 25 Jun 2020 12:19:09 GMT"}, {"version": "v2", "created": "Wed, 29 Jul 2020 13:22:16 GMT"}], "update_date": "2020-07-30", "authors_parsed": [["Sagun", "Levent", ""], ["Gulcehre", "Caglar", ""], ["Romero", "Adriana", ""], ["Rostamzadeh", "Negar", ""], ["Mannelli", "Stefano Sarao", ""]]}, {"id": "2007.13484", "submitter": "Shuyue Jia", "authors": "Shuyue Jia, Yimin Hou, Yan Shi, Yang Li", "title": "Attention-based Graph ResNet for Motor Intent Detection from Raw EEG\n  signals", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.AI cs.CV cs.LG eess.IV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In previous studies, decoding electroencephalography (EEG) signals has not\nconsidered the topological relationship of EEG electrodes. However, the latest\nneuroscience has suggested brain network connectivity. Thus, the exhibited\ninteraction between EEG channels might not be appropriately measured via\nEuclidean distance. To fill the gap, an attention-based graph residual network,\na novel structure of Graph Convolutional Neural Network (GCN), was presented to\ndetect human motor intents from raw EEG signals, where the topological\nstructure of EEG electrodes was built as a graph. Meanwhile, deep residual\nlearning with a full-attention architecture was introduced to address the\ndegradation problem concerning deeper networks in raw EEG motor imagery (MI)\ndata. Individual variability, the critical and longstanding challenge\nunderlying EEG signals, has been successfully handled with the state-of-the-art\nperformance, 98.08% accuracy at the subject level, 94.28% for 20 subjects.\nNumerical results were promising that the implementation of the\ngraph-structured topology was superior to decode raw EEG data. The innovative\ndeep learning approach was expected to entail a universal method towards both\nneuroscience research and real-world EEG-based practical applications, e.g.,\nseizure prediction.\n", "versions": [{"version": "v1", "created": "Thu, 25 Jun 2020 09:29:48 GMT"}], "update_date": "2020-07-28", "authors_parsed": [["Jia", "Shuyue", ""], ["Hou", "Yimin", ""], ["Shi", "Yan", ""], ["Li", "Yang", ""]]}, {"id": "2007.13531", "submitter": "Ioana Bica", "authors": "Ioana Bica, Daniel Jarrett, Alihan H\\\"uy\\\"uk, Mihaela van der Schaar", "title": "Learning \"What-if\" Explanations for Sequential Decision-Making", "comments": "In Proc. 9th International Conference on Learning Representations\n  (ICLR 2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Building interpretable parameterizations of real-world decision-making on the\nbasis of demonstrated behavior -- i.e. trajectories of observations and actions\nmade by an expert maximizing some unknown reward function -- is essential for\nintrospecting and auditing policies in different institutions. In this paper,\nwe propose learning explanations of expert decisions by modeling their reward\nfunction in terms of preferences with respect to \"what if\" outcomes: Given the\ncurrent history of observations, what would happen if we took a particular\naction? To learn these cost-benefit tradeoffs associated with the expert's\nactions, we integrate counterfactual reasoning into batch inverse reinforcement\nlearning. This offers a principled way of defining reward functions and\nexplaining expert behavior, and also satisfies the constraints of real-world\ndecision-making -- where active experimentation is often impossible (e.g. in\nhealthcare). Additionally, by estimating the effects of different actions,\ncounterfactuals readily tackle the off-policy nature of policy evaluation in\nthe batch setting, and can naturally accommodate settings where the expert\npolicies depend on histories of observations rather than just current states.\nThrough illustrative experiments in both real and simulated medical\nenvironments, we highlight the effectiveness of our batch, counterfactual\ninverse reinforcement learning approach in recovering accurate and\ninterpretable descriptions of behavior.\n", "versions": [{"version": "v1", "created": "Thu, 2 Jul 2020 14:24:17 GMT"}, {"version": "v2", "created": "Thu, 18 Feb 2021 13:14:44 GMT"}, {"version": "v3", "created": "Tue, 30 Mar 2021 17:32:17 GMT"}], "update_date": "2021-03-31", "authors_parsed": [["Bica", "Ioana", ""], ["Jarrett", "Daniel", ""], ["H\u00fcy\u00fck", "Alihan", ""], ["van der Schaar", "Mihaela", ""]]}, {"id": "2007.13534", "submitter": "Longbing Cao", "authors": "Longbing Cao", "title": "Coupling Learning of Complex Interactions", "comments": null, "journal-ref": "Journal of Information Processing and Management, 51(2): 167-186\n  (2015)", "doi": "10.1016/j.ipm.2014.08.007", "report-no": null, "categories": "cs.LG cs.AI cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Complex applications such as big data analytics involve different forms of\ncoupling relationships that reflect interactions between factors related to\ntechnical, business (domain-specific) and environmental (including\nsocio-cultural and economic) aspects. There are diverse forms of couplings\nembedded in poor-structured and ill-structured data. Such couplings are\nubiquitous, implicit and/or explicit, objective and/or subjective,\nheterogeneous and/or homogeneous, presenting complexities to existing learning\nsystems in statistics, mathematics and computer sciences, such as typical\ndependency, association and correlation relationships. Modeling and learning\nsuch couplings thus is fundamental but challenging. This paper discusses the\nconcept of coupling learning, focusing on the involvement of coupling\nrelationships in learning systems. Coupling learning has great potential for\nbuilding a deep understanding of the essence of business problems and handling\nchallenges that have not been addressed well by existing learning theories and\ntools. This argument is verified by several case studies on coupling learning,\nincluding handling coupling in recommender systems, incorporating couplings\ninto coupled clustering, coupling document clustering, coupled recommender\nalgorithms and coupled behavior analysis for groups.\n", "versions": [{"version": "v1", "created": "Wed, 1 Jul 2020 11:04:25 GMT"}], "update_date": "2020-07-28", "authors_parsed": [["Cao", "Longbing", ""]]}, {"id": "2007.13544", "submitter": "Noam Brown", "authors": "Noam Brown, Anton Bakhtin, Adam Lerer, Qucheng Gong", "title": "Combining Deep Reinforcement Learning and Search for\n  Imperfect-Information Games", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The combination of deep reinforcement learning and search at both training\nand test time is a powerful paradigm that has led to a number of successes in\nsingle-agent settings and perfect-information games, best exemplified by\nAlphaZero. However, prior algorithms of this form cannot cope with\nimperfect-information games. This paper presents ReBeL, a general framework for\nself-play reinforcement learning and search that provably converges to a Nash\nequilibrium in any two-player zero-sum game. In the simpler setting of\nperfect-information games, ReBeL reduces to an algorithm similar to AlphaZero.\nResults in two different imperfect-information games show ReBeL converges to an\napproximate Nash equilibrium. We also show ReBeL achieves superhuman\nperformance in heads-up no-limit Texas hold'em poker, while using far less\ndomain knowledge than any prior poker AI.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jul 2020 15:21:22 GMT"}, {"version": "v2", "created": "Sun, 29 Nov 2020 03:18:13 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Brown", "Noam", ""], ["Bakhtin", "Anton", ""], ["Lerer", "Adam", ""], ["Gong", "Qucheng", ""]]}, {"id": "2007.13690", "submitter": "Karush Suri", "authors": "Karush Suri, Xiao Qi Shi, Konstantinos N. Plataniotis, Yuri A.\n  Lawryshyn", "title": "Maximum Mutation Reinforcement Learning for Scalable Control", "comments": "10+3 Pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Advances in Reinforcement Learning (RL) have demonstrated data efficiency and\noptimal control over large state spaces at the cost of scalable performance.\nGenetic methods, on the other hand, provide scalability but depict\nhyperparameter sensitivity towards evolutionary operations. However, a\ncombination of the two methods has recently demonstrated success in scaling RL\nagents to high-dimensional action spaces. Parallel to recent developments, we\npresent the Evolution-based Soft Actor-Critic (ESAC), a scalable RL algorithm.\nWe abstract exploration from exploitation by combining Evolution Strategies\n(ES) with Soft Actor-Critic (SAC). Through this lens, we enable dominant skill\ntransfer between offsprings by making use of soft winner selections and genetic\ncrossovers in hindsight and simultaneously improve hyperparameter sensitivity\nin evolutions using the novel Automatic Mutation Tuning (AMT). AMT gradually\nreplaces the entropy framework of SAC allowing the population to succeed at the\ntask while acting as randomly as possible, without making use of\nbackpropagation updates. In a study of challenging locomotion tasks consisting\nof high-dimensional action spaces and sparse rewards, ESAC demonstrates\nimproved performance and sample efficiency in comparison to the Maximum Entropy\nframework. Additionally, ESAC presents efficacious use of hardware resources\nand algorithm overhead. A complete implementation of ESAC can be found at\nkarush17.github.io/esac-web/.\n", "versions": [{"version": "v1", "created": "Fri, 24 Jul 2020 16:29:19 GMT"}, {"version": "v2", "created": "Thu, 24 Sep 2020 01:51:07 GMT"}, {"version": "v3", "created": "Sat, 24 Oct 2020 18:08:24 GMT"}, {"version": "v4", "created": "Sun, 8 Nov 2020 02:57:01 GMT"}, {"version": "v5", "created": "Tue, 17 Nov 2020 22:21:26 GMT"}, {"version": "v6", "created": "Sat, 21 Nov 2020 23:02:54 GMT"}, {"version": "v7", "created": "Sat, 16 Jan 2021 23:51:53 GMT"}], "update_date": "2021-01-19", "authors_parsed": [["Suri", "Karush", ""], ["Shi", "Xiao Qi", ""], ["Plataniotis", "Konstantinos N.", ""], ["Lawryshyn", "Yuri A.", ""]]}, {"id": "2007.13699", "submitter": "Vaneet Aggarwal", "authors": "Kaushik Manchella and Abhishek K. Umrawal and Vaneet Aggarwal", "title": "FlexPool: A Distributed Model-Free Deep Reinforcement Learning Algorithm\n  for Joint Passengers & Goods Transportation", "comments": "Accepted to IEEE Transactions on Intelligent Transportation Systems", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.MA cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The growth in online goods delivery is causing a dramatic surge in urban\nvehicle traffic from last-mile deliveries. On the other hand, ride-sharing has\nbeen on the rise with the success of ride-sharing platforms and increased\nresearch on using autonomous vehicle technologies for routing and matching. The\nfuture of urban mobility for passengers and goods relies on leveraging new\nmethods that minimize operational costs and environmental footprints of\ntransportation systems.\n  This paper considers combining passenger transportation with goods delivery\nto improve vehicle-based transportation. Even though the problem has been\nstudied with a defined dynamics model of the transportation system environment,\nthis paper considers a model-free approach that has been demonstrated to be\nadaptable to new or erratic environment dynamics. We propose FlexPool, a\ndistributed model-free deep reinforcement learning algorithm that jointly\nserves passengers & goods workloads by learning optimal dispatch policies from\nits interaction with the environment. The proposed algorithm pools passengers\nfor a ride-sharing service and delivers goods using a multi-hop transit method.\nThese flexibilities decrease the fleet's operational cost and environmental\nfootprint while maintaining service levels for passengers and goods. Through\nsimulations on a realistic multi-agent urban mobility platform, we demonstrate\nthat FlexPool outperforms other model-free settings in serving the demands from\npassengers & goods. FlexPool achieves 30% higher fleet utilization and 35%\nhigher fuel efficiency in comparison to (i) model-free approaches where\nvehicles transport a combination of passengers & goods without the use of\nmulti-hop transit, and (ii) model-free approaches where vehicles exclusively\ntransport either passengers or goods.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jul 2020 17:25:58 GMT"}, {"version": "v2", "created": "Sun, 20 Sep 2020 19:09:34 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Manchella", "Kaushik", ""], ["Umrawal", "Abhishek K.", ""], ["Aggarwal", "Vaneet", ""]]}, {"id": "2007.13705", "submitter": "Cm Pintea", "authors": "Anca Avram, Oliviu Matei, Camelia Pintea, Carmen Anton", "title": "Innovative Platform for Designing Hybrid Collaborative & Context-Aware\n  Data Mining Scenarios", "comments": "15 figures", "journal-ref": "Mathematics 8(5):1-19, 684 (2020) (ISSN 2227-7390)", "doi": "10.3390/math8050684", "report-no": null, "categories": "cs.CY cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The process of knowledge discovery involves nowadays a major number of\ntechniques. Context-Aware Data Mining (CADM) and Collaborative Data Mining\n(CDM) are some of the recent ones. the current research proposes a new hybrid\nand efficient tool to design prediction models called Scenarios\nPlatform-Collaborative & Context-Aware Data Mining (SP-CCADM). Both CADM and\nCDM approaches are included in the new platform in a flexible manner; SP-CCADM\nallows the setting and testing of multiple configurable scenarios related to\ndata mining at once. The introduced platform was successfully tested and\nvalidated on real life scenarios, providing better results than each standalone\ntechnique-CADM and CDM. Nevertheless, SP-CCADM was validated with various\nmachine learning algorithms-k-Nearest Neighbour (k-NN), Deep Learning (DL),\nGradient Boosted Trees (GBT) and Decision Trees (DT). SP-CCADM makes a step\nforward when confronting complex data, properly approaching data contexts and\ncollaboration between data. Numerical experiments and statistics illustrate in\ndetail the potential of the proposed platform.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jul 2020 17:36:02 GMT"}], "update_date": "2020-07-28", "authors_parsed": [["Avram", "Anca", ""], ["Matei", "Oliviu", ""], ["Pintea", "Camelia", ""], ["Anton", "Carmen", ""]]}, {"id": "2007.13729", "submitter": "Chuang Gan", "authors": "Chuang Gan, Xiaoyu Chen, Phillip Isola, Antonio Torralba, Joshua B.\n  Tenenbaum", "title": "Noisy Agents: Self-supervised Exploration by Predicting Auditory Events", "comments": "Project page: http://noisy-agent.csail.mit.edu", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.RO cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Humans integrate multiple sensory modalities (e.g. visual and audio) to build\na causal understanding of the physical world. In this work, we propose a novel\ntype of intrinsic motivation for Reinforcement Learning (RL) that encourages\nthe agent to understand the causal effect of its actions through auditory event\nprediction. First, we allow the agent to collect a small amount of acoustic\ndata and use K-means to discover underlying auditory event clusters. We then\ntrain a neural network to predict the auditory events and use the prediction\nerrors as intrinsic rewards to guide RL exploration. Experimental results on\nAtari games show that our new intrinsic motivation significantly outperforms\nseveral state-of-the-art baselines. We further visualize our noisy agents'\nbehavior in a physics environment and demonstrate that our newly designed\nintrinsic reward leads to the emergence of physical interaction behaviors (e.g.\ncontact with objects).\n", "versions": [{"version": "v1", "created": "Mon, 27 Jul 2020 17:59:08 GMT"}], "update_date": "2020-07-28", "authors_parsed": [["Gan", "Chuang", ""], ["Chen", "Xiaoyu", ""], ["Isola", "Phillip", ""], ["Torralba", "Antonio", ""], ["Tenenbaum", "Joshua B.", ""]]}, {"id": "2007.13840", "submitter": "Nora Aguirre-Celis E", "authors": "N. Aguirre-Celis and R. Miikkulainen", "title": "Characterizing the Effect of Sentence Context on Word Meanings: Mapping\n  Brain to Behavior", "comments": "7 pages, 3 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Semantic feature models have become a popular tool for prediction and\ninterpretation of fMRI data. In particular, prior work has shown that\ndifferences in the fMRI patterns in sentence reading can be explained by\ncontext-dependent changes in the semantic feature representations of the words.\nHowever, whether the subjects are aware of such changes and agree with them has\nbeen an open question. This paper aims to answer this question through a\nhuman-subject study. Subjects were asked to judge how the word change from\ntheir generic meaning when the words were used in specific sentences. The\njudgements were consistent with the model predictions well above chance. Thus,\nthe results support the hypothesis that word meaning change systematically\ndepending on sentence context.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jul 2020 20:12:30 GMT"}, {"version": "v2", "created": "Thu, 6 Aug 2020 23:38:38 GMT"}, {"version": "v3", "created": "Tue, 12 Jan 2021 22:59:25 GMT"}], "update_date": "2021-01-14", "authors_parsed": [["Aguirre-Celis", "N.", ""], ["Miikkulainen", "R.", ""]]}, {"id": "2007.13862", "submitter": "Carlos Correa", "authors": "Carlos G. Correa, Mark K. Ho, Fred Callaway, Thomas L. Griffiths", "title": "Resource-rational Task Decomposition to Minimize Planning Costs", "comments": "The first two authors contributed equally. To appear in Proceedings\n  of the 42nd Annual Conference of the Cognitive Science Society (CogSci 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  People often plan hierarchically. That is, rather than planning over a\nmonolithic representation of a task, they decompose the task into simpler\nsubtasks and then plan to accomplish those. Although much work explores how\npeople decompose tasks, there is less analysis of why people decompose tasks in\nthe way they do. Here, we address this question by formalizing task\ndecomposition as a resource-rational representation problem. Specifically, we\npropose that people decompose tasks in a manner that facilitates efficient use\nof limited cognitive resources given the structure of the environment and their\nown planning algorithms. Using this model, we replicate several existing\nfindings. Our account provides a normative explanation for how people identify\nsubtasks as well as a framework for studying how people reason, plan, and act\nusing resource-rational representations.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jul 2020 20:59:26 GMT"}], "update_date": "2020-07-29", "authors_parsed": [["Correa", "Carlos G.", ""], ["Ho", "Mark K.", ""], ["Callaway", "Fred", ""], ["Griffiths", "Thomas L.", ""]]}, {"id": "2007.13885", "submitter": "Christian Blakely", "authors": "Christian D. Blakely, Ole-Christoffer Granmo", "title": "Closed-Form Expressions for Global and Local Interpretation of Tsetlin\n  Machines with Applications to Explaining High-Dimensional Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tsetlin Machines (TMs) capture patterns using conjunctive clauses in\npropositional logic, thus facilitating interpretation. However, recent TM-based\napproaches mainly rely on inspecting the full range of clauses individually.\nSuch inspection does not necessarily scale to complex prediction problems that\nrequire a large number of clauses. In this paper, we propose closed-form\nexpressions for understanding why a TM model makes a specific prediction (local\ninterpretability). Additionally, the expressions capture the most important\nfeatures of the model overall (global interpretability). We further introduce\nexpressions for measuring the importance of feature value ranges for continuous\nfeatures. The expressions are formulated directly from the conjunctive clauses\nof the TM, making it possible to capture the role of features in real-time,\nalso during the learning process as the model evolves. Additionally, from the\nclosed-form expressions, we derive a novel data clustering algorithm for\nvisualizing high-dimensional data in three dimensions. Finally, we compare our\nproposed approach against SHAP and state-of-the-art interpretable machine\nlearning techniques. For both classification and regression, our evaluation\nshow correspondence with SHAP as well as competitive prediction accuracy in\ncomparison with XGBoost, Explainable Boosting Machines, and Neural Additive\nModels.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jul 2020 21:47:24 GMT"}], "update_date": "2020-07-29", "authors_parsed": [["Blakely", "Christian D.", ""], ["Granmo", "Ole-Christoffer", ""]]}, {"id": "2007.13893", "submitter": "Ali Mousavi", "authors": "Andrew Bennett, Nathan Kallus, Lihong Li, Ali Mousavi", "title": "Off-policy Evaluation in Infinite-Horizon Reinforcement Learning with\n  Latent Confounders", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Off-policy evaluation (OPE) in reinforcement learning is an important problem\nin settings where experimentation is limited, such as education and healthcare.\nBut, in these very same settings, observed actions are often confounded by\nunobserved variables making OPE even more difficult. We study an OPE problem in\nan infinite-horizon, ergodic Markov decision process with unobserved\nconfounders, where states and actions can act as proxies for the unobserved\nconfounders. We show how, given only a latent variable model for states and\nactions, policy value can be identified from off-policy data. Our method\ninvolves two stages. In the first, we show how to use proxies to estimate\nstationary distribution ratios, extending recent work on breaking the curse of\nhorizon to the confounded setting. In the second, we show optimal balancing can\nbe combined with such learned ratios to obtain policy value while avoiding\ndirect modeling of reward functions. We establish theoretical guarantees of\nconsistency, and benchmark our method empirically.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jul 2020 22:19:01 GMT"}], "update_date": "2020-07-29", "authors_parsed": [["Bennett", "Andrew", ""], ["Kallus", "Nathan", ""], ["Li", "Lihong", ""], ["Mousavi", "Ali", ""]]}, {"id": "2007.13926", "submitter": "Yujun Zheng", "authors": "Yu-Jun Zheng, Si-Lan Yu, Jun-Chao Yang, Tie-Er Gan, Qin Song, Jun Yang\n  and Mumtaz Karatas", "title": "Intelligent Optimization of Diversified Community Prevention of COVID-19\n  using Traditional Chinese Medicine", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditional Chinese medicine (TCM) has played an important role in the\nprevention and control of the novel coronavirus pneumonia (COVID-19), and\ncommunity prevention has become the most essential part in reducing the spread\nrisk and protecting populations. However, most communities use a uniform TCM\nprevention program for all residents, which violates the \"treatment based on\nsyndrome differentiation\" principle of TCM and limits the effectiveness of\nprevention. In this paper, we propose an intelligent optimization method to\ndevelop diversified TCM prevention programs for community residents. First, we\nuse a fuzzy clustering method to divide the population based on both modern\nmedicine and TCM health characteristics; we then use an interactive\noptimization method, in which TCM experts develop different TCM prevention\nprograms for different clusters, and a heuristic algorithm is used to optimize\nthe programs under the resource constraints. We demonstrate the computational\nefficiency of the proposed method and report its successful application to\nTCM-based prevention of COVID-19 in 12 communities in Zhejiang province, China,\nduring the peak of the pandemic.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jul 2020 00:55:01 GMT"}], "update_date": "2020-07-29", "authors_parsed": [["Zheng", "Yu-Jun", ""], ["Yu", "Si-Lan", ""], ["Yang", "Jun-Chao", ""], ["Gan", "Tie-Er", ""], ["Song", "Qin", ""], ["Yang", "Jun", ""], ["Karatas", "Mumtaz", ""]]}, {"id": "2007.14009", "submitter": "Esther Galbrun", "authors": "Esther Galbrun", "title": "The Minimum Description Length Principle for Pattern Mining: A Survey", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.AI cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This is about the Minimum Description Length (MDL) principle applied to\npattern mining. The length of this description is kept to the minimum.\n  Mining patterns is a core task in data analysis and, beyond issues of\nefficient enumeration, the selection of patterns constitutes a major challenge.\nThe MDL principle, a model selection method grounded in information theory, has\nbeen applied to pattern mining with the aim to obtain compact high-quality sets\nof patterns. After giving an outline of relevant concepts from information\ntheory and coding, as well as of work on the theory behind the MDL and similar\nprinciples, we review MDL-based methods for mining various types of data and\npatterns. Finally, we open a discussion on some issues regarding these methods,\nand highlight currently active related data analysis problems.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jul 2020 06:24:39 GMT"}, {"version": "v2", "created": "Thu, 28 Jan 2021 13:43:54 GMT"}, {"version": "v3", "created": "Wed, 28 Jul 2021 05:19:57 GMT"}], "update_date": "2021-07-29", "authors_parsed": [["Galbrun", "Esther", ""]]}, {"id": "2007.14045", "submitter": "Marcelo Arenas", "authors": "Marcelo Arenas, Pablo Barcel\\'o Leopoldo Bertossi, Mika\\\"el Monet", "title": "The Tractability of SHAP-Score-Based Explanations over Deterministic and\n  Decomposable Boolean Circuits", "comments": "17 pages, including 8 pages of main text. arXiv version of the\n  AAAI'21 conference paper. Except from the addition of the technical appendix,\n  the content is the same as the AAAI one", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Scores based on Shapley values are widely used for providing explanations to\nclassification results over machine learning models. A prime example of this is\nthe influential SHAP-score, a version of the Shapley value that can help\nexplain the result of a learned model on a specific entity by assigning a score\nto every feature. While in general computing Shapley values is a\ncomputationally intractable problem, it has recently been claimed that the\nSHAP-score can be computed in polynomial time over the class of decision trees.\nIn this paper, we provide a proof of a stronger result over Boolean models: the\nSHAP-score can be computed in polynomial time over deterministic and\ndecomposable Boolean circuits. Such circuits, also known as tractable Boolean\ncircuits, generalize a wide range of Boolean circuits and binary decision\ndiagrams classes, including binary decision trees, Ordered Binary Decision\nDiagrams (OBDDs) and Free Binary Decision Diagrams (FBDDs). We also establish\nthe computational limits of the notion of SHAP-score by observing that, under a\nmild condition, computing it over a class of Boolean models is always\npolynomially as hard as the model counting problem for that class. This implies\nthat both determinism and decomposability are essential properties for the\ncircuits that we consider, as removing one or the other renders the problem of\ncomputing the SHAP-score intractable (namely, #P-hard).\n", "versions": [{"version": "v1", "created": "Tue, 28 Jul 2020 08:04:28 GMT"}, {"version": "v2", "created": "Thu, 10 Dec 2020 11:38:00 GMT"}, {"version": "v3", "created": "Sat, 3 Apr 2021 16:34:05 GMT"}], "update_date": "2021-04-06", "authors_parsed": [["Arenas", "Marcelo", ""], ["Bertossi", "Pablo Barcel\u00f3 Leopoldo", ""], ["Monet", "Mika\u00ebl", ""]]}, {"id": "2007.14070", "submitter": "Jacopo Mauro", "authors": "Jacopo Mauro", "title": "Anomaly detection in Context-aware Feature Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Feature Models are a mechanism to organize the configuration space and\nfacilitate the construction of software variants by describing configuration\noptions using features, i.e., a name representing a functionality. The\ndevelopment of Feature Models is an error prone activity and detecting their\nanomalies is a challenging and important task needed to promote their usage.\n  Recently, Feature Models have been extended with context to capture the\ncorrelation of configuration options with contextual influences and user\ncustomizations. Unfortunately, this extension makes the task of detecting\nanomalies harder. In this paper, we formalize the anomaly analysis in\nContext-aware Feature Models and we show how Quantified Boolean Formula (QBF)\nsolvers can be used to detect anomalies without relying on iterative calls to a\nSAT solver. By extending the reconfigurator engine HyVarRec, we present\nfindings evidencing that QBF solvers can outperform the common techniques for\nanomaly analysis.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jul 2020 08:59:14 GMT"}], "update_date": "2020-07-29", "authors_parsed": [["Mauro", "Jacopo", ""]]}, {"id": "2007.14071", "submitter": "Xinzhi Wang", "authors": "Xinzhi Wang, Luyao Kou, Vijayan Sugumaran, Xiangfeng Luo, and Hui\n  Zhang", "title": "Emotion Correlation Mining Through Deep Learning Models on Natural\n  Language Text", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Emotion analysis has been attracting researchers' attention. Most previous\nworks in the artificial intelligence field focus on recognizing emotion rather\nthan mining the reason why emotions are not or wrongly recognized. Correlation\namong emotions contributes to the failure of emotion recognition. In this\npaper, we try to fill the gap between emotion recognition and emotion\ncorrelation mining through natural language text from web news. Correlation\namong emotions, expressed as the confusion and evolution of emotion, is\nprimarily caused by human emotion cognitive bias. To mine emotion correlation\nfrom emotion recognition through text, three kinds of features and two deep\nneural network models are presented. The emotion confusion law is extracted\nthrough orthogonal basis. The emotion evolution law is evaluated from three\nperspectives, one-step shift, limited-step shifts, and shortest path transfer.\nThe method is validated using three datasets-the titles, the bodies, and the\ncomments of news articles, covering both objective and subjective texts in\nvarying lengths (long and short). The experimental results show that, in\nsubjective comments, emotions are easily mistaken as anger. Comments tend to\narouse emotion circulations of love-anger and sadness-anger. In objective news,\nit is easy to recognize text emotion as love and cause fear-joy circulation.\nThat means, journalists may try to attract attention using fear and joy words\nbut arouse the emotion love instead; After news release, netizens generate\nemotional comments to express their intense emotions, i.e., anger, sadness, and\nlove. These findings could provide insights for applications regarding\naffective interaction such as network public sentiment, social media\ncommunication, and human-computer interaction.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jul 2020 08:59:16 GMT"}], "update_date": "2020-07-29", "authors_parsed": [["Wang", "Xinzhi", ""], ["Kou", "Luyao", ""], ["Sugumaran", "Vijayan", ""], ["Luo", "Xiangfeng", ""], ["Zhang", "Hui", ""]]}, {"id": "2007.14075", "submitter": "Jacques Basald\\'ua Dr.", "authors": "Jacques Basald\\'ua", "title": "Formal Fields: A Framework to Automate Code Generation Across Domains", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Code generation, defined as automatically writing a piece of code to solve a\ngiven problem for which an evaluation function exists, is a classic hard AI\nproblem. Its general form, writing code using a general language used by human\nprogrammers from scratch is thought to be impractical. Adding constraints to\nthe code grammar, implementing domain specific concepts as primitives and\nproviding examples for the algorithm to learn, makes it practical. Formal\nfields is a framework to do code generation across domains using the same\nalgorithms and language structure. Its ultimate goal is not just solving\ndifferent narrow problems, but providing necessary abstractions to integrate\nmany working solutions as a single lifelong reasoning system. It provides a\ncommon grammar to define: a domain language, a problem and its evaluation. The\nframework learns from examples of code snippets about the structure of the\ndomain language and searches completely new code snippets to solve unseen\nproblems in the same field. Formal fields abstract the search algorithm away\nfrom the problem. The search algorithm is taken from existing reinforcement\nlearning algorithms. In our implementation it is an apropos Monte-Carlo Tree\nSearch (MCTS). We have implemented formal fields as a fully documented open\nsource project applied to the Abstract Reasoning Challenge (ARC). The\nimplementation found code snippets solving twenty two previously unsolved ARC\nproblems.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jul 2020 09:06:01 GMT"}], "update_date": "2020-07-29", "authors_parsed": [["Basald\u00faa", "Jacques", ""]]}, {"id": "2007.14175", "submitter": "Mehdi Ali", "authors": "Mehdi Ali, Max Berrendorf, Charles Tapley Hoyt, Laurent Vermue, Sahand\n  Sharifzadeh, Volker Tresp, and Jens Lehmann", "title": "PyKEEN 1.0: A Python Library for Training and Evaluating Knowledge Graph\n  Embeddings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, knowledge graph embeddings (KGEs) received significant attention,\nand several software libraries have been developed for training and evaluating\nKGEs. While each of them addresses specific needs, we re-designed and\nre-implemented PyKEEN, one of the first KGE libraries, in a community effort.\nPyKEEN 1.0 enables users to compose knowledge graph embedding models (KGEMs)\nbased on a wide range of interaction models, training approaches, loss\nfunctions, and permits the explicit modeling of inverse relations. Besides, an\nautomatic memory optimization has been realized in order to exploit the\nprovided hardware optimally, and through the integration of Optuna extensive\nhyper-parameter optimization (HPO) functionalities are provided.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jul 2020 12:54:28 GMT"}, {"version": "v2", "created": "Thu, 30 Jul 2020 08:57:27 GMT"}], "update_date": "2020-07-31", "authors_parsed": [["Ali", "Mehdi", ""], ["Berrendorf", "Max", ""], ["Hoyt", "Charles Tapley", ""], ["Vermue", "Laurent", ""], ["Sharifzadeh", "Sahand", ""], ["Tresp", "Volker", ""], ["Lehmann", "Jens", ""]]}, {"id": "2007.14184", "submitter": "Francesco Locatello", "authors": "Francesco Locatello, Stefan Bauer, Mario Lucic, Gunnar R\\\"atsch,\n  Sylvain Gelly, Bernhard Sch\\\"olkopf, Olivier Bachem", "title": "A Commentary on the Unsupervised Learning of Disentangled\n  Representations", "comments": null, "journal-ref": "The Thirty-Fourth AAAI Conference on Artificial Intelligence 2020\n  (AAAI-20)", "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The goal of the unsupervised learning of disentangled representations is to\nseparate the independent explanatory factors of variation in the data without\naccess to supervision. In this paper, we summarize the results of Locatello et\nal., 2019, and focus on their implications for practitioners. We discuss the\ntheoretical result showing that the unsupervised learning of disentangled\nrepresentations is fundamentally impossible without inductive biases and the\npractical challenges it entails. Finally, we comment on our experimental\nfindings, highlighting the limitations of state-of-the-art approaches and\ndirections for future research.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jul 2020 13:13:45 GMT"}], "update_date": "2020-07-29", "authors_parsed": [["Locatello", "Francesco", ""], ["Bauer", "Stefan", ""], ["Lucic", "Mario", ""], ["R\u00e4tsch", "Gunnar", ""], ["Gelly", "Sylvain", ""], ["Sch\u00f6lkopf", "Bernhard", ""], ["Bachem", "Olivier", ""]]}, {"id": "2007.14196", "submitter": "Zhi Wang", "authors": "Zhi Wang, Chunlin Chen, Daoyi Dong", "title": "Lifelong Incremental Reinforcement Learning with Online Bayesian\n  Inference", "comments": "Accepted by IEEE Transactions on Neural Networks and Learning\n  Systems, 2021", "journal-ref": null, "doi": "10.1109/TNNLS.2021.3055499", "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A central capability of a long-lived reinforcement learning (RL) agent is to\nincrementally adapt its behavior as its environment changes, and to\nincrementally build upon previous experiences to facilitate future learning in\nreal-world scenarios. In this paper, we propose LifeLong Incremental\nReinforcement Learning (LLIRL), a new incremental algorithm for efficient\nlifelong adaptation to dynamic environments. We develop and maintain a library\nthat contains an infinite mixture of parameterized environment models, which is\nequivalent to clustering environment parameters in a latent space. The prior\ndistribution over the mixture is formulated as a Chinese restaurant process\n(CRP), which incrementally instantiates new environment models without any\nexternal information to signal environmental changes in advance. During\nlifelong learning, we employ the expectation maximization (EM) algorithm with\nonline Bayesian inference to update the mixture in a fully incremental manner.\nIn EM, the E-step involves estimating the posterior expectation of\nenvironment-to-cluster assignments, while the M-step updates the environment\nparameters for future learning. This method allows for all environment models\nto be adapted as necessary, with new models instantiated for environmental\nchanges and old models retrieved when previously seen environments are\nencountered again. Experiments demonstrate that LLIRL outperforms relevant\nexisting methods, and enables effective incremental adaptation to various\ndynamic environments for lifelong learning.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jul 2020 13:23:41 GMT"}, {"version": "v2", "created": "Fri, 12 Feb 2021 10:48:28 GMT"}], "update_date": "2021-02-15", "authors_parsed": [["Wang", "Zhi", ""], ["Chen", "Chunlin", ""], ["Dong", "Daoyi", ""]]}, {"id": "2007.14215", "submitter": "Muhammad Asim", "authors": "Muhammad Asim, Yong Wang, Kezhi Wang, and Pei-Qiu Huang", "title": "A Review on Computational Intelligence Techniques in Cloud and Edge\n  Computing", "comments": "Accepted by IEEE Transactions on Emerging Topics in Computational\n  Intelligence", "journal-ref": null, "doi": "10.1109/TETCI.2020.3007905", "report-no": null, "categories": "cs.DC cs.AI eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cloud computing (CC) is a centralized computing paradigm that accumulates\nresources centrally and provides these resources to users through Internet.\nAlthough CC holds a large number of resources, it may not be acceptable by\nreal-time mobile applications, as it is usually far away from users\ngeographically. On the other hand, edge computing (EC), which distributes\nresources to the network edge, enjoys increasing popularity in the applications\nwith low-latency and high-reliability requirements. EC provides resources in a\ndecentralized manner, which can respond to users' requirements faster than the\nnormal CC, but with limited computing capacities. As both CC and EC are\nresource-sensitive, several big issues arise, such as how to conduct job\nscheduling, resource allocation, and task offloading, which significantly\ninfluence the performance of the whole system. To tackle these issues, many\noptimization problems have been formulated. These optimization problems usually\nhave complex properties, such as non-convexity and NP-hardness, which may not\nbe addressed by the traditional convex optimization-based solutions.\nComputational intelligence (CI), consisting of a set of nature-inspired\ncomputational approaches, recently exhibits great potential in addressing these\noptimization problems in CC and EC. This paper provides an overview of research\nproblems in CC and EC and recent progresses in addressing them with the help of\nCI techniques. Informative discussions and future research trends are also\npresented, with the aim of offering insights to the readers and motivating new\nresearch directions.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jul 2020 09:29:21 GMT"}], "update_date": "2020-07-29", "authors_parsed": [["Asim", "Muhammad", ""], ["Wang", "Yong", ""], ["Wang", "Kezhi", ""], ["Huang", "Pei-Qiu", ""]]}, {"id": "2007.14244", "submitter": "Gabriel Paludo Licks", "authors": "Gabriel Paludo Licks and Felipe Meneguzzi", "title": "Automated Database Indexing using Model-free Reinforcement Learning", "comments": "8 pages, 5 figures (some have subfigures), 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Configuring databases for efficient querying is a complex task, often carried\nout by a database administrator. Solving the problem of building indexes that\ntruly optimize database access requires a substantial amount of database and\ndomain knowledge, the lack of which often results in wasted space and memory\nfor irrelevant indexes, possibly jeopardizing database performance for querying\nand certainly degrading performance for updating. We develop an architecture to\nsolve the problem of automatically indexing a database by using reinforcement\nlearning to optimize queries by indexing data throughout the lifetime of a\ndatabase. In our experimental evaluation, our architecture shows superior\nperformance compared to related work on reinforcement learning and genetic\nalgorithms, maintaining near-optimal index configurations and efficiently\nscaling to large databases.\n", "versions": [{"version": "v1", "created": "Sat, 25 Jul 2020 14:36:55 GMT"}], "update_date": "2020-07-29", "authors_parsed": [["Licks", "Gabriel Paludo", ""], ["Meneguzzi", "Felipe", ""]]}, {"id": "2007.14248", "submitter": "Teng Liu", "authors": "Teng Liu, Yang Xing, Long Chen, Dongpu Cao, Fei-Yue Wang", "title": "Defining Digital Quadruplets in the Cyber-Physical-Social Space for\n  Parallel Driving", "comments": "10 pages, 11 figures. arXiv admin note: text overlap with\n  arXiv:2007.10799", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Parallel driving is a novel framework to synthesize vehicle intelligence and\ntransport automation. This article aims to define digital quadruplets in\nparallel driving. In the cyber-physical-social systems (CPSS), based on the ACP\nmethod, the names of the digital quadruplets are first given, which are\ndescriptive, predictive, prescriptive and real vehicles. The objectives of the\nthree virtual digital vehicles are interacting, guiding, simulating and\nimproving with the real vehicles. Then, the three virtual components of the\ndigital quadruplets are introduced in detail and their applications are also\nillustrated. Finally, the real vehicles in the parallel driving system and the\nresearch process of the digital quadruplets are depicted. The presented digital\nquadruplets in parallel driving are expected to make the future connected\nautomated driving safety, efficiently and synergistically.\n", "versions": [{"version": "v1", "created": "Sun, 26 Jul 2020 23:07:42 GMT"}], "update_date": "2020-07-29", "authors_parsed": [["Liu", "Teng", ""], ["Xing", "Yang", ""], ["Chen", "Long", ""], ["Cao", "Dongpu", ""], ["Wang", "Fei-Yue", ""]]}, {"id": "2007.14268", "submitter": "Ole-Christoffer Granmo", "authors": "Xuan Zhang, Lei Jiao, Ole-Christoffer Granmo, and Morten Goodwin", "title": "On the Convergence of Tsetlin Machines for the IDENTITY- and NOT\n  Operators", "comments": "23 pages, 10 figures", "journal-ref": null, "doi": "10.1109/TPAMI.2021.3085591", "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Tsetlin Machine (TM) is a recent machine learning algorithm with several\ndistinct properties, such as interpretability, simplicity, and\nhardware-friendliness. Although numerous empirical evaluations report on its\nperformance, the mathematical analysis of its convergence is still open. In\nthis article, we analyze the convergence of the TM with only one clause\ninvolved for classification. More specifically, we examine two basic logical\noperators, namely, the \"IDENTITY\"- and \"NOT\" operators. Our analysis reveals\nthat the TM, with just one clause, can converge correctly to the intended\nlogical operator, learning from training data over an infinite time horizon.\nBesides, it can capture arbitrarily rare patterns and select the most accurate\none when two candidate patterns are incompatible, by configuring a granularity\nparameter. The analysis of the convergence of the two basic operators lays the\nfoundation for analyzing other logical operators. These analyses altogether,\nfrom a mathematical perspective, provide new insights on why TMs have obtained\nstate-of-the-art performance on several pattern recognition problems.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jul 2020 14:31:16 GMT"}, {"version": "v2", "created": "Mon, 7 Jun 2021 10:19:56 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Zhang", "Xuan", ""], ["Jiao", "Lei", ""], ["Granmo", "Ole-Christoffer", ""], ["Goodwin", "Morten", ""]]}, {"id": "2007.14290", "submitter": "Sashank Tirumala", "authors": "Sashank Tirumala, Sagar Gubbi, Kartik Paigwar, Aditya Sagi, Ashish\n  Joglekar, Shalabh Bhatnagar, Ashitava Ghosal, Bharadwaj Amrutur, Shishir\n  Kolathaya", "title": "Learning Stable Manoeuvres in Quadruped Robots from Expert\n  Demonstrations", "comments": "6 pages, Robot and Human Interaction Conference Italy 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the research into development of quadruped robots picking up pace,\nlearning based techniques are being explored for developing locomotion\ncontrollers for such robots. A key problem is to generate leg trajectories for\ncontinuously varying target linear and angular velocities, in a stable manner.\nIn this paper, we propose a two pronged approach to address this problem.\nFirst, multiple simpler policies are trained to generate trajectories for a\ndiscrete set of target velocities and turning radius. These policies are then\naugmented using a higher level neural network for handling the transition\nbetween the learned trajectories. Specifically, we develop a neural\nnetwork-based filter that takes in target velocity, radius and transforms them\ninto new commands that enable smooth transitions to the new trajectory. This\ntransformation is achieved by learning from expert demonstrations. An\napplication of this is the transformation of a novice user's input into an\nexpert user's input, thereby ensuring stable manoeuvres regardless of the\nuser's experience. Training our proposed architecture requires much less expert\ndemonstrations compared to standard neural network architectures. Finally, we\ndemonstrate experimentally these results in the in-house quadruped Stoch 2.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jul 2020 15:02:04 GMT"}], "update_date": "2020-07-29", "authors_parsed": [["Tirumala", "Sashank", ""], ["Gubbi", "Sagar", ""], ["Paigwar", "Kartik", ""], ["Sagi", "Aditya", ""], ["Joglekar", "Ashish", ""], ["Bhatnagar", "Shalabh", ""], ["Ghosal", "Ashitava", ""], ["Amrutur", "Bharadwaj", ""], ["Kolathaya", "Shishir", ""]]}, {"id": "2007.14302", "submitter": "Raeid Saqur", "authors": "Frank Rudzicz and Raeid Saqur", "title": "Ethics of Artificial Intelligence in Surgery", "comments": null, "journal-ref": "In Hashimoto D.A. (Ed.) Artificial Intelligence in Surgery: A\n  Primer for Surgical Practice. New York: McGraw Hill. ISBN: 978-1260452730\n  (2020)", "doi": null, "report-no": null, "categories": "cs.CY cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Here we discuss the four key principles of bio-medical ethics from surgical\ncontext. We elaborate on the definition of 'fairness' and its implications in\nAI system design, with taxonomy of algorithmic biases in AI. We discuss the\nshifts in ethical paradigms as the degree of autonomy in AI systems continue to\nevolve. We also emphasize the need for continuous revisions of ethics in AI due\nto evolution and dynamic nature of AI systems and technologies.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jul 2020 15:16:45 GMT"}], "update_date": "2020-07-29", "authors_parsed": [["Rudzicz", "Frank", ""], ["Saqur", "Raeid", ""]]}, {"id": "2007.14358", "submitter": "Gabriele Farina", "authors": "Gabriele Farina and Christian Kroer and Tuomas Sandholm", "title": "Faster Game Solving via Predictive Blackwell Approachability: Connecting\n  Regret Matching and Mirror Descent", "comments": "Full version. The body of the paper appeared in the proceedings of\n  the AAAI 2021 conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.AI cs.LG cs.MA math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Blackwell approachability is a framework for reasoning about repeated games\nwith vector-valued payoffs. We introduce predictive Blackwell approachability,\nwhere an estimate of the next payoff vector is given, and the decision maker\ntries to achieve better performance based on the accuracy of that estimator. In\norder to derive algorithms that achieve predictive Blackwell approachability,\nwe start by showing a powerful connection between four well-known algorithms.\nFollow-the-regularized-leader (FTRL) and online mirror descent (OMD) are the\nmost prevalent regret minimizers in online convex optimization. In spite of\nthis prevalence, the regret matching (RM) and regret matching+ (RM+) algorithms\nhave been preferred in the practice of solving large-scale games (as the local\nregret minimizers within the counterfactual regret minimization framework). We\nshow that RM and RM+ are the algorithms that result from running FTRL and OMD,\nrespectively, to select the halfspace to force at all times in the underlying\nBlackwell approachability game. By applying the predictive variants of FTRL or\nOMD to this connection, we obtain predictive Blackwell approachability\nalgorithms, as well as predictive variants of RM and RM+. In experiments across\n18 common zero-sum extensive-form benchmark games, we show that predictive RM+\ncoupled with counterfactual regret minimization converges vastly faster than\nthe fastest prior algorithms (CFR+, DCFR, LCFR) across all games but two of the\npoker games, sometimes by two or more orders of magnitude.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jul 2020 16:49:55 GMT"}, {"version": "v2", "created": "Mon, 8 Mar 2021 04:15:38 GMT"}], "update_date": "2021-03-09", "authors_parsed": [["Farina", "Gabriele", ""], ["Kroer", "Christian", ""], ["Sandholm", "Tuomas", ""]]}, {"id": "2007.14490", "submitter": "Mikayla Kelley", "authors": "Mikayla Kelley", "title": "On Accuracy and Coherence with Infinite Opinion Sets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.AI stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is a well-known equivalence between avoiding accuracy dominance and\nhaving probabilistically coherent credences (see, e.g., de Finetti 1974, Joyce\n2009, Predd et al. 2009, Schervish et al. 2009, Pettigrew 2016). However, this\nequivalence has been established only when the set of propositions on which\ncredence functions are defined is finite. In this paper, we establish\nconnections between accuracy dominance and coherence when credence functions\nare defined on an infinite set of propositions. In particular, we establish the\nnecessary results to extend the classic accuracy argument for probabilism\noriginally due to Joyce (1998) to certain classes of infinite sets of\npropositions including countably infinite partitions.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jul 2020 21:11:26 GMT"}], "update_date": "2020-07-30", "authors_parsed": [["Kelley", "Mikayla", ""]]}, {"id": "2007.14535", "submitter": "Masashi Okada Dr", "authors": "Masashi Okada, Tadahiro Taniguchi", "title": "Dreaming: Model-based Reinforcement Learning by Latent Imagination\n  without Reconstruction", "comments": "Accepted to ICRA2021. Camera ready version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the present paper, we propose a decoder-free extension of Dreamer, a\nleading model-based reinforcement learning (MBRL) method from pixels. Dreamer\nis a sample- and cost-efficient solution to robot learning, as it is used to\ntrain latent state-space models based on a variational autoencoder and to\nconduct policy optimization by latent trajectory imagination. However, this\nautoencoding based approach often causes object vanishing, in which the\nautoencoder fails to perceives key objects for solving control tasks, and thus\nsignificantly limiting Dreamer's potential. This work aims to relieve this\nDreamer's bottleneck and enhance its performance by means of removing the\ndecoder. For this purpose, we firstly derive a likelihood-free and InfoMax\nobjective of contrastive learning from the evidence lower bound of Dreamer.\nSecondly, we incorporate two components, (i) independent linear dynamics and\n(ii) the random crop data augmentation, to the learning scheme so as to improve\nthe training performance. In comparison to Dreamer and other recent model-free\nreinforcement learning methods, our newly devised Dreamer with InfoMax and\nwithout generative decoder (Dreaming) achieves the best scores on 5 difficult\nsimulated robotics tasks, in which Dreamer suffers from object vanishing.\n", "versions": [{"version": "v1", "created": "Wed, 29 Jul 2020 00:14:40 GMT"}, {"version": "v2", "created": "Fri, 12 Mar 2021 03:56:41 GMT"}], "update_date": "2021-03-15", "authors_parsed": [["Okada", "Masashi", ""], ["Taniguchi", "Tadahiro", ""]]}, {"id": "2007.14604", "submitter": "Lars Hertel", "authors": "Lars Hertel, Pierre Baldi, Daniel L. Gillen", "title": "Quantity vs. Quality: On Hyperparameter Optimization for Deep\n  Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning algorithms can show strong variation in performance\nbetween training runs with different random seeds. In this paper we explore how\nthis affects hyperparameter optimization when the goal is to find\nhyperparameter settings that perform well across random seeds. In particular,\nwe benchmark whether it is better to explore a large quantity of hyperparameter\nsettings via pruning of bad performers, or if it is better to aim for quality\nof collected results by using repetitions. For this we consider the Successive\nHalving, Random Search, and Bayesian Optimization algorithms, the latter two\nwith and without repetitions. We apply these to tuning the PPO2 algorithm on\nthe Cartpole balancing task and the Inverted Pendulum Swing-up task. We\ndemonstrate that pruning may negatively affect the optimization and that\nrepeated sampling does not help in finding hyperparameter settings that perform\nbetter across random seeds. From our experiments we conclude that Bayesian\noptimization with a noise robust acquisition function is the best choice for\nhyperparameter optimization in reinforcement learning tasks.\n", "versions": [{"version": "v1", "created": "Wed, 29 Jul 2020 05:12:34 GMT"}, {"version": "v2", "created": "Thu, 30 Jul 2020 06:16:00 GMT"}], "update_date": "2020-07-31", "authors_parsed": [["Hertel", "Lars", ""], ["Baldi", "Pierre", ""], ["Gillen", "Daniel L.", ""]]}, {"id": "2007.14632", "submitter": "Guido Schillaci", "authors": "Guido Schillaci and Alejandra Ciria and Bruno Lara", "title": "Tracking Emotions: Intrinsic Motivation Grounded on Multi-Level\n  Prediction Error Dynamics", "comments": "Accepted for publication at the 10th Joint IEEE International\n  Conference on Development and Learning and Epigenetic Robotics (ICDL-EPIROB\n  2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  How do cognitive agents decide what is the relevant information to learn and\nhow goals are selected to gain this knowledge? Cognitive agents need to be\nmotivated to perform any action. We discuss that emotions arise when\ndifferences between expected and actual rates of progress towards a goal are\nexperienced. Therefore, the tracking of prediction error dynamics has a tight\nrelationship with emotions. Here, we suggest that the tracking of prediction\nerror dynamics allows an artificial agent to be intrinsically motivated to seek\nnew experiences but constrained to those that generate reducible prediction\nerror.We present an intrinsic motivation architecture that generates behaviors\ntowards self-generated and dynamic goals and that regulates goal selection and\nthe balance between exploitation and exploration through multi-level monitoring\nof prediction error dynamics. This new architecture modulates exploration noise\nand leverages computational resources according to the dynamics of the overall\nperformance of the learning system. Additionally, it establishes a possible\nsolution to the temporal dynamics of goal selection. The results of the\nexperiments presented here suggest that this architecture outperforms intrinsic\nmotivation approaches where exploratory noise and goals are fixed and a greedy\nstrategy is applied.\n", "versions": [{"version": "v1", "created": "Wed, 29 Jul 2020 06:53:13 GMT"}], "update_date": "2020-07-30", "authors_parsed": [["Schillaci", "Guido", ""], ["Ciria", "Alejandra", ""], ["Lara", "Bruno", ""]]}, {"id": "2007.14677", "submitter": "Kostas Kolomvatsos", "authors": "Anna Karanika, Panagiotis Oikonomou, Kostas Kolomvatsos, Christos\n  Anagnostopoulos", "title": "On the Use of Interpretable Machine Learning for the Management of Data\n  Quality", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data quality is a significant issue for any application that requests for\nanalytics to support decision making. It becomes very important when we focus\non Internet of Things (IoT) where numerous devices can interact to exchange and\nprocess data. IoT devices are connected to Edge Computing (EC) nodes to report\nthe collected data, thus, we have to secure data quality not only at the IoT\nbut also at the edge of the network. In this paper, we focus on the specific\nproblem and propose the use of interpretable machine learning to deliver the\nfeatures that are important to be based for any data processing activity. Our\naim is to secure data quality, at least, for those features that are detected\nas significant in the collected datasets. We have to notice that the selected\nfeatures depict the highest correlation with the remaining in every dataset,\nthus, they can be adopted for dimensionality reduction. We focus on multiple\nmethodologies for having interpretability in our learning models and adopt an\nensemble scheme for the final decision. Our scheme is capable of timely\nretrieving the final result and efficiently select the appropriate features. We\nevaluate our model through extensive simulations and present numerical results.\nOur aim is to reveal its performance under various experimental scenarios that\nwe create varying a set of parameters adopted in our mechanism.\n", "versions": [{"version": "v1", "created": "Wed, 29 Jul 2020 08:49:32 GMT"}], "update_date": "2020-07-30", "authors_parsed": [["Karanika", "Anna", ""], ["Oikonomou", "Panagiotis", ""], ["Kolomvatsos", "Kostas", ""], ["Anagnostopoulos", "Christos", ""]]}, {"id": "2007.14778", "submitter": "Nadjet Bourdache", "authors": "Nadjet Bourdache, Patrice Perny and Olivier Spanjaard", "title": "Bayesian preference elicitation for multiobjective combinatorial\n  optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new incremental preference elicitation procedure able to deal\nwith noisy responses of a Decision Maker (DM). The originality of the\ncontribution is to propose a Bayesian approach for determining a preferred\nsolution in a multiobjective decision problem involving a combinatorial set of\nalternatives. We assume that the preferences of the DM are represented by an\naggregation function whose parameters are unknown and that the uncertainty\nabout them is represented by a density function on the parameter space.\nPairwise comparison queries are used to reduce this uncertainty (by Bayesian\nrevision). The query selection strategy is based on the solution of a mixed\ninteger linear program with a combinatorial set of variables and constraints,\nwhich requires to use columns and constraints generation methods. Numerical\ntests are provided to show the practicability of the approach.\n", "versions": [{"version": "v1", "created": "Wed, 29 Jul 2020 12:28:37 GMT"}], "update_date": "2020-07-30", "authors_parsed": [["Bourdache", "Nadjet", ""], ["Perny", "Patrice", ""], ["Spanjaard", "Olivier", ""]]}, {"id": "2007.14791", "submitter": "Shailesh Tripathi", "authors": "Shailesh Tripathi, David Muhr, Brunner Manuel, Frank Emmert-Streib,\n  Herbert Jodlbauer, and Matthias Dehmer", "title": "Ensuring the Robustness and Reliability of Data-Driven Knowledge\n  Discovery Models in Production and Manufacturing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The implementation of robust, stable, and user-centered data analytics and\nmachine learning models is confronted by numerous challenges in production and\nmanufacturing. Therefore, a systematic approach is required to develop,\nevaluate, and deploy such models. The data-driven knowledge discovery framework\nprovides an orderly partition of the data-mining processes to ensure the\npractical implementation of data analytics and machine learning models.\nHowever, the practical application of robust industry-specific data-driven\nknowledge discovery models faces multiple data-- and model-development--related\nissues. These issues should be carefully addressed by allowing a flexible,\ncustomized, and industry-specific knowledge discovery framework; in our case,\nthis takes the form of the cross-industry standard process for data mining\n(CRISP-DM). This framework is designed to ensure active cooperation between\ndifferent phases to adequately address data- and model-related issues. In this\npaper, we review several extensions of CRISP-DM models and various\ndata-robustness-- and model-robustness--related problems in machine learning,\nwhich currently lacks proper cooperation between data experts and business\nexperts because of the limitations of data-driven knowledge discovery models.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jul 2020 14:21:14 GMT"}], "update_date": "2020-08-03", "authors_parsed": [["Tripathi", "Shailesh", ""], ["Muhr", "David", ""], ["Manuel", "Brunner", ""], ["Emmert-Streib", "Frank", ""], ["Jodlbauer", "Herbert", ""], ["Dehmer", "Matthias", ""]]}, {"id": "2007.14928", "submitter": "Thomas Roehr", "authors": "Thomas M. Roehr, Daniel Harnack, Hendrik W\\\"ohrle, Felix Wiebe, Moritz\n  Schilling, Oscar Lima, Malte Langosz, Shivesh Kumar, Sirko Straube, Frank\n  Kirchner", "title": "A Development Cycle for Automated Self-Exploration of Robot Behaviors", "comments": "30 pages, 16 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we introduce Q-Rock, a development cycle for the automated\nself-exploration and qualification of robot behaviors. With Q-Rock, we suggest\na novel, integrative approach to automate robot development processes. Q-Rock\ncombines several machine learning and reasoning techniques to deal with the\nincreasing complexity in the design of robotic systems. The Q-Rock development\ncycle consists of three complementary processes: (1) automated exploration of\ncapabilities that a given robotic hardware provides, (2) classification and\nsemantic annotation of these capabilities to generate more complex behaviors,\nand (3) mapping between application requirements and available behaviors. These\nprocesses are based on a graph-based representation of a robot's structure,\nincluding hardware and software components. A central, scalable knowledge base\nenables collaboration of robot designers including mechanical, electrical and\nsystems engineers, software developers and machine learning experts. In this\npaper we formalize Q-Rock's integrative development cycle and highlight its\nbenefits with a proof-of-concept implementation and a use case demonstration.\n", "versions": [{"version": "v1", "created": "Wed, 29 Jul 2020 16:01:52 GMT"}, {"version": "v2", "created": "Sun, 21 Mar 2021 00:33:52 GMT"}], "update_date": "2021-03-23", "authors_parsed": [["Roehr", "Thomas M.", ""], ["Harnack", "Daniel", ""], ["W\u00f6hrle", "Hendrik", ""], ["Wiebe", "Felix", ""], ["Schilling", "Moritz", ""], ["Lima", "Oscar", ""], ["Langosz", "Malte", ""], ["Kumar", "Shivesh", ""], ["Straube", "Sirko", ""], ["Kirchner", "Frank", ""]]}, {"id": "2007.15030", "submitter": "Eugenio Mart\\'inez-C\\'amara", "authors": "Nuria Rodr\\'iguez-Barroso, Eugenio Mart\\'inez-C\\'amara, M. Victoria\n  Luz\\'on, Gerardo Gonz\\'alez Seco, Miguel \\'Angel Veganzones, Francisco\n  Herrera", "title": "Dynamic Federated Learning Model for Identifying Adversarial Clients", "comments": "11 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated learning, as a distributed learning that conducts the training on\nthe local devices without accessing to the training data, is vulnerable to\ndirty-label data poisoning adversarial attacks. We claim that the federated\nlearning model has to avoid those kind of adversarial attacks through filtering\nout the clients that manipulate the local data. We propose a dynamic federated\nlearning model that dynamically discards those adversarial clients, which\nallows to prevent the corruption of the global learning model. We evaluate the\ndynamic discarding of adversarial clients deploying a deep learning\nclassification model in a federated learning setting, and using the EMNIST\nDigits and Fashion MNIST image classification datasets. Likewise, we analyse\nthe capacity of detecting clients with poor data distribution and reducing the\nnumber of rounds of learning by selecting the clients to aggregate. The results\nshow that the dynamic selection of the clients to aggregate enhances the\nperformance of the global learning model, discards the adversarial and poor\nclients and reduces the rounds of learning.\n", "versions": [{"version": "v1", "created": "Wed, 29 Jul 2020 18:02:11 GMT"}], "update_date": "2020-07-31", "authors_parsed": [["Rodr\u00edguez-Barroso", "Nuria", ""], ["Mart\u00ednez-C\u00e1mara", "Eugenio", ""], ["Luz\u00f3n", "M. Victoria", ""], ["Seco", "Gerardo Gonz\u00e1lez", ""], ["Veganzones", "Miguel \u00c1ngel", ""], ["Herrera", "Francisco", ""]]}, {"id": "2007.15048", "submitter": "Krzysztof Kutt", "authors": "Krzysztof Kutt (1), Dominika Dr\\k{a}\\.zyk (1), Maciej Szel\\k{a}\\.zek\n  (2), Szymon Bobek (1), Grzegorz J. Nalepa (1) ((1) Jagiellonian University,\n  Poland, (2) AGH University of Science and Technology, Poland)", "title": "The BIRAFFE2 Experiment. Study in Bio-Reactions and Faces for\n  Emotion-based Personalization for AI Systems", "comments": "Presented during the Human-AI Interaction Workshop at ECAI 2020;\n  Acknowledgements added", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper describes BIRAFFE2 data set, which is a result of an affective\ncomputing experiment conducted between 2019 and 2020, that aimed to develop\ncomputer models for classification and recognition of emotion. Such work is\nimportant to develop new methods of natural Human-AI interaction. As we believe\nthat models of emotion should be personalized by design, we present an unified\nparadigm allowing to capture emotional responses of different persons, taking\nindividual personality differences into account. We combine classical\npsychological paradigms of emotional response collection with the newer\napproach, based on the observation of the computer game player. By capturing\nones psycho-physiological reactions (ECG, EDA signal recording), mimic\nexpressions (facial emotion recognition), subjective valence-arousal balance\nratings (widget ratings) and gameplay progression (accelerometer and screencast\nrecording), we provide a framework that can be easily used and developed for\nthe purpose of the machine learning methods.\n", "versions": [{"version": "v1", "created": "Wed, 29 Jul 2020 18:35:34 GMT"}, {"version": "v2", "created": "Mon, 9 Nov 2020 20:11:03 GMT"}], "update_date": "2020-11-11", "authors_parsed": [["Kutt", "Krzysztof", ""], ["Dr\u0105\u017cyk", "Dominika", ""], ["Szel\u0105\u017cek", "Maciej", ""], ["Bobek", "Szymon", ""], ["Nalepa", "Grzegorz J.", ""]]}, {"id": "2007.15071", "submitter": "Bahare Salmani", "authors": "Bahare Salmani and Joost-Pieter Katoen", "title": "Bayesian Inference by Symbolic Model Checking", "comments": "Conference: QEST 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper applies probabilistic model checking techniques for discrete\nMarkov chains to inference in Bayesian networks. We present a simple\ntranslation from Bayesian networks into tree-like Markov chains such that\ninference can be reduced to computing reachability probabilities. Using a\nprototypical implementation on top of the Storm model checker, we show that\nsymbolic data structures such as multi-terminal BDDs (MTBDDs) are very\neffective to perform inference on large Bayesian network benchmarks. We compare\nour result to inference using probabilistic sentential decision diagrams and\nvtrees, a scalable symbolic technique in AI inference tools.\n", "versions": [{"version": "v1", "created": "Wed, 29 Jul 2020 19:38:17 GMT"}], "update_date": "2020-07-31", "authors_parsed": [["Salmani", "Bahare", ""], ["Katoen", "Joost-Pieter", ""]]}, {"id": "2007.15140", "submitter": "Alexey Ignatiev", "authors": "Jinqiang Yu, Alexey Ignatiev, Peter J. Stuckey, Pierre Le Bodic", "title": "Computing Optimal Decision Sets with SAT", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As machine learning is increasingly used to help make decisions, there is a\ndemand for these decisions to be explainable. Arguably, the most explainable\nmachine learning models use decision rules. This paper focuses on decision\nsets, a type of model with unordered rules, which explains each prediction with\na single rule. In order to be easy for humans to understand, these rules must\nbe concise. Earlier work on generating optimal decision sets first minimizes\nthe number of rules, and then minimizes the number of literals, but the\nresulting rules can often be very large. Here we consider a better measure,\nnamely the total size of the decision set in terms of literals. So we are not\ndriven to a small set of rules which require a large number of literals. We\nprovide the first approach to determine minimum-size decision sets that achieve\nminimum empirical risk and then investigate sparse alternatives where we trade\naccuracy for size. By finding optimal solutions we show we can build decision\nset classifiers that are almost as accurate as the best heuristic methods, but\nfar more concise, and hence more explainable.\n", "versions": [{"version": "v1", "created": "Wed, 29 Jul 2020 22:35:22 GMT"}], "update_date": "2020-07-31", "authors_parsed": [["Yu", "Jinqiang", ""], ["Ignatiev", "Alexey", ""], ["Stuckey", "Peter J.", ""], ["Bodic", "Pierre Le", ""]]}, {"id": "2007.15185", "submitter": "Huimin Fu", "authors": "Huimin Fu, Yang Xu, Jun Liu, Guanfeng Wu, Sutcliffe Geoff", "title": "Improving probability selecting based weights for Satisfiability Problem", "comments": null, "journal-ref": null, "doi": null, "report-no": "arXiv:2007.15185", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Boolean Satisfiability problem (SAT) is important on artificial\nintelligence community and the impact of its solving on complex problems.\nRecently, great breakthroughs have been made respectively on stochastic local\nsearch (SLS) algorithms for uniform random k-SAT resulting in several\nstate-of-the-art SLS algorithms Score2SAT, YalSAT, ProbSAT, CScoreSAT and on a\nhybrid algorithm for hard random SAT (HRS) resulting in one state-of-the-art\nhybrid algorithm SparrowToRiss. However, there is no an algorithm which can\neffectively solve both uniform random k-SAT and HRS. In this paper, we present\na new SLS algorithm named SelectNTS for uniform random k-SAT and HRS. SelectNTS\nis an improved probability selecting based local search algorithm for SAT\nproblem. The core of SelectNTS relies on new clause and variable selection\nheuristics. The new clause selection heuristic uses a new clause weighting\nscheme and a biased random walk. The new variable selection heuristic uses a\nprobability selecting strategy with the variation of CC strategy based on a new\nvariable weighting scheme. Extensive experimental results on the well-known\nrandom benchmarks instances from the SAT Competitions in 2017 and 2018, and on\nrandomly generated problems, show that our algorithm outperforms\nstate-of-the-art random SAT algorithms, and our SelectNTS can effectively solve\nboth uniform random k-SAT and HRS.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jul 2020 02:23:07 GMT"}], "update_date": "2020-08-05", "authors_parsed": [["Fu", "Huimin", ""], ["Xu", "Yang", ""], ["Liu", "Jun", ""], ["Wu", "Guanfeng", ""], ["Geoff", "Sutcliffe", ""]]}, {"id": "2007.15189", "submitter": "Guangyin Jin", "authors": "Guangyin Jin, Zhexu Xi, Hengyu Sha, Yanghe Feng, Jincai Huang", "title": "Deep Multi-View Spatiotemporal Virtual Graph Neural Network for\n  Significant Citywide Ride-hailing Demand Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Urban ride-hailing demand prediction is a crucial but challenging task for\nintelligent transportation system construction. Predictable ride-hailing demand\ncan facilitate more reasonable vehicle scheduling and online car-hailing\nplatform dispatch. Conventional deep learning methods with no external\nstructured data can be accomplished via hybrid models of CNNs and RNNs by\nmeshing plentiful pixel-level labeled data, but spatial data sparsity and\nlimited learning capabilities on temporal long-term dependencies are still two\nstriking bottlenecks. To address these limitations, we propose a new virtual\ngraph modeling method to focus on significant demand regions and a novel Deep\nMulti-View Spatiotemporal Virtual Graph Neural Network (DMVST-VGNN) to\nstrengthen learning capabilities of spatial dynamics and temporal long-term\ndependencies. Specifically, DMVST-VGNN integrates the structures of 1D\nConvolutional Neural Network, Multi Graph Attention Neural Network and\nTransformer layer, which correspond to short-term temporal dynamics view,\nspatial dynamics view and long-term temporal dynamics view respectively. In\nthis paper, experiments are conducted on two large-scale New York City datasets\nin fine-grained prediction scenes. And the experimental results demonstrate\neffectiveness and superiority of DMVST-VGNN framework in significant citywide\nride-hailing demand prediction.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jul 2020 02:37:05 GMT"}, {"version": "v2", "created": "Mon, 3 Aug 2020 01:25:17 GMT"}, {"version": "v3", "created": "Thu, 20 Aug 2020 14:20:49 GMT"}, {"version": "v4", "created": "Wed, 2 Sep 2020 12:56:57 GMT"}, {"version": "v5", "created": "Thu, 10 Sep 2020 01:53:20 GMT"}], "update_date": "2020-09-11", "authors_parsed": [["Jin", "Guangyin", ""], ["Xi", "Zhexu", ""], ["Sha", "Hengyu", ""], ["Feng", "Yanghe", ""], ["Huang", "Jincai", ""]]}, {"id": "2007.15203", "submitter": "Vijay  Menon", "authors": "Vijay Menon and Kate Larson", "title": "Algorithmic Stability in Fair Allocation of Indivisible Goods Among Two\n  Agents", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.AI cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many allocation problems in multiagent systems rely on agents specifying\ncardinal preferences. However, allocation mechanisms can be sensitive to small\nperturbations in cardinal preferences, thus causing agents who make ``small\" or\n``innocuous\" mistakes while reporting their preferences to experience a large\nchange in their utility for the final outcome. To address this, we introduce a\nnotion of algorithmic stability and study it in the context of fair and\nefficient allocations of indivisible goods among two agents. We show that it is\nimpossible to achieve exact stability along with even a weak notion of fairness\nand even approximate efficiency. As a result, we propose two relaxations to\nstability, namely, approximate-stability and weak-approximate-stability, and\nshow how existing algorithms in the fair division literature that guarantee\nfair and efficient outcomes perform poorly with respect to these relaxations.\nThis leads us to explore the possibility of designing new algorithms that are\nmore stable. Towards this end, we present a general characterization result for\npairwise maximin share allocations, and in turn use it to design an algorithm\nthat is approximately-stable and guarantees a pairwise maximin share and Pareto\noptimal allocation for two agents. Finally, we present a simple framework that\ncan be used to modify existing fair and efficient algorithms in order to ensure\nthat they also achieve weak-approximate-stability.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jul 2020 03:09:02 GMT"}, {"version": "v2", "created": "Mon, 12 Jul 2021 15:58:27 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Menon", "Vijay", ""], ["Larson", "Kate", ""]]}, {"id": "2007.15211", "submitter": "Victor Dibia", "authors": "Victor Dibia", "title": "NeuralQA: A Usable Library for Question Answering (Contextual Query\n  Expansion + BERT) on Large Datasets", "comments": "Published at Proceedings of the 2020 Conference on Empirical Methods\n  in Natural Language Processing: System Demonstrations. (EMNLP 2020), Demo\n  track. 8 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.HC cs.IR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Existing tools for Question Answering (QA) have challenges that limit their\nuse in practice. They can be complex to set up or integrate with existing\ninfrastructure, do not offer configurable interactive interfaces, and do not\ncover the full set of subtasks that frequently comprise the QA pipeline (query\nexpansion, retrieval, reading, and explanation/sensemaking). To help address\nthese issues, we introduce NeuralQA - a usable library for QA on large\ndatasets. NeuralQA integrates well with existing infrastructure (e.g.,\nElasticSearch instances and reader models trained with the HuggingFace\nTransformers API) and offers helpful defaults for QA subtasks. It introduces\nand implements contextual query expansion (CQE) using a masked language model\n(MLM) as well as relevant snippets (RelSnip) - a method for condensing large\ndocuments into smaller passages that can be speedily processed by a document\nreader model. Finally, it offers a flexible user interface to support workflows\nfor research explorations (e.g., visualization of gradient-based explanations\nto support qualitative inspection of model behaviour) and large scale search\ndeployment. Code and documentation for NeuralQA is available as open source on\nGithub (https://github.com/victordibia/neuralqa}{Github).\n", "versions": [{"version": "v1", "created": "Thu, 30 Jul 2020 03:38:30 GMT"}, {"version": "v2", "created": "Sat, 28 Nov 2020 03:06:09 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Dibia", "Victor", ""]]}, {"id": "2007.15221", "submitter": "Quoc-Viet Pham", "authors": "Quoc-Viet Pham, Dinh C. Nguyen, Seyedali Mirjalili, Dinh Thai Hoang,\n  Diep N. Nguyen, Pubudu N. Pathirana, Won-Joo Hwang", "title": "Swarm Intelligence for Next-Generation Wireless Networks: Recent\n  Advances and Applications", "comments": "Submitted to the IEEE for possible publication. Copyright may be\n  transferred without notice, after which this version may no longer be\n  accessible", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to the proliferation of smart devices and emerging applications, many\nnext-generation technologies have been paid for the development of wireless\nnetworks. Even though commercial 5G has just been widely deployed in some\ncountries, there have been initial efforts from academia and industrial\ncommunities for 6G systems. In such a network, a very large number of devices\nand applications are emerged, along with heterogeneity of technologies,\narchitectures, mobile data, etc., and optimizing such a network is of utmost\nimportance. Besides convex optimization and game theory, swarm intelligence\n(SI) has recently appeared as a promising optimization tool for wireless\nnetworks. As a new subdivision of artificial intelligence, SI is inspired by\nthe collective behaviors of societies of biological species. In SI, simple\nagents with limited capabilities would achieve intelligent strategies for\nhigh-dimensional and challenging problems, so it has recently found many\napplications in next-generation wireless networks (NGN). However, researchers\nmay not be completely aware of the full potential of SI techniques. In this\nwork, our primary focus will be the integration of these two domains: NGN and\nSI. Firstly, we provide an overview of SI techniques from fundamental concepts\nto well-known optimizers. Secondly, we review the applications of SI to settle\nemerging issues in NGN, including spectrum management and resource allocation,\nwireless caching and edge computing, network security, and several other\nmiscellaneous issues. Finally, we highlight open challenges and issues in the\nliterature, and introduce some interesting directions for future research.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jul 2020 04:32:49 GMT"}], "update_date": "2020-07-31", "authors_parsed": [["Pham", "Quoc-Viet", ""], ["Nguyen", "Dinh C.", ""], ["Mirjalili", "Seyedali", ""], ["Hoang", "Dinh Thai", ""], ["Nguyen", "Diep N.", ""], ["Pathirana", "Pubudu N.", ""], ["Hwang", "Won-Joo", ""]]}, {"id": "2007.15236", "submitter": "Andr\\'es Villa", "authors": "Andr\\'es Villa, Vladimir Araujo, Francisca Cattan, Denis Parra", "title": "Interpretable Contextual Team-aware Item Recommendation: Application in\n  Multiplayer Online Battle Arena Games", "comments": null, "journal-ref": null, "doi": "10.1145/3383313.3412211", "report-no": null, "categories": "cs.IR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The video game industry has adopted recommendation systems to boost users\ninterest with a focus on game sales. Other exciting applications within video\ngames are those that help the player make decisions that would maximize their\nplaying experience, which is a desirable feature in real-time strategy video\ngames such as Multiplayer Online Battle Arena (MOBA) like as DotA and LoL.\nAmong these tasks, the recommendation of items is challenging, given both the\ncontextual nature of the game and how it exposes the dependence on the\nformation of each team. Existing works on this topic do not take advantage of\nall the available contextual match data and dismiss potentially valuable\ninformation. To address this problem we develop TTIR, a contextual recommender\nmodel derived from the Transformer neural architecture that suggests a set of\nitems to every team member, based on the contexts of teams and roles that\ndescribe the match. TTIR outperforms several approaches and provides\ninterpretable recommendations through visualization of attention weights. Our\nevaluation indicates that both the Transformer architecture and the contextual\ninformation are essential to get the best results for this item recommendation\ntask. Furthermore, a preliminary user survey indicates the usefulness of\nattention weights for explaining recommendations as well as ideas for future\nwork. The code and dataset are available at:\nhttps://github.com/ojedaf/IC-TIR-Lol.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jul 2020 05:17:28 GMT"}], "update_date": "2020-07-31", "authors_parsed": [["Villa", "Andr\u00e9s", ""], ["Araujo", "Vladimir", ""], ["Cattan", "Francisca", ""], ["Parra", "Denis", ""]]}, {"id": "2007.15264", "submitter": "Sanghyun Park", "authors": "Sanghyun Park and Phanish Puranam", "title": "Learning what they think vs. learning what they do: The\n  micro-foundations of vicarious learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "econ.TH cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Vicarious learning is a vital component of organizational learning. We\ntheorize and model two fundamental processes underlying vicarious learning:\nobservation of actions (learning what they do) vs. belief sharing (learning\nwhat they think). The analysis of our model points to three key insights.\nFirst, vicarious learning through either process is beneficial even when no\nagent in a system of vicarious learners begins with a knowledge advantage.\nSecond, vicarious learning through belief sharing is not universally better\nthan mutual observation of actions and outcomes. Specifically, enabling mutual\nobservability of actions and outcomes is superior to sharing of beliefs when\nthe task environment features few alternatives with large differences in their\nvalue and there are no time pressures. Third, symmetry in vicarious learning in\nfact adversely affects belief sharing but improves observational learning. All\nthree results are shown to be the consequence of how vicarious learning affects\nself-confirming biased beliefs.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jul 2020 07:06:01 GMT"}, {"version": "v2", "created": "Fri, 31 Jul 2020 00:50:20 GMT"}], "update_date": "2020-08-03", "authors_parsed": [["Park", "Sanghyun", ""], ["Puranam", "Phanish", ""]]}, {"id": "2007.15270", "submitter": "Gopiram Roshan Lal", "authors": "G Roshan Lal and Sahin Cem Geyik and Krishnaram Kenthapadi", "title": "Fairness-Aware Online Personalization", "comments": "Accepted in RecSys 2020, FAccTRec Workshop: Responsible\n  Recommendation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Decision making in crucial applications such as lending, hiring, and college\nadmissions has witnessed increasing use of algorithmic models and techniques as\na result of a confluence of factors such as ubiquitous connectivity, ability to\ncollect, aggregate, and process large amounts of fine-grained data using cloud\ncomputing, and ease of access to applying sophisticated machine learning\nmodels. Quite often, such applications are powered by search and recommendation\nsystems, which in turn make use of personalized ranking algorithms. At the same\ntime, there is increasing awareness about the ethical and legal challenges\nposed by the use of such data-driven systems. Researchers and practitioners\nfrom different disciplines have recently highlighted the potential for such\nsystems to discriminate against certain population groups, due to biases in the\ndatasets utilized for learning their underlying recommendation models. We\npresent a study of fairness in online personalization settings involving the\nranking of individuals. Starting from a fair warm-start machine-learned model,\nwe first demonstrate that online personalization can cause the model to learn\nto act in an unfair manner if the user is biased in his/her responses. For this\npurpose, we construct a stylized model for generating training data with\npotentially biased features as well as potentially biased labels and quantify\nthe extent of bias that is learned by the model when the user responds in a\nbiased manner as in many real-world scenarios. We then formulate the problem of\nlearning personalized models under fairness constraints and present a\nregularization based approach for mitigating biases in machine learning. We\ndemonstrate the efficacy of our approach through extensive simulations with\ndifferent parameter settings. Code:\nhttps://github.com/groshanlal/Fairness-Aware-Online-Personalization\n", "versions": [{"version": "v1", "created": "Thu, 30 Jul 2020 07:16:17 GMT"}, {"version": "v2", "created": "Sun, 6 Sep 2020 10:03:27 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Lal", "G Roshan", ""], ["Geyik", "Sahin Cem", ""], ["Kenthapadi", "Krishnaram", ""]]}, {"id": "2007.15280", "submitter": "Xi Victoria Lin", "authors": "Jichuan Zeng, Xi Victoria Lin, Caiming Xiong, Richard Socher, Michael\n  R. Lyu, Irwin King, Steven C.H. Hoi", "title": "Photon: A Robust Cross-Domain Text-to-SQL System", "comments": "ACL 2020 system demonstration paper extended . The first two authors\n  contributed equally to this work", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Natural language interfaces to databases (NLIDB) democratize end user access\nto relational data. Due to fundamental differences between natural language\ncommunication and programming, it is common for end users to issue questions\nthat are ambiguous to the system or fall outside the semantic scope of its\nunderlying query language. We present Photon, a robust, modular, cross-domain\nNLIDB that can flag natural language input to which a SQL mapping cannot be\nimmediately determined. Photon consists of a strong neural semantic parser\n(63.2\\% structure accuracy on the Spider dev benchmark), a human-in-the-loop\nquestion corrector, a SQL executor and a response generator. The question\ncorrector is a discriminative neural sequence editor which detects confusion\nspan(s) in the input question and suggests rephrasing until a translatable\ninput is given by the user or a maximum number of iterations are conducted.\nExperiments on simulated data show that the proposed method effectively\nimproves the robustness of text-to-SQL system against untranslatable user\ninput. The live demo of our system is available at http://naturalsql.com.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jul 2020 07:44:48 GMT"}, {"version": "v2", "created": "Mon, 3 Aug 2020 08:59:06 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Zeng", "Jichuan", ""], ["Lin", "Xi Victoria", ""], ["Xiong", "Caiming", ""], ["Socher", "Richard", ""], ["Lyu", "Michael R.", ""], ["King", "Irwin", ""], ["Hoi", "Steven C. H.", ""]]}, {"id": "2007.15338", "submitter": "Andrey Chupakhin", "authors": "A. Chupakhin, A. Kolosov, R. Smeliansky, V. Antonenko, G. Ishelev", "title": "New approach to MPI program execution time prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.AI cs.LG cs.NI cs.SY eess.SY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The problem of MPI programs execution time prediction on a certain set of\ncomputer installations is considered. This problem emerges with orchestration\nand provisioning a virtual infrastructure in a cloud computing environment over\na heterogeneous network of computer installations: supercomputers or clusters\nof servers (e.g. mini data centers). One of the key criteria for the\neffectiveness of the cloud computing environment is the time staying by the\nprogram inside the environment. This time consists of the waiting time in the\nqueue and the execution time on the selected physical computer installation, to\nwhich the computational resource of the virtual infrastructure is dynamically\nmapped. One of the components of this problem is the estimation of the MPI\nprograms execution time on a certain set of computer installations. This is\nnecessary to determine a proper choice of order and place for program\nexecution. The article proposes two new approaches to the program execution\ntime prediction problem. The first one is based on computer installations\ngrouping based on the Pearson correlation coefficient. The second one is based\non vector representations of computer installations and MPI programs, so-called\nembeddings. The embedding technique is actively used in recommendation systems,\nsuch as for goods (Amazon), for articles (Arxiv.org), for videos (YouTube,\nNetflix). The article shows how the embeddings technique helps to predict the\nexecution time of a MPI program on a certain set of computer installations.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jul 2020 09:35:08 GMT"}], "update_date": "2020-07-31", "authors_parsed": [["Chupakhin", "A.", ""], ["Kolosov", "A.", ""], ["Smeliansky", "R.", ""], ["Antonenko", "V.", ""], ["Ishelev", "G.", ""]]}, {"id": "2007.15375", "submitter": "Maxime Petit", "authors": "Maxime Petit, Emmanuel Dellandrea and Liming Chen", "title": "Bayesian Optimization for Developmental Robotics with Meta-Learning by\n  Parameters Bounds Reduction", "comments": "Accepted at the IEEE International Conference on Development and\n  Learning and Epigenetic Robotics 2020 (ICDL-Epirob 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In robotics, methods and softwares usually require optimizations of\nhyperparameters in order to be efficient for specific tasks, for instance\nindustrial bin-picking from homogeneous heaps of different objects. We present\na developmental framework based on long-term memory and reasoning modules\n(Bayesian Optimisation, visual similarity and parameters bounds reduction)\nallowing a robot to use meta-learning mechanism increasing the efficiency of\nsuch continuous and constrained parameters optimizations. The new optimization,\nviewed as a learning for the robot, can take advantage of past experiences\n(stored in the episodic and procedural memories) to shrink the search space by\nusing reduced parameters bounds computed from the best optimizations realized\nby the robot with similar tasks of the new one (e.g. bin-picking from an\nhomogenous heap of a similar object, based on visual similarity of objects\nstored in the semantic memory). As example, we have confronted the system to\nthe constrained optimizations of 9 continuous hyperparameters for a\nprofessional software (Kamido) in industrial robotic arm bin-picking tasks, a\nstep that is needed each time to handle correctly new object. We used a\nsimulator to create bin-picking tasks for 8 different objects (7 in simulation\nand one with real setup, without and with meta-learning with experiences coming\nfrom other similar objects) achieving goods results despite a very small\noptimization budget, with a better performance reached when meta-learning is\nused (84.3% vs 78.9% of success overall, with a small budget of 30 iterations\nfor each optimization) for every object tested (p-value=0.036).\n", "versions": [{"version": "v1", "created": "Thu, 30 Jul 2020 10:55:56 GMT"}], "update_date": "2020-07-31", "authors_parsed": [["Petit", "Maxime", ""], ["Dellandrea", "Emmanuel", ""], ["Chen", "Liming", ""]]}, {"id": "2007.15393", "submitter": "Andres Garcia-Camino", "authors": "Andr\\'es Garc\\'ia-Camino", "title": "Social Choice Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": "report-02", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Social choice is the theory about collective decision towards social welfare\nstarting from individual opinions, preferences, interests or welfare. The field\nof Computational Social Welfare is somewhat recent and it is gaining impact in\nthe Artificial Intelligence Community. Classical literature makes the\nassumption of single-peaked preferences, i.e. there exist a order in the\npreferences and there is a global maximum in this order. This year some\ntheoretical results were published about Two-stage Approval Voting Systems\n(TAVs), Multi-winner Selection Rules (MWSR) and Incomplete (IPs) and Circular\nPreferences (CPs). The purpose of this paper is three-fold: Firstly, I want to\nintroduced Social Choice Optimisation as a generalisation of TAVs where there\nis a max stage and a min stage implementing thus a Minimax, well-known\nArtificial Intelligence decision-making rule to minimize hindering towards a\n(Social) Goal. Secondly, I want to introduce, following my Open Standardization\nand Open Integration Theory (in refinement process) put in practice in my\ndissertation, the Open Standardization of Social Inclusion, as a global social\ngoal of Social Choice Optimization.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jul 2020 11:36:36 GMT"}, {"version": "v2", "created": "Tue, 4 Aug 2020 21:05:47 GMT"}], "update_date": "2020-08-06", "authors_parsed": [["Garc\u00eda-Camino", "Andr\u00e9s", ""]]}, {"id": "2007.15475", "submitter": "Roland Ramsahai", "authors": "Roland R. Ramsahai", "title": "Connecting actuarial judgment to probabilistic learning techniques with\n  graph theory", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG q-fin.ST stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graphical models have been widely used in applications ranging from medical\nexpert systems to natural language processing. Their popularity partly arises\nsince they are intuitive representations of complex inter-dependencies among\nvariables with efficient algorithms for performing computationally intensive\ninference in high-dimensional models. It is argued that the formalism is very\nuseful for applications in the modelling of non-life insurance claims data. It\nis also shown that actuarial models in current practice can be expressed\ngraphically to exploit the advantages of the approach. More general models are\nproposed within the framework to demonstrate the potential use of graphical\nmodels for probabilistic learning with telematics and other dynamic actuarial\ndata. The discussion also demonstrates throughout that the intuitive nature of\nthe models allows the inclusion of qualitative knowledge or actuarial judgment\nin analyses.\n", "versions": [{"version": "v1", "created": "Wed, 29 Jul 2020 13:24:40 GMT"}], "update_date": "2020-07-31", "authors_parsed": [["Ramsahai", "Roland R.", ""]]}, {"id": "2007.15543", "submitter": "Prasoon Goyal", "authors": "Prasoon Goyal, Scott Niekum, Raymond J. Mooney", "title": "PixL2R: Guiding Reinforcement Learning Using Natural Language by Mapping\n  Pixels to Rewards", "comments": "Conference on Robot Learning (CoRL), 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning (RL), particularly in sparse reward settings, often\nrequires prohibitively large numbers of interactions with the environment,\nthereby limiting its applicability to complex problems. To address this,\nseveral prior approaches have used natural language to guide the agent's\nexploration. However, these approaches typically operate on structured\nrepresentations of the environment, and/or assume some structure in the natural\nlanguage commands. In this work, we propose a model that directly maps pixels\nto rewards, given a free-form natural language description of the task, which\ncan then be used for policy learning. Our experiments on the Meta-World robot\nmanipulation domain show that language-based rewards significantly improves the\nsample efficiency of policy learning, both in sparse and dense reward settings.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jul 2020 15:50:38 GMT"}, {"version": "v2", "created": "Thu, 19 Nov 2020 13:42:41 GMT"}], "update_date": "2020-11-20", "authors_parsed": [["Goyal", "Prasoon", ""], ["Niekum", "Scott", ""], ["Mooney", "Raymond J.", ""]]}, {"id": "2007.15588", "submitter": "Markus Wulfmeier", "authors": "Markus Wulfmeier, Dushyant Rao, Roland Hafner, Thomas Lampe, Abbas\n  Abdolmaleki, Tim Hertweck, Michael Neunert, Dhruva Tirumala, Noah Siegel,\n  Nicolas Heess, Martin Riedmiller", "title": "Data-efficient Hindsight Off-policy Option Learning", "comments": "Published at ICML2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce Hindsight Off-policy Options (HO2), a data-efficient option\nlearning algorithm. Given any trajectory, HO2 infers likely option choices and\nbackpropagates through the dynamic programming inference procedure to robustly\ntrain all policy components off-policy and end-to-end. The approach outperforms\nexisting option learning methods on common benchmarks. To better understand the\noption framework and disentangle benefits from both temporal and action\nabstraction, we evaluate ablations with flat policies and mixture policies with\ncomparable optimization. The results highlight the importance of both types of\nabstraction as well as off-policy training and trust-region constraints,\nparticularly in challenging, simulated 3D robot manipulation tasks from raw\npixel inputs. Finally, we intuitively adapt the inference step to investigate\nthe effect of increased temporal abstraction on training with pre-trained\noptions and from scratch.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jul 2020 16:52:33 GMT"}, {"version": "v2", "created": "Tue, 15 Jun 2021 15:55:50 GMT"}], "update_date": "2021-06-16", "authors_parsed": [["Wulfmeier", "Markus", ""], ["Rao", "Dushyant", ""], ["Hafner", "Roland", ""], ["Lampe", "Thomas", ""], ["Abdolmaleki", "Abbas", ""], ["Hertweck", "Tim", ""], ["Neunert", "Michael", ""], ["Tirumala", "Dhruva", ""], ["Siegel", "Noah", ""], ["Heess", "Nicolas", ""], ["Riedmiller", "Martin", ""]]}, {"id": "2007.15634", "submitter": "Ralph Foorthuis", "authors": "Ralph Foorthuis", "title": "On the Nature and Types of Anomalies: A Review of Deviations in Data", "comments": "39 pages (30 pages content), 10 figures and 3 tables. Preprint;\n  comments will be appreciated. Improvements in version 3: Added new anomaly\n  subtypes; Tightening of definitions; Additional examples from new literature;\n  Various minor additions and improvements", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.AI cs.LG stat.OT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Anomalies are occurrences in a dataset that are in some way unusual and do\nnot fit the general patterns. The concept of the anomaly is usually ill-defined\nand perceived as vague and domain-dependent. Moreover, despite some 250 years\nof publications on the topic, no comprehensive and concrete overviews of the\ndifferent types of anomalies have hitherto been published. By means of an\nextensive literature review this study therefore offers the first theoretically\nprincipled and domain-independent typology of data anomalies, and presents a\nfull overview of anomaly types and subtypes. To concretely define the concept\nof the anomaly and its different manifestations, the typology employs five\ndimensions: data type, cardinality of relationship, anomaly level, data\nstructure, and data distribution. These fundamental and data-centric dimensions\nnaturally yield 3 broad groups, 9 basic types and 63 subtypes of anomalies. The\ntypology facilitates the evaluation of the functional capabilities of anomaly\ndetection algorithms, contributes to explainable data science, and provides\ninsights into relevant topics such as local versus global anomalies.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jul 2020 17:55:11 GMT"}, {"version": "v2", "created": "Sun, 27 Dec 2020 22:15:50 GMT"}, {"version": "v3", "created": "Sat, 15 May 2021 11:45:58 GMT"}], "update_date": "2021-05-18", "authors_parsed": [["Foorthuis", "Ralph", ""]]}, {"id": "2007.15703", "submitter": "Desmond Ong", "authors": "Terence X. Lim, Sidney Tio, Desmond C. Ong", "title": "Improving Multi-Agent Cooperation using Theory of Mind", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in Artificial Intelligence have produced agents that can beat\nhuman world champions at games like Go, Starcraft, and Dota2. However, most of\nthese models do not seem to play in a human-like manner: People infer others'\nintentions from their behaviour, and use these inferences in scheming and\nstrategizing. Here, using a Bayesian Theory of Mind (ToM) approach, we\ninvestigated how much an explicit representation of others' intentions improves\nperformance in a cooperative game. We compared the performance of humans\nplaying with optimal-planning agents with and without ToM, in a cooperative\ngame where players have to flexibly cooperate to achieve joint goals. We find\nthat teams with ToM agents significantly outperform non-ToM agents when\ncollaborating with all types of partners: non-ToM, ToM, as well as human\nplayers, and that the benefit of ToM increases the more ToM agents there are.\nThese findings have implications for designing better cooperative agents.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jul 2020 19:31:31 GMT"}], "update_date": "2020-08-03", "authors_parsed": [["Lim", "Terence X.", ""], ["Tio", "Sidney", ""], ["Ong", "Desmond C.", ""]]}, {"id": "2007.15724", "submitter": "Zuxin Liu", "authors": "Zuxin Liu, Baiming Chen, Hongyi Zhou, Guru Koushik, Martial Hebert,\n  Ding Zhao", "title": "MAPPER: Multi-Agent Path Planning with Evolutionary Reinforcement\n  Learning in Mixed Dynamic Environments", "comments": "6 pages, accepted at the 2020 IEEE/RSJ International Conference on\n  Intelligent Robots and Systems (IROS 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-agent navigation in dynamic environments is of great industrial value\nwhen deploying a large scale fleet of robot to real-world applications. This\npaper proposes a decentralized partially observable multi-agent path planning\nwith evolutionary reinforcement learning (MAPPER) method to learn an effective\nlocal planning policy in mixed dynamic environments. Reinforcement\nlearning-based methods usually suffer performance degradation on long-horizon\ntasks with goal-conditioned sparse rewards, so we decompose the long-range\nnavigation task into many easier sub-tasks under the guidance of a global\nplanner, which increases agents' performance in large environments. Moreover,\nmost existing multi-agent planning approaches assume either perfect information\nof the surrounding environment or homogeneity of nearby dynamic agents, which\nmay not hold in practice. Our approach models dynamic obstacles' behavior with\nan image-based representation and trains a policy in mixed dynamic environments\nwithout homogeneity assumption. To ensure multi-agent training stability and\nperformance, we propose an evolutionary training approach that can be easily\nscaled to large and complex environments. Experiments show that MAPPER is able\nto achieve higher success rates and more stable performance when exposed to a\nlarge number of non-cooperative dynamic obstacles compared with traditional\nreaction-based planner LRA* and the state-of-the-art learning-based method.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jul 2020 20:14:42 GMT"}], "update_date": "2020-08-03", "authors_parsed": [["Liu", "Zuxin", ""], ["Chen", "Baiming", ""], ["Zhou", "Hongyi", ""], ["Koushik", "Guru", ""], ["Hebert", "Martial", ""], ["Zhao", "Ding", ""]]}, {"id": "2007.15780", "submitter": "Cristina Garbacea", "authors": "Cristina Garbacea, Qiaozhu Mei", "title": "Neural Language Generation: Formulation, Methods, and Evaluation", "comments": "70 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in neural network-based generative modeling have reignited\nthe hopes in having computer systems capable of seamlessly conversing with\nhumans and able to understand natural language. Neural architectures have been\nemployed to generate text excerpts to various degrees of success, in a\nmultitude of contexts and tasks that fulfil various user needs. Notably, high\ncapacity deep learning models trained on large scale datasets demonstrate\nunparalleled abilities to learn patterns in the data even in the lack of\nexplicit supervision signals, opening up a plethora of new possibilities\nregarding producing realistic and coherent texts. While the field of natural\nlanguage generation is evolving rapidly, there are still many open challenges\nto address. In this survey we formally define and categorize the problem of\nnatural language generation. We review particular application tasks that are\ninstantiations of these general formulations, in which generating natural\nlanguage is of practical importance. Next we include a comprehensive outline of\nmethods and neural architectures employed for generating diverse texts.\nNevertheless, there is no standard way to assess the quality of text produced\nby these generative models, which constitutes a serious bottleneck towards the\nprogress of the field. To this end, we also review current approaches to\nevaluating natural language generation systems. We hope this survey will\nprovide an informative overview of formulations, methods, and assessments of\nneural natural language generation.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jul 2020 00:08:28 GMT"}], "update_date": "2020-08-03", "authors_parsed": [["Garbacea", "Cristina", ""], ["Mei", "Qiaozhu", ""]]}, {"id": "2007.15823", "submitter": "Cristina Garbacea", "authors": "Cristina Garbacea, Mengtian Guo, Samuel Carton, Qiaozhu Mei", "title": "Explainable Prediction of Text Complexity: The Missing Preliminaries for\n  Text Simplification", "comments": "ACL 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Text simplification reduces the language complexity of professional content\nfor accessibility purposes. End-to-end neural network models have been widely\nadopted to directly generate the simplified version of input text, usually\nfunctioning as a blackbox. We show that text simplification can be decomposed\ninto a compact pipeline of tasks to ensure the transparency and explainability\nof the process. The first two steps in this pipeline are often neglected: 1) to\npredict whether a given piece of text needs to be simplified, and 2) if yes, to\nidentify complex parts of the text. The two tasks can be solved separately\nusing either lexical or deep learning methods, or solved jointly. Simply\napplying explainable complexity prediction as a preliminary step, the\nout-of-sample text simplification performance of the state-of-the-art,\nblack-box simplification models can be improved by a large margin.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jul 2020 03:33:37 GMT"}, {"version": "v2", "created": "Wed, 7 Jul 2021 01:28:32 GMT"}], "update_date": "2021-07-08", "authors_parsed": [["Garbacea", "Cristina", ""], ["Guo", "Mengtian", ""], ["Carton", "Samuel", ""], ["Mei", "Qiaozhu", ""]]}, {"id": "2007.15847", "submitter": "Syed Hasib Akhter Faruqui", "authors": "Syed Hasib Akhter Faruqui, Adel Alaeddini, Jing Wang, and Carlos A.\n  Jaramillo", "title": "A Functional Model for Structure Learning and Parameter Estimation in\n  Continuous Time Bayesian Network: An Application in Identifying Patterns of\n  Multiple Chronic Conditions", "comments": "Submitted to IEEE Access for review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian networks are powerful statistical models to study the probabilistic\nrelationships among set random variables with major applications in disease\nmodeling and prediction. Here, we propose a continuous time Bayesian network\nwith conditional dependencies, represented as Poisson regression, to model the\nimpact of exogenous variables on the conditional dependencies of the network.\nWe also propose an adaptive regularization method with an intuitive early\nstopping feature based on density based clustering for efficient learning of\nthe structure and parameters of the proposed network. Using a dataset of\npatients with multiple chronic conditions extracted from electronic health\nrecords of the Department of Veterans Affairs we compare the performance of the\nproposed approach with some of the existing methods in the literature for both\nshort-term (one-year ahead) and long-term (multi-year ahead) predictions. The\nproposed approach provides a sparse intuitive representation of the complex\nfunctional relationships between multiple chronic conditions. It also provides\nthe capability of analyzing multiple disease trajectories over time given any\ncombination of prior conditions.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jul 2020 05:02:34 GMT"}, {"version": "v2", "created": "Wed, 14 Jul 2021 21:03:44 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Faruqui", "Syed Hasib Akhter", ""], ["Alaeddini", "Adel", ""], ["Wang", "Jing", ""], ["Jaramillo", "Carlos A.", ""]]}, {"id": "2007.15911", "submitter": "Aniek Markus", "authors": "Aniek F. Markus, Jan A. Kors, Peter R. Rijnbeek", "title": "The role of explainability in creating trustworthy artificial\n  intelligence for health care: a comprehensive survey of the terminology,\n  design choices, and evaluation strategies", "comments": null, "journal-ref": "Journal of Biomedical Informatics, 113 (2021), 103655", "doi": "10.1016/j.jbi.2020.103655", "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Artificial intelligence (AI) has huge potential to improve the health and\nwell-being of people, but adoption in clinical practice is still limited. Lack\nof transparency is identified as one of the main barriers to implementation, as\nclinicians should be confident the AI system can be trusted. Explainable AI has\nthe potential to overcome this issue and can be a step towards trustworthy AI.\nIn this paper we review the recent literature to provide guidance to\nresearchers and practitioners on the design of explainable AI systems for the\nhealth-care domain and contribute to formalization of the field of explainable\nAI. We argue the reason to demand explainability determines what should be\nexplained as this determines the relative importance of the properties of\nexplainability (i.e. interpretability and fidelity). Based on this, we propose\na framework to guide the choice between classes of explainable AI methods\n(explainable modelling versus post-hoc explanation; model-based,\nattribution-based, or example-based explanations; global and local\nexplanations). Furthermore, we find that quantitative evaluation metrics, which\nare important for objective standardized evaluation, are still lacking for some\nproperties (e.g. clarity) and types of explanations (e.g. example-based\nmethods). We conclude that explainable modelling can contribute to trustworthy\nAI, but the benefits of explainability still need to be proven in practice and\ncomplementary measures might be needed to create trustworthy AI in health care\n(e.g. reporting data quality, performing extensive (external) validation, and\nregulation).\n", "versions": [{"version": "v1", "created": "Fri, 31 Jul 2020 09:08:27 GMT"}, {"version": "v2", "created": "Tue, 5 Jan 2021 08:32:38 GMT"}], "update_date": "2021-01-06", "authors_parsed": [["Markus", "Aniek F.", ""], ["Kors", "Jan A.", ""], ["Rijnbeek", "Peter R.", ""]]}, {"id": "2007.15987", "submitter": "W B Langdon", "authors": "William B. Langdon, Westley Weimer, Justyna Petke, Erik Fredericks,\n  Seongmin Lee, Emily Winter, Michail Basios, Myra B. Cohen, Aymeric Blot,\n  Markus Wagner, Bobby R. Bruce, Shin Yoo, Simos Gerasimou, Oliver Krauss, Yu\n  Huang and Michael Gerten", "title": "Genetic Improvement @ ICSE 2020", "comments": "7 pages, 2 figures. Write up of GI @ ICSE 2020 workshop. Submitted to\n  ACM SIGSOFT Software Engineering Notes", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Following Prof. Mark Harman of Facebook's keynote and formal presentations\n(which are recorded in the proceedings) there was a wide ranging discussion at\nthe eighth international Genetic Improvement workshop, GI-2020 @ ICSE (held as\npart of the 42nd ACM/IEEE International Conference on Software Engineering on\nFriday 3rd July 2020). Topics included industry take up, human factors,\nexplainabiloity (explainability, justifyability, exploitability) and GI\nbenchmarks. We also contrast various recent online approaches (e.g. SBST 2020)\nto holding virtual computer science conferences and workshops via the WWW on\nthe Internet without face-2-face interaction. Finally we speculate on how the\nCoronavirus Covid-19 Pandemic will affect research next year and into the\nfuture.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jul 2020 11:51:38 GMT"}], "update_date": "2020-08-03", "authors_parsed": [["Langdon", "William B.", ""], ["Weimer", "Westley", ""], ["Petke", "Justyna", ""], ["Fredericks", "Erik", ""], ["Lee", "Seongmin", ""], ["Winter", "Emily", ""], ["Basios", "Michail", ""], ["Cohen", "Myra B.", ""], ["Blot", "Aymeric", ""], ["Wagner", "Markus", ""], ["Bruce", "Bobby R.", ""], ["Yoo", "Shin", ""], ["Gerasimou", "Simos", ""], ["Krauss", "Oliver", ""], ["Huang", "Yu", ""], ["Gerten", "Michael", ""]]}, {"id": "2007.16001", "submitter": "Dom Huh", "authors": "Dom Huh", "title": "Greedy Bandits with Sampled Context", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian strategies for contextual bandits have proved promising in\nsingle-state reinforcement learning tasks by modeling uncertainty using context\ninformation from the environment. In this paper, we propose Greedy Bandits with\nSampled Context (GB-SC), a method for contextual multi-armed bandits to develop\nthe prior from the context information using Thompson Sampling, and arm\nselection using an epsilon-greedy policy. The framework GB-SC allows for\nevaluation of context-reward dependency, as well as providing robustness for\npartially observable context vectors by leveraging the prior developed. Our\nexperimental results show competitive performance on the Mushroom environment\nin terms of expected regret and expected cumulative regret, as well as insights\non how each context subset affects decision-making.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jul 2020 17:17:45 GMT"}], "update_date": "2020-08-03", "authors_parsed": [["Huh", "Dom", ""]]}, {"id": "2007.16009", "submitter": "Tom Williams", "authors": "Poulomi Pal and Tom Williams", "title": "Toward Givenness Hierarchy Theoretic Natural Language Generation", "comments": "Extended Abstract accepted for (non-archival) presentation at\n  Advances in Cognitive Systems 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Language-capable interactive robots participating in dialogues with human\ninterlocutors must be able to naturally and efficiently communicate about the\nentities in their environment. A key aspect of such communication is the use of\nanaphoric language. The linguistic theory of the Givenness Hierarchy(GH)\nsuggests that humans use anaphora based on the cognitive statuses their\nreferents have in the minds of their interlocutors. In previous work,\nresearchers presented GH-theoretic approaches to robot anaphora understanding.\nIn this paper we describe how the GH might need to be used quite differently to\nfacilitate robot anaphora generation.\n", "versions": [{"version": "v1", "created": "Fri, 17 Jul 2020 17:51:29 GMT"}], "update_date": "2020-08-03", "authors_parsed": [["Pal", "Poulomi", ""], ["Williams", "Tom", ""]]}, {"id": "2007.16011", "submitter": "Nagender Aneja", "authors": "Sandhya Aneja and Siti Nur Afikah Bte Abdul Mazid and Nagender Aneja", "title": "Neural Machine Translation model for University Email Application", "comments": "International Conference on Natural Language Processing (ICNLP 2020),\n  July 11-13, 2020", "journal-ref": "International Conference on Natural Language Processing (ICNLP\n  2020), July 11-13, 2020", "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine translation has many applications such as news translation, email\ntranslation, official letter translation etc. Commercial translators, e.g.\nGoogle Translation lags in regional vocabulary and are unable to learn the\nbilingual text in the source and target languages within the input. In this\npaper, a regional vocabulary-based application-oriented Neural Machine\nTranslation (NMT) model is proposed over the data set of emails used at the\nUniversity for communication over a period of three years. A state-of-the-art\nSequence-to-Sequence Neural Network for ML -> EN and EN -> ML translations is\ncompared with Google Translate using Gated Recurrent Unit Recurrent Neural\nNetwork machine translation model with attention decoder. The low BLEU score of\nGoogle Translation in comparison to our model indicates that the application\nbased regional models are better. The low BLEU score of EN -> ML of our model\nand Google Translation indicates that the Malay Language has complex language\nfeatures corresponding to English.\n", "versions": [{"version": "v1", "created": "Mon, 20 Jul 2020 15:05:16 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Aneja", "Sandhya", ""], ["Mazid", "Siti Nur Afikah Bte Abdul", ""], ["Aneja", "Nagender", ""]]}, {"id": "2007.16040", "submitter": "Simon Schiff", "authors": "Simon Schiff and \\\"Ozg\\\"ur \\\"Ozcep", "title": "Bounded-Memory Criteria for Streams with Application Time", "comments": "11 pages, 2 figures", "journal-ref": "Proceedings of the Thirty-Third International Florida Artificial\n  Intelligence Research Society Conference (2019) 148-153", "doi": null, "report-no": null, "categories": "cs.DB cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bounded-memory computability continues to be in the focus of those areas of\nAI and databases that deal with feasible computations over streams---be it\nfeasible arithmetical calculations on low-level streams or feasible query\nanswering for declaratively specified queries on relational data streams or\neven feasible query answering for high-level queries on streams w.r.t. a set of\nconstraints in an ontology such as in the paradigm of Ontology-Based Data\nAccess (OBDA). In classical OBDA, a high-level query is answered by\ntransforming it into a query on data source level. The transformation requires\na rewriting step, where knowledge from an ontology is incorporated into the\nquery, followed by an unfolding step with respect to a set of mappings. Given\nan OBDA setting it is very difficult to decide, whether and how a query can be\nanswered efficiently. In particular it is difficult to decide whether a query\ncan be answered in bounded memory, i.e., in constant space w.r.t. an infinitely\ngrowing prefix of a data stream. This work presents criteria for bounded-memory\ncomputability of select-project-join (SPJ) queries over streams with\napplication time. Deciding whether an SPJ query can be answered in constant\nspace is easier than for high-level queries, as neither an ontology nor a set\nof mappings are part of the input. Using the transformation process of\nclassical OBDA, these criteria then can help deciding the efficiency of\nanswering high-level queries on streams.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jul 2020 12:05:04 GMT"}], "update_date": "2020-08-03", "authors_parsed": [["Schiff", "Simon", ""], ["\u00d6zcep", "\u00d6zg\u00fcr", ""]]}, {"id": "2007.16044", "submitter": "Nicol\\`o Botteghi", "authors": "Nicol\\`o Botteghi, Ruben Obbink, Daan Geijs, Mannes Poel, Beril\n  Sirmacek, Christoph Brune, Abeje Mersha and Stefano Stramigioli", "title": "Low Dimensional State Representation Learning with Reward-shaped Priors", "comments": "Paper Accepted at ICPR2020", "journal-ref": null, "doi": null, "report-no": "978-1-7281-8808-9", "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement Learning has been able to solve many complicated robotics tasks\nwithout any need for feature engineering in an end-to-end fashion. However,\nlearning the optimal policy directly from the sensory inputs, i.e the\nobservations, often requires processing and storage of a huge amount of data.\nIn the context of robotics, the cost of data from real robotics hardware is\nusually very high, thus solutions that achieve high sample-efficiency are\nneeded. We propose a method that aims at learning a mapping from the\nobservations into a lower-dimensional state space. This mapping is learned with\nunsupervised learning using loss functions shaped to incorporate prior\nknowledge of the environment and the task. Using the samples from the state\nspace, the optimal policy is quickly and efficiently learned. We test the\nmethod on several mobile robot navigation tasks in a simulation environment and\nalso on a real robot.\n", "versions": [{"version": "v1", "created": "Wed, 29 Jul 2020 13:00:39 GMT"}, {"version": "v2", "created": "Thu, 7 Jan 2021 16:48:37 GMT"}], "update_date": "2021-03-02", "authors_parsed": [["Botteghi", "Nicol\u00f2", ""], ["Obbink", "Ruben", ""], ["Geijs", "Daan", ""], ["Poel", "Mannes", ""], ["Sirmacek", "Beril", ""], ["Brune", "Christoph", ""], ["Mersha", "Abeje", ""], ["Stramigioli", "Stefano", ""]]}, {"id": "2007.16045", "submitter": "Pablo Barros", "authors": "Pablo Barros, Ana Tanevska, Francisco Cruz, Alessandra Sciutti", "title": "Moody Learners -- Explaining Competitive Behaviour of Reinforcement\n  Learning Agents", "comments": "Accepted by ICDl-EPIROB 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Designing the decision-making processes of artificial agents that are\ninvolved in competitive interactions is a challenging task. In a competitive\nscenario, the agent does not only have a dynamic environment but also is\ndirectly affected by the opponents' actions. Observing the Q-values of the\nagent is usually a way of explaining its behavior, however, do not show the\ntemporal-relation between the selected actions. We address this problem by\nproposing the \\emph{Moody framework}. We evaluate our model by performing a\nseries of experiments using the competitive multiplayer Chef's Hat card game\nand discuss how our model allows the agents' to obtain a holistic\nrepresentation of the competitive dynamics within the game.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jul 2020 11:30:42 GMT"}], "update_date": "2020-08-03", "authors_parsed": [["Barros", "Pablo", ""], ["Tanevska", "Ana", ""], ["Cruz", "Francisco", ""], ["Sciutti", "Alessandra", ""]]}, {"id": "2007.16089", "submitter": "EPTCS", "authors": "Chidiebere Onyedinma (University of Ottawa), Patrick Gavigan (Carleton\n  University), Babak Esfandiari (Carleton University)", "title": "Toward Campus Mail Delivery Using BDI", "comments": "In Proceedings AREA 2020, arXiv:2007.11260", "journal-ref": "EPTCS 319, 2020, pp. 127-143", "doi": "10.4204/EPTCS.319.10", "report-no": null, "categories": "cs.MA cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Autonomous systems developed with the Belief-Desire-Intention (BDI)\narchitecture are usually mostly implemented in simulated environments. In this\nproject we sought to build a BDI agent for use in the real world for campus\nmail delivery in the tunnel system at Carleton University. Ideally, the robot\nshould receive a delivery order via a mobile application, pick up the mail at a\nstation, navigate the tunnels to the destination station, and notify the\nrecipient.\n  We linked the Robot Operating System (ROS) with a BDI reasoning system to\nachieve a subset of the required use cases. ROS handles the low-level sensing\nand actuation, while the BDI reasoning system handles the high-level reasoning\nand decision making. Sensory data is orchestrated and sent from ROS to the\nreasoning system as perceptions. These perceptions are then deliberated upon,\nand an action string is sent back to ROS for interpretation and driving of the\nnecessary actuator for the action to be performed.\n  In this paper we present our current implementation, which closes the loop on\nthe hardware-software integration, and implements a subset of the use cases\nrequired for the full system.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jul 2020 01:33:10 GMT"}], "update_date": "2020-08-03", "authors_parsed": [["Onyedinma", "Chidiebere", "", "University of Ottawa"], ["Gavigan", "Patrick", "", "Carleton\n  University"], ["Esfandiari", "Babak", "", "Carleton University"]]}, {"id": "2007.16107", "submitter": "Sudarshanan Bharadwaj", "authors": "Suda Bharadwaj, Abraham P. Vinod, Rayna Dimitrova, Ufuk Topcu", "title": "Near-Optimal Reactive Synthesis Incorporating Runtime Information", "comments": "Presented at ICRA2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of optimal reactive synthesis - compute a strategy\nthat satisfies a mission specification in a dynamic environment, and optimizes\na performance metric. We incorporate task-critical information, that is only\navailable at runtime, into the strategy synthesis in order to improve\nperformance. Existing approaches to utilising such time-varying information\nrequire online re-synthesis, which is not computationally feasible in real-time\napplications. In this paper, we pre-synthesize a set of strategies\ncorresponding to candidate instantiations (pre-specified representative\ninformation scenarios). We then propose a novel switching mechanism to\ndynamically switch between the strategies at runtime while guaranteeing all\nsafety and liveness goals are met. We also characterize bounds on the\nperformance suboptimality. We demonstrate our approach on two examples -\nrobotic motion planning where the likelihood of the position of the robot's\ngoal is updated in real-time, and an air traffic management problem for urban\nair mobility.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jul 2020 14:41:35 GMT"}], "update_date": "2020-08-03", "authors_parsed": [["Bharadwaj", "Suda", ""], ["Vinod", "Abraham P.", ""], ["Dimitrova", "Rayna", ""], ["Topcu", "Ufuk", ""]]}, {"id": "2007.16117", "submitter": "Jakub Marecek", "authors": "Ramen Ghosh and Jakub Marecek and Wynita M. Griggs and Matheus Souza\n  and Robert N. Shorten", "title": "Predictability and Fairness in Social Sensing", "comments": "18 pages, 6 figures", "journal-ref": "IEEE Internet of Things Journal, 2021", "doi": "10.1109/JIOT.2021.3085368", "report-no": null, "categories": "eess.SP cs.AI cs.SY eess.SY math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the design of distributed algorithms that govern the manner in\nwhich agents contribute to a social sensing platform. Specifically, we are\ninterested in situations where fairness among the agents contributing to the\nplatform is needed. A notable example are platforms operated by public bodies,\nwhere fairness is a legal requirement. The design of such distributed systems\nis challenging due to the fact that we wish to simultaneously realise an\nefficient social sensing platform, but also deliver a predefined quality of\nservice to the agents (for example, a fair opportunity to contribute to the\nplatform). In this paper, we introduce iterated function systems (IFS) as a\ntool for the design and analysis of systems of this kind. We show how the IFS\nframework can be used to realise systems that deliver a predictable quality of\nservice to agents, can be used to underpin contracts governing the interaction\nof agents with the social sensing platform, and which are efficient.\n  To illustrate our design via a use case, we consider a large, high-density\nnetwork of participating parked vehicles. When awoken by an administrative\ncentre, this network proceeds to search for moving missing entities of interest\nusing RFID-based techniques. We regulate which vehicles are actively searching\nfor the moving entity of interest at any point in time. In doing so, we seek to\nequalise vehicular energy consumption across the network. This is illustrated\nthrough simulations of a search for a missing Alzheimer's patient in Melbourne,\nAustralia. Experimental results are presented to illustrate the efficacy of our\nsystem and the predictability of access of agents to the platform independent\nof initial conditions.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jul 2020 15:04:08 GMT"}, {"version": "v2", "created": "Thu, 24 Dec 2020 09:44:26 GMT"}, {"version": "v3", "created": "Tue, 25 May 2021 16:14:29 GMT"}], "update_date": "2021-06-10", "authors_parsed": [["Ghosh", "Ramen", ""], ["Marecek", "Jakub", ""], ["Griggs", "Wynita M.", ""], ["Souza", "Matheus", ""], ["Shorten", "Robert N.", ""]]}, {"id": "2007.16119", "submitter": "Jeffrey Herrmann", "authors": "Jeffrey W. Herrmann and Kunal Mehta", "title": "Lookahead and Hybrid Sample Allocation Procedures for Multiple Attribute\n  Selection Decisions", "comments": "Pages: 49. Figures: 8", "journal-ref": null, "doi": null, "report-no": null, "categories": "econ.TH cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Attributes provide critical information about the alternatives that a\ndecision-maker is considering. When their magnitudes are uncertain, the\ndecision-maker may be unsure about which alternative is truly the best, so\nmeasuring the attributes may help the decision-maker make a better decision.\nThis paper considers settings in which each measurement yields one sample of\none attribute for one alternative. When given a fixed number of samples to\ncollect, the decision-maker must determine which samples to obtain, make the\nmeasurements, update prior beliefs about the attribute magnitudes, and then\nselect an alternative. This paper presents the sample allocation problem for\nmultiple attribute selection decisions and proposes two sequential, lookahead\nprocedures for the case in which discrete distributions are used to model the\nuncertain attribute magnitudes. The two procedures are similar but reflect\ndifferent quality measures (and loss functions), which motivate different\ndecision rules: (1) select the alternative with the greatest expected utility\nand (2) select the alternative that is most likely to be the truly best\nalternative. We conducted a simulation study to evaluate the performance of the\nsequential procedures and hybrid procedures that first allocate some samples\nusing a uniform allocation procedure and then use the sequential, lookahead\nprocedure. The results indicate that the hybrid procedures are effective;\nallocating many (but not all) of the initial samples with the uniform\nallocation procedure not only reduces overall computational effort but also\nselects alternatives that have lower average opportunity cost and are more\noften truly best.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jul 2020 15:04:49 GMT"}], "update_date": "2020-08-03", "authors_parsed": [["Herrmann", "Jeffrey W.", ""], ["Mehta", "Kunal", ""]]}, {"id": "2007.16120", "submitter": "Ivan Palomares", "authors": "Ivan Palomares, Carlos Porcel, Luiz Pizzato, Ido Guy, Enrique\n  Herrera-Viedma", "title": "Reciprocal Recommender Systems: Analysis of State-of-Art Literature,\n  Challenges and Opportunities towards Social Recommendation", "comments": "This paper has been withdrawn by the authors due to an author dispute", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.AI cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There exist situations of decision-making under information overload in the\nInternet, where people have an overwhelming number of available options to\nchoose from, e.g. products to buy in an e-commerce site, or restaurants to\nvisit in a large city. Recommender systems arose as a data-driven personalized\ndecision support tool to assist users in these situations: they are able to\nprocess user-related data, filtering and recommending items based on the users\npreferences, needs and/or behaviour. Unlike most conventional recommender\napproaches where items are inanimate entities recommended to the users and\nsuccess is solely determined upon the end users reaction to the\nrecommendation(s) received, in a Reciprocal Recommender System (RRS) users\nbecome the item being recommended to other users. Hence, both the end user and\nthe user being recommended should accept the 'matching' recommendation to yield\na successful RRS performance. The operation of an RRS entails not only\npredicting accurate preference estimates upon user interaction data as\nclassical recommenders do, but also calculating mutual compatibility between\n(pairs of) users, typically by applying fusion processes on unilateral\nuser-to-user preference information. This paper presents a snapshot-style\nanalysis of the extant literature that summarizes the state-of-the-art RRS\nresearch to date, focusing on the algorithms, fusion processes and fundamental\ncharacteristics of RRS, both inherited from conventional user-to-item\nrecommendation models and those inherent to this emerging family of approaches.\nRepresentative RRS models are likewise highlighted. Following this, we discuss\nthe challenges and opportunities for future research on RRSs, with special\nfocus on (i) fusion strategies to account for reciprocity and (ii) emerging\napplication domains related to social recommendation.\n", "versions": [{"version": "v1", "created": "Fri, 17 Jul 2020 09:48:46 GMT"}, {"version": "v2", "created": "Mon, 2 Nov 2020 16:04:47 GMT"}, {"version": "v3", "created": "Wed, 13 Jan 2021 17:48:38 GMT"}], "update_date": "2021-01-14", "authors_parsed": [["Palomares", "Ivan", ""], ["Porcel", "Carlos", ""], ["Pizzato", "Luiz", ""], ["Guy", "Ido", ""], ["Herrera-Viedma", "Enrique", ""]]}, {"id": "2007.16122", "submitter": "Zhe Wang", "authors": "Zhe Wang, Liqin Zhao, Biye Jiang, Guorui Zhou, Xiaoqiang Zhu, Kun Gai", "title": "COLD: Towards the Next Generation of Pre-Ranking System", "comments": "accepted by DLP-KDD 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-stage cascade architecture exists widely in many industrial systems\nsuch as recommender systems and online advertising, which often consists of\nsequential modules including matching, pre-ranking, ranking, etc. For a long\ntime, it is believed pre-ranking is just a simplified version of the ranking\nmodule, considering the larger size of the candidate set to be ranked. Thus,\nefforts are made mostly on simplifying ranking model to handle the explosion of\ncomputing power for online inference. In this paper, we rethink the challenge\nof the pre-ranking system from an algorithm-system co-design view. Instead of\nsaving computing power with restriction of model architecture which causes loss\nof model performance, here we design a new pre-ranking system by joint\noptimization of both the pre-ranking model and the computing power it costs. We\nname it COLD (Computing power cost-aware Online and Lightweight Deep\npre-ranking system). COLD beats SOTA in three folds: (i) an arbitrary deep\nmodel with cross features can be applied in COLD under a constraint of\ncontrollable computing power cost. (ii) computing power cost is explicitly\nreduced by applying optimization tricks for inference acceleration. This\nfurther brings space for COLD to apply more complex deep models to reach better\nperformance. (iii) COLD model works in an online learning and severing manner,\nbringing it excellent ability to handle the challenge of the data distribution\nshift. Meanwhile, the fully online pre-ranking system of COLD provides us with\na flexible infrastructure that supports efficient new model developing and\nonline A/B testing.Since 2019, COLD has been deployed in almost all products\ninvolving the pre-ranking module in the display advertising system in Alibaba,\nbringing significant improvements.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jul 2020 15:06:43 GMT"}, {"version": "v2", "created": "Mon, 17 Aug 2020 13:13:25 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Wang", "Zhe", ""], ["Zhao", "Liqin", ""], ["Jiang", "Biye", ""], ["Zhou", "Guorui", ""], ["Zhu", "Xiaoqiang", ""], ["Gai", "Kun", ""]]}, {"id": "2007.16138", "submitter": "Quanlong Wang", "authors": "Camilo Miguel Signorelli, Quanlong Wang, Ilyas Khan", "title": "A Compositional Model of Consciousness based on Consciousness-Only", "comments": "19 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Scientific studies of consciousness rely on objects whose existence is\nassumed to be independent of any consciousness. On the contrary, we assume\nconsciousness to be fundamental, and that one of the main features of\nconsciousness is characterized as being other-dependent. We set up a framework\nwhich naturally subsumes this feature by defining a compact closed category\nwhere morphisms represent conscious processes. These morphisms are a\ncomposition of a set of generators, each being specified by their relations\nwith other generators, and therefore co-dependent. The framework is general\nenough and fits well into a compositional model of consciousness.\nInterestingly, we also show how our proposal may become a step towards avoiding\nthe hard problem of consciousness, and thereby address the combination problem\nof conscious experiences.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jul 2020 15:35:50 GMT"}, {"version": "v2", "created": "Wed, 5 Aug 2020 17:49:21 GMT"}, {"version": "v3", "created": "Thu, 25 Feb 2021 00:00:14 GMT"}], "update_date": "2021-02-26", "authors_parsed": [["Signorelli", "Camilo Miguel", ""], ["Wang", "Quanlong", ""], ["Khan", "Ilyas", ""]]}, {"id": "2007.16162", "submitter": "Shubhankar Agarwal", "authors": "Shubhankar Agarwal, Harshit Sikchi, Cole Gulino and Eric Wilkinson", "title": "Imitative Planning using Conditional Normalizing Flow", "comments": "Submittted to 4th Conference on Robot Learning (CoRL 2020), Cambridge\n  MA, USA", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We explore the application of normalizing flows for improving the performance\nof trajectory planning for autonomous vehicles (AVs). Normalizing flows provide\nan invertible mapping from a known prior distribution to a potentially complex,\nmulti-modal target distribution and allow for fast sampling with exact PDF\ninference. By modeling a trajectory planner's cost manifold as an energy\nfunction we learn a scene conditioned mapping from the prior to a Boltzmann\ndistribution over the AV control space. This mapping allows for control samples\nand their associated energy to be generated jointly and in parallel. We propose\nusing neural autoregressive flow (NAF) as part of an end-to-end deep learned\nsystem that allows for utilizing sensors, map, and route information to\ncondition the flow mapping. Finally, we demonstrate the effectiveness of our\napproach on real world datasets over IL and hand constructed trajectory\nsampling techniques.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jul 2020 16:32:23 GMT"}, {"version": "v2", "created": "Wed, 26 Aug 2020 02:06:33 GMT"}], "update_date": "2020-08-27", "authors_parsed": [["Agarwal", "Shubhankar", ""], ["Sikchi", "Harshit", ""], ["Gulino", "Cole", ""], ["Wilkinson", "Eric", ""]]}]