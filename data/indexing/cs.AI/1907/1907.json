[{"id": "1907.00151", "submitter": "Yi Liao", "authors": "Yi Liao, Yasheng Wang, Qun Liu, Xin Jiang", "title": "GPT-based Generation for Classical Chinese Poetry", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a simple yet effective method for generating high quality\nclassical Chinese poetry with Generative Pre-trained Language Model (GPT). The\nmethod adopts a simple GPT model, without using any human crafted rules or\nfeatures, or designing any additional neural components. While the proposed\nmodel learns to generate various forms of classical Chinese poems, including\nJueju, L\\\"{u}shi, various Cipai and Couples, the generated poems are of very\nhigh quality. We also propose and implement a method to fine-tune the model to\ngenerate acrostic poetry. To the best of our knowledge, this is the first to\nemploy GPT in developing a poetry generation system. We have released an online\nmini demonstration program on Wechat to show the generation capability of the\nproposed method for classical Chinese poetry.\n", "versions": [{"version": "v1", "created": "Sat, 29 Jun 2019 06:04:48 GMT"}, {"version": "v2", "created": "Tue, 2 Jul 2019 14:18:55 GMT"}, {"version": "v3", "created": "Wed, 3 Jul 2019 12:55:06 GMT"}, {"version": "v4", "created": "Fri, 12 Jul 2019 05:44:58 GMT"}, {"version": "v5", "created": "Thu, 5 Sep 2019 02:34:36 GMT"}], "update_date": "2019-09-06", "authors_parsed": [["Liao", "Yi", ""], ["Wang", "Yasheng", ""], ["Liu", "Qun", ""], ["Jiang", "Xin", ""]]}, {"id": "1907.00205", "submitter": "Ido Kaminer", "authors": "Gal Raayoni, Shahar Gottlieb, George Pisha, Yoav Harris, Yahel Manor,\n  Uri Mendlovic, Doron Haviv, Yaron Hadad, and Ido Kaminer", "title": "The Ramanujan Machine: Automatically Generated Conjectures on\n  Fundamental Constants", "comments": "5 figures, 6 tables, 28 pages including the supplementary information", "journal-ref": "Nature 590, 67-73 (2021)", "doi": "10.1038/s41586-021-03229-4", "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fundamental mathematical constants like $e$ and $\\pi$ are ubiquitous in\ndiverse fields of science, from abstract mathematics to physics, biology and\nchemistry. For centuries, new formulas relating fundamental constants have been\nscarce and usually discovered sporadically. Here we propose a novel and\nsystematic approach that leverages algorithms for deriving mathematical\nformulas for fundamental constants and help reveal their underlying structure.\nOur algorithms find dozens of well-known as well as previously unknown\ncontinued fraction representations of $\\pi$, $e$, Catalan's constant, and\nvalues of the Riemann zeta function. Two example conjectures found by our\nalgorithm and so far unproven are: \\begin{equation*} \\frac{24}{\\pi^2} = 2 +\n7\\cdot 0\\cdot 1+ \\frac{8\\cdot1^4}{2 + 7\\cdot 1\\cdot 2 + \\frac{8\\cdot2^4}{2 +\n7\\cdot 2\\cdot 3 + \\frac{8\\cdot3^4}{2 + 7\\cdot 3\\cdot 4 +\n\\frac{8\\cdot4^4}{..}}}} \\quad\\quad,\\quad\\quad \\frac{8}{7 \\zeta(3)} = 1\\cdot 1 -\n\\frac{1^6}{3\\cdot 7 - \\frac{2^6}{5\\cdot 19 - \\frac{3^6}{7\\cdot 37 -\n\\frac{4^6}{..}}}} \\end{equation*} We present two algorithms that proved useful\nin finding conjectures: a Meet-In-The-Middle (MITM) algorithm and a Gradient\nDescent (GD) tailored to the recurrent structure of continued fractions. Both\nalgorithms are based on matching numerical values and thus they conjecture\nformulas without providing proofs and without requiring prior knowledge on any\nunderlying mathematical structure. This approach is especially attractive for\nconstants for which no mathematical structure is known, as it reverses the\nconventional approach of sequential logic in formal proofs. Instead, our work\nsupports a different approach for research: algorithms utilizing numerical data\nto unveil mathematical structures, thus trying to play the role of intuition of\ngreat mathematicians of the past, providing leads to new mathematical research.\n", "versions": [{"version": "v1", "created": "Sat, 29 Jun 2019 13:39:10 GMT"}, {"version": "v2", "created": "Sat, 20 Jul 2019 18:08:05 GMT"}, {"version": "v3", "created": "Sat, 3 Aug 2019 07:20:42 GMT"}, {"version": "v4", "created": "Thu, 30 Apr 2020 11:22:42 GMT"}], "update_date": "2021-04-29", "authors_parsed": [["Raayoni", "Gal", ""], ["Gottlieb", "Shahar", ""], ["Pisha", "George", ""], ["Harris", "Yoav", ""], ["Manor", "Yahel", ""], ["Mendlovic", "Uri", ""], ["Haviv", "Doron", ""], ["Hadad", "Yaron", ""], ["Kaminer", "Ido", ""]]}, {"id": "1907.00221", "submitter": "Rohit Bhattacharya", "authors": "Rohit Bhattacharya, Daniel Malinsky, Ilya Shpitser", "title": "Causal Inference Under Interference And Network Uncertainty", "comments": "16 pages, published in proceedings of 35th Conference on Uncertainty\n  in Artificial Intelligence (UAI 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Classical causal and statistical inference methods typically assume the\nobserved data consists of independent realizations. However, in many\napplications this assumption is inappropriate due to a network of dependences\nbetween units in the data. Methods for estimating causal effects have been\ndeveloped in the setting where the structure of dependence between units is\nknown exactly, but in practice there is often substantial uncertainty about the\nprecise network structure. This is true, for example, in trial data drawn from\nvulnerable communities where social ties are difficult to query directly. In\nthis paper we combine techniques from the structure learning and interference\nliteratures in causal inference, proposing a general method for estimating\ncausal effects under data dependence when the structure of this dependence is\nnot known a priori. We demonstrate the utility of our method on synthetic\ndatasets which exhibit network dependence.\n", "versions": [{"version": "v1", "created": "Sat, 29 Jun 2019 15:25:53 GMT"}], "update_date": "2019-07-02", "authors_parsed": [["Bhattacharya", "Rohit", ""], ["Malinsky", "Daniel", ""], ["Shpitser", "Ilya", ""]]}, {"id": "1907.00240", "submitter": "Dennis Soemers", "authors": "Matthew Stephenson, \\'Eric Piette, Dennis J. N. J. Soemers, Cameron\n  Browne", "title": "An Overview of the Ludii General Game System", "comments": "Accepted at the IEEE Conference on Games (CoG) 2019 (Demo paper)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Digital Ludeme Project (DLP) aims to reconstruct and analyse over 1000\ntraditional strategy games using modern techniques. One of the key aspects of\nthis project is the development of Ludii, a general game system that will be\nable to model and play the complete range of games required by this project.\nSuch an undertaking will create a wide range of possibilities for new AI\nchallenges. In this paper we describe many of the features of Ludii that can be\nused. This includes designing and modifying games using the Ludii game\ndescription language, creating agents capable of playing these games, and\nseveral advantages the system has over prior general game software.\n", "versions": [{"version": "v1", "created": "Sat, 29 Jun 2019 17:16:27 GMT"}], "update_date": "2019-07-02", "authors_parsed": [["Stephenson", "Matthew", ""], ["Piette", "\u00c9ric", ""], ["Soemers", "Dennis J. N. J.", ""], ["Browne", "Cameron", ""]]}, {"id": "1907.00244", "submitter": "Dennis Soemers", "authors": "\\'Eric Piette, Matthew Stephenson, Dennis J. N. J. Soemers, Cameron\n  Browne", "title": "An Empirical Evaluation of Two General Game Systems: Ludii and RBG", "comments": "Accepted at the IEEE Conference on Games (CoG) 2019 (Short paper)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although General Game Playing (GGP) systems can facilitate useful research in\nArtificial Intelligence (AI) for game-playing, they are often computationally\ninefficient and somewhat specialised to a specific class of games. However,\nsince the start of this year, two General Game Systems have emerged that\nprovide efficient alternatives to the academic state of the art -- the Game\nDescription Language (GDL). In order of publication, these are the Regular\nBoardgames language (RBG), and the Ludii system. This paper offers an\nexperimental evaluation of Ludii. Here, we focus mainly on a comparison between\nthe two new systems in terms of two key properties for any GGP system:\nsimplicity/clarity (e.g. human-readability), and efficiency.\n", "versions": [{"version": "v1", "created": "Sat, 29 Jun 2019 17:21:40 GMT"}], "update_date": "2019-07-02", "authors_parsed": [["Piette", "\u00c9ric", ""], ["Stephenson", "Matthew", ""], ["Soemers", "Dennis J. N. J.", ""], ["Browne", "Cameron", ""]]}, {"id": "1907.00245", "submitter": "Dennis Soemers", "authors": "C\\'edric Piette, \\'Eric Piette, Matthew Stephenson, Dennis J. N. J.\n  Soemers, Cameron Browne", "title": "Ludii and XCSP: Playing and Solving Logic Puzzles", "comments": "Accepted at the IEEE Conference on Games (CoG) 2019 (Short paper)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many of the famous single-player games, commonly called puzzles, can be shown\nto be NP-Complete. Indeed, this class of complexity contains hundreds of\npuzzles, since people particularly appreciate completing an intractable puzzle,\nsuch as Sudoku, but also enjoy the ability to check their solution easily once\nit's done. For this reason, using constraint programming is naturally suited to\nsolve them. In this paper, we focus on logic puzzles described in the Ludii\ngeneral game system and we propose using the XCSP formalism in order to solve\nthem with any CSP solver.\n", "versions": [{"version": "v1", "created": "Sat, 29 Jun 2019 17:28:27 GMT"}], "update_date": "2019-07-02", "authors_parsed": [["Piette", "C\u00e9dric", ""], ["Piette", "\u00c9ric", ""], ["Stephenson", "Matthew", ""], ["Soemers", "Dennis J. N. J.", ""], ["Browne", "Cameron", ""]]}, {"id": "1907.00246", "submitter": "Dennis Soemers", "authors": "Matthew Stephenson, \\'Eric Piette, Dennis J. N. J. Soemers, Cameron\n  Browne", "title": "Ludii as a Competition Platform", "comments": "Accepted at the IEEE Conference on Games (CoG) 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ludii is a general game system being developed as part of the ERC-funded\nDigital Ludeme Project (DLP). While its primary aim is to model, play, and\nanalyse the full range of traditional strategy games, Ludii also has the\npotential to support a wide range of AI research topics and competitions. This\npaper describes some of the future competitions and challenges that we intend\nto run using the Ludii system, highlighting some of its most important aspects\nthat can potentially lead to many algorithm improvements and new avenues of\nresearch. We compare and contrast our proposed competition motivations, goals\nand frameworks against those of existing general game playing competitions,\naddressing the strengths and weaknesses of each platform.\n", "versions": [{"version": "v1", "created": "Sat, 29 Jun 2019 17:33:12 GMT"}], "update_date": "2019-07-02", "authors_parsed": [["Stephenson", "Matthew", ""], ["Piette", "\u00c9ric", ""], ["Soemers", "Dennis J. N. J.", ""], ["Browne", "Cameron", ""]]}, {"id": "1907.00269", "submitter": "Madhavun Candadai", "authors": "Zach Dwiel, Madhavun Candadai, Mariano Phielipp", "title": "On Training Flexible Robots using Deep Reinforcement Learning", "comments": "Accepted at the Intelligent Robots and Systems (IRoS) conference,\n  2019. Camera-ready version coming soon", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The use of robotics in controlled environments has flourished over the last\nseveral decades and training robots to perform tasks using control strategies\ndeveloped from dynamical models of their hardware have proven very effective.\nHowever, in many real-world settings, the uncertainties of the environment, the\nsafety requirements and generalized capabilities that are expected of robots\nmake rigid industrial robots unsuitable. This created great research interest\ninto developing control strategies for flexible robot hardware for which\nbuilding dynamical models are challenging. In this paper, inspired by the\nsuccess of deep reinforcement learning (DRL) in other areas, we systematically\nstudy the efficacy of policy search methods using DRL in training flexible\nrobots. Our results indicate that DRL is successfully able to learn efficient\nand robust policies for complex tasks at various degrees of flexibility. We\nalso note that DRL using Deep Deterministic Policy Gradients can be sensitive\nto the choice of sensors and adding more informative sensors does not\nnecessarily make the task easier to learn.\n", "versions": [{"version": "v1", "created": "Sat, 29 Jun 2019 19:50:23 GMT"}, {"version": "v2", "created": "Sat, 13 Jul 2019 15:47:36 GMT"}], "update_date": "2019-07-16", "authors_parsed": [["Dwiel", "Zach", ""], ["Candadai", "Madhavun", ""], ["Phielipp", "Mariano", ""]]}, {"id": "1907.00313", "submitter": "Stefanos Nikolaidis", "authors": "Houston Claure, Yifang Chen, Jignesh Modi, Malte Jung, Stefanos\n  Nikolaidis", "title": "Multi-Armed Bandits with Fairness Constraints for Distributing Resources\n  to Human Teammates", "comments": null, "journal-ref": "Proceedings of the 2020 ACM/IEEE International Conference on\n  Human-Robot Interaction", "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  How should a robot that collaborates with multiple people decide upon the\ndistribution of resources (e.g. social attention, or parts needed for an\nassembly)? People are uniquely attuned to how resources are distributed. A\ndecision to distribute more resources to one team member than another might be\nperceived as unfair with potentially detrimental effects for trust. We\nintroduce a multi-armed bandit algorithm with fairness constraints, where a\nrobot distributes resources to human teammates of different skill levels. In\nthis problem, the robot does not know the skill level of each human teammate,\nbut learns it by observing their performance over time. We define fairness as a\nconstraint on the minimum rate that each human teammate is selected throughout\nthe task. We provide theoretical guarantees on performance and perform a\nlarge-scale user study, where we adjust the level of fairness in our algorithm.\nResults show that fairness in resource distribution has a significant effect on\nusers' trust in the system.\n", "versions": [{"version": "v1", "created": "Sun, 30 Jun 2019 03:41:05 GMT"}, {"version": "v2", "created": "Mon, 8 Jul 2019 02:06:54 GMT"}, {"version": "v3", "created": "Mon, 7 Dec 2020 05:32:38 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Claure", "Houston", ""], ["Chen", "Yifang", ""], ["Modi", "Jignesh", ""], ["Jung", "Malte", ""], ["Nikolaidis", "Stefanos", ""]]}, {"id": "1907.00327", "submitter": "Niranjan Balachandar", "authors": "Niranjan Balachandar, Justin Dieter, Govardana Sachithanandam\n  Ramachandran", "title": "Collaboration of AI Agents via Cooperative Multi-Agent Deep\n  Reinforcement Learning", "comments": "9 pages, 7 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There are many AI tasks involving multiple interacting agents where agents\nshould learn to cooperate and collaborate to effectively perform the task. Here\nwe develop and evaluate various multi-agent protocols to train agents to\ncollaborate with teammates in grid soccer. We train and evaluate our\nmulti-agent methods against a team operating with a smart hand-coded policy. As\na baseline, we train agents concurrently and independently, with no\ncommunication. Our collaborative protocols were parameter sharing, coordinated\nlearning with communication, and counterfactual policy gradients. Against the\nhand-coded team, the team trained with parameter sharing and the team trained\nwith coordinated learning performed the best, scoring on 89.5% and 94.5% of\nepisodes respectively when playing against the hand-coded team. Against the\nparameter sharing team, with adversarial training the coordinated learning team\nscored on 75% of the episodes, indicating it is the most adaptable of our\nmethods. The insights gained from our work can be applied to other domains\nwhere multi-agent collaboration could be beneficial.\n", "versions": [{"version": "v1", "created": "Sun, 30 Jun 2019 06:12:48 GMT"}], "update_date": "2019-07-02", "authors_parsed": [["Balachandar", "Niranjan", ""], ["Dieter", "Justin", ""], ["Ramachandran", "Govardana Sachithanandam", ""]]}, {"id": "1907.00377", "submitter": "Tanmay Randhavane", "authors": "Tanmay Randhavane, Aniket Bera, Kyra Kapsaskis, Kurt Gray, Dinesh\n  Manocha", "title": "FVA: Modeling Perceived Friendliness of Virtual Agents Using Movement\n  Characteristics", "comments": "To appear in ISMAR 2019 Special Issue of TVCG", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI cs.GR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new approach for improving the friendliness and warmth of a\nvirtual agent in an AR environment by generating appropriate movement\ncharacteristics. Our algorithm is based on a novel data-driven friendliness\nmodel that is computed using a user-study and psychological characteristics. We\nuse our model to control the movements corresponding to the gaits, gestures,\nand gazing of friendly virtual agents (FVAs) as they interact with the user's\navatar and other agents in the environment. We have integrated FVA agents with\nan AR environment using with a Microsoft HoloLens. Our algorithm can generate\nplausible movements at interactive rates to increase the social presence. We\nalso investigate the perception of a user in an AR setting and observe that an\nFVA has a statistically significant improvement in terms of the perceived\nfriendliness and social presence of a user compared to an agent without the\nfriendliness modeling. We observe an increment of 5.71% in the mean responses\nto a friendliness measure and an improvement of 4.03% in the mean responses to\na social presence measure.\n", "versions": [{"version": "v1", "created": "Sun, 30 Jun 2019 13:04:43 GMT"}], "update_date": "2019-07-02", "authors_parsed": [["Randhavane", "Tanmay", ""], ["Bera", "Aniket", ""], ["Kapsaskis", "Kyra", ""], ["Gray", "Kurt", ""], ["Manocha", "Dinesh", ""]]}, {"id": "1907.00390", "submitter": "Zhonfu Chen", "authors": "Haihong E, Peiqing Niu, Zhongfu Chen, Meina Song", "title": "A Novel Bi-directional Interrelated Model for Joint Intent Detection and\n  Slot Filling", "comments": "Accepted paper of ACL 2019 (short paper) with 5 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A spoken language understanding (SLU) system includes two main tasks, slot\nfilling (SF) and intent detection (ID). The joint model for the two tasks is\nbecoming a tendency in SLU. But the bi-directional interrelated connections\nbetween the intent and slots are not established in the existing joint models.\nIn this paper, we propose a novel bi-directional interrelated model for joint\nintent detection and slot filling. We introduce an SF-ID network to establish\ndirect connections for the two tasks to help them promote each other mutually.\nBesides, we design an entirely new iteration mechanism inside the SF-ID network\nto enhance the bi-directional interrelated connections. The experimental\nresults show that the relative improvement in the sentence-level semantic frame\naccuracy of our model is 3.79% and 5.42% on ATIS and Snips datasets,\nrespectively, compared to the state-of-the-art model.\n", "versions": [{"version": "v1", "created": "Sun, 30 Jun 2019 14:54:01 GMT"}], "update_date": "2019-07-02", "authors_parsed": [["E", "Haihong", ""], ["Niu", "Peiqing", ""], ["Chen", "Zhongfu", ""], ["Song", "Meina", ""]]}, {"id": "1907.00397", "submitter": "Samuel Yen-Chi Chen", "authors": "Samuel Yen-Chi Chen, Chao-Han Huck Yang, Jun Qi, Pin-Yu Chen, Xiaoli\n  Ma, Hsi-Sheng Goan", "title": "Variational Quantum Circuits for Deep Reinforcement Learning", "comments": "Accepted for publication by IEEE Access", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI quant-ph stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The state-of-the-art machine learning approaches are based on classical von\nNeumann computing architectures and have been widely used in many industrial\nand academic domains. With the recent development of quantum computing,\nresearchers and tech-giants have attempted new quantum circuits for machine\nlearning tasks. However, the existing quantum computing platforms are hard to\nsimulate classical deep learning models or problems because of the\nintractability of deep quantum circuits. Thus, it is necessary to design\nfeasible quantum algorithms for quantum machine learning for noisy intermediate\nscale quantum (NISQ) devices. This work explores variational quantum circuits\nfor deep reinforcement learning. Specifically, we reshape classical deep\nreinforcement learning algorithms like experience replay and target network\ninto a representation of variational quantum circuits. Moreover, we use a\nquantum information encoding scheme to reduce the number of model parameters\ncompared to classical neural networks. To the best of our knowledge, this work\nis the first proof-of-principle demonstration of variational quantum circuits\nto approximate the deep $Q$-value function for decision-making and\npolicy-selection reinforcement learning with experience replay and target\nnetwork. Besides, our variational quantum circuits can be deployed in many\nnear-term NISQ machines.\n", "versions": [{"version": "v1", "created": "Sun, 30 Jun 2019 15:35:07 GMT"}, {"version": "v2", "created": "Sat, 17 Aug 2019 03:56:39 GMT"}, {"version": "v3", "created": "Mon, 20 Jul 2020 13:47:07 GMT"}], "update_date": "2020-07-21", "authors_parsed": [["Chen", "Samuel Yen-Chi", ""], ["Yang", "Chao-Han Huck", ""], ["Qi", "Jun", ""], ["Chen", "Pin-Yu", ""], ["Ma", "Xiaoli", ""], ["Goan", "Hsi-Sheng", ""]]}, {"id": "1907.00430", "submitter": "Nadisha-Marie Aliman", "authors": "Nadisha-Marie Aliman and Leon Kester", "title": "Requisite Variety in Ethical Utility Functions for AI Value Alignment", "comments": "IJCAI 2019 AI Safety Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Being a complex subject of major importance in AI Safety research, value\nalignment has been studied from various perspectives in the last years.\nHowever, no final consensus on the design of ethical utility functions\nfacilitating AI value alignment has been achieved yet. Given the urgency to\nidentify systematic solutions, we postulate that it might be useful to start\nwith the simple fact that for the utility function of an AI not to violate\nhuman ethical intuitions, it trivially has to be a model of these intuitions\nand reflect their variety $ - $ whereby the most accurate models pertaining to\nhuman entities being biological organisms equipped with a brain constructing\nconcepts like moral judgements, are scientific models. Thus, in order to better\nassess the variety of human morality, we perform a transdisciplinary analysis\napplying a security mindset to the issue and summarizing variety-relevant\nbackground knowledge from neuroscience and psychology. We complement this\ninformation by linking it to augmented utilitarianism as a suitable ethical\nframework. Based on that, we propose first practical guidelines for the design\nof approximate ethical goal functions that might better capture the variety of\nhuman moral judgements. Finally, we conclude and address future possible\nchallenges.\n", "versions": [{"version": "v1", "created": "Sun, 30 Jun 2019 18:55:31 GMT"}], "update_date": "2019-07-02", "authors_parsed": [["Aliman", "Nadisha-Marie", ""], ["Kester", "Leon", ""]]}, {"id": "1907.00456", "submitter": "Natasha Jaques", "authors": "Natasha Jaques, Asma Ghandeharioun, Judy Hanwen Shen, Craig Ferguson,\n  Agata Lapedriza, Noah Jones, Shixiang Gu, Rosalind Picard", "title": "Way Off-Policy Batch Deep Reinforcement Learning of Implicit Human\n  Preferences in Dialog", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most deep reinforcement learning (RL) systems are not able to learn\neffectively from off-policy data, especially if they cannot explore online in\nthe environment. These are critical shortcomings for applying RL to real-world\nproblems where collecting data is expensive, and models must be tested offline\nbefore being deployed to interact with the environment -- e.g. systems that\nlearn from human interaction. Thus, we develop a novel class of off-policy\nbatch RL algorithms, which are able to effectively learn offline, without\nexploring, from a fixed batch of human interaction data. We leverage models\npre-trained on data as a strong prior, and use KL-control to penalize\ndivergence from this prior during RL training. We also use dropout-based\nuncertainty estimates to lower bound the target Q-values as a more efficient\nalternative to Double Q-Learning. The algorithms are tested on the problem of\nopen-domain dialog generation -- a challenging reinforcement learning problem\nwith a 20,000-dimensional action space. Using our Way Off-Policy algorithm, we\ncan extract multiple different reward functions post-hoc from collected human\ninteraction data, and learn effectively from all of these. We test the\nreal-world generalization of these systems by deploying them live to converse\nwith humans in an open-domain setting, and demonstrate that our algorithm\nachieves significant improvements over prior methods in off-policy batch RL.\n", "versions": [{"version": "v1", "created": "Sun, 30 Jun 2019 20:53:19 GMT"}, {"version": "v2", "created": "Mon, 8 Jul 2019 17:21:46 GMT"}], "update_date": "2019-07-09", "authors_parsed": [["Jaques", "Natasha", ""], ["Ghandeharioun", "Asma", ""], ["Shen", "Judy Hanwen", ""], ["Ferguson", "Craig", ""], ["Lapedriza", "Agata", ""], ["Jones", "Noah", ""], ["Gu", "Shixiang", ""], ["Picard", "Rosalind", ""]]}, {"id": "1907.00526", "submitter": "Longxiang Shi", "authors": "Longxiang Shi, Shijian Li, Longbing Cao, Long Yang, Gang Zheng, Gang\n  Pan", "title": "FiDi-RL: Incorporating Deep Reinforcement Learning with\n  Finite-Difference Policy Search for Efficient Learning of Continuous Control", "comments": "I found some theoretical errors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years significant progress has been made in dealing with\nchallenging problems using reinforcement learning.Despite its great success,\nreinforcement learning still faces challenge in continuous control tasks.\nConventional methods always compute the derivatives of the optimal goal with a\ncostly computation resources, and are inefficient, unstable and lack of\nrobust-ness when dealing with such tasks. Alternatively, derivative-based\nmethods treat the optimization process as a blackbox and show robustness and\nstability in learning continuous control tasks, but not data efficient in\nlearning. The combination of both methods so as to get the best of the both has\nraised attention. However, most of the existing combination works adopt complex\nneural networks (NNs) as the policy for control. The double-edged sword of deep\nNNs can yield better performance, but also makes it difficult for parameter\ntuning and computation. To this end, in this paper we presents a novel method\ncalled FiDi-RL, which incorporates deep RL with Finite-Difference (FiDi) policy\nsearch.FiDi-RL combines Deep Deterministic Policy Gradients (DDPG)with Augment\nRandom Search (ARS) and aims at improving the data efficiency of ARS. The\nempirical results show that FiDi-RL can improves the performance and stability\nof ARS, and provide competitive results against some existing deep\nreinforcement learning methods\n", "versions": [{"version": "v1", "created": "Mon, 1 Jul 2019 03:21:19 GMT"}, {"version": "v2", "created": "Wed, 10 Jul 2019 03:29:40 GMT"}, {"version": "v3", "created": "Sat, 1 Feb 2020 03:22:47 GMT"}], "update_date": "2020-02-04", "authors_parsed": [["Shi", "Longxiang", ""], ["Li", "Shijian", ""], ["Cao", "Longbing", ""], ["Yang", "Long", ""], ["Zheng", "Gang", ""], ["Pan", "Gang", ""]]}, {"id": "1907.00570", "submitter": "Joris Baan", "authors": "Joris Baan, Maartje ter Hoeve, Marlies van der Wees, Anne Schuth,\n  Maarten de Rijke", "title": "Do Transformer Attention Heads Provide Transparency in Abstractive\n  Summarization?", "comments": "To appear at FACTS-IR 2019, SIGIR", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning algorithms become more powerful, often at the cost of increased\ncomplexity. In response, the demand for algorithms to be transparent is\ngrowing. In NLP tasks, attention distributions learned by attention-based deep\nlearning models are used to gain insights in the models' behavior. To which\nextent is this perspective valid for all NLP tasks? We investigate whether\ndistributions calculated by different attention heads in a transformer\narchitecture can be used to improve transparency in the task of abstractive\nsummarization. To this end, we present both a qualitative and quantitative\nanalysis to investigate the behavior of the attention heads. We show that some\nattention heads indeed specialize towards syntactically and semantically\ndistinct input. We propose an approach to evaluate to which extent the\nTransformer model relies on specifically learned attention distributions. We\nalso discuss what this implies for using attention distributions as a means of\ntransparency.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jul 2019 06:46:43 GMT"}, {"version": "v2", "created": "Mon, 8 Jul 2019 14:57:07 GMT"}], "update_date": "2019-07-09", "authors_parsed": [["Baan", "Joris", ""], ["ter Hoeve", "Maartje", ""], ["van der Wees", "Marlies", ""], ["Schuth", "Anne", ""], ["de Rijke", "Maarten", ""]]}, {"id": "1907.00607", "submitter": "Jiyuan Zheng", "authors": "Yutong Wang, Jiyuan Zheng, Qijiong Liu, Zhou Zhao, Jun Xiao, Yueting\n  Zhuang", "title": "Weak Supervision Enhanced Generative Network for Question Generation", "comments": "Published as a conference paper at IJCAI2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic question generation according to an answer within the given passage\nis useful for many applications, such as question answering system, dialogue\nsystem, etc. Current neural-based methods mostly take two steps which extract\nseveral important sentences based on the candidate answer through manual rules\nor supervised neural networks and then use an encoder-decoder framework to\ngenerate questions about these sentences. These approaches neglect the semantic\nrelations between the answer and the context of the whole passage which is\nsometimes necessary for answering the question. To address this problem, we\npropose the Weak Supervision Enhanced Generative Network (WeGen) which\nautomatically discovers relevant features of the passage given the answer span\nin a weakly supervised manner to improve the quality of generated questions.\nMore specifically, we devise a discriminator, Relation Guider, to capture the\nrelations between the whole passage and the associated answer and then the\nMulti-Interaction mechanism is deployed to transfer the knowledge dynamically\nfor our question generation system. Experiments show the effectiveness of our\nmethod in both automatic evaluations and human evaluations.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jul 2019 08:44:30 GMT"}], "update_date": "2019-07-02", "authors_parsed": [["Wang", "Yutong", ""], ["Zheng", "Jiyuan", ""], ["Liu", "Qijiong", ""], ["Zhao", "Zhou", ""], ["Xiao", "Jun", ""], ["Zhuang", "Yueting", ""]]}, {"id": "1907.00678", "submitter": "Alexandre Quemy", "authors": "Alexandre Quemy", "title": "Two-stage Optimization for Machine Learning Workflow", "comments": "Submitted to Information Systems, DOLAP special issue", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machines learning techniques plays a preponderant role in dealing with\nmassive amount of data and are employed in almost every possible domain.\nBuilding a high quality machine learning model to be deployed in production is\na challenging task, from both, the subject matter experts and the machine\nlearning practitioners.\n  For a broader adoption and scalability of machine learning systems, the\nconstruction and configuration of machine learning workflow need to gain in\nautomation. In the last few years, several techniques have been developed in\nthis direction, known as autoML.\n  In this paper, we present a two-stage optimization process to build data\npipelines and configure machine learning algorithms. First, we study the impact\nof data pipelines compared to algorithm configuration in order to show the\nimportance of data preprocessing over hyperparameter tuning. The second part\npresents policies to efficiently allocate search time between data pipeline\nconstruction and algorithm configuration. Those policies are agnostic from the\nmetaoptimizer. Last, we present a metric to determine if a data pipeline is\nspecific or independent from the algorithm, enabling fine-grain pipeline\npruning and meta-learning for the coldstart problem.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jul 2019 12:06:18 GMT"}], "update_date": "2019-07-02", "authors_parsed": [["Quemy", "Alexandre", ""]]}, {"id": "1907.00692", "submitter": "Sihem Sahnoun", "authors": "Sihem Sahnoun", "title": "Event extraction based on open information extraction and ontology", "comments": "arXiv admin note: text overlap with arXiv:1607.02784 by other authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The work presented in this master thesis consists of extracting a set of\nevents from texts written in natural language. For this purpose, we have based\nourselves on the basic notions of the information extraction as well as the\nopen information extraction. First, we applied an open information\nextraction(OIE) system for the relationship extraction, to highlight the\nimportance of OIEs in event extraction, and we used the ontology to the event\nmodeling. We tested the results of our approach with test metrics. As a result,\nthe two-level event extraction approach has shown good performance results but\nrequires a lot of expert intervention in the construction of classifiers and\nthis will take time. In this context we have proposed an approach that reduces\nthe expert intervention in the relation extraction, the recognition of entities\nand the reasoning which are automatic and based on techniques of adaptation and\ncorrespondence. Finally, to prove the relevance of the extracted results, we\nconducted a set of experiments using different test metrics as well as a\ncomparative study.\n", "versions": [{"version": "v1", "created": "Mon, 24 Jun 2019 16:24:46 GMT"}], "update_date": "2019-07-03", "authors_parsed": [["Sahnoun", "Sihem", ""]]}, {"id": "1907.00703", "submitter": "Benjamin Bleier", "authors": "B.S. Bleier", "title": "Information Flow Theory (IFT) of Biologic and Machine Consciousness:\n  Implications for Artificial General Intelligence and the Technological\n  Singularity", "comments": "23 Pages, 2 Figures, 1 Table, 1 Appendix", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.AI cs.ET cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The subjective experience of consciousness is at once familiar and yet deeply\nmysterious. Strategies exploring the top-down mechanisms of conscious thought\nwithin the human brain have been unable to produce a generalized explanatory\ntheory that scales through evolution and can be applied to artificial systems.\nInformation Flow Theory (IFT) provides a novel framework for understanding both\nthe development and nature of consciousness in any system capable of processing\ninformation. In prioritizing the direction of information flow over information\ncomputation, IFT produces a range of unexpected predictions. The purpose of\nthis manuscript is to introduce the basic concepts of IFT and explore the\nmanifold implications regarding artificial intelligence, superhuman\nconsciousness, and our basic perception of reality.\n", "versions": [{"version": "v1", "created": "Fri, 21 Jun 2019 15:01:25 GMT"}], "update_date": "2019-07-02", "authors_parsed": [["Bleier", "B. S.", ""]]}, {"id": "1907.00710", "submitter": "Lizi Liao Ms", "authors": "Lizi Liao, Ryuichi Takanobu, Yunshan Ma, Xun Yang, Minlie Huang and\n  Tat-Seng Chua", "title": "Deep Conversational Recommender in Travel", "comments": "12 pages, 7 figures, submitted to TKDE. arXiv admin note: text\n  overlap with arXiv:1809.07070 by other authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When traveling to a foreign country, we are often in dire need of an\nintelligent conversational agent to provide instant and informative responses\nto our various queries. However, to build such a travel agent is non-trivial.\nFirst of all, travel naturally involves several sub-tasks such as hotel\nreservation, restaurant recommendation and taxi booking etc, which invokes the\nneed for global topic control. Secondly, the agent should consider various\nconstraints like price or distance given by the user to recommend an\nappropriate venue. In this paper, we present a Deep Conversational Recommender\n(DCR) and apply to travel. It augments the sequence-to-sequence (seq2seq)\nmodels with a neural latent topic component to better guide response generation\nand make the training easier. To consider the various constraints for venue\nrecommendation, we leverage a graph convolutional network (GCN) based approach\nto capture the relationships between different venues and the match between\nvenue and dialog context. For response generation, we combine the topic-based\ncomponent with the idea of pointer networks, which allows us to effectively\nincorporate recommendation results. We perform extensive evaluation on a\nmulti-turn task-oriented dialog dataset in travel domain and the results show\nthat our method achieves superior performance as compared to a wide range of\nbaselines.\n", "versions": [{"version": "v1", "created": "Tue, 25 Jun 2019 04:39:26 GMT"}], "update_date": "2019-07-03", "authors_parsed": [["Liao", "Lizi", ""], ["Takanobu", "Ryuichi", ""], ["Ma", "Yunshan", ""], ["Yang", "Xun", ""], ["Huang", "Minlie", ""], ["Chua", "Tat-Seng", ""]]}, {"id": "1907.00716", "submitter": "Fuyuan Xiao", "authors": "Fuyuan Xiao", "title": "Evidential distance measure in complex belief function theory", "comments": "4 pages, 2 figures. arXiv admin note: text overlap with\n  arXiv:1906.11409", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, an evidential distance measure is proposed which can measure\nthe difference or dissimilarity between complex basic belief assignments\n(CBBAs), in which the CBBAs are composed of complex numbers. When the CBBAs are\ndegenerated from complex numbers to real numbers, i.e., BBAs, the proposed\ndistance will degrade into the Jousselme et al.'s distance. Therefore, the\nproposed distance provides a promising way to measure the differences between\nevidences in a more general framework of complex plane space.\n", "versions": [{"version": "v1", "created": "Thu, 27 Jun 2019 02:36:22 GMT"}], "update_date": "2019-07-02", "authors_parsed": [["Xiao", "Fuyuan", ""]]}, {"id": "1907.00720", "submitter": "Tianwen Jiang", "authors": "Tianwen Jiang, Tong Zhao, Bing Qin, Ting Liu, Nitesh V. Chawla, Meng\n  Jiang", "title": "Constructing Information-Lossless Biological Knowledge Graphs from\n  Conditional Statements", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conditions are essential in the statements of biological literature. Without\nthe conditions (e.g., environment, equipment) that were precisely specified,\nthe facts (e.g., observations) in the statements may no longer be valid. One\nbiological statement has one or multiple fact(s) and/or condition(s). Their\nsubject and object can be either a concept or a concept's attribute. Existing\ninformation extraction methods do not consider the role of condition in the\nbiological statement nor the role of attribute in the subject/object. In this\nwork, we design a new tag schema and propose a deep sequence tagging framework\nto structure conditional statement into fact and condition tuples from\nbiological text. Experiments demonstrate that our method yields a\ninformation-lossless structure of the literature.\n", "versions": [{"version": "v1", "created": "Wed, 26 Jun 2019 14:50:39 GMT"}], "update_date": "2019-07-02", "authors_parsed": [["Jiang", "Tianwen", ""], ["Zhao", "Tong", ""], ["Qin", "Bing", ""], ["Liu", "Ting", ""], ["Chawla", "Nitesh V.", ""], ["Jiang", "Meng", ""]]}, {"id": "1907.00852", "submitter": "Eugene Kharitonov", "authors": "Eugene Kharitonov and Rahma Chaabouni and Diane Bouchacourt and Marco\n  Baroni", "title": "EGG: a toolkit for research on Emergence of lanGuage in Games", "comments": "EMNLP 2019 Demo paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is renewed interest in simulating language emergence among deep neural\nagents that communicate to jointly solve a task, spurred by the practical aim\nto develop language-enabled interactive AIs, as well as by theoretical\nquestions about the evolution of human language. However, optimizing deep\narchitectures connected by a discrete communication channel (such as that in\nwhich language emerges) is technically challenging. We introduce EGG, a toolkit\nthat greatly simplifies the implementation of emergent-language communication\ngames. EGG's modular design provides a set of building blocks that the user can\ncombine to create new games, easily navigating the optimization and\narchitecture space. We hope that the tool will lower the technical barrier, and\nencourage researchers from various backgrounds to do original work in this\nexciting area.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jul 2019 15:20:01 GMT"}, {"version": "v2", "created": "Sun, 13 Oct 2019 11:13:49 GMT"}], "update_date": "2019-10-15", "authors_parsed": [["Kharitonov", "Eugene", ""], ["Chaabouni", "Rahma", ""], ["Bouchacourt", "Diane", ""], ["Baroni", "Marco", ""]]}, {"id": "1907.00854", "submitter": "Daniel Whitenack", "authors": "Shirish Hirekodi, Seban Sunny, Leonard Topno, Alwin Daniel, Daniel\n  Whitenack, Reuben Skewes, Stuart Cranney", "title": "Katecheo: A Portable and Modular System for Multi-Topic Question\n  Answering", "comments": "ACL 2020 system demo submission, 7 pages, 3 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a modular system that can be deployed on any Kubernetes cluster\nfor question answering via REST API. This system, called Katecheo, includes\nthree configurable modules that collectively enable identification of\nquestions, classification of those questions into topics, document search, and\nreading comprehension. We demonstrate the system using publicly available\nknowledge base articles extracted from Stack Exchange sites. However, users can\nextend the system to any number of topics, or domains, without the need to\nmodify any of the model serving code or train their own models. All components\nof the system are open source and available under a permissive Apache 2\nLicense.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jul 2019 15:20:10 GMT"}, {"version": "v2", "created": "Fri, 31 Jan 2020 19:01:40 GMT"}], "update_date": "2020-02-04", "authors_parsed": [["Hirekodi", "Shirish", ""], ["Sunny", "Seban", ""], ["Topno", "Leonard", ""], ["Daniel", "Alwin", ""], ["Whitenack", "Daniel", ""], ["Skewes", "Reuben", ""], ["Cranney", "Stuart", ""]]}, {"id": "1907.00868", "submitter": "Lucas Beyer", "authors": "Lucas Beyer, Damien Vincent, Olivier Teboul, Sylvain Gelly, Matthieu\n  Geist, Olivier Pietquin", "title": "MULEX: Disentangling Exploitation from Exploration in Deep RL", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  An agent learning through interactions should balance its action selection\nprocess between probing the environment to discover new rewards and using the\ninformation acquired in the past to adopt useful behaviour. This trade-off is\nusually obtained by perturbing either the agent's actions (e.g., e-greedy or\nGibbs sampling) or the agent's parameters (e.g., NoisyNet), or by modifying the\nreward it receives (e.g., exploration bonus, intrinsic motivation, or\nhand-shaped rewards). Here, we adopt a disruptive but simple and generic\nperspective, where we explicitly disentangle exploration and exploitation.\nDifferent losses are optimized in parallel, one of them coming from the true\nobjective (maximizing cumulative rewards from the environment) and others being\nrelated to exploration. Every loss is used in turn to learn a policy that\ngenerates transitions, all shared in a single replay buffer. Off-policy methods\nare then applied to these transitions to optimize each loss. We showcase our\napproach on a hard-exploration environment, show its sample-efficiency and\nrobustness, and discuss further implications.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jul 2019 15:28:02 GMT"}], "update_date": "2019-07-02", "authors_parsed": [["Beyer", "Lucas", ""], ["Vincent", "Damien", ""], ["Teboul", "Olivier", ""], ["Gelly", "Sylvain", ""], ["Geist", "Matthieu", ""], ["Pietquin", "Olivier", ""]]}, {"id": "1907.00878", "submitter": "Jan Niclas Reimann", "authors": "Jan Niclas Reimann, Andreas Schwung", "title": "Neural Logic Rule Layers", "comments": null, "journal-ref": null, "doi": "10.13140/RG.2.2.10091.59687", "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Despite their great success in recent years, deep neural networks (DNN) are\nmainly black boxes where the results obtained by running through the network\nare difficult to understand and interpret. Compared to e.g. decision trees or\nbayesian classifiers, DNN suffer from bad interpretability where we understand\nby interpretability, that a human can easily derive the relations modeled by\nthe network. A reasonable way to provide interpretability for humans are\nlogical rules. In this paper we propose neural logic rule layers (NLRL) which\nare able to represent arbitrary logic rules in terms of their conjunctive and\ndisjunctive normal forms. Using various NLRL within one layer and\ncorrespondingly stacking various layers, we are able to represent arbitrary\ncomplex rules by the resulting neural network architecture. The NLRL are\nend-to-end trainable allowing to learn logic rules directly from available data\nsets. Experiments show that NLRL-enhanced neural networks can learn to model\narbitrary complex logic and perform arithmetic operation over the input values.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jul 2019 15:49:06 GMT"}], "update_date": "2019-07-02", "authors_parsed": [["Reimann", "Jan Niclas", ""], ["Schwung", "Andreas", ""]]}, {"id": "1907.00883", "submitter": "Rahul Goel", "authors": "Rahul Goel, Shachi Paul, Dilek Hakkani-T\\\"ur", "title": "HyST: A Hybrid Approach for Flexible and Accurate Dialogue State\n  Tracking", "comments": "Interspeech 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recent works on end-to-end trainable neural network based approaches have\ndemonstrated state-of-the-art results on dialogue state tracking. The best\nperforming approaches estimate a probability distribution over all possible\nslot values. However, these approaches do not scale for large value sets\ncommonly present in real-life applications and are not ideal for tracking slot\nvalues that were not observed in the training set. To tackle these issues,\ncandidate-generation-based approaches have been proposed. These approaches\nestimate a set of values that are possible at each turn based on the\nconversation history and/or language understanding outputs, and hence enable\nstate tracking over unseen values and large value sets however, they fall short\nin terms of performance in comparison to the first group. In this work, we\nanalyze the performance of these two alternative dialogue state tracking\nmethods, and present a hybrid approach (HyST) which learns the appropriate\nmethod for each slot type. To demonstrate the effectiveness of HyST on a\nrich-set of slot types, we experiment with the recently released MultiWOZ-2.0\nmulti-domain, task-oriented dialogue-dataset. Our experiments show that HyST\nscales to multi-domain applications. Our best performing model results in a\nrelative improvement of 24% and 10% over the previous SOTA and our best\nbaseline respectively.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jul 2019 15:55:36 GMT"}], "update_date": "2019-07-02", "authors_parsed": [["Goel", "Rahul", ""], ["Paul", "Shachi", ""], ["Hakkani-T\u00fcr", "Dilek", ""]]}, {"id": "1907.00884", "submitter": "Nicholas Denis", "authors": "Nick Denis", "title": "On mechanisms for transfer using landmark value functions in multi-task\n  lifelong reinforcement learning", "comments": "12 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transfer learning across different reinforcement learning (RL) tasks is\nbecoming an increasingly valuable area of research. We consider a goal-based\nmulti-task RL framework and mechanisms by which previously solved tasks can\nreduce sample complexity and regret when the agent is faced with a new task.\nSpecifically, we introduce two metrics on the state space that encode notions\nof traversibility of the state space for an agent. Using these metrics a\ntopological covering is constructed by way of a set of landmark states in a\nfully self-supervised manner. We show that these landmark coverings confer\ntheoretical advantages for transfer learning within the goal-based multi-task\nRL setting. Specifically, we demonstrate three mechanisms by which landmark\ncoverings can be used for successful transfer learning. First, we extend the\nLandmark Options Via Reflection (LOVR) framework to this new topological\ncovering; second, we use the landmark-centric value functions themselves as\nfeatures and define a greedy zombie policy that achieves near oracle\nperformance on a sequence of zero-shot transfer tasks; finally, motivated by\nthe second transfer mechanism, we introduce a learned reward function that\nprovides a more dense reward signal for goal-based RL. Our novel topological\nlandmark covering confers beneficial theoretical results, bounding the Q values\nat each state-action pair. In doing so, we introduce a mechanism that performs\naction-pruning at infeasible actions which cannot possibly be part of an\noptimal policy for the current goal.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jul 2019 15:56:24 GMT"}], "update_date": "2019-07-02", "authors_parsed": [["Denis", "Nick", ""]]}, {"id": "1907.00921", "submitter": "Kalesha Bullard", "authors": "Kalesha Bullard, Yannick Schroecker, Sonia Chernova", "title": "Active Learning within Constrained Environments through Imitation of an\n  Expert Questioner", "comments": "In Conference Proceedings for IJCAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Active learning agents typically employ a query selection algorithm which\nsolely considers the agent's learning objectives. However, this may be\ninsufficient in more realistic human domains. This work uses imitation learning\nto enable an agent in a constrained environment to concurrently reason about\nboth its internal learning goals and environmental constraints externally\nimposed, all within its objective function. Experiments are conducted on a\nconcept learning task to test generalization of the proposed algorithm to\ndifferent environmental conditions and analyze how time and resource\nconstraints impact efficacy of solving the learning problem. Our findings show\nthe environmentally-aware learning agent is able to statistically outperform\nall other active learners explored under most of the constrained conditions. A\nkey implication is adaptation for active learning agents to more realistic\nhuman environments, where constraints are often externally imposed on the\nlearner.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jul 2019 16:53:47 GMT"}], "update_date": "2019-07-02", "authors_parsed": [["Bullard", "Kalesha", ""], ["Schroecker", "Yannick", ""], ["Chernova", "Sonia", ""]]}, {"id": "1907.00927", "submitter": "Adarsh Prasad", "authors": "Adarsh Prasad, Sivaraman Balakrishnan, Pradeep Ravikumar", "title": "A Unified Approach to Robust Mean Estimation", "comments": "51 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we develop connections between two seemingly disparate, but\ncentral, models in robust statistics: Huber's epsilon-contamination model and\nthe heavy-tailed noise model. We provide conditions under which this connection\nprovides near-statistically-optimal estimators. Building on this connection, we\nprovide a simple variant of recent computationally-efficient algorithms for\nmean estimation in Huber's model, which given our connection entails that the\nsame efficient sample-pruning based estimators is simultaneously robust to\nheavy-tailed noise and Huber contamination. Furthermore, we complement our\nefficient algorithms with statistically-optimal albeit computationally\nintractable estimators, which are simultaneously optimally robust in both\nmodels. We study the empirical performance of our proposed estimators on\nsynthetic datasets, and find that our methods convincingly outperform a variety\nof practical baselines.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jul 2019 17:03:11 GMT"}], "update_date": "2019-07-03", "authors_parsed": [["Prasad", "Adarsh", ""], ["Balakrishnan", "Sivaraman", ""], ["Ravikumar", "Pradeep", ""]]}, {"id": "1907.00953", "submitter": "Alex Lee", "authors": "Alex X. Lee, Anusha Nagabandi, Pieter Abbeel, Sergey Levine", "title": "Stochastic Latent Actor-Critic: Deep Reinforcement Learning with a\n  Latent Variable Model", "comments": "Project website: https://alexlee-gk.github.io/slac/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep reinforcement learning (RL) algorithms can use high-capacity deep\nnetworks to learn directly from image observations. However, these\nhigh-dimensional observation spaces present a number of challenges in practice,\nsince the policy must now solve two problems: representation learning and task\nlearning. In this work, we tackle these two problems separately, by explicitly\nlearning latent representations that can accelerate reinforcement learning from\nimages. We propose the stochastic latent actor-critic (SLAC) algorithm: a\nsample-efficient and high-performing RL algorithm for learning policies for\ncomplex continuous control tasks directly from high-dimensional image inputs.\nSLAC provides a novel and principled approach for unifying stochastic\nsequential models and RL into a single method, by learning a compact latent\nrepresentation and then performing RL in the model's learned latent space. Our\nexperimental evaluation demonstrates that our method outperforms both\nmodel-free and model-based alternatives in terms of final performance and\nsample efficiency, on a range of difficult image-based control tasks. Our code\nand videos of our results are available at our website.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jul 2019 17:45:09 GMT"}, {"version": "v2", "created": "Mon, 3 Feb 2020 15:07:43 GMT"}, {"version": "v3", "created": "Tue, 11 Aug 2020 16:02:04 GMT"}, {"version": "v4", "created": "Mon, 26 Oct 2020 12:21:51 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Lee", "Alex X.", ""], ["Nagabandi", "Anusha", ""], ["Abbeel", "Pieter", ""], ["Levine", "Sergey", ""]]}, {"id": "1907.01047", "submitter": "Maen Alzubi", "authors": "Maen Alzubi, Szilvester Kov\\'acs", "title": "Investigating The Piece-Wise Linearity And Benchmark Related To\n  Koczy-Hirota Fuzzy Linear Interpolation", "comments": null, "journal-ref": "Journal of Theoretical and Applied Information Technology 15th\n  June 2019. Vol.97. No 11", "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fuzzy Rule Interpolation (FRI) reasoning methods have been introduced to\naddress sparse fuzzy rule bases and reduce complexity. The first FRI method was\nthe Koczy and Hirota (KH) proposed \"Linear Interpolation\". Besides, several\nconditions and criteria have been suggested for unifying the common\nrequirements FRI methods have to satisfy. One of the most conditions is\nrestricted the fuzzy set of the conclusion must preserve a Piece-Wise Linearity\n(PWL) if all antecedents and consequents of the fuzzy rules are preserving on\nPWL sets at {\\alpha}-cut levels. The KH FRI is one of FRI methods which cannot\nsatisfy this condition. Therefore, the goal of this paper is to investigate\nequations and notations related to PWL property, which is aimed to highlight\nthe problematic properties of the KH FRI method to prove its efficiency with\nPWL condition. In addition, this paper is focusing on constructing benchmark\nexamples to be a baseline for testing other FRI methods against situations that\nare not satisfied with the linearity condition for KH FRI.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jul 2019 20:08:48 GMT"}, {"version": "v2", "created": "Tue, 12 Nov 2019 16:41:36 GMT"}], "update_date": "2019-11-13", "authors_parsed": [["Alzubi", "Maen", ""], ["Kov\u00e1cs", "Szilvester", ""]]}, {"id": "1907.01068", "submitter": "Robert Bamler", "authors": "Robert Bamler, Farnood Salehi, and Stephan Mandt", "title": "Augmenting and Tuning Knowledge Graph Embeddings", "comments": "Published version, Conference on Uncertainty in Artificial\n  Intelligence (UAI 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge graph embeddings rank among the most successful methods for link\nprediction in knowledge graphs, i.e., the task of completing an incomplete\ncollection of relational facts. A downside of these models is their strong\nsensitivity to model hyperparameters, in particular regularizers, which have to\nbe extensively tuned to reach good performance [Kadlec et al., 2017]. We\npropose an efficient method for large scale hyperparameter tuning by\ninterpreting these models in a probabilistic framework. After a model\naugmentation that introduces per-entity hyperparameters, we use a variational\nexpectation-maximization approach to tune thousands of such hyperparameters\nwith minimal additional cost. Our approach is agnostic to details of the model\nand results in a new state of the art in link prediction on standard benchmark\ndata.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jul 2019 20:40:37 GMT"}], "update_date": "2019-07-03", "authors_parsed": [["Bamler", "Robert", ""], ["Salehi", "Farnood", ""], ["Mandt", "Stephan", ""]]}, {"id": "1907.01101", "submitter": "Kashif Zia Dr.", "authors": "Kashif Zia, Arshad Muhammad, Dinesh Kumar Saini", "title": "A Simulation Study of Social-Networking-Driven Smart Recommendations for\n  Internet of Vehicles", "comments": "A concise version of the paper appeared in the proceeding of the 16th\n  International Conference on Practical Applications of Agents and Multi-Agent\n  Systems 2018 held in Toledo, Spain", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.AI cs.MA", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Social aspects of connectivity and information dispersion are often ignored\nwhile weighing the potential of Internet of Things (IoT). In the specialized\ndomain of Internet of Vehicles (IoV), Social IoV (SIoV) is introduced\nrealization its importance. Assuming a more commonly acceptable standardization\nof Big Data generated by IoV, the social dimensions enabling its fruitful usage\nremains a challenge. In this paper, an agent-based model of information sharing\nbetween vehicles for context-aware recommendations is presented. The model\nadheres to social dimensions as that of human society. Some important\nhypotheses are tested under reasonable connectivity and data constraints. The\nsimulation results reveal that closure of social ties and its timing impacts\ndispersion of novel information (necessary for a recommender system)\nsubstantially. It was also observed that as the network evolves as a result of\nincremental interactions, recommendations guaranteeing a fair distribution of\nvehicles across equally good competitors is not possible.\n", "versions": [{"version": "v1", "created": "Thu, 30 May 2019 06:12:05 GMT"}], "update_date": "2019-07-03", "authors_parsed": [["Zia", "Kashif", ""], ["Muhammad", "Arshad", ""], ["Saini", "Dinesh Kumar", ""]]}, {"id": "1907.01154", "submitter": "Jon McCormack", "authors": "Patrick Hutchings and Jon McCormack", "title": "Adaptive Music Composition for Games", "comments": "Preprint. Accepted for publication in IEEE Transactions on Games,\n  2019", "journal-ref": null, "doi": "10.1109/TG.2019.2921979", "report-no": null, "categories": "cs.MM cs.AI cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The generation of music that adapts dynamically to content and actions has an\nimportant role in building more immersive, memorable and emotive game\nexperiences. To date, the development of adaptive music systems for video games\nis limited by both the nature of algorithms used for real-time music generation\nand the limited modelling of player action, game world context and emotion in\ncurrent games. We propose that these issues must be addressed in tandem for the\nquality and flexibility of adaptive game music to significantly improve.\nCognitive models of knowledge organisation and emotional affect are integrated\nwith multi-modal, multi-agent composition techniques to produce a novel\nAdaptive Music System (AMS). The system is integrated into two stylistically\ndistinct games. Gamers reported an overall higher immersion and correlation of\nmusic with game-world concepts with the AMS than with the original game\nsoundtracks in both games.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jul 2019 04:10:02 GMT"}], "update_date": "2019-07-03", "authors_parsed": [["Hutchings", "Patrick", ""], ["McCormack", "Jon", ""]]}, {"id": "1907.01180", "submitter": "Aaron M. Roth", "authors": "Aaron M. Roth, Nicholay Topin, Pooyan Jamshidi, Manuela Veloso", "title": "Conservative Q-Improvement: Reinforcement Learning for an Interpretable\n  Decision-Tree Policy", "comments": "6 pages + 1 page of references", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is a growing desire in the field of reinforcement learning (and machine\nlearning in general) to move from black-box models toward more \"interpretable\nAI.\" We improve interpretability of reinforcement learning by increasing the\nutility of decision tree policies learned via reinforcement learning. These\npolicies consist of a decision tree over the state space, which requires fewer\nparameters to express than traditional policy representations. Existing methods\nfor creating decision tree policies via reinforcement learning focus on\naccurately representing an action-value function during training, but this\nleads to much larger trees than would otherwise be required. To address this\nshortcoming, we propose a novel algorithm which only increases tree size when\nthe estimated discounted future reward of the overall policy would increase by\na sufficient amount. Through evaluation in a simulated environment, we show\nthat its performance is comparable or superior to traditional tree-based\napproaches and that it yields a more succinct policy. Additionally, we discuss\ntuning parameters to control the tradeoff between optimizing for smaller tree\nsize or for overall reward.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jul 2019 05:51:04 GMT"}], "update_date": "2019-07-03", "authors_parsed": [["Roth", "Aaron M.", ""], ["Topin", "Nicholay", ""], ["Jamshidi", "Pooyan", ""], ["Veloso", "Manuela", ""]]}, {"id": "1907.01221", "submitter": "Kun Zhao", "authors": "Kun Zhao, Takayuki Osogami and Tetsuro Morimura", "title": "Visual analytics for team-based invasion sports with significant events\n  and Markov reward process", "comments": "8 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In team-based invasion sports such as soccer and basketball, analytics is\nimportant for teams to understand their performance and for audiences to\nunderstand matches better. The present work focuses on performing visual\nanalytics to evaluate the value of any kind of event occurring in a sports\nmatch with a continuous parameter space. Here, the continuous parameter space\ninvolves the time, location, score, and other parameters. Because the\nspatiotemporal data used in such analytics is a low-level representation and\nhas a very large size, however, traditional analytics may need to discretize\nthe continuous parameter space (e.g., subdivide the playing area) or use a\nlocal feature to limit the analysis to specific events (e.g., only shots).\nThese approaches make evaluation impossible for any kind of event with a\ncontinuous parameter space. To solve this problem, we consider a whole match as\na Markov chain of significant events, so that event values can be estimated\nwith a continuous parameter space by solving the Markov chain with a machine\nlearning model. The significant events are first extracted by considering the\ntime-varying distribution of players to represent the whole match. Then, the\nextracted events are redefined as different states with the continuous\nparameter space and built as a Markov chain so that a Markov reward process can\nbe applied. Finally, the Markov reward process is solved by a customized\nfitted-value iteration algorithm so that the event values with the continuous\nparameter space can be predicted by a regression model. As a result, the event\nvalues can be visually inspected over the whole playing field under arbitrary\ngiven conditions. Experimental results with real soccer data show the\neffectiveness of the proposed system.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jul 2019 08:11:16 GMT"}], "update_date": "2019-07-03", "authors_parsed": [["Zhao", "Kun", ""], ["Osogami", "Takayuki", ""], ["Morimura", "Tetsuro", ""]]}, {"id": "1907.01224", "submitter": "Jake Chandler", "authors": "Jake Chandler and Richard Booth", "title": "Elementary Iterated Revision and the Levi Identity", "comments": "Extended version of a paper accepted to LORI 2019 (22 pages)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work has considered the problem of extending to the case of iterated\nbelief change the so-called `Harper Identity' (HI), which defines single-shot\ncontraction in terms of single-shot revision. The present paper considers the\nprospects of providing a similar extension of the Levi Identity (LI), in which\nthe direction of definition runs the other way. We restrict our attention here\nto the three classic iterated revision operators--natural, restrained and\nlexicographic, for which we provide here the first collective characterisation\nin the literature, under the appellation of `elementary' operators. We consider\ntwo prima facie plausible ways of extending (LI). The first proposal involves\nthe use of the rational closure operator to offer a `reductive' account of\niterated revision in terms of iterated contraction. The second, which doesn't\ncommit to reductionism, was put forward some years ago by Nayak et al. We\nestablish that, for elementary revision operators and under mild assumptions\nregarding contraction, Nayak's proposal is equivalent to a new set of\npostulates formalising the claim that contraction by $\\neg A$ should be\nconsidered to be a kind of `mild' revision by $A$. We then show that these, in\nturn, under slightly weaker assumptions, jointly amount to the conjunction of a\npair of constraints on the extension of (HI) that were recently proposed in the\nliterature. Finally, we consider the consequences of endorsing both suggestions\nand show that this would yield an identification of rational revision with\nnatural revision. We close the paper by discussing the general prospects for\ndefining iterated revision in terms of iterated contraction.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jul 2019 08:14:38 GMT"}], "update_date": "2019-07-03", "authors_parsed": [["Chandler", "Jake", ""], ["Booth", "Richard", ""]]}, {"id": "1907.01285", "submitter": "Steffen Wolf", "authors": "Nasim Rahaman, Steffen Wolf, Anirudh Goyal, Roman Remme, Yoshua Bengio", "title": "Learning the Arrow of Time", "comments": "A shorter version of this work was presented at the Theoretical\n  Phyiscs for Deep Learning Workshop, ICML 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We humans seem to have an innate understanding of the asymmetric progression\nof time, which we use to efficiently and safely perceive and manipulate our\nenvironment. Drawing inspiration from that, we address the problem of learning\nan arrow of time in a Markov (Decision) Process. We illustrate how a learned\narrow of time can capture meaningful information about the environment, which\nin turn can be used to measure reachability, detect side-effects and to obtain\nan intrinsic reward signal. We show empirical results on a selection of\ndiscrete and continuous environments, and demonstrate for a class of stochastic\nprocesses that the learned arrow of time agrees reasonably well with a known\nnotion of an arrow of time given by the celebrated Jordan-Kinderlehrer-Otto\nresult.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jul 2019 10:32:09 GMT"}], "update_date": "2019-07-03", "authors_parsed": [["Rahaman", "Nasim", ""], ["Wolf", "Steffen", ""], ["Goyal", "Anirudh", ""], ["Remme", "Roman", ""], ["Bengio", "Yoshua", ""]]}, {"id": "1907.01297", "submitter": "Ekaterina Komendantskaya Dr", "authors": "Ekaterina Komendantskaya and Rob Stewart and Kirsy Duncan and Daniel\n  Kienitz and Pierre Le Hen and Pascal Bacchus", "title": "Neural Network Verification for the Masses (of AI graduates)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Rapid development of AI applications has stimulated demand for, and has given\nrise to, the rapidly growing number and diversity of AI MSc degrees. AI and\nRobotics research communities, industries and students are becoming\nincreasingly aware of the problems caused by unsafe or insecure AI\napplications. Among them, perhaps the most famous example is vulnerability of\ndeep neural networks to ``adversarial attacks''. Owing to wide-spread use of\nneural networks in all areas of AI, this problem is seen as particularly acute\nand pervasive.\n  Despite of the growing number of research papers about safety and security\nvulnerabilities of AI applications, there is a noticeable shortage of\naccessible tools, methods and teaching materials for incorporating verification\ninto AI programs. LAIV -- the Lab for AI and Verification -- is a newly opened\nresearch lab at Heriot-Watt university that engages AI and Robotics MSc\nstudents in verification projects, as part of their MSc dissertation work. In\nthis paper, we will report on successes and unexpected difficulties LAIV faces,\nmany of which arise from limitations of existing programming languages used for\nverification. We will discuss future directions for incorporating verification\ninto AI degrees.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jul 2019 11:09:04 GMT"}], "update_date": "2019-07-03", "authors_parsed": [["Komendantskaya", "Ekaterina", ""], ["Stewart", "Rob", ""], ["Duncan", "Kirsy", ""], ["Kienitz", "Daniel", ""], ["Hen", "Pierre Le", ""], ["Bacchus", "Pascal", ""]]}, {"id": "1907.01298", "submitter": "Matthieu Geist", "authors": "Erinc Merdivan, Sten Hanke and Matthieu Geist", "title": "Modified Actor-Critics", "comments": "Long version of AAMAS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Recent successful deep reinforcement learning algorithms, such as Trust\nRegion Policy Optimization (TRPO) or Proximal Policy Optimization (PPO), are\nfundamentally variations of conservative policy iteration (CPI). These\nalgorithms iterate policy evaluation followed by a softened policy improvement\nstep. As so, they are naturally on-policy. In this paper, we propose to combine\n(any kind of) soft greediness with Modified Policy Iteration (MPI). The\nproposed abstract framework applies repeatedly: (i) a partial policy evaluation\nstep that allows off-policy learning and (ii) any softened greedy step. Our\ncontribution can be seen as a new generic tool for the deep reinforcement\nlearning toolbox. As a proof of concept, we instantiate this framework with the\nPPO greediness. Comparison to the original PPO shows that our algorithm is much\nmore sample efficient. We also show that it is competitive with the\nstate-of-art off-policy algorithm Soft Actor Critic (SAC).\n", "versions": [{"version": "v1", "created": "Tue, 2 Jul 2019 11:22:56 GMT"}, {"version": "v2", "created": "Fri, 24 Jan 2020 10:08:28 GMT"}], "update_date": "2020-01-27", "authors_parsed": [["Merdivan", "Erinc", ""], ["Hanke", "Sten", ""], ["Geist", "Matthieu", ""]]}, {"id": "1907.01328", "submitter": "Erik Bryhn Myklebust", "authors": "Erik Bryhn Myklebust and Ernesto Jimenez-Ruiz and Jiaoyan Chen and\n  Raoul Wolf and Knut Erik Tollefsen", "title": "Knowledge Graph Embedding for Ecotoxicological Effect Prediction", "comments": null, "journal-ref": "In: Ghidini C. et al. (eds) The Semantic Web - ISWC 2019. ISWC\n  2019. Lecture Notes in Computer Science, vol 11779. Springer, Cham", "doi": "10.1007/978-3-030-30796-7_30", "report-no": null, "categories": "cs.AI cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Exploring the effects a chemical compound has on a species takes a\nconsiderable experimental effort. Appropriate methods for estimating and\nsuggesting new effects can dramatically reduce the work needed to be done by a\nlaboratory. In this paper we explore the suitability of using a knowledge graph\nembedding approach for ecotoxicological effect prediction. A knowledge graph\nhas been constructed from publicly available data sets, including a species\ntaxonomy and chemical classification and similarity. The publicly available\neffect data is integrated to the knowledge graph using ontology alignment\ntechniques. Our experimental results show that the knowledge graph based\napproach improves the selected baselines.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jul 2019 12:43:17 GMT"}, {"version": "v2", "created": "Thu, 29 Aug 2019 12:11:23 GMT"}, {"version": "v3", "created": "Mon, 11 Nov 2019 14:20:08 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["Myklebust", "Erik Bryhn", ""], ["Jimenez-Ruiz", "Ernesto", ""], ["Chen", "Jiaoyan", ""], ["Wolf", "Raoul", ""], ["Tollefsen", "Knut Erik", ""]]}, {"id": "1907.01368", "submitter": "Kimmo Kartasalo", "authors": "Peter Str\\\"om (1), Kimmo Kartasalo (2), Henrik Olsson (1), Leslie\n  Solorzano (3), Brett Delahunt (4), Daniel M. Berney (5), David G. Bostwick\n  (6), Andrew J. Evans (7), David J. Grignon (8), Peter A. Humphrey (9),\n  Kenneth A. Iczkowski (10), James G. Kench (11), Glen Kristiansen (12),\n  Theodorus H. van der Kwast (7), Katia R.M. Leite (13), Jesse K. McKenney\n  (14), Jon Oxley (15), Chin-Chen Pan (16), Hemamali Samaratunga (17), John R.\n  Srigley (18), Hiroyuki Takahashi (19), Toyonori Tsuzuki (20), Murali Varma\n  (21), Ming Zhou (22), Johan Lindberg (1), Cecilia Bergstr\\\"om (23), Pekka\n  Ruusuvuori (2), Carolina W\\\"ahlby (3 and 24), Henrik Gr\\\"onberg (1 and 25),\n  Mattias Rantalainen (1), Lars Egevad (26), Martin Eklund (1) ((1) Department\n  of Medical Epidemiology and Biostatistics, Karolinska Institutet, Stockholm,\n  Sweden, (2) Faculty of Medicine and Health Technology, Tampere University,\n  Tampere, Finland, (3) Centre for Image Analysis, Department of Information\n  Technology, Uppsala University, Uppsala, Sweden, (4) Department of Pathology\n  and Molecular Medicine, Wellington School of Medicine and Health Sciences,\n  University of Otago, Wellington, New Zealand, (5) Barts Cancer Institute,\n  Queen Mary University of London, London, UK, (6) Bostwick Laboratories,\n  Orlando, FL, USA, (7) Laboratory Medicine Program, University Health Network,\n  Toronto General Hospital, Toronto, ON, Canada, (8) Department of Pathology\n  and Laboratory Medicine, Indiana University School of Medicine, Indianapolis,\n  IN, USA, (9) Department of Pathology, Yale University School of Medicine, New\n  Haven, CT, USA, (10) Department of Pathology, Medical College of Wisconsin,\n  Milwaukee, WI, USA, (11) Department of Tissue Pathology and Diagnostic\n  Oncology, Royal Prince Alfred Hospital and Central Clinical School,\n  University of Sydney, Sydney, NSW, Australia, (12) Institute of Pathology,\n  University Hospital Bonn, Bonn, Germany, (13) Department of Urology,\n  Laboratory of Medical Research, University of S\\~ao Paulo Medical School,\n  S\\~ao Paulo, Brazil, (14) Pathology and Laboratory Medicine Institute,\n  Cleveland Clinic, Cleveland, OH, USA, (15) Department of Cellular Pathology,\n  Southmead Hospital, Bristol, UK, (16) Department of Pathology, Taipei\n  Veterans General Hospital, Taipei, Taiwan, (17) Aquesta Uropathology and\n  University of Queensland, Brisbane, Qld, Australia, (18) Department of\n  Laboratory Medicine and Pathobiology, University of Toronto, Toronto, ON,\n  Canada, (19) Department of Pathology, Jikei University School of Medicine,\n  Tokyo, Japan, (20) Department of Surgical Pathology, School of Medicine,\n  Aichi Medical University, Nagoya, Japan, (21) Department of Cellular\n  Pathology, University Hospital of Wales, Cardiff, UK, (22) Department of\n  Pathology, UT Southwestern Medical Center, Dallas, TX, USA, (23) Department\n  of Immunology, Genetics and Pathology, Uppsala University, Uppsala, Sweden,\n  (24) BioImage Informatics Facility of SciLifeLab, Uppsala, Sweden, (25)\n  Department of Oncology, S:t G\\\"oran Hospital, Stockholm, Sweden, (26)\n  Department of Oncology and Pathology, Karolinska Institutet, Stockholm,\n  Sweden)", "title": "Pathologist-Level Grading of Prostate Biopsies with Artificial\n  Intelligence", "comments": "45 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Background: An increasing volume of prostate biopsies and a world-wide\nshortage of uro-pathologists puts a strain on pathology departments.\nAdditionally, the high intra- and inter-observer variability in grading can\nresult in over- and undertreatment of prostate cancer. Artificial intelligence\n(AI) methods may alleviate these problems by assisting pathologists to reduce\nworkload and harmonize grading.\n  Methods: We digitized 6,682 needle biopsies from 976 participants in the\npopulation based STHLM3 diagnostic study to train deep neural networks for\nassessing prostate biopsies. The networks were evaluated by predicting the\npresence, extent, and Gleason grade of malignant tissue for an independent test\nset comprising 1,631 biopsies from 245 men. We additionally evaluated grading\nperformance on 87 biopsies individually graded by 23 experienced urological\npathologists from the International Society of Urological Pathology. We\nassessed discriminatory performance by receiver operating characteristics (ROC)\nand tumor extent predictions by correlating predicted millimeter cancer length\nagainst measurements by the reporting pathologist. We quantified the\nconcordance between grades assigned by the AI and the expert urological\npathologists using Cohen's kappa.\n  Results: The performance of the AI to detect and grade cancer in prostate\nneedle biopsy samples was comparable to that of international experts in\nprostate pathology. The AI achieved an area under the ROC curve of 0.997 for\ndistinguishing between benign and malignant biopsy cores, and 0.999 for\ndistinguishing between men with or without prostate cancer. The correlation\nbetween millimeter cancer predicted by the AI and assigned by the reporting\npathologist was 0.96. For assigning Gleason grades, the AI achieved an average\npairwise kappa of 0.62. This was within the range of the corresponding values\nfor the expert pathologists (0.60 to 0.73).\n", "versions": [{"version": "v1", "created": "Tue, 2 Jul 2019 13:52:02 GMT"}], "update_date": "2019-07-03", "authors_parsed": [["Str\u00f6m", "Peter", "", "3 and 24"], ["Kartasalo", "Kimmo", "", "3 and 24"], ["Olsson", "Henrik", "", "3 and 24"], ["Solorzano", "Leslie", "", "3 and 24"], ["Delahunt", "Brett", "", "3 and 24"], ["Berney", "Daniel M.", "", "3 and 24"], ["Bostwick", "David G.", "", "3 and 24"], ["Evans", "Andrew J.", "", "3 and 24"], ["Grignon", "David J.", "", "3 and 24"], ["Humphrey", "Peter A.", "", "3 and 24"], ["Iczkowski", "Kenneth A.", "", "3 and 24"], ["Kench", "James G.", "", "3 and 24"], ["Kristiansen", "Glen", "", "3 and 24"], ["van der Kwast", "Theodorus H.", "", "3 and 24"], ["Leite", "Katia R. M.", "", "3 and 24"], ["McKenney", "Jesse K.", "", "3 and 24"], ["Oxley", "Jon", "", "3 and 24"], ["Pan", "Chin-Chen", "", "3 and 24"], ["Samaratunga", "Hemamali", "", "3 and 24"], ["Srigley", "John R.", "", "3 and 24"], ["Takahashi", "Hiroyuki", "", "3 and 24"], ["Tsuzuki", "Toyonori", "", "3 and 24"], ["Varma", "Murali", "", "3 and 24"], ["Zhou", "Ming", "", "3 and 24"], ["Lindberg", "Johan", "", "3 and 24"], ["Bergstr\u00f6m", "Cecilia", "", "3 and 24"], ["Ruusuvuori", "Pekka", "", "3 and 24"], ["W\u00e4hlby", "Carolina", "", "3 and 24"], ["Gr\u00f6nberg", "Henrik", "", "1 and 25"], ["Rantalainen", "Mattias", ""], ["Egevad", "Lars", ""], ["Eklund", "Martin", ""]]}, {"id": "1907.01385", "submitter": "Yue Xu", "authors": "Yue Xu, Zengde Deng, Mengdi Wang, Wenjun Xu, Anthony Man-Cho So,\n  Shuguang Cui", "title": "Voting-Based Multi-Agent Reinforcement Learning for Intelligent IoT", "comments": "Published at IEEE Internet of Things Journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recent success of single-agent reinforcement learning (RL) in Internet of\nthings (IoT) systems motivates the study of multi-agent reinforcement learning\n(MARL), which is more challenging but more useful in large-scale IoT. In this\npaper, we consider a voting-based MARL problem, in which the agents vote to\nmake group decisions and the goal is to maximize the globally averaged returns.\nTo this end, we formulate the MARL problem based on the linear programming form\nof the policy optimization problem and propose a distributed primal-dual\nalgorithm to obtain the optimal solution. We also propose a voting mechanism\nthrough which the distributed learning achieves the same sublinear convergence\nrate as centralized learning. In other words, the distributed decision making\ndoes not slow down the process of achieving global consensus on optimality.\nLastly, we verify the convergence of our proposed algorithm with numerical\nsimulations and conduct case studies in practical multi-agent IoT systems.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jul 2019 14:12:51 GMT"}, {"version": "v2", "created": "Mon, 2 Mar 2020 09:52:36 GMT"}, {"version": "v3", "created": "Sat, 29 Aug 2020 09:37:42 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Xu", "Yue", ""], ["Deng", "Zengde", ""], ["Wang", "Mengdi", ""], ["Xu", "Wenjun", ""], ["So", "Anthony Man-Cho", ""], ["Cui", "Shuguang", ""]]}, {"id": "1907.01405", "submitter": "Xingyu Li", "authors": "Xingyu Li, Mainak Mitra, Bogdan I. Epureanu", "title": "Analysis of the Synergy between Modularity and Autonomy in an Artificial\n  Intelligence Based Fleet Competition", "comments": "4 pages, 4 figures, 2019 NDIA Ground Vehicle Systems Engineering and\n  Technology Symposium", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A novel approach is provided for evaluating the benefits and burdens from\nvehicle modularity in fleets/units through the analysis of a game theoretical\nmodel of the competition between autonomous vehicle fleets in an\nattacker-defender game. We present an approach to obtain the heuristic\noperational strategies through fitting a decision tree on high-fidelity\nsimulation results of an intelligent agent-based model. A multi-stage game\ntheoretical model is also created for decision making considering military\nresources and impacts of past decisions. Nash equilibria of the operational\nstrategy are revealed, and their characteristics are explored. The benefits of\nfleet modularity are also analyzed by comparing the results of the decision\nmaking process under diverse operational situations.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jul 2019 14:34:30 GMT"}], "update_date": "2019-07-03", "authors_parsed": [["Li", "Xingyu", ""], ["Mitra", "Mainak", ""], ["Epureanu", "Bogdan I.", ""]]}, {"id": "1907.01475", "submitter": "Zachary Kenton", "authors": "Zachary Kenton, Angelos Filos, Owain Evans, Yarin Gal", "title": "Generalizing from a few environments in safety-critical reinforcement\n  learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Before deploying autonomous agents in the real world, we need to be confident\nthey will perform safely in novel situations. Ideally, we would expose agents\nto a very wide range of situations during training, allowing them to learn\nabout every possible danger, but this is often impractical. This paper\ninvestigates safety and generalization from a limited number of training\nenvironments in deep reinforcement learning (RL). We find RL algorithms can\nfail dangerously on unseen test environments even when performing perfectly on\ntraining environments. Firstly, in a gridworld setting, we show that\ncatastrophes can be significantly reduced with simple modifications, including\nensemble model averaging and the use of a blocking classifier. In the more\nchallenging CoinRun environment we find similar methods do not significantly\nreduce catastrophes. However, we do find that the uncertainty information from\nthe ensemble is useful for predicting whether a catastrophe will occur within a\nfew steps and hence whether human intervention should be requested.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jul 2019 16:12:34 GMT"}], "update_date": "2019-07-03", "authors_parsed": [["Kenton", "Zachary", ""], ["Filos", "Angelos", ""], ["Evans", "Owain", ""], ["Gal", "Yarin", ""]]}, {"id": "1907.01615", "submitter": "Anna Belova", "authors": "Anna Belova, Wen He, Ziyi Zhong", "title": "E-Sports Talent Scouting Based on Multimodal Twitch Stream Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose and investigate feasibility of a novel task that consists in\nfinding e-sports talent using multimodal Twitch chat and video stream data. In\nthat, we focus on predicting the ranks of Counter-Strike: Global Offensive\n(CS:GO) gamers who broadcast their games on Twitch. During January 2019-April\n2019, we have built two Twitch stream collections: One for 425 publicly ranked\nCS:GO gamers and one for 9,928 unranked CS:GO gamers. We extract neural\nfeatures from video, audio and text chat data and estimate modality-specific\nprobabilities for a gamer to be top-ranked during the data collection\ntime-frame. A hierarchical Bayesian model is then used to pool the evidence\nacross modalities and generate estimates of intrinsic skill for each gamer. Our\nmodeling is validated through correlating the intrinsic skill predictions with\nMay 2019 ranks of the publicly profiled gamers.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jul 2019 20:06:21 GMT"}], "update_date": "2019-07-04", "authors_parsed": [["Belova", "Anna", ""], ["He", "Wen", ""], ["Zhong", "Ziyi", ""]]}, {"id": "1907.01623", "submitter": "Fernando de Mesentier Silva", "authors": "Fernando de Mesentier Silva, Rodrigo Canaan, Scott Lee, Matthew C.\n  Fontaine, Julian Togelius and Amy K. Hoover", "title": "Evolving the Hearthstone Meta", "comments": "IEEE Conference on Games 2019. 8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Balancing an ever growing strategic game of high complexity, such as\nHearthstone is a complex task. The target of making strategies diverse and\ncustomizable results in a delicate intricate system. Tuning over 2000 cards to\ngenerate the desired outcome without disrupting the existing environment\nbecomes a laborious challenge. In this paper, we discuss the impacts that\nchanges to existing cards can have on strategy in Hearthstone. By analyzing the\nwin rate on match-ups across different decks, being played by different\nstrategies, we propose to compare their performance before and after changes\nare made to improve or worsen different cards. Then, using an evolutionary\nalgorithm, we search for a combination of changes to the card attributes that\ncause the decks to approach equal, 50% win rates. We then expand our\nevolutionary algorithm to a multi-objective solution to search for this result,\nwhile making the minimum amount of changes, and as a consequence disruption, to\nthe existing cards. Lastly, we propose and evaluate metrics to serve as\nheuristics with which to decide which cards to target with balance changes.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jul 2019 20:32:08 GMT"}], "update_date": "2019-07-04", "authors_parsed": [["Silva", "Fernando de Mesentier", ""], ["Canaan", "Rodrigo", ""], ["Lee", "Scott", ""], ["Fontaine", "Matthew C.", ""], ["Togelius", "Julian", ""], ["Hoover", "Amy K.", ""]]}, {"id": "1907.01627", "submitter": "Paolo Pareti Dr.", "authors": "Paolo Pareti and George Konstantinidis and Timothy J. Norman and Murat\n  \\c{S}ensoy", "title": "Rule Applicability on RDF Triplestore Schemas", "comments": "AI for Internet of Things Workshop, co-located with the 28th\n  International Joint Conference on Artificial Intelligence (IJCAI-19)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Rule-based systems play a critical role in health and safety, where policies\ncreated by experts are usually formalised as rules. When dealing with\nincreasingly large and dynamic sources of data, as in the case of Internet of\nThings (IoT) applications, it becomes important not only to efficiently apply\nrules, but also to reason about their applicability on datasets confined by a\ncertain schema. In this paper we define the notion of a triplestore schema\nwhich models a set of RDF graphs. Given a set of rules and such a schema as\ninput we propose a method to determine rule applicability and produce output\nschemas. Output schemas model the graphs that would be obtained by running the\nrules on the graph models of the input schema. We present two approaches: one\nbased on computing a canonical (critical) instance of the schema, and a novel\napproach based on query rewriting. We provide theoretical, complexity and\nevaluation results that show the superior efficiency of our rewriting approach.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jul 2019 20:50:01 GMT"}], "update_date": "2019-07-04", "authors_parsed": [["Pareti", "Paolo", ""], ["Konstantinidis", "George", ""], ["Norman", "Timothy J.", ""], ["\u015eensoy", "Murat", ""]]}, {"id": "1907.01669", "submitter": "Rahul Goel", "authors": "Mihail Eric, Rahul Goel, Shachi Paul, Adarsh Kumar, Abhishek Sethi,\n  Peter Ku, Anuj Kumar Goyal, Sanchit Agarwal, Shuyang Gao, Dilek Hakkani-Tu\\\"r", "title": "MultiWOZ 2.1: A Consolidated Multi-Domain Dialogue Dataset with State\n  Corrections and State Tracking Baselines", "comments": "Data release writeup", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  MultiWOZ 2.0 (Budzianowski et al., 2018) is a recently released multi-domain\ndialogue dataset spanning 7 distinct domains and containing over 10,000\ndialogues. Though immensely useful and one of the largest resources of its kind\nto-date, MultiWOZ 2.0 has a few shortcomings. Firstly, there is substantial\nnoise in the dialogue state annotations and dialogue utterances which\nnegatively impact the performance of state-tracking models. Secondly, follow-up\nwork (Lee et al., 2019) has augmented the original dataset with user dialogue\nacts. This leads to multiple co-existent versions of the same dataset with\nminor modifications. In this work we tackle the aforementioned issues by\nintroducing MultiWOZ 2.1. To fix the noisy state annotations, we use\ncrowdsourced workers to re-annotate state and utterances based on the original\nutterances in the dataset. This correction process results in changes to over\n32% of state annotations across 40% of the dialogue turns. In addition, we fix\n146 dialogue utterances by canonicalizing slot values in the utterances to the\nvalues in the dataset ontology. To address the second problem, we combined the\ncontributions of the follow-up works into MultiWOZ 2.1. Hence, our dataset also\nincludes user dialogue acts as well as multiple slot descriptions per dialogue\nstate slot. We then benchmark a number of state-of-the-art dialogue state\ntracking models on the MultiWOZ 2.1 dataset and show the joint state tracking\nperformance on the corrected state annotations. We are publicly releasing\nMultiWOZ 2.1 to the community, hoping that this dataset resource will allow for\nmore effective models across various dialogue subproblems to be built in the\nfuture.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jul 2019 22:30:31 GMT"}, {"version": "v2", "created": "Wed, 20 Nov 2019 21:06:30 GMT"}, {"version": "v3", "created": "Fri, 22 Nov 2019 18:34:38 GMT"}, {"version": "v4", "created": "Tue, 3 Dec 2019 22:41:37 GMT"}], "update_date": "2019-12-05", "authors_parsed": [["Eric", "Mihail", ""], ["Goel", "Rahul", ""], ["Paul", "Shachi", ""], ["Kumar", "Adarsh", ""], ["Sethi", "Abhishek", ""], ["Ku", "Peter", ""], ["Goyal", "Anuj Kumar", ""], ["Agarwal", "Sanchit", ""], ["Gao", "Shuyang", ""], ["Hakkani-Tur", "Dilek", ""]]}, {"id": "1907.01682", "submitter": "Kinzang Chhogyal", "authors": "Kinzang Chhogyal, Abhaya Nayak, Aditya Ghose, Mehmet Orgun and Hoa Dam", "title": "On Conforming and Conflicting Values", "comments": "AI for Social Good Workshop, IJCAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Values are things that are important to us. Actions activate values - they\neither go against our values or they promote our values. Values themselves can\neither be conforming or conflicting depending on the action that is taken. In\nthis short paper, we argue that values may be classified as one of two types -\nconflicting and inherently conflicting values. They are distinguished by the\nfact that the latter in some sense can be thought of as being independent of\nactions. This allows us to do two things: i) check whether a set of values is\nconsistent and ii) check whether it is in conflict with other sets of values.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jul 2019 23:40:31 GMT"}, {"version": "v2", "created": "Mon, 8 Jul 2019 01:59:05 GMT"}], "update_date": "2019-07-09", "authors_parsed": [["Chhogyal", "Kinzang", ""], ["Nayak", "Abhaya", ""], ["Ghose", "Aditya", ""], ["Orgun", "Mehmet", ""], ["Dam", "Hoa", ""]]}, {"id": "1907.01697", "submitter": "Dongrui Wu", "authors": "Dongrui Wu and Jerry Mendel", "title": "Recommendations on Designing Practical Interval Type-2 Fuzzy Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Interval type-2 (IT2) fuzzy systems have become increasingly popular in the\nlast 20 years. They have demonstrated superior performance in many\napplications. However, the operation of an IT2 fuzzy system is more complex\nthan that of its type-1 counterpart. There are many questions to be answered in\ndesigning an IT2 fuzzy system: Should singleton or non-singleton fuzzifier be\nused? How many membership functions (MFs) should be used for each input? Should\nGaussian or piecewise linear MFs be used? Should Mamdani or Takagi-Sugeno-Kang\n(TSK) inference be used? Should minimum or product $t$-norm be used? Should\ntype-reduction be used or not? How to optimize the IT2 fuzzy system? These\nquestions may look overwhelming and confusing to IT2 beginners. In this paper\nwe recommend some representative starting choices for an IT2 fuzzy system\ndesign, which hopefully will make IT2 fuzzy systems more accessible to IT2\nfuzzy system designers.\n", "versions": [{"version": "v1", "created": "Wed, 3 Jul 2019 01:32:38 GMT"}], "update_date": "2019-07-04", "authors_parsed": [["Wu", "Dongrui", ""], ["Mendel", "Jerry", ""]]}, {"id": "1907.01743", "submitter": "Haoran Dou", "authors": "Yi Wang, Haoran Dou, Xiaowei Hu, Lei Zhu, Xin Yang, Ming Xu, Jing Qin,\n  Pheng-Ann Heng, Tianfu Wang, and Dong Ni", "title": "Deep Attentive Features for Prostate Segmentation in 3D Transrectal\n  Ultrasound", "comments": "11 pages, 10 figures, 2 tables. Accepted by IEEE transactions on\n  Medical Imaging", "journal-ref": null, "doi": "10.1109/TMI.2019.2913184", "report-no": null, "categories": "eess.IV cs.AI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic prostate segmentation in transrectal ultrasound (TRUS) images is of\nessential importance for image-guided prostate interventions and treatment\nplanning. However, developing such automatic solutions remains very challenging\ndue to the missing/ambiguous boundary and inhomogeneous intensity distribution\nof the prostate in TRUS, as well as the large variability in prostate shapes.\nThis paper develops a novel 3D deep neural network equipped with attention\nmodules for better prostate segmentation in TRUS by fully exploiting the\ncomplementary information encoded in different layers of the convolutional\nneural network (CNN). Our attention module utilizes the attention mechanism to\nselectively leverage the multilevel features integrated from different layers\nto refine the features at each individual layer, suppressing the non-prostate\nnoise at shallow layers of the CNN and increasing more prostate details into\nfeatures at deep layers. Experimental results on challenging 3D TRUS volumes\nshow that our method attains satisfactory segmentation performance. The\nproposed attention mechanism is a general strategy to aggregate multi-level\ndeep features and has the potential to be used for other medical image\nsegmentation tasks. The code is publicly available at\nhttps://github.com/wulalago/DAF3D.\n", "versions": [{"version": "v1", "created": "Wed, 3 Jul 2019 05:21:52 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Wang", "Yi", ""], ["Dou", "Haoran", ""], ["Hu", "Xiaowei", ""], ["Zhu", "Lei", ""], ["Yang", "Xin", ""], ["Xu", "Ming", ""], ["Qin", "Jing", ""], ["Heng", "Pheng-Ann", ""], ["Wang", "Tianfu", ""], ["Ni", "Dong", ""]]}, {"id": "1907.01752", "submitter": "Leshem Choshen", "authors": "Leshem Choshen, Lior Fox, Zohar Aizenbud, Omri Abend", "title": "On the Weaknesses of Reinforcement Learning for Neural Machine\n  Translation", "comments": "Accepted to ICLR 2020 (matching content, different style)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning (RL) is frequently used to increase performance in\ntext generation tasks, including machine translation (MT), notably through the\nuse of Minimum Risk Training (MRT) and Generative Adversarial Networks (GAN).\nHowever, little is known about what and how these methods learn in the context\nof MT. We prove that one of the most common RL methods for MT does not optimize\nthe expected reward, as well as show that other methods take an infeasibly long\ntime to converge. In fact, our results suggest that RL practices in MT are\nlikely to improve performance only where the pre-trained parameters are already\nclose to yielding the correct translation. Our findings further suggest that\nobserved gains may be due to effects unrelated to the training signal, but\nrather from changes in the shape of the distribution curve.\n", "versions": [{"version": "v1", "created": "Wed, 3 Jul 2019 06:15:14 GMT"}, {"version": "v2", "created": "Sat, 9 Nov 2019 13:57:23 GMT"}, {"version": "v3", "created": "Mon, 23 Dec 2019 10:31:04 GMT"}, {"version": "v4", "created": "Wed, 15 Jan 2020 07:19:09 GMT"}], "update_date": "2020-01-16", "authors_parsed": [["Choshen", "Leshem", ""], ["Fox", "Lior", ""], ["Aizenbud", "Zohar", ""], ["Abend", "Omri", ""]]}, {"id": "1907.01771", "submitter": "Ulysse Marteau-Ferey", "authors": "Ulysse Marteau-Ferey (SIERRA, DI-ENS, PSL), Francis Bach (SIERRA,\n  DI-ENS, PSL), Alessandro Rudi (SIERRA, DI-ENS, PSL)", "title": "Globally Convergent Newton Methods for Ill-conditioned Generalized\n  Self-concordant Losses", "comments": null, "journal-ref": "NeurIPS 2019 - Conference on Neural Information Processing\n  Systems, Dec 2019, Vancouver, Canada", "doi": null, "report-no": null, "categories": "math.OC cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study large-scale convex optimization algorithms based on\nthe Newton method applied to regularized generalized self-concordant losses,\nwhich include logistic regression and softmax regression. We first prove that\nour new simple scheme based on a sequence of problems with decreasing\nregularization parameters is provably globally convergent, that this\nconvergence is linear with a constant factor which scales only logarithmically\nwith the condition number. In the parametric setting, we obtain an algorithm\nwith the same scaling than regular first-order methods but with an improved\nbehavior, in particular in ill-conditioned problems. Second, in the non\nparametric machine learning setting, we provide an explicit algorithm combining\nthe previous scheme with Nystr{\\\"o}m projection techniques, and prove that it\nachieves optimal generalization bounds with a time complexity of order O(ndf\n$\\lambda$), a memory complexity of order O(df 2 $\\lambda$) and no dependence on\nthe condition number, generalizing the results known for least-squares\nregression. Here n is the number of observations and df $\\lambda$ is the\nassociated degrees of freedom. In particular, this is the first large-scale\nalgorithm to solve logistic and softmax regressions in the non-parametric\nsetting with large condition numbers and theoretical guarantees.\n", "versions": [{"version": "v1", "created": "Wed, 3 Jul 2019 07:15:44 GMT"}, {"version": "v2", "created": "Thu, 21 Nov 2019 15:09:01 GMT"}], "update_date": "2019-11-22", "authors_parsed": [["Marteau-Ferey", "Ulysse", "", "SIERRA, DI-ENS, PSL"], ["Bach", "Francis", "", "SIERRA,\n  DI-ENS, PSL"], ["Rudi", "Alessandro", "", "SIERRA, DI-ENS, PSL"]]}, {"id": "1907.01791", "submitter": "Shiva P", "authors": "Shiva Pentyala, Mengwen Liu, Markus Dreyer", "title": "Multi-Task Networks With Universe, Group, and Task Feature Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present methods for multi-task learning that take advantage of natural\ngroupings of related tasks. Task groups may be defined along known properties\nof the tasks, such as task domain or language. Such task groups represent\nsupervised information at the inter-task level and can be encoded into the\nmodel. We investigate two variants of neural network architectures that\naccomplish this, learning different feature spaces at the levels of individual\ntasks, task groups, as well as the universe of all tasks: (1) parallel\narchitectures encode each input simultaneously into feature spaces at different\nlevels; (2) serial architectures encode each input successively into feature\nspaces at different levels in the task hierarchy. We demonstrate the methods on\nnatural language understanding (NLU) tasks, where a grouping of tasks into\ndifferent task domains leads to improved performance on ATIS, Snips, and a\nlarge inhouse dataset.\n", "versions": [{"version": "v1", "created": "Wed, 3 Jul 2019 08:39:14 GMT"}], "update_date": "2019-07-04", "authors_parsed": [["Pentyala", "Shiva", ""], ["Liu", "Mengwen", ""], ["Dreyer", "Markus", ""]]}, {"id": "1907.01845", "submitter": "Xiangxiang Chu", "authors": "Xiangxiang Chu and Bo Zhang and Ruijun Xu", "title": "FairNAS: Rethinking Evaluation Fairness of Weight Sharing Neural\n  Architecture Search", "comments": "Accepted to ICCV21", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the most critical problems in weight-sharing neural architecture\nsearch is the evaluation of candidate models within a predefined search space.\nIn practice, a one-shot supernet is trained to serve as an evaluator. A\nfaithful ranking certainly leads to more accurate searching results. However,\ncurrent methods are prone to making misjudgments. In this paper, we prove that\ntheir biased evaluation is due to inherent unfairness in the supernet training.\nIn view of this, we propose two levels of constraints: expectation fairness and\nstrict fairness. Particularly, strict fairness ensures equal optimization\nopportunities for all choice blocks throughout the training, which neither\noverestimates nor underestimates their capacity. We demonstrate that this is\ncrucial for improving the confidence of models' ranking. Incorporating the\none-shot supernet trained under the proposed fairness constraints with a\nmulti-objective evolutionary search algorithm, we obtain various\nstate-of-the-art models, e.g., FairNAS-A attains 77.5% top-1 validation\naccuracy on ImageNet. The models and their evaluation codes are made publicly\navailable online http://github.com/fairnas/FairNAS .\n", "versions": [{"version": "v1", "created": "Wed, 3 Jul 2019 10:50:38 GMT"}, {"version": "v2", "created": "Wed, 14 Aug 2019 06:16:45 GMT"}, {"version": "v3", "created": "Wed, 20 Nov 2019 06:41:45 GMT"}, {"version": "v4", "created": "Tue, 10 Mar 2020 11:53:02 GMT"}, {"version": "v5", "created": "Wed, 28 Jul 2021 10:19:08 GMT"}], "update_date": "2021-07-29", "authors_parsed": [["Chu", "Xiangxiang", ""], ["Zhang", "Bo", ""], ["Xu", "Ruijun", ""]]}, {"id": "1907.01851", "submitter": "Aqeel Labash", "authors": "Aqeel Labash, Jaan Aru, Tambet Matiisen, Ardi Tampuu, Raul Vicente", "title": "Perspective Taking in Deep Reinforcement Learning Agents", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.MA", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Perspective taking is the ability to take the point of view of another agent.\nThis skill is not unique to humans as it is also displayed by other animals\nlike chimpanzees. It is an essential ability for social interactions, including\nefficient cooperation, competition, and communication. Here we present our\nprogress toward building artificial agents with such abilities. We implemented\na perspective taking task inspired by experiments done with chimpanzees. We\nshow that agents controlled by artificial neural networks can learn via\nreinforcement learning to pass simple tests that require perspective taking\ncapabilities. We studied whether this ability is more readily learned by agents\nwith information encoded in allocentric or egocentric form for both their\nvisual perception and motor actions. We believe that, in the long run, building\nbetter artificial agents with perspective taking ability can help us develop\nartificial intelligence that is more human-like and easier to communicate with.\n", "versions": [{"version": "v1", "created": "Wed, 3 Jul 2019 11:08:28 GMT"}, {"version": "v2", "created": "Thu, 16 Apr 2020 00:57:24 GMT"}], "update_date": "2020-04-17", "authors_parsed": [["Labash", "Aqeel", ""], ["Aru", "Jaan", ""], ["Matiisen", "Tambet", ""], ["Tampuu", "Ardi", ""], ["Vicente", "Raul", ""]]}, {"id": "1907.01894", "submitter": "Francis Bunnin", "authors": "F.O.Bunnin and J.Q.Smith", "title": "A Bayesian Hierarchical Model for Criminal Investigations", "comments": "57 pages, 20 figures, 8 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Potential violent criminals will often need to go through a sequence of\npreparatory steps before they can execute their plans. During this escalation\nprocess police have the opportunity to evaluate the threat posed by such people\nthrough what they know, observe and learn from intelligence reports about their\nactivities. In this paper we customise a three-level Bayesian hierarchical\nmodel to describe this process. This is able to propagate both routine and\nunexpected evidence in real time. We discuss how to set up such a model so that\nit calibrates to domain expert judgments. The model illustrations include a\nhypothetical example based on a potential vehicle based terrorist attack.\n", "versions": [{"version": "v1", "created": "Wed, 3 Jul 2019 12:40:42 GMT"}, {"version": "v2", "created": "Tue, 5 Nov 2019 14:39:31 GMT"}], "update_date": "2019-11-06", "authors_parsed": [["Bunnin", "F. O.", ""], ["Smith", "J. Q.", ""]]}, {"id": "1907.01912", "submitter": "Stefano Albrecht", "authors": "Stefano V. Albrecht, S. Ramamoorthy", "title": "Are You Doing What I Think You Are Doing? Criticising Uncertain Agent\n  Models", "comments": "Proceedings of the 31st Conference on Uncertainty in Artificial\n  Intelligence (UAI), 2015. arXiv admin note: substantial text overlap with\n  arXiv:1507.07688", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The key for effective interaction in many multiagent applications is to\nreason explicitly about the behaviour of other agents, in the form of a\nhypothesised behaviour. While there exist several methods for the construction\nof a behavioural hypothesis, there is currently no universal theory which would\nallow an agent to contemplate the correctness of a hypothesis. In this work, we\npresent a novel algorithm which decides this question in the form of a\nfrequentist hypothesis test. The algorithm allows for multiple metrics in the\nconstruction of the test statistic and learns its distribution during the\ninteraction process, with asymptotic correctness guarantees. We present results\nfrom a comprehensive set of experiments, demonstrating that the algorithm\nachieves high accuracy and scalability at low computational costs.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jul 2019 14:09:48 GMT"}], "update_date": "2019-07-04", "authors_parsed": [["Albrecht", "Stefano V.", ""], ["Ramamoorthy", "S.", ""]]}, {"id": "1907.01929", "submitter": "German I. Parisi", "authors": "German I. Parisi, Christopher Kanan", "title": "Rethinking Continual Learning for Autonomous Agents and Robots", "comments": "arXiv admin note: substantial text overlap with arXiv:1802.07569", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Continual learning refers to the ability of a biological or artificial system\nto seamlessly learn from continuous streams of information while preventing\ncatastrophic forgetting, i.e., a condition in which new incoming information\nstrongly interferes with previously learned representations. Since it is\nunrealistic to provide artificial agents with all the necessary prior knowledge\nto effectively operate in real-world conditions, they must exhibit a rich set\nof learning capabilities enabling them to interact in complex environments with\nthe aim to process and make sense of continuous streams of (often uncertain)\ninformation. While the vast majority of continual learning models are designed\nto alleviate catastrophic forgetting on simplified classification tasks, here\nwe focus on continual learning for autonomous agents and robots required to\noperate in much more challenging experimental settings. In particular, we\ndiscuss well-established biological learning factors such as developmental and\ncurriculum learning, transfer learning, and intrinsic motivation and their\ncomputational counterparts for modeling the progressive acquisition of\nincreasingly complex knowledge and skills in a continual fashion.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jul 2019 16:51:45 GMT"}], "update_date": "2019-07-04", "authors_parsed": [["Parisi", "German I.", ""], ["Kanan", "Christopher", ""]]}, {"id": "1907.01932", "submitter": "Tomas Kulvicius", "authors": "Florentin W\\\"org\\\"otter, Fatemeh Ziaeetabar, Stefan Pfeiffer, Osman\n  Kaya, Tomas Kulvicius, Minija Tamosiunaite", "title": "Action Prediction in Humans and Robots", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Efficient action prediction is of central importance for the fluent workflow\nbetween humans and equally so for human-robot interaction. To achieve\nprediction, actions can be encoded by a series of events, where every event\ncorresponds to a change in a (static or dynamic) relation between some of the\nobjects in a scene. Manipulation actions and others can be uniquely encoded\nthis way and only, on average, less than 60% of the time series has to pass\nuntil an action can be predicted. Using a virtual reality setup and testing ten\ndifferent manipulation actions, here we show that in most cases humans predict\nactions at the same event as the algorithm. In addition, we perform an in-depth\nanalysis about the temporal gain resulting from such predictions when chaining\nactions and show in some robotic experiments that the percentage gain for\nhumans and robots is approximately equal. Thus, if robots use this algorithm\nthen their prediction-moments will be compatible to those of their human\ninteraction partners, which should much benefit natural human-robot\ncollaboration.\n", "versions": [{"version": "v1", "created": "Wed, 3 Jul 2019 13:23:03 GMT"}], "update_date": "2019-07-04", "authors_parsed": [["W\u00f6rg\u00f6tter", "Florentin", ""], ["Ziaeetabar", "Fatemeh", ""], ["Pfeiffer", "Stefan", ""], ["Kaya", "Osman", ""], ["Kulvicius", "Tomas", ""], ["Tamosiunaite", "Minija", ""]]}, {"id": "1907.01978", "submitter": "Hsu-Chieh Hu", "authors": "Hsu-Chieh Hu and Stephen F. Smith", "title": "Using Bi-Directional Information Exchange to Improve Decentralized\n  Schedule-Driven Traffic Control", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work in decentralized, schedule-driven traffic control has\ndemonstrated the ability to improve the efficiency of traffic flow in complex\nurban road networks. In this approach, a scheduling agent is associated with\neach intersection. Each agent senses the traffic approaching its intersection\nand in real-time constructs a schedule that minimizes the cumulative wait time\nof vehicles approaching the intersection over the current look-ahead horizon.\nIn order to achieve network level coordination in a scalable manner, scheduling\nagents communicate only with their direct neighbors. Each time an agent\ngenerates a new intersection schedule it communicates its expected outflows to\nits downstream neighbors as a prediction of future demand and these outflows\nare appended to the downstream agent's locally perceived demand. In this paper,\nwe extend this basic coordination algorithm to additionally incorporate the\ncomplementary flow of information reflective of an intersection's current\ncongestion level to its upstream neighbors. We present an asynchronous\ndecentralized algorithm for updating intersection schedules and congestion\nlevel estimates based on these bi-directional information flows. By relating\nthis algorithm to the self-optimized decision making of the basic operation, we\nare able to approach network-wide optimality and reduce inefficiency due to\nstrictly self-interested intersection control decisions.\n", "versions": [{"version": "v1", "created": "Wed, 3 Jul 2019 15:04:16 GMT"}], "update_date": "2019-07-04", "authors_parsed": [["Hu", "Hsu-Chieh", ""], ["Smith", "Stephen F.", ""]]}, {"id": "1907.02022", "submitter": "Peter Anderson", "authors": "Peter Anderson, Ayush Shrivastava, Devi Parikh, Dhruv Batra and Stefan\n  Lee", "title": "Chasing Ghosts: Instruction Following as Bayesian State Tracking", "comments": "NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CL cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A visually-grounded navigation instruction can be interpreted as a sequence\nof expected observations and actions an agent following the correct trajectory\nwould encounter and perform. Based on this intuition, we formulate the problem\nof finding the goal location in Vision-and-Language Navigation (VLN) within the\nframework of Bayesian state tracking - learning observation and motion models\nconditioned on these expectable events. Together with a mapper that constructs\na semantic spatial map on-the-fly during navigation, we formulate an end-to-end\ndifferentiable Bayes filter and train it to identify the goal by predicting the\nmost likely trajectory through the map according to the instructions. The\nresulting navigation policy constitutes a new approach to instruction following\nthat explicitly models a probability distribution over states, encoding strong\ngeometric and algorithmic priors while enabling greater explainability. Our\nexperiments show that our approach outperforms a strong LingUNet baseline when\npredicting the goal location on the map. On the full VLN task, i.e. navigating\nto the goal location, our approach achieves promising results with less\nreliance on navigation constraints.\n", "versions": [{"version": "v1", "created": "Wed, 3 Jul 2019 16:39:05 GMT"}, {"version": "v2", "created": "Tue, 26 Nov 2019 18:52:33 GMT"}], "update_date": "2019-11-27", "authors_parsed": [["Anderson", "Peter", ""], ["Shrivastava", "Ayush", ""], ["Parikh", "Devi", ""], ["Batra", "Dhruv", ""], ["Lee", "Stefan", ""]]}, {"id": "1907.02031", "submitter": "Lin Li", "authors": "Dong Li, Lin Li", "title": "Combining Q&A Pair Quality and Question Relevance Features on\n  Community-based Question Retrieval", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Q&A community has become an important way for people to access knowledge\nand information from the Internet. However, the existing translation based on\nmodels does not consider the query specific semantics when assigning weights to\nquery terms in question retrieval. So we improve the term weighting model based\non the traditional topic translation model and further considering the quality\ncharacteristics of question and answer pairs, this paper proposes a\ncommunitybased question retrieval method that combines question and answer on\nquality and question relevance (T2LM+). We have also proposed a question\nretrieval method based on convolutional neural networks. The results show that\nCompared with the relatively advanced methods, the two methods proposed in this\npaper increase MAP by 4.91% and 6.31%.\n", "versions": [{"version": "v1", "created": "Wed, 3 Jul 2019 16:53:28 GMT"}], "update_date": "2019-07-04", "authors_parsed": [["Li", "Dong", ""], ["Li", "Lin", ""]]}, {"id": "1907.02050", "submitter": "Daniel Saunders", "authors": "Sam Wenke, Dan Saunders, Mike Qiu, Jim Fleming", "title": "Reasoning and Generalization in RL: A Tool Use Perspective", "comments": "13 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning to use tools to solve a variety of tasks is an innate ability of\nhumans and has been observed of animals in the wild. However, the underlying\nmechanisms that are required to learn to use tools are abstract and widely\ncontested in the literature. In this paper, we study tool use in the context of\nreinforcement learning and propose a framework for analyzing generalization\ninspired by a classic study of tool using behavior, the trap-tube task.\nRecently, it has become common in reinforcement learning to measure\ngeneralization performance on a single test set of environments. We instead\npropose transfers that produce multiple test sets that are used to measure\nspecified types of generalization, inspired by abilities demonstrated by animal\nand human tool users. The source code to reproduce our experiments is publicly\navailable at https://github.com/fomorians/gym_tool_use.\n", "versions": [{"version": "v1", "created": "Wed, 3 Jul 2019 17:35:58 GMT"}], "update_date": "2019-07-04", "authors_parsed": [["Wenke", "Sam", ""], ["Saunders", "Dan", ""], ["Qiu", "Mike", ""], ["Fleming", "Jim", ""]]}, {"id": "1907.02057", "submitter": "Tingwu Wang", "authors": "Tingwu Wang, Xuchan Bao, Ignasi Clavera, Jerrick Hoang, Yeming Wen,\n  Eric Langlois, Shunshi Zhang, Guodong Zhang, Pieter Abbeel, Jimmy Ba", "title": "Benchmarking Model-Based Reinforcement Learning", "comments": "8 main pages, 8 figures; 14 appendix pages, 25 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Model-based reinforcement learning (MBRL) is widely seen as having the\npotential to be significantly more sample efficient than model-free RL.\nHowever, research in model-based RL has not been very standardized. It is\nfairly common for authors to experiment with self-designed environments, and\nthere are several separate lines of research, which are sometimes\nclosed-sourced or not reproducible. Accordingly, it is an open question how\nthese various existing MBRL algorithms perform relative to each other. To\nfacilitate research in MBRL, in this paper we gather a wide collection of MBRL\nalgorithms and propose over 18 benchmarking environments specially designed for\nMBRL. We benchmark these algorithms with unified problem settings, including\nnoisy environments. Beyond cataloguing performance, we explore and unify the\nunderlying algorithmic differences across MBRL algorithms. We characterize\nthree key research challenges for future MBRL research: the dynamics\nbottleneck, the planning horizon dilemma, and the early-termination dilemma.\nFinally, to maximally facilitate future research on MBRL, we open-source our\nbenchmark in http://www.cs.toronto.edu/~tingwuwang/mbrl.html.\n", "versions": [{"version": "v1", "created": "Wed, 3 Jul 2019 17:53:02 GMT"}], "update_date": "2019-07-04", "authors_parsed": [["Wang", "Tingwu", ""], ["Bao", "Xuchan", ""], ["Clavera", "Ignasi", ""], ["Hoang", "Jerrick", ""], ["Wen", "Yeming", ""], ["Langlois", "Eric", ""], ["Zhang", "Shunshi", ""], ["Zhang", "Guodong", ""], ["Abbeel", "Pieter", ""], ["Ba", "Jimmy", ""]]}, {"id": "1907.02116", "submitter": "Paria Mehrani", "authors": "Paria Mehrani, Andrei Mouraviev, and John K. Tsotsos", "title": "Multiplicative modulations in hue-selective cells enhance unique hue\n  representation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  There is still much to understand about the color processing mechanisms in\nthe brain and the transformation from cone-opponent representations to\nperceptual hues. Moreover, it is unclear which areas(s) in the brain represent\nunique hues. We propose a hierarchical model inspired by the neuronal\nmechanisms in the brain for local hue representation, which reveals the\ncontributions of each visual cortical area in hue representation. Local hue\nencoding is achieved through incrementally increasing processing nonlinearities\nbeginning with cone input. Besides employing nonlinear rectifications, we\npropose multiplicative modulations as a form of nonlinearity. Our simulation\nresults indicate that multiplicative modulations have significant contributions\nin encoding of hues along intermediate directions in the MacLeod-Boynton\ndiagram and that model V4 neurons have the capacity to encode unique hues.\nAdditionally, responses of our model neurons resemble those of biological color\ncells, suggesting that our model provides a novel formulation of the brain's\ncolor processing pathway.\n", "versions": [{"version": "v1", "created": "Wed, 3 Jul 2019 19:57:33 GMT"}], "update_date": "2019-07-05", "authors_parsed": [["Mehrani", "Paria", ""], ["Mouraviev", "Andrei", ""], ["Tsotsos", "John K.", ""]]}, {"id": "1907.02124", "submitter": "Xiaolong Ma", "authors": "Xiaolong Ma, Sheng Lin, Shaokai Ye, Zhezhi He, Linfeng Zhang, Geng\n  Yuan, Sia Huat Tan, Zhengang Li, Deliang Fan, Xuehai Qian, Xue Lin, Kaisheng\n  Ma, Yanzhi Wang", "title": "Non-Structured DNN Weight Pruning -- Is It Beneficial in Any Platform?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large deep neural network (DNN) models pose the key challenge to energy\nefficiency due to the significantly higher energy consumption of off-chip DRAM\naccesses than arithmetic or SRAM operations. It motivates the intensive\nresearch on model compression with two main approaches. Weight pruning\nleverages the redundancy in the number of weights and can be performed in a\nnon-structured, which has higher flexibility and pruning rate but incurs index\naccesses due to irregular weights, or structured manner, which preserves the\nfull matrix structure with lower pruning rate. Weight quantization leverages\nthe redundancy in the number of bits in weights. Compared to pruning,\nquantization is much more hardware-friendly, and has become a \"must-do\" step\nfor FPGA and ASIC implementations. This paper provides a definitive answer to\nthe question for the first time. First, we build ADMM-NN-S by extending and\nenhancing ADMM-NN, a recently proposed joint weight pruning and quantization\nframework. Second, we develop a methodology for fair and fundamental comparison\nof non-structured and structured pruning in terms of both storage and\ncomputation efficiency. Our results show that ADMM-NN-S consistently\noutperforms the prior art: (i) it achieves 348x, 36x, and 8x overall weight\npruning on LeNet-5, AlexNet, and ResNet-50, respectively, with (almost) zero\naccuracy loss; (ii) we demonstrate the first fully binarized (for all layers)\nDNNs can be lossless in accuracy in many cases. These results provide a strong\nbaseline and credibility of our study. Based on the proposed comparison\nframework, with the same accuracy and quantization, the results show that\nnon-structrued pruning is not competitive in terms of both storage and\ncomputation efficiency. Thus, we conclude that non-structured pruning is\nconsidered harmful. We urge the community not to continue the DNN inference\nacceleration for non-structured sparsity.\n", "versions": [{"version": "v1", "created": "Wed, 3 Jul 2019 20:27:51 GMT"}, {"version": "v2", "created": "Tue, 7 Jan 2020 19:43:16 GMT"}], "update_date": "2020-01-09", "authors_parsed": [["Ma", "Xiaolong", ""], ["Lin", "Sheng", ""], ["Ye", "Shaokai", ""], ["He", "Zhezhi", ""], ["Zhang", "Linfeng", ""], ["Yuan", "Geng", ""], ["Tan", "Sia Huat", ""], ["Li", "Zhengang", ""], ["Fan", "Deliang", ""], ["Qian", "Xuehai", ""], ["Lin", "Xue", ""], ["Ma", "Kaisheng", ""], ["Wang", "Yanzhi", ""]]}, {"id": "1907.02140", "submitter": "Tadahiro Taniguchi", "authors": "Akira Kinose and Tadahiro Taniguchi", "title": "Integration of Imitation Learning using GAIL and Reinforcement Learning\n  using Task-achievement Rewards via Probabilistic Graphical Model", "comments": "Submitted to Advanced Robotics", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Integration of reinforcement learning and imitation learning is an important\nproblem that has been studied for a long time in the field of intelligent\nrobotics. Reinforcement learning optimizes policies to maximize the cumulative\nreward, whereas imitation learning attempts to extract general knowledge about\nthe trajectories demonstrated by experts, i.e., demonstrators. Because each of\nthem has their own drawbacks, methods combining them and compensating for each\nset of drawbacks have been explored thus far. However, many of the methods are\nheuristic and do not have a solid theoretical basis. In this paper, we present\na new theory for integrating reinforcement and imitation learning by extending\nthe probabilistic generative model framework for reinforcement learning, {\\it\nplan by inference}. We develop a new probabilistic graphical model for\nreinforcement learning with multiple types of rewards and a probabilistic\ngraphical model for Markov decision processes with multiple optimality\nemissions (pMDP-MO). Furthermore, we demonstrate that the integrated learning\nmethod of reinforcement learning and imitation learning can be formulated as a\nprobabilistic inference of policies on pMDP-MO by considering the output of the\ndiscriminator in generative adversarial imitation learning as an additional\noptimal emission observation. We adapt the generative adversarial imitation\nlearning and task-achievement reward to our proposed framework, achieving\nsignificantly better performance than agents trained with reinforcement\nlearning or imitation learning alone. Experiments demonstrate that our\nframework successfully integrates imitation and reinforcement learning even\nwhen the number of demonstrators is only a few.\n", "versions": [{"version": "v1", "created": "Wed, 3 Jul 2019 21:38:48 GMT"}, {"version": "v2", "created": "Wed, 16 Oct 2019 08:24:58 GMT"}], "update_date": "2019-10-17", "authors_parsed": [["Kinose", "Akira", ""], ["Taniguchi", "Tadahiro", ""]]}, {"id": "1907.02170", "submitter": "Duligur Ibeling", "authors": "Duligur Ibeling, Thomas Icard", "title": "On Open-Universe Causal Reasoning", "comments": "UAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We extend two kinds of causal models, structural equation models and\nsimulation models, to infinite variable spaces. This enables a semantics for\nconditionals founded on a calculus of intervention, and axiomatization of\ncausal reasoning for rich, expressive generative models -- including those in\nwhich a causal representation exists only implicitly -- in an open-universe\nsetting. Further, we show that under suitable restrictions the two kinds of\nmodels are equivalent, perhaps surprisingly as their axiomatizations differ\nsubstantially in the general case. We give a series of complete axiomatizations\nin which the open-universe nature of the setting is seen to be essential.\n", "versions": [{"version": "v1", "created": "Thu, 4 Jul 2019 00:31:20 GMT"}, {"version": "v2", "created": "Wed, 2 Jun 2021 08:08:14 GMT"}], "update_date": "2021-06-03", "authors_parsed": [["Ibeling", "Duligur", ""], ["Icard", "Thomas", ""]]}, {"id": "1907.02227", "submitter": "Anhong Guo", "authors": "Anhong Guo, Ece Kamar, Jennifer Wortman Vaughan, Hanna Wallach,\n  Meredith Ringel Morris", "title": "Toward Fairness in AI for People with Disabilities: A Research Roadmap", "comments": "ACM ASSETS 2019 Workshop on AI Fairness for People with Disabilities", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  AI technologies have the potential to dramatically impact the lives of people\nwith disabilities (PWD). Indeed, improving the lives of PWD is a motivator for\nmany state-of-the-art AI systems, such as automated speech recognition tools\nthat can caption videos for people who are deaf and hard of hearing, or\nlanguage prediction algorithms that can augment communication for people with\nspeech or cognitive disabilities. However, widely deployed AI systems may not\nwork properly for PWD, or worse, may actively discriminate against them. These\nconsiderations regarding fairness in AI for PWD have thus far received little\nattention. In this position paper, we identify potential areas of concern\nregarding how several AI technology categories may impact particular disability\nconstituencies if care is not taken in their design, development, and testing.\nWe intend for this risk assessment of how various classes of AI might interact\nwith various classes of disability to provide a roadmap for future research\nthat is needed to gather data, test these hypotheses, and build more inclusive\nalgorithms.\n", "versions": [{"version": "v1", "created": "Thu, 4 Jul 2019 05:29:49 GMT"}, {"version": "v2", "created": "Fri, 2 Aug 2019 18:39:41 GMT"}], "update_date": "2019-08-06", "authors_parsed": [["Guo", "Anhong", ""], ["Kamar", "Ece", ""], ["Vaughan", "Jennifer Wortman", ""], ["Wallach", "Hanna", ""], ["Morris", "Meredith Ringel", ""]]}, {"id": "1907.02349", "submitter": "Jichen Zhu", "authors": "Jichen Zhu, Santiago Onta\\~n\\'on", "title": "Experience Management in Multi-player Games", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Experience Management studies AI systems that automatically adapt interactive\nexperiences such as games to tailor to specific players and to fulfill design\ngoals. Although it has been explored for several decades, existing work in\nexperience management has mostly focused on single-player experiences. This\npaper is a first attempt at identifying the main challenges to expand EM to\nmulti-player/multi-user games or experiences. We also make connections to\nrelated areas where solutions for similar problems have been proposed\n(especially group recommender systems) and discusses the potential impact and\napplications of multi-player EM.\n", "versions": [{"version": "v1", "created": "Thu, 4 Jul 2019 12:03:03 GMT"}], "update_date": "2019-07-05", "authors_parsed": [["Zhu", "Jichen", ""], ["Onta\u00f1\u00f3n", "Santiago", ""]]}, {"id": "1907.02405", "submitter": "Hadrien Cambazard", "authors": "Grigori German, Hadrien Cambazard, Jean-Philippe Gayon, Bernard Penz", "title": "A global constraint for the capacitated single-item lot-sizing problem", "comments": "28 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The goal of this paper is to set a constraint programming framework to solve\nlot-sizing problems. More specifically, we consider a single-item lot-sizing\nproblem with time-varying lower and upper bounds for production and inventory.\nThe cost structure includes time-varying holding costs, unitary production\ncosts and setup costs. We establish a new lower bound for this problem by using\na subtle time decomposition. We formulate this NP-hard problem as a global\nconstraint and show that bound consistency can be achieved in pseudo-polynomial\ntime and when not including the costs, in polynomial time. We develop filtering\nrules based on existing dynamic programming algorithms, exploiting the above\nmentioned time decomposition for difficult instances. In a numerical study, we\ncompare several formulations of the problem: mixed integer linear programming,\nconstraint programming and dynamic programming. We show that our global\nconstraint is able to find solutions, unlike the decomposed constraint\nprogramming model and that constraint programming can be competitive, in\nparticular when adding combinatorial side constraints.\n", "versions": [{"version": "v1", "created": "Thu, 4 Jul 2019 13:57:39 GMT"}], "update_date": "2019-07-05", "authors_parsed": [["German", "Grigori", ""], ["Cambazard", "Hadrien", ""], ["Gayon", "Jean-Philippe", ""], ["Penz", "Bernard", ""]]}, {"id": "1907.02509", "submitter": "Alexey Ignatiev", "authors": "Alexey Ignatiev, Nina Narodytska, Joao Marques-Silva", "title": "On Validating, Repairing and Refining Heuristic ML Explanations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent years have witnessed a fast-growing interest in computing explanations\nfor Machine Learning (ML) models predictions. For non-interpretable ML models,\nthe most commonly used approaches for computing explanations are heuristic in\nnature. In contrast, recent work proposed rigorous approaches for computing\nexplanations, which hold for a given ML model and prediction over the entire\ninstance space. This paper extends earlier work to the case of boosted trees\nand assesses the quality of explanations obtained with state-of-the-art\nheuristic approaches. On most of the datasets considered, and for the vast\nmajority of instances, the explanations obtained with heuristic approaches are\nshown to be inadequate when the entire instance space is (implicitly)\nconsidered.\n", "versions": [{"version": "v1", "created": "Thu, 4 Jul 2019 17:45:11 GMT"}], "update_date": "2019-07-05", "authors_parsed": [["Ignatiev", "Alexey", ""], ["Narodytska", "Nina", ""], ["Marques-Silva", "Joao", ""]]}, {"id": "1907.02548", "submitter": "Levi Lelis", "authors": "D\\^amaris S. Bento, Andr\\'e G. Pereira and Levi H. S. Lelis", "title": "Procedural Generation of Initial States of Sokoban", "comments": "Accepted for publication at IJCAI'19", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Procedural generation of initial states of state-space search problems have\napplications in human and machine learning as well as in the evaluation of\nplanning systems. In this paper we deal with the task of generating hard and\nsolvable initial states of Sokoban puzzles. We propose hardness metrics based\non pattern database heuristics and the use of novelty to improve the\nexploration of search methods in the task of generating initial states. We then\npresent a system called Beta that uses our hardness metrics and novelty to\ngenerate initial states. Experiments show that Beta is able to generate initial\nstates that are harder to solve by a specialized solver than those designed by\nhuman experts.\n", "versions": [{"version": "v1", "created": "Thu, 4 Jul 2019 18:06:25 GMT"}], "update_date": "2019-07-08", "authors_parsed": [["Bento", "D\u00e2maris S.", ""], ["Pereira", "Andr\u00e9 G.", ""], ["Lelis", "Levi H. S.", ""]]}, {"id": "1907.02582", "submitter": "Ana Lucic", "authors": "Ana Lucic, Hinda Haned, Maarten de Rijke", "title": "Explaining Predictions from Tree-based Boosting Ensembles", "comments": "SIGIR 2019: FACTS-IR Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding how \"black-box\" models arrive at their predictions has sparked\nsignificant interest from both within and outside the AI community. Our work\nfocuses on doing this by generating local explanations about individual\npredictions for tree-based ensembles, specifically Gradient Boosting Decision\nTrees (GBDTs). Given a correctly predicted instance in the training set, we\nwish to generate a counterfactual explanation for this instance, that is, the\nminimal perturbation of this instance such that the prediction flips to the\nopposite class. Most existing methods for counterfactual explanations are (1)\nmodel-agnostic, so they do not take into account the structure of the original\nmodel, and/or (2) involve building a surrogate model on top of the original\nmodel, which is not guaranteed to represent the original model accurately.\nThere exists a method specifically for random forests; we wish to extend this\nmethod for GBDTs. This involves accounting for (1) the sequential dependency\nbetween trees and (2) training on the negative gradients instead of the\noriginal labels.\n", "versions": [{"version": "v1", "created": "Thu, 4 Jul 2019 20:43:12 GMT"}], "update_date": "2019-07-08", "authors_parsed": [["Lucic", "Ana", ""], ["Haned", "Hinda", ""], ["de Rijke", "Maarten", ""]]}, {"id": "1907.02606", "submitter": "Saeedeh Shekarpour", "authors": "Saeedeh Shekarpour and Faisal Alshargi", "title": "A Road-map Towards Explainable Question Answering A Solution for\n  Information Pollution", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The increasing rate of information pollution on the Web requires novel\nsolutions to tackle that. Question Answering (QA) interfaces are simplified and\nuser-friendly interfaces to access information on the Web. However, similar to\nother AI applications, they are black boxes which do not manifest the details\nof the learning or reasoning steps for augmenting an answer. The Explainable\nQuestion Answering (XQA) system can alleviate the pain of information pollution\nwhere it provides transparency to the underlying computational model and\nexposes an interface enabling the end-user to access and validate provenance,\nvalidity, context, circulation, interpretation, and feedbacks of information.\nThis position paper sheds light on the core concepts, expectations, and\nchallenges in favor of the following questions (i) What is an XQA system?, (ii)\nWhy do we need XQA?, (iii) When do we need XQA? (iv) How to represent the\nexplanations? (iv) How to evaluate XQA systems?\n", "versions": [{"version": "v1", "created": "Thu, 4 Jul 2019 21:42:29 GMT"}], "update_date": "2019-07-08", "authors_parsed": [["Shekarpour", "Saeedeh", ""], ["Alshargi", "Faisal", ""]]}, {"id": "1907.02787", "submitter": "Daniele Ravi", "authors": "Daniele Ravi, Daniel C. Alexander, Neil P. Oxtoby", "title": "Degenerative Adversarial NeuroImage Nets: Generating Images that Mimic\n  Disease Progression", "comments": "Paper accepted for MICCAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Simulating images representative of neurodegenerative diseases is important\nfor predicting patient outcomes and for validation of computational models of\ndisease progression. This capability is valuable for secondary prevention\nclinical trials where outcomes and screening criteria involve neuroimaging.\nTraditional computational methods are limited by imposing a parametric model\nfor atrophy and are extremely resource-demanding. Recent advances in deep\nlearning have yielded data-driven models for longitudinal studies (e.g., face\nageing) that are capable of generating synthetic images in real-time. Similar\nsolutions can be used to model trajectories of atrophy in the brain, although\nnew challenges need to be addressed to ensure accurate disease progression\nmodelling. Here we propose Degenerative Adversarial NeuroImage Net (DaniNet)\n--- a new deep learning approach that learns to emulate the effect of\nneurodegeneration on MRI by simulating atrophy as a function of ages, and\ndisease progression. DaniNet uses an underlying set of Support Vector\nRegressors (SVRs) trained to capture the patterns of regional intensity changes\nthat accompany disease progression. DaniNet produces whole output images,\nconsisting of 2D-MRI slices that are constrained to match regional predictions\nfrom the SVRs. DaniNet is also able to maintain the unique brain morphology of\nindividuals. Adversarial training ensures realistic brain images and smooth\ntemporal progression. We train our model using 9652 T1-weighted (longitudinal)\nMRI extracted from the Alzheimer's Disease Neuroimaging Initiative (ADNI)\ndataset. We perform quantitative and qualitative evaluations on a separate test\nset of 1283 images (also from ADNI) demonstrating the ability of DaniNet to\nproduce accurate and convincing synthetic images that emulate disease\nprogression.\n", "versions": [{"version": "v1", "created": "Fri, 5 Jul 2019 12:11:01 GMT"}, {"version": "v2", "created": "Fri, 30 Aug 2019 18:56:35 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Ravi", "Daniele", ""], ["Alexander", "Daniel C.", ""], ["Oxtoby", "Neil P.", ""]]}, {"id": "1907.02797", "submitter": "Andrea Polonioli PhD", "authors": "Jacopo Tagliabue, Lucas Lacasa, Ciro Greco, Mattia Pavoni and Andrea\n  Polonioli", "title": "Predicting e-commerce customer conversion from minimal temporal patterns\n  on symbolized clickstream trajectories", "comments": "arXiv admin note: substantial text overlap with arXiv:1907.00400", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowing if a user is a buyer or window shopper solely based on clickstream\ndata is of crucial importance for e-commerce platforms seeking to implement\nreal-time accurate NBA (next best action) policies. However, due to the low\nfrequency of conversion events and the noisiness of browsing data, classifying\nuser sessions is very challenging. In this paper, we address the clickstream\nclassification problem in the eCommerce industry and present three major\ncontributions to the burgeoning field of AI-for-retail: first, we collected,\nnormalized and prepared a novel dataset of live shopping sessions from a major\nEuropean e-commerce website; second, we use the dataset to test in a controlled\nenvironment strong baselines and SOTA models from the literature; finally, we\npropose a new discriminative neural model that outperforms neural architectures\nrecently proposed at Rakuten labs.\n", "versions": [{"version": "v1", "created": "Wed, 3 Jul 2019 16:37:48 GMT"}, {"version": "v2", "created": "Sat, 14 Mar 2020 14:25:49 GMT"}], "update_date": "2020-03-17", "authors_parsed": [["Tagliabue", "Jacopo", ""], ["Lacasa", "Lucas", ""], ["Greco", "Ciro", ""], ["Pavoni", "Mattia", ""], ["Polonioli", "Andrea", ""]]}, {"id": "1907.02874", "submitter": "Oliver Richter", "authors": "Timo Bram, Gino Brunner, Oliver Richter, Roger Wattenhofer", "title": "Attentive Multi-Task Deep Reinforcement Learning", "comments": "Accepted as conference paper at ECML PKDD 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sharing knowledge between tasks is vital for efficient learning in a\nmulti-task setting. However, most research so far has focused on the easier\ncase where knowledge transfer is not harmful, i.e., where knowledge from one\ntask cannot negatively impact the performance on another task. In contrast, we\npresent an approach to multi-task deep reinforcement learning based on\nattention that does not require any a-priori assumptions about the\nrelationships between tasks. Our attention network automatically groups task\nknowledge into sub-networks on a state level granularity. It thereby achieves\npositive knowledge transfer if possible, and avoids negative transfer in cases\nwhere tasks interfere. We test our algorithm against two state-of-the-art\nmulti-task/transfer learning approaches and show comparable or superior\nperformance while requiring fewer network parameters.\n", "versions": [{"version": "v1", "created": "Fri, 5 Jul 2019 14:59:41 GMT"}], "update_date": "2019-07-08", "authors_parsed": [["Bram", "Timo", ""], ["Brunner", "Gino", ""], ["Richter", "Oliver", ""], ["Wattenhofer", "Roger", ""]]}, {"id": "1907.02893", "submitter": "Martin Arjovsky", "authors": "Martin Arjovsky, L\\'eon Bottou, Ishaan Gulrajani, David Lopez-Paz", "title": "Invariant Risk Minimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce Invariant Risk Minimization (IRM), a learning paradigm to\nestimate invariant correlations across multiple training distributions. To\nachieve this goal, IRM learns a data representation such that the optimal\nclassifier, on top of that data representation, matches for all training\ndistributions. Through theory and experiments, we show how the invariances\nlearned by IRM relate to the causal structures governing the data and enable\nout-of-distribution generalization.\n", "versions": [{"version": "v1", "created": "Fri, 5 Jul 2019 15:26:26 GMT"}, {"version": "v2", "created": "Sun, 1 Sep 2019 09:17:10 GMT"}, {"version": "v3", "created": "Fri, 27 Mar 2020 19:07:58 GMT"}], "update_date": "2020-03-31", "authors_parsed": [["Arjovsky", "Martin", ""], ["Bottou", "L\u00e9on", ""], ["Gulrajani", "Ishaan", ""], ["Lopez-Paz", "David", ""]]}, {"id": "1907.02908", "submitter": "Matteo Hessel", "authors": "Matteo Hessel, Hado van Hasselt, Joseph Modayil, David Silver", "title": "On Inductive Biases in Deep Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many deep reinforcement learning algorithms contain inductive biases that\nsculpt the agent's objective and its interface to the environment. These\ninductive biases can take many forms, including domain knowledge and pretuned\nhyper-parameters. In general, there is a trade-off between generality and\nperformance when algorithms use such biases. Stronger biases can lead to faster\nlearning, but weaker biases can potentially lead to more general algorithms.\nThis trade-off is important because inductive biases are not free; substantial\neffort may be required to obtain relevant domain knowledge or to tune\nhyper-parameters effectively. In this paper, we re-examine several\ndomain-specific components that bias the objective and the environmental\ninterface of common deep reinforcement learning agents. We investigated whether\nthe performance deteriorates when these components are replaced with adaptive\nsolutions from the literature. In our experiments, performance sometimes\ndecreased with the adaptive components, as one might expect when comparing to\ncomponents crafted for the domain, but sometimes the adaptive components\nperformed better. We investigated the main benefit of having fewer\ndomain-specific components, by comparing the learning performance of the two\nsystems on a different set of continuous control problems, without additional\ntuning of either system. As hypothesized, the system with adaptive components\nperformed better on many of the new tasks.\n", "versions": [{"version": "v1", "created": "Fri, 5 Jul 2019 16:14:55 GMT"}], "update_date": "2019-07-08", "authors_parsed": [["Hessel", "Matteo", ""], ["van Hasselt", "Hado", ""], ["Modayil", "Joseph", ""], ["Silver", "David", ""]]}, {"id": "1907.02998", "submitter": "Srinivas Venkattaramanujam", "authors": "Srinivas Venkattaramanujam, Eric Crawford, Thang Doan and Doina Precup", "title": "Self-supervised Learning of Distance Functions for Goal-Conditioned\n  Reinforcement Learning", "comments": "Preprint; Under Review (updated)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Goal-conditioned policies are used in order to break down complex\nreinforcement learning (RL) problems by using subgoals, which can be defined\neither in state space or in a latent feature space. This can increase the\nefficiency of learning by using a curriculum, and also enables simultaneous\nlearning and generalization across goals. A crucial requirement of\ngoal-conditioned policies is to be able to determine whether the goal has been\nachieved. Having a notion of distance to a goal is thus a crucial component of\nthis approach. However, it is not straightforward to come up with an\nappropriate distance, and in some tasks, the goal space may not even be known a\npriori. In this work we learn a distance-to-goal estimate which is computed in\nterms of the number of actions that would need to be carried out in a\nself-supervised approach. Our method solves complex tasks without prior domain\nknowledge in the online setting in three different scenarios in the context of\ngoal-conditioned policies a) the goal space is the same as the state space b)\nthe goal space is given but an appropriate distance is unknown and c) the state\nspace is accessible, but only a subset of the state space represents desired\ngoals, and this subset is known a priori. We also propose a goal-generation\nmechanism as a secondary contribution.\n", "versions": [{"version": "v1", "created": "Fri, 5 Jul 2019 19:00:14 GMT"}, {"version": "v2", "created": "Tue, 2 Jun 2020 15:42:15 GMT"}], "update_date": "2020-06-04", "authors_parsed": [["Venkattaramanujam", "Srinivas", ""], ["Crawford", "Eric", ""], ["Doan", "Thang", ""], ["Precup", "Doina", ""]]}, {"id": "1907.03007", "submitter": "Dar\\'io Garigliotti", "authors": "Jon Arne B{\\o} Hovda and Dar\\'io Garigliotti and Krisztian Balog", "title": "NeuType: A Simple and Effective Neural Network Approach for Predicting\n  Missing Entity Type Information in Knowledge Bases", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge bases store information about the semantic types of entities, which\ncan be utilized in a range of information access tasks. This information,\nhowever, is often incomplete, due to new entities emerging on a daily basis. We\naddress the task of automatically assigning types to entities in a knowledge\nbase from a type taxonomy. Specifically, we present two neural network\narchitectures, which take short entity descriptions and, optionally,\ninformation about related entities as input. Using the DBpedia knowledge base\nfor experimental evaluation, we demonstrate that these simple architectures\nyield significant improvements over the current state of the art.\n", "versions": [{"version": "v1", "created": "Fri, 5 Jul 2019 19:47:10 GMT"}], "update_date": "2019-07-09", "authors_parsed": [["Hovda", "Jon Arne B\u00f8", ""], ["Garigliotti", "Dar\u00edo", ""], ["Balog", "Krisztian", ""]]}, {"id": "1907.03020", "submitter": "Shachi Paul", "authors": "Shachi Paul, Rahul Goel, Dilek Hakkani-T\\\"ur", "title": "Towards Universal Dialogue Act Tagging for Task-Oriented Dialogues", "comments": "Interspeech 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Machine learning approaches for building task-oriented dialogue systems\nrequire large conversational datasets with labels to train on. We are\ninterested in building task-oriented dialogue systems from human-human\nconversations, which may be available in ample amounts in existing customer\ncare center logs or can be collected from crowd workers. Annotating these\ndatasets can be prohibitively expensive. Recently multiple annotated\ntask-oriented human-machine dialogue datasets have been released, however their\nannotation schema varies across different collections, even for well-defined\ncategories such as dialogue acts (DAs). We propose a Universal DA schema for\ntask-oriented dialogues and align existing annotated datasets with our schema.\nOur aim is to train a Universal DA tagger (U-DAT) for task-oriented dialogues\nand use it for tagging human-human conversations. We investigate multiple\ndatasets, propose manual and automated approaches for aligning the different\nschema, and present results on a target corpus of human-human dialogues. In\nunsupervised learning experiments we achieve an F1 score of 54.1% on system\nturns in human-human dialogues. In a semi-supervised setup, the F1 score\nincreases to 57.7% which would otherwise require at least 1.7K manually\nannotated turns. For new domains, we show further improvements when unlabeled\nor labeled target domain data is available.\n", "versions": [{"version": "v1", "created": "Fri, 5 Jul 2019 20:43:30 GMT"}], "update_date": "2019-07-09", "authors_parsed": [["Paul", "Shachi", ""], ["Goel", "Rahul", ""], ["Hakkani-T\u00fcr", "Dilek", ""]]}, {"id": "1907.03030", "submitter": "Xiaofeng Liu", "authors": "Xiaofeng Liu, B.V.K Vijaya Kumar, Chao Yang, Qingming Tang, Jane You", "title": "Dependency-aware Attention Control for Unconstrained Face Recognition\n  with Image Sets", "comments": "Fixed the unreadable code in CVF version. arXiv admin note: text\n  overlap with arXiv:1707.00130 by other authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper targets the problem of image set-based face verification and\nidentification. Unlike traditional single media (an image or video) setting, we\nencounter a set of heterogeneous contents containing orderless images and\nvideos. The importance of each image is usually considered either equal or\nbased on their independent quality assessment. How to model the relationship of\norderless images within a set remains a challenge. We address this problem by\nformulating it as a Markov Decision Process (MDP) in the latent space.\nSpecifically, we first present a dependency-aware attention control (DAC)\nnetwork, which resorts to actor-critic reinforcement learning for sequential\nattention decision of each image embedding to fully exploit the rich\ncorrelation cues among the unordered images. Moreover, we introduce its\nsample-efficient variant with off-policy experience replay to speed up the\nlearning process. The pose-guided representation scheme can further boost the\nperformance at the extremes of the pose variation.\n", "versions": [{"version": "v1", "created": "Fri, 5 Jul 2019 21:40:56 GMT"}], "update_date": "2019-08-06", "authors_parsed": [["Liu", "Xiaofeng", ""], ["Kumar", "B. V. K Vijaya", ""], ["Yang", "Chao", ""], ["Tang", "Qingming", ""], ["You", "Jane", ""]]}, {"id": "1907.03039", "submitter": "Ilse Van Der Linden", "authors": "Ilse van der Linden, Hinda Haned and Evangelos Kanoulas", "title": "Global Aggregations of Local Explanations for Black Box models", "comments": "FACTS-IR: Fairness, Accountability, Confidentiality, Transparency,\n  and Safety - SIGIR 2019 Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The decision-making process of many state-of-the-art machine learning models\nis inherently inscrutable to the extent that it is impossible for a human to\ninterpret the model directly: they are black box models. This has led to a call\nfor research on explaining black box models, for which there are two main\napproaches. Global explanations that aim to explain a model's decision making\nprocess in general, and local explanations that aim to explain a single\nprediction. Since it remains challenging to establish fidelity to black box\nmodels in globally interpretable approximations, much attention is put on local\nexplanations. However, whether local explanations are able to reliably\nrepresent the black box model and provide useful insights remains an open\nquestion. We present Global Aggregations of Local Explanations (GALE) with the\nobjective to provide insights in a model's global decision making process.\nOverall, our results reveal that the choice of aggregation matters. We find\nthat the global importance introduced by Local Interpretable Model-agnostic\nExplanations (LIME) does not reliably represent the model's global behavior.\nOur proposed aggregations are better able to represent how features affect the\nmodel's predictions, and to provide global insights by identifying\ndistinguishing features.\n", "versions": [{"version": "v1", "created": "Fri, 5 Jul 2019 22:40:36 GMT"}], "update_date": "2019-07-09", "authors_parsed": [["van der Linden", "Ilse", ""], ["Haned", "Hinda", ""], ["Kanoulas", "Evangelos", ""]]}, {"id": "1907.03046", "submitter": "Niels Justesen", "authors": "Niels Justesen, Miguel Gonzalez Duque, Daniel Cabarcas Jaramillo,\n  Jean-Baptiste Mouret, Sebastian Risi", "title": "Learning a Behavioral Repertoire from Demonstrations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Imitation Learning (IL) is a machine learning approach to learn a policy from\na dataset of demonstrations. IL can be useful to kick-start learning before\napplying reinforcement learning (RL) but it can also be useful on its own, e.g.\nto learn to imitate human players in video games. However, a major limitation\nof current IL approaches is that they learn only a single \"average\" policy\nbased on a dataset that possibly contains demonstrations of numerous different\ntypes of behaviors. In this paper, we propose a new approach called Behavioral\nRepertoire Imitation Learning (BRIL) that instead learns a repertoire of\nbehaviors from a set of demonstrations by augmenting the state-action pairs\nwith behavioral descriptions. The outcome of this approach is a single neural\nnetwork policy conditioned on a behavior description that can be precisely\nmodulated. We apply this approach to train a policy on 7,777 human replays to\nperform build-order planning in StarCraft II. Principal Component Analysis\n(PCA) is applied to construct a low-dimensional behavioral space from the\nhigh-dimensional army unit composition of each demonstration. The results\ndemonstrate that the learned policy can be effectively manipulated to express\ndistinct behaviors. Additionally, by applying the UCB1 algorithm, we are able\nto adapt the behavior of the policy - in-between games - to reach a performance\nbeyond that of the traditional IL baseline approach.\n", "versions": [{"version": "v1", "created": "Fri, 5 Jul 2019 23:08:08 GMT"}], "update_date": "2019-07-09", "authors_parsed": [["Justesen", "Niels", ""], ["Duque", "Miguel Gonzalez", ""], ["Jaramillo", "Daniel Cabarcas", ""], ["Mouret", "Jean-Baptiste", ""], ["Risi", "Sebastian", ""]]}, {"id": "1907.03077", "submitter": "Shusen Liu", "authors": "Shusen Liu, Bhavya Kailkhura, Donald Loveland, Yong Han", "title": "Generative Counterfactual Introspection for Explainable Deep Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we propose an introspection technique for deep neural networks\nthat relies on a generative model to instigate salient editing of the input\nimage for model interpretation. Such modification provides the fundamental\ninterventional operation that allows us to obtain answers to counterfactual\ninquiries, i.e., what meaningful change can be made to the input image in order\nto alter the prediction. We demonstrate how to reveal interesting properties of\nthe given classifiers by utilizing the proposed introspection approach on both\nthe MNIST and the CelebA dataset.\n", "versions": [{"version": "v1", "created": "Sat, 6 Jul 2019 04:30:13 GMT"}], "update_date": "2019-07-09", "authors_parsed": [["Liu", "Shusen", ""], ["Kailkhura", "Bhavya", ""], ["Loveland", "Donald", ""], ["Han", "Yong", ""]]}, {"id": "1907.03141", "submitter": "Ning Liu", "authors": "Ning Liu and Xiaolong Ma and Zhiyuan Xu and Yanzhi Wang and Jian Tang\n  and Jieping Ye", "title": "AutoCompress: An Automatic DNN Structured Pruning Framework for\n  Ultra-High Compression Rates", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Structured weight pruning is a representative model compression technique of\nDNNs to reduce the storage and computation requirements and accelerate\ninference. An automatic hyperparameter determination process is necessary due\nto the large number of flexible hyperparameters. This work proposes\nAutoCompress, an automatic structured pruning framework with the following key\nperformance improvements: (i) effectively incorporate the combination of\nstructured pruning schemes in the automatic process; (ii) adopt the\nstate-of-art ADMM-based structured weight pruning as the core algorithm, and\npropose an innovative additional purification step for further weight reduction\nwithout accuracy loss; and (iii) develop effective heuristic search method\nenhanced by experience-based guided search, replacing the prior deep\nreinforcement learning technique which has underlying incompatibility with the\ntarget pruning problem. Extensive experiments on CIFAR-10 and ImageNet datasets\ndemonstrate that AutoCompress is the key to achieve ultra-high pruning rates on\nthe number of weights and FLOPs that cannot be achieved before. As an example,\nAutoCompress outperforms the prior work on automatic model compression by up to\n33x in pruning rate (120x reduction in the actual parameter count) under the\nsame accuracy. Significant inference speedup has been observed from the\nAutoCompress framework on actual measurements on smartphone. We release all\nmodels of this work at anonymous link: http://bit.ly/2VZ63dS.\n", "versions": [{"version": "v1", "created": "Sat, 6 Jul 2019 15:40:02 GMT"}, {"version": "v2", "created": "Wed, 11 Sep 2019 12:15:38 GMT"}], "update_date": "2019-09-12", "authors_parsed": [["Liu", "Ning", ""], ["Ma", "Xiaolong", ""], ["Xu", "Zhiyuan", ""], ["Wang", "Yanzhi", ""], ["Tang", "Jian", ""], ["Ye", "Jieping", ""]]}, {"id": "1907.03143", "submitter": "Seyed Mehran Kazemi", "authors": "Rishab Goel, Seyed Mehran Kazemi, Marcus Brubaker, Pascal Poupart", "title": "Diachronic Embedding for Temporal Knowledge Graph Completion", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Knowledge graphs (KGs) typically contain temporal facts indicating\nrelationships among entities at different times. Due to their incompleteness,\nseveral approaches have been proposed to infer new facts for a KG based on the\nexisting ones-a problem known as KG completion. KG embedding approaches have\nproved effective for KG completion, however, they have been developed mostly\nfor static KGs. Developing temporal KG embedding models is an increasingly\nimportant problem. In this paper, we build novel models for temporal KG\ncompletion through equipping static models with a diachronic entity embedding\nfunction which provides the characteristics of entities at any point in time.\nThis is in contrast to the existing temporal KG embedding approaches where only\nstatic entity features are provided. The proposed embedding function is\nmodel-agnostic and can be potentially combined with any static model. We prove\nthat combining it with SimplE, a recent model for static KG embedding, results\nin a fully expressive model for temporal KG completion. Our experiments\nindicate the superiority of our proposal compared to existing baselines.\n", "versions": [{"version": "v1", "created": "Sat, 6 Jul 2019 15:51:29 GMT"}], "update_date": "2019-07-09", "authors_parsed": [["Goel", "Rishab", ""], ["Kazemi", "Seyed Mehran", ""], ["Brubaker", "Marcus", ""], ["Poupart", "Pascal", ""]]}, {"id": "1907.03178", "submitter": "Alexander M\\\"arz", "authors": "Alexander M\\\"arz", "title": "XGBoostLSS -- An extension of XGBoost to probabilistic forecasting", "comments": "Bayesian Optimization; Distributional Modeling; Expectile Regression;\n  GAMLSS; Probabilistic Forecast; Uncertainty Quantification; XGBoost", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new framework of XGBoost that predicts the entire conditional\ndistribution of a univariate response variable. In particular, XGBoostLSS\nmodels all moments of a parametric distribution (i.e., mean, location, scale\nand shape [LSS]) instead of the conditional mean only. Choosing from a wide\nrange of continuous, discrete and mixed discrete-continuous distribution,\nmodelling and predicting the entire conditional distribution greatly enhances\nthe flexibility of XGBoost, as it allows to gain additional insight into the\ndata generating process, as well as to create probabilistic forecasts from\nwhich prediction intervals and quantiles of interest can be derived. We present\nboth a simulation study and real world examples that demonstrate the virtues of\nour approach.\n", "versions": [{"version": "v1", "created": "Sat, 6 Jul 2019 20:25:16 GMT"}, {"version": "v2", "created": "Thu, 11 Jul 2019 10:32:31 GMT"}, {"version": "v3", "created": "Sun, 11 Aug 2019 09:16:42 GMT"}, {"version": "v4", "created": "Sun, 25 Aug 2019 09:30:15 GMT"}], "update_date": "2019-08-27", "authors_parsed": [["M\u00e4rz", "Alexander", ""]]}, {"id": "1907.03179", "submitter": "Meng Qu", "authors": "Meng Qu, Jian Tang, Yoshua Bengio", "title": "Weakly-supervised Knowledge Graph Alignment with Adversarial Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies aligning knowledge graphs from different sources or\nlanguages. Most existing methods train supervised methods for the alignment,\nwhich usually require a large number of aligned knowledge triplets. However,\nsuch a large number of aligned knowledge triplets may not be available or are\nexpensive to obtain in many domains. Therefore, in this paper we propose to\nstudy aligning knowledge graphs in fully-unsupervised or weakly-supervised\nfashion, i.e., without or with only a few aligned triplets. We propose an\nunsupervised framework to align the entity and relation embddings of different\nknowledge graphs with an adversarial learning framework. Moreover, a\nregularization term which maximizes the mutual information between the\nembeddings of different knowledge graphs is used to mitigate the problem of\nmode collapse when learning the alignment functions. Such a framework can be\nfurther seamlessly integrated with existing supervised methods by utilizing a\nlimited number of aligned triples as guidance. Experimental results on multiple\ndatasets prove the effectiveness of our proposed approach in both the\nunsupervised and the weakly-supervised settings.\n", "versions": [{"version": "v1", "created": "Sat, 6 Jul 2019 20:31:13 GMT"}], "update_date": "2019-07-09", "authors_parsed": [["Qu", "Meng", ""], ["Tang", "Jian", ""], ["Bengio", "Yoshua", ""]]}, {"id": "1907.03263", "submitter": "Aaditeshwar Seth", "authors": "Aaditeshwar Seth", "title": "Ensuring Responsible Outcomes from Technology", "comments": "Presented as an invited talk at IEEE COMSNETS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.HC cs.SI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We attempt to make two arguments in this essay. First, through a case study\nof a mobile phone based voice-media service we have been running in rural\ncentral India for more than six years, we describe several implementation\ncomplexities we had to navigate towards realizing our intended vision of\nbringing social development through technology. Most of these complexities\narose in the interface of our technology with society, and we argue that even\nother technology providers can create similar processes to manage this\nsocio-technological interface and ensure intended outcomes from their\ntechnology use. We then build our second argument about how to ensure that the\norganizations behind both market driven technologies and those technologies\nthat are adopted by the state, pay due attention towards responsibly managing\nthe socio-technological interface of their innovations. We advocate for the\ntechnology engineers and researchers who work within these organizations, to\ntake up the responsibility and ensure that their labour leads to making the\nworld a better place especially for the poor and marginalized. We outline\npossible governance structures that can give more voice to the technology\ndevelopers to push their organizations towards ensuring that responsible\noutcomes emerge from their technology. We note that the examples we use to\nbuild our arguments are limited to contemporary information and communication\ntechnology (ICT) platforms used directly by end-users to share content with one\nanother, and hence our argument may not generalize to other ICTs in a\nstraightforward manner.\n", "versions": [{"version": "v1", "created": "Sun, 7 Jul 2019 09:55:20 GMT"}], "update_date": "2019-07-15", "authors_parsed": [["Seth", "Aaditeshwar", ""]]}, {"id": "1907.03381", "submitter": "Yanyan Xu", "authors": "Wuwei Lan, Yanyan Xu, Bin Zhao", "title": "Travel Time Estimation without Road Networks: An Urban Morphological\n  Layout Representation Approach", "comments": "Accepted at IJCAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Travel time estimation is a crucial task for not only personal travel\nscheduling but also city planning. Previous methods focus on modeling toward\nroad segments or sub-paths, then summing up for a final prediction, which have\nbeen recently replaced by deep neural models with end-to-end training. Usually,\nthese methods are based on explicit feature representations, including\nspatio-temporal features, traffic states, etc. Here, we argue that the local\ntraffic condition is closely tied up with the land-use and built environment,\ni.e., metro stations, arterial roads, intersections, commercial area,\nresidential area, and etc, yet the relation is time-varying and too complicated\nto model explicitly and efficiently. Thus, this paper proposes an end-to-end\nmulti-task deep neural model, named Deep Image to Time (DeepI2T), to learn the\ntravel time mainly from the built environment images, a.k.a. the morphological\nlayout images, and showoff the new state-of-the-art performance on real-world\ndatasets in two cities. Moreover, our model is designed to tackle both\npath-aware and path-blind scenarios in the testing phase. This work opens up\nnew opportunities of using the publicly available morphological layout images\nas considerable information in multiple geography-related smart city\napplications.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jul 2019 01:52:35 GMT"}], "update_date": "2019-07-09", "authors_parsed": [["Lan", "Wuwei", ""], ["Xu", "Yanyan", ""], ["Zhao", "Bin", ""]]}, {"id": "1907.03399", "submitter": "Takuma Udagawa", "authors": "Takuma Udagawa, Akiko Aizawa", "title": "A Natural Language Corpus of Common Grounding under Continuous and\n  Partially-Observable Context", "comments": "AAAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Common grounding is the process of creating, repairing and updating mutual\nunderstandings, which is a critical aspect of sophisticated human\ncommunication. However, traditional dialogue systems have limited capability of\nestablishing common ground, and we also lack task formulations which introduce\nnatural difficulty in terms of common grounding while enabling easy evaluation\nand analysis of complex models. In this paper, we propose a minimal dialogue\ntask which requires advanced skills of common grounding under continuous and\npartially-observable context. Based on this task formulation, we collected a\nlargescale dataset of 6,760 dialogues which fulfills essential requirements of\nnatural language corpora. Our analysis of the dataset revealed important\nphenomena related to common grounding that need to be considered. Finally, we\nevaluate and analyze baseline neural models on a simple subtask that requires\nrecognition of the created common ground. We show that simple baseline models\nperform decently but leave room for further improvement. Overall, we show that\nour proposed task will be a fundamental testbed where we can train, evaluate,\nand analyze dialogue system's ability for sophisticated common grounding.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jul 2019 04:19:17 GMT"}], "update_date": "2019-07-09", "authors_parsed": [["Udagawa", "Takuma", ""], ["Aizawa", "Akiko", ""]]}, {"id": "1907.03423", "submitter": "Ashwin Balakrishna", "authors": "Ashwin Balakrishna, Brijen Thananjeyan, Jonathan Lee, Felix Li, Arsh\n  Zahed, Joseph E. Gonzalez, Ken Goldberg", "title": "On-Policy Robot Imitation Learning from a Converging Supervisor", "comments": "Conference on Robot Learning (CoRL) 2019 Oral. First two authors\n  contributed equally", "journal-ref": "3rd Conference on Robot Learning (CoRL 2019)", "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing on-policy imitation learning algorithms, such as DAgger, assume\naccess to a fixed supervisor. However, there are many settings where the\nsupervisor may evolve during policy learning, such as a human performing a\nnovel task or an improving algorithmic controller. We formalize imitation\nlearning from a \"converging supervisor\" and provide sublinear static and\ndynamic regret guarantees against the best policy in hindsight with labels from\nthe converged supervisor, even when labels during learning are only from\nintermediate supervisors. We then show that this framework is closely connected\nto a class of reinforcement learning (RL) algorithms known as dual policy\niteration (DPI), which alternate between training a reactive learner with\nimitation learning and a model-based supervisor with data from the learner.\nExperiments suggest that when this framework is applied with the\nstate-of-the-art deep model-based RL algorithm PETS as an improving supervisor,\nit outperforms deep RL baselines on continuous control tasks and provides up to\nan 80-fold speedup in policy evaluation.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jul 2019 07:02:57 GMT"}, {"version": "v2", "created": "Thu, 26 Sep 2019 07:21:21 GMT"}, {"version": "v3", "created": "Fri, 27 Sep 2019 00:45:26 GMT"}, {"version": "v4", "created": "Tue, 8 Oct 2019 06:43:52 GMT"}, {"version": "v5", "created": "Sun, 20 Oct 2019 03:48:12 GMT"}, {"version": "v6", "created": "Wed, 20 Nov 2019 09:17:16 GMT"}, {"version": "v7", "created": "Sat, 16 May 2020 00:01:35 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Balakrishna", "Ashwin", ""], ["Thananjeyan", "Brijen", ""], ["Lee", "Jonathan", ""], ["Li", "Felix", ""], ["Zahed", "Arsh", ""], ["Gonzalez", "Joseph E.", ""], ["Goldberg", "Ken", ""]]}, {"id": "1907.03540", "submitter": "Mohamed Abdelfattah", "authors": "{\\L}ukasz Dudziak, Mohamed S. Abdelfattah, Ravichander Vipperla,\n  Stefanos Laskaridis, Nicholas D. Lane", "title": "ShrinkML: End-to-End ASR Model Compression Using Reinforcement Learning", "comments": "INTERSPEECH 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  End-to-end automatic speech recognition (ASR) models are increasingly large\nand complex to achieve the best possible accuracy. In this paper, we build an\nAutoML system that uses reinforcement learning (RL) to optimize the per-layer\ncompression ratios when applied to a state-of-the-art attention based\nend-to-end ASR model composed of several LSTM layers. We use singular value\ndecomposition (SVD) low-rank matrix factorization as the compression method.\nFor our RL-based AutoML system, we focus on practical considerations such as\nthe choice of the reward/punishment functions, the formation of an effective\nsearch space, and the creation of a representative but small data set for quick\nevaluation between search steps. Finally, we present accuracy results on\nLibriSpeech of the model compressed by our AutoML system, and we compare it to\nmanually-compressed models. Our results show that in the absence of retraining\nour RL-based search is an effective and practical method to compress a\nproduction-grade ASR system. When retraining is possible, we show that our\nAutoML system can select better highly-compressed seed models compared to\nmanually hand-crafted rank selection, thus allowing for more compression than\npreviously possible.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jul 2019 12:10:18 GMT"}, {"version": "v2", "created": "Tue, 24 Sep 2019 10:06:29 GMT"}], "update_date": "2019-09-25", "authors_parsed": [["Dudziak", "\u0141ukasz", ""], ["Abdelfattah", "Mohamed S.", ""], ["Vipperla", "Ravichander", ""], ["Laskaridis", "Stefanos", ""], ["Lane", "Nicholas D.", ""]]}, {"id": "1907.03590", "submitter": "Zelin Dai", "authors": "Zelin Dai, Weitang Liu, Guanhua Zhan", "title": "Multiple Generative Models Ensemble for Knowledge-Driven Proactive\n  Human-Computer Dialogue Agent", "comments": "7 pages, 3 figures submitted to journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multiple sequence to sequence models were used to establish an end-to-end\nmulti-turns proactive dialogue generation agent, with the aid of data\naugmentation techniques and variant encoder-decoder structure designs. A\nrank-based ensemble approach was developed for boosting performance. Results\nindicate that our single model, in average, makes an obvious improvement in the\nterms of F1-score and BLEU over the baseline by 18.67% on the DuConv dataset.\nIn particular, the ensemble methods further significantly outperform the\nbaseline by 35.85%.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jul 2019 13:16:07 GMT"}, {"version": "v2", "created": "Mon, 6 Apr 2020 13:37:25 GMT"}], "update_date": "2020-04-07", "authors_parsed": [["Dai", "Zelin", ""], ["Liu", "Weitang", ""], ["Zhan", "Guanhua", ""]]}, {"id": "1907.03613", "submitter": "Yuxiang Yang", "authors": "Yuxiang Yang, Ken Caluwaerts, Atil Iscen, Tingnan Zhang, Jie Tan,\n  Vikas Sindhwani", "title": "Data Efficient Reinforcement Learning for Legged Robots", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a model-based framework for robot locomotion that achieves walking\nbased on only 4.5 minutes (45,000 control steps) of data collected on a\nquadruped robot. To accurately model the robot's dynamics over a long horizon,\nwe introduce a loss function that tracks the model's prediction over multiple\ntimesteps. We adapt model predictive control to account for planning latency,\nwhich allows the learned model to be used for real time control. Additionally,\nto ensure safe exploration during model learning, we embed prior knowledge of\nleg trajectories into the action space. The resulting system achieves fast and\nrobust locomotion. Unlike model-free methods, which optimize for a particular\ntask, our planner can use the same learned dynamics for various tasks, simply\nby changing the reward function. To the best of our knowledge, our approach is\nmore than an order of magnitude more sample efficient than current model-free\nmethods.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jul 2019 13:43:06 GMT"}, {"version": "v2", "created": "Sun, 6 Oct 2019 18:56:57 GMT"}], "update_date": "2019-10-08", "authors_parsed": [["Yang", "Yuxiang", ""], ["Caluwaerts", "Ken", ""], ["Iscen", "Atil", ""], ["Zhang", "Tingnan", ""], ["Tan", "Jie", ""], ["Sindhwani", "Vikas", ""]]}, {"id": "1907.03665", "submitter": "Hyungjun Park", "authors": "Hyungjun Park, and Min Kyu Sim, and Dong Gu Choi", "title": "An intelligent financial portfolio trading strategy using deep\n  Q-learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.PM cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Portfolio traders strive to identify dynamic portfolio allocation schemes so\nthat their total budgets are efficiently allocated through the investment\nhorizon. This study proposes a novel portfolio trading strategy in which an\nintelligent agent is trained to identify an optimal trading action by using\ndeep Q-learning. We formulate a Markov decision process model for the portfolio\ntrading process, and the model adopts a discrete combinatorial action space,\ndetermining the trading direction at prespecified trading size for each asset,\nto ensure practical applicability. Our novel portfolio trading strategy takes\nadvantage of three features to outperform in real-world trading. First, a\nmapping function is devised to handle and transform an initially found but\ninfeasible action into a feasible action closest to the originally proposed\nideal action. Second, by overcoming the dimensionality problem, this study\nestablishes models of agent and Q-network for deriving a multi-asset trading\nstrategy in the predefined action space. Last, this study introduces a\ntechnique that has the advantage of deriving a well-fitted multi-asset trading\nstrategy by designing an agent to simulate all feasible actions in each state.\nTo validate our approach, we conduct backtests for two representative\nportfolios and demonstrate superior results over the benchmark strategies.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jul 2019 15:14:13 GMT"}, {"version": "v2", "created": "Thu, 18 Jul 2019 13:17:21 GMT"}, {"version": "v3", "created": "Sat, 31 Aug 2019 09:33:25 GMT"}, {"version": "v4", "created": "Thu, 28 Nov 2019 07:31:33 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Park", "Hyungjun", ""], ["Sim", "Min Kyu", ""], ["Choi", "Dong Gu", ""]]}, {"id": "1907.03687", "submitter": "Hado van Hasselt", "authors": "Hado van Hasselt, John Quan, Matteo Hessel, Zhongwen Xu, Diana Borsa,\n  Andre Barreto", "title": "General non-linear Bellman equations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a general class of non-linear Bellman equations. These open up a\ndesign space of algorithms that have interesting properties, which has two\npotential advantages. First, we can perhaps better model natural phenomena. For\ninstance, hyperbolic discounting has been proposed as a mathematical model that\nmatches human and animal data well, and can therefore be used to explain\npreference orderings. We present a different mathematical model that matches\nthe same data, but that makes very different predictions under other\ncircumstances. Second, the larger design space can perhaps lead to algorithms\nthat perform better, similar to how discount factors are often used in practice\neven when the true objective is undiscounted. We show that many of the\nresulting Bellman operators still converge to a fixed point, and therefore that\nthe resulting algorithms are reasonable and inherit many beneficial properties\nof their linear counterparts.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jul 2019 15:51:01 GMT"}], "update_date": "2019-07-09", "authors_parsed": [["van Hasselt", "Hado", ""], ["Quan", "John", ""], ["Hessel", "Matteo", ""], ["Xu", "Zhongwen", ""], ["Borsa", "Diana", ""], ["Barreto", "Andre", ""]]}, {"id": "1907.03827", "submitter": "An Yan", "authors": "An Yan, Bill Howe", "title": "FairST: Equitable Spatial and Temporal Demand Prediction for New\n  Mobility Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.LG stat.AP", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Emerging transportation modes, including car-sharing, bike-sharing, and\nride-hailing, are transforming urban mobility but have been shown to reinforce\nsocioeconomic inequities. Spatiotemporal demand prediction models for these new\nmobility regimes must therefore consider fairness as a first-class design\nrequirement. We present FairST, a fairness-aware model for predicting demand\nfor new mobility systems. Our approach utilizes 1D, 2D and 3D convolutions to\nintegrate various urban features and learn the spatial-temporal dynamics of a\nmobility system, but we include fairness metrics as a form of regularization to\nmake the predictions more equitable across demographic groups. We propose two\nnovel spatiotemporal fairness metrics, a region-based fairness gap (RFG) and an\nindividual-based fairness gap (IFG). Both quantify equity in a spatiotemporal\ncontext, but vary by whether demographics are labeled at the region level (RFG)\nor whether population distribution information is available (IFG). Experimental\nresults on real bike share and ride share datasets demonstrate the\neffectiveness of the proposed model: FairST not only reduces the fairness gap\nby more than 80%, but can surprisingly achieve better accuracy than\nstate-of-the-art yet fairness-oblivious methods including LSTMs, ConvLSTMs, and\n3D CNN.\n", "versions": [{"version": "v1", "created": "Fri, 21 Jun 2019 19:33:16 GMT"}], "update_date": "2019-07-10", "authors_parsed": [["Yan", "An", ""], ["Howe", "Bill", ""]]}, {"id": "1907.03840", "submitter": "Rodrigo Canaan", "authors": "Rodrigo Canaan, Julian Togelius, Andy Nealen, Stefan Menzel", "title": "Diverse Agents for Ad-Hoc Cooperation in Hanabi", "comments": "8 pages, 4 figures. Accepted at the 2019 IEEE Conference on Games\n  (CoG)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In complex scenarios where a model of other actors is necessary to predict\nand interpret their actions, it is often desirable that the model works well\nwith a wide variety of previously unknown actors. Hanabi is a card game that\nbrings the problem of modeling other players to the forefront, but there is no\nagreement on how to best generate a pool of agents to use as partners in ad-hoc\ncooperation evaluation. This paper proposes Quality Diversity algorithms as a\npromising class of algorithms to generate populations for this purpose and\nshows an initial implementation of an agent generator based on this idea. We\nalso discuss what metrics can be used to compare such generators, and how the\nproposed generator could be leveraged to help build adaptive agents for the\ngame.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jul 2019 20:04:22 GMT"}], "update_date": "2019-07-10", "authors_parsed": [["Canaan", "Rodrigo", ""], ["Togelius", "Julian", ""], ["Nealen", "Andy", ""], ["Menzel", "Stefan", ""]]}, {"id": "1907.03843", "submitter": "Manuel Lopes", "authors": "Pedro Fernandes, Francisco C. Santos, Manuel Lopes", "title": "Norms for Beneficial A.I.: A Computational Analysis of the Societal\n  Value Alignment Problem", "comments": null, "journal-ref": "AI Communications, vol. 33, no. 3-6, pp. 155-171, 2020", "doi": "10.3233/AIC-201502", "report-no": null, "categories": "cs.CY cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The rise of artificial intelligence (A.I.) based systems is already offering\nsubstantial benefits to the society as a whole. However, these systems may also\nenclose potential conflicts and unintended consequences. Notably, people will\ntend to adopt an A.I. system if it confers them an advantage, at which point\nnon-adopters might push for a strong regulation if that advantage for adopters\nis at a cost for them. Here we propose an agent-based game-theoretical model\nfor these conflicts, where agents may decide to resort to A.I. to use and\nacquire additional information on the payoffs of a stochastic game, striving to\nbring insights from simulation to what has been, hitherto, a mostly\nphilosophical discussion. We frame our results under the current discussion on\nethical A.I. and the conflict between individual and societal gains: the\nsocietal value alignment problem. We test the arising equilibria in the\nadoption of A.I. technology under different norms followed by artificial\nagents, their ensuing benefits, and the emergent levels of wealth inequality.\nWe show that without any regulation, purely selfish A.I. systems will have the\nstrongest advantage, even when a utilitarian A.I. provides significant benefits\nfor the individual and the society. Nevertheless, we show that it is possible\nto develop A.I. systems following human conscious policies that, when\nintroduced in society, lead to an equilibrium where the gains for the adopters\nare not at a cost for non-adopters, thus increasing the overall wealth of the\npopulation and lowering inequality. However, as shown, a self-organised\nadoption of such policies would require external regulation.\n", "versions": [{"version": "v1", "created": "Wed, 26 Jun 2019 10:18:19 GMT"}, {"version": "v2", "created": "Tue, 22 Dec 2020 18:11:35 GMT"}], "update_date": "2020-12-23", "authors_parsed": [["Fernandes", "Pedro", ""], ["Santos", "Francisco C.", ""], ["Lopes", "Manuel", ""]]}, {"id": "1907.03848", "submitter": "Thilo Hagendorff", "authors": "Angela Daly, Thilo Hagendorff, Li Hui, Monique Mann, Vidushi Marda,\n  Ben Wagner, Wei Wang, Saskia Witteborn", "title": "Artificial Intelligence Governance and Ethics: Global Perspectives", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Artificial intelligence (AI) is a technology which is increasingly being\nutilised in society and the economy worldwide, and its implementation is\nplanned to become more prevalent in coming years. AI is increasingly being\nembedded in our lives, supplementing our pervasive use of digital technologies.\nBut this is being accompanied by disquiet over problematic and dangerous\nimplementations of AI, or indeed, even AI itself deciding to do dangerous and\nproblematic actions, especially in fields such as the military, medicine and\ncriminal justice. These developments have led to concerns about whether and how\nAI systems adhere, and will adhere to ethical standards. These concerns have\nstimulated a global conversation on AI ethics, and have resulted in various\nactors from different countries and sectors issuing ethics and governance\ninitiatives and guidelines for AI. Such developments form the basis for our\nresearch in this report, combining our international and interdisciplinary\nexpertise to give an insight into what is happening in Australia, China,\nEurope, India and the US.\n", "versions": [{"version": "v1", "created": "Fri, 28 Jun 2019 07:42:48 GMT"}], "update_date": "2019-07-10", "authors_parsed": [["Daly", "Angela", ""], ["Hagendorff", "Thilo", ""], ["Hui", "Li", ""], ["Mann", "Monique", ""], ["Marda", "Vidushi", ""], ["Wagner", "Ben", ""], ["Wang", "Wei", ""], ["Witteborn", "Saskia", ""]]}, {"id": "1907.03877", "submitter": "Tiago Machado", "authors": "Tiago Machado, Dan Gopstein, Andy Nealen and Julian Togelius", "title": "Pitako -- Recommending Game Design Elements in Cicero", "comments": "Paper accepted in the IEEE Conference on Games 2019 (COG 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recommender Systems are widely and successfully applied in e-commerce. Could\nthey be used for design? In this paper, we introduce Pitako1, a tool that\napplies the Recommender System concept to assist humans in creative tasks. More\nspecifically, Pitako provides suggestions by taking games designed by humans as\ninputs, and recommends mechanics and dynamics as outputs. Pitako is implemented\nas a new system within the mixed-initiative AI-based Game Design Assistant,\nCicero. This paper discusses the motivation behind the implementation of Pitako\nas well as its technical details and presents usage examples. We believe that\nPitako can influence the use of recommender systems to help humans in their\ndaily tasks.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jul 2019 21:19:25 GMT"}], "update_date": "2019-07-10", "authors_parsed": [["Machado", "Tiago", ""], ["Gopstein", "Dan", ""], ["Nealen", "Andy", ""], ["Togelius", "Julian", ""]]}, {"id": "1907.03947", "submitter": "Anna Guitart Atienza", "authors": "Anna Guitart, Ana Fern\\'andez del R\\'io and \\'Africa Peri\\'a\\~nez", "title": "Understanding Player Engagement and In-Game Purchasing Behavior with\n  Ensemble Learning", "comments": "Churn Prediction, Ensemble Methods, Survival Analysis, On- line\n  Games, User Behavior", "journal-ref": "Proceedings of GAME-ON'2019 AI and Simulation in Games, September\n  2019, breda, the Netherlands. ISBN 978-94-92859-08-2", "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As video games attract more and more players, the major challenge for game\nstudios is to retain them. We present a deep behavioral analysis of churn (game\nabandonment) and what we called \"purchase churn\" (the transition from paying to\nnon-paying user). A series of churning behavior profiles are identified, which\nallows a classification of churners in terms of whether they eventually return\nto the game (false churners)--or start purchasing again (false purchase\nchurners)--and their subsequent behavior. The impact of excluding some or all\nof these churners from the training sample is then explored in several churn\nand purchase churn prediction models. Our results suggest that discarding\ncertain combinations of \"zombies\" (players whose activity is extremely\nsporadic) and false churners has a significant positive impact in all models\nconsidered.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jul 2019 02:40:40 GMT"}], "update_date": "2020-03-10", "authors_parsed": [["Guitart", "Anna", ""], ["del R\u00edo", "Ana Fern\u00e1ndez", ""], ["Peri\u00e1\u00f1ez", "\u00c1frica", ""]]}, {"id": "1907.03950", "submitter": "Drew A. Hudson", "authors": "Drew A. Hudson and Christopher D. Manning", "title": "Learning by Abstraction: The Neural State Machine", "comments": "Published as a conference paper at NeurIPS 2019 (spotlight)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce the Neural State Machine, seeking to bridge the gap between the\nneural and symbolic views of AI and integrate their complementary strengths for\nthe task of visual reasoning. Given an image, we first predict a probabilistic\ngraph that represents its underlying semantics and serves as a structured world\nmodel. Then, we perform sequential reasoning over the graph, iteratively\ntraversing its nodes to answer a given question or draw a new inference. In\ncontrast to most neural architectures that are designed to closely interact\nwith the raw sensory data, our model operates instead in an abstract latent\nspace, by transforming both the visual and linguistic modalities into semantic\nconcept-based representations, thereby achieving enhanced transparency and\nmodularity. We evaluate our model on VQA-CP and GQA, two recent VQA datasets\nthat involve compositionality, multi-step inference and diverse reasoning\nskills, achieving state-of-the-art results in both cases. We provide further\nexperiments that illustrate the model's strong generalization capacity across\nmultiple dimensions, including novel compositions of concepts, changes in the\nanswer distribution, and unseen linguistic structures, demonstrating the\nqualities and efficacy of our approach.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jul 2019 03:08:41 GMT"}, {"version": "v2", "created": "Thu, 11 Jul 2019 17:14:03 GMT"}, {"version": "v3", "created": "Mon, 15 Jul 2019 09:33:51 GMT"}, {"version": "v4", "created": "Mon, 25 Nov 2019 10:02:05 GMT"}], "update_date": "2019-11-26", "authors_parsed": [["Hudson", "Drew A.", ""], ["Manning", "Christopher D.", ""]]}, {"id": "1907.03964", "submitter": "Niranjan Kumar K", "authors": "K. Niranjan Kumar, Irfan Essa, Sehoon Ha, C. Karen Liu", "title": "Estimating Mass Distribution of Articulated Objects using Non-prehensile\n  Manipulation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We explore the problem of estimating the mass distribution of an articulated\nobject by an interactive robotic agent. Our method predicts the mass\ndistribution of an object by using the limited sensing and actuating\ncapabilities of a robotic agent that is interacting with the object. We are\ninspired by the role of exploratory play in human infants. We take the combined\napproach of supervised and reinforcement learning to train an agent that learns\nto strategically interact with the object to estimate the object's mass\ndistribution. Our method consists of two neural networks: (i) the policy\nnetwork which decides how to interact with the object, and (ii) the predictor\nnetwork that estimates the mass distribution given a history of observations\nand interactions. Using our method, we train a robotic arm to estimate the mass\ndistribution of an object with moving parts (e.g. an articulated rigid body\nsystem) by pushing it on a surface with unknown friction properties. We also\ndemonstrate how our training from simulations can be transferred to real\nhardware using a small amount of real-world data for fine-tuning. We use a UR10\nrobot to interact with 3D printed articulated chains with varying mass\ndistributions and show that our method significantly outperforms the baseline\nsystem that uses random pushes to interact with the object.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jul 2019 03:32:05 GMT"}, {"version": "v2", "created": "Sun, 8 Mar 2020 02:15:58 GMT"}, {"version": "v3", "created": "Mon, 23 Mar 2020 16:41:17 GMT"}, {"version": "v4", "created": "Thu, 19 Nov 2020 03:35:22 GMT"}], "update_date": "2020-11-20", "authors_parsed": [["Kumar", "K. Niranjan", ""], ["Essa", "Irfan", ""], ["Ha", "Sehoon", ""], ["Liu", "C. Karen", ""]]}, {"id": "1907.04053", "submitter": "Daniele Gravina", "authors": "Daniele Gravina, Ahmed Khalifa, Antonios Liapis, Julian Togelius,\n  Georgios N. Yannakakis", "title": "Procedural Content Generation through Quality Diversity", "comments": "8 pages, Accepted and to appear in proceedings of the IEEE Conference\n  on Games, 2019", "journal-ref": null, "doi": "10.1109/CIG.2019.8848053", "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quality-diversity (QD) algorithms search for a set of good solutions which\ncover a space as defined by behavior metrics. This simultaneous focus on\nquality and diversity with explicit metrics sets QD algorithms apart from\nstandard single- and multi-objective evolutionary algorithms, as well as from\ndiversity preservation approaches such as niching. These properties open up new\navenues for artificial intelligence in games, in particular for procedural\ncontent generation. Creating multiple systematically varying solutions allows\nnew approaches to creative human-AI interaction as well as adaptivity. In the\nlast few years, a handful of applications of QD to procedural content\ngeneration and game playing have been proposed; we discuss these and propose\nchallenges for future work.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jul 2019 09:22:16 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Gravina", "Daniele", ""], ["Khalifa", "Ahmed", ""], ["Liapis", "Antonios", ""], ["Togelius", "Julian", ""], ["Yannakakis", "Georgios N.", ""]]}, {"id": "1907.04105", "submitter": "Vivian Silva", "authors": "Vivian S. Silva, Andr\\'e Freitas, Siegfried Handschuh", "title": "On the Semantic Interpretability of Artificial Intelligence Models", "comments": "17 pages, 4 figures. Submitted to AI Magazine on August, 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Artificial Intelligence models are becoming increasingly more powerful and\naccurate, supporting or even replacing humans' decision making. But with\nincreased power and accuracy also comes higher complexity, making it hard for\nusers to understand how the model works and what the reasons behind its\npredictions are. Humans must explain and justify their decisions, and so do the\nAI models supporting them in this process, making semantic interpretability an\nemerging field of study. In this work, we look at interpretability from a\nbroader point of view, going beyond the machine learning scope and covering\ndifferent AI fields such as distributional semantics and fuzzy logic, among\nothers. We examine and classify the models according to their nature and also\nbased on how they introduce interpretability features, analyzing how each\napproach affects the final users and pointing to gaps that still need to be\naddressed to provide more human-centered interpretability solutions.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jul 2019 12:01:35 GMT"}], "update_date": "2019-07-10", "authors_parsed": [["Silva", "Vivian S.", ""], ["Freitas", "Andr\u00e9", ""], ["Handschuh", "Siegfried", ""]]}, {"id": "1907.04269", "submitter": "Shuai Ma", "authors": "Shuai Ma, Jia Yuan Yu, Ahmet Satir", "title": "A Scheme for Dynamic Risk-Sensitive Sequential Decision Making", "comments": "20 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a scheme for sequential decision making with a risk-sensitive\nobjective and constraints in a dynamic environment. A neural network is trained\nas an approximator of the mapping from parameter space to space of risk and\npolicy with risk-sensitive constraints. For a given risk-sensitive problem, in\nwhich the objective and constraints are, or can be estimated by, functions of\nthe mean and variance of return, we generate a synthetic dataset as training\ndata. Parameters defining a targeted process might be dynamic, i.e., they might\nvary over time, so we sample them within specified intervals to deal with these\ndynamics. We show that: i). Most risk measures can be estimated using return\nvariance; ii). By virtue of the state-augmentation transformation, practical\nproblems modeled by Markov decision processes with stochastic rewards can be\nsolved in a risk-sensitive scenario; and iii). The proposed scheme is validated\nby a numerical experiment.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jul 2019 16:12:21 GMT"}], "update_date": "2019-07-10", "authors_parsed": [["Ma", "Shuai", ""], ["Yu", "Jia Yuan", ""], ["Satir", "Ahmet", ""]]}, {"id": "1907.04276", "submitter": "V\\'ictor Gallego-Fontenla", "authors": "V\\'ictor Gallego-Fontenla, Juan C. Vidal and Manuel Lama", "title": "A Conformance Checking-based Approach for Drift Detection in Business\n  Processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Real life business processes change over time, in both planned and unexpected\nways. The detection of these changes is crucial for organizations to ensure\nthat the expected and the real behavior are as similar as possible. These\nchanges over time are called concept drift and its detection is a big challenge\nin process mining since the inherent complexity of the data makes difficult\ndistinguishing between a change and an anomalous execution. In this paper, we\npresent C2D2 (Conformance Checking-based Drift Detection), a new approach to\ndetect sudden control-flow changes in the process models from event traces.\nC2D2 combines discovery techniques with conformance checking methods to perform\nan offline detection. Our approach has been validated with a synthetic\nbenchmarking dataset formed by 68 logs, showing an improvement in the accuracy\nwhile maintaining a minimum delay in the drift detection.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jul 2019 16:24:33 GMT"}], "update_date": "2019-07-10", "authors_parsed": [["Gallego-Fontenla", "V\u00edctor", ""], ["Vidal", "Juan C.", ""], ["Lama", "Manuel", ""]]}, {"id": "1907.04394", "submitter": "Souma Chowdhury", "authors": "Payam Ghassemi, David DePauw, Souma Chowdhury", "title": "Decentralized Dynamic Task Allocation in Swarm Robotic Systems for\n  Disaster Response", "comments": "Accepted for poster presentation in (and publication as extended\n  abstract in the proceedings of) The IEEE 2019 International Symposium on\n  Multi-Robot and Multi-Agent Systems (MRS)", "journal-ref": null, "doi": "10.1109/MRS.2019.8901062", "report-no": null, "categories": "cs.MA cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multiple robotic systems, working together, can provide important solutions\nto different real-world applications (e.g., disaster response), among which\ntask allocation problems feature prominently. Very few existing decentralized\nmulti-robotic task allocation (MRTA) methods simultaneously offer the following\ncapabilities: consideration of task deadlines, consideration of robot range and\ntask completion capacity limitations, and allowing asynchronous decision-making\nunder dynamic task spaces. To provision these capabilities, this paper presents\na computationally efficient algorithm that involves novel construction and\nmatching of bipartite graphs. Its performance is tested on a multi-UAV flood\nresponse application.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jul 2019 20:24:15 GMT"}, {"version": "v2", "created": "Sat, 25 Jul 2020 19:03:34 GMT"}], "update_date": "2020-07-28", "authors_parsed": [["Ghassemi", "Payam", ""], ["DePauw", "David", ""], ["Chowdhury", "Souma", ""]]}, {"id": "1907.04396", "submitter": "Souma Chowdhury", "authors": "Payam Ghassemi, Souma Chowdhury", "title": "Informative Path Planning with Local Penalization for Decentralized and\n  Asynchronous Swarm Robotic Search", "comments": "Accepted for presentation in (and publication in the proceedings of)\n  The IEEE 2019 International Symposium on Multi-Robot and Multi-Agent Systems\n  (MRS)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Decentralized swarm robotic solutions to searching for targets that emit a\nspatially varying signal promise task parallelism, time efficiency, and fault\ntolerance. It is, however, challenging for swarm algorithms to offer\nscalability and efficiency, while preserving mathematical insights into the\nexhibited behavior. A new decentralized search method (called Bayes-Swarm),\nfounded on batch Bayesian Optimization (BO) principles, is presented here to\naddress these challenges. Unlike swarm heuristics approaches, Bayes-Swarm\ndecouples the knowledge generation and task planning process, thus preserving\ninsights into the emergent behavior. Key contributions lie in: 1) modeling\nknowledge extraction over trajectories, unlike in BO; 2) time-adaptively\nbalancing exploration/exploitation and using an efficient local penalization\napproach to account for potential interactions among different robots' planned\nsamples; and 3) presenting an asynchronous implementation of the algorithm.\nThis algorithm is tested on case studies with bimodal and highly multimodal\nsignal distributions. Up to 76 times better efficiency is demonstrated compared\nto an exhaustive search baseline. The benefits of exploitation/exploration\nbalancing, asynchronous planning, and local penalization, and scalability with\nswarm size, are also demonstrated.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jul 2019 20:29:48 GMT"}], "update_date": "2019-07-11", "authors_parsed": [["Ghassemi", "Payam", ""], ["Chowdhury", "Souma", ""]]}, {"id": "1907.04408", "submitter": "Curtis Bright", "authors": "Curtis Bright, Ilias Kotsireas, Vijay Ganesh", "title": "SAT Solvers and Computer Algebra Systems: A Powerful Combination for\n  Mathematics", "comments": "To appear in Proceedings of the 29th International Conference on\n  Computer Science and Software Engineering", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI cs.SC math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Over the last few decades, many distinct lines of research aimed at\nautomating mathematics have been developed, including computer algebra systems\n(CASs) for mathematical modelling, automated theorem provers for first-order\nlogic, SAT/SMT solvers aimed at program verification, and higher-order proof\nassistants for checking mathematical proofs. More recently, some of these lines\nof research have started to converge in complementary ways. One success story\nis the combination of SAT solvers and CASs (SAT+CAS) aimed at resolving\nmathematical conjectures.\n  Many conjectures in pure and applied mathematics are not amenable to\ntraditional proof methods. Instead, they are best addressed via computational\nmethods that involve very large combinatorial search spaces. SAT solvers are\npowerful methods to search through such large combinatorial\nspaces---consequently, many problems from a variety of mathematical domains\nhave been reduced to SAT in an attempt to resolve them. However, solvers\ntraditionally lack deep repositories of mathematical domain knowledge that can\nbe crucial to pruning such large search spaces. By contrast, CASs are deep\nrepositories of mathematical knowledge but lack efficient general search\ncapabilities. By combining the search power of SAT with the deep mathematical\nknowledge in CASs we can solve many problems in mathematics that no other known\nmethods seem capable of solving.\n  We demonstrate the success of the SAT+CAS paradigm by highlighting many\nconjectures that have been disproven, verified, or partially verified using our\ntool MathCheck. These successes indicate that the paradigm is positioned to\nbecome a standard method for solving problems requiring both a significant\namount of search and deep mathematical reasoning. For example, the SAT+CAS\nparadigm has recently been used by Heule, Kauers, and Seidl to find many new\nalgorithms for $3\\times3$ matrix multiplication.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jul 2019 20:49:14 GMT"}, {"version": "v2", "created": "Mon, 16 Sep 2019 17:24:42 GMT"}], "update_date": "2019-09-18", "authors_parsed": [["Bright", "Curtis", ""], ["Kotsireas", "Ilias", ""], ["Ganesh", "Vijay", ""]]}, {"id": "1907.04457", "submitter": "Hanna Kurniawati", "authors": "Nicholas Collins and Hanna Kurniawati", "title": "Partially Observable Planning and Learning for Systems with Non-Uniform\n  Dynamics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a neural network architecture, called TransNet, that combines\nplanning and model learning for solving Partially Observable Markov Decision\nProcesses (POMDPs) with non-uniform system dynamics. The past decade has seen a\nsubstantial advancement in solving POMDP problems. However, constructing a\nsuitable POMDP model remains difficult. Recently, neural network architectures\nhave been proposed to alleviate the difficulty in acquiring such models.\nAlthough the results are promising, existing architectures restrict the type of\nsystem dynamics that can be learned --that is, system dynamics must be the same\nin all parts of the state space. TransNet relaxes such a restriction. Key to\nthis relaxation is a novel neural network module that classifies the state\nspace into classes and then learns the system dynamics of the different\nclasses. TransNet uses this module together with the overall architecture of\nQMDP-Net[1] to allow solving POMDPs that have more expressive dynamic models,\nwhile maintaining efficient data requirement. Its evaluation on typical\nbenchmarks in robot navigation with initially unknown system and environment\nmodels indicates that TransNet substantially out-performs the quality of the\ngenerated policies and learning efficiency of the state-of-the-art method\nQMDP-Net.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jul 2019 23:22:42 GMT"}], "update_date": "2019-07-11", "authors_parsed": [["Collins", "Nicholas", ""], ["Kurniawati", "Hanna", ""]]}, {"id": "1907.04482", "submitter": "Cheng He", "authors": "Cheng He, Shihua Huang, Ran Cheng, Kay Chen Tan, and Yaochu Jin", "title": "Evolutionary Multi-Objective Optimization Driven by Generative\n  Adversarial Networks", "comments": "This is a redundant version of 1910.04966", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, more and more works have proposed to drive evolutionary algorithms\nusing machine learning models.Usually, the performance of such model based\nevolutionary algorithms is highly dependent on the training qualities of the\nadopted models.Since it usually requires a certain amount of data (i.e. the\ncandidate solutions generated by the algorithms) for model training, the\nperformance deteriorates rapidly with the increase of the problem scales, due\nto the curse of dimensionality.To address this issue, we propose a\nmulti-objective evolutionary algorithm driven by the generative adversarial\nnetworks (GANs).At each generation of the proposed algorithm, the parent\nsolutions are first classified into \\emph{real} and \\emph{fake} samples to\ntrain the GANs; then the offspring solutions are sampled by the trained\nGANs.Thanks to the powerful generative ability of the GANs, our proposed\nalgorithm is capable of generating promising offspring solutions in\nhigh-dimensional decision space with limited training data.The proposed\nalgorithm is tested on 10 benchmark problems with up to 200 decision\nvariables.Experimental results on these test problems demonstrate the\neffectiveness of the proposed algorithm.\n", "versions": [{"version": "v1", "created": "Wed, 10 Jul 2019 01:50:20 GMT"}, {"version": "v2", "created": "Tue, 7 Apr 2020 02:24:47 GMT"}], "update_date": "2020-04-08", "authors_parsed": [["He", "Cheng", ""], ["Huang", "Shihua", ""], ["Cheng", "Ran", ""], ["Tan", "Kay Chen", ""], ["Jin", "Yaochu", ""]]}, {"id": "1907.04484", "submitter": "Jialin Song", "authors": "Jialin Song, Ravi Lanka, Yisong Yue, Masahiro Ono", "title": "Co-training for Policy Learning", "comments": "UAI 2019, oral presentation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of learning sequential decision-making policies in\nsettings with multiple state-action representations. Such settings naturally\narise in many domains, such as planning (e.g., multiple integer programming\nformulations) and various combinatorial optimization problems (e.g., those with\nboth integer programming and graph-based formulations). Inspired by the\nclassical co-training framework for classification, we study the problem of\nco-training for policy learning. We present sufficient conditions under which\nlearning from two views can improve upon learning from a single view alone.\nMotivated by these theoretical insights, we present a meta-algorithm for\nco-training for sequential decision making. Our framework is compatible with\nboth reinforcement learning and imitation learning. We validate the\neffectiveness of our approach across a wide range of tasks, including\ndiscrete/continuous control and combinatorial optimization.\n", "versions": [{"version": "v1", "created": "Wed, 3 Jul 2019 02:54:13 GMT"}], "update_date": "2019-07-11", "authors_parsed": [["Song", "Jialin", ""], ["Lanka", "Ravi", ""], ["Yue", "Yisong", ""], ["Ono", "Masahiro", ""]]}, {"id": "1907.04534", "submitter": "Amanda Askell", "authors": "Amanda Askell, Miles Brundage, Gillian Hadfield", "title": "The Role of Cooperation in Responsible AI Development", "comments": "23 pages, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we argue that competitive pressures could incentivize AI\ncompanies to underinvest in ensuring their systems are safe, secure, and have a\npositive social impact. Ensuring that AI systems are developed responsibly may\ntherefore require preventing and solving collective action problems between\ncompanies. We note that there are several key factors that improve the\nprospects for cooperation in collective action problems. We use this to\nidentify strategies to improve the prospects for industry cooperation on the\nresponsible development of AI.\n", "versions": [{"version": "v1", "created": "Wed, 10 Jul 2019 06:51:04 GMT"}], "update_date": "2019-07-11", "authors_parsed": [["Askell", "Amanda", ""], ["Brundage", "Miles", ""], ["Hadfield", "Gillian", ""]]}, {"id": "1907.04543", "submitter": "Rishabh Agarwal", "authors": "Rishabh Agarwal, Dale Schuurmans, Mohammad Norouzi", "title": "An Optimistic Perspective on Offline Reinforcement Learning", "comments": "ICML 2020. An earlier version was titled \"Striving for Simplicity in\n  Off-Policy Deep Reinforcement Learning\". Project Website:\n  https://offline-rl.github.io", "journal-ref": "Proceedings of the 37th International Conference on Machine\n  Learning, PMLR 119:104-114, 2020", "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Off-policy reinforcement learning (RL) using a fixed offline dataset of\nlogged interactions is an important consideration in real world applications.\nThis paper studies offline RL using the DQN replay dataset comprising the\nentire replay experience of a DQN agent on 60 Atari 2600 games. We demonstrate\nthat recent off-policy deep RL algorithms, even when trained solely on this\nfixed dataset, outperform the fully trained DQN agent. To enhance\ngeneralization in the offline setting, we present Random Ensemble Mixture\n(REM), a robust Q-learning algorithm that enforces optimal Bellman consistency\non random convex combinations of multiple Q-value estimates. Offline REM\ntrained on the DQN replay dataset surpasses strong RL baselines. Ablation\nstudies highlight the role of offline dataset size and diversity as well as the\nalgorithm choice in our positive results. Overall, the results here present an\noptimistic view that robust RL algorithms trained on sufficiently large and\ndiverse offline datasets can lead to high quality policies. The DQN replay\ndataset can serve as an offline RL benchmark and is open-sourced.\n", "versions": [{"version": "v1", "created": "Wed, 10 Jul 2019 07:23:27 GMT"}, {"version": "v2", "created": "Tue, 1 Oct 2019 16:35:52 GMT"}, {"version": "v3", "created": "Fri, 6 Mar 2020 00:35:57 GMT"}, {"version": "v4", "created": "Mon, 22 Jun 2020 04:32:50 GMT"}], "update_date": "2020-11-25", "authors_parsed": [["Agarwal", "Rishabh", ""], ["Schuurmans", "Dale", ""], ["Norouzi", "Mohammad", ""]]}, {"id": "1907.04553", "submitter": "Thao Minh Le", "authors": "Thao Minh Le, Vuong Le, Svetha Venkatesh, Truyen Tran", "title": "Neural Reasoning, Fast and Slow, for Video Question Answering", "comments": null, "journal-ref": "International Joint Conference on Neural Networks (IJCNN) 2020", "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  What does it take to design a machine that learns to answer natural questions\nabout a video? A Video QA system must simultaneously understand language,\nrepresent visual content over space-time, and iteratively transform these\nrepresentations in response to lingual content in the query, and finally\narriving at a sensible answer. While recent advances in lingual and visual\nquestion answering have enabled sophisticated representations and neural\nreasoning mechanisms, major challenges in Video QA remain on dynamic grounding\nof concepts, relations and actions to support the reasoning process. Inspired\nby the dual-process account of human reasoning, we design a dual process neural\narchitecture, which is composed of a question-guided video processing module\n(System 1, fast and reactive) followed by a generic reasoning module (System 2,\nslow and deliberative). System 1 is a hierarchical model that encodes visual\npatterns about objects, actions and relations in space-time given the textual\ncues from the question. The encoded representation is a set of high-level\nvisual features, which are then passed to System 2. Here multi-step inference\nfollows to iteratively chain visual elements as instructed by the textual\nelements. The system is evaluated on the SVQA (synthetic) and TGIF-QA datasets\n(real), demonstrating competitive results, with a large margin in the case of\nmulti-step reasoning.\n", "versions": [{"version": "v1", "created": "Wed, 10 Jul 2019 07:53:17 GMT"}, {"version": "v2", "created": "Sat, 11 Apr 2020 00:30:34 GMT"}], "update_date": "2020-04-14", "authors_parsed": [["Le", "Thao Minh", ""], ["Le", "Vuong", ""], ["Venkatesh", "Svetha", ""], ["Tran", "Truyen", ""]]}, {"id": "1907.04592", "submitter": "Alexey Potapov", "authors": "Alexey Potapov, Anatoly Belikov, Vitaly Bogdanov, Alexander Scherbatiy", "title": "Differentiable Probabilistic Logic Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Probabilistic logic reasoning is a central component of such cognitive\narchitectures as OpenCog. However, as an integrative architecture, OpenCog\nfacilitates cognitive synergy via hybridization of different inference methods.\nIn this paper, we introduce a differentiable version of Probabilistic Logic\nnetworks, which rules operate over tensor truth values in such a way that a\nchain of reasoning steps constructs a computation graph over tensors that\naccepts truth values of premises from the knowledge base as input and produces\ntruth values of conclusions as output. This allows for both learning truth\nvalues of premises and formulas for rules (specified in a form with trainable\nweights) by backpropagation combining subsymbolic optimization and symbolic\nreasoning.\n", "versions": [{"version": "v1", "created": "Wed, 10 Jul 2019 09:44:10 GMT"}], "update_date": "2019-07-11", "authors_parsed": [["Potapov", "Alexey", ""], ["Belikov", "Anatoly", ""], ["Bogdanov", "Vitaly", ""], ["Scherbatiy", "Alexander", ""]]}, {"id": "1907.04649", "submitter": "Leroy Cronin Prof", "authors": "Stuart M. Marshall, Douglas Moore, Alastair R. G. Murray, Sara I.\n  Walker, Leroy Cronin", "title": "Quantifying the pathways to life using assembly spaces", "comments": "manuscript with 10 figures and supplementary data", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI physics.bio-ph", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We have developed the concept of pathway assembly to explore the amount of\nextrinsic information required to build an object. To quantify this information\nin an agnostic way, we present a method to determine the amount of pathway\nassembly information contained within such an object by deconstructing the\nobject into its irreducible parts, and then evaluating the minimum number of\nsteps to reconstruct the object along any pathway. The mathematical\nformalisation of this approach uses an assembly space. By finding the minimal\nnumber of steps contained in the route by which the objects can be assembled\nwithin that space, we can compare how much information (I) is gained from\nknowing this pathway assembly index (PA) according to I_PA=log (|N|)/(|N_PA |)\nwhere, for an end product with PA=x, N is the set of objects possible that can\nbe created from the same irreducible parts within x steps regardless of PA, and\nNPA is the subset of those objects with the precise pathway assembly index\nPA=x. Applying this formalism to objects formed in 1D, 2D and 3D space allows\nus to identify objects in the world or wider Universe that have high assembly\nnumbers. We propose that objects with PA greater than a threshold are important\nbecause these are uniquely identifiable as those that must have been produced\nby biological or technological processes, rather than the assembly occurring\nvia unbiased random processes alone. We think this approach is needed to help\nidentify the new physical and chemical laws needed to understand what life is,\nby quantifying what life does.\n", "versions": [{"version": "v1", "created": "Sat, 6 Jul 2019 18:53:08 GMT"}, {"version": "v2", "created": "Fri, 9 Aug 2019 22:35:24 GMT"}], "update_date": "2019-08-13", "authors_parsed": [["Marshall", "Stuart M.", ""], ["Moore", "Douglas", ""], ["Murray", "Alastair R. G.", ""], ["Walker", "Sara I.", ""], ["Cronin", "Leroy", ""]]}, {"id": "1907.04651", "submitter": "Brendan Bennett", "authors": "Brendan Bennett, Wesley Chung, Muhammad Zaheer, Vincent Liu", "title": "Incrementally Learning Functions of the Return", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Temporal difference methods enable efficient estimation of value functions in\nreinforcement learning in an incremental fashion, and are of broader interest\nbecause they correspond learning as observed in biological systems. Standard\nvalue functions correspond to the expected value of a sum of discounted\nreturns. While this formulation is often sufficient for many purposes, it would\noften be useful to be able to represent functions of the return as well.\nUnfortunately, most such functions cannot be estimated directly using TD\nmethods. We propose a means of estimating functions of the return using its\nmoments, which can be learned online using a modified TD algorithm. The moments\nof the return are then used as part of a Taylor expansion to approximate\nanalytic functions of the return.\n", "versions": [{"version": "v1", "created": "Fri, 5 Jul 2019 22:33:36 GMT"}], "update_date": "2019-07-11", "authors_parsed": [["Bennett", "Brendan", ""], ["Chung", "Wesley", ""], ["Zaheer", "Muhammad", ""], ["Liu", "Vincent", ""]]}, {"id": "1907.04658", "submitter": "Jeffrey Barratt", "authors": "Jeffrey Barratt, Chuanbo Pan", "title": "Playing Go without Game Tree Search Using Convolutional Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The game of Go has a long history in East Asian countries, but the field of\nComputer Go has yet to catch up to humans until the past couple of years. While\nthe rules of Go are simple, the strategy and combinatorics of the game are\nimmensely complex. Even within the past couple of years, new programs that rely\non neural networks to evaluate board positions still explore many orders of\nmagnitude more board positions per second than a professional can. We attempt\nto mimic human intuition in the game by creating a convolutional neural policy\nnetwork which, without any sort of tree search, should play the game at or\nabove the level of most humans. We introduce three structures and training\nmethods that aim to create a strong Go player: non-rectangular convolutions,\nwhich will better learn the shapes on the board, supervised learning, training\non a data set of 53,000 professional games, and reinforcement learning,\ntraining on games played between different versions of the network. Our network\nhas already surpassed the skill level of intermediate amateurs simply using\nsupervised learning. Further training and implementation of non-rectangular\nconvolutions and reinforcement learning will likely increase this skill level\nmuch further.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jul 2019 19:12:38 GMT"}], "update_date": "2019-07-12", "authors_parsed": [["Barratt", "Jeffrey", ""], ["Pan", "Chuanbo", ""]]}, {"id": "1907.04659", "submitter": "Ravi Kashyap", "authors": "Ravi Kashyap", "title": "Artificial Intelligence: A Child's Play", "comments": null, "journal-ref": "Technological Forecasting and Social Change, 166, May 2021, 120555", "doi": "10.1016/j.techfore.2020.120555", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We discuss the objectives of any endeavor in creating artificial\nintelligence, AI, and provide a possible alternative. Intelligence might be an\nunintended consequence of curiosity left to roam free, best exemplified by a\nfrolicking infant. This suggests that our attempts at AI could have been\nmisguided. What we actually need to strive for can be termed artificial\ncuriosity, AC, and intelligence happens as a consequence of those efforts. For\nthis unintentional yet welcome aftereffect to set in a foundational list of\nguiding principles needs to be present. We start with the intuition for this\nline of reasoning and formalize it with a series of definitions, assumptions,\ningredients, models and iterative improvements that will be necessary to make\nthe incubation of intelligence a reality. Our discussion provides conceptual\nmodifications to the Turing Test and to Searle's Chinese room argument. We\ndiscuss the future implications for society as AI becomes an integral part of\nlife.\n  We provide a road-map for creating intelligence with the technical parts\nrelegated to the appendix so that the article is accessible to a wide audience.\nThe central techniques in our formal approach to creating intelligence draw\nupon tools and concepts widely used in physics, cognitive science, psychology,\nevolutionary biology, statistics, linguistics, communication systems, pattern\nrecognition, marketing, economics, finance, information science and\ncomputational theory highlighting that solutions for creating artificial\nintelligence have to transcend the artificial barriers between various fields\nand be highly multi-disciplinary.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jul 2019 04:46:07 GMT"}, {"version": "v2", "created": "Thu, 18 Jun 2020 11:50:24 GMT"}, {"version": "v3", "created": "Sat, 30 Jan 2021 15:05:12 GMT"}], "update_date": "2021-02-02", "authors_parsed": [["Kashyap", "Ravi", ""]]}, {"id": "1907.04666", "submitter": "Paul Compagnon", "authors": "Paul Compagnon (imagine), Gr\\'egoire Lefebvre, Stefan Duffner\n  (imagine), Christophe Garcia (imagine)", "title": "Routine Modeling with Time Series Metric Learning", "comments": null, "journal-ref": "28th International Conference on Artificial Neural Networks, Sep\n  2019, Munich, Germany", "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditionally, the automatic recognition of human activities is performed\nwith supervised learning algorithms on limited sets of specific activities.\nThis work proposes to recognize recurrent activity patterns, called routines,\ninstead of precisely defined activities. The modeling of routines is defined as\na metric learning problem, and an architecture, called SS2S, based on\nsequence-to-sequence models is proposed to learn a distance between time\nseries. This approach only relies on inertial data and is thus non intrusive\nand preserves privacy. Experimental results show that a clustering algorithm\nprovided with the learned distance is able to recover daily routines.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jul 2019 14:10:01 GMT"}], "update_date": "2019-07-11", "authors_parsed": [["Compagnon", "Paul", "", "imagine"], ["Lefebvre", "Gr\u00e9goire", "", "imagine"], ["Duffner", "Stefan", "", "imagine"], ["Garcia", "Christophe", "", "imagine"]]}, {"id": "1907.04679", "submitter": "Javier Navarro", "authors": "Javier Navarro, Christian Wagner", "title": "Measuring Inter-group Agreement on zSlice Based General Type-2 Fuzzy\n  Sets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, there has been much research into modelling of uncertainty in human\nperception through Fuzzy Sets (FSs). Most of this research has focused on\nallowing respondents to express their (intra) uncertainty using intervals.\nHere, depending on the technique used and types of uncertainties being modelled\ndifferent types of FSs can be obtained (e.g., Type-1, Interval Type-2, General\nType-2). Arguably, one of the most flexible techniques is the Interval\nAgreement Approach (IAA) as it allows to model the perception of all\nrespondents without making assumptions such as outlier removal or predefined\nmembership function types (e.g. Gaussian). A key aspect in the analysis of\ninterval-valued data and indeed, IAA based agreement models of said data, is to\ndetermine the position and strengths of agreement across all the\nsources/participants. While previously, the Agreement Ratio was proposed to\nmeasure the strength of agreement in fuzzy set based models of interval data,\nsaid measure has only been applicable to type-1 fuzzy sets. In this paper, we\nextend the Agreement Ratio to capture the degree of inter-group agreement\nmodelled by a General Type-2 Fuzzy Set when using the IAA. This measure relies\non using a similarity measure to quantitatively express the relation between\nthe different levels of agreement in a given FS. Synthetic examples are\nprovided in order to demonstrate both behaviour and calculation of the measure.\nFinally, an application to real-world data is provided in order to show the\npotential of this measure to assess the divergence of opinions for ambiguous\nconcepts when heterogeneous groups of participants are involved.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jul 2019 16:36:36 GMT"}], "update_date": "2019-07-11", "authors_parsed": [["Navarro", "Javier", ""], ["Wagner", "Christian", ""]]}, {"id": "1907.04711", "submitter": "Paulo Roberto De Oliveira Da Costa", "authors": "Paulo R. de O. da Costa, J. Rhuggenaath, Y. Zhang, A. Akcay, W. Lee\n  and U. Kaymak", "title": "Data-driven Policy on Feasibility Determination for the Train Shunting\n  Problem", "comments": "Accepted as conference paper at ECML PKDD 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Parking, matching, scheduling, and routing are common problems in train\nmaintenance. In particular, train units are commonly maintained and cleaned at\ndedicated shunting yards. The planning problem that results from such\nsituations is referred to as the Train Unit Shunting Problem (TUSP). This\nproblem involves matching arriving train units to service tasks and determining\nthe schedule for departing trains. The TUSP is an important problem as it is\nused to determine the capacity of shunting yards and arises as a sub-problem of\nmore general scheduling and planning problems. In this paper, we consider the\ncase of the Dutch Railways (NS) TUSP. As the TUSP is complex, NS currently uses\na local search (LS) heuristic to determine if an instance of the TUSP has a\nfeasible solution. Given the number of shunting yards and the size of the\nplanning problems, improving the evaluation speed of the LS brings significant\ncomputational gain. In this work, we use a machine learning approach that\ncomplements the LS and accelerates the search process. We use a Deep Graph\nConvolutional Neural Network (DGCNN) model to predict the feasibility of\nsolutions obtained during the run of the LS heuristic. We use this model to\ndecide whether to continue or abort the search process. In this way, the\ncomputation time is used more efficiently as it is spent on instances that are\nmore likely to be feasible. Using simulations based on real-life instances of\nthe TUSP, we show how our approach improves upon the previous method on\nprediction accuracy and leads to computational gains for the decision-making\nprocess.\n", "versions": [{"version": "v1", "created": "Wed, 10 Jul 2019 13:32:14 GMT"}], "update_date": "2019-07-11", "authors_parsed": [["da Costa", "Paulo R. de O.", ""], ["Rhuggenaath", "J.", ""], ["Zhang", "Y.", ""], ["Akcay", "A.", ""], ["Lee", "W.", ""], ["Kaymak", "U.", ""]]}, {"id": "1907.04719", "submitter": "Fuyuan Xiao", "authors": "Fuyuan Xiao", "title": "Generalized Belief Function: A new concept for uncertainty modelling and\n  processing", "comments": "10 pages. arXiv admin note: substantial text overlap with\n  arXiv:1907.00716, arXiv:1906.11409", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we generalize the belief function on complex plane from\nanother point of view. We first propose a new concept of complex mass function\nbased on the complex number, called complex basic belief assignment, which is a\ngeneralization of the traditional mass function in Dempster-Shafer evidence\ntheory. On the basis of the de nition of complex mass function, the belief\nfunction and plausibility function are generalized. In particular, when the\ncomplex mass function is degenerated from complex numbers to real numbers, the\ngeneralized belief and plausibility functions degenerate into the traditional\nbelief and plausibility functions in DSE theory, respectively.\n", "versions": [{"version": "v1", "created": "Wed, 3 Jul 2019 06:42:35 GMT"}], "update_date": "2019-07-11", "authors_parsed": [["Xiao", "Fuyuan", ""]]}, {"id": "1907.04799", "submitter": "Hao-Tien Lewis Chiang", "authors": "Hao-Tien Lewis Chiang, Jasmine Hsu, Marek Fiser, Lydia Tapia,\n  Aleksandra Faust", "title": "RL-RRT: Kinodynamic Motion Planning via Learning Reachability Estimators\n  from RL Policies", "comments": "Accepted to Robotics and Automation Letters in June 2019", "journal-ref": "Robotics and Automation Letters 2019", "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper addresses two challenges facing sampling-based kinodynamic motion\nplanning: a way to identify good candidate states for local transitions and the\nsubsequent computationally intractable steering between these candidate states.\nThrough the combination of sampling-based planning, a Rapidly Exploring\nRandomized Tree (RRT) and an efficient kinodynamic motion planner through\nmachine learning, we propose an efficient solution to long-range planning for\nkinodynamic motion planning. First, we use deep reinforcement learning to learn\nan obstacle-avoiding policy that maps a robot's sensor observations to actions,\nwhich is used as a local planner during planning and as a controller during\nexecution. Second, we train a reachability estimator in a supervised manner,\nwhich predicts the RL policy's time to reach a state in the presence of\nobstacles. Lastly, we introduce RL-RRT that uses the RL policy as a local\nplanner, and the reachability estimator as the distance function to bias\ntree-growth towards promising regions. We evaluate our method on three\nkinodynamic systems, including physical robot experiments. Results across all\nthree robots tested indicate that RL-RRT outperforms state of the art\nkinodynamic planners in efficiency, and also provides a shorter path finish\ntime than a steering function free method. The learned local planner policy and\naccompanying reachability estimator demonstrate transferability to the\npreviously unseen experimental environments, making RL-RRT fast because the\nexpensive computations are replaced with simple neural network inference.\nVideo: https://youtu.be/dDMVMTOI8KY\n", "versions": [{"version": "v1", "created": "Wed, 10 Jul 2019 15:36:03 GMT"}, {"version": "v2", "created": "Fri, 12 Jul 2019 17:55:01 GMT"}], "update_date": "2019-07-15", "authors_parsed": [["Chiang", "Hao-Tien Lewis", ""], ["Hsu", "Jasmine", ""], ["Fiser", "Marek", ""], ["Tapia", "Lydia", ""], ["Faust", "Aleksandra", ""]]}, {"id": "1907.04957", "submitter": "Jesse Thomason", "authors": "Jesse Thomason, Michael Murray, Maya Cakmak, and Luke Zettlemoyer", "title": "Vision-and-Dialog Navigation", "comments": "Conference on Robot Learning (CoRL) 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.CV cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Robots navigating in human environments should use language to ask for\nassistance and be able to understand human responses. To study this challenge,\nwe introduce Cooperative Vision-and-Dialog Navigation, a dataset of over 2k\nembodied, human-human dialogs situated in simulated, photorealistic home\nenvironments. The Navigator asks questions to their partner, the Oracle, who\nhas privileged access to the best next steps the Navigator should take\naccording to a shortest path planner. To train agents that search an\nenvironment for a goal location, we define the Navigation from Dialog History\ntask. An agent, given a target object and a dialog history between humans\ncooperating to find that object, must infer navigation actions towards the goal\nin unexplored environments. We establish an initial, multi-modal\nsequence-to-sequence model and demonstrate that looking farther back in the\ndialog history improves performance. Sourcecode and a live interface demo can\nbe found at https://cvdn.dev/\n", "versions": [{"version": "v1", "created": "Wed, 10 Jul 2019 23:41:46 GMT"}, {"version": "v2", "created": "Fri, 19 Jul 2019 04:07:17 GMT"}, {"version": "v3", "created": "Sun, 13 Oct 2019 02:09:00 GMT"}], "update_date": "2019-10-15", "authors_parsed": [["Thomason", "Jesse", ""], ["Murray", "Michael", ""], ["Cakmak", "Maya", ""], ["Zettlemoyer", "Luke", ""]]}, {"id": "1907.04964", "submitter": "Nicholas Charles Landolfi", "authors": "Nicholas C. Landolfi and Garrett Thomas and Tengyu Ma", "title": "A Model-based Approach for Sample-efficient Multi-task Reinforcement\n  Learning", "comments": "13 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The aim of multi-task reinforcement learning is two-fold: (1) efficiently\nlearn by training against multiple tasks and (2) quickly adapt, using limited\nsamples, to a variety of new tasks. In this work, the tasks correspond to\nreward functions for environments with the same (or similar) dynamical models.\nWe propose to learn a dynamical model during the training process and use this\nmodel to perform sample-efficient adaptation to new tasks at test time. We use\nsignificantly fewer samples by performing policy optimization only in a\n\"virtual\" environment whose transitions are given by our learned dynamical\nmodel. Our algorithm sequentially trains against several tasks. Upon\nencountering a new task, we first warm-up a policy on our learned dynamical\nmodel, which requires no new samples from the environment. We then adapt the\ndynamical model with samples from this policy in the real environment. We\nevaluate our approach on several continuous control benchmarks and demonstrate\nits efficacy over MAML, a state-of-the-art meta-learning algorithm, on these\ntasks.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jul 2019 00:45:44 GMT"}, {"version": "v2", "created": "Mon, 15 Jul 2019 05:35:35 GMT"}, {"version": "v3", "created": "Sun, 3 Nov 2019 20:30:47 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Landolfi", "Nicholas C.", ""], ["Thomas", "Garrett", ""], ["Ma", "Tengyu", ""]]}, {"id": "1907.05000", "submitter": "Vu Hoang Nguyen Phan", "authors": "Jeffrey M. Dudek, Vu H. N. Phan, Moshe Y. Vardi", "title": "ADDMC: Weighted Model Counting with Algebraic Decision Diagrams", "comments": "Presented at AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an algorithm to compute exact literal-weighted model counts of\nBoolean formulas in Conjunctive Normal Form. Our algorithm employs dynamic\nprogramming and uses Algebraic Decision Diagrams as the primary data structure.\nWe implement this technique in ADDMC, a new model counter. We empirically\nevaluate various heuristics that can be used with ADDMC. We then compare ADDMC\nto state-of-the-art exact weighted model counters (Cachet, c2d, d4, and\nminiC2D) on 1914 standard model counting benchmarks and show that ADDMC\nsignificantly improves the virtual best solver.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jul 2019 05:21:10 GMT"}, {"version": "v2", "created": "Tue, 2 Jun 2020 05:42:12 GMT"}], "update_date": "2020-06-03", "authors_parsed": [["Dudek", "Jeffrey M.", ""], ["Phan", "Vu H. N.", ""], ["Vardi", "Moshe Y.", ""]]}, {"id": "1907.05028", "submitter": "Siwar Jendoubi", "authors": "Siwar Jendoubi (LARODEC), Arnaud Martin (DRUID)", "title": "Evidential positive opinion influence measures for viral marketing", "comments": "Knowledge and Information Systems (KAIS), Springer, 2019", "journal-ref": null, "doi": "10.1007/s10115-019-01375-w", "report-no": null, "categories": "cs.SI cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Viral Marketing is a relatively new form of marketing that exploits\nsocial networks to promote a brand, a product, etc. The idea behind it is to\nfind a set of influencers on the network that can trigger a large cascade of\npropagation and adoptions. In this paper, we will introduce an evidential\nopinion-based influence maximization model for viral marketing. Besides, our\napproach tackles three opinions based scenarios for viral marketing in the real\nworld. The first scenario concerns influencers who have a positive opinion\nabout the product. The second scenario deals with influencers who have a\npositive opinion about the product and produce effects on users who also have a\npositive opinion. The third scenario involves influence users who have a\npositive opinion about the product and produce effects on the negative opinion\nof other users concerning the product in question. Next, we proposed six\ninfluence measures, two for each scenario. We also use an influence\nmaximization model that the set of detected influencers for each scenario.\nFinally, we show the performance of the proposed model with each influence\nmeasure through some experiments conducted on a generated dataset and a real\nworld dataset collected from Twitter.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jul 2019 07:33:27 GMT"}], "update_date": "2019-07-12", "authors_parsed": [["Jendoubi", "Siwar", "", "LARODEC"], ["Martin", "Arnaud", "", "DRUID"]]}, {"id": "1907.05079", "submitter": "Kimia Nadjahi", "authors": "Kimia Nadjahi, Romain Laroche, R\\'emi Tachet des Combes", "title": "Safe Policy Improvement with Soft Baseline Bootstrapping", "comments": "Accepted paper at ECML-PKDD2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Batch Reinforcement Learning (Batch RL) consists in training a policy using\ntrajectories collected with another policy, called the behavioural policy. Safe\npolicy improvement (SPI) provides guarantees with high probability that the\ntrained policy performs better than the behavioural policy, also called\nbaseline in this setting. Previous work shows that the SPI objective improves\nmean performance as compared to using the basic RL objective, which boils down\nto solving the MDP with maximum likelihood. Here, we build on that work and\nimprove more precisely the SPI with Baseline Bootstrapping algorithm (SPIBB) by\nallowing the policy search over a wider set of policies. Instead of binarily\nclassifying the state-action pairs into two sets (the \\textit{uncertain} and\nthe \\textit{safe-to-train-on} ones), we adopt a softer strategy that controls\nthe error in the value estimates by constraining the policy change according to\nthe local model uncertainty. The method can take more risks on uncertain\nactions all the while remaining provably-safe, and is therefore less\nconservative than the state-of-the-art methods. We propose two algorithms (one\noptimal and one approximate) to solve this constrained optimization problem and\nempirically show a significant improvement over existing SPI algorithms both on\nfinite MDPs and on infinite MDPs with a neural network function approximation.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jul 2019 09:59:10 GMT"}], "update_date": "2019-07-12", "authors_parsed": [["Nadjahi", "Kimia", ""], ["Laroche", "Romain", ""], ["Combes", "R\u00e9mi Tachet des", ""]]}, {"id": "1907.05208", "submitter": "Benjamin Genchel", "authors": "Benjamin Genchel, Ashis Pati, Alexander Lerch", "title": "Explicitly Conditioned Melody Generation: A Case Study with\n  Interdependent RNNs", "comments": "In Proceedings of the 7th International Workshop on Musical\n  Meta-creation (MUME). Charlotte, North Carolina 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.AI eess.AS", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Deep generative models for symbolic music are typically designed to model\ntemporal dependencies in music so as to predict the next musical event given\nprevious events. In many cases, such models are expected to learn abstract\nconcepts such as harmony, meter, and rhythm from raw musical data without any\nadditional information. In this study, we investigate the effects of explicitly\nconditioning deep generative models with musically relevant information.\nSpecifically, we study the effects of four different conditioning inputs on the\nperformance of a recurrent monophonic melody generation model. Several\ncombinations of these conditioning inputs are used to train different model\nvariants which are then evaluated using three objective evaluation paradigms\nacross two genres of music. The results indicate musically relevant\nconditioning significantly improves learning and performance, and reveal how\nthis information affects learning of musical features related to pitch and\nrhythm. An informal subjective evaluation suggests a corresponding improvement\nin the aesthetic quality of generations.\n", "versions": [{"version": "v1", "created": "Wed, 10 Jul 2019 00:05:53 GMT"}], "update_date": "2019-07-12", "authors_parsed": [["Genchel", "Benjamin", ""], ["Pati", "Ashis", ""], ["Lerch", "Alexander", ""]]}, {"id": "1907.05231", "submitter": "Shuai Ma", "authors": "Shuai Ma and Jia Yuan Yu", "title": "Variance-Based Risk Estimations in Markov Processes via Transformation\n  with State Lumping", "comments": "7 pages, 7 figures, SMC 2019 accepted. arXiv admin note: text overlap\n  with arXiv:1907.04269", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Variance plays a crucial role in risk-sensitive reinforcement learning, and\nmost risk measures can be analyzed via variance. In this paper, we consider two\nlaw-invariant risks as examples: mean-variance risk and exponential utility\nrisk. With the aid of the state-augmentation transformation (SAT), we show\nthat, the two risks can be estimated in Markov decision processes (MDPs) with a\nstochastic transition-based reward and a randomized policy. To relieve the\nenlarged state space, a novel definition of isotopic states is proposed for\nstate lumping, considering the special structure of the transformed transition\nprobability. In the numerical experiment, we illustrate state lumping in the\nSAT, errors from a naive reward simplification, and the validity of the SAT for\nthe two risk estimations.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jul 2019 16:04:33 GMT"}], "update_date": "2019-07-12", "authors_parsed": [["Ma", "Shuai", ""], ["Yu", "Jia Yuan", ""]]}, {"id": "1907.05246", "submitter": "Konstantinos Makantasis", "authors": "Konstantinos Makantasis, Maria Kontorinaki, Ioannis Nikolos", "title": "Deep Reinforcement-Learning-based Driving Policy for Autonomous Road\n  Vehicles", "comments": "19 pages. arXiv admin note: substantial text overlap with\n  arXiv:1905.09046", "journal-ref": null, "doi": "10.1049/iet-its.2019.0249", "report-no": null, "categories": "cs.RO cs.AI cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work the problem of path planning for an autonomous vehicle that\nmoves on a freeway is considered. The most common approaches that are used to\naddress this problem are based on optimal control methods, which make\nassumptions about the model of the environment and the system dynamics. On the\ncontrary, this work proposes the development of a driving policy based on\nreinforcement learning. In this way, the proposed driving policy makes minimal\nor no assumptions about the environment, since a priori knowledge about the\nsystem dynamics is not required. Driving scenarios where the road is occupied\nboth by autonomous and manual driving vehicles are considered. To the best of\nour knowledge, this is one of the first approaches that propose a reinforcement\nlearning driving policy for mixed driving environments. The derived\nreinforcement learning policy, firstly, is compared against an optimal policy\nderived via dynamic programming, and, secondly, its efficiency is evaluated\nunder realistic scenarios generated by the established SUMO microscopic traffic\nflow simulator. Finally, some initial results regarding the effect of\nautonomous vehicles' behavior on the overall traffic flow are presented.\n", "versions": [{"version": "v1", "created": "Wed, 10 Jul 2019 11:44:09 GMT"}, {"version": "v2", "created": "Tue, 18 Feb 2020 09:22:25 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Makantasis", "Konstantinos", ""], ["Kontorinaki", "Maria", ""], ["Nikolos", "Ioannis", ""]]}, {"id": "1907.05247", "submitter": "Stefano Albrecht", "authors": "Stefano V. Albrecht, Jacob W. Crandall, Subramanian Ramamoorthy", "title": "An Empirical Study on the Practical Impact of Prior Beliefs over Policy\n  Types", "comments": "Proceedings of the 29th AAAI Conference on Artificial Intelligence\n  (AAAI), 2015. arXiv admin note: substantial text overlap with\n  arXiv:1507.07688", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many multiagent applications require an agent to learn quickly how to\ninteract with previously unknown other agents. To address this problem,\nresearchers have studied learning algorithms which compute posterior beliefs\nover a hypothesised set of policies, based on the observed actions of the other\nagents. The posterior belief is complemented by the prior belief, which\nspecifies the subjective likelihood of policies before any actions are\nobserved. In this paper, we present the first comprehensive empirical study on\nthe practical impact of prior beliefs over policies in repeated interactions.\nWe show that prior beliefs can have a significant impact on the long-term\nperformance of such methods, and that the magnitude of the impact depends on\nthe depth of the planning horizon. Moreover, our results demonstrate that\nautomatic methods can be used to compute prior beliefs with consistent\nperformance effects. This indicates that prior beliefs could be eliminated as a\nmanual parameter and instead be computed automatically.\n", "versions": [{"version": "v1", "created": "Wed, 10 Jul 2019 09:47:44 GMT"}], "update_date": "2019-07-12", "authors_parsed": [["Albrecht", "Stefano V.", ""], ["Crandall", "Jacob W.", ""], ["Ramamoorthy", "Subramanian", ""]]}, {"id": "1907.05336", "submitter": "Mojtaba Nayyeri", "authors": "Mojtaba Nayyeri, Xiaotian Zhou, Sahar Vahdati, Hamed Shariat Yazdi,\n  Jens Lehmann", "title": "Adaptive Margin Ranking Loss for Knowledge Graph Embeddings via a\n  Correntropy Objective Function", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Translation-based embedding models have gained significant attention in link\nprediction tasks for knowledge graphs. TransE is the primary model among\ntranslation-based embeddings and is well-known for its low complexity and high\nefficiency. Therefore, most of the earlier works have modified the score\nfunction of the TransE approach in order to improve the performance of link\nprediction tasks. Nevertheless, proven theoretically and experimentally, the\nperformance of TransE strongly depends on the loss function. Margin Ranking\nLoss (MRL) has been one of the earlier loss functions which is widely used for\ntraining TransE. However, the scores of positive triples are not necessarily\nenforced to be sufficiently small to fulfill the translation from head to tail\nby using relation vector (original assumption of TransE). To tackle this\nproblem, several loss functions have been proposed recently by adding upper\nbounds and lower bounds to the scores of positive and negative samples.\nAlthough highly effective, previously developed models suffer from an expansion\nin search space for a selection of the hyperparameters (in particular the upper\nand lower bounds of scores) on which the performance of the translation-based\nmodels is highly dependent. In this paper, we propose a new loss function\ndubbed Adaptive Margin Loss (AML) for training translation-based embedding\nmodels. The formulation of the proposed loss function enables an adaptive and\nautomated adjustment of the margin during the learning process. Therefore,\ninstead of obtaining two values (upper bound and lower bound), only the center\nof a margin needs to be determined. During learning, the margin is expanded\nautomatically until it converges. In our experiments on a set of standard\nbenchmark datasets including Freebase and WordNet, the effectiveness of AML is\nconfirmed for training TransE on link prediction tasks.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jul 2019 12:32:40 GMT"}], "update_date": "2019-07-12", "authors_parsed": [["Nayyeri", "Mojtaba", ""], ["Zhou", "Xiaotian", ""], ["Vahdati", "Sahar", ""], ["Yazdi", "Hamed Shariat", ""], ["Lehmann", "Jens", ""]]}, {"id": "1907.05343", "submitter": "Ruisheng Cao", "authors": "Ruisheng Cao, Su Zhu, Chen Liu, Jieyu Li and Kai Yu", "title": "Semantic Parsing with Dual Learning", "comments": "Accepted by ACL 2019 Long Paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Semantic parsing converts natural language queries into structured logical\nforms. The paucity of annotated training samples is a fundamental challenge in\nthis field. In this work, we develop a semantic parsing framework with the dual\nlearning algorithm, which enables a semantic parser to make full use of data\n(labeled and even unlabeled) through a dual-learning game. This game between a\nprimal model (semantic parsing) and a dual model (logical form to query) forces\nthem to regularize each other, and can achieve feedback signals from some\nprior-knowledge. By utilizing the prior-knowledge of logical form structures,\nwe propose a novel reward signal at the surface and semantic levels which tends\nto generate complete and reasonable logical forms. Experimental results show\nthat our approach achieves new state-of-the-art performance on ATIS dataset and\ngets competitive performance on Overnight dataset.\n", "versions": [{"version": "v1", "created": "Wed, 10 Jul 2019 04:51:44 GMT"}, {"version": "v2", "created": "Wed, 24 Jul 2019 15:57:19 GMT"}], "update_date": "2019-07-25", "authors_parsed": [["Cao", "Ruisheng", ""], ["Zhu", "Su", ""], ["Liu", "Chen", ""], ["Li", "Jieyu", ""], ["Yu", "Kai", ""]]}, {"id": "1907.05390", "submitter": "Guojun Wu", "authors": "Guojun Wu, Yanhua Li, Zhenming Liu, Jie Bao, Yu Zheng, Jieping Ye, Jun\n  Luo", "title": "Reward Advancement: Transforming Policy under Maximum Causal Entropy\n  Principle", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Many real-world human behaviors can be characterized as a sequential decision\nmaking processes, such as urban travelers choices of transport modes and routes\n(Wu et al. 2017). Differing from choices controlled by machines, which in\ngeneral follows perfect rationality to adopt the policy with the highest\nreward, studies have revealed that human agents make sub-optimal decisions\nunder bounded rationality (Tao, Rohde, and Corcoran 2014). Such behaviors can\nbe modeled using maximum causal entropy (MCE) principle (Ziebart 2010). In this\npaper, we define and investigate a general reward trans-formation problem\n(namely, reward advancement): Recovering the range of additional reward\nfunctions that transform the agent's policy from original policy to a\npredefined target policy under MCE principle. We show that given an MDP and a\ntarget policy, there are infinite many additional reward functions that can\nachieve the desired policy transformation. Moreover, we propose an algorithm to\nfurther extract the additional rewards with minimum \"cost\" to implement the\npolicy transformation.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jul 2019 17:11:57 GMT"}], "update_date": "2019-07-12", "authors_parsed": [["Wu", "Guojun", ""], ["Li", "Yanhua", ""], ["Liu", "Zhenming", ""], ["Bao", "Jie", ""], ["Zheng", "Yu", ""], ["Ye", "Jieping", ""], ["Luo", "Jun", ""]]}, {"id": "1907.05431", "submitter": "Abhinav Verma", "authors": "Abhinav Verma, Hoang M. Le, Yisong Yue, Swarat Chaudhuri", "title": "Imitation-Projected Programmatic Reinforcement Learning", "comments": "Published in Advances in Neural Information Processing Systems\n  (NeurIPS) 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.PL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of programmatic reinforcement learning, in which\npolicies are represented as short programs in a symbolic language. Programmatic\npolicies can be more interpretable, generalizable, and amenable to formal\nverification than neural policies; however, designing rigorous learning\napproaches for such policies remains a challenge. Our approach to this\nchallenge -- a meta-algorithm called PROPEL -- is based on three insights.\nFirst, we view our learning task as optimization in policy space, modulo the\nconstraint that the desired policy has a programmatic representation, and solve\nthis optimization problem using a form of mirror descent that takes a gradient\nstep into the unconstrained policy space and then projects back onto the\nconstrained space. Second, we view the unconstrained policy space as mixing\nneural and programmatic representations, which enables employing\nstate-of-the-art deep policy gradient approaches. Third, we cast the projection\nstep as program synthesis via imitation learning, and exploit contemporary\ncombinatorial methods for this task. We present theoretical convergence results\nfor PROPEL and empirically evaluate the approach in three continuous control\ndomains. The experiments show that PROPEL can significantly outperform\nstate-of-the-art approaches for learning programmatic policies.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jul 2019 18:00:56 GMT"}, {"version": "v2", "created": "Wed, 23 Oct 2019 05:14:08 GMT"}, {"version": "v3", "created": "Mon, 4 Nov 2019 12:32:34 GMT"}, {"version": "v4", "created": "Tue, 19 Jan 2021 20:52:42 GMT"}], "update_date": "2021-01-21", "authors_parsed": [["Verma", "Abhinav", ""], ["Le", "Hoang M.", ""], ["Yue", "Yisong", ""], ["Chaudhuri", "Swarat", ""]]}, {"id": "1907.05446", "submitter": "Gabriel Ilharco", "authors": "Gabriel Ilharco, Vihan Jain, Alexander Ku, Eugene Ie, Jason Baldridge", "title": "General Evaluation for Instruction Conditioned Navigation using Dynamic\n  Time Warping", "comments": null, "journal-ref": "Thirty-third Conference on Neural Information Processing Systems\n  (NeurIPS 2019)", "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In instruction conditioned navigation, agents interpret natural language and\ntheir surroundings to navigate through an environment. Datasets for studying\nthis task typically contain pairs of these instructions and reference\ntrajectories. Yet, most evaluation metrics used thus far fail to properly\naccount for the latter, relying instead on insufficient similarity comparisons.\nWe address fundamental flaws in previously used metrics and show how Dynamic\nTime Warping (DTW), a long known method of measuring similarity between two\ntime series, can be used for evaluation of navigation agents. For such, we\ndefine the normalized Dynamic Time Warping (nDTW) metric, that softly penalizes\ndeviations from the reference path, is naturally sensitive to the order of the\nnodes composing each path, is suited for both continuous and graph-based\nevaluations, and can be efficiently calculated. Further, we define SDTW, which\nconstrains nDTW to only successful paths. We collect human similarity judgments\nfor simulated paths and find nDTW correlates better with human rankings than\nall other metrics. We also demonstrate that using nDTW as a reward signal for\nReinforcement Learning navigation agents improves their performance on both the\nRoom-to-Room (R2R) and Room-for-Room (R4R) datasets. The R4R results in\nparticular highlight the superiority of SDTW over previous success-constrained\nmetrics.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jul 2019 18:42:03 GMT"}, {"version": "v2", "created": "Thu, 28 Nov 2019 16:59:52 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Ilharco", "Gabriel", ""], ["Jain", "Vihan", ""], ["Ku", "Alexander", ""], ["Ie", "Eugene", ""], ["Baldridge", "Jason", ""]]}, {"id": "1907.05447", "submitter": "John Hooker", "authors": "Tae Wan Kim, Thomas Donaldson, John Hooker", "title": "Grounding Value Alignment with Ethical Principles", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An important step in the development of value alignment (VA) systems in AI is\nunderstanding how values can interrelate with facts. Designers of future VA\nsystems will need to utilize a hybrid approach in which ethical reasoning and\nempirical observation interrelate successfully in machine behavior. In this\narticle we identify two problems about this interrelation that have been\noverlooked by AI discussants and designers. The first problem is that many AI\ndesigners commit inadvertently a version of what has been called by moral\nphilosophers the \"naturalistic fallacy,\" that is, they attempt to derive an\n\"ought\" from an \"is.\" We illustrate when and why this occurs. The second\nproblem is that AI designers adopt training routines that fail fully to\nsimulate human ethical reasoning in the integration of ethical principles and\nfacts. Using concepts of quantified modal logic, we proceed to offer an\napproach that promises to simulate ethical reasoning in humans by connecting\nethical principles on the one hand and propositions about states of affairs on\nthe other.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jul 2019 18:55:47 GMT"}], "update_date": "2019-07-15", "authors_parsed": [["Kim", "Tae Wan", ""], ["Donaldson", "Thomas", ""], ["Hooker", "John", ""]]}, {"id": "1907.05505", "submitter": "Iman Tabrizian", "authors": "Saeedeh Parsaeefard, Iman Tabrizian, Alberto Leon-Garcia", "title": "Artificial Intelligence as a Services (AI-aaS) on Software-Defined\n  Infrastructure", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper investigates a paradigm for offering artificial intelligence as a\nservice (AI-aaS) on software-defined infrastructures (SDIs). The increasing\ncomplexity of networking and computing infrastructures is already driving the\nintroduction of automation in networking and cloud computing management\nsystems. Here we consider how these automation mechanisms can be leveraged to\noffer AI-aaS. Use cases for AI-aaS are easily found in addressing smart\napplications in sectors such as transportation, manufacturing, energy, water,\nair quality, and emissions. We propose an architectural scheme based on SDIs\nwhere each AI-aaS application is comprised of a monitoring, analysis, policy,\nexecution plus knowledge (MAPE-K) loop (MKL). Each application is composed as\none or more specific service chains embedded in SDI, some of which will include\na Machine Learning (ML) pipeline. Our model includes a new training plane and\nan AI-aaS plane to deal with the model-development and operational phases of AI\napplications. We also consider the role of an ML/MKL sandbox in ensuring\ncoherency and consistency in the operation of multiple parallel MKL loops. We\npresent experimental measurement results for three AI-aaS applications deployed\non the SAVI testbed: 1. Compressing monitored data in SDI using autoencoders;\n2. Traffic monitoring to allocate CPUs resources to VNFs; and 3. Highway\nsegment classification in smart transportation.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jul 2019 22:02:18 GMT"}], "update_date": "2019-07-15", "authors_parsed": [["Parsaeefard", "Saeedeh", ""], ["Tabrizian", "Iman", ""], ["Leon-Garcia", "Alberto", ""]]}, {"id": "1907.05518", "submitter": "Maximilian Sieb", "authors": "Maximilian Sieb, Zhou Xian, Audrey Huang, Oliver Kroemer, Katerina\n  Fragkiadaki", "title": "Graph-Structured Visual Imitation", "comments": "8 pages, 3 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We cast visual imitation as a visual correspondence problem. Our robotic\nagent is rewarded when its actions result in better matching of relative\nspatial configurations for corresponding visual entities detected in its\nworkspace and teacher's demonstration. We build upon recent advances in\nComputer Vision,such as human finger keypoint detectors, object detectors\ntrained on-the-fly with synthetic augmentations, and point detectors supervised\nby viewpoint changes and learn multiple visual entity detectors for each\ndemonstration without human annotations or robot interactions. We empirically\nshow the proposed factorized visual representations of entities and their\nspatial arrangements drive successful imitation of a variety of manipulation\nskills within minutes, using a single demonstration and without any environment\ninstrumentation. It is robust to background clutter and can effectively\ngeneralize across environment variations between demonstrator and imitator,\ngreatly outperforming unstructured non-factorized full-frame CNN encodings of\nprevious works.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jul 2019 23:06:16 GMT"}, {"version": "v2", "created": "Thu, 5 Mar 2020 01:33:45 GMT"}], "update_date": "2020-03-06", "authors_parsed": [["Sieb", "Maximilian", ""], ["Xian", "Zhou", ""], ["Huang", "Audrey", ""], ["Kroemer", "Oliver", ""], ["Fragkiadaki", "Katerina", ""]]}, {"id": "1907.05553", "submitter": "Aras Dargazany", "authors": "Aras R. Dargazany", "title": "MLR (Memory, Learning and Recognition): A General Cognitive Model --\n  applied to Intelligent Robots and Systems Control", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CV cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces a new perspective of intelligent robots and systems\ncontrol. The presented and proposed cognitive model: Memory, Learning and\nRecognition (MLR), is an effort to bridge the gap between Robotics, AI,\nCognitive Science, and Neuroscience. The currently existing gap prevents us\nfrom integrating the current advancement and achievements of these four\nresearch fields which are actively trying to define intelligence in either\napplication-based way or in generic way. This cognitive model defines\nintelligence more specifically, parametrically and detailed. The proposed MLR\nmodel helps us create a general control model for robots and systems\nindependent of their application domains and platforms since it is mainly based\non the dataset provided for robots and systems controls. This paper is mainly\nproposing and introducing this concept and trying to prove this concept in a\nsmall scale, firstly through experimentation. The proposed concept is also\napplicable to other different platforms in real-time as well as in simulation.\n", "versions": [{"version": "v1", "created": "Fri, 12 Jul 2019 02:40:37 GMT"}], "update_date": "2019-07-15", "authors_parsed": [["Dargazany", "Aras R.", ""]]}, {"id": "1907.05575", "submitter": "Sydney Katz", "authors": "Sydney M. Katz, Anne-Claire Le Bihan, Mykel J. Kochenderfer", "title": "Learning an Urban Air Mobility Encounter Model from Expert Preferences", "comments": "8 pages, 7 figures, submitted to 2019 Digital Avionics Systems\n  Conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Airspace models have played an important role in the development and\nevaluation of aircraft collision avoidance systems for both manned and unmanned\naircraft. As Urban Air Mobility (UAM) systems are being developed, we need new\nencounter models that are representative of their operational environment.\nDeveloping such models is challenging due to the lack of data on UAM behavior\nin the airspace. While previous encounter models for other aircraft types rely\non large datasets to produce realistic trajectories, this paper presents an\napproach to encounter modeling that instead relies on expert knowledge. In\nparticular, recent advances in preference-based learning are extended to tune\nan encounter model from expert preferences. The model takes the form of a\nstochastic policy for a Markov decision process (MDP) in which the reward\nfunction is learned from pairwise queries of a domain expert. We evaluate the\nperformance of two querying methods that seek to maximize the information\nobtained from each query. Ultimately, we demonstrate a method for generating\nrealistic encounter trajectories with only a few minutes of an expert's time.\n", "versions": [{"version": "v1", "created": "Fri, 12 Jul 2019 04:44:10 GMT"}], "update_date": "2019-07-15", "authors_parsed": [["Katz", "Sydney M.", ""], ["Bihan", "Anne-Claire Le", ""], ["Kochenderfer", "Mykel J.", ""]]}, {"id": "1907.05634", "submitter": "Yuping Luo", "authors": "Yuping Luo, Huazhe Xu, Tengyu Ma", "title": "Learning Self-Correctable Policies and Value Functions from\n  Demonstrations with Negative Sampling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Imitation learning, followed by reinforcement learning algorithms, is a\npromising paradigm to solve complex control tasks sample-efficiently. However,\nlearning from demonstrations often suffers from the covariate shift problem,\nwhich results in cascading errors of the learned policy. We introduce a notion\nof conservatively-extrapolated value functions, which provably lead to policies\nwith self-correction. We design an algorithm Value Iteration with Negative\nSampling (VINS) that practically learns such value functions with conservative\nextrapolation. We show that VINS can correct mistakes of the behavioral cloning\npolicy on simulated robotics benchmark tasks. We also propose the algorithm of\nusing VINS to initialize a reinforcement learning algorithm, which is shown to\noutperform significantly prior works in sample efficiency.\n", "versions": [{"version": "v1", "created": "Fri, 12 Jul 2019 09:00:49 GMT"}, {"version": "v2", "created": "Thu, 1 Aug 2019 00:43:42 GMT"}, {"version": "v3", "created": "Fri, 11 Oct 2019 05:44:14 GMT"}], "update_date": "2019-10-14", "authors_parsed": [["Luo", "Yuping", ""], ["Xu", "Huazhe", ""], ["Ma", "Tengyu", ""]]}, {"id": "1907.05636", "submitter": "Mark Burgess", "authors": "Mark Burgess", "title": "From Observability to Significance in Distributed Information Systems", "comments": "Some typos fixed", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI cs.DC cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To understand and explain process behaviour we need to be able to see it, and\ndecide its significance, i.e. be able to tell a story about its behaviours.\nThis paper describes a few of the modelling challenges that underlie monitoring\nand observation of processes in IT, by human or by software. The topic of the\nobservability of systems has been elevated recently in connection with computer\nmonitoring and tracing of processes for debugging and forensics. It raises the\nissue of well-known principles of measurement, in bounded contexts, but these\nissues have been left implicit in the Computer Science literature. This paper\naims to remedy this omission, by laying out a simple promise theoretic model,\nsummarizing a long standing trail of work on the observation of distributed\nsystems, based on elementary distinguishability of observations, and classical\ncausality, with history. Three distinct views of a system are sought, across a\nnumber of scales, that described how information is transmitted (and lost) as\nit moves around the system, aggregated into journals and logs.\n", "versions": [{"version": "v1", "created": "Fri, 12 Jul 2019 09:11:59 GMT"}, {"version": "v2", "created": "Thu, 25 Jul 2019 12:46:04 GMT"}], "update_date": "2019-07-26", "authors_parsed": [["Burgess", "Mark", ""]]}, {"id": "1907.05647", "submitter": "Alex Burdusel", "authors": "Alexandru Burdusel, Steffen Zschaler, Stefan John", "title": "Automatic Generation of Atomic Consistency Preserving Search Operators\n  for Search-Based Model Engineering", "comments": "Technical report version of the MODELS 2019 paper with the same title", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.SE", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Recently there has been increased interest in combining the fields of\nModel-Driven Engineering (MDE) and Search-Based Software Engineering (SBSE).\nSuch approaches use meta-heuristic search guided by search operators (model\nmutators and sometimes breeders) implemented as model transformations. The\ndesign of these operators can substantially impact the effectiveness and\nefficiency of the meta-heuristic search. Currently, designing search operators\nis left to the person specifying the optimisation problem. However, developing\nconsistent and efficient search-operator rules requires not only domain\nexpertise but also in-depth knowledge about optimisation, which makes the use\nof model-based meta-heuristic search challenging and expensive. In this paper,\nwe propose a generalised approach to automatically generate atomic consistency\npreserving search operators (aCPSOs) for a given optimisation problem. This\nreduces the effort required to specify an optimisation problem and shields\noptimisation users from the complexity of implementing efficient meta-heuristic\nsearch mutation operators. We evaluate our approach with a set of case studies,\nand show that the automatically generated rules are comparable to, and in some\ncases better than, manually created rules at guiding evolutionary search\ntowards near-optimal solutions. This paper is an extended version of the paper\nwith the same title published in the proceedings of the 22nd International\nConference on Model Driven Engineering Languages and Systems (MODELS '19).\n", "versions": [{"version": "v1", "created": "Fri, 12 Jul 2019 09:51:08 GMT"}], "update_date": "2019-07-15", "authors_parsed": [["Burdusel", "Alexandru", ""], ["Zschaler", "Steffen", ""], ["John", "Stefan", ""]]}, {"id": "1907.05688", "submitter": "Alexantrou Serb", "authors": "A. Serb, I. Kobyzev, J. Wang, T. Prodromakis", "title": "A semi-holographic hyperdimensional representation system for\n  hardware-friendly cognitive computing", "comments": "9 pages, 2 figures, 3 tables Submitted version", "journal-ref": null, "doi": "10.1098/rsta.2019.0162", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the main, long-term objectives of artificial intelligence is the\ncreation of thinking machines. To that end, substantial effort has been placed\ninto designing cognitive systems; i.e. systems that can manipulate\nsemantic-level information. A substantial part of that effort is oriented\ntowards designing the mathematical machinery underlying cognition in a way that\nis very efficiently implementable in hardware. In this work we propose a\n'semi-holographic' representation system that can be implemented in hardware\nusing only multiplexing and addition operations, thus avoiding the need for\nexpensive multiplication. The resulting architecture can be readily constructed\nby recycling standard microprocessor elements and is capable of performing two\nkey mathematical operations frequently used in cognition, superposition and\nbinding, within a budget of below 6 pJ for 64- bit operands. Our proposed\n'cognitive processing unit' (CoPU) is intended as just one (albeit crucial)\npart of much larger cognitive systems where artificial neural networks of all\nkinds and associative memories work in concord to give rise to intelligence.\n", "versions": [{"version": "v1", "created": "Fri, 12 Jul 2019 11:56:29 GMT"}, {"version": "v2", "created": "Mon, 15 Jul 2019 15:51:27 GMT"}], "update_date": "2021-03-17", "authors_parsed": [["Serb", "A.", ""], ["Kobyzev", "I.", ""], ["Wang", "J.", ""], ["Prodromakis", "T.", ""]]}, {"id": "1907.05707", "submitter": "Jianhong Wang", "authors": "Jianhong Wang, Yuan Zhang, Tae-Kyun Kim, Yunjie Gu", "title": "Shapley Q-value: A Local Reward Approach to Solve Global Reward Games", "comments": null, "journal-ref": "AAAI2020", "doi": "10.1609/aaai.v34i05.6220", "report-no": null, "categories": "cs.LG cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cooperative game is a critical research area in the multi-agent reinforcement\nlearning (MARL). Global reward game is a subclass of cooperative games, where\nall agents aim to maximize the global reward. Credit assignment is an important\nproblem studied in the global reward game. Most of previous works stood by the\nview of non-cooperative-game theoretical framework with the shared reward\napproach, i.e., each agent being assigned a shared global reward directly.\nThis, however, may give each agent an inaccurate reward on its contribution to\nthe group, which could cause inefficient learning. To deal with this problem,\nwe i) introduce a cooperative-game theoretical framework called extended convex\ngame (ECG) that is a superset of global reward game, and ii) propose a local\nreward approach called Shapley Q-value. Shapley Q-value is able to distribute\nthe global reward, reflecting each agent's own contribution in contrast to the\nshared reward approach. Moreover, we derive an MARL algorithm called Shapley\nQ-value deep deterministic policy gradient (SQDDPG), using Shapley Q-value as\nthe critic for each agent. We evaluate SQDDPG on Cooperative Navigation,\nPrey-and-Predator and Traffic Junction, compared with the state-of-the-art\nalgorithms, e.g., MADDPG, COMA, Independent DDPG and Independent A2C. In the\nexperiments, SQDDPG shows a significant improvement on the convergence rate.\nFinally, we plot Shapley Q-value and validate the property of fair credit\nassignment.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jul 2019 15:12:33 GMT"}, {"version": "v2", "created": "Mon, 9 Sep 2019 09:25:00 GMT"}, {"version": "v3", "created": "Thu, 21 Nov 2019 21:19:38 GMT"}, {"version": "v4", "created": "Mon, 25 Nov 2019 11:26:06 GMT"}, {"version": "v5", "created": "Tue, 24 Nov 2020 17:03:53 GMT"}], "update_date": "2020-11-25", "authors_parsed": [["Wang", "Jianhong", ""], ["Zhang", "Yuan", ""], ["Kim", "Tae-Kyun", ""], ["Gu", "Yunjie", ""]]}, {"id": "1907.05718", "submitter": "Ziv Katzir", "authors": "Ziv Katzir, Yuval Elovici", "title": "Why Blocking Targeted Adversarial Perturbations Impairs the Ability to\n  Learn", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite their accuracy, neural network-based classifiers are still prone to\nmanipulation through adversarial perturbations. Those perturbations are\ndesigned to be misclassified by the neural network, while being perceptually\nidentical to some valid input. The vast majority of attack methods rely on\nwhite-box conditions, where the attacker has full knowledge of the attacked\nnetwork's parameters. This allows the attacker to calculate the network's loss\ngradient with respect to some valid input and use this gradient in order to\ncreate an adversarial example. The task of blocking white-box attacks has\nproven difficult to solve. While a large number of defense methods have been\nsuggested, they have had limited success. In this work we examine this\ndifficulty and try to understand it. We systematically explore the abilities\nand limitations of defensive distillation, one of the most promising defense\nmechanisms against adversarial perturbations suggested so far in order to\nunderstand the defense challenge. We show that contrary to commonly held\nbelief, the ability to bypass defensive distillation is not dependent on an\nattack's level of sophistication. In fact, simple approaches, such as the\nTargeted Gradient Sign Method, are capable of effectively bypassing defensive\ndistillation. We prove that defensive distillation is highly effective against\nnon-targeted attacks but is unsuitable for targeted attacks. This discovery\nleads us to realize that targeted attacks leverage the same input gradient that\nallows a network to be trained. This implies that blocking them will require\nlosing the network's ability to learn, presenting an impossible tradeoff to the\nresearch community.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jul 2019 06:28:25 GMT"}], "update_date": "2019-07-15", "authors_parsed": [["Katzir", "Ziv", ""], ["Elovici", "Yuval", ""]]}, {"id": "1907.05792", "submitter": "Jatin Ganhotra", "authors": "Jatin Ganhotra, Siva Sankalp Patel, Kshitij Fadnis", "title": "Knowledge-incorporating ESIM models for Response Selection in\n  Retrieval-based Dialog Systems", "comments": "Ranked 2nd on Ubuntu and 4th on Advising task in DSTC-7 Track 1.\n  Accepted for an oral presentation at the DSTC-7 workshop at AAAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Goal-oriented dialog systems, which can be trained end-to-end without\nmanually encoding domain-specific features, show tremendous promise in the\ncustomer support use-case e.g. flight booking, hotel reservation, technical\nsupport, student advising etc. These dialog systems must learn to interact with\nexternal domain knowledge to achieve the desired goal e.g. recommending courses\nto a student, booking a table at a restaurant etc. This paper presents extended\nEnhanced Sequential Inference Model (ESIM) models: a) K-ESIM (Knowledge-ESIM),\nwhich incorporates the external domain knowledge and b) T-ESIM (Targeted-ESIM),\nwhich leverages information from similar conversations to improve the\nprediction accuracy. Our proposed models and the baseline ESIM model are\nevaluated on the Ubuntu and Advising datasets in the Sentence Selection track\nof the latest Dialog System Technology Challenge (DSTC7), where the goal is to\nfind the correct next utterance, given a partial conversation, from a set of\ncandidates. Our preliminary results suggest that incorporating external\nknowledge sources and leveraging information from similar dialogs leads to\nperformance improvements for predicting the next utterance.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jul 2019 15:55:24 GMT"}], "update_date": "2019-07-15", "authors_parsed": [["Ganhotra", "Jatin", ""], ["Patel", "Siva Sankalp", ""], ["Fadnis", "Kshitij", ""]]}, {"id": "1907.05850", "submitter": "Stefano Albrecht", "authors": "Stefano V. Albrecht, Subramanian Ramamoorthy", "title": "Exploiting Causality for Selective Belief Filtering in Dynamic Bayesian\n  Networks (Extended Abstract)", "comments": "Proceedings of the 26th International Joint Conference on Artificial\n  Intelligence (IJCAI), Journal Track, 2017. arXiv admin note: text overlap\n  with arXiv:1401.7941", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dynamic Bayesian networks (DBNs) are a general model for stochastic processes\nwith partially observed states. Belief filtering in DBNs is the task of\ninferring the belief state (i.e. the probability distribution over process\nstates) based on incomplete and uncertain observations. In this article, we\nexplore the idea of accelerating the filtering task by automatically exploiting\ncausality in the process. We consider a specific type of causal relation,\ncalled passivity, which pertains to how state variables cause changes in other\nvariables. We present the Passivity-based Selective Belief Filtering (PSBF)\nmethod, which maintains a factored belief representation and exploits passivity\nto perform selective updates over the belief factors. PSBF is evaluated in both\nsynthetic processes and a simulated multi-robot warehouse, where it\noutperformed alternative filtering methods by exploiting passivity.\n", "versions": [{"version": "v1", "created": "Wed, 10 Jul 2019 08:58:57 GMT"}], "update_date": "2019-07-15", "authors_parsed": [["Albrecht", "Stefano V.", ""], ["Ramamoorthy", "Subramanian", ""]]}, {"id": "1907.05855", "submitter": "Timoth\\'ee Lesort", "authors": "Ren\\'e Traor\\'e, Hugo Caselles-Dupr\\'e, Timoth\\'ee Lesort, Te Sun,\n  Guanghang Cai, Natalia D\\'iaz-Rodr\\'iguez, David Filliat", "title": "DisCoRL: Continual Reinforcement Learning via Policy Distillation", "comments": "arXiv admin note: text overlap with arXiv:1906.04452", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In multi-task reinforcement learning there are two main challenges: at\ntraining time, the ability to learn different policies with a single model; at\ntest time, inferring which of those policies applying without an external\nsignal. In the case of continual reinforcement learning a third challenge\narises: learning tasks sequentially without forgetting the previous ones. In\nthis paper, we tackle these challenges by proposing DisCoRL, an approach\ncombining state representation learning and policy distillation. We experiment\non a sequence of three simulated 2D navigation tasks with a 3 wheel\nomni-directional robot. Moreover, we tested our approach's robustness by\ntransferring the final policy into a real life setting. The policy can solve\nall tasks and automatically infer which one to run.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jul 2019 09:12:42 GMT"}], "update_date": "2019-07-15", "authors_parsed": [["Traor\u00e9", "Ren\u00e9", ""], ["Caselles-Dupr\u00e9", "Hugo", ""], ["Lesort", "Timoth\u00e9e", ""], ["Sun", "Te", ""], ["Cai", "Guanghang", ""], ["D\u00edaz-Rodr\u00edguez", "Natalia", ""], ["Filliat", "David", ""]]}, {"id": "1907.05861", "submitter": "Thomy Phan", "authors": "Thomy Phan, Thomas Gabor, Robert M\\\"uller, Christoph Roch, Claudia\n  Linnhoff-Popien", "title": "Adaptive Thompson Sampling Stacks for Memory Bounded Open-Loop Planning", "comments": "Accepted at IJCAI 2019. arXiv admin note: substantial text overlap\n  with arXiv:1905.04020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose Stable Yet Memory Bounded Open-Loop (SYMBOL) planning, a general\nmemory bounded approach to partially observable open-loop planning. SYMBOL\nmaintains an adaptive stack of Thompson Sampling bandits, whose size is bounded\nby the planning horizon and can be automatically adapted according to the\nunderlying domain without any prior domain knowledge beyond a generative model.\nWe empirically test SYMBOL in four large POMDP benchmark problems to\ndemonstrate its effectiveness and robustness w.r.t. the choice of\nhyperparameters and evaluate its adaptive memory consumption. We also compare\nits performance with other open-loop planning algorithms and POMCP.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jul 2019 09:42:47 GMT"}], "update_date": "2019-07-15", "authors_parsed": [["Phan", "Thomy", ""], ["Gabor", "Thomas", ""], ["M\u00fcller", "Robert", ""], ["Roch", "Christoph", ""], ["Linnhoff-Popien", "Claudia", ""]]}, {"id": "1907.05878", "submitter": "Adithya Murali", "authors": "Adithya Murali and P. Madhusudan", "title": "Augmenting Neural Nets with Symbolic Synthesis: Applications to Few-Shot\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose symbolic learning as extensions to standard inductive learning\nmodels such as neural nets as a means to solve few shot learning problems. We\ndevice a class of visual discrimination puzzles that calls for recognizing\nobjects and object relationships as well learning higher-level concepts from\nvery few images. We propose a two-phase learning framework that combines models\nlearned from large data sets using neural nets and symbolic first-order logic\nformulas learned from a few shot learning instance. We develop first-order\nlogic synthesis techniques for discriminating images by using symbolic search\nand logic constraint solvers. By augmenting neural nets with them, we develop\nand evaluate a tool that can solve few shot visual discrimination puzzles with\ninterpretable concepts.\n", "versions": [{"version": "v1", "created": "Fri, 12 Jul 2019 17:50:31 GMT"}], "update_date": "2019-07-15", "authors_parsed": [["Murali", "Adithya", ""], ["Madhusudan", "P.", ""]]}, {"id": "1907.05885", "submitter": "Joberto Martins Prof. Dr.", "authors": "Flavio G. Calhau and Joberto S. B. Martins", "title": "A Electric Network Reconfiguration Strategy with Case-Based Reasoning\n  for the Smart Grid", "comments": "6 pages", "journal-ref": null, "doi": "10.5281/zenodo.3277282", "report-no": null, "categories": "cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The complexity, heterogeneity and scale of electrical networks have grown far\nbeyond the limits of exclusively human-based management at the Smart Grid (SG).\nLikewise, researchers cogitate the use of artificial intelligence and\nheuristics techniques to create cognitive and autonomic management tools that\naim better assist and enhance SG management processes like in the grid\nreconfiguration. The development of self-healing management approaches towards\na cognitive and autonomic distribution power network reconfiguration is a\nscenario in which the scalability and on-the-fly computation are issues. This\npaper proposes the use of Case-Based Reasoning (CBR) coupled with the HATSGA\nalgorithm for the fast reconfiguration of large distribution power networks.\nThe suitability and the scalability of the CBR-based reconfiguration strategy\nusing HATSGA algorithm are evaluated. The evaluation indicates that the adopted\nHATSGA algorithm computes new reconfiguration topologies with a feasible\ncomputational time for large networks. The CBR strategy looks for managerial\nacceptable reconfiguration solutions at the CBR database and, as such,\ncontributes to reduce the required number of reconfiguration computation using\nHATSGA. This suggests CBR can be applied with a fast reconfiguration algorithm\nresulting in more efficient, dynamic and cognitive grid recovery strategy.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jul 2019 23:42:55 GMT"}], "update_date": "2019-07-16", "authors_parsed": [["Calhau", "Flavio G.", ""], ["Martins", "Joberto S. B.", ""]]}, {"id": "1907.05912", "submitter": "Aaron Ferber", "authors": "Aaron Ferber, Bryan Wilder, Bistra Dilkina, Milind Tambe", "title": "MIPaaL: Mixed Integer Program as a Layer", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning components commonly appear in larger decision-making\npipelines; however, the model training process typically focuses only on a loss\nthat measures accuracy between predicted values and ground truth values.\nDecision-focused learning explicitly integrates the downstream decision problem\nwhen training the predictive model, in order to optimize the quality of\ndecisions induced by the predictions. It has been successfully applied to\nseveral limited combinatorial problem classes, such as those that can be\nexpressed as linear programs (LP), and submodular optimization. However, these\nprevious applications have uniformly focused on problems from specific classes\nwith simple constraints. Here, we enable decision-focused learning for the\nbroad class of problems that can be encoded as a Mixed Integer Linear Program\n(MIP), hence supporting arbitrary linear constraints over discrete and\ncontinuous variables. We show how to differentiate through a MIP by employing a\ncutting planes solution approach, which is an exact algorithm that iteratively\nadds constraints to a continuous relaxation of the problem until an integral\nsolution is found. We evaluate our new end-to-end approach on several real\nworld domains and show that it outperforms the standard two phase approaches\nthat treat prediction and prescription separately, as well as a baseline\napproach of simply applying decision-focused learning to the LP relaxation of\nthe MIP.\n", "versions": [{"version": "v1", "created": "Fri, 12 Jul 2019 18:22:09 GMT"}, {"version": "v2", "created": "Wed, 17 Jul 2019 18:48:17 GMT"}], "update_date": "2019-07-19", "authors_parsed": [["Ferber", "Aaron", ""], ["Wilder", "Bryan", ""], ["Dilkina", "Bistra", ""], ["Tambe", "Milind", ""]]}, {"id": "1907.06005", "submitter": "Xiang Zhang", "authors": "Yu Gu, Xiang Zhang, Zhi Liu and Fuji Ren", "title": "BeSense: Leveraging WiFi Channel Data and Computational Intelligence for\n  Behavior Analysis", "comments": "11 pages accepted by IEEE Computational Intelligence Magazine", "journal-ref": null, "doi": "10.1109/MCI.2019.2937610", "report-no": null, "categories": "cs.HC cs.AI eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ever evolving informatics technology has gradually bounded human and\ncomputer in a compact way. Understanding user behavior becomes a key enabler in\nmany fields such as sedentary-related healthcare, human-computer interaction\n(HCI) and affective computing. Traditional sensor-based and vision-based user\nbehavior analysis approaches are obtrusive in general, hindering their usage in\nrealworld. Therefore, in this article, we first introduce WiFi signal as a new\nsource instead of sensor and vision for unobtrusive user behaviors analysis.\nThen we design BeSense, a contactless behavior analysis system leveraging\nsignal processing and computational intelligence over WiFi channel state\ninformation (CSI). We prototype BeSense on commodity low-cost WiFi devices and\nevaluate its performance in realworld environments. Experimental results have\nverified its effectiveness in recognizing user behaviors.\n", "versions": [{"version": "v1", "created": "Sat, 13 Jul 2019 03:31:14 GMT"}, {"version": "v2", "created": "Mon, 23 Mar 2020 10:48:13 GMT"}], "update_date": "2020-05-25", "authors_parsed": [["Gu", "Yu", ""], ["Zhang", "Xiang", ""], ["Liu", "Zhi", ""], ["Ren", "Fuji", ""]]}, {"id": "1907.06013", "submitter": "Ahmed Qureshi", "authors": "Ahmed H. Qureshi, Yinglong Miao, Anthony Simeonov and Michael C. Yip", "title": "Motion Planning Networks: Bridging the Gap Between Learning-based and\n  Classical Motion Planners", "comments": "Supplementary material including implementation parameters and\n  project videos are available at https://sites.google.com/view/mpnet/home.\n  This work has been accepted for publication at IEEE Transactions on Robotics", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes Motion Planning Networks (MPNet), a computationally\nefficient, learning-based neural planner for solving motion planning problems.\nMPNet uses neural networks to learn general near-optimal heuristics for path\nplanning in seen and unseen environments. It takes environment information such\nas raw point-cloud from depth sensors, as well as a robot's initial and desired\ngoal configurations and recursively calls itself to bidirectionally generate\nconnectable paths. In addition to finding directly connectable and near-optimal\npaths in a single pass, we show that worst-case theoretical guarantees can be\nproven if we merge this neural network strategy with classical sample-based\nplanners in a hybrid approach while still retaining significant computational\nand optimality improvements. To train the MPNet models, we present an active\ncontinual learning approach that enables MPNet to learn from streaming data and\nactively ask for expert demonstrations when needed, drastically reducing data\nfor training. We validate MPNet against gold-standard and state-of-the-art\nplanning methods in a variety of problems from 2D to 7D robot configuration\nspaces in challenging and cluttered environments, with results showing\nsignificant and consistently stronger performance metrics, and motivating\nneural planning in general as a modern strategy for solving motion planning\nproblems efficiently.\n", "versions": [{"version": "v1", "created": "Sat, 13 Jul 2019 05:34:01 GMT"}, {"version": "v2", "created": "Mon, 30 Dec 2019 21:38:01 GMT"}, {"version": "v3", "created": "Sat, 27 Jun 2020 19:14:00 GMT"}], "update_date": "2020-06-30", "authors_parsed": [["Qureshi", "Ahmed H.", ""], ["Miao", "Yinglong", ""], ["Simeonov", "Anthony", ""], ["Yip", "Michael C.", ""]]}, {"id": "1907.06090", "submitter": "Jesse Clifton", "authors": "Jesse Clifton, Lili Wu, Eric Laber", "title": "Parameterized Exploration", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce Parameterized Exploration (PE), a simple family of methods for\nmodel-based tuning of the exploration schedule in sequential decision problems.\nUnlike common heuristics for exploration, our method accounts for the time\nhorizon of the decision problem as well as the agent's current state of\nknowledge of the dynamics of the decision problem. We show our method as\napplied to several common exploration techniques has superior performance\nrelative to un-tuned counterparts in Bernoulli and Gaussian multi-armed\nbandits, contextual bandits, and a Markov decision process based on a mobile\nhealth (mHealth) study. We also examine the effects of the accuracy of the\nestimated dynamics model on the performance of PE.\n", "versions": [{"version": "v1", "created": "Sat, 13 Jul 2019 14:55:11 GMT"}], "update_date": "2019-07-16", "authors_parsed": [["Clifton", "Jesse", ""], ["Wu", "Lili", ""], ["Laber", "Eric", ""]]}, {"id": "1907.06096", "submitter": "Navya Singh", "authors": "Ms. Navya Singh, Mr. Anshul Dhull, Mr. Barath Mohan.S, Mr. Bhavish\n  Pahwa, Ms. Komal Sharma", "title": "Automated Gaming Pommerman: FFA", "comments": "5 pages , 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Our game Pommerman is based on the console game Bommerman. The game starts on\nan 11 by 11 platform. Pommerman is a multi-agent environment and is made up of\na set of different situations and contains four agents.\n", "versions": [{"version": "v1", "created": "Sat, 13 Jul 2019 15:20:19 GMT"}], "update_date": "2019-07-16", "authors_parsed": [["Singh", "Ms. Navya", ""], ["Dhull", "Mr. Anshul", ""], ["S", "Mr. Barath Mohan.", ""], ["Pahwa", "Mr. Bhavish", ""], ["Sharma", "Ms. Komal", ""]]}, {"id": "1907.06182", "submitter": "Takeshi D. Itoh", "authors": "Takeshi D. Itoh, Takatomi Kubo, Kiyoka Ikeda, Yuki Maruno, Yoshiharu\n  Ikutani, Hideaki Hata, Kenichi Matsumoto, Kazushi Ikeda", "title": "Towards Generation of Visual Attention Map for Source Code", "comments": "4 pages, 2 figures; APSIPA 2019 ACCEPTED", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Program comprehension is a dominant process in software development and\nmaintenance. Experts are considered to comprehend the source code efficiently\nby directing their gaze, or attention, to important components in it. However,\nreflecting the importance of components is still a remaining issue in gaze\nbehavior analysis for source code comprehension. Here we show a conceptual\nframework to compare the quantified importance of source code components with\nthe gaze behavior of programmers. We use \"attention\" in attention models (e.g.,\ncode2vec) as the importance indices for source code components and evaluate\nprogrammers' gaze locations based on the quantified importance. In this report,\nwe introduce the idea of our gaze behavior analysis using the attention map,\nand the results of a preliminary experiment.\n", "versions": [{"version": "v1", "created": "Sun, 14 Jul 2019 07:54:18 GMT"}, {"version": "v2", "created": "Tue, 13 Aug 2019 04:00:40 GMT"}], "update_date": "2019-08-14", "authors_parsed": [["Itoh", "Takeshi D.", ""], ["Kubo", "Takatomi", ""], ["Ikeda", "Kiyoka", ""], ["Maruno", "Yuki", ""], ["Ikutani", "Yoshiharu", ""], ["Hata", "Hideaki", ""], ["Matsumoto", "Kenichi", ""], ["Ikeda", "Kazushi", ""]]}, {"id": "1907.06226", "submitter": "Jipeng Qiang", "authors": "Jipeng Qiang and Yun Li and Yi Zhu and Yunhao Yuan and Xindong Wu", "title": "Lexical Simplification with Pretrained Encoders", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Lexical simplification (LS) aims to replace complex words in a given sentence\nwith their simpler alternatives of equivalent meaning. Recently unsupervised\nlexical simplification approaches only rely on the complex word itself\nregardless of the given sentence to generate candidate substitutions, which\nwill inevitably produce a large number of spurious candidates. We present a\nsimple LS approach that makes use of the Bidirectional Encoder Representations\nfrom Transformers (BERT) which can consider both the given sentence and the\ncomplex word during generating candidate substitutions for the complex word.\nSpecifically, we mask the complex word of the original sentence for feeding\ninto the BERT to predict the masked token. The predicted results will be used\nas candidate substitutions. Despite being entirely unsupervised, experimental\nresults show that our approach obtains obvious improvement compared with these\nbaselines leveraging linguistic databases and parallel corpus, outperforming\nthe state-of-the-art by more than 12 Accuracy points on three well-known\nbenchmarks.\n", "versions": [{"version": "v1", "created": "Sun, 14 Jul 2019 14:19:22 GMT"}, {"version": "v2", "created": "Tue, 16 Jul 2019 14:36:41 GMT"}, {"version": "v3", "created": "Tue, 30 Jul 2019 03:36:12 GMT"}, {"version": "v4", "created": "Fri, 16 Aug 2019 01:48:46 GMT"}, {"version": "v5", "created": "Thu, 29 Oct 2020 03:21:25 GMT"}], "update_date": "2020-10-30", "authors_parsed": [["Qiang", "Jipeng", ""], ["Li", "Yun", ""], ["Zhu", "Yi", ""], ["Yuan", "Yunhao", ""], ["Wu", "Xindong", ""]]}, {"id": "1907.06249", "submitter": "Feras Saad", "authors": "Feras A. Saad, Marco F. Cusumano-Towner, Ulrich Schaechtle, Martin C.\n  Rinard, Vikash K. Mansinghka", "title": "Bayesian Synthesis of Probabilistic Programs for Automatic Data Modeling", "comments": null, "journal-ref": "Proc. ACM Program. Lang. 3, POPL, Article 37 (January 2019)", "doi": "10.1145/3290350", "report-no": null, "categories": "cs.PL cs.AI cs.LG stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present new techniques for automatically constructing probabilistic\nprograms for data analysis, interpretation, and prediction. These techniques\nwork with probabilistic domain-specific data modeling languages that capture\nkey properties of a broad class of data generating processes, using Bayesian\ninference to synthesize probabilistic programs in these modeling languages\ngiven observed data. We provide a precise formulation of Bayesian synthesis for\nautomatic data modeling that identifies sufficient conditions for the resulting\nsynthesis procedure to be sound. We also derive a general class of synthesis\nalgorithms for domain-specific languages specified by probabilistic\ncontext-free grammars and establish the soundness of our approach for these\nlanguages. We apply the techniques to automatically synthesize probabilistic\nprograms for time series data and multivariate tabular data. We show how to\nanalyze the structure of the synthesized programs to compute, for key\nqualitative properties of interest, the probability that the underlying data\ngenerating process exhibits each of these properties. Second, we translate\nprobabilistic programs in the domain-specific language into probabilistic\nprograms in Venture, a general-purpose probabilistic programming system. The\ntranslated Venture programs are then executed to obtain predictions of new time\nseries data and new multivariate data records. Experimental results show that\nour techniques can accurately infer qualitative structure in multiple\nreal-world data sets and outperform standard data analysis methods in\nforecasting and predicting new data.\n", "versions": [{"version": "v1", "created": "Sun, 14 Jul 2019 17:12:55 GMT"}], "update_date": "2019-07-16", "authors_parsed": [["Saad", "Feras A.", ""], ["Cusumano-Towner", "Marco F.", ""], ["Schaechtle", "Ulrich", ""], ["Rinard", "Martin C.", ""], ["Mansinghka", "Vikash K.", ""]]}, {"id": "1907.06279", "submitter": "Seyedeh Zahra Razavi", "authors": "S. Zahra Razavi, Lenhart K. Schubert, Kimberly A. Van Orden, and\n  Mohammad Rafayet Ali", "title": "Discourse Behavior of Older Adults Interacting With a Dialogue Agent\n  Competent in Multiple Topics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present some results concerning the dialogue behavior and inferred\nsentiment of a group of older adults interacting with a computer-based avatar.\nOur avatar is unique in its ability to hold natural dialogues on a wide range\nof everyday topics---27 topics in three groups, developed with the help of\ngerontologists. The three groups vary in ``degrees of intimacy\", and as such in\ndegrees of difficulty for the user. Each participant interacted with the avatar\nfor 7-9 sessions over a period of 3-4 weeks; analysis of the dialogues reveals\ncorrelations such as greater verbosity for more difficult topics, increasing\nverbosity with successive sessions, especially for more difficult topics,\nstronger sentiment on topics concerned with life goals rather than routine\nactivities, and stronger self-disclosure for more intimate topics. In addition\nto their intrinsic interest, these results also reflect positively on the\nsophistication of our dialogue system.\n", "versions": [{"version": "v1", "created": "Sun, 14 Jul 2019 20:41:46 GMT"}], "update_date": "2019-07-16", "authors_parsed": [["Razavi", "S. Zahra", ""], ["Schubert", "Lenhart K.", ""], ["Van Orden", "Kimberly A.", ""], ["Ali", "Mohammad Rafayet", ""]]}, {"id": "1907.06290", "submitter": "Harsh Gupta", "authors": "Harsh Gupta, R. Srikant and Lei Ying", "title": "Finite-Time Performance Bounds and Adaptive Learning Rate Selection for\n  Two Time-Scale Reinforcement Learning", "comments": "17 pages, 3 figures, preprint", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study two time-scale linear stochastic approximation algorithms, which can\nbe used to model well-known reinforcement learning algorithms such as GTD,\nGTD2, and TDC. We present finite-time performance bounds for the case where the\nlearning rate is fixed. The key idea in obtaining these bounds is to use a\nLyapunov function motivated by singular perturbation theory for linear\ndifferential equations. We use the bound to design an adaptive learning rate\nscheme which significantly improves the convergence rate over the known optimal\npolynomial decay rule in our experiments, and can be used to potentially\nimprove the performance of any other schedule where the learning rate is\nchanged at pre-determined time instants.\n", "versions": [{"version": "v1", "created": "Sun, 14 Jul 2019 22:20:46 GMT"}], "update_date": "2019-07-16", "authors_parsed": [["Gupta", "Harsh", ""], ["Srikant", "R.", ""], ["Ying", "Lei", ""]]}, {"id": "1907.06314", "submitter": "Sandro Sozzo", "authors": "Sandro Sozzo", "title": "Representing Attitudes Towards Ambiguity in Hilbert Space: Foundations\n  and Applications", "comments": "23 pages, standard LaTeX, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI q-bio.NC quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide here a general mathematical framework to model attitudes towards\nambiguity which uses the formalism of quantum theory as a ``purely mathematical\nformalism, detached from any physical interpretation''. We show that the\nquantum-theoretic framework enables modelling of the \"Ellsberg paradox\", but it\nalso successfully applies to more concrete human decision-making (DM) tests\ninvolving financial, managerial and medical decisions. In particular, we\nelaborate a mathematical representation of various empirical studies which\nreveal that attitudes of managers towards uncertainty shift from \"ambiguity\nseeking\" to \"ambiguity aversion\", and viceversa, thus exhibiting \"hope effects\"\nand \"fear effects\". The present framework provides a promising direction\ntowards the development of a unified theory of decisions in the presence of\nuncertainty.\n", "versions": [{"version": "v1", "created": "Wed, 10 Jul 2019 11:32:38 GMT"}, {"version": "v2", "created": "Sun, 22 Mar 2020 11:36:18 GMT"}, {"version": "v3", "created": "Sat, 20 Jun 2020 13:31:01 GMT"}], "update_date": "2020-06-23", "authors_parsed": [["Sozzo", "Sandro", ""]]}, {"id": "1907.06386", "submitter": "Claudio Di Ciccio", "authors": "Anton Yeshchenko and Claudio Di Ciccio and Jan Mendling and Artem\n  Polyvyanyy", "title": "Comprehensive Process Drift Detection with Visual Analytics", "comments": "Accepted for publication at the 38th International Conference on\n  Conceptual Modeling (ER 2019), http://www.inf.ufrgs.br/er2019/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent research has introduced ideas from concept drift into process mining\nto enable the analysis of changes in business processes over time. This stream\nof research, however, has not yet addressed the challenges of drift\ncategorization, drilling-down, and quantification. In this paper, we propose a\nnovel technique for managing process drifts, called Visual Drift Detection\n(VDD), which fulfills these requirements. The technique starts by clustering\ndeclarative process constraints discovered from recorded logs of executed\nbusiness processes based on their similarity and then applies change point\ndetection on the identified clusters to detect drifts. VDD complements these\nfeatures with detailed visualizations and explanations of drifts. Our\nevaluation, both on synthetic and real-world logs, demonstrates all the\naforementioned capabilities of the technique.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jul 2019 09:24:45 GMT"}], "update_date": "2019-07-16", "authors_parsed": [["Yeshchenko", "Anton", ""], ["Di Ciccio", "Claudio", ""], ["Mendling", "Jan", ""], ["Polyvyanyy", "Artem", ""]]}, {"id": "1907.06432", "submitter": "Mehdi Ben Lazreg", "authors": "Mehdi Ben Lazreg, Morten Goodwin, Ole-Christoffer Granmo", "title": "A Neural Turing~Machine for Conditional Transition Graph Modeling", "comments": "Submitted to IEEE Transactions on Neural Networks and Learning\n  Systems", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graphs are an essential part of many machine learning problems such as\nanalysis of parse trees, social networks, knowledge graphs, transportation\nsystems, and molecular structures. Applying machine learning in these areas\ntypically involves learning the graph structure and the relationship between\nthe nodes of the graph. However, learning the graph structure is often complex,\nparticularly when the graph is cyclic, and the transitions from one node to\nanother are conditioned such as graphs used to represent a finite state\nmachine. To solve this problem, we propose to extend the memory based Neural\nTuring Machine (NTM) with two novel additions. We allow for transitions between\nnodes to be influenced by information received from external environments, and\nwe let the NTM learn the context of those transitions. We refer to this\nextension as the Conditional Neural Turing Machine (CNTM).\n  We show that the CNTM can infer conditional transition graphs by empirically\nverifiying the model on two data sets: a large set of randomly generated\ngraphs, and a graph modeling the information retrieval process during certain\ncrisis situations. The results show that the CNTM is able to reproduce the\npaths inside the graph with accuracy ranging from 82,12% for 10 nodes graphs to\n65,25% for 100 nodes graphs.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jul 2019 11:14:17 GMT"}], "update_date": "2019-07-16", "authors_parsed": [["Lazreg", "Mehdi Ben", ""], ["Goodwin", "Morten", ""], ["Granmo", "Ole-Christoffer", ""]]}, {"id": "1907.06479", "submitter": "Zhenyu Zhang", "authors": "Zhenyu Zhang, Xiangfeng Luo, Tong Liu, Shaorong Xie, Jianshu Wang, Wei\n  Wang, Yang Li and Yan Peng", "title": "Proximal Policy Optimization with Mixed Distributed Training", "comments": "ICTAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Instability and slowness are two main problems in deep reinforcement\nlearning. Even if proximal policy optimization (PPO) is the state of the art,\nit still suffers from these two problems. We introduce an improved algorithm\nbased on proximal policy optimization, mixed distributed proximal policy\noptimization (MDPPO), and show that it can accelerate and stabilize the\ntraining process. In our algorithm, multiple different policies train\nsimultaneously and each of them controls several identical agents that interact\nwith environments. Actions are sampled by each policy separately as usual, but\nthe trajectories for the training process are collected from all agents,\ninstead of only one policy. We find that if we choose some auxiliary\ntrajectories elaborately to train policies, the algorithm will be more stable\nand quicker to converge especially in the environments with sparse rewards.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jul 2019 12:56:38 GMT"}, {"version": "v2", "created": "Sun, 8 Sep 2019 01:06:28 GMT"}, {"version": "v3", "created": "Mon, 30 Sep 2019 07:45:09 GMT"}], "update_date": "2019-10-01", "authors_parsed": [["Zhang", "Zhenyu", ""], ["Luo", "Xiangfeng", ""], ["Liu", "Tong", ""], ["Xie", "Shaorong", ""], ["Wang", "Jianshu", ""], ["Wang", "Wei", ""], ["Li", "Yang", ""], ["Peng", "Yan", ""]]}, {"id": "1907.06508", "submitter": "Wolfgang Konen K", "authors": "Wolfgang Konen", "title": "General Board Game Playing for Education and Research in Generic AI Game\n  Learning", "comments": "8 pages, for: Conference on Games (CoG), London, 2019. Index Terms:\n  game learning, general game playing, AI, temporal difference learning, board\n  games, n-tuple systems", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new general board game (GBG) playing and learning framework. GBG\ndefines the common interfaces for board games, game states and their AI agents.\nIt allows one to run competitions of different agents on different games. It\nstandardizes those parts of board game playing and learning that otherwise\nwould be tedious and repetitive parts in coding. GBG is suitable for arbitrary\n1-, 2-, ..., N-player board games. It makes a generic TD($\\lambda$)-n-tuple\nagent for the first time available to arbitrary games. On various games,\nTD($\\lambda$)-n-tuple is found to be superior to other generic agents like\nMCTS. GBG aims at the educational perspective, where it helps students to start\nfaster in the area of game learning. GBG aims as well at the research\nperspective by collecting a growing set of games and AI agents to assess their\nstrengths and generalization capabilities in meaningful competitions. Initial\nsuccessful educational and research results are reported.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jul 2019 13:02:25 GMT"}], "update_date": "2019-07-16", "authors_parsed": [["Konen", "Wolfgang", ""]]}, {"id": "1907.06511", "submitter": "Xingyou Song", "authors": "Xingyou Song, Krzysztof Choromanski, Jack Parker-Holder, Yunhao Tang,\n  Wenbo Gao, Aldo Pacchiano, Tamas Sarlos, Deepali Jain, Yuxiang Yang", "title": "Reinforcement Learning with Chromatic Networks for Compact Architecture\n  Search", "comments": "Published at ICLR 2020 Neural Architecture Search Workshop. This\n  paper is deprecated; please see arXiv:2101.07415 for the newer version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a neural architecture search algorithm to construct compact\nreinforcement learning (RL) policies, by combining ENAS and ES in a highly\nscalable and intuitive way. By defining the combinatorial search space of NAS\nto be the set of different edge-partitionings (colorings) into same-weight\nclasses, we represent compact architectures via efficient learned\nedge-partitionings. For several RL tasks, we manage to learn colorings\ntranslating to effective policies parameterized by as few as $17$ weight\nparameters, providing >90% compression over vanilla policies and 6x compression\nover state-of-the-art compact policies based on Toeplitz matrices, while still\nmaintaining good reward. We believe that our work is one of the first attempts\nto propose a rigorous approach to training structured neural network\narchitectures for RL problems that are of interest especially in mobile\nrobotics with limited storage and computational resources.\n", "versions": [{"version": "v1", "created": "Wed, 10 Jul 2019 16:57:50 GMT"}, {"version": "v2", "created": "Wed, 25 Sep 2019 16:04:11 GMT"}, {"version": "v3", "created": "Mon, 2 Mar 2020 22:37:04 GMT"}, {"version": "v4", "created": "Tue, 6 Apr 2021 17:00:42 GMT"}], "update_date": "2021-04-07", "authors_parsed": [["Song", "Xingyou", ""], ["Choromanski", "Krzysztof", ""], ["Parker-Holder", "Jack", ""], ["Tang", "Yunhao", ""], ["Gao", "Wenbo", ""], ["Pacchiano", "Aldo", ""], ["Sarlos", "Tamas", ""], ["Jain", "Deepali", ""], ["Yang", "Yuxiang", ""]]}, {"id": "1907.06554", "submitter": "Mohammad Aliannejadi", "authors": "Mohammad Aliannejadi and Hamed Zamani and Fabio Crestani and W. Bruce\n  Croft", "title": "Asking Clarifying Questions in Open-Domain Information-Seeking\n  Conversations", "comments": "To appear in SIGIR 2019", "journal-ref": null, "doi": "10.1145/3331184.3331265", "report-no": null, "categories": "cs.CL cs.AI cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Users often fail to formulate their complex information needs in a single\nquery. As a consequence, they may need to scan multiple result pages or\nreformulate their queries, which may be a frustrating experience.\nAlternatively, systems can improve user satisfaction by proactively asking\nquestions of the users to clarify their information needs. Asking clarifying\nquestions is especially important in conversational systems since they can only\nreturn a limited number of (often only one) result(s). In this paper, we\nformulate the task of asking clarifying questions in open-domain\ninformation-seeking conversational systems. To this end, we propose an offline\nevaluation methodology for the task and collect a dataset, called Qulac,\nthrough crowdsourcing. Our dataset is built on top of the TREC Web Track\n2009-2012 data and consists of over 10K question-answer pairs for 198 TREC\ntopics with 762 facets. Our experiments on an oracle model demonstrate that\nasking only one good question leads to over 170% retrieval performance\nimprovement in terms of P@1, which clearly demonstrates the potential impact of\nthe task. We further propose a retrieval framework consisting of three\ncomponents: question retrieval, question selection, and document retrieval. In\nparticular, our question selection model takes into account the original query\nand previous question-answer interactions while selecting the next question.\nOur model significantly outperforms competitive baselines. To foster research\nin this area, we have made Qulac publicly available.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jul 2019 15:45:37 GMT"}], "update_date": "2019-07-16", "authors_parsed": [["Aliannejadi", "Mohammad", ""], ["Zamani", "Hamed", ""], ["Crestani", "Fabio", ""], ["Croft", "W. Bruce", ""]]}, {"id": "1907.06562", "submitter": "Fernando de Mesentier Silva", "authors": "Amy K. Hoover, Julian Togelius, Scott Lee and Fernando de Mesentier\n  Silva", "title": "The Many AI Challenges of Hearthstone", "comments": "12 pages. Journal paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Games have benchmarked AI methods since the inception of the field, with\nclassic board games such as Chess and Go recently leaving room for video games\nwith related yet different sets of challenges. The set of AI problems\nassociated with video games has in recent decades expanded from simply playing\ngames to win, to playing games in particular styles, generating game content,\nmodeling players etc. Different games pose very different challenges for AI\nsystems, and several different AI challenges can typically be posed by the same\ngame. In this article we analyze the popular collectible card game Hearthstone\n(Blizzard 2014) and describe a varied set of interesting AI challenges posed by\nthis game. Collectible card games are relatively understudied in the AI\ncommunity, despite their popularity and the interesting challenges they pose.\nAnalyzing a single game in-depth in the manner we do here allows us to see the\nentire field of AI and Games through the lens of a single game, discovering a\nfew new variations on existing research topics.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jul 2019 16:06:41 GMT"}], "update_date": "2019-07-16", "authors_parsed": [["Hoover", "Amy K.", ""], ["Togelius", "Julian", ""], ["Lee", "Scott", ""], ["Silva", "Fernando de Mesentier", ""]]}, {"id": "1907.06570", "submitter": "Fernando de Mesentier Silva", "authors": "Luvneesh Mugrai, Fernando de Mesentier Silva, Christoffer Holmg{\\aa}rd\n  and Julian Togelius", "title": "Automated Playtesting of Matching Tile Games", "comments": "7 pages. IEEE Conference On Games (COG) 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Matching tile games are an extremely popular game genre. Arguably the most\npopular iteration, Match-3 games, are simple to understand puzzle games, making\nthem great benchmarks for research. In this paper, we propose developing\ndifferent procedural personas for Match-3 games in order to approximate\ndifferent human playstyles to create an automated playtesting system. The\nprocedural personas are realized through evolving the utility function for the\nMonte Carlo Tree Search agent. We compare the performance and results of the\nevolution agents with the standard Vanilla Monte Carlo Tree Search\nimplementation as well as to a random move-selection agent. We then observe the\nimpacts on both the game's design and the game design process. Lastly, a user\nstudy is performed to compare the agents to human play traces.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jul 2019 16:24:43 GMT"}], "update_date": "2019-07-16", "authors_parsed": [["Mugrai", "Luvneesh", ""], ["Silva", "Fernando de Mesentier", ""], ["Holmg\u00e5rd", "Christoffer", ""], ["Togelius", "Julian", ""]]}, {"id": "1907.06572", "submitter": "Xiao Dong", "authors": "X. Dong and L. Zhou", "title": "Deep network as memory space: complexity, generalization, disentangled\n  representation and interpretability", "comments": "11 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  By bridging deep networks and physics, the programme of geometrization of\ndeep networks was proposed as a framework for the interpretability of deep\nlearning systems. Following this programme we can apply two key ideas of\nphysics, the geometrization of physics and the least action principle, on deep\nnetworks and deliver a new picture of deep networks: deep networks as memory\nspace of information, where the capacity, robustness and efficiency of the\nmemory are closely related with the complexity, generalization and\ndisentanglement of deep networks. The key components of this understanding\ninclude:(1) a Fisher metric based formulation of the network complexity; (2)the\nleast action (complexity=action) principle on deep networks and (3)the geometry\nbuilt on deep network configurations. We will show how this picture will bring\nus a new understanding of the interpretability of deep learning systems.\n", "versions": [{"version": "v1", "created": "Fri, 12 Jul 2019 12:55:59 GMT"}], "update_date": "2019-07-16", "authors_parsed": [["Dong", "X.", ""], ["Zhou", "L.", ""]]}, {"id": "1907.06584", "submitter": "Yang Yu", "authors": "Wenjie Shang, Yang Yu, Qingyang Li, Zhiwei Qin, Yiping Meng, Jieping\n  Ye", "title": "Environment Reconstruction with Hidden Confounders for Reinforcement\n  Learning based Recommendation", "comments": "Appears in KDD 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning aims at searching the best policy model for decision\nmaking, and has been shown powerful for sequential recommendations. The\ntraining of the policy by reinforcement learning, however, is placed in an\nenvironment. In many real-world applications, however, the policy training in\nthe real environment can cause an unbearable cost, due to the exploration in\nthe environment. Environment reconstruction from the past data is thus an\nappealing way to release the power of reinforcement learning in these\napplications. The reconstruction of the environment is, basically, to extract\nthe casual effect model from the data. However, real-world applications are\noften too complex to offer fully observable environment information. Therefore,\nquite possibly there are unobserved confounding variables lying behind the\ndata. The hidden confounder can obstruct an effective reconstruction of the\nenvironment. In this paper, by treating the hidden confounder as a hidden\npolicy, we propose a deconfounded multi-agent environment reconstruction\n(DEMER) approach in order to learn the environment together with the hidden\nconfounder. DEMER adopts a multi-agent generative adversarial imitation\nlearning framework. It proposes to introduce the confounder embedded policy,\nand use the compatible discriminator for training the policies. We then apply\nDEMER in an application of driver program recommendation. We firstly use an\nartificial driver program recommendation environment, abstracted from the real\napplication, to verify and analyze the effectiveness of DEMER. We then test\nDEMER in the real application of Didi Chuxing. Experiment results show that\nDEMER can effectively reconstruct the hidden confounder, and thus can build the\nenvironment better. DEMER also derives a recommendation policy with a\nsignificantly improved performance in the test phase of the real application.\n", "versions": [{"version": "v1", "created": "Fri, 12 Jul 2019 10:13:05 GMT"}], "update_date": "2019-07-16", "authors_parsed": [["Shang", "Wenjie", ""], ["Yu", "Yang", ""], ["Li", "Qingyang", ""], ["Qin", "Zhiwei", ""], ["Meng", "Yiping", ""], ["Ye", "Jieping", ""]]}, {"id": "1907.06704", "submitter": "Joe Booth", "authors": "Joe Booth", "title": "PPO Dash: Improving Generalization in Deep Reinforcement Learning", "comments": "8 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep reinforcement learning is prone to overfitting, and traditional\nbenchmarks such as Atari 2600 benchmark can exacerbate this problem. The\nObstacle Tower Challenge addresses this by using randomized environments and\nseparate seeds for training, validation, and test runs. This paper examines\nvarious improvements and best practices to the PPO algorithm using the Obstacle\nTower Challenge to empirically study their impact with regards to\ngeneralization. Our experiments show that the combination provides\nstate-of-the-art performance on the Obstacle Tower Challenge.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jul 2019 19:15:17 GMT"}, {"version": "v2", "created": "Wed, 17 Jul 2019 07:17:42 GMT"}, {"version": "v3", "created": "Thu, 25 Jul 2019 22:50:02 GMT"}], "update_date": "2019-07-29", "authors_parsed": [["Booth", "Joe", ""]]}, {"id": "1907.06773", "submitter": "Giovanni Sileno", "authors": "Giovanni Sileno", "title": "Logic Conditionals, Supervenience, and Selection Tasks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.SC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Principles of cognitive economy would require that concepts about objects,\nproperties and relations should be introduced only if they simplify the\nconceptualisation of a domain. Unexpectedly, classic logic conditionals,\nspecifying structures holding within elements of a formal conceptualisation, do\nnot always satisfy this crucial principle. The paper argues that this\nrequirement is captured by supervenience, hereby further identified as a\nproperty necessary for compression. The resulting theory suggests an\nalternative explanation of the empirical experiences observable in Wason's\nselection tasks, associating human performance with conditionals on the ability\nof dealing with compression, rather than with logic necessity.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jul 2019 22:16:00 GMT"}, {"version": "v2", "created": "Sun, 11 Aug 2019 13:17:01 GMT"}], "update_date": "2019-08-13", "authors_parsed": [["Sileno", "Giovanni", ""]]}, {"id": "1907.06831", "submitter": "Fan Yang", "authors": "Fan Yang, Mengnan Du, Xia Hu", "title": "Evaluating Explanation Without Ground Truth in Interpretable Machine\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.HC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Interpretable Machine Learning (IML) has become increasingly important in\nmany real-world applications, such as autonomous cars and medical diagnosis,\nwhere explanations are significantly preferred to help people better understand\nhow machine learning systems work and further enhance their trust towards\nsystems. However, due to the diversified scenarios and subjective nature of\nexplanations, we rarely have the ground truth for benchmark evaluation in IML\non the quality of generated explanations. Having a sense of explanation quality\nnot only matters for assessing system boundaries, but also helps to realize the\ntrue benefits to human users in practical settings. To benchmark the evaluation\nin IML, in this article, we rigorously define the problem of evaluating\nexplanations, and systematically review the existing efforts from\nstate-of-the-arts. Specifically, we summarize three general aspects of\nexplanation (i.e., generalizability, fidelity and persuasibility) with formal\ndefinitions, and respectively review the representative methodologies for each\nof them under different tasks. Further, a unified evaluation framework is\ndesigned according to the hierarchical needs from developers and end-users,\nwhich could be easily adopted for different scenarios in practice. In the end,\nopen problems are discussed, and several limitations of current evaluation\ntechniques are raised for future explorations.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jul 2019 04:25:39 GMT"}, {"version": "v2", "created": "Thu, 15 Aug 2019 21:13:50 GMT"}], "update_date": "2019-08-19", "authors_parsed": [["Yang", "Fan", ""], ["Du", "Mengnan", ""], ["Hu", "Xia", ""]]}, {"id": "1907.06838", "submitter": "Tianqi Wang", "authors": "Tianqi Wang, Dong Eui Chang", "title": "Improved Reinforcement Learning through Imitation Learning Pretraining\n  Towards Image-based Autonomous Driving", "comments": "5 pages, 2019 19th International Conference on Control, Automation\n  and Systems (ICCAS 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a training pipeline for the autonomous driving task given the\ncurrent camera image and vehicle speed as the input to produce the throttle,\nbrake, and steering control output. The simulator Airsim's convenient weather\nand lighting API provides a sufficient diversity during training which can be\nvery helpful to increase the trained policy's robustness. In order to not limit\nthe possible policy's performance, we use a continuous and deterministic\ncontrol policy setting. We utilize ResNet-34 as our actor and critic networks\nwith some slight changes in the fully connected layers. Considering human's\nmastery of this task and the high-complexity nature of this task, we first use\nimitation learning to mimic the given human policy and leverage the trained\npolicy and its weights to the reinforcement learning phase for which we use\nDDPG. This combination shows a considerable performance boost comparing to both\npure imitation learning and pure DDPG for the autonomous driving task.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jul 2019 04:48:52 GMT"}], "update_date": "2019-07-17", "authors_parsed": [["Wang", "Tianqi", ""], ["Chang", "Dong Eui", ""]]}, {"id": "1907.06995", "submitter": "Stefano Albrecht", "authors": "Stefano V. Albrecht, Subramanian Ramamoorthy", "title": "On Convergence and Optimality of Best-Response Learning with Policy\n  Types in Multiagent Systems", "comments": "Proceedings of the 30th Conference on Uncertainty in Artificial\n  Intelligence (UAI), 2014. arXiv admin note: substantial text overlap with\n  arXiv:1507.07688", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While many multiagent algorithms are designed for homogeneous systems (i.e.\nall agents are identical), there are important applications which require an\nagent to coordinate its actions without knowing a priori how the other agents\nbehave. One method to make this problem feasible is to assume that the other\nagents draw their latent policy (or type) from a specific set, and that a\ndomain expert could provide a specification of this set, albeit only a\npartially correct one. Algorithms have been proposed by several researchers to\ncompute posterior beliefs over such policy libraries, which can then be used to\ndetermine optimal actions. In this paper, we provide theoretical guidance on\ntwo central design parameters of this method: Firstly, it is important that the\nuser choose a posterior which can learn the true distribution of latent types,\nas otherwise suboptimal actions may be chosen. We analyse convergence\nproperties of two existing posterior formulations and propose a new posterior\nwhich can learn correlated distributions. Secondly, since the types are\nprovided by an expert, they may be inaccurate in the sense that they do not\npredict the agents' observed actions. We provide a novel characterisation of\noptimality which allows experts to use efficient model checking algorithms to\nverify optimality of types.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jul 2019 09:30:27 GMT"}], "update_date": "2019-07-17", "authors_parsed": [["Albrecht", "Stefano V.", ""], ["Ramamoorthy", "Subramanian", ""]]}, {"id": "1907.07019", "submitter": "Evan Piermont", "authors": "Evan Piermont", "title": "Unforeseen Evidence", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "econ.TH cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  I propose a normative updating rule, extended Bayesianism, for the\nincorporation of probabilistic information arising from the process of becoming\nmore aware. Extended Bayesianism generalizes standard Bayesian updating to\nallow the posterior to reside on richer probability space than the prior. I\nthen provide an observable criterion on prior and posterior beliefs such that\nthey were consistent with extended Bayesianism.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jul 2019 14:10:59 GMT"}, {"version": "v2", "created": "Wed, 17 Jul 2019 13:23:39 GMT"}, {"version": "v3", "created": "Fri, 8 Jan 2021 20:00:35 GMT"}], "update_date": "2021-01-12", "authors_parsed": [["Piermont", "Evan", ""]]}, {"id": "1907.07029", "submitter": "Rituraj Kaushik", "authors": "Rituraj Kaushik, Pierre Desreumaux, Jean-Baptiste Mouret", "title": "Adaptive Prior Selection for Repertoire-based Online Adaptation in\n  Robotics", "comments": "Frontiers in Robotics and AI. Vol. 6, p. 151, 2020. Video :\n  http://tiny.cc/aprol_video", "journal-ref": "Frontiers in Robotics and AI. 6 (2020) 151", "doi": "10.3389/frobt.2019.00151", "report-no": null, "categories": "cs.RO cs.AI cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Repertoire-based learning is a data-efficient adaptation approach based on a\ntwo-step process in which (1) a large and diverse set of policies is learned in\nsimulation, and (2) a planning or learning algorithm chooses the most\nappropriate policies according to the current situation (e.g., a damaged robot,\na new object, etc.). In this paper, we relax the assumption of previous works\nthat a single repertoire is enough for adaptation. Instead, we generate\nrepertoires for many different situations (e.g., with a missing leg, on\ndifferent floors, etc.) and let our algorithm selects the most useful prior.\nOur main contribution is an algorithm, APROL (Adaptive Prior selection for\nRepertoire-based Online Learning) to plan the next action by incorporating\nthese priors when the robot has no information about the current situation. We\nevaluate APROL on two simulated tasks: (1) pushing unknown objects of various\nshapes and sizes with a robotic arm and (2) a goal reaching task with a damaged\nhexapod robot. We compare with \"Reset-free Trial and Error\" (RTE) and various\nsingle repertoire-based baselines. The results show that APROL solves both the\ntasks in less interaction time than the baselines. Additionally, we demonstrate\nAPROL on a real, damaged hexapod that quickly learns to pick compensatory\npolicies to reach a goal by avoiding obstacles in the path.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jul 2019 14:26:13 GMT"}, {"version": "v2", "created": "Thu, 24 Oct 2019 11:13:57 GMT"}, {"version": "v3", "created": "Tue, 3 Mar 2020 22:25:25 GMT"}], "update_date": "2020-03-05", "authors_parsed": [["Kaushik", "Rituraj", ""], ["Desreumaux", "Pierre", ""], ["Mouret", "Jean-Baptiste", ""]]}, {"id": "1907.07178", "submitter": "Juliana Ferreira J", "authors": "Rafael Brand\\~ao, Joel Carbonera, Clarisse de Souza, Juliana Ferreira,\n  Bernardo Gon\\c{c}alves, Carla Leit\\~ao", "title": "Mediation Challenges and Socio-Technical Gaps for Explainable Deep\n  Learning Applications", "comments": "39 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The presumed data owners' right to explanations brought about by the General\nData Protection Regulation in Europe has shed light on the social challenges of\nexplainable artificial intelligence (XAI). In this paper, we present a case\nstudy with Deep Learning (DL) experts from a research and development\nlaboratory focused on the delivery of industrial-strength AI technologies. Our\naim was to investigate the social meaning (i.e. meaning to others) that DL\nexperts assign to what they do, given a richly contextualized and familiar\ndomain of application. Using qualitative research techniques to collect and\nanalyze empirical data, our study has shown that participating DL experts did\nnot spontaneously engage into considerations about the social meaning of\nmachine learning models that they build. Moreover, when explicitly stimulated\nto do so, these experts expressed expectations that, with real-world DL\napplication, there will be available mediators to bridge the gap between\ntechnical meanings that drive DL work, and social meanings that AI technology\nusers assign to it. We concluded that current research incentives and values\nguiding the participants' scientific interests and conduct are at odds with\nthose required to face some of the scientific challenges involved in advancing\nXAI, and thus responding to the alleged data owners' right to explanations or\nsimilar societal demands emerging from current debates. As a concrete\ncontribution to mitigate what seems to be a more general problem, we propose\nthree preliminary XAI Mediation Challenges with the potential to bring together\ntechnical and social meanings of DL applications, as well as to foster much\nneeded interdisciplinary collaboration among AI and the Social Sciences\nresearchers.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jul 2019 17:59:34 GMT"}], "update_date": "2019-07-17", "authors_parsed": [["Brand\u00e3o", "Rafael", ""], ["Carbonera", "Joel", ""], ["de Souza", "Clarisse", ""], ["Ferreira", "Juliana", ""], ["Gon\u00e7alves", "Bernardo", ""], ["Leit\u00e3o", "Carla", ""]]}, {"id": "1907.07223", "submitter": "Vasileios Iosifidis", "authors": "Vasileios Iosifidis, Thi Ngoc Han Tran, Eirini Ntoutsi", "title": "Fairness-enhancing interventions in stream classification", "comments": "15 pages, 7 figures. To appear in the proceedings of 30th\n  International Conference on Database and Expert Systems Applications, Linz,\n  Austria August 26 - 29, 2019", "journal-ref": null, "doi": "10.1007/978-3-030-27615-7_20", "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The wide spread usage of automated data-driven decision support systems has\nraised a lot of concerns regarding accountability and fairness of the employed\nmodels in the absence of human supervision. Existing fairness-aware approaches\ntackle fairness as a batch learning problem and aim at learning a fair model\nwhich can then be applied to future instances of the problem. In many\napplications, however, the data comes sequentially and its characteristics\nmight evolve with time. In such a setting, it is counter-intuitive to \"fix\" a\n(fair) model over the data stream as changes in the data might incur changes in\nthe underlying model therefore, affecting its fairness. In this work, we\npropose fairness-enhancing interventions that modify the input data so that the\noutcome of any stream classifier applied to that data will be fair. Experiments\non real and synthetic data show that our approach achieves good predictive\nperformance and low discrimination scores over the course of the stream.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jul 2019 19:27:19 GMT"}], "update_date": "2020-01-24", "authors_parsed": [["Iosifidis", "Vasileios", ""], ["Tran", "Thi Ngoc Han", ""], ["Ntoutsi", "Eirini", ""]]}, {"id": "1907.07237", "submitter": "Wenbin Zhang", "authors": "Wenbin Zhang and Eirini Ntoutsi", "title": "FAHT: An Adaptive Fairness-aware Decision Tree Classifier", "comments": "Accepted to IJCAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automated data-driven decision-making systems are ubiquitous across a wide\nspread of online as well as offline services. These systems, depend on\nsophisticated learning algorithms and available data, to optimize the service\nfunction for decision support assistance. However, there is a growing concern\nabout the accountability and fairness of the employed models by the fact that\noften the available historic data is intrinsically discriminatory, i.e., the\nproportion of members sharing one or more sensitive attributes is higher than\nthe proportion in the population as a whole when receiving positive\nclassification, which leads to a lack of fairness in decision support system. A\nnumber of fairness-aware learning methods have been proposed to handle this\nconcern. However, these methods tackle fairness as a static problem and do not\ntake the evolution of the underlying stream population into consideration. In\nthis paper, we introduce a learning mechanism to design a fair classifier for\nonline stream based decision-making. Our learning model, FAHT (Fairness-Aware\nHoeffding Tree), is an extension of the well-known Hoeffding Tree algorithm for\ndecision tree induction over streams, that also accounts for fairness. Our\nexperiments show that our algorithm is able to deal with discrimination in\nstreaming environments, while maintaining a moderate predictive performance\nover the stream.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jul 2019 20:00:41 GMT"}], "update_date": "2019-07-18", "authors_parsed": [["Zhang", "Wenbin", ""], ["Ntoutsi", "Eirini", ""]]}, {"id": "1907.07247", "submitter": "Justin Harris", "authors": "Justin D. Harris, Bo Waggoner", "title": "Decentralized & Collaborative AI on Blockchain", "comments": "Accepted to 2019 IEEE International Conference on Blockchain", "journal-ref": null, "doi": "10.1109/Blockchain.2019.00057", "report-no": null, "categories": "cs.CR cs.AI cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning has recently enabled large advances in artificial\nintelligence, but these tend to be highly centralized. The large datasets\nrequired are generally proprietary; predictions are often sold on a per-query\nbasis; and published models can quickly become out of date without effort to\nacquire more data and re-train them. We propose a framework for participants to\ncollaboratively build a dataset and use smart contracts to host a continuously\nupdated model. This model will be shared publicly on a blockchain where it can\nbe free to use for inference. Ideal learning problems include scenarios where a\nmodel is used many times for similar input such as personal assistants, playing\ngames, recommender systems, etc. In order to maintain the model's accuracy with\nrespect to some test set we propose both financial and non-financial (gamified)\nincentive structures for providing good data. A free and open source\nimplementation for the Ethereum blockchain is provided at\nhttps://github.com/microsoft/0xDeCA10B.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jul 2019 20:19:32 GMT"}], "update_date": "2019-07-18", "authors_parsed": [["Harris", "Justin D.", ""], ["Waggoner", "Bo", ""]]}, {"id": "1907.07273", "submitter": "Zikang Xiong", "authors": "He Zhu, Zikang Xiong, Stephen Magill, Suresh Jagannathan", "title": "An Inductive Synthesis Framework for Verifiable Reinforcement Learning", "comments": "Published on PLDI 2019", "journal-ref": null, "doi": "10.1145/3314221.3314638", "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the tremendous advances that have been made in the last decade on\ndeveloping useful machine-learning applications, their wider adoption has been\nhindered by the lack of strong assurance guarantees that can be made about\ntheir behavior. In this paper, we consider how formal verification techniques\ndeveloped for traditional software systems can be repurposed for verification\nof reinforcement learning-enabled ones, a particularly important class of\nmachine learning systems. Rather than enforcing safety by examining and\naltering the structure of a complex neural network implementation, our\ntechnique uses blackbox methods to synthesizes deterministic programs, simpler,\nmore interpretable, approximations of the network that can nonetheless\nguarantee desired safety properties are preserved, even when the network is\ndeployed in unanticipated or previously unobserved environments. Our\nmethodology frames the problem of neural network verification in terms of a\ncounterexample and syntax-guided inductive synthesis procedure over these\nprograms. The synthesis procedure searches for both a deterministic program and\nan inductive invariant over an infinite state transition system that represents\na specification of an application's control logic. Additional specifications\ndefining environment-based constraints can also be provided to further refine\nthe search space. Synthesized programs deployed in conjunction with a neural\nnetwork implementation dynamically enforce safety conditions by monitoring and\npreventing potentially unsafe actions proposed by neural policies. Experimental\nresults over a wide range of cyber-physical applications demonstrate that\nsoftware-inspired formal verification techniques can be used to realize\ntrustworthy reinforcement learning systems with low overhead.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jul 2019 21:57:17 GMT"}], "update_date": "2019-07-18", "authors_parsed": [["Zhu", "He", ""], ["Xiong", "Zikang", ""], ["Magill", "Stephen", ""], ["Jagannathan", "Suresh", ""]]}, {"id": "1907.07374", "submitter": "Erico Tjoa", "authors": "Erico Tjoa, Cuntai Guan", "title": "A Survey on Explainable Artificial Intelligence (XAI): Towards Medical\n  XAI", "comments": null, "journal-ref": null, "doi": "10.1109/TNNLS.2020.3027314", "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, artificial intelligence and machine learning in general have\ndemonstrated remarkable performances in many tasks, from image processing to\nnatural language processing, especially with the advent of deep learning. Along\nwith research progress, they have encroached upon many different fields and\ndisciplines. Some of them require high level of accountability and thus\ntransparency, for example the medical sector. Explanations for machine\ndecisions and predictions are thus needed to justify their reliability. This\nrequires greater interpretability, which often means we need to understand the\nmechanism underlying the algorithms. Unfortunately, the blackbox nature of the\ndeep learning is still unresolved, and many machine decisions are still poorly\nunderstood. We provide a review on interpretabilities suggested by different\nresearch works and categorize them. The different categories show different\ndimensions in interpretability research, from approaches that provide\n\"obviously\" interpretable information to the studies of complex patterns. By\napplying the same categorization to interpretability in medical research, it is\nhoped that (1) clinicians and practitioners can subsequently approach these\nmethods with caution, (2) insights into interpretability will be born with more\nconsiderations for medical practices, and (3) initiatives to push forward\ndata-based, mathematically- and technically-grounded medical education are\nencouraged.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jul 2019 08:00:37 GMT"}, {"version": "v2", "created": "Wed, 31 Jul 2019 02:43:20 GMT"}, {"version": "v3", "created": "Tue, 15 Oct 2019 16:08:53 GMT"}, {"version": "v4", "created": "Sun, 7 Jun 2020 12:58:21 GMT"}, {"version": "v5", "created": "Tue, 11 Aug 2020 02:28:13 GMT"}], "update_date": "2020-10-23", "authors_parsed": [["Tjoa", "Erico", ""], ["Guan", "Cuntai", ""]]}, {"id": "1907.07378", "submitter": "C. Maria Keet", "authors": "C. Maria Keet, Zola Mahlaza, Mary-Jane Antia", "title": "CLaRO: a Data-driven CNL for Specifying Competency Questions", "comments": "24 pages, 3 figures, extended technical report of a shorter paper\n  submitted to an international conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Competency Questions (CQs) for an ontology and similar artefacts aim to\nprovide insights into the contents of an ontology and to demarcate its scope.\nThe absence of a controlled natural language, tooling and automation to support\nthe authoring of CQs has hampered their effective use in ontology development\nand evaluation. The few question templates that exists are based on informal\nanalyses of a small number of CQs and have limited coverage of question types\nand sentence constructions. We aim to fill this gap by proposing a\ntemplate-based CNL to author CQs, called CLaRO. For its design, we exploited a\nnew dataset of 234 CQs that had been processed automatically into 106 patterns,\nwhich we analysed and used to design a template-based CNL, with an additional\nCNL model and XML serialisation. The CNL was evaluated with a subset of\nquestions from the original dataset and with two sets of newly sourced CQs. The\ncoverage of CLaRO, with its 93 main templates and 41 linguistic variants, is\nabout 90% for unseen questions. CLaRO has the potential to facilitate\nstreamlining formalising ontology content requirements and, given that about\none third of the competency questions in the test sets turned out to be invalid\nquestions, assist in writing good questions.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jul 2019 08:18:36 GMT"}], "update_date": "2019-07-18", "authors_parsed": [["Keet", "C. Maria", ""], ["Mahlaza", "Zola", ""], ["Antia", "Mary-Jane", ""]]}, {"id": "1907.07410", "submitter": "P B Mr", "authors": "Prasad Bhavana, Vikas Kumar, Vineet Padmanabhan", "title": "Block based Singular Value Decomposition approach to matrix\n  factorization for recommender systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the abundance of data in recent years, interesting challenges are posed\nin the area of recommender systems. Producing high quality recommendations with\nscalability and performance is the need of the hour. Singular Value\nDecomposition(SVD) based recommendation algorithms have been leveraged to\nproduce better results. In this paper, we extend the SVD technique further for\nscalability and performance in the context of 1) multi-threading 2) multiple\ncomputational units (with the use of Graphical Processing Units) and 3)\ndistributed computation. We propose block based matrix factorization (BMF)\npaired with SVD. This enabled us to take advantage of SVD over basic matrix\nfactorization(MF) while taking advantage of parallelism and scalability through\nBMF. We used Compute Unified Device Architecture (CUDA) platform and related\nhardware for leveraging Graphical Processing Unit (GPU) along with block based\nSVD to demonstrate the advantages in terms of performance and memory.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jul 2019 09:35:56 GMT"}], "update_date": "2019-07-19", "authors_parsed": [["Bhavana", "Prasad", ""], ["Kumar", "Vikas", ""], ["Padmanabhan", "Vineet", ""]]}, {"id": "1907.07493", "submitter": "Carl M\\\"orch", "authors": "Carl-Maria M\\\"orch, Abhishek Gupta, Brian L. Mishara", "title": "Canada Protocol: an ethical checklist for the use of Artificial\n  Intelligence in Suicide Prevention and Mental Health", "comments": "Submitted to CRISIS (The Journal of Crisis Intervention and Suicide\n  Prevention), Hogrefe", "journal-ref": null, "doi": "10.1016/j.artmed.2020.101934", "report-no": null, "categories": "cs.CY cs.AI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Introduction: To improve current public health strategies in suicide\nprevention and mental health, governments, researchers and private companies\nincreasingly use information and communication technologies, and more\nspecifically Artificial Intelligence and Big Data. These technologies are\npromising but raise ethical challenges rarely covered by current legal systems.\nIt is essential to better identify, and prevent potential ethical risks.\nObjectives: The Canada Protocol - MHSP is a tool to guide and support\nprofessionals, users, and researchers using AI in mental health and suicide\nprevention. Methods: A checklist was constructed based upon ten international\nreports on AI and ethics and two guides on mental health and new technologies.\n329 recommendations were identified, of which 43 were considered as applicable\nto Mental Health and AI. The checklist was validated, using a two round Delphi\nConsultation. Results: 16 experts participated in the first round of the Delphi\nConsultation and 8 participated in the second round. Of the original 43 items,\n38 were retained. They concern five categories: \"Description of the Autonomous\nIntelligent System\" (n=8), \"Privacy and Transparency\" (n=8), \"Security\" (n=6),\n\"Health-Related Risks\" (n=8), \"Biases\" (n=8). The checklist was considered\nrelevant by most users, and could need versions tailored to each category of\ntarget users.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jul 2019 13:14:13 GMT"}], "update_date": "2021-07-23", "authors_parsed": [["M\u00f6rch", "Carl-Maria", ""], ["Gupta", "Abhishek", ""], ["Mishara", "Brian L.", ""]]}, {"id": "1907.07500", "submitter": "Miroslav Bogdanovic", "authors": "Miroslav Bogdanovic, Majid Khadiv, Ludovic Righetti", "title": "Learning Variable Impedance Control for Contact Sensitive Tasks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning algorithms have shown great success in solving\ndifferent problems ranging from playing video games to robotics. However, they\nstruggle to solve delicate robotic problems, especially those involving contact\ninteractions. Though in principle a policy directly outputting joint torques\nshould be able to learn to perform these tasks, in practice we see that it has\ndifficulty to robustly solve the problem without any given structure in the\naction space. In this paper, we investigate how the choice of action space can\ngive robust performance in presence of contact uncertainties. We propose\nlearning a policy giving as output impedance and desired position in joint\nspace and compare the performance of that approach to torque and position\ncontrol under different contact uncertainties. Furthermore, we propose an\nadditional reward term designed to regularize these variable impedance control\npolicies, giving them interpretability and facilitating their transfer to real\nsystems. We present extensive experiments in simulation of both floating and\nfixed-base systems in tasks involving contact uncertainties, as well as results\nfor running the learned policies on a real system.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jul 2019 13:20:15 GMT"}, {"version": "v2", "created": "Tue, 14 Jul 2020 16:03:07 GMT"}], "update_date": "2020-07-15", "authors_parsed": [["Bogdanovic", "Miroslav", ""], ["Khadiv", "Majid", ""], ["Righetti", "Ludovic", ""]]}, {"id": "1907.07631", "submitter": "Pavel Surynek", "authors": "Pavel Surynek", "title": "On the Tour Towards DPLL(MAPF) and Beyond", "comments": "arXiv admin note: substantial text overlap with arXiv:1809.05959", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We discuss milestones on the tour towards DPLL(MAPF), a multi-agent path\nfinding (MAPF) solver fully integrated with the Davis-Putnam-Logemann-Loveland\n(DPLL) propositional satisfiability testing algorithm through satisfiability\nmodulo theories (SMT). The task in MAPF is to navigate agents in an undirected\ngraph in a non-colliding way so that each agent eventually reaches its unique\ngoal vertex. At most one agent can reside in a vertex at a time. Agents can\nmove instantaneously by traversing edges provided the movement does not result\nin a collision. Recently attempts to solve MAPF optimally w.r.t. the\nsum-of-costs or the makespan based on the reduction of MAPF to propositional\nsatisfiability (SAT) have appeared. The most successful methods rely on\nbuilding the propositional encoding for the given MAPF instance lazily by a\nprocess inspired in the SMT paradigm. The integration of satisfiability testing\nby the SAT solver and the high-level construction of the encoding is however\nrelatively loose in existing methods. Therefore the ultimate goal of research\nin this direction is to build the DPLL(MAPF) algorithm, a MAPF solver where the\nconstruction of the encoding is fully integrated with the underlying SAT\nsolver. We discuss the current state-of-the-art in MAPF solving and what steps\nneed to be done to get DPLL(MAPF). The advantages of DPLL(MAPF) in terms of its\npotential to be alternatively parametrized with MAPF$^R$, a theory of\ncontinuous MAPF with geometric agents, are also discussed.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jul 2019 23:50:09 GMT"}], "update_date": "2019-07-18", "authors_parsed": [["Surynek", "Pavel", ""]]}, {"id": "1907.07638", "submitter": "Jatin Ganhotra", "authors": "Janarthanan Rajendran, Jatin Ganhotra, Lazaros Polymenakos", "title": "Learning End-to-End Goal-Oriented Dialog with Maximal User Task Success\n  and Minimal Human Agent Use", "comments": "Author final version of article accepted for publication in TACL -\n  https://www.mitpressjournals.org/doi/full/10.1162/tacl_a_00274 and oral\n  presentation at ACL 2019", "journal-ref": "Transactions of the Association for Computational Linguistics 2019\n  Vol. 7, 375-386", "doi": "10.1162/tacl_a_00274", "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Neural end-to-end goal-oriented dialog systems showed promise to reduce the\nworkload of human agents for customer service, as well as reduce wait time for\nusers. However, their inability to handle new user behavior at deployment has\nlimited their usage in real world. In this work, we propose an end-to-end\ntrainable method for neural goal-oriented dialog systems which handles new user\nbehaviors at deployment by transferring the dialog to a human agent\nintelligently. The proposed method has three goals: 1) maximize user's task\nsuccess by transferring to human agents, 2) minimize the load on the human\nagents by transferring to them only when it is essential and 3) learn online\nfrom the human agent's responses to reduce human agents load further. We\nevaluate our proposed method on a modified-bAbI dialog task that simulates the\nscenario of new user behaviors occurring at test time. Experimental results\nshow that our proposed method is effective in achieving the desired goals.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jul 2019 16:50:16 GMT"}], "update_date": "2019-07-18", "authors_parsed": [["Rajendran", "Janarthanan", ""], ["Ganhotra", "Jatin", ""], ["Polymenakos", "Lazaros", ""]]}, {"id": "1907.07778", "submitter": "Eisa Alanazi", "authors": "Abdulaziz Alashaikh, Eisa Alanazi and Ala Al-Fuqaha", "title": "A Survey on the Use of Preferences for Virtual Machine Placement in\n  Cloud Data Centers", "comments": "40 pages, 5 figures, 6 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.AI cs.NI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  With the rapid development of virtualization techniques, cloud data centers\nallow for cost effective, flexible, and customizable deployments of\napplications on virtualized infrastructure. Virtual machine (VM) placement aims\nto assign each virtual machine to a server in the cloud environment. VM\nPlacement is of paramount importance to the design of cloud data centers.\nTypically, VM placement involves complex relations and multiple design factors\nas well as local policies that govern the assignment decisions. It also\ninvolves different constituents including cloud administrators and customers\nthat might have disparate preferences while opting for a placement solution.\nThus, it is often valuable to not only return an optimized solution to the VM\nplacement problem but also a solution that reflects the given preferences of\nthe constituents. In this paper, we provide a detailed review on the role of\npreferences in the recent literature on VM placement. We further discuss key\nchallenges and identify possible research opportunities to better incorporate\npreferences within the context of VM placement.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jul 2019 21:22:27 GMT"}, {"version": "v2", "created": "Sat, 20 Jul 2019 11:23:33 GMT"}, {"version": "v3", "created": "Thu, 16 Jan 2020 23:11:29 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Alashaikh", "Abdulaziz", ""], ["Alanazi", "Eisa", ""], ["Al-Fuqaha", "Ala", ""]]}, {"id": "1907.07835", "submitter": "Peixiang Zhong", "authors": "Peixiang Zhong, Di Wang, and Chunyan Miao", "title": "EEG-Based Emotion Recognition Using Regularized Graph Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Electroencephalography (EEG) measures the neuronal activities in different\nbrain regions via electrodes. Many existing studies on EEG-based emotion\nrecognition do not fully exploit the topology of EEG channels. In this paper,\nwe propose a regularized graph neural network (RGNN) for EEG-based emotion\nrecognition. RGNN considers the biological topology among different brain\nregions to capture both local and global relations among different EEG\nchannels. Specifically, we model the inter-channel relations in EEG signals via\nan adjacency matrix in a graph neural network where the connection and\nsparseness of the adjacency matrix are inspired by neuroscience theories of\nhuman brain organization. In addition, we propose two regularizers, namely\nnode-wise domain adversarial training (NodeDAT) and emotion-aware distribution\nlearning (EmotionDL), to better handle cross-subject EEG variations and noisy\nlabels, respectively. Extensive experiments on two public datasets, SEED and\nSEED-IV, demonstrate the superior performance of our model than\nstate-of-the-art models in most experimental settings. Moreover, ablation\nstudies show that the proposed adjacency matrix and two regularizers contribute\nconsistent and significant gain to the performance of our RGNN model. Finally,\ninvestigations on the neuronal activities reveal important brain regions and\ninter-channel relations for EEG-based emotion recognition.\n", "versions": [{"version": "v1", "created": "Thu, 18 Jul 2019 01:44:44 GMT"}, {"version": "v2", "created": "Mon, 26 Aug 2019 10:57:39 GMT"}, {"version": "v3", "created": "Sun, 12 Apr 2020 07:02:59 GMT"}, {"version": "v4", "created": "Wed, 13 May 2020 03:19:26 GMT"}], "update_date": "2020-05-14", "authors_parsed": [["Zhong", "Peixiang", ""], ["Wang", "Di", ""], ["Miao", "Chunyan", ""]]}, {"id": "1907.07958", "submitter": "H\\'el\\`ene Plisnier", "authors": "H\\'el\\`ene Plisnier, Denis Steckelmacher, Diederik Roijers, Ann Now\\'e", "title": "Transfer Learning Across Simulated Robots With Different Sensors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For a robot to learn a good policy, it often requires expensive equipment\n(such as sophisticated sensors) and a prepared training environment conducive\nto learning. However, it is seldom possible to perfectly equip robots for\neconomic reasons, nor to guarantee ideal learning conditions, when deployed in\nreal-life environments. A solution would be to prepare the robot in the lab\nenvironment, when all necessary material is available to learn a good policy.\nAfter training in the lab, the robot should be able to get by without the\nexpensive equipment that used to be available to it, and yet still be\nguaranteed to perform well on the field. The transition between the lab\n(source) and the real-world environment (target) is related to transfer\nlearning, where the state-space between the source and target tasks differ. We\ntackle a simulated task with continuous states and discrete actions presenting\nthis challenge, using Bootstrapped Dual Policy Iteration, a model-free\nactor-critic reinforcement learning algorithm, and Policy Shaping.\nSpecifically, we train a BDPI agent, embodied by a virtual robot performing a\ntask in the V-Rep simulator, sensing its environment through several proximity\nsensors. The resulting policy is then used by a second agent learning the same\ntask in the same environment, but with camera images as input. The goal is to\nobtain a policy able to perform the task relying on merely camera images.\n", "versions": [{"version": "v1", "created": "Thu, 18 Jul 2019 09:58:27 GMT"}], "update_date": "2019-07-19", "authors_parsed": [["Plisnier", "H\u00e9l\u00e8ne", ""], ["Steckelmacher", "Denis", ""], ["Roijers", "Diederik", ""], ["Now\u00e9", "Ann", ""]]}, {"id": "1907.08015", "submitter": "Zhongyang Li", "authors": "Xiao Ding, Zhongyang Li, Ting Liu and Kuo Liao", "title": "ELG: An Event Logic Graph", "comments": "arXiv admin note: text overlap with arXiv:1805.05081", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The evolution and development of events have their own basic principles,\nwhich make events happen sequentially. Therefore, the discovery of such\nevolutionary patterns among events are of great value for event prediction,\ndecision-making and scenario design of dialog systems. However, conventional\nknowledge graph mainly focuses on the entities and their relations, which\nneglects the real world events. In this paper, we present a novel type of\nknowledge base - Event Logic Graph (ELG), which can reveal evolutionary\npatterns and development logics of real world events. Specifically, ELG is a\ndirected cyclic graph, whose nodes are events, and edges stand for the\nsequential, causal, conditional or hypernym-hyponym (is-a) relations between\nevents. We constructed two domain ELG: financial domain ELG, which consists of\nmore than 1.5 million of event nodes and more than 1.8 million of directed\nedges, and travel domain ELG, which consists of about 30 thousand of event\nnodes and more than 234 thousand of directed edges. Experimental results show\nthat ELG is effective for the task of script event prediction.\n", "versions": [{"version": "v1", "created": "Thu, 18 Jul 2019 12:39:12 GMT"}, {"version": "v2", "created": "Wed, 7 Aug 2019 17:44:58 GMT"}], "update_date": "2019-08-09", "authors_parsed": [["Ding", "Xiao", ""], ["Li", "Zhongyang", ""], ["Liu", "Ting", ""], ["Liao", "Kuo", ""]]}, {"id": "1907.08027", "submitter": "Johan Ferret", "authors": "Johan Ferret, Rapha\\\"el Marinier, Matthieu Geist and Olivier Pietquin", "title": "Self-Attentional Credit Assignment for Transfer in Reinforcement\n  Learning", "comments": "21 pages, 10 figures, 3 tables (accepted as an oral presentation at\n  the Learning Transferable Skills workshop, NeurIPS 2019)", "journal-ref": "International Joint Conference on Artificial Intelligence. 29\n  (2020) 2655-2661", "doi": "10.24963/ijcai.2020/368", "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The ability to transfer knowledge to novel environments and tasks is a\nsensible desiderata for general learning agents. Despite the apparent promises,\ntransfer in RL is still an open and little exploited research area. In this\npaper, we take a brand-new perspective about transfer: we suggest that the\nability to assign credit unveils structural invariants in the tasks that can be\ntransferred to make RL more sample-efficient. Our main contribution is SECRET,\na novel approach to transfer learning for RL that uses a backward-view credit\nassignment mechanism based on a self-attentive architecture. Two aspects are\nkey to its generality: it learns to assign credit as a separate offline\nsupervised process and exclusively modifies the reward function. Consequently,\nit can be supplemented by transfer methods that do not modify the reward\nfunction and it can be plugged on top of any RL algorithm.\n", "versions": [{"version": "v1", "created": "Thu, 18 Jul 2019 13:02:16 GMT"}, {"version": "v2", "created": "Fri, 22 Nov 2019 14:22:44 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Ferret", "Johan", ""], ["Marinier", "Rapha\u00ebl", ""], ["Geist", "Matthieu", ""], ["Pietquin", "Olivier", ""]]}, {"id": "1907.08176", "submitter": "Tiantian Gao", "authors": "Tiantian Gao, Paul Fodor, Michael Kifer", "title": "Querying Knowledge via Multi-Hop English Questions", "comments": "Paper presented at the 35th International Conference on Logic\n  Programming (ICLP 2019), Las Cruces, New Mexico, USA, 20-25 September 2019,\n  16 pages", "journal-ref": "Theory and Practice of Logic Programming 19 (2019) 636-653", "doi": "10.1017/S1471068419000103", "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The inherent difficulty of knowledge specification and the lack of trained\nspecialists are some of the key obstacles on the way to making intelligent\nsystems based on the knowledge representation and reasoning (KRR) paradigm\ncommonplace. Knowledge and query authoring using natural language, especially\ncontrolled natural language (CNL), is one of the promising approaches that\ncould enable domain experts, who are not trained logicians, to both create\nformal knowledge and query it. In previous work, we introduced the KALM system\n(Knowledge Authoring Logic Machine) that supports knowledge authoring (and\nsimple querying) with very high accuracy that at present is unachievable via\nmachine learning approaches. The present paper expands on the question\nanswering aspect of KALM and introduces KALM-QA (KALM for Question Answering)\nthat is capable of answering much more complex English questions. We show that\nKALM-QA achieves 100% accuracy on an extensive suite of movie-related\nquestions, called MetaQA, which contains almost 29,000 test questions and over\n260,000 training questions. We contrast this with a published machine learning\napproach, which falls far short of this high mark.\n", "versions": [{"version": "v1", "created": "Thu, 18 Jul 2019 17:37:13 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Gao", "Tiantian", ""], ["Fodor", "Paul", ""], ["Kifer", "Michael", ""]]}, {"id": "1907.08194", "submitter": "Robin Manhaeve", "authors": "Robin Manhaeve, Sebastijan Duman\\v{c}i\\'c, Angelika Kimmig, Thomas\n  Demeester, Luc De Raedt", "title": "Neural Probabilistic Logic Programming in DeepProbLog", "comments": "Extended version of DeepProbLog: Neural Probabilistic Logic\n  Programming (previously published at NeurIPS 2018). arXiv admin note: text\n  overlap with arXiv:1805.10872", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce DeepProbLog, a neural probabilistic logic programming language\nthat incorporates deep learning by means of neural predicates. We show how\nexisting inference and learning techniques of the underlying probabilistic\nlogic programming language ProbLog can be adapted for the new language. We\ntheoretically and experimentally demonstrate that DeepProbLog supports (i) both\nsymbolic and subsymbolic representations and inference, (ii) program induction,\n(iii) probabilistic (logic) programming, and (iv) (deep) learning from\nexamples. To the best of our knowledge, this work is the first to propose a\nframework where general-purpose neural networks and expressive\nprobabilistic-logical modeling and reasoning are integrated in a way that\nexploits the full expressiveness and strengths of both worlds and can be\ntrained end-to-end based on examples.\n", "versions": [{"version": "v1", "created": "Thu, 18 Jul 2019 11:14:01 GMT"}, {"version": "v2", "created": "Mon, 23 Sep 2019 18:34:22 GMT"}], "update_date": "2019-09-26", "authors_parsed": [["Manhaeve", "Robin", ""], ["Duman\u010di\u0107", "Sebastijan", ""], ["Kimmig", "Angelika", ""], ["Demeester", "Thomas", ""], ["De Raedt", "Luc", ""]]}, {"id": "1907.08225", "submitter": "Kristian Hartikainen", "authors": "Kristian Hartikainen, Xinyang Geng, Tuomas Haarnoja, Sergey Levine", "title": "Dynamical Distance Learning for Semi-Supervised and Unsupervised Skill\n  Discovery", "comments": "11+6 pages, 6+2 figures, last two authors (Tuomas Haarnoja, Sergey\n  Levine) advised equally", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning requires manual specification of a reward function to\nlearn a task. While in principle this reward function only needs to specify the\ntask goal, in practice reinforcement learning can be very time-consuming or\neven infeasible unless the reward function is shaped so as to provide a smooth\ngradient towards a successful outcome. This shaping is difficult to specify by\nhand, particularly when the task is learned from raw observations, such as\nimages. In this paper, we study how we can automatically learn dynamical\ndistances: a measure of the expected number of time steps to reach a given goal\nstate from any other state. These dynamical distances can be used to provide\nwell-shaped reward functions for reaching new goals, making it possible to\nlearn complex tasks efficiently. We show that dynamical distances can be used\nin a semi-supervised regime, where unsupervised interaction with the\nenvironment is used to learn the dynamical distances, while a small amount of\npreference supervision is used to determine the task goal, without any manually\nengineered reward function or goal examples. We evaluate our method both on a\nreal-world robot and in simulation. We show that our method can learn to turn a\nvalve with a real-world 9-DoF hand, using raw image observations and just ten\npreference labels, without any other supervision. Videos of the learned skills\ncan be found on the project website:\nhttps://sites.google.com/view/dynamical-distance-learning.\n", "versions": [{"version": "v1", "created": "Thu, 18 Jul 2019 18:07:47 GMT"}, {"version": "v2", "created": "Wed, 25 Sep 2019 18:25:04 GMT"}, {"version": "v3", "created": "Sat, 16 Nov 2019 14:15:46 GMT"}, {"version": "v4", "created": "Fri, 14 Feb 2020 10:16:54 GMT"}], "update_date": "2020-02-17", "authors_parsed": [["Hartikainen", "Kristian", ""], ["Geng", "Xinyang", ""], ["Haarnoja", "Tuomas", ""], ["Levine", "Sergey", ""]]}, {"id": "1907.08276", "submitter": "Li Ling Dr.", "authors": "Li Ling, Zhiqiang Gao, Michael A Silas, Ian Lee and Erwan A Le Doeuff", "title": "An AI-based, Multi-stage detection system of banking botnets", "comments": "FEAP-AI4Fin 2018 : NIPS 2018 Workshop on Challenges and Opportunities\n  for AI in Financial Services: the Impact of Fairness, Explainability,\n  Accuracy, and Privacy", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Banking Trojans, botnets are primary drivers of financially-motivated\ncybercrime. In this paper, we first analyzed how an APT-based banking botnet\nworks step by step through the whole lifecycle. Specifically, we present a\nmulti-stage system that detects malicious banking botnet activities which\npotentially target the organizations. The system leverages Cyber Data Lake as\nwell as multiple artificial intelligence techniques at different stages. The\nevaluation results using public datasets showed that Deep Learning based\ndetections were highly successful compared with baseline models.\n", "versions": [{"version": "v1", "created": "Thu, 18 Jul 2019 20:38:14 GMT"}, {"version": "v2", "created": "Tue, 23 Jul 2019 22:22:08 GMT"}, {"version": "v3", "created": "Thu, 25 Jul 2019 14:05:19 GMT"}], "update_date": "2019-07-26", "authors_parsed": [["Ling", "Li", ""], ["Gao", "Zhiqiang", ""], ["Silas", "Michael A", ""], ["Lee", "Ian", ""], ["Doeuff", "Erwan A Le", ""]]}, {"id": "1907.08292", "submitter": "Bruno Gavranovi\\'c", "authors": "Bruno Gavranovi\\'c", "title": "Compositional Deep Learning", "comments": "56 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI math.CT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks have become an increasingly popular tool for solving many\nreal-world problems. They are a general framework for differentiable\noptimization which includes many other machine learning approaches as special\ncases. In this thesis we build a category-theoretic formalism around a class of\nneural networks exemplified by CycleGAN. CycleGAN is a collection of neural\nnetworks, closed under composition, whose inductive bias is increased by\nenforcing composition invariants, i.e. cycle-consistencies. Inspired by\nFunctorial Data Migration, we specify the interconnection of these networks\nusing a categorical schema, and network instances as set-valued functors on\nthis schema. We also frame neural network architectures, datasets, models, and\na number of other concepts in a categorical setting and thus show a special\nclass of functors, rather than functions, can be learned using gradient\ndescent. We use the category-theoretic framework to conceive a novel neural\nnetwork architecture whose goal is to learn the task of object insertion and\nobject deletion in images with unpaired data. We test the architecture on three\ndifferent datasets and obtain promising results.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jul 2019 10:21:15 GMT"}], "update_date": "2019-07-22", "authors_parsed": [["Gavranovi\u0107", "Bruno", ""]]}, {"id": "1907.08313", "submitter": "Angelo Oddi", "authors": "Angelo Oddi, Riccardo Rasconi, Emilio Cartoni, Gabriele Sartor,\n  Gianluca Baldassarre, Vieri Giuliano Santucci", "title": "Learning High-Level Planning Symbols from Intrinsically Motivated\n  Experience", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In symbolic planning systems, the knowledge on the domain is commonly\nprovided by an expert. Recently, an automatic abstraction procedure has been\nproposed in the literature to create a Planning Domain Definition Language\n(PDDL) representation, which is the most widely used input format for most\noff-the-shelf automated planners, starting from `options', a data structure\nused to represent actions within the hierarchical reinforcement learning\nframework. We propose an architecture that potentially removes the need for\nhuman intervention. In particular, the architecture first acquires options in a\nfully autonomous fashion on the basis of open-ended learning, then builds a\nPDDL domain based on symbols and operators that can be used to accomplish\nuser-defined goals through a standard PDDL planner.\n  We start from an implementation of the above mentioned procedure tested on a\nset of benchmark domains in which a humanoid robot can change the state of some\nobjects through direct interaction with the environment. We then investigate\nsome critical aspects of the information abstraction process that have been\nobserved, and propose an extension that mitigates such criticalities, in\nparticular by analysing the type of classifiers that allow a suitable grounding\nof symbols.\n", "versions": [{"version": "v1", "created": "Thu, 18 Jul 2019 22:42:35 GMT"}], "update_date": "2019-07-22", "authors_parsed": [["Oddi", "Angelo", ""], ["Rasconi", "Riccardo", ""], ["Cartoni", "Emilio", ""], ["Sartor", "Gabriele", ""], ["Baldassarre", "Gianluca", ""], ["Santucci", "Vieri Giuliano", ""]]}, {"id": "1907.08321", "submitter": "Isaac Kamlish", "authors": "Isaac Kamlish, Isaac Bentata Chocron, Nicholas McCarthy", "title": "SentiMATE: Learning to play Chess through Natural Language Processing", "comments": "Accepted for Oral at the AIIDE-19 Workshop on Artificial Intelligence\n  for Strategy Games", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present SentiMATE, a novel end-to-end Deep Learning model for Chess,\nemploying Natural Language Processing that aims to learn an effective\nevaluation function assessing move quality. This function is pre-trained on the\nsentiment of commentary associated with the training moves and is used to guide\nand optimize the agent's game-playing decision making. The contributions of\nthis research are three-fold: we build and put forward both a classifier which\nextracts commentary describing the quality of Chess moves in vast commentary\ndatasets, and a Sentiment Analysis model trained on Chess commentary to\naccurately predict the quality of said moves, to then use those predictions to\nevaluate the optimal next move of a Chess agent. Both classifiers achieve over\n90 % classification accuracy. Lastly, we present a Chess engine, SentiMATE,\nwhich evaluates Chess moves based on a pre-trained sentiment evaluation\nfunction. Our results exhibit strong evidence to support our initial hypothesis\n- \"Can Natural Language Processing be used to train a novel and sample\nefficient evaluation function in Chess Engines?\" - as we integrate our\nevaluation function into modern Chess engines and play against agents with\ntraditional Chess move evaluation functions, beating both random agents and a\nDeepChess implementation at a level-one search depth - representing the number\nof moves a traditional Chess agent (employing the alpha-beta search algorithm)\nlooks ahead in order to evaluate a given chess state.\n", "versions": [{"version": "v1", "created": "Thu, 18 Jul 2019 23:48:21 GMT"}, {"version": "v2", "created": "Mon, 22 Jul 2019 09:08:47 GMT"}, {"version": "v3", "created": "Wed, 25 Sep 2019 18:57:47 GMT"}], "update_date": "2019-09-27", "authors_parsed": [["Kamlish", "Isaac", ""], ["Chocron", "Isaac Bentata", ""], ["McCarthy", "Nicholas", ""]]}, {"id": "1907.08352", "submitter": "Zhanhao Xiao", "authors": "Zhanhao Xiao, Hai Wan, Hankui Hankz Zhuo, Jinxia Lin, Yanan Liu", "title": "Representation Learning for Classical Planning from Partially Observed\n  Traces", "comments": "11 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Specifying a complete domain model is time-consuming, which has been a\nbottleneck of AI planning technique application in many real-world scenarios.\nMost classical domain-model learning approaches output a domain model in the\nform of the declarative planning language, such as STRIPS or PDDL, and solve\nnew planning instances by invoking an existing planner. However, planning in\nsuch a representation is sensitive to the accuracy of the learned domain model\nwhich probably cannot be used to solve real planning problems. In this paper,\nto represent domain models in a vectorization representation way, we propose a\nnovel framework based on graph neural network (GNN) integrating model-free\nlearning and model-based planning, called LP-GNN. By embedding propositions and\nactions in a graph, the latent relationship between them is explored to form a\ndomain-specific heuristics. We evaluate our approach on five classical planning\ndomains, comparing with the classical domain-model learner ARMS. The\nexperimental results show that the domain models learned by our approach are\nmuch more effective on solving real planning problems.\n", "versions": [{"version": "v1", "created": "Fri, 19 Jul 2019 02:53:09 GMT"}], "update_date": "2019-07-22", "authors_parsed": [["Xiao", "Zhanhao", ""], ["Wan", "Hai", ""], ["Zhuo", "Hankui Hankz", ""], ["Lin", "Jinxia", ""], ["Liu", "Yanan", ""]]}, {"id": "1907.08377", "submitter": "Surat Teerapittayanon", "authors": "Surat Teerapittayanon, H. T. Kung", "title": "DaiMoN: A Decentralized Artificial Intelligence Model Network", "comments": "2019 IEEE International Conference on Blockchain", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce DaiMoN, a decentralized artificial intelligence model network,\nwhich incentivizes peer collaboration in improving the accuracy of machine\nlearning models for a given classification problem. It is an autonomous network\nwhere peers may submit models with improved accuracy and other peers may verify\nthe accuracy improvement. The system maintains an append-only decentralized\nledger to keep the log of critical information, including who has trained the\nmodel and improved its accuracy, when it has been improved, by how much it has\nimproved, and where to find the newly updated model. DaiMoN rewards these\ncontributing peers with cryptographic tokens. A main feature of DaiMoN is that\nit allows peers to verify the accuracy improvement of submitted models without\nknowing the test labels. This is an essential component in order to mitigate\nintentional model overfitting by model-improving peers. To enable this model\naccuracy evaluation with hidden test labels, DaiMoN uses a novel learnable\nDistance Embedding for Labels (DEL) function proposed in this paper. Specific\nto each test dataset, DEL scrambles the test label vector by embedding it in a\nlow-dimension space while approximately preserving the distance between the\ndataset's test label vector and a label vector inferred by the classifier. It\ntherefore allows proof-of-improvement (PoI) by peers without providing them\naccess to true test labels. We provide analysis and empirical evidence that\nunder DEL, peers can accurately assess model accuracy. We also argue that it is\nhard to invert the embedding function and thus, DEL is resilient against\nattacks aiming to recover test labels in order to cheat. Our prototype\nimplementation of DaiMoN is available at https://github.com/steerapi/daimon.\n", "versions": [{"version": "v1", "created": "Fri, 19 Jul 2019 06:02:41 GMT"}], "update_date": "2019-07-22", "authors_parsed": [["Teerapittayanon", "Surat", ""], ["Kung", "H. T.", ""]]}, {"id": "1907.08392", "submitter": "Thilo Stadelmann", "authors": "Lukas Tuggener, Mohammadreza Amirian, Katharina Rombach, Stefan\n  L\\\"orwald, Anastasia Varlet, Christian Westermann, Thilo Stadelmann", "title": "Automated Machine Learning in Practice: State of the Art and Recent\n  Results", "comments": "Accepted full paper at SDS2019, the 6th Swiss Conference on Data\n  Science", "journal-ref": null, "doi": "10.1109/SDS.2019.00-11", "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A main driver behind the digitization of industry and society is the belief\nthat data-driven model building and decision making can contribute to higher\ndegrees of automation and more informed decisions. Building such models from\ndata often involves the application of some form of machine learning. Thus,\nthere is an ever growing demand in work force with the necessary skill set to\ndo so. This demand has given rise to a new research topic concerned with\nfitting machine learning models fully automatically - AutoML. This paper gives\nan overview of the state of the art in AutoML with a focus on practical\napplicability in a business context, and provides recent benchmark results on\nthe most important AutoML algorithms.\n", "versions": [{"version": "v1", "created": "Fri, 19 Jul 2019 07:19:07 GMT"}], "update_date": "2019-07-22", "authors_parsed": [["Tuggener", "Lukas", ""], ["Amirian", "Mohammadreza", ""], ["Rombach", "Katharina", ""], ["L\u00f6rwald", "Stefan", ""], ["Varlet", "Anastasia", ""], ["Westermann", "Christian", ""], ["Stadelmann", "Thilo", ""]]}, {"id": "1907.08424", "submitter": "Mario Alviano", "authors": "Mario Alviano, Nicola Leone, Pierfrancesco Veltri, Jessica Zangari", "title": "Enhancing magic sets with an application to ontological reasoning", "comments": "Paper presented at the 35th International Conference on Logic\n  Programming (ICLP 2019), Las Cruces, New Mexico, USA, 20-25 September 2019,\n  16 pages", "journal-ref": "Theory and Practice of Logic Programming 19 (2019) 654-670", "doi": "10.1017/S1471068419000115", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Magic sets are a Datalog to Datalog rewriting technique to optimize query\nanswering. The rewritten program focuses on a portion of the stable model(s) of\nthe input program which is sufficient to answer the given query. However, the\nrewriting may introduce new recursive definitions, which can involve even\nnegation and aggregations, and may slow down program evaluation. This paper\nenhances the magic set technique by preventing the creation of (new) recursive\ndefinitions in the rewritten program. It turns out that the new version of\nmagic sets is closed for Datalog programs with stratified negation and\naggregations, which is very convenient to obtain efficient computation of the\nstable model of the rewritten program. Moreover, the rewritten program is\nfurther optimized by the elimination of subsumed rules and by the efficient\nhandling of the cases where binding propagation is lost. The research was\nstimulated by a challenge on the exploitation of Datalog/\\textsc{dlv} for\nefficient reasoning on large ontologies. All proposed techniques have been\nhence implemented in the \\textsc{dlv} system, and tested for ontological\nreasoning, confirming their effectiveness.\n  Under consideration for publication in Theory and Practice of Logic\nProgramming.\n", "versions": [{"version": "v1", "created": "Fri, 19 Jul 2019 09:31:26 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Alviano", "Mario", ""], ["Leone", "Nicola", ""], ["Veltri", "Pierfrancesco", ""], ["Zangari", "Jessica", ""]]}, {"id": "1907.08478", "submitter": "Robert Loftin", "authors": "Robert Loftin, Bei Peng, Matthew E. Taylor, Michael L. Littman and\n  David L. Roberts", "title": "Interactive Learning of Environment Dynamics for Sequential Tasks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In order for robots and other artificial agents to efficiently learn to\nperform useful tasks defined by an end user, they must understand not only the\ngoals of those tasks, but also the structure and dynamics of that user's\nenvironment. While existing work has looked at how the goals of a task can be\ninferred from a human teacher, the agent is often left to learn about the\nenvironment on its own. To address this limitation, we develop an algorithm,\nBehavior Aware Modeling (BAM), which incorporates a teacher's knowledge into a\nmodel of the transition dynamics of an agent's environment. We evaluate BAM\nboth in simulation and with real human teachers, learning from a combination of\ntask demonstrations and evaluative feedback, and show that it can outperform\napproaches which do not explicitly consider this source of dynamics knowledge.\n", "versions": [{"version": "v1", "created": "Fri, 19 Jul 2019 12:15:53 GMT"}], "update_date": "2019-07-22", "authors_parsed": [["Loftin", "Robert", ""], ["Peng", "Bei", ""], ["Taylor", "Matthew E.", ""], ["Littman", "Michael L.", ""], ["Roberts", "David L.", ""]]}, {"id": "1907.08489", "submitter": "Ning Wu", "authors": "Jingyuan Wang, Ning Wu, Wayne Xin Zhao, Fanzhang Peng and Xin Lin", "title": "Empowering A* Search Algorithms with Neural Networks for Personalized\n  Route Recommendation", "comments": "9 pages, 25TH ACM SIGKDD Conference On Knowledge Discovery And Data\n  Mining", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Personalized Route Recommendation (PRR) aims to generate user-specific route\nsuggestions in response to users' route queries. Early studies cast the PRR\ntask as a pathfinding problem on graphs, and adopt adapted search algorithms by\nintegrating heuristic strategies. Although these methods are effective to some\nextent, they require setting the cost functions with heuristics. In addition,\nit is difficult to utilize useful context information in the search procedure.\nTo address these issues, we propose using neural networks to automatically\nlearn the cost functions of a classic heuristic algorithm, namely A* algorithm,\nfor the PRR task. Our model consists of two components. First, we employ\nattention-based Recurrent Neural Networks (RNN) to model the cost from the\nsource to the candidate location by incorporating useful context information.\nInstead of learning a single cost value, the RNN component is able to learn a\ntime-varying vectorized representation for the moving state of a user. Second,\nwe propose to use a value network for estimating the cost from a candidate\nlocation to the destination. For capturing structural characteristics, the\nvalue network is built on top of improved graph attention networks by\nincorporating the moving state of a user and other context information. The two\ncomponents are integrated in a principled way for deriving a more accurate cost\nof a candidate location. Extensive experiment results on three real-world\ndatasets have shown the effectiveness and robustness of the proposed model.\n", "versions": [{"version": "v1", "created": "Fri, 19 Jul 2019 12:47:00 GMT"}], "update_date": "2019-07-22", "authors_parsed": [["Wang", "Jingyuan", ""], ["Wu", "Ning", ""], ["Zhao", "Wayne Xin", ""], ["Peng", "Fanzhang", ""], ["Lin", "Xin", ""]]}, {"id": "1907.08584", "submitter": "Arthur Szlam", "authors": "Jonathan Gray, Kavya Srinet, Yacine Jernite, Haonan Yu, Zhuoyuan Chen,\n  Demi Guo, Siddharth Goyal, C. Lawrence Zitnick, Arthur Szlam", "title": "CraftAssist: A Framework for Dialogue-enabled Interactive Agents", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes an implementation of a bot assistant in Minecraft, and\nthe tools and platform allowing players to interact with the bot and to record\nthose interactions. The purpose of building such an assistant is to facilitate\nthe study of agents that can complete tasks specified by dialogue, and\neventually, to learn from dialogue interactions.\n", "versions": [{"version": "v1", "created": "Fri, 19 Jul 2019 17:25:07 GMT"}], "update_date": "2019-07-22", "authors_parsed": [["Gray", "Jonathan", ""], ["Srinet", "Kavya", ""], ["Jernite", "Yacine", ""], ["Yu", "Haonan", ""], ["Chen", "Zhuoyuan", ""], ["Guo", "Demi", ""], ["Goyal", "Siddharth", ""], ["Zitnick", "C. Lawrence", ""], ["Szlam", "Arthur", ""]]}, {"id": "1907.08591", "submitter": "Michele Buzzicotti", "authors": "Luca Biferale, Fabio Bonaccorso, Michele Buzzicotti, Patricio Clark Di\n  Leoni and Kristian Gustavsson", "title": "Zermelo's problem: Optimal point-to-point navigation in 2D turbulent\n  flows using Reinforcement Learning", "comments": null, "journal-ref": null, "doi": "10.1063/1.5120370", "report-no": null, "categories": "nlin.CD cs.AI cs.LG cs.SY eess.SY physics.flu-dyn", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To find the path that minimizes the time to navigate between two given points\nin a fluid flow is known as Zermelo's problem. Here, we investigate it by using\na Reinforcement Learning (RL) approach for the case of a vessel which has a\nslip velocity with fixed intensity, Vs , but variable direction and navigating\nin a 2D turbulent sea. We show that an Actor-Critic RL algorithm is able to\nfind quasi-optimal solutions for both time-independent and chaotically evolving\nflow configurations. For the frozen case, we also compared the results with\nstrategies obtained analytically from continuous Optimal Navigation (ON)\nprotocols. We show that for our application, ON solutions are unstable for the\ntypical duration of the navigation process, and are therefore not useful in\npractice. On the other hand, RL solutions are much more robust with respect to\nsmall changes in the initial conditions and to external noise, even when V s is\nmuch smaller than the maximum flow velocity. Furthermore, we show how the RL\napproach is able to take advantage of the flow properties in order to reach the\ntarget, especially when the steering speed is small.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jul 2019 15:12:52 GMT"}, {"version": "v2", "created": "Thu, 26 Sep 2019 10:51:15 GMT"}], "update_date": "2020-01-08", "authors_parsed": [["Biferale", "Luca", ""], ["Bonaccorso", "Fabio", ""], ["Buzzicotti", "Michele", ""], ["Di Leoni", "Patricio Clark", ""], ["Gustavsson", "Kristian", ""]]}, {"id": "1907.08647", "submitter": "Daniel Karapetyan Dr", "authors": "Olegs Nalivajevs and Daniel Karapetyan", "title": "Conditional Markov Chain Search for the Generalised Travelling Salesman\n  Problem for Warehouse Order Picking", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Generalised Travelling Salesman Problem (GTSP) is a well-known problem\nthat, among other applications, arises in warehouse order picking, where each\nstock is distributed between several locations -- a typical approach in large\nmodern warehouses. However, the instances commonly used in the literature have\na completely different structure, and the methods are designed with those\ninstances in mind. In this paper, we give a new pseudo-random instance\ngenerator that reflects the warehouse order picking and publish new benchmark\ntestbeds. We also use the Conditional Markov Chain Search framework to\nautomatically generate new GTSP metaheuristics trained specifically for\nwarehouse order picking. Finally, we report the computational results of our\nmetaheuristics to enable further competition between solvers.\n", "versions": [{"version": "v1", "created": "Fri, 19 Jul 2019 18:53:26 GMT"}, {"version": "v2", "created": "Fri, 9 Aug 2019 17:15:19 GMT"}], "update_date": "2019-08-12", "authors_parsed": [["Nalivajevs", "Olegs", ""], ["Karapetyan", "Daniel", ""]]}, {"id": "1907.08650", "submitter": "Sutanay Choudhury", "authors": "Khushbu Agarwal, Tome Eftimov, Raghavendra Addanki, Sutanay Choudhury,\n  Suzanne Tamang, and Robert Rallo", "title": "Snomed2Vec: Random Walk and Poincar\\'e Embeddings of a Clinical\n  Knowledge Base for Healthcare Analytics", "comments": "2019 KDD Workshop on Applied Data Science for Healthcare (DSHealth\n  '19). https://gitlab.com/agarwal.khushbu/Snomed2Vec", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Representation learning methods that transform encoded data (e.g., diagnosis\nand drug codes) into continuous vector spaces (i.e., vector embeddings) are\ncritical for the application of deep learning in healthcare. Initial work in\nthis area explored the use of variants of the word2vec algorithm to learn\nembeddings for medical concepts from electronic health records or medical\nclaims datasets. We propose learning embeddings for medical concepts by using\ngraph-based representation learning methods on SNOMED-CT, a widely popular\nknowledge graph in the healthcare domain with numerous operational and research\napplications. Current work presents an empirical analysis of various embedding\nmethods, including the evaluation of their performance on multiple tasks of\nbiomedical relevance (node classification, link prediction, and patient state\nprediction). Our results show that concept embeddings derived from the\nSNOMED-CT knowledge graph significantly outperform state-of-the-art embeddings,\nshowing 5-6x improvement in ``concept similarity\" and 6-20\\% improvement in\npatient diagnosis.\n", "versions": [{"version": "v1", "created": "Fri, 19 Jul 2019 19:11:39 GMT"}], "update_date": "2019-07-23", "authors_parsed": [["Agarwal", "Khushbu", ""], ["Eftimov", "Tome", ""], ["Addanki", "Raghavendra", ""], ["Choudhury", "Sutanay", ""], ["Tamang", "Suzanne", ""], ["Rallo", "Robert", ""]]}, {"id": "1907.08671", "submitter": "Michael F\\\"arber", "authors": "Michael F\\\"arber", "title": "Linked Crunchbase: A Linked Data API and RDF Data Set About Innovative\n  Companies", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.AI cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Crunchbase is an online platform collecting information about startups and\ntechnology companies, including attributes and relations of companies, people,\nand investments. Data contained in Crunchbase is, to a large extent, not\navailable elsewhere, making Crunchbase to a unique data source. In this paper,\nwe present how to bring Crunchbase to the Web of Data so that its data can be\nused in the machine-readable RDF format by anyone on the Web. First, we give\ninsights into how we developed and hosted a Linked Data API for Crunchbase and\nhow sameAs links to other data sources are integrated. Then, we present our\nmethod for crawling RDF data based on this API to build a custom Crunchbase RDF\nknowledge graph. We created an RDF data set with over 347 million triples,\nincluding 781k people, 659k organizations, and 343k investments. Our Crunchbase\nLinked Data API is available online at http://linked-crunchbase.org.\n", "versions": [{"version": "v1", "created": "Fri, 19 Jul 2019 20:08:47 GMT"}], "update_date": "2019-07-23", "authors_parsed": [["F\u00e4rber", "Michael", ""]]}, {"id": "1907.08707", "submitter": "Liting Sun", "authors": "Liting Sun, Wei Zhan, Yeping Hu, Masayoshi Tomizuka", "title": "Interpretable Modelling of Driving Behaviors in Interactive Driving\n  Scenarios based on Cumulative Prospect Theory", "comments": "accepted to the 2019 IEEE Intelligent Transportation System\n  Conference (ITSC2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.RO cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding human driving behavior is important for autonomous vehicles. In\nthis paper, we propose an interpretable human behavior model in interactive\ndriving scenarios based on the cumulative prospect theory (CPT). As a\nnon-expected utility theory, CPT can well explain some systematically biased or\n``irrational'' behavior/decisions of human that cannot be explained by the\nexpected utility theory. Hence, the goal of this work is to formulate the human\ndrivers' behavior generation model with CPT so that some ``irrational''\nbehavior or decisions of human can be better captured and predicted. Towards\nsuch a goal, we first develop a CPT-driven decision-making model focusing on\ndriving scenarios with two interacting agents. A hierarchical learning\nalgorithm is proposed afterward to learn the utility function, the value\nfunction, and the decision weighting function in the CPT model. A case study\nfor roundabout merging is also provided as verification. With real driving\ndata, the prediction performances of three different models are compared: a\npredefined model based on time-to-collision (TTC), a learning-based model based\non neural networks, and the proposed CPT-based model. The results show that the\nproposed model outperforms the TTC model and achieves similar performance as\nthe learning-based model with much less training data and better\ninterpretability.\n", "versions": [{"version": "v1", "created": "Fri, 19 Jul 2019 21:56:38 GMT"}], "update_date": "2019-07-23", "authors_parsed": [["Sun", "Liting", ""], ["Zhan", "Wei", ""], ["Hu", "Yeping", ""], ["Tomizuka", "Masayoshi", ""]]}, {"id": "1907.08739", "submitter": "Taoan Huang", "authors": "Taoan Huang, Bohui Fang, Xiaohui Bei, Fei Fang", "title": "Dynamic Trip-Vehicle Dispatch with Scheduled and On-Demand Requests", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transportation service providers that dispatch drivers and vehicles to riders\nstart to support both on-demand ride requests posted in real time and rides\nscheduled in advance, leading to new challenges which, to the best of our\nknowledge, have not been addressed by existing works. To fill the gap, we\ndesign novel trip-vehicle dispatch algorithms to handle both types of requests\nwhile taking into account an estimated request distribution of on-demand\nrequests. At the core of the algorithms is the newly proposed Constrained\nSpatio-Temporal value function (CST-function), which is polynomial-time\ncomputable and represents the expected value a vehicle could gain with the\nconstraint that it needs to arrive at a specific location at a given time.\nBuilt upon CST-function, we design a randomized best-fit algorithm for\nscheduled requests and an online planning algorithm for on-demand requests\ngiven the scheduled requests as constraints. We evaluate the algorithms through\nextensive experiments on a real-world dataset of an online ride-hailing\nplatform.\n", "versions": [{"version": "v1", "created": "Sat, 20 Jul 2019 02:45:24 GMT"}], "update_date": "2019-07-23", "authors_parsed": [["Huang", "Taoan", ""], ["Fang", "Bohui", ""], ["Bei", "Xiaohui", ""], ["Fang", "Fei", ""]]}, {"id": "1907.08823", "submitter": "Bhaskar Ramasubramanian", "authors": "Baicen Xiao, Bhaskar Ramasubramanian, Andrew Clark, Hannaneh\n  Hajishirzi, Linda Bushnell, Radha Poovendran", "title": "Potential-Based Advice for Stochastic Policy Learning", "comments": "Accepted to the IEEE Conference on Decision and Control, 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper augments the reward received by a reinforcement learning agent\nwith potential functions in order to help the agent learn (possibly stochastic)\noptimal policies. We show that a potential-based reward shaping scheme is able\nto preserve optimality of stochastic policies, and demonstrate that the ability\nof an agent to learn an optimal policy is not affected when this scheme is\naugmented to soft Q-learning. We propose a method to impart potential based\nadvice schemes to policy gradient algorithms. An algorithm that considers an\nadvantage actor-critic architecture augmented with this scheme is proposed, and\nwe give guarantees on its convergence. Finally, we evaluate our approach on a\npuddle-jump grid world with indistinguishable states, and the continuous state\nand action mountain car environment from classical control. Our results\nindicate that these schemes allow the agent to learn a stochastic optimal\npolicy faster and obtain a higher average reward.\n", "versions": [{"version": "v1", "created": "Sat, 20 Jul 2019 15:21:11 GMT"}], "update_date": "2019-07-23", "authors_parsed": [["Xiao", "Baicen", ""], ["Ramasubramanian", "Bhaskar", ""], ["Clark", "Andrew", ""], ["Hajishirzi", "Hannaneh", ""], ["Bushnell", "Linda", ""], ["Poovendran", "Radha", ""]]}, {"id": "1907.08892", "submitter": "Jan Strappa Figueroa", "authors": "Jan Strappa and Facundo Bromberg", "title": "Efficient comparison of independence structures of log-linear models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Log-linear models are a family of probability distributions which capture\nrelationships between variables, including context-specific independencies.\nMany approaches exist for automatic learning of their independence structures\nfrom data, although the only known methods for evaluating these approaches are\nindirect measures of their complete density. This requires additional learning\nof numerical parameters, and introduces distortions when used for comparing\nstructures. This work addresses this issue by presenting a measure for the\ndirect and efficient comparison of independence structures of log-linear\nmodels. We present proof that the measure is a metric, and a method for its\ncomputation that is efficient in the number of variables of the domain.\nEfficiency in the number of features in the models is not guaranteed and will\nbe the subject of future work.\n", "versions": [{"version": "v1", "created": "Sun, 21 Jul 2019 01:52:28 GMT"}, {"version": "v2", "created": "Thu, 11 Feb 2021 14:10:35 GMT"}, {"version": "v3", "created": "Thu, 13 May 2021 21:18:32 GMT"}], "update_date": "2021-05-17", "authors_parsed": [["Strappa", "Jan", ""], ["Bromberg", "Facundo", ""]]}, {"id": "1907.08908", "submitter": "Yi-Wei Chen", "authors": "Yi-Wei Chen, Qingquan Song, Xia Hu", "title": "Techniques for Automated Machine Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automated machine learning (AutoML) aims to find optimal machine learning\nsolutions automatically given a machine learning problem. It could release the\nburden of data scientists from the multifarious manual tuning process and\nenable the access of domain experts to the off-the-shelf machine learning\nsolutions without extensive experience. In this paper, we review the current\ndevelopments of AutoML in terms of three categories, automated feature\nengineering (AutoFE), automated model and hyperparameter learning (AutoMHL),\nand automated deep learning (AutoDL). State-of-the-art techniques adopted in\nthe three categories are presented, including Bayesian optimization,\nreinforcement learning, evolutionary algorithm, and gradient-based approaches.\nWe summarize popular AutoML frameworks and conclude with current open\nchallenges of AutoML.\n", "versions": [{"version": "v1", "created": "Sun, 21 Jul 2019 04:03:36 GMT"}], "update_date": "2019-07-23", "authors_parsed": [["Chen", "Yi-Wei", ""], ["Song", "Qingquan", ""], ["Hu", "Xia", ""]]}, {"id": "1907.08937", "submitter": "Hao Zhu", "authors": "Weize Chen, Hao Zhu, Xu Han, Zhiyuan Liu, Maosong Sun", "title": "Quantifying Similarity between Relations with Fact Distribution", "comments": "ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  We introduce a conceptually simple and effective method to quantify the\nsimilarity between relations in knowledge bases. Specifically, our approach is\nbased on the divergence between the conditional probability distributions over\nentity pairs. In this paper, these distributions are parameterized by a very\nsimple neural network. Although computing the exact similarity is in-tractable,\nwe provide a sampling-based method to get a good approximation. We empirically\nshow the outputs of our approach significantly correlate with human judgments.\nBy applying our method to various tasks, we also find that (1) our approach\ncould effectively detect redundant relations extracted by open information\nextraction (Open IE) models, that (2) even the most competitive models for\nrelational classification still make mistakes among very similar relations, and\nthat (3) our approach could be incorporated into negative sampling and softmax\nclassification to alleviate these mistakes. The source code and experiment\ndetails of this paper can be obtained from\nhttps://github.com/thunlp/relation-similarity.\n", "versions": [{"version": "v1", "created": "Sun, 21 Jul 2019 09:22:50 GMT"}], "update_date": "2019-07-23", "authors_parsed": [["Chen", "Weize", ""], ["Zhu", "Hao", ""], ["Han", "Xu", ""], ["Liu", "Zhiyuan", ""], ["Sun", "Maosong", ""]]}, {"id": "1907.08996", "submitter": "Mazharul Islam", "authors": "Mazharul Islam, Shuangrong Liu, Lin Wang, Xiaojing Zhang", "title": "Improving Neural Network Classifier using Gradient-based Floating\n  Centroid Method", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Floating centroid method (FCM) offers an efficient way to solve a\nfixed-centroid problem for the neural network classifiers. However,\nevolutionary computation as its optimization method restrains the FCM to\nachieve satisfactory performance for different neural network structures,\nbecause of the high computational complexity and inefficiency. Traditional\ngradient-based methods have been extensively adopted to optimize the neural\nnetwork classifiers. In this study, a gradient-based floating centroid (GDFC)\nmethod is introduced to address the fixed centroid problem for the neural\nnetwork classifiers optimized by gradient-based methods. Furthermore, a new\nloss function for optimizing GDFC is introduced. The experimental results\ndisplay that GDFC obtains promising classification performance than the\ncomparison methods on the benchmark datasets.\n", "versions": [{"version": "v1", "created": "Sun, 21 Jul 2019 16:09:16 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Islam", "Mazharul", ""], ["Liu", "Shuangrong", ""], ["Wang", "Lin", ""], ["Zhang", "Xiaojing", ""]]}, {"id": "1907.09050", "submitter": "Richard Jiang", "authors": "Richard Jiang and Danny Crookes", "title": "Shallow Unorganized Neural Networks using Smart Neuron Model for Visual\n  Perception", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.NE eess.IV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The recent success of Deep Neural Networks (DNNs) has revealed the\nsignificant capability of neural computing in many challenging applications.\nAlthough DNNs are derived from emulating biological neurons, there still exist\ndoubts over whether or not DNNs are the final and best model to emulate the\nmechanism of human intelligence. In particular, there are two discrepancies\nbetween computational DNN models and the observed facts of biological neurons.\nFirst, human neurons are interconnected randomly, while DNNs need\ncarefully-designed architectures to work properly. Second, human neurons\nusually have a long spiking latency (~100ms) which implies that not many layers\ncan be involved in making a decision, while DNNs could have hundreds of layers\nto guarantee high accuracy. In this paper, we propose a new computational\nmodel, namely shallow unorganized neural networks (SUNNs), in contrast to\nANNs/DNNs. The proposed SUNNs differ from standard ANNs or DNNs in three\nfundamental aspects: 1) SUNNs are based on an adaptive neuron cell model, Smart\nNeurons, that allows each artificial neuron cell to adaptively respond to its\ninputs rather than carrying out a fixed weighted-sum operation like the classic\nneuron model in ANNs/DNNs; 2) SUNNs can cope with computational tasks with very\nshallow architectures; 3) SUNNs have a natural topology with random\ninterconnections, as the human brain does, and as proposed by Turing's B-type\nunorganized machines. We implemented the proposed SUNN architecture and tested\nit on a number of unsupervised early stage visual perception tasks.\nSurprisingly, such simple shallow architectures achieved very good results in\nour experiments. The success of our new computational model makes it the first\nworkable example of Turing's B-Type unorganized machine that can achieve\ncomparable or better performance against the state-of-the-art algorithms.\n", "versions": [{"version": "v1", "created": "Sun, 21 Jul 2019 23:09:35 GMT"}, {"version": "v2", "created": "Wed, 30 Oct 2019 23:50:49 GMT"}], "update_date": "2019-11-01", "authors_parsed": [["Jiang", "Richard", ""], ["Crookes", "Danny", ""]]}, {"id": "1907.09065", "submitter": "Cheng Li", "authors": "Cheng Li, Santu Rana, Sunil Gupta, Vu Nguyen, Svetha Venkatesh,\n  Alessandra Sutti, David Rubin, Teo Slezak, Murray Height, Mazher Mohammed,\n  Ian Gibson", "title": "Accelerating Experimental Design by Incorporating Experimenter Hunches", "comments": "IEEE International Conference on Data Mining (ICDM) 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Experimental design is a process of obtaining a product with target property\nvia experimentation. Bayesian optimization offers a sample-efficient tool for\nexperimental design when experiments are expensive. Often, expert experimenters\nhave 'hunches' about the behavior of the experimental system, offering\npotentials to further improve the efficiency. In this paper, we consider\nper-variable monotonic trend in the underlying property that results in a\nunimodal trend in those variables for a target value optimization. For example,\nsweetness of a candy is monotonic to the sugar content. However, to obtain a\ntarget sweetness, the utility of the sugar content becomes a unimodal function,\nwhich peaks at the value giving the target sweetness and falls off both ways.\nIn this paper, we propose a novel method to solve such problems that achieves\ntwo main objectives: a) the monotonicity information is used to the fullest\nextent possible, whilst ensuring that b) the convergence guarantee remains\nintact. This is achieved by a two-stage Gaussian process modeling, where the\nfirst stage uses the monotonicity trend to model the underlying property, and\nthe second stage uses `virtual' samples, sampled from the first, to model the\ntarget value optimization function. The process is made theoretically\nconsistent by adding appropriate adjustment factor in the posterior\ncomputation, necessitated because of using the `virtual' samples. The proposed\nmethod is evaluated through both simulations and real world experimental design\nproblems of a) new short polymer fiber with the target length, and b) designing\nof a new three dimensional porous scaffolding with a target porosity. In all\nscenarios our method demonstrates faster convergence than the basic Bayesian\noptimization approach not using such `hunches'.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jul 2019 00:48:24 GMT"}], "update_date": "2019-07-23", "authors_parsed": [["Li", "Cheng", ""], ["Rana", "Santu", ""], ["Gupta", "Sunil", ""], ["Nguyen", "Vu", ""], ["Venkatesh", "Svetha", ""], ["Sutti", "Alessandra", ""], ["Rubin", "David", ""], ["Slezak", "Teo", ""], ["Height", "Murray", ""], ["Mohammed", "Mazher", ""], ["Gibson", "Ian", ""]]}, {"id": "1907.09097", "submitter": "EPTCS", "authors": "Krzysztof R. Apt (Centrum Wiskunde & Informatica, Amsterdam, The\n  Netherlands and University of Warsaw, Warsaw, Poland), Dominik Wojtczak\n  (University of Liverpool, Liverpool, UK)", "title": "Open Problems in a Logic of Gossips", "comments": "In Proceedings TARK 2019, arXiv:1907.08335", "journal-ref": "EPTCS 297, 2019, pp. 1-18", "doi": "10.4204/EPTCS.297.1", "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gossip protocols are programs used in a setting in which each agent holds a\nsecret and the aim is to reach a situation in which all agents know all\nsecrets. Such protocols rely on a point-to-point or group communication.\nDistributed epistemic gossip protocols use epistemic formulas in the component\nprograms for the agents. The advantage of the use of epistemic logic is that\nthe resulting protocols are very concise and amenable for a simple\nverification.\n  Recently, we introduced a natural modal logic that allows one to express\ndistributed epistemic gossip protocols and to reason about their correctness.\nWe proved that the resulting protocols are implementable and that all aspects\nof their correctness, including termination, are decidable. To establish these\nresults we showed that both the definition of semantics and of truth of the\nunderlying logic are decidable. We also showed that the analogous results hold\nfor an extension of this logic with the 'common knowledge' operator.\n  However, several, often deceptively simple, questions about this logic and\nthe corresponding gossip protocols remain open. The purpose of this paper is to\nlist and elucidate these questions and provide for them an appropriate\nbackground information in the form of partial of related results.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jul 2019 03:12:30 GMT"}], "update_date": "2019-07-23", "authors_parsed": [["Apt", "Krzysztof R.", "", "Centrum Wiskunde & Informatica, Amsterdam, The\n  Netherlands and University of Warsaw, Warsaw, Poland"], ["Wojtczak", "Dominik", "", "University of Liverpool, Liverpool, UK"]]}, {"id": "1907.09103", "submitter": "EPTCS", "authors": "Nourhan Ehab, Haythem O. Ismail", "title": "A Unified Algebraic Framework for Non-Monotonicity", "comments": "In Proceedings TARK 2019, arXiv:1907.08335", "journal-ref": "EPTCS 297, 2019, pp. 155-174", "doi": "10.4204/EPTCS.297.11", "report-no": null, "categories": "cs.LO cs.AI cs.SC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tremendous research effort has been dedicated over the years to thoroughly\ninvestigate non-monotonic reasoning. With the abundance of non-monotonic\nlogical formalisms, a unified theory that enables comparing the different\napproaches is much called for. In this paper, we present an algebraic graded\nlogic we refer to as LogAG capable of encompassing a wide variety of\nnon-monotonic formalisms. We build on Lin and Shoham's argument systems first\ndeveloped to formalize non-monotonic commonsense reasoning. We show how to\nencode argument systems as LogAG theories, and prove that LogAG captures the\nnotion of belief spaces in argument systems. Since argument systems capture\ndefault logic, autoepistemic logic, the principle of negation as failure, and\ncircumscription, our results show that LogAG captures the before-mentioned\nnon-monotonic logical formalisms as well. Previous results show that LogAG\nsubsumes possibilistic logic and any non-monotonic inference relation\nsatisfying Makinson's rationality postulates. In this way, LogAG provides a\npowerful unified framework for non-monotonicity.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jul 2019 03:15:28 GMT"}], "update_date": "2019-07-23", "authors_parsed": [["Ehab", "Nourhan", ""], ["Ismail", "Haythem O.", ""]]}, {"id": "1907.09106", "submitter": "EPTCS", "authors": "Joseph Y. Halpern (Cornell University), Rafael Pass (Cornell\n  University)", "title": "A Conceptually Well-Founded Characterization of Iterated Admissibility\n  Using an \"All I Know\" Operator", "comments": "In Proceedings TARK 2019, arXiv:1907.08335", "journal-ref": "EPTCS 297, 2019, pp. 221-232", "doi": "10.4204/EPTCS.297.15", "report-no": null, "categories": "cs.GT cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Brandenburger, Friedenberg, and Keisler provide an epistemic characterization\nof iterated admissibility (IA), also known as iterated deletion of weakly\ndominated strategies, where uncertainty is represented using LPSs\n(lexicographic probability sequences). Their characterization holds in a rich\nstructure called a complete structure, where all types are possible. In earlier\nwork, we gave a characterization of iterated admissibility using an \"all I\nknow\" operator, that captures the intuition that \"all the agent knows\" is that\nagents satisfy the appropriate rationality assumptions. That characterization\ndid not need complete structures and used probability structures, not LPSs.\nHowever, that characterization did not deal with Samuelson's conceptual concern\nregarding IA, namely, that at higher levels, players do not consider possible\nstrategies that were used to justify their choice of strategy at lower levels.\nIn this paper, we give a characterization of IA using the all I know operator\nthat does deal with Samuelson's concern. However, it uses LPSs. We then show\nhow to modify the characterization using notions of \"approximate belief\" and\n\"approximately all I know\" so as to deal with Samuelson's concern while still\nworking with probability structures.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jul 2019 03:16:38 GMT"}], "update_date": "2019-07-23", "authors_parsed": [["Halpern", "Joseph Y.", "", "Cornell University"], ["Pass", "Rafael", "", "Cornell\n  University"]]}, {"id": "1907.09111", "submitter": "EPTCS", "authors": "Magdalena Ivanovska, Marija Slavkovik", "title": "Aggregating Probabilistic Judgments", "comments": "In Proceedings TARK 2019, arXiv:1907.08335", "journal-ref": "EPTCS 297, 2019, pp. 273-292", "doi": "10.4204/EPTCS.297.18", "report-no": null, "categories": "cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we explore the application of methods for classical judgment\naggregation in pooling probabilistic opinions on logically related issues. For\nthis reason, we first modify the Boolean judgment aggregation framework in the\nway that allows handling probabilistic judgments and then define probabilistic\naggregation functions obtained by generalization of the classical ones. In\naddition, we discuss essential desirable properties for the aggregation\nfunctions and explore impossibility results.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jul 2019 03:17:47 GMT"}], "update_date": "2019-07-23", "authors_parsed": [["Ivanovska", "Magdalena", ""], ["Slavkovik", "Marija", ""]]}, {"id": "1907.09113", "submitter": "EPTCS", "authors": "Grzegorz Lisowski (University of Warwick), Sylvie Doutre (University\n  of Toulouse), Umberto Grandi (University of Toulouse)", "title": "Aggregation in Value-Based Argumentation Frameworks", "comments": "In Proceedings TARK 2019, arXiv:1907.08335", "journal-ref": "EPTCS 297, 2019, pp. 313-331", "doi": "10.4204/EPTCS.297.20", "report-no": null, "categories": "cs.MA cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Value-based argumentation enhances a classical abstract argumentation graph -\nin which arguments are modelled as nodes connected by directed arrows called\nattacks - with labels on arguments, called values, and an ordering on values,\ncalled audience, to provide a more fine-grained justification of the attack\nrelation. With more than one agent facing such an argumentation problem, agents\nmay differ in their ranking of values. When needing to reach a collective view,\nsuch agents face a dilemma between two equally justifiable approaches:\naggregating their views at the level of values, or aggregating their attack\nrelations, remaining therefore at the level of the graphs. We explore the\nstrenghts and limitations of both approaches, employing techniques from\npreference aggregation and graph aggregation, and propose a third possibility\naggregating rankings extracted from given attack relations.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jul 2019 03:18:29 GMT"}], "update_date": "2019-07-23", "authors_parsed": [["Lisowski", "Grzegorz", "", "University of Warwick"], ["Doutre", "Sylvie", "", "University\n  of Toulouse"], ["Grandi", "Umberto", "", "University of Toulouse"]]}, {"id": "1907.09114", "submitter": "EPTCS", "authors": "Emiliano Lorini (IRIT-CNRS, Toulouse University, France)", "title": "Exploiting Belief Bases for Building Rich Epistemic Structures", "comments": "In Proceedings TARK 2019, arXiv:1907.08335", "journal-ref": "EPTCS 297, 2019, pp. 332-353", "doi": "10.4204/EPTCS.297.21", "report-no": null, "categories": "cs.GT cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a semantics for epistemic logic exploiting a belief base\nabstraction. Differently from existing Kripke-style semantics for epistemic\nlogic in which the notions of possible world and epistemic alternative are\nprimitive, in the proposed semantics they are non-primitive but are defined\nfrom the concept of belief base. We show that this semantics allows us to\ndefine the universal epistemic model in a simpler and more compact way than\nexisting inductive constructions of it. We provide (i) a number of semantic\nequivalence results for both the basic epistemic language with \"individual\nbelief\" operators and its extension by the notion of \"only believing\", and (ii)\na lower bound complexity result for epistemic logic model checking relative to\nthe universal epistemic model.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jul 2019 03:18:48 GMT"}], "update_date": "2019-07-23", "authors_parsed": [["Lorini", "Emiliano", "", "IRIT-CNRS, Toulouse University, France"]]}, {"id": "1907.09115", "submitter": "EPTCS", "authors": "Sven Neth (University of California, Berkeley)", "title": "Measuring Belief and Risk Attitude", "comments": "In Proceedings TARK 2019, arXiv:1907.08335", "journal-ref": "EPTCS 297, 2019, pp. 354-364", "doi": "10.4204/EPTCS.297.22", "report-no": null, "categories": "cs.GT cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ramsey (1926) sketches a proposal for measuring the subjective probabilities\nof an agent by their observable preferences, assuming that the agent is an\nexpected utility maximizer. I show how to extend the spirit of Ramsey's method\nto a strictly wider class of agents: risk-weighted expected utility maximizers\n(Buchak 2013). In particular, I show how we can measure the risk attitudes of\nan agent by their observable preferences, assuming that the agent is a\nrisk-weighted expected utility maximizer. Further, we can leverage this method\nto measure the subjective probabilities of a risk-weighted expected utility\nmaximizer.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jul 2019 03:19:07 GMT"}], "update_date": "2019-07-23", "authors_parsed": [["Neth", "Sven", "", "University of California, Berkeley"]]}, {"id": "1907.09173", "submitter": "Jindong Wang", "authors": "Yiqiang Chen, Jindong Wang, Chaohui Yu, Wen Gao, Xin Qin", "title": "FedHealth: A Federated Transfer Learning Framework for Wearable\n  Healthcare", "comments": "IJCAI-19 Workshop on Federated Machine Learning for User Privacy and\n  Data Confidentiality (IJCAI (FML)) 2019; fix typos; journal version:\n  https://ieeexplore.ieee.org/document/9076082", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  With the rapid development of computing technology, wearable devices such as\nsmart phones and wristbands make it easy to get access to people's health\ninformation including activities, sleep, sports, etc. Smart healthcare achieves\ngreat success by training machine learning models on a large quantity of user\ndata. However, there are two critical challenges. Firstly, user data often\nexists in the form of isolated islands, making it difficult to perform\naggregation without compromising privacy security. Secondly, the models trained\non the cloud fail on personalization. In this paper, we propose FedHealth, the\nfirst federated transfer learning framework for wearable healthcare to tackle\nthese challenges. FedHealth performs data aggregation through federated\nlearning, and then builds personalized models by transfer learning. It is able\nto achieve accurate and personalized healthcare without compromising privacy\nand security. Experiments demonstrate that FedHealth produces higher accuracy\n(5.3% improvement) for wearable activity recognition when compared to\ntraditional methods. FedHealth is general and extensible and has the potential\nto be used in many healthcare applications.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jul 2019 07:56:33 GMT"}, {"version": "v2", "created": "Tue, 11 May 2021 10:22:03 GMT"}], "update_date": "2021-05-12", "authors_parsed": [["Chen", "Yiqiang", ""], ["Wang", "Jindong", ""], ["Yu", "Chaohui", ""], ["Gao", "Wen", ""], ["Qin", "Xin", ""]]}, {"id": "1907.09189", "submitter": "Stefano Albrecht", "authors": "Stefano V. Albrecht, Subramanian Ramamoorthy", "title": "Comparative Evaluation of Multiagent Learning Algorithms in a Diverse\n  Set of Ad Hoc Team Problems", "comments": "Proceedings of the 11th International Conference on Autonomous Agents\n  and Multiagent Systems (AAMAS), 2012. This arXiv version of the original\n  paper published in AAMAS 2012 uses an expanded title to spell out \"MAL\", and\n  is otherwise identical", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper is concerned with evaluating different multiagent learning (MAL)\nalgorithms in problems where individual agents may be heterogenous, in the\nsense of utilizing different learning strategies, without the opportunity for\nprior agreements or information regarding coordination. Such a situation arises\nin ad hoc team problems, a model of many practical multiagent systems\napplications. Prior work in multiagent learning has often been focussed on\nhomogeneous groups of agents, meaning that all agents were identical and a\npriori aware of this fact. Also, those algorithms that are specifically\ndesigned for ad hoc team problems are typically evaluated in teams of agents\nwith fixed behaviours, as opposed to agents which are adapting their\nbehaviours. In this work, we empirically evaluate five MAL algorithms,\nrepresenting major approaches to multiagent learning but originally developed\nwith the homogeneous setting in mind, to understand their behaviour in a set of\nad hoc team problems. All teams consist of agents which are continuously\nadapting their behaviours. The algorithms are evaluated with respect to a\ncomprehensive characterisation of repeated matrix games, using performance\ncriteria that include considerations such as attainment of equilibrium, social\nwelfare and fairness. Our main conclusion is that there is no clear winner.\nHowever, the comparative evaluation also highlights the relative strengths of\ndifferent algorithms with respect to the type of performance criteria, e.g.,\nsocial welfare vs. attainment of equilibrium.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jul 2019 09:01:08 GMT"}], "update_date": "2019-07-23", "authors_parsed": [["Albrecht", "Stefano V.", ""], ["Ramamoorthy", "Subramanian", ""]]}, {"id": "1907.09198", "submitter": "Julian Zilly", "authors": "Andrea Censi, Saverio Bolognani, Julian G. Zilly, Shima Sadat Mousavi,\n  Emilio Frazzoli", "title": "Today Me, Tomorrow Thee: Efficient Resource Allocation in Competitive\n  Settings using Karma Games", "comments": "9 pages, 6 figures, conference paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new type of coordination mechanism among multiple agents for the\nallocation of a finite resource, such as the allocation of time slots for\npassing an intersection. We consider the setting where we associate one counter\nto each agent, which we call karma value, and where there is an established\nmechanism to decide resource allocation based on agents exchanging karma. The\nidea is that agents might be inclined to pass on using resources today, in\nexchange for karma, which will make it easier for them to claim the resource\nuse in the future. To understand whether such a system might work robustly, we\nonly design the protocol and not the agents' policies. We take a game-theoretic\nperspective and compute policies corresponding to Nash equilibria for the game.\nWe find, surprisingly, that the Nash equilibria for a society of\nself-interested agents are very close in social welfare to a centralized\ncooperative solution. These results suggest that many resource allocation\nproblems can have a simple, elegant, and robust solution, assuming the\navailability of a karma accounting mechanism.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jul 2019 09:31:09 GMT"}], "update_date": "2019-07-23", "authors_parsed": [["Censi", "Andrea", ""], ["Bolognani", "Saverio", ""], ["Zilly", "Julian G.", ""], ["Mousavi", "Shima Sadat", ""], ["Frazzoli", "Emilio", ""]]}, {"id": "1907.09209", "submitter": "Leo Cazenille Dr", "authors": "Leo Cazenille, Nicolas Bredeche, Jos\\'e Halloy", "title": "Automatic Calibration of Artificial Neural Networks for Zebrafish\n  Collective Behaviours using a Quality Diversity Algorithm", "comments": "8 pages, 4 figures, 1 table", "journal-ref": "Conference on Biomimetic and Biohybrid Systems. Springer, Cham,\n  2019", "doi": "10.1007/978-3-030-24741-6_4", "report-no": null, "categories": "cs.NE cs.AI q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  During the last two decades, various models have been proposed for fish\ncollective motion. These models are mainly developed to decipher the biological\nmechanisms of social interaction between animals. They consider very simple\nhomogeneous unbounded environments and it is not clear that they can simulate\naccurately the collective trajectories. Moreover when the models are more\naccurate, the question of their scalability to either larger groups or more\nelaborate environments remains open. This study deals with learning how to\nsimulate realistic collective motion of collective of zebrafish, using\nreal-world tracking data. The objective is to devise an agent-based model that\ncan be implemented on an artificial robotic fish that can blend into a\ncollective of real fish. We present a novel approach that uses Quality\nDiversity algorithms, a class of algorithms that emphasise exploration over\npure optimisation. In particular, we use CVT-MAP-Elites, a variant of the\nstate-of-the-art MAP-Elites algorithm for high dimensional search space.\nResults show that Quality Diversity algorithms not only outperform classic\nevolutionary reinforcement learning methods at the macroscopic level (i.e.\ngroup behaviour), but are also able to generate more realistic biomimetic\nbehaviours at the microscopic level (i.e. individual behaviour).\n", "versions": [{"version": "v1", "created": "Mon, 22 Jul 2019 10:04:22 GMT"}], "update_date": "2019-07-23", "authors_parsed": [["Cazenille", "Leo", ""], ["Bredeche", "Nicolas", ""], ["Halloy", "Jos\u00e9", ""]]}, {"id": "1907.09212", "submitter": "Giovambattista Ianni", "authors": "Francesco Calimeri, Giovambattista Ianni, Francesco Pacenza, Simona\n  Perri and Jessica Zangari", "title": "Incremental Answer Set Programming with Overgrounding", "comments": "Paper presented at the 35th International Conference on Logic\n  Programming (ICLP 2019), Las Cruces, New Mexico, USA, 20-25 September 2019,\n  16 pages", "journal-ref": "Theory and Practice of Logic Programming 19 (2019) 957-973", "doi": "10.1017/S1471068419000292", "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Repeated executions of reasoning tasks for varying inputs are necessary in\nmany applicative settings, such as stream reasoning. In this context, we\npropose an incremental grounding approach for the answer set semantics. We\nfocus on the possibility of generating incrementally larger ground logic\nprograms equivalent to a given non-ground one; so called overgrounded programs\ncan be reused in combination with deliberately many different sets of inputs.\nUpdating overgrounded programs requires a small effort, thus making the\ninstantiation of logic programs considerably faster when grounding is repeated\non a series of inputs similar to each other. Notably, the proposed approach\nworks \"under the hood\", relieving designers of logic programs from controlling\ntechnical aspects of grounding engines and answer set systems. In this work we\npresent the theoretical basis of the proposed incremental grounding technique,\nwe illustrate the consequent repeated evaluation strategy and report about our\nexperiments. This paper is under consideration in Theory and Practice of Logic\nProgramming (TPLP).\n", "versions": [{"version": "v1", "created": "Mon, 22 Jul 2019 10:07:47 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Calimeri", "Francesco", ""], ["Ianni", "Giovambattista", ""], ["Pacenza", "Francesco", ""], ["Perri", "Simona", ""], ["Zangari", "Jessica", ""]]}, {"id": "1907.09239", "submitter": "Tom Hanika", "authors": "Maximilian Stubbemann and Tom Hanika and Gerd Stumme", "title": "Orometric Methods in Bounded Metric Data", "comments": "8 Pages, 1 figure", "journal-ref": null, "doi": "10.1007/978-3-030-44584-3_39", "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A large amount of data accommodated in knowledge graphs (KG) is actually\nmetric. For example, the Wikidata KG contains a plenitude of metric facts about\ngeographic entities like cities, chemical compounds or celestial objects. In\nthis paper, we propose a novel approach that transfers orometric (topographic)\nmeasures to bounded metric spaces. While these methods were originally designed\nto identify relevant mountain peaks on the surface of the earth, we demonstrate\na notion to use them for metric data sets in general. Notably, metric sets of\nitems inclosed in knowledge graphs. Based on this we present a method for\nidentifying outstanding items using the transferred valuations functions\n'isolation' and 'prominence'. Building up on this we imagine an item\nrecommendation process. To demonstrate the relevance of the novel valuations\nfor such processes we use item sets from the Wikidata knowledge graph. We then\nevaluate the usefulness of 'isolation' and 'prominence' empirically in a\nsupervised machine learning setting. In particular, we find structurally\nrelevant items in the geographic population distributions of Germany and\nFrance.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jul 2019 11:30:06 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Stubbemann", "Maximilian", ""], ["Hanika", "Tom", ""], ["Stumme", "Gerd", ""]]}, {"id": "1907.09247", "submitter": "Jorge Fandinno", "authors": "Jorge Fandinno", "title": "Founded (Auto)Epistemic Equilibrium Logic Satisfies Epistemic Splitting", "comments": "Paper presented at the 35th International Conference on Logic\n  Programming (ICLP 2019), Las Cruces, New Mexico, USA, 20-25 September 2019,\n  16 pages", "journal-ref": "Theory and Practice of Logic Programming 19 (2019) 671-687", "doi": "10.1017/S1471068419000127", "report-no": null, "categories": "cs.LO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a recent line of research, two familiar concepts from logic programming\nsemantics (unfounded sets and splitting) were extrapolated to the case of\nepistemic logic programs. The property of epistemic splitting provides a\nnatural and modular way to understand programs without epistemic cycles but,\nsurprisingly, was only fulfilled by Gelfond's original semantics (G91), among\nthe many proposals in the literature. On the other hand, G91 may suffer from a\nkind of self-supported, unfounded derivations when epistemic cycles come into\nplay. Recently, the absence of these derivations was also formalised as a\nproperty of epistemic semantics called foundedness. Moreover, a first semantics\nproved to satisfy foundedness was also proposed, the so-called Founded\nAutoepistemic Equilibrium Logic (FAEEL). In this paper, we prove that FAEEL\nalso satisfies the epistemic splitting property something that, together with\nfoundedness, was not fulfilled by any other approach up to date. To prove this\nresult, we provide an alternative characterisation of FAEEL as a combination of\nG91 with a simpler logic we called Founded Epistemic Equilibrium Logic (FEEL),\nwhich is somehow an extrapolation of the stable model semantics to the modal\nlogic S5. Under consideration for acceptance in TPLP.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jul 2019 11:48:15 GMT"}, {"version": "v2", "created": "Thu, 20 Feb 2020 15:33:26 GMT"}], "update_date": "2020-02-21", "authors_parsed": [["Fandinno", "Jorge", ""]]}, {"id": "1907.09273", "submitter": "Arthur Szlam", "authors": "Arthur Szlam, Jonathan Gray, Kavya Srinet, Yacine Jernite, Armand\n  Joulin, Gabriel Synnaeve, Douwe Kiela, Haonan Yu, Zhuoyuan Chen, Siddharth\n  Goyal, Demi Guo, Danielle Rothermel, C. Lawrence Zitnick, Jason Weston", "title": "Why Build an Assistant in Minecraft?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this document we describe a rationale for a research program aimed at\nbuilding an open \"assistant\" in the game Minecraft, in order to make progress\non the problems of natural language understanding and learning from dialogue.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jul 2019 12:32:15 GMT"}, {"version": "v2", "created": "Thu, 25 Jul 2019 21:52:08 GMT"}], "update_date": "2019-07-29", "authors_parsed": [["Szlam", "Arthur", ""], ["Gray", "Jonathan", ""], ["Srinet", "Kavya", ""], ["Jernite", "Yacine", ""], ["Joulin", "Armand", ""], ["Synnaeve", "Gabriel", ""], ["Kiela", "Douwe", ""], ["Yu", "Haonan", ""], ["Chen", "Zhuoyuan", ""], ["Goyal", "Siddharth", ""], ["Guo", "Demi", ""], ["Rothermel", "Danielle", ""], ["Zitnick", "C. Lawrence", ""], ["Weston", "Jason", ""]]}, {"id": "1907.09278", "submitter": "Frans A. Oliehoek", "authors": "Frans A. Oliehoek, Stefan Witwicki, Leslie P. Kaelbling", "title": "A Sufficient Statistic for Influence in Structured Multiagent\n  Environments", "comments": null, "journal-ref": "Journal of Artificial Intelligence Research, pp. 789-870, AI\n  Access Foundation, Inc., February 2021", "doi": "10.1613/jair.1.12136", "report-no": null, "categories": "cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Making decisions in complex environments is a key challenge in artificial\nintelligence (AI). Situations involving multiple decision makers are\nparticularly complex, leading to computational intractability of principled\nsolution methods. A body of work in AI has tried to mitigate this problem by\ntrying to distill interaction to its essence: how does the policy of one agent\ninfluence another agent? If we can find more compact representations of such\ninfluence, this can help us deal with the complexity, for instance by searching\nthe space of influences rather than the space of policies. However, so far\nthese notions of influence have been restricted in their applicability to\nspecial cases of interaction. In this paper we formalize influence-based\nabstraction (IBA), which facilitates the elimination of latent state factors\nwithout any loss in value, for a very general class of problems described as\nfactored partially observable stochastic games (fPOSGs). On the one hand, this\ngeneralizes existing descriptions of influence, and thus can serve as the\nfoundation for improvements in scalability and other insights in decision\nmaking in complex multiagent settings. On the other hand, since the presence of\nother agents can be seen as a generalization of single agent settings, our\nformulation of IBA also provides a sufficient statistic for decision making\nunder abstraction for a single agent. We also give a detailed discussion of the\nrelations to such previous works, identifying new insights and interpretations\nof these approaches. In these ways, this paper deepens our understanding of\nabstraction in a wide range of sequential decision making settings, providing\nthe basis for new approaches and algorithms for a large class of problems.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jul 2019 12:39:48 GMT"}, {"version": "v2", "created": "Mon, 1 Mar 2021 14:26:10 GMT"}], "update_date": "2021-03-02", "authors_parsed": [["Oliehoek", "Frans A.", ""], ["Witwicki", "Stefan", ""], ["Kaelbling", "Leslie P.", ""]]}, {"id": "1907.09279", "submitter": "Simon Rey", "authors": "Haris Aziz and Simon Rey", "title": "Almost Group Envy-free Allocation of Indivisible Goods and Chores", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a multi-agent resource allocation setting in which an agent's\nutility may decrease or increase when an item is allocated. We take the group\nenvy-freeness concept that is well-established in the literature and present\nstronger and relaxed versions that are especially suitable for the allocation\nof indivisible items. Of particular interest is a concept called group\nenvy-freeness up to one item (GEF1). We then present a clear taxonomy of the\nfairness concepts. We study which fairness concepts guarantee the existence of\na fair allocation under which preference domain. For two natural classes of\nadditive utilities, we design polynomial-time algorithms to compute a GEF1\nallocation. We also prove that checking whether a given allocation satisfies\nGEF1 is coNP-complete when there are either only goods, only chores or both.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jul 2019 23:46:59 GMT"}], "update_date": "2019-07-23", "authors_parsed": [["Aziz", "Haris", ""], ["Rey", "Simon", ""]]}, {"id": "1907.09285", "submitter": "Clement Leroy", "authors": "Clement Leroy, Eric Anquetil, Nathalie Girard", "title": "ParaFIS:A new online fuzzy inference system based on parallel drift\n  anticipation", "comments": null, "journal-ref": "FUZZ-IEEE, Jun 2019, New Orleans, United States", "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a new architecture of incremen-tal fuzzy inference system\n(also called Evolving Fuzzy System-EFS). In the context of classifying data\nstream in non stationary environment, concept drifts problems must be\naddressed. Several studies have shown that EFS can deal with such environment\nthanks to their high structural flexibility. These EFS perform well with smooth\ndrift (or incremental drift). The new architecture we propose is focused on\nimproving the processing of brutal changes in the data distribution (often\ncalled brutal concept drift). More precisely, a generalized EFS is paired with\na module of anticipation to improve the adaptation of new rules after a brutal\ndrift. The proposed architecture is evaluated on three datasets from UCI\nrepository where artificial brutal drifts have been applied. A fit model is\nalso proposed to get a \"reactivity time\" needed to converge to the steady-state\nand the score at end. Both characteristics are compared between the same system\nwith and without anticipation and with a similar EFS from state-of-the-art. The\nexperiments demonstrates improvements in both cases.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jul 2019 08:30:59 GMT"}], "update_date": "2019-07-23", "authors_parsed": [["Leroy", "Clement", ""], ["Anquetil", "Eric", ""], ["Girard", "Nathalie", ""]]}, {"id": "1907.09293", "submitter": "David Powers", "authors": "David M W Powers", "title": "DREAMT -- Embodied Motivational Conversational Storytelling", "comments": "12 pages; to be presented as lightning talk plus poster at StoryNLP\n  on 1 August 2019 at ACL in Florence - poster pdf and powerpoint available", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.HC cs.MA cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Storytelling is fundamental to language, including culture, conversation and\ncommunication in their broadest senses. It thus emerges as an essential\ncomponent of intelligent systems, including systems where natural language is\nnot a primary focus or where we do not usually think of a story being involved.\nIn this paper we explore the emergence of storytelling as a requirement in\nembodied conversational agents, including its role in educational and health\ninterventions, as well as in a general-purpose computer interface for people\nwith disabilities or other constraints that prevent the use of traditional\nkeyboard and speech interfaces. We further present a characterization of\nstorytelling as an inventive fleshing out of detail according to a particular\npersonal perspective, and propose the DREAMT model to focus attention on the\ndifferent layers that need to be present in a character-driven storytelling\nsystem. Most if not all aspects of the DREAMT model have arisen from or been\nexplored in some aspect of our implemented research systems, but currently only\nat a primitive and relatively unintegrated level. However, this experience\nleads us to formalize and elaborate the DREAMT model mnemonically as follows: -\nDescription/Dialogue/Definition/Denotation - Realization/Representation/Role -\nExplanation/Education/Entertainment - Actualization/Activation -\nMotivation/Modelling - Topicalization/Transformation\n", "versions": [{"version": "v1", "created": "Fri, 19 Jul 2019 01:49:37 GMT"}], "update_date": "2019-07-23", "authors_parsed": [["Powers", "David M W", ""]]}, {"id": "1907.09294", "submitter": "Thibault Laugel", "authors": "Thibault Laugel, Marie-Jeanne Lesot, Christophe Marsala, Xavier\n  Renard, Marcin Detyniecki", "title": "The Dangers of Post-hoc Interpretability: Unjustified Counterfactual\n  Explanations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Post-hoc interpretability approaches have been proven to be powerful tools to\ngenerate explanations for the predictions made by a trained black-box model.\nHowever, they create the risk of having explanations that are a result of some\nartifacts learned by the model instead of actual knowledge from the data. This\npaper focuses on the case of counterfactual explanations and asks whether the\ngenerated instances can be justified, i.e. continuously connected to some\nground-truth data. We evaluate the risk of generating unjustified\ncounterfactual examples by investigating the local neighborhoods of instances\nwhose predictions are to be explained and show that this risk is quite high for\nseveral datasets. Furthermore, we show that most state of the art approaches do\nnot differentiate justified from unjustified counterfactual examples, leading\nto less useful explanations.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jul 2019 13:10:24 GMT"}], "update_date": "2021-04-14", "authors_parsed": [["Laugel", "Thibault", ""], ["Lesot", "Marie-Jeanne", ""], ["Marsala", "Christophe", ""], ["Renard", "Xavier", ""], ["Detyniecki", "Marcin", ""]]}, {"id": "1907.09309", "submitter": "Amir Mosavi", "authors": "Shahaboddin Shamshirband, Amir Mosavi, Kwok-wing Chau", "title": "Sensitivity study of ANFIS model parameters to predict the pressure\n  gradient with combined input and outputs hydrodynamics parameters in the\n  bubble column reactor", "comments": "48 pages, 14 figures, journal paper preprint", "journal-ref": null, "doi": "10.20944/preprints201905.0044.v1", "report-no": null, "categories": "cs.AI cs.CE cs.CG cs.NA math.NA", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Intelligent algorithms are recently used in the optimization process in\nchemical engineering and application of multiphase flows such as bubbling flow.\nThis overview of modeling can be a great replacement with complex numerical\nmethods or very time-consuming and disruptive measurement experimental process.\nIn this study, we develop the adaptive network-based fuzzy inference system\n(ANFIS) method for mapping inputs and outputs together and understand the\nbehavior of the fluid flow from other output parameters of the bubble column\nreactor. Neural cells can fully learn the process in their memory and after the\ntraining stage, the fuzzy structure predicts the multiphase flow data. Four\ninputs such as x coordinate, y coordinate, z coordinate, and air superficial\nvelocity and one output such as pressure gradient are considered in the\nlearning process of the ANFIS method. During the learning process, the\ndifferent number of the membership function, type of membership functions and\nthe number of inputs are examined to achieve the intelligent algorithm with\nhigh accuracy. The results show that as the number of inputs increases the\naccuracy of the ANFIS method rises up to R^2>0.99 almost for all cases, while\nthe increment in the number of rules has a effect on the intelligence of\nartificial algorithm. This finding shows that the density of neural objects or\nhigher input parameters enables the moded for better understanding. We also\nproposed a new evaluation of data in the bubble column reactor by mapping\ninputs and outputs and shuffle all parameters together to understand the\nbehaviour of the multiphase flow as a function of either inputs or outputs.\nThis new process of mapping inputs and outputs data provides a framework to\nfully understand the flow in the fluid domain in a short time of fuzzy\nstructure calculation.\n", "versions": [{"version": "v1", "created": "Fri, 19 Jul 2019 13:01:32 GMT"}], "update_date": "2019-07-23", "authors_parsed": [["Shamshirband", "Shahaboddin", ""], ["Mosavi", "Amir", ""], ["Chau", "Kwok-wing", ""]]}, {"id": "1907.09319", "submitter": "Taylan \\c{S}ahin", "authors": "Taylan \\c{S}ahin, Ramin Khalili, Mate Boban, Adam Wolisz", "title": "VRLS: A Unified Reinforcement Learning Scheduler for Vehicle-to-Vehicle\n  Communications", "comments": "Article accepted to IEEE CAVS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.AI cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Vehicle-to-vehicle (V2V) communications have distinct challenges that need to\nbe taken into account when scheduling the radio resources. Although centralized\nschedulers (e.g., located on base stations) could be utilized to deliver high\nscheduling performance, they cannot be employed in case of coverage gaps. To\naddress the issue of reliable scheduling of V2V transmissions out of coverage,\nwe propose Vehicular Reinforcement Learning Scheduler (VRLS), a centralized\nscheduler that predictively assigns the resources for V2V communication while\nthe vehicle is still in cellular network coverage. VRLS is a unified\nreinforcement learning (RL) solution, wherein the learning agent, the state\nrepresentation, and the reward provided to the agent are applicable to\ndifferent vehicular environments of interest (in terms of vehicular density,\nresource configuration, and wireless channel conditions). Such a unified\nsolution eliminates the necessity of redesigning the RL components for a\ndifferent environment, and facilitates transfer learning from one to another\nsimilar environment. We evaluate the performance of VRLS and show its ability\nto avoid collisions and half-duplex errors, and to reuse the resources better\nthan the state of the art scheduling algorithms. We also show that pre-trained\nVRLS agent can adapt to different V2V environments with limited retraining,\nthus enabling real-world deployment in different scenarios.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jul 2019 13:42:51 GMT"}], "update_date": "2019-07-23", "authors_parsed": [["\u015eahin", "Taylan", ""], ["Khalili", "Ramin", ""], ["Boban", "Mate", ""], ["Wolisz", "Adam", ""]]}, {"id": "1907.09361", "submitter": "Nilesh Chakraborty", "authors": "Nilesh Chakraborty, Denis Lukovnikov, Gaurav Maheshwari, Priyansh\n  Trivedi, Jens Lehmann, Asja Fischer", "title": "Introduction to Neural Network based Approaches for Question Answering\n  over Knowledge Graphs", "comments": "Preprint, under review. The first four authors contributed equally to\n  this paper, and should be regarded as co-first authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Question answering has emerged as an intuitive way of querying structured\ndata sources, and has attracted significant advancements over the years. In\nthis article, we provide an overview over these recent advancements, focusing\non neural network based question answering systems over knowledge graphs. We\nintroduce readers to the challenges in the tasks, current paradigms of\napproaches, discuss notable advancements, and outline the emerging trends in\nthe field. Through this article, we aim to provide newcomers to the field with\na suitable entry point, and ease their process of making informed decisions\nwhile creating their own QA system.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jul 2019 14:57:13 GMT"}], "update_date": "2019-07-23", "authors_parsed": [["Chakraborty", "Nilesh", ""], ["Lukovnikov", "Denis", ""], ["Maheshwari", "Gaurav", ""], ["Trivedi", "Priyansh", ""], ["Lehmann", "Jens", ""], ["Fischer", "Asja", ""]]}, {"id": "1907.09402", "submitter": "Carmine Dodaro", "authors": "Giovanni Amendola, Carmine Dodaro, Marco Maratea", "title": "Abstract Solvers for Computing Cautious Consequences of ASP programs", "comments": "Paper presented at the 35th International Conference on Logic\n  Programming (ICLP 2019), Las Cruces, New Mexico, USA, 20-25 September 2019,\n  20 pages", "journal-ref": "Theory and Practice of Logic Programming 19 (2019) 740-756", "doi": "10.1017/S1471068419000164", "report-no": null, "categories": "cs.LO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Abstract solvers are a method to formally analyze algorithms that have been\nprofitably used for describing, comparing and composing solving techniques in\nvarious fields such as Propositional Satisfiability (SAT), Quantified SAT,\nSatisfiability Modulo Theories, Answer Set Programming (ASP), and Constraint\nASP. In this paper, we design, implement and test novel abstract solutions for\ncautious reasoning tasks in ASP. We show how to improve the current abstract\nsolvers for cautious reasoning in ASP with new techniques borrowed from\nbackbone computation in SAT, in order to design new solving algorithms. By\ndoing so, we also formally show that the algorithms for solving cautious\nreasoning tasks in ASP are strongly related to those for computing backbones of\nBoolean formulas. We implement some of the new solutions in the ASP solver WASP\nand show that their performance are comparable to state-of-the-art solutions on\nthe benchmark problems from the past ASP Competitions. Under consideration for\nacceptance in TPLP.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jul 2019 16:25:11 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Amendola", "Giovanni", ""], ["Dodaro", "Carmine", ""], ["Maratea", "Marco", ""]]}, {"id": "1907.09426", "submitter": "Francesco Ricca", "authors": "Giovanni Amendola, Francesco Ricca", "title": "Paracoherent Answer Set Semantics meets Argumentation Frameworks", "comments": "Paper presented at the 35th International Conference on Logic\n  Programming (ICLP 2019), Las Cruces, New Mexico, USA, 20-25 September 2019,\n  16 pages", "journal-ref": "Theory and Practice of Logic Programming 19 (2019) 688-704", "doi": "10.1017/S1471068419000139", "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the last years, abstract argumentation has met with great success in AI,\nsince it has served to capture several non-monotonic logics for AI. Relations\nbetween argumentation framework (AF) semantics and logic programming ones are\ninvestigating more and more. In particular, great attention has been given to\nthe well-known stable extensions of an AF, that are closely related to the\nanswer sets of a logic program. However, if a framework admits a small\nincoherent part, no stable extension can be provided. To overcome this\nshortcoming, two semantics generalizing stable extensions have been studied,\nnamely semi-stable and stage. In this paper, we show that another perspective\nis possible on incoherent AFs, called paracoherent extensions, as they have a\ncounterpart in paracoherent answer set semantics. We compare this perspective\nwith semi-stable and stage semantics, by showing that computational costs\nremain unchanged, and moreover an interesting symmetric behaviour is\nmaintained. Under consideration for acceptance in TPLP.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jul 2019 16:53:33 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Amendola", "Giovanni", ""], ["Ricca", "Francesco", ""]]}, {"id": "1907.09466", "submitter": "Elaheh Barati", "authors": "Elaheh Barati and Xuewen Chen", "title": "An Actor-Critic-Attention Mechanism for Deep Reinforcement Learning in\n  Multi-view Environments", "comments": "The 28th International Joint Conference on Artificial Intelligence\n  (IJCAI'19). arXiv admin note: text overlap with arXiv:1905.03985", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In reinforcement learning algorithms, leveraging multiple views of the\nenvironment can improve the learning of complicated policies. In multi-view\nenvironments, due to the fact that the views may frequently suffer from partial\nobservability, their level of importance are often different. In this paper, we\npropose a deep reinforcement learning method and an attention mechanism in a\nmulti-view environment. Each view can provide various representative\ninformation about the environment. Through our attention mechanism, our method\ngenerates a single feature representation of environment given its multiple\nviews. It learns a policy to dynamically attend to each view based on its\nimportance in the decision-making process. Through experiments, we show that\nour method outperforms its state-of-the-art baselines on TORCS racing car\nsimulator and three other complex 3D environments with obstacles. We also\nprovide experimental results to evaluate the performance of our method on noisy\nconditions and partial observation settings.\n", "versions": [{"version": "v1", "created": "Fri, 19 Jul 2019 19:38:02 GMT"}], "update_date": "2019-07-24", "authors_parsed": [["Barati", "Elaheh", ""], ["Chen", "Xuewen", ""]]}, {"id": "1907.09467", "submitter": "Qing Wang", "authors": "Qing Wang, Jiechao Xiong, Lei Han, Meng Fang, Xinghai Sun, Zhuobin\n  Zheng, Peng Sun, Zhengyou Zhang", "title": "Arena: a toolkit for Multi-Agent Reinforcement Learning", "comments": "21 pages, 14 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce Arena, a toolkit for multi-agent reinforcement learning (MARL)\nresearch. In MARL, it usually requires customizing observations, rewards and\nactions for each agent, changing cooperative-competitive agent-interaction, and\nplaying with/against a third-party agent, etc. We provide a novel modular\ndesign, called Interface, for manipulating such routines in essentially two\nways: 1) Different interfaces can be concatenated and combined, which extends\nthe OpenAI Gym Wrappers concept to MARL scenarios. 2) During MARL training or\ntesting, interfaces can be embedded in either wrapped OpenAI Gym compatible\nEnvironments or raw environment compatible Agents. We offer off-the-shelf\ninterfaces for several popular MARL platforms, including StarCraft II,\nPommerman, ViZDoom, Soccer, etc. The interfaces effectively support self-play\nRL and cooperative-competitive hybrid MARL. Also, Arena can be conveniently\nextended to your own favorite MARL platform.\n", "versions": [{"version": "v1", "created": "Sat, 20 Jul 2019 05:13:53 GMT"}], "update_date": "2019-07-24", "authors_parsed": [["Wang", "Qing", ""], ["Xiong", "Jiechao", ""], ["Han", "Lei", ""], ["Fang", "Meng", ""], ["Sun", "Xinghai", ""], ["Zheng", "Zhuobin", ""], ["Sun", "Peng", ""], ["Zhang", "Zhengyou", ""]]}, {"id": "1907.09468", "submitter": "Robert Manger", "authors": "Marko \\v{S}poljarec, Robert Manger", "title": "Heuristic solutions to robust variants of the minimum-cost integer flow\n  problem", "comments": null, "journal-ref": "Journal of Heuristics, 2020", "doi": "10.1007/s10732-020-09441-1", "report-no": null, "categories": "cs.AI cs.NE math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper deals with robust optimization applied to network flows. Two\nrobust variants of the minimum-cost integer flow problem are considered.\nThereby, uncertainty in problem formulation is limited to arc unit costs and\nexpressed by a finite set of explicitly given scenarios. It is shown that both\nproblem variants are NP-hard. To solve the considered variants, several\nheuristics based on local search or evolutionary computing are proposed. The\nheuristics are experimentally evaluated on appropriate problem instances.\n", "versions": [{"version": "v1", "created": "Sun, 21 Jul 2019 10:11:09 GMT"}], "update_date": "2020-02-27", "authors_parsed": [["\u0160poljarec", "Marko", ""], ["Manger", "Robert", ""]]}, {"id": "1907.09470", "submitter": "Xinlei Pan", "authors": "Chaowei Xiao, Xinlei Pan, Warren He, Jian Peng, Mingjie Sun, Jinfeng\n  Yi, Mingyan Liu, Bo Li, Dawn Song", "title": "Characterizing Attacks on Deep Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep reinforcement learning (DRL) has achieved great success in various\napplications. However, recent studies show that machine learning models are\nvulnerable to adversarial attacks. DRL models have been attacked by adding\nperturbations to observations. While such observation based attack is only one\naspect of potential attacks on DRL, other forms of attacks which are more\npractical require further analysis, such as manipulating environment dynamics.\nTherefore, we propose to understand the vulnerabilities of DRL from various\nperspectives and provide a thorough taxonomy of potential attacks. We conduct\nthe first set of experiments on the unexplored parts within the taxonomy. In\naddition to current observation based attacks against DRL, we propose the first\ntargeted attacks based on action space and environment dynamics. We also\nintroduce the online sequential attacks based on temporal consistency\ninformation among frames. To better estimate gradient in black-box setting, we\npropose a sampling strategy and theoretically prove its efficiency and\nestimation error bound. We conduct extensive experiments to compare the\neffectiveness of different attacks with several baselines in various\nenvironments, including game playing, robotics control, and autonomous driving.\n", "versions": [{"version": "v1", "created": "Sun, 21 Jul 2019 22:00:24 GMT"}, {"version": "v2", "created": "Wed, 24 Jul 2019 07:46:39 GMT"}], "update_date": "2019-07-25", "authors_parsed": [["Xiao", "Chaowei", ""], ["Pan", "Xinlei", ""], ["He", "Warren", ""], ["Peng", "Jian", ""], ["Sun", "Mingjie", ""], ["Yi", "Jinfeng", ""], ["Liu", "Mingyan", ""], ["Li", "Bo", ""], ["Song", "Dawn", ""]]}, {"id": "1907.09472", "submitter": "EPTCS", "authors": "Alexandru Baltag, Soroush Rafiee Rad, Sonja Smets", "title": "Learning Probabilities: Towards a Logic of Statistical Learning", "comments": "In Proceedings TARK 2019, arXiv:1907.08335", "journal-ref": "EPTCS 297, 2019, pp. 35-49", "doi": "10.4204/EPTCS.297.3", "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new model for forming beliefs and learning about unknown\nprobabilities (such as the probability of picking a red marble from a bag with\nan unknown distribution of coloured marbles). The most widespread model for\nsuch situations of 'radical uncertainty' is in terms of imprecise\nprobabilities, i.e. representing the agent's knowledge as a set of probability\nmeasures. We add to this model a plausibility map, associating to each measure\na plausibility number, as a way to go beyond what is known with certainty and\nrepresent the agent's beliefs about probability. There are a number of standard\nexamples: Shannon Entropy, Centre of Mass etc. We then consider learning of two\ntypes of information: (1) learning by repeated sampling from the unknown\ndistribution (e.g. picking marbles from the bag); and (2) learning higher-order\ninformation about the distribution (in the shape of linear inequalities, e.g.\nwe are told there are more red marbles than green marbles). The first changes\nonly the plausibility map (via a 'plausibilistic' version of Bayes' Rule), but\nleaves the given set of measures unchanged; the second shrinks the set of\nmeasures, without changing their plausibility. Beliefs are defined as in Belief\nRevision Theory, in terms of truth in the most plausible worlds. But our belief\nchange does not comply with standard AGM axioms, since the revision induced by\n(1) is of a non-AGM type. This is essential, as it allows our agents to learn\nthe true probability: we prove that the beliefs obtained by repeated sampling\nconverge almost surely to the correct belief (in the true probability). We end\nby sketching the contours of a dynamic doxastic logic for statistical learning.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jul 2019 03:13:04 GMT"}], "update_date": "2019-07-24", "authors_parsed": [["Baltag", "Alexandru", ""], ["Rad", "Soroush Rafiee", ""], ["Smets", "Sonja", ""]]}, {"id": "1907.09475", "submitter": "Siqi Liu", "authors": "Siqi Liu, Kee Yuan Ngiam, Mengling Feng", "title": "Deep Reinforcement Learning for Clinical Decision Support: A Brief\n  Survey", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Owe to the recent advancements in Artificial Intelligence especially deep\nlearning, many data-driven decision support systems have been implemented to\nfacilitate medical doctors in delivering personalized care. We focus on the\ndeep reinforcement learning (DRL) models in this paper. DRL models have\ndemonstrated human-level or even superior performance in the tasks of computer\nvision and game playings, such as Go and Atari game. However, the adoption of\ndeep reinforcement learning techniques in clinical decision optimization is\nstill rare. We present the first survey that summarizes reinforcement learning\nalgorithms with Deep Neural Networks (DNN) on clinical decision support. We\nalso discuss some case studies, where different DRL algorithms were applied to\naddress various clinical challenges. We further compare and contrast the\nadvantages and limitations of various DRL algorithms and present a preliminary\nguide on how to choose the appropriate DRL algorithm for particular clinical\napplications.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jul 2019 14:44:25 GMT"}], "update_date": "2019-07-24", "authors_parsed": [["Liu", "Siqi", ""], ["Ngiam", "Kee Yuan", ""], ["Feng", "Mengling", ""]]}, {"id": "1907.09520", "submitter": "Benedikt Z\\\"onnchen", "authors": "Benedikt Kleinmeier, Benedikt Z\\\"onnchen, Marion G\\\"odel, Gerta\n  K\\\"oster", "title": "Vadere: An open-source simulation framework to promote interdisciplinary\n  understanding", "comments": "submitted to Collective Dynamics", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.MA", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Pedestrian dynamics is an interdisciplinary field of research. Psychologists,\nsociologists, traffic engineers, physicists, mathematicians and computer\nscientists all strive to understand the dynamics of a moving crowd. In\nprinciple, computer simulations offer means to further this understanding. Yet,\nunlike for many classic dynamical systems in physics, there is no universally\naccepted locomotion model for crowd dynamics. On the contrary, a multitude of\napproaches, with very different characteristics, compete. Often only the\nexperts in one special model type are able to assess the consequences these\ncharacteristics have on a simulation study. Therefore, scientists from all\ndisciplines who wish to use simulations to analyze pedestrian dynamics need a\ntool to compare competing approaches. Developers, too, would profit from an\neasy way to get insight into an alternative modeling ansatz. Vadere meets this\ninterdisciplinary demand by offering an open-source simulation framework that\nis lightweight in its approach and in its user interface while offering\npre-implemented versions of the most widely spread models.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jul 2019 12:24:40 GMT"}], "update_date": "2019-07-24", "authors_parsed": [["Kleinmeier", "Benedikt", ""], ["Z\u00f6nnchen", "Benedikt", ""], ["G\u00f6del", "Marion", ""], ["K\u00f6ster", "Gerta", ""]]}, {"id": "1907.09527", "submitter": "Vrindavan Harrison", "authors": "Vrindavan Harrison, Lena Reed, Shereen Oraby, Marilyn Walker", "title": "Maximizing Stylistic Control and Semantic Accuracy in NLG: Personality\n  Variation and Discourse Contrast", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural generation methods for task-oriented dialogue typically generate from\na meaning representation that is populated using a database of domain\ninformation, such as a table of data describing a restaurant. While earlier\nwork focused solely on the semantic fidelity of outputs, recent work has\nstarted to explore methods for controlling the style of the generated text\nwhile simultaneously achieving semantic accuracy. Here we experiment with two\nstylistic benchmark tasks, generating language that exhibits variation in\npersonality, and generating discourse contrast. We report a huge performance\nimprovement in both stylistic control and semantic accuracy over the state of\nthe art on both of these benchmarks. We test several different models and show\nthat putting stylistic conditioning in the decoder and eliminating the semantic\nre-ranker used in earlier models results in more than 15 points higher BLEU for\nPersonality, with a reduction of semantic error to near zero. We also report an\nimprovement from .75 to .81 in controlling contrast and a reduction in semantic\nerror from 16% to 2%.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jul 2019 18:57:14 GMT"}], "update_date": "2019-07-24", "authors_parsed": [["Harrison", "Vrindavan", ""], ["Reed", "Lena", ""], ["Oraby", "Shereen", ""], ["Walker", "Marilyn", ""]]}, {"id": "1907.09548", "submitter": "Jo\\~ao Alc\\^antara", "authors": "Jo\\~ao Alc\\^antara and Samy S\\'a and Juan Acosta-Guadarrama", "title": "On the Equivalence Between Abstract Dialectical Frameworks and Logic\n  Programs", "comments": "Paper presented at the 35th International Conference on Logic\n  Programming (ICLP 2019), Las Cruces, New Mexico, USA, 20-25 September 2019,\n  16 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Abstract Dialectical Frameworks (ADFs) are argumentation frameworks where\neach node is associated with an acceptance condition. This allows us to model\ndifferent types of dependencies as supports and attacks. Previous studies\nprovided a translation from Normal Logic Programs (NLPs) to ADFs and proved the\nstable models semantics for a normal logic program has an equivalent semantics\nto that of the corresponding ADF. However, these studies failed in identifying\na semantics for ADFs equivalent to a three-valued semantics (as partial stable\nmodels and well-founded models) for NLPs. In this work, we focus on a fragment\nof ADFs, called Attacking Dialectical Frameworks (ADF$^+$s), and provide a\ntranslation from NLPs to ADF$^+$s robust enough to guarantee the equivalence\nbetween partial stable models, well-founded models, regular models, stable\nmodels semantics for NLPs and respectively complete models, grounded models,\npreferred models, stable models for ADFs. In addition, we define a new\nsemantics for ADF$^+$s, called L-stable, and show it is equivalent to the\nL-stable semantics for NLPs. This paper is under consideration for acceptance\nin TPLP.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jul 2019 19:54:20 GMT"}], "update_date": "2019-07-24", "authors_parsed": [["Alc\u00e2ntara", "Jo\u00e3o", ""], ["S\u00e1", "Samy", ""], ["Acosta-Guadarrama", "Juan", ""]]}, {"id": "1907.09559", "submitter": "Giovanni Amendola", "authors": "Giovanni Amendola, Francesco Ricca, Mirek Truszczynski", "title": "Beyond NP: Quantifying over Answer Sets", "comments": "Paper presented at the 35th International Conference on Logic\n  Programming (ICLP 2019), Las Cruces, New Mexico, USA, 20-25 September 2019,\n  16 pages", "journal-ref": "Theory and Practice of Logic Programming 19 (2019) 705-721", "doi": "10.1017/S1471068419000140", "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Answer Set Programming (ASP) is a logic programming paradigm featuring a\npurely declarative language with comparatively high modeling capabilities.\nIndeed, ASP can model problems in NP in a compact and elegant way. However,\nmodeling problems beyond NP with ASP is known to be complicated, on the one\nhand, and limited to problems in {\\Sigma}^P_2 on the other. Inspired by the way\nQuantified Boolean Formulas extend SAT formulas to model problems beyond NP, we\npropose an extension of ASP that introduces quantifiers over stable models of\nprograms. We name the new language ASP with Quantifiers (ASP(Q)). In the paper\nwe identify computational properties of ASP(Q); we highlight its modeling\ncapabilities by reporting natural encodings of several complex problems with\napplications in artificial intelligence and number theory; and we compare\nASP(Q) with related languages. Arguably, ASP(Q) allows one to model problems in\nthe Polynomial Hierarchy in a direct way, providing an elegant expansion of ASP\nbeyond the class NP. Under consideration for acceptance in TPLP.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jul 2019 20:25:58 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Amendola", "Giovanni", ""], ["Ricca", "Francesco", ""], ["Truszczynski", "Mirek", ""]]}, {"id": "1907.09560", "submitter": "Carmine Dodaro", "authors": "Giovanni Amendola, Carmine Dodaro, Francesco Ricca", "title": "Better Paracoherent Answer Sets with Less Resources", "comments": "Paper presented at the 35th International Conference on Logic\n  Programming (ICLP 2019), Las Cruces, New Mexico, USA, 20-25 September 2019,\n  15 pages", "journal-ref": "Theory and Practice of Logic Programming 19 (2019) 757-772", "doi": "10.1017/S1471068419000176", "report-no": null, "categories": "cs.LO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Answer Set Programming (ASP) is a well-established formalism for logic\nprogramming. Problem solving in ASP requires to write an ASP program whose\nanswers sets correspond to solutions. Albeit the non-existence of answer sets\nfor some ASP programs can be considered as a modeling feature, it turns out to\nbe a weakness in many other cases, and especially for query answering.\nParacoherent answer set semantics extend the classical semantics of ASP to draw\nmeaningful conclusions also from incoherent programs, with the result of\nincreasing the range of applications of ASP. State of the art implementations\nof paracoherent ASP adopt the semi-equilibrium semantics, but cannot be lifted\nstraightforwardly to compute efficiently the (better) split semi-equilibrium\nsemantics that discards undesirable semi-equilibrium models. In this paper an\nefficient evaluation technique for computing a split semi-equilibrium model is\npresented. An experiment on hard benchmarks shows that better paracoherent\nanswer sets can be computed consuming less computational resources than\nexisting methods. Under consideration for acceptance in TPLP.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jul 2019 20:27:43 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Amendola", "Giovanni", ""], ["Dodaro", "Carmine", ""], ["Ricca", "Francesco", ""]]}, {"id": "1907.09620", "submitter": "Kelsey Allen", "authors": "Kelsey R. Allen, Kevin A. Smith, Joshua B. Tenenbaum", "title": "Rapid trial-and-error learning with simulation supports flexible tool\n  use and physical reasoning", "comments": "This manuscript is in press at PNAS. It is an extended version of a\n  paper \"Rapid Trial-and-Error Learning in Physical Problem Solving\" accepted\n  for oral presentation at the 41st Annual Meeting of the Cognitive Science\n  Society (2019). It represents ongoing work on the part of the authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many animals, and an increasing number of artificial agents, display\nsophisticated capabilities to perceive and manipulate objects. But human beings\nremain distinctive in their capacity for flexible, creative tool use -- using\nobjects in new ways to act on the world, achieve a goal, or solve a problem. To\nstudy this type of general physical problem solving, we introduce the Virtual\nTools game. In this game, people solve a large range of challenging physical\npuzzles in just a handful of attempts. We propose that the flexibility of human\nphysical problem solving rests on an ability to imagine the effects of\nhypothesized actions, while the efficiency of human search arises from rich\naction priors which are updated via observations of the world. We instantiate\nthese components in the \"Sample, Simulate, Update\" (SSUP) model and show that\nit captures human performance across 30 levels of the Virtual Tools game. More\nbroadly, this model provides a mechanism for explaining how people condense\ngeneral physical knowledge into actionable, task-specific plans to achieve\nflexible and efficient physical problem-solving.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jul 2019 22:49:27 GMT"}, {"version": "v2", "created": "Thu, 25 Jul 2019 18:15:30 GMT"}, {"version": "v3", "created": "Mon, 29 Jun 2020 17:05:56 GMT"}], "update_date": "2020-06-30", "authors_parsed": [["Allen", "Kelsey R.", ""], ["Smith", "Kevin A.", ""], ["Tenenbaum", "Joshua B.", ""]]}, {"id": "1907.09633", "submitter": "Trevor Davis", "authors": "Trevor Davis, Martin Schmid, Michael Bowling", "title": "Low-Variance and Zero-Variance Baselines for Extensive-Form Games", "comments": "Under review for NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Extensive-form games (EFGs) are a common model of multi-agent interactions\nwith imperfect information. State-of-the-art algorithms for solving these games\ntypically perform full walks of the game tree that can prove prohibitively slow\nin large games. Alternatively, sampling-based methods such as Monte Carlo\nCounterfactual Regret Minimization walk one or more trajectories through the\ntree, touching only a fraction of the nodes on each iteration, at the expense\nof requiring more iterations to converge due to the variance of sampled values.\nIn this paper, we extend recent work that uses baseline estimates to reduce\nthis variance. We introduce a framework of baseline-corrected values in EFGs\nthat generalizes the previous work. Within our framework, we propose new\nbaseline functions that result in significantly reduced variance compared to\nexisting techniques. We show that one particular choice of such a function ---\npredictive baseline --- is provably optimal under certain sampling schemes.\nThis allows for efficient computation of zero-variance value estimates even\nalong sampled trajectories.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jul 2019 23:46:39 GMT"}], "update_date": "2019-07-24", "authors_parsed": [["Davis", "Trevor", ""], ["Schmid", "Martin", ""], ["Bowling", "Michael", ""]]}, {"id": "1907.09671", "submitter": "David Gaddy", "authors": "David Gaddy and Dan Klein", "title": "Pre-Learning Environment Representations for Data-Efficient Neural\n  Instruction Following", "comments": "ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of learning to map from natural language instructions\nto state transitions (actions) in a data-efficient manner. Our method takes\ninspiration from the idea that it should be easier to ground language to\nconcepts that have already been formed through pre-linguistic observation. We\naugment a baseline instruction-following learner with an initial\nenvironment-learning phase that uses observations of language-free state\ntransitions to induce a suitable latent representation of actions before\nprocessing the instruction-following training data. We show that mapping to\npre-learned representations substantially improves performance over systems\nwhose representations are learned from limited instructional data alone.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jul 2019 03:11:07 GMT"}], "update_date": "2019-07-24", "authors_parsed": [["Gaddy", "David", ""], ["Klein", "Dan", ""]]}, {"id": "1907.09692", "submitter": "Boyuan Pan", "authors": "Boyuan Pan, Yazheng Yang, Zhou Zhao, Yueting Zhuang, Deng Cai, Xiaofei\n  He", "title": "Discourse Marker Augmented Network with Reinforcement Learning for\n  Natural Language Inference", "comments": "Accepted in ACL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Natural Language Inference (NLI), also known as Recognizing Textual\nEntailment (RTE), is one of the most important problems in natural language\nprocessing. It requires to infer the logical relationship between two given\nsentences. While current approaches mostly focus on the interaction\narchitectures of the sentences, in this paper, we propose to transfer knowledge\nfrom some important discourse markers to augment the quality of the NLI model.\nWe observe that people usually use some discourse markers such as \"so\" or \"but\"\nto represent the logical relationship between two sentences. These words\npotentially have deep connections with the meanings of the sentences, thus can\nbe utilized to help improve the representations of them. Moreover, we use\nreinforcement learning to optimize a new objective function with a reward\ndefined by the property of the NLI datasets to make full use of the labels\ninformation. Experiments show that our method achieves the state-of-the-art\nperformance on several large-scale datasets.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jul 2019 04:27:57 GMT"}], "update_date": "2019-07-24", "authors_parsed": [["Pan", "Boyuan", ""], ["Yang", "Yazheng", ""], ["Zhao", "Zhou", ""], ["Zhuang", "Yueting", ""], ["Cai", "Deng", ""], ["He", "Xiaofei", ""]]}, {"id": "1907.09750", "submitter": "Junghee Cho", "authors": "Junghee Cho, Junseok Kwon, Byung-Woo Hong", "title": "Adaptive Regularization via Residual Smoothing in Deep Learning\n  Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an adaptive regularization algorithm that can be effectively\napplied to the optimization problem in deep learning framework. Our\nregularization algorithm aims to take into account the fitness of data to the\ncurrent state of model in the determination of regularity to achieve better\ngeneralization. The degree of regularization at each element in the target\nspace of the neural network architecture is determined based on the residual at\neach optimization iteration in an adaptive way. Our adaptive regularization\nalgorithm is designed to apply a diffusion process driven by the heat equation\nwith spatially varying diffusivity depending on the probability density\nfunction following a certain distribution of residual. Our data-driven\nregularity is imposed by adaptively smoothing a simplified objective function\nin which the explicit regularization term is omitted in an alternating manner\nbetween the evaluation of residual and the determination of the degree of its\nregularity. The effectiveness of our algorithm is empirically demonstrated by\nthe numerical experiments in the application of image classification problems,\nindicating that our algorithm outperforms other commonly used optimization\nalgorithms in terms of generalization using popular deep learning models and\nbenchmark datasets.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jul 2019 08:28:09 GMT"}, {"version": "v2", "created": "Fri, 30 Aug 2019 14:27:37 GMT"}], "update_date": "2019-09-02", "authors_parsed": [["Cho", "Junghee", ""], ["Kwon", "Junseok", ""], ["Hong", "Byung-Woo", ""]]}, {"id": "1907.09789", "submitter": "Victor Pankratius", "authors": "Ho Chit Siu, Victor Pankratius", "title": "Genetic Algorithms for Starshade Retargeting in Space-Based Telescopes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "astro-ph.IM cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Future space-based telescopes will leverage starshades as components that can\nbe independently positioned. Starshades will adjust the light coming in from\nexoplanet host stars and enhance the direct imaging of exoplanets and other\nphenomena. In this context, scheduling of space-based telescope observations is\nsubject to a large number of dynamic constraints, including target\nobservability, fuel, and target priorities. We present an application of\ngenetic algorithm (GA) scheduling on this problem that not only takes physical\nconstraints into account, but also considers direct human suggestions on\nschedules. By allowing direct suggestions on schedules, this type of heuristic\ncan capture the scheduling preferences and expertise of stakeholders without\nthe need to always formally codify such objectives. Additionally, this approach\nallows schedules to be constructed from existing ones when scenarios change;\nfor example, this capability allows for optimization without the need to\nrecompute schedules from scratch after changes such as new discoveries or new\ntargets of opportunity. We developed a specific graph-traversal-based framework\nupon which to apply GA for telescope scheduling, and use it to demonstrate the\nconvergence behavior of a particular implementation of GA. From this work,\ndifficulties with regards to assigning values to observational targets are also\nnoted, and recommendations are made for different scenarios.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jul 2019 09:45:21 GMT"}], "update_date": "2019-07-24", "authors_parsed": [["Siu", "Ho Chit", ""], ["Pankratius", "Victor", ""]]}, {"id": "1907.09810", "submitter": "Stefano Albrecht", "authors": "Stefano V. Albrecht, Jacob W. Crandall, Subramanian Ramamoorthy", "title": "E-HBA: Using Action Policies for Expert Advice and Agent Typification", "comments": "Proceedings of the Second Workshop on Multiagent Interaction without\n  Prior Coordination (MIPC), 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Past research has studied two approaches to utilise predefined policy sets in\nrepeated interactions: as experts, to dictate our own actions, and as types, to\ncharacterise the behaviour of other agents. In this work, we bring these\ncomplementary views together in the form of a novel meta-algorithm, called\nExpert-HBA (E-HBA), which can be applied to any expert algorithm that considers\nthe average (or total) payoff an expert has yielded in the past. E-HBA\ngradually mixes the past payoff with a predicted future payoff, which is\ncomputed using the type-based characterisation. We present results from a\ncomprehensive set of repeated matrix games, comparing the performance of\nseveral well-known expert algorithms with and without the aid of E-HBA. Our\nresults show that E-HBA has the potential to significantly improve the\nperformance of expert algorithms.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jul 2019 10:48:10 GMT"}], "update_date": "2019-07-24", "authors_parsed": [["Albrecht", "Stefano V.", ""], ["Crandall", "Jacob W.", ""], ["Ramamoorthy", "Subramanian", ""]]}, {"id": "1907.09867", "submitter": "Stefania  Costantini", "authors": "Stefania Costantini", "title": "About epistemic negation and world views in Epistemic Logic Programs", "comments": "Paper presented at the 35th International Conference on Logic\n  Programming (ICLP 2019), Las Cruces, New Mexico, USA, 20-25 September 2019,\n  16 pages", "journal-ref": "Theory and Practice of Logic Programming 19 (2019) 790-807", "doi": "10.1017/S147106841900019X", "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we consider Epistemic Logic Programs, which extend Answer Set\nProgramming (ASP) with \"epistemic operators\" and \"epistemic negation\", and a\nrecent approach to the semantics of such programs in terms of World Views. We\npropose some observations on the existence and number of world views. We show\nhow to exploit an extended ASP semantics in order to: (i) provide a\ncharacterization of world views, different from existing ones; (ii) query world\nviews and query the whole set of world views.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jul 2019 13:29:10 GMT"}, {"version": "v2", "created": "Tue, 30 Jul 2019 21:09:05 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Costantini", "Stefania", ""]]}, {"id": "1907.09915", "submitter": "Huajun Liu", "authors": "Huajun Liu, Hui Zhang, Christoph Mertz", "title": "DeepDA: LSTM-based Deep Data Association Network for Multi-Targets\n  Tracking in Clutter", "comments": "8 pages, 12 figures. arXiv admin note: text overlap with\n  arXiv:1802.06897, arXiv:1604.03635 by other authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Long Short-Term Memory (LSTM) neural network based data association\nalgorithm named as DeepDA for multi-target tracking in clutters is proposed to\ndeal with the NP-hard combinatorial optimization problem in this paper.\nDifferent from the classical data association methods involving complex models\nand accurate prior knowledge on clutter density, filter covariance or\nassociated gating etc, data-driven deep learning methods have been extensively\nresearched for this topic. Firstly, data association mathematical problem for\nmultitarget tracking on unknown target number, missed detection and clutter,\nwhich is beyond one-to-one mapping between observations and targets is\nredefined formally. Subsequently, an LSTM network is designed to learn the\nmeasurement-to-track association probability from radar noisy measurements and\nexist tracks. Moreover, an LSTM-based data-driven deep neural network after a\nsupervised training through the BPTT and RMSprop optimization method can get\nthe association probability directly. Experimental results on simulated data\nshow a significant performance on association ratio, target ID switching and\ntime-consuming for tracking multiple targets even they are crossing each other\nin the complicated clutter environment.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jul 2019 23:00:42 GMT"}], "update_date": "2019-07-29", "authors_parsed": [["Liu", "Huajun", ""], ["Zhang", "Hui", ""], ["Mertz", "Christoph", ""]]}, {"id": "1907.10016", "submitter": "Shikib Mehri", "authors": "Shikib Mehri, Tejas Srinivasan and Maxine Eskenazi", "title": "Structured Fusion Networks for Dialog", "comments": "Accepted to SIGDial 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural dialog models have exhibited strong performance, however their\nend-to-end nature lacks a representation of the explicit structure of dialog.\nThis results in a loss of generalizability, controllability and a data-hungry\nnature. Conversely, more traditional dialog systems do have strong models of\nexplicit structure. This paper introduces several approaches for explicitly\nincorporating structure into neural models of dialog. Structured Fusion\nNetworks first learn neural dialog modules corresponding to the structured\ncomponents of traditional dialog systems and then incorporate these modules in\na higher-level generative model. Structured Fusion Networks obtain strong\nresults on the MultiWOZ dataset, both with and without reinforcement learning.\nStructured Fusion Networks are shown to have several valuable properties,\nincluding better domain generalizability, improved performance in reduced data\nscenarios and robustness to divergence during reinforcement learning.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jul 2019 17:20:13 GMT"}], "update_date": "2019-07-24", "authors_parsed": [["Mehri", "Shikib", ""], ["Srinivasan", "Tejas", ""], ["Eskenazi", "Maxine", ""]]}, {"id": "1907.10029", "submitter": "Blake Hannaford", "authors": "Blake Hannaford", "title": "Hidden Markov Models derived from Behavior Trees", "comments": "Submitted to IEEE Transactions on Robotics and Automation,\n  23-Jul-2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Behavior trees are rapidly attracting interest in robotics and human\ntask-related motion tracking. However no algorithms currently exist to track or\nidentify parameters of BTs under noisy observations. We report a new\nrelationship between BTs, augmented with statistical information, and Hidden\nMarkov Models. Exploiting this relationship will allow application of many\nalgorithms for HMMs (and dynamic Bayesian networks) to data acquired from\nBT-based systems.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jul 2019 17:37:40 GMT"}], "update_date": "2019-07-24", "authors_parsed": [["Hannaford", "Blake", ""]]}, {"id": "1907.10054", "submitter": "Benoit Vuillemin", "authors": "Benoit Vuillemin (LIRIS), Lionel Delphin-Poulat (FTR&D), Rozenn Nicol,\n  La\\\"etitia Matignon (SMA), Salima Hassas (MSI)", "title": "TSRuleGrowth : Extraction de r\\`egles de pr\\'ediction semi-ordonn\\'ees\n  \\`a partir d'une s\\'erie temporelle d'\\'el\\'ements discrets, application dans\n  un contexte d'intelligence ambiante", "comments": "in French. Conf\\'erence Nationale sur les Applications Pratiques de\n  l'Intelligence Artificielle (APIA), Jul 2019, Toulouse, France", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a new algorithm: TSRuleGrowth, looking for\npartially-ordered rules over a time series. This algorithm takes principles\nfrom the state of the art of rule mining and applies them to time series via a\nnew notion of support. We apply this algorithm to real data from a connected\nenvironment, which extract user habits through different connected objects.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jul 2019 09:17:47 GMT"}], "update_date": "2019-07-25", "authors_parsed": [["Vuillemin", "Benoit", "", "LIRIS"], ["Delphin-Poulat", "Lionel", "", "FTR&D"], ["Nicol", "Rozenn", "", "SMA"], ["Matignon", "La\u00ebtitia", "", "SMA"], ["Hassas", "Salima", "", "MSI"]]}, {"id": "1907.10247", "submitter": "Yijie Guo", "authors": "Yijie Guo, Jongwook Choi, Marcin Moczulski, Shengyu Feng, Samy Bengio,\n  Mohammad Norouzi, Honglak Lee", "title": "Memory Based Trajectory-conditioned Policies for Learning from Sparse\n  Rewards", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning with sparse rewards is challenging because an agent\ncan rarely obtain non-zero rewards and hence, gradient-based optimization of\nparameterized policies can be incremental and slow. Recent work demonstrated\nthat using a memory buffer of previous successful trajectories can result in\nmore effective policies. However, existing methods may overly exploit past\nsuccessful experiences, which can encourage the agent to adopt sub-optimal and\nmyopic behaviors. In this work, instead of focusing on good experiences with\nlimited diversity, we propose to learn a trajectory-conditioned policy to\nfollow and expand diverse past trajectories from a memory buffer. Our method\nallows the agent to reach diverse regions in the state space and improve upon\nthe past trajectories to reach new states. We empirically show that our\napproach significantly outperforms count-based exploration methods (parametric\napproach) and self-imitation learning (parametric approach with non-parametric\nmemory) on various complex tasks with local optima. In particular, without\nusing expert demonstrations or resetting to arbitrary states, we achieve the\nstate-of-the-art scores under five billion number of frames, on challenging\nAtari games such as Montezuma's Revenge and Pitfall.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jul 2019 05:46:27 GMT"}, {"version": "v2", "created": "Wed, 20 Nov 2019 00:41:38 GMT"}, {"version": "v3", "created": "Mon, 15 Feb 2021 03:53:20 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Guo", "Yijie", ""], ["Choi", "Jongwook", ""], ["Moczulski", "Marcin", ""], ["Feng", "Shengyu", ""], ["Bengio", "Samy", ""], ["Norouzi", "Mohammad", ""], ["Lee", "Honglak", ""]]}, {"id": "1907.10323", "submitter": "Paul Weng", "authors": "Paul Weng", "title": "Fairness in Reinforcement Learning", "comments": "Presented at the AI for Social Good Workshop at IJCAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Decision support systems (e.g., for ecological conservation) and autonomous\nsystems (e.g., adaptive controllers in smart cities) start to be deployed in\nreal applications. Although their operations often impact many users or\nstakeholders, no fairness consideration is generally taken into account in\ntheir design, which could lead to completely unfair outcomes for some users or\nstakeholders. To tackle this issue, we advocate for the use of social welfare\nfunctions that encode fairness and present this general novel problem in the\ncontext of (deep) reinforcement learning, although it could possibly be\nextended to other machine learning tasks.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jul 2019 09:27:11 GMT"}], "update_date": "2019-07-25", "authors_parsed": [["Weng", "Paul", ""]]}, {"id": "1907.10327", "submitter": "Yusuke Kawamoto", "authors": "Yusuke Kawamoto", "title": "Towards Logical Specification of Statistical Machine Learning", "comments": "SEFM'19 conference paper (full version with errors corrected)", "journal-ref": null, "doi": "10.1007/978-3-030-30446-1_16", "report-no": null, "categories": "cs.LO cs.AI cs.CR cs.LG cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a logical approach to formalizing statistical properties of\nmachine learning. Specifically, we propose a formal model for statistical\nclassification based on a Kripke model, and formalize various notions of\nclassification performance, robustness, and fairness of classifiers by using\nepistemic logic. Then we show some relationships among properties of\nclassifiers and those between classification performance and robustness, which\nsuggests robustness-related properties that have not been formalized in the\nliterature as far as we know. To formalize fairness properties, we define a\nnotion of counterfactual knowledge and show techniques to formalize conditional\nindistinguishability by using counterfactual epistemic operators. As far as we\nknow, this is the first work that uses logical formulas to express statistical\nproperties of machine learning, and that provides epistemic (resp.\ncounterfactually epistemic) views on robustness (resp. fairness) of\nclassifiers.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jul 2019 09:33:07 GMT"}, {"version": "v2", "created": "Sat, 28 Mar 2020 14:30:40 GMT"}], "update_date": "2020-03-31", "authors_parsed": [["Kawamoto", "Yusuke", ""]]}, {"id": "1907.10389", "submitter": "Markus Hecher", "authors": "Mario Alviano, Carmine Dodaro, Johannes K. Fichte, Markus Hecher,\n  Tobias Philipp, Jakob Rath", "title": "Inconsistency Proofs for ASP: The ASP-DRUPE Format", "comments": "Paper presented at the 35th International Conference on Logic\n  Programming (ICLP 2019), Las Cruces, New Mexico, USA, 20-25 September 2019,\n  16 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Answer Set Programming (ASP) solvers are highly-tuned and complex procedures\nthat implicitly solve the consistency problem, i.e., deciding whether a logic\nprogram admits an answer set. Verifying whether a claimed answer set is\nformally a correct answer set of the program can be decided in polynomial time\nfor (normal) programs. However, it is far from immediate to verify whether a\nprogram that is claimed to be inconsistent, indeed does not admit any answer\nsets. In this paper, we address this problem and develop the new proof format\nASP-DRUPE for propositional, disjunctive logic programs, including weight and\nchoice rules. ASP-DRUPE is based on the Reverse Unit Propagation (RUP) format\ndesigned for Boolean satisfiability. We establish correctness of ASP-DRUPE and\ndiscuss how to integrate it into modern ASP solvers. Later, we provide an\nimplementation of ASP-DRUPE into the wasp solver for normal logic programs.\nThis work is under consideration for acceptance in TPLP.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jul 2019 12:32:37 GMT"}], "update_date": "2019-07-25", "authors_parsed": [["Alviano", "Mario", ""], ["Dodaro", "Carmine", ""], ["Fichte", "Johannes K.", ""], ["Hecher", "Markus", ""], ["Philipp", "Tobias", ""], ["Rath", "Jakob", ""]]}, {"id": "1907.10424", "submitter": "Andrea Polonioli PhD", "authors": "Ciro Greco, Andrea Polonioli and Jacopo Tagliabue", "title": "Less (Data) Is More: Why Small Data Holds the Key to the Future of\n  Artificial Intelligence", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The claims that big data holds the key to enterprise successes and that\nArtificial Intelligence is going to replace humanity have become increasingly\nmore popular over the past few years, both in academia and in the industry.\nHowever, while these claims may indeed capture some truth, they have also been\nmassively oversold, or so we contend here. The goal of this paper is two-fold.\nFirst, we provide a qualified defence of the value of less data within the\ncontext of AI. This is done by carefully reviewing two distinct problems for\nbig data driven AI, namely a) the limited track record of Deep Learning in key\nareas such as Natural Language Processing, b) the regulatory and business\nsignificance of being able to learn from few data points. Second, we briefly\nsketch what we refer to as a case of AI with humans and for humans, namely an\nAI paradigm whereby the systems we build are privacy-oriented and focused on\nhuman-machine collaboration, not competition. Combining our claims above, we\nconclude that when seen through the lens of cognitively inspired AI, the bright\nfuture of the discipline is about less data, not more, and more humans, not\nfewer.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jul 2019 15:57:00 GMT"}], "update_date": "2019-07-25", "authors_parsed": [["Greco", "Ciro", ""], ["Polonioli", "Andrea", ""], ["Tagliabue", "Jacopo", ""]]}, {"id": "1907.10469", "submitter": "Bernardo Cuteri", "authors": "Bernardo Cuteri, Carmine Dodaro, Francesco Ricca, Peter Sch\\\"uller", "title": "Partial Compilation of ASP Programs", "comments": "Paper presented at the 35th International Conference on Logic\n  Programming (ICLP 2019), Las Cruces, New Mexico, USA, 20-25 September 2019,\n  16 pages, 6 figures", "journal-ref": "Theory and Practice of Logic Programming 19 (2019) 857-873", "doi": "10.1017/S1471068419000231", "report-no": null, "categories": "cs.LO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Answer Set Programming (ASP) is a well-known declarative formalism in logic\nprogramming. Efficient implementations made it possible to apply ASP in many\nscenarios, ranging from deductive databases applications to the solution of\nhard combinatorial problems. State-of-the-art ASP systems are based on the\ntraditional ground\\&solve approach and are general-purpose implementations,\ni.e., they are essentially built once for any kind of input program. In this\npaper, we propose an extended architecture for ASP systems, in which parts of\nthe input program are compiled into an ad-hoc evaluation algorithm (i.e., we\nobtain a specific binary for a given program), and might not be subject to the\ngrounding step. To this end, we identify a condition that allows the\ncompilation of a sub-program, and present the related partial compilation\ntechnique. Importantly, we have implemented the new approach on top of a\nwell-known ASP solver and conducted an experimental analysis on\npublicly-available benchmarks. Results show that our compilation-based approach\nimproves on the state of the art in various scenarios, including cases in which\nthe input program is stratified or the grounding blow-up makes the evaluation\nunpractical with traditional ASP systems.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jul 2019 14:42:57 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Cuteri", "Bernardo", ""], ["Dodaro", "Carmine", ""], ["Ricca", "Francesco", ""], ["Sch\u00fcller", "Peter", ""]]}, {"id": "1907.10492", "submitter": "EPTCS", "authors": "Francesco Belardinelli (Department of Computing, Imperial College\n  London, UK and Laboratoire IBISC, University of Evry, France), Umberto Grandi\n  (IRIT, University of Toulouse, France)", "title": "Social Choice Methods for Database Aggregation", "comments": "In Proceedings TARK 2019, arXiv:1907.08335. arXiv admin note:\n  substantial text overlap with arXiv:1802.08586", "journal-ref": "EPTCS 297, 2019, pp. 50-67", "doi": "10.4204/EPTCS.297.4", "report-no": null, "categories": "cs.LO cs.AI cs.DB cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge can be represented compactly in multiple ways, from a set of\npropositional formulas, to a Kripke model, to a database. In this paper we\nstudy the aggregation of information coming from multiple sources, each source\nsubmitting a database modelled as a first-order relational structure. In the\npresence of integrity constraints, we identify classes of aggregators that\nrespect them in the aggregated database, provided these are satisfied in all\nindividual databases. We also characterise languages for first-order queries on\nwhich the answer to a query on the aggregated database coincides with the\naggregation of the answers to the query obtained on each individual database.\nThis contribution is meant to be a first step on the application of techniques\nfrom social choice theory to knowledge representation in databases.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jul 2019 03:13:22 GMT"}], "update_date": "2019-07-25", "authors_parsed": [["Belardinelli", "Francesco", "", "Department of Computing, Imperial College\n  London, UK and Laboratoire IBISC, University of Evry, France"], ["Grandi", "Umberto", "", "IRIT, University of Toulouse, France"]]}, {"id": "1907.10500", "submitter": "Yen-Wei Chang", "authors": "Yen-Wei Chang and Wen-Hsiao Peng", "title": "Learning Goal-Oriented Visual Dialog Agents: Imitating and Surpassing\n  Analytic Experts", "comments": "ICME2019 Oral Paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper tackles the problem of learning a questioner in the goal-oriented\nvisual dialog task. Several previous works adopt model-free reinforcement\nlearning. Most pretrain the model from a finite set of human-generated data. We\nargue that using limited demonstrations to kick-start the questioner is\ninsufficient due to the large policy search space. Inspired by a recently\nproposed information theoretic approach, we develop two analytic experts to\nserve as a source of high-quality demonstrations for imitation learning. We\nthen take advantage of reinforcement learning to refine the model towards the\ngoal-oriented objective. Experimental results on the GuessWhat?! dataset show\nthat our method has the combined merits of imitation and reinforcement\nlearning, achieving the state-of-the-art performance.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jul 2019 15:08:38 GMT"}], "update_date": "2019-07-25", "authors_parsed": [["Chang", "Yen-Wei", ""], ["Peng", "Wen-Hsiao", ""]]}, {"id": "1907.10508", "submitter": "Alexantrou Serb", "authors": "Alexander Serb, Themistoklis Prodromakis", "title": "A system of different layers of abstraction for artificial intelligence", "comments": "12 pages, 1 figure, 1 table, submitted version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The field of artificial intelligence (AI) represents an enormous endeavour of\nhumankind that is currently transforming our societies down to their very\nfoundations. Its task, building truly intelligent systems, is underpinned by a\nvast array of subfields ranging from the development of new electronic\ncomponents to mathematical formulations of highly abstract and complex\nreasoning. This breadth of subfields renders it often difficult to understand\nhow they all fit together into a bigger picture and hides the multi-faceted,\nmulti-layered conceptual structure that in a sense can be said to be what AI\ntruly is. In this perspective we propose a system of five levels/layers of\nabstraction that underpin many AI implementations. We further posit that each\nlayer is subject to a complexity-performance trade-off whilst different layers\nare interlocked with one another in a control-complexity trade-off. This\noverview provides a conceptual map that can help to identify how and where\ninnovation should be targeted in order to achieve different levels of\nfunctionality, assure them for safety, optimise performance under various\noperating constraints and map the opportunity space for social and economic\nexploitation.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jul 2019 08:09:14 GMT"}], "update_date": "2019-07-25", "authors_parsed": [["Serb", "Alexander", ""], ["Prodromakis", "Themistoklis", ""]]}, {"id": "1907.10528", "submitter": "Joe Raad", "authors": "Joe Raad, Nathalie Pernelle, Fatiha Sa\\\"is, Wouter Beek and Frank van\n  Harmelen", "title": "The sameAs Problem: A Survey on Identity Management in the Web of Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a decentralised knowledge representation system such as the Web of Data,\nit is common and indeed desirable for different knowledge graphs to overlap.\nWhenever multiple names are used to denote the same thing, owl:sameAs\nstatements are needed in order to link the data and foster reuse. Whilst the\ndeductive value of such identity statements can be extremely useful in\nenhancing various knowledge-based systems, incorrect use of identity can have\nwide-ranging effects in a global knowledge space like the Web of Data. With\nseveral works already proven that identity in the Web is broken, this survey\ninvestigates the current state of this \"sameAs problem\". An open discussion\nhighlights the main weaknesses suffered by solutions in the literature, and\ndraws open challenges to be faced in the future.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jul 2019 15:42:22 GMT"}], "update_date": "2019-07-25", "authors_parsed": [["Raad", "Joe", ""], ["Pernelle", "Nathalie", ""], ["Sa\u00efs", "Fatiha", ""], ["Beek", "Wouter", ""], ["van Harmelen", "Frank", ""]]}, {"id": "1907.10662", "submitter": "Xuankang Lin", "authors": "Xuankang Lin, He Zhu, Roopsha Samanta, Suresh Jagannathan", "title": "ART: Abstraction Refinement-Guided Training for Provably Correct Neural\n  Networks", "comments": "FMCAD'20", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.PL cs.SC stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Artificial Neural Networks (ANNs) have demonstrated remarkable utility in\nvarious challenging machine learning applications. While formally verified\nproperties of their behaviors are highly desired, they have proven notoriously\ndifficult to derive and enforce. Existing approaches typically formulate this\nproblem as a post facto analysis process. In this paper, we present a novel\nlearning framework that ensures such formal guarantees are enforced by\nconstruction. Our technique enables training provably correct networks with\nrespect to a broad class of safety properties, a capability that goes\nwell-beyond existing approaches, without compromising much accuracy. Our key\ninsight is that we can integrate an optimization-based abstraction refinement\nloop into the learning process and operate over dynamically constructed\npartitions of the input space that considers accuracy and safety objectives\nsynergistically. The refinement procedure iteratively splits the input space\nfrom which training data is drawn, guided by the efficacy with which such\npartitions enable safety verification. We have implemented our approach in a\ntool (ART) and applied it to enforce general safety properties on unmanned\naviator collision avoidance system ACAS Xu dataset and the Collision Detection\ndataset. Importantly, we empirically demonstrate that realizing safety does not\ncome at the price of much accuracy. Our methodology demonstrates that an\nabstraction refinement methodology provides a meaningful pathway for building\nboth accurate and correct machine learning networks.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jul 2019 16:58:33 GMT"}, {"version": "v2", "created": "Fri, 26 Jul 2019 02:42:17 GMT"}, {"version": "v3", "created": "Thu, 1 Oct 2020 21:49:51 GMT"}], "update_date": "2020-10-05", "authors_parsed": [["Lin", "Xuankang", ""], ["Zhu", "He", ""], ["Samanta", "Roopsha", ""], ["Jagannathan", "Suresh", ""]]}, {"id": "1907.10738", "submitter": "Pratyay Banerjee", "authors": "Pratyay Banerjee, Kuntal Kumar Pal, Arindam Mitra, Chitta Baral", "title": "Careful Selection of Knowledge to solve Open Book Question Answering", "comments": "Accepted to ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Open book question answering is a type of natural language based QA (NLQA)\nwhere questions are expected to be answered with respect to a given set of open\nbook facts, and common knowledge about a topic. Recently a challenge involving\nsuch QA, OpenBookQA, has been proposed. Unlike most other NLQA tasks that focus\non linguistic understanding, OpenBookQA requires deeper reasoning involving\nlinguistic understanding as well as reasoning with common knowledge. In this\npaper we address QA with respect to the OpenBookQA dataset and combine state of\nthe art language models with abductive information retrieval (IR), information\ngain based re-ranking, passage selection and weighted scoring to achieve 72.0%\naccuracy, an 11.6% improvement over the current state of the art.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jul 2019 21:37:16 GMT"}], "update_date": "2019-07-26", "authors_parsed": [["Banerjee", "Pratyay", ""], ["Pal", "Kuntal Kumar", ""], ["Mitra", "Arindam", ""], ["Baral", "Chitta", ""]]}, {"id": "1907.10739", "submitter": "Sebastian Gehrmann", "authors": "Sebastian Gehrmann, Hendrik Strobelt, Robert Kr\\\"uger, Hanspeter\n  Pfister, Alexander M. Rush", "title": "Visual Interaction with Deep Learning Models through Collaborative\n  Semantic Inference", "comments": "IEEE VIS 2019 (VAST)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automation of tasks can have critical consequences when humans lose agency\nover decision processes. Deep learning models are particularly susceptible\nsince current black-box approaches lack explainable reasoning. We argue that\nboth the visual interface and model structure of deep learning systems need to\ntake into account interaction design. We propose a framework of collaborative\nsemantic inference (CSI) for the co-design of interactions and models to enable\nvisual collaboration between humans and algorithms. The approach exposes the\nintermediate reasoning process of models which allows semantic interactions\nwith the visual metaphors of a problem, which means that a user can both\nunderstand and control parts of the model reasoning process. We demonstrate the\nfeasibility of CSI with a co-designed case study of a document summarization\nsystem.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jul 2019 21:37:29 GMT"}], "update_date": "2019-07-26", "authors_parsed": [["Gehrmann", "Sebastian", ""], ["Strobelt", "Hendrik", ""], ["Kr\u00fcger", "Robert", ""], ["Pfister", "Hanspeter", ""], ["Rush", "Alexander M.", ""]]}, {"id": "1907.10761", "submitter": "Mikel Artetxe", "authors": "Mikel Artetxe, Gorka Labaka, Eneko Agirre", "title": "Bilingual Lexicon Induction through Unsupervised Machine Translation", "comments": "ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A recent research line has obtained strong results on bilingual lexicon\ninduction by aligning independently trained word embeddings in two languages\nand using the resulting cross-lingual embeddings to induce word translation\npairs through nearest neighbor or related retrieval methods. In this paper, we\npropose an alternative approach to this problem that builds on the recent work\non unsupervised machine translation. This way, instead of directly inducing a\nbilingual lexicon from cross-lingual embeddings, we use them to build a\nphrase-table, combine it with a language model, and use the resulting machine\ntranslation system to generate a synthetic parallel corpus, from which we\nextract the bilingual lexicon using statistical word alignment techniques. As\nsuch, our method can work with any word embedding and cross-lingual mapping\ntechnique, and it does not require any additional resource besides the\nmonolingual corpus used to train the embeddings. When evaluated on the exact\nsame cross-lingual embeddings, our proposed method obtains an average\nimprovement of 6 accuracy points over nearest neighbor and 4 points over CSLS\nretrieval, establishing a new state-of-the-art in the standard MUSE dataset.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jul 2019 22:30:04 GMT"}], "update_date": "2019-07-26", "authors_parsed": [["Artetxe", "Mikel", ""], ["Labaka", "Gorka", ""], ["Agirre", "Eneko", ""]]}, {"id": "1907.10772", "submitter": "Jorge Gustavo Madrid Perez", "authors": "Jorge G. Madrid, Hugo Jair Escalante, Eduardo F. Morales, Wei-Wei Tu,\n  Yang Yu, Lisheng Sun-Hosoya, Isabelle Guyon, Michele Sebag", "title": "Towards AutoML in the presence of Drift: first results", "comments": "AutoML 2018 @ ICML/IJCAI-ECAI", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Research progress in AutoML has lead to state of the art solutions that can\ncope quite wellwith supervised learning task, e.g., classification with\nAutoSklearn. However, so far thesesystems do not take into account the changing\nnature of evolving data over time (i.e., theystill assume i.i.d. data); even\nwhen this sort of domains are increasingly available in realapplications (e.g.,\nspam filtering, user preferences, etc.). We describe a first attempt to\nde-velop an AutoML solution for scenarios in which data distribution changes\nrelatively slowlyover time and in which the problem is approached in a lifelong\nlearning setting. We extendAuto-Sklearn with sound and intuitive mechanisms\nthat allow it to cope with this sort ofproblems. The extended Auto-Sklearn is\ncombined with concept drift detection techniquesthat allow it to automatically\ndetermine when the initial models have to be adapted. Wereport experimental\nresults in benchmark data from AutoML competitions that adhere tothis scenario.\nResults demonstrate the effectiveness of the proposed methodology.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jul 2019 23:28:37 GMT"}], "update_date": "2019-07-26", "authors_parsed": [["Madrid", "Jorge G.", ""], ["Escalante", "Hugo Jair", ""], ["Morales", "Eduardo F.", ""], ["Tu", "Wei-Wei", ""], ["Yu", "Yang", ""], ["Sun-Hosoya", "Lisheng", ""], ["Guyon", "Isabelle", ""], ["Sebag", "Michele", ""]]}, {"id": "1907.10914", "submitter": "Fernando S\\'aenz-P\\'erez", "authors": "Fernando S\\'aenz-P\\'erez", "title": "Applying Constraint Logic Programming to SQL Semantic Analysis", "comments": "Paper presented at the 35th International Conference on Logic\n  Programming (ICLP 2019), Las Cruces, New Mexico, USA, 20-25 September 2019,\n  16 pages", "journal-ref": "Theory and Practice of Logic Programming 19 (2019) 808-825", "doi": "10.1017/S1471068419000206", "report-no": null, "categories": "cs.DB cs.AI cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes the use of Constraint Logic Programming (CLP) to model\nSQL queries in a data-independent abstract layer by focusing on some semantic\nproperties for signalling possible errors in such queries. First, we define a\ntranslation from SQL to Datalog, and from Datalog to CLP, so that solving this\nCLP program will give information about inconsistency, tautology, and possible\nsimplifications. We use different constraint domains which are mapped to SQL\ntypes, and propose them to cooperate for improving accuracy. Our approach\nleverages a deductive system that includes SQL and Datalog, and we present an\nimplementation in this system which is currently being tested in classroom,\nshowing its advantages and differences with respect to other approaches, as\nwell as some performance data. This paper is under consideration for acceptance\nin TPLP.\n", "versions": [{"version": "v1", "created": "Thu, 25 Jul 2019 09:19:30 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["S\u00e1enz-P\u00e9rez", "Fernando", ""]]}, {"id": "1907.10925", "submitter": "Michael Morak", "authors": "Wolfgang Faber, Michael Morak, and Stefan Woltran", "title": "On Uniform Equivalence of Epistemic Logic Programs", "comments": "Accepted for publication and presentation at the 35th International\n  Conference of Logic Programming, ICLP 2019, in Las Cruces, New Mexico, USA", "journal-ref": "Theory and Practice of Logic Programming 19 (2019) 826-840", "doi": "10.1017/S1471068419000218", "report-no": null, "categories": "cs.LO cs.AI", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Epistemic Logic Programs (ELPs) extend Answer Set Programming (ASP) with\nepistemic negation and have received renewed interest in recent years. This led\nto the development of new research and efficient solving systems for ELPs. In\npractice, ELPs are often written in a modular way, where each module interacts\nwith other modules by accepting sets of facts as input, and passing on sets of\nfacts as output. An interesting question then presents itself: under which\nconditions can such a module be replaced by another one without changing the\noutcome, for any set of input facts? This problem is known as uniform\nequivalence, and has been studied extensively for ASP. For ELPs, however, such\nan investigation is, as of yet, missing. In this paper, we therefore propose a\ncharacterization of uniform equivalence that can be directly applied to the\nlanguage of state-of-the-art ELP solvers. We also investigate the computational\ncomplexity of deciding uniform equivalence for two ELPs, and show that it is on\nthe third level of the polynomial hierarchy.\n", "versions": [{"version": "v1", "created": "Thu, 25 Jul 2019 09:34:13 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Faber", "Wolfgang", ""], ["Morak", "Michael", ""], ["Woltran", "Stefan", ""]]}, {"id": "1907.10952", "submitter": "Andrew Cropper", "authors": "Andrew Cropper and Sophie Tourret", "title": "Logical reduction of metarules", "comments": "MLJ submission", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many forms of inductive logic programming (ILP) use \\emph{metarules},\nsecond-order Horn clauses, to define the structure of learnable programs and\nthus the hypothesis space. Deciding which metarules to use for a given learning\ntask is a major open problem and is a trade-off between efficiency and\nexpressivity: the hypothesis space grows given more metarules, so we wish to\nuse fewer metarules, but if we use too few metarules then we lose expressivity.\nIn this paper, we study whether fragments of metarules can be logically reduced\nto minimal finite subsets. We consider two traditional forms of logical\nreduction: subsumption and entailment. We also consider a new reduction\ntechnique called \\emph{derivation reduction}, which is based on SLD-resolution.\nWe compute reduced sets of metarules for fragments relevant to ILP and\ntheoretically show whether these reduced sets are reductions for more general\ninfinite fragments. We experimentally compare learning with reduced sets of\nmetarules on three domains: Michalski trains, string transformations, and game\nrules. In general, derivation reduced sets of metarules outperforms subsumption\nand entailment reduced sets, both in terms of predictive accuracies and\nlearning times.\n", "versions": [{"version": "v1", "created": "Thu, 25 Jul 2019 10:31:34 GMT"}], "update_date": "2019-07-26", "authors_parsed": [["Cropper", "Andrew", ""], ["Tourret", "Sophie", ""]]}, {"id": "1907.10953", "submitter": "Andrew Cropper", "authors": "Andrew Cropper and Rolf Morel and Stephen H. Muggleton", "title": "Learning higher-order logic programs", "comments": "Submitted to the MLJ", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A key feature of inductive logic programming (ILP) is its ability to learn\nfirst-order programs, which are intrinsically more expressive than\npropositional programs. In this paper, we introduce techniques to learn\nhigher-order programs. Specifically, we extend meta-interpretive learning (MIL)\nto support learning higher-order programs by allowing for \\emph{higher-order\ndefinitions} to be used as background knowledge. Our theoretical results show\nthat learning higher-order programs, rather than first-order programs, can\nreduce the textual complexity required to express programs which in turn\nreduces the size of the hypothesis space and sample complexity. We implement\nour idea in two new MIL systems: the Prolog system \\namea{} and the ASP system\n\\nameb{}. Both systems support learning higher-order programs and higher-order\npredicate invention, such as inventing functions for \\tw{map/3} and conditions\nfor \\tw{filter/3}. We conduct experiments on four domains (robot strategies,\nchess playing, list transformations, and string decryption) that compare\nlearning first-order and higher-order programs. Our experimental results\nsupport our theoretical claims and show that, compared to learning first-order\nprograms, learning higher-order programs can significantly improve predictive\naccuracies and reduce learning times.\n", "versions": [{"version": "v1", "created": "Thu, 25 Jul 2019 10:36:01 GMT"}], "update_date": "2019-07-26", "authors_parsed": [["Cropper", "Andrew", ""], ["Morel", "Rolf", ""], ["Muggleton", "Stephen H.", ""]]}, {"id": "1907.11007", "submitter": "Efthimis Tsilionis", "authors": "Efthimis Tsilionis, Nikolaos Koutroumanis, Panagiotis Nikitopoulos,\n  Christos Doulkeridis and Alexander Artikis", "title": "Online Event Recognition from Moving Vehicles: Application Paper", "comments": "Paper presented at the 35th International Conference on Logic\n  Programming (ICLP 2019), Las Cruces, New Mexico, USA, 20-25 September 2019,\n  16 pages", "journal-ref": "Theory and Practice of Logic Programming 19 (2019) 841-856", "doi": "10.1017/S147106841900022X", "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a system for online composite event recognition over streaming\npositions of commercial vehicles. Our system employs a data enrichment module,\naugmenting the mobility data with external information, such as weather data\nand proximity to points of interest. In addition, the composite event\nrecognition module, based on a highly optimised logic programming\nimplementation of the Event Calculus, consumes the enriched data and identifies\nactivities that are beneficial in fleet management applications. We evaluate\nour system on large, real-world data from commercial vehicles, and illustrate\nits efficiency. Under consideration for acceptance in TPLP.\n", "versions": [{"version": "v1", "created": "Thu, 25 Jul 2019 12:30:08 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Tsilionis", "Efthimis", ""], ["Koutroumanis", "Nikolaos", ""], ["Nikitopoulos", "Panagiotis", ""], ["Doulkeridis", "Christos", ""], ["Artikis", "Alexander", ""]]}, {"id": "1907.11021", "submitter": "Ochilbek Rakhmanov", "authors": "Rakhmanov Ochilbek, Nzurumike Obianuju, Amina Sani, and Rukayya Umar", "title": "Experimentation on the motion of an obstacle avoiding robot", "comments": "5 pages, 8 figures, 1 table", "journal-ref": "African Journal of Management Information System (VOL. 1, ISSUE 3,\n  JULY 2019)", "doi": null, "report-no": null, "categories": "cs.RO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An intelligent robot can be used for applications where a human is at\nsignificant risk (like nuclear, space, military), the economics or menial\nnature of the application result in inefficient use of human workers (service\nindustry, agriculture), for humanitarian uses where there is great risk\n(demining an area of land mines, urban search and rescue). This paper\nimplements an experiment on one of important fields of AI Searching Algorithms,\nto find shortest possible solution by searching the produced tree. We will\nconcentrate on Hill climbing algorithm, which is one of simplest searching\nalgorithms in AI. This algorithm is one of most suitable searching methods to\nhelp expert system to make decision at every state, at every node. The\nexperimental robot will traverse the maze by using sensors plugged on it. The\nrobot used is E.V.3 Lego Mind storms, with native software for programming\nLabView. The reason we chose this robot is that it interacts quickly with\nsensors and can be reconstructed in many ways. This programmed robot will\ncalculate the best possibilities to find way out of maze. The maze is made of\nwood, and it is adjustable, as robot should be able to leave the maze in any\ndesign.\n", "versions": [{"version": "v1", "created": "Thu, 25 Jul 2019 13:15:12 GMT"}], "update_date": "2019-07-26", "authors_parsed": [["Ochilbek", "Rakhmanov", ""], ["Obianuju", "Nzurumike", ""], ["Sani", "Amina", ""], ["Umar", "Rukayya", ""]]}, {"id": "1907.11075", "submitter": "Andrew Warrington", "authors": "Andrew Warrington, Arthur Spencer, Frank Wood", "title": "The Virtual Patch Clamp: Imputing C. elegans Membrane Potentials from\n  Calcium Imaging", "comments": "Includes Supplementary Materials", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a stochastic whole-brain and body simulator of the nematode\nroundworm Caenorhabditis elegans (C. elegans) and show that it is sufficiently\nregularizing to allow imputation of latent membrane potentials from partial\ncalcium fluorescence imaging observations. This is the first attempt we know of\nto \"complete the circle,\" where an anatomically grounded whole-connectome\nsimulator is used to impute a time-varying \"brain\" state at single-cell\nfidelity from covariates that are measurable in practice. The sequential Monte\nCarlo (SMC) method we employ not only enables imputation of said latent states\nbut also presents a strategy for learning simulator parameters via variational\noptimization of the noisy model evidence approximation provided by SMC. Our\nimputation and parameter estimation experiments were conducted on distributed\nsystems using novel implementations of the aforementioned techniques applied to\nsynthetic data of dimension and type representative of that which are measured\nin laboratories currently.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jul 2019 17:57:39 GMT"}], "update_date": "2019-07-26", "authors_parsed": [["Warrington", "Andrew", ""], ["Spencer", "Arthur", ""], ["Wood", "Frank", ""]]}, {"id": "1907.11090", "submitter": "Heyang Gong", "authors": "Gong Heyang and Zhu Ke", "title": "Info Intervention", "comments": "See more information on Causal AI:\n  https://sites.google.com/view/minituring/home", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Causal diagrams based on do intervention are useful tools to formalize,\nprocess and understand causal relationship among variables. However, the do\nintervention has controversial interpretation of causal questions for\nnon-manipulable variables, and it also lacks the power to check the conditions\nrelated to counterfactual variables. This paper introduces a new info\nintervention to tackle these two problems, and provides causal diagrams for\ncommunication and theoretical focus based on this info intervention. Our info\nintervention intervenes the input/output information of causal mechanisms,\nwhile the do intervention intervenes the causal mechanisms. Consequently, the\ncausality is viewed as information transfer in the info intervention framework.\nAs an extension, the generalized info intervention is also proposed and studied\nin this paper.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jul 2019 07:31:14 GMT"}, {"version": "v2", "created": "Sun, 29 Dec 2019 02:59:06 GMT"}, {"version": "v3", "created": "Thu, 16 Apr 2020 15:33:59 GMT"}, {"version": "v4", "created": "Fri, 17 Apr 2020 03:22:07 GMT"}, {"version": "v5", "created": "Mon, 1 Jun 2020 08:11:52 GMT"}, {"version": "v6", "created": "Tue, 2 Jun 2020 03:25:10 GMT"}], "update_date": "2020-06-03", "authors_parsed": [["Heyang", "Gong", ""], ["Ke", "Zhu", ""]]}, {"id": "1907.11112", "submitter": "Arpit Sharma", "authors": "Arpit Sharma", "title": "Using Answer Set Programming for Commonsense Reasoning in the Winograd\n  Schema Challenge", "comments": "Paper presented at the 35th International Conference on Logic\n  Programming (ICLP 2019), Las Cruces, New Mexico, USA, 20-25 September 2019,\n  16 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Winograd Schema Challenge (WSC) is a natural language understanding task\nproposed as an alternative to the Turing test in 2011. In this work we attempt\nto solve WSC problems by reasoning with additional knowledge. By using an\napproach built on top of graph-subgraph isomorphism encoded using Answer Set\nProgramming (ASP) we were able to handle 240 out of 291 WSC problems. The ASP\nencoding allows us to add additional constraints in an elaboration tolerant\nmanner. In the process we present a graph based representation of WSC problems\nas well as relevant commonsense knowledge. This paper is under consideration\nfor acceptance in TPLP.\n", "versions": [{"version": "v1", "created": "Thu, 25 Jul 2019 14:45:04 GMT"}], "update_date": "2019-07-26", "authors_parsed": [["Sharma", "Arpit", ""]]}, {"id": "1907.11184", "submitter": "Prithviraj Sen", "authors": "Yiwei Yang, Eser Kandogan, Yunyao Li, Walter S. Lasecki, and\n  Prithviraj Sen", "title": "HEIDL: Learning Linguistic Expressions with Deep Learning and\n  Human-in-the-Loop", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While the role of humans is increasingly recognized in machine learning\ncommunity, representation of and interaction with models in current\nhuman-in-the-loop machine learning (HITL-ML) approaches are too low-level and\nfar-removed from human's conceptual models. We demonstrate HEIDL, a prototype\nHITL-ML system that exposes the machine-learned model through high-level,\nexplainable linguistic expressions formed of predicates representing semantic\nstructure of text. In HEIDL, human's role is elevated from simply evaluating\nmodel predictions to interpreting and even updating the model logic directly by\nenabling interaction with rule predicates themselves. Raising the currency of\ninteraction to such semantic levels calls for new interaction paradigms between\nhumans and machines that result in improved productivity for text analytics\nmodel development process. Moreover, by involving humans in the process, the\nhuman-machine co-created models generalize better to unseen data as domain\nexperts are able to instill their expertise by extrapolating from what has been\nlearned by automated algorithms from few labelled data.\n", "versions": [{"version": "v1", "created": "Thu, 25 Jul 2019 16:45:06 GMT"}], "update_date": "2019-07-26", "authors_parsed": [["Yang", "Yiwei", ""], ["Kandogan", "Eser", ""], ["Li", "Yunyao", ""], ["Lasecki", "Walter S.", ""], ["Sen", "Prithviraj", ""]]}, {"id": "1907.11238", "submitter": "Szymon Drgas", "authors": "Tomasz Grzywalski, Riccardo Belluzzo, Szymon Drgas, Agnieszka\n  Cwalinska, Honorata Hafke-Dys", "title": "Interactive Lungs Auscultation with Reinforcement Learning Agent", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.AI cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To perform a precise auscultation for the purposes of examination of\nrespiratory system normally requires the presence of an experienced doctor.\nWith most recent advances in machine learning and artificial intelligence,\nautomatic detection of pathological breath phenomena in sounds recorded with\nstethoscope becomes a reality. But to perform a full auscultation in home\nenvironment by layman is another matter, especially if the patient is a child.\nIn this paper we propose a unique application of Reinforcement Learning for\ntraining an agent that interactively guides the end user throughout the\nauscultation procedure. We show that \\textit{intelligent} selection of\nauscultation points by the agent reduces time of the examination fourfold\nwithout significant decrease in diagnosis accuracy compared to exhaustive\nauscultation.\n", "versions": [{"version": "v1", "created": "Thu, 25 Jul 2019 11:04:08 GMT"}], "update_date": "2019-07-29", "authors_parsed": [["Grzywalski", "Tomasz", ""], ["Belluzzo", "Riccardo", ""], ["Drgas", "Szymon", ""], ["Cwalinska", "Agnieszka", ""], ["Hafke-Dys", "Honorata", ""]]}, {"id": "1907.11321", "submitter": "Mark-Oliver Stehr", "authors": "Mark-Oliver Stehr, Minyoung Kim, Carolyn L. Talcott, Merrill Knapp,\n  Akos Vertes", "title": "Probabilistic Approximate Logic and its Implementation in the Logical\n  Imagination Engine", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.LO q-bio.CB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In spite of the rapidly increasing number of applications of machine learning\nin various domains, a principled and systematic approach to the incorporation\nof domain knowledge in the engineering process is still lacking and ad hoc\nsolutions that are difficult to validate are still the norm in practice, which\nis of growing concern not only in mission-critical applications.\n  In this note, we introduce Probabilistic Approximate Logic (PALO) as a logic\nbased on the notion of mean approximate probability to overcome conceptual and\ncomputational difficulties inherent to strictly probabilistic logics. The logic\nis approximate in several dimensions. Logical independence assumptions are used\nto obtain approximate probabilities, but by averaging over many instances of\nformulas a useful estimate of mean probability with known confidence can\nusually be obtained. To enable efficient computational inference, the logic has\na continuous semantics that reflects only a subset of the structural properties\nof classical logic, but this imprecision can be partly compensated by richer\ntheories obtained by classical inference or other means. Computational\ninference, which refers to the construction of models and validation of logical\nproperties, is based on Stochastic Gradient Descent (SGD) and Markov Chain\nMonte Carlo (MCMC) techniques and hence another dimension where approximations\nare involved.\n  We also present the Logical Imagination Engine (LIME), a prototypical\nimplementation of PALO based on TensorFlow. Albeit not limited to the\nbiological domain, we illustrate its operation in a quite substantial\nbioinformatics machine learning application concerned with network synthesis\nand analysis in a recent DARPA project.\n", "versions": [{"version": "v1", "created": "Thu, 25 Jul 2019 22:13:24 GMT"}], "update_date": "2019-07-29", "authors_parsed": [["Stehr", "Mark-Oliver", ""], ["Kim", "Minyoung", ""], ["Talcott", "Carolyn L.", ""], ["Knapp", "Merrill", ""], ["Vertes", "Akos", ""]]}, {"id": "1907.11377", "submitter": "Dongpeng Liu", "authors": "Ming Liu, Dongpeng Liu, Guangyu Sun, Yi Zhao, Duolin Wang, Fangxing\n  Liu, Xiang Fang, Qing He, Dong Xu", "title": "Deep Learning Detection of Inaccurate Smart Electricity Meters: A Case\n  Study", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Detecting inaccurate smart meters and targeting them for replacement can save\nsignificant resources. For this purpose, a novel deep-learning method was\ndeveloped based on long short-term memory (LSTM) and a modified convolutional\nneural network (CNN) to predict electricity usage trajectories based on\nhistorical data. From the significant difference between the predicted\ntrajectory and the observed one, the meters that cannot measure electricity\naccurately are located. In a case study, a proof of principle was demonstrated\nin detecting inaccurate meters with high accuracy for practical usage to\nprevent unnecessary replacement and increase the service life span of smart\nmeters.\n", "versions": [{"version": "v1", "created": "Fri, 26 Jul 2019 04:05:07 GMT"}, {"version": "v2", "created": "Mon, 23 Sep 2019 01:10:07 GMT"}, {"version": "v3", "created": "Fri, 7 Aug 2020 23:29:32 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Liu", "Ming", ""], ["Liu", "Dongpeng", ""], ["Sun", "Guangyu", ""], ["Zhao", "Yi", ""], ["Wang", "Duolin", ""], ["Liu", "Fangxing", ""], ["Fang", "Xiang", ""], ["He", "Qing", ""], ["Xu", "Dong", ""]]}, {"id": "1907.11461", "submitter": "Weixun Wang", "authors": "Weixun Wang, Tianpei Yang, Yong Liu, Jianye Hao, Xiaotian Hao, Yujing\n  Hu, Yingfeng Chen, Changjie Fan, Yang Gao", "title": "Action Semantics Network: Considering the Effects of Actions in\n  Multiagent Systems", "comments": "accepted by ICLR2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In multiagent systems (MASs), each agent makes individual decisions but all\nof them contribute globally to the system evolution. Learning in MASs is\ndifficult since each agent's selection of actions must take place in the\npresence of other co-learning agents. Moreover, the environmental stochasticity\nand uncertainties increase exponentially with the increase in the number of\nagents. Previous works borrow various multiagent coordination mechanisms into\ndeep learning architecture to facilitate multiagent coordination. However, none\nof them explicitly consider action semantics between agents that different\nactions have different influences on other agents. In this paper, we propose a\nnovel network architecture, named Action Semantics Network (ASN), that\nexplicitly represents such action semantics between agents. ASN characterizes\ndifferent actions' influence on other agents using neural networks based on the\naction semantics between them. ASN can be easily combined with existing deep\nreinforcement learning (DRL) algorithms to boost their performance.\nExperimental results on StarCraft II micromanagement and Neural MMO show ASN\nsignificantly improves the performance of state-of-the-art DRL approaches\ncompared with several network architectures.\n", "versions": [{"version": "v1", "created": "Fri, 26 Jul 2019 09:51:30 GMT"}, {"version": "v2", "created": "Thu, 26 Sep 2019 04:05:11 GMT"}, {"version": "v3", "created": "Thu, 16 Jan 2020 02:08:54 GMT"}], "update_date": "2020-01-17", "authors_parsed": [["Wang", "Weixun", ""], ["Yang", "Tianpei", ""], ["Liu", "Yong", ""], ["Hao", "Jianye", ""], ["Hao", "Xiaotian", ""], ["Hu", "Yujing", ""], ["Chen", "Yingfeng", ""], ["Fan", "Changjie", ""], ["Gao", "Yang", ""]]}, {"id": "1907.11467", "submitter": "Jorge Fandinno", "authors": "Felicidad Aguado, Pedro Cabalar, Jorge Fandinno, David Pearce,\n  Gilberto Perez and Concepcion Vidal", "title": "Revisiting Explicit Negation in Answer Set Programming", "comments": "Paper presented at the 35th International Conference on Logic\n  Programming (ICLP 2019), Las Cruces, New Mexico, USA, 20-25 September 2019,\n  16 pages", "journal-ref": "Theory and Practice of Logic Programming 19 (2019) 908-924", "doi": "10.1017/S1471068419000267", "report-no": null, "categories": "cs.LO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A common feature in Answer Set Programming is the use of a second negation,\nstronger than default negation and sometimes called explicit, strong or\nclassical negation. This explicit negation is normally used in front of atoms,\nrather than allowing its use as a regular operator. In this paper we consider\nthe arbitrary combination of explicit negation with nested expressions, as\nthose defined by Lifschitz, Tang and Turner. We extend the concept of reduct\nfor this new syntax and then prove that it can be captured by an extension of\nEquilibrium Logic with this second negation. We study some properties of this\nvariant and compare to the already known combination of Equilibrium Logic with\nNelson's strong negation. Under consideration for acceptance in TPLP.\n", "versions": [{"version": "v1", "created": "Fri, 26 Jul 2019 10:19:47 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Aguado", "Felicidad", ""], ["Cabalar", "Pedro", ""], ["Fandinno", "Jorge", ""], ["Pearce", "David", ""], ["Perez", "Gilberto", ""], ["Vidal", "Concepcion", ""]]}, {"id": "1907.11468", "submitter": "Francesco Giannini", "authors": "Giuseppe Marra, Francesco Giannini, Michelangelo Diligenti, Marco\n  Maggini and Marco Gori", "title": "T-Norms Driven Loss Functions for Machine Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural-symbolic approaches have recently gained popularity to inject prior\nknowledge into a learner without requiring it to induce this knowledge from\ndata. These approaches can potentially learn competitive solutions with a\nsignificant reduction of the amount of supervised data. A large class of\nneural-symbolic approaches is based on First-Order Logic to represent prior\nknowledge, relaxed to a differentiable form using fuzzy logic. This paper shows\nthat the loss function expressing these neural-symbolic learning tasks can be\nunambiguously determined given the selection of a t-norm generator. When\nrestricted to supervised learning, the presented theoretical apparatus provides\na clean justification to the popular cross-entropy loss, which has been shown\nto provide faster convergence and to reduce the vanishing gradient problem in\nvery deep structures. However, the proposed learning formulation extends the\nadvantages of the cross-entropy loss to the general knowledge that can be\nrepresented by a neural-symbolic method. Therefore, the methodology allows the\ndevelopment of a novel class of loss functions, which are shown in the\nexperimental results to lead to faster convergence rates than the approaches\npreviously proposed in the literature.\n", "versions": [{"version": "v1", "created": "Fri, 26 Jul 2019 10:22:16 GMT"}, {"version": "v2", "created": "Thu, 17 Oct 2019 09:18:21 GMT"}, {"version": "v3", "created": "Tue, 7 Jul 2020 10:27:46 GMT"}, {"version": "v4", "created": "Wed, 9 Sep 2020 16:49:12 GMT"}], "update_date": "2020-09-10", "authors_parsed": [["Marra", "Giuseppe", ""], ["Giannini", "Francesco", ""], ["Diligenti", "Michelangelo", ""], ["Maggini", "Marco", ""], ["Gori", "Marco", ""]]}, {"id": "1907.11501", "submitter": "Christoph Benzm\\\"uller", "authors": "Alexander Steen and Christoph Benzm\\\"uller", "title": "Extensional Higher-Order Paramodulation in Leo-III", "comments": "34 pages, 7 Figures, 1 Table; submitted article", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO cs.SC math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Leo-III is an automated theorem prover for extensional type theory with\nHenkin semantics and choice. Reasoning with primitive equality is enabled by\nadapting paramodulation-based proof search to higher-order logic. The prover\nmay cooperate with multiple external specialist reasoning systems such as\nfirst-order provers and SMT solvers. Leo-III is compatible with the TPTP/TSTP\nframework for input formats, reporting results and proofs, and standardized\ncommunication between reasoning systems, enabling e.g. proof reconstruction\nfrom within proof assistants such as Isabelle/HOL. Leo-III supports reasoning\nin polymorphic first-order and higher-order logic, in all normal quantified\nmodal logics, as well as in different deontic logics. Its development had\ninitiated the ongoing extension of the TPTP infrastructure to reasoning within\nnon-classical logics.\n", "versions": [{"version": "v1", "created": "Fri, 26 Jul 2019 11:58:08 GMT"}, {"version": "v2", "created": "Sun, 28 Feb 2021 06:05:39 GMT"}], "update_date": "2021-03-02", "authors_parsed": [["Steen", "Alexander", ""], ["Benzm\u00fcller", "Christoph", ""]]}, {"id": "1907.11740", "submitter": "Wenxuan Zhou", "authors": "Wenxuan Zhou, Lerrel Pinto, Abhinav Gupta", "title": "Environment Probing Interaction Policies", "comments": "Published as a conference paper at ICLR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A key challenge in reinforcement learning (RL) is environment generalization:\na policy trained to solve a task in one environment often fails to solve the\nsame task in a slightly different test environment. A common approach to\nimprove inter-environment transfer is to learn policies that are invariant to\nthe distribution of testing environments. However, we argue that instead of\nbeing invariant, the policy should identify the specific nuances of an\nenvironment and exploit them to achieve better performance. In this work, we\npropose the 'Environment-Probing' Interaction (EPI) policy, a policy that\nprobes a new environment to extract an implicit understanding of that\nenvironment's behavior. Once this environment-specific information is obtained,\nit is used as an additional input to a task-specific policy that can now\nperform environment-conditioned actions to solve a task. To learn these\nEPI-policies, we present a reward function based on transition predictability.\nSpecifically, a higher reward is given if the trajectory generated by the\nEPI-policy can be used to better predict transitions. We experimentally show\nthat EPI-conditioned task-specific policies significantly outperform commonly\nused policy generalization methods on novel testing environments.\n", "versions": [{"version": "v1", "created": "Fri, 26 Jul 2019 18:19:25 GMT"}], "update_date": "2019-07-30", "authors_parsed": [["Zhou", "Wenxuan", ""], ["Pinto", "Lerrel", ""], ["Gupta", "Abhinav", ""]]}, {"id": "1907.11752", "submitter": "Mauricio Gonzalez-Soto", "authors": "Mauricio Gonzalez-Soto, L. Enrique Sucar, Hugo J. Escalante", "title": "von Neumann-Morgenstern and Savage Theorems for Causal Decision Making", "comments": "Submitted to Journal of Causal Inference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Causal thinking and decision making under uncertainty are fundamental aspects\nof intelligent reasoning. Decision making under uncertainty has been well\nstudied when information is considered at the associative (probabilistic)\nlevel. The classical Theorems of von Neumann-Morgenstern and Savage provide a\nformal criterion for rational choice using purely associative information.\nCausal inference often yields uncertainty about the exact causal structure, so\nwe consider what kinds of decisions are possible in those conditions. In this\nwork, we consider decision problems in which available actions and consequences\nare causally connected. After recalling a previous causal decision making\nresult, which relies on a known causal model, we consider the case in which the\ncausal mechanism that controls some environment is unknown to a rational\ndecision maker. In this setting we state and prove a causal version of Savage's\nTheorem, which we then use to develop a notion of causal games with its\nrespective causal Nash equilibrium. These results highlight the importance of\ncausal models in decision making and the variety of potential applications.\n", "versions": [{"version": "v1", "created": "Fri, 26 Jul 2019 18:44:39 GMT"}, {"version": "v2", "created": "Mon, 9 Sep 2019 12:13:10 GMT"}, {"version": "v3", "created": "Thu, 28 May 2020 23:18:32 GMT"}, {"version": "v4", "created": "Mon, 5 Apr 2021 04:13:33 GMT"}], "update_date": "2021-04-06", "authors_parsed": [["Gonzalez-Soto", "Mauricio", ""], ["Sucar", "L. Enrique", ""], ["Escalante", "Hugo J.", ""]]}, {"id": "1907.11788", "submitter": "Pablo Hernandez-Leal", "authors": "Chao Gao, Bilal Kartal, Pablo Hernandez-Leal and Matthew E. Taylor", "title": "On Hard Exploration for Reinforcement Learning: a Case Study in\n  Pommerman", "comments": "AAAI Conference on Artificial Intelligence and Interactive Digital\n  Entertainment (AIIDE) 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  How to best explore in domains with sparse, delayed, and deceptive rewards is\nan important open problem for reinforcement learning (RL). This paper considers\none such domain, the recently-proposed multi-agent benchmark of Pommerman. This\ndomain is very challenging for RL --- past work has shown that model-free RL\nalgorithms fail to achieve significant learning without artificially reducing\nthe environment's complexity. In this paper, we illuminate reasons behind this\nfailure by providing a thorough analysis on the hardness of random exploration\nin Pommerman. While model-free random exploration is typically futile, we\ndevelop a model-based automatic reasoning module that can be used for safer\nexploration by pruning actions that will surely lead the agent to death. We\nempirically demonstrate that this module can significantly improve learning.\n", "versions": [{"version": "v1", "created": "Fri, 26 Jul 2019 20:36:09 GMT"}], "update_date": "2019-07-30", "authors_parsed": [["Gao", "Chao", ""], ["Kartal", "Bilal", ""], ["Hernandez-Leal", "Pablo", ""], ["Taylor", "Matthew E.", ""]]}, {"id": "1907.11813", "submitter": "Ayush Raina", "authors": "Ayush Raina, Christopher McComb and Jonathan Cagan", "title": "Learning to design from humans: Imitating human designers through deep\n  learning", "comments": null, "journal-ref": "J. Mech. Des, ASME, November 2019", "doi": "10.1115/1.4044256", "report-no": "Volume 141 Issue 11", "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Humans as designers have quite versatile problem-solving strategies. Computer\nagents on the other hand can access large scale computational resources to\nsolve certain design problems. Hence, if agents can learn from human behavior,\na synergetic human-agent problem solving team can be created. This paper\npresents an approach to extract human design strategies and implicit rules,\npurely from historical human data, and use that for design generation. A\ntwo-step framework that learns to imitate human design strategies from\nobservation is proposed and implemented. This framework makes use of deep\nlearning constructs to learn to generate designs without any explicit\ninformation about objective and performance metrics. The framework is designed\nto interact with the problem through a visual interface as humans did when\nsolving the problem. It is trained to imitate a set of human designers by\nobserving their design state sequences without inducing problem-specific\nmodelling bias or extra information about the problem. Furthermore, an\nend-to-end agent is developed that uses this deep learning framework as its\ncore in conjunction with image processing to map pixel-to-design moves as a\nmechanism to generate designs. Finally, the designs generated by a\ncomputational team of these agents are then compared to actual human data for\nteams solving a truss design problem. Results demonstrates that these agents\nare able to create feasible and efficient truss designs without guidance,\nshowing that this methodology allows agents to learn effective design\nstrategies.\n", "versions": [{"version": "v1", "created": "Fri, 26 Jul 2019 23:09:57 GMT"}, {"version": "v2", "created": "Fri, 2 Aug 2019 15:16:50 GMT"}], "update_date": "2019-09-24", "authors_parsed": [["Raina", "Ayush", ""], ["McComb", "Christopher", ""], ["Cagan", "Jonathan", ""]]}, {"id": "1907.11889", "submitter": "Matan Orbach", "authors": "Tamar Lavee, Matan Orbach, Lili Kotlerman, Yoav Kantor, Shai Gretz,\n  Lena Dankin, Shachar Mirkin, Michal Jacovi, Yonatan Bilu, Ranit Aharonov and\n  Noam Slonim", "title": "Towards Effective Rebuttal: Listening Comprehension using Corpus-Wide\n  Claim Mining", "comments": "6th Argument Mining Workshop @ ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Engaging in a live debate requires, among other things, the ability to\neffectively rebut arguments claimed by your opponent. In particular, this\nrequires identifying these arguments. Here, we suggest doing so by\nautomatically mining claims from a corpus of news articles containing billions\nof sentences, and searching for them in a given speech. This raises the\nquestion of whether such claims indeed correspond to those made in spoken\nspeeches. To this end, we collected a large dataset of $400$ speeches in\nEnglish discussing $200$ controversial topics, mined claims for each topic, and\nasked annotators to identify the mined claims mentioned in each speech. Results\nshow that in the vast majority of speeches debaters indeed make use of such\nclaims. In addition, we present several baselines for the automatic detection\nof mined claims in speeches, forming the basis for future work. All collected\ndata is freely available for research.\n", "versions": [{"version": "v1", "created": "Sat, 27 Jul 2019 10:19:19 GMT"}], "update_date": "2019-07-30", "authors_parsed": [["Lavee", "Tamar", ""], ["Orbach", "Matan", ""], ["Kotlerman", "Lili", ""], ["Kantor", "Yoav", ""], ["Gretz", "Shai", ""], ["Dankin", "Lena", ""], ["Mirkin", "Shachar", ""], ["Jacovi", "Michal", ""], ["Bilu", "Yonatan", ""], ["Aharonov", "Ranit", ""], ["Slonim", "Noam", ""]]}, {"id": "1907.11932", "submitter": "Zhijing Jin", "authors": "Di Jin, Zhijing Jin, Joey Tianyi Zhou, Peter Szolovits", "title": "Is BERT Really Robust? A Strong Baseline for Natural Language Attack on\n  Text Classification and Entailment", "comments": "AAAI 2020 (Oral)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Machine learning algorithms are often vulnerable to adversarial examples that\nhave imperceptible alterations from the original counterparts but can fool the\nstate-of-the-art models. It is helpful to evaluate or even improve the\nrobustness of these models by exposing the maliciously crafted adversarial\nexamples. In this paper, we present TextFooler, a simple but strong baseline to\ngenerate natural adversarial text. By applying it to two fundamental natural\nlanguage tasks, text classification and textual entailment, we successfully\nattacked three target models, including the powerful pre-trained BERT, and the\nwidely used convolutional and recurrent neural networks. We demonstrate the\nadvantages of this framework in three ways: (1) effective---it outperforms\nstate-of-the-art attacks in terms of success rate and perturbation rate, (2)\nutility-preserving---it preserves semantic content and grammaticality, and\nremains correctly classified by humans, and (3) efficient---it generates\nadversarial text with computational complexity linear to the text length. *The\ncode, pre-trained target models, and test examples are available at\nhttps://github.com/jind11/TextFooler.\n", "versions": [{"version": "v1", "created": "Sat, 27 Jul 2019 15:07:04 GMT"}, {"version": "v2", "created": "Sat, 7 Sep 2019 05:33:35 GMT"}, {"version": "v3", "created": "Sat, 23 Nov 2019 07:53:08 GMT"}, {"version": "v4", "created": "Thu, 23 Jan 2020 07:16:25 GMT"}, {"version": "v5", "created": "Sun, 5 Apr 2020 07:12:08 GMT"}, {"version": "v6", "created": "Wed, 8 Apr 2020 23:10:10 GMT"}], "update_date": "2020-04-10", "authors_parsed": [["Jin", "Di", ""], ["Jin", "Zhijing", ""], ["Zhou", "Joey Tianyi", ""], ["Szolovits", "Peter", ""]]}, {"id": "1907.11971", "submitter": "Per-Arne Andersen", "authors": "Per-Arne Andersen, Morten Goodwin, Ole-Christoffer Granmo", "title": "Towards Model-based Reinforcement Learning for Industry-near\n  Environments", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep reinforcement learning has over the past few years shown great potential\nin learning near-optimal control in complex simulated environments with little\nvisible information. Rainbow (Q-Learning) and PPO (Policy Optimisation) have\nshown outstanding performance in a variety of tasks, including Atari 2600,\nMuJoCo, and Roboschool test suite. While these algorithms are fundamentally\ndifferent, both suffer from high variance, low sample efficiency, and\nhyperparameter sensitivity that in practice, make these algorithms a no-go for\ncritical operations in the industry.\n  On the other hand, model-based reinforcement learning focuses on learning the\ntransition dynamics between states in an environment. If these environment\ndynamics are adequately learned, a model-based approach is perhaps the most\nsample efficient method for learning agents to act in an environment optimally.\nThe traits of model-based reinforcement are ideal for real-world environments\nwhere sampling is slow and for mission-critical operations. In the warehouse\nindustry, there is an increasing motivation to minimise time and to maximise\nproduction. Currently, autonomous agents act suboptimally using handcrafted\npolicies for significant portions of the state-space.\n  In this paper, we present The Dreaming Variational Autoencoder v2 (DVAE-2), a\nmodel-based reinforcement learning algorithm that increases sample efficiency,\nhence enable algorithms with low sample efficiency function better in\nreal-world environments. We introduce Deep Warehouse, a simulated environment\nfor industry-near testing of autonomous agents in grid-based warehouses.\nFinally, we illustrate that DVAE-2 improves the sample efficiency for the Deep\nWarehouse compared to model-free methods.\n", "versions": [{"version": "v1", "created": "Sat, 27 Jul 2019 20:05:52 GMT"}], "update_date": "2019-07-30", "authors_parsed": [["Andersen", "Per-Arne", ""], ["Goodwin", "Morten", ""], ["Granmo", "Ole-Christoffer", ""]]}, {"id": "1907.12001", "submitter": "Rouzbeh Shirvani", "authors": "Gloria Washington, Rouzbeh Shirvani", "title": "Towards Understanding and Modeling Empathy for Use in Motivational\n  Design Thinking", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Design Thinking workshops are used by companies to help generate new ideas\nfor technologies and products by engaging subjects in exercises to understand\ntheir users' wants and become more empathetic towards their needs. The \"aha\nmoment\" experienced during these thought-provoking, step outside the yourself\nactivities occurs when a group of persons iterate over several problems and\nconverge upon a solution that will fit seamlessly everyday life. With the\nincreasing use and cost of Design workshops being offered, it is important that\ntechnology be developed that can help identify empathy and its onset in humans.\nThis position paper presents an approach to modeling empathy using Gaussian\nmixture models and heart rate and skin conductance. This paper also presents an\nupdated approach to Design Thinking that helps to ensure participants are\nthinking outside of their own race's, culture's, or other affiliations'\nmotives.\n", "versions": [{"version": "v1", "created": "Sun, 28 Jul 2019 02:04:56 GMT"}], "update_date": "2019-07-30", "authors_parsed": [["Washington", "Gloria", ""], ["Shirvani", "Rouzbeh", ""]]}, {"id": "1907.12003", "submitter": "Zhila Esna Ashari", "authors": "Zhila Esna Ashari and Hassan Ghasemzadeh", "title": "Mindful Active Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel active learning framework for activity recognition using\nwearable sensors. Our work is unique in that it takes physical and cognitive\nlimitations of the oracle into account when selecting sensor data to be\nannotated by the oracle. Our approach is inspired by human-beings' limited\ncapacity to respond to external stimulus such as responding to a prompt on\ntheir mobile devices. This capacity constraint is manifested not only in the\nnumber of queries that a person can respond to in a given time-frame but also\nin the lag between the time that a query is made and when it is responded to.\nWe introduce the notion of mindful active learning and propose a computational\nframework, called EMMA, to maximize the active learning performance taking\ninformativeness of sensor data, query budget, and human memory into account. We\nformulate this optimization problem, propose an approach to model memory\nretention, discuss complexity of the problem, and propose a greedy heuristic to\nsolve the problem. We demonstrate the effectiveness of our approach on three\npublicly available datasets and by simulating oracles with various memory\nstrengths. We show that the activity recognition accuracy ranges from 21% to\n97% depending on memory strength, query budget, and difficulty of the machine\nlearning task. Our results also indicate that EMMA achieves an accuracy level\nthat is, on average, 13.5% higher than the case when only informativeness of\nthe sensor data is considered for active learning. Additionally, we show that\nthe performance of our approach is at most 20% less than experimental\nupper-bound and up to 80% higher than experimental lower-bound. We observe that\nmindful active learning is most beneficial when query budget is small and/or\noracle's memory is weak, thus emphasizing contributions of our work in\nhuman-centered mobile health settings and for elderly with cognitive\nimpairments.\n", "versions": [{"version": "v1", "created": "Sun, 28 Jul 2019 02:44:52 GMT"}], "update_date": "2019-07-30", "authors_parsed": [["Ashari", "Zhila Esna", ""], ["Ghasemzadeh", "Hassan", ""]]}, {"id": "1907.12021", "submitter": "William Yang Wang", "authors": "Pushkar Shukla, Carlos Elmadjian, Richika Sharan, Vivek Kulkarni,\n  Matthew Turk, William Yang Wang", "title": "What Should I Ask? Using Conversationally Informative Rewards for\n  Goal-Oriented Visual Dialog", "comments": "Accepted to ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.CV cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ability to engage in goal-oriented conversations has allowed humans to\ngain knowledge, reduce uncertainty, and perform tasks more efficiently.\nArtificial agents, however, are still far behind humans in having goal-driven\nconversations. In this work, we focus on the task of goal-oriented visual\ndialogue, aiming to automatically generate a series of questions about an image\nwith a single objective. This task is challenging since these questions must\nnot only be consistent with a strategy to achieve a goal, but also consider the\ncontextual information in the image. We propose an end-to-end goal-oriented\nvisual dialogue system, that combines reinforcement learning with regularized\ninformation gain. Unlike previous approaches that have been proposed for the\ntask, our work is motivated by the Rational Speech Act framework, which models\nthe process of human inquiry to reach a goal. We test the two versions of our\nmodel on the GuessWhat?! dataset, obtaining significant results that outperform\nthe current state-of-the-art models in the task of generating questions to find\nan undisclosed object in an image.\n", "versions": [{"version": "v1", "created": "Sun, 28 Jul 2019 06:15:35 GMT"}], "update_date": "2019-07-30", "authors_parsed": [["Shukla", "Pushkar", ""], ["Elmadjian", "Carlos", ""], ["Sharan", "Richika", ""], ["Kulkarni", "Vivek", ""], ["Turk", "Matthew", ""], ["Wang", "William Yang", ""]]}, {"id": "1907.12047", "submitter": "Avi Segal", "authors": "Avi Segal, Kobi Gal, Guy Shani, Bracha Shapira", "title": "A difficulty ranking approach to personalization in E-learning", "comments": null, "journal-ref": "International Journal of Human-Computer Studies, Volume 130,\n  October 2019, Pages 261-272", "doi": "10.1016/j.ijhcs.2019.07.002", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The prevalence of e-learning systems and on-line courses has made educational\nmaterial widely accessible to students of varying abilities and backgrounds.\nThere is thus a growing need to accommodate for individual differences in\ne-learning systems. This paper presents an algorithm called EduRank for\npersonalizing educational content to students that combines a collaborative\nfiltering algorithm with voting methods. EduRank constructs a difficulty\nranking for each student by aggregating the rankings of similar students using\ndifferent aspects of their performance on common questions. These aspects\ninclude grades, number of retries, and time spent solving questions. It infers\na difficulty ranking directly over the questions for each student, rather than\nordering them according to the student's predicted score. The EduRank algorithm\nwas tested on two data sets containing thousands of students and a million\nrecords. It was able to outperform the state-of-the-art ranking approaches as\nwell as a domain expert. EduRank was used by students in a classroom activity,\nwhere a prior model was incorporated to predict the difficulty rankings of\nstudents with no prior history in the system. It was shown to lead students to\nsolve more difficult questions than an ordering by a domain expert, without\nreducing their performance.\n", "versions": [{"version": "v1", "created": "Sun, 28 Jul 2019 08:54:06 GMT"}], "update_date": "2019-07-30", "authors_parsed": [["Segal", "Avi", ""], ["Gal", "Kobi", ""], ["Shani", "Guy", ""], ["Shapira", "Bracha", ""]]}, {"id": "1907.12130", "submitter": "Patrick Rodler", "authors": "Patrick Rodler", "title": "Towards Optimizing Reiter's HS-Tree for Sequential Diagnosis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reiter's HS-Tree is one of the most popular diagnostic search algorithms due\nto its desirable properties and general applicability. In sequential diagnosis,\nwhere the addressed diagnosis problem is subject to successive change through\nthe acquisition of additional knowledge about the diagnosed system, HS-Tree is\nused in a stateless fashion. That is, the existing search tree is discarded\nwhen new knowledge is obtained, albeit often large parts of the tree are still\nrelevant and have to be rebuilt in the next iteration, involving redundant\noperations and costly reasoner calls. As a remedy to this, we propose\nDynamicHS, a variant of HS-Tree that avoids these redundancy issues by\nmaintaining state throughout sequential diagnosis while preserving all\ndesirable properties of HS-Tree. Preliminary results of ongoing evaluations in\na problem domain where HS-Tree is the state-of-the-art diagnostic method\nsuggest significant time savings achieved by DynamicHS by reducing expensive\nreasoner calls.\n", "versions": [{"version": "v1", "created": "Sun, 28 Jul 2019 19:26:08 GMT"}], "update_date": "2019-07-30", "authors_parsed": [["Rodler", "Patrick", ""]]}, {"id": "1907.12293", "submitter": "Yajun Zhou", "authors": "Weinan E and Yajun Zhou", "title": "A mathematical model for universal semantics", "comments": "Main text (12 pages, 7 figures); Software Manual (ii+262 pages, 16\n  figures, 12 tables, available as two ancillary files). Revised according to\n  reviewers' comments", "journal-ref": null, "doi": "10.1109/TPAMI.2020.3022533", "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We characterize the meaning of words with language-independent numerical\nfingerprints, through a mathematical analysis of recurring patterns in texts.\nApproximating texts by Markov processes on a long-range time scale, we are able\nto extract topics, discover synonyms, and sketch semantic fields from a\nparticular document of moderate length, without consulting external\nknowledge-base or thesaurus. Our Markov semantic model allows us to represent\neach topical concept by a low-dimensional vector, interpretable as algebraic\ninvariants in succinct statistical operations on the document, targeting local\nenvironments of individual words. These language-independent semantic\nrepresentations enable a robot reader to both understand short texts in a given\nlanguage (automated question-answering) and match medium-length texts across\ndifferent languages (automated word translation). Our semantic fingerprints\nquantify local meaning of words in 14 representative languages across 5 major\nlanguage families, suggesting a universal and cost-effective mechanism by which\nhuman languages are processed at the semantic level. Our protocols and source\ncodes are publicly available on\nhttps://github.com/yajun-zhou/linguae-naturalis-principia-mathematica\n", "versions": [{"version": "v1", "created": "Mon, 29 Jul 2019 09:25:49 GMT"}, {"version": "v2", "created": "Wed, 31 Jul 2019 02:21:44 GMT"}, {"version": "v3", "created": "Thu, 10 Oct 2019 04:19:43 GMT"}, {"version": "v4", "created": "Sat, 23 Nov 2019 10:09:43 GMT"}, {"version": "v5", "created": "Thu, 16 Jan 2020 11:46:28 GMT"}, {"version": "v6", "created": "Sun, 15 Mar 2020 01:46:54 GMT"}, {"version": "v7", "created": "Sun, 12 Jul 2020 12:59:40 GMT"}], "update_date": "2020-09-10", "authors_parsed": [["E", "Weinan", ""], ["Zhou", "Yajun", ""]]}, {"id": "1907.12344", "submitter": "Paul Ogris", "authors": "Thomas Eiter, Paul Ogris, Konstantin Schekotihin", "title": "A Distributed Approach to LARS Stream Reasoning (System paper)", "comments": "16 pages. Under consideration for acceptance in TPLP", "journal-ref": "Theory and Practice of Logic Programming 19 (2019) 974-989", "doi": "10.1017/S1471068419000309", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stream reasoning systems are designed for complex decision-making from\npossibly infinite, dynamic streams of data. Modern approaches to stream\nreasoning are usually performing their computations using stand-alone solvers,\nwhich incrementally update their internal state and return results as the new\nportions of data streams are pushed. However, the performance of such\napproaches degrades quickly as the rates of the input data and the complexity\nof decision problems are growing. This problem was already recognized in the\narea of stream processing, where systems became distributed in order to\nallocate vast computing resources provided by clouds. In this paper we propose\na distributed approach to stream reasoning that can efficiently split\ncomputations among different solvers communicating their results over data\nstreams. Moreover, in order to increase the throughput of the distributed\nsystem, we suggest an interval-based semantics for the LARS language, which\nenables significant reductions of network traffic. Performed evaluations\nindicate that the distributed stream reasoning significantly outperforms\nexisting stand-alone LARS solvers when the complexity of decision problems and\nthe rate of incoming data are increasing. Under consideration for acceptance in\nTheory and Practice of Logic Programming.\n", "versions": [{"version": "v1", "created": "Mon, 29 Jul 2019 11:39:05 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Eiter", "Thomas", ""], ["Ogris", "Paul", ""], ["Schekotihin", "Konstantin", ""]]}, {"id": "1907.12374", "submitter": "Feng Nan", "authors": "Feng Nan, Ran Ding, Ramesh Nallapati, Bing Xiang", "title": "Topic Modeling with Wasserstein Autoencoders", "comments": "In Proceedings of the 57th Annual Meeting of the Association for\n  Computational Linguistics (pp. 6345-6381)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel neural topic model in the Wasserstein autoencoders (WAE)\nframework. Unlike existing variational autoencoder based models, we directly\nenforce Dirichlet prior on the latent document-topic vectors. We exploit the\nstructure of the latent space and apply a suitable kernel in minimizing the\nMaximum Mean Discrepancy (MMD) to perform distribution matching. We discover\nthat MMD performs much better than the Generative Adversarial Network (GAN) in\nmatching high dimensional Dirichlet distribution. We further discover that\nincorporating randomness in the encoder output during training leads to\nsignificantly more coherent topics. To measure the diversity of the produced\ntopics, we propose a simple topic uniqueness metric. Together with the widely\nused coherence measure NPMI, we offer a more wholistic evaluation of topic\nquality. Experiments on several real datasets show that our model produces\nsignificantly better topics than existing topic models.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jul 2019 14:08:23 GMT"}, {"version": "v2", "created": "Fri, 6 Dec 2019 21:47:06 GMT"}], "update_date": "2019-12-10", "authors_parsed": [["Nan", "Feng", ""], ["Ding", "Ran", ""], ["Nallapati", "Ramesh", ""], ["Xiang", "Bing", ""]]}, {"id": "1907.12392", "submitter": "Felix Leibfried", "authors": "Felix Leibfried and Sergio Pascual-Diaz and Jordi Grau-Moya", "title": "A Unified Bellman Optimality Principle Combining Reward Maximization and\n  Empowerment", "comments": "Proceedings of the 33rd Conference on Neural Information Processing\n  Systems (NeurIPS), Vancouver, Canada, 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Empowerment is an information-theoretic method that can be used to\nintrinsically motivate learning agents. It attempts to maximize an agent's\ncontrol over the environment by encouraging visiting states with a large number\nof reachable next states. Empowered learning has been shown to lead to complex\nbehaviors, without requiring an explicit reward signal. In this paper, we\ninvestigate the use of empowerment in the presence of an extrinsic reward\nsignal. We hypothesize that empowerment can guide reinforcement learning (RL)\nagents to find good early behavioral solutions by encouraging highly empowered\nstates. We propose a unified Bellman optimality principle for empowered reward\nmaximization. Our empowered reward maximization approach generalizes both\nBellman's optimality principle as well as recent information-theoretical\nextensions to it. We prove uniqueness of the empowered values and show\nconvergence to the optimal solution. We then apply this idea to develop\noff-policy actor-critic RL algorithms which we validate in high-dimensional\ncontinuous robotics domains (MuJoCo). Our methods demonstrate improved initial\nand competitive final performance compared to model-free state-of-the-art\ntechniques.\n", "versions": [{"version": "v1", "created": "Fri, 26 Jul 2019 16:34:21 GMT"}, {"version": "v2", "created": "Tue, 30 Jul 2019 12:13:31 GMT"}, {"version": "v3", "created": "Mon, 9 Sep 2019 14:24:58 GMT"}, {"version": "v4", "created": "Tue, 8 Oct 2019 15:25:58 GMT"}, {"version": "v5", "created": "Wed, 8 Jan 2020 11:08:57 GMT"}], "update_date": "2020-01-09", "authors_parsed": [["Leibfried", "Felix", ""], ["Pascual-Diaz", "Sergio", ""], ["Grau-Moya", "Jordi", ""]]}, {"id": "1907.12393", "submitter": "The Anh Han", "authors": "The Anh Han, Luis Moniz Pereira, Francisco C. Santos and Tom Lenaerts", "title": "To regulate or not: a social dynamics analysis of the race for AI\n  supremacy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Rapid technological advancements in AI as well as the growing deployment of\nintelligent technologies in new application domains are currently driving the\ncompetition between businesses, nations and regions. This race for\ntechnological supremacy creates a complex ecology of choices that may lead to\nnegative consequences, in particular, when ethical and safety procedures are\nunderestimated or even ignored. As a consequence, different actors are urging\nto consider both the normative and social impact of these technological\nadvancements. As there is no easy access to data describing this AI race,\ntheoretical models are necessary to understand its dynamics, allowing for the\nidentification of when, how and which procedures need to be put in place to\nfavour outcomes beneficial for all. We show that, next to the risks of setbacks\nand being reprimanded for unsafe behaviour, the time-scale in which AI\nsupremacy can be achieved plays a crucial role. When this supremacy can be\nachieved in a short term, those who completely ignore the safety precautions\nare bound to win the race but at a cost to society, apparently requiring\nregulatory actions. Our analysis reveals that blindly imposing regulations may\nnot have anticipated effect as only for specific conditions a dilemma arises\nbetween what individually preferred and globally beneficial. Similar\nobservations can be made for the long-term development case. Yet different from\nthe short term situation, certain conditions require the promotion of\nrisk-taking as opposed to compliance to safety regulations in order to improve\nsocial welfare. These results remain robust when two or several actors are\ninvolved in the race and when collective rather than individual setbacks are\nproduced by risk-taking behaviour. When defining codes of conduct and\nregulatory policies for AI, a clear understanding about the time-scale of the\nrace is required.\n", "versions": [{"version": "v1", "created": "Fri, 26 Jul 2019 14:59:27 GMT"}, {"version": "v2", "created": "Thu, 16 Jan 2020 16:48:16 GMT"}], "update_date": "2020-01-17", "authors_parsed": [["Han", "The Anh", ""], ["Pereira", "Luis Moniz", ""], ["Santos", "Francisco C.", ""], ["Lenaerts", "Tom", ""]]}, {"id": "1907.12430", "submitter": "Alexander V Terekhov", "authors": "Alexander V. Terekhov and J. Kevin O'Regan", "title": "Learning abstract perceptual notions: the example of space", "comments": "arXiv admin note: text overlap with arXiv:1308.2124", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Humans are extremely swift learners. We are able to grasp highly abstract\nnotions, whether they come from art perception or pure mathematics. Current\nmachine learning techniques demonstrate astonishing results in extracting\npatterns in information. Yet the abstract notions we possess are more than just\nstatistical patterns in the incoming information. Sensorimotor theory suggests\nthat they represent functions, laws, describing how the information can be\ntransformed, or, in other words, they represent the statistics of sensorimotor\nchanges rather than sensory inputs themselves. The aim of our work is to\nsuggest a way for machine learning and sensorimotor theory to benefit from each\nother so as to pave the way toward new horizons in learning. We show in this\nstudy that a highly abstract notion, that of space, can be seen as a collection\nof laws of transformations of sensory information and that these laws could in\ntheory be learned by a naive agent. As an illustration we do a one-dimensional\nsimulation in which an agent extracts spatial knowledge in the form of\ninternalized (\"sensible\") rigid displacements. The agent uses them to encode\nits own displacements in a way which is isometrically related to external\nspace. Though the algorithm allowing acquisition of rigid displacements is\ndesigned \\emph{ad hoc}, we believe it can stimulate the development of\nunsupervised learning techniques leading to similar results.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jul 2019 17:57:54 GMT"}], "update_date": "2019-07-30", "authors_parsed": [["Terekhov", "Alexander V.", ""], ["O'Regan", "J. Kevin", ""]]}, {"id": "1907.12439", "submitter": "Hanbo Zhang", "authors": "Hanbo Zhang, Site Bai, Xuguang Lan, David Hsu, Nanning Zheng", "title": "Hindsight Trust Region Policy Optimization", "comments": "Accepted by IJCAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement Learning(RL) with sparse rewards is a major challenge. We\npropose \\emph{Hindsight Trust Region Policy Optimization}(HTRPO), a new RL\nalgorithm that extends the highly successful TRPO algorithm with\n\\emph{hindsight} to tackle the challenge of sparse rewards. Hindsight refers to\nthe algorithm's ability to learn from information across goals, including ones\nnot intended for the current task. HTRPO leverages two main ideas. It\nintroduces QKL, a quadratic approximation to the KL divergence constraint on\nthe trust region, leading to reduced variance in KL divergence estimation and\nimproved stability in policy update. It also presents Hindsight Goal\nFiltering(HGF) to select conductive hindsight goals. In experiments, we\nevaluate HTRPO in various sparse reward tasks, including simple benchmarks,\nimage-based Atari games, and simulated robot control. Ablation studies indicate\nthat QKL and HGF contribute greatly to learning stability and high performance.\nComparison results show that in all tasks, HTRPO consistently outperforms both\nTRPO and HPG, a state-of-the-art algorithm for RL with sparse rewards.\n", "versions": [{"version": "v1", "created": "Mon, 29 Jul 2019 13:59:42 GMT"}, {"version": "v2", "created": "Tue, 24 Sep 2019 15:16:59 GMT"}, {"version": "v3", "created": "Tue, 11 Feb 2020 02:00:15 GMT"}, {"version": "v4", "created": "Wed, 12 May 2021 14:24:39 GMT"}, {"version": "v5", "created": "Mon, 17 May 2021 06:09:53 GMT"}], "update_date": "2021-05-18", "authors_parsed": [["Zhang", "Hanbo", ""], ["Bai", "Site", ""], ["Lan", "Xuguang", ""], ["Hsu", "David", ""], ["Zheng", "Nanning", ""]]}, {"id": "1907.12477", "submitter": "Robert Tjarko Lange", "authors": "Robert Tjarko Lange, Aldo Faisal", "title": "Semantic RL with Action Grammars: Data-Efficient Learning of\n  Hierarchical Task Abstractions", "comments": "11 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hierarchical Reinforcement Learning algorithms have successfully been applied\nto temporal credit assignment problems with sparse reward signals. However,\nstate-of-the-art algorithms require manual specification of sub-task\nstructures, a sample inefficient exploration phase or lack semantic\ninterpretability. Humans, on the other hand, efficiently detect hierarchical\nsub-structures induced by their surroundings. It has been argued that this\ninference process universally applies to language, logical reasoning as well as\nmotor control. Therefore, we propose a cognitive-inspired Reinforcement\nLearning architecture which uses grammar induction to identify sub-goal\npolicies. By treating an on-policy trajectory as a sentence sampled from the\npolicy-conditioned language of the environment, we identify hierarchical\nconstituents with the help of unsupervised grammatical inference. The resulting\nset of temporal abstractions is called action grammar (Pastra & Aloimonos,\n2012) and unifies symbolic and connectionist approaches to Reinforcement\nLearning. It can be used to facilitate efficient imitation, transfer and online\nlearning.\n", "versions": [{"version": "v1", "created": "Mon, 29 Jul 2019 15:27:50 GMT"}, {"version": "v2", "created": "Mon, 23 Sep 2019 17:26:35 GMT"}], "update_date": "2019-09-24", "authors_parsed": [["Lange", "Robert Tjarko", ""], ["Faisal", "Aldo", ""]]}, {"id": "1907.12495", "submitter": "Jessica Zangari", "authors": "Alessio Fiorentino, Nicola Leone, Marco Manna, Simona Perri, Jessica\n  Zangari", "title": "Precomputing Datalog evaluation plans in large-scale scenarios", "comments": "Paper presented at the 35th International Conference on Logic\n  Programming (ICLP 2019), Las Cruces, New Mexico, USA, 20-25 September 2019,\n  16 pages", "journal-ref": "Theory and Practice of Logic Programming 19 (2019) 1073-1089", "doi": "10.1017/S147106841900036X", "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the more and more growing demand for semantic Web services over large\ndatabases, an efficient evaluation of Datalog queries is arousing a renewed\ninterest among researchers and industry experts. In this scenario, to reduce\nmemory consumption and possibly optimize execution times, the paper proposes\nnovel techniques to determine an optimal indexing schema for the underlying\ndatabase together with suitable body-orderings for the Datalog rules. The new\napproach is compared with the standard execution plans implemented in DLV over\nwidely used ontological benchmarks. The results confirm that the memory usage\ncan be significantly reduced without paying any cost in efficiency. This paper\nis under consideration in Theory and Practice of Logic Programming (TPLP).\n", "versions": [{"version": "v1", "created": "Mon, 29 Jul 2019 15:52:45 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Fiorentino", "Alessio", ""], ["Leone", "Nicola", ""], ["Manna", "Marco", ""], ["Perri", "Simona", ""], ["Zangari", "Jessica", ""]]}, {"id": "1907.12501", "submitter": "Matthias Knorr", "authors": "Matti Berthold, Ricardo Gon\\c{c}alves, Matthias Knorr, Jo\\~ao Leite", "title": "A Syntactic Operator for Forgetting that Satisfies Strong Persistence", "comments": "Paper presented at the 35th International Conference on Logic\n  Programming (ICLP 2019), Las Cruces, New Mexico, USA, 20-25 September 2019,\n  16 pages", "journal-ref": "Theory and Practice of Logic Programming 19 (2019) 1038-1055", "doi": "10.1017/S1471068419000346", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Whereas the operation of forgetting has recently seen a considerable amount\nof attention in the context of Answer Set Programming (ASP), most of it has\nfocused on theoretical aspects, leaving the practical issues largely untouched.\nRecent studies include results about what sets of properties operators should\nsatisfy, as well as the abstract characterization of several operators and\ntheir theoretical limits. However, no concrete operators have been\ninvestigated.\n  In this paper, we address this issue by presenting the first concrete\noperator that satisfies strong persistence - a property that seems to best\ncapture the essence of forgetting in the context of ASP - whenever this is\npossible, and many other important properties. The operator is syntactic,\nlimiting the computation of the forgetting result to manipulating the rules in\nwhich the atoms to be forgotten occur, naturally yielding a forgetting result\nthat is close to the original program.\n  This paper is under consideration for acceptance in TPLP.\n", "versions": [{"version": "v1", "created": "Mon, 29 Jul 2019 16:03:48 GMT"}, {"version": "v2", "created": "Wed, 31 Jul 2019 11:32:06 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Berthold", "Matti", ""], ["Gon\u00e7alves", "Ricardo", ""], ["Knorr", "Matthias", ""], ["Leite", "Jo\u00e3o", ""]]}, {"id": "1907.12648", "submitter": "Pavel Surynek", "authors": "Pavel Surynek, T. K. Satish Kumar, Sven Koenig", "title": "Multi-Agent Path Finding with Capacity Constraints", "comments": "arXiv admin note: substantial text overlap with arXiv:1809.05959 and\n  arXiv:1907.07631", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In multi-agent path finding (MAPF) the task is to navigate agents from their\nstarting positions to given individual goals. The problem takes place in an\nundirected graph whose vertices represent positions and edges define the\ntopology. Agents can move to neighbor vertices across edges. In the standard\nMAPF, space occupation by agents is modeled by a capacity constraint that\npermits at most one agent per vertex. We suggest an extension of MAPF in this\npaper that permits more than one agent per vertex. Propositional satisfiability\n(SAT) models for these extensions of MAPF are studied. We focus on modeling\ncapacity constraints in SAT-based formulations of MAPF and evaluation of\nperformance of these models. We extend two existing SAT-based formulations with\nvertex capacity constraints: MDD-SAT and SMT-CBS where the former is an\napproach that builds the model in an eager way while the latter relies on lazy\nconstruction of the model.\n", "versions": [{"version": "v1", "created": "Sun, 21 Jul 2019 22:41:33 GMT"}], "update_date": "2019-07-31", "authors_parsed": [["Surynek", "Pavel", ""], ["Kumar", "T. K. Satish", ""], ["Koenig", "Sven", ""]]}, {"id": "1907.12652", "submitter": "Christin Seifert", "authors": "Andrea Papenmeier and Gwenn Englebienne and Christin Seifert", "title": "How model accuracy and explanation fidelity influence user trust", "comments": "AI IJCAI Workshop on Explainable Artificial Intelligence (X-AI) 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning systems have become popular in fields such as marketing,\nfinancing, or data mining. While they are highly accurate, complex machine\nlearning systems pose challenges for engineers and users. Their inherent\ncomplexity makes it impossible to easily judge their fairness and the\ncorrectness of statistically learned relations between variables and classes.\nExplainable AI aims to solve this challenge by modelling explanations alongside\nwith the classifiers, potentially improving user trust and acceptance. However,\nusers should not be fooled by persuasive, yet untruthful explanations. We\ntherefore conduct a user study in which we investigate the effects of model\naccuracy and explanation fidelity, i.e. how truthfully the explanation\nrepresents the underlying model, on user trust. Our findings show that accuracy\nis more important for user trust than explainability. Adding an explanation for\na classification result can potentially harm trust, e.g. when adding\nnonsensical explanations. We also found that users cannot be tricked by\nhigh-fidelity explanations into having trust for a bad classifier. Furthermore,\nwe found a mismatch between observed (implicit) and self-reported (explicit)\ntrust.\n", "versions": [{"version": "v1", "created": "Fri, 26 Jul 2019 09:22:16 GMT"}], "update_date": "2019-07-31", "authors_parsed": [["Papenmeier", "Andrea", ""], ["Englebienne", "Gwenn", ""], ["Seifert", "Christin", ""]]}, {"id": "1907.12667", "submitter": "Boyuan Pan", "authors": "Boyuan Pan, Hao Li, Ziyu Yao, Deng Cai, Huan Sun", "title": "Reinforced Dynamic Reasoning for Conversational Question Generation", "comments": "Accepted in ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper investigates a new task named Conversational Question Generation\n(CQG) which is to generate a question based on a passage and a conversation\nhistory (i.e., previous turns of question-answer pairs). CQG is a crucial task\nfor developing intelligent agents that can drive question-answering style\nconversations or test user understanding of a given passage. Towards that end,\nwe propose a new approach named Reinforced Dynamic Reasoning (ReDR) network,\nwhich is based on the general encoder-decoder framework but incorporates a\nreasoning procedure in a dynamic manner to better understand what has been\nasked and what to ask next about the passage. To encourage producing meaningful\nquestions, we leverage a popular question answering (QA) model to provide\nfeedback and fine-tune the question generator using a reinforcement learning\nmechanism. Empirical results on the recently released CoQA dataset demonstrate\nthe effectiveness of our method in comparison with various baselines and model\nvariants. Moreover, to show the applicability of our method, we also apply it\nto create multi-turn question-answering conversations for passages in SQuAD.\n", "versions": [{"version": "v1", "created": "Mon, 29 Jul 2019 21:56:35 GMT"}], "update_date": "2019-07-31", "authors_parsed": [["Pan", "Boyuan", ""], ["Li", "Hao", ""], ["Yao", "Ziyu", ""], ["Cai", "Deng", ""], ["Sun", "Huan", ""]]}, {"id": "1907.12669", "submitter": "Muhammad Aurangzeb Ahmad", "authors": "Muhammad Aurangzeb Ahmad, Carly Eckert, Ankur Teredesai", "title": "The Challenge of Imputation in Explainable Artificial Intelligence\n  Models", "comments": "The IJCAI-19 Workshop on Artificial Intelligence Safety", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Explainable models in Artificial Intelligence are often employed to ensure\ntransparency and accountability of AI systems. The fidelity of the explanations\nare dependent upon the algorithms used as well as on the fidelity of the data.\nMany real world datasets have missing values that can greatly influence\nexplanation fidelity. The standard way to deal with such scenarios is\nimputation. This can, however, lead to situations where the imputed values may\ncorrespond to a setting which refer to counterfactuals. Acting on explanations\nfrom AI models with imputed values may lead to unsafe outcomes. In this paper,\nwe explore different settings where AI models with imputation can be\nproblematic and describe ways to address such scenarios.\n", "versions": [{"version": "v1", "created": "Mon, 29 Jul 2019 22:06:21 GMT"}], "update_date": "2019-07-31", "authors_parsed": [["Ahmad", "Muhammad Aurangzeb", ""], ["Eckert", "Carly", ""], ["Teredesai", "Ankur", ""]]}, {"id": "1907.12687", "submitter": "Mor Vered", "authors": "Mor Vered, Frank Dignum and Tim Miller", "title": "Let's Make It Personal, A Challenge in Personalizing Medical Inter-Human\n  Communication", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current AI approaches have frequently been used to help personalize many\naspects of medical experiences and tailor them to a specific individuals'\nneeds. However, while such systems consider medically-relevant information,\nthey ignore socially-relevant information about how this diagnosis should be\ncommunicated and discussed with the patient. The lack of this capability may\nlead to mis-communication, resulting in serious implications, such as patients\nopting out of the best treatment. Consider a case in which the same treatment\nis proposed to two different individuals. The manner in which this treatment is\nmediated to each should be different, depending on the individual patient's\nhistory, knowledge, and mental state. While it is clear that this communication\nshould be conveyed via a human medical expert and not a software-based system,\nhumans are not always capable of considering all of the relevant aspects and\ntraversing all available information. We pose the challenge of creating\nIntelligent Agents (IAs) to assist medical service providers (MSPs) and\nconsumers in establishing a more personalized human-to-human dialogue.\nPersonalizing conversations will enable patients and MSPs to reach a solution\nthat is best for their particular situation, such that a relation of trust can\nbe built and commitment to the outcome of the interaction is assured. We\npropose a four-part conceptual framework for personalized social interactions,\nexpand on which techniques are available within current AI research and discuss\nwhat has yet to be achieved.\n", "versions": [{"version": "v1", "created": "Mon, 29 Jul 2019 23:37:25 GMT"}], "update_date": "2019-07-31", "authors_parsed": [["Vered", "Mor", ""], ["Dignum", "Frank", ""], ["Miller", "Tim", ""]]}, {"id": "1907.12690", "submitter": "Byunghyun Ban", "authors": "Byunghyun Ban, Soobin Kim", "title": "Control of nonlinear, complex and black-boxed greenhouse system with\n  reinforcement learning", "comments": "4 pages, 2 figures, 1 table. 2 pages of supplementary information.\n  Published on ICTC 2017", "journal-ref": "2017 International Conference on Information and Communication\n  Technology Convergence (ICTC)", "doi": "10.1109/ICTC.2017.8190813", "report-no": null, "categories": "cs.LG cs.AI cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern control theories such as systems engineering approaches try to solve\nnonlinear system problems by revelation of causal relationship or\nco-relationship among the components; most of those approaches focus on control\nof sophisticatedly modeled white-boxed systems. We suggest an application of\nactor-critic reinforcement learning approach to control a nonlinear, complex\nand black-boxed system. We demonstrated this approach on artificial green-house\nenvironment simulator all of whose control inputs have several side effects so\nhuman cannot figure out how to control this system easily. Our approach\nsucceeded to maintain the circumstance at least 20 times longer than PID and\nDeep Q Learning.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jul 2019 00:06:47 GMT"}], "update_date": "2021-01-07", "authors_parsed": [["Ban", "Byunghyun", ""], ["Kim", "Soobin", ""]]}, {"id": "1907.12868", "submitter": "Lars Schmarje", "authors": "Lars Schmarje, Claudius Zelenka, Ulf Geisen, Claus-C. Gl\\\"uer,\n  Reinhard Koch", "title": "2D and 3D Segmentation of uncertain local collagen fiber orientations in\n  SHG microscopy", "comments": null, "journal-ref": "DAGM GCPR 2019", "doi": "10.1007/978-3-030-33676-9_26", "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Collagen fiber orientations in bones, visible with Second Harmonic Generation\n(SHG) microscopy, represent the inner structure and its alteration due to\ninfluences like cancer. While analyses of these orientations are valuable for\nmedical research, it is not feasible to analyze the needed large amounts of\nlocal orientations manually. Since we have uncertain borders for these local\norientations only rough regions can be segmented instead of a pixel-wise\nsegmentation. We analyze the effect of these uncertain borders on human\nperformance by a user study. Furthermore, we compare a variety of 2D and 3D\nmethods such as classical approaches like Fourier analysis with\nstate-of-the-art deep neural networks for the classification of local fiber\norientations. We present a general way to use pretrained 2D weights in 3D\nneural networks, such as Inception-ResNet-3D a 3D extension of\nInception-ResNet-v2. In a 10 fold cross-validation our two stage segmentation\nbased on Inception-ResNet-3D and transferred 2D ImageNet weights achieves a\nhuman comparable accuracy.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jul 2019 12:56:01 GMT"}], "update_date": "2020-06-29", "authors_parsed": [["Schmarje", "Lars", ""], ["Zelenka", "Claudius", ""], ["Geisen", "Ulf", ""], ["Gl\u00fcer", "Claus-C.", ""], ["Koch", "Reinhard", ""]]}, {"id": "1907.12887", "submitter": "Fabian B. Fuchs Mr", "authors": "Fabian B. Fuchs, Adam R. Kosiorek, Li Sun, Oiwi Parker Jones, Ingmar\n  Posner", "title": "End-to-end Recurrent Multi-Object Tracking and Trajectory Prediction\n  with Relational Reasoning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The majority of contemporary object-tracking approaches do not model\ninteractions between objects. This contrasts with the fact that objects' paths\nare not independent: a cyclist might abruptly deviate from a previously planned\ntrajectory in order to avoid colliding with a car. Building upon HART, a neural\nclass-agnostic single-object tracker, we introduce a multi-object tracking\nmethod MOHART capable of relational reasoning. Importantly, the entire system,\nincluding the understanding of interactions and relations between objects, is\nclass-agnostic and learned simultaneously in an end-to-end fashion. We explore\na number of relational reasoning architectures and show that\npermutation-invariant models outperform non-permutation-invariant alternatives.\nWe also find that architectures using a single permutation invariant operation\nlike DeepSets, despite, in theory, being universal function approximators, are\nnonetheless outperformed by a more complex architecture based on multi-headed\nattention. The latter better accounts for complex physical interactions in a\nchallenging toy experiment. Further, we find that modelling interactions leads\nto consistent performance gains in tracking as well as future trajectory\nprediction on three real-world datasets (MOTChallenge, UA-DETRAC, and Stanford\nDrone dataset), particularly in the presence of ego-motion, occlusions, crowded\nscenes, and faulty sensor inputs.\n", "versions": [{"version": "v1", "created": "Fri, 12 Jul 2019 22:40:13 GMT"}, {"version": "v2", "created": "Fri, 9 Aug 2019 17:17:49 GMT"}, {"version": "v3", "created": "Mon, 30 Sep 2019 15:44:01 GMT"}, {"version": "v4", "created": "Thu, 30 Apr 2020 21:40:28 GMT"}, {"version": "v5", "created": "Mon, 28 Sep 2020 14:25:23 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Fuchs", "Fabian B.", ""], ["Kosiorek", "Adam R.", ""], ["Sun", "Li", ""], ["Jones", "Oiwi Parker", ""], ["Posner", "Ingmar", ""]]}, {"id": "1907.12908", "submitter": "Hossein Zeinali", "authors": "Hossein Zeinali, Themos Stafylakis, Georgia Athanasopoulou, Johan\n  Rohdin, Ioannis Gkinis, Luk\\'a\\v{s} Burget, Jan \"Honza'' \\v{C}ernock\\'y", "title": "Detecting Spoofing Attacks Using VGG and SincNet: BUT-Omilia Submission\n  to ASVspoof 2019 Challenge", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present the system description of the joint efforts of Brno\nUniversity of Technology (BUT) and Omilia -- Conversational Intelligence for\nthe ASVSpoof2019 Spoofing and Countermeasures Challenge. The primary submission\nfor Physical access (PA) is a fusion of two VGG networks, trained on single and\ntwo-channels features. For Logical access (LA), our primary system is a fusion\nof VGG and the recently introduced SincNet architecture. The results on PA show\nthat the proposed networks yield very competitive performance in all conditions\nand achieved 86\\:\\% relative improvement compared to the official baseline. On\nthe other hand, the results on LA showed that although the proposed\narchitecture and training strategy performs very well on certain spoofing\nattacks, it fails to generalize to certain attacks that are unseen during\ntraining.\n", "versions": [{"version": "v1", "created": "Sat, 13 Jul 2019 17:27:40 GMT"}], "update_date": "2019-07-31", "authors_parsed": [["Zeinali", "Hossein", ""], ["Stafylakis", "Themos", ""], ["Athanasopoulou", "Georgia", ""], ["Rohdin", "Johan", ""], ["Gkinis", "Ioannis", ""], ["Burget", "Luk\u00e1\u0161", ""], ["\u010cernock\u00fd", "Jan \"Honza''", ""]]}, {"id": "1907.12991", "submitter": "Jorge Guevara", "authors": "Jorge Guevara, Roberto Hirata Jr, St\\'ephane Canu", "title": "Kernels on fuzzy sets: an overview", "comments": "Learning on Distributions, Functions, Graphs and Groups @ NIPS-2017,\n  8th Dec", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces the concept of kernels on fuzzy sets as a similarity\nmeasure for $[0,1]$-valued functions, a.k.a. \\emph{membership functions of\nfuzzy sets}.\n  We defined the following classes of kernels: the cross product, the\nintersection, the non-singleton and the distance-based kernels on fuzzy sets.\n  Applicability of those kernels are on machine learning and data science tasks\nwhere uncertainty in data has an ontic or epistemistic interpretation.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jul 2019 14:54:01 GMT"}], "update_date": "2019-07-31", "authors_parsed": [["Guevara", "Jorge", ""], ["Hirata", "Roberto", "Jr"], ["Canu", "St\u00e9phane", ""]]}, {"id": "1907.13054", "submitter": "Volker Fischer", "authors": "Lukas Hoyer, Mauricio Munoz, Prateek Katiyar, Anna Khoreva, Volker\n  Fischer", "title": "Grid Saliency for Context Explanations of Semantic Segmentation", "comments": "33rd Conference on Neural Information Processing Systems (NeurIPS\n  2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, there has been a growing interest in developing saliency methods\nthat provide visual explanations of network predictions. Still, the usability\nof existing methods is limited to image classification models. To overcome this\nlimitation, we extend the existing approaches to generate grid saliencies,\nwhich provide spatially coherent visual explanations for (pixel-level) dense\nprediction networks. As the proposed grid saliency allows to spatially\ndisentangle the object and its context, we specifically explore its potential\nto produce context explanations for semantic segmentation networks, discovering\nwhich context most influences the class predictions inside a target object\narea. We investigate the effectiveness of grid saliency on a synthetic dataset\nwith an artificially induced bias between objects and their context as well as\non the real-world Cityscapes dataset using state-of-the-art segmentation\nnetworks. Our results show that grid saliency can be successfully used to\nprovide easily interpretable context explanations and, moreover, can be\nemployed for detecting and localizing contextual biases present in the data.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jul 2019 16:25:52 GMT"}, {"version": "v2", "created": "Thu, 7 Nov 2019 12:29:44 GMT"}], "update_date": "2019-11-11", "authors_parsed": [["Hoyer", "Lukas", ""], ["Munoz", "Mauricio", ""], ["Katiyar", "Prateek", ""], ["Khoreva", "Anna", ""], ["Fischer", "Volker", ""]]}, {"id": "1907.13062", "submitter": "Laurent Orseau", "authors": "Malte Helmert, Tor Lattimore, Levi H. S. Lelis, Laurent Orseau, Nathan\n  R. Sturtevant", "title": "Iterative Budgeted Exponential Search", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We tackle two long-standing problems related to re-expansions in heuristic\nsearch algorithms. For graph search, A* can require $\\Omega(2^{n})$ expansions,\nwhere $n$ is the number of states within the final $f$ bound. Existing\nalgorithms that address this problem like B and B' improve this bound to\n$\\Omega(n^2)$. For tree search, IDA* can also require $\\Omega(n^2)$ expansions.\nWe describe a new algorithmic framework that iteratively controls an expansion\nbudget and solution cost limit, giving rise to new graph and tree search\nalgorithms for which the number of expansions is $O(n \\log C)$, where $C$ is\nthe optimal solution cost. Our experiments show that the new algorithms are\nrobust in scenarios where existing algorithms fail. In the case of tree search,\nour new algorithms have no overhead over IDA* in scenarios to which IDA* is\nwell suited and can therefore be recommended as a general replacement for IDA*.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jul 2019 16:40:41 GMT"}], "update_date": "2019-07-31", "authors_parsed": [["Helmert", "Malte", ""], ["Lattimore", "Tor", ""], ["Lelis", "Levi H. S.", ""], ["Orseau", "Laurent", ""], ["Sturtevant", "Nathan R.", ""]]}, {"id": "1907.13196", "submitter": "Mohammed Amin Abdullah Dr", "authors": "Mohammed Amin Abdullah and Hang Ren and Haitham Bou Ammar and Vladimir\n  Milenkovic and Rui Luo and Mingtian Zhang and Jun Wang", "title": "Wasserstein Robust Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning algorithms, though successful, tend to over-fit to\ntraining environments hampering their application to the real-world. This paper\nproposes $\\text{W}\\text{R}^{2}\\text{L}$ -- a robust reinforcement learning\nalgorithm with significant robust performance on low and high-dimensional\ncontrol tasks. Our method formalises robust reinforcement learning as a novel\nmin-max game with a Wasserstein constraint for a correct and convergent solver.\nApart from the formulation, we also propose an efficient and scalable solver\nfollowing a novel zero-order optimisation method that we believe can be useful\nto numerical optimisation in general. We empirically demonstrate significant\ngains compared to standard and robust state-of-the-art algorithms on\nhigh-dimensional MuJuCo environments.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jul 2019 19:42:52 GMT"}, {"version": "v2", "created": "Sun, 4 Aug 2019 12:17:48 GMT"}, {"version": "v3", "created": "Sat, 10 Aug 2019 10:05:35 GMT"}, {"version": "v4", "created": "Mon, 16 Sep 2019 22:43:14 GMT"}], "update_date": "2019-09-18", "authors_parsed": [["Abdullah", "Mohammed Amin", ""], ["Ren", "Hang", ""], ["Ammar", "Haitham Bou", ""], ["Milenkovic", "Vladimir", ""], ["Luo", "Rui", ""], ["Zhang", "Mingtian", ""], ["Wang", "Jun", ""]]}, {"id": "1907.13257", "submitter": "Saptadeep Pal", "authors": "Saptadeep Pal and Eiman Ebrahimi and Arslan Zulfiqar and Yaosheng Fu\n  and Victor Zhang and Szymon Migacz and David Nellans and Puneet Gupta", "title": "Optimizing Multi-GPU Parallelization Strategies for Deep Learning\n  Training", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.DC stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Deploying deep learning (DL) models across multiple compute devices to train\nlarge and complex models continues to grow in importance because of the demand\nfor faster and more frequent training. Data parallelism (DP) is the most widely\nused parallelization strategy, but as the number of devices in data parallel\ntraining grows, so does the communication overhead between devices.\nAdditionally, a larger aggregate batch size per step leads to statistical\nefficiency loss, i.e., a larger number of epochs are required to converge to a\ndesired accuracy. These factors affect overall training time and beyond a\ncertain number of devices, the speedup from leveraging DP begins to scale\npoorly. In addition to DP, each training step can be accelerated by exploiting\nmodel parallelism (MP). This work explores hybrid parallelization, where each\ndata parallel worker is comprised of more than one device, across which the\nmodel dataflow graph (DFG) is split using MP. We show that at scale, hybrid\ntraining will be more effective at minimizing end-to-end training time than\nexploiting DP alone. We project that for Inception-V3, GNMT, and BigLSTM, the\nhybrid strategy provides an end-to-end training speedup of at least 26.5%, 8%,\nand 22% respectively compared to what DP alone can achieve at scale.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jul 2019 23:20:50 GMT"}], "update_date": "2019-08-01", "authors_parsed": [["Pal", "Saptadeep", ""], ["Ebrahimi", "Eiman", ""], ["Zulfiqar", "Arslan", ""], ["Fu", "Yaosheng", ""], ["Zhang", "Victor", ""], ["Migacz", "Szymon", ""], ["Nellans", "David", ""], ["Gupta", "Puneet", ""]]}, {"id": "1907.13274", "submitter": "Uehwan Kim", "authors": "Ue-Hwan Kim and Jong-Hwan Kim", "title": "A Stabilized Feedback Episodic Memory (SF-EM) and Home Service Provision\n  Framework for Robot and IoT Collaboration", "comments": "Accepted (Early Access)", "journal-ref": null, "doi": "10.1109/TCYB.2018.2882921", "report-no": null, "categories": "cs.RO cs.AI cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The automated home referred to as Smart Home is expected to offer fully\ncustomized services to its residents, reducing the amount of home labor, thus\nimproving human beings' welfare. Service robots and Internet of Things (IoT)\nplay the key roles in the development of Smart Home. The service provision with\nthese two main components in a Smart Home environment requires: 1) learning and\nreasoning algorithms and 2) the integration of robot and IoT systems.\nConventional computational intelligence-based learning and reasoning algorithms\ndo not successfully manage dynamic changes in the Smart Home data, and the\nsimple integrations fail to fully draw the synergies from the collaboration of\nthe two systems. To tackle these limitations, we propose: 1) a stabilized\nmemory network with a feedback mechanism which can learn user behaviors in an\nincremental manner and 2) a robot-IoT service provision framework for a Smart\nHome which utilizes the proposed memory architecture as a learning and\nreasoning module and exploits synergies between the robot and IoT systems. We\nconduct a set of comprehensive experiments under various conditions to verify\nthe performance of the proposed memory architecture and the service provision\nframework and analyze the experiment results.\n", "versions": [{"version": "v1", "created": "Wed, 31 Jul 2019 01:27:34 GMT"}], "update_date": "2019-08-01", "authors_parsed": [["Kim", "Ue-Hwan", ""], ["Kim", "Jong-Hwan", ""]]}, {"id": "1907.13275", "submitter": "Mohan Sridharan", "authors": "Rocio Gomez, Mohan Sridharan, Heather Riley", "title": "Towards a Theory of Intentions for Human-Robot Collaboration", "comments": "25 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The architecture described in this paper encodes a theory of intentions based\non the the key principles of non-procrastination, persistence, and\nautomatically limiting reasoning to relevant knowledge and observations. The\narchitecture reasons with transition diagrams of any given domain at two\ndifferent resolutions, with the fine-resolution description defined as a\nrefinement of, and hence tightly-coupled to, a coarse-resolution description.\nNon-monotonic logical reasoning with the coarse-resolution description computes\nan activity (i.e., plan) comprising abstract actions for any given goal. Each\nabstract action is implemented as a sequence of concrete actions by\nautomatically zooming to and reasoning with the part of the fine-resolution\ntransition diagram relevant to the current coarse-resolution transition and the\ngoal. Each concrete action in this sequence is executed using probabilistic\nmodels of the uncertainty in sensing and actuation, and the corresponding\nfine-resolution outcomes are used to infer coarse-resolution observations that\nare added to the coarse-resolution history. The architecture's capabilities are\nevaluated in the context of a simulated robot assisting humans in an office\ndomain, on a physical robot (Baxter) manipulating tabletop objects, and on a\nwheeled robot (Turtlebot) moving objects to particular places or people. The\nexperimental results indicate improvements in reliability and computational\nefficiency compared with an architecture that does not include the theory of\nintentions, and an architecture that does not include zooming for\nfine-resolution reasoning.\n", "versions": [{"version": "v1", "created": "Wed, 31 Jul 2019 01:31:04 GMT"}], "update_date": "2019-08-01", "authors_parsed": [["Gomez", "Rocio", ""], ["Sridharan", "Mohan", ""], ["Riley", "Heather", ""]]}, {"id": "1907.13285", "submitter": "Uehwan Kim", "authors": "Ue-Hwan Kim, Sahng-Min Yoo and Jong-Hwan Kim", "title": "I-Keyboard: Fully Imaginary Keyboard on Touch Devices Empowered by Deep\n  Neural Decoder", "comments": "Submitted to IEEE TRANSACTIONS ON CYBERNETICS", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Text-entry aims to provide an effective and efficient pathway for humans to\ndeliver their messages to computers. With the advent of mobile computing, the\nrecent focus of text-entry research has moved from physical keyboards to soft\nkeyboards. Current soft keyboards, however, increase the typo rate due to lack\nof tactile feedback and degrade the usability of mobile devices due to their\nlarge portion on screens. To tackle these limitations, we propose a fully\nimaginary keyboard (I-Keyboard) with a deep neural decoder (DND). The\ninvisibility of I-Keyboard maximizes the usability of mobile devices and DND\nempowered by a deep neural architecture allows users to start typing from any\nposition on the touch screens at any angle. To the best of our knowledge, the\neyes-free ten-finger typing scenario of I-Keyboard which does not necessitate\nboth a calibration step and a predefined region for typing is first explored in\nthis work. For the purpose of training DND, we collected the largest user data\nin the process of developing I-Keyboard. We verified the performance of the\nproposed I-Keyboard and DND by conducting a series of comprehensive simulations\nand experiments under various conditions. I-Keyboard showed 18.95% and 4.06%\nincreases in typing speed (45.57 WPM) and accuracy (95.84%), respectively over\nthe baseline.\n", "versions": [{"version": "v1", "created": "Wed, 31 Jul 2019 02:22:49 GMT"}], "update_date": "2019-08-01", "authors_parsed": [["Kim", "Ue-Hwan", ""], ["Yoo", "Sahng-Min", ""], ["Kim", "Jong-Hwan", ""]]}, {"id": "1907.13295", "submitter": "Sahisnu Mazumder", "authors": "Sahisnu Mazumder, Bing Liu, Shuai Wang, Nianzu Ma", "title": "Lifelong and Interactive Learning of Factual Knowledge in Dialogues", "comments": "Published in SIGDIAL 2019", "journal-ref": null, "doi": "10.18653/v1/W19-5903", "report-no": null, "categories": "cs.CL cs.AI cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dialogue systems are increasingly using knowledge bases (KBs) storing\nreal-world facts to help generate quality responses. However, as the KBs are\ninherently incomplete and remain fixed during conversation, it limits dialogue\nsystems' ability to answer questions and to handle questions involving entities\nor relations that are not in the KB. In this paper, we make an attempt to\npropose an engine for Continuous and Interactive Learning of Knowledge (CILK)\nfor dialogue systems to give them the ability to continuously and interactively\nlearn and infer new knowledge during conversations. With more knowledge\naccumulated over time, they will be able to learn better and answer more\nquestions. Our empirical evaluation shows that CILK is promising.\n", "versions": [{"version": "v1", "created": "Wed, 31 Jul 2019 03:11:33 GMT"}, {"version": "v2", "created": "Sat, 21 Dec 2019 02:25:13 GMT"}], "update_date": "2019-12-24", "authors_parsed": [["Mazumder", "Sahisnu", ""], ["Liu", "Bing", ""], ["Wang", "Shuai", ""], ["Ma", "Nianzu", ""]]}, {"id": "1907.13305", "submitter": "EPTCS", "authors": "Jos\\'e Luis Vilchis Medina (LIS), Pierre Siegel (LIS), Vincent Risch\n  (LIS), Andrei Doncescu (LAAS)", "title": "An Implementation of a Non-monotonic Logic in an Embedded Computer for a\n  Motor-glider", "comments": "In Proceedings ICLP 2019, arXiv:1909.07646", "journal-ref": "EPTCS 306, 2019, pp. 323-329", "doi": "10.4204/EPTCS.306.37", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this article we present an implementation of non-monotonic reasoning in an\nembedded system. As a part of an autonomous motor-glider, it simulates piloting\ndecisions of an airplane. A real pilot must take care not only about the\ninformation arising from the cockpit (airspeed, altitude, variometer,\ncompass...) but also from outside the cabin. Throughout a flight, a pilot is\nconstantly in communication with the control tower to follow orders, because\nthere is an airspace regulation to respect. In addition, if the control tower\nsends orders while the pilot has an emergency, he may have to violate these\norders and airspace regulations to solve his problem (e.g. emergency landing).\nOn the other hand, climate changes constantly (wind, snow, hail..) and can\naffect the sensors. All these cases easily lead to contradictions. Switching to\nreasoning under uncertainty, a pilot must make decisions to carry out a flight.\nThe objective of this implementation is to validate a non-monotonic model which\nallows to solve the question of incomplete and contradictory information. We\nformalize the problem using default logic, a non-monotonic logic which allows\nto find fixed-points in the face of contradictions. For the implementation, the\nProlog language is used in an embedded computer running at 1 GHz single core\nwith 512 Mb of RAM and 0.8 watts of energy consumption.\n", "versions": [{"version": "v1", "created": "Wed, 31 Jul 2019 04:48:56 GMT"}, {"version": "v2", "created": "Fri, 20 Sep 2019 11:08:16 GMT"}], "update_date": "2019-09-23", "authors_parsed": [["Medina", "Jos\u00e9 Luis Vilchis", "", "LIS"], ["Siegel", "Pierre", "", "LIS"], ["Risch", "Vincent", "", "LIS"], ["Doncescu", "Andrei", "", "LAAS"]]}, {"id": "1907.13440", "submitter": "William Guss", "authors": "William H. Guss, Brandon Houghton, Nicholay Topin, Phillip Wang,\n  Cayden Codel, Manuela Veloso, Ruslan Salakhutdinov", "title": "MineRL: A Large-Scale Dataset of Minecraft Demonstrations", "comments": "Accepted at IJCAI 2019, 7 pages, 6 figures. arXiv admin note: text\n  overlap with arXiv:1904.10079", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The sample inefficiency of standard deep reinforcement learning methods\nprecludes their application to many real-world problems. Methods which leverage\nhuman demonstrations require fewer samples but have been researched less. As\ndemonstrated in the computer vision and natural language processing\ncommunities, large-scale datasets have the capacity to facilitate research by\nserving as an experimental and benchmarking platform for new methods. However,\nexisting datasets compatible with reinforcement learning simulators do not have\nsufficient scale, structure, and quality to enable the further development and\nevaluation of methods focused on using human examples. Therefore, we introduce\na comprehensive, large-scale, simulator-paired dataset of human demonstrations:\nMineRL. The dataset consists of over 60 million automatically annotated\nstate-action pairs across a variety of related tasks in Minecraft, a dynamic,\n3D, open-world environment. We present a novel data collection scheme which\nallows for the ongoing introduction of new tasks and the gathering of complete\nstate information suitable for a variety of methods. We demonstrate the\nhierarchality, diversity, and scale of the MineRL dataset. Further, we show the\ndifficulty of the Minecraft domain along with the potential of MineRL in\ndeveloping techniques to solve key research challenges within it.\n", "versions": [{"version": "v1", "created": "Mon, 29 Jul 2019 18:10:30 GMT"}], "update_date": "2019-08-01", "authors_parsed": [["Guss", "William H.", ""], ["Houghton", "Brandon", ""], ["Topin", "Nicholay", ""], ["Wang", "Phillip", ""], ["Codel", "Cayden", ""], ["Veloso", "Manuela", ""], ["Salakhutdinov", "Ruslan", ""]]}, {"id": "1907.13482", "submitter": "Joohyung Lee", "authors": "Yi Wang and Shiqi Zhang and Joohyung Lee", "title": "Bridging Commonsense Reasoning and Probabilistic Planning via a\n  Probabilistic Action Language", "comments": "Paper presented at the 35th International Conference on Logic\n  Programming (ICLP 2019), Las Cruces, New Mexico, USA, 20-25 September 2019,\n  16 pages. arXiv admin note: text overlap with arXiv:1904.00512", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To be responsive to dynamically changing real-world environments, an\nintelligent agent needs to perform complex sequential decision-making tasks\nthat are often guided by commonsense knowledge. The previous work on this line\nof research led to the framework called \"interleaved commonsense reasoning and\nprobabilistic planning\" (icorpp), which used P-log for representing\ncommmonsense knowledge and Markov Decision Processes (MDPs) or Partially\nObservable MDPs (POMDPs) for planning under uncertainty. A main limitation of\nicorpp is that its implementation requires non-trivial engineering efforts to\nbridge the commonsense reasoning and probabilistic planning formalisms. In this\npaper, we present a unified framework to integrate icorpp's reasoning and\nplanning components. In particular, we extend probabilistic action language\npBC+ to express utility, belief states, and observation as in POMDP models.\nInheriting the advantages of action languages, the new action language provides\nan elaboration tolerant representation of POMDP that reflects commonsense\nknowledge. The idea led to the design of the system pbcplus2pomdp, which\ncompiles a pBC+ action description into a POMDP model that can be directly\nprocessed by off-the-shelf POMDP solvers to compute an optimal policy of the\npBC+ action description. Our experiments show that it retains the advantages of\nicorpp while avoiding the manual efforts in bridging the commonsense reasoner\nand the probabilistic planner.\n", "versions": [{"version": "v1", "created": "Wed, 31 Jul 2019 15:29:44 GMT"}], "update_date": "2019-08-01", "authors_parsed": [["Wang", "Yi", ""], ["Zhang", "Shiqi", ""], ["Lee", "Joohyung", ""]]}, {"id": "1907.13525", "submitter": "Tiago Botari T.B.", "authors": "Tiago Botari, Rafael Izbicki, and Andre C. P. L. F. de Carvalho", "title": "Local Interpretation Methods to Machine Learning Using the Domain of the\n  Feature Space", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As machine learning becomes an important part of many real world applications\naffecting human lives, new requirements, besides high predictive accuracy,\nbecome important. One important requirement is transparency, which has been\nassociated with model interpretability. Many machine learning algorithms induce\nmodels difficult to interpret, named black box. Moreover, people have\ndifficulty to trust models that cannot be explained. In particular for machine\nlearning, many groups are investigating new methods able to explain black box\nmodels. These methods usually look inside the black models to explain their\ninner work. By doing so, they allow the interpretation of the decision making\nprocess used by black box models. Among the recently proposed model\ninterpretation methods, there is a group, named local estimators, which are\ndesigned to explain how the label of particular instance is predicted. For\nsuch, they induce interpretable models on the neighborhood of the instance to\nbe explained. Local estimators have been successfully used to explain specific\npredictions. Although they provide some degree of model interpretability, it is\nstill not clear what is the best way to implement and apply them. Open\nquestions include: how to best define the neighborhood of an instance? How to\ncontrol the trade-off between the accuracy of the interpretation method and its\ninterpretability? How to make the obtained solution robust to small variations\non the instance to be explained? To answer to these questions, we propose and\ninvestigate two strategies: (i) using data instance properties to provide\nimproved explanations, and (ii) making sure that the neighborhood of an\ninstance is properly defined by taking the geometry of the domain of the\nfeature space into account. We evaluate these strategies in a regression task\nand present experimental results that show that they can improve local\nexplanations.\n", "versions": [{"version": "v1", "created": "Wed, 31 Jul 2019 14:28:55 GMT"}], "update_date": "2019-08-01", "authors_parsed": [["Botari", "Tiago", ""], ["Izbicki", "Rafael", ""], ["de Carvalho", "Andre C. P. L. F.", ""]]}, {"id": "1907.13528", "submitter": "Allyson Ettinger", "authors": "Allyson Ettinger", "title": "What BERT is not: Lessons from a new suite of psycholinguistic\n  diagnostics for language models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pre-training by language modeling has become a popular and successful\napproach to NLP tasks, but we have yet to understand exactly what linguistic\ncapacities these pre-training processes confer upon models. In this paper we\nintroduce a suite of diagnostics drawn from human language experiments, which\nallow us to ask targeted questions about the information used by language\nmodels for generating predictions in context. As a case study, we apply these\ndiagnostics to the popular BERT model, finding that it can generally\ndistinguish good from bad completions involving shared category or role\nreversal, albeit with less sensitivity than humans, and it robustly retrieves\nnoun hypernyms, but it struggles with challenging inferences and role-based\nevent prediction -- and in particular, it shows clear insensitivity to the\ncontextual impacts of negation.\n", "versions": [{"version": "v1", "created": "Wed, 31 Jul 2019 14:37:32 GMT"}, {"version": "v2", "created": "Mon, 13 Jul 2020 15:21:20 GMT"}], "update_date": "2020-07-14", "authors_parsed": [["Ettinger", "Allyson", ""]]}]