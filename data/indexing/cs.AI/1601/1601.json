[{"id": "1601.00027", "submitter": "Thomas Fuchs", "authors": "Thomas J. Fuchs and Joachim M. Buhmann", "title": "Computational Pathology: Challenges and Promises for Tissue Analysis", "comments": null, "journal-ref": "Computerized Medical Imaging and Graphics, vol. 35, 7-8, p.\n  515-530, 2011", "doi": "10.1016/j.compmedimag.2011.02.006", "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The histological assessment of human tissue has emerged as the key challenge\nfor detection and treatment of cancer. A plethora of different data sources\nranging from tissue microarray data to gene expression, proteomics or\nmetabolomics data provide a detailed overview of the health status of a\npatient. Medical doctors need to assess these information sources and they rely\non data driven automatic analysis tools. Methods for classification, grouping\nand segmentation of heterogeneous data sources as well as regression of noisy\ndependencies and estimation of survival probabilities enter the processing\nworkflow of a pathology diagnosis system at various stages. This paper reports\non state-of-the-art of the design and effectiveness of computational pathology\nworkflows and it discusses future research directions in this emergent field of\nmedical informatics and diagnostic machine learning.\n", "versions": [{"version": "v1", "created": "Thu, 31 Dec 2015 22:33:44 GMT"}], "update_date": "2016-01-05", "authors_parsed": [["Fuchs", "Thomas J.", ""], ["Buhmann", "Joachim M.", ""]]}, {"id": "1601.00287", "submitter": "Vincent Lostanlen", "authors": "Vincent Lostanlen and St\\'ephane Mallat", "title": "Wavelet Scattering on the Pitch Spiral", "comments": "Proceedings of the 18th International Conference on Digital Audio\n  Effects (DAFx-15), Trondheim, Norway, Nov 30 - Dec 3, 2015, pp. 429--432. 4\n  pages, 3 figures", "journal-ref": "Proceedings of the 18th International Conference on Digital Audio\n  Effects (DAFx-15), Trondheim, Norway, Nov 30 - Dec 3, 2015, pp. 429--432", "doi": null, "report-no": null, "categories": "cs.SD cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new representation of harmonic sounds that linearizes the\ndynamics of pitch and spectral envelope, while remaining stable to deformations\nin the time-frequency plane. It is an instance of the scattering transform, a\ngeneric operator which cascades wavelet convolutions and modulus\nnonlinearities. It is derived from the pitch spiral, in that convolutions are\nsuccessively performed in time, log-frequency, and octave index. We give a\nclosed-form approximation of spiral scattering coefficients for a nonstationary\ngeneralization of the harmonic source-filter model.\n", "versions": [{"version": "v1", "created": "Sun, 3 Jan 2016 12:30:38 GMT"}], "update_date": "2016-01-05", "authors_parsed": [["Lostanlen", "Vincent", ""], ["Mallat", "St\u00e9phane", ""]]}, {"id": "1601.00318", "submitter": "Han Zhao", "authors": "Han Zhao, Pascal Poupart, Geoff Gordon", "title": "A Unified Approach for Learning the Parameters of Sum-Product Networks", "comments": "NIPS 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a unified approach for learning the parameters of Sum-Product\nnetworks (SPNs). We prove that any complete and decomposable SPN is equivalent\nto a mixture of trees where each tree corresponds to a product of univariate\ndistributions. Based on the mixture model perspective, we characterize the\nobjective function when learning SPNs based on the maximum likelihood\nestimation (MLE) principle and show that the optimization problem can be\nformulated as a signomial program. We construct two parameter learning\nalgorithms for SPNs by using sequential monomial approximations (SMA) and the\nconcave-convex procedure (CCCP), respectively. The two proposed methods\nnaturally admit multiplicative updates, hence effectively avoiding the\nprojection operation. With the help of the unified framework, we also show\nthat, in the case of SPNs, CCCP leads to the same algorithm as Expectation\nMaximization (EM) despite the fact that they are different in general.\n", "versions": [{"version": "v1", "created": "Sun, 3 Jan 2016 18:11:14 GMT"}, {"version": "v2", "created": "Wed, 13 Jan 2016 06:49:49 GMT"}, {"version": "v3", "created": "Sat, 30 Jan 2016 19:32:33 GMT"}, {"version": "v4", "created": "Fri, 26 Aug 2016 18:10:50 GMT"}], "update_date": "2016-08-29", "authors_parsed": [["Zhao", "Han", ""], ["Poupart", "Pascal", ""], ["Gordon", "Geoff", ""]]}, {"id": "1601.00367", "submitter": "Pascal Van Hentenryck", "authors": "Arthur Maheo, Philip Kilby, Pascal Van Hentenryck", "title": "Benders Decomposition for the Design of a Hub and Shuttle Public Transit\n  System", "comments": null, "journal-ref": null, "doi": "10.1287/trsc.2017.0756", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The BusPlus project aims at improving the off-peak hours public transit\nservice in Canberra, Australia. To address the difficulty of covering a large\ngeographic area, BusPlus proposes a hub and shuttle model consisting of a\ncombination of a few high-frequency bus routes between key hubs and a large\nnumber of shuttles that bring passengers from their origin to the closest hub\nand take them from their last bus stop to their destination. This paper focuses\non the design of bus network and proposes an efficient solving method to this\nmultimodal network design problem based on the Benders decomposition method.\nStarting from a MIP formulation of the problem, the paper presents a Benders\ndecomposition approach using dedicated solution techniques for solving\nindependent sub-problems, Pareto optimal cuts, cut bundling, and core point\nupdate. Computational results on real-world data from Canberra's public transit\nsystem justify the design choices and show that the approach outperforms the\nMIP formulation by two orders of magnitude. Moreover, the results show that the\nhub and shuttle model may decrease transit time by a factor of 2, while staying\nwithin the costs of the existing transit system.\n", "versions": [{"version": "v1", "created": "Wed, 30 Dec 2015 23:26:47 GMT"}], "update_date": "2019-07-02", "authors_parsed": [["Maheo", "Arthur", ""], ["Kilby", "Philip", ""], ["Van Hentenryck", "Pascal", ""]]}, {"id": "1601.00372", "submitter": "Jiwei Li", "authors": "Jiwei Li and Dan Jurafsky", "title": "Mutual Information and Diverse Decoding Improve Neural Machine\n  Translation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sequence-to-sequence neural translation models learn semantic and syntactic\nrelations between sentence pairs by optimizing the likelihood of the target\ngiven the source, i.e., $p(y|x)$, an objective that ignores other potentially\nuseful sources of information. We introduce an alternative objective function\nfor neural MT that maximizes the mutual information between the source and\ntarget sentences, modeling the bi-directional dependency of sources and\ntargets. We implement the model with a simple re-ranking method, and also\nintroduce a decoding algorithm that increases diversity in the N-best list\nproduced by the first pass. Applied to the WMT German/English and\nFrench/English tasks, the proposed models offers a consistent performance boost\non both standard LSTM and attention-based neural MT architectures.\n", "versions": [{"version": "v1", "created": "Mon, 4 Jan 2016 03:04:05 GMT"}, {"version": "v2", "created": "Tue, 22 Mar 2016 21:15:30 GMT"}], "update_date": "2016-03-24", "authors_parsed": [["Li", "Jiwei", ""], ["Jurafsky", "Dan", ""]]}, {"id": "1601.00529", "submitter": "Fariba Sadri Dr.", "authors": "Robert Kowalski and Fariba Sadri", "title": "Programming in logic without logic programming", "comments": "Under consideration in Theory and Practice of Logic Programming\n  (TPLP)", "journal-ref": "Theory and Practice of Logic Programming 16 (2016) 269-295", "doi": "10.1017/S1471068416000041", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In previous work, we proposed a logic-based framework in which computation is\nthe execution of actions in an attempt to make reactive rules of the form if\nantecedent then consequent true in a canonical model of a logic program\ndetermined by an initial state, sequence of events, and the resulting sequence\nof subsequent states. In this model-theoretic semantics, reactive rules are the\ndriving force, and logic programs play only a supporting role.\n  In the canonical model, states, actions and other events are represented with\ntimestamps. But in the operational semantics, for the sake of efficiency,\ntimestamps are omitted and only the current state is maintained. State\ntransitions are performed reactively by executing actions to make the\nconsequents of rules true whenever the antecedents become true. This\noperational semantics is sound, but incomplete. It cannot make reactive rules\ntrue by preventing their antecedents from becoming true, or by proactively\nmaking their consequents true before their antecedents become true.\n  In this paper, we characterize the notion of reactive model, and prove that\nthe operational semantics can generate all and only such models. In order to\nfocus on the main issues, we omit the logic programming component of the\nframework.\n", "versions": [{"version": "v1", "created": "Mon, 4 Jan 2016 15:09:38 GMT"}, {"version": "v2", "created": "Tue, 5 Jan 2016 15:06:29 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Kowalski", "Robert", ""], ["Sadri", "Fariba", ""]]}, {"id": "1601.00626", "submitter": "Tim Weninger PhD", "authors": "Baoxu Shi and Tim Weninger", "title": "Scalable Models for Computing Hierarchies in Information Networks", "comments": "Preprint for \"Knowledge and Information Systems\" paper, in press", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.DL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Information hierarchies are organizational structures that often used to\norganize and present large and complex information as well as provide a\nmechanism for effective human navigation. Fortunately, many statistical and\ncomputational models exist that automatically generate hierarchies; however,\nthe existing approaches do not consider linkages in information {\\em networks}\nthat are increasingly common in real-world scenarios. Current approaches also\ntend to present topics as an abstract probably distribution over words, etc\nrather than as tangible nodes from the original network. Furthermore, the\nstatistical techniques present in many previous works are not yet capable of\nprocessing data at Web-scale. In this paper we present the Hierarchical\nDocument Topic Model (HDTM), which uses a distributed vertex-programming\nprocess to calculate a nonparametric Bayesian generative model. Experiments on\nthree medium size data sets and the entire Wikipedia dataset show that HDTM can\ninfer accurate hierarchies even over large information networks.\n", "versions": [{"version": "v1", "created": "Mon, 4 Jan 2016 20:05:19 GMT"}], "update_date": "2016-01-05", "authors_parsed": [["Shi", "Baoxu", ""], ["Weninger", "Tim", ""]]}, {"id": "1601.00669", "submitter": "Antonio Lieto", "authors": "Agnese Augello, Ignazio Infantino, Antonio Lieto, Giovanni Pilato,\n  Riccardo Rizzo, Filippo Vella", "title": "Artwork creation by a cognitive architecture integrating computational\n  creativity and dual process approaches", "comments": "30 pages, 8 figures, to appear in Biologically Inspired Cognitive\n  Architectures 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper proposes a novel cognitive architecture (CA) for computational\ncreativity based on the Psi model and on the mechanisms inspired by dual\nprocess theories of reasoning and rationality. In recent years, many cognitive\nmodels have focused on dual process theories to better describe and implement\ncomplex cognitive skills in artificial agents, but creativity has been\napproached only at a descriptive level. In previous works we have described\nvarious modules of the cognitive architecture that allows a robot to execute\ncreative paintings. By means of dual process theories we refine some relevant\nmechanisms to obtain artworks, and in particular we explain details about the\nresolution level of the CA dealing with different strategies of access to the\nLong Term Memory (LTM) and managing the interaction between S1 and S2 processes\nof the dual process theory. The creative process involves both divergent and\nconvergent processes in either implicit or explicit manner. This leads to four\nactivities (exploratory, reflective, tacit, and analytic) that, triggered by\nurges and motivations, generate creative acts. These creative acts exploit both\nthe LTM and the WM in order to make novel substitutions to a perceived image by\nproperly mixing parts of pictures coming from different domains. The paper\nhighlights the role of the interaction between S1 and S2 processes, modulated\nby the resolution level, which focuses the attention of the creative agent by\nbroadening or narrowing the exploration of novel solutions, or even drawing the\nsolution from a set of already made associations. An example of artificial\npainter is described in some experimentations by using a robotic platform.\n", "versions": [{"version": "v1", "created": "Mon, 4 Jan 2016 21:24:48 GMT"}], "update_date": "2016-01-06", "authors_parsed": [["Augello", "Agnese", ""], ["Infantino", "Ignazio", ""], ["Lieto", "Antonio", ""], ["Pilato", "Giovanni", ""], ["Rizzo", "Riccardo", ""], ["Vella", "Filippo", ""]]}, {"id": "1601.00706", "submitter": "Jimei Yang", "authors": "Jimei Yang, Scott Reed, Ming-Hsuan Yang, Honglak Lee", "title": "Weakly-supervised Disentangling with Recurrent Transformations for 3D\n  View Synthesis", "comments": "This was published in NIPS 2015 conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An important problem for both graphics and vision is to synthesize novel\nviews of a 3D object from a single image. This is particularly challenging due\nto the partial observability inherent in projecting a 3D object onto the image\nspace, and the ill-posedness of inferring object shape and pose. However, we\ncan train a neural network to address the problem if we restrict our attention\nto specific object categories (in our case faces and chairs) for which we can\ngather ample training data. In this paper, we propose a novel recurrent\nconvolutional encoder-decoder network that is trained end-to-end on the task of\nrendering rotated objects starting from a single image. The recurrent structure\nallows our model to capture long-term dependencies along a sequence of\ntransformations. We demonstrate the quality of its predictions for human faces\non the Multi-PIE dataset and for a dataset of 3D chair models, and also show\nits ability to disentangle latent factors of variation (e.g., identity and\npose) without using full supervision.\n", "versions": [{"version": "v1", "created": "Tue, 5 Jan 2016 00:08:09 GMT"}], "update_date": "2016-01-06", "authors_parsed": [["Yang", "Jimei", ""], ["Reed", "Scott", ""], ["Yang", "Ming-Hsuan", ""], ["Lee", "Honglak", ""]]}, {"id": "1601.00720", "submitter": "Subutai Ahmad", "authors": "Subutai Ahmad, Jeff Hawkins", "title": "How do neurons operate on sparse distributed representations? A\n  mathematical theory of sparsity, neurons and active dendrites", "comments": "Journal submission, under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We propose a formal mathematical model for sparse representations and active\ndendrites in neocortex. Our model is inspired by recent experimental findings\non active dendritic processing and NMDA spikes in pyramidal neurons. These\nexperimental and modeling studies suggest that the basic unit of pattern memory\nin the neocortex is instantiated by small clusters of synapses operated on by\nlocalized non-linear dendritic processes. We derive a number of scaling laws\nthat characterize the accuracy of such dendrites in detecting activation\npatterns in a neuronal population under adverse conditions. We introduce the\nunion property which shows that synapses for multiple patterns can be randomly\nmixed together within a segment and still lead to highly accurate recognition.\nWe describe simulation results that provide further insight into sparse\nrepresentations as well as two primary results. First we show that pattern\nrecognition by a neuron with active dendrites can be extremely accurate and\nrobust with high dimensional sparse inputs even when using a tiny number of\nsynapses to recognize large patterns. Second, equations representing\nrecognition accuracy of a dendrite predict optimal NMDA spiking thresholds\nunder a generous set of assumptions. The prediction tightly matches NMDA\nspiking thresholds measured in the literature. Our model matches many of the\nknown properties of pyramidal neurons. As such the theory provides a\nmathematical framework for understanding the benefits and limits of sparse\nrepresentations in cortical networks.\n", "versions": [{"version": "v1", "created": "Tue, 5 Jan 2016 02:53:09 GMT"}, {"version": "v2", "created": "Fri, 13 May 2016 01:12:00 GMT"}], "update_date": "2016-05-16", "authors_parsed": [["Ahmad", "Subutai", ""], ["Hawkins", "Jeff", ""]]}, {"id": "1601.00738", "submitter": "Jiaan Zeng", "authors": "Jiaan Zeng", "title": "Resource Sharing for Multi-Tenant NoSQL Data Store in Cloud", "comments": "PhD dissertation, December 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.AI cs.DB cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-tenancy hosting of users in cloud NoSQL data stores is favored by cloud\nproviders because it enables resource sharing at low operating cost.\nMulti-tenancy takes several forms depending on whether the back-end file system\nis a local file system (LFS) or a parallel file system (PFS), and on whether\ntenants are independent or share data across tenants. In this thesis I focus on\nand propose solutions to two cases: independent data-local file system, and\nshared data-parallel file system.\n  In the independent data-local file system case, resource contention occurs\nunder certain conditions in Cassandra and HBase, two state-of-the-art NoSQL\nstores, causing performance degradation for one tenant by another. We\ninvestigate the interference and propose two approaches. The first provides a\nscheduling scheme that can approximate resource consumption, adapt to workload\ndynamics and work in a distributed fashion. The second introduces a\nworkload-aware resource reservation approach to prevent interference. The\napproach relies on a performance model obtained offline and plans the\nreservation according to different workload resource demands. Results show the\napproaches together can prevent interference and adapt to dynamic workloads\nunder multi-tenancy.\n  In the shared data-parallel file system case, it has been shown that running\na distributed NoSQL store over PFS for shared data across tenants is not cost\neffective. Overheads are introduced due to the unawareness of the NoSQL store\nof PFS. This dissertation targets the key-value store (KVS), a specific form of\nNoSQL stores, and proposes a lightweight KVS over a parallel file system to\nimprove efficiency. The solution is built on an embedded KVS for high\nperformance but uses novel data structures to support concurrent writes.\nResults show the proposed system outperforms Cassandra and Voldemort in several\ndifferent workloads.\n", "versions": [{"version": "v1", "created": "Tue, 5 Jan 2016 05:15:12 GMT"}], "update_date": "2016-01-06", "authors_parsed": [["Zeng", "Jiaan", ""]]}, {"id": "1601.00741", "submitter": "Ashesh Jain", "authors": "Ashesh Jain, Shikhar Sharma, Thorsten Joachims, Ashutosh Saxena", "title": "Learning Preferences for Manipulation Tasks from Online Coactive\n  Feedback", "comments": "IJRR accepted (Learning preferences over trajectories from coactive\n  feedback)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of learning preferences over trajectories for mobile\nmanipulators such as personal robots and assembly line robots. The preferences\nwe learn are more intricate than simple geometric constraints on trajectories;\nthey are rather governed by the surrounding context of various objects and\nhuman interactions in the environment. We propose a coactive online learning\nframework for teaching preferences in contextually rich environments. The key\nnovelty of our approach lies in the type of feedback expected from the user:\nthe human user does not need to demonstrate optimal trajectories as training\ndata, but merely needs to iteratively provide trajectories that slightly\nimprove over the trajectory currently proposed by the system. We argue that\nthis coactive preference feedback can be more easily elicited than\ndemonstrations of optimal trajectories. Nevertheless, theoretical regret bounds\nof our algorithm match the asymptotic rates of optimal trajectory algorithms.\n  We implement our algorithm on two high degree-of-freedom robots, PR2 and\nBaxter, and present three intuitive mechanisms for providing such incremental\nfeedback. In our experimental evaluation we consider two context rich settings\n-- household chores and grocery store checkout -- and show that users are able\nto train the robot with just a few feedbacks (taking only a few\nminutes).\\footnote{Parts of this work has been published at NIPS and ISRR\nconferences~\\citep{Jain13,Jain13b}. This journal submission presents a\nconsistent full paper, and also includes the proof of regret bounds, more\ndetails of the robotic system, and a thorough related work.}\n", "versions": [{"version": "v1", "created": "Tue, 5 Jan 2016 05:47:09 GMT"}], "update_date": "2016-01-06", "authors_parsed": [["Jain", "Ashesh", ""], ["Sharma", "Shikhar", ""], ["Joachims", "Thorsten", ""], ["Saxena", "Ashutosh", ""]]}, {"id": "1601.00816", "submitter": "Pierre-Yves Oudeyer", "authors": "Pierre-Yves Oudeyer (Flowers)", "title": "Open challenges in understanding development and evolution of speech\n  forms: The roles of embodied self-organization, motivation and active\n  exploration", "comments": null, "journal-ref": "Journal of Phonetics, Elsevier, 2015, 53, pp.5", "doi": "10.1016/j.wocn.2015.09.001", "report-no": null, "categories": "cs.AI cs.CL cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article discusses open scientific challenges for understanding\ndevelopment and evolution of speech forms, as a commentary to Moulin-Frier et\nal. (Moulin-Frier et al., 2015). Based on the analysis of mathematical models\nof the origins of speech forms, with a focus on their assumptions , we study\nthe fundamental question of how speech can be formed out of non--speech, at\nboth developmental and evolutionary scales. In particular, we emphasize the\nimportance of embodied self-organization , as well as the role of mechanisms of\nmotivation and active curiosity-driven exploration in speech formation. Finally\n, we discuss an evolutionary-developmental perspective of the origins of\nspeech.\n", "versions": [{"version": "v1", "created": "Tue, 5 Jan 2016 12:50:14 GMT"}], "update_date": "2016-01-06", "authors_parsed": [["Oudeyer", "Pierre-Yves", "", "Flowers"]]}, {"id": "1601.00901", "submitter": "Janez Starc", "authors": "Janez Starc and Dunja Mladeni\\'c", "title": "Joint learning of ontology and semantic parser from text", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Semantic parsing methods are used for capturing and representing semantic\nmeaning of text. Meaning representation capturing all the concepts in the text\nmay not always be available or may not be sufficiently complete. Ontologies\nprovide a structured and reasoning-capable way to model the content of a\ncollection of texts. In this work, we present a novel approach to joint\nlearning of ontology and semantic parser from text. The method is based on\nsemi-automatic induction of a context-free grammar from semantically annotated\ntext. The grammar parses the text into semantic trees. Both, the grammar and\nthe semantic trees are used to learn the ontology on several levels -- classes,\ninstances, taxonomic and non-taxonomic relations. The approach was evaluated on\nthe first sentences of Wikipedia pages describing people.\n", "versions": [{"version": "v1", "created": "Tue, 5 Jan 2016 16:56:28 GMT"}], "update_date": "2016-01-06", "authors_parsed": [["Starc", "Janez", ""], ["Mladeni\u0107", "Dunja", ""]]}, {"id": "1601.01058", "submitter": "Gilad Katz", "authors": "Gilad Katz, Lior Rokach", "title": "Wikiometrics: A Wikipedia Based Ranking System", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL cs.AI cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new concept - Wikiometrics - the derivation of metrics and\nindicators from Wikipedia. Wikipedia provides an accurate representation of the\nreal world due to its size, structure, editing policy and popularity. We\ndemonstrate an innovative mining methodology, where different elements of\nWikipedia - content, structure, editorial actions and reader reviews - are used\nto rank items in a manner which is by no means inferior to rankings produced by\nexperts or other methods. We test our proposed method by applying it to two\nreal-world ranking problems: top world universities and academic journals. Our\nproposed ranking methods were compared to leading and widely accepted\nbenchmarks, and were found to be extremely correlative but with the advantage\nof the data being publically available.\n", "versions": [{"version": "v1", "created": "Wed, 6 Jan 2016 02:44:42 GMT"}, {"version": "v2", "created": "Fri, 8 Jan 2016 05:25:27 GMT"}], "update_date": "2016-01-11", "authors_parsed": [["Katz", "Gilad", ""], ["Rokach", "Lior", ""]]}, {"id": "1601.01228", "submitter": "Maumita Bhattacharya", "authors": "J. West and Maumita Bhattacharya", "title": "Some Experimental Issues in Financial Fraud Detection: An Investigation", "comments": "J. West and Maumita Bhattacharya. \"Some Experimental Issues in\n  Financial Fraud Detection: An Investigation\", In the Proceedings of The 5th\n  International Symposium on Cloud and Service Computing (SC2 2015), IEEE CS\n  Press", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Financial fraud detection is an important problem with a number of design\naspects to consider. Issues such as algorithm selection and performance\nanalysis will affect the perceived ability of proposed solutions, so for\nauditors and re-searchers to be able to sufficiently detect financial fraud it\nis necessary that these issues be thoroughly explored. In this paper we will\nrevisit the key performance metrics used for financial fraud detection with a\nfocus on credit card fraud, critiquing the prevailing ideas and offering our\nown understandings. There are many different performance metrics that have been\nemployed in prior financial fraud detection research. We will analyse several\nof the popular metrics and compare their effectiveness at measuring the ability\nof detection mechanisms. We further investigated the performance of a range of\ncomputational intelligence techniques when applied to this problem domain, and\nexplored the efficacy of several binary classification methods.\n", "versions": [{"version": "v1", "created": "Wed, 6 Jan 2016 16:18:43 GMT"}], "update_date": "2016-01-07", "authors_parsed": [["West", "J.", ""], ["Bhattacharya", "Maumita", ""]]}, {"id": "1601.01297", "submitter": "Lars Roemheld", "authors": "Imanol Arrieta Ibarra, Bernardo Ramos, Lars Roemheld", "title": "Angrier Birds: Bayesian reinforcement learning", "comments": "Stanford University CS221 Final Project", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We train a reinforcement learner to play a simplified version of the game\nAngry Birds. The learner is provided with a game state in a manner similar to\nthe output that could be produced by computer vision algorithms. We improve on\nthe efficiency of regular {\\epsilon}-greedy Q-Learning with linear function\napproximation through more systematic exploration in Randomized Least Squares\nValue Iteration (RLSVI), an algorithm that samples its policy from a posterior\ndistribution on optimal policies. With larger state-action spaces, efficient\nexploration becomes increasingly important, as evidenced by the faster learning\nin RLSVI.\n", "versions": [{"version": "v1", "created": "Wed, 6 Jan 2016 20:22:22 GMT"}, {"version": "v2", "created": "Thu, 7 Jan 2016 01:28:34 GMT"}], "update_date": "2016-01-08", "authors_parsed": [["Ibarra", "Imanol Arrieta", ""], ["Ramos", "Bernardo", ""], ["Roemheld", "Lars", ""]]}, {"id": "1601.01492", "submitter": "Robert Bredereck", "authors": "Robert Bredereck, Piotr Faliszewski, Rolf Niedermeier, Nimrod Talmon", "title": "Complexity of Shift Bribery in Committee Elections", "comments": "30 Pages. An extended abstract of this paper appears in the\n  Proceedings of the 30th AAAI Conference on Artificial Intelligence (AAAI 16)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given an election, a preferred candidate p, and a budget, the SHIFT BRIBERY\nproblem asks whether p can win the election after shifting p higher in some\nvoters' preference orders. Of course, shifting comes at a price (depending on\nthe voter and on the extent of the shift) and one must not exceed the given\nbudget. We study the (parameterized) computational complexity of S HIFT BRIBERY\nfor multiwinner voting rules where winning the election means to be part of\nsome winning committee. We focus on the well-established SNTV, Bloc, k-Borda,\nand Chamberlin-Courant rules, as well as on approximate variants of the\nChamberlin-Courant rule, since the original rule is NP-hard to compute. We show\nthat SHIFT BRIBERY tends to be harder in the multiwinner setting than in the\nsingle-winner one by showing settings where SHIFT BRIBERY is easy in the\nsingle-winner cases, but is hard (and hard to approximate) in the multiwinner\nones. Moreover, we show that the non-monotonicity of those rules which are\nbased on approximation algorithms for the Chamberlin-Courant rule sometimes\naffects the complexity of SHIFT BRIBERY.\n", "versions": [{"version": "v1", "created": "Thu, 7 Jan 2016 11:35:43 GMT"}, {"version": "v2", "created": "Mon, 24 Sep 2018 19:00:42 GMT"}], "update_date": "2018-09-26", "authors_parsed": [["Bredereck", "Robert", ""], ["Faliszewski", "Piotr", ""], ["Niedermeier", "Rolf", ""], ["Talmon", "Nimrod", ""]]}, {"id": "1601.01614", "submitter": "Cl\\'ement Duhart Mr", "authors": "Duhart Cl\\'ement and Bertelle Cyrille", "title": "Toward Organic Computing Approach for Cybernetic Responsive Environment", "comments": null, "journal-ref": "International Journal of Ambient Systems and Applications (IJASA),\n  december 2015, Volume 3, Number 4", "doi": "10.5121/ijasa.2015.3401.", "report-no": null, "categories": "cs.AI cs.MA cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The developpment of the Internet of Things (IoT) concept revives Responsive\nEnvironments (RE) technologies. Nowadays, the idea of a permanent connection\nbetween physical and digital world is technologically possible. The capillar\nInternet relates to the Internet extension into daily appliances such as they\nbecome actors of Internet like any hu-man. The parallel development of\nMachine-to-Machine communications and Arti cial Intelligence (AI) technics\nstart a new area of cybernetic. This paper presents an approach for Cybernetic\nOrganism (Cyborg) for RE based on Organic Computing (OC). In such approach,\neach appli-ance is a part of an autonomic system in order to control a physical\nenvironment. The underlying idea is that such systems must have self-x\nproperties in order to adapt their behavior to external disturbances with a\nhigh-degree of autonomy.\n", "versions": [{"version": "v1", "created": "Thu, 7 Jan 2016 17:29:00 GMT"}], "update_date": "2016-01-08", "authors_parsed": [["Cl\u00e9ment", "Duhart", ""], ["Cyrille", "Bertelle", ""]]}, {"id": "1601.01635", "submitter": "Dmytro Terletskyi", "authors": "D. A. Terletskyi, A. I. Provotar", "title": "Fuzzy Object-Oriented Dynamic Networks. I", "comments": null, "journal-ref": "Cybernetics and Systems Analysis, 2015, Volume 51, Issue 1, pp\n  34-40", "doi": "10.1007/s10559-015-9694-0", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The concepts of fuzzy objects and their classes are described that make it\npossible to structurally represent knowledge about fuzzy and partially-defined\nobjects and their classes. Operations over such objects and classes are also\nproposed that make it possible to obtain sets and new classes of fuzzy objects\nand also to model variations in object structures under the influence of\nexternal factors.\n", "versions": [{"version": "v1", "created": "Thu, 7 Jan 2016 18:39:55 GMT"}, {"version": "v2", "created": "Tue, 16 Feb 2016 19:22:47 GMT"}], "update_date": "2016-02-17", "authors_parsed": [["Terletskyi", "D. A.", ""], ["Provotar", "A. I.", ""]]}, {"id": "1601.01653", "submitter": "Avi Ma'ayan", "authors": "Avi Ma'ayan and Neil R. Clark", "title": "Large Collection of Diverse Gene Set Search Queries Recapitulate Known\n  Protein-Protein Interactions and Gene-Gene Functional Associations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.MN cs.AI cs.SI q-bio.GN stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Popular online enrichment analysis tools from the field of molecular systems\nbiology provide users with the ability to submit their experimental results as\ngene sets for individual analysis. Such queries are kept private, and have\nnever before been considered as a resource for integrative analysis. By\nharnessing gene set query submissions from thousands of users, we aim to\ndiscover biological knowledge beyond the scope of an individual study. In this\nwork, we investigated a large collection of gene sets submitted to the tool\nEnrichr by thousands of users. Based on co-occurrence, we constructed a global\ngene-gene association network. We interpret this inferred network as providing\na summary of the structure present in this crowdsourced gene set library, and\nshow that this network recapitulates known protein-protein interactions and\nfunctional associations between genes. This finding implies that this network\nalso offers predictive value. Furthermore, we visualize this gene-gene\nassociation network using a new edge-pruning algorithm that retains both the\nlocal and global structures of large-scale networks. Our ability to make\npredictions for currently unknown gene associations, that may not be captured\nby individual researchers and data sources, is a demonstration of the potential\nof harnessing collective knowledge from users of popular tools in the field of\nmolecular systems biology.\n", "versions": [{"version": "v1", "created": "Thu, 7 Jan 2016 20:06:18 GMT"}], "update_date": "2016-01-08", "authors_parsed": [["Ma'ayan", "Avi", ""], ["Clark", "Neil R.", ""]]}, {"id": "1601.01675", "submitter": "Denis Sidorov", "authors": "Alexei Zhukov, Victor Kurbatsky, Nikita Tomin, Denis Sidorov, Daniil\n  Panasetsky and Aoife Foley", "title": "Ensemble Methods of Classification for Power Systems Security Assessment", "comments": "6 pages, 4 figures, 4 tables. Submitted to PSSC", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the most promising approaches for complex technical systems analysis\nemploys ensemble methods of classification. Ensemble methods enable to build a\nreliable decision rules for feature space classification in the presence of\nmany possible states of the system. In this paper, novel techniques based on\ndecision trees are used for evaluation of the reliability of the regime of\nelectric power systems. We proposed hybrid approach based on random forests\nmodels and boosting models. Such techniques can be applied to predict the\ninteraction of increasing renewable power, storage devices and swiching of\nsmart loads from intelligent domestic appliances, heaters and air-conditioning\nunits and electric vehicles with grid for enhanced decision making. The\nensemble classification methods were tested on the modified 118-bus IEEE power\nsystem showing that proposed technique can be employed to examine whether the\npower system is secured under steady-state operating conditions.\n", "versions": [{"version": "v1", "created": "Thu, 7 Jan 2016 13:31:41 GMT"}], "update_date": "2016-01-11", "authors_parsed": [["Zhukov", "Alexei", ""], ["Kurbatsky", "Victor", ""], ["Tomin", "Nikita", ""], ["Sidorov", "Denis", ""], ["Panasetsky", "Daniil", ""], ["Foley", "Aoife", ""]]}, {"id": "1601.01700", "submitter": "Robert Murphy", "authors": "Robert A. Murphy", "title": "A Predictive Model using the Markov Property", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a data set of numerical values which are sampled from some unknown\nprobability distribution, we will show how to check if the data set exhibits\nthe Markov property and we will show how to use the Markov property to predict\nfuture values from the same distribution, with probability 1.\n", "versions": [{"version": "v1", "created": "Fri, 8 Jan 2016 16:19:21 GMT"}], "update_date": "2016-01-11", "authors_parsed": [["Murphy", "Robert A.", ""]]}, {"id": "1601.01917", "submitter": "Sylvain Castagnos", "authors": "Sylvain Castagnos (KIWI), Amaury L 'Huillier (KIWI), Anne Boyer (KIWI)", "title": "Toward a Robust Diversity-Based Model to Detect Changes of Context", "comments": "27th IEEE International Conference on Tools with Artificial\n  Intelligence (ICTAI 2015), Nov 2015, Vietri sul Mare, Italy", "journal-ref": null, "doi": "10.1109/ICTAI.2015.84", "report-no": null, "categories": "cs.IR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Being able to automatically and quickly understand the user context during a\nsession is a main issue for recommender systems. As a first step toward\nachieving that goal, we propose a model that observes in real time the\ndiversity brought by each item relatively to a short sequence of consultations,\ncorresponding to the recent user history. Our model has a complexity in\nconstant time, and is generic since it can apply to any type of items within an\nonline service (e.g. profiles, products, music tracks) and any application\ndomain (e-commerce, social network, music streaming), as long as we have\npartial item descriptions. The observation of the diversity level over time\nallows us to detect implicit changes. In the long term, we plan to characterize\nthe context, i.e. to find common features among a contiguous sub-sequence of\nitems between two changes of context determined by our model. This will allow\nus to make context-aware and privacy-preserving recommendations, to explain\nthem to users. As this is an ongoing research, the first step consists here in\nstudying the robustness of our model while detecting changes of context. In\norder to do so, we use a music corpus of 100 users and more than 210,000\nconsultations (number of songs played in the global history). We validate the\nrelevancy of our detections by finding connections between changes of context\nand events, such as ends of session. Of course, these events are a subset of\nthe possible changes of context, since there might be several contexts within a\nsession. We altered the quality of our corpus in several manners, so as to test\nthe performances of our model when confronted with sparsity and different types\nof items. The results show that our model is robust and constitutes a promising\napproach.\n", "versions": [{"version": "v1", "created": "Fri, 8 Jan 2016 15:50:03 GMT"}], "update_date": "2016-01-11", "authors_parsed": [["Castagnos", "Sylvain", "", "KIWI"], ["'Huillier", "Amaury L", "", "KIWI"], ["Boyer", "Anne", "", "KIWI"]]}, {"id": "1601.01920", "submitter": "Adeyinka K. Akanbi MR", "authors": "Adeyinka K. Akanbi and Muthoni Masinde", "title": "Towards Semantic Integration of Heterogeneous Sensor Data with\n  Indigenous Knowledge for Drought Forecasting", "comments": "5 pages, 3 figures, In Proceedings of the Doctoral Symposium of the\n  16th International Middleware Conference (Middleware Doct Symposium 2015),\n  Ivan Beschastnikh and Wouter Joosen (Eds.). ACM, New York, NY, USA", "journal-ref": null, "doi": "10.1145/2843966.2843968", "report-no": null, "categories": "cs.AI cs.NI cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the Internet of Things (IoT) domain, various heterogeneous ubiquitous\ndevices would be able to connect and communicate with each other seamlessly,\nirrespective of the domain. Semantic representation of data through detailed\nstandardized annotation has shown to improve the integration of the\ninterconnected heterogeneous devices. However, the semantic representation of\nthese heterogeneous data sources for environmental monitoring systems is not\nyet well supported. To achieve the maximum benefits of IoT for drought\nforecasting, a dedicated semantic middleware solution is required. This\nresearch proposes a middleware that semantically represents and integrates\nheterogeneous data sources with indigenous knowledge based on a unified\nontology for an accurate IoT-based drought early warning system (DEWS).\n", "versions": [{"version": "v1", "created": "Fri, 8 Jan 2016 15:57:00 GMT"}], "update_date": "2016-01-11", "authors_parsed": [["Akanbi", "Adeyinka K.", ""], ["Masinde", "Muthoni", ""]]}, {"id": "1601.02197", "submitter": "Wei-Long Zheng", "authors": "Wei-Long Zheng, Jia-Yi Zhu, Bao-Liang Lu", "title": "Identifying Stable Patterns over Time for Emotion Recognition from EEG", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we investigate stable patterns of electroencephalogram (EEG)\nover time for emotion recognition using a machine learning approach. Up to now,\nvarious findings of activated patterns associated with different emotions have\nbeen reported. However, their stability over time has not been fully\ninvestigated yet. In this paper, we focus on identifying EEG stability in\nemotion recognition. To validate the efficiency of the machine learning\nalgorithms used in this study, we systematically evaluate the performance of\nvarious popular feature extraction, feature selection, feature smoothing and\npattern classification methods with the DEAP dataset and a newly developed\ndataset for this study. The experimental results indicate that stable patterns\nexhibit consistency across sessions; the lateral temporal areas activate more\nfor positive emotion than negative one in beta and gamma bands; the neural\npatterns of neutral emotion have higher alpha responses at parietal and\noccipital sites; and for negative emotion, the neural patterns have significant\nhigher delta responses at parietal and occipital sites and higher gamma\nresponses at prefrontal sites. The performance of our emotion recognition\nsystem shows that the neural patterns are relatively stable within and between\nsessions.\n", "versions": [{"version": "v1", "created": "Sun, 10 Jan 2016 10:43:24 GMT"}], "update_date": "2016-01-12", "authors_parsed": [["Zheng", "Wei-Long", ""], ["Zhu", "Jia-Yi", ""], ["Lu", "Bao-Liang", ""]]}, {"id": "1601.02213", "submitter": "Michael Berthold", "authors": "Michael R. Berthold and Frank H\\\"oppner", "title": "On Clustering Time Series Using Euclidean Distance and Pearson\n  Correlation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For time series comparisons, it has often been observed that z-score\nnormalized Euclidean distances far outperform the unnormalized variant. In this\npaper we show that a z-score normalized, squared Euclidean Distance is, in\nfact, equal to a distance based on Pearson Correlation. This has profound\nimpact on many distance-based classification or clustering methods. In addition\nto this theoretically sound result we also show that the often used k-Means\nalgorithm formally needs a mod ification to keep the interpretation as Pearson\ncorrelation strictly valid. Experimental results demonstrate that in many cases\nthe standard k-Means algorithm generally produces the same results.\n", "versions": [{"version": "v1", "created": "Sun, 10 Jan 2016 13:17:46 GMT"}], "update_date": "2016-01-12", "authors_parsed": [["Berthold", "Michael R.", ""], ["H\u00f6ppner", "Frank", ""]]}, {"id": "1601.02327", "submitter": "Guangneng Hu", "authors": "Guang-Neng Hu, Xin-Yu Dai, Yunya Song, Shu-Jian Huang, Jia-Jun Chen", "title": "A Synthetic Approach for Recommendation: Combining Ratings, Social\n  Relations, and Reviews", "comments": "7 pages, 8 figures", "journal-ref": "24th IJCAI,2015,1756-1762", "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Recommender systems (RSs) provide an effective way of alleviating the\ninformation overload problem by selecting personalized choices. Online social\nnetworks and user-generated content provide diverse sources for recommendation\nbeyond ratings, which present opportunities as well as challenges for\ntraditional RSs. Although social matrix factorization (Social MF) can integrate\nratings with social relations and topic matrix factorization can integrate\nratings with item reviews, both of them ignore some useful information. In this\npaper, we investigate the effective data fusion by combining the two\napproaches, in two steps. First, we extend Social MF to exploit the graph\nstructure of neighbors. Second, we propose a novel framework MR3 to jointly\nmodel these three types of information effectively for rating prediction by\naligning latent factors and hidden topics. We achieve more accurate rating\nprediction on two real-life datasets. Furthermore, we measure the contribution\nof each data source to the proposed framework.\n", "versions": [{"version": "v1", "created": "Mon, 11 Jan 2016 05:41:39 GMT"}], "update_date": "2020-10-19", "authors_parsed": [["Hu", "Guang-Neng", ""], ["Dai", "Xin-Yu", ""], ["Song", "Yunya", ""], ["Huang", "Shu-Jian", ""], ["Chen", "Jia-Jun", ""]]}, {"id": "1601.02433", "submitter": "Lavdim Halilaj", "authors": "Lavdim Halilaj, Irl\\'an Grangel-Gonz\\'alez, G\\\"okhan Coskun and\n  S\\\"oren Auer", "title": "Git4Voc: Git-based Versioning for Collaborative Vocabulary Development", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.DB cs.HC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Collaborative vocabulary development in the context of data integration is\nthe process of finding consensus between the experts of the different systems\nand domains. The complexity of this process is increased with the number of\ninvolved people, the variety of the systems to be integrated and the dynamics\nof their domain. In this paper we advocate that the realization of a powerful\nversion control system is the heart of the problem. Driven by this idea and the\nsuccess of Git in the context of software development, we investigate the\napplicability of Git for collaborative vocabulary development. Even though\nvocabulary development and software development have much more similarities\nthan differences there are still important differences. These need to be\nconsidered within the development of a successful versioning and collaboration\nsystem for vocabulary development. Therefore, this paper starts by presenting\nthe challenges we were faced with during the creation of vocabularies\ncollaboratively and discusses its distinction to software development. Based on\nthese insights we propose Git4Voc which comprises guidelines how Git can be\nadopted to vocabulary development. Finally, we demonstrate how Git hooks can be\nimplemented to go beyond the plain functionality of Git by realizing\nvocabulary-specific features like syntactic validation and semantic diffs.\n", "versions": [{"version": "v1", "created": "Mon, 11 Jan 2016 13:11:51 GMT"}], "update_date": "2016-01-12", "authors_parsed": [["Halilaj", "Lavdim", ""], ["Grangel-Gonz\u00e1lez", "Irl\u00e1n", ""], ["Coskun", "G\u00f6khan", ""], ["Auer", "S\u00f6ren", ""]]}, {"id": "1601.02543", "submitter": "Sunil Kumar Kopparapu Dr", "authors": "Vinod Kumar Pandey, Sunil Kumar Kopparapu", "title": "Evaluating the Performance of a Speech Recognition based System", "comments": "7 pages, 2 figure, ACC 2011", "journal-ref": "ACC (3) 2011: 230-238", "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Speech based solutions have taken center stage with growth in the services\nindustry where there is a need to cater to a very large number of people from\nall strata of the society. While natural language speech interfaces are the\ntalk in the research community, yet in practice, menu based speech solutions\nthrive. Typically in a menu based speech solution the user is required to\nrespond by speaking from a closed set of words when prompted by the system. A\nsequence of human speech response to the IVR prompts results in the completion\nof a transaction. A transaction is deemed successful if the speech solution can\ncorrectly recognize all the spoken utterances of the user whenever prompted by\nthe system. The usual mechanism to evaluate the performance of a speech\nsolution is to do an extensive test of the system by putting it to actual\npeople use and then evaluating the performance by analyzing the logs for\nsuccessful transactions. This kind of evaluation could lead to dissatisfied\ntest users especially if the performance of the system were to result in a poor\ntransaction completion rate. To negate this the Wizard of Oz approach is\nadopted during evaluation of a speech system. Overall this kind of evaluations\nis an expensive proposition both in terms of time and cost. In this paper, we\npropose a method to evaluate the performance of a speech solution without\nactually putting it to people use. We first describe the methodology and then\nshow experimentally that this can be used to identify the performance\nbottlenecks of the speech solution even before the system is actually used thus\nsaving evaluation time and expenses.\n", "versions": [{"version": "v1", "created": "Mon, 11 Jan 2016 18:01:56 GMT"}], "update_date": "2016-01-12", "authors_parsed": [["Pandey", "Vinod Kumar", ""], ["Kopparapu", "Sunil Kumar", ""]]}, {"id": "1601.02650", "submitter": "Dominik Tomaszuk Dr", "authors": "Dominik Tomaszuk", "title": "Inference rules for RDF(S) and OWL in N3Logic", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents inference rules for Resource Description Framework (RDF),\nRDF Schema (RDFS) and Web Ontology Language (OWL). Our formalization is based\non Notation 3 Logic, which extended RDF by logical symbols and created Semantic\nWeb logic for deductive RDF graph stores. We also propose OWL-P that is a\nlightweight formalism of OWL and supports soft inferences by omitting complex\nlanguage constructs.\n", "versions": [{"version": "v1", "created": "Mon, 11 Jan 2016 21:18:59 GMT"}], "update_date": "2016-01-13", "authors_parsed": [["Tomaszuk", "Dominik", ""]]}, {"id": "1601.02705", "submitter": "Jaeyong Sung", "authors": "Jaeyong Sung, Seok Hyun Jin, Ian Lenz, Ashutosh Saxena", "title": "Robobarista: Learning to Manipulate Novel Objects via Deep Multimodal\n  Embedding", "comments": "Journal Version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is a large variety of objects and appliances in human environments,\nsuch as stoves, coffee dispensers, juice extractors, and so on. It is\nchallenging for a roboticist to program a robot for each of these object types\nand for each of their instantiations. In this work, we present a novel approach\nto manipulation planning based on the idea that many household objects share\nsimilarly-operated object parts. We formulate the manipulation planning as a\nstructured prediction problem and learn to transfer manipulation strategy\nacross different objects by embedding point-cloud, natural language, and\nmanipulation trajectory data into a shared embedding space using a deep neural\nnetwork. In order to learn semantically meaningful spaces throughout our\nnetwork, we introduce a method for pre-training its lower layers for multimodal\nfeature embedding and a method for fine-tuning this embedding space using a\nloss-based margin. In order to collect a large number of manipulation\ndemonstrations for different objects, we develop a new crowd-sourcing platform\ncalled Robobarista. We test our model on our dataset consisting of 116 objects\nand appliances with 249 parts along with 250 language instructions, for which\nthere are 1225 crowd-sourced manipulation demonstrations. We further show that\nour robot with our model can even prepare a cup of a latte with appliances it\nhas never seen before.\n", "versions": [{"version": "v1", "created": "Tue, 12 Jan 2016 00:56:30 GMT"}], "update_date": "2016-01-13", "authors_parsed": [["Sung", "Jaeyong", ""], ["Jin", "Seok Hyun", ""], ["Lenz", "Ian", ""], ["Saxena", "Ashutosh", ""]]}, {"id": "1601.02745", "submitter": "Xiaodong He", "authors": "Paul Smolensky, Moontae Lee, Xiaodong He, Wen-tau Yih, Jianfeng Gao,\n  Li Deng", "title": "Basic Reasoning with Tensor Product Representations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we present the initial development of a general theory for\nmapping inference in predicate logic to computation over Tensor Product\nRepresentations (TPRs; Smolensky (1990), Smolensky & Legendre (2006)). After an\ninitial brief synopsis of TPRs (Section 0), we begin with particular examples\nof inference with TPRs in the 'bAbI' question-answering task of Weston et al.\n(2015) (Section 1). We then present a simplification of the general analysis\nthat suffices for the bAbI task (Section 2). Finally, we lay out the general\ntreatment of inference over TPRs (Section 3). We also show the simplification\nin Section 2 derives the inference methods described in Lee et al. (2016); this\nshows how the simple methods of Lee et al. (2016) can be formally extended to\nmore general reasoning tasks.\n", "versions": [{"version": "v1", "created": "Tue, 12 Jan 2016 06:44:54 GMT"}], "update_date": "2016-01-13", "authors_parsed": [["Smolensky", "Paul", ""], ["Lee", "Moontae", ""], ["He", "Xiaodong", ""], ["Yih", "Wen-tau", ""], ["Gao", "Jianfeng", ""], ["Deng", "Li", ""]]}, {"id": "1601.02865", "submitter": "Peter Nightingale", "authors": "Peter Nightingale and Andrea Rendl", "title": "Essence' Description", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A description of the Essence' language as used by the tool Savile Row.\n", "versions": [{"version": "v1", "created": "Tue, 12 Jan 2016 14:05:35 GMT"}], "update_date": "2016-01-13", "authors_parsed": [["Nightingale", "Peter", ""], ["Rendl", "Andrea", ""]]}, {"id": "1601.02939", "submitter": "Andrew Gainer-Dewar", "authors": "Andrew Gainer-Dewar and Paola Vera-Licona", "title": "The minimal hitting set generation problem: algorithms and computation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.AI cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Finding inclusion-minimal \"hitting sets\" for a given collection of sets is a\nfundamental combinatorial problem with applications in domains as diverse as\nBoolean algebra, computational biology, and data mining. Much of the\nalgorithmic literature focuses on the problem of *recognizing* the collection\nof minimal hitting sets; however, in many of the applications, it is more\nimportant to *generate* these hitting sets. We survey twenty algorithms from\nacross a variety of domains, considering their history, classification, useful\nfeatures, and computational performance on a variety of synthetic and\nreal-world inputs. We also provide a suite of implementations of these\nalgorithms with a ready-to-use, platform-agnostic interface based on Docker\ncontainers and the AlgoRun framework, so that interested computational\nscientists can easily perform similar tests with inputs from their own research\nareas on their own computers or through a convenient Web interface.\n", "versions": [{"version": "v1", "created": "Tue, 5 Jan 2016 19:24:25 GMT"}], "update_date": "2016-01-13", "authors_parsed": [["Gainer-Dewar", "Andrew", ""], ["Vera-Licona", "Paola", ""]]}, {"id": "1601.02975", "submitter": "Derek Greene", "authors": "Ewa M{\\l}ynarska and Derek Greene and P\\'adraig Cunningham", "title": "Indicators of Good Student Performance in Moodle Activity Data", "comments": "Short version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we conduct an analysis of Moodle activity data focused on\nidentifying early predictors of good student performance. The analysis shows\nthat three relevant hypotheses are largely supported by the data. These\nhypotheses are: early submission is a good sign, a high level of activity is\npredictive of good results and evening activity is even better than daytime\nactivity. We highlight some pathological examples where high levels of activity\ncorrelates with bad results.\n", "versions": [{"version": "v1", "created": "Tue, 12 Jan 2016 17:42:24 GMT"}], "update_date": "2016-01-13", "authors_parsed": [["M\u0142ynarska", "Ewa", ""], ["Greene", "Derek", ""], ["Cunningham", "P\u00e1draig", ""]]}, {"id": "1601.03065", "submitter": "Igor Subbotin", "authors": "Igor Ya. Subbotin, Michael Gr. Voskoglou", "title": "An Application of the Generalized Rectangular Fuzzy Model to Critical\n  Thinking Assessment", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The authors apply the Generalized Rectangular Model to assessing critical\nthinking skills and its relations with their language competency.\n", "versions": [{"version": "v1", "created": "Fri, 8 Jan 2016 18:18:36 GMT"}], "update_date": "2016-01-14", "authors_parsed": [["Subbotin", "Igor Ya.", ""], ["Voskoglou", "Michael Gr.", ""]]}, {"id": "1601.03095", "submitter": "Yaron Singer", "authors": "Avinatan Hassidim and Yaron Singer", "title": "Submodular Optimization under Noise", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.AI cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of maximizing a monotone submodular function under\nnoise. There has been a great deal of work on optimization of submodular\nfunctions under various constraints, resulting in algorithms that provide\ndesirable approximation guarantees. In many applications, however, we do not\nhave access to the submodular function we aim to optimize, but rather to some\nerroneous or noisy version of it. This raises the question of whether provable\nguarantees are obtainable in presence of error and noise. We provide initial\nanswers, by focusing on the question of maximizing a monotone submodular\nfunction under a cardinality constraint when given access to a noisy oracle of\nthe function. We show that:\n  - For a cardinality constraint $k \\geq 2$, there is an approximation\nalgorithm whose approximation ratio is arbitrarily close to $1-1/e$;\n  - For $k=1$ there is an algorithm whose approximation ratio is arbitrarily\nclose to $1/2$. No randomized algorithm can obtain an approximation ratio\nbetter than $1/2+o(1)$;\n  -If the noise is adversarial, no non-trivial approximation guarantee can be\nobtained.\n", "versions": [{"version": "v1", "created": "Tue, 12 Jan 2016 23:05:24 GMT"}, {"version": "v2", "created": "Tue, 12 Apr 2016 22:24:46 GMT"}, {"version": "v3", "created": "Fri, 4 Nov 2016 21:33:37 GMT"}], "update_date": "2016-11-08", "authors_parsed": [["Hassidim", "Avinatan", ""], ["Singer", "Yaron", ""]]}, {"id": "1601.03411", "submitter": "Andrew MacFie", "authors": "Andrew MacFie", "title": "Analysis of Algorithms and Partial Algorithms", "comments": null, "journal-ref": "Artificial General Intelligence 2016, New York, USA, July 16-19,\n  2016, Proceedings, 284-293", "doi": "10.1007/978-3-319-41649-6_29", "report-no": null, "categories": "cs.AI cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an alternative methodology for the analysis of algorithms, based\non the concept of expected discounted reward. This methodology naturally\nhandles algorithms that do not always terminate, so it can (theoretically) be\nused with partial algorithms for undecidable problems, such as those found in\nartificial general intelligence (AGI) and automated theorem proving. We mention\nan approach to self-improving AGI enabled by this methodology.\n  Aug 2017 addendum: This article was originally written with multiple\naudiences in mind. It is really best put in the following terms. Goertzel,\nHutter, Legg, and others have developed a definition of an intelligence score\nfor a general abstract agent: expected lifetime reward in a random environment.\nAIXI is generally the optimal agent according to this score, but there may be\nreasons to analyze other agents and compare score values. If we want to use\nthis definition of intelligence in practice, perhaps we can start by analyzing\nsome simple agents. Common algorithms can be thought of as simple agents\n(environment is input, reward is based on running time) so we take the goal of\napplying the agent intelligence score to algorithms. That is, we want to find,\nwhat are the IQ scores of algorithms? We can do some very simple analysis, but\nthe real answer is that even for simple algorithms, the intelligence score is\ntoo difficult to work with in practice.\n", "versions": [{"version": "v1", "created": "Wed, 13 Jan 2016 21:17:42 GMT"}, {"version": "v2", "created": "Sun, 28 Feb 2016 18:30:51 GMT"}, {"version": "v3", "created": "Tue, 1 Mar 2016 19:21:41 GMT"}, {"version": "v4", "created": "Sun, 8 May 2016 00:52:51 GMT"}, {"version": "v5", "created": "Mon, 7 Aug 2017 01:30:46 GMT"}], "update_date": "2017-08-08", "authors_parsed": [["MacFie", "Andrew", ""]]}, {"id": "1601.03778", "submitter": "Baichuan Zhang", "authors": "Baichuan Zhang, Sutanay Choudhury, Mohammad Al Hasan, Xia Ning,\n  Khushbu Agarwal, Sumit Purohit, Paola Pesntez Cabrera", "title": "Trust from the past: Bayesian Personalized Ranking based Link Prediction\n  in Knowledge Graphs", "comments": "SDM Workshop on Mining Networks and Graphs (MNG 2016), Miami, FL", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Link prediction, or predicting the likelihood of a link in a knowledge graph\nbased on its existing state is a key research task. It differs from a\ntraditional link prediction task in that the links in a knowledge graph are\ncategorized into different predicates and the link prediction performance of\ndifferent predicates in a knowledge graph generally varies widely. In this\nwork, we propose a latent feature embedding based link prediction model which\nconsiders the prediction task for each predicate disjointly. To learn the model\nparameters it utilizes a Bayesian personalized ranking based optimization\ntechnique. Experimental results on large-scale knowledge bases such as YAGO2\nshow that our link prediction approach achieves substantially higher\nperformance than several state-of-art approaches. We also show that for a given\npredicate the topological properties of the knowledge graph induced by the\ngiven predicate edges are key indicators of the link prediction performance of\nthat predicate in the knowledge graph.\n", "versions": [{"version": "v1", "created": "Thu, 14 Jan 2016 23:13:00 GMT"}, {"version": "v2", "created": "Mon, 15 Feb 2016 05:12:32 GMT"}], "update_date": "2016-02-16", "authors_parsed": [["Zhang", "Baichuan", ""], ["Choudhury", "Sutanay", ""], ["Hasan", "Mohammad Al", ""], ["Ning", "Xia", ""], ["Agarwal", "Khushbu", ""], ["Purohit", "Sumit", ""], ["Cabrera", "Paola Pesntez", ""]]}, {"id": "1601.03785", "submitter": "Regivan Santiago", "authors": "A. Diego S. Farias, Valdigleis S. Costa, Luiz Ranyer A. Lopes,\n  Benjam\\'in Bedregal and Regivan Santiago", "title": "A Method for Image Reduction Based on a Generalization of Ordered\n  Weighted Averaging Functions", "comments": "32 pages, 19 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we propose a special type of aggregation function which\ngeneralizes the notion of Ordered Weighted Averaging Function - OWA. The\nresulting functions are called Dynamic Ordered Weighted Averaging Functions ---\nDYOWAs. This generalization will be developed in such way that the weight\nvectors are variables depending on the input vector. Particularly, this\noperators generalize the aggregation functions: Minimum, Maximum, Arithmetic\nMean, Median, etc, which are extensively used in image processing. In this\nfield of research two problems are considered: The determination of methods to\nreduce images and the construction of techniques which provide noise reduction.\nThe operators described here are able to be used in both cases. In terms of\nimage reduction we apply the methodology provided by Patermain et al. We use\nthe noise reduction operators obtained here to treat the images obtained in the\nfirst part of the paper, thus obtaining images with better quality.\n", "versions": [{"version": "v1", "created": "Fri, 15 Jan 2016 00:13:33 GMT"}], "update_date": "2016-01-18", "authors_parsed": [["Farias", "A. Diego S.", ""], ["Costa", "Valdigleis S.", ""], ["Lopes", "Luiz Ranyer A.", ""], ["Bedregal", "Benjam\u00edn", ""], ["Santiago", "Regivan", ""]]}, {"id": "1601.04037", "submitter": "Anirudha Majumdar", "authors": "Anirudha Majumdar and Russ Tedrake", "title": "Funnel Libraries for Real-Time Robust Feedback Motion Planning", "comments": "International Journal of Robotics Research (To Appear)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.SY math.DS math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of generating motion plans for a robot that are\nguaranteed to succeed despite uncertainty in the environment, parametric model\nuncertainty, and disturbances. Furthermore, we consider scenarios where these\nplans must be generated in real-time, because constraints such as obstacles in\nthe environment may not be known until they are perceived (with a noisy sensor)\nat runtime. Our approach is to pre-compute a library of \"funnels\" along\ndifferent maneuvers of the system that the state is guaranteed to remain within\n(despite bounded disturbances) when the feedback controller corresponding to\nthe maneuver is executed. We leverage powerful computational machinery from\nconvex optimization (sums-of-squares programming in particular) to compute\nthese funnels. The resulting funnel library is then used to sequentially\ncompose motion plans at runtime while ensuring the safety of the robot. A major\nadvantage of the work presented here is that by explicitly taking into account\nthe effect of uncertainty, the robot can evaluate motion plans based on how\nvulnerable they are to disturbances.\n  We demonstrate and validate our method using extensive hardware experiments\non a small fixed-wing airplane avoiding obstacles at high speed (~12 mph),\nalong with thorough simulation experiments of ground vehicle and quadrotor\nmodels navigating through cluttered environments. To our knowledge, these\ndemonstrations constitute one of the first examples of provably safe and robust\ncontrol for robotic systems with complex nonlinear dynamics that need to plan\nin real-time in environments with complex geometric constraints.\n", "versions": [{"version": "v1", "created": "Fri, 15 Jan 2016 19:22:09 GMT"}, {"version": "v2", "created": "Thu, 21 Jul 2016 09:52:41 GMT"}, {"version": "v3", "created": "Sat, 29 Apr 2017 20:33:11 GMT"}], "update_date": "2017-05-02", "authors_parsed": [["Majumdar", "Anirudha", ""], ["Tedrake", "Russ", ""]]}, {"id": "1601.04038", "submitter": "Heinz Schmitz", "authors": "Heinz Schmitz and Ioanna Lykourentzou", "title": "It's about time: Online Macrotask Sequencing in Expert Crowdsourcing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce the problem of Task Assignment and Sequencing (TAS), which adds\nthe timeline perspective to expert crowdsourcing optimization. Expert\ncrowdsourcing involves macrotasks, like document writing, product design, or\nweb development, which take more time than typical binary microtasks, require\nexpert skills, assume varying degrees of knowledge over a topic, and require\ncrowd workers to build on each other's contributions. Current works usually\nassume offline optimization models, which consider worker and task arrivals\nknown and do not take into account the element of time. Realistically however,\ntime is critical: tasks have deadlines, expert workers are available only at\nspecific time slots, and worker/task arrivals are not known a-priori. Our work\nis the first to address the problem of optimal task sequencing for online,\nheterogeneous, time-constrained macrotasks. We propose tas-online, an online\nalgorithm that aims to complete as many tasks as possible within budget,\nrequired quality and a given timeline, without future input information\nregarding job release dates or worker availabilities. Results, comparing\ntas-online to four typical benchmarks, show that it achieves more completed\njobs, lower flow times and higher job quality. This work has practical\nimplications for improving the Quality of Service of current crowdsourcing\nplatforms, allowing them to offer cost, quality and time improvements for\nexpert tasks.\n", "versions": [{"version": "v1", "created": "Fri, 15 Jan 2016 19:26:04 GMT"}], "update_date": "2016-01-18", "authors_parsed": [["Schmitz", "Heinz", ""], ["Lykourentzou", "Ioanna", ""]]}, {"id": "1601.04105", "submitter": "Mohsen Taheriyan", "authors": "Mohsen Taheriyan, Craig A. Knoblock, Pedro Szekely, Jose Luis Ambite", "title": "Learning the Semantics of Structured Data Sources", "comments": "Web Semantics: Science, Services and Agents on the World Wide Web,\n  2016", "journal-ref": null, "doi": "10.1016/j.websem.2015.12.003", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Information sources such as relational databases, spreadsheets, XML, JSON,\nand Web APIs contain a tremendous amount of structured data that can be\nleveraged to build and augment knowledge graphs. However, they rarely provide a\nsemantic model to describe their contents. Semantic models of data sources\nrepresent the implicit meaning of the data by specifying the concepts and the\nrelationships within the data. Such models are the key ingredients to\nautomatically publish the data into knowledge graphs. Manually modeling the\nsemantics of data sources requires significant effort and expertise, and\nalthough desirable, building these models automatically is a challenging\nproblem. Most of the related work focuses on semantic annotation of the data\nfields (source attributes). However, constructing a semantic model that\nexplicitly describes the relationships between the attributes in addition to\ntheir semantic types is critical.\n  We present a novel approach that exploits the knowledge from a domain\nontology and the semantic models of previously modeled sources to automatically\nlearn a rich semantic model for a new source. This model represents the\nsemantics of the new source in terms of the concepts and relationships defined\nby the domain ontology. Given some sample data from the new source, we leverage\nthe knowledge in the domain ontology and the known semantic models to construct\na weighted graph that represents the space of plausible semantic models for the\nnew source. Then, we compute the top k candidate semantic models and suggest to\nthe user a ranked list of the semantic models for the new source. The approach\ntakes into account user corrections to learn more accurate semantic models on\nfuture data sources. Our evaluation shows that our method generates expressive\nsemantic models for data sources and services with minimal user input. ...\n", "versions": [{"version": "v1", "created": "Sat, 16 Jan 2016 00:55:25 GMT"}], "update_date": "2016-01-19", "authors_parsed": [["Taheriyan", "Mohsen", ""], ["Knoblock", "Craig A.", ""], ["Szekely", "Pedro", ""], ["Ambite", "Jose Luis", ""]]}, {"id": "1601.04126", "submitter": "Kush Varshney", "authors": "Kush R. Varshney", "title": "Engineering Safety in Machine Learning", "comments": "2016 Information Theory and Applications Workshop, La Jolla,\n  California", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning algorithms are increasingly influencing our decisions and\ninteracting with us in all parts of our daily lives. Therefore, just like for\npower plants, highways, and myriad other engineered sociotechnical systems, we\nmust consider the safety of systems involving machine learning. In this paper,\nwe first discuss the definition of safety in terms of risk, epistemic\nuncertainty, and the harm incurred by unwanted outcomes. Then we examine\ndimensions, such as the choice of cost function and the appropriateness of\nminimizing the empirical average training cost, along which certain real-world\napplications may not be completely amenable to the foundational principle of\nmodern statistical machine learning: empirical risk minimization. In\nparticular, we note an emerging dichotomy of applications: ones in which safety\nis important and risk minimization is not the complete story (we name these\nType A applications), and ones in which safety is not so critical and risk\nminimization is sufficient (we name these Type B applications). Finally, we\ndiscuss how four different strategies for achieving safety in engineering\n(inherently safe design, safety reserves, safe fail, and procedural safeguards)\ncan be mapped to the machine learning context through interpretability and\ncausality of predictive models, objectives beyond expected prediction accuracy,\nhuman involvement for labeling difficult or rare examples, and user experience\ndesign of software.\n", "versions": [{"version": "v1", "created": "Sat, 16 Jan 2016 05:46:57 GMT"}], "update_date": "2016-01-19", "authors_parsed": [["Varshney", "Kush R.", ""]]}, {"id": "1601.04149", "submitter": "Zhangyang Wang", "authors": "Zhangyang Wang, Ding Liu, Shiyu Chang, Qing Ling, Yingzhen Yang, and\n  Thomas S. Huang", "title": "$\\mathbf{D^3}$: Deep Dual-Domain Based Fast Restoration of\n  JPEG-Compressed Images", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we design a Deep Dual-Domain ($\\mathbf{D^3}$) based fast\nrestoration model to remove artifacts of JPEG compressed images. It leverages\nthe large learning capacity of deep networks, as well as the problem-specific\nexpertise that was hardly incorporated in the past design of deep\narchitectures. For the latter, we take into consideration both the prior\nknowledge of the JPEG compression scheme, and the successful practice of the\nsparsity-based dual-domain approach. We further design the One-Step Sparse\nInference (1-SI) module, as an efficient and light-weighted feed-forward\napproximation of sparse coding. Extensive experiments verify the superiority of\nthe proposed $D^3$ model over several state-of-the-art methods. Specifically,\nour best model is capable of outperforming the latest deep model for around 1\ndB in PSNR, and is 30 times faster.\n", "versions": [{"version": "v1", "created": "Sat, 16 Jan 2016 10:38:43 GMT"}, {"version": "v2", "created": "Fri, 1 Apr 2016 03:19:10 GMT"}, {"version": "v3", "created": "Sat, 9 Apr 2016 19:25:08 GMT"}], "update_date": "2016-04-12", "authors_parsed": [["Wang", "Zhangyang", ""], ["Liu", "Ding", ""], ["Chang", "Shiyu", ""], ["Ling", "Qing", ""], ["Yang", "Yingzhen", ""], ["Huang", "Thomas S.", ""]]}, {"id": "1601.04153", "submitter": "Zhangyang Wang", "authors": "Zhangyang Wang, Shiyu Chang, Yingzhen Yang, Ding Liu, and Thomas S.\n  Huang", "title": "Studying Very Low Resolution Recognition Using Deep Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Visual recognition research often assumes a sufficient resolution of the\nregion of interest (ROI). That is usually violated in practice, inspiring us to\nexplore the Very Low Resolution Recognition (VLRR) problem. Typically, the ROI\nin a VLRR problem can be smaller than $16 \\times 16$ pixels, and is challenging\nto be recognized even by human experts. We attempt to solve the VLRR problem\nusing deep learning methods. Taking advantage of techniques primarily in super\nresolution, domain adaptation and robust regression, we formulate a dedicated\ndeep learning method and demonstrate how these techniques are incorporated step\nby step. Any extra complexity, when introduced, is fully justified by both\nanalysis and simulation results. The resulting \\textit{Robust Partially Coupled\nNetworks} achieves feature enhancement and recognition simultaneously. It\nallows for both the flexibility to combat the LR-HR domain mismatch, and the\nrobustness to outliers. Finally, the effectiveness of the proposed models is\nevaluated on three different VLRR tasks, including face identification, digit\nrecognition and font recognition, all of which obtain very impressive\nperformances.\n", "versions": [{"version": "v1", "created": "Sat, 16 Jan 2016 10:54:33 GMT"}, {"version": "v2", "created": "Fri, 1 Apr 2016 03:21:40 GMT"}], "update_date": "2016-04-04", "authors_parsed": [["Wang", "Zhangyang", ""], ["Chang", "Shiyu", ""], ["Yang", "Yingzhen", ""], ["Liu", "Ding", ""], ["Huang", "Thomas S.", ""]]}, {"id": "1601.04574", "submitter": "Heriberto Cuay\\'ahuitl", "authors": "Heriberto Cuay\\'ahuitl", "title": "SimpleDS: A Simple Deep Reinforcement Learning Dialogue System", "comments": "International Workshop on Spoken Dialogue Systems (IWSDS), 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents 'SimpleDS', a simple and publicly available dialogue\nsystem trained with deep reinforcement learning. In contrast to previous\nreinforcement learning dialogue systems, this system avoids manual feature\nengineering by performing action selection directly from raw text of the last\nsystem and (noisy) user responses. Our initial results, in the restaurant\ndomain, show that it is indeed possible to induce reasonable dialogue behaviour\nwith an approach that aims for high levels of automation in dialogue control\nfor intelligent interactive agents.\n", "versions": [{"version": "v1", "created": "Mon, 18 Jan 2016 15:37:22 GMT"}], "update_date": "2021-05-10", "authors_parsed": [["Cuay\u00e1huitl", "Heriberto", ""]]}, {"id": "1601.04667", "submitter": "Patrick Eschenfeldt", "authors": "Patrick Eschenfeldt, Dan Schmidt, Stark Draper, Jonathan Yedidia", "title": "Proactive Message Passing on Memory Factor Networks", "comments": "35 pages, 13 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new type of graphical model that we call a \"memory factor\nnetwork\" (MFN). We show how to use MFNs to model the structure inherent in many\ntypes of data sets. We also introduce an associated message-passing style\nalgorithm called \"proactive message passing\"' (PMP) that performs inference on\nMFNs. PMP comes with convergence guarantees and is efficient in comparison to\ncompeting algorithms such as variants of belief propagation. We specialize MFNs\nand PMP to a number of distinct types of data (discrete, continuous, labelled)\nand inference problems (interpolation, hypothesis testing), provide examples,\nand discuss approaches for efficient implementation.\n", "versions": [{"version": "v1", "created": "Mon, 18 Jan 2016 19:38:51 GMT"}], "update_date": "2016-01-19", "authors_parsed": [["Eschenfeldt", "Patrick", ""], ["Schmidt", "Dan", ""], ["Draper", "Stark", ""], ["Yedidia", "Jonathan", ""]]}, {"id": "1601.04800", "submitter": "Zhao Kang", "authors": "Zhao Kang, Chong Peng, Qiang Cheng", "title": "Top-N Recommender System via Matrix Completion", "comments": "AAAI 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Top-N recommender systems have been investigated widely both in industry and\nacademia. However, the recommendation quality is far from satisfactory. In this\npaper, we propose a simple yet promising algorithm. We fill the user-item\nmatrix based on a low-rank assumption and simultaneously keep the original\ninformation. To do that, a nonconvex rank relaxation rather than the nuclear\nnorm is adopted to provide a better rank approximation and an efficient\noptimization strategy is designed. A comprehensive set of experiments on real\ndatasets demonstrates that our method pushes the accuracy of Top-N\nrecommendation to a new level.\n", "versions": [{"version": "v1", "created": "Tue, 19 Jan 2016 04:48:42 GMT"}], "update_date": "2016-01-20", "authors_parsed": [["Kang", "Zhao", ""], ["Peng", "Chong", ""], ["Cheng", "Qiang", ""]]}, {"id": "1601.04908", "submitter": "Martha Lewis", "authors": "Desislava Bankova, Bob Coecke, Martha Lewis, Daniel Marsden", "title": "Graded Entailment for Compositional Distributional Semantics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LO math.CT quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The categorical compositional distributional model of natural language\nprovides a conceptually motivated procedure to compute the meaning of\nsentences, given grammatical structure and the meanings of its words. This\napproach has outperformed other models in mainstream empirical language\nprocessing tasks. However, until recently it has lacked the crucial feature of\nlexical entailment -- as do other distributional models of meaning.\n  In this paper we solve the problem of entailment for categorical\ncompositional distributional semantics. Taking advantage of the abstract\ncategorical framework allows us to vary our choice of model. This enables the\nintroduction of a notion of entailment, exploiting ideas from the categorical\nsemantics of partial knowledge in quantum computation.\n  The new model of language uses density matrices, on which we introduce a\nnovel robust graded order capturing the entailment strength between concepts.\nThis graded measure emerges from a general framework for approximate\nentailment, induced by any commutative monoid. Quantum logic embeds in our\ngraded order.\n  Our main theorem shows that entailment strength lifts compositionally to the\nsentence level, giving a lower bound on sentence entailment. We describe the\nessential properties of graded entailment such as continuity, and provide a\nprocedure for calculating entailment strength.\n", "versions": [{"version": "v1", "created": "Tue, 19 Jan 2016 13:13:25 GMT"}, {"version": "v2", "created": "Mon, 25 Jan 2016 20:10:27 GMT"}], "update_date": "2016-01-26", "authors_parsed": [["Bankova", "Desislava", ""], ["Coecke", "Bob", ""], ["Lewis", "Martha", ""], ["Marsden", "Daniel", ""]]}, {"id": "1601.04943", "submitter": "Hongseok Yang", "authors": "Sam Staton, Hongseok Yang, Chris Heunen, Ohad Kammar, Frank Wood", "title": "Semantics for probabilistic programming: higher-order functions,\n  continuous distributions, and soft constraints", "comments": null, "journal-ref": "Logic in Computer Science 525--534, 2016", "doi": "10.1145/2933575.2935313", "report-no": null, "categories": "cs.PL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the semantic foundation of expressive probabilistic programming\nlanguages, that support higher-order functions, continuous distributions, and\nsoft constraints (such as Anglican, Church, and Venture). We define a\nmetalanguage (an idealised version of Anglican) for probabilistic computation\nwith the above features, develop both operational and denotational semantics,\nand prove soundness, adequacy, and termination. They involve measure theory,\nstochastic labelled transition systems, and functor categories, but admit\nintuitive computational readings, one of which views sampled random variables\nas dynamically allocated read-only variables. We apply our semantics to\nvalidate nontrivial equations underlying the correctness of certain compiler\noptimisations and inference algorithms such as sequential Monte Carlo\nsimulation. The language enables defining probability distributions on\nhigher-order functions, and we study their properties.\n", "versions": [{"version": "v1", "created": "Tue, 19 Jan 2016 14:53:54 GMT"}, {"version": "v2", "created": "Wed, 20 Jan 2016 05:51:41 GMT"}, {"version": "v3", "created": "Wed, 4 May 2016 04:38:55 GMT"}], "update_date": "2017-03-31", "authors_parsed": [["Staton", "Sam", ""], ["Yang", "Hongseok", ""], ["Heunen", "Chris", ""], ["Kammar", "Ohad", ""], ["Wood", "Frank", ""]]}, {"id": "1601.05140", "submitter": "Aram Galstyan", "authors": "V.S. Subrahmanian, Amos Azaria, Skylar Durst, Vadim Kagan, Aram\n  Galstyan, Kristina Lerman, Linhong Zhu, Emilio Ferrara, Alessandro Flammini,\n  Filippo Menczer, Andrew Stevens, Alexander Dekhtyar, Shuyang Gao, Tad Hogg,\n  Farshad Kooti, Yan Liu, Onur Varol, Prashant Shiralkar, Vinod Vydiswaran,\n  Qiaozhu Mei, Tim Hwang", "title": "The DARPA Twitter Bot Challenge", "comments": "IEEE Computer Magazine, in press", "journal-ref": "Computer 49 (6), 38-46. IEEE, 2016", "doi": "10.1109/MC.2016.183", "report-no": null, "categories": "cs.SI cs.AI cs.CY physics.data-an physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A number of organizations ranging from terrorist groups such as ISIS to\npoliticians and nation states reportedly conduct explicit campaigns to\ninfluence opinion on social media, posing a risk to democratic processes. There\nis thus a growing need to identify and eliminate \"influence bots\" - realistic,\nautomated identities that illicitly shape discussion on sites like Twitter and\nFacebook - before they get too influential. Spurred by such events, DARPA held\na 4-week competition in February/March 2015 in which multiple teams supported\nby the DARPA Social Media in Strategic Communications program competed to\nidentify a set of previously identified \"influence bots\" serving as ground\ntruth on a specific topic within Twitter. Past work regarding influence bots\noften has difficulty supporting claims about accuracy, since there is limited\nground truth (though some exceptions do exist [3,7]). However, with the\nexception of [3], no past work has looked specifically at identifying influence\nbots on a specific topic. This paper describes the DARPA Challenge and\ndescribes the methods used by the three top-ranked teams.\n", "versions": [{"version": "v1", "created": "Wed, 20 Jan 2016 00:23:03 GMT"}, {"version": "v2", "created": "Thu, 21 Apr 2016 23:02:08 GMT"}], "update_date": "2017-03-07", "authors_parsed": [["Subrahmanian", "V. S.", ""], ["Azaria", "Amos", ""], ["Durst", "Skylar", ""], ["Kagan", "Vadim", ""], ["Galstyan", "Aram", ""], ["Lerman", "Kristina", ""], ["Zhu", "Linhong", ""], ["Ferrara", "Emilio", ""], ["Flammini", "Alessandro", ""], ["Menczer", "Filippo", ""], ["Stevens", "Andrew", ""], ["Dekhtyar", "Alexander", ""], ["Gao", "Shuyang", ""], ["Hogg", "Tad", ""], ["Kooti", "Farshad", ""], ["Liu", "Yan", ""], ["Varol", "Onur", ""], ["Shiralkar", "Prashant", ""], ["Vydiswaran", "Vinod", ""], ["Mei", "Qiaozhu", ""], ["Hwang", "Tim", ""]]}, {"id": "1601.05403", "submitter": "Jo\\~ao Sedoc", "authors": "Jo\\~ao Sedoc, Jean Gallier, Lyle Ungar, Dean Foster", "title": "Semantic Word Clusters Using Signed Normalized Graph Cuts", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Vector space representations of words capture many aspects of word\nsimilarity, but such methods tend to make vector spaces in which antonyms (as\nwell as synonyms) are close to each other. We present a new signed spectral\nnormalized graph cut algorithm, signed clustering, that overlays existing\nthesauri upon distributionally derived vector representations of words, so that\nantonym relationships between word pairs are represented by negative weights.\nOur signed clustering algorithm produces clusters of words which simultaneously\ncapture distributional and synonym relations. We evaluate these clusters\nagainst the SimLex-999 dataset (Hill et al.,2014) of human judgments of word\npair similarities, and also show the benefit of using our clusters to predict\nthe sentiment of a given text.\n", "versions": [{"version": "v1", "created": "Wed, 20 Jan 2016 20:37:47 GMT"}], "update_date": "2016-01-21", "authors_parsed": [["Sedoc", "Jo\u00e3o", ""], ["Gallier", "Jean", ""], ["Ungar", "Lyle", ""], ["Foster", "Dean", ""]]}, {"id": "1601.05744", "submitter": "Jared Weed", "authors": "Jared Weed", "title": "Sub-Optimal Multi-Phase Path Planning: A Method for Solving Rubik's\n  Revenge", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.HO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Rubik's Revenge, a 4x4x4 variant of the Rubik's puzzles, remains to date as\nan unsolved puzzle. That is to say, we do not have a method or successful\ncategorization to optimally solve every one of its approximately $7.401 \\times\n10^{45}$ possible configurations. Rubik's Cube, Rubik's Revenge's predecessor\n(3x3x3), with its approximately $4.33 \\times 10^{19}$ possible configurations,\nhas only recently been completely solved by Rokicki et. al, further finding\nthat any configuration requires no more than 20 moves. With the sheer dimension\nof Rubik's Revenge and its total configuration space, a brute-force method of\nfinding all optimal solutions would be in vain. Similar to the methods used by\nRokicki et. al on Rubik's Cube, in this paper we develop a method for solving\narbitrary configurations of Rubik's Revenge in phases, using a combination of a\npowerful algorithm known as IDA* and a useful definition of distance in the\ncube space. While time-series results were not successfully gathered, it will\nbe shown that this method far outweighs current human-solving methods and can\nbe used to determine loose upper bounds for the cube space. Discussion will\nsuggest that this method can also be applied to other puzzles with the proper\ntransformations.\n", "versions": [{"version": "v1", "created": "Wed, 20 Jan 2016 18:27:44 GMT"}], "update_date": "2016-01-23", "authors_parsed": [["Weed", "Jared", ""]]}, {"id": "1601.05893", "submitter": "Hans De Sterck", "authors": "Shawn Brunsting, Hans De Sterck, Remco Dolman, Teun van Sprundel", "title": "GeoTextTagger: High-Precision Location Tagging of Textual Documents\n  using a Natural Language Processing Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.DB cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Location tagging, also known as geotagging or geolocation, is the process of\nassigning geographical coordinates to input data. In this paper we present an\nalgorithm for location tagging of textual documents. Our approach makes use of\nprevious work in natural language processing by using a state-of-the-art\npart-of-speech tagger and named entity recognizer to find blocks of text which\nmay refer to locations. A knowledge base (OpenStreatMap) is then used to find a\nlist of possible locations for each block. Finally, one location is chosen for\neach block by assigning distance-based scores to each location and repeatedly\nselecting the location and block with the best score. We tested our geolocation\nalgorithm with Wikipedia articles about topics with a well-defined geographical\nlocation that are geotagged by the articles' authors, where classification\napproaches have achieved median errors as low as 11 km, with attainable\naccuracy limited by the class size. Our approach achieved a 10th percentile\nerror of 490 metres and median error of 54 kilometres on the Wikipedia dataset\nwe used. When considering the five location tags with the greatest scores, 50%\nof articles were assigned at least one tag within 8.5 kilometres of the\narticle's author-assigned true location. We also tested our approach on Twitter\nmessages that are tagged with the location from which the message was sent.\nTwitter texts are challenging because they are short and unstructured and often\ndo not contain words referring to the location they were sent from, but we\nobtain potentially useful results. We explain how we use the Spark framework\nfor data analytics to collect and process our test data. In general,\nclassification-based approaches for location tagging may be reaching their\nupper accuracy limit, but our precision-focused approach has high accuracy for\nsome texts and shows significant potential for improvement overall.\n", "versions": [{"version": "v1", "created": "Fri, 22 Jan 2016 07:09:54 GMT"}], "update_date": "2016-01-25", "authors_parsed": [["Brunsting", "Shawn", ""], ["De Sterck", "Hans", ""], ["Dolman", "Remco", ""], ["van Sprundel", "Teun", ""]]}, {"id": "1601.05977", "submitter": "Amnon Eden", "authors": "Amnon H. Eden", "title": "The Singularity Controversy, Part I: Lessons Learned and Open Questions:\n  Conclusions from the Battle on the Legitimacy of the Debate", "comments": null, "journal-ref": null, "doi": "10.13140/RG.2.1.3416.6809", "report-no": "STR 2016-1", "categories": "cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This report seeks to inform policy makers on the nature and the merit of the\narguments for and against the concerns associated with a potential\ntechnological singularity.\n  Part I describes the lessons learned from our investigation of the subject,\nseparating the argu-ments of merit from the fallacies and misconceptions that\nconfuse the debate and undermine its rational resolution.\n", "versions": [{"version": "v1", "created": "Fri, 22 Jan 2016 12:41:43 GMT"}, {"version": "v2", "created": "Thu, 28 Jan 2016 16:32:19 GMT"}], "update_date": "2016-02-12", "authors_parsed": [["Eden", "Amnon H.", ""]]}, {"id": "1601.06041", "submitter": "Elias Alevizos", "authors": "Kostas Patroumpas and Elias Alevizos and Alexander Artikis and Marios\n  Vodas and Nikos Pelekis and Yannis Theodoridis", "title": "Online Event Recognition from Moving Vessel Trajectories", "comments": null, "journal-ref": null, "doi": "10.1007/s10707-016-0266-x", "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a system for online monitoring of maritime activity over streaming\npositions from numerous vessels sailing at sea. It employs an online tracking\nmodule for detecting important changes in the evolving trajectory of each\nvessel across time, and thus can incrementally retain concise, yet reliable\nsummaries of its recent movement. In addition, thanks to its complex event\nrecognition module, this system can also offer instant notification to marine\nauthorities regarding emergency situations, such as risk of collisions,\nsuspicious moves in protected zones, or package picking at open sea. Not only\ndid our extensive tests validate the performance, efficiency, and robustness of\nthe system against scalable volumes of real-world and synthetically enlarged\ndatasets, but its deployment against online feeds from vessels has also\nconfirmed its capabilities for effective, real-time maritime surveillance.\n", "versions": [{"version": "v1", "created": "Fri, 22 Jan 2016 15:24:41 GMT"}], "update_date": "2018-12-18", "authors_parsed": [["Patroumpas", "Kostas", ""], ["Alevizos", "Elias", ""], ["Artikis", "Alexander", ""], ["Vodas", "Marios", ""], ["Pelekis", "Nikos", ""], ["Theodoridis", "Yannis", ""]]}, {"id": "1601.06069", "submitter": "Alexander Kott", "authors": "Larry Ground, Alexander Kott, Ray Budd", "title": "Coalition-based Planning of Military Operations: Adversarial Reasoning\n  Algorithms in an Integrated Decision Aid", "comments": "A version of this paper appeared in proceedings of the 2002\n  International Conference on Knowledge Systems for Coalition Operations (KSCO)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Use of knowledge-based planning tools can help alleviate the challenges of\nplanning a complex operation by a coalition of diverse parties in an\nadversarial environment. We explore these challenges and potential\ncontributions of knowledge-based tools using as an example the CADET system, a\nknowledge-based tool capable of producing automatically (or with human\nguidance) battle plans with realistic degree of detail and complexity. In\nongoing experiments, it compared favorably with human planners. Interleaved\nplanning, scheduling, routing, attrition and consumption processes comprise the\ncomputational approach of this tool. From the coalition operations perspective,\nsuch tools offer an important aid in rapid synchronization of assets and\nactions of heterogeneous assets belonging to multiple organizations,\npotentially with distinct doctrine and rules of engagement. In this paper, we\ndiscuss the functionality of the tool, provide a brief overview of the\ntechnical approach and experimental results, and outline the potential value of\nsuch tools.\n", "versions": [{"version": "v1", "created": "Fri, 22 Jan 2016 16:53:45 GMT"}], "update_date": "2016-01-25", "authors_parsed": [["Ground", "Larry", ""], ["Kott", "Alexander", ""], ["Budd", "Ray", ""]]}, {"id": "1601.06071", "submitter": "Minje Kim", "authors": "Minje Kim and Paris Smaragdis", "title": "Bitwise Neural Networks", "comments": "This paper was presented at the International Conference on Machine\n  Learning (ICML) Workshop on Resource-Efficient Machine Learning, Lille,\n  France, Jul. 6-11, 2015", "journal-ref": "International Conference on Machine Learning (ICML) Workshop on\n  Resource-Efficient Machine Learning, Lille, France, Jul. 6-11, 2015", "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Based on the assumption that there exists a neural network that efficiently\nrepresents a set of Boolean functions between all binary inputs and outputs, we\npropose a process for developing and deploying neural networks whose weight\nparameters, bias terms, input, and intermediate hidden layer output signals,\nare all binary-valued, and require only basic bit logic for the feedforward\npass. The proposed Bitwise Neural Network (BNN) is especially suitable for\nresource-constrained environments, since it replaces either floating or\nfixed-point arithmetic with significantly more efficient bitwise operations.\nHence, the BNN requires for less spatial complexity, less memory bandwidth, and\nless power consumption in hardware. In order to design such networks, we\npropose to add a few training schemes, such as weight compression and noisy\nbackpropagation, which result in a bitwise network that performs almost as well\nas its corresponding real-valued network. We test the proposed network on the\nMNIST dataset, represented using binary features, and show that BNNs result in\ncompetitive performance while offering dramatic computational savings.\n", "versions": [{"version": "v1", "created": "Fri, 22 Jan 2016 16:59:01 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Kim", "Minje", ""], ["Smaragdis", "Paris", ""]]}, {"id": "1601.06108", "submitter": "Alexander Kott", "authors": "Alexander Kott, Ray Budd, Larry Ground, Lakshmi Rebbapragada, John\n  Langston", "title": "Decision Aids for Adversarial Planning in Military Operations:\n  Algorithms, Tools, and Turing-test-like Experimental Validation", "comments": "A version of this paper appeared in the Applied Intelligence journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Use of intelligent decision aids can help alleviate the challenges of\nplanning complex operations. We describe integrated algorithms, and a tool\ncapable of translating a high-level concept for a tactical military operation\ninto a fully detailed, actionable plan, producing automatically (or with human\nguidance) plans with realistic degree of detail and of human-like quality.\nTight interleaving of several algorithms -- planning, adversary estimates,\nscheduling, routing, attrition and consumption estimates -- comprise the\ncomputational approach of this tool. Although originally developed for Army\nlarge-unit operations, the technology is generic and also applies to a number\nof other domains, particularly in critical situations requiring detailed\nplanning within a constrained period of time. In this paper, we focus\nparticularly on the engineering tradeoffs in the design of the tool. In an\nexperimental evaluation, reminiscent of the Turing test, the tool's performance\ncompared favorably with human planners.\n", "versions": [{"version": "v1", "created": "Fri, 22 Jan 2016 19:13:06 GMT"}], "update_date": "2016-01-25", "authors_parsed": [["Kott", "Alexander", ""], ["Budd", "Ray", ""], ["Ground", "Larry", ""], ["Rebbapragada", "Lakshmi", ""], ["Langston", "John", ""]]}, {"id": "1601.06180", "submitter": "Robert Peharz", "authors": "Robert Peharz, Robert Gens, Franz Pernkopf, Pedro Domingos", "title": "On the Latent Variable Interpretation in Sum-Product Networks", "comments": "Revised version, accepted for publication in IEEE Transactions on\n  Machine Intelligence and Pattern Analysis (TPAMI). Shortened and revised\n  Section 4: Thanks to our reviewers, pointing out that Theorem 2 holds for\n  selective SPNs. Added paragraph in Section 2.1, relating sizes of\n  original/augmented SPNs. Fixed typos, rephrased sentences, revised references", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the central themes in Sum-Product networks (SPNs) is the\ninterpretation of sum nodes as marginalized latent variables (LVs). This\ninterpretation yields an increased syntactic or semantic structure, allows the\napplication of the EM algorithm and to efficiently perform MPE inference. In\nliterature, the LV interpretation was justified by explicitly introducing the\nindicator variables corresponding to the LVs' states. However, as pointed out\nin this paper, this approach is in conflict with the completeness condition in\nSPNs and does not fully specify the probabilistic model. We propose a remedy\nfor this problem by modifying the original approach for introducing the LVs,\nwhich we call SPN augmentation. We discuss conditional independencies in\naugmented SPNs, formally establish the probabilistic interpretation of the\nsum-weights and give an interpretation of augmented SPNs as Bayesian networks.\nBased on these results, we find a sound derivation of the EM algorithm for\nSPNs. Furthermore, the Viterbi-style algorithm for MPE proposed in literature\nwas never proven to be correct. We show that this is indeed a correct\nalgorithm, when applied to selective SPNs, and in particular when applied to\naugmented SPNs. Our theoretical results are confirmed in experiments on\nsynthetic data and 103 real-world datasets.\n", "versions": [{"version": "v1", "created": "Fri, 22 Jan 2016 21:40:33 GMT"}, {"version": "v2", "created": "Fri, 28 Oct 2016 07:54:35 GMT"}], "update_date": "2016-10-31", "authors_parsed": [["Peharz", "Robert", ""], ["Gens", "Robert", ""], ["Pernkopf", "Franz", ""], ["Domingos", "Pedro", ""]]}, {"id": "1601.06245", "submitter": "Zhiwei Zeng", "authors": "Zhiwei Zeng", "title": "Artificial Persuasion in Pedagogical Games", "comments": "This is a book draft", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A Persuasive Teachable Agent (PTA) is a special type of Teachable Agent which\nincorporates a persuasion theory in order to provide persuasive and more\npersonalized feedback to the student. By employing the persuasion techniques,\nthe PTA seeks to maintain the student in a high motivation and high ability\nstate in which he or she has higher cognitive ability and his or her changes in\nattitudes are more persistent. However, the existing model of the PTA still has\na few limitations. Firstly, the existing PTA model focuses on modelling the\nPTA's ability to persuade, while does not model its ability to be taught by the\nstudent and to practice the knowledge it has learnt. Secondly, the quantitative\nmodel for computational processes in the PTA has low reusability. Thirdly,\nthere is still a gap between theoretical models and practical implementation of\nthe PTA.\n  To address these three limitations, this book proposes an improved agent\nmodel which follows a goal-oriented approach and models the PTA in its totality\nby integrating the Persuasion Reasoning of the PTA with the Teachability\nReasoning and the Practicability Reasoning. The project also proposes a more\nabstract and generalized quantitative model for the computations in the PTA.\nWith higher level of abstraction, the reusability of the quantitative model is\nalso improved. New system architecture is introduced to bridge the gap between\ntheoretical models and implementation of the PTA.\n", "versions": [{"version": "v1", "created": "Sat, 23 Jan 2016 07:29:20 GMT"}], "update_date": "2016-01-26", "authors_parsed": [["Zeng", "Zhiwei", ""]]}, {"id": "1601.06569", "submitter": "Kareem Amin", "authors": "Kareem Amin, Satinder Singh", "title": "Towards Resolving Unidentifiability in Inverse Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a setting for Inverse Reinforcement Learning (IRL) where the\nlearner is extended with the ability to actively select multiple environments,\nobserving an agent's behavior on each environment. We first demonstrate that if\nthe learner can experiment with any transition dynamics on some fixed set of\nstates and actions, then there exists an algorithm that reconstructs the\nagent's reward function to the fullest extent theoretically possible, and that\nrequires only a small (logarithmic) number of experiments. We contrast this\nresult to what is known about IRL in single fixed environments, namely that the\ntrue reward function is fundamentally unidentifiable. We then extend this\nsetting to the more realistic case where the learner may not select any\ntransition dynamic, but rather is restricted to some fixed set of environments\nthat it may try. We connect the problem of maximizing the information derived\nfrom experiments to submodular function maximization and demonstrate that a\ngreedy algorithm is near optimal (up to logarithmic factors). Finally, we\nempirically validate our algorithm on an environment inspired by behavioral\npsychology.\n", "versions": [{"version": "v1", "created": "Mon, 25 Jan 2016 11:50:43 GMT"}], "update_date": "2016-01-26", "authors_parsed": [["Amin", "Kareem", ""], ["Singh", "Satinder", ""]]}, {"id": "1601.06580", "submitter": "Christian Napoli", "authors": "Dawid Polap, Marcin Wozniak, Christian Napoli, Emiliano Tramontana", "title": "Is swarm intelligence able to create mazes?", "comments": null, "journal-ref": "International Journal of Electronics and Telecommunications, Vol.\n  6, n. 4, pp. 305-310 (2015)", "doi": "10.1515/eletel-2015-0039", "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, the idea of applying Computational Intelligence in the process\nof creation board games, in particular mazes, is presented. For two different\nalgorithms the proposed idea has been examined. The results of the experiments\nare shown and discussed to present advantages and disadvantages.\n", "versions": [{"version": "v1", "created": "Mon, 25 Jan 2016 12:49:28 GMT"}], "update_date": "2016-01-29", "authors_parsed": [["Polap", "Dawid", ""], ["Wozniak", "Marcin", ""], ["Napoli", "Christian", ""], ["Tramontana", "Emiliano", ""]]}, {"id": "1601.06602", "submitter": "Markus Schneider", "authors": "Markus Schneider and Wolfgang Ertel and Fabio Ramos", "title": "Expected Similarity Estimation for Large-Scale Batch and Streaming\n  Anomaly Detection", "comments": null, "journal-ref": null, "doi": "10.1007/s10994-016-5567-7", "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel algorithm for anomaly detection on very large datasets and\ndata streams. The method, named EXPected Similarity Estimation (EXPoSE), is\nkernel-based and able to efficiently compute the similarity between new data\npoints and the distribution of regular data. The estimator is formulated as an\ninner product with a reproducing kernel Hilbert space embedding and makes no\nassumption about the type or shape of the underlying data distribution. We show\nthat offline (batch) learning with EXPoSE can be done in linear time and online\n(incremental) learning takes constant time per instance and model update.\nFurthermore, EXPoSE can make predictions in constant time, while it requires\nonly constant memory. In addition, we propose different methodologies for\nconcept drift adaptation on evolving data streams. On several real datasets we\ndemonstrate that our approach can compete with state of the art algorithms for\nanomaly detection while being an order of magnitude faster than most other\napproaches.\n", "versions": [{"version": "v1", "created": "Mon, 25 Jan 2016 13:56:59 GMT"}, {"version": "v2", "created": "Mon, 18 Apr 2016 12:37:33 GMT"}, {"version": "v3", "created": "Mon, 6 Jun 2016 13:48:17 GMT"}], "update_date": "2016-06-07", "authors_parsed": [["Schneider", "Markus", ""], ["Ertel", "Wolfgang", ""], ["Ramos", "Fabio", ""]]}, {"id": "1601.06610", "submitter": "Diederik Aerts", "authors": "Diederik Aerts, Jan Broekaert, Liane Gabora and Sandro Sozzo", "title": "Generalizing Prototype Theory: A Formal Quantum Framework", "comments": "30 pages, 3 figures", "journal-ref": "Frontiers in Psychology 7, 418, (2016)", "doi": "10.3389/fpsyg.2016.00418", "report-no": null, "categories": "cs.AI quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Theories of natural language and concepts have been unable to model the\nflexibility, creativity, context-dependence, and emergence, exhibited by words,\nconcepts and their combinations. The mathematical formalism of quantum theory\nhas instead been successful in capturing these phenomena such as graded\nmembership, situational meaning, composition of categories, and also more\ncomplex decision making situations, which cannot be modeled in traditional\nprobabilistic approaches. We show how a formal quantum approach to concepts and\ntheir combinations can provide a powerful extension of prototype theory. We\nexplain how prototypes can interfere in conceptual combinations as a\nconsequence of their contextual interactions, and provide an illustration of\nthis using an intuitive wave-like diagram. This quantum-conceptual approach\ngives new life to original prototype theory, without however making it a\nprivileged concept theory, as we explain at the end of our paper.\n", "versions": [{"version": "v1", "created": "Mon, 25 Jan 2016 14:12:59 GMT"}], "update_date": "2016-09-09", "authors_parsed": [["Aerts", "Diederik", ""], ["Broekaert", "Jan", ""], ["Gabora", "Liane", ""], ["Sozzo", "Sandro", ""]]}, {"id": "1601.06672", "submitter": "Jakub Mare\\v{c}ek", "authors": "Jakub Marecek, Robert Shorten, Jia Yuan Yu", "title": "Pricing Vehicle Sharing with Proximity Information", "comments": null, "journal-ref": null, "doi": "10.1109/ICBDSC.2016.7460378", "report-no": null, "categories": "math.OC cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For vehicle sharing schemes, where drop-off positions are not fixed, we\npropose a pricing scheme, where the price depends in part on the distance\nbetween where a vehicle is being dropped off and where the closest shared\nvehicle is parked. Under certain restrictive assumptions, we show that this\npricing leads to a socially optimal spread of the vehicles within a region.\n", "versions": [{"version": "v1", "created": "Mon, 25 Jan 2016 16:55:30 GMT"}], "update_date": "2019-10-01", "authors_parsed": [["Marecek", "Jakub", ""], ["Shorten", "Robert", ""], ["Yu", "Jia Yuan", ""]]}, {"id": "1601.06732", "submitter": "Martha Lewis", "authors": "Martha Lewis, Jonathan Lawry", "title": "Concept Generation in Language Evolution", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This thesis investigates the generation of new concepts from combinations of\nexisting concepts as a language evolves. We give a method for combining\nconcepts, and will be investigating the utility of composite concepts in\nlanguage evolution and thence the utility of concept generation.\n", "versions": [{"version": "v1", "created": "Mon, 25 Jan 2016 19:23:44 GMT"}], "update_date": "2016-01-26", "authors_parsed": [["Lewis", "Martha", ""], ["Lawry", "Jonathan", ""]]}, {"id": "1601.06738", "submitter": "Martha Lewis", "authors": "Martha Lewis, Jonathan Lawry", "title": "A Label Semantics Approach to Linguistic Hedges", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a model for the linguistic hedges `very' and `quite' within the\nlabel semantics framework, and combined with the prototype and conceptual\nspaces theories of concepts. The proposed model emerges naturally from the\nrepresentational framework we use and as such, has a clear semantic grounding.\nWe give generalisations of these hedge models and show that they can be\ncomposed with themselves and with other functions, going on to examine their\nbehaviour in the limit of composition.\n", "versions": [{"version": "v1", "created": "Mon, 25 Jan 2016 19:38:37 GMT"}], "update_date": "2016-01-26", "authors_parsed": [["Lewis", "Martha", ""], ["Lawry", "Jonathan", ""]]}, {"id": "1601.06755", "submitter": "Martha Lewis", "authors": "Martha Lewis, Jonathan Lawry", "title": "The Utility of Hedged Assertions in the Emergence of Shared Categorical\n  Labels", "comments": "AISB 2013, updated to include cross-reference to previous work", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the emergence of shared concepts in a community of language\nusers using a multi-agent simulation. We extend results showing that negated\nassertions are of use in developing shared categories, to include assertions\nmodified by linguistic hedges. Results show that using hedged assertions\npositively affects the emergence of shared categories in two distinct ways.\nFirstly, using contraction hedges like `very' gives better convergence over\ntime. Secondly, using expansion hedges such as `quite' reduces concept overlap.\nHowever, both these improvements come at a cost of slower speed of development.\n", "versions": [{"version": "v1", "created": "Mon, 25 Jan 2016 20:24:50 GMT"}], "update_date": "2016-01-26", "authors_parsed": [["Lewis", "Martha", ""], ["Lawry", "Jonathan", ""]]}, {"id": "1601.06763", "submitter": "Martha Lewis", "authors": "Martha Lewis, Jonathan Lawry", "title": "Emerging Dimension Weights in a Conceptual Spaces Model of Concept\n  Combination", "comments": "AISB 2014, updated to include references to previous work", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the generation of new concepts from combinations of properties\nas an artificial language develops. To do so, we have developed a new framework\nfor conjunctive concept combination. This framework gives a semantic grounding\nto the weighted sum approach to concept combination seen in the literature. We\nimplement the framework in a multi-agent simulation of language evolution and\nshow that shared combination weights emerge. The expected value and the\nvariance of these weights across agents may be predicted from the distribution\nof elements in the conceptual space, as determined by the underlying\nenvironment, together with the rate at which agents adopt others' concepts.\nWhen this rate is smaller, the agents are able to converge to weights with\nlower variance. However, the time taken to converge to a steady state\ndistribution of weights is longer.\n", "versions": [{"version": "v1", "created": "Mon, 25 Jan 2016 20:40:55 GMT"}], "update_date": "2016-01-26", "authors_parsed": [["Lewis", "Martha", ""], ["Lawry", "Jonathan", ""]]}, {"id": "1601.06862", "submitter": "Han Yu", "authors": "Simon Fauvel and Han Yu", "title": "A Survey on Artificial Intelligence and Data Mining for MOOCs", "comments": "Working Paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Massive Open Online Courses (MOOCs) have gained tremendous popularity in the\nlast few years. Thanks to MOOCs, millions of learners from all over the world\nhave taken thousands of high-quality courses for free. Putting together an\nexcellent MOOC ecosystem is a multidisciplinary endeavour that requires\ncontributions from many different fields. Artificial intelligence (AI) and data\nmining (DM) are two such fields that have played a significant role in making\nMOOCs what they are today. By exploiting the vast amount of data generated by\nlearners engaging in MOOCs, DM improves our understanding of the MOOC ecosystem\nand enables MOOC practitioners to deliver better courses. Similarly, AI,\nsupported by DM, can greatly improve student experience and learning outcomes.\nIn this survey paper, we first review the state-of-the-art artificial\nintelligence and data mining research applied to MOOCs, emphasising the use of\nAI and DM tools and techniques to improve student engagement, learning\noutcomes, and our understanding of the MOOC ecosystem. We then offer an\noverview of key trends and important research to carry out in the fields of AI\nand DM so that MOOCs can reach their full potential.\n", "versions": [{"version": "v1", "created": "Tue, 26 Jan 2016 01:28:29 GMT"}], "update_date": "2016-01-27", "authors_parsed": [["Fauvel", "Simon", ""], ["Yu", "Han", ""]]}, {"id": "1601.06923", "submitter": "Nevin L.  Zhang", "authors": "Chen Fu, Nevin L. Zhang, Bao Xin Chen, Zhou Rong Chen, Xiang Lan Jin,\n  Rong Juan Guo, Zhi Gang Chen, Yun Ling Zhang", "title": "Identification and classification of TCM syndrome types among patients\n  with vascular mild cognitive impairment using latent tree analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Objective: To treat patients with vascular mild cognitive impairment (VMCI)\nusing TCM, it is necessary to classify the patients into TCM syndrome types and\nto apply different treatments to different types. We investigate how to\nproperly carry out the classification using a novel data-driven method known as\nlatent tree analysis.\n  Method: A cross-sectional survey on VMCI was carried out in several regions\nin northern China from 2008 to 2011, which resulted in a data set that involves\n803 patients and 93 symptoms. Latent tree analysis was performed on the data to\nreveal symptom co-occurrence patterns, and the patients were partitioned into\nclusters in multiple ways based on the patterns. The patient clusters were\nmatched up with syndrome types, and population statistics of the clusters are\nused to quantify the syndrome types and to establish classification rules.\n  Results: Eight syndrome types are identified: Qi Deficiency, Qi Stagnation,\nBlood Deficiency, Blood Stasis, Phlegm-Dampness, Fire-Heat, Yang Deficiency,\nand Yin Deficiency. The prevalence and symptom occurrence characteristics of\neach syndrome type are determined. Quantitative classification rules are\nestablished for determining whether a patient belongs to each of the syndrome\ntypes.\n  Conclusions: A solution for the TCM syndrome classification problem\nassociated with VMCI is established based on the latent tree analysis of\nunlabeled symptom survey data. The results can be used as a reference in clinic\npractice to improve the quality of syndrome differentiation and to reduce\ndiagnosis variances across physicians. They can also be used for patient\nselection in research projects aimed at finding biomarkers for the syndrome\ntypes and in randomized control trials aimed at determining the efficacy of TCM\ntreatments of VMCI.\n", "versions": [{"version": "v1", "created": "Tue, 26 Jan 2016 08:34:56 GMT"}, {"version": "v2", "created": "Wed, 24 Feb 2016 16:04:24 GMT"}], "update_date": "2016-02-25", "authors_parsed": [["Fu", "Chen", ""], ["Zhang", "Nevin L.", ""], ["Chen", "Bao Xin", ""], ["Chen", "Zhou Rong", ""], ["Jin", "Xiang Lan", ""], ["Guo", "Rong Juan", ""], ["Chen", "Zhi Gang", ""], ["Zhang", "Yun Ling", ""]]}, {"id": "1601.06931", "submitter": "Manuel Marin-Jimenez", "authors": "F.M. Castro and M.J. Mar\\'in-Jim\\'enez and N. Guil and R.\n  Mu\\~noz-Salinas", "title": "Fisher Motion Descriptor for Multiview Gait Recognition", "comments": "This paper extends with new experiments the one published at\n  ICPR'2014", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The goal of this paper is to identify individuals by analyzing their gait.\nInstead of using binary silhouettes as input data (as done in many previous\nworks) we propose and evaluate the use of motion descriptors based on densely\nsampled short-term trajectories. We take advantage of state-of-the-art people\ndetectors to define custom spatial configurations of the descriptors around the\ntarget person, obtaining a rich representation of the gait motion. The local\nmotion features (described by the Divergence-Curl-Shear descriptor) extracted\non the different spatial areas of the person are combined into a single\nhigh-level gait descriptor by using the Fisher Vector encoding. The proposed\napproach, coined Pyramidal Fisher Motion, is experimentally validated on\n`CASIA' dataset (parts B and C), `TUM GAID' dataset, `CMU MoBo' dataset and the\nrecent `AVA Multiview Gait' dataset. The results show that this new approach\nachieves state-of-the-art results in the problem of gait recognition, allowing\nto recognize walking people from diverse viewpoints on single and multiple\ncamera setups, wearing different clothes, carrying bags, walking at diverse\nspeeds and not limited to straight walking paths.\n", "versions": [{"version": "v1", "created": "Tue, 26 Jan 2016 09:05:26 GMT"}], "update_date": "2016-01-27", "authors_parsed": [["Castro", "F. M.", ""], ["Mar\u00edn-Jim\u00e9nez", "M. J.", ""], ["Guil", "N.", ""], ["Mu\u00f1oz-Salinas", "R.", ""]]}, {"id": "1601.07065", "submitter": "Ong Sing Goh", "authors": "Ser Ling Lim, Ong Sing Goh", "title": "Intelligent Conversational Bot for Massive Online Open Courses (MOOCs)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Massive Online Open Courses (MOOCs) which were introduced in 2008 has since\ndrawn attention around the world for both its advantages as well as criticism\non its drawbacks. One of the issues in MOOCs which is the lack of interactivity\nwith the instructor has brought conversational bot into the picture to fill in\nthis gap. In this study, a prototype of MOOCs conversational bot, MOOC-bot is\nbeing developed and integrated into MOOCs website to respond to the learner\ninquiries using text or speech input. MOOC-bot is using the popular Artificial\nIntelligence Markup Language (AIML) to develop its knowledge base, leverage\nfrom AIML capability to deliver appropriate responses and can be quickly\nadapted to new knowledge domains. The system architecture of MOOC-bot consists\nof knowledge base along with AIML interpreter, chat interface, MOOCs website\nand Web Speech API to provide speech recognition and speech synthesis\ncapability. The initial MOOC-bot prototype has the general knowledge from the\npast Loebner Prize winner - ALICE, frequent asked questions, and a content\noffered by Universiti Teknikal Malaysia Melaka (UTeM). The evaluation of\nMOOC-bot based on the past competition questions from Chatterbox Challenge\n(CBC) and Loebner Prize has shown that it was able to provide correct answers\nmost of the time during the test and demonstrated the capability to prolong the\nconversation. The advantages of MOOC-bot such as able to provide 24-hour\nservice that can serve different time zones, able to have knowledge in multiple\ndomains, and can be shared by multiple sites simultaneously have outweighed its\nexisting limitations.\n", "versions": [{"version": "v1", "created": "Tue, 26 Jan 2016 15:23:29 GMT"}], "update_date": "2016-01-27", "authors_parsed": [["Lim", "Ser Ling", ""], ["Goh", "Ong Sing", ""]]}, {"id": "1601.07224", "submitter": "Yura Perov N", "authors": "Yura N Perov", "title": "Bachelor's thesis on generative probabilistic programming (in Russian\n  language, June 2014)", "comments": "49 pages, in Russian", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This Bachelor's thesis, written in Russian, is devoted to a relatively new\ndirection in the field of machine learning and artificial intelligence, namely\nprobabilistic programming. The thesis gives a brief overview to the already\nexisting probabilistic programming languages: Church, Venture, and Anglican. It\nalso describes the results of the first experiments on the automatic induction\nof probabilistic programs. The thesis was submitted, in June 2014, in partial\nfulfilment of the requirements for the degree of Bachelor of Science in\nMathematics in the Department of Mathematics and Computer Science, Siberian\nFederal University, Krasnoyarsk, Russia. The work, which is described in this\nthesis, has been performing in 2012-2014 in the Massachusetts Institute of\nTechnology and in the University of Oxford by the colleagues of the author and\nby himself.\n", "versions": [{"version": "v1", "created": "Tue, 26 Jan 2016 23:31:05 GMT"}], "update_date": "2016-01-28", "authors_parsed": [["Perov", "Yura N", ""]]}, {"id": "1601.07252", "submitter": "Anshul Gupta", "authors": "Anshul Gupta, Ricardo Gutierrez-Osuna, Matthew Christy, Richard\n  Furuta, Laura Mandell", "title": "Font Identification in Historical Documents Using Active Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.DL stat.AP stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Identifying the type of font (e.g., Roman, Blackletter) used in historical\ndocuments can help optical character recognition (OCR) systems produce more\naccurate text transcriptions. Towards this end, we present an active-learning\nstrategy that can significantly reduce the number of labeled samples needed to\ntrain a font classifier. Our approach extracts image-based features that\nexploit geometric differences between fonts at the word level, and combines\nthem into a bag-of-word representation for each page in a document. We evaluate\nsix sampling strategies based on uncertainty, dissimilarity and diversity\ncriteria, and test them on a database containing over 3,000 historical\ndocuments with Blackletter, Roman and Mixed fonts. Our results show that a\ncombination of uncertainty and diversity achieves the highest predictive\naccuracy (89% of test cases correctly classified) while requiring only a small\nfraction of the data (17%) to be labeled. We discuss the implications of this\nresult for mass digitization projects of historical documents.\n", "versions": [{"version": "v1", "created": "Wed, 27 Jan 2016 03:24:05 GMT"}], "update_date": "2016-01-28", "authors_parsed": [["Gupta", "Anshul", ""], ["Gutierrez-Osuna", "Ricardo", ""], ["Christy", "Matthew", ""], ["Furuta", "Richard", ""], ["Mandell", "Laura", ""]]}, {"id": "1601.07358", "submitter": "Jens Clausen", "authors": "Jens Clausen, Hans J. Briegel", "title": "Quantum machine learning with glow for episodic tasks and decision games", "comments": "20 pages, 14 figures", "journal-ref": "Phys. Rev. A 97, 022303 (2018)", "doi": "10.1103/PhysRevA.97.022303", "report-no": null, "categories": "quant-ph cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a general class of models, where a reinforcement learning (RL)\nagent learns from cyclic interactions with an external environment via\nclassical signals. Perceptual inputs are encoded as quantum states, which are\nsubsequently transformed by a quantum channel representing the agent's memory,\nwhile the outcomes of measurements performed at the channel's output determine\nthe agent's actions. The learning takes place via stepwise modifications of the\nchannel properties. They are described by an update rule that is inspired by\nthe projective simulation (PS) model and equipped with a glow mechanism that\nallows for a backpropagation of policy changes, analogous to the eligibility\ntraces in RL and edge glow in PS. In this way, the model combines features of\nPS with the ability for generalization, offered by its physical embodiment as a\nquantum system. We apply the agent to various setups of an invasion game and a\ngrid world, which serve as elementary model tasks allowing a direct comparison\nwith a basic classical PS agent.\n", "versions": [{"version": "v1", "created": "Wed, 27 Jan 2016 13:31:38 GMT"}], "update_date": "2018-02-14", "authors_parsed": [["Clausen", "Jens", ""], ["Briegel", "Hans J.", ""]]}, {"id": "1601.07409", "submitter": "Chi Mai Nguyen", "authors": "Chi Mai Nguyen, Roberto Sebastiani, Paolo Giorgini, and John\n  Mylopoulos", "title": "Multi-Object Reasoning with Constrained Goal Models", "comments": "52 pages (with appendices). Under journal submission", "journal-ref": null, "doi": "10.1007/s00766-016-0263-5", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Goal models have been widely used in Computer Science to represent software\nrequirements, business objectives, and design qualities. Existing goal\nmodelling techniques, however, have shown limitations of expressiveness and/or\ntractability in coping with complex real-world problems. In this work, we\nexploit advances in automated reasoning technologies, notably Satisfiability\nand Optimization Modulo Theories (SMT/OMT), and we propose and formalize: (i)\nan extended modelling language for goals, namely the Constrained Goal Model\n(CGM), which makes explicit the notion of goal refinement and of domain\nassumption, allows for expressing preferences between goals and refinements,\nand allows for associating numerical attributes to goals and refinements for\ndefining constraints and optimization goals over multiple objective functions,\nrefinements and their numerical attributes; (ii) a novel set of automated\nreasoning functionalities over CGMs, allowing for automatically generating\nsuitable refinements of input CGMs, under user-specified assumptions and\nconstraints, that also maximize preferences and optimize given objective\nfunctions. We have implemented these modelling and reasoning functionalities in\na tool, named CGM-Tool, using the OMT solver OptiMathSAT as automated reasoning\nbackend. Moreover, we have conducted an experimental evaluation on large CGMs\nto support the claim that our proposal scales well for goal models with\nthousands of elements.\n", "versions": [{"version": "v1", "created": "Wed, 27 Jan 2016 15:36:30 GMT"}, {"version": "v2", "created": "Fri, 25 Nov 2016 18:03:54 GMT"}], "update_date": "2016-12-09", "authors_parsed": [["Nguyen", "Chi Mai", ""], ["Sebastiani", "Roberto", ""], ["Giorgini", "Paolo", ""], ["Mylopoulos", "John", ""]]}, {"id": "1601.07446", "submitter": "Christian Napoli", "authors": "Marcin Wozniak, Dawid Polap, Grzegorz Borowik, Christian Napoli", "title": "A First Attempt to Cloud-Based User Verification in Distributed System", "comments": "Final version published on: Asia-Pacific Conference on Computer Aided\n  System Engineering (APCASE), pp. 226-231 (2015)", "journal-ref": "Asia-Pacific Conference on Computer Aided System Engineering\n  (APCASE), pp. 226-231 (2015)", "doi": "10.1109/APCASE.2015.47", "report-no": null, "categories": "cs.NE cs.AI cs.CR cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, the idea of client verification in distributed systems is\npresented. The proposed solution presents a sample system where client\nverification through cloud resources using input signature is discussed. For\ndifferent signatures the proposed method has been examined. Research results\nare presented and discussed to show potential advantages.\n", "versions": [{"version": "v1", "created": "Wed, 27 Jan 2016 16:54:51 GMT"}], "update_date": "2016-01-28", "authors_parsed": [["Wozniak", "Marcin", ""], ["Polap", "Dawid", ""], ["Borowik", "Grzegorz", ""], ["Napoli", "Christian", ""]]}, {"id": "1601.07483", "submitter": "Shashank Shekhar", "authors": "Shashank Shekhar and Deepak Khemani", "title": "Learning and Tuning Meta-heuristics in Plan Space Planning", "comments": "AAAI format, (9 pages), (1 figure), (4 tables)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In recent years, the planning community has observed that techniques for\nlearning heuristic functions have yielded improvements in performance. One\napproach is to use offline learning to learn predictive models from existing\nheuristics in a domain dependent manner. These learned models are deployed as\nnew heuristic functions. The learned models can in turn be tuned online using a\ndomain independent error correction approach to further enhance their\ninformativeness. The online tuning approach is domain independent but instance\nspecific, and contributes to improved performance for individual instances as\nplanning proceeds. Consequently it is more effective in larger problems.\n  In this paper, we mention two approaches applicable in Partial Order Causal\nLink (POCL) Planning that is also known as Plan Space Planning. First, we\nendeavor to enhance the performance of a POCL planner by giving an algorithm\nfor supervised learning. Second, we then discuss an online error minimization\napproach in POCL framework to minimize the step-error associated with the\noffline learned models thus enhancing their informativeness. Our evaluation\nshows that the learning approaches scale up the performance of the planner over\nstandard benchmarks, specially for larger problems.\n", "versions": [{"version": "v1", "created": "Wed, 27 Jan 2016 18:23:24 GMT"}, {"version": "v2", "created": "Thu, 28 Jan 2016 09:26:10 GMT"}, {"version": "v3", "created": "Sun, 24 Apr 2016 15:03:37 GMT"}], "update_date": "2016-04-26", "authors_parsed": [["Shekhar", "Shashank", ""], ["Khemani", "Deepak", ""]]}, {"id": "1601.07596", "submitter": "Francisco Chicano", "authors": "Francisco Chicano, Darrell Whitley and Renato Tinos", "title": "Efficient Hill-Climber for Multi-Objective Pseudo-Boolean Optimization", "comments": "Paper accepted for publication in the 16th European Conference on\n  Evolutionary Computation for Combinatorial Optimisation (EvoCOP 2016)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Local search algorithms and iterated local search algorithms are a basic\ntechnique. Local search can be a stand along search methods, but it can also be\nhybridized with evolutionary algorithms. Recently, it has been shown that it is\npossible to identify improving moves in Hamming neighborhoods for k-bounded\npseudo-Boolean optimization problems in constant time. This means that local\nsearch does not need to enumerate neighborhoods to find improving moves. It\nalso means that evolutionary algorithms do not need to use random mutation as a\noperator, except perhaps as a way to escape local optima. In this paper, we\nshow how improving moves can be identified in constant time for multiobjective\nproblems that are expressed as k-bounded pseudo-Boolean functions. In\nparticular, multiobjective forms of NK Landscapes and Mk Landscapes are\nconsidered.\n", "versions": [{"version": "v1", "created": "Wed, 27 Jan 2016 23:35:05 GMT"}], "update_date": "2016-01-29", "authors_parsed": [["Chicano", "Francisco", ""], ["Whitley", "Darrell", ""], ["Tinos", "Renato", ""]]}, {"id": "1601.07929", "submitter": "Martin Plajner", "authors": "Martin Plajner and Ji\\v{r}\\'i Vomlel", "title": "Probabilistic Models for Computerized Adaptive Testing: Experiments", "comments": "9 pages, v2: language corrections", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper follows previous research we have already performed in the area of\nBayesian networks models for CAT. We present models using Item Response Theory\n(IRT - standard CAT method), Bayesian networks, and neural networks. We\nconducted simulated CAT tests on empirical data. Results of these tests are\npresented for each model separately and compared.\n", "versions": [{"version": "v1", "created": "Thu, 28 Jan 2016 22:03:32 GMT"}, {"version": "v2", "created": "Mon, 1 Feb 2016 06:36:09 GMT"}], "update_date": "2016-02-02", "authors_parsed": [["Plajner", "Martin", ""], ["Vomlel", "Ji\u0159\u00ed", ""]]}]