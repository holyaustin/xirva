[{"id": "1008.0273", "submitter": "Jean Dezert", "authors": "Jean Dezert (ONERA), Florentin Smarandache (E3I2)", "title": "Threat assessment of a possible Vehicle-Born Improvised Explosive Device\n  using DSmT", "comments": "26 pages", "journal-ref": "Fusion 2010, Edinburgh : United Kingdom (2010)", "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents the solution about the threat of a VBIED (Vehicle-Born\nImprovised Explosive Device) obtained with the DSmT (Dezert-Smarandache\nTheory). This problem has been proposed recently to the authors by Simon\nMaskell and John Lavery as a typical illustrative example to try to compare the\ndifferent approaches for dealing with uncertainty for decision-making support.\nThe purpose of this paper is to show in details how a solid justified solution\ncan be obtained from DSmT approach and its fusion rules thanks to a proper\nmodeling of the belief functions involved in this problem.\n", "versions": [{"version": "v1", "created": "Mon, 2 Aug 2010 10:18:24 GMT"}], "update_date": "2010-08-03", "authors_parsed": [["Dezert", "Jean", "", "ONERA"], ["Smarandache", "Florentin", "", "E3I2"]]}, {"id": "1008.0322", "submitter": "Tamir Tuller", "authors": "Tamir Tuller and Elchanan Mossel", "title": "Co-evolution is Incompatible with the Markov Assumption in Phylogenetics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.PE cs.AI cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Markov models are extensively used in the analysis of molecular evolution. A\nrecent line of research suggests that pairs of proteins with functional and\nphysical interactions co-evolve with each other. Here, by analyzing hundreds of\northologous sets of three fungi and their co-evolutionary relations, we\ndemonstrate that co-evolutionary assumption may violate the Markov assumption.\nOur results encourage developing alternative probabilistic models for the cases\nof extreme co-evolution.\n", "versions": [{"version": "v1", "created": "Mon, 2 Aug 2010 15:03:37 GMT"}, {"version": "v2", "created": "Wed, 4 Aug 2010 11:37:46 GMT"}], "update_date": "2010-08-05", "authors_parsed": [["Tuller", "Tamir", ""], ["Mossel", "Elchanan", ""]]}, {"id": "1008.0659", "submitter": "Thanasis Balafoutis", "authors": "Thanasis Balafoutis and Kostas Stergiou", "title": "Evaluating and Improving Modern Variable and Revision Ordering\n  Strategies in CSPs", "comments": "To appear in the Journal Fundamenta Informaticae (FI) IOS Press", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A key factor that can dramatically reduce the search space during constraint\nsolving is the criterion under which the variable to be instantiated next is\nselected. For this purpose numerous heuristics have been proposed. Some of the\nbest of such heuristics exploit information about failures gathered throughout\nsearch and recorded in the form of constraint weights, while others measure the\nimportance of variable assignments in reducing the search space. In this work\nwe experimentally evaluate the most recent and powerful variable ordering\nheuristics, and new variants of them, over a wide range of benchmarks. Results\ndemonstrate that heuristics based on failures are in general more efficient.\nBased on this, we then derive new revision ordering heuristics that exploit\nrecorded failures to efficiently order the propagation list when arc\nconsistency is maintained during search. Interestingly, in addition to reducing\nthe number of constraint checks and list operations, these heuristics are also\nable to cut down the size of the explored search tree.\n", "versions": [{"version": "v1", "created": "Tue, 3 Aug 2010 21:09:43 GMT"}, {"version": "v2", "created": "Sat, 7 Aug 2010 09:48:42 GMT"}], "update_date": "2010-08-10", "authors_parsed": [["Balafoutis", "Thanasis", ""], ["Stergiou", "Kostas", ""]]}, {"id": "1008.0660", "submitter": "Thanasis Balafoutis", "authors": "Thanasis Balafoutis and Kostas Stergiou", "title": "Adaptive Branching for Constraint Satisfaction Problems", "comments": "To appear in Proceedings of the 19th European Conference on\n  Artificial Intelligence - ECAI 2010", "journal-ref": "In Proceedings of the 19th European Conference on Artificial\n  Intelligence - ECAI 2010", "doi": "10.3233/978-1-60750-606-5-855", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The two standard branching schemes for CSPs are d-way and 2-way branching.\nAlthough it has been shown that in theory the latter can be exponentially more\neffective than the former, there is a lack of empirical evidence showing such\ndifferences. To investigate this, we initially make an experimental comparison\nof the two branching schemes over a wide range of benchmarks. Experimental\nresults verify the theoretical gap between d-way and 2-way branching as we move\nfrom a simple variable ordering heuristic like dom to more sophisticated ones\nlike dom/ddeg. However, perhaps surprisingly, experiments also show that when\nstate-of-the-art variable ordering heuristics like dom/wdeg are used then d-way\ncan be clearly more efficient than 2-way branching in many cases. Motivated by\nthis observation, we develop two generic heuristics that can be applied at\ncertain points during search to decide whether 2-way branching or a restricted\nversion of 2-way branching, which is close to d-way branching, will be\nfollowed. The application of these heuristics results in an adaptive branching\nscheme. Experiments with instantiations of the two generic heuristics confirm\nthat search with adaptive branching outperforms search with a fixed branching\nscheme on a wide range of problems.\n", "versions": [{"version": "v1", "created": "Tue, 3 Aug 2010 21:10:15 GMT"}], "update_date": "2010-09-06", "authors_parsed": [["Balafoutis", "Thanasis", ""], ["Stergiou", "Kostas", ""]]}, {"id": "1008.0775", "submitter": "Armen Bagdasaryan", "authors": "Armen Bagdasaryan", "title": "Systems Theoretic Techniques for Modeling, Control, and Decision Support\n  in Complex Dynamic Systems", "comments": "58 pages, 24 figures, 1 table; a book chapter published by Bentham\n  Science", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SY cs.AI cs.MA math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We discuss the problems of modeling, control, and decision support in complex\ndynamic systems from a general system theoretic point of view. The main\ncharacteristics of complex systems and of system approach to complex system\nstudy are considered. We provide an overview and analysis of known existing\nparadigms and methods of mathematical modeling and simulation of complex\nsystems, which support the processes of control and decision making. Then we\ncontinue with the general dynamic modeling and simulation technique for complex\nhierarchical systems functioning in control loop. Architectural and structural\nmodels of computer information system intended for simulation and decision\nsupport in complex systems are presented.\n", "versions": [{"version": "v1", "created": "Wed, 4 Aug 2010 13:29:57 GMT"}, {"version": "v2", "created": "Wed, 25 Dec 2013 15:31:39 GMT"}], "update_date": "2013-12-30", "authors_parsed": [["Bagdasaryan", "Armen", ""]]}, {"id": "1008.0823", "submitter": "Adrian Paschke", "authors": "Adrian Paschke, Alexander Kozlenkov, Harold Boley", "title": "A Homogeneous Reaction Rule Language for Complex Event Processing", "comments": "In Proc. 2nd International Workshop on Event Drive Architecture and\n  Event Processing Systems (EDA-PS 2007) at VLDB 2007", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Event-driven automation of reactive functionalities for complex event\nprocessing is an urgent need in today's distributed service-oriented\narchitectures and Web-based event-driven environments. An important problem to\nbe addressed is how to correctly and efficiently capture and process the\nevent-based behavioral, reactive logic embodied in reaction rules, and\ncombining this with other conditional decision logic embodied, e.g., in\nderivation rules. This paper elaborates a homogeneous integration approach that\ncombines derivation rules, reaction rules and other rule types such as\nintegrity constraints into the general framework of logic programming, the\nindustrial-strength version of declarative programming. We describe syntax and\nsemantics of the language, implement a distributed web-based middleware using\nenterprise service technologies and illustrate its adequacy in terms of\nexpressiveness, efficiency and scalability through examples extracted from\nindustrial use cases. The developed reaction rule language provides expressive\nfeatures such as modular ID-based updates with support for external imports and\nself-updates of the intensional and extensional knowledge bases, transactions\nincluding integrity testing and roll-backs of update transition paths. It also\nsupports distributed complex event processing, event messaging and event\nquerying via efficient and scalable enterprise middleware technologies and\nevent/action reasoning based on an event/action algebra implemented by an\ninterval-based event calculus variant as a logic inference formalism.\n", "versions": [{"version": "v1", "created": "Wed, 4 Aug 2010 17:05:33 GMT"}], "update_date": "2010-08-05", "authors_parsed": [["Paschke", "Adrian", ""], ["Kozlenkov", "Alexander", ""], ["Boley", "Harold", ""]]}, {"id": "1008.0838", "submitter": "Omar Khazamov", "authors": "Isa Magomedov, Omar Khazamov", "title": "Associative control processor with a rigid structure", "comments": "16 pages, 7 figures", "journal-ref": "DSTU Journal,2009,p. 445-453", "doi": null, "report-no": null, "categories": "cs.AR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The approach of applying associative processor for decision making problem\nwas proposed. It focuses on hardware implementations of fuzzy processing\nsystems, associativity as effective management basis of fuzzy processor. The\nstructural approach is being developed resulting in a quite simple and compact\nparallel associative memory unit (PAMU). The memory cost and speed comparison\nof processors with rigid and soft-variable structure is given. Also the example\nPAMU flashing is considered.\n", "versions": [{"version": "v1", "created": "Wed, 4 Aug 2010 18:35:25 GMT"}], "update_date": "2010-08-05", "authors_parsed": [["Magomedov", "Isa", ""], ["Khazamov", "Omar", ""]]}, {"id": "1008.1309", "submitter": "Osman Bineev", "authors": "Osman Bineev", "title": "Towards arrow-theoretic semantics of ontologies: conceptories", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI math.CT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In context of efforts of composing category-theoretic and logical methods in\nthe area of knowledge representation we propose the notion of conceptory. We\nconsider intersection/union and other constructions in conceptories as\nexpressive alternative to category-theoretic (co)limits and show they have\nfeatures similar to (pro-, in-)jections. Then we briefly discuss approaches to\ndevelopment of formal systems built on the base of conceptories and describe\npossible application of such system to the specific ontology.\n", "versions": [{"version": "v1", "created": "Sat, 7 Aug 2010 06:56:14 GMT"}], "update_date": "2010-08-10", "authors_parsed": [["Bineev", "Osman", ""]]}, {"id": "1008.1328", "submitter": "Zeeshan Ahmed Mr.", "authors": "Zeeshan Ahmed and Detlef Gerhard", "title": "Semantic Oriented Agent based Approach towards Engineering Data\n  Management, Web Information Retrieval and User System Communication Problems", "comments": "In the proceedings of 3rd International Conference for Internet\n  Technology and Secured Transactions, Dublin Institute of Technology, ICITST\n  08, June 23-28, pp 19-22 Dublin Ireland, 2008", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The four intensive problems to the software rose by the software industry\n.i.e., User System Communication / Human Machine Interface, Meta Data\nextraction, Information processing & management and Data representation are\ndiscussed in this research paper. To contribute in the field we have proposed\nand described an intelligent semantic oriented agent based search engine\nincluding the concepts of intelligent graphical user interface, natural\nlanguage based information processing, data management and data reconstruction\nfor the final user end information representation.\n", "versions": [{"version": "v1", "created": "Sat, 7 Aug 2010 12:08:43 GMT"}], "update_date": "2010-08-10", "authors_parsed": [["Ahmed", "Zeeshan", ""], ["Gerhard", "Detlef", ""]]}, {"id": "1008.1333", "submitter": "Zeeshan Ahmed Mr.", "authors": "Zeeshan Ahmed and Detlef Gerhard", "title": "An Agent based Approach towards Metadata Extraction, Modelling and\n  Information Retrieval over the Web", "comments": "In the proceedings of First International Workshop on Cultural\n  Heritage on the Semantic Web in conjunction with the 6th International\n  Semantic Web Conference and the 2nd Asian Semantic Web Conference 2007, (ISWC\n  + ASWC 2007), P 117, 12-15 November 2007", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Web development is a challenging research area for its creativity and\ncomplexity. The existing raised key challenge in web technology technologic\ndevelopment is the presentation of data in machine read and process able format\nto take advantage in knowledge based information extraction and maintenance.\nCurrently it is not possible to search and extract optimized results using full\ntext queries because there is no such mechanism exists which can fully extract\nthe semantic from full text queries and then look for particular knowledge\nbased information.\n", "versions": [{"version": "v1", "created": "Sat, 7 Aug 2010 12:29:02 GMT"}], "update_date": "2010-08-10", "authors_parsed": [["Ahmed", "Zeeshan", ""], ["Gerhard", "Detlef", ""]]}, {"id": "1008.1484", "submitter": "Ping Zhu", "authors": "Ping Zhu and Qiaoyan Wen", "title": "A note on communicating between information systems based on including\n  degrees", "comments": "4 pages", "journal-ref": "International Journal of General Systems, 40(8): 837-840, 2011", "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In order to study the communication between information systems, Gong and\nXiao [Z. Gong and Z. Xiao, Communicating between information systems based on\nincluding degrees, International Journal of General Systems 39 (2010) 189--206]\nproposed the concept of general relation mappings based on including degrees.\nSome properties and the extension for fuzzy information systems of the general\nrelation mappings have been investigated there. In this paper, we point out by\ncounterexamples that several assertions (Lemma 3.1, Lemma 3.2, Theorem 4.1, and\nTheorem 4.3) in the aforementioned work are not true in general.\n", "versions": [{"version": "v1", "created": "Mon, 9 Aug 2010 10:54:54 GMT"}], "update_date": "2011-11-08", "authors_parsed": [["Zhu", "Ping", ""], ["Wen", "Qiaoyan", ""]]}, {"id": "1008.1566", "submitter": "Zhemin Zhu", "authors": "Zhemin Zhu, Djoerd Hiemstra, Peter Apers, Andreas Wombacher", "title": "Separate Training for Conditional Random Fields Using Co-occurrence Rate\n  Factorization", "comments": "10pages", "journal-ref": null, "doi": null, "report-no": "TR-CTIT-12-29", "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The standard training method of Conditional Random Fields (CRFs) is very slow\nfor large-scale applications. As an alternative, piecewise training divides the\nfull graph into pieces, trains them independently, and combines the learned\nweights at test time. In this paper, we present \\emph{separate} training for\nundirected models based on the novel Co-occurrence Rate Factorization (CR-F).\nSeparate training is a local training method. In contrast to MEMMs, separate\ntraining is unaffected by the label bias problem. Experiments show that\nseparate training (i) is unaffected by the label bias problem; (ii) reduces the\ntraining time from weeks to seconds; and (iii) obtains competitive results to\nthe standard and piecewise training on linear-chain CRFs.\n", "versions": [{"version": "v1", "created": "Mon, 9 Aug 2010 19:02:04 GMT"}, {"version": "v2", "created": "Tue, 10 Aug 2010 16:42:50 GMT"}, {"version": "v3", "created": "Tue, 28 Sep 2010 13:58:29 GMT"}, {"version": "v4", "created": "Sun, 1 May 2011 16:40:05 GMT"}, {"version": "v5", "created": "Tue, 4 Dec 2012 09:50:03 GMT"}], "update_date": "2012-12-05", "authors_parsed": [["Zhu", "Zhemin", ""], ["Hiemstra", "Djoerd", ""], ["Apers", "Peter", ""], ["Wombacher", "Andreas", ""]]}, {"id": "1008.1643", "submitter": "Ninan Sajeeth Philip", "authors": "Ninan Sajeeth Philip", "title": "A Learning Algorithm based on High School Teaching Wisdom", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  A learning algorithm based on primary school teaching and learning is\npresented. The methodology is to continuously evaluate a student and to give\nthem training on the examples for which they repeatedly fail, until, they can\ncorrectly answer all types of questions. This incremental learning procedure\nproduces better learning curves by demanding the student to optimally dedicate\ntheir learning time on the failed examples. When used in machine learning, the\nalgorithm is found to train a machine on a data with maximum variance in the\nfeature space so that the generalization ability of the network improves. The\nalgorithm has interesting applications in data mining, model evaluations and\nrare objects discovery.\n", "versions": [{"version": "v1", "created": "Tue, 10 Aug 2010 07:44:08 GMT"}, {"version": "v2", "created": "Sun, 12 Dec 2010 06:13:31 GMT"}], "update_date": "2010-12-14", "authors_parsed": [["Philip", "Ninan Sajeeth", ""]]}, {"id": "1008.1710", "submitter": "Torsten Schaub", "authors": "Manuel Hermenegildo and Torsten Schaub", "title": "Introduction to the 26th International Conference on Logic Programming\n  Special Issue", "comments": "6 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This is the preface to the 26th International Conference on Logic Programming\nSpecial Issue\n", "versions": [{"version": "v1", "created": "Tue, 10 Aug 2010 13:27:33 GMT"}], "update_date": "2010-08-11", "authors_parsed": [["Hermenegildo", "Manuel", ""], ["Schaub", "Torsten", ""]]}, {"id": "1008.1723", "submitter": "Zeeshan Ahmed Mr.", "authors": "Zeeshan Ahmed and Detlef Gerhard", "title": "Role of Ontology in Semantic Web Development", "comments": "In the proceedings of First International Workshop on Cultural\n  Heritage on the Semantic Web in conjunction with the 6th International\n  Semantic Web Conference and the 2nd Asian Semantic Web Conference 2007, (ISWC\n  + ASWC 2007), P 119, 12-15 November 2007", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  World Wide Web (WWW) is the most popular global information sharing and\ncommunication system consisting of three standards .i.e., Uniform Resource\nIdentifier (URL), Hypertext Transfer Protocol (HTTP) and Hypertext Mark-up\nLanguage (HTML). Information is provided in text, image, audio and video\nformats over the web by using HTML which is considered to be unconventional in\ndefining and formalizing the meaning of the context...\n", "versions": [{"version": "v1", "created": "Sat, 7 Aug 2010 12:32:22 GMT"}], "update_date": "2010-08-11", "authors_parsed": [["Ahmed", "Zeeshan", ""], ["Gerhard", "Detlef", ""]]}, {"id": "1008.2028", "submitter": "Daphne Koller", "authors": "Suchi Saria, Daphne Koller and Anna Penn", "title": "Discovering shared and individual latent structure in multiple time\n  series", "comments": "Additional supplementary section in tex file", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a nonparametric Bayesian method for exploratory data\nanalysis and feature construction in continuous time series. Our method focuses\non understanding shared features in a set of time series that exhibit\nsignificant individual variability. Our method builds on the framework of\nlatent Diricihlet allocation (LDA) and its extension to hierarchical Dirichlet\nprocesses, which allows us to characterize each series as switching between\nlatent ``topics'', where each topic is characterized as a distribution over\n``words'' that specify the series dynamics. However, unlike standard\napplications of LDA, we discover the words as we learn the model. We apply this\nmodel to the task of tracking the physiological signals of premature infants;\nour model obtains clinically significant insights as well as useful features\nfor supervised learning tasks.\n", "versions": [{"version": "v1", "created": "Thu, 12 Aug 2010 00:41:23 GMT"}], "update_date": "2010-08-13", "authors_parsed": [["Saria", "Suchi", ""], ["Koller", "Daphne", ""], ["Penn", "Anna", ""]]}, {"id": "1008.2121", "submitter": "Johan Wittocx", "authors": "Johan Wittocx, Marc Denecker, Maurice Bruynooghe", "title": "Constraint Propagation for First-Order Logic and Inductive Definitions", "comments": "43 pages, 1 figure submitted to ACM Transactions on Computational\n  Logic", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Constraint propagation is one of the basic forms of inference in many\nlogic-based reasoning systems. In this paper, we investigate constraint\npropagation for first-order logic (FO), a suitable language to express a wide\nvariety of constraints. We present an algorithm with polynomial-time data\ncomplexity for constraint propagation in the context of an FO theory and a\nfinite structure. We show that constraint propagation in this manner can be\nrepresented by a datalog program and that the algorithm can be executed\nsymbolically, i.e., independently of a structure. Next, we extend the algorithm\nto FO(ID), the extension of FO with inductive definitions. Finally, we discuss\nseveral applications.\n", "versions": [{"version": "v1", "created": "Thu, 12 Aug 2010 14:40:04 GMT"}, {"version": "v2", "created": "Fri, 8 Jul 2011 14:22:16 GMT"}], "update_date": "2011-07-11", "authors_parsed": [["Wittocx", "Johan", ""], ["Denecker", "Marc", ""], ["Bruynooghe", "Maurice", ""]]}, {"id": "1008.2186", "submitter": "Julien Leblay", "authors": "Fran\\c{c}ois Goasdou\\'e (LRI), Konstantinos Karanasos (INRIA Saclay -\n  Ile de France), Julien Leblay (INRIA Saclay - Ile de France), Ioana Manolescu\n  (LRI, INRIA Saclay - Ile de France)", "title": "RDFViewS: A Storage Tuning Wizard for RDF Applications", "comments": null, "journal-ref": "ACM International Conference on Information and Knowledge\n  Management, Toronto : Canada (2010)", "doi": null, "report-no": null, "categories": "cs.DB cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, the significant growth of RDF data used in numerous\napplications has made its efficient and scalable manipulation an important\nissue. In this paper, we present RDFViewS, a system capable of choosing the\nmost suitable views to materialize, in order to minimize the query response\ntime for a specific SPARQL query workload, while taking into account the view\nmaintenance cost and storage space constraints. Our system employs practical\nalgorithms and heuristics to navigate through the search space of potential\nview configurations, and exploits the possibly available semantic information -\nexpressed via an RDF Schema - to ensure the completeness of the query\nevaluation.\n", "versions": [{"version": "v1", "created": "Thu, 12 Aug 2010 18:55:15 GMT"}], "update_date": "2010-08-13", "authors_parsed": [["Goasdou\u00e9", "Fran\u00e7ois", "", "LRI"], ["Karanasos", "Konstantinos", "", "INRIA Saclay -\n  Ile de France"], ["Leblay", "Julien", "", "INRIA Saclay - Ile de France"], ["Manolescu", "Ioana", "", "LRI, INRIA Saclay - Ile de France"]]}, {"id": "1008.2277", "submitter": "Jose M. Pe\\~na", "authors": "Jose M. Pe\\~na", "title": "Faithfulness in Chain Graphs: The Gaussian Case", "comments": null, "journal-ref": "Proceedings of the 14th International Conference on Artificial\n  Intelligence and Statistics (AISTATS 2011), 588-599", "doi": null, "report-no": null, "categories": "stat.ML cs.AI math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper deals with chain graphs under the classic\nLauritzen-Wermuth-Frydenberg interpretation. We prove that the regular Gaussian\ndistributions that factorize with respect to a chain graph $G$ with $d$\nparameters have positive Lebesgue measure with respect to $\\mathbb{R}^d$,\nwhereas those that factorize with respect to $G$ but are not faithful to it\nhave zero Lebesgue measure with respect to $\\mathbb{R}^d$. This means that, in\nthe measure-theoretic sense described, almost all the regular Gaussian\ndistributions that factorize with respect to $G$ are faithful to it.\n", "versions": [{"version": "v1", "created": "Fri, 13 Aug 2010 10:03:48 GMT"}], "update_date": "2012-06-27", "authors_parsed": [["Pe\u00f1a", "Jose M.", ""]]}, {"id": "1008.2514", "submitter": "Gert De Cooman", "authors": "Gert de Cooman, Filip Hermans, Alessandro Antonucci and Marco Zaffalon", "title": "Epistemic irrelevance in credal nets: the case of imprecise Markov trees", "comments": "29 pages, 5 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI math.PR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We focus on credal nets, which are graphical models that generalise Bayesian\nnets to imprecise probability. We replace the notion of strong independence\ncommonly used in credal nets with the weaker notion of epistemic irrelevance,\nwhich is arguably more suited for a behavioural theory of probability. Focusing\non directed trees, we show how to combine the given local uncertainty models in\nthe nodes of the graph into a global model, and we use this to construct and\njustify an exact message-passing algorithm that computes updated beliefs for a\nvariable in the tree. The algorithm, which is linear in the number of nodes, is\nformulated entirely in terms of coherent lower previsions, and is shown to\nsatisfy a number of rationality requirements. We supply examples of the\nalgorithm's operation, and report an application to on-line character\nrecognition that illustrates the advantages of our approach for prediction. We\ncomment on the perspectives, opened by the availability, for the first time, of\na truly efficient algorithm based on epistemic irrelevance.\n", "versions": [{"version": "v1", "created": "Sun, 15 Aug 2010 12:26:24 GMT"}], "update_date": "2010-08-17", "authors_parsed": [["de Cooman", "Gert", ""], ["Hermans", "Filip", ""], ["Antonucci", "Alessandro", ""], ["Zaffalon", "Marco", ""]]}, {"id": "1008.2626", "submitter": "Jan Van den Bussche", "authors": "Eveline Hoekx and Jan Van den Bussche", "title": "Mining tree-query associations in graphs", "comments": "Full version of two earlier conference papers presented at KDD 2005\n  and ICDM 2006", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  New applications of data mining, such as in biology, bioinformatics, or\nsociology, are faced with large datasetsstructured as graphs. We introduce a\nnovel class of tree-shapedpatterns called tree queries, and present algorithms\nfor miningtree queries and tree-query associations in a large data graph. Novel\nabout our class of patterns is that they can containconstants, and can contain\nexistential nodes which are not counted when determining the number of\noccurrences of the patternin the data graph. Our algorithms have a number of\nprovableoptimality properties, which are based on the theory of conjunctive\ndatabase queries. We propose a practical, database-oriented implementation in\nSQL, and show that the approach works in practice through experiments on data\nabout food webs, protein interactions, and citation analysis.\n", "versions": [{"version": "v1", "created": "Mon, 16 Aug 2010 11:35:59 GMT"}], "update_date": "2010-08-17", "authors_parsed": [["Hoekx", "Eveline", ""], ["Bussche", "Jan Van den", ""]]}, {"id": "1008.2743", "submitter": "Gautam Pendse", "authors": "Gautam V. Pendse", "title": "PMOG: The projected mixture of Gaussians model with application to blind\n  source separation", "comments": "46 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We extend the mixtures of Gaussians (MOG) model to the projected mixture of\nGaussians (PMOG) model. In the PMOG model, we assume that q dimensional input\ndata points z_i are projected by a q dimensional vector w into 1-D variables\nu_i. The projected variables u_i are assumed to follow a 1-D MOG model. In the\nPMOG model, we maximize the likelihood of observing u_i to find both the model\nparameters for the 1-D MOG as well as the projection vector w. First, we derive\nan EM algorithm for estimating the PMOG model. Next, we show how the PMOG model\ncan be applied to the problem of blind source separation (BSS). In contrast to\nconventional BSS where an objective function based on an approximation to\ndifferential entropy is minimized, PMOG based BSS simply minimizes the\ndifferential entropy of projected sources by fitting a flexible MOG model in\nthe projected 1-D space while simultaneously optimizing the projection vector\nw. The advantage of PMOG over conventional BSS algorithms is the more flexible\nfitting of non-Gaussian source densities without assuming near-Gaussianity (as\nin conventional BSS) and still retaining computational feasibility.\n", "versions": [{"version": "v1", "created": "Mon, 16 Aug 2010 19:26:17 GMT"}], "update_date": "2010-08-17", "authors_parsed": [["Pendse", "Gautam V.", ""]]}, {"id": "1008.3282", "submitter": "Md. Saiful Islam", "authors": "Md. Saiful Islam, Shah Mostafa Khaled, Khalid Farhan, Md. Abdur Rahman\n  and Joy Rahman", "title": "Modeling Spammer Behavior: Na\\\"ive Bayes vs. Artificial Neural Networks", "comments": "4 pages, 1 figure, 3 tables", "journal-ref": "Proc. of IEEE ICIMT, Jeju Island, South Korea, December 16-18,\n  2009, pp. 52-55", "doi": null, "report-no": null, "categories": "cs.IR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Addressing the problem of spam emails in the Internet, this paper presents a\ncomparative study on Na\\\"ive Bayes and Artificial Neural Networks (ANN) based\nmodeling of spammer behavior. Keyword-based spam email filtering techniques\nfall short to model spammer behavior as the spammer constantly changes tactics\nto circumvent these filters. The evasive tactics that the spammer uses are\nthemselves patterns that can be modeled to combat spam. It has been observed\nthat both Na\\\"ive Bayes and ANN are best suitable for modeling spammer common\npatterns. Experimental results demonstrate that both of them achieve a\npromising detection rate of around 92%, which is considerably an improvement of\nperformance compared to the keyword-based contemporary filtering approaches.\n", "versions": [{"version": "v1", "created": "Thu, 19 Aug 2010 12:03:39 GMT"}], "update_date": "2010-08-20", "authors_parsed": [["Islam", "Md. Saiful", ""], ["Khaled", "Shah Mostafa", ""], ["Farhan", "Khalid", ""], ["Rahman", "Md. Abdur", ""], ["Rahman", "Joy", ""]]}, {"id": "1008.3314", "submitter": "Tijl De Bie", "authors": "Tijl De Bie", "title": "Maximum entropy models and subjective interestingness: an application to\n  tiles in binary databases", "comments": "43 pages, submitted", "journal-ref": null, "doi": null, "report-no": "University of Bristol Tech. Rep. 125861", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent research has highlighted the practical benefits of subjective\ninterestingness measures, which quantify the novelty or unexpectedness of a\npattern when contrasted with any prior information of the data miner\n(Silberschatz and Tuzhilin, 1995; Geng and Hamilton, 2006). A key challenge\nhere is the formalization of this prior information in a way that lends itself\nto the definition of an interestingness subjective measure that is both\nmeaningful and practical.\n  In this paper, we outline a general strategy of how this could be achieved,\nbefore working out the details for a use case that is important in its own\nright.\n  Our general strategy is based on considering prior information as constraints\non a probabilistic model representing the uncertainty about the data. More\nspecifically, we represent the prior information by the maximum entropy\n(MaxEnt) distribution subject to these constraints. We briefly outline various\nmeasures that could subsequently be used to contrast patterns with this MaxEnt\nmodel, thus quantifying their subjective interestingness.\n", "versions": [{"version": "v1", "created": "Thu, 19 Aug 2010 14:41:55 GMT"}], "update_date": "2010-08-20", "authors_parsed": [["De Bie", "Tijl", ""]]}, {"id": "1008.3829", "submitter": "Ilan Nehama", "authors": "Ilan Nehama", "title": "Approximate Judgement Aggregation", "comments": null, "journal-ref": null, "doi": "10.1007/s10472-013-9358-6", "report-no": null, "categories": "cs.GT cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we analyze judgement aggregation problems in which a group of\nagents independently votes on a set of complex propositions that has some\ninterdependency constraint between them(e.g., transitivity when describing\npreferences). We consider the issue of judgement aggregation from the\nperspective of approximation. That is, we generalize the previous results by\nstudying approximate judgement aggregation. We relax the main two constraints\nassumed in the current literature, Consistency and Independence and consider\nmechanisms that only approximately satisfy these constraints, that is, satisfy\nthem up to a small portion of the inputs. The main question we raise is whether\nthe relaxation of these notions significantly alters the class of satisfying\naggregation mechanisms. The recent works for preference aggregation of Kalai,\nMossel, and Keller fit into this framework. The main result of this paper is\nthat, as in the case of preference aggregation, in the case of a subclass of a\nnatural class of aggregation problems termed `truth-functional agendas', the\nset of satisfying aggregation mechanisms does not extend non-trivially when\nrelaxing the constraints. Our proof techniques involve Boolean Fourier\ntransform and analysis of voter influences for voting protocols. The question\nwe raise for Approximate Aggregation can be stated in terms of Property\nTesting. For instance, as a corollary from our result we get a generalization\nof the classic result for property testing of linearity of Boolean functions.\n  An updated version (RePEc:huj:dispap:dp574R) is available at\nhttp://www.ratio.huji.ac.il/dp_files/dp574R.pdf\n", "versions": [{"version": "v1", "created": "Mon, 23 Aug 2010 14:26:46 GMT"}, {"version": "v2", "created": "Fri, 8 Apr 2011 12:34:24 GMT"}, {"version": "v3", "created": "Tue, 22 Nov 2011 20:58:26 GMT"}], "update_date": "2013-06-20", "authors_parsed": [["Nehama", "Ilan", ""]]}, {"id": "1008.3879", "submitter": "Yves Moinard", "authors": "Yves Moinard (INRIA - IRISA)", "title": "A formalism for causal explanations with an Answer Set Programming\n  translation", "comments": null, "journal-ref": "4th International Conference on Knowledge Science, Engineering &\n  Management (KSEM 2010), Belfast : United Kingdom (2010)", "doi": "10.1007/978-3-642-15280-1_56", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We examine the practicality for a user of using Answer Set Programming (ASP)\nfor representing logical formalisms. Our example is a formalism aiming at\ncapturing causal explanations from causal information. We show the naturalness\nand relative efficiency of this translation job. We are interested in the ease\nfor writing an ASP program. Limitations of the earlier systems made that in\npractice, the ``declarative aspect'' was more theoretical than practical. We\nshow how recent improvements in working ASP systems facilitate the translation.\n", "versions": [{"version": "v1", "created": "Mon, 23 Aug 2010 18:38:23 GMT"}], "update_date": "2020-07-17", "authors_parsed": [["Moinard", "Yves", "", "INRIA - IRISA"]]}, {"id": "1008.4071", "submitter": "Stanislav Zivny", "authors": "Martin C. Cooper, Stanislav Zivny", "title": "Hybrid tractability of soft constraint problems", "comments": "A full version of a CP'10 paper, 26 pages", "journal-ref": "Artificial Intelligence 175(9-10) 1555-1569 (2011)", "doi": "10.1016/j.artint.2011.02.003", "report-no": null, "categories": "cs.AI cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The constraint satisfaction problem (CSP) is a central generic problem in\ncomputer science and artificial intelligence: it provides a common framework\nfor many theoretical problems as well as for many real-life applications. Soft\nconstraint problems are a generalisation of the CSP which allow the user to\nmodel optimisation problems. Considerable effort has been made in identifying\nproperties which ensure tractability in such problems. In this work, we\ninitiate the study of hybrid tractability of soft constraint problems; that is,\nproperties which guarantee tractability of the given soft constraint problem,\nbut which do not depend only on the underlying structure of the instance (such\nas being tree-structured) or only on the types of soft constraints in the\ninstance (such as submodularity). We present several novel hybrid classes of\nsoft constraint problems, which include a machine scheduling problem,\nconstraint problems of arbitrary arities with no overlapping nogoods, and the\nSoftAllDiff constraint with arbitrary unary soft constraints. An important tool\nin our investigation will be the notion of forbidden substructures.\n", "versions": [{"version": "v1", "created": "Tue, 24 Aug 2010 15:42:21 GMT"}], "update_date": "2011-04-25", "authors_parsed": [["Cooper", "Martin C.", ""], ["Zivny", "Stanislav", ""]]}, {"id": "1008.4249", "submitter": "Md. Saiful Islam", "authors": "Md. Saiful Islam, Abdullah Al Mahmud, Md. Rafiqul Islam", "title": "Machine Learning Approaches for Modeling Spammer Behavior", "comments": "12 pages, 3 figures, 5 tables, Submitted to AIRS 2010", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spam is commonly known as unsolicited or unwanted email messages in the\nInternet causing potential threat to Internet Security. Users spend a valuable\namount of time deleting spam emails. More importantly, ever increasing spam\nemails occupy server storage space and consume network bandwidth. Keyword-based\nspam email filtering strategies will eventually be less successful to model\nspammer behavior as the spammer constantly changes their tricks to circumvent\nthese filters. The evasive tactics that the spammer uses are patterns and these\npatterns can be modeled to combat spam. This paper investigates the\npossibilities of modeling spammer behavioral patterns by well-known\nclassification algorithms such as Na\\\"ive Bayesian classifier (Na\\\"ive Bayes),\nDecision Tree Induction (DTI) and Support Vector Machines (SVMs). Preliminary\nexperimental results demonstrate a promising detection rate of around 92%,\nwhich is considerably an enhancement of performance compared to similar spammer\nbehavior modeling research.\n", "versions": [{"version": "v1", "created": "Wed, 25 Aug 2010 10:36:40 GMT"}], "update_date": "2010-08-26", "authors_parsed": [["Islam", "Md. Saiful", ""], ["Mahmud", "Abdullah Al", ""], ["Islam", "Md. Rafiqul", ""]]}, {"id": "1008.4257", "submitter": "Nada Matta", "authors": "Nada Matta (UTT), Oswaldo Castillo (UTT)", "title": "Learning from Profession Knowledge: Application on Knitting", "comments": null, "journal-ref": "5th International Conference on Signal-Image Technology and\n  Internet based Systems, Marakesh : Morocco (2009)", "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge Management is a global process in companies. It includes all the\nprocesses that allow capitalization, sharing and evolution of the Knowledge\nCapital of the firm, generally recognized as a critical resource of the\norganization. Several approaches have been defined to capitalize knowledge but\nfew of them study how to learn from this knowledge. We present in this paper an\napproach that helps to enhance learning from profession knowledge in an\norganisation. We apply our approach on knitting industry.\n", "versions": [{"version": "v1", "created": "Wed, 25 Aug 2010 11:41:28 GMT"}], "update_date": "2010-08-26", "authors_parsed": [["Matta", "Nada", "", "UTT"], ["Castillo", "Oswaldo", "", "UTT"]]}, {"id": "1008.4268", "submitter": "Vijay Kumar Mago Dr", "authors": "Kawal Jeet, Vijay Kumar Mago, Bhanu Prasad and Rajinder Singh Minhas", "title": "An Influence Diagram-Based Approach for Estimating Staff Training in\n  Software Industry", "comments": "16 Pages, 7 Figures, 2 Tables", "journal-ref": "Journal of Intelligent Systems, Vol 18 (4). 2009. pp 267-283", "doi": null, "report-no": null, "categories": "cs.SE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The successful completion of a software development process depends on the\nanalytical capability and foresightedness of the project manager. For the\nproject manager, the main intriguing task is to manage the risk factors as they\nadversely influence the completion deadline. One such key risk factor is staff\ntraining. The risk of this factor can be avoided by pre-judging the amount of\ntraining required by the staff. So, a procedure is required to help the project\nmanager make this decision. This paper presents a system that uses influence\ndiagrams to implement the risk model to aid decision making. The system also\nconsiders the cost of conducting the training, based on various risk factors\nsuch as, (i) Lack of experience with project software; (ii) Newly appointed\nstaff; (iii) Staff not well versed with the required quality standards; and\n(iv) Lack of experience with project environment. The system provides estimated\nrequirement details for staff training at the beginning of a software\ndevelopment project.\n", "versions": [{"version": "v1", "created": "Wed, 25 Aug 2010 13:10:30 GMT"}], "update_date": "2010-08-26", "authors_parsed": [["Jeet", "Kawal", ""], ["Mago", "Vijay Kumar", ""], ["Prasad", "Bhanu", ""], ["Minhas", "Rajinder Singh", ""]]}, {"id": "1008.4310", "submitter": "Nada Matta", "authors": "Nada Matta (UTT), Karima Sidoumou (UTT), Goritsa Ninova (UTT, LIPN),\n  Hassan Atifi (UTT)", "title": "Mod\\'elisation d'une analyse pragma-linguistique d'un forum de\n  discussion", "comments": null, "journal-ref": "Intelligence collective et organisation des connaissances (ISKO),\n  Lyon : France (2009)", "doi": null, "report-no": null, "categories": "cs.AI cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present in this paper, a modelling of an expertise in pragmatics. We\nfollow knowledge engineering techniques and observe the expert when he analyses\na social discussion forum. Then a number of models are defined. These models\nemphasises the process followed by the expert and a number of criteria used in\nhis analysis. Results can be used as guides that help to understand and\nannotate discussion forum. We aim at modelling other pragmatics analysis in\norder to complete the base of guides; criteria, process, etc. of discussion\nanalysis\n", "versions": [{"version": "v1", "created": "Wed, 25 Aug 2010 16:23:03 GMT"}], "update_date": "2010-08-26", "authors_parsed": [["Matta", "Nada", "", "UTT"], ["Sidoumou", "Karima", "", "UTT"], ["Ninova", "Goritsa", "", "UTT, LIPN"], ["Atifi", "Hassan", "", "UTT"]]}, {"id": "1008.4326", "submitter": "Lars Kotthoff", "authors": "Ian Gent and Lars Kotthoff and Ian Miguel and Peter Nightingale", "title": "Machine learning for constraint solver design -- A case study for the\n  alldifferent constraint", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Constraint solvers are complex pieces of software which require many design\ndecisions to be made by the implementer based on limited information. These\ndecisions affect the performance of the finished solver significantly. Once a\ndesign decision has been made, it cannot easily be reversed, although a\ndifferent decision may be more appropriate for a particular problem.\n  We investigate using machine learning to make these decisions automatically\ndepending on the problem to solve. We use the alldifferent constraint as a case\nstudy. Our system is capable of making non-trivial, multi-level decisions that\nimprove over always making a default choice and can be implemented as part of a\ngeneral-purpose constraint solver.\n", "versions": [{"version": "v1", "created": "Wed, 25 Aug 2010 18:04:03 GMT"}], "update_date": "2010-08-26", "authors_parsed": [["Gent", "Ian", ""], ["Kotthoff", "Lars", ""], ["Miguel", "Ian", ""], ["Nightingale", "Peter", ""]]}, {"id": "1008.4328", "submitter": "Lars Kotthoff", "authors": "Lars Kotthoff and Neil C.A. Moore", "title": "Distributed solving through model splitting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Constraint problems can be trivially solved in parallel by exploring\ndifferent branches of the search tree concurrently. Previous approaches have\nfocused on implementing this functionality in the solver, more or less\ntransparently to the user. We propose a new approach, which modifies the\nconstraint model of the problem. An existing model is split into new models\nwith added constraints that partition the search space. Optionally, additional\nconstraints are imposed that rule out the search already done. The advantages\nof our approach are that it can be implemented easily, computations can be\nstopped and restarted, moved to different machines and indeed solved on\nmachines which are not able to communicate with each other at all.\n", "versions": [{"version": "v1", "created": "Wed, 25 Aug 2010 18:07:40 GMT"}], "update_date": "2010-08-26", "authors_parsed": [["Kotthoff", "Lars", ""], ["Moore", "Neil C. A.", ""]]}, {"id": "1008.4831", "submitter": "Kevin H. Knuth", "authors": "Kevin H. Knuth, John Skilling", "title": "Foundations of Inference", "comments": "This updated version of the paper has been published in the journal\n  Axioms (please see journal reference). 28 pages, 9 figures", "journal-ref": "Axioms 2012, 1(1):38-73", "doi": "10.3390/axioms1010038", "report-no": null, "categories": "math.PR cs.AI math.LO math.ST physics.data-an stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a simple and clear foundation for finite inference that unites and\nsignificantly extends the approaches of Kolmogorov and Cox. Our approach is\nbased on quantifying lattices of logical statements in a way that satisfies\ngeneral lattice symmetries. With other applications such as measure theory in\nmind, our derivations assume minimal symmetries, relying on neither negation\nnor continuity nor differentiability. Each relevant symmetry corresponds to an\naxiom of quantification, and these axioms are used to derive a unique set of\nquantifying rules that form the familiar probability calculus. We also derive a\nunique quantification of divergence, entropy and information.\n", "versions": [{"version": "v1", "created": "Sat, 28 Aug 2010 04:37:19 GMT"}, {"version": "v2", "created": "Thu, 21 Jun 2012 05:11:39 GMT"}], "update_date": "2012-06-22", "authors_parsed": [["Knuth", "Kevin H.", ""], ["Skilling", "John", ""]]}, {"id": "1008.5078", "submitter": "Joel Ratsaby", "authors": "Joel Ratsaby", "title": "Prediction by Compression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.AI cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is well known that text compression can be achieved by predicting the next\nsymbol in the stream of text data based on the history seen up to the current\nsymbol. The better the prediction the more skewed the conditional probability\ndistribution of the next symbol and the shorter the codeword that needs to be\nassigned to represent this next symbol. What about the opposite direction ?\nsuppose we have a black box that can compress text stream. Can it be used to\npredict the next symbol in the stream ? We introduce a criterion based on the\nlength of the compressed data and use it to predict the next symbol. We examine\nempirically the prediction error rate and its dependency on some compression\nparameters.\n", "versions": [{"version": "v1", "created": "Mon, 30 Aug 2010 13:21:49 GMT"}], "update_date": "2010-08-31", "authors_parsed": [["Ratsaby", "Joel", ""]]}, {"id": "1008.5133", "submitter": "Farnood Merrikh-Bayat", "authors": "Farnood Merrikh-Bayat, Saeed Bagheri-Shouraki, and Ali Rohani", "title": "Memristor Crossbar-based Hardware Implementation of IDS Method", "comments": "16 pages, 13 figures, Submitted to IEEE Transaction on Fuzzy Systems", "journal-ref": null, "doi": "10.1109/TFUZZ.2011.2160024", "report-no": null, "categories": "cs.LG cs.AI cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ink Drop Spread (IDS) is the engine of Active Learning Method (ALM), which is\nthe methodology of soft computing. IDS, as a pattern-based processing unit,\nextracts useful information from a system subjected to modeling. In spite of\nits excellent potential in solving problems such as classification and modeling\ncompared to other soft computing tools, finding its simple and fast hardware\nimplementation is still a challenge. This paper describes a new hardware\nimplementation of IDS method based on the memristor crossbar structure. In\naddition of simplicity, being completely real-time, having low latency and the\nability to continue working after the occurrence of power breakdown are some of\nthe advantages of our proposed circuit.\n", "versions": [{"version": "v1", "created": "Sun, 22 Aug 2010 16:44:23 GMT"}, {"version": "v2", "created": "Thu, 2 Sep 2010 15:56:15 GMT"}], "update_date": "2016-11-18", "authors_parsed": [["Merrikh-Bayat", "Farnood", ""], ["Bagheri-Shouraki", "Saeed", ""], ["Rohani", "Ali", ""]]}, {"id": "1008.5161", "submitter": "Robert Burger PhD", "authors": "John Robert Burger", "title": "Artificial Brain Based on Credible Neural Circuits in a Human Brain", "comments": "14 pages 12 figures corrected Fig. 3 & edited", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neurons are individually translated into simple gates to plan a brain based\non human psychology and intelligence. State machines, assumed previously\nlearned in subconscious associative memory are shown to enable equation solving\nand rudimentary thinking using nanoprocessing within short term memory.\n", "versions": [{"version": "v1", "created": "Mon, 30 Aug 2010 20:33:45 GMT"}, {"version": "v2", "created": "Fri, 17 Sep 2010 18:16:33 GMT"}, {"version": "v3", "created": "Mon, 4 Oct 2010 07:22:34 GMT"}], "update_date": "2010-10-05", "authors_parsed": [["Burger", "John Robert", ""]]}, {"id": "1008.5163", "submitter": "Brian McFee", "authors": "Brian McFee and Gert Lanckriet", "title": "Learning Multi-modal Similarity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many applications involving multi-media data, the definition of similarity\nbetween items is integral to several key tasks, e.g., nearest-neighbor\nretrieval, classification, and recommendation. Data in such regimes typically\nexhibits multiple modalities, such as acoustic and visual content of video.\nIntegrating such heterogeneous data to form a holistic similarity space is\ntherefore a key challenge to be overcome in many real-world applications.\n  We present a novel multiple kernel learning technique for integrating\nheterogeneous data into a single, unified similarity space. Our algorithm\nlearns an optimal ensemble of kernel transfor- mations which conform to\nmeasurements of human perceptual similarity, as expressed by relative\ncomparisons. To cope with the ubiquitous problems of subjectivity and\ninconsistency in multi- media similarity, we develop graph-based techniques to\nfilter similarity measurements, resulting in a simplified and robust training\nprocedure.\n", "versions": [{"version": "v1", "created": "Mon, 30 Aug 2010 20:51:26 GMT"}], "update_date": "2010-09-01", "authors_parsed": [["McFee", "Brian", ""], ["Lanckriet", "Gert", ""]]}, {"id": "1008.5188", "submitter": "Chunhua Shen", "authors": "Chunhua Shen, Hanxi Li, Nick Barnes", "title": "Totally Corrective Boosting for Regularized Risk Minimization", "comments": "This paper has been withdrawn by the author", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Consideration of the primal and dual problems together leads to important new\ninsights into the characteristics of boosting algorithms. In this work, we\npropose a general framework that can be used to design new boosting algorithms.\nA wide variety of machine learning problems essentially minimize a regularized\nrisk functional. We show that the proposed boosting framework, termed CGBoost,\ncan accommodate various loss functions and different regularizers in a\ntotally-corrective optimization fashion. We show that, by solving the primal\nrather than the dual, a large body of totally-corrective boosting algorithms\ncan actually be efficiently solved and no sophisticated convex optimization\nsolvers are needed. We also demonstrate that some boosting algorithms like\nAdaBoost can be interpreted in our framework--even their optimization is not\ntotally corrective. We empirically show that various boosting algorithms based\non the proposed framework perform similarly on the UCIrvine machine learning\ndatasets [1] that we have used in the experiments.\n", "versions": [{"version": "v1", "created": "Mon, 30 Aug 2010 23:40:51 GMT"}, {"version": "v2", "created": "Mon, 12 Dec 2011 04:42:17 GMT"}], "update_date": "2011-12-13", "authors_parsed": [["Shen", "Chunhua", ""], ["Li", "Hanxi", ""], ["Barnes", "Nick", ""]]}, {"id": "1008.5189", "submitter": "Anastasia Paparrizou Ms", "authors": "Thanasis Balafoutis, Anastasia Paparrizou, Kostas Stergiou and Toby\n  Walsh", "title": "Improving the Performance of maxRPC", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Max Restricted Path Consistency (maxRPC) is a local consistency for binary\nconstraints that can achieve considerably stronger pruning than arc\nconsistency. However, existing maxRRC algorithms suffer from overheads and\nredundancies as they can repeatedly perform many constraint checks without\ntriggering any value deletions. In this paper we propose techniques that can\nboost the performance of maxRPC algorithms. These include the combined use of\ntwo data structures to avoid many redundant constraint checks, and heuristics\nfor the efficient ordering and execution of certain operations. Based on these,\nwe propose two closely related algorithms. The first one which is a maxRPC\nalgorithm with optimal O(end^3) time complexity, displays good performance when\nused stand-alone, but is expensive to apply during search. The second one\napproximates maxRPC and has O(en^2d^4) time complexity, but a restricted\nversion with O(end^4) complexity can be very efficient when used during search.\nBoth algorithms have O(ed) space complexity. Experimental results demonstrate\nthat the resulting methods constantly outperform previous algorithms for\nmaxRPC, often by large margins, and constitute a more than viable alternative\nto arc consistency on many problems.\n", "versions": [{"version": "v1", "created": "Mon, 30 Aug 2010 23:50:33 GMT"}], "update_date": "2010-09-01", "authors_parsed": [["Balafoutis", "Thanasis", ""], ["Paparrizou", "Anastasia", ""], ["Stergiou", "Kostas", ""], ["Walsh", "Toby", ""]]}, {"id": "1008.5387", "submitter": "Hesam Dashti", "authors": "Hesam T. Dashti, Adel Ardalan, Alireza F. Siahpirani, Jernej Tonejc,\n  Ioan V. Uilecan, Tiago Simas, Bruno Miranda, Rita Ribeiro, Liya Wang, and\n  Amir H. Assadi", "title": "Pattern Recognition in Collective Cognitive Systems: Hybrid\n  Human-Machine Learning (HHML) By Heterogeneous Ensembles", "comments": "International Conference on Artificial Intelligence, WorldComp 2010", "journal-ref": "IC-AI CSREA Press (2010) , p. 183-188", "doi": null, "report-no": null, "categories": "cs.AI astro-ph.CO q-bio.QM", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  The ubiquitous role of the cyber-infrastructures, such as the WWW, provides\nmyriad opportunities for machine learning and its broad spectrum of application\ndomains taking advantage of digital communication. Pattern classification and\nfeature extraction are among the first applications of machine learning that\nhave received extensive attention. The most remarkable achievements have\naddressed data sets of moderate-to-large size. The 'data deluge' in the last\ndecade or two has posed new challenges for AI researchers to design new,\neffective and accurate algorithms for similar tasks using ultra-massive data\nsets and complex (natural or synthetic) dynamical systems. We propose a novel\nprincipled approach to feature extraction in hybrid architectures comprised of\nhumans and machines in networked communication, who collaborate to solve a\npre-assigned pattern recognition (feature extraction) task. There are two\npractical considerations addressed below: (1) Human experts, such as plant\nbiologists or astronomers, often use their visual perception and other implicit\nprior knowledge or expertise without any obvious constraints to search for the\nsignificant features, whereas machines are limited to a pre-programmed set of\ncriteria to work with; (2) in a team collaboration of collective problem\nsolving, the human experts have diverse abilities that are complementary, and\nthey learn from each other to succeed in cognitively complex tasks in ways that\nare still impossible imitate by machines.\n", "versions": [{"version": "v1", "created": "Tue, 31 Aug 2010 18:53:20 GMT"}], "update_date": "2011-11-22", "authors_parsed": [["Dashti", "Hesam T.", ""], ["Ardalan", "Adel", ""], ["Siahpirani", "Alireza F.", ""], ["Tonejc", "Jernej", ""], ["Uilecan", "Ioan V.", ""], ["Simas", "Tiago", ""], ["Miranda", "Bruno", ""], ["Ribeiro", "Rita", ""], ["Wang", "Liya", ""], ["Assadi", "Amir H.", ""]]}]