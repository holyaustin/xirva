[{"id": "1403.0034", "submitter": "Manfred Eppe", "authors": "Manfred Eppe", "title": "Tractable Epistemic Reasoning with Functional Fluents, Static Causal\n  Laws and Postdiction", "comments": "There are flaws in the mathematical background. The paper has been\n  reviewed at a conference and there are fundamental issues with the proposed\n  methodology that cannot be addressed with a simple correction notice", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an epistemic action theory for tractable epistemic reasoning as an\nextension to the h-approximation (HPX) theory. In contrast to existing\ntractable approaches, the theory supports functional fluents and postdictive\nreasoning with static causal laws. We argue that this combination is\nparticularly synergistic because it allows one not only to perform direct\npostdiction about the conditions of actions, but also indirect postdiction\nabout the conditions of static causal laws. We show that despite the richer\nexpressiveness, the temporal projection problem remains tractable (polynomial),\nand therefore the planning problem remains in NP. We present the operational\nsemantics of our theory as well as its formulation as Answer Set Programming.\n", "versions": [{"version": "v1", "created": "Sat, 1 Mar 2014 00:39:26 GMT"}, {"version": "v2", "created": "Sat, 22 Mar 2014 17:56:47 GMT"}, {"version": "v3", "created": "Sun, 8 Dec 2019 13:36:33 GMT"}, {"version": "v4", "created": "Wed, 25 Nov 2020 15:18:51 GMT"}], "update_date": "2020-11-26", "authors_parsed": [["Eppe", "Manfred", ""]]}, {"id": "1403.0036", "submitter": "Menghan Wang", "authors": "Menghan Wang", "title": "Dynamic Decision Process Modeling and Relation-line Handling in\n  Distributed Cooperative Modeling System", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Distributed Cooperative Modeling System (DCMS) solves complex decision\nproblems involving a lot of participants with different viewpoints by network\nbased distributed modeling and multi-template aggregation.\n  This thesis aims at extending the system with support for dynamic decision\nmaking process. First, the thesis presents a discussion of characteristics and\noptimal policy finding Markov Decision Process as well as a brief introduction\nto dynamic Bayesian decision network, which is inherently equal to MDP. After\nthat, discussion and implementation of prediction in Markov process for both\ndiscrete and continuous random variable are given, as well as several different\nkinds of correlation analysis among multiple indices which could help\ndecision-makers to realize the interaction of indices and design appropriate\npolicy.\n  Appending history data of Macau industry, as the foundation of extending\nDCMS, is introduced. Additional works include rearrangement of graphical class\nhierarchy in DCMS, which in turn allows convenient implementation of curve\nrelation-line, which makes template modeling clearer and friendlier.\n", "versions": [{"version": "v1", "created": "Sat, 1 Mar 2014 01:12:34 GMT"}], "update_date": "2014-03-04", "authors_parsed": [["Wang", "Menghan", ""]]}, {"id": "1403.0222", "submitter": "Hubie Chen", "authors": "Hubie Chen (Universidad del Pa\\'is Vasco and IKERBASQUE)", "title": "Beyond Q-Resolution and Prenex Form: A Proof System for Quantified\n  Constraint Satisfaction", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 10, Issue 4 (December\n  23, 2014) lmcs:1012", "doi": "10.2168/LMCS-10(4:14)2014", "report-no": null, "categories": "cs.LO cs.AI cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the quantified constraint satisfaction problem (QCSP) which is to\ndecide, given a structure and a first-order sentence (not assumed here to be in\nprenex form) built from conjunction and quantification, whether or not the\nsentence is true on the structure. We present a proof system for certifying the\nfalsity of QCSP instances and develop its basic theory; for instance, we\nprovide an algorithmic interpretation of its behavior. Our proof system places\nthe established Q-resolution proof system in a broader context, and also allows\nus to derive QCSP tractability results.\n", "versions": [{"version": "v1", "created": "Sun, 2 Mar 2014 15:19:57 GMT"}, {"version": "v2", "created": "Fri, 23 May 2014 08:15:56 GMT"}, {"version": "v3", "created": "Mon, 17 Nov 2014 14:07:51 GMT"}, {"version": "v4", "created": "Sat, 20 Dec 2014 13:55:26 GMT"}], "update_date": "2015-07-01", "authors_parsed": [["Chen", "Hubie", "", "Universidad del Pa\u00eds Vasco and IKERBASQUE"]]}, {"id": "1403.0461", "submitter": "Francesco Santini", "authors": "Stefano Bistarelli, Maurizio Gabbrielli, Maria Chiara Meo, Francesco\n  Santini", "title": "Timed Soft Concurrent Constraint Programs: An Interleaved and a Parallel\n  Approach", "comments": null, "journal-ref": "Theory and Practice of Logic Programming 15 (2014) 743-782", "doi": "10.1017/S1471068414000106", "report-no": null, "categories": "cs.PL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a timed and soft extension of Concurrent Constraint Programming.\nThe time extension is based on the hypothesis of bounded asynchrony: the\ncomputation takes a bounded period of time and is measured by a discrete global\nclock. Action prefixing is then considered as the syntactic marker which\ndistinguishes a time instant from the next one. Supported by soft constraints\ninstead of crisp ones, tell and ask agents are now equipped with a preference\n(or consistency) threshold which is used to determine their success or\nsuspension. In the paper we provide a language to describe the agents behavior,\ntogether with its operational and denotational semantics, for which we also\nprove the compositionality and correctness properties. After presenting a\nsemantics using maximal parallelism of actions, we also describe a version for\ntheir interleaving on a single processor (with maximal parallelism for time\nelapsing). Coordinating agents that need to take decisions both on preference\nvalues and time events may benefit from this language. To appear in Theory and\nPractice of Logic Programming (TPLP).\n", "versions": [{"version": "v1", "created": "Mon, 24 Feb 2014 12:23:38 GMT"}, {"version": "v2", "created": "Tue, 22 Apr 2014 09:08:34 GMT"}], "update_date": "2015-10-07", "authors_parsed": [["Bistarelli", "Stefano", ""], ["Gabbrielli", "Maurizio", ""], ["Meo", "Maria Chiara", ""], ["Santini", "Francesco", ""]]}, {"id": "1403.0504", "submitter": "Brooks Paige", "authors": "Brooks Paige and Frank Wood", "title": "A Compilation Target for Probabilistic Programming Languages", "comments": "In Proceedings of the 31st International Conference on Machine\n  Learning (ICML), 2014", "journal-ref": "JMLR W&CP 32 (1) : 1935-1943, 2014", "doi": null, "report-no": null, "categories": "cs.AI cs.PL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Forward inference techniques such as sequential Monte Carlo and particle\nMarkov chain Monte Carlo for probabilistic programming can be implemented in\nany programming language by creative use of standardized operating system\nfunctionality including processes, forking, mutexes, and shared memory.\nExploiting this we have defined, developed, and tested a probabilistic\nprogramming language intermediate representation language we call probabilistic\nC, which itself can be compiled to machine code by standard compilers and\nlinked to operating system libraries yielding an efficient, scalable, portable\nprobabilistic programming compilation target. This opens up a new hardware and\nsystems research path for optimizing probabilistic programming systems.\n", "versions": [{"version": "v1", "created": "Mon, 3 Mar 2014 18:08:57 GMT"}, {"version": "v2", "created": "Thu, 10 Jul 2014 17:41:10 GMT"}], "update_date": "2014-07-11", "authors_parsed": [["Paige", "Brooks", ""], ["Wood", "Frank", ""]]}, {"id": "1403.0522", "submitter": "Ahmad Taher Azar Dr.", "authors": "Ahmad Taher Azar, Aboul Ella Hassanien", "title": "Expert System Based On Neural-Fuzzy Rules for Thyroid Diseases Diagnosis", "comments": "Conference Paper", "journal-ref": null, "doi": "10.1007/978-3-642-35521-9_13", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The thyroid, an endocrine gland that secretes hormones in the blood,\ncirculates its products to all tissues of the body, where they control vital\nfunctions in every cell. Normal levels of thyroid hormone help the brain,\nheart, intestines, muscles and reproductive system function normally. Thyroid\nhormones control the metabolism of the body. Abnormalities of thyroid function\nare usually related to production of too little thyroid hormone\n(hypothyroidism) or production of too much thyroid hormone (hyperthyroidism).\nTherefore, the correct diagnosis of these diseases is very important topic. In\nthis study, Linguistic Hedges Neural-Fuzzy Classifier with Selected Features\n(LHNFCSF) is presented for diagnosis of thyroid diseases. The performance\nevaluation of this system is estimated by using classification accuracy and\nk-fold cross-validation. The results indicated that the classification accuracy\nwithout feature selection was 98.6047% and 97.6744% during training and testing\nphases, respectively with RMSE of 0.02335. After applying feature selection\nalgorithm, LHNFCSF achieved 100% for all cluster sizes during training phase.\nHowever, in the testing phase LHNFCSF achieved 88.3721% using one cluster for\neach class, 90.6977% using two clusters, 91.8605% using three clusters and\n97.6744% using four clusters for each class and 12 fuzzy rules. The obtained\nclassification accuracy was very promising with regard to the other\nclassification applications in literature for this problem.\n", "versions": [{"version": "v1", "created": "Mon, 3 Mar 2014 18:50:08 GMT"}], "update_date": "2014-03-04", "authors_parsed": [["Azar", "Ahmad Taher", ""], ["Hassanien", "Aboul Ella", ""]]}, {"id": "1403.0541", "submitter": "Saadat Anwar", "authors": "Saadat Anwar", "title": "Representing, reasoning and answering questions about biological\n  pathways - various applications", "comments": "thesis", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CE cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Biological organisms are composed of numerous interconnected biochemical\nprocesses. Diseases occur when normal functionality of these processes is\ndisrupted. Thus, understanding these biochemical processes and their\ninterrelationships is a primary task in biomedical research and a prerequisite\nfor diagnosing diseases, and drug development. Scientists studying these\nprocesses have identified various pathways responsible for drug metabolism, and\nsignal transduction, etc.\n  Newer techniques and speed improvements have resulted in deeper knowledge\nabout these pathways, resulting in refined models that tend to be large and\ncomplex, making it difficult for a person to remember all aspects of it. Thus,\ncomputer models are needed to analyze them. We want to build such a system that\nallows modeling of biological systems and pathways in such a way that we can\nanswer questions about them.\n  Many existing models focus on structural and/or factoid questions, using\nsurface-level knowledge that does not require understanding the underlying\nmodel. We believe these are not the kind of questions that a biologist may ask\nsomeone to test their understanding of the biological processes. We want our\nsystem to answer the kind of questions a biologist may ask. Such questions\nappear in early college level text books.\n  Thus the main goal of our thesis is to develop a system that allows us to\nencode knowledge about biological pathways and answer such questions about them\ndemonstrating understanding of the pathway. To that end, we develop a language\nthat will allow posing such questions and illustrate the utility of our\nframework with various applications in the biological domain. We use some\nexisting tools with modifications to accomplish our goal.\n  Finally, we apply our system to real world applications by extracting pathway\nknowledge from text and answering questions related to drug development.\n", "versions": [{"version": "v1", "created": "Mon, 3 Mar 2014 19:45:41 GMT"}], "update_date": "2014-03-04", "authors_parsed": [["Anwar", "Saadat", ""]]}, {"id": "1403.0613", "submitter": "Zhiguo Long", "authors": "Sanjiang Li, Zhiguo Long, Weiming Liu, Matt Duckham, Alan Both", "title": "On Redundant Topological Constraints", "comments": "An extended abstract appears in Proceedings of the 14th International\n  Conference on the Principles of Knowledge Representation and Reasoning\n  (KR-14), Vienna, Austria, July 20-24, 2014", "journal-ref": "Artificial Intelligence 225 (2015) 51-76", "doi": "10.1016/j.artint.2015.03.010", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Region Connection Calculus (RCC) is a well-known calculus for\nrepresenting part-whole and topological relations. It plays an important role\nin qualitative spatial reasoning, geographical information science, and\nontology. The computational complexity of reasoning with RCC5 and RCC8 (two\nfragments of RCC) as well as other qualitative spatial/temporal calculi has\nbeen investigated in depth in the literature. Most of these works focus on the\nconsistency of qualitative constraint networks. In this paper, we consider the\nimportant problem of redundant qualitative constraints. For a set $\\Gamma$ of\nqualitative constraints, we say a constraint $(x R y)$ in $\\Gamma$ is redundant\nif it is entailed by the rest of $\\Gamma$. A prime subnetwork of $\\Gamma$ is a\nsubset of $\\Gamma$ which contains no redundant constraints and has the same\nsolution set as $\\Gamma$. It is natural to ask how to compute such a prime\nsubnetwork, and when it is unique.\n  In this paper, we show that this problem is in general intractable, but\nbecomes tractable if $\\Gamma$ is over a tractable subalgebra $\\mathcal{S}$ of a\nqualitative calculus. Furthermore, if $\\mathcal{S}$ is a subalgebra of RCC5 or\nRCC8 in which weak composition distributes over nonempty intersections, then\n$\\Gamma$ has a unique prime subnetwork, which can be obtained in cubic time by\nremoving all redundant constraints simultaneously from $\\Gamma$. As a\nbyproduct, we show that any path-consistent network over such a distributive\nsubalgebra is weakly globally consistent and minimal. A thorough empirical\nanalysis of the prime subnetwork upon real geographical data sets demonstrates\nthe approach is able to identify significantly more redundant constraints than\npreviously proposed algorithms, especially in constraint networks with larger\nproportions of partial overlap relations.\n", "versions": [{"version": "v1", "created": "Mon, 3 Mar 2014 22:01:16 GMT"}, {"version": "v2", "created": "Fri, 13 Feb 2015 15:22:28 GMT"}], "update_date": "2017-02-21", "authors_parsed": [["Li", "Sanjiang", ""], ["Long", "Zhiguo", ""], ["Liu", "Weiming", ""], ["Duckham", "Matt", ""], ["Both", "Alan", ""]]}, {"id": "1403.0764", "submitter": "Kieran Greer Dr", "authors": "Kieran Greer", "title": "Clustering Concept Chains from Ordered Data without Path Descriptions", "comments": "Pre-print", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes a process for clustering concepts into chains from data\npresented randomly to an evaluating system. There are a number of rules or\nguidelines that help the system to determine more accurately what concepts\nbelong to a particular chain and what ones do not, but it should be possible to\nwrite these in a generic way. This mechanism also uses a flat structure without\nany hierarchical path information, where the link between two concepts is made\nat the level of the concept itself. It does not require related metadata, but\ninstead, a simple counting mechanism is used. Key to this is a count for both\nthe concept itself and also the group or chain that it belongs to. To test the\npossible success of the mechanism, concept chain parts taken randomly from a\nlarger ontology were presented to the system, but only at a depth of 2 concepts\neach time. That is - root concept plus a concept that it is linked to. The\nresults show that this can still lead to very variable structures being formed\nand can also accommodate some level of randomness.\n", "versions": [{"version": "v1", "created": "Tue, 4 Mar 2014 12:37:36 GMT"}], "update_date": "2014-03-05", "authors_parsed": [["Greer", "Kieran", ""]]}, {"id": "1403.0778", "submitter": "Kieran Greer Dr", "authors": "Kieran Greer", "title": "Dynamic Move Chains -- a Forward Pruning Approach to Tree Search in\n  Computer Chess", "comments": "Published", "journal-ref": "Advances in Artificial Intelligence, Vol. 2013, Article ID 357068,\n  9 pages, 2013. Hindawi", "doi": "10.1155/2013/357068", "report-no": null, "categories": "cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a new mechanism for pruning a search game-tree in\ncomputer chess. The algorithm stores and then reuses chains or sequences of\nmoves, built up from previous searches. These move sequences have a built-in\nforward-pruning mechanism that can radically reduce the search space. A typical\nsearch process might retrieve a move from a Transposition Table, where the\ndecision of what move to retrieve would be based on the position itself. This\nalgorithm stores move sequences based on what previous sequences were better,\nor caused cutoffs. This is therefore position independent and so it could also\nbe useful in games with imperfect information or uncertainty, where the whole\nsituation is not known at any one time. Over a small set of tests, the\nalgorithm was shown to clearly out-perform Transposition Tables, both in terms\nof search reduction and game-play results.\n", "versions": [{"version": "v1", "created": "Tue, 4 Mar 2014 13:07:48 GMT"}], "update_date": "2014-03-05", "authors_parsed": [["Greer", "Kieran", ""]]}, {"id": "1403.1076", "submitter": "Kieran Greer Dr", "authors": "Kieran Greer", "title": "Is Intelligence Artificial?", "comments": "This new version adds some clarity to the discussion. Also the\n  opportunity to extend or update some sections. Some new references", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Our understanding of intelligence is directed primarily at the human level.\nThis paper attempts to give a more unifying definition that can be applied to\nthe natural world in general and then Artificial Intelligence. The definition\nwould be used more to verify a relative intelligence, not to quantify it and\nmight help when making judgements on the matter. While correct behaviour is the\npreferred definition, a metric that is grounded in Kolmogorov's Complexity\nTheory is suggested, which leads to a measurement about entropy. A version of\nan accepted AI test is then put forward as the 'acid test' and might be what a\nfree-thinking program would try to achieve. Recent work by the author has been\nmore from a direction of mechanical processes, or ones that might operate\nautomatically. This paper agrees that intelligence is a pro-active event, but\nalso notes a second aspect to it that is in the background and mechanical. The\npaper suggests looking at intelligence and the conscious as being slightly\ndifferent, where consciousness is this more mechanical aspect. In fact, a\nsurprising conclusion can be a passive but intelligent brain being invoked by\nactive and less intelligent senses.\n", "versions": [{"version": "v1", "created": "Wed, 5 Mar 2014 11:09:55 GMT"}, {"version": "v2", "created": "Sat, 8 Nov 2014 13:20:49 GMT"}, {"version": "v3", "created": "Tue, 25 Nov 2014 16:19:47 GMT"}, {"version": "v4", "created": "Wed, 28 Jan 2015 17:10:05 GMT"}, {"version": "v5", "created": "Mon, 29 Jun 2015 11:49:38 GMT"}, {"version": "v6", "created": "Mon, 18 Jan 2021 10:59:41 GMT"}, {"version": "v7", "created": "Mon, 14 Jun 2021 11:29:11 GMT"}, {"version": "v8", "created": "Thu, 29 Jul 2021 11:44:43 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["Greer", "Kieran", ""]]}, {"id": "1403.1080", "submitter": "Kieran Greer Dr", "authors": "Kieran Greer", "title": "New Ideas for Brain Modelling", "comments": null, "journal-ref": "BRAIN. Broad Research in Artificial Intelligence and Neuroscience,\n  Volume 6, Issues 3-4, December 2015, ISSN 2067-3957 (online), ISSN 2068 -\n  0473 (print)", "doi": null, "report-no": null, "categories": "cs.AI q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes some biologically-inspired processes that could be used\nto build the sort of networks that we associate with the human brain. New to\nthis paper, a 'refined' neuron will be proposed. This is a group of neurons\nthat by joining together can produce a more analogue system, but with the same\nlevel of control and reliability that a binary neuron would have. With this new\nstructure, it will be possible to think of an essentially binary system in\nterms of a more variable set of values. The paper also shows how recent\nresearch associated with the new model, can be combined with established\ntheories, to produce a more complete picture. The propositions are largely in\nline with conventional thinking, but possibly with one or two more radical\nsuggestions. An earlier cognitive model can be filled in with more specific\ndetails, based on the new research results, where the components appear to fit\ntogether almost seamlessly. The intention of the research has been to describe\nplausible 'mechanical' processes that can produce the appropriate brain\nstructures and mechanisms, but that could be used without the magical\n'intelligence' part that is still not fully understood. There are also some\nimportant updates from an earlier version of this paper.\n", "versions": [{"version": "v1", "created": "Wed, 5 Mar 2014 11:17:11 GMT"}, {"version": "v2", "created": "Sat, 5 Jul 2014 21:16:13 GMT"}, {"version": "v3", "created": "Mon, 9 May 2016 08:28:20 GMT"}, {"version": "v4", "created": "Mon, 17 Oct 2016 09:02:21 GMT"}], "update_date": "2018-02-06", "authors_parsed": [["Greer", "Kieran", ""]]}, {"id": "1403.1169", "submitter": "J. G. Wolff", "authors": "J Gerard Wolff", "title": "A proof challenge: multiple alignment and information compression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  These notes pose a \"proof challenge\": a proof, or disproof, of the\nproposition that \"For any given body of information, I, expressed as a\none-dimensional sequence of atomic symbols, a multiple alignment concept,\ndescribed in the document, provides a means of encoding all the redundancy that\nmay exist in I. Aspects of the challenge are described.\n", "versions": [{"version": "v1", "created": "Tue, 4 Mar 2014 17:00:19 GMT"}], "update_date": "2014-03-06", "authors_parsed": [["Wolff", "J Gerard", ""]]}, {"id": "1403.1353", "submitter": "Yang Wu", "authors": "Yang Wu, Vansteenberge Jarich, Masayuki Mukunoki, and Michihiko Minoh", "title": "Collaborative Representation for Classification, Sparse or Non-sparse?", "comments": "8 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sparse representation based classification (SRC) has been proved to be a\nsimple, effective and robust solution to face recognition. As it gets popular,\ndoubts on the necessity of enforcing sparsity starts coming up, and primary\nexperimental results showed that simply changing the $l_1$-norm based\nregularization to the computationally much more efficient $l_2$-norm based\nnon-sparse version would lead to a similar or even better performance. However,\nthat's not always the case. Given a new classification task, it's still unclear\nwhich regularization strategy (i.e., making the coefficients sparse or\nnon-sparse) is a better choice without trying both for comparison. In this\npaper, we present as far as we know the first study on solving this issue,\nbased on plenty of diverse classification experiments. We propose a scoring\nfunction for pre-selecting the regularization strategy using only the dataset\nsize, the feature dimensionality and a discrimination score derived from a\ngiven feature representation. Moreover, we show that when dictionary learning\nis taking into account, non-sparse representation has a more significant\nsuperiority to sparse representation. This work is expected to enrich our\nunderstanding of sparse/non-sparse collaborative representation for\nclassification and motivate further research activities.\n", "versions": [{"version": "v1", "created": "Thu, 6 Mar 2014 05:44:32 GMT"}], "update_date": "2014-03-07", "authors_parsed": [["Wu", "Yang", ""], ["Jarich", "Vansteenberge", ""], ["Mukunoki", "Masayuki", ""], ["Minoh", "Michihiko", ""]]}, {"id": "1403.1497", "submitter": "Manuel Lopes", "authors": "Manuel Lopes and Luis Montesano", "title": "Active Learning for Autonomous Intelligent Agents: Exploration,\n  Curiosity, and Interaction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this survey we present different approaches that allow an intelligent\nagent to explore autonomous its environment to gather information and learn\nmultiple tasks. Different communities proposed different solutions, that are in\nmany cases, similar and/or complementary. These solutions include active\nlearning, exploration/exploitation, online-learning and social learning. The\ncommon aspect of all these approaches is that it is the agent to selects and\ndecides what information to gather next. Applications for these approaches\nalready include tutoring systems, autonomous grasping learning, navigation and\nmapping and human-robot interaction. We discuss how these approaches are\nrelated, explaining their similarities and their differences in terms of\nproblem assumptions and metrics of success. We consider that such an integrated\ndiscussion will improve inter-disciplinary research and applications.\n", "versions": [{"version": "v1", "created": "Thu, 6 Mar 2014 17:12:30 GMT"}], "update_date": "2014-03-07", "authors_parsed": [["Lopes", "Manuel", ""], ["Montesano", "Luis", ""]]}, {"id": "1403.1521", "submitter": "Karl Wiegand", "authors": "Ian Helmke, Daniel Kreymer, Karl Wiegand", "title": "Approximation Models of Combat in StarCraft 2", "comments": "13 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Real-time strategy (RTS) games make heavy use of artificial intelligence\n(AI), especially in the design of computerized opponents. Because of the\ncomputational complexity involved in managing all aspects of these games, many\nAI opponents are designed to optimize only a few areas of playing style. In\ngames like StarCraft 2, a very popular and recently released RTS, most AI\nstrategies revolve around economic and building efficiency: AI opponents try to\ngather and spend all resources as quickly and effectively as possible while\nensuring that no units are idle. The aim of this work was to help address the\nneed for AI combat strategies that are not computationally intensive. Our goal\nwas to produce a computationally efficient model that is accurate at predicting\nthe results of complex battles between diverse armies, including which army\nwill win and how many units will remain. Our results suggest it may be possible\nto develop a relatively simple approximation model of combat that can\naccurately predict many battles that do not involve micromanagement. Future\ndesigns of AI opponents may be able to incorporate such an approximation model\ninto their decision and planning systems to provide a challenge that is\nstrategically balanced across all aspects of play.\n", "versions": [{"version": "v1", "created": "Thu, 6 Mar 2014 18:26:49 GMT"}], "update_date": "2014-03-07", "authors_parsed": [["Helmke", "Ian", ""], ["Kreymer", "Daniel", ""], ["Wiegand", "Karl", ""]]}, {"id": "1403.1523", "submitter": "Changchuan Yin Dr.", "authors": "Changchuan Yin, Xuemeng E. Yin, Jiasong Wang", "title": "A Novel Method for Comparative Analysis of DNA Sequences by\n  Ramanujan-Fourier Transform", "comments": "Ramanujan-Fourier transform and DNA sequences", "journal-ref": null, "doi": "10.1089/cmb.2014.0120", "report-no": null, "categories": "cs.CE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Alignment-free sequence analysis approaches provide important alternatives\nover multiple sequence alignment (MSA) in biological sequence analysis because\nalignment-free approaches have low computation complexity and are not dependent\non high level of sequence identity, however, most of the existing\nalignment-free methods do not employ true full information content of sequences\nand thus can not accurately reveal similarities and differences among DNA\nsequences. We present a novel alignment-free computational method for sequence\nanalysis based on Ramanujan-Fourier transform (RFT), in which complete\ninformation of DNA sequences is retained. We represent DNA sequences as four\nbinary indicator sequences and apply RFT on the indicator sequences to convert\nthem into frequency domain. The Euclidean distance of the complete RFT\ncoefficients of DNA sequences are used as similarity measure. To address the\ndifferent lengths in Euclidean space of RFT coefficients, we pad zeros to short\nDNA binary sequences so that the binary sequences equal the longest length in\nthe comparison sequence data. Thus, the DNA sequences are compared in the same\ndimensional frequency space without information loss. We demonstrate the\nusefulness of the proposed method by presenting experimental results on\nhierarchical clustering of genes and genomes. The proposed method opens a new\nchannel to biological sequence analysis, classification, and structural module\nidentification.\n", "versions": [{"version": "v1", "created": "Thu, 6 Mar 2014 18:29:52 GMT"}, {"version": "v2", "created": "Fri, 27 Jun 2014 18:35:05 GMT"}], "update_date": "2016-08-02", "authors_parsed": [["Yin", "Changchuan", ""], ["Yin", "Xuemeng E.", ""], ["Wang", "Jiasong", ""]]}, {"id": "1403.1618", "submitter": "Mohammad Mahmoodi Varnamkhasti", "authors": "Maryam Mahmoodi, Mohammad Mahmoodi Varnamkhasti", "title": "Design a Persian Automated Plagiarism Detector (AMZPPD)", "comments": "3 pages, Published with International Journal of Engineering Trends\n  and Technology (IJETT)Published with International Journal of Engineering\n  Trends and Technology (IJETT)", "journal-ref": "International Journal of Engineering Trends and Technology(IJETT),\n  V8(8),465-467 February 2014", "doi": "10.14445/22315381/IJETT-V8P280", "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Currently there are lots of plagiarism detection approaches. But few of them\nimplemented and adapted for Persian languages. In this paper, our work on\ndesigning and implementation of a plagiarism detection system based on\npre-processing and NLP technics will be described. And the results of testing\non a corpus will be presented.\n", "versions": [{"version": "v1", "created": "Thu, 6 Mar 2014 22:57:29 GMT"}], "update_date": "2014-03-10", "authors_parsed": [["Mahmoodi", "Maryam", ""], ["Varnamkhasti", "Mohammad Mahmoodi", ""]]}, {"id": "1403.1891", "submitter": "Lihong Li", "authors": "Lihong Li and Shunbao Chen and Jim Kleban and Ankur Gupta", "title": "Counterfactual Estimation and Optimization of Click Metrics for Search\n  Engines", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Optimizing an interactive system against a predefined online metric is\nparticularly challenging, when the metric is computed from user feedback such\nas clicks and payments. The key challenge is the counterfactual nature: in the\ncase of Web search, any change to a component of the search engine may result\nin a different search result page for the same query, but we normally cannot\ninfer reliably from search log how users would react to the new result page.\nConsequently, it appears impossible to accurately estimate online metrics that\ndepend on user feedback, unless the new engine is run to serve users and\ncompared with a baseline in an A/B test. This approach, while valid and\nsuccessful, is unfortunately expensive and time-consuming. In this paper, we\npropose to address this problem using causal inference techniques, under the\ncontextual-bandit framework. This approach effectively allows one to run\n(potentially infinitely) many A/B tests offline from search log, making it\npossible to estimate and optimize online metrics quickly and inexpensively.\nFocusing on an important component in a commercial search engine, we show how\nthese ideas can be instantiated and applied, and obtain very promising results\nthat suggest the wide applicability of these techniques.\n", "versions": [{"version": "v1", "created": "Fri, 7 Mar 2014 22:54:52 GMT"}, {"version": "v2", "created": "Wed, 12 Mar 2014 06:36:02 GMT"}], "update_date": "2014-03-13", "authors_parsed": [["Li", "Lihong", ""], ["Chen", "Shunbao", ""], ["Kleban", "Jim", ""], ["Gupta", "Ankur", ""]]}, {"id": "1403.1893", "submitter": "Michael Smith", "authors": "Michael R. Smith and Tony Martinez", "title": "Becoming More Robust to Label Noise with Classifier Diversity", "comments": "37 pages, 10 tables, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is widely known in the machine learning community that class noise can be\n(and often is) detrimental to inducing a model of the data. Many current\napproaches use a single, often biased, measurement to determine if an instance\nis noisy. A biased measure may work well on certain data sets, but it can also\nbe less effective on a broader set of data sets. In this paper, we present\nnoise identification using classifier diversity (NICD) -- a method for deriving\na less biased noise measurement and integrating it into the learning process.\nTo lessen the bias of the noise measure, NICD selects a diverse set of\nclassifiers (based on their predictions of novel instances) to determine which\ninstances are noisy. We examine NICD as a technique for filtering, instance\nweighting, and selecting the base classifiers of a voting ensemble. We compare\nNICD with several other noise handling techniques that do not consider\nclassifier diversity on a set of 54 data sets and 5 learning algorithms. NICD\nsignificantly increases the classification accuracy over the other considered\napproaches and is effective across a broad set of data sets and learning\nalgorithms.\n", "versions": [{"version": "v1", "created": "Fri, 7 Mar 2014 22:58:48 GMT"}], "update_date": "2014-03-11", "authors_parsed": [["Smith", "Michael R.", ""], ["Martinez", "Tony", ""]]}, {"id": "1403.2150", "submitter": "Sofia Triantafillou", "authors": "Sofia Triantafillou, Ioannis Tsamardinos", "title": "Constraint-based Causal Discovery from Multiple Interventions over\n  Overlapping Variable Sets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Scientific practice typically involves repeatedly studying a system, each\ntime trying to unravel a different perspective. In each study, the scientist\nmay take measurements under different experimental conditions (interventions,\nmanipulations, perturbations) and measure different sets of quantities\n(variables). The result is a collection of heterogeneous data sets coming from\ndifferent data distributions. In this work, we present algorithm COmbINE, which\naccepts a collection of data sets over overlapping variable sets under\ndifferent experimental conditions; COmbINE then outputs a summary of all causal\nmodels indicating the invariant and variant structural characteristics of all\nmodels that simultaneously fit all of the input data sets. COmbINE converts\nestimated dependencies and independencies in the data into path constraints on\nthe data-generating causal model and encodes them as a SAT instance. The\nalgorithm is sound and complete in the sample limit. To account for conflicting\nconstraints arising from statistical errors, we introduce a general method for\nsorting constraints in order of confidence, computed as a function of their\ncorresponding p-values. In our empirical evaluation, COmbINE outperforms in\nterms of efficiency the only pre-existing similar algorithm; the latter\nadditionally admits feedback cycles, but does not admit conflicting constraints\nwhich hinders the applicability on real data. As a proof-of-concept, COmbINE is\nemployed to co-analyze 4 real, mass-cytometry data sets measuring\nphosphorylated protein concentrations of overlapping protein sets under 3\ndifferent interventions.\n", "versions": [{"version": "v1", "created": "Mon, 10 Mar 2014 07:24:20 GMT"}], "update_date": "2014-03-11", "authors_parsed": [["Triantafillou", "Sofia", ""], ["Tsamardinos", "Ioannis", ""]]}, {"id": "1403.2194", "submitter": "Yannis Haralambous", "authors": "Yannis Haralambous and Pedro Quaresma", "title": "Querying Geometric Figures Using a Controlled Language, Ontological\n  Graphs and Dependency Lattices", "comments": "14 pages, 5 figures, accepted at CICM 2014", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.AI cs.DB cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dynamic geometry systems (DGS) have become basic tools in many areas of\ngeometry as, for example, in education. Geometry Automated Theorem Provers\n(GATP) are an active area of research and are considered as being basic tools\nin future enhanced educational software as well as in a next generation of\nmechanized mathematics assistants. Recently emerged Web repositories of\ngeometric knowledge, like TGTP and Intergeo, are an attempt to make the already\nvast data set of geometric knowledge widely available. Considering the large\namount of geometric information already available, we face the need of a query\nmechanism for descriptions of geometric constructions.\n  In this paper we discuss two approaches for describing geometric figures\n(declarative and procedural), and present algorithms for querying geometric\nfigures in declaratively and procedurally described corpora, by using a DGS or\na dedicated controlled natural language for queries.\n", "versions": [{"version": "v1", "created": "Mon, 10 Mar 2014 09:39:12 GMT"}, {"version": "v2", "created": "Thu, 8 May 2014 07:06:02 GMT"}, {"version": "v3", "created": "Tue, 13 May 2014 23:44:33 GMT"}], "update_date": "2014-05-15", "authors_parsed": [["Haralambous", "Yannis", ""], ["Quaresma", "Pedro", ""]]}, {"id": "1403.2498", "submitter": "Guoru Ding", "authors": "Qihui Wu, Guoru Ding (Corresponding author), Yuhua Xu, Shuo Feng,\n  Zhiyong Du, Jinlong Wang, and Keping Long", "title": "Cognitive Internet of Things: A New Paradigm beyond Connection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current research on Internet of Things (IoT) mainly focuses on how to enable\ngeneral objects to see, hear, and smell the physical world for themselves, and\nmake them connected to share the observations. In this paper, we argue that\nonly connected is not enough, beyond that, general objects should have the\ncapability to learn, think, and understand both physical and social worlds by\nthemselves. This practical need impels us to develop a new paradigm, named\nCognitive Internet of Things (CIoT), to empower the current IoT with a `brain'\nfor high-level intelligence. Specifically, we first present a comprehensive\ndefinition for CIoT, primarily inspired by the effectiveness of human\ncognition. Then, we propose an operational framework of CIoT, which mainly\ncharacterizes the interactions among five fundamental cognitive tasks:\nperception-action cycle, massive data analytics, semantic derivation and\nknowledge discovery, intelligent decision-making, and on-demand service\nprovisioning. Furthermore, we provide a systematic tutorial on key enabling\ntechniques involved in the cognitive tasks. In addition, we also discuss the\ndesign of proper performance metrics on evaluating the enabling techniques.\nLast but not least, we present the research challenges and open issues ahead.\nBuilding on the present work and potentially fruitful future studies, CIoT has\nthe capability to bridge the physical world (with objects, resources, etc.) and\nthe social world (with human demand, social behavior, etc.), and enhance smart\nresource allocation, automatic network operation, and intelligent service\nprovisioning.\n", "versions": [{"version": "v1", "created": "Tue, 11 Mar 2014 08:34:31 GMT"}], "update_date": "2014-03-12", "authors_parsed": [["Wu", "Qihui", "", "Corresponding author"], ["Ding", "Guoru", "", "Corresponding author"], ["Xu", "Yuhua", ""], ["Feng", "Shuo", ""], ["Du", "Zhiyong", ""], ["Wang", "Jinlong", ""], ["Long", "Keping", ""]]}, {"id": "1403.2541", "submitter": "Kieran Greer Dr", "authors": "Kieran Greer", "title": "Turing: Then, Now and Still Key", "comments": "Published", "journal-ref": "'Artificial Intelligence, Evolutionary Computation and\n  Metaheuristics (AIECM) - Turing 2012', Eds. X-S. Yang, Studies in\n  Computational Intelligence, 2013, Vol. 427/2013, pp. 43-62, Springer-Verlag\n  Berlin Heidelberg", "doi": "10.1007/978-3-642-29694-9_3", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper looks at Turing's postulations about Artificial Intelligence in\nhis paper 'Computing Machinery and Intelligence', published in 1950. It notes\nhow accurate they were and how relevant they still are today. This paper notes\nthe arguments and mechanisms that he suggested and tries to expand on them\nfurther. The paper however is mostly about describing the essential ingredients\nfor building an intelligent model and the problems related with that. The\ndiscussion includes recent work by the author himself, who adds his own\nthoughts on the matter that come from a purely technical investigation into the\nproblem. These are personal and quite speculative, but provide an interesting\ninsight into the mechanisms that might be used for building an intelligent\nsystem.\n", "versions": [{"version": "v1", "created": "Tue, 11 Mar 2014 11:38:23 GMT"}], "update_date": "2014-03-12", "authors_parsed": [["Greer", "Kieran", ""]]}, {"id": "1403.3084", "submitter": "Juan Juli\\'an Merelo-Guerv\\'os Pr.", "authors": "R.H. Garc\\'ia-Ortega, P. Garc\\'ia-S\\'anchez and J. J. Merelo", "title": "Emerging archetypes in massive artificial societies for literary\n  purposes using genetic algorithms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  The creation of fictional stories is a very complex task that usually implies\na creative process where the author has to combine characters, conflicts and\nplots to create an engaging narrative. This work presents a simulated\nenvironment with hundreds of characters that allows the study of coherent and\ninteresting literary archetypes (or behaviours), plots and sub-plots. We will\nuse this environment to perform a study about the number of profiles\n(parameters that define the personality of a character) needed to create two\nemergent scenes of archetypes: \"natality control\" and \"revenge\". A Genetic\nAlgorithm (GA) will be used to find the fittest number of profiles and\nparameter configuration that enables the existence of the desired archetypes\n(played by the characters without their explicit knowledge). The results show\nthat parametrizing this complex system is possible and that these kind of\narchetypes can emerge in the given environment.\n", "versions": [{"version": "v1", "created": "Wed, 12 Mar 2014 18:35:43 GMT"}], "update_date": "2014-03-14", "authors_parsed": [["Garc\u00eda-Ortega", "R. H.", ""], ["Garc\u00eda-S\u00e1nchez", "P.", ""], ["Merelo", "J. J.", ""]]}, {"id": "1403.3807", "submitter": "Bibo Hao", "authors": "Bibo Hao, Lin Li, Rui Gao, Ang Li, Tingshao Zhu", "title": "Sensing Subjective Well-being from Social Media", "comments": "12 pages, 1 figures, 2 tables, 10th International Conference, AMT\n  2014, Warsaw, Poland, August 11-14, 2014. Proceedings", "journal-ref": null, "doi": "10.1007/978-3-319-09912-5_27", "report-no": null, "categories": "cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Subjective Well-being(SWB), which refers to how people experience the quality\nof their lives, is of great use to public policy-makers as well as economic,\nsociological research, etc. Traditionally, the measurement of SWB relies on\ntime-consuming and costly self-report questionnaires. Nowadays, people are\nmotivated to share their experiences and feelings on social media, so we\npropose to sense SWB from the vast user generated data on social media. By\nutilizing 1785 users' social media data with SWB labels, we train machine\nlearning models that are able to \"sense\" individual SWB from users' social\nmedia. Our model, which attains the state-by-art prediction accuracy, can then\nbe used to identify SWB of large population of social media users in time with\nvery low cost.\n", "versions": [{"version": "v1", "created": "Sat, 15 Mar 2014 14:19:47 GMT"}, {"version": "v2", "created": "Thu, 28 Aug 2014 11:43:14 GMT"}], "update_date": "2014-08-29", "authors_parsed": [["Hao", "Bibo", ""], ["Li", "Lin", ""], ["Gao", "Rui", ""], ["Li", "Ang", ""], ["Zhu", "Tingshao", ""]]}, {"id": "1403.4023", "submitter": "David Budden", "authors": "David Budden, Peter Wang, Oliver Obst and Mikhail Prokopenko", "title": "Simulation leagues: Analysis of competition formats", "comments": "12 pages, 2 figures, presented at RoboCup 2014 symposium, Brazil", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The selection of an appropriate competition format is critical for both the\nsuccess and credibility of any competition, both real and simulated. In this\npaper, the automated parallelism offered by the RoboCupSoccer 2D simulation\nleague is leveraged to conduct a 28,000 game round-robin between the top 8\nteams from RoboCup 2012 and 2013. A proposed new competition format is found to\nreduce variation from the resultant statistically significant team performance\nrankings by 75% and 67%, when compared to the actual competition results from\nRoboCup 2012 and 2013 respectively. These results are statistically validated\nby generating 10,000 random tournaments for each of the three considered\nformats and comparing the respective distributions of ranking discrepancy.\n", "versions": [{"version": "v1", "created": "Mon, 17 Mar 2014 08:22:12 GMT"}, {"version": "v2", "created": "Thu, 26 Jun 2014 02:10:02 GMT"}], "update_date": "2014-06-27", "authors_parsed": [["Budden", "David", ""], ["Wang", "Peter", ""], ["Obst", "Oliver", ""], ["Prokopenko", "Mikhail", ""]]}, {"id": "1403.4682", "submitter": "Fei-Yun Zhu", "authors": "Feiyun Zhu, Ying Wang, Shiming Xiang, Bin Fan, Chunhong Pan", "title": "Structured Sparse Method for Hyperspectral Unmixing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hyperspectral Unmixing (HU) has received increasing attention in the past\ndecades due to its ability of unveiling information latent in hyperspectral\ndata. Unfortunately, most existing methods fail to take advantage of the\nspatial information in data. To overcome this limitation, we propose a\nStructured Sparse regularized Nonnegative Matrix Factorization (SS-NMF) method\nfrom the following two aspects. First, we incorporate a graph Laplacian to\nencode the manifold structures embedded in the hyperspectral data space. In\nthis way, the highly similar neighboring pixels can be grouped together.\nSecond, the lasso penalty is employed in SS-NMF for the fact that pixels in the\nsame manifold structure are sparsely mixed by a common set of relevant bases.\nThese two factors act as a new structured sparse constraint. With this\nconstraint, our method can learn a compact space, where highly similar pixels\nare grouped to share correlated sparse representations. Experiments on real\nhyperspectral data sets with different noise levels demonstrate that our method\noutperforms the state-of-the-art methods significantly.\n", "versions": [{"version": "v1", "created": "Wed, 19 Mar 2014 03:23:30 GMT"}], "update_date": "2014-07-14", "authors_parsed": [["Zhu", "Feiyun", ""], ["Wang", "Ying", ""], ["Xiang", "Shiming", ""], ["Fan", "Bin", ""], ["Pan", "Chunhong", ""]]}, {"id": "1403.5029", "submitter": "Wei Zhang", "authors": "Wei Zhang, Jae-Woong Chang, Lilong Lin, Kay Minn, Baolin Wu, Jeremy\n  Chien, Jeongsik Yong, Hui Zheng, Rui Kuang", "title": "Network-based Isoform Quantification with RNA-Seq Data for Cancer\n  Transcriptome Analysis", "comments": null, "journal-ref": null, "doi": "10.1371/journal.pcbi.1004465", "report-no": null, "categories": "cs.CE cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  High-throughput mRNA sequencing (RNA-Seq) is widely used for transcript\nquantification of gene isoforms. Since RNA-Seq data alone is often not\nsufficient to accurately identify the read origins from the isoforms for\nquantification, we propose to explore protein domain-domain interactions as\nprior knowledge for integrative analysis with RNA-seq data. We introduce a\nNetwork-based method for RNA-Seq-based Transcript Quantification (Net-RSTQ) to\nintegrate protein domain-domain interaction network with short read alignments\nfor transcript abundance estimation. Based on our observation that the\nabundances of the neighboring isoforms by domain-domain interactions in the\nnetwork are positively correlated, Net-RSTQ models the expression of the\nneighboring transcripts as Dirichlet priors on the likelihood of the observed\nread alignments against the transcripts in one gene. The transcript abundances\nof all the genes are then jointly estimated with alternating optimization of\nmultiple EM problems. In simulation Net-RSTQ effectively improved isoform\ntranscript quantifications when isoform co-expressions correlate with their\ninteractions. qRT-PCR results on 25 multi-isoform genes in a stem cell line, an\novarian cancer cell line, and a breast cancer cell line also showed that\nNet-RSTQ estimated more consistent isoform proportions with RNA-Seq data. In\nthe experiments on the RNA-Seq data in The Cancer Genome Atlas (TCGA), the\ntranscript abundances estimated by Net-RSTQ are more informative for patient\nsample classification of ovarian cancer, breast cancer and lung cancer. All\nexperimental results collectively support that Net-RSTQ is a promising approach\nfor isoform quantification.\n", "versions": [{"version": "v1", "created": "Thu, 20 Mar 2014 02:35:15 GMT"}, {"version": "v2", "created": "Fri, 20 Mar 2015 16:06:01 GMT"}, {"version": "v3", "created": "Tue, 15 Sep 2015 15:48:46 GMT"}], "update_date": "2015-12-31", "authors_parsed": [["Zhang", "Wei", ""], ["Chang", "Jae-Woong", ""], ["Lin", "Lilong", ""], ["Minn", "Kay", ""], ["Wu", "Baolin", ""], ["Chien", "Jeremy", ""], ["Yong", "Jeongsik", ""], ["Zheng", "Hui", ""], ["Kuang", "Rui", ""]]}, {"id": "1403.5045", "submitter": "Branislav Kveton", "authors": "Branislav Kveton, Zheng Wen, Azin Ashkan, Hoda Eydgahi, Brian Eriksson", "title": "Matroid Bandits: Fast Combinatorial Optimization with Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A matroid is a notion of independence in combinatorial optimization which is\nclosely related to computational efficiency. In particular, it is well known\nthat the maximum of a constrained modular function can be found greedily if and\nonly if the constraints are associated with a matroid. In this paper, we bring\ntogether the ideas of bandits and matroids, and propose a new class of\ncombinatorial bandits, matroid bandits. The objective in these problems is to\nlearn how to maximize a modular function on a matroid. This function is\nstochastic and initially unknown. We propose a practical algorithm for solving\nour problem, Optimistic Matroid Maximization (OMM); and prove two upper bounds,\ngap-dependent and gap-free, on its regret. Both bounds are sublinear in time\nand at most linear in all other quantities of interest. The gap-dependent upper\nbound is tight and we prove a matching lower bound on a partition matroid\nbandit. Finally, we evaluate our method on three real-world problems and show\nthat it is practical.\n", "versions": [{"version": "v1", "created": "Thu, 20 Mar 2014 05:52:43 GMT"}, {"version": "v2", "created": "Fri, 11 Apr 2014 06:25:22 GMT"}, {"version": "v3", "created": "Mon, 16 Jun 2014 20:23:34 GMT"}], "update_date": "2015-04-15", "authors_parsed": [["Kveton", "Branislav", ""], ["Wen", "Zheng", ""], ["Ashkan", "Azin", ""], ["Eydgahi", "Hoda", ""], ["Eriksson", "Brian", ""]]}, {"id": "1403.5142", "submitter": "Kostyantyn Shchekotykhin", "authors": "Kostyantyn Shchekotykhin", "title": "Interactive Debugging of ASP Programs", "comments": "Published in Proceedings of the 15th International Workshop on\n  Non-Monotonic Reasoning (NMR 2014)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Broad application of answer set programming (ASP) for declarative problem\nsolving requires the development of tools supporting the coding process.\nProgram debugging is one of the crucial activities within this process.\nRecently suggested ASP debugging approaches allow efficient computation of\npossible explanations of a fault. However, even for a small program a debugger\nmight return a large number of possible explanations and selection of the\ncorrect one must be done manually. In this paper we present an interactive\nquery-based ASP debugging method which extends previous approaches and finds a\npreferred explanation by means of observations. The system queries a programmer\nwhether a set of ground atoms must be true in all (cautiously) or some\n(bravely) answer sets of the program. Since some queries can be more\ninformative than the others, we discuss query selection strategies which, given\nuser's preferences for an explanation, can find the best query. That is, the\nquery an answer of which reduces the overall number of queries required for the\nidentification of a preferred explanation.\n", "versions": [{"version": "v1", "created": "Thu, 20 Mar 2014 14:22:58 GMT"}, {"version": "v2", "created": "Thu, 8 May 2014 06:58:31 GMT"}, {"version": "v3", "created": "Wed, 21 May 2014 19:39:14 GMT"}, {"version": "v4", "created": "Tue, 28 Oct 2014 13:16:04 GMT"}], "update_date": "2014-10-29", "authors_parsed": [["Shchekotykhin", "Kostyantyn", ""]]}, {"id": "1403.5169", "submitter": "Xinyang Deng", "authors": "Yunpeng Li, Ya Li, Jie Liu, Yong Deng", "title": "Defuzzify firstly or finally: Dose it matter in fuzzy DEMATEL under\n  uncertain environment?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Decision-Making Trial and Evaluation Laboratory (DEMATEL) method is widely\nused in many real applications. With the desirable property of efficient\nhandling with the uncertain information in decision making, the fuzzy DEMATEL\nis heavily studied. Recently, Dytczak and Ginda suggested to defuzzify the\nfuzzy numbers firstly and then use the classical DEMATEL to obtain the final\nresult. In this short paper, we show that it is not reasonable in some\nsituations. The results of defuzzification at the first step are not coincide\nwith the results of defuzzification at the final step.It seems that the\nalternative is to defuzzification in the final step in fuzzy DEMATEL.\n", "versions": [{"version": "v1", "created": "Thu, 20 Mar 2014 15:28:29 GMT"}], "update_date": "2014-03-21", "authors_parsed": [["Li", "Yunpeng", ""], ["Li", "Ya", ""], ["Liu", "Jie", ""], ["Deng", "Yong", ""]]}, {"id": "1403.5508", "submitter": "Stefania  Costantini", "authors": "Stefania Costantini", "title": "Towards Active Logic Programming", "comments": "This work was presented at the 2nd International Workshop on\n  Component-based Software Development in Computational Logic (COCL 1999). In\n  this paper, the DALI language was first introduced", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we present the new logic programming language DALI, aimed at\ndefining agents and agent systems. A main design objective for DALI has been\nthat of introducing in a declarative fashion all the essential features, while\nkeeping the language as close as possible to the syntax and semantics of the\nplain Horn--clause language. Special atoms and rules have been introduced, for\nrepresenting: external events, to which the agent is able to respond\n(reactivity); actions (reactivity and proactivity); internal events (previous\nconclusions which can trigger further activity); past and present events (to be\naware of what has happened). An extended resolution is provided, so that a DALI\nagent is able to answer queries like in the plain Horn--clause language, but is\nalso able to cope with the different kinds of events, and exhibit a (rational)\nreactive and proactive behaviour.\n", "versions": [{"version": "v1", "created": "Fri, 21 Mar 2014 16:22:17 GMT"}], "update_date": "2014-03-24", "authors_parsed": [["Costantini", "Stefania", ""]]}, {"id": "1403.5618", "submitter": "P\\\"ar-Ola Zander", "authors": "Shahadat Hossein, Par-Ola Zander, Md. Kamal, Linkon Chowdhury", "title": "Belief-Rule-Based Expert Systems for Evaluation of E- Government: A Case\n  Study", "comments": "Accepted with no Changes for Wiley Expert Systems", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Little knowledge exists on the impact and results associated with\ne-government projects in many specific use domains. Therefore it is necessary\nto evaluate the efficiency and effectiveness of e-government systems. Since the\ndevelopment of e-government is a continuous process of improvement, it requires\ncontinuous evaluation of the overall e-government system as well as evaluation\nof its various dimensions such as determinants, characteristics and results.\nE-government development is often complex with multiple stakeholders, large\nuser bases and complex goals. Consequently, even experts have difficulties in\nevaluating these systems, especially in an integrated and comprehensive way as\nwell as on an aggregate level. Expert systems are a candidate solution to\nevaluate such complex e-government systems. However, it is difficult for expert\nsystems to cope with uncertain evaluation data that are vague, inconsistent,\nhighly subjective or in other ways challenging to formalize. This paper\npresents an approach that can handle uncertainty in e-government evaluation:\nThe combination of Belief Rule Base (BRB) knowledge representation and\nEvidential Reasoning (ES). This approach is illustrated with a concrete\nprototype, known as Belief Rule Based Expert System (BRBES) and put to use in\nthe local e-government of Bangladesh. The results have been compared with a\nrecently developed method of evaluating e-Government, and it is shown that the\nresults of BRBES are more accurate and reliable. BRBES can be used to identify\nthe factors that need to be improved to achieve the overall aim of an\ne-government project. In addition, various \"what if\" scenarios can be generated\nand developers and managers can get a forecast of the outcomes. In this way,\nthe system can be used to facilitate decision making processes under\nuncertainty.\n", "versions": [{"version": "v1", "created": "Sat, 22 Mar 2014 05:56:26 GMT"}, {"version": "v2", "created": "Mon, 9 Mar 2015 09:35:48 GMT"}], "update_date": "2015-03-10", "authors_parsed": [["Hossein", "Shahadat", ""], ["Zander", "Par-Ola", ""], ["Kamal", "Md.", ""], ["Chowdhury", "Linkon", ""]]}, {"id": "1403.5701", "submitter": "Boris Toma\\v{s}", "authors": "Boris Tomas", "title": "Cortex simulation system proposal using distributed computer network\n  environments", "comments": "4 pages", "journal-ref": "IJCSIS Volume 12 No. 3 2014", "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/publicdomain/", "abstract": "  In the dawn of computer science and the eve of neuroscience we participate in\nrebirth of neuroscience due to new technology that allows us to deeply and\nprecisely explore whole new world that dwells in our brains.\n", "versions": [{"version": "v1", "created": "Sat, 22 Mar 2014 20:30:55 GMT"}], "update_date": "2014-03-25", "authors_parsed": [["Tomas", "Boris", ""]]}, {"id": "1403.5753", "submitter": "Xinyang Deng", "authors": "Xinyang Deng, Felix T.S. Chan, Rehan Sadiq, Sankaran Mahadevan, Yong\n  Deng", "title": "D-CFPR: D numbers extended consistent fuzzy preference relations", "comments": "28 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  How to express an expert's or a decision maker's preference for alternatives\nis an open issue. Consistent fuzzy preference relation (CFPR) is with big\nadvantages to handle this problem due to it can be construed via a smaller\nnumber of pairwise comparisons and satisfies additive transitivity property.\nHowever, the CFPR is incapable of dealing with the cases involving uncertain\nand incomplete information. In this paper, a D numbers extended consistent\nfuzzy preference relation (D-CFPR) is proposed to overcome the weakness. The\nD-CFPR extends the classical CFPR by using a new model of expressing uncertain\ninformation called D numbers. The D-CFPR inherits the merits of classical CFPR\nand can be totally reduced to the classical CFPR. This study can be integrated\ninto our previous study about D-AHP (D numbers extended AHP) model to provide a\nsystematic solution for multi-criteria decision making (MCDM).\n", "versions": [{"version": "v1", "created": "Sun, 23 Mar 2014 14:09:08 GMT"}], "update_date": "2014-03-25", "authors_parsed": [["Deng", "Xinyang", ""], ["Chan", "Felix T. S.", ""], ["Sadiq", "Rehan", ""], ["Mahadevan", "Sankaran", ""], ["Deng", "Yong", ""]]}, {"id": "1403.6036", "submitter": "C R Ramakrishnan", "authors": "Arun Nampally, C. R. Ramakrishnan", "title": "Adaptive MCMC-Based Inference in Probabilistic Logic Programs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Probabilistic Logic Programming (PLP) languages enable programmers to specify\nsystems that combine logical models with statistical knowledge. The inference\nproblem, to determine the probability of query answers in PLP, is intractable\nin general, thereby motivating the need for approximate techniques. In this\npaper, we present a technique for approximate inference of conditional\nprobabilities for PLP queries. It is an Adaptive Markov Chain Monte Carlo\n(MCMC) technique, where the distribution from which samples are drawn is\nmodified as the Markov Chain is explored. In particular, the distribution is\nprogressively modified to increase the likelihood that a generated sample is\nconsistent with evidence. In our context, each sample is uniquely characterized\nby the outcomes of a set of random variables. Inspired by reinforcement\nlearning, our technique propagates rewards to random variable/outcome pairs\nused in a sample based on whether the sample was consistent or not. The\ncumulative rewards of each outcome is used to derive a new \"adapted\ndistribution\" for each random variable. For a sequence of samples, the\ndistributions are progressively adapted after each sample. For a query with\n\"Markovian evaluation structure\", we show that the adapted distribution of\nsamples converges to the query's conditional probability distribution. For\nMarkovian queries, we present a modified adaptation process that can be used in\nadaptive MCMC as well as adaptive independent sampling. We empirically evaluate\nthe effectiveness of the adaptive sampling methods for queries with and without\nMarkovian evaluation structure.\n", "versions": [{"version": "v1", "created": "Mon, 24 Mar 2014 16:51:06 GMT"}], "update_date": "2014-03-25", "authors_parsed": [["Nampally", "Arun", ""], ["Ramakrishnan", "C. R.", ""]]}, {"id": "1403.6348", "submitter": "Bla\\v{z} Sovdat", "authors": "Blaz Sovdat", "title": "Updating Formulas and Algorithms for Computing Entropy and Gini Index\n  from Time-Changing Data Streams", "comments": "Added directions future work; more consistent notation; fixed the\n  errors in the updating algorithms for entropy; fixed an error in the\n  statement of theorem 5; added two references to related work; fixed a few\n  typos", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Despite growing interest in data stream mining the most successful\nincremental learners, such as VFDT, still use periodic recomputation to update\nattribute information gains and Gini indices. This note provides simple\nincremental formulas and algorithms for computing entropy and Gini index from\ntime-changing data streams.\n", "versions": [{"version": "v1", "created": "Tue, 25 Mar 2014 14:07:21 GMT"}, {"version": "v2", "created": "Sun, 6 Apr 2014 20:22:43 GMT"}, {"version": "v3", "created": "Mon, 28 Apr 2014 20:48:57 GMT"}, {"version": "v4", "created": "Thu, 4 Feb 2016 20:58:31 GMT"}, {"version": "v5", "created": "Sun, 7 Feb 2016 17:04:17 GMT"}, {"version": "v6", "created": "Sat, 30 Jul 2016 10:10:10 GMT"}], "update_date": "2016-08-02", "authors_parsed": [["Sovdat", "Blaz", ""]]}, {"id": "1403.6508", "submitter": "Xiaomin Lin", "authors": "Xiaomin Lin and Peter A. Beling and Randy Cogill", "title": "Multi-agent Inverse Reinforcement Learning for Two-person Zero-sum Games", "comments": null, "journal-ref": "IEEE Transactions on Games 10(1) (2018) 56-68", "doi": "10.1109/TCIAIG.2017.2679115", "report-no": null, "categories": "cs.GT cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The focus of this paper is a Bayesian framework for solving a class of\nproblems termed multi-agent inverse reinforcement learning (MIRL). Compared to\nthe well-known inverse reinforcement learning (IRL) problem, MIRL is formalized\nin the context of stochastic games, which generalize Markov decision processes\nto game theoretic scenarios. We establish a theoretical foundation for\ncompetitive two-agent zero-sum MIRL problems and propose a Bayesian solution\napproach in which the generative model is based on an assumption that the two\nagents follow a minimax bi-policy. Numerical results are presented comparing\nthe Bayesian MIRL method with two existing methods in the context of an\nabstract soccer game. Investigation centers on relationships between the extent\nof prior information and the quality of learned rewards. Results suggest that\ncovariance structure is more important than mean value in reward priors.\n", "versions": [{"version": "v1", "created": "Tue, 25 Mar 2014 21:03:57 GMT"}, {"version": "v2", "created": "Thu, 10 Apr 2014 22:51:35 GMT"}, {"version": "v3", "created": "Tue, 30 Jul 2019 01:28:36 GMT"}], "update_date": "2019-07-31", "authors_parsed": [["Lin", "Xiaomin", ""], ["Beling", "Peter A.", ""], ["Cogill", "Randy", ""]]}, {"id": "1403.6512", "submitter": "Jon Yaggie", "authors": "Gyorgy Turan, Jon Yaggie", "title": "Non-characterizability of belief revision: an application of finite\n  model theory", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.LO cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A formal framework is given for the characterizability of a class of belief\nrevision operators, defined using minimization over a class of partial\npreorders, by postulates. It is shown that for partial orders\ncharacterizability implies a definability property of the class of partial\norders in monadic second-order logic. Based on a non-definability result for a\nclass of partial orders, an example is given of a non-characterizable class of\nrevision operators. This appears to be the first non-characterizability result\nin belief revision.\n", "versions": [{"version": "v1", "created": "Tue, 25 Mar 2014 21:22:37 GMT"}, {"version": "v2", "created": "Mon, 31 Mar 2014 19:16:35 GMT"}], "update_date": "2014-04-01", "authors_parsed": [["Turan", "Gyorgy", ""], ["Yaggie", "Jon", ""]]}, {"id": "1403.7292", "submitter": "Arti Gupta Shambhuprasad", "authors": "Arti Gupta, Prof. N.T Deotale", "title": "A Mining Method to Create Knowledge Map by Analysing the Data Resource", "comments": "6 pages,5 figures, Published with International Journal of\n  Engineering Trends and Technology (IJETT)\"", "journal-ref": "International Journal of Engineering Trends and\n  Technology(IJETT),V9(9),430-435 March 2014", "doi": "10.14445/22315381/IJETT-V9P282", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The fundamental step in measuring the robustness of a system is the synthesis\nof the so called Process Map.This is generally based on the user raw data\nmaterial.Process Maps are of fundamental importance towards the understanding\nof the nature of a system in that they indicate which variables are causally\nrelated and which are particularly important.This paper represent the system\nMap or business structure map to understand business criteria studying the\nvarious aspects of the company.The business structure map or knowledge map or\nProcess map are used to increase the growth of the company by giving some\nuseful measures according to the business criteria.This paper also deals with\nthe different company strategy to reduce the risk factors.Process Map is\nhelpful for building such knowledge successfully.Making decisions from such map\nin a highly complex situation requires more knowledge and resources.\n", "versions": [{"version": "v1", "created": "Fri, 28 Mar 2014 07:35:56 GMT"}], "update_date": "2014-03-31", "authors_parsed": [["Gupta", "Arti", ""], ["Deotale", "Prof. N. T", ""]]}, {"id": "1403.7308", "submitter": "Marko Robnik-\\v{S}ikonja", "authors": "Marko Robnik-\\v{S}ikonja", "title": "Data Generators for Learning Systems Based on RBF Networks", "comments": null, "journal-ref": "IEEE Transaction on Neural Networks and Learning Systems,\n  27(5):926-938, 2016", "doi": "10.1109/TNNLS.2015.2429711", "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There are plenty of problems where the data available is scarce and\nexpensive. We propose a generator of semi-artificial data with similar\nproperties to the original data which enables development and testing of\ndifferent data mining algorithms and optimization of their parameters. The\ngenerated data allow a large scale experimentation and simulations without\ndanger of overfitting. The proposed generator is based on RBF networks, which\nlearn sets of Gaussian kernels. These Gaussian kernels can be used in a\ngenerative mode to generate new data from the same distributions. To assess\nquality of the generated data we evaluated the statistical properties of the\ngenerated data, structural similarity and predictive similarity using\nsupervised and unsupervised learning techniques. To determine usability of the\nproposed generator we conducted a large scale evaluation using 51 UCI data\nsets. The results show a considerable similarity between the original and\ngenerated data and indicate that the method can be useful in several\ndevelopment and simulation scenarios. We analyze possible improvements in\nclassification performance by adding different amounts of generated data to the\ntraining set, performance on high dimensional data sets, and conditions when\nthe proposed approach is successful.\n", "versions": [{"version": "v1", "created": "Fri, 28 Mar 2014 08:55:21 GMT"}, {"version": "v2", "created": "Sun, 19 Jul 2020 21:49:33 GMT"}], "update_date": "2020-07-21", "authors_parsed": [["Robnik-\u0160ikonja", "Marko", ""]]}, {"id": "1403.7373", "submitter": "Radek Pel\\'anek", "authors": "Radek Pel\\'anek", "title": "Difficulty Rating of Sudoku Puzzles: An Overview and Evaluation", "comments": "24 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  How can we predict the difficulty of a Sudoku puzzle? We give an overview of\ndifficulty rating metrics and evaluate them on extensive dataset on human\nproblem solving (more then 1700 Sudoku puzzles, hundreds of solvers). The best\nresults are obtained using a computational model of human solving activity.\nUsing the model we show that there are two sources of the problem difficulty:\ncomplexity of individual steps (logic operations) and structure of dependency\namong steps. We also describe metrics based on analysis of solutions under\nrelaxed constraints -- a novel approach inspired by phase transition phenomenon\nin the graph coloring problem. In our discussion we focus not just on the\nperformance of individual metrics on the Sudoku puzzle, but also on their\ngeneralizability and applicability to other problems.\n", "versions": [{"version": "v1", "created": "Fri, 28 Mar 2014 13:43:50 GMT"}], "update_date": "2014-03-31", "authors_parsed": [["Pel\u00e1nek", "Radek", ""]]}, {"id": "1403.7426", "submitter": "Ilche Georgievski", "authors": "Ilche Georgievski and Marco Aiello", "title": "An Overview of Hierarchical Task Network Planning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hierarchies are the most common structure used to understand the world\nbetter. In galaxies, for instance, multiple-star systems are organised in a\nhierarchical system. Then, governmental and company organisations are\nstructured using a hierarchy, while the Internet, which is used on a daily\nbasis, has a space of domain names arranged hierarchically. Since Artificial\nIntelligence (AI) planning portrays information about the world and reasons to\nsolve some of world's problems, Hierarchical Task Network (HTN) planning has\nbeen introduced almost 40 years ago to represent and deal with hierarchies. Its\nrequirement for rich domain knowledge to characterise the world enables HTN\nplanning to be very useful, but also to perform well. However, the history of\nalmost 40 years obfuscates the current understanding of HTN planning in terms\nof accomplishments, planning models, similarities and differences among\nhierarchical planners, and its current and objective image. On top of these\nissues, attention attracts the ability of hierarchical planning to truly cope\nwith the requirements of applications from the real world. We propose a\nframework-based approach to remedy this situation. First, we provide a basis\nfor defining different formal models of hierarchical planning, and define two\nmodels that comprise a large portion of HTN planners. Second, we provide a set\nof concepts that helps to interpret HTN planners from the aspect of their\nsearch space. Then, we analyse and compare the planners based on a variety of\nproperties organised in five segments, namely domain authoring, expressiveness,\ncompetence, performance and applicability. Furthermore, we select Web service\ncomposition as a real-world and current application, and classify and compare\nthe approaches that employ HTN planning to solve the problem of service\ncomposition. Finally, we conclude with our findings and present directions for\nfuture work.\n", "versions": [{"version": "v1", "created": "Fri, 28 Mar 2014 16:01:51 GMT"}], "update_date": "2014-03-31", "authors_parsed": [["Georgievski", "Ilche", ""], ["Aiello", "Marco", ""]]}, {"id": "1403.7465", "submitter": "Nisheeth Joshi", "authors": "Iti Mathur, Nisheeth Joshi, Hemant Darbari and Ajai Kumar", "title": "Shiva: A Framework for Graph Based Ontology Matching", "comments": null, "journal-ref": "International Journal of Computer Applications 89(11):30-34, March\n  2014", "doi": "10.5120/15678-4435", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Since long, corporations are looking for knowledge sources which can provide\nstructured description of data and can focus on meaning and shared\nunderstanding. Structures which can facilitate open world assumptions and can\nbe flexible enough to incorporate and recognize more than one name for an\nentity. A source whose major purpose is to facilitate human communication and\ninteroperability. Clearly, databases fail to provide these features and\nontologies have emerged as an alternative choice, but corporations working on\nsame domain tend to make different ontologies. The problem occurs when they\nwant to share their data/knowledge. Thus we need tools to merge ontologies into\none. This task is termed as ontology matching. This is an emerging area and\nstill we have to go a long way in having an ideal matcher which can produce\ngood results. In this paper we have shown a framework to matching ontologies\nusing graphs.\n", "versions": [{"version": "v1", "created": "Fri, 28 Mar 2014 18:00:13 GMT"}], "update_date": "2014-03-31", "authors_parsed": [["Mathur", "Iti", ""], ["Joshi", "Nisheeth", ""], ["Darbari", "Hemant", ""], ["Kumar", "Ajai", ""]]}, {"id": "1403.7766", "submitter": "Tejal Shah", "authors": "Tejal Shah, Fethi Rabhi, Pradeep Ray and Kerry Taylor", "title": "Enhancing Automated Decision Support across Medical and Oral Health\n  Domains with Semantic Web Technologies", "comments": "The paper has been published at the 24th Australasian Conference on\n  Information Systems, 4-6 Dec 2013, Melbourne. The paper can be found at:\n  http://mo.bf.rmit.edu.au/acis2013/382.pdf", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Research has shown that the general health and oral health of an individual\nare closely related. Accordingly, current practice of isolating the information\nbase of medical and oral health domains can be dangerous and detrimental to the\nhealth of the individual. However, technical issues such as heterogeneous data\ncollection and storage formats, limited sharing of patient information and lack\nof decision support over the shared information are the principal reasons for\nthe current state of affairs. To address these issues, the following research\ninvestigates the development and application of a cross-domain ontology and\nrules to build an evidence-based and reusable knowledge base consisting of the\ninter-dependent conditions from the two domains. Through example implementation\nof the knowledge base in Protege, we demonstrate the effectiveness of our\napproach in reasoning over and providing decision support for cross-domain\npatient information.\n", "versions": [{"version": "v1", "created": "Sun, 30 Mar 2014 14:20:22 GMT"}], "update_date": "2014-04-01", "authors_parsed": [["Shah", "Tejal", ""], ["Rabhi", "Fethi", ""], ["Ray", "Pradeep", ""], ["Taylor", "Kerry", ""]]}, {"id": "1403.8046", "submitter": "Marius Buliga", "authors": "Marius Buliga and Louis H. Kauffman", "title": "Chemlambda, universality and self-multiplication", "comments": "8 pages, 21 colour figures, conference paper submitted to ALIFE 14", "journal-ref": "ALIFE 2014: The Fourteenth International Conference on the\n  Synthesis and Simulation of Living Systems July 2014 p.490-497", "doi": "10.7551/978-0-262-32621-6-ch079", "report-no": null, "categories": "cs.AI math.GT math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present chemlambda (or the chemical concrete machine), an artificial\nchemistry with the following properties: (a) is Turing complete, (b) has a\nmodel of decentralized, distributed computing associated to it, (c) works at\nthe level of individual (artificial) molecules, subject of reversible, but\notherwise deterministic interactions with a small number of enzymes, (d)\nencodes information in the geometrical structure of the molecules and not in\ntheir numbers, (e) all interactions are purely local in space and time. This is\npart of a larger project to create computing, artificial chemistry and\nartificial life in a distributed context, using topological and graphical\nlanguages.\n", "versions": [{"version": "v1", "created": "Mon, 31 Mar 2014 15:25:34 GMT"}], "update_date": "2019-02-20", "authors_parsed": [["Buliga", "Marius", ""], ["Kauffman", "Louis H.", ""]]}, {"id": "1403.8118", "submitter": "Jochen Burghardt", "authors": "Jochen Burghardt", "title": "E-Generalization Using Grammars", "comments": "49 pages, 16 figures, author address given in header is meanwhile\n  outdated, full version of an article in the \"Artificial Intelligence\n  Journal\", appeared as technical report in 2003. An open-source C\n  implementation and some examples are found at the Ancillary files", "journal-ref": "Artificial Intelligence Journal (Elsevier), Vol.165, No.1, p.1-35,\n  2005", "doi": null, "report-no": null, "categories": "cs.LO cs.AI cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We extend the notion of anti-unification to cover equational theories and\npresent a method based on regular tree grammars to compute a finite\nrepresentation of E-generalization sets. We present a framework to combine\nInductive Logic Programming and E-generalization that includes an extension of\nPlotkin's lgg theorem to the equational case. We demonstrate the potential\npower of E-generalization by three example applications: computation of\nsuggestions for auxiliary lemmas in equational inductive proofs, computation of\nconstruction laws for given term sequences, and learning of screen editor\ncommand sequences.\n", "versions": [{"version": "v1", "created": "Fri, 28 Mar 2014 12:55:39 GMT"}, {"version": "v2", "created": "Tue, 21 Mar 2017 13:48:58 GMT"}], "update_date": "2017-09-05", "authors_parsed": [["Burghardt", "Jochen", ""]]}]