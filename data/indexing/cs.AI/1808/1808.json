[{"id": "1808.00033", "submitter": "Mengnan Du", "authors": "Mengnan Du, Ninghao Liu, Xia Hu", "title": "Techniques for Interpretable Machine Learning", "comments": "Accepted by Communications of the ACM (CACM), Review Article", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Interpretable machine learning tackles the important problem that humans\ncannot understand the behaviors of complex machine learning models and how\nthese models arrive at a particular decision. Although many approaches have\nbeen proposed, a comprehensive understanding of the achievements and challenges\nis still lacking. We provide a survey covering existing techniques to increase\nthe interpretability of machine learning models. We also discuss crucial issues\nthat the community should consider in future work such as designing\nuser-friendly explanations and developing comprehensive evaluation metrics to\nfurther push forward the area of interpretable machine learning.\n", "versions": [{"version": "v1", "created": "Tue, 31 Jul 2018 19:14:39 GMT"}, {"version": "v2", "created": "Mon, 10 Dec 2018 17:24:35 GMT"}, {"version": "v3", "created": "Sun, 19 May 2019 20:44:37 GMT"}], "update_date": "2019-05-21", "authors_parsed": [["Du", "Mengnan", ""], ["Liu", "Ninghao", ""], ["Hu", "Xia", ""]]}, {"id": "1808.00048", "submitter": "Christos Rodosthenous", "authors": "Christos Rodosthenous and Loizos Michael", "title": "Web-STAR: A Visual Web-Based IDE for a Story Comprehension System", "comments": "Under consideration in Theory and Practice of Logic Programming\n  (TPLP)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present Web-STAR, an online platform for story understanding built on top\nof the STAR reasoning engine for STory comprehension through ARgumentation. The\nplatform includes a web-based IDE, integration with the STAR system, and a web\nservice infrastructure to support integration with other systems that rely on\nstory understanding functionality to complete their tasks. The platform also\ndelivers a number of \"social\" features, including a community repository for\npublic story sharing with a built-in commenting system, and tools for\ncollaborative story editing that can be used for team development projects and\nfor educational purposes.\n", "versions": [{"version": "v1", "created": "Sat, 28 Jul 2018 05:09:27 GMT"}], "update_date": "2018-08-02", "authors_parsed": [["Rodosthenous", "Christos", ""], ["Michael", "Loizos", ""]]}, {"id": "1808.00068", "submitter": "Javad Rahimipour Anaraki", "authors": "Javad Rahimipour Anaraki, Saeed Samet, Mahdi Eftekhari, Chang Wook Ahn", "title": "A Fuzzy-Rough based Binary Shuffled Frog Leaping Algorithm for Feature\n  Selection", "comments": "24 pages, 11 Tables, 1 figure", "journal-ref": null, "doi": "10.5281/zenodo.1474575", "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Feature selection and attribute reduction are crucial problems, and widely\nused techniques in the field of machine learning, data mining and pattern\nrecognition to overcome the well-known phenomenon of the Curse of\nDimensionality, by either selecting a subset of features or removing unrelated\nones. This paper presents a new feature selection method that efficiently\ncarries out attribute reduction, thereby selecting the most informative\nfeatures of a dataset. It consists of two components: 1) a measure for feature\nsubset evaluation, and 2) a search strategy. For the evaluation measure, we\nhave employed the fuzzy-rough dependency degree (FRFDD) in the lower\napproximation-based fuzzy-rough feature selection (L-FRFS) due to its\neffectiveness in feature selection. As for the search strategy, a new version\nof a binary shuffled frog leaping algorithm is proposed (B-SFLA). The new\nfeature selection method is obtained by hybridizing the B-SFLA with the FRDD.\nNon-parametric statistical tests are conducted to compare the proposed approach\nwith several existing methods over twenty two datasets, including nine high\ndimensional and large ones, from the UCI repository. The experimental results\ndemonstrate that the B-SFLA approach significantly outperforms other\nmetaheuristic methods in terms of the number of selected features and the\nclassification accuracy.\n", "versions": [{"version": "v1", "created": "Tue, 31 Jul 2018 20:38:19 GMT"}], "update_date": "2018-11-26", "authors_parsed": [["Anaraki", "Javad Rahimipour", ""], ["Samet", "Saeed", ""], ["Eftekhari", "Mahdi", ""], ["Ahn", "Chang Wook", ""]]}, {"id": "1808.00076", "submitter": "Gabriel de Souza Pereira Moreira", "authors": "Gabriel de Souza P. Moreira, Felipe Ferreira, Adilson Marques da Cunha", "title": "News Session-Based Recommendations using Deep Neural Networks", "comments": "Accepted for the Third Workshop on Deep Learning for Recommender\n  Systems - DLRS 2018, October 02-07, 2018, Vancouver, Canada.\n  https://recsys.acm.org/recsys18/dlrs/", "journal-ref": null, "doi": "10.1145/3270323.3270328", "report-no": null, "categories": "cs.IR cs.AI cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  News recommender systems are aimed to personalize users experiences and help\nthem to discover relevant articles from a large and dynamic search space.\nTherefore, news domain is a challenging scenario for recommendations, due to\nits sparse user profiling, fast growing number of items, accelerated item's\nvalue decay, and users preferences dynamic shift. Some promising results have\nbeen recently achieved by the usage of Deep Learning techniques on Recommender\nSystems, specially for item's feature extraction and for session-based\nrecommendations with Recurrent Neural Networks. In this paper, it is proposed\nan instantiation of the CHAMELEON -- a Deep Learning Meta-Architecture for News\nRecommender Systems. This architecture is composed of two modules, the first\nresponsible to learn news articles representations, based on their text and\nmetadata, and the second module aimed to provide session-based recommendations\nusing Recurrent Neural Networks. The recommendation task addressed in this work\nis next-item prediction for users sessions: \"what is the next most likely\narticle a user might read in a session?\" Users sessions context is leveraged by\nthe architecture to provide additional information in such extreme cold-start\nscenario of news recommendation. Users' behavior and item features are both\nmerged in an hybrid recommendation approach. A temporal offline evaluation\nmethod is also proposed as a complementary contribution, for a more realistic\nevaluation of such task, considering dynamic factors that affect global\nreadership interests like popularity, recency, and seasonality. Experiments\nwith an extensive number of session-based recommendation methods were performed\nand the proposed instantiation of CHAMELEON meta-architecture obtained a\nsignificant relative improvement in top-n accuracy and ranking metrics (10% on\nHit Rate and 13% on MRR) over the best benchmark methods.\n", "versions": [{"version": "v1", "created": "Tue, 31 Jul 2018 21:15:54 GMT"}, {"version": "v2", "created": "Fri, 7 Sep 2018 01:02:00 GMT"}, {"version": "v3", "created": "Mon, 17 Sep 2018 03:09:58 GMT"}], "update_date": "2018-09-18", "authors_parsed": [["Moreira", "Gabriel de Souza P.", ""], ["Ferreira", "Felipe", ""], ["da Cunha", "Adilson Marques", ""]]}, {"id": "1808.00089", "submitter": "Biplav Srivastava", "authors": "Biplav Srivastava and Francesca Rossi", "title": "Towards Composable Bias Rating of AI Services", "comments": "6 pages, appeared in 2018 ACM/AAAI Conference on AI Ethics and\n  Society (AIES 2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A new wave of decision-support systems are being built today using AI\nservices that draw insights from data (like text and video) and incorporate\nthem in human-in-the-loop assistance. However, just as we expect humans to be\nethical, the same expectation needs to be met by automated systems that\nincreasingly get delegated to act on their behalf. A very important aspect of\nan ethical behavior is to avoid (intended, perceived, or accidental) bias. Bias\noccurs when the data distribution is not representative enough of the natural\nphenomenon one wants to model and reason about. The possibly biased behavior of\na service is hard to detect and handle if the AI service is merely being used\nand not developed from scratch, since the training data set is not available.\nIn this situation, we envisage a 3rd party rating agency that is independent of\nthe API producer or consumer and has its own set of biased and unbiased data,\nwith customizable distributions. We propose a 2-step rating approach that\ngenerates bias ratings signifying whether the AI service is unbiased\ncompensating, data-sensitive biased, or biased. The approach also works on\ncomposite services. We implement it in the context of text translation and\nreport interesting results.\n", "versions": [{"version": "v1", "created": "Tue, 31 Jul 2018 22:15:13 GMT"}, {"version": "v2", "created": "Mon, 14 Jan 2019 19:26:28 GMT"}], "update_date": "2019-01-16", "authors_parsed": [["Srivastava", "Biplav", ""], ["Rossi", "Francesca", ""]]}, {"id": "1808.00130", "submitter": "Duo Lu", "authors": "Duo Lu, Dijiang Huang", "title": "FMCode: A 3D In-the-Air Finger Motion Based User Login Framework for\n  Gesture Interface", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Applications using gesture-based human-computer interface require a new user\nlogin method with gestures because it does not have a traditional input method\nto type a password. However, due to various challenges, existing gesture-based\nauthentication systems are generally considered too weak to be useful in\npractice. In this paper, we propose a unified user login framework using 3D\nin-air-handwriting, called FMCode. We define new types of features critical to\ndistinguish legitimate users from attackers and utilize Support Vector Machine\n(SVM) for user authentication. The features and data-driven models are\nspecially designed to accommodate minor behavior variations that existing\ngesture authentication methods neglect. In addition, we use deep neural network\napproaches to efficiently identify the user based on his or her\nin-air-handwriting, which avoids expansive account database search methods\nemployed by existing work. On a dataset collected by us with over 100 users,\nour prototype system achieves 0.1% and 0.5% best Equal Error Rate (EER) for\nuser authentication, as well as 96.7% and 94.3% accuracy for user\nidentification, using two types of gesture input devices. Compared to existing\nbehavioral biometric systems using gesture and in-air-handwriting, our\nframework achieves the state-of-the-art performance. In addition, our\nexperimental results show that FMCode is capable to defend against client-side\nspoofing attacks, and it performs persistently in the long run. These results\nand discoveries pave the way to practical usage of gesture-based user login\nover the gesture interface.\n", "versions": [{"version": "v1", "created": "Wed, 1 Aug 2018 01:24:22 GMT"}], "update_date": "2018-08-02", "authors_parsed": [["Lu", "Duo", ""], ["Huang", "Dijiang", ""]]}, {"id": "1808.00177", "submitter": "OpenAI OpenAI", "authors": "OpenAI, Marcin Andrychowicz, Bowen Baker, Maciek Chociej, Rafal\n  Jozefowicz, Bob McGrew, Jakub Pachocki, Arthur Petron, Matthias Plappert,\n  Glenn Powell, Alex Ray, Jonas Schneider, Szymon Sidor, Josh Tobin, Peter\n  Welinder, Lilian Weng, Wojciech Zaremba", "title": "Learning Dexterous In-Hand Manipulation", "comments": "Making OpenAI the first author. We wish this paper to be cited as\n  \"Learning Dexterous In-Hand Manipulation\" by OpenAI et al. We are replicating\n  the approach from the physics community: arXiv:1812.06489", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We use reinforcement learning (RL) to learn dexterous in-hand manipulation\npolicies which can perform vision-based object reorientation on a physical\nShadow Dexterous Hand. The training is performed in a simulated environment in\nwhich we randomize many of the physical properties of the system like friction\ncoefficients and an object's appearance. Our policies transfer to the physical\nrobot despite being trained entirely in simulation. Our method does not rely on\nany human demonstrations, but many behaviors found in human manipulation emerge\nnaturally, including finger gaiting, multi-finger coordination, and the\ncontrolled use of gravity. Our results were obtained using the same distributed\nRL system that was used to train OpenAI Five. We also include a video of our\nresults: https://youtu.be/jwSbzNHGflM\n", "versions": [{"version": "v1", "created": "Wed, 1 Aug 2018 06:02:36 GMT"}, {"version": "v2", "created": "Tue, 28 Aug 2018 09:08:32 GMT"}, {"version": "v3", "created": "Tue, 15 Jan 2019 02:26:22 GMT"}, {"version": "v4", "created": "Wed, 16 Jan 2019 01:52:36 GMT"}, {"version": "v5", "created": "Fri, 18 Jan 2019 23:26:53 GMT"}], "update_date": "2019-01-23", "authors_parsed": [["OpenAI", "", ""], ["Andrychowicz", "Marcin", ""], ["Baker", "Bowen", ""], ["Chociej", "Maciek", ""], ["Jozefowicz", "Rafal", ""], ["McGrew", "Bob", ""], ["Pachocki", "Jakub", ""], ["Petron", "Arthur", ""], ["Plappert", "Matthias", ""], ["Powell", "Glenn", ""], ["Ray", "Alex", ""], ["Schneider", "Jonas", ""], ["Sidor", "Szymon", ""], ["Tobin", "Josh", ""], ["Welinder", "Peter", ""], ["Weng", "Lilian", ""], ["Zaremba", "Wojciech", ""]]}, {"id": "1808.00222", "submitter": "Amir Ramezani Dooraki Mr", "authors": "Amir Ramezani Dooraki", "title": "Experience, Imitation and Reflection; Confucius' Conjecture and Machine\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Artificial intelligence recently had a great advancements caused by the\nemergence of new processing power and machine learning methods. Having said\nthat, the learning capability of artificial intelligence is still at its\ninfancy comparing to the learning capability of human and many animals. Many of\nthe current artificial intelligence applications can only operate in a very\norchestrated, specific environments with an extensive training set that exactly\ndescribes the conditions that will occur during execution time. Having that in\nmind, and considering the several existing machine learning methods this\nquestion rises that 'What are some of the best ways for a machine to learn?'\nRegarding the learning methods of human, Confucius' point of view is that they\nare by experience, imitation and reflection. This paper tries to explore and\ndiscuss regarding these three ways of learning and their implementations in\nmachines by having a look at how they happen in minds.\n", "versions": [{"version": "v1", "created": "Wed, 1 Aug 2018 08:27:27 GMT"}], "update_date": "2018-08-02", "authors_parsed": [["Dooraki", "Amir Ramezani", ""]]}, {"id": "1808.00265", "submitter": "Yundong Zhang", "authors": "Yundong Zhang, Juan Carlos Niebles, Alvaro Soto", "title": "Interpretable Visual Question Answering by Visual Grounding from\n  Attention Supervision Mining", "comments": "8 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A key aspect of VQA models that are interpretable is their ability to ground\ntheir answers to relevant regions in the image. Current approaches with this\ncapability rely on supervised learning and human annotated groundings to train\nattention mechanisms inside the VQA architecture. Unfortunately, obtaining\nhuman annotations specific for visual grounding is difficult and expensive. In\nthis work, we demonstrate that we can effectively train a VQA architecture with\ngrounding supervision that can be automatically obtained from available region\ndescriptions and object annotations. We also show that our model trained with\nthis mined supervision generates visual groundings that achieve a higher\ncorrelation with respect to manually-annotated groundings, meanwhile achieving\nstate-of-the-art VQA accuracy.\n", "versions": [{"version": "v1", "created": "Wed, 1 Aug 2018 11:06:08 GMT"}], "update_date": "2018-08-02", "authors_parsed": [["Zhang", "Yundong", ""], ["Niebles", "Juan Carlos", ""], ["Soto", "Alvaro", ""]]}, {"id": "1808.00300", "submitter": "Mateusz Malinowski", "authors": "Mateusz Malinowski and Carl Doersch and Adam Santoro and Peter\n  Battaglia", "title": "Learning Visual Question Answering by Bootstrapping Hard Attention", "comments": "ECCV 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CL cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Attention mechanisms in biological perception are thought to select subsets\nof perceptual information for more sophisticated processing which would be\nprohibitive to perform on all sensory inputs. In computer vision, however,\nthere has been relatively little exploration of hard attention, where some\ninformation is selectively ignored, in spite of the success of soft attention,\nwhere information is re-weighted and aggregated, but never filtered out. Here,\nwe introduce a new approach for hard attention and find it achieves very\ncompetitive performance on a recently-released visual question answering\ndatasets, equalling and in some cases surpassing similar soft attention\narchitectures while entirely ignoring some features. Even though the hard\nattention mechanism is thought to be non-differentiable, we found that the\nfeature magnitudes correlate with semantic relevance, and provide a useful\nsignal for our mechanism's attentional selection criterion. Because hard\nattention selects important features of the input information, it can also be\nmore efficient than analogous soft attention mechanisms. This is especially\nimportant for recent approaches that use non-local pairwise operations, whereby\ncomputational and memory costs are quadratic in the size of the set of\nfeatures.\n", "versions": [{"version": "v1", "created": "Wed, 1 Aug 2018 12:39:43 GMT"}], "update_date": "2018-08-02", "authors_parsed": [["Malinowski", "Mateusz", ""], ["Doersch", "Carl", ""], ["Santoro", "Adam", ""], ["Battaglia", "Peter", ""]]}, {"id": "1808.00329", "submitter": "Sabina Marchetti", "authors": "Sabina Marchetti, Alessandro Antonucci", "title": "Imaginary Kinematics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a novel class of adjustment rules for a collection of beliefs.\nThis is an extension of Lewis' imaging to absorb probabilistic evidence in\ngeneralized settings. Unlike standard tools for belief revision, our proposal\nmay be used when information is inconsistent with an agent's belief base. We\nshow that the functionals we introduce are based on the imaginary counterpart\nof probability kinematics for standard belief revision, and prove that, under\ncertain conditions, all standard postulates for belief revision are satisfied.\n", "versions": [{"version": "v1", "created": "Wed, 1 Aug 2018 14:13:59 GMT"}], "update_date": "2018-08-02", "authors_parsed": [["Marchetti", "Sabina", ""], ["Antonucci", "Alessandro", ""]]}, {"id": "1808.00417", "submitter": "Carmine Dodaro", "authors": "Carmine Dodaro, Philip Gasteiger, Kristian Reale, Francesco Ricca,\n  Konstantin Schekotihin", "title": "Debugging Non-Ground ASP Programs: Technique and Graphical Tools", "comments": "27 pages, 6 figures, Under consideration in Theory and Practice of\n  Logic Programming (TPLP)", "journal-ref": "Theory and Practice of Logic Programming 19 (2019) 290-316", "doi": "10.1017/S1471068418000492", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Answer Set Programming (ASP) is one of the major declarative programming\nparadigms in the area of logic programming and non-monotonic reasoning. Despite\nthat ASP features a simple syntax and an intuitive semantics, errors are common\nduring the development of ASP programs. In this paper we propose a novel\ndebugging approach allowing for interactive localization of bugs in non-ground\nprograms. The new approach points the user directly to a set of non-ground\nrules involved in the bug, which might be refined (up to the point in which the\nbug is easily identified) by asking the programmer a sequence of questions on\nan expected answer set. The approach has been implemented on top of the ASP\nsolver WASP. The resulting debugger has been complemented by a user-friendly\ngraphical interface, and integrated in ASPIDE, a rich IDE for answer set\nprograms. In addition, an empirical analysis shows that the new debugger is not\naffected by the grounding blowup limiting the application of previous\napproaches based on meta-programming. Under consideration in Theory and\nPractice of Logic Programming (TPLP).\n", "versions": [{"version": "v1", "created": "Wed, 1 Aug 2018 16:59:01 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Dodaro", "Carmine", ""], ["Gasteiger", "Philip", ""], ["Reale", "Kristian", ""], ["Ricca", "Francesco", ""], ["Schekotihin", "Konstantin", ""]]}, {"id": "1808.00434", "submitter": "Michael Cochez", "authors": "Martina Garofalo and Maria Angela Pellegrino and Abdulrahman Altabba\n  and Michael Cochez", "title": "Leveraging Knowledge Graph Embedding Techniques for Industry 4.0 Use\n  Cases", "comments": "Accepted for publication in NATO Science Series. arXiv admin note:\n  text overlap with arXiv:1709.07604 by other authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Industry is evolving towards Industry 4.0, which holds the promise of\nincreased flexibility in manufacturing, better quality and improved\nproductivity. A core actor of this growth is using sensors, which must capture\ndata that can used in unforeseen ways to achieve a performance not achievable\nwithout them. However, the complexity of this improved setting is much greater\nthan what is currently used in practice. Hence, it is imperative that the\nmanagement cannot only be performed by human labor force, but part of that will\nbe done by automated algorithms instead. A natural way to represent the data\ngenerated by this large amount of sensors, which are not acting measuring\nindependent variables, and the interaction of the different devices is by using\na graph data model. Then, machine learning could be used to aid the Industry\n4.0 system to, for example, perform predictive maintenance. However, machine\nlearning directly on graphs, needs feature engineering and has scalability\nissues. In this paper we discuss methods to convert (embed) the graph in a\nvector space, such that it becomes feasible to use traditional machine learning\nmethods for Industry 4.0 settings.\n", "versions": [{"version": "v1", "created": "Tue, 31 Jul 2018 11:26:46 GMT"}], "update_date": "2018-08-02", "authors_parsed": [["Garofalo", "Martina", ""], ["Pellegrino", "Maria Angela", ""], ["Altabba", "Abdulrahman", ""], ["Cochez", "Michael", ""]]}, {"id": "1808.00496", "submitter": "Ini Oguntola", "authors": "Ini Oguntola, Subby Olubeko, Christopher Sweeney", "title": "SlimNets: An Exploration of Deep Model Compression and Acceleration", "comments": "To be published in 2018 IEEE High Performance Extreme Computing\n  Conference (HPEC)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks have achieved increasingly accurate results on a wide\nvariety of complex tasks. However, much of this improvement is due to the\ngrowing use and availability of computational resources (e.g use of GPUs, more\nlayers, more parameters, etc). Most state-of-the-art deep networks, despite\nperforming well, over-parameterize approximate functions and take a significant\namount of time to train. With increased focus on deploying deep neural networks\non resource constrained devices like smart phones, there has been a push to\nevaluate why these models are so resource hungry and how they can be made more\nefficient. This work evaluates and compares three distinct methods for deep\nmodel compression and acceleration: weight pruning, low rank factorization, and\nknowledge distillation. Comparisons on VGG nets trained on CIFAR10 show that\neach of the models on their own are effective, but that the true power lies in\ncombining them. We show that by combining pruning and knowledge distillation\nmethods we can create a compressed network 85 times smaller than the original,\nall while retaining 96% of the original model's accuracy.\n", "versions": [{"version": "v1", "created": "Wed, 1 Aug 2018 18:28:12 GMT"}], "update_date": "2018-08-03", "authors_parsed": [["Oguntola", "Ini", ""], ["Olubeko", "Subby", ""], ["Sweeney", "Christopher", ""]]}, {"id": "1808.00590", "submitter": "Yang Zhang", "authors": "Lucjan Hanzlik, Yang Zhang, Kathrin Grosse, Ahmed Salem, Max Augustin,\n  Michael Backes, Mario Fritz", "title": "MLCapsule: Guarded Offline Deployment of Machine Learning as a Service", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the widespread use of machine learning (ML) techniques, ML as a service\nhas become increasingly popular. In this setting, an ML model resides on a\nserver and users can query it with their data via an API. However, if the\nuser's input is sensitive, sending it to the server is undesirable and\nsometimes even legally not possible. Equally, the service provider does not\nwant to share the model by sending it to the client for protecting its\nintellectual property and pay-per-query business model.\n  In this paper, we propose MLCapsule, a guarded offline deployment of machine\nlearning as a service. MLCapsule executes the model locally on the user's side\nand therefore the data never leaves the client. Meanwhile, MLCapsule offers the\nservice provider the same level of control and security of its model as the\ncommonly used server-side execution. In addition, MLCapsule is applicable to\noffline applications that require local execution. Beyond protecting against\ndirect model access, we couple the secure offline deployment with defenses\nagainst advanced attacks on machine learning models such as model stealing,\nreverse engineering, and membership inference.\n", "versions": [{"version": "v1", "created": "Wed, 1 Aug 2018 22:45:48 GMT"}, {"version": "v2", "created": "Wed, 6 Feb 2019 17:02:07 GMT"}], "update_date": "2019-02-07", "authors_parsed": [["Hanzlik", "Lucjan", ""], ["Zhang", "Yang", ""], ["Grosse", "Kathrin", ""], ["Salem", "Ahmed", ""], ["Augustin", "Max", ""], ["Backes", "Michael", ""], ["Fritz", "Mario", ""]]}, {"id": "1808.00677", "submitter": "Yuting Gao", "authors": "Yuting Gao, Zheng Huang, Yuchen Dai, Cheng Xu, Kai Chen, Jie Tuo", "title": "Double Supervised Network with Attention Mechanism for Scene Text\n  Recognition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose Double Supervised Network with Attention Mechanism\n(DSAN), a novel end-to-end trainable framework for scene text recognition. It\nincorporates one text attention module during feature extraction which enforces\nthe model to focus on text regions and the whole framework is supervised by two\nbranches. One supervision branch comes from context-level modelling and another\ncomes from one extra supervision enhancement branch which aims at tackling\ninexplicit semantic information at character level. These two supervisions can\nbenefit each other and yield better performance. The proposed approach can\nrecognize text in arbitrary length and does not need any predefined lexicon.\nOur method outperforms the current state-of-the-art methods on three text\nrecognition benchmarks: IIIT5K, ICDAR2013 and SVT reaching accuracy 88.6%,\n92.3% and 84.1% respectively which suggests the effectiveness of the proposed\nmethod.\n", "versions": [{"version": "v1", "created": "Thu, 2 Aug 2018 06:01:52 GMT"}, {"version": "v2", "created": "Sun, 19 May 2019 10:36:15 GMT"}, {"version": "v3", "created": "Tue, 22 Oct 2019 13:05:11 GMT"}], "update_date": "2019-10-23", "authors_parsed": [["Gao", "Yuting", ""], ["Huang", "Zheng", ""], ["Dai", "Yuchen", ""], ["Xu", "Cheng", ""], ["Chen", "Kai", ""], ["Tuo", "Jie", ""]]}, {"id": "1808.00679", "submitter": "Alex James Dr", "authors": "Irina Dolzhikova, Khaled Salama, Vipin Kizheppatt, Alex Pappachen\n  James", "title": "Memristor-based Synaptic Sampling Machines", "comments": null, "journal-ref": "IEEE NANO, 2018", "doi": null, "report-no": null, "categories": "cs.ET cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Synaptic Sampling Machine (SSM) is a type of neural network model that\nconsiders biological unreliability of the synapses. We propose the circuit\ndesign of the SSM neural network which is realized through the memristive-CMOS\ncrossbar structure with the synaptic sampling cell (SSC) being used as a basic\nstochastic unit. The increase in the edge computing devices in the Internet of\nthings era, drives the need for hardware acceleration for data processing and\ncomputing. The computational considerations of the processing speed and\npossibility for the real-time realization pushes the synaptic sampling\nalgorithm that demonstrated promising results on software for hardware\nimplementation.\n", "versions": [{"version": "v1", "created": "Thu, 2 Aug 2018 06:05:07 GMT"}], "update_date": "2018-08-03", "authors_parsed": [["Dolzhikova", "Irina", ""], ["Salama", "Khaled", ""], ["Kizheppatt", "Vipin", ""], ["James", "Alex Pappachen", ""]]}, {"id": "1808.00727", "submitter": "Christoph Redl", "authors": "Christoph Redl", "title": "Inlining External Sources in Answer Set Programs", "comments": "Under consideration in Theory and Practice of Logic Programming\n  (TPLP)", "journal-ref": "Theory and Practice of Logic Programming 19 (2019) 360-411", "doi": "10.1017/S147106841800056X", "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  HEX-programs are an extension of answer set programs (ASP) with external\nsources. To this end, external atoms provide a bidirectional interface between\nthe program and an external source. The traditional evaluation algorithm for\nHEX-programs is based on guessing truth values of external atoms and verifying\nthem by explicit calls of the external source. The approach was optimized by\ntechniques that reduce the number of necessary verification calls or speed them\nup, but the remaining external calls are still expensive. In this paper we\npresent an alternative evaluation approach based on inlining of external atoms,\nmotivated by existing but less general approaches for specialized formalisms\nsuch as DL-programs. External atoms are then compiled away such that no\nverification calls are necessary. The approach is implemented in the dlvhex\nreasoner. Experiments show a significant performance gain. Besides performance\nimprovements, we further exploit inlining for extending previous (semantic)\ncharacterizations of program equivalence from ASP to HEX-programs, including\nthose of strong equivalence, uniform equivalence and H, B -equivalence.\nFinally, based on these equivalence criteria, we characterize also\ninconsistency of programs wrt. extensions. Since well-known ASP extensions\n(such as constraint ASP) are special cases of HEX, the results are interesting\nbeyond the particular formalism. Under consideration in Theory and Practice of\nLogic Programming (TPLP).\n", "versions": [{"version": "v1", "created": "Thu, 2 Aug 2018 09:32:20 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Redl", "Christoph", ""]]}, {"id": "1808.00733", "submitter": "Alex James Dr", "authors": "Olga Krestinskaya, Alex Pappachen James", "title": "Approximate Probabilistic Neural Networks with Gated Threshold Logic", "comments": null, "journal-ref": "IEEE NANO 2018", "doi": null, "report-no": null, "categories": "cs.ET cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Probabilistic Neural Network (PNN) is a feed-forward artificial neural\nnetwork developed for solving classification problems. This paper proposes a\nhardware implementation of an approximated PNN (APNN) algorithm in which the\nconventional exponential function of the PNN is replaced with gated threshold\nlogic. The weights of the PNN are approximated using a memristive crossbar\narchitecture. In particular, the proposed algorithm performs normalization of\nthe training weights, and quantization into 16 levels which significantly\nreduces the complexity of the circuit.\n", "versions": [{"version": "v1", "created": "Thu, 2 Aug 2018 09:48:11 GMT"}], "update_date": "2018-08-03", "authors_parsed": [["Krestinskaya", "Olga", ""], ["James", "Alex Pappachen", ""]]}, {"id": "1808.00737", "submitter": "Alex James Dr", "authors": "Olga Krestinskaya, Alex Pappachen James", "title": "Binary Weighted Memristive Analog Deep Neural Network for Near-Sensor\n  Edge Processing", "comments": null, "journal-ref": "IEEE NANO 2018", "doi": null, "report-no": null, "categories": "cs.ET cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The memristive crossbar aims to implement analog weighted neural network,\nhowever, the realistic implementation of such crossbar arrays is not possible\ndue to limited switching states of memristive devices. In this work, we propose\nthe design of an analog deep neural network with binary weight update through\nbackpropagation algorithm using binary state memristive devices. We show that\nsuch networks can be successfully used for image processing task and has the\nadvantage of lower power consumption and small on-chip area in comparison with\ndigital counterparts. The proposed network was benchmarked for MNIST\nhandwritten digits recognition achieving an accuracy of approximately 90%.\n", "versions": [{"version": "v1", "created": "Thu, 2 Aug 2018 09:51:07 GMT"}], "update_date": "2018-08-03", "authors_parsed": [["Krestinskaya", "Olga", ""], ["James", "Alex Pappachen", ""]]}, {"id": "1808.00758", "submitter": "Bo Yang", "authors": "Bo Yang, Sen Wang, Andrew Markham, Niki Trigoni", "title": "Robust Attentional Aggregation of Deep Feature Sets for Multi-view 3D\n  Reconstruction", "comments": "IJCV 2019. Code and data are available at\n  https://github.com/Yang7879/AttSets", "journal-ref": null, "doi": "10.1007/s11263-019-01217-w", "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of recovering an underlying 3D shape from a set of\nimages. Existing learning based approaches usually resort to recurrent neural\nnets, e.g., GRU, or intuitive pooling operations, e.g., max/mean poolings, to\nfuse multiple deep features encoded from input images. However, GRU based\napproaches are unable to consistently estimate 3D shapes given different\npermutations of the same set of input images as the recurrent unit is\npermutation variant. It is also unlikely to refine the 3D shape given more\nimages due to the long-term memory loss of GRU. Commonly used pooling\napproaches are limited to capturing partial information, e.g., max/mean values,\nignoring other valuable features. In this paper, we present a new feed-forward\nneural module, named AttSets, together with a dedicated training algorithm,\nnamed FASet, to attentively aggregate an arbitrarily sized deep feature set for\nmulti-view 3D reconstruction. The AttSets module is permutation invariant,\ncomputationally efficient and flexible to implement, while the FASet algorithm\nenables the AttSets based network to be remarkably robust and generalize to an\narbitrary number of input images. We thoroughly evaluate FASet and the\nproperties of AttSets on multiple large public datasets. Extensive experiments\nshow that AttSets together with FASet algorithm significantly outperforms\nexisting aggregation approaches.\n", "versions": [{"version": "v1", "created": "Thu, 2 Aug 2018 11:09:13 GMT"}, {"version": "v2", "created": "Sun, 18 Aug 2019 06:32:40 GMT"}], "update_date": "2019-08-20", "authors_parsed": [["Yang", "Bo", ""], ["Wang", "Sen", ""], ["Markham", "Andrew", ""], ["Trigoni", "Niki", ""]]}, {"id": "1808.00934", "submitter": "Enayat Ullah", "authors": "Enayat Ullah, Poorya Mianjy, Teodor V. Marinov, Raman Arora", "title": "Streaming Kernel PCA with $\\tilde{O}(\\sqrt{n})$ Random Features", "comments": "Advances in Neural Information Processing Systems (NIPS), 2018. 42\n  pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the statistical and computational aspects of kernel principal\ncomponent analysis using random Fourier features and show that under mild\nassumptions, $O(\\sqrt{n} \\log n)$ features suffices to achieve\n$O(1/\\epsilon^2)$ sample complexity. Furthermore, we give a memory efficient\nstreaming algorithm based on classical Oja's algorithm that achieves this rate.\n", "versions": [{"version": "v1", "created": "Thu, 2 Aug 2018 17:41:15 GMT"}, {"version": "v2", "created": "Thu, 15 Nov 2018 21:22:58 GMT"}], "update_date": "2018-11-19", "authors_parsed": [["Ullah", "Enayat", ""], ["Mianjy", "Poorya", ""], ["Marinov", "Teodor V.", ""], ["Arora", "Raman", ""]]}, {"id": "1808.00981", "submitter": "Trevor Buteau", "authors": "Trevor Buteau and Damian Lyons", "title": "Constructionist Steps Towards an Autonomously Empathetic System", "comments": "Submitted for SIGCHI ICMI 2018's Late-Breaking-Work track", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.HC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Prior efforts to create an autonomous computer system capable of predicting\nwhat a human being is thinking or feeling from facial expression data have been\nlargely based on outdated, inaccurate models of how emotions work that rely on\nmany scientifically questionable assumptions. In our research, we are creating\nan empathetic system that incorporates the latest provable scientific\nunderstanding of emotions: that they are constructs of the human mind, rather\nthan universal expressions of distinct internal states. Thus, our system uses a\nuser-dependent method of analysis and relies heavily on contextual information\nto make predictions about what subjects are experiencing. Our system's accuracy\nand therefore usefulness are built on provable ground truths that prohibit the\ndrawing of inaccurate conclusions that other systems could too easily make.\n", "versions": [{"version": "v1", "created": "Thu, 2 Aug 2018 18:14:23 GMT"}], "update_date": "2018-08-06", "authors_parsed": [["Buteau", "Trevor", ""], ["Lyons", "Damian", ""]]}, {"id": "1808.01174", "submitter": "Daniel Jakubovitz", "authors": "Daniel Jakubovitz, Raja Giryes, Miguel R. D. Rodrigues", "title": "Generalization Error in Deep Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning models have lately shown great performance in various fields\nsuch as computer vision, speech recognition, speech translation, and natural\nlanguage processing. However, alongside their state-of-the-art performance, it\nis still generally unclear what is the source of their generalization ability.\nThus, an important question is what makes deep neural networks able to\ngeneralize well from the training set to new data. In this article, we provide\nan overview of the existing theory and bounds for the characterization of the\ngeneralization error of deep neural networks, combining both classical and more\nrecent theoretical and empirical results.\n", "versions": [{"version": "v1", "created": "Fri, 3 Aug 2018 12:57:12 GMT"}, {"version": "v2", "created": "Thu, 20 Dec 2018 13:34:09 GMT"}, {"version": "v3", "created": "Sat, 6 Apr 2019 15:25:50 GMT"}], "update_date": "2019-04-09", "authors_parsed": [["Jakubovitz", "Daniel", ""], ["Giryes", "Raja", ""], ["Rodrigues", "Miguel R. D.", ""]]}, {"id": "1808.01262", "submitter": "Hendrik Baier", "authors": "Timothy Atkinson, Hendrik Baier, Tara Copplestone, Sam Devlin, Jerry\n  Swan", "title": "The Text-Based Adventure AI Competition", "comments": "updated to journal version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In 2016, 2017, and 2018 at the IEEE Conference on Computational Intelligence\nin Games, the authors of this paper ran a competition for agents that can play\nclassic text-based adventure games. This competition fills a gap in existing\ngame AI competitions that have typically focussed on traditional card/board\ngames or modern video games with graphical interfaces. By providing a platform\nfor evaluating agents in text-based adventures, the competition provides a\nnovel benchmark for game AI with unique challenges for natural language\nunderstanding and generation. This paper summarises the three competitions ran\nin 2016, 2017, and 2018 (including details of open source implementations of\nboth the competition framework and our competitors) and presents the results of\nan improved evaluation of these competitors across 20 games.\n", "versions": [{"version": "v1", "created": "Fri, 3 Aug 2018 17:19:28 GMT"}, {"version": "v2", "created": "Thu, 18 Oct 2018 09:56:02 GMT"}, {"version": "v3", "created": "Fri, 19 Oct 2018 10:32:52 GMT"}, {"version": "v4", "created": "Thu, 24 Jan 2019 14:40:42 GMT"}], "update_date": "2019-01-25", "authors_parsed": [["Atkinson", "Timothy", ""], ["Baier", "Hendrik", ""], ["Copplestone", "Tara", ""], ["Devlin", "Sam", ""], ["Swan", "Jerry", ""]]}, {"id": "1808.01358", "submitter": "Hiroki Ohashi", "authors": "Hiroki Ohashi, Mohammad Al-Naser, Sheraz Ahmed, Katsuyuki Nakamura,\n  Takuto Sato, Andreas Dengel", "title": "Attributes' Importance for Zero-Shot Pose-Classification Based on\n  Wearable Sensors", "comments": "The paper was published at Sensors, an open access journal\n  (http://www.mdpi.com/1424-8220/18/8/2485). This article belongs to the\n  Special Issue Artificial Intelligence and Machine Learning in Sensors\n  Networks", "journal-ref": "Sensors 2018, 18, 2485", "doi": "10.3390/s18082485", "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a simple yet effective method for improving the\nperformance of zero-shot learning (ZSL). ZSL classifies instances of unseen\nclasses, from which no training data is available, by utilizing the attributes\nof the classes. Conventional ZSL methods have equally dealt with all the\navailable attributes, but this sometimes causes misclassification. This is\nbecause an attribute that is effective for classifying instances of one class\nis not always effective for another class. In this case, a metric of\nclassifying the latter class can be undesirably influenced by the irrelevant\nattribute. This paper solves this problem by taking the importance of each\nattribute for each class into account when calculating the metric. In addition\nto the proposal of this new method, this paper also contributes by providing a\ndataset for pose classification based on wearable sensors, named HDPoseDS. It\ncontains 22 classes of poses performed by 10 subjects with 31 IMU sensors\nacross full body. To the best of our knowledge, it is the richest\nwearable-sensor dataset especially in terms of sensor density, and thus it is\nsuitable for studying zero-shot pose/action recognition. The presented method\nwas evaluated on HDPoseDS and outperformed relative improvement of 5.9% in\ncomparison to the best baseline method.\n", "versions": [{"version": "v1", "created": "Thu, 2 Aug 2018 07:51:01 GMT"}], "update_date": "2018-08-07", "authors_parsed": [["Ohashi", "Hiroki", ""], ["Al-Naser", "Mohammad", ""], ["Ahmed", "Sheraz", ""], ["Nakamura", "Katsuyuki", ""], ["Sato", "Takuto", ""], ["Dengel", "Andreas", ""]]}, {"id": "1808.01412", "submitter": "Yanqiao Zhu", "authors": "Kai Yang, Jie Ren, Yanqiao Zhu, Weiyi Zhang", "title": "Active Learning for Wireless IoT Intrusion Detection", "comments": "7 pages, 4 figures, accepted by IEEE Wireless Communications", "journal-ref": "IEEE Wireless Communications, 25 (2018) 19-25", "doi": "10.1109/MWC.2017.1800079", "report-no": null, "categories": "cs.CR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Internet of Things (IoT) is becoming truly ubiquitous in our everyday life,\nbut it also faces unique security challenges. Intrusion detection is critical\nfor the security and safety of a wireless IoT network. This paper discusses the\nhuman-in-the-loop active learning approach for wireless intrusion detection. We\nfirst present the fundamental challenges against the design of a successful\nIntrusion Detection System (IDS) for wireless IoT network. We then briefly\nreview the rudimentary concepts of active learning and propose its employment\nin the diverse applications of wireless intrusion detection. Experimental\nexample is also presented to show the significant performance improvement of\nthe active learning method over traditional supervised learning approach. While\nmachine learning techniques have been widely employed for intrusion detection,\nthe application of human-in-the-loop machine learning that leverages both\nmachine and human intelligence to intrusion detection of IoT is still in its\ninfancy. We hope this article can assist the readers in understanding the key\nconcepts of active learning and spur further research in this area.\n", "versions": [{"version": "v1", "created": "Sat, 4 Aug 2018 03:09:29 GMT"}], "update_date": "2019-01-10", "authors_parsed": [["Yang", "Kai", ""], ["Ren", "Jie", ""], ["Zhu", "Yanqiao", ""], ["Zhang", "Weiyi", ""]]}, {"id": "1808.01527", "submitter": "Kobi Cohen", "authors": "Anton Puzanov and Kobi Cohen", "title": "Deep Reinforcement One-Shot Learning for Artificially Intelligent\n  Classification Systems", "comments": "27 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years there has been a sharp rise in networking applications, in\nwhich significant events need to be classified but only a few training\ninstances are available. These are known as cases of one-shot learning.\nExamples include analyzing network traffic under zero-day attacks, and computer\nvision tasks by sensor networks deployed in the field. To handle this\nchallenging task, organizations often use human analysts to classify events\nunder high uncertainty. Existing algorithms use a threshold-based mechanism to\ndecide whether to classify an object automatically or send it to an analyst for\ndeeper inspection. However, this approach leads to a significant waste of\nresources since it does not take the practical temporal constraints of system\nresources into account. Our contribution is threefold. First, we develop a\nnovel Deep Reinforcement One-shot Learning (DeROL) framework to address this\nchallenge. The basic idea of the DeROL algorithm is to train a deep-Q network\nto obtain a policy which is oblivious to the unseen classes in the testing\ndata. Then, in real-time, DeROL maps the current state of the one-shot learning\nprocess to operational actions based on the trained deep-Q network, to maximize\nthe objective function. Second, we develop the first open-source software for\npractical artificially intelligent one-shot classification systems with limited\nresources for the benefit of researchers in related fields. Third, we present\nan extensive experimental study using the OMNIGLOT dataset for computer vision\ntasks and the UNSW-NB15 dataset for intrusion detection tasks that demonstrates\nthe versatility and efficiency of the DeROL framework.\n", "versions": [{"version": "v1", "created": "Sat, 4 Aug 2018 20:13:35 GMT"}], "update_date": "2018-08-07", "authors_parsed": [["Puzanov", "Anton", ""], ["Cohen", "Kobi", ""]]}, {"id": "1808.01552", "submitter": "Leye Wang", "authors": "Leye Wang, Bin Guo, Qiang Yang", "title": "Smart City Development with Urban Transfer Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nowadays, the smart city development levels of different cities are still\nunbalanced. For a large number of cities which just started development, the\ngovernments will face a critical cold-start problem: 'how to develop a new\nsmart city service with limited data?'. To address this problem, transfer\nlearning can be leveraged to accelerate the smart city development, which we\nterm the urban transfer learning paradigm. This article investigates the common\nprocess of urban transfer learning, aiming to provide city planners and\nrelevant practitioners with guidelines on how to apply this novel learning\nparadigm. Our guidelines include common transfer strategies to take, general\nsteps to follow, and case studies in public safety, transportation management,\netc. We also summarize a few research opportunities and expect this article can\nattract more researchers to study urban transfer learning.\n", "versions": [{"version": "v1", "created": "Sun, 5 Aug 2018 02:28:27 GMT"}, {"version": "v2", "created": "Sun, 21 Oct 2018 03:42:02 GMT"}], "update_date": "2018-10-23", "authors_parsed": [["Wang", "Leye", ""], ["Guo", "Bin", ""], ["Yang", "Qiang", ""]]}, {"id": "1808.01591", "submitter": "Pankaj Gupta", "authors": "Pankaj Gupta and Hinrich Sch\\\"utze", "title": "LISA: Explaining Recurrent Neural Network Judgments via Layer-wIse\n  Semantic Accumulation and Example to Pattern Transformation", "comments": "2018 Conference on Empirical Methods in Natural Language Processing\n  (EMNLP2018) workshop on Analyzing and Interpreting Neural Networks for NLP\n  (BlackBoxNLP)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recurrent neural networks (RNNs) are temporal networks and cumulative in\nnature that have shown promising results in various natural language processing\ntasks. Despite their success, it still remains a challenge to understand their\nhidden behavior. In this work, we analyze and interpret the cumulative nature\nof RNN via a proposed technique named as Layer-wIse-Semantic-Accumulation\n(LISA) for explaining decisions and detecting the most likely (i.e., saliency)\npatterns that the network relies on while decision making. We demonstrate (1)\nLISA: \"How an RNN accumulates or builds semantics during its sequential\nprocessing for a given text example and expected response\" (2) Example2pattern:\n\"How the saliency patterns look like for each category in the data according to\nthe network in decision making\". We analyse the sensitiveness of RNNs about\ndifferent inputs to check the increase or decrease in prediction scores and\nfurther extract the saliency patterns learned by the network. We employ two\nrelation classification datasets: SemEval 10 Task 8 and TAC KBP Slot Filling to\nexplain RNN predictions via the LISA and example2pattern.\n", "versions": [{"version": "v1", "created": "Sun, 5 Aug 2018 09:50:47 GMT"}], "update_date": "2018-08-07", "authors_parsed": [["Gupta", "Pankaj", ""], ["Sch\u00fctze", "Hinrich", ""]]}, {"id": "1808.01650", "submitter": "Deepak Gupta", "authors": "Deepak Gupta, Sarah Kohail and Pushpak Bhattacharyya", "title": "Combining Graph-based Dependency Features with Convolutional Neural\n  Network for Answer Triggering", "comments": "19th International Conference on Computational Linguistics and\n  Intelligent Text Processing (CICLing 2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Answer triggering is the task of selecting the best-suited answer for a given\nquestion from a set of candidate answers if exists. In this paper, we present a\nhybrid deep learning model for answer triggering, which combines several\ndependency graph based alignment features, namely graph edit distance,\ngraph-based similarity and dependency graph coverage, with dense vector\nembeddings from a Convolutional Neural Network (CNN). Our experiments on the\nWikiQA dataset show that such a combination can more accurately trigger a\ncandidate answer compared to the previous state-of-the-art models. Comparative\nstudy on WikiQA dataset shows 5.86% absolute F-score improvement at the\nquestion level.\n", "versions": [{"version": "v1", "created": "Sun, 5 Aug 2018 16:44:25 GMT"}], "update_date": "2018-08-07", "authors_parsed": [["Gupta", "Deepak", ""], ["Kohail", "Sarah", ""], ["Bhattacharyya", "Pushpak", ""]]}, {"id": "1808.01664", "submitter": "Kaidi Xu", "authors": "Kaidi Xu, Sijia Liu, Pu Zhao, Pin-Yu Chen, Huan Zhang, Quanfu Fan,\n  Deniz Erdogmus, Yanzhi Wang, Xue Lin", "title": "Structured Adversarial Attack: Towards General Implementation and Better\n  Interpretability", "comments": "Published as a conference paper at ICLR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When generating adversarial examples to attack deep neural networks (DNNs),\nLp norm of the added perturbation is usually used to measure the similarity\nbetween original image and adversarial example. However, such adversarial\nattacks perturbing the raw input spaces may fail to capture structural\ninformation hidden in the input. This work develops a more general attack\nmodel, i.e., the structured attack (StrAttack), which explores group sparsity\nin adversarial perturbations by sliding a mask through images aiming for\nextracting key spatial structures. An ADMM (alternating direction method of\nmultipliers)-based framework is proposed that can split the original problem\ninto a sequence of analytically solvable subproblems and can be generalized to\nimplement other attacking methods. Strong group sparsity is achieved in\nadversarial perturbations even with the same level of Lp norm distortion as the\nstate-of-the-art attacks. We demonstrate the effectiveness of StrAttack by\nextensive experimental results onMNIST, CIFAR-10, and ImageNet. We also show\nthat StrAttack provides better interpretability (i.e., better correspondence\nwith discriminative image regions)through adversarial saliency map (Papernot et\nal., 2016b) and class activation map(Zhou et al., 2016).\n", "versions": [{"version": "v1", "created": "Sun, 5 Aug 2018 18:06:37 GMT"}, {"version": "v2", "created": "Thu, 4 Oct 2018 03:52:24 GMT"}, {"version": "v3", "created": "Tue, 19 Feb 2019 21:36:46 GMT"}], "update_date": "2019-02-21", "authors_parsed": [["Xu", "Kaidi", ""], ["Liu", "Sijia", ""], ["Zhao", "Pu", ""], ["Chen", "Pin-Yu", ""], ["Zhang", "Huan", ""], ["Fan", "Quanfu", ""], ["Erdogmus", "Deniz", ""], ["Wang", "Yanzhi", ""], ["Lin", "Xue", ""]]}, {"id": "1808.01690", "submitter": "Hongzhi Wang", "authors": "Sifan Liu and Hongzhi Wang", "title": "Error Detection in a Large-Scale Lexical Taxonomy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge base (KB) is an important aspect in artificial intelligence. One\nsignificant challenge faced by KB construction is that it contains many noises,\nwhich prevents its effective usage. Even though some KB cleansing algorithms\nhave been proposed, they focus on the structure of the knowledge graph and\nneglect the relation between the concepts, which could be helpful to discover\nwrong relations in KB. Motived by this, we measure the relation of two concepts\nby the distance between their corresponding instances and detect errors within\nthe intersection of the conflicting concept sets. For efficient and effective\nknowledge base cleansing, we first apply a distance-based Model to determine\nthe conflicting concept sets using two different methods. Then, we propose and\nanalyze several algorithms on how to detect and repairing the errors based on\nour model, where we use hash method for an efficient way to calculate distance.\nExperimental results demonstrate that the proposed approaches could cleanse the\nknowledge bases efficiently and effectively.\n", "versions": [{"version": "v1", "created": "Sun, 5 Aug 2018 21:53:40 GMT"}], "update_date": "2018-08-07", "authors_parsed": [["Liu", "Sifan", ""], ["Wang", "Hongzhi", ""]]}, {"id": "1808.01741", "submitter": "Walid Saba", "authors": "Walid S. Saba", "title": "Logical Semantics and Commonsense Knowledge: Where Did we Go Wrong, and\n  How to Go Forward, Again", "comments": "Ontology, Commonsense Knowledge, Language Understanding, Reasoning,\n  Types, Logical Semantics", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We argue that logical semantics might have faltered due to its failure in\ndistinguishing between two fundamentally very different types of concepts:\nontological concepts, that should be types in a strongly-typed ontology, and\nlogical concepts, that are predicates corresponding to properties of and\nrelations between objects of various ontological types. We will then show that\naccounting for these differences amounts to the integration of lexical and\ncompositional semantics in one coherent framework, and to an embedding in our\nlogical semantics of a strongly-typed ontology that reflects our commonsense\nview of the world and the way we talk about it in ordinary language. We will\nshow that in such a framework a number of challenges in natural language\nsemantics can be adequately and systematically treated.\n", "versions": [{"version": "v1", "created": "Mon, 6 Aug 2018 06:20:41 GMT"}, {"version": "v2", "created": "Thu, 9 Aug 2018 04:06:20 GMT"}], "update_date": "2018-08-10", "authors_parsed": [["Saba", "Walid S.", ""]]}, {"id": "1808.01743", "submitter": "Marinka Zitnik", "authors": "Marinka Zitnik and Blaz Zupan", "title": "NIMFA: A Python Library for Nonnegative Matrix Factorization", "comments": null, "journal-ref": "Journal of Machine Learning Research 13 (2012) 849-853", "doi": null, "report-no": null, "categories": "cs.LG cs.AI q-bio.QM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  NIMFA is an open-source Python library that provides a unified interface to\nnonnegative matrix factorization algorithms. It includes implementations of\nstate-of-the-art factorization methods, initialization approaches, and quality\nscoring. It supports both dense and sparse matrix representation. NIMFA's\ncomponent-based implementation and hierarchical design should help the users to\nemploy already implemented techniques or design and code new strategies for\nmatrix factorization tasks.\n", "versions": [{"version": "v1", "created": "Mon, 6 Aug 2018 06:28:35 GMT"}], "update_date": "2018-08-07", "authors_parsed": [["Zitnik", "Marinka", ""], ["Zupan", "Blaz", ""]]}, {"id": "1808.01785", "submitter": "Sibo Song", "authors": "Sibo Song, Yueru Chen, Ngai-Man Cheung, C.-C. Jay Kuo", "title": "Defense Against Adversarial Attacks with Saak Transform", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (DNNs) are known to be vulnerable to adversarial\nperturbations, which imposes a serious threat to DNN-based decision systems. In\nthis paper, we propose to apply the lossy Saak transform to adversarially\nperturbed images as a preprocessing tool to defend against adversarial attacks.\nSaak transform is a recently-proposed state-of-the-art for computing the\nspatial-spectral representations of input images. Empirically, we observe that\noutputs of the Saak transform are very discriminative in differentiating\nadversarial examples from clean ones. Therefore, we propose a Saak transform\nbased preprocessing method with three steps: 1) transforming an input image to\na joint spatial-spectral representation via the forward Saak transform, 2)\napply filtering to its high-frequency components, and, 3) reconstructing the\nimage via the inverse Saak transform. The processed image is found to be robust\nagainst adversarial perturbations. We conduct extensive experiments to\ninvestigate various settings of the Saak transform and filtering functions.\nWithout harming the decision performance on clean images, our method\noutperforms state-of-the-art adversarial defense methods by a substantial\nmargin on both the CIFAR-10 and ImageNet datasets. Importantly, our results\nsuggest that adversarial perturbations can be effectively and efficiently\ndefended using state-of-the-art frequency analysis.\n", "versions": [{"version": "v1", "created": "Mon, 6 Aug 2018 09:01:41 GMT"}], "update_date": "2018-08-07", "authors_parsed": [["Song", "Sibo", ""], ["Chen", "Yueru", ""], ["Cheung", "Ngai-Man", ""], ["Kuo", "C. -C. Jay", ""]]}, {"id": "1808.01843", "submitter": "Yinglong Ma", "authors": "Yinglong Ma, Peng Zhang and Jiangang Ma", "title": "An Efficient Approach to Learning Chinese Judgment Document Similarity\n  Based on Knowledge Summarization", "comments": "23 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A previous similar case in common law systems can be used as a reference with\nrespect to the current case such that identical situations can be treated\nsimilarly in every case. However, current approaches for judgment document\nsimilarity computation failed to capture the core semantics of judgment\ndocuments and therefore suffer from lower accuracy and higher computation\ncomplexity. In this paper, a knowledge block summarization based machine\nlearning approach is proposed to compute the semantic similarity of Chinese\njudgment documents. By utilizing domain ontologies for judgment documents, the\ncore semantics of Chinese judgment documents is summarized based on knowledge\nblocks. Then the WMD algorithm is used to calculate the similarity between\nknowledge blocks. At last, the related experiments were made to illustrate that\nour approach is very effective and efficient in achieving higher accuracy and\nfaster computation speed in comparison with the traditional approaches.\n", "versions": [{"version": "v1", "created": "Mon, 6 Aug 2018 12:24:19 GMT"}], "update_date": "2018-08-07", "authors_parsed": [["Ma", "Yinglong", ""], ["Zhang", "Peng", ""], ["Ma", "Jiangang", ""]]}, {"id": "1808.01874", "submitter": "Loris Bozzato", "authors": "Loris Bozzato, Luciano Serafini, Thomas Eiter", "title": "Reasoning with Justifiable Exceptions in Contextual Hierarchies\n  (Appendix)", "comments": "Appendix to the paper \"Reasoning with Justifiable Exceptions in\n  Contextual Hierarchies\", accepted to the 16th International Conference on\n  Principles of Knowledge Representation and Reasoning (KR 2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper is an appendix to the paper \"Reasoning with Justifiable Exceptions\nin Contextual Hierarchies\" by Bozzato, Serafini and Eiter, 2018. It provides\nfurther details on the language, the complexity results and the datalog\ntranslation introduced in the main paper.\n", "versions": [{"version": "v1", "created": "Mon, 6 Aug 2018 13:15:24 GMT"}], "update_date": "2018-08-07", "authors_parsed": [["Bozzato", "Loris", ""], ["Serafini", "Luciano", ""], ["Eiter", "Thomas", ""]]}, {"id": "1808.01876", "submitter": "Yilun Lin", "authors": "Yilun Lin, Xingyuan Dai, Li Li, Fei-Yue Wang", "title": "An Efficient Deep Reinforcement Learning Model for Urban Traffic Control", "comments": "10 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Urban Traffic Control (UTC) plays an essential role in Intelligent\nTransportation System (ITS) but remains difficult. Since model-based UTC\nmethods may not accurately describe the complex nature of traffic dynamics in\nall situations, model-free data-driven UTC methods, especially reinforcement\nlearning (RL) based UTC methods, received increasing interests in the last\ndecade. However, existing DL approaches did not propose an efficient algorithm\nto solve the complicated multiple intersections control problems whose\nstate-action spaces are vast. To solve this problem, we propose a Deep\nReinforcement Learning (DRL) algorithm that combines several tricks to master\nan appropriate control strategy within an acceptable time. This new algorithm\nrelaxes the fixed traffic demand pattern assumption and reduces human invention\nin parameter tuning. Simulation experiments have shown that our method\noutperforms traditional rule-based approaches and has the potential to handle\nmore complex traffic problems in the real world.\n", "versions": [{"version": "v1", "created": "Mon, 6 Aug 2018 13:16:52 GMT"}, {"version": "v2", "created": "Fri, 24 Aug 2018 06:02:32 GMT"}], "update_date": "2018-08-27", "authors_parsed": [["Lin", "Yilun", ""], ["Dai", "Xingyuan", ""], ["Li", "Li", ""], ["Wang", "Fei-Yue", ""]]}, {"id": "1808.01949", "submitter": "Ferdinando Fioretto", "authors": "Ferdinando Fioretto and Pascal Van Hentenryck", "title": "OptStream: Releasing Time Series Privately", "comments": null, "journal-ref": "Journal of Artificial Intelligence Research (JAIR) Vol. 65 (2019)", "doi": "10.1613/jair.1.11583", "report-no": null, "categories": "cs.CR cs.AI cs.DB cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many applications of machine learning and optimization operate on data\nstreams. While these datasets are fundamental to fuel decision-making\nalgorithms, often they contain sensitive information about individuals and\ntheir usage poses significant privacy risks. Motivated by an application in\nenergy systems, this paper presents OPTSTREAM, a novel algorithm for releasing\ndifferentially private data streams under the w-event model of privacy.\nOPTSTREAM is a 4-step procedure consisting of sampling, perturbation,\nreconstruction, and post-processing modules. First, the sampling module selects\na small set of points to access in each period of interest. Then, the\nperturbation module adds noise to the sampled data points to guarantee privacy.\nNext, the reconstruction module reassembles non-sampled data points from the\nperturbed sample points. Finally, the post-processing module uses convex\noptimization over the private output of the previous modules, as well as the\nprivate answers of additional queries on the data stream, to improve accuracy\nby redistributing the added noise. OPTSTREAM is evaluated on a test case\ninvolving the release of a real data stream from the largest European\ntransmission operator. Experimental results show that OPTSTREAM may not only\nimprove the accuracy of state-of-the-art methods by at least one order of\nmagnitude but also supports accurate load forecasting on the private data.\n", "versions": [{"version": "v1", "created": "Mon, 6 Aug 2018 14:54:42 GMT"}, {"version": "v2", "created": "Tue, 30 Oct 2018 13:24:03 GMT"}], "update_date": "2020-04-20", "authors_parsed": [["Fioretto", "Ferdinando", ""], ["Van Hentenryck", "Pascal", ""]]}, {"id": "1808.01968", "submitter": "Vuong M. Ngo", "authors": "Vuong M. Ngo", "title": "Discovering Latent Information By Spreading Activation Algorithm For\n  Document Retrieval", "comments": "12pages, will be published in The International Journal of Artificial\n  Intelligence & Applications (IJAIA). arXiv admin note: text overlap with\n  arXiv:1807.07967", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Syntactic search relies on keywords contained in a query to find suitable\ndocuments. So, documents that do not contain the keywords but contain\ninformation related to the query are not retrieved. Spreading activation is an\nalgorithm for finding latent information in a query by exploiting relations\nbetween nodes in an associative network or semantic network. However, the\nclassical spreading activation algorithm uses all relations of a node in the\nnetwork that will add unsuitable information into the query. In this paper, we\npropose a novel approach for semantic text search, called\nquery-oriented-constrained spreading activation that only uses relations\nrelating to the content of the query to find really related information.\nExperiments on a benchmark dataset show that, in terms of the MAP measure, our\nsearch engine is 18.9% and 43.8% respectively better than the syntactic search\nand the search using the classical constrained spreading activation.\n  KEYWORDS: Information Retrieval, Ontology, Semantic Search, Spreading\nActivation\n", "versions": [{"version": "v1", "created": "Sun, 29 Jul 2018 08:42:30 GMT"}], "update_date": "2018-08-07", "authors_parsed": [["Ngo", "Vuong M.", ""]]}, {"id": "1808.02022", "submitter": "Saeedeh Shekarpour", "authors": "Saeedeh Shekarpour, Ankita Saxena, Krishnaprasad Thirunarayan, Valerie\n  L. Shalin, Amit Sheth", "title": "Principles for Developing a Knowledge Graph of Interlinked Events from\n  News Headlines on Twitter", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ever-growing datasets published on Linked Open Data mainly contain\nencyclopedic information. However, there is a lack of quality structured and\nsemantically annotated datasets extracted from unstructured real-time sources.\nIn this paper, we present principles for developing a knowledge graph of\ninterlinked events using the case study of news headlines published on Twitter\nwhich is a real-time and eventful source of fresh information. We represent the\nessential pipeline containing the required tasks ranging from choosing\nbackground data model, event annotation (i.e., event recognition and\nclassification), entity annotation and eventually interlinking events. The\nstate-of-the-art is limited to domain-specific scenarios for recognizing and\nclassifying events, whereas this paper plays the role of a domain-agnostic\nroad-map for developing a knowledge graph of interlinked events.\n", "versions": [{"version": "v1", "created": "Mon, 6 Aug 2018 03:04:35 GMT"}], "update_date": "2018-10-12", "authors_parsed": [["Shekarpour", "Saeedeh", ""], ["Saxena", "Ankita", ""], ["Thirunarayan", "Krishnaprasad", ""], ["Shalin", "Valerie L.", ""], ["Sheth", "Amit", ""]]}, {"id": "1808.02093", "submitter": "Dj Strouse", "authors": "DJ Strouse, Max Kleiman-Weiner, Josh Tenenbaum, Matt Botvinick, David\n  Schwab", "title": "Learning to Share and Hide Intentions using Information Regularization", "comments": "Presented at the 32nd Conference on Neural Information Processing\n  Systems (NIPS 2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.IT cs.LG cs.MA math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning to cooperate with friends and compete with foes is a key component\nof multi-agent reinforcement learning. Typically to do so, one requires access\nto either a model of or interaction with the other agent(s). Here we show how\nto learn effective strategies for cooperation and competition in an asymmetric\ninformation game with no such model or interaction. Our approach is to\nencourage an agent to reveal or hide their intentions using an\ninformation-theoretic regularizer. We consider both the mutual information\nbetween goal and action given state, as well as the mutual information between\ngoal and state. We show how to optimize these regularizers in a way that is\neasy to integrate with policy gradient reinforcement learning. Finally, we\ndemonstrate that cooperative (competitive) policies learned with our approach\nlead to more (less) reward for a second agent in two simple asymmetric\ninformation games.\n", "versions": [{"version": "v1", "created": "Mon, 6 Aug 2018 20:10:27 GMT"}, {"version": "v2", "created": "Tue, 1 Jan 2019 23:54:47 GMT"}], "update_date": "2019-01-03", "authors_parsed": [["Strouse", "DJ", ""], ["Kleiman-Weiner", "Max", ""], ["Tenenbaum", "Josh", ""], ["Botvinick", "Matt", ""], ["Schwab", "David", ""]]}, {"id": "1808.02123", "submitter": "Nandini Ramanan", "authors": "Nandini Ramanan, Gautam Kunapuli, Tushar Khot, Bahare Fatemi, Seyed\n  Mehran Kazemi, David Poole, Kristian Kersting, Sriraam Natarajan", "title": "Structure Learning for Relational Logistic Regression: An Ensemble\n  Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of learning Relational Logistic Regression (RLR).\nUnlike standard logistic regression, the features of RLRs are first-order\nformulae with associated weight vectors instead of scalar weights. We turn the\nproblem of learning RLR to learning these vector-weighted formulae and develop\na learning algorithm based on the recently successful functional-gradient\nboosting methods for probabilistic logic models. We derive the functional\ngradients and show how weights can be learned simultaneously in an efficient\nmanner. Our empirical evaluation on standard and novel data sets demonstrates\nthe superiority of our approach over other methods for learning RLR.\n", "versions": [{"version": "v1", "created": "Mon, 6 Aug 2018 21:27:05 GMT"}], "update_date": "2018-08-08", "authors_parsed": [["Ramanan", "Nandini", ""], ["Kunapuli", "Gautam", ""], ["Khot", "Tushar", ""], ["Fatemi", "Bahare", ""], ["Kazemi", "Seyed Mehran", ""], ["Poole", "David", ""], ["Kersting", "Kristian", ""], ["Natarajan", "Sriraam", ""]]}, {"id": "1808.02291", "submitter": "Alessandro Ronca", "authors": "Alessandro Ronca, Mark Kaminski, Bernardo Cuenca Grau, Ian Horrocks", "title": "The Window Validity Problem in Rule-Based Stream Reasoning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.DB cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Rule-based temporal query languages provide the expressive power and\nflexibility required to capture in a natural way complex analysis tasks over\nstreaming data. Stream processing applications, however, typically require near\nreal-time response using limited resources. In particular, it becomes essential\nthat the underpinning query language has favourable computational properties\nand that stream processing algorithms are able to keep only a small number of\npreviously received facts in memory at any point in time without sacrificing\ncorrectness. In this paper, we propose a recursive fragment of temporal Datalog\nwith tractable data complexity and study the properties of a generic stream\nreasoning algorithm for this fragment. We focus on the window validity problem\nas a way to minimise the number of time points for which the stream reasoning\nalgorithm needs to keep data in memory at any point in time.\n", "versions": [{"version": "v1", "created": "Tue, 7 Aug 2018 10:17:11 GMT"}, {"version": "v2", "created": "Wed, 14 Nov 2018 12:04:03 GMT"}, {"version": "v3", "created": "Thu, 15 Nov 2018 17:53:44 GMT"}], "update_date": "2018-11-16", "authors_parsed": [["Ronca", "Alessandro", ""], ["Kaminski", "Mark", ""], ["Grau", "Bernardo Cuenca", ""], ["Horrocks", "Ian", ""]]}, {"id": "1808.02354", "submitter": "EPTCS", "authors": "Allan F. Randall", "title": "Objective and Subjective Solomonoff Probabilities in Quantum Mechanics", "comments": "In Proceedings PC 2018, arXiv:1807.10563", "journal-ref": "EPTCS 273, 2018, pp. 27-38", "doi": "10.4204/EPTCS.273.3", "report-no": null, "categories": "quant-ph cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Algorithmic probability has shown some promise in dealing with the\nprobability problem in the Everett interpretation, since it provides an\nobjective, single-case probability measure. Many find the Everettian cosmology\nto be overly extravagant, however, and algorithmic probability has also\nprovided improved models of subjective probability and Bayesian reasoning. I\nattempt here to generalize algorithmic Everettianism to more Bayesian and\nsubjectivist interpretations. I present a general framework for applying\ngenerative probability, of which algorithmic probability can be considered a\nspecial case. I apply this framework to two commonly vexing thought experiments\nthat have immediate application to quantum probability: the Sleeping Beauty and\nReplicator experiments.\n", "versions": [{"version": "v1", "created": "Mon, 30 Jul 2018 01:30:09 GMT"}], "update_date": "2018-08-08", "authors_parsed": [["Randall", "Allan F.", ""]]}, {"id": "1808.02455", "submitter": "Hassan Ismail Fawaz", "authors": "Hassan Ismail Fawaz, Germain Forestier, Jonathan Weber, Lhassane\n  Idoumghar, Pierre-Alain Muller", "title": "Data augmentation using synthetic data for time series classification\n  with deep residual networks", "comments": "Accepted at AALTD'18 workshop in ECML/PKDD", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data augmentation in deep neural networks is the process of generating\nartificial data in order to reduce the variance of the classifier with the goal\nto reduce the number of errors. This idea has been shown to improve deep neural\nnetwork's generalization capabilities in many computer vision tasks such as\nimage recognition and object localization. Apart from these applications, deep\nConvolutional Neural Networks (CNNs) have also recently gained popularity in\nthe Time Series Classification (TSC) community. However, unlike in image\nrecognition problems, data augmentation techniques have not yet been\ninvestigated thoroughly for the TSC task. This is surprising as the accuracy of\ndeep learning models for TSC could potentially be improved, especially for\nsmall datasets that exhibit overfitting, when a data augmentation method is\nadopted. In this paper, we fill this gap by investigating the application of a\nrecently proposed data augmentation technique based on the Dynamic Time Warping\ndistance, for a deep learning model for TSC. To evaluate the potential of\naugmenting the training set, we performed extensive experiments using the UCR\nTSC benchmark. Our preliminary experiments reveal that data augmentation can\ndrastically increase deep CNN's accuracy on some datasets and significantly\nimprove the deep model's accuracy when the method is used in an ensemble\napproach.\n", "versions": [{"version": "v1", "created": "Tue, 7 Aug 2018 16:48:21 GMT"}], "update_date": "2018-08-08", "authors_parsed": [["Fawaz", "Hassan Ismail", ""], ["Forestier", "Germain", ""], ["Weber", "Jonathan", ""], ["Idoumghar", "Lhassane", ""], ["Muller", "Pierre-Alain", ""]]}, {"id": "1808.02473", "submitter": "Changqing Zou Dr.", "authors": "Changqing Zou, Qian Yu, Ruofei Du, Haoran Mo, Yi-Zhe Song, Tao Xiang,\n  Chengying Gao, Baoquan Chen, Hao Zhang", "title": "SketchyScene: Richly-Annotated Scene Sketches", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We contribute the first large-scale dataset of scene sketches, SketchyScene,\nwith the goal of advancing research on sketch understanding at both the object\nand scene level. The dataset is created through a novel and carefully designed\ncrowdsourcing pipeline, enabling users to efficiently generate large quantities\nof realistic and diverse scene sketches. SketchyScene contains more than 29,000\nscene-level sketches, 7,000+ pairs of scene templates and photos, and 11,000+\nobject sketches. All objects in the scene sketches have ground-truth semantic\nand instance masks. The dataset is also highly scalable and extensible, easily\nallowing augmenting and/or changing scene composition. We demonstrate the\npotential impact of SketchyScene by training new computational models for\nsemantic segmentation of scene sketches and showing how the new dataset enables\nseveral applications including image retrieval, sketch colorization, editing,\nand captioning, etc. The dataset and code can be found at\nhttps://github.com/SketchyScene/SketchyScene.\n", "versions": [{"version": "v1", "created": "Tue, 7 Aug 2018 17:47:55 GMT"}], "update_date": "2018-08-08", "authors_parsed": [["Zou", "Changqing", ""], ["Yu", "Qian", ""], ["Du", "Ruofei", ""], ["Mo", "Haoran", ""], ["Song", "Yi-Zhe", ""], ["Xiang", "Tao", ""], ["Gao", "Chengying", ""], ["Chen", "Baoquan", ""], ["Zhang", "Hao", ""]]}, {"id": "1808.02541", "submitter": "Nare Karapetyan", "authors": "Nare Karapetyan, Kelly Benson, Chris McKinney, Perouz Taslakian,\n  Ioannis Rekleitis", "title": "Efficient Multi-Robot Coverage of a Known Environment", "comments": "In proceedings of IEEE/RSJ International Conference on Intelligent\n  Robots and Systems (IROS), 2017", "journal-ref": null, "doi": "10.1109/IROS.2017.8206000", "report-no": null, "categories": "cs.RO cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  This paper addresses the complete area coverage problem of a known\nenvironment by multiple-robots. Complete area coverage is the problem of moving\nan end-effector over all available space while avoiding existing obstacles. In\nsuch tasks, using multiple robots can increase the efficiency of the area\ncoverage in terms of minimizing the operational time and increase the\nrobustness in the face of robot attrition. Unfortunately, the problem of\nfinding an optimal solution for such an area coverage problem with multiple\nrobots is known to be NP-complete. In this paper we present two approximation\nheuristics for solving the multi-robot coverage problem. The first solution\npresented is a direct extension of an efficient single robot area coverage\nalgorithm, based on an exact cellular decomposition. The second algorithm is a\ngreedy approach that divides the area into equal regions and applies an\nefficient single-robot coverage algorithm to each region. We present\nexperimental results for two algorithms. Results indicate that our approaches\nprovide good coverage distribution between robots and minimize the workload per\nrobot, meanwhile ensuring complete coverage of the area.\n", "versions": [{"version": "v1", "created": "Tue, 7 Aug 2018 20:24:29 GMT"}], "update_date": "2018-08-09", "authors_parsed": [["Karapetyan", "Nare", ""], ["Benson", "Kelly", ""], ["McKinney", "Chris", ""], ["Taslakian", "Perouz", ""], ["Rekleitis", "Ioannis", ""]]}, {"id": "1808.02550", "submitter": "Shray Bansal", "authors": "Shray Bansal, Akansel Cosgun, Alireza Nakhaei and Kikuo Fujimura", "title": "Collaborative Planning for Mixed-Autonomy Lane Merging", "comments": "To appear at the 2018 IEEE/RSJ International Conference on\n  Intelligent Robots and Systems (IROS 2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.MA cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Driving is a social activity: drivers often indicate their intent to change\nlanes via motion cues. We consider mixed-autonomy traffic where a Human-driven\nVehicle (HV) and an Autonomous Vehicle (AV) drive together. We propose a\nplanning framework where the degree to which the AV considers the other agent's\nreward is controlled by a selfishness factor. We test our approach on a\nsimulated two-lane highway where the AV and HV merge into each other's lanes.\nIn a user study with 21 subjects and 6 different selfishness factors, we found\nthat our planning approach was sound and that both agents had less merging\ntimes when a factor that balances the rewards for the two agents was chosen.\nOur results on double lane merging suggest it to be a non-zero-sum game and\nencourage further investigation on collaborative decision making algorithms for\nmixed-autonomy traffic.\n", "versions": [{"version": "v1", "created": "Tue, 7 Aug 2018 20:50:56 GMT"}], "update_date": "2018-08-09", "authors_parsed": [["Bansal", "Shray", ""], ["Cosgun", "Akansel", ""], ["Nakhaei", "Alireza", ""], ["Fujimura", "Kikuo", ""]]}, {"id": "1808.02552", "submitter": "Nare Karapetyan", "authors": "Nare Karapetyan, Jason Moulton, Jeremy S. Lewis, Alberto Quattrini Li,\n  Jason M. O'Kane, Ioannis Rekleitis", "title": "Multi-robot Dubins Coverage with Autonomous Surface Vehicles", "comments": "In proceedings of IEEE International Conference on Robotics and\n  Automation (ICRA), 2018", "journal-ref": null, "doi": "10.1109/ICRA.2018.8460661", "report-no": null, "categories": "cs.RO cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In large scale coverage operations, such as marine exploration or aerial\nmonitoring, single robot approaches are not ideal, as they may take too long to\ncover a large area. In such scenarios, multi-robot approaches are preferable.\nFurthermore, several real world vehicles are non-holonomic, but can be modeled\nusing Dubins vehicle kinematics. This paper focuses on environmental monitoring\nof aquatic environments using Autonomous Surface Vehicles (ASVs). In\nparticular, we propose a novel approach for solving the problem of complete\ncoverage of a known environment by a multi-robot team consisting of Dubins\nvehicles. It is worth noting that both multi-robot coverage and Dubins vehicle\ncoverage are NP-complete problems. As such, we present two heuristics methods\nbased on a variant of the traveling salesman problem -- k-TSP -- formulation\nand clustering algorithms that efficiently solve the problem. The proposed\nmethods are tested both in simulations to assess their scalability and with a\nteam of ASVs operating on a lake to ensure their applicability in real world.\n", "versions": [{"version": "v1", "created": "Tue, 7 Aug 2018 20:52:54 GMT"}], "update_date": "2018-09-24", "authors_parsed": [["Karapetyan", "Nare", ""], ["Moulton", "Jason", ""], ["Lewis", "Jeremy S.", ""], ["Li", "Alberto Quattrini", ""], ["O'Kane", "Jason M.", ""], ["Rekleitis", "Ioannis", ""]]}, {"id": "1808.02560", "submitter": "Fabio Cuzzolin", "authors": "Fabio Cuzzolin", "title": "Belief likelihood function for generalised logistic regression", "comments": "10 pages, 3 figures; submitted to UAI 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.AI stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The notion of belief likelihood function of repeated trials is introduced,\nwhenever the uncertainty for individual trials is encoded by a belief measure\n(a finite random set). This generalises the traditional likelihood function,\nand provides a natural setting for belief inference from statistical data.\nFactorisation results are proven for the case in which conjunctive or\ndisjunctive combination are employed, leading to analytical expressions for the\nlower and upper likelihoods of `sharp' samples in the case of Bernoulli trials,\nand to the formulation of a generalised logistic regression framework.\n", "versions": [{"version": "v1", "created": "Tue, 7 Aug 2018 21:43:32 GMT"}, {"version": "v2", "created": "Mon, 20 Aug 2018 10:12:21 GMT"}], "update_date": "2018-08-21", "authors_parsed": [["Cuzzolin", "Fabio", ""]]}, {"id": "1808.02608", "submitter": "Takaaki Hori", "authors": "Takaaki Hori, Jaejin Cho, Shinji Watanabe", "title": "End-to-end Speech Recognition with Word-based RNN Language Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper investigates the impact of word-based RNN language models\n(RNN-LMs) on the performance of end-to-end automatic speech recognition (ASR).\nIn our prior work, we have proposed a multi-level LM, in which character-based\nand word-based RNN-LMs are combined in hybrid CTC/attention-based ASR. Although\nthis multi-level approach achieves significant error reduction in the Wall\nStreet Journal (WSJ) task, two different LMs need to be trained and used for\ndecoding, which increase the computational cost and memory usage. In this\npaper, we further propose a novel word-based RNN-LM, which allows us to decode\nwith only the word-based LM, where it provides look-ahead word probabilities to\npredict next characters instead of the character-based LM, leading competitive\naccuracy with less computation compared to the multi-level LM. We demonstrate\nthe efficacy of the word-based RNN-LMs using a larger corpus, LibriSpeech, in\naddition to WSJ we used in the prior work. Furthermore, we show that the\nproposed model achieves 5.1 %WER for WSJ Eval'92 test set when the vocabulary\nsize is increased, which is the best WER reported for end-to-end ASR systems on\nthis benchmark.\n", "versions": [{"version": "v1", "created": "Wed, 8 Aug 2018 03:05:11 GMT"}], "update_date": "2018-08-09", "authors_parsed": [["Hori", "Takaaki", ""], ["Cho", "Jaejin", ""], ["Watanabe", "Shinji", ""]]}, {"id": "1808.02632", "submitter": "Pan Lu", "authors": "Peng Gao, Pan Lu, Hongsheng Li, Shuang Li, Yikang Li, Steven Hoi,\n  Xiaogang Wang", "title": "Question-Guided Hybrid Convolution for Visual Question Answering", "comments": "17 pages, 4 figures, accepted in ECCV 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CL cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a novel Question-Guided Hybrid Convolution (QGHC)\nnetwork for Visual Question Answering (VQA). Most state-of-the-art VQA methods\nfuse the high-level textual and visual features from the neural network and\nabandon the visual spatial information when learning multi-modal features.To\naddress these problems, question-guided kernels generated from the input\nquestion are designed to convolute with visual features for capturing the\ntextual and visual relationship in the early stage. The question-guided\nconvolution can tightly couple the textual and visual information but also\nintroduce more parameters when learning kernels. We apply the group\nconvolution, which consists of question-independent kernels and\nquestion-dependent kernels, to reduce the parameter size and alleviate\nover-fitting. The hybrid convolution can generate discriminative multi-modal\nfeatures with fewer parameters. The proposed approach is also complementary to\nexisting bilinear pooling fusion and attention based VQA methods. By\nintegrating with them, our method could further boost the performance.\nExtensive experiments on public VQA datasets validate the effectiveness of\nQGHC.\n", "versions": [{"version": "v1", "created": "Wed, 8 Aug 2018 05:39:00 GMT"}], "update_date": "2018-08-09", "authors_parsed": [["Gao", "Peng", ""], ["Lu", "Pan", ""], ["Li", "Hongsheng", ""], ["Li", "Shuang", ""], ["Li", "Yikang", ""], ["Hoi", "Steven", ""], ["Wang", "Xiaogang", ""]]}, {"id": "1808.02636", "submitter": "Atri Mandal", "authors": "Atri Mandal, Nikhil Malhotra, Shivali Agarwal, Anupama Ray, Giriprasad\n  Sridhara", "title": "Cognitive system to achieve human-level accuracy in automated assignment\n  of helpdesk email tickets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ticket assignment/dispatch is a crucial part of service delivery business\nwith lot of scope for automation and optimization. In this paper, we present an\nend-to-end automated helpdesk email ticket assignment system, which is also\noffered as a service. The objective of the system is to determine the nature of\nthe problem mentioned in an incoming email ticket and then automatically\ndispatch it to an appropriate resolver group (or team) for resolution.\n  The proposed system uses an ensemble classifier augmented with a configurable\nrule engine. While design of classifier that is accurate is one of the main\nchallenges, we also need to address the need of designing a system that is\nrobust and adaptive to changing business needs. We discuss some of the main\ndesign challenges associated with email ticket assignment automation and how we\nsolve them. The design decisions for our system are driven by high accuracy,\ncoverage, business continuity, scalability and optimal usage of computational\nresources.\n  Our system has been deployed in production of three major service providers\nand currently assigning over 40,000 emails per month, on an average, with an\naccuracy close to 90% and covering at least 90% of email tickets. This\ntranslates to achieving human-level accuracy and results in a net saving of\nabout 23000 man-hours of effort per annum.\n", "versions": [{"version": "v1", "created": "Wed, 8 Aug 2018 06:04:35 GMT"}, {"version": "v2", "created": "Thu, 9 Aug 2018 06:27:47 GMT"}], "update_date": "2018-08-10", "authors_parsed": [["Mandal", "Atri", ""], ["Malhotra", "Nikhil", ""], ["Agarwal", "Shivali", ""], ["Ray", "Anupama", ""], ["Sridhara", "Giriprasad", ""]]}, {"id": "1808.02668", "submitter": "Corentin Kervadec", "authors": "Valentin Vielzeuf, Corentin Kervadec, St\\'ephane Pateux, Alexis\n  Lechervy, Fr\\'ed\\'eric Jurie", "title": "An Occam's Razor View on Learning Audiovisual Emotion Recognition with\n  Small Training Sets", "comments": null, "journal-ref": "ICMI (EmotiW) 2018, Oct 2018, Boulder, Colorado, United States", "doi": null, "report-no": null, "categories": "cs.AI cs.CV cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a light-weight and accurate deep neural model for\naudiovisual emotion recognition. To design this model, the authors followed a\nphilosophy of simplicity, drastically limiting the number of parameters to\nlearn from the target datasets, always choosing the simplest earning methods:\ni) transfer learning and low-dimensional space embedding allows to reduce the\ndimensionality of the representations. ii) The isual temporal information is\nhandled by a simple score-per-frame selection process, averaged across time.\niii) A simple frame selection echanism is also proposed to weight the images of\na sequence. iv) The fusion of the different modalities is performed at\nprediction level (late usion). We also highlight the inherent challenges of the\nAFEW dataset and the difficulty of model selection with as few as 383\nvalidation equences. The proposed real-time emotion classifier achieved a\nstate-of-the-art accuracy of 60.64 % on the test set of AFEW, and ranked 4th at\nhe Emotion in the Wild 2018 challenge.\n", "versions": [{"version": "v1", "created": "Wed, 8 Aug 2018 08:43:43 GMT"}], "update_date": "2018-08-09", "authors_parsed": [["Vielzeuf", "Valentin", ""], ["Kervadec", "Corentin", ""], ["Pateux", "St\u00e9phane", ""], ["Lechervy", "Alexis", ""], ["Jurie", "Fr\u00e9d\u00e9ric", ""]]}, {"id": "1808.02838", "submitter": "Amir Behrouzi-Far", "authors": "Amir Behrouzi-Far and Emina Soljanin", "title": "On the Effect of Task-to-Worker Assignment in Distributed Computing\n  Systems with Stragglers", "comments": "Accepted at the 56th Annual Allerton Conference on Communication,\n  Control, and Computing", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.AI cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the expected completion time of some recently proposed algorithms\nfor distributed computing which redundantly assign computing tasks to multiple\nmachines in order to tolerate a certain number of machine failures. We\nanalytically show that not only the amount of redundancy but also the\ntask-to-machine assignments affect the latency in a distributed system. We\nstudy systems with a fixed number of computing tasks that are split in possibly\noverlapping batches, and independent exponentially distributed machine service\ntimes. We show that, for such systems, the uniform replication of non-\noverlapping (disjoint) batches of computing tasks achieves the minimum expected\ncomputing time.\n", "versions": [{"version": "v1", "created": "Wed, 8 Aug 2018 15:51:18 GMT"}], "update_date": "2018-08-10", "authors_parsed": [["Behrouzi-Far", "Amir", ""], ["Soljanin", "Emina", ""]]}, {"id": "1808.02850", "submitter": "Medina Andresel", "authors": "Medina Andre\\c{s}el, Yazmin Ib\\'a\\~nez-Garc\\'ia, Magdalena Ortiz and\n  Mantas \\v{S}imkus", "title": "Relaxing and Restraining Queries for OBDA", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In ontology-based data access (OBDA), ontologies have been successfully\nemployed for querying possibly unstructured and incomplete data. In this paper,\nwe advocate using ontologies not only to formulate queries and compute their\nanswers, but also for modifying queries by relaxing or restraining them, so\nthat they can retrieve either more or less answers over a given dataset.\nTowards this goal, we first illustrate that some domain knowledge that could be\nnaturally leveraged in OBDA can be expressed using complex role inclusions\n(CRI). Queries over ontologies with CRI are not first-order (FO) rewritable in\ngeneral. We propose an extension of DL-Lite with CRI, and show that conjunctive\nqueries over ontologies in this extension are FO rewritable. Our main\ncontribution is a set of rules to relax and restrain conjunctive queries (CQs).\nFirstly, we define rules that use the ontology to produce CQs that are\nrelaxations/restrictions over any dataset. Secondly, we introduce a set of\ndata-driven rules, that leverage patterns in the current dataset, to obtain\nmore fine-grained relaxations and restrictions.\n", "versions": [{"version": "v1", "created": "Wed, 8 Aug 2018 16:27:52 GMT"}], "update_date": "2018-08-09", "authors_parsed": [["Andre\u015fel", "Medina", ""], ["Ib\u00e1\u00f1ez-Garc\u00eda", "Yazmin", ""], ["Ortiz", "Magdalena", ""], ["\u0160imkus", "Mantas", ""]]}, {"id": "1808.03043", "submitter": "Ronald de Haan", "authors": "Ronald de Haan", "title": "Hunting for Tractable Languages for Judgment Aggregation", "comments": "To appear in the Proceedings of the 16th International Conference on\n  Principles of Knowledge Representation and Reasoning (KR 2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CC cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Judgment aggregation is a general framework for collective decision making\nthat can be used to model many different settings. Due to its general nature,\nthe worst case complexity of essentially all relevant problems in this\nframework is very high. However, these intractability results are mainly due to\nthe fact that the language to represent the aggregation domain is overly\nexpressive. We initiate an investigation of representation languages for\njudgment aggregation that strike a balance between (1) being limited enough to\nyield computational tractability results and (2) being expressive enough to\nmodel relevant applications. In particular, we consider the languages of Krom\nformulas, (definite) Horn formulas, and Boolean circuits in decomposable\nnegation normal form (DNNF). We illustrate the use of the positive complexity\nresults that we obtain for these languages with a concrete application: voting\non how to spend a budget (i.e., participatory budgeting).\n", "versions": [{"version": "v1", "created": "Thu, 9 Aug 2018 07:16:56 GMT"}], "update_date": "2018-08-10", "authors_parsed": [["de Haan", "Ronald", ""]]}, {"id": "1808.03090", "submitter": "Ruihua Song", "authors": "Wen-Feng Cheng, Chao-Chung Wu, Ruihua Song, Jianlong Fu, Xing Xie,\n  Jian-Yun Nie", "title": "Image Inspired Poetry Generation in XiaoIce", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Vision is a common source of inspiration for poetry. The objects and the\nsentimental imprints that one perceives from an image may lead to various\nfeelings depending on the reader. In this paper, we present a system of poetry\ngeneration from images to mimic the process. Given an image, we first extract a\nfew keywords representing objects and sentiments perceived from the image.\nThese keywords are then expanded to related ones based on their associations in\nhuman written poems. Finally, verses are generated gradually from the keywords\nusing recurrent neural networks trained on existing poems. Our approach is\nevaluated by human assessors and compared to other generation baselines. The\nresults show that our method can generate poems that are more artistic than the\nbaseline methods. This is one of the few attempts to generate poetry from\nimages. By deploying our proposed approach, XiaoIce has already generated more\nthan 12 million poems for users since its release in July 2017. A book of its\npoems has been published by Cheers Publishing, which claimed that the book is\nthe first-ever poetry collection written by an AI in human history.\n", "versions": [{"version": "v1", "created": "Thu, 9 Aug 2018 11:17:38 GMT"}], "update_date": "2018-08-10", "authors_parsed": [["Cheng", "Wen-Feng", ""], ["Wu", "Chao-Chung", ""], ["Song", "Ruihua", ""], ["Fu", "Jianlong", ""], ["Xie", "Xing", ""], ["Nie", "Jian-Yun", ""]]}, {"id": "1808.03096", "submitter": "Mohammad Etemad", "authors": "Mohammad Etemad, Amilcar Soares Junior, Stan Matwin", "title": "On feature selection and evaluation of transportation mode prediction\n  strategies", "comments": "arXiv admin note: substantial text overlap with arXiv:1807.10876", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transportation modes prediction is a fundamental task for decision making in\nsmart cities and traffic management systems. Traffic policies designed based on\ntrajectory mining can save money and time for authorities and the public. It\nmay reduce the fuel consumption and commute time and moreover, may provide more\npleasant moments for residents and tourists. Since the number of features that\nmay be used to predict a user transportation mode can be substantial, finding a\nsubset of features that maximizes a performance measure is worth investigating.\nIn this work, we explore wrapper and information retrieval methods to find the\nbest subset of trajectory features. After finding the best classifier and the\nbest feature subset, our results were compared with two related papers that\napplied deep learning methods and the results showed that our framework\nachieved better performance. Furthermore, two types of cross-validation\napproaches were investigated, and the performance results show that the random\ncross-validation method provides optimistic results.\n", "versions": [{"version": "v1", "created": "Thu, 9 Aug 2018 11:27:11 GMT"}, {"version": "v2", "created": "Wed, 5 Sep 2018 20:29:07 GMT"}], "update_date": "2018-09-07", "authors_parsed": [["Etemad", "Mohammad", ""], ["Junior", "Amilcar Soares", ""], ["Matwin", "Stan", ""]]}, {"id": "1808.03130", "submitter": "Filip Murlak", "authors": "Tomasz Gogacz, Yazmin Ib\\'a\\~nez-Garc\\'ia, and Filip Murlak", "title": "Finite Query Answering in Expressive Description Logics with Transitive\n  Roles", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of finite ontology mediated query answering (FOMQA), the\nvariant of OMQA where the represented world is assumed to be finite, and thus\nonly finite models of the ontology are considered. We adopt the most typical\nsetting with unions of conjunctive queries and ontologies expressed in\ndescription logics (DLs). The study of FOMQA is relevant in settings that are\nnot finitely controllable. This is the case not only for DLs without the finite\nmodel property, but also for those allowing transitive role declarations. When\ntransitive roles are allowed, evaluating queries is challenging: FOMQA is\nundecidable for SHOIF and only known to be decidable for the Horn fragment of\nALCIF. We show decidability of FOMQA for three proper fragments of SOIF: SOI,\nSOF, and SIF. Our approach is to characterise models relevant for deciding\nfinite query entailment. Relying on a certain regularity of these models, we\ndevelop automata-based decision procedures with optimal complexity bounds.\n", "versions": [{"version": "v1", "created": "Thu, 9 Aug 2018 12:54:04 GMT"}], "update_date": "2018-08-10", "authors_parsed": [["Gogacz", "Tomasz", ""], ["Ib\u00e1\u00f1ez-Garc\u00eda", "Yazmin", ""], ["Murlak", "Filip", ""]]}, {"id": "1808.03147", "submitter": "Jacob Turner", "authors": "Gianluca Micchi, Saeid Soheily-Khah, and Jacob Turner", "title": "A New Optimization Layer for Real-Time Bidding Advertising Campaigns", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While it is relatively easy to start an online advertising campaign,\nobtaining a high Key Performance Indicator (KPI) can be challenging. A large\nbody of work on this subject has already been performed and platforms known as\nDSPs are available on the market that deal with such an optimization. From the\nadvertiser's point of view, each DSP is a different black box, with its pros\nand cons, that needs to be configured. In order to take advantage of the pros\nof every DSP, advertisers are well-advised to use a combination of them when\nsetting up their campaigns. In this paper, we propose an algorithm for\nadvertisers to add an optimization layer on top of DSPs. The algorithm we\nintroduce, called SKOTT, maximizes the chosen KPI by optimally configuring the\nDSPs and putting them in competition with each other. SKOTT is a highly\nspecialized iterative algorithm loosely based on gradient descent that is made\nup of three independent sub-routines, each dealing with a different problem:\npartitioning the budget, setting the desired average bid, and preventing\nunder-delivery. In particular, one of the novelties of our approach lies in our\ntaking the perspective of the advertisers rather than the DSPs. Synthetic\nmarket data is used to evaluate the efficiency of SKOTT against other\nstate-of-the-art approaches adapted from similar problems. The results\nillustrate the benefits of our proposals, which greatly outperforms the other\nmethods.\n", "versions": [{"version": "v1", "created": "Tue, 7 Aug 2018 19:04:40 GMT"}], "update_date": "2018-08-10", "authors_parsed": [["Micchi", "Gianluca", ""], ["Soheily-Khah", "Saeid", ""], ["Turner", "Jacob", ""]]}, {"id": "1808.03233", "submitter": "Chengrun Yang", "authors": "Chengrun Yang, Yuji Akimoto, Dae Won Kim, Madeleine Udell", "title": "OBOE: Collaborative Filtering for AutoML Model Selection", "comments": null, "journal-ref": null, "doi": "10.1145/3292500.3330909", "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Algorithm selection and hyperparameter tuning remain two of the most\nchallenging tasks in machine learning. Automated machine learning (AutoML)\nseeks to automate these tasks to enable widespread use of machine learning by\nnon-experts. This paper introduces OBOE, a collaborative filtering method for\ntime-constrained model selection and hyperparameter tuning. OBOE forms a matrix\nof the cross-validated errors of a large number of supervised learning models\n(algorithms together with hyperparameters) on a large number of datasets, and\nfits a low rank model to learn the low-dimensional feature vectors for the\nmodels and datasets that best predict the cross-validated errors. To find\npromising models for a new dataset, OBOE runs a set of fast but informative\nalgorithms on the new dataset and uses their cross-validated errors to infer\nthe feature vector for the new dataset. OBOE can find good models under\nconstraints on the number of models fit or the total time budget. To this end,\nthis paper develops a new heuristic for active learning in time-constrained\nmatrix completion based on optimal experiment design. Our experiments\ndemonstrate that OBOE delivers state-of-the-art performance faster than\ncompeting approaches on a test bed of supervised learning problems. Moreover,\nthe success of the bilinear model used by OBOE suggests that AutoML may be\nsimpler than was previously understood.\n", "versions": [{"version": "v1", "created": "Thu, 9 Aug 2018 16:56:04 GMT"}, {"version": "v2", "created": "Mon, 20 May 2019 19:55:26 GMT"}], "update_date": "2019-05-22", "authors_parsed": [["Yang", "Chengrun", ""], ["Akimoto", "Yuji", ""], ["Kim", "Dae Won", ""], ["Udell", "Madeleine", ""]]}, {"id": "1808.03387", "submitter": "Janardan Misra", "authors": "Janardan Misra", "title": "Computational Complexity of Observing Evolution in Artificial-Life Forms", "comments": "arXiv admin note: substantial text overlap with arXiv:0901.1610", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Observations are an essential component of the simulation based studies on\nartificial-evolutionary systems (AES) by which entities are identified and\ntheir behavior is observed to uncover higher-level \"emergent\" phenomena.\nBecause of the heterogeneity of AES models and implicit nature of observations,\nprecise characterization of the observation process, independent of the\nunderlying micro-level reaction semantics of the model, is a difficult problem.\nBuilding upon the multiset based algebraic framework to characterize\nstate-space trajectory of AES model simulations, we estimate bounds on\ncomputational resource requirements of the process of automatically discovering\nlife-like evolutionary behavior in AES models during simulations. For\nillustration, we consider the case of Langton's Cellular Automata model and\ncharacterize the worst case computational complexity bounds for identifying\nentity and population level reproduction.\n", "versions": [{"version": "v1", "created": "Sun, 24 Jun 2018 04:18:55 GMT"}], "update_date": "2018-08-13", "authors_parsed": [["Misra", "Janardan", ""]]}, {"id": "1808.03420", "submitter": "Dharma Teja Vooturi", "authors": "Dharma Teja Vooturi, Dheevatsa Mudigere, Sasikanth Avancha", "title": "Hierarchical Block Sparse Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sparse deep neural networks(DNNs) are efficient in both memory and compute\nwhen compared to dense DNNs. But due to irregularity in computation of sparse\nDNNs, their efficiencies are much lower than that of dense DNNs on regular\nparallel hardware such as TPU. This inefficiency leads to poor/no performance\nbenefits for sparse DNNs. Performance issue for sparse DNNs can be alleviated\nby bringing structure to the sparsity and leveraging it for improving runtime\nefficiency. But such structural constraints often lead to suboptimal\naccuracies. In this work, we jointly address both accuracy and performance of\nsparse DNNs using our proposed class of sparse neural networks called HBsNN\n(Hierarchical Block sparse Neural Networks). For a given sparsity, HBsNN models\nachieve better runtime performance than unstructured sparse models and better\naccuracy than highly structured sparse models.\n", "versions": [{"version": "v1", "created": "Fri, 10 Aug 2018 05:53:12 GMT"}, {"version": "v2", "created": "Fri, 28 Dec 2018 02:05:11 GMT"}], "update_date": "2018-12-31", "authors_parsed": [["Vooturi", "Dharma Teja", ""], ["Mudigere", "Dheevatsa", ""], ["Avancha", "Sasikanth", ""]]}, {"id": "1808.03454", "submitter": "Moshe BenBassat Professor", "authors": "Moshe BenBassat", "title": "AIQ: Measuring Intelligence of Business AI Software", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Focusing on Business AI, this article introduces the AIQ quadrant that\nenables us to measure AI for business applications in a relative comparative\nmanner, i.e. to judge that software A has more or less intelligence than\nsoftware B. Recognizing that the goal of Business software is to maximize value\nin terms of business results, the dimensions of the quadrant are the key\nfactors that determine the business value of AI software: Level of Output\nQuality (Smartness) and Level of Automation. The use of the quadrant is\nillustrated by several software solutions to support the real life business\nchallenge of field service scheduling. The role of machine learning and\nconversational digital assistants in increasing the business value are also\ndiscussed and illustrated with a recent integration of existing intelligent\ndigital assistants for factory floor decision making with the new version of\nGoogle Glass. Such hands free AI solutions elevate the AIQ level to its\nultimate position.\n", "versions": [{"version": "v1", "created": "Fri, 10 Aug 2018 08:40:32 GMT"}], "update_date": "2018-08-13", "authors_parsed": [["BenBassat", "Moshe", ""]]}, {"id": "1808.03519", "submitter": "Andreas Niederquell", "authors": "Andreas Niederquell", "title": "Self-Adaptive Systems in Organic Computing: Strategies for\n  Self-Improvement", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the intensified use of intelligent things, the demands on the\ntechnological systems are increasing permanently. A possible approach to meet\nthe continuously changing challenges is to shift the system integration from\ndesign to run-time by using adaptive systems. Diverse adaptivity properties,\nso-called self-* properties, form the basis of these systems and one of the\nproperties is self-improvement. It describes the ability of a system not only\nto adapt to a changing environment according to a predefined model, but also\nthe capability to adapt the adaptation logic of the whole system. In this\npaper, a closer look is taken at the structure of self-adaptive systems.\nAdditionally, the systems' ability to improve themselves during run-time is\ndescribed from the perspective of Organic Computing. Furthermore, four\ndifferent strategies for self-improvement are presented, following the taxonomy\nof self-adaptation suggested by Christian Krupitzer et al.\n", "versions": [{"version": "v1", "created": "Wed, 8 Aug 2018 13:56:29 GMT"}], "update_date": "2018-08-13", "authors_parsed": [["Niederquell", "Andreas", ""]]}, {"id": "1808.03598", "submitter": "Henok Ghebrechristos", "authors": "Henok Ghebrechristos, Drew Miller", "title": "Overarching Computation Model (OCM)", "comments": "We present a framework and use it to shed light on the p vs np\n  problem. More precisely we provide a proof for separating deterministic and\n  non-deterministic algorithms with underlying concept that the two processes\n  are fundamental and inherently different", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing models of computation, such as a Turing machine (hereafter, TM), do\nnot consider the agent involved in interpreting the outcome of the computation.\nWe argue that a TM, or any other computation model, has no significance if its\noutput is not interpreted by some agent. Furthermore, we argue that including\nthe interpreter in the model definition sheds light on some of the difficult\nproblems faced in computation and mathematics. We provide an analytic process\nframework to address this limitation. The framework can be overlaid on existing\nconcepts of computation to address many practical and philosophical concerns\nsuch as the P vs NP problem. In addition, we argue that the P vs NP problem is\nreminiscent of existing computation model which does not account for the person\nthat initiates the computation and interprets the intermediate and final\noutput. We utilize the observation that deterministic computational procedures\nlack fundamental capacity to fully simulate their non-deterministic variant to\nconclude that the set NP cannot be fully contained in P. Deterministic\nprocedure can approximate non-deterministic variant to some degree. However,\nthe logical implication of the fundamental differences between determinism and\nnon-determinism is that equivalence of the two classes is impossible to\nestablish.\n", "versions": [{"version": "v1", "created": "Wed, 1 Aug 2018 14:48:59 GMT"}, {"version": "v2", "created": "Mon, 13 Aug 2018 17:26:08 GMT"}], "update_date": "2018-08-14", "authors_parsed": [["Ghebrechristos", "Henok", ""], ["Miller", "Drew", ""]]}, {"id": "1808.03611", "submitter": "Zhenxing Xu", "authors": "Zhen-Xing Xu, Kun He, Chu-Min Li", "title": "An Iterative Path-Breaking Approach with Mutation and Restart Strategies\n  for the MAX-SAT Problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although Path-Relinking is an effective local search method for many\ncombinatorial optimization problems, its application is not straightforward in\nsolving the MAX-SAT, an optimization variant of the satisfiability problem\n(SAT) that has many real-world applications and has gained more and more\nattention in academy and industry. Indeed, it was not used in any recent\ncompetitive MAX-SAT algorithms in our knowledge. In this paper, we propose a\nnew local search algorithm called IPBMR for the MAX-SAT, that remedies the\ndrawbacks of the Path-Relinking method by using a careful combination of three\ncomponents: a new strategy named Path-Breaking to avoid unpromising regions of\nthe search space when generating trajectories between two elite solutions; a\nweak and a strong mutation strategies, together with restarts, to diversify the\nsearch; and stochastic path generating steps to avoid premature local optimum\nsolutions. We then present experimental results to show that IPBMR outperforms\ntwo of the best state-of-the-art MAX-SAT solvers, and an empirical\ninvestigation to identify and explain the effect of the three components in\nIPBMR.\n", "versions": [{"version": "v1", "created": "Fri, 10 Aug 2018 16:33:13 GMT"}], "update_date": "2018-08-13", "authors_parsed": [["Xu", "Zhen-Xing", ""], ["He", "Kun", ""], ["Li", "Chu-Min", ""]]}, {"id": "1808.03644", "submitter": "Roman Yampolskiy", "authors": "Micha\\\"el Trazzi, Roman V. Yampolskiy", "title": "Building Safer AGI by introducing Artificial Stupidity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Artificial Intelligence (AI) achieved super-human performance in a broad\nvariety of domains. We say that an AI is made Artificially Stupid on a task\nwhen some limitations are deliberately introduced to match a human's ability to\ndo the task. An Artificial General Intelligence (AGI) can be made safer by\nlimiting its computing power and memory, or by introducing Artificial Stupidity\non certain tasks. We survey human intellectual limits and give recommendations\nfor which limits to implement in order to build a safe AGI.\n", "versions": [{"version": "v1", "created": "Sat, 11 Aug 2018 00:14:33 GMT"}], "update_date": "2018-08-14", "authors_parsed": [["Trazzi", "Micha\u00ebl", ""], ["Yampolskiy", "Roman V.", ""]]}, {"id": "1808.03677", "submitter": "Sandro Sozzo", "authors": "Diederik Aerts, Massimiliano Sassoli de Bianchi, Sandro Sozzo, Tomas\n  Veloz", "title": "Modeling Meaning Associated with Documental Entities: Introducing the\n  Brussels Quantum Approach", "comments": "27 pages, 6 figures, LateX", "journal-ref": null, "doi": "10.1007/978-3-030-25913-6_1", "report-no": null, "categories": "cs.IR cs.AI quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that the Brussels operational-realistic approach to quantum physics\nand quantum cognition offers a fundamental strategy for modeling the meaning\nassociated with collections of documental entities. To do so, we take the World\nWide Web as a paradigmatic example and emphasize the importance of\ndistinguishing the Web, made of printed documents, from a more abstract meaning\nentity, which we call the Quantum Web, or QWeb, where the former is considered\nto be the collection of traces that can be left by the latter, in specific\nmeasurements, similarly to how a non-spatial quantum entity, like an electron,\ncan leave localized traces of impact on a detection screen. The double-slit\nexperiment is extensively used to illustrate the rationale of the modeling,\nwhich is guided by how physicists constructed quantum theory to describe the\nbehavior of the microscopic entities. We also emphasize that the superposition\nprinciple and the associated interference effects are not sufficient to model\nall experimental probabilistic data, like those obtained by counting the\nrelative number of documents containing certain words and co-occurrences of\nwords. For this, additional effects, like context effects, must also be taken\ninto consideration.\n", "versions": [{"version": "v1", "created": "Fri, 3 Aug 2018 08:08:51 GMT"}], "update_date": "2021-04-08", "authors_parsed": [["Aerts", "Diederik", ""], ["de Bianchi", "Massimiliano Sassoli", ""], ["Sozzo", "Sandro", ""], ["Veloz", "Tomas", ""]]}, {"id": "1808.03726", "submitter": "Muhao Chen", "authors": "Muhao Chen, Yingtao Tian, Haochen Chen, Kai-Wei Chang, Steven Skiena,\n  Carlo Zaniolo", "title": "Learning to Represent Bilingual Dictionaries", "comments": "CoNLL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bilingual word embeddings have been widely used to capture the similarity of\nlexical semantics in different human languages. However, many applications,\nsuch as cross-lingual semantic search and question answering, can be largely\nbenefited from the cross-lingual correspondence between sentences and lexicons.\nTo bridge this gap, we propose a neural embedding model that leverages\nbilingual dictionaries. The proposed model is trained to map the literal word\ndefinitions to the cross-lingual target words, for which we explore with\ndifferent sentence encoding techniques. To enhance the learning process on\nlimited resources, our model adopts several critical learning strategies,\nincluding multi-task learning on different bridges of languages, and joint\nlearning of the dictionary model with a bilingual word embedding model.\nExperimental evaluation focuses on two applications. The results of the\ncross-lingual reverse dictionary retrieval task show our model's promising\nability of comprehending bilingual concepts based on descriptions, and\nhighlight the effectiveness of proposed learning strategies in improving\nperformance. Meanwhile, our model effectively addresses the bilingual\nparaphrase identification problem and significantly outperforms previous\napproaches.\n", "versions": [{"version": "v1", "created": "Fri, 10 Aug 2018 23:21:07 GMT"}, {"version": "v2", "created": "Fri, 31 Aug 2018 10:14:33 GMT"}, {"version": "v3", "created": "Fri, 6 Sep 2019 20:14:24 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["Chen", "Muhao", ""], ["Tian", "Yingtao", ""], ["Chen", "Haochen", ""], ["Chang", "Kai-Wei", ""], ["Skiena", "Steven", ""], ["Zaniolo", "Carlo", ""]]}, {"id": "1808.03736", "submitter": "Renata Wong", "authors": "Renata Wong", "title": "An Implementation, Empirical Evaluation and Proposed Improvement for\n  Bidirectional Splitting Method for Argumentation Frameworks under Stable\n  Semantics", "comments": "19 pages", "journal-ref": "Journal of Artificial Intelligence and Applications, Vol.9, No.4,\n  2018, pp. 11-29", "doi": "10.5121/ijaia.2018.9402", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Abstract argumentation frameworks are formal systems that facilitate\nobtaining conclusions from non-monotonic knowledge systems. Within such a\nsystem, an argumentation semantics is defined as a set of arguments with some\ndesired qualities, for example, that the elements are not in conflict with each\nother. Splitting an argumentation framework can efficiently speed up the\ncomputation of argumentation semantics. With respect to stable semantics, two\nmethods have been proposed to split an argumentation framework either in a\nunidirectional or bidirectional fashion. The advantage of bidirectional\nsplitting is that it is not structure-dependent and, unlike unidirectional\nsplitting, it can be used for frameworks consisting of a single strongly\nconnected component. Bidirectional splitting makes use of a minimum cut. In\nthis paper, we implement and test the performance of the bidirectional\nsplitting method, along with two types of graph cut algorithms. Experimental\ndata suggest that using a minimum cut will not improve the performance of\ncomputing stable semantics in most cases. Hence, instead of a minimum cut, we\npropose to use a balanced cut, where the framework is split into two\nsub-frameworks of equal size. Experimental results conducted on bidirectional\nsplitting using the balanced cut show a significant improvement in the\nperformance of computing semantics.\n", "versions": [{"version": "v1", "created": "Sat, 11 Aug 2018 01:52:57 GMT"}], "update_date": "2018-08-14", "authors_parsed": [["Wong", "Renata", ""]]}, {"id": "1808.03737", "submitter": "Kan Ren", "authors": "Kan Ren, Yuchen Fang, Weinan Zhang, Shuhao Liu, Jiajun Li, Ya Zhang,\n  Yong Yu, Jun Wang", "title": "Learning Multi-touch Conversion Attribution with Dual-attention\n  Mechanisms for Online Advertising", "comments": "10 pages, 11 figures; CIKM 2018", "journal-ref": null, "doi": "10.1145/3269206.3271677", "report-no": null, "categories": "cs.IR cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In online advertising, the Internet users may be exposed to a sequence of\ndifferent ad campaigns, i.e., display ads, search, or referrals from multiple\nchannels, before led up to any final sales conversion and transaction. For both\ncampaigners and publishers, it is fundamentally critical to estimate the\ncontribution from ad campaign touch-points during the customer journey\n(conversion funnel) and assign the right credit to the right ad exposure\naccordingly. However, the existing research on the multi-touch attribution\nproblem lacks a principled way of utilizing the users' pre-conversion actions\n(i.e., clicks), and quite often fails to model the sequential patterns among\nthe touch points from a user's behavior data. To make it worse, the current\nindustry practice is merely employing a set of arbitrary rules as the\nattribution model, e.g., the popular last-touch model assigns 100% credit to\nthe final touch-point regardless of actual attributions. In this paper, we\npropose a Dual-attention Recurrent Neural Network (DARNN) for the multi-touch\nattribution problem. It learns the attribution values through an attention\nmechanism directly from the conversion estimation objective. To achieve this,\nwe utilize sequence-to-sequence prediction for user clicks, and combine both\npost-view and post-click attribution patterns together for the final conversion\nestimation. To quantitatively benchmark attribution models, we also propose a\nnovel yet practical attribution evaluation scheme through the proxy of budget\nallocation (under the estimated attributions) over ad channels. The\nexperimental results on two real datasets demonstrate the significant\nperformance gains of our attribution model against the state of the art.\n", "versions": [{"version": "v1", "created": "Sat, 11 Aug 2018 01:58:19 GMT"}, {"version": "v2", "created": "Thu, 30 Aug 2018 01:31:31 GMT"}], "update_date": "2018-08-31", "authors_parsed": [["Ren", "Kan", ""], ["Fang", "Yuchen", ""], ["Zhang", "Weinan", ""], ["Liu", "Shuhao", ""], ["Li", "Jiajun", ""], ["Zhang", "Ya", ""], ["Yu", "Yong", ""], ["Wang", "Jun", ""]]}, {"id": "1808.03852", "submitter": "Ronald de Haan", "authors": "Ronald de Haan", "title": "A Parameterized Complexity View on Description Logic Reasoning", "comments": "To appear in the Proceedings of the 16th International Conference on\n  Principles of Knowledge Representation and Reasoning (KR 2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Description logics are knowledge representation languages that have been\ndesigned to strike a balance between expressivity and computational\ntractability. Many different description logics have been developed, and\nnumerous computational problems for these logics have been studied for their\ncomputational complexity. However, essentially all complexity analyses of\nreasoning problems for description logics use the one-dimensional framework of\nclassical complexity theory. The multi-dimensional framework of parameterized\ncomplexity theory is able to provide a much more detailed image of the\ncomplexity of reasoning problems.\n  In this paper we argue that the framework of parameterized complexity has a\nlot to offer for the complexity analysis of description logic reasoning\nproblems---when one takes a progressive and forward-looking view on\nparameterized complexity tools. We substantiate our argument by means of three\ncase studies. The first case study is about the problem of concept\nsatisfiability for the logic ALC with respect to nearly acyclic TBoxes. The\nsecond case study concerns concept satisfiability for ALC concepts\nparameterized by the number of occurrences of union operators and the number of\noccurrences of full existential quantification. The third case study offers a\ncritical look at data complexity results from a parameterized complexity point\nof view. These three case studies are representative for the wide range of uses\nfor parameterized complexity methods for description logic problems.\n", "versions": [{"version": "v1", "created": "Sat, 11 Aug 2018 19:25:04 GMT"}], "update_date": "2018-08-14", "authors_parsed": [["de Haan", "Ronald", ""]]}, {"id": "1808.03894", "submitter": "Reza Ghaeini", "authors": "Reza Ghaeini, Xiaoli Z. Fern, Prasad Tadepalli", "title": "Interpreting Recurrent and Attention-Based Neural Models: a Case Study\n  on Natural Language Inference", "comments": "11 pages, 11 figures, accepted as a short paper at EMNLP 2018", "journal-ref": "EMNLP 2018", "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning models have achieved remarkable success in natural language\ninference (NLI) tasks. While these models are widely explored, they are hard to\ninterpret and it is often unclear how and why they actually work. In this\npaper, we take a step toward explaining such deep learning based models through\na case study on a popular neural model for NLI. In particular, we propose to\ninterpret the intermediate layers of NLI models by visualizing the saliency of\nattention and LSTM gating signals. We present several examples for which our\nmethods are able to reveal interesting insights and identify the critical\ninformation contributing to the model decisions.\n", "versions": [{"version": "v1", "created": "Sun, 12 Aug 2018 05:42:26 GMT"}], "update_date": "2019-05-21", "authors_parsed": [["Ghaeini", "Reza", ""], ["Fern", "Xiaoli Z.", ""], ["Tadepalli", "Prasad", ""]]}, {"id": "1808.03920", "submitter": "Paul Pu Liang", "authors": "Paul Pu Liang, Ziyin Liu, Amir Zadeh, Louis-Philippe Morency", "title": "Multimodal Language Analysis with Recurrent Multistage Fusion", "comments": "EMNLP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computational modeling of human multimodal language is an emerging research\narea in natural language processing spanning the language, visual and acoustic\nmodalities. Comprehending multimodal language requires modeling not only the\ninteractions within each modality (intra-modal interactions) but more\nimportantly the interactions between modalities (cross-modal interactions). In\nthis paper, we propose the Recurrent Multistage Fusion Network (RMFN) which\ndecomposes the fusion problem into multiple stages, each of them focused on a\nsubset of multimodal signals for specialized, effective fusion. Cross-modal\ninteractions are modeled using this multistage fusion approach which builds\nupon intermediate representations of previous stages. Temporal and intra-modal\ninteractions are modeled by integrating our proposed fusion approach with a\nsystem of recurrent neural networks. The RMFN displays state-of-the-art\nperformance in modeling human multimodal language across three public datasets\nrelating to multimodal sentiment analysis, emotion recognition, and speaker\ntraits recognition. We provide visualizations to show that each stage of fusion\nfocuses on a different subset of multimodal signals, learning increasingly\ndiscriminative multimodal representations.\n", "versions": [{"version": "v1", "created": "Sun, 12 Aug 2018 10:04:45 GMT"}], "update_date": "2018-08-14", "authors_parsed": [["Liang", "Paul Pu", ""], ["Liu", "Ziyin", ""], ["Zadeh", "Amir", ""], ["Morency", "Louis-Philippe", ""]]}, {"id": "1808.03944", "submitter": "Chengjia Wang", "authors": "Chengjia Wang, Gillian Macnaught, Giorgos Papanastasiou, Tom\n  MacGillivray, and David Newby", "title": "Unsupervised learning for cross-domain medical image synthesis using\n  deformation invariant cycle consistency networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, the cycle-consistent generative adversarial networks (CycleGAN) has\nbeen widely used for synthesis of multi-domain medical images. The\ndomain-specific nonlinear deformations captured by CycleGAN make the\nsynthesized images difficult to be used for some applications, for example,\ngenerating pseudo-CT for PET-MR attenuation correction. This paper presents a\ndeformation-invariant CycleGAN (DicycleGAN) method using deformable\nconvolutional layers and new cycle-consistency losses. Its robustness dealing\nwith data that suffer from domain-specific nonlinear deformations has been\nevaluated through comparison experiments performed on a multi-sequence brain MR\ndataset and a multi-modality abdominal dataset. Our method has displayed its\nability to generate synthesized data that is aligned with the source while\nmaintaining a proper quality of signal compared to CycleGAN-generated data. The\nproposed model also obtained comparable performance with CycleGAN when data\nfrom the source and target domains are alignable through simple affine\ntransformations.\n", "versions": [{"version": "v1", "created": "Sun, 12 Aug 2018 13:49:19 GMT"}], "update_date": "2018-08-14", "authors_parsed": [["Wang", "Chengjia", ""], ["Macnaught", "Gillian", ""], ["Papanastasiou", "Giorgos", ""], ["MacGillivray", "Tom", ""], ["Newby", "David", ""]]}, {"id": "1808.03948", "submitter": "Florentin Smarandache", "authors": "Florentin Smarandache", "title": "Plithogeny, Plithogenic Set, Logic, Probability, and Statistics", "comments": "141 pages, Physical Plithogenic Set (approved), 71st Annual Gaseous\n  Electronics Conference, American Physical Society, November 2018, Portland,\n  Oregon, and Pons, Brussels, 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this book we introduce the plithogenic set (as generalization of crisp,\nfuzzy, intuitionistic fuzzy, and neutrosophic sets), plithogenic logic (as\ngeneralization of classical, fuzzy, intuitionistic fuzzy, and neutrosophic\nlogics), plithogenic probability (as generalization of classical, imprecise,\nand neutrosophic probabilities), and plithogenic statistics (as generalization\nof classical, and neutrosophic statistics). Plithogenic Set is a set whose\nelements are characterized by one or more attributes, and each attribute may\nhave many values. An attribute value v has a corresponding (fuzzy,\nintuitionistic fuzzy, or neutrosophic) degree of appurtenance d(x,v) of the\nelement x, to the set P, with respect to some given criteria. In order to\nobtain a better accuracy for the plithogenic aggregation operators in the\nplithogenic set, logic, probability and for a more exact inclusion (partial\norder), a (fuzzy, intuitionistic fuzzy, or neutrosophic) contradiction\n(dissimilarity) degree is defined between each attribute value and the dominant\n(most important) attribute value. The plithogenic intersection and union are\nlinear combinations of the fuzzy operators tnorm and tconorm, while the\nplithogenic complement, inclusion, equality are influenced by the attribute\nvalues contradiction (dissimilarity) degrees. Formal definitions of plithogenic\nset, logic, probability, statistics are presented into the book, followed by\nplithogenic aggregation operators, various theorems related to them, and\nafterwards examples and applications of these new concepts in our everyday\nlife.\n", "versions": [{"version": "v1", "created": "Sun, 12 Aug 2018 14:14:45 GMT"}], "update_date": "2018-08-14", "authors_parsed": [["Smarandache", "Florentin", ""]]}, {"id": "1808.03986", "submitter": "Badri Narayana Patro", "authors": "Badri N. Patro, Sandeep Kumar, Vinod K. Kurmi, Vinay P. Namboodiri", "title": "Multimodal Differential Network for Visual Question Generation", "comments": "EMNLP 2018 (accepted)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.CV", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Generating natural questions from an image is a semantic task that requires\nusing visual and language modality to learn multimodal representations. Images\ncan have multiple visual and language contexts that are relevant for generating\nquestions namely places, captions, and tags. In this paper, we propose the use\nof exemplars for obtaining the relevant context. We obtain this by using a\nMultimodal Differential Network to produce natural and engaging questions. The\ngenerated questions show a remarkable similarity to the natural questions as\nvalidated by a human study. Further, we observe that the proposed approach\nsubstantially improves over state-of-the-art benchmarks on the quantitative\nmetrics (BLEU, METEOR, ROUGE, and CIDEr).\n", "versions": [{"version": "v1", "created": "Sun, 12 Aug 2018 18:56:56 GMT"}, {"version": "v2", "created": "Thu, 17 Oct 2019 10:23:19 GMT"}], "update_date": "2019-10-18", "authors_parsed": [["Patro", "Badri N.", ""], ["Kumar", "Sandeep", ""], ["Kurmi", "Vinod K.", ""], ["Namboodiri", "Vinay P.", ""]]}, {"id": "1808.04043", "submitter": "Shizhe Zhao", "authors": "Shizhe Zhao, Daniel D. Harabor, David Taniar", "title": "Faster and More Robust Mesh-based Algorithms for Obstacle k-Nearest\n  Neighbour", "comments": "submitted on Journal of Artificial Intelligence Research 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We are interested in the problem of finding $k$ nearest neighbours in the\nplane and in the presence of polygonal obstacles ($\\textit{OkNN}$). Widely used\nalgorithms for OkNN are based on incremental visibility graphs, which means\nthey require costly and online visibility checking and have worst-case\nquadratic running time. Recently $\\mathbf{Polyanya}$, a fast point-to-point\npathfinding algorithm was proposed which avoids the disadvantages of visibility\ngraphs by searching over an alternative data structure known as a navigation\nmesh. Previously, we adapted $\\mathbf{Polyanya}$ to multi-target scenarios by\ndeveloping two specialised heuristic functions: the $\\mathbf{Interval\nheuristic}$ $h_v$ and the $\\mathbf{Target heuristic}$ $h_t$. Though these\nmethods outperform visibility graph algorithms by orders of magnitude in all\nour experiments they are not robust: $h_v$ expands many redundant nodes when\nthe set of neighbours is small while $h_t$ performs poorly when the set of\nneighbours is large. In this paper, we propose new algorithms and heuristics\nfor OkNN which perform well regardless of neighbour density.\n", "versions": [{"version": "v1", "created": "Mon, 13 Aug 2018 02:05:27 GMT"}], "update_date": "2018-08-14", "authors_parsed": [["Zhao", "Shizhe", ""], ["Harabor", "Daniel D.", ""], ["Taniar", "David", ""]]}, {"id": "1808.04096", "submitter": "H\\'el\\`ene Plisnier", "authors": "H\\'el\\`ene Plisnier, Denis Steckelmacher, Tim Brys, Diederik M.\n  Roijers, Ann Now\\'e", "title": "Directed Policy Gradient for Safe Reinforcement Learning with Human\n  Advice", "comments": "Accepted at the European Workshop on Reinforcement Learning 2018\n  (EWRL14)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many currently deployed Reinforcement Learning agents work in an environment\nshared with humans, be them co-workers, users or clients. It is desirable that\nthese agents adjust to people's preferences, learn faster thanks to their help,\nand act safely around them. We argue that most current approaches that learn\nfrom human feedback are unsafe: rewarding or punishing the agent a-posteriori\ncannot immediately prevent it from wrong-doing. In this paper, we extend Policy\nGradient to make it robust to external directives, that would otherwise break\nthe fundamentally on-policy nature of Policy Gradient. Our technique, Directed\nPolicy Gradient (DPG), allows a teacher or backup policy to override the agent\nbefore it acts undesirably, while allowing the agent to leverage human advice\nor directives to learn faster. Our experiments demonstrate that DPG makes the\nagent learn much faster than reward-based approaches, while requiring an order\nof magnitude less advice.\n", "versions": [{"version": "v1", "created": "Mon, 13 Aug 2018 08:12:22 GMT"}], "update_date": "2018-08-14", "authors_parsed": [["Plisnier", "H\u00e9l\u00e8ne", ""], ["Steckelmacher", "Denis", ""], ["Brys", "Tim", ""], ["Roijers", "Diederik M.", ""], ["Now\u00e9", "Ann", ""]]}, {"id": "1808.04217", "submitter": "Siddhartha Brahma", "authors": "Siddhartha Brahma", "title": "Unsupervised Learning of Sentence Representations Using Sequence\n  Consistency", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computing universal distributed representations of sentences is a fundamental\ntask in natural language processing. We propose ConsSent, a simple yet\nsurprisingly powerful unsupervised method to learn such representations by\nenforcing consistency constraints on sequences of tokens. We consider two\nclasses of such constraints -- sequences that form a sentence and between two\nsequences that form a sentence when merged. We learn sentence encoders by\ntraining them to distinguish between consistent and inconsistent examples, the\nlatter being generated by randomly perturbing consistent examples in six\ndifferent ways. Extensive evaluation on several transfer learning and\nlinguistic probing tasks shows improved performance over strong unsupervised\nand supervised baselines, substantially surpassing them in several cases. Our\nbest results are achieved by training sentence encoders in a multitask setting\nand by an ensemble of encoders trained on the individual tasks.\n", "versions": [{"version": "v1", "created": "Fri, 10 Aug 2018 08:15:01 GMT"}, {"version": "v2", "created": "Sat, 29 Sep 2018 16:24:31 GMT"}, {"version": "v3", "created": "Thu, 3 Jan 2019 19:25:44 GMT"}, {"version": "v4", "created": "Wed, 23 Jan 2019 19:54:25 GMT"}], "update_date": "2019-01-25", "authors_parsed": [["Brahma", "Siddhartha", ""]]}, {"id": "1808.04228", "submitter": "Zhan Yang", "authors": "Zhan Yang, Osolo Ian Raymond, ChengYuan Zhang, Ying Wan, Jun Long", "title": "DFTerNet: Towards 2-bit Dynamic Fusion Networks for Accurate Human\n  Activity Recognition", "comments": "19 pages, 5 figures, 6 tables, accepted by IEEE Access", "journal-ref": "IEEE ACCESS, vol. 6, pp. 56750-56764, 2018", "doi": "10.1109/ACCESS.2018.2873315", "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.HC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Convolutional Neural Networks (DCNNs) are currently popular in human\nactivity recognition applications. However, in the face of modern artificial\nintelligence sensor-based games, many research achievements cannot be\npractically applied on portable devices. DCNNs are typically resource-intensive\nand too large to be deployed on portable devices, thus this limits the\npractical application of complex activity detection. In addition, since\nportable devices do not possess high-performance Graphic Processing Units\n(GPUs), there is hardly any improvement in Action Game (ACT) experience.\nBesides, in order to deal with multi-sensor collaboration, all previous human\nactivity recognition models typically treated the representations from\ndifferent sensor signal sources equally. However, distinct types of activities\nshould adopt different fusion strategies. In this paper, a novel scheme is\nproposed. This scheme is used to train 2-bit Convolutional Neural Networks with\nweights and activations constrained to {-0.5,0,0.5}. It takes into account the\ncorrelation between different sensor signal sources and the activity types.\nThis model, which we refer to as DFTerNet, aims at producing a more reliable\ninference and better trade-offs for practical applications. Our basic idea is\nto exploit quantization of weights and activations directly in pre-trained\nfilter banks and adopt dynamic fusion strategies for different activity types.\nExperiments demonstrate that by using dynamic fusion strategy can exceed the\nbaseline model performance by up to ~5% on activity recognition like\nOPPORTUNITY and PAMAP2 datasets. Using the quantization method proposed, we\nwere able to achieve performances closer to that of full-precision counterpart.\nThese results were also verified using the UniMiB-SHAR dataset. In addition,\nthe proposed method can achieve ~9x acceleration on CPUs and ~11x memory\nsaving.\n", "versions": [{"version": "v1", "created": "Tue, 31 Jul 2018 02:33:34 GMT"}, {"version": "v2", "created": "Sat, 29 Sep 2018 04:47:24 GMT"}], "update_date": "2018-12-05", "authors_parsed": [["Yang", "Zhan", ""], ["Raymond", "Osolo Ian", ""], ["Zhang", "ChengYuan", ""], ["Wan", "Ying", ""], ["Long", "Jun", ""]]}, {"id": "1808.04245", "submitter": "Dongrui Wu", "authors": "Dongrui Wu and Chin-Teng Lin and Jian Huang", "title": "Active Learning for Regression Using Greedy Sampling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Regression problems are pervasive in real-world applications. Generally a\nsubstantial amount of labeled samples are needed to build a regression model\nwith good generalization ability. However, many times it is relatively easy to\ncollect a large number of unlabeled samples, but time-consuming or expensive to\nlabel them. Active learning for regression (ALR) is a methodology to reduce the\nnumber of labeled samples, by selecting the most beneficial ones to label,\ninstead of random selection. This paper proposes two new ALR approaches based\non greedy sampling (GS). The first approach (GSy) selects new samples to\nincrease the diversity in the output space, and the second (iGS) selects new\nsamples to increase the diversity in both input and output spaces. Extensive\nexperiments on 12 UCI and CMU StatLib datasets from various domains, and on 15\nsubjects on EEG-based driver drowsiness estimation, verified their\neffectiveness and robustness.\n", "versions": [{"version": "v1", "created": "Wed, 8 Aug 2018 22:29:19 GMT"}], "update_date": "2018-08-14", "authors_parsed": [["Wu", "Dongrui", ""], ["Lin", "Chin-Teng", ""], ["Huang", "Jian", ""]]}, {"id": "1808.04247", "submitter": "Truyen Tran", "authors": "Trang Pham, Truyen Tran, Svetha Venkatesh", "title": "Relational dynamic memory networks", "comments": "Previous versions published in 3rd Representation Learning for Graphs\n  Workshop (ReLiG 2017), ICPR'18, and NeurIPS'18 Workshop on machine learning\n  for molecules and materials; arXiv admin note: text overlap with\n  arXiv:1801.02622\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks excel in detecting regular patterns but are less successful\nin representing and manipulating complex data structures, possibly due to the\nlack of an external memory. This has led to the recent development of a new\nline of architectures known as Memory-Augmented Neural Networks (MANNs), each\nof which consists of a neural network that interacts with an external memory\nmatrix. However, this RAM-like memory matrix is unstructured and thus does not\nnaturally encode structured objects. Here we design a new MANN dubbed\nRelational Dynamic Memory Network (RMDN) to bridge the gap. Like existing\nMANNs, RMDN has a neural controller but its memory is structured as\nmulti-relational graphs. RMDN uses the memory to represent and manipulate\ngraph-structured data in response to query; and as a neural network, RMDN is\ntrainable from labeled data. Thus RMDN learns to answer queries about a set of\ngraph-structured objects without explicit programming. We evaluate the\ncapability of RMDN on several important prediction problems, including software\nvulnerability, molecular bioactivity and chemical-chemical interaction. Results\ndemonstrate the efficacy of the proposed model.\n", "versions": [{"version": "v1", "created": "Fri, 10 Aug 2018 00:01:34 GMT"}, {"version": "v2", "created": "Tue, 30 Oct 2018 02:17:15 GMT"}, {"version": "v3", "created": "Wed, 28 Nov 2018 03:19:09 GMT"}], "update_date": "2018-11-29", "authors_parsed": [["Pham", "Trang", ""], ["Tran", "Truyen", ""], ["Venkatesh", "Svetha", ""]]}, {"id": "1808.04287", "submitter": "Paul Jasek", "authors": "Paul Jasek and Bernard Abayowa", "title": "Visual Sensor Network Reconfiguration with Deep Reinforcement Learning", "comments": "6 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an approach for reconfiguration of dynamic visual sensor networks\nwith deep reinforcement learning (RL). Our RL agent uses a modified\nasynchronous advantage actor-critic framework and the recently proposed\nRelational Network module at the foundation of its network architecture. To\naddress the issue of sample inefficiency in current approaches to model-free\nreinforcement learning, we train our system in an abstract simulation\nenvironment that represents inputs from a dynamic scene. Our system is\nvalidated using inputs from a real-world scenario and preexisting object\ndetection and tracking algorithms.\n", "versions": [{"version": "v1", "created": "Mon, 13 Aug 2018 15:24:01 GMT"}], "update_date": "2018-08-14", "authors_parsed": [["Jasek", "Paul", ""], ["Abayowa", "Bernard", ""]]}, {"id": "1808.04295", "submitter": "Zhiqin Xu", "authors": "Zhiqin John Xu", "title": "Understanding training and generalization in deep learning by Fourier\n  analysis", "comments": "10 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI math.OC math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Background: It is still an open research area to theoretically understand why\nDeep Neural Networks (DNNs)---equipped with many more parameters than training\ndata and trained by (stochastic) gradient-based methods---often achieve\nremarkably low generalization error. Contribution: We study DNN training by\nFourier analysis. Our theoretical framework explains: i) DNN with (stochastic)\ngradient-based methods often endows low-frequency components of the target\nfunction with a higher priority during the training; ii) Small initialization\nleads to good generalization ability of DNN while preserving the DNN's ability\nto fit any function. These results are further confirmed by experiments of DNNs\nfitting the following datasets, that is, natural images, one-dimensional\nfunctions and MNIST dataset.\n", "versions": [{"version": "v1", "created": "Mon, 13 Aug 2018 15:40:41 GMT"}, {"version": "v2", "created": "Tue, 21 Aug 2018 21:01:43 GMT"}, {"version": "v3", "created": "Tue, 18 Sep 2018 01:14:01 GMT"}, {"version": "v4", "created": "Thu, 29 Nov 2018 03:20:18 GMT"}], "update_date": "2018-11-30", "authors_parsed": [["Xu", "Zhiqin John", ""]]}, {"id": "1808.04317", "submitter": "Hugo Scurti", "authors": "Hugo Scurti, Clark Verbrugge", "title": "Generating Paths with WFC", "comments": "7 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motion plans are often randomly generated for minor game NPCs. Repetitive or\nregular movements, however, require non-trivial programming effort and/or\nintegration with a pathing system. We here describe an example-based approach\nto path generation that requires little or no additional programming effort.\nOur work modifies the Wave Function Collapse (WFC) algorithm, adapting it to\nproduce pathing plans similar to an input sketch. We show how simple sketch\nmodifications control path characteristics, and demonstrate feasibility through\na usable Unity implementation.\n", "versions": [{"version": "v1", "created": "Mon, 13 Aug 2018 16:21:00 GMT"}], "update_date": "2018-08-14", "authors_parsed": [["Scurti", "Hugo", ""], ["Verbrugge", "Clark", ""]]}, {"id": "1808.04343", "submitter": "Siddhartha Brahma", "authors": "Siddhartha Brahma", "title": "REGMAPR - Text Matching Made Easy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Text matching is a fundamental problem in natural language processing. Neural\nmodels using bidirectional LSTMs for sentence encoding and inter-sentence\nattention mechanisms perform remarkably well on several benchmark datasets. We\npropose REGMAPR - a simple and general architecture for text matching that does\nnot use inter-sentence attention. Starting from a Siamese architecture, we\naugment the embeddings of the words with two features based on exact and para-\nphrase match between words in the two sentences. We train the model using three\ntypes of regularization on datasets for textual entailment, paraphrase\ndetection and semantic related- ness. REGMAPR performs comparably or better\nthan more complex neural models or models using a large number of handcrafted\nfeatures. REGMAPR achieves state-of-the-art results for paraphrase detection on\nthe SICK dataset and for textual entailment on the SNLI dataset among models\nthat do not use inter-sentence attention.\n", "versions": [{"version": "v1", "created": "Mon, 13 Aug 2018 17:38:54 GMT"}, {"version": "v2", "created": "Wed, 29 Aug 2018 03:28:55 GMT"}, {"version": "v3", "created": "Mon, 10 Sep 2018 22:12:53 GMT"}], "update_date": "2018-09-12", "authors_parsed": [["Brahma", "Siddhartha", ""]]}, {"id": "1808.04355", "submitter": "Deepak Pathak", "authors": "Yuri Burda, Harri Edwards, Deepak Pathak, Amos Storkey, Trevor\n  Darrell, Alexei A. Efros", "title": "Large-Scale Study of Curiosity-Driven Learning", "comments": "First three authors contributed equally and ordered alphabetically.\n  Website at https://pathak22.github.io/large-scale-curiosity/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning algorithms rely on carefully engineering environment\nrewards that are extrinsic to the agent. However, annotating each environment\nwith hand-designed, dense rewards is not scalable, motivating the need for\ndeveloping reward functions that are intrinsic to the agent. Curiosity is a\ntype of intrinsic reward function which uses prediction error as reward signal.\nIn this paper: (a) We perform the first large-scale study of purely\ncuriosity-driven learning, i.e. without any extrinsic rewards, across 54\nstandard benchmark environments, including the Atari game suite. Our results\nshow surprisingly good performance, and a high degree of alignment between the\nintrinsic curiosity objective and the hand-designed extrinsic rewards of many\ngame environments. (b) We investigate the effect of using different feature\nspaces for computing prediction error and show that random features are\nsufficient for many popular RL game benchmarks, but learned features appear to\ngeneralize better (e.g. to novel game levels in Super Mario Bros.). (c) We\ndemonstrate limitations of the prediction-based rewards in stochastic setups.\nGame-play videos and code are at\nhttps://pathak22.github.io/large-scale-curiosity/\n", "versions": [{"version": "v1", "created": "Mon, 13 Aug 2018 17:58:01 GMT"}], "update_date": "2018-08-14", "authors_parsed": [["Burda", "Yuri", ""], ["Edwards", "Harri", ""], ["Pathak", "Deepak", ""], ["Storkey", "Amos", ""], ["Darrell", "Trevor", ""], ["Efros", "Alexei A.", ""]]}, {"id": "1808.04359", "submitter": "Akshat Agarwal", "authors": "Akshat Agarwal, Swaminathan Gurumurthy, Vasu Sharma, Mike Lewis, Katia\n  Sycara", "title": "Community Regularization of Visually-Grounded Dialog", "comments": "7 pages, ICML/AAMAS Adaptive Learning Agents Workshop 2018 and CVPR\n  Visual Dialog Workshop 2018. Code available at\n  https://github.com/agakshat/visualdialog-pytorch", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CL cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The task of conducting visually grounded dialog involves learning\ngoal-oriented cooperative dialog between autonomous agents who exchange\ninformation about a scene through several rounds of questions and answers in\nnatural language. We posit that requiring artificial agents to adhere to the\nrules of human language, while also requiring them to maximize information\nexchange through dialog is an ill-posed problem. We observe that humans do not\nstray from a common language because they are social creatures who live in\ncommunities, and have to communicate with many people everyday, so it is far\neasier to stick to a common language even at the cost of some efficiency loss.\nUsing this as inspiration, we propose and evaluate a multi-agent\ncommunity-based dialog framework where each agent interacts with, and learns\nfrom, multiple agents, and show that this community-enforced regularization\nresults in more relevant and coherent dialog (as judged by human evaluators)\nwithout sacrificing task performance (as judged by quantitative metrics).\n", "versions": [{"version": "v1", "created": "Fri, 10 Aug 2018 22:09:43 GMT"}, {"version": "v2", "created": "Thu, 6 Sep 2018 20:01:29 GMT"}], "update_date": "2018-09-10", "authors_parsed": [["Agarwal", "Akshat", ""], ["Gurumurthy", "Swaminathan", ""], ["Sharma", "Vasu", ""], ["Lewis", "Mike", ""], ["Sycara", "Katia", ""]]}, {"id": "1808.04364", "submitter": "Qiongkai Xu", "authors": "Qiongkai Xu, Juyan Zhang, Lizhen Qu, Lexing Xie, Richard Nock", "title": "D-PAGE: Diverse Paraphrase Generation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we investigate the diversity aspect of paraphrase generation.\nPrior deep learning models employ either decoding methods or add random input\nnoise for varying outputs. We propose a simple method Diverse Paraphrase\nGeneration (D-PAGE), which extends neural machine translation (NMT) models to\nsupport the generation of diverse paraphrases with implicit rewriting patterns.\nOur experimental results on two real-world benchmark datasets demonstrate that\nour model generates at least one order of magnitude more diverse outputs than\nthe baselines in terms of a new evaluation metric Jeffrey's Divergence. We have\nalso conducted extensive experiments to understand various properties of our\nmodel with a focus on diversity.\n", "versions": [{"version": "v1", "created": "Mon, 13 Aug 2018 10:18:54 GMT"}], "update_date": "2018-08-15", "authors_parsed": [["Xu", "Qiongkai", ""], ["Zhang", "Juyan", ""], ["Qu", "Lizhen", ""], ["Xie", "Lexing", ""], ["Nock", "Richard", ""]]}, {"id": "1808.04365", "submitter": "Ivan P Yamshchikov", "authors": "Alexey Tikhonov, Ivan P. Yamshchikov", "title": "What is wrong with style transfer for texts?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A number of recent machine learning papers work with an automated style\ntransfer for texts and, counter to intuition, demonstrate that there is no\nconsensus formulation of this NLP task. Different researchers propose different\nalgorithms, datasets and target metrics to address it. This short opinion paper\naims to discuss possible formalization of this NLP task in anticipation of a\nfurther growing interest to it.\n", "versions": [{"version": "v1", "created": "Mon, 13 Aug 2018 11:50:03 GMT"}], "update_date": "2018-08-15", "authors_parsed": [["Tikhonov", "Alexey", ""], ["Yamshchikov", "Ivan P.", ""]]}, {"id": "1808.04440", "submitter": "Evangello Flouty", "authors": "Evangello Flouty, Odysseas Zisimopoulos, and Danail Stoyanov", "title": "FaceOff: Anonymizing Videos in the Operating Rooms", "comments": "MICCAI 2018: OR 2.0 Context-Aware Operating Theaters", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Video capture in the surgical operating room (OR) is increasingly possible\nand has potential for use with computer assisted interventions (CAI), surgical\ndata science and within smart OR integration. Captured video innately carries\nsensitive information that should not be completely visible in order to\npreserve the patient's and the clinical teams' identities. When surgical video\nstreams are stored on a server, the videos must be anonymized prior to storage\nif taken outside of the hospital. In this article, we describe how a deep\nlearning model, Faster R-CNN, can be used for this purpose and help to\nanonymize video data captured in the OR. The model detects and blurs faces in\nan effort to preserve anonymity. After testing an existing face detection\ntrained model, a new dataset tailored to the surgical environment, with faces\nobstructed by surgical masks and caps, was collected for fine-tuning to achieve\nhigher face-detection rates in the OR. We also propose a temporal\nregularisation kernel to improve recall rates. The fine-tuned model achieves a\nface detection recall of 88.05 % and 93.45 % before and after applying\ntemporal-smoothing respectively.\n", "versions": [{"version": "v1", "created": "Mon, 6 Aug 2018 09:36:08 GMT"}], "update_date": "2018-08-15", "authors_parsed": [["Flouty", "Evangello", ""], ["Zisimopoulos", "Odysseas", ""], ["Stoyanov", "Danail", ""]]}, {"id": "1808.04444", "submitter": "Rami Al-Rfou", "authors": "Rami Al-Rfou, Dokook Choe, Noah Constant, Mandy Guo, Llion Jones", "title": "Character-Level Language Modeling with Deeper Self-Attention", "comments": "8 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  LSTMs and other RNN variants have shown strong performance on character-level\nlanguage modeling. These models are typically trained using truncated\nbackpropagation through time, and it is common to assume that their success\nstems from their ability to remember long-term contexts. In this paper, we show\nthat a deep (64-layer) transformer model with fixed context outperforms RNN\nvariants by a large margin, achieving state of the art on two popular\nbenchmarks: 1.13 bits per character on text8 and 1.06 on enwik8. To get good\nresults at this depth, we show that it is important to add auxiliary losses,\nboth at intermediate network layers and intermediate sequence positions.\n", "versions": [{"version": "v1", "created": "Thu, 9 Aug 2018 18:44:38 GMT"}, {"version": "v2", "created": "Mon, 10 Dec 2018 17:08:57 GMT"}], "update_date": "2018-12-11", "authors_parsed": [["Al-Rfou", "Rami", ""], ["Choe", "Dokook", ""], ["Constant", "Noah", ""], ["Guo", "Mandy", ""], ["Jones", "Llion", ""]]}, {"id": "1808.04449", "submitter": "Maarten Bieshaar", "authors": "Maarten Bieshaar, Malte Depping, Jan Schneegans, Bernhard Sick", "title": "Starting Movement Detection of Cyclists Using Smart Devices", "comments": "10 pages, accepted for publication at DSAA 2018, Turin, Italy", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In near future, vulnerable road users (VRUs) such as cyclists and pedestrians\nwill be equipped with smart devices and wearables which are capable to\ncommunicate with intelligent vehicles and other traffic participants. Road\nusers are then able to cooperate on different levels, such as in cooperative\nintention detection for advanced VRU protection. Smart devices can be used to\ndetect intentions, e.g., an occluded cyclist intending to cross the road, to\nwarn vehicles of VRUs, and prevent potential collisions. This article presents\na human activity recognition approach to detect the starting movement of\ncyclists wearing smart devices. We propose a novel two-stage feature selection\nprocedure using a score specialized for robust starting detection reducing the\nfalse positive detections and leading to understandable and interpretable\nfeatures. The detection is modelled as a classification problem and realized by\nmeans of a machine learning classifier. We introduce an auxiliary class, that\nmodels starting movements and allows to integrate early movement indicators,\ni.e., body part movements indicating future behaviour. In this way we improve\nthe robustness and reduce the detection time of the classifier. Our empirical\nstudies with real-world data originating from experiments which involve 49 test\nsubjects and consists of 84 starting motions show that we are able to detect\nthe starting movements early. Our approach reaches an F1-score of 67 % within\n0.33 s after the first movement of the bicycle wheel. Investigations concerning\nthe device wearing location show that for devices worn in the trouser pocket\nthe detector has less false detections and detects starting movements faster on\naverage. We found that we can further improve the results when we train\ndistinct classifiers for different wearing locations.\n", "versions": [{"version": "v1", "created": "Wed, 8 Aug 2018 09:20:13 GMT"}], "update_date": "2018-08-15", "authors_parsed": [["Bieshaar", "Maarten", ""], ["Depping", "Malte", ""], ["Schneegans", "Jan", ""], ["Sick", "Bernhard", ""]]}, {"id": "1808.04456", "submitter": "Garrett Goh", "authors": "Garrett B. Goh, Khushmeen Sakloth, Charles Siegel, Abhinav Vishnu, Jim\n  Pfaendtner", "title": "Multimodal Deep Neural Networks using Both Engineered and Learned\n  Representations for Biodegradability Prediction", "comments": "Submitted to a peer-reviewed ML conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning algorithms excel at extracting patterns from raw data, and with\nlarge datasets, they have been very successful in computer vision and natural\nlanguage applications. However, in other domains, large datasets on which to\nlearn representations from may not exist. In this work, we develop a novel\nmultimodal CNN-MLP neural network architecture that utilizes both\ndomain-specific feature engineering as well as learned representations from raw\ndata. We illustrate the effectiveness of such network designs in the chemical\nsciences, for predicting biodegradability. DeepBioD, a multimodal CNN-MLP\nnetwork is more accurate than either standalone network designs, and achieves\nan error classification rate of 0.125 that is 27% lower than the current\nstate-of-the-art. Thus, our work indicates that combining traditional feature\nengineering with representation learning can be effective, particularly in\nsituations where labeled data is limited.\n", "versions": [{"version": "v1", "created": "Mon, 13 Aug 2018 20:36:08 GMT"}, {"version": "v2", "created": "Thu, 13 Sep 2018 18:27:08 GMT"}], "update_date": "2018-09-17", "authors_parsed": [["Goh", "Garrett B.", ""], ["Sakloth", "Khushmeen", ""], ["Siegel", "Charles", ""], ["Vishnu", "Abhinav", ""], ["Pfaendtner", "Jim", ""]]}, {"id": "1808.04468", "submitter": "Yinlam Chow", "authors": "Jonathan Lacotte and Mohammad Ghavamzadeh and Yinlam Chow and Marco\n  Pavone", "title": "Risk-Sensitive Generative Adversarial Imitation Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study risk-sensitive imitation learning where the agent's goal is to\nperform at least as well as the expert in terms of a risk profile. We first\nformulate our risk-sensitive imitation learning setting. We consider the\ngenerative adversarial approach to imitation learning (GAIL) and derive an\noptimization problem for our formulation, which we call it risk-sensitive GAIL\n(RS-GAIL). We then derive two different versions of our RS-GAIL optimization\nproblem that aim at matching the risk profiles of the agent and the expert\nw.r.t. Jensen-Shannon (JS) divergence and Wasserstein distance, and develop\nrisk-sensitive generative adversarial imitation learning algorithms based on\nthese optimization problems. We evaluate the performance of our algorithms and\ncompare them with GAIL and the risk-averse imitation learning (RAIL) algorithms\nin two MuJoCo and two OpenAI classical control tasks.\n", "versions": [{"version": "v1", "created": "Mon, 13 Aug 2018 21:08:46 GMT"}, {"version": "v2", "created": "Mon, 24 Dec 2018 02:41:29 GMT"}], "update_date": "2018-12-27", "authors_parsed": [["Lacotte", "Jonathan", ""], ["Ghavamzadeh", "Mohammad", ""], ["Chow", "Yinlam", ""], ["Pavone", "Marco", ""]]}, {"id": "1808.04527", "submitter": "Joohyung Lee", "authors": "Joohyung Lee, Yi Wang", "title": "Weight Learning in a Probabilistic Extension of Answer Set Programs", "comments": "Technical Report of the paper to appear in 16th International\n  Conference on Principles of Knowledge Representation and Reasoning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  LPMLN is a probabilistic extension of answer set programs with the weight\nscheme derived from that of Markov Logic. Previous work has shown how inference\nin LPMLN can be achieved. In this paper, we present the concept of weight\nlearning in LPMLN and learning algorithms for LPMLN derived from those for\nMarkov Logic. We also present a prototype implementation that uses answer set\nsolvers for learning as well as some example domains that illustrate distinct\nfeatures of LPMLN learning. Learning in LPMLN is in accordance with the stable\nmodel semantics, thereby it learns parameters for probabilistic extensions of\nknowledge-rich domains where answer set programming has shown to be useful but\nlimited to the deterministic case, such as reachability analysis and reasoning\nabout actions in dynamic domains. We also apply the method to learn the\nparameters for probabilistic abductive reasoning about actions.\n", "versions": [{"version": "v1", "created": "Tue, 14 Aug 2018 05:16:41 GMT"}, {"version": "v2", "created": "Tue, 9 Oct 2018 03:34:18 GMT"}], "update_date": "2018-10-10", "authors_parsed": [["Lee", "Joohyung", ""], ["Wang", "Yi", ""]]}, {"id": "1808.04545", "submitter": "Xinchen Yan", "authors": "Xinchen Yan, Akash Rastogi, Ruben Villegas, Kalyan Sunkavalli, Eli\n  Shechtman, Sunil Hadap, Ersin Yumer, Honglak Lee", "title": "MT-VAE: Learning Motion Transformations to Generate Multimodal Human\n  Dynamics", "comments": "Published at ECCV 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.GR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Long-term human motion can be represented as a series of motion\nmodes---motion sequences that capture short-term temporal dynamics---with\ntransitions between them. We leverage this structure and present a novel Motion\nTransformation Variational Auto-Encoders (MT-VAE) for learning motion sequence\ngeneration. Our model jointly learns a feature embedding for motion modes (that\nthe motion sequence can be reconstructed from) and a feature transformation\nthat represents the transition of one motion mode to the next motion mode. Our\nmodel is able to generate multiple diverse and plausible motion sequences in\nthe future from the same input. We apply our approach to both facial and full\nbody motion, and demonstrate applications like analogy-based motion transfer\nand video synthesis.\n", "versions": [{"version": "v1", "created": "Tue, 14 Aug 2018 06:21:03 GMT"}], "update_date": "2018-08-15", "authors_parsed": [["Yan", "Xinchen", ""], ["Rastogi", "Akash", ""], ["Villegas", "Ruben", ""], ["Sunkavalli", "Kalyan", ""], ["Shechtman", "Eli", ""], ["Hadap", "Sunil", ""], ["Yumer", "Ersin", ""], ["Lee", "Honglak", ""]]}, {"id": "1808.04600", "submitter": "Sagar Uprety Mr.", "authors": "Sagar Uprety, Dawei Song", "title": "Reconciling Irrational Human Behavior with AI based Decision Making: A\n  Quantum Probabilistic Approach", "comments": "Published at the Workshop on AI and Computational Psychology at\n  IJCAI-ECAI 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There are many examples of human decision making which cannot be modeled by\nclassical probabilistic and logic models, on which the current AI systems are\nbased. Hence the need for a modeling framework which can enable intelligent\nsystems to detect and predict cognitive biases in human decisions to facilitate\nbetter human-agent interaction. We give a few examples of irrational behavior\nand use a generalized probabilistic model inspired by the mathematical\nframework of Quantum Theory to model and explain such behavior.\n", "versions": [{"version": "v1", "created": "Tue, 14 Aug 2018 09:47:16 GMT"}], "update_date": "2018-08-15", "authors_parsed": [["Uprety", "Sagar", ""], ["Song", "Dawei", ""]]}, {"id": "1808.04614", "submitter": "Tomer Wolfson", "authors": "Jonathan Berant, Daniel Deutch, Amir Globerson, Tova Milo, Tomer\n  Wolfson", "title": "Explaining Queries over Web Tables to Non-Experts", "comments": "Short paper version to appear in ICDE 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Designing a reliable natural language (NL) interface for querying tables has\nbeen a longtime goal of researchers in both the data management and natural\nlanguage processing (NLP) communities. Such an interface receives as input an\nNL question, translates it into a formal query, executes the query and returns\nthe results. Errors in the translation process are not uncommon, and users\ntypically struggle to understand whether their query has been mapped correctly.\nWe address this problem by explaining the obtained formal queries to non-expert\nusers. Two methods for query explanations are presented: the first translates\nqueries into NL, while the second method provides a graphic representation of\nthe query cell-based provenance (in its execution on a given table). Our\nsolution augments a state-of-the-art NL interface over web tables, enhancing it\nin both its training and deployment phase. Experiments, including a user study\nconducted on Amazon Mechanical Turk, show our solution to improve both the\ncorrectness and reliability of an NL interface.\n", "versions": [{"version": "v1", "created": "Tue, 14 Aug 2018 10:23:32 GMT"}], "update_date": "2018-08-15", "authors_parsed": [["Berant", "Jonathan", ""], ["Deutch", "Daniel", ""], ["Globerson", "Amir", ""], ["Milo", "Tova", ""], ["Wolfson", "Tomer", ""]]}, {"id": "1808.04617", "submitter": "Suttinee Sawadsitang", "authors": "Suttinee Sawadsitang, Dusit Niyato, Puay-Siew Tan, and Ping Wang", "title": "Joint Ground and Aerial Package Delivery Services: A Stochastic\n  Optimization Approach", "comments": "14 pages, 15 figures, Accepted as REGULAR PAPER", "journal-ref": "Transactions on Intelligent Transportation Systems 2018", "doi": null, "report-no": null, "categories": "cs.AI math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unmanned aerial vehicles (UAVs), also known as drones, have emerged as a\npromising mode of fast, energy-efficient, and cost-effective package delivery.\nA considerable number of works have studied different aspects of drone package\ndelivery service by a supplier, one of which is delivery planning. However,\nexisting works addressing the planning issues consider a simple case of perfect\ndelivery without service interruption, e.g., due to accident which is common\nand realistic. Therefore, this paper introduces the joint ground and aerial\ndelivery service optimization and planning (GADOP) framework. The framework\nexplicitly incorporates uncertainty of drone package delivery, i.e., takeoff\nand breakdown conditions. The GADOP framework aims to minimize the total\ndelivery cost given practical constraints, e.g., traveling distance limit.\nSpecifically, we formulate the GADOP framework as a three-stage stochastic\ninteger programming model. To deal with the high complexity issue of the\nproblem, a decomposition method is adopted. Then, the performance of the GADOP\nframework is evaluated by using two data sets including Solomon benchmark suite\nand the real data from one of the Singapore logistics companies. The\nperformance evaluation clearly shows that the GADOP framework can achieve\nsignificantly lower total payment than that of the baseline methods which do\nnot take uncertainty into account.\n", "versions": [{"version": "v1", "created": "Tue, 14 Aug 2018 10:32:30 GMT"}, {"version": "v2", "created": "Wed, 15 Aug 2018 03:08:25 GMT"}], "update_date": "2018-08-16", "authors_parsed": [["Sawadsitang", "Suttinee", ""], ["Niyato", "Dusit", ""], ["Tan", "Puay-Siew", ""], ["Wang", "Ping", ""]]}, {"id": "1808.04620", "submitter": "Javier \\'Alvez", "authors": "Javier \\'Alvez and Itziar Gonzalez-Dios and German Rigau", "title": "Applying the Closed World Assumption to SUMO-based FOL Ontologies for\n  Effective Commonsense Reasoning", "comments": "7 pages, 2 figure, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most commonly, the Open World Assumption is adopted as a standard strategy\nfor the design, construction and use of ontologies. This strategy limits the\ninferencing capabilities of any system because non-asserted statements (missing\nknowledge) could be assumed to be alternatively true or false. As we will\ndemonstrate, this is especially the case of first-order logic (FOL) ontologies\nwhere non-asserted statements is nowadays one of the main obstacles to its\npractical application in automated commonsense reasoning tasks. In this paper,\nwe investigate the application of the Closed World Assumption (CWA) to enable a\nbetter exploitation of FOL ontologies by using state-of-the-art automated\ntheorem provers. To that end, we explore different CWA formulations for the\nstructural knowledge encoded in a FOL translation of the SUMO ontology,\ndiscovering that almost 30 % of the structural knowledge is missing. We\nevaluate these formulations on a practical experimentation using a very large\ncommonsense benchmark obtained from WordNet through its mapping to SUMO. The\nresults show that the competency of the ontology improves more than 50 % when\nreasoning under the CWA. Thus, applying the CWA automatically to FOL ontologies\nreduces their ambiguity and more commonsense questions can be answered\n", "versions": [{"version": "v1", "created": "Tue, 14 Aug 2018 10:41:14 GMT"}, {"version": "v2", "created": "Wed, 4 Mar 2020 09:02:27 GMT"}], "update_date": "2020-03-05", "authors_parsed": [["\u00c1lvez", "Javier", ""], ["Gonzalez-Dios", "Itziar", ""], ["Rigau", "German", ""]]}, {"id": "1808.04673", "submitter": "Sudip Mittal", "authors": "Lorenzo Neil, Sudip Mittal, Anupam Joshi", "title": "Mining Threat Intelligence about Open-Source Projects and Libraries from\n  Code Repository Issues and Bug Reports", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.AI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Open-Source Projects and Libraries are being used in software development\nwhile also bearing multiple security vulnerabilities. This use of third party\necosystem creates a new kind of attack surface for a product in development. An\nintelligent attacker can attack a product by exploiting one of the\nvulnerabilities present in linked projects and libraries.\n  In this paper, we mine threat intelligence about open source projects and\nlibraries from bugs and issues reported on public code repositories. We also\ntrack library and project dependencies for installed software on a client\nmachine. We represent and store this threat intelligence, along with the\nsoftware dependencies in a security knowledge graph. Security analysts and\ndevelopers can then query and receive alerts from the knowledge graph if any\nthreat intelligence is found about linked libraries and projects, utilized in\ntheir products.\n", "versions": [{"version": "v1", "created": "Thu, 9 Aug 2018 23:28:09 GMT"}], "update_date": "2018-08-15", "authors_parsed": [["Neil", "Lorenzo", ""], ["Mittal", "Sudip", ""], ["Joshi", "Anupam", ""]]}, {"id": "1808.04679", "submitter": "Li-Fang Cheng", "authors": "Li-Fang Cheng, Niranjani Prasad, Barbara E Engelhardt", "title": "An Optimal Policy for Patient Laboratory Tests in Intensive Care Units", "comments": "The first two authors contributed equally to this work. Preprint of\n  an article submitted for consideration in Pacific Symposium on Biocomputing\n  copyright 2018 [copyright World Scientific Publishing Company]\n  [https://psb.stanford.edu/]", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Laboratory testing is an integral tool in the management of patient care in\nhospitals, particularly in intensive care units (ICUs). There exists an\ninherent trade-off in the selection and timing of lab tests between\nconsiderations of the expected utility in clinical decision-making of a given\ntest at a specific time, and the associated cost or risk it poses to the\npatient. In this work, we introduce a framework that learns policies for\nordering lab tests which optimizes for this trade-off. Our approach uses batch\noff-policy reinforcement learning with a composite reward function based on\nclinical imperatives, applied to data that include examples of clinicians\nordering labs for patients. To this end, we develop and extend principles of\nPareto optimality to improve the selection of actions based on multiple reward\nfunction components while respecting typical procedural considerations and\nprioritization of clinical goals in the ICU. Our experiments show that we can\nestimate a policy that reduces the frequency of lab tests and optimizes timing\nto minimize information redundancy. We also find that the estimated policies\ntypically suggest ordering lab tests well ahead of critical onsets--such as\nmechanical ventilation or dialysis--that depend on the lab results. We evaluate\nour approach by quantifying how these policies may initiate earlier onset of\ntreatment.\n", "versions": [{"version": "v1", "created": "Tue, 14 Aug 2018 13:34:06 GMT"}], "update_date": "2019-11-01", "authors_parsed": [["Cheng", "Li-Fang", ""], ["Prasad", "Niranjani", ""], ["Engelhardt", "Barbara E", ""]]}, {"id": "1808.04738", "submitter": "Gulay Unel", "authors": "Gulay Unel", "title": "Stream Reasoning on Expressive Logics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data streams occur widely in various real world applications. The research on\nstreaming data mainly focuses on the data management, query evaluation and\noptimization on these data, however the work on reasoning procedures for\nstreaming knowledge bases on both the assertional and terminological levels is\nvery limited. Typically reasoning services on large knowledge bases are very\nexpensive, and need to be applied continuously when the data is received as a\nstream. Hence new techniques for optimizing this continuous process is needed\nfor developing efficient reasoners on streaming data. In this paper, we survey\nthe related research on reasoning on expressive logics that can be applied to\nthis setting, and point to further research directions in this area.\n", "versions": [{"version": "v1", "created": "Tue, 14 Aug 2018 15:18:02 GMT"}, {"version": "v2", "created": "Wed, 15 Aug 2018 13:35:20 GMT"}], "update_date": "2018-08-19", "authors_parsed": [["Unel", "Gulay", ""]]}, {"id": "1808.04750", "submitter": "Jens Schreiber", "authors": "Jens Schreiber and Bernhard Sick", "title": "Quantifying the Influences on Probabilistic Wind Power Forecasts", "comments": "5 pages; 1 table; 3 figures; This work has been submitted to the IEEE\n  for possible publication. Copyright may be transferred without notice, after\n  which this version may no longer be accessible", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, probabilistic forecasts techniques were proposed in research\nas well as in applications to integrate volatile renewable energy resources\ninto the electrical grid. These techniques allow decision makers to take the\nuncertainty of the prediction into account and, therefore, to devise optimal\ndecisions, e.g., related to costs and risks in the electrical grid. However, it\nwas yet not studied how the input, such as numerical weather predictions,\naffects the model output of forecasting models in detail. Therefore, we examine\nthe potential influences with techniques from the field of sensitivity analysis\non three different black-box models to obtain insights into differences and\nsimilarities of these probabilistic models. The analysis shows a considerable\nnumber of potential influences in those models depending on, e.g., the\npredicted probability and the type of model. These effects motivate the need to\ntake various influences into account when models are tested, analyzed, or\ncompared. Nevertheless, results of the sensitivity analysis will allow us to\nselect a model with advantages in the practical application.\n", "versions": [{"version": "v1", "created": "Tue, 14 Aug 2018 15:27:22 GMT"}], "update_date": "2018-08-15", "authors_parsed": [["Schreiber", "Jens", ""], ["Sick", "Bernhard", ""]]}, {"id": "1808.04758", "submitter": "James Cussens", "authors": "James Cussens", "title": "Finding Minimal Cost Herbrand Models with Branch-Cut-and-Price", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given (1) a set of clauses $T$ in some first-order language $\\cal L$ and (2)\na cost function $c : B_{{\\cal L}} \\rightarrow \\mathbb{R}_{+}$, mapping each\nground atom in the Herbrand base $B_{{\\cal L}}$ to a non-negative real, then\nthe problem of finding a minimal cost Herbrand model is to either find a\nHerbrand model $\\cal I$ of $T$ which is guaranteed to minimise the sum of the\ncosts of true ground atoms, or establish that there is no Herbrand model for\n$T$. A branch-cut-and-price integer programming (IP) approach to solving this\nproblem is presented. Since the number of ground instantiations of clauses and\nthe size of the Herbrand base are both infinite in general, we add the\ncorresponding IP constraints and IP variables `on the fly' via `cutting' and\n`pricing' respectively. In the special case of a finite Herbrand base we show\nthat adding all IP variables and constraints from the outset can be\nadvantageous, showing that a challenging Markov logic network MAP problem can\nbe solved in this way if encoded appropriately.\n", "versions": [{"version": "v1", "created": "Tue, 14 Aug 2018 15:45:01 GMT"}], "update_date": "2018-08-15", "authors_parsed": [["Cussens", "James", ""]]}, {"id": "1808.04794", "submitter": "Maciej Swiechowski", "authors": "Maciej \\'Swiechowski, Tomasz Tajmajer and Andrzej Janusz", "title": "Improving Hearthstone AI by Combining MCTS and Supervised Learning\n  Algorithms", "comments": "Proceedings of the 2018 IEEE Conference on Computational Intelligence\n  and Games (CIG'18); pages 445-452; ISBN: 978-1-5386-4358-7", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the impact of supervised prediction models on the strength and\nefficiency of artificial agents that use the Monte-Carlo Tree Search (MCTS)\nalgorithm to play a popular video game Hearthstone: Heroes of Warcraft. We\noverview our custom implementation of the MCTS that is well-suited for games\nwith partially hidden information and random effects. We also describe\nexperiments which we designed to quantify the performance of our Hearthstone\nagent's decision making. We show that even simple neural networks can be\ntrained and successfully used for the evaluation of game states. Moreover, we\ndemonstrate that by providing a guidance to the game state search heuristic, it\nis possible to substantially improve the win rate, and at the same time reduce\nthe required computations.\n", "versions": [{"version": "v1", "created": "Tue, 14 Aug 2018 16:58:11 GMT"}], "update_date": "2018-08-15", "authors_parsed": [["\u015awiechowski", "Maciej", ""], ["Tajmajer", "Tomasz", ""], ["Janusz", "Andrzej", ""]]}, {"id": "1808.04803", "submitter": "Adrian Bulat", "authors": "Adrian Bulat and Georgios Tzimiropoulos", "title": "Hierarchical binary CNNs for landmark localization with limited\n  resources", "comments": "Accepted to IEEE TPAMI18: Best of ICCV 2017 SI. Previously portions\n  of this work appeared as arXiv:1703.00862, which was the conference version", "journal-ref": null, "doi": "10.1109/TPAMI.2018.2866051", "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Our goal is to design architectures that retain the groundbreaking\nperformance of Convolutional Neural Networks (CNNs) for landmark localization\nand at the same time are lightweight, compact and suitable for applications\nwith limited computational resources. To this end, we make the following\ncontributions: (a) we are the first to study the effect of neural network\nbinarization on localization tasks, namely human pose estimation and face\nalignment. We exhaustively evaluate various design choices, identify\nperformance bottlenecks, and more importantly propose multiple orthogonal ways\nto boost performance. (b) Based on our analysis, we propose a novel\nhierarchical, parallel and multi-scale residual architecture that yields large\nperformance improvement over the standard bottleneck block while having the\nsame number of parameters, thus bridging the gap between the original network\nand its binarized counterpart. (c) We perform a large number of ablation\nstudies that shed light on the properties and the performance of the proposed\nblock. (d) We present results for experiments on the most challenging datasets\nfor human pose estimation and face alignment, reporting in many cases\nstate-of-the-art performance. (e) We further provide additional results for the\nproblem of facial part segmentation. Code can be downloaded from\nhttps://www.adrianbulat.com/binary-cnn-landmark\n", "versions": [{"version": "v1", "created": "Tue, 14 Aug 2018 17:32:29 GMT"}], "update_date": "2018-08-28", "authors_parsed": [["Bulat", "Adrian", ""], ["Tzimiropoulos", "Georgios", ""]]}, {"id": "1808.04819", "submitter": "Kevin Hu", "authors": "Kevin Z. Hu, Michiel A. Bakker, Stephen Li, Tim Kraska, C\\'esar A.\n  Hidalgo", "title": "VizML: A Machine Learning Approach to Visualization Recommendation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data visualization should be accessible for all analysts with data, not just\nthe few with technical expertise. Visualization recommender systems aim to\nlower the barrier to exploring basic visualizations by automatically generating\nresults for analysts to search and select, rather than manually specify. Here,\nwe demonstrate a novel machine learning-based approach to visualization\nrecommendation that learns visualization design choices from a large corpus of\ndatasets and associated visualizations. First, we identify five key design\nchoices made by analysts while creating visualizations, such as selecting a\nvisualization type and choosing to encode a column along the X- or Y-axis. We\ntrain models to predict these design choices using one million\ndataset-visualization pairs collected from a popular online visualization\nplatform. Neural networks predict these design choices with high accuracy\ncompared to baseline models. We report and interpret feature importances from\none of these baseline models. To evaluate the generalizability and uncertainty\nof our approach, we benchmark with a crowdsourced test set, and show that the\nperformance of our model is comparable to human performance when predicting\nconsensus visualization type, and exceeds that of other ML-based systems.\n", "versions": [{"version": "v1", "created": "Tue, 14 Aug 2018 18:00:01 GMT"}], "update_date": "2018-08-16", "authors_parsed": [["Hu", "Kevin Z.", ""], ["Bakker", "Michiel A.", ""], ["Li", "Stephen", ""], ["Kraska", "Tim", ""], ["Hidalgo", "C\u00e9sar A.", ""]]}, {"id": "1808.04926", "submitter": "Divyansh Kaushik", "authors": "Divyansh Kaushik, Zachary C. Lipton", "title": "How Much Reading Does Reading Comprehension Require? A Critical\n  Investigation of Popular Benchmarks", "comments": "To appear in EMNLP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many recent papers address reading comprehension, where examples consist of\n(question, passage, answer) tuples. Presumably, a model must combine\ninformation from both questions and passages to predict corresponding answers.\nHowever, despite intense interest in the topic, with hundreds of published\npapers vying for leaderboard dominance, basic questions about the difficulty of\nmany popular benchmarks remain unanswered. In this paper, we establish sensible\nbaselines for the bAbI, SQuAD, CBT, CNN, and Who-did-What datasets, finding\nthat question- and passage-only models often perform surprisingly well. On $14$\nout of $20$ bAbI tasks, passage-only models achieve greater than $50\\%$\naccuracy, sometimes matching the full model. Interestingly, while CBT provides\n$20$-sentence stories only the last is needed for comparably accurate\nprediction. By comparison, SQuAD and CNN appear better-constructed.\n", "versions": [{"version": "v1", "created": "Tue, 14 Aug 2018 23:59:26 GMT"}, {"version": "v2", "created": "Tue, 21 Aug 2018 16:48:54 GMT"}], "update_date": "2018-08-22", "authors_parsed": [["Kaushik", "Divyansh", ""], ["Lipton", "Zachary C.", ""]]}, {"id": "1808.04946", "submitter": "Minzhong Luo", "authors": "MinZhong Luo, Li Liu", "title": "Automatic Derivation Of Formulas Using Reforcement Learning", "comments": "conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  This paper presents an artificial intelligence algorithm that can be used to\nderive formulas from various scientific disciplines called automatic derivation\nmachine. First, the formula is abstractly expressed as a multiway tree model,\nand then each step of the formula derivation transformation is abstracted as a\nmapping of multiway trees. Derivation steps similar can be expressed as a\nreusable formula template by a multiway tree map. After that, the formula\nmultiway tree is eigen-encoded to feature vectors construct the feature space\nof formulas, the Q-learning model using in this feature space can achieve the\nderivation by making training data from derivation process. Finally, an\nautomatic formula derivation machine is made to choose the next derivation step\nbased on the current state and object. We also make an example about the\nnuclear reactor physics problem to show how the automatic derivation machine\nworks.\n", "versions": [{"version": "v1", "created": "Wed, 15 Aug 2018 02:08:23 GMT"}], "update_date": "2018-08-16", "authors_parsed": [["Luo", "MinZhong", ""], ["Liu", "Li", ""]]}, {"id": "1808.05006", "submitter": "Eita Nakamura", "authors": "Eita Nakamura, Kazuyoshi Yoshii", "title": "Statistical Piano Reduction Controlling Performance Difficulty", "comments": "12 pages, 7 figures, version accepted to APSIPA Transactions on\n  Signal and Information Processing", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a statistical-modelling method for piano reduction, i.e.\nconverting an ensemble score into piano scores, that can control performance\ndifficulty. While previous studies have focused on describing the condition for\nplayable piano scores, it depends on player's skill and can change continuously\nwith the tempo. We thus computationally quantify performance difficulty as well\nas musical fidelity to the original score, and formulate the problem as\noptimization of musical fidelity under constraints on difficulty values. First,\nperformance difficulty measures are developed by means of probabilistic\ngenerative models for piano scores and the relation to the rate of performance\nerrors is studied. Second, to describe musical fidelity, we construct a\nprobabilistic model integrating a prior piano-score model and a model\nrepresenting how ensemble scores are likely to be edited. An iterative\noptimization algorithm for piano reduction is developed based on statistical\ninference of the model. We confirm the effect of the iterative procedure; we\nfind that subjective difficulty and musical fidelity monotonically increase\nwith controlled difficulty values; and we show that incorporating sequential\ndependence of pitches and fingering motion in the piano-score model improves\nthe quality of reduction scores in high-difficulty cases.\n", "versions": [{"version": "v1", "created": "Wed, 15 Aug 2018 09:08:39 GMT"}, {"version": "v2", "created": "Thu, 25 Oct 2018 09:19:11 GMT"}], "update_date": "2018-10-26", "authors_parsed": [["Nakamura", "Eita", ""], ["Yoshii", "Kazuyoshi", ""]]}, {"id": "1808.05032", "submitter": "Per-Arne Andersen", "authors": "Per-Arne Andersen, Morten Goodwin, Ole-Christoffer Granmo", "title": "Deep RTS: A Game Environment for Deep Reinforcement Learning in\n  Real-Time Strategy Games", "comments": "Proceedings of the IEEE International Conference on Computational\n  Intelligence and Games (CIG 2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Reinforcement learning (RL) is an area of research that has blossomed\ntremendously in recent years and has shown remarkable potential for artificial\nintelligence based opponents in computer games. This success is primarily due\nto the vast capabilities of convolutional neural networks, that can extract\nuseful features from noisy and complex data. Games are excellent tools to test\nand push the boundaries of novel RL algorithms because they give valuable\ninsight into how well an algorithm can perform in isolated environments without\nthe real-life consequences. Real-time strategy games (RTS) is a genre that has\ntremendous complexity and challenges the player in short and long-term\nplanning. There is much research that focuses on applied RL in RTS games, and\nnovel advances are therefore anticipated in the not too distant future.\nHowever, there are to date few environments for testing RTS AIs. Environments\nin the literature are often either overly simplistic, such as microRTS, or\ncomplex and without the possibility for accelerated learning on consumer\nhardware like StarCraft II. This paper introduces the Deep RTS game environment\nfor testing cutting-edge artificial intelligence algorithms for RTS games. Deep\nRTS is a high-performance RTS game made specifically for artificial\nintelligence research. It supports accelerated learning, meaning that it can\nlearn at a magnitude of 50 000 times faster compared to existing RTS games.\nDeep RTS has a flexible configuration, enabling research in several different\nRTS scenarios, including partially observable state-spaces and map complexity.\nWe show that Deep RTS lives up to our promises by comparing its performance\nwith microRTS, ELF, and StarCraft II on high-end consumer hardware. Using Deep\nRTS, we show that a Deep Q-Network agent beats random-play agents over 70% of\nthe time. Deep RTS is publicly available at https://github.com/cair/DeepRTS.\n", "versions": [{"version": "v1", "created": "Wed, 15 Aug 2018 10:30:41 GMT"}], "update_date": "2018-08-16", "authors_parsed": [["Andersen", "Per-Arne", ""], ["Goodwin", "Morten", ""], ["Granmo", "Ole-Christoffer", ""]]}, {"id": "1808.05249", "submitter": "Ramon Fraga Pereira", "authors": "Leonardo Amado, Jo\\~ao Paulo Aires, Ramon Fraga Pereira, Maur\\'icio C.\n  Magnaguagno, Roger Granada, Felipe Meneguzzi", "title": "LSTM-Based Goal Recognition in Latent Space", "comments": "Added/Fixed some references", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Approaches to goal recognition have progressively relaxed the requirements\nabout the amount of domain knowledge and available observations, yielding\naccurate and efficient algorithms capable of recognizing goals. However, to\nrecognize goals in raw data, recent approaches require either human engineered\ndomain knowledge, or samples of behavior that account for almost all actions\nbeing observed to infer possible goals. This is clearly too strong a\nrequirement for real-world applications of goal recognition, and we develop an\napproach that leverages advances in recurrent neural networks to perform goal\nrecognition as a classification task, using encoded plan traces for training.\nWe empirically evaluate our approach against the state-of-the-art in goal\nrecognition with image-based domains, and discuss under which conditions our\napproach is superior to previous ones.\n", "versions": [{"version": "v1", "created": "Wed, 15 Aug 2018 18:52:19 GMT"}, {"version": "v2", "created": "Mon, 20 Aug 2018 19:50:55 GMT"}], "update_date": "2018-08-22", "authors_parsed": [["Amado", "Leonardo", ""], ["Aires", "Jo\u00e3o Paulo", ""], ["Pereira", "Ramon Fraga", ""], ["Magnaguagno", "Maur\u00edcio C.", ""], ["Granada", "Roger", ""], ["Meneguzzi", "Felipe", ""]]}, {"id": "1808.05264", "submitter": "Renato Luiz de Freitas Cunha", "authors": "Eduardo R. Rodrigues, Igor Oliveira, Renato L. F. Cunha, Marco A. S.\n  Netto", "title": "DeepDownscale: a Deep Learning Strategy for High-Resolution Weather\n  Forecast", "comments": "8 pages, 6 figures, accepted for publication at 14th IEEE eScience", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Running high-resolution physical models is computationally expensive and\nessential for many disciplines. Agriculture, transportation, and energy are\nsectors that depend on high-resolution weather models, which typically consume\nmany hours of large High Performance Computing (HPC) systems to deliver timely\nresults. Many users cannot afford to run the desired resolution and are forced\nto use low resolution output. One simple solution is to interpolate results for\nvisualization. It is also possible to combine an ensemble of low resolution\nmodels to obtain a better prediction. However, these approaches fail to capture\nthe redundant information and patterns in the low-resolution input that could\nhelp improve the quality of prediction. In this paper, we propose and evaluate\na strategy based on a deep neural network to learn a high-resolution\nrepresentation from low-resolution predictions using weather forecast as a\npractical use case. We take a supervised learning approach, since obtaining\nlabeled data can be done automatically. Our results show significant\nimprovement when compared with standard practices and the strategy is still\nlightweight enough to run on modest computer systems.\n", "versions": [{"version": "v1", "created": "Wed, 15 Aug 2018 19:22:15 GMT"}], "update_date": "2018-08-17", "authors_parsed": [["Rodrigues", "Eduardo R.", ""], ["Oliveira", "Igor", ""], ["Cunha", "Renato L. F.", ""], ["Netto", "Marco A. S.", ""]]}, {"id": "1808.05322", "submitter": "Thierry Denoeux", "authors": "Thierry Denoeux", "title": "Decision-Making with Belief Functions: a Review", "comments": null, "journal-ref": "International Journal of Approximate Reasoning, vol. 109, Pages\n  87-110, 2019", "doi": "10.1016/j.ijar.2019.03.009", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Approaches to decision-making under uncertainty in the belief function\nframework are reviewed. Most methods are shown to blend criteria for decision\nunder ignorance with the maximum expected utility principle of Bayesian\ndecision theory. A distinction is made between methods that construct a\ncomplete preference relation among acts, and those that allow incomparability\nof some acts due to lack of information. Methods developed in the imprecise\nprobability framework are applicable in the Dempster-Shafer context and are\nalso reviewed. Shafer's constructive decision theory, which substitutes the\nnotion of goal for that of utility, is described and contrasted with other\napproaches. The paper ends by pointing out the need to carry out deeper\ninvestigation of fundamental issues related to decision-making with belief\nfunctions and to assess the descriptive, normative and prescriptive values of\nthe different approaches.\n", "versions": [{"version": "v1", "created": "Thu, 16 Aug 2018 01:52:46 GMT"}, {"version": "v2", "created": "Thu, 12 Dec 2019 08:02:05 GMT"}], "update_date": "2019-12-13", "authors_parsed": [["Denoeux", "Thierry", ""]]}, {"id": "1808.05336", "submitter": "Sunil Prakash", "authors": "Sunil Prakash and Gaelan Gu", "title": "Simultaneous Localization And Mapping with depth Prediction using\n  Capsule Networks for UAVs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose an novel implementation of a simultaneous\nlocalization and mapping (SLAM) system based on a monocular camera from an\nunmanned aerial vehicle (UAV) using Depth prediction performed with Capsule\nNetworks (CapsNet), which possess improvements over the drawbacks of the more\nwidely-used Convolutional Neural Networks (CNN). An Extended Kalman Filter will\nassist in estimating the position of the UAV so that we are able to update the\nbelief for the environment. Results will be evaluated on a benchmark dataset to\nportray the accuracy of our intended approach.\n", "versions": [{"version": "v1", "created": "Thu, 16 Aug 2018 03:39:25 GMT"}], "update_date": "2018-08-17", "authors_parsed": [["Prakash", "Sunil", ""], ["Gu", "Gaelan", ""]]}, {"id": "1808.05344", "submitter": "Szu-Wei Fu", "authors": "Szu-Wei Fu, Yu Tsao, Hsin-Te Hwang, Hsin-Min Wang", "title": "Quality-Net: An End-to-End Non-intrusive Speech Quality Assessment Model\n  based on BLSTM", "comments": "Accepted in Interspeech2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.AI eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nowadays, most of the objective speech quality assessment tools (e.g.,\nperceptual evaluation of speech quality (PESQ)) are based on the comparison of\nthe degraded/processed speech with its clean counterpart. The need of a\n\"golden\" reference considerably restricts the practicality of such assessment\ntools in real-world scenarios since the clean reference usually cannot be\naccessed. On the other hand, human beings can readily evaluate the speech\nquality without any reference (e.g., mean opinion score (MOS) tests), implying\nthe existence of an objective and non-intrusive (no clean reference needed)\nquality assessment mechanism. In this study, we propose a novel end-to-end,\nnon-intrusive speech quality evaluation model, termed Quality-Net, based on\nbidirectional long short-term memory. The evaluation of utterance-level quality\nin Quality-Net is based on the frame-level assessment. Frame constraints and\nsensible initializations of forget gate biases are applied to learn meaningful\nframe-level quality assessment from the utterance-level quality label.\nExperimental results show that Quality-Net can yield high correlation to PESQ\n(0.9 for the noisy speech and 0.84 for the speech processed by speech\nenhancement). We believe that Quality-Net has potential to be used in a wide\nvariety of applications of speech signal processing.\n", "versions": [{"version": "v1", "created": "Thu, 16 Aug 2018 04:26:41 GMT"}, {"version": "v2", "created": "Fri, 17 Aug 2018 08:02:30 GMT"}], "update_date": "2018-08-20", "authors_parsed": [["Fu", "Szu-Wei", ""], ["Tsao", "Yu", ""], ["Hwang", "Hsin-Te", ""], ["Wang", "Hsin-Min", ""]]}, {"id": "1808.05385", "submitter": "Yu Li", "authors": "Yu Li, Lizhong Ding, Xin Gao", "title": "On the Decision Boundary of Deep Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While deep learning models and techniques have achieved great empirical\nsuccess, our understanding of the source of success in many aspects remains\nvery limited. In an attempt to bridge the gap, we investigate the decision\nboundary of a production deep learning architecture with weak assumptions on\nboth the training data and the model. We demonstrate, both theoretically and\nempirically, that the last weight layer of a neural network converges to a\nlinear SVM trained on the output of the last hidden layer, for both the binary\ncase and the multi-class case with the commonly used cross-entropy loss.\nFurthermore, we show empirically that training a neural network as a whole,\ninstead of only fine-tuning the last weight layer, may result in better bias\nconstant for the last weight layer, which is important for generalization. In\naddition to facilitating the understanding of deep learning, our result can be\nhelpful for solving a broad range of practical problems of deep learning, such\nas catastrophic forgetting and adversarial attacking. The experiment codes are\navailable at https://github.com/lykaust15/NN_decision_boundary\n", "versions": [{"version": "v1", "created": "Thu, 16 Aug 2018 09:25:50 GMT"}, {"version": "v2", "created": "Thu, 23 Aug 2018 06:23:32 GMT"}, {"version": "v3", "created": "Tue, 1 Jan 2019 08:20:22 GMT"}], "update_date": "2019-01-03", "authors_parsed": [["Li", "Yu", ""], ["Ding", "Lizhong", ""], ["Gao", "Xin", ""]]}, {"id": "1808.05488", "submitter": "Lukas Cavigelli", "authors": "Lukas Cavigelli, Luca Benini", "title": "CBinfer: Exploiting Frame-to-Frame Locality for Faster Convolutional\n  Network Inference on Video Streams", "comments": "arXiv admin note: substantial text overlap with arXiv:1704.04313", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.NE eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The last few years have brought advances in computer vision at an amazing\npace, grounded on new findings in deep neural network construction and training\nas well as the availability of large labeled datasets. Applying these networks\nto images demands a high computational effort and pushes the use of\nstate-of-the-art networks on real-time video data out of reach of embedded\nplatforms. Many recent works focus on reducing network complexity for real-time\ninference on embedded computing platforms. We adopt an orthogonal viewpoint and\npropose a novel algorithm exploiting the spatio-temporal sparsity of pixel\nchanges. This optimized inference procedure resulted in an average speed-up of\n9.1x over cuDNN on the Tegra X2 platform at a negligible accuracy loss of <0.1%\nand no retraining of the network for a semantic segmentation application.\nSimilarly, an average speed-up of 7.0x has been achieved for a pose detection\nDNN and a reduction of 5x of the number of arithmetic operations to be\nperformed for object detection on static camera video surveillance data. These\nthroughput gains combined with a lower power consumption result in an energy\nefficiency of 511 GOp/s/W compared to 70 GOp/s/W for the baseline.\n", "versions": [{"version": "v1", "created": "Wed, 15 Aug 2018 15:27:29 GMT"}, {"version": "v2", "created": "Mon, 4 Mar 2019 17:07:31 GMT"}], "update_date": "2019-03-05", "authors_parsed": [["Cavigelli", "Lukas", ""], ["Benini", "Luca", ""]]}, {"id": "1808.05577", "submitter": "Stefano B. Blumberg", "authors": "Stefano B. Blumberg, Ryutaro Tanno, Iasonas Kokkinos, Daniel C.\n  Alexander", "title": "Deeper Image Quality Transfer: Training Low-Memory Neural Networks for\n  3D Images", "comments": "Accepted in: MICCAI 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we address the memory demands that come with the processing of\n3-dimensional, high-resolution, multi-channeled medical images in deep\nlearning. We exploit memory-efficient backpropagation techniques, to reduce the\nmemory complexity of network training from being linear in the network's depth,\nto being roughly constant $ - $ permitting us to elongate deep architectures\nwith negligible memory increase. We evaluate our methodology in the paradigm of\nImage Quality Transfer, whilst noting its potential application to various\ntasks that use deep learning. We study the impact of depth on accuracy and show\nthat deeper models have more predictive power, which may exploit larger\ntraining sets. We obtain substantially better results than the previous\nstate-of-the-art model with a slight memory increase, reducing the\nroot-mean-squared-error by $ 13\\% $. Our code is publicly available.\n", "versions": [{"version": "v1", "created": "Thu, 16 Aug 2018 16:42:10 GMT"}], "update_date": "2018-08-17", "authors_parsed": [["Blumberg", "Stefano B.", ""], ["Tanno", "Ryutaro", ""], ["Kokkinos", "Iasonas", ""], ["Alexander", "Daniel C.", ""]]}, {"id": "1808.05770", "submitter": "Yi Han", "authors": "Yi Han, Benjamin I.P. Rubinstein, Tamas Abraham, Tansu Alpcan, Olivier\n  De Vel, Sarah Erfani, David Hubczenko, Christopher Leckie, Paul Montague", "title": "Reinforcement Learning for Autonomous Defence in Software-Defined\n  Networking", "comments": "20 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the successful application of machine learning (ML) in a wide range\nof domains, adaptability---the very property that makes machine learning\ndesirable---can be exploited by adversaries to contaminate training and evade\nclassification. In this paper, we investigate the feasibility of applying a\nspecific class of machine learning algorithms, namely, reinforcement learning\n(RL) algorithms, for autonomous cyber defence in software-defined networking\n(SDN). In particular, we focus on how an RL agent reacts towards different\nforms of causative attacks that poison its training process, including\nindiscriminate and targeted, white-box and black-box attacks. In addition, we\nalso study the impact of the attack timing, and explore potential\ncountermeasures such as adversarial training.\n", "versions": [{"version": "v1", "created": "Fri, 17 Aug 2018 06:34:53 GMT"}], "update_date": "2018-08-20", "authors_parsed": [["Han", "Yi", ""], ["Rubinstein", "Benjamin I. P.", ""], ["Abraham", "Tamas", ""], ["Alpcan", "Tansu", ""], ["De Vel", "Olivier", ""], ["Erfani", "Sarah", ""], ["Hubczenko", "David", ""], ["Leckie", "Christopher", ""], ["Montague", "Paul", ""]]}, {"id": "1808.05839", "submitter": "Abdullah Zyarah", "authors": "Abdullah M. Zyarah and Dhireesha Kudithipudi", "title": "Neuromorphic Architecture for the Hierarchical Temporal Memory", "comments": null, "journal-ref": null, "doi": "10.1109/TETCI.2018.2850314", "report-no": null, "categories": "cs.AI cs.ET", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A biomimetic machine intelligence algorithm, that holds promise in creating\ninvariant representations of spatiotemporal input streams is the hierarchical\ntemporal memory (HTM). This unsupervised online algorithm has been demonstrated\non several machine-learning tasks, including anomaly detection. Significant\neffort has been made in formalizing and applying the HTM algorithm to different\nclasses of problems. There are few early explorations of the HTM hardware\narchitecture, especially for the earlier version of the spatial pooler of HTM\nalgorithm. In this article, we present a full-scale HTM architecture for both\nspatial pooler and temporal memory. Synthetic synapse design is proposed to\naddress the potential and dynamic interconnections occurring during learning.\nThe architecture is interweaved with parallel cells and columns that enable\nhigh processing speed for the HTM. The proposed architecture is verified for\ntwo different datasets: MNIST and the European number plate font (EUNF), with\nand without the presence of noise. The spatial pooler architecture is\nsynthesized on Xilinx ZYNQ-7, with 91.16% classification accuracy for MNIST and\n90\\% accuracy for EUNF, with noise. For the temporal memory sequence\nprediction, first and second order predictions are observed for a 5-number long\nsequence generated from EUNF dataset and 95% accuracy is obtained. Moreover,\nthe proposed hardware architecture offers 1364X speedup over the software\nrealization. These results indicate that the proposed architecture can serve as\na digital core to build the HTM in hardware and eventually as a standalone\nself-learning system.\n", "versions": [{"version": "v1", "created": "Fri, 17 Aug 2018 12:37:58 GMT"}], "update_date": "2018-08-20", "authors_parsed": [["Zyarah", "Abdullah M.", ""], ["Kudithipudi", "Dhireesha", ""]]}, {"id": "1808.05908", "submitter": "Siddhartha Brahma", "authors": "Siddhartha Brahma", "title": "Improved Language Modeling by Decoding the Past", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Highly regularized LSTMs achieve impressive results on several benchmark\ndatasets in language modeling. We propose a new regularization method based on\ndecoding the last token in the context using the predicted distribution of the\nnext token. This biases the model towards retaining more contextual\ninformation, in turn improving its ability to predict the next token. With\nnegligible overhead in the number of parameters and training time, our Past\nDecode Regularization (PDR) method achieves a word level perplexity of 55.6 on\nthe Penn Treebank and 63.5 on the WikiText-2 datasets using a single softmax.\nWe also show gains by using PDR in combination with a mixture-of-softmaxes,\nachieving a word level perplexity of 53.8 and 60.5 on these datasets. In\naddition, our method achieves 1.169 bits-per-character on the Penn Treebank\nCharacter dataset for character level language modeling. These results\nconstitute a new state-of-the-art in their respective settings.\n", "versions": [{"version": "v1", "created": "Tue, 14 Aug 2018 18:44:58 GMT"}, {"version": "v2", "created": "Sat, 29 Sep 2018 16:29:06 GMT"}, {"version": "v3", "created": "Thu, 3 Jan 2019 19:23:46 GMT"}, {"version": "v4", "created": "Wed, 23 Jan 2019 19:52:46 GMT"}], "update_date": "2019-01-25", "authors_parsed": [["Brahma", "Siddhartha", ""]]}, {"id": "1808.05979", "submitter": "Khalid Raza", "authors": "Tarun Kumar Gupta and Khalid Raza", "title": "Optimizing Deep Neural Network Architecture: A Tabu Search Based\n  Approach", "comments": "15 pages, 2 figures, 2 algorithms, 2 tables", "journal-ref": "Neural Processing Letters (2020), Springer", "doi": "10.1007/s11063-020-10234-7", "report-no": null, "categories": "cs.LG cs.AI cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The performance of Feedforward neural network (FNN) fully de-pends upon the\nselection of architecture and training algorithm. FNN architecture can be\ntweaked using several parameters, such as the number of hidden layers, number\nof hidden neurons at each hidden layer and number of connections between\nlayers. There may be exponential combinations for these architectural\nattributes which may be unmanageable manually, so it requires an algorithm\nwhich can automatically design an optimal architecture with high generalization\nability. Numerous optimization algorithms have been utilized for FNN\narchitecture determination. This paper proposes a new methodology which can\nwork on the estimation of hidden layers and their respective neurons for FNN.\nThis work combines the advantages of Tabu search (TS) and Gradient descent with\nmomentum backpropagation (GDM) training algorithm to demonstrate how Tabu\nsearch can automatically select the best architecture from the populated\narchitectures based on minimum testing error criteria. The proposed approach\nhas been tested on four classification benchmark dataset of different size.\n", "versions": [{"version": "v1", "created": "Fri, 17 Aug 2018 20:12:26 GMT"}], "update_date": "2020-05-01", "authors_parsed": [["Gupta", "Tarun Kumar", ""], ["Raza", "Khalid", ""]]}, {"id": "1808.06206", "submitter": "Pan Xiao", "authors": "Pan Xiao, Bo Du, Jia Wu, Lefei Zhang, Ruimin Hu and Xuelong Li", "title": "TLR: Transfer Latent Representation for Unsupervised Domain Adaptation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Domain adaptation refers to the process of learning prediction models in a\ntarget domain by making use of data from a source domain. Many classic methods\nsolve the domain adaptation problem by establishing a common latent space,\nwhich may cause the loss of many important properties across both domains. In\nthis manuscript, we develop a novel method, transfer latent representation\n(TLR), to learn a better latent space. Specifically, we design an objective\nfunction based on a simple linear autoencoder to derive the latent\nrepresentations of both domains. The encoder in the autoencoder aims to project\nthe data of both domains into a robust latent space. Besides, the decoder\nimposes an additional constraint to reconstruct the original data, which can\npreserve the common properties of both domains and reduce the noise that causes\ndomain shift. Experiments on cross-domain tasks demonstrate the advantages of\nTLR over competing methods.\n", "versions": [{"version": "v1", "created": "Sun, 19 Aug 2018 13:14:01 GMT"}], "update_date": "2018-08-21", "authors_parsed": [["Xiao", "Pan", ""], ["Du", "Bo", ""], ["Wu", "Jia", ""], ["Zhang", "Lefei", ""], ["Hu", "Ruimin", ""], ["Li", "Xuelong", ""]]}, {"id": "1808.06217", "submitter": "Jim Davies", "authors": "Vincent Breault, Sebastien Ouellet, Jim Davies", "title": "Let CONAN tell you a story: Procedural quest generation", "comments": "ten pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work proposes an engine for the Creation Of Novel Adventure Narrative\n(CONAN), which is a procedural quest generator. It uses a planning approach to\nstory generation. The engine is tested on its ability to create quests, which\nare sets of actions that must be performed in order to achieve a certain goal,\nusually for a reward. The engine takes in a world description represented as a\nset of facts, including characters, locations, and items, and generates quests\naccording to the state of the world and the preferences of the characters. We\nevaluate quests through the classification of the motivations behind the\nquests, based on the sequences of actions required to complete the quests. We\nalso compare different world descriptions and analyze the difference in\nmotivations for the quests produced by the engine. Compared against human\nstructural quest analysis, the current engine was found to be able to replicate\nthe quest structures found in commercial video game quests.\n", "versions": [{"version": "v1", "created": "Sun, 19 Aug 2018 14:39:46 GMT"}], "update_date": "2018-08-21", "authors_parsed": [["Breault", "Vincent", ""], ["Ouellet", "Sebastien", ""], ["Davies", "Jim", ""]]}, {"id": "1808.06244", "submitter": "Wenhu Chen", "authors": "Wenhu Chen, Jianshu Chen, Yu Su, Xin Wang, Dong Yu, Xifeng Yan and\n  William Yang Wang", "title": "XL-NBT: A Cross-lingual Neural Belief Tracking Framework", "comments": "13 pages, 5 figures, 3 tables, accepted to EMNLP 2018 conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Task-oriented dialog systems are becoming pervasive, and many companies\nheavily rely on them to complement human agents for customer service in call\ncenters. With globalization, the need for providing cross-lingual customer\nsupport becomes more urgent than ever. However, cross-lingual support poses\ngreat challenges---it requires a large amount of additional annotated data from\nnative speakers. In order to bypass the expensive human annotation and achieve\nthe first step towards the ultimate goal of building a universal dialog system,\nwe set out to build a cross-lingual state tracking framework. Specifically, we\nassume that there exists a source language with dialog belief tracking\nannotations while the target languages have no annotated dialog data of any\nform. Then, we pre-train a state tracker for the source language as a teacher,\nwhich is able to exploit easy-to-access parallel data. We then distill and\ntransfer its own knowledge to the student state tracker in target languages. We\nspecifically discuss two types of common parallel resources: bilingual corpus\nand bilingual dictionary, and design different transfer learning strategies\naccordingly. Experimentally, we successfully use English state tracker as the\nteacher to transfer its knowledge to both Italian and German trackers and\nachieve promising results.\n", "versions": [{"version": "v1", "created": "Sun, 19 Aug 2018 19:08:10 GMT"}, {"version": "v2", "created": "Sat, 25 Aug 2018 16:26:38 GMT"}], "update_date": "2018-08-28", "authors_parsed": [["Chen", "Wenhu", ""], ["Chen", "Jianshu", ""], ["Su", "Yu", ""], ["Wang", "Xin", ""], ["Yu", "Dong", ""], ["Yan", "Xifeng", ""], ["Wang", "William Yang", ""]]}, {"id": "1808.06316", "submitter": "Saisai Ma", "authors": "Saisai Ma, Jiuyong Li, Lin Liu, Thuc Duy Le", "title": "Discovering Context Specific Causal Relationships", "comments": "This paper has been accepted by Intelligent Data Analysis", "journal-ref": "Intelligent Data Analysis 23(4), 2019", "doi": null, "report-no": null, "categories": "cs.AI stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the increasing need of personalised decision making, such as\npersonalised medicine and online recommendations, a growing attention has been\npaid to the discovery of the context and heterogeneity of causal relationships.\nMost existing methods, however, assume a known cause (e.g. a new drug) and\nfocus on identifying from data the contexts of heterogeneous effects of the\ncause (e.g. patient groups with different responses to the new drug). There is\nno approach to efficiently detecting directly from observational data context\nspecific causal relationships, i.e. discovering the causes and their contexts\nsimultaneously. In this paper, by taking the advantages of highly efficient\ndecision tree induction and the well established causal inference framework, we\npropose the Tree based Context Causal rule discovery (TCC) method, for\nefficient exploration of context specific causal relationships from data.\nExperiments with both synthetic and real world data sets show that TCC can\neffectively discover context specific causal rules from the data.\n", "versions": [{"version": "v1", "created": "Mon, 20 Aug 2018 06:03:47 GMT"}], "update_date": "2018-08-21", "authors_parsed": [["Ma", "Saisai", ""], ["Li", "Jiuyong", ""], ["Liu", "Lin", ""], ["Le", "Thuc Duy", ""]]}, {"id": "1808.06423", "submitter": "Christian A. Mueller", "authors": "Madhura Thosar, Christian A. Mueller, Sebastian Zug", "title": "What Stands-in for a Missing Tool? A Prototypical Grounded\n  Knowledge-based Approach to Tool Substitution", "comments": "This work is accepted for the 11th International Cognitive Robotics\n  Workshop (CogRob) of the 16th International Conference on Principles of\n  Knowledge Representation and Reasoning (KR), Tempe, Arizona, November, 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When a robot is operating in a dynamic environment, it cannot be assumed that\na tool required to solve a given task will always be available. In case of a\nmissing tool, an ideal response would be to find a substitute to complete the\ntask. In this paper, we present a proof of concept of a grounded\nknowledge-based approach to tool substitution. In order to validate the\nsuitability of a substitute, we conducted experiments involving 22 substitution\nscenarios. The substitutes computed by the proposed approach were validated on\nthe basis of the experts' choices for each scenario. Our evaluation showed, in\n20 out of 22 scenarios (91%), the approach identified the same substitutes as\nexperts.\n", "versions": [{"version": "v1", "created": "Mon, 20 Aug 2018 12:40:25 GMT"}, {"version": "v2", "created": "Mon, 8 Oct 2018 18:26:11 GMT"}, {"version": "v3", "created": "Mon, 15 Oct 2018 19:37:20 GMT"}], "update_date": "2018-10-17", "authors_parsed": [["Thosar", "Madhura", ""], ["Mueller", "Christian A.", ""], ["Zug", "Sebastian", ""]]}, {"id": "1808.06462", "submitter": "Nitish Nag", "authors": "Nitish Nag, Vaibhav Pandey, Preston J. Putzel, Hari Bhimaraju,\n  Srikanth Krishnan, Ramesh C. Jain", "title": "Cross-Modal Health State Estimation", "comments": "Accepted to ACM Multimedia 2018 Conference - Brave New Ideas, Seoul,\n  Korea, ACM ISBN 978-1-4503-5665-7/18/10", "journal-ref": "Nitish Nag, Vaibhav Pandey, Preston J. Putzel, Hari Bhimaraju,\n  Srikanth Krishnan, Ramesh C. Jain, 2018 ACM Multimedia Conference (MM '18),\n  October 22--26, 2018, Seoul, Republic of Korea", "doi": "10.1145/3240508.3241913", "report-no": null, "categories": "cs.CY cs.AI cs.MM q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Individuals create and consume more diverse data about themselves today than\nany time in history. Sources of this data include wearable devices, images,\nsocial media, geospatial information and more. A tremendous opportunity rests\nwithin cross-modal data analysis that leverages existing domain knowledge\nmethods to understand and guide human health. Especially in chronic diseases,\ncurrent medical practice uses a combination of sparse hospital based biological\nmetrics (blood tests, expensive imaging, etc.) to understand the evolving\nhealth status of an individual. Future health systems must integrate data\ncreated at the individual level to better understand health status perpetually,\nespecially in a cybernetic framework. In this work we fuse multiple user\ncreated and open source data streams along with established biomedical domain\nknowledge to give two types of quantitative state estimates of cardiovascular\nhealth. First, we use wearable devices to calculate cardiorespiratory fitness\n(CRF), a known quantitative leading predictor of heart disease which is not\nroutinely collected in clinical settings. Second, we estimate inherent genetic\ntraits, living environmental risks, circadian rhythm, and biological metrics\nfrom a diverse dataset. Our experimental results on 24 subjects demonstrate how\nmulti-modal data can provide personalized health insight. Understanding the\ndynamic nature of health status will pave the way for better health based\nrecommendation engines, better clinical decision making and positive lifestyle\nchanges.\n", "versions": [{"version": "v1", "created": "Tue, 7 Aug 2018 00:38:38 GMT"}, {"version": "v2", "created": "Thu, 23 Aug 2018 21:19:53 GMT"}], "update_date": "2018-08-27", "authors_parsed": [["Nag", "Nitish", ""], ["Pandey", "Vaibhav", ""], ["Putzel", "Preston J.", ""], ["Bhimaraju", "Hari", ""], ["Krishnan", "Srikanth", ""], ["Jain", "Ramesh C.", ""]]}, {"id": "1808.06474", "submitter": "Yi-Te Hsu", "authors": "Yi-Te Hsu, Yu-Chen Lin, Szu-Wei Fu, Yu Tsao, Tei-Wei Kuo", "title": "A study on speech enhancement using exponent-only floating point\n  quantized neural network (EOFP-QNN)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.AI cs.LG cs.SD eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Numerous studies have investigated the effectiveness of neural network\nquantization on pattern classification tasks. The present study, for the first\ntime, investigated the performance of speech enhancement (a regression task in\nspeech processing) using a novel exponent-only floating-point quantized neural\nnetwork (EOFP-QNN). The proposed EOFP-QNN consists of two stages:\nmantissa-quantization and exponent-quantization. In the mantissa-quantization\nstage, EOFP-QNN learns how to quantize the mantissa bits of the model\nparameters while preserving the regression accuracy using the least mantissa\nprecision. In the exponent-quantization stage, the exponent part of the\nparameters is further quantized without causing any additional performance\ndegradation. We evaluated the proposed EOFP quantization technique on two types\nof neural networks, namely, bidirectional long short-term memory (BLSTM) and\nfully convolutional neural network (FCN), on a speech enhancement task.\nExperimental results showed that the model sizes can be significantly reduced\n(the model sizes of the quantized BLSTM and FCN models were only 18.75% and\n21.89%, respectively, compared to those of the original models) while\nmaintaining satisfactory speech-enhancement performance.\n", "versions": [{"version": "v1", "created": "Fri, 17 Aug 2018 11:44:34 GMT"}, {"version": "v2", "created": "Thu, 23 Aug 2018 13:04:58 GMT"}, {"version": "v3", "created": "Sun, 26 Aug 2018 16:28:20 GMT"}, {"version": "v4", "created": "Tue, 30 Oct 2018 23:49:21 GMT"}], "update_date": "2018-11-01", "authors_parsed": [["Hsu", "Yi-Te", ""], ["Lin", "Yu-Chen", ""], ["Fu", "Szu-Wei", ""], ["Tsao", "Yu", ""], ["Kuo", "Tei-Wei", ""]]}, {"id": "1808.06492", "submitter": "Adithya Balaji", "authors": "Adithya Balaji, Alexander Allen", "title": "Benchmarking Automatic Machine Learning Frameworks", "comments": "9 pages, 8 figures, 5 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  AutoML serves as the bridge between varying levels of expertise when\ndesigning machine learning systems and expedites the data science process. A\nwide range of techniques is taken to address this, however there does not exist\nan objective comparison of these techniques. We present a benchmark of current\nopen source AutoML solutions using open source datasets. We test auto-sklearn,\nTPOT, auto_ml, and H2O's AutoML solution against a compiled set of regression\nand classification datasets sourced from OpenML and find that auto-sklearn\nperforms the best across classification datasets and TPOT performs the best\nacross regression datasets.\n", "versions": [{"version": "v1", "created": "Fri, 17 Aug 2018 02:15:39 GMT"}], "update_date": "2018-08-21", "authors_parsed": [["Balaji", "Adithya", ""], ["Allen", "Alexander", ""]]}, {"id": "1808.06497", "submitter": "Keting Lu", "authors": "Keting Lu, Shiqi Zhang, Xiaoping Chen", "title": "Goal-oriented Dialogue Policy Learning from Failures", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning methods have been used for learning dialogue policies.\nHowever, learning an effective dialogue policy frequently requires\nprohibitively many conversations. This is partly because of the sparse rewards\nin dialogues, and the very few successful dialogues in early learning phase.\nHindsight experience replay (HER) enables learning from failures, but the\nvanilla HER is inapplicable to dialogue learning due to the implicit goals. In\nthis work, we develop two complex HER methods providing different trade-offs\nbetween complexity and performance, and, for the first time, enabled HER-based\ndialogue policy learning. Experiments using a realistic user simulator show\nthat our HER methods perform better than existing experience replay methods (as\napplied to deep Q-networks) in learning rate.\n", "versions": [{"version": "v1", "created": "Mon, 20 Aug 2018 15:04:30 GMT"}, {"version": "v2", "created": "Thu, 22 Nov 2018 13:51:34 GMT"}], "update_date": "2018-11-26", "authors_parsed": [["Lu", "Keting", ""], ["Zhang", "Shiqi", ""], ["Chen", "Xiaoping", ""]]}, {"id": "1808.06511", "submitter": "Ji Ma", "authors": "Ji Ma, Kuzman Ganchev and David Weiss", "title": "State-of-the-art Chinese Word Segmentation with Bi-LSTMs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A wide variety of neural-network architectures have been proposed for the\ntask of Chinese word segmentation.\n  Surprisingly, we find that a bidirectional LSTM model, when combined with\nstandard deep learning techniques and best practices, can achieve better\naccuracy on many of the popular datasets as compared to models based on more\ncomplex neural-network architectures.\n  Furthermore, our error analysis shows that out-of-vocabulary words remain\nchallenging for neural-network models, and many of the remaining errors are\nunlikely to be fixed through architecture changes.\n  Instead, more effort should be made on exploring resources for further\nimprovement.\n", "versions": [{"version": "v1", "created": "Mon, 20 Aug 2018 15:19:38 GMT"}, {"version": "v2", "created": "Fri, 24 Aug 2018 16:44:16 GMT"}], "update_date": "2018-08-27", "authors_parsed": [["Ma", "Ji", ""], ["Ganchev", "Kuzman", ""], ["Weiss", "David", ""]]}, {"id": "1808.06570", "submitter": "Zining Zhu", "authors": "Zining Zhu, Jekaterina Novikova, Frank Rudzicz", "title": "Detecting cognitive impairments by agreeing on interpretations of\n  linguistic features", "comments": "NAACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Linguistic features have shown promising applications for detecting various\ncognitive impairments. To improve detection accuracies, increasing the amount\nof data or the number of linguistic features have been two applicable\napproaches. However, acquiring additional clinical data can be expensive, and\nhand-crafting features is burdensome. In this paper, we take a third approach,\nproposing Consensus Networks (CNs), a framework to classify after reaching\nagreements between modalities. We divide linguistic features into\nnon-overlapping subsets according to their modalities, and let neural networks\nlearn low-dimensional representations that agree with each other. These\nrepresentations are passed into a classifier network. All neural networks are\noptimized iteratively.\n  In this paper, we also present two methods that improve the performance of\nCNs. We then present ablation studies to illustrate the effectiveness of\nmodality division. To understand further what happens in CNs, we visualize the\nrepresentations during training. Overall, using all of the 413 linguistic\nfeatures, our models significantly outperform traditional classifiers, which\nare used by the state-of-the-art papers.\n", "versions": [{"version": "v1", "created": "Mon, 20 Aug 2018 17:05:46 GMT"}, {"version": "v2", "created": "Tue, 4 Sep 2018 15:55:46 GMT"}, {"version": "v3", "created": "Thu, 28 Mar 2019 03:12:56 GMT"}], "update_date": "2019-03-29", "authors_parsed": [["Zhu", "Zining", ""], ["Novikova", "Jekaterina", ""], ["Rudzicz", "Frank", ""]]}, {"id": "1808.06661", "submitter": "Bin Wang", "authors": "Bin Wang and Yanan Sun and Bing Xue and Mengjie Zhang", "title": "A Hybrid Differential Evolution Approach to Designing Deep Convolutional\n  Neural Networks for Image Classification", "comments": "Accepted by The Australasian Joint Conference on Artificial\n  Intelligence 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional Neural Networks (CNNs) have demonstrated their superiority in\nimage classification, and evolutionary computation (EC) methods have recently\nbeen surging to automatically design the architectures of CNNs to save the\ntedious work of manually designing CNNs. In this paper, a new hybrid\ndifferential evolution (DE) algorithm with a newly added crossover operator is\nproposed to evolve the architectures of CNNs of any lengths, which is named\nDECNN. There are three new ideas in the proposed DECNN method. Firstly, an\nexisting effective encoding scheme is refined to cater for variable-length CNN\narchitectures; Secondly, the new mutation and crossover operators are developed\nfor variable-length DE to optimise the hyperparameters of CNNs; Finally, the\nnew second crossover is introduced to evolve the depth of the CNN\narchitectures. The proposed algorithm is tested on six widely-used benchmark\ndatasets and the results are compared to 12 state-of-the-art methods, which\nshows the proposed method is vigorously competitive to the state-of-the-art\nalgorithms. Furthermore, the proposed method is also compared with a method\nusing particle swarm optimisation with a similar encoding strategy named IPPSO,\nand the proposed DECNN outperforms IPPSO in terms of the accuracy.\n", "versions": [{"version": "v1", "created": "Mon, 20 Aug 2018 19:24:45 GMT"}, {"version": "v2", "created": "Wed, 22 Aug 2018 01:32:59 GMT"}], "update_date": "2018-08-23", "authors_parsed": [["Wang", "Bin", ""], ["Sun", "Yanan", ""], ["Xue", "Bing", ""], ["Zhang", "Mengjie", ""]]}, {"id": "1808.06675", "submitter": "Soham Saha", "authors": "Soham Saha, Girish Varma, C.V.Jawahar", "title": "Class2Str: End to End Latent Hierarchy Learning", "comments": "6 pages, ICPR 2018, Beijing", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Deep neural networks for image classification typically consists of a\nconvolutional feature extractor followed by a fully connected classifier\nnetwork. The predicted and the ground truth labels are represented as one hot\nvectors. Such a representation assumes that all classes are equally dissimilar.\nHowever, classes have visual similarities and often form a hierarchy. Learning\nthis latent hierarchy explicitly in the architecture could provide invaluable\ninsights. We propose an alternate architecture to the classifier network called\nthe Latent Hierarchy (LH) Classifier and an end to end learned Class2Str\nmapping which discovers a latent hierarchy of the classes. We show that for\nsome of the best performing architectures on CIFAR and Imagenet datasets, the\nproposed replacement and training by LH classifier recovers the accuracy, with\na fraction of the number of parameters in the classifier part. Compared to the\nprevious work of HDCNN, which also learns a 2 level hierarchy, we are able to\nlearn a hierarchy at an arbitrary number of levels as well as obtain an\naccuracy improvement on the Imagenet classification task over them. We also\nverify that many visually similar classes are grouped together, under the\nlearnt hierarchy.\n", "versions": [{"version": "v1", "created": "Mon, 20 Aug 2018 19:58:35 GMT"}], "update_date": "2018-08-22", "authors_parsed": [["Saha", "Soham", ""], ["Varma", "Girish", ""], ["Jawahar", "C. V.", ""]]}, {"id": "1808.06686", "submitter": "Ekraam Sabir", "authors": "Ekraam Sabir, Wael AbdAlmageed, Yue Wu and Prem Natarajan", "title": "Deep Multimodal Image-Repurposing Detection", "comments": "To be published at ACM Multimeda 2018 (orals)", "journal-ref": null, "doi": "10.1145/3240508.3240707", "report-no": null, "categories": "cs.MM cs.AI cs.CV cs.LG cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nefarious actors on social media and other platforms often spread rumors and\nfalsehoods through images whose metadata (e.g., captions) have been modified to\nprovide visual substantiation of the rumor/falsehood. This type of modification\nis referred to as image repurposing, in which often an unmanipulated image is\npublished along with incorrect or manipulated metadata to serve the actor's\nulterior motives. We present the Multimodal Entity Image Repurposing (MEIR)\ndataset, a substantially challenging dataset over that which has been\npreviously available to support research into image repurposing detection. The\nnew dataset includes location, person, and organization manipulations on\nreal-world data sourced from Flickr. We also present a novel, end-to-end, deep\nmultimodal learning model for assessing the integrity of an image by combining\ninformation extracted from the image with related information from a knowledge\nbase. The proposed method is compared against state-of-the-art techniques on\nexisting datasets as well as MEIR, where it outperforms existing methods across\nthe board, with AUC improvement up to 0.23.\n", "versions": [{"version": "v1", "created": "Mon, 20 Aug 2018 20:47:56 GMT"}], "update_date": "2018-08-22", "authors_parsed": [["Sabir", "Ekraam", ""], ["AbdAlmageed", "Wael", ""], ["Wu", "Yue", ""], ["Natarajan", "Prem", ""]]}, {"id": "1808.06740", "submitter": "Ziyu Yao", "authors": "Ziyu Yao, Xiujun Li, Jianfeng Gao, Brian Sadler and Huan Sun", "title": "Interactive Semantic Parsing for If-Then Recipes via Hierarchical\n  Reinforcement Learning", "comments": "13 pages, 2 figures, accepted by AAAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a text description, most existing semantic parsers synthesize a program\nin one shot. However, it is quite challenging to produce a correct program\nsolely based on the description, which in reality is often ambiguous or\nincomplete. In this paper, we investigate interactive semantic parsing, where\nthe agent can ask the user clarification questions to resolve ambiguities via a\nmulti-turn dialogue, on an important type of programs called \"If-Then recipes.\"\nWe develop a hierarchical reinforcement learning (HRL) based agent that\nsignificantly improves the parsing performance with minimal questions to the\nuser. Results under both simulation and human evaluation show that our agent\nsubstantially outperforms non-interactive semantic parsers and rule-based\nagents.\n", "versions": [{"version": "v1", "created": "Tue, 21 Aug 2018 02:39:08 GMT"}, {"version": "v2", "created": "Wed, 14 Nov 2018 18:08:39 GMT"}], "update_date": "2018-11-15", "authors_parsed": [["Yao", "Ziyu", ""], ["Li", "Xiujun", ""], ["Gao", "Jianfeng", ""], ["Sadler", "Brian", ""], ["Sun", "Huan", ""]]}, {"id": "1808.06880", "submitter": "Yuding Liang", "authors": "Yuding Liang and Kenny Q. Zhu", "title": "Automatic Generation of Text Descriptive Comments for Code Blocks", "comments": "aaai 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a framework to automatically generate descriptive comments for\nsource code blocks. While this problem has been studied by many researchers\npreviously, their methods are mostly based on fixed template and achieves poor\nresults. Our framework does not rely on any template, but makes use of a new\nrecursive neural network called Code-RNN to extract features from the source\ncode and embed them into one vector. When this vector representation is input\nto a new recurrent neural network (Code-GRU), the overall framework generates\ntext descriptions of the code with accuracy (Rouge-2 value) significantly\nhigher than other learning-based approaches such as sequence-to-sequence model.\nThe Code-RNN model can also be used in other scenario where the representation\nof code is required.\n", "versions": [{"version": "v1", "created": "Tue, 21 Aug 2018 12:53:52 GMT"}], "update_date": "2018-08-22", "authors_parsed": [["Liang", "Yuding", ""], ["Zhu", "Kenny Q.", ""]]}, {"id": "1808.06885", "submitter": "Fei Sun", "authors": "Fei Sun, Peng Jiang, Hanxiao Sun, Changhua Pei, Wenwu Ou, Xiaobo Wang", "title": "Multi-Source Pointer Network for Product Title Summarization", "comments": "10 pages, To appear in CIKM 2018, fix mistakes in dataset stats", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we study the product title summarization problem in E-commerce\napplications for display on mobile devices. Comparing with conventional\nsentence summarization, product title summarization has some extra and\nessential constraints. For example, factual errors or loss of the key\ninformation are intolerable for E-commerce applications. Therefore, we abstract\ntwo more constraints for product title summarization: (i) do not introduce\nirrelevant information; (ii) retain the key information (e.g., brand name and\ncommodity name). To address these issues, we propose a novel multi-source\npointer network by adding a new knowledge encoder for pointer network. The\nfirst constraint is handled by pointer mechanism. For the second constraint, we\nrestore the key information by copying words from the knowledge encoder with\nthe help of the soft gating mechanism. For evaluation, we build a large\ncollection of real-world product titles along with human-written short titles.\nExperimental results demonstrate that our model significantly outperforms the\nother baselines. Finally, online deployment of our proposed model has yielded a\nsignificant business impact, as measured by the click-through rate.\n", "versions": [{"version": "v1", "created": "Tue, 21 Aug 2018 13:07:53 GMT"}, {"version": "v2", "created": "Sun, 30 Sep 2018 15:31:02 GMT"}, {"version": "v3", "created": "Mon, 8 Oct 2018 16:44:32 GMT"}], "update_date": "2018-10-09", "authors_parsed": [["Sun", "Fei", ""], ["Jiang", "Peng", ""], ["Sun", "Hanxiao", ""], ["Pei", "Changhua", ""], ["Ou", "Wenwu", ""], ["Wang", "Xiaobo", ""]]}, {"id": "1808.06907", "submitter": "Rafael S. Gon\\c{c}alves", "authors": "Rafael S. Gon\\c{c}alves and Mark A. Musen", "title": "The variable quality of metadata about biological samples used in\n  biomedical experiments", "comments": "arXiv admin note: text overlap with arXiv:1708.01286", "journal-ref": null, "doi": "10.1038/sdata.2019.21", "report-no": null, "categories": "cs.DB cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present an analytical study of the quality of metadata about samples used\nin biomedical experiments. The metadata under analysis are stored in two\nwell-known databases: BioSample---a repository managed by the National Center\nfor Biotechnology Information (NCBI), and BioSamples---a repository managed by\nthe European Bioinformatics Institute (EBI). We tested whether 11.4M sample\nmetadata records in the two repositories are populated with values that fulfill\nthe stated requirements for such values. Our study revealed multiple anomalies\nin the metadata. Most metadata field names and their values are not\nstandardized or controlled. Even simple binary or numeric fields are often\npopulated with inadequate values of different data types. By clustering\nmetadata field names, we discovered there are often many distinct ways to\nrepresent the same aspect of a sample. Overall, the metadata we analyzed reveal\nthat there is a lack of principled mechanisms to enforce and validate metadata\nrequirements. The significant aberrancies that we found in the metadata are\nlikely to impede search and secondary use of the associated datasets.\n", "versions": [{"version": "v1", "created": "Fri, 17 Aug 2018 18:03:26 GMT"}, {"version": "v2", "created": "Sat, 19 Jan 2019 03:46:41 GMT"}], "update_date": "2019-02-27", "authors_parsed": [["Gon\u00e7alves", "Rafael S.", ""], ["Musen", "Mark A.", ""]]}, {"id": "1808.06934", "submitter": "Giuseppe Marra", "authors": "Alessandro Betti and Marco Gori and Giuseppe Marra", "title": "Backpropagation and Biological Plausibility", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  By and large, Backpropagation (BP) is regarded as one of the most important\nneural computation algorithms at the basis of the progress in machine learning,\nincluding the recent advances in deep learning. However, its computational\nstructure has been the source of many debates on its arguable biological\nplausibility. In this paper, it is shown that when framing supervised learning\nin the Lagrangian framework, while one can see a natural emergence of\nBackpropagation, biologically plausible local algorithms can also be devised\nthat are based on the search for saddle points in the learning adjoint space\ncomposed of weights, neural outputs, and Lagrangian multipliers. This might\nopen the doors to a truly novel class of learning algorithms where, because of\nthe introduction of the notion of support neurons, the optimization scheme also\nplays a fundamental role in the construction of the architecture.\n", "versions": [{"version": "v1", "created": "Tue, 21 Aug 2018 14:41:56 GMT"}], "update_date": "2018-08-22", "authors_parsed": [["Betti", "Alessandro", ""], ["Gori", "Marco", ""], ["Marra", "Giuseppe", ""]]}, {"id": "1808.07004", "submitter": "J. G. Wolff", "authors": "J Gerard Wolff", "title": "Mathematics as information compression via the matching and unification\n  of patterns", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes a novel perspective on the foundations of mathematics:\nhow mathematics may be seen to be largely about 'information compression via\nthe matching and unification of patterns' (ICMUP). ICMUP is itself a novel\napproach to information compression, couched in terms of non-mathematical\nprimitives, as is necessary in any investigation of the foundations of\nmathematics. This new perspective on the foundations of mathematics has grown\nout of an extensive programme of research developing the \"SP Theory of\nIntelligence\" and its realisation in the \"SP Computer Model\", a system in which\na generalised version of ICMUP -- the powerful concept of SP-multiple-alignment\n-- plays a central role. These ideas may be seen to be part of a \"Big Picture\"\ncomprising six areas of interest, with information compression as a unifying\ntheme. The paper describes the close relation between mathematics and\ninformation compression, and describes examples showing how variants of ICMUP\nmay be seen in widely-used structures and operations in mathematics. Examples\nare also given to show how the mathematics-related disciplines of logic and\ncomputing may be understood as ICMUP. There are many potential benefits and\napplications of these ideas.\n", "versions": [{"version": "v1", "created": "Sun, 5 Aug 2018 09:17:06 GMT"}, {"version": "v2", "created": "Tue, 9 Oct 2018 13:42:48 GMT"}], "update_date": "2018-10-10", "authors_parsed": [["Wolff", "J Gerard", ""]]}, {"id": "1808.07036", "submitter": "Mark Yatskar", "authors": "Eunsol Choi, He He, Mohit Iyyer, Mark Yatskar, Wen-tau Yih, Yejin\n  Choi, Percy Liang, Luke Zettlemoyer", "title": "QuAC : Question Answering in Context", "comments": "EMNLP Camera Ready", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present QuAC, a dataset for Question Answering in Context that contains\n14K information-seeking QA dialogs (100K questions in total). The dialogs\ninvolve two crowd workers: (1) a student who poses a sequence of freeform\nquestions to learn as much as possible about a hidden Wikipedia text, and (2) a\nteacher who answers the questions by providing short excerpts from the text.\nQuAC introduces challenges not found in existing machine comprehension\ndatasets: its questions are often more open-ended, unanswerable, or only\nmeaningful within the dialog context, as we show in a detailed qualitative\nevaluation. We also report results for a number of reference models, including\na recently state-of-the-art reading comprehension architecture extended to\nmodel dialog context. Our best model underperforms humans by 20 F1, suggesting\nthat there is significant room for future work on this data. Dataset, baseline,\nand leaderboard available at http://quac.ai.\n", "versions": [{"version": "v1", "created": "Tue, 21 Aug 2018 17:46:12 GMT"}, {"version": "v2", "created": "Wed, 22 Aug 2018 00:50:43 GMT"}, {"version": "v3", "created": "Tue, 28 Aug 2018 00:58:48 GMT"}], "update_date": "2018-08-29", "authors_parsed": [["Choi", "Eunsol", ""], ["He", "He", ""], ["Iyyer", "Mohit", ""], ["Yatskar", "Mark", ""], ["Yih", "Wen-tau", ""], ["Choi", "Yejin", ""], ["Liang", "Percy", ""], ["Zettlemoyer", "Luke", ""]]}, {"id": "1808.07042", "submitter": "Siva Reddy", "authors": "Siva Reddy and Danqi Chen and Christopher D. Manning", "title": "CoQA: A Conversational Question Answering Challenge", "comments": "TACL (presented at NAACL 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Humans gather information by engaging in conversations involving a series of\ninterconnected questions and answers. For machines to assist in information\ngathering, it is therefore essential to enable them to answer conversational\nquestions. We introduce CoQA, a novel dataset for building Conversational\nQuestion Answering systems. Our dataset contains 127k questions with answers,\nobtained from 8k conversations about text passages from seven diverse domains.\nThe questions are conversational, and the answers are free-form text with their\ncorresponding evidence highlighted in the passage. We analyze CoQA in depth and\nshow that conversational questions have challenging phenomena not present in\nexisting reading comprehension datasets, e.g., coreference and pragmatic\nreasoning. We evaluate strong conversational and reading comprehension models\non CoQA. The best system obtains an F1 score of 65.4%, which is 23.4 points\nbehind human performance (88.8%), indicating there is ample room for\nimprovement. We launch CoQA as a challenge to the community at\nhttp://stanfordnlp.github.io/coqa/\n", "versions": [{"version": "v1", "created": "Tue, 21 Aug 2018 17:52:02 GMT"}, {"version": "v2", "created": "Fri, 29 Mar 2019 20:50:21 GMT"}], "update_date": "2019-04-02", "authors_parsed": [["Reddy", "Siva", ""], ["Chen", "Danqi", ""], ["Manning", "Christopher D.", ""]]}, {"id": "1808.07049", "submitter": "Albert Ierusalem", "authors": "Albert Ierusalem", "title": "Catastrophic Importance of Catastrophic Forgetting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes some of the possibilities of artificial neural networks\nthat open up after solving the problem of catastrophic forgetting. A simple\nmodel and reinforcement learning applications of existing methods are also\nproposed.\n", "versions": [{"version": "v1", "created": "Mon, 20 Aug 2018 21:49:13 GMT"}], "update_date": "2018-08-23", "authors_parsed": [["Ierusalem", "Albert", ""]]}, {"id": "1808.07050", "submitter": "Yuanlin Zhang", "authors": "Michael Gelfond and Yuanlin Zhang", "title": "Vicious Circle Principle and Logic Programs with Aggregates", "comments": "arXiv admin note: text overlap with arXiv:1405.3637", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper presents a knowledge representation language $\\mathcal{A}log$ which\nextends ASP with aggregates. The goal is to have a language based on simple\nsyntax and clear intuitive and mathematical semantics. We give some properties\nof $\\mathcal{A}log$, an algorithm for computing its answer sets, and comparison\nwith other approaches.\n", "versions": [{"version": "v1", "created": "Tue, 21 Aug 2018 04:16:03 GMT"}], "update_date": "2018-08-23", "authors_parsed": [["Gelfond", "Michael", ""], ["Zhang", "Yuanlin", ""]]}, {"id": "1808.07074", "submitter": "Tarek Richard Besold", "authors": "Tarek R. Besold and Sara L. Uckelman", "title": "The What, the Why, and the How of Artificial Explanations in Automated\n  Decision-Making", "comments": "working draft, comments/feedback welcome", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CY cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The increasing incorporation of Artificial Intelligence in the form of\nautomated systems into decision-making procedures highlights not only the\nimportance of decision theory for automated systems but also the need for these\ndecision procedures to be explainable to the people involved in them.\nTraditional realist accounts of explanation, wherein explanation is a relation\nthat holds (or does not hold) eternally between an explanans and an\nexplanandum, are not adequate to account for the notion of explanation required\nfor artificial decision procedures. We offer an alternative account of\nexplanation as used in the context of automated decision-making that makes\nexplanation an epistemic phenomenon, and one that is dependent on context. This\naccount of explanation better accounts for the way that we talk about, and use,\nexplanations and derived concepts, such as `explanatory power', and also allows\nus to differentiate between reasons or causes on the one hand, which do not\nneed to have an epistemic aspect, and explanations on the other, which do have\nsuch an aspect. Against this theoretical backdrop we then review existing\napproaches to explanation in Artificial Intelligence and Machine Learning, and\nsuggest desiderata which truly explainable decision systems should fulfill.\n", "versions": [{"version": "v1", "created": "Tue, 21 Aug 2018 18:06:22 GMT"}], "update_date": "2018-08-23", "authors_parsed": [["Besold", "Tarek R.", ""], ["Uckelman", "Sara L.", ""]]}, {"id": "1808.07104", "submitter": "Yury Zemlyanskiy", "authors": "Yury Zemlyanskiy and Fei Sha", "title": "Aiming to Know You Better Perhaps Makes Me a More Engaging Dialogue\n  Partner", "comments": "To appear in the proceedings of Conference on Computational Natural\n  Language Learning, CoNLL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There have been several attempts to define a plausible motivation for a\nchit-chat dialogue agent that can lead to engaging conversations. In this work,\nwe explore a new direction where the agent specifically focuses on discovering\ninformation about its interlocutor. We formalize this approach by defining a\nquantitative metric. We propose an algorithm for the agent to maximize it. We\nvalidate the idea with human evaluation where our system outperforms various\nbaselines. We demonstrate that the metric indeed correlates with the human\njudgments of engagingness.\n", "versions": [{"version": "v1", "created": "Tue, 21 Aug 2018 19:52:08 GMT"}], "update_date": "2018-08-23", "authors_parsed": [["Zemlyanskiy", "Yury", ""], ["Sha", "Fei", ""]]}, {"id": "1808.07168", "submitter": "Stanimire Tomov", "authors": "Nathalie-Sofia Tomov and Stanimire Tomov", "title": "On Deep Neural Networks for Detecting Heart Disease", "comments": "10 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.PF stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Heart disease is the leading cause of death, and experts estimate that\napproximately half of all heart attacks and strokes occur in people who have\nnot been flagged as \"at risk.\" Thus, there is an urgent need to improve the\naccuracy of heart disease diagnosis. To this end, we investigate the potential\nof using data analysis, and in particular the design and use of deep neural\nnetworks (DNNs) for detecting heart disease based on routine clinical data. Our\nmain contribution is the design, evaluation, and optimization of DNN\narchitectures of increasing depth for heart disease diagnosis. This work led to\nthe discovery of a novel five layer DNN architecture - named Heart Evaluation\nfor Algorithmic Risk-reduction and Optimization Five (HEARO-5) -- that yields\nbest prediction accuracy. HEARO-5's design employs regularization optimization\nand automatically deals with missing data and/or data outliers. To evaluate and\ntune the architectures we use k-way cross-validation as well as Matthews\ncorrelation coefficient (MCC) to measure the quality of our classifications.\nThe study is performed on the publicly available Cleveland dataset of medical\ninformation, and we are making our developments open source, to further\nfacilitate openness and research on the use of DNNs in medicine. The HEARO-5\narchitecture, yielding 99% accuracy and 0.98 MCC, significantly outperforms\ncurrently published research in the area.\n", "versions": [{"version": "v1", "created": "Wed, 22 Aug 2018 00:51:57 GMT"}], "update_date": "2018-08-23", "authors_parsed": [["Tomov", "Nathalie-Sofia", ""], ["Tomov", "Stanimire", ""]]}, {"id": "1808.07187", "submitter": "Xingxing Zhang", "authors": "Xingxing Zhang, Mirella Lapata, Furu Wei and Ming Zhou", "title": "Neural Latent Extractive Document Summarization", "comments": "to appear in EMNLP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Extractive summarization models require sentence-level labels, which are\nusually created heuristically (e.g., with rule-based methods) given that most\nsummarization datasets only have document-summary pairs. Since these labels\nmight be suboptimal, we propose a latent variable extractive model where\nsentences are viewed as latent variables and sentences with activated variables\nare used to infer gold summaries. During training the loss comes\n\\emph{directly} from gold summaries. Experiments on the CNN/Dailymail dataset\nshow that our model improves over a strong extractive baseline trained on\nheuristically approximated labels and also performs competitively to several\nrecent models.\n", "versions": [{"version": "v1", "created": "Wed, 22 Aug 2018 02:18:40 GMT"}, {"version": "v2", "created": "Tue, 28 Aug 2018 06:27:09 GMT"}], "update_date": "2018-08-29", "authors_parsed": [["Zhang", "Xingxing", ""], ["Lapata", "Mirella", ""], ["Wei", "Furu", ""], ["Zhou", "Ming", ""]]}, {"id": "1808.07191", "submitter": "Shuming Ma", "authors": "Deli Chen, Shuming Ma, Pengcheng Yang, Xu Sun", "title": "Identifying High-Quality Chinese News Comments Based on Multi-Target\n  Text Matching Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the development of information technology, there is an explosive growth\nin the number of online comment concerning news, blogs and so on. The massive\ncomments are overloaded, and often contain some misleading and unwelcome\ninformation. Therefore, it is necessary to identify high-quality comments and\nfilter out low-quality comments. In this work, we introduce a novel task:\nhigh-quality comment identification (HQCI), which aims to automatically assess\nthe quality of online comments. First, we construct a news comment corpus,\nwhich consists of news, comments, and the corresponding quality label. Second,\nwe analyze the dataset, and find the quality of comments can be measured in\nthree aspects: informativeness, consistency, and novelty. Finally, we propose a\nnovel multi-target text matching model, which can measure three aspects by\nreferring to the news and surrounding comments. Experimental results show that\nour method can outperform various baselines by a large margin on the news\ndataset.\n", "versions": [{"version": "v1", "created": "Wed, 22 Aug 2018 02:33:15 GMT"}], "update_date": "2018-08-23", "authors_parsed": [["Chen", "Deli", ""], ["Ma", "Shuming", ""], ["Yang", "Pengcheng", ""], ["Sun", "Xu", ""]]}, {"id": "1808.07220", "submitter": "Brandon Da Silva", "authors": "Brandon Da Silva", "title": "Approximating Poker Probabilities with Deep Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many poker systems, whether created with heuristics or machine learning, rely\non the probability of winning as a key input. However calculating the precise\nprobability using combinatorics is an intractable problem, so instead we\napproximate it. Monte Carlo simulation is an effective technique that can be\nused to approximate the probability that a player will win and/or tie a hand.\nHowever, without the use of a memory-intensive lookup table or a supercomputer,\nit becomes infeasible to run millions of times when training an agent with\nself-play. To combat the space-time tradeoff, we use deep learning to\napproximate the probabilities obtained from the Monte Carlo simulation with\nhigh accuracy. The learned model proves to be a lightweight alternative to\nMonte Carlo simulation, which ultimately allows us to use the probabilities as\ninputs during self-play efficiently. The source code and optimized neural\nnetwork can be found at\nhttps://github.com/brandinho/Poker-Probability-Approximation\n", "versions": [{"version": "v1", "created": "Wed, 22 Aug 2018 05:14:41 GMT"}, {"version": "v2", "created": "Thu, 23 Aug 2018 02:21:56 GMT"}], "update_date": "2018-08-24", "authors_parsed": [["Da Silva", "Brandon", ""]]}, {"id": "1808.07228", "submitter": "Ganbin Zhou", "authors": "Ganbin Zhou, Rongyu Cao, Xiang Ao, Ping Luo, Fen Lin, Leyu Lin, Qing\n  He", "title": "Hierarchical Neural Network for Extracting Knowledgeable Snippets and\n  Documents", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this study, we focus on extracting knowledgeable snippets and annotating\nknowledgeable documents from Web corpus, consisting of the documents from\nsocial media and We-media. Informally, knowledgeable snippets refer to the text\ndescribing concepts, properties of entities, or relations among entities, while\nknowledgeable documents are the ones with enough knowledgeable snippets. These\nknowledgeable snippets and documents could be helpful in multiple applications,\nsuch as knowledge base construction and knowledge-oriented service. Previous\nstudies extracted the knowledgeable snippets using the pattern-based method.\nHere, we propose the semantic-based method for this task. Specifically, a CNN\nbased model is developed to extract knowledgeable snippets and annotate\nknowledgeable documents simultaneously. Additionally, a \"low-level sharing,\nhigh-level splitting\" structure of CNN is designed to handle the documents from\ndifferent content domains. Compared with building multiple domain-specific\nCNNs, this joint model not only critically saves the training time, but also\nimproves the prediction accuracy visibly. The superiority of the proposed\nmethod is demonstrated in a real dataset from Wechat public platform.\n", "versions": [{"version": "v1", "created": "Wed, 22 Aug 2018 05:57:13 GMT"}], "update_date": "2018-08-23", "authors_parsed": [["Zhou", "Ganbin", ""], ["Cao", "Rongyu", ""], ["Ao", "Xiang", ""], ["Luo", "Ping", ""], ["Lin", "Fen", ""], ["Lin", "Leyu", ""], ["He", "Qing", ""]]}, {"id": "1808.07251", "submitter": "Murat Ali Bayir", "authors": "Murat Ali Bayir, Mingsen Xu, Yaojia Zhu, Yifan Shi", "title": "Genie: An Open Box Counterfactual Policy Estimator for Optimizing\n  Sponsored Search Marketplace", "comments": "20 pages, 13 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose an offline counterfactual policy estimation\nframework called Genie to optimize Sponsored Search Marketplace. Genie employs\nan open box simulation engine with click calibration model to compute the KPI\nimpact of any modification to the system. From the experimental results on Bing\ntraffic, we showed that Genie performs better than existing observational\napproaches that employs randomized experiments for traffic slices that have\nfrequent policy updates. We also show that Genie can be used to tune completely\nnew policies efficiently without creating risky randomized experiments due to\ncold start problem. As time of today, Genie hosts more than 10000 optimization\njobs yearly which runs more than 30 Million processing node hours of big data\njobs for Bing Ads. For the last 3 years, Genie has been proven to be the one of\nthe major platforms to optimize Bing Ads Marketplace due to its reliability\nunder frequent policy changes and its efficiency to minimize risks in real\nexperiments.\n", "versions": [{"version": "v1", "created": "Wed, 22 Aug 2018 07:27:26 GMT"}], "update_date": "2018-08-23", "authors_parsed": [["Bayir", "Murat Ali", ""], ["Xu", "Mingsen", ""], ["Zhu", "Yaojia", ""], ["Shi", "Yifan", ""]]}, {"id": "1808.07261", "submitter": "Michael Hind", "authors": "Matthew Arnold, Rachel K. E. Bellamy, Michael Hind, Stephanie Houde,\n  Sameep Mehta, Aleksandra Mojsilovic, Ravi Nair, Karthikeyan Natesan\n  Ramamurthy, Darrell Reimer, Alexandra Olteanu, David Piorkowski, Jason Tsay,\n  and Kush R. Varshney", "title": "FactSheets: Increasing Trust in AI Services through Supplier's\n  Declarations of Conformity", "comments": "31 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Accuracy is an important concern for suppliers of artificial intelligence\n(AI) services, but considerations beyond accuracy, such as safety (which\nincludes fairness and explainability), security, and provenance, are also\ncritical elements to engender consumers' trust in a service. Many industries\nuse transparent, standardized, but often not legally required documents called\nsupplier's declarations of conformity (SDoCs) to describe the lineage of a\nproduct along with the safety and performance testing it has undergone. SDoCs\nmay be considered multi-dimensional fact sheets that capture and quantify\nvarious aspects of the product and its development to make it worthy of\nconsumers' trust. Inspired by this practice, we propose FactSheets to help\nincrease trust in AI services. We envision such documents to contain purpose,\nperformance, safety, security, and provenance information to be completed by AI\nservice providers for examination by consumers. We suggest a comprehensive set\nof declaration items tailored to AI and provide examples for two fictitious AI\nservices in the appendix of the paper.\n", "versions": [{"version": "v1", "created": "Wed, 22 Aug 2018 07:55:56 GMT"}, {"version": "v2", "created": "Thu, 7 Feb 2019 13:34:04 GMT"}], "update_date": "2019-02-08", "authors_parsed": [["Arnold", "Matthew", ""], ["Bellamy", "Rachel K. E.", ""], ["Hind", "Michael", ""], ["Houde", "Stephanie", ""], ["Mehta", "Sameep", ""], ["Mojsilovic", "Aleksandra", ""], ["Nair", "Ravi", ""], ["Ramamurthy", "Karthikeyan Natesan", ""], ["Reimer", "Darrell", ""], ["Olteanu", "Alexandra", ""], ["Piorkowski", "David", ""], ["Tsay", "Jason", ""], ["Varshney", "Kush R.", ""]]}, {"id": "1808.07270", "submitter": "Margarita Osadchy", "authors": "Jinchao Liu, Stuart J. Gibson, Margarita Osadchy", "title": "Learning to Support: Exploiting Structure Information in Support Sets\n  for One-Shot Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Learning shows very good performance when trained on large labeled data\nsets. The problem of training a deep net on a few or one sample per class\nrequires a different learning approach which can generalize to unseen classes\nusing only a few representatives of these classes. This problem has previously\nbeen approached by meta-learning. Here we propose a novel meta-learner which\nshows state-of-the-art performance on common benchmarks for one/few shot\nclassification. Our model features three novel components: First is a\nfeed-forward embedding that takes random class support samples (after a\ncustomary CNN embedding) and transfers them to a better class representation in\nterms of a classification problem. Second is a novel attention mechanism,\ninspired by competitive learning, which causes class representatives to compete\nwith each other to become a temporary class prototype with respect to the query\npoint. This mechanism allows switching between representatives depending on the\nposition of the query point. Once a prototype is chosen for each class, the\npredicated label is computed using a simple attention mechanism over prototypes\nof all considered classes. The third feature is the ability of our meta-learner\nto incorporate deeper CNN embedding, enabling larger capacity. Finally, to ease\nthe training procedure and reduce overfitting, we averages the top $t$ models\n(evaluated on the validation) over the optimization trajectory. We show that\nthis approach can be viewed as an approximation to an ensemble, which saves the\nfactor of $t$ in training and test times and the factor of of $t$ in the\nstorage of the final model.\n", "versions": [{"version": "v1", "created": "Wed, 22 Aug 2018 08:29:16 GMT"}], "update_date": "2018-08-23", "authors_parsed": [["Liu", "Jinchao", ""], ["Gibson", "Stuart J.", ""], ["Osadchy", "Margarita", ""]]}, {"id": "1808.07272", "submitter": "Sibo Song", "authors": "Sibo Song, Ngai-Man Cheung, Vijay Chandrasekhar, Bappaditya Mandal", "title": "Deep Adaptive Temporal Pooling for Activity Recognition", "comments": "Accepted by ACM Multimedia 2018", "journal-ref": null, "doi": "10.1145/3240508.3240713", "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks have recently achieved competitive accuracy for human\nactivity recognition. However, there is room for improvement, especially in\nmodeling long-term temporal importance and determining the activity relevance\nof different temporal segments in a video. To address this problem, we propose\na learnable and differentiable module: Deep Adaptive Temporal Pooling (DATP).\nDATP applies a self-attention mechanism to adaptively pool the classification\nscores of different video segments. Specifically, using frame-level features,\nDATP regresses importance of different temporal segments and generates weights\nfor them. Remarkably, DATP is trained using only the video-level label. There\nis no need of additional supervision except video-level activity class label.\nWe conduct extensive experiments to investigate various input features and\ndifferent weight models. Experimental results show that DATP can learn to\nassign large weights to key video segments. More importantly, DATP can improve\ntraining of frame-level feature extractor. This is because relevant temporal\nsegments are assigned large weights during back-propagation. Overall, we\nachieve state-of-the-art performance on UCF101, HMDB51 and Kinetics datasets.\n", "versions": [{"version": "v1", "created": "Wed, 22 Aug 2018 08:29:38 GMT"}], "update_date": "2018-08-23", "authors_parsed": [["Song", "Sibo", ""], ["Cheung", "Ngai-Man", ""], ["Chandrasekhar", "Vijay", ""], ["Mandal", "Bappaditya", ""]]}, {"id": "1808.07275", "submitter": "Valentin Vielzeuf", "authors": "Valentin Vielzeuf, Alexis Lechervy, St\\'ephane Pateux, Fr\\'ed\\'eric\n  Jurie", "title": "CentralNet: a Multilayer Approach for Multimodal Fusion", "comments": null, "journal-ref": "European Conference on Computer Vision Workshops: Multimodal\n  Learning and Applications, Sep 2018, Munich, Germany.\n  https://mula2018.github.io/", "doi": null, "report-no": null, "categories": "cs.AI cs.CV cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a novel multimodal fusion approach, aiming to produce\nbest possible decisions by integrating information coming from multiple media.\nWhile most of the past multimodal approaches either work by projecting the\nfeatures of different modalities into the same space, or by coordinating the\nrepresentations of each modality through the use of constraints, our approach\nborrows from both visions. More specifically, assuming each modality can be\nprocessed by a separated deep convolutional network, allowing to take decisions\nindependently from each modality, we introduce a central network linking the\nmodality specific networks. This central network not only provides a common\nfeature embedding but also regularizes the modality specific networks through\nthe use of multi-task learning. The proposed approach is validated on 4\ndifferent computer vision tasks on which it consistently improves the accuracy\nof existing multimodal fusion approaches.\n", "versions": [{"version": "v1", "created": "Wed, 22 Aug 2018 08:37:55 GMT"}], "update_date": "2018-08-23", "authors_parsed": [["Vielzeuf", "Valentin", ""], ["Lechervy", "Alexis", ""], ["Pateux", "St\u00e9phane", ""], ["Jurie", "Fr\u00e9d\u00e9ric", ""]]}, {"id": "1808.07302", "submitter": "Sergey Paramonov", "authors": "Sergey Paramonov, Daria Stepanova, Pauli Miettinen", "title": "Hybrid ASP-based Approach to Pattern Mining", "comments": "29 pages, 7 figures, 5 tables", "journal-ref": "Theory and Practice of Logic Programming 19 (2019) 505-535", "doi": "10.1017/S1471068418000467", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Detecting small sets of relevant patterns from a given dataset is a central\nchallenge in data mining. The relevance of a pattern is based on user-provided\ncriteria; typically, all patterns that satisfy certain criteria are considered\nrelevant. Rule-based languages like Answer Set Programming (ASP) seem\nwell-suited for specifying such criteria in a form of constraints. Although\nprogress has been made, on the one hand, on solving individual mining problems\nand, on the other hand, developing generic mining systems, the existing methods\neither focus on scalability or on generality. In this paper we make steps\ntowards combining local (frequency, size, cost) and global (various condensed\nrepresentations like maximal, closed, skyline) constraints in a generic and\nefficient way. We present a hybrid approach for itemset, sequence and graph\nmining which exploits dedicated highly optimized mining systems to detect\nfrequent patterns and then filters the results using declarative ASP. To\nfurther demonstrate the generic nature of our hybrid framework we apply it to a\nproblem of approximately tiling a database. Experiments on real-world datasets\nshow the effectiveness of the proposed method and computational gains for\nitemset, sequence and graph mining, as well as approximate tiling.\n  Under consideration in Theory and Practice of Logic Programming (TPLP).\n", "versions": [{"version": "v1", "created": "Wed, 22 Aug 2018 10:21:13 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Paramonov", "Sergey", ""], ["Stepanova", "Daria", ""], ["Miettinen", "Pauli", ""]]}, {"id": "1808.07374", "submitter": "Junyang Lin", "authors": "Junyang Lin, Xu Sun, Xuancheng Ren, Muyu Li and Qi Su", "title": "Learning When to Concentrate or Divert Attention: Self-Adaptive\n  Attention Temperature for Neural Machine Translation", "comments": "To appear in EMNLP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most of the Neural Machine Translation (NMT) models are based on the\nsequence-to-sequence (Seq2Seq) model with an encoder-decoder framework equipped\nwith the attention mechanism. However, the conventional attention mechanism\ntreats the decoding at each time step equally with the same matrix, which is\nproblematic since the softness of the attention for different types of words\n(e.g. content words and function words) should differ. Therefore, we propose a\nnew model with a mechanism called Self-Adaptive Control of Temperature (SACT)\nto control the softness of attention by means of an attention temperature.\nExperimental results on the Chinese-English translation and English-Vietnamese\ntranslation demonstrate that our model outperforms the baseline models, and the\nanalysis and the case study show that our model can attend to the most relevant\nelements in the source-side contexts and generate the translation of high\nquality.\n", "versions": [{"version": "v1", "created": "Wed, 22 Aug 2018 14:13:24 GMT"}, {"version": "v2", "created": "Sun, 26 Aug 2018 16:19:56 GMT"}], "update_date": "2018-08-28", "authors_parsed": [["Lin", "Junyang", ""], ["Sun", "Xu", ""], ["Ren", "Xuancheng", ""], ["Li", "Muyu", ""], ["Su", "Qi", ""]]}, {"id": "1808.07431", "submitter": "Kerstin Kl\\\"aser", "authors": "Kerstin Kl\\\"aser, Pawel Markiewicz, Marta Ranzini, Wenqi Li, Marc\n  Modat, Brian F Hutton, David Atkinson, Kris Thielemans, M Jorge Cardoso, and\n  Sebastien Ourselin", "title": "Deep Boosted Regression for MR to CT Synthesis", "comments": "Accepted at SASHIMI2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.med-ph cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Attenuation correction is an essential requirement of positron emission\ntomography (PET) image reconstruction to allow for accurate quantification.\nHowever, attenuation correction is particularly challenging for PET-MRI as\nneither PET nor magnetic resonance imaging (MRI) can directly image tissue\nattenuation properties. MRI-based computed tomography (CT) synthesis has been\nproposed as an alternative to physics based and segmentation-based approaches\nthat assign a population-based tissue density value in order to generate an\nattenuation map. We propose a novel deep fully convolutional neural network\nthat generates synthetic CTs in a recursive manner by gradually reducing the\nresiduals of the previous network, increasing the overall accuracy and\ngeneralisability, while keeping the number of trainable parameters within\nreasonable limits. The model is trained on a database of 20 pre-acquired MRI/CT\npairs and a four-fold random bootstrapped validation with a 80:20 split is\nperformed. Quantitative results show that the proposed framework outperforms a\nstate-of-the-art atlas-based approach decreasing the Mean Absolute Error (MAE)\nfrom 131HU to 68HU for the synthetic CTs and reducing the PET reconstruction\nerror from 14.3% to 7.2%.\n", "versions": [{"version": "v1", "created": "Wed, 22 Aug 2018 16:40:22 GMT"}], "update_date": "2018-08-23", "authors_parsed": [["Kl\u00e4ser", "Kerstin", ""], ["Markiewicz", "Pawel", ""], ["Ranzini", "Marta", ""], ["Li", "Wenqi", ""], ["Modat", "Marc", ""], ["Hutton", "Brian F", ""], ["Atkinson", "David", ""], ["Thielemans", "Kris", ""], ["Cardoso", "M Jorge", ""], ["Ourselin", "Sebastien", ""]]}, {"id": "1808.07561", "submitter": "Ankur Bapna", "authors": "Ankur Bapna, Mia Xu Chen, Orhan Firat, Yuan Cao, Yonghui Wu", "title": "Training Deeper Neural Machine Translation Models with Transparent\n  Attention", "comments": "To appear in EMNLP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While current state-of-the-art NMT models, such as RNN seq2seq and\nTransformers, possess a large number of parameters, they are still shallow in\ncomparison to convolutional models used for both text and vision applications.\nIn this work we attempt to train significantly (2-3x) deeper Transformer and\nBi-RNN encoders for machine translation. We propose a simple modification to\nthe attention mechanism that eases the optimization of deeper models, and\nresults in consistent gains of 0.7-1.1 BLEU on the benchmark WMT'14\nEnglish-German and WMT'15 Czech-English tasks for both architectures.\n", "versions": [{"version": "v1", "created": "Wed, 22 Aug 2018 20:53:37 GMT"}, {"version": "v2", "created": "Tue, 4 Sep 2018 20:10:24 GMT"}], "update_date": "2018-09-06", "authors_parsed": [["Bapna", "Ankur", ""], ["Chen", "Mia Xu", ""], ["Firat", "Orhan", ""], ["Cao", "Yuan", ""], ["Wu", "Yonghui", ""]]}, {"id": "1808.07569", "submitter": "Abhimanyu Mitra", "authors": "Abhimanyu Mitra, Kannan Achan and Sushant Kumar", "title": "Robust Counterfactual Inferences using Feature Learning and their\n  Applications", "comments": "15 pages,1 Figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a wide variety of applications, including personalization, we want to\nmeasure the difference in outcome due to an intervention and thus have to deal\nwith counterfactual inference. The feedback from a customer in any of these\nsituations is only 'bandit feedback' - that is, a partial feedback based on\nwhether we chose to intervene or not. Typically randomized experiments are\ncarried out to understand whether an intervention is overall better than no\nintervention. Here we present a feature learning algorithm to learn from a\nrandomized experiment where the intervention in consideration is most effective\nand where it is least effective rather than only focusing on the overall\nimpact, thus adding a context to our learning mechanism and extract more\ninformation. From the randomized experiment, we learn the feature\nrepresentations which divide the population into subpopulations where we\nobserve statistically significant difference in average customer feedback\nbetween those who were subjected to the intervention and those who were not,\nwith a level of significance l, where l is a configurable parameter in our\nmodel. We use this information to derive the value of the intervention in\nconsideration for each instance in the population. With experiments, we show\nthat using this additional learning, in future interventions, the context for\neach instance could be leveraged to decide whether to intervene or not.\n", "versions": [{"version": "v1", "created": "Wed, 22 Aug 2018 21:26:06 GMT"}], "update_date": "2018-08-24", "authors_parsed": [["Mitra", "Abhimanyu", ""], ["Achan", "Kannan", ""], ["Kumar", "Sushant", ""]]}, {"id": "1808.07582", "submitter": "Xinyue Liu", "authors": "Xinyue Liu, Xiangnan Kong, Lei Liu, Kuorong Chiang", "title": "TreeGAN: Syntax-Aware Sequence Generation with Generative Adversarial\n  Networks", "comments": "IEEE International Conference on Data Mining (ICDM'18)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Generative Adversarial Networks (GANs) have shown great capacity on image\ngeneration, in which a discriminative model guides the training of a generative\nmodel to construct images that resemble real images. Recently, GANs have been\nextended from generating images to generating sequences (e.g., poems, music and\ncodes). Existing GANs on sequence generation mainly focus on general sequences,\nwhich are grammar-free. In many real-world applications, however, we need to\ngenerate sequences in a formal language with the constraint of its\ncorresponding grammar. For example, to test the performance of a database, one\nmay want to generate a collection of SQL queries, which are not only similar to\nthe queries of real users, but also follow the SQL syntax of the target\ndatabase. Generating such sequences is highly challenging because both the\ngenerator and discriminator of GANs need to consider the structure of the\nsequences and the given grammar in the formal language. To address these\nissues, we study the problem of syntax-aware sequence generation with GANs, in\nwhich a collection of real sequences and a set of pre-defined grammatical rules\nare given to both discriminator and generator. We propose a novel GAN\nframework, namely TreeGAN, to incorporate a given Context-Free Grammar (CFG)\ninto the sequence generation process. In TreeGAN, the generator employs a\nrecurrent neural network (RNN) to construct a parse tree. Each generated parse\ntree can then be translated to a valid sequence of the given grammar. The\ndiscriminator uses a tree-structured RNN to distinguish the generated trees\nfrom real trees. We show that TreeGAN can generate sequences for any CFG and\nits generation fully conforms with the given syntax. Experiments on synthetic\nand real data sets demonstrated that TreeGAN significantly improves the quality\nof the sequence generation in context-free languages.\n", "versions": [{"version": "v1", "created": "Wed, 22 Aug 2018 22:32:34 GMT"}], "update_date": "2018-08-24", "authors_parsed": [["Liu", "Xinyue", ""], ["Kong", "Xiangnan", ""], ["Liu", "Lei", ""], ["Chiang", "Kuorong", ""]]}, {"id": "1808.07621", "submitter": "Chenchen Li", "authors": "Chenchen Li, Xiang Yan, Xiaotie Deng, Yuan Qi, Wei Chu, Le Song,\n  Junlong Qiao, Jianshan He, Junwu Xiong", "title": "Latent Dirichlet Allocation for Internet Price War", "comments": "22 pages, 8 figures, Draft", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Internet market makers are always facing intense competitive environment,\nwhere personalized price reductions or discounted coupons are provided for\nattracting more customers. Participants in such a price war scenario have to\ninvest a lot to catch up with other competitors. However, such a huge cost of\nmoney may not always lead to an improvement of market share. This is mainly due\nto a lack of information about others' strategies or customers' willingness\nwhen participants develop their strategies.\n  In order to obtain this hidden information through observable data, we study\nthe relationship between companies and customers in the Internet price war.\nTheoretically, we provide a formalization of the problem as a stochastic game\nwith imperfect and incomplete information. Then we develop a variant of Latent\nDirichlet Allocation (LDA) to infer latent variables under the current market\nenvironment, which represents the preferences of customers and strategies of\ncompetitors. To our best knowledge, it is the first time that LDA is applied to\ngame scenario.\n  We conduct simulated experiments where our LDA model exhibits a significant\nimprovement on finding strategies in the Internet price war by including all\navailable market information of the market maker's competitors. And the model\nis applied to an open dataset for real business. Through comparisons on the\nlikelihood of prediction for users' behavior and distribution distance between\ninferred opponent's strategy and the real one, our model is shown to be able to\nprovide a better understanding for the market environment.\n  Our work marks a successful learning method to infer latent information in\nthe environment of price war by the LDA modeling, and sets an example for\nrelated competitive applications to follow.\n", "versions": [{"version": "v1", "created": "Thu, 23 Aug 2018 03:39:52 GMT"}], "update_date": "2018-08-24", "authors_parsed": [["Li", "Chenchen", ""], ["Yan", "Xiang", ""], ["Deng", "Xiaotie", ""], ["Qi", "Yuan", ""], ["Chu", "Wei", ""], ["Song", "Le", ""], ["Qiao", "Junlong", ""], ["He", "Jianshan", ""], ["Xiong", "Junwu", ""]]}, {"id": "1808.07624", "submitter": "Lingfei Wu", "authors": "Kun Xu, Lingfei Wu, Zhiguo Wang, Mo Yu, Liwei Chen, Vadim Sheinin", "title": "Exploiting Rich Syntactic Information for Semantic Parsing with\n  Graph-to-Sequence Model", "comments": "EMNLP'18", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing neural semantic parsers mainly utilize a sequence encoder, i.e., a\nsequential LSTM, to extract word order features while neglecting other valuable\nsyntactic information such as dependency graph or constituent trees. In this\npaper, we first propose to use the \\textit{syntactic graph} to represent three\ntypes of syntactic information, i.e., word order, dependency and constituency\nfeatures. We further employ a graph-to-sequence model to encode the syntactic\ngraph and decode a logical form. Experimental results on benchmark datasets\nshow that our model is comparable to the state-of-the-art on Jobs640, ATIS and\nGeo880. Experimental results on adversarial examples demonstrate the robustness\nof the model is also improved by encoding more syntactic information.\n", "versions": [{"version": "v1", "created": "Thu, 23 Aug 2018 03:58:21 GMT"}], "update_date": "2018-08-24", "authors_parsed": [["Xu", "Kun", ""], ["Wu", "Lingfei", ""], ["Wang", "Zhiguo", ""], ["Yu", "Mo", ""], ["Chen", "Liwei", ""], ["Sheinin", "Vadim", ""]]}, {"id": "1808.07645", "submitter": "Huang Hu", "authors": "Huang Hu, Xianchao Wu, Bingfeng Luo, Chongyang Tao, Can Xu, Wei Wu,\n  Zhan Chen", "title": "Playing 20 Question Game with Policy-Based Reinforcement Learning", "comments": "Accepted by EMNLP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The 20 Questions (Q20) game is a well known game which encourages deductive\nreasoning and creativity. In the game, the answerer first thinks of an object\nsuch as a famous person or a kind of animal. Then the questioner tries to guess\nthe object by asking 20 questions. In a Q20 game system, the user is considered\nas the answerer while the system itself acts as the questioner which requires a\ngood strategy of question selection to figure out the correct object and win\nthe game. However, the optimal policy of question selection is hard to be\nderived due to the complexity and volatility of the game environment. In this\npaper, we propose a novel policy-based Reinforcement Learning (RL) method,\nwhich enables the questioner agent to learn the optimal policy of question\nselection through continuous interactions with users. To facilitate training,\nwe also propose to use a reward network to estimate the more informative\nreward. Compared to previous methods, our RL method is robust to noisy answers\nand does not rely on the Knowledge Base of objects. Experimental results show\nthat our RL method clearly outperforms an entropy-based engineering system and\nhas competitive performance in a noisy-free simulation environment.\n", "versions": [{"version": "v1", "created": "Thu, 23 Aug 2018 06:34:32 GMT"}, {"version": "v2", "created": "Sun, 26 Aug 2018 09:47:54 GMT"}, {"version": "v3", "created": "Mon, 24 Jun 2019 06:28:09 GMT"}], "update_date": "2019-06-25", "authors_parsed": [["Hu", "Huang", ""], ["Wu", "Xianchao", ""], ["Luo", "Bingfeng", ""], ["Tao", "Chongyang", ""], ["Xu", "Can", ""], ["Wu", "Wei", ""], ["Chen", "Zhan", ""]]}, {"id": "1808.07647", "submitter": "Michele Polese", "authors": "Michele Polese, Rittwik Jana, Velin Kounev, Ke Zhang, Supratim Deb,\n  Michele Zorzi", "title": "Machine Learning at the Edge: A Data-Driven Architecture with\n  Applications to 5G Cellular Networks", "comments": "15 pages, 10 figures, 5 tables. IEEE Transactions on Mobile Computing", "journal-ref": null, "doi": "10.1109/TMC.2020.2999852", "report-no": null, "categories": "cs.NI cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The fifth generation of cellular networks (5G) will rely on edge cloud\ndeployments to satisfy the ultra-low latency demand of future applications. In\nthis paper, we argue that such deployments can also be used to enable advanced\ndata-driven and Machine Learning (ML) applications in mobile networks. We\npropose an edge-controller-based architecture for cellular networks and\nevaluate its performance with real data from hundreds of base stations of a\nmajor U.S. operator. In this regard, we will provide insights on how to\ndynamically cluster and associate base stations and controllers, according to\nthe global mobility patterns of the users. Then, we will describe how the\ncontrollers can be used to run ML algorithms to predict the number of users in\neach base station, and a use case in which these predictions are exploited by a\nhigher-layer application to route vehicular traffic according to network Key\nPerformance Indicators (KPIs). We show that the prediction accuracy improves\nwhen based on machine learning algorithms that rely on the controllers' view\nand, consequently, on the spatial correlation introduced by the user mobility,\nwith respect to when the prediction is based only on the local data of each\nsingle base station.\n", "versions": [{"version": "v1", "created": "Thu, 23 Aug 2018 07:06:41 GMT"}, {"version": "v2", "created": "Sun, 16 Dec 2018 00:17:48 GMT"}, {"version": "v3", "created": "Sun, 7 Apr 2019 16:07:50 GMT"}, {"version": "v4", "created": "Thu, 4 Jun 2020 15:33:19 GMT"}], "update_date": "2020-06-05", "authors_parsed": [["Polese", "Michele", ""], ["Jana", "Rittwik", ""], ["Kounev", "Velin", ""], ["Zhang", "Ke", ""], ["Deb", "Supratim", ""], ["Zorzi", "Michele", ""]]}, {"id": "1808.07658", "submitter": "Xipeng Qiu", "authors": "Junkun Chen and Kaiyu Chen and Xinchi Chen and Xipeng Qiu and Xuanjing\n  Huang", "title": "Exploring Shared Structures and Hierarchies for Multiple NLP Tasks", "comments": "8", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Designing shared neural architecture plays an important role in multi-task\nlearning. The challenge is that finding an optimal sharing scheme heavily\nrelies on the expert knowledge and is not scalable to a large number of diverse\ntasks. Inspired by the promising work of neural architecture search (NAS), we\napply reinforcement learning to automatically find possible shared architecture\nfor multi-task learning. Specifically, we use a controller to select from a set\nof shareable modules and assemble a task-specific architecture, and repeat the\nsame procedure for other tasks. The controller is trained with reinforcement\nlearning to maximize the expected accuracies for all tasks. We conduct\nextensive experiments on two types of tasks, text classification and sequence\nlabeling, which demonstrate the benefits of our approach.\n", "versions": [{"version": "v1", "created": "Thu, 23 Aug 2018 08:07:44 GMT"}], "update_date": "2018-08-24", "authors_parsed": [["Chen", "Junkun", ""], ["Chen", "Kaiyu", ""], ["Chen", "Xinchi", ""], ["Qiu", "Xipeng", ""], ["Huang", "Xuanjing", ""]]}, {"id": "1808.07712", "submitter": "Gurkirt Singh", "authors": "Gurkirt Singh and Suman Saha and Fabio Cuzzolin", "title": "Predicting Action Tubes", "comments": "ECCV workshop; Anticipating Human Behaviour 2018; 16 page 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we present a method to predict an entire `action tube' (a set\nof temporally linked bounding boxes) in a trimmed video just by observing a\nsmaller subset of it. Predicting where an action is going to take place in the\nnear future is essential to many computer vision based applications such as\nautonomous driving or surgical robotics. Importantly, it has to be done in\nreal-time and in an online fashion. We propose a Tube Prediction network\n(TPnet) which jointly predicts the past, present and future bounding boxes\nalong with their action classification scores. At test time TPnet is used in a\n(temporal) sliding window setting, and its predictions are put into a tube\nestimation framework to construct/predict the video long action tubes not only\nfor the observed part of the video but also for the unobserved part.\nAdditionally, the proposed action tube predictor helps in completing action\ntubes for unobserved segments of the video. We quantitatively demonstrate the\nlatter ability, and the fact that TPnet improves state-of-the-art detection\nperformance, on one of the standard action detection benchmarks - J-HMDB-21\ndataset.\n", "versions": [{"version": "v1", "created": "Thu, 23 Aug 2018 12:11:06 GMT"}], "update_date": "2018-08-24", "authors_parsed": [["Singh", "Gurkirt", ""], ["Saha", "Suman", ""], ["Cuzzolin", "Fabio", ""]]}, {"id": "1808.07724", "submitter": "Dimitri Kartsaklis", "authors": "Dimitri Kartsaklis, Mohammad Taher Pilehvar, Nigel Collier", "title": "Mapping Text to Knowledge Graph Entities using Multi-Sense LSTMs", "comments": "Accepted for presentation at EMNLP 2018 (main conference)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper addresses the problem of mapping natural language text to\nknowledge base entities. The mapping process is approached as a composition of\na phrase or a sentence into a point in a multi-dimensional entity space\nobtained from a knowledge graph. The compositional model is an LSTM equipped\nwith a dynamic disambiguation mechanism on the input word embeddings (a\nMulti-Sense LSTM), addressing polysemy issues. Further, the knowledge base\nspace is prepared by collecting random walks from a graph enhanced with textual\nfeatures, which act as a set of semantic bridges between text and knowledge\nbase entities. The ideas of this work are demonstrated on large-scale\ntext-to-entity mapping and entity classification tasks, with state of the art\nresults.\n", "versions": [{"version": "v1", "created": "Thu, 23 Aug 2018 12:47:01 GMT"}], "update_date": "2018-08-24", "authors_parsed": [["Kartsaklis", "Dimitri", ""], ["Pilehvar", "Mohammad Taher", ""], ["Collier", "Nigel", ""]]}, {"id": "1808.07739", "submitter": "Fabien C. Y. Benureau", "authors": "Fabien C. Y. Benureau and Pierre-Yves Oudeyer", "title": "Diversity-Driven Selection of Exploration Strategies in Multi-Armed\n  Bandits", "comments": null, "journal-ref": "2015 Joint IEEE International Conference on Development and\n  Learning and Epigenetic Robotics (ICDL-EpiRob), pp. 135-142", "doi": "10.1109/devlrn.2015.7346130", "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We consider a scenario where an agent has multiple available strategies to\nexplore an unknown environment. For each new interaction with the environment,\nthe agent must select which exploration strategy to use. We provide a new\nstrategy-agnostic method that treat the situation as a Multi-Armed Bandits\nproblem where the reward signal is the diversity of effects that each strategy\nproduces. We test the method empirically on a simulated planar robotic arm, and\nestablish that the method is both able discriminate between strategies of\ndissimilar quality, even when the differences are tenuous, and that the\nresulting performance is competitive with the best fixed mixture of strategies.\n", "versions": [{"version": "v1", "created": "Thu, 23 Aug 2018 13:24:17 GMT"}], "update_date": "2018-08-24", "authors_parsed": [["Benureau", "Fabien C. Y.", ""], ["Oudeyer", "Pierre-Yves", ""]]}, {"id": "1808.07804", "submitter": "Bradly Stadie", "authors": "S\\\"oren R. K\\\"unzel, Bradly C. Stadie, Nikita Vemuri, Varsha\n  Ramakrishnan, Jasjeet S. Sekhon, Pieter Abbeel", "title": "Transfer Learning for Estimating Causal Effects using Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop new algorithms for estimating heterogeneous treatment effects,\ncombining recent developments in transfer learning for neural networks with\ninsights from the causal inference literature. By taking advantage of transfer\nlearning, we are able to efficiently use different data sources that are\nrelated to the same underlying causal mechanisms. We compare our algorithms\nwith those in the extant literature using extensive simulation studies based on\nlarge-scale voter persuasion experiments and the MNIST database. Our methods\ncan perform an order of magnitude better than existing benchmarks while using a\nfraction of the data.\n", "versions": [{"version": "v1", "created": "Thu, 23 Aug 2018 15:27:14 GMT"}], "update_date": "2018-08-24", "authors_parsed": [["K\u00fcnzel", "S\u00f6ren R.", ""], ["Stadie", "Bradly C.", ""], ["Vemuri", "Nikita", ""], ["Ramakrishnan", "Varsha", ""], ["Sekhon", "Jasjeet S.", ""], ["Abbeel", "Pieter", ""]]}, {"id": "1808.07899", "submitter": "Barbara Grosz", "authors": "Barbara J. Grosz and Peter Stone", "title": "A Century Long Commitment to Assessing Artificial Intelligence and its\n  Impact on Society", "comments": "This paper will appear in Communications of the ACM (December 2018,\n  vol 61, no. 12)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In September 2016, Stanford's \"One Hundred Year Study on Artificial\nIntelligence\" project (AI100) issued the first report of its planned long-term\nperiodic assessment of artificial intelligence (AI) and its impact on society.\nThe report, entitled \"Artificial Intelligence and Life in 2030,\" examines eight\ndomains of typical urban settings on which AI is likely to have impact over the\ncoming years: transportation, home and service robots, healthcare, education,\npublic safety and security, low-resource communities, employment and workplace,\nand entertainment. It aims to provide the general public with a scientifically\nand technologically accurate portrayal of the current state of AI and its\npotential and to help guide decisions in industry and governments, as well as\nto inform research and development in the field. This article by the chair of\nthe 2016 Study Panel and the inaugural chair of the AI100 Standing Committee\ndescribes the origins of this ambitious longitudinal study, discusses the\nframing of the inaugural report, and presents the report's main findings. It\nconcludes with a brief description of the AI100 project's ongoing efforts and\nplanned next steps.\n", "versions": [{"version": "v1", "created": "Thu, 23 Aug 2018 18:38:26 GMT"}], "update_date": "2018-08-27", "authors_parsed": [["Grosz", "Barbara J.", ""], ["Stone", "Peter", ""]]}, {"id": "1808.07921", "submitter": "Ankush Desai", "authors": "Ankush Desai and Shromona Ghosh and Sanjit A. Seshia and Natarajan\n  Shankar and Ashish Tiwari", "title": "SOTER: A Runtime Assurance Framework for Programming Safe Robotics\n  Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.PL cs.SE cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recent drive towards achieving greater autonomy and intelligence in\nrobotics has led to high levels of complexity. Autonomous robots increasingly\ndepend on third party off-the-shelf components and complex machine-learning\ntechniques. This trend makes it challenging to provide strong design-time\ncertification of correct operation.\n  To address these challenges, we present SOTER, a robotics programming\nframework with two key components: (1) a programming language for implementing\nand testing high-level reactive robotics software and (2) an integrated runtime\nassurance (RTA) system that helps enable the use of uncertified components,\nwhile still providing safety guarantees. SOTER provides language primitives to\ndeclaratively construct a RTA module consisting of an advanced,\nhigh-performance controller (uncertified), a safe, lower-performance controller\n(certified), and the desired safety specification. The framework provides a\nformal guarantee that a well-formed RTA module always satisfies the safety\nspecification, without completely sacrificing performance by using higher\nperformance uncertified components whenever safe. SOTER allows the complex\nrobotics software stack to be constructed as a composition of RTA modules,\nwhere each uncertified component is protected using a RTA module.\n  To demonstrate the efficacy of our framework, we consider a real-world\ncase-study of building a safe drone surveillance system. Our experiments both\nin simulation and on actual drones show that the SOTER-enabled RTA ensures the\nsafety of the system, including when untrusted third-party components have bugs\nor deviate from the desired behavior.\n", "versions": [{"version": "v1", "created": "Thu, 23 Aug 2018 19:49:53 GMT"}, {"version": "v2", "created": "Mon, 11 Feb 2019 23:26:09 GMT"}, {"version": "v3", "created": "Fri, 19 Apr 2019 19:02:53 GMT"}], "update_date": "2019-04-23", "authors_parsed": [["Desai", "Ankush", ""], ["Ghosh", "Shromona", ""], ["Seshia", "Sanjit A.", ""], ["Shankar", "Natarajan", ""], ["Tiwari", "Ashish", ""]]}, {"id": "1808.07980", "submitter": "Thomas Lukasiewicz", "authors": "Patrick Hohenecker, Thomas Lukasiewicz", "title": "Ontology Reasoning with Deep Neural Networks", "comments": null, "journal-ref": "J. Artif. Intell. Res. 68:503-540 (2020)", "doi": "10.1613/jair.1.11661", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ability to conduct logical reasoning is a fundamental aspect of\nintelligent human behavior, and thus an important problem along the way to\nhuman-level artificial intelligence. Traditionally, logic-based symbolic\nmethods from the field of knowledge representation and reasoning have been used\nto equip agents with capabilities that resemble human logical reasoning\nqualities. More recently, however, there has been an increasing interest in\nusing machine learning rather than logic-based symbolic formalisms to tackle\nthese tasks. In this paper, we employ state-of-the-art methods for training\ndeep neural networks to devise a novel model that is able to learn how to\neffectively perform logical reasoning in the form of basic ontology reasoning.\nThis is an important and at the same time very natural logical reasoning task,\nwhich is why the presented approach is applicable to a plethora of important\nreal-world problems. We present the outcomes of several experiments, which show\nthat our model is able to learn to perform highly accurate ontology reasoning\non very large, diverse, and challenging benchmarks. Furthermore, it turned out\nthat the suggested approach suffers much less from different obstacles that\nprohibit logic-based symbolic reasoning, and, at the same time, is surprisingly\nplausible from a biological point of view.\n", "versions": [{"version": "v1", "created": "Fri, 24 Aug 2018 01:44:37 GMT"}, {"version": "v2", "created": "Tue, 4 Sep 2018 18:14:04 GMT"}, {"version": "v3", "created": "Mon, 10 Dec 2018 15:25:16 GMT"}, {"version": "v4", "created": "Fri, 8 Jan 2021 12:35:36 GMT"}], "update_date": "2021-01-11", "authors_parsed": [["Hohenecker", "Patrick", ""], ["Lukasiewicz", "Thomas", ""]]}, {"id": "1808.08003", "submitter": "Wenhu Chen", "authors": "Wenhu Chen, Guanlin Li, Shujie Liu, Zhirui Zhang, Mu Li, Ming Zhou", "title": "Approximate Distribution Matching for Sequence-to-Sequence Learning", "comments": "9 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sequence-to-Sequence models were introduced to tackle many real-life problems\nlike machine translation, summarization, image captioning, etc. The standard\noptimization algorithms are mainly based on example-to-example matching like\nmaximum likelihood estimation, which is known to suffer from data sparsity\nproblem. Here we present an alternate view to explain sequence-to-sequence\nlearning as a distribution matching problem, where each source or target\nexample is viewed to represent a local latent distribution in the source or\ntarget domain. Then, we interpret sequence-to-sequence learning as learning a\ntransductive model to transform the source local latent distributions to match\ntheir corresponding target distributions. In our framework, we approximate both\nthe source and target latent distributions with recurrent neural networks\n(augmenter). During training, the parallel augmenters learn to better\napproximate the local latent distributions, while the sequence prediction model\nlearns to minimize the KL-divergence of the transformed source distributions\nand the approximated target distributions. This algorithm can alleviate the\ndata sparsity issues in sequence learning by locally augmenting more unseen\ndata pairs and increasing the model's robustness. Experiments conducted on\nmachine translation and image captioning consistently demonstrate the\nsuperiority of our proposed algorithm over the other competing algorithms.\n", "versions": [{"version": "v1", "created": "Fri, 24 Aug 2018 05:00:17 GMT"}, {"version": "v2", "created": "Tue, 28 Aug 2018 05:09:44 GMT"}, {"version": "v3", "created": "Sun, 2 Sep 2018 04:38:56 GMT"}], "update_date": "2018-09-05", "authors_parsed": [["Chen", "Wenhu", ""], ["Li", "Guanlin", ""], ["Liu", "Shujie", ""], ["Zhang", "Zhirui", ""], ["Li", "Mu", ""], ["Zhou", "Ming", ""]]}, {"id": "1808.08079", "submitter": "Dieuwke Hupkes", "authors": "Mario Giulianelli, Jack Harding, Florian Mohnert, Dieuwke Hupkes,\n  Willem Zuidema", "title": "Under the Hood: Using Diagnostic Classifiers to Investigate and Improve\n  how Language Models Track Agreement Information", "comments": "to appear at the EMNLP workshop \"Analyzing and interpreting neural\n  networks for NLP\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  How do neural language models keep track of number agreement between subject\nand verb? We show that `diagnostic classifiers', trained to predict number from\nthe internal states of a language model, provide a detailed understanding of\nhow, when, and where this information is represented. Moreover, they give us\ninsight into when and where number information is corrupted in cases where the\nlanguage model ends up making agreement errors. To demonstrate the causal role\nplayed by the representations we find, we then use agreement information to\ninfluence the course of the LSTM during the processing of difficult sentences.\nResults from such an intervention reveal a large increase in the language\nmodel's accuracy. Together, these results show that diagnostic classifiers give\nus an unrivalled detailed look into the representation of linguistic\ninformation in neural models, and demonstrate that this knowledge can be used\nto improve their performance.\n", "versions": [{"version": "v1", "created": "Fri, 24 Aug 2018 10:29:45 GMT"}, {"version": "v2", "created": "Fri, 7 Sep 2018 13:51:39 GMT"}], "update_date": "2018-09-10", "authors_parsed": [["Giulianelli", "Mario", ""], ["Harding", "Jack", ""], ["Mohnert", "Florian", ""], ["Hupkes", "Dieuwke", ""], ["Zuidema", "Willem", ""]]}, {"id": "1808.08157", "submitter": "Claudio Pinhanez", "authors": "Claudio S. Pinhanez, Heloisa Candello, Mauro C. Pichiliani, Marisa\n  Vasconcelos, Melina Guerra, Ma\\'ira G. de Bayser, Paulo Cavalin", "title": "Different but Equal: Comparing User Collaboration with Digital Personal\n  Assistants vs. Teams of Expert Agents", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work compares user collaboration with conversational personal assistants\nvs. teams of expert chatbots. Two studies were performed to investigate whether\neach approach affects accomplishment of tasks and collaboration costs.\nParticipants interacted with two equivalent financial advice chatbot systems,\none composed of a single conversational adviser and the other based on a team\nof four experts chatbots. Results indicated that users had different forms of\nexperiences but were equally able to achieve their goals. Contrary to the\nexpected, there were evidences that in the teamwork situation that users were\nmore able to predict agent behavior better and did not have an overhead to\nmaintain common ground, indicating similar collaboration costs. The results\npoint towards the feasibility of either of the two approaches for user\ncollaboration with conversational agents.\n", "versions": [{"version": "v1", "created": "Fri, 24 Aug 2018 14:28:04 GMT"}], "update_date": "2018-08-27", "authors_parsed": [["Pinhanez", "Claudio S.", ""], ["Candello", "Heloisa", ""], ["Pichiliani", "Mauro C.", ""], ["Vasconcelos", "Marisa", ""], ["Guerra", "Melina", ""], ["de Bayser", "Ma\u00edra G.", ""], ["Cavalin", "Paulo", ""]]}, {"id": "1808.08213", "submitter": "Arquimedes Canedo", "authors": "Jiang Wan, Blake S. Pollard, Sujit Rokka Chhetri, Palash Goyal,\n  Mohammad Abdullah Al Faruque, Arquimedes Canedo", "title": "Future Automation Engineering using Structural Graph Convolutional\n  Neural Networks", "comments": "ICCAD 2018", "journal-ref": null, "doi": "10.1145/3240765.3243477", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The digitalization of automation engineering generates large quantities of\nengineering data that is interlinked in knowledge graphs. Classifying and\nclustering subgraphs according to their functionality is useful to discover\nfunctionally equivalent engineering artifacts that exhibit different graph\nstructures. This paper presents a new graph learning algorithm designed to\nclassify engineering data artifacts -- represented in the form of graphs --\naccording to their structure and neighborhood features. Our Structural Graph\nConvolutional Neural Network (SGCNN) is capable of learning graphs and\nsubgraphs with a novel graph invariant convolution kernel and\ndownsampling/pooling algorithm. On a realistic engineering-related dataset, we\nshow that SGCNN is capable of achieving ~91% classification accuracy.\n", "versions": [{"version": "v1", "created": "Fri, 24 Aug 2018 17:07:05 GMT"}], "update_date": "2018-08-27", "authors_parsed": [["Wan", "Jiang", ""], ["Pollard", "Blake S.", ""], ["Chhetri", "Sujit Rokka", ""], ["Goyal", "Palash", ""], ["Faruque", "Mohammad Abdullah Al", ""], ["Canedo", "Arquimedes", ""]]}, {"id": "1808.08256", "submitter": "Siddharth Karamcheti", "authors": "Siddharth Karamcheti, Gideon Mann, and David Rosenberg", "title": "Adaptive Grey-Box Fuzz-Testing with Thompson Sampling", "comments": "Published as a workshop paper in the 11th ACM Workshop on Artificial\n  Intelligence and Security (AISec '18) with the 25th ACM Conference on\n  Computer and Communications Security (CCS '18)", "journal-ref": null, "doi": "10.1145/3270101.3270108", "report-no": null, "categories": "cs.AI cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fuzz testing, or \"fuzzing,\" refers to a widely deployed class of techniques\nfor testing programs by generating a set of inputs for the express purpose of\nfinding bugs and identifying security flaws. Grey-box fuzzing, the most popular\nfuzzing strategy, combines light program instrumentation with a data driven\nprocess to generate new program inputs. In this work, we present a machine\nlearning approach that builds on AFL, the preeminent grey-box fuzzer, by\nadaptively learning a probability distribution over its mutation operators on a\nprogram-specific basis. These operators, which are selected uniformly at random\nin AFL and mutational fuzzers in general, dictate how new inputs are generated,\na core part of the fuzzer's efficacy. Our main contributions are two-fold:\nFirst, we show that a sampling distribution over mutation operators estimated\nfrom training programs can significantly improve performance of AFL. Second, we\nintroduce a Thompson Sampling, bandit-based optimization approach that\nfine-tunes the mutator distribution adaptively, during the course of fuzzing an\nindividual program. A set of experiments across complex programs demonstrates\nthat tuning the mutational operator distribution generates sets of inputs that\nyield significantly higher code coverage and finds more crashes faster and more\nreliably than both baseline versions of AFL as well as other AFL-based learning\napproaches.\n", "versions": [{"version": "v1", "created": "Fri, 24 Aug 2018 18:22:46 GMT"}], "update_date": "2018-08-28", "authors_parsed": [["Karamcheti", "Siddharth", ""], ["Mann", "Gideon", ""], ["Rosenberg", "David", ""]]}, {"id": "1808.08282", "submitter": "Mahdieh Abbasi", "authors": "Mahdieh Abbasi, Arezoo Rajabi, Azadeh Sadat Mozafari, Rakesh B. Bobba,\n  Christian Gagne", "title": "Controlling Over-generalization and its Effect on Adversarial Examples\n  Generation and Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional Neural Networks (CNNs) significantly improve the\nstate-of-the-art for many applications, especially in computer vision. However,\nCNNs still suffer from a tendency to confidently classify out-distribution\nsamples from unknown classes into pre-defined known classes. Further, they are\nalso vulnerable to adversarial examples. We are relating these two issues\nthrough the tendency of CNNs to over-generalize for areas of the input space\nnot covered well by the training set. We show that a CNN augmented with an\nextra output class can act as a simple yet effective end-to-end model for\ncontrolling over-generalization. As an appropriate training set for the extra\nclass, we introduce two resources that are computationally efficient to obtain:\na representative natural out-distribution set and interpolated in-distribution\nsamples. To help select a representative natural out-distribution set among\navailable ones, we propose a simple measurement to assess an out-distribution\nset's fitness. We also demonstrate that training such an augmented CNN with\nrepresentative out-distribution natural datasets and some interpolated samples\nallows it to better handle a wide range of unseen out-distribution samples and\nblack-box adversarial examples without training it on any adversaries. Finally,\nwe show that generation of white-box adversarial attacks using our proposed\naugmented CNN can become harder, as the attack algorithms have to get around\nthe rejection regions when generating actual adversaries.\n", "versions": [{"version": "v1", "created": "Tue, 21 Aug 2018 02:05:57 GMT"}, {"version": "v2", "created": "Wed, 3 Oct 2018 22:43:58 GMT"}], "update_date": "2018-10-05", "authors_parsed": [["Abbasi", "Mahdieh", ""], ["Rajabi", "Arezoo", ""], ["Mozafari", "Azadeh Sadat", ""], ["Bobba", "Rakesh B.", ""], ["Gagne", "Christian", ""]]}, {"id": "1808.08296", "submitter": "Xiaoxiao Li", "authors": "Xiaoxiao Li, Nicha C. Dvornek, Juntang Zhuang, Pamela Ventola and\n  James S. Duncan", "title": "Brain Biomarker Interpretation in ASD Using Deep Learning and fMRI", "comments": "8 pagers, accepted by MICCAI 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Autism spectrum disorder (ASD) is a complex neurodevelopmental disorder.\nFinding the biomarkers associated with ASD is extremely helpful to understand\nthe underlying roots of the disorder and can lead to earlier diagnosis and more\ntargeted treatment. Although Deep Neural Networks (DNNs) have been applied in\nfunctional magnetic resonance imaging (fMRI) to identify ASD, understanding the\ndata-driven computational decision making procedure has not been previously\nexplored. Therefore, in this work, we address the problem of interpreting\nreliable biomarkers associated with identifying ASD; specifically, we propose a\n2-stage method that classifies ASD and control subjects using fMRI images and\ninterprets the saliency features activated by the classifier. First, we trained\nan accurate DNN classifier. Then, for detecting the biomarkers, different from\nthe DNN visualization works in computer vision, we take advantage of the\nanatomical structure of brain fMRI and develop a frequency-normalized sampling\nmethod to corrupt images. Furthermore, in the ASD vs. control subjects\nclassification scenario, we provide a new approach to detect and characterize\nimportant brain features into three categories. The biomarkers we found by the\nproposed method are robust and consistent with previous findings in the\nliterature. We also validate the detected biomarkers by neurological function\ndecoding and comparing with the DNN activation maps.\n", "versions": [{"version": "v1", "created": "Thu, 23 Aug 2018 06:24:56 GMT"}], "update_date": "2018-08-28", "authors_parsed": [["Li", "Xiaoxiao", ""], ["Dvornek", "Nicha C.", ""], ["Zhuang", "Juntang", ""], ["Ventola", "Pamela", ""], ["Duncan", "James S.", ""]]}, {"id": "1808.08319", "submitter": "Tomas Hodan", "authors": "Tomas Hodan, Frank Michel, Eric Brachmann, Wadim Kehl, Anders Glent\n  Buch, Dirk Kraft, Bertram Drost, Joel Vidal, Stephan Ihrke, Xenophon Zabulis,\n  Caner Sahin, Fabian Manhardt, Federico Tombari, Tae-Kyun Kim, Jiri Matas,\n  Carsten Rother", "title": "BOP: Benchmark for 6D Object Pose Estimation", "comments": "ECCV 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a benchmark for 6D pose estimation of a rigid object from a single\nRGB-D input image. The training data consists of a texture-mapped 3D object\nmodel or images of the object in known 6D poses. The benchmark comprises of: i)\neight datasets in a unified format that cover different practical scenarios,\nincluding two new datasets focusing on varying lighting conditions, ii) an\nevaluation methodology with a pose-error function that deals with pose\nambiguities, iii) a comprehensive evaluation of 15 diverse recent methods that\ncaptures the status quo of the field, and iv) an online evaluation system that\nis open for continuous submission of new results. The evaluation shows that\nmethods based on point-pair features currently perform best, outperforming\ntemplate matching methods, learning-based methods and methods based on 3D local\nfeatures. The project website is available at bop.felk.cvut.cz.\n", "versions": [{"version": "v1", "created": "Fri, 24 Aug 2018 21:38:53 GMT"}], "update_date": "2018-08-28", "authors_parsed": [["Hodan", "Tomas", ""], ["Michel", "Frank", ""], ["Brachmann", "Eric", ""], ["Kehl", "Wadim", ""], ["Buch", "Anders Glent", ""], ["Kraft", "Dirk", ""], ["Drost", "Bertram", ""], ["Vidal", "Joel", ""], ["Ihrke", "Stephan", ""], ["Zabulis", "Xenophon", ""], ["Sahin", "Caner", ""], ["Manhardt", "Fabian", ""], ["Tombari", "Federico", ""], ["Kim", "Tae-Kyun", ""], ["Matas", "Jiri", ""], ["Rother", "Carsten", ""]]}, {"id": "1808.08433", "submitter": "Pascal Hitzler", "authors": "Pascal Hitzler, Adila Krisnadhi", "title": "A Tutorial on Modular Ontology Modeling with Ontology Design Patterns:\n  The Cooking Recipes Ontology", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide a detailed example for modular ontology modeling based on ontology\ndesign patterns.\n", "versions": [{"version": "v1", "created": "Sat, 25 Aug 2018 14:36:00 GMT"}], "update_date": "2018-08-28", "authors_parsed": [["Hitzler", "Pascal", ""], ["Krisnadhi", "Adila", ""]]}, {"id": "1808.08441", "submitter": "Mark Law", "authors": "Mark Law, Alessandra Russo and Krysia Broda", "title": "Inductive Learning of Answer Set Programs from Noisy Examples", "comments": "To appear in Advances in Cognitive Systems", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, non-monotonic Inductive Logic Programming has received\ngrowing interest. Specifically, several new learning frameworks and algorithms\nhave been introduced for learning under the answer set semantics, allowing the\nlearning of common-sense knowledge involving defaults and exceptions, which are\nessential aspects of human reasoning. In this paper, we present a\nnoise-tolerant generalisation of the learning from answer sets framework. We\nevaluate our ILASP3 system, both on synthetic and on real datasets, represented\nin the new framework. In particular, we show that on many of the datasets\nILASP3 achieves a higher accuracy than other ILP systems that have previously\nbeen applied to the datasets, including a recently proposed differentiable\nlearning framework.\n", "versions": [{"version": "v1", "created": "Sat, 25 Aug 2018 15:30:17 GMT"}], "update_date": "2018-08-28", "authors_parsed": [["Law", "Mark", ""], ["Russo", "Alessandra", ""], ["Broda", "Krysia", ""]]}, {"id": "1808.08447", "submitter": "Chie Hieida", "authors": "Chie Hieida, Takato Horii and Takayuki Nagai", "title": "Deep Emotion: A Computational Model of Emotion Using Deep Neural\n  Networks", "comments": "29 pages, 14 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Emotions are very important for human intelligence. For example, emotions are\nclosely related to the appraisal of the internal bodily state and external\nstimuli. This helps us to respond quickly to the environment. Another important\nperspective in human intelligence is the role of emotions in decision-making.\nMoreover, the social aspect of emotions is also very important. Therefore, if\nthe mechanism of emotions were elucidated, we could advance toward the\nessential understanding of our natural intelligence. In this study, a model of\nemotions is proposed to elucidate the mechanism of emotions through the\ncomputational model. Furthermore, from the viewpoint of partner robots, the\nmodel of emotions may help us to build robots that can have empathy for humans.\nTo understand and sympathize with people's feelings, the robots need to have\ntheir own emotions. This may allow robots to be accepted in human society. The\nproposed model is implemented using deep neural networks consisting of three\nmodules, which interact with each other. Simulation results reveal that the\nproposed model exhibits reasonable behavior as the basic mechanism of emotion.\n", "versions": [{"version": "v1", "created": "Sat, 25 Aug 2018 16:33:08 GMT"}], "update_date": "2018-08-28", "authors_parsed": [["Hieida", "Chie", ""], ["Horii", "Takato", ""], ["Nagai", "Takayuki", ""]]}, {"id": "1808.08497", "submitter": "Qibing Li", "authors": "Xiaolin Zheng, Mengying Zhu, Qibing Li, Chaochao Chen, Yanchao Tan", "title": "FinBrain: When Finance Meets AI 2.0", "comments": "11 pages", "journal-ref": "Frontiers of Information Technology & Electronic Engineering 2018", "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Artificial intelligence (AI) is the core technology of technological\nrevolution and industrial transformation. As one of the new intelligent needs\nin the AI 2.0 era, financial intelligence has elicited much attention from the\nacademia and industry. In our current dynamic capital market, financial\nintelligence demonstrates a fast and accurate machine learning capability to\nhandle complex data and has gradually acquired the potential to become a\n\"financial brain\". In this work, we survey existing studies on financial\nintelligence. First, we describe the concept of financial intelligence and\nelaborate on its position in the financial technology field. Second, we\nintroduce the development of financial intelligence and review state-of-the-art\ntechniques in wealth management, risk management, financial security, financial\nconsulting, and blockchain. Finally, we propose a research framework called\nFinBrain and summarize four open issues, namely, explainable financial agents\nand causality, perception and prediction under uncertainty, risk-sensitive and\nrobust decision making, and multi-agent game and mechanism design. We believe\nthat these research directions can lay the foundation for the development of AI\n2.0 in the finance field.\n", "versions": [{"version": "v1", "created": "Sun, 26 Aug 2018 03:12:50 GMT"}], "update_date": "2018-08-28", "authors_parsed": [["Zheng", "Xiaolin", ""], ["Zhu", "Mengying", ""], ["Li", "Qibing", ""], ["Chen", "Chaochao", ""], ["Tan", "Yanchao", ""]]}, {"id": "1808.08517", "submitter": "Mahardhika Pratama Dr", "authors": "Mahardhika Pratama, Witold Pedrycz, Geoffrey I. Webb", "title": "An Incremental Construction of Deep Neuro Fuzzy System for Continual\n  Learning of Non-stationary Data Streams", "comments": "This paper has been published in IEEE Transactions on Fuzzy Systems", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.NE", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Existing FNNs are mostly developed under a shallow network configuration\nhaving lower generalization power than those of deep structures. This paper\nproposes a novel self-organizing deep FNN, namely DEVFNN. Fuzzy rules can be\nautomatically extracted from data streams or removed if they play limited role\nduring their lifespan. The structure of the network can be deepened on demand\nby stacking additional layers using a drift detection method which not only\ndetects the covariate drift, variations of input space, but also accurately\nidentifies the real drift, dynamic changes of both feature space and target\nspace. DEVFNN is developed under the stacked generalization principle via the\nfeature augmentation concept where a recently developed algorithm, namely\ngClass, drives the hidden layer. It is equipped by an automatic feature\nselection method which controls activation and deactivation of input attributes\nto induce varying subsets of input features. A deep network simplification\nprocedure is put forward using the concept of hidden layer merging to prevent\nuncontrollable growth of dimensionality of input space due to the nature of\nfeature augmentation approach in building a deep network structure. DEVFNN\nworks in the sample-wise fashion and is compatible for data stream\napplications. The efficacy of DEVFNN has been thoroughly evaluated using seven\ndatasets with non-stationary properties under the prequential test-then-train\nprotocol. It has been compared with four popular continual learning algorithms\nand its shallow counterpart where DEVFNN demonstrates improvement of\nclassification accuracy. Moreover, it is also shown that the concept drift\ndetection method is an effective tool to control the depth of network structure\nwhile the hidden layer merging scenario is capable of simplifying the network\ncomplexity of a deep network with negligible compromise of generalization\nperformance.\n", "versions": [{"version": "v1", "created": "Sun, 26 Aug 2018 08:10:13 GMT"}, {"version": "v2", "created": "Mon, 9 Dec 2019 03:14:33 GMT"}], "update_date": "2019-12-10", "authors_parsed": [["Pratama", "Mahardhika", ""], ["Pedrycz", "Witold", ""], ["Webb", "Geoffrey I.", ""]]}, {"id": "1808.08531", "submitter": "Dongyu Liu", "authors": "Dongyu Liu, Weiwei Cui, Kai Jin, Yuxiao Guo, Huamin Qu", "title": "DeepTracker: Visualizing the Training Process of Convolutional Neural\n  Networks", "comments": "Published at ACM Transactions on Intelligent Systems and Technology\n  (in press)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep convolutional neural networks (CNNs) have achieved remarkable success in\nvarious fields. However, training an excellent CNN is practically a\ntrial-and-error process that consumes a tremendous amount of time and computer\nresources. To accelerate the training process and reduce the number of trials,\nexperts need to understand what has occurred in the training process and why\nthe resulting CNN behaves as such. However, current popular training platforms,\nsuch as TensorFlow, only provide very little and general information, such as\ntraining/validation errors, which is far from enough to serve this purpose. To\nbridge this gap and help domain experts with their training tasks in a\npractical environment, we propose a visual analytics system, DeepTracker, to\nfacilitate the exploration of the rich dynamics of CNN training processes and\nto identify the unusual patterns that are hidden behind the huge amount of\ntraining log. Specifically,we combine a hierarchical index mechanism and a set\nof hierarchical small multiples to help experts explore the entire training log\nfrom different levels of detail. We also introduce a novel cube-style\nvisualization to reveal the complex correlations among multiple types of\nheterogeneous training data including neuron weights, validation images, and\ntraining iterations. Three case studies are conducted to demonstrate how\nDeepTracker provides its users with valuable knowledge in an industry-level CNN\ntraining process, namely in our case, training ResNet-50 on the ImageNet\ndataset. We show that our method can be easily applied to other\nstate-of-the-art \"very deep\" CNN models.\n", "versions": [{"version": "v1", "created": "Sun, 26 Aug 2018 11:09:44 GMT"}], "update_date": "2018-08-28", "authors_parsed": [["Liu", "Dongyu", ""], ["Cui", "Weiwei", ""], ["Jin", "Kai", ""], ["Guo", "Yuxiao", ""], ["Qu", "Huamin", ""]]}, {"id": "1808.08578", "submitter": "Jinming Duan", "authors": "Jinming Duan, Ghalib Bello, Jo Schlemper, Wenjia Bai, Timothy J W\n  Dawes, Carlo Biffi, Antonio de Marvao, Georgia Doumou, Declan P O'Regan,\n  Daniel Rueckert", "title": "Automatic 3D bi-ventricular segmentation of cardiac images by a\n  shape-refined multi-task deep learning approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning approaches have achieved state-of-the-art performance in\ncardiac magnetic resonance (CMR) image segmentation. However, most approaches\nhave focused on learning image intensity features for segmentation, whereas the\nincorporation of anatomical shape priors has received less attention. In this\npaper, we combine a multi-task deep learning approach with atlas propagation to\ndevelop a shape-constrained bi-ventricular segmentation pipeline for short-axis\nCMR volumetric images. The pipeline first employs a fully convolutional network\n(FCN) that learns segmentation and landmark localisation tasks simultaneously.\nThe architecture of the proposed FCN uses a 2.5D representation, thus combining\nthe computational advantage of 2D FCNs networks and the capability of\naddressing 3D spatial consistency without compromising segmentation accuracy.\nMoreover, the refinement step is designed to explicitly enforce a shape\nconstraint and improve segmentation quality. This step is effective for\novercoming image artefacts (e.g. due to different breath-hold positions and\nlarge slice thickness), which preclude the creation of anatomically meaningful\n3D cardiac shapes. The proposed pipeline is fully automated, due to network's\nability to infer landmarks, which are then used downstream in the pipeline to\ninitialise atlas propagation. We validate the pipeline on 1831 healthy subjects\nand 649 subjects with pulmonary hypertension. Extensive numerical experiments\non the two datasets demonstrate that our proposed method is robust and capable\nof producing accurate, high-resolution and anatomically smooth bi-ventricular\n3D models, despite the artefacts in input CMR volumes.\n", "versions": [{"version": "v1", "created": "Sun, 26 Aug 2018 15:42:50 GMT"}, {"version": "v2", "created": "Tue, 28 Aug 2018 13:18:46 GMT"}, {"version": "v3", "created": "Sat, 13 Jul 2019 19:39:39 GMT"}], "update_date": "2019-07-16", "authors_parsed": [["Duan", "Jinming", ""], ["Bello", "Ghalib", ""], ["Schlemper", "Jo", ""], ["Bai", "Wenjia", ""], ["Dawes", "Timothy J W", ""], ["Biffi", "Carlo", ""], ["de Marvao", "Antonio", ""], ["Doumou", "Georgia", ""], ["O'Regan", "Declan P", ""], ["Rueckert", "Daniel", ""]]}, {"id": "1808.08609", "submitter": "Pasquale Minervini", "authors": "Pasquale Minervini, Sebastian Riedel", "title": "Adversarially Regularising Neural NLI Models to Integrate Logical\n  Background Knowledge", "comments": "Accepted at the SIGNLL Conference on Computational Natural Language\n  Learning (CoNLL 2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial examples are inputs to machine learning models designed to cause\nthe model to make a mistake. They are useful for understanding the shortcomings\nof machine learning models, interpreting their results, and for regularisation.\nIn NLP, however, most example generation strategies produce input text by using\nknown, pre-specified semantic transformations, requiring significant manual\neffort and in-depth understanding of the problem and domain. In this paper, we\ninvestigate the problem of automatically generating adversarial examples that\nviolate a set of given First-Order Logic constraints in Natural Language\nInference (NLI). We reduce the problem of identifying such adversarial examples\nto a combinatorial optimisation problem, by maximising a quantity measuring the\ndegree of violation of such constraints and by using a language model for\ngenerating linguistically-plausible examples. Furthermore, we propose a method\nfor adversarially regularising neural NLI models for incorporating background\nknowledge. Our results show that, while the proposed method does not always\nimprove results on the SNLI and MultiNLI datasets, it significantly and\nconsistently increases the predictive accuracy on adversarially-crafted\ndatasets -- up to a 79.6% relative improvement -- while drastically reducing\nthe number of background knowledge violations. Furthermore, we show that\nadversarial examples transfer among model architectures, and that the proposed\nadversarial training procedure improves the robustness of NLI models to\nadversarial examples.\n", "versions": [{"version": "v1", "created": "Sun, 26 Aug 2018 18:36:20 GMT"}], "update_date": "2018-08-28", "authors_parsed": [["Minervini", "Pasquale", ""], ["Riedel", "Sebastian", ""]]}, {"id": "1808.08617", "submitter": "Nalin Jayaweera", "authors": "Nalin Jayaweera, Nandana Rajatheva and Matti Latva-aho", "title": "Autonomous Driving without a Burden: View from Outside with Elevated\n  LiDAR", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The current autonomous driving architecture places a heavy burden in signal\nprocessing for the graphics processing units (GPUs) in the car. This directly\ntranslates into battery drain and lower energy efficiency, crucial factors in\nelectric vehicles. This is due to the high bit rate of the captured video and\nother sensing inputs, mainly due to Light Detection and Ranging (LiDAR) sensor\nat the top of the car which is an essential feature in autonomous vehicles.\nLiDAR is needed to obtain a high precision map for the vehicle AI to make\nrelevant decisions. However, this is still a quite restricted view from the\ncar. This is the same even in the case of cars without a LiDAR such as Tesla.\nThe existing LiDARs and the cameras have limited horizontal and vertical fields\nof visions. In all cases it can be argued that precision is lower, given the\nsmaller map generated. This also results in the accumulation of a large amount\nof data in the order of several TBs in a day, the storage of which becomes\nchallenging. If we are to reduce the effort for the processing units inside the\ncar, we need to uplink the data to edge or an appropriately placed cloud.\nHowever, the required data rates in the order of several Gbps are difficult to\nbe met even with the advent of 5G. Therefore, we propose to have a coordinated\nset of LiDAR's outside at an elevation which can provide an integrated view\nwith a much larger field of vision (FoV) to a centralized decision making body\nwhich then sends the required control actions to the vehicles with a lower bit\nrate in the downlink and with the required latency. The calculations we have\nbased on industry standard equipment from several manufacturers show that this\nis not just a concept but a feasible system which can be implemented.The\nproposed system can play a supportive role with existing autonomous vehicle\narchitecture and it is easily applicable in an urban area.\n", "versions": [{"version": "v1", "created": "Sun, 26 Aug 2018 20:20:37 GMT"}, {"version": "v2", "created": "Wed, 31 Oct 2018 18:07:40 GMT"}], "update_date": "2018-11-02", "authors_parsed": [["Jayaweera", "Nalin", ""], ["Rajatheva", "Nandana", ""], ["Latva-aho", "Matti", ""]]}, {"id": "1808.08702", "submitter": "Joon-Hyuk Chang", "authors": "Moa Lee and Joon Hyuk Chang", "title": "Augmenting Bottleneck Features of Deep Neural Network Employing Motor\n  State for Speech Recognition at Humanoid Robots", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.AI eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As for the humanoid robots, the internal noise, which is generated by motors,\nfans and mechanical components when the robot is moving or shaking its body,\nseverely degrades the performance of the speech recognition accuracy. In this\npaper, a novel speech recognition system robust to ego-noise for humanoid\nrobots is proposed, in which on/off state of the motor is employed as auxiliary\ninformation for finding the relevant input features. For this, we consider the\nbottleneck features, which have been successfully applied to deep neural\nnetwork (DNN) based automatic speech recognition (ASR) system. When learning\nthe bottleneck features to catch, we first exploit the motor on/off state data\nas supplementary information in addition to the acoustic features as the input\nof the first deep neural network (DNN) for preliminary acoustic modeling. Then,\nthe second DNN for primary acoustic modeling employs both the bottleneck\nfeatures tossed from the first DNN and the acoustics features. When the\nproposed method is evaluated in terms of phoneme error rate (PER) on TIMIT\ndatabase, the experimental results show that achieve obvious improvement (11%\nrelative) is achieved by our algorithm over the conventional systems.\n", "versions": [{"version": "v1", "created": "Mon, 27 Aug 2018 06:41:47 GMT"}], "update_date": "2018-08-28", "authors_parsed": [["Lee", "Moa", ""], ["Chang", "Joon Hyuk", ""]]}, {"id": "1808.08703", "submitter": "Afroz Ahamad Siddiqui", "authors": "Afroz Ahamad", "title": "Generating Text through Adversarial Training using Skip-Thought Vectors", "comments": "NAACL 2019: https://www.aclweb.org/anthology/N19-3008", "journal-ref": "\"Proceedings of the 2019 Conference of the North {A}merican\n  Chapter of the Association for Computational Linguistics: Student Research\n  Workshop, Jun 2019, Pages 53-60\"", "doi": "10.18653/v1/N19-3008", "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  GANs have been shown to perform exceedingly well on tasks pertaining to image\ngeneration and style transfer. In the field of language modelling, word\nembeddings such as GLoVe and word2vec are state-of-the-art methods for applying\nneural network models on textual data. Attempts have been made to utilize GANs\nwith word embeddings for text generation. This study presents an approach to\ntext generation using Skip-Thought sentence embeddings with GANs based on\ngradient penalty functions and f-measures. The proposed architecture aims to\nreproduce writing style in the generated text by modelling the way of\nexpression at a sentence level across all the works of an author. Extensive\nexperiments were run in different embedding settings on a variety of tasks\nincluding conditional text generation and language generation. The model\noutperforms baseline text generation networks across several automated\nevaluation metrics like BLEU-n, METEOR and ROUGE. Further, wide applicability\nand effectiveness in real life tasks are demonstrated through human judgement\nscores.\n", "versions": [{"version": "v1", "created": "Mon, 27 Aug 2018 06:51:07 GMT"}, {"version": "v2", "created": "Tue, 13 Nov 2018 21:37:36 GMT"}, {"version": "v3", "created": "Sat, 16 May 2020 10:18:53 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Ahamad", "Afroz", ""]]}, {"id": "1808.08720", "submitter": "Thomas Demeester", "authors": "Thomas Demeester, Johannes Deleu, Fr\\'ederic Godin, Chris Develder", "title": "Predefined Sparseness in Recurrent Sequence Models", "comments": "the SIGNLL Conference on Computational Natural Language Learning\n  (CoNLL, 2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inducing sparseness while training neural networks has been shown to yield\nmodels with a lower memory footprint but similar effectiveness to dense models.\nHowever, sparseness is typically induced starting from a dense model, and thus\nthis advantage does not hold during training. We propose techniques to enforce\nsparseness upfront in recurrent sequence models for NLP applications, to also\nbenefit training. First, in language modeling, we show how to increase hidden\nstate sizes in recurrent layers without increasing the number of parameters,\nleading to more expressive models. Second, for sequence labeling, we show that\nword embeddings with predefined sparseness lead to similar performance as dense\nembeddings, at a fraction of the number of trainable parameters.\n", "versions": [{"version": "v1", "created": "Mon, 27 Aug 2018 07:55:41 GMT"}], "update_date": "2018-08-28", "authors_parsed": [["Demeester", "Thomas", ""], ["Deleu", "Johannes", ""], ["Godin", "Fr\u00e9deric", ""], ["Develder", "Chris", ""]]}, {"id": "1808.08750", "submitter": "Robert Geirhos", "authors": "Robert Geirhos, Carlos R. Medina Temme, Jonas Rauber, Heiko H.\n  Sch\\\"utt, Matthias Bethge, Felix A. Wichmann", "title": "Generalisation in humans and deep neural networks", "comments": "Added optimal probability aggregation method to appendix", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We compare the robustness of humans and current convolutional deep neural\nnetworks (DNNs) on object recognition under twelve different types of image\ndegradations. First, using three well known DNNs (ResNet-152, VGG-19,\nGoogLeNet) we find the human visual system to be more robust to nearly all of\nthe tested image manipulations, and we observe progressively diverging\nclassification error-patterns between humans and DNNs when the signal gets\nweaker. Secondly, we show that DNNs trained directly on distorted images\nconsistently surpass human performance on the exact distortion types they were\ntrained on, yet they display extremely poor generalisation abilities when\ntested on other distortion types. For example, training on salt-and-pepper\nnoise does not imply robustness on uniform white noise and vice versa. Thus,\nchanges in the noise distribution between training and testing constitutes a\ncrucial challenge to deep learning vision systems that can be systematically\naddressed in a lifelong machine learning approach. Our new dataset consisting\nof 83K carefully measured human psychophysical trials provide a useful\nreference for lifelong robustness against image degradations set by the human\nvisual system.\n", "versions": [{"version": "v1", "created": "Mon, 27 Aug 2018 09:17:57 GMT"}, {"version": "v2", "created": "Fri, 21 Dec 2018 16:26:58 GMT"}, {"version": "v3", "created": "Fri, 23 Oct 2020 09:05:30 GMT"}], "update_date": "2020-10-26", "authors_parsed": [["Geirhos", "Robert", ""], ["Temme", "Carlos R. Medina", ""], ["Rauber", "Jonas", ""], ["Sch\u00fctt", "Heiko H.", ""], ["Bethge", "Matthias", ""], ["Wichmann", "Felix A.", ""]]}, {"id": "1808.08754", "submitter": "Ren Yang", "authors": "Jiaxin Lu, Mai Xu, Ren Yang, Zulin Wang", "title": "What Makes Natural Scene Memorable?", "comments": "Accepted to ACM MM Workshops", "journal-ref": "Proceedings of the 2018 Workshop on Understanding Subjective\n  Attributes of Data, with the Focus on Evoked Emotions", "doi": "10.1145/3267799.3267802", "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent studies on image memorability have shed light on the visual features\nthat make generic images, object images or face photographs memorable. However,\na clear understanding and reliable estimation of natural scene memorability\nremain elusive. In this paper, we provide an attempt to answer: \"what exactly\nmakes natural scene memorable\". Specifically, we first build LNSIM, a\nlarge-scale natural scene image memorability database (containing 2,632 images\nand memorability annotations). Then, we mine our database to investigate how\nlow-, middle- and high-level handcrafted features affect the memorability of\nnatural scene. In particular, we find that high-level feature of scene category\nis rather correlated with natural scene memorability. Thus, we propose a deep\nneural network based natural scene memorability (DeepNSM) predictor, which\ntakes advantage of scene category. Finally, the experimental results validate\nthe effectiveness of DeepNSM.\n", "versions": [{"version": "v1", "created": "Mon, 27 Aug 2018 09:38:16 GMT"}], "update_date": "2019-08-16", "authors_parsed": [["Lu", "Jiaxin", ""], ["Xu", "Mai", ""], ["Yang", "Ren", ""], ["Wang", "Zulin", ""]]}, {"id": "1808.08773", "submitter": "Pratik Jawanpuria", "authors": "Pratik Jawanpuria, Arjun Balgovind, Anoop Kunchukuttan, Bamdev Mishra", "title": "Learning Multilingual Word Embeddings in Latent Metric Space: A\n  Geometric Approach", "comments": "Accepted in Transactions of the Association for Computational\n  Linguistics", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel geometric approach for learning bilingual mappings given\nmonolingual embeddings and a bilingual dictionary. Our approach decouples\nlearning the transformation from the source language to the target language\ninto (a) learning rotations for language-specific embeddings to align them to a\ncommon space, and (b) learning a similarity metric in the common space to model\nsimilarities between the embeddings. We model the bilingual mapping problem as\nan optimization problem on smooth Riemannian manifolds. We show that our\napproach outperforms previous approaches on the bilingual lexicon induction and\ncross-lingual word similarity tasks. We also generalize our framework to\nrepresent multiple languages in a common latent space. In particular, the\nlatent space representations for several languages are learned jointly, given\nbilingual dictionaries for multiple language pairs. We illustrate the\neffectiveness of joint learning for multiple languages in zero-shot word\ntranslation setting. Our implementation is available at\nhttps://github.com/anoopkunchukuttan/geomm .\n", "versions": [{"version": "v1", "created": "Mon, 27 Aug 2018 10:37:16 GMT"}, {"version": "v2", "created": "Tue, 28 Aug 2018 17:30:39 GMT"}, {"version": "v3", "created": "Tue, 18 Dec 2018 09:48:26 GMT"}], "update_date": "2018-12-19", "authors_parsed": [["Jawanpuria", "Pratik", ""], ["Balgovind", "Arjun", ""], ["Kunchukuttan", "Anoop", ""], ["Mishra", "Bamdev", ""]]}, {"id": "1808.08777", "submitter": "Takumi Ichimura", "authors": "Shin Kamada, Takumi Ichimura, Toshihide Harada", "title": "Adaptive Structural Learning of Deep Belief Network for Medical\n  Examination Data and Its Knowledge Extraction by using C4.5", "comments": "8 pages, 7 figures, The First IEEE International Conference on\n  Artificial Intelligence and Knowledge Engineering (AIKE2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Learning has a hierarchical network architecture to represent the\ncomplicated feature of input patterns. The adaptive structural learning method\nof Deep Belief Network (DBN) has been developed. The method can discover an\noptimal number of hidden neurons for given input data in a Restricted Boltzmann\nMachine (RBM) by neuron generation-annihilation algorithm, and generate a new\nhidden layer in DBN by the extension of the algorithm. In this paper, the\nproposed adaptive structural learning of DBN was applied to the comprehensive\nmedical examination data for the cancer prediction. The prediction system shows\nhigher classification accuracy (99.8% for training and 95.5% for test) than the\ntraditional DBN. Moreover, the explicit knowledge with respect to the relation\nbetween input and output patterns was extracted from the trained DBN network by\nC4.5. Some characteristics extracted in the form of IF-THEN rules to find an\ninitial cancer at the early stage were reported in this paper.\n", "versions": [{"version": "v1", "created": "Mon, 27 Aug 2018 10:47:31 GMT"}], "update_date": "2018-08-28", "authors_parsed": [["Kamada", "Shin", ""], ["Ichimura", "Takumi", ""], ["Harada", "Toshihide", ""]]}, {"id": "1808.08794", "submitter": "Juliao Braga", "authors": "Juliao Braga, Joao Nuno Silva, Patricia Takako Endo, Nizam Omar", "title": "Theoretical Foundations of the A2RD Project: Part I", "comments": "9 pages", "journal-ref": null, "doi": "10.13140/RG.2.2.22156.97923", "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This article identifies and discusses the theoretical foundations that were\nconsidered in the design of the A2RD model. In addition to the points\nconsidered, references are made to the studies available and considered in the\napproach.\n", "versions": [{"version": "v1", "created": "Mon, 27 Aug 2018 11:46:13 GMT"}, {"version": "v2", "created": "Wed, 29 Aug 2018 02:48:14 GMT"}, {"version": "v3", "created": "Thu, 30 Aug 2018 15:23:53 GMT"}], "update_date": "2018-08-31", "authors_parsed": [["Braga", "Juliao", ""], ["Silva", "Joao Nuno", ""], ["Endo", "Patricia Takako", ""], ["Omar", "Nizam", ""]]}, {"id": "1808.08858", "submitter": "Stefanos Angelidis", "authors": "Stefanos Angelidis, Mirella Lapata", "title": "Summarizing Opinions: Aspect Extraction Meets Sentiment Prediction and\n  They Are Both Weakly Supervised", "comments": "In EMNLP 2018 (long paper). For supplementary material, see\n  http://stangelid.github.io/supplemental.pdf", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a neural framework for opinion summarization from online product\nreviews which is knowledge-lean and only requires light supervision (e.g., in\nthe form of product domain labels and user-provided ratings). Our method\ncombines two weakly supervised components to identify salient opinions and form\nextractive summaries from multiple reviews: an aspect extractor trained under a\nmulti-task objective, and a sentiment predictor based on multiple instance\nlearning. We introduce an opinion summarization dataset that includes a\ntraining set of product reviews from six diverse domains and human-annotated\ndevelopment and test sets with gold standard aspect annotations, salience\nlabels, and opinion summaries. Automatic evaluation shows significant\nimprovements over baselines, and a large-scale study indicates that our opinion\nsummaries are preferred by human judges according to multiple criteria.\n", "versions": [{"version": "v1", "created": "Mon, 27 Aug 2018 14:17:08 GMT"}], "update_date": "2018-08-28", "authors_parsed": [["Angelidis", "Stefanos", ""], ["Lapata", "Mirella", ""]]}, {"id": "1808.08866", "submitter": "Lijun Wu", "authors": "Lijun Wu, Fei Tian, Tao Qin, Jianhuang Lai and Tie-Yan Liu", "title": "A Study of Reinforcement Learning for Neural Machine Translation", "comments": "EMNLP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent studies have shown that reinforcement learning (RL) is an effective\napproach for improving the performance of neural machine translation (NMT)\nsystem. However, due to its instability, successfully RL training is\nchallenging, especially in real-world systems where deep models and large\ndatasets are leveraged. In this paper, taking several large-scale translation\ntasks as testbeds, we conduct a systematic study on how to train better NMT\nmodels using reinforcement learning. We provide a comprehensive comparison of\nseveral important factors (e.g., baseline reward, reward shaping) in RL\ntraining. Furthermore, to fill in the gap that it remains unclear whether RL is\nstill beneficial when monolingual data is used, we propose a new method to\nleverage RL to further boost the performance of NMT systems trained with\nsource/target monolingual data. By integrating all our findings, we obtain\ncompetitive results on WMT14 English- German, WMT17 English-Chinese, and WMT17\nChinese-English translation tasks, especially setting a state-of-the-art\nperformance on WMT17 Chinese-English translation task.\n", "versions": [{"version": "v1", "created": "Mon, 27 Aug 2018 14:43:38 GMT"}], "update_date": "2018-08-28", "authors_parsed": [["Wu", "Lijun", ""], ["Tian", "Fei", ""], ["Qin", "Tao", ""], ["Lai", "Jianhuang", ""], ["Liu", "Tie-Yan", ""]]}, {"id": "1808.08871", "submitter": "Wei Chen", "authors": "Wei Chen and Mark Fuge", "title": "B\\'ezierGAN: Automatic Generation of Smooth Curves from Interpretable\n  Low-Dimensional Parameters", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many real-world objects are designed by smooth curves, especially in the\ndomain of aerospace and ship, where aerodynamic shapes (e.g., airfoils) and\nhydrodynamic shapes (e.g., hulls) are designed. To facilitate the design\nprocess of those objects, we propose a deep learning based generative model\nthat can synthesize smooth curves. The model maps a low-dimensional latent\nrepresentation to a sequence of discrete points sampled from a rational\nB\\'ezier curve. We demonstrate the performance of our method in completing both\nsynthetic and real-world generative tasks. Results show that our method can\ngenerate diverse and realistic curves, while preserving consistent shape\nvariation in the latent space, which is favorable for latent space design\noptimization or design space exploration.\n", "versions": [{"version": "v1", "created": "Mon, 27 Aug 2018 14:57:17 GMT"}, {"version": "v2", "created": "Tue, 5 Jan 2021 03:36:06 GMT"}], "update_date": "2021-01-06", "authors_parsed": [["Chen", "Wei", ""], ["Fuge", "Mark", ""]]}, {"id": "1808.08888", "submitter": "Dan-Bo Zhang Dr.", "authors": "Dan-Bo Zhang, Zheng-Yuan Xue, Shi-Liang Zhu, and Z. D. Wang", "title": "Realizing quantum linear regression with auxiliary qumodes", "comments": "7 pages, 2 figures. Add implementation with trapped ions", "journal-ref": "Phys. Rev. A 99, 012331 (2019)", "doi": "10.1103/PhysRevA.99.012331", "report-no": null, "categories": "quant-ph cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In order to exploit quantum advantages, quantum algorithms are indispensable\nfor operating machine learning with quantum computers. We here propose an\nintriguing hybrid approach of quantum information processing for quantum linear\nregression, which utilizes both discrete and continuous quantum variables, in\ncontrast to existing wisdoms based solely upon discrete qubits. In our\nframework, data information is encoded in a qubit system, while information\nprocessing is tackled using auxiliary continuous qumodes via qubit-qumode\ninteractions. Moreover, it is also elaborated that finite squeezing is quite\nhelpful for efficiently running the quantum algorithms in realistic setup.\nComparing with an all-qubit approach, the present hybrid approach is more\nefficient and feasible for implementing quantum algorithms, still retaining\nexponential quantum speed-up.\n", "versions": [{"version": "v1", "created": "Mon, 27 Aug 2018 15:36:33 GMT"}, {"version": "v2", "created": "Tue, 22 Jan 2019 06:28:27 GMT"}], "update_date": "2019-01-23", "authors_parsed": [["Zhang", "Dan-Bo", ""], ["Xue", "Zheng-Yuan", ""], ["Zhu", "Shi-Liang", ""], ["Wang", "Z. D.", ""]]}, {"id": "1808.08941", "submitter": "Stephan Baier", "authors": "Stephan Baier, Yunpu Ma, Volker Tresp", "title": "Improving Information Extraction from Images with Learned Semantic\n  Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many applications require an understanding of an image that goes beyond the\nsimple detection and classification of its objects. In particular, a great deal\nof semantic information is carried in the relationships between objects. We\nhave previously shown that the combination of a visual model and a statistical\nsemantic prior model can improve on the task of mapping images to their\nassociated scene description. In this paper, we review the model and compare it\nto a novel conditional multi-way model for visual relationship detection, which\ndoes not include an explicitly trained visual prior model. We also discuss\npotential relationships between the proposed methods and memory models of the\nhuman brain.\n", "versions": [{"version": "v1", "created": "Mon, 27 Aug 2018 17:39:56 GMT"}], "update_date": "2018-08-28", "authors_parsed": [["Baier", "Stephan", ""], ["Ma", "Yunpu", ""], ["Tresp", "Volker", ""]]}, {"id": "1808.08951", "submitter": "Xuchao Zhang", "authors": "Bingsheng Wang, Xuchao Zhang, Chang-Tien Lu, Feng Chen", "title": "Water Disaggregation via Shape Features based Bayesian Discriminative\n  Sparse Coding", "comments": "20 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As the issue of freshwater shortage is increasing daily, it is critical to\ntake effective measures for water conservation. According to previous studies,\ndevice level consumption could lead to significant freshwater conservation.\nExisting water disaggregation methods focus on learning the signatures for\nappliances; however, they are lack of the mechanism to accurately discriminate\nparallel appliances' consumption. In this paper, we propose a Bayesian\nDiscriminative Sparse Coding model using Laplace Prior (BDSC-LP) to extensively\nenhance the disaggregation performance. To derive discriminative basis\nfunctions, shape features are presented to describe the low-sampling-rate water\nconsumption patterns. A Gibbs sampling based inference method is designed to\nextend the discriminative capability of the disaggregation dictionaries.\nExtensive experiments were performed to validate the effectiveness of the\nproposed model using both real-world and synthetic datasets.\n", "versions": [{"version": "v1", "created": "Sun, 26 Aug 2018 16:01:11 GMT"}], "update_date": "2018-08-29", "authors_parsed": [["Wang", "Bingsheng", ""], ["Zhang", "Xuchao", ""], ["Lu", "Chang-Tien", ""], ["Chen", "Feng", ""]]}, {"id": "1808.08953", "submitter": "Jonathan Mamou", "authors": "Jonathan Mamou, Oren Pereg, Moshe Wasserblat, Alon Eirew, Yael Green,\n  Shira Guskin, Peter Izsak, Daniel Korat", "title": "Term Set Expansion based NLP Architect by Intel AI Lab", "comments": "EMNLP 2018 System Demonstrations. arXiv admin note: substantial text\n  overlap with arXiv:1807.10104", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present SetExpander, a corpus-based system for expanding a seed set of\nterms into amore complete set of terms that belong to the same semantic class.\nSetExpander implements an iterative end-to-end workflow. It enables users to\neasily select a seed set of terms, expand it, view the expanded set, validate\nit, re-expand the validated set and store it, thus simplifying the extraction\nof domain-specific fine-grained semantic classes.SetExpander has been used\nsuccessfully in real-life use cases including integration into an automated\nrecruitment system and an issues and defects resolution system. A video demo of\nSetExpander is available at\nhttps://drive.google.com/open?id=1e545bB87Autsch36DjnJHmq3HWfSd1Rv (some images\nwere blurred for privacy reasons)\n", "versions": [{"version": "v1", "created": "Mon, 27 Aug 2018 12:19:07 GMT"}, {"version": "v2", "created": "Mon, 15 Oct 2018 10:55:24 GMT"}], "update_date": "2018-10-17", "authors_parsed": [["Mamou", "Jonathan", ""], ["Pereg", "Oren", ""], ["Wasserblat", "Moshe", ""], ["Eirew", "Alon", ""], ["Green", "Yael", ""], ["Guskin", "Shira", ""], ["Izsak", "Peter", ""], ["Korat", "Daniel", ""]]}, {"id": "1808.08954", "submitter": "Blake Hannaford", "authors": "Blake Hannaford and Randall Bly and Ian Humphreys and Mark Whipple", "title": "Behavior Trees as a Representation for Medical Procedures", "comments": "We are pleased to acknowledge support from National Science\n  Foundation grant #IIS-1637444. arXiv admin note: text overlap with\n  arXiv:1801.07864", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Objective: Effective collaboration between machines and clinicians requires\nflexible data structures to represent medical processes and clinical practice\nguidelines. Such a data structure could enable effective turn-taking between\nhuman and automated components of a complex treatment, accurate on-line\nmonitoring of clinical treatments (for example to detect medical errors), or\nautomated treatment systems (such as future medical robots) whose overall\ntreatment plan is understandable and auditable by human experts.\n  Materials and Methods: Behavior trees (BTs) emerged from video game\ndevelopment as a graphical language for modeling intelligent agent behavior.\nBTs have several properties which are attractive for modeling medical\nprocedures including human-readability, authoring tools, and composability.\n  Results: This paper will illustrate construction of BTs for exemplary medical\nprocedures and clinical protocols.\n  Discussion and Conclusion: Behavior Trees thus form a useful, and human\nauthorable/readable bridge between clinical practice guidelines and AI systems.\n", "versions": [{"version": "v1", "created": "Mon, 27 Aug 2018 16:56:53 GMT"}], "update_date": "2018-08-29", "authors_parsed": [["Hannaford", "Blake", ""], ["Bly", "Randall", ""], ["Humphreys", "Ian", ""], ["Whipple", "Mark", ""]]}, {"id": "1808.09016", "submitter": "Xianshan Qu", "authors": "Xianshan Qu, Xiaopeng Li, John R. Rose", "title": "Review Helpfulness Assessment based on Convolutional Neural Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we describe the implementation of a convolutional neural\nnetwork (CNN) used to assess online review helpfulness. To our knowledge, this\nis the first use of this architecture to address this problem. We explore the\nimpact of two related factors impacting CNN performance: different word\nembedding initializations and different input review lengths. We also propose\nan approach to combining rating star information with review text to further\nimprove prediction accuracy. We demonstrate that this can improve the overall\naccuracy by 2%. Finally, we evaluate the method on a benchmark dataset and show\nan improvement in accuracy relative to published results for traditional\nmethods of 2.5% for a model trained using only review text and 4.24% for a\nmodel trained on a combination of rating star information and review text.\n", "versions": [{"version": "v1", "created": "Mon, 27 Aug 2018 19:53:52 GMT"}], "update_date": "2018-08-29", "authors_parsed": [["Qu", "Xianshan", ""], ["Li", "Xiaopeng", ""], ["Rose", "John R.", ""]]}, {"id": "1808.09057", "submitter": "Ritesh Noothigattu", "authors": "Ritesh Noothigattu, Nihar B. Shah, Ariel D. Procaccia", "title": "Loss Functions, Axioms, and Peer Review", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.GT cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is common to see a handful of reviewers reject a highly novel paper,\nbecause they view, say, extensive experiments as far more important than\nnovelty, whereas the community as a whole would have embraced the paper. More\ngenerally, the disparate mapping of criteria scores to final recommendations by\ndifferent reviewers is a major source of inconsistency in peer review. In this\npaper we present a framework inspired by empirical risk minimization (ERM) for\nlearning the community's aggregate mapping. The key challenge that arises is\nthe specification of a loss function for ERM. We consider the class of $L(p,q)$\nloss functions, which is a matrix-extension of the standard class of $L_p$\nlosses on vectors; here the choice of the loss function amounts to choosing the\nhyperparameters $p, q \\in [1,\\infty]$. To deal with the absence of ground truth\nin our problem, we instead draw on computational social choice to identify\ndesirable values of the hyperparameters $p$ and $q$. Specifically, we\ncharacterize $p=q=1$ as the only choice of these hyperparameters that satisfies\nthree natural axiomatic properties. Finally, we implement and apply our\napproach to reviews from IJCAI 2017.\n", "versions": [{"version": "v1", "created": "Mon, 27 Aug 2018 23:02:18 GMT"}, {"version": "v2", "created": "Mon, 2 Mar 2020 08:15:48 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Noothigattu", "Ritesh", ""], ["Shah", "Nihar B.", ""], ["Procaccia", "Ariel D.", ""]]}, {"id": "1808.09062", "submitter": "Huayu Li", "authors": "Huayu Li", "title": "Cognitive Consistency Routing Algorithm of Capsule-network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Artificial Neural Networks (ANNs) are computational models inspired by the\ncentral nervous system (especially the brain) of animals and are used to\nestimate or generate unknown approximation functions relied on large amounts of\ninputs. Capsule Neural Network (Sabour S, et al.[2017]) is a novel structure of\nConvolutional Neural Networks which simulates the visual processing system of\nhuman brain. In this paper, we introduce psychological theories which called\nCognitive Consistency to optimize the routing algorithm of Capsnet to make it\nmore close to the work pattern of human brain. It has been shown in the\nexperiment that a progress had been made compared with the baseline.\n", "versions": [{"version": "v1", "created": "Mon, 27 Aug 2018 23:26:08 GMT"}, {"version": "v2", "created": "Mon, 10 Sep 2018 15:18:14 GMT"}, {"version": "v3", "created": "Wed, 19 Sep 2018 20:01:10 GMT"}], "update_date": "2018-09-21", "authors_parsed": [["Li", "Huayu", ""]]}, {"id": "1808.09079", "submitter": "Foaad Khosmood", "authors": "Gavin Scott and Foaad Khosmood", "title": "A Framework for Complementary Companion Character Behavior in Video\n  Games", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a game development framework capable of governing the behavior of\ncomplementary companions in a video game. A \"complementary\" action is\ncontrasted with a mimicking action and is defined as any action by a friendly\nnon-player character that furthers the player's strategy. This is determined\nthrough a combination of both player action and game state prediction processes\nwhile allowing the AI companion to experiment. We determine the location of\ninterest for companion actions based on a dynamic set of regions customized to\nthe individual player. A user study shows promising results; a majority of\nparticipants familiar with game design react positively to the companion\nbehavior, stating that they would consider using the frame-work in future games\nthemselves.\n", "versions": [{"version": "v1", "created": "Tue, 28 Aug 2018 01:12:33 GMT"}], "update_date": "2018-08-29", "authors_parsed": [["Scott", "Gavin", ""], ["Khosmood", "Foaad", ""]]}, {"id": "1808.09123", "submitter": "Sarah Tan", "authors": "Sarah Tan and Julius Adebayo and Kori Inkpen and Ece Kamar", "title": "Investigating Human + Machine Complementarity for Recidivism Predictions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When might human input help (or not) when assessing risk in fairness domains?\nDressel and Farid (2018) asked Mechanical Turk workers to evaluate a subset of\ndefendants in the ProPublica COMPAS data for risk of recidivism, and concluded\nthat COMPAS predictions were no more accurate or fair than predictions made by\nhumans. We delve deeper into this claim to explore differences in human and\nalgorithmic decision making. We construct a Human Risk Score based on the\npredictions made by multiple Turk workers, characterize the features that\ndetermine agreement and disagreement between COMPAS and Human Scores, and\nconstruct hybrid Human+Machine models to predict recidivism. Our key finding is\nthat on this data set, Human and COMPAS decision making differed, but not in\nways that could be leveraged to significantly improve ground-truth prediction.\nWe present the results of our analyses and suggestions for data collection best\npractices to leverage complementary strengths of human and machines in the\nfairness domain.\n", "versions": [{"version": "v1", "created": "Tue, 28 Aug 2018 05:28:35 GMT"}, {"version": "v2", "created": "Mon, 3 Dec 2018 07:11:32 GMT"}], "update_date": "2018-12-04", "authors_parsed": [["Tan", "Sarah", ""], ["Adebayo", "Julius", ""], ["Inkpen", "Kori", ""], ["Kamar", "Ece", ""]]}, {"id": "1808.09293", "submitter": "Juliao Braga", "authors": "Juliao Braga, Joao Nuno Silva, Patricia Takako Endo, Nizam Omar", "title": "A Summary Description of the A2RD Project", "comments": "arXiv admin note: text overlap with arXiv:1805.02241,\n  arXiv:1805.05250", "journal-ref": null, "doi": "10.13140/RG.2.2.33386.57281", "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper describes the Autonomous Architecture Over Restricted Domains\nproject. It begins with the description of the context upon which the project\nis focused, and in the sequence describes the project and implementation\nmodels. It finish by presenting the environment conceptual model, showing where\nstand the components, inputs and facilities required to interact among the\nintelligent agents of the various implementations in their respective and\nrestricted, routing domains (Autonomous Systems) which together make the\nInternet work.\n", "versions": [{"version": "v1", "created": "Sun, 26 Aug 2018 15:02:23 GMT"}, {"version": "v2", "created": "Wed, 29 Aug 2018 03:01:34 GMT"}, {"version": "v3", "created": "Thu, 6 Sep 2018 07:45:25 GMT"}], "update_date": "2018-09-10", "authors_parsed": [["Braga", "Juliao", ""], ["Silva", "Joao Nuno", ""], ["Endo", "Patricia Takako", ""], ["Omar", "Nizam", ""]]}, {"id": "1808.09333", "submitter": "Dongyeop Kang", "authors": "Dongyeop Kang, Tushar Khot, Ashish Sabharwal, Peter Clark", "title": "Bridging Knowledge Gaps in Neural Entailment via Symbolic Models", "comments": "EMNLP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most textual entailment models focus on lexical gaps between the premise text\nand the hypothesis, but rarely on knowledge gaps. We focus on filling these\nknowledge gaps in the Science Entailment task, by leveraging an external\nstructured knowledge base (KB) of science facts. Our new architecture combines\nstandard neural entailment models with a knowledge lookup module. To facilitate\nthis lookup, we propose a fact-level decomposition of the hypothesis, and\nverifying the resulting sub-facts against both the textual premise and the\nstructured KB. Our model, NSnet, learns to aggregate predictions from these\nheterogeneous data formats. On the SciTail dataset, NSnet outperforms a simpler\ncombination of the two predictions by 3% and the base entailment model by 5%.\n", "versions": [{"version": "v1", "created": "Tue, 28 Aug 2018 14:45:47 GMT"}, {"version": "v2", "created": "Tue, 4 Sep 2018 14:24:03 GMT"}], "update_date": "2018-09-05", "authors_parsed": [["Kang", "Dongyeop", ""], ["Khot", "Tushar", ""], ["Sabharwal", "Ashish", ""], ["Clark", "Peter", ""]]}, {"id": "1808.09384", "submitter": "Saku Sugawara", "authors": "Saku Sugawara, Kentaro Inui, Satoshi Sekine, Akiko Aizawa", "title": "What Makes Reading Comprehension Questions Easier?", "comments": "12 pages, EMNLP2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A challenge in creating a dataset for machine reading comprehension (MRC) is\nto collect questions that require a sophisticated understanding of language to\nanswer beyond using superficial cues. In this work, we investigate what makes\nquestions easier across recent 12 MRC datasets with three question styles\n(answer extraction, description, and multiple choice). We propose to employ\nsimple heuristics to split each dataset into easy and hard subsets and examine\nthe performance of two baseline models for each of the subsets. We then\nmanually annotate questions sampled from each subset with both validity and\nrequisite reasoning skills to investigate which skills explain the difference\nbetween easy and hard questions. From this study, we observed that (i) the\nbaseline performances for the hard subsets remarkably degrade compared to those\nof entire datasets, (ii) hard questions require knowledge inference and\nmultiple-sentence reasoning in comparison with easy questions, and (iii)\nmultiple-choice questions tend to require a broader range of reasoning skills\nthan answer extraction and description questions. These results suggest that\none might overestimate recent advances in MRC.\n", "versions": [{"version": "v1", "created": "Tue, 28 Aug 2018 16:17:43 GMT"}], "update_date": "2018-08-29", "authors_parsed": [["Sugawara", "Saku", ""], ["Inui", "Kentaro", ""], ["Sekine", "Satoshi", ""], ["Aizawa", "Akiko", ""]]}, {"id": "1808.09442", "submitter": "Yun-Nung Chen", "authors": "Shang-Yu Su and Xiujun Li and Jianfeng Gao and Jingjing Liu and\n  Yun-Nung Chen", "title": "Discriminative Deep Dyna-Q: Robust Planning for Dialogue Policy Learning", "comments": "11 pages, 10 figures, EMNLP 2018 long paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a Discriminative Deep Dyna-Q (D3Q) approach to improving\nthe effectiveness and robustness of Deep Dyna-Q (DDQ), a recently proposed\nframework that extends the Dyna-Q algorithm to integrate planning for\ntask-completion dialogue policy learning. To obviate DDQ's high dependency on\nthe quality of simulated experiences, we incorporate an RNN-based discriminator\nin D3Q to differentiate simulated experience from real user experience in order\nto control the quality of training data. Experiments show that D3Q\nsignificantly outperforms DDQ by controlling the quality of simulated\nexperience used for planning. The effectiveness and robustness of D3Q is\nfurther demonstrated in a domain extension setting, where the agent's\ncapability of adapting to a changing environment is tested.\n", "versions": [{"version": "v1", "created": "Tue, 28 Aug 2018 17:59:08 GMT"}, {"version": "v2", "created": "Thu, 6 Sep 2018 17:50:22 GMT"}], "update_date": "2018-09-07", "authors_parsed": [["Su", "Shang-Yu", ""], ["Li", "Xiujun", ""], ["Gao", "Jianfeng", ""], ["Liu", "Jingjing", ""], ["Chen", "Yun-Nung", ""]]}, {"id": "1808.09446", "submitter": "Bin Liu", "authors": "Bin Liu, Yaochu Jin", "title": "A Particle Filter based Multi-Objective Optimization Algorithm: PFOPS", "comments": "5 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper is concerned with a recently developed paradigm for\npopulation-based optimization, termed particle filter optimization (PFO). This\nparadigm is attractive in terms of coherence in theory and easiness in\nmathematical analysis and interpretation. Current PFO algorithms only work for\nsingle-objective optimization cases, while many real-life problems involve\nmultiple objectives to be optimized simultaneously. To this end, we make an\neffort to extend the scope of application of the PFO paradigm to\nmulti-objective optimization (MOO) cases. An idea called path sampling is\nadopted within the PFO scheme to balance the different objectives to be\noptimized. The resulting algorithm is thus termed PFO with Path Sampling\n(PFOPS). The validity of the presented algorithm is assessed based on three\nbenchmark MOO experiments, in which the shapes of the Pareto fronts are convex,\nconcave and discontinuous, respectively.\n", "versions": [{"version": "v1", "created": "Tue, 28 Aug 2018 08:30:12 GMT"}, {"version": "v2", "created": "Sun, 28 Oct 2018 08:33:54 GMT"}, {"version": "v3", "created": "Tue, 30 Oct 2018 03:37:19 GMT"}, {"version": "v4", "created": "Fri, 23 Nov 2018 03:08:30 GMT"}], "update_date": "2018-11-26", "authors_parsed": [["Liu", "Bin", ""], ["Jin", "Yaochu", ""]]}, {"id": "1808.09551", "submitter": "Fr\\'ederic Godin", "authors": "Fr\\'ederic Godin, Kris Demuynck, Joni Dambre, Wesley De Neve and\n  Thomas Demeester", "title": "Explaining Character-Aware Neural Networks for Word-Level Prediction: Do\n  They Discover Linguistic Rules?", "comments": "Accepted at EMNLP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Character-level features are currently used in different neural network-based\nnatural language processing algorithms. However, little is known about the\ncharacter-level patterns those models learn. Moreover, models are often\ncompared only quantitatively while a qualitative analysis is missing. In this\npaper, we investigate which character-level patterns neural networks learn and\nif those patterns coincide with manually-defined word segmentations and\nannotations. To that end, we extend the contextual decomposition technique\n(Murdoch et al. 2018) to convolutional neural networks which allows us to\ncompare convolutional neural networks and bidirectional long short-term memory\nnetworks. We evaluate and compare these models for the task of morphological\ntagging on three morphologically different languages and show that these models\nimplicitly discover understandable linguistic rules. Our implementation can be\nfound at https://github.com/FredericGodin/ContextualDecomposition-NLP .\n", "versions": [{"version": "v1", "created": "Tue, 28 Aug 2018 21:44:26 GMT"}], "update_date": "2018-08-30", "authors_parsed": [["Godin", "Fr\u00e9deric", ""], ["Demuynck", "Kris", ""], ["Dambre", "Joni", ""], ["De Neve", "Wesley", ""], ["Demeester", "Thomas", ""]]}, {"id": "1808.09563", "submitter": "Rogerio Bonatti", "authors": "Rogerio Bonatti, Yanfu Zhang, Sanjiban Choudhury, Wenshan Wang, and\n  Sebastian Scherer", "title": "Autonomous drone cinematographer: Using artistic principles to create\n  smooth, safe, occlusion-free trajectories for aerial filming", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Autonomous aerial cinematography has the potential to enable automatic\ncapture of aesthetically pleasing videos without requiring human intervention,\nempowering individuals with the capability of high-end film studios. Current\napproaches either only handle off-line trajectory generation, or offer\nstrategies that reason over short time horizons and simplistic representations\nfor obstacles, which result in jerky movement and low real-life applicability.\nIn this work we develop a method for aerial filming that is able to trade off\nshot smoothness, occlusion, and cinematography guidelines in a principled\nmanner, even under noisy actor predictions. We present a novel algorithm for\nreal-time covariant gradient descent that we use to efficiently find the\ndesired trajectories by optimizing a set of cost functions. Experimental\nresults show that our approach creates attractive shots, avoiding obstacles and\nocclusion 65 times over 1.25 hours of flight time, re-planning at 5 Hz with a\n10 s time horizon. We robustly film human actors, cars and bicycles performing\ndifferent motion among obstacles, using various shot types.\n", "versions": [{"version": "v1", "created": "Tue, 28 Aug 2018 22:28:20 GMT"}], "update_date": "2018-08-30", "authors_parsed": [["Bonatti", "Rogerio", ""], ["Zhang", "Yanfu", ""], ["Choudhury", "Sanjiban", ""], ["Wang", "Wenshan", ""], ["Scherer", "Sebastian", ""]]}, {"id": "1808.09572", "submitter": "Nicholas Waytowich", "authors": "Nicholas R. Waytowich, Vinicius G. Goecks, Vernon J. Lawhern", "title": "Cycle-of-Learning for Autonomous Systems from Human Interaction", "comments": "Presented at AI-HRI AAAI-FSS, 2018 (arXiv:1809.06606)", "journal-ref": null, "doi": null, "report-no": "AI-HRI/2018/05", "categories": "cs.AI cs.HC cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We discuss different types of human-robot interaction paradigms in the\ncontext of training end-to-end reinforcement learning algorithms. We provide a\ntaxonomy to categorize the types of human interaction and present our\nCycle-of-Learning framework for autonomous systems that combines different\nhuman-interaction modalities with reinforcement learning. Two key concepts\nprovided by our Cycle-of-Learning framework are how it handles the integration\nof the different human-interaction modalities (demonstration, intervention, and\nevaluation) and how to define the switching criteria between them.\n", "versions": [{"version": "v1", "created": "Tue, 28 Aug 2018 23:00:12 GMT"}, {"version": "v2", "created": "Tue, 9 Oct 2018 16:25:03 GMT"}], "update_date": "2018-10-30", "authors_parsed": [["Waytowich", "Nicholas R.", ""], ["Goecks", "Vinicius G.", ""], ["Lawhern", "Vernon J.", ""]]}, {"id": "1808.09633", "submitter": "Dinghan Shen", "authors": "Dinghan Shen, Xinyuan Zhang, Ricardo Henao, Lawrence Carin", "title": "Improved Semantic-Aware Network Embedding with Fine-Grained Word\n  Alignment", "comments": "To appear at EMNLP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Network embeddings, which learn low-dimensional representations for each\nvertex in a large-scale network, have received considerable attention in recent\nyears. For a wide range of applications, vertices in a network are typically\naccompanied by rich textual information such as user profiles, paper abstracts,\netc. We propose to incorporate semantic features into network embeddings by\nmatching important words between text sequences for all pairs of vertices. We\nintroduce a word-by-word alignment framework that measures the compatibility of\nembeddings between word pairs, and then adaptively accumulates these alignment\nfeatures with a simple yet effective aggregation function. In experiments, we\nevaluate the proposed framework on three real-world benchmarks for downstream\ntasks, including link prediction and multi-label vertex classification. Results\ndemonstrate that our model outperforms state-of-the-art network embedding\nmethods by a large margin.\n", "versions": [{"version": "v1", "created": "Wed, 29 Aug 2018 04:23:02 GMT"}], "update_date": "2018-08-30", "authors_parsed": [["Shen", "Dinghan", ""], ["Zhang", "Xinyuan", ""], ["Henao", "Ricardo", ""], ["Carin", "Lawrence", ""]]}, {"id": "1808.09648", "submitter": "Avikalp Srivastava", "authors": "Avikalp Srivastava, Hsin Wen Liu, Sumio Fujita", "title": "Adapting Visual Question Answering Models for Enhancing Multimodal\n  Community Q&A Platforms", "comments": "Submitted for review at CIKM 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Question categorization and expert retrieval methods have been crucial for\ninformation organization and accessibility in community question & answering\n(CQA) platforms. Research in this area, however, has dealt with only the text\nmodality. With the increasing multimodal nature of web content, we focus on\nextending these methods for CQA questions accompanied by images. Specifically,\nwe leverage the success of representation learning for text and images in the\nvisual question answering (VQA) domain, and adapt the underlying concept and\narchitecture for automated category classification and expert retrieval on\nimage-based questions posted on Yahoo! Chiebukuro, the Japanese counterpart of\nYahoo! Answers.\n  To the best of our knowledge, this is the first work to tackle the\nmultimodality challenge in CQA, and to adapt VQA models for tasks on a more\necologically valid source of visual questions. Our analysis of the differences\nbetween visual QA and community QA data drives our proposal of novel\naugmentations of an attention method tailored for CQA, and use of auxiliary\ntasks for learning better grounding features. Our final model markedly\noutperforms the text-only and VQA model baselines for both tasks of\nclassification and expert retrieval on real-world multimodal CQA data.\n", "versions": [{"version": "v1", "created": "Wed, 29 Aug 2018 05:53:17 GMT"}, {"version": "v2", "created": "Sat, 25 May 2019 20:24:44 GMT"}], "update_date": "2019-05-28", "authors_parsed": [["Srivastava", "Avikalp", ""], ["Liu", "Hsin Wen", ""], ["Fujita", "Sumio", ""]]}, {"id": "1808.09658", "submitter": "Yang Gao", "authors": "Yang Gao, Christian M. Meyer, Iryna Gurevych", "title": "APRIL: Interactively Learning to Summarise by Combining Active\n  Preference Learning and Reinforcement Learning", "comments": "EMNLP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a method to perform automatic document summarisation without using\nreference summaries. Instead, our method interactively learns from users'\npreferences. The merit of preference-based interactive summarisation is that\npreferences are easier for users to provide than reference summaries. Existing\npreference-based interactive learning methods suffer from high sample\ncomplexity, i.e. they need to interact with the oracle for many rounds in order\nto converge. In this work, we propose a new objective function, which enables\nus to leverage active learning, preference learning and reinforcement learning\ntechniques in order to reduce the sample complexity. Both simulation and\nreal-user experiments suggest that our method significantly advances the state\nof the art. Our source code is freely available at\nhttps://github.com/UKPLab/emnlp2018-april.\n", "versions": [{"version": "v1", "created": "Wed, 29 Aug 2018 06:49:49 GMT"}], "update_date": "2018-08-30", "authors_parsed": [["Gao", "Yang", ""], ["Meyer", "Christian M.", ""], ["Gurevych", "Iryna", ""]]}, {"id": "1808.09735", "submitter": "Yi-Ting Huang", "authors": "Yi-Ting Huang, Meng Chang Chen, and Yeali S. Sun", "title": "Bringing personalized learning into computer-aided question generation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a novel and statistical method of ability estimation\nbased on acquisition distribution for a personalized computer aided question\ngeneration. This method captures the learning outcomes over time and provides a\nflexible measurement based on the acquisition distributions instead of\nprecalibration. Compared to the previous studies, the proposed method is\nrobust, especially when an ability of a student is unknown. The results from\nthe empirical data show that the estimated abilities match the actual abilities\nof learners, and the pretest and post-test of the experimental group show\nsignificant improvement. These results suggest that this method can serves as\nthe ability estimation for a personalized computer-aided testing environment.\n", "versions": [{"version": "v1", "created": "Wed, 29 Aug 2018 11:31:53 GMT"}], "update_date": "2018-08-30", "authors_parsed": [["Huang", "Yi-Ting", ""], ["Chen", "Meng Chang", ""], ["Sun", "Yeali S.", ""]]}, {"id": "1808.09806", "submitter": "Mohamed Khamis Dr.", "authors": "Ahmed Fares, Walid Gomaa, Mohamed A. Khamis", "title": "MARL-FWC: Optimal Coordination of Freeway Traffic Control Measures", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SY cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The objective of this article is to optimize the overall traffic flow on\nfreeways using multiple ramp metering controls plus its complementary Dynamic\nSpeed Limits (DSLs). An optimal freeway operation can be reached when\nminimizing the difference between the freeway density and the critical ratio\nfor maximum traffic flow. In this article, a Multi-Agent Reinforcement Learning\nfor Freeways Control (MARL-FWC) system for ramps metering and DSLs is proposed.\nMARL-FWC introduces a new microscopic framework at the network level based on\ncollaborative Markov Decision Process modeling (Markov game) and an associated\ncooperative Q-learning algorithm. The technique incorporates payoff propagation\n(Max-Plus algorithm) under the coordination graphs framework, particularly\nsuited for optimal control purposes. MARL-FWC provides three control designs:\nfully independent, fully distributed, and centralized; suited for different\nnetwork architectures. MARL-FWC was extensively tested in order to assess the\nproposed model of the joint payoff, as well as the global payoff. Experiments\nare conducted with heavy traffic flow under the renowned VISSIM traffic\nsimulator to evaluate MARL-FWC. The experimental results show a significant\ndecrease in the total travel time and an increase in the average speed (when\ncompared with the base case) while maintaining an optimal traffic flow.\n", "versions": [{"version": "v1", "created": "Mon, 27 Aug 2018 08:28:20 GMT"}], "update_date": "2018-08-30", "authors_parsed": [["Fares", "Ahmed", ""], ["Gomaa", "Walid", ""], ["Khamis", "Mohamed A.", ""]]}, {"id": "1808.09809", "submitter": "Thibaut Vidal", "authors": "Mayra Albuquerque, Thibaut Vidal", "title": "An Efficient Matheuristic for the Minimum-Weight Dominating Set Problem", "comments": null, "journal-ref": null, "doi": "10.1016/j.asoc.2018.06.052", "report-no": null, "categories": "cs.AI cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A minimum dominating set in a graph is a minimum set of vertices such that\nevery vertex of the graph either belongs to it, or is adjacent to one vertex of\nthis set. This mathematical object is of high relevance in a number of\napplications related to social networks analysis, design of wireless networks,\ncoding theory, and data mining, among many others. When vertex weights are\ngiven, minimizing the total weight of the dominating set gives rise to a\nproblem variant known as the minimum weight dominating set problem. To solve\nthis problem, we introduce a hybrid matheuristic combining a tabu search with\nan integer programming solver. The latter is used to solve subproblems in which\nonly a fraction of the decision variables, selected relatively to the search\nhistory, are left free while the others are fixed. Moreover, we introduce an\nadaptive penalty to promote the exploration of intermediate infeasible\nsolutions during the search, enhance the algorithm with perturbations and node\nelimination procedures, and exploit richer neighborhood classes. Extensive\nexperimental analyses on a variety of instance classes demonstrate the good\nperformance of the algorithm, and the contribution of each component in the\nsuccess of the search is analyzed.\n", "versions": [{"version": "v1", "created": "Tue, 28 Aug 2018 17:13:17 GMT"}], "update_date": "2018-08-30", "authors_parsed": [["Albuquerque", "Mayra", ""], ["Vidal", "Thibaut", ""]]}, {"id": "1808.09819", "submitter": "Adrien Ali Taiga", "authors": "Adrien Ali Ta\\\"iga, Aaron Courville and Marc G. Bellemare", "title": "Approximate Exploration through State Abstraction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although exploration in reinforcement learning is well understood from a\ntheoretical point of view, provably correct methods remain impractical. In this\npaper we study the interplay between exploration and approximation, what we\ncall approximate exploration. Our main goal is to further our theoretical\nunderstanding of pseudo-count based exploration bonuses (Bellemare et al.,\n2016), a practical exploration scheme based on density modelling. As a warm-up,\nwe quantify the performance of an exploration algorithm, MBIE-EB (Strehl and\nLittman, 2008), when explicitly combined with state aggregation. This allows us\nto confirm that, as might be expected, approximation allows the agent to trade\noff between learning speed and quality of the learned policy. Next, we show how\na given density model can be related to an abstraction and that the\ncorresponding pseudo-count bonus can act as a substitute in MBIE-EB combined\nwith this abstraction, but may lead to either under- or over-exploration. Then,\nwe show that a given density model also defines an implicit abstraction, and\nfind a surprising mismatch between pseudo-counts derived either implicitly or\nexplicitly. Finally we derive a new pseudo-count bonus alleviating this issue.\n", "versions": [{"version": "v1", "created": "Wed, 29 Aug 2018 13:41:33 GMT"}, {"version": "v2", "created": "Thu, 24 Jan 2019 17:18:53 GMT"}], "update_date": "2019-01-25", "authors_parsed": [["Ta\u00efga", "Adrien Ali", ""], ["Courville", "Aaron", ""], ["Bellemare", "Marc G.", ""]]}, {"id": "1808.09847", "submitter": "\\\"Ozg\\\"ur Akg\\\"un", "authors": "\\\"Ozg\\\"ur Akg\\\"un, Ian Miguel", "title": "Modelling Langford's Problem: A Viewpoint for Search", "comments": null, "journal-ref": "ModRef 2018 - The 17th workshop on Constraint Modelling and\n  Reformulation", "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The performance of enumerating all solutions to an instance of Langford's\nProblem is sensitive to the model and the search strategy. In this paper we\ncompare the performance of a large variety of models, all derived from two base\nviewpoints. We empirically show that a channelled model with a static branching\norder on one of the viewpoints offers the best performance out of all the\noptions we consider. Surprisingly, one of the base models proves very effective\nfor propagation, while the other provides an effective means of stating a\nstatic search order.\n", "versions": [{"version": "v1", "created": "Wed, 29 Aug 2018 14:25:55 GMT"}], "update_date": "2018-08-30", "authors_parsed": [["Akg\u00fcn", "\u00d6zg\u00fcr", ""], ["Miguel", "Ian", ""]]}, {"id": "1808.09888", "submitter": "Shi Yin", "authors": "Shi Yin, Yi Zhou, Chenguang Li, Shangfei Wang, Jianmin Ji, Xiaoping\n  Chen, Ruili Wang", "title": "KDSL: a Knowledge-Driven Supervised Learning Framework for Word Sense\n  Disambiguation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose KDSL, a new word sense disambiguation (WSD) framework that\nutilizes knowledge to automatically generate sense-labeled data for supervised\nlearning. First, from WordNet, we automatically construct a semantic knowledge\nbase called DisDict, which provides refined feature words that highlight the\ndifferences among word senses, i.e., synsets. Second, we automatically generate\nnew sense-labeled data by DisDict from unlabeled corpora. Third, these\ngenerated data, together with manually labeled data and unlabeled data, are fed\nto a neural framework conducting supervised and unsupervised learning jointly\nto model the semantic relations among synsets, feature words and their\ncontexts. The experimental results show that KDSL outperforms several\nrepresentative state-of-the-art methods on various major benchmarks.\nInterestingly, it performs relatively well even when manually labeled data is\nunavailable, thus provides a potential solution for similar tasks in a lack of\nmanual annotations.\n", "versions": [{"version": "v1", "created": "Tue, 28 Aug 2018 12:20:37 GMT"}, {"version": "v2", "created": "Thu, 30 Aug 2018 04:01:52 GMT"}, {"version": "v3", "created": "Wed, 5 Sep 2018 00:47:51 GMT"}, {"version": "v4", "created": "Mon, 24 Sep 2018 07:31:08 GMT"}], "update_date": "2018-09-25", "authors_parsed": [["Yin", "Shi", ""], ["Zhou", "Yi", ""], ["Li", "Chenguang", ""], ["Wang", "Shangfei", ""], ["Ji", "Jianmin", ""], ["Chen", "Xiaoping", ""], ["Wang", "Ruili", ""]]}, {"id": "1808.09890", "submitter": "Isak Czeresnia Etinger", "authors": "Isak Czeresnia Etinger", "title": "An Adaptive Conversational Bot Framework", "comments": "5 pages, Microsoft, \\'Ecole polytechnique", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  How can we enable users to heavily specify criteria for database queries in a\nuser-friendly way? This paper describes a general framework of a conversational\nbot that extracts meaningful information from user's sentences, that asks\nsubsequent questions to complete missing information, and that adjusts its\nquestions and information-extraction parameters for later conversations\ndepending on users' behavior. Additionally, we provide a comparison of existing\ntools and give novel techniques to implement such framework. Finally, we\nexemplify the framework with a bot to query movies in a database, whose code is\navailable for Microsoft employees.\n", "versions": [{"version": "v1", "created": "Mon, 27 Aug 2018 21:37:42 GMT"}], "update_date": "2018-08-30", "authors_parsed": [["Etinger", "Isak Czeresnia", ""]]}, {"id": "1808.09942", "submitter": "Nitish Gupta", "authors": "Nitish Gupta and Mike Lewis", "title": "Neural Compositional Denotational Semantics for Question Answering", "comments": "EMNLP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Answering compositional questions requiring multi-step reasoning is\nchallenging. We introduce an end-to-end differentiable model for interpreting\nquestions about a knowledge graph (KG), which is inspired by formal approaches\nto semantics. Each span of text is represented by a denotation in a KG and a\nvector that captures ungrounded aspects of meaning. Learned composition modules\nrecursively combine constituent spans, culminating in a grounding for the\ncomplete sentence which answers the question. For example, to interpret \"not\ngreen\", the model represents \"green\" as a set of KG entities and \"not\" as a\ntrainable ungrounded vector---and then uses this vector to parameterize a\ncomposition function that performs a complement operation. For each sentence,\nwe build a parse chart subsuming all possible parses, allowing the model to\njointly learn both the composition operators and output structure by gradient\ndescent from end-task supervision. The model learns a variety of challenging\nsemantic operators, such as quantifiers, disjunctions and composed relations,\nand infers latent syntactic structure. It also generalizes well to longer\nquestions than seen in its training data, in contrast to RNN, its tree-based\nvariants, and semantic parsing baselines.\n", "versions": [{"version": "v1", "created": "Wed, 29 Aug 2018 17:43:11 GMT"}], "update_date": "2018-08-30", "authors_parsed": [["Gupta", "Nitish", ""], ["Lewis", "Mike", ""]]}, {"id": "1808.09996", "submitter": "Jatin Ganhotra", "authors": "Janarthanan Rajendran, Jatin Ganhotra, Satinder Singh, Lazaros\n  Polymenakos", "title": "Learning End-to-End Goal-Oriented Dialog with Multiple Answers", "comments": "EMNLP 2018. permuted-bAbI dialog tasks are available at -\n  https://github.com/IBM/permuted-bAbI-dialog-tasks", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In a dialog, there can be multiple valid next utterances at any point. The\npresent end-to-end neural methods for dialog do not take this into account.\nThey learn with the assumption that at any time there is only one correct next\nutterance. In this work, we focus on this problem in the goal-oriented dialog\nsetting where there are different paths to reach a goal. We propose a new\nmethod, that uses a combination of supervised learning and reinforcement\nlearning approaches to address this issue. We also propose a new and more\neffective testbed, permuted-bAbI dialog tasks, by introducing multiple valid\nnext utterances to the original-bAbI dialog tasks, which allows evaluation of\ngoal-oriented dialog systems in a more realistic setting. We show that there is\na significant drop in performance of existing end-to-end neural methods from\n81.5% per-dialog accuracy on original-bAbI dialog tasks to 30.3% on\npermuted-bAbI dialog tasks. We also show that our proposed method improves the\nperformance and achieves 47.3% per-dialog accuracy on permuted-bAbI dialog\ntasks.\n", "versions": [{"version": "v1", "created": "Fri, 24 Aug 2018 19:24:58 GMT"}], "update_date": "2018-08-31", "authors_parsed": [["Rajendran", "Janarthanan", ""], ["Ganhotra", "Jatin", ""], ["Singh", "Satinder", ""], ["Polymenakos", "Lazaros", ""]]}, {"id": "1808.10009", "submitter": "Aishwarya Padmakumar", "authors": "Aishwarya Padmakumar and Peter Stone and Raymond J. Mooney", "title": "Learning a Policy for Opportunistic Active Learning", "comments": "EMNLP 2018 Camera Ready", "journal-ref": "EMNLP 2018", "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Active learning identifies data points to label that are expected to be the\nmost useful in improving a supervised model. Opportunistic active learning\nincorporates active learning into interactive tasks that constrain possible\nqueries during interactions. Prior work has shown that opportunistic active\nlearning can be used to improve grounding of natural language descriptions in\nan interactive object retrieval task. In this work, we use reinforcement\nlearning for such an object retrieval task, to learn a policy that effectively\ntrades off task completion with model improvement that would benefit future\ntasks.\n", "versions": [{"version": "v1", "created": "Wed, 29 Aug 2018 18:40:26 GMT"}], "update_date": "2018-08-31", "authors_parsed": [["Padmakumar", "Aishwarya", ""], ["Stone", "Peter", ""], ["Mooney", "Raymond J.", ""]]}, {"id": "1808.10012", "submitter": "Niket Tandon", "authors": "Niket Tandon, Bhavana Dalvi Mishra, Joel Grus, Wen-tau Yih, Antoine\n  Bosselut, Peter Clark", "title": "Reasoning about Actions and State Changes by Injecting Commonsense\n  Knowledge", "comments": "Accepted at EMNLP 2018. Niket Tandon and Bhavana Dalvi Mishra\n  contributed equally to this work", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Comprehending procedural text, e.g., a paragraph describing photosynthesis,\nrequires modeling actions and the state changes they produce, so that questions\nabout entities at different timepoints can be answered. Although several recent\nsystems have shown impressive progress in this task, their predictions can be\nglobally inconsistent or highly improbable. In this paper, we show how the\npredicted effects of actions in the context of a paragraph can be improved in\ntwo ways: (1) by incorporating global, commonsense constraints (e.g., a\nnon-existent entity cannot be destroyed), and (2) by biasing reading with\npreferences from large-scale corpora (e.g., trees rarely move). Unlike earlier\nmethods, we treat the problem as a neural structured prediction task, allowing\nhard and soft constraints to steer the model away from unlikely predictions. We\nshow that the new model significantly outperforms earlier systems on a\nbenchmark dataset for procedural text comprehension (+8% relative gain), and\nthat it also avoids some of the nonsensical predictions that earlier systems\nmake.\n", "versions": [{"version": "v1", "created": "Wed, 29 Aug 2018 18:53:53 GMT"}], "update_date": "2018-08-31", "authors_parsed": [["Tandon", "Niket", ""], ["Mishra", "Bhavana Dalvi", ""], ["Grus", "Joel", ""], ["Yih", "Wen-tau", ""], ["Bosselut", "Antoine", ""], ["Clark", "Peter", ""]]}, {"id": "1808.10073", "submitter": "Zhiqian Chen", "authors": "Zhiqian Chen, Feng Chen, Rongjie Lai, Xuchao Zhang and Chang-Tien Lu", "title": "Rational Neural Networks for Approximating Jump Discontinuities of Graph\n  Convolution Operator", "comments": "ICDM 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For node level graph encoding, a recent important state-of-art method is the\ngraph convolutional networks (GCN), which nicely integrate local vertex\nfeatures and graph topology in the spectral domain. However, current studies\nsuffer from several drawbacks: (1) graph CNNs relies on Chebyshev polynomial\napproximation which results in oscillatory approximation at jump\ndiscontinuities; (2) Increasing the order of Chebyshev polynomial can reduce\nthe oscillations issue, but also incurs unaffordable computational cost; (3)\nChebyshev polynomials require degree $\\Omega$(poly(1/$\\epsilon$)) to\napproximate a jump signal such as $|x|$, while rational function only needs\n$\\mathcal{O}$(poly log(1/$\\epsilon$))\\cite{liang2016deep,telgarsky2017neural}.\nHowever, it's non-trivial to apply rational approximation without increasing\ncomputational complexity due to the denominator. In this paper, the superiority\nof rational approximation is exploited for graph signal recovering. RatioanlNet\nis proposed to integrate rational function and neural networks. We show that\nrational function of eigenvalues can be rewritten as a function of graph\nLaplacian, which can avoid multiplication by the eigenvector matrix. Focusing\non the analysis of approximation on graph convolution operation, a graph signal\nregression task is formulated. Under graph signal regression task, its time\ncomplexity can be significantly reduced by graph Fourier transform. To overcome\nthe local minimum problem of neural networks model, a relaxed Remez algorithm\nis utilized to initialize the weight parameters. Convergence rate of\nRatioanlNet and polynomial based methods on jump signal is analyzed for a\ntheoretical guarantee. The extensive experimental results demonstrated that our\napproach could effectively characterize the jump discontinuities, outperforming\ncompeting methods by a substantial margin on both synthetic and real-world\ngraphs.\n", "versions": [{"version": "v1", "created": "Thu, 30 Aug 2018 00:33:28 GMT"}], "update_date": "2020-03-12", "authors_parsed": [["Chen", "Zhiqian", ""], ["Chen", "Feng", ""], ["Lai", "Rongjie", ""], ["Zhang", "Xuchao", ""], ["Lu", "Chang-Tien", ""]]}, {"id": "1808.10104", "submitter": "Md Kamruzzaman Sarker", "authors": "Md. Kamruzzaman Sarker, David Carral, Adila A. Krisnadhi, Pascal\n  Hitzler", "title": "Modeling OWL with Rules: The ROWL Protege Plugin", "comments": "Accepted at ISWC 2016", "journal-ref": "S. Md Kamruzzaman, Carral, D., Krisnadhi, A., and Hitzler, P.,\n  Modeling OWL with Rules: The ROWL Protege Plugin Kobe, Japan, 2016", "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In our experience, some ontology users find it much easier to convey logical\nstatements using rules rather than OWL (or description logic) axioms. Based on\nrecent theoretical developments on transformations between rules and\ndescription logics, we develop ROWL, a Protege plugin that allows users to\nenter OWL axioms by way of rules; the plugin then automatically converts these\nrules into OWL DL axioms if possible, and prompts the user in case such a\nconversion is not possible without weakening the semantics of the rule.\n", "versions": [{"version": "v1", "created": "Thu, 30 Aug 2018 03:55:11 GMT"}], "update_date": "2018-08-31", "authors_parsed": [["Sarker", "Md. Kamruzzaman", ""], ["Carral", "David", ""], ["Krisnadhi", "Adila A.", ""], ["Hitzler", "Pascal", ""]]}, {"id": "1808.10105", "submitter": "Md Kamruzzaman Sarker", "authors": "Md. Kamruzzaman Sarker, Adila A. Krisnadhi, Pascal Hitzler", "title": "OWLAx: A Protege Plugin to Support Ontology Axiomatization through\n  Diagramming", "comments": "Poster in ISWC 2016", "journal-ref": "The 15th International Semantic Web Conference (ISWC 2016) Kobe,\n  Japan", "doi": null, "report-no": null, "categories": "cs.AI cs.DB", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Once the conceptual overview, in terms of a somewhat informal class diagram,\nhas been designed in the course of engineering an ontology, the process of\nadding many of the appropriate logical axioms is mostly a routine task. We\nprovide a Protege plugin which supports this task, together with a visual user\ninterface, based on established methods for ontology design pattern modeling.\n", "versions": [{"version": "v1", "created": "Thu, 30 Aug 2018 03:57:58 GMT"}], "update_date": "2018-08-31", "authors_parsed": [["Sarker", "Md. Kamruzzaman", ""], ["Krisnadhi", "Adila A.", ""], ["Hitzler", "Pascal", ""]]}, {"id": "1808.10108", "submitter": "Md Kamruzzaman Sarker", "authors": "Md. Kamruzzaman Sarker, Adila Krisnadhi, David Carral, Pascal Hitzler", "title": "Rule-based OWL Modeling with ROWLTab Protege Plugin", "comments": "Accepted at ESWC 2017", "journal-ref": "14th ESWC 2017, Portoroz, Slovenia", "doi": null, "report-no": null, "categories": "cs.AI cs.DB cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It has been argued that it is much easier to convey logical statements using\nrules rather than OWL (or description logic (DL)) axioms. Based on recent\ntheoretical developments on transformations between rules and DLs, we have\ndeveloped ROWLTab, a Protege plugin that allows users to enter OWL axioms by\nway of rules; the plugin then automatically converts these rules into OWL 2 DL\naxioms if possible, and prompts the user in case such a conversion is not\npossible without weakening the semantics of the rule. In this paper, we present\nROWLTab, together with a user evaluation of its effectiveness compared to\nentering axioms using the standard Protege interface. Our evaluation shows that\nmodeling with ROWLTab is much quicker than the standard interface, while at the\nsame time, also less prone to errors for hard modeling tasks.\n", "versions": [{"version": "v1", "created": "Thu, 30 Aug 2018 04:05:35 GMT"}], "update_date": "2018-08-31", "authors_parsed": [["Sarker", "Md. Kamruzzaman", ""], ["Krisnadhi", "Adila", ""], ["Carral", "David", ""], ["Hitzler", "Pascal", ""]]}, {"id": "1808.10120", "submitter": "Andy Kitchen BSc", "authors": "Andy Kitchen and Michela Benedetti", "title": "ExIt-OOS: Towards Learning from Planning in Imperfect Information Games", "comments": "8 pages. 1 figure, 5 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.GT cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The current state of the art in playing many important perfect information\ngames, including Chess and Go, combines planning and deep reinforcement\nlearning with self-play. We extend this approach to imperfect information games\nand present ExIt-OOS, a novel approach to playing imperfect information games\nwithin the Expert Iteration framework and inspired by AlphaZero. We use Online\nOutcome Sampling, an online search algorithm for imperfect information games in\nplace of MCTS. While training online, our neural strategy is used to improve\nthe accuracy of playouts in OOS, allowing a learning and planning feedback loop\nfor imperfect information games.\n", "versions": [{"version": "v1", "created": "Thu, 30 Aug 2018 05:04:44 GMT"}, {"version": "v2", "created": "Thu, 25 Oct 2018 00:51:42 GMT"}], "update_date": "2018-10-26", "authors_parsed": [["Kitchen", "Andy", ""], ["Benedetti", "Michela", ""]]}, {"id": "1808.10133", "submitter": "Belinda Spratt", "authors": "Belinda Spratt and Erhan Kozan", "title": "A real-time reactive framework for the surgical case sequencing problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we address the multiple operating room (OR) surgical case\nsequencing problem (SCSP). The objective is to maximise total OR utilisation\nduring standard opening hours. This work uses a case study of a large\nAustralian public hospital with long surgical waiting lists and high levels of\nnon-elective demand. Due to the complexity of the SCSP and the size of the\ninstances considered herein, heuristic techniques are required to solve the\nproblem. We present constructive heuristics based on both a modified block\nscheduling policy and an open scheduling policy. A number of real-time reactive\nstrategies are presented that can be used to maintain schedule feasibility in\nthe case of disruptions. Results of computational experiments show that this\napproach maintains schedule feasibility in real-time, whilst increasing\noperating theatre (OT) utilisation and throughput, and reducing the waiting\ntime of non-elective patients. The framework presented here is applicable to\nthe real-life scheduling of OT departments, and we provide recommendations\nregarding implementation of the approach.\n", "versions": [{"version": "v1", "created": "Thu, 30 Aug 2018 06:28:49 GMT"}, {"version": "v2", "created": "Thu, 3 Jan 2019 05:16:31 GMT"}, {"version": "v3", "created": "Fri, 7 Jun 2019 02:54:00 GMT"}], "update_date": "2019-06-10", "authors_parsed": [["Spratt", "Belinda", ""], ["Kozan", "Erhan", ""]]}, {"id": "1808.10134", "submitter": "Fan Zhu", "authors": "Fan Zhu, Lin Ma, Xin Xu, Dingfeng Guo, Xiao Cui, and Qi Kong", "title": "Baidu Apollo Auto-Calibration System - An Industry-Level Data-Driven and\n  Learning based Vehicle Longitude Dynamic Calibrating Algorithm", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For any autonomous driving vehicle, control module determines its road\nperformance and safety, i.e. its precision and stability should stay within a\ncarefully-designed range. Nonetheless, control algorithms require vehicle\ndynamics (such as longitudinal dynamics) as inputs, which, unfortunately, are\nobscure to calibrate in real time. As a result, to achieve reasonable\nperformance, most, if not all, research-oriented autonomous vehicles do manual\ncalibrations in a one-by-one fashion. Since manual calibration is not\nsustainable once entering into mass production stage for industrial purposes,\nwe here introduce a machine-learning based auto-calibration system for\nautonomous driving vehicles. In this paper, we will show how we build a\ndata-driven longitudinal calibration procedure using machine learning\ntechniques. We first generated offline calibration tables from human driving\ndata. The offline table serves as an initial guess for later uses and it only\nneeds twenty-minutes data collection and process. We then used an\nonline-learning algorithm to appropriately update the initial table (the\noffline table) based on real-time performance analysis. This longitudinal\nauto-calibration system has been deployed to more than one hundred Baidu Apollo\nself-driving vehicles (including hybrid family vehicles and electronic\ndelivery-only vehicles) since April 2018. By August 27, 2018, it had been\ntested for more than two thousands hours, ten thousands kilometers (6,213\nmiles) and yet proven to be effective.\n", "versions": [{"version": "v1", "created": "Thu, 30 Aug 2018 06:29:10 GMT"}], "update_date": "2018-08-31", "authors_parsed": [["Zhu", "Fan", ""], ["Ma", "Lin", ""], ["Xu", "Xin", ""], ["Guo", "Dingfeng", ""], ["Cui", "Xiao", ""], ["Kong", "Qi", ""]]}, {"id": "1808.10139", "submitter": "Belinda Spratt", "authors": "Belinda Spratt and Erhan Kozan", "title": "An integrated rolling horizon approach to increase operating theatre\n  efficiency", "comments": "arXiv admin note: substantial text overlap with arXiv:1808.10133", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Demand for healthcare is increasing rapidly. To meet demand, we must improve\nthe efficiency of our public health services. We present a mixed integer\nprogramming (MIP) formulation that simultaneously tackles the integrated Master\nSurgical Schedule (MSS) and Surgical Case Assignment (SCA) problems. We\nconsider volatile surgical durations and non-elective arrivals whilst applying\na rolling horizon approach to adjust the schedule after cancellations,\nequipment failure, or new arrivals on the waiting list. A case study of an\nAustralian public hospital with a large surgical department is the basis for\nthe model. The formulation includes significant detail and provides\npractitioners with a globally implementable model. We produce good feasible\nsolutions in short amounts of computational time with a constructive heuristic\nand two hyper metaheuristics. Using a rolling horizon schedule increases\npatient throughput and can help reduce waiting lists.\n", "versions": [{"version": "v1", "created": "Thu, 30 Aug 2018 06:39:23 GMT"}, {"version": "v2", "created": "Sat, 8 Sep 2018 07:07:38 GMT"}, {"version": "v3", "created": "Mon, 14 Jan 2019 07:18:53 GMT"}], "update_date": "2019-06-07", "authors_parsed": [["Spratt", "Belinda", ""], ["Kozan", "Erhan", ""]]}, {"id": "1808.10369", "submitter": "Risto Kojcev", "authors": "V\\'ictor Mayoral Vilches, Alejandro Hern\\'andez Cordero, Asier Bilbao\n  Calvo, Irati Zamalloa Ugarte, Risto Kojcev", "title": "Robot_gym: accelerated robot training through simulation in the cloud\n  with ROS and Gazebo", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Rather than programming, training allows robots to achieve behaviors that\ngeneralize better and are capable to respond to real-world needs. However, such\ntraining requires a big amount of experimentation which is not always feasible\nfor a physical robot. In this work, we present robot_gym, a framework to\naccelerate robot training through simulation in the cloud that makes use of\nroboticists' tools, simplifying the development and deployment processes on\nreal robots. We unveil that, for simple tasks, simple 3DoF robots require more\nthan 140 attempts to learn. For more complex, 6DoF robots, the number of\nattempts increases to more than 900 for the same task. We demonstrate that our\nframework, for simple tasks, accelerates the robot training time by more than\n33% while maintaining similar levels of accuracy and repeatability.\n", "versions": [{"version": "v1", "created": "Thu, 30 Aug 2018 15:55:42 GMT"}], "update_date": "2018-08-31", "authors_parsed": [["Vilches", "V\u00edctor Mayoral", ""], ["Cordero", "Alejandro Hern\u00e1ndez", ""], ["Calvo", "Asier Bilbao", ""], ["Ugarte", "Irati Zamalloa", ""], ["Kojcev", "Risto", ""]]}, {"id": "1808.10393", "submitter": "Ashish Mehta", "authors": "Ashish Mehta, Adithya Subramanian, Anbumani Subramanian", "title": "Learning End-to-end Autonomous Driving using Guided Auxiliary\n  Supervision", "comments": "12 pages, 5 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.RO stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Learning to drive faithfully in highly stochastic urban settings remains an\nopen problem. To that end, we propose a Multi-task Learning from Demonstration\n(MT-LfD) framework which uses supervised auxiliary task prediction to guide the\nmain task of predicting the driving commands. Our framework involves an\nend-to-end trainable network for imitating the expert demonstrator's driving\ncommands. The network intermediately predicts visual affordances and action\nprimitives through direct supervision which provide the aforementioned\nauxiliary supervised guidance. We demonstrate that such joint learning and\nsupervised guidance facilitates hierarchical task decomposition, assisting the\nagent to learn faster, achieve better driving performance and increases\ntransparency of the otherwise black-box end-to-end network. We run our\nexperiments to validate the MT-LfD framework in CARLA, an open-source urban\ndriving simulator. We introduce multiple non-player agents in CARLA and induce\ntemporal noise in them for realistic stochasticity.\n", "versions": [{"version": "v1", "created": "Thu, 30 Aug 2018 16:46:22 GMT"}], "update_date": "2018-08-31", "authors_parsed": [["Mehta", "Ashish", ""], ["Subramanian", "Adithya", ""], ["Subramanian", "Anbumani", ""]]}, {"id": "1808.10442", "submitter": "Henry Charlesworth", "authors": "Henry Charlesworth", "title": "Application of Self-Play Reinforcement Learning to a Four-Player Game of\n  Imperfect Information", "comments": "6 pages + 7 pages SI, 5 figures in total", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new virtual environment for simulating a card game known as\n\"Big 2\". This is a four-player game of imperfect information with a relatively\ncomplicated action space (being allowed to play 1,2,3,4 or 5 card combinations\nfrom an initial starting hand of 13 cards). As such it poses a challenge for\nmany current reinforcement learning methods. We then use the recently proposed\n\"Proximal Policy Optimization\" algorithm to train a deep neural network to play\nthe game, purely learning via self-play, and find that it is able to reach a\nlevel which outperforms amateur human players after only a relatively short\namount of training time and without needing to search a tree of future game\nstates.\n", "versions": [{"version": "v1", "created": "Thu, 30 Aug 2018 11:26:59 GMT"}], "update_date": "2018-09-03", "authors_parsed": [["Charlesworth", "Henry", ""]]}, {"id": "1808.10568", "submitter": "Xi Victoria Lin", "authors": "Xi Victoria Lin and Richard Socher and Caiming Xiong", "title": "Multi-Hop Knowledge Graph Reasoning with Reward Shaping", "comments": "Accepted to EMNLP 2018, 12 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-hop reasoning is an effective approach for query answering (QA) over\nincomplete knowledge graphs (KGs). The problem can be formulated in a\nreinforcement learning (RL) setup, where a policy-based agent sequentially\nextends its inference path until it reaches a target. However, in an incomplete\nKG environment, the agent receives low-quality rewards corrupted by false\nnegatives in the training data, which harms generalization at test time.\nFurthermore, since no golden action sequence is used for training, the agent\ncan be misled by spurious search trajectories that incidentally lead to the\ncorrect answer. We propose two modeling advances to address both issues: (1) we\nreduce the impact of false negative supervision by adopting a pretrained\none-hop embedding model to estimate the reward of unobserved facts; (2) we\ncounter the sensitivity to spurious paths of on-policy RL by forcing the agent\nto explore a diverse set of paths using randomly generated edge masks. Our\napproach significantly improves over existing path-based KGQA models on several\nbenchmark datasets and is comparable or better than embedding-based models.\n", "versions": [{"version": "v1", "created": "Fri, 31 Aug 2018 01:55:09 GMT"}, {"version": "v2", "created": "Tue, 11 Sep 2018 22:00:49 GMT"}], "update_date": "2018-09-13", "authors_parsed": [["Lin", "Xi Victoria", ""], ["Socher", "Richard", ""], ["Xiong", "Caiming", ""]]}, {"id": "1808.10631", "submitter": "Alex James Dr", "authors": "Olga Krestinskaya, Khaled Nabil Salama, Alex Pappachen James", "title": "Learning in Memristive Neural Network Architectures using Analog\n  Backpropagation Circuits", "comments": null, "journal-ref": "IEEE Transactions on Circuits and Systems 1: Regular Papers, 2018", "doi": "10.1109/TCSI.2018.2866510", "report-no": null, "categories": "cs.ET cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The on-chip implementation of learning algorithms would speed-up the training\nof neural networks in crossbar arrays. The circuit level design and\nimplementation of backpropagation algorithm using gradient descent operation\nfor neural network architectures is an open problem. In this paper, we proposed\nthe analog backpropagation learning circuits for various memristive learning\narchitectures, such as Deep Neural Network (DNN), Binary Neural Network (BNN),\nMultiple Neural Network (MNN), Hierarchical Temporal Memory (HTM) and\nLong-Short Term Memory (LSTM). The circuit design and verification is done\nusing TSMC 180nm CMOS process models, and TiO2 based memristor models. The\napplication level validations of the system are done using XOR problem, MNIST\ncharacter and Yale face image databases\n", "versions": [{"version": "v1", "created": "Fri, 31 Aug 2018 08:31:15 GMT"}], "update_date": "2018-09-03", "authors_parsed": [["Krestinskaya", "Olga", ""], ["Salama", "Khaled Nabil", ""], ["James", "Alex Pappachen", ""]]}, {"id": "1808.10654", "submitter": "Amir Zamir", "authors": "Fei Xia, Amir Zamir, Zhi-Yang He, Alexander Sax, Jitendra Malik,\n  Silvio Savarese", "title": "Gibson Env: Real-World Perception for Embodied Agents", "comments": "Access the code, dataset, and project website at\n  http://gibsonenv.vision/ . CVPR 2018", "journal-ref": "CVPR 2018", "doi": null, "report-no": null, "categories": "cs.AI cs.CV cs.GR cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Developing visual perception models for active agents and sensorimotor\ncontrol are cumbersome to be done in the physical world, as existing algorithms\nare too slow to efficiently learn in real-time and robots are fragile and\ncostly. This has given rise to learning-in-simulation which consequently casts\na question on whether the results transfer to real-world. In this paper, we are\nconcerned with the problem of developing real-world perception for active\nagents, propose Gibson Virtual Environment for this purpose, and showcase\nsample perceptual tasks learned therein. Gibson is based on virtualizing real\nspaces, rather than using artificially designed ones, and currently includes\nover 1400 floor spaces from 572 full buildings. The main characteristics of\nGibson are: I. being from the real-world and reflecting its semantic\ncomplexity, II. having an internal synthesis mechanism, \"Goggles\", enabling\ndeploying the trained models in real-world without needing further domain\nadaptation, III. embodiment of agents and making them subject to constraints of\nphysics and space.\n", "versions": [{"version": "v1", "created": "Fri, 31 Aug 2018 09:56:43 GMT"}], "update_date": "2018-09-03", "authors_parsed": [["Xia", "Fei", ""], ["Zamir", "Amir", ""], ["He", "Zhi-Yang", ""], ["Sax", "Alexander", ""], ["Malik", "Jitendra", ""], ["Savarese", "Silvio", ""]]}, {"id": "1808.10750", "submitter": "Andrew Brockmann", "authors": "Andrew Brockmann", "title": "Victory Probability in the Fire Emblem Arena", "comments": "14 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We demonstrate how to efficiently compute the probability of victory in Fire\nEmblem arena battles. The probability can be expressed in terms of a\nmultivariate recurrence relation which lends itself to a straightforward\ndynamic programming solution. Some implementation issues are addressed, and a\nfull implementation is provided in code.\n", "versions": [{"version": "v1", "created": "Wed, 29 Aug 2018 01:21:22 GMT"}], "update_date": "2018-09-03", "authors_parsed": [["Brockmann", "Andrew", ""]]}, {"id": "1808.10784", "submitter": "David Smyth", "authors": "David L. Smyth, Frank G. Glavin, Michael G. Madden", "title": "Using a Game Engine to Simulate Critical Incidents and Data Collection\n  by Autonomous Drones", "comments": "5 Pages", "journal-ref": "David L. Smyth, Frank G. Glavin, Michael G. Madden. \"Using a Game\n  Engine to Simulate Critical Incidents and Data Collection by Autonomous\n  Drones\", IEEE Games and Entertainment Media, National University of Galway,\n  Ireland, 2018", "doi": "10.1109/GEM.2018.8516527", "report-no": null, "categories": "cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Using a game engine, we have developed a virtual environment which models\nimportant aspects of critical incident scenarios. We focused on modelling\nphenomena relating to the identification and gathering of key forensic\nevidence, in order to develop and test a system which can handle chemical,\nbiological, radiological/nuclear or explosive (CBRNe) events autonomously. This\nallows us to build and validate AI-based technologies, which can be trained and\ntested in our custom virtual environment before being deployed in real-world\nscenarios. We have used our virtual scenario to rapidly prototype a system\nwhich can use simulated Remote Aerial Vehicles (RAVs) to gather images from the\nenvironment for the purpose of mapping. Our environment provides us with an\neffective medium through which we can develop and test various AI methodologies\nfor critical incident scene assessment, in a safe and controlled manner\n", "versions": [{"version": "v1", "created": "Fri, 31 Aug 2018 14:38:23 GMT"}, {"version": "v2", "created": "Mon, 17 Dec 2018 12:19:52 GMT"}], "update_date": "2018-12-18", "authors_parsed": [["Smyth", "David L.", ""], ["Glavin", "Frank G.", ""], ["Madden", "Michael G.", ""]]}, {"id": "1808.10792", "submitter": "Sebastian Gehrmann", "authors": "Sebastian Gehrmann, Yuntian Deng, Alexander M. Rush", "title": "Bottom-Up Abstractive Summarization", "comments": "EMNLP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural network-based methods for abstractive summarization produce outputs\nthat are more fluent than other techniques, but which can be poor at content\nselection. This work proposes a simple technique for addressing this issue: use\na data-efficient content selector to over-determine phrases in a source\ndocument that should be part of the summary. We use this selector as a\nbottom-up attention step to constrain the model to likely phrases. We show that\nthis approach improves the ability to compress text, while still generating\nfluent summaries. This two-step process is both simpler and higher performing\nthan other end-to-end content selection models, leading to significant\nimprovements on ROUGE for both the CNN-DM and NYT corpus. Furthermore, the\ncontent selector can be trained with as little as 1,000 sentences, making it\neasy to transfer a trained summarizer to a new domain.\n", "versions": [{"version": "v1", "created": "Fri, 31 Aug 2018 14:55:52 GMT"}, {"version": "v2", "created": "Tue, 9 Oct 2018 02:04:07 GMT"}], "update_date": "2018-10-10", "authors_parsed": [["Gehrmann", "Sebastian", ""], ["Deng", "Yuntian", ""], ["Rush", "Alexander M.", ""]]}, {"id": "1808.10813", "submitter": "Oleg Shylo", "authors": "Oleg V. Shylo, Hesam Shams", "title": "Boosting Binary Optimization via Binary Classification: A Case Study of\n  Job Shop Scheduling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many optimization techniques evaluate solutions consecutively, where the next\ncandidate for evaluation is determined by the results of previous evaluations.\nFor example, these include iterative methods, \"black box\" optimization\nalgorithms, simulated annealing, evolutionary algorithms and tabu search, to\nname a few. When solving an optimization problem, these algorithms evaluate a\nlarge number of solutions, which raises the following question: Is it possible\nto learn something about the optimum using these solutions? In this paper, we\ndefine this \"learning\" question in terms of a logistic regression model and\nexplore its predictive accuracy computationally. The proposed model uses a\ncollection of solutions to predict the components of the optimal solutions. To\nillustrate the utility of such predictions, we embed the logistic regression\nmodel into the tabu search algorithm for job shop scheduling problem. The\nresulting framework is simple to implement, yet provides a significant boost to\nthe performance of the standard tabu search.\n", "versions": [{"version": "v1", "created": "Fri, 31 Aug 2018 15:42:55 GMT"}], "update_date": "2018-09-03", "authors_parsed": [["Shylo", "Oleg V.", ""], ["Shams", "Hesam", ""]]}, {"id": "1808.10831", "submitter": "Alberto Camacho", "authors": "Alberto Camacho, Meghyn Bienvenu and Sheila A. McIlraith", "title": "Finite LTL Synthesis with Environment Assumptions and Quality Measures", "comments": "14 pages. To appear in the Proceedings of the 16th International\n  Conference on Principles of Knowledge Representation and Reasoning (KR 2018)\n  without the appendix proofs. The body of this paper is the same as the KR\n  2018 paper except that a minor typographic error has been corrected, as noted\n  in this paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we investigate the problem of synthesizing strategies for\nlinear temporal logic (LTL) specifications that are interpreted over finite\ntraces -- a problem that is central to the automated construction of\ncontrollers, robot programs, and business processes. We study a natural variant\nof the finite LTL synthesis problem in which strategy guarantees are predicated\non specified environment behavior. We further explore a quantitative extension\nof LTL that supports specification of quality measures, utilizing it to\nsynthesize high-quality strategies. We propose new notions of optimality and\nassociated algorithms that yield strategies that best satisfy specified quality\nmeasures. Our algorithms utilize an automata-game approach, positioning them\nwell for future implementation via existing state-of-the-art techniques.\n", "versions": [{"version": "v1", "created": "Fri, 31 Aug 2018 16:28:54 GMT"}], "update_date": "2018-09-03", "authors_parsed": [["Camacho", "Alberto", ""], ["Bienvenu", "Meghyn", ""], ["McIlraith", "Sheila A.", ""]]}]